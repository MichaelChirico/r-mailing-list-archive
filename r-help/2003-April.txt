From paulda at BATTELLE.ORG  Tue Apr  1 00:06:38 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Mon, 31 Mar 2003 17:06:38 -0500
Subject: [R] nonpos. def. var-cov matrix
Message-ID: 
 <940250A9EB37A24CBE28D858EF077749136C4B@ws-bco-mse3.milky-way.battelle.org>

R 1.6.2 for Windows, Win2k:

I have fitted a weighted least squares model using the code

"wls.out <- gls(y ~ x1 + x2 + x3 + x4 + x5 + x6 - 1, data = foo.frame, 
weights = varConstPower(form = ~ fitted(.), fixed = list(power = 0.5), 
const = 1))"

The data has 62 rows and the response is zero when the covariates are
zero.  The purpose of the model was to account
for the the fact that the variances appear to increase linearly with
the fitted values in diagnostic plots.  When I use 

"intervals(wls.out)"

R1.6.2 yields the message

"Error in intervals.gls(wls7.strat1) : Cannot get confidence 
intervals on var-cov components: Non-positive definite approximate 
variance-covariance"

Would I be correct in assuming that this means the form of the 
weighting function is incorrect?  How might I examine the estimated
variance-covariance matrix?  Any suggestions would be greatly 
appreciated.


Respectfully,

 David Paul


From mail at fwr.on.ca  Tue Apr  1 00:09:42 2003
From: mail at fwr.on.ca (Nurnberg-LaZerte)
Date: Mon, 31 Mar 2003 17:09:42 -0500
Subject: [R] Convert char vector to numeric table
Message-ID: <E1907TK-0000jk-00@server.family>

I'm a great fan of read.table(), but this time the data had a lot of cruft. So I used readLines() and editted the char vector to eventually get something like this:
"     23.4   1.5   4.2"
"     19.1   2.2   4.1"
and so on. To get that into a 3 col numeric table, I first just used:

writeLines(data,"tempfile")
read.table("tempfile",col.names=c("A","B","C"))

Works fine, but writing to a temporary file seems ... inelegant?  And read.table() doesn't take a char vector as a file or connection argument. The following works but it seems like a lot of code: 

data <- sub(" +","",data)   		# remove leading blanks for strsplit
data <- strsplit(data," +")   		# strsplit returns a list of char vectors
ndata <- character(0)			# vectorize the list of char vectors
for (ii in 1:length(data)) ndata <- c(ndata,data[[ii]])  
ndata <- as.numeric(ndata)				
dim(ndata) <- c(3,length(data))	  	
data <- t(ndata)
data.frame(A=data[,1],B=data[,2],C=data[,3])

Am I missing something?

Thanks,
Bruce L.


From trainor at uic.edu  Tue Apr  1 00:27:22 2003
From: trainor at uic.edu (Douglas Trainor)
Date: Mon, 31 Mar 2003 16:27:22 -0600
Subject: [R] monte carlo method for circle area
In-Reply-To: <20030331194604.94066.qmail@web21004.mail.yahoo.com>
References: <20030331194604.94066.qmail@web21004.mail.yahoo.com>
Message-ID: <3E88C0CA.8050100@uic.edu>

Roxana,

Ignoring R for the moment...
I'm not sure I understand your nxn window thing, but:
if you have a circle with center (A,B) and radius R,
and you have a given point (X,Y), if you conceptually
translate everything by (-A,-B), so now you have a circle
with center (0,0) and radius R, and the point (X-A,Y-B).

The given point (X,Y) is inside the original circle
if sqrt((X-A)*(X-A)+(Y-B)*(Y-B)) < R. 

The given point (X,Y) is outside the original circle
if sqrt((X-A)*(X-A)+(Y-B)*(Y-B)) > R. 

If sqrt((X-A)*(X-A)+(Y-B)*(Y-B)) = R,
then it's exactly on the edge of the circle.

If you generate many pseudo-random points (X,Y) uniformly
within a box where:  A-R < X < A+r and B-R < Y < B+r, then
you just need to count how many satisfy
sqrt((X-A)*(X-A)+(Y-B)*(Y-B)) < R and how many
do not.  Or should that be <= R ?  I just got off an
airplane, but it goes something like that.

For extra credit, how many points (X,Y) do you
need on average to calculate the area within some
margin of error (delta)? 

    douglas

Roxana Bravo wrote:

>Hello everyone
>
>I hope Im not bothering you all again. I have just begun to use R and so Im not yet familiarized with it..
>
>I ve got an assignment which consists in calculating the area of a circle given  a certain radius and center using the monte carlo method, which means that I have to plot a circle given its parameters. Limit the area inside it...with as many sample points as possible...and all of this inside a nxn size window, which could be 1x1, or any size actually. I wonder how I could just limit the area inside the circle..that would be great help for me. Some of you have given me several suggestions about plotting a circle using some built-in functions but I wonder if its suits my problem since I have to somehow limit the circles inner area.
>
>thanks a lot
>  
>


From paulda at BATTELLE.ORG  Tue Apr  1 00:52:02 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Mon, 31 Mar 2003 17:52:02 -0500
Subject: [R] nonpos. def. var-cov matrix
Message-ID: 
 <940250A9EB37A24CBE28D858EF077749136C4C@ws-bco-mse3.milky-way.battelle.org>

Well, using the Splus language reference menu I was able to find the
way to extract the approximate covariance matrix of the parameters
in the "weights" statement for a *DIFFERENT* model:

"wls2.out$apVar
                       varStruct.const.Group2 varStruct.const.Group1
lSigma
varStruct.const.Group2             219.669352            -461.166077
-1.89736618
varStruct.const.Group1            -461.166077            9774.570475
3.97560767
lSigma                              -1.897366               3.975608
0.01854346
attr(,"Pars")
varStruct.const.Group2 varStruct.const.Group1                 lSigma 
             -2.577615             -14.816961               1.545618"


The 3 x 3 matrix in the first part represents the var-cov matrix of
the constant term for Group2, Group1, and the estimated variance parameter.
This particular matrix is associated with a weights statement that looks
like

"...,weights = varConstPower(form = ~ fitted(.)|Strata.Factor,
fixed = list(power = c(Group1 = 0.5, Group2 = 0.5)), const = 1),..."

I have no idea what the attr(,"Pars") part is telling me.  Trying 

"wls.out$apVar"

on the model I am *actually* interested in yields the not very helpful

[1] "Non-positive definite approximate variance-covariance"

so I guess I'm out of luck.  Suggestions for how to modify my code to
actually
get an estimated covariance matrix and/or do some diagnostics would be
especially 
welcome.  The confidence intervals for the model parameters are what I'm 
really after.

As an aside, I often use the Splus language reference to search for the
proper
tools to use in R.... I'm sure that's bad since I'm wasting my computer
memory 
by having Splus open just so I can look in the language reference
once in a while.  On the other hand, the Splus language reference is a lot
easier to use and it avoids those "...you could try `help.search(" <blah>
")'..."
messages.  Suggestions in this area would also be greatly appreciated.


Respectfully,

  david paul




-----Original Message-----
From: Paul, David A 
Sent: Monday, March 31, 2003 5:07 PM
To: 'r-help at stat.math.ethz.ch'
Subject: [R] nonpos. def. var-cov matrix


R 1.6.2 for Windows, Win2k:

I have fitted a weighted least squares model using the code

"wls.out <- gls(y ~ x1 + x2 + x3 + x4 + x5 + x6 - 1, data = foo.frame, 
weights = varConstPower(form = ~ fitted(.), fixed = list(power = 0.5), 
const = 1))"

The data has 62 rows and the response is zero when the covariates are zero.
The purpose of the model was to account for the the fact that the variances
appear to increase linearly with the fitted values in diagnostic plots.
When I use 

"intervals(wls.out)"

R1.6.2 yields the message

"Error in intervals.gls(wls7.strat1) : Cannot get confidence 
intervals on var-cov components: Non-positive definite approximate 
variance-covariance"

Would I be correct in assuming that this means the form of the 
weighting function is incorrect?  How might I examine the estimated
variance-covariance matrix?  Any suggestions would be greatly 
appreciated.


Respectfully,

 David Paul

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From sundar.dorai-raj at pdf.com  Tue Apr  1 01:12:15 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 31 Mar 2003 17:12:15 -0600
Subject: [R] Convert char vector to numeric table
References: <E1907TK-0000jk-00@server.family>
Message-ID: <3E88CB4F.5020102@pdf.com>



Nurnberg-LaZerte wrote:
> I'm a great fan of read.table(), but this time the data had a lot of cruft. So I used readLines() and editted the char vector to eventually get something like this:
> "     23.4   1.5   4.2"
> "     19.1   2.2   4.1"
> and so on. To get that into a 3 col numeric table, I first just used:
> 
> writeLines(data,"tempfile")
> read.table("tempfile",col.names=c("A","B","C"))
> 
> Works fine, but writing to a temporary file seems ... inelegant?  And read.table() doesn't take a char vector as a file or connection argument. The following works but it seems like a lot of code: 
> 
> data <- sub(" +","",data)   		# remove leading blanks for strsplit
> data <- strsplit(data," +")   		# strsplit returns a list of char vectors
> ndata <- character(0)			# vectorize the list of char vectors
> for (ii in 1:length(data)) ndata <- c(ndata,data[[ii]])  
> ndata <- as.numeric(ndata)				
> dim(ndata) <- c(3,length(data))	  	
> data <- t(ndata)
> data.frame(A=data[,1],B=data[,2],C=data[,3])
> 


Bruce,
   I don't know if this is any more elegant, but...

data <- c("     23.4   1.5   4.2","     19.1   2.2   4.1")
data.new <- as.data.frame(t(sapply(strsplit(gsub("[ \t]*"," ",data)," 
"),as.numeric))[,-1])
names(data.new) <- LETTERS[1:3]


Sundar


From laurens_leerink at yahoo.com  Tue Apr  1 01:13:06 2003
From: laurens_leerink at yahoo.com (Laurens Leerink)
Date: Mon, 31 Mar 2003 15:13:06 -0800 (PST)
Subject: [R] Windows XP specific memory problems
Message-ID: <20030331231306.95110.qmail@web40710.mail.yahoo.com>

Dear R users,

Have been using both R1.6.1 and R1.6.2 under Windows 2000 for some time now w/o
any problems.  We've been upgraded to faster machines running XP, but I've
found that the same version of R with identical command line arguments, script
and data on XP runs out of memory.  

While monitoring the process its clear that on Windows 2000 the memory usage of
Rterm stabilizes at about 750Mb, but on XP it continues to increase until it
fails just over 1.6Gb (as noted in the R for Windows FAQ, the highest value of
--max-mem-size that Rterm seems to accept is 1750M)  Have reproduced the
problem on another XP machine.  Virtual memory size is set to 4Gb (the max) and
the machine has 2Gb of physical memory.

Am curious if anyone else has encountered this problem, or any other
suggestions eg WRT Windows XP specific system parameter defaults that need to
be changed...

Thanks in advance,
Laurens Leerink


From spencer.graves at pdf.com  Tue Apr  1 01:33:17 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 31 Mar 2003 15:33:17 -0800
Subject: [R] Convert char vector to numeric table
References: <E1907TK-0000jk-00@server.family>
Message-ID: <3E88D03D.3050500@pdf.com>

Have you considered something like the following:

 > tst <- c("     23.4   1.5   4.2", "     19.1   2.2   4.1")
 > num1 <- regexpr("[0-9]", tst)
 > tst1 <- substring(tst, num1)
 > b1 <- regexpr(" ", tst1)
 > x1 <- as.numeric(substring(tst1, 1, num1))
 > tst <- substring(tst1, b1)
 > x1; tst
[1] 23.4 19.1
[1] "   1.5   4.2" "   2.2   4.1"

You can put this in a loop with appropriate modification for the end of 
the strings, etc.

Will this solve your problems?
Best Wishes,
Spencer Graves

Nurnberg-LaZerte wrote:
> I'm a great fan of read.table(), but this time the data had a lot of cruft. So I used readLines() and editted the char vector to eventually get something like this:
> "     23.4   1.5   4.2"
> "     19.1   2.2   4.1"
> and so on. To get that into a 3 col numeric table, I first just used:
> 
> writeLines(data,"tempfile")
> read.table("tempfile",col.names=c("A","B","C"))
> 
> Works fine, but writing to a temporary file seems ... inelegant?  And read.table() doesn't take a char vector as a file or connection argument. The following works but it seems like a lot of code: 
> 
> data <- sub(" +","",data)   		# remove leading blanks for strsplit
> data <- strsplit(data," +")   		# strsplit returns a list of char vectors
> ndata <- character(0)			# vectorize the list of char vectors
> for (ii in 1:length(data)) ndata <- c(ndata,data[[ii]])  
> ndata <- as.numeric(ndata)				
> dim(ndata) <- c(3,length(data))	  	
> data <- t(ndata)
> data.frame(A=data[,1],B=data[,2],C=data[,3])
> 
> Am I missing something?
> 
> Thanks,
> Bruce L.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From andys at neptuneinc.org  Tue Apr  1 02:12:35 2003
From: andys at neptuneinc.org (Andrew Schuh)
Date: Mon, 31 Mar 2003 17:12:35 -0700
Subject: [R] RODBC, freetds, and MS SQL Server
Message-ID: <200303311712.35962.andys@neptuneinc.org>

I have a question for RODBC users out there.  I have used the package with 
good results for some time.  However, I have just switched from an OpenLink 
proprietary driver for MS SQL to the FreeTDS driver (I think it is MS SQL 
Server 2000 I'm connecting to if it matters).  I was/am running them from 
unixODBC on a Linux Client.  I think I have it set up fine since I can use 
"isql" to perform simple queries on the database.  However, I get really odd 
behavior when I try to use it through RODBC.  It seems to connect fine but 
gives back odd results.  The database I'm accessing is called "cmp" and there 
are many tables of which one is called "Medium".  In the past "select * from 
cmp.Medium" has returned the whole table to me but now it only seems like I 
get column headers.  Any help or advice would be appreciated.

##-------------------------------------------------------------------------------##
> library(RODBC)
> con <- odbcConnect("BIGSKY","***","**********")
> con
RODB Connection 0
Details:
  case=nochange
  0?????????? 
> sqlTables(con)
[1] TABLE_QUALIFIER TABLE_OWNER     TABLE_NAME      TABLE_TYPE     
[5] REMARKS        
<0 rows> (or 0-length row.names)
> sqlQuery(con,"select * from Medium")
[1] "[RODBC] ERROR: Could not SQLExecute"                                                                  
[2] "S1000 1 [unixODBC] Msg 208, Level 16, State 1, Server BIGSKY, Line 
1\nInvalid object name 'Medium'.\n"
> sqlQuery(con,"select * from cmp.Medium")
[1] MediumKey Medium    IsSpecies
<0 rows> (or 0-length row.names)
> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu        
system   i686, linux-gnu
status                    
major    1
minor    6.2
year     2003             
month    01               
day      10               
language R                
>

Also, I'm using the latest RODBC I got from CRAN yesterday.

-- 
Sincerely,

+++++++++++*******+++++***++*
Andrew Schuh
Environmental Mathematician
Neptune and Co.
(970) 223-7265
andys at neptuneinc.org
+++++++++++*******+++++***++*


From james.holtman at convergys.com  Tue Apr  1 02:22:59 2003
From: james.holtman at convergys.com (james.holtman@convergys.com)
Date: Mon, 31 Mar 2003 19:22:59 -0500
Subject: [R] Convert char vector to numeric table
Message-ID: <OF69102251.B9E37A3A-ON85256CFB.0002058F@convergys.com>


use 'textConnection':

> x.1 <- c('1 2 3','4 5 6','7 8 9','8 7 6','6 5 4')   # create character
vector
> x.in <- textConnection(x.1) # setup connection
> x.data <- read.table(x.in)  # read in the character vector
> x.data
  V1 V2 V3
1  1  2  3
2  4  5  6
3  7  8  9
4  8  7  6
5  6  5  4
>



                                                                                                                                           
                      "Nurnberg-LaZerte"                                                                                                   
                      <mail at fwr.on.ca>             To:       "R's help mailing list" <r-help at stat.math.ethz.ch>                            
                      Sent by:                     cc:                                                                                     
                      r-help-bounces at stat.m        Subject:  [R] Convert char vector to numeric table                                      
                      ath.ethz.ch                                                                                                          
                                                                                                                                           
                                                                                                                                           
                      03/31/03 17:09                                                                                                       
                      Please respond to                                                                                                    
                      Nurnberg-LaZerte                                                                                                     
                                                                                                                                           
                                                                                                                                           




I'm a great fan of read.table(), but this time the data had a lot of cruft.
So I used readLines() and editted the char vector to eventually get
something like this:
"     23.4   1.5   4.2"
"     19.1   2.2   4.1"
and so on. To get that into a 3 col numeric table, I first just used:

writeLines(data,"tempfile")
read.table("tempfile",col.names=c("A","B","C"))

Works fine, but writing to a temporary file seems ... inelegant?  And
read.table() doesn't take a char vector as a file or connection argument.
The following works but it seems like a lot of code:

data <- sub(" +","",data)                        # remove leading blanks
for strsplit
data <- strsplit(data," +")                            # strsplit returns a
list of char vectors
ndata <- character(0)                                  # vectorize the list
of char vectors
for (ii in 1:length(data)) ndata <- c(ndata,data[[ii]])
ndata <- as.numeric(ndata)
dim(ndata) <- c(3,length(data))
data <- t(ndata)
data.frame(A=data[,1],B=data[,2],C=data[,3])

Am I missing something?

Thanks,
Bruce L.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help




--
"NOTICE:  The information contained in this electronic mail transmission is
intended by Convergys Corporation for the use of the named individual or
entity to which it is directed and may contain information that is
privileged or otherwise confidential.  If you have received this electronic
mail transmission in error, please delete it from your system without
copying or forwarding it, and notify the sender of the error by reply email
or by telephone (collect), so that the sender's address records can be
corrected."


From john.maindonald at anu.edu.au  Tue Apr  1 03:21:30 2003
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Tue, 1 Apr 2003 11:21:30 +1000
Subject: [R] simple test of lme, questions on DF corrections
Message-ID: <44A84E5D-63E0-11D7-ACCC-000393073F7A@anu.edu.au>

Dear Greg -
My understanding is that method="ML" changes only the
method used to fit the model.  The parameter estimates
are not the ML parameter estimates.  The fitted values
are the fitted values for ML.

The easiest way to get the anova sum of squares is to specify:
 > fm1.aov <- aov(travel~1+Error(factor(Rail)),data=Rail)
 > summary(fm1.aov)

Error: factor(Rail)
           Df Sum Sq Mean Sq F value Pr(>F)
Residuals  5 9310.5  1862.1

Error: Within
           Df  Sum Sq Mean Sq F value Pr(>F)
Residuals 12 194.000  16.167

This compares with:
 > fm1.lme <- lme(travel~1, random=~1|Rail,data=Rail,method="ML")
 > sum(fm1.lme$residuals[,2]^2)
[1] 195.0106
 > sqrt(195.0106/12)
[1] 4.031238

Consistent with this, the predicted values that are obtained with
 > predict(fm1.lme,level=1)
(the Best Linear Unbiased Predictors, or BLUPs)
are not the group means that you can get from:
 > predict(aov(travel~Rail,data=Rail))

Thus a residual mean square of 194/12 has become, in the ML fit,
195.0106/12.  This change in the predicted values (BLUPs), in the
residuals, and in the sum of squares of residuals, arises because
the likelihood is now being maximised for a model where there
are two variance parameters that must be estimated.  Notice that
the BLUPs are pulled back towards the overall mean, relative to
the group means.

NB also, specify level=1 to incorporate the random group (Rail)
effects into the predicted values.

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.

------------------------------------------------------------------------ 
-----------------
Date: Sat, 29 Mar 2003 20:19:33 -0500
From: Greg Hammett <hammett at princeton.edu>
Subject: [R] simple test of lme, questions on DF corrections
To: r-help at stat.math.ethz.ch
Message-ID: <200303300119.h2U1JXg21977 at hammett-xt.pppl.gov>
Content-Type: text/plain; charset=US-ASCII

I'm a physicist working on fusion energy and dabble in statistics
only occasionally, so please excuse gaps in my statistical
knowledge.  I'd appreciate any help that a real statistics expert
could provide.  Most people in my field do only very simple
statistics, and I am trying to extend some work on multivariate
linear regression to account for significant between-group
correlated errors.  It looks to me like the lme routine in the
nlme package does most of what I want. (My congrats to the
developers of R and nlme, they are extremely useful!).

To summarize my questions: I've tested lme on a very simple test
case (with just 1 parameter, the mean, and 1 random effect), but
the results are somewhat different than I get from some simple
maximum-likelhood formulas.  It appears that some quantities
calculated by lme are corrected for the reduction in the degrees
of freedom due to the number of fit parameters.  But these
corrections are slightly different (0.3%-3%) than what I would
have expected, and I'd like to understand these differences
better.  .....
------------------------------------------------------------------------ 
---------------


From dfalster at rna.bio.mq.edu.au  Tue Apr  1 03:45:31 2003
From: dfalster at rna.bio.mq.edu.au (Daniel Falster)
Date: Tue, 01 Apr 2003 11:45:31 +1000
Subject: [R] using Rmath standalone
Message-ID: <se897db4.089@carbon.els.mq.edu.au>

Hi,
I am a c/c++ programmer attempting to utilise the Rmath library (looks VERY useful). I have downloaded the Rsource and compiled the library as recommened (compiled on windows 98 using the cygwin environment). But whenever i try to use functions from the library i get similar error messages  - 
eg. using the function dnorm(double, double...... etc   ) i get the message : "undefined reference to dnorm4". 

dnorm4 is called by dnorm to implement the function, but for some reason the function isn't being implemented. Can anyone suggest what might be a solution to this? I have tried including all the relevant directories in my compiler path for both inlcude and library files. I don't know what else might eb the problem.

many thanks
Daniel Falster
(biologist attempting to program in a world of non-programmers)
  

**************************************
Daniel Falster
Ecology Lab, Biological Sciences
Macquarie University, NSW, 2109
Australia
Ph:( 61 2) 9850 8194 Fax: (61 2) 9850 8245
http://www.bio.mq.edu.au/ecology/falster/


From tvargas at cisco.com  Tue Apr  1 04:23:29 2003
From: tvargas at cisco.com (Tony Vargas)
Date: Mon, 31 Mar 2003 18:23:29 -0800 (PST)
Subject: [R] Autogenerated png, bitmap images
Message-ID: <Pine.GSO.4.44.0303311809590.3275-200000@tvargas-u5.cisco.com>

I have two questions -

1.  I am trying to create R png graphs via cron.  I have this part working
using Xvfb (X virtual frame buffer).  One problem that I have, though, is
that all the fonts on my graphs get messed up.  Anybody have any nija R
commands to make all fonts look great?  Anybody have any idea how to fix
this?  So far, no luck on Solaris or Linux making the Xvfb fonts look
good.

I was thining of sending an e-mail to the Xfree86 org people.  Haven't seen anything helpful on google so far.


2.  I really like the png solution that I have working, above, except for
the fonts.  Assumming that I can't get the virtual frame buffer working,
I guess I can switch to bitmap devices.  One thing I have noticed, though,
is that the bitmap files are enormous compared to the png images.  Any
idea how I could make the bmp images smaller (and create faster?) (One of
my R bmp generation files is attached.)

Thanks,

Tony

Tony Vargas
Cisco Systems
Engineering Computing Services
(408) 525-4113
tvargas at cisco.com
-------------- next part --------------
my.yugo.Mar.2003.unused.memory <- read.table(file="/auto/solperf/tgu/ActiveParsedFiles/yugo/Mar.2003/unused.memory", sep="=", header=TRUE)
names(my.yugo.Mar.2003.unused.memory)
attach(my.yugo.Mar.2003.unused.memory)
bitmap("/auto/solperf/tgu/Images/Mar.2003/yugo.Mar.2003.freemem.lines.jpg", height = 700, width = 700, type = "png256", res = 50)
plot(freemem, xlab = "Time", ylab = "Free Memory Pages Available", main = "yugo's Free Memory Pages Available Mar.2003", type="l", col="red", xaxt = "n")
temp <- seq(1, length(Time), by = 144)
axis(1, at = temp, labels = as.character(Time[temp]), las = 3)
bitmap("/auto/solperf/tgu/Thumbs/Mar.2003/yugo.Mar.2003.freemem.lines.png", height = 350, width = 350, type = "png256", res = 50)
plot(freemem, xlab = "Time", ylab = "Free Memory Pages Available", main = "yugo's Free Memory Pages Available Mar.2003", type="l", col="red", xaxt = "n")
temp <- seq(1, length(Time), by = 288)
axis(1, at = temp, labels = as.character(Time[temp]), las = 3)
bitmap("/auto/solperf/tgu/Images/Mar.2003/yugo.Mar.2003.freeswap.lines.jpg", height = 700, width = 700, type = "png256", res = 50)
plot(freeswap, xlab = "Time", ylab = "Average # of blocks availalbe for swapping", main = "yugo's Average # of blocks availalbe for swapping Mar.2003", type="l", col="red", xaxt = "n")
temp <- seq(1, length(Time), by = 144)
axis(1, at = temp, labels = as.character(Time[temp]), las = 3)
bitmap("/auto/solperf/tgu/Thumbs/Mar.2003/yugo.Mar.2003.freeswap.lines.png", height = 350, width = 350, type = "png256", res = 50)
plot(freeswap, xlab = "Time", ylab = "Average # of blocks availalbe for swapping", main = "yugo's Average # of blocks availalbe for swapping Mar.2003", type="l", col="red", xaxt = "n")
temp <- seq(1, length(Time), by = 288)
axis(1, at = temp, labels = as.character(Time[temp]), las = 3)

From bpeng at stat.rice.edu  Tue Apr  1 05:34:50 2003
From: bpeng at stat.rice.edu (Bo Peng)
Date: Mon, 31 Mar 2003 21:34:50 -0600
Subject: [R] How to list functions in a library?
Message-ID: <20030401033450.GA10562@stat.rice.edu>

I am sorry for such a simple question but I just could not find a 
command to list functions (objects) in a certain library. I had to refer 
to library documents (often not readily available ) to find them.

Many thanks in advance.

-- 
Bo Peng


From myxvfirefrore at yahoo.com  Tue Apr  1 05:47:10 2003
From: myxvfirefrore at yahoo.com (Henry)
Date: Tue, 1 Apr 2003 04:47:10 +0100
Subject: [R] Fwd: APRIL FOOLS DAY PRANK
Message-ID: <200304010347.h313lR2s010251@hypatia.math.ethz.ch>

=============APRIL FOOL`S PRANK==============


==New Features==

# Voice recognition! (live feedback from victims response).
# 17 Different pranks to play on your mates.
# Call back feature (call back your victim if they hang up).
# Listen in to the prank as your victim is wound up.


INSTRUCTIONS:

1 Dial 0906 664 1901  (Dial 09067 380 080 for the original service)
2 Select the prank 
3 Enter your victims phone number
4 Listen to their reaction as the computer dials out to them!



Calls to 09067 380 080 cost one pound per minute. Calls to 0906 664 1901 cost one pound and fifty pence per minute. Service provider: TPX 0871 872 3731. This email was sent from outside the UK. You are not on any distribution list which is controlled by the service provider. Promotion code: nhmxu


From myxvfirefrore at yahoo.com  Tue Apr  1 05:47:41 2003
From: myxvfirefrore at yahoo.com (Henry)
Date: Tue, 1 Apr 2003 04:47:41 +0100
Subject: [R] Fwd: APRIL FOOLS DAY PRANK
Message-ID: <200304010348.h313lR2u010251@hypatia.math.ethz.ch>

=============APRIL FOOL`S PRANK==============


==New Features==

# Voice recognition! (live feedback from victims response).
# 17 Different pranks to play on your mates.
# Call back feature (call back your victim if they hang up).
# Listen in to the prank as your victim is wound up.


INSTRUCTIONS:

1 Dial 0906 664 1901  (Dial 09067 380 080 for the original service)
2 Select the prank 
3 Enter your victims phone number
4 Listen to their reaction as the computer dials out to them!



Calls to 09067 380 080 cost one pound per minute. Calls to 0906 664 1901 cost one pound and fifty pence per minute. Service provider: TPX 0871 872 3731. This email was sent from outside the UK. You are not on any distribution list which is controlled by the service provider. Promotion code: nhmxu


From ripley at stats.ox.ac.uk  Tue Apr  1 08:41:36 2003
From: ripley at stats.ox.ac.uk (Prof. Brian Ripley)
Date: Tue, 1 Apr 2003 07:41:36 +0100 (BST)
Subject: [R] Convert char vector to numeric table
In-Reply-To: <E1907TK-0000jk-00@server.family>
Message-ID: <Pine.LNX.4.44.0304010740250.9220-100000@gannet.stats>

Use a file() connection (no argument) or a textConnection.

file() is a powerful tool, often overlooked.

On Mon, 31 Mar 2003, Nurnberg-LaZerte wrote:

> I'm a great fan of read.table(), but this time the data had a lot of cruft. So I used readLines() and editted the char vector to eventually get something like this:
> "     23.4   1.5   4.2"
> "     19.1   2.2   4.1"
> and so on. To get that into a 3 col numeric table, I first just used:
> 
> writeLines(data,"tempfile")
> read.table("tempfile",col.names=c("A","B","C"))
> 
> Works fine, but writing to a temporary file seems ... inelegant?  And read.table() doesn't take a char vector as a file or connection argument. The following works but it seems like a lot of code: 
> 
> data <- sub(" +","",data)   		# remove leading blanks for strsplit
> data <- strsplit(data," +")   		# strsplit returns a list of char vectors
> ndata <- character(0)			# vectorize the list of char vectors
> for (ii in 1:length(data)) ndata <- c(ndata,data[[ii]])  
> ndata <- as.numeric(ndata)				
> dim(ndata) <- c(3,length(data))	  	
> data <- t(ndata)
> data.frame(A=data[,1],B=data[,2],C=data[,3])

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Apr  1 08:52:05 2003
From: ripley at stats.ox.ac.uk (Prof. Brian Ripley)
Date: Tue, 1 Apr 2003 07:52:05 +0100 (BST)
Subject: [R] RODBC, freetds, and MS SQL Server
In-Reply-To: <200303311712.35962.andys@neptuneinc.org>
Message-ID: <Pine.LNX.4.44.0304010749550.9328-100000@gannet.stats>

?odbcConnect has

believeNRows: logical.  Is the number of rows returned by the ODBC
          connection believable?  Not true for Oracle, apparently.

Try setting it to FALSE, as it looks like your driver is broken.

I am not wure why people keep ignoring this parameter in RODBC ....


On Mon, 31 Mar 2003, Andrew Schuh wrote:

> I have a question for RODBC users out there.  I have used the package with 
> good results for some time.  However, I have just switched from an OpenLink 
> proprietary driver for MS SQL to the FreeTDS driver (I think it is MS SQL 
> Server 2000 I'm connecting to if it matters).  I was/am running them from 
> unixODBC on a Linux Client.  I think I have it set up fine since I can use 
> "isql" to perform simple queries on the database.  However, I get really odd 
> behavior when I try to use it through RODBC.  It seems to connect fine but 
> gives back odd results.  The database I'm accessing is called "cmp" and there 
> are many tables of which one is called "Medium".  In the past "select * from 
> cmp.Medium" has returned the whole table to me but now it only seems like I 
> get column headers.  Any help or advice would be appreciated.
> 
> ##-------------------------------------------------------------------------------##
> > library(RODBC)
> > con <- odbcConnect("BIGSKY","***","**********")
> > con
> RODB Connection 0
> Details:
>   case=nochange
>   0?????????? 
> > sqlTables(con)
> [1] TABLE_QUALIFIER TABLE_OWNER     TABLE_NAME      TABLE_TYPE     
> [5] REMARKS        
> <0 rows> (or 0-length row.names)
> > sqlQuery(con,"select * from Medium")
> [1] "[RODBC] ERROR: Could not SQLExecute"                                                                  
> [2] "S1000 1 [unixODBC] Msg 208, Level 16, State 1, Server BIGSKY, Line 
> 1\nInvalid object name 'Medium'.\n"
> > sqlQuery(con,"select * from cmp.Medium")
> [1] MediumKey Medium    IsSpecies
> <0 rows> (or 0-length row.names)
> > version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu        
> system   i686, linux-gnu
> status                    
> major    1
> minor    6.2
> year     2003             
> month    01               
> day      10               
> language R                
> >
> 
> Also, I'm using the latest RODBC I got from CRAN yesterday.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Apr  1 08:58:14 2003
From: ripley at stats.ox.ac.uk (Prof. Brian Ripley)
Date: Tue, 1 Apr 2003 07:58:14 +0100 (BST)
Subject: [R] using Rmath standalone
In-Reply-To: <se897db4.089@carbon.els.mq.edu.au>
Message-ID: <Pine.LNX.4.44.0304010754000.9328-100000@gannet.stats>

On Tue, 1 Apr 2003, Daniel Falster wrote:

> Hi,
> I am a c/c++ programmer attempting to utilise the Rmath library 
(looks VERY useful). I have downloaded the Rsource and compiled the 
library as recommened (compiled on windows 98 using the cygwin environment). 

We do NOT recommend a Cygwin environment!

But whenever i try to use functions from the library i get similar error messages  - 
> eg. using the function dnorm(double, double...... etc   ) i get the 
message : "undefined reference to dnorm4". 
> 
> dnorm4 is called by dnorm to implement the function, but for some 
reason the function isn't being implemented. Can anyone suggest what 
might be a solution to this? I have tried including all the relevant 
directories in my compiler path for both inlcude and library files. 
I don't know what else might eb the problem.

I assume you mean that you get the message when linking.  In that case you
have not included the import library, or not specified the path to it, or 
are using an incompatible compiler or ....

This is not an R question, and I suggest you seek local help on whatever 
compilation environment you are using.

Please learn to wrap the lines in your email messages, at about 75 chars.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From julien at swissrisk.com  Tue Apr  1 09:11:25 2003
From: julien at swissrisk.com (Julien Dinh)
Date: Tue, 1 Apr 2003 09:11:25 +0200
Subject: [R] SQL and system
Message-ID: <000b01c2f81d$e850e1b0$6c00000a@proteus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030401/7dd7811b/attachment.pl

From kwan022 at stat.auckland.ac.nz  Tue Apr  1 10:32:10 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 1 Apr 2003 20:32:10 +1200 (NZST)
Subject: [R] How to list functions in a library?
In-Reply-To: <20030401033450.GA10562@stat.rice.edu>
Message-ID: <Pine.LNX.4.33.0304012030250.3630-100000@stat56.stat.auckland.ac.nz>

Hi,

Which library is it?  If it is a proper R library and has been properly 
installed, I think you should be able to do something like:
  library(help = ts) # Get the list of functions in ts package

In fact that will also show some information about the library itself.

On Mon, 31 Mar 2003, Bo Peng wrote:

> Date: Mon, 31 Mar 2003 21:34:50 -0600
> From: Bo Peng <bpeng at stat.rice.edu>
> To: r-help at stat.math.ethz.ch
> Subject: [R] How to list functions in a library?
> 
> I am sorry for such a simple question but I just could not find a 
> command to list functions (objects) in a certain library. I had to refer 
> to library documents (often not readily available ) to find them.
> 
> Many thanks in advance.
> 
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From maechler at stat.math.ethz.ch  Tue Apr  1 09:35:08 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 1 Apr 2003 09:35:08 +0200
Subject: [R] integer overflow error problem
In-Reply-To: <Pine.LNX.4.44.0303312152540.8649-100000@gannet.stats>
References: <200303312047.h2VKlfOb028972@r.hankin.sges.auckland.ac.nz>
	<Pine.LNX.4.44.0303312152540.8649-100000@gannet.stats>
Message-ID: <16009.16684.849504.534447@gargle.gargle.HOWL>

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>>>     on Mon, 31 Mar 2003 21:57:12 +0100 (BST) writes:

    BDR> On Tue, 1 Apr 2003, Robin Hankin wrote:
    BDR> [...]

    >> Now _why_ does colon have this behaviour, when it seems that very few
    >> other functions return integers; help(":") gives no clue to the
    >> motivation.  Splus does the same thing (apparently), so there must be
    >> some rationale.  What is it?


    BDR> If you mean integers, it helps to have them to avoid rounding errors.
    BDR> S-PLUS (sic) currently thinks 20 is integer and 20. is double.

Other good rationales for "m:n" integers are
- it's half the size; at least useful if  |n-m| is big.
- when used   for(i in m:n)  {  ... x[i] ... }
  `i' is integer and will be used as such in almost all cases.

    >> Also, it would appear, both "if(2+2==4)" and "(1:10)==4" are
    >> inadvisable, because in both cases, at least one side of the "==" is a
    >> double.  How do I get round this?

    BDR> ?identical
    BDR> ?as.equal
          ^^^  typo, meant
	  all.equal

    BDR> BTW, == does coerce as needed, so 2+2==as.integer(4) is fine.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/


From ripley at stats.ox.ac.uk  Tue Apr  1 09:47:24 2003
From: ripley at stats.ox.ac.uk (Prof. Brian Ripley)
Date: Tue, 1 Apr 2003 08:47:24 +0100 (BST)
Subject: [R] How to list functions in a library?
In-Reply-To: <Pine.LNX.4.33.0304012030250.3630-100000@stat56.stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0304010840160.9425-100000@gannet.stats>

On Tue, 1 Apr 2003, Ko-Kang Kevin Wang wrote:

> Which library is it?  If it is a proper R library and has been properly 
> installed, I think you should be able to do something like:
>   library(help = ts) # Get the list of functions in ts package
> 
> In fact that will also show some information about the library itself.

Alternatively,

ls("package:ts")

will list all the objects in the package (I presume package and not 
library was meant: a library is a directory holding installed packages).

If you really want to know about the functions (and not all objects) in a 
package try

lsf.str("package:ts")

which gives the call sequences too.

> 
> On Mon, 31 Mar 2003, Bo Peng wrote:
> 
> > Date: Mon, 31 Mar 2003 21:34:50 -0600
> > From: Bo Peng <bpeng at stat.rice.edu>
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] How to list functions in a library?
> > 
> > I am sorry for such a simple question but I just could not find a 
> > command to list functions (objects) in a certain library. I had to refer 
> > to library documents (often not readily available ) to find them.
> > 
> > Many thanks in advance.
> > 
> > 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Ted.Harding at nessie.mcc.ac.uk  Tue Apr  1 00:07:36 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Mon, 31 Mar 2003 22:07:36 -0000 (BST)
Subject: [R] monte carlo method for circle area
In-Reply-To: <6r1y0nthhs.fsf@bates4.stat.wisc.edu>
Message-ID: <XFMail.030331220736.Ted.Harding@nessie.mcc.ac.uk>

On 31-Mar-03 Douglas Bates wrote:
> Interestingly, in my first simulation I got a ratio that is exactly
> pi/4 to 4 significant digits.
> 
>> rdat = matrix(runif(10000 * 2, min = -1 , max = 1), nrow = 2)
>> sum(colSums(rdat * rdat) < 1) 
> [1] 7854
>> pi/4 
> [1] 0.7853982

Assuming your error e <= 0.00005 (taken literally, e = 0.0000018).

s = SD = sqrt(p*(1-p)/10000) = 0.004105458 where p = pi/4.

So your e <= 0.00005/s SDs = 0.01217891 SDs, and

P = pnorm(0.01217891) - pnorm(-0.01217891) = 0.009717124

so you are significant! (Not that that's news).

(with e = 0.0000018, we get P = 0.0003498250, but let's not exaggerate)

Cheers,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 31-Mar-03                                       Time: 22:07:36
------------------------------ XFMail ------------------------------


From pingping.zheng at lancaster.ac.uk  Tue Apr  1 10:47:25 2003
From: pingping.zheng at lancaster.ac.uk (Pingping Zheng)
Date: Tue, 01 Apr 2003 09:47:25 +0100
Subject: [R] How to list functions in a library?
In-Reply-To: <20030401033450.GA10562@stat.rice.edu>
References: <20030401033450.GA10562@stat.rice.edu>
Message-ID: <3E89521D.9050508@lancs.ac.uk>

nm - list symbols from object files (.o .a .so etc.) - maybe that is
what you want?

nm something.so


Bo Peng wrote:
> I am sorry for such a simple question but I just could not find a 
> command to list functions (objects) in a certain library. I had to refer 
> to library documents (often not readily available ) to find them.
> 
> Many thanks in advance.
> 

-- 
Pingping Zheng
Department of Mathematics and Statistics
Fylde College
Lancaster University
Lancaster LA1 4YF
UK


From gvera at omniwhittington.com  Tue Apr  1 11:30:14 2003
From: gvera at omniwhittington.com (Vera, Graciela)
Date: Tue, 1 Apr 2003 10:30:14 +0100 
Subject: [R] RE: Computer specifications
Message-ID: <555A08FAAD36D711B17400508BB358E310A57F@OWMAIL05>



I would be most grateful for advice on optimal computer specification, and
possibly make  to run the most demanding modules in R.

Many thanks


G Vera

_______
Confidentiality Notice

This email (and any attachment) is intended only for the attention of the addressee.  Its unauthorised use, disclosure, storage or copying is not permitted.  If you are not the intended recipient, please destroy all copies and inform the sender by return email.  Thank you
____________________________________________________________________
This email has been scanned for all viruses by the MessageLabs SkyScan
service. For more information on a proactive anti-virus service working
around the clock, around the globe, visit http://www.messagelabs.com


From Beat.Huggler at rmf.ch  Tue Apr  1 11:32:05 2003
From: Beat.Huggler at rmf.ch (Beat Huggler)
Date: Tue, 1 Apr 2003 11:32:05 +0200
Subject: [R] Nlminb equivalent function in R?
Message-ID: <3635AAE6EA743844B05655F805CB3125039D8F2B@titlis.rmf.ch>

Hello everybody

I need some help. Currently, I'm translating a code from Splus to R. In Splus code there is the function nlminb (Nonlinear Minimization subject to Box Constraints) used. Does anybody know an equivalent function in R?

Thanks for help

Kind regards,
Beat Huggler

_____________________________________________

Beat Huggler
Quantitative Analysis

RMF Investment Management
Huobstrasse 16   
8808 Pf?ffikon/SZ   Switzerland
Tel +41 (0) 55 415 87 30  Fax +41 (0) 55 415 87 99
beat.huggler at rmf.ch   www.rmf.ch
A member of the Man Group



Any information in this communication is confidential and may be privileged or otherwise protected from disclosure without our consent. If you are not the intended recipient, you are not authorised to and must not disclose, copy, distribute, or retain this message or any part of it. You are requested to please telephone or email the sender and delete this message and any attachment from your system.
	
Due to the electronic nature of e-mail, there is a risk that the information contained in this message has been modified. Consequently we can accept no responsibility or liability as to the completeness or accuracy of the information.

A-03-03-E


From rita at liacc.up.pt  Tue Apr  1 11:38:16 2003
From: rita at liacc.up.pt (Rita Ribeiro)
Date: 01 Apr 2003 10:38:16 +0100
Subject: [R] Load and unload libraries
Message-ID: <1049189896.6945.703.camel@terrakente.niaad.liacc.up.pt>


Hi all,

I'm having some problems in loading libraries. I wonder if anyone can
help me with this.

I have created two libraries with the same name at different locations.

I want to use both of them, one at a time.

So I do:

library(mylib,lib.loc1)
(....)
detach('package:mylib')

library(mylib,lib.loc2)

The problem is that, after this, the used library is still the one first
loaded.

Isn't detach command enough? 

Thanks in advance,

Rita

-- 
Rita Ribeiro <rita at liacc.up.pt>


From ripley at stats.ox.ac.uk  Tue Apr  1 11:46:31 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 1 Apr 2003 10:46:31 +0100 (BST)
Subject: [R] RE: Computer specifications
In-Reply-To: <555A08FAAD36D711B17400508BB358E310A57F@OWMAIL05>
Message-ID: <Pine.LNX.4.44.0304011043190.10128-100000@gannet.stats>

Well, R likes lots of memory, so a 64-bit system with say 16Gb RAM and at 
least two processors would be pretty good.  (And is: I've used such a 
Compaq Alpha system.)

For most purposes a dual Athlon or Xeon PC running Linux with at least 1Gb 
of memory works pretty well.

On Tue, 1 Apr 2003, Vera, Graciela wrote:

> I would be most grateful for advice on optimal computer specification, and
> possibly make  to run the most demanding modules in R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Apr  1 11:47:32 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 1 Apr 2003 10:47:32 +0100 (BST)
Subject: [R] Nlminb equivalent function in R?
In-Reply-To: <3635AAE6EA743844B05655F805CB3125039D8F2B@titlis.rmf.ch>
Message-ID: <Pine.LNX.4.44.0304011046370.10128-100000@gannet.stats>

On Tue, 1 Apr 2003, Beat Huggler wrote:

> I need some help. Currently, I'm translating a code from Splus to R. 
In Splus code there is the function nlminb (Nonlinear Minimization 
subject to Box Constraints) used. Does anybody know an equivalent 
function in R?

?optim


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Apr  1 11:53:23 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 1 Apr 2003 10:53:23 +0100 (BST)
Subject: [R] Load and unload libraries
In-Reply-To: <1049189896.6945.703.camel@terrakente.niaad.liacc.up.pt>
Message-ID: <Pine.LNX.4.44.0304011047520.10128-100000@gannet.stats>

On 1 Apr 2003, Rita Ribeiro wrote:

> I'm having some problems in loading libraries. I wonder if anyone can
> help me with this.
> 
> I have created two libraries with the same name at different locations.

Do you mean packages?

> I want to use both of them, one at a time.
> 
> So I do:
> 
> library(mylib,lib.loc1)
> (....)
> detach('package:mylib')
> 
> library(mylib,lib.loc2)
> 
> The problem is that, after this, the used library is still the one first
> loaded.
> 
> Isn't detach command enough? 

Not in general. detaching a package does not in general unload any 
*library* (DLL, shared library, dynamic library, name depending on OS)
that was loaded.  If there are no namespaces involved (a new feature of 
1.7.0) it should give you the second version of the R code, and it did so 
when I just did an experiment.

I'm afraid you will need to be more precise in your terminology and give 
us more details.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rdiaz at cnio.es  Tue Apr  1 12:02:08 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Tue, 1 Apr 2003 12:02:08 +0200
Subject: [R] R function calling: efficiency of different alternatives
Message-ID: <200304011202.08220.rdiaz@cnio.es>

Dear all,

I have a piece of code, call it "FA", that will be called thousands of times 
in a typical run of function "FB". I can:

a) define FA as a function outside of FB (in the global environment), and call 
it;
b) define FA as a function inside the body of FB and call it;
c) "expand inline" FA inside FB.

FA mainly does data frame subsetting, runs svd's, and calls compiled C++ code.

I think I recall reading something about differences in efficiency between 
those three approaches, but I can't find the information (I've searched the 
email archives, Venables & Ripley's "S programming" and MASS, the R manuals, 
and Burn's "S Poetry"). 

Are there any real performance differences? 

(I'd personally prefer b) since these functions will hopefully become a 
contributed package, and FA is not supposed to be used directly by an end 
user. I am aware of scoping differences between the three approaches, but 
that is not my main concern now).

Thanks,

Ram?n

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
http://bioinfo.cnio.es/~rdiaz


From bogus@does.not.exist.com  Tue Apr  1 12:10:17 2003
From: bogus@does.not.exist.com (Ido M. Tamir)
Date: Tue, 1 Apr 2003 12:10:17 +0200
Subject: [R] survival data format
Message-ID: <200304011210.17355."Ido M. Tamir" <>>

Hi,

I have collected data in order to generate a Kaplan Meier Plot (survival 
curve).
However the data does not measure events for individuals but for the whole 
group.
e.g.
day	living		deaths	group
2	16	5	A
2	12	2	B
3	11	0	A
3	10	3	B

Can the survival package do something with this data directly or do I have to
generate a different format first.

Thanks

Ido


From rita at liacc.up.pt  Tue Apr  1 12:43:57 2003
From: rita at liacc.up.pt (Rita Ribeiro)
Date: 01 Apr 2003 11:43:57 +0100
Subject: [R] Load and unload libraries
In-Reply-To: <Pine.LNX.4.44.0304011047520.10128-100000@gannet.stats>
References: <Pine.LNX.4.44.0304011047520.10128-100000@gannet.stats>
Message-ID: <1049193837.6944.752.camel@terrakente.niaad.liacc.up.pt>

On Tue, 2003-04-01 at 10:53, Prof Brian Ripley wrote:
> On 1 Apr 2003, Rita Ribeiro wrote:
> 
> > I'm having some problems in loading libraries. I wonder if anyone can
> > help me with this.
> > 
> > I have created two libraries with the same name at different locations.
> 
> Do you mean packages?

Yes, sorry. 
Packages in tar.gz files which I have installed with R CMD INSTALL in
different locations, just to test different things.

The library locations are the paths to where the packages have been
installed.

Here's a small simulation:

> library(mylib,lib.loc1)
> .path.package("mylib") # returns lib.loc1
(...)
> detach('package:mylib')
> .path.package("rpart")
Error in .path.package(mylib) : none of the packages are loaded
> exists("mylib") # returns FALSE

> library(mylib,lib.loc2)
> .path.package("mylib") # returns lib.loc2
or
> .find.package("mylib") # returns lib.loc2

The problem is when I invoke mylib function: it uses the binary code
from the first library location.

Is there anyway of "unloading" the first library to load a new one,
although with the same name. Ie is there anyway of getting a "cleanup"
state?

Should I give different names to the packages to solve the problem? I
preferred no to....


My system information:

platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.0              
year     2002             
month    10               
day      01               
language R       

Thanks,
Rita
> 
> > I want to use both of them, one at a time.
> > 
> > So I do:
> > 
> > library(mylib,lib.loc1)
> > (....)
> > detach('package:mylib')
> > 
> > library(mylib,lib.loc2)
> > 
> > The problem is that, after this, the used library is still the one first
> > loaded.
> > 
> > Isn't detach command enough? 
> 
> Not in general. detaching a package does not in general unload any 
> *library* (DLL, shared library, dynamic library, name depending on OS)
> that was loaded.  If there are no namespaces involved (a new feature of 
> 1.7.0) it should give you the second version of the R code, and it did so 
> when I just did an experiment.
> 
> I'm afraid you will need to be more precise in your terminology and give 
> us more details.
-- 
Rita Ribeiro <rita at liacc.up.pt>


From ripley at stats.ox.ac.uk  Tue Apr  1 12:53:06 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 1 Apr 2003 11:53:06 +0100 (BST)
Subject: [R] Load and unload libraries
In-Reply-To: <1049193837.6944.752.camel@terrakente.niaad.liacc.up.pt>
Message-ID: <Pine.LNX.4.44.0304011149550.10380-100000@gannet.stats>

On 1 Apr 2003, Rita Ribeiro wrote:

> On Tue, 2003-04-01 at 10:53, Prof Brian Ripley wrote:
> > On 1 Apr 2003, Rita Ribeiro wrote:
> > 
> > > I'm having some problems in loading libraries. I wonder if anyone can
> > > help me with this.
> > > 
> > > I have created two libraries with the same name at different locations.
> > 
> > Do you mean packages?
> 
> Yes, sorry. 
> Packages in tar.gz files which I have installed with R CMD INSTALL in
> different locations, just to test different things.
> 
> The library locations are the paths to where the packages have been
> installed.
> 
> Here's a small simulation:
> 
> > library(mylib,lib.loc1)
> > .path.package("mylib") # returns lib.loc1
> (...)
> > detach('package:mylib')
> > .path.package("rpart")
> Error in .path.package(mylib) : none of the packages are loaded
> > exists("mylib") # returns FALSE
> 
> > library(mylib,lib.loc2)
> > .path.package("mylib") # returns lib.loc2
> or
> > .find.package("mylib") # returns lib.loc2
> 
> The problem is when I invoke mylib function: it uses the binary code
> from the first library location.
> 
> Is there anyway of "unloading" the first library to load a new one,
> although with the same name. Ie is there anyway of getting a "cleanup"
> state?

If you mean shared library, yes.  See the .Last.lib function in
src/library/tcltk/R/windows/zzz.R.  Don't do this if you have used the 
registration functions, though.

> Should I give different names to the packages to solve the problem? I
> preferred no to....

It's what R expects.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From B.Rowlingson at lancaster.ac.uk  Tue Apr  1 13:29:43 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 01 Apr 2003 12:29:43 +0100
Subject: [R] R function calling: efficiency of different alternatives
In-Reply-To: <200304011202.08220.rdiaz@cnio.es>
References: <200304011202.08220.rdiaz@cnio.es>
Message-ID: <3E897827.6040009@lancaster.ac.uk>

Ramon Diaz wrote:

> I think I recall reading something about differences in efficiency between 
> those three approaches, but I can't find the information (I've searched the 
> email archives, Venables & Ripley's "S programming" and MASS, the R manuals, 
> and Burn's "S Poetry"). 
> 
> Are there any real performance differences? 
> 

  I've always worked on the understanding that you should get code 
working and then profile it before you think about optimising it. 
There's no point worrying about efficiency issues with function calling 
strategies if your program is going to be spending 99% of its time doing 
those matrix operations and svd calculations.

  Do you think the overhead in searching for a function in a few tables, 
passing some parameters, and returning, is going to overwhelm the time 
taken in all the other calculations? Seems unlikely to me.

  Get it working one way or another - preferably with concerns in other 
aspects of software engineering (modularity, reusability etc) - and then 
if efficiency is a problem then profile the code to see where its 
spending its time. If it really is in the function calling mechanism, 
and not the guts of the code, then worry.

Barry


From partha_bagchi at hgsi.com  Tue Apr  1 14:38:03 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Tue, 1 Apr 2003 07:38:03 -0500
Subject: [R] Bug in Plot.table?
Message-ID: <OF9A45505B.1A9235FD-ON85256CFB.0044C416-85256CFB.00456686@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030401/7526b796/attachment.pl

From maechler at stat.math.ethz.ch  Tue Apr  1 14:52:08 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 1 Apr 2003 14:52:08 +0200
Subject: [R] Bug in Plot.table?
In-Reply-To: <OF9A45505B.1A9235FD-ON85256CFB.0044C416-85256CFB.00456686@hgsi.com>
References: <OF9A45505B.1A9235FD-ON85256CFB.0044C416-85256CFB.00456686@hgsi.com>
Message-ID: <16009.35704.201174.202502@gargle.gargle.HOWL>

>>>>> "partha" == partha bagchi <partha_bagchi at hgsi.com>
>>>>>     on Tue, 1 Apr 2003 07:38:03 -0500 writes:

    partha> While plotting a table using plot(table), I am not able to suppress the 
    partha> axes with axes = FALSE. Am I missing something or is it a bug?

    partha> For example:

    >> x <- c(rep(0, 7), rep(1, 4), rep(5, 3), rep(6, 4), rep(8, 10))
    >> table(x)

    >> plot(table(x), axes = FALSE)                #does not suppress the axes

it does suppress the y-axis only.

Yes, this can be considered to be a bug, and I'll look into a
simple fix for R 1.7.0

    >> plot(table(x), frame.plot= FALSE, axes = FASLE)   #deliberate spelling 
    partha> mistake does the job :)
    >> plot.default(table(x), type = "h", lwd= 10, axes= FALSE)  #this works

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From ben at zoo.ufl.edu  Tue Apr  1 15:13:56 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Tue, 1 Apr 2003 08:13:56 -0500 (EST)
Subject: [R] Does R have an inverse wishart distribution?
In-Reply-To: <90821ABF429A074DA88E56D1DF7A716101F512@afifs1.affinnova.com>
Message-ID: <Pine.LNX.4.44.0304010804340.1310-100000@bolker.zoo.ufl.edu>


  [Forwarding to R-list as well just so the answer ends up archived 
there.]

  Actually, now that I look again, there's actually a package already on  
CRAN (MCMCpack) that looks like it will do what you want -- 
has random draws and PDF for wishart and inverse-wishart.  It might have 
other useful components as well.
   The only thing I might conceivably have that would go beyond this is 
that the most common algorithm for generating random wishart distributions 
requires that the degrees of freedom be greater than the size (number of 
rows/columns) of the variance-covariance matrix; I coded an alternative 
algorithm without that restriction (from a Springer book by Gentle).

  Let me know if you need it, good luck.

  Ben



On Mon, 31 Mar 2003, Kevin Karty wrote:

> 
> I do in fact mean to sample from it.  Pretty much a basic MCMC using a
> Metropolis Hastings algorithm.  I was unable to find any reference to
> either of these in the help docs.  In particular, am writing a
> hierarchical bayesian multinomial logit application with a mult. Normal
> distribution of coefficients at higher level, so if you know of any
> canned algorithms, that would work as well.  Otherwise, I might be able
> to do some QA work for you. :)  
> 
> 
> -Kevin
> 
> 
> -----Original Message-----
> From: Ben Bolker [mailto:ben at zoo.ufl.edu] 
> Sent: Monday, March 31, 2003 3:25 PM
> To: Kevin Karty
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Does R have an inverse wishart distribution?
> 
> 
> 
>   Do you want to simulate from it?
>   If so, I could send you various bits of code (some sent by Bill
> Venables 
> to the S-PLUS help list long ago), which I would eventually mean to 
> package and put up.
>  
>   I don't have any code for calculating probability densities (or 
> cumulative distribution functions, or quantiles).
> 
>   Ben Bolker
> 
> On Mon, 31 Mar 2003, Kevin Karty wrote:
> 
> > 
> > 
> > If so, I've had trouble finding it.  Can anyone help?
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list 
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From Bernhard.Pfaff at drkw.com  Tue Apr  1 15:13:07 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Tue, 1 Apr 2003 15:13:07 +0200
Subject: [R] Using R2HTML
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB90047302E9@ibfftce505.is.de.dresdnerkb.com>

Hello,
I'm using R2HTML library to make a HTML page output (both data frames and
graphics):

HTMLStart(outdir=paste(getwd(),"/prove html", sep = ""),filename="index",
echo = F, HTMLframe = T, withprompt = "HTML> ", CSSFile = "R2HTML.CSS",
Title = "Indici di attivit?")
...

barplot(tab41[,2],main="...",ylab="%",names.arg=rownames(tab41),cex.names=0.
7)
grid(nx=0,ny=NULL,lty=2)
barplot(tab41[,3],main="...",ylab="",names.arg=rownames(tab41),cex.names=0.7
)
grid(nx=0,ny=NULL,lty=2)
barplot(tab41[,4],main="...",ylab="giorni",names.arg=rownames(tab41),cex.nam
es=0.7)
grid(nx=0,ny=NULL,lty=2)

HTMLplot(Caption=paste("Indici di attivit? - centro
n.",cod.centro),GraphDirectory = get(".HTML.outdir", env = get("HTMLenv",
envir = .GlobalEnv)), GraphFileName = "ind-pos",Align = "center")

	But I get this error:

Error in dev.print(png, file = AbsGraphFileName, width = 400) :
	can only print from screen device
Execution halted

Can anyone help me?
Thanks

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


Hello Gianluca,

save your graph as jpg-file first and then include it in your html-file
like:


HTMLInitFile(...)
.
.
.
HTML("<img src=\"Filename.jpg\" border=\"2\">")
.
.
.
HTMLEndFile()

HTH,
Bernhard


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------


From Ted.Harding at nessie.mcc.ac.uk  Tue Apr  1 14:49:38 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 01 Apr 2003 13:49:38 +0100 (BST)
Subject: [R] Shafer's MI software for S-plus
Message-ID: <XFMail.030401134938.Ted.Harding@nessie.mcc.ac.uk>

Greetings folks,

Shafer's S-plus package "norm" for multiple imputation of
missing values in multivariate normal data has been most
kindly and usefully ported to R by Alvaro A. Novo.

Shafer's website

  http://www.stat.psu.edu/~jls/

lists four S-plus packages in all:

  NORM - multiple imputation of multivariate continuous data

  CAT - multiple imputation of multivariate categorical data

  MIX - multiple imputation of mixed continuous and categorical data

  PAN - multiple imputation of multivariate panel or clustered data

I am particularly interested at the moment in the functionality
of "MIX", and am (naively) prepared to try my hand at getting it
into R, but I am wondering generally if this or any of the others
("CAT", "PAN") have been tried in R by anyone.

With thanks, and best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 01-Apr-03                                       Time: 13:49:38
------------------------------ XFMail ------------------------------


From v_bill_pikounis at merck.com  Tue Apr  1 15:21:43 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Tue, 01 Apr 2003 08:21:43 -0500
Subject: [R] Autogenerated png, bitmap images
Message-ID: <E827328028C66044B4998F2EC353CD3003185382@usrymx12.merck.com>

Tony,

> that all the fonts on my graphs get messed up.  Anybody have 
> any nija R
> commands to make all fonts look great?  Anybody have any idea 
> how to fix
> this?  So far, no luck on Solaris or Linux making the Xvfb fonts look

I have played with Xvfb and have not seen the same font problem (Mandrake
9.0 for Linux, R 1.6.2) generating png's via CGI (my problems are more with
CGI-secure permissions).  You mentioned running a cron (batch) job -- do you
see the same problem using R interactively (such as an ssh login with X not
running)?  Perhaps you can provide some lines of your code of your cron
script to help the diagnosis?  What is specifically messed up with the
fonts?

Adjusting the pointsize argument in png might help.

> is that the bitmap files are enormous compared to the png images.  Any
> idea how I could make the bmp images smaller (and create 
> faster?) (One of
> my R bmp generation files is attached.)

As far as bitmaps go, I think that in general the smaller they are, the less
resolution you will have. But even if you are willing to give that up, you
might need to delve into ghostscript call options, since my understanding is
that what bitmap() uses under Linux (and I presume other X11 device
approaches including Solaris).  See the code for bitmap(), in particular the
gsexe and cmd objects. (I noticed your setting of some arguments like res in
your bitmap generation file attachment, but as I guess above, other
gs-intrinsic flags may be needed.)

Hope that helps,
Bill

----------------------------------------
Bill Pikounis, Ph.D.

Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY84-16  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

v_bill_pikounis at merck.com

Phone: 732 594 3913
Fax: 732 594 1565


> -----Original Message-----
> From: Tony Vargas [mailto:tvargas at cisco.com]
> Sent: Monday, March 31, 2003 9:23 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Autogenerated png, bitmap images
> 
> 
> I have two questions -
> 
> 1.  I am trying to create R png graphs via cron.  I have this 
> part working
> using Xvfb (X virtual frame buffer).  One problem that I 
> have, though, is
> that all the fonts on my graphs get messed up.  Anybody have 
> any nija R
> commands to make all fonts look great?  Anybody have any idea 
> how to fix
> this?  So far, no luck on Solaris or Linux making the Xvfb fonts look
> good.
> 
> I was thining of sending an e-mail to the Xfree86 org people. 
>  Haven't seen anything helpful on google so far.
> 
> 
> 2.  I really like the png solution that I have working, 
> above, except for
> the fonts.  Assumming that I can't get the virtual frame 
> buffer working,
> I guess I can switch to bitmap devices.  One thing I have 
> noticed, though,
> is that the bitmap files are enormous compared to the png images.  Any
> idea how I could make the bmp images smaller (and create 
> faster?) (One of
> my R bmp generation files is attached.)
> 
> Thanks,
> 
> Tony
> 
> Tony Vargas
> Cisco Systems
> Engineering Computing Services
> (408) 525-4113
> tvargas at cisco.com
> 


------------------------------------------------------------------------------


From bpeng at stat.rice.edu  Tue Apr  1 15:32:50 2003
From: bpeng at stat.rice.edu (Bo Peng)
Date: Tue, 1 Apr 2003 07:32:50 -0600
Subject: [R] How to list functions in a library?
In-Reply-To: <3E89521D.9050508@lancs.ac.uk>
References: <20030401033450.GA10562@stat.rice.edu>
	<3E89521D.9050508@lancs.ac.uk>
Message-ID: <20030401133250.GA12731@stat.rice.edu>

Thank you all for your apply. Both commands works. For example, 

    library(help=MASS)

will list function names with description and 

   ls(package:MASS)

will list all object names.


-- 
Bo Peng


From bates at stat.wisc.edu  Tue Apr  1 16:12:38 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 01 Apr 2003 08:12:38 -0600
Subject: [R] R function calling: efficiency of different alternatives
In-Reply-To: <200304011202.08220.rdiaz@cnio.es>
References: <200304011202.08220.rdiaz@cnio.es>
Message-ID: <6rznnamhm1.fsf@bates4.stat.wisc.edu>

Ramon Diaz <rdiaz at cnio.es> writes:

> Dear all,
> 
> I have a piece of code, call it "FA", that will be called thousands of times 
> in a typical run of function "FB". I can:
> 
> a) define FA as a function outside of FB (in the global environment), and call 
> it;
> b) define FA as a function inside the body of FB and call it;
> c) "expand inline" FA inside FB.
> 
> FA mainly does data frame subsetting, runs svd's, and calls compiled C++ code.
> 
> I think I recall reading something about differences in efficiency between 
> those three approaches, but I can't find the information (I've searched the 
> email archives, Venables & Ripley's "S programming" and MASS, the R manuals, 
> and Burn's "S Poetry"). 
> 
> Are there any real performance differences? 
> 
> (I'd personally prefer b) since these functions will hopefully become a 
> contributed package, and FA is not supposed to be used directly by an end 
> user. I am aware of scoping differences between the three approaches, but 
> that is not my main concern now).

After R-1.7.0 is released you can use a namespace to make FA local to
your package.  

As Luke Tierney said in his presentation at DSC-2003, people have in
the past written functions in the style of b) primarily to keep the
names of local utility functions hidden.  Style a) and the use of
namespaces is a better way of accomplishing this.

I agree with what Barry Rowlingson wrote in his reply.  The best
approach is to write the code in the most convenient and
understandable way then profile the execution of the code to see where
the bottlenecks really are.


From fharrell at virginia.edu  Tue Apr  1 16:31:31 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Tue, 1 Apr 2003 09:31:31 -0500
Subject: [R] Re: [S] Old style and new style classes
In-Reply-To: <54C6B7921595FF40AB81D151FDFB7F4F0AAB5C@fps01.proteom.com>
References: <54C6B7921595FF40AB81D151FDFB7F4F0AAB5C@fps01.proteom.com>
Message-ID: <20030401093131.4d94f4e8.fharrell@virginia.edu>

On Tue, 1 Apr 2003 14:33:39 +0100
Jonathan Swinton <jswinton at proteom.com> wrote:

> 
> I have been writing quick and dirty S-plus code for years, but for a recent project I took the plunge, bought Venables and Ripley's S Programming, and implemented a class library using new style classes (in S-Plus 6.0). It worked quite nicely and I am wondering about making more routine use of them. Before I make much more of an investment, I have a few questions, both factual and subjective, that I'd be grateful for opinions on. 
> 
> 1) I don't use R at the moment, but I might, and might want to target users who do. The documentation at http://cran.r-project.org/doc/manuals/R-lang.pdf seems to suggest that R 1.6.2 supports only old style classes, but http://developer.r-project.org/methodsPackage.html implies that new style classes can be used with the aid of a methods package from John Chambers. Venables and Ripley only describe old-style classes for R and add in their online supplement that there are 'small changes' between S-Plus and R for new style classes. Can the new style class mechanism be used in practice transparently and portably between S-Plus and R?
> 
> 2) The s-news archives hold a few complaints about the design of the new style classes scattered over the last few years. On mature reflection, do people have opinions about the practical workability of old or new style classes for implementing reusable, object oriented code?
> 
> 3) There are also some hints (eg top line of http://developer.r-project.org/classIssues.html) that new style classes have not been committed to by some active developers. Is this true? Do new style classes have an active future? Is R committed to them?   Insightful?   
> 
> I use old-style (S version3 engine) and new-style (S version4) classes in the sense of Venables and Ripley. 
> 
>  -------------------------------------
>  Dr Jonathan Swinton
>  Proteom Ltd 
>  Babraham Hall
>  Babraham
>  Cambridge CB2 4AT
>   www.proteom.com
>  
>
Jonathan,

I think you are asking the right questions.  SV4 has caused severe problems in S-Plus mainly due to lack of multiple inheritance.  I have been burned MANY times when running an object through a method (e.g., imputation) that sticks on an additional class.  Right now I am teaching a class using S-Plus 6 with my impute function in the Hmisc library and strange error messages are driving the students crazy.  So far all my tests in the R 1.7 development version indicate that R, unlike S-Plus, is backward compatible with old-style classes and methods.  But if you want to be compatible with S-Plus it would be nice if we could just avoid new classes and methods.  Unfortunately S-Plus does not let us do that either, because multiple old-style classes is not allowed any more.  

In the bigger picture,  I am still not really convinced that new classes and methods offer advantages to data analysts.  The new methods are not as flexible and take longer to program.  I frequently stick on a new element of a fit object list for debugging or for enhancing functions that others wrote.  You can't really do this with SV4.  Also, new methods and classes have made some code non-transportable across systems (primarily to older versions of S-Plus).  There are now packages on CRAN that use slots to address elements while other versions of these same packages use list elements.  Hence some code retrieves details of fit objects using @ and some needs to use $.  I know that retrieving pieces of fit objects is inelegant (extractor methods should be written) but it is very common that I don't want to take the time to write an extractor method for every application, and I sure hate to waste time sensing whether the object was created using old vs. new style classes.

I know that new classes and methods are more elegant from a computer science perspective, but I analyze data and like to use what works (e.g., I really like both Perl and Python).  New methods provide much more safety.  I have found though that I don't need this kind of protection from myself.  I have plenty of other problems to worry about.

That's my $.02 worth.

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From ripley at stats.ox.ac.uk  Tue Apr  1 16:43:55 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 1 Apr 2003 15:43:55 +0100 (BST)
Subject: [R] Shafer's MI software for S-plus
In-Reply-To: <XFMail.030401134938.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0304011535550.10837-100000@gannet.stats>

I have an R port of MIX, but it is not 100% reliable. However, neither is
the S-PLUS original!  (We have found several bugs already.)

When I have a few spare days (if ever?) I will try again.  We got enough
to work for the project we needed it for.  Meanwhile,

http://www.stats.ox.ac.uk/pub/bdr/mix_1.0-1.tar.gz

has the current state.

Brian Ripley

On Tue, 1 Apr 2003 Ted.Harding at nessie.mcc.ac.uk wrote:

> Greetings folks,
> 
> Shafer's S-plus package "norm" for multiple imputation of
> missing values in multivariate normal data has been most
> kindly and usefully ported to R by Alvaro A. Novo.
> 
> Shafer's website
> 
>   http://www.stat.psu.edu/~jls/
> 
> lists four S-plus packages in all:
> 
>   NORM - multiple imputation of multivariate continuous data
> 
>   CAT - multiple imputation of multivariate categorical data
> 
>   MIX - multiple imputation of mixed continuous and categorical data
> 
>   PAN - multiple imputation of multivariate panel or clustered data
> 
> I am particularly interested at the moment in the functionality
> of "MIX", and am (naively) prepared to try my hand at getting it
> into R, but I am wondering generally if this or any of the others
> ("CAT", "PAN") have been tried in R by anyone.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tblackw at umich.edu  Tue Apr  1 17:05:50 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 1 Apr 2003 10:05:50 -0500 (EST)
Subject: [R] SQL and system
In-Reply-To: <000b01c2f81d$e850e1b0$6c00000a@proteus>
Message-ID: <Pine.SOL.4.44.0304011001220.8569-100000@rygar.gpcc.itd.umich.edu>

Does the greater than sign in the isql.tcl command need to quoted
in some way to protect it from being interpreted by the shell ?
(That's just a guess.  I don't understand why there's an R question
here.)

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

(all the quotes in Julien's message below seem to have been trashed
by switching from one encoding to another - sorry.)

On Tue, 1 Apr 2003, Julien Dinh wrote:

> Hi All,
>
> Im using system commands in R to send requests to my database.
>
> CMD=paste(isql.tcl \ select xxxx from yyyyy where zzzzz = 501 \)
> Data=system(CMD,intern=T)
>
> This works perfectly fine, but if I want to be able to add dates
> constraints:
> In command line it would be
> isql.tcl  select xxxx from yyyyy where zzzzz = 501 and date>20021020 
>
> Does somebody has an idea how to translate this into R code?
>
> Thank you for your time,
> Julien Dinh


From Ted.Harding at nessie.mcc.ac.uk  Tue Apr  1 17:31:36 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 01 Apr 2003 16:31:36 +0100 (BST)
Subject: [R] Shafer's MI software for S-plus
In-Reply-To: <Pine.LNX.4.44.0304011535550.10837-100000@gannet.stats>
Message-ID: <XFMail.030401163136.Ted.Harding@nessie.mcc.ac.uk>

On 01-Apr-03 Prof Brian Ripley wrote:
> I have an R port of MIX, but it is not 100% reliable. However, neither
> is the S-PLUS original!  (We have found several bugs already.)
> 
> When I have a few spare days (if ever?) I will try again.  We got
> enough to work for the project we needed it for.  Meanwhile,
> 
> http://www.stats.ox.ac.uk/pub/bdr/mix_1.0-1.tar.gz
> 
> has the current state.

Thanks, Brian! I'll see how it goes on the somewhat recalcitrant dataset
I'm looking at, and report back on anything interesting.

However, you gave the wrong URL: not found there, but I eventually found
my way to

  http://www.stats.ox.ac.uk/pub/R/mix_1.0-1.tar.gz

Further: Is there a pointer to a list of the bugs found?

Thanks again, and best wishes.
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 01-Apr-03                                       Time: 16:31:36
------------------------------ XFMail ------------------------------


From ripley at stats.ox.ac.uk  Tue Apr  1 17:54:18 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 1 Apr 2003 16:54:18 +0100 (BST)
Subject: [R] Shafer's MI software for S-plus
In-Reply-To: <XFMail.030401163136.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0304011653180.11140-100000@gannet.stats>

On Tue, 1 Apr 2003 Ted.Harding at nessie.mcc.ac.uk wrote:

> On 01-Apr-03 Prof Brian Ripley wrote:
> > I have an R port of MIX, but it is not 100% reliable. However, neither
> > is the S-PLUS original!  (We have found several bugs already.)
> > 
> > When I have a few spare days (if ever?) I will try again.  We got
> > enough to work for the project we needed it for.  Meanwhile,
> > 
> > http://www.stats.ox.ac.uk/pub/bdr/mix_1.0-1.tar.gz
> > 
> > has the current state.
> 
> Thanks, Brian! I'll see how it goes on the somewhat recalcitrant dataset
> I'm looking at, and report back on anything interesting.
> 
> However, you gave the wrong URL: not found there, but I eventually found
> my way to

I moved it ...

>   http://www.stats.ox.ac.uk/pub/R/mix_1.0-1.tar.gz
> 
> Further: Is there a pointer to a list of the bugs found?

Not yet available.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From shujf at yahoo.com  Tue Apr  1 18:55:02 2003
From: shujf at yahoo.com (shujf)
Date: Tue, 1 Apr 2003 08:55:02 -0800 (PST)
Subject: [R] XML to R datafram or list
Message-ID: <20030401165502.16800.qmail@web13901.mail.yahoo.com>

Hello all:

I am a new user of XML.  I need to convert XML files to R dataframes or
lists. The XML files were created by SAS 8.02 XML engine with options
xmltype=oimdbm  xmlschema=yes to keep user-defined format and SAS datetime
format.  Based on Duncan Temple Lang's reply to the post by Antonio
Pacheco (XML to Dataframe), there is no general way to read 
XML and convert it to a specific data format.  Do any of you by change
have a handler and an DTD or schema file for this case ready to share or
can you provide me any hints to write a handler?  Thanks a lot.

Jennifer Shu


From zhuw at mail.smu.edu  Tue Apr  1 18:56:50 2003
From: zhuw at mail.smu.edu (Wang, Zhu)
Date: Tue, 1 Apr 2003 10:56:50 -0600
Subject: [R] Is there any Time series change-point estimate in R?
Message-ID: <0FBE46098704A242B0DC8FEC4169F9978140CF@s31xs3.systems.smu.edu>

Hello,
 
I am looking for time series non-stationary test and change - point estimate. 
The pachage strucchange seems not serving my purpose.
 
Thanks in advance.
 
Zhu Wang
 
Statistical Science Department
SMU


From chrysopa at insecta.ufv.br  Tue Apr  1 16:58:40 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Tue, 1 Apr 2003 11:58:40 -0300
Subject: [R] [OFF]- Xemacs, delete key and ESS
Message-ID: <200304011158.40374.chrysopa@insecta.ufv.br>

Hi,

I use R with XEmacs and ESS, when I'm editing a R file in XEmacs, the delete 
key work like the Backspace key.

This behaviour is only in XEmacs + ESS + R file, it dont have this behaviour 
on a R section (M+R).

Anybody know how to make a delete key to work like the delete key??

ESS 5.1.20-2

XEmacs 21.4.6-8

Thanks for all
-- 
You will always have good luck in your personal affairs.
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From Benjamin.STABLER at odot.state.or.us  Tue Apr  1 19:37:40 2003
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Tue, 1 Apr 2003 09:37:40 -0800 
Subject: [R] How to list functions in a library?
Message-ID: <76A000A82289D411952F001083F9DD06039ACAFE@exsalem4-bu.odot.state.or.us>

> library(e1071)
> search()
[1] ".GlobalEnv"    "package:e1071" "Autoloads"     "package:base" 
> ls(pos=2)
 [1] "allShortestPaths"      "bclust"                "best.nnet"            
 [4] "best.randomForest"     "best.rpart"            "best.svm"             
 [7] "bincombinations"       "bootstrap.lca"         "boxplot.bclust"       
[10] "centers.bclust"        "classAgreement"        "clusters.bclust"      
[13] "cmeans"                "compareMatchedClasses" "countpattern"         
[16] "cshell"                "d2sigmoid"             "ddiscrete"            
[19] "dsigmoid"              "element"               "extractPath"          
[22] "fclustIndex"           "hamming.distance"      "hamming.window"       
[25] "hanning.window"        "hclust.bclust"         "ica"                  
[28] "impute"                "interpolate"           "knn.wrapper"          
[31] "kurtosis"              "lca"                   "matchClasses"         
[34] "moment"                "na.fail.matrix.csr"    "pdiscrete"            
[37] "permutations"          "plot.bclust"           "plot.ica"             
[40] "plot.stft"             "plot.svm"              "plot.tune"            
[43] "predict.lca"           "predict.svm"           "print.bootstrap.lca"  
[46] "print.fclust"          "print.ica"             "print.lca"            
[49] "print.summary.lca"     "print.summary.svm"     "print.summary.tune"   
[52] "print.svm"             "print.tune"            "prune.bclust"         
[55] "qdiscrete"             "rbridge"               "rdiscrete"            
[58] "read.matrix.csr"       "read.octave"           "rectangle.window"     
[61] "rpart.wrapper"         "rwiener"               "scaclust"             
[64] "scale.data.frame"      "sigmoid"               "skewness"             
[67] "stft"                  "summary.lca"           "summary.svm"          
[70] "summary.tune"          "svm"                   "svm.default"          
[73] "svm.formula"           "tune"                  "tune.knn"             
[76] "tune.nnet"             "tune.randomForest"     "tune.rpart"           
[79] "tune.svm"              "write.matrix.csr"     

Benjamin Stabler
Transportation Planning Analysis Unit
Oregon Department of Transportation
555 13th Street NE, Suite 2
Salem, OR 97301  Ph: 503-986-4104


Bo Peng wrote:
> I am sorry for such a simple question but I just could not find a 
> command to list functions (objects) in a certain library. I had to refer 
> to library documents (often not readily available ) to find them.
> 
> Many thanks in advance.
>


From hodgess at uhddx01.dt.uh.edu  Tue Apr  1 19:49:54 2003
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Tue, 1 Apr 2003 11:49:54 -0600 (CST)
Subject: [R] .Random.seed vs. set.seed
Message-ID: <200304011749.LAA11452@uhddx01.dt.uh.edu>

Dear R People:

What is the difference betwween 
.Random.seed <<- seed

vs.
set.seed

please?

Thank you so much!
Sincerely,
Erin Hodgess
mailto: hodgess at uhddx01.dt.uh.edu

Version 1.5.1 for Windows


From Ted.Harding at nessie.mcc.ac.uk  Tue Apr  1 20:08:56 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 01 Apr 2003 19:08:56 +0100 (BST)
Subject: [R] Shafer's MI software for S-plus
In-Reply-To: <XFMail.030401163136.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.030401190856.Ted.Harding@nessie.mcc.ac.uk>

On 01-Apr-03 Ted Harding wrote:
> On 01-Apr-03 Prof Brian Ripley wrote:
>> I have an R port of MIX, but it is not 100% reliable. However, neither
>> is the S-PLUS original!  (We have found several bugs already.)
>> 
>> When I have a few spare days (if ever?) I will try again.  We got
>> enough to work for the project we needed it for.  Meanwhile,
>> 
>> http://www.stats.ox.ac.uk/pub/bdr/mix_1.0-1.tar.gz
>> 
>> has the current state.
> 
> Thanks, Brian! I'll see how it goes on the somewhat recalcitrant
> dataset I'm looking at, and report back on anything interesting.

Got it installed in R (version 1.6.2 on SuSE Linux 7.2). Apparently
trouble free.

Worked through the case-study "stlouis.dat" according to Shafer's
example in the README. All went well until the final batch of
commands below:

   # Now try some imputations. The following commands produce three
   # multiple imputations under the alternative model. The imputations
   # are proper if we can assume that the data augmentation procedure
   # achieves stationarity by 100 steps.
   rngseed(454545)
** newtheta<-dabipf.mix(s,margins,design,thetahat4,steps=100,showits=T)
** imp1<-imp.mix(s,newtheta,x)
** newtheta<-dabipf.mix(s,margins,design,newtheta,steps=100,showits=T)
** imp2<-imp.mix(s,newtheta,x)
   newtheta<-dabipf.mix(s,margins,design,newtheta,steps=100,showits=T)
   imp3<-imp.mix(s,newtheta,x)

> newtheta<-dabipf.mix(s,margins,design,newtheta,steps=100,showits=T)
Steps of Data Augmentation-Bayesian IPF: 
1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...
16...17...18...19...20...21...22...23...24...25...26...27...28...
Segmentation fault

Or it may segfault on the imp1 step or the imp2 step.

Is this one of the "mix" bugs, or some R/Linux version incompatibility?
A memory problem (though plating a trace-print of "gc()" indicates that
there's plenty of R memory to spare)?

Any comments welcome.

With thanks,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 01-Apr-03                                       Time: 19:08:56
------------------------------ XFMail ------------------------------


From den.duurs at lycos.com  Tue Apr  1 20:23:37 2003
From: den.duurs at lycos.com (Remko Duursma)
Date: Tue, 01 Apr 2003 10:23:37 -0800
Subject: [R] R syntax highlighter for Source Edit
Message-ID: <IPFELKJOLPBAEEAA@mailcity.com>

Hi all,

i made an R syntax highlighter for the free program SourceEdit, see www.sourceedit.com

remko


From jerosenb at hcs.harvard.edu  Tue Apr  1 20:25:13 2003
From: jerosenb at hcs.harvard.edu (janet rosenbaum)
Date: Tue, 1 Apr 2003 13:25:13 -0500 (EST)
Subject: [R] Windows GUI palimpsest
Message-ID: <200304011825.h31IPDxV020390@hcs.harvard.edu>



Windows (both XP and 98) seems to have a problem with our GUI, written
using R's tcl/tk package.

When we open another window, and then return to the GUI, the GUI has old
pieces of text left from the previous windows and/or places which are
cut off where a window had been.  

Also, when it computes something, the window will often decide to move 
itself over for no apparent reason, so it moves one button at a time,
very slowly --- this doesn't happen under linux or Mac.

Is there any way to stop this from happening?

Thanks,

Janet Rosenbaum					  jerosenb at fas.harvard.edu
Center for Basic Research in the Social Sciences, Harvard University


From rossini at blindglobe.net  Tue Apr  1 20:28:01 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Tue, 01 Apr 2003 10:28:01 -0800
Subject: [R] Scripting with an external editor
In-Reply-To: <Pine.LNX.4.44.0303311847080.3175-100000@gannet.stats> ("Prof.
 Brian Ripley"'s message of "Mon, 31 Mar 2003 18:52:11 +0100 (BST)")
References: <Pine.LNX.4.44.0303311847080.3175-100000@gannet.stats>
Message-ID: <87y92u9ioe.fsf@jeeves.blindglobe.net>

"Prof. Brian Ripley" <ripley at stats.ox.ac.uk> writes:


> I think the `trick' is how text for parsing is sent to R, and the answer 
> is via the command line, using C redirection (and ptys under Unix).
> I've already suggested that approach a week ago.

This is exactly it -- ESS works by sitting on top of R's I/O streams,
i.e. stdin and stdout, and parsing the input and output of known
commands.  Why anyone would want to reinvent that wheel is beyond me.

(i.e. even the comment about how nice WinEDT's LaTeX support; compare
that with complete completion facilities for references, near WYSIWYG
support under a subset of platforms, and perhaps the nicest debugger,
with descriptions of what the errors might be coming straight from
Leslie Lamport).

best,
-tony

-- 
A.J. Rossini					   rossini at u.washington.edu	
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
They make me add this: CONFIDENTIALITY NOTICE: This e-mail message and any attachments may be confidential and privileged. If you received this message in error, please destroy it and notify the sender. Thank you.


From andys at neptuneinc.org  Tue Apr  1 20:42:21 2003
From: andys at neptuneinc.org (Andrew Schuh)
Date: Tue, 01 Apr 2003 11:42:21 -0700
Subject: [R] RODBC, freetds, and MS SQL Server
References: <Pine.LNX.4.44.0304010749550.9328-100000@gannet.stats>
Message-ID: <3E89DD8D.1060400@neptuneinc.org>

I'm happy.  Setting this argument seemed to work for me and I guess I 
should have messed with it a bit.  I guess the argument seemed a bit 
confusing and didn't seem to imply to me that it represented a possible 
solution.  However, it does seem to work with the MS SQL Server I'm 
having to use.  I haven't been connected to the list since last November 
so I'm sorry if I missed some discussion on this.  It might be a good 
idea to call it out a bit more in the details and state that it has 
represented a potential solution with Oracle and MS SQL Server.  Also, 
for those out there that are looking for a good way to connect R to a MS 
SQL Server; installing freetds via unixODBC seems to work (fingers 
crossed).  Thanks again.

Prof. Brian Ripley wrote:

>?odbcConnect has
>
>believeNRows: logical.  Is the number of rows returned by the ODBC
>          connection believable?  Not true for Oracle, apparently.
>
>Try setting it to FALSE, as it looks like your driver is broken.
>
>I am not wure why people keep ignoring this parameter in RODBC ....
>
>
>On Mon, 31 Mar 2003, Andrew Schuh wrote:
>
>  
>
>>I have a question for RODBC users out there.  I have used the package with 
>>good results for some time.  However, I have just switched from an OpenLink 
>>proprietary driver for MS SQL to the FreeTDS driver (I think it is MS SQL 
>>Server 2000 I'm connecting to if it matters).  I was/am running them from 
>>unixODBC on a Linux Client.  I think I have it set up fine since I can use 
>>"isql" to perform simple queries on the database.  However, I get really odd 
>>behavior when I try to use it through RODBC.  It seems to connect fine but 
>>gives back odd results.  The database I'm accessing is called "cmp" and there 
>>are many tables of which one is called "Medium".  In the past "select * from 
>>cmp.Medium" has returned the whole table to me but now it only seems like I 
>>get column headers.  Any help or advice would be appreciated.
>>
>>##-------------------------------------------------------------------------------##
>>    
>>
>>>library(RODBC)
>>>con <- odbcConnect("BIGSKY","***","**********")
>>>con
>>>      
>>>
>>RODB Connection 0
>>Details:
>>  case=nochange
>>  0?????????? 
>>    
>>
>>>sqlTables(con)
>>>      
>>>
>>[1] TABLE_QUALIFIER TABLE_OWNER     TABLE_NAME      TABLE_TYPE     
>>[5] REMARKS        
>><0 rows> (or 0-length row.names)
>>    
>>
>>>sqlQuery(con,"select * from Medium")
>>>      
>>>
>>[1] "[RODBC] ERROR: Could not SQLExecute"                                                                  
>>[2] "S1000 1 [unixODBC] Msg 208, Level 16, State 1, Server BIGSKY, Line 
>>1\nInvalid object name 'Medium'.\n"
>>    
>>
>>>sqlQuery(con,"select * from cmp.Medium")
>>>      
>>>
>>[1] MediumKey Medium    IsSpecies
>><0 rows> (or 0-length row.names)
>>    
>>
>>>version
>>>      
>>>
>>         _
>>platform i686-pc-linux-gnu
>>arch     i686
>>os       linux-gnu        
>>system   i686, linux-gnu
>>status                    
>>major    1
>>minor    6.2
>>year     2003             
>>month    01               
>>day      10               
>>language R                
>>    
>>
>>Also, I'm using the latest RODBC I got from CRAN yesterday.
>>
>>
>>    
>>
>
>  
>


From mli at emmes.com  Tue Apr  1 20:57:01 2003
From: mli at emmes.com (Ming-Chung Li)
Date: Tue, 01 Apr 2003 13:57:01 -0500
Subject: [R] cor.test observations limit
Message-ID: <3.0.5.32.20030401135701.009f71a0@host2a.emmes.com>

Hi,

Is there a limit on the number of observations for using cor.test. For
example,

> library(ctest)
> cor.test(rnorm(3000), rnorm(3000), method="spearman")
Error in if (q > (n^3 - n)/6) pspearman(q - 1, n, lower.tail = FALSE) else
pspearman(q,  : 
        missing value where logical needed
In addition: Warning message: 
NAs introduced by coercion 

I mainly want to calculate the spearman correlation rho for a data with
missing values. But the rcorr function in Hmisc library (from
Hmisc_1.4.2.zip) gave me an error message 

> library(Hmisc)
> rcorr(tmp[5600:5900,1:2], type="spearman")
Error in rcorr(tmp[5600:5900, 1:2], type = "spearman") : 
        NA/NaN/Inf in foreign function call (arg 1)

Any help is appreciated,

Ming-Chung Li


From ripley at stats.ox.ac.uk  Tue Apr  1 20:56:02 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 1 Apr 2003 19:56:02 +0100 (BST)
Subject: [R] .Random.seed vs. set.seed
In-Reply-To: <200304011749.LAA11452@uhddx01.dt.uh.edu>
Message-ID: <Pine.LNX.4.44.0304011912450.11865-100000@gannet.stats>

On Tue, 1 Apr 2003, Erin Hodgess wrote:

> Dear R People:
> 
> What is the difference betwween 
> .Random.seed <<- seed
> 
> vs.
> set.seed
> 
> please?

1) In the first you have to know a suitable value for `seed', and that's
far from easy, whereas in the second you can supply a number in 1:1024.

2) Setting .Random.seed does not reset the state of the Box-Muller
generator if it is in use.

> Version 1.5.1 for Windows

Time to update ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Apr  1 20:56:45 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 1 Apr 2003 19:56:45 +0100 (BST)
Subject: [R] Shafer's MI software for S-plus
In-Reply-To: <XFMail.030401190856.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0304011956160.11960-100000@gannet.stats>

On Tue, 1 Apr 2003 Ted.Harding at nessie.mcc.ac.uk wrote:

> On 01-Apr-03 Ted Harding wrote:
> > On 01-Apr-03 Prof Brian Ripley wrote:
> >> I have an R port of MIX, but it is not 100% reliable. However, neither
> >> is the S-PLUS original!  (We have found several bugs already.)
> >> 
> >> When I have a few spare days (if ever?) I will try again.  We got
> >> enough to work for the project we needed it for.  Meanwhile,
> >> 
> >> http://www.stats.ox.ac.uk/pub/bdr/mix_1.0-1.tar.gz
> >> 
> >> has the current state.
> > 
> > Thanks, Brian! I'll see how it goes on the somewhat recalcitrant
> > dataset I'm looking at, and report back on anything interesting.
> 
> Got it installed in R (version 1.6.2 on SuSE Linux 7.2). Apparently
> trouble free.
> 
> Worked through the case-study "stlouis.dat" according to Shafer's
> example in the README. All went well until the final batch of
> commands below:
> 
>    # Now try some imputations. The following commands produce three
>    # multiple imputations under the alternative model. The imputations
>    # are proper if we can assume that the data augmentation procedure
>    # achieves stationarity by 100 steps.
>    rngseed(454545)
> ** newtheta<-dabipf.mix(s,margins,design,thetahat4,steps=100,showits=T)
> ** imp1<-imp.mix(s,newtheta,x)
> ** newtheta<-dabipf.mix(s,margins,design,newtheta,steps=100,showits=T)
> ** imp2<-imp.mix(s,newtheta,x)
>    newtheta<-dabipf.mix(s,margins,design,newtheta,steps=100,showits=T)
>    imp3<-imp.mix(s,newtheta,x)
> 
> > newtheta<-dabipf.mix(s,margins,design,newtheta,steps=100,showits=T)
> Steps of Data Augmentation-Bayesian IPF: 
> 1...2...3...4...5...6...7...8...9...10...11...12...13...14...15...
> 16...17...18...19...20...21...22...23...24...25...26...27...28...
> Segmentation fault
> 
> Or it may segfault on the imp1 step or the imp2 step.
> 
> Is this one of the "mix" bugs, or some R/Linux version incompatibility?
> A memory problem (though plating a trace-print of "gc()" indicates that
> there's plenty of R memory to spare)?

It's a bug, but it sometimes does in S-PLUS too.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hodgess at uhddx01.dt.uh.edu  Tue Apr  1 21:20:07 2003
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Tue, 1 Apr 2003 13:20:07 -0600 (CST)
Subject: [R] Answer to .Random.seed vs. set.seed
Message-ID: <200304011920.NAA12207@uhddx01.dt.uh.edu>

Here is the answer to the .Random.seed vs. set.seed question:

On Tue, 1 Apr 2003, Erin Hodgess wrote:

> Dear R People:
> 
> What is the difference betwween 
> .Random.seed <<- seed
> 
> vs.
> set.seed
> 
> please?

1) In the first you have to know a suitable value for `seed', and that's
far from easy, whereas in the second you can supply a number in 1:1024.

2) Setting .Random.seed does not reset the state of the Box-Muller
generator if it is in use.

> Version 1.5.1 for Windows

Time to update ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk


Thanks so much to Prof. Ripley!!!!!

Sincerely,
Erin


From jerome at hivnet.ubc.ca  Tue Apr  1 21:22:55 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Tue, 1 Apr 2003 11:22:55 -0800
Subject: [R] 
	lme() and nlme() give inconsistent numbers of degrees of freedom
	(PR#2384)
Message-ID: <200304011928.LAA07104@hivnet.ubc.ca>


I apologize for cross-posting.

In the reproducable example below, I fit the same model with lme() and 
nlme(). However, I get 12 degrees of freedom with lme() and 2 df with 
nlme().

library(nlme)
set.seed(14)

a <- 2
x <- rep(rnorm(3),rep(5,3))
id <- rep(c("a","b","c"),rep(5,3))
y <- a+x+rnorm(15)
data <- data.frame(y=y,id=id)
initx <- matrix(x[c(1,6,11)],dimnames=list(c("a","b","c"),"x"))

summary(fit.lme <-
              lme(y ~ 1,data=data,random=~1|id,method="ML"))
summary(fit.nlme <-
              nlme(y ~ a + x, fixed= a~1, random=x~1|id,
              data=data, start=list(fixed=c(a=2),
              random=list(id=initx)),method="ML"))

When I try the same thing with set.seed(18), I get 12 df for both.

I have submitted a bug report on that issue on Dec 20th and I have tried 
to find the source of the problem, but no success. You can check what I 
found so far at:
http://r-bugs.biostat.ku.dk/cgi-bin/R/Add-ons?id=2384

Can anyone help find the source of this problem?

Sincerely,
Jerome Asselin

R 1.6.2 on Red Hat Linux 7.2
Package: nlme 3.1-38


From tvargas at cisco.com  Tue Apr  1 21:39:55 2003
From: tvargas at cisco.com (Tony Vargas)
Date: Tue, 1 Apr 2003 11:39:55 -0800 (PST)
Subject: [R] Autogenerated png, bitmap images
In-Reply-To: <E827328028C66044B4998F2EC353CD3003185382@usrymx12.merck.com>
Message-ID: <Pine.GSO.4.44.0304011127290.3930-202000@tvargas-u5.cisco.com>

Bill,

Thanks for the response.  Comments in-line

Tony

Tony Vargas
Cisco Systems
Engineering Computing Services
(408) 525-4113
tvargas at cisco.com

On Tue, 1 Apr 2003, Pikounis, Bill wrote:

> Tony,
>
> > that all the fonts on my graphs get messed up.  Anybody have
> > any nija R
> > commands to make all fonts look great?  Anybody have any idea
> > how to fix
> > this?  So far, no luck on Solaris or Linux making the Xvfb fonts look
>
> I have played with Xvfb and have not seen the same font problem (Mandrake
> 9.0 for Linux, R 1.6.2) generating png's via CGI (my problems are more with
> CGI-secure permissions).  You mentioned running a cron (batch) job -- do you
> see the same problem using R interactively (such as an ssh login with X not
> running)?  Perhaps you can provide some lines of your code of your cron
> script to help the diagnosis?  What is specifically messed up with the
> fonts?

Files are attached.  One of the files shows a creation via cron, one via an ssh sesssion.
Any idea how to make them look the exact same?  The script that I use to
start Xvbg (and call R) is also attached.

>
> Adjusting the pointsize argument in png might help.

I've played with this a little.  Any specific value you suggest?


>
> > is that the bitmap files are enormous compared to the png images.  Any
> > idea how I could make the bmp images smaller (and create
> > faster?) (One of
> > my R bmp generation files is attached.)
>
> As far as bitmaps go, I think that in general the smaller they are, the less
> resolution you will have. But even if you are willing to give that up, you
> might need to delve into ghostscript call options, since my understanding is
> that what bitmap() uses under Linux (and I presume other X11 device
> approaches including Solaris).  See the code for bitmap(), in particular the
> gsexe and cmd objects. (I noticed your setting of some arguments like res in
> your bitmap generation file attachment, but as I guess above, other
> gs-intrinsic flags may be needed.)
>
> Hope that helps,
> Bill
>
> ----------------------------------------
> Bill Pikounis, Ph.D.
>
> Biometrics Research Department
> Merck Research Laboratories
> PO Box 2000, MailDrop RY84-16
> 126 E. Lincoln Avenue
> Rahway, New Jersey 07065-0900
> USA
>
> v_bill_pikounis at merck.com
>
> Phone: 732 594 3913
> Fax: 732 594 1565
>
>
> > -----Original Message-----
> > From: Tony Vargas [mailto:tvargas at cisco.com]
> > Sent: Monday, March 31, 2003 9:23 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Autogenerated png, bitmap images
> >
> >
> > I have two questions -
> >
> > 1.  I am trying to create R png graphs via cron.  I have this
> > part working
> > using Xvfb (X virtual frame buffer).  One problem that I
> > have, though, is
> > that all the fonts on my graphs get messed up.  Anybody have
> > any nija R
> > commands to make all fonts look great?  Anybody have any idea
> > how to fix
> > this?  So far, no luck on Solaris or Linux making the Xvfb fonts look
> > good.
> >
> > I was thining of sending an e-mail to the Xfree86 org people.
> >  Haven't seen anything helpful on google so far.
> >
> >
> > 2.  I really like the png solution that I have working,
> > above, except for
> > the fonts.  Assumming that I can't get the virtual frame
> > buffer working,
> > I guess I can switch to bitmap devices.  One thing I have
> > noticed, though,
> > is that the bitmap files are enormous compared to the png images.  Any
> > idea how I could make the bmp images smaller (and create
> > faster?) (One of
> > my R bmp generation files is attached.)
> >
> > Thanks,
> >
> > Tony
> >
> > Tony Vargas
> > Cisco Systems
> > Engineering Computing Services
> > (408) 525-4113
> > tvargas at cisco.com
> >
>
>
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named in this message.  If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.
>
> ==============================================================================
>
>
-------------- next part --------------
#!/bin/bash
#Shell script to generate nightly tgu graphs

#Need to setup a virtual X11 frame buffer so that R can print image files.  Will not work without.  In addition, this is why graph generation needs to be run as root - so that the frame buffer can be created

TERM="vt100"
XVFB_HOME="/nfs/ecs/perf/opt/tgu_perf/XVFB"
export TERM
export XVFB_HOME



#Updated font path - so graphs look better
$XVFB_HOME/Xvfb :101 -co $XVFB_HOME/rgb -fp /usr/openwin/lib/X11/fonts/F3bitmaps/,/usr/openwin/lib/X11/fonts/Type1/,/usr/openwin/lib/X11/fonts/Speedo/,/usr/openwin/lib/X11/fonts/misc/,/usr/openwin/lib/X11/fonts/75dpi/,/usr/openwin/lib/X11/fonts/100dpi/ -sp /usr/X/server/etc/SecurityPolicy &


export DISPLAY=localhost:101:0


AppBaseDir="/nfs/ecs/perf/opt/tgu_perf/bin"
BaseDir="/auto/solperf/tgu"
BaseRFileDir="$BaseDir/RFileBase"
BaseImageDir="$BaseDir/Images"
BaseThumbsDir="$BaseDir/Thumbs"

Month='/bin/date +"%h"'
Year='/bin/date +"%Y"'
Day='/bin/date +"%d"'
Month_Year_Combo=`/bin/date +"%h.%Y"`


#Create a directory for every month for both images, thumbnails and RFiles - if do this, no need to do a rm every night

if [ ! -d "$BaseRFileDir/$Month_Year_Combo" ] ; then 
     mkdir $BaseRFileDir/$Month_Year_Combo
     mkdir $BaseThumbsDir/$Month_Year_Combo
     mkdir $BaseImageDir/$Month_Year_Combo
fi
 
#Generate R config files

$AppBaseDir/tgu_r_mon_gen

cd $BaseRFileDir/$Month_Year_Combo
for i in `ls`; do
   /usr/cisco/bin/R < $i --no-save --silent 

 done



#####Stuff below is just junk

##$XVFB_HOME/Xvfb :101 -co $XVFB_HOME/rgb -fp $XVFB_HOME/fonts/misc/,$XVFB_HOME/fonts/Speedo/,$XVFB_HOME/fonts/Type1/,$XVFB_HOME/fonts/75dpi/,$XVFB_HOME/fonts/100dpi/ -sp $XVFB_HOME/SecurityPolicy &

#$XVFB_HOME/Xvfb :101 -co $XVFB_HOME/rgb -fp /usr/X/lib/X11/fonts/TrueType/,/usr/X/lib/X11/fonts/Type1/,/usr/X/lib/X11/fonts/Type3/,/usr/X/lib/X11/fonts/100dpi/,/usr/X/lib/X11/fonts/75dpi/,/usr/X/lib/X11/fonts/CSL/,/usr/X/lib/X11/fonts/misc/ -sp $XVFB_HOME/SecurityPolicy &

From ripley at stats.ox.ac.uk  Tue Apr  1 21:45:16 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 1 Apr 2003 20:45:16 +0100 (BST)
Subject: [R] cor.test observations limit
In-Reply-To: <3.0.5.32.20030401135701.009f71a0@host2a.emmes.com>
Message-ID: <Pine.LNX.4.44.0304012023250.12034-100000@gannet.stats>

Yes.  About 1290 for the Spearman test.

You need (n^3 - n) representable as an integer.

On Tue, 1 Apr 2003, Ming-Chung Li wrote:

> Is there a limit on the number of observations for using cor.test. For
> example,
> 
> > library(ctest)

That's not needed, and has not been for about 3 years.

> > cor.test(rnorm(3000), rnorm(3000), method="spearman")
> Error in if (q > (n^3 - n)/6) pspearman(q - 1, n, lower.tail = FALSE) else
> pspearman(q,  : 
>         missing value where logical needed
> In addition: Warning message: 
> NAs introduced by coercion 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jfox at mcmaster.ca  Tue Apr  1 21:57:25 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 01 Apr 2003 14:57:25 -0500
Subject: [R] [OFF]- Xemacs, delete key and ESS
In-Reply-To: <200304011158.40374.chrysopa@insecta.ufv.br>
Message-ID: <5.1.0.14.2.20030401145438.01e6f990@mcmail.cis.mcmaster.ca>

Dear Ronaldo,

You can add the following lines to your .xemacs file:

         (define-key ess-mode-map [delete] 'delete-char)
         (define-key inferior-ess-mode-map [delete] 'delete-char)

I hope that this helps,
  John

At 11:58 AM 4/1/2003 -0300, you wrote:
>Hi,
>
>I use R with XEmacs and ESS, when I'm editing a R file in XEmacs, the delete
>key work like the Backspace key.
>
>This behaviour is only in XEmacs + ESS + R file, it dont have this behaviour
>on a R section (M+R).
>
>Anybody know how to make a delete key to work like the delete key??
>
>ESS 5.1.20-2
>
>XEmacs 21.4.6-8

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From peterm at andrew.cmu.edu  Tue Apr  1 23:42:58 2003
From: peterm at andrew.cmu.edu (Peter Muhlberger)
Date: Tue, 01 Apr 2003 16:42:58 -0500
Subject: [R] Can't run regression on G3 Mac
Message-ID: <BAAF7212.4AB6%peterm@andrew.cmu.edu>

Hi, I'm new to R.  I was wondering if anyone has an OS X native installation
(not Carbon) of R on a G3 Macintosh that is able to run linear regression?
I installed Jan de Leeuw's R binary for OS 10.2 Jaguar on my laptop, which
is still a G3 model.  When I try to run a simple regression, using lm, I get
an "Illegal Instruction" message and R quits.  Jan thinks it may be the case
that his R binary depends on a G4 instruction (I could provide console
output, but I don't know what it means).  Anyway, I'm curious if there is
*some* way of getting R running without this problem on a G3.  Perhaps I
should try installing R using Fink?  Are there instructions for how to do
this somewhere?  (Wish I didn't have to install the developer tools, because
there isn't a lot of space on my hard disk.)

Cheers,

Peter


From lamac_k at hotmail.com  Tue Apr  1 23:43:44 2003
From: lamac_k at hotmail.com (lamack lamack)
Date: Tue, 01 Apr 2003 21:43:44 +0000
Subject: [R] replication of latin squares
Message-ID: <F43iNdBDuZ10kpeH2820000da95@hotmail.com>

Dear all,

I have a 4x4 latin square replicated 3 times. That is:

          operators
batches 1  2  3  4
  1      A  B  C  D
  2      B  C  D  A
  3      C  D  A  B
  4      D  A  B  C

          operators
batches 1  2  3  4
  5      A  B  C  D
  6      B  C  D  A
  7      C  D  A  B
  8      D  A  B  C

          operators
batches 1  2  3  4
  9      A  B  C  D
  10     B  C  D  A
  11     C  D  A  B
  12     D  A  B  C

I have used the same operators but different batches.
How can I get the anova table for this design using R?
I have created a R object as

  bathces operators treatment  y   rep
   1         1        A        y1   1
   1         1        b        b2   1

and so on

Thank you very much

L.


From arrayprofile at yahoo.com  Wed Apr  2 00:14:47 2003
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 1 Apr 2003 14:14:47 -0800 (PST)
Subject: [R] LDA
Message-ID: <20030401221447.53241.qmail@web41207.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030401/391ca7a8/attachment.pl

From Oldradio69 at aol.com  Wed Apr  2 00:36:05 2003
From: Oldradio69 at aol.com (Oldradio69@aol.com)
Date: Tue, 01 Apr 2003 17:36:05 -0500
Subject: [R] read.table
Message-ID: <27933486.17A39E2F.0C4E5449@aol.com>

Group members,

I am using read.table() to read in ASCII data into a data
frame.  The file has multiple columns that are not the
same length.  The function gives me errors, or I get 'NA'
characters in the blank fields.  I want to read these values
in to, e.g., perform a two-sample t-test.

Thanks,

Jason


From jzhu at stanford.edu  Wed Apr  2 03:53:22 2003
From: jzhu at stanford.edu (Ji Zhu)
Date: Tue, 1 Apr 2003 17:53:22 -0800 (PST)
Subject: [R] n.iter in simplex()
Message-ID: <Pine.GSO.4.44.0304011737200.9564-100000@elaine8.Stanford.EDU>


Dear R users,

Is anyone familiar with the "n.iter" argument of the simplex() function
(in the boot package)?  It seems it doesn't have an effect no matter what
value I set it ...

I'm trying to solve a linear programming problem and running into the
problem of

simplex.object$solved = 0

or

"A value of 0 indicates that the maximum number of iterations was reached
without termination of the second stage. This may indicate an unbounded
function or simply that more iterations are needed."  (Quoted from R
online help)

I'm pretty sure that my objective function is bounded.  So I tried to set
different values for "n.iter" (I even tried to set it equal to 0 and -1),
but no matter what values I set, I always got the same result.  Could
anyone give me some hint about what's going on?  Thanks in advance.

Regards,

Ji


From arrayprofile at yahoo.com  Wed Apr  2 04:06:33 2003
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 1 Apr 2003 18:06:33 -0800 (PST)
Subject: [R] lda of MASS library
Message-ID: <20030402020633.63539.qmail@web41206.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030401/2790c9a6/attachment.pl

From umalvarez at fata.unam.mx  Wed Apr  2 04:32:45 2003
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Tue, 1 Apr 2003 20:32:45 -0600 (CST)
Subject: [R] Can't run regression on G3 Mac
In-Reply-To: <BAAF7212.4AB6%peterm@andrew.cmu.edu>
Message-ID: <Pine.LNX.4.44.0304012026460.6614-100000@fata.unam.mx>

Hi:

Install R using fink doesn't help. I installed r-base-atlas 1.6.1-3 with 
fink on an IBook G3 and I'm getting the same behavior. Whenever I try to 
get a lm or an aov R quits with "Illegal instruction".

Maybe is a bug.

Regards.


On Tue, 1 Apr 2003, Peter Muhlberger wrote:

> Hi, I'm new to R.  I was wondering if anyone has an OS X native installation
> (not Carbon) of R on a G3 Macintosh that is able to run linear regression?
> I installed Jan de Leeuw's R binary for OS 10.2 Jaguar on my laptop, which
> is still a G3 model.  When I try to run a simple regression, using lm, I get
> an "Illegal Instruction" message and R quits.  Jan thinks it may be the case
> that his R binary depends on a G4 instruction (I could provide console
> output, but I don't know what it means).  Anyway, I'm curious if there is
> *some* way of getting R running without this problem on a G3.  Perhaps I
> should try installing R using Fink?  Are there instructions for how to do
> this somewhere?  (Wish I didn't have to install the developer tools, because
> there isn't a lot of space on my hard disk.)
> 
> Cheers,
> 
> Peter
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx


From ripley at stats.ox.ac.uk  Wed Apr  2 08:16:46 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Apr 2003 07:16:46 +0100 (BST)
Subject: [R] lda of MASS library
In-Reply-To: <20030402020633.63539.qmail@web41206.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0304020712520.11976-100000@gannet.stats>

On Tue, 1 Apr 2003, array chip wrote:

> it seems that the lda function in MASS library doesn't give out the
> constant for the linear discriminant function under the situation that
> we don't use standardized variable, anyone knows how to obtain the
> constant in order to construct the linear discriminant function?

There is no constant in the LDF as defined by Fisher.
 
> I understand that if the priors are set to be 1/2, the threshold of the
> discriminant score used to separate the 2 classes is 0, how about if the
> priors are not 1/2 vs. 1/2, e.g. like 1/3 vs. 2/3, in this situation,
> how to determine a threshold of the discriminant score to separate the 2
> classes? Is there a simple formula existing? I understand posterior
> probabilities are usually used for classification, but I would like to
> know if I want to use discriminant scores, how can I do it?

The formulae are in MASS (the book), but this is not then an LDF.
For two classes (not the only case!) you take the log odds of the 
posterior probabilities.

May I suggest you try to understand the theory behind the lda() function?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Apr  2 08:25:55 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Apr 2003 07:25:55 +0100 (BST)
Subject: [R] LDA
In-Reply-To: <20030401221447.53241.qmail@web41207.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0304020722330.11976-100000@gannet.stats>

On Tue, 1 Apr 2003, array chip wrote:

> 
> I used the "lda" function in the MASS library of S-Plus (R) to do a
> linear discriminant analysis, and got the linear coefficients, say b1
> and b2 for the 2 predictors x1 and x2. I have trouble to calculate the
> discrimiant scores for each observation, I used 3 ways to try to repeat
> the scores returned by the "predict" function in S-Plus:
> 
> 1. b1*x1+b2*x2
> 2. b1*(x1-mean of x1)+b2*(x2-mean of x2)
> 3. b1* standardized x1+b2*standardized x2 (standardize: mean 0 & variance 1)
> 
> none of the above procedures can repeat the scores returned by the
> "predict" function. However, method 2 & 3 can predict the classes
> correctly if using 0 as cutoff, juts like using the "predict function".

You've sent this to R-help, but S-PLUS (sic) and R are different as is my 
lda() function in each.  MASS is a book, and it contains the details, 
as does the code.

> What should be the correct formula to compute the scores for each
> observation?
> 
> BTW, how to retrieve the linear coefficients from an lda object? I can't
> retrieve it by using @coef, @coefficients, etc.

Of course not: in R these are not S4 classes.  You could read the help 
page to see what lda() actually computes.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Wed Apr  2 08:43:12 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 02 Apr 2003 08:43:12 +0200
Subject: [R] Windows GUI palimpsest
In-Reply-To: <200304011825.h31IPDxV020390@hcs.harvard.edu>
References: <200304011825.h31IPDxV020390@hcs.harvard.edu>
Message-ID: <3E8A8680.7050105@statistik.uni-dortmund.de>

janet rosenbaum wrote:
> 
> Windows (both XP and 98) seems to have a problem with our GUI, written
> using R's tcl/tk package.
> 
> When we open another window, and then return to the GUI, the GUI has old
> pieces of text left from the previous windows and/or places which are
> cut off where a window had been.  
> 
> Also, when it computes something, the window will often decide to move 
> itself over for no apparent reason, so it moves one button at a time,
> very slowly --- this doesn't happen under linux or Mac.
> 
> Is there any way to stop this from happening?

Since it's a tcl/tk issue, please ask the tcl/tk developers ....

Uwe Ligges


From ripley at stats.ox.ac.uk  Wed Apr  2 08:44:10 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Apr 2003 07:44:10 +0100 (BST)
Subject: [R] read.table
In-Reply-To: <27933486.17A39E2F.0C4E5449@aol.com>
Message-ID: <Pine.LNX.4.44.0304020734330.11976-100000@gannet.stats>

On Tue, 1 Apr 2003 Oldradio69 at aol.com wrote:

> I am using read.table() to read in ASCII data into a data
> frame.  The file has multiple columns that are not the
> same length.  The function gives me errors, or I get 'NA'
> characters in the blank fields.  I want to read these values
> in to, e.g., perform a two-sample t-test.

You can't use read.table.  It is designed to read a data frame where by 
definition the columns are the same length.

What you can do is to use scan and remove the NAs as in

tmp <- lapply(scan("foo.txt", list(0, 0)), function(x) x[!is.na(x)])

which will give you a list of two numeric vectors.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Wed Apr  2 08:48:01 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 02 Apr 2003 08:48:01 +0200
Subject: [R] read.table
In-Reply-To: <27933486.17A39E2F.0C4E5449@aol.com>
References: <27933486.17A39E2F.0C4E5449@aol.com>
Message-ID: <3E8A87A1.1090604@statistik.uni-dortmund.de>

Oldradio69 at aol.com wrote:
> Group members,
> 
> I am using read.table() to read in ASCII data into a data
> frame.  The file has multiple columns that are not the
> same length.  The function gives me errors, or I get 'NA'
> characters in the blank fields.  I want to read these values
> in to, e.g., perform a two-sample t-test.

So a data.frame isn't the appropiate structure for your data.
You might want to convert it to another structure and remove the 
appended NAs, or consider to read the data in using scan() and friends. 
See the R Data Import/Export Manual for details.

Uwe Ligges


From ripley at stats.ox.ac.uk  Wed Apr  2 09:01:16 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Apr 2003 08:01:16 +0100 (BST)
Subject: [R] read.table
In-Reply-To: <Pine.LNX.4.44.0304020734330.11976-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0304020800510.12025-100000@gannet.stats>

On Wed, 2 Apr 2003, Prof Brian Ripley wrote:

> On Tue, 1 Apr 2003 Oldradio69 at aol.com wrote:
> 
> > I am using read.table() to read in ASCII data into a data
> > frame.  The file has multiple columns that are not the
> > same length.  The function gives me errors, or I get 'NA'
> > characters in the blank fields.  I want to read these values
> > in to, e.g., perform a two-sample t-test.
> 
> You can't use read.table.  It is designed to read a data frame where by 
> definition the columns are the same length.
> 
> What you can do is to use scan and remove the NAs as in
> 
> tmp <- lapply(scan("foo.txt", list(0, 0)), function(x) x[!is.na(x)])
> 
> which will give you a list of two numeric vectors.
> 

Sorry, I omitted fill=TRUE from the scan call.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Apr  2 09:12:50 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Apr 2003 08:12:50 +0100 (BST)
Subject: [R] rbind data.frames with character vectors? 
In-Reply-To: <Pine.LNX.4.44.0303311816240.3175-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0304020808300.12088-100000@gannet.stats>

I have put some bug fixes in R-devel (to be 1.7.0) which make this work
(and sorted out quite a few other anomalies, not all of which work
correctly in current S-PLUS).

My advice remains to use I(), as I think there are other functions (e.g.  
merge, possibly) which may not expect `raw' character columns in data
frames.

On Mon, 31 Mar 2003, Prof. Brian Ripley wrote:

> That is not how you are intended to put character strings in data frames 
> in S.  Rather, there is
> 
> A <- data.frame(a=1, b=I("A"))
> B <- data.frame(a=2, b=I("B"))
> AB <- rbind(A,B)
> 
> etc works (at least in R-devel)
> 
> Using $ on data frame is underhand, and avoids some of the consistency 
> checks.
> 
> We are planning to use I("foo") to put the column in as a character 
> column and use it consistently, but for 1.8.0 not 1.7.x
> 
> 
> On Mon, 31 Mar 2003, Spencer Graves wrote:
> 
> > "rbind(A, B)" converts character columns of A and B to factors.  This 
> > means that "A <- rbind(A, B)" generates NAs unless the character strings 
> > in B are already levels of the corresponding columns of A.
> > 
> > I've got a work-around, but I'm not happy with it.  What do you suggest?
> > 
> > Example:
> > 
> >  > A <- data.frame(a=1)
> >  > A$b <- "A"
> >  > B <- data.frame(a=2)
> >  > B$b <- "B"
> >  > sapply(A, data.class)
> >            a           b
> >    "numeric" "character"
> >  > AB <- rbind(A,B)
> >  > sapply(AB, data.class)
> >          a         b
> > "numeric"  "factor"
> >  > C. <- data.frame(a=3)
> >  > C.$b <- "C"
> >  > rbind(AB, C.)
> >      a    b
> > 1   1    A
> > 11  2    B
> > 111 3 <NA>
> > Warning message:
> > invalid factor level, NAs generated in: "[<-.factor"(*tmp*, ri, value = 
> > "C")
> >  > sapply(rbind(AB, C.), data.class)
> >          a         b
> > "numeric"  "factor"
> > Warning message:
> > invalid factor level, NAs generated in: "[<-.factor"(*tmp*, ri, value = 
> > "C")
> > 
> > Thanks,
> > Spencer Graves
> > p.s.  This example produces the desired result in S-Plus 2000 and 6.1 
> > Professional for Windows 2000.
> 
> I am not at clear sure that is intentional, though.
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Simon.Gatehouse at csiro.au  Wed Apr  2 09:15:16 2003
From: Simon.Gatehouse at csiro.au (Simon.Gatehouse@csiro.au)
Date: Wed, 2 Apr 2003 17:15:16 +1000 
Subject: [R] vectorize an expression
Message-ID: <FFE02AF26875734B82A728403821CB2EFB043A@asp-ri.riverside.csiro.au>

Dear listers,
I'm having a bad R day.  I just can't think of the vectorized equivalent of:

for (ii in 1:n)   aa[ii]  =  bb[ii,cc[ii]]

Any suggestion received with embarrassment and gratitude

Simon Gatehouse                                  
CSIRO Exploration and Mining,
Newbigin Close off Julius Ave
North Ryde, NSW
 
Mail:      PO Box 136, North Ryde
           NSW 1670, Australia
Phone:     61 (2) 9490 8677
Fax:       61 (2) 9490 8921
Mobile:    61  0407 130 635 
E-mail:    simon.gatehouse at csiro.au
Web Page:  http://www.csiro.au/


From fredrik.karlsson at ling.umu.se  Wed Apr  2 09:23:11 2003
From: fredrik.karlsson at ling.umu.se (Fredrik Karlsson)
Date: Wed, 2 Apr 2003 09:23:11 +0200
Subject: [R] RODBC sqlSave problem.
Message-ID: <20030402072311.GA4823@ling.umu.se>

Dear list,

Being new to both the postgres database, ODBC and the RODBC interface, I
am somewhat confused by some of the problems I am experiencing trying to
connect R to the database.

Whai I am trying is basically the example part of the help file for the 
sqlSave function:

> library(RODBC)
> odbcConnect("theodor") -> channel
> data(USArrests)
> sqlSave(channel, USArrests, verbose = TRUE)
Query: CREATE TABLE USArrests  (rownames varchar(255)  ,Murder float8
,Assault int4  ,UrbanPop int4  ,Rape float8  )
Error in sqlSave(channel, USArrests, verbose = TRUE) : 
        [RODBC] ERROR: Could not SQLExecute

When issuing this comamnd, a table is created in the specified database,
with fields corresponding to names(USArrests), except in lower case, but 
the fiels contain no data. 

Does anyone know the reason for this? One of my guesses is that the
table and field names are converted into lower cases by the database
manager, which would result in an error due to  non-existent symbols
when RODBC tries to inser the data.
Is this a possibility? Does anyone know how to investigate this?

Are there alternative explanations?

I would, of course, be extremely greateful for all the help I can get.



/Fredrik Karlsson


From ligges at statistik.uni-dortmund.de  Wed Apr  2 09:28:13 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 02 Apr 2003 09:28:13 +0200
Subject: [R] n.iter in simplex()
In-Reply-To: <Pine.GSO.4.44.0304011737200.9564-100000@elaine8.Stanford.EDU>
References: <Pine.GSO.4.44.0304011737200.9564-100000@elaine8.Stanford.EDU>
Message-ID: <3E8A910D.40806@statistik.uni-dortmund.de>

Ji Zhu wrote:
> Dear R users,
> 
> Is anyone familiar with the "n.iter" argument of the simplex() function
> (in the boot package)?  It seems it doesn't have an effect no matter what
> value I set it ...
> 
> I'm trying to solve a linear programming problem and running into the
> problem of
> 
> simplex.object$solved = 0
> 
> or
> 
> "A value of 0 indicates that the maximum number of iterations was reached
> without termination of the second stage. This may indicate an unbounded
> function or simply that more iterations are needed."  (Quoted from R
> online help)
> 
> I'm pretty sure that my objective function is bounded.  So I tried to set
> different values for "n.iter" (I even tried to set it equal to 0 and -1),
> but no matter what values I set, I always got the same result.  Could
> anyone give me some hint about what's going on?  Thanks in advance.

Well, it works for the example, at least. Play around with it.
Please specify more details, we cannot help otherwise.

Uwe Ligges


From ligges at statistik.uni-dortmund.de  Wed Apr  2 09:38:10 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 02 Apr 2003 09:38:10 +0200
Subject: [R] vectorize an expression
In-Reply-To: <FFE02AF26875734B82A728403821CB2EFB043A@asp-ri.riverside.csiro.au>
References: <FFE02AF26875734B82A728403821CB2EFB043A@asp-ri.riverside.csiro.au>
Message-ID: <3E8A9362.2090100@statistik.uni-dortmund.de>

Simon.Gatehouse at csiro.au wrote:
> Dear listers,
> I'm having a bad R day.  I just can't think of the vectorized equivalent of:
> 
> for (ii in 1:n)   aa[ii]  =  bb[ii,cc[ii]]
> 
> Any suggestion received with embarrassment and gratitude


a <- b[cbind(1:n, cc[1:n])]

Uwe Ligges


> Simon Gatehouse                                  
> CSIRO Exploration and Mining,
> Newbigin Close off Julius Ave
> North Ryde, NSW
>  
> Mail:      PO Box 136, North Ryde
>            NSW 1670, Australia
> Phone:     61 (2) 9490 8677
> Fax:       61 (2) 9490 8921
> Mobile:    61  0407 130 635 
> E-mail:    simon.gatehouse at csiro.au
> Web Page:  http://www.csiro.au/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Wed Apr  2 09:39:05 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Apr 2003 08:39:05 +0100 (BST)
Subject: [R] vectorize an expression
In-Reply-To: <FFE02AF26875734B82A728403821CB2EFB043A@asp-ri.riverside.csiro.au>
Message-ID: <Pine.LNX.4.44.0304020838150.14915-100000@gannet.stats>

On Wed, 2 Apr 2003 Simon.Gatehouse at csiro.au wrote:

> Dear listers,
> I'm having a bad R day.  I just can't think of the vectorized equivalent of:
> 
> for (ii in 1:n)   aa[ii]  =  bb[ii,cc[ii]]

aa <- bb[cbind(1:n, cc[1:n])]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lecoutre at stat.ucl.ac.be  Wed Apr  2 09:46:16 2003
From: lecoutre at stat.ucl.ac.be (Eric Lecoutre)
Date: Wed, 02 Apr 2003 09:46:16 +0200
Subject: [R] vectorize an expression
In-Reply-To: <FFE02AF26875734B82A728403821CB2EFB043A@asp-ri.riverside.cs
 iro.au>
Message-ID: <5.1.1.5.2.20030402094551.00ce3008@stat4ux.stat.ucl.ac.be>


What about:

bb[cbind(1:length(cc),cc)]

Eric


At 17:15 2/04/2003 +1000, Simon.Gatehouse at csiro.au wrote:
>Dear listers,
>I'm having a bad R day.  I just can't think of the vectorized equivalent of:
>
>for (ii in 1:n)   aa[ii]  =  bb[ii,cc[ii]]
>
>Any suggestion received with embarrassment and gratitude
>
>Simon Gatehouse
>CSIRO Exploration and Mining,
>Newbigin Close off Julius Ave
>North Ryde, NSW
>
>Mail:      PO Box 136, North Ryde
>            NSW 1670, Australia
>Phone:     61 (2) 9490 8677
>Fax:       61 (2) 9490 8921
>Mobile:    61  0407 130 635
>E-mail:    simon.gatehouse at csiro.au
>Web Page:  http://www.csiro.au/
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help



--------------------------------------------------
L'erreur est certes humaine, mais un vrai d?sastre
n?cessite un ou deux ordinateurs. Citation anonyme
--------------------------------------------------
Eric Lecoutre
Informaticien/Statisticien
Institut de Statistique / UCL

TEL (+32)(0)10473050       lecoutre at stat.ucl.ac.be
URL http://www.stat.ucl.ac.be/ISpersonnel/lecoutre
--------------------------------------------------


From ripley at stats.ox.ac.uk  Wed Apr  2 09:54:36 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 2 Apr 2003 08:54:36 +0100 (BST)
Subject: [R] RODBC sqlSave problem.
In-Reply-To: <20030402072311.GA4823@ling.umu.se>
Message-ID: <Pine.LNX.4.44.0304020844590.14915-100000@gannet.stats>

On Wed, 2 Apr 2003, Fredrik Karlsson wrote:

> Being new to both the postgres database, ODBC and the RODBC interface, I
> am somewhat confused by some of the problems I am experiencing trying to
> connect R to the database.

You would be: there is an extensive set of help pages, and you have not
looked up odbcConnect!

> Whai I am trying is basically the example part of the help file for the 
> sqlSave function:
> 
> > library(RODBC)
> > odbcConnect("theodor") -> channel
> > data(USArrests)
> > sqlSave(channel, USArrests, verbose = TRUE)
> Query: CREATE TABLE USArrests  (rownames varchar(255)  ,Murder float8
> ,Assault int4  ,UrbanPop int4  ,Rape float8  )
> Error in sqlSave(channel, USArrests, verbose = TRUE) : 
>         [RODBC] ERROR: Could not SQLExecute
> 
> When issuing this comamnd, a table is created in the specified database,
> with fields corresponding to names(USArrests), except in lower case, but 
> the fiels contain no data. 
> 
> Does anyone know the reason for this? One of my guesses is that the
> table and field names are converted into lower cases by the database
> manager, which would result in an error due to  non-existent symbols
> when RODBC tries to inser the data.
> Is this a possibility? Does anyone know how to investigate this?

Read the help page!  odbcConnect has a `case' argument. There is even a
file tests.R with PostgreSQL examples in the distribution.

> I would, of course, be extremely greateful for all the help I can get.

I would be grateful if you would read the help pages before posting to
R-help.


From gisar at nus.edu.sg  Wed Apr  2 10:55:17 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Wed, 2 Apr 2003 16:55:17 +0800
Subject: [BioC] [R] SAM: Significance of Microarray Analysis availability
	in R
Message-ID: <024D6AEFCB92CB47BA1085751D184BB801053F98@MBXSRV03.stf.nus.edu.sg>

Please ignore this mail. I don't remember sending this mail for the
second time. Thanks to all those who replied.

-----Original Message-----
From: Adaikalavan Ramasamy 
Sent: Monday, March 31, 2003 3:30 PM
To: r-help at stat.math.ethz.ch; bioconductor at stat.math.ethz.ch
Subject: [BioC] [R] SAM: Significance of Microarray Analysis
availability in R

Dear all, 

I have been asked to compare the SAM method on some datasets I have.
Searching the archives and help files for SAM was not fruitful. As I
understand it is available as Excel add-in and not in R. 

I am wondering if anyone has written this (in R or S-PLUS) and would be
willing to share it or at least point me right direction. Thank you. 

Regards, Adai.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

_______________________________________________
Bioconductor mailing list
Bioconductor at stat.math.ethz.ch
https://www.stat.math.ethz.ch/mailman/listinfo/bioconductor


From sbarbar at gwdg.de  Wed Apr  2 11:08:28 2003
From: sbarbar at gwdg.de (Salvatore Barbaro)
Date: Wed, 02 Apr 2003 11:08:28 +0200
Subject: [R] weighted samples
Message-ID: <3E8AC4AC.29216.785BCD@localhost>

Hi everybody,

I have some troubles by using R with weighted data. It is very
easy to obtain the mean of a weighted data set due to the function
weighted.mean, but unfortunately, such a function is not available
for any other estimators. Is there a comfortable way to consider
the column with the weights which would not lead to an expansion
of the sample (what would apply by using the rep() command). To
put it more generally: I'm looking for a nice way to use most of
the social science samples. Thanks in advance.

P.S. Such a sample looks like

Income  	Children    Age    Sex   Weight
5000		2		29	1	5874
6000		3		28	2	584
5500		0		32	1	8513
6951		1		23	1	510

	
Salvatore

salvatore barbaro
department of public economics
platz der g?ttinger sieben 3
37073 g?ttingen
tel.: +49 551 3919704
fax:  +49 551 39 7353
http://www.gwdg.de/~sbarbar


From brostaux.y at fsagx.ac.be  Wed Apr  2 11:46:03 2003
From: brostaux.y at fsagx.ac.be (Yves Brostaux)
Date: Wed, 02 Apr 2003 11:46:03 +0200
Subject: [R] randomForests predict problem
Message-ID: <5.1.0.14.1.20030402113552.00ae1ca0@fusamail.fsagx.ac.be>

Hello everybody,

I'm testing the randomForest package in order to do some simulations and I 
get some trouble with the prediction of new values. The random forest 
computation is fine but each time I try to predict values with the newly 
created object, I get an error message. I thought I was because NA values 
in the dataframe, but I cleaned them and still got the same error. What am 
I doing wrong ?

 > library(mlbench)
 > library(randomForest)
 > data(Soybean)
 > test <- sample(1:683, 150, replace=F)
 > sb.rf <- randomForest(Class~., data=Soybean[-test,])
 > sb.rf.pred <- predict(sb.rf, Soybean[test,])
Error in matrix(t1$countts, nr = nclass, nc = ntest) :
         No data to replace in matrix(...)

I did it the same way with rpart and all worked fine :
 > library(rpart)
 > sb.rp <- rpart(Class~., data=Soybean[-test,])
 > sb.rp.pred <- predict(sb.rp, Soybean[test,], type="class")

Thank you all for any advice you can give to me.

-- 
Ir. Yves Brostaux - Statistics and Computer Science Dpt.
Gembloux Agricultural University
8, avenue de la Facult? B-5030 Gembloux (Belgium)
T?l : +32 (0)81 62 24 69
E-mail : brostaux.y at fsagx.ac.be
Web : http://www.fsagx.ac.be/si/


From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Apr  2 13:13:30 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 2 Apr 2003 13:13:30 +0200 (CEST)
Subject: [R] randomForests predict problem
In-Reply-To: <5.1.0.14.1.20030402113552.00ae1ca0@fusamail.fsagx.ac.be>
References: <5.1.0.14.1.20030402113552.00ae1ca0@fusamail.fsagx.ac.be>
Message-ID: <Pine.LNX.4.51.0304021309290.29011@artemis.imbe.med.uni-erlangen.de>


> Hello everybody,
>
> I'm testing the randomForest package in order to do some simulations and I
> get some trouble with the prediction of new values. The random forest
> computation is fine but each time I try to predict values with the newly
> created object, I get an error message. I thought I was because NA values
> in the dataframe, but I cleaned them and still got the same error. What am
> I doing wrong ?
>
>  > library(mlbench)
>  > library(randomForest)
>  > data(Soybean)
>  > test <- sample(1:683, 150, replace=F)
>  > sb.rf <- randomForest(Class~., data=Soybean[-test,])
>  > sb.rf.pred <- predict(sb.rf, Soybean[test,])
> Error in matrix(t1$countts, nr = nclass, nc = ntest) :
>          No data to replace in matrix(...)


try

R> test <- sample(1:683, 150, replace=FALSE)
R>
R> st <- Soybean[test,]
R>
R> sb.rf <- randomForest(Class~., data=Soybean, subset=-test)
R> sb.rf.pred <- predict(sb.rf, data=st)
R>
R> sb.rf.pred[1:10]
 [1] diaporthe-stem-canker diaporthe-stem-canker diaporthe-stem-canker
 [4] diaporthe-stem-canker diaporthe-stem-canker diaporthe-stem-canker
 [7] diaporthe-stem-canker charcoal-rot          charcoal-rot
[10] charcoal-rot
19 Levels: 2-4-d-injury alternarialeaf-spot anthracnose ...
rhizoctonia-root-rot


Torsten

>
> I did it the same way with rpart and all worked fine :
>  > library(rpart)
>  > sb.rp <- rpart(Class~., data=Soybean[-test,])
>  > sb.rp.pred <- predict(sb.rp, Soybean[test,], type="class")
>
> Thank you all for any advice you can give to me.
>
> --
> Ir. Yves Brostaux - Statistics and Computer Science Dpt.
> Gembloux Agricultural University
> 8, avenue de la Facult? B-5030 Gembloux (Belgium)
> T?l : +32 (0)81 62 24 69
> E-mail : brostaux.y at fsagx.ac.be
> Web : http://www.fsagx.ac.be/si/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>


From lamac_k at hotmail.com  Wed Apr  2 13:57:23 2003
From: lamac_k at hotmail.com (lamack lamack)
Date: Wed, 02 Apr 2003 11:57:23 +0000
Subject: [R] replication of latin squares --- again
Message-ID: <F95AFVSt6X7474oxKEs000485eb@hotmail.com>

Dear all, this is a newbie's question.

I have a 4x4 latin square replicated 3 times. That is:

          operators
batches 1  2  3  4
  1      A  B  C  D
  2      B  C  D  A
  3      C  D  A  B
  4      D  A  B  C

          operators
batches 1  2  3  4
  5      A  B  C  D
  6      B  C  D  A
  7      C  D  A  B
  8      D  A  B  C

          operators
batches 1  2  3  4
  9      A  B  C  D
  10     B  C  D  A
  11     C  D  A  B
  12     D  A  B  C

I have used the same operators but different batches.
How can I get the anova table for this design using R?
I have created a R object as

  bathces operators treatment  y   rep
   1         1        A        y1   1
   1         1        b        b2   1
   .         .        .        .    .
and so on

I appreciate in advance.

L.


From brostaux.y at fsagx.ac.be  Wed Apr  2 14:17:58 2003
From: brostaux.y at fsagx.ac.be (Yves Brostaux)
Date: Wed, 02 Apr 2003 14:17:58 +0200
Subject: [R] randomForests predict problem
In-Reply-To: <Pine.LNX.4.51.0304021309290.29011@artemis.imbe.med.uni-erl
 angen.de>
References: <5.1.0.14.1.20030402113552.00ae1ca0@fusamail.fsagx.ac.be>
 <5.1.0.14.1.20030402113552.00ae1ca0@fusamail.fsagx.ac.be>
Message-ID: <5.1.0.14.1.20030402134136.00b2ccc0@fusamail.fsagx.ac.be>

Well, thank you for your answer, but this is not doing the right thing, 
that is predicting the Class value for the test set Soybean[test,]. It 
gives instead prediction for data used for forest computation (ignoring all 
data with NA's) ; 'data' argument is simply ignored as the right name for 
this argument is 'newdata', which still gives the same error when named.

 > length(sb.rf.pred)
[1] 445
 > dim(Soybean[test,])
[1] 150  36
 > dim(Soybean[-test,])
[1] 533  36
 > sb.rf.pred <- predict(sb.rf, newdata=st)
Error in matrix(t1$countts, nr = nclass, nc = ntest) :
         No data to replace in matrix(...)

At 13:13 02/04/03, you wrote:

> > Hello everybody,
> >
> > I'm testing the randomForest package in order to do some simulations and I
> > get some trouble with the prediction of new values. The random forest
> > computation is fine but each time I try to predict values with the newly
> > created object, I get an error message. I thought I was because NA values
> > in the dataframe, but I cleaned them and still got the same error. What am
> > I doing wrong ?
> >
> >  > library(mlbench)
> >  > library(randomForest)
> >  > data(Soybean)
> >  > test <- sample(1:683, 150, replace=F)
> >  > sb.rf <- randomForest(Class~., data=Soybean[-test,])
> >  > sb.rf.pred <- predict(sb.rf, Soybean[test,])
> > Error in matrix(t1$countts, nr = nclass, nc = ntest) :
> >          No data to replace in matrix(...)
>
>
>try
>
>R> test <- sample(1:683, 150, replace=FALSE)
>R>
>R> st <- Soybean[test,]
>R>
>R> sb.rf <- randomForest(Class~., data=Soybean, subset=-test)
>R> sb.rf.pred <- predict(sb.rf, data=st)
>R>
>R> sb.rf.pred[1:10]
>  [1] diaporthe-stem-canker diaporthe-stem-canker diaporthe-stem-canker
>  [4] diaporthe-stem-canker diaporthe-stem-canker diaporthe-stem-canker
>  [7] diaporthe-stem-canker charcoal-rot          charcoal-rot
>[10] charcoal-rot
>19 Levels: 2-4-d-injury alternarialeaf-spot anthracnose ...
>rhizoctonia-root-rot
>
>
>Torsten


From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Apr  2 14:37:45 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 2 Apr 2003 14:37:45 +0200 (CEST)
Subject: [R] randomForests predict problem
In-Reply-To: <5.1.0.14.1.20030402134136.00b2ccc0@fusamail.fsagx.ac.be>
References: <5.1.0.14.1.20030402113552.00ae1ca0@fusamail.fsagx.ac.be>
 <5.1.0.14.1.20030402113552.00ae1ca0@fusamail.fsagx.ac.be>
 <5.1.0.14.1.20030402134136.00b2ccc0@fusamail.fsagx.ac.be>
Message-ID: <Pine.LNX.4.51.0304021435550.29011@artemis.imbe.med.uni-erlangen.de>


> Well, thank you for your answer, but this is not doing the right thing,
> that is predicting the Class value for the test set Soybean[test,]. It
> gives instead prediction for data used for forest computation (ignoring all
> data with NA's) ; 'data' argument is simply ignored as the right name for
> this argument is 'newdata', which still gives the same error when named.
>

oups, sorry, 'newdata' needs to be specified:

R> library(mlbench)
R> library(randomForest)
R> data(Soybean)
R>
R> test <- sample(1:683, 150, replace=FALSE)
R>
R> sl <- Soybean[-test,]
R> st <- Soybean[test,]
R>
R> sb.rf <- randomForest(Class~., data=Soybean, subset=-test)
R> st <- st[complete.cases(st),]
R> dim(st)
[1] 115  36
R> sb.rf.pred <- predict(sb.rf, newdata=st)
R> length(sb.rf.pred)
[1] 115
R> sb.rf.pred[1:10]
 [1] brown-spot          alternarialeaf-spot brown-spot
 [4] alternarialeaf-spot brown-spot          anthracnose
 [7] bacterial-pustule   bacterial-blight    alternarialeaf-spot
[10] frog-eye-leaf-spot
19 Levels: 2-4-d-injury alternarialeaf-spot anthracnose ...
rhizoctonia-root-rot

looks like an NA problem, anyway.

Torsten


>  > length(sb.rf.pred)
> [1] 445
>  > dim(Soybean[test,])
> [1] 150  36
>  > dim(Soybean[-test,])
> [1] 533  36
>  > sb.rf.pred <- predict(sb.rf, newdata=st)
> Error in matrix(t1$countts, nr = nclass, nc = ntest) :
>          No data to replace in matrix(...)
>
> At 13:13 02/04/03, you wrote:
>
> > > Hello everybody,
> > >
> > > I'm testing the randomForest package in order to do some simulations and I
> > > get some trouble with the prediction of new values. The random forest
> > > computation is fine but each time I try to predict values with the newly
> > > created object, I get an error message. I thought I was because NA values
> > > in the dataframe, but I cleaned them and still got the same error. What am
> > > I doing wrong ?
> > >
> > >  > library(mlbench)
> > >  > library(randomForest)
> > >  > data(Soybean)
> > >  > test <- sample(1:683, 150, replace=F)
> > >  > sb.rf <- randomForest(Class~., data=Soybean[-test,])
> > >  > sb.rf.pred <- predict(sb.rf, Soybean[test,])
> > > Error in matrix(t1$countts, nr = nclass, nc = ntest) :
> > >          No data to replace in matrix(...)
> >
> >
> >try
> >
> >R> test <- sample(1:683, 150, replace=FALSE)
> >R>
> >R> st <- Soybean[test,]
> >R>
> >R> sb.rf <- randomForest(Class~., data=Soybean, subset=-test)
> >R> sb.rf.pred <- predict(sb.rf, data=st)
> >R>
> >R> sb.rf.pred[1:10]
> >  [1] diaporthe-stem-canker diaporthe-stem-canker diaporthe-stem-canker
> >  [4] diaporthe-stem-canker diaporthe-stem-canker diaporthe-stem-canker
> >  [7] diaporthe-stem-canker charcoal-rot          charcoal-rot
> >[10] charcoal-rot
> >19 Levels: 2-4-d-injury alternarialeaf-spot anthracnose ...
> >rhizoctonia-root-rot
> >
> >
> >Torsten
>
>


From andy_liaw at merck.com  Wed Apr  2 15:12:15 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 02 Apr 2003 08:12:15 -0500
Subject: [R] randomForests predict problem
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F917@usrymx25.merck.com>

Yves,

Which version of the package are you using?  I get:

> soy <- na.omit(Soybean)
> ts <- sample(nrow(soy), 150, replace=FALSE)
> sb.rf <- randomForest(Class ~ ., data=soy[-ts,])
> table(predict(sb.rf, soy[ts,], type="class"))

               2-4-d-injury         alternarialeaf-spot 
                          0                          37 
                anthracnose            bacterial-blight 
                         10                           3 
          bacterial-pustule                  brown-spot 
                          2                          29 
             brown-stem-rot                charcoal-rot 
                         11                           7 
              cyst-nematode diaporthe-pod-&-stem-blight 
                          0                           0 
      diaporthe-stem-canker                downy-mildew 
                          4                           8 
         frog-eye-leaf-spot            herbicide-injury 
                         17                           0 
     phyllosticta-leaf-spot            phytophthora-rot 
                          3                           5 
             powdery-mildew           purple-seed-stain 
                          4                           5 
       rhizoctonia-root-rot 
                          5 

Cheers,
Andy

> -----Original Message-----
> From: Yves Brostaux [mailto:brostaux.y at fsagx.ac.be]
> Sent: Wednesday, April 02, 2003 4:46 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] randomForests predict problem
> 
> 
> Hello everybody,
> 
> I'm testing the randomForest package in order to do some 
> simulations and I 
> get some trouble with the prediction of new values. The random forest 
> computation is fine but each time I try to predict values 
> with the newly 
> created object, I get an error message. I thought I was 
> because NA values 
> in the dataframe, but I cleaned them and still got the same 
> error. What am 
> I doing wrong ?
> 
>  > library(mlbench)
>  > library(randomForest)
>  > data(Soybean)
>  > test <- sample(1:683, 150, replace=F)
>  > sb.rf <- randomForest(Class~., data=Soybean[-test,])
>  > sb.rf.pred <- predict(sb.rf, Soybean[test,])
> Error in matrix(t1$countts, nr = nclass, nc = ntest) :
>          No data to replace in matrix(...)
> 
> I did it the same way with rpart and all worked fine :
>  > library(rpart)
>  > sb.rp <- rpart(Class~., data=Soybean[-test,])
>  > sb.rp.pred <- predict(sb.rp, Soybean[test,], type="class")
> 
> Thank you all for any advice you can give to me.
> 
> -- 
> Ir. Yves Brostaux - Statistics and Computer Science Dpt.
> Gembloux Agricultural University
> 8, avenue de la Facult? B-5030 Gembloux (Belgium)
> T?l : +32 (0)81 62 24 69
> E-mail : brostaux.y at fsagx.ac.be
> Web : http://www.fsagx.ac.be/si/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------


From gemireni at qubisoft.it  Wed Apr  2 15:12:21 2003
From: gemireni at qubisoft.it (Gianluca Emireni)
Date: Wed, 2 Apr 2003 15:12:21 +0200
Subject: [R] CGIwithR for IIS
Message-ID: <HBEKIOBADKJHAGANMFFHGEBJCAAA.gemireni@qubisoft.it>

Hi, I have a (maybe stupid) question... Does CGIwithR package can be
installed in R for Windows to work with a Microsoft IIS web-server? Or I
need other libraries?
Thank you, Gianluca.


From brostaux.y at fsagx.ac.be  Wed Apr  2 15:33:49 2003
From: brostaux.y at fsagx.ac.be (Yves Brostaux)
Date: Wed, 02 Apr 2003 15:33:49 +0200
Subject: [R] randomForests predict problem
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4F917@usrymx25.merck.com>
Message-ID: <5.1.0.14.1.20030402152246.00b01250@fusamail.fsagx.ac.be>

I use randomForest version 3.4-4, but yes, now I correctly omitted NA's it 
works. I should have made a mistake while removing them first time.

I was surprised that this method doesn't have another way to deal with NA's 
than omitting them. As Torsten Hothorn suggested, the associated predict 
function should then check for NA's in newdata, shouldn't it ?

Thank you both for your answers !

At 15:12 02/04/03, Liaw, Andy wrote:
>Yves,
>
>Which version of the package are you using?  I get:
>
> > soy <- na.omit(Soybean)
> > ts <- sample(nrow(soy), 150, replace=FALSE)
> > sb.rf <- randomForest(Class ~ ., data=soy[-ts,])
> > table(predict(sb.rf, soy[ts,], type="class"))
>
>                2-4-d-injury         alternarialeaf-spot
>                           0                          37
>                 anthracnose            bacterial-blight
>                          10                           3
>           bacterial-pustule                  brown-spot
>                           2                          29
>              brown-stem-rot                charcoal-rot
>                          11                           7
>               cyst-nematode diaporthe-pod-&-stem-blight
>                           0                           0
>       diaporthe-stem-canker                downy-mildew
>                           4                           8
>          frog-eye-leaf-spot            herbicide-injury
>                          17                           0
>      phyllosticta-leaf-spot            phytophthora-rot
>                           3                           5
>              powdery-mildew           purple-seed-stain
>                           4                           5
>        rhizoctonia-root-rot
>                           5
>
>Cheers,
>Andy
>
> > -----Original Message-----
> > From: Yves Brostaux [mailto:brostaux.y at fsagx.ac.be]
> > Sent: Wednesday, April 02, 2003 4:46 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] randomForests predict problem
> >
> >
> > Hello everybody,
> >
> > I'm testing the randomForest package in order to do some
> > simulations and I
> > get some trouble with the prediction of new values. The random forest
> > computation is fine but each time I try to predict values
> > with the newly
> > created object, I get an error message. I thought I was
> > because NA values
> > in the dataframe, but I cleaned them and still got the same
> > error. What am
> > I doing wrong ?
> >
> >  > library(mlbench)
> >  > library(randomForest)
> >  > data(Soybean)
> >  > test <- sample(1:683, 150, replace=F)
> >  > sb.rf <- randomForest(Class~., data=Soybean[-test,])
> >  > sb.rf.pred <- predict(sb.rf, Soybean[test,])
> > Error in matrix(t1$countts, nr = nclass, nc = ntest) :
> >          No data to replace in matrix(...)
> >
> > I did it the same way with rpart and all worked fine :
> >  > library(rpart)
> >  > sb.rp <- rpart(Class~., data=Soybean[-test,])
> >  > sb.rp.pred <- predict(sb.rp, Soybean[test,], type="class")
> >
> > Thank you all for any advice you can give to me.
> >
> > --
> > Ir. Yves Brostaux - Statistics and Computer Science Dpt.
> > Gembloux Agricultural University
> > 8, avenue de la Facult? B-5030 Gembloux (Belgium)
> > T?l : +32 (0)81 62 24 69
> > E-mail : brostaux.y at fsagx.ac.be
> > Web : http://www.fsagx.ac.be/si/
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
>------------------------------------------------------------------------------
>Notice: This e-mail message, together with any attachments, contains 
>information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) 
>that may be confidential, proprietary copyrighted and/or legally 
>privileged, and is intended solely for the use of the individual or entity 
>named on this message.  If you are not the intended recipient, and have 
>received this message in error, please immediately return this by e-mail 
>and then delete it.
>
>==============================================================================


From andy_liaw at merck.com  Wed Apr  2 15:43:09 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 02 Apr 2003 08:43:09 -0500
Subject: [R] randomForests predict problem
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F919@usrymx25.merck.com>

Yves,

I will add checks for NAs in predict.randomForest().

In the next version of randomForest (currently called 3.9-x), there will be
facilities for handling NAs in the training set.  However, there's no way to
handle NAs in the test set yet.  I believe Leo is still working on that.

In Leo's v.4 of the Fortran code, he uses proximity from random forest to
iteratively impute NAs, starting with column median or mode (depending on
variable types).  I've implemented this scheme at the R level, so that it
works for both regression and classification.

There are a couple of things in Leo's new code that I have not added to the
package, and that's why the version is 3.9 rather than 4.0.  If you would
like to test the new code, please let me know.

Cheers,
Andy

> -----Original Message-----
> From: Yves Brostaux [mailto:brostaux.y at fsagx.ac.be]
> Sent: Wednesday, April 02, 2003 8:34 AM
> To: r-help at stat.math.ethz.ch
> Cc: Liaw, Andy; Torsten Hothorn
> Subject: RE: [R] randomForests predict problem
> 
> 
> I use randomForest version 3.4-4, but yes, now I correctly 
> omitted NA's it 
> works. I should have made a mistake while removing them first time.
> 
> I was surprised that this method doesn't have another way to 
> deal with NA's 
> than omitting them. As Torsten Hothorn suggested, the 
> associated predict 
> function should then check for NA's in newdata, shouldn't it ?
> 
> Thank you both for your answers !
> 
> At 15:12 02/04/03, Liaw, Andy wrote:
> >Yves,
> >
> >Which version of the package are you using?  I get:
> >
> > > soy <- na.omit(Soybean)
> > > ts <- sample(nrow(soy), 150, replace=FALSE)
> > > sb.rf <- randomForest(Class ~ ., data=soy[-ts,])
> > > table(predict(sb.rf, soy[ts,], type="class"))
> >
> >                2-4-d-injury         alternarialeaf-spot
> >                           0                          37
> >                 anthracnose            bacterial-blight
> >                          10                           3
> >           bacterial-pustule                  brown-spot
> >                           2                          29
> >              brown-stem-rot                charcoal-rot
> >                          11                           7
> >               cyst-nematode diaporthe-pod-&-stem-blight
> >                           0                           0
> >       diaporthe-stem-canker                downy-mildew
> >                           4                           8
> >          frog-eye-leaf-spot            herbicide-injury
> >                          17                           0
> >      phyllosticta-leaf-spot            phytophthora-rot
> >                           3                           5
> >              powdery-mildew           purple-seed-stain
> >                           4                           5
> >        rhizoctonia-root-rot
> >                           5
> >
> >Cheers,
> >Andy
> >
> > > -----Original Message-----
> > > From: Yves Brostaux [mailto:brostaux.y at fsagx.ac.be]
> > > Sent: Wednesday, April 02, 2003 4:46 AM
> > > To: r-help at stat.math.ethz.ch
> > > Subject: [R] randomForests predict problem
> > >
> > >
> > > Hello everybody,
> > >
> > > I'm testing the randomForest package in order to do some
> > > simulations and I
> > > get some trouble with the prediction of new values. The 
> random forest
> > > computation is fine but each time I try to predict values
> > > with the newly
> > > created object, I get an error message. I thought I was
> > > because NA values
> > > in the dataframe, but I cleaned them and still got the same
> > > error. What am
> > > I doing wrong ?
> > >
> > >  > library(mlbench)
> > >  > library(randomForest)
> > >  > data(Soybean)
> > >  > test <- sample(1:683, 150, replace=F)
> > >  > sb.rf <- randomForest(Class~., data=Soybean[-test,])
> > >  > sb.rf.pred <- predict(sb.rf, Soybean[test,])
> > > Error in matrix(t1$countts, nr = nclass, nc = ntest) :
> > >          No data to replace in matrix(...)
> > >
> > > I did it the same way with rpart and all worked fine :
> > >  > library(rpart)
> > >  > sb.rp <- rpart(Class~., data=Soybean[-test,])
> > >  > sb.rp.pred <- predict(sb.rp, Soybean[test,], type="class")
> > >
> > > Thank you all for any advice you can give to me.
> > >
> > > --
> > > Ir. Yves Brostaux - Statistics and Computer Science Dpt.
> > > Gembloux Agricultural University
> > > 8, avenue de la Facult? B-5030 Gembloux (Belgium)
> > > T?l : +32 (0)81 62 24 69
> > > E-mail : brostaux.y at fsagx.ac.be
> > > Web : http://www.fsagx.ac.be/si/
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> >
> >-------------------------------------------------------------
> -----------------
> >Notice: This e-mail message, together with any attachments, contains 
> >information of Merck & Co., Inc. (Whitehouse Station, New 
> Jersey, USA) 
> >that may be confidential, proprietary copyrighted and/or legally 
> >privileged, and is intended solely for the use of the 
> individual or entity 
> >named on this message.  If you are not the intended 
> recipient, and have 
> >received this message in error, please immediately return 
> this by e-mail 
> >and then delete it.
> >
> >=============================================================
> =================
> 
> 


------------------------------------------------------------------------------


From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Apr  2 15:46:05 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 2 Apr 2003 15:46:05 +0200 (CEST)
Subject: [R] randomForests predict problem
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4F919@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD5C4F919@usrymx25.merck.com>
Message-ID: <Pine.LNX.4.51.0304021545450.29011@artemis.imbe.med.uni-erlangen.de>

On Wed, 2 Apr 2003, Liaw, Andy wrote:

> Yves,
>
> I will add checks for NAs in predict.randomForest().
>
> In the next version of randomForest (currently called 3.9-x), there will be
> facilities for handling NAs in the training set.  However, there's no way to
> handle NAs in the test set yet.  I believe Leo is still working on that.
>
> In Leo's v.4 of the Fortran code, he uses proximity from random forest to
> iteratively impute NAs, starting with column median or mode (depending on
> variable types).  I've implemented this scheme at the R level, so that it
> works for both regression and classification.
>
> There are a couple of things in Leo's new code that I have not added to the
> package, and that's why the version is 3.9 rather than 4.0.  If you would
> like to test the new code, please let me know.

yes, sure!

best,

Torsten

>
> Cheers,
> Andy
>
> > -----Original Message-----
> > From: Yves Brostaux [mailto:brostaux.y at fsagx.ac.be]
> > Sent: Wednesday, April 02, 2003 8:34 AM
> > To: r-help at stat.math.ethz.ch
> > Cc: Liaw, Andy; Torsten Hothorn
> > Subject: RE: [R] randomForests predict problem
> >
> >
> > I use randomForest version 3.4-4, but yes, now I correctly
> > omitted NA's it
> > works. I should have made a mistake while removing them first time.
> >
> > I was surprised that this method doesn't have another way to
> > deal with NA's
> > than omitting them. As Torsten Hothorn suggested, the
> > associated predict
> > function should then check for NA's in newdata, shouldn't it ?
> >
> > Thank you both for your answers !
> >
> > At 15:12 02/04/03, Liaw, Andy wrote:
> > >Yves,
> > >
> > >Which version of the package are you using?  I get:
> > >
> > > > soy <- na.omit(Soybean)
> > > > ts <- sample(nrow(soy), 150, replace=FALSE)
> > > > sb.rf <- randomForest(Class ~ ., data=soy[-ts,])
> > > > table(predict(sb.rf, soy[ts,], type="class"))
> > >
> > >                2-4-d-injury         alternarialeaf-spot
> > >                           0                          37
> > >                 anthracnose            bacterial-blight
> > >                          10                           3
> > >           bacterial-pustule                  brown-spot
> > >                           2                          29
> > >              brown-stem-rot                charcoal-rot
> > >                          11                           7
> > >               cyst-nematode diaporthe-pod-&-stem-blight
> > >                           0                           0
> > >       diaporthe-stem-canker                downy-mildew
> > >                           4                           8
> > >          frog-eye-leaf-spot            herbicide-injury
> > >                          17                           0
> > >      phyllosticta-leaf-spot            phytophthora-rot
> > >                           3                           5
> > >              powdery-mildew           purple-seed-stain
> > >                           4                           5
> > >        rhizoctonia-root-rot
> > >                           5
> > >
> > >Cheers,
> > >Andy
> > >
> > > > -----Original Message-----
> > > > From: Yves Brostaux [mailto:brostaux.y at fsagx.ac.be]
> > > > Sent: Wednesday, April 02, 2003 4:46 AM
> > > > To: r-help at stat.math.ethz.ch
> > > > Subject: [R] randomForests predict problem
> > > >
> > > >
> > > > Hello everybody,
> > > >
> > > > I'm testing the randomForest package in order to do some
> > > > simulations and I
> > > > get some trouble with the prediction of new values. The
> > random forest
> > > > computation is fine but each time I try to predict values
> > > > with the newly
> > > > created object, I get an error message. I thought I was
> > > > because NA values
> > > > in the dataframe, but I cleaned them and still got the same
> > > > error. What am
> > > > I doing wrong ?
> > > >
> > > >  > library(mlbench)
> > > >  > library(randomForest)
> > > >  > data(Soybean)
> > > >  > test <- sample(1:683, 150, replace=F)
> > > >  > sb.rf <- randomForest(Class~., data=Soybean[-test,])
> > > >  > sb.rf.pred <- predict(sb.rf, Soybean[test,])
> > > > Error in matrix(t1$countts, nr = nclass, nc = ntest) :
> > > >          No data to replace in matrix(...)
> > > >
> > > > I did it the same way with rpart and all worked fine :
> > > >  > library(rpart)
> > > >  > sb.rp <- rpart(Class~., data=Soybean[-test,])
> > > >  > sb.rp.pred <- predict(sb.rp, Soybean[test,], type="class")
> > > >
> > > > Thank you all for any advice you can give to me.
> > > >
> > > > --
> > > > Ir. Yves Brostaux - Statistics and Computer Science Dpt.
> > > > Gembloux Agricultural University
> > > > 8, avenue de la Facult? B-5030 Gembloux (Belgium)
> > > > T?l : +32 (0)81 62 24 69
> > > > E-mail : brostaux.y at fsagx.ac.be
> > > > Web : http://www.fsagx.ac.be/si/
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > >
> > >
> > >-------------------------------------------------------------
> > -----------------
> > >Notice: This e-mail message, together with any attachments, contains
> > >information of Merck & Co., Inc. (Whitehouse Station, New
> > Jersey, USA)
> > >that may be confidential, proprietary copyrighted and/or legally
> > >privileged, and is intended solely for the use of the
> > individual or entity
> > >named on this message.  If you are not the intended
> > recipient, and have
> > >received this message in error, please immediately return
> > this by e-mail
> > >and then delete it.
> > >
> > >=============================================================
> > =================
> >
> >
>
>
> ------------------------------------------------------------------------------
> Notice: This e-mail message, together with any attachments, contains information of Merck & Co., Inc. (Whitehouse Station, New Jersey, USA) that may be confidential, proprietary copyrighted and/or legally privileged, and is intended solely for the use of the individual or entity named on this message. If you are not the intended recipient, and have received this message in error, please immediately return this by e-mail and then delete it.
>
> ==============================================================================
>
>


From Soren.Hojsgaard at agrsci.dk  Wed Apr  2 15:57:58 2003
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Wed, 2 Apr 2003 15:57:58 +0200
Subject: [R] Continuation string in Sweave
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC0CC673@DJFPOST01.djf.agrsci.dk>

Dear all,
In Sweave I have a code chunk
aaa <- "Sex, Drug/Sex:W1,Drug:W1,\
    Sex:W2,Drug:W2/Sex:W1:W2,Drug:W1:W2"
which in tex code turns into
\begin{Sinput}
> aaa <- "Sex, Drug/Sex:W1,Drug:W1,\n    Sex:W2,Drug:W2/Sex:W1:W2,Drug:W1:W2"
\end{Sinput}
meaning that the string is not split to two lines. Any suggestion about how to make Sweave break the string ?
Thanks in advance
S?ren H?jsgaard



==========================================
S?ren H?jsgaard,  PhD, Senior Scientist
Biometry Research Unit
Danish Institute of Agricultural Sciences
Research Centre Foulum, DK-8830 Tjele, Denmark
Phone: +45 8999 1703
E-mail : sorenh at agrsci.dk
Homepage : http://www.jbs.agrsci.dk/~sorenh/


From jarioksa at sun3.oulu.fi  Wed Apr  2 16:22:58 2003
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: 02 Apr 2003 17:22:58 +0300
Subject: [R] "..." and Error: unused argument(s)
Message-ID: <1049293378.9460.59.camel@pc112145.oulu.fi>

Dear R people,

Would it be possible to add "..." to the argument list of arrows() or
should this be dealt with at the user level? 

The problem is that I need arrows() in a function together with points()
or text(). All these are used with their default values, but I let the
user to change these so that there is "..." in my function call. Some of
these parameters (like col) are meaningfully transferred to both
arrows() and points()/text(), but other makes sense only in one. This
results sometimes in a warning in points() and text(), but this can be
tolerated. Function arrows() doesn't tolerate any strange parameters,
but gives an error, stops, and doesn't draw anything:

Error in arrows(0, 0, pts[, 1], pts[, 2], length = head.arrow, ...) :
        unused argument(s) (cex ...)

Instead of dying from unused arguments, I would like arrows() to
silently ignore them.

Now I solved this problem with a hack (or is that a kludge?) of adding
this line in my function: 

formals(arrows) <- c(formals(arrows), alist(... = ))

Is this the recommended way to go?

cheers, jari oksanen
-- 
Jari Oksanen <jarioksa at sun3.oulu.fi>


From v_bill_pikounis at merck.com  Wed Apr  2 17:05:55 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Wed, 02 Apr 2003 10:05:55 -0500
Subject: [R] Autogenerated png, bitmap images
Message-ID: <E827328028C66044B4998F2EC353CD3003185398@usrymx12.merck.com>

Hi Tony,
I looked over the files and I am puzzled why the difference in font sizes.
Unfortunately my knowledge about X window configurations is pretty scant.
(You mention in the shell script comments that you run the job as root, so I
wonder if that makes any difference to X..I doubt it).  I recall some
threads on X devices and font sizes in the R-help archives, so you may wish
to consult there. You also suggested an XFree86 list, and I think that would
be a good idea to post.

But as a potential workaround thru R, perhaps the cex settings (see ?par),
like cex, cex.axis, cex.lab, cex.main, and cex.sub could help you adjust the
font-sizes down to what you would like.

> > Adjusting the pointsize argument in png might help.
> 
> I've played with this a little.  Any specific value you suggest?

I use pointsize = 10 in my set-up for png() with Xvfb, which is somewhat
different from the default (12).  It is hard to judge if that will reduce
your size enough.

Hope that helps,
Bill


> -----Original Message-----
> From: Tony Vargas [mailto:tvargas at cisco.com]
> Sent: Tuesday, April 01, 2003 2:40 PM
> To: Pikounis, Bill
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] Autogenerated png, bitmap images
> 
> 
> Bill,
> 
> Thanks for the response.  Comments in-line
> 
> Tony
> 
> Tony Vargas
> Cisco Systems
> Engineering Computing Services
> (408) 525-4113
> tvargas at cisco.com
> 
> On Tue, 1 Apr 2003, Pikounis, Bill wrote:
> 
> > Tony,
> >
> > > that all the fonts on my graphs get messed up.  Anybody have
> > > any nija R
> > > commands to make all fonts look great?  Anybody have any idea
> > > how to fix
> > > this?  So far, no luck on Solaris or Linux making the 
> Xvfb fonts look
> >
> > I have played with Xvfb and have not seen the same font 
> problem (Mandrake
> > 9.0 for Linux, R 1.6.2) generating png's via CGI (my 
> problems are more with
> > CGI-secure permissions).  You mentioned running a cron 
> (batch) job -- do you
> > see the same problem using R interactively (such as an ssh 
> login with X not
> > running)?  Perhaps you can provide some lines of your code 
> of your cron
> > script to help the diagnosis?  What is specifically messed 
> up with the
> > fonts?
> 
> Files are attached.  One of the files shows a creation via 
> cron, one via an ssh sesssion.
> Any idea how to make them look the exact same?  The script 
> that I use to
> start Xvbg (and call R) is also attached.
> 
> >
> > Adjusting the pointsize argument in png might help.
> 
> I've played with this a little.  Any specific value you suggest?
> 
> 
> >
> > > is that the bitmap files are enormous compared to the png 
> images.  Any
> > > idea how I could make the bmp images smaller (and create
> > > faster?) (One of
> > > my R bmp generation files is attached.)
> >
> > As far as bitmaps go, I think that in general the smaller 
> they are, the less
> > resolution you will have. But even if you are willing to 
> give that up, you
> > might need to delve into ghostscript call options, since my 
> understanding is
> > that what bitmap() uses under Linux (and I presume other X11 device
> > approaches including Solaris).  See the code for bitmap(), 
> in particular the
> > gsexe and cmd objects. (I noticed your setting of some 
> arguments like res in
> > your bitmap generation file attachment, but as I guess above, other
> > gs-intrinsic flags may be needed.)
> >
> > Hope that helps,
> > Bill


------------------------------------------------------------------------------


From david.firth at nuffield.oxford.ac.uk  Wed Apr  2 17:11:15 2003
From: david.firth at nuffield.oxford.ac.uk (David Firth)
Date: Wed, 2 Apr 2003 16:11:15 +0100
Subject: [R] CGIwithR for IIS
In-Reply-To: <HBEKIOBADKJHAGANMFFHGEBJCAAA.gemireni@qubisoft.it>
Message-ID: <58E1B4EE-651D-11D7-A03E-000393CD9F1A@nuffield.oxford.ac.uk>

CGIwithR works only on unix-like operating systems.  Not Windows.

David


On Wednesday, Apr 2, 2003, at 14:12 Europe/London, Gianluca Emireni 
wrote:

> Hi, I have a (maybe stupid) question... Does CGIwithR package can be
> installed in R for Windows to work with a Microsoft IIS web-server? Or 
> I
> need other libraries?
> Thank you, Gianluca.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From mmiller3 at iupui.edu  Wed Apr  2 17:57:26 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: 02 Apr 2003 10:57:26 -0500
Subject: [R] nlme groupedData warning
Message-ID: <878yussxi1.fsf@lumen.indyrad.iupui.edu>

I have a question about nlme (and yes, I have a copy of
"Mixed-Effects Models in S and S-Plus" on order :-)

I have a data frame, df, that I use to create a groupedData
object:

> df.K1 <- groupedData(K1 ~ tissue.ROI | scan, data=df )

If I add an outer grouping factor, I get a warning:

> df.K1 <- groupedData(K1 ~ tissue.ROI | scan, data=df, outer=~input.ROI )
Warning message: 
argument lengths differ in: split(x, f) 

Can anyone help me understand where this warning message is
coming from?  And what I might make of it?

Thanks, Mike

-- 
Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine


From robert at swissrisk.com  Wed Apr  2 17:59:42 2003
From: robert at swissrisk.com (Robert Milic)
Date: Wed, 2 Apr 2003 17:59:42 +0200
Subject: [R] SJava RInterpreter.dll
Message-ID: <000401c2f930$e0ace990$7000000a@enceladus>

I'm getting the following error message when running an SJava example:

Exception in thread "main" java.lang.UnsatisfiedLinkError: no
RInterpreter in java.library.path
        at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1344)
        at java.lang.Runtime.loadLibrary0(Runtime.java:744)
        at java.lang.System.loadLibrary(System.java:815)
        at
org.omegahat.R.Java.ROmegahatInterpreter.<clinit>(ROmegahatInterpreter.j
ava:34)
        at
org.omegahat.R.Java.Examples.JavaRPrompt.main(JavaRPrompt.java:17)

I have downloaded the SJava source files as well but was unable to
'make' them.


thank you for your time.
Julien Dinh


From richard.nixon at mrc-bsu.cam.ac.uk  Wed Apr  2 18:49:46 2003
From: richard.nixon at mrc-bsu.cam.ac.uk (Richard Nixon)
Date: Wed, 2 Apr 2003 17:49:46 +0100 (BST)
Subject: [R] lm with an arbitrary number of terms 
Message-ID: <E190lQo-0006Ly-00@bernstein.mrc-bsu.cam.ac.uk>

Hello folks,

Any ideas how to do this?

data.frame is a data frame with column names "x1",...,"xn"
y is a response variable of length dim(data.frame)[1]

I want to write a function

function(y, data.frame){
    lm(y~x1+...+xn)
}

This would be easy if n was always the same.
If n is arbitrary how could I feed the x1+...+xn terms into lm(response~terms)?

Thanks
Richard

--
Dr. Richard Nixon
MRC Biostatistics Unit, Cambridge, UK
http://www.mrc-bsu.cam.ac.uk/personal/richard
Tel: +44 (0)1223 330382, Fax: +44 (0)1223 33038


From yb8d at virginia.edu  Wed Apr  2 06:43:48 2003
From: yb8d at virginia.edu (Yongde Bao)
Date: Tue, 01 Apr 2003 23:43:48 -0500
Subject: [R] 
Message-ID: <5.1.1.6.0.20030401234126.02b28a70@unix.mail.virginia.edu>

Can someone point out for me where to find a package to do principal 
component analysis for Affy data, if existing?
Thanks, Yongde

Yongde Bao, Ph.D
Biomolecular Research Facility
Department of Microbiology
University of Virginia School of Medicine
Charlottesville, VA 22908

E-mail: yb8d at virginia.edu
Voice mail: 434-982-2551, 434-924-2553
FAX: 434-982-2514


From connie.davis at mail.internetseer.com  Wed Apr  2 19:09:37 2003
From: connie.davis at mail.internetseer.com (Connie Davis)
Date: Wed, 2 Apr 2003 12:09:37 -0500 (EST)
Subject: [R] Broken link on your website
Message-ID: <11441899.1049303377392.JavaMail.promon@pm68>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030402/d66f104a/attachment.pl

From rossini at blindglobe.net  Wed Apr  2 19:28:25 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 02 Apr 2003 09:28:25 -0800
Subject: [R] CGIwithR for IIS
In-Reply-To: <HBEKIOBADKJHAGANMFFHGEBJCAAA.gemireni@qubisoft.it> ("Gianluca
 Emireni"'s message of "Wed, 2 Apr 2003 15:12:21 +0200")
References: <HBEKIOBADKJHAGANMFFHGEBJCAAA.gemireni@qubisoft.it>
Message-ID: <87r88koll2.fsf@jeeves.blindglobe.net>

"Gianluca Emireni" <gemireni at qubisoft.it> writes:

> Hi, I have a (maybe stupid) question... Does CGIwithR package can be
> installed in R for Windows to work with a Microsoft IIS web-server? Or I
> need other libraries?

It should be possible; IIS will run CGI scripts.  However, that is the
limit of my knowledge of IIS.  I suspect it will take a great deal of
trial/error, knowledge, or both...

best,
-tony

-- 
A.J. Rossini					   rossini at u.washington.edu	
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email
UW:   Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX
They make me add this: CONFIDENTIALITY NOTICE: This e-mail message and any attachments may be confidential and privileged. If you received this message in error, please destroy it and notify the sender. Thank you.


From forporphyry at hotmail.com  Wed Apr  2 19:41:33 2003
From: forporphyry at hotmail.com (graham lawrence)
Date: Wed, 02 Apr 2003 09:41:33 -0800
Subject: [R] Efficiency: whole vector and for loop methods
Message-ID: <F154QfhuHeoGLaREOQP0000747f@hotmail.com>


Dear R-help,

As a generalization, is it more efficient to use a single method to 
selectively transform items in a matrix?  Preferably whole-vector, yes; but 
if one of the column vectors compels the use of a "for loop", is it then 
faster to do all of the transformations for the matrix via that "for loop", 
rather than use a mixture of methods on a column-wise basis?

TIA

graham lawrence


From john.janmaat at acadiau.ca  Wed Apr  2 19:46:07 2003
From: john.janmaat at acadiau.ca (John Janmaat)
Date: Wed, 02 Apr 2003 13:46:07 -0400
Subject: [R] Getting contours ...
Message-ID: <3E8B21DF.1060509@acadiau.ca>

Hello All,

I have a matrix of data that I want to locate a specific contour from. 
Is there a function to return points on a contour (or all the drawn 
contours) from a contour plot?

Thanks,

John.
-- 
--------------------------------------------------------------------------
Dr. John Janmaat
Department of Economics, Acadia University, Wolfville, NS, B4P 2R6
E-mail: jjanmaat at acadiau.ca        Web: http://ace.acadiau.ca/~jjanmaat
Tel: 902-585-1461		   Fax: 902-585-1070


From mli at emmes.com  Wed Apr  2 20:00:47 2003
From: mli at emmes.com (Ming-Chung Li)
Date: Wed, 02 Apr 2003 13:00:47 -0500
Subject: [R] cor.test observations limit
In-Reply-To: <Pine.LNX.4.44.0304012023250.12034-100000@gannet.stats>
References: <3.0.5.32.20030401135701.009f71a0@host2a.emmes.com>
Message-ID: <3.0.5.32.20030402130047.00a0d840@host2a.emmes.com>

This is a note to my second question. I just discovered my data containing
an 'Inf' value and this causes the error I saw when I used rcorr() function
from the Hmisc package. If I delete this observation, everything is fine.

Best,
Ming-Chung


From djisgitt at soundenergy.com  Wed Apr  2 21:02:28 2003
From: djisgitt at soundenergy.com (Don Isgitt)
Date: Wed, 02 Apr 2003 13:02:28 -0600
Subject: [R] S intrp function
Message-ID: <3E8B33C4.3000002@soundenergy.com>

Hi.

I am trying some S-Plus scripts that I used a few years ago on R. Many 
things have worked flawlesly and I am very impressed with the work the 
developers have done. (As I remember, the license fee on S-Plus at that 
time was ~$4500 per seat (AIX) ouch!!) So, thank you.

My question relates to the intrp function, which takes irregularly 
spaced xyz data and produces a regular xyz grid suitable for contouring 
or imaging. I have not found the equivalent function in R; have I missed 
it or is there some other preferred method to accomplish this.

Thank you very much.

Don

p.s. I am not subscribed to this list, so an email reply would be 
appreciated.


From john.janmaat at acadiau.ca  Wed Apr  2 20:39:05 2003
From: john.janmaat at acadiau.ca (John Janmaat)
Date: Wed, 02 Apr 2003 14:39:05 -0400
Subject: [R] Index of item in matrix
Message-ID: <3E8B2E49.4040306@acadiau.ca>

Hello All,

Is there a fast way to find the index(row and column) of a point in a 
matrix?

Thanks,

John.
-- 
--------------------------------------------------------------------------
Dr. John Janmaat
Department of Economics, Acadia University, Wolfville, NS, B4P 2R6
E-mail: jjanmaat at acadiau.ca        Web: http://ace.acadiau.ca/~jjanmaat
Tel: 902-585-1461		   Fax: 902-585-1070


From spencer.graves at pdf.com  Wed Apr  2 20:47:39 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 02 Apr 2003 10:47:39 -0800
Subject: [R] replication of latin squares --- again
References: <F95AFVSt6X7474oxKEs000485eb@hotmail.com>
Message-ID: <3E8B304B.5070701@pdf.com>

Dear Lamack:

Have you considered "lme" or "varcomp"?  For me, essential documentation 
for "lme" is Pinhiero and Bates (2000) Mixed-Effects Models in S and 
S-Plus (Springer).

In my experience, it is easier to get "varcomp" to run but harder to get 
the answers I want from it.

Best Wishes,
Spencer Graves
##################################
lamack lamack wrote:
> Dear all, this is a newbie's question.
> 
> I have a 4x4 latin square replicated 3 times. That is:
> 
>          operators
> batches 1  2  3  4
>  1      A  B  C  D
>  2      B  C  D  A
>  3      C  D  A  B
>  4      D  A  B  C
> 
>          operators
> batches 1  2  3  4
>  5      A  B  C  D
>  6      B  C  D  A
>  7      C  D  A  B
>  8      D  A  B  C
> 
>          operators
> batches 1  2  3  4
>  9      A  B  C  D
>  10     B  C  D  A
>  11     C  D  A  B
>  12     D  A  B  C
> 
> I have used the same operators but different batches.
> How can I get the anova table for this design using R?
> I have created a R object as
> 
>  bathces operators treatment  y   rep
>   1         1        A        y1   1
>   1         1        b        b2   1
>   .         .        .        .    .
> and so on
> 
> I appreciate in advance.
> 
> L.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From peterm at andrew.cmu.edu  Wed Apr  2 20:55:47 2003
From: peterm at andrew.cmu.edu (Peter Muhlberger)
Date: Wed, 02 Apr 2003 13:55:47 -0500
Subject: [R] Can't run regression on G3 Mac
Message-ID: <BAB09C63.4AEF%peterm@andrew.cmu.edu>

First, let me thank all the folks who replied, many of which didn't make it
into the digest.

The following summarizes their experiences w/ lm on a G3 Mac.  Apparently
some people have lm in R working w/ apparently the same configuration that
doesn't work for others:
                   
Machine             Operating System    R Configuration     Result
G3 iBook            10.2                Jan's OS X Binary   lm works
Pbook 500mhz G3     10.2                Jan's OS X Binary   lm fails
PB 400mhz G3 Pismo  10.2.4              Jan's OS X Binary   lm fails
Beige G3            OS X                Jan's OS X Binary   lm fails
Beige G3            OS X                Fink'ed             lm works
G3 iBook            OS X       Fink'ed r-base-atlas 1.6.1-3 lm fails
G3 Laptop           OS X?               Carbon rm162.sit    lm works
G3                  OS X?               Carbon rm162.sit    lm works

These are responses from the following folks:

D.G. , David, Peter (me), Steve, Steve, Ulises, Albyn, Martin

>From the above, the carbon version always seems to work, the finked version
worked for one person and not the other, and Jan's binary worked for 1
person but not three others.

Peter


From reid_huntsinger at merck.com  Wed Apr  2 21:18:16 2003
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Wed, 02 Apr 2003 14:18:16 -0500
Subject: [R] vectorize an expression
Message-ID: <2C23DE2983BE034CB1CB90DB6B813FD6028AC3FB@uswpmx11.merck.com>

You could calculate the index vector like

ind <- n * (cc - 1) + (1:n)

and then use it to index bb as a vector

aa <- bb[ind]

Reid Huntsinger

-----Original Message-----
From: Simon.Gatehouse at csiro.au [mailto:Simon.Gatehouse at csiro.au] 
Sent: Wednesday, April 02, 2003 2:15 AM
To: r-help at stat.math.ethz.ch
Subject: [R] vectorize an expression


Dear listers,
I'm having a bad R day.  I just can't think of the vectorized equivalent of:

for (ii in 1:n)   aa[ii]  =  bb[ii,cc[ii]]

Any suggestion received with embarrassment and gratitude

Simon Gatehouse                                  
CSIRO Exploration and Mining,
Newbigin Close off Julius Ave
North Ryde, NSW
 
Mail:      PO Box 136, North Ryde
           NSW 1670, Australia
Phone:     61 (2) 9490 8677
Fax:       61 (2) 9490 8921
Mobile:    61  0407 130 635 
E-mail:    simon.gatehouse at csiro.au
Web Page:  http://www.csiro.au/

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------


From csillery at selway.umt.edu  Wed Apr  2 22:02:15 2003
From: csillery at selway.umt.edu (Katalin Csillery)
Date: Wed, 2 Apr 2003 13:02:15 -0700 (MST)
Subject: [R] Can boot return matrix?
Message-ID: <Pine.OSF.4.21.0304021138310.31009-100000@selway.umt.edu>


Dear All,

I have a function which takes a n x m matrix as an argument and returns
an n x n matrix. I want to take bootstrap samples form the input matrix in
the way as each row represent a multivariate observation, so each
bootstrap sample would be an n x m matrix, and on each sample I want to
calculate the n x n matrix.  

This task can be done with the sample function, but I would like to use
the boot() function. I hope that it is going to be faster.
Something like this:
f1 <- function(nxm.matrix){...; return(nxn.matrix)}
f2 <- function(nxm.matrix, i) f1(nxm.matrix[i,])
boot.out <- boot(nxm.matrix, R, f2)
Error: incorrect number of subscripts on matrix

Since the final goal would be to put a confidence interval on the
statistics in each cell of the matrix I would like to use the boot.ci.
Even if I do the resampling with the sample function and I just use the
boot.ci by artificially putting togethet an boot.out type of list I run
into problems. Any idea how to set it up?

Also a note, the examples at the end of the boot.ci documentation, for the
city and gravity data set I get error messages for boot.ci() call. Did
anyone else noticed that? E.g.
> boot.ci(grav1.boot, type=c("stud","norm"))
[1] "odd number of coulumns"
     [,1]         [,2]
[1,] "95/-5.803"  "0.123/-6.929"
Error in paste("(", ints1[, 2 * (1:n1)], ",", sep = "") :
     subscript out of bounds

Thanks for any help in advance!

Katalin

___
Katalin Csillery
Division of Biological Sciences
University of Montana, Missoula MT 59801
Phone: 406 243 6106, E-mail: csillery at selway.umt.edu
----------------------------------------------------


From richard_raubertas at merck.com  Wed Apr  2 22:26:13 2003
From: richard_raubertas at merck.com (Raubertas, Richard)
Date: Wed, 02 Apr 2003 15:26:13 -0500
Subject: [R] Scripting with an external editor
Message-ID: <38C4C095FC35E5469BED686B42F40A134C5EB1@usrymx17.merck.com>

A.J. Rossini writes:

> From: rossini at blindglobe.net [mailto:rossini at blindglobe.net]
> Sent: Tuesday, April 01, 2003 1:28 PM
> To: r-help at stat.math.ethz.ch
> 
> "Prof. Brian Ripley" <ripley at stats.ox.ac.uk> writes:
> 
> > I think the `trick' is how text for parsing is sent to R, 
> and the answer 
> > is via the command line, using C redirection (and ptys under Unix).
> > I've already suggested that approach a week ago.
> 
> This is exactly it -- ESS works by sitting on top of R's I/O streams,
> i.e. stdin and stdout, and parsing the input and output of known
> commands.  Why anyone would want to reinvent that wheel is beyond me.
> 

Perhaps because some people (myself included) find Emacs a
really unpleasant editor to use.  (Not implying this is the
case for the person who started this thread, however.)  I know 
it is hard for the Emacs zealots to comprehend.

Having the ability to pipe selections from, say Nedit, directly
to the R command line would be nice.  It's absence is not 
enough to make me switch editors though.

Rich Raubertas

------------------------------------------------------------------------------


From John.Fieberg at dnr.state.mn.us  Wed Apr  2 22:36:02 2003
From: John.Fieberg at dnr.state.mn.us (John Fieberg)
Date: Wed, 02 Apr 2003 14:36:02 -0600
Subject: [R] lme parameterization question
Message-ID: <se8af703.072@co5.dnr.state.mn.us>

Hi,

I am trying to parameterize the following mixed model (following Piepho
and Ogutu 2002), to test for a trend over time, using multiple sites:

y[ij]=mu+b[j]+a[i]+w[j]*(beta +t[i])+c[ij]

where:
y[ij]= a response variable at site i and year j
mu = fixed intercept
Beta=fixed slope
w[j]=constant representing the jth year (covariate) 
b[j]=random effect of jth year, iid N(0,sigma2[b])
a[i]=random effect of the ith site, iid N(0, sigma2[a])
t[i]=random effect of ith site, iid N(0, sigma2[t])
c[ij]=random error associated with ith site and jth year

I would like to assume that an unstructured relationship applies to
a[i] and t[i] (i.e., I would like to assume that the random effects a[i]
and t[i] are drawn from a multivariate normal distribution with non-zero
covariance parameter).  These random effects are assumed to be
independent from the b[j]'s and from the c[ij]'s.  I have tried several
approaches, but cannot seem to duplicate the results presented in Piepho
and Ogutu using R's lme function (but I can reproduce the results using
SAS proc mixed).

In SAS, the model is fit using:

proc mixed method=REML nobound;
   class year site;
   model y=w site/ddfm=satterth s;
   random int/sub=year;
   random int w/sub=site type=un;
run;

Any help would be greatly appreciated!

Reference:
Piepho, H-P. and J.O.Ogutu. 2002.  A simple mixed model for trend
analysis in wildlife populations.  Journal of Agricultural, Biological,
and Environmental Statistics, 7(3):350-360.


Thanks,

John


From hodgess at uhddx01.dt.uh.edu  Wed Apr  2 22:45:36 2003
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Wed, 2 Apr 2003 14:45:36 -0600 (CST)
Subject: [R] Multivariate Time series
Message-ID: <200304022045.OAA05771@uhddx01.dt.uh.edu>

Dear R People:

Is there a library for Multivariate time series, please?

For some reason, I'm thinking that Dr. Paul Gilbert may have one?

R Version 1.6.2 (i've updated!) for Windows

Thanks so much!

Sincerely,
Erin Hodgess
University of Houston - Downtown
mailto: hodgess at uhddx01.dt.uh.edu


From spencer.graves at pdf.com  Wed Apr  2 23:44:08 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 02 Apr 2003 13:44:08 -0800
Subject: [R] lm with an arbitrary number of terms
References: <E190lQo-0006Ly-00@bernstein.mrc-bsu.cam.ac.uk>
Message-ID: <3E8B59A8.5070302@pdf.com>

The following might work:

	mdl <- paste("y~", paste(names(data.frame), collapse="+"))
	lm(mdl, ...)

If y = "y" is a column of your data.frame, you can delete it be 
selecting "names(data.frame)[!is.element(y, names(data.frame)]"

Can you solve the problem from here?
Best Wishes,
Spencer Graves

Richard Nixon wrote:
> Hello folks,
> 
> Any ideas how to do this?
> 
> data.frame is a data frame with column names "x1",...,"xn"
> y is a response variable of length dim(data.frame)[1]
> 
> I want to write a function
> 
> function(y, data.frame){
>     lm(y~x1+...+xn)
> }
> 
> This would be easy if n was always the same.
> If n is arbitrary how could I feed the x1+...+xn terms into lm(response~terms)?
> 
> Thanks
> Richard
> 
> --
> Dr. Richard Nixon
> MRC Biostatistics Unit, Cambridge, UK
> http://www.mrc-bsu.cam.ac.uk/personal/richard
> Tel: +44 (0)1223 330382, Fax: +44 (0)1223 33038
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From vograno at arbitrade.com  Wed Apr  2 23:58:48 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Wed, 2 Apr 2003 15:58:48 -0600 
Subject: [R] lm with an arbitrary number of terms 
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DD6C@jupiter.arbitrade.com>

I think you can do it like this

lm(y~., data=data.frame) # note the dot to the right of ~

> -----Original Message-----
> From: Richard Nixon [mailto:richard.nixon at mrc-bsu.cam.ac.uk]
> Sent: Wednesday, April 02, 2003 8:50 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] lm with an arbitrary number of terms 
> 
> 
> Hello folks,
> 
> Any ideas how to do this?
> 
> data.frame is a data frame with column names "x1",...,"xn"
> y is a response variable of length dim(data.frame)[1]
> 
> I want to write a function
> 
> function(y, data.frame){
>     lm(y~x1+...+xn)
> }
> 
> This would be easy if n was always the same.
> If n is arbitrary how could I feed the x1+...+xn terms into 
> lm(response~terms)?
> 
> Thanks
> Richard
> 
> --
> Dr. Richard Nixon
> MRC Biostatistics Unit, Cambridge, UK
> http://www.mrc-bsu.cam.ac.uk/personal/richard
> Tel: +44 (0)1223 330382, Fax: +44 (0)1223 33038
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-------------------------------------------------- 
DISCLAIMER\ This e-mail, and any attachments thereto, is intende... {{dropped}}


From cschuste at nd.edu  Thu Apr  3 00:12:05 2003
From: cschuste at nd.edu (Christof Schuster)
Date: Wed, 2 Apr 2003 17:12:05 -0500 (EST)
Subject: [R] ace with mon=0
Message-ID: <Pine.SOL.4.10.10304021710310.16797-100000@shakespeare.helios.nd.edu>


I was wondering whether someone can help me understand the
following behavior of the ace-function:

When ace is called with mon-parameter set to zero, R gives the
message "response spec can only be lin or ordered
(default)" and returns immediately. However, according to the help
file mon=0 requires the response transformations to be limited
to monotonic transformations.

For instance, the following call of the ace-function will not be
evaluated if one gives mon=0

     TWOPI <- 8*atan(1)
     x <- runif(200,0,TWOPI)
     y <- exp(sin(x)+rnorm(200)/2)
     a <- ace(x,y, mon=0)

Why does mon=0 not work and how should one interpret the message
"the response spec can only be lin or ordered" ?

Any help will be greatly appreciated,
  Christof

Christof Schuster
University of Notre Dame
Department of Psychology                       
103 Haggar Hall
Notre Dame, IN 46556

Tel: (574) 631-5473    email: cschuste at nd.edu
Fax: (574) 631-8883    www.nd.edu/~cschuste


From jimmcloughlin at earthlink.net  Thu Apr  3 00:19:25 2003
From: jimmcloughlin at earthlink.net (Jim McLoughlin)
Date: Wed, 2 Apr 2003 14:19:25 -0800
Subject: [R] normalized frequency histogram
Message-ID: <29CCF9BB-6559-11D7-B016-000393B2DF14@earthlink.net>

Hi folks

I'm trying to plot a normalized frequency histogram of some data.  
After checking the docs, it seems there is no built in feature for this.

from the definition for normalized frequency, I need to divide the 
relative frequency by the size of the intervals being used.

So I could divide the series by this interval length, and then plot the 
relative frequency.

The problem is determining the interval length that will be used in 
advance.  I'm supposed to manually pick the # of intervals between 20 
and 40 (not use sturges).  However, when I try different values for the 
nbreaks parameters, incrementing from 20 - 40, the histogram only 
changes at a couple of points on that interval.

Anyone have any suggestions as to how I should create this plot?  Or an 
explanation as to why my nbreaks parameter does not seem to force the 
number of intervals, but rather suggests a ballpark to be in?

thanks

Jim M


From p.dalgaard at biostat.ku.dk  Thu Apr  3 00:21:09 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Apr 2003 00:21:09 +0200
Subject: [R] lm with an arbitrary number of terms
In-Reply-To: <E190lQo-0006Ly-00@bernstein.mrc-bsu.cam.ac.uk>
References: <E190lQo-0006Ly-00@bernstein.mrc-bsu.cam.ac.uk>
Message-ID: <x2llys4k2y.fsf@biostat.ku.dk>

Richard Nixon <richard.nixon at mrc-bsu.cam.ac.uk> writes:

> Hello folks,
> 
> Any ideas how to do this?
> 
> data.frame is a data frame with column names "x1",...,"xn"
> y is a response variable of length dim(data.frame)[1]
> 
> I want to write a function
> 
> function(y, data.frame){
>     lm(y~x1+...+xn)
> }
> 
> This would be easy if n was always the same.
> If n is arbitrary how could I feed the x1+...+xn terms into lm(response~terms)?
> 

You could build up the formula in a for loop; something like

n <- names(my.data.frame)
f <- as.symbol(n[1])
for (i in 2:length(n))
  f <- substitute(f+a,list(a=as.symbol(n[i])) 
f <- substitute(y~f)

(I didn't try it. Most likely it doesn't quite work.)

However, what's wrong with 

lm(y ~ ., data=my.data.frame)

??

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From jfox at mcmaster.ca  Thu Apr  3 00:21:45 2003
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 02 Apr 2003 17:21:45 -0500
Subject: [R] lm with an arbitrary number of terms 
In-Reply-To: <E190lQo-0006Ly-00@bernstein.mrc-bsu.cam.ac.uk>
Message-ID: <5.0.2.1.0.20030402171218.026acdb0@mcmail.cis.mcmaster.ca>

Dear Richard,

At 05:49 PM 4/2/2003 +0100, Richard Nixon wrote:

>Any ideas how to do this?
>
>data.frame is a data frame with column names "x1",...,"xn"
>y is a response variable of length dim(data.frame)[1]
>
>I want to write a function
>
>function(y, data.frame){
>     lm(y~x1+...+xn)
>}
>
>This would be easy if n was always the same.
>If n is arbitrary how could I feed the x1+...+xn terms into 
>lm(response~terms)?

If y contains the *name* of the response variable, which is also in the 
data frame, then the following should work:

fun <- function(y, df){
     lm(as.formula(paste(y, "~.")), data=df)
     }

Alternatively, if y is a vector and is not in the data frame, then you 
might try

fun <- function(y, df){
     df <- data.frame(y, df)
     lm(y~., data=df)
     }

I hope that this helps,
  John
____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox


From dunn at usq.edu.au  Thu Apr  3 01:03:57 2003
From: dunn at usq.edu.au (Peter Dunn)
Date: 03 Apr 2003 09:03:57 +1000
Subject: [R] Two questions
Message-ID: <1049324637.3120.15.camel@grover.sci.usq.edu.au>

Hi all

Two questions:

1. I note that help for the postscript device claims "The 
postscript produced by R is EPS (Encapsulated PostScript)
compatible...".  It does not say it is EPS *compliant*.  
Indeed, the EPS produced by R includes a \showpage command 
which I believe (not that I'm an expert!) non-standard EPS.  
My question:  Is there any reason why it is EPS compatible,
but not compliant?  (I ask because the \showpage caused me
a minor trouble once.)

2.  R and S-Plus restrict the available combinations of
link functions and response distributions when using  glm.
The combinations allowed are certainly sensible, but what is
the logic for disallowing other combinations (eg  identity 
link only is allowed for the  gaussian  family)?  I also
know there are ways around it; I was just wondering about
the reasoning.

Thanks,

P.

-- 
Dr Peter Dunn          (USQ CRICOS No. 00244B)
  Web:    http://www.sci.usq.edu.au/staff/dunn
  Email:  dunn @ usq.edu.au
Opinions expressed are mine, not those of USQ.  Obviously...


From rpeng at stat.ucla.edu  Thu Apr  3 01:48:40 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 2 Apr 2003 15:48:40 -0800 (PST)
Subject: [R] lm with an arbitrary number of terms 
In-Reply-To: <E190lQo-0006Ly-00@bernstein.mrc-bsu.cam.ac.uk>
Message-ID: <Pine.GSO.4.10.10304021546001.28803-100000@quetelet.stat.ucla.edu>

You need to paste() together a formula.  There's an example in ?formula.
Try,

n <- 10
rhs <- paste("x", 1:n, collapse = "+", sep = "")
lhs <- "y ~"
f <- as.formula(paste(lhs, rhs))

Then pass `f' into lm().

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 2 Apr 2003, Richard Nixon wrote:

> Hello folks,
> 
> Any ideas how to do this?
> 
> data.frame is a data frame with column names "x1",...,"xn"
> y is a response variable of length dim(data.frame)[1]
> 
> I want to write a function
> 
> function(y, data.frame){
>     lm(y~x1+...+xn)
> }
> 
> This would be easy if n was always the same.
> If n is arbitrary how could I feed the x1+...+xn terms into lm(response~terms)?
> 
> Thanks
> Richard
> 
> --
> Dr. Richard Nixon
> MRC Biostatistics Unit, Cambridge, UK
> http://www.mrc-bsu.cam.ac.uk/personal/richard
> Tel: +44 (0)1223 330382, Fax: +44 (0)1223 33038
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From jmiyamot at u.washington.edu  Thu Apr  3 01:54:14 2003
From: jmiyamot at u.washington.edu (John Miyamoto)
Date: Wed, 2 Apr 2003 15:54:14 -0800 (PST)
Subject: [R] Combining the components of a character vector
Message-ID: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>

Dear Help,
   Suppose I have a character vector.

x <- c("Bob", "loves", "Sally")

I want to combine it into a single string:  "Bob loves Sally" .
paste(x) yields:
paste(x)
[1] "Bob"   "loves" "Sally"

The following function combines the character vector into a string in the
way that I want, but it seems somewhat inelegant.

paste.vector <- function(x, ...) {
	output <- NULL
	for (i in 1:length(x)) output <- paste(output, x[i], ...)
	output	} #end of function definition

paste.vector(x)
[1] " Bob loves Sally"

Is there a more natural (no loop) way to do this in R?

John Miyamoto

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------


From jerome at hivnet.ubc.ca  Thu Apr  3 02:47:15 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Wed, 2 Apr 2003 16:47:15 -0800
Subject: [R] Efficiency: whole vector and for loop methods
In-Reply-To: <F154QfhuHeoGLaREOQP0000747f@hotmail.com>
References: <F154QfhuHeoGLaREOQP0000747f@hotmail.com>
Message-ID: <200304030052.QAA09307@hivnet.ubc.ca>


Based on your particular problem, you can test the efficiency of any 
method you can think of with the system.time() function. I find it 
difficult to give a better advice considering the little information you 
provided about your problem.

If that doesn't help, perhaps you could send a simple and reproducable 
example of what you want to do.

Jerome

On April 2, 2003 09:41 am, graham lawrence wrote:
> Content-Length: 535
> Status: R
> X-Status: N
>
>
> Dear R-help,
>
> As a generalization, is it more efficient to use a single method to
> selectively transform items in a matrix?  Preferably whole-vector, yes;
> but if one of the column vectors compels the use of a "for loop", is it
> then faster to do all of the transformations for the matrix via that
> "for loop", rather than use a mixture of methods on a column-wise basis?
>
> TIA
>
> graham lawrence
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From white.denis at epamail.epa.gov  Thu Apr  3 04:15:24 2003
From: white.denis at epamail.epa.gov (white.denis@epamail.epa.gov)
Date: Wed, 02 Apr 2003 18:15:24 -0800
Subject: [R] Index of item in matrix
Message-ID: <OF2255D8FB.D2A9BA70-ON88256CFD.000BDA97@rtp.epa.gov>


Try these:

which.col <- function (mat, x) (which(mat==x)-1) %/% nrow(mat) + 1
which.row <- function (mat, x) (which(mat==x)-1) %% nrow(mat) + 1

Knowing the R community, there may be already functions to do this.

> Is there a fast way to find the index(row and column) of a
> point in a matrix?


From mschwartz at medanalytics.com  Thu Apr  3 04:17:07 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 2 Apr 2003 20:17:07 -0600
Subject: [R] Index of item in matrix
In-Reply-To: <3E8B2E49.4040306@acadiau.ca>
Message-ID: <000001c2f987$213ca940$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of John Janmaat
>Sent: Wednesday, April 02, 2003 12:39 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] Index of item in matrix
>
>
>Hello All,
>
>Is there a fast way to find the index(row and column) of a point in a

>matrix?
>
>Thanks,
>
>John.

Look at ?which.

Specifically the form: which(x, arr.ind = TRUE)

> m <- matrix(1:12,3,4) 
> m
     [,1] [,2] [,3] [,4]
[1,]    1    4    7   10
[2,]    2    5    8   11
[3,]    3    6    9   12
> which(m == 9, arr.ind = TRUE)
     row col
[1,]   3   3
> m[3,3]
[1] 9


HTH,

Marc Schwartz


From rpeng at stat.ucla.edu  Thu Apr  3 04:42:42 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 2 Apr 2003 18:42:42 -0800 (PST)
Subject: [R] S intrp function
In-Reply-To: <3E8B33C4.3000002@soundenergy.com>
Message-ID: <Pine.GSO.4.10.10304021841230.9599-100000@quetelet.stat.ucla.edu>

There is function `interp' in library(akima).  Maybe this is what you're
looking for?

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Wed, 2 Apr 2003, Don Isgitt wrote:

> Hi.
> 
> I am trying some S-Plus scripts that I used a few years ago on R. Many 
> things have worked flawlesly and I am very impressed with the work the 
> developers have done. (As I remember, the license fee on S-Plus at that 
> time was ~$4500 per seat (AIX) ouch!!) So, thank you.
> 
> My question relates to the intrp function, which takes irregularly 
> spaced xyz data and produces a regular xyz grid suitable for contouring 
> or imaging. I have not found the equivalent function in R; have I missed 
> it or is there some other preferred method to accomplish this.
> 
> Thank you very much.
> 
> Don
> 
> p.s. I am not subscribed to this list, so an email reply would be 
> appreciated.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From Bill.Venables at csiro.au  Thu Apr  3 06:31:39 2003
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Thu, 3 Apr 2003 14:31:39 +1000 
Subject: [R] lm with an arbitrary number of terms 
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A91659C0@roper-cv.qld.cmis.CSIRO.AU>

What are you using the data frame argument for?

If y, x1, x2, ..., xn were all the variables in the data frame all you need
do is

myfun <- function(y, dat) {
	lm(y ~ ., dat) 
}

but your question is very vague and ill-posed.


-----Original Message-----
From: Richard Nixon [mailto:richard.nixon at mrc-bsu.cam.ac.uk]
Sent: Thursday, April 03, 2003 2:50 AM
To: r-help at stat.math.ethz.ch
Subject: [R] lm with an arbitrary number of terms 


Hello folks,

Any ideas how to do this?

data.frame is a data frame with column names "x1",...,"xn"
y is a response variable of length dim(data.frame)[1]

I want to write a function

function(y, data.frame){
    lm(y~x1+...+xn)
}

This would be easy if n was always the same.
If n is arbitrary how could I feed the x1+...+xn terms into
lm(response~terms)?

Thanks
Richard

--
Dr. Richard Nixon
MRC Biostatistics Unit, Cambridge, UK
http://www.mrc-bsu.cam.ac.uk/personal/richard
Tel: +44 (0)1223 330382, Fax: +44 (0)1223 33038

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Thu Apr  3 06:40:14 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 02 Apr 2003 20:40:14 -0800
Subject: [R] Index of item in matrix
References: <3E8B2E49.4040306@acadiau.ca>
Message-ID: <3E8BBB2E.3000203@pdf.com>

Satisfying what conditions?

Does the following example help you get what you want?

 > set.seed(1)
 > A <- array(rnorm(12), dim=c(3,4))
 >
 > sel <- (round(A)==1)
 > sel
       [,1]  [,2]  [,3]  [,4]
[1,] FALSE FALSE FALSE  TRUE
[2,] FALSE  TRUE FALSE FALSE
[3,] FALSE FALSE FALSE FALSE
 > cbind(row(A)[sel],col(A)[sel])
      [,1] [,2]
[1,]    2    2
[2,]    1    4

Spencer Graves

John Janmaat wrote:
> Hello All,
> 
> Is there a fast way to find the index(row and column) of a point in a 
> matrix?
> 
> Thanks,
> 
> John.


From kjetil at entelnet.bo  Thu Apr  3 06:13:48 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Thu, 03 Apr 2003 00:13:48 -0400
Subject: [R] S intrp function
In-Reply-To: <3E8B33C4.3000002@soundenergy.com>
Message-ID: <3E8B7CBC.1457.150781B@localhost>

On 2 Apr 2003 at 13:02, Don Isgitt wrote:

Try package akima.

Kjetil Halvorsen


> Hi.
> 
> I am trying some S-Plus scripts that I used a few years ago on R. Many 
> things have worked flawlesly and I am very impressed with the work the 
> developers have done. (As I remember, the license fee on S-Plus at that 
> time was ~$4500 per seat (AIX) ouch!!) So, thank you.
> 
> My question relates to the intrp function, which takes irregularly 
> spaced xyz data and produces a regular xyz grid suitable for contouring 
> or imaging. I have not found the equivalent function in R; have I missed 
> it or is there some other preferred method to accomplish this.
> 
> Thank you very much.
> 
> Don
> 
> p.s. I am not subscribed to this list, so an email reply would be 
> appreciated.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From kjetil at entelnet.bo  Thu Apr  3 07:09:18 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Thu, 03 Apr 2003 01:09:18 -0400
Subject: [R] replication of latin squares --- again
In-Reply-To: <F95AFVSt6X7474oxKEs000485eb@hotmail.com>
Message-ID: <3E8B89BE.12634.1834694@localhost>

On 2 Apr 2003 at 11:57, lamack lamack wrote:

> Dear all, this is a newbie's question.
> 
> I have a 4x4 latin square replicated 3 times. That is:
> 
>           operators
> batches 1  2  3  4
>   1      A  B  C  D
>   2      B  C  D  A
>   3      C  D  A  B
>   4      D  A  B  C
> 
>           operators
> batches 1  2  3  4
>   5      A  B  C  D
>   6      B  C  D  A
>   7      C  D  A  B
>   8      D  A  B  C
> 
>           operators
> batches 1  2  3  4
>   9      A  B  C  D
>   10     B  C  D  A
>   11     C  D  A  B
>   12     D  A  B  C
> 
> I have used the same operators but different batches.
> How can I get the anova table for this design using R?
> I have created a R object as
> 
>   bathces operators treatment  y   rep
>    1         1        A        y1   1
>    1         1        b        b2   1
>    .         .        .        .    .
> and so on
> 

Something like , assuming the variables batches, operators, 
treatment, rep are factors and y is numeric, 

model <- aov(y ~ rep + batches + operators + treatment)

or 

model <- aov(y ~ batches + operators + treatment)
  (which will give another parametrization of the same model)

summary(model)

Kjetil Halvorsen


> I appreciate in advance.
> 
> L.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From otoomet at econ.dk  Thu Apr  3 06:52:47 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Thu, 3 Apr 2003 06:52:47 +0200
Subject: [R] Index of item in matrix
In-Reply-To: <3E8B2E49.4040306@acadiau.ca> (message from John Janmaat on Wed,
	02 Apr 2003 14:39:05 -0400)
References: <3E8B2E49.4040306@acadiau.ca>
Message-ID: <200304030452.h334qlw02926@punik.econ.au.dk>

Hi,

 | Date: Wed, 02 Apr 2003 14:39:05 -0400
 | From: John Janmaat <john.janmaat at acadiau.ca>
 | Hello All,
 | 
 | Is there a fast way to find the index(row and column) of a point in a 
 | matrix?

what do you mean as ,,a point in a matrix''?  Perhaps 
which( ,arr.ind=T) does what you are looking for.

Best wishes,
Ott


From Simon.Blomberg at anu.edu.au  Thu Apr  3 07:55:50 2003
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Thu, 3 Apr 2003 15:55:50 +1000
Subject: [R] Multivariate Time series
Message-ID: <7A3A13F416B40842BD2C1753E044B359B09839@CASEVS02.cas.anu.edu.au>

Look for package dse on CRAN.

Simon Blomberg
Depression & Anxiety Consumer Research Unit
Centre for Mental Health Research
Australian National University
http://www.anu.edu.au/cmhr/
Simon.Blomberg at anu.edu.au  +61 (2) 6125 3379


-----Original Message-----
From: Erin Hodgess [mailto:hodgess at uhddx01.dt.uh.edu]
Sent: Thursday, 3 April 2003 6:46 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Multivariate Time series


Dear R People:

Is there a library for Multivariate time series, please?

For some reason, I'm thinking that Dr. Paul Gilbert may have one?

R Version 1.6.2 (i've updated!) for Windows

Thanks so much!

Sincerely,
Erin Hodgess
University of Houston - Downtown
mailto: hodgess at uhddx01.dt.uh.edu

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From noel at univ-lille3.fr  Thu Apr  3 09:28:48 2003
From: noel at univ-lille3.fr (Noel Yvonnick)
Date: Thu, 3 Apr 2003 07:28:48 +0000
Subject: [R] Re: point-biserial correlation
In-Reply-To: <3E889595.14318.2451ED6@localhost>
References: <3E889595.14318.2451ED6@localhost>
Message-ID: <200304030728.48490.noel@univ-lille3.fr>

Le Lundi 31 Mars 2003 17:23, Bernd Weiss a ?crit :
> On 31 Mar 2003 at 15:07, Noel Yvonnick wrote:
>
> [...]
>
> > Note that the point-biserial correlation is nothing but the standard
> > correlation coefficient when one of the variables is dichotomous, so
> > that cor(.) is OK.
>
> Yes, this is a misleading subject.
>
> > The biserial is different and includes a correction for the so-called
> > "point of dichotomy". The following should work (translating a formula
> > found in a psychometric manual) :
>
> [...]
>
> >   # Biserial correlation
> >   # Be cautious in interpreting the sign :
> >   # depends upon the ordering of levels(x)
> >   ((m[1]-m[2])/Sy)*(f[1]*f[2]/dnorm(f[1]-.5))
>
> Thanks a lot for your help. Your code inspired me to do some modifications.
>
> (1) Following a German statistic book (Bortz, J?rgen, 1993: Statistik.
> Heidelberg: Springer) I use the following term "dnorm(qnorm(f[1]))" instead
> of "dnorm(f[1]-.5)".
>
> (2) I added some code for handling NA's.
>
> (3) Finaly, it is now possible to do some significance test for rbis.
>
>
> Bernd
>
>
> # Modification of Noel Yvonnick function for computing biserial
> correlations # x.na: 0/1 variable
> # y.na: continuous variable
> cor.biserial = function(x.na,y.na)
> {
>   x <- x[!is.na(y.na) & !is.na(x.na)]
>   y <- y[!is.na(y.na) & !is.na(x.na)]
>
>   stopifnot(is.factor(x))
>   stopifnot(length(levels(x))==2)
>   stopifnot(length(x)==length(y))
>
>   N = length(y)
>
>   # Success / Failure frequencies
>   n <- table(x)
>   f = table(x)/length(x)
>
>   # Means of success/failure groups on the global score
>   m = tapply(y,x,mean)
>
>   # Variance of the global score
>   Sy = sqrt(var(y)*(N-1)/N)
>
>   # Biserial correlation
>   # Be cautious in interpreting the sign :
>   # depends upon the ordering of levels(x)
>   rbis <- ((m[1]-m[2])/Sy)*(f[1]*f[2]/dnorm(qnorm(f[1])))
>
>   # significance test for rbis
>   rhobis <- sqrt(n[1]*n[2])/(dnorm(qnorm(f[1]))*N*sqrt(N))
>   z <- rbis/rhobis
>   alpha <- ifelse(z<0,pnorm(z),1-pnorm(z))
>
>   return(rbis,rhobis,z,alpha,N)
> }

That's great. I like this spontaneous collaboration ! This is the very spirit 
of R and this list. Thank you.

Just in case someone is interested : I am trying to compile as many 
psychometric functions I can in a so-called "Psychom" library. It is just a 
script for my students at that time, with very simple functions, but maybe 
other people could contribute to finalize a formal library ?

http://yvonnick.noel.free.fr/cours/licence/psychometrie/2003/psychom.R


Yvonnick Noel
Dpt. of Psychology
U. of Lille 3
FRANCE


From darryl.greig at hp.com  Thu Apr  3 08:31:57 2003
From: darryl.greig at hp.com (Darryl)
Date: Thu, 3 Apr 2003 09:31:57 +0300
Subject: [R] lm with an arbitrary number of terms 
In-Reply-To: <E190lQo-0006Ly-00@bernstein.mrc-bsu.cam.ac.uk>
Message-ID: <001701c2f9aa$ba10b990$bf09b00f@hpli.hpl.hp.com>

How about the following?

lm(as.formula(paste("y~",paste(names(data.frame),
collapse="+"),sep=""),cbind(data.frame,y))

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Richard Nixon
Sent: 02 April 2003 19:50
To: r-help at stat.math.ethz.ch
Subject: [R] lm with an arbitrary number of terms


Hello folks,

Any ideas how to do this?

data.frame is a data frame with column names "x1",...,"xn"
y is a response variable of length dim(data.frame)[1]

I want to write a function

function(y, data.frame){
    lm(y~x1+...+xn)
}

This would be easy if n was always the same.
If n is arbitrary how could I feed the x1+...+xn terms into
lm(response~terms)?

Thanks
Richard

--
Dr. Richard Nixon
MRC Biostatistics Unit, Cambridge, UK
http://www.mrc-bsu.cam.ac.uk/personal/richard
Tel: +44 (0)1223 330382, Fax: +44 (0)1223 33038

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Roger.Bivand at nhh.no  Thu Apr  3 08:35:22 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 3 Apr 2003 08:35:22 +0200 (CEST)
Subject: [R] S intrp function
In-Reply-To: <3E8B33C4.3000002@soundenergy.com>
Message-ID: <Pine.LNX.4.44.0304030832540.23320-100000@reclus.nhh.no>

On Wed, 2 Apr 2003, Don Isgitt wrote:

> Hi.
> 
> I am trying some S-Plus scripts that I used a few years ago on R. Many 
> things have worked flawlesly and I am very impressed with the work the 
> developers have done. (As I remember, the license fee on S-Plus at that 
> time was ~$4500 per seat (AIX) ouch!!) So, thank you.
> 
> My question relates to the intrp function, which takes irregularly 
> spaced xyz data and produces a regular xyz grid suitable for contouring 
> or imaging. I have not found the equivalent function in R; have I missed 
> it or is there some other preferred method to accomplish this.

Try package akima, interp() or variants should do what you need.

> 
> Thank you very much.
> 
> Don
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no


From Roger.Bivand at nhh.no  Thu Apr  3 08:38:04 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 3 Apr 2003 08:38:04 +0200 (CEST)
Subject: [R] Index of item in matrix
In-Reply-To: <3E8B2E49.4040306@acadiau.ca>
Message-ID: <Pine.LNX.4.44.0304030837270.23320-100000@reclus.nhh.no>

On Wed, 2 Apr 2003, John Janmaat wrote:

> Hello All,
> 
> Is there a fast way to find the index(row and column) of a point in a 
> matrix?

> x <- matrix(rnorm(25), 5, 5)
> which(x < -1, arr.ind=TRUE)
     row col
[1,]   1   1
[2,]   2   1
[3,]   2   2
[4,]   5   2
[5,]   1   3
[6,]   2   4

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no


From ritz at dina.kvl.dk  Thu Apr  3 08:45:59 2003
From: ritz at dina.kvl.dk (Christian Ritz)
Date: Thu, 3 Apr 2003 08:45:59 +0200
Subject: [R] lme parameterization question
References: <se8af703.072@co5.dnr.state.mn.us>
Message-ID: <001801c2f9ac$af900e60$e728e182@santamaria>

Hi,

try something like:

lme(y~w,random=list(~1|year,~1+w|site))

Christian

----- Original Message ----- 
From: "John Fieberg" <John.Fieberg at dnr.state.mn.us>
To: <R-help at stat.math.ethz.ch>
Sent: Wednesday, April 02, 2003 10:36 PM
Subject: [R] lme parameterization question


> Hi,
> 
> I am trying to parameterize the following mixed model (following Piepho
> and Ogutu 2002), to test for a trend over time, using multiple sites:
> 
> y[ij]=mu+b[j]+a[i]+w[j]*(beta +t[i])+c[ij]
> 
> where:
> y[ij]= a response variable at site i and year j
> mu = fixed intercept
> Beta=fixed slope
> w[j]=constant representing the jth year (covariate) 
> b[j]=random effect of jth year, iid N(0,sigma2[b])
> a[i]=random effect of the ith site, iid N(0, sigma2[a])
> t[i]=random effect of ith site, iid N(0, sigma2[t])
> c[ij]=random error associated with ith site and jth year


From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Apr  3 09:17:27 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu, 3 Apr 2003 09:17:27 +0200 (CEST)
Subject: [R] Index of item in matrix
In-Reply-To: <3E8B2E49.4040306@acadiau.ca>
References: <3E8B2E49.4040306@acadiau.ca>
Message-ID: <Pine.LNX.4.51.0304030916260.19038@artemis.imbe.med.uni-erlangen.de>


> Hello All,
>
> Is there a fast way to find the index(row and column) of a point in a
> matrix?
>

R> a <- matrix(1:25, ncol=5)
R> which(a == 2, arr.ind=TRUE)
     row col
[1,]   2   1
R> a
     [,1] [,2] [,3] [,4] [,5]
[1,]    1    6   11   16   21
[2,]    2    7   12   17   22
[3,]    3    8   13   18   23
[4,]    4    9   14   19   24
[5,]    5   10   15   20   25

best,

Torsten

> Thanks,
>
> John.
> --
> --------------------------------------------------------------------------
> Dr. John Janmaat
> Department of Economics, Acadia University, Wolfville, NS, B4P 2R6
> E-mail: jjanmaat at acadiau.ca        Web: http://ace.acadiau.ca/~jjanmaat
> Tel: 902-585-1461		   Fax: 902-585-1070
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>


From w.huber at dkfz-heidelberg.de  Thu Apr  3 09:34:54 2003
From: w.huber at dkfz-heidelberg.de (w.huber@dkfz-heidelberg.de)
Date: Thu, 3 Apr 2003 09:34:54 +0200 (MET DST)
Subject: [R] Re: [BioC] 
In-Reply-To: <5.1.1.6.0.20030401234126.02b28a70@unix.mail.virginia.edu>
References: <5.1.1.6.0.20030401234126.02b28a70@unix.mail.virginia.edu>
Message-ID: <Pine.GSO.4.53.0304030931170.6861@herkules>


Hi Yongde,

you do not need a special version of PCA for Affy data, a generic
implementation, e.g. mva::princomp, should do.

Best regards
Wolfgang

-------------------------------------
Wolfgang Huber
http://www.dkfz.de/mga/whuber
Division of Molecular Genome Analysis
German Cancer Research Center
Heidelberg, Germany
-------------------------------------

On Tue, 1 Apr 2003, Yongde Bao wrote:

> Can someone point out for me where to find a package to do principal
> component analysis for Affy data, if existing?
> Thanks, Yongde
>
> Yongde Bao, Ph.D
> Biomolecular Research Facility
> Department of Microbiology
> University of Virginia School of Medicine
> Charlottesville, VA 22908
>
> E-mail: yb8d at virginia.edu
> Voice mail: 434-982-2551, 434-924-2553
> FAX: 434-982-2514
>


From jasont at indigoindustrial.co.nz  Thu Apr  3 10:02:53 2003
From: jasont at indigoindustrial.co.nz (Jason Turner)
Date: Thu, 3 Apr 2003 20:02:53 +1200
Subject: [R] Multivariate Time series
In-Reply-To: <200304022045.OAA05771@uhddx01.dt.uh.edu>;
	from hodgess@uhddx01.dt.uh.edu on Wed, Apr 02, 2003 at 02:45:36PM -0600
References: <200304022045.OAA05771@uhddx01.dt.uh.edu>
Message-ID: <20030403200253.B8623@camille.indigoindustrial.co.nz>

On Wed, Apr 02, 2003 at 02:45:36PM -0600, Erin Hodgess wrote:
> Dear R People:
> 
> Is there a library for Multivariate time series, please?
> 
> For some reason, I'm thinking that Dr. Paul Gilbert may have one?

He does.  Download the dse bundle from CRAN, which contains the
libraries dse1, dse2, syskern, and tframe.

Cheers

Jason
-- 
Indigo Industrial Controls Ltd.
64-21-343-545
jasont at indigoindustrial.co.nz


From gavin.simpson at ucl.ac.uk  Thu Apr  3 10:44:48 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 3 Apr 2003 09:44:48 +0100
Subject: [R] Multivariate Time series
In-Reply-To: <200304022045.OAA05771@uhddx01.dt.uh.edu>
Message-ID: <000501c2f9bd$48f7a6c0$4c202880@gsimpson>

Hi Erin,

Paul Gilbert's package bundle is dse.  It is on CRAN under Package Sources.

Gavin

%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Erin Hodgess
Sent: 02 April 2003 21:46
To: r-help at stat.math.ethz.ch
Subject: [R] Multivariate Time series


Dear R People:

Is there a library for Multivariate time series, please?

For some reason, I'm thinking that Dr. Paul Gilbert may have one?

R Version 1.6.2 (i've updated!) for Windows

Thanks so much!

Sincerely,
Erin Hodgess
University of Houston - Downtown
mailto: hodgess at uhddx01.dt.uh.edu

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tamir at imp.univie.ac.at  Thu Apr  3 11:02:57 2003
From: tamir at imp.univie.ac.at (Ido M. Tamir)
Date: Thu, 3 Apr 2003 11:02:57 +0200
Subject: [R]
In-Reply-To: <5.1.1.6.0.20030401234126.02b28a70@unix.mail.virginia.edu>
References: <5.1.1.6.0.20030401234126.02b28a70@unix.mail.virginia.edu>
Message-ID: <200304031102.57958.tamir@imp.univie.ac.at>

On Wednesday 02 Apr 2003 6:43 am, Yongde Bao wrote:
> Can someone point out for me where to find a package to do principal
> component analysis for Affy data, if existing?

http://www.stat.uni-muenchen.de/~strimmer/rexpress.html

mva, multiv

best wishes

Ido


From zeileis at ci.tuwien.ac.at  Thu Apr  3 11:21:38 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Thu, 3 Apr 2003 10:21:38 +0100
Subject: [R] Is there any Time series change-point estimate in R?
In-Reply-To: <0FBE46098704A242B0DC8FEC4169F9978140CF@s31xs3.systems.smu.edu>
References: <0FBE46098704A242B0DC8FEC4169F9978140CF@s31xs3.systems.smu.edu>
Message-ID: <200304030921.h339LcxL003498@thorin.ci.tuwien.ac.at>

On Tuesday 01 April 2003 18:56, Wang, Zhu wrote:

> Hello,
>
> I am looking for time series non-stationary test and change - point
> estimate. The pachage strucchange seems not serving my purpose.

This is both very vague. You might find a suitable test for 
non-stationarity in tseries. And depending on what you mean by 
changepoint, strucchange might be able to do what you want. The 
function breakpoints() can estimate breakpoints in linear regression 
models, which includes certain types of models for non-stationary time 
series.
Z

> Thanks in advance.
>
> Zhu Wang
>
> Statistical Science Department
> SMU
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From richard.nixon at mrc-bsu.cam.ac.uk  Thu Apr  3 12:04:36 2003
From: richard.nixon at mrc-bsu.cam.ac.uk (Richard Nixon)
Date: Thu, 3 Apr 2003 11:04:36 +0100 (BST)
Subject: [R] lm with an arbitrary number of terms 
Message-ID: <E1911aG-0001Gw-00@bernstein.mrc-bsu.cam.ac.uk>

Thanks to James Holtman, Matt Wiener, Douglas Bates, Spencer Graves, John Fox,
Roger Peng, Bill Venable, Darryl Greig, Vadim Ogranovich and Peter Dalgaard

There are several ways to tackel this problem, and one easy one which I missed
:-) 


----------------------------------------------------------------------
Question
data.frame is a data frame with column names "x1",...,"xn"
y is a response variable of length dim(data.frame)[1]

I want to write a function

function(y, data.frame){
    lm(y~x1+...+xn)
}

This would be easy if n was always the same.
If n is arbitrary how could I feed the x1+...+xn terms into
lm(response~terms)?

----------------------------------------------------------------------
y <- c(67,76,56,48,10,43,12,33,88,63,75,14,58,19,14)
x1 <- as.factor(c(2,2,2,2,2,1,1,1,1,1,1,1,1,1,1))
x2 <- c(25,40,35,34,51,24,37,31,26,21,41,45,24,26,29)

data<-data.frame(x1,x2)
----------------------------------------------------------------------
1) James Holtman

fun <- function(y, data.frame){
    .vars <- paste(names(data.frame), collapse="+")
    eval(parse(text=paste('lm(y~',.vars,',data.frame)')))
}

fun(y,data)

Call:
lm(formula = y ~ x1 + x2, data = data.frame)

Coefficients:
(Intercept)          x12           x2  
     84.565       18.763       -1.403  
----------------------------------------------------------------------
2) Matt Wiener

fun <- function(y, data.frame){
    lm(y ~ ., data = data.frame)
}

fun(y,data)

Call:
lm(formula = y ~ ., data = data.frame)

Coefficients:
(Intercept)          x12           x2  
     84.565       18.763       -1.403  

----------------------------------------------------------------------
3) Matt Wiener

fun <- function(y, data.frame){
    .vars <- paste(names(data.frame), collapse="+")
     lm(as.formula(paste('y~',.vars)),data.frame)
}

fun(y,data)

Call:
lm(formula = as.formula(paste("y~", .vars)), data = data.frame)

Coefficients:
(Intercept)          x12           x2  
     84.565       18.763       -1.403  


----------------------------------------------------------------------
Douglas Bates: same as (2)
Spencer Graves: similar to (3)
John Fox: mixture of (2) and (3) 
Roger Peng: similar to (3)
Bill Venable: same as (2)
Darryl Greig: simmilar to (3)
Vadim Ogranovich: same as (2)

Peter Dalgaard
n <- names(my.data.frame)
f <- as.symbol(n[1])
for (i in 2:length(n))
  f <- substitute(f+a,list(a=as.symbol(n[i])) 
f <- substitute(y~f)
(I didn't try it. Most likely it doesn't quite work.)
Neither did I - Richard ;)




--
Dr. Richard Nixon
MRC Biostatistics Unit, Cambridge, UK
http://www.mrc-bsu.cam.ac.uk/personal/richard
Tel: +44 (0)1223 330382, Fax: +44 (0)1223 33038


From MartynB at nag.co.uk  Thu Apr  3 12:14:55 2003
From: MartynB at nag.co.uk (Martyn Byng)
Date: Thu, 3 Apr 2003 11:14:55 +0100 
Subject: [R] Calling Fortran routines
Message-ID: <A1B373D68745D31180D100A0244BB400019F2FDF@nagmail.nag.co.uk>

Hi,

I am having problems calling a fortran routine from within R. When the
routine is called, R exits with an application error:
"The instruction at 0x004a8b7d referenced memory at 0x200000015. The memory
could not be written".

The R code used to call the routine is:
.Fortran("GTEST",a=as.integer(1),b=as.integer(3),c=as.integer(-10),d=as.inte
ger(0),e=as.integer(0))

The Fortran routine itself, is just a dummy routine, created to try and find
out why a more complex routine was causing R to crash, and consists of:

     SUBROUTINE GTEST_(A,B,C,D,E)
	INTEGER A,B,C,D,E

	!DEC$ ATTRIBUTES DLLEXPORT :: GTEST_
	!DEC$ ATTRIBUTES ALIAS:'GTEST_' :: GTEST_

      END

Where the !DEC commands are needed in Visual Fortran to create the DLL (I
think !, these were copied from an example file on the compaq web page).

The strange thing about this is that if I remove variable E from the
subroutine definition and recreate the DLL everything works as expected. The
routine causes R to crash only when it has more than 4 variables.

Any help would be appreciated.

Martyn

PS: I am using R version 1.6.2, under windows 2000 (professional), and the
Fortran code is compiled into a Windows 32bit DLL using Compaq Visual
Fortran Professional, edition 6.1.0

________________________________________________________________________
This e-mail has been scanned for all viruses by Star Internet. The
service is powered by MessageLabs. For more information on a proactive
anti-virus service working around the clock, around the globe, visit:
http://www.star.net.uk


From stanimura-ngs at umin.ac.jp  Thu Apr  3 09:53:49 2003
From: stanimura-ngs at umin.ac.jp (Susumu =?ISO-2022-JP?B?VGFuaW11cmEvGyRCQytCPBsoQiAbJEI/OBsoQg==?=)
Date: Thu, 3 Apr 2003 16:53:49 +0900
Subject: [R] New package of R 1.6.2 for VineLinux2.6
Message-ID: <20030403165349.54d4df56.stanimura-ngs@umin.ac.jp>

This is an announcement of a new package of R 1.6.2 built for
VineLinux2.6, which is RedHat based distribution integrated with Japanese
environment.

VineLinux users can download the source and binary package for i386 from
CRAN (http://www.r-project.org/). Although the VineLinux can work on i386
family, alpha, ppc, arm, ia64, aparc and ps2, only i386 package is ready
now. 

--
Susumu Tanimura
stanimura-ngs at umin.ac.jp


From abu_haifa at plasa.com  Thu Apr  3 12:39:19 2003
From: abu_haifa at plasa.com (Abu Haifa)
Date: Thu, 03 Apr 2003 17:39:19 +0700
Subject: [R] Call for papers
Message-ID: <web-2105122@b1.c.plasa.com>

"CALL FOR PAPERS"

THE ISLAMIC SOCIETY IN SOUTH EAST ASIA CONFERENCE ON 
STATISTICAL AND MATHEMATICAL SCIENCES 
BANDUNG, 25 - 26 APRIL 2003

Fakultas Matematika dan Ilmu Pengetahuan Alam
Universitas Islam Bandung
Jalan Tamansari No. 1, Bandung 40116
Telepon +62 22 4203368 Ext. 136 or 135
Facsimile +62 22 4263895
E-mail: -	fmipa_unisba at yahoo.com
              - wanda at dns.math.itb.ac.id


INTRODUCTION 
The Islamic Society in South East Asia Conference on 
Statistical and Mathematical Sciences will hold at 
Universitas Islam Bandung on April 25-26, 2003 with the 
following main objectives : 

* bring together research workers and practitioners in 
statistical and mathematical sciences from all over the 
South East Asia Countries in particular from Islamic 
Countries or countries with muslim majority through mutual 
exchange program.
* organize and strengthen a statistical and mathematical 
information system. 
* promote the application of statistical and mathematical 
sciences including computer and information technology in 
the development of Islamic Countries. 
* probe the establishment of Muslim Association of 
Statistical and Mathematical Sciences in South East Asia.
* hold seminars and any other means of communication 
helpful in exchanging scientific ideas. 

TENTATIVE PROGRAM 
April 25, 2003 
- Registration 
- Opening Ceremony 
- Keynote Speaker 
Prof. Dr. Maman A. Djauhari 
(Data Analysis Research Group - Institut Teknologi 
Bandung, Indonesia)
- Invited Papers
Prof. Dr. Kamel Ariffin Mohd. Atan J.S.M 
(Director of Institute for Mathematical Research - 
Universiti Putera Malaysia, Malaysia)
- Contributed Papers 
- Meeting on the establishment of Muslim Association of 
Statistical and Mathematical Sciences in South East Asia.

April 26, 2003 
- Invited Papers
Prof. Dr. Ismail Mohammad 
(Head of Department of Mathematics - Kolej Universiti 
Sains dan Teknologi Malaysia, Malaysia)
Dr. Aunuddin
(Director of Research Institute - Insitut Pertanian Bogor, 
Indonesia)
Suwanda, MSc. 
(Department of Statistics - Universitas Islam Bandung, 
Indonesia)
- Contributed Papers 
- Studium Generale
- Closing Ceremony 
Participation 
Conference is open to all nationalities. Participants from 
all scientific disciplines are expected. 


REGISTRATION 
The registration fees are as follows: 
- Foreign delegates/participants : US$ 100.00 
- Participants authors of contributed papers from 
Indonesia : Rp 250,000.00 
- Students from Indonesia : Rp 200,000.00

Please send the conference fee to :

Abdul Kudus
No. 236.001322641.901
Bank BNI Cabang ITB
Bandung, Indonesia

or

pay on cash at registration time (April 25, 2003).

Registration fee includes :
- 1 lunches, 2 times tea/coffee and snack per day.
- Conference kit.
- Certificate 
- Proceeding (will be sent to all participant, contributed 
paper, later)

ACCOMODATION 
If required by participants, Conference Committee may 
assist to get accommodation at hotel in Bandung. List of 
hotels see file attachment. 

TRANSPORTATION 
 From International Airport Soekarno Hatta Jakarta to 
Train Station GAMBIR by bus DAMRI about 30 minutes and to 
Bandung by train about 3 hours. Taxi/transport will be 
available at the Conference Venue. 

INSTRUCTION TO AUTHORS
Contributed papers related to any theory and applied work 
in the areas of Statistical and Mathematical Sciences. 
Participants wishing to contribute a paper are requested 
to follow the instructions as given below :  
* The manuscript must be typed in MS Word format using 
template ARTICLE.DOT (see File Attachment) or LaTeX in 
single spacing with 10 Times New Roman font, 3 cm top 
margin, 2.5 cm bottom margin, 3.5 cm left margin and 2 cm 
right margin. Abstract and complete paper not more than 6 
pages.
* All contributions should be written in English or Bahasa 
Indonesia or Melayu and contain an abstract of 
approximately 200 words plus a list of key words. 
* Paragraphs should be indented five spaces. 
* The name and full postal address of each author should 
be given immediately below the title of the paper along 
with e-mail. 
* Tables should be inserted in the text as close to the 
point of reference as possible. 
* Graphs and other numbered figures should be drawn in 
black India ink. 
* The numbers identifying displayed mathematical 
expressions should be placed in parentheses at the right 
margin.
* References should be indicated in the text by author's 
name(s) and the year of publication in parentheses. All 
references should also be given alphabetically at the end 
of the paper in the same way as the following examples :
Rao, C. R., 1972, Linear statistical inference and its 
applications, Wiley, New York.
Heckman, J.J. and B.E. Honor?, 1989, The identifiability 
of the competing risk model, Biometrika, 76, 325-330.
* Submission of a paper will be held to imply that it 
contains original unpublished work and is not being 
submitted for publication elsewhere.

Please submit complete paper to Conference Secretariat 
before 20 April, 2003.  If you send it by e-mail (file 
attachment), we sugest that it should be compressed (ZIP 
file). 
Please fill out the following Information Form and return 
it to Conference Secretariat as soon as possible. We would 
appreciate your 
assistance in promoting this Conference to those potential 
participants from your institution. 

INFORMATION FORM 

Please print or type 

[ ] Prof.   [ ] Dr.   [ ] Mr.    [ ] Ms. 

First (Given) Name: 
 ......................................
Last (Family) Name:  .....................................

Name of Organization:  ..................................

Mailing Address: 
............................................
.......................................................................
........................................................................

Tel: 
 ................................................................

Fax: 
 ...............................................................

Email Address: 
 ..............................................

Tittle of paper : 
.................................................

I intend to attend the Conference on Statistical and 
Mathematical Sciences of Islamic Society in South East 
Asia 
===========================================================================================
Malas antri buat mendapatkan print-out tagihan telepon ? Klik aja http://billinfo2.plasa.com
Gratis Perpanjangan dan Pendaftaran Nama Domain http://idc.plasa.com khusus di bulan Maret !


From s0238397 at sms.ed.ac.uk  Thu Apr  3 12:53:32 2003
From: s0238397 at sms.ed.ac.uk (Allan McRae)
Date: Thu, 3 Apr 2003 11:53:32 +0100
Subject: [R] Two y-axis in plots
Message-ID: <002001c2f9cf$44cd58d0$e5bed781@UNIVERSIVLBV7X>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030403/b83008f6/attachment.pl

From B.Rowlingson at lancaster.ac.uk  Thu Apr  3 13:07:41 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 03 Apr 2003 12:07:41 +0100
Subject: [R] Two questions
In-Reply-To: <1049324637.3120.15.camel@grover.sci.usq.edu.au>
References: <1049324637.3120.15.camel@grover.sci.usq.edu.au>
Message-ID: <3E8C15FD.7060508@lancaster.ac.uk>

Peter Dunn wrote:

> 1. I note that help for the postscript device claims "The 
> postscript produced by R is EPS (Encapsulated PostScript)
> compatible...".  It does not say it is EPS *compliant*.  
> Indeed, the EPS produced by R includes a \showpage command 
> which I believe (not that I'm an expert!) non-standard EPS.  
> My question:  Is there any reason why it is EPS compatible,
> but not compliant?  (I ask because the \showpage caused me
> a minor trouble once.)

  Adobe's tech documents are here:

http://partners.adobe.com/asn/developer/technotes/postscript.html

  and says

"The showpage operator is permitted in EPS files because it is present 
in so many PostScript language files. Therefore, it is reasonable for an 
EPS file to use the showpage operator, although it is not necessary if 
the EPS file will only be imported into another document. The 
application importing the EPS file is responsible for redefining showpage."

  So it seems that any problem you had with showpage was possibly the 
importing application's fault.

  I've just realised I've been hacking PS files for 15 years now...

Barry Rowlingson
Maths and Stats
Lancaster University
Lancaster, UK


From Friedrich.Leisch at ci.tuwien.ac.at  Thu Apr  3 13:08:54 2003
From: Friedrich.Leisch at ci.tuwien.ac.at (Friedrich.Leisch@ci.tuwien.ac.at)
Date: Thu, 3 Apr 2003 13:08:54 +0200
Subject: [R] R Foundation for Statistical Computing
Message-ID: <16012.5702.313924.464414@galadriel.ci.tuwien.ac.at>


The R Development Core Team would like to formally announce the
creation of the R Foundation for Statistical Computing. The Foundation
is incorporated in Austria and the specific details can be viewed at:

	http://www.r-project.org/foundation/

There are many reasons for this decision on our part, largely it is
based on the belief that R has become a mature and valuable tool and
we would like to ensure its continued development and the development
of future innovations in software for statistical and computational
research.

The R Foundation is a not for profit foundation whose general goals
are to provide support for the R project and other innovations in
statistical computing. The R Foundation will provide a reference point
for individuals, instititutions or commercial enterprises that want to
support or interact with the R development community.

We would like to solicit memberships from interested parties
(individual and institutional) in the R Foundation.  Details regarding
fees and membership categories can be obtained from the web site and
email enquiries can be sent to R-foundation at R-project.org.

Among the goals of the Foundation are the support of continued
development of R, the exploration of new methodology, teaching and
training of statistical computing and the organization of meetings and
conferences with a statistical computing orientation. We hope to
attract sufficient funding to make these goals realities.



For the R Development Core Team:

Robert Gentleman & Ross Ihaka
(Presidents, R Foundation)

Friedrich Leisch
(Secretary General, R Foundation)


From wegmann at biozentrum.uni-wuerzburg.de  Thu Apr  3 13:19:52 2003
From: wegmann at biozentrum.uni-wuerzburg.de (Martin Wegmann)
Date: Thu, 03 Apr 2003 13:19:52 +0200
Subject: [R] ts function 
Message-ID: <3E8C18D8.484E5C9D@biozentrum.uni-wuerzburg.de>

hello

I read "Practical Time Series" (Gareth Janacek; 2001) and they presented
e.g the
smoothing functions msmooth(x,k) or the bivariate function
crosscorr(x,y,k),
but both didn't work on my machine.  I only load the ts library, is
another
library necessary or did this function change since 2001? Is there a
more recent and detailed manual for ts?

thanks, cheers Martin


--
Martin Wegmann
Department of Animal Ecology and Tropical Biology
Zoology III, Biocenter
Am Hubland
97074 W?rzburg
Germany
0931/888-4378
wegmann at biozentrum.uni-wuerzburg.de
m.wegmann at web.de


From ded at novonordisk.com  Thu Apr  3 13:20:25 2003
From: ded at novonordisk.com (DED (David George Edwards))
Date: Thu, 3 Apr 2003 13:20:25 +0200 
Subject: [R] cdf function: inverse to quantile?
Message-ID: <36A25802686476479FBE08B99D1C111C0F3C4B@exdkba023.novo.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030403/790f2471/attachment.pl

From spencer.graves at pdf.com  Thu Apr  3 13:35:12 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 03 Apr 2003 03:35:12 -0800
Subject: [R] normalized frequency histogram
References: <29CCF9BB-6559-11D7-B016-000393B2DF14@earthlink.net>
Message-ID: <3E8C1C70.7070500@pdf.com>

Have you considered "truehist" in library(mass)?

Spencer Graves
p.s.  This is discussed in Venables and Ripley (2002) Modern Applied 
Statistics with S, 4th ed., which I recommend highly for anyone who uses 
S-Plus or R.  I only wish I had gotten the first edition when it 
appeared.

Jim McLoughlin wrote:
> Hi folks
> 
> I'm trying to plot a normalized frequency histogram of some data.  After 
> checking the docs, it seems there is no built in feature for this.
> 
> from the definition for normalized frequency, I need to divide the 
> relative frequency by the size of the intervals being used.
> 
> So I could divide the series by this interval length, and then plot the 
> relative frequency.
> 
> The problem is determining the interval length that will be used in 
> advance.  I'm supposed to manually pick the # of intervals between 20 
> and 40 (not use sturges).  However, when I try different values for the 
> nbreaks parameters, incrementing from 20 - 40, the histogram only 
> changes at a couple of points on that interval.
> 
> Anyone have any suggestions as to how I should create this plot?  Or an 
> explanation as to why my nbreaks parameter does not seem to force the 
> number of intervals, but rather suggests a ballpark to be in?
> 
> thanks
> 
> Jim M
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Thu Apr  3 13:39:09 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 03 Apr 2003 03:39:09 -0800
Subject: [R] lme parameterization question
References: <se8af703.072@co5.dnr.state.mn.us>
Message-ID: <3E8C1D5D.1090908@pdf.com>

Have you looked at Pinheiro and Bates (2000) Mixed Effects Models in S 
and s-Plus?  "lme" is great, but I couldn't make it work until I spent 
some time with that book.

Hope this helps.
Spencer Graves

John Fieberg wrote:
> Hi,
> 
> I am trying to parameterize the following mixed model (following Piepho
> and Ogutu 2002), to test for a trend over time, using multiple sites:
> 
> y[ij]=mu+b[j]+a[i]+w[j]*(beta +t[i])+c[ij]
> 
> where:
> y[ij]= a response variable at site i and year j
> mu = fixed intercept
> Beta=fixed slope
> w[j]=constant representing the jth year (covariate) 
> b[j]=random effect of jth year, iid N(0,sigma2[b])
> a[i]=random effect of the ith site, iid N(0, sigma2[a])
> t[i]=random effect of ith site, iid N(0, sigma2[t])
> c[ij]=random error associated with ith site and jth year
> 
> I would like to assume that an unstructured relationship applies to
> a[i] and t[i] (i.e., I would like to assume that the random effects a[i]
> and t[i] are drawn from a multivariate normal distribution with non-zero
> covariance parameter).  These random effects are assumed to be
> independent from the b[j]'s and from the c[ij]'s.  I have tried several
> approaches, but cannot seem to duplicate the results presented in Piepho
> and Ogutu using R's lme function (but I can reproduce the results using
> SAS proc mixed).
> 
> In SAS, the model is fit using:
> 
> proc mixed method=REML nobound;
>    class year site;
>    model y=w site/ddfm=satterth s;
>    random int/sub=year;
>    random int w/sub=site type=un;
> run;
> 
> Any help would be greatly appreciated!
> 
> Reference:
> Piepho, H-P. and J.O.Ogutu. 2002.  A simple mixed model for trend
> analysis in wildlife populations.  Journal of Agricultural, Biological,
> and Environmental Statistics, 7(3):350-360.
> 
> 
> Thanks,
> 
> John
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From feh3k at cms.mail.virginia.edu  Thu Apr  3 13:45:05 2003
From: feh3k at cms.mail.virginia.edu (Frank E Harrell Jr)
Date: Thu, 03 Apr 2003 06:45:05 -0500
Subject: [R] ace with =?us-ascii?q?mon=3D0?=
In-Reply-To: <Pine.SOL.4.10.10304021710310.16797-100000@shakespeare.helios.nd.edu>
Message-ID: <200304031145.GAA20022@www6.mail.Virginia.EDU>

-------------------
> 
> I was wondering whether someone can help me understand the
> following behavior of the ace-function:
> 
> When ace is called with mon-parameter set to zero, R gives the
> message "response spec can only be lin or ordered
> (default)" and returns immediately. However, according to the help
> file mon=0 requires the response transformations to be limited
> to monotonic transformations.
> 
> For instance, the following call of the ace-function will not be
> evaluated if one gives mon=0
> 
>      TWOPI <- 8*atan(1)
>      x <- runif(200,0,TWOPI)
>      y <- exp(sin(x)+rnorm(200)/2)
>      a <- ace(x,y, mon=0)
> 
> Why does mon=0 not work and how should one interpret the message
> "the response spec can only be lin or ordered" ?
> 
> Any help will be greatly appreciated,
>   Christof
> 
> Christof Schuster
> University of Notre Dame
> Department of Psychology                       
> 103 Haggar Hall
> Notre Dame, IN 46556

I use ace and avas quite a bit and have found a few tiny bugs such as 
that one.  I reported these bugs to the R bug list about a year ago 
and await corrections.  As you said, ace does handle nonmonotonic 
transformations of Y; you just have to turn off that error message.

Frank Harrell


From seidel at micro-biolytics.com  Thu Apr  3 15:16:31 2003
From: seidel at micro-biolytics.com (seidel@micro-biolytics.com)
Date: Thu, 3 Apr 2003 15:16:31 +0200
Subject: [R] 
	SVM module: scaling data applied to new test set without using SVM
	again
Message-ID: <OF1BA8628B.F3061D9D-ONC1256CFD.003FA6DF@imtek.uni-freiburg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030403/46f6af69/attachment.pl

From p.dalgaard at biostat.ku.dk  Thu Apr  3 14:19:35 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Apr 2003 14:19:35 +0200
Subject: [R] Combining the components of a character vector
In-Reply-To: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
References: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
Message-ID: <x2of3n6aeg.fsf@biostat.ku.dk>

John Miyamoto <jmiyamot at u.washington.edu> writes:

> Dear Help,
>    Suppose I have a character vector.
> 
> x <- c("Bob", "loves", "Sally")
> 
> I want to combine it into a single string:  "Bob loves Sally" .
> paste(x) yields:
> paste(x)
> [1] "Bob"   "loves" "Sally"

Like this:

> paste(x,collapse=" ")
[1] "Bob loves Sally"

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From sns at labyrinth.net.au  Thu Apr  3 14:20:59 2003
From: sns at labyrinth.net.au (strumila network systems)
Date: Thu, 3 Apr 2003 22:20:59 +1000
Subject: [R] Combining the components of a character vector
In-Reply-To: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
Message-ID: <000001c2f9db$7cbf6fb0$0700a8c0@epc>

paste(x,collapse=" ")

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of John Miyamoto
Sent: Thursday, 3 April 2003 9:54 AM
To: R discussion group
Subject: [R] Combining the components of a character vector


Dear Help,
   Suppose I have a character vector.

x <- c("Bob", "loves", "Sally")

I want to combine it into a single string:  "Bob loves Sally" .
paste(x) yields:
paste(x)
[1] "Bob"   "loves" "Sally"

The following function combines the character vector into a string in the
way that I want, but it seems somewhat inelegant.

paste.vector <- function(x, ...) {
	output <- NULL
	for (i in 1:length(x)) output <- paste(output, x[i], ...)
	output	} #end of function definition

paste.vector(x)
[1] " Bob loves Sally"

Is there a more natural (no loop) way to do this in R?

John Miyamoto

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From zeileis at ci.tuwien.ac.at  Thu Apr  3 14:27:09 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Thu, 3 Apr 2003 13:27:09 +0100
Subject: [R] Combining the components of a character vector
In-Reply-To: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
References: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
Message-ID: <200304031227.h33CR9Vb004057@thorin.ci.tuwien.ac.at>

On Thursday 03 April 2003 01:54, John Miyamoto wrote:

> Dear Help,
>    Suppose I have a character vector.
>
> x <- c("Bob", "loves", "Sally")
>
> I want to combine it into a single string:  "Bob loves Sally" .
> paste(x) yields:
> paste(x)
> [1] "Bob"   "loves" "Sally"

R> x <- c("Bob", "loves", "Sally")
R> paste(x, collapse = " ")
[1] "Bob loves Sally"

For further info a look at help(paste) might help
Z

> The following function combines the character vector into a string
> in the way that I want, but it seems somewhat inelegant.
>
> paste.vector <- function(x, ...) {
> 	output <- NULL
> 	for (i in 1:length(x)) output <- paste(output, x[i], ...)
> 	output	} #end of function definition
>
> paste.vector(x)
> [1] " Bob loves Sally"
>
> Is there a more natural (no loop) way to do this in R?
>
> John Miyamoto
>
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157, Email
> jmiyamot at u.washington.edu Homepage
> http://faculty.washington.edu/jmiyamot/
> --------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ndsub at mail.internetseer.com  Thu Apr  3 14:32:21 2003
From: ndsub at mail.internetseer.com (Mike Dever)
Date: Thu, 3 Apr 2003 07:32:21 -0500 (EST)
Subject: [R] InternetSeer- Account Set Up
Message-ID: <13318047.1049373141320.JavaMail.root@sunrays>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030403/32a0bc56/attachment.pl

From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Apr  3 14:42:59 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu, 3 Apr 2003 14:42:59 +0200 (CEST)
Subject: [R] Combining the components of a character vector
In-Reply-To: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
References: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
Message-ID: <Pine.LNX.4.51.0304031442420.19931@artemis.imbe.med.uni-erlangen.de>

> Dear Help,
>    Suppose I have a character vector.
>
> x <- c("Bob", "loves", "Sally")
>
> I want to combine it into a single string:  "Bob loves Sally" .
> paste(x) yields:
> paste(x)
> [1] "Bob"   "loves" "Sally"
>

R> x <- c("Bob", "loves", "Sally")
R> paste(x, collapse=" ")
[1] "Bob loves Sally"

best,

Torsten


> The following function combines the character vector into a string in the
> way that I want, but it seems somewhat inelegant.
>
> paste.vector <- function(x, ...) {
> 	output <- NULL
> 	for (i in 1:length(x)) output <- paste(output, x[i], ...)
> 	output	} #end of function definition
>
> paste.vector(x)
> [1] " Bob loves Sally"
>
> Is there a more natural (no loop) way to do this in R?
>
> John Miyamoto
>
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
> Homepage http://faculty.washington.edu/jmiyamot/
> --------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>


From Friedrich.Leisch at univie.ac.at  Thu Apr  3 14:45:23 2003
From: Friedrich.Leisch at univie.ac.at (Friedrich.Leisch@univie.ac.at)
Date: Thu, 3 Apr 2003 14:45:23 +0200
Subject: [R] Continuation string in Sweave
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC0CC673@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC0CC673@DJFPOST01.djf.agrsci.dk>
Message-ID: <16012.11491.329382.126782@ci.tuwien.ac.at>

>>>>> On Wed, 2 Apr 2003 15:57:58 +0200,
>>>>> S?ren H?jsgaard (SH) wrote:

  > Dear all,
  > In Sweave I have a code chunk
  > aaa <- "Sex, Drug/Sex:W1,Drug:W1,\
  >     Sex:W2,Drug:W2/Sex:W1:W2,Drug:W1:W2"
  > which in tex code turns into
  > \begin{Sinput}
  >> aaa <- "Sex, Drug/Sex:W1,Drug:W1,\n    Sex:W2,Drug:W2/Sex:W1:W2,Drug:W1:W2"
  > \end{Sinput}
  > meaning that the string is not split to two lines. Any suggestion about how to make Sweave break the string ?


Currently there is no way: Sweave operates on the *parsed* expressions
which do not contain the newlines. It does respect options(width=...)
settings, hence you can control approximately where lines are broken
(but not exactly).

Hope this helps,
Fritz

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik & DSS                Tel: (+43 1) 4277 38613
Universit?t Wien  		            Fax: (+43 1) 4277 38639
Universit?tsstra?e 5                  Friedrich.Leisch at univie.ac.at
1010 Wien, Austria     http://mailbox.univie.ac.at/Friedrich.Leisch
-------------------------------------------------------------------


From tamir at imp.univie.ac.at  Thu Apr  3 15:01:29 2003
From: tamir at imp.univie.ac.at (Ido M. Tamir)
Date: Thu, 3 Apr 2003 15:01:29 +0200
Subject: [R] Combining the components of a character vector
In-Reply-To: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
References: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
Message-ID: <200304031501.29761.tamir@imp.univie.ac.at>

On Thursday 03 Apr 2003 1:54 am, John Miyamoto wrote:
> Dear Help,
>    Suppose I have a character vector.
>
> x <- c("Bob", "loves", "Sally")
>
> I want to combine it into a single string:  "Bob loves Sally" .

y <- paste(c, collapse=" ")

best wishes

Ido


From vito.muggeo at giustizia.it  Thu Apr  3 15:11:19 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Thu, 3 Apr 2003 15:11:19 +0200
Subject: [R] Combining the components of a character vector
References: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
Message-ID: <007b01c2f9e2$8a5d7160$5c13070a@it.giustizia.it>

> x <- c("Bob", "loves", "Sally")
> paste(x,collapse=" ")
[1] "Bob loves Sally"

best,
vito


----- Original Message ----- 
From: "John Miyamoto" <jmiyamot at u.washington.edu>
To: "R discussion group" <r-help at stat.math.ethz.ch>
Sent: Thursday, April 03, 2003 1:54 AM
Subject: [R] Combining the components of a character vector


> Dear Help,
>    Suppose I have a character vector.
> 
> x <- c("Bob", "loves", "Sally")
> 
> I want to combine it into a single string:  "Bob loves Sally" .
> paste(x) yields:
> paste(x)
> [1] "Bob"   "loves" "Sally"
> 
> The following function combines the character vector into a string in the
> way that I want, but it seems somewhat inelegant.
> 
> paste.vector <- function(x, ...) {
> output <- NULL
> for (i in 1:length(x)) output <- paste(output, x[i], ...)
> output } #end of function definition
> 
> paste.vector(x)
> [1] " Bob loves Sally"
> 
> Is there a more natural (no loop) way to do this in R?
> 
> John Miyamoto
> 
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
> Homepage http://faculty.washington.edu/jmiyamot/
> --------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From upton at mitre.org  Thu Apr  3 15:25:38 2003
From: upton at mitre.org (Stephen C. Upton)
Date: Thu, 03 Apr 2003 08:25:38 -0500
Subject: [R] Combining the components of a character vector
References: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
Message-ID: <3E8C3651.EEB51F37@mitre.org>

John,

Try paste with collapse argument:
> x <- c("Bob", "loves", "Sally")
> paste(x,collapse=" ")
[1] "Bob loves Sally"

HTH
steve

John Miyamoto wrote:

> Dear Help,
>    Suppose I have a character vector.
>
> x <- c("Bob", "loves", "Sally")
>
> I want to combine it into a single string:  "Bob loves Sally" .
> paste(x) yields:
> paste(x)
> [1] "Bob"   "loves" "Sally"
>
> The following function combines the character vector into a string in the
> way that I want, but it seems somewhat inelegant.
>
> paste.vector <- function(x, ...) {
>         output <- NULL
>         for (i in 1:length(x)) output <- paste(output, x[i], ...)
>         output  } #end of function definition
>
> paste.vector(x)
> [1] " Bob loves Sally"
>
> Is there a more natural (no loop) way to do this in R?
>
> John Miyamoto
>
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
> Homepage http://faculty.washington.edu/jmiyamot/
> --------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From pwolf at wiwi.uni-bielefeld.de  Thu Apr  3 15:30:42 2003
From: pwolf at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Thu, 03 Apr 2003 15:30:42 +0200
Subject: [R] Combining the components of a character vector
References: <200304031235.h33CZoq26435@mailgate5.cinetic.de>
Message-ID: <3E8C3782.ADE0423B@wiwi.uni-bielefeld.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030403/c9073f8e/attachment.pl

From matthew_wiener at merck.com  Thu Apr  3 15:31:05 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Thu, 03 Apr 2003 08:31:05 -0500
Subject: [R] Combining the components of a character vector
Message-ID: <AEBD81486231A343B1813FE62D33522501317812@usrymx15.merck.com>

The collapse argument does what you want:

x <- c("Bob", "loves", "Sally")
paste(c, collapse = " ")

Hope this helps,

Matt Wiener

-----Original Message-----
From: John Miyamoto [mailto:jmiyamot at u.washington.edu] 
Sent: Wednesday, April 02, 2003 6:54 PM
To: R discussion group
Subject: [R] Combining the components of a character vector


Dear Help,
   Suppose I have a character vector.

x <- c("Bob", "loves", "Sally")

I want to combine it into a single string:  "Bob loves Sally" .
paste(x) yields:
paste(x)
[1] "Bob"   "loves" "Sally"

The following function combines the character vector into a string in the
way that I want, but it seems somewhat inelegant.

paste.vector <- function(x, ...) {
	output <- NULL
	for (i in 1:length(x)) output <- paste(output, x[i], ...)
	output	} #end of function definition

paste.vector(x)
[1] " Bob loves Sally"

Is there a more natural (no loop) way to do this in R?

John Miyamoto

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------


From ben at zoo.ufl.edu  Thu Apr  3 15:38:52 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Thu, 3 Apr 2003 08:38:52 -0500 (EST)
Subject: [R] Combining the components of a character vector
In-Reply-To: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
Message-ID: <Pine.LNX.4.44.0304030838410.3494-100000@bolker.zoo.ufl.edu>


  paste(x,collapse=" ")


On Wed, 2 Apr 2003, John Miyamoto wrote:

> Dear Help,
>    Suppose I have a character vector.
> 
> x <- c("Bob", "loves", "Sally")
> 
> I want to combine it into a single string:  "Bob loves Sally" .
> paste(x) yields:
> paste(x)
> [1] "Bob"   "loves" "Sally"
> 
> The following function combines the character vector into a string in the
> way that I want, but it seems somewhat inelegant.
> 
> paste.vector <- function(x, ...) {
> 	output <- NULL
> 	for (i in 1:length(x)) output <- paste(output, x[i], ...)
> 	output	} #end of function definition
> 
> paste.vector(x)
> [1] " Bob loves Sally"
> 
> Is there a more natural (no loop) way to do this in R?
> 
> John Miyamoto
> 
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
> Homepage http://faculty.washington.edu/jmiyamot/
> --------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From Ted.Harding at nessie.mcc.ac.uk  Thu Apr  3 15:03:33 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 03 Apr 2003 14:03:33 +0100 (BST)
Subject: [R] Two questions
In-Reply-To: <1049324637.3120.15.camel@grover.sci.usq.edu.au>
Message-ID: <XFMail.030403140333.Ted.Harding@nessie.mcc.ac.uk>

... and one answer ...

On 02-Apr-03 Peter Dunn wrote:
> Hi all
> 
> Two questions:
> 
> 1. I note that help for the postscript device claims "The 
> postscript produced by R is EPS (Encapsulated PostScript)
> compatible...".  It does not say it is EPS *compliant*.  
> Indeed, the EPS produced by R includes a \showpage command 
> which I believe (not that I'm an expert!) non-standard EPS.  
> My question:  Is there any reason why it is EPS compatible,
> but not compliant?  (I ask because the \showpage caused me
> a minor trouble once.)

Nothing whatever wrong with this, and it is perfectly standard
and "compliant" and indeed is covered in the PostScript Language
Reference Manual.

Using 'showpage' allows the file to be displayed directly on
any PS device, while the file can be embedded in another document
PROVIDED the embedding PS code redefines 'showpage' to be null
(i.e. /showpage {} def) for the duration of the wrapper.

Some document-generating software, however, can be sloppy about
this, in which case you will indeed have trouble. But that is
the fault of the software, not of the fact that 'showpage' is
present in the file.

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 03-Apr-03                                       Time: 14:03:33
------------------------------ XFMail ------------------------------


From JonesW at kssg.com  Thu Apr  3 15:32:19 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Thu, 3 Apr 2003 14:32:19 +0100 
Subject: [R] Na handing with time series objects
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB01EE2105@GIMLI>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030403/8a881ab5/attachment.pl

From bates at stat.wisc.edu  Thu Apr  3 15:38:00 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 03 Apr 2003 07:38:00 -0600
Subject: [R] Trying to make a nested lme analysis
In-Reply-To: <200303211119.21611.chrysopa@insecta.ufv.br>
References: <200303211119.21611.chrysopa@insecta.ufv.br>
Message-ID: <6rr88jitvr.fsf@bates4.stat.wisc.edu>

Where is the rats data available?

It looks as if you have an lme model with both a fixed effect for
Treatment and a random effect for Treatment.  I would guess that you
want to have a fixed effect for treatment and random effects for

 Rat %in% Treatment 

and 

 Liver %in% Rat %in% Treatment

If so you would first create a factor for Rat %in% Treatment, say rTrT
by 

 rats$rTrt = getGroups(~ 1 | Treatment/Rat, data = rats, level = 2)

then fit the lme model as

 lme(Glycogen ~ Treatment, data = rats, random = ~ 1|rTrT/Liver)


"Ronaldo Reis Jr." <chrysopa at insecta.ufv.br> writes:

> Hi,
> 
> I'm trying to understand the lme output and procedure.
> I'm using the Crawley's book.
> 
> I'm try to analyse the rats example take from Sokal and Rohlf (1995).
> I make a nested analysis using aov following the book.
> 
> > summary(rats)
>     Glycogen       Treatment      Rat          Liver  
>  Min.   :125.0   Min.   :1   Min.   :1.0   Min.   :1  
>  1st Qu.:135.8   1st Qu.:1   1st Qu.:1.0   1st Qu.:1  
>  Median :141.0   Median :2   Median :1.5   Median :2  
>  Mean   :142.2   Mean   :2   Mean   :1.5   Mean   :2  
>  3rd Qu.:150.0   3rd Qu.:3   3rd Qu.:2.0   3rd Qu.:3  
>  Max.   :162.0   Max.   :3   Max.   :2.0   Max.   :3  
>
> > attach(rats)
> > Treatment <- factor(Treatment)
> > Rat <- factor(Rat)
> > Liver <- factor(Liver)
> 
> > model <- aov(Glycogen~Treatment/Rat/Liver+Error(Treatment/Rat/Liver))
> > summary(model)
> 
> Error: Treatment
>           Df  Sum Sq Mean Sq
> Treatment  2 1557.56  778.78
> 
> Error: Treatment:Rat
>               Df Sum Sq Mean Sq
> Treatment:Rat  3 797.67  265.89
> 
> Error: Treatment:Rat:Liver
>                     Df Sum Sq Mean Sq
> Treatment:Rat:Liver 12  594.0    49.5
> 
> Error: Within
>           Df Sum Sq Mean Sq F value Pr(>F)
> Residuals 18 381.00   21.17               
> > 
> 
> OK,
> 
> Then I try to make this analysis using lme.
> 
> > model <- lme(Glycogen~Treatment, random=~1|Treatment/Rat/Liver)
> > summary(model)
> Linear mixed-effects model fit by REML
>  Data: NULL 
>        AIC      BIC    logLik
>   233.6213 244.0968 -109.8106
> 
> Random effects:
>  Formula: ~1 | Treatment
>         (Intercept)
> StdDev:    3.541272
> 
>  Formula: ~1 | Rat %in% Treatment
>         (Intercept)
> StdDev:     6.00658
> 
>  Formula: ~1 | Liver %in% Rat %in% Treatment
>         (Intercept) Residual
> StdDev:    3.764883 4.600247
> 
> Fixed effects: Glycogen ~ Treatment 
> Error in if (any(wchLv <- (as.double(levels(xtTab[, wchPval])) == 0))) { : 
> 	missing value where logical needed
> In addition: Warning message: 
> NaNs produced in: pt(q, df, lower.tail, log.p) 
> > 
> 
> The random effects are correct, the variance component is OK:
> 
> In nested aov | In nested lme
> Residual
> 21.1666       | 21.16227
> Liver in Rats
> 14.16667      | 14.17434
> Rats in Treatment
> 36.0648       | 36.079
> 
> But I not understand why the Fixed effects error?
> 
> What is the problem in my formula to make this analysis using lme?
> 
> Thanks for all
> Inte
> Ronaldo
> -- 
> Anger kills as surely as the other vices.
> --
> |   // | \\   [*****************************][*******************]
> || ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
> |      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
> ||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
> |  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
> ||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
> |/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
> ||  ( `-  )   [*****************************][*******************]
> ||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/


From andy_liaw at merck.com  Thu Apr  3 15:44:31 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 03 Apr 2003 08:44:31 -0500
Subject: [R] S intrp function
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F929@usrymx25.merck.com>

See if the `akima' package on CRAN does what you want.  I just checked in
Splus 6.1 on Linux and there's no `intrp'.  Do you mean `interp'?

Andy

> -----Original Message-----
> From: Don Isgitt [mailto:djisgitt at soundenergy.com]
> Sent: Wednesday, April 02, 2003 2:02 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] S intrp function
> 
> 
> Hi.
> 
> I am trying some S-Plus scripts that I used a few years ago 
> on R. Many 
> things have worked flawlesly and I am very impressed with the 
> work the 
> developers have done. (As I remember, the license fee on 
> S-Plus at that 
> time was ~$4500 per seat (AIX) ouch!!) So, thank you.
> 
> My question relates to the intrp function, which takes irregularly 
> spaced xyz data and produces a regular xyz grid suitable for 
> contouring 
> or imaging. I have not found the equivalent function in R; 
> have I missed 
> it or is there some other preferred method to accomplish this.
> 
> Thank you very much.
> 
> Don
> 
> p.s. I am not subscribed to this list, so an email reply would be 
> appreciated.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------


From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Apr  3 15:54:21 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu, 3 Apr 2003 15:54:21 +0200 (CEST)
Subject: [R] Efficiency: whole vector and for loop methods
In-Reply-To: <200304030052.QAA09307@hivnet.ubc.ca>
References: <F154QfhuHeoGLaREOQP0000747f@hotmail.com>
	<200304030052.QAA09307@hivnet.ubc.ca>
Message-ID: <Pine.LNX.4.51.0304031553460.22960@artemis.imbe.med.uni-erlangen.de>



>
> Based on your particular problem, you can test the efficiency of any
> method you can think of with the system.time() function.

or, much more informative, by profiling via `Rprof()' !

Torsten

> I find it
> difficult to give a better advice considering the little information you
> provided about your problem.
>
> If that doesn't help, perhaps you could send a simple and reproducable
> example of what you want to do.
>
> Jerome
>
> On April 2, 2003 09:41 am, graham lawrence wrote:
> > Content-Length: 535
> > Status: R
> > X-Status: N
> >
> >
> > Dear R-help,
> >
> > As a generalization, is it more efficient to use a single method to
> > selectively transform items in a matrix?  Preferably whole-vector, yes;
> > but if one of the column vectors compels the use of a "for loop", is it
> > then faster to do all of the transformations for the matrix via that
> > "for loop", rather than use a mixture of methods on a column-wise basis?
> >
> > TIA
> >
> > graham lawrence
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>


From bates at stat.wisc.edu  Thu Apr  3 15:59:03 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 03 Apr 2003 07:59:03 -0600
Subject: [R] Combining the components of a character vector
In-Reply-To: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
References: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
Message-ID: <6rhe9fiswo.fsf@bates4.stat.wisc.edu>

Use the collapse argument to paste.

> paste(c('Bob', 'loves', 'Sally'), collapse = ' ')
[1] "Bob loves Sally"

John Miyamoto <jmiyamot at u.washington.edu> writes:

>    Suppose I have a character vector.
> 
> x <- c("Bob", "loves", "Sally")
> 
> I want to combine it into a single string:  "Bob loves Sally" .


From jfox at mcmaster.ca  Thu Apr  3 16:08:02 2003
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 03 Apr 2003 09:08:02 -0500
Subject: [R] Combining the components of a character vector
In-Reply-To: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washingto
 n.edu>
Message-ID: <5.1.0.14.2.20030403090651.01e1dd00@mcmail.cis.mcmaster.ca>

Dear John,

Try paste(x, collapse=" ")

John


At 03:54 PM 4/2/2003 -0800, John Miyamoto wrote:
>Dear Help,
>    Suppose I have a character vector.
>
>x <- c("Bob", "loves", "Sally")
>
>I want to combine it into a single string:  "Bob loves Sally" .
>paste(x) yields:
>paste(x)
>[1] "Bob"   "loves" "Sally"
>
>The following function combines the character vector into a string in the
>way that I want, but it seems somewhat inelegant.
>
>paste.vector <- function(x, ...) {
>         output <- NULL
>         for (i in 1:length(x)) output <- paste(output, x[i], ...)
>         output  } #end of function definition
>
>paste.vector(x)
>[1] " Bob loves Sally"
>
>Is there a more natural (no loop) way to do this in R?

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From p.dalgaard at biostat.ku.dk  Thu Apr  3 16:24:48 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 03 Apr 2003 16:24:48 +0200
Subject: [R] Index of item in matrix
In-Reply-To: <OF2255D8FB.D2A9BA70-ON88256CFD.000BDA97@rtp.epa.gov>
References: <OF2255D8FB.D2A9BA70-ON88256CFD.000BDA97@rtp.epa.gov>
Message-ID: <x2k7eb64lr.fsf@biostat.ku.dk>

white.denis at epamail.epa.gov writes:

> Try these:
> 
> which.col <- function (mat, x) (which(mat==x)-1) %/% nrow(mat) + 1
> which.row <- function (mat, x) (which(mat==x)-1) %% nrow(mat) + 1
> 
> Knowing the R community, there may be already functions to do this.

There is. Take another look at ?which.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From tlumley at u.washington.edu  Thu Apr  3 16:38:40 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 3 Apr 2003 06:38:40 -0800 (PST)
Subject: [R] Efficiency: whole vector and for loop methods
In-Reply-To: <F154QfhuHeoGLaREOQP0000747f@hotmail.com>
Message-ID: <Pine.A41.4.44.0304030637440.66102-100000@homer22.u.washington.edu>

On Wed, 2 Apr 2003, graham lawrence wrote:

>
> Dear R-help,
>
> As a generalization, is it more efficient to use a single method to
> selectively transform items in a matrix?  Preferably whole-vector, yes; but
> if one of the column vectors compels the use of a "for loop", is it then
> faster to do all of the transformations for the matrix via that "for loop",
> rather than use a mixture of methods on a column-wise basis?
>

Hard to say.

My guess is that a mixture of methods would be faster, but the only
reliable answer to 'is it faster' is to try it and see.

	-thomas


From ernesto at ipimar.pt  Thu Apr  3 16:43:29 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 03 Apr 2003 15:43:29 +0100
Subject: [R] How to organize/develop an R function
Message-ID: <1049381009.1333.25.camel@gandalf.ipimar.pt>

Hi

Maybe this is not an issue about R. It's probably a programming issue
and I am not a developer at all. Anyway my main developing activities
are in R and that's where I have difficulties.

When I develop a function or group of functions I lose eternities with
the objects attributes and classes. I do a lot of object manipulation
(lists to arrays, factors to numeric vectors, etc, etc) so that I can
group data and apply the proper calculations/models to the proper data
combination.

Some times I get lost or need debugging and hell comes on earth. The
objects names are unconsistent, the objects classes are not correct so
methods work differently, etc.

My question is about programming good pratices in R. Does anyone know
about documents ? Do you use some project management software that help
on the function structure ? Do you have any ideas ? How do you (the R
gurus) develop your packages ?

Thanks

EJ


From mikael.niva at ebc.uu.se  Thu Apr  3 16:58:41 2003
From: mikael.niva at ebc.uu.se (Mikael Niva)
Date: Thu, 3 Apr 2003 16:58:41 +0200
Subject: [R] Matrix eigenvectors in R and MatLab
Message-ID: <000001c2f9f1$84ca9a20$3d9aee82@uu.se.vaxtbio>

Dear R-listers

Is there anyone who knows why I get different eigenvectors when I run
MatLab and R? I run both programs in Windows Me. Can I make R to produce
the same vectors as MatLab?

#R Matrix
PA9900<-c(11/24 ,10/53 ,0/1 ,0/1 ,29/43 ,1/24 ,27/53 ,0/1 ,0/1 ,13/43
,14/24 ,178/53 ,146/244 ,17/23 ,15/43 ,2/24 ,4/53 ,0/1 ,2/23 ,2/43 ,4/24
,58/53 ,26/244 ,0/1 ,5/43)

#R-syntax
PA9900<-matrix(PA9900,nrow=5,byrow=T)
eigen(PA9900)

#R-output
$values
[1]  1.2352970  0.3901522 -0.2562860  0.2259411  0.1742592

$vectors
            [,1]        [,2]        [,3]      [,4]       [,5]
[1,] -0.67795430 -1.70686496 -0.52613955 -8.675109 -0.8413826
[2,] -0.32621100  0.54611272 -0.21526356 -2.726193 -0.2876643
[3,] -2.83313878 -2.88801964  0.87388189 45.427935  4.5069361
[4,] -0.09857565 -0.33015962  0.09136359 -5.426254 -0.8201206
[5,] -0.68977432  0.01977374  0.61772506  3.751978  0.4348802


%Matlab Matrix
PA9900 =[11/24 10/53 0/1 0/1 29/43 ;1/24 27/53 0/1 0/1 13/43 ;14/24
178/53 146/244 17/23 15/43 ;2/24 4/53 0/1 2/23 2/43 ;4/24 58/53 26/244
0/1 5/43]

%MatLab-syntax
[wmat,dmat]=eig(mat)

%MatLab-output
wmat =

   -0.2250    0.4330   -0.4998   -0.1795   -0.1854
   -0.1083    0.1771    0.1599   -0.0614   -0.0583
   -0.9403   -0.7191   -0.8457    0.9617    0.9708
   -0.0327   -0.0752   -0.0967   -0.1750   -0.1160
   -0.2289   -0.5083    0.0058    0.0928    0.0802


dmat =

    1.2353         0         0         0         0
         0   -0.2563         0         0         0
         0         0    0.3902         0         0
         0         0         0    0.1743         0
         0         0         0         0    0.2259

Yours sincerely, Mikael Niva

********************************************
Mikael Niva
Avd. f?r V?xtekologi, Dept. of Plant Ecology
EvolutionsBiologiskt Centrum, Uppsala Universitet
Villav?gen 14
752 36 UPPSALA
E-post Mikael.Niva at EBC.UU.SE
Tel. +46 (0)18 471 28 65
Fax +46 (0)18 55 34 19


From Jean-Pierre.Mueller at dssp.unil.ch  Thu Apr  3 17:30:28 2003
From: Jean-Pierre.Mueller at dssp.unil.ch (Jean-Pierre.Mueller@dssp.unil.ch)
Date: Thu,  3 Apr 2003 17:30:28 MET DST
Subject: [R] Combining the components of a character vector
Message-ID: <mnet1.1049383828.20939.Jean-Pierre.Mueller@dssp.unil.ch>

At 15:54 -0800 2.4.2003, John Miyamoto wrote:
>Dear Help,
>   Suppose I have a character vector.
>
>x <- c("Bob", "loves", "Sally")
>
>I want to combine it into a single string:  "Bob loves Sally" .
>[...]
>Is there a more natural (no loop) way to do this in R?
>
>John Miyamoto


paste(x, sep = "", collapse = " ") ?


------------------------------------------------------------------------------
Jean-Pierre Muller
SSP / UNIL /  BFSH2 / CH-1015 Lausanne


From ernesto at ipimar.pt  Thu Apr  3 17:50:43 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 03 Apr 2003 16:50:43 +0100
Subject: [R] How to organize/develop an R function
Message-ID: <1049385042.1333.29.camel@gandalf.ipimar.pt>

Hi

Maybe this is not an issue about R. It's probably a programming issue
and I am not a developer at all. Anyway my main developing activities
are in R and that's where I have difficulties.

When I develop a function or group of functions I lose eternities with
the objects attributes and classes. I do a lot of object manipulation
(lists to arrays, factors to numeric vectors, etc, etc) so that I can
group data and apply the proper calculations/models to the proper data
combination.

Some times I get lost or need debugging and hell comes on earth. The
objects names are unconsistent, the objects classes are not correct so
methods work differently, etc.

My question is about programming good pratices in R. Does anyone know
about documents ? Do you use some project management software that help
on the function structure ? Do you have any ideas ? How do you (the R
gurus) develop your packages ?

Thanks

EJ


From umalvarez at fata.unam.mx  Thu Apr  3 18:15:04 2003
From: umalvarez at fata.unam.mx (Ulises Mora Alvarez)
Date: Thu, 3 Apr 2003 10:15:04 -0600 (CST)
Subject: [R] Fink-ed R-base 1.6.2's lm() OK on G3 iBook
In-Reply-To: <BAB09C63.4AEF%peterm@andrew.cmu.edu>
Message-ID: <Pine.LNX.4.44.0304031003580.17188-100000@fata.unam.mx>

Hi:

As a follow up on fink-ed R running on a G3 iBook:

As some folks suggest, I move from r-base-atlas to r-base using fink. As 
far as I can tell R is working OK now.

Machine: iBook G3 700 MHz
OS: 10.2.4
fink: Package manager version: 0.12.1; Distribution version: 0.5.1.cvs 
Version: R 1.6.2 (2003-01-10).

Regards.


On Wed, 2 Apr 2003, Peter Muhlberger wrote:

> First, let me thank all the folks who replied, many of which didn't make it
> into the digest.
> 
> The following summarizes their experiences w/ lm on a G3 Mac.  Apparently
> some people have lm in R working w/ apparently the same configuration that
> doesn't work for others:
>                    
> Machine             Operating System    R Configuration     Result
> G3 iBook            10.2                Jan's OS X Binary   lm works
> Pbook 500mhz G3     10.2                Jan's OS X Binary   lm fails
> PB 400mhz G3 Pismo  10.2.4              Jan's OS X Binary   lm fails
> Beige G3            OS X                Jan's OS X Binary   lm fails
> Beige G3            OS X                Fink'ed             lm works
> G3 iBook            OS X       Fink'ed r-base-atlas 1.6.1-3 lm fails
> G3 Laptop           OS X?               Carbon rm162.sit    lm works
> G3                  OS X?               Carbon rm162.sit    lm works
> 
> These are responses from the following folks:
> 
> D.G. , David, Peter (me), Steve, Steve, Ulises, Albyn, Martin
> 
> >From the above, the carbon version always seems to work, the finked version
> worked for one person and not the other, and Jan's binary worked for 1
> person but not three others.
> 
> Peter
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Ulises M. Alvarez
LAB. DE ONDAS DE CHOQUE
FISICA APLICADA Y TECNOLOGIA AVANZADA
UNAM
umalvarez at fata.unam.mx


From spencer.graves at pdf.com  Thu Apr  3 18:26:13 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 03 Apr 2003 08:26:13 -0800
Subject: [R] Combining the components of a character vector
References: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
Message-ID: <3E8C60A5.2090300@pdf.com>

paste( c("Bob", "loves", "Sally"), collapse=" ")

Spencer Graves

John Miyamoto wrote:
> Dear Help,
>    Suppose I have a character vector.
> 
> x <- c("Bob", "loves", "Sally")
> 
> I want to combine it into a single string:  "Bob loves Sally" .
> paste(x) yields:
> paste(x)
> [1] "Bob"   "loves" "Sally"
> 
> The following function combines the character vector into a string in the
> way that I want, but it seems somewhat inelegant.
> 
> paste.vector <- function(x, ...) {
> 	output <- NULL
> 	for (i in 1:length(x)) output <- paste(output, x[i], ...)
> 	output	} #end of function definition
> 
> paste.vector(x)
> [1] " Bob loves Sally"
> 
> Is there a more natural (no loop) way to do this in R?
> 
> John Miyamoto
> 
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
> Homepage http://faculty.washington.edu/jmiyamot/
> --------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tplate at blackmesacapital.com  Thu Apr  3 18:42:31 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Thu, 03 Apr 2003 09:42:31 -0700
Subject: [R] Combining the components of a character vector
In-Reply-To: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washingto
 n.edu>
Message-ID: <5.2.0.9.2.20030403093541.03dc30b0@mailhost.blackmesacapital.com>

 From ?paste:
>      If a value is specified for `collapse', the values in the result
>      are then concatenated into a single string, with the elements
>      being separated by the value of `collapse'.

 > paste(c("Bob", "loves", "Sally"), collapse=" ")
[1] "Bob loves Sally"
 >

At Wednesday 03:54 PM 4/2/2003 -0800, John Miyamoto wrote:
>Dear Help,
>    Suppose I have a character vector.
>
>x <- c("Bob", "loves", "Sally")
>
>I want to combine it into a single string:  "Bob loves Sally" .
>paste(x) yields:
>paste(x)
>[1] "Bob"   "loves" "Sally"
>
>The following function combines the character vector into a string in the
>way that I want, but it seems somewhat inelegant.
>
>paste.vector <- function(x, ...) {
>         output <- NULL
>         for (i in 1:length(x)) output <- paste(output, x[i], ...)
>         output  } #end of function definition
>
>paste.vector(x)
>[1] " Bob loves Sally"
>
>Is there a more natural (no loop) way to do this in R?
>
>John Miyamoto
>
>--------------------------------------------------------------------
>John Miyamoto, Dept. of Psychology, Box 351525
>University of Washington, Seattle, WA 98195-1525
>Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
>Homepage http://faculty.washington.edu/jmiyamot/
>--------------------------------------------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From chunlou at yahoo.com  Thu Apr  3 18:50:07 2003
From: chunlou at yahoo.com (Chunlou Yung)
Date: Thu, 3 Apr 2003 11:50:07 -0500
Subject: [R] Multivariate Time series
In-Reply-To: <200304022045.OAA05771@uhddx01.dt.uh.edu>
Message-ID: <NCBBKDNFIKJKKCFELNNMGEDHDFAA.chunlou@yahoo.com>

Dr. Paul Gilbert's DSE (Dynamic System Estimation) library (which includes
VAR) is available in R package library, CRAN, if that's what you're asking.


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Erin Hodgess
> Sent: Wednesday, April 02, 2003 03:46 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Multivariate Time series
>
>
> Dear R People:
>
> Is there a library for Multivariate time series, please?
>
> For some reason, I'm thinking that Dr. Paul Gilbert may have one?
>
> R Version 1.6.2 (i've updated!) for Windows
>
> Thanks so much!
>
> Sincerely,
> Erin Hodgess
> University of Houston - Downtown
> mailto: hodgess at uhddx01.dt.uh.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From sundar.dorai-raj at pdf.com  Thu Apr  3 19:06:15 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 03 Apr 2003 11:06:15 -0600
Subject: [R] Index of item in matrix
References: <3E8B2E49.4040306@acadiau.ca> <3E8BBB2E.3000203@pdf.com>
Message-ID: <3E8C6A07.5020807@pdf.com>

Or more simply:

 > set.seed(1)
 > A <- array(rnorm(12), dim=c(3,4))
 > which(round(A) == 1, arr.ind = TRUE)
      row col
[1,]   2   2
[2,]   1   4

Though, the original post may need more clarification.

Sundar

Spencer Graves wrote:
> Satisfying what conditions?
> 
> Does the following example help you get what you want?
> 
>  > set.seed(1)
>  > A <- array(rnorm(12), dim=c(3,4))
>  >
>  > sel <- (round(A)==1)
>  > sel
>       [,1]  [,2]  [,3]  [,4]
> [1,] FALSE FALSE FALSE  TRUE
> [2,] FALSE  TRUE FALSE FALSE
> [3,] FALSE FALSE FALSE FALSE
>  > cbind(row(A)[sel],col(A)[sel])
>      [,1] [,2]
> [1,]    2    2
> [2,]    1    4
> 
> Spencer Graves
> 
> John Janmaat wrote:
> 
>> Hello All,
>>
>> Is there a fast way to find the index(row and column) of a point in a 
>> matrix?
>>
>> Thanks,
>>
>> John.
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From john.janmaat at acadiau.ca  Thu Apr  3 19:30:38 2003
From: john.janmaat at acadiau.ca (John Janmaat)
Date: Thu, 03 Apr 2003 13:30:38 -0400
Subject: [R] Index of item in matrix
References: <OF2255D8FB.D2A9BA70-ON88256CFD.000BDA97@rtp.epa.gov>
	<x2k7eb64lr.fsf@biostat.ku.dk>
Message-ID: <3E8C6FBE.9030205@acadiau.ca>

Hello All,

Thanks,

John.

Peter Dalgaard BSA wrote:
> white.denis at epamail.epa.gov writes:
> 
> 
>>Try these:
>>
>>which.col <- function (mat, x) (which(mat==x)-1) %/% nrow(mat) + 1
>>which.row <- function (mat, x) (which(mat==x)-1) %% nrow(mat) + 1
>>
>>Knowing the R community, there may be already functions to do this.
> 
> 
> There is. Take another look at ?which.
> 


-- 
--------------------------------------------------------------------------
Dr. John Janmaat
Department of Economics, Acadia University, Wolfville, NS, B4P 2R6
E-mail: jjanmaat at acadiau.ca        Web: http://ace.acadiau.ca/~jjanmaat
Tel: 902-585-1461		   Fax: 902-585-1070


From jerome at hivnet.ubc.ca  Thu Apr  3 20:00:43 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Thu, 3 Apr 2003 10:00:43 -0800
Subject: [R] Combining the components of a character vector
In-Reply-To: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
References: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
Message-ID: <200304031806.KAA28295@hivnet.ubc.ca>


Please, have a closer look at the help file for paste(), and use the 
"collapse" arguments.

Jerome

On April 2, 2003 03:54 pm, John Miyamoto wrote:
> Dear Help,
>    Suppose I have a character vector.
>
> x <- c("Bob", "loves", "Sally")
>
> I want to combine it into a single string:  "Bob loves Sally" .
> paste(x) yields:
> paste(x)
> [1] "Bob"   "loves" "Sally"
>
> The following function combines the character vector into a string in
> the way that I want, but it seems somewhat inelegant.
>
> paste.vector <- function(x, ...) {
> 	output <- NULL
> 	for (i in 1:length(x)) output <- paste(output, x[i], ...)
> 	output	} #end of function definition
>
> paste.vector(x)
> [1] " Bob loves Sally"
>
> Is there a more natural (no loop) way to do this in R?
>
> John Miyamoto
>
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
> Homepage http://faculty.washington.edu/jmiyamot/
> --------------------------------------------------------------------
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From pkleiber at honlab.nmfs.hawaii.edu  Thu Apr  3 20:51:39 2003
From: pkleiber at honlab.nmfs.hawaii.edu (Pierre Kleiber)
Date: Thu, 03 Apr 2003 08:51:39 -1000
Subject: [R] Combining the components of a character vector
References: <Pine.A41.4.44.0304021552520.19986-100000@mead5.u.washington.edu>
Message-ID: <3E8C82BB.8030404@honlab.nmfs.hawaii.edu>

Try the "collapse" argument in paste(), i.e.
    paste(x,collapse=" ")


John Miyamoto wrote:
> Dear Help,
>    Suppose I have a character vector.
> 
> x <- c("Bob", "loves", "Sally")
> 
> I want to combine it into a single string:  "Bob loves Sally" .
> paste(x) yields:
> paste(x)
> [1] "Bob"   "loves" "Sally"
> 
> The following function combines the character vector into a string in the
> way that I want, but it seems somewhat inelegant.
> 
> paste.vector <- function(x, ...) {
> 	output <- NULL
> 	for (i in 1:length(x)) output <- paste(output, x[i], ...)
> 	output	} #end of function definition
> 
> paste.vector(x)
> [1] " Bob loves Sally"
> 
> Is there a more natural (no loop) way to do this in R?
> 
> John Miyamoto
> 
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
> Homepage http://faculty.washington.edu/jmiyamot/
> --------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 


-- 
-----------------------------------------------------------------
Pierre Kleiber             Email: pkleiber at honlab.nmfs.hawaii.edu
Fishery Biologist                     Tel: 808 983-5399/737-7544
NOAA FISHERIES - Honolulu Laboratory         Fax: 808 983-2902
2570 Dole St., Honolulu, HI 96822-2396
-----------------------------------------------------------------
  "God could have told Moses about galaxies and mitochondria and
   all.  But behold... It was good enough for government work."
-----------------------------------------------------------------


From spencer.graves at pdf.com  Thu Apr  3 21:19:28 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 03 Apr 2003 11:19:28 -0800
Subject: [R] Index of item in matrix
References: <3E8B2E49.4040306@acadiau.ca> <3E8BBB2E.3000203@pdf.com>
	<3E8C6A07.5020807@pdf.com>
Message-ID: <3E8C8940.7050505@pdf.com>

Sundar's solution is better than mine unless the code must also work in 
S-Plus.

Spencer Graves

Sundar Dorai-Raj wrote:
> Or more simply:
> 
>  > set.seed(1)
>  > A <- array(rnorm(12), dim=c(3,4))
>  > which(round(A) == 1, arr.ind = TRUE)
>      row col
> [1,]   2   2
> [2,]   1   4
> 
> Though, the original post may need more clarification.
> 
> Sundar
> 
> Spencer Graves wrote:
> 
>> Satisfying what conditions?
>>
>> Does the following example help you get what you want?
>>
>>  > set.seed(1)
>>  > A <- array(rnorm(12), dim=c(3,4))
>>  >
>>  > sel <- (round(A)==1)
>>  > sel
>>       [,1]  [,2]  [,3]  [,4]
>> [1,] FALSE FALSE FALSE  TRUE
>> [2,] FALSE  TRUE FALSE FALSE
>> [3,] FALSE FALSE FALSE FALSE
>>  > cbind(row(A)[sel],col(A)[sel])
>>      [,1] [,2]
>> [1,]    2    2
>> [2,]    1    4
>>
>> Spencer Graves
>>
>> John Janmaat wrote:
>>
>>> Hello All,
>>>
>>> Is there a fast way to find the index(row and column) of a point in a 
>>> matrix?
>>>
>>> Thanks,
>>>
>>> John.
>>
>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
> 
>


From jmiyamot at u.washington.edu  Thu Apr  3 21:25:06 2003
From: jmiyamot at u.washington.edu (John Miyamoto)
Date: Thu, 3 Apr 2003 11:25:06 -0800 (PST)
Subject: [R] Thanks re Combining the components of a character vector
Message-ID: <Pine.A41.4.44.0304031117340.27734-100000@mead1.u.washington.edu>

Many people pointed out that the 'collapse' argument yields the solution
to my query:

> x <- c("Bob", "loves", "Sally")
> paste(x, collapse=" ")
[1] "Bob loves Sally"

I had looked at the documentation for 'paste' within R and also in several
books before sending my question to R-Help, so I was aware of the
'collapse' argument, but I was making the mistake of abbreviating
'collapse':

> paste(x, col=" ")
[1] "Bob  "   "loves  " "Sally  "

The real source of my confusion was that I wasn't aware that arguments
following '...' must be fully specified.  Now I know that this is
important.  Thanks for the help.

John

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------


From f0z6305 at labs.tamu.edu  Thu Apr  3 23:30:59 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu, 3 Apr 2003 13:30:59 -0800
Subject: [R] How to estimate 2-D principal curve using PCURVE?
Message-ID: <001001c2fa28$52355d20$61455ba5@zhangfeng>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030403/10a2bb13/attachment.pl

From f0z6305 at labs.tamu.edu  Thu Apr  3 23:30:59 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu, 3 Apr 2003 13:30:59 -0800
Subject: [R] How to estimate 2-D principal curve using PCURVE?
Message-ID: <001001c2fa28$52355d20$61455ba5@zhangfeng>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030403/10a2bb13/attachment-0001.pl

From fbiz at mideastmail.net  Thu Apr  3 21:10:06 2003
From: fbiz at mideastmail.net (Fbiz Marketing)
Date: Fri, 4 Apr 2003 03:10:06 +0800
Subject: [R] New Coin Operated Mobile Phone Charger -  Seeking Overseas
	Distributors
Message-ID: <E191B0o-00010Q-00@bernie.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030404/858c20fe/attachment.pl

From spencer.graves at pdf.com  Thu Apr  3 22:11:54 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 03 Apr 2003 12:11:54 -0800
Subject: [R] Tukey's one degree of freedom for nonadditivity? 
Message-ID: <3E8C958A.3030509@pdf.com>

	  Is there code available to decompose interactions involving at least 
one nominal factor with more than 2 levels as described, e.g., by Tukey 
or by Mandel (1971, Technometrics, 13: 1-18)?

	  Tukey's model:

	E(y[i,j]) = mu0 + a[i] + b[j] + c*a[i]*b[j],

estimating a, b, and c so sum(a) = sum(b)= 0.  Mandel essentially 
describes a singular value decomposition of the interaction.

Thanks,
Spencer Graves


From ray at mcs.vuw.ac.nz  Thu Apr  3 22:27:20 2003
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Fri, 4 Apr 2003 08:27:20 +1200 (NZST)
Subject: [R] Combining the components of a character vector
Message-ID: <200304032027.h33KRK4M018823@tahi.mcs.vuw.ac.nz>

>    Suppose I have a character vector.
> 
> x <- c("Bob", "loves", "Sally")
> 
> I want to combine it into a single string:  "Bob loves Sally" .
> paste(x) yields:
> paste(x)
> [1] "Bob"   "loves" "Sally"
> 
> Is there a more natural (no loop) way to do this in R?
> 
RTFM:
> paste(x, collapse=" ")
[1] "Bob loves Sally"

Ray


From djisgitt at soundenergy.com  Thu Apr  3 23:31:16 2003
From: djisgitt at soundenergy.com (Don Isgitt)
Date: Thu, 03 Apr 2003 15:31:16 -0600
Subject: [R] S intrp function
References: <Pine.GSO.4.10.10304021841230.9599-100000@quetelet.stat.ucla.edu>
Message-ID: <3E8CA824.9040600@soundenergy.com>

Thank you, Roger, and to all who responded. akima is what I needed.

Don

Roger Peng wrote:

>There is function `interp' in library(akima).  Maybe this is what you're
>looking for?
>
>-roger
>_______________________________
>UCLA Department of Statistics
>rpeng at stat.ucla.edu
>http://www.stat.ucla.edu/~rpeng
>
>On Wed, 2 Apr 2003, Don Isgitt wrote:
>
>>Hi.
>>
>>I am trying some S-Plus scripts that I used a few years ago on R. Many 
>>things have worked flawlesly and I am very impressed with the work the 
>>developers have done. (As I remember, the license fee on S-Plus at that 
>>time was ~$4500 per seat (AIX) ouch!!) So, thank you.
>>
>>My question relates to the intrp function, which takes irregularly 
>>spaced xyz data and produces a regular xyz grid suitable for contouring 
>>or imaging. I have not found the equivalent function in R; have I missed 
>>it or is there some other preferred method to accomplish this.
>>
>>Thank you very much.
>>
>>Don
>>
>>p.s. I am not subscribed to this list, so an email reply would be 
>>appreciated.
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>
>
>


From Ted.Harding at nessie.mcc.ac.uk  Thu Apr  3 22:22:12 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 03 Apr 2003 21:22:12 +0100 (BST)
Subject: [R] Hypatia
Message-ID: <XFMail.030403212212.Ted.Harding@nessie.mcc.ac.uk>

It seems that hypatia.math.ethz.ch is hoarding messages
to the r-help list for up to 13 hours ... ?

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 03-Apr-03                                       Time: 21:22:12
------------------------------ XFMail ------------------------------


From bmagill at earthlink.net  Thu Apr  3 23:27:41 2003
From: bmagill at earthlink.net (Brett Magill)
Date: Thu, 03 Apr 2003 15:27:41 -0600
Subject: [R] Re: point-biserial correlation
In-Reply-To: <200304030728.48490.noel@univ-lille3.fr>
References: <3E889595.14318.2451ED6@localhost>
 <3E889595.14318.2451ED6@localhost>
Message-ID: <5.2.0.9.0.20030403152548.00b14190@mail.earthlink.net>

Take a look at my function, see if anything is of interest:

http://home.earthlink.net/~bmagill/MyMisc.html


At 07:28 AM 4/3/2003 +0000, Noel Yvonnick wrote:
>Le Lundi 31 Mars 2003 17:23, Bernd Weiss a ?crit :
> > On 31 Mar 2003 at 15:07, Noel Yvonnick wrote:
> >
> > [...]
> >
> > > Note that the point-biserial correlation is nothing but the standard
> > > correlation coefficient when one of the variables is dichotomous, so
> > > that cor(.) is OK.
> >
> > Yes, this is a misleading subject.
> >
> > > The biserial is different and includes a correction for the so-called
> > > "point of dichotomy". The following should work (translating a formula
> > > found in a psychometric manual) :
> >
> > [...]
> >
> > >   # Biserial correlation
> > >   # Be cautious in interpreting the sign :
> > >   # depends upon the ordering of levels(x)
> > >   ((m[1]-m[2])/Sy)*(f[1]*f[2]/dnorm(f[1]-.5))
> >
> > Thanks a lot for your help. Your code inspired me to do some modifications.
> >
> > (1) Following a German statistic book (Bortz, J?rgen, 1993: Statistik.
> > Heidelberg: Springer) I use the following term "dnorm(qnorm(f[1]))" instead
> > of "dnorm(f[1]-.5)".
> >
> > (2) I added some code for handling NA's.
> >
> > (3) Finaly, it is now possible to do some significance test for rbis.
> >
> >
> > Bernd
> >
> >
> > # Modification of Noel Yvonnick function for computing biserial
> > correlations # x.na: 0/1 variable
> > # y.na: continuous variable
> > cor.biserial = function(x.na,y.na)
> > {
> >   x <- x[!is.na(y.na) & !is.na(x.na)]
> >   y <- y[!is.na(y.na) & !is.na(x.na)]
> >
> >   stopifnot(is.factor(x))
> >   stopifnot(length(levels(x))==2)
> >   stopifnot(length(x)==length(y))
> >
> >   N = length(y)
> >
> >   # Success / Failure frequencies
> >   n <- table(x)
> >   f = table(x)/length(x)
> >
> >   # Means of success/failure groups on the global score
> >   m = tapply(y,x,mean)
> >
> >   # Variance of the global score
> >   Sy = sqrt(var(y)*(N-1)/N)
> >
> >   # Biserial correlation
> >   # Be cautious in interpreting the sign :
> >   # depends upon the ordering of levels(x)
> >   rbis <- ((m[1]-m[2])/Sy)*(f[1]*f[2]/dnorm(qnorm(f[1])))
> >
> >   # significance test for rbis
> >   rhobis <- sqrt(n[1]*n[2])/(dnorm(qnorm(f[1]))*N*sqrt(N))
> >   z <- rbis/rhobis
> >   alpha <- ifelse(z<0,pnorm(z),1-pnorm(z))
> >
> >   return(rbis,rhobis,z,alpha,N)
> > }
>
>That's great. I like this spontaneous collaboration ! This is the very spirit
>of R and this list. Thank you.
>
>Just in case someone is interested : I am trying to compile as many
>psychometric functions I can in a so-called "Psychom" library. It is just a
>script for my students at that time, with very simple functions, but maybe
>other people could contribute to finalize a formal library ?
>
>http://yvonnick.noel.free.fr/cours/licence/psychometrie/2003/psychom.R
>
>
>Yvonnick Noel
>Dpt. of Psychology
>U. of Lille 3
>FRANCE
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From GPetris at uark.edu  Thu Apr  3 23:54:12 2003
From: GPetris at uark.edu (Giovanni Petris)
Date: Thu, 3 Apr 2003 15:54:12 -0600 (CST)
Subject: [R] Printing zero as dot
Message-ID: <200304032154.h33LsCX7009631@definetti.uark.edu>


I'm pretty sure I've seen some examples of a function printing zero
entries in a matrix as dots, but I'm not able to find it now...
Any suggestions...? Thanks in advance. (Of course, I might have dreamt
of such a function...) 

Best,
Giovanni

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]


From tblackw at umich.edu  Fri Apr  4 00:45:32 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 3 Apr 2003 17:45:32 -0500 (EST)
Subject: [R] Can boot return matrix?
In-Reply-To: <Pine.OSF.4.21.0304021138310.31009-100000@selway.umt.edu>
Message-ID: <Pine.SOL.4.44.0304031728090.10086-100000@asteroids.gpcc.itd.umich.edu>


You're certainly very close.  I observe that you have interchanged
positions for the function which calculates the statistic (f2) and
the number of replicates (R) in the third line of your example below.
Swap positions, or assign arguments by name instead of by position,
and I would expect this example to work.  Probably, you've spotted
this already.  Details are in  help("boot").

And, a matrix is also a vector, so perhaps f1() can return a matrix
without causing any problems.  If not, use

f2 <- function(nxm.matrix, i)  as.vector(f1(nxm.matrix[i, ]))

The confidence intervals will require a separate call to boot.ci()
for each entry in the matrix, changing the value of boot.ci(index= )
each time.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 2 Apr 2003, Katalin  Csillery wrote:

> Dear All,
>
> I have a function which takes a n x m matrix as an argument and returns
> an n x n matrix. I want to take bootstrap samples form the input matrix
> in the way as each row represent a multivariate observation, so each
> bootstrap sample would be an n x m matrix, and on each sample I want to
> calculate the n x n matrix.
>
> f1 <- function(nxm.matrix){...; return(nxn.matrix)}
> f2 <- function(nxm.matrix, i) f1(nxm.matrix[i,])
> boot.out <- boot(nxm.matrix, R, f2)
> Error: incorrect number of subscripts on matrix
>
> Since the final goal would be to put a confidence interval on the
> statistics in each cell of the matrix I would like to use the boot.ci.
> Even if I do the resampling with the sample function and I just use the
> boot.ci by artificially putting togethet an boot.out type of list I run
> into problems. Any idea how to set it up?
>
> Katalin Csillery
> Division of Biological Sciences
> University of Montana, Missoula MT 59801
> Phone: 406 243 6106, E-mail: csillery at selway.umt.edu
> ----------------------------------------------------


From arrayprofile at yahoo.com  Fri Apr  4 01:37:03 2003
From: arrayprofile at yahoo.com (array chip)
Date: Thu, 3 Apr 2003 15:37:03 -0800 (PST)
Subject: [R] Re: point-biserial correlation
In-Reply-To: <200304030728.48490.noel@univ-lille3.fr>
Message-ID: <20030403233703.79803.qmail@web41206.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030403/40baeff9/attachment.pl

From arrayprofile at yahoo.com  Fri Apr  4 01:40:02 2003
From: arrayprofile at yahoo.com (array chip)
Date: Thu, 3 Apr 2003 15:40:02 -0800 (PST)
Subject: [R] Re: point-biserial correlation
In-Reply-To: <200304030728.48490.noel@univ-lille3.fr>
Message-ID: <20030403234002.72259.qmail@web41203.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030403/7634d491/attachment.pl

From chrysopa at insecta.ufv.br  Fri Apr  4 02:34:56 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Thu, 3 Apr 2003 21:34:56 -0300
Subject: [R] Trying to make a nested lme analysis
In-Reply-To: <6rr88jitvr.fsf@bates4.stat.wisc.edu>
References: <200303211119.21611.chrysopa@insecta.ufv.br>
	<6rr88jitvr.fsf@bates4.stat.wisc.edu>
Message-ID: <200304031422.06562.chrysopa@insecta.ufv.br>

Thanks,

it works:))

Inte
Ronaldo


ps. rats data and others used in book is in the Crawley home page:

http://www.bio.ic.ac.uk/research/mjcraw/statcomp/welcome.htm


Em Douglas Bates, escreveu:
> Where is the rats data available?
>
> It looks as if you have an lme model with both a fixed effect for
> Treatment and a random effect for Treatment.  I would guess that you
> want to have a fixed effect for treatment and random effects for
>
>  Rat %in% Treatment
>
> and
>
>  Liver %in% Rat %in% Treatment
>
> If so you would first create a factor for Rat %in% Treatment, say rTrT
> by
>
>  rats$rTrt = getGroups(~ 1 | Treatment/Rat, data = rats, level = 2)
>
> then fit the lme model as
>
>  lme(Glycogen ~ Treatment, data = rats, random = ~ 1|rTrT/Liver)
>
> "Ronaldo Reis Jr." <chrysopa at insecta.ufv.br> writes:
> > Hi,
> >
> > I'm trying to understand the lme output and procedure.
> > I'm using the Crawley's book.
> >
> > I'm try to analyse the rats example take from Sokal and Rohlf (1995).
> > I make a nested analysis using aov following the book.
> >
> > > summary(rats)
> >
> >     Glycogen       Treatment      Rat          Liver
> >  Min.   :125.0   Min.   :1   Min.   :1.0   Min.   :1
> >  1st Qu.:135.8   1st Qu.:1   1st Qu.:1.0   1st Qu.:1
> >  Median :141.0   Median :2   Median :1.5   Median :2
> >  Mean   :142.2   Mean   :2   Mean   :1.5   Mean   :2
> >  3rd Qu.:150.0   3rd Qu.:3   3rd Qu.:2.0   3rd Qu.:3
> >  Max.   :162.0   Max.   :3   Max.   :2.0   Max.   :3
> >
> > > attach(rats)
> > > Treatment <- factor(Treatment)
> > > Rat <- factor(Rat)
> > > Liver <- factor(Liver)
> > >
> > > model <- aov(Glycogen~Treatment/Rat/Liver+Error(Treatment/Rat/Liver))
> > > summary(model)
> >
> > Error: Treatment
> >           Df  Sum Sq Mean Sq
> > Treatment  2 1557.56  778.78
> >
> > Error: Treatment:Rat
> >               Df Sum Sq Mean Sq
> > Treatment:Rat  3 797.67  265.89
> >
> > Error: Treatment:Rat:Liver
> >                     Df Sum Sq Mean Sq
> > Treatment:Rat:Liver 12  594.0    49.5
> >
> > Error: Within
> >           Df Sum Sq Mean Sq F value Pr(>F)
> > Residuals 18 381.00   21.17
> >
> >
> > OK,
> >
> > Then I try to make this analysis using lme.
> >
> > > model <- lme(Glycogen~Treatment, random=~1|Treatment/Rat/Liver)
> > > summary(model)
> >
> > Linear mixed-effects model fit by REML
> >  Data: NULL
> >        AIC      BIC    logLik
> >   233.6213 244.0968 -109.8106
> >
> > Random effects:
> >  Formula: ~1 | Treatment
> >         (Intercept)
> > StdDev:    3.541272
> >
> >  Formula: ~1 | Rat %in% Treatment
> >         (Intercept)
> > StdDev:     6.00658
> >
> >  Formula: ~1 | Liver %in% Rat %in% Treatment
> >         (Intercept) Residual
> > StdDev:    3.764883 4.600247
> >
> > Fixed effects: Glycogen ~ Treatment
> > Error in if (any(wchLv <- (as.double(levels(xtTab[, wchPval])) == 0))) {
> > : missing value where logical needed
> > In addition: Warning message:
> > NaNs produced in: pt(q, df, lower.tail, log.p)
> >
> >
> > The random effects are correct, the variance component is OK:
> >
> > In nested aov | In nested lme
> > Residual
> > 21.1666       | 21.16227
> > Liver in Rats
> > 14.16667      | 14.17434
> > Rats in Treatment
> > 36.0648       | 36.079
> >
> > But I not understand why the Fixed effects error?
> >
> > What is the problem in my formula to make this analysis using lme?
> >
> > Thanks for all
> > Inte
> > Ronaldo
> > --
> > Anger kills as surely as the other vices.
> > --
> >
> > |   // | \\   [*****************************][*******************]
> > |
> > || ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
> > |
> > |      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
> > |
> > ||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
> > |
> > |  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
> > |
> > ||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
> > |
> > |/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
> > |
> > ||  ( `-  )   [*****************************][*******************]
> > ||
> > ||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
	O muito torna-se pouco com desejar um pouco mais.
		-- Francisco de Quevedo 
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From doug_browning at hotmail.com  Fri Apr  4 03:55:17 2003
From: doug_browning at hotmail.com (Doug Browning)
Date: Thu, 03 Apr 2003 17:55:17 -0800
Subject: [R] R Users
Message-ID: <F66S566uh2ueNjPSFwU00001f25@hotmail.com>

I have been introduced to "R" in the last few weeks. I have been in contact 
with Fritz at the main website. One of the issues I am looking into is the 
amount of users that are involved with open source products. Fritz was able 
to give me some information with regard to the downloads of R from the 
website but he said he was not sure at all as to how many users there were 
regarding "R".

Does anybody have an opinion as to approximately how many actual users of 
"R" exist out there in the open source community?  I am also interested to 
find out how many actual users there are out there for the Linux operating 
system if anybody happens to know.


_______________________________
Doug Browning
doug_browning at hotmail.com
425-313-0331


From whitep at fern.dsto.defence.gov.au  Fri Apr  4 04:40:41 2003
From: whitep at fern.dsto.defence.gov.au (Paul White)
Date: Fri, 4 Apr 2003 12:40:41 +1000
Subject: [R] advice on anlysing the spacing of growth rings
Message-ID: <20030404124041.A672@fern.dsto.defence.gov.au>

Hello,

I have an image of a fatigue crack that I want to analyse. It is simular 
to a photograph of the cross section of a (non-circular) tree showing the 
tree rings that indicate the growth of the tree. I would like to determine 
the spacing of the repeated growth patterns without actually picking off 
individual points (there are too many). Could someone give me an 
indication of how I could tackle this. It may be similar to a geographical 
mapping approach. Can anyone recommand any R packages that I should look 
at ?

Thanks
Paul

Paul White
Defence Science and Technology Organisation
Department of Defence
Melbourne, Australia


From gisar at nus.edu.sg  Fri Apr  4 05:58:03 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Fri, 4 Apr 2003 11:58:03 +0800
Subject: [R] Combining the components of a character vector
Message-ID: <024D6AEFCB92CB47BA1085751D184BB801053FA0@MBXSRV03.stf.nus.edu.sg>

Yes there is. 

> x <- c("Bob", "loves", "Sally")
> paste(x, collapse=" ")
[1] "Bob loves Sally"



-----Original Message-----
From: John Miyamoto [mailto:jmiyamot at u.washington.edu] 
Sent: Thursday, April 03, 2003 7:54 AM
To: R discussion group
Subject: [R] Combining the components of a character vector

Dear Help,
   Suppose I have a character vector.

x <- c("Bob", "loves", "Sally")

I want to combine it into a single string:  "Bob loves Sally" .
paste(x) yields:
paste(x)
[1] "Bob"   "loves" "Sally"

The following function combines the character vector into a string in
the
way that I want, but it seems somewhat inelegant.

paste.vector <- function(x, ...) {
	output <- NULL
	for (i in 1:length(x)) output <- paste(output, x[i], ...)
	output	} #end of function definition

paste.vector(x)
[1] " Bob loves Sally"

Is there a more natural (no loop) way to do this in R?

John Miyamoto

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
Homepage http://faculty.washington.edu/jmiyamot/
--------------------------------------------------------------------

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Alexander.Herr at csiro.au  Fri Apr  4 08:04:30 2003
From: Alexander.Herr at csiro.au (Alexander.Herr@csiro.au)
Date: Fri, 4 Apr 2003 16:04:30 +1000 
Subject: [R] trellis.graphic in for-loop
Message-ID: <2FE6D3D02CCDD211B80600902745F56C018D129E@exchange-tv.tvl.qld.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030404/95fce483/attachment.pl

From dougbrowning1 at attbi.com  Fri Apr  4 08:31:27 2003
From: dougbrowning1 at attbi.com (Doug)
Date: Thu, 3 Apr 2003 22:31:27 -0800
Subject: [R] R Users
Message-ID: <001001c2fa73$d2ffaeb0$4f95e60c@doug>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030403/a6e4f1a3/attachment.pl

From sqbabs824269 at hotmail.com  Fri Apr  4 09:21:54 2003
From: sqbabs824269 at hotmail.com (Julia)
Date: Fri, 4 Apr 2003 08:21:54 +0100
Subject: [R] Fwd: APRIL FOOL PRANK
Message-ID: <E191LWo-0002mI-00@bernie.ethz.ch>

=============APRIL FOOLS PRANK==============


==New Features==

# Voice recognition! (live feedback from victims response).
# 17 Different pranks to play on your mates.
# Call back feature (call back your victim if they hang up).
# Listen in to the prank as your victim is wound up.


INSTRUCTIONS:

1 Dial 0906 664 1901  (Dial 09067 380 080 for the original service)
2 Select the prank 
3 Enter your victims phone number
4 Listen to their reaction as the computer dials out to them!



Calls to 09067 380 080 cost one pound per minute. Calls to 0906 664 1901 cost one pound and fifty pence per minute. Service provider: TPX 0871 872 3731. This email was sent from outside the UK. You are not on any distribution list which is controlled by the service provider. Promotion code: fynsi


From dray at biomserv.univ-lyon1.fr  Fri Apr  4 09:22:46 2003
From: dray at biomserv.univ-lyon1.fr (Stephane Dray)
Date: Fri, 4 Apr 2003 09:22:46 +0200
Subject: [R]
In-Reply-To: <200304031102.57958.tamir@imp.univie.ac.at>
References: <5.1.1.6.0.20030401234126.02b28a70@unix.mail.virginia.edu>
 <200304031102.57958.tamir@imp.univie.ac.at>
Message-ID: <a05010400bab2e31b9364@[134.214.32.69]>

>On Wednesday 02 Apr 2003 6:43 am, Yongde Bao wrote:
>>  Can someone point out for me where to find a package to do principal
>>  component analysis for Affy data, if existing?
>
>http://www.stat.uni-muenchen.de/~strimmer/rexpress.html
>
>mva, multiv

See also the function dui.pca of the ade4 package.

Sincerely.
-- 
St?phane DRAY
---------------------------------------------------------------
Biom?trie et Biologie ?volutive - Equipe "?cologie Statistique"
Universite Lyon 1 - Bat 711 - 69622 Villeurbanne CEDEX - France

Tel : 04 72 43 27 56			   Fax : 04 78 89 27 19
       04 72 43 27 57 	   E-mail : dray at biomserv.univ-lyon1.fr 
---------------------------------------------------------------
Web                            http://www.steph280.freesurf.fr/
---------------------------------------------------------------


From kris.nackaerts at agr.kuleuven.ac.be  Fri Apr  4 10:01:23 2003
From: kris.nackaerts at agr.kuleuven.ac.be (Kris Nackaerts)
Date: Fri, 04 Apr 2003 10:01:23 +0200
Subject: [R] R on AIX RISC-6000
Message-ID: <3E8D3BD3.2010507@agr.kuleuven.ac.be>

Dear,

has anyone experience compiling R on a cluster of RISC-6000 systems (IBM 
Scalable Parallel System) with the xlc compiler (version 5)? We 
discovered we can use such a system at our university and have some 
processing time problems on Linux and Windows systems (running at 1.8 
Ghz an analysis takes us 20 hours for running approx. 2.000.000 logistic 
regressions).

Regards,

Kris

-- 
------------------------------------------------------------------------
 
 http://perswww.kuleuven.ac.be/~u0027178/VCard/mycard.php?name=krisn
 
------------------------------------------------------------------------
 Minds are like parachutes, they only work when open


From jerome at hivnet.ubc.ca  Fri Apr  4 10:02:08 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Fri, 4 Apr 2003 00:02:08 -0800
Subject: [R] Two y-axis in plots
In-Reply-To: <002001c2f9cf$44cd58d0$e5bed781@UNIVERSIVLBV7X>
References: <002001c2f9cf$44cd58d0$e5bed781@UNIVERSIVLBV7X>
Message-ID: <200304040807.AAA23383@hivnet.ubc.ca>


See the axis() function.

x <- rnorm(20)
y<- rnorm(20)
plot(x,y)
axis(4,at=-3:3,labels=(-3:3)*10)
axis(3,at=-3:3,labels=letters[1:7])

You may want to also consider plot(x,y,xaxt="n",yaxt="n") to suppress the 
x and y axes which you can rebuild with axis() to fit your purpose. See 
also the help file on par() for all kinds graphicals arguments. E.g., you 
may have to reset your margins with the "mai" options if you need enough 
space to include a label on the right axis.

Jerome

On April 3, 2003 02:53 am, Allan McRae wrote:
> Hi,
>
> I am trying to plot two data sets on one plot but with using a different
> y-axis ranges for each - preferably with one shown on each side of the
> graph.
>
> Is there a function that will allow me to do this.
>
> Thanks
>
> Allan McRae
> 	[[alternate HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From JonesW at kssg.com  Fri Apr  4 10:07:06 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Fri, 4 Apr 2003 09:07:06 +0100 
Subject: [R] NA handling with time series objects
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB01EE210D@GIMLI>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030404/e4a7af9e/attachment.pl

From ernesto at ipimar.pt  Fri Apr  4 11:19:54 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 04 Apr 2003 10:19:54 +0100
Subject: [R] How to organize/develop an R function
Message-ID: <1049447994.27483.11.camel@gandalf.ipimar.pt>

Hi

Maybe this is not an issue about R. It's probably a programming issue and I am not a developer at all. Anyway my main developing activities are in R and that's where I have difficulties.

When I develop a function or group of functions I lose eternities with the objects attributes and classes. I do a lot of object manipulation (lists to arrays, factors to numeric vectors, etc, etc) so that I can group data and apply the proper calculations/models to the proper data combination.

Then comes debugging and hell comes on earth. The objects names are unconsistent, the objects classes are not correct so methods work differently, etc.

My question is about programming good pratices in R. Does anyone know about documents (others than R manuals and MASS) ? Do you use some project management software that help on the function structure ? Do you have any ideas ? How do you (the R gurus) develop your packages ?

Thanks

EJ


-- 
Ernesto Jardim <ernesto at ipimar.pt>
Marine Biologist
IPIMAR - National Research Institute for Agriculture and Fisheries
Av. Brasilia, 1400-006
Lisboa, Portugal
Tel: +351 213 027 000
Fax: +351 213 015 948
http://ernesto.freezope.org


From dray at biomserv.univ-lyon1.fr  Fri Apr  4 11:33:16 2003
From: dray at biomserv.univ-lyon1.fr (Stephane Dray)
Date: Fri, 4 Apr 2003 11:33:16 +0200
Subject: [R] cdf function: inverse to quantile?
In-Reply-To: <36A25802686476479FBE08B99D1C111C0F3C4B@exdkba023.novo.dk>
References: <36A25802686476479FBE08B99D1C111C0F3C4B@exdkba023.novo.dk>
Message-ID: <a05010400bab301b7be1d@[134.214.32.69]>

>Is there a function in R for calculating empirical cumulative distribution
>functions, i.e. the inverse of the quantile function? Perhaps in some
>library? I'd hate to have to re-invent the wheel.

see ecdf in the stepfun package
-- 
St?phane DRAY
---------------------------------------------------------------
Biom?trie et Biologie ?volutive - Equipe "?cologie Statistique"
Universite Lyon 1 - Bat 711 - 69622 Villeurbanne CEDEX - France

Tel : 04 72 43 27 56			   Fax : 04 78 89 27 19
       04 72 43 27 57 	   E-mail : dray at biomserv.univ-lyon1.fr 
---------------------------------------------------------------
Web                            http://www.steph280.freesurf.fr/
---------------------------------------------------------------


From gavin.simpson at ucl.ac.uk  Fri Apr  4 11:45:31 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 4 Apr 2003 10:45:31 +0100
Subject: [R] ts function
In-Reply-To: <3E8C18D8.484E5C9D@biozentrum.uni-wuerzburg.de>
Message-ID: <000d01c2fa8e$ef19ca20$4c202880@gsimpson>

Hi Martin,

I guess you didn't get to Chapter 9 or the Preface ;-)

Yes, you need some further commands.  Get the files from:

http://www.uea.ac.uk/~gj/tsbook.html

The two commands you are having trouble with are both part of the commands
written by the authors for the book.  These are not packaged nicely in a
package that you can load with library().  Instead, you need to get the
files from the web site and then use source to read them into the working
environment.

Hope it helps,

Gavin

%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Martin Wegmann
Sent: 03 April 2003 12:20
To: R-help
Subject: [R] ts function


hello

I read "Practical Time Series" (Gareth Janacek; 2001) and they presented
e.g the
smoothing functions msmooth(x,k) or the bivariate function
crosscorr(x,y,k),
but both didn't work on my machine.  I only load the ts library, is
another
library necessary or did this function change since 2001? Is there a
more recent and detailed manual for ts?

thanks, cheers Martin


--
Martin Wegmann
Department of Animal Ecology and Tropical Biology
Zoology III, Biocenter
Am Hubland
97074 W?rzburg
Germany
0931/888-4378
wegmann at biozentrum.uni-wuerzburg.de
m.wegmann at web.de


From noel at univ-lille3.fr  Fri Apr  4 13:42:29 2003
From: noel at univ-lille3.fr (Noel Yvonnick)
Date: Fri, 4 Apr 2003 11:42:29 +0000
Subject: [R] Re: point-biserial correlation
In-Reply-To: <20030403233703.79803.qmail@web41206.mail.yahoo.com>
References: <20030403233703.79803.qmail@web41206.mail.yahoo.com>
Message-ID: <200304041142.29146.noel@univ-lille3.fr>

John,

> Thanks for sharing the code to the R community. I am new to biserial 
correlation, and had just tried your code for the following data:
> > cor.biserial(as.factor(c(0,1,0,0,0,1,1,0,1,1,1)), c(1.2, 4.5, 0.97, 1.02,
> > 1.4,3.8,3.97,1.23,3.78,4.23,4.76))
>
> $rbis:
>          0
>  -1.233783
>
> $rhobis:
>         0
>  0.378785
> $z:
>          0
>  -3.257211
> $alpha:
>             0
>  0.0005625642
> $N:
> [1] 11
>
>
>  Is it possible to have a biserial correlation greater than 1 or less than
> -1? I undrestand that normal correlation like Pearson should be between -1
> and 1. And if biserial correlation can be beyond the boundary, then how big
> can be seen as a good correlation? Since if we use Pearson correlation,
> people can usually claim above 0.8 will be a good correlation though it's
> arbitrary.

The biserial correlation includes a correction that assumes that the 
dichotomous variable is a discretization of some latent normally distributed 
variable. Of course, any departure from this assumption may result in 
meaningless correction and values outside [-1;1] may be observed.

As to what a "good" correlation is, you should not judge of it by reference to 
some a priori fixed value, as it depends upon sample size. Look at the 
p-value.


Yvonnick Noel, PhD.
U. of Lille 3
FRANCE


From koller at isis.wu-wien.ac.at  Fri Apr  4 13:19:32 2003
From: koller at isis.wu-wien.ac.at (Wolfgang Koller)
Date: Fri, 04 Apr 2003 13:19:32 +0200
Subject: [R] biplot
Message-ID: <3.0.6.32.20030404131932.00926bc0@isis.wu-wien.ac.at>

Dear list,

 I want to perform a biplot, using customized titels for the x and y axis.
Setting xlab="" and ylab="" resulted in an error, e.g.:

> data(USArrests)
> biplot(princomp(USArrests),xlab="",ylab="")
Error in biplot.default(t(t(scores[, choices])/lam), t(t(x$loadings[,  : 
        length of dimnames[1] not equal to array extent
> 

How do I proceed?

Thanks in advance!

Wolfgang Koller


-------------------------------------------------
Wolfgang Koller,  wolfgang.koller at wu-wien.ac.at
Forschungsinstitut f?r Europafragen
Wirtschaftsuniversit?t Wien
Althanstra?e 39-45, 1090 Vienna, Austria
Tel: ++43/1/31336/4147  Fax: ++43/1/31336/758
http://fgr.wu-wien.ac.at/institut/ef/ief-home.htm
-------------------------------------------------


From petr.pikal at precheza.cz  Fri Apr  4 13:22:21 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 04 Apr 2003 13:22:21 +0200
Subject: [R] cdf function: inverse to quantile?
In-Reply-To: <36A25802686476479FBE08B99D1C111C0F3C4B@exdkba023.novo.dk>
Message-ID: <3E8D870D.13035.135A483@localhost>

Hi

On 3 Apr 2003 at 13:20, DED (David George Edwards) wrote:

> Is there a function in R for calculating empirical cumulative
> distribution functions, i.e. the inverse of the quantile function?
> Perhaps in some library? I'd hate to have to re-invent the wheel.

try tu use search provided with the installation
in my case

D:\programy\R\rw1061\doc\html\search\SearchEngine.html

result

ecdf in Hmisc and stepfun libraries.

Cheers



> 
> 
> David Edwards, Biostatistics, 
> Novo Nordisk A/S, Bagsv?rd, Denmark.
> DEd at novonordisk.com <mailto:DEd at novonordisk.com> 
> Tlf: +45 44 42 62 35. Fax: +45 44 42 14 80
> 
> 
>  [[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz


From jarrod.hadfield at imperial.ac.uk  Fri Apr  4 15:19:30 2003
From: jarrod.hadfield at imperial.ac.uk (Jarrod Hadfield)
Date: Fri, 4 Apr 2003 14:19:30 +0100
Subject: [R] nlme and variance-covariance matrices.
Message-ID: <a05100304bab33678324d@[129.31.3.147]>


-- 
Dear R users,

I have data on around 2000 birds from 3 generations for which I know 
an individual's pedigree (i.e. the relationship it shares with other 
individuals e.g brother, uncle, mother) and also a pedigree based on 
foster-families, because half broods were removed from their nest of 
origin and placed in a foster parent's nest.

 From this I want to model two types of random effects.  The first are 
additive genetic effects (Va) and the variance-covariance matrix 
associated with these are nearly always positive-definite and will 
look something like the following:

  1   0   0  0.5   0
  0   1   0  0.5   0
  0   0   1   0    0
0.5 0.5  0   1   0.25
  0   0   0  0.25   1

The elements basically correspond to the proportion of genes shared 
by any two individuals.

The second matrix will model additive maternal effects (Vm) and the 
variance-covariance matrix associated with these effects will usually 
not be positive definite as shown below.

1   1    0    0   0.5
1   1    0    0    0
0   0    1    1    0
0   0    1    1    0
0.5 0    0    0    1

The elements here correspond to the proportion of genes shared by the 
(foster) parents of the two individuals.  In this case 2 individuals 
raised in the same nest that fail to breed in subsequent years will 
have identical variance-covariance elements (row 3&4).

The structure of the random effects for the model will then be:


Va  0
  0  Vm

or possibly,

    Va     Cov(a,m)
Cov(m,a)     Vm


I am quite new to both mixed effect models and R so would like to 
know if it is possible to specify specific variance covariance 
structures and whether non-positive-definite matrices can be used.

Many thanks

Jarrod Hadfield.


From matthew_wiener at merck.com  Fri Apr  4 15:36:17 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Fri, 04 Apr 2003 08:36:17 -0500
Subject: [R] cdf function: inverse to quantile?
Message-ID: <AEBD81486231A343B1813FE62D3352250131781D@usrymx15.merck.com>

Take a look at ecdf in package stepfun.

-----Original Message-----
From: DED (David George Edwards) [mailto:ded at novonordisk.com] 
Sent: Thursday, April 03, 2003 6:20 AM
To: 'r-help at stat.math.ethz.ch'
Subject: [R] cdf function: inverse to quantile?


Is there a function in R for calculating empirical cumulative distribution
functions, i.e. the inverse of the quantile function? Perhaps in some
library? I'd hate to have to re-invent the wheel.


David Edwards, Biostatistics, 
Novo Nordisk A/S, Bagsv?rd, Denmark.
DEd at novonordisk.com <mailto:DEd at novonordisk.com> 
Tlf: +45 44 42 62 35. Fax: +45 44 42 14 80


	[[alternate HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------


From tblackw at umich.edu  Fri Apr  4 15:54:46 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 4 Apr 2003 08:54:46 -0500 (EST)
Subject: [R] cdf function: inverse to quantile?
In-Reply-To: <36A25802686476479FBE08B99D1C111C0F3C4B@exdkba023.novo.dk>
Message-ID: <Pine.SOL.4.44.0304040853090.13007-100000@timepilot.gpcc.itd.umich.edu>

library(stepfun) help(ecdf)

... although there's not a great deal involved in re-inventing it.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 3 Apr 2003, DED (David George Edwards) wrote:

> Is there a function in R for calculating empirical cumulative distribution
> functions, i.e. the inverse of the quantile function? Perhaps in some
> library? I'd hate to have to re-invent the wheel.
>
> David Edwards, Biostatistics,
> Novo Nordisk A/S, Bagsvrd, Denmark.
> DEd at novonordisk.com <mailto:DEd at novonordisk.com>
> Tlf: +45 44 42 62 35. Fax: +45 44 42 14 80


From j.logsdon at lancaster.ac.uk  Fri Apr  4 16:06:19 2003
From: j.logsdon at lancaster.ac.uk (j.logsdon@lancaster.ac.uk)
Date: Fri, 4 Apr 2003 15:06:19 +0100 (GMT)
Subject: [R] hypatia problems?
Message-ID: <Pine.LNX.4.10.10304041450530.6086-100000@mercury.quantex>

Dear all

Off topic to some extent but Ted Harding has just called me to say he is

(a) seeing large delays in the list messages when it is sent internally
from hypatia.math.ethz.ch. I get only a delay of an hour which is
reasonable in the scrap below but Ted reports delays of the order 24
hours,

(b) messages he has sent to the list don't appear on it for a long time.

Is anyone else experiencing such difficulties?

TIA

John

Received: from hypatia.math.ethz.ch (mailman at hypatia [129.132.58.23])
        by hypatia.math.ethz.ch (8.12.9/8.12.6) with ESMTP id
h34DDGfm022344;
        Fri, 4 Apr 2003 15:13:29 +0200 (MEST)
                        ^^^^^^^^^^^^^^^^^^^^^
Received: from eyre.southern.net.au (eyre.southern.net.au
[202.182.64.147])
        by hypatia.math.ethz.ch (8.12.9/8.12.6) with ESMTP id
h33CLFfl025858
        for <r-help at stat.math.ethz.ch>; Thu, 3 Apr 2003 14:21:16 +0200
(MEST)
                                                        ^^^^^^^^^^^^^^


From tblackw at umich.edu  Fri Apr  4 16:39:08 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 4 Apr 2003 09:39:08 -0500 (EST)
Subject: [R] Two y-axis in plots
In-Reply-To: <002001c2f9cf$44cd58d0$e5bed781@UNIVERSIVLBV7X>
Message-ID: <Pine.SOL.4.44.0304040919180.13007-100000@timepilot.gpcc.itd.umich.edu>

Allan  -

Nothing canned, as far as I know.  For a single plot,
use  plot(),  then  points(), axis(4, ...).  See the
help pages for each one.  Wehn plotting the second
data set using points, you will need to shift and
scale the vertical coordinate yourself, to the scale
of the first dataset, and do the same for axis().

Here's a somewhat cooked example.

data.x <- c(1:50)
data.y <- exp(rnorm(50))
data.p <- rank(data.y) / 50  #  percentiles

plot(data.x, data.y, pch="+")
temp <- range(data.y)
points(data.x,    temp[1] + (temp[2] - temp[1]) * data.p, pch=20)
axis(side=4, at = temp[1] + (temp[2] - temp[1]) * c(0:5) / 5, labels = c(0:5) / 5)

What's cooked here is that I know by construction that
data.p lies in 0 to 1, therefore I don't have
to do a more complicated shift and scaling to get the
second data set into the vertical scale of the first.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 3 Apr 2003, Allan McRae wrote:

> I am trying to plot two data sets on one plot but with using a different y-axis ranges for each - preferably with one shown on each side of the graph.
>
> Is there a function that will allow me to do this.
>
> Thanks
>
> Allan McRae


From spencer.graves at pdf.com  Fri Apr  4 16:41:00 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 04 Apr 2003 06:41:00 -0800
Subject: [R] Two y-axis in plots
References: <002001c2f9cf$44cd58d0$e5bed781@UNIVERSIVLBV7X>
Message-ID: <3E8D997C.2010907@pdf.com>

Have you considered "plot" with "axes" and "points" or "lines"?

"?plot" provides examples using "points" and "lines";  "?axes" should 
fill in the gap.

Spencer Graves

Allan McRae wrote:
> Hi,
> 
> I am trying to plot two data sets on one plot but with using a different y-axis ranges for each - preferably with one shown on each side of the graph.
> 
> Is there a function that will allow me to do this.
> 
> Thanks
> 
> Allan McRae
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tlumley at u.washington.edu  Fri Apr  4 16:51:02 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 4 Apr 2003 06:51:02 -0800 (PST)
Subject: [R] Combining the components of a character vector
In-Reply-To: <200304031227.h33CR9Vb004057@thorin.ci.tuwien.ac.at>
Message-ID: <Pine.A41.4.44.0304040648180.199144-100000@homer04.u.washington.edu>

> On Thursday 03 April 2003 01:54, John Miyamoto wrote:

<snippage>

> > The following function combines the character vector into a string
> > in the way that I want, but it seems somewhat inelegant.
> >
> > paste.vector <- function(x, ...) {
> > 	output <- NULL
> > 	for (i in 1:length(x)) output <- paste(output, x[i], ...)
> > 	output	} #end of function definition
> >
> > paste.vector(x)
> > [1] " Bob loves Sally"
> >
> > Is there a more natural (no loop) way to do this in R?

I might also take this opportunity to note that if paste() didn't have the
collapse=  argument there would still be more elegant way to write the
loop

   do.call("paste",as.list(x))

creates a call to paste() whose arguments are the elements of x.


	-thomas


From otoomet at econ.dk  Fri Apr  4 16:06:12 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Fri, 4 Apr 2003 16:06:12 +0200
Subject: [R] Two y-axis in plots
In-Reply-To: <002001c2f9cf$44cd58d0$e5bed781@UNIVERSIVLBV7X>
	(s0238397@sms.ed.ac.uk)
References: <002001c2f9cf$44cd58d0$e5bed781@UNIVERSIVLBV7X>
Message-ID: <200304041406.h34E6Ch03802@punik.econ.au.dk>

Hi,

 | From: "Allan McRae" <s0238397 at sms.ed.ac.uk>
 | Date: Thu, 3 Apr 2003 11:53:32 +0100
 | 
 | Hi,
 | 
 | I am trying to plot two data sets on one plot but with
 | using a different y-axis ranges for each - preferably with one shown on each side of the graph.

This is a common question, you may try to search the mail archives.
There is no ready-made function in any of the common packages.
There may be some more-or-less suitable function either in the mailing
list or somewhere in the less common packages.

Basically what you have to do is to rescale your data, plot on the
same graph and draw a new axis using axis().

> plot(data1)
> newdata2 <- ... #rescale your data2 into the same range as data1
> lines(data2) # or points()
> a3ticks <- pretty(data2)
> newa3dticks <- ... # here rescale the a3 ticks in the same way
> axis(3, at=newa3ticks, labels=a3ticks) # e.g. new location but old
>					 # labels.

Perhaps it helps.

Ott


From Ted.Harding at nessie.mcc.ac.uk  Fri Apr  4 17:54:59 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 04 Apr 2003 16:54:59 +0100 (BST)
Subject: [R] hypatia problems?
Message-ID: <XFMail.030404165459.Ted.Harding@nessie.mcc.ac.uk>

Just found John Logsdon's posting (copied below) on the R-help
archives (for which thanks, John). For comparison with what he
put up below (about 1 hour delay), following that is what I'm
getting at the moment (26 hours delay and increasingly steadily:
was 13 hours yesterday evening).

Just wondering if there's something about mailing to my account
which may be causing delay (but the admins at mcc.ac.uk assure
me there's no problem at their end). If anyone else is experiencing
similar problem (though in that case heaven knows when you'll get
this one) it would be useful to hear fron you (direct, please,
and not via the list!).
======================================
> From j.logsdon at lancaster.ac.uk:
> Dear all
> 
> Off topic to some extent but Ted Harding has just called me to say he is
> 
> (a) seeing large delays in the list messages when it is sent internally
> from hypatia.math.ethz.ch. I get only a delay of an hour which is
> reasonable in the scrap below but Ted reports delays of the order 24
> hours,
> 
> (b) messages he has sent to the list don't appear on it for a long time.
> 
> Is anyone else experiencing such difficulties?
> 
> TIA
> 
> John
> 
> Received: from hypatia.math.ethz.ch (mailman at hypatia [129.132.58.23])
>   by hypatia.math.ethz.ch (8.12.9/8.12.6) with ESMTP id
>   h34DDGfm022344;
>   Fri, 4 Apr 2003 15:13:29 +0200 (MEST)
>   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> Received: from eyre.southern.net.au (eyre.southern.net.au
>   [202.182.64.147]) by hypatia.math.ethz.ch (8.12.9/8.12.6) with
>   ESMTP id h33CLFfl025858 for <r-help at stat.math.ethz.ch>;
>   Thu, 3 Apr 2003 14:21:16 +0200 (MEST)
>   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
=========================================
By contrast, from a message from r-help just received by me:

  Received: from hypatia.math.ethz.ch (mailman at hypatia [129.132.58.23]) by
   hypatia.math.ethz.ch (8.12.9/8.12.6) with ESMTP id h34FXHg0022987;
   Fri, 4 Apr 2003 17:35:46 +0200 (MEST)
   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  Received: from usryws02.merck.com (taz.merck.com [155.91.6.20]) by
   hypatia.math.ethz.ch (8.12.9/8.12.6) with SMTP id h33DVIfl010695 for
   <r-help at stat.math.ethz.ch>;
   Thu, 3 Apr 2003 15:31:18 +0200 (MEST)
   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

[26 hours delay]

Thanks, apologies for OT[ish], and best wishes to all.

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 04-Apr-03                                       Time: 16:54:59
------------------------------ XFMail ------------------------------


From spencer.graves at pdf.com  Fri Apr  4 18:08:50 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 04 Apr 2003 08:08:50 -0800
Subject: [R] Na handing with time series objects
References: <6B5A9304046AD411BD0200508BDFB6CB01EE2105@GIMLI>
Message-ID: <3E8DAE12.5050205@pdf.com>

I don't know of software, but the math is outlined in the "Foundations 
of Monitoring" material on "www.prodsyse.com".  If you don't get an 
acceptable answer otherwise, I can at least find S-Plus code I used to 
generate some of the examples described therein.

Spencer Graves

Wayne Jones wrote:
> Hello All, 
> 
> Does anyone out there know a way to decompose time series objects with
> missing values. 
> A simple "na.omit" will not work since it does not preserve the time
> differences between succesive observations. 
> 
> Thanks in advance, 
> 
> Wayne
> 
> 
> 
> Dr Wayne R. Jones
> Statistician / Research Analyst
> KSS Group plc
> St James's Buildings
> 79 Oxford Street
> Manchester M1 6SS
> Tel: +44(0)161 609 4084
> Mob: +44(0)7810 523 713
> 
> 
> 
> KSS Ltd
> A division of Knowledge Support Systems Group plc
> Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1 6SS  England
> Company Registration Number 2800886 (Limited) 3449594 (plc)
> Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com		http://www.kssg.com
> 
> 
> The information in this Internet email is confidential and may b... {{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From maechler at stat.math.ethz.ch  Fri Apr  4 18:09:27 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 4 Apr 2003 18:09:27 +0200
Subject: [R] cdf function: inverse to quantile?
In-Reply-To: <36A25802686476479FBE08B99D1C111C0F3C4B@exdkba023.novo.dk>
References: <36A25802686476479FBE08B99D1C111C0F3C4B@exdkba023.novo.dk>
Message-ID: <16013.44599.230902.589245@gargle.gargle.HOWL>

>>>>> "Ded" == Ded (David George Edwards) <ded at novonordisk.com>
>>>>>     on Thu, 3 Apr 2003 13:20:25 +0200  writes:

    Ded> Is there a function in R for calculating empirical
    Ded> cumulative distribution functions, i.e. the inverse of
    Ded> the quantile function? Perhaps in some library?

Yes: in the `stepfun' package 
     (and already re-invented in other places)

(( "package" {in R; and  "library section" in other S implementations}))

    Ded> I'd hate to have to re-invent the wheel.

good idea ;-)

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From f0z6305 at labs.tamu.edu  Fri Apr  4 18:28:25 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Fri, 4 Apr 2003 10:28:25 -0600
Subject: [R] How to use PCURVE to estimate 2-D principal curves?
Message-ID: <006001c2fac7$3735e4f0$8bd75ba5@IE.TAMU.EDU>

Hey, Rlisters.

Does anybody know how to use the package "PCURVE" to estimate a
2-Dimensional principal curve?

My 2-D data x is stored as a .txt file, looks as following:
xx xx
xx xx
...
xx xx

So how to write the command to get the principal curve?

Thanks for your point.

Fred


From spencer.graves at pdf.com  Fri Apr  4 18:34:55 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 04 Apr 2003 08:34:55 -0800
Subject: [R] How to organize/develop an R function
References: <1049381009.1333.25.camel@gandalf.ipimar.pt>
Message-ID: <3E8DB42F.7070306@pdf.com>

	  1.  Have you read Venables and Ripley's two books, "Modern Applied 
Statistics with S" (now in its 4th edition) and "S Programming"? 
Especially the latter book could help in this regard.

	  2.  Which version of R are you using, under which operating system? 
With R 1.6.2 under Windows 2000, I can copy a "*.r" file into a new 
directory, double click, and have R open an empty ".RData" file in that 
directory.  This is can be helpful for identifying globals that you 
thought were local to a particular function (e.g., misspelled variable 
names).

Hope this helps.
Spencer Graves

Ernesto Jardim wrote:
> Hi
> 
> Maybe this is not an issue about R. It's probably a programming issue
> and I am not a developer at all. Anyway my main developing activities
> are in R and that's where I have difficulties.
> 
> When I develop a function or group of functions I lose eternities with
> the objects attributes and classes. I do a lot of object manipulation
> (lists to arrays, factors to numeric vectors, etc, etc) so that I can
> group data and apply the proper calculations/models to the proper data
> combination.
> 
> Some times I get lost or need debugging and hell comes on earth. The
> objects names are unconsistent, the objects classes are not correct so
> methods work differently, etc.
> 
> My question is about programming good pratices in R. Does anyone know
> about documents ? Do you use some project management software that help
> on the function structure ? Do you have any ideas ? How do you (the R
> gurus) develop your packages ?
> 
> Thanks
> 
> EJ
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From maechler at stat.math.ethz.ch  Fri Apr  4 19:02:21 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 4 Apr 2003 19:02:21 +0200
Subject: [R] Re: ... Outbound e-mail slow from R servers ...
In-Reply-To: <16012.25340.851344.274158@gargle.gargle.HOWL>
References: <3E8C5224.9090109@medanalytics.com>
	<16012.25340.851344.274158@gargle.gargle.HOWL>
Message-ID: <16013.47773.515024.538268@gargle.gargle.HOWL>

About a day ago, I wrote
to R-devel (and Marc) :

>>>>> "MM" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Thu, 3 Apr 2003 18:36:12 +0200 writes:

  >>>>> "Marc" == Marc Schwartz <mschwartz at medanalytics.com>
  >>>>>     on Thu, 03 Apr 2003 09:24:20 -0600 writes:

      Marc> Martin,

      Marc> Not sure if you are aware of this, but since yesterday
      Marc> there seems to be multi-hour delays in outbound e-mail
      Marc> from r-help and r-devel.  Inbound mail seems to show
      Marc> up on the archive OK.

      Marc> I am just now getting posts from late yesterday my
      Marc> time.  My post to r-devel on RH9 yesterday morning did
      Marc> not show up back to me until last night (my time).

      Marc> HTH,

    MM> Indeed that helped a bit, particularly since I'm in a
    MM> two day course today and tomorrow and haven't had time
    MM> to look closely.

    MM> What happened is that the mailman software has
    MM> occasionally been producing too long delays (of e.g.,
    MM> half an hour, even for R-core with 17 addresses!), for
    MM> quite a few weeks now -- which it didn't several weeks
    MM> ago.  The first thing I was advised to try was to revert
    MM> the mailman and sendmail settings to their defaults --
    MM> which I had done yesterday.  Additionally, yesterday a
    MM> big part of ETH had severe network problems during noon
    MM> time -- hence it wasn't too easy to find out which
    MM> timeouts where caused by what.

    MM> I have now re-reverted the mailman settings to what they
    MM> were before yesterday, and will start tackling the
    MM> "only" halfhour delays (which I think come from the
    MM> different qrunner setup that mailman 2.1.x is using --
    MM> which is active since about March 4).

    MM> Thanks for adverting me!

and the really bad thing that happened was that I had somehow
managed to almost stop mailman delivery ... 
I have restarted and things seem to got working much better
about an hour ago, and I've received many list mails myself
since  -- most delayed for more than a day...
I'm very sorry about that and hope it hasn't caused too much grief.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


PS: This still applies:

    MM> BTW: If anyone has time for writing a small perl or
    MM> python script that automatically retrieves the mailman
    MM> delay from the two "Received:" headers in each message
    MM> that contain "hypatia" -- I'd be quite grateful..


From spencer.graves at pdf.com  Fri Apr  4 19:19:56 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 04 Apr 2003 09:19:56 -0800
Subject: [R] Time to distribute replies to "r-help" 
Message-ID: <3E8DBEBC.5050507@pdf.com>

	  There appears to be a problem with the cycle time to distribe replies 
to "r-help":  My reply (copied below) was submitted at 4/3/2003 8:26 AM, 
some 4.5 hours after the original post.  In those 4.5 hours, some 12 
others had submitted public replies.  However, none of those 12 had 
arrived at my computer before I filed mine.  My reply came back to me 
some 24.5 hours after I posted it.

	  Perhaps this problem has already corrected itself.  If not, I hope 
that someone who knows how to arrange for correction of this kind of 
problem will initiate effective corrective action.  (Our colleagues at 
the Eidgenoesche Technische Hochschule Zuerich may be suffering from too 
much success.)

Best Wishes,
Spencer Graves

Spencer Graves wrote:
 > paste( c("Bob", "loves", "Sally"), collapse=" ")
 >
 > Spencer Graves
 >
 > John Miyamoto wrote:
 >
 >> Dear Help,
 >>    Suppose I have a character vector.
 >>
 >> x <- c("Bob", "loves", "Sally")
 >>
 >> I want to combine it into a single string:  "Bob loves Sally" .
 >> paste(x) yields:
 >> paste(x)
 >> [1] "Bob"   "loves" "Sally"
 >>
 >> The following function combines the character vector into a string 
in the
 >> way that I want, but it seems somewhat inelegant.
 >>
 >> paste.vector <- function(x, ...) {
 >>     output <- NULL
 >>     for (i in 1:length(x)) output <- paste(output, x[i], ...)
 >>     output    } #end of function definition
 >>
 >> paste.vector(x)
 >> [1] " Bob loves Sally"
 >>
 >> Is there a more natural (no loop) way to do this in R?
 >>
 >> John Miyamoto
 >>
 >> --------------------------------------------------------------------
 >> John Miyamoto, Dept. of Psychology, Box 351525
 >> University of Washington, Seattle, WA 98195-1525
 >> Phone 206-543-0805, Fax 206-685-3157, Email jmiyamot at u.washington.edu
 >> Homepage http://faculty.washington.edu/jmiyamot/
 >> --------------------------------------------------------------------
 >>
 >> ______________________________________________
 >> R-help at stat.math.ethz.ch mailing list
 >> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
 >
 >
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From david.meyer at ci.tuwien.ac.at  Fri Apr  4 19:59:04 2003
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Fri, 04 Apr 2003 19:59:04 +0200
Subject: [R] SVM module: scaling data applied to new test set without
	using  SVMagain
References: <OF1BA8628B.F3061D9D-ONC1256CFD.003FA6DF@imtek.uni-freiburg.de>
Message-ID: <3E8DC7E8.C0CCDAAA@ci.tuwien.ac.at>

seidel at micro-biolytics.com wrote:
> 
> Hello!
> 
> We are new in  using R.  We use the SVM module from the library 'e1071'
> for training.
> 
> Problem formulation:
> 
> a classification has been performed using SVM module (linear kernel).
> Later, a new data set (test set) comparable to the training data shall be
> scaled in the same way  as the training set (using the same scaling
> parameter set, but without using the SVM again to save time). We found the
> scaling matrices, but we do not know, how to apply them.

[note: in the `x.scale' element of the fitted model]

> 
> How must the scaling parameter matrices (scaled:center and scaled:scale)
> be applied to the test data set to receive the same scaling as it would
> have been done by the SVM module?

the function `scale' has two parameters: `center' and `scale'.
So, you could do sth. like:

scale(newdata, 
      center = model$x.scale$"scaled:center", 
      scale = model$x.scale$"scaled:scale")

best,
	
David

> 
> Thanx very much in advance!
>         [[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
        Mag. David Meyer            Wiedner Hauptstrasse 8-10
Vienna University of Technology     A-1040 Vienna/AUSTRIA
         Department of              Tel.: (+431) 58801/10772
Statistics and Probability Theory   Fax.: (+431) 58801/10798


From spencer.graves at pdf.com  Fri Apr  4 20:11:41 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 04 Apr 2003 10:11:41 -0800
Subject: [R] Hypatia
References: <XFMail.030403212212.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <3E8DCADD.5030203@pdf.com>

Hi, Ted:

Thanks.  This is one of many cases where poor quality may cost more than 
high quality:  It requires roughly 60 time as much space to store a 13+ 
hour queue than a 13 minute queue.

Best Wishes,
Spencer Graves

(Ted Harding) wrote:
> It seems that hypatia.math.ethz.ch is hoarding messages
> to the r-help list for up to 13 hours ... ?
> 
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 167 1972
> Date: 03-Apr-03                                       Time: 21:22:12
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From sundar.dorai-raj at pdf.com  Fri Apr  4 20:41:25 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri, 04 Apr 2003 12:41:25 -0600
Subject: [R] Printing zero as dot
References: <200304032154.h33LsCX7009631@definetti.uark.edu>
Message-ID: <3E8DD1D5.2050400@pdf.com>


Giovanni Petris wrote:
> I'm pretty sure I've seen some examples of a function printing zero
> entries in a matrix as dots, but I'm not able to find it now...
> Any suggestions...? Thanks in advance. (Of course, I might have dreamt
> of such a function...) 
> 
> Best,
> Giovanni
> 

I just so have something that may help:

print.matrix2 <- function(x, zero = ".", ...) {
   zeros <- which(x == 0, arr.ind = TRUE)
   x[zeros] <- zero
   print(x, quote = FALSE, right = TRUE, ...)
   invisible()
}

 > print.matrix2(diag(5))
      [,1] [,2] [,3] [,4] [,5]
[1,]    1    .    .    .    .
[2,]    .    1    .    .    .
[3,]    .    .    1    .    .
[4,]    .    .    .    1    .
[5,]    .    .    .    .    1
 >

Sundar


From rpeng at stat.ucla.edu  Fri Apr  4 21:03:52 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri, 4 Apr 2003 11:03:52 -0800 (PST)
Subject: [R] trellis.graphic in for-loop
In-Reply-To: <2FE6D3D02CCDD211B80600902745F56C018D129E@exchange-tv.tvl.qld.csiro.au>
Message-ID: <Pine.GSO.4.10.10304041103040.4857-100000@quetelet.stat.ucla.edu>

Trellis graphics need to be print()-ed for them to show on the device.  I
think if you wrap your call to barchart() with print(), it should work as
you expect.

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Fri, 4 Apr 2003, Alexander.Herr at csiro.au wrote:

> Hi list,
> 
> I am unsuccessfully trying to produce a serious of trellis barcharts from
> within a for-loop. The barcharts work outside the loop. What am I missing?
> Example attached.
> 
> Thanks Herry
> 
> #XXXXXXXXXXXXXXXXXXXXXX
> 
> 
> trellis.device(bg="white")
> trellis.par.get("fontsize")->fontsize
> fontsize$default<-16
> trellis.par.set("fontsize",fontsize)
> 
> a<-c(1,2,4,5,4,3,3,3)
> b<-c(2,5,1,1,1,3,3,3)
> c<-c(3,5,1,2,2,5,5,5)
> as.data.frame(cbind(a,b,c))->q21
> varnames<-colnames(q21)
> i<-9999
> for (i in 1:3) {
> round(table(q21[,i])/sum(table(q21[,i])),3)*100->z1
>  as.data.frame.table(table(q21[,i]))->z1
>   round(z1[,2]/sum(z1[,2]),3)*100->z1[,2]
>    colnames(z1)<-c(varnames[i],"y")
>    xnames<-levels(z1[,1])
>     paste(xnames[1]," - low",sep="")->xnames[1]
>      paste(xnames[length(xnames)]," - high",sep="")->xnames[length(xnames)]
>   z1[,1]<-xnames
>  as.factor(z1[,1])->z1[,1]
> barchart(
>   horizontal=FALSE,
>    z1[,2]~z1[,1],
>     ylab=list("% frequency",cex=1.5),
>      main=list(varnames[i],cex=1.25),
>     scales=list(1,cex=1.5), col="#ffd18f",
>    sub=list("Rating",cex=1.25)
>         )
> filename<-paste("test",i,"_q21k.jpg",sep="")
> #dev.print(jpeg, filename , width=1000, height=1000, quality=100,
> bg="white", pointsize=20)
> }
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From spencer.graves at pdf.com  Fri Apr  4 21:06:34 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 04 Apr 2003 11:06:34 -0800
Subject: [R] message
References: <1049450377.27483.14.camel@gandalf.ipimar.pt>
Message-ID: <3E8DD7BA.2060200@pdf.com>

r-help has recently experienced delays exceeding 24 hours.  Some 
progress has been made in diagnosis, but I don't know about the fix.

Spencer Graves

Ernesto Jardim wrote:
> Hi 
> 
> This is a test message. I've tried to send some messages that never got
> throught. I'm just checking what's wrong.
> 
> Sorry and don't bother answering.
> 
> EJ
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From p.dalgaard at biostat.ku.dk  Fri Apr  4 21:18:46 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 04 Apr 2003 21:18:46 +0200
Subject: [R] Hypatia
In-Reply-To: <3E8DCADD.5030203@pdf.com>
References: <XFMail.030403212212.Ted.Harding@nessie.mcc.ac.uk>
	<3E8DCADD.5030203@pdf.com>
Message-ID: <x2he9evzop.fsf@biostat.ku.dk>

Spencer Graves <spencer.graves at pdf.com> writes:

> Thanks.  This is one of many cases where poor quality may cost more
> than high quality:  It requires roughly 60 time as much space to store
> a 13+ hour queue than a 13 minute queue.

Not to mention the fact that shorter queues will keep people from
replying to something that was already answered. I think current
r-help subscribers are unlikely to forget about paste(x, collapse=" ")
for a while.... 

The queue would appear to be clearing now.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From deepayan at stat.wisc.edu  Fri Apr  4 21:26:05 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 4 Apr 2003 13:26:05 -0600
Subject: [R] trellis.graphic in for-loop
In-Reply-To: <2FE6D3D02CCDD211B80600902745F56C018D129E@exchange-tv.tvl.qld.csiro.au>
References: <2FE6D3D02CCDD211B80600902745F56C018D129E@exchange-tv.tvl.qld.csiro.au>
Message-ID: <200304041326.05520.deepayan@stat.wisc.edu>

On Friday 04 April 2003 12:04 am, Alexander.Herr at csiro.au wrote:
> Hi list,
>
> I am unsuccessfully trying to produce a serious of trellis barcharts from
> within a for-loop. The barcharts work outside the loop. What am I missing?

An explicit print() outside the barchart call. The result of barchart is a 
"trellis" object, which needs to be printed for anything to be plotted.

Deepayan


From kwan022 at stat.auckland.ac.nz  Fri Apr  4 22:25:07 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sat, 5 Apr 2003 08:25:07 +1200 (NZST)
Subject: [R] How to organize/develop an R function
In-Reply-To: <3E8DB42F.7070306@pdf.com>
Message-ID: <Pine.LNX.4.33.0304050824190.8571-100000@stat56.stat.auckland.ac.nz>

Hi,

On Fri, 4 Apr 2003, Spencer Graves wrote:

> 	  1.  Have you read Venables and Ripley's two books, "Modern Applied 
> Statistics with S" (now in its 4th edition) and "S Programming"? 
> Especially the latter book could help in this regard.

Another good one is John Chambers's Programming with Data, aka the Green 
Book.

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From pavlicov at stat.ohio-state.edu  Fri Apr  4 21:38:32 2003
From: pavlicov at stat.ohio-state.edu (Martina Pavlicova)
Date: Fri, 4 Apr 2003 14:38:32 -0500 (EST)
Subject: [R] trellis.graphic in for-loop
In-Reply-To: <2FE6D3D02CCDD211B80600902745F56C018D129E@exchange-tv.tvl.qld.csiro.au>
Message-ID: <Pine.SOL.4.33.0304041437170.3895-100000@spatial.stat.ohio-state.edu>


HI,

try to use 'print.trellis()'

Martina
-----------------------------
see:

library(lattice)
trellis.device(bg="white")
trellis.par.get("fontsize")->fontsize
fontsize$default<-16
trellis.par.set("fontsize",fontsize)

a<-c(1,2,4,5,4,3,3,3)
b<-c(2,5,1,1,1,3,3,3)
c<-c(3,5,1,2,2,5,5,5)
as.data.frame(cbind(a,b,c))->q21
varnames<-colnames(q21)
i<-9999
for (i in 1:3) {
  round(table(q21[,i])/sum(table(q21[,i])),3)*100->z1
  as.data.frame.table(table(q21[,i]))->z1
  round(z1[,2]/sum(z1[,2]),3)*100->z1[,2]
  colnames(z1)<-c(varnames[i],"y")
  xnames<-levels(z1[,1])
  paste(xnames[1]," - low",sep="")->xnames[1]
  paste(xnames[length(xnames)]," - high",sep="")->xnames[length(xnames)]
  z1[,1]<-xnames
  as.factor(z1[,1])->z1[,1]
  print.trellis(barchart(
           horizontal=FALSE,
           z1[,2]~z1[,1],
           ylab=list("% frequency",cex=1.5),
           main=list(varnames[i],cex=1.25),
           scales=list(1,cex=1.5), col="#ffd18f",
           sub=list("Rating",cex=1.25)
           ))
  filename<-paste("test",i,"_q21k.jpg",sep="")
                                        #dev.print(jpeg, filename ,
width=1000, height=1000, quality=100, bg="white", pointsize=20)
}


--------------------------------------------------------------------------
Department of Statistics             Office Phone: (614) 292-1567
1958 Neil Avenue, 304E Cockins Hall  FAX: (614) 292-2096
The Ohio State University            E-mail: pavlicov at stat.ohio-state.edu
Columbus, OH 43210-1247              www.stat.ohio-state.edu/~pavlicov


On Fri, 4 Apr 2003 Alexander.Herr at csiro.au wrote:

> Hi list,
>
> I am unsuccessfully trying to produce a serious of trellis barcharts from
> within a for-loop. The barcharts work outside the loop. What am I missing?
> Example attached.
>
> Thanks Herry
>
> #XXXXXXXXXXXXXXXXXXXXXX
>
>
> trellis.device(bg="white")
> trellis.par.get("fontsize")->fontsize
> fontsize$default<-16
> trellis.par.set("fontsize",fontsize)
>
> a<-c(1,2,4,5,4,3,3,3)
> b<-c(2,5,1,1,1,3,3,3)
> c<-c(3,5,1,2,2,5,5,5)
> as.data.frame(cbind(a,b,c))->q21
> varnames<-colnames(q21)
> i<-9999
> for (i in 1:3) {
> round(table(q21[,i])/sum(table(q21[,i])),3)*100->z1
>  as.data.frame.table(table(q21[,i]))->z1
>   round(z1[,2]/sum(z1[,2]),3)*100->z1[,2]
>    colnames(z1)<-c(varnames[i],"y")
>    xnames<-levels(z1[,1])
>     paste(xnames[1]," - low",sep="")->xnames[1]
>      paste(xnames[length(xnames)]," - high",sep="")->xnames[length(xnames)]
>   z1[,1]<-xnames
>  as.factor(z1[,1])->z1[,1]
> barchart(
>   horizontal=FALSE,
>    z1[,2]~z1[,1],
>     ylab=list("% frequency",cex=1.5),
>      main=list(varnames[i],cex=1.25),
>     scales=list(1,cex=1.5), col="#ffd18f",
>    sub=list("Rating",cex=1.25)
>         )
> filename<-paste("test",i,"_q21k.jpg",sep="")
> #dev.print(jpeg, filename , width=1000, height=1000, quality=100,
> bg="white", pointsize=20)
> }
>
>
> 	[[alternate HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From kwan022 at stat.auckland.ac.nz  Fri Apr  4 23:01:13 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sat, 5 Apr 2003 09:01:13 +1200 (NZST)
Subject: [R] Sampling from a Data Frame
Message-ID: <Pine.LNX.4.33.0304050900010.8713-100000@stat56.stat.auckland.ac.nz>

Hi,

I've been looking through the documentation for sample(), but can only get 
it to work with vectors.  Is it possible to sample from a dataframe?

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From ccleland at optonline.net  Fri Apr  4 22:24:06 2003
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 04 Apr 2003 15:24:06 -0500
Subject: [R] Sampling from a Data Frame
In-Reply-To: 
 <Pine.LNX.4.33.0304050900010.8713-100000@stat56.stat.auckland.ac.nz>
References: <Pine.LNX.4.33.0304050900010.8713-100000@stat56.stat.auckland.ac.nz>
Message-ID: <3E8DE9E6.4020505@optonline.net>

Ko-Kang Kevin Wang wrote:
> I've been looking through the documentation for sample(), but can only get 
> it to work with vectors.  Is it possible to sample from a dataframe?

Do you want to sample rows from a single dataframe?  How about 
something like this where 10 is the number of rows sampled:

mydata[sample(dim(mydata)[1], 10),]

hope it helps,

Chuck Cleland


From spencer.graves at pdf.com  Fri Apr  4 22:30:51 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 04 Apr 2003 12:30:51 -0800
Subject: [R] Sampling from a Data Frame
References: <Pine.LNX.4.33.0304050900010.8713-100000@stat56.stat.auckland.ac.nz>
Message-ID: <3E8DEB7B.3070906@pdf.com>

What do you want?

The following selects 3 rows at random from DataFrame:

	DataFrame <- data.frame(x=1:9, y=rnorm(9))
	DataFrame[sample(dim(DataFrame)[1], 3, replace=TRUE), ]

Spencer Graves

Ko-Kang Kevin Wang wrote:
> Hi,
> 
> I've been looking through the documentation for sample(), but can only get 
> it to work with vectors.  Is it possible to sample from a dataframe?
>


From murdoch at stats.uwo.ca  Fri Apr  4 22:33:40 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 04 Apr 2003 15:33:40 -0500
Subject: [R] Calling Fortran routines
In-Reply-To: <A1B373D68745D31180D100A0244BB400019F2FDF@nagmail.nag.co.uk>
References: <A1B373D68745D31180D100A0244BB400019F2FDF@nagmail.nag.co.uk>
Message-ID: <uiqr8vgmug1cb4sdml5dealrd3sst04o9t@4ax.com>

On Thu, 3 Apr 2003 11:14:55 +0100 , you wrote in message
<A1B373D68745D31180D100A0244BB400019F2FDF at nagmail.nag.co.uk>:


>PS: I am using R version 1.6.2, under windows 2000 (professional), and the
>Fortran code is compiled into a Windows 32bit DLL using Compaq Visual
>Fortran Professional, edition 6.1.0

I don't know that compiler at all, but the usual cause of crashes like
this is using incompatible calling conventions.  The usual calling
convention for a DLL in Windows is "stdcall", but R uses "cdecl";
since I didn't see anything mentioned in your source, I think you were
probably using "stdcall".

Hopefully your documentation will tell you how to ask for "cdecl".

Once you find this, could you please email me a short paragraph saying
in detail what to do with your compiler?  I'm putting together a web
page showing what's necessary in various cases.   My current
incomplete draft is visible here: 

 <http://www.stats.uwo.ca/faculty/murdoch/software/compilingDLLs>

Duncan Murdoch


From partha_bagchi at hgsi.com  Fri Apr  4 22:54:40 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Fri, 4 Apr 2003 15:54:40 -0500
Subject: [R] Hypatia
Message-ID: <OF98F3D7C2.D61DF7B7-ON85256CFE.0072D019-85256CFE.0072DE2A@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030404/1026f48f/attachment.pl

From brahm at alum.mit.edu  Fri Apr  4 23:23:26 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Fri, 4 Apr 2003 16:23:26 -0500
Subject: [R] Matrix eigenvectors in R and MatLab
References: <000001c2f9f1$84ca9a20$3d9aee82@uu.se.vaxtbio>
Message-ID: <16013.63438.79519.834830@arbprod.fmr.com>

Mikael Niva <mikael.niva at ebc.uu.se> wrote:
> Is there anyone who knows why I get different eigenvectors when I run
> MatLab and R?

R orders the eigenvalues by absolute value, which seems sensible; the MatLab
eigenvalues you gave do not seem to be in any particular order.

R does not normalize the eigenvectors (as MatLab does), but you can easily do
so yourself:

R> PA9900<-c(11/24 ,10/53 ,0/1 ,0/1 ,29/43 ,1/24 ,27/53 ,0/1 ,0/1 ,13/43
R>   ,14/24 ,178/53 ,146/244 ,17/23 ,15/43 ,2/24 ,4/53 ,0/1 ,2/23 ,2/43 ,4/24
R>   ,58/53 ,26/244 ,0/1 ,5/43)
R> PA9900<-matrix(PA9900,nrow=5,byrow=T)
R> eig <- eigen(PA9900)

R> eig$values   # Note they are in descending order of absolute value:
[1]  1.2352970  0.3901522 -0.2562860  0.2259411  0.1742592

R> sweep(eig$vectors, 2, sqrt(colSums(eig$vectors^2)), "/")
            [,1]         [,2]        [,3]        [,4]        [,5]
[1,] -0.22500913 -0.499825704 -0.43295788 -0.18537961 -0.17952679
[2,] -0.10826756  0.159919608 -0.17713941 -0.05825639 -0.06137926
[3,] -0.94030246 -0.845706299  0.71911349  0.97075584  0.96165016
[4,] -0.03271669 -0.096681499  0.07518268 -0.11595437 -0.17499009
[5,] -0.22893213  0.005790397  0.50832318  0.08017655  0.09279089


This is the same as the MatLab result you gave, except for 2 things:

1) The column order matches the eigenvalue order, so R's columns are in a
   different order than Matlab's.

2) The sign is different for one of the vectors (my column 3, your 2).  The
   sign of an eigenvector is not well defined, even after normalization.

MatLab> wmat =
MatLab>    -0.2250    0.4330   -0.4998   -0.1795   -0.1854
MatLab>    -0.1083    0.1771    0.1599   -0.0614   -0.0583
MatLab>    -0.9403   -0.7191   -0.8457    0.9617    0.9708
MatLab>    -0.0327   -0.0752   -0.0967   -0.1750   -0.1160
MatLab>    -0.2289   -0.5083    0.0058    0.0928    0.0802
MatLab> 
MatLab> dmat =
MatLab>     1.2353         0         0         0         0
MatLab>          0   -0.2563         0         0         0
MatLab>          0         0    0.3902         0         0
MatLab>          0         0         0    0.1743         0
MatLab>          0         0         0         0    0.2259

   Side note: there is some relation between eigenvectors and svd (singular
value decomposition) which I have not fully grokked yet; if anyone has a simple
explanation I'd be grateful.
-- 
                              -- David Brahm (brahm at alum.mit.edu)


From csillery at selway.umt.edu  Fri Apr  4 23:58:50 2003
From: csillery at selway.umt.edu (Katalin Csillery)
Date: Fri, 4 Apr 2003 14:58:50 -0700 (MST)
Subject: [R] Problems with Mac OS X Beta 3 display?
Message-ID: <Pine.OSF.4.21.0304041444340.19814-100000@selway.umt.edu>


Beyond a general problem with X11, that it sometimes doesn't display 
-especially when it is inactive for a while-  new windows (like new 
terminal, R device, or emacs) and only the restart helps, I found a       
problem which might also be especially the X11's problem.
   
>From an apple Terminal window, the following code (which is the first  
boot.ci example) works just fine.
     data(city)
     ratio <- function(d, w)
          sum(d$x * w)/sum(d$u * w)
     city.boot <- boot(city, ratio, R=999, stype="w",sim="ordinary")
     boot.ci(city.boot, conf=c(0.90,0.95),
          type=c("norm","basic","perc","bca"))
I get normally the four types of confidenec intervals.
   
But form apple X11 public Beta 0.3 I get the following error messages,

> library(boot)

Attaching package `boot':


        The following object(s) are masked _by_ .GlobalEnv :
         boot

> data(city)
> ratio <- function(d, w)  sum(d$x * w)/sum(d$u * w)
> city.boot <- boot(city, ratio, R=999, stype="w",sim="ordinary")
> boot.ci(city.boot, conf=c(0.90,0.95), type=c("norm","basic","perc","bca"))
[1] "odd number of coulumns"
     [,1]       [,2]
[1,] "95/1.074" "1.908/0.978"
Error in paste("(", ints1[, 2 * (1:n1)], ",", sep = "") :
        subscript out of bounds

Did anyone find the same behavior under X11? Any soultions? Or just that
is why it is still beta.

Thanks for any thoughts, suggestions!

Katalin


From Setzer.Woodrow at epamail.epa.gov  Sat Apr  5 00:05:59 2003
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow@epamail.epa.gov)
Date: Fri, 04 Apr 2003 17:05:59 -0500
Subject: [R] creating function bodies using body()
Message-ID: <OFD5A9F863.8E1E25FF-ON85256CFE.00785D4D@rtp.epa.gov>

I'm having trouble figuring out how to create a function using "body<-"
().  The help file for body() says that the argument should be a list of
R expressions.  However if I try that I get an error:

> tmpfun <- function(a, b=2){}
> body(tmpfun) <- list(expression(z <- a + b),expression(z^2))
Error in as.function.default(c(formals(f), value), envir) :
        invalid formal argument list for "function"

Can someone give me a simple example for doing this?  Thanks!

R. Woodrow Setzer, Jr.                        Phone: (919) 541-0128
Experimental Toxicology Division             Fax:  (919) 541-4284
Pharmacokinetics Branch
NHEERL B143-05; US EPA; RTP, NC 27711


From bates at stat.wisc.edu  Sat Apr  5 00:07:22 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 04 Apr 2003 16:07:22 -0600
Subject: [R] trellis.graphic in for-loop
In-Reply-To: <Pine.SOL.4.33.0304041437170.3895-100000@spatial.stat.ohio-state.edu>
References: <Pine.SOL.4.33.0304041437170.3895-100000@spatial.stat.ohio-state.edu>
Message-ID: <6ry92prk6d.fsf@bates4.stat.wisc.edu>

Martina Pavlicova <pavlicov at stat.ohio-state.edu> writes:

> HI,
> 
> try to use 'print.trellis()'
> 
> Martina

Actually the preferred approach is to use print(), not
print.trellis().  That is, call the generic function, not the specific
name of the method.  With namespaces, available in R-1.7.0 and later,
package authors have the option of hiding direct access to methods.
If Deepayan Sarkar added a namespace to the lattice package (and I
think he does plan to do that at some point) then using print() would
work as expected but using print.trellis() would no longer work.


From andy_liaw at merck.com  Sat Apr  5 00:23:11 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 04 Apr 2003 17:23:11 -0500
Subject: [R] creating function bodies using body()
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F943@usrymx25.merck.com>

This apparently worked:

> body(f) <- expression({x^2; x+3})
> f
function (x) 
{
    x^2
    x + 3
}

HTH,
Andy

> -----Original Message-----
> From: Setzer.Woodrow at epamail.epa.gov
> [mailto:Setzer.Woodrow at epamail.epa.gov]
> Sent: Friday, April 04, 2003 5:06 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] creating function bodies using body()
> 
> 
> I'm having trouble figuring out how to create a function 
> using "body<-"
> ().  The help file for body() says that the argument should 
> be a list of
> R expressions.  However if I try that I get an error:
> 
> > tmpfun <- function(a, b=2){}
> > body(tmpfun) <- list(expression(z <- a + b),expression(z^2))
> Error in as.function.default(c(formals(f), value), envir) :
>         invalid formal argument list for "function"
> 
> Can someone give me a simple example for doing this?  Thanks!
> 
> R. Woodrow Setzer, Jr.                        Phone: (919) 541-0128
> Experimental Toxicology Division             Fax:  (919) 541-4284
> Pharmacokinetics Branch
> NHEERL B143-05; US EPA; RTP, NC 27711
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------


From tblackw at umich.edu  Sat Apr  5 00:35:56 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 4 Apr 2003 17:35:56 -0500 (EST)
Subject: [R] creating function bodies using body()
In-Reply-To: <OFD5A9F863.8E1E25FF-ON85256CFE.00785D4D@rtp.epa.gov>
Message-ID: <Pine.SOL.4.44.0304041730001.13101-100000@mspacman.gpcc.itd.umich.edu>

Defining a function is much simpler than that:

tmpfun <- function(a, b=2)
 {  z <- a = b
    z^2         }    #  returns (a + b)^2

But maybe you want the advertised syntax to work.  Please
pardon if I've misjudged the depth of your question.  I've
never tried to use  body().

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 4 Apr 2003 Setzer.Woodrow at epamail.epa.gov wrote:

> I'm having trouble figuring out how to create a function using "body<-"
> ().  The help file for body() says that the argument should be a list of
> R expressions.  However if I try that I get an error:
>
> > tmpfun <- function(a, b=2){}
> > body(tmpfun) <- list(expression(z <- a + b),expression(z^2))
> Error in as.function.default(c(formals(f), value), envir) :
>         invalid formal argument list for "function"
>
> Can someone give me a simple example for doing this?  Thanks!
>
> R. Woodrow Setzer, Jr.                        Phone: (919) 541-0128
> Experimental Toxicology Division             Fax:  (919) 541-4284
> Pharmacokinetics Branch
> NHEERL B143-05; US EPA; RTP, NC 27711


From tblackw at umich.edu  Sat Apr  5 00:55:38 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 4 Apr 2003 17:55:38 -0500 (EST)
Subject: [R] biplot
In-Reply-To: <3.0.6.32.20030404131932.00926bc0@isis.wu-wien.ac.at>
Message-ID: <Pine.SOL.4.44.0304041750210.13101-100000@mspacman.gpcc.itd.umich.edu>

Wolfgang  -

Due to a name conflict with the other arguments to biplot()
named "xlabs" and "ylabs", you have to set those arguments
explicitly, in order to be able to set xlab="", ylab="" as
well.  The following command works for me:

biplot(princomp(USArrests), xlabs=dimnames(USArrests)[[1]],
  ylabs=dimnames(USArrests)[[2]], xlab="", ylab="")

This complication is unfortunate, but it's a consequence of
partial matching of argument names.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 4 Apr 2003, Wolfgang Koller wrote:

>  I want to perform a biplot, using customized titels for the x and y axis.
> Setting xlab="" and ylab="" resulted in an error, e.g.:
>
> > data(USArrests)
> > biplot(princomp(USArrests),xlab="",ylab="")
> Error in biplot.default(t(t(scores[, choices])/lam), t(t(x$loadings[,  :
>         length of dimnames[1] not equal to array extent
>
> -------------------------------------------------
> Wolfgang Koller,  wolfgang.koller at wu-wien.ac.at
> Forschungsinstitut fr Europafragen
> Wirtschaftsuniversitt Wien
> Althanstrae 39-45, 1090 Vienna, Austria
> Tel: ++43/1/31336/4147  Fax: ++43/1/31336/758
> http://fgr.wu-wien.ac.at/institut/ef/ief-home.htm
> -------------------------------------------------


From GPetris at uark.edu  Sat Apr  5 00:54:42 2003
From: GPetris at uark.edu (Giovanni Petris)
Date: Fri, 4 Apr 2003 16:54:42 -0600 (CST)
Subject: [R] Printing zero as dot
In-Reply-To: <200304032154.h33LsCX7009631@definetti.uark.edu> (message from
	Giovanni Petris on Thu, 03 Apr 2003 15:54:12 -0600 (CST))
References: <200304032154.h33LsCX7009631@definetti.uark.edu>
Message-ID: <200304042254.h34MsgMl010924@definetti.uark.edu>


Many thanks to J.R. Lockwood and to Sundar Dorai-Raj for sending me
their suggestions. I ended up using Sundar's function blended with a
flavour of `zapsmall':

print.matrix2 <- function(x, zero = ".", digits=getOption("digits"), ...) {
    if (all(ina <- is.na(x))) 
        return(x)
    if (length(digits) == 0) 
        stop("invalid digits")
    mx <- max(abs(x[!ina]))
    x <- round(x, digits = if (mx > 0) 
               max(0, digits - log10(mx))
    else digits)
    zeros <- which(x == 0, arr.ind = TRUE)
    x[zeros] <- zero
    print(x, quote = FALSE, right = TRUE, ...)
    invisible()
}

Have a good weekend,
Giovanni 


> 
> I'm pretty sure I've seen some examples of a function printing zero
> entries in a matrix as dots, but I'm not able to find it now...
> Any suggestions...? Thanks in advance. (Of course, I might have dreamt
> of such a function...) 
> 
> Best,
> Giovanni
> 

-- 

 __________________________________________________
[                                                  ]
[ Giovanni Petris                 GPetris at uark.edu ]
[ Department of Mathematical Sciences              ]
[ University of Arkansas - Fayetteville, AR 72701  ]
[ Ph: (479) 575-6324, 575-8630 (fax)               ]
[ http://definetti.uark.edu/~gpetris/              ]
[__________________________________________________]


From myao at ou.edu  Sat Apr  5 00:57:59 2003
From: myao at ou.edu (Minghua Yao)
Date: Fri, 04 Apr 2003 16:57:59 -0600
Subject: [R] sqlSave() Question
Message-ID: <HDEPJCAKDEJMEEHKJOKECEBNCAAA.myao@ou.edu>

All,

I am new in R. I found sqlSave() doesn't work for our Oracle9i. The
following was the message:

> sqlSave(channel, USArrests, rownames="state")
Error in sqlColumns(channel, tablename) : USArrests : table not found on
channel
Check case parameter in odbcConnect
>

sqlQuery() works OK.

Please help. Thanks.

-MY


From p.dalgaard at biostat.ku.dk  Sat Apr  5 01:24:49 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 05 Apr 2003 01:24:49 +0200
Subject: [R] creating function bodies using body()
In-Reply-To: <OFD5A9F863.8E1E25FF-ON85256CFE.00785D4D@rtp.epa.gov>
References: <OFD5A9F863.8E1E25FF-ON85256CFE.00785D4D@rtp.epa.gov>
Message-ID: <x2vfxtvoam.fsf@biostat.ku.dk>

Setzer.Woodrow at epamail.epa.gov writes:

> I'm having trouble figuring out how to create a function using "body<-"
> ().  The help file for body() says that the argument should be a list of
> R expressions.  However if I try that I get an error:
> 
> > tmpfun <- function(a, b=2){}
> > body(tmpfun) <- list(expression(z <- a + b),expression(z^2))
> Error in as.function.default(c(formals(f), value), envir) :
>         invalid formal argument list for "function"
> 
> Can someone give me a simple example for doing this?  Thanks!

Like this:

> tmpfun <- function(a, b=2){}
> body(tmpfun) <- quote({z <- a + b; z^2})
> tmpfun(3)
[1] 25

And yes, that help page could do with a rewrite...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From tblackw at umich.edu  Sat Apr  5 01:29:47 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 4 Apr 2003 18:29:47 -0500 (EST)
Subject: [R] Matrix eigenvectors in R and MatLab
In-Reply-To: <000001c2f9f1$84ca9a20$3d9aee82@uu.se.vaxtbio>
Message-ID: <Pine.SOL.4.44.0304041816010.13101-100000@mspacman.gpcc.itd.umich.edu>

Mikael  -

The matrix PA9900 is not a symmetric matrix.  Eigen() will
automatically detect this.  help("eigen") says explicitly:

"For `eigen( , symmetric = FALSE)' the choice of length of
the eigenvectors is not defined by LINPACK.  In all other
cases the vectors are normalized to unit length."

In the example you give, the eigenvectors from R are clearly
NOT normalized to unit length, while those from Matlab are.
Even after normalizing them, the R eigenvectors will differ
by order and sign from the Matlab ones.  (Compare R column 3
with Matlab column 2.)  Have to look at the EISPACK source
documentation to see whether it's returning right eigenvectors
or left eigenvectors for an asymmetric matix.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 3 Apr 2003, Mikael Niva wrote:

> Dear R-listers
>
> Is there anyone who knows why I get different eigenvectors when I run
> MatLab and R? I run both programs in Windows Me. Can I make R to produce
> the same vectors as MatLab?
>
> #R Matrix
> PA9900<-c(11/24 ,10/53 ,0/1 ,0/1 ,29/43 ,1/24 ,27/53 ,0/1 ,0/1 ,13/43
> ,14/24 ,178/53 ,146/244 ,17/23 ,15/43 ,2/24 ,4/53 ,0/1 ,2/23 ,2/43 ,4/24
> ,58/53 ,26/244 ,0/1 ,5/43)
>
> #R-syntax
> PA9900<-matrix(PA9900,nrow=5,byrow=T)
> eigen(PA9900)
>
> #R-output
> $values
> [1]  1.2352970  0.3901522 -0.2562860  0.2259411  0.1742592
>
> $vectors
>             [,1]        [,2]        [,3]      [,4]       [,5]
> [1,] -0.67795430 -1.70686496 -0.52613955 -8.675109 -0.8413826
> [2,] -0.32621100  0.54611272 -0.21526356 -2.726193 -0.2876643
> [3,] -2.83313878 -2.88801964  0.87388189 45.427935  4.5069361
> [4,] -0.09857565 -0.33015962  0.09136359 -5.426254 -0.8201206
> [5,] -0.68977432  0.01977374  0.61772506  3.751978  0.4348802
>
> %Matlab Matrix
> PA9900 =[11/24 10/53 0/1 0/1 29/43 ;1/24 27/53 0/1 0/1 13/43 ;14/24
> 178/53 146/244 17/23 15/43 ;2/24 4/53 0/1 2/23 2/43 ;4/24 58/53 26/244
> 0/1 5/43]
>
> %MatLab-syntax
> [wmat,dmat]=eig(mat)
>
> %MatLab-output
> wmat =
>    -0.2250    0.4330   -0.4998   -0.1795   -0.1854
>    -0.1083    0.1771    0.1599   -0.0614   -0.0583
>    -0.9403   -0.7191   -0.8457    0.9617    0.9708
>    -0.0327   -0.0752   -0.0967   -0.1750   -0.1160
>    -0.2289   -0.5083    0.0058    0.0928    0.0802
>
> dmat =
>     1.2353         0         0         0         0
>          0   -0.2563         0         0         0
>          0         0    0.3902         0         0
>          0         0         0    0.1743         0
>          0         0         0         0    0.2259
>
> Yours sincerely, Mikael Niva
>
> ********************************************
> Mikael Niva
> Avd. fr Vxtekologi, Dept. of Plant Ecology
> EvolutionsBiologiskt Centrum, Uppsala Universitet
> Villavgen 14
> 752 36 UPPSALA
> E-post Mikael.Niva at EBC.UU.SE
> Tel. +46 (0)18 471 28 65
> Fax +46 (0)18 55 34 19


From tlumley at u.washington.edu  Sat Apr  5 01:39:12 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 4 Apr 2003 15:39:12 -0800 (PST)
Subject: [R] Problems with Mac OS X Beta 3 display?
In-Reply-To: <Pine.OSF.4.21.0304041444340.19814-100000@selway.umt.edu>
Message-ID: <Pine.A41.4.44.0304041534340.121496-100000@homer40.u.washington.edu>

On Fri, 4 Apr 2003, Katalin  Csillery wrote:

> But form apple X11 public Beta 0.3 I get the following error messages,
>
> > library(boot)
>
> Attaching package `boot':
>
>
>         The following object(s) are masked _by_ .GlobalEnv :
>          boot


This message means that you have something called `boot' in your workspace
that will override the bootstrap function, and is probably causing the
error. In any case, it makes it very hard to diagnose the error.

I don't have any trouble with this example using version 0.2.1 of Apple's
X11 server, and since the example doesn't use any graphics it would be
surprising (though not completely impossible) for X11 to be the problem.

Try the example in a clean R workspace (if you are starting R from the
command line then type

	R --vanilla

to start R without loading any previous workspace.


	-thomas


From spencer.graves at pdf.com  Sat Apr  5 01:51:17 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 04 Apr 2003 15:51:17 -0800
Subject: [R] Matrix eigenvectors in R and MatLab
References: <Pine.SOL.4.44.0304041816010.13101-100000@mspacman.gpcc.itd.umich.edu>
Message-ID: <3E8E1A75.6020005@pdf.com>

Excellent analysis, Thomas.  An alternative to looking at EISPACK 
documentation is to do the following computations:

	(1) Values %*% diag(vectors) %*% solve(Values)

	(2) solve(Values) %*% diag(vectors) %*% Values

One of these two should return the original matrix; the other will 
likely be very different.  If so, the mystery is solved.  If (1) returns
PA9900, then

	PA9900 %*% Values = Values %*% diag(vectors)

Else

	Values %*% PA9900 = diag(vectors) %*% Values

Best Wishes,
Spencer Graves

Thomas W Blackwell wrote:
> Mikael  -
> 
> The matrix PA9900 is not a symmetric matrix.  Eigen() will
> automatically detect this.  help("eigen") says explicitly:
> 
> "For `eigen( , symmetric = FALSE)' the choice of length of
> the eigenvectors is not defined by LINPACK.  In all other
> cases the vectors are normalized to unit length."
> 
> In the example you give, the eigenvectors from R are clearly
> NOT normalized to unit length, while those from Matlab are.
> Even after normalizing them, the R eigenvectors will differ
> by order and sign from the Matlab ones.  (Compare R column 3
> with Matlab column 2.)  Have to look at the EISPACK source
> documentation to see whether it's returning right eigenvectors
> or left eigenvectors for an asymmetric matix.
> 
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> On Thu, 3 Apr 2003, Mikael Niva wrote:
> 
> 
>>Dear R-listers
>>
>>Is there anyone who knows why I get different eigenvectors when I run
>>MatLab and R? I run both programs in Windows Me. Can I make R to produce
>>the same vectors as MatLab?
>>
>>#R Matrix
>>PA9900<-c(11/24 ,10/53 ,0/1 ,0/1 ,29/43 ,1/24 ,27/53 ,0/1 ,0/1 ,13/43
>>,14/24 ,178/53 ,146/244 ,17/23 ,15/43 ,2/24 ,4/53 ,0/1 ,2/23 ,2/43 ,4/24
>>,58/53 ,26/244 ,0/1 ,5/43)
>>
>>#R-syntax
>>PA9900<-matrix(PA9900,nrow=5,byrow=T)
>>eigen(PA9900)
>>
>>#R-output
>>$values
>>[1]  1.2352970  0.3901522 -0.2562860  0.2259411  0.1742592
>>
>>$vectors
>>            [,1]        [,2]        [,3]      [,4]       [,5]
>>[1,] -0.67795430 -1.70686496 -0.52613955 -8.675109 -0.8413826
>>[2,] -0.32621100  0.54611272 -0.21526356 -2.726193 -0.2876643
>>[3,] -2.83313878 -2.88801964  0.87388189 45.427935  4.5069361
>>[4,] -0.09857565 -0.33015962  0.09136359 -5.426254 -0.8201206
>>[5,] -0.68977432  0.01977374  0.61772506  3.751978  0.4348802
>>
>>%Matlab Matrix
>>PA9900 =[11/24 10/53 0/1 0/1 29/43 ;1/24 27/53 0/1 0/1 13/43 ;14/24
>>178/53 146/244 17/23 15/43 ;2/24 4/53 0/1 2/23 2/43 ;4/24 58/53 26/244
>>0/1 5/43]
>>
>>%MatLab-syntax
>>[wmat,dmat]=eig(mat)
>>
>>%MatLab-output
>>wmat =
>>   -0.2250    0.4330   -0.4998   -0.1795   -0.1854
>>   -0.1083    0.1771    0.1599   -0.0614   -0.0583
>>   -0.9403   -0.7191   -0.8457    0.9617    0.9708
>>   -0.0327   -0.0752   -0.0967   -0.1750   -0.1160
>>   -0.2289   -0.5083    0.0058    0.0928    0.0802
>>
>>dmat =
>>    1.2353         0         0         0         0
>>         0   -0.2563         0         0         0
>>         0         0    0.3902         0         0
>>         0         0         0    0.1743         0
>>         0         0         0         0    0.2259
>>
>>Yours sincerely, Mikael Niva
>>
>>********************************************
>>Mikael Niva
>>Avd. f?r V?xtekologi, Dept. of Plant Ecology
>>EvolutionsBiologiskt Centrum, Uppsala Universitet
>>Villav?gen 14
>>752 36 UPPSALA
>>E-post Mikael.Niva at EBC.UU.SE
>>Tel. +46 (0)18 471 28 65
>>Fax +46 (0)18 55 34 19
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From gavin.simpson at ucl.ac.uk  Sat Apr  5 03:00:47 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Sat, 5 Apr 2003 02:00:47 +0100
Subject: [R]
In-Reply-To: <a05010400bab2e31b9364@[134.214.32.69]>
Message-ID: <003401c2fb0e$cb835150$4c202880@gsimpson>

or function rda() in package vegan for that matter [fitting rda without
constraints == pca]

Gavin

%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Stephane Dray
Sent: 04 April 2003 08:23
To: r-help at stat.math.ethz.ch
Subject: Re: [R]


>On Wednesday 02 Apr 2003 6:43 am, Yongde Bao wrote:
>>  Can someone point out for me where to find a package to do principal
>>  component analysis for Affy data, if existing?
>
>http://www.stat.uni-muenchen.de/~strimmer/rexpress.html
>
>mva, multiv

See also the function dui.pca of the ade4 package.

Sincerely.
-- 
St?phane DRAY
---------------------------------------------------------------
Biom?trie et Biologie ?volutive - Equipe "?cologie Statistique"
Universite Lyon 1 - Bat 711 - 69622 Villeurbanne CEDEX - France

Tel : 04 72 43 27 56			   Fax : 04 78 89 27 19
       04 72 43 27 57 	   E-mail : dray at biomserv.univ-lyon1.fr 
---------------------------------------------------------------
Web                            http://www.steph280.freesurf.fr/
---------------------------------------------------------------

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Sat Apr  5 08:28:45 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 5 Apr 2003 07:28:45 +0100 (BST)
Subject: [R] sqlSave() Question
In-Reply-To: <HDEPJCAKDEJMEEHKJOKECEBNCAAA.myao@ou.edu>
Message-ID: <Pine.LNX.4.44.0304050726050.8135-100000@gannet.stats>

On Fri, 4 Apr 2003, Minghua Yao wrote:

> I am new in R. I found sqlSave() doesn't work for our Oracle9i. The
> following was the message:
> 
> > sqlSave(channel, USArrests, rownames="state")
> Error in sqlColumns(channel, tablename) : USArrests : table not found on
> channel
> Check case parameter in odbcConnect
  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
It tells you what to do, so please do it!

Also, I trust you have read ?odbcConnect and understood what it says about
Oracle?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From fredrik.lundgren at norrkoping.mail.telia.com  Sat Apr  5 09:01:49 2003
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Sat, 5 Apr 2003 09:01:49 +0200
Subject: [R] slides in linux R
Message-ID: <001a01c2fb41$3b3b8e40$2d0ffea9@oemcomputer>

Hello,

In S-Plus Windows you can transform graphics to Powerpoint very easily, in R Windows you can use enhanced metafiles (.emf) and Powerpoint almost as easy. Is there a simular way with R in Linux to transform to the presentation program in StarOffice or OpenOffice or are you stuck with the pdf device?

Fredrik Lundgren


From tpapp at axelero.hu  Sat Apr  5 10:15:10 2003
From: tpapp at axelero.hu (Tamas Papp)
Date: Sat, 5 Apr 2003 10:15:10 +0200
Subject: [R] slides in linux R
In-Reply-To: <001a01c2fb41$3b3b8e40$2d0ffea9@oemcomputer>
References: <001a01c2fb41$3b3b8e40$2d0ffea9@oemcomputer>
Message-ID: <20030405081510.GA1590@localhost>

On Sat, Apr 05, 2003 at 09:01:49AM +0200, Fredrik Lundgren wrote:

> Hello,
> 
> In S-Plus Windows you can transform graphics to Powerpoint very
> easily, in R Windows you can use enhanced metafiles (.emf) and
> Powerpoint almost as easy. Is there a simular way with R in Linux to
> transform to the presentation program in StarOffice or OpenOffice or
> are you stuck with the pdf device?
> 
> Fredrik Lundgren

I recommend using LaTeX with the prosper class and the listings
package --- this generates beautiful slides which you can show using
Acrobat reader (Ghostscript won't handle cross references) on Windows
or Unix machines. Obviously, TeX has the advantage of typesetting
formulas beautifully, as opposed to *Office. 

Hope this example code below helps you get started, however:

1. make sure that you generate PS of PDF, since DVI won't show
anything,

2. if you like this method, please read the documentation of listings
and prosper.

---- cut here ----
\documentclass[slideColor, colorBG, autumn]{prosper}

\usepackage{listings}

\begin{document}

\lstset{language=R} % you could set colors and styles here

\title{Sample R Code}

\begin{slide}{Example from \lstinline!?c!}

  \begin{lstlisting}{}
    c(1,7:9)
    c(1:5, 10.5, "next")
  
    ## append to a list:
    ll <- list(A = 1, c="C")
    ## do *not*
    c(ll, d = 1:3) # which is == c(ll, as.list(c(d=1:3))
 
    ## but rather
    c(ll, d = list(1:3))# c() combining two lists
  \end{lstlisting}
\end{slide}

\end{document}
---- cut here ----

Regards,

Tamas Papp

PS.: Please break you lines at 70 characters.

-- 
Tam?s K. Papp
E-mail: tpapp at axelero.hu (preferred, especially for large messages)
        tpapp at westel900.net
Please try to send only (latin-2) plain text, not HTML or other garbage.


From fredrik.karlsson at ling.umu.se  Sat Apr  5 11:31:55 2003
From: fredrik.karlsson at ling.umu.se (Fredrik Karlsson)
Date: Sat, 5 Apr 2003 11:31:55 +0200
Subject: [R] sqlSave() Question
In-Reply-To: <HDEPJCAKDEJMEEHKJOKECEBNCAAA.myao@ou.edu>
References: <HDEPJCAKDEJMEEHKJOKECEBNCAAA.myao@ou.edu>
Message-ID: <20030405093155.GA21886@ling.umu.se>

Hi,

I asked the same question to this list previously this week. 
The solution to the problem may be to use the 'case' argument to
odbcConnect. 

See my previous post as well as the reply by Prof. Ripley.

/Fredrik Karlsson



On Fri, Apr 04, 2003 at 04:57:59PM -0600, Minghua Yao wrote:
> All,
> 
> I am new in R. I found sqlSave() doesn't work for our Oracle9i. The
> following was the message:
> 
> > sqlSave(channel, USArrests, rownames="state")
> Error in sqlColumns(channel, tablename) : USArrests : table not found on
> channel
> Check case parameter in odbcConnect
> >
> 
> sqlQuery() works OK.
> 
> Please help. Thanks.
> 
> -MY
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From baron at psych.upenn.edu  Sat Apr  5 13:18:56 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Sat, 5 Apr 2003 06:18:56 -0500
Subject: [R] slides in linux R - OFF TOPIC REPLY
In-Reply-To: <001a01c2fb41$3b3b8e40$2d0ffea9@oemcomputer>
References: <001a01c2fb41$3b3b8e40$2d0ffea9@oemcomputer>
Message-ID: <20030405111856.GA18383@mail2.sas.upenn.edu>

On 04/05/03 09:01, Fredrik Lundgren wrote:

>In S-Plus Windows you can transform graphics to Powerpoint very
>easily, in R Windows you can use enhanced metafiles (.emf) and
>Powerpoint almost as easy. Is there a simular way with R in
>Linux to transform to the presentation program in StarOffice or
>OpenOffice or are you stuck with the pdf device?

This isn't really an answer.  But for an ordinary talk - without
movies or audio - I have made pdf slides with Latex, including
eps output from R, like this:

\documentclass[landscape]{slides}
\usepackage{color,graphicx}
\pagestyle{empty}
\begin{document}
\begin{slide}
...
\end{slide}
and so on.

(The "color" allows fancy ppt-like overlays, etc.)  Then, when I
format this, I do the following.  (This is the batch file I run,
so $1 stands for the name of the tex file.)

latex $1
dvips -Ppdf -T 11in,8.2in $1
ps2pdf $1.ps

Finally, when I show it, I use
xpdf -fullscreen

When I gave a local talk this way, one of my colleagues, knowing
of my antipathy toward Microsoft, said, "You've given in!"  He
thought it was PowerPoint, but actually it took about 1/10 of the
disk space that ppt would take.

I think it would be better still if I used pdflatex, but I
haven't tried that because lately I've been doing slides in html
using http://www.psych.upenn.edu/~baron/900/slides.css . (Any of
the htm files in that directory will work with it.  Some are
quite old and ugly, however.)  This uses a feature of css, namely

html, body {
  height: 100%;
  overflow: visible;
}

This does not work in most browsers but does work in Mozilla and
recent versions of Netscape.  In a way this is an advantage for
classes because the students print out the slides with IE and
don't have to waste paper with all the white space.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/


From ligges at statistik.uni-dortmund.de  Sat Apr  5 14:53:47 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 05 Apr 2003 14:53:47 +0200
Subject: [R] biplot
In-Reply-To: <3.0.6.32.20030404131932.00926bc0@isis.wu-wien.ac.at>
References: <3.0.6.32.20030404131932.00926bc0@isis.wu-wien.ac.at>
Message-ID: <3E8ED1DB.8060505@statistik.uni-dortmund.de>

Wolfgang Koller wrote:
> Dear list,
> 
>  I want to perform a biplot, using customized titels for the x and y axis.
> Setting xlab="" and ylab="" resulted in an error, e.g.:
> 
> 
>>data(USArrests)
>>biplot(princomp(USArrests),xlab="",ylab="")
> 
> Error in biplot.default(t(t(scores[, choices])/lam), t(t(x$loadings[,  : 
>         length of dimnames[1] not equal to array extent
> 
> 
> How do I proceed?
> 
> Thanks in advance!

This will work for R-1.7.0 (beta; in developement).
For the meantime follow Thomas Blackwell's suggestion.

Uwe Ligges


From kjetil at entelnet.bo  Sat Apr  5 16:43:12 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Sat, 05 Apr 2003 10:43:12 -0400
Subject: [R] Tukey's one degree of freedom for nonadditivity? 
In-Reply-To: <3E8C958A.3030509@pdf.com>
Message-ID: <3E8EB340.31461.417543@localhost>

On 3 Apr 2003 at 12:11, Spencer Graves wrote:

See the code copied below.

Kjetil Halvorsen

# From S-Plus:  Guide to Statistical & Mathemathical
# Analysis, page 11.25       slightly changed to function with R.
tukey.1  <-  function(aov.obj, data) {
	vnames <- names(aov.obj$contrasts)
	if(length(vnames) != 2)
		stop("The model must be two-way.")
	vara  <-  data[, vnames[1]]
	varb  <-  data[, vnames[2]]
	na  <-  length(levels(vara))
	nb  <-  length(levels(varb))
        where.resp <-  as.character(attr(aov.obj$terms,
	          "variables")[-1][attr(aov.obj$terms, "response" )])
	resp  <-  data[, where.resp]
	cfs  <-  coef(aov.obj)
	alpha.A  <-  aov.obj$contrasts[[vnames[1]]] %*% 
		     cfs[aov.obj$assign[aov.obj$assign==1]] 
	alpha.B  <-  aov.obj$contrasts[[vnames[2]]] %*% 
		     cfs[aov.obj$assign[aov.obj$assign==2]] 
	r.mat  <-  matrix(0, nb, na)
	r.mat[cbind(as.vector(unclass(varb)), as.vector(
		unclass(vara)))]  <-  resp
	SS.theta.num  <-  sum((alpha.B %*% t(alpha.A)) * 
		r.mat)^2
	SS.theta.den  <-  sum(alpha.A^2) * sum(alpha.B^2)
	SS.theta  <-  SS.theta.num / SS.theta.den
	SS.res    <-  sum(resid(aov.obj)^2)
	SS.res.1  <-  SS.res - SS.theta
	T.1df     <-  ((na * nb -na -nb) *  SS.theta)/SS.res.1
	p.value   <-  1 - pf(T.1df, 1, na*nb - na -nb)
	list(T.1df = T.1df, p.value = p.value)
	}



> 	  Is there code available to decompose interactions involving at least 
> one nominal factor with more than 2 levels as described, e.g., by Tukey 
> or by Mandel (1971, Technometrics, 13: 1-18)?
> 
> 	  Tukey's model:
> 
> 	E(y[i,j]) = mu0 + a[i] + b[j] + c*a[i]*b[j],
> 
> estimating a, b, and c so sum(a) = sum(b)= 0.  Mandel essentially 
> describes a singular value decomposition of the interaction.
> 
> Thanks,
> Spencer Graves
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From uyi_ohonba at latinmail.com  Sat Apr  5 16:44:35 2003
From: uyi_ohonba at latinmail.com (Uyi Ohonba)
Date: Sat,  5 Apr 2003 09:44:35 -0500
Subject: [R] Re:GOOD NEWS
Message-ID: <20030405144432.57600186AC@smtp.latinmail.com>

FROM THE DESK OF UYI OHONBA 
ORIENT BANK OF NIGERIA 
PRIVATE EMAIL:uyiohonba at netscape.net 
 
I am Uyi Ohonba, I am a staff of the bank in the foreign credits 
and bills procurement/debiting department. 
 
I write this mail with respect to a certain sum of money that has been 
stagnant in our vault for more than 4 years runnning, I would not have 
raised the issue of contacting you if I could have been able to sort this 
out myself, the funds was deposited in the name of a company owned by an expertraite firm that did construction works in Bulevard the Morno in Port novo. 
 
The company was owned by a Mesuier James gregson, who is an european. I was surmoned by the government to remit all funds that has been redundant over a period of 4 years, it was while going through the files that I came acrross Mesuier James account with a mouth stagering sum of $23.7 million dollars. I decided to contact you because I could not bring myself to remit such funds to an African government that has been most corrupt and left it's citenzenry with little or nothing. 
 
So I immediately filed an application in the companies name, stating that 
the next of kin has applied for the transfer, hence I would want you to act 
as the next of kin so that we can transfer this funds into your account. 
 
I would anticipate that you have a question or two to ask, please feel 
free to ask any question you think might better foster a more workable 
arrangement. 
 
I will handle the inside informations, please contact me at the afore 
mentioned email address so as to initiate an immediate procedural 
retrieval. 
 
with kind regards 
Uyi Ohonba


From spencer.graves at pdf.com  Sat Apr  5 17:58:35 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 05 Apr 2003 07:58:35 -0800
Subject: [R] Tukey's one degree of freedom for nonadditivity?
References: <3E8EB340.31461.417543@localhost>
Message-ID: <3E8EFD2B.8080309@pdf.com>

Thanks very much for the solution and the reference.

Best Wishes,
Spencer Graves
p.s.  Before I posted the question, I looked in Venables and Ripley and 
checked the "R search site", among other things, to no avail.  I just 
wrote to Jonathan Baron, who maintains the "R search site", asking if it 
might be feasible to include in his data base indices and tables of 
contents from leading references.  I would think that publishers would 
see that as cheap advertising.

kjetil brinchmann halvorsen wrote:
> On 3 Apr 2003 at 12:11, Spencer Graves wrote:
> 
> See the code copied below.
> 
> Kjetil Halvorsen
> 
> # From S-Plus:  Guide to Statistical & Mathemathical
> # Analysis, page 11.25       slightly changed to function with R.
> tukey.1  <-  function(aov.obj, data) {
> 	vnames <- names(aov.obj$contrasts)
> 	if(length(vnames) != 2)
> 		stop("The model must be two-way.")
> 	vara  <-  data[, vnames[1]]
> 	varb  <-  data[, vnames[2]]
> 	na  <-  length(levels(vara))
> 	nb  <-  length(levels(varb))
>         where.resp <-  as.character(attr(aov.obj$terms,
> 	          "variables")[-1][attr(aov.obj$terms, "response" )])
> 	resp  <-  data[, where.resp]
> 	cfs  <-  coef(aov.obj)
> 	alpha.A  <-  aov.obj$contrasts[[vnames[1]]] %*% 
> 		     cfs[aov.obj$assign[aov.obj$assign==1]] 
> 	alpha.B  <-  aov.obj$contrasts[[vnames[2]]] %*% 
> 		     cfs[aov.obj$assign[aov.obj$assign==2]] 
> 	r.mat  <-  matrix(0, nb, na)
> 	r.mat[cbind(as.vector(unclass(varb)), as.vector(
> 		unclass(vara)))]  <-  resp
> 	SS.theta.num  <-  sum((alpha.B %*% t(alpha.A)) * 
> 		r.mat)^2
> 	SS.theta.den  <-  sum(alpha.A^2) * sum(alpha.B^2)
> 	SS.theta  <-  SS.theta.num / SS.theta.den
> 	SS.res    <-  sum(resid(aov.obj)^2)
> 	SS.res.1  <-  SS.res - SS.theta
> 	T.1df     <-  ((na * nb -na -nb) *  SS.theta)/SS.res.1
> 	p.value   <-  1 - pf(T.1df, 1, na*nb - na -nb)
> 	list(T.1df = T.1df, p.value = p.value)
> 	}
> 
> 
> 
> 
>>	  Is there code available to decompose interactions involving at least 
>>one nominal factor with more than 2 levels as described, e.g., by Tukey 
>>or by Mandel (1971, Technometrics, 13: 1-18)?
>>
>>	  Tukey's model:
>>
>>	E(y[i,j]) = mu0 + a[i] + b[j] + c*a[i]*b[j],
>>
>>estimating a, b, and c so sum(a) = sum(b)= 0.  Mandel essentially 
>>describes a singular value decomposition of the interaction.
>>
>>Thanks,
>>Spencer Graves
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> 
>


From mohamed at engr.uconn.edu  Sat Apr  5 20:10:44 2003
From: mohamed at engr.uconn.edu (Mohamed A. Kerasha)
Date: Sat, 5 Apr 2003 13:10:44 -0500
Subject: [R] Branch and Bound
References: <001a01c2fb41$3b3b8e40$2d0ffea9@oemcomputer>
	<20030405111856.GA18383@mail2.sas.upenn.edu>
Message-ID: <005301c2fb9e$ad6be890$62bb7644@ipl>

Dear R helpers,

Is there a Branch and Bound code in R? (other than the one in the leaps
package).

I really appreciate your help,

-M. Kerasha


From zhuw at mail.smu.edu  Sat Apr  5 22:45:55 2003
From: zhuw at mail.smu.edu (Wang, Zhu)
Date: Sat, 5 Apr 2003 14:45:55 -0600
Subject: [R] Is there any Time series change-point estimate in R?
Message-ID: <0FBE46098704A242B0DC8FEC4169F9978140D1@s31xs3.systems.smu.edu>

Thanks.
I am currentlly investigating the package strucchange.
My interested change-point is the covariance structure change. Can strucchange do that? Does strucchange consider Box-Jenkins model?
 
Zhu Wang
 
Statistical Science Department
SMU

	-----Original Message----- 
	From: Achim Zeileis [mailto:zeileis at ci.tuwien.ac.at] 
	Sent: Thu 4/3/2003 3:21 AM 
	To: Wang, Zhu; r-help at stat.math.ethz.ch 
	Cc: 
	Subject: Re: [R] Is there any Time series change-point estimate in R?
	
	

	On Tuesday 01 April 2003 18:56, Wang, Zhu wrote:
	
	> Hello,
	>
	> I am looking for time series non-stationary test and change - point
	> estimate. The pachage strucchange seems not serving my purpose.
	
	This is both very vague. You might find a suitable test for
	non-stationarity in tseries. And depending on what you mean by
	changepoint, strucchange might be able to do what you want. The
	function breakpoints() can estimate breakpoints in linear regression
	models, which includes certain types of models for non-stationary time
	series.
	Z
	
	> Thanks in advance.
	>
	> Zhu Wang
	>
	> Statistical Science Department
	> SMU
	>
	> ______________________________________________
	> R-help at stat.math.ethz.ch mailing list
	> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
	
	______________________________________________
	R-help at stat.math.ethz.ch mailing list
	https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From hodgess at uhddx01.dt.uh.edu  Sun Apr  6 07:35:50 2003
From: hodgess at uhddx01.dt.uh.edu (Erin Hodgess)
Date: Sat, 5 Apr 2003 23:35:50 -0600 (CST)
Subject: [R] Summary for multivariate time series
Message-ID: <200304060535.XAA15042@uhddx01.dt.uh.edu>

The package dse on CRAN does multivariate time series.

Thank you for the many kind responses!

Sincerely,
Erin


From Ted.Harding at nessie.mcc.ac.uk  Sun Apr  6 13:04:26 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sun, 06 Apr 2003 12:04:26 +0100 (BST)
Subject: [R] Re: R list delays
In-Reply-To: <16013.53227.110854.314886@gargle.gargle.HOWL>
Message-ID: <XFMail.030406120426.Ted.Harding@nessie.mcc.ac.uk>

Many thanks (I'm sure from all of us) to Martin Maechler for
taking time at a late hour on Friday evening to resolve the
delays on the R server at ethz.ch (hypatia).

Hypatia (cunning minx) waited till his back was turned before
settling down to do her worst.

However, all seems to be well now, so thanks again!
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 06-Apr-03                                       Time: 12:04:26
------------------------------ XFMail ------------------------------


From Ted.Harding at nessie.mcc.ac.uk  Sun Apr  6 14:04:07 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sun, 06 Apr 2003 13:04:07 +0100 (BST)
Subject: [R] slides in linux R - OFF TOPIC REPLY
In-Reply-To: <20030405111856.GA18383@mail2.sas.upenn.edu>
Message-ID: <XFMail.030406130407.Ted.Harding@nessie.mcc.ac.uk>

On 05-Apr-03 Jonathan Baron wrote:
> On 04/05/03 09:01, Fredrik Lundgren wrote:
>>In S-Plus Windows you can transform graphics to Powerpoint very
>>easily, in R Windows you can use enhanced metafiles (.emf) and
>>Powerpoint almost as easy. Is there a simular way with R in
>>Linux to transform to the presentation program in StarOffice or
>>OpenOffice or are you stuck with the pdf device?
> 
> This isn't really an answer.  But for an ordinary talk - without
> movies or audio - I have made pdf slides with Latex, including
> eps output from R, like this:
> [...]

Tottering dinosaurs like myself will perhaps appreciate the following,
but it is also worth attention from more recently evolved individuals.

As well as LaTeX, don't forget good old Unix troff -- or, rather, its
re-incarnation as GNU groff. As well as troff's long-established
capability to import EPS files (the output format of postscript() in R), 
groff is now capable of colours and, using the \X'ps: exec <code>'
passthrough to the PS postprocessor, can incorprate "PDFmark" tags.

The resulting PS file can be converted to PDF using any good converter
(Acrobat Distiller works beautifully, of course, and recent versions
of ghostscript -- 'ps2pdf' command -- also implement PDFmarks well;
see also Frank Siegert's "PStill" program).

PDFmarks in effect convert a PDF document into a HyperText document
when viewed using Acrobat Reader (recent versions of "xpdf" also work
well), with embedded links/tags enabling you to jump from place to place
in a document, open external PDF files (and return), visit Web URLs,
flash up "comment" boxes, and all sort of other things including spawning
other programs (e.g. to show a "movie" clip).

For recent groff see any recent Linux distribution, or visit
  http://www.gnu.org/software/groff/groff.html

For PStill visit
  http://www.wizards.de/~frank/pstill.html

For various information about PDFmarks (and PDF generally) see
  http://www.pdflib.com/pdfmark/index.html
  http://www.pdflib.com/

For PDFmark reference material see
  http://partners.adobe.com/asn/developer/acrosdk/DOCS/pdfmark.pdf
  http://partners.adobe.com/asn/developer/acrosdk/DOCS/pdfspec.pdf

HTML output from groff is also available (though PDFmarks are silent
in HTML -- use other tags defined for the output format 'html').

Best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 06-Apr-03                                       Time: 13:04:07
------------------------------ XFMail ------------------------------


From pikachoodave at yahoo.co.uk  Sun Apr  6 14:29:21 2003
From: pikachoodave at yahoo.co.uk (=?iso-8859-1?q?Dave=20Caccace?=)
Date: Sun, 6 Apr 2003 13:29:21 +0100 (BST)
Subject: [R] Odd and Even
Message-ID: <20030406122921.39589.qmail@web20701.mail.yahoo.com>

Hi,
I'm trying to create a function, jim(p) which varies
depending on whether the value of p is odd or even. I
was trying to use th eIf function, but i cant work out
a formula to work out if p is odd or even.
Thanks,
Dave

__________________________________________________
Yahoo! Plus
For a better Internet experience
http://www.yahoo.co.uk/btoffer


From ligges at statistik.uni-dortmund.de  Sun Apr  6 14:35:55 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 06 Apr 2003 14:35:55 +0200
Subject: [R] Odd and Even
In-Reply-To: <20030406122921.39589.qmail@web20701.mail.yahoo.com>
References: <20030406122921.39589.qmail@web20701.mail.yahoo.com>
Message-ID: <3E901F2B.80403@statistik.uni-dortmund.de>

Dave Caccace wrote:
> Hi,
> I'm trying to create a function, jim(p) which varies
> depending on whether the value of p is odd or even. I
> was trying to use th eIf function, but i cant work out
> a formula to work out if p is odd or even.
> Thanks,
> Dave

if(p %% 2) "odd" else "even"

Uwe Ligges


From briefantr at gmx.de  Sun Apr  6 19:11:42 2003
From: briefantr at gmx.de (Tino Richter)
Date: Sun, 6 Apr 2003 19:11:42 +0200
Subject: [R] Details to factor analysis
Message-ID: <004501c2fc5f$9d2e5ff0$fe7aa8c0@tower>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030406/473a7acf/attachment.pl

From spencer.graves at pdf.com  Sun Apr  6 19:20:36 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 06 Apr 2003 10:20:36 -0700
Subject: [R] Odd and Even
References: <20030406122921.39589.qmail@web20701.mail.yahoo.com>
	<3E901F2B.80403@statistik.uni-dortmund.de>
Message-ID: <3E9061E4.10906@pdf.com>

Or in vector format:

 > ifelse(seq(1, 2, length=3) %%2, "odd", "even")
[1] "odd"  "odd"  "even"

Enjoy,
Spencer Graves

Uwe Ligges wrote:
> Dave Caccace wrote:
> 
>> Hi,
>> I'm trying to create a function, jim(p) which varies
>> depending on whether the value of p is odd or even. I
>> was trying to use th eIf function, but i cant work out
>> a formula to work out if p is odd or even.
>> Thanks,
>> Dave
> 
> 
> if(p %% 2) "odd" else "even"
> 
> Uwe Ligges
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From kwan022 at stat.auckland.ac.nz  Mon Apr  7 01:03:07 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Mon, 7 Apr 2003 11:03:07 +1200 (NZST)
Subject: [R] Change cex.axis in biplot()
Message-ID: <Pine.LNX.4.33.0304071101590.24787-100000@stat56.stat.auckland.ac.nz>

Hi,

If I do something like:
  biplot(x, cex.axis = .7)
then it will only change the font size for axis 1 and 2, but not 3 and 4.  
Is there a way to change the fonts on axis 3 and 4?

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From gisar at nus.edu.sg  Mon Apr  7 04:31:03 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Mon, 7 Apr 2003 10:31:03 +0800
Subject: [R] Odd and Even
Message-ID: <024D6AEFCB92CB47BA1085751D184BB801053FA1@MBXSRV03.stf.nus.edu.sg>

Or if you are very lazy there is is.odd() and is.even() in library sma.

-----Original Message-----
From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
Sent: Sunday, April 06, 2003 8:36 PM
To: Dave Caccace
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Odd and Even

Dave Caccace wrote:
> Hi,
> I'm trying to create a function, jim(p) which varies
> depending on whether the value of p is odd or even. I
> was trying to use th eIf function, but i cant work out
> a formula to work out if p is odd or even.
> Thanks,
> Dave

if(p %% 2) "odd" else "even"

Uwe Ligges

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From nikko at hailmail.net  Mon Apr  7 05:10:24 2003
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: 07 Apr 2003 11:10:24 +0800
Subject: [R] Re: [Rd]Comparing fp numbers, was  Bug in %in% (match)
In-Reply-To: <x2pto2w043.fsf@biostat.ku.dk>
References: <1049447236.11249.7.camel@sta49.stat.nus.edu.sg> 
	<x2pto2w043.fsf@biostat.ku.dk>
Message-ID: <1049685038.2206.12.camel@sta49.stat.nus.edu.sg>

Hi,
Thanks, I should have thought of that. If I do
tst<-(10*seq(100,125,by=.2))%in%(10*seq(0,800,by=.1))
> sum(tst)
[1] 122
> tst<-(seq(100,125,by=.2))%in%(seq(0,800,by=.1))
> sum(tst)
[1] 76
The problem is corrected. However in my code, where I am comparing much
longer sequences it doesn't always work, even with rounding and
multiplying to an integer. Is there a more robust way to do this? Here
is the function where things are going wrong

spectots<-function(t,x,begin=min(t,na.rm=TRUE),end=max(t,na.rm=TRUE),
                   by.inter=.5,precis=1){
  #browser()
  j<-!is.na(t)
  k<-!((t>end) | (t<begin))
  j<-j&k
  t<-t[j]
  x<-x[j]
  get.mult<-function(pre)return(10^pre)
  new.t<-seq(begin,end,by=by.inter)
  new.x<-rep(NA,length(new.t))
  #new.n<-length(new.t)
  t.err<-rep(NA,length(new.t))
  ######### Here is the matching ############
  tst<-(get.mult(precis)*new.t)%in%(get.mult(precis)*round(t,precis))
  check<-sum(tst)
  if(check!=length(t))warning("not all values matched!")
  new.x[tst]<-x
  t.err[tst]<-t-new.t[tst]
  x.impute<-ifelse(is.na(new.x),.5*min(new.x,na.rm=TRUE),new.x)
  ts(cbind(x.impute,new.x,t.err),start=begin,end=end,freq=1/by.inter)
}

On Sat, 2003-04-05 at 03:09, Peter Dalgaard BSA wrote:
> Nicholas Lewin-Koh <nikko at hailmail.net> writes:
> 
> > Hi,
> > Am I hitting some limit in match? Consider the following example:
> > 
> > > tst<-seq(100,125,by=.2)%in%seq(0,800,by=.1)
> > > sum(tst)
> > [1] 76
> 
> > Gives the correct answer. Did I miss something?
> 
> The fact that 1/5 and 1/10 are not represented exactly in a binary
> computer? 
> 
> > sum(tst<-seq(100,125,by=.2)%in%seq(0,800,by=.1))
> [1] 76
> > sum(tst<-seq(100,125,by=.2)%in%round(seq(0,800,by=.1),1))
> [1] 126
> 
> And, just to be sure:
> 
> > sum(round(seq(100,125,by=.2),1)%in%round(seq(0,800,by=.1),1))
> [1] 126
> 
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
>


From nikko at hailmail.net  Mon Apr  7 05:26:34 2003
From: nikko at hailmail.net (Nicholas Lewin-Koh)
Date: 07 Apr 2003 11:26:34 +0800
Subject: [R] Re: [Rd]Comparing fp numbers, was  Bug in %in% (match)
In-Reply-To: <1049685038.2206.12.camel@sta49.stat.nus.edu.sg>
References: <1049447236.11249.7.camel@sta49.stat.nus.edu.sg> 
	<x2pto2w043.fsf@biostat.ku.dk> 
	<1049685038.2206.12.camel@sta49.stat.nus.edu.sg>
Message-ID: <1049686001.2206.17.camel@sta49.stat.nus.edu.sg>

Hi,
I am dense some days, the following worked;
tst<-as.integer(get.mult(precis)*new.t)%in%as.integer(get.mult(precis)*round(t,precis))

I didn't catch this part of the documentation

Factors are converted to character vectors, and then `x' and
     `table' are coerced to a common type (the later of the two types
     in R's ordering, logical < integer < numeric < complex <
     character) before matching.


Nicholas

On Mon, 2003-04-07 at 11:10, Nicholas Lewin-Koh wrote:
> Hi,
> Thanks, I should have thought of that. If I do
> tst<-(10*seq(100,125,by=.2))%in%(10*seq(0,800,by=.1))
> > sum(tst)
> [1] 122
> > tst<-(seq(100,125,by=.2))%in%(seq(0,800,by=.1))
> > sum(tst)
> [1] 76
> The problem is corrected. However in my code, where I am comparing much
> longer sequences it doesn't always work, even with rounding and
> multiplying to an integer. Is there a more robust way to do this? Here
> is the function where things are going wrong
> 
> spectots<-function(t,x,begin=min(t,na.rm=TRUE),end=max(t,na.rm=TRUE),
>                    by.inter=.5,precis=1){
>   #browser()
>   j<-!is.na(t)
>   k<-!((t>end) | (t<begin))
>   j<-j&k
>   t<-t[j]
>   x<-x[j]
>   get.mult<-function(pre)return(10^pre)
>   new.t<-seq(begin,end,by=by.inter)
>   new.x<-rep(NA,length(new.t))
>   #new.n<-length(new.t)
>   t.err<-rep(NA,length(new.t))
>   ######### Here is the matching ############
>   tst<-(get.mult(precis)*new.t)%in%(get.mult(precis)*round(t,precis))
>   check<-sum(tst)
>   if(check!=length(t))warning("not all values matched!")
>   new.x[tst]<-x
>   t.err[tst]<-t-new.t[tst]
>   x.impute<-ifelse(is.na(new.x),.5*min(new.x,na.rm=TRUE),new.x)
>   ts(cbind(x.impute,new.x,t.err),start=begin,end=end,freq=1/by.inter)
> }
> 
> On Sat, 2003-04-05 at 03:09, Peter Dalgaard BSA wrote:
> > Nicholas Lewin-Koh <nikko at hailmail.net> writes:
> > 
> > > Hi,
> > > Am I hitting some limit in match? Consider the following example:
> > > 
> > > > tst<-seq(100,125,by=.2)%in%seq(0,800,by=.1)
> > > > sum(tst)
> > > [1] 76
> > 
> > > Gives the correct answer. Did I miss something?
> > 
> > The fact that 1/5 and 1/10 are not represented exactly in a binary
> > computer? 
> > 
> > > sum(tst<-seq(100,125,by=.2)%in%seq(0,800,by=.1))
> > [1] 76
> > > sum(tst<-seq(100,125,by=.2)%in%round(seq(0,800,by=.1),1))
> > [1] 126
> > 
> > And, just to be sure:
> > 
> > > sum(round(seq(100,125,by=.2),1)%in%round(seq(0,800,by=.1),1))
> > [1] 126
> > 
> > 
> > -- 
> >    O__  ---- Peter Dalgaard             Blegdamsvej 3  
> >   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
> >  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> > ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
> > 
>


From nirmalg at psu.edu  Mon Apr  7 05:19:48 2003
From: nirmalg at psu.edu (Nirmal Govind)
Date: Sun, 6 Apr 2003 23:19:48 -0400 (EDT)
Subject: [R] spline with multiple predictor vars?
Message-ID: <200304070319.XAA12044@webmail13.cac.psu.edu>

Hi, is there a way in R to generate a polynomial spline with multiple predictor
variables? I have one response and two predictors and I'm trying to fit a
spline model for this...

Please cc me on the reply..

Thanks,
nirmal


From simon at stats.gla.ac.uk  Mon Apr  7 07:42:03 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Mon, 7 Apr 2003 06:42:03 +0100 (BST)
Subject: [R] spline with multiple predictor vars?
In-Reply-To: <200304070319.XAA12044@webmail13.cac.psu.edu>
Message-ID: <Pine.SOL.3.96.1030407063937.4244C-100000@jupiter.stats.gla.ac.uk>

There are thin plate regression splines in mgcv and thin plate splines and
tensor product splines in gss that will probably do what you want.

See examples in mgcv helpfile ?gam for a couple of examples.

> Hi, is there a way in R to generate a polynomial spline with multiple predictor
> variables? I have one response and two predictors and I'm trying to fit a
> spline model for this...
_____________________________________________________________________
> Simon Wood simon at stats.gla.ac.uk        www.stats.gla.ac.uk/~simon/
>>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
>>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814


From mama at it.usyd.edu.au  Mon Apr  7 08:28:29 2003
From: mama at it.usyd.edu.au (Mama Benchaffai)
Date: Mon, 7 Apr 2003 16:28:29 +1000 (EST)
Subject: [R] graphic question
Message-ID: <Pine.SOL.4.21.0304071619300.7797-100000@staff.cs.usyd.edu.au>

Hi,

I want to use R for some data mining project , and was wondering if it has
any intercative graphical features?
For example, is it possible to plot a histogram and be able to select a
specific point on it and have all the data about it? or select a specific
area in a curve and have all the data about it? or possibilities to zoom
out and in?

Thank you for your help,

Mama Benchaffai
School of Information Technology
University of Sydney


From temiz at deprem.gov.tr  Mon Apr  7 10:35:01 2003
From: temiz at deprem.gov.tr (orkun)
Date: Mon, 07 Apr 2003 11:35:01 +0300
Subject: [R] log-linear
Message-ID: <3E913835.10308@deprem.gov.tr>

hello

I have spatial data which contain
  number of landslide presence cells with respect to landslide 
predictors and
  number of landslide absence cells with respect to same predictors.

predictors are essentially categorical data.

I tried logistic regression. But because of providing interaction 
capability
of predictors, I want to use log-linear method.
I hesitate the way I should use landslide count as response variable.
only landslide presence data should be regarded ? or both landslide 
presence and absent data should be regarded as response variable ?

I will appreciate if anyone can supply information

thanks in advance

Ahmet Temiz
Gen Dir of Disaster of Affairs

TURKEY


______________________________________



______________________________________
The views and opinions expressed in this e-mail message are the sender's own
and do not necessarily represent the views and the opinions of Earthquake Research Dept.
of General Directorate of Disaster Affairs.

Bu e-postadaki fikir ve gorusler gonderenin sahsina ait olup, yasal olarak T.C.
B.I.B. Afet Isleri Gn.Mud. Deprem Arastirma Dairesi'ni baglayici nitelikte degildir.


From petr.pikal at precheza.cz  Mon Apr  7 11:48:26 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 07 Apr 2003 11:48:26 +0200
Subject: [R] plot.POSIXct with axes FALSE
Message-ID: <3E91658A.17293.12F977D@localhost>

Hallo all

I have a question regarding POSIX class objects.

I try tu use as.POSIXct for creating and plotting some time series. To be able to 
set labels for time (x) axis I started with plot(..., axes=FALSE) but although it 
suppressed all other axes, x axis is still plotted together with labels. Is it a bug?

see

datum.vyber<-seq(ISOdate(2000,1,1), ISOdate(2003,1,1), by="3 months")
plot(datum.vyber,1:13,axes=F)

in next command

axis.POSIXct(1,at=datum.vyber,format="%Y-%m")
axis(2)
box()

the x axis is overplotted with intended labels.

however I just found that I can use

plot(datum.vyber,1:13, xaxt="n") 
axis.POSIXct(1,at=datum.vyber,format="%Y-%m")

to get intended result. 

Why axes = FALSE does not work in case of POSIX classes?

Thank you.

Best regards
Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz


From krcabrer at perseus.unalmed.edu.co  Mon Apr  7 14:11:21 2003
From: krcabrer at perseus.unalmed.edu.co (Kenneth Cabrera)
Date: Mon, 07 Apr 2003 07:11:21 -0500
Subject: [R] Sampling from a Data Frame
In-Reply-To: <Pine.LNX.4.33.0304050900010.8713-100000@stat56.stat.auckland.ac.nz>
References: <Pine.LNX.4.33.0304050900010.8713-100000@stat56.stat.auckland.ac.nz>
Message-ID: <oprm9dg7gvfaouaq@200.24.8.4>

On Sat, 5 Apr 2003 09:01:13 +1200 (NZST), Ko-Kang Kevin Wang 
<kwan022 at stat.auckland.ac.nz> wrote:

> Hi,
>
> I've been looking through the documentation for sample(), but can only 
> get it to work with vectors.  Is it possible to sample from a dataframe?
>
I think somebody already answer, but, just in case:

suppose dfrme is a "data frame" and "n" is the sample size, then using
indexing you try this:

samp1<-dfrme[sample(1:dim(dfrme)[1],n),]

If you want to preserve the original order in the sample:

samp1<-dfrme[sort(sample(1:dim(dfrme)[1],n)),]


--


From Samuel.Plessis at cgm.cnrs-gif.fr  Mon Apr  7 14:40:48 2003
From: Samuel.Plessis at cgm.cnrs-gif.fr (Samuel Plessis-Fraissard)
Date: 07 Apr 2003 14:40:48 +0200
Subject: [R] Is it possible to have data stuctures like in C ?
Message-ID: <m2brzibhv3.fsf@bob.cgm.cnrs-gif.fr>

I'am a very fresh R user and I'd like to know how I could create such
structures. 

I saw R was objects-oriented but I can not find any doccumentation on
about how to build my hown ojects.

Thanks.


From tblackw at umich.edu  Mon Apr  7 15:04:47 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 7 Apr 2003 09:04:47 -0400 (EDT)
Subject: [R] spline with multiple predictor vars?
In-Reply-To: <200304070319.XAA12044@webmail13.cac.psu.edu>
Message-ID: <Pine.SOL.4.44.0304070902500.10983-100000@zektor.gpcc.itd.umich.edu>

gam() and friends comes close.  Not literally a cubic B spline,
but the same effect.  "Generalized Additive Models" a la Hastie
and Tibshirani.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Sun, 6 Apr 2003, Nirmal Govind wrote:

> Hi, is there a way in R to generate a polynomial spline with multiple predictor
> variables? I have one response and two predictors and I'm trying to fit a
> spline model for this...
>
> Please cc me on the reply..
>
> Thanks,
> nirmal
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From d_pleydell at yahoo.com  Mon Apr  7 15:36:12 2003
From: d_pleydell at yahoo.com (=?iso-8859-1?q?David=20Pleydell?=)
Date: Mon, 7 Apr 2003 14:36:12 +0100 (BST)
Subject: [R] Cressie & Read (1989) Weighted Median Polish
Message-ID: <20030407133612.33845.qmail@web41504.mail.yahoo.com>

Hi 
I am trying to implement the weighted median polish
method described in Cressie, Statistics for Spatial
Data Revised Ed' page 398.  The median polish bit
looks simple but I can't understand the weighting
described in section 3.3.13, p147.  Sadly I don't have
access to either of the referenced papers.

Could anyone explain the weighting to me so I can
impliment the method in R, or does anyone have some R
code for this?

Many thanks
Dave

__________________________________________________
Yahoo! Plus
For a better Internet experience
http://www.yahoo.co.uk/btoffer


From tblackw at umich.edu  Mon Apr  7 15:36:26 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 7 Apr 2003 09:36:26 -0400 (EDT)
Subject: [R] log-linear
In-Reply-To: <3E913835.10308@deprem.gov.tr>
Message-ID: <Pine.SOL.4.44.0304070910570.10983-100000@zektor.gpcc.itd.umich.edu>



The presence/absence nature of the outcome variable strongly supports
using logistic regression and nothing else.  I strongly encourage you
to stick with logistic regression.  The model formula and interaction
term capabilities in R are just the same for logistic regression as for
log-linear models.  (In some textbooks, log-linear models are used as
the motivation and example for introducing the ideas of interaction
terms, but once introduced, the ideas apply very generally.)

I would set up the data as you have, as a data frame or a matrix with
columns representing the number of landslide presence cells, the number
of landslide absence cells, and then one column for each predictor.

Then use  glm() with a call something like:

result <- glm(cbind(present, absent) ~ (a+b+c+d)^3,  family=binomial,
                 data = name.of.data.frame)

In  help("glm"), there's a sentence under "Details" which describes
the cbind() syntax I've used above, and  help("formula")  explains
the (.)^3 syntax.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 7 Apr 2003, orkun wrote:

> hello
>
> I have spatial data which contain number of landslide presence cells
> with respect to landslide predictors and number of landslide absence
> cells with respect to same predictors.
>
> predictors are essentially categorical data.
>
> I tried logistic regression. But because of providing interaction
> capability of predictors, I want to use log-linear method.
> I hesitate the way I should use landslide count as response variable.
> only landslide presence data should be regarded ? or both landslide
> presence and absent data should be regarded as response variable ?
>
> I will appreciate if anyone can supply information
>
> thanks in advance
>
> Ahmet Temiz
> Gen Dir of Disaster of Affairs
> TURKEY


From tblackw at umich.edu  Mon Apr  7 15:49:36 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 7 Apr 2003 09:49:36 -0400 (EDT)
Subject: [R] Details to factor analysis
In-Reply-To: <004501c2fc5f$9d2e5ff0$fe7aa8c0@tower>
Message-ID: <Pine.SOL.4.44.0304070942240.10983-100000@zektor.gpcc.itd.umich.edu>


I've been hoping someone else would reply.  My only suggestion
is:  look up the formula for the quantities you want and calculate
them directly, using matrix or vector arithmetic at the R command
line.  That's what most people do.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Sun, 6 Apr 2003, Tino Richter wrote:

> Well, it is no problem to use R or S-Plus for a principle
> component analysis (PCA). The function "princomp" works very
> well with my polychoric correlation matrix, that I use for
> this approach on ordinal variables. But I want to inspect the
> Kaiser-Meyer-Olkin-crieterion with the "measure of sampling
> adequancy (MSA)" and the anti-image-correlation matrix.
> I can't find any possibility to compute this. Please give me
> a hint.
>
> Many Thanks!
> Tino
>


From rdiaz at cnio.es  Mon Apr  7 16:06:45 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Mon, 7 Apr 2003 16:06:45 +0200
Subject: [R] Is it possible to have data stuctures like in C ?
In-Reply-To: <m2brzibhv3.fsf@bob.cgm.cnrs-gif.fr>
References: <m2brzibhv3.fsf@bob.cgm.cnrs-gif.fr>
Message-ID: <200304071606.45391.rdiaz@cnio.es>

Dear Samuel,

With regards to the second question, essentially everything in R (S) is an 
object. As a simple example, if you do:
> x <- 1:5
x is an object. It has attributes, there are methods appropriate for printing 
it, etc.

As for the first, the simplest thing to use would be a list, where you can 
have named components of different types.
> y <- list(the.first.vector = 1:5, one.character = "a", another.vector = 
10:15)

S4 classes do provide more sophisticated ways of dealing with classes, and 
they might be closer to what you expect from structs in C/C++ and classes in 
C++. S4 are thoroughly documented in Venables & Ripley's "S Programming" and 
in Chambers' "Programming with Data".

But I think you problably should start with the introductory manuals (such as 
"An introduction to R", which comes with R) and then maybe move to Venables & 
Ripley's "S Programming".


Hope this helps,

Ram?n


On Monday 07 April 2003 14:40, Samuel Plessis-Fraissard wrote:
> I'am a very fresh R user and I'd like to know how I could create such
> structures.
>
> I saw R was objects-oriented but I can not find any doccumentation on
> about how to build my hown ojects.
>
> Thanks.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://bioinfo.cnio.es/~rdiaz


From tlumley at u.washington.edu  Mon Apr  7 16:08:08 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 7 Apr 2003 07:08:08 -0700 (PDT)
Subject: [R] Is it possible to have data stuctures like in C ?
In-Reply-To: <m2brzibhv3.fsf@bob.cgm.cnrs-gif.fr>
Message-ID: <Pine.A41.4.44.0304070700050.203084-100000@homer07.u.washington.edu>

On 7 Apr 2003, Samuel Plessis-Fraissard wrote:

> I'am a very fresh R user and I'd like to know how I could create such
> structures.
>
> I saw R was objects-oriented but I can not find any doccumentation on
> about how to build my hown ojects.
>

You can build arbitrarily complex structures using lists (and lists of
lists, and...).

This isn't what people mean when they describe R as object-oriented,
though.

There are two systems for handling generic and method functions, so you
can say
    print(x)
or
    plot(x)

and the appropriate function for printing or plotting an `x' will be
called.

While there is some documentation (see ?class, ?UseMethod, and help for
the `methods' package) and there are quite a lot of examples in R itself
and in the Bioconductor project you probably want to read a book on S
programming.

	-thomas


From Samuel.Plessis at cgm.cnrs-gif.fr  Mon Apr  7 16:15:54 2003
From: Samuel.Plessis at cgm.cnrs-gif.fr (Samuel Plessis-Fraissard)
Date: 07 Apr 2003 16:15:54 +0200
Subject: [R] Is it possible to have data stuctures like in C ?
In-Reply-To: <Pine.A41.4.44.0304070700050.203084-100000@homer07.u.washington.edu>
References: <Pine.A41.4.44.0304070700050.203084-100000@homer07.u.washington.edu>
Message-ID: <m2ptny9yw5.fsf@bob.cgm.cnrs-gif.fr>

Thomas Lumley <tlumley at u.washington.edu> writes:

|On 7 Apr 2003, Samuel Plessis-Fraissard wrote:
|
|> I'am a very fresh R user and I'd like to know how I could create such
|> structures.
|>
|> I saw R was objects-oriented but I can not find any doccumentation on
|> about how to build my hown ojects.
|>
|
|You can build arbitrarily complex structures using lists (and lists of
|lists, and...).
|
|This isn't what people mean when they describe R as object-oriented,
|though.
|
|There are two systems for handling generic and method functions, so you
|can say
|    print(x)
|or
|    plot(x)
|
|and the appropriate function for printing or plotting an `x' will be
|called.
|
|While there is some documentation (see ?class, ?UseMethod, and help for
|the `methods' package) and there are quite a lot of examples in R itself
|and in the Bioconductor project you probably want to read a book on S
|programming.
|

Thanks


From Samuel.Plessis at cgm.cnrs-gif.fr  Mon Apr  7 16:17:17 2003
From: Samuel.Plessis at cgm.cnrs-gif.fr (Samuel Plessis-Fraissard)
Date: 07 Apr 2003 16:17:17 +0200
Subject: [R] Is it possible to have data stuctures like in C ?
In-Reply-To: <200304071606.45391.rdiaz@cnio.es>
References: <m2brzibhv3.fsf@bob.cgm.cnrs-gif.fr>
	<200304071606.45391.rdiaz@cnio.es>
Message-ID: <m2llym9ytu.fsf@bob.cgm.cnrs-gif.fr>

Ramon Diaz <rdiaz at cnio.es> writes:

|Dear Samuel,
|
|With regards to the second question, essentially everything in R (S) is an 
|object. As a simple example, if you do:
|> x <- 1:5
|x is an object. It has attributes, there are methods appropriate for printing 
|it, etc.
|
|As for the first, the simplest thing to use would be a list, where you can 
|have named components of different types.
|> y <- list(the.first.vector = 1:5, one.character = "a", another.vector = 
|10:15)
|
|S4 classes do provide more sophisticated ways of dealing with classes, and 
|they might be closer to what you expect from structs in C/C++ and classes in 
|C++. S4 are thoroughly documented in Venables & Ripley's "S Programming" and 
|in Chambers' "Programming with Data".
|
|But I think you problably should start with the introductory manuals (such as 
|"An introduction to R", which comes with R) and then maybe move to Venables & 
|Ripley's "S Programming".
|
|
|Hope this helps,
|
|Ram?n

Thanks for help.


From spencer.graves at pdf.com  Mon Apr  7 16:25:07 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 07 Apr 2003 07:25:07 -0700
Subject: [R] log-linear
References: <3E913835.10308@deprem.gov.tr>
Message-ID: <3E918A43.2050103@pdf.com>

	  1.  What did you use for logistic regression?  "glm"?  If your 
response variable is "number of landslides", I would think that "glm" 
with "family = poisson" might be appropriate.  Have you checked the R 
help for "?glm" and "?family" and the R search site at 
"http://www.r-project.org/" -> search -> "R search site"?  In 
particular, if you don't have "Modern Applied Statistics with S" by 
Venables and Ripley (2002), I suggest you get a copy.  This is the best 
reference I know on R.  If you've digested Venables and Ripley, at least 
on "glm", the next best book I know for your issues may be  McCullagh P. 
and Nelder, J. A. (1989) Generalized Linear Models (London: Chapman and 
Hall).

	  2.  You can use interactions with logistic regression, as you could 
with Poisson regression, "glm(..., family = poisson)".  If your 
explanatory variables are all categorical, then you might have a problem 
with estimating too many parameters:  If you have 5 categories in one 
variable and 7 in another, the main effects will estimate 4=(5-1) and 
6=(7-1) parameters, and the interaction will involve 4*6 = 24 
parameters.  Moreover, if you do NOT have data on at least 24 
sufficiently different combinations out of the 5*7 = 35 possible, you 
won't be able to estimate all the parameters in the interaction.  I 
suggest you try to construct at least ordinal scales, code the 
categories as numbers whereever that might be done plausibly, then look 
for linear terms, parabolics, etc., and linear*linear interactions, 
etc., THEN look for large residuals from the fitted model.

Hope this helps,
Spencer Graves

orkun wrote:
> hello
> 
> I have spatial data which contain
>  number of landslide presence cells with respect to landslide predictors 
> and
>  number of landslide absence cells with respect to same predictors.
> 
> predictors are essentially categorical data.
> 
> I tried logistic regression. But because of providing interaction 
> capability
> of predictors, I want to use log-linear method.
> I hesitate the way I should use landslide count as response variable.
> only landslide presence data should be regarded ? or both landslide 
> presence and absent data should be regarded as response variable ?
> 
> I will appreciate if anyone can supply information
> 
> thanks in advance
> 
> Ahmet Temiz
> Gen Dir of Disaster of Affairs
> 
> TURKEY
> 
> 
> ______________________________________
> 
> 
> 
> ______________________________________
> The views and opinions expressed in this e-mail message are the sender's 
> own
> and do not necessarily represent the views and the opinions of 
> Earthquake Research Dept.
> of General Directorate of Disaster Affairs.
> 
> Bu e-postadaki fikir ve gorusler gonderenin sahsina ait olup, yasal 
> olarak T.C.
> B.I.B. Afet Isleri Gn.Mud. Deprem Arastirma Dairesi'ni baglayici 
> nitelikte degildir.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From fehily at pacbell.net  Mon Apr  7 17:03:02 2003
From: fehily at pacbell.net (Chris Fehily)
Date: Mon, 07 Apr 2003 08:03:02 -0700
Subject: [R] Scalar vs. vector
Message-ID: <5.2.0.9.2.20030407075040.00b675c8@postoffice.pacbell.net>

Do these statements yield identical types of objects?
   x = 3
and
   y = c(3)

That is, intrinsically, is x, like y, a vector of length one, but created 
with abbreviated syntax?

More simply: Are scalars really trivial vectors?

Thanks.
-chris


From abunn at montana.edu  Mon Apr  7 17:17:25 2003
From: abunn at montana.edu (Andy Bunn)
Date: Mon, 7 Apr 2003 09:17:25 -0600
Subject: [R] log-linear
In-Reply-To: <3E918A43.2050103@pdf.com>
Message-ID: <000001c2fd18$e02133f0$3bf05a99@msu.montana.edu>

With this type of binary spatial data it would be nice to use
autologistic regression. I recently asked the list if there was a R
autologit function and nobody thought that there was. However, Jennifer
Hoeting has an S+ (and C++) version at her website:

http://www.stat.colostate.edu/~jah/software/


Mantel's test has also been used successfully on binary spatially
autocorrelated data:

Schick, R.S., Urban, D.L., 2000, Spatial Components of Bowhead
Whale(Balaena mysticetus) distribution in the Alaskan Beufort Sea.
Canadian Journal of Fisheries Aquatic Sciences, 57, 2193-2200.

I have a highly confounded binary dataset that has first and second
order spatial effects (live vs. dead trees and a host of environmental
correlates) for which I'm looking for a tidy analytical framework. I
haven't really found the right thing just yet.

Cheers, Andy


From vele.samak at citigroup.com  Mon Apr  7 17:30:19 2003
From: vele.samak at citigroup.com (Samak, Vele [EQRE])
Date: Mon, 7 Apr 2003 11:30:19 -0400 
Subject: [R] filtering ts with arima
Message-ID: <D532F841E8DDD311BED00002A51350A40C53A3A4@EXCHNY38.ny.ssmb.com>

Hi,

I have the following code from Splus that I'd like to migrate to R. So far,
the only problem is the arima.filt function. This function allows me to
filter an existing time-series through a previously estimated arima model,
and obtain the residuals for further use. Here's the Splus code:

# x is the estimation time series, new.infl is a timeseries that contains
new information
# a.mle is estimated result (list) from arima.mle, (1,0,1) x (1,0,1)12
seasonal model
mdl 	_ list(list(order=c(1,0,1)), list(order=c(1,0,1), period=12))
a.mle	_ arima.mle(x, model = mdl)

# then, we get regular residuals:
new.pred        _ arima.filt(new.infl, a.mle$model)$pred  
new.res         _ new.infl - new.pred 

The R code from library(ts) would be:

# new.infl is a timeseries
# a.mle is estimated result (list) from arima.mle, (1,0,1) x (1,0,1)12
seasonal model
a2.mle _ arima(x, order=c(1,0,1), seasonal=list(order=c(1,0,1), period=12),
include.mean=F, method="ML")

new.infl ????
new.res         _ new.infl - new.pred 

What's the arima.filt equivalent in R: filter doesn't seem to take the
coefficients for a seasonal model correctly, also predict isn't quite the
answer? Help is appreciated. Thanks,


> Vele Samak
> Vice President
> Global Quantitative Research Group
> CITIGROUP / Smith Barney
> 388 Greenwich St. 29th Floor
> New York, NY 10013
> (212) 816-0379


From bojaniss at poczta.onet.pl  Mon Apr  7 18:46:02 2003
From: bojaniss at poczta.onet.pl (Michal Bojanowski)
Date: Mon, 7 Apr 2003 18:46:02 +0200
Subject: [R] graphic question
In-Reply-To: <Pine.SOL.4.21.0304071619300.7797-100000@staff.cs.usyd.edu.au>
References: <Pine.SOL.4.21.0304071619300.7797-100000@staff.cs.usyd.edu.au>
Message-ID: <7915315632.20030407184602@poczta.onet.pl>

Hello Mama,

Monday, April 7, 2003, 8:28:29 AM, you wrote:

MB> I want to use R for some data mining project , and was wondering if it has
MB> any intercative graphical features?
MB> For example, is it possible to plot a histogram and be able to select a
MB> specific point on it and have all the data about it? or select a specific
MB> area in a curve and have all the data about it? or possibilities to zoom
MB> out and in?

I guess R is not the best choice for this kind of applications at this
moment (correct me, if I'm wrong). Interacting with graphs is AFAIK
limited to the use of locator(). Creating functions, that will provide
you with some information (what kind?) about plotted data via
locator(), would require considerable work with coding.

I've heard, that LispStat is good at this kind of jobs. I don't have
any experience with it, thats what "rumours" say.


I hope this helps
and good luck



m.


-- 
Best regards,
 Michal                            mailto:bojaniss at poczta.onet.pl


From pikachoodave at yahoo.co.uk  Mon Apr  7 19:08:00 2003
From: pikachoodave at yahoo.co.uk (=?iso-8859-1?q?Dave=20Caccace?=)
Date: Mon, 7 Apr 2003 18:08:00 +0100 (BST)
Subject: [R] naming an operation inside a function
In-Reply-To: <024D6AEFCB92CB47BA1085751D184BB801053FA1@MBXSRV03.stf.nus.edu.sg>
Message-ID: <20030407170800.24543.qmail@web20706.mail.yahoo.com>

 Thank you for you previous help :)

I now need ot know how i can name a specific operation
inside a function. i am using the if(cond){}else{}
construction and would like to name it. However if i
do assign a name to it and then call it later onm in
the function, it is not recognised. does any one have
any idea why?
Thank you,
Dave


From martinol at ensam.inra.fr  Mon Apr  7 19:28:40 2003
From: martinol at ensam.inra.fr (Martin Olivier)
Date: Mon, 07 Apr 2003 19:28:40 +0200
Subject: [R] problem with mvtnorm installation
Message-ID: <3E91B548.5010900@ensam.inra.fr>

Hi all,

I tried to install the mvtnorm library on linux (mandrake version) and i
obtained the following result :

/usr/bin/ld: cannot find -lreadline
collect2: ld returned 1 exit status
make: *** [mvtnorm.so] Erreur 1
ERROR: compilation failed for package 'mvtnorm'

Could you help me ?
Best regards,
Olivier


From den.duurs at lycos.com  Mon Apr  7 19:51:16 2003
From: den.duurs at lycos.com (Remko Duursma)
Date: Mon, 07 Apr 2003 10:51:16 -0700
Subject: [R] How to sort a dataframe?
Message-ID: <IPOIHPHJJKHNFEAA@mailcity.com>

Dear R-helpers,

for the purpose of plotting a dataframe, i am trying to sort a dataframe by one column, for example

tester <- data.frame(one=c(3,2,1), two=c(2,3,1))

#> tester
#  one two
#1   3   2
#2   2   3
#3   1   1

# I want to sort "tester" by column "one", so that i get a dataframe
# that looks like:
#one two
#1    1
#2    3
#3    2

I know of 'sort' but it can only sort vectors.

Thanks for your help,

Remko Duursma


From spencer.graves at pdf.com  Mon Apr  7 20:07:29 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 07 Apr 2003 11:07:29 -0700
Subject: [R] How to sort a dataframe?
References: <IPOIHPHJJKHNFEAA@mailcity.com>
Message-ID: <3E91BE61.4060907@pdf.com>

 > tester <- data.frame(one=c(3,2,1), two=c(2,3,1))
 > tester[order(tester$one),]
   one two
3   1   1
2   2   3
1   3   2
 >
Spencer Graves

Remko Duursma wrote:
> Dear R-helpers,
> 
> for the purpose of plotting a dataframe, i am trying to sort a dataframe by one column, for example
> 
> tester <- data.frame(one=c(3,2,1), two=c(2,3,1))
> 
> #> tester
> #  one two
> #1   3   2
> #2   2   3
> #3   1   1
> 
> # I want to sort "tester" by column "one", so that i get a dataframe
> # that looks like:
> #one two
> #1    1
> #2    3
> #3    2
> 
> I know of 'sort' but it can only sort vectors.
> 
> Thanks for your help,
> 
> Remko Duursma
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ccleland at optonline.net  Mon Apr  7 20:11:29 2003
From: ccleland at optonline.net (Chuck Cleland)
Date: Mon, 07 Apr 2003 14:11:29 -0400
Subject: [R] How to sort a dataframe?
In-Reply-To: <IPOIHPHJJKHNFEAA@mailcity.com>
References: <IPOIHPHJJKHNFEAA@mailcity.com>
Message-ID: <3E91BF51.1080808@optonline.net>

Remko Duursma wrote:
> for the purpose of plotting a dataframe, i am trying to sort a dataframe by one column, for example
> 
> tester <- data.frame(one=c(3,2,1), two=c(2,3,1))
> 
> #> tester
> #  one two
> #1   3   2
> #2   2   3
> #3   1   1
> 
> # I want to sort "tester" by column "one", so that i get a dataframe
> # that looks like:
> #one two
> #1    1
> #2    3
> #3    2

Remko:

   First examine the results of the following:

order(tester[,1])

   Then try this:

tester[order(tester[,1]),]

   See ?order.

hope it helps,

Chuck Cleland


From rpeng at stat.ucla.edu  Mon Apr  7 20:25:02 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon, 7 Apr 2003 11:25:02 -0700 (PDT)
Subject: [R] problem with mvtnorm installation
In-Reply-To: <3E91B548.5010900@ensam.inra.fr>
Message-ID: <Pine.GSO.4.10.10304071124110.20692-100000@quetelet.stat.ucla.edu>

I'm not familiar with Mandrake but it appears that you are missing either
the readline or perhaps the readline-devel packages (I'm guessing the
names here).  

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Mon, 7 Apr 2003, Martin Olivier wrote:

> Hi all,
> 
> I tried to install the mvtnorm library on linux (mandrake version) and i
> obtained the following result :
> 
> /usr/bin/ld: cannot find -lreadline
> collect2: ld returned 1 exit status
> make: *** [mvtnorm.so] Erreur 1
> ERROR: compilation failed for package 'mvtnorm'
> 
> Could you help me ?
> Best regards,
> Olivier
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From jfox at mcmaster.ca  Mon Apr  7 20:15:36 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 07 Apr 2003 14:15:36 -0400
Subject: [R] How to sort a dataframe?
In-Reply-To: <IPOIHPHJJKHNFEAA@mailcity.com>
Message-ID: <5.0.2.1.0.20030407141345.00aecba0@mcmail.cis.mcmaster.ca>

Dear Remko,

Simply index the rows of the data frame by the order of elements in the 
first column:

 > tester[order(tester$one),]
   one two
3   1   1
2   2   3
1   3   2
 >

John

At 10:51 AM 4/7/2003 -0700, Remko Duursma wrote:

>for the purpose of plotting a dataframe, i am trying to sort a dataframe 
>by one column, for example
>
>tester <- data.frame(one=c(3,2,1), two=c(2,3,1))
>
>#> tester
>#  one two
>#1   3   2
>#2   2   3
>#3   1   1
>
># I want to sort "tester" by column "one", so that i get a dataframe
># that looks like:
>#one two
>#1    1
>#2    3
>#3    2
>
>I know of 'sort' but it can only sort vectors.

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox


From chandorf at siverion.com  Mon Apr  7 20:28:08 2003
From: chandorf at siverion.com (Chris Handorf)
Date: Mon, 07 Apr 2003 11:28:08 -0700
Subject: [R] subsetting a dataframe
Message-ID: <3E91C338.8090805@siverion.com>

How does one remove a column from a data frame when the name of
the column to remove is stored in a variable?

For Example:

colname <- "LOT"

newdf <- subset(olddf,select = - colname)

The above statement will give an error, but thats what I'm trying to 
accomplish.

If I had used:

newdf <- subset(olddf,select = - LOT)

then it would have worked, but as I said the column name is stored in a 
variable
so I can't just enter it explicity.

Thanks.


From dgrove at fhcrc.org  Mon Apr  7 20:47:53 2003
From: dgrove at fhcrc.org (Douglas Grove)
Date: Mon, 7 Apr 2003 11:47:53 -0700 (PDT)
Subject: [R] subsetting a dataframe
In-Reply-To: <3E91C338.8090805@siverion.com>
Message-ID: <Pine.LNX.4.44.0304071145090.23763-100000@echidna.fhcrc.org>

> How does one remove a column from a data frame when the name of
> the column to remove is stored in a variable?
> 
> For Example:
> 
> colname <- "LOT"
> 
> newdf <- subset(olddf,select = - colname)


This is how I do it.  There are variations on this
and I'm sure totally different ways as well.

newdf <- newdf[, names(newdf) != colname]


If 'colnames' is a vector (i.e. if you have multiple columns
to delete) then do:


newdf <- newdf[, !(names(newdf) %in% colname)]

This command will work even if 'colname' is not a vector


Doug


 
> The above statement will give an error, but thats what I'm trying to 
> accomplish.
> 
> If I had used:
> 
> newdf <- subset(olddf,select = - LOT)
> 
> then it would have worked, but as I said the column name is stored in a 
> variable
> so I can't just enter it explicity.
> 
> Thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From tvargas at cisco.com  Mon Apr  7 21:01:59 2003
From: tvargas at cisco.com (Tony Vargas)
Date: Mon, 7 Apr 2003 12:01:59 -0700 (PDT)
Subject: [R] Justifying only the X-label
Message-ID: <Pine.GSO.4.44.0304071158300.10457-201000@tvargas-u5.cisco.com>

In the attached plot, how do I move just the X-label(Time) to the right.
Basically, I just want to do a par ( adj = 1) on just the X-label, not
all my labels.  Any ideas how to accomplish this?

Thanks,

Tony

Tony Vargas
Cisco Systems
Engineering Computing Services
(408) 525-4113
tvargas at cisco.com
-------------- next part --------------
 my.yugo.Apr.2003.other.info <- read.table(file="/auto/solperf/tgu/ActiveParsedFiles/yugo/Apr.2003/other.info", sep="=", header=TRUE)
 names(my.yugo.Apr.2003.other.info)
 attach(my.yugo.Apr.2003.other.info)
 bitmap("foo8.bmp",type = "png256",  height = 4, width = 4,)
 par( omi = c(.5,.1,0,0))
 plot(total.views, xlab = "Time", ylab = "Total number of views", main = "yugo's Total number of views Apr.2003", type="l", col="red", xaxt = "n", cex.axis = 1.5, cex.main = 1.25, cex.lab = 1.25) 
 temp <- seq(1, length(Time), by = 144)
 axis(1, at = temp, labels = as.character(Time[temp]), las = 3, cex.axis = 1.5)
 quit()


From SuzieBlatt at netscape.net  Mon Apr  7 21:13:46 2003
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Mon, 07 Apr 2003 15:13:46 -0400
Subject: [R] Segmentation error
Message-ID: <474425BF.6DC9163D.0D1322AF@netscape.net>


Hello,

I'm using library(spatstat) and trying to use ppp on my dataset.  I get a segmentation error when I try to run it.  Any suggestions?  Code below ...

Thanks,
Suzanne
---------------------------------------
dat <- read.delim(file="trees_R2.csv", sep=",", header=1)

P16 <- (dat$Plot == "P1") | (dat$Plot == "P2") | (dat$Plot == "P3")
y94 <- dat$Easting[P16]
x94 <- dat$Northing[P16]

library(spatstat)
F194 <- ppp(x94, y94, c(0, 100), c(0, 50))
a <- allstats(F194, dataname="Field 1 - 1994")
plot(a)


From jfox at mcmaster.ca  Mon Apr  7 20:48:20 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 07 Apr 2003 14:48:20 -0400
Subject: [R] subsetting a dataframe
In-Reply-To: <3E91C338.8090805@siverion.com>
Message-ID: <5.0.2.1.0.20030407144706.028ec698@mcmail.cis.mcmaster.ca>

Dear Chris,

The following should work for you:

         olddf[[colname]] <- NULL

I hope this helps,
  John

At 11:28 AM 4/7/2003 -0700, Chris Handorf wrote:
>How does one remove a column from a data frame when the name of
>the column to remove is stored in a variable?
>
>For Example:
>
>colname <- "LOT"
>
>newdf <- subset(olddf,select = - colname)
>
>The above statement will give an error, but thats what I'm trying to 
>accomplish.
>
>If I had used:
>
>newdf <- subset(olddf,select = - LOT)
>
>then it would have worked, but as I said the column name is stored in a 
>variable
>so I can't just enter it explicity.

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox


From myao at ou.edu  Mon Apr  7 21:33:03 2003
From: myao at ou.edu (Minghua Yao)
Date: Mon, 07 Apr 2003 14:33:03 -0500
Subject: [R] New window for plot()
Message-ID: <HDEPJCAKDEJMEEHKJOKEGECDCAAA.myao@ou.edu>

Hi, 

Can anybody tell me how to open new a new window for plot()? Thanks.

Minghua


From ihaka at stat.auckland.ac.nz  Mon Apr  7 21:52:40 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Tue, 08 Apr 2003 07:52:40 +1200
Subject: [R] graphic question
References: <Pine.SOL.4.21.0304071619300.7797-100000@staff.cs.usyd.edu.au>
Message-ID: <3E91D708.7040207@stat.auckland.ac.nz>

Mama Benchaffai wrote:
> Hi,
> 
> I want to use R for some data mining project , and was wondering if it has
> any intercative graphical features?
> For example, is it possible to plot a histogram and be able to select a
> specific point on it and have all the data about it? or select a specific
> area in a curve and have all the data about it? or possibilities to zoom
> out and in?

Simon Urbanek previewed something called iPlots in Vienna last month.
It may well provide at least some of what you want.  You can find a
paper by Simon and Martin Theus in the DSC proceedings.

http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Drafts/UrbanekTheus.pdf

I'm not sure when the release will happen.

-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand


From ligges at statistik.uni-dortmund.de  Mon Apr  7 21:53:18 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 07 Apr 2003 21:53:18 +0200
Subject: [R] subsetting a dataframe
References: <3E91C338.8090805@siverion.com>
Message-ID: <3E91D72E.80730700@statistik.uni-dortmund.de>



Chris Handorf wrote:
> 
> How does one remove a column from a data frame when the name of
> the column to remove is stored in a variable?
> 
> For Example:
> 
> colname <- "LOT"
> 
> newdf <- subset(olddf,select = - colname)
> 
> The above statement will give an error, but thats what I'm trying to
> accomplish.
> 
> If I had used:
> 
> newdf <- subset(olddf,select = - LOT)
> 
> then it would have worked, but as I said the column name is stored in a
> variable
> so I can't just enter it explicity.

What about
 subset(olddf, select= -get(colname))
or
 olddf[, names(olddf) != colname]

Uwe Ligges


From ligges at statistik.uni-dortmund.de  Mon Apr  7 21:57:28 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 07 Apr 2003 21:57:28 +0200
Subject: [R] New window for plot()
References: <HDEPJCAKDEJMEEHKJOKEGECDCAAA.myao@ou.edu>
Message-ID: <3E91D828.B2192480@statistik.uni-dortmund.de>



Minghua Yao wrote:
> 
> Hi,
> 
> Can anybody tell me how to open new a new window for plot()? Thanks.
> 
> Minghua


E.g. X11(), Macintosh() or windows() to open a new device, depending on
which OS you are.
Please read at least Section 12.6 of "An Introduction to R"! 

Uwe Ligges


From paradis at isem.univ-montp2.fr  Mon Apr  7 22:03:24 2003
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Mon, 07 Apr 2003 22:03:24 +0200
Subject: [R] New window for plot()
In-Reply-To: <HDEPJCAKDEJMEEHKJOKEGECDCAAA.myao@ou.edu>
Message-ID: <4.2.0.58.20030407213821.00b1a2a0@162.38.183.200>

At 14:33 07/04/2003 -0500, vous avez ?crit:
>Hi,
>
>Can anybody tell me how to open new a new window for plot()? Thanks.

x11()

This should work for all operating systems due to alias to the proper function.


>Minghua
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


Emmanuel Paradis
Laboratoire de Pal?ontologie
Institut des Sciences de l'?volution
Universit? Montpellier II
F-34095 Montpellier c?dex 05
France
    phone: +33  4 67 14 39 64
      fax: +33  4 67 14 36 10
   mailto:paradis at isem.univ-montp2.fr
   http://www.isem.univ-montp2.fr/PPP/PPPphylogenie/ParadisHome.php


From gvasudevan at medarex.com  Mon Apr  7 22:04:19 2003
From: gvasudevan at medarex.com (Vasudevan, Geetha)
Date: Mon, 7 Apr 2003 13:04:19 -0700
Subject: [R] New window for plot()
Message-ID: <8249C3256E593D4FB066BB9998D9F7E41CF1B0@ca2-fs03.ca2.2k.medarex.com>


Either x11() or related window() in cmd line opens a new window.

-Geetha.

-----Original Message-----
From:	Minghua Yao [mailto:myao at ou.edu]
Sent:	Mon 4/7/2003 12:33 PM
To:	r-help at stat.math.ethz.ch
Cc:	
Subject:	[R] New window for plot()
Hi, 

Can anybody tell me how to open new a new window for plot()? Thanks.

Minghua

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ligges at statistik.uni-dortmund.de  Mon Apr  7 22:05:34 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 07 Apr 2003 22:05:34 +0200
Subject: [R] Change cex.axis in biplot()
References: <Pine.LNX.4.33.0304071101590.24787-100000@stat56.stat.auckland.ac.nz>
Message-ID: <3E91DA0E.2B313BD0@statistik.uni-dortmund.de>

Ko-Kang Kevin Wang wrote:
> 
> Hi,
> 
> If I do something like:
>   biplot(x, cex.axis = .7)
> then it will only change the font size for axis 1 and 2, but not 3 and 4.
> Is there a way to change the fonts on axis 3 and 4?
> 
> --
> Cheers,
> 
> Kevin

Yes.

1) Provide a patch for biplot.default(). The lines containing
    axis(3, col = col[2])
    axis(4, col = col[2])
are the culprit, obviously.

2) or use

  par(cex.axis=0.7)
  biplot(x)

Uwe Ligges


From jerome at hivnet.ubc.ca  Mon Apr  7 22:35:28 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Mon, 7 Apr 2003 13:35:28 -0700
Subject: [R] Justifying only the X-label
In-Reply-To: <Pine.GSO.4.44.0304071158300.10457-201000@tvargas-u5.cisco.com>
References: <Pine.GSO.4.44.0304071158300.10457-201000@tvargas-u5.cisco.com>
Message-ID: <200304072040.NAA17874@hivnet.ubc.ca>


Use the title() function to write the x label.

plot(1,1,xlab="")
title(xlab="my x label name", adj=1)

Jerome

On April 7, 2003 12:01 pm, Tony Vargas wrote:
> In the attached plot, how do I move just the X-label(Time) to the right.
> Basically, I just want to do a par ( adj = 1) on just the X-label, not
> all my labels.  Any ideas how to accomplish this?
>
> Thanks,
>
> Tony
>
> Tony Vargas
> Cisco Systems
> Engineering Computing Services
> (408) 525-4113
> tvargas at cisco.com
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Mon Apr  7 22:38:44 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 07 Apr 2003 13:38:44 -0700
Subject: [R] subsetting a dataframe
References: <3E91C338.8090805@siverion.com>
Message-ID: <3E91E1D4.9060101@pdf.com>

 > df <- data.frame(a=1, b=2, c=3)
 > df1 <- data.frame(a=1, b=2, c=3)
 > df1[,!is.element(names(df1), "b")]
   a c
1 1 3

Spencer Graves

Chris Handorf wrote:
> How does one remove a column from a data frame when the name of
> the column to remove is stored in a variable?
> 
> For Example:
> 
> colname <- "LOT"
> 
> newdf <- subset(olddf,select = - colname)
> 
> The above statement will give an error, but thats what I'm trying to 
> accomplish.
> 
> If I had used:
> 
> newdf <- subset(olddf,select = - LOT)
> 
> then it would have worked, but as I said the column name is stored in a 
> variable
> so I can't just enter it explicity.
> 
> Thanks.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tvargas at cisco.com  Mon Apr  7 22:57:27 2003
From: tvargas at cisco.com (Tony Vargas)
Date: Mon, 7 Apr 2003 13:57:27 -0700 (PDT)
Subject: [R] Justifying only the X-label
In-Reply-To: <200304072040.NAA17874@hivnet.ubc.ca>
Message-ID: <Pine.GSO.4.44.0304071357200.10983-100000@tvargas-u5.cisco.com>

Worked great . . . thanks for your help.

Tony

Tony Vargas
Cisco Systems
Engineering Computing Services
(408) 525-4113
tvargas at cisco.com

On Mon, 7 Apr 2003, Jerome Asselin wrote:

>
> Use the title() function to write the x label.
>
> plot(1,1,xlab="")
> title(xlab="my x label name", adj=1)
>
> Jerome
>
> On April 7, 2003 12:01 pm, Tony Vargas wrote:
> > In the attached plot, how do I move just the X-label(Time) to the right.
> > Basically, I just want to do a par ( adj = 1) on just the X-label, not
> > all my labels.  Any ideas how to accomplish this?
> >
> > Thanks,
> >
> > Tony
> >
> > Tony Vargas
> > Cisco Systems
> > Engineering Computing Services
> > (408) 525-4113
> > tvargas at cisco.com
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>


From p.dalgaard at biostat.ku.dk  Mon Apr  7 23:09:57 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 07 Apr 2003 23:09:57 +0200
Subject: [R] Segmentation error
In-Reply-To: <474425BF.6DC9163D.0D1322AF@netscape.net>
References: <474425BF.6DC9163D.0D1322AF@netscape.net>
Message-ID: <x2vfxqnhei.fsf@biostat.ku.dk>

SuzieBlatt at netscape.net (Suzanne E. Blatt) writes:

> I'm using library(spatstat) and trying to use ppp on my dataset. I
> get a segmentation error when I try to run it. Any suggestions? Code
> below ...

Since you're not showing the data, it is difficult to reproduce your
problem, so you're stuck with debugging it yourself. If you're on
Linux, you can run R under the debugger by starting it with "R -d gdb"
(and then just say "run" to get started). On Windows, it gets harder
and you might find that your time is better spent devising suitable
test data that others could use (please don't send huge data sets in
email!). Also, first check that you have up-to-date versions of R,
spatstat and the packages it requires.

BTW, why aren't you using read.csv to read a CSV file??
 
> dat <- read.delim(file="trees_R2.csv", sep=",", header=1)
> 
> P16 <- (dat$Plot == "P1") | (dat$Plot == "P2") | (dat$Plot == "P3")
> y94 <- dat$Easting[P16]
> x94 <- dat$Northing[P16]
> 
> library(spatstat)
> F194 <- ppp(x94, y94, c(0, 100), c(0, 50))
> a <- allstats(F194, dataname="Field 1 - 1994")
> plot(a)
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From tblackw at umich.edu  Mon Apr  7 23:13:57 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 7 Apr 2003 17:13:57 -0400 (EDT)
Subject: [R] Justifying only the X-label
In-Reply-To: <Pine.GSO.4.44.0304071158300.10457-201000@tvargas-u5.cisco.com>
Message-ID: <Pine.SOL.4.44.0304071703030.16783-100000@timepilot.gpcc.itd.umich.edu>


Without trying to look at the attachment ... I think that
title(xlab= ) does NOT have the flexibility you want, but

  mtext("Time", side=1, line=2, at=range(x)[2], adj=1)

might be enough to plug the new label in wherever you want it.
If you're using some version of the basic  plot()  function to
create the plot in the first place, use argument xlab="" to
suppress the automatic axis label in the center of the axis.
See  help("mtext"), help("title"), etc.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 7 Apr 2003, Tony Vargas wrote:

> In the attached plot, how do I move just the X-label(Time) to the right.
> Basically, I just want to do a par ( adj = 1) on just the X-label, not
> all my labels.  Any ideas how to accomplish this?
>
> Thanks, Tony
>
> Tony Vargas
> Cisco Systems
> Engineering Computing Services
> (408) 525-4113
> tvargas at cisco.com
>


From rvaradha at jhsph.edu  Tue Apr  8 00:21:47 2003
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Mon, 07 Apr 2003 18:21:47 -0400
Subject: [R] How to sort a dataframe?
Message-ID: <77819e7765b4.7765b477819e@jhsph.edu>


How does one sort a dataframe on multiple columns, say you first sort 
on variable 1 and then on variable 2, etc.? Is there a simple, one-
liner to do this?

thanks,
Ravi.

----- Original Message -----
From: Spencer Graves <spencer.graves at pdf.com>
Date: Monday, April 7, 2003 2:07 pm
Subject: Re: [R] How to sort a dataframe?

> > tester <- data.frame(one=c(3,2,1), two=c(2,3,1))
> > tester[order(tester$one),]
>   one two
> 3   1   1
> 2   2   3
> 1   3   2
> >
> Spencer Graves
> 
> Remko Duursma wrote:
> > Dear R-helpers,
> > 
> > for the purpose of plotting a dataframe, i am trying to sort a 
> dataframe by one column, for example
> > 
> > tester <- data.frame(one=c(3,2,1), two=c(2,3,1))
> > 
> > #> tester
> > #  one two
> > #1   3   2
> > #2   2   3
> > #3   1   1
> > 
> > # I want to sort "tester" by column "one", so that i get a dataframe
> > # that looks like:
> > #one two
> > #1    1
> > #2    3
> > #3    2
> > 
> > I know of 'sort' but it can only sort vectors.
> > 
> > Thanks for your help,
> > 
> > Remko Duursma
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From andy_liaw at merck.com  Tue Apr  8 00:32:39 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 07 Apr 2003 18:32:39 -0400
Subject: [R] How to sort a dataframe?
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F959@usrymx25.merck.com>

mydata[order(mydata$col1, mydata$col2, mydata$col3, ...), ]

HTH,
Andy

> -----Original Message-----
> From: Ravi Varadhan [mailto:rvaradha at jhsph.edu]
> Sent: Monday, April 07, 2003 6:22 PM
> To: Spencer Graves
> Cc: rhelp; den.duurs at lycos.com
> Subject: Re: [R] How to sort a dataframe?
> 
> 
> 
> How does one sort a dataframe on multiple columns, say you first sort 
> on variable 1 and then on variable 2, etc.? Is there a simple, one-
> liner to do this?
> 
> thanks,
> Ravi.
> 
> ----- Original Message -----
> From: Spencer Graves <spencer.graves at pdf.com>
> Date: Monday, April 7, 2003 2:07 pm
> Subject: Re: [R] How to sort a dataframe?
> 
> > > tester <- data.frame(one=c(3,2,1), two=c(2,3,1))
> > > tester[order(tester$one),]
> >   one two
> > 3   1   1
> > 2   2   3
> > 1   3   2
> > >
> > Spencer Graves
> > 
> > Remko Duursma wrote:
> > > Dear R-helpers,
> > > 
> > > for the purpose of plotting a dataframe, i am trying to sort a 
> > dataframe by one column, for example
> > > 
> > > tester <- data.frame(one=c(3,2,1), two=c(2,3,1))
> > > 
> > > #> tester
> > > #  one two
> > > #1   3   2
> > > #2   2   3
> > > #3   1   1
> > > 
> > > # I want to sort "tester" by column "one", so that i get 
> a dataframe
> > > # that looks like:
> > > #one two
> > > #1    1
> > > #2    3
> > > #3    2
> > > 
> > > I know of 'sort' but it can only sort vectors.
> > > 
> > > Thanks for your help,
> > > 
> > > Remko Duursma
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------


From spencer.graves at pdf.com  Tue Apr  8 00:44:28 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 07 Apr 2003 15:44:28 -0700
Subject: [R] How to sort a dataframe?
References: <77819e7765b4.7765b477819e@jhsph.edu>
Message-ID: <3E91FF4C.9010804@pdf.com>

 > df1 <- data.frame(a=rep(2:1, 2), b=rep(2:1, each=2), c=1:4)
 > df1[order(df1$b, df1$a),]
   a b c
4 1 1 4
3 2 1 3
2 1 2 2
1 2 2 1

Spencer Graves

Ravi Varadhan wrote:
> How does one sort a dataframe on multiple columns, say you first sort 
> on variable 1 and then on variable 2, etc.? Is there a simple, one-
> liner to do this?
> 
> thanks,
> Ravi.
> 
> ----- Original Message -----
> From: Spencer Graves <spencer.graves at pdf.com>
> Date: Monday, April 7, 2003 2:07 pm
> Subject: Re: [R] How to sort a dataframe?
> 
> 
>>>tester <- data.frame(one=c(3,2,1), two=c(2,3,1))
>>>tester[order(tester$one),]
>>
>>  one two
>>3   1   1
>>2   2   3
>>1   3   2
>>
>>Spencer Graves
>>
>>Remko Duursma wrote:
>>
>>>Dear R-helpers,
>>>
>>>for the purpose of plotting a dataframe, i am trying to sort a 
>>
>>dataframe by one column, for example
>>
>>>tester <- data.frame(one=c(3,2,1), two=c(2,3,1))
>>>
>>>#> tester
>>>#  one two
>>>#1   3   2
>>>#2   2   3
>>>#3   1   1
>>>
>>># I want to sort "tester" by column "one", so that i get a dataframe
>>># that looks like:
>>>#one two
>>>#1    1
>>>#2    3
>>>#3    2
>>>
>>>I know of 'sort' but it can only sort vectors.
>>>
>>>Thanks for your help,
>>>
>>>Remko Duursma
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From p.murrell at auckland.ac.nz  Tue Apr  8 02:24:40 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 08 Apr 2003 12:24:40 +1200
Subject: [R] Justifying only the X-label
References: <Pine.GSO.4.44.0304071158300.10457-201000@tvargas-u5.cisco.com>
Message-ID: <3E9216C8.30708@stat.auckland.ac.nz>

Hi


Tony Vargas wrote:
> In the attached plot, how do I move just the X-label(Time) to the right.
> Basically, I just want to do a par ( adj = 1) on just the X-label, not
> all my labels.  Any ideas how to accomplish this?


I can't replicate your plot exactly because I don't have your data, but 
the following may help [draw the X-label in a separate call to title()]:

	par( omi = c(.5,.1,0,0))
	plot(1:10, xlab = "", ylab = "Total number of views", main = "yugo's 
Total number of views Apr.2003", type="l", col="red", xaxt = "n", 
cex.axis = 1.5, cex.main = 1.25, cex.lab = 1.25)
	temp <- 1:10
	axis(1, at = temp, labels = temp, las = 3, cex.axis = 1.5)
	title(xlab="Time", adj=1, cex.lab=1.25)


Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz


From kjetil at entelnet.bo  Tue Apr  8 03:40:37 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Mon, 07 Apr 2003 21:40:37 -0400
Subject: [R] graphic question
In-Reply-To: <7915315632.20030407184602@poczta.onet.pl>
References: <Pine.SOL.4.21.0304071619300.7797-100000@staff.cs.usyd.edu.au>
Message-ID: <3E91F055.16824.131A462@localhost>

On 7 Apr 2003 at 18:46, Michal Bojanowski wrote:
.
.
.
 
> I guess R is not the best choice for this kind of applications at this
> moment (correct me, if I'm wrong). Interacting with graphs is AFAIK
> limited to the use of locator(). Creating functions, that will provide
> you with some information (what kind?) about plotted data via
> locator(), would require considerable work with coding.
> 
> I've heard, that LispStat is good at this kind of jobs. I don't have
> any experience with it, thats what "rumours" say.

Those "rumours" are certainly true. But something could possible
be done *from* R, using the interface to ggobi. Bit I haven't 
tried that.

Kjetil Halvorsen

> 
> 
> I hope this helps
> and good luck
> 
> 
> 
> m.
> 
> 
> -- 
> Best regards,
>  Michal                            mailto:bojaniss at poczta.onet.pl
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From kwan022 at stat.auckland.ac.nz  Tue Apr  8 03:52:17 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 8 Apr 2003 13:52:17 +1200 (NZST)
Subject: [R] graphic question
In-Reply-To: <3E91F055.16824.131A462@localhost>
Message-ID: <Pine.LNX.4.33.0304081350470.22307-100000@stat61.stat.auckland.ac.nz>

Hi,

On Mon, 7 Apr 2003, kjetil brinchmann halvorsen wrote:

> Those "rumours" are certainly true. But something could possible
> be done *from* R, using the interface to ggobi. Bit I haven't 
> tried that.

It is possible.  I have just written a short guide on this at 
http://www.stat.auckland.ac.nz/~kwan022/pub/gguide.pdf

Although it is intended for Windows users, some of the things mentioned in 
it can be applied to Linux version of GGobi too.

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From joernfischer at gmx.net  Tue Apr  8 04:00:04 2003
From: joernfischer at gmx.net (Joern Fischer)
Date: Tue, 08 Apr 2003 12:00:04 +1000
Subject: [R] truncated poisson in glm / glmmPQL
Message-ID: <5.0.2.1.0.20030408114333.00ab7c20@cres.anu.edu.au>

Hi

I'm a postgrad in ecology, and have recently started to use R. I'm planning 
to model various sets of animal abundance (i.e. count) data in relation to 
habitat data using glm's and/or glmmPQL's. However, some of my potential 
response variables have many zeros. From what I gather the "family = ..." 
option in the command line does not allow for the direct specification of a 
truncated / zero-modified poisson distribution. My problem is probably not 
uncommon, but I could not find anything on truncated poisson distributions 
in the R web pages or documentation.

Does anyone know of a bit of software that someone may have written to deal 
with this problem? I'm interested in modifications to the poisson as well 
as quasipoisson families.

Thanks a lot for your help - Joern.


From ririzarr at jhsph.edu  Tue Apr  8 04:33:31 2003
From: ririzarr at jhsph.edu (Rafael A. Irizarry)
Date: Mon, 07 Apr 2003 22:33:31 -0400 (EDT)
Subject: [R] sweave quesiton
Message-ID: <Pine.GSO.4.10.10304072224220.29778-100000@athena.biostat.jhsph.edu>

if i write a funciton like this

	f <- function(x) Sweave("report.Rnw")

and report.Rnw has an R chunk like this:
	
	<<>>=
	print(x)
	@

i get an error: 'Object "x" not found'. 

is there a way to avoid this
without using assign to create a global variable?

thanks,
rafael


From nirmalg at psu.edu  Tue Apr  8 08:42:28 2003
From: nirmalg at psu.edu (Nirmal Govind)
Date: Mon, 7 Apr 2003 23:42:28 -0700
Subject: [R] spline with multiple predictor vars?
In-Reply-To: <Pine.SOL.3.96.1030407063937.4244C-100000@jupiter.stats.gla.ac.uk>
References: <Pine.SOL.3.96.1030407063937.4244C-100000@jupiter.stats.gla.ac.uk>
Message-ID: <200304072342.28632.nirmalg@psu.edu>

Thanks for all the suggestions.. I will investigate thin plate regression 
splines, gam, mars... would the best references for these be the ones 
mentioned in the help for these?

Thanks,
nirmal


From TyagiAnupam at aol.com  Tue Apr  8 08:44:47 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Tue, 8 Apr 2003 02:44:47 EDT
Subject: [R] Multiple Merge
Message-ID: <169.1ce0f5a5.2bc3c9df@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030408/32ce1b51/attachment.pl

From Friedrich.Leisch at univie.ac.at  Tue Apr  8 09:40:38 2003
From: Friedrich.Leisch at univie.ac.at (Friedrich.Leisch@univie.ac.at)
Date: Tue, 8 Apr 2003 09:40:38 +0200
Subject: [R] sweave quesiton
In-Reply-To: <Pine.GSO.4.10.10304072224220.29778-100000@athena.biostat.jhsph.edu>
References: <Pine.GSO.4.10.10304072224220.29778-100000@athena.biostat.jhsph.edu>
Message-ID: <16018.31990.297155.4316@ci.tuwien.ac.at>

>>>>> On Mon, 07 Apr 2003 22:33:31 -0400 (EDT),
>>>>> Rafael A Irizarry (RAI) wrote:

  > if i write a funciton like this
  > 	f <- function(x) Sweave("report.Rnw")

  > and report.Rnw has an R chunk like this:
	
  > 	<<>>=
  > 	print(x)
  > 	@

  > i get an error: 'Object "x" not found'. 

  > is there a way to avoid this
  > without using assign to create a global variable?

Not at the moment, because all Sweave evaluations are done in the
global environment.

.f

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik & DSS                Tel: (+43 1) 4277 38613
Universit?t Wien  		            Fax: (+43 1) 4277 38639
Universit?tsstra?e 5                  Friedrich.Leisch at univie.ac.at
1010 Wien, Austria     http://mailbox.univie.ac.at/Friedrich.Leisch
-------------------------------------------------------------------


From Isabelle.ZABALZA-MEZGHANI at ifp.fr  Tue Apr  8 10:21:45 2003
From: Isabelle.ZABALZA-MEZGHANI at ifp.fr (ZABALZA-MEZGHANI Isabelle)
Date: Tue, 8 Apr 2003 10:21:45 +0200 
Subject: [R] density ranges for uniform law
Message-ID: <488C02265C6AD611BF200002A542182F022B337C@irnts22.ifp.fr>

Hello,

I would have some details and explanations about the results I get.
In fact, I start with a uniform sample between -1 and 1, and then plot its
density.
My problem is that the density ranges are much more longer than I expected :

samp <- runif(10000,-1,1)
plot(density(samp))

Instead of varying between -1 and 1, the density varies between approximaly
-1.5 and 1.5
Could someone explain me what is happening ? Maybe some arguments for
density estimation need to be set ?

Waiting for an answer,
Thanks in advance

Isabelle.

Isabelle Zabalza-Mezghani, PhD
IFP - Research Reservoir Engineer


From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Apr  8 08:36:39 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 8 Apr 2003 08:36:39 +0200 (CEST)
Subject: [R] problem with mvtnorm installation
In-Reply-To: <3E91B548.5010900@ensam.inra.fr>
References: <3E91B548.5010900@ensam.inra.fr>
Message-ID: <Pine.LNX.4.51.0304080830340.5798@artemis.imbe.med.uni-erlangen.de>

> Hi all,
>
> I tried to install the mvtnorm library on linux (mandrake version) and i
> obtained the following result :
>
> /usr/bin/ld: cannot find -lreadline
> collect2: ld returned 1 exit status
> make: *** [mvtnorm.so] Erreur 1
> ERROR: compilation failed for package 'mvtnorm'
>

You are using a precompiled binary of R and expect it to know about your
local system configuration when compiling packages sources. In this
special case, readline was installed at compile time but is not at
runtime. Install the readline shared libraries and
header files (something like 'libreadline4-dev') and this problem should
be gone. Alternatively, install R from its sources which is always a good
idea ... This issue was discussed on r-help several times, wasn't it,
Dirk? ;-)

best,

Torsten

> Could you help me ?
> Best regards,
> Olivier
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>


From ripley at stats.ox.ac.uk  Tue Apr  8 10:56:08 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Apr 2003 09:56:08 +0100 (BST)
Subject: [R] truncated poisson in glm / glmmPQL
In-Reply-To: <5.0.2.1.0.20030408114333.00ab7c20@cres.anu.edu.au>
Message-ID: <Pine.LNX.4.44.0304080953200.4611-100000@gannet.stats>

The short answer is the the model(s) you want to fit are not glms, so 
neither glm() nor glmmPQL() can be adapted (easily) to fit them.

I think your first task is understand what a glm is.  Then I suggest
specifying precisely what you do want and using maximum-likelihood
estimation (e.g. via optim).

On Tue, 8 Apr 2003, Joern Fischer wrote:

> I'm a postgrad in ecology, and have recently started to use R. I'm planning 
> to model various sets of animal abundance (i.e. count) data in relation to 
> habitat data using glm's and/or glmmPQL's. However, some of my potential 
> response variables have many zeros. From what I gather the "family = ..." 
> option in the command line does not allow for the direct specification of a 
> truncated / zero-modified poisson distribution. My problem is probably not 
> uncommon, but I could not find anything on truncated poisson distributions 
> in the R web pages or documentation.
> 
> Does anyone know of a bit of software that someone may have written to deal 
> with this problem? I'm interested in modifications to the poisson as well 
> as quasipoisson families.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Roger.Bivand at nhh.no  Tue Apr  8 10:57:47 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 8 Apr 2003 10:57:47 +0200 (CEST)
Subject: [R] density ranges for uniform law
In-Reply-To: <488C02265C6AD611BF200002A542182F022B337C@irnts22.ifp.fr>
Message-ID: <Pine.LNX.4.44.0304081048310.10201-100000@reclus.nhh.no>

On Tue, 8 Apr 2003, ZABALZA-MEZGHANI Isabelle wrote:

> Hello,
> 
> I would have some details and explanations about the results I get.
> In fact, I start with a uniform sample between -1 and 1, and then plot its
> density.
> My problem is that the density ranges are much more longer than I expected :
> 
> samp <- runif(10000,-1,1)
> plot(density(samp))
> 
> Instead of varying between -1 and 1, the density varies between approximaly
> -1.5 and 1.5
> Could someone explain me what is happening ? Maybe some arguments for
> density estimation need to be set ?
> 

Try:

> samp <- runif(10000,-1,1)
> range(samp)
[1] -0.9995812  0.9996801

(for this samp)

> plot(density(samp), ylim=c(0,0.6))
> abline(v=c(-1,1))
> lines(density(samp, cut=0), col="green")
> lines(density(samp, from=-1, to=1), col="red")

So you can add arguments to density() - see help(density) - but they will
not affect the fact that for the chosen bandwidth and kernel, the kernel
will extend outside the data range.

Does:

> samp1 <- runif(10000,-1.5,1.5)
> plot(density(samp1, from=-1, to=1), ylim=c(0,0.6))
> abline(v=c(-1,1))

"look" "better"?

Roger

> Waiting for an answer,
> Thanks in advance
> 
> Isabelle.
> 
> Isabelle Zabalza-Mezghani, PhD
> IFP - Research Reservoir Engineer
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no


From ripley at stats.ox.ac.uk  Tue Apr  8 11:08:40 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Apr 2003 10:08:40 +0100 (BST)
Subject: [R] plot.POSIXct with axes FALSE
In-Reply-To: <3E91658A.17293.12F977D@localhost>
Message-ID: <Pine.LNX.4.44.0304081004080.4635-100000@gannet.stats>

On Mon, 7 Apr 2003, Petr Pikal wrote:

> I have a question regarding POSIX class objects.

[...]

> Why axes = FALSE does not work in case of POSIX classes?

It is not a documented argument to plot.POSIXct!  Don't assume all plot 
methods take all the arguments of plot.default.

You should be using par(xaxt) and friends, as you found out.  Please do
read the documentation if you don't understand your errors.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From zeileis at ci.tuwien.ac.at  Tue Apr  8 11:28:41 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Tue, 8 Apr 2003 11:28:41 +0200
Subject: [R] Is there any Time series change-point estimate in R?
In-Reply-To: <0FBE46098704A242B0DC8FEC4169F9978140D1@s31xs3.systems.smu.edu>
References: <0FBE46098704A242B0DC8FEC4169F9978140D1@s31xs3.systems.smu.edu>
Message-ID: <200304080928.h389SfKk016356@thorin.ci.tuwien.ac.at>

On Saturday 05 April 2003 22:45, Wang, Zhu wrote:

> Thanks.
> I am currentlly investigating the package strucchange.
> My interested change-point is the covariance structure change. Can
> strucchange do that?

No, not really. You might be able to use the functions in strucchange 
to test and estimate variance changes (if you are able to write the 
model as a regression model), but covariance changes are more 
difficult.

> Does strucchange consider Box-Jenkins model?

No, not currently.

Best,
Z

> Zhu Wang
>
> Statistical Science Department
> SMU
>
> 	-----Original Message-----
> 	From: Achim Zeileis [mailto:zeileis at ci.tuwien.ac.at]
> 	Sent: Thu 4/3/2003 3:21 AM
> 	To: Wang, Zhu; r-help at stat.math.ethz.ch
> 	Cc:
> 	Subject: Re: [R] Is there any Time series change-point estimate in
> R?
>
> 	On Tuesday 01 April 2003 18:56, Wang, Zhu wrote:
> 	> Hello,
> 	>
> 	> I am looking for time series non-stationary test and change -
> 	> point estimate. The pachage strucchange seems not serving my
> 	> purpose.
>
> 	This is both very vague. You might find a suitable test for
> 	non-stationarity in tseries. And depending on what you mean by
> 	changepoint, strucchange might be able to do what you want. The
> 	function breakpoints() can estimate breakpoints in linear
> regression models, which includes certain types of models for
> non-stationary time series.
> 	Z
>
> 	> Thanks in advance.
> 	>
> 	> Zhu Wang
> 	>
> 	> Statistical Science Department
> 	> SMU
> 	>
> 	> ______________________________________________
> 	> R-help at stat.math.ethz.ch mailing list
> 	> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> 	______________________________________________
> 	R-help at stat.math.ethz.ch mailing list
> 	https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From otoomet at econ.dk  Tue Apr  8 10:41:58 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Tue, 8 Apr 2003 10:41:58 +0200
Subject: [R] density ranges for uniform law
In-Reply-To: <488C02265C6AD611BF200002A542182F022B337C@irnts22.ifp.fr>
	(message from ZABALZA-MEZGHANI Isabelle on Tue, 8 Apr 2003 10:21:45
	+0200)
References: <488C02265C6AD611BF200002A542182F022B337C@irnts22.ifp.fr>
Message-ID: <200304080841.h388fwY10950@punik.econ.au.dk>

Hi,

 | From: ZABALZA-MEZGHANI Isabelle <Isabelle.ZABALZA-MEZGHANI at ifp.fr>
 | Date: Tue, 8 Apr 2003 10:21:45 +0200 
 | Hello,
 | 
 | I would have some details and explanations about the results I get.
 | In fact, I start with a uniform sample between -1 and 1, and then plot its
 | density.
 | My problem is that the density ranges are much more longer than I expected :
 | 
 | samp <- runif(10000,-1,1)
 | plot(density(samp))
 | 
 | Instead of varying between -1 and 1, the density varies between approximaly
 | -1.5 and 1.5

The density is positive in the interval about (-1.3, 1.3) using the
default bandwidth.  Its value is around 0.5.  I guess you should try
to change bandwidth.  Try

> plot(density(samp, bw=0.1))
> lines(density(samp, bw=0.03), col=2)
> lines(density(samp, bw=0.01), col=3)

best wishes,

Ott

 | Could someone explain me what is happening ? Maybe some arguments for
 | density estimation need to be set ?
 | 
 | Isabelle.


From Ted.Harding at nessie.mcc.ac.uk  Tue Apr  8 11:40:50 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 08 Apr 2003 10:40:50 +0100 (BST)
Subject: [R] density ranges for uniform law
In-Reply-To: <488C02265C6AD611BF200002A542182F022B337C@irnts22.ifp.fr>
Message-ID: <XFMail.030408104050.Ted.Harding@nessie.mcc.ac.uk>

On 08-Apr-03 ZABALZA-MEZGHANI Isabelle wrote:
> samp <- runif(10000,-1,1)
> plot(density(samp))
> 
> Instead of varying between -1 and 1, the density varies between
> approximaly -1.5 and 1.5
> Could someone explain me what is happening ? Maybe some arguments for
> density estimation need to be set ?

density() computes a kernel-density estimate of the density, i.e.
it replaces each observation by a distribution ("kernel") which is
spread out over a certain width on either side of it, and sums these
contributions. Therefore, observations near the ends of the range [-1,1]
are replaced by distributions which extend beyond the range, with the
result you have seen.

There are options to density() which can limit the estimated density
to the range [-1,1]: try

  plot(density(samp,from=-1,to=1))

or

  plot(density(samp,cut=0))

(which both seem to give the same result), though you may not think that
the result looks satisfactory at the ends.

Ideally, for this sort of problem is should be possible to make the width
of the kernel depend on the position (rank) of the observation it is
applied to -- for a uniform distribution in particular the variance
of an order statistic is strongly dependent on its rank (the median
over [-1,1] has variance 1/(n+2), the min or the max has variance
4n/((n+2)*(n+1)^2) approx = 4/(n^2) for a sample of n). If you know
that a sample is from a uniform distribution, the end-points are
very precisely estimated from the extremes of the sample, and a
fixed-width kernel-density estimate will not do justice to this..

I don't know whether this is possible directly with current R functions
(though one can always write one which does it).

I hope this helps,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 08-Apr-03                                       Time: 10:40:50
------------------------------ XFMail ------------------------------


From agata_kubera at hotmail.com  Tue Apr  8 11:57:52 2003
From: agata_kubera at hotmail.com (Agata Kubera)
Date: Tue, 08 Apr 2003 09:57:52 +0000
Subject: [R] R-Installation
Message-ID: <BAY1-F76WbOAxVzYJgm0005f774@hotmail.com>

Sehr geehrte Damen und Herren,

bei der Installation von R bekam ich eine Fehlermeldung:
error creating registry key

Die Installation wurde trotzdem abgeschlossen, beim Versuch R zu starten 
kommt jedoch die nchste Fehlermeldung:

Fatal error: Cant mkdir R_tempDir

Knnen Sie mir helfen?

MfG
Agata Kubera


From pikachoodave at yahoo.co.uk  Tue Apr  8 12:25:46 2003
From: pikachoodave at yahoo.co.uk (=?iso-8859-1?q?Dave=20Caccace?=)
Date: Tue, 8 Apr 2003 11:25:46 +0100 (BST)
Subject: [R] selecting f+gth element.
Message-ID: <20030408102546.5169.qmail@web20713.mail.yahoo.com>

Hallo 
I want to remove the fth, f+pth, f+2pth element from a
vector and I'm not sure how to do this. Any help woudl
be much appreciated!
Thank You,
Dave


From lm.silva at sapo.pt  Tue Apr  8 13:04:38 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Tue, 08 Apr 2003 12:04:38 +0100 (WEST)
Subject: [R] tree plot
Message-ID: <1049799878.3e92acc6b3788@webmail.sapo.pt>

Hello helpers

I have this problem. When I plot a regression tree, some words 
are cutted in the figure. There is an attached file tree.ps to 
see what I'm saying. In the right figure some labels are 
cutted. How can I solve this problem?
--


http://adsl.sapo.pt

-------------- next part --------------
A non-text attachment was scrubbed...
Name: tree.ps
Type: application/postscript
Size: 4743 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030408/364d89b8/tree.ps

From kwan022 at stat.auckland.ac.nz  Tue Apr  8 14:17:13 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 9 Apr 2003 00:17:13 +1200 (NZST)
Subject: [R] tree plot
In-Reply-To: <1049799878.3e92acc6b3788@webmail.sapo.pt>
Message-ID: <Pine.LNX.4.33.0304090014590.12733-100000@stat56.stat.auckland.ac.nz>

Are you using the tree or the rpart package?  It is better to use rpart 
(and I'm assuming that you did).

You can set the font size when you put the text.  For example suppose you 
have fitted an rpart() regression tree called "iris.rpart", then you can 
do:
  plot(iris.rpart)
  text(iris.rpart, cex = 0.7)
this should show the text properly as the text will be scaled to 70% of 
the original size.  

On Tue, 8 Apr 2003, Luis Silva wrote:

> Date: Tue, 08 Apr 2003 12:04:38 +0100 (WEST)
> From: Luis Silva <lm.silva at sapo.pt>
> To: R help <r-help at stat.math.ethz.ch>
> Subject: [R] tree plot
> 
> Hello helpers
> 
> I have this problem. When I plot a regression tree, some words 
> are cutted in the figure. There is an attached file tree.ps to 
> see what I'm saying. In the right figure some labels are 
> cutted. How can I solve this problem?
> --
> 
> 
> http://adsl.sapo.pt
> 
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From lm.silva at sapo.pt  Tue Apr  8 13:29:41 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Tue, 08 Apr 2003 12:29:41 +0100 (WEST)
Subject: [R] tree plot
Message-ID: <1049801381.3e92b2a584fc0@webmail.sapo.pt>

The left plot is from tree pack and the rigth is from rpart. It 
solved partially my problem. It still cuts "setosa" and the 
text is getting too small...

See attached file
> plot(ir.tr); text(ir.tr,cex=0.7)
> plot(ir.rpart); text(ir.rpart,use.n=TRUE,cex=0.6)

What are the differences between both packages?


} Are you using the tree or the rpart package?  It is
} better to use rpart 
} (and I'm assuming that you did).
} 
} You can set the font size when you put the text.  For
} example suppose you 
} have fitted an rpart() regression tree called
} "iris.rpart", then you can 
} do:
}   plot(iris.rpart)
}   text(iris.rpart, cex = 0.7)
} this should show the text properly as the text will
} be scaled to 70% of 
} the original size.  
} 
} On Tue, 8 Apr 2003, Luis Silva wrote:
} 
} > Date: Tue, 08 Apr 2003 12:04:38 +0100 (WEST)
} > From: Luis Silva <lm.silva at sapo.pt>
} > To: R help <r-help at stat.math.ethz.ch>
} > Subject: [R] tree plot
} > 
} > Hello helpers
} > 
} > I have this problem. When I plot a regression tree,
} some words 
} > are cutted in the figure. There is an attached file
} tree.ps to 
} > see what I'm saying. In the right figure some
} labels are 
} > cutted. How can I solve this problem?
} > --
} > 
} > 
} > http://adsl.sapo.pt
} > 
} > 
} 
} -- 
} Cheers,
} 
} Kevin
} 
}
} --------------------------------------------------------------
----------------
} /* Time is the greatest teacher, unfortunately it
} kills its students */
} 
} --
} Ko-Kang Kevin Wang
} Master of Science (MSc) Student
} SLC Tutor and Lab Demonstrator
} Department of Statistics
} University of Auckland
} New Zealand
} Homepage: http://www.stat.auckland.ac.nz/~kwan022
} Ph: 373-7599
}     x88475 (City)
}     x88480 (Tamaki)
} 
} 
} 

--


http://adsl.sapo.pt

-------------- next part --------------
A non-text attachment was scrubbed...
Name: tree.ps
Type: application/postscript
Size: 4758 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20030408/df219f33/tree.ps

From ripley at stats.ox.ac.uk  Tue Apr  8 14:00:59 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Apr 2003 13:00:59 +0100 (BST)
Subject: [R] tree plot
In-Reply-To: <1049801381.3e92b2a584fc0@webmail.sapo.pt>
Message-ID: <Pine.LNX.4.44.0304081257310.6408-100000@gannet.stats>

?par, look at xpd.

I haven't looked at your figures, but if you are plotting in less that the 
full device region you probably ought to both decrease the font size and
remove clipping to the plot region.  You probably want par(xpd=TRUE), and 
you may want to adjust the figure margins too.

On Tue, 8 Apr 2003, Luis Silva wrote:

> The left plot is from tree pack and the rigth is from rpart. It 
> solved partially my problem. It still cuts "setosa" and the 
> text is getting too small...
> 
> See attached file
> > plot(ir.tr); text(ir.tr,cex=0.7)
> > plot(ir.rpart); text(ir.rpart,use.n=TRUE,cex=0.6)
> 
> What are the differences between both packages?
> 
> 
> } Are you using the tree or the rpart package?  It is
> } better to use rpart 
> } (and I'm assuming that you did).
> } 
> } You can set the font size when you put the text.  For
> } example suppose you 
> } have fitted an rpart() regression tree called
> } "iris.rpart", then you can 
> } do:
> }   plot(iris.rpart)
> }   text(iris.rpart, cex = 0.7)
> } this should show the text properly as the text will
> } be scaled to 70% of 
> } the original size.  
> } 
> } On Tue, 8 Apr 2003, Luis Silva wrote:
> } 
> } > Date: Tue, 08 Apr 2003 12:04:38 +0100 (WEST)
> } > From: Luis Silva <lm.silva at sapo.pt>
> } > To: R help <r-help at stat.math.ethz.ch>
> } > Subject: [R] tree plot
> } > 
> } > Hello helpers
> } > 
> } > I have this problem. When I plot a regression tree,
> } some words 
> } > are cutted in the figure. There is an attached file
> } tree.ps to 
> } > see what I'm saying. In the right figure some
> } labels are 
> } > cutted. How can I solve this problem?
> } > --
> } > 
> } > 
> } > http://adsl.sapo.pt
> } > 
> } > 
> } 
> } -- 
> } Cheers,
> } 
> } Kevin
> } 
> }
> } --------------------------------------------------------------
> ----------------
> } /* Time is the greatest teacher, unfortunately it
> } kills its students */
> } 
> } --
> } Ko-Kang Kevin Wang
> } Master of Science (MSc) Student
> } SLC Tutor and Lab Demonstrator
> } Department of Statistics
> } University of Auckland
> } New Zealand
> } Homepage: http://www.stat.auckland.ac.nz/~kwan022
> } Ph: 373-7599
> }     x88475 (City)
> }     x88480 (Tamaki)
> } 
> } 
> } 
> 
> --
> 
> 
> http://adsl.sapo.pt
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Tue Apr  8 14:09:57 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Apr 2003 13:09:57 +0100 (BST)
Subject: [R] Scalar vs. vector
In-Reply-To: <5.2.0.9.2.20030407075040.00b675c8@postoffice.pacbell.net>
Message-ID: <Pine.LNX.4.44.0304081307090.6408-100000@gannet.stats>

On Mon, 7 Apr 2003, Chris Fehily wrote:

> Do these statements yield identical types of objects?
>    x = 3
> and
>    y = c(3)
> 
> That is, intrinsically, is x, like y, a vector of length one, but created 
> with abbreviated syntax?

Yes.  c() is a function which here is doing nothing useful.

> More simply: Are scalars really trivial vectors?

Thare are no scalar variables in S.  Since there are vectors of length 
zero, those of length one are not `really trivial' in comparison.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From v_bill_pikounis at merck.com  Tue Apr  8 14:14:12 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Tue, 08 Apr 2003 08:14:12 -0400
Subject: [R] dump.frames & .Traceback information
Message-ID: <E827328028C66044B4998F2EC353CD30031853CB@usrymx12.merck.com>

Thanks to the nice examples shown on the ?dump.frames help page and to the
design of R, one can devise an error handling strategy when R is called
non-interactively to return run-time error information to a calling program
(e.g. CGI with Perl as the calling program).

So if I run R 1.6.2 under Linux with something like "R --vanilla --silent <
inputfile > outputfile" where no .RData has been previously created, and
there is an execution error, is it correct that:

1)  The object .Traceback will not be created and thus a traceback() call
included in an options("error") custom redefinition will always yield the
message "No traceback available?"

The more important second question for me comes from the following: Let us
say that I use dump.frames() in the custom error handler and create a
"last.dump" object of class "dump.frames". Then debugger() shows that
names(last.dump) will output a list of available environments to browse.  

2) Are the descriptive lines produced by names(last.dump) essentially the
same content that traceback() would give in the analogous *interactive*
execution of the same code?

A code snippet example is below.

Thanks very much in advance,
Bill 

Code example:

cmdline.errorhandler <- function() {
  dump.frames(to.file=FALSE)
  sink("results.Rerror")

  ## next 7 lines copied directly from debugger() body	
  if (length(msg <- attr(last.dump, "error.message"))) {
    cat("Message: ", msg, "\n")
  }
  n <- length(last.dump)
  calls <- names(last.dump)
  cat("Available environments had calls:\n")
  cat(paste(1:n, ": ", calls, sep = ""), sep = "\n")
  ##

  traceback() ## does not seem to find a .Traceback object	
  sink()
  save.image() ## saves last current state
  invisible()
}

options(error = quote({cmdline.errorhandler(); q()}))

----------------------------------------
Bill Pikounis, Ph.D.
Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY84-16  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

v_bill_pikounis at merck.com

Phone: 732 594 3913
Fax: 732 594 1565


------------------------------------------------------------------------------


From p.dalgaard at biostat.ku.dk  Tue Apr  8 14:29:42 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Apr 2003 14:29:42 +0200
Subject: [R] Scalar vs. vector
In-Reply-To: <5.2.0.9.2.20030407075040.00b675c8@postoffice.pacbell.net>
References: <5.2.0.9.2.20030407075040.00b675c8@postoffice.pacbell.net>
Message-ID: <x2he998955.fsf@biostat.ku.dk>

Chris Fehily <fehily at pacbell.net> writes:

> Do these statements yield identical types of objects?
>    x = 3
> and
>    y = c(3)
> 
> That is, intrinsically, is x, like y, a vector of length one, but
> created with abbreviated syntax?

No, y is like x, a vector of length one, only created with an overly
long-winded syntax... 

(c() is for *concatenation*)

> More simply: Are scalars really trivial vectors?

Yes.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From tblackw at umich.edu  Tue Apr  8 14:30:24 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 8 Apr 2003 08:30:24 -0400 (EDT)
Subject: [R] Scalar vs. vector
In-Reply-To: <5.2.0.9.2.20030407075040.00b675c8@postoffice.pacbell.net>
Message-ID: <Pine.SOL.4.44.0304080828290.15883-100000@mspacman.gpcc.itd.umich.edu>

Yes, scalars are really trivial vectors.

On Mon, 7 Apr 2003, Chris Fehily wrote:

> Do these statements yield identical types of objects?
>    x = 3
> and
>    y = c(3)
>
> That is, intrinsically, is x, like y, a vector of length
> one, but created with abbreviated syntax?
>
> More simply: Are scalars really trivial vectors?
>
> Thanks.
> -chris
>


From tblackw at umich.edu  Tue Apr  8 14:47:35 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 8 Apr 2003 08:47:35 -0400 (EDT)
Subject: [R] naming an operation inside a function
In-Reply-To: <20030407170800.24543.qmail@web20706.mail.yahoo.com>
Message-ID: <Pine.SOL.4.44.0304080832310.15883-100000@mspacman.gpcc.itd.umich.edu>


I don't understand what it would mean to "name" a specific
operation inside a function, so that you could "call it"
later on.

It's perfectly possible to define and use one function
inside the scope of another.  E.g.

conditional.plot <- function(cond, ...)
   {  if (cond[1]) plot(...) else hist(...)  }

(Poorly designed example, since it depends on having
named arguments "x" or "x" and "y" in ... for correct
execution of the plotting commands, and, in its present
form, doesn't use that as part of the condition ... but.)

Ah, with this example I can see that one reason why you
might want to do this is if you want the side effects of
function.a or function.b, such as a plot, rather than
their return values.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 7 Apr 2003, [iso-8859-1] Dave Caccace wrote:

>  Thank you for you previous help :)
>
> I now need ot know how i can name a specific operation
> inside a function. i am using the if(cond){}else{}
> construction and would like to name it. However if i
> do assign a name to it and then call it later onm in
> the function, it is not recognised. does any one have
> any idea why?
> Thank you,
> Dave


From robert at ishoptech.com  Tue Apr  8 15:31:10 2003
From: robert at ishoptech.com (Robert Trembath)
Date: Tue, 08 Apr 2003 08:31:10 -0500
Subject: [R] Looking for Experienced R programmer for Houston-based BioTech
	company
Message-ID: <3E92CF1E.7040706@ishoptech.com>

Biostatistician / Software Developer (Biotechnology)

We currently have an opening for a team player to assist in the 
development of our Web-based analytical software products. The ideal 
candidate would have a strong background in statistics, molecular 
microbiology, genetics, or bioinformatics, and database development.
Application development experience with the statistical packages S+ and 
R, and software development experience with Linux, PHP, Apache, MySQL, 
Java, Flash, Perl, C, C++ would be a plus. We offer competitive 
compensation and excellent benefits.
Please e-mail your resume to: info at bacbarcodes.com or fax to: (713) 
467-7766. EOE m/f/d/v. Principals only.


From sundar.dorai-raj at pdf.com  Tue Apr  8 15:36:18 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 08 Apr 2003 08:36:18 -0500
Subject: [R] selecting f+gth element.
References: <20030408102546.5169.qmail@web20713.mail.yahoo.com>
Message-ID: <3E92D052.2080403@pdf.com>



Dave Caccace wrote:
> Hallo 
> I want to remove the fth, f+pth, f+2pth element from a
> vector and I'm not sure how to do this. Any help woudl
> be much appreciated!
> Thank You,
> Dave


x <- x[- c(f, f+p, f+2*p)]

Sundar


From lm.silva at sapo.pt  Tue Apr  8 15:40:57 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Tue, 08 Apr 2003 14:40:57 +0100 (WEST)
Subject: [R] tree plot
In-Reply-To: <Pine.LNX.4.44.0304081257310.6408-100000@gannet.stats>
References: <Pine.LNX.4.44.0304081257310.6408-100000@gannet.stats>
Message-ID: <1049809257.3e92d1692aa71@webmail.sapo.pt>

xpd solved my problem. thanks! I did not tried post. my purpose 
is not to create a postscript file. thanks anyway

luis

} ?par, look at xpd.
} 
} I haven't looked at your figures, but if you are
} plotting in less that the 
} full device region you probably ought to both
} decrease the font size and
} remove clipping to the plot region.  You probably
} want par(xpd=TRUE), and 
} you may want to adjust the figure margins too.
} 
} On Tue, 8 Apr 2003, Luis Silva wrote:
} 
} > The left plot is from tree pack and the rigth is
} from rpart. It 
} > solved partially my problem. It still cuts "setosa"
} and the 
} > text is getting too small...
} > 
} > See attached file
} > > plot(ir.tr); text(ir.tr,cex=0.7)
} > > plot(ir.rpart);
} text(ir.rpart,use.n=TRUE,cex=0.6)
} > 
} > What are the differences between both packages?
} > 
} > 
} > } Are you using the tree or the rpart package?  It
} is
} > } better to use rpart 
} > } (and I'm assuming that you did).
} > } 
} > } You can set the font size when you put the text. 
} For
} > } example suppose you 
} > } have fitted an rpart() regression tree called
} > } "iris.rpart", then you can 
} > } do:
} > }   plot(iris.rpart)
} > }   text(iris.rpart, cex = 0.7)
} > } this should show the text properly as the text
} will
} > } be scaled to 70% of 
} > } the original size.  
} > } 
} > } On Tue, 8 Apr 2003, Luis Silva wrote:
} > } 
} > } > Date: Tue, 08 Apr 2003 12:04:38 +0100 (WEST)
} > } > From: Luis Silva <lm.silva at sapo.pt>
} > } > To: R help <r-help at stat.math.ethz.ch>
} > } > Subject: [R] tree plot
} > } > 
} > } > Hello helpers
} > } > 
} > } > I have this problem. When I plot a regression
} tree,
} > } some words 
} > } > are cutted in the figure. There is an attached
} file
} > } tree.ps to 
} > } > see what I'm saying. In the right figure some
} > } labels are 
} > } > cutted. How can I solve this problem?
} > } > --
} > } > 
} > } > 
} > } > http://adsl.sapo.pt
} > } > 
} > } > 
} > } 
} > } -- 
} > } Cheers,
} > } 
} > } Kevin
} > } 
} > }
} > }
} --------------------------------------------------------------
} > ----------------
} > } /* Time is the greatest teacher, unfortunately
} it
} > } kills its students */
} > } 
} > } --
} > } Ko-Kang Kevin Wang
} > } Master of Science (MSc) Student
} > } SLC Tutor and Lab Demonstrator
} > } Department of Statistics
} > } University of Auckland
} > } New Zealand
} > } Homepage:
} http://www.stat.auckland.ac.nz/~kwan022
} > } Ph: 373-7599
} > }     x88475 (City)
} > }     x88480 (Tamaki)
} > } 
} > } 
} > } 
} > 
} > --
} > 
} > 
} > http://adsl.sapo.pt
} > 
} > 
} 
} -- 
} Brian D. Ripley,                 
} ripley at stats.ox.ac.uk
} Professor of Applied Statistics, 
} http://www.stats.ox.ac.uk/~ripley/
} University of Oxford,             Tel:  +44 1865
} 272861 (self)
} 1 South Parks Road,                     +44 1865
} 272866 (PA)
} Oxford OX1 3TG, UK                Fax:  +44 1865
} 272595
} 
} 

--


http://adsl.sapo.pt


From ripley at stats.ox.ac.uk  Tue Apr  8 15:45:00 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Apr 2003 14:45:00 +0100 (BST)
Subject: [R] Multiple Merge
In-Reply-To: <169.1ce0f5a5.2bc3c9df@aol.com>
Message-ID: <Pine.LNX.4.44.0304081441560.6577-100000@gannet.stats>

On Tue, 8 Apr 2003 TyagiAnupam at aol.com wrote:

> How to merge multiple dataframes with a common column? Merge takes only two 
> dataframes as arguments.
> Something like:
> df <- merge(df1,df2,df3,...,by="ID")

Is that a unique ID the same values of which occur in all the dfs?  Then
it is not a question of merging.  Sort them all on ID and cbind them.

Otherwise you can merge df1 with df2, df12 with df3 etc.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From plxmh at nottingham.ac.uk  Tue Apr  8 16:08:32 2003
From: plxmh at nottingham.ac.uk (Martin Hoyle)
Date: Tue, 08 Apr 2003 15:08:32 +0100
Subject: [R] Basic LME
Message-ID: <se92e5fd.051@ccw0m1.nottingham.ac.uk>

Hello R Users,
I am investigating the basic use of the LME function, using the following example;

Response is Weight, covariate is Age, random factor is Genotype

model.lme <- lme (Weight~Age, random=~ 1|Genotype)

After summary(model.lme), I find that the estimate of Age is 0.098 with p=0.758.

I am comparing the above model with the AOV function;

model.aov <- aov (Weight~Age + Genotype)

I find that the estimate of Age is also 0.098, and p=0.758 as in the LME model above.

So, my questions are;

1: I expected that the LME model would be a better way to analyse this data compared to the AOV model, since Genotype is a random factor. However, I obtain the same parameter estimate and p value for Age. Please can someone tell me why?

2: When using LME, when I am after a p value for the covariate Age, is it better to do the following;

Model.lme2 <- lme (Weight~Age, random=~ 1|Genotype, method="ML")
Model.lme3 <- lme (Weight~1, random=~ 1|Genotype, method="ML")
Anova(Model.lme2, Model.lme3)

Giving likelihood ratio=0.102, with p=0.749, which is slightly different to the p values of 0.758 above.


Thanks for your attention,
Martin.


Martin Hoyle,
School of Life and Environmental Sciences,
University of Nottingham,
University Park,
Nottingham,
NG7 2RD,
UK
Webpage: http://myprofile.cos.com/martinhoyle


From ligges at statistik.uni-dortmund.de  Tue Apr  8 16:24:14 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 08 Apr 2003 16:24:14 +0200
Subject: [R] R-Installation
In-Reply-To: <BAY1-F76WbOAxVzYJgm0005f774@hotmail.com>
References: <BAY1-F76WbOAxVzYJgm0005f774@hotmail.com>
Message-ID: <3E92DB8E.1050506@statistik.uni-dortmund.de>

Agata Kubera wrote:
> Sehr geehrte Damen und Herren,

On this list in english, please.


> bei der Installation von R bekam ich eine Fehlermeldung:
> error creating registry key

You need Administrator privileges to add (modify) those registry keys 
(setup tries to do so; those registry keys are unimportant to run R itself).


> Die Installation wurde trotzdem abgeschlossen, beim Versuch R zu starten 
> kommt jedoch die n?chste Fehlermeldung:
> 
> Fatal error: Cant mkdir R_tempDir
> 
> K?nnen Sie mir helfen?

You need write access to your temp-directory (which might be important 
for other software products beside R as well).
If you cannot get write access, see ?tempfile how you can get R to use 
another directory:
"The [temporary] directory [that R uses] will be a subdirectory of the 
first found of the environment variables TMP, TEMP and R_USER (see 
Rconsole)."


> MfG
> Agata Kubera

Uwe Ligges


From spencer.graves at pdf.com  Tue Apr  8 17:11:12 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 08 Apr 2003 08:11:12 -0700
Subject: [R] naming an operation inside a function
References: <20030407170800.24543.qmail@web20706.mail.yahoo.com>
Message-ID: <3E92E690.3010607@pdf.com>

Functions can be defined within (i.e. local to) functions.  If you are 
more specific about what you did, it would be easier for others to help.

Spencer Graves

Dave Caccace wrote:
>  Thank you for you previous help :)
> 
> I now need ot know how i can name a specific operation
> inside a function. i am using the if(cond){}else{}
> construction and would like to name it. However if i
> do assign a name to it and then call it later onm in
> the function, it is not recognised. does any one have
> any idea why?
> Thank you,
> Dave
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From poizot at cnam.fr  Tue Apr  8 17:09:14 2003
From: poizot at cnam.fr (Poizot Emmanuel)
Date: Tue, 8 Apr 2003 17:09:14 +0200
Subject: [R] Modeling the trend and eliminate it
Message-ID: <200304081709.14432.poizot@cnam.fr>

Hi,
I would like to eliminate the trend of a set localised (with x an  y) data.
I try to fit a linear model to the data:
mod.01 <- lm(ff~x+y)
I've got so a model. My question is how can I do to subtract the model from 
the initial f data ?

-- 
Cordialement
----------------------------------------
Emmanuel POIZOT
Cnam/Intechmer
Digue de Collignon
50110 Tourlaville
T?l : (33)(0)2 33 88 73 42
Fax : (33)(0)2 33 88 73 39
-----------------------------------------


From spencer.graves at pdf.com  Tue Apr  8 17:24:37 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 08 Apr 2003 08:24:37 -0700
Subject: [R] Matrix eigenvectors in R and MatLab
References: <000001c2f9f1$84ca9a20$3d9aee82@uu.se.vaxtbio>
	<16013.63438.79519.834830@arbprod.fmr.com>
Message-ID: <3E92E9B5.9000804@pdf.com>

Regarding the relationship between eigen and svd:

	  For symmetric matrices, the svd is a solution to the Eigenvalue 
problem.  However, if eigenvectors are not normalized to length 1, then 
the two solutions will not look the same.

	  Another current question asked about the differences in eigenanalysis 
between R and Matlab.  In sum, it appears that R sorts the eigenvalues 
in decreasing order of absolute values while Matlab does not, but Matlab 
normalizes the eigenvectors to length 1 while R does not.

Spencer Graves

David Brahm wrote:
> Mikael Niva <mikael.niva at ebc.uu.se> wrote:
> 
>>Is there anyone who knows why I get different eigenvectors when I run
>>MatLab and R?
> 
> 
> R orders the eigenvalues by absolute value, which seems sensible; the MatLab
> eigenvalues you gave do not seem to be in any particular order.
> 
> R does not normalize the eigenvectors (as MatLab does), but you can easily do
> so yourself:
> 
> R> PA9900<-c(11/24 ,10/53 ,0/1 ,0/1 ,29/43 ,1/24 ,27/53 ,0/1 ,0/1 ,13/43
> R>   ,14/24 ,178/53 ,146/244 ,17/23 ,15/43 ,2/24 ,4/53 ,0/1 ,2/23 ,2/43 ,4/24
> R>   ,58/53 ,26/244 ,0/1 ,5/43)
> R> PA9900<-matrix(PA9900,nrow=5,byrow=T)
> R> eig <- eigen(PA9900)
> 
> R> eig$values   # Note they are in descending order of absolute value:
> [1]  1.2352970  0.3901522 -0.2562860  0.2259411  0.1742592
> 
> R> sweep(eig$vectors, 2, sqrt(colSums(eig$vectors^2)), "/")
>             [,1]         [,2]        [,3]        [,4]        [,5]
> [1,] -0.22500913 -0.499825704 -0.43295788 -0.18537961 -0.17952679
> [2,] -0.10826756  0.159919608 -0.17713941 -0.05825639 -0.06137926
> [3,] -0.94030246 -0.845706299  0.71911349  0.97075584  0.96165016
> [4,] -0.03271669 -0.096681499  0.07518268 -0.11595437 -0.17499009
> [5,] -0.22893213  0.005790397  0.50832318  0.08017655  0.09279089
> 
> 
> This is the same as the MatLab result you gave, except for 2 things:
> 
> 1) The column order matches the eigenvalue order, so R's columns are in a
>    different order than Matlab's.
> 
> 2) The sign is different for one of the vectors (my column 3, your 2).  The
>    sign of an eigenvector is not well defined, even after normalization.
> 
> MatLab> wmat =
> MatLab>    -0.2250    0.4330   -0.4998   -0.1795   -0.1854
> MatLab>    -0.1083    0.1771    0.1599   -0.0614   -0.0583
> MatLab>    -0.9403   -0.7191   -0.8457    0.9617    0.9708
> MatLab>    -0.0327   -0.0752   -0.0967   -0.1750   -0.1160
> MatLab>    -0.2289   -0.5083    0.0058    0.0928    0.0802
> MatLab> 
> MatLab> dmat =
> MatLab>     1.2353         0         0         0         0
> MatLab>          0   -0.2563         0         0         0
> MatLab>          0         0    0.3902         0         0
> MatLab>          0         0         0    0.1743         0
> MatLab>          0         0         0         0    0.2259
> 
>    Side note: there is some relation between eigenvectors and svd (singular
> value decomposition) which I have not fully grokked yet; if anyone has a simple
> explanation I'd be grateful.


From ripley at stats.ox.ac.uk  Tue Apr  8 17:48:49 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Apr 2003 16:48:49 +0100 (BST)
Subject: [R] Matrix eigenvectors in R and MatLab
In-Reply-To: <3E92E9B5.9000804@pdf.com>
Message-ID: <Pine.LNX.4.44.0304081645360.19145-100000@gannet.stats>

On Tue, 8 Apr 2003, Spencer Graves wrote:

> Regarding the relationship between eigen and svd:
> 
> 	  For symmetric matrices, the svd is a solution to the Eigenvalue 
> problem.  However, if eigenvectors are not normalized to length 1, then 
> the two solutions will not look the same.
> 
> 	  Another current question asked about the differences in eigenanalysis 
> between R and Matlab.  In sum, it appears that R sorts the eigenvalues 
> in decreasing order of absolute values while Matlab does not, but Matlab 
> normalizes the eigenvectors to length 1 while R does not.

The last is not wholly accurate for R 1.6.2 (it only applies to
eigen(symmetric=FALSE)), and the imminent R 1.7.0 will normalize
the eigenvectors (except in back-compatibility mode).

> 
> Spencer Graves
> 
> David Brahm wrote:
> > Mikael Niva <mikael.niva at ebc.uu.se> wrote:
> > 
> >>Is there anyone who knows why I get different eigenvectors when I run
> >>MatLab and R?
> > 
> > 
> > R orders the eigenvalues by absolute value, which seems sensible; the MatLab
> > eigenvalues you gave do not seem to be in any particular order.
> > 
> > R does not normalize the eigenvectors (as MatLab does), but you can easily do
> > so yourself:
> > 
> > R> PA9900<-c(11/24 ,10/53 ,0/1 ,0/1 ,29/43 ,1/24 ,27/53 ,0/1 ,0/1 ,13/43
> > R>   ,14/24 ,178/53 ,146/244 ,17/23 ,15/43 ,2/24 ,4/53 ,0/1 ,2/23 ,2/43 ,4/24
> > R>   ,58/53 ,26/244 ,0/1 ,5/43)
> > R> PA9900<-matrix(PA9900,nrow=5,byrow=T)
> > R> eig <- eigen(PA9900)
> > 
> > R> eig$values   # Note they are in descending order of absolute value:
> > [1]  1.2352970  0.3901522 -0.2562860  0.2259411  0.1742592
> > 
> > R> sweep(eig$vectors, 2, sqrt(colSums(eig$vectors^2)), "/")
> >             [,1]         [,2]        [,3]        [,4]        [,5]
> > [1,] -0.22500913 -0.499825704 -0.43295788 -0.18537961 -0.17952679
> > [2,] -0.10826756  0.159919608 -0.17713941 -0.05825639 -0.06137926
> > [3,] -0.94030246 -0.845706299  0.71911349  0.97075584  0.96165016
> > [4,] -0.03271669 -0.096681499  0.07518268 -0.11595437 -0.17499009
> > [5,] -0.22893213  0.005790397  0.50832318  0.08017655  0.09279089
> > 
> > 
> > This is the same as the MatLab result you gave, except for 2 things:
> > 
> > 1) The column order matches the eigenvalue order, so R's columns are in a
> >    different order than Matlab's.
> > 
> > 2) The sign is different for one of the vectors (my column 3, your 2).  The
> >    sign of an eigenvector is not well defined, even after normalization.
> > 
> > MatLab> wmat =
> > MatLab>    -0.2250    0.4330   -0.4998   -0.1795   -0.1854
> > MatLab>    -0.1083    0.1771    0.1599   -0.0614   -0.0583
> > MatLab>    -0.9403   -0.7191   -0.8457    0.9617    0.9708
> > MatLab>    -0.0327   -0.0752   -0.0967   -0.1750   -0.1160
> > MatLab>    -0.2289   -0.5083    0.0058    0.0928    0.0802
> > MatLab> 
> > MatLab> dmat =
> > MatLab>     1.2353         0         0         0         0
> > MatLab>          0   -0.2563         0         0         0
> > MatLab>          0         0    0.3902         0         0
> > MatLab>          0         0         0    0.1743         0
> > MatLab>          0         0         0         0    0.2259
> > 
> >    Side note: there is some relation between eigenvectors and svd (singular
> > value decomposition) which I have not fully grokked yet; if anyone has a simple
> > explanation I'd be grateful.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From paulda at BATTELLE.ORG  Tue Apr  8 17:48:57 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Tue, 08 Apr 2003 11:48:57 -0400
Subject: [R] Basic LME
Message-ID: 
 <940250A9EB37A24CBE28D858EF077749136C74@ws-bco-mse3.milky-way.battelle.org>

I'm certainly no expert, but I believe that aov( ) is simply a
front-end to the lm( ) function, which fits fixed-effects linear
models.  As you may know, it is possible to write any ANOVA model
as a regression model with appropriate use of indicator variables
for the various levels of treatments.

So, aov( ) does not, in general, yield results that are comparable
to those generated by lme( ).  You have specified the same _fixed_
effect ( ~ Age ) in both aov( ) and lme( ) which is why they
give you the same parameter estimates for this covariate.

When you perform anova( ) to compare the two lme( ) models, you
are performing a likelihood ratio test.  This is not generally
the same as the F-test/t-test used to evaluate the marginal 
significance of a fixed-effect term in a linear model, which explains 
the difference between the p-values.


Best,
 
  david paul

-----Original Message-----
From: Martin Hoyle [mailto:plxmh at nottingham.ac.uk] 
Sent: Tuesday, April 08, 2003 10:09 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Basic LME


Hello R Users,
I am investigating the basic use of the LME function, using the following
example;

Response is Weight, covariate is Age, random factor is Genotype

model.lme <- lme (Weight~Age, random=~ 1|Genotype)

After summary(model.lme), I find that the estimate of Age is 0.098 with
p=0.758.

I am comparing the above model with the AOV function;

model.aov <- aov (Weight~Age + Genotype)

I find that the estimate of Age is also 0.098, and p=0.758 as in the LME
model above.

So, my questions are;

1: I expected that the LME model would be a better way to analyse this data
compared to the AOV model, since Genotype is a random factor. However, I
obtain the same parameter estimate and p value for Age. Please can someone
tell me why?

2: When using LME, when I am after a p value for the covariate Age, is it
better to do the following;

Model.lme2 <- lme (Weight~Age, random=~ 1|Genotype, method="ML") Model.lme3
<- lme (Weight~1, random=~ 1|Genotype, method="ML") Anova(Model.lme2,
Model.lme3)

Giving likelihood ratio=0.102, with p=0.749, which is slightly different to
the p values of 0.758 above.


Thanks for your attention,
Martin.


Martin Hoyle,
School of Life and Environmental Sciences,
University of Nottingham,
University Park,
Nottingham,
NG7 2RD,
UK
Webpage: http://myprofile.cos.com/martinhoyle

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Tue Apr  8 18:09:59 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Apr 2003 17:09:59 +0100 (BST)
Subject: [R] Basic LME
In-Reply-To: <940250A9EB37A24CBE28D858EF077749136C74@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <Pine.LNX.4.44.0304081702331.19145-100000@gannet.stats>

aov() can also be used with an Error() term, when it is not just a 
front-end to lm and does fits random effects.  (As the help page for 
aov says.)

On Tue, 8 Apr 2003, Paul, David  A wrote:

> I'm certainly no expert, but I believe that aov( ) is simply a
> front-end to the lm( ) function, which fits fixed-effects linear
> models.  As you may know, it is possible to write any ANOVA model
> as a regression model with appropriate use of indicator variables
> for the various levels of treatments.
> 
> So, aov( ) does not, in general, yield results that are comparable
> to those generated by lme( ).  You have specified the same _fixed_
> effect ( ~ Age ) in both aov( ) and lme( ) which is why they
> give you the same parameter estimates for this covariate.

Not really.  The error structure is different, but that may not matter
if there is the right nesting/balance in the design. After all `randomized 
block designs' are random effects normally analysed as fixed effects, and 
the results are the same.

> When you perform anova( ) to compare the two lme( ) models, you
> are performing a likelihood ratio test.  This is not generally
> the same as the F-test/t-test used to evaluate the marginal 
> significance of a fixed-effect term in a linear model, which explains 
> the difference between the p-values.

(and those lme fits were by ML rather than the default REML used earlier).
In general there are other differences due to the different assumptions 
about error structures, and when there are likelihood-ratio tests would
generally be preferred.

> 
> Best,
>  
>   david paul
> 
> -----Original Message-----
> From: Martin Hoyle [mailto:plxmh at nottingham.ac.uk] 
> Sent: Tuesday, April 08, 2003 10:09 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Basic LME
> 
> 
> Hello R Users,
> I am investigating the basic use of the LME function, using the following
> example;
> 
> Response is Weight, covariate is Age, random factor is Genotype
> 
> model.lme <- lme (Weight~Age, random=~ 1|Genotype)
> 
> After summary(model.lme), I find that the estimate of Age is 0.098 with
> p=0.758.
> 
> I am comparing the above model with the AOV function;
> 
> model.aov <- aov (Weight~Age + Genotype)
> 
> I find that the estimate of Age is also 0.098, and p=0.758 as in the LME
> model above.
> 
> So, my questions are;
> 
> 1: I expected that the LME model would be a better way to analyse this data
> compared to the AOV model, since Genotype is a random factor. However, I
> obtain the same parameter estimate and p value for Age. Please can someone
> tell me why?
> 
> 2: When using LME, when I am after a p value for the covariate Age, is it
> better to do the following;
> 
> Model.lme2 <- lme (Weight~Age, random=~ 1|Genotype, method="ML") Model.lme3
> <- lme (Weight~1, random=~ 1|Genotype, method="ML") Anova(Model.lme2,
> Model.lme3)
> 
> Giving likelihood ratio=0.102, with p=0.749, which is slightly different to
> the p values of 0.758 above.
> 
> 
> Thanks for your attention,
> Martin.
> 
> 
> Martin Hoyle,
> School of Life and Environmental Sciences,
> University of Nottingham,
> University Park,
> Nottingham,
> NG7 2RD,
> UK
> Webpage: http://myprofile.cos.com/martinhoyle
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hdoran at nasdc.org  Tue Apr  8 18:31:12 2003
From: hdoran at nasdc.org (Harold Doran)
Date: Tue, 8 Apr 2003 12:31:12 -0400
Subject: [R] Multilevel Analyses in R
Message-ID: <66578BFC0BA55348B5907A0F798EE9300ED160@ernesto.NASDC.ORG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030408/86d7b284/attachment.pl

From ritz at dina.kvl.dk  Tue Apr  8 18:41:18 2003
From: ritz at dina.kvl.dk (ritz@dina.kvl.dk)
Date: Tue, 8 Apr 2003 16:41:18 -0000
Subject: [R] Basic LME
In-Reply-To: <se92e5fd.051@ccw0m1.nottingham.ac.uk>
Message-ID: <200304081641.SAA21946@sheridan.dina.kvl.dk>

Martin Hoyle <plxmh at nottingham.ac.uk> said:

> Hello R Users,
> I am investigating the basic use of the LME function, using the following 
example;
> 
> Response is Weight, covariate is Age, random factor is Genotype
> 
> model.lme <- lme (Weight~Age, random=~ 1|Genotype)
> 
> After summary(model.lme), I find that the estimate of Age is 0.098 with 
p=0.758.
> 
> I am comparing the above model with the AOV function;
> 
> model.aov <- aov (Weight~Age + Genotype)
> 
> I find that the estimate of Age is also 0.098, and p=0.758 as in the LME 
model above.

Have a look at summary(model.lme), find the "Random Effect:"-part and see 
whether the Genotype variation is close to 0. If so, this would explain why 
the estimates are similar, as the random factor Genotype then has almost 
negligible variation. 

Pinheiro, J. C. and Bates, D. M. (2000): "Mixed-Effects Models in S and S-
PLUS" discuss the merits of the different tests.

Christian


From ripley at stats.ox.ac.uk  Tue Apr  8 18:41:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 8 Apr 2003 17:41:39 +0100 (BST)
Subject: [R] Multilevel Analyses in R
In-Reply-To: <66578BFC0BA55348B5907A0F798EE9300ED160@ernesto.NASDC.ORG>
Message-ID: <Pine.LNX.4.44.0304081740120.19240-100000@gannet.stats>

There are examples in the scripts for the nlme package, and in the scripts 
in the MASS package,  Both are installed in R, and even cover educational 
data.

On Tue, 8 Apr 2003, Harold Doran wrote:

> I am new to R and would like to get some practice analyzing multilevel
> data. I wonder if anyone can point me to a sample data set and command
> lines that I might replicate for a sample session. I would then compare
> my output with HLM output.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jfox at mcmaster.ca  Tue Apr  8 19:00:29 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 08 Apr 2003 13:00:29 -0400
Subject: [R] Multilevel Analyses in R
In-Reply-To: <66578BFC0BA55348B5907A0F798EE9300ED160@ernesto.NASDC.ORG>
Message-ID: <5.1.0.14.2.20030408125748.01e79ab8@mcmail.cis.mcmaster.ca>

Dear Harold,

You might take a look at the appendix on mixed-effect models to my R and 
S-PLUS Companion to Applied Regression; the appendix is available at 
<http://socserv.socsci.mcmaster.ca/jfox/Books/Companion/appendix-mixed-models.pdf>.

I hope that this helps,
  John

At 12:31 PM 4/8/2003 -0400, Harold Doran wrote:
>I am new to R and would like to get some practice analyzing multilevel 
>data. I wonder if anyone can point me to a sample data set and command 
>lines that I might replicate for a sample session. I would then compare my 
>output with HLM output.
>
>Any help is appreciated.
>

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From hdoran at nasdc.org  Tue Apr  8 19:01:25 2003
From: hdoran at nasdc.org (Harold Doran)
Date: Tue, 8 Apr 2003 13:01:25 -0400
Subject: [R] Multilevel Analyses in R
Message-ID: <66578BFC0BA55348B5907A0F798EE9300ED162@ernesto.NASDC.ORG>

John et al

I have already printed it out. This is a very helpful list, thank you.

 
------
Harold C. Doran
Director of Research and Evaluation
New American Schools
675 N. Washington Street, Suite 220
Alexandria, Virginia 22314
703.647.1628
<http://www.edperform.net>  
 
 


-----Original Message-----
From: John Fox [mailto:jfox at mcmaster.ca]
Sent: Tuesday, April 08, 2003 1:00 PM
To: Harold Doran; r-help at stat.math.ethz.ch
Subject: Re: [R] Multilevel Analyses in R


Dear Harold,

You might take a look at the appendix on mixed-effect models to my R and 
S-PLUS Companion to Applied Regression; the appendix is available at 
<http://socserv.socsci.mcmaster.ca/jfox/Books/Companion/appendix-mixed-models.pdf>.

I hope that this helps,
  John

At 12:31 PM 4/8/2003 -0400, Harold Doran wrote:
>I am new to R and would like to get some practice analyzing multilevel 
>data. I wonder if anyone can point me to a sample data set and command 
>lines that I might replicate for a sample session. I would then compare my 
>output with HLM output.
>
>Any help is appreciated.
>

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From p.dalgaard at biostat.ku.dk  Tue Apr  8 19:08:41 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Apr 2003 19:08:41 +0200
Subject: [R] Basic LME
In-Reply-To: <200304081641.SAA21946@sheridan.dina.kvl.dk>
References: <200304081641.SAA21946@sheridan.dina.kvl.dk>
Message-ID: <x2ptnw7w86.fsf@biostat.ku.dk>

<ritz at dina.kvl.dk> writes:

> Martin Hoyle <plxmh at nottingham.ac.uk> said:
> 
> > Hello R Users,
> > I am investigating the basic use of the LME function, using the following 
> example;
> > 
> > Response is Weight, covariate is Age, random factor is Genotype
> > 
> > model.lme <- lme (Weight~Age, random=~ 1|Genotype)
> > 
> > After summary(model.lme), I find that the estimate of Age is 0.098 with 
> p=0.758.
> > 
> > I am comparing the above model with the AOV function;
> > 
> > model.aov <- aov (Weight~Age + Genotype)
> > 
> > I find that the estimate of Age is also 0.098, and p=0.758 as in the LME 
> model above.
> 
> Have a look at summary(model.lme), find the "Random Effect:"-part and see 
> whether the Genotype variation is close to 0. If so, this would explain why 
> the estimates are similar, as the random factor Genotype then has almost 
> negligible variation. 

And, as Brian pointed out (and I'm sure you already know), the
distinctions disappear in an orthogonal design. If the same ages are
recorded for all Genotypes, you get the same results whether you use
lme, lm, aov, or aov with an Error(Genotype) term. Perhaps except for
the DF calculation in lme, but this might be a case it can get right.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From rpeng at stat.ucla.edu  Tue Apr  8 19:15:23 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Tue, 8 Apr 2003 10:15:23 -0700 (PDT)
Subject: [R] Modeling the trend and eliminate it
In-Reply-To: <200304081709.14432.poizot@cnam.fr>
Message-ID: <Pine.GSO.4.10.10304081014190.17955-100000@quetelet.stat.ucla.edu>

residuals(mod.01)

or maybe

ff - fitted(mod.01)

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Tue, 8 Apr 2003, Poizot Emmanuel wrote:

> Hi,
> I would like to eliminate the trend of a set localised (with x an  y) data.
> I try to fit a linear model to the data:
> mod.01 <- lm(ff~x+y)
> I've got so a model. My question is how can I do to subtract the model from 
> the initial f data ?
> 
> -- 
> Cordialement
> ----------------------------------------
> Emmanuel POIZOT
> Cnam/Intechmer
> Digue de Collignon
> 50110 Tourlaville
> Tl : (33)(0)2 33 88 73 42
> Fax : (33)(0)2 33 88 73 39
> -----------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From chris at fonnesbeck.org  Tue Apr  8 21:20:17 2003
From: chris at fonnesbeck.org (Christopher Fonnesbeck)
Date: Tue, 08 Apr 2003 15:20:17 -0400
Subject: [R] Build fails for R 1.6.2: [base-Ex.Rout] Error 1
Message-ID: <3E9320F1.9090607@fonnesbeck.org>

I am trying to build 1.6.2 from source RPM's on RedHat 9, but encounter 
a failure when running the base tests. An inspection of 
base-Ex.Rout.fail reveals the following:

 > ##___ Examples ___:
 >
 > var(1:10)# 9.166667
[1] 9.166667
 >
 > var(1:5,1:5)# 2.5
[1] 2.5
 >
 > ## Two simple vectors
 > cor(1:10,2:11)# == 1
[1] 1
 >
 >
 >  stopifnot(  is.na(var(1)),
+            !is.nan(var(1)))
Error: !is.nan(var(1)) is not TRUE
Execution halted

Any ideas?

TIA,
chris fonnesbeck
-- 
Christopher J. Fonnesbeck (chris at fonnesbeck.org)
GA Coop. Fish & Wildlife Research Unit, University of Georgia

Oh my friend, what a time is this
To trade the handshake for the fist
	-- Joni Mitchell


From tlumley at u.washington.edu  Tue Apr  8 21:44:00 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 8 Apr 2003 12:44:00 -0700 (PDT)
Subject: [R] Build fails for R 1.6.2: [base-Ex.Rout] Error 1
In-Reply-To: <3E9320F1.9090607@fonnesbeck.org>
Message-ID: <Pine.A41.4.44.0304081238140.77668-100000@homer18.u.washington.edu>

On Tue, 8 Apr 2003, Christopher Fonnesbeck wrote:

> I am trying to build 1.6.2 from source RPM's on RedHat 9, but encounter
> a failure when running the base tests. An inspection of
> base-Ex.Rout.fail reveals the following:
>

>  >
>  >  stopifnot(  is.na(var(1)),
> +            !is.nan(var(1)))
> Error: !is.nan(var(1)) is not TRUE
> Execution halted

Yes. The version of gcc in RedHat 9 will not distinguish NA and NaN at
least sometimes, when optimization is used.  The bug report for RedHat is
at
https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=88174

A fix has been added to the development version of R.


	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From p.dalgaard at biostat.ku.dk  Tue Apr  8 22:36:29 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 08 Apr 2003 22:36:29 +0200
Subject: [R] Build fails for R 1.6.2: [base-Ex.Rout] Error 1
In-Reply-To: <Pine.A41.4.44.0304081238140.77668-100000@homer18.u.washington.edu>
References: <Pine.A41.4.44.0304081238140.77668-100000@homer18.u.washington.edu>
Message-ID: <x2adf0eng2.fsf@biostat.ku.dk>

Thomas Lumley <tlumley at u.washington.edu> writes:

> On Tue, 8 Apr 2003, Christopher Fonnesbeck wrote:
> 
> > I am trying to build 1.6.2 from source RPM's on RedHat 9, but encounter
> > a failure when running the base tests. An inspection of
> > base-Ex.Rout.fail reveals the following:
> >
...
> Yes. The version of gcc in RedHat 9 will not distinguish NA and NaN at
> least sometimes, when optimization is used.  The bug report for RedHat is
> at
> https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=88174
> 
> A fix has been added to the development version of R.

Well, let's call it a workaround. The fix is gcc 3.3.

...but it's a one-liner: Inside the 

static double R_ValueOfNA(void)

in src/main/arithmetic.c

declare x volatile, i.e.

static double R_ValueOfNA(void)
{
    /* The gcc shipping with RedHat 9 gets this wrong without
     * the volatile declaration. Thanks to Marc Schwartz. */
    volatile ieee_double x;
    x.word[hw] = 0x7ff00000;
    x.word[lw] = 1954;
    return x.value;
}


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From jerosenb at hcs.harvard.edu  Tue Apr  8 22:49:10 2003
From: jerosenb at hcs.harvard.edu (janet rosenbaum)
Date: Tue, 8 Apr 2003 16:49:10 -0400 (EDT)
Subject: [R] use of variable labels
Message-ID: <200304082049.h38KnA43016909@hcs.harvard.edu>


The R documentation for some of the foreign package's functions says 
that the set of variable labels becomes attributes in the resulting
data frame.  

Thus, e.g., 5="strongly agree", 4="agree", etc.

I'm happy that the labels are being passed, but unfortunately, when 
R summarizes the data, it will list it only as categories, and
doesn't deal with the corresponding numbers.  It seems as though 
the numbers attached to the categories don't exist.  

Is there a way to make R go back and forth between the categories and 
the corresponding numbers as Stata does, or do I just have to set
convert.factors=FALSE ?

Hope everyone's enjoying the April snow!
Thanks,

Janet

> MC<-read.dta("C:/Documents and Settings/janet/Desktop/poleff/mexchn_gary.dta")
> summary(MC)
       id             country              code         sex     
 Min.   :10100001   Length:1068        Mexico:604   Female:541  
 1st Qu.:10100306   Mode  :character   China :464   Male  :509  
 Median :14000071                                   NA's  : 18  
 Mean   :12305905                                               
 3rd Qu.:14000339                                               
 Max.   :14000628                                               
> mean(MC$id)
[1] 12305905
> mean(MC$sex)
[1] NA
Warning message: 
argument is not numeric or logical: returning NA in: mean.default(MC$sex) 



Stata gives:

. summ

    Variable |     Obs        Mean   Std. Dev.       Min        Max
-------------+-----------------------------------------------------
          id |    1068    1.23e+07    1934101   1.01e+07   1.40e+07
     country |       0
        code |    1068    .4344569   .4959177          0          1
         sex |    1050    1.484762   .5000059          1          2


From mschwartz at medanalytics.com  Tue Apr  8 23:12:22 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 08 Apr 2003 16:12:22 -0500
Subject: [R] Build fails for R 1.6.2: [base-Ex.Rout] Error 1
In-Reply-To: <x2adf0eng2.fsf@biostat.ku.dk>
References: 
	<Pine.A41.4.44.0304081238140.77668-100000@homer18.u.washington.edu>
	<x2adf0eng2.fsf@biostat.ku.dk>
Message-ID: <3E933B36.8090706@medanalytics.com>

Peter Dalgaard BSA wrote:
> Thomas Lumley <tlumley at u.washington.edu> writes:
> 
> 
>>On Tue, 8 Apr 2003, Christopher Fonnesbeck wrote:
>>
>>
>>>I am trying to build 1.6.2 from source RPM's on RedHat 9, but encounter
>>>a failure when running the base tests. An inspection of
>>>base-Ex.Rout.fail reveals the following:
>>>
> 
> ...
> 
>>Yes. The version of gcc in RedHat 9 will not distinguish NA and NaN at
>>least sometimes, when optimization is used.  The bug report for RedHat is
>>at
>>https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=88174
>>
>>A fix has been added to the development version of R.
> 
> 
> Well, let's call it a workaround. The fix is gcc 3.3.
> 
> ...but it's a one-liner: Inside the 
> 
> static double R_ValueOfNA(void)
> 
> in src/main/arithmetic.c
> 
> declare x volatile, i.e.
> 
> static double R_ValueOfNA(void)
> {
>     /* The gcc shipping with RedHat 9 gets this wrong without
>      * the volatile declaration. Thanks to Marc Schwartz. */
>     volatile ieee_double x;
>     x.word[hw] = 0x7ff00000;
>     x.word[lw] = 1954;
>     return x.value;
> }
> 

I can verify that the above change does work for R 1.6.2 and passes make 
check under RH 9.

Chris, download the source tar file from CRAN and as Peter has pointed 
out, make the change in line 119 in arithmetic.c.  Then:

./configure
make
make check
make install

HTH,

Marc Schwartz


From spencer.graves at pdf.com  Tue Apr  8 23:28:57 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 08 Apr 2003 14:28:57 -0700
Subject: [R] use of variable labels
References: <200304082049.h38KnA43016909@hcs.harvard.edu>
Message-ID: <3E933F19.8000701@pdf.com>

 > tst.df <- data.frame(a=letters[1:3], b=factor(c(3:5)))
 > tst.df
   a b
1 a 3
2 b 4
3 c 5
 > as.numeric(tst.df$a)
[1] 1 2 3
 > as.numeric(tst.df$b)
[1] 1 2 3
 > as.character(tst.df$b)
[1] "3" "4" "5"
 > as.numeric(as.character(tst.df$b))
[1] 3 4 5
Does this answer your question?
Spencer Graves

janet rosenbaum wrote:
> The R documentation for some of the foreign package's functions says 
> that the set of variable labels becomes attributes in the resulting
> data frame.  
> 
> Thus, e.g., 5="strongly agree", 4="agree", etc.
> 
> I'm happy that the labels are being passed, but unfortunately, when 
> R summarizes the data, it will list it only as categories, and
> doesn't deal with the corresponding numbers.  It seems as though 
> the numbers attached to the categories don't exist.  
> 
> Is there a way to make R go back and forth between the categories and 
> the corresponding numbers as Stata does, or do I just have to set
> convert.factors=FALSE ?
> 
> Hope everyone's enjoying the April snow!
> Thanks,
> 
> Janet
> 
> 
>>MC<-read.dta("C:/Documents and Settings/janet/Desktop/poleff/mexchn_gary.dta")
>>summary(MC)
> 
>        id             country              code         sex     
>  Min.   :10100001   Length:1068        Mexico:604   Female:541  
>  1st Qu.:10100306   Mode  :character   China :464   Male  :509  
>  Median :14000071                                   NA's  : 18  
>  Mean   :12305905                                               
>  3rd Qu.:14000339                                               
>  Max.   :14000628                                               
> 
>>mean(MC$id)
> 
> [1] 12305905
> 
>>mean(MC$sex)
> 
> [1] NA
> Warning message: 
> argument is not numeric or logical: returning NA in: mean.default(MC$sex) 
> 
> 
> 
> Stata gives:
> 
> . summ
> 
>     Variable |     Obs        Mean   Std. Dev.       Min        Max
> -------------+-----------------------------------------------------
>           id |    1068    1.23e+07    1934101   1.01e+07   1.40e+07
>      country |       0
>         code |    1068    .4344569   .4959177          0          1
>          sex |    1050    1.484762   .5000059          1          2
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From chris at fonnesbeck.org  Tue Apr  8 23:29:15 2003
From: chris at fonnesbeck.org (Christopher Fonnesbeck)
Date: Tue, 08 Apr 2003 17:29:15 -0400
Subject: [R] Build fails for R 1.6.2: [base-Ex.Rout] Error 1
In-Reply-To: <3E933B36.8090706@medanalytics.com>
References: 
	<Pine.A41.4.44.0304081238140.77668-100000@homer18.u.washington.edu>
	<x2adf0eng2.fsf@biostat.ku.dk> <3E933B36.8090706@medanalytics.com>
Message-ID: <3E933F2B.6000403@fonnesbeck.org>

Thanks,

I have made the change; once I build the rpm binary I will submit it to 
Martyn Plummer for the CRAN ftp site.

Chris Fonnesbeck

Marc Schwartz wrote:
> Peter Dalgaard BSA wrote:
> 
>> Thomas Lumley <tlumley at u.washington.edu> writes:
>>
>>
>>> On Tue, 8 Apr 2003, Christopher Fonnesbeck wrote:
>>>
>>>
>>>> I am trying to build 1.6.2 from source RPM's on RedHat 9, but encounter
>>>> a failure when running the base tests. An inspection of
>>>> base-Ex.Rout.fail reveals the following:
>>>>
>>
>> ...
>>
>>> Yes. The version of gcc in RedHat 9 will not distinguish NA and NaN at
>>> least sometimes, when optimization is used.  The bug report for 
>>> RedHat is
>>> at
>>> https://bugzilla.redhat.com/bugzilla/show_bug.cgi?id=88174
>>>
>>> A fix has been added to the development version of R.
>>
>>
>>
>> Well, let's call it a workaround. The fix is gcc 3.3.
>>
>> ...but it's a one-liner: Inside the
>> static double R_ValueOfNA(void)
>>
>> in src/main/arithmetic.c
>>
>> declare x volatile, i.e.
>>
>> static double R_ValueOfNA(void)
>> {
>>     /* The gcc shipping with RedHat 9 gets this wrong without
>>      * the volatile declaration. Thanks to Marc Schwartz. */
>>     volatile ieee_double x;
>>     x.word[hw] = 0x7ff00000;
>>     x.word[lw] = 1954;
>>     return x.value;
>> }
>>
> 
> I can verify that the above change does work for R 1.6.2 and passes make 
> check under RH 9.
> 
> Chris, download the source tar file from CRAN and as Peter has pointed 
> out, make the change in line 119 in arithmetic.c.  Then:
> 
> ./configure
> make
> make check
> make install
> 
> HTH,
> 
> Marc Schwartz
> 
> 
> 
> 
> 

-- 
Christopher J. Fonnesbeck (chris at fonnesbeck.org)
GA Coop. Fish & Wildlife Research Unit, University of Georgia

Oh my friend, what a time is this
To trade the handshake for the fist
	-- Joni Mitchell


From tlumley at u.washington.edu  Tue Apr  8 23:32:48 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 8 Apr 2003 14:32:48 -0700 (PDT)
Subject: [R] use of variable labels
In-Reply-To: <200304082049.h38KnA43016909@hcs.harvard.edu>
Message-ID: <Pine.A41.4.44.0304081425460.77668-100000@homer18.u.washington.edu>

On Tue, 8 Apr 2003, janet rosenbaum wrote:

>
> The R documentation for some of the foreign package's functions says
> that the set of variable labels becomes attributes in the resulting
> data frame.
>
> Thus, e.g., 5="strongly agree", 4="agree", etc.
>
> I'm happy that the labels are being passed, but unfortunately, when
> R summarizes the data, it will list it only as categories, and
> doesn't deal with the corresponding numbers.  It seems as though
> the numbers attached to the categories don't exist.
>
> Is there a way to make R go back and forth between the categories and
> the corresponding numbers as Stata does, or do I just have to set
> convert.factors=FALSE ?

In this particular case I don't see why you would want the numbers, but
the function as.numeric() will extract the underlying numbers from a
factor.

eg
  mean(as.numeric(MC$sex))
or
  mean(as.numeric(MC$code))
should work, but
  mean(MC$sex=="Male")
or
  mean(MC$code=="China")
should also work and seem clearer to me.


	-thomas


From dk.tyler at virgin.net  Tue Apr  8 23:59:01 2003
From: dk.tyler at virgin.net (David Tyler)
Date: Tue, 8 Apr 2003 22:59:01 +0100
Subject: [R] Solving A System of Equations
Message-ID: <000801c2fe1a$12c2db40$ea130150@DLZTYLERHOME>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030408/69e5dab8/attachment.pl

From jerosenb at hcs.harvard.edu  Wed Apr  9 00:01:11 2003
From: jerosenb at hcs.harvard.edu (janet rosenbaum)
Date: Tue, 8 Apr 2003 18:01:11 -0400 (EDT)
Subject: [R] use of variable labels
In-Reply-To: 
	<Pine.A41.4.44.0304081425460.77668-100000@homer18.u.washington.edu> from
	"Thomas Lumley" at Apr 08, 2003 02:32:48 PM
Message-ID: <200304082201.h38M1BKS027575@hcs.harvard.edu>

 
 
> In this particular case I don't see why you would want the numbers, but
> the function as.numeric() will extract the underlying numbers from a
> factor.
 
The mean was just an example.  We have a 4000 line program that expects
numbers.  I was hoping that there would be some way of dealing with this
problem on the level of the data.frame.

I'm guessing I'm just going to have to throw out the labels since it's 
not practical to cast as a number every time and I also just noticed 
something strange about having convert.factors=TRUE:  

When I do 
read.dta("filename.dta")
some of the variables which are numbers are read as NA:
     age         educyrs              
      refuse:   0   refuse:   0   
      DK    :   0   DK    :   0 
      NA's  :1068   NA's  :1068   

When I do
read.dta("filename.dta", convert.factors=FALSE)
the variables are again treated like numbers:

      age           educyrs    
 Min.   :18.00   Min.   : 0.00
 1st Qu.:30.00   1st Qu.: 5.00
 Median :41.00   Median : 9.00
 Mean   :43.18   Mean   : 8.65
 3rd Qu.:54.00   3rd Qu.:12.00
 Max.   :88.00   Max.   :40.00
 NA's   :18.00   NA's   :87.00  

I'm guessing that this means that by default -only- the labels are used 
when convert.factors=TRUE, and even variables without labels have to be
cast as numbers.

Anyhow, thanks so much for the help.  
Thanks,

Janet


From tlumley at u.washington.edu  Wed Apr  9 00:19:06 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 8 Apr 2003 15:19:06 -0700 (PDT)
Subject: [R] use of variable labels
In-Reply-To: <200304082201.h38M1BKS027575@hcs.harvard.edu>
Message-ID: <Pine.A41.4.44.0304081513560.77668-100000@homer18.u.washington.edu>

On Tue, 8 Apr 2003, janet rosenbaum wrote:
>
> The mean was just an example.  We have a 4000 line program that expects
> numbers.  I was hoping that there would be some way of dealing with this
> problem on the level of the data.frame.

as.data.frame(lapply(df,as.numeric))

would work if all your variables were either unlabelled or completely
labelled, but it doesn't seem any simpler than using convert.factors=FALSE

> I'm guessing I'm just going to have to throw out the labels since it's
> not practical to cast as a number every time and I also just noticed
> something strange about having convert.factors=TRUE:
>
> When I do
> read.dta("filename.dta")
> some of the variables which are numbers are read as NA:
>      age         educyrs
>       refuse:   0   refuse:   0
>       DK    :   0   DK    :   0
>       NA's  :1068   NA's  :1068
>
> When I do
> read.dta("filename.dta", convert.factors=FALSE)
> the variables are again treated like numbers:
>
>       age           educyrs
>  Min.   :18.00   Min.   : 0.00
>  1st Qu.:30.00   1st Qu.: 5.00
>  Median :41.00   Median : 9.00
>  Mean   :43.18   Mean   : 8.65
>  3rd Qu.:54.00   3rd Qu.:12.00
>  Max.   :88.00   Max.   :40.00
>  NA's   :18.00   NA's   :87.00
>
> I'm guessing that this means that by default -only- the labels are used
> when convert.factors=TRUE, and even variables without labels have to be
> cast as numbers.

No, that is not the case.  I suspect you have variable labels
declared in Stata for these variables, it's just that the variables don't
take on those values.

read.dta does assume that if any value of a variable has a label then all
values should. It doesn't eg handle labels for different types of missing
on an otherwise numeric variable.

	-thomas


From f0z6305 at labs.tamu.edu  Wed Apr  9 00:28:37 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Tue, 8 Apr 2003 17:28:37 -0500
Subject: [R] Help on smooth.spline?
Message-ID: <007601c2fe1e$32d57880$8bd75ba5@IE.TAMU.EDU>

Hey, R-listers

I was recommended to try using smooth.spline function
for estimating 2-Dimensinal curve given a data set.

So will you please tell me where to get this R function?
Or which package provides this function?

Thanks for your point.

Fred


From f0z6305 at labs.tamu.edu  Wed Apr  9 00:28:37 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Tue, 8 Apr 2003 17:28:37 -0500
Subject: [R] Help on smooth.spline?
Message-ID: <007601c2fe1e$32d57880$8bd75ba5@IE.TAMU.EDU>

Hey, R-listers

I was recommended to try using smooth.spline function
for estimating 2-Dimensinal curve given a data set.

So will you please tell me where to get this R function?
Or which package provides this function?

Thanks for your point.

Fred


From kwan022 at stat.auckland.ac.nz  Wed Apr  9 01:31:18 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 9 Apr 2003 11:31:18 +1200 (NZST)
Subject: [R] Help on smooth.spline?
In-Reply-To: <007601c2fe1e$32d57880$8bd75ba5@IE.TAMU.EDU>
Message-ID: <Pine.LNX.4.33.0304091131070.18048-100000@stat56.stat.auckland.ac.nz>

Have a look at:
> library(modreg)
> ?smooth.spline


On Tue, 8 Apr 2003, Feng Zhang wrote:

> Date: Tue, 8 Apr 2003 17:28:37 -0500
> From: Feng Zhang <f0z6305 at labs.tamu.edu>
> To: R-Help <r-help at stat.math.ethz.ch>
> Subject: [R] Help on smooth.spline?
> 
> Hey, R-listers
> 
> I was recommended to try using smooth.spline function
> for estimating 2-Dimensinal curve given a data set.
> 
> So will you please tell me where to get this R function?
> Or which package provides this function?
> 
> Thanks for your point.
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From sundar.dorai-raj at pdf.com  Wed Apr  9 00:36:50 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 08 Apr 2003 17:36:50 -0500
Subject: [R] Help on smooth.spline?
References: <007601c2fe1e$32d57880$8bd75ba5@IE.TAMU.EDU>
Message-ID: <3E934F02.4060702@pdf.com>

package:modreg

Feng Zhang wrote:
> Hey, R-listers
> 
> I was recommended to try using smooth.spline function
> for estimating 2-Dimensinal curve given a data set.
> 
> So will you please tell me where to get this R function?
> Or which package provides this function?
> 
> Thanks for your point.
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From f0z6305 at labs.tamu.edu  Wed Apr  9 00:47:48 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Tue, 8 Apr 2003 17:47:48 -0500
Subject: [R] Help on smooth.spline?
References: <Pine.LNX.4.33.0304091131070.18048-100000@stat56.stat.auckland.ac.nz>
Message-ID: <007c01c2fe20$e0dd4000$8bd75ba5@IE.TAMU.EDU>

Can I get a smooth estimated curve as the output argument?
For example, if the data set is corrupted by some
noise, I want to estimate a smooth curve from the
noisy data.

----- Original Message -----
From: "Ko-Kang Kevin Wang" <kwan022 at stat.auckland.ac.nz>
To: "Feng Zhang" <f0z6305 at labs.tamu.edu>
Cc: "R-Help" <r-help at stat.math.ethz.ch>
Sent: Tuesday, April 08, 2003 6:31 PM
Subject: Re: [R] Help on smooth.spline?


> Have a look at:
> > library(modreg)
> > ?smooth.spline
>
>
> On Tue, 8 Apr 2003, Feng Zhang wrote:
>
> > Date: Tue, 8 Apr 2003 17:28:37 -0500
> > From: Feng Zhang <f0z6305 at labs.tamu.edu>
> > To: R-Help <r-help at stat.math.ethz.ch>
> > Subject: [R] Help on smooth.spline?
> >
> > Hey, R-listers
> >
> > I was recommended to try using smooth.spline function
> > for estimating 2-Dimensinal curve given a data set.
> >
> > So will you please tell me where to get this R function?
> > Or which package provides this function?
> >
> > Thanks for your point.
> >
> > Fred
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>
> --
> Cheers,
>
> Kevin
>
> --------------------------------------------------------------------------
----
> /* Time is the greatest teacher, unfortunately it kills its students */
>
> --
> Ko-Kang Kevin Wang
> Master of Science (MSc) Student
> SLC Tutor and Lab Demonstrator
> Department of Statistics
> University of Auckland
> New Zealand
> Homepage: http://www.stat.auckland.ac.nz/~kwan022
> Ph: 373-7599
>     x88475 (City)
>     x88480 (Tamaki)
>
>


From jerosenb at hcs.harvard.edu  Wed Apr  9 00:53:15 2003
From: jerosenb at hcs.harvard.edu (janet rosenbaum)
Date: Tue, 8 Apr 2003 18:53:15 -0400 (EDT)
Subject: [R] quotes within quotes
Message-ID: <200304082253.h38MrFpc030075@hcs.harvard.edu>


How does one put quotes within quotes, if it's possible?  
I've tried replacing one set of the quotes by single quotes.

If it's not possible, is there any way to do the following?

 > cmd <- "read.dta"
 > opt <- "convert.factors=FALSE"
 > data.file <- " file="/full/path/name.dta" "
 > eval(call(cmd,data.file,opt))

Prior to adding this option, I had been using match.fun to get the 
function call corresponding to cmd and then evaluating it, but match.fun 
doesn't seem to help here.

Thanks,

Janet


From andy_liaw at merck.com  Wed Apr  9 01:12:11 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 08 Apr 2003 19:12:11 -0400
Subject: [R] Help on smooth.spline?
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F971@usrymx25.merck.com>

PLEASE!!

As if not doing the basic search yourself before posting to R-help wasn't
enough, you  completely failed to follow the rather explicit answers given
to you!

When told to RTFM, please do.

Andy

> -----Original Message-----
> From: Feng Zhang [mailto:f0z6305 at labs.tamu.edu]
> Sent: Tuesday, April 08, 2003 6:48 PM
> To: Ko-Kang Kevin Wang
> Cc: R-Help
> Subject: Re: [R] Help on smooth.spline?
> 
> 
> Can I get a smooth estimated curve as the output argument?
> For example, if the data set is corrupted by some
> noise, I want to estimate a smooth curve from the
> noisy data.
> 
> ----- Original Message -----
> From: "Ko-Kang Kevin Wang" <kwan022 at stat.auckland.ac.nz>
> To: "Feng Zhang" <f0z6305 at labs.tamu.edu>
> Cc: "R-Help" <r-help at stat.math.ethz.ch>
> Sent: Tuesday, April 08, 2003 6:31 PM
> Subject: Re: [R] Help on smooth.spline?
> 
> 
> > Have a look at:
> > > library(modreg)
> > > ?smooth.spline
> >
> >
> > On Tue, 8 Apr 2003, Feng Zhang wrote:
> >
> > > Date: Tue, 8 Apr 2003 17:28:37 -0500
> > > From: Feng Zhang <f0z6305 at labs.tamu.edu>
> > > To: R-Help <r-help at stat.math.ethz.ch>
> > > Subject: [R] Help on smooth.spline?
> > >
> > > Hey, R-listers
> > >
> > > I was recommended to try using smooth.spline function
> > > for estimating 2-Dimensinal curve given a data set.
> > >
> > > So will you please tell me where to get this R function?
> > > Or which package provides this function?
> > >
> > > Thanks for your point.
> > >
> > > Fred
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> >
> > --
> > Cheers,
> >
> > Kevin
> >
> > 
> --------------------------------------------------------------
> ------------
> ----
> > /* Time is the greatest teacher, unfortunately it kills its 
> students */
> >
> > --
> > Ko-Kang Kevin Wang
> > Master of Science (MSc) Student
> > SLC Tutor and Lab Demonstrator
> > Department of Statistics
> > University of Auckland
> > New Zealand
> > Homepage: http://www.stat.auckland.ac.nz/~kwan022
> > Ph: 373-7599
> >     x88475 (City)
> >     x88480 (Tamaki)
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------


From spencer.graves at pdf.com  Wed Apr  9 01:15:55 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 08 Apr 2003 16:15:55 -0700
Subject: [R] quotes within quotes
References: <200304082253.h38MrFpc030075@hcs.harvard.edu>
Message-ID: <3E93582B.6050305@pdf.com>

Two ways:

(a) Use single and double qoutes, e.g., "'" is the character string 
consisting of a single apostrophe, while '"' is the character string 
consisting of a single (double) quote mark.

(b) "\"" == '"'; '\'' == "'"

Also, you example suggests you may wish to try "paste".

Spencer Graves

janet rosenbaum wrote:
> How does one put quotes within quotes, if it's possible?  
> I've tried replacing one set of the quotes by single quotes.
> 
> If it's not possible, is there any way to do the following?
> 
>  > cmd <- "read.dta"
>  > opt <- "convert.factors=FALSE"
>  > data.file <- " file="/full/path/name.dta" "
>  > eval(call(cmd,data.file,opt))
> 
> Prior to adding this option, I had been using match.fun to get the 
> function call corresponding to cmd and then evaluating it, but match.fun 
> doesn't seem to help here.
> 
> Thanks,
> 
> Janet
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From rpeng at stat.ucla.edu  Wed Apr  9 03:39:11 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Tue, 8 Apr 2003 18:39:11 -0700 (PDT)
Subject: [R] quotes within quotes
In-Reply-To: <200304082253.h38MrFpc030075@hcs.harvard.edu>
Message-ID: <Pine.GSO.4.10.10304081836370.21869-100000@quetelet.stat.ucla.edu>

You may want to investigate using do.call().  For example,

do.call("read.dta",list(convert.factors=FALSE, file="/full/path/name.dta"))

Or else, maybe a conbination of paste() and parse()/eval().

-roger
_______________________________
UCLA Department of Statistics
rpeng at stat.ucla.edu
http://www.stat.ucla.edu/~rpeng

On Tue, 8 Apr 2003, janet rosenbaum wrote:

> 
> How does one put quotes within quotes, if it's possible?  
> I've tried replacing one set of the quotes by single quotes.
> 
> If it's not possible, is there any way to do the following?
> 
>  > cmd <- "read.dta"
>  > opt <- "convert.factors=FALSE"
>  > data.file <- " file="/full/path/name.dta" "
>  > eval(call(cmd,data.file,opt))
> 
> Prior to adding this option, I had been using match.fun to get the 
> function call corresponding to cmd and then evaluating it, but match.fun 
> doesn't seem to help here.
> 
> Thanks,
> 
> Janet
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From gisar at nus.edu.sg  Wed Apr  9 04:34:57 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Wed, 9 Apr 2003 10:34:57 +0800
Subject: [R] selecting f+gth element.
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F23B@MBXSRV03.stf.nus.edu.sg>

Try this 

s <- seq(from=f, to=(f+g), by=p) # going in steps of p 
new.data <- data[ ,-s]


-----Original Message-----
From: Dave Caccace [mailto:pikachoodave at yahoo.co.uk] 
Sent: Tuesday, April 08, 2003 6:26 PM
To: r-help at stat.math.ethz.ch
Subject: [R] selecting f+gth element.

Hallo 
I want to remove the fth, f+pth, f+2pth element from a
vector and I'm not sure how to do this. Any help woudl
be much appreciated!
Thank You,
Dave

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From grolemun at fas.harvard.edu  Wed Apr  9 09:25:19 2003
From: grolemun at fas.harvard.edu (Garrett Gman)
Date: Wed, 9 Apr 2003 03:25:19 -0400 (EDT)
Subject: [R] plotting the lognormal density curve
Message-ID: <Pine.OSF.4.44.0304090320580.20222-100000@is05.fas.harvard.edu>

I am trying to plot a lognormal density curve on top of an existing
histogram. Can anybody suggest a simple way to do this? Even if someone
could just explain how to plot a regular normal density curve on top of an
existing histogram, it would be a big help.

Also, is there some way to search through the R-help archives other than
simple browsing?

Thank you so much. Your help and time is greatly appreciated.


From hb at maths.lth.se  Wed Apr  9 09:39:32 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Wed, 9 Apr 2003 09:39:32 +0200
Subject: [R] plotting the lognormal density curve
In-Reply-To: <Pine.OSF.4.44.0304090320580.20222-100000@is05.fas.harvard.edu>
Message-ID: <001b01c2fe6b$294ea190$e502eb82@alpha.wehi.edu.au>

For the normal distribution

N <- 1000
xSamples <- rnorm(N, mean=0, sd=1)
hist(xSamples, freq=FALSE)
curve(dnorm(x, mean=0, sd=1), add=TRUE)

Similar for log normal; dlnorm() & friends.

Cheers

Henrik Bengtsson

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Garrett Gman
> Sent: den 9 april 2003 09:25
> To: r-help at stat.math.ethz.ch
> Subject: [R] plotting the lognormal density curve
> 
> 
> I am trying to plot a lognormal density curve on top of an 
> existing histogram. Can anybody suggest a simple way to do 
> this? Even if someone could just explain how to plot a 
> regular normal density curve on top of an existing histogram, 
> it would be a big help.
> 
> Also, is there some way to search through the R-help archives 
> other than simple browsing?
> 
> Thank you so much. Your help and time is greatly appreciated.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
>


From paradis at isem.univ-montp2.fr  Wed Apr  9 09:44:53 2003
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Wed, 09 Apr 2003 09:44:53 +0200
Subject: [R] plotting the lognormal density curve
Message-ID: <4.2.0.58.20030409094421.00b3f008@162.38.183.200>

At 03:25 09/04/2003 -0400, vous avez ?crit:
>I am trying to plot a lognormal density curve on top of an existing
>histogram. Can anybody suggest a simple way to do this? Even if someone
>could just explain how to plot a regular normal density curve on top of an
>existing histogram, it would be a big help.

There is an example in An Introduction to R:

8.2 Examining the distribution of a set of data



>Also, is there some way to search through the R-help archives other than
>simple browsing?

http://cran.r-project.org/search.html


>Thank you so much. Your help and time is greatly appreciated.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

EP


From Bill.Venables at csiro.au  Wed Apr  9 09:46:38 2003
From: Bill.Venables at csiro.au (Bill.Venables@csiro.au)
Date: Wed, 9 Apr 2003 17:46:38 +1000 
Subject: [R] plotting the lognormal density curve
Message-ID: <E09E527B56BE2D438A3D6A246DDD27A91659F7@roper-cv.qld.cmis.CSIRO.AU>

OK.  You need to start with a "true" histogram, not one of these bastardised
frequency diagrams that hist() by itself produces:

x <- rlnorm(1000, 1, 1)  # for example
r <- range(x)
d <- dlnorm(r[1]:r[2], meanlog = mean(log(x)), sdlog = sd(log(x)))
hist(x, prob = TRUE, ylim = range(d))
lines(r[1]:r[2], d, col="red")


You will most likely get a better result if you evaluate your density at
(exponentials of) many equally spaced points in the range of log(x).

You will also get a much better histogram using

truehist(x, ylim = range(d))

where truehist() comes from the MASS library (thanks to BDR).

Bill Venables.


-----Original Message-----
From: Garrett Gman [mailto:grolemun at fas.harvard.edu]
Sent: Wednesday, April 09, 2003 5:25 PM
To: r-help at stat.math.ethz.ch
Subject: [R] plotting the lognormal density curve


I am trying to plot a lognormal density curve on top of an existing
histogram. Can anybody suggest a simple way to do this? Even if someone
could just explain how to plot a regular normal density curve on top of an
existing histogram, it would be a big help.

Also, is there some way to search through the R-help archives other than
simple browsing?

Thank you so much. Your help and time is greatly appreciated.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From arnaud_amsellem at ssga.com  Wed Apr  9 09:55:56 2003
From: arnaud_amsellem at ssga.com (arnaud_amsellem@ssga.com)
Date: Wed, 9 Apr 2003 08:55:56 +0100
Subject: [R] How to count the number of parameters in a function
Message-ID: <OFAD99F2AA.8B9052DB-ON80256D03.002A9A0E@ssga.statestreet.com>

I have the following function:
Myfunc <- function(var1,var2,.....,varN)
{ .....
}
In the above function I have a variable number of parameters (N>2). How can
I count how many parameters have been entered?

Any help appreciated

Thanks

Arno


From ripley at stats.ox.ac.uk  Wed Apr  9 10:09:07 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 9 Apr 2003 09:09:07 +0100 (BST)
Subject: [R] How to count the number of parameters in a function
In-Reply-To: <OFAD99F2AA.8B9052DB-ON80256D03.002A9A0E@ssga.statestreet.com>
Message-ID: <Pine.LNX.4.44.0304090903030.21144-100000@gannet.stats>

On Wed, 9 Apr 2003 arnaud_amsellem at ssga.com wrote:

> I have the following function:
> Myfunc <- function(var1,var2,.....,varN)
> { .....
> }
> In the above function I have a variable number of parameters (N>2). How can
> I count how many parameters have been entered?

Well, that example will not parse. If you had

Myfunc <- function(...)
{
    dots <- list(...)
    cat("#args is", length(dots), "\n")
}

you would be able to see how it might be done.

Another way is to use match.call(expand.dots=TRUE), as in

Myfunc <- function(...)
{
    Call <- match.call(expand.dots=TRUE)
    cat("#args is", length(Call) - 1, "\n")
}

the first element being the function name.  In this version you can have
named formal arguments and ... .


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Apr  9 10:09:07 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 9 Apr 2003 09:09:07 +0100 (BST)
Subject: [R] How to count the number of parameters in a function
In-Reply-To: <OFAD99F2AA.8B9052DB-ON80256D03.002A9A0E@ssga.statestreet.com>
Message-ID: <Pine.LNX.4.44.0304090903030.21144-100000@gannet.stats>

On Wed, 9 Apr 2003 arnaud_amsellem at ssga.com wrote:

> I have the following function:
> Myfunc <- function(var1,var2,.....,varN)
> { .....
> }
> In the above function I have a variable number of parameters (N>2). How can
> I count how many parameters have been entered?

Well, that example will not parse. If you had

Myfunc <- function(...)
{
    dots <- list(...)
    cat("#args is", length(dots), "\n")
}

you would be able to see how it might be done.

Another way is to use match.call(expand.dots=TRUE), as in

Myfunc <- function(...)
{
    Call <- match.call(expand.dots=TRUE)
    cat("#args is", length(Call) - 1, "\n")
}

the first element being the function name.  In this version you can have
named formal arguments and ... .


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From calenge at biomserv.univ-lyon1.fr  Wed Apr  9 10:09:41 2003
From: calenge at biomserv.univ-lyon1.fr (=?iso-8859-1?Q?Cl=E9ment?= Calenge)
Date: Wed, 09 Apr 2003 10:09:41 +0200
Subject: [R] How to count the number of parameters in a function
In-Reply-To: <OFAD99F2AA.8B9052DB-ON80256D03.002A9A0E@ssga.statestreet.c
 om>
Message-ID: <5.1.0.14.0.20030409100628.00b1a678@biomserv.univ-lyon1.fr>

You can use list(...):

Myfunc<-function(...)
{
d<-list(...)
n<-length(d)
## Other instructions
return(n)
}

##  Example:

var1<-runif(20)
var2<-rnorm(20)
var3<-rpois(20, 2)
Myfunc(var1, var2, var3)

Hope this helps,

Clem.



At 08:55 09/04/2003 +0100, arnaud_amsellem at ssga.com wrote:
>I have the following function:
>Myfunc <- function(var1,var2,.....,varN)
>{ .....
>}
>In the above function I have a variable number of parameters (N>2). How can
>I count how many parameters have been entered?
>
>Any help appreciated
>
>Thanks
>
>Arno
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Apr  9 10:15:05 2003
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 9 Apr 2003 10:15:05 +0200 (CEST)
Subject: [R] How to count the number of parameters in a function
In-Reply-To: <OFAD99F2AA.8B9052DB-ON80256D03.002A9A0E@ssga.statestreet.com>
References: <OFAD99F2AA.8B9052DB-ON80256D03.002A9A0E@ssga.statestreet.com>
Message-ID: <Pine.LNX.4.51.0304091014370.5258@artemis.imbe.med.uni-erlangen.de>

On Wed, 9 Apr 2003 arnaud_amsellem at ssga.com wrote:

> I have the following function:
> Myfunc <- function(var1,var2,.....,varN)
> { .....
> }
> In the above function I have a variable number of parameters (N>2). How can
> I count how many parameters have been entered?
>

using `lm' as example:

length(formals(lm))

best,

Torsten

> Any help appreciated
>
> Thanks
>
> Arno
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>


From poizot at cnam.fr  Wed Apr  9 11:05:05 2003
From: poizot at cnam.fr (Poizot Emmanuel)
Date: Wed, 9 Apr 2003 11:05:05 +0200
Subject: [R] Equation au Fisher Law
Message-ID: <200304091105.05618.poizot@cnam.fr>

Hello,
I would like to know the equation of Fisher law.
Does any body can identicate me where to find it ?
Thanks
-- 
Cordialy
----------------------------------------
Emmanuel POIZOT
Cnam/Intechmer
Digue de Collignon
50110 Tourlaville
T?l : (33)(0)2 33 88 73 42
Fax : (33)(0)2 33 88 73 39
-----------------------------------------


From JonesW at kssg.com  Wed Apr  9 12:56:34 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Wed, 9 Apr 2003 11:56:34 +0100 
Subject: [R] Building function libraries
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB01EE2118@GIMLI>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030409/19bad889/attachment.pl

From ligges at statistik.uni-dortmund.de  Wed Apr  9 13:39:10 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 09 Apr 2003 13:39:10 +0200
Subject: [R] Building function libraries
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB01EE2118@GIMLI>
References: <6B5A9304046AD411BD0200508BDFB6CB01EE2118@GIMLI>
Message-ID: <3E94065E.7020502@statistik.uni-dortmund.de>

Wayne Jones wrote:
> HI there, 
> 
> Does anyone how I can build my own library of R functions?
> 

The manual "Writing R extensions".

Uwe Ligges


> Regards, 
> 
> Wayne
> 
> 
> Dr Wayne R. Jones
> Statistician / Research Analyst
> KSS Group plc
> St James's Buildings
> 79 Oxford Street
> Manchester M1 6SS
> Tel: +44(0)161 609 4084
> Mob: +44(0)7810 523 713
> 
> 
> 
> KSS Ltd
> A division of Knowledge Support Systems Group plc
> Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1 6SS  England
> Company Registration Number 2800886 (Limited) 3449594 (plc)
> Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com		http://www.kssg.com
> 
> 
> The information in this Internet email is confidential and may b... {{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From kurt.sys at rug.ac.be  Wed Apr  9 13:43:28 2003
From: kurt.sys at rug.ac.be (Kurt Sys)
Date: Wed, 9 Apr 2003 13:43:28 +0200
Subject: [R] Building function libraries
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB01EE2118@GIMLI>
References: <6B5A9304046AD411BD0200508BDFB6CB01EE2118@GIMLI>
Message-ID: <16020.1888.404699.989589@ksys.rug.ac.be>

Hello,

It's very simple: read the manual (R-exts.pdf, R extensions):
R CMD build <dir>
with <dir> the name of the directory (which is be the name of your
library), and this directory should be conform the directory structure
one should have to build libraries. To know how this looks like: read
the manual (R-exts.pdf, R extensions):
Function sources in <dir/R>, manual pages sources in <dir/man> ...


Kurt.



--
Mail from Wayne Jones
sent on Wednesday April 9 2003 at 11:56 (GMT+0100):

> 
> HI there,
> 
> Does anyone how I can build my own library of R functions?
> 
> 
> Regards,
> 
> Wayne

-- 
The world would be much nicer if we would trust nature somewhat
more. It seems as if we forgot that the same nature created us.


From Paul.Bliese at NA.AMEDD.ARMY.MIL  Wed Apr  9 15:51:38 2003
From: Paul.Bliese at NA.AMEDD.ARMY.MIL (Bliese, Paul D MAJ WRAIR-Wash DC)
Date: Wed, 9 Apr 2003 09:51:38 -0400 
Subject: [R] Reading in multiple files
Message-ID: <58CAB2332C0DD511BC7900A0C9EA316D013D1A1F@dasmtyjqf009.amedd.army.mil>

I apologize if this is a FAQ -- I kind of recall seeing something along
these lines before, but I couldn't find the message when I searched the
archives.

Problem:
1. I have hundreds of small files in a subdirectory ("c:\\temp") and I would
like to combine the files into a single data frame.
2. Individually, it is easy to read each file
>DATA<-read.csv("c:\\temp\\file1a.csv",header=T)
3. It is also fairly easy to add new files to the data frame one at a time:
>DATA<-rbind(DATA,read.csv("c:\\temp\\file1b.csv",header=T))

What is tedious about this solution is that we have to change the file name
in step 3 every time.

Is there a way to have R identify all the files in a directory and create
one big data frame?

I'm working in Windows with R 1.6.2.

Thanks

Paul
MAJ Paul Bliese, Ph.D.
Walter Reed Army Institute of Research
Phone: (301) 319-9873
Fax: (301) 319-9484
paul.bliese at na.amedd.army.mil


From fredrik.karlsson at ling.umu.se  Wed Apr  9 16:11:33 2003
From: fredrik.karlsson at ling.umu.se (Fredrik Karlsson)
Date: Wed, 9 Apr 2003 16:11:33 +0200
Subject: [R] Reading in multiple files
In-Reply-To: <58CAB2332C0DD511BC7900A0C9EA316D013D1A1F@dasmtyjqf009.amedd.army.mil>
References: <58CAB2332C0DD511BC7900A0C9EA316D013D1A1F@dasmtyjqf009.amedd.army.mil>
Message-ID: <20030409141133.GA3163@ling.umu.se>

Dear Dr. Bliese,

One way is  to loop over the results of list.files(). Look it up in the
manual.

/Fredrik


On Wed, Apr 09, 2003 at 09:51:38AM -0400, Bliese, Paul D MAJ WRAIR-Wash DC wrote:
> I apologize if this is a FAQ -- I kind of recall seeing something along
> these lines before, but I couldn't find the message when I searched the
> archives.
> 
> Problem:
> 1. I have hundreds of small files in a subdirectory ("c:\\temp") and I would
> like to combine the files into a single data frame.
> 2. Individually, it is easy to read each file
> >DATA<-read.csv("c:\\temp\\file1a.csv",header=T)
> 3. It is also fairly easy to add new files to the data frame one at a time:
> >DATA<-rbind(DATA,read.csv("c:\\temp\\file1b.csv",header=T))
> 
> What is tedious about this solution is that we have to change the file name
> in step 3 every time.
> 
> Is there a way to have R identify all the files in a directory and create
> one big data frame?
> 
> I'm working in Windows with R 1.6.2.
> 
> Thanks
> 
> Paul
> MAJ Paul Bliese, Ph.D.
> Walter Reed Army Institute of Research
> Phone: (301) 319-9873
> Fax: (301) 319-9484
> paul.bliese at na.amedd.army.mil
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From andy_liaw at merck.com  Wed Apr  9 16:15:22 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 09 Apr 2003 10:15:22 -0400
Subject: [R] Reading in multiple files
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F975@usrymx25.merck.com>

Try:

tmpf <- list.files("c:/temp")
dat <- read.csv(tmpf[1])
for (f in tmpf[-1]) {
    dat <- rbind(dat, read.csv(f)
}

If the data are all numeric, reading them as matrices could be a lot more
efficient.  Or you can specify the colclass argument to speed up read.csv().

Another way is to concatenate all the files into one (using things like
`cat') outside of R, and read it in at once.

HTH,
Andy


> -----Original Message-----
> From: Bliese, Paul D MAJ WRAIR-Wash DC
> [mailto:Paul.Bliese at na.amedd.army.mil]
> Sent: Wednesday, April 09, 2003 9:52 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Reading in multiple files
> 
> 
> I apologize if this is a FAQ -- I kind of recall seeing 
> something along
> these lines before, but I couldn't find the message when I 
> searched the
> archives.
> 
> Problem:
> 1. I have hundreds of small files in a subdirectory 
> ("c:\\temp") and I would
> like to combine the files into a single data frame.
> 2. Individually, it is easy to read each file
> >DATA<-read.csv("c:\\temp\\file1a.csv",header=T)
> 3. It is also fairly easy to add new files to the data frame 
> one at a time:
> >DATA<-rbind(DATA,read.csv("c:\\temp\\file1b.csv",header=T))
> 
> What is tedious about this solution is that we have to change 
> the file name
> in step 3 every time.
> 
> Is there a way to have R identify all the files in a 
> directory and create
> one big data frame?
> 
> I'm working in Windows with R 1.6.2.
> 
> Thanks
> 
> Paul
> MAJ Paul Bliese, Ph.D.
> Walter Reed Army Institute of Research
> Phone: (301) 319-9873
> Fax: (301) 319-9484
> paul.bliese at na.amedd.army.mil
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------


From tblackw at umich.edu  Wed Apr  9 16:34:39 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 9 Apr 2003 10:34:39 -0400 (EDT)
Subject: [R] Equation au Fisher Law
In-Reply-To: <200304091105.05618.poizot@cnam.fr>
Message-ID: <Pine.SOL.4.44.0304091022530.26413-100000@timepilot.gpcc.itd.umich.edu>

Let  X  be the ratio of independent chi-squared random variables
having k1 and k2 degrees of freedom.  (k1 = numerator, k2 = denominator).
Then  X  has density ... (this will take three lines to type out)

  dF(X)	= [ Gamma((k1 + k2)/2) / (Gamma(k1/2) * Gamma(k2/2)) ]

	* (k1/k2)^(k1/2) * X^((k1/2) - 1)

	* (1 + X * (k1/k2))^-((k1 + k2)/2) * dX

My source is:
Samuel S. Wilks.  Mathematical Statistics.
Wiley, 1962.  equation (7.8.9), p. 186.  q.v.

Probably Google would turn up the same result.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 9 Apr 2003, Poizot Emmanuel wrote:

> Hello,
> I would like to know the equation of Fisher law.
> Does any body can identicate me where to find it ?
> Thanks
> --
> Cordialy
> ----------------------------------------
> Emmanuel POIZOT
> Cnam/Intechmer
> Digue de Collignon
> 50110 Tourlaville
> Tl : (33)(0)2 33 88 73 42
> Fax : (33)(0)2 33 88 73 39
> -----------------------------------------


From vele.samak at citigroup.com  Wed Apr  9 16:41:49 2003
From: vele.samak at citigroup.com (Samak, Vele [EQRE])
Date: Wed, 9 Apr 2003 10:41:49 -0400 
Subject: [R] filtering ts with arima
Message-ID: <D532F841E8DDD311BED00002A51350A40C53A3B3@EXCHNY38.ny.ssmb.com>

Anyone know how to do this? Thanks,

-----Original Message-----
From: Samak, Vele [EQRE] 
Sent: Monday, April 07, 2003 11:30 AM
To: 'r-help at stat.math.ethz.ch'
Subject: [R] filtering ts with arima


Hi,

I have the following code from Splus that I'd like to migrate to R. So far,
the only problem is the arima.filt function. This function allows me to
filter an existing time-series through a previously estimated arima model,
and obtain the residuals for further use. Here's the Splus code:

# x is the estimation time series, new.infl is a timeseries that contains
new information
# a.mle is estimated result (list) from arima.mle, (1,0,1) x (1,0,1)12
seasonal model
mdl 	_ list(list(order=c(1,0,1)), list(order=c(1,0,1), period=12))
a.mle	_ arima.mle(x, model = mdl)

# then, we get regular residuals:
new.pred        _ arima.filt(new.infl, a.mle$model)$pred  
new.res         _ new.infl - new.pred 

The R code from library(ts) would be:

# new.infl is a timeseries
# a.mle is estimated result (list) from arima.mle, (1,0,1) x (1,0,1)12
seasonal model
a2.mle _ arima(x, order=c(1,0,1), seasonal=list(order=c(1,0,1), period=12),
include.mean=F, method="ML")

new.infl ????
new.res         _ new.infl - new.pred 

What's the arima.filt equivalent in R: filter doesn't seem to take the
coefficients for a seasonal model correctly, also predict isn't quite the
answer? Help is appreciated. Thanks,


> Vele Samak
> Vice President
> Global Quantitative Research Group
> CITIGROUP / Smith Barney
> 388 Greenwich St. 29th Floor
> New York, NY 10013
> (212) 816-0379

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Wed Apr  9 16:56:00 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Wed, 9 Apr 2003 15:56:00 +0100 (GMT Daylight Time)
Subject: [R] filtering ts with arima
In-Reply-To: <D532F841E8DDD311BED00002A51350A40C53A3B3@EXCHNY38.ny.ssmb.com>
Message-ID: <Pine.WNT.4.44.0304091550450.2240-100000@gannet.stats.ox.ac.uk>

I know that there is no direct equivalent to arima.filt in R.  I also know
that your R calls are *not* equivalent to the S-PLUS ones.

I would use S-PLUS to run S-PLUS code: you are a commercial operation and
should be able to afford it, Or you could employ an S programmer to convert
the code for you.

As `_' is strongly deprecated in both S-PLUS and R, it should to be used in
postings.

On Wed, 9 Apr 2003, Samak, Vele [EQRE] wrote:

> Anyone know how to do this? Thanks,
>
> -----Original Message-----
> From: Samak, Vele [EQRE]
> Sent: Monday, April 07, 2003 11:30 AM
> To: 'r-help at stat.math.ethz.ch'
> Subject: [R] filtering ts with arima
>
>
> Hi,
>
> I have the following code from Splus that I'd like to migrate to R. So far,
> the only problem is the arima.filt function. This function allows me to
> filter an existing time-series through a previously estimated arima model,
> and obtain the residuals for further use. Here's the Splus code:
>
> # x is the estimation time series, new.infl is a timeseries that contains
> new information
> # a.mle is estimated result (list) from arima.mle, (1,0,1) x (1,0,1)12
> seasonal model
> mdl 	_ list(list(order=c(1,0,1)), list(order=c(1,0,1), period=12))
> a.mle	_ arima.mle(x, model = mdl)
>
> # then, we get regular residuals:
> new.pred        _ arima.filt(new.infl, a.mle$model)$pred
> new.res         _ new.infl - new.pred
>
> The R code from library(ts) would be:
>
> # new.infl is a timeseries
> # a.mle is estimated result (list) from arima.mle, (1,0,1) x (1,0,1)12
> seasonal model
> a2.mle _ arima(x, order=c(1,0,1), seasonal=list(order=c(1,0,1), period=12),
> include.mean=F, method="ML")
>
> new.infl ????
> new.res         _ new.infl - new.pred
>
> What's the arima.filt equivalent in R: filter doesn't seem to take the
> coefficients for a seasonal model correctly, also predict isn't quite the
> answer? Help is appreciated. Thanks,
>
>
> > Vele Samak
> > Vice President
> > Global Quantitative Research Group
> > CITIGROUP / Smith Barney
> > 388 Greenwich St. 29th Floor
> > New York, NY 10013
> > (212) 816-0379
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Wed Apr  9 16:59:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Apr 2003 16:59:03 +0200
Subject: [R] Equation au Fisher Law
In-Reply-To: <Pine.SOL.4.44.0304091022530.26413-100000@timepilot.gpcc.itd.umich.edu>
References: <Pine.SOL.4.44.0304091022530.26413-100000@timepilot.gpcc.itd.umich.edu>
Message-ID: <x2n0iziuo8.fsf@biostat.ku.dk>

Thomas W Blackwell <tblackw at umich.edu> writes:

> Let  X  be the ratio of independent chi-squared random variables
> having k1 and k2 degrees of freedom.  (k1 = numerator, k2 = denominator).
> Then  X  has density ... (this will take three lines to type out)
> 
>   dF(X)	= [ Gamma((k1 + k2)/2) / (Gamma(k1/2) * Gamma(k2/2)) ]
> 
> 	* (k1/k2)^(k1/2) * X^((k1/2) - 1)
> 
> 	* (1 + X * (k1/k2))^-((k1 + k2)/2) * dX
> 
> My source is:
> Samuel S. Wilks.  Mathematical Statistics.
> Wiley, 1962.  equation (7.8.9), p. 186.  q.v.
> 
> Probably Google would turn up the same result.

Not to mention ?FDist... Looks better when printed via LaTeX or in
the PDF version of the reference manual, though. To be specific, p.
213 of 

http://cran.r-project.org/doc/manuals/refman.pdf

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From spencer.graves at pdf.com  Wed Apr  9 17:00:06 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 09 Apr 2003 08:00:06 -0700
Subject: [R] filtering ts with arima
References: <D532F841E8DDD311BED00002A51350A40C53A3B3@EXCHNY38.ny.ssmb.com>
Message-ID: <3E943576.5080205@pdf.com>

Did you try library(ts)?

Spencer Graves

Samak, Vele [EQRE] wrote:
> Anyone know how to do this? Thanks,
> 
> -----Original Message-----
> From: Samak, Vele [EQRE] 
> Sent: Monday, April 07, 2003 11:30 AM
> To: 'r-help at stat.math.ethz.ch'
> Subject: [R] filtering ts with arima
> 
> 
> Hi,
> 
> I have the following code from Splus that I'd like to migrate to R. So far,
> the only problem is the arima.filt function. This function allows me to
> filter an existing time-series through a previously estimated arima model,
> and obtain the residuals for further use. Here's the Splus code:
> 
> # x is the estimation time series, new.infl is a timeseries that contains
> new information
> # a.mle is estimated result (list) from arima.mle, (1,0,1) x (1,0,1)12
> seasonal model
> mdl 	_ list(list(order=c(1,0,1)), list(order=c(1,0,1), period=12))
> a.mle	_ arima.mle(x, model = mdl)
> 
> # then, we get regular residuals:
> new.pred        _ arima.filt(new.infl, a.mle$model)$pred  
> new.res         _ new.infl - new.pred 
> 
> The R code from library(ts) would be:
> 
> # new.infl is a timeseries
> # a.mle is estimated result (list) from arima.mle, (1,0,1) x (1,0,1)12
> seasonal model
> a2.mle _ arima(x, order=c(1,0,1), seasonal=list(order=c(1,0,1), period=12),
> include.mean=F, method="ML")
> 
> new.infl ????
> new.res         _ new.infl - new.pred 
> 
> What's the arima.filt equivalent in R: filter doesn't seem to take the
> coefficients for a seasonal model correctly, also predict isn't quite the
> answer? Help is appreciated. Thanks,
> 
> 
> 
>>Vele Samak
>>Vice President
>>Global Quantitative Research Group
>>CITIGROUP / Smith Barney
>>388 Greenwich St. 29th Floor
>>New York, NY 10013
>>(212) 816-0379
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tblackw at umich.edu  Wed Apr  9 17:14:20 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 9 Apr 2003 11:14:20 -0400 (EDT)
Subject: [R] Solving A System of Equations
In-Reply-To: <000801c2fe1a$12c2db40$ea130150@DLZTYLERHOME>
Message-ID: <Pine.SOL.4.44.0304091047380.26413-100000@timepilot.gpcc.itd.umich.edu>


Maybe there are other R tools, but what I do, repeatedly, is
to work out first and second derivatives w.r.t. x on paper.
Then I execute one step of Newton's method in R, line by line
at the command line, however many lines it takes.  Then use
up-arrow to repeat those command lines for maybe five or six
iterations of Newton's method.  Quick, clear and cheap.

The point is:  start with a four dimensional grid of starting
values for x,y,z,zz.  This can be a four-dimensional array in
which each variable is initially constant wrt the other three.
In subsequent iterations, particular x,y,z,zz quadruples will
either converge toward a solution or diverge, and you can use
standard tests to distinguish between the two.

After you've done this once or twice by hand, at the command
line, then you'll be ready to code up a single Newton step
as a function, then call it an appropriate (fixed) number of
times inside an outer function.  I wouldn't worry about trying
to be adaptive and economize on computer cycles.  All of that
stuff from the older numerical analysis literature is misplaced
effort, in my view, in this day and age.

Other users may know of much fancier methods.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 8 Apr 2003, David Tyler wrote:

> I'm trying to solve a system of 3 equations
> as part of a sub-routine in R, ie
> first eqn a/x-b*sqrtx+c=log(1/dx+1/e(sqrtx);
> snd eqn (f*y)/z-g/y-h=-log(2/x+(z/y)/(i*x)
> and third eqn is of the form zz=x/(j-k(z/y)
> where a..k inclusive are constants, x,y,z
> and zz are inputs.
>
> How can this be done in R?


From tlumley at u.washington.edu  Wed Apr  9 17:29:36 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 9 Apr 2003 08:29:36 -0700 (PDT)
Subject: [R] Reading in multiple files
In-Reply-To: <58CAB2332C0DD511BC7900A0C9EA316D013D1A1F@dasmtyjqf009.amedd.army.mil>
Message-ID: <Pine.A41.4.44.0304090824170.51664-100000@homer27.u.washington.edu>

On Wed, 9 Apr 2003, Bliese, Paul D MAJ WRAIR-Wash DC wrote:

> I apologize if this is a FAQ -- I kind of recall seeing something along
> these lines before, but I couldn't find the message when I searched the
> archives.
>
> Problem:
> 1. I have hundreds of small files in a subdirectory ("c:\\temp") and I would
> like to combine the files into a single data frame.
> 2. Individually, it is easy to read each file
> >DATA<-read.csv("c:\\temp\\file1a.csv",header=T)
> 3. It is also fairly easy to add new files to the data frame one at a time:
> >DATA<-rbind(DATA,read.csv("c:\\temp\\file1b.csv",header=T))
>
> What is tedious about this solution is that we have to change the file name
> in step 3 every time.
>
> Is there a way to have R identify all the files in a directory and create
> one big data frame?

You can get the file list with

   all.the.files <- list.files("C:/temp",full=TRUE)

where full=TRUE asks for absolute file paths, which will be useful if this
isn't your working directory. You could also add pattern="\\.csv$" to
ensure that you only get .csv files.


Then you could read them all in

  all.the.data <- lapply( all.the.files,  read.csv, header=TRUE)

and then rbind them into a data frame

  DATA <- do.call("rbind", all.the.data)

In one line this would be

DATA <- do.call("rbind", lapply( list.files("C:/temp",full=TRUE),
		read.csv, header=TRUE))


It should be faster to use do.call("rbind",) rather than a loop, but I
don't know if it actually is.


	-thomas


From spencer.graves at pdf.com  Wed Apr  9 17:57:17 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 09 Apr 2003 08:57:17 -0700
Subject: [R] Solving A System of Equations
References: <Pine.SOL.4.44.0304091047380.26413-100000@timepilot.gpcc.itd.umich.edu>
Message-ID: <3E9442DD.2090101@pdf.com>

The best method I know is as follows:

1.  Write a function to be minimized, e.g., sum of squares of errors in 
the equations.  If your functions are continuously differentiable, then 
sum of squares is better than sum of absolute values, because the sum of 
squares it is continuous at the minimum while the sum of absolute values 
is not.

2.  If there is any question that there might be multiple local minima, 
then I would implement one of Prof. Blackwell's suggestions, namely 
testing it over an appropriate grid of points.  With only one unknown, I 
make a plot.  With two, I make a contour plot.  With three or more, I 
might try some kind of grid or Monte Carlo.

3.  With some appropriate starting value(s), I then pass the function to 
"optim".  If I want confidence intervals with nonlinear least squares, I 
may pass the output of optim to "nls".  If my objective function is a 
log(likelihood), "optim" will output the Hessian, which is the negative 
of the observed information, whose invers in the approximate covariance 
matrix.

Comments?
Spencer Graves

Thomas W Blackwell wrote:
> Maybe there are other R tools, but what I do, repeatedly, is
> to work out first and second derivatives w.r.t. x on paper.
> Then I execute one step of Newton's method in R, line by line
> at the command line, however many lines it takes.  Then use
> up-arrow to repeat those command lines for maybe five or six
> iterations of Newton's method.  Quick, clear and cheap.
> 
> The point is:  start with a four dimensional grid of starting
> values for x,y,z,zz.  This can be a four-dimensional array in
> which each variable is initially constant wrt the other three.
> In subsequent iterations, particular x,y,z,zz quadruples will
> either converge toward a solution or diverge, and you can use
> standard tests to distinguish between the two.
> 
> After you've done this once or twice by hand, at the command
> line, then you'll be ready to code up a single Newton step
> as a function, then call it an appropriate (fixed) number of
> times inside an outer function.  I wouldn't worry about trying
> to be adaptive and economize on computer cycles.  All of that
> stuff from the older numerical analysis literature is misplaced
> effort, in my view, in this day and age.
> 
> Other users may know of much fancier methods.
> 
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> On Tue, 8 Apr 2003, David Tyler wrote:
> 
> 
>>I'm trying to solve a system of 3 equations
>>as part of a sub-routine in R, ie
>>first eqn a/x-b*sqrtx+c=log(1/dx+1/e(sqrtx);
>>snd eqn (f*y)/z-g/y-h=-log(2/x+(z/y)/(i*x)
>>and third eqn is of the form zz=x/(j-k(z/y)
>>where a..k inclusive are constants, x,y,z
>>and zz are inputs.
>>
>>How can this be done in R?
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From jerosenb at hcs.harvard.edu  Wed Apr  9 18:19:58 2003
From: jerosenb at hcs.harvard.edu (janet rosenbaum)
Date: Wed, 9 Apr 2003 12:19:58 -0400 (EDT)
Subject: [R] quotes within quotes
In-Reply-To: 
	<Pine.GSO.4.10.10304081836370.21869-100000@quetelet.stat.ucla.edu> from "Roger
	Peng" at Apr 08, 2003 06:39:11 PM
Message-ID: <200304091619.h39GJxKC000064@hcs.harvard.edu>

 
Thanks for all the suggestions.  
Some people asked why I'm bothering with all this.  This is just
the toy code I'm trying on the command-line, but the two errors below
are the same as I get in the real code.  

It's true that I could avoid the modularity, but it improves readability
and maintainability immensely.

Here are my results to three suggestions.  The pathnames below are all
abbreviated for readability.

1.  do.call seems to work.  

Both of the following successfully read the data in:

> read.dta("C:/Documents and Settings/mexchn_gary.dta", convert.factors=FALSE)
> do.call("read.dta", list(file="C:/Documents and Settings/mexchn_gary.dta", convert.factors=FALSE))

2.  quotes within quotes:

Correspondants suggested using single quotes or backslashes to escape 
the quotes.  It turns out R interprets both the same way.

> cmd <- "read.dta"
> opt <- "convert.factors=FALSE"
> data.file <- 'file="C:/Documents and Settings/mexchn_gary.dta"'
> do.call(cmd, list(data.file, opt))
Error in read.dta("file=\"C:/Documents and Settings/mexchn_gary.dta\"",  : 
        unable to open file

3.  Avoid using quotes within quotes

When we call read.dta and don't use "file=", it works (see #1), but not 
inside do.call.

> data.file <- "C:/Documents and Settings/mexchn_gary.dta"
> do.call(cmd, list(data.file, opt))
 Error in if (convert.dates) { : argument is not interpretable as
 logical


Thanks,

Janet


From ripley at stats.ox.ac.uk  Wed Apr  9 18:39:05 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 9 Apr 2003 17:39:05 +0100 (BST)
Subject: [R] quotes within quotes
In-Reply-To: <200304091619.h39GJxKC000064@hcs.harvard.edu>
Message-ID: <Pine.LNX.4.44.0304091726400.1108-100000@gannet.stats>

On Wed, 9 Apr 2003, janet rosenbaum wrote:

> Thanks for all the suggestions.  
> Some people asked why I'm bothering with all this.  This is just
> the toy code I'm trying on the command-line, but the two errors below
> are the same as I get in the real code.  

I think those people were right: you seem to be misunderstanding do.call.

> It's true that I could avoid the modularity, but it improves readability
> and maintainability immensely.
> 
> Here are my results to three suggestions.  The pathnames below are all
> abbreviated for readability.
> 
> 1.  do.call seems to work.  
> 
> Both of the following successfully read the data in:
> 
> > read.dta("C:/Documents and Settings/mexchn_gary.dta", convert.factors=FALSE)
> > do.call("read.dta", list(file="C:/Documents and Settings/mexchn_gary.dta", convert.factors=FALSE))
> 
> 2.  quotes within quotes:
> 
> Correspondants suggested using single quotes or backslashes to escape 
> the quotes.  It turns out R interprets both the same way.
> 
> > cmd <- "read.dta"
> > opt <- "convert.factors=FALSE"
> > data.file <- 'file="C:/Documents and Settings/mexchn_gary.dta"'
> > do.call(cmd, list(data.file, opt))
> Error in read.dta("file=\"C:/Documents and Settings/mexchn_gary.dta\"",  : 
>         unable to open file

That's nothing to do with quotes within quotes. You should be giving a 
*named list* to do.call, not a list of "var=value" strings.

> 3.  Avoid using quotes within quotes
> 
> When we call read.dta and don't use "file=", it works (see #1), but not 
> inside do.call.
> 
> > data.file <- "C:/Documents and Settings/mexchn_gary.dta"
> > do.call(cmd, list(data.file, opt))
>  Error in if (convert.dates) { : argument is not interpretable as
>  logical

It's your `opt' which is in the wrong format:
	
cmd <- "read.dta"
cf <- FALSE
data.file <- "C:/Documents and Settings/mexchn_gary.dta"
do.call(cmd, list(file=data.file, convert.factors=cf))

is a correct way to use do.call. You could also do something like

args <- list(data.file, cf)
names(args) <- c("file", "convert.factors")
do.call(cmd, args)

and that's the sort of thing discussed for useful examples in section 3.5 
of `S Programming'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From chrysopa at insecta.ufv.br  Wed Apr  9 21:07:57 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Wed, 9 Apr 2003 16:07:57 -0300
Subject: [R] [OFF] Nested or not nested, this is the question.
Message-ID: <200304091607.58089.chrysopa@insecta.ufv.br>

Hi,

sorry by this off.

I'm still try to understand nested design.

I have the follow example (fiction):

I have 12 plots in 4 sizes in 3 replicates (4*3 = 12)
In each plot I put 2 species (A and B) to reproduce.
After a period I make samples in each board and count the number of 
individuals total (tot) and individuals A and B (nsp). Others individuals 
excepts A and B are in total of individuals.

This make a dataset with the 24 lines and not 12. Its smell pseudoreplication 
in a nested design, OK?

I need to know:

the species are different in proportion?

the size affect the species's proportion?

existe interaction between size and species?

I make the analysis.

> m.lme <- lme(nsp/tot~size*specie,random=~1|size/specie)
> anova(m.lme)
            numDF denDF  F-value p-value
(Intercept)     1    16 374.7121  <.0001
size            1     2  37.8683  0.0254
specie          1     2  18.2036  0.0508
size:specie     1     2   9.3203  0.0926
> 

This is the correct mean to make this analysis?

or

> m.lme <- lme(nsp/tot~size*specie,random=~1|plot/specie)
> anova(m.lme)
            numDF denDF  F-value p-value
(Intercept)     1    10 579.8853  <.0001
size            1    10  58.6030  <.0001
specie          1    10  59.5235  <.0001
size:specie     1    10  30.4760   3e-04
> 

or neither?

I know about the distribution (binomial in this case), but I try to understand 
the nested design.

Thanks for any help.

The dataset is:

   plot size specie nsp tot
1     1   10      A   2  20
2     1   10      B   6  20
3     5   10      A   3  20
4     5   10      B   5  20
5     9   10      A   1  20
6     9   10      B   4  20
7     2   20      A   5  20
8     2   20      B   8  20
9     6   20      A   6  20
10    6   20      B   9  20
11   10   20      A   4  20
12   10   20      B   6  20
13    3   30      A   8  20
14    3   30      B   9  20
15    7   30      A   9  20
16    7   30      B  10  20
17   11   30      A   7  20
18   11   30      B   8  20
19    4   40      A  10  20
20    4   40      B   9  20
21    8   40      A   9  20
22    8   40      B  10  20
23   12   40      A   9  20
24   12   40      B   9  20
-- 
Great minds run in great circles.
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From deli-wang at uiowa.edu  Wed Apr  9 21:32:47 2003
From: deli-wang at uiowa.edu (Deli Wang)
Date: Wed, 9 Apr 2003 14:32:47 -0500
Subject: [R] local weight and coef from LOESS or locfit
Message-ID: <200304091432.47107.deli-wang@uiowa.edu>

Hi, there,

Could someone tell me is there any way to get the local weight , local 
parameters estimation for each  points when using LOESS or locfit packages?

Thank you very much!

Deli


From p.dalgaard at biostat.ku.dk  Wed Apr  9 22:03:20 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 09 Apr 2003 22:03:20 +0200
Subject: [R] [OFF] Nested or not nested, this is the question.
In-Reply-To: <200304091607.58089.chrysopa@insecta.ufv.br>
References: <200304091607.58089.chrysopa@insecta.ufv.br>
Message-ID: <x265pne8vr.fsf@biostat.ku.dk>

"Ronaldo Reis Jr." <chrysopa at insecta.ufv.br> writes:

> I have 12 plots in 4 sizes in 3 replicates (4*3 = 12)
> In each plot I put 2 species (A and B) to reproduce.
> After a period I make samples in each board and count the number of 
> individuals total (tot) and individuals A and B (nsp). Others individuals 
> excepts A and B are in total of individuals.
> 
> This make a dataset with the 24 lines and not 12. Its smell pseudoreplication 
> in a nested design, OK?
> 
> I need to know:
> 
> the species are different in proportion?
> 
> the size affect the species's proportion?
> 
> existe interaction between size and species?
> 
> I make the analysis.
> 
> > m.lme <- lme(nsp/tot~size*specie,random=~1|size/specie)
> > anova(m.lme)
>             numDF denDF  F-value p-value
> (Intercept)     1    16 374.7121  <.0001
> size            1     2  37.8683  0.0254
> specie          1     2  18.2036  0.0508
> size:specie     1     2   9.3203  0.0926
> > 
> 
> This is the correct mean to make this analysis?
> 
> or
> 
> > m.lme <- lme(nsp/tot~size*specie,random=~1|plot/specie)
> > anova(m.lme)
>             numDF denDF  F-value p-value
> (Intercept)     1    10 579.8853  <.0001
> size            1    10  58.6030  <.0001
> specie          1    10  59.5235  <.0001
> size:specie     1    10  30.4760   3e-04
> > 
> 
> or neither?


Neither. First of all, you have numDF = 1 for things that have more
than two levels, so you forgot to make them factors.

reis$plot<-factor(reis$plot)
reis$size<-factor(reis$size)
reis$specie<-factor(reis$specie)

Then you seem to be needing something that describes the replication,
and you're not actually telling us, but if I guess that plots 1-4 is
the 1st replication and 5-8 and 9-12 are the others, then this should
work:

reis$repl <- factor((as.numeric(reis$plot)-1)%/%4+1)
table(reis$plot,reis$repl) # just to check

now you can do 

anova(lme(nsp/tot~size*specie,random=~1|repl/plot,data=reis))

and have

            numDF denDF   F-value p-value
(Intercept)     1     8 207.18935  <.0001
size            3     6  94.58027  <.0001
specie          1     8  57.14293   1e-04
size:specie     3     8  10.28573   4e-03

or, as I'd prefer in a balanced study:

summary(aov(nsp/tot~specie*size+Error(repl+plot),data=reis))

Error: repl
          Df   Sum Sq  Mean Sq F value Pr(>F)
Residuals  2 0.027708 0.013854

Error: plot
          Df   Sum Sq  Mean Sq F value    Pr(>F)
size       3 0.305417 0.101806   94.58 1.927e-05 ***
Residuals  6 0.006458 0.001076
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

Error: Within
            Df   Sum Sq  Mean Sq F value    Pr(>F)
specie       1 0.041667 0.041667  57.143 6.551e-05 ***
specie:size  3 0.022500 0.007500  10.286   0.00404 **
Residuals    8 0.005833 0.000729
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

(Error(repl/plot) actually works too because repl:plot is the same as plot)

This gets a little confusin because "repl" is a coarsening of "plot".
It may be easier with a within-repl numbering, which you can get by
noting that plot is equivalent to repl:size

anova(lme(nsp/tot~size*specie,random=~1|repl/size,data=reis))
summary(aov(nsp/tot~specie*size+Error(repl/size),data=reis))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From gregory_r_warnes at groton.pfizer.com  Thu Apr 10 08:04:11 2003
From: gregory_r_warnes at groton.pfizer.com (Warnes, Gregory R)
Date: Thu, 10 Apr 2003 02:04:11 -0400
Subject: [R] Gregmisc 0.8.3 is now available
Message-ID: <D7A3CFD7825BD6119B880002A58F06C202F2C7CF@groexmb02.pfizer.com>


Version 0.8.3 of the gregmisc package is now available on CRAN.

In addition to updates for 1.7.0, this version adds the following functions

capture        Return the printed output of an R expression as a string
sprint	   Return the results of calling 'print' on an object as a string

textplot       Display text information in a graphics plot

These functions are useful when you want to manipulate or display the output

of R expressions in a nonstandard way, such as "printing" them to a graphics
window.  

The textplot function is generic and specialized methods for data frames,
vectors, and matrices are been provided.

-Greg





LEGAL NOTICE\ Unless expressly stated otherwise, this message is... {{dropped}}


From ripley at stats.ox.ac.uk  Thu Apr 10 09:27:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Apr 2003 08:27:58 +0100 (BST)
Subject: [R] local weight and coef from LOESS or locfit
In-Reply-To: <200304091432.47107.deli-wang@uiowa.edu>
Message-ID: <Pine.LNX.4.44.0304100824100.7622-100000@gannet.stats>

AFAIK they are not available, both in principle (the packages fit at a 
smaller set of points and interpolate) and in practice (the fits at the
points where fitting is used are not retained in the Fortran/C code).

So it looks like the designers saw no need for these to be available, and 
neither do I.  Given that loess and locfit are rather different (and
KernSmooth has locpoly too), *why* do you want these components of the 
fits?

On Wed, 9 Apr 2003, Deli Wang wrote:

> Could someone tell me is there any way to get the local weight , local 
> parameters estimation for each  points when using LOESS or locfit packages?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sharon at math.chalmers.se  Thu Apr 10 10:15:13 2003
From: sharon at math.chalmers.se (Sharon Kuhlmann-Berenzon)
Date: Thu, 10 Apr 2003 10:15:13 +0200 (MET DST)
Subject: [R] Rprof in Windows
Message-ID: <Pine.SOL.4.30.0304101009280.7994-100000@fourier.math.chalmers.se>


Dear list,

I am currently using R 1.6.1 on Windows XP. I am trying to profile a
lengthy program I have. I managed to obtain the profile twice using
Rprof() and then summaryRprof(). But after that, all further attempts
indicate that no events have  been recorded in the .out file.

> Rprof()
> [my program]
> Rprof(NULL)
> summaryRprof()
Error in summaryRprof() : no events were recorded

The Rprof.out file is created, but it only contains the line on the length
of the interval. Could there be a parameter or option that I should check
or that might have been changed unadvertedly?

Thank you for any help,

Sharon K?hlmann

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
SHARON K?HLMANN-BERENZON

Tel. +46-31-772 53 60			Dept. Mathematical Statistics
Fax. +46-31-772 35 08			Chalmers University of Tech.
e-mail: sharon at math.chalmers.se		Eklandagatan 86
					412 96 G?teborg, Sweden


From maechler at stat.math.ethz.ch  Thu Apr 10 10:02:37 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 10 Apr 2003 10:02:37 +0200
Subject: [R] R-help list: archives off for a few hours; duplicate postings
Message-ID: <16021.9501.299571.410451@gargle.gargle.HOWL>

Dear mailing lists users,
For some restructuring time, the R-help mailing list _archives_
are out of reach for a few hours (since 5 minutes ago).

Also, many of you have seen duplication of some messages to the
mailing list.  This has been caused by a change to the mailman
configuration I had done for speed-up reasons (and according to
the docs) and mailman race-condition bugs that I didn't expect.
For the moment, I'd rather continue the current behavior with
increased delivery speed and hope you'll live fine with the
occasional duplicates.

Yours,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From petr.pikal at precheza.cz  Thu Apr 10 12:14:20 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 10 Apr 2003 12:14:20 +0200
Subject: [R] how to estimate parameters of multimodal distribution
Message-ID: <3E95601C.31649.E15EB7@localhost>

Dear all

Please, is there any function or package for dealing with multimodal distributions? 
I try to fit multimodal distribution or more precisely to find out mixture of normal 
distributions which can lead to my actual data.

I use optim to find (in that case) two parameters but what I want is to let the 
function find out arbitrary number of normal distributions underlaying my actual 
data and estimate all parameters automatically. Actually I want to elaborate some 
function which is similar to procedures used for evaluating DTA, IR or XRD 
spectra. Is the optim way suitable for this task? 

I would be gratefull for **any** hint.

Here is some artificial example.

# making two normals and putting them together

x<-seq(5,100,5)
y1<-abs(dnorm(x,30,5)+rnorm(20,0,.002))
y2<-abs(dnorm(x,60,10)+rnorm(20,0,.002))
y<-y1+y2
y<-y/sum(y)*100

# *** my data actually look like this***
n<-round(y/sum(y)*100)

opt<-optim(c(5,10),fff)
matplot(x,cbind(y,fff2(c(5.3,10))),type="l")

# quite OK but I need a little bit more general solution

fff<-function(p) 
{
p1<-p[1]
p2<-p[2]
v<-dnorm(x,30,p1)+dnorm(x,60,p2)
s<-sum(v)
sum((y-v/s)^2)
}

fff2<-function(p) 
{
p1<-p[1]
p2<-p[2]
v<-dnorm(x,30,p1)+dnorm(x,60,p2)
s<-sum(v)
v/s
}

Thank you very much for any help.
Best regards.

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz


From david.barron at said-business-school.oxford.ac.uk  Thu Apr 10 12:36:35 2003
From: david.barron at said-business-school.oxford.ac.uk (David Barron)
Date: Thu, 10 Apr 2003 11:36:35 +0100
Subject: [R] error log
Message-ID: <006401c2ff4d$0f315090$8b224381@sbs.ox.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030410/cdff3bc4/attachment.pl

From ripley at stats.ox.ac.uk  Thu Apr 10 12:38:29 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Apr 2003 11:38:29 +0100 (BST)
Subject: [R] Rprof in Windows
In-Reply-To: <Pine.SOL.4.30.0304101009280.7994-100000@fourier.math.chalmers.se>
Message-ID: <Pine.LNX.4.44.0304101130080.10470-100000@gannet.stats>

On Thu, 10 Apr 2003, Sharon Kuhlmann-Berenzon wrote:

> I am currently using R 1.6.1 on Windows XP. I am trying to profile a
> lengthy program I have. I managed to obtain the profile twice using
> Rprof() and then summaryRprof(). But after that, all further attempts
> indicate that no events have  been recorded in the .out file.
> 
> > Rprof()
> > [my program]
> > Rprof(NULL)
> > summaryRprof()
> Error in summaryRprof() : no events were recorded
> 
> The Rprof.out file is created, but it only contains the line on the length
> of the interval. Could there be a parameter or option that I should check
> or that might have been changed unadvertedly?

My guess is that you have a single-CPU machine: you need to leave a time
gap between Rprof() and running the code.  It seems to be a bug in the
Windows runtime used in 1.6.x that is failing to start the profiling
thread: it did not happen in 1.5.1 and 1.7.0 (a week away) will contain a
workaround -- dual-CPU machines always worked correctly.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Apr 10 12:42:40 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Apr 2003 11:42:40 +0100 (BST)
Subject: [R] how to estimate parameters of multimodal distribution
In-Reply-To: <3E95601C.31649.E15EB7@localhost>
Message-ID: <Pine.LNX.4.44.0304101139200.10470-100000@gannet.stats>

Package mclust is all about fitting mixtures of normal distributions to 
data.

It's not as easy as some people make out, since there can be many good 
fits with very different sets of parameters -- I would run the procedures 
in mclust several times from different starting points.

On Thu, 10 Apr 2003, Petr Pikal wrote:

> Dear all
> 
> Please, is there any function or package for dealing with multimodal distributions? 
> I try to fit multimodal distribution or more precisely to find out mixture of normal 
> distributions which can lead to my actual data.
> 
> I use optim to find (in that case) two parameters but what I want is to let the 
> function find out arbitrary number of normal distributions underlaying my actual 
> data and estimate all parameters automatically. Actually I want to elaborate some 
> function which is similar to procedures used for evaluating DTA, IR or XRD 
> spectra. Is the optim way suitable for this task? 
> 
> I would be gratefull for **any** hint.
> 
> Here is some artificial example.
> 
> # making two normals and putting them together
> 
> x<-seq(5,100,5)
> y1<-abs(dnorm(x,30,5)+rnorm(20,0,.002))
> y2<-abs(dnorm(x,60,10)+rnorm(20,0,.002))
> y<-y1+y2
> y<-y/sum(y)*100
> 
> # *** my data actually look like this***
> n<-round(y/sum(y)*100)
> 
> opt<-optim(c(5,10),fff)
> matplot(x,cbind(y,fff2(c(5.3,10))),type="l")
> 
> # quite OK but I need a little bit more general solution
> 
> fff<-function(p) 
> {
> p1<-p[1]
> p2<-p[2]
> v<-dnorm(x,30,p1)+dnorm(x,60,p2)
> s<-sum(v)
> sum((y-v/s)^2)
> }
> 
> fff2<-function(p) 
> {
> p1<-p[1]
> p2<-p[2]
> v<-dnorm(x,30,p1)+dnorm(x,60,p2)
> s<-sum(v)
> v/s
> }
> 
> Thank you very much for any help.
> Best regards.
> 
> Petr Pikal
> petr.pikal at precheza.cz
> p.pik at volny.cz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ng_angie_03 at yahoo.co.uk  Thu Apr 10 12:44:59 2003
From: ng_angie_03 at yahoo.co.uk (=?iso-8859-1?q?Angie=20Ng?=)
Date: Thu, 10 Apr 2003 11:44:59 +0100 (BST)
Subject: [R] re:  question on 
Message-ID: <20030410104459.33532.qmail@web41805.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030410/28c44c04/attachment.pl

From ramzi_feg at yahoo.fr  Thu Apr 10 15:56:46 2003
From: ramzi_feg at yahoo.fr (=?iso-8859-1?q?Ramzi=20Feghali?=)
Date: Thu, 10 Apr 2003 15:56:46 +0200 (CEST)
Subject: [R] Transforming matrix
Message-ID: <20030410135646.68565.qmail@web20308.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030410/3d7c1089/attachment.pl

From rdiaz at cnio.es  Thu Apr 10 16:12:43 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Thu, 10 Apr 2003 16:12:43 +0200
Subject: [R] Transforming matrix
In-Reply-To: <20030410135646.68565.qmail@web20308.mail.yahoo.com>
References: <20030410135646.68565.qmail@web20308.mail.yahoo.com>
Message-ID: <200304101612.43831.rdiaz@cnio.es>

Dear Ramzi,

If you have your TRUE/FALSE values in m1, then do

> mode(m1) <- "numeric".

This is probably not the best way but it seems to work.


Ram?n



On Thursday 10 April 2003 15:56, Ramzi Feghali wrote:
> hi everybody,
> anyone knows how we can transform a binary matrix with TRUE and FALSE to 0
> and 1 without looping? Thx
>
>
>
> ---------------------------------
>
>
> 	[[alternate HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://bioinfo.cnio.es/~rdiaz


From sundar.dorai-raj at pdf.com  Thu Apr 10 16:17:06 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 10 Apr 2003 09:17:06 -0500
Subject: [R] Transforming matrix
References: <20030410135646.68565.qmail@web20308.mail.yahoo.com>
Message-ID: <3E957CE2.6060807@pdf.com>

Assuming that TRUE==1 and FALSE==0, just do

 > x = matrix(c(TRUE,TRUE,FALSE,FALSE),2,2)
 > x
      [,1]  [,2]
[1,] TRUE FALSE
[2,] TRUE FALSE
 > as.numeric(x)
[1] 1 1 0 0
 > array(as.numeric(x),dim=dim(x))
      [,1] [,2]
[1,]    1    0
[2,]    1    0



Ramzi Feghali wrote:
> hi everybody, 
> anyone knows how we can transform a binary matrix with TRUE and FALSE to 0 and 1 without looping? 
> Thx 
> 
> 
> 
> ---------------------------------
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From andy_liaw at merck.com  Thu Apr 10 16:19:18 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 10 Apr 2003 10:19:18 -0400
Subject: [R] Transforming matrix
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F982@usrymx25.merck.com>

storage.mode(mat) <- "integer"

or

d <- dim(mat)
mat <- as.integer(mat)
dim(mat) <- d

HTH,
Andy

> -----Original Message-----
> From: Ramzi Feghali [mailto:ramzi_feg at yahoo.fr]
> Sent: Thursday, April 10, 2003 9:57 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Transforming matrix
> 
> 
> 
> hi everybody, 
> anyone knows how we can transform a binary matrix with TRUE 
> and FALSE to 0 and 1 without looping? 
> Thx 
> 
> 
> 
> ---------------------------------
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------


From paradis at isem.univ-montp2.fr  Thu Apr 10 16:20:28 2003
From: paradis at isem.univ-montp2.fr (Emmanuel Paradis)
Date: Thu, 10 Apr 2003 16:20:28 +0200
Subject: [R] Transforming matrix
In-Reply-To: <20030410135646.68565.qmail@web20308.mail.yahoo.com>
Message-ID: <4.2.0.58.20030410161218.00b1a128@162.38.183.200>

At 15:56 10/04/2003 +0200, vous avez ?crit:

>hi everybody,
>anyone knows how we can transform a binary matrix with TRUE and FALSE to 0 
>and 1 without looping?
>Thx

I guess you mean:

  TRUE ==> 1
FALSE ==> 0

as this is the rule when logicals are converted into numerics. Then, if M 
is your matrix, you can do:

mode(M) <- "numeric"

If you actually want:

  TRUE ==> 0
FALSE ==> 1

then:

M <- !M
mode(M) <- "numeric"

should do it.

HTH

EP



>---------------------------------
>
>
>         [[alternate HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From B.Rowlingson at lancaster.ac.uk  Thu Apr 10 16:20:41 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 10 Apr 2003 15:20:41 +0100
Subject: [R] Transforming matrix
In-Reply-To: <200304101612.43831.rdiaz@cnio.es>
References: <20030410135646.68565.qmail@web20308.mail.yahoo.com>
	<200304101612.43831.rdiaz@cnio.es>
Message-ID: <3E957DB9.9080601@lancaster.ac.uk>

Ramon Diaz wrote:
> Dear Ramzi,
> 
> If you have your TRUE/FALSE values in m1, then do
> 
> 
>>mode(m1) <- "numeric".

  Except that TRUE is 1 and FALSE is 0. The original question was:

>>anyone knows how we can transform a binary matrix with TRUE and FALSE to 0
>>and 1 without looping? 

  which could imply they want TRUE mapped to 0, and FALSE to 1, which is 
done with '1-':

 > foo
       [,1] [,2]  [,3]  [,4]  [,5]
[1,] FALSE TRUE FALSE FALSE  TRUE
[2,]  TRUE TRUE  TRUE FALSE FALSE

 > 1-foo
      [,1] [,2] [,3] [,4] [,5]
[1,]    1    0    1    1    0
[2,]    0    0    0    1    1
 >

  R will convert TRUE to 1 and FALSE to 0 in a numeric context:

 > foo*1
      [,1] [,2] [,3] [,4] [,5]
[1,]    0    1    0    0    1
[2,]    1    1    1    0    0

Baz


From spencer.graves at pdf.com  Thu Apr 10 16:21:59 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 10 Apr 2003 07:21:59 -0700
Subject: [R] Transforming matrix
References: <20030410135646.68565.qmail@web20308.mail.yahoo.com>
Message-ID: <3E957E07.2010005@pdf.com>

 > A <- array(c(T,F,F,T), dim=c(2,2))
 > A+0
      [,1] [,2]
[1,]    1    0
[2,]    0    1

How's this?
Spencer Graves

Ramzi Feghali wrote:
> hi everybody, 
> anyone knows how we can transform a binary matrix with TRUE and FALSE to 0 and 1 without looping? 
> Thx 
> 
> 
> 
> ---------------------------------
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Thu Apr 10 16:26:40 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Apr 2003 15:26:40 +0100 (BST)
Subject: [R] Transforming matrix
In-Reply-To: <200304101612.43831.rdiaz@cnio.es>
Message-ID: <Pine.LNX.4.44.0304101523490.11613-100000@gannet.stats>

On Thu, 10 Apr 2003, Ramon Diaz wrote:

> If you have your TRUE/FALSE values in m1, then do
> 
> > mode(m1) <- "numeric".
> 
> This is probably not the best way but it seems to work.

That maps TRUE to 1 and FALSE to 0, and I read the request as for the 
reverse.

ifelse(m1, 0, 1) is probably the most transparent way.


> On Thursday 10 April 2003 15:56, Ramzi Feghali wrote:
> > hi everybody,
> > anyone knows how we can transform a binary matrix with TRUE and FALSE to 0
> > and 1 without looping? Thx

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Thu Apr 10 16:45:52 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 10 Apr 2003 16:45:52 +0200
Subject: [R] error log
In-Reply-To: <006401c2ff4d$0f315090$8b224381@sbs.ox.ac.uk>
References: <006401c2ff4d$0f315090$8b224381@sbs.ox.ac.uk>
Message-ID: <3E9583A0.3030709@statistik.uni-dortmund.de>

David Barron wrote:
 > I'm using R version 1.6.2 under Windows 2000 Prof.  I've recently had
a problem with R terminating

What terminated? R or your function?
If R, the message was generated by
Dr. Watson presumably, the default debugger, which writes debug
information into your windows system directory. Please read the manuals
for your OS.
This indicates a bug in R, a package, or a self-compiled dll you are using.

 > with an error message that tells me that an error log has been
generated.  However, I've been unable to find this error log.  Could
someone tell me where it should have been written to and/or what the
name of the file should be?

 >
 > Thanks,
 > Dave
 >
 > ===================================================
 > David Barron
 > Jesus College
 > Oxford OX1 3DW
 > 01865 279684

Please, enable line wrapping for your broswer!
Uwe Ligges


From ramzi_feg at yahoo.fr  Thu Apr 10 17:03:09 2003
From: ramzi_feg at yahoo.fr (=?iso-8859-1?q?Ramzi=20Feghali?=)
Date: Thu, 10 Apr 2003 17:03:09 +0200 (CEST)
Subject: [R] New problem
Message-ID: <20030410150309.36723.qmail@web20301.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030410/fe0660bc/attachment.pl

From ripley at stats.ox.ac.uk  Thu Apr 10 17:28:49 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Apr 2003 16:28:49 +0100 (BST)
Subject: [R] New problem
In-Reply-To: <20030410150309.36723.qmail@web20301.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0304101621410.11717-100000@gannet.stats>

On Thu, 10 Apr 2003, Ramzi Feghali wrote:

> in fact i know that R deals with logical numbers 0 and 1 the same way
> like TRUE and FALSE but my problem is in fact with C language.

Could you please use a meaningful subject line.

> I have done an interface with C and my first problem was with float
> variables, but this warning doesn't appear everytime and really i don't
> know the problem with R:
> 
> "Warning message: 
> DLL attempted to change FPU control word from 8001f to 9001f"

That's not a problem with R, that is R complaining (correctly) about your
compiled code.  See e.g. the CHANGES file.  I am surmising that you are
using Windows (without saying so) and not using the recommended compiler
(without saying so).  If you follow the recommendations you will not see 
this.

> The second problem is how to define my matrix in the function call of R
> so that C take it as an input, knowing that for C this matrix is dfine
> as: "int M[dimrow][dimcol]" and for R is define as.matrix(m),

An R array is not a C matrix: it is a vector with attributes.  There are
examples in the `Writing R Extensions' manual, `S Programming' and in many 
of the 207 packages on CRAN.

> it really hurts interfacing with R

There is an easy way, via reading the manuals, and a hard way, via
trial-and-error.  Your choice, but you will not get sympathy for the 
second.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pleissner at mpiib-berlin.mpg.de  Thu Apr 10 17:30:12 2003
From: pleissner at mpiib-berlin.mpg.de (Klaus-Peter Pleissner)
Date: Thu, 10 Apr 2003 17:30:12 +0200
Subject: [R] R under Sun Solaris 8
Message-ID: <3E958E04.EBB07467@mpiib-berlin.mpg.de>

Hi,

I have installed R1.6.2 on a Sun Sparc workstatioin 60 under Solaris 8.
I' m using csh, tcsh or bash- shell.
Unfortunately, it is impossible to use the "arrow-up" key  on  Sun's
German keyboard to repeat a R command by using this key.

Always following syntax error occurs:
^[[A

Does anybody have a hint ?

Thanks

Klaus-P. Pleissner

--
Dr. Klaus-Peter Pleissner
Max Planck Institute for Infection Biology
Campus Charit? Mitte
Schumannstr. 21/22
D-10117 Berlin
Germany


phone: +49-30-28460-119
fax:   +49-30-28460-507
email: pleissner at mpiib-berlin.mpg.de


From ripley at stats.ox.ac.uk  Thu Apr 10 17:47:35 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Apr 2003 16:47:35 +0100 (BST)
Subject: [R] R under Sun Solaris 8
In-Reply-To: <3E958E04.EBB07467@mpiib-berlin.mpg.de>
Message-ID: <Pine.LNX.4.44.0304101645090.11717-100000@gannet.stats>

On Thu, 10 Apr 2003, Klaus-Peter Pleissner wrote:

> I have installed R1.6.2 on a Sun Sparc workstatioin 60 under Solaris 8.
> I' m using csh, tcsh or bash- shell.
> Unfortunately, it is impossible to use the "arrow-up" key  on  Sun's
> German keyboard to repeat a R command by using this key.
> 
> Always following syntax error occurs:
> ^[[A
> 
> Does anybody have a hint ?

Do you have libreadline installed?
Was it found when you configured R?

I can't speak for your keyboard, but ESC[A is the `raw' sequence generated 
by the up-arrow key on an English Sun keyboard, and what you show is what 
happens if readline is not compiled into R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From baron at psych.upenn.edu  Thu Apr 10 17:49:34 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 10 Apr 2003 11:49:34 -0400
Subject: [R] R under Sun Solaris 8
In-Reply-To: <3E958E04.EBB07467@mpiib-berlin.mpg.de>
References: <3E958E04.EBB07467@mpiib-berlin.mpg.de>
Message-ID: <20030410154934.GA25701@mail1.sas.upenn.edu>

On 04/10/03 17:30, Klaus-Peter Pleissner wrote:
>Hi,
>
>I have installed R1.6.2 on a Sun Sparc workstatioin 60 under Solaris 8.
>I' m using csh, tcsh or bash- shell.
>Unfortunately, it is impossible to use the "arrow-up" key  on  Sun's
>German keyboard to repeat a R command by using this key.
>
>Always following syntax error occurs:
>^[[A
>
>Does anybody have a hint ?

A hint, yes.  You may not have the readline library installed.
This is discussed in the installation notes.

Whether this is the problem, I do not know.

Jon


From ramzi_feg at yahoo.fr  Thu Apr 10 17:54:12 2003
From: ramzi_feg at yahoo.fr (=?iso-8859-1?q?Ramzi=20Feghali?=)
Date: Thu, 10 Apr 2003 17:54:12 +0200 (CEST)
Subject: [R] New Problem
Message-ID: <20030410155413.91283.qmail@web20308.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030410/f25c8868/attachment.pl

From zhuw at mail.smu.edu  Thu Apr 10 18:15:00 2003
From: zhuw at mail.smu.edu (Wang, Zhu)
Date: Thu, 10 Apr 2003 11:15:00 -0500
Subject: [R] Is there any Time series change-point estimate in R?
Message-ID: <0FBE46098704A242B0DC8FEC4169F9978140DB@s31xs3.systems.smu.edu>

Thanks for the great help.

Zhu Wang

Statistical Science Department
SMU




-----Original Message-----
From:	Achim Zeileis [mailto:zeileis at ci.tuwien.ac.at]
Sent:	Tue 4/8/2003 4:28 AM
To:	Wang, Zhu
Cc:	r-help at stat.math.ethz.ch
Subject:	Re: [R] Is there any Time series change-point estimate in R?

On Saturday 05 April 2003 22:45, Wang, Zhu wrote:

> Thanks.
> I am currentlly investigating the package strucchange.
> My interested change-point is the covariance structure change. Can
> strucchange do that?

No, not really. You might be able to use the functions in strucchange 
to test and estimate variance changes (if you are able to write the 
model as a regression model), but covariance changes are more 
difficult.

> Does strucchange consider Box-Jenkins model?

No, not currently.

Best,
Z

> Zhu Wang
>
> Statistical Science Department
> SMU
>
> 	-----Original Message-----
> 	From: Achim Zeileis [mailto:zeileis at ci.tuwien.ac.at]
> 	Sent: Thu 4/3/2003 3:21 AM
> 	To: Wang, Zhu; r-help at stat.math.ethz.ch
> 	Cc:
> 	Subject: Re: [R] Is there any Time series change-point estimate in
> R?
>
> 	On Tuesday 01 April 2003 18:56, Wang, Zhu wrote:
> 	> Hello,
> 	>
> 	> I am looking for time series non-stationary test and change -
> 	> point estimate. The pachage strucchange seems not serving my
> 	> purpose.
>
> 	This is both very vague. You might find a suitable test for
> 	non-stationarity in tseries. And depending on what you mean by
> 	changepoint, strucchange might be able to do what you want. The
> 	function breakpoints() can estimate breakpoints in linear
> regression models, which includes certain types of models for
> non-stationary time series.
> 	Z
>
> 	> Thanks in advance.
> 	>
> 	> Zhu Wang
> 	>
> 	> Statistical Science Department
> 	> SMU
> 	>
> 	> ______________________________________________
> 	> R-help at stat.math.ethz.ch mailing list
> 	> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> 	______________________________________________
> 	R-help at stat.math.ethz.ch mailing list
> 	https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From chrysopa at insecta.ufv.br  Thu Apr 10 15:40:30 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Thu, 10 Apr 2003 10:40:30 -0300
Subject: [R] [OFF] Nested or not nested, this is the question.
In-Reply-To: <x265pne8vr.fsf@biostat.ku.dk>
References: <200304091607.58089.chrysopa@insecta.ufv.br>
	<x265pne8vr.fsf@biostat.ku.dk>
Message-ID: <200304101038.36785.chrysopa@insecta.ufv.br>

Em Qua 09 Abr 2003 17:03, Peter Dalgaard BSA escreveu:

Peter,

thank for your exaplanation. But I still have doubt.

> Neither. First of all, you have numDF = 1 for things that have more
> than two levels, so you forgot to make them factors.
>
> reis$plot<-factor(reis$plot)
> reis$size<-factor(reis$size)
> reis$specie<-factor(reis$specie)

In this case size is quantitative, measurement in meter.
species is one DF because is a two level factor.

> Then you seem to be needing something that describes the replication,
> and you're not actually telling us, but if I guess that plots 1-4 is
> the 1st replication and 5-8 and 9-12 are the others, then this should
> work:
>
> reis$repl <- factor((as.numeric(reis$plot)-1)%/%4+1)
> table(reis$plot,reis$repl) # just to check

Ok, I understande this

> now you can do
>
> anova(lme(nsp/tot~size*specie,random=~1|repl/plot,data=reis))
>
> and have
>
>             numDF denDF   F-value p-value
> (Intercept)     1     8 207.18935  <.0001
> size            3     6  94.58027  <.0001
> specie          1     8  57.14293   1e-04
> size:specie     3     8  10.28573   4e-03

Here is my problem to understand.
Why is repl/plot, or repl/size? plot is the high level.
Why is not repl/specie or plot/specie?

I think this because in each repl I have two measurement of specie.
Is like the rats example of Crawley's book. repl = rat, specie = liver and 
size = treatment, in this case the nested design is size/repl/specie.
The diference is that liver in rat is a random effect but specie is a fixed 
effect. In rats example it make a simple nested anova, but dnt have any 
example to make a nested ancova. It is a bit confused.

If I dont have real replication (one plot by size), only pseudoreplication?

> or, as I'd prefer in a balanced study:
>
> summary(aov(nsp/tot~specie*size+Error(repl+plot),data=reis))
>
> Error: repl
>           Df   Sum Sq  Mean Sq F value Pr(>F)
> Residuals  2 0.027708 0.013854
>
> Error: plot
>           Df   Sum Sq  Mean Sq F value    Pr(>F)
> size       3 0.305417 0.101806   94.58 1.927e-05 ***
> Residuals  6 0.006458 0.001076
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
>
> Error: Within
>             Df   Sum Sq  Mean Sq F value    Pr(>F)
> specie       1 0.041667 0.041667  57.143 6.551e-05 ***
> specie:size  3 0.022500 0.007500  10.286   0.00404 **
> Residuals    8 0.005833 0.000729
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
>
> (Error(repl/plot) actually works too because repl:plot is the same as plot)
>
> This gets a little confusin because "repl" is a coarsening of "plot".
> It may be easier with a within-repl numbering, which you can get by
> noting that plot is equivalent to repl:size
>
> anova(lme(nsp/tot~size*specie,random=~1|repl/size,data=reis))
> summary(aov(nsp/tot~specie*size+Error(repl/size),data=reis))

This example (create by me) is a manipulative example, but I try to understand 
this for use with ecological "exploratory" data. In this case I only collect 
the data, normally I can not manipulate (create) the "design". All book's 
examples are perfectly data with tradicional design, its ease to understand.

Any help still welcome.
Please dont say "Read the book ..." I dont have money for books at the moment, 
sorry.

Thanks for all
Ronaldo
-- 
APL is a write-only language.  I can write programs in APL, but I can't
read any of them.
		-- Roy Keir
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From wss at ufla.br  Thu Apr 10 19:03:13 2003
From: wss at ufla.br (Washington Santos da Silva)
Date: Thu, 10 Apr 2003 14:03:13 -0300
Subject: [R] 
	Exact confidence intervals based on the hypergeometric distribuiton
Message-ID: <20030410140313.M73524@ufla.br>

I need to estimates some exact confidence intervals for one 
proportion based on the exact hypergeometric distribution of the number of 
units in the sample with the attribute. Does a code exist for performing such 
procedure? 

Thanks for your help.

Washington S. Silva


From wss at ufla.br  Thu Apr 10 19:06:12 2003
From: wss at ufla.br (Washington Santos da Silva)
Date: Thu, 10 Apr 2003 14:06:12 -0300
Subject: [R] 
	Exact confidence intervals based on the hypergeometric distribuiton
Message-ID: <20030410140612.M50178@ufla.br>

I need to estimates some exact confidence intervals for one 
proportion based on the exact hypergeometric distribution of the number of 
units in the sample with the attribute. Does a code exist for performing such 
procedure? 

Thanks for your help.

Washington S. Silva


From abunn at montana.edu  Thu Apr 10 19:36:04 2003
From: abunn at montana.edu (Andy Bunn)
Date: Thu, 10 Apr 2003 11:36:04 -0600
Subject: [R] Classification problem - rpart
Message-ID: <001201c2ff87$acaecd40$e6a00ecf@simATE>

I am performing a binary classification using a classification tree.
Ironically, the data themselves are 2483 tree (real biological ones)
locations as described by a suite of environmental variables (slope, soil
moisture, radiation load, etc). I want to separate them from an equal number
of random points. Doing eda on the data shows that there is substantial
difference between the tree and random classes, e.g., box and whisker plots
for slope show separation.

The data frame is thus:

curvegrid,dir2tl,dist2tl,slope,tasp,tci10,class
-0.000244141,266,1852.701,2.382412,0.2124468,131,random
0.3005371,246,1146.342,10.45694,0.8045813,63,random
.
.
.
.
-0.3000488,90,10,20.25561,-0.1293357,62,tree
-0.5,90,10,18.68057,-0.05228489,61,tree
-0.6994629,0,0,18.30121,0.0320744,66,tree

I've run rpart on similar data without an issue but when I try it on this
data as follows:

tree <- rpart(class ~ curvegrid + slope + tci10, method="class")

I get the following output:

> tree
n= 4966 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

1) root 4966 2483 dw (0.500000000 0.500000000)  
  2) slope=0.3206026,0.5159777,0.679302,0.7163697,1.1324.......... 2574   94
dw (0.963480963 0.036519037) *
  3) slope=0,0.1011371,0.1013844,0.2027681,0.2267014,0.32......... MISSING
2392    3 random (0.001254181 0.998745819) *


This is not like other trees I have run!

And:

summary(tree)
> summary(tree)
Call:
rpart(formula = class ~ curvegrid + slope + tci10)
  n= 4966 

         CP nsplit  rel error    xerror       xstd
1 0.9609344      0 1.00000000 1.0322191 0.01418310
2 0.0100000      1 0.03906565 0.7635924 0.01378822

Node number 1: 4966 observations,    complexity param=0.9609344
  predicted class=dw      expected loss=0.5
    class counts:  2483  2483
   probabilities: 0.500 0.500 
  left son=2 (2574 obs) right son=3 (2392 obs)
  Primary splits:
     slope     splits as  RRRRRRLRRRLRRRRLLRRRRRRR.......
     tci10     splits as  RRRRRRRRRRLLRLLRLLRLLRLL.......

etc.

Node number 2: 2574 observations
  predicted class=dw      expected loss=0.03651904
    class counts:  2480    94
   probabilities: 0.963 0.037 

Node number 3: 2392 observations
  predicted class=random  expected loss=0.001254181
    class counts:     3  2389
   probabilities: 0.001 0.999

I'm assuming that I have to adjust something in rpart.control. I am also
hesitant at posting prematurely but am in fetters.

Thanks in advance, Andy


From shutnik_xx at yahoo.co.uk  Thu Apr 10 20:11:03 2003
From: shutnik_xx at yahoo.co.uk (=?iso-8859-1?q?Shutnik?=)
Date: Thu, 10 Apr 2003 19:11:03 +0100 (BST)
Subject: [R] R help
Message-ID: <20030410181103.50856.qmail@web10902.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030410/d73c3d6b/attachment.pl

From ripley at stats.ox.ac.uk  Thu Apr 10 20:16:30 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Apr 2003 19:16:30 +0100 (BST)
Subject: [R] Classification problem - rpart
In-Reply-To: <001201c2ff87$acaecd40$e6a00ecf@simATE>
Message-ID: <Pine.LNX.4.44.0304101907470.14718-100000@gannet.stats>

You have slope and tci10 (at least) coded as factors.  Run summary() on 
your data frame.  My bet is that you have MISSING in there, and did not
declare that when using read.table (or whatever)

Do *look* at your data at least cursorily.

On Thu, 10 Apr 2003, Andy Bunn wrote:

> I am performing a binary classification using a classification tree.
> Ironically, the data themselves are 2483 tree (real biological ones)
> locations as described by a suite of environmental variables (slope, soil
> moisture, radiation load, etc). I want to separate them from an equal number
> of random points. Doing eda on the data shows that there is substantial
> difference between the tree and random classes, e.g., box and whisker plots
> for slope show separation.
> 
> The data frame is thus:
> 
> curvegrid,dir2tl,dist2tl,slope,tasp,tci10,class
> -0.000244141,266,1852.701,2.382412,0.2124468,131,random
> 0.3005371,246,1146.342,10.45694,0.8045813,63,random
> .
> .
> .
> .
> -0.3000488,90,10,20.25561,-0.1293357,62,tree
> -0.5,90,10,18.68057,-0.05228489,61,tree
> -0.6994629,0,0,18.30121,0.0320744,66,tree
> 
> I've run rpart on similar data without an issue but when I try it on this
> data as follows:
> 
> tree <- rpart(class ~ curvegrid + slope + tci10, method="class")
> 
> I get the following output:
> 
> > tree
> n= 4966 
> 
> node), split, n, loss, yval, (yprob)
>       * denotes terminal node
> 
> 1) root 4966 2483 dw (0.500000000 0.500000000)  
>   2) slope=0.3206026,0.5159777,0.679302,0.7163697,1.1324.......... 2574   94
> dw (0.963480963 0.036519037) *
>   3) slope=0,0.1011371,0.1013844,0.2027681,0.2267014,0.32......... MISSING
> 2392    3 random (0.001254181 0.998745819) *
> 
> 
> This is not like other trees I have run!
> 
> And:
> 
> summary(tree)
> > summary(tree)
> Call:
> rpart(formula = class ~ curvegrid + slope + tci10)
>   n= 4966 
> 
>          CP nsplit  rel error    xerror       xstd
> 1 0.9609344      0 1.00000000 1.0322191 0.01418310
> 2 0.0100000      1 0.03906565 0.7635924 0.01378822
> 
> Node number 1: 4966 observations,    complexity param=0.9609344
>   predicted class=dw      expected loss=0.5
>     class counts:  2483  2483
>    probabilities: 0.500 0.500 
>   left son=2 (2574 obs) right son=3 (2392 obs)
>   Primary splits:
>      slope     splits as  RRRRRRLRRRLRRRRLLRRRRRRR.......
>      tci10     splits as  RRRRRRRRRRLLRLLRLLRLLRLL.......
> 
> etc.
> 
> Node number 2: 2574 observations
>   predicted class=dw      expected loss=0.03651904
>     class counts:  2480    94
>    probabilities: 0.963 0.037 
> 
> Node number 3: 2392 observations
>   predicted class=random  expected loss=0.001254181
>     class counts:     3  2389
>    probabilities: 0.001 0.999
> 
> I'm assuming that I have to adjust something in rpart.control. I am also
> hesitant at posting prematurely but am in fetters.

It's not rpart, it is your data manipulation: `pilot error'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From myao at ou.edu  Thu Apr 10 20:23:12 2003
From: myao at ou.edu (Minghua Yao)
Date: Thu, 10 Apr 2003 13:23:12 -0500
Subject: [R] A Question on lowess() function
Message-ID: <HDEPJCAKDEJMEEHKJOKEAEDPCAAA.myao@ou.edu>

Hi, all,

I want to use lowess(x, y) where x and y are vectors of length of 4000+.  In
fact, x and y are log of some vectors. So, some of the elements are NaN.
lowess() can not take away those elements then do the fitting. It will give
the error message and do nothing.

1. Can anybody tell me how to get rid of those NaN's and use lowess()?
2. How to get the LOWESS fitting values for any elements in x?

Thank you in advance.

-MY


From ripley at stats.ox.ac.uk  Thu Apr 10 20:37:35 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Apr 2003 19:37:35 +0100 (BST)
Subject: [R] A Question on lowess() function
In-Reply-To: <HDEPJCAKDEJMEEHKJOKEAEDPCAAA.myao@ou.edu>
Message-ID: <Pine.LNX.4.44.0304101936200.14738-100000@gannet.stats>

lowess was old-fashioned a decade ago: use loess.

And this Q was answered about a week ago, so use the archives.

On Thu, 10 Apr 2003, Minghua Yao wrote:

> I want to use lowess(x, y) where x and y are vectors of length of 4000+.  In
> fact, x and y are log of some vectors. So, some of the elements are NaN.
> lowess() can not take away those elements then do the fitting. It will give
> the error message and do nothing.
> 
> 1. Can anybody tell me how to get rid of those NaN's and use lowess()?
> 2. How to get the LOWESS fitting values for any elements in x?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jerome at hivnet.ubc.ca  Thu Apr 10 20:57:07 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Thu, 10 Apr 2003 11:57:07 -0700
Subject: [R] R help
In-Reply-To: <20030410181103.50856.qmail@web10902.mail.yahoo.com>
References: <20030410181103.50856.qmail@web10902.mail.yahoo.com>
Message-ID: <200304101902.MAA19989@hivnet.ubc.ca>


Here is a solution, but it may take several seconds to run.

x <- matrix(rnorm(1050*1000),1050,1000)
mat <- t(x)%*%x

This is the idea behind Wishart random matrices. In theory, that matrix 
should be positive definite. This can be verified with

eigen(mat,only.values=T)

Also read ?ninvwish in package "norm". But I am not sure if it was 
designed for large matrices.

HTH,
Jerome

On April 10, 2003 11:11 am, Shutnik wrote:
>  Dear friends,
>  How can I generate (simulate) a large, say 1000x1000, positive definite
> var-covar matrix?
>
>  Regards,
>
>  Max
>
>
>
>
> ---------------------------------
>
>
> 	[[alternate HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From f0z6305 at labs.tamu.edu  Thu Apr 10 21:39:29 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu, 10 Apr 2003 14:39:29 -0500
Subject: [R] How to plot several graphs in a single 2-D figure?
Message-ID: <004d01c2ff98$e6c3aad0$8bd75ba5@IE.TAMU.EDU>

Hi, R-listers

I tried to plot several graphs in a sigle x-y coordinate settings, like the
following:
|(y)                           s
|    ******               s
|               *****      s
|    sssssssssssssssssss
|_______________________________(x)
where "*" and "s" denote two diffrent plots.

However, when I used
plot(data1); % data1 is the data points of "*"
par(new=T);
plot(data2); % data2 is the data points of "s"

I found that the x and y labels are messed up, since different graphs use
diffrent unit length on the x-axis and y-axis.

So is there someway to avoid this problem?
Or is there some other function plottting multiple plots in
one x-y axis setting?

Thanks for your point and help.

Fred


From myao at ou.edu  Thu Apr 10 21:58:15 2003
From: myao at ou.edu (Minghua Yao)
Date: Thu, 10 Apr 2003 14:58:15 -0500
Subject: [R] A Question on lowess() function
In-Reply-To: <Pine.LNX.4.44.0304101936200.14738-100000@gannet.stats>
Message-ID: <HDEPJCAKDEJMEEHKJOKEMEEACAAA.myao@ou.edu>

Thank you for your reply.

I didn't find what I needed from the archieves. Maybe, I need to figure out
how to search the archieves effectively.

I used y<-x[!is.na(x)] to get rid of NA and NaN. But I don't know how to get
rid of Inf.

Also, is there more detailed info about loess() than help(loess)?

Thanks.

-MY

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Thursday, April 10, 2003 1:38 PM
To: Minghua Yao
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] A Question on lowess() function


lowess was old-fashioned a decade ago: use loess.

And this Q was answered about a week ago, so use the archives.

On Thu, 10 Apr 2003, Minghua Yao wrote:

> I want to use lowess(x, y) where x and y are vectors of length of 4000+.
In
> fact, x and y are log of some vectors. So, some of the elements are NaN.
> lowess() can not take away those elements then do the fitting. It will
give
> the error message and do nothing.
>
> 1. Can anybody tell me how to get rid of those NaN's and use lowess()?
> 2. How to get the LOWESS fitting values for any elements in x?

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jerome at hivnet.ubc.ca  Thu Apr 10 21:59:06 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Thu, 10 Apr 2003 12:59:06 -0700
Subject: [R] How to plot several graphs in a single 2-D figure?
In-Reply-To: <004d01c2ff98$e6c3aad0$8bd75ba5@IE.TAMU.EDU>
References: <004d01c2ff98$e6c3aad0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <200304102004.NAA21541@hivnet.ubc.ca>


This has been discussed previously. You can get the idea from the R Help 
archive. See the thread on "multiple plot overlay - dataframe" at:

http://maths.newcastle.edu.au/~rking/R/help/03a/2035.html

HTH,
Jerome

On April 10, 2003 12:39 pm, Feng Zhang wrote:
> Hi, R-listers
>
> I tried to plot several graphs in a sigle x-y coordinate settings, like
> the
>
> following:
> |(y)                           s
> |    ******               s
> |               *****      s
> |    sssssssssssssssssss
> |_______________________________(x)
>
> where "*" and "s" denote two diffrent plots.
>
> However, when I used
> plot(data1); % data1 is the data points of "*"
> par(new=T);
> plot(data2); % data2 is the data points of "s"
>
> I found that the x and y labels are messed up, since different graphs
> use diffrent unit length on the x-axis and y-axis.
>
> So is there someway to avoid this problem?
> Or is there some other function plottting multiple plots in
> one x-y axis setting?
>
> Thanks for your point and help.
>
> Fred
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From f0z6305 at labs.tamu.edu  Thu Apr 10 22:03:24 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu, 10 Apr 2003 15:03:24 -0500
Subject: [R] How to plot several graphs in a single 2-D figure?
References: <433782665F24734CB1EDEF38E0F9F3EF31AC28@ntserver>
Message-ID: <005d01c2ff9c$3e330fb0$8bd75ba5@IE.TAMU.EDU>

Thanks, Iyue

But here the data1 and data2 are not necessarily two vectors.
Maybe they are results from some other functions, defined
as a data structure.
Like using norMix package,

x <- norMix(mu=c(-1,0,1.5),sig2=c(.49,.36,.16),w=c(.4,.3,.3));
plot(x); %% x is not a vector, but a structure
y <- norMix(mu=c(-2,0,2),sig2=c(.16,.36,.64),w=c(.4,.3,.3));
par(new=T);
plot(y);

The result graph is messed up and x,y dont have consistent axis label
settings.

Fred

----- Original Message -----
From: "Iyue Sung" <isung at epidemiology.com>
To: "Feng Zhang" <f0z6305 at labs.tamu.edu>
Sent: Thursday, April 10, 2003 2:55 PM
Subject: RE: [R] How to plot several graphs in a single 2-D figure?



Fred, Try:

>xrange<-range(c(data1[,1],data2[,1]))
>yrange<-range(c(data1[,2],data2[,2]))
>
>plot(data1, xlim=xrange, ylim=yrange, pch=1)
>points(data2, pch=2)

-Iyue

> -----Original Message-----
> From: Feng Zhang [mailto:f0z6305 at labs.tamu.edu]
> Sent: Thursday, April 10, 2003 3:39 PM
> To: R-Help
> Subject: [R] How to plot several graphs in a single 2-D figure?
>
>
> Hi, R-listers
>
> I tried to plot several graphs in a sigle x-y coordinate
> settings, like the
> following:
> |(y)                           s
> |    ******               s
> |               *****      s
> |    sssssssssssssssssss
> |_______________________________(x)
> where "*" and "s" denote two diffrent plots.
>
> However, when I used
> plot(data1); % data1 is the data points of "*"
> par(new=T);
> plot(data2); % data2 is the data points of "s"
>
> I found that the x and y labels are messed up, since
> different graphs use
> diffrent unit length on the x-axis and y-axis.
>
> So is there someway to avoid this problem?
> Or is there some other function plottting multiple plots in
> one x-y axis setting?
>
> Thanks for your point and help.
>
> Fred
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From f0z6305 at labs.tamu.edu  Thu Apr 10 22:08:04 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu, 10 Apr 2003 15:08:04 -0500
Subject: [R] How to plot several graphs in a single 2-D figure?
References: <433782665F24734CB1EDEF38E0F9F3EF31AC28@ntserver>
Message-ID: <007b01c2ff9c$e4f75270$8bd75ba5@IE.TAMU.EDU>


----- Original Message ----- 
From: "Iyue Sung" <isung at epidemiology.com>
To: "Feng Zhang" <f0z6305 at labs.tamu.edu>
Sent: Thursday, April 10, 2003 2:55 PM
Subject: RE: [R] How to plot several graphs in a single 2-D figure?



Fred, Try:

>xrange<-range(c(data1[,1],data2[,1]))
>yrange<-range(c(data1[,2],data2[,2]))
>
>plot(data1, xlim=xrange, ylim=yrange, pch=1)
>points(data2, pch=2)

-Iyue

> -----Original Message-----
> From: Feng Zhang [mailto:f0z6305 at labs.tamu.edu]
> Sent: Thursday, April 10, 2003 3:39 PM
> To: R-Help
> Subject: [R] How to plot several graphs in a single 2-D figure?
> 
> 
> Hi, R-listers
> 
> I tried to plot several graphs in a sigle x-y coordinate 
> settings, like the
> following:
> |(y)                           s
> |    ******               s
> |               *****      s
> |    sssssssssssssssssss
> |_______________________________(x)
> where "*" and "s" denote two diffrent plots.
> 
> However, when I used
> plot(data1); % data1 is the data points of "*"
> par(new=T);
> plot(data2); % data2 is the data points of "s"
> 
> I found that the x and y labels are messed up, since 
> different graphs use
> diffrent unit length on the x-axis and y-axis.
> 
> So is there someway to avoid this problem?
> Or is there some other function plottting multiple plots in
> one x-y axis setting?
> 
> Thanks for your point and help.
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From p.dalgaard at biostat.ku.dk  Thu Apr 10 22:15:29 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 10 Apr 2003 22:15:29 +0200
Subject: [R] How to plot several graphs in a single 2-D figure?
In-Reply-To: <004d01c2ff98$e6c3aad0$8bd75ba5@IE.TAMU.EDU>
References: <004d01c2ff98$e6c3aad0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <x2ptnuglcu.fsf@biostat.ku.dk>

"Feng Zhang" <f0z6305 at labs.tamu.edu> writes:

> Hi, R-listers
> 
> I tried to plot several graphs in a sigle x-y coordinate settings, like the
> following:
> |(y)                           s
> |    ******               s
> |               *****      s
> |    sssssssssssssssssss
> |_______________________________(x)
> where "*" and "s" denote two diffrent plots.
> 
> However, when I used
> plot(data1); % data1 is the data points of "*"
> par(new=T);
> plot(data2); % data2 is the data points of "s"
> 
> I found that the x and y labels are messed up, since different graphs use
> diffrent unit length on the x-axis and y-axis.
> 
> So is there someway to avoid this problem?
> Or is there some other function plottting multiple plots in
> one x-y axis setting?

There are several. I assume data1 and data2 are data frames with an x
and a y column? Then you might do

plot(rbind(data1,data2),type="n")
points(data1,pch=1) 
points(data2,pch=2)

Another way is to do what you already did, but add explicit xlim and
ylim arguments.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From edd at debian.org  Thu Apr 10 22:17:24 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 10 Apr 2003 15:17:24 -0500
Subject: [R] A Question on lowess() function
In-Reply-To: <HDEPJCAKDEJMEEHKJOKEMEEACAAA.myao@ou.edu>
References: <Pine.LNX.4.44.0304101936200.14738-100000@gannet.stats>
	<HDEPJCAKDEJMEEHKJOKEMEEACAAA.myao@ou.edu>
Message-ID: <20030410201724.GA724@sonny.eddelbuettel.com>

On Thu, Apr 10, 2003 at 02:58:15PM -0500, Minghua Yao wrote:
> I used y<-x[!is.na(x)] to get rid of NA and NaN. But I don't know how to get
> rid of Inf.

y<-x[is.finite(x)]   # remove NA,NaN,and Inf all at once

> Also, is there more detailed info about loess() than help(loess)?

help(loess) offers a references to the literature. It doesn't get much more 
detailed than papers in scholarly journals and books.

Dirk

-- 
Wishful thinking can dominate much of the work of a profession for a decade,
but not indefinitely.   -- Robert Shiller, on Efficient Markets models, 2002


From andy_liaw at merck.com  Thu Apr 10 22:18:20 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 10 Apr 2003 16:18:20 -0400
Subject: [R] A Question on lowess() function
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F98D@usrymx25.merck.com>

"Statistical Models in S" edited by Chamber & Hastie (the "white book") has
a chapter on loess.  "Modern Applied statistics in S" by Venables & Ripley
has some coverage as well.  On top of that, you have the source code--- you
can get as detailed as you wish with that!

Andy



> -----Original Message-----
> From: Minghua Yao [mailto:myao at ou.edu]
> Sent: Thursday, April 10, 2003 3:58 PM
> To: Prof Brian Ripley
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] A Question on lowess() function
> 
> 
> Thank you for your reply.
> 
> I didn't find what I needed from the archieves. Maybe, I need 
> to figure out
> how to search the archieves effectively.
> 
> I used y<-x[!is.na(x)] to get rid of NA and NaN. But I don't 
> know how to get
> rid of Inf.
> 
> Also, is there more detailed info about loess() than help(loess)?
> 
> Thanks.
> 
> -MY
> 
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Thursday, April 10, 2003 1:38 PM
> To: Minghua Yao
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] A Question on lowess() function
> 
> 
> lowess was old-fashioned a decade ago: use loess.
> 
> And this Q was answered about a week ago, so use the archives.
> 
> On Thu, 10 Apr 2003, Minghua Yao wrote:
> 
> > I want to use lowess(x, y) where x and y are vectors of 
> length of 4000+.
> In
> > fact, x and y are log of some vectors. So, some of the 
> elements are NaN.
> > lowess() can not take away those elements then do the 
> fitting. It will
> give
> > the error message and do nothing.
> >
> > 1. Can anybody tell me how to get rid of those NaN's and 
> use lowess()?
> > 2. How to get the LOWESS fitting values for any elements in x?
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------


From ripley at stats.ox.ac.uk  Thu Apr 10 22:21:29 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 10 Apr 2003 21:21:29 +0100 (BST)
Subject: [R] A Question on lowess() function
In-Reply-To: <HDEPJCAKDEJMEEHKJOKEMEEACAAA.myao@ou.edu>
Message-ID: <Pine.LNX.4.44.0304102119350.14967-100000@gannet.stats>

On Thu, 10 Apr 2003, Minghua Yao wrote:

> Thank you for your reply.
> 
> I didn't find what I needed from the archieves. Maybe, I need to figure out
> how to search the archieves effectively.
> 
> I used y<-x[!is.na(x)] to get rid of NA and NaN. But I don't know how to get
> rid of Inf.

That's not what you asked for, and is.finite() will do that (if you apply 
it to x as well).

> Also, is there more detailed info about loess() than help(loess)?

Look at the na.action parameter ..., as well as the references.

> Thanks.
> 
> -MY
> 
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Thursday, April 10, 2003 1:38 PM
> To: Minghua Yao
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] A Question on lowess() function
> 
> 
> lowess was old-fashioned a decade ago: use loess.
> 
> And this Q was answered about a week ago, so use the archives.
> 
> On Thu, 10 Apr 2003, Minghua Yao wrote:
> 
> > I want to use lowess(x, y) where x and y are vectors of length of 4000+.
> In
> > fact, x and y are log of some vectors. So, some of the elements are NaN.
> > lowess() can not take away those elements then do the fitting. It will
> give
> > the error message and do nothing.
> >
> > 1. Can anybody tell me how to get rid of those NaN's and use lowess()?
> > 2. How to get the LOWESS fitting values for any elements in x?



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From spencer.graves at pdf.com  Thu Apr 10 22:24:53 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 10 Apr 2003 13:24:53 -0700
Subject: [R] A Question on lowess() function
References: <HDEPJCAKDEJMEEHKJOKEMEEACAAA.myao@ou.edu>
Message-ID: <3E95D315.8000400@pdf.com>

The following should solve one of your questions below:

 > is.finite(c(1, Inf))
[1]  TRUE FALSE

Spencer Graves

Minghua Yao wrote:
> Thank you for your reply.
> 
> I didn't find what I needed from the archieves. Maybe, I need to figure out
> how to search the archieves effectively.
> 
> I used y<-x[!is.na(x)] to get rid of NA and NaN. But I don't know how to get
> rid of Inf.
> 
> Also, is there more detailed info about loess() than help(loess)?
> 
> Thanks.
> 
> -MY
> 
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Thursday, April 10, 2003 1:38 PM
> To: Minghua Yao
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] A Question on lowess() function
> 
> 
> lowess was old-fashioned a decade ago: use loess.
> 
> And this Q was answered about a week ago, so use the archives.
> 
> On Thu, 10 Apr 2003, Minghua Yao wrote:
> 
> 
>>I want to use lowess(x, y) where x and y are vectors of length of 4000+.
> 
> In
> 
>>fact, x and y are log of some vectors. So, some of the elements are NaN.
>>lowess() can not take away those elements then do the fitting. It will
> 
> give
> 
>>the error message and do nothing.
>>
>>1. Can anybody tell me how to get rid of those NaN's and use lowess()?
>>2. How to get the LOWESS fitting values for any elements in x?
> 
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From rg117 at yahoo.co.uk  Thu Apr 10 22:26:53 2003
From: rg117 at yahoo.co.uk (=?iso-8859-1?q?Rishabh=20Gupta?=)
Date: Thu, 10 Apr 2003 21:26:53 +0100 (BST)
Subject: [R] multiple numerical variables in aov
Message-ID: <20030410202653.88792.qmail@web41113.mail.yahoo.com>

Hi all,
 I have a question regarding the anova function aov(). I want to perform an anova calculation
using one grouping variable but more than one numerical variables:
So instead of:
     aov(v ~ g)
I want something like
     aov(v1 + v2 + v3 ~ g)
Essentially I want to find out whether the variables v1, v2, v3, etc can collectively discriminate
between different values of variable g. Could somebody tell whether this is possible and if so
how?

Also, could somebody please tell me the difference between the aov() function and the anova()
function. I've been using aov() so far and it seems to work fine. Could somebody tell me what the
difference is and which one is better.

Any help would be greatly appreciated. Many Thanks

Rishabh


From andy_liaw at merck.com  Thu Apr 10 22:32:57 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 10 Apr 2003 16:32:57 -0400
Subject: [R] How to plot several graphs in a single 2-D figure?
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F98F@usrymx25.merck.com>

1.  Use xlim and ylim in plot(...) to make sure the axes are the same.

2.  For overlaying graphs, use plot(..., axes=FALSE, xlab="", ylab="") to
suppress the axes and labels.

Andy
> -----Original Message-----
> From: Feng Zhang [mailto:f0z6305 at labs.tamu.edu]
> Sent: Thursday, April 10, 2003 4:03 PM
> To: Iyue Sung
> Cc: R-Help
> Subject: Re: [R] How to plot several graphs in a single 2-D figure?
> 
> 
> Thanks, Iyue
> 
> But here the data1 and data2 are not necessarily two vectors.
> Maybe they are results from some other functions, defined
> as a data structure.
> Like using norMix package,
> 
> x <- norMix(mu=c(-1,0,1.5),sig2=c(.49,.36,.16),w=c(.4,.3,.3));
> plot(x); %% x is not a vector, but a structure
> y <- norMix(mu=c(-2,0,2),sig2=c(.16,.36,.64),w=c(.4,.3,.3));
> par(new=T);
> plot(y);
> 
> The result graph is messed up and x,y dont have consistent axis label
> settings.
> 
> Fred
> 
> ----- Original Message -----
> From: "Iyue Sung" <isung at epidemiology.com>
> To: "Feng Zhang" <f0z6305 at labs.tamu.edu>
> Sent: Thursday, April 10, 2003 2:55 PM
> Subject: RE: [R] How to plot several graphs in a single 2-D figure?
> 
> 
> 
> Fred, Try:
> 
> >xrange<-range(c(data1[,1],data2[,1]))
> >yrange<-range(c(data1[,2],data2[,2]))
> >
> >plot(data1, xlim=xrange, ylim=yrange, pch=1)
> >points(data2, pch=2)
> 
> -Iyue
> 
> > -----Original Message-----
> > From: Feng Zhang [mailto:f0z6305 at labs.tamu.edu]
> > Sent: Thursday, April 10, 2003 3:39 PM
> > To: R-Help
> > Subject: [R] How to plot several graphs in a single 2-D figure?
> >
> >
> > Hi, R-listers
> >
> > I tried to plot several graphs in a sigle x-y coordinate
> > settings, like the
> > following:
> > |(y)                           s
> > |    ******               s
> > |               *****      s
> > |    sssssssssssssssssss
> > |_______________________________(x)
> > where "*" and "s" denote two diffrent plots.
> >
> > However, when I used
> > plot(data1); % data1 is the data points of "*"
> > par(new=T);
> > plot(data2); % data2 is the data points of "s"
> >
> > I found that the x and y labels are messed up, since
> > different graphs use
> > diffrent unit length on the x-axis and y-axis.
> >
> > So is there someway to avoid this problem?
> > Or is there some other function plottting multiple plots in
> > one x-y axis setting?
> >
> > Thanks for your point and help.
> >
> > Fred
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------


From myao at ou.edu  Fri Apr 11 00:03:19 2003
From: myao at ou.edu (Minghua Yao)
Date: Thu, 10 Apr 2003 17:03:19 -0500
Subject: [R] A Question on lowess() function
In-Reply-To: <Pine.LNX.4.44.0304102119350.14967-100000@gannet.stats>
Message-ID: <HDEPJCAKDEJMEEHKJOKEIEECCAAA.myao@ou.edu>

I still haven't found out from the mail archieves

How to get the LOWESS or LOESS fitting values for any elements in x?

Help please. Thanks.

-MY

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent: Thursday, April 10, 2003 3:21 PM
To: Minghua Yao
Cc: r-help at stat.math.ethz.ch
Subject: RE: [R] A Question on lowess() function


On Thu, 10 Apr 2003, Minghua Yao wrote:

> Thank you for your reply.
>
> I didn't find what I needed from the archieves. Maybe, I need to figure
out
> how to search the archieves effectively.
>
> I used y<-x[!is.na(x)] to get rid of NA and NaN. But I don't know how to
get
> rid of Inf.

That's not what you asked for, and is.finite() will do that (if you apply
it to x as well).

> Also, is there more detailed info about loess() than help(loess)?

Look at the na.action parameter ..., as well as the references.

> Thanks.
>
> -MY
>
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Thursday, April 10, 2003 1:38 PM
> To: Minghua Yao
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] A Question on lowess() function
>
>
> lowess was old-fashioned a decade ago: use loess.
>
> And this Q was answered about a week ago, so use the archives.
>
> On Thu, 10 Apr 2003, Minghua Yao wrote:
>
> > I want to use lowess(x, y) where x and y are vectors of length of 4000+.
> In
> > fact, x and y are log of some vectors. So, some of the elements are NaN.
> > lowess() can not take away those elements then do the fitting. It will
> give
> > the error message and do nothing.
> >
> > 1. Can anybody tell me how to get rid of those NaN's and use lowess()?
> > 2. How to get the LOWESS fitting values for any elements in x?



--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Fri Apr 11 01:53:52 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 11 Apr 2003 01:53:52 +0200
Subject: [R] A Question on lowess() function
In-Reply-To: <HDEPJCAKDEJMEEHKJOKEIEECCAAA.myao@ou.edu>
References: <HDEPJCAKDEJMEEHKJOKEIEECCAAA.myao@ou.edu>
Message-ID: <x2d6jthptb.fsf@biostat.ku.dk>

Minghua Yao <myao at ou.edu> writes:

> I still haven't found out from the mail archieves
> 
> How to get the LOWESS or LOESS fitting values for any elements in x?
> 
> Help please. Thanks.

Not to put too fine a point on it: This is contained in the example
in help(loess) and help(predict.loess)!

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From andy_liaw at merck.com  Fri Apr 11 01:54:27 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 10 Apr 2003 19:54:27 -0400
Subject: [R] A Question on lowess() function
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F993@usrymx25.merck.com>

On the "See Also" section of the help page to loess(), there's a link to
"predict.loess".  On that help page, under "Arguments":

newdata   an optional data frame specifying points at 
          which to do the predictions. If missing, the 
          original data points are used. 

There, I've read the documentation for you.

Andy

> -----Original Message-----
> From: Minghua Yao [mailto:myao at ou.edu]
> Sent: Thursday, April 10, 2003 6:03 PM
> To: Prof Brian Ripley
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] A Question on lowess() function
> 
> 
> I still haven't found out from the mail archieves
> 
> How to get the LOWESS or LOESS fitting values for any elements in x?
> 
> Help please. Thanks.
> 
> -MY
> 
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Thursday, April 10, 2003 3:21 PM
> To: Minghua Yao
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] A Question on lowess() function
> 
> 
> On Thu, 10 Apr 2003, Minghua Yao wrote:
> 
> > Thank you for your reply.
> >
> > I didn't find what I needed from the archieves. Maybe, I 
> need to figure
> out
> > how to search the archieves effectively.
> >
> > I used y<-x[!is.na(x)] to get rid of NA and NaN. But I 
> don't know how to
> get
> > rid of Inf.
> 
> That's not what you asked for, and is.finite() will do that 
> (if you apply
> it to x as well).
> 
> > Also, is there more detailed info about loess() than help(loess)?
> 
> Look at the na.action parameter ..., as well as the references.
> 
> > Thanks.
> >
> > -MY
> >
> > -----Original Message-----
> > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > Sent: Thursday, April 10, 2003 1:38 PM
> > To: Minghua Yao
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] A Question on lowess() function
> >
> >
> > lowess was old-fashioned a decade ago: use loess.
> >
> > And this Q was answered about a week ago, so use the archives.
> >
> > On Thu, 10 Apr 2003, Minghua Yao wrote:
> >
> > > I want to use lowess(x, y) where x and y are vectors of 
> length of 4000+.
> > In
> > > fact, x and y are log of some vectors. So, some of the 
> elements are NaN.
> > > lowess() can not take away those elements then do the 
> fitting. It will
> > give
> > > the error message and do nothing.
> > >
> > > 1. Can anybody tell me how to get rid of those NaN's and 
> use lowess()?
> > > 2. How to get the LOWESS fitting values for any elements in x?
> 
> 
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------


From f0z6305 at labs.tamu.edu  Fri Apr 11 07:06:01 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu, 10 Apr 2003 22:06:01 -0700
Subject: [R] How to plot a sample or empirical density function?
References: <007601c2fe1e$32d57880$8bd75ba5@IE.TAMU.EDU>
	<3E934F02.4060702@pdf.com>
Message-ID: <000f01c2ffe8$0c3412b0$5e485ba5@zhangfeng>

Hey, R-listers:

Given a one-dimensional sample data set, I want to 
plot its empirical density function.
So with the vector data X, can R provide some function
to plot its sample density?

Thanks for your attention.

Fred


From tvr at stanford.edu  Fri Apr 11 06:09:15 2003
From: tvr at stanford.edu (tvr@stanford.edu)
Date: Thu, 10 Apr 2003 21:09:15 -0700
Subject: [R] princomp with not non-negative definite correlation matrix
Message-ID: <1050034155.3e963febd1b0b@webmail.stanford.edu>

$ R --version
R 1.6.1 (2002-11-01).

So I would like to perform principal components analysis on a 16X16
correlation matrix, [princomp(cov.mat=x) where x is correlation matrix],
the problem is princomp complains that it is not non-negative definite.

I called eigen() on the correlation matrix and found that one of the 
eigenvectors is close to zero & negative (-0.001832311). Is there any
way to work around this problem. A constraint: I only have the
correlation matrix, not the data that produced it. 

I believe I could replicate most of the functionality of princomp
step-by-step (loadings, scores, etc.) and track the effect of the
negative eigenvector on the rest of the analysis, but I'd rather not do
that with every covariance/correlation matrix that might have a few
eigenvectors that are negative but close to zero.

(I've attached the matrix if anyone wants to replicate the error)
-------------- next part --------------
1.00 0.99 0.36 0.99 0.91 0.25 0.31 0.44 0.22 0.45 0.66 0.16 0.39 0.34 0.55 0.02
0.99 1.00 0.34 0.99 0.92 0.25 0.31 0.44 0.22 0.45 0.66 0.16 0.39 0.33 0.55 0.01
0.36 0.34 1.00 0.32 0.28 0.21 0.08 0.33 0.23 0.34 0.29 0.08 0.32 0.18 0.36 0.04
0.99 0.99 0.32 1.00 0.89 0.25 0.33 0.44 0.22 0.45 0.67 0.13 0.39 0.36 0.54 0.01
0.91 0.92 0.28 0.89 1.00 0.24 0.28 0.38 0.19 0.42 0.49 0.17 0.32 0.27 0.54 0.01
0.25 0.25 0.21 0.25 0.24 1.00 0.48 0.69 0.62 0.69 0.29 0.32 0.67 0.46 0.65 0.18
0.31 0.31 0.08 0.33 0.28 0.48 1.00 0.35 0.28 0.35 0.26 0.15 0.33 0.26 0.33 0.01
0.44 0.44 0.33 0.44 0.38 0.69 0.35 1.00 0.91 0.95 0.54 0.43 0.99 0.65 0.77 0.15
0.22 0.22 0.23 0.22 0.19 0.62 0.28 0.91 1.00 0.77 0.31 0.34 0.92 0.59 0.54 0.07
0.45 0.45 0.34 0.45 0.42 0.69 0.35 0.95 0.77 1.00 0.51 0.47 0.93 0.57 0.84 0.19
0.66 0.66 0.29 0.67 0.49 0.29 0.26 0.54 0.31 0.51 1.00 0.20 0.50 0.49 0.53 0.14
0.16 0.16 0.08 0.13 0.17 0.32 0.15 0.43 0.34 0.47 0.20 1.00 0.35 0.30 0.34 0.16
0.39 0.39 0.32 0.39 0.32 0.67 0.33 0.99 0.92 0.93 0.50 0.35 1.00 0.57 0.71 0.13
0.34 0.33 0.18 0.36 0.27 0.46 0.26 0.65 0.59 0.57 0.49 0.30 0.57 1.00 0.49 0.16
0.55 0.55 0.36 0.54 0.54 0.65 0.33 0.77 0.54 0.84 0.53 0.34 0.71 0.49 1.00 0.20
0.02 0.01 0.04 0.01 0.01 0.18 0.01 0.15 0.07 0.19 0.14 0.16 0.13 0.16 0.20 1.00

From otoomet at econ.dk  Fri Apr 11 07:13:39 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Fri, 11 Apr 2003 07:13:39 +0200
Subject: [R] How to plot several graphs in a single 2-D figure?
In-Reply-To: <005d01c2ff9c$3e330fb0$8bd75ba5@IE.TAMU.EDU>
	(f0z6305@labs.tamu.edu)
References: <433782665F24734CB1EDEF38E0F9F3EF31AC28@ntserver>
	<005d01c2ff9c$3e330fb0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <200304110513.h3B5DdQ13318@punik.econ.au.dk>

Hi,

you are definitely looking for functions like points() and lines().
E.g. do

plot(x)
lines(y)

lines() uses the previous coordinate system (defined by plot()) and
does not draw any axes.  Of course, x and y should have rougly the
same range (consider also plot(x, xlim=..., ylim=...).  If the scales
are very different, you should rescale e.g. y and draw a new axis
(look ?axis).

Perhaps it helps.

Ott

 | From: "Feng Zhang" <f0z6305 at labs.tamu.edu>
 | Date: Thu, 10 Apr 2003 15:03:24 -0500
 | 
 | Thanks, Iyue
 | 
 | But here the data1 and data2 are not necessarily two vectors.
 | Maybe they are results from some other functions, defined
 | as a data structure.
 | Like using norMix package,
 | 
 | x <- norMix(mu=c(-1,0,1.5),sig2=c(.49,.36,.16),w=c(.4,.3,.3));
 | plot(x); %% x is not a vector, but a structure
 | y <- norMix(mu=c(-2,0,2),sig2=c(.16,.36,.64),w=c(.4,.3,.3));
 | par(new=T);
 | plot(y);
 | 
 | The result graph is messed up and x,y dont have consistent axis label
 | settings.
 | 
 | Fred


From H.RINNER at tirol.gv.at  Fri Apr 11 08:32:43 2003
From: H.RINNER at tirol.gv.at (RINNER Heinrich)
Date: Fri, 11 Apr 2003 08:32:43 +0200
Subject: AW: [R]  Exact confidence intervals based on the hypergeometric d
	istribuiton
Message-ID: <C4D44AB4CB62D311BA6500041202E886031EE1F9@xms1.tirol.gv.at>

I have asked about this on this list some while ago, so you might find the
following answer useful:
http://finzi.psych.upenn.edu/R/Rhelp00/archive/1756.html

Basically it shows that you can use a combination of "uniroot" and "phyper"
here. 

-Heinrich. 

> -----Urspr?ngliche Nachricht-----
> Von: Washington Santos da Silva [mailto:wss at ufla.br] 
> Gesendet: Donnerstag, 10. April 2003 19:03
> An: R-help at stat.math.ethz.ch
> Betreff: [R] Exact confidence intervals based on the 
> hypergeometric distribuiton
> 
> 
> I need to estimates some exact confidence intervals for one 
> proportion based on the exact hypergeometric distribution of 
> the number of 
> units in the sample with the attribute. Does a code exist for 
> performing such 
> procedure? 
> 
> Thanks for your help.
> 
> Washington S. Silva
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From ng_angie_03 at yahoo.co.uk  Thu Apr 10 12:47:36 2003
From: ng_angie_03 at yahoo.co.uk (=?iso-8859-1?q?Angie=20Ng?=)
Date: Thu, 10 Apr 2003 11:47:36 +0100 (BST)
Subject: [R] re:  question on R
Message-ID: <20030410104736.99030.qmail@web41812.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030410/509c1c7b/attachment.pl

From hb at maths.lth.se  Fri Apr 11 09:14:20 2003
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 11 Apr 2003 09:14:20 +0200
Subject: [R] R under Sun Solaris 8
In-Reply-To: <20030410154934.GA25701@mail1.sas.upenn.edu>
Message-ID: <001d01c2fff9$f90a0c00$e502eb82@alpha.wehi.edu.au>

Hi, I remember having the same problem when I tried to install a
personal version on our Sun Solaris 8 system. As readline was not in my
search paths the command line editing did not work. I do the following
before calling configure and make:

# Readline related stuff needed by [R] (readline is required for 
# the command line history in [R] to work).
# C.f. R-FAQ: "7.22 How can I get command line editing to work?"
# and "R Installation and Administration" on www.r-project.org
# Library path to 'libreadline.*'. Don't forget the prefix '-L'
LIBS=-L/usr/common2/appjoa/lib.sun4
export LIBS
# Source path to 'readline.h' etc. Don't forget the prefix '-I'
CPPFLAGS=-I/usr/common2/appjoa/include
export CPPFLAGS 

Maybe this is what you are missing

Henrik Bengtsson

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jonathan Baron
> Sent: den 10 april 2003 17:50
> To: Klaus-Peter Pleissner
> Cc: R-Help
> Subject: Re: [R] R under Sun Solaris 8
> 
> 
> On 04/10/03 17:30, Klaus-Peter Pleissner wrote:
> >Hi,
> >
> >I have installed R1.6.2 on a Sun Sparc workstatioin 60 under 
> Solaris 8. 
> >I' m using csh, tcsh or bash- shell. Unfortunately, it is 
> impossible to 
> >use the "arrow-up" key  on  Sun's German keyboard to repeat 
> a R command 
> >by using this key.
> >
> >Always following syntax error occurs:
> >^[[A
> >
> >Does anybody have a hint ?
> 
> A hint, yes.  You may not have the readline library 
> installed. This is discussed in the installation notes.
> 
> Whether this is the problem, I do not know.
> 
> Jon
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://www.stat.math.ethz.ch/mailman/listinfo> /r-help
> 
>


From gerds at fdm.uni-freiburg.de  Fri Apr 11 10:25:41 2003
From: gerds at fdm.uni-freiburg.de (Thomas Gerds)
Date: Fri, 11 Apr 2003 10:25:41 +0200
Subject: [R] summary.formula: method reverse does not use fun argument
Message-ID: <7ewui1bfui.fsf@rembrandt.fdm.uni-freiburg.de>

hi,

recently i discovered the functionability summary.formula, awesome!
from the help page i understand that method=reverse allows to
summarize all variables on the right hand side of formula 
(the help page on line 229 wrongly refers to the left? hand side variables)
in categories which are determined by a single left hand side
variable.

my problem is that the argument fun seems not to be compatible with
method=reverse!? every continuous variable is summarized in three
quantiles.

here is an example:

hist is a factor, PET and CT are "numeric" 

summary(PET~hist,data=her,fun=sum)
PET    N=47

+-------+------------------+--+---+
|       |                  |N |PET|
+-------+------------------+--+---+
|hist   |Morbus Hodgkin    |18| 81|
|       |Niedrigmaligne NHL|11| 39|
|       |Hochmaligne NHL   |18| 49|
+-------+------------------+--+---+
|Overall|                  |47|169|
+-------+------------------+--+---+

> summary(CT~hist,data=her,fun=sum)
CT    N=47

+-------+------------------+--+---+
|       |                  |N |CT |
+-------+------------------+--+---+
|hist   |Morbus Hodgkin    |18| 70|
|       |Niedrigmaligne NHL|11| 16|
|       |Hochmaligne NHL   |18| 32|
+-------+------------------+--+---+
|Overall|                  |47|118|
+-------+------------------+--+---+

it would be desirable to combine both tables such that there is one
column for PET and one for CT ... is this possible?

trying method=reverse gives:

summary(hist~PET+CT,data=her,fun=sum,method="reverse") 

Descriptive Statistics by hist

+------+---------------+-------------------+----------------+
|      |Morbus Hodgkin |Niedrigmaligne NHL |Hochmaligne NHL |
|      |(N=18)         |(N=11)             |(N=18)          |
+------+---------------+-------------------+----------------+
|PET   |3.00/3.50/6.75 |1.50/3.00/6.00     |1.00/2.00/3.75  |
+------+---------------+-------------------+----------------+
|CT : 0|     0% (0)    |    36% (4)        |    28% (5)     |
+------+---------------+-------------------+----------------+
|    1 |    11% (2)    |     9% (1)        |    28% (5)     |
+------+---------------+-------------------+----------------+
|    2 |    28% (5)    |    36% (4)        |    11% (2)     |
+------+---------------+-------------------+----------------+
|    3 |    17% (3)    |     9% (1)        |    11% (2)     |
+------+---------------+-------------------+----------------+
|    4 |    11% (2)    |     9% (1)        |    17% (3)     |
+------+---------------+-------------------+----------------+
|    5 |     6% (1)    |     0% (0)        |     6% (1)     |
+------+---------------+-------------------+----------------+
|    6 |     6% (1)    |     0% (0)        |     0% (0)     |
+------+---------------+-------------------+----------------+
|    7 |    11% (2)    |     0% (0)        |     0% (0)     |
+------+---------------+-------------------+----------------+
|    8 |    11% (2)    |     0% (0)        |     0% (0)     |
+------+---------------+-------------------+----------------+

thanks a lot in advance,
tomy

-- 
no signature


From wegmann at biozentrum.uni-wuerzburg.de  Fri Apr 11 11:42:27 2003
From: wegmann at biozentrum.uni-wuerzburg.de (Martin Wegmann)
Date: Fri, 11 Apr 2003 11:42:27 +0200
Subject: [R] mean etc at the end of column
Message-ID: <3E968E03.9B3F52A1@biozentrum.uni-wuerzburg.de>

Hello

I would like to know how I can add mean, max etc (summary(), acf or lm()
...)) at the end of a column in a data frame or as a new data frame with
several columns corresponding to the input columns instead of having a
separate output.

thanks in advance, cheers Martin



--
Martin Wegmann
Department of Animal Ecology and Tropical Biology
Zoology III, Biocenter
Am Hubland
97074 W?rzburg
Germany
0931/888-4378
wegmann at biozentrum.uni-wuerzburg.de
m.wegmann at web.de


From stevan.goode at micron-research.com  Fri Apr 11 12:11:13 2003
From: stevan.goode at micron-research.com (Stevan Goode)
Date: Fri, 11 Apr 2003 11:11:13 +0100
Subject: [R] CGI output
Message-ID: <3E9694C1.4060908@micron-research.com>

Hi all,

I'm trying to interface an R program output into a PHP program. What I'm 
after at the moment is to know if there's a way to redirect the output 
from the R command line program to STDOUT instead of into a file.

If anyone can help me out on this I'd be grateful.

Thanks,

Steve


From nielssteenkrogh at hotmail.com  Fri Apr 11 12:37:54 2003
From: nielssteenkrogh at hotmail.com (Niels Steen Krogh)
Date: Fri, 11 Apr 2003 12:37:54 +0200
Subject: [R] danish characters - installing R - linux redhat 8.0
Message-ID: <F106FRnuh2GCLzCOegJ00006712@hotmail.com>

I'm using R on a linux redhat 8.0 installation.

The special danish characters () are showed wrong on the screen.

Example:

yy<-matrix(c(0,2,1,1,8),ncol=1,dimnames=list(c("Br","AGF","AB","Farum","FC-Kbh." 
),c("Stemmer")))

barplot(yy[1:5],ylab=names(as.data.frame(yy)),main="5. grade.... ")


Any hints?



Cand. Polit.
Niels Steen Krogh
Solsortvej 44
2000 F.

Tlf: 3888 8613

ZiteLab / Empower your data



_________________________________________________________________
F Hotmail p mobilen http://www.msn.dk/mobile


From rg117 at yahoo.co.uk  Fri Apr 11 12:42:06 2003
From: rg117 at yahoo.co.uk (=?iso-8859-1?q?Rishabh=20Gupta?=)
Date: Fri, 11 Apr 2003 11:42:06 +0100 (BST)
Subject: [R] multiple numerical variables in aov
Message-ID: <20030411104206.18113.qmail@web41114.mail.yahoo.com>

Hi all,
 I have a question regarding the anova function aov(). I want to perform an anova calculation
using one grouping variable but more than one numerical variables:
So instead of:
     aov(v ~ g)
I want something like
     aov(v1 + v2 + v3 ~ g)
Essentially I want to find out whether the variables v1, v2, v3, etc can collectively discriminate
between different values of variable g. Could somebody tell whether this is possible and if so
how?

Also, could somebody please tell me the difference between the aov() function and the anova()
function. I've been using aov() so far and it seems to work fine. Could somebody tell me what the
difference is and which one is better.

Any help would be greatly appreciated. Many Thanks

Rishabh


From ripley at stats.ox.ac.uk  Fri Apr 11 12:52:48 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 11 Apr 2003 11:52:48 +0100 (BST)
Subject: [R] multiple numerical variables in aov
In-Reply-To: <20030411104206.18113.qmail@web41114.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0304111147380.17384-100000@gannet.stats>

On Fri, 11 Apr 2003, Rishabh Gupta wrote:

>  I have a question regarding the anova function aov(). I want to perform 
> an anova calculation
> using one grouping variable but more than one numerical variables:
> So instead of:
>      aov(v ~ g)
> I want something like
>      aov(v1 + v2 + v3 ~ g)
> Essentially I want to find out whether the variables v1, v2, v3, etc can collectively discriminate
> between different values of variable g. Could somebody tell whether this is possible and if so
> how?

You might intend MANOVA, run in R by

summary(manova(cbind(v1,v2,v3) ~g)))

but from your words it sounds like you want lda(g ~ v1+v2+v3).

> Also, could somebody please tell me the difference between the aov() function and the anova()
> function. I've been using aov() so far and it seems to work fine. Could somebody tell me what the
> difference is and which one is better.

They are completely different. anova() extracts results from one or more
fitted models.

See the help pages or any of the good books on using S.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Fri Apr 11 12:57:14 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 11 Apr 2003 11:57:14 +0100 (BST)
Subject: [R] CGI output
In-Reply-To: <3E9694C1.4060908@micron-research.com>
Message-ID: <Pine.LNX.4.44.0304111153050.17384-100000@gannet.stats>

On Fri, 11 Apr 2003, Stevan Goode wrote:

> I'm trying to interface an R program output into a PHP program. What I'm 
> after at the moment is to know if there's a way to redirect the output 
> from the R command line program to STDOUT instead of into a file.

Output goes to stdout by default.  (Note: the upcoming 1.7.0 sends errors
to stderr and all other output to stdout by default.)  There are quite a
few examples in the R sources of running R from Perl and capturing the
output on stdout (although these are complicated by deficiencies of
Windows Perl on Win9X).

You may need to tell us more about what you are trying to do.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ccleland at optonline.net  Fri Apr 11 13:42:17 2003
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 11 Apr 2003 07:42:17 -0400
Subject: [R] multiple numerical variables in aov
In-Reply-To: <20030411104206.18113.qmail@web41114.mail.yahoo.com>
References: <20030411104206.18113.qmail@web41114.mail.yahoo.com>
Message-ID: <3E96AA19.70206@optonline.net>

Rishabh Gupta wrote:
> I want something like
>      aov(v1 + v2 + v3 ~ g)
> Essentially I want to find out whether the variables v1, v2, v3, etc can collectively discriminate
> between different values of variable g. Could somebody tell whether this is possible and if so
> how?

Rishabh:
   With v1, v2, v3, and g in the dataframe mydata, try the following:

summary(manova(cbind(v1, v2, v3) ~ g, data = mydata), test="Wilks")

hope it helps,

Chuck Cleland


From fharrell at virginia.edu  Fri Apr 11 13:50:46 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 11 Apr 2003 07:50:46 -0400
Subject: [R] summary.formula: method reverse does not use fun argument
In-Reply-To: <7ewui1bfui.fsf@rembrandt.fdm.uni-freiburg.de>
References: <7ewui1bfui.fsf@rembrandt.fdm.uni-freiburg.de>
Message-ID: <20030411075046.5d32c3e2.fharrell@virginia.edu>

On Fri, 11 Apr 2003 10:25:41 +0200
Thomas Gerds <gerds at fdm.uni-freiburg.de> wrote:

> hi,
> 
> recently i discovered the functionability summary.formula, awesome!
> from the help page i understand that method=reverse allows to
> summarize all variables on the right hand side of formula 
> (the help page on line 229 wrongly refers to the left? hand side variables)
> in categories which are determined by a single left hand side
> variable.

Sorry about the typo.  You are correct, that should have been "right hand side variables".

> 
> my problem is that the argument fun seems not to be compatible with
> method=reverse!? every continuous variable is summarized in three
> quantiles.

As stated in the documentation, fun applies only to method='response' and method='cross'.

> 
> here is an example:
> 
> hist is a factor, PET and CT are "numeric" 
> 
> summary(PET~hist,data=her,fun=sum)
> PET    N=47
> 
> +-------+------------------+--+---+
> |       |                  |N |PET|
> +-------+------------------+--+---+
> |hist   |Morbus Hodgkin    |18| 81|
> |       |Niedrigmaligne NHL|11| 39|
> |       |Hochmaligne NHL   |18| 49|
> +-------+------------------+--+---+
> |Overall|                  |47|169|
> +-------+------------------+--+---+
> 
> > summary(CT~hist,data=her,fun=sum)
> CT    N=47
> 
> +-------+------------------+--+---+
> |       |                  |N |CT |
> +-------+------------------+--+---+
> |hist   |Morbus Hodgkin    |18| 70|
> |       |Niedrigmaligne NHL|11| 16|
> |       |Hochmaligne NHL   |18| 32|
> +-------+------------------+--+---+
> |Overall|                  |47|118|
> +-------+------------------+--+---+
> 
> it would be desirable to combine both tables such that there is one
> column for PET and one for CT ... is this possible?

Yes, see the documentation.  Create a bivariate response variable with cbind and use a bivariate summarization function as 'fun'.  And note that using 'stratify(someothervariable)' you can create multiple groups across columns as with method='reverse'; you just can't get statistical tests for them with method='response'.

Frank Harrell

> 
> trying method=reverse gives:
> 
> summary(hist~PET+CT,data=her,fun=sum,method="reverse") 
> 
> Descriptive Statistics by hist
> 
> +------+---------------+-------------------+----------------+
> |      |Morbus Hodgkin |Niedrigmaligne NHL |Hochmaligne NHL |
> |      |(N=18)         |(N=11)             |(N=18)          |
> +------+---------------+-------------------+----------------+
> |PET   |3.00/3.50/6.75 |1.50/3.00/6.00     |1.00/2.00/3.75  |
> +------+---------------+-------------------+----------------+
> |CT : 0|     0% (0)    |    36% (4)        |    28% (5)     |
> +------+---------------+-------------------+----------------+
> |    1 |    11% (2)    |     9% (1)        |    28% (5)     |
> +------+---------------+-------------------+----------------+
> |    2 |    28% (5)    |    36% (4)        |    11% (2)     |
> +------+---------------+-------------------+----------------+
> |    3 |    17% (3)    |     9% (1)        |    11% (2)     |
> +------+---------------+-------------------+----------------+
> |    4 |    11% (2)    |     9% (1)        |    17% (3)     |
> +------+---------------+-------------------+----------------+
> |    5 |     6% (1)    |     0% (0)        |     6% (1)     |
> +------+---------------+-------------------+----------------+
> |    6 |     6% (1)    |     0% (0)        |     0% (0)     |
> +------+---------------+-------------------+----------------+
> |    7 |    11% (2)    |     0% (0)        |     0% (0)     |
> +------+---------------+-------------------+----------------+
> |    8 |    11% (2)    |     0% (0)        |     0% (0)     |
> +------+---------------+-------------------+----------------+
> 
> thanks a lot in advance,
> tomy

-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From Isabelle.ZABALZA-MEZGHANI at ifp.fr  Fri Apr 11 14:29:04 2003
From: Isabelle.ZABALZA-MEZGHANI at ifp.fr (ZABALZA-MEZGHANI Isabelle)
Date: Fri, 11 Apr 2003 14:29:04 +0200
Subject: [R] Latin hyper cube
Message-ID: <488C02265C6AD611BF200002A542182F022B3381@irnts22.ifp.fr>

Hello,

I would like to know if somebody has an algorithm in R langage for building
Latin hyper cube ?

Thanks in advance

Isabelle


From bates at stat.wisc.edu  Fri Apr 11 14:35:49 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 11 Apr 2003 07:35:49 -0500
Subject: [R] mean etc at the end of column
In-Reply-To: <3E968E03.9B3F52A1@biozentrum.uni-wuerzburg.de>
References: <3E968E03.9B3F52A1@biozentrum.uni-wuerzburg.de>
Message-ID: <6r65plb49m.fsf@bates4.stat.wisc.edu>

Martin Wegmann <wegmann at biozentrum.uni-wuerzburg.de> writes:

> Hello
> 
> I would like to know how I can add mean, max etc (summary(), acf or lm()
> ...)) at the end of a column in a data frame or as a new data frame with
> several columns corresponding to the input columns instead of having a
> separate output.

use rbind to add a row created by
 unlist(lapply(dataframe, summary.function))
as in

> data(women)
> wsumry = rbind(women, unlist(lapply(women, mean)))
> wsumry
   height   weight
1      58 115.0000
2      59 117.0000
3      60 120.0000
4      61 123.0000
5      62 126.0000
6      63 129.0000
7      64 132.0000
8      65 135.0000
9      66 139.0000
10     67 142.0000
11     68 146.0000
12     69 150.0000
13     70 154.0000
14     71 159.0000
15     72 164.0000
16     65 136.7333

However, you may want to ask yourself if you really want to do this.
It is hard to distinguish that last row of means from the rest of the
data.  In general I would suggest keeping the summary separate from
the original data.

-- 
Douglas Bates                            bates at stat.wisc.edu
Statistics Department                    608/262-2598
University of Wisconsin - Madison        http://www.stat.wisc.edu/~bates/


From rg117 at yahoo.co.uk  Fri Apr 11 16:07:27 2003
From: rg117 at yahoo.co.uk (=?iso-8859-1?q?Rishabh=20Gupta?=)
Date: Fri, 11 Apr 2003 15:07:27 +0100 (BST)
Subject: [R] multiple numerical variables in aov
In-Reply-To: <3E96AA19.70206@optonline.net>
Message-ID: <20030411140727.73497.qmail@web41105.mail.yahoo.com>

Hi Chuck,
 Thanks very much for your help. Just a follow up question..

Like I said I was using aov() instead of anova(). I want to maintain maximum compatability with
what I've been using so far and I notice that manova() is just a wrapper to aov(). How important
is it to use summary(......, test="Wilks") exactly, do you think that the default test statistic
would be sufficient.

Once again, many thanks for your help.

Rishabh

 --- Chuck Cleland <ccleland at optonline.net> wrote: > Rishabh Gupta wrote:
> > I want something like
> >      aov(v1 + v2 + v3 ~ g)
> > Essentially I want to find out whether the variables v1, v2, v3, etc can collectively
> discriminate
> > between different values of variable g. Could somebody tell whether this is possible and if so
> > how?
> 
> Rishabh:
>    With v1, v2, v3, and g in the dataframe mydata, try the following:
> 
> summary(manova(cbind(v1, v2, v3) ~ g, data = mydata), test="Wilks")
> 
> hope it helps,
> 
> Chuck Cleland
> 
>


From ccleland at optonline.net  Fri Apr 11 16:17:58 2003
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 11 Apr 2003 10:17:58 -0400
Subject: [R] multiple numerical variables in aov
In-Reply-To: <20030411140727.73497.qmail@web41105.mail.yahoo.com>
References: <20030411140727.73497.qmail@web41105.mail.yahoo.com>
Message-ID: <3E96CE96.9030409@optonline.net>

Rishabh Gupta wrote:
> Like I said I was using aov() instead of anova(). I want to maintain maximum compatability with
> what I've been using so far and I notice that manova() is just a wrapper to aov(). How important
> is it to use summary(......, test="Wilks") exactly, do you think that the default test statistic
> would be sufficient.

Rishabh:
   The default multivariate test would be based on Pillai's 
trace.  That may meet your needs.  Also, note how the following 
differ:

summary(manova(cbind(v1, v2, v3) ~ g, data = mydata))

vs.

summary(aov(cbind(v1, v2, v3) ~ g, data = mydata))

   So if I understood your initial request, I think you want 
summary(manova()) and not summary(aov()).

hope it helps,

Chuck Cleland


From tlumley at u.washington.edu  Fri Apr 11 17:26:19 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 11 Apr 2003 08:26:19 -0700 (PDT)
Subject: [R] multiple numerical variables in aov
In-Reply-To: <20030411104206.18113.qmail@web41114.mail.yahoo.com>
Message-ID: <Pine.A41.4.44.0304110820370.100930-100000@homer03.u.washington.edu>

On Fri, 11 Apr 2003, [iso-8859-1] Rishabh Gupta wrote:

> Hi all,
>  I have a question regarding the anova function aov(). I want to perform an anova calculation
> using one grouping variable but more than one numerical variables:
> So instead of:
>      aov(v ~ g)
> I want something like
>      aov(v1 + v2 + v3 ~ g)

> Essentially I want to find out whether the variables v1, v2, v3, etc can
> collectively discriminate between different values of variable g. Could
> somebody tell whether this is possible and if so how?

help(aov) does say that the formula can specify multiple responses,
though admittedly it doesn't explain how.  You use

       aov(cbind(v1,v2,v3)~g)

However, if you want to find out about whether these variables
collectively discriminate this will not be the right way. You want
something like lda() in the MASS package.

> Also, could somebody please tell me the difference between the aov()
> function and the anova() function. I've been using aov() so far and it
> seems to work fine. Could somebody tell me what the difference is and
> which one is better.

They are both of excellent quality :). They do completely different
things. As their respective help pages say

 Compute analysis of variance (or deviance) tables for one or more
     fitted model objects.

 Fit an analysis of variance model by a call to `lm' for each
     stratum.



	-thomas


From tlumley at u.washington.edu  Fri Apr 11 17:38:55 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 11 Apr 2003 08:38:55 -0700 (PDT)
Subject: [R] summary.formula: method reverse does not use fun argument
In-Reply-To: <7ewui1bfui.fsf@rembrandt.fdm.uni-freiburg.de>
Message-ID: <Pine.A41.4.44.0304110830040.100930-100000@homer03.u.washington.edu>

On Fri, 11 Apr 2003, Thomas Gerds wrote:

> hi,
>
> recently i discovered the functionability summary.formula, awesome!

It would be useful to say *where* you discovered it -- it is in a package
that isn't yet on CRAN.


> from the help page i understand that method=reverse allows to
> summarize all variables on the right hand side of formula
> (the help page on line 229 wrongly refers to the left? hand side variables)
> in categories which are determined by a single left hand side
> variable.
>
> my problem is that the argument fun seems not to be compatible with
> method=reverse!? every continuous variable is summarized in three
> quantiles.

Yes, that's what the help page says.

It also says that for the default method="response" the response variable
can be multivariate, which seems to be what you want.  It says many other
helpful things, too.


	-thomas


From rg117 at yahoo.co.uk  Fri Apr 11 17:55:30 2003
From: rg117 at yahoo.co.uk (=?iso-8859-1?q?Rishabh=20Gupta?=)
Date: Fri, 11 Apr 2003 16:55:30 +0100 (BST)
Subject: [R] multiple numerical variables in aov
In-Reply-To: <Pine.LNX.4.44.0304111548350.21223-100000@gannet.stats>
Message-ID: <20030411155530.70990.qmail@web41101.mail.yahoo.com>

Prof,
 It is true that you sent me the email earlier but the way that my email is sorted, Chuck's emails
were at the top of my list and hence I read it and responded to it first.
With respect to providing me with *all* the info, Chuck did this also although he did so in two
differnt emails. He seems to have CCed only one of them two the r-help mailing list though.
Finally, my follow up question was about something that was mentioned in Chuck's email but was not
in yours.

THANK YOU

Rishabh

 --- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote: > On Fri, 11 Apr 2003, Rishabh Gupta wrote:
> 
> >  Thanks very much for your help. Just a follow up question..
> 
> Although you had been told precisely that earlier, for some reason I don't 
> get any thanks.
> 
> > Like I said I was using aov() instead of anova(). I want to maintain maximum compatability
> with
> > what I've been using so far and I notice that manova() is just a wrapper to 
> > aov(). 
> 
> Notice a bit harder.  The `wrapper' changes the class, and summary.manova
> does all the work.
> 
> > How important
> > is it to use summary(......, test="Wilks") exactly, do you think that the default test
> statistic
> > would be sufficient.
> 
> Sufficient for what?  The default test is the default for a good reason.
> 
> > Once again, many thanks for your help.
> 
> Once again, it is not polite to ignore others who give you the same help, 
> especially when it comes from the person who provided you with *all* of 
> this.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From f0z6305 at labs.tamu.edu  Fri Apr 11 18:31:59 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Fri, 11 Apr 2003 11:31:59 -0500
Subject: [R] Do you know how to plot a PDF function?
Message-ID: <000701c30047$e007a020$8bd75ba5@IE.TAMU.EDU>

Hey, All

There are some 1-Dimensional probability density functions (PDF), e.g.,
f(x), g(x), etc.
And I want to plot them given the range of x.

So which function can I apply to achieve this?

Thanks.

Fred


From rpeng at stat.ucla.edu  Fri Apr 11 18:57:58 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri, 11 Apr 2003 09:57:58 -0700 (PDT)
Subject: [R] Do you know how to plot a PDF function?
In-Reply-To: <000701c30047$e007a020$8bd75ba5@IE.TAMU.EDU>
Message-ID: <Pine.GSO.4.10.10304110957560.19978-100000@quetelet.stat.ucla.edu>

?curve

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Fri, 11 Apr 2003, Feng Zhang wrote:

> Hey, All
> 
> There are some 1-Dimensional probability density functions (PDF), e.g.,
> f(x), g(x), etc.
> And I want to plot them given the range of x.
> 
> So which function can I apply to achieve this?
> 
> Thanks.
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From f0z6305 at labs.tamu.edu  Fri Apr 11 19:04:48 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Fri, 11 Apr 2003 12:04:48 -0500
Subject: [R] Do you know how to plot a PDF function?
References: <Pine.GSO.4.10.10304110957560.19978-100000@quetelet.stat.ucla.edu>
Message-ID: <001301c3004c$75a3a800$8bd75ba5@IE.TAMU.EDU>

One stupid question again.
How to plot the Normal density function?

----- Original Message ----- 
From: "Roger Peng" <rpeng at stat.ucla.edu>
To: "Feng Zhang" <f0z6305 at labs.tamu.edu>
Cc: "R-Help" <r-help at stat.math.ethz.ch>
Sent: Friday, April 11, 2003 11:57 AM
Subject: Re: [R] Do you know how to plot a PDF function?


> ?curve
> 
> -roger
> _______________________________
> UCLA Department of Statistics
> http://www.stat.ucla.edu/~rpeng
> 
> On Fri, 11 Apr 2003, Feng Zhang wrote:
> 
> > Hey, All
> > 
> > There are some 1-Dimensional probability density functions (PDF), e.g.,
> > f(x), g(x), etc.
> > And I want to plot them given the range of x.
> > 
> > So which function can I apply to achieve this?
> > 
> > Thanks.
> > 
> > Fred
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
>


From ramarcos at worldonline.es  Fri Apr 11 19:07:21 2003
From: ramarcos at worldonline.es (=?iso-8859-1?Q?Ramon_Mart=EDnez_Coscoll=E0?=)
Date: Fri, 11 Apr 2003 19:07:21 +0200
Subject: [R] Bayesian package
Message-ID: <002601c3004c$d3774770$8126ca51@statw1c2z9batg>

We are trying to obtain a predictive distribution in a Poisson model using a
non-informative prior distribution. We have found a gamma poisson as a
result of our analysis and we want to evaluate it in R. Is there any package
where this distribution and anothers are defined?

In any case, we have tried to programm the gammapoisson probability function
but we have found another problem: we must evaluate a gamma function with a
quite high value (gamma(284)). How can it be done?

Thank you very much!


From jerome at hivnet.ubc.ca  Fri Apr 11 19:17:42 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Fri, 11 Apr 2003 10:17:42 -0700
Subject: [R] Do you know how to plot a PDF function?
In-Reply-To: <001301c3004c$75a3a800$8bd75ba5@IE.TAMU.EDU>
References: <Pine.GSO.4.10.10304110957560.19978-100000@quetelet.stat.ucla.edu>
	<001301c3004c$75a3a800$8bd75ba5@IE.TAMU.EDU>
Message-ID: <200304111723.KAA14311@hivnet.ubc.ca>


See the thread on "plotting the lognormal density curve" which was posted 
only 2 days ago.

http://maths.newcastle.edu.au/~rking/R/help/03a/3794.html

Jerome

On April 11, 2003 10:04 am, Feng Zhang wrote:
> One stupid question again.
> How to plot the Normal density function?
>
> ----- Original Message -----
> From: "Roger Peng" <rpeng at stat.ucla.edu>
> To: "Feng Zhang" <f0z6305 at labs.tamu.edu>
> Cc: "R-Help" <r-help at stat.math.ethz.ch>
> Sent: Friday, April 11, 2003 11:57 AM
> Subject: Re: [R] Do you know how to plot a PDF function?
>
> > ?curve
> >
> > -roger
> > _______________________________
> > UCLA Department of Statistics
> > http://www.stat.ucla.edu/~rpeng
> >
> > On Fri, 11 Apr 2003, Feng Zhang wrote:
> > > Hey, All
> > >
> > > There are some 1-Dimensional probability density functions (PDF),
> > > e.g., f(x), g(x), etc.
> > > And I want to plot them given the range of x.
> > >
> > > So which function can I apply to achieve this?
> > >
> > > Thanks.
> > >
> > > Fred
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Fri Apr 11 19:20:27 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 11 Apr 2003 18:20:27 +0100 (BST)
Subject: [R] Do you know how to plot a PDF function?
In-Reply-To: <001301c3004c$75a3a800$8bd75ba5@IE.TAMU.EDU>
Message-ID: <Pine.LNX.4.44.0304111817330.25359-100000@gannet.stats>

On Fri, 11 Apr 2003, Feng Zhang wrote:

> One stupid question again.
> How to plot the Normal density function?

plot(dnorm, -4, 4)

using plot.function, or use curve directly.

BTW, `PDF function' is tautology.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From fharrell at virginia.edu  Fri Apr 11 20:00:10 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 11 Apr 2003 14:00:10 -0400
Subject: [R] summary.formula: method reverse does not use fun argument
Message-ID: <20030411140010.6860130a.fharrell@virginia.edu>


Thanks also to Thomas Lumley for his reply concerning summary.formula in the Hmisc package.  See below for some more notes.  -FH

On Fri, 11 Apr 2003 10:25:41 +0200
Thomas Gerds <gerds at fdm.uni-freiburg.de> wrote:

> hi,
> 
> recently i discovered the functionability summary.formula, awesome!
> from the help page i understand that method=reverse allows to
> summarize all variables on the right hand side of formula 
> (the help page on line 229 wrongly refers to the left? hand side variables)
> in categories which are determined by a single left hand side
> variable.

Sorry about the typo.  You are correct, that should have been "right hand side variables".

> 
> my problem is that the argument fun seems not to be compatible with
> method=reverse!? every continuous variable is summarized in three
> quantiles.

As stated in the documentation, fun applies only to method='response' and method='cross'.

> 
> here is an example:
> 
> hist is a factor, PET and CT are "numeric" 
> 
> summary(PET~hist,data=her,fun=sum)
> PET    N=47
> 
> +-------+------------------+--+---+
> |       |                  |N |PET|
> +-------+------------------+--+---+
> |hist   |Morbus Hodgkin    |18| 81|
> |       |Niedrigmaligne NHL|11| 39|
> |       |Hochmaligne NHL   |18| 49|
> +-------+------------------+--+---+
> |Overall|                  |47|169|
> +-------+------------------+--+---+
> 
> > summary(CT~hist,data=her,fun=sum)
> CT    N=47
> 
> +-------+------------------+--+---+
> |       |                  |N |CT |
> +-------+------------------+--+---+
> |hist   |Morbus Hodgkin    |18| 70|
> |       |Niedrigmaligne NHL|11| 16|
> |       |Hochmaligne NHL   |18| 32|
> +-------+------------------+--+---+
> |Overall|                  |47|118|
> +-------+------------------+--+---+
> 
> it would be desirable to combine both tables such that there is one
> column for PET and one for CT ... is this possible?

Yes, see the documentation.  Create a bivariate response variable with cbind and use a bivariate summarization function as 'fun'.  And note that using 'stratify(someothervariable)' you can create multiple groups across columns as with method='reverse'; you just can't get statistical tests for them with method='response'.

Frank Harrell

> 
> trying method=reverse gives:
> 
> summary(hist~PET+CT,data=her,fun=sum,method="reverse") 
> 
> Descriptive Statistics by hist
> 
> +------+---------------+-------------------+----------------+
> |      |Morbus Hodgkin |Niedrigmaligne NHL |Hochmaligne NHL |
> |      |(N=18)         |(N=11)             |(N=18)          |
> +------+---------------+-------------------+----------------+
> |PET   |3.00/3.50/6.75 |1.50/3.00/6.00     |1.00/2.00/3.75  |
> +------+---------------+-------------------+----------------+
> |CT : 0|     0% (0)    |    36% (4)        |    28% (5)     |
> +------+---------------+-------------------+----------------+
> |    1 |    11% (2)    |     9% (1)        |    28% (5)     |
> +------+---------------+-------------------+----------------+
> |    2 |    28% (5)    |    36% (4)        |    11% (2)     |
> +------+---------------+-------------------+----------------+
> |    3 |    17% (3)    |     9% (1)        |    11% (2)     |
> +------+---------------+-------------------+----------------+
> |    4 |    11% (2)    |     9% (1)        |    17% (3)     |
> +------+---------------+-------------------+----------------+
> |    5 |     6% (1)    |     0% (0)        |     6% (1)     |
> +------+---------------+-------------------+----------------+
> |    6 |     6% (1)    |     0% (0)        |     0% (0)     |
> +------+---------------+-------------------+----------------+
> |    7 |    11% (2)    |     0% (0)        |     0% (0)     |
> +------+---------------+-------------------+----------------+
> |    8 |    11% (2)    |     0% (0)        |     0% (0)     |
> +------+---------------+-------------------+----------------+
> 
> thanks a lot in advance,
> tomy
---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From sheth at economics.rutgers.edu  Fri Apr 11 21:46:35 2003
From: sheth at economics.rutgers.edu (Arnav Sheth)
Date: Fri, 11 Apr 2003 15:46:35 -0400
Subject: [R] Tcl/Tk Help
Message-ID: <1050090395.3e971b9baca85@webmail.econ.rutgers.edu>


Hi Everyone,

I am trying to load the Tcl/Tk package in order to use the AnalyzeFMRI GUI, but 
I keep getting the following error when I load the Tcl/Tk package:

Error in firstlib(which.lib.loc, package) : 
        TCL_LIBRARY is not set
Error in library(pkg, character.only = TRUE) : 
        .First.lib failed

I am using Windows and I altered the autoexec.bat file, I tried to set the tcl 
library in R and none of these seemed to work.

Can anyone help me?


Thanks,
Arnav.


From kwan022 at stat.auckland.ac.nz  Fri Apr 11 23:23:12 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Sat, 12 Apr 2003 09:23:12 +1200 (NZST)
Subject: [R] Can I improve the efficiency of my scan() command?
Message-ID: <Pine.LNX.4.33.0304120920550.12635-100000@stat56.stat.auckland.ac.nz>

Hi,

Suppose I use the following codes to read in a data set.

###############################################
> rating <- scan("../Data/Rating.csv",
+                what = list(
+                  usage = "",
+                  mileage = 0,
+                  sex = "",
+                  excess = "",
+                  ncd = "",
+                  primage = "",
+                  minage = "",
+                  drivers = "",
+                  district = "",
+                  cargroup = "",
+                  car.age = 0,
+                  wsclms = "",
+                  adclms = "",
+                  ftclms = "",
+                  pdclms = "",
+                  piclms = "",
+                  adincur = 0,
+                  pdincur = 0,
+                  wsincur = 0,
+                  ftincur = 0,
+                  piincur = 0,
+                  record = 0,
+                  days = 0,
+                  minagen = 0,
+                  primagen = 0),
+                sep=",", quiet = TRUE, skip = 1)
> rating.df <- as.data.frame(rating)
> rating.df <- rating.df[, c(-6, -7, -22)]
> attach(rating.df)
> summary(rating.df)
 usage          mileage      sex        excess       ncd        drivers   
 S :125788   Min.   :  288   F: 82208   0  :  4744   0:   880   1:100791  
 SB: 12581   1st Qu.: 5000   M:217792   100:161311   1:  2819   2:175100  
 SC:161524   Median : 8000              75 :133945   2:  5245   3: 19146  
 ST:   107   Mean   : 7640                           3:  5230   4:  4156  
             3rd Qu.:10000                           4:285826   5:   515  
             Max.   :40000                                      6:    69  
                                                                7:   223  
    district        cargroup        car.age       wsclms     adclms    
 6      :59053   8      :44524   Min.   :-1.000   0:294521   0:292852  
 5      :57113   6      :39171   1st Qu.: 4.000   1:  5267   1:  6720  
 7      :51166   9      :38965   Median : 7.000   2:   201   2:   405  
 4      :50643   7      :35139   Mean   : 7.234   3:    11   3:    23  
 3      :33041   10     :31091   3rd Qu.:10.000                        
 8      :16437   5      :27456   Max.   :30.000                        
 (Other):32547   (Other):83654                                         
 ftclms     pdclms     piclms        adincur            pdincur        
 0:298661    :281056    :281056   Min.   :    0.00   Min.   : -4985.2  
 1:  1316   0: 15277   0: 18131   1st Qu.:    0.00   1st Qu.:     0.0  
 2:    22   1:  3587   1:   809   Median :    0.00   Median :     0.0  
 3:     1   2:    79   2:     4   Mean   :   21.25   Mean   :   225.4  
            3:     1              3rd Qu.:    0.00   3rd Qu.:     0.0  
                                  Max.   :13779.55   Max.   : 25050.0  
                                                     NA's   :281056.0  
    wsincur           ftincur             piincur              days      
 Min.   :   0.00   Min.   :    0.000   Min.   :     0.0   Min.   :  0.0  
 1st Qu.:   0.00   1st Qu.:    0.000   1st Qu.:     0.0   1st Qu.:123.0  
 Median :   0.00   Median :    0.000   Median :     0.0   Median :340.0  
 Mean   :   2.07   Mean   :    5.183   Mean   :   345.8   Mean   :248.7  
 3rd Qu.:   0.00   3rd Qu.:    0.000   3rd Qu.:     0.0   3rd Qu.:364.0  
 Max.   :2004.64   Max.   :25082.910   Max.   :484550.1   Max.   :365.0  
                                       NA's   :281056.0                  
    minagen         primagen    
 Min.   :17.00   Min.   :17.00  
 1st Qu.:41.00   1st Qu.:43.00  
 Median :56.00   Median :53.00  
 Mean   :63.81   Mean   :53.25  
 3rd Qu.:99.00   3rd Qu.:64.00  
 Max.   :99.00   Max.   :93.00  
                             
#########################################################################

It worked all right, but I'm just wondering if there is a more efficient 
way (it takes about 10 minutes to run the above scripts, for my 300,000 x 
25 CSV file)?

For example, the CSV file has 25 columns but I don't need 3 of them (6, 7, 
and 22).  What I have done is to scan them in anyway, convert the list 
into a data frame then remove the 3 columns.  Just wonder if it is 
possible to simply ignore them in scan() to make the process faster?

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From tlumley at u.washington.edu  Fri Apr 11 23:14:20 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 11 Apr 2003 14:14:20 -0700 (PDT)
Subject: [R] Can I improve the efficiency of my scan() command?
In-Reply-To: <Pine.LNX.4.33.0304120920550.12635-100000@stat56.stat.auckland.ac.nz>
Message-ID: <Pine.A41.4.44.0304111412580.86846-100000@homer36.u.washington.edu>

On Sat, 12 Apr 2003, Ko-Kang Kevin Wang wrote:

> Hi,
>
> Suppose I use the following codes to read in a data set.
>
> ###############################################
> > rating <- scan("../Data/Rating.csv",
> +                what = list(
> +                  usage = "",
> +                  mileage = 0,
> +                  sex = "",
> +                  excess = "",
> +                  ncd = "",
> +                  primage = "",
> +                  minage = "",
> +                  drivers = "",
> +                  district = "",
> +                  cargroup = "",
> +                  car.age = 0,
> +                  wsclms = "",
> +                  adclms = "",
> +                  ftclms = "",
> +                  pdclms = "",
> +                  piclms = "",
> +                  adincur = 0,
> +                  pdincur = 0,
> +                  wsincur = 0,
> +                  ftincur = 0,
> +                  piincur = 0,
> +                  record = 0,
> +                  days = 0,
> +                  minagen = 0,
> +                  primagen = 0),
> +                sep=",", quiet = TRUE, skip = 1)
> > rating.df <- as.data.frame(rating)
> > rating.df <- rating.df[, c(-6, -7, -22)]
> > attach(rating.df)
> > summary(rating.df)
<snip>
> #########################################################################
>
> It worked all right, but I'm just wondering if there is a more efficient
> way (it takes about 10 minutes to run the above scripts, for my 300,000 x
> 25 CSV file)?
>

It should be quicker not to convert to a data frame.  You can just keep
the data as a list of vectors and lapply() the summary() function.

	-thomas


From pkleiber at honlab.nmfs.hawaii.edu  Sat Apr 12 00:07:49 2003
From: pkleiber at honlab.nmfs.hawaii.edu (Pierre Kleiber)
Date: Fri, 11 Apr 2003 12:07:49 -1000
Subject: [R] Can I improve the efficiency of my scan() command?
References: <Pine.LNX.4.33.0304120920550.12635-100000@stat56.stat.auckland.ac.nz>
Message-ID: <3E973CB5.3070304@honlab.nmfs.hawaii.edu>

Ko-Kang Kevin Wang wrote:
> Hi,
> 
> Suppose I use the following codes to read in a data set.
> 
> ###############################################
> 
>>rating <- scan("../Data/Rating.csv",
> 
> +                what = list(
 > +                  usage = "",
 > +                  mileage = 0,
 > +                  sex = "",
 > +                  excess = "",
 > +                  ncd = "",
 > +                  primage = "",
 > +                  minage = "",
 > +                  drivers = "",
 > +                  district = "",
 > +                  cargroup = "",
 > +                  car.age = 0,
 > +                  wsclms = "",

[...]
>                              
> #########################################################################
> 
> It worked all right, but I'm just wondering if there is a more efficient 
> way (it takes about 10 minutes to run the above scripts, for my 300,000 x 
> 25 CSV file)?
> 
> For example, the CSV file has 25 columns but I don't need 3 of them (6, 7, 
> and 22).  What I have done is to scan them in anyway, convert the list 
> into a data frame then remove the 3 columns.  Just wonder if it is 
> possible to simply ignore them in scan() to make the process faster?
> 


It might not make a lot of difference in your case where you are
reading many fields and want to ignore a few, but if you want to read
a few out of many, it would help to preprocess the input file using,
for example, awk as in the following, which would pick up fields 1, 2,
and 4:

 > con <- pipe("awk -F , '{print $1,$3 $4}' ../Data/Rating.csv")
 > rating <- scan(con, what = list(
+                  usage = "",
+                  mileage = 0,
+                  excess = "")
+            , quiet = TRUE, skip = 1)
 > close(con)

I do this sort of thing a lot using various utilities; so I've defined
the following function to take care of opening and closing the
connection:

scanpipe <- function(x,...) {
   con <- pipe(x)
   out <- scan(con,...)
   close(con)
   out
}


-- 
-----------------------------------------------------------------
Pierre Kleiber             Email: pkleiber at honlab.nmfs.hawaii.edu
Fishery Biologist                     Tel: 808 983-5399/737-7544
NOAA FISHERIES - Honolulu Laboratory         Fax: 808 983-2902
2570 Dole St., Honolulu, HI 96822-2396
-----------------------------------------------------------------


From andy_liaw at merck.com  Sat Apr 12 00:28:22 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 11 Apr 2003 18:28:22 -0400
Subject: [R] Can I improve the efficiency of my scan() command?
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F99B@usrymx25.merck.com>

> From: Pierre Kleiber [mailto:pkleiber at honlab.nmfs.hawaii.edu]
> 
> Ko-Kang Kevin Wang wrote:
[snipped]
> > 
> > It worked all right, but I'm just wondering if there is a 
> more efficient 
> > way (it takes about 10 minutes to run the above scripts, 
> for my 300,000 x 
> > 25 CSV file)?
> > 
> > For example, the CSV file has 25 columns but I don't need 3 
> of them (6, 7, 
> > and 22).  What I have done is to scan them in anyway, 
> convert the list 
> > into a data frame then remove the 3 columns.  Just wonder if it is 
> > possible to simply ignore them in scan() to make the process faster?
> > 
> 
> 
> It might not make a lot of difference in your case where you are
> reading many fields and want to ignore a few, but if you want to read
> a few out of many, it would help to preprocess the input file using,
> for example, awk as in the following, which would pick up fields 1, 2,
> and 4:
> 
>  > con <- pipe("awk -F , '{print $1,$3 $4}' ../Data/Rating.csv")
>  > rating <- scan(con, what = list(
> +                  usage = "",
> +                  mileage = 0,
> +                  excess = "")
> +            , quiet = TRUE, skip = 1)
>  > close(con)

Or even pipe("cut -d, -f1,3-4 ...")

Andy

> 
> I do this sort of thing a lot using various utilities; so I've defined
> the following function to take care of opening and closing the
> connection:
> 
> scanpipe <- function(x,...) {
>    con <- pipe(x)
>    out <- scan(con,...)
>    close(con)
>    out
> }
> 
> 
> -- 
> -----------------------------------------------------------------
> Pierre Kleiber             Email: pkleiber at honlab.nmfs.hawaii.edu
> Fishery Biologist                     Tel: 808 983-5399/737-7544
> NOAA FISHERIES - Honolulu Laboratory         Fax: 808 983-2902
> 2570 Dole St., Honolulu, HI 96822-2396
> -----------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------


From jmagalhaes at oninetspeed.pt  Sat Apr 12 01:19:52 2003
From: jmagalhaes at oninetspeed.pt (Jorge =?iso-8859-15?q?Magalh=E3es?=)
Date: Sat, 12 Apr 2003 00:19:52 +0100
Subject: [R] Pearson's Chi-squared Test
Message-ID: <200304120019.52864.jmagalhaes@oninetspeed.pt>

How i can perform a Pearson's Chi-squared Test  in this data set:

                                  |          Outcome
   -----------------+-----------+----------------------------------+
   Treatment   |  Sex     | None |Some | Marked  |  Total
   -----------------+------------+--------+--------+-------------+
   Active        |  Female |      6 |      5 |     16      |     27
                    |  Male     |      7 |      2 |      5       |     14
   ----------------+-------------+--------+--------+-------------+
   Placebo     |  Female |     19 |      7 |      6       |     32
                   |  Male     |     10 |      0 |      1       |     11
   ---------------+-------------+---------+--------+-------------+
       Total                       42       14       28              84

if i do:
y<- matrix(c(5,6,16, 19,7,6,7,2,5,10,0,1), nc=3)

and 

chisq.test(y) i found that X-squared=20.3176 but the true value is 15.075 
(http://www.math.yorku.ca/SCS/Courses/grcat/grc2.html#H2_43:Sample) 

Now i tried:

the Cochran-Mantel-Haenszel Chi-Squared Test for Count Data:

x <- array(c(6, 19, 7, 10,
        	5, 7, 2, 0,
		16, 6, 5, 1),
      dim = c(2, 2, 3),
      dimnames = list(
          Active = c("Female", "Male"),
          Placebo = c("Female", "Male"),
          Outcome.Level = c("None", "Some", "Marked")))

mantelhaen.test(x)

and now X-squared=2.0863

What is wrong?

Best regards
Many thanks in advance

Jorge M.


From christianlederer at t-online.de  Sat Apr 12 05:17:51 2003
From: christianlederer at t-online.de (Christian Lederer)
Date: Sat, 12 Apr 2003 05:17:51 +0200
Subject: [R] Autocovariance and acf
Message-ID: <20030412051751.4a1fa8f9.christianlederer@t-online.de>


Hi,

i calculated the autocovariance of a vector x of length n, using

	result <- acf(x, lag, type="covariance")

and expected, that result$acf would contain the values
cov(x,x), cov(x[1:(n-1)], x[2:n]) ... 

However, acf does not calculate this covariances. Instead
of cov(x[1:(n-i)], x[(i+1):n]) i am getting

	( (x[1] - m) * (x[i+1]-m) + ... + (x[n-i]-m) * (x[n]-m) ) / n

where m = mean(x). 

I anderstand, that for efficiency reasons only the mean of the whole 
vector x is substracted instead of the means of the partial vectors.
But why does it divide by n instead of n-i?


Christian


From fisher at plessthan.com  Sat Apr 12 06:24:10 2003
From: fisher at plessthan.com (Dennis Fisher)
Date: Fri, 11 Apr 2003 21:24:10 -0700
Subject: [R] system()
Message-ID: <p05001902babd43d20b9a@[192.168.123.153]>

I am new to R but have used Splus for many years.  When I create many 
graphics in sequence in Splus/Linux, each time that I complete a 
page, I send a message to my command line interface using the 
following function:

FOOT <- function(PAGENO,TEXT)
         {
         mtext(outer=T, TEXT, side=1)
         unix("cat", c(paste("Finished with page", PAGENO)),FALSE, FALSE)
         }
PAGENO <- PAGENO + 1
FOOT(PAGENO,"Text")

In R, the corresponding function appears to be "system()".  I don't 
see how I can pass the PAGENO argument to "cat" in R.

Any advice?

-- 


Dennis M. Fisher, MD
The "P Less Than" Company
Toll-free phone:	1-866-PLessThan (1-866-753-7784)
Fax:		1-415 564-2220
Email:		fisher at PLessThan.com
Web:		www.PLessThan.com


From ripley at stats.ox.ac.uk  Sat Apr 12 09:09:35 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 12 Apr 2003 08:09:35 +0100 (BST)
Subject: [R] system()
In-Reply-To: <p05001902babd43d20b9a@[192.168.123.153]>
Message-ID: <Pine.LNX.4.44.0304120804010.26726-100000@gannet.stats>

1) You didn't need to use unix() in S-PLUS.  Just

    cat("Finished with page", PAGENO, "\n")

which also works in R.

2) In R you could use

    system(paste("echo", "Finished with page", PAGENO))

this being a more standard way to produce output in Unix that creating a 
file and piping it to cat: but you could do that if you wanted to.
(That's exactly what unix(input="foo") does: list it to see.)

On Fri, 11 Apr 2003, Dennis Fisher wrote:

> I am new to R but have used Splus for many years.  When I create many 
> graphics in sequence in Splus/Linux, each time that I complete a 
> page, I send a message to my command line interface using the 
> following function:
> 
> FOOT <- function(PAGENO,TEXT)
>          {
>          mtext(outer=T, TEXT, side=1)
>          unix("cat", c(paste("Finished with page", PAGENO)),FALSE, FALSE)
>          }
> PAGENO <- PAGENO + 1
> FOOT(PAGENO,"Text")
> 
> In R, the corresponding function appears to be "system()".  I don't 
> see how I can pass the PAGENO argument to "cat" in R.
> 
> Any advice?
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sat Apr 12 09:14:17 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 12 Apr 2003 08:14:17 +0100 (BST)
Subject: [R] Can I improve the efficiency of my scan() command?
In-Reply-To: <Pine.LNX.4.33.0304120920550.12635-100000@stat56.stat.auckland.ac.nz>
Message-ID: <Pine.LNX.4.44.0304120810440.26726-100000@gannet.stats>

On Sat, 12 Apr 2003, Ko-Kang Kevin Wang wrote:

[...]

> For example, the CSV file has 25 columns but I don't need 3 of them (6, 7, 
> and 22).  What I have done is to scan them in anyway, convert the list 
> into a data frame then remove the 3 columns.  Just wonder if it is 
> possible to simply ignore them in scan() to make the process faster?

Yes: see the help page

      If any of the types is `NULL', the corresponding field is skipped
     (but a `NULL' component appears in the result).

If you don't need a data frame, don't do the conversion.  You might
well find read.table setting colClasses is faster than converting by 
as.data.frame.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jmagalhaes at oninetspeed.pt  Sat Apr 12 12:48:04 2003
From: jmagalhaes at oninetspeed.pt (Jorge =?iso-8859-1?q?Magalh=E3es?=)
Date: Sat, 12 Apr 2003 11:48:04 +0100
Subject: [R] Pearson's Chi-squared Test
In-Reply-To: <200304120019.52864.jmagalhaes@oninetspeed.pt>
References: <200304120019.52864.jmagalhaes@oninetspeed.pt>
Message-ID: <200304121148.04484.jmagalhaes@oninetspeed.pt>


 How i can perform a Pearson's Chi-squared Test  in this data set:
                                   |          Outcome

    -----------------+-----------+----------------------------------+
    Treatment   |  Sex     | None |Some | Marked  |  Total
    -----------------+------------+--------+--------+-------------+
    Active        |  Female |      6 |      5 |     16      |     27

                     |  Male     |      7 |      2 |      5       |     14

    ----------------+-------------+--------+--------+-------------+
    Placebo     |  Female |     19 |      7 |      6       |     32

                    |  Male     |     10 |      0 |      1       |     11

    ---------------+-------------+---------+--------+-------------+
        Total                       42       14       28              84

 if i do:
 y<- matrix(c(5,6,16, 19,7,6,7,2,5,10,0,1), nc=3)

 and

 chisq.test(y) i found that X-squared=20.3176 but the true value is 15.075
 (http://www.math.yorku.ca/SCS/Courses/grcat/grc2.html#H2_43:Sample)

 Now i tried:

 the Cochran-Mantel-Haenszel Chi-Squared Test for Count Data:

 x <- array(c(6, 19, 7, 10,
         	5, 7, 2, 0,
 		16, 6, 5, 1),
       dim = c(2, 2, 3),
       dimnames = list(
           Active = c("Female", "Male"),
           Placebo = c("Female", "Male"),
           Outcome.Level = c("None", "Some", "Marked")))

 mantelhaen.test(x)

 and now X-squared=2.0863

 What is wrong?

 Best regards
 Many thanks in advance

 Jorge M.


From nirv402 at yahoo.com  Sat Apr 12 16:16:30 2003
From: nirv402 at yahoo.com (Nirvan Sunderam)
Date: Sat, 12 Apr 2003 07:16:30 -0700 (PDT)
Subject: [R] SARIMA
Message-ID: <20030412141630.5483.qmail@web14005.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030412/d97c1255/attachment.pl

From p.dalgaard at biostat.ku.dk  Sat Apr 12 16:38:09 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 12 Apr 2003 16:38:09 +0200
Subject: [R] Pearson's Chi-squared Test
In-Reply-To: <200304121148.04484.jmagalhaes@oninetspeed.pt>
References: <200304120019.52864.jmagalhaes@oninetspeed.pt>
	<200304121148.04484.jmagalhaes@oninetspeed.pt>
Message-ID: <x21y076asu.fsf@biostat.ku.dk>

Jorge Magalh?es <jmagalhaes at oninetspeed.pt> writes:

>  How i can perform a Pearson's Chi-squared Test  in this data set:

[that was garbled. Here's the original]

                      |         Outcome
   ---------+---------+--------------------------+
   Treatment|  Sex    |None    |Some    |Marked  |  Total
   ---------+---------+--------+--------+--------+
   Active   |  Female |      6 |      5 |     16 |     27
            |  Male   |      7 |      2 |      5 |     14
   ---------+---------+--------+--------+--------+
   Placebo  |  Female |     19 |      7 |      6 |     32
            |  Male   |     10 |      0 |      1 |     11
   ---------+---------+--------+--------+--------+
   Total                    42       14       28       84

> 
>  if i do:
>  y<- matrix(c(5,6,16, 19,7,6,7,2,5,10,0,1), nc=3)
> 
>  and
> 
>  chisq.test(y) i found that X-squared=20.3176 but the true value is 15.075
>  (http://www.math.yorku.ca/SCS/Courses/grcat/grc2.html#H2_43:Sample)

No you don't, and I don't see the value 15.075 anywhere on that page.

Please check your input, rather than relying on r-helpers to do so:
y<- matrix(c(6,5,16, 19,7,6,7,2,5,10,0,1), nc=3,byrow=T)
             !!!                                !!!!!!!

will give you the 20.3176, but that test (for independence in the 4x3
table) isn't on the page you cite.
 
With correct entry of your "x" table (see below) you might have
calculated the 2x3 marginal over sex and gotten

> chisq.test(margin.table(x,c(1,3)))

        Pearson's Chi-squared test

data:  margin.table(x, c(1, 3))
X-squared = 13.055, df = 2, p-value = 0.001463

which is indeed in the SAS output.

>  Now i tried:
> 
>  the Cochran-Mantel-Haenszel Chi-Squared Test for Count Data:
> 
>  x <- array(c(6, 19, 7, 10,
>          	5, 7, 2, 0,
>  		16, 6, 5, 1),
>        dim = c(2, 2, 3),
>        dimnames = list(
>            Active = c("Female", "Male"),
>            Placebo = c("Female", "Male"),
>            Outcome.Level = c("None", "Some", "Marked")))
> 
>  mantelhaen.test(x)
> 
>  and now X-squared=2.0863
> 
>  What is wrong?

Printing that table ought to have given you a clue. Here's the right
way:

 x <- array(c(6, 19, 7, 10,
              5,  7, 2, 0,
             16,  6, 5, 1),
        dim = c(2, 2, 3),
        dimnames = list(
           treat=c("Active","Placebo"),
           sex=c("Female", "Male"),
           Outcome.Level = c("None", "Some", "Marked")))

However, for the Mantel-Haenszel test you'd want to stratify by sex,
not outcome, as happens when that is the last dimension of the table,
so use aperm to sort the indices differently:

mantelhaen.test(aperm(x,c(3,1,2))

gives 14.6323, as in SAS.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From pospiech at de.ibm.com  Sat Apr 12 18:55:01 2003
From: pospiech at de.ibm.com (Dr. Christoph Pospiech)
Date: Sat, 12 Apr 2003 18:55:01 +0200
Subject: [R] Compiling R in 64-bit mode under AIX
Message-ID: <200304121855.01424.pospiech@de.ibm.com>

Hi all,

I am trying to compile R in 64-bit addressing mode under AIX 5.1. Currently, I 
am using the following.

./configure -without-x  CC='xlC_r' F77='xlf_r' CXX='xlC_r' CFLAGS='-q64 -g 
-qfullpath' FFLAGS='-q64 -g -qfullpath' CXXFLAGS='-q64 -g -qfullpath' 
MAIN_LDFLAGS='-q64 -g -qfullpath' LDFLAGS='-q64' SHLIB_CXXLDFLAGS='-q64' 
SHLIB_LDFLAGS='-q64' AR='ar -X32_64' MAKE='gmake' && gmake

I am getting stuck at the following part of the make process.
xlC_r -q64 -G -q64 -o methods.so do_substitute_direct.o 
methods_list_dispatch.o method_meta_data.o slot.o class_support.o tests.o   
-lm
gmake[5]: Leaving directory `/xhome/cp/bench/DKFZ/R/src/library/methods/src'
gmake[4]: Leaving directory `/xhome/cp/bench/DKFZ/R/src/library/methods/src'
gmake[4]: Entering directory `/xhome/cp/bench/DKFZ/R/src/library/methods'
dumping R code in package 'methods'
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library 
"/home/cp/bench/DKFZ/R/library/ctest/libs/ctest.so":
  No such file or directory
^C
Execution halted
^C
[cp at polar R]$

I know that the R help page states the following for AIX.
"Also, the R main program is unable to dynamically load modules (such as X11) 
with the dlopen call."

But how do you get across the above part of the make process ? It gets stuck 
at using dlopen to link /home/cp/bench/DKFZ/R/library/ctest/libs/ctest.so. 
Inspecting with dbx, I found that dlopen returns the NULL pointer.

Any hints ?
-- 

Mit freundlichen Gruessen/Best Regards

Dr. Christoph Pospiech
High Performance & Parallel Computing
Advanced Computing Technology Center
Phone +49-621-469450, Fax: ...-469200, eMail: pospiech at de.ibm.com
Mobile +49-171 765 5871
---- Please Note new Tel+FAX Number ----


From pospiech at de.ibm.com  Sat Apr 12 18:58:54 2003
From: pospiech at de.ibm.com (Dr. Christoph Pospiech)
Date: Sat, 12 Apr 2003 18:58:54 +0200
Subject: [R] compiling R in 64-bit mode on Linux on Power4
Message-ID: <200304121858.54624.pospiech@de.ibm.com>

Hi all,

today I tried to compile R in 64-bit mode on Linux on Power4. I used the 
following parameter with configure.

./configure -without-x  CC='xlC' F77='xlf' CXX='xlC' CFLAGS='-q64 -g 
-qfullpath' FFLAGS='-q64 -g -qfullpath' CXXFLAGS='-q64 -g -qfullpath' 
MAIN_LDFLAGS='-q64 -g -qfullpath' LDFLAGS='-q64' SHLIB_CXXLDFLAGS='-q64 -G' 
SHLIB_LDFLAGS='-q64 -G' CPICFLAGS='-G' FPICFLAGS='-G' CXXPICFLAGS='-G' && 
gmake

The error message was as follows.
xlC -q64 -G  -q64 -o internet.so  Rsock.lo internet.lo nanoftp.lo nanohttp.lo 
sock.lo sockconn.lo
xlC: 1501-218 file Rsock.lo contains an incorrect file suffix
xlC: 1501-218 file internet.lo contains an incorrect file suffix
xlC: 1501-218 file nanoftp.lo contains an incorrect file suffix
xlC: 1501-218 file nanohttp.lo contains an incorrect file suffix
xlC: 1501-218 file sock.lo contains an incorrect file suffix
xlC: 1501-218 file sockconn.lo contains an incorrect file suffix
/opt/cross/bin/powerpc64-linux-ld: 
/opt/ibmcmp/vacpp/6.0/lib64/libxl.a(atoff.o)(.eh_frame+0x320): unresolvable 
relocation against symbol `.atoi@@GLIBC_2.2.5'
gmake[4]: *** [internet.so] Error 1
gmake[4]: Leaving directory 
`/works/work5/cp/bench/DKFZ/R/src/modules/internet'
gmake[3]: *** [R] Error 2
gmake[3]: Leaving directory 
`/works/work5/cp/bench/DKFZ/R/src/modules/internet'
gmake[2]: *** [R] Error 1
gmake[2]: Leaving directory `/works/work5/cp/bench/DKFZ/R/src/modules'
gmake[1]: *** [R] Error 1
gmake[1]: Leaving directory `/works/work5/cp/bench/DKFZ/R/src'
gmake: *** [R] Error 1

Anyone seen a similar thing before ?
-- 

Mit freundlichen Gruessen/Best Regards

Dr. Christoph Pospiech
High Performance & Parallel Computing
Advanced Computing Technology Center
Phone +49-621-469450, Fax: ...-469200, eMail: pospiech at de.ibm.com
Mobile +49-171 765 5871
---- Please Note new Tel+FAX Number ----


From chumpmonkey at hushmail.com  Sat Apr 12 23:41:00 2003
From: chumpmonkey at hushmail.com (chumpmonkey@hushmail.com)
Date: Sat, 12 Apr 2003 14:41:00 -0700
Subject: [R] rpart vs. randomForest
Message-ID: <200304122141.h3CLf0fB025857@mailserver2.hushmail.com>


Greetings. I'm trying to determine whether to use rpart or randomForest
for a classification tree. Has anybody tested efficacy formally? I've
run both and the confusion matrix for rf beats rpart. I've looking at
the rf help page and am unable to figure out how to extract the tree.
But more than that I'm looking for a more comprehensive user's guide
for randomForest including the benefits on using it with MDS. Can anybody
suggest a general guide? I've been finding a lot of broken links and
cs-type of web pages rather than an end-user's guide. Also people's experience
on adjusting the mtry param would be useful. Breiman says that it isn't
too sensitive but I'm curious if anybody has had a different experience
with it. Thanks in advance and apologies if this is too general.



Concerned about your privacy? Follow this link to get
FREE encrypted email: https://www.hushmail.com/?l=2 

Big $$$ to be made with the HushMail Affiliate Program: 
https://www.hushmail.com/about.php?subloc=affiliate&l=427


From zynnel at yahoo.com  Sun Apr 13 00:17:50 2003
From: zynnel at yahoo.com (Elena Zheleva)
Date: Sat, 12 Apr 2003 15:17:50 -0700 (PDT)
Subject: [R] embedding R: plot freezing
In-Reply-To: <3E61514A.70109@joeconway.com>
Message-ID: <20030412221750.37526.qmail@web11801.mail.yahoo.com>

i have a problem with plotting dataframes from an R
interpreter set up in another application (using C and
GTK).

i have the following two functions in two separate
files:

loadDataFrame <- function(filename, analysisDF){
	tempfile <- "bla"
	d <- read.table(tempfile, header=TRUE)  
	d <<- d
}

finalDC <- function(){ 
	print(d)

	##create an empty plot 
	xlim <- range(d[,1], na.rm=TRUE)
	ylim <- range(d[,-1], na.rm=TRUE)

	plot(NA, xlim=xlim, ylim=ylim, xlab="x", ylab="y")
	title("DC Analysis", "All nodes")
	##plot the data
	for (k in 2:ncol(d))
		lines(d[,1], d[,k], col=k-1)
}

if i invoke these directly from R, they work just
fine. when i invoke them from the R interpreter set up
in my application, the dataframe prints out and then
one of two things happens. i either get a segmentation
fault, or the plot displays and freezes, so i cannot
close it. 

currently, i have R initialized with the following
args:
char *argv[] = {"simulus", "--no-save", "--silent"};

does anyone have any idea why? thank you very much in
advance.

elena zheleva


From mitsu5 at ruby.famille.ne.jp  Sun Apr 13 05:23:53 2003
From: mitsu5 at ruby.famille.ne.jp (Mitsuo Igarashi)
Date: Sun, 13 Apr 2003 12:23:53 +0900
Subject: [R] Pearson's Chi-squared Test
In-Reply-To: <200304121148.04484.jmagalhaes@oninetspeed.pt>
References: <200304121148.04484.jmagalhaes@oninetspeed.pt>
Message-ID: <200304130324.h3D3O4Mv027475@mp2.vectant.ne.jp>

HI Jorge.

Jorge Magalh??s <jmagalhaes at oninetspeed.pt> wrote:

> 
>  How i can perform a Pearson's Chi-squared Test  in this data set:
>                                    |          Outcome
> 
>     -----------------+-----------+----------------------------------+
>     Treatment   |  Sex     | None |Some | Marked  |  Total
>     -----------------+------------+--------+--------+-------------+
>     Active        |  Female |      6 |      5 |     16      |     27
> 
>                      |  Male     |      7 |      2 |      5       |     14
> 
>     ----------------+-------------+--------+--------+-------------+
>     Placebo     |  Female |     19 |      7 |      6       |     32
> 
>                     |  Male     |     10 |      0 |      1       |     11
> 
>     ---------------+-------------+---------+--------+-------------+
>         Total                       42       14       28              84
> 
>  if i do:
>  y<- matrix(c(5,6,16, 19,7,6,7,2,5,10,0,1), nc=3)
> 
>  and
> 
>  chisq.test(y) i found that X-squared=20.3176 but the true value is 15.075
>  (http://www.math.yorku.ca/SCS/Courses/grcat/grc2.html#H2_43:Sample)

I have read these sentences of the URL.
If you combine the data you cited of female and male, you get 
the following table.

    Active   |     13 |      7 |     21 |
    Placebo  |     29 |      7 |      7 |
This is expressed as x<-matrix(c(13,7,21,29,7,7),2,3,byrow=TRUE).
> x
     [,1] [,2] [,3]
[1,]   13    7   21
[2,]   29    7    7
> chisq.test(x)  : This runs in R.
        Pearson's Chi-squared test
data:  x 
X-squared = 13.055, df = 2, p-value = 0.001463

You can see the following sentennces in the URL you cited which 
is the same calculation just as I write above.
         STATISTICS FOR TABLE OF TREAT BY IMPROVE               |
|                                                                   |
|     Statistic                     DF     Value        Prob        |
|     ------------------------------------------------------        |
|     Chi-Square                     2    13.055       0.001        |
Chi-squared value is completely same.

I like to add a note that this section you cited is "Tests of 
Association for Two-Way Tables". And  Cochran-Mantel-Haenszel 
Chi-Squared Test is different from chisq.test in R.

You can find a very good basic lectures:"Data Analysis With Epi 
Info" at http://www.sjsu.edu/faculty/gerstman/EpiInfo/ .
 
Good luck!       
-------========--------
mitsu5
mitsu5 at ruby.famille.ne.jp

 
>  Now i tried:
> 
>  the Cochran-Mantel-Haenszel Chi-Squared Test for Count Data:
> 
>  x <- array(c(6, 19, 7, 10,
>          	5, 7, 2, 0,
>  		16, 6, 5, 1),
>        dim = c(2, 2, 3),
>        dimnames = list(
>            Active = c("Female", "Male"),
>            Placebo = c("Female", "Male"),
>            Outcome.Level = c("None", "Some", "Marked")))
> 
>  mantelhaen.test(x)
> 
>  and now X-squared=2.0863
> 
>  What is wrong?
> 
>  Best regards
>  Many thanks in advance
> 
>  Jorge M.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From andrewr at uidaho.edu  Sun Apr 13 23:16:45 2003
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Sun, 13 Apr 2003 14:16:45 -0700 (PDT)
Subject: [R] Peculiarity in non-central qchisq for ncp > 294.92 ...
Message-ID: <Pine.GHP.4.51.0304131405590.2386@raptor.csrv.uidaho.edu>

Hello all,

Here's my query:

Running R 1.6.2 on FreeBSD 5.0, and on WinXP, and I find that the
following hangs the process:

dchisq(alpha=0.01, df=1, ncp=295)

but it does work for ncp < 294.92.

Is this general?

Best wishes to all,

Andrew

Andrew Robinson			     Ph: 208 885 7115
Department of Forest Resources	     Fa: 208 885 6226
University of Idaho		     E : andrewr at uidaho.edu
PO Box 441133			     W : http://www.uidaho.edu/~andrewr
Moscow ID 83843			     Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.


From yanyu at cs.ucla.edu  Mon Apr 14 03:52:10 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Sun, 13 Apr 2003 18:52:10 -0700 (PDT)
Subject: [R] functions in a package 
Message-ID: <Pine.SOL.4.33.0304131848130.20605-100000@panther.cs.ucla.edu>

Hello,
I have a beginner's Q:
   if i want to know all the functions provided by a package,
what is command for that?
in another word,
Is there a command to list all the commands available in a packege?
thanks a lot,
yan


From mschwartz at medanalytics.com  Mon Apr 14 04:17:55 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 13 Apr 2003 21:17:55 -0500
Subject: [R] functions in a package 
In-Reply-To: <Pine.SOL.4.33.0304131848130.20605-100000@panther.cs.ucla.edu>
Message-ID: <008b01c3022c$10650ba0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Yan Yu
>Sent: Sunday, April 13, 2003 8:52 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] functions in a package 
>
>
>Hello,
>I have a beginner's Q:
>   if i want to know all the functions provided by a package, 
>what is command for that? in another word, Is there a command 
>to list all the commands available in a packege? thanks a lot, yan

Look at ?package.contents

For example:

package.contents("ctest")

HTH,

Marc Schwartz


From jerome at hivnet.ubc.ca  Mon Apr 14 04:19:36 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Sun, 13 Apr 2003 19:19:36 -0700
Subject: [R] functions in a package
In-Reply-To: <Pine.SOL.4.33.0304131848130.20605-100000@panther.cs.ucla.edu>
References: <Pine.SOL.4.33.0304131848130.20605-100000@panther.cs.ucla.edu>
Message-ID: <200304140225.TAA07890@hivnet.ubc.ca>


E.g.: for package MASS, use:

library(help="MASS")

Jerome

On April 13, 2003 06:52 pm, Yan Yu wrote:
> Content-Length: 361
> Status: R
> X-Status: N
>
> Hello,
> I have a beginner's Q:
>    if i want to know all the functions provided by a package,
> what is command for that?
> in another word,
> Is there a command to list all the commands available in a packege?
> thanks a lot,
> yan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 

Jerome Asselin (J?r?me), Statistical Analyst
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital, 608 - 1081 Burrard Street
Vancouver, British Columbia, CANADA V6Z 1Y6
Email: jerome at hivnet.ubc.ca
Phone: 604 806-9112   Fax: 604 806-9044


From s195404 at student.uq.edu.au  Mon Apr 14 04:23:04 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Mon, 14 Apr 2003 02:23:04 +0000
Subject: [R] functions in a package
In-Reply-To: <Pine.SOL.4.33.0304131848130.20605-100000@panther.cs.ucla.edu>
References: <Pine.SOL.4.33.0304131848130.20605-100000@panther.cs.ucla.edu>
Message-ID: <1050286984.3e9a1b88744b1@my.uq.edu.au>

Yan, I believe this very question was asked on this list in the past
couple of weeks. One of the solutions was
  > search() # gives a list of loaded packages
  > ls(pos=2) # lists all functions in pos=2 of the search path


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au




 Quoting Yan Yu <yanyu at cs.ucla.edu>:

> Hello,
> I have a beginner's Q:
>    if i want to know all the functions provided by a package,
> what is command for that?
> in another word,
> Is there a command to list all the commands available in a
> packege?
> thanks a lot,
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From faheem at email.unc.edu  Mon Apr 14 05:13:42 2003
From: faheem at email.unc.edu (Faheem Mitha)
Date: Sun, 13 Apr 2003 23:13:42 -0400 (EDT)
Subject: [R] cannot create postscript files with trellis graphics inside a
	function
Message-ID: <Pine.LNX.4.44.0304132303170.1580-100000@Chrestomanci>


Dear People,

If I define

foo <-function()
{
  x <- rnorm(500)
  trellis.device(postscript, file="plot.ps")
  densityplot(~x)
  dev.off()
 }

and call foo() then plot.ps is just a blank plot. However, if I extract
the lines inside foo and run them, ie.

x <- rnorm(500)
trellis.device(postscript, file="plot.ps")
densityplot(~x)
dev.off()

then plot.ps is created without problems. The former method worked with
the regular postscript() device, which I used to use all the time inside
functions.

I've never used lattice/trellis graphics before. Is this a bug or am I
doing something wrong?

                                                  Faheem.


From TyagiAnupam at aol.com  Mon Apr 14 05:39:08 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Sun, 13 Apr 2003 23:39:08 EDT
Subject: [R] functions in a package 
Message-ID: <4c.1b2e3253.2bcb875c@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030413/21e2e67a/attachment.pl

From pingzhao at waffle.cs.dal.ca  Mon Apr 14 05:53:21 2003
From: pingzhao at waffle.cs.dal.ca (pingzhao)
Date: Mon, 14 Apr 2003 00:53:21 -0300
Subject: [R] kmeans clustering
Message-ID: <3EA24FDA@webmail.ucis.dal.ca>

Hi,

I am using kmeans to cluster a dataset.
I test this example:

> data<-matrix(scan("data100.txt"),100,37,byrow=T)
(my dataset is 100 rows and 37 columns--clustering rows)

 > c1<-kmeans(data,3,20)
> c1
$cluster
  [1] 1 1 1 1 1 1 1 3 3 3 1 3 1 3 3 1 1 1 1 3 1 3 3 1 1 1 3 3 1 1 3 1 1 1 1 3 
3
 [38] 3 1 1 1 3 1 1 1 1 3 3 3 1 1 1 1 1 1 3 1 3 1 1 3 1 1 1 1 3 1 1 1 1 1 1 3 
1
 [75] 1 3 1 3 1 1 1 1 3 1 1 1 1 1 3 1 1 3 1 1 3 3 1 2 1 1

$withinss
[1] 1037.5987    0.0000  666.9701

$size
[1] 68  1 31

> c4<-kmeans(data,3,20)
$withinss
[1]   0.0000 865.7628 851.1214

$size
[1]  1 54 45

Does any one tell me why the results are very different with the same 
dataset and parameters when I run some times this command 
'kmeans(data,3,20)'???

Thank you for your help in advance!

ping


From mikael.niva at ebc.uu.se  Mon Apr 14 07:34:22 2003
From: mikael.niva at ebc.uu.se (Mikael Niva)
Date: Mon, 14 Apr 2003 07:34:22 +0200
Subject: [R] Thank you
Message-ID: <000001c30247$821a4880$3d9aee82@uu.se.vaxtbio>

Dear R-listers

Once again several of you have helped me, a BIG LETTER THANK YOU!

Yours sincerely Mikael Niva
********************************************
Mikael Niva
Avd. f?r V?xtekologi, Dept. of Plant Ecology 
EvolutionsBiologiskt Centrum, Uppsala Universitet


From kwan022 at stat.auckland.ac.nz  Mon Apr 14 10:52:46 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Mon, 14 Apr 2003 20:52:46 +1200 (NZST)
Subject: [R] re:  question on R
In-Reply-To: <20030410104736.99030.qmail@web41812.mail.yahoo.com>
Message-ID: <Pine.LNX.4.33.0304142050100.11130-100000@stat56.stat.auckland.ac.nz>

Hi,

It is a mailing list for users to help users on a volutary basis.  There 
are, I think, thousands of people on this list.  The idea is if one has a 
question regarding R, one will post to this list and someone will answer 
it.  Usually the question will be answered by several people using 
different solutions.  The R Core Team members are also on the list and 
most of them constantly reply messages too.

On Thu, 10 Apr 2003, Angie Ng wrote:

> Date: Thu, 10 Apr 2003 11:47:36 +0100 (BST)
> From: Angie Ng <ng_angie_03 at yahoo.co.uk>
> To: r-help at stat.math.ethz.ch
> Subject: [R] re:  question on R
> 
> 
> Hi,
> 
> While I was searching the web to see who I can look for to help me with the R program, I came across your email in one of the reply screen.
> 
> Would appreciate if you could let me know are you the consultant of the R program and in what cases will you help people with the R question?
> 
> Looking forward to your early reply.

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From adrian.trapletti at lmttrading.com  Mon Apr 14 10:22:59 2003
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Mon, 14 Apr 2003 10:22:59 +0200
Subject: [R] Re: R-help Digest, Vol 2, Issue 13
References: <200304121001.h3CA1BAP002344@hypatia.math.ethz.ch>
Message-ID: <3E9A6FE3.487BC7DD@lmttrading.com>

> Subject: [R] Autocovariance and acf
> Date: Sat, 12 Apr 2003 05:17:51 +0200
> From: christianlederer at t-online.de (Christian Lederer)
> Reply-To: lederer at trium.de
> To: R-Help <r-help at stat.math.ethz.ch>
>
> Hi,
>
> i calculated the autocovariance of a vector x of length n, using
>
>         result <- acf(x, lag, type="covariance")
>
> and expected, that result$acf would contain the values
> cov(x,x), cov(x[1:(n-1)], x[2:n]) ...
>
> However, acf does not calculate this covariances. Instead
> of cov(x[1:(n-i)], x[(i+1):n]) i am getting
>
>         ( (x[1] - m) * (x[i+1]-m) + ... + (x[n-i]-m) * (x[n]-m) ) / n
>
> where m = mean(x).

There are many possibilities to estimate the autocovariance function. acf implements the standard estimator. Your suggestion has some disadvantages: See, e.g., in L?tkepohl (1994), Zeitreihenanalyse, 5. Auflage, pp. 236, and in particular p. 243 (I guess you understand German).

> I anderstand, that for efficiency reasons only the mean of the whole
> vector x is substracted instead of the means of the partial vectors.
> But why does it divide by n instead of n-i?
>
> Christian

best
Adrian

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5631
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com


From ripley at stats.ox.ac.uk  Mon Apr 14 10:27:48 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 09:27:48 +0100 (BST)
Subject: [R] princomp with not non-negative definite correlation matrix
In-Reply-To: <1050034155.3e963febd1b0b@webmail.stanford.edu>
Message-ID: <Pine.LNX.4.44.0304140922230.7209-100000@gannet.stats>

On Thu, 10 Apr 2003 tvr at stanford.edu wrote:

> $ R --version
> R 1.6.1 (2002-11-01).
> 
> So I would like to perform principal components analysis on a 16X16
> correlation matrix, [princomp(cov.mat=x) where x is correlation matrix],
> the problem is princomp complains that it is not non-negative definite.
> 
> I called eigen() on the correlation matrix and found that one of the 
> eigenvectors is close to zero & negative (-0.001832311). Is there any
> way to work around this problem. A constraint: I only have the
> correlation matrix, not the data that produced it. 
> 
> I believe I could replicate most of the functionality of princomp
> step-by-step (loadings, scores, etc.) and track the effect of the
> negative eigenvector on the rest of the analysis, but I'd rather not do
> that with every covariance/correlation matrix that might have a few
> eigenvectors that are negative but close to zero.

No correlation/covariance matrix ever has negative eigenvectors, so 
princomp is correctly telling you that you have a problem.

I have no idea what your matrix is, but it is not a correlation matrix.
Possibly it has been written out and rounded?  In that case try
setting the negative eigenvalues to zero.  But I would want to be sure 
that there was not some more serious error in the correlation matrix.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Apr 14 10:32:54 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 09:32:54 +0100 (BST)
Subject: [R] SARIMA
In-Reply-To: <20030412141630.5483.qmail@web14005.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0304140931040.7209-100000@gannet.stats>

On Sat, 12 Apr 2003, Nirvan Sunderam wrote:

> I'm trying to fit a SARIMA(p,d,q)x(P,D,Q) with seasonal period s to some
> data. When dealing with these types of models one often looks at the ACF
> and PACF of the time series at lags that are multiples of s, to identify
> potential values of P, Q. How would I do this in R given the original
> time series? 

?acf

> Secondly given a time series x acf(x) just gives me the
> plot of the acf. How would I actually get the actual numeric values at
> each lag?Thanks in advance.N

?acf: note there is a Value: section and your assertion is incorrect.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Apr 14 10:36:18 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 09:36:18 +0100 (BST)
Subject: [R] Tcl/Tk Help
In-Reply-To: <1050090395.3e971b9baca85@webmail.econ.rutgers.edu>
Message-ID: <Pine.LNX.4.44.0304140933100.7209-100000@gannet.stats>

This is in the rw-FAQ.  Without knowing which version of Windows you used
and what you actually did it is impossible to tell what your mistake is,
but this does work if you follow the instructions exactly.

On Fri, 11 Apr 2003, Arnav Sheth wrote:

> I am trying to load the Tcl/Tk package in order to use the AnalyzeFMRI GUI, but 
> I keep getting the following error when I load the Tcl/Tk package:
> 
> Error in firstlib(which.lib.loc, package) : 
>         TCL_LIBRARY is not set
> Error in library(pkg, character.only = TRUE) : 
>         .First.lib failed
> 
> I am using Windows and I altered the autoexec.bat file, I tried to set the tcl 
> library in R and none of these seemed to work.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gerds at fdm.uni-freiburg.de  Mon Apr 14 10:40:10 2003
From: gerds at fdm.uni-freiburg.de (Thomas Gerds)
Date: Mon, 14 Apr 2003 10:40:10 +0200
Subject: [R] summary.formula: method reverse does not use fun argument
In-Reply-To: 
	<Pine.A41.4.44.0304110830040.100930-100000@homer03.u.washington.edu> (Thomas
	Lumley's message of "Fri, 11 Apr 2003 08:38:55 -0700 (PDT)")
References: <Pine.A41.4.44.0304110830040.100930-100000@homer03.u.washington.edu>
Message-ID: <7ewuhx4glx.fsf@rembrandt.fdm.uni-freiburg.de>


thanks for both answers! sorry, for not reading the doc carefully
enough in the first place, and also for not referring to the marvelous
Hmisc package.

tomy

Thomas Lumley <tlumley at u.washington.edu> writes:

> On Fri, 11 Apr 2003, Thomas Gerds wrote:
>
>> hi,
>>
>> recently i discovered the functionability summary.formula, awesome!
>
> It would be useful to say *where* you discovered it -- it is in a package
> that isn't yet on CRAN.
>
>
>> from the help page i understand that method=reverse allows to
>> summarize all variables on the right hand side of formula
>> (the help page on line 229 wrongly refers to the left? hand side variables)
>> in categories which are determined by a single left hand side
>> variable.
>>
>> my problem is that the argument fun seems not to be compatible with
>> method=reverse!? every continuous variable is summarized in three
>> quantiles.
>
> Yes, that's what the help page says.
>
> It also says that for the default method="response" the response variable
> can be multivariate, which seems to be what you want.  It says many other
> helpful things, too.
>
>
> 	-thomas

-- 
no signature


From p.dalgaard at biostat.ku.dk  Mon Apr 14 11:01:43 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Apr 2003 11:01:43 +0200
Subject: [R] functions in a package
In-Reply-To: <1050286984.3e9a1b88744b1@my.uq.edu.au>
References: <Pine.SOL.4.33.0304131848130.20605-100000@panther.cs.ucla.edu>
	<1050286984.3e9a1b88744b1@my.uq.edu.au>
Message-ID: <x2llyd4fm0.fsf@biostat.ku.dk>

"Andrew C. Ward" <s195404 at student.uq.edu.au> writes:

> Yan, I believe this very question was asked on this list in the past
> couple of weeks. One of the solutions was
>   > search() # gives a list of loaded packages
>   > ls(pos=2) # lists all functions in pos=2 of the search path

...although ls("package:foo") might be preferable if you can't be sure
of the position in the search path.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From ramzi_feg at yahoo.fr  Mon Apr 14 11:14:08 2003
From: ramzi_feg at yahoo.fr (=?iso-8859-1?q?Ramzi=20Feghali?=)
Date: Mon, 14 Apr 2003 11:14:08 +0200 (CEST)
Subject: [R] Memory size of R 
Message-ID: <20030414091408.74354.qmail@web20302.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030414/df85f4f5/attachment.pl

From p.dalgaard at biostat.ku.dk  Mon Apr 14 11:21:49 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Apr 2003 11:21:49 +0200
Subject: [R] danish characters - installing R - linux redhat 8.0
In-Reply-To: <F106FRnuh2GCLzCOegJ00006712@hotmail.com>
References: <F106FRnuh2GCLzCOegJ00006712@hotmail.com>
Message-ID: <x2he914eoi.fsf@biostat.ku.dk>

"Niels Steen Krogh" <nielssteenkrogh at hotmail.com> writes:

> I'm using R on a linux redhat 8.0 installation.
> 
> The special danish characters (??????) are showed wrong on the screen.
> 
> Example:
> 
> yy<-matrix(c(0,2,1,1,8),ncol=1,dimnames=list(c("Br???","AGF","AB","Farum","FC-Kbh."
> ),c("Stemmer")))
> 
> barplot(yy[1:5],ylab=names(as.data.frame(yy)),main="5. grade.... ")
> 
> 
> Any hints?

UTF-8 characters, I suspect. R doesn't know how to deal with those
(volunteers?). Works for me with Danish letters, but I have.

LANG=C
LC_CTYPE=da_DK

i.e. my /etc/sysconfig/i18n is now

#LANG="en_US.UTF-8"
#SUPPORTED="da_DK.UTF-8:da_DK:da:en_DK.UTF-8:en_DK:en:en_US.UTF-8:en_US:en"
#SYSFONT="latarcyrheb-sun16"
LANG=C
LC_CTYPE=da_DK

I use the "C" locale to get "ls -a" to behave as it's makers intended
and to avoid seeing Danish translations of system messages, which are
awkward to put it amicably... (Not that anyone else gets translations
right.)  You might also use LANG=da_DK and then the LC_CTYPE setting
should be irrelevant.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From maechler at stat.math.ethz.ch  Mon Apr 14 11:32:57 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 14 Apr 2003 11:32:57 +0200
Subject: [R] rpart vs. randomForest
In-Reply-To: <200304122141.h3CLf0fB025857@mailserver2.hushmail.com>
References: <200304122141.h3CLf0fB025857@mailserver2.hushmail.com>
Message-ID: <16026.32841.875472.558024@gargle.gargle.HOWL>

>>>>> "Anonymous" ==   <chumpmonkey at hushmail.com>
>>>>>     on Sat, 12 Apr 2003 14:41:00 -0700 writes:

    Anonymous> Greetings. I'm trying to determine whether to use
    Anonymous> rpart or randomForest for a classification
    Anonymous> tree. Has anybody tested efficacy formally? I've
    Anonymous> run both and the confusion matrix for rf beats
    Anonymous> rpart. I've looking at the rf help page and am
    Anonymous> unable to figure out how to extract the tree.
    Anonymous> But more than that I'm looking for a more
    Anonymous> comprehensive user's guide for randomForest
    Anonymous> including the benefits on using it with MDS. Can
    Anonymous> anybody suggest a general guide? I've been
    Anonymous> finding a lot of broken links and cs-type of web
    Anonymous> pages rather than an end-user's guide. Also
    Anonymous> people's experience on adjusting the mtry param
    Anonymous> would be useful. Breiman says that it isn't too
    Anonymous> sensitive but I'm curious if anybody has had a
    Anonymous> different experience with it. Thanks in advance
    Anonymous> and apologies if this is too general.


If you really read Breiman, or alternatively, remember English,
you'll know that a forest has many trees...

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/


From spencer.graves at pdf.com  Mon Apr 14 11:36:14 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 14 Apr 2003 02:36:14 -0700
Subject: [R] Bayesian package
References: <002601c3004c$d3774770$8126ca51@statw1c2z9batg>
Message-ID: <3E9A810E.1090603@pdf.com>

GAMMA-POISSON:  Am I correct that the discrete marginal of a 
gamma-Poisson is negative binomial?  Try, "?pnbinom" for that.  The 
posterior is another gamma;  use "?pgamma", etc., for that.

GAMMA FUNCTION WITH LARGE ARGUMENTS:

 > lgamma(284)
[1] 1318.403
 > gamma(284)
[1] Inf

Acceptable?
Spencer Graves

Ramon Mart?nez Coscoll? wrote:
> We are trying to obtain a predictive distribution in a Poisson model using a
> non-informative prior distribution. We have found a gamma poisson as a
> result of our analysis and we want to evaluate it in R. Is there any package
> where this distribution and anothers are defined?
> 
> In any case, we have tried to programm the gammapoisson probability function
> but we have found another problem: we must evaluate a gamma function with a
> quite high value (gamma(284)). How can it be done?
> 
> Thank you very much!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From petr.pikal at precheza.cz  Mon Apr 14 11:51:44 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 14 Apr 2003 11:51:44 +0200
Subject: [R] NA in logical vector = data frame row numbers scrambled
Message-ID: <3E9AA0D0.21940.757BAB@localhost>

Dear all.

RE how to estimate parameters of multimodal distribution
Thank to prof.Ripley for pointing me to mclust package, although I am not sure I 
can apply it to my problem.

I have another question. 

I need to change some of my values in data frame to NA.

I use something like  
df[df$v1 < 5, 5:10] <- NA 

which is OK if there are no NA values in v1.

here are some foo attempts 
> test
   index cislo     time den hod min  zatizdp   plyndp  skalice
5      5     1 37693.79  13  19   0 106.6707 533.0288 5.932448
6      6     1 37693.80  13  19  15 106.2308 533.8799 6.008640
7      7     1 37693.81  13  19  30 106.3643 534.5321 5.960807
8      8     1 37693.82  13  19  45 106.9483 533.9640 5.962759
9      9     1 37693.83  13  20   0 106.9289 533.9978 5.939210
10    10     1 37693.84  13  20  15 107.1585 518.3881 5.980370

> test[test$min==0,7:9]<-NA

> test
   index cislo     time den hod min  zatizdp   plyndp  skalice
5      5     1 37693.79  13  19   0       NA       NA       NA
6      6     1 37693.80  13  19  15 106.2308 533.8799 6.008640
7      7     1 37693.81  13  19  30 106.3643 534.5321 5.960807
8      8     1 37693.82  13  19  45 106.9483 533.9640 5.962759
9      9     1 37693.83  13  20   0       NA       NA       NA
10    10     1 37693.84  13  20  15 107.1585 518.3881 5.980370

but further on

> test[test$plyndp<520,7:9]<-NA
Error in if (all(i >= 0) && (nn <- max(i)) > nrows) { : 
        missing value where logical needed

the problem is in logical vector having NA

> test$plyndp<520
[1]    NA FALSE FALSE FALSE    NA  TRUE

and subsequent scrambled row numbering

> test[test$plyndp<520,7:9]
     zatizdp   plyndp skalice
NA        NA       NA      NA
NA1       NA       NA      NA
X10 107.1585 518.3881 5.98037

Is there some more simple or direct way how to achieve this

> test[complete.cases(test),][na.omit(test$plyn<530),]
   index cislo     time den hod min  zatizdp   plyndp skalice
10    10     1 37693.84  13  20  15 107.1585 518.3881 5.98037

to be able to change values in data frame gradually to NA?

Excuse my awkward English. I hope you will understand my problem.
Thanks.

Best regards.

Petr Pikal
petr.pikal at precheza.cz
p.pik at volny.cz


From maechler at stat.math.ethz.ch  Mon Apr 14 11:54:59 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 14 Apr 2003 11:54:59 +0200
Subject: [R] Peculiarity in non-central qchisq for ncp > 294.92 ...
In-Reply-To: <Pine.GHP.4.51.0304131405590.2386@raptor.csrv.uidaho.edu>
References: <Pine.GHP.4.51.0304131405590.2386@raptor.csrv.uidaho.edu>
Message-ID: <16026.34163.735248.736122@gargle.gargle.HOWL>

>>>>> "Andrew" == Andrew Robinson <andrewr at uidaho.edu>
>>>>>     on Sun, 13 Apr 2003 14:16:45 -0700 (PDT) writes:

    Andrew> Hello all, Here's my query:

    Andrew> Running R 1.6.2 on FreeBSD 5.0, and on WinXP, and I
    Andrew> find that the following hangs the process:

    Andrew> dchisq(alpha=0.01, df=1, ncp=295)

    Andrew> but it does work for ncp < 294.92.

No!
	dchisq(alpha = *)  
always gives an error about the invalidly named argument `alpha'.
But then,
     dchisq(0.01, df=1, ncp=295)
and many other values of "ncp") do work here.
Only when carefully reading the "Subject" line, I see that
there, you are talking about  qchisq() rather than dchisq().
And indeed, I can  confirm the "hanging" behavior on Windows 2000(server).

On Linux, the result is 
> qchisq(0.01, df=1, ncp=295)
[1] 1.797693e+308
> all.equal(.Machine$double.xmax, qchisq(0.01, df=1, ncp=295))
[1] TRUE

which is not really good either:

      plot(function(x) pchisq(x, df=1, ncp=295), from=1,to=1e4, log='x')

shows the pretty bad behavior (a clear bug).
So, after all, thanks for reporting!

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From thierlan at freesurf.fr  Mon Apr 14 11:56:02 2003
From: thierlan at freesurf.fr (thierlan@freesurf.fr)
Date: Mon, 14 Apr 2003 11:56:02 +0200 (CEST)
Subject: [R] No graphical view ?!
Message-ID: <17628.81.51.89.234.1050314162.squirrel@arlette.freesurf.fr>

Hello,

I've just installed R (Linux) and I have some problems with graphical
viewing.Could you, please, explain me why I can't see graph when I just want to make
a plot ?

Many thanks !

St?phanie Langevin
Helios BioSciences


----------------------------------------------------------------
Ce service de mailing vous est offert par http://www.freesurf.fr.
FreeSurf, votre acces ADSL a partir de 29 euros/mois
http://www.freesurf.fr/adsl/


From ripley at stats.ox.ac.uk  Mon Apr 14 12:14:27 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 11:14:27 +0100 (BST)
Subject: [R] No graphical view ?!
In-Reply-To: <17628.81.51.89.234.1050314162.squirrel@arlette.freesurf.fr>
Message-ID: <Pine.LNX.4.44.0304141110130.8667-100000@gannet.stats>

On Mon, 14 Apr 2003 thierlan at freesurf.fr wrote:

> Hello,
> 
> I've just installed R (Linux) and I have some problems with graphical
> viewing.Could you, please, explain me why I can't see graph when I just want to make
> a plot ?

You give us very little to go on here.  The most likely explanation is 
that X11 was not found when you installed R (perhaps because you don't 
have the -devel RPMs installed?)

What happens when you run R and do

> x11()

?  A graphics window should pop up, or you should get an informative error 
message.

To help you further we need to know

- the version of R and the distribution of Linux
- how you installed R (from the sources, RPMs etc)
- the logs of the installation.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From david.whiting at ncl.ac.uk  Mon Apr 14 15:17:33 2003
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Mon, 14 Apr 2003 13:17:33 +0000
Subject: [R] Analyzing Medical Data Using S-PLUS by Everitt and Rabe-Hasketh
Message-ID: <20030414131733.GH13842@192.168.57.2>

Dear All,

I have just read a glowing review (in the Int. Journal of
Epidemiology) of "Analyzing Medical Data Using S-PLUS" by Everitt and
Rabe-Hesketh and it sounds like the sort of thing I would like to get
my hands on.  Is anyone on this list familiar with this book, and in
particular have a feel for how useful it will be with R?  According to
the review the emphasis is on the command line rather than the gui
which is a good sign for "compatibility".  From what I have picked up
from being on this list, my copy of MASS and various R docs the
differences are likely to be few, but I would feel more comfortable if
I could get some opinions from more experienced R/S-plus users.

Thanks.

Dave

-- 
Dave Whiting
Dar es Salaam, Tanzania


From ripley at stats.ox.ac.uk  Mon Apr 14 13:00:59 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 12:00:59 +0100 (BST)
Subject: [R] NA in logical vector = data frame row numbers scrambled
In-Reply-To: <3E9AA0D0.21940.757BAB@localhost>
Message-ID: <Pine.LNX.4.44.0304141145460.8819-100000@gannet.stats>

On Mon, 14 Apr 2003, Petr Pikal wrote:

> Dear all.
> 
> RE how to estimate parameters of multimodal distribution
> Thank to prof.Ripley for pointing me to mclust package, although I am not sure I 
> can apply it to my problem.
> 
> I have another question. 
> 
> I need to change some of my values in data frame to NA.
> 
> I use something like  
> df[df$v1 < 5, 5:10] <- NA 
> 
> which is OK if there are no NA values in v1.
> 
> here are some foo attempts 
> > test
>    index cislo     time den hod min  zatizdp   plyndp  skalice
> 5      5     1 37693.79  13  19   0 106.6707 533.0288 5.932448
> 6      6     1 37693.80  13  19  15 106.2308 533.8799 6.008640
> 7      7     1 37693.81  13  19  30 106.3643 534.5321 5.960807
> 8      8     1 37693.82  13  19  45 106.9483 533.9640 5.962759
> 9      9     1 37693.83  13  20   0 106.9289 533.9978 5.939210
> 10    10     1 37693.84  13  20  15 107.1585 518.3881 5.980370
> 
> > test[test$min==0,7:9]<-NA
> 
> > test
>    index cislo     time den hod min  zatizdp   plyndp  skalice
> 5      5     1 37693.79  13  19   0       NA       NA       NA
> 6      6     1 37693.80  13  19  15 106.2308 533.8799 6.008640
> 7      7     1 37693.81  13  19  30 106.3643 534.5321 5.960807
> 8      8     1 37693.82  13  19  45 106.9483 533.9640 5.962759
> 9      9     1 37693.83  13  20   0       NA       NA       NA
> 10    10     1 37693.84  13  20  15 107.1585 518.3881 5.980370
> 
> but further on
> 
> > test[test$plyndp<520,7:9]<-NA
> Error in if (all(i >= 0) && (nn <- max(i)) > nrows) { : 
>         missing value where logical needed
> 
> the problem is in logical vector having NA
> 
> > test$plyndp<520
> [1]    NA FALSE FALSE FALSE    NA  TRUE
> 
> and subsequent scrambled row numbering

No, that's not `scrambled', and those are row names and not row numbers.  
You asked for a missing value in two rows, and that is what you got.
You don't know if those are rows 5 and 9 or not, so the name has correctly
been changed.  However, when doing replacement, we could probably assume 
that one true value should be replaced, but then it is unclear whether the
values corresponding to the NA indices on the RHS should be used or not.

> > test[test$plyndp<520,7:9]
>      zatizdp   plyndp skalice
> NA        NA       NA      NA
> NA1       NA       NA      NA
> X10 107.1585 518.3881 5.98037
> 
> Is there some more simple or direct way how to achieve this

test[!is.na(test$plyndp) & test$plyndp<520,7:9] <- NA

or (R >= 1.7.0)

is.na(test)[, 7:9] <- test$plyndp<520

(The last does not work in S-PLUS, btw, as it does skip the NA values.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Apr 14 13:04:20 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 12:04:20 +0100 (BST)
Subject: [R] kmeans clustering
In-Reply-To: <3EA24FDA@webmail.ucis.dal.ca>
Message-ID: <Pine.LNX.4.44.0304141201430.8819-100000@gannet.stats>

On Mon, 14 Apr 2003, pingzhao wrote:

> Hi,
> 
> I am using kmeans to cluster a dataset.
> I test this example:
> 
> > data<-matrix(scan("data100.txt"),100,37,byrow=T)
> (my dataset is 100 rows and 37 columns--clustering rows)
> 
>  > c1<-kmeans(data,3,20)
> > c1
> $cluster
>   [1] 1 1 1 1 1 1 1 3 3 3 1 3 1 3 3 1 1 1 1 3 1 3 3 1 1 1 3 3 1 1 3 1 1 1 1 3 
> 3
>  [38] 3 1 1 1 3 1 1 1 1 3 3 3 1 1 1 1 1 1 3 1 3 1 1 3 1 1 1 1 3 1 1 1 1 1 1 3 
> 1
>  [75] 1 3 1 3 1 1 1 1 3 1 1 1 1 1 3 1 1 3 1 1 3 3 1 2 1 1
> 
> $withinss
> [1] 1037.5987    0.0000  666.9701
> 
> $size
> [1] 68  1 31
> 
> > c4<-kmeans(data,3,20)
> $withinss
> [1]   0.0000 865.7628 851.1214
> 
> $size
> [1]  1 54 45
> 
> Does any one tell me why the results are very different with the same 
> dataset and parameters when I run some times this command 
> 'kmeans(data,3,20)'???

The help page could tell  you:

 centers: Either the number of clusters or a set of initial cluster
          centers. If the first, a random set of rows in `x' are chosen
          as the initial centers. 

At the very least, the labellings of the clusters are arbitrary, but 
K-means usually has multiple local minima.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ernesto at ipimar.pt  Mon Apr 14 13:09:44 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 14 Apr 2003 12:09:44 +0100
Subject: [R] Charts to M$Word - what's the best format
Message-ID: <1050318584.1343.9.camel@gandalf.ipimar.pt>

Hi

I'm exporting some graphs from R to M$Word. I used png, jpeg and bmp and
the quality is poor when comparing with the postscript.

What is the best way to export a chart to be included in a M$Word file ?

Thanks

EJ


From kwan022 at stat.auckland.ac.nz  Mon Apr 14 14:06:32 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 15 Apr 2003 00:06:32 +1200 (NZST)
Subject: [R] kmeans clustering
In-Reply-To: <3EA24FDA@webmail.ucis.dal.ca>
Message-ID: <Pine.LNX.4.33.0304150004060.12304-100000@stat56.stat.auckland.ac.nz>

Hi,                                                                                                                                 
                                                                                                                                    
It is expected!  If you read:                                                                                                       
  ?kmeans                                                                                                                           
For the "centers" argument:                                                                                                         
"...a random set of rows in `x' are chosen                                                                                          
          as the initial centers. "                                                                                                 
                                                                                                                                    
In other words the starting values are different.  In fact one should run                                                           
kmeans() several times to avoid local minimum.                                                                                       
                                               
If you run it, say, 20 times and you get the same results 15 times, then 
you can "probably" be confident to use that solution.

On Mon, 14 Apr 2003, pingzhao wrote:

> Does any one tell me why the results are very different with the same 
> dataset and parameters when I run some times this command 
> 'kmeans(data,3,20)'???
> 
> Thank you for your help in advance!
> 
> ping
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From p.dalgaard at biostat.ku.dk  Mon Apr 14 13:12:45 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Apr 2003 13:12:45 +0200
Subject: [R] Peculiarity in non-central qchisq for ncp > 294.92 ...
In-Reply-To: <16026.34163.735248.736122@gargle.gargle.HOWL>
References: <Pine.GHP.4.51.0304131405590.2386@raptor.csrv.uidaho.edu>
	<16026.34163.735248.736122@gargle.gargle.HOWL>
Message-ID: <x28yud49jm.fsf@biostat.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> which is not really good either:
> 
>       plot(function(x) pchisq(x, df=1, ncp=295), from=1,to=1e4, log='x')
> 
> shows the pretty bad behavior (a clear bug).

Well... shortcoming, I'd say. The author of those routines didn't
expect people to use them with huge noncentralities. I've had this on
my TODO list for a couple of years by now, ever since fixing the
similar issue with dchisq--see Rnews 1/1. It looks fairly easy to do
something along the same lines, but there is now a double recurrence
relation and it requires a bit of concentration to get the tail bounds
for the termination criterion.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From kjetil at entelnet.bo  Mon Apr 14 06:15:06 2003
From: kjetil at entelnet.bo (kjetil brinchmann halvorsen)
Date: Mon, 14 Apr 2003 00:15:06 -0400
Subject: [R] Problem with nlme or glmmPQL (MASS)
Message-ID: <3E99FD8A.8803.165E381@localhost>

Hola!

I am encountering the following problem, in a multilevel analysis, 
using glmmPQL from MASS. This occurs with bothj rw1062 and r-devel, 
respectively with nlme versions 3.1-38 and 3.1-39 (windows XP).

>  S817.mod1 <- glmmPQL( S817 ~ MIEMBROScat+S901+S902A+S923+URBRUR+REGION+
+                  
S102+S103+S106A+S108+S110A+S109A+S202+S401+S557A+S557B+
+                  YHOGFcat, data=Hogares, random= ~1, 
family=binomial, 
+                  na.action=na.omit)
iteration 1 
Error in getGroups.data.frame(dataMix, groups) : 
        Invalid formula for groups
> getGroupsFormula(Hogares)
~ID08

Hogares is a groupedData object. The only non-default thing I have 
done is to use order.groups=FALSE in groupedData, since the response 
is a factor and the max ordering function does not apply. 

What is wring here?

Kjetil Halvorsen


From Ursula.Becker at nfoeurope.com  Mon Apr 14 13:23:10 2003
From: Ursula.Becker at nfoeurope.com (Ursula Becker)
Date: Mon, 14 Apr 2003 13:23:10 +0200
Subject: [R] Factor analysis in R
Message-ID: <3E9AB63E.15967.1AC1C5BF@localhost>

Hi all,

is it possible to run factor analysis in R such that the routine 
returns
- unstandardized factor scores (according to the original scale)
- rotated factor scores (these may be standardized)

So far I have only found the possibility to return standardised 
unrotated factor scores.

Thank you very much,
Ursula


====================================================
NFO Infratest
Ursula Becker
EX-A-MINE Centre
Landsberger Str. 338
D - 80 687 M?nchen
Germany
Tel.: +49 89 5600 423
Fax: +49 89 5600 611
ursula.becker at nfoeurope.com
www.ex-a-mine.com
----------------------------------------------------
EX-A-MINE: Explore, Analyze and Mine your Data!
Services for Data Mining and Database Marketing by NFO Infratest.
====================================================

The information transmitted is intended only for the person or entity to
which it is addressed and may contain confidential and/or privileged
material. Any review, retransmission, dissemination or other use of, or
taking of any action in reliance upon, this information by persons or
entities other than the intended recipient is prohibited.   

If you received this in error, please contact the sender and delete the
material from any computer.


From kwan022 at stat.auckland.ac.nz  Mon Apr 14 14:22:48 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 15 Apr 2003 00:22:48 +1200 (NZST)
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <1050318584.1343.9.camel@gandalf.ipimar.pt>
Message-ID: <Pine.LNX.4.33.0304150021450.12304-100000@stat56.stat.auckland.ac.nz>

Try Metafile.  You can copy the graph (I'm assuming you're using Rgui) as 
Metafile, then in Word, go to Edit -> Paste Special..., then paste as 
Enhanced Metafile.

This allows you to resize the plot in Word without losing its quality.

On 14 Apr 2003, Ernesto Jardim wrote:

> Date: 14 Apr 2003 12:09:44 +0100
> From: Ernesto Jardim <ernesto at ipimar.pt>
> To: Mailing List R <r-help at stat.math.ethz.ch>
> Subject: [R] Charts to M$Word - what's the best format
> 
> Hi
> 
> I'm exporting some graphs from R to M$Word. I used png, jpeg and bmp and
> the quality is poor when comparing with the postscript.
> 
> What is the best way to export a chart to be included in a M$Word file ?
> 
> Thanks
> 
> EJ
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From ripley at stats.ox.ac.uk  Mon Apr 14 13:30:44 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 12:30:44 +0100 (BST)
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <1050318584.1343.9.camel@gandalf.ipimar.pt>
Message-ID: <Pine.LNX.4.44.0304141229030.11858-100000@gannet.stats>

On 14 Apr 2003, Ernesto Jardim wrote:

> I'm exporting some graphs from R to M$Word. I used png, jpeg and bmp and
> the quality is poor when comparing with the postscript.
> 
> What is the best way to export a chart to be included in a M$Word file ?

I'll assume you are using Word on Windows and not MacOS: Windows MetaFile,
or postscript if you have a postscript printer.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ernesto at ipimar.pt  Mon Apr 14 13:34:21 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 14 Apr 2003 12:34:21 +0100
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <Pine.LNX.4.33.0304150021450.12304-100000@stat56.stat.auckland.ac.nz>
References: 
	 <Pine.LNX.4.33.0304150021450.12304-100000@stat56.stat.auckland.ac.nz>
Message-ID: <1050320061.1345.43.camel@gandalf.ipimar.pt>

Hi

You're also assuming I'm in M$Windows, which I'm not. Anyway if I'm in
windows that is the best way ? What about exporting with R functions
like png() ? 

I thought these functions would be the best way of exporting charts.

Regards

EJ

On Mon, 2003-04-14 at 13:22, Ko-Kang Kevin Wang wrote:
> Try Metafile.  You can copy the graph (I'm assuming you're using Rgui) as 
> Metafile, then in Word, go to Edit -> Paste Special..., then paste as 
> Enhanced Metafile.
> 
> This allows you to resize the plot in Word without losing its quality.
> 
> On 14 Apr 2003, Ernesto Jardim wrote:
> 
> > Date: 14 Apr 2003 12:09:44 +0100
> > From: Ernesto Jardim <ernesto at ipimar.pt>
> > To: Mailing List R <r-help at stat.math.ethz.ch>
> > Subject: [R] Charts to M$Word - what's the best format
> > 
> > Hi
> > 
> > I'm exporting some graphs from R to M$Word. I used png, jpeg and bmp and
> > the quality is poor when comparing with the postscript.
> > 
> > What is the best way to export a chart to be included in a M$Word file ?
> > 
> > Thanks
> > 
> > EJ
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >


From ripley at stats.ox.ac.uk  Mon Apr 14 13:40:20 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 12:40:20 +0100 (BST)
Subject: [R] Problem with nlme or glmmPQL (MASS)
In-Reply-To: <3E99FD8A.8803.165E381@localhost>
Message-ID: <Pine.LNX.4.44.0304141237380.11901-100000@gannet.stats>

glmmPQL is not documented to work with groupedData objects, so that's your 
mistake.

See ?glmmPQL and supply a valid formula for random.

On Mon, 14 Apr 2003, kjetil brinchmann halvorsen wrote:

> I am encountering the following problem, in a multilevel analysis, 
> using glmmPQL from MASS. This occurs with bothj rw1062 and r-devel, 
> respectively with nlme versions 3.1-38 and 3.1-39 (windows XP).
> 
> >  S817.mod1 <- glmmPQL( S817 ~ MIEMBROScat+S901+S902A+S923+URBRUR+REGION+
> +                  
> S102+S103+S106A+S108+S110A+S109A+S202+S401+S557A+S557B+
> +                  YHOGFcat, data=Hogares, random= ~1, 
> family=binomial, 
> +                  na.action=na.omit)
> iteration 1 
> Error in getGroups.data.frame(dataMix, groups) : 
>         Invalid formula for groups
> > getGroupsFormula(Hogares)
> ~ID08
> 
> Hogares is a groupedData object. The only non-default thing I have 
> done is to use order.groups=FALSE in groupedData, since the response 
> is a factor and the max ordering function does not apply. 
> 
> What is wring here?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Apr 14 13:47:49 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 12:47:49 +0100 (BST)
Subject: [R] Factor analysis in R
In-Reply-To: <3E9AB63E.15967.1AC1C5BF@localhost>
Message-ID: <Pine.LNX.4.44.0304141241530.11901-100000@gannet.stats>

I think you must be using `scores' in a different sense from ?factanal and 
the references therein.  The scores are determined by the loadings plus a 
fitting method.  It makes no sense to rotate scores and not loadings, and 
the scores are always on the original scales.

On Mon, 14 Apr 2003, Ursula Becker wrote:

> is it possible to run factor analysis in R such that the routine 
> returns
> - unstandardized factor scores (according to the original scale)
> - rotated factor scores (these may be standardized)
> 
> So far I have only found the possibility to return standardised 
> unrotated factor scores.

All the possibilities are documented on the help page, with copious 
references.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From andrewr at uidaho.edu  Mon Apr 14 13:49:32 2003
From: andrewr at uidaho.edu (Andrew Robinson)
Date: Mon, 14 Apr 2003 04:49:32 -0700 (PDT)
Subject: [R] Peculiarity in non-central qchisq for ncp > 294.92 ...
In-Reply-To: <x28yud49jm.fsf@biostat.ku.dk>
References: <Pine.GHP.4.51.0304131405590.2386@raptor.csrv.uidaho.edu>
 <16026.34163.735248.736122@gargle.gargle.HOWL> <x28yud49jm.fsf@biostat.ku.dk>
Message-ID: <Pine.GHP.4.51.0304140419210.9573@raptor.csrv.uidaho.edu>

Peter,

I'm sympathetic to the package author.  I'm running some pretty extreme
simulations, and am quite satisfied by artificially constraining the ncp
to be below 294.  This makes my conclusions slightly conservative, but
only very slightly, and the results are very unlikely to change much when
the proper value is used.

I respectfully submit that undocumented shortcomings are bugs.  This one
did me no damage because I was too impatient to wait for the result.
However, had my simulations been much longer term, I would have obtained
very inaccurate results!

I would be more than pleased to draft a note for the help file for this
and any other that you know of.  I'd view that as being higher priority
than fixing it (them).

Best wishes

Andrew

On Mon, 14 Apr 2003, Peter Dalgaard BSA wrote:

> Martin Maechler <maechler at stat.math.ethz.ch> writes:
>
> > which is not really good either:
> >
> >       plot(function(x) pchisq(x, df=1, ncp=295), from=1,to=1e4, log='x')
> >
> > shows the pretty bad behavior (a clear bug).
>
> Well... shortcoming, I'd say. The author of those routines didn't
> expect people to use them with huge noncentralities. I've had this on
> my TODO list for a couple of years by now, ever since fixing the
> similar issue with dchisq--see Rnews 1/1. It looks fairly easy to do
> something along the same lines, but there is now a double recurrence
> relation and it requires a bit of concentration to get the tail bounds
> for the termination criterion.
>
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
>

Andrew Robinson			     Ph: 208 885 7115
Department of Forest Resources	     Fa: 208 885 6226
University of Idaho		     E : andrewr at uidaho.edu
PO Box 441133			     W : http://www.uidaho.edu/~andrewr
Moscow ID 83843			     Or: http://www.biometrics.uidaho.edu
No statement above necessarily represents my employer's opinion.


From ripley at stats.ox.ac.uk  Mon Apr 14 14:00:27 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 13:00:27 +0100 (BST)
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <1050320061.1345.43.camel@gandalf.ipimar.pt>
Message-ID: <Pine.LNX.4.44.0304141253480.11901-100000@gannet.stats>

On 14 Apr 2003, Ernesto Jardim wrote:

> You're also assuming I'm in M$Windows, which I'm not. Anyway if I'm in

How do use use bmp if you are not?  Perhaps you would be so kind as to 
tell us

- What platform you are using R on?
- What platform you are using MicroSoft Word on?

and in future disclose such information in your first posting.

> windows that is the best way ? What about exporting with R functions
> like png() ? 
> 
> I thought these functions would be the best way of exporting charts.

You assert, but you don't explain why and you don't like the results! If a
`chart' means a vector plot, it is pretty obvious that a vector graphics
format is best, and that means EMF, ps, PDF or SVG in the world of R
graphics drivers.  AFAIK Word does not support the last two.

> On Mon, 2003-04-14 at 13:22, Ko-Kang Kevin Wang wrote:
> > Try Metafile.  You can copy the graph (I'm assuming you're using Rgui) as 
> > Metafile, then in Word, go to Edit -> Paste Special..., then paste as 
> > Enhanced Metafile.
> > 
> > This allows you to resize the plot in Word without losing its quality.
> > 
> > On 14 Apr 2003, Ernesto Jardim wrote:
> > 
> > > Date: 14 Apr 2003 12:09:44 +0100
> > > From: Ernesto Jardim <ernesto at ipimar.pt>
> > > To: Mailing List R <r-help at stat.math.ethz.ch>
> > > Subject: [R] Charts to M$Word - what's the best format
> > > 
> > > Hi
> > > 
> > > I'm exporting some graphs from R to M$Word. I used png, jpeg and bmp and
> > > the quality is poor when comparing with the postscript.
> > > 
> > > What is the best way to export a chart to be included in a M$Word file ?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jfox at mcmaster.ca  Mon Apr 14 14:11:16 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 14 Apr 2003 08:11:16 -0400
Subject: [R] cannot create postscript files with trellis graphics
  inside a function
In-Reply-To: <Pine.LNX.4.44.0304132303170.1580-100000@Chrestomanci>
Message-ID: <5.1.0.14.2.20030414080649.01e26520@mcmail.cis.mcmaster.ca>

Dear Faheem,

At 11:13 PM 4/13/2003 -0400, Faheem Mitha wrote:

>If I define
>
>foo <-function()
>{
>   x <- rnorm(500)
>   trellis.device(postscript, file="plot.ps")
>   densityplot(~x)
>   dev.off()
>  }
>
>and call foo() then plot.ps is just a blank plot. However, if I extract
>the lines inside foo and run them, ie.
>
>x <- rnorm(500)
>trellis.device(postscript, file="plot.ps")
>densityplot(~x)
>dev.off()
>
>then plot.ps is created without problems. The former method worked with
>the regular postscript() device, which I used to use all the time inside
>functions.
>
>I've never used lattice/trellis graphics before. Is this a bug or am I
>doing something wrong?

Lattice-graphics functions return objects rather than drawing plots as side 
effects. When you call a lattice function such as densityplot directly at 
the command plot, print is invoked implicitly and "prints" the plot. Within 
a function, you have to call print explicitly -- e.g., print(densityplot(~x)).

I hope that this helps,
  John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox
-----------------------------------------------------


From p.dalgaard at biostat.ku.dk  Mon Apr 14 14:37:01 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Apr 2003 14:37:01 +0200
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <Pine.LNX.4.44.0304141253480.11901-100000@gannet.stats>
References: <Pine.LNX.4.44.0304141253480.11901-100000@gannet.stats>
Message-ID: <x2vfxh2r2q.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> You assert, but you don't explain why and you don't like the results! If a
> `chart' means a vector plot, it is pretty obvious that a vector graphics
> format is best, and that means EMF, ps, PDF or SVG in the world of R
> graphics drivers.  AFAIK Word does not support the last two.

With add-ons it might. I did some work with someone who had purchased
the relevant Adobe software, and things came out very nicely with R's
pdf plots. (Is there a "cheapskate" version of that involving
Ghostscript, maybe?) 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From comm at 263.net  Mon Apr 14 04:36:46 2003
From: comm at 263.net (comm)
Date: Mon, 14 Apr 2003 10:36:46 +0800
Subject: [R] A statistical problem.Anybody can help me?
Message-ID: <20030414023731.C8B7A2F8F5@mta5.x263.net>

Sorry for the contents not relating to R.

Assume there are N i.i.d zero-mean complex gaussian random
variables(RVs),as w(i),0<=i<N} with known variance,from which one
can generate another N RVs,as

    R(0)=sum over i {w(i)*w'(i)}
    R(1)=sum over i {w(i+1)*w'(i)}
    ...
up to
	R(N-1)= w(N-1)w'(i)

where w'(i) is the complex conjugate of w(i).
(from viewpoint of signal processing, R(i) are serial correlation of time series w(i))

If one defines a new random variable using {R(k)} as

Z=a(0)R(0)+a(1)|R(1)|+...  a(N-1)|R(N-1)|,

with {a(k)} are known and |.| is modulus operation.It's a decision
statistic encountered in my work. I wish to find its approximated(using
Central Limit Theorem) statistical characteristics in close-form.Mean and
variance are enough.

Does anybody have any ideas or references which can solve this problem?

(below is my previous thoughts and now it is tested not work because RVs appear to be Rician distributed)
Mean of Z is easy to get. However its variance is troublesome. I think it can be calculated by

    Var=alpha*C*alpha',

where alpha=[a(0) a(1) ... a(N-1)],C is covariance matrix of vector [R(0),|R(1)|,...,|R(N-1)|].

Besides the diagonal and first row and first column, the other elements is
small that can be ignored,which can be shown by simulations.Namely weak
cross-correlation is hold between any two RVs of set
{|R(1)|,|R(2)|,R(N-1)},while the crosss-correlation between R(0) and each
RV of set {|R(1)|,|R(2)|, |R(N-1)|} and self-correlation of set
{|R(0)|,|R(1)|,|R(N-1)|} is large and should not be ignored. The former is
what i seek. I almost exhausted,so i came here for help.


Any suggestion will be appreciated.

Regards,
Jeans Sun


From wouter.buytaert at tiscali.be  Mon Apr 14 15:22:56 2003
From: wouter.buytaert at tiscali.be (wouter buytaert)
Date: 14 Apr 2003 15:22:56 +0200
Subject: [R] factor differences in anova
Message-ID: <1050326576.2354.10.camel@BNL32.agr.kuleuven.ac.be>

Hello,

(maybe a quite basic statistical question, but I'm just struggling with
it)

I'm doing an anova:

> Res1<-aov(H2O~location+topo+horizon+pF+Error(location:topo:horizon))

(water retention of soils)

which gives a significant difference at factor "location".

Which function should I use to now which locations (there are 3: A, B
and C) differ significantly and which do not?

Thanks,

Wouter


From ernesto at ipimar.pt  Mon Apr 14 15:27:19 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 14 Apr 2003 14:27:19 +0100
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <Pine.LNX.4.44.0304141253480.11901-100000@gannet.stats>
References: <Pine.LNX.4.44.0304141253480.11901-100000@gannet.stats>
Message-ID: <1050326839.1345.201.camel@gandalf.ipimar.pt>

On Mon, 2003-04-14 at 13:00, Prof Brian Ripley wrote:
> On 14 Apr 2003, Ernesto Jardim wrote:
> 
> > You're also assuming I'm in M$Windows, which I'm not. Anyway if I'm in
> 
> How do use use bmp if you are not?  Perhaps you would be so kind as to 
> tell us
> 
> - What platform you are using R on?
> - What platform you are using MicroSoft Word on?
> 
> and in future disclose such information in your first posting.
> 

I'm using R 1.6.2 in SuSE linux box. I promise not to forget this
information in my posts anymore. 

I've tried bmp in a machine with windows. Rigth now I'm in Linux and I
don't have a windows machine with me. However, as you know, I'm able to
see the bmp in linux and I can also print all these formats.

One of the major R features for me is the ability to use it in Linux or
windows without worry with platform issues. I want to produce some plots
that I can send to someone else, who uses M$Windows and M$Word (I don't
know what version).

So I made a simple question. What's the best way to export a chart from
R to be used in M$Word. The copy/paste doesn't help, but it's a good
information for a moment that I'll be working in R for windows.


> > windows that is the best way ? What about exporting with R functions
> > like png() ? 
> > 
> > I thought these functions would be the best way of exporting charts.
> 
> You assert, but you don't explain why and you don't like the results! If a
> `chart' means a vector plot, it is pretty obvious that a vector graphics
> format is best, and that means EMF, ps, PDF or SVG in the world of R
> graphics drivers.  AFAIK Word does not support the last two.
> 

I'm not asserting anything. I'm making a statement based on my
understanding and experience of R.

Open Source, as I see it, makes use of the users comments and opinions.
So if I have an opinion I'll post it, the R team is free to use it or
not. If it will contribute to a better R I'll be deligth to help,
otherwise it's just a few minutes I lose writing a message. 

I'm doing simple plot() and png(), bmp() and jpeg() are producing plots
with lower resolution. You can find the files here:

http://ernesto.freezope.org/cmf/r/plot.png
http://ernesto.freezope.org/cmf/r/plot.ps

if you want to see what I mean.

> > On Mon, 2003-04-14 at 13:22, Ko-Kang Kevin Wang wrote:
> > > Try Metafile.  You can copy the graph (I'm assuming you're using Rgui) as 
> > > Metafile, then in Word, go to Edit -> Paste Special..., then paste as 
> > > Enhanced Metafile.
> > > 
> > > This allows you to resize the plot in Word without losing its quality.
> > > 
> > > On 14 Apr 2003, Ernesto Jardim wrote:
> > > 
> > > > Date: 14 Apr 2003 12:09:44 +0100
> > > > From: Ernesto Jardim <ernesto at ipimar.pt>
> > > > To: Mailing List R <r-help at stat.math.ethz.ch>
> > > > Subject: [R] Charts to M$Word - what's the best format
> > > > 
> > > > Hi
> > > > 
> > > > I'm exporting some graphs from R to M$Word. I used png, jpeg and bmp and
> > > > the quality is poor when comparing with the postscript.
> > > > 
> > > > What is the best way to export a chart to be included in a M$Word file ?

Regards

EJ


From tblackw at umich.edu  Mon Apr 14 15:36:08 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 14 Apr 2003 09:36:08 -0400 (EDT)
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <1050318584.1343.9.camel@gandalf.ipimar.pt>
Message-ID: <Pine.SOL.4.44.0304140927580.18818-100000@mspacman.gpcc.itd.umich.edu>


I think maybe the question is, how do you import postscript format
into an M$Word document.  I am NOT a word user, but I had to do this
some years ago and found that it IS possible to import postscript.

You do something like "import picture ... (some kind of generic-
sounding graphics format)", and it works fine.  The postscript
behaves very nicely once you get it in.  You have to play around
quite a bit, and try some very unlikely sounding possibilities to
get it in, but it WILL work.  There are definitely some shortcomings
in the documentation for M$Word (to put it charitably).

Other people will have more recent experience with this than I have.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On 14 Apr 2003, Ernesto Jardim wrote:

> Hi
>
> I'm exporting some graphs from R to M$Word. I used png, jpeg and bmp and
> the quality is poor when comparing with the postscript.
>
> What is the best way to export a chart to be included in a M$Word file ?
>
> Thanks
>
> EJ


From ripley at stats.ox.ac.uk  Mon Apr 14 15:47:54 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 14:47:54 +0100 (BST)
Subject: [R] factor differences in anova
In-Reply-To: <1050326576.2354.10.camel@BNL32.agr.kuleuven.ac.be>
Message-ID: <Pine.LNX.4.44.0304141441340.12108-100000@gannet.stats>

On 14 Apr 2003, wouter buytaert wrote:

> Hello,
> 
> (maybe a quite basic statistical question, but I'm just struggling with
> it)
> 
> I'm doing an anova:
> 
> > Res1<-aov(H2O~location+topo+horizon+pF+Error(location:topo:horizon))
> 
> (water retention of soils)
> 
> which gives a significant difference at factor "location".
> 
> Which function should I use to now which locations (there are 3: A, B
> and C) differ significantly and which do not?

Possibly TukeyHSD or package multicomp.  However, we would need to know a 
bit more about the design, as that's a rather peculiar Error() 
specification and you would need to be careful to apply these functions in 
the right stratum (assuming the location effect only occurs in one).

Function se.contrast would also be useful, and as there are only three
pairwise differences, multiple comparison issues are going to be minor
(especially as you have tested for an overall difference first).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lm.silva at sapo.pt  Mon Apr 14 15:49:10 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Mon, 14 Apr 2003 14:49:10 +0100 (WEST)
Subject: [R] categorical variables
Message-ID: <1050328150.3e9abc566e729@webmail.sapo.pt>

Dear helpers

I constructed a data frame with this structure

> str(dados1)
`data.frame':   485 obs. of  16 variables:
 $ Emissor         : int  1 1 1 1 1 1 1 1 1 1 ...
 $ Marisca.Rio     : int  1 1 1 1 1 1 1 1 1 1 ...
 $ Per?odo         : int  1 1 1 1 1 1 1 1 1 1 ...
 $ Reproducao      : int  3 3 3 3 3 3 3 3 3 3 ...
 $ Estacao         : int  2 2 2 2 2 2 2 2 2 2 ...
 $ X30cm           : int  1 1 1 1 1 1 1 1 1 1 ...
 $ Dir.mov         : int  0 0 0 0 0 0 0 0 0 0 ...
 $ Temp.media      : num  12.0 11.3 12.1 12.3 12.4 ...
 $ Temp.amplitude  : num   1.167 -0.750  0.875  0.125 ...
 $ Vel.media       : num  0.479 0.514 0.517 0.445 0.468 ...
 $ Vel.amplitude   : num  -0.04865  0.03417  0.00312 0.02364 ...
 $ Caudal.medio    : num  0.570 0.585 0.589 0.485 0.501 ...
 $ Caudal.amplitude: num  -0.04323  0.01449  0.00405 0.01617 ...
 $ Prof.media      : num  36.1 34.6 34.1 32.9 32.1 ...
 $ Prof.amplitude  : num   0.458 -1.500 -0.500 -1.250 -0.750 ...
 $ Movimento       : num  0 0 0 0 0 0 0 0 0 0 ...

My problem is that the first 7 variables are in fact 
categorical, some of them of the type Present/Absent. R is 
taking them as integer but I want categorical. How can I solve 
this problem? I searched data.frame help but I didn't found any 
parameter to set some variables to categorical


thank you
luis
--


http://adsl.sapo.pt


From tlumley at u.washington.edu  Mon Apr 14 15:50:44 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 14 Apr 2003 06:50:44 -0700 (PDT)
Subject: [R] princomp with not non-negative definite correlation matrix
In-Reply-To: <1050034155.3e963febd1b0b@webmail.stanford.edu>
Message-ID: <Pine.A41.4.44.0304140649010.226560-100000@homer06.u.washington.edu>

On Thu, 10 Apr 2003 tvr at stanford.edu wrote:

> $ R --version
> R 1.6.1 (2002-11-01).
>
> So I would like to perform principal components analysis on a 16X16
> correlation matrix, [princomp(cov.mat=x) where x is correlation matrix],
> the problem is princomp complains that it is not non-negative definite.
>
> I called eigen() on the correlation matrix and found that one of the
> eigenvectors is close to zero & negative (-0.001832311). Is there any
> way to work around this problem. A constraint: I only have the
> correlation matrix, not the data that produced it.

If you are confident the problem is due to rounding (or perhaps to small
amounts of missing data) you could set the smallest eigenvalue to zero.

However, in revising an introductory biostatistics text recently I have
found two correlation matrices with negative eigenvalues, both of which
were actually data entry errors.

	-thomas
Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From ben at zoo.ufl.edu  Mon Apr 14 15:00:33 2003
From: ben at zoo.ufl.edu (Ben Bolker)
Date: Mon, 14 Apr 2003 09:00:33 -0400 (EDT)
Subject: [R] bounces
Message-ID: <Pine.LNX.4.44.0304140850200.29266-100000@bolker.zoo.ufl.edu>


  I've gotten two messages now about bounces from the R-help (see below).  
I haven't set any vacation messages or the like, but we have recently
switched mail servers and I think our current server bounces "dangerous"
attachments (.exe etc).
   Can anyone help with diagnostics so I can figure out what's going on?

  Ben Bolker

On Fri, 11 Apr 2003 r-help-request at stat.math.ethz.ch wrote:

> Your membership in the mailing list R-help has been disabled due to
> excessive bounces The last bounce received from you was dated
> 04-Apr-2003.  You will not get any more messages from this list until
> you re-enable your membership.  You will receive 2 more reminders like
> this before your membership in the list is deleted.
> 



-- 
318 Carr Hall                                bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704


From tblackw at umich.edu  Mon Apr 14 15:56:04 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 14 Apr 2003 09:56:04 -0400 (EDT)
Subject: [R] A statistical problem.Anybody can help me?
In-Reply-To: <20030414023731.C8B7A2F8F5@mta5.x263.net>
Message-ID: <Pine.SOL.4.44.0304140939360.18818-100000@mspacman.gpcc.itd.umich.edu>


If this were my problem, I would try to separate real and imaginary
parts - write everything out in polar coordinates - and recognize
chi-squared random variables where they occur.  But that's very much
a beginner's approach.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 14 Apr 2003, comm wrote:

> Sorry for the contents not relating to R.
>
> Assume there are N i.i.d zero-mean complex gaussian random
> variables(RVs),as w(i),0<=i<N} with known variance,from which one
> can generate another N RVs,as
>
>     R(0)=sum over i {w(i)*w'(i)}
>     R(1)=sum over i {w(i+1)*w'(i)}
>     ...
> up to
> 	R(N-1)= w(N-1)w'(i)
>
> where w'(i) is the complex conjugate of w(i).
> (from viewpoint of signal processing, R(i) are serial correlation of time series w(i))
>
> If one defines a new random variable using {R(k)} as
>
> Z=a(0)R(0)+a(1)|R(1)|+...  a(N-1)|R(N-1)|,
>
> with {a(k)} are known and |.| is modulus operation.It's a decision
> statistic encountered in my work. I wish to find its approximated(using
> Central Limit Theorem) statistical characteristics in close-form.Mean and
> variance are enough.
>
> Does anybody have any ideas or references which can solve this problem?
>
> (below is my previous thoughts and now it is tested not work because RVs appear to be Rician distributed)
> Mean of Z is easy to get. However its variance is troublesome. I think it can be calculated by
>
>     Var=alpha*C*alpha',
>
> where alpha=[a(0) a(1) ... a(N-1)],C is covariance matrix of vector [R(0),|R(1)|,...,|R(N-1)|].
>
> Besides the diagonal and first row and first column, the other elements is
> small that can be ignored,which can be shown by simulations.Namely weak
> cross-correlation is hold between any two RVs of set
> {|R(1)|,|R(2)|,R(N-1)},while the crosss-correlation between R(0) and each
> RV of set {|R(1)|,|R(2)|, |R(N-1)|} and self-correlation of set
> {|R(0)|,|R(1)|,|R(N-1)|} is large and should not be ignored. The former is
> what i seek. I almost exhausted,so i came here for help.
>
> Any suggestion will be appreciated.
>
> Regards,
> Jeans Sun


From tlumley at u.washington.edu  Mon Apr 14 15:58:40 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 14 Apr 2003 06:58:40 -0700 (PDT)
Subject: [R] Peculiarity in non-central qchisq for ncp > 294.92 ...
In-Reply-To: <Pine.GHP.4.51.0304131405590.2386@raptor.csrv.uidaho.edu>
Message-ID: <Pine.A41.4.44.0304140657570.226560-100000@homer06.u.washington.edu>

On Sun, 13 Apr 2003, Andrew Robinson wrote:

> Hello all,
>
> Here's my query:
>
> Running R 1.6.2 on FreeBSD 5.0, and on WinXP, and I find that the
> following hangs the process:
>
> dchisq(alpha=0.01, df=1, ncp=295)
>
> but it does work for ncp < 294.92.
>

If you mean
   qchisq(0.01, df=1, ncp=295)
then this also happens on Mac OS X.


	-thomas


From ripley at stats.ox.ac.uk  Mon Apr 14 16:00:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 15:00:58 +0100 (BST)
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <Pine.SOL.4.44.0304140927580.18818-100000@mspacman.gpcc.itd.umich.edu>
Message-ID: <Pine.LNX.4.44.0304141456000.12108-100000@gannet.stats>

On Mon, 14 Apr 2003, Thomas W Blackwell wrote:

> I think maybe the question is, how do you import postscript format
> into an M$Word document.  I am NOT a word user, but I had to do this
> some years ago and found that it IS possible to import postscript.
> 
> You do something like "import picture ... (some kind of generic-
> sounding graphics format)", and it works fine.  The postscript
> behaves very nicely once you get it in.  You have to play around
> quite a bit, and try some very unlikely sounding possibilities to
> get it in, but it WILL work.  There are definitely some shortcomings
> in the documentation for M$Word (to put it charitably).

It just works in modern versions of Word under Windows, provided you have
a postscript printer.  Insert | Picture | From file ... and select the
file.  What does not work well is the preview, if the PS file has one
(which R ones do not).

Our secretaries were doing this (with S-PLUS figures) a decade ago, and it 
worked the same way then.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wouter.buytaert at tiscali.be  Mon Apr 14 16:07:21 2003
From: wouter.buytaert at tiscali.be (wouter buytaert)
Date: 14 Apr 2003 16:07:21 +0200
Subject: [R] factor differences in anova
In-Reply-To: <Pine.LNX.4.44.0304141441340.12108-100000@gannet.stats>
References: <Pine.LNX.4.44.0304141441340.12108-100000@gannet.stats>
Message-ID: <1050329241.2354.22.camel@BNL32.agr.kuleuven.ac.be>


Well, it is a quite specific design: we want to see if there is
influence of sample location, topography and soil horizon (depth) on the
water retention of a set of soil samples. We have water retention points
of every sample at different pF tensions, and want to compare the
complete pF-curves. As there is of course a strong relationship between
tension (pF) and water content, my PhD director proposed this type of
Error() design.

Thanks for the help!

Wouter Buytaert
PhD student
Katholieke Universiteit Leuven
Belgium



On Mon, 2003-04-14 at 15:47, Prof Brian Ripley wrote:
> On 14 Apr 2003, wouter buytaert wrote:
> 
> > Hello,
> > 
> > (maybe a quite basic statistical question, but I'm just struggling with
> > it)
> > 
> > I'm doing an anova:
> > 
> > > Res1<-aov(H2O~location+topo+horizon+pF+Error(location:topo:horizon))
> > 
> > (water retention of soils)
> > 
> > which gives a significant difference at factor "location".
> > 
> > Which function should I use to now which locations (there are 3: A, B
> > and C) differ significantly and which do not?
> 
> Possibly TukeyHSD or package multicomp.  However, we would need to know a 
> bit more about the design, as that's a rather peculiar Error() 
> specification and you would need to be careful to apply these functions in 
> the right stratum (assuming the location effect only occurs in one).
> 
> Function se.contrast would also be useful, and as there are only three
> pairwise differences, multiple comparison issues are going to be minor
> (especially as you have tested for an overall difference first).


From rdiaz at cnio.es  Mon Apr 14 16:09:58 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Mon, 14 Apr 2003 16:09:58 +0200
Subject: [R] removing NULL elements from a list
Message-ID: <200304141609.58282.rdiaz@cnio.es>

Dear All,

I have a list, where several components are NULL, and I'd like to obtain that 
very same list without the NULL components (i.e., I do not want to unlist or 
otherwise loose the rest of the list structure). I can do that with a loop, 
but how could I do it without a loop?

Thanks,

Ram?n

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://bioinfo.cnio.es/~rdiaz


From calenge at biomserv.univ-lyon1.fr  Mon Apr 14 16:16:17 2003
From: calenge at biomserv.univ-lyon1.fr (=?iso-8859-1?Q?Cl=E9ment?= Calenge)
Date: Mon, 14 Apr 2003 16:16:17 +0200
Subject: [R] categorical variables
In-Reply-To: <1050328150.3e9abc566e729@webmail.sapo.pt>
Message-ID: <5.1.0.14.0.20030414161435.00b4ac48@biomserv.univ-lyon1.fr>

At 14:49 14/04/2003 +0100, Luis Silva wrote:
>Dear helpers
>
>I constructed a data frame with this structure
>
> > str(dados1)
>`data.frame':   485 obs. of  16 variables:
>  $ Emissor         : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ Marisca.Rio     : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ Per?odo         : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ Reproducao      : int  3 3 3 3 3 3 3 3 3 3 ...
>  $ Estacao         : int  2 2 2 2 2 2 2 2 2 2 ...
>  $ X30cm           : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ Dir.mov         : int  0 0 0 0 0 0 0 0 0 0 ...
>  $ Temp.media      : num  12.0 11.3 12.1 12.3 12.4 ...
>  $ Temp.amplitude  : num   1.167 -0.750  0.875  0.125 ...
>  $ Vel.media       : num  0.479 0.514 0.517 0.445 0.468 ...
>  $ Vel.amplitude   : num  -0.04865  0.03417  0.00312 0.02364 ...
>  $ Caudal.medio    : num  0.570 0.585 0.589 0.485 0.501 ...
>  $ Caudal.amplitude: num  -0.04323  0.01449  0.00405 0.01617 ...
>  $ Prof.media      : num  36.1 34.6 34.1 32.9 32.1 ...
>  $ Prof.amplitude  : num   0.458 -1.500 -0.500 -1.250 -0.750 ...
>  $ Movimento       : num  0 0 0 0 0 0 0 0 0 0 ...
>
>My problem is that the first 7 variables are in fact
>categorical, some of them of the type Present/Absent. R is
>taking them as integer but I want categorical. How can I solve
>this problem? I searched data.frame help but I didn't found any
>parameter to set some variables to categorical



see ?factor:

for (i in 1:7) dados1[,i]<-factor(dados1[,i])

hope this helps,

Clem.


From ripley at stats.ox.ac.uk  Mon Apr 14 16:27:17 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 15:27:17 +0100 (BST)
Subject: [R] No more Windows compiled packages for R 1.6.x
Message-ID: <Pine.LNX.4.44.0304141520520.12299-100000@gannet.stats>

With R 1.7.0 imminent, no more compiled packages for rw1060/1/2 will be
produced (unless there are critical bug fixes needed).

rw1070 will look for compiled packages under different names (including
the version number) in a different area of CRAN (which is already
populated).  The intention is to build these automatically in due course, 
and if that cannot be achieved, to update them infrequently.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From carlos.ortega at minorplanet.com  Mon Apr 14 16:42:45 2003
From: carlos.ortega at minorplanet.com (Carlos Ortega)
Date: Mon, 14 Apr 2003 16:42:45 +0200
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <1050326839.1345.201.camel@gandalf.ipimar.pt>
Message-ID: <LMEKLMMLPDKOJNOOEELEKENCEBAA.carlos.ortega@minorplanet.com>

Hello,

Even if you are using a Linux box, you can save your images in png, bmp or
jpeg formats which can be uploaded into Word without any problem, well for
png you should have installed your Word with that enhancement.

If you prefer to save your image as ps, you can convert it to whatever of
the previous formats with ImageMagick (command "convert") although the
resolution is lower than if you generate the image in png, bmp or jpeg
directly.

Hope it helps,
Carlos.


-----Mensaje original-----
De: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]En nombre de Ernesto Jardim
Enviado el: lunes, 14 de abril de 2003 15:27
Para: Prof Brian Ripley
CC: Mailing List R
Asunto: Re: [R] Charts to M$Word - what's the best format


On Mon, 2003-04-14 at 13:00, Prof Brian Ripley wrote:
> On 14 Apr 2003, Ernesto Jardim wrote:
>
> > You're also assuming I'm in M$Windows, which I'm not. Anyway if I'm in
>
> How do use use bmp if you are not?  Perhaps you would be so kind as to
> tell us
>
> - What platform you are using R on?
> - What platform you are using MicroSoft Word on?
>
> and in future disclose such information in your first posting.
>

I'm using R 1.6.2 in SuSE linux box. I promise not to forget this
information in my posts anymore.

I've tried bmp in a machine with windows. Rigth now I'm in Linux and I
don't have a windows machine with me. However, as you know, I'm able to
see the bmp in linux and I can also print all these formats.

One of the major R features for me is the ability to use it in Linux or
windows without worry with platform issues. I want to produce some plots
that I can send to someone else, who uses M$Windows and M$Word (I don't
know what version).

So I made a simple question. What's the best way to export a chart from
R to be used in M$Word. The copy/paste doesn't help, but it's a good
information for a moment that I'll be working in R for windows.


> > windows that is the best way ? What about exporting with R functions
> > like png() ?
> >
> > I thought these functions would be the best way of exporting charts.
>
> You assert, but you don't explain why and you don't like the results! If a
> `chart' means a vector plot, it is pretty obvious that a vector graphics
> format is best, and that means EMF, ps, PDF or SVG in the world of R
> graphics drivers.  AFAIK Word does not support the last two.
>

I'm not asserting anything. I'm making a statement based on my
understanding and experience of R.

Open Source, as I see it, makes use of the users comments and opinions.
So if I have an opinion I'll post it, the R team is free to use it or
not. If it will contribute to a better R I'll be deligth to help,
otherwise it's just a few minutes I lose writing a message.

I'm doing simple plot() and png(), bmp() and jpeg() are producing plots
with lower resolution. You can find the files here:

http://ernesto.freezope.org/cmf/r/plot.png
http://ernesto.freezope.org/cmf/r/plot.ps

if you want to see what I mean.

> > On Mon, 2003-04-14 at 13:22, Ko-Kang Kevin Wang wrote:
> > > Try Metafile.  You can copy the graph (I'm assuming you're using Rgui)
as
> > > Metafile, then in Word, go to Edit -> Paste Special..., then paste as
> > > Enhanced Metafile.
> > >
> > > This allows you to resize the plot in Word without losing its quality.
> > >
> > > On 14 Apr 2003, Ernesto Jardim wrote:
> > >
> > > > Date: 14 Apr 2003 12:09:44 +0100
> > > > From: Ernesto Jardim <ernesto at ipimar.pt>
> > > > To: Mailing List R <r-help at stat.math.ethz.ch>
> > > > Subject: [R] Charts to M$Word - what's the best format
> > > >
> > > > Hi
> > > >
> > > > I'm exporting some graphs from R to M$Word. I used png, jpeg and bmp
and
> > > > the quality is poor when comparing with the postscript.
> > > >
> > > > What is the best way to export a chart to be included in a M$Word
file ?

Regards

EJ

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

###  This email has been checked for all known viruses by the
###  Firstnet anti-virus system - http://www.firstnet.net.uk
###  Please email fav at firstnet.net.uk for details.


_____
The information in this email is confidential and it may not be\... {{dropped}}


From fharrell at virginia.edu  Mon Apr 14 16:44:40 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon, 14 Apr 2003 10:44:40 -0400
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <Pine.LNX.4.44.0304141456000.12108-100000@gannet.stats>
References: <Pine.SOL.4.44.0304140927580.18818-100000@mspacman.gpcc.itd.umich.edu>
	<Pine.LNX.4.44.0304141456000.12108-100000@gannet.stats>
Message-ID: <20030414104440.6b6fa8ed.fharrell@virginia.edu>

On Mon, 14 Apr 2003 15:00:58 +0100 (BST)
Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On Mon, 14 Apr 2003, Thomas W Blackwell wrote:
> 
> > I think maybe the question is, how do you import postscript format
> > into an M$Word document.  I am NOT a word user, but I had to do this
> > some years ago and found that it IS possible to import postscript.
> > 
> > You do something like "import picture ... (some kind of generic-
> > sounding graphics format)", and it works fine.  The postscript
> > behaves very nicely once you get it in.  You have to play around
> > quite a bit, and try some very unlikely sounding possibilities to
> > get it in, but it WILL work.  There are definitely some shortcomings
> > in the documentation for M$Word (to put it charitably).
> 
> It just works in modern versions of Word under Windows, provided you have
> a postscript printer.  Insert | Picture | From file ... and select the
> file.  What does not work well is the preview, if the PS file has one
> (which R ones do not).
> 
> Our secretaries were doing this (with S-PLUS figures) a decade ago, and it 
> worked the same way then.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk

I have never understood why more people don't use this approach.  Even without a postscript printer it is an excellent approach; you can install Adobe Acrobat Distiller and print to non-postscript printers (same with Ghostscript).
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From mineoeli at unipa.it  Mon Apr 14 16:54:48 2003
From: mineoeli at unipa.it (Elio Mineo)
Date: Mon, 14 Apr 2003 16:54:48 +0200
Subject: [R] New package: normalp
Message-ID: <3E9ACBB8.5000706@unipa.it>

Dear All,
a new package, called normalp, is on the CRAN web site.
This package contains a collection of utilities refered to a normal of 
order p distribution, also known as General Error Distribution.
This is the content of the INDEX file:
dnormp                  Density function of a Normal of Order p 
Distribution.
estimatep               Estimation of p.
graphnp                 Plot of Normal of order p distributions.
kurtosis                Indexes of kurtosis.
lmp                     Fitted linear model with normal of order p errors.
paramp                  Estimation of location and scale parameters.
plot.lmp                Diagnostic plots for an lmp object.
plot.simul.lmp          Plots of the results of a simulation plan on a
                        linear regression model.
plot.simul.mp           Plots of the results of a simulation plan on the 
parameters
                        of a normal of order p distribution.
pnormp                  Probability Function of a Normal of Order p
                        Distribution.
qnormp                  Quantiles of a Normal of Order p Distribution.
qqnormp                 Quantile-Quantile plot for a normal of order p 
distribution.
rnormp                  Pseudo-random numbers from a Normal of Order p 
Distribution.
simul.lmp               Simulation planning for a linear regression
                        model with errors distributed as a Normal of 
Order p.
simul.mp                Simulation planning for the parameters of a 
normal of order p
                        distribution.
summary.lmp             Summarize linear model fits with normal of order 
p errors.
summary.simul.lmp       Summarize simulation results on linear 
regression model.

Any comment or suggestion is graetly appreciated.
I hope this package can be useful for the R comunity.
Greetings
Angelo M. Mineo

-- 
--------------------------------------------------------------------------
Prof. Angelo M. Mineo
Dipartimento di Scienze Statistiche e Matematiche "Silvio Vianelli"
Universit? degli Studi di Palermo
Viale delle Scienze
90128 Palermo
URL: http://dssm.unipa.it/elio
--------------------------------------------------------------------------


From mineoeli at unipa.it  Mon Apr 14 16:54:48 2003
From: mineoeli at unipa.it (Elio Mineo)
Date: Mon, 14 Apr 2003 16:54:48 +0200
Subject: [R] New package: normalp
Message-ID: <3E9ACBB8.5000706@unipa.it>

Dear All,
a new package, called normalp, is on the CRAN web site.
This package contains a collection of utilities refered to a normal of 
order p distribution, also known as General Error Distribution.
This is the content of the INDEX file:
dnormp                  Density function of a Normal of Order p 
Distribution.
estimatep               Estimation of p.
graphnp                 Plot of Normal of order p distributions.
kurtosis                Indexes of kurtosis.
lmp                     Fitted linear model with normal of order p errors.
paramp                  Estimation of location and scale parameters.
plot.lmp                Diagnostic plots for an lmp object.
plot.simul.lmp          Plots of the results of a simulation plan on a
                        linear regression model.
plot.simul.mp           Plots of the results of a simulation plan on the 
parameters
                        of a normal of order p distribution.
pnormp                  Probability Function of a Normal of Order p
                        Distribution.
qnormp                  Quantiles of a Normal of Order p Distribution.
qqnormp                 Quantile-Quantile plot for a normal of order p 
distribution.
rnormp                  Pseudo-random numbers from a Normal of Order p 
Distribution.
simul.lmp               Simulation planning for a linear regression
                        model with errors distributed as a Normal of 
Order p.
simul.mp                Simulation planning for the parameters of a 
normal of order p
                        distribution.
summary.lmp             Summarize linear model fits with normal of order 
p errors.
summary.simul.lmp       Summarize simulation results on linear 
regression model.

Any comment or suggestion is graetly appreciated.
I hope this package can be useful for the R comunity.
Greetings
Angelo M. Mineo

-- 
--------------------------------------------------------------------------
Prof. Angelo M. Mineo
Dipartimento di Scienze Statistiche e Matematiche "Silvio Vianelli"
Universit? degli Studi di Palermo
Viale delle Scienze
90128 Palermo
URL: http://dssm.unipa.it/elio
--------------------------------------------------------------------------


From spencer.graves at pdf.com  Mon Apr 14 16:57:57 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 14 Apr 2003 07:57:57 -0700
Subject: [R] categorical variables
References: <1050328150.3e9abc566e729@webmail.sapo.pt>
Message-ID: <3E9ACC75.2080204@pdf.com>

What do you want to do with the categorical variables?

summary(data.fr) or sapply(data.fr[,1:7], table) will get you started. 
glm for model fitting, etc.

Spencer Graves

Luis Silva wrote:
> Dear helpers
> 
> I constructed a data frame with this structure
> 
> 
>>str(dados1)
> 
> `data.frame':   485 obs. of  16 variables:
>  $ Emissor         : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ Marisca.Rio     : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ Per?odo         : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ Reproducao      : int  3 3 3 3 3 3 3 3 3 3 ...
>  $ Estacao         : int  2 2 2 2 2 2 2 2 2 2 ...
>  $ X30cm           : int  1 1 1 1 1 1 1 1 1 1 ...
>  $ Dir.mov         : int  0 0 0 0 0 0 0 0 0 0 ...
>  $ Temp.media      : num  12.0 11.3 12.1 12.3 12.4 ...
>  $ Temp.amplitude  : num   1.167 -0.750  0.875  0.125 ...
>  $ Vel.media       : num  0.479 0.514 0.517 0.445 0.468 ...
>  $ Vel.amplitude   : num  -0.04865  0.03417  0.00312 0.02364 ...
>  $ Caudal.medio    : num  0.570 0.585 0.589 0.485 0.501 ...
>  $ Caudal.amplitude: num  -0.04323  0.01449  0.00405 0.01617 ...
>  $ Prof.media      : num  36.1 34.6 34.1 32.9 32.1 ...
>  $ Prof.amplitude  : num   0.458 -1.500 -0.500 -1.250 -0.750 ...
>  $ Movimento       : num  0 0 0 0 0 0 0 0 0 0 ...
> 
> My problem is that the first 7 variables are in fact 
> categorical, some of them of the type Present/Absent. R is 
> taking them as integer but I want categorical. How can I solve 
> this problem? I searched data.frame help but I didn't found any 
> parameter to set some variables to categorical
> 
> 
> thank you
> luis
> --
> 
> 
> http://adsl.sapo.pt
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ligges at statistik.uni-dortmund.de  Mon Apr 14 17:04:05 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 14 Apr 2003 17:04:05 +0200
Subject: [R] removing NULL elements from a list
In-Reply-To: <200304141609.58282.rdiaz@cnio.es>
References: <200304141609.58282.rdiaz@cnio.es>
Message-ID: <3E9ACDE5.1040800@statistik.uni-dortmund.de>

Ramon Diaz wrote:
> Dear All,
> 
> I have a list, where several components are NULL, and I'd like to obtain that 
> very same list without the NULL components (i.e., I do not want to unlist or 
> otherwise loose the rest of the list structure). I can do that with a loop, 
> but how could I do it without a loop?

For a list L:
   L[!sapply(L, is.null)]

Uwe Ligges


From ripley at stats.ox.ac.uk  Mon Apr 14 17:06:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 16:06:58 +0100 (BST)
Subject: [R] removing NULL elements from a list
In-Reply-To: <200304141609.58282.rdiaz@cnio.es>
Message-ID: <Pine.LNX.4.44.0304141602490.12329-100000@gannet.stats>

somelist[!sapply(somelist, is.null)]

e.g. 

> s <- list(a=1, b=NULL, c=3, d=NULL, e=5)
> s[!sapply(s, is.null)]
$a
[1] 1

$c
[1] 3

$e
[1] 5

It you want to confuse people, try s[sapply(s, is.null)] <- NULL
which also removes the NULL components.

On Mon, 14 Apr 2003, Ramon Diaz wrote:

> I have a list, where several components are NULL, and I'd like to obtain
> that very same list without the NULL components (i.e., I do not want to
> unlist or otherwise loose the rest of the list structure). I can do that
> with a loop, but how could I do it without a loop?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From spencer.graves at pdf.com  Mon Apr 14 17:10:13 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 14 Apr 2003 08:10:13 -0700
Subject: [R] A statistical problem.Anybody can help me?
References: <Pine.SOL.4.44.0304140939360.18818-100000@mspacman.gpcc.itd.umich.edu>
Message-ID: <3E9ACF55.9000107@pdf.com>

The standard asymptotic theory would start by deriving the 
characteristic funciton of |R(i)|, then of a(i)|R(i)|, then multiplying 
together the characteristics functions.  Then invert the characteristic 
function with liberal use of Taylor's theorem.

Any good book on asymptotics and approximation theory in Statistics 
(especially Edgeworth expansions) will discuss this.  The modern theory 
of saddlepoint approximations may do something different, but I'm not 
familiar with that.

Hope this helps.

Spencer Graves

Thomas W Blackwell wrote:
> If this were my problem, I would try to separate real and imaginary
> parts - write everything out in polar coordinates - and recognize
> chi-squared random variables where they occur.  But that's very much
> a beginner's approach.
> 
> HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> On Mon, 14 Apr 2003, comm wrote:
> 
> 
>>Sorry for the contents not relating to R.
>>
>>Assume there are N i.i.d zero-mean complex gaussian random
>>variables(RVs),as w(i),0<=i<N} with known variance,from which one
>>can generate another N RVs,as
>>
>>    R(0)=sum over i {w(i)*w'(i)}
>>    R(1)=sum over i {w(i+1)*w'(i)}
>>    ...
>>up to
>>	R(N-1)= w(N-1)w'(i)
>>
>>where w'(i) is the complex conjugate of w(i).
>>(from viewpoint of signal processing, R(i) are serial correlation of time series w(i))
>>
>>If one defines a new random variable using {R(k)} as
>>
>>Z=a(0)R(0)+a(1)|R(1)|+...  a(N-1)|R(N-1)|,
>>
>>with {a(k)} are known and |.| is modulus operation.It's a decision
>>statistic encountered in my work. I wish to find its approximated(using
>>Central Limit Theorem) statistical characteristics in close-form.Mean and
>>variance are enough.
>>
>>Does anybody have any ideas or references which can solve this problem?
>>
>>(below is my previous thoughts and now it is tested not work because RVs appear to be Rician distributed)
>>Mean of Z is easy to get. However its variance is troublesome. I think it can be calculated by
>>
>>    Var=alpha*C*alpha',
>>
>>where alpha=[a(0) a(1) ... a(N-1)],C is covariance matrix of vector [R(0),|R(1)|,...,|R(N-1)|].
>>
>>Besides the diagonal and first row and first column, the other elements is
>>small that can be ignored,which can be shown by simulations.Namely weak
>>cross-correlation is hold between any two RVs of set
>>{|R(1)|,|R(2)|,R(N-1)},while the crosss-correlation between R(0) and each
>>RV of set {|R(1)|,|R(2)|, |R(N-1)|} and self-correlation of set
>>{|R(0)|,|R(1)|,|R(N-1)|} is large and should not be ignored. The former is
>>what i seek. I almost exhausted,so i came here for help.
>>
>>Any suggestion will be appreciated.
>>
>>Regards,
>>Jeans Sun
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From carlos.ortega at minorplanet.com  Mon Apr 14 17:14:48 2003
From: carlos.ortega at minorplanet.com (Carlos Ortega)
Date: Mon, 14 Apr 2003 17:14:48 +0200
Subject: [R] removing NULL elements from a list
In-Reply-To: <200304141609.58282.rdiaz@cnio.es>
Message-ID: <LMEKLMMLPDKOJNOOEELEEENDEBAA.carlos.ortega@minorplanet.com>

Hello,

Have you tried:

lapply(your_list, na.omit)

Regards,
Carlos.



-----Mensaje original-----
De: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]En nombre de Ramon Diaz
Enviado el: lunes, 14 de abril de 2003 16:10
Para: R-Help (E-mail)
Asunto: [R] removing NULL elements from a list


Dear All,

I have a list, where several components are NULL, and I'd like to obtain
that
very same list without the NULL components (i.e., I do not want to unlist or
otherwise loose the rest of the list structure). I can do that with a loop,
but how could I do it without a loop?

Thanks,

Ram?n

--
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://bioinfo.cnio.es/~rdiaz

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

###  This email has been checked for all known viruses by the
###  Firstnet anti-virus system - http://www.firstnet.net.uk
###  Please email fav at firstnet.net.uk for details.


_____
The information in this email is confidential and it may not be\... {{dropped}}


From deraco at ipsogen.com  Mon Apr 14 18:26:33 2003
From: deraco at ipsogen.com (=?iso-8859-1?Q?St=E9phane_Deraco?=)
Date: Mon, 14 Apr 2003 17:26:33 +0100
Subject: [R] isoMDS and stress
Message-ID: <000001c302a2$9fbbfa40$1a01a8c0@ipsoadmin.local>

Hi all,

I try to calculate the stress of a configuration using the formula in
the isoMDS help, but I don't have the same result than the stress
returned by isoMDS :

> library(mva)
> library(MASS)
> data(swiss)
> swiss.x <- as.matrix(swiss[,-1])
> swiss.dist <- dist(swiss.x)
> swiss.mds <- isoMDS(swiss.dist)
initial  value 2.979731 
iter   5 value 2.431486
iter  10 value 2.343353
final  value 2.338839 
Converged
> 
> delta.x <- swiss.mds$points
> delta.dist <- dist(delta.x)
>
> stress <- function(avant, apres) {
+ 	l <- length(avant)
+ 	num <- 0
+ 	denum <- 0
+ 
+ 	for (i in 1:l) {
+ 		num <- num + (avant[i] - apres[i])^2
+ 		denum <- denum + apres[i]
+ 	}
+ 
+ 	sqrt(num / denum)
+ }
> 
> swiss.mds$stress
[1] 2.338839
> stress(swiss.dist, delta.dist)
[1] 0.4196349
>


Any idea ?
Thanks

--
Stephane


From B.Rowlingson at lancaster.ac.uk  Mon Apr 14 17:26:51 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 14 Apr 2003 16:26:51 +0100
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <20030414104440.6b6fa8ed.fharrell@virginia.edu>
References: 
	<Pine.SOL.4.44.0304140927580.18818-100000@mspacman.gpcc.itd.umich.edu>
	<Pine.LNX.4.44.0304141456000.12108-100000@gannet.stats>
	<20030414104440.6b6fa8ed.fharrell@virginia.edu>
Message-ID: <3E9AD33B.2050509@lancaster.ac.uk>

Frank E Harrell Jr wrote:

> I have never understood why more people don't use this approach.
 > Even without a postscript printer it is an excellent approach;
 > you can install Adobe Acrobat Distiller and print to non-postscript
 > printers (same with Ghostscript).

  I suspect (with very little evidence) that perhaps these people have 
tried with PostScript files and failed - since they should have been 
using Encapsulated PostScript files. Forget (or not understand the 
consequences) to put 'onefile=FALSE' when creating the file and you may 
well end up with something that mucks up when included in a document.

  Many applications produce very poor EPS files, and many other 
applications have trouble importing them. Thankfully for most technical 
people R generates very good EPS files and LaTeX/dvips imports them 
flawlessly.

  Anyway, now that machines are fast and disk space cheap, why cant 
Windows users just produce bitmaps at 600dpi? :)

Baz


From lm.silva at sapo.pt  Mon Apr 14 17:31:12 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Mon, 14 Apr 2003 16:31:12 +0100 (WEST)
Subject: [R] categorical variables
In-Reply-To: <3E9ACC75.2080204@pdf.com>
References: <1050328150.3e9abc566e729@webmail.sapo.pt>
	<3E9ACC75.2080204@pdf.com>
Message-ID: <1050334272.3e9ad4409d1c4@webmail.sapo.pt>

I want to fit an rpart model (regression tree). I transformed 
those variables to factors already and it worked. The problem 
is that when I plot the tree the categorical variables came 
like Emissor=acde, that I suppose it is a code for the numbers 
1,3,4,5. I think I can force R to plot Emissor=1345 or 
something like that

luis

} What do you want to do with the categorical variables?
} 
} summary(data.fr) or sapply(data.fr[,1:7], table) will
} get you started. 
} glm for model fitting, etc.
} 
} Spencer Graves
} 
} Luis Silva wrote:
} > Dear helpers
} > 
} > I constructed a data frame with this structure
} > 
} > 
} >>str(dados1)
} > 
} > `data.frame':   485 obs. of  16 variables:
} >  $ Emissor         : int  1 1 1 1 1 1 1 1 1 1 ...
} >  $ Marisca.Rio     : int  1 1 1 1 1 1 1 1 1 1 ...
} >  $ Per?odo         : int  1 1 1 1 1 1 1 1 1 1 ...
} >  $ Reproducao      : int  3 3 3 3 3 3 3 3 3 3 ...
} >  $ Estacao         : int  2 2 2 2 2 2 2 2 2 2 ...
} >  $ X30cm           : int  1 1 1 1 1 1 1 1 1 1 ...
} >  $ Dir.mov         : int  0 0 0 0 0 0 0 0 0 0 ...
} >  $ Temp.media      : num  12.0 11.3 12.1 12.3 12.4
} ...
} >  $ Temp.amplitude  : num   1.167 -0.750  0.875 
} 0.125 ...
} >  $ Vel.media       : num  0.479 0.514 0.517 0.445
} 0.468 ...
} >  $ Vel.amplitude   : num  -0.04865  0.03417 
} 0.00312 0.02364 ...
} >  $ Caudal.medio    : num  0.570 0.585 0.589 0.485
} 0.501 ...
} >  $ Caudal.amplitude: num  -0.04323  0.01449 
} 0.00405 0.01617 ...
} >  $ Prof.media      : num  36.1 34.6 34.1 32.9 32.1
} ...
} >  $ Prof.amplitude  : num   0.458 -1.500 -0.500
} -1.250 -0.750 ...
} >  $ Movimento       : num  0 0 0 0 0 0 0 0 0 0 ...
} > 
} > My problem is that the first 7 variables are in
} fact 
} > categorical, some of them of the type
} Present/Absent. R is 
} > taking them as integer but I want categorical. How
} can I solve 
} > this problem? I searched data.frame help but I
} didn't found any 
} > parameter to set some variables to categorical
} > 
} > 
} > thank you
} > luis
} > --
} > 
} > 
} > http://adsl.sapo.pt
} > 
} > ______________________________________________
} > R-help at stat.math.ethz.ch mailing list
} >
} https://www.stat.math.ethz.ch/mailman/listinfo/r-help
} 
} 
} 

--


http://adsl.sapo.pt


From faheem at email.unc.edu  Mon Apr 14 17:38:42 2003
From: faheem at email.unc.edu (Faheem Mitha)
Date: Mon, 14 Apr 2003 11:38:42 -0400 (EDT)
Subject: [R] cannot create postscript files with trellis graphics  inside
 a function
In-Reply-To: <5.1.0.14.2.20030414080649.01e26520@mcmail.cis.mcmaster.ca>
Message-ID: <Pine.LNX.4.44.0304141136310.1580-100000@Chrestomanci>



On Mon, 14 Apr 2003, John Fox wrote:

> Lattice-graphics functions return objects rather than drawing plots as side
> effects. When you call a lattice function such as densityplot directly at
> the command plot, print is invoked implicitly and "prints" the plot. Within
> a function, you have to call print explicitly -- e.g., print(densityplot(~x)).

I see. And also print(histogram()), I presume? Thanks.

                                                          Faheem.


From p.dalgaard at biostat.ku.dk  Mon Apr 14 17:52:21 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Apr 2003 17:52:21 +0200
Subject: [R] removing NULL elements from a list
In-Reply-To: <200304141609.58282.rdiaz@cnio.es>
References: <200304141609.58282.rdiaz@cnio.es>
Message-ID: <x2el452i16.fsf@biostat.ku.dk>

Ramon Diaz <rdiaz at cnio.es> writes:

> Dear All,
> 
> I have a list, where several components are NULL, and I'd like to obtain that 
> very same list without the NULL components (i.e., I do not want to unlist or 
> otherwise loose the rest of the list structure). I can do that with a loop, 
> but how could I do it without a loop?

How about

l <- l[!lapply(l,is.null)]

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From danlinyu at yahoo.com  Mon Apr 14 18:30:27 2003
From: danlinyu at yahoo.com (Danlin Yu)
Date: Mon, 14 Apr 2003 09:30:27 -0700 (PDT)
Subject: [R] How to do the significant test on Local Moran's I
Message-ID: <20030414163027.86745.qmail@web11003.mail.yahoo.com>

Dear list:
    I've tried professor Roger Bivand's spdep package
for a while, and found it is quite useful. However,
when considering the significance test of the local
moran's index under the assumption of both normality
and randomization, I just can't get a clue from the
package's calculating results. I also read professor
Luc Anselin's 1995 LISA paper (geographical analysis),
but cannot figure out a way of using R to do the
significant test. I know I must missed something, but
just don't know what is it. Could anybody give a hand?
Any idea will be greatly appreciated.
    Dan


From ripley at stats.ox.ac.uk  Mon Apr 14 18:30:50 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 17:30:50 +0100 (BST)
Subject: [R] categorical variables
In-Reply-To: <1050334272.3e9ad4409d1c4@webmail.sapo.pt>
Message-ID: <Pine.LNX.4.44.0304141725570.13788-100000@gannet.stats>

On Mon, 14 Apr 2003, Luis Silva wrote:

> I want to fit an rpart model (regression tree). I transformed 
> those variables to factors already and it worked. The problem 
> is that when I plot the tree the categorical variables came 
> like Emissor=acde, that I suppose it is a code for the numbers 
> 1,3,4,5. I think I can force R to plot Emissor=1345 or 
> something like that

?text.rpart says

  pretty: an integer denoting the extent to which factor levels in
          split labels will be abbreviated.  A value of (0) signifies
          no abbreviation.  A `NULL', the default, signifies using
          elements of letters to represent the different factor levels. 

so the answer is right there on the help page.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Mon Apr 14 18:33:23 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 17:33:23 +0100 (BST)
Subject: [R] isoMDS and stress
In-Reply-To: <000001c302a2$9fbbfa40$1a01a8c0@ipsoadmin.local>
Message-ID: <Pine.LNX.4.44.0304141717090.13772-100000@gannet.stats>

On Mon, 14 Apr 2003, St?phane Deraco wrote:

> I try to calculate the stress of a configuration using the formula in
> the isoMDS help, 

You used a very different formula than the description on that page (which
does not contain a formula).

> but I don't have the same result than the stress
> returned by isoMDS :
> 
> > library(mva)
> > library(MASS)
> > data(swiss)
> > swiss.x <- as.matrix(swiss[,-1])
> > swiss.dist <- dist(swiss.x)
> > swiss.mds <- isoMDS(swiss.dist)
> initial  value 2.979731 
> iter   5 value 2.431486
> iter  10 value 2.343353
> final  value 2.338839 
> Converged
> > 
> > delta.x <- swiss.mds$points
> > delta.dist <- dist(delta.x)
> >
> > stress <- function(avant, apres) {
> + 	l <- length(avant)
> + 	num <- 0
> + 	denum <- 0
> + 
> + 	for (i in 1:l) {
> + 		num <- num + (avant[i] - apres[i])^2
> + 		denum <- denum + apres[i]
> + 	}
> + 
> + 	sqrt(num / denum)
> + }
> > 
> > swiss.mds$stress
> [1] 2.338839

The help page says that is a *percentage*.

> > stress(swiss.dist, delta.dist)
> [1] 0.4196349
> >
> 
> 
> Any idea ?

Use the right formula:

     However, the input distances are allowed a monotonic
     transformation.

and you haven't allowed one.  You have also forgotten to multiply by 100.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Mon Apr 14 19:07:08 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Apr 2003 19:07:08 +0200
Subject: [R] removing NULL elements from a list
In-Reply-To: <x2el452i16.fsf@biostat.ku.dk>
References: <200304141609.58282.rdiaz@cnio.es> <x2el452i16.fsf@biostat.ku.dk>
Message-ID: <x2adet2ekj.fsf@biostat.ku.dk>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> l <- l[!lapply(l,is.null)]

... sapply, of course, as Brian and Uwe said.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From mschwartz at medanalytics.com  Mon Apr 14 19:14:18 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 14 Apr 2003 12:14:18 -0500
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <20030414104440.6b6fa8ed.fharrell@virginia.edu>
Message-ID: <002701c302a9$4a1032d0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Frank E 
>Harrell Jr
>Sent: Monday, April 14, 2003 9:45 AM
>To: Prof Brian Ripley
>Cc: r-help at stat.math.ethz.ch; tblackw at umich.edu
>Subject: Re: [R] Charts to M$Word - what's the best format
>
>
>On Mon, 14 Apr 2003 15:00:58 +0100 (BST)
>Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
>> On Mon, 14 Apr 2003, Thomas W Blackwell wrote:
>> 
>> > I think maybe the question is, how do you import postscript
format 
>> > into an M$Word document.  I am NOT a word user, but I had 
>to do this 
>> > some years ago and found that it IS possible to import
postscript.
>> > 
>> > You do something like "import picture ... (some kind of generic- 
>> > sounding graphics format)", and it works fine.  The postscript 
>> > behaves very nicely once you get it in.  You have to play around 
>> > quite a bit, and try some very unlikely sounding possibilities to

>> > get it in, but it WILL work.  There are definitely some 
>shortcomings 
>> > in the documentation for M$Word (to put it charitably).
>> 
>> It just works in modern versions of Word under Windows, provided
you 
>> have a postscript printer.  Insert | Picture | From file ... and 
>> select the file.  What does not work well is the preview, if the PS

>> file has one (which R ones do not).
>> 
>> Our secretaries were doing this (with S-PLUS figures) a decade ago,

>> and it
>> worked the same way then.
>> 
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>
>I have never understood why more people don't use this 
>approach.  Even without a postscript printer it is an 
>excellent approach; you can install Adobe Acrobat Distiller 
>and print to non-postscript printers (same with Ghostscript).
>-- 
>Frank E Harrell Jr              Prof. of Biostatistics & Statistics
>Div. of Biostatistics & Epidem. Dept. of Health Evaluation 
>Sciences U. Virginia School of Medicine  
>http://hesweb1.med.virginia.edu/biostat


I think that part of the issue is how the Word (and related Office)
files will be used and by whom.  

If only by the person generating the file or immediate staff, such as
the scenario Prof. Ripley indicated, this is not a significant issue.

On the other hand, if you are going to send the file to a third party,
then there is the real challenge of the lack of portability to folks
without PS printing support and/or who don't like the lack of a PS
preview capability. At the risk of broad generalization, this is more
likely to be an issue with less technical folks and/or those who may
be in a industry business setting and may not have or may not be
comfortable with using third party or open source applications such as
GS/GSView.

For my own use, whether under Windows or Linux, I have the flexibility
of using whatever fits the task at hand, which may be PNG, PS or PDF
typically. I have GS/GSview installed under Windows, so I can go back
and forth easily. If I am printing the documents/graphics here (I use
an Oki 7400n color laser w/PS 3), then I have no other issues.

However, when I send Word or PowerPoint files with embedded graphics
to Windows based clients (which is almost all at this point), they
prefer it when I incorporate WMF graphics, which they can view and
print without using third party applications. WMF formats preserve
very reasonable quality and can be re-sized as needed, which
non-vector formats cannot be without losing image quality. They tend
to prefer this approach over using PDF files even after considering
the free availability of the Acrobat Reader. They want to be able to
open the attachment, see what they need to see, discuss it, perhaps
print it (not always) and move on. I consider this a "customer
service" requirement.

I suspect that this will change as more people become comfortable with
non-Windows platforms and open source applications, especially the
IS/IT support departments who will be "burdened" with the additional
training and support duties required by non-technical users. The
increasing adoption of OpenOffice (especially the next update version,
which will support the generation of PDF files) will also put
additional tools into the hands of mainstream Windows users and should
help broaden the options over time as companies look for ways to
reduce IS/IT costs by moving away from MS products.

Regards,

Marc Schwartz


From abunn at montana.edu  Mon Apr 14 19:24:27 2003
From: abunn at montana.edu (Andy Bunn)
Date: Mon, 14 Apr 2003 11:24:27 -0600
Subject: [R] rpart vs. randomForest
Message-ID: <000001c302aa$c57b64c0$3bf05a99@msu.montana.edu>

I think you are misunderstanding what randomForest does. It is not an
optimizer that spits the "best" tree back at you. It grows a forest of
trees (as many as you tell it to but 500 is the default). I would stick
to rpart if you are having trouble wrapping your head around
randomForest. Tree models are being used in many fields now and you
should be able to find an applied guide in you field with a little
effort.

Good luck, Andy


From andy_liaw at merck.com  Mon Apr 14 19:37:21 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 14 Apr 2003 13:37:21 -0400
Subject: [R] rpart vs. randomForest
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F9AA@usrymx25.merck.com>

One of these days I promise to write a package vignette...

As Martin said, RF uses many trees (500 by default).  The "forest" component
of the randomForest object contains all the trees, but not in a easily
readable form (because I don't see much use in "looking" at the trees except
for debugging purposes).  If you really want to see what a tree look like,
grow just one tree and look at the "forest" component.  Here are some
explanation:

For each tree: 
o  "nrnodes" is the maxinum number of nodes a tree can have.  

o  "ndbigtree" is a vector of length ntree containing the total number of
nodes in the trees.

o  "nodestatus" is a nrnodes by ntree matrix of indicators: -1 if the node
is terminal.

o  "treemap" a 3-D array, containing a two-column matrix for each tree.  The
first column indicate which node is the "left decendent" and the second
column the "right decendent".  Both are 0 if the node is terminal.

o  "bestvar" is a nrnodes by ntree matrix that indicate, for each node,
which variable is used to split that node.  0 for terminal nodes.

o  "xbestsplit" is the same as "bestvar", except it tells where to split.


One thing people should keep in mind about the "predicted" component of the
randomForest object (and the confusion matrix for the training data), as
well as "predict(rf.object)" without giving the newdata for prediction:
That prediction is based on Out-of-Bag samples, so is *NOT* the same as
usual prediction on training data.  It is closer to the out-of-sample
prediction as in, e.g., cross-validation.

AFAIK there are only empirical and anecdotal evidence on sensitivity of
performance to value of mtry.  I can say that in my own experience, fiddling
with mtry will only give at best marginal improvement.  One easy way to
answer the question for your situation is to try it yourself and see.

With MDS on proximity matrix, you probably need to be a bit careful in its
interpretation.  The proximity matrix of the training data is computed on
the *entire* training data, rather than just the out of bag portion.  Thus
the MDS plot will quite often show the different classes that look more
"separable" than they really are.  (We are thinking about a fix.  Breiman
pointed out that the difficulty is that if the proximity matrix is
calculated only on the out-of-bag data, than 1-proximity is no longer
positive definite).

HTH,
Andy

> -----Original Message-----
> From: chumpmonkey at hushmail.com [mailto:chumpmonkey at hushmail.com]
> Sent: Saturday, April 12, 2003 5:41 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] rpart vs. randomForest
> 
> 
> 
> Greetings. I'm trying to determine whether to use rpart or 
> randomForest
> for a classification tree. Has anybody tested efficacy formally? I've
> run both and the confusion matrix for rf beats rpart. I've looking at
> the rf help page and am unable to figure out how to extract the tree.
> But more than that I'm looking for a more comprehensive user's guide
> for randomForest including the benefits on using it with MDS. 
> Can anybody
> suggest a general guide? I've been finding a lot of broken links and
> cs-type of web pages rather than an end-user's guide. Also 
> people's experience
> on adjusting the mtry param would be useful. Breiman says 
> that it isn't
> too sensitive but I'm curious if anybody has had a different 
> experience
> with it. Thanks in advance and apologies if this is too general.
> 
> 
> 
> Concerned about your privacy? Follow this link to get
> FREE encrypted email: 
> 

> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


------------------------------------------------------------------------------


From fredrik.lundgren at norrkoping.mail.telia.com  Mon Apr 14 19:37:26 2003
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Mon, 14 Apr 2003 19:37:26 +0200
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <1050318584.1343.9.camel@gandalf.ipimar.pt>
References: <1050318584.1343.9.camel@gandalf.ipimar.pt>
Message-ID: <200304141937.27133.fredrik.lundgren@norrkoping.mail.telia.com>

m?ndagen den 14 april 2003 13.09 skrev Ernesto Jardim:
Hello,

As a Linux newbie I think a graphics device capable of producing the wmf 
(windows meta file) format wouldn't hurt - or is this a blasphemy in the 
Linux society?

Fredrik Lundgren

 > Hi
>
> I'm exporting some graphs from R to M$Word. I used png, jpeg and bmp and
> the quality is poor when comparing with the postscript.
>
> What is the best way to export a chart to be included in a M$Word file ?
>
> Thanks
>
> EJ
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Mon Apr 14 19:47:16 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 18:47:16 +0100 (BST)
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <200304141937.27133.fredrik.lundgren@norrkoping.mail.telia.com>
Message-ID: <Pine.LNX.4.44.0304141845560.13927-100000@gannet.stats>

On Mon, 14 Apr 2003, Fredrik Lundgren wrote:

> m?ndagen den 14 april 2003 13.09 skrev Ernesto Jardim:
> Hello,
> 
> As a Linux newbie I think a graphics device capable of producing the wmf 
> (windows meta file) format wouldn't hurt - or is this a blasphemy in the 
> Linux society?

It would be nice.  We look forward to your contributing one.

It has been on the wishlist on developer.r-project.org for a couple of 
years at least, and no one has yet volunteered.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Mon Apr 14 19:55:51 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 14 Apr 2003 19:55:51 +0200
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <200304141937.27133.fredrik.lundgren@norrkoping.mail.telia.com>
References: <1050318584.1343.9.camel@gandalf.ipimar.pt>
	<200304141937.27133.fredrik.lundgren@norrkoping.mail.telia.com>
Message-ID: <x265ph2cbc.fsf@biostat.ku.dk>

Fredrik Lundgren <fredrik.lundgren at norrkoping.mail.telia.com> writes:

> As a Linux newbie I think a graphics device capable of producing the wmf 
> (windows meta file) format wouldn't hurt - or is this a blasphemy in the 
> Linux society?

Maybe, but mainly hard work. The file format would seem to be rather
well documented here:

http://www.csn.ul.ie/~caolan/publink/libwmf/libwmf/doc/ora-wmf.html

Even so, it's still a bit of a toss up whether it works. Microsoft's
track record in writing software that behaves according to their own
documentation is not impressive...

(It is amusing though, that the same people that wouldn't think twice
about sending you a Word file will whine horribly if *you* require
*them* to install any additional software to read your files. Even
though it's free.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From rossini at blindglobe.net  Mon Apr 14 20:38:26 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 14 Apr 2003 11:38:26 -0700
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <200304141937.27133.fredrik.lundgren@norrkoping.mail.telia.com>
	(Fredrik Lundgren's message of "Mon, 14 Apr 2003 19:37:26 +0200")
References: <1050318584.1343.9.camel@gandalf.ipimar.pt>
	<200304141937.27133.fredrik.lundgren@norrkoping.mail.telia.com>
Message-ID: <87znmsx6u5.fsf@jeeves.blindglobe.net>

Fredrik Lundgren <fredrik.lundgren at norrkoping.mail.telia.com> writes:

> As a Linux newbie I think a graphics device capable of producing the wmf 
> (windows meta file) format wouldn't hurt - or is this a blasphemy in the 
> Linux society?

Not blasphemy, but difficulty to find a good library to do it right
(vector rather than bitmap'd).  Hopefully, someone will care enough to
do both, right now apparently no one does (care enough -- enough
people care a small bit).

best,
-tony

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center 
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 
CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}


From fredrik.lundgren at norrkoping.mail.telia.com  Mon Apr 14 20:41:50 2003
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Mon, 14 Apr 2003 20:41:50 +0200
Subject: [R] Charts to M$Word - what's the best format
References: <Pine.LNX.4.44.0304141845560.13927-100000@gannet.stats>
Message-ID: <001f01c302b5$86666720$2d0ffea9@oemcomputer>

No offence meant. To newbies nothing seems to be impossible for those who created the R system - but of course a little reflection reveals that even magicians can find some tricks more difficult to perform.

Fredrik
----- Original Message ----- 
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "Fredrik Lundgren" <fredrik.lundgren at norrkoping.mail.telia.com>
Cc: "Ernesto Jardim" <ernesto at ipimar.pt>; "Mailing List R" <r-help at stat.math.ethz.ch>
Sent: Monday, April 14, 2003 7:47 PM
Subject: Re: [R] Charts to M$Word - what's the best format


> On Mon, 14 Apr 2003, Fredrik Lundgren wrote:
> 
> > m?ndagen den 14 april 2003 13.09 skrev Ernesto Jardim:
> > Hello,
> > 
> > As a Linux newbie I think a graphics device capable of producing the wmf 
> > (windows meta file) format wouldn't hurt - or is this a blasphemy in the 
> > Linux society?
> 
> It would be nice.  We look forward to your contributing one.
> 
> It has been on the wishlist on developer.r-project.org for a couple of 
> years at least, and no one has yet volunteered.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From vograno at arbitrade.com  Mon Apr 14 20:57:05 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Mon, 14 Apr 2003 13:57:05 -0500
Subject: [R] removing NULL elements from a list
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DD8D@jupiter.arbitrade.com>

you can also modify the original list "in place":

l[sapply(l, is.null)] <- NULL


I don't understand why it works this way especially given that, for example,

l[sapply(l, is.null)] <- 5

simply replaces NULL elements of the list with 5. This probably has to do
with the special semantics of NULL. I'd appreciate if someone could clearify
this for me.

Thanks,
Vadim




> -----Original Message-----
> From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
> Sent: Monday, April 14, 2003 10:07 AM
> To: Peter Dalgaard BSA
> Cc: R-Help (E-mail); Ramon Diaz
> Subject: Re: [R] removing NULL elements from a list
> 
> 
> Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:
> 
> > l <- l[!lapply(l,is.null)]
> 
> ... sapply, of course, as Brian and Uwe said.
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: 
> (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: 
> (+45) 35327907
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-------------------------------------------------- 
DISCLAIMER\ This e-mail, and any attachments thereto, is intende... {{dropped}}


From Jeff.Breiwick at noaa.gov  Mon Apr 14 21:31:43 2003
From: Jeff.Breiwick at noaa.gov (Jeff Breiwick)
Date: Mon, 14 Apr 2003 12:31:43 -0700
Subject: [R] functions in a package 
In-Reply-To: <200304141108.h3EB8HAR017453@hypatia.math.ethz.ch>
Message-ID: <000001c302bc$7b1e8210$84b037a1@nmml1012breiwxp>

Below is a function that lists all packages (called without an argument) or
the functions in a package (called with the package name - quotes not
needed).

"libs"<-
function (Lib) 
{
    if (missing(Lib)) 
        print(.packages(all = TRUE), q = F)
    else eval(parse(text = paste("library(help=",
as.character(substitute(Lib)),")")))
}

-------------------------------------------
Jeffrey M Breiwick, Ph.D.
National Marine Mammal Lab., AFSC, NOAA
7600 Sand Point Way NE, Bldg. 4
Seattle, Washington 98115    USA


From pcovelli at tin.it  Mon Apr 14 22:37:30 2003
From: pcovelli at tin.it (Paolo Covelli)
Date: Mon, 14 Apr 2003 22:37:30 +0200
Subject: [R] gui - script
Message-ID: <000501c302c5$adaa7c30$410f6850@paolo>

Hi, 

is R a script language too?
In affirmative case is it possible to create a GUI - script? How?
Thank in advance.

Paolo


From rpeng at stat.ucla.edu  Mon Apr 14 23:08:16 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon, 14 Apr 2003 14:08:16 -0700 (PDT)
Subject: [R] functions in a package 
In-Reply-To: <Pine.SOL.4.33.0304131848130.20605-100000@panther.cs.ucla.edu>
Message-ID: <Pine.GSO.4.10.10304141406230.24507-100000@quetelet.stat.ucla.edu>

You might be interested in the function lsf.str(), which lists all
functions and their argument lists.  For example, 

> library(foreign)
> lsf.str("package:foreign")
data.restore : function (file, print = FALSE, verbose = FALSE, env =
.GlobalEnv)  
lookup.xport : function (file)  
read.S : function (file)  
read.dta : function (file, convert.dates = TRUE, tz = "GMT",
convert.factors = TRUE)  
read.epiinfo : function (file, read.deleted = FALSE, guess.broken.dates =
FALSE, 
    thisyear = NULL, lower.case.names = FALSE)  
read.mtp : function (file)  
read.spss : function (file, use.value.labels = TRUE, to.data.frame =
FALSE, 
    max.value.labels = Inf)  
read.ssd : function (libname, sectionnames, tmpXport = tempfile(),
tmpProgLoc = tempfile(), 
    sascmd = "sas")  
read.xport : function (file)  
write.dta : function (dataframe, file, version = 6, convert.dates = TRUE, 
    tz = "GMT", convert.factors = c("labels", "string", "numeric", 
        "codes"))  
> 


-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Sun, 13 Apr 2003, Yan Yu wrote:

> Hello,
> I have a beginner's Q:
>    if i want to know all the functions provided by a package,
> what is command for that?
> in another word,
> Is there a command to list all the commands available in a packege?
> thanks a lot,
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From ripley at stats.ox.ac.uk  Mon Apr 14 23:42:34 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 14 Apr 2003 22:42:34 +0100 (BST)
Subject: [R] removing NULL elements from a list
In-Reply-To: <AFD78192EC49D311BFAE00902798AB8F23DD8D@jupiter.arbitrade.com>
Message-ID: <Pine.LNX.4.44.0304142242110.14022-100000@gannet.stats>

On Mon, 14 Apr 2003, Vadim Ogranovich wrote:

> you can also modify the original list "in place":
> 
> l[sapply(l, is.null)] <- NULL
> 
> 
> I don't understand why it works this way especially given that, for example,
> 
> l[sapply(l, is.null)] <- 5
> 
> simply replaces NULL elements of the list with 5. This probably has to do
> with the special semantics of NULL. I'd appreciate if someone could clearify
> this for me.

It's in the FAQ.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.connolly at hortresearch.co.nz  Tue Apr 15 00:02:45 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue, 15 Apr 2003 10:02:45 +1200
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <LMEKLMMLPDKOJNOOEELEKENCEBAA.carlos.ortega@minorplanet.com>
References: <1050326839.1345.201.camel@gandalf.ipimar.pt>
	<LMEKLMMLPDKOJNOOEELEKENCEBAA.carlos.ortega@minorplanet.com>
Message-ID: <20030414220245.GL3002@hortresearch.co.nz>

On Mon, 14-Apr-2003 at 04:42PM +0200, Carlos Ortega wrote:

|> Hello,
|> 
|> Even if you are using a Linux box, you can save your images in png, bmp or
|> jpeg formats which can be uploaded into Word without any problem, well for
|> png you should have installed your Word with that enhancement.
|> 
|> If you prefer to save your image as ps, you can convert it to whatever of
|> the previous formats with ImageMagick (command "convert") although the
|> resolution is lower than if you generate the image in png, bmp or jpeg
|> directly.

I'm a little surprised that the bitmap function hasn't come up in this
discussion.  Its default res argument is too small for the purpose in
this discussion, but setting it to about 300 gives quite good results
that can be imported into Word for Windoze provided the machine has
more than 32 Meg RAM (which some people still try to work with).  The
main failing I've seen with it is that conversion of grey lines are
somewhat unsatisfactory, but colour files seem fine, with moderate
amounts of resizing possible.

If the plot is a lattice plot, I find it necessary to use a postscript
file and convert that to a png file using the Gimp with minimal
effort.  AFAIK, ImageMagick will not convert at a high enough
resolution otherwise that would be even simpler.

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


From mmiller3 at iupui.edu  Tue Apr 15 01:19:13 2003
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: 14 Apr 2003 18:19:13 -0500
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <87znmsx6u5.fsf@jeeves.blindglobe.net>
References: <1050318584.1343.9.camel@gandalf.ipimar.pt>
	<200304141937.27133.fredrik.lundgren@norrkoping.mail.telia.com>
	<87znmsx6u5.fsf@jeeves.blindglobe.net>
Message-ID: <87ptno7jm6.fsf@lumen.indyrad.iupui.edu>

>>>>> "A" == A J Rossini <rossini at blindglobe.net> writes:

    > Fredrik Lundgren
    > <fredrik.lundgren at norrkoping.mail.telia.com> writes:
    >> As a Linux newbie I think a graphics device capable of
    >> producing the wmf (windows meta file) format wouldn't hurt
    >> - or is this a blasphemy in the Linux society?

    > Not blasphemy, but difficulty to find a good library to do
    > it right (vector rather than bitmap'd).  Hopefully, someone
    > will care enough to do both, right now apparently no one
    > does (care enough -- enough people care a small bit).

I've been looking into the same issue lately.  It would be great
if there was a simple way to convert postscript to windows
metafiles, but I haven't been able to find anything.

There is a library called libemf (enhanced metafile library,
http://libemf.sourceforge.net/) that might do it - "pstoedit uses
this library for creating WMF/EMF files under non-Windows
systems."

Mike


From netreply at dciexpo.com  Tue Apr 15 01:57:18 2003
From: netreply at dciexpo.com (DCI's Event Manager)
Date: Mon, 14 Apr 2003 19:57:18 -0400
Subject: [R] Help Desk/Call Center Seminars coming to Boston!
Message-ID: <ITUUmY8EAAIrAbeJjcK00015f37@it.dciexpo.com>

Don't miss two new hands-on, in-depth action workshop seminars for Help
Desk and Call Center professionals - Delivering Maximum ROI From Your Call
Center/Help Desk and Benchmarking, Best Practices and Beyond: Training for
the Multi-Tasking Call Center & Help Desk - running consecutively in
Boston this June. Not only will you come away with the tools to maximize
your ROI with technology, but you'll have the critical training and
measurement tools to take your call center/help desk to the next level.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
SPECIAL DISCOUNT & OFFER...
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Register for both seminars and save $395 off the combined registration
fee! Attendees at the Benchmarking, Best Practices and Beyond seminar will
receive a one time only Complimentary Peer Group Benchmarking Report - a
$1500 value - comparing each individual center to their vertical market.
Know where you are today, and where you should be! Register by phone,
978-470-3880 or online, http://www.dci.com/regsysv2/page1.asp?REGID=689
Provide priority code BZJTL33 when you register or request more
information

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
SEMINAR DETAILS...
Download a brochure PDF or view details online by clicking on the links
below.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Delivering Maximum ROI From Your Call Center/Help Desk
June 18-19, 2003 ~ Boston, MA
http://www.dci.com/events/cchd

INSTRUCTED BY: Phil Grosdidier, President, and Donald J. Sutton, CEO, of
Dial Interactive.
This seminar explains the start to finish process of IVR (Interactive
Voice Response) and CTI (Computer Telephony Integration) systems, from the
purchase process, through design, through tuning up existing applications,
to the deployment of a new systems and applications.  There are practical
hands-on techniques for harvesting, defining and organizing your business
rules.  The focus of the seminar is on real-life experiences with workshop
examples providing a roadmap to success with your IVR and CTI
self-services applications.  In addition, the seminar will discuss how to
match Web self-service with IVR self-service and provide insight into the
most important uses of the information entered into the IVR.

Benchmarking, Best Practices and Beyond:
Training for the Multi-Tasking Call Center & Help Desk
June 16-17, 2003 ~ Boston, MA
http://www.dci.com/events/benchmark

INSTRUCTED BY: Rosanne D'Ausillio, Ph.D., President of Human Technologies
Global, Inc.
This seminar provides attendees the opportunity to assess where their
center is today in the area of customer service, best practices and
benchmarking.  Participants will learn what is being measured today and
why, compare their center's metrics to competition, and determine where
they are headed, what goals need defining and/or setting, and most
importantly, how to get where they want to go.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
To register or request more information:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~ Visit http://www.dciseminars.com
~ Or call 978-470-3880 (M-F, 8:00 AM ? 5:30 PM, EST)
~ Please use your priority code, BZJTL33, when you register
  or request more information

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
CAN'T ATTEND?  BRING THESE SEMINARS TO YOUR SITE!
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
DCI's on-site training and consulting brings customized knowledge to you!
On-site seminars are an extremely cost-effective and convenient way to
educate your employees with a program tailored to your specific needs,
without ever leaving the office.  To learn more about how these services
can benefit both your staff and your entire organization, call DCI's
On-site Specialist at (978) 470-3870 or visit http://www.dciseminars.com
and receive a free quote today.

-------------------------------------------------
Your email address has been provided to DCI by Dial Interactive, Inc. If
you wish to be removed from Dial Interactive's email list, send email with
"unsubscribe" as the Subject to editor at dialinteractive.com.


From rossini at blindglobe.net  Tue Apr 15 02:08:55 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 14 Apr 2003 17:08:55 -0700
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <87ptno7jm6.fsf@lumen.indyrad.iupui.edu> (mmiller3@iupui.edu's
 message of "14 Apr 2003 18:19:13 -0500")
References: <1050318584.1343.9.camel@gandalf.ipimar.pt>
	<200304141937.27133.fredrik.lundgren@norrkoping.mail.telia.com>
	<87znmsx6u5.fsf@jeeves.blindglobe.net>
	<87ptno7jm6.fsf@lumen.indyrad.iupui.edu>
Message-ID: <87ptnoei5k.fsf@jeeves.blindglobe.net>

mmiller3 at iupui.edu (Michael A. Miller) writes:

> There is a library called libemf (enhanced metafile library,
> http://libemf.sourceforge.net/) that might do it - "pstoedit uses
> this library for creating WMF/EMF files under non-Windows
> systems."

That is the one I'm thinking about as well -- it was okay last I
looked, supposedly better now, but still a bit of work.

best,
-tony

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center 
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 
CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}


From Jeff.Breiwick at noaa.gov  Mon Apr 14 21:31:43 2003
From: Jeff.Breiwick at noaa.gov (Jeff Breiwick)
Date: Mon, 14 Apr 2003 12:31:43 -0700
Subject: [R] functions in a package 
Message-ID: <200304150345.h3F3j8P4011128@smtp.ic.sunysb.edu>

Below is a function that lists all packages (called without an argument) or
the functions in a package (called with the package name - quotes not
needed).

"libs"<-
function (Lib) 
{
    if (missing(Lib)) 
        print(.packages(all = TRUE), q = F)
    else eval(parse(text = paste("library(help=",
as.character(substitute(Lib)),")")))
}

-------------------------------------------
Jeffrey M Breiwick, Ph.D.
National Marine Mammal Lab., AFSC, NOAA
7600 Sand Point Way NE, Bldg. 4
Seattle, Washington 98115    USA

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From sung-youn.kim at stonybrook.edu  Tue Apr 15 05:54:34 2003
From: sung-youn.kim at stonybrook.edu (sung-youn.kim@stonybrook.edu)
Date: Mon, 14 Apr 2003 23:54:34 -0400 (EDT)
Subject: [R] Installing RMySQL with MySQL-4.0.12 on Debian Linux
Message-ID: <200304150354.h3F3sYP4013654@smtp.ic.sunysb.edu>

Hi,

I got error messeges when I try to install RMySQL. The version of
MySQL installed on my Debian is 4.0.12. Error messages were about the
location of /include and /lib of MySQL distribution. Final error
messages were;

usr/bin/ld: cannot find -lz 


Any tips or advices?

Thanks

-- 
Sung-youn Kim
--------------
Dept. of Political Science
Stony Brook University (SUNY at Stony Brook)
Office: (631)-632-7664
Web: http://www.ic.sunysb.edu/www/stu/sungyoki


From edd at debian.org  Tue Apr 15 06:23:37 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 14 Apr 2003 23:23:37 -0500
Subject: [R] Installing RMySQL with MySQL-4.0.12 on Debian Linux
In-Reply-To: <200304150354.h3F3sYP4013654@smtp.ic.sunysb.edu>
References: <200304150354.h3F3sYP4013654@smtp.ic.sunysb.edu>
Message-ID: <20030415042336.GA9587@sonny.eddelbuettel.com>

On Mon, Apr 14, 2003 at 11:54:34PM -0400, sung-youn.kim at stonybrook.edu wrote:
> I got error messeges when I try to install RMySQL. The version of
> MySQL installed on my Debian is 4.0.12. Error messages were about the
> location of /include and /lib of MySQL distribution. Final error
> messages were;
> 
> usr/bin/ld: cannot find -lz 

That means you don't have the "development" version of zlib needed to compile
(as opposed to merely run) programs with zlib. So do

$ apt-get install zlib1g-dev

As for the prior question: You probably also need libmysqlclient-dev for
the same reason, thus 

$ apt-get install libmysqlclient-dev

Hope this helps,  Dirk

-- 
Wishful thinking can dominate much of the work of a profession for a decade,
but not indefinitely.   -- Robert Shiller, on Efficient Markets models, 2002


From david.whiting at ncl.ac.uk  Tue Apr 15 11:11:21 2003
From: david.whiting at ncl.ac.uk (david.whiting@ncl.ac.uk)
Date: Tue, 15 Apr 2003 09:11:21 +0000
Subject: [R] Analyzing Medical Data Using S-PLUS by Everitt and
	Rabe-Hasketh
In-Reply-To: <001001c30309$0f106eb0$0201a8c0@MARC>
References: <20030414131733.GH13842@192.168.57.2>
	<001001c30309$0f106eb0$0201a8c0@MARC>
Message-ID: <20030415091121.GU13842@192.168.57.2>

On Mon, Apr 14, 2003 at 11:39:52PM -0500, Marc Schwartz wrote:
> 
> Dave,
> 
> I don't know if you have received any feedback, but thought I would
> offer my thoughts.

[...]
> particular writing style.  My recommendation would be to see if your
> library might have a copy for you to review before your commit to a
> purchase. That would give you the opportunity to review it in
> comparison to the others and see if the content is sufficiently
> different to warrant a purchase.

Thanks Mark.  Good advice.  I am based full-time in Tanzania at the
moment and probably won't be able to see a copy before I buy.
Compared to your collection my book collection is still relatively
small (but growing).  

The synopsis on Amazon is not very helpful and seems to be more of a
plan for the book conceived before the it was written.  The synopsis
also says:

"The book would complement Venables and Ripley (VR). However, there is
far less about the details of S-PLUS and probably less technical
descriptions of techniques."

The first sentence is good - I have (critical) MASS - but the second
makes me nervous... Ah, I'm going to give it a go.

Thanks.

Dave

-- 
Dave Whiting
Dar es Salaam, Tanzania


From rdiaz at cnio.es  Tue Apr 15 10:25:55 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Tue, 15 Apr 2003 10:25:55 +0200
Subject: [R] removing NULL elements from a list: Thanks
In-Reply-To: <x2el452i16.fsf@biostat.ku.dk>
References: <200304141609.58282.rdiaz@cnio.es> <x2el452i16.fsf@biostat.ku.dk>
Message-ID: <200304151025.55743.rdiaz@cnio.es>

Thank you very much for the very helpful responses from D. Bates, P. Dalgaard, 
J. Holtman, D. James, U. Ligges, V. Ogranovich, C. Ortega, B. D. Ripley and 
T. Plate. 


The original question is at the end.
Most of the answers were: (A is the list, with the NULLs I want to get rid of)

A[!sapply(A, is.null)]

A[!unlist(lapply(A, is.null))]

A[sapply(A, is.null)] <- NULL ## potentially confussing, as pointed out by 
B.D. Ripley


Thanks again,

Ram?n

> Dear All,
>
> I have a list, where several components are NULL, and I'd like to obtain
> that very same list without the NULL components (i.e., I do not want to
> unlist or otherwise loose the rest of the list structure). I can do that
> with a loop, but how could I do it without a loop?

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://bioinfo.cnio.es/~rdiaz


From cypark1 at kmu.ac.kr  Tue Apr 15 10:33:14 2003
From: cypark1 at kmu.ac.kr (Cheolyong Park)
Date: Tue, 15 Apr 2003 17:33:14 +0900
Subject: [R] Fortran interface
Message-ID: <3E9BC3CA.45005459@kmu.ac.kr>

Hello!

I have some difficulty in interfacing with Fortran.

I made the dll file of fortran subroutine named "avg" and its symbol
name is "_avg at 12".
I successfully loaded the dll file via dyn.load ( is.loaded("_avg at 12").)
was TRUE).
The problem is that nether .Fortran("_avg at 12", ... ) nor .Fortran("avg",
...) could call the subroutine avg.
My understanding is that the first argument of .Fortran is the
subroutine name not the symbol name.
Is there any way to use the symbol name directly in .Fortran function?

Please give me a clue!

Cheolyong Park.


From laurent at cbs.dtu.dk  Tue Apr 15 10:35:59 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Tue, 15 Apr 2003 10:35:59 +0200
Subject: [R] speed issue with 'multcomp' ?
Message-ID: <20030415083559.GH21354843@genome.cbs.dtu.dk>

Hi,


This post could well be slightly off-topic, and addressed to the
maintainer of the package, but I's like to hear from others too.

I using the package multcomp (fresh version) with R-1.6.2. I have
contrasts matrices of size 42x43 and it takes a fair amount of
time to perform a single call to 'simtest' on my data. Anyone
with similar problems (I should snoop in the code, but sort of
short of time at the moment) ?


Thanks,


 

L.


From p.dalgaard at biostat.ku.dk  Tue Apr 15 10:38:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Apr 2003 10:38:02 +0200
Subject: [R] Analyzing Medical Data Using S-PLUS by Everitt and
	Rabe-Hasketh
In-Reply-To: <20030415091121.GU13842@192.168.57.2>
References: <20030414131733.GH13842@192.168.57.2>
	<001001c30309$0f106eb0$0201a8c0@MARC>
	<20030415091121.GU13842@192.168.57.2>
Message-ID: <x2smsk17h1.fsf@biostat.ku.dk>

david.whiting at ncl.ac.uk writes:

> The synopsis on Amazon is not very helpful and seems to be more of a
> plan for the book conceived before the it was written.  The synopsis
> also says:
> 
> "The book would complement Venables and Ripley (VR). However, there is
> far less about the details of S-PLUS and probably less technical
> descriptions of techniques."
> 
> The first sentence is good - I have (critical) MASS - but the second
> makes me nervous... Ah, I'm going to give it a go.

There's a bit more info on the Springer sites (www.springer.de and
www.springer-ny.com), including a snippet from an ISI short book
review. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From ripley at stats.ox.ac.uk  Tue Apr 15 11:07:59 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 15 Apr 2003 10:07:59 +0100 (BST)
Subject: [R] Fortran interface
In-Reply-To: <3E9BC3CA.45005459@kmu.ac.kr>
Message-ID: <Pine.LNX.4.44.0304151003500.16175-100000@gannet.stats>

This is Windows (unstated)!

It will not work anyway: the symbol is "_avg", and symbol.For does that
mapping for you.  However, the @12 is a linker instruction saying this is 
stdcall and not cdecl.

The recommended compiler etc does not do this.  Please either use it or at 
least read the documentation (in readme.packages).  We do not support
stdcall, nor do we offer support for other compiler systems.  But you 
should be able to produce cdecl linking from a Fortran Windows compiler.

On Tue, 15 Apr 2003, Cheolyong Park wrote:

> Hello!
> 
> I have some difficulty in interfacing with Fortran.
> 
> I made the dll file of fortran subroutine named "avg" and its symbol
> name is "_avg at 12".
> I successfully loaded the dll file via dyn.load ( is.loaded("_avg at 12").)
> was TRUE).
> The problem is that nether .Fortran("_avg at 12", ... ) nor .Fortran("avg",
> ...) could call the subroutine avg.
> My understanding is that the first argument of .Fortran is the
> subroutine name not the symbol name.
> Is there any way to use the symbol name directly in .Fortran function?
> 
> Please give me a clue!
> 
> Cheolyong Park.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Jan_Svatos at eurotel.cz  Tue Apr 15 11:16:04 2003
From: Jan_Svatos at eurotel.cz (Jan_Svatos@eurotel.cz)
Date: Tue, 15 Apr 2003 11:16:04 +0200
Subject: [R] References of R in use (SHORT SUMMARY)
Message-ID: <OF4A3CC198.5288315D-ONC1256D09.002C1746@eurotel.cz>


Dear R-list,

about one month back I posted here a question/idea that it would be nice to
have
some list of references of R in use plus some other "marketing" arguments
for R to promote it.

Thanks for all your responses.
I was given useful responses from Armin Roehrl, Jim Lemon, Edith Hodgen,
Ko-Kang Kevin Wang,
Charles Berry, Martin Maechler, Spencer Graves, Paul Gilbert, Adelchi
Azzalini and Matthew Wiener.
(I am sorry If I have omitted someone,but I checked the responses
thoroughly).

I think that at least three ideas in the responses are really worth futher
developing:
A response from Martin Maechler including the bash command which gives the
list of domains,
from Kevin Wang (his idea that list of domains contains lot of ISP domains
is true)
and a response from Charles Berry stating that "R-team of developers
includes many of the
heaviest hitters in statistical computing".

>From Charles Berry's response:
"(R-developers) include John Chambers (winner of the ACM award for software
design),
Brian Ripley (author of best selling books on statistical computing), and
Luke Tierney (author of LISP-STAT). The team includes many of the heaviest
hitters in statistical computing."

I would only add citation from R homepage:
"R is a language and environment for statistical computing and graphics. It
is a GNU project which is similar to the S language and environment
which was developed at Bell Laboratories (formerly AT&T, now Lucent
Technologies) by John Chambers and colleagues.
R can be considered as a different implementation of S. "


Domains list:
After download of list from R web site (saved as r_help_lists.txt),

#!/bin/sh
# following gives the domains lists, 2nd and 3rd sed substitutions get rid
off unwanted HTML tags
sed 's/.* at //;s/<\/a>//;s/)<\/em>//' r_help_lists.txt | sort | uniq >
r_help_domains.txt
# not very elegant way to obtain domains of states and com, edu,...but it
works
sed 's/\.[^\.]*$/yyyy&/;s/.*yyyy\.//'  r_help_domains.txt | sort | uniq -c
> r_help_states.txt

Resulting file r_help_states inludes 64 rows. (Note: "my" list may differ
from list by Martin Maechler).

cat r_help_states.txt

     2      ae
      1     ar
     12     at
     59     au
     11     be
      1     bo
     23     br
     37     ca
     31     ch
      1     cn
      2     co
    228     com
      1     cu
      8     cz
    100     de
     18     dk
      1     ec
    178     edu
      1     eg
     38     es
     16     fi
      1     fk
      3     fm
     47     fr
     22     gov
      3     gr
      1     hk
      1     hr
      4     hu
      1     id
      4     ie
      1     il
      3     in
      1     is
     23     it
     54     jp
      1     kg
      2     kr
      1     lb
      3     lt
      3     mil
      1     mw
      4     mx
      1     my
     40     net
     15     nl
     13     no
     19     nz
     32     org
      4     pl
     15     pt
      3     ru
      1     sa
     12     se
      3     sg
      1     si
      5     sk
      2     sn
      1     th
      2     tw
     74     uk
      4     us
      2     ve
      4     za

This list shows, among others, that R is being used at all continents....

Jan


From kwan022 at stat.auckland.ac.nz  Tue Apr 15 12:22:39 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 15 Apr 2003 22:22:39 +1200 (NZST)
Subject: [R] References of R in use (SHORT SUMMARY)
In-Reply-To: <OF4A3CC198.5288315D-ONC1256D09.002C1746@eurotel.cz>
Message-ID: <Pine.LNX.4.33.0304152219420.23637-100000@stat56.stat.auckland.ac.nz>

Hi,

On Tue, 15 Apr 2003 Jan_Svatos at eurotel.cz wrote:

> I think that at least three ideas in the responses are really worth futher
> developing:
> A response from Martin Maechler including the bash command which gives the
> list of domains,
> from Kevin Wang (his idea that list of domains contains lot of ISP domains
> is true)

I've got the list of domains from Martin, and am in the process of create 
a hopefully comprehensive list from it.  The idea is to find the name of 
the institution, its category (e.g. academic, government...etc), the 
country it is in.  I'm a bit behind my own schedule at the moment but 
hopefully it will be done in the next few weeks.

> cat r_help_states.txt
> 
>      2      ae
>       1     ar
>      12     at
>      59     au
> This list shows, among others, that R is being used at all continents....


Thanks for the list!  It will help for what I'm doing!

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From ek735 at soi.city.ac.uk  Tue Apr 15 12:06:34 2003
From: ek735 at soi.city.ac.uk (Marcus Pearce)
Date: Tue, 15 Apr 2003 11:06:34 +0100 (BST)
Subject: [R] Testing for trends 
Message-ID: <Pine.LNX.4.33.0304151104140.12616-100000@atlanta.soi.city.ac.uk>


Hello All, 

I've not been able to find Page/Jonckheere trend tests in R and was 
wondering if anyone can tell me if they exist or not. 

Thanks for your help, 
Marcus


From dmurdoch at pair.com  Tue Apr 15 12:44:14 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 15 Apr 2003 06:44:14 -0400
Subject: [R] Fortran interface
In-Reply-To: <Pine.LNX.4.44.0304151003500.16175-100000@gannet.stats>
References: <3E9BC3CA.45005459@kmu.ac.kr>
	<Pine.LNX.4.44.0304151003500.16175-100000@gannet.stats>
Message-ID: <8bon9v0k5peufl6ebmgv52nq9d0e7bspuf@4ax.com>

On Tue, 15 Apr 2003 10:07:59 +0100 (BST), you wrote:

>The recommended compiler etc does not do this.  Please either use it or at 
>least read the documentation (in readme.packages).  We do not support
>stdcall, nor do we offer support for other compiler systems.  But you 
>should be able to produce cdecl linking from a Fortran Windows compiler.

We don't support other compiler systems, but I'm putting together a
collection of user-submitted instructions about them.  It's in the
early stages, but you might find something useful there.  If not,
please submit instructions for your compiler once you work them out.

The current URL is
<http://www.stats.uwo.ca/faculty/murdoch/software/compilingDLLs>

Duncan Murdoch


From p.dalgaard at biostat.ku.dk  Tue Apr 15 14:59:10 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Apr 2003 14:59:10 +0200
Subject: [R] Re: [Rd] cran.us.r-project.org off
In-Reply-To: <3E9BFD52.6AE026D5@bank-banque-canada.ca>
References: <3E9BFD52.6AE026D5@bank-banque-canada.ca>
Message-ID: <x2brz729y9.fsf@biostat.ku.dk>

Paul Gilbert <pgilbert at bank-banque-canada.ca> writes:

> cran.us.r-project.org seems to be off line this morning.

...and with it the R CVS archive and the developers web pages.
Hopefully, someone in Wisconsin has been alerted to the fact by now.
Otherwise, I fear we'll have to postpone the planned release tomorrow.

Notice that this machine is also the physical "r-project.org"
redirecting mail to "lists.r-project.org" in Zurich. So mail adressed
to (e.g.) r-help at r-project.org is not going through, please use
... at lists.r-project.org or ... at stat.math.ethz.ch .


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From brahm at alum.mit.edu  Tue Apr 15 15:31:37 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Tue, 15 Apr 2003 09:31:37 -0400
Subject: [R] Charts to M$Word - what's the best format
References: <1050326839.1345.201.camel@gandalf.ipimar.pt>
Message-ID: <16028.2489.521594.354182@arbres1a.fmr.com>

Ernesto Jardim <ernesto at ipimar.pt> wrote:
> I'm exporting some graphs from R to M$Word. I used png, jpeg and bmp and
> the quality is poor when comparing with the postscript.

Patrick Connolly <p.connolly at hortresearch.co.nz> replied:
> I'm a little surprised that the bitmap function hasn't come up in this
> discussion.  Its default res argument is too small... conversion of grey
> lines are somewhat unsatisfactory...

My magic line for exporting graphs from R on Solaris to PowerPoint on WinNT is:
   bitmap("myfile.png", type="png16m", height=8.5, width=11, res=300)

(The type="png16m" argument may help with the grey line problem.)  Good luck.
-- 
                              -- David Brahm (brahm at alum.mit.edu)


From ramzi_feg at yahoo.fr  Tue Apr 15 15:47:30 2003
From: ramzi_feg at yahoo.fr (=?iso-8859-1?q?Ramzi=20Feghali?=)
Date: Tue, 15 Apr 2003 15:47:30 +0200 (CEST)
Subject: [R] Interface problems
Message-ID: <20030415134730.54501.qmail@web20310.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030415/64c46cb2/attachment.pl

From tlumley at u.washington.edu  Tue Apr 15 15:54:12 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 15 Apr 2003 06:54:12 -0700 (PDT)
Subject: [R] Re: [Rd] cran.us.r-project.org off
In-Reply-To: <x2brz729y9.fsf@biostat.ku.dk>
Message-ID: <Pine.A41.4.44.0304150651130.35162-100000@homer34.u.washington.edu>

On 15 Apr 2003, Peter Dalgaard BSA wrote:

> Paul Gilbert <pgilbert at bank-banque-canada.ca> writes:
>
> > cran.us.r-project.org seems to be off line this morning.
>
> ...and with it the R CVS archive and the developers web pages.
> Hopefully, someone in Wisconsin has been alerted to the fact by now.
> Otherwise, I fear we'll have to postpone the planned release tomorrow.

I called Doug Bates by phone and he had already rebooted things.  I can
now get cvs.  I don't know if everything else works.

	-thomas

Thomas Lumley			Asst. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle


From matthew_wiener at merck.com  Tue Apr 15 16:00:20 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Tue, 15 Apr 2003 10:00:20 -0400
Subject: [R] rpart vs. randomForest
Message-ID: <AEBD81486231A343B1813FE62D33522501317863@usrymx15.merck.com>

I can echo that in data I've worked with (separate from the data Andy Liaw
has worked with), fiddling with mtry doesn't make a whole lot of difference.
To the extent it makes any difference at all, the default value tends to be
near the optimum.

Matt Wiener


------------------------------------------------------------------------------


From bates at stat.wisc.edu  Tue Apr 15 16:07:52 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 15 Apr 2003 09:07:52 -0500
Subject: [R] Re: [Rd] cran.us.r-project.org off
In-Reply-To: <x2brz729y9.fsf@biostat.ku.dk>
References: <3E9BFD52.6AE026D5@bank-banque-canada.ca>
	<x2brz729y9.fsf@biostat.ku.dk>
Message-ID: <6rllybkg5j.fsf@bates4.stat.wisc.edu>

Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> writes:

> Paul Gilbert <pgilbert at bank-banque-canada.ca> writes:
> 
> > cran.us.r-project.org seems to be off line this morning.
> 
> ...and with it the R CVS archive and the developers web pages.
> Hopefully, someone in Wisconsin has been alerted to the fact by now.
> Otherwise, I fear we'll have to postpone the planned release tomorrow.
> 
> Notice that this machine is also the physical "r-project.org"
> redirecting mail to "lists.r-project.org" in Zurich. So mail adressed
> to (e.g.) r-help at r-project.org is not going through, please use
> ... at lists.r-project.org or ... at stat.math.ethz.ch .

Should be back now.


From p.dalgaard at biostat.ku.dk  Tue Apr 15 16:16:45 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Apr 2003 16:16:45 +0200
Subject: [R] Re: [Rd] cran.us.r-project.org off
In-Reply-To: <Pine.A41.4.44.0304150651130.35162-100000@homer34.u.washington.edu>
References: <Pine.A41.4.44.0304150651130.35162-100000@homer34.u.washington.edu>
Message-ID: <x24r4z26cy.fsf@biostat.ku.dk>

Thomas Lumley <tlumley at u.washington.edu> writes:

> On 15 Apr 2003, Peter Dalgaard BSA wrote:
> 
> > Paul Gilbert <pgilbert at bank-banque-canada.ca> writes:
> >
> > > cran.us.r-project.org seems to be off line this morning.
> >
> > ...and with it the R CVS archive and the developers web pages.
> > Hopefully, someone in Wisconsin has been alerted to the fact by now.
> > Otherwise, I fear we'll have to postpone the planned release tomorrow.
> 
> I called Doug Bates by phone and he had already rebooted things.  I can
> now get cvs.  I don't know if everything else works.

The web access was down for a while, other things seem to be OK. The
daily snapshot got built with a couple of glitches (a CVS conflict
over the FAQ, and apparently it couldn't fetch the Recommended
packages because of a name resolution failure).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From andy_liaw at merck.com  Tue Apr 15 16:26:21 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 15 Apr 2003 10:26:21 -0400
Subject: [R] rpart vs. randomForest
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F9BB@usrymx25.merck.com>

I just saw in the prelimenary program for JSM '03, there will be (at least)
5 talks on random forest (one from our group), two of which will address the
issue of tuning mtry, judging form the abstracts.

If I may do a bit of advertising: I was asked to organized a roundtable
luncheon at the JSM on multiple trees.  I'd welcome anyone interested in
this area to come.

Cheers,
Andy

> -----Original Message-----
> From: Wiener, Matthew [mailto:matthew_wiener at merck.com]
> Sent: Tuesday, April 15, 2003 10:00 AM
> To: r-help at stat.math.ethz.ch
> Subject: RE: [R] rpart vs. randomForest
> 
> 
> I can echo that in data I've worked with (separate from the 
> data Andy Liaw
> has worked with), fiddling with mtry doesn't make a whole lot 
> of difference.
> To the extent it makes any difference at all, the default 
> value tends to be
> near the optimum.
> 
> Matt Wiener
> 
> 
> --------------------------------------------------------------
> ----------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> --------------------------------------------------------------
> ----------------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (Whitehouse 
> Station, New Jersey, USA) that may be confidential, 
> proprietary copyrighted and/or legally privileged, and is 
> intended solely for the use of the individual or entity named 
> in this message.  If you are not the intended recipient, and 
> have received this message in error, please immediately 
> return this by e-mail and then delete it.
> 
> ==============================================================
> ================
> 

------------------------------------------------------------------------------


From martin.schmettow at bibliothek.uni-regensburg.de  Tue Apr 15 16:53:32 2003
From: martin.schmettow at bibliothek.uni-regensburg.de (Martin Schmettow)
Date: Tue, 15 Apr 2003 16:53:32 +0200
Subject: [R] graphics output produces corrupt/empty files
Message-ID: <3E9C1CEC.7010209@bibliothek.uni-regensburg.de>

Hi there.

as a newbie I figured out the basics of R but when it came to graphic 
output it was a bad surprise.
All but the X11 device do not function properly. Most of them generate 
an empty file and pdf() produces non valid output (gs and acroread as well).
Very annoying, because I have to write a report.
I got the recent stable binary rpm (v1.6.2) from CRAN on a SuSE Linux 8.1.
Any help?

CU
Martin.

-- 
Martin Schmettow
Universit?tsbibliothek Regensburg, Projekt Meta-Akad
http://www.bibliothek.uni-regensburg.de/projekte/metaakad/metaakad.htm


From pgilbert at bank-banque-canada.ca  Tue Apr 15 16:38:57 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Tue, 15 Apr 2003 10:38:57 -0400
Subject: [R] Re: [Rd] cran.us.r-project.org off
References: 
	<Pine.A41.4.44.0304150651130.35162-100000@homer34.u.washington.edu>
	<x24r4z26cy.fsf@biostat.ku.dk>
Message-ID: <3E9C1981.436AB114@bank-banque-canada.ca>

Peter Dalgaard BSA wrote:
> 
> Thomas Lumley <tlumley at u.washington.edu> writes:
> 
> > On 15 Apr 2003, Peter Dalgaard BSA wrote:
> >
> > > Paul Gilbert <pgilbert at bank-banque-canada.ca> writes:
> > >
> > > > cran.us.r-project.org seems to be off line this morning.
> > >
> > > ...and with it the R CVS archive and the developers web pages.
> > > Hopefully, someone in Wisconsin has been alerted to the fact by now.
> > > Otherwise, I fear we'll have to postpone the planned release tomorrow.
> >
> > I called Doug Bates by phone and he had already rebooted things.  I can
> > now get cvs.  I don't know if everything else works.
> 
> The web access was down for a while, other things seem to be OK. 

Web access seems to be ok now.

>The
> daily snapshot got built with a couple of glitches (a CVS conflict
> over the FAQ, and apparently it couldn't fetch the Recommended
> packages because of a name resolution failure).
> 
> --
>    O__  ---- Peter Dalgaard             Blegdamsvej 3
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From ramzi_feg at yahoo.fr  Tue Apr 15 16:40:34 2003
From: ramzi_feg at yahoo.fr (=?iso-8859-1?q?Ramzi=20Feghali?=)
Date: Tue, 15 Apr 2003 16:40:34 +0200 (CEST)
Subject: [R] ok ok 
Message-ID: <20030415144034.8410.qmail@web20308.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030415/2c138f1e/attachment.pl

From Bernhard.Pfaff at drkw.com  Tue Apr 15 17:01:32 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Tue, 15 Apr 2003 17:01:32 +0200
Subject: [R] graphics output produces corrupt/empty files
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB9004730340@ibfftce505.is.de.dresdnerkb.com>

-----Original Message-----
From: Martin Schmettow
[mailto:martin.schmettow at bibliothek.uni-regensburg.de]
Sent: 15 April 2003 16:54
To: r-help at stat.math.ethz.ch
Subject: [R] graphics output produces corrupt/empty files


Hi there.

as a newbie I figured out the basics of R but when it came to graphic 
output it was a bad surprise.
All but the X11 device do not function properly. Most of them generate 
an empty file and pdf() produces non valid output (gs and acroread as well).
Very annoying, because I have to write a report.
I got the recent stable binary rpm (v1.6.2) from CRAN on a SuSE Linux 8.1.
Any help?

CU
Martin.

-- 
Martin Schmettow
Universit?tsbibliothek Regensburg, Projekt Meta-Akad
http://www.bibliothek.uni-regensburg.de/projekte/metaakad/metaakad.htm

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


dev.off()
*********

Have you included dev.off() at the end of your graphic commands?

HTH
Bernhard






----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.
----------------------------------------------------------------------


From rvaradha at jhsph.edu  Tue Apr 15 17:07:36 2003
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Tue, 15 Apr 2003 11:07:36 -0400
Subject: [R] Simulation of Stochastic processes
Message-ID: <e13007e15ccb.e15ccbe13007@jhsph.edu>

Hi:

I was wondering whether I can find some help for computer simulation of 
stochastic processes (e.g. Brownian motion), for 
pedagogicl/instructional purposes. Any help would be appreciated.

thanks,
Ravi.


From p.dalgaard at biostat.ku.dk  Tue Apr 15 17:13:21 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 15 Apr 2003 17:13:21 +0200
Subject: [R] graphics output produces corrupt/empty files
In-Reply-To: <3E9C1CEC.7010209@bibliothek.uni-regensburg.de>
References: <3E9C1CEC.7010209@bibliothek.uni-regensburg.de>
Message-ID: <x2vfxfztda.fsf@biostat.ku.dk>

Martin Schmettow <martin.schmettow at bibliothek.uni-regensburg.de> writes:

> Hi there.
> 
> as a newbie I figured out the basics of R but when it came to graphic
> output it was a bad surprise.
> All but the X11 device do not function properly. Most of them generate
> an empty file and pdf() produces non valid output (gs and acroread as
> well).
> Very annoying, because I have to write a report.
> I got the recent stable binary rpm (v1.6.2) from CRAN on a SuSE Linux 8.1.
> Any help?

Don't forget dev.off() when you're finished plotting; the file I/O is
buffered. Or plot to X11 and use dev.copy2eps(file="foo.eps").

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From otoomet at econ.dk  Tue Apr 15 16:20:52 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Tue, 15 Apr 2003 16:20:52 +0200
Subject: [R] graphics output produces corrupt/empty files
In-Reply-To: <3E9C1CEC.7010209@bibliothek.uni-regensburg.de> (message from
	Martin Schmettow on Tue, 15 Apr 2003 16:53:32 +0200)
References: <3E9C1CEC.7010209@bibliothek.uni-regensburg.de>
Message-ID: <200304151420.h3FEKqB09021@punik.econ.au.dk>

Hi,

can you please describe what did you do exactly?  Which commands did
you use in order to redirect the output to a file?

It sound like you have forgotten to call dev.off().
Look ?dev.off

Ott

 | Date: Tue, 15 Apr 2003 16:53:32 +0200
 | From: Martin Schmettow <martin.schmettow at bibliothek.uni-regensburg.de>
 | 
 | Hi there.
 | 
 | as a newbie I figured out the basics of R but when it came to graphic 
 | output it was a bad surprise.
 | All but the X11 device do not function properly. Most of them generate 
 | an empty file and pdf() produces non valid output (gs and acroread as well).
 | Very annoying, because I have to write a report.
 | I got the recent stable binary rpm (v1.6.2) from CRAN on a SuSE Linux 8.1.
 | Any help?
 | 
 | CU
 | Martin.


From peterm at andrew.cmu.edu  Tue Apr 15 17:11:34 2003
From: peterm at andrew.cmu.edu (Peter Muhlberger)
Date: Tue, 15 Apr 2003 11:11:34 -0400
Subject: [R] Re: Charts to M$Word - what's the best format
In-Reply-To: <200304151022.h3FAEZAn022826@hypatia.math.ethz.ch>
Message-ID: <BAC19966.4B06%peterm@andrew.cmu.edu>

I'm a Mac OS X user.  Is there any way of transferring an R plot or chart to
a Mac (or UNIX) graphics program so it can be modified?

Cheers,
Peter


From ernesto at ipimar.pt  Tue Apr 15 17:15:21 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 15 Apr 2003 16:15:21 +0100
Subject: [R] graphics output produces corrupt/empty files
In-Reply-To: <3E9C1CEC.7010209@bibliothek.uni-regensburg.de>
References: <3E9C1CEC.7010209@bibliothek.uni-regensburg.de>
Message-ID: <1050419720.1484.1.camel@gandalf.ipimar.pt>

On Tue, 2003-04-15 at 15:53, Martin Schmettow wrote:
> Hi there.
> 
> as a newbie I figured out the basics of R but when it came to graphic 
> output it was a bad surprise.
> All but the X11 device do not function properly. Most of them generate 
> an empty file and pdf() produces non valid output (gs and acroread as well).
> Very annoying, because I have to write a report.
> I got the recent stable binary rpm (v1.6.2) from CRAN on a SuSE Linux 8.1.
> Any help?
> 
> CU
> Martin.

Hi

After producing your file with pdf() you have to do dev.off()

pdf("file")
plot(...)
dev.off()

Have you done it ?

Regards

EJ


From zeileis at ci.tuwien.ac.at  Tue Apr 15 17:32:10 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Tue, 15 Apr 2003 17:32:10 +0200 (CEST)
Subject: [R] Simulation of Stochastic processes
In-Reply-To: <e13007e15ccb.e15ccbe13007@jhsph.edu>
Message-ID: <Pine.LNX.3.96.1030415173035.28784B-100000@thorin.ci.tuwien.ac.at>

On Tue, 15 Apr 2003, Ravi Varadhan wrote:

> Hi:
> 
> I was wondering whether I can find some help for computer simulation of 
> stochastic processes (e.g. Brownian motion), for 
> pedagogicl/instructional purposes. Any help would be appreciated.

You could have a look at the function rwiener and rbridge in the package
e1071. To simulate a Brownian motion you could do

R> x <- rwiener()
R> plot(x)

hth,
Z

 
> thanks,
> Ravi.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From peterm at andrew.cmu.edu  Tue Apr 15 17:45:09 2003
From: peterm at andrew.cmu.edu (Peter Muhlberger)
Date: Tue, 15 Apr 2003 11:45:09 -0400
Subject: [R] 
	R capabilities:  Bayesian estimation, Covariance Structure
	Analysis
Message-ID: <BAC1A145.4B13%peterm@andrew.cmu.edu>

I'm contemplating doing Bayesian estimation in R but am wondering how
Bayesian estimation on R stacks up against BUGS.  Is R reasonably complete,
more difficult to use,...?  Anyone care to share their experience?

Also, am I right to conclude that covariance structure analysis &
confirmatory factor analysis are not available in R?  (I can't find them
with help)

Peter


From baron at psych.upenn.edu  Tue Apr 15 17:55:24 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Tue, 15 Apr 2003 11:55:24 -0400
Subject: [R] R capabilities:  Bayesian estimation, Covariance Structure
	Analysis
In-Reply-To: <BAC1A145.4B13%peterm@andrew.cmu.edu>
References: <BAC1A145.4B13%peterm@andrew.cmu.edu>
Message-ID: <20030415155524.GA9837@mail1.sas.upenn.edu>

On 04/15/03 11:45, Peter Muhlberger wrote:
>Also, am I right to conclude that covariance structure analysis &
>confirmatory factor analysis are not available in R?  (I can't find them
>with help)

I believe that the sem package does these.  In general, a lot of
things are in contributed packages, so "help" is not the way to
find out about R's ultimate capabilities.

My site (below) lets you search the packages as well as the
r-help news.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/


From tlumley at u.washington.edu  Tue Apr 15 17:57:08 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 15 Apr 2003 08:57:08 -0700 (PDT)
Subject: [R] Re: Charts to M$Word - what's the best format
In-Reply-To: <BAC19966.4B06%peterm@andrew.cmu.edu>
Message-ID: <Pine.A41.4.44.0304150847590.107924-100000@homer39.u.washington.edu>

On Tue, 15 Apr 2003, Peter Muhlberger wrote:

> I'm a Mac OS X user.  Is there any way of transferring an R plot or chart to
> a Mac (or UNIX) graphics program so it can be modified?
>

Yes. The best way depends on which graphics program you have.  If you can
edit PDF files (eg Photoshop with Acrobat) then use the pdf() driver.

The xfig() driver produces files that you can edit with the Unix Xfig
program.

If neither of these is available, you can produce png() bitmap graphs (at
least on the Darwin version of R) and edit these in most image editing
programs.


	-thomas


From bmagill at earthlink.net  Tue Apr 15 16:12:04 2003
From: bmagill at earthlink.net (Brett Magill)
Date: Tue, 15 Apr 2003 09:12:04 -0500 (CDT)
Subject: [R] Recursion Limits?
Message-ID: <3658280.1050423262767.JavaMail.nobody@kermit.psp.pas.earthlink.net>

See the code below.

First, what are recursion limits in R.  The function is stopping after 25 iterations for me.  Is this general, or localized?  Can recursion limits be changed?

Second, which is generally more efficient, recursion or looping over a function?

R 1.6.1
Windows 98

-----------------------------------------------------------
recurse<-function (n) {
   ifelse(n<50, {print(n); n=n+1; Recall(n)}, print (n) )
   }

>recurse(30)
[1] 30
[1] 31
...
...
...
[1] 50
[1] 50
>

> recurse(20)
[1] 20
[1] 21
...
...
...
[1] 44
[1] 45
Error in ifelse(n < 50, { : evaluation is nested too deeply: infinite recursion?
>


From bates at stat.wisc.edu  Tue Apr 15 18:36:49 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 15 Apr 2003 11:36:49 -0500
Subject: [R] Recursion Limits?
In-Reply-To: <3658280.1050423262767.JavaMail.nobody@kermit.psp.pas.earthlink.net>
References: <3658280.1050423262767.JavaMail.nobody@kermit.psp.pas.earthlink.net>
Message-ID: <6rfzojiuou.fsf@bates4.stat.wisc.edu>

Brett Magill <bmagill at earthlink.net> writes:

> See the code below.
> 
> First, what are recursion limits in R.  The function is stopping after 25 iterations for me.  Is this general, or localized?  Can recursion limits be changed?
> 
> Second, which is generally more efficient, recursion or looping over a function?
> 
> R 1.6.1
> Windows 98
> 
> -----------------------------------------------------------
> recurse<-function (n) {
>    ifelse(n<50, {print(n); n=n+1; Recall(n)}, print (n) )
>    }
> 
> >recurse(30)
> [1] 30
> [1] 31
> ...
> ...
> ...
> [1] 50
> [1] 50
> >
> 
> > recurse(20)
> [1] 20
> [1] 21
> ...
> ...
> ...
> [1] 44
> [1] 45
> Error in ifelse(n < 50, { : evaluation is nested too deeply: infinite recursion?

Try 

options(expressions = some_large_value)

>From the help page for options

     `expressions': sets a limit on the number of nested expressions
          that will be evaluated.  This is especially important on the
          Macintosh since stack overflow is likely if this is set too
          high.  Valid values are 25...100000 with default 500.


From plxmh at nottingham.ac.uk  Tue Apr 15 18:47:57 2003
From: plxmh at nottingham.ac.uk (Martin Hoyle)
Date: Tue, 15 Apr 2003 17:47:57 +0100
Subject: [R] GLM model simplification
Message-ID: <se9c45d8.018@ccw0m1.nottingham.ac.uk>

Hello R Users,

I have the GLMs:

model1 <- glm (response ~ explanatory * block, poisson)
model2 <- glm (response ~ explanatory + block, poisson)
anova(model1, model2, test="Chi")

and I find that the interaction is significant.
I am interested in the main effect of "explanatory". However, I am advised that model simplification should stop when a higher order term is found to be significant (here, the interaction).
I imagine that I should do;

model3 <- glm (response ~ block, poisson)
anova(model2, model3, test="Chi")

to test for the significance of the main effect of "explanatory". Am I allowed to do this, even though the interaction is significant?

Thanks for your attention,
Martin.


Martin Hoyle,
School of Life and Environmental Sciences,
University of Nottingham,
University Park,
Nottingham,
NG7 2RD,
UK
Webpage: http://myprofile.cos.com/martinhoyle


From wl at eimb.ru  Tue Apr 15 19:20:58 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Tue, 15 Apr 2003 21:20:58 +0400
Subject: [R] troubles with displaying legend on the plot
Message-ID: <2889.030415@eimb.ru>

Dear colleagues,

I have troubles while trying to display legend on the plot.

I have data.frame fr

> fr
   year  M1             M2
1  1979  58.85198     56.77303
2  1980  57.59725     55.93749
3  1981  57.32133     55.55232
4  1982  54.69320     53.10566
5  1983  56.58973     55.03811
6  1984  58.81363     56.97641
7  1985  58.35583     56.82091
8  1986  60.41842     58.45457
9  1987  58.75928     57.03679
10 1988  59.89553     58.69077
11 1989  51.03595     49.45001
12 1990  52.23915     50.96713
13 1991  46.50311     45.50370
14 1992  47.38811     46.31649
15 1993  48.58066     47.44610
16 1994  46.04452     44.82441
17 1995  46.41809     45.54565
18 1996  37.65783     36.48118
19 1997  60.16313     58.63771
20 1998  51.47550     50.43720
21 1999  52.56228     51.64243
22 2000  41.71746     40.79734
23 2001  44.71175     44.05241
24 2002  49.78033     47.91608

actually I've loaded it from MySQL database.

Now drawing this plot with the following plot.r

===8<====
op<-par(no.readonly=TRUE);

par(usr=c(1979,2002,20,90),mar=c(7, 4, 4, 2) + 0.1);

plot(fr$year,fr$M1
     ,cex=0.8
     ,type="o",ylim=c(20,90),xlim=c(1979,2002)
     ,xlab="year",ylab="M, %"
     ,pch=20
     ,xaxt="n",
     );

lines(fr$year,fr$M2);
points(fr$year,fr$M2,pch=21)
axis(1,at=c(1979:2002));

for(x in 1979:2002) {
  abline(v=x, col = "lightgray", lty = "dotted");
}
for(y in seq(20,90,10)){
  abline(h=y, col = "lightgray", lty = "dotted");
}
legend(1979,0,
       legend=c("M1","M2"),
       pch=c(20,21));

par(op);
===8<===

Legend doesn't appear.
I tried different coordinates, (1979,0), (0,0),
different colors, etc...

Nothing helps. What should I do to make the legend to appear?

I'm using R 1.6.2 for windows.
OS: Windows NT workstation 4.0.

Thank you in advance.
-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru

==========================================================================
Research Scientist                                Leninsky Prospect 33,
Space Monitoring & Ecoinformation Systems Sector, Moscow, Russia, 119071,
Institute of Ecology,                             Phone: (095) 135-9972;
Russian Academy of Sciences                       Fax: (095) 954-5534


From jerome at hivnet.ubc.ca  Tue Apr 15 19:47:07 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Tue, 15 Apr 2003 10:47:07 -0700
Subject: [R] troubles with displaying legend on the plot
In-Reply-To: <2889.030415@eimb.ru>
References: <2889.030415@eimb.ru>
Message-ID: <200304151752.KAA14265@hivnet.ubc.ca>


You have set par(usr=c(1979,2002,20,90)). The y-coordinate of your legend 
is outside this specified plotting range.

Hence, try legend(1979,50,[other options]) instead of
legend(1979,0,[other options]).

Jerome

On April 15, 2003 10:20 am, Wladimir Eremeev wrote:
> Dear colleagues,
>
> I have troubles while trying to display legend on the plot.
>
> I have data.frame fr
>
> > fr
>
>    year  M1             M2
> 1  1979  58.85198     56.77303
> 2  1980  57.59725     55.93749
> 3  1981  57.32133     55.55232
> 4  1982  54.69320     53.10566
> 5  1983  56.58973     55.03811
> 6  1984  58.81363     56.97641
> 7  1985  58.35583     56.82091
> 8  1986  60.41842     58.45457
> 9  1987  58.75928     57.03679
> 10 1988  59.89553     58.69077
> 11 1989  51.03595     49.45001
> 12 1990  52.23915     50.96713
> 13 1991  46.50311     45.50370
> 14 1992  47.38811     46.31649
> 15 1993  48.58066     47.44610
> 16 1994  46.04452     44.82441
> 17 1995  46.41809     45.54565
> 18 1996  37.65783     36.48118
> 19 1997  60.16313     58.63771
> 20 1998  51.47550     50.43720
> 21 1999  52.56228     51.64243
> 22 2000  41.71746     40.79734
> 23 2001  44.71175     44.05241
> 24 2002  49.78033     47.91608
>
> actually I've loaded it from MySQL database.
>
> Now drawing this plot with the following plot.r
>
> ===8<====
> op<-par(no.readonly=TRUE);
>
> par(usr=c(1979,2002,20,90),mar=c(7, 4, 4, 2) + 0.1);
>
> plot(fr$year,fr$M1
>      ,cex=0.8
>      ,type="o",ylim=c(20,90),xlim=c(1979,2002)
>      ,xlab="year",ylab="M, %"
>      ,pch=20
>      ,xaxt="n",
>      );
>
> lines(fr$year,fr$M2);
> points(fr$year,fr$M2,pch=21)
> axis(1,at=c(1979:2002));
>
> for(x in 1979:2002) {
>   abline(v=x, col = "lightgray", lty = "dotted");
> }
> for(y in seq(20,90,10)){
>   abline(h=y, col = "lightgray", lty = "dotted");
> }
> legend(1979,0,
>        legend=c("M1","M2"),
>        pch=c(20,21));
>
> par(op);
> ===8<===
>
> Legend doesn't appear.
> I tried different coordinates, (1979,0), (0,0),
> different colors, etc...
>
> Nothing helps. What should I do to make the legend to appear?
>
> I'm using R 1.6.2 for windows.
> OS: Windows NT workstation 4.0.
>
> Thank you in advance.


From murdoch at stats.uwo.ca  Tue Apr 15 20:06:50 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 15 Apr 2003 14:06:50 -0400
Subject: [R] Charts to M$Word - what's the best format
In-Reply-To: <87znmsx6u5.fsf@jeeves.blindglobe.net>
References: <1050318584.1343.9.camel@gandalf.ipimar.pt>
	<200304141937.27133.fredrik.lundgren@norrkoping.mail.telia.com>
	<87znmsx6u5.fsf@jeeves.blindglobe.net>
Message-ID: <b7io9vkvgqcbk1s0u3lmfknn889pjkljjg@4ax.com>

On Mon, 14 Apr 2003 11:38:26 -0700, you wrote in message
<87znmsx6u5.fsf at jeeves.blindglobe.net>:

>Fredrik Lundgren <fredrik.lundgren at norrkoping.mail.telia.com> writes:
>
>> As a Linux newbie I think a graphics device capable of producing the wmf 
>> (windows meta file) format wouldn't hurt - or is this a blasphemy in the 
>> Linux society?
>
>Not blasphemy, but difficulty to find a good library to do it right
>(vector rather than bitmap'd).  Hopefully, someone will care enough to
>do both, right now apparently no one does (care enough -- enough
>people care a small bit).

I'm not sure it's worthwhile.  I've found WMF or EMF files don't look
nearly as good as Postscript or (high resolution) bitmap formats.  The
fonts get messed up, symbols change shape in strange ways, etc.  

Of course, I've sworn off using MS Word n times (and reluctantly gone
back n-1 times).  It's good for memos and such, but not good enough
for something containing math, or that you want to look good.

Duncan Murdoch


From den.duurs at lycos.com  Tue Apr 15 20:20:24 2003
From: den.duurs at lycos.com (Remko Duursma)
Date: Tue, 15 Apr 2003 11:20:24 -0700
Subject: [R] making a dataframe out of lapply() result
Message-ID: <LCMNBELGGELHBAAA@mailcity.com>

Dear R-helpers,

i have a question on how to vectorize this problem:

i have a dataframe:

tester <- data.frame(groups=c("A","A","B","B","C","C"), one=c(1,1,2,2,3,3), two=c(6,6,7,7,8,8))

# i split it into a list
tester.L <- split(tester, tester$groups)

# And want to keep only the first item in each:
lapply(tester.L, function(x) x <- x[1,] )


How do i make a dataframe out of the last result, which looks like "tester", without looping? (i can use rbind in a for loop, but is rather slow)

thanks for your help,

Remko Duursma


____________________________________________________________
Get advanced SPAM filtering on Webmail or POP Mail ... Get Lycos Mail!


From spencer.graves at pdf.com  Tue Apr 15 20:39:22 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 15 Apr 2003 11:39:22 -0700
Subject: [R] making a dataframe out of lapply() result
References: <LCMNBELGGELHBAAA@mailcity.com>
Message-ID: <3E9C51DA.9000200@pdf.com>

 > tester <- data.frame(groups=c("A","A","B","B","C","C"), 
one=c(1,1,2,2,3,3), two=c(6,6,7,7,8,8))
 > tester.L <- split(tester, tester$groups)
 > as.data.frame(lapply(tester.L, function(x) x <- unlist(x[1,] )))
        A B C
groups 1 2 3
one    1 2 3
two    6 7 8

How's this?
Spencer Graves

Remko Duursma wrote:
> Dear R-helpers,
> 
> i have a question on how to vectorize this problem:
> 
> i have a dataframe:
> 
> tester <- data.frame(groups=c("A","A","B","B","C","C"), one=c(1,1,2,2,3,3), two=c(6,6,7,7,8,8))
> 
> # i split it into a list
> tester.L <- split(tester, tester$groups)
> 
> # And want to keep only the first item in each:
> lapply(tester.L, function(x) x <- x[1,] )
> 
> 
> How do i make a dataframe out of the last result, which looks like "tester", without looping? (i can use rbind in a for loop, but is rather slow)
> 
> thanks for your help,
> 
> Remko Duursma
> 
> 
> ____________________________________________________________
> Get advanced SPAM filtering on Webmail or POP Mail ... Get Lycos Mail!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From rpeng at stat.ucla.edu  Tue Apr 15 20:42:27 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Tue, 15 Apr 2003 11:42:27 -0700 (PDT)
Subject: [R] making a dataframe out of lapply() result
In-Reply-To: <LCMNBELGGELHBAAA@mailcity.com>
Message-ID: <Pine.GSO.4.10.10304151141300.14125-100000@quetelet.stat.ucla.edu>

You could try:

s <- lapply(tester.L, function(x) x <- x[1,] )
do.call("rbind", s)

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Tue, 15 Apr 2003, Remko Duursma wrote:

> Dear R-helpers,
> 
> i have a question on how to vectorize this problem:
> 
> i have a dataframe:
> 
> tester <- data.frame(groups=c("A","A","B","B","C","C"), one=c(1,1,2,2,3,3), two=c(6,6,7,7,8,8))
> 
> # i split it into a list
> tester.L <- split(tester, tester$groups)
> 
> # And want to keep only the first item in each:
> lapply(tester.L, function(x) x <- x[1,] )
> 
> 
> How do i make a dataframe out of the last result, which looks like
> "tester", without looping? (i can use rbind in a for loop, but is
> rather slow)
> 
> thanks for your help,
> 
> Remko Duursma
> 
> 
> ____________________________________________________________
> Get advanced SPAM filtering on Webmail or POP Mail ... Get Lycos Mail!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From york at noaa.gov  Tue Apr 15 20:44:07 2003
From: york at noaa.gov (Anne York)
Date: Tue, 15 Apr 2003 11:44:07 -0700 (PDT)
Subject: [R] Charts to M$Word - what's the best format
Message-ID: <Pine.GSO.4.05.10304151140260.28701-100000@ofis450a.akctr.noaa.gov>

I found the post by David Brahm on 20 February 2003 to be very helpful for
this problem. His suggestion was to use the bitmap() command and specify
better color depth and resolution than the default values. You must have
ghostscipt installed to take advantage of the bitmap command.

Anne
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Anne E. York
National Marine Mammal Laboratory
Seattle WA 98115-0070  USA
e-mail: anne.york at noaa.gov
Voice: +1 206-526-4039
Fax: +1 206-526-6615
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Message: 5
Date: 14 Apr 2003 12:09:44 +0100
From: Ernesto Jardim <ernesto at ipimar.pt>
Subject: [R] Charts to M$Word - what's the best format
To: Mailing List R <r-help at stat.math.ethz.ch>
Message-ID: <1050318584.1343.9.camel at gandalf.ipimar.pt>
Content-Type: text/plain

Hi

I'm exporting some graphs from R to M$Word. I used png, jpeg and bmp and
the quality is poor when comparing with the postscript.

What is the best way to export a chart to be included in a M$Word file ?

Thanks

EJ


From sundar.dorai-raj at pdf.com  Tue Apr 15 20:57:35 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 15 Apr 2003 13:57:35 -0500
Subject: [R] making a dataframe out of lapply() result
References: <LCMNBELGGELHBAAA@mailcity.com>
Message-ID: <3E9C561F.6070406@pdf.com>



Remko Duursma wrote:
> Dear R-helpers,
> 
> i have a question on how to vectorize this problem:
> 
> i have a dataframe:
> 
> tester <- data.frame(groups=c("A","A","B","B","C","C"), one=c(1,1,2,2,3,3), two=c(6,6,7,7,8,8))
> 
> # i split it into a list
> tester.L <- split(tester, tester$groups)
> 
> # And want to keep only the first item in each:
> lapply(tester.L, function(x) x <- x[1,] )
> 
> 
> How do i make a dataframe out of the last result, which looks like "tester", without looping? (i can use rbind in a for loop, but is rather slow)
> 


If you're always trying to get the unique rows, then just use unique():

 > tester
   groups one two
1      A   1   6
2      A   1   6
3      B   2   7
4      B   2   7
5      C   3   8
6      C   3   8
 > unique(tester)
   groups one two
1      A   1   6
3      B   2   7
5      C   3   8

Or use do.call("rbind", ...)

 > do.call("rbind", lapply(split(tester, tester$group),
+  function(x) x[1, ]))
   groups one two
A      1   1   6
B      2   2   7
C      3   3   8
 >

Or just for fun:

 > tester[which(!duplicated(tester$groups)), ]
   groups one two
1      A   1   6
3      B   2   7
5      C   3   8


Regards,
Sundar


From ocbruno at netscape.net  Tue Apr 15 21:03:17 2003
From: ocbruno at netscape.net (ocbruno@netscape.net)
Date: Tue, 15 Apr 2003 15:03:17 -0400
Subject: [R] About kruskal.test
Message-ID: <305DDED6.4CB2023F.00206454@netscape.net>

Hi,

I'm newbie in R package,
but i'm extremely gratefull for these list! 

is there possible to make kruskal.test
summarize the sum of ranks??
e.g 
#####
z<-c(1.2,3.4,0,0,0,0,0)
ranks(z) # like in octave package
ans=
6 7 3 3 3 3 3
sum(ranks(z))
ans= 28
###
then apply multiple comparisions for many other data
SE<-sqrt(n*(n*k)*(n*k+1)/12) # according Zar,JH. Bioestatistical
                             # Analysis sec.12.6, on pg. 199 
Thanks for any helps
Marcelo A. BRUNO
--# Oceanographer            #
--# FURG - Dpto.Oceanografia #
--# CP 474 - RIO GRANDE - RS #
--# CEP 96.200-000 BRAZIL    #
##############################


From kwan022 at stat.auckland.ac.nz  Tue Apr 15 23:07:15 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 16 Apr 2003 09:07:15 +1200 (NZST)
Subject: [R] Re: Charts to M$Word - what's the best format
In-Reply-To: <BAC19966.4B06%peterm@andrew.cmu.edu>
Message-ID: <Pine.LNX.4.33.0304160906140.26971-100000@stat56.stat.auckland.ac.nz>

If on Unix (I don't know about Mac) I'd export the graph as an xfig 
picture, then edit it in xfig, then from xfig export it out to other 
formats.  Take a look at :
  ?xfig

On Tue, 15 Apr 2003, Peter Muhlberger wrote:

> Date: Tue, 15 Apr 2003 11:11:34 -0400
> From: Peter Muhlberger <peterm at andrew.cmu.edu>
> To: r-help at stat.math.ethz.ch
> Subject: [R] Re: Charts to M$Word - what's the best format
> 
> I'm a Mac OS X user.  Is there any way of transferring an R plot or chart to
> a Mac (or UNIX) graphics program so it can be modified?
> 
> Cheers,
> Peter
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From d.scott at auckland.ac.nz  Tue Apr 15 23:36:34 2003
From: d.scott at auckland.ac.nz (David Scott)
Date: Wed, 16 Apr 2003 09:36:34 +1200 (NZST)
Subject: [R] ok ok 
In-Reply-To: <20030415144034.8410.qmail@web20308.mail.yahoo.com>
Message-ID: <Pine.LNX.4.33.0304160935250.1900-100000@localhost.localdomain>

On Tue, 15 Apr 2003, Ramzi Feghali wrote:

> ok ok sorry i will do my punishment and read all the manuals of Rcheers
> 

Punishment???

They are the favourite bedtime reading of all true R-helpers :-)

David Scott


_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
		The University of Auckland, PB 92019
		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz


From wolski at molgen.mpg.de  Tue Apr 15 23:50:40 2003
From: wolski at molgen.mpg.de (Eryk Wolski)
Date: Tue, 15 Apr 2003 23:50:40 +0200 (MET DST)
Subject: [R] Building R package.
Message-ID: <Pine.OSF.4.31.0304152336530.18887-101000@molgix.molgen.mpg.de>

Hi!
I am trying to build a package which calls an c function. It compiles
it and installs it. But if i run R CMD check test_

the last output are:

* checking examples ... ERROR
Running examples failed. x<-1:10


and in the test-Ex.out file i find:
> test(x)
Error in .C("mytest", as.double(x), as.integer(lengthx)) :
        C/Fortran function name not in load table Execution halte



May anyone take a look on this test please?


system  "Linux"  "2.4.19-16mdk"
R version 1.62


Eryk

From bates at stat.wisc.edu  Wed Apr 16 00:03:42 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 15 Apr 2003 17:03:42 -0500
Subject: [R] Building R package.
In-Reply-To: <Pine.OSF.4.31.0304152336530.18887-101000@molgix.molgen.mpg.de>
References: <Pine.OSF.4.31.0304152336530.18887-101000@molgix.molgen.mpg.de>
Message-ID: <6ru1czfmf5.fsf@bates4.stat.wisc.edu>

Eryk Wolski <wolski at molgen.mpg.de> writes:

> Hi!
> I am trying to build a package which calls an c function. It compiles
> it and installs it. But if i run R CMD check test_
> 
> the last output are:
> 
> * checking examples ... ERROR
> Running examples failed. x<-1:10
> 
> 
> and in the test-Ex.out file i find:
> > test(x)
> Error in .C("mytest", as.double(x), as.integer(lengthx)) :
>         C/Fortran function name not in load table Execution halte
> 
> 
> 
> May anyone take a look on this test please?
> 
> 
> system  "Linux"  "2.4.19-16mdk"
> R version 1.62

You probably haven't called library.dynam in a .First.lib function as
described in the "Package subdirectories" section of "Writing R
Extensions"

  "If necessary, one of these files (historically `zzz.R') should use
  `library.dynam()' _inside_ `.First.lib()' to load compiled code."

The typical contents of the file R/zzz.R in a package source directory
are

.First.lib <- function(lib, pkg) {
    library.dynam(pkg, pkg, lib)
}


From wolski at molgen.mpg.de  Wed Apr 16 00:23:14 2003
From: wolski at molgen.mpg.de (Eryk Wolski)
Date: Wed, 16 Apr 2003 00:23:14 +0200 (MET DST)
Subject: [R] Building R packag. Thanks a lot.
Message-ID: <Pine.OSF.4.31.0304160020510.6507-100000@molgix.molgen.mpg.de>


Thanks a lot for fast help!

good night.

zzz.R


From SuzieBlatt at netscape.net  Wed Apr 16 00:32:44 2003
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Tue, 15 Apr 2003 18:32:44 -0400
Subject: [R] Summarizing levels for future commands
Message-ID: <600FA73C.18018676.0D1322AF@netscape.net>


Hi.  This will hopefully be readily understood but if not, bear with me.

I have to do a repeated analysis (in spatstat) and want to batch file it.  For each of my 'runs' certain variables change.  At present I am manually specifying these changes and want to automate it if possible.

Ok, I am creating an object which is comprised of 'levels' that are 'characters'.  Further in my program I need to select one of these 'levels' as the comparison to the others.  The one I want to select is the most frequent and then compare it to the second most frequent.  Is there anyway to get R to determine the most frequency of 'levels' in an object and then use a specific one in future functions?  I couldn't find it in my search through the manual or the r-help archives.

I hope what I am attempting to do is clear, let me know if it isn't.
Thanks,
Suzanne


From dirkvandyck at belgacom.net  Wed Apr 16 02:01:14 2003
From: dirkvandyck at belgacom.net (Van Dyck Dirk)
Date: Wed, 16 Apr 2003 02:01:14 +0200
Subject: [R] R 1.6.2 on Mac OSN1-8.1
Message-ID: <007801c303ab$56629ca0$5ab3043e@mshome.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030416/715567a1/attachment.pl

From dirkvandyck at belgacom.net  Wed Apr 16 02:24:17 2003
From: dirkvandyck at belgacom.net (Van Dyck Dirk)
Date: Wed, 16 Apr 2003 02:24:17 +0200
Subject: [R] Re: R 1.6.2 on Mac OSN1-8.1
Message-ID: <008301c303ae$8861a7c0$5ab3043e@mshome.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030416/7b26fbcc/attachment.pl

From john.maindonald at anu.edu.au  Wed Apr 16 02:52:29 2003
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Wed, 16 Apr 2003 10:52:29 +1000
Subject: [R] princomp with not non-negative definite correlation
In-Reply-To: <200304151014.h3FAEZAR022826@hypatia.math.ethz.ch>
Message-ID: <B344185E-6FA5-11D7-97F5-000393073F7A@anu.edu.au>


On Tuesday, April 15, 2003, at 08:14  PM,  tlumley at u.washington.edu 
wrote:

> On Thu, 10 Apr 2003 tvr at stanford.edu wrote:
>
>> $ R --version
>> R 1.6.1 (2002-11-01).
>>
>> So I would like to perform principal components analysis on a 16X16
>> correlation matrix, [princomp(cov.mat=x) where x is correlation 
>> matrix],
>> the problem is princomp complains that it is not non-negative 
>> definite.
>>
>> I called eigen() on the correlation matrix and found that one of the
>> eigenvectors is close to zero & negative (-0.001832311). Is there any
>> way to work around this problem. A constraint: I only have the
>> correlation matrix, not the data that produced it.
>
> If you are confident the problem is due to rounding (or perhaps to 
> small
> amounts of missing data) you could set the smallest eigenvalue to zero.
>
> However, in revising an introductory biostatistics text recently I have
> found two correlation matrices with negative eigenvalues, both of which
> were actually data entry errors.

Of course, if the covariance matrix has been created using cov() with
use="pairwise.complete.obs", or there has been the equivalent of this
in another program, then it is perfectly possible to have a covariance
matrix with negative eigenvalues.

Inspection of the eigenvector that corresponds to the negative 
eigenvalue
will in any case identify the (near?) dependency that is responsible.
The same information can be obtained directly using alias(lm(y~X))
where X is the matrix from which the covariance matrix was formed and
the values in y are immaterial, providing only none are missing & it is
the right length.  But, if there are missing values & you had used cov()
with the pairwise setting, you might be unlucky and find that  omission 
of
rows that have any missing values gives an X which appears to be
positive definite!

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Bioinformation Science, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


From faheem at email.unc.edu  Wed Apr 16 04:50:43 2003
From: faheem at email.unc.edu (Faheem Mitha)
Date: Tue, 15 Apr 2003 22:50:43 -0400 (EDT)
Subject: [R] trying to plot function using curve
Message-ID: <Pine.LNX.4.44.0304152231130.13178-100000@Chrestomanci>


Dear People,

I hope someone can help me with this. I have a function (density) which I
am trying to plot using curve. I am calling mg.hist(3,2,1), and getting
the following errors.

Error in xy.coords(x, y, xlabel, ylabel, log) :
	x and y lengths differ
In addition: There were 50 or more warnings (use warnings() to see the
first 50)
> warnings()
1: longer object length
	is not a multiple of shorter object length in: x * y

and more of the same.

I'm not sure where the problem is. I assume it has something to do with me
incorrectly vectorising my functions(s). However, it seems to me that
density() is vectorised.

By the way, if anyone would like to suggest a better way to plot density
plots, please let me know. curve() was suggested to me, which is why I am
using it. Actually, I want to plot a density curve on top of a histogram.
I was thinking of trying to use trellis graphics for this, but I'm not
sure it has any advantages for this purpose.

                                                     Faheem.

***********************************************************************

mg.hist <- function(len,theta,pos)
{
  postscript(file="plot.ps", horizontal = FALSE, onefile = FALSE, paper
             = "special", width=6, height=4)

  densityfn <- function(x)
    {
      density(x,theta,pos,len)
    }
  curve(densityfn)
  dev.off()
 }

density <- function(x,theta,pos,len)
  {
    if((len !=2) && (len !=3))
      stop("length must be 2 or 3")
    if((pos < 1) || (pos > len))
      stop("pos must be between 0 and len-1")

    if(len==2)
      {
        if((pos==1) || (pos==2) )
          {
            unnorm <- function(x)
              {
                ifelse(x==0,2*theta,(exp(theta*x)-exp(-theta*x))/x)
              }
            return(unnorm(x)/
                   integrate(unnorm,lower = -theta, upper = theta,
                             subdivisions=1000)$value)
          }

      }

    if(len==3)
      {
        if((pos==1) || (pos==3))
          {
            unnorm1 <- function(y) ##here y is 2-dim
              {
                ifelse(y[2] == 0,2*theta,
                       (1/y[2])*(exp(y[1]*y[2] + y[2]*theta)
                                 - exp(y[1]*y[2] - y[2]*theta)))
              }
            unnorm2 <- function(y)
              {
                ## return(unnorm1(c(x,y)))  ##here y is 1-dim
                ifelse(y == 0,2*theta,
                       (1/y)*(exp(x*y + y*theta)
                              - exp(x*y - y*theta)))
              }
          }
        return(integrate(unnorm2, lower=-theta, upper=theta,

subdivisions=1000)$value/adapt(ndim=2,lower=c(-theta, -theta),
                           upper=c(theta, theta), functn=unnorm1)$value)
      }

    if(pos==2)
      {
        unnorm <- function(x)
          {
            ifelse(x==0,4,(exp(2*theta*x)+exp(-2*theta*x) - 2)/(x^2))
          }
        return(integrate(unnorm,lower = -theta, upper = x,
                         subdivisions=1000)$value/
               integrate(unnorm,lower = -theta, upper = theta,
                         subdivisions=1000)$value)
      }
  }


From bates at stat.wisc.edu  Wed Apr 16 04:57:35 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 15 Apr 2003 21:57:35 -0500
Subject: [R] Summarizing levels for future commands
In-Reply-To: <600FA73C.18018676.0D1322AF@netscape.net>
References: <600FA73C.18018676.0D1322AF@netscape.net>
Message-ID: <6rllybtahs.fsf@bates4.stat.wisc.edu>

SuzieBlatt at netscape.net (Suzanne E. Blatt) writes:

> Hi.  This will hopefully be readily understood but if not, bear with me.
> 
> I have to do a repeated analysis (in spatstat) and want to batch file it.  For each of my 'runs' certain variables change.  At present I am manually specifying these changes and want to automate it if possible.
> 
> Ok, I am creating an object which is comprised of 'levels' that are 'characters'.  Further in my program I need to select one of these 'levels' as the comparison to the others.  The one I want to select is the most frequent and then compare it to the second most frequent.  Is there anyway to get R to determine the most frequency of 'levels' in an object and then use a specific one in future functions?  I couldn't find it in my search through the manual or the r-help archives.
> 
> I hope what I am attempting to do is clear, let me know if it isn't.

I think I know what you want to do but I'm not sure.  I believe you
want to find the mode, or the "most popular" level.  For example, in
the following sample of size 50 from the values 1:10

> samp = sample(1:10, 50, replace = TRUE)
> table(samp)
samp
 1  2  3  4  5  6  7  8  9 10 
 5  3  7  3  4  2  8  9  3  6 

the most popular value is 8.

As you can see, the table function tells you the frequencies of the
values.  From that it is just a matter of extracting the index of the
value with the maximum count and getting the label.

> names(tbl)[match(max(tbl), tbl)]
[1] "8"

Hope this helps.


From thuja at silvae.cfr.washington.edu  Wed Apr 16 05:13:36 2003
From: thuja at silvae.cfr.washington.edu (Kevin Ceder)
Date: Tue, 15 Apr 2003 20:13:36 -0700 (PDT)
Subject: [R] Scaling points in legends
Message-ID: <Pine.LNX.4.44.0304152001200.9625-100000@silvae.cfr.washington.edu>

I need to scale points in a legend of a graph.  The cex argument in the 
legend functions scales the whole legend, not just the point.  Here's the 
solution I came up with:

Add argument cex.point=1 to the legend function ( line 13250 of base, R 
version 1.6.2 ) then change cex=cex argument where points2 is called at 
line 13416 to cex=cex.point.

This allows me to scale the point on my machine but the script won't be 
usable to others unless the modify their copy of base.  Any ideas for a 
'cleaner' or more portable fix?

Cheers,

Kevin Ceder

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Forest Technology Specialist
Rural Technology Initiative
University of Washington
thuja at u.washington.edu
206.543.0827


From ahmlatif at yahoo.com  Wed Apr 16 07:10:28 2003
From: ahmlatif at yahoo.com (Mahbub Latif)
Date: Tue, 15 Apr 2003 22:10:28 -0700 (PDT)
Subject: [R] making a dataframe out of lapply() result
In-Reply-To: <LCMNBELGGELHBAAA@mailcity.com>
Message-ID: <20030416051028.18549.qmail@web41207.mail.yahoo.com>

you can try this,...
data.frame(t(sapply(tester.L, function(x) x <- x[1,]
)))

Mahbub.

--- Remko Duursma <den.duurs at lycos.com> wrote:
> Dear R-helpers,
> 
> i have a question on how to vectorize this problem:
> 
> i have a dataframe:
> 
> tester <-
> data.frame(groups=c("A","A","B","B","C","C"),
> one=c(1,1,2,2,3,3), two=c(6,6,7,7,8,8))
> 
> # i split it into a list
> tester.L <- split(tester, tester$groups)
> 
> # And want to keep only the first item in each:
> lapply(tester.L, function(x) x <- x[1,] )
> 
> 
> How do i make a dataframe out of the last result,
> which looks like "tester", without looping? (i can
> use rbind in a for loop, but is rather slow)
> 
> thanks for your help,
> 
> Remko Duursma
> 
> 
>
____________________________________________________________
> Get advanced SPAM filtering on Webmail or POP Mail
> ... Get Lycos Mail!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
>
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


__________________________________________________

The New Yahoo! Search - Faster. Easier. Bingo


From marwan.khawaja at aub.edu.lb  Wed Apr 16 18:41:07 2003
From: marwan.khawaja at aub.edu.lb (Marwan Khawaja)
Date: Wed, 16 Apr 2003 09:41:07 -0700
Subject: [R] barplot2
Message-ID: <CLECJBOEBGOMOKJHJNDAEEJBCOAA.marwan.khawaja@aub.edu.lb>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030416/a2798a55/attachment.pl

From ligges at statistik.uni-dortmund.de  Wed Apr 16 08:47:38 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 16 Apr 2003 08:47:38 +0200
Subject: [R] About kruskal.test
In-Reply-To: <305DDED6.4CB2023F.00206454@netscape.net>
References: <305DDED6.4CB2023F.00206454@netscape.net>
Message-ID: <3E9CFC8A.3070800@statistik.uni-dortmund.de>

ocbruno at netscape.net wrote:
> Hi,
> 
> I'm newbie in R package,
> but i'm extremely gratefull for these list! 
> 
> is there possible to make kruskal.test
> summarize the sum of ranks??
> e.g 
> #####
> z<-c(1.2,3.4,0,0,0,0,0)
> ranks(z) # like in octave package

rank() # like in R ;-)

Uwe Ligges

> ans=
> 6 7 3 3 3 3 3
> sum(ranks(z))
> ans= 28
> ###
> then apply multiple comparisions for many other data
> SE<-sqrt(n*(n*k)*(n*k+1)/12) # according Zar,JH. Bioestatistical
>                              # Analysis sec.12.6, on pg. 199 
> Thanks for any helps
> Marcelo A. BRUNO
> --# Oceanographer            #
> --# FURG - Dpto.Oceanografia #
> --# CP 474 - RIO GRANDE - RS #
> --# CEP 96.200-000 BRAZIL    #
> ##############################
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ligges at statistik.uni-dortmund.de  Wed Apr 16 09:00:49 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 16 Apr 2003 09:00:49 +0200
Subject: [R] trying to plot function using curve
In-Reply-To: <Pine.LNX.4.44.0304152231130.13178-100000@Chrestomanci>
References: <Pine.LNX.4.44.0304152231130.13178-100000@Chrestomanci>
Message-ID: <3E9CFFA1.5090404@statistik.uni-dortmund.de>

Faheem Mitha wrote:
> Dear People,
> 
> I hope someone can help me with this. I have a function (density) which I
> am trying to plot using curve. I am calling mg.hist(3,2,1), and getting
> the following errors.
> 
> Error in xy.coords(x, y, xlabel, ylabel, log) :
> 	x and y lengths differ
> In addition: There were 50 or more warnings (use warnings() to see the
> first 50)
> 
>>warnings()
> 
> 1: longer object length
> 	is not a multiple of shorter object length in: x * y
> 
> and more of the same.
> 
> I'm not sure where the problem is. I assume it has something to do with me
> incorrectly vectorising my functions(s). However, it seems to me that
> density() is vectorised.
> 
> By the way, if anyone would like to suggest a better way to plot density
> plots, please let me know. curve() was suggested to me, which is why I am
> using it. Actually, I want to plot a density curve on top of a histogram.
> I was thinking of trying to use trellis graphics for this, but I'm not
> sure it has any advantages for this purpose.
> 
>                                                      Faheem.
> 

[Code snipped]

Some comments:
- Indeed, I'd use curve(), but of course you can do it "manually"
   with plot(.., type="l") as well.
- In your usage of curve() you rely heavily on R's scoping rules
   (should work, from my point of view, but always looks a bit
   dangerous):
       densityfn <- function(x) density(x,theta,pos,len) # No defaults!
       # Now curve() grabs theta, pos, len from any environment before:
       curve(densityfn)
- I would not use that many functions as in your code,
   but that's a matter of taste.
- It's not that amusing to debug all that code - try it yourself,
   R has many nice debugging tools (debug(), browser(), etc.).

Uwe Ligges


From =?windows-1251?Q?=CA=EE=F1=E5=ED=EA=EE=E2_=CA=E8=F0=E8=EB=EB_=CD?=  Wed Apr 16 09:52:49 2003
From: =?windows-1251?Q?=CA=EE=F1=E5=ED=EA=EE=E2_=CA=E8=F0=E8=EB=EB_=CD?= (=?windows-1251?Q?=CA=EE=F1=E5=ED=EA=EE=E2_=CA=E8=F0=E8=EB=EB_=CD?=)
Date: Wed, 16 Apr 2003 11:52:49 +0400
Subject: [R] troubles with displaying legend on the plot
In-Reply-To: <2889.030415@eimb.ru>
References: <2889.030415@eimb.ru>
Message-ID: <3E9D0BD1.1080608@nac.spb.ru>

Hi! It seems, that y-coord of your legend (1979,0), (0,0) located 
outside your coordinate system. 
par(usr=c(1979,2002,20,90),mar=c(7, 4, 4, 2) + 0.1)

You can use par('usr') to determine extremes of your coordinates 
for automatic legend placing. Or you can
legend(locator(1),[other options])
to place legend on your plot interactively.
Notice, that the y-coord has its 0 in the _bottom_ of figure region.

Wladimir Eremeev wrote:
> Dear colleagues,
> 
> I have troubles while trying to display legend on the plot.
> 
> I have data.frame fr
> 
> 
>>fr
> 
>    year  M1             M2
> 1  1979  58.85198     56.77303
> 2  1980  57.59725     55.93749
> 3  1981  57.32133     55.55232
> 4  1982  54.69320     53.10566
> 5  1983  56.58973     55.03811
> 6  1984  58.81363     56.97641
> 7  1985  58.35583     56.82091
> 8  1986  60.41842     58.45457
> 9  1987  58.75928     57.03679
> 10 1988  59.89553     58.69077
> 11 1989  51.03595     49.45001
> 12 1990  52.23915     50.96713
> 13 1991  46.50311     45.50370
> 14 1992  47.38811     46.31649
> 15 1993  48.58066     47.44610
> 16 1994  46.04452     44.82441
> 17 1995  46.41809     45.54565
> 18 1996  37.65783     36.48118
> 19 1997  60.16313     58.63771
> 20 1998  51.47550     50.43720
> 21 1999  52.56228     51.64243
> 22 2000  41.71746     40.79734
> 23 2001  44.71175     44.05241
> 24 2002  49.78033     47.91608
> 
> actually I've loaded it from MySQL database.
> 
> Now drawing this plot with the following plot.r
> 
> ===8<====
> op<-par(no.readonly=TRUE);
> 
> par(usr=c(1979,2002,20,90),mar=c(7, 4, 4, 2) + 0.1);
> 
> plot(fr$year,fr$M1
>      ,cex=0.8
>      ,type="o",ylim=c(20,90),xlim=c(1979,2002)
>      ,xlab="year",ylab="M, %"
>      ,pch=20
>      ,xaxt="n",
>      );
> 
> lines(fr$year,fr$M2);
> points(fr$year,fr$M2,pch=21)
> axis(1,at=c(1979:2002));
> 
> for(x in 1979:2002) {
>   abline(v=x, col = "lightgray", lty = "dotted");
> }
> for(y in seq(20,90,10)){
>   abline(h=y, col = "lightgray", lty = "dotted");
> }
> legend(1979,0,
>        legend=c("M1","M2"),
>        pch=c(20,21));
> 
> par(op);
> ===8<===
> 
> Legend doesn't appear.
> I tried different coordinates, (1979,0), (0,0),
> different colors, etc...
> 
> Nothing helps. What should I do to make the legend to appear?
> 
> I'm using R 1.6.2 for windows.
> OS: Windows NT workstation 4.0.
> 
> Thank you in advance.


From wl at eimb.ru  Wed Apr 16 10:26:11 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Wed, 16 Apr 2003 12:26:11 +0400
Subject: [R] troubles with displaying legend on the plot
In-Reply-To: <3E9D0BD1.1080608@nac.spb.ru>
References: <3E9D0BD1.1080608@nac.spb.ru>
Message-ID: <16518.030416@eimb.ru>

Dear colleagues,

Thank you, I've already realized that...

Is is possible to place the legend outside a plot in any other way
except using lattice package?

BTW, maybe it would be useful to place this question in FAQ?
I've searched the mail archive. The question about placing the legend
outside a plot already have arose...

Wednesday, April 16, 2003, 11:52:49, you wrote:

???> Hi! It seems, that y-coord of your legend (1979,0), (0,0) located 
???> outside your coordinate system. 
???> par(usr=c(1979,2002,20,90),mar=c(7, 4, 4, 2) + 0.1)

???> You can use par('usr') to determine extremes of your coordinates 
???> for automatic legend placing. Or you can
???> legend(locator(1),[other options])
???> to place legend on your plot interactively.
???> Notice, that the y-coord has its 0 in the _bottom_ of figure region.

-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru

==========================================================================
Research Scientist                                Leninsky Prospect 33,
Space Monitoring & Ecoinformation Systems Sector, Moscow, Russia, 119071,
Institute of Ecology,                             Phone: (095) 135-9972;
Russian Academy of Sciences                       Fax: (095) 954-5534


From maechler at stat.math.ethz.ch  Wed Apr 16 10:27:59 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 16 Apr 2003 10:27:59 +0200
Subject: [R] Color conversion of ps to pdf
In-Reply-To: <CLECJBOEBGOMOKJHJNDAEEJBCOAA.marwan.khawaja@aub.edu.lb>
References: <CLECJBOEBGOMOKJHJNDAEEJBCOAA.marwan.khawaja@aub.edu.lb>
Message-ID: <16029.5135.402927.450336@gargle.gargle.HOWL>

(Corrected "Subject" !)

>>>>> "Marwan" == Marwan Khawaja <marwan.khawaja at aub.edu.lb>
>>>>>     on Wed, 16 Apr 2003 09:41:07 -0700 writes:

    Marwan> Hello,
    Marwan> I get a nice looking barplot using the barplot2 function in the gregmisc
    Marwan> package:

    Marwan> body2 <- barplot2(hh3, beside = TRUE,
    Marwan> col = c("mistyrose", "lightcyan"),
    Marwan> ....
    Marwan> cex.names = 1.0, plot.ci = TRUE, ci.l = cil, ci.u = ciu,
    Marwan> plot.grid = TRUE)
    Marwan> box()

    Marwan> However, obviously I lose the collors when
    Marwan> converting from ps to a pdf (outside of R) but I get
    Marwan> a single shaded pattern!  Is it my choice of
    Marwan> collors? Or the conversion software I am using?  Any
    Marwan> help would be appreciated.  TIA Marwan

a more useful example using standard R functions and
reproducible data --- from  help(barplot) :

postscript("barp-VAD.eps", onefile=FALSE, horizontal=FALSE,
           height=4, width=6)

     data(VADeaths, package = "base")
     
     barplot(VADeaths, beside = TRUE,
             col = c("lightblue", "mistyrose", "lightcyan",
                     "lavender", "cornsilk"),
             legend = rownames(VADeaths), ylim = c(0, 100))
     title(main = "Death Rates in Virginia", font.main = 4)

dev.off()

## Using Latex's epstopdf
system("epstopdf barp-VAD.eps") #--> barp-VAD.pdf 
## Use Acrobat reader:
system("acroread  barp-VAD.pdf &")
## alternatively, requiring a newer `gv' (GView) which can deal with pdf:
system("gv  barp-VAD.pdf &")

---
Looks perfect  (Linux).
Hence, yes, it's your conversion software!

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From wouter.buytaert at tiscali.be  Wed Apr 16 10:41:09 2003
From: wouter.buytaert at tiscali.be (wouter buytaert)
Date: 16 Apr 2003 10:41:09 +0200
Subject: [R] TukeyHSD
Message-ID: <1050482469.1841.4.camel@BNL32.agr.kuleuven.ac.be>

Hello,

for some reason TukeyHSD() seems not to want to play with aov-results
with an Error() function:

> Res1<-aov(H2O~location+topo+horizon+pF+Error(location:topo:horizon))
> TukeyHSD(Res1, "topo")
Error in TukeyHSD(Res1, "topo") : no applicable method for "TukeyHSD"


However you could do it by hand by doing all pairwise comparisons and
adapt the confidence interval with Tukey or Scheffe. 
Or do I make a statistical thinking error?

Thanks,

Wouter


From Roger.Bivand at nhh.no  Wed Apr 16 11:28:28 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 16 Apr 2003 11:28:28 +0200 (CEST)
Subject: [R] How to do the significant test on Local Moran's I
In-Reply-To: <20030414163027.86745.qmail@web11003.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0304161112390.29558-100000@reclus.nhh.no>

On Mon, 14 Apr 2003, Danlin Yu wrote:

>     I've tried professor Roger Bivand's spdep package
> for a while, and found it is quite useful. However,
> when considering the significance test of the local
> moran's index under the assumption of both normality
> and randomization, I just can't get a clue from the
> package's calculating results. I also read professor
> Luc Anselin's 1995 LISA paper (geographical analysis),
> but cannot figure out a way of using R to do the
> significant test. I know I must missed something, but
> just don't know what is it. Could anybody give a hand?

The ideas are in the documentation and references of the functions you
refer to in the spdep package: localmoran(), localG(), and
localmoran.sad(). You need to recall that doing lots of local
"significance" tests on the same data means that you have to apply
corrections, as in p.adjust(), to any p-values you might compute. If you
are just testing a single relationship (values of x in Rhode Island are
correlated with values of x in its contiguous neighbours), you can do that
in the standard way, but you cannot extend this to gat a map of p-values -
they will be very misleading, as the references point out - Ord, J. K. and
Getis, A. 1995 Local spatial autocorrelation statistics: distributional
issues and an application. Geographical Analysis, 27, 286-306 - have a 
table of corrections. 

The functions in the package let you compute the pieces you need to do the
test, but do not provide any p-values, because the function cannot know
how many tests you are doing on the same data - you have to do that. That
is also why localmoran.sad() returns a list of "htest" objects, to point
up the fact that you should decide yourself what you are trying to test.

Please also be aware that by modifying the boundaries of the aggregations 
you may be analysing, you can often choose the test results you might like 
(the Modifiable Areal Unit Problem), so your "significance" tests may not 
actually be very informative.

Roger

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no


From SuzieBlatt at netscape.net  Wed Apr 16 13:17:23 2003
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Wed, 16 Apr 2003 07:17:23 -0400
Subject: [R] Summarizing levels for future commands
Message-ID: <25118371.0BF65A3E.0D1322AF@netscape.net>


Hello,

Thanks to those who have been responding to my query.

I've done the following, and get the following results:

table(x)

"elm.american" "hawthorn" "ironwood"
    2                1        4

which.max(table(x))

"3"

The first 'table' is fine, the 'which.max' part not.  Can I get it to actually use "ironwood", or is numeric all I can hope for?  I tried putting 'as.character' in front of the 'which.max' command but that didn't work.  The 'names(tbl)[match(max(tbl), tbl)]' also didn't work for me, claims it didn't know what the 'names' function was.

Any further suggestions most welcome,

Suzanne


>> samp = sample(1:10, 50, replace = TRUE)
>> table(samp)
>samp
> 1  2  3  4  5  6  7  8  9 10 
> 5  3  7  3  4  2  8  9  3  6 
>
>the most popular value is 8.
>
>As you can see, the table function tells you the frequencies of the
>values.  From that it is just a matter of extracting the index of the
>value with the maximum count and getting the label.
>
>> names(tbl)[match(max(tbl), tbl)]
>[1] "8"
>
>Hope this helps.
>


From SuzieBlatt at netscape.net  Wed Apr 16 13:32:11 2003
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Wed, 16 Apr 2003 07:32:11 -0400
Subject: [R] Summarizing levels for future commands
Message-ID: <47F1287D.6288685A.0D1322AF@netscape.net>


Hello again,

Figured out one of my errors, forgot the 's' on the 'names' command.  So, now I can get my max (or min) of the levels within my table and I can plug them successfully into my function farther along my code.  However, how can I get the 2nd or 3rd most frequent level and use them as well as the most frequent level?

Thanks for the continued help,

Suzanne


Douglas Bates <bates at stat.wisc.edu> wrote:

>SuzieBlatt at netscape.net (Suzanne E. Blatt) writes:
>
>> Hi.  This will hopefully be readily understood but if not, bear with me.
>> 
>> I have to do a repeated analysis (in spatstat) and want to batch file it.  For each of my 'runs' certain variables change.  At present I am manually specifying these changes and want to automate it if possible.
>> 
>> Ok, I am creating an object which is comprised of 'levels' that are 'characters'.  Further in my program I need to select one of these 'levels' as the comparison to the others.  The one I want to select is the most frequent and then compare it to the second most frequent.  Is there anyway to get R to determine the most frequency of 'levels' in an object and then use a specific one in future functions?  I couldn't find it in my search through the manual or the r-help archives.
>> 
>> I hope what I am attempting to do is clear, let me know if it isn't.
>
>I think I know what you want to do but I'm not sure.  I believe you
>want to find the mode, or the "most popular" level.  For example, in
>the following sample of size 50 from the values 1:10
>
>> samp = sample(1:10, 50, replace = TRUE)
>> table(samp)
>samp
> 1  2  3  4  5  6  7  8  9 10 
> 5  3  7  3  4  2  8  9  3  6 
>
>the most popular value is 8.
>
>As you can see, the table function tells you the frequencies of the
>values.  From that it is just a matter of extracting the index of the
>value with the maximum count and getting the label.
>
>> names(tbl)[match(max(tbl), tbl)]
>[1] "8"
>
>Hope this helps.
>


From edd at debian.org  Wed Apr 16 13:46:57 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 16 Apr 2003 06:46:57 -0500
Subject: [R] troubles with displaying legend on the plot
In-Reply-To: <16518.030416@eimb.ru>
References: <3E9D0BD1.1080608@nac.spb.ru> <16518.030416@eimb.ru>
Message-ID: <20030416114657.GA23424@sonny.eddelbuettel.com>

On Wed, Apr 16, 2003 at 12:26:11PM +0400, Wladimir Eremeev wrote:
> Is is possible to place the legend outside a plot in any other way
> except using lattice package?

Sort of -- I once did that using layout(). In essence you arrange two (or
more) plots on a page. One of those plots remains 'empty' and only contains
a legend, which gives the desired of having a plot with a separate legend.

> BTW, maybe it would be useful to place this question in FAQ?
> I've searched the mail archive. The question about placing the legend
> outside a plot already have arose...

This was discussed before. Simply trying one google query as in
     http://www.google.com/search?q=legend+outside+r-help
or     
     http://www.google.com/search?q=legend+outside+site:r-project.org
shows several results, including one with the simpler answer
     par(xpd=T)

Hope this helps, Dirk

-- 
Wishful thinking can dominate much of the work of a profession for a decade,
but not indefinitely.   -- Robert Shiller, on Efficient Markets models, 2002


From partha_bagchi at hgsi.com  Wed Apr 16 13:46:10 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Wed, 16 Apr 2003 07:46:10 -0400
Subject: [R] Summarizing levels for future commands
Message-ID: <OF400798D3.2CC2ECD7-ON85256D0A.00406C00-85256D0A.0040A5D6@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030416/2a4c84bf/attachment.pl

From SuzieBlatt at netscape.net  Wed Apr 16 14:29:17 2003
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Wed, 16 Apr 2003 08:29:17 -0400
Subject: [R] Summarizing levels for future commands
Message-ID: <772307DA.592E10F3.0D1322AF@netscape.net>


Thank you all!  I got my program doing what I want it to - it will save me ALOT of time!!

Suzanne


Douglas Bates <bates at stat.wisc.edu> wrote:

>SuzieBlatt at netscape.net (Suzanne E. Blatt) writes:
>
>> Hi.  This will hopefully be readily understood but if not, bear with me.
>> 
>> I have to do a repeated analysis (in spatstat) and want to batch file it.  For each of my 'runs' certain variables change.  At present I am manually specifying these changes and want to automate it if possible.
>> 
>> Ok, I am creating an object which is comprised of 'levels' that are 'characters'.  Further in my program I need to select one of these 'levels' as the comparison to the others.  The one I want to select is the most frequent and then compare it to the second most frequent.  Is there anyway to get R to determine the most frequency of 'levels' in an object and then use a specific one in future functions?  I couldn't find it in my search through the manual or the r-help archives.
>> 
>> I hope what I am attempting to do is clear, let me know if it isn't.
>
>I think I know what you want to do but I'm not sure.  I believe you
>want to find the mode, or the "most popular" level.  For example, in
>the following sample of size 50 from the values 1:10
>
>> samp = sample(1:10, 50, replace = TRUE)
>> table(samp)
>samp
> 1  2  3  4  5  6  7  8  9 10 
> 5  3  7  3  4  2  8  9  3  6 
>
>the most popular value is 8.
>
>As you can see, the table function tells you the frequencies of the
>values.  From that it is just a matter of extracting the index of the
>value with the maximum count and getting the label.
>
>> names(tbl)[match(max(tbl), tbl)]
>[1] "8"
>
>Hope this helps.
>


From mschwartz at medanalytics.com  Wed Apr 16 14:43:04 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 16 Apr 2003 07:43:04 -0500
Subject: [R] barplot2
In-Reply-To: <CLECJBOEBGOMOKJHJNDAEEJBCOAA.marwan.khawaja@aub.edu.lb>
Message-ID: <00ac01c30415$b99e27c0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marwan Khawaja
>Sent: Wednesday, April 16, 2003 11:41 AM
>To: R
>Subject: [R] barplot2
>
>
>Hello,
>I get a nice looking barplot using the barplot2 function in 
>the gregmisc
>package:
>
>    body2 <- barplot2(hh3, beside = TRUE,
>            col = c("mistyrose", "lightcyan"),
>    ....
>    cex.names = 1.0, plot.ci = TRUE, ci.l = cil, ci.u = ciu,
>            plot.grid = TRUE)
>    box()
>
>However, obviously I lose the collors when converting from ps 
>to a pdf (outside of R) but I get a single shaded pattern! Is 
>it my choice of collors? Or the conversion software I am 
>using? Any help would be appreciated. TIA Marwan


Marwan,

I don't have your full code, but I used barplot2() in R 1.6.2 under
WinXP Pro to generate a simple bar plot with two bars in the colors
that you have above. I can generate a .PS file and then convert it to
.PDF using GhostScript/GSView and default settings without problem.
The colors are properly retained.

Can you provide your full code so that I can exactly replicate your
plot and specify what program you are using to do the PS to PDF
conversion?

Regards,

Marc Schwartz


From laurent.faisnel at ariase.com  Wed Apr 16 14:46:56 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Wed, 16 Apr 2003 14:46:56 +0200
Subject: [R] unable to load package RPgSQL
Message-ID: <3E9D50C0.4040506@ariase.com>

Hi all,
I'm trying to install an add-on package for R called RPgSQL. Its role 
will be to link R with a PostgreSql database. I work on a Linux machine.
However, I'm quite a newbie as far as R's concerned, and I don't manage 
to install the package properly.
That's the steps I followed :

    * downloading the package (archive) 
    * R CMD INSTALL /path/to/package.tar.gz (as indicated in docs) - at
      that moment I had an error about unspecified directories for
      PostgreSql , so I used the option  --configure-args to specify
      where are the PostgreSql libraries and headers.
    * The installation then seemed to be a success : 

------------------------------------------------------------------------

R CMD INSTALL /home/faisnel/PostGresSql/RPgSQL_1.0-0.tar.gz 
--configure-args='--with-pgsql-libraries=/usr/local/pgsql/lib 
--with-pgsql-includes=/usr/local/pgsql/include'
* Installing *source* package 'RPgSQL' ...
creating cache ./config.cache
checking for crypt in -lcrypt... yes
checking how to run the C preprocessor... cc -E
checking for /usr/include/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /usr/include/pgsql/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /usr/include/postgresql/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /usr/local/include/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /usr/local/include/pgsql/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /usr/local/include/postgresql/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /opt/include/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /opt/include/pgsql/libpq-fe.h... no
checking how to run the C preprocessor... cc -E
checking for /opt/include/postgresql/libpq-fe.h... no
updating cache ./config.cache
creating ./config.status
creating src/Makevars
** libs
gcc -I/usr/lib/R/include -I/usr/local/pgsql/include  -D__NO_MATH_INLINES 
-mieee-fp  -fPIC  -O2 -march=i386 -mcpu=i686 -c RPgSQL.c -o RPgSQL.o
gcc -shared -L/usr/local/lib -o RPgSQL.so RPgSQL.o -lcrypt 
-L/usr/local/pgsql/lib -lpq
** R
** help
 >>> Building/Updating help pages for package 'RPgSQL'
     Formats: text html latex example
  db.result.get.value               text    html    latex   example
  db.write.table                    text    html    latex   example
  psql                              text    html    latex
  rpgsql.connections                text    html    latex
  rpgsql.execute.query              text    html    latex   example
  rpgsql.input                      text    html    latex   example
  rpgsql.list.contents              text    html    latex   example
  rpgsql.proxy                      text    html    latex   example
  rpgsql.result.attributes          text    html    latex
  rpgsql.type.conversions           text    html    latex   example
  rpgsql.utils                      text    html    latex
  sql.insert                        text    html    latex   example
  sql.select                        text    html    latex   example
  sql.update                        text    html    latex   example
* DONE (RPgSQL)

* DONE (INSTALL)
------------------------------------------------------------------------

However, when I try to load the package in R, it's a failure :

 > library(RPgSQL)
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library 
"/usr/lib/R/library/RPgSQL/libs/RPgSQL.so":
  libpq.so.3: cannot open shared object file: No such file or directory
Error in library(RPgSQL) : .First.lib failed

Thank you in advance for any help.

Laurent


From erwan.barret at wanadoo.fr  Wed Apr 16 15:39:11 2003
From: erwan.barret at wanadoo.fr (Erwan BARRET)
Date: Wed, 16 Apr 2003 15:39:11 +0200 (CEST)
Subject: [R] besoin d'aide
Message-ID: <11036683.1050500351447.JavaMail.www@wwinf0601>

J'aimerais savoir si la fonction merge() est la seule disponible pour concatener des tableaux de donn?es?
Est-ce normal que l'ex?cution soit lente?


From p.dalgaard at biostat.ku.dk  Wed Apr 16 15:42:04 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 16 Apr 2003 15:42:04 +0200
Subject: [R] R-1.7.0 is released
Message-ID: <x2n0iqa79v.fsf@biostat.ku.dk>


I've rolled up R-1.7.0.tgz a short while ago. This is a new version
with major changes in the methods/class area and with namespaces used
much more widely than before. Several routines now use the faster and
more modern LAPACK library. Also notice that the underscore is now
strongly deprecated as an assignment operator.

There are also a bunch of new functions and an assortment of bugs have
been fixed.

You can get it from

http://cran.us.r-project.org/src/base/R-1.7.0.tgz

or wait for it to be mirrored at a CRAN site nearer to you. Binaries
for various platforms will appear in due course.
 
There is also a version split for floppies.

These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

292dbe4dc47e6b492ff72a62471654ca  R-1.7.0.tgz
693d29ea3959f1b862704b59367e4ac1  R-1.7.0.tgz-split.aa
42b3fa5bc17fc3151eaabd2db0f530ca  R-1.7.0.tgz-split.ab
3fa95fa9661b6ff3ff33936ca57bdb89  R-1.7.0.tgz-split.ac
c124f1be4d35676975527bc19efbd579  R-1.7.0.tgz-split.ad
bb3a82202a8f113abf0260b6b585dc92  R-1.7.0.tgz-split.ae
84720f839a564abc8255c9a4b8c2980d  R-1.7.0.tgz-split.af
cfe0314cfc1ceea9ec74d00919e82865  R-1.7.0.tgz-split.ag


        For the R Core Team,

        Peter D.


Here's the relevant part of the NEWS file:


		CHANGES IN R VERSION 1.7.0


USER-VISIBLE CHANGES

    o	solve(), chol(), eigen() and svd() now use LAPACK routines
	unless a new back-compatibility option is turned on.  The
	signs and normalization of eigen/singular vectors may change
	from earlier versions.

    o	The `methods', `modreg', `mva', `nls' and `ts' packages
	are now attached by default at startup (in addition to `ctest').
	The option "defaultPackages" has been added which contains the
	initial list of packages.  See ?Startup and ?options for details.
	Note that .First() is no longer used by R itself.

	class() now always (not just when `methods' is attached) gives
	a non-null class, and UseMethod() always dispatches on the
	class that class() returns.  This means that methods like
	foo.matrix and foo.integer will be used.  Functions oldClass()
	and oldClass<-() get and set the "class" attribute as R
	without `methods' used to.

    o	The default random number generators have been changed to
	`Mersenne-Twister' and `Inversion'.  A new RNGversion()
	function allows you to restore the generators of an earlier R
	version if reproducibility is required.

    o	Namespaces can now be defined for packages other than `base':
	see `Writing R Extensions'.  This hides some internal objects
	and changes the search path from objects in a namespace.  All
	the base packages (except methods and tcltk) have namespaces,
	as well as the recommended packages `KernSmooth', `MASS',
	`boot', `class', `nnet', `rpart' and `spatial'.

    o	Formulae are not longer automatically simplified when terms()
	is called, so the formulae in results may still be in the
	original form rather than the equivalent simplified form
	(which may have reordered the terms): the results are now
	much closer to those of S.

    o	The tables for plotmath, Hershey and Japanese have been moved
	from the help pages (example(plotmath) etc) to demo(plotmath) etc.

    o	Errors and warnings are sent to stderr not stdout on
	command-line versions of R (Unix and Windows).

    o	The R_X11 module is no longer loaded until it is needed, so
	do test that x11() works in a new Unix-alike R installation.


NEW FEATURES

    o	if() and while() give a warning if called with a vector condition.

    o	Installed packages under Unix without compiled code are no
	longer stamped with the platform and can be copied to other
	Unix-alike platforms (but not to other OSes because of
	potential problems with line endings and OS-specific help files).

    o	The internal random number generators will now never return
	values of 0 or 1 for runif.  This might affect simulation
	output in extremely rare cases.	 Note that this is not
	guaranteed for user-supplied random-number generators, nor
	when the standalone Rmath library is used.

    o	When assigning names to a vector, a value that is too short is
	padded by character NAs. (Wishlist part of PR#2358)

    o	It is now recommended to use the 'SystemRequirements:' field in
	the DESCRIPTION file for specifying dependencies external to the
	R system.

    o	Output text connections no longer have a line-length limit.

    o	On platforms where vsnprintf does not return the needed buffer
	size the output line-length limit for fifo(), gzfile() and
	bzfile() has been raised from 10k to 100k chars.

    o	The Math group generic does not check the number of arguments
	supplied before dispatch: it used to if the default method had
	one argument but not if it had two.  This allows trunc.POSIXt()
	to be called via the group generic trunc().

    o	Logical matrix replacement indexing of data frames is now
	implemented (interpreted as if the lhs was a matrix).

    o	Recursive indexing of lists is allowed, so x[[c(4,2)]] is
	shorthand for x[[4]][[2]] etc.	(Wishlist PR#1588)

    o	Most of the time series functions now check explicitly for a
	numeric time series, rather than fail at a later stage.

    o	The postscript output makes use of relative moves, and so is
	somewhat more compact.

    o	%*% and crossprod() for complex arguments make use of BLAS
	routines and so may be much faster on some platforms.

    o	arima() has coef(), logLik() (and hence AIC) and vcov() methods.

    o	New function as.difftime() for time-interval data.

    o	basename() and dirname() are now vectorized.

    o	biplot.default() {mva} allows `xlab' and `ylab' parameters to
	be set (without partially matching to `xlabs' and `ylabs').
	(Thanks to Uwe Ligges.)

    o	New function capture.output() to send printed output from an expression
	to a connection or a text string.

    o	ccf() (pckage ts) now coerces its x and y arguments to class "ts".

    o	chol() and chol2inv() now use LAPACK routines by default.

    o	as.dist(.) is now idempotent, i.e., works for "dist" objects.

    o	Generic function confint() and `lm' method (formerly in
	package MASS, which has `glm' and `nls' methods).

    o	New function constrOptim() for optimisation under linear inequality
	constraints.

    o	Add `difftime' subscript method and methods for the group
	generics. (Thereby fixing PR#2345)

    o	download.file() can now use HTTP proxies which require `basic'
	username/password authentication.

    o	dump() has a new argument `envir'.  The search for named
	objects now starts by default in the environment from which
	dump() is called.

    o	The edit.matrix() and edit.data.frame() editors can now handle
	logical data.

    o	New argument `local' for example() (suggested by Andy Liaw).

    o	New function file.symlink() to create symbolic file links
	where supported by the OS.

    o	New generic function flush() with a method to flush connections.

    o	New function force() to force evaluation of a formal argument.

    o	New functions getFromNamespace(), fixInNamespace() and
	getS3method() to facilitate developing code in packages with
	namespaces.

    o	glm() now accepts `etastart' and `mustart' as alternative ways
	to express starting values.

    o	New function gzcon() which wraps a connection and provides
	(de)compression compatible with gzip.

	load() now uses gzcon(), so can read compressed saves from
	suitable connections.

    o	help.search() can now reliably match individual aliases and
	keywords, provided that all packages searched were installed
	using R 1.7.0 or newer.

    o	hist.default() now returns the nominal break points, not those
	adjusted for numerical tolerances.

	To guard against unthinking use, `include.lowest' in
	hist.default() is now ignored, with a warning, unless `breaks'
	is a vector.  (It either generated an error or had no effect,
	depending how prettification of the range operated.)

    o	New generic functions influence(), hatvalues() and dfbeta()
	with lm and glm methods; the previously normal functions rstudent(),
	rstandard(), cooks.distance() and dfbetas() became generic.
	These have changed behavior for glm objects -- all originating from
	John Fox' car package.

    o	interaction.plot() has several new arguments, and the legend
	is not clipped anymore by default.  It internally uses axis(1,*)
	instead of mtext().
	This also addresses "bugs" PR#820, PR#1305, PR#1899.

    o	New isoreg() function and class for isotonic regression
	(`modreg' package).

    o	La.chol() and La.chol2inv() now give interpretable error
	messages rather than LAPACK error codes.

    o	legend() has a new `plot' argument.  Setting it `FALSE' gives
	size information without plotting (suggested by U.Ligges).

    o	library() was changed so that when the methods package is
	attached it no longer complains about formal generic functions
	not specific to the library.

    o	list.files()/dir() have a new argument `recursive'.

    o	lm.influence() has a new `do.coef' argument allowing *not* to
	compute casewise changed coefficients.	This makes plot.lm() much
	quicker for large data sets.

    o	load() now returns invisibly a character vector of the names
	of the objects which were restored.

    o	New convenience function loadURL() to allow loading data files
	from URLs (requested by Frank Harrell).

    o	New function mapply(), a multivariate lapply().

    o	New function md5sum() in package tools to calculate MD5
	checksums on files (e.g. on parts of the R installation).

    o	medpolish() {package eda} now has an `na.rm' argument (PR#2298).

    o	methods() now looks for registered methods in namespaces, and
	knows about many objects that look like methods but are not.

    o	mosaicplot() has a new default for `main', and supports the
	`las' argument (contributed by Uwe Ligges and Wolfram Fischer).

    o	An attempt to open() an already open connection will be detected
	and ignored with a warning.  This avoids improperly closing
	some types of connections if they are opened repeatedly.

    o	optim(method = "SANN") can now cover combinatorial optimization
	by supplying a move function as the `gr' argument (contributed
	by Adrian Trapletti).

    o	PDF files produced by pdf() have more extensive information
	fields, including the version of R that produced them.

    o	On Unix(-alike) systems the default PDF viewer is now determined
	during configuration, and available as the 'pdfviewer' option.

    o	pie(...) has always accepted graphical pars but only passed
	them on to title().  Now pie(, cex=1.5) works.

    o	plot.dendrogram (`mva' package) now draws leaf labels if present
	by default.

    o	New plot.design() function as in S.

    o	The postscript() and PDF() drivers now allow the title to be set.

    o	New function power.anova.test(), contributed by Claus Ekstr?m.

    o	power.t.test() now behaves correctly for negative delta in the
	two-tailed case.

    o	power.t.test() and power.prop.test() now have a `strict'
	argument that includes rejections in the "wrong tail" in the
	power calculation. (Based in part on code suggested by Ulrich
	Halekoh.)

    o	prcomp() is now fast for n x m inputs with m >> n.

    o	princomp() no longer allows the use of more variables than
	units: use prcomp() instead.

    o	princomp.formula() now has principal argument `formula', so
	update() can be used.

    o	Printing an object with attributes now dispatches on the
	class(es) of the attributes. See ?print.default for the fine
	print. (PR#2506)

    o	print.matrix() and prmatrix() are now separate functions.
	prmatrix() is the old S-compatible function, and
	print.matrix() is a proper print method, currently identical
	to print.default().  prmatrix() and the old print.matrix()
	did not print attributes of a matrix, but the new print.matrix()
	does.

    o	print.summary.{lm,glm} now default to symbolic.cor = FALSE, but
	symbolic.cor can be passed to the print methods from the
	summary methods.  print.summary.{lm,glm} print correlations to
	2 decimal places, and the symbolic printout avoids abbreviating
	labels.

    o	If a prompt() method is called with 'filename' as 'NA', a
	list-style representation of the documentation shell generated
	is returned.  New function promptData() for documenting objects
	as data sets.

    o	qqnorm() and qqline() have an optional logical argument
	`datax' to transpose the plot (S-PLUS compatibility).

    o	qr() now has the option to use LAPACK routines, and the
	results can be used by the helper routines qr.coef(), qr.qy()
	and qr.qty().  The LAPACK-using versions may be much faster
	for large matrices (using an optimized BLAS) but are less
	flexible.

    o	QR objects now have class "qr", and solve.qr() is now just the
	method for solve() for the class.

    o	New function r2dtable() for generating random samples of two-way
	tables with given marginals using Patefield's algorithm.

    o	rchisq() now has a non-centrality parameter `ncp', and there's a
	C API for rnchisq().

    o	New generic function reorder() with a dendrogram method;
	new order.dendrogram() and heatmap().

    o	require() has a new argument, character.only,
	  -- to make it align with library.

    o	New functions rmultinom() and dmultinom(), the first one with
	a C API.

    o	New function runmed() for fast runnning medians (`modreg' package).

    o	New function slice.index() for identifying indexes with respect
	to slices of an array.

    o	solve.default(a) now gives the dimnames one would expect.

    o	stepfun() has a new `right' argument for right-continuous step
	function construction.

    o	str() now shows ordered factors different from unordered ones.
	It also differentiates "NA" and as.character(NA), also for factor
	levels.

    o	symnum() has a new logical argument `abbr.colnames'.

    o	summary(<logical>) now mentions NA's as suggested by
	G?ran Brostr?m.

    o	summaryRprof() now prints times with a precision appropriate
	to the sampling interval, rather than always to 2dp.

    o	New function Sys.getpid() to get the process ID of the R session.

    o	table() now allows exclude= with factor arguments (requested by
	Michael Friendly).

    o	The tempfile() function now takes an optional second argument
	giving the directory name.

    o	The ordering of terms for terms.formula(keep.order=FALSE) is
	now defined on the help page and used consistently, so that
	repeated calls will not alter the ordering (which is why
	delete.response() was failing: see the bug fixes).  The
	formula is not simplified unless the new argument `simplify'
	is true.

    o	added "[" method for terms objects.

    o	New argument `silent' to try().

    o	ts() now allows arbitrary values for y in start/end = c(x, y):
	it always allowed y < 1 but objected to y > frequency.

    o	unique.default() now works for POSIXct objects, and hence so
	does factor().


    o	Package tcltk now allows return values from the R side to the
	Tcl side in callbacks and the R_eval command. If the return
	value from the R function or expression is of class "tclObj"
	then it will be returned to Tcl.

    o	A new HIGHLY EXPERIMENTAL graphical user interface using the tcltk
	package is provided. Currently, little more than a proof of concept.
	It can be started by calling "R -g Tk" (this may change in later
	versions) or by evaluating tkStartGUI(). Only Unix-like systems
	for now. It is not too stable at this point; in particular, signal
	handling is not working properly.


    o	Changes to support name spaces:

	- Placing base in a name space can no longer be disabled by
	  defining the environment variable R_NO_BASE_NAMESPACE.

	- New function topenv() to determine the nearest top level
	  environment (usually .GlobalEnv or a name space environment).

	- Added name space support for packages that do not use methods.

    o	Formal classes and methods can be `sealed', by using the
	corresponding argument to setClass or setMethod.  New
	functions isSealedClass() and isSealedMethod() test sealing.

    o	packages can now be loaded with version numbers. This allows
	for multiple versions of files to be installed (and potentially
	loaded). Some serious testing will be going on, but it should
	have no effect unless specifically asked for.


INSTALLATION CHANGES

    o	TITLE files in packages are no longer used, the Title field
	in the DESCRIPTION file being preferred.  TITLE files will be
	ignored in both installed packages and source packages.

    o	When searching for a Fortran 77 compiler, configure by default
	now also looks for Fujitsu's frt and Compaq's fort, but no
	longer for cf77 and cft77.

    o	Configure checks that mixed C/Fortran code can be run before
	checking compatibility on ints and doubles: the latter test
	was sometimes failing because the Fortran libraries were not
	found.

    o	PCRE and bzip2 are built from versions in the R sources if the
	appropriate library is not found.

    o	New configure option --with-lapack to allow high-performance
	LAPACK libraries to be used: a generic LAPACK library will be
	used if found.	This option is not the default.

    o	New configure options --with-libpng, --with-jpeglib, --with-zlib,
	--with-bzlib and --with-pcre, principally to allow these
	libraries to be avoided if they are unsuitable.

    o	If the precious variable R_BROWSER is set at configure time
	it overrides the automatic selection of the default browser.
	It should be set to the full path unless the browser appears
	at different locations on different client machines.

    o	Perl requirements are down again to 5.004 or newer.

    o	Autoconf 2.57 or later is required to build the configure
	script.

    o	Configure provides a more comprehensive summary of its results.

    o	Index generation now happens when installing source packages
	using R code in package tools.	An existing 'INDEX' file is used
	as is; otherwise, it is automatically generated from the \name
	and \title entries in the Rd files.  Data, demo and vignette
	indices are computed from all available files of the respective
	kind, and the corresponding index information (in the Rd files,
	the 'demo/00Index' file, and the \VignetteIndexEntry{} entries,
	respectively).	These index files, as well as the package Rd
	contents data base, are serialized as R objects in the 'Meta'
	subdirectory of the top-level package directory, allowing for
	faster and more reliable index-based computations (e.g., in
	help.search()).

    o	The Rd contents data base is now computed when installing source
	packages using R code in package tools.	 The information is
	represented as a data frame without collapsing the aliases and
	keywords, and serialized as an R object.  (The 'CONTENTS' file
	in Debian Control Format is still written, as it is used by the
	HTML search engine.)

    o	A NAMESPACE file in root directory of a source package is copied
	to the root of the package installation directory.  Attempting to
	install a package with a NAMESPACE file using --save signals an
	error; this is a temporary measure.


DEPRECATED & DEFUNCT

    o	The assignment operator `_' will be removed in the next
	release and users are now warned on every usage: you may even see
	multiple warnings for each usage.

	If environment variable R_NO_UNDERLINE is set to anything of
	positive length then use of `_' becomes a syntax error.

    o	machine(), Machine() and Platform() are defunct.

    o	restart() is defunct.  Use try(), as has long been recommended.

    o	The deprecated arguments `pkg' and `lib' of system.file() have
	been removed.

    o	printNoClass() {methods} is deprecated (and moved to base,
	since it was a copy of a base function).

    o	Primitives dataClass() and objWithClass() have been replaced
	by class() and class<-(); they were internal support functions
	for use by package methods.

    o	The use of SIGUSR2 to quit a running R process under Unix is
	deprecated, the signal may need to be reclaimed for other
	purposes.


UTILITIES

    o	R CMD check more compactly displays the tests of DESCRIPTION
	meta-information.  It now reports demos and vignettes without
	available index information.  Unless installation tests are
	skipped, checking is aborted if the package dependencies cannot
	be resolved at run time.  Rd files are now also explicitly
	checked for empty \name and \title entries.  The examples are
	always run with T and F redefined to give an error if used
	instead of TRUE and FALSE.

    o	The Perl code to build help now removes an existing example
	file if there are no examples in the current help file.

    o	R CMD Rdindex is now deprecated in favor of function Rdindex()
	in package tools.

    o	Sweave() now encloses the Sinput and Soutput environments of
	each chunk in an Schunk environment. This allows to fix some
	vertical spacing problems when using the latex class slides.


C-LEVEL FACILITIES

    o	A full double-precision LAPACK shared library is made
	available as -lRlapack.	 To use this include
	$(LAPACK_LIBS) $(BLAS_LIBS) in PKG_LIBS.

    o	Header file R_ext/Lapack.h added.  C declarations of BLAS
	routines moved to R_ext/BLAS.h and included in R_ext/Applic.h
	and R_ext/Linpack.h for backward compatibility.

    o	R will automatically call initialization and unload routines, if
	present, in shared libraries/DLLs during dyn.load() and
	dyn.unload() calls. The routines are named R_init_<dll name>
	and R_unload_<dll name>, respectively.	See the Writing R
	Extensions Manual for more information.

    o	Routines exported directly from the R executable for use with
	.C(), .Call(), .Fortran() and .External() are now accessed via
	the registration mechanism (optionally) used by packages.  The
	ROUTINES file (in src/appl/) and associated scripts to
	generate FFTab.h and FFDecl.h are no longer used.

    o	Entry point Rf_append is no longer in the installed headers
	(but is still available).  It is apparently unused.

    o	Many conflicts between other headers and R's can be avoided by
	defining STRICT_R_HEADERS and/or R_NO_REMAP -- see `Writing R
	Extensions' for details.

    o	New entry point R_GetX11Image and formerly undocumented
	ptr_R_GetX11Image are in new header R_ext/GetX11Image.	These
	are used by package tkrplot.


BUG FIXES

    o	Sys.sleep() on Unix was having trouble with waits of less than 0.5s

    o	The fix to PR#2396 broke read.table() on files with CR line
	endings. (PR#2469)   Separate problem with this on Carbon MacOS
	build fixed as well.

    o	Converting Sweave files to noweb syntax using SweaveSyntConv()
	was broken.

    o	Printing numbers near the minimum could get the number of
	significant figures wrong due to underflow: for example 4e-308
	might print as 4.00000e-308.  (Seen on some Windows builds,
	and also on numbers around 1e-317 on Linux.)

    o	wilcox.test() could give integer overflow warnings on very long
	vectors.  Also added tests for numeric inputs, as per the help
	page.  (PR#2453)

    o	Printing unquoted character vectors containing escape
	characters was computing the wrong length and hence
	misaligning names.  This was due to a bug in Rstrlen which
	might have had other effects.

    o	if(logical(0)) and while(logical(0)) now report zero length,
	not `missing value where logical is needed'.

    o	The gaussian() and inverse.gaussian() families were documented
	to allow only one link, which has not been true in R for at
	least four years.

    o	prmatrix() forced conversion to character if `na.print' was
	used, and that conversion neither respected `digits' nor
	`quote'.

    o	Rprof() might give misleading results for too small values of
	`interval' and in practice the default 20ms was about as small
	as is advisable on Linux.  Now the interval is forced to be at
	least one clock tick.

    o	summary.data.frame() was not giving interpretable results when
	the data frame contained a data frame as a column. (PR#1891)

    o	delete.response() might re-order the rhs terms so prediction
	might fail or even give incorrect results. (PR#2206)

    o	StructTS() now accepts numeric time series of integer storage mode.

    o	all(), any() now handle NAs as documented.

    o	Subsetting arrays to a result with 0 dimension(s) failed if
	the array had dimnames. (PR#2507)

    o	If the call to data.frame() included 0-row arguments, it tried
	to replicate them to the maximum number of rows, and failed if
	this was 1 or more.

    o	replicate() now understands data frames to which na.omit() has
	been applied.

    o	is.ts() was too liberal: a time series must have at least one point.

    o	methods() was sorting by package, not by name.

    o	symbols(thermometers=) was often giving a spurious warning about
	the range.

    o	tcltk was using deprecated internals of the Tcl library when
	accessing error messages.  Not likely to be a user-visible
	change.

    o	The automatic search for BLAS libs now tries Sun's libsunperf
	the way the latest versions require. (PR#2530)

    o	str(array(1)) now does show the array.
	str(Surv(...)) now works again.

    o	step(), add1.default() and drop1.default() now work somewhat
	better if called from a function.

    o	page() was searching from the wrong environment, and so
	searching base before the workspace.

    o	crossprod(Z) for complex Z was returning nonsense.

    o	La.chol2inv() gave incorrect results unless the matrix was square.

    o	When the POSIXt date functions were required to guess DST,
	they sometimes guessed correctly that DST was in force but
	converted a POSIXlt time as if standard time was given.

    o	c/rbind were not handling zero col/row matrices correctly.
	(PR#2541 was one symptom.)

    o	approx() and approxfun() now work with 1 knot if
	method = "constant".  stepfun(), ecdf() and plot.stepfun() do so
	as well.

    o	AIC.lm/default was failing if multiple objects and k were
	specified.  (PR#2518)

    o	removeMethods{methods} was broken. (PR#2519)

    o	summary.glm() had two `aic' components in the returned object.

    o	autoload() was returning the value of its last command, a
	promise, even though it was documented to have no value.
	As a result some packages (e.g. nlme) were loading packages
	they meant to autoload.

    o	Fixes to methods and classes:
	   - show() is consistent with using setOldClass for S3 classes.
	   - several problems with the coerce and replace methods
	     generated by setIs have been fixed.
	   - more thorough tests & informative messages for invalid
	     `def' arguments to setGeneric
	   - setGeneric will now create the generic function even when
	     a generic of the same name already exists (it does issue
	     a warning).

    o	unz() connections could no longer be opened. (PR#2579)

    o	unique(ordered factor) returned an unordered factor. (PR#2591)

    o	x[] <- value coerced x to the mode of value if and only if x
	had length 0!  (Should only happen if x is null: PR#2590)

    o	lm() mislabelled the cols of the qr decomposition. (cause of PR#2586)

    o	data() looks for file extensions in an order prescribed in the
	help file: previously whether foo.R or foo.csv was used was
	locale-dependent.

    o	sys.function() now returns the actual function being evaluated in
	the specified frame rather than one inferred from the call.

    o	match.call() now uses the definition of the actual function being
	evaluated rather than one inferred from the call.

    o	abbreviate(*, dot = TRUE) now only adds a "." where abbreviations
	did happen.

    o	Changing timezones in the POSIXt functions was not working on
	some Linux systems, and this has been corrected.

    o	ks.test() in package ctest had numerical problems in the lower
	tail of the asymptotic distribution (PR#2571).

    o	Sweave() now handles empty chunks at the end of files correctly.

    o	[<-() lost the object bit if coercion was involved.

    o	package::object wasn't being deparsed properly.

    o	seq.POSIXt() with `by' an object of class "difftime" ignored
	the units.

    o	rank(c("B", NA)) no longer returns character.

    o	reference to by() added in ?tapply

    o	?lm describes what happens with matrix response

    o	The X11 device has improved event handling. In particular it
	used to often miss the last of a series of resize events.

    o	lm.influence() and related functions now work again for the
	multivariate case and when there are zero weights.

    o	format( <character> ) now always keeps names and dimnames.

    o	table(factor(c(2,NA), exclude=NULL)) prints better now.

    o	predict(foo, type = "terms") and hence
	residuals(foo, type = "partial") now work for lm and glm objects
	with weights zero.  Further, model.matrix() is now only called once.

    o	R CMD config now works correctly when called from a Makefile
	using GNU make.

    o	The data.frame method for rbind() was
	- converting character columns to factors,
	- converting ordered factor columns to unordered factors,
	- failing to append correctly a factor to a character column
	  and vice versa.

    o	as.hclust.twins() now does provide proper `labels', `method' and
	`call' components.

    o	cycle() sometimes failed on a time series which started at a cycle
	other than 1.

    o	read.dcf() read incorrectly files which did not end in a new line.

    o   read.socket() dropped certain non-alphanumeric characters. (PR#2639)

    o   termplot() handles missing data better (PR#2687, 
         <Mark.Bravington at csiro.au>)

    o	Corrected MacRoman encoding for Icircumflex etc.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From edd at debian.org  Wed Apr 16 15:46:41 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 16 Apr 2003 08:46:41 -0500
Subject: [R] unable to load package RPgSQL
In-Reply-To: <3E9D50C0.4040506@ariase.com>
References: <3E9D50C0.4040506@ariase.com>
Message-ID: <20030416134641.GA24603@sonny.eddelbuettel.com>

On Wed, Apr 16, 2003 at 02:46:56PM +0200, Laurent Faisnel wrote:
> I'm trying to install an add-on package for R called RPgSQL. Its role 
[...]
>    * The installation then seemed to be a success : 

Not exactly as ...

> R CMD INSTALL /home/faisnel/PostGresSql/RPgSQL_1.0-0.tar.gz 
> --configure-args='--with-pgsql-libraries=/usr/local/pgsql/lib 
> --with-pgsql-includes=/usr/local/pgsql/include'
> * Installing *source* package 'RPgSQL' ...
> creating cache ./config.cache
> checking for crypt in -lcrypt... yes
> checking how to run the C preprocessor... cc -E
> checking for /usr/include/libpq-fe.h... no
> checking how to run the C preprocessor... cc -E
> checking for /usr/include/pgsql/libpq-fe.h... no
> checking how to run the C preprocessor... cc -E
> checking for /usr/include/postgresql/libpq-fe.h... no
> checking how to run the C preprocessor... cc -E
> checking for /usr/local/include/libpq-fe.h... no
> checking how to run the C preprocessor... cc -E
> checking for /usr/local/include/pgsql/libpq-fe.h... no
> checking how to run the C preprocessor... cc -E
> checking for /usr/local/include/postgresql/libpq-fe.h... no
> checking how to run the C preprocessor... cc -E
> checking for /opt/include/libpq-fe.h... no
> checking how to run the C preprocessor... cc -E
> checking for /opt/include/pgsql/libpq-fe.h... no
> checking how to run the C preprocessor... cc -E
> checking for /opt/include/postgresql/libpq-fe.h... no
> updating cache ./config.cache
> creating ./config.status
> creating src/Makevars

... it told you about nine times that a header file is amiss.  I would call
it a bug in RPgSQL that it even progrsses as it will obviously fail later
at the point you noticed.

Bottom line: install the required postgresql header files package, and try
again.

Hth, Dirk

-- 
Wishful thinking can dominate much of the work of a profession for a decade,
but not indefinitely.   -- Robert Shiller, on Efficient Markets models, 2002


From spencer.graves at pdf.com  Wed Apr 16 15:44:38 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 16 Apr 2003 06:44:38 -0700
Subject: [R] troubles with displaying legend on the plot
References: <3E9D0BD1.1080608@nac.spb.ru> <16518.030416@eimb.ru>
	<20030416114657.GA23424@sonny.eddelbuettel.com>
Message-ID: <3E9D5E46.5020901@pdf.com>

Another trick (which I think I got from Modern Applied Statistics with 
S) is to compute xlim manually and add 20% or 50% on the right or left 
to create the blank space you want for the legend.

hth
spencer graves

Dirk Eddelbuettel wrote:
> On Wed, Apr 16, 2003 at 12:26:11PM +0400, Wladimir Eremeev wrote:
> 
>>Is is possible to place the legend outside a plot in any other way
>>except using lattice package?
> 
> 
> Sort of -- I once did that using layout(). In essence you arrange two (or
> more) plots on a page. One of those plots remains 'empty' and only contains
> a legend, which gives the desired of having a plot with a separate legend.
> 
> 
>>BTW, maybe it would be useful to place this question in FAQ?
>>I've searched the mail archive. The question about placing the legend
>>outside a plot already have arose...
> 
> 
> This was discussed before. Simply trying one google query as in
>      http://www.google.com/search?q=legend+outside+r-help
> or     
>      http://www.google.com/search?q=legend+outside+site:r-project.org
> shows several results, including one with the simpler answer
>      par(xpd=T)
> 
> Hope this helps, Dirk
>


From jmagalhaes at oninetspeed.pt  Wed Apr 16 16:04:24 2003
From: jmagalhaes at oninetspeed.pt (Jorge =?iso-8859-15?q?Magalh=E3es?=)
Date: Wed, 16 Apr 2003 15:04:24 +0100
Subject: [R] Discrete Multivariate Analysis (log-linear model)
Message-ID: <200304161504.24731.jmagalhaes@oninetspeed.pt>

I'm reading a old statistics book "MARVIN J. Karson (1982), Multivariate 
Statistical Methods, The IOWA State University Press, Iowa". In the chapter 
XI i can find some information about discrete multivariate analysis. This 
chapter is restricted to an introduction to log-linear models for analysis of 
multidimensional contingency tables. For example, in the log-linear model for 
the 3-way table e can test several Hypothesis:

Note: MLE, maximum likelihood estimator
Mijk: counts in the cell i, j, k

Hypothesis #		Hypothesis		df				MLE of Mijk
1				(ABC)			(a-1)(b-1)(c-1)		----
2				(AB)(ABC)			(a-1)(b-1)c			mi+k m+jk/m++k
3				(AC)(ABC)			(a-1)(c-1)b			mij+m+jk/m+j+
.....
8				(AB)(AC)(BC)(ABC)	abc-a-b-c+2		mi++m+j+m++k/n?
..........
18

for better understanding it, MARVIN gives an example:

>From MARVIN (p.269):

"Table X presents data from a national sample of n = 10524 respondents 
classified according to income A; mobility, B; and educational C. Each 
variable was categorized in two classes, with income classified as low 
<$12,500 and high otherwise, mobility classified as mobile if the respondent 
has made one or more moves over the last five years and nonmobile otherwise, 
and education classified as high scholl graduate or under versus some college 
or above. 
								Table X

			        	Mobile (j=1)				Nonmobile(j=2)
			High School		College		High School 		College
				k = 1			k=2				k=1			k=2
Low income (i=1)	1137			1091				2160			886
High income (i=2)	547			1415				1363			1925


M(111) = 1137
M(121) = 2160
and so on....

The satured model is:

Lijk = ln Mijk
Lijk =  u + u(A)(i) + u(B)(j) + u(AB)(ij) + u(AC)(ik) + u(BC)(jk) +u(ABC)(ijk)

For example, the independence hypothesis 8, states that income, mobility, and 
education are independent variables when grouped according to the given cross 
classification of low or high, mobile or nonmobile, and high or college.
.....". end of citation

My main questios is: how i can perform similar analysis in R environment. I 
want to test the hypothesis 8 and the all others. For each hypothesis, i want 
calculate de X^2 and G^2 and select the best model for fit the data 
moderately well.

Note: G^2 = 2 SUM (mijk ln(mijk/Mijk))
Note: X^2 = SUM((mijk-E(Mijk))^2/E(Mijk))

Thanks very much, in advance.

Jorge Magalh?es


From felipemenasalas at hotmail.com  Wed Apr 16 15:55:07 2003
From: felipemenasalas at hotmail.com (felipe mena)
Date: Wed, 16 Apr 2003 09:55:07 -0400
Subject: [R] Information about bootstrap
Message-ID: <Law15-F99CuyzC0bHwr000063ed@hotmail.com>

Hi, I am a chilean student and I am doing my thesis and I?ll very thankfully 
if you answer a question. In the thesis I need to applied Bootstrap 
simulations to the residulas for the time series model 
(AR(1),GARCH(1,1),GARCH-M(1,1)). The question is, the R software have a 
function to do the Bootstrap simulation or I need to create a algorithm?
                     Regards
                                Felipe Mena.





_________________________________________________________________

http://messenger.yupimsn.com/


From spencer.graves at pdf.com  Wed Apr 16 15:58:12 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 16 Apr 2003 06:58:12 -0700
Subject: [R] besoin d'aide
References: <11036683.1050500351447.JavaMail.www@wwinf0601>
Message-ID: <3E9D6174.80102@pdf.com>

In S-Plus, and presumably also in R, the execution of merge() with large 
data.frames is slow.  When speed becomes an issue, my colleagues use 
other language to handle this kind of operation with large data sets.

Hope this helps,
Spencer Graves

Erwan BARRET wrote:
> J'aimerais savoir si la fonction merge() est la seule disponible pour concatener des tableaux de donn?es?
> Est-ce normal que l'ex?cution soit lente?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From edd at debian.org  Wed Apr 16 16:34:13 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 16 Apr 2003 09:34:13 -0500
Subject: [R] besoin d'aide
In-Reply-To: <11036683.1050500351447.JavaMail.www@wwinf0601>
References: <11036683.1050500351447.JavaMail.www@wwinf0601>
Message-ID: <20030416143413.GA24908@sonny.eddelbuettel.com>


La langue officielle de la liste est bien Anglais.
(The official language of the list is English.)

On Wed, Apr 16, 2003 at 03:39:11PM +0200, Erwan BARRET wrote:
> J'aimerais savoir si la fonction merge() est la seule disponible pour concatener des tableaux de donn?es?

Eh non, pour concatener il en a egalement rbind(), cbind() et pas mal
d'autres. 
(Oh no, there are also rbind() and cbind(), among others.)

> Est-ce normal que l'ex?cution soit lente?

Ca depend.
(Depends)

Dirk
(Dirk)

-- 
Wishful thinking can dominate much of the work of a profession for a decade,
but not indefinitely.   -- Robert Shiller, on Efficient Markets models, 2002


From tblackw at umich.edu  Wed Apr 16 16:49:20 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 16 Apr 2003 10:49:20 -0400 (EDT)
Subject: [R] besoin d'aide
In-Reply-To: <11036683.1050500351447.JavaMail.www@wwinf0601>
Message-ID: <Pine.SOL.4.44.0304161045130.18494-100000@timepilot.gpcc.itd.umich.edu>


? "concatener" ?  Transliterated, this suggests the function  rbind().
The function  merge()  does something very special.  If  rbind() will
do what you want, it might be much faster.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 16 Apr 2003, Erwan BARRET wrote:

> J'aimerais savoir si la fonction merge() est la seule
> disponible pour concatener des tableaux de donnes?
> Est-ce normal que l'excution soit lente?
>


From tblackw at umich.edu  Wed Apr 16 17:13:57 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 16 Apr 2003 11:13:57 -0400 (EDT)
Subject: [R] trying to plot function using curve
In-Reply-To: <Pine.LNX.4.44.0304152231130.13178-100000@Chrestomanci>
Message-ID: <Pine.SOL.4.44.0304161106370.18494-100000@timepilot.gpcc.itd.umich.edu>

Faheem  -

I observe that function  unnorm1() explicitly returns a vector of
length one, constructed from the first and second elements of its
argument.  Possibly, it was intended to use the first and second
columns of its argument, in which case the subscripts should read
 y[ ,1]  and  y[ ,2].  Uwe Ligges' comment applies.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Tue, 15 Apr 2003, Faheem Mitha wrote:

> Dear People,
>
> I hope someone can help me with this. I have a function (density) which I
> am trying to plot using curve. I am calling mg.hist(3,2,1), and getting
> the following errors.
>   . . .
>
> and more of the same.
>
> I'm not sure where the problem is. I assume it has something to do with me
> incorrectly vectorising my functions(s). However, it seems to me that
> density() is vectorised.
>
> By the way, if anyone would like to suggest a better way to plot density
> plots, please let me know. curve() was suggested to me, which is why I am
> using it. Actually, I want to plot a density curve on top of a histogram.
> I was thinking of trying to use trellis graphics for this, but I'm not
> sure it has any advantages for this purpose.
>                                                      Faheem.
>
> ***********************************************************************
>   . . .
>             unnorm1 <- function(y) ##here y is 2-dim
>               {
>                 ifelse(y[2] == 0,2*theta,
>                        (1/y[2])*(exp(y[1]*y[2] + y[2]*theta)
>                                  - exp(y[1]*y[2] - y[2]*theta)))
>               }
>             unnorm2 <- function(y)
>               {
>                 ## return(unnorm1(c(x,y)))  ##here y is 1-dim
>                 ifelse(y == 0,2*theta,
>                        (1/y)*(exp(x*y + y*theta)
>                               - exp(x*y - y*theta)))
>               }
>   . . .
>


From bates at stat.wisc.edu  Wed Apr 16 17:23:22 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 16 Apr 2003 10:23:22 -0500
Subject: [R] R-1.7.0 sources now available through rsync
Message-ID: <6rn0iqpitx.fsf@bates4.stat.wisc.edu>

Sources for R-1.7.0 are now available through rsync to
rsync.r-project.org.

$ rsync rsync.r-project.org::
r-release      	R-1.7.0 sources (current released version - approx 30 MB)
r-patched      	R sources (patched released version - approx 30 MB)
r-devel        	R sources (development version)
r-manuals      	Development sources for manuals for R
r-recommended  	Sources for recommended R packages
xlispstat      	xlispstat sources (development version) CVS tree (approx 12 MB)
CRAN           	Complete CRAN ftp area
Bioc-release   	Bioconductor sources (current release version)
Bioc-devel     	Bioconductor sources (development version)
GGobi          	GGobi sources (devel version)
omega-cvs      	Omega Project for Statistical Computing CVS tree
r-project-web  	Web pages for www.r-project.org and mirrors
Omegahat       	Complete ftp archive for Omegahat


From bates at stat.wisc.edu  Wed Apr 16 17:23:22 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 16 Apr 2003 10:23:22 -0500
Subject: [R] R-1.7.0 sources now available through rsync
Message-ID: <6rn0iqpitx.fsf@bates4.stat.wisc.edu>

Sources for R-1.7.0 are now available through rsync to
rsync.r-project.org.

$ rsync rsync.r-project.org::
r-release      	R-1.7.0 sources (current released version - approx 30 MB)
r-patched      	R sources (patched released version - approx 30 MB)
r-devel        	R sources (development version)
r-manuals      	Development sources for manuals for R
r-recommended  	Sources for recommended R packages
xlispstat      	xlispstat sources (development version) CVS tree (approx 12 MB)
CRAN           	Complete CRAN ftp area
Bioc-release   	Bioconductor sources (current release version)
Bioc-devel     	Bioconductor sources (development version)
GGobi          	GGobi sources (devel version)
omega-cvs      	Omega Project for Statistical Computing CVS tree
r-project-web  	Web pages for www.r-project.org and mirrors
Omegahat       	Complete ftp archive for Omegahat


From f.calboli at ucl.ac.uk  Wed Apr 16 17:40:42 2003
From: f.calboli at ucl.ac.uk (Federico Calboli)
Date: Wed, 16 Apr 2003 16:40:42 +0100
Subject: [R] Error terms in aov and lme
Message-ID: <3.0.6.32.20030416164042.00a5ddc8@pop-server.ucl.ac.uk>

Hi All,

I have a purely theoretical question on how to speciy (correctly, if
possible) the error terms to use in a linear model with mixed effects.

I have an experiment where I grow flies from 4 selection regimes at 2
temeratures. Each selection regime has 3 independent replicates.

I summary:
2 temperatures
4 selection regimes
3 independent replicates per selection regime, for a grand total of 12. The
replicates are coded 1:12 as a factor

If I write dow the anova table, I have the following effects:
		d.f.
temp     	 1
sel		 3
sel/rep		 8
temp*sel	 3
temp*sel/rep	 8
residuals


If I am correct, the error terms are:

temp over temp*sel/rep (the df are 1/8)
sel over sel/rep (the df are 3/8)
sel/rep over the residuals (the df are 8/residuals)
temp*sel over temp*sel/rep (the df are 3/8)
temp*sel/rep over the residuals (the df are 8/residuals)

Using lme the model:

anova(lme( measurement.taken ~  temp*sel, random = ~ 1|rep/temp,  mydata))

gives an estimate with the right degrees of freedom for num and dem.  But
WHY do I have to nest tem inside rep? cannot figure it out for the life of me.

If I want to use aov:

anova(aov( measurement.taken ~ temp*sel + temp*sel/rep + sel/rep + Error
???, mydata))

How do I specify the correct error terms? 

=========================

Federico C.F. Calboli

Department of Biology
University College London
Room 327
Darwin Building
Gower Street
London
WClE 6BT

Tel: (+44) 020 7679 4395 
Fax (+44) 020 7679 7096
f.calboli at ucl.ac.uk


From alex.wittl at vr-web.de  Wed Apr 16 17:22:41 2003
From: alex.wittl at vr-web.de (Alexander Wittl)
Date: Wed, 16 Apr 2003 17:22:41 +0200
Subject: [R] Data Import
Message-ID: <000a01c3042c$0f6dc4b0$3400a8c0@Local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030416/ee6d7d88/attachment.pl

From ernesto at ipimar.pt  Wed Apr 16 17:36:49 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 16 Apr 2003 16:36:49 +0100
Subject: [R] Information about bootstrap
In-Reply-To: <Law15-F99CuyzC0bHwr000063ed@hotmail.com>
References: <Law15-F99CuyzC0bHwr000063ed@hotmail.com>
Message-ID: <1050507409.28514.9.camel@gandalf.ipimar.pt>

On Wed, 2003-04-16 at 14:55, felipe mena wrote:
> Hi, I am a chilean student and I am doing my thesis and I?ll very thankfully 
> if you answer a question. In the thesis I need to applied Bootstrap 
> simulations to the residulas for the time series model 
> (AR(1),GARCH(1,1),GARCH-M(1,1)). The question is, the R software have a 
> function to do the Bootstrap simulation or I need to create a algorithm?
>                      Regards
>                                 Felipe Mena.
> 
> 
> 
> 
> 
> _________________________________________________________________
> 
> http://messenger.yupimsn.com/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


Hi

Take a look at package "boot".

EJ
-- 
Ernesto Jardim <ernesto at ipimar.pt>
Marine Biologist
IPIMAR, Lisboa, Portugal
PIII 733, 1GB Ram, SuSE Linux 8.1, R 1.6.2, LyX 1.3.1, Gnome 2.2.0


From tplate at blackmesacapital.com  Wed Apr 16 18:18:26 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Wed, 16 Apr 2003 10:18:26 -0600
Subject: [R] besoin d'aide
In-Reply-To: <11036683.1050500351447.JavaMail.www@wwinf0601>
Message-ID: <5.2.1.1.2.20030416101131.07558110@mailhost.blackmesacapital.com>

The function merge() is like the "join" operation in relational data bases 
- it's much more powerful than mere concatenation (and thus often much 
slower, especially on large tables.)

To merely concatenate tables together, use rbind() (to concatenate by rows) 
or cbind() (to concatenate by columns).

If you do need the power of merge(), but it is too slow for your purposes 
you may be able to write a special-purpose function in R that does just 
only you need and much more quickly -- such is the nature of the S language 
-- it is very powerful, but the powerful general-purpose functions can 
often be quite slow in particular cases.

Hope this helps, and apologies if I have not completely understood your 
question.

-- Tony Plate


At Wednesday 03:39 PM 4/16/2003 +0200, Erwan BARRET wrote:
>J'aimerais savoir si la fonction merge() est la seule disponible pour 
>concatener des tableaux de donn?es?
>Est-ce normal que l'ex?cution soit lente?
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From sundar.dorai-raj at pdf.com  Wed Apr 16 18:37:38 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 16 Apr 2003 11:37:38 -0500
Subject: [R] R-1.7.0 WIN2000 INSTALL
Message-ID: <3E9D86D2.8010704@pdf.com>

This is the first time I've ever compiled from sources so bear with me.

OS: Windows 2000
PATH:
   .:
   D:/Rtools/:
   D:/mingw/bin/:
   C:/Progra~1/Perl/bin:
   D:/texmf/miktex/bin/:
   D:/Progra~1/HTMLHe~1:
   D:/Progra~1/R/rw1062/bin/:
   C:/Progra~1/Insightful/splus61/cmd/:
   D:/cygwin/bin:
   D:/Progra~1/SSHCom~1/SSHSec~1:
   D:/Progra~1/Tcl/bin/:
   C:/Progra~1/Microso~3/VC98/Bin

I've read src/gnuwin32/INSTALL and changed all the pertintent lines in 
src/gnuwin32/MkRules.

I'm running `make' under a bash shell. I couldn't get `make' to run in a 
DOS shell (I'm not sure why). I've removed `cygwin1.dll' and 
`cygpcre.dll' in the cygwin directory so as not to conflict with the 
ones supplied in `Rtools.zip'. Then when I run `make' in src/gnuwin32/ 
it seems to work fine until it reaches this point:

dlltool -k --as as   --dllname Rblas.dll \
   --def Rblas.def --output-lib libRblas.a
d:\mingw\bin\dlltool.exe: installation problem, cannot exec `as'
make[1]: *** [libRblas.a] Error 1
make[1]: Leaving directory `/cygdrive/d/R/R-1.7.0/src/gnuwin32'
make: *** [all] Error 2

Any ideas? Need more info?

Best,
Sundar


From ligges at statistik.uni-dortmund.de  Wed Apr 16 18:43:44 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 16 Apr 2003 18:43:44 +0200
Subject: [R] R-1.7.0 WIN2000 INSTALL
In-Reply-To: <3E9D86D2.8010704@pdf.com>
References: <3E9D86D2.8010704@pdf.com>
Message-ID: <3E9D8840.3060603@statistik.uni-dortmund.de>

Sundar Dorai-Raj wrote:
> This is the first time I've ever compiled from sources so bear with me.
> 
> OS: Windows 2000
> PATH:
>   .:
>   D:/Rtools/:
>   D:/mingw/bin/:
>   C:/Progra~1/Perl/bin:
>   D:/texmf/miktex/bin/:
>   D:/Progra~1/HTMLHe~1:
>   D:/Progra~1/R/rw1062/bin/:
>   C:/Progra~1/Insightful/splus61/cmd/:
>   D:/cygwin/bin:
>   D:/Progra~1/SSHCom~1/SSHSec~1:
>   D:/Progra~1/Tcl/bin/:
>   C:/Progra~1/Microso~3/VC98/Bin
> 
> I've read src/gnuwin32/INSTALL and changed all the pertintent lines in 
> src/gnuwin32/MkRules.
> 
> I'm running `make' under a bash shell. I couldn't get `make' to run in a 
> DOS shell (I'm not sure why). 

For compiling R, make is ought to be executed in the windows command 
shell. Please start debugging here ...

Uwe Ligges

 > I've removed `cygwin1.dll' and
> `cygpcre.dll' in the cygwin directory so as not to conflict with the 
> ones supplied in `Rtools.zip'. Then when I run `make' in src/gnuwin32/ 
> it seems to work fine until it reaches this point:
> 
> dlltool -k --as as   --dllname Rblas.dll \
>   --def Rblas.def --output-lib libRblas.a
> d:\mingw\bin\dlltool.exe: installation problem, cannot exec `as'
> make[1]: *** [libRblas.a] Error 1
> make[1]: Leaving directory `/cygdrive/d/R/R-1.7.0/src/gnuwin32'
> make: *** [all] Error 2
> 
> Any ideas? Need more info?
> 
> Best,
> Sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ramzi_feg at yahoo.fr  Wed Apr 16 18:46:42 2003
From: ramzi_feg at yahoo.fr (=?iso-8859-1?q?Ramzi=20Feghali?=)
Date: Wed, 16 Apr 2003 18:46:42 +0200 (CEST)
Subject: [R] besoin d'aide
In-Reply-To: <3E9D6174.80102@pdf.com>
Message-ID: <20030416164642.76619.qmail@web20302.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030416/73f701c8/attachment.pl

From ligges at statistik.uni-dortmund.de  Wed Apr 16 18:50:08 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 16 Apr 2003 18:50:08 +0200
Subject: [R] Data Import
In-Reply-To: <000a01c3042c$0f6dc4b0$3400a8c0@Local>
References: <000a01c3042c$0f6dc4b0$3400a8c0@Local>
Message-ID: <3E9D89C0.4010508@statistik.uni-dortmund.de>

Alexander Wittl wrote:
> Hi,
> I am new at this web page and also the R-programm ist new for me(i am a beginner!!).
 > Can anybody help me and tell me how to import data (Excel-file)from a 
folder maybe

called R-Data on the Harddisk(c:) into the R-Programm (tell me exactly 
how to)??
> My second problem is how to get a Regression Line into an existing Plot.
> I would be very lucky if anyone cold help me.
> Thanks
> Alex
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

a) Please warp lines in e-mails.

b) Please read the manual "R Data Import / Export" for your first 
question (there are at least two ways described in that manual, AFAIK).

c) Please read the manual "An Introduction to R", Section 12.2, for your 
second question.

Uwe Ligges


From carolxue at yahoo.com  Wed Apr 16 18:55:13 2003
From: carolxue at yahoo.com (Meng Xue)
Date: Wed, 16 Apr 2003 09:55:13 -0700 (PDT)
Subject: [R] help about the dist() error message
Message-ID: <20030416165513.38097.qmail@web11706.mail.yahoo.com>

hello,

I have a problem when call dist() of package mva on a large data
set. The following error message are obtained when I use dist()
on m, a two dimensional data set with the size 100,000. It seems
that the length of vector out of bound, since when I compute
dist on small data set(10,000), it works well. but for large
data set, it   exit with the message "negative length vector are
not allowed" .

Could you please give me an idea about how to solve it? Thanks
in advance.
Meng 
****error message***
> library(mva)              
> dist(m,method="euclidean")
Error in vector("double", length) : negative length vectors are
not allowed
In addition: Warning message: 
NAs introduced by coercion


From comm at 263.net  Wed Apr 16 13:54:40 2003
From: comm at 263.net (Jean Sun)
Date: Wed, 16 Apr 2003 19:54:40 +0800
Subject: [R] A statistical problem.Anybody can help me?
Message-ID: <20030416115524.25DE62F999@mta5.x263.net>

A doubt: 
Multiplying together the characteristics functions is available only if all a(i)|R(i)| is independent,i think.However, obviously, that is not true herein.

I will try the methods you mentioned.Thanks a lot!


2003-04-14 08:10:00 Spencer Graves wrote
>The standard asymptotic theory would start by deriving the 
>characteristic funciton of |R(i)|, then of a(i)|R(i)|, then multiplying 
>together the characteristics functions.  Then invert the characteristic 
>function with liberal use of Taylor's theorem.
>
>Any good book on asymptotics and approximation theory in Statistics 
>(especially Edgeworth expansions) will discuss this.  The modern theory 
>of saddlepoint approximations may do something different, but I'm not 
>familiar with that.
>
>Hope this helps.
>
>Spencer Graves
>
>Thomas W Blackwell wrote:
>> If this were my problem, I would try to separate real and imaginary
>> parts - write everything out in polar coordinates - and recognize
>> chi-squared random variables where they occur.  But that's very much
>> a beginner's approach.
>> 
>> HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -
>> 
>> On Mon, 14 Apr 2003, comm wrote:
>> 
>> 
>>>Sorry for the contents not relating to R.
>>>
>>>Assume there are N i.i.d zero-mean complex gaussian random
>>>variables(RVs),as w(i),0<=i<N} with known variance,from which one
>>>can generate another N RVs,as
>>>
>>>    R(0)=sum over i {w(i)*w'(i)}
>>>    R(1)=sum over i {w(i+1)*w'(i)}
>>>    ...
>>>up to
>>>	R(N-1)= w(N-1)w'(i)
>>>
>>>where w'(i) is the complex conjugate of w(i).
>>>(from viewpoint of signal processing, R(i) are serial correlation of time series w(i))
>>>
>>>If one defines a new random variable using {R(k)} as
>>>
>>>Z=a(0)R(0)+a(1)|R(1)|+...  a(N-1)|R(N-1)|,
>>>
>>>with {a(k)} are known and |.| is modulus operation.It's a decision
>>>statistic encountered in my work. I wish to find its approximated(using
>>>Central Limit Theorem) statistical characteristics in close-form.Mean and
>>>variance are enough.
>>>
>>>Does anybody have any ideas or references which can solve this problem?
>>>
>>>(below is my previous thoughts and now it is tested not work because RVs appear to be Rician distributed)
>>>Mean of Z is easy to get. However its variance is troublesome. I think it can be calculated by
>>>
>>>    Var=alpha*C*alpha',
>>>
>>>where alpha=[a(0) a(1) ... a(N-1)],C is covariance matrix of vector [R(0),|R(1)|,...,|R(N-1)|].
>>>
>>>Besides the diagonal and first row and first column, the other elements is
>>>small that can be ignored,which can be shown by simulations.Namely weak
>>>cross-correlation is hold between any two RVs of set
>>>{|R(1)|,|R(2)|,R(N-1)},while the crosss-correlation between R(0) and each
>>>RV of set {|R(1)|,|R(2)|, |R(N-1)|} and self-correlation of set
>>>{|R(0)|,|R(1)|,|R(N-1)|} is large and should not be ignored. The former is
>>>what i seek. I almost exhausted,so i came here for help.
>>>
>>>Any suggestion will be appreciated.
>>>
>>>Regards,
>>>Jeans Sun
>> 
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From chumpmonkey at hushmail.com  Wed Apr 16 19:28:08 2003
From: chumpmonkey at hushmail.com (chumpmonkey@hushmail.com)
Date: Wed, 16 Apr 2003 10:28:08 -0700
Subject: [R] Jackknife and rpart
Message-ID: <200304161728.h3GHS894001759@mailserver3.hushmail.com>


Hi,

First, thanks to those who helped me see my gross misunderstanding of
randomForest. I worked through a baging tutorial and now understand the
"many tree" approach. However, it is not what I want to do! My bagged
errors are accpetable but I need to use the actual tree and need a single
tree application. 

I am using rpart for a classification tree but am interested in a more
unbaised estimator of error in my tree. I lack sufficent data to train
and test the tree and I'm hoping to bootstrap, or rather jacknife, an
error estimate.

I do not think the rpart.object can be applied to the jackknife function
in bootstrap but can I do something as simple as:

for(i in 1:number of samples){
  remove i from the data
  run the tree
  compare sample[i] to the tree using predict
  create an error matrix}

This would give me a confussion matrix of data not included in the tree's
constuction.

Am I being obtuse again?

Thanks, CM


From fharrell at virginia.edu  Wed Apr 16 19:49:12 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed, 16 Apr 2003 13:49:12 -0400
Subject: [R] Jackknife and rpart
In-Reply-To: <200304161728.h3GHS894001759@mailserver3.hushmail.com>
References: <200304161728.h3GHS894001759@mailserver3.hushmail.com>
Message-ID: <20030416134912.7b90481d.fharrell@virginia.edu>

On Wed, 16 Apr 2003 10:28:08 -0700
chumpmonkey at hushmail.com wrote:

> 
> Hi,
> 
> First, thanks to those who helped me see my gross misunderstanding of
> randomForest. I worked through a baging tutorial and now understand the
> "many tree" approach. However, it is not what I want to do! My bagged
> errors are accpetable but I need to use the actual tree and need a single
> tree application. 
> 
> I am using rpart for a classification tree but am interested in a more
> unbaised estimator of error in my tree. I lack sufficent data to train
> and test the tree and I'm hoping to bootstrap, or rather jacknife, an
> error estimate.
> 
> I do not think the rpart.object can be applied to the jackknife function
> in bootstrap but can I do something as simple as:
> 
> for(i in 1:number of samples){
>   remove i from the data
>   run the tree
>   compare sample[i] to the tree using predict
>   create an error matrix}
> 
> This would give me a confussion matrix of data not included in the tree's
> constuction.
> 
> Am I being obtuse again?
> 
> Thanks, CM
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

You might look at the validate.tree function in the Design library (http://hesweb1.med.virginia.edu/biostat/s/Design.html) but better validated predictive accuracy would be obtained by approximating the predictions from the randomForest by a single (moderately large) tree.  You can use rpart to develop such a tree, stopping when, for example, the R-square is 0.9 or 0.95.
---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From jonck at vanderkogel.net  Wed Apr 16 19:57:07 2003
From: jonck at vanderkogel.net (Jonck van der Kogel)
Date: Wed, 16 Apr 2003 19:57:07 +0200
Subject: [R] Question on SOM and clustering
Message-ID: <D6E2A9EB-7034-11D7-B5EC-0005026E2B43@vanderkogel.net>

Hello everyone,
I'm new to this list, so let me introduce myself: my name is Jonck van 
der Kogel and I am a graduate student at the Erasmus University of 
Rotterdam. I am currently working on my thesis which is on the use of 
artificial intelligence for large data-sets.
To do an analysis of a certain data-set I want to use Kohonen's SOM 
algorithm. However, as I understand it, the SOM algorithm as it's 
implemented in R only gives a visual representation of the topological 
mapping. I want to do further analysis with this mapping and thus I 
need to do a clustering of the topological mapping produced by the SOM.
I was wondering wether anyone could give me some advice on which 
clustering method in R is most suited for clustering the map produced 
by the SOM algorithm.

Thanks very much, Jonck


From yanyu at cs.ucla.edu  Wed Apr 16 20:07:38 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Wed, 16 Apr 2003 11:07:38 -0700 (PDT)
Subject: [R] 
	import data from Matlab & error msg when install package "e1071"
Message-ID: <Pine.SOL.4.33.0304161058020.7032-100000@panther.cs.ucla.edu>

Hello,
  I am trying to import data from Matlab..
  when i looked up R documentation, it says, package "e1071" have command
(read.octave) to import data from octave.
but when I tried to install package by using:
install.packages("e1071");
I got the following message: ( BTW, my platform is linux version 2.4.18-3
my gcc is 2.96).

* Installing *source* package 'e1071' ...
checking for C++ compiler default output... a.out
checking whether the C++ compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
configure: WARNING: g++ 2.96 cannot reliably be used with this package.
configure: error: Please use a different C++ compiler.
ERROR: configuration failed for package 'e1071'


I am wondering did anyone successfully install "e1071" on linux box, what
gcc are you using?

Or Is there another way to import data from Matlab?

Thanks a lot,
yan


From myao at ou.edu  Wed Apr 16 20:21:03 2003
From: myao at ou.edu (Minghua Yao)
Date: Wed, 16 Apr 2003 13:21:03 -0500
Subject: [R] Local parameter calculation
Message-ID: <HDEPJCAKDEJMEEHKJOKEMEGGCAAA.myao@ou.edu>

Dear all,

I am a newbie in R. I encounter a problem as follows.

I have 2 vectors X and Y that have a equal length of several thousand. I see
Y as the function of X. Both of them are random. X is not arrranged in any
order. Of course, I do plot(X,Y). Now, I want to use a sliding narrow window
to run over each X, then calculate the variances within that window.

Anyone knows easy way in R to do this? Reply is appreciated.

-MY


From den.duurs at lycos.com  Wed Apr 16 20:27:28 2003
From: den.duurs at lycos.com (Remko Duursma)
Date: Wed, 16 Apr 2003 11:27:28 -0700
Subject: [R] making a dataframe out of lapply() result
Message-ID: <NDEKCIMKLDKMBAAA@mailcity.com>


Mahbub's solution 

data.frame(t(sapply(...)))

is much faster than

do.call("rbind", lapply(...))

as tested on a larger dataset.

Thanks everyone,

Remko Duursma
--

On Tue, 15 Apr 2003 22:10:28  
 Mahbub Latif wrote:
>you can try this,...
>data.frame(t(sapply(tester.L, function(x) x <- x[1,]
>)))
>
>Mahbub.
>
>--- Remko Duursma <den.duurs at lycos.com> wrote:
>> Dear R-helpers,
>> 
>> i have a question on how to vectorize this problem:
>> 
>> i have a dataframe:
>> 
>> tester <-
>> data.frame(groups=c("A","A","B","B","C","C"),
>> one=c(1,1,2,2,3,3), two=c(6,6,7,7,8,8))
>> 
>> # i split it into a list
>> tester.L <- split(tester, tester$groups)
>> 
>> # And want to keep only the first item in each:
>> lapply(tester.L, function(x) x <- x[1,] )
>> 
>> 
>> How do i make a dataframe out of the last result,
>> which looks like "tester", without looping? (i can
>> use rbind in a for loop, but is rather slow)
>> 
>> thanks for your help,
>> 
>> Remko Duursma
>> 
>> 
>>
>____________________________________________________________
>> Get advanced SPAM filtering on Webmail or POP Mail
>> ... Get Lycos Mail!
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>>
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>__________________________________________________
>Do you Yahoo!?

>http://search.yahoo.com
>


From tlumley at u.washington.edu  Wed Apr 16 20:32:18 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 16 Apr 2003 11:32:18 -0700 (PDT)
Subject: [R] help about the dist() error message
In-Reply-To: <20030416165513.38097.qmail@web11706.mail.yahoo.com>
Message-ID: <Pine.A41.4.44.0304161130240.136078-100000@homer34.u.washington.edu>

On Wed, 16 Apr 2003, Meng Xue wrote:

> hello,
>
> I have a problem when call dist() of package mva on a large data
> set. The following error message are obtained when I use dist()
> on m, a two dimensional data set with the size 100,000. It seems
> that the length of vector out of bound, since when I compute
> dist on small data set(10,000), it works well. but for large
> data set, it   exit with the message "negative length vector are
> not allowed" .
>

With 100,000 points there are 50 billion pairwise distances, which would
take at least 400 Gb of memory.  It probably wouldn't even fit on your
disk, let alone in memory.

You need to work out why you want the pairwise distances and decide what
you can do instead.

	-thomas


From wl at eimb.ru  Wed Apr 16 20:35:20 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Wed, 16 Apr 2003 22:35:20 +0400
Subject: [R] layout.show()
Message-ID: <13941.030416@eimb.ru>

Dear r-help,

  Please, be so kind, tell me what does mean the parameter of layout.show()?
  I use R 1.6.2... Windows NT 4.0
  
  Unfortunately I cannot understand phrases from the help
  "n: number of figures to plot."
        what figures?

  "`layout.show(n)' plots (part of) the current layout, namely the
    outlines of the next `n' figures."

    what figures?
    what does 'next' mean?

 I'm still trying to draw a legend outside a graph :)

    layout(matrix(c(1:2))) creates a wonderful layout.

calls to

    plot.formula(...
    lines(...
    points(...
    axis(1,at=c(1979:2002));

draw a beautiful graph.

but call to
    layout.show(1) (or any other parameter instead of 1) destroys it.

what should I say to the R to make it keep already drawn graphs and
show a legend on the other "panel" of the layout?
-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru

==========================================================================
Research Scientist                                Leninsky Prospect 33,
Space Monitoring & Ecoinformation Systems Sector, Moscow, Russia, 119071,
Institute of Ecology,                             Phone: (095) 135-9972;
Russian Academy of Sciences                       Fax: (095) 954-5534


From den.duurs at lycos.com  Wed Apr 16 20:34:30 2003
From: den.duurs at lycos.com (Remko Duursma)
Date: Wed, 16 Apr 2003 11:34:30 -0700
Subject: [R] wait, t(sapply()) does not work
Message-ID: <GFGFJABPNJKMBAAA@mailcity.com>

I just noticed that the code

data.frame(t(sapply(tester.L, function(x) x <- x[1,])))

does not result in a nice dataframe, although is.data.frame gives TRUE. It works on the small example in the previous emails, but something weird happens for a larger dataset.

remko


From mschwartz at medanalytics.com  Wed Apr 16 20:40:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 16 Apr 2003 13:40:03 -0500
Subject: [R] import data from Matlab & error msg when install package
	"e1071"
In-Reply-To: <Pine.SOL.4.33.0304161058020.7032-100000@panther.cs.ucla.edu>
Message-ID: <012c01c30447$9dd866e0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Yan Yu
>Sent: Wednesday, April 16, 2003 1:08 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] import data from Matlab & error msg when install 
>package "e1071"
>
>
>Hello,
>  I am trying to import data from Matlab..
>  when i looked up R documentation, it says, package "e1071" 
>have command
>(read.octave) to import data from octave.
>but when I tried to install package by using: 
>install.packages("e1071"); I got the following message: ( BTW, 
>my platform is linux version 2.4.18-3 my gcc is 2.96).
>
>* Installing *source* package 'e1071' ...
>checking for C++ compiler default output... a.out
>checking whether the C++ compiler works... yes
>checking whether we are cross compiling... no
>checking for suffix of executables...
>checking for suffix of object files... o
>checking whether we are using the GNU C++ compiler... yes 
>checking whether g++ accepts -g... yes
>configure: WARNING: g++ 2.96 cannot reliably be used with this
package.
>configure: error: Please use a different C++ compiler.
>ERROR: configuration failed for package 'e1071'
>
>
>I am wondering did anyone successfully install "e1071" on 
>linux box, what gcc are you using?
>
>Or Is there another way to import data from Matlab?
>
>Thanks a lot,
>yan


There are known problems with gcc 2.96, which was released with some
distros (ie. Red Hat), but was not an official release.  Long story,
but you can probably Google on "gcc 2.96" and get the history. One
place to start is here: http://gcc.gnu.org/gcc-2.96.html.

You can (should) upgrade to a more recent version, either via your
distro's support network or you can go to the gcc web site at
http://gcc.gnu.org/, to download the latest version, which is 3.2.2.

HTH,

Marc Schwartz


From bates at stat.wisc.edu  Wed Apr 16 20:53:17 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 16 Apr 2003 13:53:17 -0500
Subject: [R] help about the dist() error message
In-Reply-To: <Pine.A41.4.44.0304161130240.136078-100000@homer34.u.washington.edu>
References: <Pine.A41.4.44.0304161130240.136078-100000@homer34.u.washington.edu>
Message-ID: <6rel42nujm.fsf@bates4.stat.wisc.edu>

Thomas Lumley <tlumley at u.washington.edu> writes:

> On Wed, 16 Apr 2003, Meng Xue wrote:
> 
> > hello,
> >
> > I have a problem when call dist() of package mva on a large data
> > set. The following error message are obtained when I use dist()
> > on m, a two dimensional data set with the size 100,000. It seems
> > that the length of vector out of bound, since when I compute
> > dist on small data set(10,000), it works well. but for large
> > data set, it   exit with the message "negative length vector are
> > not allowed" .
> >
> 
> With 100,000 points there are 50 billion pairwise distances, which would
> take at least 400 Gb of memory.  It probably wouldn't even fit on your
> disk, let alone in memory.

You exaggerate.  It's a mere 40 GB, I believe.

> N = 100000
> 8*(N * (N - 1))/2
[1] 39999600000
> (8*(N * (N - 1))/2)/2^30
[1] 37.25253


From sbarbar at uni-goettingen.de  Wed Apr 16 20:55:35 2003
From: sbarbar at uni-goettingen.de (salvatore barbaro)
Date: Wed, 16 Apr 2003 20:55:35 +0200
Subject: [R] Information about bootstrap
In-Reply-To: <Law15-F99CuyzC0bHwr000063ed@hotmail.com>
Message-ID: <3E9DC347.32001.1F651B@localhost>

see package boot or alternatively the package bootstrap. Each of them 
based on a famous introduction into the bootstrap - Davison, A.C. and 
Hinkley, D.V. (1997)  Bootstrap Methods and Their Application. 
Cambridge University Press. and Efron, B. and Tibshirani, R. (1993) An 
Introduction to the Bootstrap. Chapman & Hall, resp.

yours

s.





On 16 Apr 2003 at 9:55, felipe mena wrote:

> Hi, I am a chilean student and I am doing my thesis and I?ll very thankfully 
> if you answer a question. In the thesis I need to applied Bootstrap 
> simulations to the residulas for the time series model 
> (AR(1),GARCH(1,1),GARCH-M(1,1)). The question is, the R software have a 
> function to do the Bootstrap simulation or I need to create a algorithm?
>                      Regards
>                                 Felipe Mena.
> 
> 
> 
> 
> 
> _________________________________________________________________
> 
> http://messenger.yupimsn.com/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From Coupal at uwyo.edu  Wed Apr 16 22:21:00 2003
From: Coupal at uwyo.edu (Roger H. Coupal)
Date: Wed, 16 Apr 2003 14:21:00 -0600
Subject: [R] installing a new package in R
Message-ID: <B2E55E2903AAA844B7FC7E70BB97D319016341AC@POSTOFFICE.uwyo.edu>

I am new to R. I am running it on a Mac with Osx. I want to run the
package systemfit on a problem I have but  get a response that the
package was not properly installed. I 've perused the manuals but cannot
seem to find the instructions for installing separate packages on R
under the mac. I'd be very appreciative if someone spelled out the
instructions. I put the package in the library directory, but I guess
there is more to it than that. Thanks.

Roger Coupal
Dept. of Agricultural and Applied Economics
University of Wyoming
307.766.5246
http://Agecon.uwyo.edu/EconDev
http://uwyo.edu/openspaces/index.html


From lina at u.washington.edu  Wed Apr 16 22:39:27 2003
From: lina at u.washington.edu (Michael Na Li)
Date: Wed, 16 Apr 2003 13:39:27 -0700
Subject: [R] failed to load MASS at start up
Message-ID: <dxfzoigosg.fsf@qiuranke.phony.washington.edu>


Just installed R-1.7.0 (with recommended libraries) on RedHat 8.0.  
At R console, I can do

> library (MASS)
> 

just fine.  However, if I put a line 'library(MASS)' into ~/.Rprofile, it
fails to load,

R : Copyright 2003, The R Development Core Team
Version 1.7.0  (2003-04-16)
....
Type `q()' to quit R.

Error in get(x, envir, mode, inherits) : variable "biplot" was not found
Error in library(MASS) : package/namespace load failed
[Previously saved workspace restored]

>

What's happening?  I also tried to load 'lattice' (which I assume is where
biplot is defined) before 'MASS', but got the same error.

Michael


From rab at nauticom.net  Wed Apr 16 23:15:53 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Wed, 16 Apr 2003 17:15:53 -0400
Subject: [R] arima function - estimated coefficients and forecasts
Message-ID: <3E9DC809.8010704@nauticom.net>

I'm using the arima function to estimate coefficients and also using 
predict.Arima to forecast. This works nicely and I can see that the 
results are the same as using SAS's proc arima.

I can also take the coefficent estimates for a simple model like 
ARIMA(2,1,0) and manually compute the forecast. The results agree to 5 
or 6 decimal places. I can do this for models with and without means 
(i.e., using the include.mean argument).

When I include an exogenous variable using the xreg argument, I can't 
manually reproduce the forecast I get when using predict.Arima with the 
newxreg argument, even with just one exogenous variable with an AR(1) 
model for the response.  There does not appear to be any information in 
the arima help file explaining the model when xreg is used. I would have 
thought it was as simple as including an extra term containing the 
product of the coefficient and the value of the exogenous variable. Yet 
I can't manually reproduce the forecast. The manual forecasts seems to 
be off by a constant and a scale factor but I can't for the life of me 
see how I can fix this. Could someone point me in the right direction?

Rick B.


From bates at stat.wisc.edu  Wed Apr 16 23:02:59 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 16 Apr 2003 16:02:59 -0500
Subject: [R] failed to load MASS at start up
In-Reply-To: <dxfzoigosg.fsf@qiuranke.phony.washington.edu>
References: <dxfzoigosg.fsf@qiuranke.phony.washington.edu>
Message-ID: <6rd6jmm9z0.fsf@bates4.stat.wisc.edu>

Michael Na Li <lina at u.washington.edu> writes:

> Just installed R-1.7.0 (with recommended libraries) on RedHat 8.0.  
> At R console, I can do
> 
> > library (MASS)
> > 
> 
> just fine.  However, if I put a line 'library(MASS)' into ~/.Rprofile, it
> fails to load,
> 
> R : Copyright 2003, The R Development Core Team
> Version 1.7.0  (2003-04-16)
> ....
> Type `q()' to quit R.
> 
> Error in get(x, envir, mode, inherits) : variable "biplot" was not found
> Error in library(MASS) : package/namespace load failed
> [Previously saved workspace restored]
> 
> >
> 
> What's happening?  I also tried to load 'lattice' (which I assume is where
> biplot is defined) before 'MASS', but got the same error.

biplot is in mva

> help.search('biplot')
Help files with alias or title matching 'biplot' using fuzzy matching:

corresp(MASS)           Simple Correspondence Analysis
Rows(lattice)           Miscellaneous Functions used within Lattice
panel.bwplot(lattice)   Default Panel Function for bwplot
barchart(lattice)       Common Bivariate Trellis Plots
biplot(mva)             Biplot of Multivariate Data
biplot.princomp(mva)    Biplot for Principal Components

By default mva is loaded but perhaps that does not occur until after
~/.Rprofile is executed.


From SuzieBlatt at netscape.net  Wed Apr 16 23:18:14 2003
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Wed, 16 Apr 2003 17:18:14 -0400
Subject: [R] processing of Fest in spatstat
Message-ID: <4AB4475D.24635A83.0D1322AF@netscape.net>


Hello,

I'm using spatstat and generating G and K function curves, plotting the theoretical lines, etc. etc.  I run multiple programs as batch files and can happily work 'up front' while R number crunches 'in back', until ...

I ask it to generate the F curve with Fest.  When I invoke the 'F word' suddenly my happy coexistence with R, and even Linux, is over.  'Slow' does not do justice to the agony of my waiting for almost a minute (I timed it!) for a click to be responded to, or for a window to become functional.  Further, my panel can mysteriously disappear (with no recovery, it's KDE) and my screen saver does not work. Trying to use ANY other program is futile. 

I'm running spatstat 1.3-1 with R 1.6.1 on SUSE 8.0.  If anyone can explain why Fest results in my computer becoming a large paperweight until it is finished with the batch or file or segment containing 'Fest' it is running (and it won't even indicate that it is done without my 'requesting' it to update the screen), I'd really like to know.  My hubby, who introduced me to R, is fascinated with how often I can make Linux crash, even though our installations are the same and we use the same programs for data analysis and paper writing.

Thanks,
Suzanne


From lina at u.washington.edu  Wed Apr 16 23:22:55 2003
From: lina at u.washington.edu (Michael Na Li)
Date: Wed, 16 Apr 2003 14:22:55 -0700
Subject: [R] failed to load MASS at start up
In-Reply-To: <6rd6jmm9z0.fsf@bates4.stat.wisc.edu> (Douglas Bates's message
 of "16 Apr 2003 16:02:59 -0500")
References: <dxfzoigosg.fsf@qiuranke.phony.washington.edu>
	<6rd6jmm9z0.fsf@bates4.stat.wisc.edu>
Message-ID: <j6wuhuqgr4.fsf@qiuranke.phony.washington.edu>

On 16 Apr 2003, Douglas Bates outgrape:

>  Michael Na Li <lina at u.washington.edu> writes:
>  
> > just fine.  However, if I put a line 'library(MASS)' into ~/.Rprofile, it
> > fails to load,
> > 
> > R : Copyright 2003, The R Development Core Team
> > Version 1.7.0  (2003-04-16)
> > ....
> > Type `q()' to quit R.
> > 
> > Error in get(x, envir, mode, inherits) : variable "biplot" was not found
> > Error in library(MASS) : package/namespace load failed
> > [Previously saved workspace restored]
> > 
> >
>  biplot is in mva
>  
>  biplot(mva)             Biplot of Multivariate Data
>  biplot.princomp(mva)    Biplot for Principal Components
>  
>  By default mva is loaded but perhaps that does not occur until after
>  ~/.Rprofile is executed.
> 

Yes, load mva before MASS (in ~/.Rprofile) solved the problem.

Thanks.

Michael


From p.murrell at auckland.ac.nz  Thu Apr 17 01:05:45 2003
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Thu, 17 Apr 2003 11:05:45 +1200
Subject: [R] layout.show()
References: <13941.030416@eimb.ru>
Message-ID: <3E9DE1C9.6030402@stat.auckland.ac.nz>

Hi

layout.show() is only intended to be used to draw a diagram illustrating 
how the device is being split up into different figure regions by 
layout().  An example from help(layout) demonstrates what it does ...

      nf <- layout(matrix(c(1,1,0,2), 2, 2, byrow=TRUE), respect=TRUE)
      layout.show(nf)

The "n" parameter says how many of the figure regions to draw *in the 
diagram*.  So layout.show() is just there to help you to understand what 
layout() is doing.

For drawing a legend outside a plot, perhaps the following example may 
help (it is a modification of one of the examples in help(legend)) ...

     x <- seq(-pi, pi, len = 65)

     # layout with two columns; second one is 3cm wide
     layout(matrix(1:2, ncol=2),
            widths=c(1, lcm(3)))

     # plot;  goes in first column of layout
     plot(x, sin(x), type = "l", ylim = c(-1.2, 1.8), col = 3,
          lty = 2)
     points(x, cos(x), pch = 3, col = 4)
     lines(x, tan(x), type = "b", lty = 1, pch = 4, col = 6)
     title("legend(..., lty = c(2, -1, 1), pch = c(-1,3,4), merge=TRUE)",
           cex.main = 1.1)

     # legend (as separate plot);  goes in second column of layout
     par(mar=c(5.1, 0, 4.1, 0))
     plot.new()
     plot.window(0:1, 0:1)
     legend(0.5, 0.5,
            xjust=0.5, yjust=0.5,
            c("sin", "cos", "tan"),
            col = c(3, 4, 6),
            lty = c(2, -1, 1),
            pch = c(-1, 3, 4),
            merge = TRUE,
            bg = "gray90")
     par(mar=c(5.1, 4.1, 4.1, 2.1))


Hope that helps.

Paul


Wladimir Eremeev wrote:
> Dear r-help,
> 
>   Please, be so kind, tell me what does mean the parameter of layout.show()?
>   I use R 1.6.2... Windows NT 4.0
>   
>   Unfortunately I cannot understand phrases from the help
>   "n: number of figures to plot."
>         what figures?
> 
>   "`layout.show(n)' plots (part of) the current layout, namely the
>     outlines of the next `n' figures."
> 
>     what figures?
>     what does 'next' mean?
> 
>  I'm still trying to draw a legend outside a graph :)
> 
>     layout(matrix(c(1:2))) creates a wonderful layout.
> 
> calls to
> 
>     plot.formula(...
>     lines(...
>     points(...
>     axis(1,at=c(1979:2002));
> 
> draw a beautiful graph.
> 
> but call to
>     layout.show(1) (or any other parameter instead of 1) destroys it.
> 
> what should I say to the R to make it keep already drawn graphs and
> show a legend on the other "panel" of the layout?


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz


From yanyu at cs.ucla.edu  Thu Apr 17 01:38:42 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Wed, 16 Apr 2003 16:38:42 -0700 (PDT)
Subject: [R] good source for explaining input and output parameters of R
	functions
Message-ID: <Pine.SOL.4.33.0304161629070.29530-100000@panther.cs.ucla.edu>

Hello,
   thank you all for answering my previous Qs.. I have a new Q:
   I am wondering is there good source for explaning input and output
parameters of R function?
  In that aspect, I found the help documents in R is not that helpful:)
I am struggling with trying to understand what some of the returned value
means..
for example, for surf.ls() function, the help in R only describes 3
fields(the wierd thing is that those explained 3 fields are identical to
the input) of returned value, and leave a bunch of others(e.g., like "f"
and "wz"which looks pretty interesting, but i had no clue what they are
about..) unexplained.

Is there any good source if I want to understand the input and output of ,
or how to use a particular R function?

Many thanks,
yan


From p.connolly at hortresearch.co.nz  Thu Apr 17 02:05:22 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 17 Apr 2003 12:05:22 +1200
Subject: [R] make check failure with R-1.7.0
Message-ID: <20030417000522.GD3191@hortresearch.co.nz>

I'm baffled.  When I run make check after installing from source, I
get a Error 2.  From my understanding of how these things work, it
would appear to be coming from this (as at the end of base-Ex.Rout.fail:


> has.VR <- require(MASS, quietly = TRUE)

Attaching package 'MASS':


	The following object(s) are masked from package:base :

	 confint confint.lm nclass.FD nclass.scott vcov vcov.glm vcov.lm 

> if(!has.VR) {
+ ## From Venables and Ripley (2002) p.165.
+ N <- c(0,1,0,1,1,1,0,0,0,1,1,0,1,1,0,0,1,0,1,0,1,1,0,0)
+ P <- c(1,1,0,0,0,1,0,1,1,1,0,0,0,1,0,1,1,0,0,1,0,1,1,0)
+ K <- c(1,0,0,1,0,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,1,0)
+ yield <- c(49.5,62.8,46.8,57.0,59.8,58.5,55.5,56.0,62.8,55.8,69.5,55.0,
+            62.0,48.8,45.5,44.2,52.0,51.5,49.8,48.8,57.2,59.0,53.2,56.0)
+ npk <- data.frame(block=gl(6,4), N=factor(N), P=factor(P),
+                   K=factor(K), yield=yield)
+ }
> 
> op <- options(contrasts=c("contr.helmert", "contr.poly"))
> npk.aov <- aov(yield ~ block + N*P*K, npk)
Error in terms.formula(formula, "Error", data = data) : 
	Object "npk" not found
Execution halted


Why would npk not be found?

best


-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


From spencer.graves at pdf.com  Thu Apr 17 02:13:13 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 16 Apr 2003 17:13:13 -0700
Subject: [R] wait, t(sapply()) does not work
References: <GFGFJABPNJKMBAAA@mailcity.com>
Message-ID: <3E9DF199.3010207@pdf.com>

What are the symptoms?

Do "sapply(tester.L, data.class)".  If some of the attributes of 
tester.L are data.frames, then do, e.g., "sapply(tester.L[[1]], 
data.class)".  If the objects passed to "function(x) x <- x[1,]" are 
data.frames, the ouput of "function(x)x <- x[1,]" may be a list, not a 
vector, with attributes of different classes.

Spencer

Remko Duursma wrote:
> I just noticed that the code
> 
> data.frame(t(sapply(tester.L, function(x) x <- x[1,])))
> 
> does not result in a nice dataframe, although is.data.frame gives TRUE. It works on the small example in the previous emails, but something weird happens for a larger dataset.
> 
> remko
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From andy_liaw at merck.com  Thu Apr 17 02:37:14 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 16 Apr 2003 20:37:14 -0400
Subject: [R] good source for explaining input and output parameters
 of	R functions
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F9D3@usrymx25.merck.com>

It's almost entirely up to the author of the function how much (or little)
to document in the help page.  Packages on CRAN go through some checks, one
of which is that all parameters of functions are documented in the help
page.  However, the return value is another matter.  It's supposed to be
documented in the "Value" section of the help page, but some people don't
bother documenting everything being returned, sometimes because some of them
weren't meant to be used by user directly.

When all else fails, read the R code itself.

HTH,
Andy

> -----Original Message-----
> From: Yan Yu [mailto:yanyu at cs.ucla.edu]
> Sent: Wednesday, April 16, 2003 7:39 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] good source for explaining input and output 
> parameters of R
> functions
> 
> 
> Hello,
>    thank you all for answering my previous Qs.. I have a new Q:
>    I am wondering is there good source for explaning input and output
> parameters of R function?
>   In that aspect, I found the help documents in R is not that 
> helpful:)
> I am struggling with trying to understand what some of the 
> returned value
> means..
> for example, for surf.ls() function, the help in R only describes 3
> fields(the wierd thing is that those explained 3 fields are 
> identical to
> the input) of returned value, and leave a bunch of 
> others(e.g., like "f"
> and "wz"which looks pretty interesting, but i had no clue 
> what they are
> about..) unexplained.
> 
> Is there any good source if I want to understand the input 
> and output of ,
> or how to use a particular R function?
> 
> Many thanks,
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From rpeng at stat.ucla.edu  Thu Apr 17 02:40:50 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 16 Apr 2003 17:40:50 -0700 (PDT)
Subject: [R] good source for explaining input and output parameters of
 R functions
In-Reply-To: <Pine.SOL.4.33.0304161629070.29530-100000@panther.cs.ucla.edu>
Message-ID: <Pine.GSO.4.10.10304161737160.9499-100000@quetelet.stat.ucla.edu>

If certain elements returned by a function are not documented, they are
unlikely to be of much use to the user.  In particular, the help page for
surf.ls() says:

Value:

     list with components

    beta: the coefficients 

       x: 

       y: 

       z: and others for internal use only. 
          

So there are other elements returned but they are only used for internal
computations or whatever.  The user will likely not need them or even be
able to use them intelligently.

If you really want to know what all of the returned values are, the best
place to look is the source code.

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Wed, 16 Apr 2003, Yan Yu wrote:

> Hello,
>    thank you all for answering my previous Qs.. I have a new Q:
>    I am wondering is there good source for explaning input and output
> parameters of R function?
>   In that aspect, I found the help documents in R is not that helpful:)
> I am struggling with trying to understand what some of the returned value
> means..
> for example, for surf.ls() function, the help in R only describes 3
> fields(the wierd thing is that those explained 3 fields are identical to
> the input) of returned value, and leave a bunch of others(e.g., like "f"
> and "wz"which looks pretty interesting, but i had no clue what they are
> about..) unexplained.
> 
> Is there any good source if I want to understand the input and output of ,
> or how to use a particular R function?
> 
> Many thanks,
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From p.connolly at hortresearch.co.nz  Thu Apr 17 03:03:35 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 17 Apr 2003 13:03:35 +1200
Subject: [R] make check failure with R-1.7.0
In-Reply-To: <20030417000522.GD3191@hortresearch.co.nz>
References: <20030417000522.GD3191@hortresearch.co.nz>
Message-ID: <20030417010335.GE3191@hortresearch.co.nz>

On Thu, 17-Apr-2003 at 12:05PM +1200, Patrick Connolly wrote:

|> I'm baffled.  When I run make check after installing from source, I
|> get a Error 2.  From my understanding of how these things work, it
|> would appear to be coming from this (as at the end of base-Ex.Rout.fail:
|> 
|> 
|> > has.VR <- require(MASS, quietly = TRUE)
|> 
|> Attaching package 'MASS':
|> 
|> 
|> 	The following object(s) are masked from package:base :
|> 
|> 	 confint confint.lm nclass.FD nclass.scott vcov vcov.glm vcov.lm 
|> 
|> > if(!has.VR) {
|> + ## From Venables and Ripley (2002) p.165.
|> + N <- c(0,1,0,1,1,1,0,0,0,1,1,0,1,1,0,0,1,0,1,0,1,1,0,0)
|> + P <- c(1,1,0,0,0,1,0,1,1,1,0,0,0,1,0,1,1,0,0,1,0,1,1,0)
|> + K <- c(1,0,0,1,0,1,1,0,0,1,0,1,0,1,1,0,0,0,1,1,1,0,1,0)
|> + yield <- c(49.5,62.8,46.8,57.0,59.8,58.5,55.5,56.0,62.8,55.8,69.5,55.0,
|> +            62.0,48.8,45.5,44.2,52.0,51.5,49.8,48.8,57.2,59.0,53.2,56.0)
|> + npk <- data.frame(block=gl(6,4), N=factor(N), P=factor(P),
|> +                   K=factor(K), yield=yield)
|> + }
|> > 
|> > op <- options(contrasts=c("contr.helmert", "contr.poly"))
|> > npk.aov <- aov(yield ~ block + N*P*K, npk)
|> Error in terms.formula(formula, "Error", data = data) : 
|> 	Object "npk" not found
|> Execution halted
|> 
|> 
|> Why would npk not be found?

OK, it's somewhat clearer now.  Since npk is only created if !has.VR
is TRUE, it won't happen unless MASS isn't available.  I don't think
that's the intention.

But everyone who doesn't have an npk object will have the same
problem, so I'd expect that means everyone who runs that script.

Anyone with a better experience?

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


From andy_liaw at merck.com  Thu Apr 17 04:00:38 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 16 Apr 2003 22:00:38 -0400
Subject: [R] good source for explaining input and output parameters
 of	R functions
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F9D5@usrymx25.merck.com>

I forgot to mention this: It may be unsafe to use undocumented
 part of returned value.  One possible reason that some parts 
are not documented is that they are subject to change without 
notice, and not considered part of the API.

Andy

> From: Liaw, Andy [mailto:andy_liaw at merck.com]
> 
> It's almost entirely up to the author of the function how 
> much (or little)
> to document in the help page.  Packages on CRAN go through 
> some checks, one
> of which is that all parameters of functions are documented 
> in the help
> page.  However, the return value is another matter.  It's 
> supposed to be
> documented in the "Value" section of the help page, but some 
> people don't
> bother documenting everything being returned, sometimes 
> because some of them
> weren't meant to be used by user directly.
> 
> When all else fails, read the R code itself.
> 
> HTH,
> Andy
> 
> > -----Original Message-----
> > From: Yan Yu [mailto:yanyu at cs.ucla.edu]
> > Sent: Wednesday, April 16, 2003 7:39 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] good source for explaining input and output 
> > parameters of R
> > functions
> > 
> > 
> > Hello,
> >    thank you all for answering my previous Qs.. I have a new Q:
> >    I am wondering is there good source for explaning input 
> and output
> > parameters of R function?
> >   In that aspect, I found the help documents in R is not that 
> > helpful:)
> > I am struggling with trying to understand what some of the 
> > returned value
> > means..
> > for example, for surf.ls() function, the help in R only describes 3
> > fields(the wierd thing is that those explained 3 fields are 
> > identical to
> > the input) of returned value, and leave a bunch of 
> > others(e.g., like "f"
> > and "wz"which looks pretty interesting, but i had no clue 
> > what they are
> > about..) unexplained.
> > 
> > Is there any good source if I want to understand the input 
> > and output of ,
> > or how to use a particular R function?
> > 
> > Many thanks,
> > yan
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> --------------------------------------------------------------
> ----------------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (Whitehouse 
> Station, New Jersey, USA) that may be confidential, 
> proprietary copyrighted and/or legally privileged, and is 
> intended solely for the use of the individual or entity named 
> in this message.  If you are not the intended recipient, and 
> have received this message in error, please immediately 
> return this by e-mail and then delete it.
> 
> ==============================================================
> ================
>


From gisar at nus.edu.sg  Thu Apr 17 04:22:16 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Thu, 17 Apr 2003 10:22:16 +0800
Subject: [R] layout.show()
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F242@MBXSRV03.stf.nus.edu.sg>

You can partition the plotting region into an arrangement of smaller
plotting regions using nf <- layout(...). This allows you to put several
plots of different sizes on the same graph. Layout also allows you to
control where the sub plots go.

But it can be difficult to know if you have entered the correct
parameters else the ordering or number of plots can be screwed up.
layout.show(nf) shows you the locations where the 1st, 2nd, ... graph
will be plotted. 

Not only is it a very handy check before you plot but you can reuse the
same design if you plan on doing this repeatedly. Calling layout.show()
AFTER plotting a graph will certainly destroy the previous plot. Try
running the example in layout().


-----Original Message-----
From: Wladimir Eremeev [mailto:wl at eimb.ru] 
Sent: Thursday, April 17, 2003 2:35 AM
To: r-help at stat.math.ethz.ch
Subject: [R] layout.show()


Dear r-help,

  Please, be so kind, tell me what does mean the parameter of
layout.show()?
  I use R 1.6.2... Windows NT 4.0
  
  Unfortunately I cannot understand phrases from the help
  "n: number of figures to plot."
        what figures?

  "`layout.show(n)' plots (part of) the current layout, namely the
    outlines of the next `n' figures."

    what figures?
    what does 'next' mean?

 I'm still trying to draw a legend outside a graph :)

    layout(matrix(c(1:2))) creates a wonderful layout.

calls to

    plot.formula(...
    lines(...
    points(...
    axis(1,at=c(1979:2002));

draw a beautiful graph.

but call to
    layout.show(1) (or any other parameter instead of 1) destroys it.

what should I say to the R to make it keep already drawn graphs and show
a legend on the other "panel" of the layout?
-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru

========================================================================
==
Research Scientist                                Leninsky Prospect 33,
Space Monitoring & Ecoinformation Systems Sector, Moscow, Russia,
119071,
Institute of Ecology,                             Phone: (095) 135-9972;
Russian Academy of Sciences                       Fax: (095) 954-5534

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From edd at debian.org  Thu Apr 17 04:36:16 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 16 Apr 2003 21:36:16 -0500
Subject: [R] Debian packages for R-1.7.0 available
In-Reply-To: <x2n0iqa79v.fsf@biostat.ku.dk>
References: <x2n0iqa79v.fsf@biostat.ku.dk>
Message-ID: <20030417023616.GA30170@sonny.eddelbuettel.com>


Earlier today Doug Bates uploaded R 1.7.0 packages for Debian, which will be
installed into the master Debian archive, and which should be available on
mirrors soon afterwards. Doug also prepared versions for testing and stable
which are available via the Debian section of CRAN rather than the Debian
mirrors.

All these 1.7.0 versions builds upon the 7 pre-releases we made of R 1.7.0.
One noteworthy change is that the R_LIBS variable is now set. Its default
value, set via /etc/R/Renviron (to which /usr/lib/R/etc/Renviron links) sets
up three directories such that /usr/local/lib/R/site-library will
automatically be used for user-installed R packages, /usr/lib/R/site-library
is available for use by Debian R packages (such as, e.g., r-cran-tseries)
and /usr/lib/R/library will be used by packages contained in a main R
release such as 1.7.0.  We also improved upon our support for Atlas versions
of Lapack and Blas, and made some other smaller changes.

Regards,  Dirk

-- 
Better to have an approximate answer to the right question than a precise 
answer to the wrong question.  --  John Tukey as quoted by John Chambers


From cariello at mindspring.com  Thu Apr 17 04:54:07 2003
From: cariello at mindspring.com (Neal Cariello)
Date: Wed, 16 Apr 2003 22:54:07 -0400
Subject: [R] R Install problems with Redhat 9 : "tcl.so" versus "tcl.so.0"
Message-ID: <000001c3048c$9dc48360$6401a8c0@bigdell2k>

Hi,

I'm having problems with a R Redhat Linux install.  Please bear with me,
I've only been working with Linux for about a week here.

I have Redhat Linux 9 running on a recent Pentium machine.  Here's the
install, showing I'm running kernel release 2.4.20-6.

[root at localhost root]# uname -a
Linux localhost.localdomain 2.4.20-6 #1 Thu Feb 27 10:06:59 EST 2003 i686
i686 i386 GNU/Linux

I've downloaded R for linux Redhat 8.x, but I am running Redhat 9.  I'm
assuming we have backward compatibility ?

To continue, attemping to load R produces the following errors:

[root at localhost temp]# rpm -ivh R-1.6.2-1.i386.rpm
warning: R-1.6.2-1.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
error: Failed dependencies:
        libtcl.so.0 is needed by R-1.6.2-1
        libtk.so.0 is needed by R-1.6.2-1

OK, I understand this so far.  So I go to http://rpmfind.net/linux/RPM/ to
get the packages.  Searching for "libtcl.so.0" shows me that's it's in the
tcl package.  The most current one from http://rpmfind.net/linux/RPM/ is
tcl-8.3.3-74.i386.rpm.

However, after considerable gnashing of teeth, I come to discover that tcl
is already on my machine as the following command shows:

[root at localhost temp]# rpm -qa | grep tcl
tcl-8.3.5-88

NOTE - tcl-8.3.5-88 that I have on my machine is newer than anything I found
on the Web, so when I tried to install the downloaded tcl-8.3.3-74.i386.rpm,
it of course fails with "warning: tcl-8.3.3-74.i386.rpm: V3 DSA signature:
NOKEY, key ID db42a60e package tcl-8.3.5-88 (which is newer than
tcl-8.3.3-74) is already installed".

Here's all files on my system with filename *libtcl*:

[root at localhost root]# locate libtcl
/usr/lib/libtcl.so
/usr/lib/libtcl8.3.so
/usr/lib/libtclstub8.3.a

Is the "libtcl.so" really the "libtcl.so.0" that R is looking for ?  If so,
do I try and fool R somehow ?

Any idea why libtcl.so.0 is not being found in my installed tcl-8.3.5-88 ?

If this is heading towards source code compiling, please be explicit, I've
not done this before !

Grovelling for advice,
Neal in NC


From p.connolly at hortresearch.co.nz  Thu Apr 17 05:46:28 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 17 Apr 2003 15:46:28 +1200
Subject: [R] make check failure with R-1.7.0
In-Reply-To: <20030417022229.GC25909171@genome.cbs.dtu.dk>
References: <20030417000522.GD3191@hortresearch.co.nz>
	<20030417022229.GC25909171@genome.cbs.dtu.dk>
Message-ID: <20030417034627.GF3191@hortresearch.co.nz>

On Thu, 17-Apr-2003 at 04:22AM +0200, Laurent Gautier wrote:

|> I'm even more puzzled... I installed R1.7.0 from source
|> and R check hangs on:
|> make[3]: Entering directory `/home/laurent/R-release/tests'
|> running code in 'internet.R' ...
|> 
|> (Linux and Mdk9.1).
|> 
|> 
|> Which OS did you compile it on  ?

Sorry.  Forgot to mention:

platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    7.0              
year     2003             
month    04               
day      16               
language R                

Redhat 7.3.  

I'm compiling without root access, which you appear to be doing.  I
got a lot further when I tinkered with the base-Ex.R file, seeming to
have no problem with internet.R.  You seem to be saying you didn't
have the problem I had.  I'd be interested to know how that could be.

You should be able to find a 'fail' file to see what didn't work.  In
your case, it would be
/home/laurent/R-release/tests/internet.Rout.fail



I've run into another one with some data called cement at the end
(line 871) of reg-tests-2.Rout.  So far, I can't work out where it
should be findable from.

Ideas welcome.

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


From p.connolly at hortresearch.co.nz  Thu Apr 17 06:40:43 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 17 Apr 2003 16:40:43 +1200
Subject: [R] make check failure with R-1.7.0
In-Reply-To: <20030417034627.GF3191@hortresearch.co.nz>
References: <20030417000522.GD3191@hortresearch.co.nz>
	<20030417022229.GC25909171@genome.cbs.dtu.dk>
	<20030417034627.GF3191@hortresearch.co.nz>
Message-ID: <20030417044043.GH3191@hortresearch.co.nz>

On Thu, 17-Apr-2003 at 03:46PM +1200, Patrick Connolly wrote:


|> I've run into another one with some data called cement at the end
|> (line 871) of reg-tests-2.Rout.  So far, I can't work out where it
|> should be findable from.

Pleased to report, I found the problem was with an old MASS library
that was being used.  Easy once you know. :-)

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


From yanyu at cs.ucla.edu  Thu Apr 17 08:44:40 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Wed, 16 Apr 2003 23:44:40 -0700 (PDT)
Subject: [R] Q on spatial package 
Message-ID: <Pine.SOL.4.33.0304162338160.13019-100000@panther.cs.ucla.edu>

Hi, there,
   I would like to compute covariance or variogram matrix on some data
set..
"expcov" or "variogram" function  basically give me a big look up table,
say map covariance value to some lag distance..

I suppose one way to get the covariance matrix is to first generate a fine
grained lookup table, when i need a covariance value for some distance
value, I can look in the big lookup table, find the closet match??
It is sort of a tedious job even if i write some program to do it..
I am wondering is there some built in functionality to acheive that?

Or is there an easier way to generate covariance matrix??

any suggestions is appreciated,
yan


From mike_rphd at yahoo.com  Thu Apr 17 08:45:12 2003
From: mike_rphd at yahoo.com (Mike Sumner)
Date: Wed, 16 Apr 2003 23:45:12 -0700 (PDT)
Subject: [R] bit set or bit test 
Message-ID: <20030417064512.35898.qmail@web10703.mail.yahoo.com>

Hello, does R have functions for setting and testing
bit values?

I want to conserve memory for storing presence/absence
data for large multiple arrays within a single array,
using element values like

present[x,y] <- ntharray[x,y]*(2^n)

where presence is 1, non-presence is 0 and n is the
nth array

e.g.  1*(2^0) + 0*(2^1) + 0*(2^2) + 1*(2^3) + 0(2^4) 

for storing the value 9 for presence in the first and
fourth array, and absence in the second, third and
fifth arrays.  

Does R already have something to handle stuff like
this?

Cheers, Mike.


From yanyu at cs.ucla.edu  Thu Apr 17 08:45:48 2003
From: yanyu at cs.ucla.edu (Yan Yu)
Date: Wed, 16 Apr 2003 23:45:48 -0700 (PDT)
Subject: [R] a quick Q on dataframe
Message-ID: <Pine.SOL.4.33.0304162344470.13019-100000@panther.cs.ucla.edu>

How to make a dataframe from a vector or matrix?

thanks,
yan


From s195404 at student.uq.edu.au  Thu Apr 17 09:04:54 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Thu, 17 Apr 2003 07:04:54 +0000
Subject: [R] a quick Q on dataframe
In-Reply-To: <Pine.SOL.4.33.0304162344470.13019-100000@panther.cs.ucla.edu>
References: <Pine.SOL.4.33.0304162344470.13019-100000@panther.cs.ucla.edu>
Message-ID: <1050563094.3e9e52162106c@my.uq.edu.au>

?as.data.frame
?cbind.data.frame


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au


Quoting Yan Yu <yanyu at cs.ucla.edu>:

> How to make a dataframe from a vector or matrix?
> 
> thanks,
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From ynoel at tele2.fr  Thu Apr 17 09:28:29 2003
From: ynoel at tele2.fr (Yvonnick Noel)
Date: Thu, 17 Apr 2003 09:28:29 +0200
Subject: [R] Help with TCL packages
Message-ID: <000901c304b2$f281f9c0$ae4860d4@YvonnickNol>

Hello,

I am exploring the TCLTK package under R and try to load and use additional TCL libraries (under Windows, with TCL8.3). For example :

> addTclPath("C:/TCL/lib/bwidget1.5")
> tclRequire("BWidget")
<Tcl> 1.5

Loading seems to work, but when I try to create a specific widget :

# The main window appears correctly
> top=tktoplevel()

# Trying to insert a combobox
> combo <- tkwidget(top,"BWidget::combobox")
Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class = "tclObj") : 
        [tcl] invalid command name "BWidget::combobox".

The file combobox.tcl is present in the BWidget directory.

I wonder what I'm doing wrong. Any idea ?

Yvonnick NOEL


From vito.muggeo at giustizia.it  Thu Apr 17 09:45:41 2003
From: vito.muggeo at giustizia.it (vito muggeo)
Date: Thu, 17 Apr 2003 09:45:41 +0200
Subject: [R] A function as argument of another function
Message-ID: <003a01c304b5$5f397aa0$5c13070a@it.giustizia.it>

Dear all,
I would like to write a function like:
myfun<-function(x,fn) {xx<-exp(x); x*fn(xx)}
where fn is a symbolic description of any function with its argument to be
specified. Therefore
myfun(5,"2+0.3*y^2")
should return 5*(2+0.3*exp(5)^2),
myfun(5,"log(y)") should return 5*log(exp(5)) and so on.

I tried with "expression" and others, but without success. How can I solve
my problem?

Many thanks,
vito


From laurent.faisnel at ariase.com  Thu Apr 17 09:50:37 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Thu, 17 Apr 2003 09:50:37 +0200
Subject: [R] unable to load package RPgSQL
References: <3E9D50C0.4040506@ariase.com>
	<20030416134641.GA24603@sonny.eddelbuettel.com>
Message-ID: <3E9E5CCD.1060008@ariase.com>

Dirk Eddelbuettel wrote:

>On Wed, Apr 16, 2003 at 02:46:56PM +0200, Laurent Faisnel wrote:
>  
>
>>I'm trying to install an add-on package for R called RPgSQL. Its role 
>>    
>>
>[...]
>  
>
>>   * The installation then seemed to be a success : 
>>    
>>
>
>Not exactly as ...
>
>  
>
>>R CMD INSTALL /home/faisnel/PostGresSql/RPgSQL_1.0-0.tar.gz 
>>--configure-args='--with-pgsql-libraries=/usr/local/pgsql/lib 
>>--with-pgsql-includes=/usr/local/pgsql/include'
>>* Installing *source* package 'RPgSQL' ...
>>creating cache ./config.cache
>>checking for crypt in -lcrypt... yes
>>checking how to run the C preprocessor... cc -E
>>checking for /usr/include/libpq-fe.h... no
>>checking how to run the C preprocessor... cc -E
>>checking for /usr/include/pgsql/libpq-fe.h... no
>>checking how to run the C preprocessor... cc -E
>>checking for /usr/include/postgresql/libpq-fe.h... no
>>checking how to run the C preprocessor... cc -E
>>checking for /usr/local/include/libpq-fe.h... no
>>checking how to run the C preprocessor... cc -E
>>checking for /usr/local/include/pgsql/libpq-fe.h... no
>>checking how to run the C preprocessor... cc -E
>>checking for /usr/local/include/postgresql/libpq-fe.h... no
>>checking how to run the C preprocessor... cc -E
>>checking for /opt/include/libpq-fe.h... no
>>checking how to run the C preprocessor... cc -E
>>checking for /opt/include/pgsql/libpq-fe.h... no
>>checking how to run the C preprocessor... cc -E
>>checking for /opt/include/postgresql/libpq-fe.h... no
>>updating cache ./config.cache
>>creating ./config.status
>>creating src/Makevars
>>    
>>
>
>... it told you about nine times that a header file is amiss.  I would call
>it a bug in RPgSQL that it even progrsses as it will obviously fail later
>at the point you noticed.
>
>Bottom line: install the required postgresql header files package, and try
>again.
>
>Hth, Dirk
>
>  
>
Thank you for your fast help. I desperately tried to install the header 
files yesterday, but it seemed to me they were already there. The 
solution was given to me this morning. I had to set an environment 
variable to the correct value (LD_LIBRARY_PATH), and nothing to install.
I gave the path to the libraries, so that the computer could find 
libpq.so.3, and it worked at once.

Laurent


From Ramlau at gmx.de  Thu Apr 17 10:11:07 2003
From: Ramlau at gmx.de (Ramlau@gmx.de)
Date: Thu, 17 Apr 2003 10:11:07 +0200 (MEST)
Subject: [R] Simulation of recurrent events
Message-ID: <29294.1050567067@www45.gmx.net>

I'd like to program a simulation of recurrent events to test few models in
R. Is there anybody who has experience of that and could give me advice?

Your help is greatly appreciated!

Regards, 

-- 
Peggy Ramlau
ramlau at gmx.de
+493080906358


Bitte l?cheln! Fotogalerie online mit GMX ohne eigene Homepage!


From maechler at stat.math.ethz.ch  Thu Apr 17 10:13:10 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 17 Apr 2003 10:13:10 +0200
Subject: [R] A function as argument of another function
In-Reply-To: <003a01c304b5$5f397aa0$5c13070a@it.giustizia.it>
References: <003a01c304b5$5f397aa0$5c13070a@it.giustizia.it>
Message-ID: <16030.25110.309065.58742@gargle.gargle.HOWL>

>>>>> "vito" == vito muggeo <vito.muggeo at giustizia.it>
>>>>>     on Thu, 17 Apr 2003 09:45:41 +0200 writes:

(MM: I've added " " around "<-" and empty lines:)

    vito> Dear all,
    vito> I would like to write a function like:

    vito> myfun <- function(x,fn) {xx<-exp(x); x*fn(xx)}

    vito> where fn is a symbolic description of any function
    vito> with its argument to be specified. Therefore

    vito> myfun(5,"2+0.3*y^2")
    vito> should return 5*(2+0.3*exp(5)^2),

    vito> myfun(5,"log(y)") should return 5*log(exp(5)) and so on.

    vito> I tried with "expression" and others, but without
    vito> success. How can I solve my problem?

As you say yourself in the subject, the argument must be a
*function*, not a string or an expression, e.g.,  
   function(y) y^2  

is a function.  So,

  myfun <- function(x,fn) { xx <- exp(x); x*fn(xx) }
  myfun(5, function(y) 2+0.3*y^2)

gives 33049.7, as desired.

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/


From mkondrin at hppi.troitsk.ru  Thu Apr 17 21:32:32 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Thu, 17 Apr 2003 12:32:32 -0700
Subject: [R] R Install problems with Redhat 9 : "tcl.so" versus "tcl.so.0"
References: <000001c3048c$9dc48360$6401a8c0@bigdell2k>
Message-ID: <3E9F0150.4070302@hppi.troitsk.ru>

Neal Cariello wrote:
> Hi,
> 
> I'm having problems with a R Redhat Linux install.  Please bear with me,
> I've only been working with Linux for about a week here.
> 
> I have Redhat Linux 9 running on a recent Pentium machine.  Here's the
> install, showing I'm running kernel release 2.4.20-6.
> 
> [root at localhost root]# uname -a
> Linux localhost.localdomain 2.4.20-6 #1 Thu Feb 27 10:06:59 EST 2003 i686
> i686 i386 GNU/Linux
> 
> I've downloaded R for linux Redhat 8.x, but I am running Redhat 9.  I'm
> assuming we have backward compatibility ?
> 
> To continue, attemping to load R produces the following errors:
> 
> [root at localhost temp]# rpm -ivh R-1.6.2-1.i386.rpm
> warning: R-1.6.2-1.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
> error: Failed dependencies:
>         libtcl.so.0 is needed by R-1.6.2-1
>         libtk.so.0 is needed by R-1.6.2-1
> 
> OK, I understand this so far.  So I go to http://rpmfind.net/linux/RPM/ to
> get the packages.  Searching for "libtcl.so.0" shows me that's it's in the
> tcl package.  The most current one from http://rpmfind.net/linux/RPM/ is
> tcl-8.3.3-74.i386.rpm.
> 
> However, after considerable gnashing of teeth, I come to discover that tcl
> is already on my machine as the following command shows:
> 
> [root at localhost temp]# rpm -qa | grep tcl
> tcl-8.3.5-88
> 
> NOTE - tcl-8.3.5-88 that I have on my machine is newer than anything I found
> on the Web, so when I tried to install the downloaded tcl-8.3.3-74.i386.rpm,
> it of course fails with "warning: tcl-8.3.3-74.i386.rpm: V3 DSA signature:
> NOKEY, key ID db42a60e package tcl-8.3.5-88 (which is newer than
> tcl-8.3.3-74) is already installed".
> 
> Here's all files on my system with filename *libtcl*:
> 
> [root at localhost root]# locate libtcl
> /usr/lib/libtcl.so
> /usr/lib/libtcl8.3.so
> /usr/lib/libtclstub8.3.a
> 
> Is the "libtcl.so" really the "libtcl.so.0" that R is looking for ?  If so,
> do I try and fool R somehow ?
> 
> Any idea why libtcl.so.0 is not being found in my installed tcl-8.3.5-88 ?
> 
> If this is heading towards source code compiling, please be explicit, I've
> not done this before !
> 
> Grovelling for advice,
> Neal in NC
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

If you haven't /usr/lib/libtcl.so.0 on your system I would suggest to 
make a symlink ln -s /usr/lib/libtcl8.3.so /usr/lib/libtcl.so.0

May be ldconfig is also required.

May be you will need to repeat this operation with libtk.so.0


From JonesW at kssg.com  Thu Apr 17 10:30:18 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Thu, 17 Apr 2003 09:30:18 +0100
Subject: [R] Testing for randomness
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB01EE213B@GIMLI>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030417/f06ad1c9/attachment.pl

From r.lambkin at retroscreen.com  Thu Apr 17 10:50:39 2003
From: r.lambkin at retroscreen.com (Rob Lambkin)
Date: Thu, 17 Apr 2003 09:50:39 +0100
Subject: [R] Validation of R
Message-ID: <4E80833214549243A7D982F979A7979603BDE963@EXBENS01GB1.netstore.local>

Hi All

I am really very interested in starting to use R within our company. I
particularly like the open source nature of the product. My company is a
medical research company which is part of the University of London.

We conduct contract virology research for large pharma companies. My
question is how do we validate this software? I wonder if anyone else
has had the problem and might be able to comment.

Thanks

Rob


Robert Lambkin BSc (Hon's), MRPharmS, PhD
Director and General Manager
Retroscreen Limited 
Retroscreen Virology Limited
The Medical Building, Queen Mary, University of London,   327 Mile End
Road, London, E1 4NS
Tel: 020 7882 7624  Fax: 020 7882 6990
(Retroscreen Virology Ltd. Registered in England & Wales No:2326557) 
 
The information contained in this message is confidential and is
intended for the addressee(s) only. If you have received this message in
error or there are any problems please notify the originator
immediately. 
 
Unauthorised use, disclosure, copying or alteration of this message is
strictly forbidden.

Retroscreen Virology Limited will not be liable for any action taken in
reliance on the data contained in this e-mail as it may not have been
quality assessed or assured.


From otoomet at econ.dk  Thu Apr 17 10:02:12 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Thu, 17 Apr 2003 10:02:12 +0200
Subject: [R] A function as argument of another function
In-Reply-To: <003a01c304b5$5f397aa0$5c13070a@it.giustizia.it>
	(vito.muggeo@giustizia.it)
References: <003a01c304b5$5f397aa0$5c13070a@it.giustizia.it>
Message-ID: <200304170802.h3H82Cu10395@punik.econ.au.dk>

Pronto,

It is very easy.  You have to define your fn as a function:

myfun <- function(x,fn) {xx<-exp(x); x*fn(xx)}
testf <- function(y) 2 + 0.3*y^2
myfun(5, testf)

or you may write

myfun(5, function(y) 2 + 0.3*y^2)

In your example you passed a character string into the function, I am
pretty sure it can be transformed into function but you don't need to.

Cheers,

Ott

 | From: "vito muggeo" <vito.muggeo at giustizia.it>
 | Date: Thu, 17 Apr 2003 09:45:41 +0200
 | 
 | Dear all,
 | I would like to write a function like:
 | myfun<-function(x,fn) {xx<-exp(x); x*fn(xx)}
 | where fn is a symbolic description of any function with its argument to be
 | specified. Therefore
 | myfun(5,"2+0.3*y^2")
 | should return 5*(2+0.3*exp(5)^2),
 | myfun(5,"log(y)") should return 5*log(exp(5)) and so on.
 | 
 | I tried with "expression" and others, but without success. How can I solve
 | my problem?


From ernesto at ipimar.pt  Thu Apr 17 10:52:33 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 17 Apr 2003 09:52:33 +0100
Subject: [R] kriging in R
In-Reply-To: <Pine.SOL.4.33.0304162133460.11965-100000@panther.cs.ucla.edu>
References: <Pine.SOL.4.33.0304162133460.11965-100000@panther.cs.ucla.edu>
Message-ID: <1050569553.26483.10.camel@gandalf.ipimar.pt>

Hi

If you read the description of "varcov.spatial" you'll see that it is
used to *predict* a covariance matrix, based on the parameters of the
covariance function. So you don't need the oebserved data, you need
parameters for the covariance function.

Regards

EJ

On Thu, 2003-04-17 at 05:43, Yan Yu wrote:
> THanks for the suggestion.
> I have a Q when trying to use it..
> I want to get covariance matrix from the data set in hand..
> basically i have a rainfall data set in a 15x12 points.
> i try to use:
> "varcov.spatial", but it seems that the input to that function is just
> coordinate list of the data values, not the actual data at those points.
> I am confused by this?
>  How come the covariance matrix or variogram matrix is irrelevant to the
> the data value, but only depends on the data configuration(i.e., the
> sampling locations)?
> I found other covariance functions, like cor.number or cov.spatial is
> similar in the sense that they only ask for data locations, not data values..
> 
> Any hints or pointer is appreciated!
> yan
> 
> 
> On 17 Jan 2003, Ernesto Jardim wrote:
> 
> > Hi
> >
> > I'm working with geostatistics and I use geoR package, which I find very
> > good. However it doesn't implement the classic geostatistics but a
> > "model based geostatistics" as proposed by Peter Diggle and team.
> >
> > R news of June 2001 has an article about geoR by Paulo Ribeiro, the main
> > developer, that you might like to take a look at. I find this number of
> > Rnews a very good source for someone willing to use geostatistics in R.
> >
> > Regards
> >
> > EJ
> >
> > On Fri, 2003-01-17 at 05:06, Yan Yu wrote:
> > > Hi, all,
> > >    Have anyone used kringing included in R?  How is it?
> > > Does it handle anisotropy data well?
> > > How does it compare with Kriging in Arc/Info? or other geostatistics
> > > software customized to do kriging or other geostatistics functions?
> > >
> > > I tried Easykriging, a geostatistics tool developed for Matlab. It has
> > > very nice GUI, but it does not provide library which i can call in my programs.
> > > so it is good for doing it mannually for small number of data set. but if
> > > i have large number of data set, and i want to automate the kriging
> > > process for those data set, Does anyone have good recommendation on what
> > > software to use?  something that can be called in c/c++ code(or matlab)
> > > and freeware:) is preferred..
> > >
> > > Thanks a lot in advance for any input.
> > > yan
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > http://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >


From phgrosjean at sciviews.org  Thu Apr 17 11:30:19 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Thu, 17 Apr 2003 11:30:19 +0200
Subject: [R] gui - script
In-Reply-To: <000501c302c5$adaa7c30$410f6850@paolo>
Message-ID: <MABBLJDICACNFOLGIHJOGEAODGAA.phgrosjean@sciviews.org>

>Hi,

>is R a script language too?
>In affirmative case is it possible to create a GUI - script? How?
>Thank in advance.

>Paolo

R is a language focused at data/statistical analyses, but it is rather
flexible. It is not the simplest one for making a script language (many
features are there for statistical purposes, and complicate the syntax more
than desired for a script language). I may not understand what you mean by
"create a GUI - script", but you should look at http://www.r-project.org/GUI
as a starting point for any GUI-related questions with R.
Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.18, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................


From Bernhard.Pfaff at drkw.com  Thu Apr 17 11:31:38 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Thu, 17 Apr 2003 11:31:38 +0200
Subject: [R] A function as argument of another function
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB900473034B@ibfftce505.is.de.dresdnerkb.com>

Dear all,
I would like to write a function like:
myfun<-function(x,fn) {xx<-exp(x); x*fn(xx)}
where fn is a symbolic description of any function with its argument to be
specified. Therefore
myfun(5,"2+0.3*y^2")
should return 5*(2+0.3*exp(5)^2),
myfun(5,"log(y)") should return 5*log(exp(5)) and so on.

I tried with "expression" and others, but without success. How can I solve
my problem?

Many thanks,
vito

hello Vito,

how about:


myfun <- function(x,fn)
  {
    xx <- exp(x)
    aux <- function(y)
      {
        eval(parse(text=fn))
      }
    x*aux(xx)
  }

myfun(5,"2+0.3*y^2")

as an alternative to Ott's answer.

HTH,
Bernhard

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.


From david.meyer at ci.tuwien.ac.at  Thu Apr 17 11:55:43 2003
From: david.meyer at ci.tuwien.ac.at (David Meyer)
Date: Thu, 17 Apr 2003 11:55:43 +0200
Subject: [R] import data from Matlab & error msg when install package
	"e1071"
References: <Pine.SOL.4.33.0304161058020.7032-100000@panther.cs.ucla.edu>
Message-ID: <3E9E7A1F.673537B3@ci.tuwien.ac.at>

Yan Yu wrote:
> 
> Hello,
>   I am trying to import data from Matlab..
>   when i looked up R documentation, it says, package "e1071" have command
> (read.octave) to import data from octave.
> but when I tried to install package by using:
> install.packages("e1071");
> I got the following message: ( BTW, my platform is linux version 2.4.18-3
> my gcc is 2.96).
> 
> * Installing *source* package 'e1071' ...
> checking for C++ compiler default output... a.out
> checking whether the C++ compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> configure: WARNING: g++ 2.96 cannot reliably be used with this package.
> configure: error: Please use a different C++ compiler.
> ERROR: configuration failed for package 'e1071'
> 
> I am wondering did anyone successfully install "e1071" on linux box, what
> gcc are you using?

Well, not `2.96', apparently, which actually does not exist (see former
messages in the mail archives on this topic). This `version' of gcc is
buggy and at least breaks the `svm' code in e1071, that's why this check
has been added. So you are well advised to upgrade your compiler suite
anyway.

> 
> Or Is there another way to import data from Matlab?
> 

Depends on your data. If you only have tabular data and your MATLAB file
uses ascii representation, `read.table' could be your friend. If you
insist on using `read.octave' from e1071 without updating your
C-compiler, just source the `read.octave.R' file from the source
package, it's plain R code and so is not affected by any C compiler. For
more complex data, you might consider using `StatDataML'---the R package
is on CRAN, the corresponding MATLAB functions will appear at

http://www.omegahat.org/StatDataML/

by the end of this week.

Best,
David.

> Thanks a lot,
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
        Mag. David Meyer            Wiedner Hauptstrasse 8-10
Vienna University of Technology     A-1040 Vienna/AUSTRIA
         Department of              Tel.: (+431) 58801/10772
Statistics and Probability Theory   Fax.: (+431) 58801/10798


From p.dalgaard at biostat.ku.dk  Thu Apr 17 12:00:02 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Apr 2003 12:00:02 +0200
Subject: [R] R Install problems with Redhat 9 : "tcl.so" versus "tcl.so.0"
In-Reply-To: <3E9F0150.4070302@hppi.troitsk.ru>
References: <000001c3048c$9dc48360$6401a8c0@bigdell2k>
	<3E9F0150.4070302@hppi.troitsk.ru>
Message-ID: <x24r4xa1gd.fsf@biostat.ku.dk>

"M.Kondrin" <mkondrin at hppi.troitsk.ru> writes:

> > [root at localhost root]# locate libtcl
> > /usr/lib/libtcl.so
> > /usr/lib/libtcl8.3.so
> > /usr/lib/libtclstub8.3.a
> > Is the "libtcl.so" really the "libtcl.so.0" that R is looking for ?
> > If so,
> > do I try and fool R somehow ?

We had a correspondent from Estonia (Allan Sims) run into that exact
problem (look in the archives). Last I heard, it didn't quite work to
just make the symlinks as suggested below -- rpm would still complain,
even with the links in place. What might work is to "rpm -i --force",
but there could be further problems down the road.

> > Any idea why libtcl.so.0 is not being found in my installed
> > tcl-8.3.5-88 ?

Probably a deliberate cleanup action from RedHat. By their convention,
they can break binary compatibility, including things like that, when
bumping the major version number.

> > If this is heading towards source code compiling, please be
> > explicit, I've
> > not done this before !
> > Grovelling for advice,

I suspect that Martyn will have made RPMs of 1.7.0 for both RH8 and 9
before you'd get through...

Actually, that's not quite fair. Building from source only takes half
an hour *if you have all the prerequisites*, but you lose the package
management (R is very easily uninstalled from /usr/local/, though).
Also note that RH9 has a compiler glitch that needs working around. I
think that was in the thread with Allan Sims too.

> If you haven't /usr/lib/libtcl.so.0 on your system I would suggest to
> make a symlink ln -s /usr/lib/libtcl8.3.so /usr/lib/libtcl.so.0
> 
> May be ldconfig is also required.
> 
> May be you will need to repeat this operation with libtk.so.0

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From adrian.trapletti at lmttrading.com  Thu Apr 17 12:00:15 2003
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Thu, 17 Apr 2003 12:00:15 +0200
Subject: [R] Information about bootstrap
References: <200304170917.h3H9H5UZ028170@hypatia.math.ethz.ch>
Message-ID: <3E9E7B2F.6FBF2F10@lmttrading.com>

> Subject: [R] Information about bootstrap
> Date: Wed, 16 Apr 2003 09:55:07 -0400
> From: "felipe mena" <felipemenasalas at hotmail.com>
> To: R-help at stat.math.ethz.ch
>
> Hi, I am a chilean student and I am doing my thesis and I?ll very thankfully
> if you answer a question. In the thesis I need to applied Bootstrap
> simulations to the residulas for the time series model
> (AR(1),GARCH(1,1),

These models are available in R.

> GARCH-M(1,1)).

This one not.

> The question is, the R software have a
> function to do the Bootstrap simulation or I need to create a algorithm?

In the simplest case you get a bootstrap dataset with, e.g.,

md<-garch(x)
sample(na.remove(residuals(md)),replace=TRUE)

Otherwise you can use tsbootstrap() from tseries, or packages boot and bootstrap.

>
>                      Regards
>                                 Felipe Mena.

best
Adrian

PS: If, for some reason, you want to use a blockwise bootstrap for time series, use the one in tsbootstrap. Blockwise bootstrap in packages boot and bootstrap is not correctly implemented.

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5631
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com


From adrian.trapletti at lmttrading.com  Thu Apr 17 12:06:45 2003
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Thu, 17 Apr 2003 12:06:45 +0200
Subject: [R] Testing for randomness
References: <200304170917.h3H9H5UZ028170@hypatia.math.ethz.ch>
Message-ID: <3E9E7CB5.8DFD48A6@lmttrading.com>

> Subject: [R] Testing for randomness
> Date: Thu, 17 Apr 2003 09:30:18 +0100
> From: Wayne Jones <JonesW at kssg.com>
> To: "'r-help at stat.math.ethz.ch'" <r-help at stat.math.ethz.ch>
>
> Hi there,
>
> Does anyone know whether R has an inbuilt function to test if a series of
> numbers is completely random??

Maybe runs.test, bds.test, Box.test?? (package tseries and ts)

> thanks in advance,
>
> Wayne
>
> Dr Wayne R. Jones
> Statistician / Research Analyst
> KSS Group plc
> St James's Buildings
> 79 Oxford Street
> Manchester M1 6SS
> Tel: +44(0)161 609 4084
> Mob: +44(0)7810 523 713
>
> KSS Ltd
> A division of Knowledge Support Systems Group plc
> Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1 6SS  England
> Company Registration Number 2800886 (Limited) 3449594 (plc)
> Tel: +44 (0) 161 228 0040       Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com           http://www.kssg.com
>
> The information in this Internet email is confidential and may b... {{dropped}}
>

Best
Adrian

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5631
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com


From plummer at iarc.fr  Thu Apr 17 12:10:53 2003
From: plummer at iarc.fr (Martyn Plummer)
Date: 17 Apr 2003 12:10:53 +0200
Subject: [R] R Install problems with Redhat 9 : "tcl.so" versus
	"tcl.so.0"
In-Reply-To: <000001c3048c$9dc48360$6401a8c0@bigdell2k>
References: <000001c3048c$9dc48360$6401a8c0@bigdell2k>
Message-ID: <1050574254.1360.18.camel@xena>

Red Hat 9 is not binary compatible with Red Hat 8.x and you should not
attempt to install an RPM for RH 8.x on a RH 9 system.

An RPM of R 1.7.0 (released yesterday) for RH 9 will be available soon,
but you must exercise some patience.

Martyn

On Thu, 2003-04-17 at 04:54, Neal Cariello wrote:
> Hi,
> 
> I'm having problems with a R Redhat Linux install.  Please bear with me,
> I've only been working with Linux for about a week here.
> 
> I have Redhat Linux 9 running on a recent Pentium machine.  Here's the
> install, showing I'm running kernel release 2.4.20-6.
> 
> [root at localhost root]# uname -a
> Linux localhost.localdomain 2.4.20-6 #1 Thu Feb 27 10:06:59 EST 2003 i686
> i686 i386 GNU/Linux
> 
> I've downloaded R for linux Redhat 8.x, but I am running Redhat 9.  I'm
> assuming we have backward compatibility ?
> 
> To continue, attemping to load R produces the following errors:
> 
> [root at localhost temp]# rpm -ivh R-1.6.2-1.i386.rpm
> warning: R-1.6.2-1.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
> error: Failed dependencies:
>         libtcl.so.0 is needed by R-1.6.2-1
>         libtk.so.0 is needed by R-1.6.2-1
> 
> OK, I understand this so far.  So I go to http://rpmfind.net/linux/RPM/ to
> get the packages.  Searching for "libtcl.so.0" shows me that's it's in the
> tcl package.  The most current one from http://rpmfind.net/linux/RPM/ is
> tcl-8.3.3-74.i386.rpm.
> 
> However, after considerable gnashing of teeth, I come to discover that tcl
> is already on my machine as the following command shows:
> 
> [root at localhost temp]# rpm -qa | grep tcl
> tcl-8.3.5-88
> 
> NOTE - tcl-8.3.5-88 that I have on my machine is newer than anything I found
> on the Web, so when I tried to install the downloaded tcl-8.3.3-74.i386.rpm,
> it of course fails with "warning: tcl-8.3.3-74.i386.rpm: V3 DSA signature:
> NOKEY, key ID db42a60e package tcl-8.3.5-88 (which is newer than
> tcl-8.3.3-74) is already installed".
> 
> Here's all files on my system with filename *libtcl*:
> 
> [root at localhost root]# locate libtcl
> /usr/lib/libtcl.so
> /usr/lib/libtcl8.3.so
> /usr/lib/libtclstub8.3.a
> 
> Is the "libtcl.so" really the "libtcl.so.0" that R is looking for ?  If so,
> do I try and fool R somehow ?
> 
> Any idea why libtcl.so.0 is not being found in my installed tcl-8.3.5-88 ?
> 
> If this is heading towards source code compiling, please be explicit, I've
> not done this before !
> 
> Grovelling for advice,
> Neal in NC
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From p.dalgaard at biostat.ku.dk  Thu Apr 17 12:14:18 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Apr 2003 12:14:18 +0200
Subject: [R] Help with TCL packages
In-Reply-To: <000901c304b2$f281f9c0$ae4860d4@YvonnickNol>
References: <000901c304b2$f281f9c0$ae4860d4@YvonnickNol>
Message-ID: <x2y9298m85.fsf@biostat.ku.dk>

"Yvonnick Noel" <ynoel at tele2.fr> writes:

> Hello,
> 
> I am exploring the TCLTK package under R and try to load and use additional TCL libraries (under Windows, with TCL8.3). For example :
> 
> > addTclPath("C:/TCL/lib/bwidget1.5")
> > tclRequire("BWidget")
> <Tcl> 1.5
> 
> Loading seems to work, but when I try to create a specific widget :
> 
> # The main window appears correctly
> > top=tktoplevel()
> 
> # Trying to insert a combobox
> > combo <- tkwidget(top,"BWidget::combobox")
> Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class = "tclObj") : 
>         [tcl] invalid command name "BWidget::combobox".
> 
> The file combobox.tcl is present in the BWidget directory.
> 
> I wonder what I'm doing wrong. Any idea ?

I haven't got BWidgets around, but it seems that it likes to use
MacCapitalizationStyle, so shouldn't it be BWidget::ComboBox ?? 

In general, you might want to try things out in the "wish" interpreter
since R interfaces to an embedded Tcl interpreter and you're seeing
its error messages.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From andy_liaw at merck.com  Thu Apr 17 14:09:46 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 17 Apr 2003 08:09:46 -0400
Subject: [R] Testing for randomness
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F9D7@usrymx25.merck.com>

It's hard to tell what you're looking for.  There are some white noise tests
in time series, some of which, I imagine, are implemented in some of the
time series packages for R.  There are tests for quality of pseudo-random
number generators, probably the best known being Marsaglia's DIEHARD battery
of tests.  You can find them by googling.  They are not in R, though, AFAIK.

Andy

> -----Original Message-----
> From: Wayne Jones [mailto:JonesW at kssg.com]
> Sent: Thursday, April 17, 2003 4:30 AM
> To: 'r-help at stat.math.ethz.ch'
> Subject: [R] Testing for randomness
> 
> 
> Hi there, 
> 
> Does anyone know whether R has an inbuilt function to test if 
> a series of
> numbers is completely random??
> 
> thanks in advance, 
> 
> Wayne
> 
> 
> Dr Wayne R. Jones
> Statistician / Research Analyst
> KSS Group plc
> St James's Buildings
> 79 Oxford Street
> Manchester M1 6SS
> Tel: +44(0)161 609 4084
> Mob: +44(0)7810 523 713
> 
> 
> 
> KSS Ltd
> A division of Knowledge Support Systems Group plc
> Seventh Floor  St James's Buildings  79 Oxford Street  
> Manchester  M1 6SS  England
> Company Registration Number 2800886 (Limited) 3449594 (plc)
> Tel: +44 (0) 161 228 0040	Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com		http://www.kssg.com
> 
> 
> The information in this Internet email is confidential and 
> may b... {{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From andy_liaw at merck.com  Thu Apr 17 14:18:11 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 17 Apr 2003 08:18:11 -0400
Subject: [R] Local parameter calculation
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F9D8@usrymx25.merck.com>

I suspect running() or wapply() in the `gregmisc' package would suit your
need.

HTH,
andy

> -----Original Message-----
> From: Minghua Yao [mailto:myao at ou.edu]
> Sent: Wednesday, April 16, 2003 2:21 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Local parameter calculation
> 
> 
> Dear all,
> 
> I am a newbie in R. I encounter a problem as follows.
> 
> I have 2 vectors X and Y that have a equal length of several 
> thousand. I see
> Y as the function of X. Both of them are random. X is not 
> arrranged in any
> order. Of course, I do plot(X,Y). Now, I want to use a 
> sliding narrow window
> to run over each X, then calculate the variances within that window.
> 
> Anyone knows easy way in R to do this? Reply is appreciated.
> 
> -MY
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From p.dalgaard at biostat.ku.dk  Thu Apr 17 14:21:21 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Apr 2003 14:21:21 +0200
Subject: [R] Testing for randomness
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4F9D7@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD5C4F9D7@usrymx25.merck.com>
Message-ID: <x2adepgvr2.fsf@biostat.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> It's hard to tell what you're looking for.  There are some white noise tests
> in time series, some of which, I imagine, are implemented in some of the
> time series packages for R.  There are tests for quality of pseudo-random
> number generators, probably the best known being Marsaglia's DIEHARD battery
> of tests.  You can find them by googling.  They are not in R, though, AFAIK.

...and given that we have just discarded one of Marsaglia's generators
as the default RNG in R, some critical sense probably needs to be
applied to his test battery as well!

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From andy_liaw at merck.com  Thu Apr 17 14:21:12 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 17 Apr 2003 08:21:12 -0400
Subject: [R] Jackknife and rpart
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F9D9@usrymx25.merck.com>

That's essentially leave-one-out cross-validation.

In addition to Frank's suggestion, you might want to check out the
errorest() function in the ipred package.  You can do k-fold CV or the .632+
bootstrap.

HTH,
Andy

> -----Original Message-----
> From: chumpmonkey at hushmail.com [mailto:chumpmonkey at hushmail.com]
> Sent: Wednesday, April 16, 2003 1:28 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] Jackknife and rpart
> 
> 
> 
> Hi,
> 
> First, thanks to those who helped me see my gross misunderstanding of
> randomForest. I worked through a baging tutorial and now 
> understand the
> "many tree" approach. However, it is not what I want to do! My bagged
> errors are accpetable but I need to use the actual tree and 
> need a single
> tree application. 
> 
> I am using rpart for a classification tree but am interested in a more
> unbaised estimator of error in my tree. I lack sufficent data to train
> and test the tree and I'm hoping to bootstrap, or rather jacknife, an
> error estimate.
> 
> I do not think the rpart.object can be applied to the 
> jackknife function
> in bootstrap but can I do something as simple as:
> 
> for(i in 1:number of samples){
>   remove i from the data
>   run the tree
>   compare sample[i] to the tree using predict
>   create an error matrix}
> 
> This would give me a confussion matrix of data not included 
> in the tree's
> constuction.
> 
> Am I being obtuse again?
> 
> Thanks, CM
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From v_bill_pikounis at merck.com  Thu Apr 17 14:53:39 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Thu, 17 Apr 2003 08:53:39 -0400
Subject: [R] Validation of R
Message-ID: <CFBD404F5E0C9547B4E10B7BDC3DFA2F6621D2@usrymx18.merck.com>

Hi Rob,

> We conduct contract virology research for large pharma companies. My
> question is how do we validate this software? I wonder if anyone else
> has had the problem and might be able to comment.

Notwithstanding the disclaimer automatically appended below by my "Big
Pharma" member IT dept on all my email sends, I have not had this problem,
or perhaps more accurately, not allowed it to be a problem when work I have
done in R has made it into drug application filings and responses to FDA and
European regulatory agencies.

"Validation" of software is an ill-defined concept, so I am afraid I cannot
offer anything like a concrete "how-to", not would I be surprised if anyone
else can.  What I would like to suggest is to (1) ask your vendor companies
what specifically they are concerned about, (2) benchmark some guidelines on
how you all or others have "validated" other software.

If you are looking for extensive documentation on whats/hows/whys of R, it
already has it.  If you are looking for it to compute the same values as
"validated" software within realistic numeric accuracy for your procedures,
that is straightforward to do.  And the ultimate key is that anyone can look
at the source code and have a high probability to get it to run on any
reasonably current system, and even many systems not so current. 

On a visible, continuous (daily), *OPEN* basis, there is ongoing review and
input from the R user community, as well as all the highest standards of
software engineering that are met by the R core team and other developers. R
clearly stands up to rigorous, scholastic scrutiny. In my very grateful
view, this makes R at least as reliable as commercial vendor software that
claims "validation" or "compliance", etc., ...and probably, more reliable. 

Hope that helps.
Bill
----------------------------------------
Bill Pikounis, Ph.D.
Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY84-16  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

v_bill_pikounis at merck.com

Phone: 732 594 3913
Fax: 732 594 1565


> -----Original Message-----
> From: Rob Lambkin [mailto:r.lambkin at retroscreen.com]
> Sent: Thursday, April 17, 2003 4:51 AM
> To: r-help at stat.math.ethz.ch
> Cc: Shobana Balasingam; Seb Bossuyt; Katie Benjamin; Alex Mann
> Subject: [R] Validation of R
> 
> 
> Hi All
> 
> I am really very interested in starting to use R within our company. I
> particularly like the open source nature of the product. My 
> company is a
> medical research company which is part of the University of London.
> 
> We conduct contract virology research for large pharma companies. My
> question is how do we validate this software? I wonder if anyone else
> has had the problem and might be able to comment.
> 
> Thanks
> 
> Rob
> 
> 
> Robert Lambkin BSc (Hon's), MRPharmS, PhD
> Director and General Manager
> Retroscreen Limited 
> Retroscreen Virology Limited
> The Medical Building, Queen Mary, University of London,   327 Mile End
> Road, London, E1 4NS
> Tel: 020 7882 7624  Fax: 020 7882 6990
> (Retroscreen Virology Ltd. Registered in England & Wales No:2326557) 
>  
> The information contained in this message is confidential and is
> intended for the addressee(s) only. If you have received this 
> message in
> error or there are any problems please notify the originator
> immediately. 
>  
> Unauthorised use, disclosure, copying or alteration of this message is
> strictly forbidden.
> 
> Retroscreen Virology Limited will not be liable for any 
> action taken in
> reliance on the data contained in this e-mail as it may not have been
> quality assessed or assured.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From billthebrute at yahoo.fr  Thu Apr 17 14:59:36 2003
From: billthebrute at yahoo.fr (=?iso-8859-1?q?william=20ritchie?=)
Date: Thu, 17 Apr 2003 14:59:36 +0200 (CEST)
Subject: [R] sma 
Message-ID: <20030417125936.86012.qmail@web41103.mail.yahoo.com>

in the sma library, I m trying to use stat.t2 but I
don t know what the parameter cl actually means!!
cheers


From billthebrute at yahoo.fr  Thu Apr 17 15:01:24 2003
From: billthebrute at yahoo.fr (=?iso-8859-1?q?william=20ritchie?=)
Date: Thu, 17 Apr 2003 15:01:24 +0200 (CEST)
Subject: [R] sma
Message-ID: <20030417130124.83816.qmail@web41102.mail.yahoo.com>

Hello again and thanks again for your quick reply!
I m using the stat.Newton() function and would like to
know how I can retrieve the significantly expressed
spots to be able to put a name on them?

Cheers!


From jrogers at cantatapharm.com  Thu Apr 17 15:03:50 2003
From: jrogers at cantatapharm.com (Jim Rogers)
Date: Thu, 17 Apr 2003 09:03:50 -0400
Subject: [R] besoin d'aide
Message-ID: <99A12772DCDEEB458B996332957B0D530117A3@mercury.cantatapharm.com>

For writing "special-purpose" merge functions as mentioned below, you will probably want to know about match(). A lot of the essential work of merge() is being done by match(), but merge() also includes a lot of idiot-proofing. Comparing the length of the code for these two functions will give you some idea of the overhead of all that idiot-proofing. If you write your own merge function using match() and cbind(), or match() and data.frame(), it will probably be much faster (but less idiot proof; e.g. if your "by" variable is a factor, you need to be very careful - probably you want to convert it to character prior to the merging operation).  


>The function merge() is like the "join" operation in relational data bases 
>- it's much more powerful than mere concatenation (and thus often much 
>slower, especially on large tables.) 
>
>
>To merely concatenate tables together, use rbind() (to concatenate by rows) 
>or cbind() (to concatenate by columns). 
>
>
>If you do need the power of merge(), but it is too slow for your purposes 
>you may be able to write a special-purpose function in R that does just 
>only you need and much more quickly -- such is the nature of the S language 
>-- it is very powerful, but the powerful general-purpose functions can 
>often be quite slow in particular cases. 
>
>
>Hope this helps, and apologies if I have not completely understood your 
>question. 
>
>
>-- Tony Plate 
>
>
>
>At Wednesday 03:39 PM 4/16/2003 +0200, Erwan BARRET wrote: 
>>J'aimerais savoir si la fonction merge() est la seule disponible pour 
>>concatener des tableaux de donn?es? 
>>Est-ce normal que l'ex?cution soit lente? 
>> 

James A. Rogers, Ph.D. <rogers at cantatapharm.com>
Statistical Scientist
Cantata Pharmaceuticals
300 Technology Square, 5th floor
Cambridge, MA  02139
617.225.9009 x312
Fax 617.225.9010


From sway at tanox.com  Thu Apr 17 15:07:59 2003
From: sway at tanox.com (Shawn Way)
Date: Thu, 17 Apr 2003 08:07:59 -0500
Subject: [R] Validation of R
Message-ID: <2F3262756375D411B0CC00B0D049775DAFB351@westpark.tanox.net>

I suspect that there is no easy answer to this.

The first step will be to write a user specification for what you want to
use the software for.  In most cases, I believe that you will want to use
specific functions and scripts.  Define those functions and scripts up front
in the user specification.

Next will be to create those scripts you wish to use and documenting the
creation (I'm thinking of a library here)

Once this is created, you would need to create a standard dataset(s), the
more the better, for the testing of the functions defined in the user
requirement specification. This is for comparison with a known result and
used if the software is upgraded in the future.  I would propose to do the
analysis (on the standard data set) the first time with a known package such
as SAS, and compare that with R.  Once the data is been documented to match,
this becomes your standard setup.  I would then use a program such as gnu's
diff for any changes in printouts from the two applications.

Graphics are harder, but I believe that Paul Murrell and Kurt Hornik are
working on this by the paper: Quality Assurance for Graphics in R,  from the
DSC 2003 Working Papers.

Hope this helps.

-----Original Message-----
From: Rob Lambkin [mailto:r.lambkin at retroscreen.com] 
Sent: Thursday, April 17, 2003 3:51 AM
To: r-help at stat.math.ethz.ch
Cc: Shobana Balasingam; Seb Bossuyt; Katie Benjamin; Alex Mann
Subject: [R] Validation of R


Hi All

I am really very interested in starting to use R within our company. I
particularly like the open source nature of the product. My company is a
medical research company which is part of the University of London.

We conduct contract virology research for large pharma companies. My
question is how do we validate this software? I wonder if anyone else has
had the problem and might be able to comment.

Thanks

Rob


Robert Lambkin BSc (Hon's), MRPharmS, PhD
Director and General Manager
Retroscreen Limited 
Retroscreen Virology Limited
The Medical Building, Queen Mary, University of London,   327 Mile End
Road, London, E1 4NS
Tel: 020 7882 7624  Fax: 020 7882 6990
(Retroscreen Virology Ltd. Registered in England & Wales No:2326557) 
 
The information contained in this message is confidential and is... {{dropped}}


From sundar.dorai-raj at pdf.com  Thu Apr 17 15:09:33 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 17 Apr 2003 08:09:33 -0500
Subject: [R] R-1.7.0 WIN2000 INSTALL
References: <3A822319EB35174CA3714066D590DCD5C4F9DA@usrymx25.merck.com>
Message-ID: <3E9EA78D.1000604@pdf.com>

Thanks for the replies. I've taken the suggestion of removing cygwin and 
all registry keys (that I can find). Again here is my path:

D:\R\R-17~1.0\src\gnuwin32>path
PATH=C:\Program Files\Perl\bin\;
C:\WINNT\system32;
C:\WINNT;
C:\WINNT\System32\Wbem;
"C:\Program Files\Hummingbird\Connectivity\7.00\Accessories\";
.;
D:\Rtools\;
D:\mingw\bin\;
C:\Progra~1\Perl\bin;
D:\texmf\miktex\bin\;
D:\Progra~1\HTMLHe~1;
D:\Progra~1\R\rw1062\bin\;
C:\Progra~1\Insightful\splus61\cmd\;
D:\Progra~1\SSHCom~1\SSHSec~1;
D:\Progra~1\Tcl\bin\;
C:\Progra~1\Microso~3\VC98\Bin;

Everything before the . is prepended by the administrator. After 
modifying src\gnuwin32\MkRules, I try `make' in the same directory:

D:\R\R-17~1.0\src\gnuwin32>make
make --no-print-directory -C front-ends Rpwd
make: *** [front-ends/Rpwd.exe] Error 255

D:\R\R-17~1.0\src\gnuwin32>

Here's another anomaly that I've worked around though it may be related: 
If I type `tar zxvf R-1.7.0.tgz' at the command prompt I get a dialog 
box listing the tar options and no untarring is accomplished. I was able 
to use tar properly in the bash shell to extract everyting before I 
deleted the cygwin directory.

Any clues? Have I missed something obvious?

Regards,
Sundar


From andy_liaw at merck.com  Thu Apr 17 15:10:42 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 17 Apr 2003 09:10:42 -0400
Subject: [R] sma
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F9DD@usrymx25.merck.com>

In case you don't know how to read the help page, ?stat.t2 says, under
"Arguments":

cl   vector of class labels. Must consist of integers 1 and 2.

... meaning you need a vector consisting of 1's and 2's that indicate which
observation belong to which of the two groups.

Andy

> -----Original Message-----
> From: william ritchie [mailto:billthebrute at yahoo.fr]
> Sent: Thursday, April 17, 2003 9:00 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] sma
> 
> 
> in the sma library, I m trying to use stat.t2 but I
> don t know what the parameter cl actually means!!
> cheers
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From andy_liaw at merck.com  Thu Apr 17 15:15:25 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 17 Apr 2003 09:15:25 -0400
Subject: [R] sma
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F9DE@usrymx25.merck.com>

Can I be any more explicit?  Please do read the help pages of functions
you're trying to use.  In this case, the "Value" section of ?stat.Newton
would help!

Andy

> -----Original Message-----
> From: william ritchie [mailto:billthebrute at yahoo.fr]
> Sent: Thursday, April 17, 2003 9:01 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] sma
> 
> 
> Hello again and thanks again for your quick reply!
> I m using the stat.Newton() function and would like to
> know how I can retrieve the significantly expressed
> spots to be able to put a name on them?
> 
> Cheers!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From bmagill at earthlink.net  Thu Apr 17 13:22:15 2003
From: bmagill at earthlink.net (Brett Magill)
Date: Thu, 17 Apr 2003 06:22:15 -0500 (CDT)
Subject: [R] Validation of R
Message-ID: <4185163.1050585873831.JavaMail.nobody@ernie.psp.pas.earthlink.net>

The national institute of standards and technology offers reference data sets and expected results for various statistical procedures using these data sets.  From the web site:

"The purpose of this project is to improve the accuracy of statistical software by providing reference datasets with certified computational results that enable the objective evaluation of statistical software."  

     http://www.itl.nist.gov/div898/strd/


-------Original Message-------
From: "Pikounis, Bill" <v_bill_pikounis at merck.com>
Sent: 04/17/03 07:53 AM
To: 'Rob Lambkin' <r.lambkin at retroscreen.com>, r-help at stat.math.ethz.ch
Subject: RE: [R] Validation of R

> 
> Hi Rob,

> We conduct contract virology research for large pharma companies. My
> question is how do we validate this software? I wonder if anyone else
> has had the problem and might be able to comment.

Notwithstanding the disclaimer automatically appended below by my "Big
Pharma" member IT dept on all my email sends, I have not had this problem,
or perhaps more accurately, not allowed it to be a problem when work I
have
done in R has made it into drug application filings and responses to FDA
and
European regulatory agencies.

"Validation" of software is an ill-defined concept, so I am afraid I
cannot
offer anything like a concrete "how-to", not would I be surprised if
anyone
else can.  What I would like to suggest is to (1) ask your vendor
companies
what specifically they are concerned about, (2) benchmark some guidelines
on
how you all or others have "validated" other software.

If you are looking for extensive documentation on whats/hows/whys of R, it
already has it.  If you are looking for it to compute the same values as
"validated" software within realistic numeric accuracy for your
procedures,
that is straightforward to do.  And the ultimate key is that anyone can
look
at the source code and have a high probability to get it to run on any
reasonably current system, and even many systems not so current. 

On a visible, continuous (daily), *OPEN* basis, there is ongoing review
and
input from the R user community, as well as all the highest standards of
software engineering that are met by the R core team and other developers. 
R
clearly stands up to rigorous, scholastic scrutiny. In my very grateful
view, this makes R at least as reliable as commercial vendor software that
claims "validation" or "compliance", etc., ...and probably, more reliable. 


Hope that helps.
Bill
----------------------------------------
Bill Pikounis, Ph.D.
Biometrics Research Department
Merck Research Laboratories
PO Box 2000, MailDrop RY84-16  
126 E. Lincoln Avenue
Rahway, New Jersey 07065-0900
USA

v_bill_pikounis at merck.com

Phone: 732 594 3913
Fax: 732 594 1565


> -----Original Message-----
> From: Rob Lambkin [mailto:r.lambkin at retroscreen.com]
> Sent: Thursday, April 17, 2003 4:51 AM
> To: r-help at stat.math.ethz.ch
> Cc: Shobana Balasingam; Seb Bossuyt; Katie Benjamin; Alex Mann
> Subject: [R] Validation of R
> 
> 
> Hi All
> 
> I am really very interested in starting to use R within our company. I
> particularly like the open source nature of the product. My 
> company is a
> medical research company which is part of the University of London.
> 
> We conduct contract virology research for large pharma companies. My
> question is how do we validate this software? I wonder if anyone else
> has had the problem and might be able to comment.
> 
> Thanks
> 
> Rob
> 
> 
> Robert Lambkin BSc (Hon's), MRPharmS, PhD
> Director and General Manager
> Retroscreen Limited 
> Retroscreen Virology Limited
> The Medical Building, Queen Mary, University of London,   327 Mile End
> Road, London, E1 4NS
> Tel: 020 7882 7624  Fax: 020 7882 6990
> (Retroscreen Virology Ltd. Registered in England & Wales No:2326557) 
>  
> The information contained in this message is confidential and is
> intended for the addressee(s) only. If you have received this 
> message in
> error or there are any problems please notify the originator
> immediately. 
>  
> Unauthorised use, disclosure, copying or alteration of this message is
> strictly forbidden.
> 
> Retroscreen Virology Limited will not be liable for any 
> action taken in
> reliance on the data contained in this e-mail as it may not have been
> quality assessed or assured.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From rolf at math.unb.ca  Thu Apr 17 15:38:28 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 17 Apr 2003 10:38:28 -0300 (ADT)
Subject: [R] Testing.
Message-ID: <200304171338.h3HDcStK004751@erdos.math.unb.ca>


Please ignore this message.


From rolf at math.unb.ca  Thu Apr 17 15:41:26 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 17 Apr 2003 10:41:26 -0300 (ADT)
Subject: [R] Install of R-1.7.0; permissions.
Message-ID: <200304171341.h3HDfQhj004817@erdos.math.unb.ca>


I just installed R-1.7.0 on our (solaris 2.9) system and was
pleasantly surprise by how well things went.  The hang-ups that
occurred when I tried (and failed) to install R-1.6.2 did not show
up.

However there was one minor glitch:  Some of the permissions on
the files in the installed version (in /usr/local/lib/R) were
wrong. E.g. here's a listing of /usr/local/lib/R/library:

===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
{erdos} /usr/local/lib/R/library ## ls -l
total 28
drwxr-xr-x  10 root          512 Apr 16 15:52 KernSmooth/
drwxr-xr-x  13 root          512 Apr 16 15:52 MASS/
-rw-r--r--   1 root          608 Apr 16 15:52 R.css
drwx------  11 root          512 Apr 16 15:52 base/
drwxr-xr-x  10 root          512 Apr 16 15:52 boot/
drwxr-xr-x  10 root          512 Apr 16 15:52 class/
drwxr-xr-x  11 root          512 Apr 16 15:52 cluster/
drwx------  10 root          512 Apr 16 15:52 ctest/
drwx------  11 root          512 Apr 16 15:52 eda/
drwxr-xr-x  10 root          512 Apr 16 15:52 foreign/
drwxr-xr-x  11 root          512 Apr 16 15:52 grid/
drwxr-xr-x  12 root          512 Apr 16 15:52 lattice/
drwx------  10 root          512 Apr 16 15:52 lqs/
drwx------  10 root          512 Apr 16 15:52 methods/
drwxr-xr-x  10 root          512 Apr 16 15:52 mgcv/
drwx------  11 root          512 Apr 16 15:52 modreg/
drwx------  11 root          512 Apr 16 15:52 mva/
drwxr-xr-x  13 root          512 Apr 16 15:52 nlme/
drwx------  11 root          512 Apr 16 15:52 nls/
drwxr-xr-x  10 root          512 Apr 16 15:52 nnet/
drwxr-xr-x  11 root          512 Apr 16 15:52 rpart/
drwxr-xr-x  11 root          512 Apr 16 15:52 spatial/
drwx------  10 root          512 Apr 16 15:52 splines/
drwx------   9 root          512 Apr 16 15:52 stepfun/
drwxr-xr-x  11 root          512 Apr 16 15:52 survival/
drwx------  11 root          512 Apr 16 15:52 tcltk/
drwx------  11 root          512 Apr 16 15:52 tools/
drwx------  11 root          512 Apr 16 15:52 ts/
===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

You'll notice that a substantial number --- though not all --- of the
directories are executable/readable only by root.  (I became root in
order to effect a system-wide install.)  These directories include
the ***base*** (!) package, and if I am not mistaken consist of all
of the ``basic'' packages.

Likewise a number of files in /usr/local/lib/R/bin were accessible
only to root --- this includes the fundamental (!) R.bin.

I managed to do a global reset of the permissions fairly easily, but
I'm wondering --- is there a wee glitch in the installation procedure
for R-1.7.0, or did I muck something up, or is there a glitch in our
operating system?  It seems funny that if there is a problem at my
end it only, selectively, hit these ``basic'' packages.

Has anyone else experienced permission problems like unto these?

System details:

===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===
 > version
         _                   
platform sparc-sun-solaris2.9
arch     sparc               
os       solaris2.9          
system   sparc, solaris2.9   
status                       
major    1                   
minor    7.0                 
year     2003                
month    04                  
day      16                  
language R
===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===+===

				cheers,

					Rolf Turner
					rolf at math.unb.ca


From uth at zhwin.ch  Thu Apr 17 15:59:39 2003
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Thu, 17 Apr 2003 15:59:39 +0200
Subject: [R] BATCH and tcltk
Message-ID: <6A4BCEF0FD65344A8F496D7E520DD8B9023E9094@lobster.zhwin.ch>


Hi R-hackers

I try to write a batch (in Windows, i have to use!) with 
Rcmd BATCH D:\Test.R D:\Test.Rout and
Rterm.exe --no-restore --no-save < D:\Test.R > D:\Test.Rout.

In my file Test.R are any tk-codelines (like: Window1 <- tktoplevel(); ... tkbutton...).
It works not interactifly, what is written in Rcmd BATCH --help.

Exist there a way to do it all the same?

Please help... Otherwise i have to use Excel to get the GUIs .

(and sorry about my english, it's terrible)


Thomas


                            

Content Security by MailMarshal


From tblackw at umich.edu  Thu Apr 17 15:59:43 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 17 Apr 2003 09:59:43 -0400 (EDT)
Subject: [R] Question on SOM and clustering
In-Reply-To: <D6E2A9EB-7034-11D7-B5EC-0005026E2B43@vanderkogel.net>
Message-ID: <Pine.SOL.4.44.0304170927140.3157-100000@millipede.gpcc.itd.umich.edu>

Jonck  -

Welcome.  As you read this list day after day, you will find that
it's mostly about the mechanics of how to get R to "do its thing"
... and sometimes about "what is the name of the function that
does so-and-so".  This last is because the reverse-indexing problem
is inherently a difficult one (we can alphabetize the function
names, but how do you "alphabetize" what they do ?) and R users all
recognize that the collective memory is a BETTER, more efficient
way to handle the reverse indexing problem than any algorithm !
(It takes us, as users, less time to read and respond to questions
as they come up, than it would to design and write an automated
system.)  (Er, I digress.)

Advice on how to do the data analysis for a specific problem is in
a very different category ... because the person directly facing a
problem has a  LOT  more knowledge, about that problem and about
constraints on the kind of answer they want, than can possibly be
communicated in a few sentences of email.  It's very hard to give
good statistical guidance without quite a bit of back-and-forth
communication about the problem.

So, you're on your own about choosing a "clustering method".
Do you mean that you want to further cluster the nodes of the
grid returned by Kohonen's SOM ?  (I don't even understand the
question clearly.)  Well, then you'll need to think about what
criteria you want to use to do that ... and only then think
about what methods might be appropriate.

As to the technical part,  help("SOM"), help("batchSOM") make it
clear that both functions do have a return value.  They do NOT
"only give a visual representation of the topological mapping."

It's your problem, have fun with it !   Keep in touch.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 16 Apr 2003, Jonck van der Kogel wrote:

> Hello everyone,
> I'm new to this list, so let me introduce myself: my name is Jonck van
> der Kogel and I am a graduate student at the Erasmus University of
> Rotterdam. I am currently working on my thesis which is on the use of
> artificial intelligence for large data-sets.
> To do an analysis of a certain data-set I want to use Kohonen's SOM
> algorithm. However, as I understand it, the SOM algorithm as it's
> implemented in R only gives a visual representation of the topological
> mapping. I want to do further analysis with this mapping and thus I
> need to do a clustering of the topological mapping produced by the SOM.
> I was wondering wether anyone could give me some advice on which
> clustering method in R is most suited for clustering the map produced
> by the SOM algorithm.
>
> Thanks very much, Jonck


From rab at nauticom.net  Thu Apr 17 16:23:28 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Thu, 17 Apr 2003 10:23:28 -0400
Subject: [R] Problem with R 1.6.2 and RH 8.0?
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4F9DE@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD5C4F9DE@usrymx25.merck.com>
Message-ID: <3E9EB8E0.7000800@nauticom.net>

When I was running R 1.6.1 (under Red Hat 8.0), R would abruptly 
terminate from time to time. I would type in a line of code and hit 
return, and the cursor would not move from the end of the line. Then the 
hard drive would start churning. This goes on for at least 10 minutes. 
Finally R terminates (finally freeing up the keyboard and display). The 
only word printed is "Killed" immediately at the end of the last line of 
code. I upgraded to 1.6.2 and the same thing continues to happen. This 
happens for no apparent reason (doesn't seem to have anything to do with 
any particular code or function).

Here is the last time:

 > library(help=ts)Killed

Has anyone seen this problem? Any idea on what I should fix/change?

Rick B.


From rolf at math.unb.ca  Thu Apr 17 16:07:29 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 17 Apr 2003 11:07:29 -0300 (ADT)
Subject: [R] R-1.7.0; empty html files.
Message-ID: <200304171407.h3HE7T39006008@erdos.math.unb.ca>


When I installed R-1.7.0, the *.html files in /usr/local/lib/R/doc/manual
all wound up being empty:

ls -l *.html
-rw-r--r--    1 root     other           0 Apr 16 15:52 R-FAQ.html
-rw-r--r--    1 root     other           0 Apr 16 15:52 R-admin.html
-rw-r--r--    1 root     other           0 Apr 16 15:52 R-data.html
-rw-r--r--    1 root     other           0 Apr 16 15:52 R-exts.html
-rw-r--r--    1 root     other           0 Apr 16 15:52 R-intro.html
-rw-r--r--    1 root     other           0 Apr 16 15:52 R-lang.html

I thought that they got put in automatically, and indeed the
files are ***there*** there's just nothing in them.

I did the usual

	./configure
	make
	make check
	make install

and no errors seemed to occur --- other than the permissions
problem I alluded to in an earlier email.  When I noticed that
the *.html files were empty I tried doing

	make html

explicitly --- although the instructions seem to indicate that
this shouldn't be necessary --- and repeated the make install.
Not a sausage.

What am I doing wrong?

					cheers,

						Rolf Turner


From p.dalgaard at biostat.ku.dk  Thu Apr 17 16:20:53 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Apr 2003 16:20:53 +0200
Subject: [R] BATCH and tcltk
In-Reply-To: <6A4BCEF0FD65344A8F496D7E520DD8B9023E9094@lobster.zhwin.ch>
References: <6A4BCEF0FD65344A8F496D7E520DD8B9023E9094@lobster.zhwin.ch>
Message-ID: <x21y01gq7u.fsf@biostat.ku.dk>

"Untern?hrer Thomas, uth" <uth at zhwin.ch> writes:

> Hi R-hackers
> 
> I try to write a batch (in Windows, i have to use!) with 
> Rcmd BATCH D:\Test.R D:\Test.Rout and
> Rterm.exe --no-restore --no-save < D:\Test.R > D:\Test.Rout.
> 
> In my file Test.R are any tk-codelines (like: Window1 <- tktoplevel(); ... tkbutton...).
> It works not interactifly, what is written in Rcmd BATCH --help.
> 
> Exist there a way to do it all the same?
> 
> Please help... Otherwise i have to use Excel to get the GUIs .
> 
> (and sorry about my english, it's terrible)

I haven't messed with this on Windows for a while, but it might help
to stick a tkwait.variable("foo") or something like that at the end of
your input script. The thing is to get Tcl's event loop going - R
usually drives it from the keyboard entry loop, but there is none in
batch mode.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From uth at zhwin.ch  Thu Apr 17 16:19:27 2003
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Thu, 17 Apr 2003 16:19:27 +0200
Subject: [R] Odd and Even
Message-ID: <6A4BCEF0FD65344A8F496D7E520DD8B9023E9095@lobster.zhwin.ch>


Try this

ifelse(p%%2 == 1,"Odd","Even")


Thomas Untern?hrer                              
E-Mail:  thomas.unternaehrer at zhwin.ch

Content Security by MailMarshal


From Setzer.Woodrow at epamail.epa.gov  Thu Apr 17 16:19:22 2003
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow@epamail.epa.gov)
Date: Thu, 17 Apr 2003 10:19:22 -0400
Subject: [R] Validation of R
Message-ID: <OFE45854BB.CFAC5D66-ON85256D0B.004E66F8@rtp.epa.gov>


Remember also, that there is an extensive series of tests available when
installing R from source by executing "make check".  Some time ago there
was discussion of this topic in r-help (see the r-help archives).

R. Woodrow Setzer, Jr.                        Phone: (919) 541-0128
Experimental Toxicology Division             Fax:  (919) 541-4284
Pharmacokinetics Branch
NHEERL B143-05; US EPA; RTP, NC 27711


                                                                                                                                           
                      Shawn Way                                                                                                            
                      <sway at tanox.com>             To:       'Rob Lambkin' <r.lambkin at retroscreen.com>                                     
                      Sent by:                     cc:       "'r-help at stat.math.ethz.ch'" <r-help at stat.math.ethz.ch>                       
                      r-help-bounces at stat.m        Subject:  RE: [R] Validation of R                                                       
                      ath.ethz.ch                                                                                                          
                                                                                                                                           
                                                                                                                                           
                      04/17/03 09:07 AM                                                                                                    
                                                                                                                                           
                                                                                                                                           




I suspect that there is no easy answer to this.

The first step will be to write a user specification for what you want
to
use the software for.  In most cases, I believe that you will want to
use
specific functions and scripts.  Define those functions and scripts up
front
in the user specification.

Next will be to create those scripts you wish to use and documenting the
creation (I'm thinking of a library here)

Once this is created, you would need to create a standard dataset(s),
the
more the better, for the testing of the functions defined in the user
requirement specification. This is for comparison with a known result
and
used if the software is upgraded in the future.  I would propose to do
the
analysis (on the standard data set) the first time with a known package
such
as SAS, and compare that with R.  Once the data is been documented to
match,
this becomes your standard setup.  I would then use a program such as
gnu's
diff for any changes in printouts from the two applications.

Graphics are harder, but I believe that Paul Murrell and Kurt Hornik are
working on this by the paper: Quality Assurance for Graphics in R,  from
the
DSC 2003 Working Papers.

Hope this helps.

-----Original Message-----
From: Rob Lambkin [mailto:r.lambkin at retroscreen.com]
Sent: Thursday, April 17, 2003 3:51 AM
To: r-help at stat.math.ethz.ch
Cc: Shobana Balasingam; Seb Bossuyt; Katie Benjamin; Alex Mann
Subject: [R] Validation of R


Hi All

I am really very interested in starting to use R within our company. I
particularly like the open source nature of the product. My company is a
medical research company which is part of the University of London.

We conduct contract virology research for large pharma companies. My
question is how do we validate this software? I wonder if anyone else
has
had the problem and might be able to comment.

Thanks

Rob


Robert Lambkin BSc (Hon's), MRPharmS, PhD
Director and General Manager
Retroscreen Limited
Retroscreen Virology Limited
The Medical Building, Queen Mary, University of London,   327 Mile End
Road, London, E1 4NS
Tel: 020 7882 7624  Fax: 020 7882 6990
(Retroscreen Virology Ltd. Registered in England & Wales No:2326557)

The information contained in this message is confidential and is... {{dropped}}


From rab at nauticom.net  Thu Apr 17 16:45:14 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Thu, 17 Apr 2003 10:45:14 -0400
Subject: [R] Subsetting Time Series
In-Reply-To: <2F3262756375D411B0CC00B0D049775DAFB351@westpark.tanox.net>
References: <2F3262756375D411B0CC00B0D049775DAFB351@westpark.tanox.net>
Message-ID: <3E9EBDFA.5040801@nauticom.net>

Is there any way to subset a time series without converting the result 
to a matrix or vector? I would like to replace some values in the time 
series to see the effect on forecasts.


From ramzi_feg at yahoo.fr  Thu Apr 17 16:23:55 2003
From: ramzi_feg at yahoo.fr (=?iso-8859-1?q?Ramzi=20Feghali?=)
Date: Thu, 17 Apr 2003 16:23:55 +0200 (CEST)
Subject: [R] Question on SOM and clustering
In-Reply-To: <Pine.SOL.4.44.0304170927140.3157-100000@millipede.gpcc.itd.umich.edu>
Message-ID: <20030417142355.71230.qmail@web20310.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030417/c0601eaa/attachment.pl

From mikalzet at libero.it  Thu Apr 17 16:25:50 2003
From: mikalzet at libero.it (mikalzet@libero.it)
Date: Thu, 17 Apr 2003 16:25:50 +0200 (CEST)
Subject: [R] Mandrake RPMS for R 1.7.0
Message-ID: <Pine.LNX.4.50.0304171621310.11324-100000@macchinetta>


The SRPM for 1.7.0 and RPMS for Mandrake 9.1, 9.0 and 8.2 have been 
successfully compiled and uploaded and will propagate through CRAN in due 
course.

Versions for 8.1 and 8.0 have incurred into a problem with make check-all 
and will be uploaded as soon as this has been fixed ... probably after 
Easter at this point !

A very Happy and Holy Easter to all !

-- 
Michele Alzetta


From tlumley at u.washington.edu  Thu Apr 17 16:32:18 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 17 Apr 2003 07:32:18 -0700 (PDT)
Subject: [R] help about the dist() error message
In-Reply-To: <6rel42nujm.fsf@bates4.stat.wisc.edu>
Message-ID: <Pine.A41.4.44.0304170731180.227706-100000@homer01.u.washington.edu>

On 16 Apr 2003, Douglas Bates wrote:
>
> You exaggerate.  It's a mere 40 GB, I believe.
>
> > N = 100000
> > 8*(N * (N - 1))/2
> [1] 39999600000
> > (8*(N * (N - 1))/2)/2^30
> [1] 37.25253
>

Ok. I should use R rather than doing mental arithmetic.  There might well
be sufficient virtual memory if Meng's machine is 64-bit and can address
it. :)


	-thomas


From tblackw at umich.edu  Thu Apr 17 16:33:06 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 17 Apr 2003 10:33:06 -0400 (EDT)
Subject: [R] BATCH and tcltk
In-Reply-To: <6A4BCEF0FD65344A8F496D7E520DD8B9023E9094@lobster.zhwin.ch>
Message-ID: <Pine.SOL.4.44.0304171024080.3157-100000@millipede.gpcc.itd.umich.edu>

Thomas  -

Does your batch script include the line  library("tcltk") ?

The syntax for a batch script is exactly the sequence of
commands you would type at the R command line, without an
R prompt character at the beginning of each line.  It's
often much easier to develop and debug a batch script by
working interactively the first time.

Unfortunately, I do not use Windows, so I do not understand
any details of getting tcl/tk to work properly under Windows.

Could you ask a more specific question.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 17 Apr 2003, [iso-8859-1] "Unternhrer Thomas, uth" wrote:

> Hi R-hackers
>
> I try to write a batch (in Windows, i have to use!) with
> Rcmd BATCH D:\Test.R D:\Test.Rout and
> Rterm.exe --no-restore --no-save < D:\Test.R > D:\Test.Rout.
>
> In my file Test.R are any tk-codelines
> (like: Window1 <- tktoplevel(); ... tkbutton...).
> It works not interactifly, what is written in Rcmd BATCH --help.
>
> Exist there a way to do it all the same?
>
> Please help... Otherwise i have to use Excel to get the GUIs .
>
> (and sorry about my english, it's terrible)
>
> Thomas


From p.dalgaard at biostat.ku.dk  Thu Apr 17 16:37:46 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Apr 2003 16:37:46 +0200
Subject: [R] Problem with R 1.6.2 and RH 8.0?
In-Reply-To: <3E9EB8E0.7000800@nauticom.net>
References: <3A822319EB35174CA3714066D590DCD5C4F9DE@usrymx25.merck.com>
	<3E9EB8E0.7000800@nauticom.net>
Message-ID: <x2wuhtfav9.fsf@biostat.ku.dk>

"Richard A. Bilonick" <rab at nauticom.net> writes:

> When I was running R 1.6.1 (under Red Hat 8.0), R would abruptly
> terminate from time to time. I would type in a line of code and hit
> return, and the cursor would not move from the end of the line. Then
> the hard drive would start churning. This goes on for at least 10
> minutes. Finally R terminates (finally freeing up the keyboard and
> display). The only word printed is "Killed" immediately at the end of
> the last line of code. I upgraded to 1.6.2 and the same thing
> continues to happen. This happens for no apparent reason (doesn't seem
> to have anything to do with any particular code or function).
> 
> Here is the last time:
> 
>  > library(help=ts)Killed
> 
> Has anyone seen this problem? Any idea on what I should fix/change?

Haven't heard about that before. There are three things you can do:

a) Upgrade to R 1.7.0 when it comes out "tomorrow" (for largish
values of tomorrow -- depends on what Martyn's plans are for
Easter...) and see if the problem is still there.

b) Next time it happens, run "top" or "ps" in another terminal, figure
out the process ID (say, 7913) and run strace -p 7913 and tell us what
you see.

c) Make a habit of starting R under the debugger: "R -d gdb", then in
gdb use "run". When the bad thing happens, Ctrl-C will bring you back
to the debugger where you say "bt" which might give us a clue. (If you
need to interrupt R for other reasons, use Ctrl-C and enter "signal
2"). You can also attach gdb to a running R much in the same way as
strace.
 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Thu Apr 17 16:44:37 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 17 Apr 2003 16:44:37 +0200
Subject: [R] R-1.7.0; empty html files.
In-Reply-To: <200304171407.h3HE7T39006008@erdos.math.unb.ca>
References: <200304171407.h3HE7T39006008@erdos.math.unb.ca>
Message-ID: <x2smshfaju.fsf@biostat.ku.dk>

Rolf Turner <rolf at math.unb.ca> writes:

> When I installed R-1.7.0, the *.html files in /usr/local/lib/R/doc/manual
> all wound up being empty:
> 
> ls -l *.html
> -rw-r--r--    1 root     other           0 Apr 16 15:52 R-FAQ.html
> -rw-r--r--    1 root     other           0 Apr 16 15:52 R-admin.html
> -rw-r--r--    1 root     other           0 Apr 16 15:52 R-data.html
> -rw-r--r--    1 root     other           0 Apr 16 15:52 R-exts.html
> -rw-r--r--    1 root     other           0 Apr 16 15:52 R-intro.html
> -rw-r--r--    1 root     other           0 Apr 16 15:52 R-lang.html
> 
> I thought that they got put in automatically, and indeed the
> files are ***there*** there's just nothing in them.
> 
> I did the usual
> 
> 	./configure
> 	make
> 	make check
> 	make install
> 
> and no errors seemed to occur --- other than the permissions
> problem I alluded to in an earlier email.  When I noticed that
> the *.html files were empty I tried doing
> 
> 	make html
> 
> explicitly --- although the instructions seem to indicate that
> this shouldn't be necessary --- and repeated the make install.
> Not a sausage.
> 
> What am I doing wrong?

Didn't happen to me:

$ ls -l `R RHOME`/doc/manual
total 2238
-rw-r--r--   1 root     other     168182 Apr 16 16:32 R-FAQ.html
-rw-r--r--   1 root     other      64461 Apr 16 16:32 R-admin.html
-rw-r--r--   1 root     other      97901 Apr 16 16:32 R-data.html
-rw-r--r--   1 root     other     246379 Apr 16 16:32 R-exts.html
-rw-r--r--   1 root     other     313551 Apr 16 16:32 R-intro.html
-rw-r--r--   1 root     other     200270 Apr 16 16:32 R-lang.html
$ uname -a
SunOS rasch 5.9 Generic_112233-03 sun4u sparc SUNW,Ultra-4

Could your umask settings have been set unfortunately? Mine are '022'
both as regular user and as root.


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From chrysopa at insecta.ufv.br  Thu Apr 17 16:19:32 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Thu, 17 Apr 2003 11:19:32 -0300
Subject: [R] Howto calculate R^2 from an anconva glm
Message-ID: <200304171119.32691.chrysopa@insecta.ufv.br>

Hi,

If I have the follow example:

y = count data
x1 = continuous data
x2 = qualitative data (2 factors levels)

I make a model

glm(y~x1,family=poisson)

The model has only one curve, to calculate r-square, I do 

"x1 Deviance"/"total Deviance"

But in a model with x2

glm(y~x1+x2,family=poisson)

I have two curves, but I dont have, using summary() or anova(), the deviance 
for separates levels. How to obtain rsquare for the two ajusted curves???

Thanks
Ronaldo


-- 

Quando uma boa administra??o ? trazida para um mau neg?cio, ? a reputa??o do 
neg?cio que permanece intacta

--Warren Buffet
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From tpapp at axelero.hu  Thu Apr 17 16:47:30 2003
From: tpapp at axelero.hu (Tamas Papp)
Date: Thu, 17 Apr 2003 16:47:30 +0200
Subject: [R] Testing for whole numbers
Message-ID: <20030417144730.GA1194@localhost>

Is there a way in R to test if a given number is an integer, ie a
whole number? I am not referring to the data type of a number, but to
its value.

That is to say, is.whole(pi-pi+2) would be TRUE, whereas is.whole(4/3)
would be false. At the moment I am using

is.whole <- function(a) { floor(a)==a }

which is OK for real numbers, but not for complex ones (a+bi would be
a whole number if both a and b are whole). Although it's obvious to
test for the type of the argument and treat it accordingly, I am sure
that there is a function for that in R.

My questions are:

1. Is there a predefined function for this? I am not trying to
reinvent the wheel, but I have searched help and found nothing
relevant.

2. Would it make sense to propose the extension of floor, trunc etc to
complex numbers? It would certainly make my life easier in many
situations.

Regards,

Tamas Papp

-- 
Tam?s K. Papp
E-mail: tpapp at axelero.hu (preferred, especially for large messages)
        tpapp at westel900.net
Please try to send only (latin-2) plain text, not HTML or other garbage.


From partha_bagchi at hgsi.com  Thu Apr 17 16:38:06 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Thu, 17 Apr 2003 10:38:06 -0400
Subject: [R] Validation of R
Message-ID: <OF45D0DD1D.46A0D82D-ON85256D0B.004F5E71-85256D0B.005063BF@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030417/8b7d9565/attachment.pl

From plummer at iarc.fr  Thu Apr 17 16:52:58 2003
From: plummer at iarc.fr (Martyn Plummer)
Date: 17 Apr 2003 16:52:58 +0200
Subject: [R] Problem with R 1.6.2 and RH 8.0?
In-Reply-To: <3E9EB8E0.7000800@nauticom.net>
References: <3A822319EB35174CA3714066D590DCD5C4F9DE@usrymx25.merck.com> 
	<3E9EB8E0.7000800@nauticom.net>
Message-ID: <1050591178.1889.63.camel@xena>

On Thu, 2003-04-17 at 16:23, Richard A. Bilonick wrote:
> When I was running R 1.6.1 (under Red Hat 8.0), R would abruptly 
> terminate from time to time. I would type in a line of code and hit 
> return, and the cursor would not move from the end of the line. Then the 
> hard drive would start churning. This goes on for at least 10 minutes. 
> Finally R terminates (finally freeing up the keyboard and display). The 
> only word printed is "Killed" immediately at the end of the last line of 
> code. I upgraded to 1.6.2 and the same thing continues to happen. This 
> happens for no apparent reason (doesn't seem to have anything to do with 
> any particular code or function).
> 
> Here is the last time:
> 
>  > library(help=ts)Killed
> 
> Has anyone seen this problem? Any idea on what I should fix/change?

Can you reproduce this problem with "R --vanilla" - i.e. without loading
your saved workspace?

Do you get the same problem if you install the RPM for Red Hat 8.0?

What is happening here is that R is trying to allocate more and more
memory. Eventually it runs out of RAM and starts using the swap space on
your hard disk - hence the churning.  When the swap space is used up,
the operating system kills the offending process.

Martyn


From edd at debian.org  Thu Apr 17 16:52:59 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 17 Apr 2003 09:52:59 -0500
Subject: [R] BATCH and tcltk
In-Reply-To: <x21y01gq7u.fsf@biostat.ku.dk>
References: <6A4BCEF0FD65344A8F496D7E520DD8B9023E9094@lobster.zhwin.ch>
	<x21y01gq7u.fsf@biostat.ku.dk>
Message-ID: <20030417145259.GA10242@sonny.eddelbuettel.com>

On Thu, Apr 17, 2003 at 04:20:53PM +0200, Peter Dalgaard BSA wrote:
> > I try to write a batch (in Windows, i have to use!) with 
> > Rcmd BATCH D:\Test.R D:\Test.Rout and
> > Rterm.exe --no-restore --no-save < D:\Test.R > D:\Test.Rout.
> > 
> > In my file Test.R are any tk-codelines (like: Window1 <- tktoplevel(); ... tkbutton...).
> > It works not interactifly, what is written in Rcmd BATCH --help.
> > 
> > Exist there a way to do it all the same?
[...]
> 
> I haven't messed with this on Windows for a while, but it might help
> to stick a tkwait.variable("foo") or something like that at the end of
> your input script. The thing is to get Tcl's event loop going - R
> usually drives it from the keyboard entry loop, but there is none in
> batch mode.

The tkttest.R demo works fine in batch mode, so you coukld study that
example:

~:> cp /mnt/d/R/rw1062/library/tcltk/demo/tkttest.R .
~:> Rcmd.exe BATCH  tkttest.R   

This is from a Cygwin shell, but that does not matter.

Hth, Dirk

-- 
Don't drink and derive. Alcohol and algebra don't mix.


From john_hendrickx at yahoo.com  Thu Apr 17 16:56:06 2003
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Thu, 17 Apr 2003 07:56:06 -0700 (PDT)
Subject: [R] R search engine and Mozilla
Message-ID: <20030417145606.25773.qmail@web14202.mail.yahoo.com>

Not really an R question but I'm hoping someone can help me out. I'm
having problems with the R help page "The R language" and Mozilla 1.3
with the Java 2 runtime environment 1.4.1_02 under Windows XP. The
problems occur on the "Search Engine & Keywords" page. I can open two
links, but after that links aren't recognized.

The problem seems to be javascript related. When I open the "Search
Engine" page, the status bar shows "Applet SearchEngine started". If
I move the cursur to a link, e.g. "attribute", the status bar shows
the link refers to
"javascript:SearchInIndex('attribute',false,true,false);") . 

If I click on the link, the page opens but the status bar shows
"stopped" and the Mozilla JavaScript Console shows an error:

Error: [Exception... "Component returned failure code: 0x80004005
(NS_ERROR_FAILURE) [nsIURI.hostPort]"  nsresult: "0x80004005
(NS_ERROR_FAILURE)"  location: "JS frame ::
chrome://navigator/content/nsBrowserStatusHandler.js :: anonymous ::
line 350"  data: no]
Source File: chrome://navigator/content/nsBrowserStatusHandler.js
Line: 350

If I move the cursor over a link, it appears correctly on the status
bar and I can open the link with no problems. But if I open e.g. the
"attr" link, then go back, the links no longer work. The status bar
shows nothing, right-clicking to open the link in a new window or tab
doesn't work either. The JavaScript Console shows the same error as
before and the following:

Security Error: Content at
wyciwyg://0/file:///C:/PROGRA~1/R/rw1062/doc/html/search/SearchEngine.html
may not load or link to
file:///C:/PROGRA~1/R/rw1062/doc/html/search/SearchEngine.html.

Reloading the current page doesn't help, it just reproduces the above
JavaScript errors.

A workaround is to use I.E., which works fine. However, I rather like
Mozilla. Any suggestions on what the problem is here? Is this an R
problem or should I report it to Mozilla.org? I'm afraid I'm
unfamiliar with JavaScript or I might have a bit of a clue as to
what's going on.

Advanced thanks for any help,
John Hendrickx


From JonesW at kssg.com  Thu Apr 17 16:52:43 2003
From: JonesW at kssg.com (Wayne Jones)
Date: Thu, 17 Apr 2003 15:52:43 +0100
Subject: [R] Testing for Stationarity of time series
Message-ID: <6B5A9304046AD411BD0200508BDFB6CB01EE213D@GIMLI>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030417/e7d7842d/attachment.pl

From rab at nauticom.net  Thu Apr 17 17:24:43 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Thu, 17 Apr 2003 11:24:43 -0400
Subject: [R] Problem with R 1.6.2 and RH 8.0?
In-Reply-To: <x2wuhtfav9.fsf@biostat.ku.dk>
References: <3A822319EB35174CA3714066D590DCD5C4F9DE@usrymx25.merck.com>
	<3E9EB8E0.7000800@nauticom.net> <x2wuhtfav9.fsf@biostat.ku.dk>
Message-ID: <3E9EC73B.600@nauticom.net>

>
>
>Haven't heard about that before. There are three things you can do:
>
>a) Upgrade to R 1.7.0 when it comes out "tomorrow" (for largish
>values of tomorrow -- depends on what Martyn's plans are for
>Easter...) and see if the problem is still there.
>
>b) Next time it happens, run "top" or "ps" in another terminal, figure
>out the process ID (say, 7913) and run strace -p 7913 and tell us what
>you see.
>
>c) Make a habit of starting R under the debugger: "R -d gdb", then in
>gdb use "run". When the bad thing happens, Ctrl-C will bring you back
>to the debugger where you say "bt" which might give us a clue. (If you
>need to interrupt R for other reasons, use Ctrl-C and enter "signal
>2"). You can also attach gdb to a running R much in the same way as
>strace.
> 
>
>  
>
Thanks. I will try this. I have a habit of leaving many windows and 
programs open on 8 virtual desktops. I think this may be the cause of 
the slowdown in the system (as open windows and programs pile up). It 
takes longer and longer to open a new shell, etc. I closed all the 
programs and windows and then logged out and back in to see if that is 
connected to the problem running R.

I just have a few windows open and already it takes a LONG time to open 
a shell window. Other programs start right up. Guess it's time to go to 
RH help list.

Rick B.


From spencer.graves at pdf.com  Thu Apr 17 17:01:48 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 17 Apr 2003 08:01:48 -0700
Subject: [R] a quick Q on dataframe
References: <Pine.SOL.4.33.0304162344470.13019-100000@panther.cs.ucla.edu>
Message-ID: <3E9EC1DC.70200@pdf.com>

 > dimnames(amat) <- list(letters[1:2], LETTERS[3:4])
 > data.frame(amat)
   C D
a 1 3
b 2 4
 > as.data.frame(amat)
   C D
a 1 3
b 2 4
 >
Read "?data.frame" to see the difference between "data.frame" and 
"as.data.frame".

hth
Spencer Graves

Yan Yu wrote:
> How to make a dataframe from a vector or matrix?
> 
> thanks,
> yan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tlumley at u.washington.edu  Thu Apr 17 17:03:07 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 17 Apr 2003 08:03:07 -0700 (PDT)
Subject: [R] Validation of R
In-Reply-To: <4185163.1050585873831.JavaMail.nobody@ernie.psp.pas.earthlink.net>
Message-ID: <Pine.A41.4.44.0304170752200.227706-100000@homer01.u.washington.edu>

On Thu, 17 Apr 2003, Brett Magill wrote:

> The national institute of standards and technology offers reference data
> sets and expected results for various statistical procedures using these
> data sets.  From the web site:
>
> "The purpose of this project is to improve the accuracy of statistical
> software by providing reference datasets with certified computational
> results that enable the objective evaluation of statistical software."
>

Yes, but the NIST tests I have seen (possibly an unrepresentative subset)
have been testing IMO the wrong thing. That is, they are good for finding
out where the rounding errors come in when the procedures are really
stressed.

They say
 "In response to industrial concerns about the numerical accuracy of
  computations from statistical software, the Statistical Engineering and
  Mathematical and Computational Sciences Divisions of NIST's Information
  Technology Laboratory are providing datasets with certified values for a
  variety of statistical methods."

In practice I think there's more danger from the wrong calculations being
done rather that from the results being accurate to 6 not  10
digits. Or from the wrong maximum being found in a multi-modal function,
which again is difficult to test.

It's perhaps also worth noting that the worst situation I know of in
recent years arose from accepting a poor default for a user-adjustable
precision setting (in S-PLUS, not that it really matters where).


	-thomas


From rab at nauticom.net  Thu Apr 17 17:31:54 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Thu, 17 Apr 2003 11:31:54 -0400
Subject: [R] Problem with R 1.6.2 and RH 8.0?
In-Reply-To: <1050591178.1889.63.camel@xena>
References: <3A822319EB35174CA3714066D590DCD5C4F9DE@usrymx25.merck.com>
	<3E9EB8E0.7000800@nauticom.net> <1050591178.1889.63.camel@xena>
Message-ID: <3E9EC8EA.8070504@nauticom.net>

Martyn Plummer wrote:

>Can you reproduce this problem with "R --vanilla" - i.e. without loading
>your saved workspace?
>
>Do you get the same problem if you install the RPM for Red Hat 8.0?
>
>What is happening here is that R is trying to allocate more and more
>memory. Eventually it runs out of RAM and starts using the swap space on
>your hard disk - hence the churning.  When the swap space is used up,
>the operating system kills the offending process.
>
>Martyn
>
>
>
>  
>
I haven't tried it with vanilla options. The problem occurs randomly and 
almost all my work is connected with one project at the moment. I 
installed both 1.6.1 and 1.6.2 from the rpm binary for RH 8.0. The 
Compaq Deskpro EN has  319mb of memory but this seems to be eaten up 
quickly with Mozilla running. Most of the physical memory gets cached 
right away.

Rick B.


From spencer.graves at pdf.com  Thu Apr 17 17:12:31 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 17 Apr 2003 08:12:31 -0700
Subject: [R] A function as argument of another function
References: <003a01c304b5$5f397aa0$5c13070a@it.giustizia.it>
Message-ID: <3E9EC45F.5090105@pdf.com>

What you wrote works if "fn" is a function.  If it is a character 
string, I would look at Venables and Ripley (2000) S Programming;  I 
believe they discuss several ways of doing that.

For certain applications of this nature, I have used constructs like 
"eval(pars(text= paste('...')))".

hth,
Spencer Graves

vito muggeo wrote:
> Dear all,
> I would like to write a function like:
> myfun<-function(x,fn) {xx<-exp(x); x*fn(xx)}
> where fn is a symbolic description of any function with its argument to be
> specified. Therefore
> myfun(5,"2+0.3*y^2")
> should return 5*(2+0.3*exp(5)^2),
> myfun(5,"log(y)") should return 5*log(exp(5)) and so on.
> 
> I tried with "expression" and others, but without success. How can I solve
> my problem?
> 
> Many thanks,
> vito
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Thu Apr 17 17:12:31 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 17 Apr 2003 08:12:31 -0700
Subject: [R] A function as argument of another function
References: <003a01c304b5$5f397aa0$5c13070a@it.giustizia.it>
Message-ID: <3E9EC45F.5090105@pdf.com>

What you wrote works if "fn" is a function.  If it is a character 
string, I would look at Venables and Ripley (2000) S Programming;  I 
believe they discuss several ways of doing that.

For certain applications of this nature, I have used constructs like 
"eval(pars(text= paste('...')))".

hth,
Spencer Graves

vito muggeo wrote:
> Dear all,
> I would like to write a function like:
> myfun<-function(x,fn) {xx<-exp(x); x*fn(xx)}
> where fn is a symbolic description of any function with its argument to be
> specified. Therefore
> myfun(5,"2+0.3*y^2")
> should return 5*(2+0.3*exp(5)^2),
> myfun(5,"log(y)") should return 5*log(exp(5)) and so on.
> 
> I tried with "expression" and others, but without success. How can I solve
> my problem?
> 
> Many thanks,
> vito
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From rab at nauticom.net  Thu Apr 17 17:52:12 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Thu, 17 Apr 2003 11:52:12 -0400
Subject: [R] 
	Using Coefficients Estimated from arima function using xreg argument
In-Reply-To: <6B5A9304046AD411BD0200508BDFB6CB01EE213D@GIMLI>
References: <6B5A9304046AD411BD0200508BDFB6CB01EE213D@GIMLI>
Message-ID: <3E9ECDAC.3000908@nauticom.net>

Does anyone know how to write the ARIMA time series model based on 
coefficients estimated using the arima function with argumetn xreg? I 
can exactly reproduce the corresponding forecasts manually to match 
predict.Arima for simple AR(p) models. But if I add just one exogenous 
variable with xreg to an AR(1) model for the dependent time series, I 
cannot get the manual forecast to match predict.Arima with newxreg 
argument. The help file for arima does not write out the model for the 
case of using xreg. What am I missing?

Rick B.


From spencer.graves at pdf.com  Thu Apr 17 17:37:24 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 17 Apr 2003 08:37:24 -0700
Subject: [R] Validation of R
References: <CFBD404F5E0C9547B4E10B7BDC3DFA2F6621D2@usrymx18.merck.com>
Message-ID: <3E9ECA34.4040808@pdf.com>

	  Just to amplify on one of Bill Pikounis' remarks:  I found bugs with 
S-Plus code roughly 16 months ago.  I fixed them myself for my own use. 
  Legally, my modifications could go no further.  If I took the time to 
try to convince the Insightful developers that the bugs were worth 
fixing, they would consider my fixes of develop their own.  However, 
since I modified their functions, it would have been a violation of 
copyright law for me to distribute my fix any further.  If the bug had 
been in C or Fortran, I would have had to develop a correct replacement 
from scratch.

	  Open source is very different.  If I find a bug, I'm encouraged to 
program a fix and offer it to the world.

Spencer Graves

Pikounis, Bill wrote:
> Hi Rob,
> 
> 
>>We conduct contract virology research for large pharma companies. My
>>question is how do we validate this software? I wonder if anyone else
>>has had the problem and might be able to comment.
> 
> 
> Notwithstanding the disclaimer automatically appended below by my "Big
> Pharma" member IT dept on all my email sends, I have not had this problem,
> or perhaps more accurately, not allowed it to be a problem when work I have
> done in R has made it into drug application filings and responses to FDA and
> European regulatory agencies.
> 
> "Validation" of software is an ill-defined concept, so I am afraid I cannot
> offer anything like a concrete "how-to", not would I be surprised if anyone
> else can.  What I would like to suggest is to (1) ask your vendor companies
> what specifically they are concerned about, (2) benchmark some guidelines on
> how you all or others have "validated" other software.
> 
> If you are looking for extensive documentation on whats/hows/whys of R, it
> already has it.  If you are looking for it to compute the same values as
> "validated" software within realistic numeric accuracy for your procedures,
> that is straightforward to do.  And the ultimate key is that anyone can look
> at the source code and have a high probability to get it to run on any
> reasonably current system, and even many systems not so current. 
> 
> On a visible, continuous (daily), *OPEN* basis, there is ongoing review and
> input from the R user community, as well as all the highest standards of
> software engineering that are met by the R core team and other developers. R
> clearly stands up to rigorous, scholastic scrutiny. In my very grateful
> view, this makes R at least as reliable as commercial vendor software that
> claims "validation" or "compliance", etc., ...and probably, more reliable. 
> 
> Hope that helps.
> Bill
> ----------------------------------------
> Bill Pikounis, Ph.D.
> Biometrics Research Department
> Merck Research Laboratories
> PO Box 2000, MailDrop RY84-16  
> 126 E. Lincoln Avenue
> Rahway, New Jersey 07065-0900
> USA
> 
> v_bill_pikounis at merck.com
> 
> Phone: 732 594 3913
> Fax: 732 594 1565
> 
> 
> 
>>-----Original Message-----
>>From: Rob Lambkin [mailto:r.lambkin at retroscreen.com]
>>Sent: Thursday, April 17, 2003 4:51 AM
>>To: r-help at stat.math.ethz.ch
>>Cc: Shobana Balasingam; Seb Bossuyt; Katie Benjamin; Alex Mann
>>Subject: [R] Validation of R
>>
>>
>>Hi All
>>
>>I am really very interested in starting to use R within our company. I
>>particularly like the open source nature of the product. My 
>>company is a
>>medical research company which is part of the University of London.
>>
>>We conduct contract virology research for large pharma companies. My
>>question is how do we validate this software? I wonder if anyone else
>>has had the problem and might be able to comment.
>>
>>Thanks
>>
>>Rob
>>
>>
>>Robert Lambkin BSc (Hon's), MRPharmS, PhD
>>Director and General Manager
>>Retroscreen Limited 
>>Retroscreen Virology Limited
>>The Medical Building, Queen Mary, University of London,   327 Mile End
>>Road, London, E1 4NS
>>Tel: 020 7882 7624  Fax: 020 7882 6990
>>(Retroscreen Virology Ltd. Registered in England & Wales No:2326557) 
>> 
>>The information contained in this message is confidential and is
>>intended for the addressee(s) only. If you have received this 
>>message in
>>error or there are any problems please notify the originator
>>immediately. 
>> 
>>Unauthorised use, disclosure, copying or alteration of this message is
>>strictly forbidden.
>>
>>Retroscreen Virology Limited will not be liable for any 
>>action taken in
>>reliance on the data contained in this e-mail as it may not have been
>>quality assessed or assured.
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tplate at blackmesacapital.com  Thu Apr 17 17:41:59 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Thu, 17 Apr 2003 09:41:59 -0600
Subject: [R] Local parameter calculation
In-Reply-To: <HDEPJCAKDEJMEEHKJOKEMEGGCAAA.myao@ou.edu>
Message-ID: <5.2.1.1.2.20030417082236.075e81d8@mailhost.blackmesacapital.com>

At Wednesday 01:21 PM 4/16/2003 -0500, Minghua Yao <myao at ou.edu> wrote:
>[...]
>I have 2 vectors X and Y that have a equal length of several thousand. I see
>Y as the function of X. Both of them are random. X is not arrranged in any
>order. Of course, I do plot(X,Y). Now, I want to use a sliding narrow window
>to run over each X, then calculate the variances within that window.
>[...]

Here's an example of how this can be done using general R functions:

 > # Example of randomly ordered data
 > x <- sample(1:10)
 > y <- ifelse(x%%2, x, -x)
 > cbind(x, y)
        x   y
  [1,] 10 -10
  [2,]  3   3
  [3,]  8  -8
  [4,]  1   1
  [5,]  6  -6
  [6,]  7   7
  [7,]  9   9
  [8,]  5   5
  [9,]  2  -2
[10,]  4  -4
 > # Order the data by x
 > x.order <- order(x)
 > x <- x[x.order]
 > y <- y[x.order]
 > cbind(x, y)
        x   y
  [1,]  1   1
  [2,]  2  -2
  [3,]  3   3
  [4,]  4  -4
  [5,]  5   5
  [6,]  6  -6
  [7,]  7   7
  [8,]  8  -8
  [9,]  9   9
[10,] 10 -10
 > # var.window calculates variance on a window of length "len", of z, 
ending at i
 > var.window <- function(i, z, len) var(z[seq(from=max(0,i-len+1),to=i)])
 > sapply(seq(along=x), var.window, z=y, len=3)
  [1]         NA   4.500000   6.333333  13.000000  22.333333  34.333333
  [7]  49.000000  66.333333  86.333333 109.000000
 >

Hope this helps,

Tony Plate


From billthebrute at yahoo.fr  Thu Apr 17 17:47:03 2003
From: billthebrute at yahoo.fr (=?iso-8859-1?q?william=20ritchie?=)
Date: Thu, 17 Apr 2003 17:47:03 +0200 (CEST)
Subject: [R] NA
Message-ID: <20030417154703.83599.qmail@web41101.mail.yahoo.com>

I know this has allready been asked but...
HOW TO I GET RID OF NA's IN A LIST!!!!


From J.Illian at abertay.ac.uk  Thu Apr 17 17:54:39 2003
From: J.Illian at abertay.ac.uk (J.Illian@abertay.ac.uk)
Date: Thu, 17 Apr 2003 16:54:39 +0100
Subject: [R] glm:  NA/NaN/Inf in foreign function call 
Message-ID: <F934BF2710426B44833B8677AF47F2467486D3@mail3.tay.ac.uk>

Dear all,
I am running the glm function (family: Poisson) in R and most of the time it
works fine. But sometimes, with large data sets, I get the following error
message:
Error: NA/NaN/Inf in foreign function call (arg 1) 

What puzzles me most about this is the fact that there are no missing values
in my vectors at all- so where do the missing values come from? Could this
be related to the size of the vectors I use?

Thanks

Janine

------------------------------------------
Peace cannot be kept by force. It can only be achieved through
understanding. 
Albert Einstein  

Janine Illian
lecturer in statistics
SIMBIOS
School of Computing and Advanced Technologies
University of Abertay Dundee
Bell Street
Dundee, DD1 1HG 
Scotland, UK
Tel: +44-(0)1382-308488
Fax: +44-(0)1382-308537


From J.Illian at abertay.ac.uk  Thu Apr 17 17:54:39 2003
From: J.Illian at abertay.ac.uk (J.Illian@abertay.ac.uk)
Date: Thu, 17 Apr 2003 16:54:39 +0100
Subject: [R] glm:  NA/NaN/Inf in foreign function call 
Message-ID: <F934BF2710426B44833B8677AF47F2467486D3@mail3.tay.ac.uk>

Dear all,
I am running the glm function (family: Poisson) in R and most of the time it
works fine. But sometimes, with large data sets, I get the following error
message:
Error: NA/NaN/Inf in foreign function call (arg 1) 

What puzzles me most about this is the fact that there are no missing values
in my vectors at all- so where do the missing values come from? Could this
be related to the size of the vectors I use?

Thanks

Janine

------------------------------------------
Peace cannot be kept by force. It can only be achieved through
understanding. 
Albert Einstein  

Janine Illian
lecturer in statistics
SIMBIOS
School of Computing and Advanced Technologies
University of Abertay Dundee
Bell Street
Dundee, DD1 1HG 
Scotland, UK
Tel: +44-(0)1382-308488
Fax: +44-(0)1382-308537


From mschwartz at medanalytics.com  Thu Apr 17 17:57:20 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 17 Apr 2003 10:57:20 -0500
Subject: [R] R search engine and Mozilla
In-Reply-To: <20030417145606.25773.qmail@web14202.mail.yahoo.com>
References: <20030417145606.25773.qmail@web14202.mail.yahoo.com>
Message-ID: <3E9ECEE0.8030708@medanalytics.com>

John Hendrickx wrote:
> Not really an R question but I'm hoping someone can help me out. I'm
> having problems with the R help page "The R language" and Mozilla 1.3
> with the Java 2 runtime environment 1.4.1_02 under Windows XP. The
> problems occur on the "Search Engine & Keywords" page. I can open two
> links, but after that links aren't recognized.
> 
> The problem seems to be javascript related. When I open the "Search
> Engine" page, the status bar shows "Applet SearchEngine started". If
> I move the cursur to a link, e.g. "attribute", the status bar shows
> the link refers to
> "javascript:SearchInIndex('attribute',false,true,false);") . 
> 
> If I click on the link, the page opens but the status bar shows
> "stopped" and the Mozilla JavaScript Console shows an error:
> 
> Error: [Exception... "Component returned failure code: 0x80004005
> (NS_ERROR_FAILURE) [nsIURI.hostPort]"  nsresult: "0x80004005
> (NS_ERROR_FAILURE)"  location: "JS frame ::
> chrome://navigator/content/nsBrowserStatusHandler.js :: anonymous ::
> line 350"  data: no]
> Source File: chrome://navigator/content/nsBrowserStatusHandler.js
> Line: 350
> 
> If I move the cursor over a link, it appears correctly on the status
> bar and I can open the link with no problems. But if I open e.g. the
> "attr" link, then go back, the links no longer work. The status bar
> shows nothing, right-clicking to open the link in a new window or tab
> doesn't work either. The JavaScript Console shows the same error as
> before and the following:
> 
> Security Error: Content at
> wyciwyg://0/file:///C:/PROGRA~1/R/rw1062/doc/html/search/SearchEngine.html
> may not load or link to
> file:///C:/PROGRA~1/R/rw1062/doc/html/search/SearchEngine.html.
> 
> Reloading the current page doesn't help, it just reproduces the above
> JavaScript errors.
> 
> A workaround is to use I.E., which works fine. However, I rather like
> Mozilla. Any suggestions on what the problem is here? Is this an R
> problem or should I report it to Mozilla.org? I'm afraid I'm
> unfamiliar with JavaScript or I might have a bit of a clue as to
> what's going on.
> 
> Advanced thanks for any help,
> John Hendrickx


This is a known Mozilla problem that has been raised here under Linux as 
well.  It has to do with the use of the 'wyciwyg' protocol to display 
dynamically generated pages in Mozilla. It results in the inability to 
use the Back and Forward buttons to retrieve such pages from Mozilla's 
cache.

One Bugzilla post that I saw suggested that this is actually an 
intentional security feature to prevent URL spoofing, hence the security 
warning that is given.

Lacking additional data, it is this difference (the wyciwyg protocol) 
that allows IE to work but not Mozilla, in this scenario.

The best "workaround" at this point is to use Mozilla's tabbed browsing 
feature to display the specific help page that you want to display from 
the search results.  Open that page in a new tab. Then just close that 
tab and go back to the main search page.

Perhaps this is something that will get resolved when the Moz folks make 
further progress on breaking out the browser, now known as Firebird 
(formerly Phoenix, though the use of Firebird results in other issues).

Time will tell.

HTH,

Marc


From rab at nauticom.net  Thu Apr 17 18:23:56 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Thu, 17 Apr 2003 12:23:56 -0400
Subject: [R] Subsetting Time Series
In-Reply-To: <16030.50815.986982.126070@gargle.gargle.HOWL>
References: <3E9EBDFA.5040801@nauticom.net>
	<16030.50815.986982.126070@gargle.gargle.HOWL>
Message-ID: <3E9ED51C.8040901@nauticom.net>

Martin Maechler wrote:

>
>It seems you want to  *replace*  rather than  *subset* 
>(otherwise, try to be more specific), and 
>there's no problem with that, e.g., with first two lines from
>example(ts) :
>
>  
>
>>gnp <- ts(cumsum(1 + round(rnorm(100), 2)), start = c(1954,7), frequency= 12)
>>plot(gnp)
>>gnp[20] <- 80
>>str(gnp)
>>    
>>
> Time-Series [1:100] from 1954 to 1963: 2.47 3.26 4.50 5.18 6.31 ...
>  
>
>>lines(gnp, col=2)
>>    
>>
>
>------------
>
>If you really want to subset, you can use  window(.) on your
>time series, but only for those kinds of subsetting.
>General subsetting doesn't give regularly spaced series.
>
>{"thinning" (e.g. taking every 2nd value) would be one kind of
> subsetting that could be made to work ... 
> --> proposals please to R-devel at lists.R-project.org :-) 
>}
>
>Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
>Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
>ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
>phone: x-41-1-632-3408		fax: ...-1228			<><
>
>
>  
>
There does seem to be a problem in 1.6.2 - or am I missing something? 
First, x is a ts object. Once I use subsetting notation to replace one 
value, x does not seem to print correctly, and is.ts reports FALSE:

 > x <- ts(1:12,start=c(2003,1),frequency=12)
 > x
     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
2003   1   2   3   4   5   6   7   8   9  10  11  12
 > x[1]
[1] 1
 > x[1] <- 9
 > x
 [1]  9  2  3  4  5  6  7  8  9 10 11 12
attr(,"tsp")
[1] 2003.000 2003.917   12.000
attr(,"class")
[1] "ts"
 > x
 [1]  9  2  3  4  5  6  7  8  9 10 11 12
attr(,"tsp")
[1] 2003.000 2003.917   12.000
attr(,"class")
[1] "ts"
 > as.ts(x)
     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
2003   9   2   3   4   5   6   7   8   9  10  11  12
 > is.ts(x)
[1] FALSE

Is it supposed to work this way?

Rick B.


From luke at inpharmatica.co.uk  Thu Apr 17 18:02:36 2003
From: luke at inpharmatica.co.uk (Luke Whitaker)
Date: Thu, 17 Apr 2003 17:02:36 +0100 (BST)
Subject: [R] Measure of linearity between two variables?
In-Reply-To: <200304170927.h3H9IJUk028293@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.21.0304171639140.22369-100000@dollis-hill.inpharmatica.co.uk>


Hello,

I am looking for a measure of linearity in the relationship between
two variables.

Specifically, I have two variables for which the relationship is
reasonably linear over a certain range of values, and then diverges
from linearity at either end of the range, as one or other variable
"saturates" at a maximum or minimum value. I want to identify the
region of linearity, where neither variable has saturated.

This is a problem that will be repeated many times so I want a
programmatic solution.  I am intending to implement some kind of
search over the central range of values, expanding out and testing
for linearity over each incrementally increased range. However,
I need a measure if linearity.

So far, I have thought of doing a regression on x ~ y + y^2, and
using the absolute value of the ratio of coefficients of the squared
and linear terms. Does anyone have any better ideas, either for a
linearity measure or a different approach to finding the region of
linearity between the two variables ?

Thanks,

Luke Whitaker


From maechler at stat.math.ethz.ch  Thu Apr 17 18:05:55 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 17 Apr 2003 18:05:55 +0200
Subject: [R] Testing for whole numbers
In-Reply-To: <20030417144730.GA1194@localhost>
References: <20030417144730.GA1194@localhost>
Message-ID: <16030.53475.248477.16961@gargle.gargle.HOWL>

>>>>> "Tamas" == Tamas Papp <tpapp at axelero.hu>
>>>>>     on Thu, 17 Apr 2003 16:47:30 +0200 writes:

    Tamas> Is there a way in R to test if a given number is an integer, ie a
    Tamas> whole number? I am not referring to the data type of a number, but to
    Tamas> its value.

    Tamas> That is to say, is.whole(pi-pi+2) would be TRUE, whereas is.whole(4/3)
    Tamas> would be false. At the moment I am using

    Tamas> is.whole <- function(a) { floor(a)==a }

    Tamas> which is OK for real numbers, but not for complex ones (a+bi would be
    Tamas> a whole number if both a and b are whole). Although it's obvious to
    Tamas> test for the type of the argument and treat it accordingly, I am sure
    Tamas> that there is a function for that in R.

    Tamas> My questions are:

    Tamas> 1. Is there a predefined function for this? I am not trying to
    Tamas> reinvent the wheel, but I have searched help and found nothing
    Tamas> relevant.

No, not in the standard packages at least.
Following your original, I'd recommend to use

is.whole <- function(a) { 
   (is.numeric(a) && floor(a)==a) ||
   (is.complex(a) && floor(Re(a)) == Re(a) && floor(Im(a)) == Im(a))
}

or rather something like

is.whole <- function(a, tol = 1e-7) { 
   is.eq <- function(x,y) { 
	 r <- all.equal(x,y, tol=tol)
	 is.logical(r) && r 
   }
   (is.numeric(a) && is.eq(a, floor(a))) ||
   (is.complex(a) && {ri <- c(Re(a),Im(a)); is.eq(ri, floor(ri))})
}


    Tamas> 2. Would it make sense to propose the extension of
    Tamas> floor, trunc etc to complex numbers? It would
    Tamas> certainly make my life easier in many situations.

It would make sense to propose, yes.
[ Actually maybe another nice test bed for using S4 methods? ]
Even better, if you'd provide the necessary code patches.

But, then, you'd find that R (as well as the other S
implementations) are lacking much of complex number computing
facilities you might want to dream of.
To provide some of these would require a *lot* of more source
code, though that's not true for floor.
One reason for the lack of extensive complex support has been
the rare use of it in (main stream) statistics.
But, as said above:  Improvements are welcome!

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From fharrell at virginia.edu  Thu Apr 17 18:10:47 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu, 17 Apr 2003 12:10:47 -0400
Subject: [R] Validation of R
In-Reply-To: <OF45D0DD1D.46A0D82D-ON85256D0B.004F5E71-85256D0B.005063BF@hgsi.com>
References: <OF45D0DD1D.46A0D82D-ON85256D0B.004F5E71-85256D0B.005063BF@hgsi.com>
Message-ID: <20030417121047.3e8ef2e0.fharrell@virginia.edu>

On Thu, 17 Apr 2003 10:38:06 -0400
partha_bagchi at hgsi.com wrote:

> However, the perception out there is the "SAS is the accepted software" 
> especially for regulatory submission and especially in the US. Thus, I 
> think validation usually means "Yeah, but did you use SAS to get the 
> answer" , no matter how irrelevant the question is. For a 
> non-statistician, or a person doing validation certain software do not 
> need validation (Microsoft Word, SAS etc.) certain other , perhaps more so 
> for open source, validation is essential.

SAS is NOT the accepted software for FDA, because FDA does not accept ANY brand of software.  This is really a "mind share" issue at pharma companies.  SAS is not validated in every sense; there is a huge list of current SAS bugs.

Validation is best done on a per-project basis as you can't anticipate all aspects of a particular dataset.  The validation can be done by independent calculations of pivotal findings.  For R there is an especially good opportunity because if you are using the base packages you can run essentially the same code in S-Plus to get an independent validation of the underlying calculations (but not of your S code).  The base code in R is independent of that in S-Plus (this is not true of most add-on packages by users).  There is no other "SAS" you can run.

---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From sundar.dorai-raj at pdf.com  Thu Apr 17 18:09:18 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 17 Apr 2003 11:09:18 -0500
Subject: [R] R-1.7.0 WIN2000 INSTALL
References: <3A822319EB35174CA3714066D590DCD5C4F9DA@usrymx25.merck.com>
	<3E9EA78D.1000604@pdf.com> <3E9EB27B.80106@neptuneinc.org>
Message-ID: <3E9ED1AE.8070500@pdf.com>



Thomas Stockton wrote:
> Sundar,
> 
> Looks like Perl is in the PATH before ".". ?
> 
> Tom
> 


It seems that this was the problem and R was installed successfully. 
However, none of the Recommended packages were installed (i.e. those 
packages found in D:\R\R-1.7.0\src\library\Recommended\*.tgz). And if I 
try to use install.packages I get:

 > install.packages("nlme")
trying URL `http://cran.r-project.org/bin/windows/contrib/1.7/PACKAGES'
Content type `text/plain; charset=iso-8859-1' length 8762 bytes
opened URL
downloaded 8762 bytes

Warning message:
No package "nlme" on CRAN. in: download.packages(pkgs, destdir = tmpd, 
available = available,
 >


Regards,
Sundar


From maechler at stat.math.ethz.ch  Thu Apr 17 18:20:48 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 17 Apr 2003 18:20:48 +0200
Subject: [R] Subsetting Time Series
In-Reply-To: <3E9ED51C.8040901@nauticom.net>
References: <3E9EBDFA.5040801@nauticom.net>
	<16030.50815.986982.126070@gargle.gargle.HOWL>
	<3E9ED51C.8040901@nauticom.net>
Message-ID: <16030.54368.445189.163811@gargle.gargle.HOWL>

>>>>> "Richard" == Richard A Bilonick <rab at nauticom.net>
>>>>>     on Thu, 17 Apr 2003 12:23:56 -0400 writes:

   Richard> Martin Maechler wrote:

  >> It seems you want to  *replace*  rather than  *subset* 
  >> (otherwise, try to be more specific), and 
  >> there's no problem with that, e.g., with first two lines from
  >> example(ts) :
  >> 
  >> 
  >> 
  >> > gnp <- ts(cumsum(1 + round(rnorm(100), 2)), start = c(1954,7), frequency= 12)
  >> > plot(gnp)
  >> > gnp[20] <- 80
  >> > str(gnp)
  >> Time-Series [1:100] from 1954 to 1963: 2.47 3.26 4.50 5.18 6.31 ...
  >> > lines(gnp, col=2)
  >> 
  >> ------------
  >> 
  >> If you really want to subset, you can use  window(.) on your
  >> time series, but only for those kinds of subsetting.
  >> General subsetting doesn't give regularly spaced series.
  >> 
  >> {"thinning" (e.g. taking every 2nd value) would be one kind of
  >> subsetting that could be made to work ... 
  --> proposals please to R-devel at lists.R-project.org :-) 
  >> }

    Richard> There does seem to be a problem in 1.6.2 - or am I
    Richard> missing something?  First, x is a ts object. Once I
    Richard> use subsetting notation to replace one value, x
    Richard> does not seem to print correctly, and is.ts reports
    Richard> FALSE:

    >> x <- ts(1:12,start=c(2003,1),frequency=12)
    >> x
    Richard> Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
    Richard> 2003   1   2   3   4   5   6   7   8   9  10  11  12
    >> x[1]
    Richard> [1] 1
    >> x[1] <- 9
    >> x
    Richard> [1]  9  2  3  4  5  6  7  8  9 10 11 12
    Richard> attr(,"tsp")
    Richard> [1] 2003.000 2003.917   12.000
    Richard> attr(,"class")
    Richard> [1] "ts"
    >> x
    Richard> [1]  9  2  3  4  5  6  7  8  9 10 11 12
    Richard> attr(,"tsp")
    Richard> [1] 2003.000 2003.917   12.000
    Richard> attr(,"class")
    Richard> [1] "ts"
    >> as.ts(x)
    Richard> Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
    Richard> 2003   9   2   3   4   5   6   7   8   9  10  11  12
    >> is.ts(x)
    Richard> [1] FALSE

    Richard> Is it supposed to work this way?

No.  Yes, there's a bug in there, 
but only when the time series is constructed from an *integer*
vector -- which is very rare in practice but happens in these
toy examples (and we had one report of practical data !)
Anyway,
     ---> your personal first reason to upgrade to version 1.7.0 !

If you use   as.numeric(1:12)    instead of   1:12
in your examples, all is well, even for R versions prior to 1.7

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From bates at stat.wisc.edu  Thu Apr 17 18:21:51 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 17 Apr 2003 11:21:51 -0500
Subject: [R] glm:  NA/NaN/Inf in foreign function call
In-Reply-To: <F934BF2710426B44833B8677AF47F2467486D3@mail3.tay.ac.uk>
References: <F934BF2710426B44833B8677AF47F2467486D3@mail3.tay.ac.uk>
Message-ID: <6rof35gkm8.fsf@bates4.stat.wisc.edu>

J.Illian at abertay.ac.uk writes:

> Dear all,
> I am running the glm function (family: Poisson) in R and most of the time it
> works fine. But sometimes, with large data sets, I get the following error
> message:
> Error: NA/NaN/Inf in foreign function call (arg 1) 
> 
> What puzzles me most about this is the fact that there are no missing values
> in my vectors at all- so where do the missing values come from? Could this
> be related to the size of the vectors I use?

Try using control = list(trace = TRUE) in your call to glm to see what
the progress of the IRLS algorithm is.


From baron at psych.upenn.edu  Thu Apr 17 18:34:05 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 17 Apr 2003 12:34:05 -0400
Subject: [R] R Install problems with Redhat 9 : "tcl.so" versus "tcl.so.0"
In-Reply-To: <3E9F0150.4070302@hppi.troitsk.ru>
References: <000001c3048c$9dc48360$6401a8c0@bigdell2k>
	<3E9F0150.4070302@hppi.troitsk.ru>
Message-ID: <20030417163405.GA2402@mail2.sas.upenn.edu>

I seem to have installed R-1.7 on RH 9, using the following
suggestions.  It may take a while to learn if they caused any
problems.  But basic things certainly work.

On 04/17/03 12:32, M.Kondrin wrote:
>If you haven't /usr/lib/libtcl.so.0 on your system I would suggest to 
>make a symlink 

ln -s /usr/lib/libtcl8.3.so /usr/lib/libtcl.so.0
and I also did (as suggested)
ln -s /usr/lib/libtk8.3.so /usr/lib/libtk.so.0

But the RPM still won't install because these are not registered
in the RPM database.  So I just did
rpm -Uvh -nodeps R-1.7.0-1.i386.rpm

As the README says, you do need to have blas installed, and it is
indeed on the installation disks (and in the RedHat mirror sites).

>May be ldconfig is also required.

It wasn't.

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page:            http://www.sas.upenn.edu/~baron
R page:               http://finzi.psych.upenn.edu/


From Setzer.Woodrow at epamail.epa.gov  Thu Apr 17 18:39:18 2003
From: Setzer.Woodrow at epamail.epa.gov (Setzer.Woodrow@epamail.epa.gov)
Date: Thu, 17 Apr 2003 12:39:18 -0400
Subject: [R] Validation of R
Message-ID: <OF8160859A.A93E7903-ON85256D0B.00589B9D@rtp.epa.gov>


This discussion reminds me of the hall-grousing about QA requirements
that I hear (and participate in at times!) in my Laboratory.  QA
requirements generally address issues such as record-keeping, equipment
maintenance and calibration, and standardizing methods that are used
repeatedly.  By no means does satisfying such QA requirements guarantee
that conclusions drawn under such conditions are correct!  They do help
to eliminate some common sources of error, and the cost is generally not
so great.

With respect to software validation, certainly ensuring that the package
is installed properly and gives generally correct results for
calculations helps to allay concerns of non-specialists who have to rely
on the results of the package.  In some applications, the fact that the
package used for a data analysis is completely open is a definite
advantage (for example, in a government regulatory setting, such as here
at the US EPA), since reviewers can have complete access to the
computational machinery used in the analysis.

R. Woodrow Setzer, Jr.                        Phone: (919) 541-0128
Experimental Toxicology Division             Fax:  (919) 541-4284
Pharmacokinetics Branch
NHEERL B143-05; US EPA; RTP, NC 27711


From jyan at stat.wisc.edu  Thu Apr 17 18:49:22 2003
From: jyan at stat.wisc.edu (Jun Yan)
Date: Thu, 17 Apr 2003 11:49:22 -0500 (CDT)
Subject: [R] Simulation of recurrent events
In-Reply-To: <29294.1050567067@www45.gmx.net>
Message-ID: <Pine.LNX.4.21.0304171143200.7461-100000@ludwig.stat.wisc.edu>

> I'd like to program a simulation of recurrent events to test few models in
> R. Is there anybody who has experience of that and could give me advice?

Lin, Wei, and Ying (2001) JASA 96:620-628 has method to simulate recurrent
event specified by the marginal means E[N(t)]. Covariate can be
incorporated, with even time-varying coefficient, by adjusting their
method.

Jun Yan

Department of Statistics         Office: CSSC 4252
university of Wisconsin-Madison  Tel: (608)262-7478 
1210 W. Dayton St.               Email: jyan at stat.wisc.edu
Madison, WI 53706                URL: http://www.stat.wisc.edu/~jyan/


From mschwartz at medanalytics.com  Thu Apr 17 19:05:11 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Thu, 17 Apr 2003 12:05:11 -0500
Subject: [R] R Install problems with Redhat 9 : "tcl.so" versus "tcl.so.0"
In-Reply-To: <20030417163405.GA2402@mail2.sas.upenn.edu>
References: <000001c3048c$9dc48360$6401a8c0@bigdell2k>
	<3E9F0150.4070302@hppi.troitsk.ru> <20030417163405.GA2402@mail2.sas.upenn.edu>
Message-ID: <3E9EDEC7.20804@medanalytics.com>

Jonathan Baron wrote:
> I seem to have installed R-1.7 on RH 9, using the following
> suggestions.  It may take a while to learn if they caused any
> problems.  But basic things certainly work.
> 
> On 04/17/03 12:32, M.Kondrin wrote:
> 
>>If you haven't /usr/lib/libtcl.so.0 on your system I would suggest to 
>>make a symlink 
> 
> 
> ln -s /usr/lib/libtcl8.3.so /usr/lib/libtcl.so.0
> and I also did (as suggested)
> ln -s /usr/lib/libtk8.3.so /usr/lib/libtk.so.0
> 
> But the RPM still won't install because these are not registered
> in the RPM database.  So I just did
> rpm -Uvh -nodeps R-1.7.0-1.i386.rpm
> 
> As the README says, you do need to have blas installed, and it is
> indeed on the installation disks (and in the RedHat mirror sites).
> 
> 
>>May be ldconfig is also required.
> 
> 
> It wasn't.


Until Martyn posts the RH 9 RPM up on CRAN, which should be soon I 
believe, you can build an RPM from the SRPM at:

http://cran.r-project.org/bin/linux/redhat/SRPMS/R-1.7.0-1.src.rpm

or build from the source tar file, which I have done as well.

I successfully built an RH 9 RPM this morning, though had some pdftex 
related warnings. After a discussion with Martyn off-list this morning, 
these seem to be largely a non-issue at this point.  I didn't recall 
them from RH 8.0, so I made mention of it. The install and debug RPMS 
were built and successfully installed on my RH 9 system without errors.

HTH,

Marc Schwartz


From jerome at hivnet.ubc.ca  Thu Apr 17 19:11:54 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Thu, 17 Apr 2003 10:11:54 -0700
Subject: [R] bit set or bit test
In-Reply-To: <20030417064512.35898.qmail@web10703.mail.yahoo.com>
References: <20030417064512.35898.qmail@web10703.mail.yahoo.com>
Message-ID: <200304171717.KAA06896@hivnet.ubc.ca>


Hi Mike,

I'm not sure I understand your message, but see if this example is useful.

ntharray <- rbind(c(1,0,0,1,0),c(0,0,1,0,1))
ntharray%*%2^(0:(ncol(ntharray)-1))
#     [,1]
#[1,]    9
#[2,]   20

See also ?binary in package "wle".
library(wle)
binary(9,dim=5)
#$binary
#[1] 1 0 0 1 0
#
#$dicotomy
#[1]  TRUE FALSE FALSE  TRUE FALSE

HTH,
Jerome

On April 16, 2003 11:45 pm, Mike Sumner wrote:
> Hello, does R have functions for setting and testing
> bit values?
>
> I want to conserve memory for storing presence/absence
> data for large multiple arrays within a single array,
> using element values like
>
> present[x,y] <- ntharray[x,y]*(2^n)
>
> where presence is 1, non-presence is 0 and n is the
> nth array
>
> e.g.  1*(2^0) + 0*(2^1) + 0*(2^2) + 1*(2^3) + 0(2^4)
>
> for storing the value 9 for presence in the first and
> fourth array, and absence in the second, third and
> fifth arrays.
>
> Does R already have something to handle stuff like
> this?
>
> Cheers, Mike.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 

Jerome Asselin (J?r?me), Statistical Analyst
British Columbia Centre for Excellence in HIV/AIDS
St. Paul's Hospital, 608 - 1081 Burrard Street
Vancouver, British Columbia, CANADA V6Z 1Y6
Email: jerome at hivnet.ubc.ca
Phone: 604 806-9112   Fax: 604 806-9044


From bm8 at st-andrews.ac.uk  Thu Apr 17 19:13:16 2003
From: bm8 at st-andrews.ac.uk (Bernie McConnell)
Date: Thu, 17 Apr 2003 18:13:16 +0100
Subject: [R] accessing current factor in tapply
Message-ID: <5.1.0.14.0.20030417180833.00acf6e8@bute.st-and.ac.uk>

G'Day,

I want to access in a function called from tapply the current factor.  In 
my example below, all I want to do is to write the current factor on each 
histogram.  Needless to say my example does not work. I would be grateful 
for pointers in the right direction.

Many thanks
Bernie McConnell
Sea Mammal Reserach Unit


cc <- 1:10
ff <- rep(c("a","b"),5)

pp<- function(x,f) {
   hist(x, main=as.character(f))
   }


tapply(aa, ff, pp, f=ff)


From paulda at BATTELLE.ORG  Thu Apr 17 19:34:29 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Thu, 17 Apr 2003 13:34:29 -0400
Subject: [R] Measure of linearity between two variables?
Message-ID: 
 <940250A9EB37A24CBE28D858EF077749136CB5@ws-bco-mse3.milky-way.battelle.org>

Maybe I'm missing something, but why not use the Pearson Product
Moment Correlation Coefficient (r) ?  It directly measures the strength
of the linear relationship between two variables.  A simple approach
would be the following:

(1) fix a percentage p of the data you are interested in
(2) fix one of your two variables (x,y) as a reference - call
	it x
(3) subset your data.frame down to those pairs (x*,y*) 
	corresponding to the middle p percent of x
(4) calculate r for the pairs (x*,y*)

By doing (1) through (4) many time for increasing values of p
I think you'll get what you want.

Best, 
  david paul


-----Original Message-----
From: Luke Whitaker [mailto:luke at inpharmatica.co.uk] 
Sent: Thursday, April 17, 2003 12:03 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Measure of linearity between two variables?



Hello,

I am looking for a measure of linearity in the relationship between two
variables.

Specifically, I have two variables for which the relationship is reasonably
linear over a certain range of values, and then diverges from linearity at
either end of the range, as one or other variable "saturates" at a maximum
or minimum value. I want to identify the region of linearity, where neither
variable has saturated.

This is a problem that will be repeated many times so I want a programmatic
solution.  I am intending to implement some kind of search over the central
range of values, expanding out and testing for linearity over each
incrementally increased range. However, I need a measure if linearity.

So far, I have thought of doing a regression on x ~ y + y^2, and using the
absolute value of the ratio of coefficients of the squared and linear terms.
Does anyone have any better ideas, either for a linearity measure or a
different approach to finding the region of linearity between the two
variables ?

Thanks,

Luke Whitaker

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From sundar.dorai-raj at pdf.com  Thu Apr 17 19:36:46 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 17 Apr 2003 12:36:46 -0500
Subject: [R] accessing current factor in tapply
References: <5.1.0.14.0.20030417180833.00acf6e8@bute.st-and.ac.uk>
Message-ID: <3E9EE62E.9030502@pdf.com>



Bernie McConnell wrote:
> G'Day,
> 
> I want to access in a function called from tapply the current factor.  
> In my example below, all I want to do is to write the current factor on 
> each histogram.  Needless to say my example does not work. I would be 
> grateful for pointers in the right direction.
> 
> Many thanks
> Bernie McConnell
> Sea Mammal Reserach Unit
> 
> 
> cc <- 1:10
> ff <- rep(c("a","b"),5)
> 
> pp<- function(x,f) {
>   hist(x, main=as.character(f))
>   }
> 
> 
> tapply(aa, ff, pp, f=ff)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

I think it would be easier and more foolproof to use a for loop:

cc <- 1:10
ff <- rep(c("a", "b"), 5)
par(mfrow = c(1, 2))
for(f in unique(ff))
   hist(cc[ff==f], main = as.character(f))

Regards,
Sundar


From tplate at blackmesacapital.com  Thu Apr 17 19:54:15 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Thu, 17 Apr 2003 11:54:15 -0600
Subject: [R] accessing current factor in tapply
In-Reply-To: <5.1.0.14.0.20030417180833.00acf6e8@bute.st-and.ac.uk>
Message-ID: <5.2.1.1.2.20030417115210.035f0220@mailhost.blackmesacapital.com>

Here's a way (but as Sundar Dorai-Raj suggests, it might be easier to use a 
for loop.)

 > cc <- 1:10
 > ff <- rep(c("a","b"),5)
 > # a different function, so that we can see what data and what label it gets
 > data.lab <- function(data,lab) paste(paste(data, collapse=" "), 
paste(as.character(lab), collapse=" "), sep="/")
 > # ii is indices of each group of ff
 > ii <- tapply(cc, ff, c)
 > sapply(seq(along=ii), function(j, ii, cc, labs) 
data.lab(data=cc[ii[[j]]],lab=labs[j]), ii=ii, cc=cc, labs=names(ii))
[1] "1 3 5 7 9/a"  "2 4 6 8 10/b"
 >
 >


At Thursday 06:13 PM 4/17/2003 +0100, you wrote:
>G'Day,
>
>I want to access in a function called from tapply the current factor.  In 
>my example below, all I want to do is to write the current factor on each 
>histogram.  Needless to say my example does not work. I would be grateful 
>for pointers in the right direction.
>
>Many thanks
>Bernie McConnell
>Sea Mammal Reserach Unit
>
>
>cc <- 1:10
>ff <- rep(c("a","b"),5)
>
>pp<- function(x,f) {
>   hist(x, main=as.character(f))
>   }
>
>
>tapply(aa, ff, pp, f=ff)
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tblackw at umich.edu  Thu Apr 17 19:54:38 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 17 Apr 2003 13:54:38 -0400 (EDT)
Subject: [R] accessing current factor in tapply
In-Reply-To: <5.1.0.14.0.20030417180833.00acf6e8@bute.st-and.ac.uk>
Message-ID: <Pine.SOL.4.44.0304171337180.4686-100000@robotron.gpcc.itd.umich.edu>


I've just been puzzling through this for my own use.
There are three different R functions which do related
things:  tapply(), by() and aggregate().  In this context,
I think I would use  by()  rather than  tapply().  Define
cc, ff as before, and re-define

pp <- function(dat, name)
	hist(dat$x, main=as.character(unique(dat[[name]])))
then

by(data.frame(cc,ff), ff, pp, "ff")	#  should do what you want

The slightly odd syntax at the end of pp() allows its second
argument "name" to be either a string naming the selection
variable (as here) or else an integer specifying it by position
within the data frame.  If you want to split the data set on
the cross product of two factors, ff x gg, the second argument
to by() would have to be  list(ff,gg).  tapply(), by contrast,
requires the list() syntax even when there's only one factor
to split on.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 17 Apr 2003, Bernie McConnell wrote:

> G'Day,
>
> I want to access in a function called from tapply the current factor.  In
> my example below, all I want to do is to write the current factor on each
> histogram.  Needless to say my example does not work. I would be grateful
> for pointers in the right direction.
>
> Many thanks
> Bernie McConnell
> Sea Mammal Reserach Unit
>
> cc <- 1:10
> ff <- rep(c("a","b"),5)
>
> pp<- function(x,f) {
>    hist(x, main=as.character(f))
>    }
>
> tapply(aa, ff, pp, f=ff)


From spencer.graves at pdf.com  Thu Apr 17 20:44:08 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 17 Apr 2003 11:44:08 -0700
Subject: [R] Measure of linearity between two variables?
References: <940250A9EB37A24CBE28D858EF077749136CB5@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <3E9EF5F8.5030506@pdf.com>

Could you be more specific about what you want?

For example, do you want a statistical test with a significance 
probability or a measure like R^2?  Also, are your numbers bounded, 
e.g., between 0 and 1?  What kind of error structure is inherent in the 
application?  Should we think about transforming the response variable 
or using "glm" or nonlinear regression?

If I were concerned about saturation at either end, perhaps the 
simpliest thing might be to add a cubic to what you considered:

	x ~ y + I(y^2) + I(y^3)

 From this we could get significance probabilities for the squared and 
cubic terms combined.  Also, by converting the sum of squares column to 
percent, we get something like R^2.

Hope this helps.
Spencer Graves

Paul, David A wrote:
> Maybe I'm missing something, but why not use the Pearson Product
> Moment Correlation Coefficient (r) ?  It directly measures the strength
> of the linear relationship between two variables.  A simple approach
> would be the following:
> 
> (1) fix a percentage p of the data you are interested in
> (2) fix one of your two variables (x,y) as a reference - call
> 	it x
> (3) subset your data.frame down to those pairs (x*,y*) 
> 	corresponding to the middle p percent of x
> (4) calculate r for the pairs (x*,y*)
> 
> By doing (1) through (4) many time for increasing values of p
> I think you'll get what you want.
> 
> Best, 
>   david paul
> 
> 
> -----Original Message-----
> From: Luke Whitaker [mailto:luke at inpharmatica.co.uk] 
> Sent: Thursday, April 17, 2003 12:03 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Measure of linearity between two variables?
> 
> 
> 
> Hello,
> 
> I am looking for a measure of linearity in the relationship between two
> variables.
> 
> Specifically, I have two variables for which the relationship is reasonably
> linear over a certain range of values, and then diverges from linearity at
> either end of the range, as one or other variable "saturates" at a maximum
> or minimum value. I want to identify the region of linearity, where neither
> variable has saturated.
> 
> This is a problem that will be repeated many times so I want a programmatic
> solution.  I am intending to implement some kind of search over the central
> range of values, expanding out and testing for linearity over each
> incrementally increased range. However, I need a measure if linearity.
> 
> So far, I have thought of doing a regression on x ~ y + y^2, and using the
> absolute value of the ratio of coefficients of the squared and linear terms.
> Does anyone have any better ideas, either for a linearity measure or a
> different approach to finding the region of linearity between the two
> variables ?
> 
> Thanks,
> 
> Luke Whitaker
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From rab at nauticom.net  Thu Apr 17 21:44:27 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Thu, 17 Apr 2003 15:44:27 -0400
Subject: [R] Problem with arima function with xreg argument to forecast using
 predict - How to write the forecast function?
In-Reply-To: <3E9EE62E.9030502@pdf.com>
References: <5.1.0.14.0.20030417180833.00acf6e8@bute.st-and.ac.uk>
	<3E9EE62E.9030502@pdf.com>
Message-ID: <3E9F041B.9050909@nauticom.net>

Using the LakeHuron data, fit a simple AR(2) model:

 > data(LakeHuron) 
 > ar.lh <- arima(LakeHuron, order = c(2,0,0))
 > ar.lh

Call:
arima(x = LakeHuron, order = c(2, 0, 0))

Coefficients:
         ar1      ar2  intercept
      1.0436  -0.2495   579.0473
s.e.  0.0983   0.1008     0.3319

sigma^2 estimated as 0.4788:  log likelihood = -103.63,  aic = 215.27

Make a 1-step ahead forecast:

 > predict(ar.lh,1)[[1]]
Time Series:
Start = 1973
End = 1973
Frequency = 1
[1] 579.7896

Compute the forecast manually:

 > sum(ar.lh$coef*c(c(579.96,579.89)-ar.lh$coef[3],1))
[1] 579.7896

This just says that the forecast for the next period (after the end of 
the data) is 579.0473 + 1.0436*(579.96 - 579.0473) - 0.2495*(579.89 - 
579.0473). In other words: the forecast is the intercept plus the AR 
coefficients times the  (previous ts values minus the intercepts).

Now add an exogenous variable (in this case, the (year - 1920):

 > ar.lh <- arima(LakeHuron, order = c(2,0,0), xreg = time(LakeHuron)-1920)
 > ar.lh

Call:
arima(x = LakeHuron, order = c(2, 0, 0), xreg = time(LakeHuron) - 1920)

Coefficients:
         ar1      ar2  intercept  time(LakeHuron) - 1920
      1.0048  -0.2913   579.0993                 -0.0216
s.e.  0.0976   0.1004     0.2370                  0.0081

sigma^2 estimated as 0.4566:  log likelihood = -101.2,  aic = 212.4

The prediction is:

 > predict(ar.lh,1,newxreg=53)[[1]]
Time Series:
Start = 1973
End = 1973
Frequency = 1
[1] 579.3972


Now try to manually forecast where the next time period is 53:

 > sum(ar.lh$coef*c(c(579.96,579.89)-ar.lh$coef[3],1,53))
[1] 578.5907

What am I doing wrong? I've tried this with numerous examples and 
whenever there is an exogenous variable I cannot get the manual forecast 
to agree with predict. Is it not correct to just add (-0.0216 times 53) 
to the rest? I need to know how to write the model correctly. Obviously 
there is something I am overlooking. R's arima function and predict 
function work correctly - at least they agree with SAS for example so 
I'm not doing something right.

I would really appreciate some insight here.

Rick B.


From lamkelj at yahoo.com  Thu Apr 17 21:22:26 2003
From: lamkelj at yahoo.com (Kel)
Date: Thu, 17 Apr 2003 12:22:26 -0700 (PDT)
Subject: [R] HoltWinters() - p-values for alpha, beta and gamma
Message-ID: <20030417192226.47924.qmail@web12504.mail.yahoo.com>

Need your expertise for the theoretical approach to
deduce the p-values for the level, trend and
seasonality parameters.  I wonder if there's source
code available.  Thanks group.

Kel


From partha_bagchi at hgsi.com  Thu Apr 17 21:31:42 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Thu, 17 Apr 2003 15:31:42 -0400
Subject: [R] Validation of R
Message-ID: <OF094F923F.6F0D0D4D-ON85256D0B.006B0108-85256D0B.006B44D9@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030417/c8f35101/attachment.pl

From sung-youn.kim at stonybrook.edu  Thu Apr 17 21:44:06 2003
From: sung-youn.kim at stonybrook.edu (sung-youn.kim@stonybrook.edu)
Date: Thu, 17 Apr 2003 15:44:06 -0400 (EDT)
Subject: [R] graph problems with r-1.7.0 on debian (woody)
Message-ID: <200304171944.h3HJi6P4007709@smtp.ic.sunysb.edu>

Hi,

I installed r-1.7.0 from the source on Debian. For some reasons,
connections to X seems to be broken. Simply, graphs do not show up
without any warning or error messages. 

I configured the sources --with-x before I installed it. Any hints?


One other thing. I tried to uninstall r-1.7.0 using 

make uninstall 

(with r-1.6.2 remaining in the system). When I call R,
r-1.7.0 rather than r-1.6.2 is still brought up. How can I completely
uninstall r-1.7.0?   

best,


From paulda at BATTELLE.ORG  Thu Apr 17 22:18:23 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Thu, 17 Apr 2003 16:18:23 -0400
Subject: [R] Validation of R
Message-ID: 
 <940250A9EB37A24CBE28D858EF077749136CB9@ws-bco-mse3.milky-way.battelle.org>

At Battelle, the QA/QC folks have the philosophy that the
FDA will likely hold us responsible for whatever internal
standards we set for ourselves, assuming that such standards
are "reasonable".

For software, our internal standards basically say that

(1) COTS (Com'l Off The Shelf software) developed by a
company having both a long history of selling high-quality
products and good QA doesn't need extensive from-scratch
validation, only validation of simpler routines like the
computation of means, variances, linear regression models,
&etc.  (After all, how would anyone really validate what, 
say, PROC NLMIXED yields in a complex growth-curve application?)

(2) Anything free needs to be extensively validated by 
comparing it with something that fits into (1)

This leaves R completely out of our GLP studies, and favors
SAS since Insightful hasn't been around as long as the SAS 
Institute.  Like it or not, the perception is that using SAS
won't get you into trouble with the FDA or other regulatory
agencies.


-David Paul



-----Original Message-----
From: partha_bagchi at hgsi.com [mailto:partha_bagchi at hgsi.com] 
Sent: Thursday, April 17, 2003 3:32 PM
To: Frank E Harrell Jr
Cc: k.benjamin at retroscreen.com; r-help at stat.math.ethz.ch;
a.mann at retroscreen.com; s.balasingam at retroscreen.com;
r.lambkin at retroscreen.com; v_bill_pikounis at merck.com;
s.bossuyt at retroscreen.com
Subject: Re: [R] Validation of R


I agree with your points and if you notice I share your philosophical 
view. I was commenting more on what you call "mind" share. It is still 
real. 

However, also a minor point  - there is mention in the regs regarding COTS 
software (which I believe stands for Commercial of the Shelf software) ..






Frank E Harrell Jr <fharrell at virginia.edu>
04/17/2003 12:10 PM

 
        To:     partha_bagchi at hgsi.com
        cc:     v_bill_pikounis at merck.com, k.benjamin at retroscreen.com, 
r-help at stat.math.ethz.ch, a.mann at retroscreen.com, 
s.balasingam at retroscreen.com, r.lambkin at retroscreen.com, 
s.bossuyt at retroscreen.com
        Subject:        Re: [R] Validation of R


On Thu, 17 Apr 2003 10:38:06 -0400
partha_bagchi at hgsi.com wrote:

> However, the perception out there is the "SAS is the accepted 
> software" especially for regulatory submission and especially in the 
> US. Thus, I think validation usually means "Yeah, but did you use SAS 
> to get the answer" , no matter how irrelevant the question is. For a 
> non-statistician, or a person doing validation certain software do not 
> need validation (Microsoft Word, SAS etc.) certain other , perhaps 
> more
so
> for open source, validation is essential.

SAS is NOT the accepted software for FDA, because FDA does not accept ANY 
brand of software.  This is really a "mind share" issue at pharma 
companies.  SAS is not validated in every sense; there is a huge list of 
current SAS bugs.

Validation is best done on a per-project basis as you can't anticipate all 
aspects of a particular dataset.  The validation can be done by 
independent calculations of pivotal findings.  For R there is an 
especially good opportunity because if you are using the base packages you 
can run essentially the same code in S-Plus to get an independent 
validation of the underlying calculations (but not of your S code).  The 
base code in R is independent of that in S-Plus (this is not true of most 
add-on packages by users).  There is no other "SAS" you can run.

---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences U.
Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat

--
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



	[[alternate HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From andy_liaw at merck.com  Thu Apr 17 22:37:27 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 17 Apr 2003 16:37:27 -0400
Subject: [R] Validation of R
Message-ID: <3A822319EB35174CA3714066D590DCD5C4F9EF@usrymx25.merck.com>

Perception, perception, perception...

This reminds me of what I heard from Frank Harrell: "The different between S
and SAS is five years".  S has been around much longer than Insightful.
Doesn't that count?

R also comes with its own set suite ("make check", "make fullcheck", etc.).
Doesn't that count?

I guess one can try to validate NLMIXED by comparing the output with that of
nlme()...

Andy

> -----Original Message-----
> From: Paul, David A [mailto:paulda at BATTELLE.ORG]
> Sent: Thursday, April 17, 2003 4:18 PM
> To: r-help at stat.math.ethz.ch
> Subject: RE: [R] Validation of R
> 
> 
> At Battelle, the QA/QC folks have the philosophy that the
> FDA will likely hold us responsible for whatever internal
> standards we set for ourselves, assuming that such standards
> are "reasonable".
> 
> For software, our internal standards basically say that
> 
> (1) COTS (Com'l Off The Shelf software) developed by a
> company having both a long history of selling high-quality
> products and good QA doesn't need extensive from-scratch
> validation, only validation of simpler routines like the
> computation of means, variances, linear regression models,
> &etc.  (After all, how would anyone really validate what, 
> say, PROC NLMIXED yields in a complex growth-curve application?)
> 
> (2) Anything free needs to be extensively validated by 
> comparing it with something that fits into (1)
> 
> This leaves R completely out of our GLP studies, and favors
> SAS since Insightful hasn't been around as long as the SAS 
> Institute.  Like it or not, the perception is that using SAS
> won't get you into trouble with the FDA or other regulatory
> agencies.
> 
> 
> -David Paul
> 
> 
> 
> -----Original Message-----
> From: partha_bagchi at hgsi.com [mailto:partha_bagchi at hgsi.com] 
> Sent: Thursday, April 17, 2003 3:32 PM
> To: Frank E Harrell Jr
> Cc: k.benjamin at retroscreen.com; r-help at stat.math.ethz.ch;
> a.mann at retroscreen.com; s.balasingam at retroscreen.com;
> r.lambkin at retroscreen.com; v_bill_pikounis at merck.com;
> s.bossuyt at retroscreen.com
> Subject: Re: [R] Validation of R
> 
> 
> I agree with your points and if you notice I share your philosophical 
> view. I was commenting more on what you call "mind" share. It 
> is still 
> real. 
> 
> However, also a minor point  - there is mention in the regs 
> regarding COTS 
> software (which I believe stands for Commercial of the Shelf 
> software) ..
> 
> 
> 
> 
> 
> 
> Frank E Harrell Jr <fharrell at virginia.edu>
> 04/17/2003 12:10 PM
> 
>  
>         To:     partha_bagchi at hgsi.com
>         cc:     v_bill_pikounis at merck.com, 
> k.benjamin at retroscreen.com, 
> r-help at stat.math.ethz.ch, a.mann at retroscreen.com, 
> s.balasingam at retroscreen.com, r.lambkin at retroscreen.com, 
> s.bossuyt at retroscreen.com
>         Subject:        Re: [R] Validation of R
> 
> 
> On Thu, 17 Apr 2003 10:38:06 -0400
> partha_bagchi at hgsi.com wrote:
> 
> > However, the perception out there is the "SAS is the accepted 
> > software" especially for regulatory submission and 
> especially in the 
> > US. Thus, I think validation usually means "Yeah, but did 
> you use SAS 
> > to get the answer" , no matter how irrelevant the question 
> is. For a 
> > non-statistician, or a person doing validation certain 
> software do not 
> > need validation (Microsoft Word, SAS etc.) certain other , perhaps 
> > more
> so
> > for open source, validation is essential.
> 
> SAS is NOT the accepted software for FDA, because FDA does 
> not accept ANY 
> brand of software.  This is really a "mind share" issue at pharma 
> companies.  SAS is not validated in every sense; there is a 
> huge list of 
> current SAS bugs.
> 
> Validation is best done on a per-project basis as you can't 
> anticipate all 
> aspects of a particular dataset.  The validation can be done by 
> independent calculations of pivotal findings.  For R there is an 
> especially good opportunity because if you are using the base 
> packages you 
> can run essentially the same code in S-Plus to get an independent 
> validation of the underlying calculations (but not of your S 
> code).  The 
> base code in R is independent of that in S-Plus (this is not 
> true of most 
> add-on packages by users).  There is no other "SAS" you can run.
> 
> ---
> Frank E Harrell Jr              Prof. of Biostatistics & Statistics
> Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences U.
> Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat
> 
> --
> This message has been scanned for viruses and
> dangerous content by MailScanner, and is
> believed to be clean.
> 
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From rossini at blindglobe.net  Thu Apr 17 22:55:08 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Thu, 17 Apr 2003 13:55:08 -0700
Subject: [R] Validation of R
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4F9EF@usrymx25.merck.com>
	("Liaw, Andy"'s message of "Thu, 17 Apr 2003 16:37:27 -0400")
References: <3A822319EB35174CA3714066D590DCD5C4F9EF@usrymx25.merck.com>
Message-ID: <878yu8g7yr.fsf@jeeves.blindglobe.net>


>> From: Paul, David A [mailto:paulda at BATTELLE.ORG]

>> For software, our internal standards basically say that
>> 
>> (1) COTS (Com'l Off The Shelf software) developed by a
>> company having both a long history of selling high-quality
>> products and good QA doesn't need extensive from-scratch
>> validation, only validation of simpler routines like the
>> computation of means, variances, linear regression models,
>> &etc.  (After all, how would anyone really validate what, 
>> say, PROC NLMIXED yields in a complex growth-curve application?)

Too bad that can't be edited just a bit:

(1) OTS (Off the Shelf software) developed by a group having both a
long history of creating high-quality products and good QA which
doesn't need extensive from-scratch validation, only validation of
simpler routines like the computation of means, variances, linear
regression models, etc.  (After all, how would anyone really validate
what, say, nlme(), yields in a complex growth-curve application, other
than one of the originators of one of the families of NLME
algorithms?)

best,
-tony

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center 
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 
CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}


From fharrell at virginia.edu  Fri Apr 18 01:55:10 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu, 17 Apr 2003 19:55:10 -0400
Subject: [R] Validation of R
In-Reply-To: <940250A9EB37A24CBE28D858EF077749136CB9@ws-bco-mse3.milky-way.battelle.org>
References: <940250A9EB37A24CBE28D858EF077749136CB9@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <20030417195510.20a42bd4.fharrell@virginia.edu>

On Thu, 17 Apr 2003 16:18:23 -0400
"Paul, David  A" <paulda at battelle.org> wrote:

> At Battelle, the QA/QC folks have the philosophy that the
> FDA will likely hold us responsible for whatever internal
> standards we set for ourselves, assuming that such standards
> are "reasonable".
> 
> For software, our internal standards basically say that
> 
> (1) COTS (Com'l Off The Shelf software) developed by a
> company having both a long history of selling high-quality
> products and good QA doesn't need extensive from-scratch
> validation, only validation of simpler routines like the
> computation of means, variances, linear regression models,
> &etc.  (After all, how would anyone really validate what, 
> say, PROC NLMIXED yields in a complex growth-curve application?)

You can validate much of that using simulation, which is not done often enough in my opinion.

> 
> (2) Anything free needs to be extensively validated by 
> comparing it with something that fits into (1)
> 
> This leaves R completely out of our GLP studies, and favors
> SAS since Insightful hasn't been around as long as the SAS 
> Institute.  Like it or not, the perception is that using SAS
> won't get you into trouble with the FDA or other regulatory
> agencies.

> - David Paul

Since you have the option of validating free software against COTS your conclusion does not make sense to me.  And to reiterate, the perception that SAS won't get you into trouble, or more accurately speaking, the perception that non-SAS software will get you into trouble with the FDA, is only a perception.  The FDA has no guidelines on that.  And why should closed-source software be so trusted anyway? 
---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From Richard.Rowe at jcu.edu.au  Fri Apr 18 02:17:52 2003
From: Richard.Rowe at jcu.edu.au (Richard Rowe)
Date: Fri, 18 Apr 2003 10:17:52 +1000
Subject: [R] Validation of R
In-Reply-To: <878yu8g7yr.fsf@jeeves.blindglobe.net>
References: <3A822319EB35174CA3714066D590DCD5C4F9EF@usrymx25.merck.com>
 <3A822319EB35174CA3714066D590DCD5C4F9EF@usrymx25.merck.com>
Message-ID: <5.0.0.25.1.20030418095434.03779070@pop.jcu.edu.au>

At 13:55 17/04/03 -0700, you wrote:

> >> From: Paul, David A [mailto:paulda at BATTELLE.ORG]
>
> >> For software, our internal standards basically say that
> >>
> >> (1) COTS (Com'l Off The Shelf software) developed by a
> >> company having both a long history of selling high-quality
> >> products and good QA doesn't need extensive from-scratch
> >> validation, only validation of simpler routines like the
> >> computation of means, variances, linear regression models,
> >> &etc.  (After all, how would anyone really validate what,
> >> say, PROC NLMIXED yields in a complex growth-curve application?)
>
>Too bad that can't be edited just a bit:
>
>(1) OTS (Off the Shelf software) developed by a group having both a
>long history of creating high-quality products and good QA which
>doesn't need extensive from-scratch validation, only validation of
>simpler routines like the computation of means, variances, linear
>regression models, etc.  (After all, how would anyone really validate
>what, say, nlme(), yields in a complex growth-curve application, other
>than one of the originators of one of the families of NLME
>algorithms?)


I think this active and fun thread just demonstrates the futility and 
essential speciousness of the QA and other 'audit culture' processes when 
it comes to science.

There are multiple sources of 'error' in analysis, and choosing an 
inappropriate method/model is by far the most likely, most misleading, and 
most pernicious ... and one entirely outside QA protocols.

Wrt COTS - MS is a large firm with a long history, and a substantial record 
for producing large (detractors would say 'bloated') and complex code that 
does all sorts of complex manipulations of binary strings.  I am sure the 
MS organisation will have comprehensive internal QA processes in 
place.  ... but would many of us use MS Excel(t)  to conduct even 'simple' 
statistical analyses?  And if not, why not?

Validation should require transparency of algorithm choice and 
implementation so all steps and assumptions of the mechanical process can 
be evaluated independently ...

Otherwise it is just a piece of paper,


Richard Rowe
Senior Lecturer
Department of Zoology and Tropical Ecology, James Cook University
Townsville, Queensland 4811, Australia
fax (61)7 47 25 1570
phone (61)7 47 81 4851
e-mail: Richard.Rowe at jcu.edu.au
http://www.jcu.edu.au/school/tbiol/zoology/homepage.html


From dmurdoch at pair.com  Fri Apr 18 03:29:05 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 17 Apr 2003 21:29:05 -0400
Subject: [R] R 1.7.0 Windows binary build released
Message-ID: <hrku9vgk9eet6g3nub6t9h4bdp0kdbei3i@4ax.com>

I've just finished uploading the Windows binary of R 1.7.0 to CRAN.
It should move to the public areas and the mirrors in a day or two.

It will appear in <http://cran.r-project.org/bin/windows/base> and the
corresponding directory on a mirror near you.

Duncan Murdoch


From ynoel at tele2.fr  Fri Apr 18 05:48:26 2003
From: ynoel at tele2.fr (Yvonnick Noel)
Date: Fri, 18 Apr 2003 05:48:26 +0200
Subject: [R] Help with TCL packages
References: <000901c304b2$f281f9c0$ae4860d4@YvonnickNol>
	<x2y9298m85.fsf@biostat.ku.dk>
Message-ID: <000701c3055d$5ff38c80$204860d4@YvonnickNol>

Thanks for your reply Peter.

> I haven't got BWidgets around, but it seems that it likes to use
> MacCapitalizationStyle, so shouldn't it be BWidget::ComboBox ?? 

I have tried many case variations, but none worked.

> In general, you might want to try things out in the "wish" interpreter
> since R interfaces to an embedded Tcl interpreter and you're seeing
> its error messages.

What TCL command would you suggest (I am no expert in TCL)?

I also tried to load IWidgets, but now, loading doesn't work !

> library(tcltk)
> addTclPath("C:/TCL/LIB/IWIDGETS4.0.2")
> tclRequire("IWidgets")
Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class = "tclObj") : 
        [tcl] can't find package IWidgets.

again when varying lower/upper case.

I would like to use one of these to write a simple TCLTK interface to R for my students.

Yvonnick Noel, PhD.
U. of Lille 3
FRANCE
----- Message d'origine ----- 
De : "Peter Dalgaard BSA" <p.dalgaard at biostat.ku.dk>
? : "Yvonnick Noel" <ynoel at tele2.fr>
Cc : <r-help at stat.math.ethz.ch>
Envoy? : jeudi 17 avril 2003 12:14
Objet : Re: [R] Help with TCL packages


> "Yvonnick Noel" <ynoel at tele2.fr> writes:
> 
> > Hello,
> > 
> > I am exploring the TCLTK package under R and try to load and use additional TCL libraries (under Windows, with TCL8.3). For example :
> > 
> > > addTclPath("C:/TCL/lib/bwidget1.5")
> > > tclRequire("BWidget")
> > <Tcl> 1.5
> > 
> > Loading seems to work, but when I try to create a specific widget :
> > 
> > # The main window appears correctly
> > > top=tktoplevel()
> > 
> > # Trying to insert a combobox
> > > combo <- tkwidget(top,"BWidget::combobox")
> > Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class = "tclObj") : 
> >         [tcl] invalid command name "BWidget::combobox".
> > 
> > The file combobox.tcl is present in the BWidget directory.
> > 
> > I wonder what I'm doing wrong. Any idea ?
> 
> I haven't got BWidgets around, but it seems that it likes to use
> MacCapitalizationStyle, so shouldn't it be BWidget::ComboBox ?? 
> 
> In general, you might want to try things out in the "wish" interpreter
> since R interfaces to an embedded Tcl interpreter and you're seeing
> its error messages.
> 
> -- 
>    O__  ---- Peter Dalgaard             Blegdamsvej 3  
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907
>


From jfox at mcmaster.ca  Fri Apr 18 06:04:04 2003
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 18 Apr 2003 00:04:04 -0400
Subject: [R] NA
In-Reply-To: <20030417154703.83599.qmail@web41101.mail.yahoo.com>
Message-ID: <5.1.0.14.2.20030417235505.01e2b7d0@mcmail.cis.mcmaster.ca>

Dear William,

At 05:47 PM 4/17/2003 +0200, william ritchie wrote:
>I know this has allready been asked but...
>HOW TO I GET RID OF NA's IN A LIST!!!!

As you say, this question was addressed just a couple of days ago. To 
elaborate on the previous solution, here's a recursive version, with an 
example (the first line of the function given is the non-recursive solution).

 > Lst <- list(a=NULL, b=1, c=list(d=NULL, e=2, f=list(g=3, h=list(i=NULL, 
k=4))))
 > rm.null <- function(L) {
+     L[sapply(L, is.null)] <- NULL
+     for (i in seq(along=L)) if (is.list(L[[i]])) L[[i]] <- Recall(L[[i]])
+     L
+     }
 > rm.null(Lst)
$b
[1] 1

$c
$c$e
[1] 2

$c$f
$c$f$g
[1] 3

$c$f$h
$c$f$h$k
[1] 4

Does that do what you want? Perhaps someone can think of a simpler 
recursive version.

John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox


From phgrosjean at sciviews.org  Fri Apr 18 08:21:53 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 18 Apr 2003 08:21:53 +0200
Subject: [R] Version 2 of benchmark test
Message-ID: <MABBLJDICACNFOLGIHJOIEBNDGAA.phgrosjean@sciviews.org>

Hi all,

I have update my benchmark test suite to version 2 that now uses R as the
reference software (http://www.sciviews.org/other/benchmark.htm). Results
concern R 1.7.0 under Windows XP, compared to S-PLUS, Matlab, Octave,
Scilab, O-Matrix and Ox. Testing data analysis software for speed is just
one part of the problem (a current thread is dealing, for instance, with QA
which is a different aspect). However, this benchmark could be informative,
keeping its limitations in mind.
Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.18, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................


From ken_lee at tynesys.com  Fri Apr 18 08:39:01 2003
From: ken_lee at tynesys.com (Ken Lee)
Date: Fri, 18 Apr 2003 14:39:01 +0800
Subject: [R] error msg for vector of size 
In-Reply-To: <20030417192226.47924.qmail@web12504.mail.yahoo.com>
Message-ID: <FFEKIEFDONDECJDODGDJMECICGAA.ken_lee@tynesys.com>

Dear all,
       Are there any problems at my BATCH program for the two error log, 
can I change the size of vector to avoid the error ?

error log 1:
Garbage collection 2881 = 2513+248+120 (level 2) ... 
1034265 cons cells free (35%)
14.1 Mbytes of heap free (33%)
Garbage collection 2940 = 2564+254+122 (level 2) ... 
1009265 cons cells free (34%)
15.4 Mbytes of heap free (35%)
Garbage collection 3006 = 2624+258+124 (level 2) ... 
984057 cons cells free (33%)
15.0 Mbytes of heap free (34%)
Garbage collection 3067 = 2678+263+126 (level 2) ... 
958953 cons cells free (32%)
14.6 Mbytes of heap free (33%)
Error: cannot allocate vector of size 2048 Kb
Execution halted

error log2:
Garbage collection 2895 = 2525+249+121 (level 2) ... 
1009160 cons cells free (34%)
15.2 Mbytes of heap free (34%)
Garbage collection 2962 = 2586+253+123 (level 2) ... 
983952 cons cells free (33%)
14.7 Mbytes of heap free (33%)
Garbage collection 3022 = 2638+259+125 (level 2) ... 
958848 cons cells free (32%)
16.1 Mbytes of heap free (35%)
Error: cannot allocate vector of size 448 Kb
Execution halted


From el at ac.lisse.na  Fri Apr 18 08:42:43 2003
From: el at ac.lisse.na (Dr Eberhard W. Lisse)
Date: Fri, 18 Apr 2003 07:42:43 +0100
Subject: [R] R-1.7.0 SUSE RPM anyone?
In-Reply-To: Your message of "Wed, 16 Apr 2003 21:36:16 EST."
             <20030417023616.GA30170@sonny.eddelbuettel.com> 
Message-ID: <20030418064243.4E7AE82471@ac.lisse.na>

Anyone working on RPMs for SUSE 8.1/2?

el
-- 
Dr. Eberhard W. Lisse  \   *    /        Managing Member, NA-NiC (cc) 
<el at lisse.NA> el108    /       | NA-NiC is the the .NA ccTLD Registry
Private Bag X5501       \     /           NA-NiC, Not Just Like That!
Oshakati, Namibia       ;____/     Telephone: +264 81 124 6733 (cell)
Please send DNS/NA-NiC related e-mail to dns-admin at na-nic.com.na only


From ramzi_feg at yahoo.fr  Fri Apr 18 09:53:55 2003
From: ramzi_feg at yahoo.fr (=?iso-8859-1?q?Ramzi=20Feghali?=)
Date: Fri, 18 Apr 2003 09:53:55 +0200 (CEST)
Subject: [R] Compiling with Microsoft Visual C++
Message-ID: <20030418075355.11199.qmail@web20302.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030418/3d827240/attachment.pl

From t_isog at hotmail.com  Fri Apr 18 10:57:15 2003
From: t_isog at hotmail.com (Isogai Takashi)
Date: Fri, 18 Apr 2003 08:57:15 +0000
Subject: [R] Question about PAM clustering method
Message-ID: <Sea1-F62Xa1y1gWrddI000067cf@hotmail.com>

Hello everyone.  I just started learning R for clustering analysis in my 
research project.  I tried k-means method and PAM method, both of which 
were properly processed with my data.  I have some questions about PAM 
graphical output.  

Suppose to do the commands shown below;
pm<-pam(D, 6)
plot(pm)

I got two charts after prompted.  In the first chart, 6 oval clusters are 
drawn together with data markers.  I see four 'pink' lines that connect 
oval clusters.  In this case, oval clusters are located very near, and some 
of them are overlapped.  The line starts from the edge of one oval, and it 
ends at the edge of another oval.  Does anyone know the meaning of this 
line?  I imagine that the line shows close linkage of the corresponding 
clusters, but no comments regarding this line can be found in the help 
documents.  

Second question is the meaning of the comment "these two components explain 
x% of the point variability" at the bottom oh the graph.  In my case, the 
data has 6 (groups) x 20 (properties) dimension.  I think that R extract 
the first and the second factors, and map them on the graph.  Therefore, 
the number is the total contribution of those two factors.  Am I correct?  
If so, how can I choose the factors other than the first or the second?  

Lastly, I read a document that says about the average silhouette, "even 
that highest width is below (say) 0.25, one may conclude that no 
substantial structure has been found".  Is this true?  In my case, the 
value is far below 0.25, possibly because some clusters overlap on the 
graph.  I can accept the overlapping clusters from the viewpoint of my 
research, but I wonder if the PAM method is also useful for these clusters. 
 

Thank you very much for your help in advance.  

T. Isog
Tokyo, Japan


_________________________________________________________________
?????????????  ?????? MSN ???   
http://house.msn.co.jp/


From J.Illian at abertay.ac.uk  Fri Apr 18 11:20:33 2003
From: J.Illian at abertay.ac.uk (J.Illian@abertay.ac.uk)
Date: Fri, 18 Apr 2003 10:20:33 +0100
Subject: [R] stepwise discriminant analysis
Message-ID: <F934BF2710426B44833B8677AF47F2467486D4@mail3.tay.ac.uk>

Hi all,
is it possible to do stepwise discriminant analysis (linear amnd non-linear)
in R?

If yes- which package does it|?

Thanks

Janine

--------------------------------------------
"El gesto y la palabra son el pensamiento del hombre"
Isabel Allende

Janine Illian
lecturer in statistics
SIMBIOS
School of Computing
University of Abertay Dundee
Bell Street
Dundee, DD1 1HG 
Scotland, UK
Tel: +44-(0)1382-308488
Fax: +44-(0)1382-308537


From partha_bagchi at hgsi.com  Fri Apr 18 14:01:15 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Fri, 18 Apr 2003 08:01:15 -0400
Subject: [R] Validation of R
Message-ID: <OFA57475B0.0FD57D8E-ON85256D0C.0041A131-85256D0C.00420218@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030418/c671d1a2/attachment.pl

From sandrine.mainard1 at etud.univ-ubs.fr  Fri Apr 18 16:04:45 2003
From: sandrine.mainard1 at etud.univ-ubs.fr (sandrine.mainard1@etud.univ-ubs.fr)
Date: Fri, 18 Apr 2003 16:04:45 +0200
Subject: [R] Problem with multtest
Message-ID: <1050674685.3ea005fd08c92@homae.univ-ubs.fr>

Hello,

I'm a novice in R. So i don't understand why in the package multtest, i 
found "possible results" with mt.teststat (for example : -1.227144e+00), but i 
i've found  : 1.000000e+00, for resT or maxT. i think it's very strange,no????

Thanks for your help

sandrine



--------------------------------------------------------------------------------
Universit de Bretagne sud                               http://www.univ-ubs.fr/


From hans.gardfjell at eg.umu.se  Fri Apr 18 17:55:33 2003
From: hans.gardfjell at eg.umu.se (Hans Gardfjell)
Date: Fri, 18 Apr 2003 11:55:33 -0400
Subject: [R] Problem with eigen() and LAPACK
Message-ID: <3EA01FF5.2040704@eg.umu.se>

Hi all,

when testing the new improvements in the new 1.7.0-version I stumbled 
over the following:

 >eigen(matrix(c(0,.3,2,.9),2,2))
Error in eigen(matrix(c(0,.3,2,.9),2,2)) :
         LAPACK routine DGEEV gave error code -13


 >eigen(matrix(c(0,.3,2,.9),2,2),EISPACK=TRUE)
$values
[1]  1.3458236 -0.4458236

$vectors
            [,1]       [,2]
[1,] -1.1436890 -0.9760443
[2,] -0.7696018  0.2175718


My R-version
[1] "R version 1.7.0, 2003-04-16", running on Debian PC.

Anyone who has a clue why LAPACK refuses to solve the eigenvalues?


Thanks,

Hans Gardfjell
EG, Ume? Universitet, Sweden


From saml at demog.berkeley.edu  Fri Apr 18 18:16:59 2003
From: saml at demog.berkeley.edu (SamL)
Date: Fri, 18 Apr 2003 09:16:59 -0700 (PDT)
Subject: [R] Help with nlme--freq weights, logit model, and more
Message-ID: <Pine.SUN.4.10.10304180858400.4965-100000@davis.demog.berkeley.edu>

Below you will find the output from a failed multi-level model run.  I am
trying to estimate the following model:

Pr(PLFP=1)= logistic regression -> 
 B1_j * bm + B2_j * wm + B3_j bf + B4_j wf + B5 yrsed+ B6 age+ B7 age^2+e_ij

 B1_j = G01 + G11 bmxd + d1
 B2_j = G02 + G12 wmxd + d2
 B3_j = G03 + G13 bfxd + d3
 B4_j = G04 + G14 wfxd + d4

d1-d4 freely correlated

Note that there is no intercept, so the B1-B4 are race/sex specific
intercepts (bm=black male, wm=white male, bf=black female, wf=white
female).

This model allows the xd variables to influence the means within the
geographic locations (50 states).

SO, my questions:

1)I cannot figure out what the error code means.  This is the first time I
have received that code, which I think is a good sign--I am getting closer
to the correct syntax.  But, still, no results.  I am not sure what to do
next.  Maybe it is in my coding for the logit model; I've not written that
into a program before and am not sure I am to write it for the
probability.

2)Even once that is solved, I still need to learn how to make the program
use frequency weights.  Each line of data represents different numbers of
people.  I collapsed a massive datafile this way.  One line might refer to
7324 people, while another refers to 261.  How do I make nlme use that
information to estimate the model appropriately?

3)How do I get nlme to read starting values from results of a logit model
estimated before the nlme run.  i haven't tried that but assume those
starting values will be far better than my "all zeros" starting values,
which I am using just to debug the code.  But,

4)I did not find a place I had to tell the program what the clustering was
on (states)?  Is this unnecessary?  And if it is necessary, how?

5)Well, that'll do for now I suppose.  Any assistance is greatly
appreciated.

Sam


R : Copyright 2002, The R Development Core Team
Version 1.5.1  (2002-06-17)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type `license()' or `licence()' for distribution details.

R is a collaborative project with many contributors.
Type `contributors()' for more information.

Type `demo()' for some demos, `help()' for on-line help, or
`help.start()' for a HTML browser interface to help.
Type `q()' to quit R.

[Previously saved workspace restored]

> invisible(options(echo = TRUE))
> library(nlme)
Loading required package: nls 
Loading required package: lattice 
> fm1<-nlme(model=plfp ~ (exp(-1+bm + bmxd +
+              wm + wmxd +
+              bf + bfxd +
+              wf + wfxd +
+              yrsed + age + age2)) / (1+exp(-1+bm + bmrd +
+              wm + wmxd +
+              bf + bfxd +
+              wf + wfxd +
+              yrsed + age + age2)),
+       fixed=list(bm ~ 1, bmxd ~ 1,
+                  wm ~ 1, wmxd ~ 1,
+                  bf ~ 1, bfxd ~ 1,
+                  wf ~ 1, wfxd ~ 1,
+              yrsed ~ 1, age ~ 1, age2 ~ 1,
+       data = PLFPANAL,
+       random=list(bm ~ 1, wm ~ 1, bf ~ 1, wf ~ 1),
+       start = c(bm = 0, bmxd = 0,
+              wm = 0, wmxd = 0,
+              bf = 0, bfxd = 0,
+              wf = 0, wfxd = 0,
+              yrsed = 0, age = 0, age2 = 0))
Error in parse(file, n, text, prompt) : parse error
Execution halted


* * * * * * * * * * * * * * * * * * * * * * * *
Samuel R. Lucas
Associate Professor of Sociology
University of California-Berkeley
410 Barrows Hall #1980
Berkeley, California 94720-1980
e-mail: Lucas at demog.berkeley.edu
home-page: http://sociology.berkeley.edu/faculty/lucas/
* * * * * * * * * * * * * * * * * * * * * * * *


From otoomet at econ.dk  Fri Apr 18 17:31:14 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Fri, 18 Apr 2003 17:31:14 +0200
Subject: [R] error msg for vector of size
In-Reply-To: <FFEKIEFDONDECJDODGDJMECICGAA.ken_lee@tynesys.com>
References: <FFEKIEFDONDECJDODGDJMECICGAA.ken_lee@tynesys.com>
Message-ID: <200304181531.h3IFVEg11820@punik.econ.au.dk>

Hello,

It looks like your memory has become fragmented (there are several MB
free but not a single 2 MB chunk. 

If this is the case, you may consider:

1) save your data, exit R, start it again and continue.  It should
   free all the memory, occupied by R, and hopefully allocate it
   better next time.

2) Use unix/linux.  There are rumours that unix has better memory
   management than windows (your mail was sent from windows).  

3) Dont start other programs while R is running.  Keep the number of
   running programs/precesses to minimum.  They may be part of the
   reason of memory fragmentation.

4) Try with subsets of your data, split your data into separate
   indipendent subsets (if you can) etc...

Perhaps it helps.

Ott

 | From: "Ken Lee" <ken_lee at tynesys.com>
 | Date: Fri, 18 Apr 2003 14:39:01 +0800
 | 
 | Dear all,
 |        Are there any problems at my BATCH program for the two error log, 
 | can I change the size of vector to avoid the error ?
 | 
 | error log 1:
 | Garbage collection 2881 = 2513+248+120 (level 2) ... 
 | 1034265 cons cells free (35%)
 | 14.1 Mbytes of heap free (33%)
 | Garbage collection 2940 = 2564+254+122 (level 2) ... 
 | 1009265 cons cells free (34%)
 | 15.4 Mbytes of heap free (35%)
 | Garbage collection 3006 = 2624+258+124 (level 2) ... 
 | 984057 cons cells free (33%)
 | 15.0 Mbytes of heap free (34%)
 | Garbage collection 3067 = 2678+263+126 (level 2) ... 
 | 958953 cons cells free (32%)
 | 14.6 Mbytes of heap free (33%)
 | Error: cannot allocate vector of size 2048 Kb
 | Execution halted


From edd at debian.org  Fri Apr 18 18:51:15 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 18 Apr 2003 11:51:15 -0500
Subject: [R] Problem with eigen() and LAPACK
In-Reply-To: <3EA01FF5.2040704@eg.umu.se>
References: <3EA01FF5.2040704@eg.umu.se>
Message-ID: <20030418165115.GA22044@sonny.eddelbuettel.com>


Hi Hans,

On Fri, Apr 18, 2003 at 11:55:33AM -0400, Hans Gardfjell wrote:
> Hi all,
> 
> when testing the new improvements in the new 1.7.0-version I stumbled 
> over the following:
> 
> >eigen(matrix(c(0,.3,2,.9),2,2))
> Error in eigen(matrix(c(0,.3,2,.9),2,2)) :
>         LAPACK routine DGEEV gave error code -13
> 
> 
> >eigen(matrix(c(0,.3,2,.9),2,2),EISPACK=TRUE)
> $values
> [1]  1.3458236 -0.4458236
> 
> $vectors
>            [,1]       [,2]
> [1,] -1.1436890 -0.9760443
> [2,] -0.7696018  0.2175718
> 
> 
> My R-version
> [1] "R version 1.7.0, 2003-04-16", running on Debian PC.

Am I correct in assumimg that you are using Debian 3.0 aka "stable",
along with the R 1.7.0 package from CRAN?

The example above works fine for me on Debian "testing". R on testing was
built using the (almost) identical configuration at compile-time (gcc 3.0
and tcl/tk 8.3 on stable; 3.2 and 8.4 on testing) and the difference should
therefore be attributable to the libraries and compilers used, which are,
generally speaking, up to a year more recent on testing.
 
> Anyone who has a clue why LAPACK refuses to solve the eigenvalues?

I suspect an problem with the LAPACK libs on the stable release. Matthias
Burger reported a similar problem. We may just have to configure R to not
use Lapack on that older platform unless we find a way to tame this.

Dirk

-- 
Don't drink and derive. Alcohol and algebra don't mix.


From fharrell at virginia.edu  Fri Apr 18 18:56:56 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 18 Apr 2003 12:56:56 -0400
Subject: [R] Validation of R
In-Reply-To: <940250A9EB37A24CBE28D858EF077749136CC1@ws-bco-mse3.milky-way.battelle.org>
References: <940250A9EB37A24CBE28D858EF077749136CC1@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <20030418125656.2483087b.fharrell@virginia.edu>

On Fri, 18 Apr 2003 09:50:19 -0400
"Paul, David  A" <paulda at battelle.org> wrote:

. . . 
> Now, what would REALLY be nice is if some generous organization
> would pay a bunch of programmers to spend 2 - 3 years validating
> the algorithms in R, taking the FDA's CFR guidelines into account...
> That would truly be a service to everyone.
> 
> 
> Sincerely,
> 
>   David Paul

In re-reviewing FDA guidelines there are no guidelines (either usage or validation guidelines) for statistical analysis software, only guidelines for database management software and software used in medical devices.  And the only place where SAS is mentioned is related to data archiving using SAS Version 5 transport files.  That (very problematic) format is currently preferred by FDA but experts expect that will be replaced with XML in the not-too-distant future.  
What is truly important is that data analysts check their work no matter what they are doing.

By the way, I know of an important study in which incorrect final efficacy event rates were reported to FDA and in the scientific literature, due to (what I consider) a bug that has been in SAS for 30 years: a missing value is considered to be less than any valid numeric value, so "IF x < y THEN z=1" generates z=1 when x is missing and y is not.
---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From saml at demog.berkeley.edu  Fri Apr 18 19:00:26 2003
From: saml at demog.berkeley.edu (SamL)
Date: Fri, 18 Apr 2003 10:00:26 -0700 (PDT)
Subject: [R] Help with nlme correction
Message-ID: <Pine.SUN.4.10.10304180957330.15796-100000@davis.demog.berkeley.edu>

Thanks for the help people have sent.  The fixed subcommand was correct,
the missing parenthesis IS actually in the code and the output.  Just in
cutting and pasting the output I apparently skipped over that parenthesis.
Sorry for the mix-up.

The correct code (w/ the parenthesis) produced the error.  Any ideas?

Sam


From bates at stat.wisc.edu  Fri Apr 18 19:05:35 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 18 Apr 2003 12:05:35 -0500
Subject: [R] Problem with eigen() and LAPACK
In-Reply-To: <20030418165115.GA22044@sonny.eddelbuettel.com>
References: <3EA01FF5.2040704@eg.umu.se>
	<20030418165115.GA22044@sonny.eddelbuettel.com>
Message-ID: <6rvfxbenxc.fsf@bates4.stat.wisc.edu>

Dirk Eddelbuettel <edd at debian.org> writes:

> Hi Hans,
> 
> On Fri, Apr 18, 2003 at 11:55:33AM -0400, Hans Gardfjell wrote:
> > Hi all,
> > 
> > when testing the new improvements in the new 1.7.0-version I stumbled 
> > over the following:
> > 
> > >eigen(matrix(c(0,.3,2,.9),2,2))
> > Error in eigen(matrix(c(0,.3,2,.9),2,2)) :
> >         LAPACK routine DGEEV gave error code -13
> > 
> > 
> > >eigen(matrix(c(0,.3,2,.9),2,2),EISPACK=TRUE)
> > $values
> > [1]  1.3458236 -0.4458236
> > 
> > $vectors
> >            [,1]       [,2]
> > [1,] -1.1436890 -0.9760443
> > [2,] -0.7696018  0.2175718
> > 
> > 
> > My R-version
> > [1] "R version 1.7.0, 2003-04-16", running on Debian PC.
> 
> Am I correct in assumimg that you are using Debian 3.0 aka "stable",
> along with the R 1.7.0 package from CRAN?
> 
> The example above works fine for me on Debian "testing". R on testing was
> built using the (almost) identical configuration at compile-time (gcc 3.0
> and tcl/tk 8.3 on stable; 3.2 and 8.4 on testing) and the difference should
> therefore be attributable to the libraries and compilers used, which are,
> generally speaking, up to a year more recent on testing.
>  
> > Anyone who has a clue why LAPACK refuses to solve the eigenvalues?
> 
> I suspect an problem with the LAPACK libs on the stable release. Matthias
> Burger reported a similar problem. We may just have to configure R to not
> use Lapack on that older platform unless we find a way to tame this.

On a Debian stable machine (the one where the packages for Debian
stable were built) I don't get a problem

> eigen(matrix(c(0,.3,2,.9),2,2))
$values
[1]  1.3458236 -0.4458236

$vectors
           [,1]       [,2]
[1,] -0.8296512 -0.9760443
[2,] -0.5582821  0.2175718


From Phguardiol at aol.com  Fri Apr 18 19:18:52 2003
From: Phguardiol at aol.com (Phguardiol@aol.com)
Date: Fri, 18 Apr 2003 13:18:52 EDT
Subject: [R] memory problem
Message-ID: <1ad.12edeb35.2bd18d7c@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030418/5d0a8ba8/attachment.pl

From partha_bagchi at hgsi.com  Fri Apr 18 19:13:20 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Fri, 18 Apr 2003 13:13:20 -0400
Subject: [R] Validation of R
Message-ID: <OFB665334A.00826CED-ON85256D0C.005E74AF-85256D0C.005E9443@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030418/d0df1990/attachment.pl

From Benjamin.STABLER at odot.state.or.us  Fri Apr 18 20:04:48 2003
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Fri, 18 Apr 2003 11:04:48 -0700
Subject: [R] system() and R 1.7
Message-ID: <76A000A82289D411952F001083F9DD06039ACB63@exsalem4-bu.odot.state.or.us>

I am using the system(command, input=a character vector) command on a
Windows NT machine and I now get the following warning with R 1.7:

Warning message: 
the condition has length > 1 and only the first element will be used in: if
(input != "") { 

I think I am getting this warning because, according to Peter Dalgaard, R
1.7 now gives a warning if if() and while() are called with a vector
condition.  Is there anyway to fix this issue besides options(warn=-1)?
Thanks.

> system
function (command, intern = FALSE, wait = TRUE, input = "",
show.output.on.console = FALSE, 
    minimized = FALSE, invisible = FALSE) 
{
    f <- ""
    if (input != "") {
        f <- tempfile()
        on.exit(unlink(f))
        cat(input, file = f, sep = "\n")
    }
    if (intern) 
        flag <- 3
    else {
        if (wait) 
            flag <- ifelse(show.output.on.console, 2, 1)
        else flag <- 0
    }
    if (invisible) 
        flag <- 20 + flag
    else if (minimized) 
        flag <- 10 + flag
    .Internal(system(command, as.integer(flag), f))
}
<environment: namespace:base>

Benjamin Stabler
Transportation Planning Analysis Unit
Oregon Department of Transportation
555 13th Street NE, Suite 2
Salem, OR 97301  Ph: 503-986-4104


From hans.gardfjell at eg.umu.se  Fri Apr 18 20:45:23 2003
From: hans.gardfjell at eg.umu.se (Hans Gardfjell)
Date: Fri, 18 Apr 2003 14:45:23 -0400
Subject: [R] Problem with eigen() and LAPACK
In-Reply-To: <20030418165115.GA22044@sonny.eddelbuettel.com>
References: <3EA01FF5.2040704@eg.umu.se>
	<20030418165115.GA22044@sonny.eddelbuettel.com>
Message-ID: <3EA047C3.6060805@eg.umu.se>

Dirk Eddelbuettel wrote:

>Hi Hans,
>
>On Fri, Apr 18, 2003 at 11:55:33AM -0400, Hans Gardfjell wrote:
>  
>
>>Hi all,
>>
>>when testing the new improvements in the new 1.7.0-version I stumbled 
>>over the following:
>>
>>    
>>
>>>eigen(matrix(c(0,.3,2,.9),2,2))
>>>      
>>>
>>Error in eigen(matrix(c(0,.3,2,.9),2,2)) :
>>        LAPACK routine DGEEV gave error code -13
>>
>>
>>    
>>
>>>eigen(matrix(c(0,.3,2,.9),2,2),EISPACK=TRUE)
>>>      
>>>
>>$values
>>[1]  1.3458236 -0.4458236
>>
>>$vectors
>>           [,1]       [,2]
>>[1,] -1.1436890 -0.9760443
>>[2,] -0.7696018  0.2175718
>>
>>
>>My R-version
>>[1] "R version 1.7.0, 2003-04-16", running on Debian PC.
>>    
>>
>
>Am I correct in assumimg that you are using Debian 3.0 aka "stable",
>along with the R 1.7.0 package from CRAN?
>  
>
No, I'm also running a "testing" Debian configuration. I first tried R 
from the CRAN testing depository, and then today installed the latest 
version from the unstable tree. So, just now I'm running the Debian 
precompiled R version 1.7.0-1 from the unstable branch at debian.org. I 
got the same result with both versions.

However, when checking the dependencies I removed my atlas2-p3 package. 
And then it worked. I then realised that atlas2-p3 is replaced by 
atlas2-sse. So with an upgrade of atlas2 everything works fine.

/hans

>The example above works fine for me on Debian "testing". R on testing was
>built using the (almost) identical configuration at compile-time (gcc 3.0
>and tcl/tk 8.3 on stable; 3.2 and 8.4 on testing) and the difference should
>therefore be attributable to the libraries and compilers used, which are,
>generally speaking, up to a year more recent on testing.
> 
>  
>
>>Anyone who has a clue why LAPACK refuses to solve the eigenvalues?
>>    
>>
>
>I suspect an problem with the LAPACK libs on the stable release. Matthias
>Burger reported a similar problem. We may just have to configure R to not
>use Lapack on that older platform unless we find a way to tame this.
>
>Dirk
>
>  
>


From Jim_Garrett at bd.com  Fri Apr 18 20:58:55 2003
From: Jim_Garrett at bd.com (Jim_Garrett@bd.com)
Date: Fri, 18 Apr 2003 14:58:55 -0400
Subject: [R] Re: Validation of R
Message-ID: <OFEA39FB05.FE747744-ON85256D0C.0058B914@bd.com>


Like the original poster, I'm in a corporation that interacts with the FDA
(submissions for product approval, and potential for auditing of QC
procedures).  I fully expect to be asked to validate R, in some sense,
within the year, maybe two.  I have two main comments.

First, I would be interested in participating in a small sub-project
interested in exploring this in very practical ways, such as
1.   Documenting resistance or regulatory needs R users are encountering in
this environment, offline from the r-help list,
2.   Sharing experiences (what works and what doesn't for assuaging
managers' fears), and
3.   If any further validation activities are deemed helpful (such as
additional test cases and describing what the test cases are intended to
test), making sure that these activities are fed back to the R project in a
way that others can leverage them in the future.

If you would also like to participate in this off-line discussion, I will
be happy to collect names and e-mails.  Or, if anyone has other ideas or
feels motivated to drive something, feel free to step forward.

Second, just minutes ago I raised this question with our software testor
over lunch.  She tests SAS code used to generate reports of clinical trial
results, and other software used to get clinical data into a database.  In
retrospect she is a biased sample (of size 1!) because the open-source
software model de-emphasizes the role (and value) of the professional
software testor; nonetheless I thought her comments offer a taste of the
opposition some may encounter.  I'll tell you what she said, and then I'll
offer my impressions; please don't argue with her points, because I already
did!

(A bit of background:  we have chosen not to validate SAS procedures, and
we say so in our test documentation.  In practice, I think our clinical
reporting rarely strays far from base SAS--99% of our reporting is just
manipulating and tabulating data--and that may be a reason for the
decision.)

In a nutshell, she thought SAS was more trustworthy than R (to the extent
that she thought we should test R's functions) based on two points:
1.   SAS has a team of professional software testors who spend their time
coming up with test cases that are as esoteric and odd as they can think of
(within the limits of their specifications).  She was not convinced that a
large community of users is sufficient to flush out obscure bugs.  In her
view (not surprisingly), software testors will look at software with a
unique eye.  (Which I think is true--but an army of users also does pretty
well.)
2.   SAS has a long history of quality, and their market niche requires
them to pay close attention to quality.  This distinguishes them from
Microsoft, which has little financial incentive to pay close attention to
quality, and does not have a history of quality despite a large group of
professional software testors.

She and I agreed that if one must know for certain that a particular
function works, one must test it or find documentation indicating precisely
how someone else tested it.  Fortunately R packages come with test cases,
but they're not usually test cases designed to check a large number of
possible failure mechanisms.

My take on this is as follows:
1.   There seem to be two varieties of validation involved here.  The first
provides clear assurance that a specific application does a specific thing.
This is what software validation should really be, and no software, not
even SAS, is above this.  Then there is "warm and fuzzy" validation that
offers limited assurance that the software is generally of good quality.
This is subjective, a matter of reputation, and there is no testing or
documentation that can definitively address this ill-defined criterion.  A
software package could be excellent, with only one bug, but if your
application hits that bug, you have a problem.
2.   I think this thread is mainly addressing the "warm and fuzzy"
validation model.  R is going to encounter skepticism among people who
haven't been exposed to it before, especially if they also have not been
exposed to other open-source software (OSS).  In my experience, people who
have not been involved in any software development expect corporate support
to lead to quality software ("they have resources!").  We all know this is
a fallacy, but you can't argue it away, you just have to demonstrate the
software.  When they become familiar with it, they'll stop asking for the
warm and fuzzy validation.

If my reading of the situation is correct, then the right response is to
dazzle.  The warm-and-fuzzy validation is really an opportunity for a
software demo.  Demonstrate the functions you're likely to use, especially
(following Dr. Harrell's advice) using simulation.  Then repeat the
simulation but with outliers added, and use robust methods.  Read in a CSV
file from a network drive, create some beautiful plots, save the data in
compressed format and document file size (also document the original CSV's
file size), read the data back into a concurrently-running R process and
show it's the same.  Install a particularly impressive and esoteric package
that's remotely related to your problem and document what it does.
Generate pseudorandom data using three different generators, from a given
seed, and then reproduce the data.  Calculate P(Z <= -20) for Z ~ N(0, 1),
then calculate P(Z > 20) using lower.tail = F.

You will provide only an iota of assurance that a particular future
application will work, but you will have removed all doubt that R is a
serious, rigorous, powerful package.  And that addresses the concerns that
may not be voiced, but are underlying.

-Jim Garrett
Becton Dickinson Diagnostic Systems


**********************************************************************
This message is intended only for the designated recipient(s).  ... {{dropped}}


From sung-youn.kim at stonybrook.edu  Fri Apr 18 21:02:50 2003
From: sung-youn.kim at stonybrook.edu (sung-youn.kim@stonybrook.edu)
Date: Fri, 18 Apr 2003 15:02:50 -0400 (EDT)
Subject: [R] MCMCpack gelman.plot and gelman.diag
Message-ID: <200304181902.h3IJ2oP4002326@smtp.ic.sunysb.edu>

Hi, 

A question. When I run gelman.diag and gelman.plot
with mcmc lists obtained from MCMCregress, the results are following.  

> post.R <- MCMCregress(Size~Age+Status, data = data, burnin = 5000, mcmc = 100000,
+         thin = 10, verbose = FALSE, beta.start = NA, sigma2.start = NA,
+         b0 = 0, B0 = 0, nu = 0.001, delta = 0.001) 
> post1.R <- MCMCregress(Size~Age+Status, data = data, burnin = 5000, mcmc = 100000,
+         thin = 10, verbose = FALSE, beta.start = -3, sigma2.start = NA,
+         b0 = 0, B0 = 0, nu = 0.001, delta = 0.001) 
> post2.R <- MCMCregress(Size~Age+Status, data = data, burnin = 5000, mcmc = 100000,
+         thin = 10, verbose = FALSE, beta.start = 3, sigma2.start = NA,
+         b0 = 0, B0 = 0, nu = 0.001, delta = 0.001) 
> post.R.all <- mcmc.list(post.R, post1.R, post2.R)
> gelman.diag(post.R.all, confidence = 0.95, transform=FALSE)
Potential scale reduction factors:

     Point est. 97.5% quantile
[1,]        NaN            NaN
[2,]        NaN            NaN
[3,]        NaN            NaN
[4,]        NaN            NaN

Multivariate psrf

1
> gelman.plot(post.R.all, bin.width = 20, max.bins = 100, confidence = 0.95, transform = FALSE, auto.layout = TRUE, ask = FALSE)

******* Error: *******
Cannot compute Gelman & Rubin's diagnostic for any chain 
segments for variables (Intercept) Age Status sigma2 
This indicates convergence failure
 

Should I have run them with more chains? Any hint?

thanks in advance,

-- 
Sung-youn Kim
--------------
Dept. of Political Science
Stony Brook University (SUNY at Stony Brook)
Office: (631)-632-7664
Web: http://www.ic.sunysb.edu/www/stu/sungyoki


From DJNordlund at aol.com  Fri Apr 18 21:34:01 2003
From: DJNordlund at aol.com (DJNordlund@aol.com)
Date: Fri, 18 Apr 2003 15:34:01 EDT
Subject: [R] Keyboard problem using RWin 1.7.0
Message-ID: <55.3dea5b34.2bd1ad29@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030418/aec9dcad/attachment.pl

From dmurdoch at pair.com  Fri Apr 18 21:47:46 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Fri, 18 Apr 2003 15:47:46 -0400
Subject: [R] Re: Quick question on upgrading R
In-Reply-To: <CA612484A337C6479EA341DF9EEE14ACAC664E@hercules.SSAINFO>
References: <CA612484A337C6479EA341DF9EEE14ACAC664E@hercules.SSAINFO>
Message-ID: <q6l0av4siv3lupq05k8c5n5chb22l8lve1@4ax.com>

On Fri, 18 Apr 2003 11:29:45 -0500, you wrote:

>If one has an earlier version of R installed (1.5.0 in my case) and one wants to upgrade to 1.7.0 leaving in place workspaces, work in progress, etc. is there any special procedure required, or should one simply procede as if for a new installation?

>From the rw-FAQ (which I don't seem to have a link to from the binary
page; I'll fix that):

2.6 What's the best way to upgrade?
===================================

That's a matter of taste.  For most people the best thing to do is to
uninstall R (see the previous Q), install the new version, copy any
installed packages to the library folder in the new installation, run
`update.packages()' in the new R (`Update packages from CRAN' from the
Packages menu, if you prefer) and then delete anything left of the old
installation.  Different versions of R are quite deliberately
installed
in parallel folders so you can keep old versions around if you wish.

Duncan Murdoch


From quinn at stat.washington.edu  Fri Apr 18 22:30:17 2003
From: quinn at stat.washington.edu (Kevin Quinn)
Date: Fri, 18 Apr 2003 13:30:17 -0700 (PDT)
Subject: [R] MCMCpack gelman.plot and gelman.diag
In-Reply-To: <200304181902.h3IJ2oP4002326@smtp.ic.sunysb.edu>
Message-ID: <Pine.OSF.4.44.0304181323280.402098-100000@lisbon1.stat.washington.edu>

2 problems here--

1) you need to use different seeds in the three runs. you can do this by
specifying the seed argument in MCMCregress().

2) if you look at the C++ code the first full-conditional that is sampled
from is [\beta|\sigma^2, y]. Since you are using the same starting values
for \sigma^2 in all three runs (and the same seed) you are getting exactly
the same stream of draws in each run.

if you specify seed and sigma2.start differently for each run you should
be able to use the Gelman diagnostics.

KQ

On Fri, 18 Apr 2003 sung-youn.kim at stonybrook.edu wrote:

> Hi,
>
> A question. When I run gelman.diag and gelman.plot
> with mcmc lists obtained from MCMCregress, the results are following.
>
> > post.R <- MCMCregress(Size~Age+Status, data = data, burnin = 5000, mcmc = 100000,
> +         thin = 10, verbose = FALSE, beta.start = NA, sigma2.start = NA,
> +         b0 = 0, B0 = 0, nu = 0.001, delta = 0.001)
> > post1.R <- MCMCregress(Size~Age+Status, data = data, burnin = 5000, mcmc = 100000,
> +         thin = 10, verbose = FALSE, beta.start = -3, sigma2.start = NA,
> +         b0 = 0, B0 = 0, nu = 0.001, delta = 0.001)
> > post2.R <- MCMCregress(Size~Age+Status, data = data, burnin = 5000, mcmc = 100000,
> +         thin = 10, verbose = FALSE, beta.start = 3, sigma2.start = NA,
> +         b0 = 0, B0 = 0, nu = 0.001, delta = 0.001)
> > post.R.all <- mcmc.list(post.R, post1.R, post2.R)
> > gelman.diag(post.R.all, confidence = 0.95, transform=FALSE)
> Potential scale reduction factors:
>
>      Point est. 97.5% quantile
> [1,]        NaN            NaN
> [2,]        NaN            NaN
> [3,]        NaN            NaN
> [4,]        NaN            NaN
>
> Multivariate psrf
>
> 1
> > gelman.plot(post.R.all, bin.width = 20, max.bins = 100, confidence = 0.95, transform = FALSE, auto.layout = TRUE, ask = FALSE)
>
> ******* Error: *******
> Cannot compute Gelman & Rubin's diagnostic for any chain
> segments for variables (Intercept) Age Status sigma2
> This indicates convergence failure
>
>
> Should I have run them with more chains? Any hint?
>
> thanks in advance,
>
> --
> Sung-youn Kim
> --------------
> Dept. of Political Science
> Stony Brook University (SUNY at Stony Brook)
> Office: (631)-632-7664
> Web: http://www.ic.sunysb.edu/www/stu/sungyoki
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


--------------------------------------------------------
Kevin Quinn
Assistant Professor
Department of Political Science and
Center for Statistics and the Social Sciences
Box 354320
Padelford Hall
University of Washington
Seattle, WA  98195-4320

Office: (206) 221-6981
Fax:    (206) 221-6873
Email:  quinn at stat.washington.edu


From p.dalgaard at biostat.ku.dk  Fri Apr 18 23:53:13 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 18 Apr 2003 23:53:13 +0200
Subject: [R] Help with nlme--freq weights, logit model, and more
In-Reply-To: <Pine.SUN.4.10.10304180858400.4965-100000@davis.demog.berkeley.edu>
References: <Pine.SUN.4.10.10304180858400.4965-100000@davis.demog.berkeley.edu>
Message-ID: <x24r4v4gmu.fsf@biostat.ku.dk>

SamL <saml at demog.berkeley.edu> writes:

> > fm1<-nlme(model=plfp ~ (exp(-1+bm + bmxd +
> +              wm + wmxd +
> +              bf + bfxd +
> +              wf + wfxd +
> +              yrsed + age + age2)) / (1+exp(-1+bm + bmrd +
> +              wm + wmxd +
> +              bf + bfxd +
> +              wf + wfxd +
> +              yrsed + age + age2)),
> +       fixed=list(bm ~ 1, bmxd ~ 1,
> +                  wm ~ 1, wmxd ~ 1,
> +                  bf ~ 1, bfxd ~ 1,
> +                  wf ~ 1, wfxd ~ 1,
> +              yrsed ~ 1, age ~ 1, age2 ~ 1,
> +       data = PLFPANAL,
> +       random=list(bm ~ 1, wm ~ 1, bf ~ 1, wf ~ 1),
> +       start = c(bm = 0, bmxd = 0,
> +              wm = 0, wmxd = 0,
> +              bf = 0, bfxd = 0,
> +              wf = 0, wfxd = 0,
> +              yrsed = 0, age = 0, age2 = 0))
> Error in parse(file, n, text, prompt) : parse error

Insert parenthesis at end of "fixed" list...
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From TyagiAnupam at aol.com  Fri Apr 18 23:55:50 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Fri, 18 Apr 2003 17:55:50 EDT
Subject: [R] Validation of R
Message-ID: <194.17d8b5a0.2bd1ce66@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030418/3225adfa/attachment.pl

From rossini at blindglobe.net  Sat Apr 19 00:24:29 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Fri, 18 Apr 2003 15:24:29 -0700
Subject: [R] Validation of R
In-Reply-To: <194.17d8b5a0.2bd1ce66@aol.com> (TyagiAnupam@aol.com's message
 of "Fri, 18 Apr 2003 17:55:50 EDT")
References: <194.17d8b5a0.2bd1ce66@aol.com>
Message-ID: <87ptnjsaua.fsf@jeeves.blindglobe.net>

TyagiAnupam at aol.com writes:

> This has been a fruitful discussion about doing "scientific" research.? To 
> the software issues one can add the general issue of
> reproducability: 

Reproducible research has been a key interest of many of R's core
developers and related folk.  Other references include:

Vince Carey's work, circa 1993, on literate codebooks for documenting
datasets. 

Jan deLeeuw's paper (originally 1996, added as UCLA tech report in
2001), http://preprints.stat.ucla.edu/301/

my work on ESS and Noweb (literate statistical practice), as described
in my DSC-2001 conference paper, as well as University of Washington
Biostat TechRep #163 http://www.bepress.com/uwbiostat/paper194/ and
related Chance article with Fritz Leisch (to appear in next issue).

Robert Gentleman and Duncan Temple Lang's work (not sure if there is a
paper, but there is software which worked for me once). 

There are many others...

best,
-tony

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center 
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 
CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}


From bates at stat.wisc.edu  Sat Apr 19 00:27:49 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 18 Apr 2003 17:27:49 -0500
Subject: [R] Re: Validation of R
In-Reply-To: <OFEA39FB05.FE747744-ON85256D0C.0058B914@bd.com>
References: <OFEA39FB05.FE747744-ON85256D0C.0058B914@bd.com>
Message-ID: <6rd6jj7862.fsf@bates4.stat.wisc.edu>

Jim_Garrett at bd.com writes, quoting a software tester at BD.com:

> 1.   SAS has a team of professional software testors who spend their time
> coming up with test cases that are as esoteric and odd as they can think of
> (within the limits of their specifications).  She was not convinced that a
> large community of users is sufficient to flush out obscure bugs.  In her
> view (not surprisingly), software testors will look at software with a
> unique eye.  (Which I think is true--but an army of users also does pretty
> well.)

Does she know how many such software testers are actively involved in
testing the accuracy/reliability of statistical procedures in SAS or
is she just assuming that there will be a large number.

People often assume that a commercial software company has legions of
programmers working on program development and testing and frequently
this is not the case.  In a typical software company there are many
more employees working on marketing, customer support, etc. than on
development and testing.

I remember when a person told me that they expected that MathSoft (now
Insightful) would have 'at least a dozen' people working on the
development of lme and nlme.  I knew that the actual number was 0
because Jos? Pinheiro and I wrote and contributed that code and
neither of us work for Insightful.

I'm sure that most informal guesses of the number of professional
software testers working on accuracy/reliability of statistical
procedures in SAS will be overestimates.

I'm surprised that in this discussion of validation no one has quoted
ideas from "The Cathedral and the Bazaar" by Eric Raymond
(http://www.catb.org/~esr/writings/).  He has some very perceptive
observations in that essay including the observation that bug
detection and fixing is one of the few aspects of software development
that can be parallelized (provided, of course, that those detecting
the bugs have access to the sources).  A succinct expression is that
"Given enough eyeballs, all bugs are shallow".

In that sense I think it could be said that there are a lot more
software testers working on R than on any other statistical software
system.

Another important consideration in assessing the reliability of open
source software is that the people who develop this software do so
because they are interested in it, not because it is "just a job".
This makes it much more likely that the person developing open source
software will work on getting it "right" and not just getting it ready
to ship out the door.  A person once asked me why the functions for
probability densities, cumulative distribution functions, and
quantiles in R were demonstrably better than those in commercial
software packages.  I said that it was because we had an unfair
advantage - they just have a bunch of programmers working on their
code and we have Martin (Maechler).  To the other programmers getting
good answers is a job requirement; to Martin getting the best possible
answer is a passion.


From abunn at montana.edu  Sat Apr 19 00:28:41 2003
From: abunn at montana.edu (Andy Bunn)
Date: 18 Apr 2003 16:28:41 -0600
Subject: [R] Help with nlme--freq weights, logit model, and more
In-Reply-To: <x24r4v4gmu.fsf@biostat.ku.dk>
References: 
	 <Pine.SUN.4.10.10304180858400.4965-100000@davis.demog.berkeley.edu>
	 <x24r4v4gmu.fsf@biostat.ku.dk>
Message-ID: <1050704921.25098.21.camel@facet.msu.montana.edu>

Hi, I'm making the painful but liberating step to full-time linux user.
The switch has been mostly OK. All the stuff I learned when I first sat
down at a unix box is slowly coming back. But I digress.

Today I went to CRAN to get the RH 9 RPM:

http://cran.us.r-project.org/bin/linux/redhat/9/i386/

And, alas I found none and got the RH 8 build instead.

Here's what happens when I try the RPM:

[root at facet r.stuff]# rpm -i R-1.7.0-1.i386.rpm
warning: R-1.7.0-1.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
error: Failed dependencies:
        libtcl.so.0 is needed by R-1.7.0-1
        libtk.so.0 is needed by R-1.7.0-1

But a newer version of tcl (and tk) was installed with the RH 9
installation. 

[root at facet misc.rpms]# rpm -qa | grep -i tcl
tcl-8.3.5-88

So, in a short and ill-advised moment of lunacy I forced it:

[root at facet r.stuff]# rpm -i --nodeps *.rpm


That went as poorly as one might expect.
 
I suppose that I could roll back the tcl version but that seems
counterproductive. Is there a way to force the rpm? Can somebody smarter
than me make a good RPM for RH 9?

I'm loathe to install from source.

Thanks and I hope this is isn't an embarrassing question.

-Andy


From TyagiAnupam at aol.com  Sat Apr 19 00:41:51 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Fri, 18 Apr 2003 18:41:51 EDT
Subject: [R] Validation of R
Message-ID: <33.376565e1.2bd1d92f@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030418/7a24a152/attachment.pl

From abunn at montana.edu  Sat Apr 19 00:43:30 2003
From: abunn at montana.edu (Andy Bunn)
Date: Fri, 18 Apr 2003 16:43:30 -0600
Subject: [R] Sorry - Red Hat 9.0 RPM problem
In-Reply-To: <1050704921.25098.21.camel@facet.msu.montana.edu>
Message-ID: <NEBBIPHDAMMOKDKPOFFIMEKGCHAA.abunn@montana.edu>

Excuse the wrong subject header.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Andy Bunn
Sent: Friday, April 18, 2003 4:29 PM
To: R Listserv
Subject: Re: [R] Help with nlme--freq weights, logit model, and more


Hi, I'm making the painful but liberating step to full-time linux user.
The switch has been mostly OK. All the stuff I learned when I first sat
down at a unix box is slowly coming back. But I digress.

Today I went to CRAN to get the RH 9 RPM:

http://cran.us.r-project.org/bin/linux/redhat/9/i386/

And, alas I found none and got the RH 8 build instead.

Here's what happens when I try the RPM:

[root at facet r.stuff]# rpm -i R-1.7.0-1.i386.rpm
warning: R-1.7.0-1.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
error: Failed dependencies:
        libtcl.so.0 is needed by R-1.7.0-1
        libtk.so.0 is needed by R-1.7.0-1

But a newer version of tcl (and tk) was installed with the RH 9
installation. 

[root at facet misc.rpms]# rpm -qa | grep -i tcl
tcl-8.3.5-88

So, in a short and ill-advised moment of lunacy I forced it:

[root at facet r.stuff]# rpm -i --nodeps *.rpm


That went as poorly as one might expect.
 
I suppose that I could roll back the tcl version but that seems
counterproductive. Is there a way to force the rpm? Can somebody smarter
than me make a good RPM for RH 9?

I'm loathe to install from source.

Thanks and I hope this is isn't an embarrassing question.

-Andy

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From abunn at montana.edu  Sat Apr 19 01:04:00 2003
From: abunn at montana.edu (Andy Bunn)
Date: 18 Apr 2003 17:04:00 -0600
Subject: [R] Sorry - Red Hat 9.0 RPM problem
In-Reply-To: <NEBBIPHDAMMOKDKPOFFIMEKGCHAA.abunn@montana.edu>
References: <NEBBIPHDAMMOKDKPOFFIMEKGCHAA.abunn@montana.edu>
Message-ID: <1050707040.2929.3.camel@facet.msu.montana.edu>

Egads. The force worked. It hung when I tried it and the process
resisted killing but when I rebooted R was working. Appologies for
misusing the list. I really didn't think it had worked.

Repentfully, Andy 


On Fri, 2003-04-18 at 16:43, Andy Bunn wrote:
> Excuse the wrong subject header.
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Andy Bunn
> Sent: Friday, April 18, 2003 4:29 PM
> To: R Listserv
> Subject: Re: [R] Help with nlme--freq weights, logit model, and more
> 
> 
> Hi, I'm making the painful but liberating step to full-time linux user.
> The switch has been mostly OK. All the stuff I learned when I first sat
> down at a unix box is slowly coming back. But I digress.
> 
> Today I went to CRAN to get the RH 9 RPM:
> 
> http://cran.us.r-project.org/bin/linux/redhat/9/i386/
> 
> And, alas I found none and got the RH 8 build instead.
> 
> Here's what happens when I try the RPM:
> 
> [root at facet r.stuff]# rpm -i R-1.7.0-1.i386.rpm
> warning: R-1.7.0-1.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
> error: Failed dependencies:
>         libtcl.so.0 is needed by R-1.7.0-1
>         libtk.so.0 is needed by R-1.7.0-1
> 
> But a newer version of tcl (and tk) was installed with the RH 9
> installation. 
> 
> [root at facet misc.rpms]# rpm -qa | grep -i tcl
> tcl-8.3.5-88
> 
> So, in a short and ill-advised moment of lunacy I forced it:
> 
> [root at facet r.stuff]# rpm -i --nodeps *.rpm
> 
> 
> That went as poorly as one might expect.
>  
> I suppose that I could roll back the tcl version but that seems
> counterproductive. Is there a way to force the rpm? Can somebody smarter
> than me make a good RPM for RH 9?
> 
> I'm loathe to install from source.
> 
> Thanks and I hope this is isn't an embarrassing question.
> 
> -Andy
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>


From mschwartz at medanalytics.com  Sat Apr 19 01:05:53 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Fri, 18 Apr 2003 18:05:53 -0500
Subject: [R] Sorry - Red Hat 9.0 RPM problem
In-Reply-To: <NEBBIPHDAMMOKDKPOFFIMEKGCHAA.abunn@montana.edu>
References: <NEBBIPHDAMMOKDKPOFFIMEKGCHAA.abunn@montana.edu>
Message-ID: <3EA084D1.1090408@medanalytics.com>

Andy Bunn wrote:
> Excuse the wrong subject header.
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Andy Bunn
> Sent: Friday, April 18, 2003 4:29 PM
> To: R Listserv
> Subject: Re: [R] Help with nlme--freq weights, logit model, and more
> 
> 
> Hi, I'm making the painful but liberating step to full-time linux user.
> The switch has been mostly OK. All the stuff I learned when I first sat
> down at a unix box is slowly coming back. But I digress.
> 
> Today I went to CRAN to get the RH 9 RPM:
> 
> http://cran.us.r-project.org/bin/linux/redhat/9/i386/
> 
> And, alas I found none and got the RH 8 build instead.
> 
> Here's what happens when I try the RPM:
> 
> [root at facet r.stuff]# rpm -i R-1.7.0-1.i386.rpm
> warning: R-1.7.0-1.i386.rpm: V3 DSA signature: NOKEY, key ID 97d3544e
> error: Failed dependencies:
>         libtcl.so.0 is needed by R-1.7.0-1
>         libtk.so.0 is needed by R-1.7.0-1
> 
> But a newer version of tcl (and tk) was installed with the RH 9
> installation. 
> 
> [root at facet misc.rpms]# rpm -qa | grep -i tcl
> tcl-8.3.5-88
> 
> So, in a short and ill-advised moment of lunacy I forced it:
> 
> [root at facet r.stuff]# rpm -i --nodeps *.rpm
> 
> 
> That went as poorly as one might expect.
>  
> I suppose that I could roll back the tcl version but that seems
> counterproductive. Is there a way to force the rpm? Can somebody smarter
> than me make a good RPM for RH 9?
> 
> I'm loathe to install from source.
> 
> Thanks and I hope this is isn't an embarrassing question.
> 
> -Andy

Andy,

It would appear that Martyn has begun the process of uploading the 
official RH 9 RPM (as the RH 9 folder was not there yesterday).  If you 
can wait, my guess is that the RPM should show up on CRAN "soon" given 
that the MD5 sum file is now there.

If not and you are comfortable with the process, you can create the RH 9 
RPM from the source RPM (SRPM) at:

http://cran.r-project.org/bin/linux/redhat/SRPMS/R-1.7.0-1.src.rpm

Alternatively, you can compile from the source tar ball on CRAN.

Either compiling approach will take about 30 to 40 minutes, depending 
upon your platform.

As you have experienced, do not try to force the RH 8.0 RPM on RH 9.

HTH,

Marc Schwartz


From faheem at email.unc.edu  Sat Apr 19 01:22:58 2003
From: faheem at email.unc.edu (Faheem Mitha)
Date: Fri, 18 Apr 2003 19:22:58 -0400 (EDT)
Subject: [R] superimposing graphs
Message-ID: <Pine.LNX.4.44.0304181845500.4959-100000@Chrestomanci>


Dear People,

I have a data set of data x from a probability distribution, and I have a
function, mydensity, of the pdf of that distribution.

I'm asking for help in superimposing the histogram of x and the plot of
mydensity.

In the function below, I call truehist and curve, but these are plotted in
different figures.

I'd like them to be plotted on the same figure, and to use common axes, of
course. Can anyone suggest a simple, robust way to do this? I'd prefer not
to do micro-fiddling of graphical parameters if possible.

I'm currently searching R-help mail archives to see if I can turn up
something.

A couple of people suggest par(new=TRUE), but this superimposes
everything, including the axes.

I notice that there is something very similar in the trellis demo, namely

 print(densityplot(~x))
  print(histogram(x, type = "density",
                  panel = function(x, ...) {
                    panel.histogram(x, ...)
                    panel.densityplot(x, col = "brown",
plot.points = FALSE)
                  }))

which plots a histogram and a density plot on top of that. However, I
cannot get the syntax to work right. (I'm not at all familar with trellis
graphics).  Does anyone know whether I could turn this to my purposes?
If so, the exact syntax required would be helpful.

Thanks in advance.

                                                      Faheem.

***********************************************************************

mg.hist <- function(len,theta,pos,size)
{
  x <- empmargdistvec(len,theta,pos,size)


  postscript(file="plot.ps", horizontal = FALSE, onefile = FALSE, paper
             = "special", width=6, height=4)
  par(mfcol=c(1,2),pch=20)

  truehist(x, nbins=100)

  mydensityfn <- function(x)
    {
      mydensity(x,theta,pos,len)
    }
  curve(mydensityfn)

  dev.off()


From edd at debian.org  Sat Apr 19 02:30:49 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 18 Apr 2003 19:30:49 -0500
Subject: [R] superimposing graphs
In-Reply-To: <Pine.LNX.4.44.0304181845500.4959-100000@Chrestomanci>
References: <Pine.LNX.4.44.0304181845500.4959-100000@Chrestomanci>
Message-ID: <20030419003049.GA25335@sonny.eddelbuettel.com>

On Fri, Apr 18, 2003 at 07:22:58PM -0400, Faheem Mitha wrote:
> In the function below, I call truehist and curve, but these are plotted in
> different figures.
> 
> I'd like them to be plotted on the same figure, and to use common axes, of
> course. Can anyone suggest a simple, robust way to do this? I'd prefer not
> to do micro-fiddling of graphical parameters if possible.

Here is one way with an estimated density function, IIRC more a less a copy
of what is in MASS.

> library(MASS)
> X<-rt(250,2)
> Xdensity <- density(X, width=width.SJ(X, method="dpi"), n=200)
> truehist(X, col="lightgray", ymax=max(Xdensity$y))
> lines(Xdensity)
> title(main="Histogram and Density")
> box()

Peter has another solution in ISwR, but that may have been particular to a
Normal distribution, and my copy is at work anyway.

Hth,  Dirk

-- 
Don't drink and derive. Alcohol and algebra don't mix.


From Karen.Chancellor at asu.edu  Sat Apr 19 02:32:40 2003
From: Karen.Chancellor at asu.edu (Karen.Chancellor@asu.edu)
Date: Fri, 18 Apr 2003 17:32:40 -0700 (MST)
Subject: [R] tcltk and Windo$e
Message-ID: <Pine.GSO.4.21.0304181727170.5118-100000@general3.asu.edu>

I am running R1.6.2 under windo$e98. I have followed the instructions in the
Win port faq concerning tck, but when I try 'library(tcltk)', I get

Error in dyn.load(x, as.logical(local), as.logical(now)) : 
        unable to load shared library
"C:/PROGRA~1/R/RW1062/library/tcltk/libs/tcltk.dll":
  LoadLibrary failure:  One of the library files needed to run this
application cannot be found.
Error in library(tcltk) : .First.lib failed

Any ideas?
Thanks
Karen

.-  --.  ....-  -.-.  -.-.


From rpeng at stat.ucla.edu  Sat Apr 19 02:47:41 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri, 18 Apr 2003 17:47:41 -0700 (PDT)
Subject: [R] superimposing graphs
In-Reply-To: <Pine.LNX.4.44.0304181845500.4959-100000@Chrestomanci>
Message-ID: <Pine.GSO.4.10.10304181746020.5072-100000@quetelet.stat.ucla.edu>

You can use curve(), but you need to add the `add = TRUE' argument.  For
example,

library(MASS)
x <- rnorm(100)
truehist(x)
curve(dnorm, -3, 3, add = TRUE)


-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Fri, 18 Apr 2003, Faheem Mitha wrote:

> 
> Dear People,
> 
> I have a data set of data x from a probability distribution, and I have a
> function, mydensity, of the pdf of that distribution.
> 
> I'm asking for help in superimposing the histogram of x and the plot of
> mydensity.
> 
> In the function below, I call truehist and curve, but these are plotted in
> different figures.
> 
> I'd like them to be plotted on the same figure, and to use common axes, of
> course. Can anyone suggest a simple, robust way to do this? I'd prefer not
> to do micro-fiddling of graphical parameters if possible.
> 
> I'm currently searching R-help mail archives to see if I can turn up
> something.
> 
> A couple of people suggest par(new=TRUE), but this superimposes
> everything, including the axes.
> 
> I notice that there is something very similar in the trellis demo, namely
> 
>  print(densityplot(~x))
>   print(histogram(x, type = "density",
>                   panel = function(x, ...) {
>                     panel.histogram(x, ...)
>                     panel.densityplot(x, col = "brown",
> plot.points = FALSE)
>                   }))
> 
> which plots a histogram and a density plot on top of that. However, I
> cannot get the syntax to work right. (I'm not at all familar with trellis
> graphics).  Does anyone know whether I could turn this to my purposes?
> If so, the exact syntax required would be helpful.
> 
> Thanks in advance.
> 
>                                                       Faheem.
> 
> ***********************************************************************
> 
> mg.hist <- function(len,theta,pos,size)
> {
>   x <- empmargdistvec(len,theta,pos,size)
> 
> 
>   postscript(file="plot.ps", horizontal = FALSE, onefile = FALSE, paper
>              = "special", width=6, height=4)
>   par(mfcol=c(1,2),pch=20)
> 
>   truehist(x, nbins=100)
> 
>   mydensityfn <- function(x)
>     {
>       mydensity(x,theta,pos,len)
>     }
>   curve(mydensityfn)
> 
>   dev.off()
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From Richard.Rowe at jcu.edu.au  Sat Apr 19 02:22:08 2003
From: Richard.Rowe at jcu.edu.au (Richard Rowe)
Date: Sat, 19 Apr 2003 10:22:08 +1000
Subject: [R] superimposing graphs
In-Reply-To: <Pine.LNX.4.44.0304181845500.4959-100000@Chrestomanci>
Message-ID: <5.0.0.25.1.20030419101342.03d08d70@pop.jcu.edu.au>

Faheem this has been asked several times in the past couple of months.

check ?curve and the parameter 'add' as in

curve(fc(x), 0, 10, col = "darkblue", add = TRUE) # from the reference manual

If this isn't what you want then search Jonathon Baron's archive at 
http://finzi.psych.upenn.edu/search.html for numerous other solutions,



Richard Rowe
Senior Lecturer
Department of Zoology and Tropical Ecology, James Cook University
Townsville, Queensland 4811, Australia
fax (61)7 47 25 1570
phone (61)7 47 81 4851
e-mail: Richard.Rowe at jcu.edu.au
http://www.jcu.edu.au/school/tbiol/zoology/homepage.html


From faheem at email.unc.edu  Sat Apr 19 03:15:28 2003
From: faheem at email.unc.edu (Faheem Mitha)
Date: Fri, 18 Apr 2003 21:15:28 -0400 (EDT)
Subject: [R] superimposing graphs
In-Reply-To: <5.0.0.25.1.20030419101342.03d08d70@pop.jcu.edu.au>
Message-ID: <Pine.LNX.4.44.0304182108390.4959-100000@Chrestomanci>



On Sat, 19 Apr 2003, Richard Rowe wrote:

> Faheem this has been asked several times in the past couple of months.
>
> check ?curve and the parameter 'add' as in
>
> curve(fc(x), 0, 10, col = "darkblue", add = TRUE) # from the reference manual
>
> If this isn't what you want then search Jonathon Baron's archive at
> http://finzi.psych.upenn.edu/search.html for numerous other solutions,

Yes, I spent some time searching the R-help archive, but my queries were
of the general form "superpose graph" and similar. I did not notice that
curve had the add=TRUE option, which clearly is the simplest way to handle
this. The trouble with finding the right answer is first asking the right
question...

Thanks to everyone else who replied, namely james.holtman at convergys.com,
Dirk Eddelbuettel and Roger Peng (who also suggested the add=TRUE option).
I appreciate it.

                                             Faheem.


From Richard.Rowe at jcu.edu.au  Sat Apr 19 03:09:24 2003
From: Richard.Rowe at jcu.edu.au (Richard Rowe)
Date: Sat, 19 Apr 2003 11:09:24 +1000
Subject: [R] Re: Validation of R
In-Reply-To: <6rd6jj7862.fsf@bates4.stat.wisc.edu>
References: <OFEA39FB05.FE747744-ON85256D0C.0058B914@bd.com>
 <OFEA39FB05.FE747744-ON85256D0C.0058B914@bd.com>
Message-ID: <5.0.0.25.1.20030419102529.03d0abf0@pop.jcu.edu.au>

OK - to hard reality.

R has become mainstream among practitioners BECAUSE IT IS 
GOOD.  Practitioners have been voting with their feet/time for years, but 
with recent publicity the tide is becoming a flood.

At some stage we (as in the R community, not the over-worked core) are 
going to have to do something to 'protect' our members in the commercial 
community (and with the push of 'accountability' and its legions of 
analphabet clerks into the academic/research community soon the rest of us).

I suggest that those interested in 'validation' form a group and set about 
systematically 'validating' R processes.
Prebuilt 'evil' datasets (like Anscombe) and simulation using a range of 
different pseudorandom generators to generate data is probably the best 
way.  I once attended a lecture by John Tukey where he described the 
'tests' a measure should be put through wrt input structures (I remember 
one was characterised as a 'rabbit punch', another as 'knee-in-the-groin'), 
such a repertoire of exercises could be put in place.  Testers need to 
recognise that standard functions can be exposed to the weirdest 
distributions when they are called as an intermediate step in another 
calculation.
Code needs to do exactly what it is documented to do, and to squawk loudly 
when asked to do what it doesn't.

I am sure those who have built so much code would really appreciate getting 
a note from the validating group confirming it has been tested and hasn't 
broken down, or else getting a note documenting exactly where and how code 
doesn't work as expected ...

R is open source.  We all have access to the code.  We could also have open 
source published test datasets and outcomes ... which would actually 
present a challenge to the COTS industry to match.

If it is to happen then someone who feels strongly about this needs to get 
the ball rolling, and there would probably need to be a sympathetic conduit 
into/from the core.

For QA purposes the 'testers' will need to be independent of the 
'producers' ...

Richard Rowe
Senior Lecturer
Department of Zoology and Tropical Ecology, James Cook University
Townsville, Queensland 4811, Australia
fax (61)7 47 25 1570
phone (61)7 47 81 4851
e-mail: Richard.Rowe at jcu.edu.au
http://www.jcu.edu.au/school/tbiol/zoology/homepage.html


From p.dalgaard at biostat.ku.dk  Sat Apr 19 11:08:57 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 19 Apr 2003 11:08:57 +0200
Subject: [R] superimposing graphs
In-Reply-To: <20030419003049.GA25335@sonny.eddelbuettel.com>
References: <Pine.LNX.4.44.0304181845500.4959-100000@Chrestomanci>
	<20030419003049.GA25335@sonny.eddelbuettel.com>
Message-ID: <x2ptniua52.fsf@biostat.ku.dk>

Dirk Eddelbuettel <edd at debian.org> writes:

> On Fri, Apr 18, 2003 at 07:22:58PM -0400, Faheem Mitha wrote:

> Peter has another solution in ISwR, but that may have been particular to a
> Normal distribution, and my copy is at work anyway.

(The scripts are in the ISwR package, though... End of Section 1.3 and
beginning of 1.4.) The basic principle is this

h <- hist(x, plot=F)
ylim <- range(0, h$density, dnorm(0))
hist(x, freq=F, ylim=ylim)
curve(dnorm(x), add=T)

The main point is to keep both the histogram and the curve on scale,
so it does rely on knowing that the max of the normal density is at
the mean. For an empirical density, you'll have to find its maximum
empirically, but otherwise the same technique applies.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From dmurdoch at pair.com  Sat Apr 19 12:31:59 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 19 Apr 2003 06:31:59 -0400
Subject: [R] tcltk and Windo$e
In-Reply-To: <Pine.GSO.4.21.0304181727170.5118-100000@general3.asu.edu>
References: <Pine.GSO.4.21.0304181727170.5118-100000@general3.asu.edu>
Message-ID: <tu82av0bk65o3knr6jshsh281ct2u1fc98@4ax.com>

On Fri, 18 Apr 2003 17:32:40 -0700 (MST), you wrote:

>I am running R1.6.2 under windo$e98. I have followed the instructions in the
>Win port faq concerning tck, but when I try 'library(tcltk)', I get
>
>Error in dyn.load(x, as.logical(local), as.logical(now)) : 
>        unable to load shared library
>"C:/PROGRA~1/R/RW1062/library/tcltk/libs/tcltk.dll":
>  LoadLibrary failure:  One of the library files needed to run this
>application cannot be found.
>Error in library(tcltk) : .First.lib failed

Assuming that tcltk.dll really is there, this probably means that it
can't find one of the dlls that it uses.  I'd guess one of the
environment variables isn't set properly, and I think it's the PATH
that's used to find the DLL.  Use Sys.getenv("PATH") and
Sys.getenv("TCL_LIBRARY") inside R to make sure they look right.

Even better: I recommend upgrading to 1.7.0:  in the new release the
TCL/TK files are automatically installed properly.

Duncan Murdoch


From ligges at statistik.uni-dortmund.de  Sat Apr 19 13:08:17 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 19 Apr 2003 13:08:17 +0200
Subject: [R] Keyboard problem using RWin 1.7.0
References: <55.3dea5b34.2bd1ad29@aol.com>
Message-ID: <3EA12E21.81E9F23B@statistik.uni-dortmund.de>



DJNordlund at aol.com wrote:
> 
> I just installed RWin 1.7.0 on an Intel box running Win2000 Pro.  If I try to
> paste from the clipboard to the console command line, the command(s) are
> executed, but the console then stops responding to the keyboard.  The only
> way I have found to continue is to use the mouse to shut down R.
> 
> Typing in the console works just fine; commands are executed, command-line
> editing is ok, source-ing files works, etc.  Everything works fine until I
> try to paste to the console, then the keyboard stops responding.  Any
> thoughts?


Works for me on WinXP and WinNT4.0 with self-compiled copies (I guess
you are using the binaries from CRAN?).
- What exactly did you copy from the clipboard?
- Do you have any additional clipboard software running?

BTW: 
Duncan, browsing to http://cran.r-project.org/bin/windows/base ,
there seems to be a wrong link pointing to a non-existing file
"rw08.exe".

Uwe Ligges


From ligges at statistik.uni-dortmund.de  Sat Apr 19 13:24:45 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 19 Apr 2003 13:24:45 +0200
Subject: [R] system() and R 1.7
References: <76A000A82289D411952F001083F9DD06039ACB63@exsalem4-bu.odot.state.or.us>
Message-ID: <3EA131FD.F2E55084@statistik.uni-dortmund.de>

Benjamin.STABLER at odot.state.or.us wrote:
> 
> I am using the system(command, input=a character vector) command on a
> Windows NT machine and I now get the following warning with R 1.7:
> 
> Warning message:
> the condition has length > 1 and only the first element will be used in: if
> (input != "") {
> 
> I think I am getting this warning because, according to Peter Dalgaard, R
> 1.7 now gives a warning if if() and while() are called with a vector
> condition.  Is there anyway to fix this issue besides options(warn=-1)?
> Thanks.

The fix to system would be as follows (just those two lines):


> > system
> function (command, intern = FALSE, wait = TRUE, input = "",

 function (command, intern = FALSE, wait = TRUE, input = NULL,

> show.output.on.console = FALSE,
>     minimized = FALSE, invisible = FALSE)
> {
>     f <- ""
>     if (input != "") {

    if(!is.null(input)){

>         f <- tempfile()
>         on.exit(unlink(f))
>         cat(input, file = f, sep = "\n")
>     }
>     if (intern)
>         flag <- 3
>     else {
>         if (wait)
>             flag <- ifelse(show.output.on.console, 2, 1)
>         else flag <- 0
>     }
>     if (invisible)
>         flag <- 20 + flag
>     else if (minimized)
>         flag <- 10 + flag
>     .Internal(system(command, as.integer(flag), f))
> }
> <environment: namespace:base>
> 
> Benjamin Stabler
> Transportation Planning Analysis Unit
> Oregon Department of Transportation
> 555 13th Street NE, Suite 2
> Salem, OR 97301  Ph: 503-986-4104


Uwe Ligges


From dmurdoch at pair.com  Sat Apr 19 18:07:16 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 19 Apr 2003 12:07:16 -0400
Subject: [R] system() and R 1.7
In-Reply-To: <76A000A82289D411952F001083F9DD06039ACB63@exsalem4-bu.odot.state.or.us>
References: <76A000A82289D411952F001083F9DD06039ACB63@exsalem4-bu.odot.state.or.us>
Message-ID: <ils2avckilc721gggqtrgamk2a6jb7mmcb@4ax.com>

On Fri, 18 Apr 2003 11:04:48 -0700, you wrote:

>I am using the system(command, input=a character vector) command on a
>Windows NT machine and I now get the following warning with R 1.7:
>
>Warning message: 
>the condition has length > 1 and only the first element will be used in: if
>(input != "") { 
>

This is a bug, fixed in the current patch version.  To fix your own,
you could edit the file library/base/R/base, as follows:

27878c27879
< system <- function(command, intern = FALSE, wait = TRUE, input = "",
---
> system <- function(command, intern = FALSE, wait = TRUE, input = NULL,
27883c27884
<     if (input!="") {
---
>     if (!is.null(input)) {

The top lines are the released version, the lower lines are the patch.

Duncan Murdoch


From DJNordlund at aol.com  Sat Apr 19 21:03:05 2003
From: DJNordlund at aol.com (DJNordlund@aol.com)
Date: Sat, 19 Apr 2003 15:03:05 EDT
Subject: [R] Keyboard problem using RWin 1.7.0
Message-ID: <4e.1b0a3265.2bd2f769@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030419/9d0f376a/attachment.pl

From dmurdoch at pair.com  Sat Apr 19 21:24:48 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sat, 19 Apr 2003 15:24:48 -0400
Subject: [R] Keyboard problem using RWin 1.7.0
In-Reply-To: <4e.1b0a3265.2bd2f769@aol.com>
References: <4e.1b0a3265.2bd2f769@aol.com>
Message-ID: <jd83avsm0hpkk262cfg5hmd54kjedc2rrh@4ax.com>

On Sat, 19 Apr 2003 15:03:05 EDT, you wrote:

>
>Since others do not appear to be having this problem, and I have two simple 
>work arounds, I will probably not pursue this much further.  Thanks for the 
>input.

Could you submit your description and workaround as a bug report?
I've seen lockups before, but never reproducibly.  

I can't reproduce yours now (it doesn't happen for me in WinXP Pro),
but it would be useful to have a record of it in case I can sometime
in the future.

Duncan Murdoch


From sdfrost at ucsd.edu  Sat Apr 19 21:26:35 2003
From: sdfrost at ucsd.edu (sdfrost@ucsd.edu)
Date: Sat, 19 Apr 2003 19:26:35 GMT
Subject: [R] nls, gnls, starting values, and covariance matrix
Message-ID: <200304191926.h3JJQYM4012576@smtp.ucsd.edu>

Dear R-Help,

I'm trying to fit a model of the following form using gnls. I've fitted it 
using nlsList with the following syntax:

nlsList(Y~log(exp(a0-a1*X)+exp(b0-b1*X))|K,start=list
(a0=6,a1=0.2,b0=4.5,b1=0.001),data=data.frame(Y=y,X=X,K=k)))

which works just fine:

<snip>

Coefficients:
         a0        a1       b0            b1 
 1 5.459381 0.5006811 5.137458 -0.0040548687
 2 5.761496 0.1716723 6.359151 -0.0022802595
 3 5.683510 0.5436838 5.906742 -0.0007788076
 4 6.225745 0.2807003 5.875803 -0.0008351051
 5 6.558350 0.1388707 5.071080  0.0014594212
 6 5.483639 0.2757080 2.406683 -0.0003282243
 7 5.746064 0.4354105 5.883882 -0.0002577279
 8 5.448679 0.3385350 2.851571  0.0011627360
 9 5.259762 0.5654369 5.498967  0.0015381718
10 6.546022 0.8008781 4.913085  0.0051150166
12 5.602982 1.1538595 5.008253 -0.0006087786
13 6.452605 0.1752357 6.229393  0.0007899073
15 5.937199 0.2214811 4.980386  0.0081102533
16 5.998689 0.2925840 6.077816  0.0062388250

However, I'd like to be able to fit the model using gnls. The format is a 
little different, but I get an error when I use the following syntax:

gnls(Y~log(exp(a0-a1*X)+exp(b0-b1*X)),params=a0+a1+b0+b1~K,start=list(rep(c
(6.02,0.2,4.5,0.001),16)),data=data.frame(Y=y,X=x,K=k),control=list
(msVerbose=TRUE,apVar=FALSE,returnObject=TRUE))

Error in gnls(Y ~ log(exp(a0 - a1 * X) + exp(b0 - b1 * X)), params = a0 +  : 
        Approx. covariance matrix for parameter estimates not of full rank

I assume that I'm getting the format of my starting values wrong. Any 
suggestions would be greatly appreciated.

Best wishes
Simon


From tblackw at umich.edu  Sat Apr 19 21:54:20 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Sat, 19 Apr 2003 15:54:20 -0400 (EDT)
Subject: [R] nls, gnls, starting values, and covariance matrix
In-Reply-To: <200304191926.h3JJQYM4012576@smtp.ucsd.edu>
Message-ID: <Pine.SOL.4.44.0304191545070.21911-100000@tetris.gpcc.itd.umich.edu>

Simon  -

There's a symmetry in the model you are fitting, and the error
message returned sounds to me as though it is referring to that.

Could you try a model formula of the form

Y ~ a0 + log(exp(-c0-a1*X) + exp(+c0-b1*X))

Maybe you will need to make the two slopes identifiable in much
the same fashion that I've done for the two intercepts, in order
to get it to work.  Or maybe not.  I'll leave that up to you.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Sat, 19 Apr 2003 sdfrost at ucsd.edu wrote:

> Dear R-Help,
>
> I'm trying to fit a model of the following form using gnls. I've fitted it
> using nlsList with the following syntax:
>
> nlsList(Y~log(exp(a0-a1*X)+exp(b0-b1*X))|K,start=list
> (a0=6,a1=0.2,b0=4.5,b1=0.001),data=data.frame(Y=y,X=X,K=k)))
>
> which works just fine:
>
> <snip>
>
> Coefficients:
>          a0        a1       b0            b1
>  1 5.459381 0.5006811 5.137458 -0.0040548687
>  2 5.761496 0.1716723 6.359151 -0.0022802595
>  3 5.683510 0.5436838 5.906742 -0.0007788076
>  4 6.225745 0.2807003 5.875803 -0.0008351051
>  5 6.558350 0.1388707 5.071080  0.0014594212
>  6 5.483639 0.2757080 2.406683 -0.0003282243
>  7 5.746064 0.4354105 5.883882 -0.0002577279
>  8 5.448679 0.3385350 2.851571  0.0011627360
>  9 5.259762 0.5654369 5.498967  0.0015381718
> 10 6.546022 0.8008781 4.913085  0.0051150166
> 12 5.602982 1.1538595 5.008253 -0.0006087786
> 13 6.452605 0.1752357 6.229393  0.0007899073
> 15 5.937199 0.2214811 4.980386  0.0081102533
> 16 5.998689 0.2925840 6.077816  0.0062388250
>
> However, I'd like to be able to fit the model using gnls. The format is a
> little different, but I get an error when I use the following syntax:
>
> gnls(Y~log(exp(a0-a1*X)+exp(b0-b1*X)),params=a0+a1+b0+b1~K,start=list(rep(c
> (6.02,0.2,4.5,0.001),16)),data=data.frame(Y=y,X=x,K=k),control=list
> (msVerbose=TRUE,apVar=FALSE,returnObject=TRUE))
>
> Error in gnls(Y ~ log(exp(a0 - a1 * X) + exp(b0 - b1 * X)), params = a0 +  :
>         Approx. covariance matrix for parameter estimates not of full rank
>
> I assume that I'm getting the format of my starting values wrong. Any
> suggestions would be greatly appreciated.
>
> Best wishes
> Simon


From spencer.graves at pdf.com  Sat Apr 19 22:29:51 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 19 Apr 2003 13:29:51 -0700
Subject: [R] nls, gnls, starting values, and covariance matrix
References: <Pine.SOL.4.44.0304191545070.21911-100000@tetris.gpcc.itd.umich.edu>
Message-ID: <3EA1B1BF.5060005@pdf.com>

	  I'm not familiar with gnls, but Bates and Watts (1988, Nonlinear 
Regression Analysis and Its Applications, Wiley, esp. pp. 256-259) 
establish that changing the way a problem is parameterized can have a 
major impact on numerical stability and on the adequacy of approximate 
normal theory for confidence intervals, etc.

	  If you let a0 = c0+c1 and b0 = c0-c1, then your model can be 
rewritten as follows:

	  Y ~ c0 + log(exp(c1-a1*X)+exp(-c1-b1*X))

hth, spencer graves

Thomas W Blackwell wrote:
> Simon  -
> 
> There's a symmetry in the model you are fitting, and the error
> message returned sounds to me as though it is referring to that.
> 
> Could you try a model formula of the form
> 
> Y ~ a0 + log(exp(-c0-a1*X) + exp(+c0-b1*X))
> 
> Maybe you will need to make the two slopes identifiable in much
> the same fashion that I've done for the two intercepts, in order
> to get it to work.  Or maybe not.  I'll leave that up to you.
> 
> HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> On Sat, 19 Apr 2003 sdfrost at ucsd.edu wrote:
> 
> 
>>Dear R-Help,
>>
>>I'm trying to fit a model of the following form using gnls. I've fitted it
>>using nlsList with the following syntax:
>>
>>nlsList(Y~log(exp(a0-a1*X)+exp(b0-b1*X))|K,start=list
>>(a0=6,a1=0.2,b0=4.5,b1=0.001),data=data.frame(Y=y,X=X,K=k)))
>>
>>which works just fine:
>>
>><snip>
>>
>>Coefficients:
>>         a0        a1       b0            b1
>> 1 5.459381 0.5006811 5.137458 -0.0040548687
>> 2 5.761496 0.1716723 6.359151 -0.0022802595
>> 3 5.683510 0.5436838 5.906742 -0.0007788076
>> 4 6.225745 0.2807003 5.875803 -0.0008351051
>> 5 6.558350 0.1388707 5.071080  0.0014594212
>> 6 5.483639 0.2757080 2.406683 -0.0003282243
>> 7 5.746064 0.4354105 5.883882 -0.0002577279
>> 8 5.448679 0.3385350 2.851571  0.0011627360
>> 9 5.259762 0.5654369 5.498967  0.0015381718
>>10 6.546022 0.8008781 4.913085  0.0051150166
>>12 5.602982 1.1538595 5.008253 -0.0006087786
>>13 6.452605 0.1752357 6.229393  0.0007899073
>>15 5.937199 0.2214811 4.980386  0.0081102533
>>16 5.998689 0.2925840 6.077816  0.0062388250
>>
>>However, I'd like to be able to fit the model using gnls. The format is a
>>little different, but I get an error when I use the following syntax:
>>
>>gnls(Y~log(exp(a0-a1*X)+exp(b0-b1*X)),params=a0+a1+b0+b1~K,start=list(rep(c
>>(6.02,0.2,4.5,0.001),16)),data=data.frame(Y=y,X=x,K=k),control=list
>>(msVerbose=TRUE,apVar=FALSE,returnObject=TRUE))
>>
>>Error in gnls(Y ~ log(exp(a0 - a1 * X) + exp(b0 - b1 * X)), params = a0 +  :
>>        Approx. covariance matrix for parameter estimates not of full rank
>>
>>I assume that I'm getting the format of my starting values wrong. Any
>>suggestions would be greatly appreciated.
>>
>>Best wishes
>>Simon
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Sat Apr 19 22:58:49 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 19 Apr 2003 13:58:49 -0700
Subject: [R] nls, gnls, starting values, and covariance matrix
References: <Pine.SOL.4.44.0304191545070.21911-100000@tetris.gpcc.itd.umich.edu>
Message-ID: <3EA1B889.7090008@pdf.com>

Also, not all algorithms are equally robust.  McCullougn (either 1998 or 
1999, "Assessing the reliability of statistical software: Part I or 
II'', The American Statistician,  52: 358-366 or 53:  149-159) reported 
that he often had trouble getting "nls" in S-Plus to converge.  He 
recommended using "nlminb" to get convergence and then using the output 
from nlminb as starting values in "nls" to get confidence intervals that 
nls provided but nlminb did not.  Today, I use "optim" in the MASS 
library in place of nlminb.

hth, spencer graves
#################
	  I'm not familiar with gnls, but Bates and Watts (1988, Nonlinear 
Regression Analysis and Its Applications, Wiley, esp. pp. 256-259) 
establish that changing the way a problem is parameterized can have a 
major impact on numerical stability and on the adequacy of approximate 
normal theory for confidence intervals, etc.

	  If you let a0 = c0+c1 and b0 = c0-c1, then your model can be
rewritten as follows:

	  Y ~ c0 + log(exp(c1-a1*X)+exp(-c1-b1*X))

hth, spencer graves

Thomas W Blackwell wrote:
 > Simon  -
 >
 > There's a symmetry in the model you are fitting, and the error
 > message returned sounds to me as though it is referring to that.
 >
 > Could you try a model formula of the form
 >
 > Y ~ a0 + log(exp(-c0-a1*X) + exp(+c0-b1*X))
 >
 > Maybe you will need to make the two slopes identifiable in much
 > the same fashion that I've done for the two intercepts, in order
 > to get it to work.  Or maybe not.  I'll leave that up to you.
 >
 > HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -
 >
 > On Sat, 19 Apr 2003 sdfrost at ucsd.edu wrote:
 >
 >
 >>Dear R-Help,
 >>
 >>I'm trying to fit a model of the following form using gnls. I've 
fitted it
 >>using nlsList with the following syntax:
 >>
 >>nlsList(Y~log(exp(a0-a1*X)+exp(b0-b1*X))|K,start=list
 >>(a0=6,a1=0.2,b0=4.5,b1=0.001),data=data.frame(Y=y,X=X,K=k)))
 >>
 >>which works just fine:
 >>
 >><snip>
 >>
 >>Coefficients:
 >>         a0        a1       b0            b1
 >> 1 5.459381 0.5006811 5.137458 -0.0040548687
 >> 2 5.761496 0.1716723 6.359151 -0.0022802595
 >> 3 5.683510 0.5436838 5.906742 -0.0007788076
 >> 4 6.225745 0.2807003 5.875803 -0.0008351051
 >> 5 6.558350 0.1388707 5.071080  0.0014594212
 >> 6 5.483639 0.2757080 2.406683 -0.0003282243
 >> 7 5.746064 0.4354105 5.883882 -0.0002577279
 >> 8 5.448679 0.3385350 2.851571  0.0011627360
 >> 9 5.259762 0.5654369 5.498967  0.0015381718
 >>10 6.546022 0.8008781 4.913085  0.0051150166
 >>12 5.602982 1.1538595 5.008253 -0.0006087786
 >>13 6.452605 0.1752357 6.229393  0.0007899073
 >>15 5.937199 0.2214811 4.980386  0.0081102533
 >>16 5.998689 0.2925840 6.077816  0.0062388250
 >>
 >>However, I'd like to be able to fit the model using gnls. The format is a
 >>little different, but I get an error when I use the following syntax:
 >>
 >>gnls(Y~log(exp(a0-a1*X)+exp(b0-b1*X)),params=a0+a1+b0+b1~K,start=list(rep(c
 >>(6.02,0.2,4.5,0.001),16)),data=data.frame(Y=y,X=x,K=k),control=list
 >>(msVerbose=TRUE,apVar=FALSE,returnObject=TRUE))
 >>
 >>Error in gnls(Y ~ log(exp(a0 - a1 * X) + exp(b0 - b1 * X)), params = 
a0 +  :
 >>        Approx. covariance matrix for parameter estimates not of full 
rank
 >>
 >>I assume that I'm getting the format of my starting values wrong. Any
 >>suggestions would be greatly appreciated.
 >>
 >>Best wishes
 >>Simon
 >
 >
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Sun Apr 20 00:08:34 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 19 Apr 2003 15:08:34 -0700
Subject: [R] nls, gnls, starting values, and covariance matrix
References: <Pine.SOL.4.44.0304191545070.21911-100000@tetris.gpcc.itd.umich.edu>
Message-ID: <3EA1C8E2.9000607@pdf.com>

	  Question:  I note that b1 is close to 0.  In other words, do you get 
any significant reduction in the quality of the fit by removing it from 
the regression equation?  If no, doing so resolved the identifiability 
problem mentioned by Tom Blackwell.

	  If b1 needs to be nonzero in the equation, then I suggest another 
parameterization:  Have you considered replacing a0=c00+c01, b0=c00-c01, 
a1=c10+c11, and b1=c10-c11, so c00=(a0+b0)/2, c01=(a0-b0)/2, 
c10=(a1+b1)/2, and c11=(a1-b1)/2?  With this, we get the following:

	  Y ~ c00+c10*x + log(exp(c01+c11*x)+exp(-c01-c11*x)).

Since b1 is close to 0, both c10 and c11 are approximately a1/2.  Since 
a1 is always positive, you could further replace c11 by exp(c111), and 
break the identifiability problem that way.

hth, spencer graves
################
Also, not all algorithms are equally robust.  McCullougn (either 1998 or
1999, "Assessing the reliability of statistical software: Part I or
II'', The American Statistician,  52: 358-366 or 53:  149-159) reported
that he often had trouble getting "nls" in S-Plus to converge.  He
recommended using "nlminb" to get convergence and then using the output
from nlminb as starting values in "nls" to get confidence intervals that
nls provided but nlminb did not.  Today, I use "optim" in the MASS
library in place of nlminb.

hth, spencer graves
#################
	  I'm not familiar with gnls, but Bates and Watts (1988, Nonlinear
Regression Analysis and Its Applications, Wiley, esp. pp. 256-259)
establish that changing the way a problem is parameterized can have a
major impact on numerical stability and on the adequacy of approximate
normal theory for confidence intervals, etc.

	  If you let a0 = c0+c1 and b0 = c0-c1, then your model can be
rewritten as follows:

	  Y ~ c0 + log(exp(c1-a1*X)+exp(-c1-b1*X))

hth, spencer graves

Thomas W Blackwell wrote:
  > Simon  -
  >
  > There's a symmetry in the model you are fitting, and the error
  > message returned sounds to me as though it is referring to that.
  >
  > Could you try a model formula of the form
  >
  > Y ~ a0 + log(exp(-c0-a1*X) + exp(+c0-b1*X))
  >
  > Maybe you will need to make the two slopes identifiable in much
  > the same fashion that I've done for the two intercepts, in order
  > to get it to work.  Or maybe not.  I'll leave that up to you.
  >
  > HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -
  >
  > On Sat, 19 Apr 2003 sdfrost at ucsd.edu wrote:
  >
  >
  >>Dear R-Help,
  >>
  >>I'm trying to fit a model of the following form using gnls. I've
fitted it
  >>using nlsList with the following syntax:
  >>
  >>nlsList(Y~log(exp(a0-a1*X)+exp(b0-b1*X))|K,start=list
  >>(a0=6,a1=0.2,b0=4.5,b1=0.001),data=data.frame(Y=y,X=X,K=k)))
  >>
  >>which works just fine:
  >>
  >><snip>
  >>
  >>Coefficients:
  >>         a0        a1       b0            b1
  >> 1 5.459381 0.5006811 5.137458 -0.0040548687
  >> 2 5.761496 0.1716723 6.359151 -0.0022802595
  >> 3 5.683510 0.5436838 5.906742 -0.0007788076
  >> 4 6.225745 0.2807003 5.875803 -0.0008351051
  >> 5 6.558350 0.1388707 5.071080  0.0014594212
  >> 6 5.483639 0.2757080 2.406683 -0.0003282243
  >> 7 5.746064 0.4354105 5.883882 -0.0002577279
  >> 8 5.448679 0.3385350 2.851571  0.0011627360
  >> 9 5.259762 0.5654369 5.498967  0.0015381718
  >>10 6.546022 0.8008781 4.913085  0.0051150166
  >>12 5.602982 1.1538595 5.008253 -0.0006087786
  >>13 6.452605 0.1752357 6.229393  0.0007899073
  >>15 5.937199 0.2214811 4.980386  0.0081102533
  >>16 5.998689 0.2925840 6.077816  0.0062388250
  >>
  >>However, I'd like to be able to fit the model using gnls. The format 
is a
  >>little different, but I get an error when I use the following syntax:
  >>
 
 >>gnls(Y~log(exp(a0-a1*X)+exp(b0-b1*X)),params=a0+a1+b0+b1~K,start=list(rep(c
  >>(6.02,0.2,4.5,0.001),16)),data=data.frame(Y=y,X=x,K=k),control=list
  >>(msVerbose=TRUE,apVar=FALSE,returnObject=TRUE))
  >>
  >>Error in gnls(Y ~ log(exp(a0 - a1 * X) + exp(b0 - b1 * X)), params =
a0 +  :
  >>        Approx. covariance matrix for parameter estimates not of full
rank
  >>
  >>I assume that I'm getting the format of my starting values wrong. Any
  >>suggestions would be greatly appreciated.
  >>
  >>Best wishes
  >>Simon
  >
  >
  > ______________________________________________
  > R-help at stat.math.ethz.ch mailing list
  > https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Sun Apr 20 03:40:56 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 19 Apr 2003 18:40:56 -0700
Subject: [R] survreg penalized likelihood?  
Message-ID: <3EA1FAA8.4010201@pdf.com>

	  What objective function is maximized by survreg with the default 
Weibull model?  I'm getting finite parameters in a case that has the 
likelihood maximzed at Infinite, so it can't be a simple maximum 
likelihood.

Consider the following:
#############################
 > set.seed(3)
 > Stress <- rep(1:3, each=3)
 > ch.life <- exp(9-3*Stress)
 > simLife <- rexp(9, rate=1/ch.life)
 > Data <- data.frame(Stress=factor(Stress),
+  Time=pmin(simLife, 50), dead = (simLife<=50))
 > Data[1:3,]
   Stress Time  dead
1      1   50 FALSE
2      1   50 FALSE
3      1   50 FALSE
# All three observations at Stress=1 are censored.
 > Fit <- survreg(Surv(Time, dead)~Stress-1, data=Data)
 > Fit
Call:
survreg(formula = Surv(Time, dead) ~ Stress - 1, data = Data)

Coefficients:
    Stress1    Stress2    Stress3
41.3724178  2.2819204 -0.5281005

Scale= 0.2577886

Loglik(model)= -6.6   Loglik(intercept only)= -22.1
	Chisq= 30.88 on 2 degrees of freedom, p= 2e-07
n= 9
# Even though 100% of observations at Stress=1 are censored,
# I still get a finite estimate for log(characteristics life).

Thanks,
Spencer Graves


From den.duurs at lycos.com  Sun Apr 20 05:42:29 2003
From: den.duurs at lycos.com (Remko Duursma)
Date: Sat, 19 Apr 2003 20:42:29 -0700
Subject: [R] Hmisc interaction behavior
Message-ID: <GGKEFPJJMDENCAAA@mailcity.com>

Dear R-helpers,

Can someone explain to me why the function interaction() from the Hmisc library results in numeric?

test1 <- c("A","B","C")
test2 <- c("D","E","F")

is.numeric(interaction(test1,test2))

[1] TRUE

I had problems with this side effect in a different function.

thanks,

Remko Duursma


From yakovp at earthlink.net  Sun Apr 20 06:21:30 2003
From: yakovp at earthlink.net (yakov peretz)
Date: Sun, 20 Apr 2003 00:21:30 -0400
Subject: [R] horiz barplot with 2 values for each year
Message-ID: <3EA22049.416F49C0@earthlink.net>

Hi,

I'm trying to plot a graph where for each year I have 2 numbers best and
worse. for example for year 2003 I will two values 3.2 and 5.4, and for
year 2004 I will have 3.5 and 6, and so on.



 2003  XXXX
        XXXXXX

2004   XXXXX
        XXXXXXXX

For the same year the 2 entries, if possible, will have different color,
and will be on the graph without space between them. The space will be
between  the years only.

Thnx Yakov


From contact at bonsplansweb.com  Sun Apr 20 06:55:36 2003
From: contact at bonsplansweb.com (BONS PLANS WEB)
Date: Sun, 20 Apr 2003 06:55:36 +0200
Subject: [R] Recommande pour vous :
Message-ID: <20030420045538.922333000475@mwinf0201.wanadoo.fr>


Cher Internaute bonjour !

Vous cherchez les bons plans du Web !? Ne cherchez plus http://www.bonsplansweb.com les trouve pour vous !

En vedette ce mois-ci : Le Super Fuel MAX  un economiseur de carburant brevete mondialement !
Nous l'avons teste pour vous, et ca marche !!!

Pour plus d'infos : http://www.econotec-fr.com

::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
Notre dernier bon plan :

http://www.banco.fr

Site Web serieux proposant des pronostics pour enfin gagner aux courses, la plus grande librairie dediee aux jeux de hasard...
(livres et logiciels sur le LOTO, KENO, CASINO... )

A bientot.
Bon surf !
Le webmaster
http://www.bonsplansweb.com

//////////////////////////////////////////////////////////////////////////////////////////////////////////////
Vous ne revevez qu'un seul e-mail de notre part, votre adresse n'est pas conservee, il n'est donc pas necessaire de vous desinscrire...
//////////////////////////////////////////////////////////////////////////////////////////////////////////////


From vograno at arbitrade.com  Sun Apr 20 08:26:22 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Sun, 20 Apr 2003 01:26:22 -0500
Subject: [R] covariance = diagonal + F'F
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DD9C@jupiter.arbitrade.com>

Dear R-Helpers,

I have a n*m data matrix (n is the number of observations) and I want to
estimate its covariance matrix as a sum of a diagonal matrix and a low-rank
matrix F'F, where F is p*m matrix (sometimes called "factors"), p<<m, and F'
is F transpose.

My questions are:
1. Given the number of factors p is there an R function that finds the best
F?
2. How to select the "best" p?

Somehow I feel like this was already discussed on the list (but I couldn't
find it in the archives). If this is the case what was the subject of that
thread?

Thanks,
Vadim

-------------------------------------------------- 
DISCLAIMER\ This e-mail, and any attachments thereto, is intende... {{dropped}}


From fharrell at virginia.edu  Sun Apr 20 13:22:52 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Sun, 20 Apr 2003 07:22:52 -0400
Subject: [R] Hmisc interaction behavior
In-Reply-To: <GGKEFPJJMDENCAAA@mailcity.com>
References: <GGKEFPJJMDENCAAA@mailcity.com>
Message-ID: <20030420072252.19663fe1.fharrell@virginia.edu>

On Sat, 19 Apr 2003 20:42:29 -0700
Remko Duursma <den.duurs at lycos.com> wrote:

> Dear R-helpers,
> 
> Can someone explain to me why the function interaction() from the Hmisc library results in numeric?
> 
> test1 <- c("A","B","C")
> test2 <- c("D","E","F")
> 
> is.numeric(interaction(test1,test2))
> 
> [1] TRUE
> 
> I had problems with this side effect in a different function.
> 
> thanks,
> 
> Remko Duursma
> 

interaction in Hmisc returns a factor just as the default interaction.  Why that results tests TRUE for is.numeric unlike the default interaction is not clear.   The returned objects tests TRUE for is.factor as it should [I seldom use is.numeric but I use is.factor a lot].

The object returned by Hmisc's interaction is created by saying

levels(levs) <- labs
oldClass(levs) <- 'factor'

for reasons of compatibility with S-Plus 6.  For R I define oldClass<- as 
function (x, value) 
{
    class(x) <- value
    x
}

I should change interaction to use factor( ) instead but I'm curious to know why this problem occurs.

---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From mschwartz at medanalytics.com  Sun Apr 20 15:40:03 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 20 Apr 2003 08:40:03 -0500
Subject: [R] horiz barplot with 2 values for each year
In-Reply-To: <3EA22049.416F49C0@earthlink.net>
References: <3EA22049.416F49C0@earthlink.net>
Message-ID: <3EA2A333.1020508@medanalytics.com>

yakov peretz wrote:
> Hi,
> 
> I'm trying to plot a graph where for each year I have 2 numbers best and
> worse. for example for year 2003 I will two values 3.2 and 5.4, and for
> year 2004 I will have 3.5 and 6, and so on.
> 
> 
> 
>  2003  XXXX
>         XXXXXX
> 
> 2004   XXXXX
>         XXXXXXXX
> 
> For the same year the 2 entries, if possible, will have different color,
> and will be on the graph without space between them. The space will be
> between  the years only.
> 
> Thnx Yakov


Yakov,

Try this:

# Create a matrix containing your data
# with one column per year, in this case 2
mydata <- matrix(c(3.2, 5.4, 3.5, 6), ncol = 2)

# Set the column names to be the years
colnames(mydata) <- c(2003, 2004)

# Look at the structure of the data
mydata

# Create the barplot, setting 'beside' = TRUE
# to generate pairs of bars per year
barplot(mydata, beside = TRUE)

By default the color of the first bars will be different than the colors 
of the second bars. You can also explicitly set the colors in the call 
to barplot() using the 'col' argument.

See ?barplot for more information.

Hope that helps,

Marc Schwartz


From lm.silva at sapo.pt  Sun Apr 20 15:57:53 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Sun, 20 Apr 2003 14:57:53 +0100 (WEST)
Subject: [R] loop
Message-ID: <1050847073.3ea2a76195a7c@webmail.sapo.pt>

Dear helpers

I have this problem. I want to make a linear combination a*A+(1-
a)*B where A and B are matrices. I want that a be incremented 
from 0 to 1 by 0.1 so I made a loop with for. The problem is 
that I want to keep the result in an object or list or 
something like that and then apply eigen decomposition to all 
of the resulting matrices

sapply(my.list,eigen)

the problem is that I don't know how to build that list in the 
loop. I tried several things but it doesn't work (in Matlab i 
can do it)

thanks
luis
--


http://adsl.sapo.pt


From mschwartz at medanalytics.com  Sun Apr 20 16:15:15 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 20 Apr 2003 09:15:15 -0500
Subject: [R] horiz barplot with 2 values for each year
In-Reply-To: <3EA2A333.1020508@medanalytics.com>
References: <3EA22049.416F49C0@earthlink.net>
	<3EA2A333.1020508@medanalytics.com>
Message-ID: <3EA2AB73.3000804@medanalytics.com>

Marc Schwartz wrote:
> yakov peretz wrote:
> 
>> Hi,
>>
>> I'm trying to plot a graph where for each year I have 2 numbers best and
>> worse. for example for year 2003 I will two values 3.2 and 5.4, and for
>> year 2004 I will have 3.5 and 6, and so on.
>>
>>
>>
>>  2003  XXXX
>>         XXXXXX
>>
>> 2004   XXXXX
>>         XXXXXXXX
>>
>> For the same year the 2 entries, if possible, will have different color,
>> and will be on the graph without space between them. The space will be
>> between  the years only.
>>
>> Thnx Yakov


Yakov,

Quick correction, I forgot to set the barplot to horizontal and I noted 
that you want the years to be decreasing as you go down the y axis.  So, 
  use this sequence instead:

mydata <- matrix(c(5.4, 3.2, 6, 3.5), ncol = 2)
colnames(mydata) <- c(2003, 2004)
mydata

# This call reverses the columns in 'mydata' by year and sets
# 'horiz' = TRUE to do a horizontal bar plot. The 'las = 1'
# sets the y axis labels to horizontal as well.

barplot(mydata[, rev(colnames(mydata))], beside = TRUE,
         horiz = TRUE, las = 1)

Sorry for the oversight.

Marc


From sundar.dorai-raj at pdf.com  Sun Apr 20 17:28:51 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Sun, 20 Apr 2003 10:28:51 -0500
Subject: [R] loop
References: <1050847073.3ea2a76195a7c@webmail.sapo.pt>
Message-ID: <3EA2BCB3.3040301@pdf.com>



Luis Silva wrote:
> Dear helpers
> 
> I have this problem. I want to make a linear combination a*A+(1-
> a)*B where A and B are matrices. I want that a be incremented 
> from 0 to 1 by 0.1 so I made a loop with for. The problem is 
> that I want to keep the result in an object or list or 
> something like that and then apply eigen decomposition to all 
> of the resulting matrices
> 
> sapply(my.list,eigen)
> 
> the problem is that I don't know how to build that list in the 
> loop. I tried several things but it doesn't work (in Matlab i 
> can do it)
> 

a <- seq(0, 1, 0.1)
my.list <- lapply(a, function(a, A, B) a*A + (a-1)*B, A=A, B=B)
names(my.list) <- as.character(a)
sapply(my.list, function(x) eigen(x)$value)

Regards,
Sundar


From tblackw at umich.edu  Sun Apr 20 20:56:07 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Sun, 20 Apr 2003 14:56:07 -0400 (EDT)
Subject: [R] covariance = diagonal + F'F
In-Reply-To: <AFD78192EC49D311BFAE00902798AB8F23DD9C@jupiter.arbitrade.com>
Message-ID: <Pine.SOL.4.44.0304201446120.14513-100000@mspacman.gpcc.itd.umich.edu>

Vadim  -

Use  svd()  or  eigen()  to get the eigenvectors and eigenvalues
of a covariance matrix.  svd() gives them without calculating the
matrix product first, so it is preferable numerically.  For your
sum-of-matrices decomposition, I think you'll have to calculate
the covariance matrix minus its diagonal first, and expect the
result not to be positive definite.  Then calculate eigenvectors
and eigenvalues of that and truncate the number retained.  "Best"
is entirely subjective.

I do not recall this sum decomposition from a previous thread.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Sun, 20 Apr 2003, Vadim Ogranovich wrote:

> Dear R-Helpers,
>
> I have a n*m data matrix (n is the number of observations) and I want to
> estimate its covariance matrix as a sum of a diagonal matrix and a low-rank
> matrix F'F, where F is p*m matrix (sometimes called "factors"), p<<m, and F'
> is F transpose.
>
> My questions are:
> 1. Given the number of factors p is there an R function that finds the best
> F?
> 2. How to select the "best" p?
>
> Somehow I feel like this was already discussed on the list (but I couldn't
> find it in the archives). If this is the case what was the subject of that
> thread?
>
> Thanks,
> Vadim


From magnolia at absolutok.net  Sun Apr 20 21:01:47 2003
From: magnolia at absolutok.net (ana kozomara)
Date: Sun, 20 Apr 2003 21:01:47 +0200
Subject: [R] how to use apply with a function created by ourselfs...?
Message-ID: <001cd4701191443SILJA@silja.absolutok.com>

Hi.
I'm a real newbie in R, so
I don't know how to apply, a function created by myself...

prediction<-function(a,b)
{
..
}

to a vector...
It doesn't seem to understand
lapply(vector, prediction())...
Anyone can help me?
Thanks in advance,
ana


From spencer.graves at pdf.com  Sun Apr 20 21:59:38 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 20 Apr 2003 12:59:38 -0700
Subject: [R] covariance = diagonal + F'F
References: <Pine.SOL.4.44.0304201446120.14513-100000@mspacman.gpcc.itd.umich.edu>
Message-ID: <3EA2FC2A.1000703@pdf.com>

	  Have you considered "factanal" in library(mva)?  Unless you want to 
force "diagonal" to be a constant times the identity matrix, this is 
essentially the model fit by factanal.

	  I have not followed the factor analysis literature for some years, so 
I don't know what modern factor analysis gurus recommend to estimate "p" 
= the number of factors, but if I had to have an answer this afternoon, 
I would do the following:  First, I would fit models for p = 1, 2, and 
3.  I would also try p = 0 and hope that would not bomb the software.

	  The documentation for "factanal" says that it has an attribute 
"criterion", which is the negative of the log(likelihood).  I'd extract 
those numbers as one column of a matrix.  In the second column, I'd put 
the attribute "dof" = degrees of freedom in the model.  I'd then compute 
the Akaike Information Criterion (AIC) and put that in the third column.

	  More precisely, I would compute the AIC with a finite sample correction,

	  AIC.c = (-2)*(log(likelihood)-K*(1+(K+1)/(n*m-K-1)),

where K = (dof+m);  this is a slight modification of AIC.c described by 
Burnham and Anderson (2002) Model Selection and Multi-Model Inference, 
2nd ed. (Springer).  The model with the smallest value for AIC.c is the 
best.  Following Burnham and Anderson, I would then compute Del.AIC = 
AIC.c - min(AIC.c) and put that in another column.  The next column 
would then hold w.i = exp(-Del.AIC/2), and the final column would hold 
posterior = w.i/sum(w.i).  This computation is an application of Bayes' 
theorem with a uniform prior and with a correction for bias in 
estimating the likelihood.

	  If this posterior does not sharply favor a value of p in the middle 
of the range tested, I would test more values for p.  If I could not 
easily get a value for p = 0 and the posterior strongly favored 1 
without it, I would try to devlop another way to get a comparable number 
for p = 0.

Hope this helps,
spencer graves

Thomas W Blackwell wrote:
> Vadim  -
> 
> Use  svd()  or  eigen()  to get the eigenvectors and eigenvalues
> of a covariance matrix.  svd() gives them without calculating the
> matrix product first, so it is preferable numerically.  For your
> sum-of-matrices decomposition, I think you'll have to calculate
> the covariance matrix minus its diagonal first, and expect the
> result not to be positive definite.  Then calculate eigenvectors
> and eigenvalues of that and truncate the number retained.  "Best"
> is entirely subjective.
> 
> I do not recall this sum decomposition from a previous thread.
> 
> HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> On Sun, 20 Apr 2003, Vadim Ogranovich wrote:
> 
> 
>>Dear R-Helpers,
>>
>>I have a n*m data matrix (n is the number of observations) and I want to
>>estimate its covariance matrix as a sum of a diagonal matrix and a low-rank
>>matrix F'F, where F is p*m matrix (sometimes called "factors"), p<<m, and F'
>>is F transpose.
>>
>>My questions are:
>>1. Given the number of factors p is there an R function that finds the best
>>F?
>>2. How to select the "best" p?
>>
>>Somehow I feel like this was already discussed on the list (but I couldn't
>>find it in the archives). If this is the case what was the subject of that
>>thread?
>>
>>Thanks,
>>Vadim
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Sun Apr 20 22:05:22 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 20 Apr 2003 13:05:22 -0700
Subject: [R] how to use apply with a function created by ourselfs...?
References: <001cd4701191443SILJA@silja.absolutok.com>
Message-ID: <3EA2FD82.7060507@pdf.com>

By default, arithmetic in R is vectorized, with a scalar being a vector 
of length 1.

Consider the following example:

prediction <- function(a, b)
{
	a+b
}
 > prediction(1:3, 4:6)
[1] 5 7 9

hope this helps, spencer graves

ana kozomara wrote:
> Hi.
> I'm a real newbie in R, so
> I don't know how to apply, a function created by myself...
> 
> prediction<-function(a,b)
> {
> ..
> }
> 
> to a vector...
> It doesn't seem to understand
> lapply(vector, prediction())...
> Anyone can help me?
> Thanks in advance,
> ana
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From p.dalgaard at biostat.ku.dk  Sun Apr 20 22:31:52 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 20 Apr 2003 22:31:52 +0200
Subject: [R] how to use apply with a function created by ourselfs...?
In-Reply-To: <3EA2FD82.7060507@pdf.com>
References: <001cd4701191443SILJA@silja.absolutok.com>
	<3EA2FD82.7060507@pdf.com>
Message-ID: <x2wuhosyfb.fsf@biostat.ku.dk>

Spencer Graves <spencer.graves at pdf.com> writes:

> By default, arithmetic in R is vectorized, with a scalar being a
> vector of length 1.
> 
> Consider the following example:
> 
> prediction <- function(a, b)
> {
> 	a+b
> }
>  > prediction(1:3, 4:6)
> [1] 5 7 9
> 
> hope this helps, spencer graves

Not sure that was the question... If something else was meant, the
answer might be

lapply(v,prediction,b=5)

or

do.call("prediction",as.list(v))

Rephrasing the question might help...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From khealy at kieranhealy.org  Mon Apr 21 00:02:01 2003
From: khealy at kieranhealy.org (Kieran Healy)
Date: Sun, 20 Apr 2003 15:02:01 -0700
Subject: [R] R 1.7.0 fails to compile on OS X 10.2.5
Message-ID: <B6ED0580-737B-11D7-A9D0-000393A6C440@kieranhealy.org>

Hello -

I'm trying to compile R 1.7.0 on a PowerBook running OS X 10.2.5. I've 
compiled R (1.6.2) successfully before on this machine, under either 
10.2.3 or 10.2.4. My gcc is from the latest Apple Developer Tools 
release and the g77 is up-to-date via Fink. R passes ./configure just 
fine, with the following options:

R is now configured for powerpc-apple-darwin6.5

   Source directory:          .
   Installation directory:    /usr/local

   C compiler:                gcc  -g -O2
   C++ compiler:              g++  -g -O2
   Fortran compiler:          g77  -g -O2

   Interfaces supported:      X11, tcltk
   External libraries:
   Additional capabilities:   PNG, JPEG, bzip2, PCRE
   Options enabled:           R profiling

   Recommended packages:      yes

Compilation proceeds as normal for a while (though with occasional 
warnings), and then terminates with the following series of warnings 
and errors:

gcc -bundle -flat_namespace -undefined suppress -L/sw/lib 
-L/usr/local/lib -o R_X11.so  dataentry.lo devX11.lo rotated.lo 
rbitmap.lo  -lSM -lICE -L/usr/X11R6/lib -lX11  -ljpeg -lpng -lz  -lbz2 
-lz -ldl -lncurses -lm
ld: warning dynamic shared library: /usr/lib/libz.dylib not made a weak 
library in output with MACOSX_DEPLOYMENT_TARGET environment variable 
set to: 10.1
/Users/kjhealy/downloads/R-1.7.0/modules/R_X11.so is unchanged
making Rsock.d from Rsock.c
making internet.d from internet.c
making nanoftp.d from nanoftp.c
making nanohttp.d from nanohttp.c
making sock.d from sock.c
making sockconn.d from sockconn.c
gcc -no-cpp-precomp -I. -I../../../src/include -I../../../src/include 
-I/sw/include -I/usr/local/include -DHAVE_CONFIG_H  -fno-common  -g -O2 
-c Rsock.c -o Rsock.lo
Rsock.c: In function `R_SockConnect':
Rsock.c:380: warning: passing arg 5 of `getsockopt' from incompatible 
pointer type
gcc -no-cpp-precomp -I. -I../../../src/include -I../../../src/include 
-I/sw/include -I/usr/local/include -DHAVE_CONFIG_H  -fno-common  -g -O2 
-c internet.c -o internet.lo
gcc -no-cpp-precomp -I. -I../../../src/include -I../../../src/include 
-I/sw/include -I/usr/local/include -DHAVE_CONFIG_H  -fno-common  -g -O2 
-c nanoftp.c -o nanoftp.lo
nanoftp.c: In function `RxmlNanoFTPGetConnection':
nanoftp.c:1175: warning: passing arg 3 of `getsockname' from 
incompatible pointer type
nanoftp.c:1182: warning: passing arg 3 of `getsockname' from 
incompatible pointer type
gcc -no-cpp-precomp -I. -I../../../src/include -I../../../src/include 
-I/sw/include -I/usr/local/include -DHAVE_CONFIG_H  -fno-common  -g -O2 
-c nanohttp.c -o nanohttp.lo
nanohttp.c: In function `RxmlNanoHTTPConnectAttempt':
nanohttp.c:909: warning: passing arg 5 of `getsockopt' from 
incompatible pointer type
gcc -no-cpp-precomp -I. -I../../../src/include -I../../../src/include 
-I/sw/include -I/usr/local/include -DHAVE_CONFIG_H  -fno-common  -g -O2 
-c sock.c -o sock.lo
sock.c: In function `Sock_listen':
sock.c:189: warning: passing arg 3 of `accept' from incompatible 
pointer type
gcc -no-cpp-precomp -I. -I../../../src/include -I../../../src/include 
-I/sw/include -I/usr/local/include -DHAVE_CONFIG_H  -fno-common  -g -O2 
-c sockconn.c -o sockconn.lo
gcc -bundle -flat_namespace -undefined suppress -L/sw/lib 
-L/usr/local/lib -o internet.so  Rsock.lo internet.lo nanoftp.lo 
nanohttp.lo sock.lo sockconn.lo
making Lapack.d from Lapack.c
g77  -fno-common  -g -O2 -c dlapack0.f -o dlapack0.lo
g77  -fno-common  -g -O2 -c dlapack1.f -o dlapack1.lo
g77  -fno-common  -g -O2 -c dlapack2.f -o dlapack2.lo
g77  -fno-common  -g -O2 -c dlapack3.f -o dlapack3.lo
g77  -fno-common  -g -O2 -c cmplx.f -o cmplx.lo
g77  -fno-common  -g -O2 -c cmplxblas.f -o cmplxblas.lo
gcc -dynamiclib -install_name /usr/local/lib/R/bin/libRlapack.dylib 
-L/sw/lib -L/usr/local/lib -o libRlapack.dylib dlapack0.lo dlapack1.lo 
dlapack2.lo dlapack3.lo cmplx.lo  cmplxblas.lo  -L/sw/lib 
-L/usr/local/lib -L/sw/lib/gcc-lib/powerpc-apple-darwin6.2/3.1 
-L/sw/lib/gcc-lib/powerpc-apple-darwin6.2/3.1/../../.. -lfrtbegin -lg2c 
-lSystem
ld: common symbols not allowed with MH_DYLIB output format with the 
-multi_module option
/sw/lib/libg2c.a(err.o) definition of common _f__cblank (size 4)
/sw/lib/libg2c.a(fmt.o) definition of common _f__cnt (size 40)
/sw/lib/libg2c.a(fmt.o) definition of common f(char,  *) (size 4)
/sw/lib/libg2c.a(err.o) definition of common f(char, long *, short 
__restrict) (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__cursor (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__doed (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__doend (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__doned (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__dorevert (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__elist (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__fmtbuf (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__fmtlen (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__init (size 4)
/sw/lib/libg2c.a(fmt.o) definition of common _f__nonl (size 4)
/sw/lib/libg2c.a(fmt.o) definition of common _f__parenlvl (size 4)
/sw/lib/libg2c.a(fmt.o) definition of common f(char *) (size 4)
/sw/lib/libg2c.a(fmt.o) definition of common _f__ret (size 40)
/sw/lib/libg2c.a(fmt.o) definition of common _f__revloc (size 4)
/sw/lib/libg2c.a(fmt.o) definition of common f(long double,  *) (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__scale (size 4)
/sw/lib/libg2c.a(fmt.o) definition of common _f__workdone (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__units (size 4800)
/sw/lib/libg2c.a(err.o) definition of common f(char, float) (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__curunit (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__donewrec (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__external (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__formatted (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__hiwater (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__putn (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__reading (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__recpos (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__sequential (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__getn (size 4)
/sw/lib/libg2c.a(err.o) definition of common _f__icptr (size 4)
/sw/lib/libg2c.a(err.o) definition of common f(short, void, int, char) 
(size 4)
/usr/bin/libtool: internal link edit command failed
make[4]: *** [libRlapack.dylib] Error 1
make[3]: *** [R] Error 2
make[2]: *** [R] Error 1
make[1]: *** [R] Error 1
make: *** [R] Error 1


Any idea what I'm missing/doing wrong here?

--
Kieran Healy, http://www.u.arizona.edu/~kjhealy
Asst Professor, Sociology Dept, University of Arizona.


From tlumley at u.washington.edu  Mon Apr 21 00:26:10 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 20 Apr 2003 15:26:10 -0700 (PDT)
Subject: [R] survreg penalized likelihood?  
In-Reply-To: <3EA1FAA8.4010201@pdf.com>
Message-ID: <Pine.A41.4.44.0304201500470.7362-100000@homer41.u.washington.edu>

On Sat, 19 Apr 2003, Spencer Graves wrote:

> 	  What objective function is maximized by survreg with the default
> Weibull model?  I'm getting finite parameters in a case that has the
> likelihood maximzed at Infinite, so it can't be a simple maximum
> likelihood.

The objective function *is* the loglikelihood.

> Consider the following:
> #############################
>  > set.seed(3)
>  > Stress <- rep(1:3, each=3)
>  > ch.life <- exp(9-3*Stress)
>  > simLife <- rexp(9, rate=1/ch.life)
>  > Data <- data.frame(Stress=factor(Stress),
> +  Time=pmin(simLife, 50), dead = (simLife<=50))
>  > Data[1:3,]
>    Stress Time  dead
> 1      1   50 FALSE
> 2      1   50 FALSE
> 3      1   50 FALSE
> # All three observations at Stress=1 are censored.
>  > Fit <- survreg(Surv(Time, dead)~Stress-1, data=Data)
>  > Fit
> Call:
> survreg(formula = Surv(Time, dead) ~ Stress - 1, data = Data)
>
> Coefficients:
>     Stress1    Stress2    Stress3
> 41.3724178  2.2819204 -0.5281005
>
> Scale= 0.2577886
>
> Loglik(model)= -6.6   Loglik(intercept only)= -22.1
> 	Chisq= 30.88 on 2 degrees of freedom, p= 2e-07
> n= 9
> # Even though 100% of observations at Stress=1 are censored,
> # I still get a finite estimate for log(characteristics life).
>


I suppose technically 41.3 is a finite estimate of log(life), but since
your data are censored at 50, a life expectancy of nearly 10^18 isn't
terribly finite.  The likelihood at this value is very very very close to
the likelihood at the true mle, and that's all a numerical optimisation
technique can really be expected to give you (and all that statistical
theory, frequentist or Bayesian, demands).

It's quite difficult to come up with a reliable test for ridges in the
loglikelihood -- coxph() tries, but gives too many false positives.

Incidentally, if you relax the assumption that the scale parameter is the
same for each Stress you end up with much larger finite predictions for
Stress=1, as the scale parameter ends up around 10^15 in that stratum.

	-thomas


From tom.kennedy at bigpond.com  Mon Apr 21 01:32:08 2003
From: tom.kennedy at bigpond.com (Tom Kennedy)
Date: Mon, 21 Apr 2003 09:32:08 +1000
Subject: [R] R 1.7.0 fails to compile on OS X 10.2.5
Message-ID: <4D94B468-7388-11D7-8F39-000393B552A2@bigpond.com>

Had the same problem. The LAPACK library will not compile with the gcc  
on macosx.

Jan de Leeuw helped with this configuration:

./configure  
--with-tcl-config=/Library/Frameworks/Tcl.framework/tclConfig.sh   
--with-tk-config=/Library/Frameworks/Tk.framework/tkConfig.sh   
--enable-R-shlib --with-x --with-blas='-framework vecLib'   
--with-lapack TCLTK_LIBS='-framework Tcl -framework Tk'  
TCLTK_CPPFLAGS='-I/Library/Frameworks/Tcl.Framework/Headers   
-I/Library/Frameworks/Tk.Framework/Headers'

This uses the vecLib library in macosx instead of LAPACK.

PS. If you don't have tcl/tk aqua frameworks installed, delete these  
sections in the config.

./configure  --enable-R-shlib --with-x --with-blas='-framework vecLib'   
--with-lapack

I presume you have an X11 installed.

Check out  
https://www.stat.math.ethz.ch/pipermail/r-sig-mac/2003-April/ 
thread.html which is a macos
specific list for R which Jan de Leeuw moderates.

Tom


From spencer.graves at pdf.com  Mon Apr 21 01:33:44 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 20 Apr 2003 16:33:44 -0700
Subject: [R] survreg penalized likelihood?
References: <Pine.A41.4.44.0304201500470.7362-100000@homer41.u.washington.edu>
Message-ID: <3EA32E58.20709@pdf.com>

Thanks very much.

After I distributed that example, I noticed that the documtation for the 
survival package says, "Survival analysis, including penalised 
likelihood", so I thought that some penalty function might be invoked 
under certain circumstances.

Thanks again,
Spencer Graves

Thomas Lumley wrote:
> On Sat, 19 Apr 2003, Spencer Graves wrote:
> 
> 
>>	  What objective function is maximized by survreg with the default
>>Weibull model?  I'm getting finite parameters in a case that has the
>>likelihood maximzed at Infinite, so it can't be a simple maximum
>>likelihood.
> 
> 
> The objective function *is* the loglikelihood.
> 
> 
>>Consider the following:
>>#############################
>> > set.seed(3)
>> > Stress <- rep(1:3, each=3)
>> > ch.life <- exp(9-3*Stress)
>> > simLife <- rexp(9, rate=1/ch.life)
>> > Data <- data.frame(Stress=factor(Stress),
>>+  Time=pmin(simLife, 50), dead = (simLife<=50))
>> > Data[1:3,]
>>   Stress Time  dead
>>1      1   50 FALSE
>>2      1   50 FALSE
>>3      1   50 FALSE
>># All three observations at Stress=1 are censored.
>> > Fit <- survreg(Surv(Time, dead)~Stress-1, data=Data)
>> > Fit
>>Call:
>>survreg(formula = Surv(Time, dead) ~ Stress - 1, data = Data)
>>
>>Coefficients:
>>    Stress1    Stress2    Stress3
>>41.3724178  2.2819204 -0.5281005
>>
>>Scale= 0.2577886
>>
>>Loglik(model)= -6.6   Loglik(intercept only)= -22.1
>>	Chisq= 30.88 on 2 degrees of freedom, p= 2e-07
>>n= 9
>># Even though 100% of observations at Stress=1 are censored,
>># I still get a finite estimate for log(characteristics life).
>>
> 
> 
> 
> I suppose technically 41.3 is a finite estimate of log(life), but since
> your data are censored at 50, a life expectancy of nearly 10^18 isn't
> terribly finite.  The likelihood at this value is very very very close to
> the likelihood at the true mle, and that's all a numerical optimisation
> technique can really be expected to give you (and all that statistical
> theory, frequentist or Bayesian, demands).
> 
> It's quite difficult to come up with a reliable test for ridges in the
> loglikelihood -- coxph() tries, but gives too many false positives.
> 
> Incidentally, if you relax the assumption that the scale parameter is the
> same for each Stress you end up with much larger finite predictions for
> Stress=1, as the scale parameter ends up around 10^15 in that stratum.
> 
> 	-thomas
> 
>


From Phguardiol at aol.com  Mon Apr 21 01:42:25 2003
From: Phguardiol at aol.com (Phguardiol@aol.com)
Date: Sun, 20 Apr 2003 19:42:25 EDT
Subject: [R] Win binaries
Message-ID: <3c.2e6d7bfd.2bd48a61@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030420/b2be6061/attachment.pl

From bates at stat.wisc.edu  Mon Apr 21 02:34:33 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 20 Apr 2003 19:34:33 -0500
Subject: [R] Win binaries
In-Reply-To: <3c.2e6d7bfd.2bd48a61@aol.com>
References: <3c.2e6d7bfd.2bd48a61@aol.com>
Message-ID: <6rptng1yee.fsf@bates4.stat.wisc.edu>

Phguardiol at aol.com writes:

> I m trying to down load the binary for Win of R1.7 (called R 0.8... ?) from 
> few mirrors but all are down... Is it normal ?

I just noticed that problem on the cran.us.r-project.org site and will
correct it there.  It is just the link and the text on the index.html
page that is wrong.  The binary is actually there.

You can download the binary as

 http://cran.us.r-project.org/bin/windows/base/rw1070.exe


From mschwartz at medanalytics.com  Mon Apr 21 02:35:47 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Sun, 20 Apr 2003 19:35:47 -0500
Subject: [R] Win binaries
In-Reply-To: <3c.2e6d7bfd.2bd48a61@aol.com>
References: <3c.2e6d7bfd.2bd48a61@aol.com>
Message-ID: <3EA33CE3.7050003@medanalytics.com>

Phguardiol at aol.com wrote:
> Hi,
> I m trying to down load the binary for Win of R1.7 (called R 0.8... ?) from 
> few mirrors but all are down... Is it normal ?
> Regards
> Philippe


Try using this URL as it looks like the links on CRAN are bad:

http://cran.r-project.org/bin/windows/base/rw1070.exe

As an alternative, you can also use this FTP based target:

ftp://cran.r-project.org/pub/R/bin/windows/base

which will provide you with a list of the Windows files.

The file that you want is: rw1070.exe

I have cc'd Duncan Murdoch on this as an FYI.  I thought that I saw 
something on this in the past day or two but cannot locate the post.

HTH,

Marc Schwartz


From dmurdoch at pair.com  Mon Apr 21 03:13:10 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 20 Apr 2003 21:13:10 -0400
Subject: [R] Win binaries
In-Reply-To: <3EA33CE3.7050003@medanalytics.com>
References: <3c.2e6d7bfd.2bd48a61@aol.com> <3EA33CE3.7050003@medanalytics.com>
Message-ID: <j7h6av8chfqggfapo4n0hh6ffcrfp040rl@4ax.com>

On Sun, 20 Apr 2003 19:35:47 -0500, you wrote:

>Try using this URL as it looks like the links on CRAN are bad:
>
>http://cran.r-project.org/bin/windows/base/rw1070.exe

Thanks Marc.  Yes, that link works, the ones that are currently on
CRAN don't.  I'm not sure how I those rw08 links got there, but it
happened when I added the links to the FAQs to the page.

I've fixed the base copy of the web page, but it takes a while to show
up on the public web site.

Duncan Murdoch


From langensk at fas.harvard.edu  Mon Apr 21 04:15:04 2003
From: langensk at fas.harvard.edu (langensk@fas.harvard.edu)
Date: Sun, 20 Apr 2003 22:15:04 -0400
Subject: [R] To create a Panel and run a Pooled OLS
Message-ID: <1050891304.3ea354281c3e2@webmail.fas.harvard.edu>



Dear all,

I have tried to merge two cross sections (crossA and crossB) as follows, both 
crossA and crossB include the same variables, e.g., ID,y,x1,x2:

Panel <- merge(crossA,crossB,by="ID")

I have, thereafter, tried to run the following pooled OLS:

OLS <- lm(Panel$y~Panel$x1+Panel$x2)

and have received the following error message "Error in model.frame(formula, 
rownames, variables, varnames, extras, extranames,  : invalid variable type"

I would be very grateful for help. At the moment, I believe that I have tried 
everything.

Thanks in advance,
Sophie


From spencer.graves at pdf.com  Mon Apr 21 04:46:15 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 20 Apr 2003 19:46:15 -0700
Subject: [R] To create a Panel and run a Pooled OLS
References: <1050891304.3ea354281c3e2@webmail.fas.harvard.edu>
Message-ID: <3EA35B77.6050200@pdf.com>

Have you tried the following:

	OLS <- lm(Panel$y~Panel$x1+Panel$x2, data=Panel)

If yes, could you replicate the error with a small data set that you 
send with your help request?  It can make it easier for others to 
diagnose.

Hope this helps. spencer graves

langensk at fas.harvard.edu wrote:
> 
> Dear all,
> 
> I have tried to merge two cross sections (crossA and crossB) as follows, both 
> crossA and crossB include the same variables, e.g., ID,y,x1,x2:
> 
> Panel <- merge(crossA,crossB,by="ID")
> 
> I have, thereafter, tried to run the following pooled OLS:
> 
> OLS <- lm(Panel$y~Panel$x1+Panel$x2)
> 
> and have received the following error message "Error in model.frame(formula, 
> rownames, variables, varnames, extras, extranames,  : invalid variable type"
> 
> I would be very grateful for help. At the moment, I believe that I have tried 
> everything.
> 
> Thanks in advance,
> Sophie
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Mon Apr 21 04:50:35 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 20 Apr 2003 19:50:35 -0700
Subject: [R] To create a Panel and run a Pooled OLS
References: <1050891304.3ea354281c3e2@webmail.fas.harvard.edu>
Message-ID: <3EA35C7B.3010709@pdf.com>

I just see a difference between what I wrote and what I use.  Have you 
tried the following:

	OLS <- lm(y~x1+x2, data=Panel)

spencer graves
###################
If yes, could you replicate the error with a small data set that you
send with your help request?  It can make it easier for others to
diagnose.

Hope this helps. spencer graves

langensk at fas.harvard.edu wrote:
 >
 > Dear all,
 >
 > I have tried to merge two cross sections (crossA and crossB) as 
follows, both
 > crossA and crossB include the same variables, e.g., ID,y,x1,x2:
 >
 > Panel <- merge(crossA,crossB,by="ID")
 >
 > I have, thereafter, tried to run the following pooled OLS:
 >
 > OLS <- lm(Panel$y~Panel$x1+Panel$x2)
 >
 > and have received the following error message "Error in 
model.frame(formula,
 > rownames, variables, varnames, extras, extranames,  : invalid 
variable type"
 >
 > I would be very grateful for help. At the moment, I believe that I 
have tried
 > everything.
 >
 > Thanks in advance,
 > Sophie
 >
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From langensk at fas.harvard.edu  Mon Apr 21 05:02:06 2003
From: langensk at fas.harvard.edu (Sophie Langenskiold)
Date: Mon, 21 Apr 2003 05:02:06 +0200
Subject: [R] To create a Panel and run a Pooled OLS
In-Reply-To: <3EA35C7B.3010709@pdf.com>
Message-ID: <000b01c307b2$66dbcd80$b029f78c@emp.hhs.se>

I appreciate your help a lot. Unfortunately, none of your
recommendations work. I have written a small program to illustrate my
problems. I hope there is a solution...

Cross1 <- data.frame(i=c(1,2,3),Y=c(3,2,2),X1=c(2,3,4))
Cross2 <- data.frame(i=c(1,2,3),Y=c(2,3,1),X1=c(5,6,7))
Panel <- merge(Cross1,Cross2,by="i")
OLS <- lm(Panel$Y~Panel$X1)

Thanks again for your help,
Sophie

-----Original Message-----
From: Spencer Graves [mailto:spencer.graves at PDF.COM] 
Sent: den 21 april 2003 04:51
To: langensk at fas.harvard.edu
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] To create a Panel and run a Pooled OLS

I just see a difference between what I wrote and what I use.  Have you 
tried the following:

	OLS <- lm(y~x1+x2, data=Panel)

spencer graves
###################
If yes, could you replicate the error with a small data set that you
send with your help request?  It can make it easier for others to
diagnose.

Hope this helps. spencer graves

langensk at fas.harvard.edu wrote:
 >
 > Dear all,
 >
 > I have tried to merge two cross sections (crossA and crossB) as 
follows, both
 > crossA and crossB include the same variables, e.g., ID,y,x1,x2:
 >
 > Panel <- merge(crossA,crossB,by="ID")
 >
 > I have, thereafter, tried to run the following pooled OLS:
 >
 > OLS <- lm(Panel$y~Panel$x1+Panel$x2)
 >
 > and have received the following error message "Error in 
model.frame(formula,
 > rownames, variables, varnames, extras, extranames,  : invalid 
variable type"
 >
 > I would be very grateful for help. At the moment, I believe that I 
have tried
 > everything.
 >
 > Thanks in advance,
 > Sophie
 >
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tlumley at u.washington.edu  Mon Apr 21 05:23:38 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 20 Apr 2003 20:23:38 -0700 (PDT)
Subject: [R] survreg penalized likelihood?
In-Reply-To: <3EA32E58.20709@pdf.com>
Message-ID: <Pine.A41.4.44.0304202023040.74150-100000@homer06.u.washington.edu>

On Sun, 20 Apr 2003, Spencer Graves wrote:

> Thanks very much.
>
> After I distributed that example, I noticed that the documtation for the
> survival package says, "Survival analysis, including penalised
> likelihood", so I thought that some penalty function might be invoked
> under certain circumstances.
>

You need to ask for a penalty function (see eg frailty(), pspline(),
ridge())

	-thomas


From tlumley at u.washington.edu  Mon Apr 21 05:31:32 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 20 Apr 2003 20:31:32 -0700 (PDT)
Subject: [R] To create a Panel and run a Pooled OLS
In-Reply-To: <000b01c307b2$66dbcd80$b029f78c@emp.hhs.se>
Message-ID: <Pine.A41.4.44.0304202027260.74150-100000@homer06.u.washington.edu>

On Mon, 21 Apr 2003, Sophie Langenskiold wrote:

> I appreciate your help a lot. Unfortunately, none of your
> recommendations work. I have written a small program to illustrate my
> problems. I hope there is a solution...
>
> Cross1 <- data.frame(i=c(1,2,3),Y=c(3,2,2),X1=c(2,3,4))
> Cross2 <- data.frame(i=c(1,2,3),Y=c(2,3,1),X1=c(5,6,7))
> Panel <- merge(Cross1,Cross2,by="i")
> OLS <- lm(Panel$Y~Panel$X1)
>

I think your problem is with the merge() statement. The Panel dataframe
looks like
> Panel
  i Y.x X1.x Y.y X1.y
1 1   3    2   2    5
2 2   2    3   3    6
3 3   2    4   1    7

so it doesn't have X1 or Y variables.

The solution depends on what you want, but my guess is that you need
  Panel<-rbind(Cross1,Cross2)
  lm(Y~X1,data=Panel)

Or perhaps
   Panel<-rbind(cbind(Cross1,time=1),cbind(Cross2,time=2))
   lm(Y~X1,data=Panel)


	-thomas


From jfox at mcmaster.ca  Mon Apr 21 05:37:47 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 20 Apr 2003 23:37:47 -0400
Subject: [R] To create a Panel and run a Pooled OLS
In-Reply-To: <000b01c307b2$66dbcd80$b029f78c@emp.hhs.se>
References: <3EA35C7B.3010709@pdf.com>
Message-ID: <5.1.0.14.2.20030420233040.01e2c1a0@mcmail.cis.mcmaster.ca>

Dear Sophie,

I think that the real question here is what you're trying to do; if you 
simply want to stack one cross section on top of the other, the simplest 
way to do that is with cbind.

To understand why your merge failed, just look at the merged data frame:

     > Cross1 <- data.frame(i=c(1,2,3),Y=c(3,2,2),X1=c(2,3,4))
     > Cross2 <- data.frame(i=c(1,2,3),Y=c(2,3,1),X1=c(5,6,7))
     > Panel <- merge(Cross1,Cross2,by="i")
     > Panel
     i Y.x X1.x Y.y X1.y
     1 1   3    2   2    5
     2 2   2    3   3    6
     3 3   2    4   1    7

On the other hand, here's what you get with rbind:

     > Panel <- rbind(Cross1, Cross2)
     > Panel
     i Y X1
     1  1 3  2
     2  2 2  3
     3  3 2  4
     11 1 2  5
     22 2 3  6
     33 3 1  7

Fitting a regression to this data frame works fine; either  OLS <- 
lm(Panel$Y ~ Panel$X1)  or  OLS <- lm(Y ~ X1, data=Panel)  will do the 
trick, although the latter is clearer, I think.

I hope that this helps,
  John

At 05:02 AM 4/21/2003 +0200, Sophie Langenskiold wrote:
>I appreciate your help a lot. Unfortunately, none of your
>recommendations work. I have written a small program to illustrate my
>problems. I hope there is a solution...
>
>Cross1 <- data.frame(i=c(1,2,3),Y=c(3,2,2),X1=c(2,3,4))
>Cross2 <- data.frame(i=c(1,2,3),Y=c(2,3,1),X1=c(5,6,7))
>Panel <- merge(Cross1,Cross2,by="i")
>OLS <- lm(Panel$Y~Panel$X1)
>
>Thanks again for your help,
>Sophie
>
>-----Original Message-----
>From: Spencer Graves [mailto:spencer.graves at PDF.COM]
>Sent: den 21 april 2003 04:51
>To: langensk at fas.harvard.edu
>Cc: r-help at stat.math.ethz.ch
>Subject: Re: [R] To create a Panel and run a Pooled OLS
>
>I just see a difference between what I wrote and what I use.  Have you
>tried the following:
>
>         OLS <- lm(y~x1+x2, data=Panel)
>
>spencer graves
>###################
>If yes, could you replicate the error with a small data set that you
>send with your help request?  It can make it easier for others to
>diagnose.
>
>Hope this helps. spencer graves
>
>langensk at fas.harvard.edu wrote:
>  >
>  > Dear all,
>  >
>  > I have tried to merge two cross sections (crossA and crossB) as
>follows, both
>  > crossA and crossB include the same variables, e.g., ID,y,x1,x2:
>  >
>  > Panel <- merge(crossA,crossB,by="ID")
>  >
>  > I have, thereafter, tried to run the following pooled OLS:
>  >
>  > OLS <- lm(Panel$y~Panel$x1+Panel$x2)
>  >
>  > and have received the following error message "Error in
>model.frame(formula,
>  > rownames, variables, varnames, extras, extranames,  : invalid
>variable type"
>  >
>  > I would be very grateful for help. At the moment, I believe that I
>have tried
>  > everything.
>  >
>  > Thanks in advance,
>  > Sophie
>  >
>  > ______________________________________________
>  > R-help at stat.math.ethz.ch mailing list
>  > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox


From zoey at excuria.com  Mon Apr 21 06:08:50 2003
From: zoey at excuria.com (Zoey)
Date: Mon, 21 Apr 2003 04:08:50 -0000
Subject: [R] Inkjet & Laser Toner Cartridges ~ Save upto 89%
Message-ID: <200304210408.h3L48hUZ004906@hypatia.math.ethz.ch>

  
Save up to 89% on Inkjet & Laser Toner Cartridges
Quality Products w/ 100% Satisfaction Guarantee
Easy, Fast, Affordable Shipping Worldwide
Plenty of Payment Options to Meet YOUR Needs!
  
Visit us on the web at http://excuria.com/inkstore/
  
  
For instruction on how to be permanently remove from
this distribution system go to http://excuria.com/remove/


From zhuw at mail.smu.edu  Mon Apr 21 06:52:00 2003
From: zhuw at mail.smu.edu (Wang, Zhu)
Date: Sun, 20 Apr 2003 23:52:00 -0500
Subject: [R] nonlinear equation solver?
Message-ID: <0FBE46098704A242B0DC8FEC4169F9978140EC@s31xs3.systems.smu.edu>

Dear R-Help,
 
I am trying to use R to solve a nonlinear equation many times for different values. I am looking for a mathematical nonlinear equation solution which may not have a closed solution form. For example, I have equation:
2 = (t^2)/log(t)
What is t?
 
I am wondering how to solve it in R.
Many thanks,
 
Zhu Wang
 
Statistical Science Department
SMU.


From maj at stats.waikato.ac.nz  Mon Apr 21 07:13:30 2003
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Mon, 21 Apr 2003 17:13:30 +1200
Subject: [R] nonlinear equation solver?
In-Reply-To: <0FBE46098704A242B0DC8FEC4169F9978140EC@s31xs3.systems.smu.edu>
References: <0FBE46098704A242B0DC8FEC4169F9978140EC@s31xs3.systems.smu.edu>
Message-ID: <3EA37DFA.2040408@stats.waikato.ac.nz>

For this equation you are out of luck as log(z) < z for all positive z's 
(such as t^2). More generally you should consult a numerical analysis 
textbook for advice on the solution of nonlinear equations. There you 
will read about many algorithms in common use by statisticians.

Murray Jorgensen

Wang, Zhu wrote:
> Dear R-Help,
>  
> I am trying to use R to solve a nonlinear equation many times for different values. I am looking for a mathematical nonlinear equation solution which may not have a closed solution form. For example, I have equation:
> 2 = (t^2)/log(t)
> What is t?
>  
> I am wondering how to solve it in R.
> Many thanks,
>  
> Zhu Wang
>  
> Statistical Science Department
> SMU.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    +64 7 849 6486 home    Mobile 021 1395 862


From Karen.Chancellor at asu.edu  Mon Apr 21 08:56:35 2003
From: Karen.Chancellor at asu.edu (Karen.Chancellor@asu.edu)
Date: Sun, 20 Apr 2003 23:56:35 -0700 (MST)
Subject: [R] randomForest crash?
Message-ID: <Pine.GSO.4.21.0304202345210.27701-100000@general3.asu.edu>

I am attempting to use randomForests to look for interesting genes in
microarray data with 216genes, 2 classes and 52 samples. My data.frame 
is 52x217 with the last column, V217 being the class(1 or 2).

When I try
        lung.rf <- randomForest(V217 ~ ., data=tlSA216cda, importance=
                TRUE, proximity = TRUE)
the GUI crashes. 

I am running R-1.6.2 under windo$e98, and most recent version of randomForest.
Your ideas appreciated.
Karen


.-  --.  ....-  -.-.  -.-.


From magnolia at absolutok.net  Mon Apr 21 10:26:16 2003
From: magnolia at absolutok.net (ANA KOZOMARA)
Date: Mon, 21 Apr 2003 10:26:16 +0200
Subject: [R] how to use apply with a function created by ourselfs...?
Message-ID: <001c51626081543SILJA@silja.absolutok.com>


..hey thanks for the answer, both of you...
but :-(, I don't seem to have an answer to my problem...
I tried with what u suggested, but it doesn't work yet...
so I will precise it...
I have a data frame...
and I would like to apply the function "prediction" which acts on two
vectors
prediction(linear,ind),
to my data frame,I mean to all the rows of my data frame...
something like a function "Map" in Mathematica...
Shortly, I want to apply function "prediction" to a list of arguments, not
to a single argument...
I hope now it is more clear...
Thanks for the answers once more,
best regards,
ana
______________________________________________________________________
Original poruka
Od: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
Za: Spencer Graves <spencer.graves at pdf.com>
Tema: Re: [R] how to use apply with a function created by ourselfs...?
Primljena: 20 Apr 2003 22:31:52

Spencer Graves <spencer.graves at pdf.com> writes:

> By default, arithmetic in R is vectorized, with a scalar being a
> vector of length 1.
>
> Consider the following example:
>
> prediction <- function(a, b)
> {
> a+b
> }
>  > prediction(1:3, 4:6)
> [1] 5 7 9
>
> hope this helps, spencer graves

Not sure that was the question... If something else was meant, the
answer might be

lapply(v,prediction,b=5)

or

do.call("prediction",as.list(v))

Rephrasing the question might help...

--
   O__  ---- Peter Dalgaard             Blegdamsvej 3
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Mon Apr 21 11:27:48 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 21 Apr 2003 11:27:48 +0200
Subject: [R] how to use apply with a function created by ourselfs...?
In-Reply-To: <001c51626081543SILJA@silja.absolutok.com>
References: <001c51626081543SILJA@silja.absolutok.com>
Message-ID: <x2of30ryi3.fsf@biostat.ku.dk>

"ANA KOZOMARA" <magnolia at absolutok.net> writes:

> ..hey thanks for the answer, both of you...
> but :-(, I don't seem to have an answer to my problem...
> I tried with what u suggested, but it doesn't work yet...
> so I will precise it...
> I have a data frame...
> and I would like to apply the function "prediction" which acts on two
> vectors
> prediction(linear,ind),
> to my data frame,I mean to all the rows of my data frame...
> something like a function "Map" in Mathematica...
> Shortly, I want to apply function "prediction" to a list of arguments, not
> to a single argument...
> I hope now it is more clear...
> Thanks for the answers once more,
> best regards,
> ana

It depends on your prediction function. The best thing is to arrange
that it vectorizes over its arguments, as Spencer Graves suggested.
Then it's just 

prediction(df[,1],df[,2])

or, if you want something that works for more than two rows,

do.call("prediction", df) 

if your prediction() does not vectorize (i.e. a and b has to be
scalars), you can do two things:

pr.row <- function(row) do.call("prediction",row)
apply(df, 1, pr.row)

or create a vectorized prediction(), as in 

pr.vec <- function(a,b)
   sapply(seq(along=a),function(i)prediction(a[i],b[i]))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From magnolia at absolutok.net  Mon Apr 21 11:43:19 2003
From: magnolia at absolutok.net (ANA KOZOMARA)
Date: Mon, 21 Apr 2003 11:43:19 +0200
Subject: [R] how to use apply with a function created by ourselfs...?
Message-ID: <000e92043091543SILJA@silja.absolutok.com>

hey thanks a lot...
finally I decided to write my own fonction which will do it...
I was completely lost with rbind, mode="list"...
I find slightely weird the R-kind-of-thinking...:)))
Anyway, i'm trying to acomplish my project in R and not c spirit,
so i'll try what u suggests,
..hey, thanks a lot again...

______________________________________________________________________
Original poruka
Od: Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk>
Za: ANA KOZOMARA <magnolia at absolutok.net>
Tema: Re: [R] how to use apply with a function created by ourselfs...?
Primljena: 21 Apr 2003 11:27:48

"ANA KOZOMARA" <magnolia at absolutok.net> writes:

> ..hey thanks for the answer, both of you...
> but :-(, I don't seem to have an answer to my problem...
> I tried with what u suggested, but it doesn't work yet...
> so I will precise it...
> I have a data frame...
> and I would like to apply the function "prediction" which acts on two
> vectors
> prediction(linear,ind),
> to my data frame,I mean to all the rows of my data frame...
> something like a function "Map" in Mathematica...
> Shortly, I want to apply function "prediction" to a list of arguments,
not
> to a single argument...
> I hope now it is more clear...
> Thanks for the answers once more,
> best regards,
> ana

It depends on your prediction function. The best thing is to arrange
that it vectorizes over its arguments, as Spencer Graves suggested.
Then it's just

prediction(df[,1],df[,2])

or, if you want something that works for more than two rows,

do.call("prediction", df)

if your prediction() does not vectorize (i.e. a and b has to be
scalars), you can do two things:

pr.row <- function(row) do.call("prediction",row)
apply(df, 1, pr.row)

or create a vectorized prediction(), as in

pr.vec <- function(a,b)
   sapply(seq(along=a),function(i)prediction(a[i],b[i]))

--
   O__  ---- Peter Dalgaard             Blegdamsvej 3
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From lm.silva at sapo.pt  Mon Apr 21 12:03:05 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Mon, 21 Apr 2003 11:03:05 +0100 (WEST)
Subject: [R] loop
In-Reply-To: <3EA2BCB3.3040301@pdf.com>
References: <1050847073.3ea2a76195a7c@webmail.sapo.pt>
	<3EA2BCB3.3040301@pdf.com>
Message-ID: <1050919385.3ea3c1d9231cd@webmail.sapo.pt>

I tried the tips from Sundar but I  still have problems. I want 
both values and vectors, and the latter will be used to project 
my original data. The problem is that with those command lines 
I can't get them as a matrix and when I try as.matrix it 
doesn't work. With only vectors

> b<-sapply(my.list, function(x) eigen(x)$vectors)
> attributes(b)
$dim
[1] 65536    11

$dimnames
$dimnames[[1]]
NULL

$dimnames[[2]]
 
[1] "0"   "0.1" "0.2" "0.3" "0.4" "0.5" "0.6" "0.7" "0.8" "0.9" 
"1"  


> b[1]
[1] 0.02533057+0i

thanks
luis

} 
} 
} Luis Silva wrote:
} > Dear helpers
} > 
} > I have this problem. I want to make a linear
} combination a*A+(1-
} > a)*B where A and B are matrices. I want that a be
} incremented 
} > from 0 to 1 by 0.1 so I made a loop with for. The
} problem is 
} > that I want to keep the result in an object or list
} or 
} > something like that and then apply eigen
} decomposition to all 
} > of the resulting matrices
} > 
} > sapply(my.list,eigen)
} > 
} > the problem is that I don't know how to build that
} list in the 
} > loop. I tried several things but it doesn't work
} (in Matlab i 
} > can do it)
} > 
} 
} a <- seq(0, 1, 0.1)
} my.list <- lapply(a, function(a, A, B) a*A + (a-1)*B,
} A=A, B=B)
} names(my.list) <- as.character(a)
} sapply(my.list, function(x) eigen(x)$value)
} 
} Regards,
} Sundar
} 
} 

--


http://adsl.sapo.pt


From ernesto at ipimar.pt  Mon Apr 21 12:49:26 2003
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: 21 Apr 2003 11:49:26 +0100
Subject: [R] loop
In-Reply-To: <1050919385.3ea3c1d9231cd@webmail.sapo.pt>
References: <1050847073.3ea2a76195a7c@webmail.sapo.pt>
	<1050919385.3ea3c1d9231cd@webmail.sapo.pt>
Message-ID: <1050922166.4547.17.camel@gandalf.ipimar.pt>

Ol?

Podes criar a lista antes do loop (ali?s ? aconselh?vel que o fa?as para
poupar tempo de computa??o) e "apontas" os resultados do loop para os
elementos da lista.

lst <- list()
vec <- seq(0,1,0.1)
length(lst)<-length(vec)
for(i in 1:length(vec)){

...

lst[[i]] <- ...

}

Espero que ajude

EJ


PS: The answer is in portuguese.

On Mon, 2003-04-21 at 11:03, Luis Silva wrote:
> I tried the tips from Sundar but I  still have problems. I want 
> both values and vectors, and the latter will be used to project 
> my original data. The problem is that with those command lines 
> I can't get them as a matrix and when I try as.matrix it 
> doesn't work. With only vectors
> 
> > b<-sapply(my.list, function(x) eigen(x)$vectors)
> > attributes(b)
> $dim
> [1] 65536    11
> 
> $dimnames
> $dimnames[[1]]
> NULL
> 
> $dimnames[[2]]
>  
> [1] "0"   "0.1" "0.2" "0.3" "0.4" "0.5" "0.6" "0.7" "0.8" "0.9" 
> "1"  
> 
> 
> > b[1]
> [1] 0.02533057+0i
> 
> thanks
> luis
> 
> } 
> } 
> } Luis Silva wrote:
> } > Dear helpers
> } > 
> } > I have this problem. I want to make a linear
> } combination a*A+(1-
> } > a)*B where A and B are matrices. I want that a be
> } incremented 
> } > from 0 to 1 by 0.1 so I made a loop with for. The
> } problem is 
> } > that I want to keep the result in an object or list
> } or 
> } > something like that and then apply eigen
> } decomposition to all 
> } > of the resulting matrices
> } > 
> } > sapply(my.list,eigen)
> } > 
> } > the problem is that I don't know how to build that
> } list in the 
> } > loop. I tried several things but it doesn't work
> } (in Matlab i 
> } > can do it)
> } > 
> } 
> } a <- seq(0, 1, 0.1)
> } my.list <- lapply(a, function(a, A, B) a*A + (a-1)*B,
> } A=A, B=B)
> } names(my.list) <- as.character(a)
> } sapply(my.list, function(x) eigen(x)$value)
> } 
> } Regards,
> } Sundar
> } 
> } 
> 
> --
> 
> 
> http://adsl.sapo.pt
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From fatman at aracnet.com  Mon Apr 21 08:01:06 2003
From: fatman at aracnet.com (John Jaynes)
Date: Sun, 20 Apr 2003 23:01:06 -0700
Subject: [R] Generating axes with "Sun Apr 20 22:45:27 PDT 2003" time
	coordinates.
Message-ID: <200304202301.06368.fatman@aracnet.com>

Good Morning!

My apologies for what may be considered an infantile question: I have data 
that I would like to plot, positive integers for the y-axis, and time 
coordinates of the "Sun Apr 20 22:45:27 PDT 2003" format for the x-axis.
I have tried:

x1 <- 1050352610
x2 <- 1050352999
x3 <- 1050858319
class(x1) <- "POSIXct"
class(x2) <- "POSIXct"
class(x3) <- "POSIXct"
X <- c(x1, x2, x3)
...
...
plot(X, Y, type = "l")

I end up with "Mon", "Tues", "Wed", ... x-axis coordinates, when I need 
"2003-04-14 13:36:50 PDT",  "2003-04-14 13:43:19 PDT"
and  "2003-04-20 10:05:19 PDT" x-axis coordinates. I adjusted the data to be 
one second apart and ended up with integer "19", "20", ... x-axis 
coordinates. What do I need to do to accomplish this? Any help will be 
greatly appreciated, as I have looked at the help pages, and the web, to no 
avail. I would also be more than happy to purchase a book that contains 
information to this level of detail if that is available.

Thank You,

John Jaynes


From lm.silva at sapo.pt  Mon Apr 21 14:13:40 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Mon, 21 Apr 2003 13:13:40 +0100 (WEST)
Subject: [R] loop
In-Reply-To: <1050922166.4547.17.camel@gandalf.ipimar.pt>
References: <1050847073.3ea2a76195a7c@webmail.sapo.pt>
	<3EA2BCB3.3040301@pdf.com>  <1050919385.3ea3c1d9231cd@webmail.sapo.pt>
	<1050922166.4547.17.camel@gandalf.ipimar.pt>
Message-ID: <1050927220.3ea3e074d37f9@webmail.sapo.pt>

Ol? (em portugu?s finalmente)

J? estive a experimentar com um pequeno exemplo e parece que 
funciona. Vou agora aplicar ao que estou a fazer e depois dou 
not?cias. O uso de sapply e variantes era para evitar o loop, 
mas quando quero usar os resultados ? que surgem os problemas.

obrigado e boa pascoa
luis

} Ol?
} 
} Podes criar a lista antes do loop (ali?s ?
} aconselh?vel que o fa?as para
} poupar tempo de computa??o) e "apontas" os resultados
} do loop para os
} elementos da lista.
} 
} lst <- list()
} vec <- seq(0,1,0.1)
} length(lst)<-length(vec)
} for(i in 1:length(vec)){
} 
} ...
} 
} lst[[i]] <- ...
} 
} }
} 
} Espero que ajude
} 
} EJ
} 
} 
} PS: The answer is in portuguese.
} 
} On Mon, 2003-04-21 at 11:03, Luis Silva wrote:
} > I tried the tips from Sundar but I  still have
} problems. I want 
} > both values and vectors, and the latter will be
} used to project 
} > my original data. The problem is that with those
} command lines 
} > I can't get them as a matrix and when I try
} as.matrix it 
} > doesn't work. With only vectors
} > 
} > > b<-sapply(my.list, function(x) eigen(x)$vectors)
} > > attributes(b)
} > $dim
} > [1] 65536    11
} > 
} > $dimnames
} > $dimnames[[1]]
} > NULL
} > 
} > $dimnames[[2]]
} >  
} > [1] "0"   "0.1" "0.2" "0.3" "0.4" "0.5" "0.6" "0.7"
} "0.8" "0.9" 
} > "1"  
} > 
} > 
} > > b[1]
} > [1] 0.02533057+0i
} > 
} > thanks
} > luis
} > 
} > } 
} > } 
} > } Luis Silva wrote:
} > } > Dear helpers
} > } > 
} > } > I have this problem. I want to make a linear
} > } combination a*A+(1-
} > } > a)*B where A and B are matrices. I want that a
} be
} > } incremented 
} > } > from 0 to 1 by 0.1 so I made a loop with for.
} The
} > } problem is 
} > } > that I want to keep the result in an object or
} list
} > } or 
} > } > something like that and then apply eigen
} > } decomposition to all 
} > } > of the resulting matrices
} > } > 
} > } > sapply(my.list,eigen)
} > } > 
} > } > the problem is that I don't know how to build
} that
} > } list in the 
} > } > loop. I tried several things but it doesn't
} work
} > } (in Matlab i 
} > } > can do it)
} > } > 
} > } 
} > } a <- seq(0, 1, 0.1)
} > } my.list <- lapply(a, function(a, A, B) a*A +
} (a-1)*B,
} > } A=A, B=B)
} > } names(my.list) <- as.character(a)
} > } sapply(my.list, function(x) eigen(x)$value)
} > } 
} > } Regards,
} > } Sundar
} > } 
} > } 
} > 
} > --
} > 
} > 
} > http://adsl.sapo.pt
} > 
} > ______________________________________________
} > R-help at stat.math.ethz.ch mailing list
} >
} https://www.stat.math.ethz.ch/mailman/listinfo/r-help
} 
} 

--


http://adsl.sapo.pt


From andy_liaw at merck.com  Mon Apr 21 14:18:13 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 21 Apr 2003 08:18:13 -0400
Subject: [R] randomForest crash?
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FA06@usrymx25.merck.com>

Hi Karen,

I have not seen such problem, nor heard similar report.  All I can say is
that we have used the package on much larger data sets without problem.

As the R developers say, the best way to get bugs fixed is by crashing the
developer's machine.  If you can send me the data (without column/row
labels, if need be), I can try and see if it crashes R on my machine.  Other
than that, there's not much I can offer.

Cheers,
Andy

> -----Original Message-----
> From: Karen.Chancellor at asu.edu [mailto:Karen.Chancellor at asu.edu]
> Sent: Monday, April 21, 2003 2:57 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] randomForest crash?
> 
> 
> I am attempting to use randomForests to look for interesting genes in
> microarray data with 216genes, 2 classes and 52 samples. My 
> data.frame 
> is 52x217 with the last column, V217 being the class(1 or 2).
> 
> When I try
>         lung.rf <- randomForest(V217 ~ ., data=tlSA216cda, importance=
>                 TRUE, proximity = TRUE)
> the GUI crashes. 
> 
> I am running R-1.6.2 under windo$e98, and most recent version 
> of randomForest.
> Your ideas appreciated.
> Karen
> 
> 
> .-  --.  ....-  -.-.  -.-.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From wegmann at biozentrum.uni-wuerzburg.de  Mon Apr 21 14:22:27 2003
From: wegmann at biozentrum.uni-wuerzburg.de (Martin Wegmann)
Date: Mon, 21 Apr 2003 14:22:27 +0200
Subject: [R] name of arrays
Message-ID: <3EA3E283.51DE85D6@biozentrum.uni-wuerzburg.de>

Hello,

I computed acf() and have an array as output. now I would like to have
only one matrix or data frame (not yet familiar with the nomenclature)
extracted from this array. or even only the first row of each matrix.
 the first part of my data "test" is called
$acf
,1
        , , 1 , , 2
1, ,     ...    ...
2, ,        ..    ...

I tried several names but nothing wants to work, I only get the message:
name not recognized.

any idea? thanks Martin

--
Martin Wegmann
Department of Animal Ecology and Tropical Biology
Zoology III, Biocenter
Am Hubland
97074 W?rzburg
Germany
0931/888-4378
wegmann at biozentrum.uni-wuerzburg.de
m.wegmann at web.de


From rolf at math.unb.ca  Mon Apr 21 14:32:12 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 21 Apr 2003 09:32:12 -0300 (ADT)
Subject: [R] help.start in R-1.7.0 with Netscape 7.0.
Message-ID: <200304211232.h3LCWC2k023471@erdos.math.unb.ca>


I'm experiencing a new and annoying phenomenon which seems to consist
of an unfortunate interaction between R-1.7.0 and netscape version 7.

When I invoke help.start(), a netscape window duly appears
with the browser pointed at the file .../R/doc/html/index.html
as one would hope and expect.

However if I then ask for help on a function, e.g.

	> help(glm)

the help does NOT get displayed in the existing netscape window.
Instead, up pops a small window asking me to ``Select User
Profile''.  If I click on ``Start Netscape 7.0'' in this small
window, I get a message saying ``Netscape 7.0 cannot use the profile
``rolf'' because it is in use.  Please choose another profile or
create a new one.''

If I do create a new one, and then ask for help on another function,
the same thing happens unless I explicitly close the window in
which the help on glm() is displayed.

OK, I can do that, and keep a ``profile'' around for displaying R
help, but it's an irritation and a slow-down.

Is there a way to tell R or netscape --- I'm not sure which one
I should be talking to --- to display the help in the existing
netscape window, and not keep trying to open new ones under
new ``profiles''?

				cheers,

					Rolf Turner
					rolf at math.unb.ca


From casiano at ull.es  Mon Apr 21 15:09:36 2003
From: casiano at ull.es (Casiano Rodriguez Leon)
Date: Mon, 21 Apr 2003 14:09:36 +0100 (WEST)
Subject: [R] piece wise functions
Message-ID: <Pine.LNX.4.44.0304211320400.24276-100000@nereida.deioc.ull.es>

Hello,

Apologies if this question has already arised, hope you can
help me to the find the solution to this or point the place to look at.

I have a multidimensional piece-wise regression linear problem, i.e.
to find not only the regression coefficients for each "interval" but
also the beginning and ends of the intervals.

To simplify it to the one dimensional case and
two intervals, the problem is to find A_0, A_1, ... A_p and "C"
from the given sample, assuming the curve is like this:

A_0*f_0(x)+A_1*f_1(x)+ ... + A_p*f_p(x) with x < C

A_0'*f_0(x)+A_1'*f_1(x)+ ... + A_p'*f_p(x) with x >= C

Functions f_1, f_2, ... f_p are known.

Is there anything in R for that?

I have tried to use nonlinear (nls package)
regression, "forcing" with the "nls" function the shape of the surface,
but it does not work.

By the way, the cofficients A_i have to be positive, but I suppose this is
another question.

Thanks

Casiano
casiano at ull.es


From Detlef.Steuer at unibw-hamburg.de  Mon Apr 21 14:56:28 2003
From: Detlef.Steuer at unibw-hamburg.de (Detlef Steuer)
Date: Mon, 21 Apr 2003 14:56:28 +0200 (CEST)
Subject: [R] R-1.7.0 SUSE RPM anyone?
In-Reply-To: <20030418064243.4E7AE82471@ac.lisse.na>
Message-ID: <XFMail.20030421145628.steuer@unibw-hamburg.de>


On 18-Apr-2003 Dr Eberhard W. Lisse wrote:
> Anyone working on RPMs for SUSE 8.1/2?

Yes, me. :-)

For 7.3/8.0 Compilation runs fine and will be finished soon.
I will upload to vienna in the evening and you should find rpms tomorrow.

8.1 has problems compiling:

collecting examples for package 'tcltk' ...
make[5]: Wechsel in das Verzeichnis
?/usr/src/packages/BUILD/R-1.7.0/src/library?
 >>> Building/Updating help pages for package 'tcltk'
     Formats: text example
make[5]: Verlassen des Verzeichnisses
?/usr/src/packages/BUILD/R-1.7.0/src/library?
running code in 'tcltk-Ex.R' ...make[4]: *** [tcltk-Ex.Rout] Fehler 1
make[4]: Verlassen des Verzeichnisses
?/usr/src/packages/BUILD/R-1.7.0/tests/Examples?
make[3]: *** [test-Examples-Base] Fehler 2
make[3]: Verlassen des Verzeichnisses
?/usr/src/packages/BUILD/R-1.7.0/tests/Examples?
make[2]: *** [test-Examples] Fehler 2
make[2]: Verlassen des Verzeichnisses ?/usr/src/packages/BUILD/R-1.7.0/tests?
make[1]: *** [test-all-basics] Fehler 1
make[1]: Verlassen des Verzeichnisses ?/usr/src/packages/BUILD/R-1.7.0/tests?
make: *** [check] Fehler 2

I?m trying to sort it out. Any immediate ideas, Peter?
# rpm -q tk                         
tk-8.4-48
# rpm -q tcl
tcl-8.4-48
# rpm -q tcl-devel
tcl-devel-8.4-48



8.2 will be there as soon as my package from SuSE arrives. :-)

> 
> el
> -- 
> Dr. Eberhard W. Lisse  \   *    /        Managing Member, NA-NiC (cc) 
> <el at lisse.NA> el108    /       | NA-NiC is the the .NA ccTLD Registry
> Private Bag X5501       \     /           NA-NiC, Not Just Like That!
> Oshakati, Namibia       ;____/     Telephone: +264 81 124 6733 (cell)
> Please send DNS/NA-NiC related e-mail to dns-admin at na-nic.com.na only
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

"There is no way to peace, peace is the way." -- Ghandi

Detlef Steuer --- http://fawn.unibw-hamburg.de/steuer.html
***** Encrypted mail preferred *****


From rolf at math.unb.ca  Mon Apr 21 15:03:14 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 21 Apr 2003 10:03:14 -0300 (ADT)
Subject: [R] help.start in R-1.7.0 with Netscape 7.0.
Message-ID: <200304211303.h3LD3EE0023954@erdos.math.unb.ca>


Forgot to mention:

 > version
         _                   
platform sparc-sun-solaris2.9
arch     sparc               
os       solaris2.9          
system   sparc, solaris2.9   
status                       
major    1                   
minor    7.0                 
year     2003                
month    04                  
day      16                  
language R

				cheers,

					Rolf Turner
					rolf at math.unb.ca


From rab at nauticom.net  Mon Apr 21 16:14:17 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Mon, 21 Apr 2003 10:14:17 -0400
Subject: [R] 
	Anyone Familiar with Using arima function with exogenous variables?
Message-ID: <3EA3FCB9.1090607@nauticom.net>

I've posted this before but have not been able to locate what I'm doing 
wrong. I cannot determine how the forecast is made using the estimated 
coefficients from a simple AR(2) model when there is an exogenous 
variable. Does anyone know what the problem is? The help file for arima 
doesn't show the model with any exogenous variables. I haven't been able 
to locate any documents covering this. I put together a simple example 
of an AR(2) model (no exogenous variables) and another example of an 
AR(2) with one exogenous variable.  In the first case it's easy to see 
how the forecasts are computed. When there is an exogenous variable, 
it's not clear (at leat to me) how the forecast is computed. I thought I 
understood how the model is written but apparently not.

Using the LakeHuron data, fit a simple AR(2) model:

 > data(LakeHuron)
 > ar.lh <- arima(LakeHuron, order = c(2,0,0))
 > ar.lh

Call:
arima(x = LakeHuron, order = c(2, 0, 0))

Coefficients:
        ar1      ar2  intercept
     1.0436  -0.2495   579.0473
s.e.  0.0983   0.1008     0.3319

sigma2 estimated as 0.4788:  log likelihood = -103.63,  aic = 215.27

Make a 1-step ahead forecast:

 > predict(ar.lh,1)[[1]]
Time Series:
Start = 1973
End = 1973
Frequency = 1
[1] 579.7896

Compute the forecast manually:

 > sum(ar.lh$coef*c(c(579.96,579.89)-ar.lh$coef[3],1))
[1] 579.7896

This just says that the forecast for the next period (after the end of 
the data) is 579.0473 + 1.0436*(579.96 - 579.0473) - 0.2495*(579.89 - 
579.0473). In other words: the forecast is the intercept plus the AR 
coefficients times the  (previous ts values minus the intercepts).

Now add an exogenous variable (in this case, the (year - 1920):

 > ar.lh <- arima(LakeHuron, order = c(2,0,0), xreg = time(LakeHuron)-1920)
 > ar.lh

Call:
arima(x = LakeHuron, order = c(2, 0, 0), xreg = time(LakeHuron) - 1920)

Coefficients:
         ar1      ar2  intercept  time(LakeHuron) - 1920
      1.0048  -0.2913   579.0993                 -0.0216
s.e.  0.0976   0.1004     0.2370                  0.0081

sigma2 estimated as 0.4566:  log likelihood = -101.2,  aic = 212.4

The prediction is:

 > predict(ar.lh,1,newxreg=53)[[1]]
Time Series:
Start = 1973
End = 1973
Frequency = 1
[1] 579.3972


Now try to manually forecast when the next time period is 53 (i.e., 1973 
- 1920):

 > sum(ar.lh$coef*c(c(579.96,579.89)-ar.lh$coef[3],1,53))
[1] 578.5907

What am I doing wrong? I've tried this with numerous examples and 
whenever there is an exogenous variable I cannot get the manual forecast 
to agree with predict. Is it not correct to just add (-0.0216 times 53) 
to the rest? I need to know how to write the model correctly. Obviously 
there is something I am overlooking. R's arima function and predict 
function work correctly - at least they agree with SAS for example so 
I'm not doing something right.

I would really appreciate some insight here.

Rick B.


From TyagiAnupam at aol.com  Mon Apr 21 15:59:01 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Mon, 21 Apr 2003 09:59:01 EDT
Subject: [R] piece wise functions
Message-ID: <17c.19ca8f0f.2bd55325@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030421/b7c401c0/attachment.pl

From tlumley at u.washington.edu  Mon Apr 21 16:16:04 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 21 Apr 2003 07:16:04 -0700 (PDT)
Subject: [R] how to use apply with a function created by ourselfs...?
In-Reply-To: <001c51626081543SILJA@silja.absolutok.com>
Message-ID: <Pine.A41.4.44.0304210714010.134378-100000@homer35.u.washington.edu>

On Mon, 21 Apr 2003, ANA KOZOMARA wrote:

>
> ..hey thanks for the answer, both of you...
> but :-(, I don't seem to have an answer to my problem...
> I tried with what u suggested, but it doesn't work yet...
> so I will precise it...
> I have a data frame...
> and I would like to apply the function "prediction" which acts on two
> vectors
> prediction(linear,ind),
> to my data frame,I mean to all the rows of my data frame...
> something like a function "Map" in Mathematica...
> Shortly, I want to apply function "prediction" to a list of arguments, not
> to a single argument...

I don't know Mathemtica but it sounds like you want mapply() (in R 1.7.0).

	-thomas


From marwan.khawaja at aub.edu.lb  Tue Apr 22 02:07:57 2003
From: marwan.khawaja at aub.edu.lb (Marwan Khawaja)
Date: Mon, 21 Apr 2003 17:07:57 -0700
Subject: [R] barplot2
In-Reply-To: <00ac01c30415$b99e27c0$0201a8c0@MARC>
Message-ID: <CLECJBOEBGOMOKJHJNDACEKNCOAA.marwan.khawaja@aub.edu.lb>

I want to thank Mark Schwartz and Martin Meachler for their suggestions re
conversion to pdf.
Obviously, the problem was witht the conversion software used --
GhostScript/GSView solved it.
Thanks again Marwan

=======================
Marwan Khawaja					marwan.khawaja at aub.edu.lb
Associate Professor & Director				http://webfaculty.aub.edu.lb/~mk36
Center for Research on Population & Health
Faculty of Health Sciences				Tel:  +961 1 35 00 00 ext. 4668 (O)
American University of Beirut				       +961 1 35 00 00 ext. 4640 (O))
P.O.Box 11--0236, Riad El-Solh				       +961 1 35 00 00 ext. 2821 (H)
Beirut 1107 2020, Lebanon 				Fax: +961 1 74 44 70


-----Original Message-----
From: Marc Schwartz [mailto:mschwartz at medanalytics.com]
Sent: Wednesday, April 16, 2003 5:43 AM
To: 'Marwan Khawaja'; 'R'
Subject: RE: [R] barplot2


>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marwan Khawaja
>Sent: Wednesday, April 16, 2003 11:41 AM
>To: R
>Subject: [R] barplot2
>
>
>Hello,
>I get a nice looking barplot using the barplot2 function in
>the gregmisc
>package:
>
>    body2 <- barplot2(hh3, beside = TRUE,
>            col = c("mistyrose", "lightcyan"),
>    ....
>    cex.names = 1.0, plot.ci = TRUE, ci.l = cil, ci.u = ciu,
>            plot.grid = TRUE)
>    box()
>
>However, obviously I lose the collors when converting from ps
>to a pdf (outside of R) but I get a single shaded pattern! Is
>it my choice of collors? Or the conversion software I am
>using? Any help would be appreciated. TIA Marwan


Marwan,

I don't have your full code, but I used barplot2() in R 1.6.2 under
WinXP Pro to generate a simple bar plot with two bars in the colors
that you have above. I can generate a .PS file and then convert it to
.PDF using GhostScript/GSView and default settings without problem.
The colors are properly retained.

Can you provide your full code so that I can exactly replicate your
plot and specify what program you are using to do the PS to PDF
conversion?

Regards,

Marc Schwartz


From tblackw at umich.edu  Mon Apr 21 16:23:55 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 21 Apr 2003 10:23:55 -0400 (EDT)
Subject: [R] piece wise functions
In-Reply-To: <Pine.LNX.4.44.0304211320400.24276-100000@nereida.deioc.ull.es>
Message-ID: <Pine.SOL.4.44.0304210954270.5089-100000@timepilot.gpcc.itd.umich.edu>

Casiano  -

A practical approach would be to use  gam() and its friends
in package mgcv.  This implements Generalized Additive Models
(Hastie & Tibshirani, 1990).  The fit will be smoother than
you would get with an explicit piece-wise linear regression,
but it's already implemented.

If you really care about estimating the boundaries between
distinct regions of the fit, that's a research question, in
my humble opinion, and you are cast onto the stormy sea of
statistical literature for that.  That's a difficult problem.
Start with  gam() and eyeball the boundaries ?

Others will have better ideas.  Maybe packages "GRASS",
"grasper" or "geoR" have something to offer ?

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 21 Apr 2003, Casiano Rodriguez Leon wrote:

> Hello,
>
> I have a multidimensional piece-wise regression linear problem, i.e.
> to find not only the regression coefficients for each "interval" but
> also the beginning and ends of the intervals.
>
> To simplify it to the one dimensional case and
> two intervals, the problem is to find A_0, A_1, ... A_p and "C"
> from the given sample, assuming the curve is like this:
>
> A_0*f_0(x)+A_1*f_1(x)+ ... + A_p*f_p(x) with x < C
>
> A_0'*f_0(x)+A_1'*f_1(x)+ ... + A_p'*f_p(x) with x >= C
>
> Functions f_1, f_2, ... f_p are known.
>
> Is there anything in R for that?
>
> I have tried to use nonlinear (nls package) regression, "forcing" with
> the "nls" function the shape of the surface, but it does not work.
>
> By the way, the cofficients A_i have to be positive, but I suppose this is
> another question.
>
> Thanks
>
> Casiano
> casiano at ull.es


From spencer.graves at pdf.com  Mon Apr 21 16:48:47 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 21 Apr 2003 07:48:47 -0700
Subject: [R] name of arrays
References: <3EA3E283.51DE85D6@biozentrum.uni-wuerzburg.de>
Message-ID: <3EA404CF.6010501@pdf.com>

Have you tried the following:

tst <- acf()...
tst$acf

???
hope this helps. spencer graves

Martin Wegmann wrote:
> Hello,
> 
> I computed acf() and have an array as output. now I would like to have
> only one matrix or data frame (not yet familiar with the nomenclature)
> extracted from this array. or even only the first row of each matrix.
>  the first part of my data "test" is called
> $acf
> ,1
>         , , 1 , , 2
> 1, ,     ...    ...
> 2, ,        ..    ...
> 
> I tried several names but nothing wants to work, I only get the message:
> name not recognized.
> 
> any idea? thanks Martin
> 
> --
> Martin Wegmann
> Department of Animal Ecology and Tropical Biology
> Zoology III, Biocenter
> Am Hubland
> 97074 W?rzburg
> Germany
> 0931/888-4378
> wegmann at biozentrum.uni-wuerzburg.de
> m.wegmann at web.de
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Mon Apr 21 16:52:04 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 21 Apr 2003 07:52:04 -0700
Subject: [R] nonlinear equation solver?
References: <0FBE46098704A242B0DC8FEC4169F9978140EC@s31xs3.systems.smu.edu>
	<3EA37DFA.2040408@stats.waikato.ac.nz>
Message-ID: <3EA40594.3040909@pdf.com>

You may also wise to consider a book on nonlinear regression such as 
Bates and Watts (1988) Nonlinear Regression Analysis and Its 
Applications (Wiley).

hope this helps. spencer graves

Murray Jorgensen wrote:
> For this equation you are out of luck as log(z) < z for all positive z's 
> (such as t^2). More generally you should consult a numerical analysis 
> textbook for advice on the solution of nonlinear equations. There you 
> will read about many algorithms in common use by statisticians.
> 
> Murray Jorgensen
> 
> Wang, Zhu wrote:
> 
>> Dear R-Help,
>>  
>> I am trying to use R to solve a nonlinear equation many times for 
>> different values. I am looking for a mathematical nonlinear equation 
>> solution which may not have a closed solution form. For example, I 
>> have equation:
>> 2 = (t^2)/log(t)
>> What is t?
>>  
>> I am wondering how to solve it in R.
>> Many thanks,
>>  
>> Zhu Wang
>>  
>> Statistical Science Department
>> SMU.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>


From myao at ou.edu  Mon Apr 21 17:00:11 2003
From: myao at ou.edu (Minghua Yao)
Date: Mon, 21 Apr 2003 10:00:11 -0500
Subject: [R] How to assigen column of matrix
Message-ID: <HDEPJCAKDEJMEEHKJOKECEIHCAAA.myao@ou.edu>


Hi, 

A simple question.

I want to assign values to columns (or rows) of a matrix.

It seems that
AA[,i]<-A; # A is a vector or array;
doesn't work. 

How can I accomplish that?

Thanks alot.

-MY


From zhuw at mail.smu.edu  Mon Apr 21 17:25:23 2003
From: zhuw at mail.smu.edu (Wang, Zhu)
Date: Mon, 21 Apr 2003 10:25:23 -0500
Subject: [R] nonlinear equation solver?
Message-ID: <0FBE46098704A242B0DC8FEC4169F9978140ED@s31xs3.systems.smu.edu>

Thanks to all.
 
I know how to solve it numerically but I am just wondering if there is a function already in R or S. I guess I have to implement some C codes then.
 
Thanks to Murray for good observation.
 
I am not sure why optim function is working in general to solve a nonlinear equation from Patrick's advice.

	-----Original Message----- 
	From: Murray Jorgensen [mailto:maj at stats.waikato.ac.nz] 
	Sent: Mon 4/21/2003 12:13 AM 
	To: Wang, Zhu 
	Cc: r-help at stat.math.ethz.ch 
	Subject: Re: [R] nonlinear equation solver?


From tlumley at u.washington.edu  Mon Apr 21 17:25:50 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 21 Apr 2003 08:25:50 -0700 (PDT)
Subject: [R] How to assigen column of matrix
In-Reply-To: <HDEPJCAKDEJMEEHKJOKECEIHCAAA.myao@ou.edu>
Message-ID: <Pine.A41.4.44.0304210824340.124622-100000@homer03.u.washington.edu>

On Mon, 21 Apr 2003, Minghua Yao wrote:

>
> Hi,
>
> A simple question.
>
> I want to assign values to columns (or rows) of a matrix.
>
> It seems that
> AA[,i]<-A; # A is a vector or array;
> doesn't work.
>

It seems that it does work for me:
> AA<-matrix(1:4,2)
> AA
     [,1] [,2]
[1,]    1    3
[2,]    2    4
> A<-c(10,11)
> AA[,2]<-A
> AA
     [,1] [,2]
[1,]    1   10
[2,]    2   11

if that's what you were trying to do.  Note that command lines in R don't
end with a ;, but in this case it doesn't matter.

	-thomas


From p.dalgaard at biostat.ku.dk  Mon Apr 21 17:39:09 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 21 Apr 2003 17:39:09 +0200
Subject: [R] nonlinear equation solver?
In-Reply-To: <0FBE46098704A242B0DC8FEC4169F9978140ED@s31xs3.systems.smu.edu>
References: <0FBE46098704A242B0DC8FEC4169F9978140ED@s31xs3.systems.smu.edu>
Message-ID: <x2bryzsvvm.fsf@biostat.ku.dk>

"Wang, Zhu" <zhuw at mail.smu.edu> writes:

> Thanks to all.
>  
> I know how to solve it numerically but I am just wondering if there is a function already in R or S. I guess I have to implement some C codes then.
>  
> Thanks to Murray for good observation.
>  
> I am not sure why optim function is working in general to solve a nonlinear equation from Patrick's advice.

help(uniroot) ...

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From ligges at statistik.uni-dortmund.de  Mon Apr 21 17:48:33 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 21 Apr 2003 17:48:33 +0200
Subject: [R] name of arrays
References: <3EA3E283.51DE85D6@biozentrum.uni-wuerzburg.de>
Message-ID: <3EA412D1.EDDE446@statistik.uni-dortmund.de>



Martin Wegmann wrote:
> 
> Hello,
> 
> I computed acf() and have an array as output. now I would like to have
> only one matrix or data frame (not yet familiar with the nomenclature)
> extracted from this array. or even only the first row of each matrix.
>  the first part of my data "test" is called
> $acf
> ,1
>         , , 1 , , 2
> 1, ,     ...    ...
> 2, ,        ..    ...


It look's different, doesn't it?

$acf
, , 1

              [,1]         [,2]
 [1,] 		...



> I tried several names but nothing wants to work, I only get the message:
> name not recognized.
> 
> any idea? thanks Martin

Since it's an array (obviously inside a list, say L), you can index is
like an array:

L$acf[,,1] # for the first matrix of the third dimension
L$acf[,1,] # for the first matrix of the second dimension
  # in other words: all 1st columns
L$acf[4,,] # for the fourth matrix of the first dimension
  # in other words: all 4th rows

See the manuals for details on indexing arrays.

Uwe Ligges


From tw.chan at sociology.oxford.ac.uk  Mon Apr 21 17:58:59 2003
From: tw.chan at sociology.oxford.ac.uk (Tak Wing Chan)
Date: Mon, 21 Apr 2003 16:58:59 +0100
Subject: [R] Multinomial logistic regression under R and Stata
Message-ID: <3EA41543.6000700@sociology.oxford.ac.uk>

Dear Colleagues

I posted to the R-help and Stata lists a little while ago concerning 
some disagreement in results I obtained from using the multinom function 
in R and the mlogit command in Stata.

Many thanks to colleagues for your comments and ideas. I have checked 
out some of your suggestions, and here is a report. The disagreements I 
reported are of two types: (1) parameter estimates for the intercepts 
and (2) standard errors of a quadratic term of a quantitative variable.

Regarding (1): yes, as some of you suggested, this is due to the coding 
of another covariate in the model. Thanks!

As for (2), it turns out that the problem has to do with the scale of 
the quadratic term.

In my original model, I have, out of habit, scaled down the quadratic 
term by 100, so as to make its scale comparable to the linear term. I.e. 
I did the following.

varsq <- var*var/100

This is in fact unnecessary in the present case, given the scale of the 
linear term. But anyway, with the division, R and Stata disagree:

        beta        s.e.
R:      5.939880  2.920165
Stata:  5.939747  5.455495

R:      11.228705 2.191625
Stata:  11.22761  4.630293

However, if I don't divide the quadratic term by 100, then R and Stata agree.

R:       0.05939645  0.05455490
Stata:   0.0593975   0.0545549

R:       0.11227038  0.04630296
Stata:   0.1122761   0.0463029

So it apprears that R might have some precision problem in calculating 
the Hessian when the scale of a variable is very small. I talked to a 
colleague, David Firth, about this, and he suggests

 > Possibly it would be worth implementing an algebraic vcov method for 
multinomial logit models [in R]?

Once again, many thanks to colleagues for your time and help.

Cheers.  Wing

-- 
Department of Sociology, University of Oxford,
Littlegate House, St Ebbes, Oxford OX1 1PT, UK
tel: +44 (1865) 286176, fax: +44 (1865) 286171
http://users.ox.ac.uk/~sfos0006


From jfox at mcmaster.ca  Mon Apr 21 17:47:06 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 21 Apr 2003 11:47:06 -0400
Subject: [R] How to assigen column of matrix
In-Reply-To: <HDEPJCAKDEJMEEHKJOKECEIHCAAA.myao@ou.edu>
Message-ID: <5.0.2.1.0.20030421114336.00aee978@mcmail.cis.mcmaster.ca>

Dear Minghua Yao,

Commands of the form AA[, i] <- A do indeed work, although the number of 
elements in the i-th row of AA has to be a multiple of the number of 
elements in A. Perhaps you can specify in more detail what it is that you 
want to do and the nature of the error that you encountered.

I hope that this helps,
  John

At 10:00 AM 4/21/2003 -0500, Minghua Yao wrote:

>Hi,
>
>A simple question.
>
>I want to assign values to columns (or rows) of a matrix.
>
>It seems that
>AA[,i]<-A; # A is a vector or array;
>doesn't work.
>
>How can I accomplish that?
>
>Thanks alot.
>
>-MY
>

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox


From rab at nauticom.net  Mon Apr 21 18:32:12 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Mon, 21 Apr 2003 12:32:12 -0400
Subject: [R] Anyone Familiar with Using arima function with exogenous
 variables?
In-Reply-To: <3EA40337.7030206@pdf.com>
References: <3EA3FCB9.1090607@nauticom.net> <3EA40337.7030206@pdf.com>
Message-ID: <3EA41D0C.5040701@nauticom.net>

Spencer Graves wrote:

> Have you tried reading predict.Arima?
>
> Do you have any references that compute a simple numerical example?  I 
> believe there is one in Box, Jenkins, Reinsel, but I don't have time 
> to research it.
>
> Hope this helps.
> spencer graves
>

There does not appear to be any relevant information in predict.Arima 
concerning xreg.

I tried using arima to estimate the sales data (Series M in Box and 
Jenkins) using the leading indicator. I think I estimated the same model 
correctly. The AR and MA coefficients roughly agreed but the intercept 
and coefficient for the leading indicator were very different. The 
intercept was 10 times too large (approximately) and the coefficient for 
the leading indicator was about 1/10 of that shown in B&J.

So far I haven't located any simple examples to try.

Thanks.

Rick B.


From ligges at statistik.uni-dortmund.de  Mon Apr 21 18:09:00 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 21 Apr 2003 18:09:00 +0200
Subject: [R] Generating axes with "Sun Apr 20 22:45:27 PDT 2003" 
 timecoordinates.
References: <200304202301.06368.fatman@aracnet.com>
Message-ID: <3EA4179C.C76271E1@statistik.uni-dortmund.de>



John Jaynes wrote:
> 
> Good Morning!
> 
> My apologies for what may be considered an infantile question: I have data
> that I would like to plot, positive integers for the y-axis, and time
> coordinates of the "Sun Apr 20 22:45:27 PDT 2003" format for the x-axis.
> I have tried:
> 
> x1 <- 1050352610
> x2 <- 1050352999
> x3 <- 1050858319
> class(x1) <- "POSIXct"
> class(x2) <- "POSIXct"
> class(x3) <- "POSIXct"
> X <- c(x1, x2, x3)
> ...
> ...
> plot(X, Y, type = "l")
> 
> I end up with "Mon", "Tues", "Wed", ... x-axis coordinates, when I need
> "2003-04-14 13:36:50 PDT",  "2003-04-14 13:43:19 PDT"
> and  "2003-04-20 10:05:19 PDT" x-axis coordinates. I adjusted the data to be
> one second apart and ended up with integer "19", "20", ... x-axis
> coordinates. What do I need to do to accomplish this? Any help will be
> greatly appreciated, as I have looked at the help pages, and the web, to no
> avail. I would also be more than happy to purchase a book that contains
> information to this level of detail if that is available.
> 
> Thank You,
> 
> John Jaynes


I guess you are looking for:

  plot(X, Y, type = "l", xaxt = "n")
  axis.POSIXct(1, X, at=X, format="%a %b %d %H:%M:%S %Z %Y")

Uwe Ligges


From rvaradha at jhsph.edu  Mon Apr 21 18:21:28 2003
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Mon, 21 Apr 2003 12:21:28 -0400
Subject: [R] nonlinear equation solver?
References: <0FBE46098704A242B0DC8FEC4169F9978140ED@s31xs3.systems.smu.edu>
Message-ID: <003601c30822$101b22f0$1158120a@BSTE3005>

Dear Wang:

You can solve nonlinear equations (multiple variables) with "optim" using a
trick as follows:
Suppose your equations are:
f1(x1,x2,...,xn) = 0
f2(x1,x2,...,xn) = 0
.
.
.
fn(x1,x2,...,xn) = 0

You simply create a quadratic objective function, which is the sum of the
squared values of all functions, i.e.
f(x1,x2,...,xn) = f1^2 + f2^2 + ... + fn^2
 Minimizing this objective function is equivalent to solving simultaneous
nonlinear equations.

Hope this help,

Ravi.
----- Original Message -----
From: "Wang, Zhu" <zhuw at mail.smu.edu>
To: <maj at waikato.ac.nz>; <pburns at pburns.seanet.com>;
<spencer.graves at pdf.com>
Cc: <r-help at stat.math.ethz.ch>
Sent: Monday, April 21, 2003 11:25 AM
Subject: RE: [R] nonlinear equation solver?


> Thanks to all.
>
> I know how to solve it numerically but I am just wondering if there is a
function already in R or S. I guess I have to implement some C codes then.
>
> Thanks to Murray for good observation.
>
> I am not sure why optim function is working in general to solve a
nonlinear equation from Patrick's advice.
>
> -----Original Message-----
> From: Murray Jorgensen [mailto:maj at stats.waikato.ac.nz]
> Sent: Mon 4/21/2003 12:13 AM
> To: Wang, Zhu
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] nonlinear equation solver?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From hess at stat.colostate.edu  Mon Apr 21 18:19:36 2003
From: hess at stat.colostate.edu (Ann Hess)
Date: Mon, 21 Apr 2003 10:19:36 -0600 (MDT)
Subject: [R] index after rbind
Message-ID: <Pine.GSO.4.55.0304211015540.2788@liberator.stat.colostate.edu>

I am using rbind to concatenate two dataframes, but after the rbind I get
a strange "double" index.

I am using rbind a number of times to make one large dataset.  Is there a
way to prevent the "double" index?  Or is there some other way to
concatenate the data (it looks like merge only works by columns)?

Here is an example of the "double" index.

>numbers<-(1:5)
>letters<-matrix(c("a","b","c","d","e"),5,1)
>data<-data.frame(letters,numbers)
>doubledata<-rbind(data,data)
> doubledata
   letters numbers
1        a       1
2        b       2
3        c       3
4        d       4
5        e       5
11       a       1
22       b       2
33       c       3
44       d       4
55       e       5


From edd at debian.org  Mon Apr 21 18:23:07 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 21 Apr 2003 11:23:07 -0500
Subject: [R] Anyone Familiar with Using arima function with exogenous
	variables?
In-Reply-To: <3EA41D0C.5040701@nauticom.net>
References: <3EA3FCB9.1090607@nauticom.net> <3EA40337.7030206@pdf.com>
	<3EA41D0C.5040701@nauticom.net>
Message-ID: <20030421162307.GA13477@sonny.eddelbuettel.com>

On Mon, Apr 21, 2003 at 12:32:12PM -0400, Richard A. Bilonick wrote:
> I tried using arima to estimate the sales data (Series M in Box and 
> Jenkins) using the leading indicator. I think I estimated the same model 
> correctly. The AR and MA coefficients roughly agreed but the intercept 
> and coefficient for the leading indicator were very different. The 
> intercept was 10 times too large (approximately) and the coefficient for 
> the leading indicator was about 1/10 of that shown in B&J.
> 
> So far I haven't located any simple examples to try.

Why don't you try simulation?  

Create some data under the 'null' you're trying to get to, say, y <-
seq(1,n) + arima.error where arima.error could be as simple as an AR(1) or
MA(1). Then estimate the model, using 90% or 95% of the data and evaluate
the forecast to the retained 10% or 5%. Repeat the DGP creation, estimation,
forecast evaluation steps N (say 500) times and you should have a good idea
about the merits of predict.arima.

Dirk

-- 
Don't drink and derive. Alcohol and algebra don't mix.


From spencer.graves at pdf.com  Mon Apr 21 18:34:52 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 21 Apr 2003 09:34:52 -0700
Subject: [R] index after rbind
References: <Pine.GSO.4.55.0304211015540.2788@liberator.stat.colostate.edu>
Message-ID: <3EA41DAC.6070408@pdf.com>

 > df1 <- data.frame(a=1:2)
 > df2 <- rbind(df1, df1)
 > df2
    a
1  1
2  2
11 1
22 2
 > rownames(df2) <- 1:4

hope this helps. spencer graves

Ann Hess wrote:
> I am using rbind to concatenate two dataframes, but after the rbind I get
> a strange "double" index.
> 
> I am using rbind a number of times to make one large dataset.  Is there a
> way to prevent the "double" index?  Or is there some other way to
> concatenate the data (it looks like merge only works by columns)?
> 
> Here is an example of the "double" index.
> 
> 
>>numbers<-(1:5)
>>letters<-matrix(c("a","b","c","d","e"),5,1)
>>data<-data.frame(letters,numbers)
>>doubledata<-rbind(data,data)
>>doubledata
> 
>    letters numbers
> 1        a       1
> 2        b       2
> 3        c       3
> 4        d       4
> 5        e       5
> 11       a       1
> 22       b       2
> 33       c       3
> 44       d       4
> 55       e       5
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From rab at nauticom.net  Mon Apr 21 19:09:14 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Mon, 21 Apr 2003 13:09:14 -0400
Subject: [R] Anyone Familiar with Using arima function with exogenous
 variables?
In-Reply-To: <20030421162307.GA13477@sonny.eddelbuettel.com>
References: <3EA3FCB9.1090607@nauticom.net> <3EA40337.7030206@pdf.com>
	<3EA41D0C.5040701@nauticom.net>
	<20030421162307.GA13477@sonny.eddelbuettel.com>
Message-ID: <3EA425BA.6030401@nauticom.net>

Dirk Eddelbuettel wrote:

>Why don't you try simulation?  
>
>Create some data under the 'null' you're trying to get to, say, y <-
>seq(1,n) + arima.error where arima.error could be as simple as an AR(1) or
>MA(1). Then estimate the model, using 90% or 95% of the data and evaluate
>the forecast to the retained 10% or 5%. Repeat the DGP creation, estimation,
>forecast evaluation steps N (say 500) times and you should have a good idea
>about the merits of predict.arima.
>
>Dirk
>
>  
>
I will try this. I was hoping to find documentation in R or elsewhere 
but this may be my only hope at this point. I don't doubt that 
predict.Arima is correct (the results agree with SAS, for example), it's 
just that I need to be able to compute the forecasts in other software.

Thanks.

Rick B.


From dieter.menne at menne-biomed.de  Mon Apr 21 19:18:24 2003
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 21 Apr 2003 19:18:24 +0200
Subject: [R] R(D) Com under R1070
Message-ID: <JLEPLGAANFCEAEDCAGJNEEMPCEAA.dieter.menne@menne-biomed.de>

Dear List,

I have unregistered the working installation of R(D)COM from r1060 as
described in http://cran.r-project.org/contrib/extra/dcom/ReadMe.txt,
and have re-installed it for r1070.

Now, vbtest gives the following message:

Loading StatConnector Server... Done
Initializing R...Function call failed
  Code: -2147221485
  Text: installation problem: unable to load connector
Box: Method '~' of object '~' failed.

Releasing StatConnector Server...Done

Any ideas?

Dieter Menne


From ma at ne.su.se  Mon Apr 21 19:23:52 2003
From: ma at ne.su.se (Mahmood ARAI)
Date: Mon, 21 Apr 2003 19:23:52 +0200
Subject: [R] using update( ) in a function?
Message-ID: <20030421172352.5B7EB3B88F@mbox2.su.se>

Hello, 

using the function "update()" in the following function
does not work. 

# a function for running a model:  x1 ~ x2
# by updating the original model: fm1 <- lm(y ~ x1 + x2,data=df)
# update(fm1, x1 ~ . -x1, data=df) works at the command line
# but not in the function below. 


R>   foo <- function(fm,x,df)
+     {
+     update(fm, x ~ . -x,data=df)
+     }
R>
R>
R>  df1 <- data.frame(y= 1:10, x1=(1:10)^2, x2=sqrt(1:10)^3)
R>  fm1 <- lm(y ~ x1+x2, data=df1)
R>
R>  foo(fm1, x1, df1)
Error in eval(expr, envir, enclos) : Object "x" not found
R>  update(fm1, x1 ~ . -x1,data=df1) 

Call:
lm(formula = x1 ~ x2, data = df1) 

Coefficients:
(Intercept)           x2
    -7.753        3.242 

any idea? 

thanks!
mahmood arai


From rpeng at stat.ucla.edu  Mon Apr 21 19:24:28 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon, 21 Apr 2003 10:24:28 -0700 (PDT)
Subject: [R] nonlinear equation solver?
In-Reply-To: <0FBE46098704A242B0DC8FEC4169F9978140EC@s31xs3.systems.smu.edu>
Message-ID: <Pine.GSO.4.10.10304211024170.27528-100000@quetelet.stat.ucla.edu>

I think what you are looking for is uniroot().

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Sun, 20 Apr 2003, Wang, Zhu wrote:

> Dear R-Help,
>  
> I am trying to use R to solve a nonlinear equation many times for different values. I am looking for a mathematical nonlinear equation solution which may not have a closed solution form. For example, I have equation:
> 2 = (t^2)/log(t)
> What is t?
>  
> I am wondering how to solve it in R.
> Many thanks,
>  
> Zhu Wang
>  
> Statistical Science Department
> SMU.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From rpeng at stat.ucla.edu  Mon Apr 21 19:36:16 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon, 21 Apr 2003 10:36:16 -0700 (PDT)
Subject: [R] index after rbind
In-Reply-To: <Pine.GSO.4.55.0304211015540.2788@liberator.stat.colostate.edu>
Message-ID: <Pine.GSO.4.10.10304211034090.27528-100000@quetelet.stat.ucla.edu>

When you rbind() `data' and `data', the two dataframes have the exact same
rownames so rbind() tries to modify them to make the combined dataframe
have unique rownames.  If you don't want this, just use rownames()<- to
modify the row names.  Such as,

rownames(doubledata) <- 1:nrow(doubledata)

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Mon, 21 Apr 2003, Ann Hess wrote:

> I am using rbind to concatenate two dataframes, but after the rbind I get
> a strange "double" index.
> 
> I am using rbind a number of times to make one large dataset.  Is there a
> way to prevent the "double" index?  Or is there some other way to
> concatenate the data (it looks like merge only works by columns)?
> 
> Here is an example of the "double" index.
> 
> >numbers<-(1:5)
> >letters<-matrix(c("a","b","c","d","e"),5,1)
> >data<-data.frame(letters,numbers)
> >doubledata<-rbind(data,data)
> > doubledata
>    letters numbers
> 1        a       1
> 2        b       2
> 3        c       3
> 4        d       4
> 5        e       5
> 11       a       1
> 22       b       2
> 33       c       3
> 44       d       4
> 55       e       5
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From rpeng at stat.ucla.edu  Mon Apr 21 19:46:52 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Mon, 21 Apr 2003 10:46:52 -0700 (PDT)
Subject: [R] using update( ) in a function?
In-Reply-To: <20030421172352.5B7EB3B88F@mbox2.su.se>
Message-ID: <Pine.GSO.4.10.10304211046080.27528-100000@quetelet.stat.ucla.edu>

I believe this is bug PR#1861.  Not sure what the workaround is.

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Mon, 21 Apr 2003, Mahmood ARAI wrote:

> Hello, 
> 
> using the function "update()" in the following function
> does not work. 
> 
> # a function for running a model:  x1 ~ x2
> # by updating the original model: fm1 <- lm(y ~ x1 + x2,data=df)
> # update(fm1, x1 ~ . -x1, data=df) works at the command line
> # but not in the function below. 
> 
> 
> R>   foo <- function(fm,x,df)
> +     {
> +     update(fm, x ~ . -x,data=df)
> +     }
> R>
> R>
> R>  df1 <- data.frame(y= 1:10, x1=(1:10)^2, x2=sqrt(1:10)^3)
> R>  fm1 <- lm(y ~ x1+x2, data=df1)
> R>
> R>  foo(fm1, x1, df1)
> Error in eval(expr, envir, enclos) : Object "x" not found
> R>  update(fm1, x1 ~ . -x1,data=df1) 
> 
> Call:
> lm(formula = x1 ~ x2, data = df1) 
> 
> Coefficients:
> (Intercept)           x2
>     -7.753        3.242 
> 
> any idea? 
> 
> thanks!
> mahmood arai
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From p.dalgaard at biostat.ku.dk  Mon Apr 21 19:54:05 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 21 Apr 2003 19:54:05 +0200
Subject: [R] index after rbind
In-Reply-To: <3EA41DAC.6070408@pdf.com>
References: <Pine.GSO.4.55.0304211015540.2788@liberator.stat.colostate.edu>
	<3EA41DAC.6070408@pdf.com>
Message-ID: <x27k9nspmq.fsf@biostat.ku.dk>

Spencer Graves <spencer.graves at pdf.com> writes:

>  > df1 <- data.frame(a=1:2)
>  > df2 <- rbind(df1, df1)
>  > df2
>     a
> 1  1
> 2  2
> 11 1
> 22 2
>  > rownames(df2) <- 1:4
> 
> hope this helps. spencer graves

...and this is not a bug. Data frames should have unique rownames, so
rbind.data.frame does this internally:

    while (any(xj <- duplicated(rlabs))) rlabs[xj] <- paste(rlabs[xj],
        1:sum(xj), sep = "")

[Just for fun, have a look at 
  df1 <- data.frame(a=1:2)
  df2 <- rbind(df1, df1, df1)
  rbind(df2,df2)
]

However, it might be considered slightly unfortunate that there is no
way to turn this off, even when the next thing you're going to do is to
set new rownames.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From jfox at mcmaster.ca  Mon Apr 21 19:48:42 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 21 Apr 2003 13:48:42 -0400
Subject: [R] index after rbind
In-Reply-To: <3EA41DAC.6070408@pdf.com>
References: <Pine.GSO.4.55.0304211015540.2788@liberator.stat.colostate.edu>
Message-ID: <5.0.2.1.0.20030421134245.00afae30@mcmail.cis.mcmaster.ca>

Dear Ann,

To elaborate Spencer's answer slightly, R requires that the row names of a 
data frame be unique. That's why it generated different row names for the 
rows of the two data frames given as arguments to rbind.

Again, the question is what you want to do here. You could generate more 
meaningful row names (e.g., "A1" - "A5", "B1" - "B5" for your original 
example) if this seems appropriate, but they have to be unique.

John

At 09:34 AM 4/21/2003 -0700, Spencer Graves wrote:
> > df1 <- data.frame(a=1:2)
> > df2 <- rbind(df1, df1)
> > df2
>    a
>1  1
>2  2
>11 1
>22 2
> > rownames(df2) <- 1:4
>
>hope this helps. spencer graves
>
>Ann Hess wrote:
>>I am using rbind to concatenate two dataframes, but after the rbind I get
>>a strange "double" index.
>>I am using rbind a number of times to make one large dataset.  Is there a
>>way to prevent the "double" index?  Or is there some other way to
>>concatenate the data (it looks like merge only works by columns)?
>>Here is an example of the "double" index.
>>
>>>numbers<-(1:5)
>>>letters<-matrix(c("a","b","c","d","e"),5,1)
>>>data<-data.frame(letters,numbers)
>>>doubledata<-rbind(data,data)
>>>doubledata
>>    letters numbers
>>1        a       1
>>2        b       2
>>3        c       3
>>4        d       4
>>5        e       5
>>11       a       1
>>22       b       2
>>33       c       3
>>44       d       4
>>55       e       5
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox


From andrea.malagoli at magnitudecapital.com  Mon Apr 21 19:59:56 2003
From: andrea.malagoli at magnitudecapital.com (Andrea Malagoli)
Date: Mon, 21 Apr 2003 10:59:56 -0700
Subject: [R] R 1.7.0 Windows binary build released
Message-ID: <7EE095E2138E5A4D94FD51F6CFADF1480356E1C9@ehost005.intermedia.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030421/6fda44b0/attachment.pl

From ayalahec at msu.edu  Mon Apr 21 20:18:18 2003
From: ayalahec at msu.edu (Hector L. Ayala-del-Rio)
Date: Mon, 21 Apr 2003 14:18:18 -0400
Subject: [R] multiv library
Message-ID: <A03919E6-7425-11D7-A090-000393DB5846@msu.edu>

Hi
   I am not sure if this question if appropriate for this forum but here 
it goes.
I was trying to do PCA analysis using the multiv library and I realized 
that this particular library contains 8 methods of PCA which use 
different correlation covariance structures and normalization of the 
data.  When I analyze one particular data set with the 8 different 
methods I get different results in terms of the graphical display and 
percentage of the variance explained.  My question which method is more 
appropriate under what circumstances.  If somebody knows a reference 
that talks about the 8 different methods mentioned in documentation of 
this library please let me know. I am familiar with the differences 
between a correlation and a covariance matrix, but not with the other 
ones.  If you think that I should post this message in a different 
mailing list, please let me know.

Thanks and apologies if there is any information in the archives that I 
did not find :-).

Hector

H?ctor L. Ayala-del-R?o, Ph.D.
Center for Microbial Ecology &
Center for Genomic and Evolutionary Studies
on Microbial Life at Low Temperatures
Michigan State University
545 Plant & Soil Sciences Building
East Lansing, MI 48824-1325
Phone: 517-353-9021
Fax: 517-353-2917


From mschwartz at medanalytics.com  Mon Apr 21 20:29:11 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 21 Apr 2003 13:29:11 -0500
Subject: [R] R 1.7.0 Windows binary build released
In-Reply-To: <7EE095E2138E5A4D94FD51F6CFADF1480356E1C9@ehost005.intermedia.net>
Message-ID: <001901c30833$e871c3f0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Andrea
Malagoli
>Sent: Monday, April 21, 2003 1:00 PM
>To: r-announce at stat.math.ethz.ch
>Subject: [R] R 1.7.0 Windows binary build released
>
>
>FYI, I installed R.1.7.0 on my WinXP laptop and I am
>getting an unspecified error when starting Rgui that
>prevents it from working. You may have received this
>notice already.
> 
>- Andrea Malagoli

Andrea,

When you say "unspecified error", does that mean that R just won't
startup or are you getting a particular error message or some other
symptom(s) that can help us help you?

I am running R 1.7.0 on a WinXP Pro laptop without problem.

Also, for future reference, this type of message should be posted to
r-help (r-help at stat.math.ethz.ch), not to r-announce.

Regards,

Marc Schwartz


From chrysopa at insecta.ufv.br  Mon Apr 21 20:49:45 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Mon, 21 Apr 2003 15:49:45 -0300
Subject: [R] Difficult to compare models
Message-ID: <200304211549.45206.chrysopa@insecta.ufv.br>

Hi,

I have the follow situation in a ancova analysis:

y (count data)
x1 (continuous data)
x2 (qualitative data)

x2 have 10 levels (a,b,c,d,e,f,g,h,i,j)

I make the model

m1 <- glm(y~x1*x2, family=poisson)

then I want to remove the levels h, i and j (make these levels with 
intercept = 0 and slope = 0)

A make a new datafile without these levels. This new table is smallest than 
the original table.

I refit the model:

m2 <- glm(y~x1*x2, family=poisson)

Then I want to compare m1 with m2, I need to know if the removing of the 3 
levels are significant. But howto compare this if the total GL and the total 
deviance are different.

Existe another mean to make this? Maybe using offset? How?

Thanks for all
Ronaldo

-- 
You can observe a lot just by watching.  -- Yogi Berra
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From pgilbert at bank-banque-canada.ca  Mon Apr 21 20:52:20 2003
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Mon, 21 Apr 2003 14:52:20 -0400
Subject: [R] Re: Validation of R
References: <OFEA39FB05.FE747744-ON85256D0C.0058B914@bd.com>
	<OFEA39FB05.FE747744-ON85256D0C.0058B914@bd.com>
	<5.0.0.25.1.20030419102529.03d0abf0@pop.jcu.edu.au>
Message-ID: <3EA43DE4.68F66242@bank-banque-canada.ca>

I think there may be some exaggeration of how much effort and co-ordination is
needed in order to "validate" R (at least in a non official sense). The QA tools
already in R are incredible good. What is need is for people to actually use
them. If you make a package with code in the tests directory and in that code
you compare results with known results, and stop() if there is an error, then
the package will fail to build and will produce an error message indicating a
problem. Furthermore, the QA tools for checking documentation are exceptional.
If you make the package interesting enough that others may want to use it, and
submit it to CRAN, then the tests are run as part of the development cycle (I
believe) so the feedback to R core is automatic (although debugging may get
bounced back to you, especially if the problem is your code and not R itself).

For tests which may not be of special interest to others, you can set this up
yourself to run automatically and indicate only when there is a problem. In
addition to the tests in my packages on CRAN I have tests that I run myself for
days. These do simulations, estimations, compare results with known results, or
at least previous results, and do calculations multiple ways to test that
results are the same (for example, that the roots of a state space model are the
same as the roots of an equivalent ARMA model). I run about six hours of these
regularly on Linux and on Solaris with a few R release candidates and try to run
the whole suite at least once before a new release. This does not take any
"hands on time," it just takes computer time. On Linux I start it before going
to work (R 1.7.0beta was being released in the morning, my time) and the main
part is done when I get home. The hands on time is to devise meaningful,
comprehensive tests (and to debug when there are problems).

There may be less work involved in doing (un-official) validation than there is
in advertising how much is actually being done. Perhaps the simplest approach is
for individuals to put together packages of tests with descriptions that explain
the extent of the testing which is done, and then submit the packages to CRAN.

Paul Gilbert
Head Statistician/Statisticien en chef, 
Department of Monetary and Financial Analysis, 
     /D?partement des ?tudes mon?taires et financiers, 
Bank of Canada/Banque du Canada

Richard Rowe wrote:
> 
> OK - to hard reality.
> 
> R has become mainstream among practitioners BECAUSE IT IS
> GOOD.  Practitioners have been voting with their feet/time for years, but
> with recent publicity the tide is becoming a flood.
> 
> At some stage we (as in the R community, not the over-worked core) are
> going to have to do something to 'protect' our members in the commercial
> community (and with the push of 'accountability' and its legions of
> analphabet clerks into the academic/research community soon the rest of us).
> 
> I suggest that those interested in 'validation' form a group and set about
> systematically 'validating' R processes.
> Prebuilt 'evil' datasets (like Anscombe) and simulation using a range of
> different pseudorandom generators to generate data is probably the best
> way.  I once attended a lecture by John Tukey where he described the
> 'tests' a measure should be put through wrt input structures (I remember
> one was characterised as a 'rabbit punch', another as 'knee-in-the-groin'),
> such a repertoire of exercises could be put in place.  Testers need to
> recognise that standard functions can be exposed to the weirdest
> distributions when they are called as an intermediate step in another
> calculation.
> Code needs to do exactly what it is documented to do, and to squawk loudly
> when asked to do what it doesn't.
> 
> I am sure those who have built so much code would really appreciate getting
> a note from the validating group confirming it has been tested and hasn't
> broken down, or else getting a note documenting exactly where and how code
> doesn't work as expected ...
> 
> R is open source.  We all have access to the code.  We could also have open
> source published test datasets and outcomes ... which would actually
> present a challenge to the COTS industry to match.
> 
> If it is to happen then someone who feels strongly about this needs to get
> the ball rolling, and there would probably need to be a sympathetic conduit
> into/from the core.
> 
> For QA purposes the 'testers' will need to be independent of the
> 'producers' ...
> 
> Richard Rowe
> Senior Lecturer
> Department of Zoology and Tropical Ecology, James Cook University
> Townsville, Queensland 4811, Australia
> fax (61)7 47 25 1570
> phone (61)7 47 81 4851
> e-mail: Richard.Rowe at jcu.edu.au
> http://www.jcu.edu.au/school/tbiol/zoology/homepage.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From zhuw at mail.smu.edu  Mon Apr 21 21:04:27 2003
From: zhuw at mail.smu.edu (Wang, Zhu)
Date: Mon, 21 Apr 2003 14:04:27 -0500
Subject: [R] nonlinear equation solver?
Message-ID: <0FBE46098704A242B0DC8FEC4169F9978140F1@s31xs3.systems.smu.edu>

Thanks to Roger Peng and Peter Dalgaard who pointed to me the function "uniroot" which is what I am looking for. 
I am grateful for the trick by Ravi Varadhan who directly lead me to using "optim" for solving the nonlinear equation by minimizing the square of the function.
 
Zhu Wang
 
Statistical Science Department
SMU

	-----Original Message----- 
	From: Roger Peng [mailto:rpeng at stat.ucla.edu] 
	Sent: Mon 4/21/2003 12:24 PM 
	To: Wang, Zhu 
	Cc: r-help at stat.math.ethz.ch 
	Subject: Re: [R] nonlinear equation solver?


From tlumley at u.washington.edu  Mon Apr 21 21:11:23 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 21 Apr 2003 12:11:23 -0700 (PDT)
Subject: [R] using update( ) in a function?
In-Reply-To: <Pine.GSO.4.10.10304211046080.27528-100000@quetelet.stat.ucla.edu>
Message-ID: <Pine.A41.4.44.0304211133450.124622-100000@homer03.u.washington.edu>

On Mon, 21 Apr 2003, Roger Peng wrote:

> I believe this is bug PR#1861.  Not sure what the workaround is.

No, the code as given doesn't get as far as that

> On Mon, 21 Apr 2003, Mahmood ARAI wrote:
>
> > Hello,
> >
> > using the function "update()" in the following function
> > does not work.
> >
> > # a function for running a model:  x1 ~ x2
> > # by updating the original model: fm1 <- lm(y ~ x1 + x2,data=df)
> > # update(fm1, x1 ~ . -x1, data=df) works at the command line
> > # but not in the function below.
> >
> >
> > R>   foo <- function(fm,x,df)
> > +     {
> > +     update(fm, x ~ . -x,data=df)
> > +     }
> > R>
> > R>
> > R>  df1 <- data.frame(y= 1:10, x1=(1:10)^2, x2=sqrt(1:10)^3)
> > R>  fm1 <- lm(y ~ x1+x2, data=df1)
> > R>
> > R>  foo(fm1, x1, df1)
> > Error in eval(expr, envir, enclos) : Object "x" not found

The main problem here is that the argument `x' is only going to have the
*value* of x1, where you need the symbol x1.  On top of that,
	update(fm, x ~ . -x,data=df)
uses the symbol `x' rather than its value, so even if its value were
correct it wouldn't work.

This works
> foo<-function(model,term,data){
+ ff<-substitute(term~.-term)
+ update(model,ff,data=data)
+ }
> data(trees)
> a<-lm(Girth~Height+Volume,data=trees)
> foo(a,Height,data=trees)

Call:
lm(formula = Height ~ Volume, data = data)

Coefficients:
(Intercept)       Volume
    69.0034       0.2319

but is not recommended style, as you are defeating the call-by-value
semantics of R.  A better version is
> bar<-function(model,term,data){
+ ff<-substitute(x~.-x,list(x=as.name(term)))
+  update(model,ff,data=data)
+ }
> bar(a,"Height",data=trees)

Call:
lm(formula = Height ~ Volume, data = data)

Coefficients:
(Intercept)       Volume
    69.0034       0.2319

and you could have versions that allowed `term' to be a quoted name or
expression rather than a string.

	-thomas


From rab at nauticom.net  Mon Apr 21 22:09:42 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Mon, 21 Apr 2003 16:09:42 -0400
Subject: [R] Anyone Familiar with Using arima function with exogenous
 variables?
In-Reply-To: <20030421162307.GA13477@sonny.eddelbuettel.com>
References: <3EA3FCB9.1090607@nauticom.net> <3EA40337.7030206@pdf.com>
	<3EA41D0C.5040701@nauticom.net>
	<20030421162307.GA13477@sonny.eddelbuettel.com>
Message-ID: <3EA45006.1030209@nauticom.net>

Dirk Eddelbuettel wrote:

>Why don't you try simulation?  
>
>Create some data under the 'null' you're trying to get to, say, y <-
>seq(1,n) + arima.error where arima.error could be as simple as an AR(1) or
>MA(1). Then estimate the model, using 90% or 95% of the data and evaluate
>the forecast to the retained 10% or 5%. Repeat the DGP creation, estimation,
>forecast evaluation steps N (say 500) times and you should have a good idea
>about the merits of predict.arima.
>
>Dirk
>
>  
>
I simulated a simple model:

y[t] - c = phi*(y[t-1] - c) + b*x[t] + e[t]

where the errors e are i.i.d. and normal. The coefficient of x is just 
b=1 (x is just an increasing linear trend). I used arima.sim to simulate 
y with phi=0.5. There was no intercept so c = 0. When I used arima to 
estimate the model coefficients, the estimates are very close to what 
you would expect. The coefficient for x was near 1, the intercept was 
very close to zero, and so forth. So my problem must be in making the 
forecast. I would have thought the forecast for the next time point 
would be:

y[t+1]' = c' + phi'*(y[t] - c') + b'*x[t+1]

where y[t+1]' is the forecast, c' is the estimated intercept, phi' is 
the estimated ar coefficient, and b' is the estimated coefficient for 
the exogenous variable.

So if I have 200 observations and I want to estimate for time t = 201, I 
would use y[200] and x[200] and I would have my forecast. But 
predict.Arima produces a different forecast (which looks more reasonable 
to me).

If I estimate a simple AR(2) model, the same method produces exactly the 
forecast given by predict.Arima.

I've studied predict.Arima. Unfortunately for my understanding, it uses 
KalmanForecast and I don't see the details. It passes the arma 
information to KalmanForecast, gets a prediction and to this adds the 
intercept and the product of the exogenous variable and corresponding 
estimated coefficient.

What is so different by just having one exogenous variable compared to 
just a simple AR(1)?

Rick B.


From TyagiAnupam at aol.com  Mon Apr 21 22:36:13 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Mon, 21 Apr 2003 16:36:13 EDT
Subject: [R] Re: Validation of R
Message-ID: <a1.376fa859.2bd5b03d@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030421/2eb7d3a5/attachment.pl

From f0z6305 at labs.tamu.edu  Mon Apr 21 22:43:22 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Mon, 21 Apr 2003 15:43:22 -0500
Subject: [R] Anyone familiar with Cumulants or good reference books?
Message-ID: <002401c30846$a7154db0$8bd75ba5@IE.TAMU.EDU>

Hey, R-listers

I want to get some statistical books on Cumulants for 
studying.
So will you please give me some suggestions on
these related books?

Thanks for your point.

Fred


From fharrell at virginia.edu  Mon Apr 21 22:46:07 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon, 21 Apr 2003 16:46:07 -0400
Subject: [R] Dates in read.spss
Message-ID: <20030421164607.34f50583.fharrell@virginia.edu>

I am using read.spss in the foreign package to read an SPSS save file.  For date variables I get huge values such as 11489990400.  Does anyone know how to convert these values to R POSIXct date objects?  Thanks in advance -Frank

platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    6.1              
year     2002             
month    11               
day      01               
language R                

Package: foreign
Priority: recommended
Version: 0.5-10
Date: 2003-03-01

---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From rossini at blindglobe.net  Mon Apr 21 22:57:12 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Mon, 21 Apr 2003 13:57:12 -0700
Subject: [R] Re: Validation of R
In-Reply-To: <a1.376fa859.2bd5b03d@aol.com> (TyagiAnupam@aol.com's message
 of "Mon, 21 Apr 2003 16:36:13 EDT")
References: <a1.376fa859.2bd5b03d@aol.com>
Message-ID: <87he8rpo0n.fsf@jeeves.blindglobe.net>

TyagiAnupam at aol.com writes:


> In a message dated 4/21/03 3:07:20 PM Eastern Daylight Time, 
> pgilbert at bank-banque-canada.ca writes:
>
>> There may be less work involved in doing (un-official) validation than there 
>> is
>> in advertising how much is actually being done. Perhaps the simplest 
>> approach is
>> for individuals to put together packages of tests with descriptions that 
>> explain
>> the extent of the testing which is done, and then submit the packages to 
>> CRAN.
>> 
>
> Another suggestion to address the issue of validation in the long-term:
>
> 1) "Validation" of scientific research takes the form of peer-review, perhaps 
> it is possible to come-up with a similar (not same) process for publishing 
> software, while maintaining the openness.

Note that the journal of statistical software
(http://www.jstatsoft.org/) already does this.

> 2)  We can also think of contribution to open source software as academic 
> contribution

We can.  I am personally aware of at least one major statistics
department that has decided that this is definitely not the case (and
aware of another that has).

best,
-tony

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center 
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 
CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}


From rolf at math.unb.ca  Mon Apr 21 23:07:53 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 21 Apr 2003 18:07:53 -0300 (ADT)
Subject: [R] help.start in R-1.7.0 with Netscape 7.0.
Message-ID: <200304212107.h3LL7rP6004500@erdos.math.unb.ca>


No avuncular advice has been forthcoming from the list about
my problem with getting html-help, but I've been fiddling around
with it myself and have had a certain amount of insight.  (???)

The source of the problem seems to be the way that the variable
isLocal is defined in browseURL():

	isLocal <- length(grep("^(localhost|):",
                          Sys.getenv("DISPLAY"))) > 0

This seems to make isLocal FALSE in any context in which I work.

For instance, I am currently sitting at an NCD Xwindows terminal,
logged into host ``erdos''.  If I execute

	> Sys.getenv("DISPLAY")

I get
              DISPLAY 
"131.202.169.153:0.0"

the string of digits being the IP address of the terminal.  Not
a "^(localhost|):" in sight.

I thought to rectify this --- in a kludgy and perhaps dangerous
way --- by creating for myself a local version of browseURL()
in which isLocal is always TRUE.  But a funny thing happened:

I ***still*** got the annoying phenomenon of Netscape's trying
to open a new browser window (and wanting a new ``profile'')
every time I asked for help on another function.

To investigate a bit, I created a local version of help() in
which I could stick some browser() calls to find out the values
of certain variables.  Blow me down, but didn't things now
work just fine!  Took out the browser() calls; things still
worked.  Removed the local help() --- back to not working.

Even more mysterious to me is the fact that if I just put in
a local help(), by doing

	> help <- help

then things don't work.  But (ah-ha!) the way I created my local copy
of help() was to make a local ascii file of the code of help() (with
a ``help <- '' added at the beginning) and then source this file.
When this procedure is followed, things ***do*** work!

This applies even though

	> all.equal(help,get("help",pos=grep("base",search()))

yields TRUE, so that nothing has actually changed in my local copy.

So help() doesn't find the local copy of browseURL() unless there is
also a local copy of help() --- and that local copy needs to have
been created by sourcing a text file!!!  This doesn't make any sense
to me.  It verges on the mystical.  What on earth is going on?

More to the point is there any way that I can persuade help()
that ``isLocal'' should be taken to be TRUE?

I don't follow the rationale of ``isLocal'' anyhow.  If I'm sitting
at machine melvin, but am typing away into a window that is connected
to host clyde, and I start R in that window, then help.start() will
invoke the Netscape that lives on clyde.  (Steps must of course have
been taken to permit clyde to open a Netscape window on melvin's
display, but that's all done in the normal course of events.)  Hence
the Netscape that gets fired up will look for the *.html help files
on clyde and everything will work just as if I were sitting at
clyde's console.  So why would ``isLocal'' ***ever*** need to be
FALSE?

				cheers,

					Rolf Turner


From tlumley at u.washington.edu  Mon Apr 21 23:17:31 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 21 Apr 2003 14:17:31 -0700 (PDT)
Subject: [R] Dates in read.spss
In-Reply-To: <20030421164607.34f50583.fharrell@virginia.edu>
Message-ID: <Pine.A41.4.44.0304211415490.21612-100000@homer14.u.washington.edu>

On Mon, 21 Apr 2003, Frank E Harrell Jr wrote:

> I am using read.spss in the foreign package to read an SPSS save file.
> For date variables I get huge values such as 11489990400.  Does anyone
> know how to convert these values to R POSIXct date objects?  Thanks in
> advance -Frank
>

I believe it is

ISOdate(1584,10,14)+11489990400

that is, the dates are seconds since 14 October 1584

I don't know if R and SPSS necessarily agree on how long ago that was on
all machines, though.

	-thomas


From p.dalgaard at biostat.ku.dk  Mon Apr 21 23:39:03 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 21 Apr 2003 23:39:03 +0200
Subject: [R] Dates in read.spss
In-Reply-To: <20030421164607.34f50583.fharrell@virginia.edu>
References: <20030421164607.34f50583.fharrell@virginia.edu>
Message-ID: <x2y923r0nc.fsf@biostat.ku.dk>

Frank E Harrell Jr <fharrell at virginia.edu> writes:

> I am using read.spss in the foreign package to read an SPSS save file.  For date variables I get huge values such as 11489990400.  Does anyone know how to convert these values to R POSIXct date objects?  Thanks in advance -Frank

Google is your friend. 3rd item from a search on spss+dates is

Statistical Packages at MIMAS: SPSS - date handling and the Year ...
Conclusions. SPSS stores dates internally as elapsed seconds since 00:00:00
on 14 October 1582, the first allowable date being 15 October 1582.

So who's born Nov.21 1946?

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From rmshee0 at email.uky.edu  Mon Apr 21 23:41:58 2003
From: rmshee0 at email.uky.edu (Sheetz, Michael)
Date: Mon, 21 Apr 2003 17:41:58 -0400
Subject: [R] R on HP/HPUX IA-64
Message-ID: <7D1BD77F4206B9468B26D409CA587CFD317D1F@e2kbe1.ad.uky.edu>

Does the current version of R run on HP/HPUX IA-64 Itanium processors?


From edd at debian.org  Mon Apr 21 23:58:47 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 21 Apr 2003 16:58:47 -0500
Subject: [R] R on HP/HPUX IA-64
In-Reply-To: <7D1BD77F4206B9468B26D409CA587CFD317D1F@e2kbe1.ad.uky.edu>
References: <7D1BD77F4206B9468B26D409CA587CFD317D1F@e2kbe1.ad.uky.edu>
Message-ID: <20030421215847.GA16581@sonny.eddelbuettel.com>

On Mon, Apr 21, 2003 at 05:41:58PM -0400, Sheetz, Michael wrote:
> Does the current version of R run on HP/HPUX IA-64 Itanium processors?

Can't vouch for the HPUX part, but the page 

   http://buildd.debian.org/build.php?pkg=r-base&arch=ia64

tells you that R has been built successfully ever since Debian started
recording the outcomes of our automated build daemons, or about eighteen
months ago. So gcc and friends work fine, but I wouldn't now what compilers
and libraries are used in HPUX.

Dirk

-- 
Don't drink and derive. Alcohol and algebra don't mix.


From d.scott at auckland.ac.nz  Tue Apr 22 00:13:07 2003
From: d.scott at auckland.ac.nz (David Scott)
Date: Tue, 22 Apr 2003 10:13:07 +1200 (NZST)
Subject: [R] help.start in R-1.7.0 with Netscape 7.0.
In-Reply-To: <200304211232.h3LCWC2k023471@erdos.math.unb.ca>
Message-ID: <Pine.LNX.4.44.0304221007150.31213-100000@stat10.stat.auckland.ac.nz>

On Mon, 21 Apr 2003, Rolf Turner wrote:

> 
> I'm experiencing a new and annoying phenomenon which seems to consist
> of an unfortunate interaction between R-1.7.0 and netscape version 7.
> 
> When I invoke help.start(), a netscape window duly appears
> with the browser pointed at the file .../R/doc/html/index.html
> as one would hope and expect.
> 
> However if I then ask for help on a function, e.g.
> 
> 	> help(glm)
> 
> the help does NOT get displayed in the existing netscape window.
> Instead, up pops a small window asking me to ``Select User
> Profile''.  If I click on ``Start Netscape 7.0'' in this small
> window, I get a message saying ``Netscape 7.0 cannot use the profile
> ``rolf'' because it is in use.  Please choose another profile or
> create a new one.''
> 
I think this is a thoughtful new feature of Netscape---I have encountered 
this sort of catch 22 from Netscape on a linux box when I have not been 
interacting with R at all. I simply wanted to use Netscape but it said 
dscott was in use and I had to create a new user profile. Subsequently I 
have to choose from dscott or the new profile I was forced to create. 
Possibly if you do create a new profile, you might be able to use rolf on 
your use of Netscape for help in R

David Scott




_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
		The University of Auckland, PB 92019
		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz 


Graduate Officer, Department of Statistics

Webmaster, New Zealand Statistical Association:
        http://www.stat.auckland.ac.nz/nzsa/


From edd at debian.org  Tue Apr 22 00:16:30 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 21 Apr 2003 17:16:30 -0500
Subject: [R] R on HP/HPUX IA-64
In-Reply-To: <20030421215847.GA16581@sonny.eddelbuettel.com>
References: <7D1BD77F4206B9468B26D409CA587CFD317D1F@e2kbe1.ad.uky.edu>
	<20030421215847.GA16581@sonny.eddelbuettel.com>
Message-ID: <20030421221630.GA16807@sonny.eddelbuettel.com>

On Mon, Apr 21, 2003 at 04:58:47PM -0500, Dirk Eddelbuettel wrote:
> On Mon, Apr 21, 2003 at 05:41:58PM -0400, Sheetz, Michael wrote:
> > Does the current version of R run on HP/HPUX IA-64 Itanium processors?
> 
> Can't vouch for the HPUX part, but the page 
> 
>    http://buildd.debian.org/build.php?pkg=r-base&arch=ia64
> 
> tells you that R has been built successfully ever since Debian started
> recording the outcomes of our automated build daemons, or about eighteen
> months ago. So gcc and friends work fine, but I wouldn't now what compilers

s/now/know/

> and libraries are used in HPUX.

And I forgot to add that the logfiles include the results of the normal
regression testing, which is fairly extensive.

Dirk

-- 
Don't drink and derive. Alcohol and algebra don't mix.


From spencer.graves at pdf.com  Tue Apr 22 00:25:21 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 21 Apr 2003 15:25:21 -0700
Subject: [R] Anyone familiar with Cumulants or good reference books?
References: <002401c30846$a7154db0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <3EA46FD1.9010903@pdf.com>

Any book on Edgeworth expansions will discuss cumulants.  Also, Kendall 
and Stuart, vol. 1, discuss cumulants.

hope this helps.  spencer graves

Feng Zhang wrote:
> Hey, R-listers
> 
> I want to get some statistical books on Cumulants for 
> studying.
> So will you please give me some suggestions on
> these related books?
> 
> Thanks for your point.
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From d.scott at auckland.ac.nz  Tue Apr 22 00:31:04 2003
From: d.scott at auckland.ac.nz (David Scott)
Date: Tue, 22 Apr 2003 10:31:04 +1200 (NZST)
Subject: [R] Anyone familiar with Cumulants or good reference books?
In-Reply-To: <002401c30846$a7154db0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <Pine.LNX.4.44.0304221027330.31213-100000@stat10.stat.auckland.ac.nz>

On Mon, 21 Apr 2003, Feng Zhang wrote:

> Hey, R-listers
> 
> I want to get some statistical books on Cumulants for 
> studying.
> So will you please give me some suggestions on
> these related books?
> 

You are talking about classical statistical theory. I suggest as a 
starting point Kendall and Stuart, Advanced Theory of Statistics. I think 
this is in Volume 1. I am not familiar enough with it (and am not in my 
office to check), but I would be surprised if you didn't find enough to 
satisfy your needs in Lukacs, Characteristic Functions.

David Scott


_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
		The University of Auckland, PB 92019
		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz 


Graduate Officer, Department of Statistics

Webmaster, New Zealand Statistical Association:
        http://www.stat.auckland.ac.nz/nzsa/


From nirmalg at psu.edu  Tue Apr 22 01:24:02 2003
From: nirmalg at psu.edu (Nirmal Govind)
Date: Mon, 21 Apr 2003 19:24:02 -0400 (EDT)
Subject: [R] significant terms in spline model using GAM
Message-ID: <200304212324.h3LNO2202173@webmail2.cac.psu.edu>

Hi.. I'm using gam() to fit a spline model for a data set that has two predictor
variables (say A and B). The results indicate that the higher order interaction
terms are significant. The R^2 jumps from .5 to .9 when I change the maximum
order for the interaction from 10 to 15 (i.e. (AB)^10 to (AB)^15). Is there any
way of finding out which of the terms in the model are really "significant" so
that I could drop some of the terms from the model?

Thanks,
nirmal


From andy_liaw at merck.com  Tue Apr 22 02:15:44 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 21 Apr 2003 20:15:44 -0400
Subject: [R] significant terms in spline model using GAM
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FA15@usrymx25.merck.com>

Doing subset selection purely based on statistical significance this way is
known to be very problematic, to put it mildly.  I'd suggest that you read
up on Prof. Harrell's recent book, Regression Modeling Strategies, on how to
do appropriate model selection.

Andy

> -----Original Message-----
> From: Nirmal Govind [mailto:nirmalg at psu.edu]
> Sent: Monday, April 21, 2003 7:24 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] significant terms in spline model using GAM
> 
> 
> Hi.. I'm using gam() to fit a spline model for a data set 
> that has two predictor
> variables (say A and B). The results indicate that the higher 
> order interaction
> terms are significant. The R^2 jumps from .5 to .9 when I 
> change the maximum
> order for the interaction from 10 to 15 (i.e. (AB)^10 to 
> (AB)^15). Is there any
> way of finding out which of the terms in the model are really 
> "significant" so
> that I could drop some of the terms from the model?
> 
> Thanks,
> nirmal
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From fharrell at virginia.edu  Tue Apr 22 02:19:16 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Mon, 21 Apr 2003 20:19:16 -0400
Subject: [R] significant terms in spline model using GAM
In-Reply-To: <200304212324.h3LNO2202173@webmail2.cac.psu.edu>
References: <200304212324.h3LNO2202173@webmail2.cac.psu.edu>
Message-ID: <20030421201916.0f5c72ff.fharrell@virginia.edu>

On Mon, 21 Apr 2003 19:24:02 -0400 (EDT)
Nirmal Govind <nirmalg at psu.edu> wrote:

> Hi.. I'm using gam() to fit a spline model for a data set that has two predictor
> variables (say A and B). The results indicate that the higher order interaction
> terms are significant. The R^2 jumps from .5 to .9 when I change the maximum
> order for the interaction from 10 to 15 (i.e. (AB)^10 to (AB)^15). Is there any
> way of finding out which of the terms in the model are really "significant" so
> that I could drop some of the terms from the model?
> 
> Thanks,
> nirmal
> 

Dropping insignificant terms in that way is usually bad statistical practice.

---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From andy_liaw at merck.com  Tue Apr 22 03:48:21 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 21 Apr 2003 21:48:21 -0400
Subject: [R] randomForest crash?
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FA16@usrymx25.merck.com>

Karen,

There were a couple of stupid errors in 3.4-4.  I've uploaded a patched
release, 3.4-5, to CRAN.  Your example now runs without problem.

However, you probably are not using the function correctly, even though the
new version runs without problem.  The response you are using, V217, is
numeric with values 1 and 2.  randomForest() will think that you actually
have numerical response, and thus fit a regression model, rather than
classification.  To do classification, the response *must* be factor.

Last but not least, it's a good idea to upgrade R: if not for the new
features, at least for the bug fixes.  

Cheers,
Andy

> From: Karen.Chancellor at asu.edu [mailto:Karen.Chancellor at asu.edu]
> 
> Hi Andy,
> Here is the data.frame, and my command is
>     lung.rf <- randomForest(V217 ~ ., data=tlAS216cda, 
> importance=TRUE,
>           proximity=TRUE)
> 
> Thanks for checking it on your machine.
> Also, I have R-1.5 on a linux6.1 machine. Will this version 
> of randomForests 
> run on that machine? If not, is there one that will?
> Thanks. 
> Karen
> 
> Quoting "Liaw, Andy" <andy_liaw at merck.com>:
> 
> > Hi Karen,
> > 
> > I have not seen such problem, nor heard similar report.  
> All I can say
> > is
> > that we have used the package on much larger data sets without
> > problem.
> > 
> > As the R developers say, the best way to get bugs fixed is 
> by crashing
> > the
> > developer's machine.  If you can send me the data (without 
> column/row
> > labels, if need be), I can try and see if it crashes R on 
> my machine. 
> > Other
> > than that, there's not much I can offer.
> > 
> > Cheers,
> > Andy
> > 
> > > -----Original Message-----
> > > From: Karen.Chancellor at asu.edu [mailto:Karen.Chancellor at asu.edu]
> > > Sent: Monday, April 21, 2003 2:57 AM
> > > To: r-help at stat.math.ethz.ch
> > > Subject: [R] randomForest crash?
> > > 
> > > 
> > > I am attempting to use randomForests to look for interesting genes
> > in
> > > microarray data with 216genes, 2 classes and 52 samples. My 
> > > data.frame 
> > > is 52x217 with the last column, V217 being the class(1 or 2).
> > > 
> > > When I try
> > >         lung.rf <- randomForest(V217 ~ ., data=tlSA216cda,
> > importance=
> > >                 TRUE, proximity = TRUE)
> > > the GUI crashes. 
> > > 
> > > I am running R-1.6.2 under windo$e98, and most recent version 
> > > of randomForest.
> > > Your ideas appreciated.
> > > Karen
> > > 
> > > 
> > > .-  --.  ....-  -.-.  -.-.
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > > 
> > 
> > 
> --------------------------------------------------------------
> ----------------
> > Notice: This e-mail message, together with any attachments, contains
> > information of Merck & Co., Inc. (Whitehouse Station, New 
> Jersey, USA)
> > that may be confidential, proprietary copyrighted and/or legally
> > privileged, and is intended solely for the use of the individual or
> > entity named on this message.  If you are not the intended 
> recipient,
> > and have received this message in error, please immediately 
> return this
> > by e-mail and then delete it.
> > 
> > 
> ==============================================================
> ================
> > 
> > 
>


From p.connolly at hortresearch.co.nz  Tue Apr 22 03:51:15 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue, 22 Apr 2003 13:51:15 +1200
Subject: [R] How do I get 10^4 to become 10000?
Message-ID: <20030422015115.GA14368@hortresearch.co.nz>

Of course, that's as trivial as it gets on the command line, but I
can't work out how to get a column of numbers that are entered as
"10^5" from its 'character' format into a numeric one?

I feel a bit embarrassed asking such a simple question.  Too much
Easter....

Thanks



-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


From mschwartz at medanalytics.com  Tue Apr 22 05:23:08 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 21 Apr 2003 22:23:08 -0500
Subject: [R] How do I get 10^4 to become 10000?
In-Reply-To: <20030422015115.GA14368@hortresearch.co.nz>
Message-ID: <004401c3087e$7fd91320$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Patrick
Connolly
>Sent: Monday, April 21, 2003 8:51 PM
>To: R-help
>Subject: [R] How do I get 10^4 to become 10000?
>
>
>Of course, that's as trivial as it gets on the command line, 
>but I can't work out how to get a column of numbers that are 
>entered as "10^5" from its 'character' format into a numeric one?
>
>I feel a bit embarrassed asking such a simple question.  Too 
>much Easter....
>
>Thanks
> 
>Patrick Connolly


For an individual value you can use:

> eval(parse(text = "10 ^ 5"))
[1] 1e+05


However, that simple approach does not work with a vector, since the
'text' argument is treated as if it were single lines in an input
file.  Thus you need to do something like this to loop through the
vector elements:

# create the character vector
cv <- c("10 ^ 5", "10 ^ 4", "10 ^ 8")

# function to convert char vector elements to numeric
convtext <- function(x) eval(parse(text = x))

# use sapply to convert the vector
sapply(cv, convtext, USE.NAMES = FALSE)
[1] 1e+05 1e+04 1e+08


HTH,

Marc Schwartz


From p.connolly at hortresearch.co.nz  Tue Apr 22 05:54:07 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Tue, 22 Apr 2003 15:54:07 +1200
Subject: [R] How do I get 10^4 to become 10000?
In-Reply-To: <004401c3087e$7fd91320$0201a8c0@MARC>
References: <20030422015115.GA14368@hortresearch.co.nz>
	<004401c3087e$7fd91320$0201a8c0@MARC>
Message-ID: <20030422035407.GC14368@hortresearch.co.nz>

On Mon, 21-Apr-2003 at 10:23PM -0500, Marc Schwartz wrote:


|> For an individual value you can use:
|> 
|> > eval(parse(text = "10 ^ 5"))
|> [1] 1e+05
|> 
|> 
|> However, that simple approach does not work with a vector, since the
|> 'text' argument is treated as if it were single lines in an input
|> file.  Thus you need to do something like this to loop through the
|> vector elements:
|> 
|> # create the character vector
|> cv <- c("10 ^ 5", "10 ^ 4", "10 ^ 8")
|> 
|> # function to convert char vector elements to numeric
|> convtext <- function(x) eval(parse(text = x))
|> 
|> # use sapply to convert the vector
|> sapply(cv, convtext, USE.NAMES = FALSE)
|> [1] 1e+05 1e+04 1e+08

That's precisely what I needed to know.  Thanks

Thanks also to Tony Plate, Ray Brownrigg, and Robin Hankin for
reminding me of the 'text' argument to parse().

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


From r.hankin at auckland.ac.nz  Tue Apr 22 06:07:39 2003
From: r.hankin at auckland.ac.nz (Robin Hankin)
Date: Tue, 22 Apr 2003 16:07:39 +1200
Subject: [R] lexical scope
Message-ID: <200304220407.h3M47dXu016904@r.hankin.sges.auckland.ac.nz>

Hi everyone

another documented feature that was a bit unexpected for me:

R> x <- 19
R> f <- function(t){t+x}
R> f(100)
[1] 119

--as expected: x is visible from within f()
..but...


R> g <- function(a){x <- 1e99 ; return(f(a))}
R> g(4)
[1] 23

--the "x" that is visible from within g() is just 19, which is not the
  one I expected it to find.


R> rm(x)
R> g(4)
Error in f(a) : Object "x" not found

--g() looks in the first search path place and finds it empty,
  returning an error.


QUESTIONS:
Why doesn't g()  "keep looking" ?
How do I tell g() where to find x?
Where to look for documentation for this?

 

-- 

Robin Hankin, Lecturer,
School of Geography and Environmental Science
Tamaki Campus
Private Bag 92019 Auckland
New Zealand

r.hankin at auckland.ac.nz
tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042


From laurent at cbs.dtu.dk  Tue Apr 22 07:31:36 2003
From: laurent at cbs.dtu.dk (Laurent Gautier)
Date: Tue, 22 Apr 2003 07:31:36 +0200
Subject: [R] lexical scope
In-Reply-To: <200304220407.h3M47dXu016904@r.hankin.sges.auckland.ac.nz>
References: <200304220407.h3M47dXu016904@r.hankin.sges.auckland.ac.nz>
Message-ID: <20030422053136.GB28956423@genome.cbs.dtu.dk>

On Tue, Apr 22, 2003 at 04:07:39PM +1200, Robin Hankin wrote:
> Hi everyone
> 
> another documented feature that was a bit unexpected for me:
> 
> R> x <- 19
> R> f <- function(t){t+x}
> R> f(100)
> [1] 119
> 
> --as expected: x is visible from within f()
> ..but...
> 
> 
> R> g <- function(a){x <- 1e99 ; return(f(a))}
> R> g(4)
> [1] 23
> 
> --the "x" that is visible from within g() is just 19, which is not the
>   one I expected it to find.
> 
> 
> R> rm(x)
> R> g(4)
> Error in f(a) : Object "x" not found
> 
> --g() looks in the first search path place and finds it empty,
>   returning an error.
> 
> 
> QUESTIONS:
> Why doesn't g()  "keep looking" ?
> How do I tell g() where to find x?
> Where to look for documentation for this?
> 

(TENTATIVE) ANSWERS:

1- becase the enclosing frame for f is .GlobalEnv.
2- f <- function(t){t+get("x", envir=parent.frame())}
3- R language definition p.22 is a place to start


Hopin' it helps,




L.
>  
> 
> -- 
> 
> Robin Hankin, Lecturer,
> School of Geography and Environmental Science
> Tamaki Campus
> Private Bag 92019 Auckland
> New Zealand
> 
> r.hankin at auckland.ac.nz
> tel 0064-9-373-7599 x6820; FAX 0064-9-373-7042
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
--------------------------------------------------------------
currently at the National Yang-Ming University in Taipei, Taiwan
--------------------------------------------------------------
Laurent Gautier			CBS, Building 208, DTU
PhD. Student			DK-2800 Lyngby,Denmark	
tel: +45 45 25 24 89		http://www.cbs.dtu.dk/laurent


From ma at ne.su.se  Tue Apr 22 09:54:33 2003
From: ma at ne.su.se (Mahmood Arai)
Date: Tue, 22 Apr 2003 09:54:33 +0200
Subject: [R] thanks! using update( ) in a function?
References: <Pine.A41.4.44.0304211133450.124622-100000@homer03.u.washington.edu>
Message-ID: <3EA4F539.8040906@ne.su.se>

Thank you very much for your suggestion.
mahmood arai

Thomas Lumley wrote:

>On Mon, 21 Apr 2003, Roger Peng wrote:
>
>  
>
>>I believe this is bug PR#1861.  Not sure what the workaround is.
>>    
>>
>
>No, the code as given doesn't get as far as that
>
>  
>
>>On Mon, 21 Apr 2003, Mahmood ARAI wrote:
>>
>>    
>>
>>>Hello,
>>>
>>>using the function "update()" in the following function
>>>does not work.
>>>
>>># a function for running a model:  x1 ~ x2
>>># by updating the original model: fm1 <- lm(y ~ x1 + x2,data=df)
>>># update(fm1, x1 ~ . -x1, data=df) works at the command line
>>># but not in the function below.
>>>
>>>
>>>R>   foo <- function(fm,x,df)
>>>+     {
>>>+     update(fm, x ~ . -x,data=df)
>>>+     }
>>>R>
>>>R>
>>>R>  df1 <- data.frame(y= 1:10, x1=(1:10)^2, x2=sqrt(1:10)^3)
>>>R>  fm1 <- lm(y ~ x1+x2, data=df1)
>>>R>
>>>R>  foo(fm1, x1, df1)
>>>Error in eval(expr, envir, enclos) : Object "x" not found
>>>      
>>>
>
>The main problem here is that the argument `x' is only going to have the
>*value* of x1, where you need the symbol x1.  On top of that,
>	update(fm, x ~ . -x,data=df)
>uses the symbol `x' rather than its value, so even if its value were
>correct it wouldn't work.
>
>This works
>  
>
>>foo<-function(model,term,data){
>>    
>>
>+ ff<-substitute(term~.-term)
>+ update(model,ff,data=data)
>+ }
>  
>
>>data(trees)
>>a<-lm(Girth~Height+Volume,data=trees)
>>foo(a,Height,data=trees)
>>    
>>
>
>Call:
>lm(formula = Height ~ Volume, data = data)
>
>Coefficients:
>(Intercept)       Volume
>    69.0034       0.2319
>
>but is not recommended style, as you are defeating the call-by-value
>semantics of R.  A better version is
>  
>
>>bar<-function(model,term,data){
>>    
>>
>+ ff<-substitute(x~.-x,list(x=as.name(term)))
>+  update(model,ff,data=data)
>+ }
>  
>
>>bar(a,"Height",data=trees)
>>    
>>
>
>Call:
>lm(formula = Height ~ Volume, data = data)
>
>Coefficients:
>(Intercept)       Volume
>    69.0034       0.2319
>
>and you could have versions that allowed `term' to be a quoted name or
>expression rather than a string.
>
>	-thomas
>
>  
>


From simon at stats.gla.ac.uk  Tue Apr 22 11:27:02 2003
From: simon at stats.gla.ac.uk (Simon Wood)
Date: Tue, 22 Apr 2003 10:27:02 +0100 (BST)
Subject: [R] significant terms in spline model using GAM
In-Reply-To: <200304212324.h3LNO2202173@webmail2.cac.psu.edu>
Message-ID: <Pine.SOL.3.96.1030422101621.4139A-100000@moon.stats.gla.ac.uk>


> Hi.. I'm using gam() to fit a spline model for a data set that has two predictor
> variables (say A and B). The results indicate that the higher order interaction
> terms are significant. The R^2 jumps from .5 to .9 when I change the maximum
> order for the interaction from 10 to 15 (i.e. (AB)^10 to (AB)^15). 
- This is perhaps not the best way of thinking about the interaction terms,
there are certainly no terms like (AB)^10 or (AB)^15 in the basis produced
by s(A,B,k=10 or 15). 
> Is there any
> way of finding out which of the terms in the model are really "significant" so
> that I could drop some of the terms from the model?
The default model selection used by gam() is GCV, a mean square error
criterion, and I'm not sure how useful it is to mix model selection by
hypothesis testing with GCV model selection. I think that your results
indicate that in GCV terms your original choice of k=10 was too
restrictive. 

If you want to do model selection by hypothesis testing you can -
s(A,B,k=10,fx=TRUE) is nested within s(A,B,k=15,fx=TRUE), for example -
however the process is not automated - you would have to construct
F-ratios (or deviance differences) yourself from the response data and the
fitted values. 

best,
Simon

_____________________________________________________________________
> Simon Wood simon at stats.gla.ac.uk        www.stats.gla.ac.uk/~simon/
>>  Department of Statistics, University of Glasgow, Glasgow, G12 8QQ
>>>   Direct telephone: (0)141 330 4530          Fax: (0)141 330 4814


From Bernhard.Pfaff at drkw.com  Tue Apr 22 11:44:18 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Tue, 22 Apr 2003 11:44:18 +0200
Subject: [R] R 1.7.0: Startup error: Error in "class<-"(*tmp*, value = Class)
	: couldn't find function "objWithClass"
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB9004730350@ibfftce505.is.de.dresdnerkb.com>

Dear R-List member,

I have installed the new version of R on my PC (see system details below). I
can start the RGui with http_proxy succesfully. However, I do encounter two
problems:

1)
After starting the Rgui the following error message is displayed (vertical
dots represent omissions of output):

R : Copyright 2003, The R Development Core Team
Version 1.7.0  (2003-04-16)
.
.
.
.

Error in "class<-"(*tmp*, value = Class) : 
        couldn't find function "objWithClass"

Furthermore, Sys.getenv() reveals:

Warning message: 
package methods in options("defaultPackages") was not found

However, this package is included in "C:\Program
Files\R\rw1070\library\base\R\Rprofile".
code-snippet:

.
.
.
local({dp <- as.vector(Sys.getenv("R_DEFAULT_PACKAGES"))
       if(identical(dp, "")) # marginally faster to do methods last
           dp <- c("ts", "nls", "modreg", "mva", "ctest", "methods",
"tools")
#           dp <- c("methods", "ctest")
       else if(identical(dp, "NULL")) dp <- character(0)
       else dp <- strsplit(dp, ",")[[1]]
       dp <- sub("[[:blank:]]*([[:alnum:]]+)", "\\1", dp) # strip whitespace
       options(defaultPackages = dp)
    })
.
.
.
 

2)
By executing update.packages(), the CRAN connection is established and the
packages to be updated are downloaded, but not installed. Instead, I obtain
the error message:

Error in loadNamespace(name) : package `tools' does not have a name space

I have stored the packages in a different directory ("C:\Program
Files\R\library") that is set in
"C:\Program Files\R\rw1070\etc\RProfile" as:
.libPaths("C:/PROGRA~1/R/library")


Any hints how to resolve these problems are warmly appreciated.

Bernhard


System information:

OS
"Windows_NT"
Os2LibPath
"C:\\WINNT\\system32\\os2\\dll;"
Path 
"C:\\Perl\\bin\\;C:\\WINNT\\system32;C:\\WINNT;C:\\WINNT\\System32\\Wbem;C:\
\Program Files\\Microsoft SQL
Server\\80\\Tools\\BINN;C:\\Progra~1\\R\\tools;C:\\Tcl\\bin;C:\\miktex\\mikt
ex\\bin\\;C:\\MinGW\\bin;C:\\Perl\\bin;C:\\HTMLHelp;"
PATHEXT
".COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.tcl"
PROCESSOR_ARCHITECTURE
"x86"
PROCESSOR_IDENTIFIER
"x86 Family 15 Model 1 Stepping 2, GenuineIntel"
ProgramFiles
"C:\\Program Files"
R_HOME
"C:\\PROGRA~1\\R\\rw1070"
R_USER
"c:\\emacs-21.2" 
 



----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.


From rdiaz at cnio.es  Tue Apr 22 12:22:39 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Tue, 22 Apr 2003 12:22:39 +0200
Subject: [R] lexical scope
In-Reply-To: <200304220407.h3M47dXu016904@r.hankin.sges.auckland.ac.nz>
References: <200304220407.h3M47dXu016904@r.hankin.sges.auckland.ac.nz>
Message-ID: <200304221222.39764.rdiaz@cnio.es>

Dear Robin,

In terms of documentation I have found John Fox's "Frames, environments, and 
scope in R and S-PLUS" (available at
http://socserv.socsci.mcmaster.ca/jfox/Books/companion/appendix-scope.pdf) to 
be an excellent document. 

"Lexical scope and statistical computing" by Gentleman & Ihaka (at the J. 
Comp. Graph. Stat., 2000, 9: 491-508, though I think a pdf of a preprint can 
be found somewhere in the net) contains more general discussion and more 
ellaborate examples.

Finally, section 10.7 of "An introduction to R" has brief discussion of these 
issues, but that should answer the specific questions you asked.


With regards to your specific situation:
x is a "free variable" for f, and f will look for it in (at? I'll never get 
this right) the environment where it was defined (the global environment in 
your example).

When you call f from g, f still looks for x in the environment where it was 
defined; first time (before you rm(x)) x is 19 there; the second time, there 
is no x anymore.

This behavior is different from that of S-PLUS.

Hope this helps,

Ram?n


On Tuesday 22 April 2003 06:07, Robin Hankin wrote:
> Hi everyone
>
> another documented feature that was a bit unexpected for me:
>
> R> x <- 19
> R> f <- function(t){t+x}
> R> f(100)
> [1] 119
>
> --as expected: x is visible from within f()
> ..but...
>
>
> R> g <- function(a){x <- 1e99 ; return(f(a))}
> R> g(4)
> [1] 23
>
> --the "x" that is visible from within g() is just 19, which is not the
>   one I expected it to find.
>
>
> R> rm(x)
> R> g(4)
> Error in f(a) : Object "x" not found
>
> --g() looks in the first search path place and finds it empty,
>   returning an error.
>
>
> QUESTIONS:
> Why doesn't g()  "keep looking" ?
> How do I tell g() where to find x?
> Where to look for documentation for this?

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://bioinfo.cnio.es/~rdiaz


From Bernhard.Pfaff at drkw.com  Tue Apr 22 12:57:11 2003
From: Bernhard.Pfaff at drkw.com (Pfaff, Bernhard)
Date: Tue, 22 Apr 2003 12:57:11 +0200
Subject: [R] R 1.7.0: Startup error: Error in "class<-"(*tmp*, value =
    Class) : couldn't find function "objWithClass"
Message-ID: 
    <18D602BD42B7E24EB810D6454A58DB9004730354@ibfftce505.is.de.dresdnerkb.com>

sorry, found the error by myself...a second .libpaths with "C:\Program
Files\R\rw1070\library" seems to be the solution.

Thks.
Bernhard

-----Original Message-----
From: Pfaff, Bernhard [mailto:Bernhard.Pfaff at drkw.com]
Sent: 22 April 2003 11:44
To: 'R'
Subject: [R] R 1.7.0: Startup error: Error in "class<-"(*tmp*, value =
Class) : couldn't find function "objWithClass"


Dear R-List member,

I have installed the new version of R on my PC (see system details below). I
can start the RGui with http_proxy succesfully. However, I do encounter two
problems:

1)
After starting the Rgui the following error message is displayed (vertical
dots represent omissions of output):

R : Copyright 2003, The R Development Core Team
Version 1.7.0  (2003-04-16)
.
.
.
.

Error in "class<-"(*tmp*, value = Class) : 
        couldn't find function "objWithClass"

Furthermore, Sys.getenv() reveals:

Warning message: 
package methods in options("defaultPackages") was not found

However, this package is included in "C:\Program
Files\R\rw1070\library\base\R\Rprofile".
code-snippet:

.
.
.
local({dp <- as.vector(Sys.getenv("R_DEFAULT_PACKAGES"))
       if(identical(dp, "")) # marginally faster to do methods last
           dp <- c("ts", "nls", "modreg", "mva", "ctest", "methods",
"tools")
#           dp <- c("methods", "ctest")
       else if(identical(dp, "NULL")) dp <- character(0)
       else dp <- strsplit(dp, ",")[[1]]
       dp <- sub("[[:blank:]]*([[:alnum:]]+)", "\\1", dp) # strip whitespace
       options(defaultPackages = dp)
    })
.
.
.
 

2)
By executing update.packages(), the CRAN connection is established and the
packages to be updated are downloaded, but not installed. Instead, I obtain
the error message:

Error in loadNamespace(name) : package `tools' does not have a name space

I have stored the packages in a different directory ("C:\Program
Files\R\library") that is set in
"C:\Program Files\R\rw1070\etc\RProfile" as:
.libPaths("C:/PROGRA~1/R/library")


Any hints how to resolve these problems are warmly appreciated.

Bernhard


System information:

OS
"Windows_NT"
Os2LibPath
"C:\\WINNT\\system32\\os2\\dll;"
Path 
"C:\\Perl\\bin\\;C:\\WINNT\\system32;C:\\WINNT;C:\\WINNT\\System32\\Wbem;C:\
\Program Files\\Microsoft SQL
Server\\80\\Tools\\BINN;C:\\Progra~1\\R\\tools;C:\\Tcl\\bin;C:\\miktex\\mikt
ex\\bin\\;C:\\MinGW\\bin;C:\\Perl\\bin;C:\\HTMLHelp;"
PATHEXT
".COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.tcl"
PROCESSOR_ARCHITECTURE
"x86"
PROCESSOR_IDENTIFIER
"x86 Family 15 Model 1 Stepping 2, GenuineIntel"
ProgramFiles
"C:\\Program Files"
R_HOME
"C:\\PROGRA~1\\R\\rw1070"
R_USER
"c:\\emacs-21.2" 
 



----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


----------------------------------------------------------------------
If you have received this e-mail in error or wish to read our e-mail 
disclaimer statement and monitoring policy, please refer to 
http://www.drkw.com/disc/email/ or contact the sender.


From dirkj at rz.uni-leipzig.de  Tue Apr 22 14:07:40 2003
From: dirkj at rz.uni-leipzig.de (Dirk Janssen)
Date: Tue, 22 Apr 2003 14:07:40 +0200 (CEST)
Subject: [R] fisher exact vs. simulated chi-square
Message-ID: <Pine.LNX.4.33.0304221334420.1733-100000@c2d2511.isuew.uni-leipzig.de>


Dear All,

I have a problem understanding the difference between the outcome of a
fisher exact test and a chi-square test (with simulated p.value).

For some sample data (see below), fisher reports p=.02337. The normal
chi-square test complains about "approximation may be incorrect",
because there is a column with cells with very small values. I
therefore tried the chi-square with simulated p-values, but this still
gives p=.04037. I also simulated the p-value myself, using r2dtable,
getting the same result, p=0.04 (approx).

Why is this substantially higher than what the fisher exact says? Do
the two tests make different assumptions? I noticed that the
discrepancy gets smaller when I increase the number of observations
for column A3. Does this mean that the simulated chi-square is still
sensitive to cells with small counts, even though it does not give me
the warning?


Thanks in advance,
Dirk Janssen

------------------------------------------------------------------

> ta <- matrix(c(45,85,27,32,40,34,1,2,1),nc=3,
           dimnames=list(c("A","B","C"),c("A1","A2","A3")))
> ta
  A1 A2 A3
A 45 32  1
B 85 40  2
C 27 34  1

> fisher.test(ta)

	Fisher's Exact Test for Count Data

data:  ta
p-value = 0.02337
alternative hypothesis: two.sided

> chisq.test(ta, simulate=T, B=100000)

	Pearson's Chi-squared test with simulated p-value (based on 1e+05
	replicates)

data:  ta
X-squared = 9.6976, df = NA, p-value = 0.04037

> chisq.test(ta)

	Pearson's Chi-squared test

data:  ta
X-squared = 9.6976, df = 4, p-value = 0.04584

Warning message:
Chi-squared approximation may be incorrect in: chisq.test(ta)


# simulate values by hand, based on r2dtable example
> expected <- outer(rowSums(ta), colSums(ta), "*") / sum(ta)
> meanSqResid <- function(x) mean((x - expected) ^ 2 / expected)
> sum(sapply(r2dtable(100000, rowSums(ta), colSums(ta)), meanSqResid)
      >= meanSqResid(ta))/ 100000
[1] 0.03939

#  is  similar to
> sum(sapply(r2dtable(100000, rowSums(ta), colSums(ta)),
             function(x) { chisq.test(x)$statistic })
      >= 9.6976)/ 100000
[1] 0.04044
There were 50 or more warnings (use warnings() to see the first 50)


From dj at research.bell-labs.com  Tue Apr 22 14:23:20 2003
From: dj at research.bell-labs.com (David James)
Date: Tue, 22 Apr 2003 08:23:20 -0400
Subject: [R] ROracle 0.5-0 package update
Message-ID: <20030422082320.A13042@jessie.research.bell-labs.com>

An update to the ROracle package is now in CRAN.

Version 0.5-0

* This version has an experimental dynamic SQL binding to data
  frames.  SQL statements can be "prepared" (parsed and cached for
  improved performance), and columns of data frames bound to them
  for automatic data transfer).  For details see the help() for
  "Oracle", "dbPrepareStatement" and "dbExecStatement".

* Host arrays are now operational. These are buffers used by Oracle's
  internal implementation to reduce network traffic and speed
  up fetches and prepared statements.  Currently fetches use a
  default buffer size (host arrays) of size 500 (previous version
  did no buffering).  **Very preliminary** results suggest performance
  improvements on fetching of about a factor of 2.
  (Note that the maximum size of these buffers is limited to about 
  65K bytes per column.)
 
* dbCommit() and dbRollback() are now explicitly implemented,
  but save points are not (but you may code them through dynamic SQL).

* The precompiler ProC/C++ is now used with the option PARSE=none
  to avoid bogus C errors with some compilers and/or platforms
  (e.g., Mac OS X).

-- 
David A. James
Statistics Research, Room 2C-253            Phone:  (908) 582-3082       
Bell Labs, Lucent Technologies              Fax:    (908) 582-3340
Murray Hill, NJ 09794-0636


From fharrell at virginia.edu  Tue Apr 22 14:46:36 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Tue, 22 Apr 2003 08:46:36 -0400
Subject: [R] Dates in read.spss
In-Reply-To: <x2y923r0nc.fsf@biostat.ku.dk>
References: <20030421164607.34f50583.fharrell@virginia.edu>
	<x2y923r0nc.fsf@biostat.ku.dk>
Message-ID: <20030422084636.20e39fbe.fharrell@virginia.edu>

Many thanks to Scot McNary, Thomas Lumley, and Peter Dalgaard.  
ISOdate(1584,10,14) + x worked like a charm in converting SPSS dates to POSIX.

I have written a little function spss.get that calls read.spss and makes the needed changes in date/time variables.  It also converts integer-valued variables to be stored as integers and associates variable labels with each variable as Hmisc expects (as with sas.get).  spss.get will be in the next version of the Hmisc package.  

read.spss works extremely well for us.  I especially appreciate how it sets up value labels in factors.  It was also able to import an SPSS files that S-Plus 6 could not import properly.  Thanks to Saikat DebRoy for writing read.spss.
---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From gisar at nus.edu.sg  Tue Apr 22 15:04:08 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Tue, 22 Apr 2003 21:04:08 +0800
Subject: [R] fisher exact vs. simulated chi-square
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F247@MBXSRV03.stf.nus.edu.sg>

There is a reason why this is called Fisher's Exact test - it is EXACT.
It calculates all the possible outcomes using permutations. Then it
calculate the p-value as the proportion of number of times of obtaining.
Look for Fisher's Exact test under Section 8a of
http://faculty.vassar.edu/lowry/webtext.html. 

Fisher's test is non-parametric and exact but using permutations can be
computationally intensive. For large counts, the parametric chiquare is
ok. When a cell contains too low a count (what is the default limit), R
correctly complains that chiquare may not be appropriate. Hope this
helps.

Regards, Adai.


-----Original Message-----
From: Dirk Janssen [mailto:dirkj at rz.uni-leipzig.de] 
Sent: Tuesday, April 22, 2003 8:08 PM
To: r-help at stat.math.ethz.ch
Subject: [R] fisher exact vs. simulated chi-square



Dear All,

I have a problem understanding the difference between the outcome of a
fisher exact test and a chi-square test (with simulated p.value).

For some sample data (see below), fisher reports p=.02337. The normal
chi-square test complains about "approximation may be incorrect",
because there is a column with cells with very small values. I therefore
tried the chi-square with simulated p-values, but this still gives
p=.04037. I also simulated the p-value myself, using r2dtable, getting
the same result, p=0.04 (approx).

Why is this substantially higher than what the fisher exact says? Do the
two tests make different assumptions? I noticed that the discrepancy
gets smaller when I increase the number of observations for column A3.
Does this mean that the simulated chi-square is still sensitive to cells
with small counts, even though it does not give me the warning?


Thanks in advance,
Dirk Janssen

------------------------------------------------------------------

> ta <- matrix(c(45,85,27,32,40,34,1,2,1),nc=3,
           dimnames=list(c("A","B","C"),c("A1","A2","A3")))
> ta
  A1 A2 A3
A 45 32  1
B 85 40  2
C 27 34  1

> fisher.test(ta)

	Fisher's Exact Test for Count Data

data:  ta
p-value = 0.02337
alternative hypothesis: two.sided

> chisq.test(ta, simulate=T, B=100000)

	Pearson's Chi-squared test with simulated p-value (based on
1e+05
	replicates)

data:  ta
X-squared = 9.6976, df = NA, p-value = 0.04037

> chisq.test(ta)

	Pearson's Chi-squared test

data:  ta
X-squared = 9.6976, df = 4, p-value = 0.04584

Warning message:
Chi-squared approximation may be incorrect in: chisq.test(ta)


# simulate values by hand, based on r2dtable example
> expected <- outer(rowSums(ta), colSums(ta), "*") / sum(ta) meanSqResid

> <- function(x) mean((x - expected) ^ 2 / expected) 
> sum(sapply(r2dtable(100000, rowSums(ta), colSums(ta)), meanSqResid)
      >= meanSqResid(ta))/ 100000
[1] 0.03939

#  is  similar to
> sum(sapply(r2dtable(100000, rowSums(ta), colSums(ta)),
             function(x) { chisq.test(x)$statistic })
      >= 9.6976)/ 100000
[1] 0.04044
There were 50 or more warnings (use warnings() to see the first 50)

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tlumley at u.washington.edu  Tue Apr 22 15:45:06 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 22 Apr 2003 06:45:06 -0700 (PDT)
Subject: [R] lexical scope
In-Reply-To: <20030422053136.GB28956423@genome.cbs.dtu.dk>
Message-ID: <Pine.A41.4.44.0304220643010.95464-100000@homer06.u.washington.edu>

On Tue, 22 Apr 2003, Laurent Gautier wrote:

> On Tue, Apr 22, 2003 at 04:07:39PM +1200, Robin Hankin wrote:
> > Hi everyone
> >
> > another documented feature that was a bit unexpected for me:
> >
> > R> x <- 19
> > R> f <- function(t){t+x}
> > R> f(100)
> > [1] 119
> >
> > --as expected: x is visible from within f()
> > ..but...
> >
> >
> > R> g <- function(a){x <- 1e99 ; return(f(a))}
> > R> g(4)
> > [1] 23
> >
> > --the "x" that is visible from within g() is just 19, which is not the
> >   one I expected it to find.
> >

Yes. R has lexical, not dynamic, scope.  That is, the lookup depends on
where a function was defined, not where it was called from.

If you need to fake dynamic scope then
a) Try not to
b) Use eval.parent()

	-thomas


From ndey00 at yahoo.com  Tue Apr 22 15:46:07 2003
From: ndey00 at yahoo.com (N Dey)
Date: Tue, 22 Apr 2003 06:46:07 -0700 (PDT)
Subject: [R] Do loop
Message-ID: <20030422134607.54911.qmail@web41302.mail.yahoo.com>

Dear all,

I am doing integration by using integrate(..) command
of R.  Integrand is a function of parameters (say p).
And I ahve to do the integration for p ranging from 10
to 500 (eg p<-10*1:50). And I want to store the
results in a table like.

p	result
10	------
20	------

Is there any easy way to do this. I was trying 
for(p<-10*1:50){integrate(Func, lower = 0, upper =
182)}, but some problem couldn't do it.


> Func<-function(x,p){exp(2*x-(3*p/10))*exp(-(5*x))}
> for(p in 10*1:50){integrate(Func, lower = 0, upper =
182)}
Error in f(x, ...) : Argument "p" is missing, with no
default

Pl. help me, thanking you.

best regards,
N Dey


From tlumley at u.washington.edu  Tue Apr 22 16:00:54 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 22 Apr 2003 07:00:54 -0700 (PDT)
Subject: [R] fisher exact vs. simulated chi-square
In-Reply-To: <Pine.LNX.4.33.0304221334420.1733-100000@c2d2511.isuew.uni-leipzig.de>
Message-ID: <Pine.A41.4.44.0304220648510.95464-100000@homer06.u.washington.edu>

On Tue, 22 Apr 2003, Dirk Janssen wrote:

>
> Dear All,
>
> I have a problem understanding the difference between the outcome of a
> fisher exact test and a chi-square test (with simulated p.value).
>
> For some sample data (see below), fisher reports p=.02337. The normal
> chi-square test complains about "approximation may be incorrect",
> because there is a column with cells with very small values. I
> therefore tried the chi-square with simulated p-values, but this still
> gives p=.04037. I also simulated the p-value myself, using r2dtable,
> getting the same result, p=0.04 (approx).
>
> Why is this substantially higher than what the fisher exact says? Do
> the two tests make different assumptions? I noticed that the
> discrepancy gets smaller when I increase the number of observations
> for column A3. Does this mean that the simulated chi-square is still
> sensitive to cells with small counts, even though it does not give me
> the warning?

Both are exact. I beleive the difference is just the test statistic.

Imagine listing all the possible 3x3 tables with the same margins as
yours.  A test has to sort them into some ordering of distance from the
null and then add up the probabilities for all possible tables further
from the null than yours.

There's more than one way to do this.  Even in the 2x2 case this leads to
ambiguity about how define the two-sided test.  In the 3x3 case it is
worse since there are so many more ways for tables to differ.

chisq.test orders tables according to the chisquare statistic and I think
fisher.test orders them according to their probability under the null
hypothesis.


	-thomas

"An hypothesis that may be true is rejected because it has failed to
predict observable results that have not occurred." Jeffreys (1939)


From gregory.benmenzer at gazdefrance.com  Tue Apr 22 17:15:40 2003
From: gregory.benmenzer at gazdefrance.com (Gregory BENMENZER)
Date: Tue, 22 Apr 2003 16:15:40 +0100
Subject: [R] Sweave
Message-ID: <OF84D20440.66BFF9A2-ON41256D10.0053B2BE@notes.edfgdf.fr>

hello,

I use Sweave and I'd want to plot severall graphics with a loop.

For example,

\begin{figure}
<<fig=TRUE>>
for (i in 1:10) plot(rnorm(100)+i)
@
\end{figure}

When I do that, all graphics are plotted on the same figure and I'd want
Sweave plotted 10 differents figures !

Could you help me  ?

Best regard,

Gr?gory Benmenzer


From jfox at mcmaster.ca  Tue Apr 22 16:32:35 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 22 Apr 2003 10:32:35 -0400
Subject: [R] lexical scope
In-Reply-To: <Pine.A41.4.44.0304220643010.95464-100000@homer06.u.washing
 ton.edu>
References: <20030422053136.GB28956423@genome.cbs.dtu.dk>
Message-ID: <5.1.0.14.2.20030422102545.01e2cb18@mcmail.cis.mcmaster.ca>

Dear Robin,


>On Tue, Apr 22, 2003 at 04:07:39PM +1200, Robin Hankin wrote:
>Hi everyone
>
>another documented feature that was a bit unexpected for me:
>
>  R> x <- 19
>  R> f <- function(t){t+x}
>  R> f(100)
>  [1] 119
>
>  --as expected: x is visible from within f()
>..but...
>
>
>  R> g <- function(a){x <- 1e99 ; return(f(a))}
>  R> g(4)
>  [1] 23
>
>  --the "x" that is visible from within g() is just 19, which is not the
>    one I expected it to find.


A couple of people have pointed out that the source of the difficulty here 
is lexical scoping. One can sometimes take advantage of lexical scoping by 
defining a local function. For your illustration, for example,

 > x <- 19
 > g <- function(a){
+     f <- function(t){t + x}
+     x <- 1e99
+     f(a)
+     }
 > g(4)
[1] 1e+99
 >

Whether or not this solves your problem depends upon whether it's 
reasonable to make f local to g.

John


-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox


From mounier at lmd.polytechnique.fr  Tue Apr 22 16:32:16 2003
From: mounier at lmd.polytechnique.fr (Flore MOUNIER)
Date: Tue, 22 Apr 2003 16:32:16 +0200
Subject: [R] space-time power spectra analysis
Message-ID: <200304221632.16396.mounier@lmd.polytechnique.fr>

Dear R users,
I would like to do a space-time power spectra analysis. Have anybody done it 
before. If yes, with which package?
Thank you in advance for any advices.
Sincerely,
Flore MOUNIER

-- 
Flore MOUNIER
Laboratoire de M?t?orologie Dynamique
Ecole Polytechnique
F 91128 Palaiseau Cedex
T?l:  01-69-33-36-19
Fax:  01-69-33-30-49
e-mail : mounier at lmd.polytechnique.fr


From kris.nackaerts at agr.kuleuven.ac.be  Tue Apr 22 16:49:26 2003
From: kris.nackaerts at agr.kuleuven.ac.be (Kris Nackaerts)
Date: Tue, 22 Apr 2003 16:49:26 +0200
Subject: [R] read.table and decimals
Message-ID: <3EA55676.3070101@agr.kuleuven.ac.be>

Dear,

We are trying to read an asciifile using the read.table() function and 
discovered that only 4 decimals are read. Any idea how to get more decimals?

Kris

-- 
------------------------------------------------------------------------
 
 http://perswww.kuleuven.ac.be/~u0027178/VCard/mycard.php?name=krisn
 
------------------------------------------------------------------------
 Minds are like parachutes, they only work when open


From buyske at stat.rutgers.edu  Tue Apr 22 17:02:22 2003
From: buyske at stat.rutgers.edu (Steve Buyske)
Date: Tue, 22 Apr 2003 11:02:22 -0400
Subject: [R] glmmPQL and additive random effects?
Message-ID: <p05210602bacb01b30d84@[10.0.1.2]>

I'm a bit puzzled by how to write out additive random effects in 
glmmPQL. In my situation, I have a factorial design on two 
(categorical) random factors, A and B. At each combination, I have a 
binary response, y, and two binary fixed covariates, C and D.

If everything were fixed, I would use
	glm(y ~ A + B + C + D, family = binomial)

My first thought was to use
	glmmPQL(y ~ A + B, random = ~ C + D, family = binomial)
but glmmPQL wants to see a grouping variable in the random term. Something like
	glmmPQL(y ~ A + B, random = ~ C + D | CD, family = binomial)
where CD is a a variable combining C and D, eats up all my memory, while
	glmmPQL(y ~ A + B, random = ~ 1 | CD, family = binomial)
doesn't seem like the model I want.

Perhaps this model is too hard to fit, but before I quit this 
approach I want to make sure that I'm not just coding it incorrectly.

Thanks,
Steve Buyske


From bates at stat.wisc.edu  Tue Apr 22 17:35:33 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 22 Apr 2003 10:35:33 -0500
Subject: [R] glmmPQL and additive random effects?
In-Reply-To: <p05210602bacb01b30d84@[10.0.1.2]>
References: <p05210602bacb01b30d84@[10.0.1.2]>
Message-ID: <6rist67dfe.fsf@bates4.stat.wisc.edu>

Steve Buyske <buyske at stat.rutgers.edu> writes:

> I'm a bit puzzled by how to write out additive random effects in
> glmmPQL. In my situation, I have a factorial design on two
> (categorical) random factors, A and B. At each combination, I have a
> binary response, y, and two binary fixed covariates, C and D.
> 
> 
> If everything were fixed, I would use
> 	glm(y ~ A + B + C + D, family = binomial)
> 
> My first thought was to use
> 	glmmPQL(y ~ A + B, random = ~ C + D, family = binomial)
> but glmmPQL wants to see a grouping variable in the random term. Something like
> 	glmmPQL(y ~ A + B, random = ~ C + D | CD, family = binomial)
> where CD is a a variable combining C and D, eats up all my memory, while
> 	glmmPQL(y ~ A + B, random = ~ 1 | CD, family = binomial)
> doesn't seem like the model I want.
> 
> Perhaps this model is too hard to fit, but before I quit this approach
> I want to make sure that I'm not just coding it incorrectly.

lme and, by extension, glmmPQL do not handle crossed random effects
easily.  

You must create a factor of the same length as y, A, B, C, and D with
a single level

const = factor(rep(1, length(y)))

then use the non-obvious formulation

glmmPQL(y ~ A + B, random = list(const = pdBlocked(pdIdent(~ C - 1), 
  pdIdent(~ D - 1))))


From tlumley at u.washington.edu  Tue Apr 22 17:49:30 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 22 Apr 2003 08:49:30 -0700 (PDT)
Subject: [R] Do loop
In-Reply-To: <20030422134607.54911.qmail@web41302.mail.yahoo.com>
Message-ID: <Pine.A41.4.44.0304220840130.51324-100000@homer33.u.washington.edu>

On Tue, 22 Apr 2003, N Dey wrote:

> Dear all,
>
> I am doing integration by using integrate(..) command
> of R.  Integrand is a function of parameters (say p).
> And I ahve to do the integration for p ranging from 10
> to 500 (eg p<-10*1:50). And I want to store the
> results in a table like.
>
> p	result
> 10	------
> 20	------
>
> Is there any easy way to do this. I was trying
> for(p<-10*1:50){integrate(Func, lower = 0, upper =
> 182)}, but some problem couldn't do it.
>
>
> > Func<-function(x,p){exp(2*x-(3*p/10))*exp(-(5*x))}
> > for(p in 10*1:50){integrate(Func, lower = 0, upper =
> 182)}
> Error in f(x, ...) : Argument "p" is missing, with no
> default

You need to pass the `p' argument.

One way is
 Func<-function(x,p){exp(2*x-(3*p/10))*exp(-(5*x))}
 results<-numeric(50)
 for(i in 1:50){
	result[i]<-integrate(Func,lower=0, upper=182,p=10*i)$value
}

More elegantly
 Func<-function(x,p){exp(2*x-(3*p/10))*exp(-(5*x))}
 results<-sapply(10*(1:50), function(p) integrate(Func,
				lower=0,upper=182,p=p)$value)



	-thomas


From rab at nauticom.net  Tue Apr 22 18:37:34 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Tue, 22 Apr 2003 12:37:34 -0400
Subject: [R] Anyone Familiar with Using arima function with exogenous
   variables?
In-Reply-To: <3EA547E3.7060409@bank-banque-canada.ca>
References: <3EA3FCB9.1090607@nauticom.net> <3EA40337.7030206@pdf.com>
	<3EA41D0C.5040701@nauticom.net>
	<20030421162307.GA13477@sonny.eddelbuettel.com>
	<3EA45006.1030209@nauticom.net> <3EA547E3.7060409@bank-banque-canada.ca>
Message-ID: <3EA56FCE.90109@nauticom.net>

Paul Gilbert wrote:

>> So if I have 200 observations and I want to estimate for time t = 
>> 201, I would use y[200] and x[200] and I would have my forecast. But 
>
> ^^^^^^
> Don't you mean x[201] ?
>

Yes, I meant x[201].

I found what I was looking for (although it's not in the R 
documentation). When Y is differenced, fitted by an AR(1) with one 
exogenous variable with no intercept, the model is written as:

(1-B)Y[t] = wX[t] + e[t]/(1 - phi B)

Solving for Y[t]:

(1 - phi B)(1 - B) Y[t] = w(1 - phi B) X[t] + e[t]

(1 - phi B - B + phi B2) Y[t] = w(X[t] - phi X[t-1]) + e[t]

Y[t] = (1 + phi)Y[t-1] - phi Y[t-2] + w(X[t] - phi X[t-1]) + e[t]

So the 1-step ahead forecast is:

Y[t]' = (1 + phi')Y[t-1] - phi' Y[t-2] + w'(X[t] - phi' X[t-1])


Rick B.


From krcabrer at perseus.unalmed.edu.co  Tue Apr 22 18:42:08 2003
From: krcabrer at perseus.unalmed.edu.co (Kenneth Cabrera)
Date: Tue, 22 Apr 2003 11:42:08 -0500
Subject: [R] Problem with pixmap on R 1.7.0?
Message-ID: <oprn1h0iilfaouaq@200.24.8.4>

Hi R users:
I got the following message when I use the pixmap library
on R 1.7.0 over w2K platform (on R 1.6.2 it runs right).

pixmapGrey(matrix(c(0,1),128,128))
Error in .class1(object) : Object "from" not found

I download the library .zip file from:

http://cran.r-project.org/bin/windows/contrib/1.7/pixmap_0.3-2.zip

Other question:

When I try to "Install package(s) from bioconductor" I got the
following message:

local({a<-CRAN.packages(CRAN=getOption("BIOC"))
+ install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a, 
CRAN=getOption("BIOC"))})

trying URL `http://www.bioconductor.org/bin/windows/contrib/1.7/PACKAGES'
Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  : 
cannot open: HTTP status was `404 Not Found'

Are the packages in other path of www.bioconductor.org? Which one?

Thank you for your help.

Kenneth


From ligges at statistik.uni-dortmund.de  Tue Apr 22 18:47:39 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 22 Apr 2003 18:47:39 +0200
Subject: [R] read.table and decimals
In-Reply-To: <3EA55676.3070101@agr.kuleuven.ac.be>
References: <3EA55676.3070101@agr.kuleuven.ac.be>
Message-ID: <3EA5722B.4050800@statistik.uni-dortmund.de>

Kris Nackaerts wrote:
> Dear,
> 
> We are trying to read an asciifile using the read.table() function and 
> discovered that only 4 decimals are read. Any idea how to get more 
> decimals?

It reads *all* decimals, if the format is specified correctly.
I guess you printed the read in data in an inappropriate way to see full 
accuracy.

Try to print it with
   format(x, digits=22)
and see that everythinbg was read in ....

Uwe Ligges


From rolf at math.unb.ca  Tue Apr 22 19:02:19 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 22 Apr 2003 14:02:19 -0300 (ADT)
Subject: [R] help.start in R-1.7.0 with Netscape 7.0.
Message-ID: <200304221702.h3MH2JoZ028530@erdos.math.unb.ca>


The recent discussion on lexical scoping has enlightened me
as regards the phenomenon that I found so puzzling yesterday:

> So help() doesn't find the local copy of browseURL() unless there is
> also a local copy of help() --- and that local copy needs to have
> been created by sourcing a text file!!!  This doesn't make any sense
> to me.  It verges on the mystical.  What on earth is going on?

Thomas Lumley's succinct explanation 

> ... the lookup depends on where a function was defined, not where
> it was called from.

made the light click on.  No mystical behaviour at all.

The silence as regards the substance of my question has been
deafening, however.

***HOW*** do I get help()/browseURL() to acquire a sensible idea of
``isLocal'' so that Netscape does not keep demanding new windows and
new ``profiles''?

Does this behaviour not amount to a bug in help()/browseURL()?

				cheers,

					Rolf Turner
					rolf at math.unb.ca


From saml at demog.berkeley.edu  Tue Apr 22 23:01:29 2003
From: saml at demog.berkeley.edu (SamL)
Date: Tue, 22 Apr 2003 14:01:29 -0700 (PDT)
Subject: [R] Quick query on output
Message-ID: <Pine.SUN.4.10.10304221356240.7799-100000@davis.demog.berkeley.edu>

I am attempting to estimate a very complex glmmPQL model.  I have
(apparently) gotten working syntax.  But, I don't want to wait a long time
only to find I have not made the correct syntax to see the output.  So,
what I've written is:

EXCERPT FROM COMMAND FILE:

glmmPQL(plfp ~ -1 + bmrd4 + bmsd4 + wmrd4 + wmsd4 + bfrd4 + bfsd4 +
             wfrd4 + wfsd4 + y4yrsed + y4age + y4age2,
        data=PLFPANAL,
        random=~ bm4 + wm4 + bf4 + wf4 | state,
        family=binomial,
        weights=wt1)

summary(fm1)

q

END OF EXCERPT FROM COMMAND FILE

I bet the "suummary(fm1)" line is wrong, it was apparently a holdover from
some other code I tried to emulate.  At any rate, what do I do to get the
output?  Have I done enough?  Is something else required?  Assistance or
reassurance greatly appreciated!

Thanks.
Sam


From sean at rootnode.com  Tue Apr 22 23:14:28 2003
From: sean at rootnode.com (R. Sean Bowman)
Date: Tue, 22 Apr 2003 16:14:28 -0500 (CDT)
Subject: [R] converting to factor
Message-ID: <20030422160051.B69267-100000@exigence.rootnode.com>

hello,

I have a list of numbers that I want to convert into factors representing
ranges of values.  For example, if I have

c(2.5, 1.6, 3.2)

I might want a list of factors like

c("<3", "<3", ">3")

I think I can do this by writing a function and using apply, as.matrix,
&c., but I'm looking for a nicer way.  Any help is greatly appreciated.

Thanks!
Sean


From sundar.dorai-raj at pdf.com  Tue Apr 22 23:22:50 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 22 Apr 2003 16:22:50 -0500
Subject: [R] converting to factor
References: <20030422160051.B69267-100000@exigence.rootnode.com>
Message-ID: <3EA5B2AA.4020407@pdf.com>


R. Sean Bowman wrote:
> hello,
> 
> I have a list of numbers that I want to convert into factors representing
> ranges of values.  For example, if I have
> 
> c(2.5, 1.6, 3.2)
> 
> I might want a list of factors like
> 
> c("<3", "<3", ">3")
> 
> I think I can do this by writing a function and using apply, as.matrix,
> &c., but I'm looking for a nicer way.  Any help is greatly appreciated.
> 

See ?cut.

R> cut(c(2.5, 1.6, 3.2), 3)
[1] (2.13,2.67] (1.6,2.13]  (2.67,3.2]
Levels: (1.6,2.13] (2.13,2.67] (2.67,3.2]


From jerome at hivnet.ubc.ca  Tue Apr 22 23:26:48 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Tue, 22 Apr 2003 14:26:48 -0700
Subject: [R] converting to factor
In-Reply-To: <20030422160051.B69267-100000@exigence.rootnode.com>
References: <20030422160051.B69267-100000@exigence.rootnode.com>
Message-ID: <200304222132.OAA04891@hivnet.ubc.ca>


?cut

#E.g.,
cut(c(2.5, 1.6, 3.2),c(-Inf,3,Inf))
#[1] (-Inf,3] (-Inf,3] (3,Inf]

See also the "labels" option of cut().

HTH,
J.

On April 22, 2003 02:14 pm, R. Sean Bowman wrote:
> hello,
>
> I have a list of numbers that I want to convert into factors
> representing ranges of values.  For example, if I have
>
> c(2.5, 1.6, 3.2)
>
> I might want a list of factors like
>
> c("<3", "<3", ">3")
>
> I think I can do this by writing a function and using apply, as.matrix,
> &c., but I'm looking for a nicer way.  Any help is greatly appreciated.
>
> Thanks!
> Sean
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From sundar.dorai-raj at pdf.com  Tue Apr 22 23:28:50 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 22 Apr 2003 16:28:50 -0500
Subject: [R] converting to factor
References: <20030422160051.B69267-100000@exigence.rootnode.com>
Message-ID: <3EA5B412.8030703@pdf.com>



R. Sean Bowman wrote:
> hello,
> 
> I have a list of numbers that I want to convert into factors representing
> ranges of values.  For example, if I have
> 
> c(2.5, 1.6, 3.2)
> 
> I might want a list of factors like
> 
> c("<3", "<3", ">3")
> 
> I think I can do this by writing a function and using apply, as.matrix,
> &c., but I'm looking for a nicer way.  Any help is greatly appreciated.
> 

Sorry, wrong syntax for what you asked for:


R>
R> cut(c(2.5, 1.6, 3.2), breaks = c(-Inf, 3, Inf))
[1] (-Inf,3] (-Inf,3] (3,Inf]
Levels: (-Inf,3] (3,Inf]
R>


From khealy at kieranhealy.org  Tue Apr 22 23:39:14 2003
From: khealy at kieranhealy.org (Kieran Healy)
Date: Tue, 22 Apr 2003 14:39:14 -0700
Subject: [R] Hmisc's aregImpute segfaults R-1.7.0 under linux
Message-ID: <DD09FDBE-750A-11D7-B248-000393A6C440@kieranhealy.org>

Hello -

When trying to use Hmisc library's aregImpute function on R 1.7.0, I 
got the following error -- shown here using the example code from the 
help page --- under both Linux and Mac OS X 10.2.5:

set.seed(3)
x1 <- factor(sample(c('a','b','c'),1000,T))
x2 <- (x1=='b') + 3*(x1=='c') + rnorm(1000,0,2)
x3 <- rnorm(1000)
y  <- x2 + 1*(x1=='c') + .2*x3 + rnorm(1000,0,2)
orig.x1 <- x1[1:250]
orig.x2 <- x2[251:350]
x1[1:250] <- NA
x2[251:350] <- NA

# Use 100 imputations to better check against individual true values
f <- aregImpute(~y + x1 + x2 + x3, n.impute=100)
Iteration:1 Error in whichClosest(pti[j], pti[nai]) : Incorrect number 
of arguments (7), expecting 8 for bincode

I upgraded to the most recent version of Hmisc (verson 1.5-3) on both 
platforms. This fixed the problem on OS X and aregImpute runs fine 
there. But with Hmisc 1.5-3, aregImpute now causes R to segfault on my 
linux box, viz:

f <- aregImpute(~y + x1 + x2 + x3, n.impute=100)
Iteration:1
Process R segmentation fault at Tue Apr 22 14:29:18 2003

I'm running an updated version of SuSE 7.1, if that's relevant. Is this 
a known issue?

Kieran

--
Kieran Healy, http://www.u.arizona.edu/~kjhealy
Asst Professor, Sociology Dept, University of Arizona.


From sean at rootnode.com  Tue Apr 22 23:42:02 2003
From: sean at rootnode.com (sean@rootnode.com)
Date: Tue, 22 Apr 2003 16:42:02 -0500 (CDT)
Subject: [R] converting to factor
In-Reply-To: <200304222132.OAA04891@hivnet.ubc.ca>
Message-ID: <20030422164044.J69267-100000@exigence.rootnode.com>

hello,

wow, thanks to everybody for the prompt response.  I appreciate it!

Sean


From chrysopa at insecta.ufv.br  Tue Apr 22 23:25:11 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Tue, 22 Apr 2003 18:25:11 -0300
Subject: [R] Correct SE in a poisson model.
Message-ID: <200304221825.12010.chrysopa@insecta.ufv.br>

Hi all,

I'm here again with my newbies questions :(

I have a simple example:

count of slugs in two fields.

I need to make a barplot with mean and SE of mean.

So I have:

The mean:
> tapply(slugs,field,mean)
Nursery Rookery 
  1.275   2.275 

The SE:
> tapply(slugs,field,sd)/sqrt(tapply(slugs,field,length))
  Nursery   Rookery 
0.3651264 0.3508004 

If the data has been normally distributed it is correct, but it is 
overdipersed count data.

I make a model

> m.poisson <- glm(slugs~field,family=quasipoisson)

And I have these coefficients:

Coefficients:
             Estimate Std. Error t value Pr(>|t|)  
(Intercept)    0.2429     0.2490   0.976   0.3323  
fieldRookery   0.5790     0.3112   1.861   0.0666 .

The estimate mean = mean
1.275 = exp(0.2429)
2.275 = exp(0.2429+0.5790)

But and the correct standard error of mean? How to obtain this? Exist any 
function for calculate this? Exist another better measure than SE for 
non-normal errors (poisson, quasi, binomial, gamma etc)?


Thanks
Ronaldo

-- 
Without followers, evil cannot spread.
		-- Spock, "And The Children Shall Lead", stardate 5029.5
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From p.connolly at hortresearch.co.nz  Wed Apr 23 00:08:00 2003
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Wed, 23 Apr 2003 10:08:00 +1200
Subject: [R] Default value for title in postscript function
Message-ID: <20030422220800.GF14368@hortresearch.co.nz>

I like the fact that the postscript function enables the possbiility
of a more useful title than before.  However, I'd prefer the default
to be the file name.  

It's very simple for me to make my own postscript function that does
just that simply by setting title = file.  I always use onefile =
TRUE, so it always works (so far).  However, I'm a little reluctant to
do that in case some future changes cause conflicts.  I've been warned
off tinkering with .Internal

My question is: What is the tidiest way of doing such a thing?  Should
I make a private function that calls the standard postscript function,
or should I go the whole hog and make an S4 type method to handle it?

Or would it be simpler for the standard function to be changed
(assuming, of course, there aren't good reasons against doing that)?

best

-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~


From fjmolina at lbl.gov  Wed Apr 23 00:41:09 2003
From: fjmolina at lbl.gov (Francisco J Molina)
Date: Tue, 22 Apr 2003 15:41:09 -0700
Subject: [R] 
Message-ID: <16037.50437.848602.939080@0-e0-98-8a-c5-4a.dhcp.lbl.gov>

Subject: Eliminate repeated components from a vector
X-Mailer: VM 7.00 under 21.4 (patch 6) "Common Lisp" XEmacs Lucid
Reply-To: fjmolina at lbl.gov
FCC: /home/f/.xemacs/mail/sent


Does anyone know how I can eliminate repeated elements from a vector?


From emmanuel.koku at utoronto.ca  Wed Apr 23 00:43:22 2003
From: emmanuel.koku at utoronto.ca (Emmanuel F. Koku)
Date: Tue, 22 Apr 2003 18:43:22 -0400
Subject: [R] Social Network Analysis and R
Message-ID: <1051051402.3ea5c58a8b304@webmail.utoronto.ca>

I'm interested in computing densities of a number of small ego-centred or local 
networks. I've installed both the R program and the sna package.  My next task 
is importing the data into R. 

Our data was entered into Spss in an edgelist format in which each case 
specifies the link between an alter and an ego. For example: 

10101  10102  1 
10101  10103  3 
10102  10104  2 
10201  10203  4 
10203  10204  2 

The following data fragment for example shows an ego-centred network of 2 
persons: 101 and 102. Person 101 for example reports of a closeness of ties 
between alters 01 and 02 = value of 1; alters 01 and 03 - value of 3, etc. 
Similarly Person 102 reports on the closeness of ties between his alters 01 
and 03 = value of 4; and alters 03 and 04=value of 2. 

We have about 350 of these small ego networks represented as 560 cases in 
edgelist format in spss (each line or ego-alter relational link represents a 
case in spss). 

First, how do I write out the commands in R to read the edgelists ? 

Secondly, is there any way to tell R that the first 3 characters of the ego 
and alter values are actually identifiers for the ego networks -- so that 
densities are computed for each these? 

I've begun reading the reference manual on data reading and import facilities 
and hope that would help me get further along. 

thanks in advance - em 

--------------------------------------------------------
Emmanuel F. Koku               emmanuel.koku at utoronto.ca
          Doctoral Candidate - Sociology
          Centre for Urban and Community Studies
             University of Toronto
          455 Spadina Avenue, Toronto, Canada M5S 2G8
Tel: +1-416-425-4936           Fax: +1-416-425-7803

                 NOTE: Effective February 1. 2003
          New email address: emmanuel.koku at utoronto.ca


From s195404 at student.uq.edu.au  Wed Apr 23 00:46:24 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Tue, 22 Apr 2003 22:46:24 +0000
Subject: [R] Eliminating repeated elements in a vector
In-Reply-To: <16037.50437.848602.939080@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
References: <16037.50437.848602.939080@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
Message-ID: <1051051584.3ea5c640809e5@my.uq.edu.au>

> x <- c(1,1,2,3,4,4,5)
> x
[1] 1 1 2 3 4 4 5
> x <- unique(x)
> x
[1] 1 2 3 4 5


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au


Quoting Francisco J Molina <fjmolina at lbl.gov>:

> Subject: Eliminate repeated components from a vector
> X-Mailer: VM 7.00 under 21.4 (patch 6) "Common Lisp" XEmacs Lucid
> Reply-To: fjmolina at lbl.gov
> FCC: /home/f/.xemacs/mail/sent
> 
> 
> Does anyone know how I can eliminate repeated elements from a
> vector?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From sundar.dorai-raj at pdf.com  Wed Apr 23 00:47:17 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 22 Apr 2003 17:47:17 -0500
Subject: [R]
References: <16037.50437.848602.939080@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
Message-ID: <3EA5C675.2030007@pdf.com>



Francisco J Molina wrote:
> Subject: Eliminate repeated components from a vector
> X-Mailer: VM 7.00 under 21.4 (patch 6) "Common Lisp" XEmacs Lucid
> Reply-To: fjmolina at lbl.gov
> FCC: /home/f/.xemacs/mail/sent
> 
> 
> Does anyone know how I can eliminate repeated elements from a vector?
> 

?unique
?duplicated

Sundar


From d.scott at auckland.ac.nz  Wed Apr 23 00:53:17 2003
From: d.scott at auckland.ac.nz (David Scott)
Date: Wed, 23 Apr 2003 10:53:17 +1200 (NZST)
Subject: [R] 
In-Reply-To: <16037.50437.848602.939080@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
Message-ID: <Pine.LNX.4.44.0304231052430.16771-100000@hydra.stat.auckland.ac.nz>

On Tue, 22 Apr 2003, Francisco J Molina wrote:

> Subject: Eliminate repeated components from a vector
> X-Mailer: VM 7.00 under 21.4 (patch 6) "Common Lisp" XEmacs Lucid
> Reply-To: fjmolina at lbl.gov
> FCC: /home/f/.xemacs/mail/sent
> 
> 
> Does anyone know how I can eliminate repeated elements from a vector?
> 

An easy one:

?unique

David Scott

_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
		The University of Auckland, PB 92019
		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz 


Graduate Officer, Department of Statistics

Webmaster, New Zealand Statistical Association:
        http://www.stat.auckland.ac.nz/nzsa/


From andy_liaw at merck.com  Wed Apr 23 02:25:32 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 22 Apr 2003 20:25:32 -0400
Subject: [R] changing dir to network drive in Rgui caused crash (1.7.0)
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FA32@usrymx25.merck.com>

Dear R-help,

Has anyone experienced similar problem?  On WinNT4(sp6), running Rgui from
1.7.0, when try to change directory to some network drive using the "File /
Change dir..." menu, Rgui gets a visit by Dr. Watson.  If I first change dir
to a local drive, then again to a network drive, it works fine.  It also
works fine with setwd() from the command prompt.

Best,
Andy

Andy I. Liaw, PhD
Biometrics Research          Phone: (732) 594-0820
Merck & Co., Inc.              Fax: (732) 594-1565
P.O. Box 2000, RY84-16            Rahway, NJ 07065
mailto:andy_liaw at merck.com



------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, contains 
information of Merck & Co., Inc. (Whitehouse Station, New Jersey, 
USA) that may be confidential, proprietary copyrighted and/or legally 
privileged, and is intended solely for the use of the individual or entity
named on this message. If you are not the intended recipient, and
have received this message in error, please immediately return this by 
e-mail and then delete it.


From mschwartz at medanalytics.com  Wed Apr 23 03:59:10 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 22 Apr 2003 20:59:10 -0500
Subject: [R] changing dir to network drive in Rgui caused crash (1.7.0)
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4FA32@usrymx25.merck.com>
Message-ID: <003a01c3093b$ef41c050$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Liaw, Andy
>Sent: Tuesday, April 22, 2003 7:26 PM
>To: 'R-help at stat.math.ethz.ch'
>Subject: [R] changing dir to network drive in Rgui caused crash
(1.7.0)
>
>
>Dear R-help,
>
>Has anyone experienced similar problem?  On WinNT4(sp6), 
>running Rgui from 1.7.0, when try to change directory to some 
>network drive using the "File / Change dir..." menu, Rgui gets 
>a visit by Dr. Watson.  If I first change dir to a local 
>drive, then again to a network drive, it works fine.  It also 
>works fine with setwd() from the command prompt.
>
>Best,
>Andy


It does not happen on WinXP Pro using 1.7.0, whether I explicitly
enter the network path (ie. \\ServerName\Drive\Folder) in the dialog
or browse to it. 

Are you using a mapped network drive (ie. 'M:') or a non-mapped target
path?

Regards,

Marc Schwartz


From kwan022 at stat.auckland.ac.nz  Wed Apr 23 04:56:41 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 23 Apr 2003 14:56:41 +1200 (NZST)
Subject: [R] Plotting Factors -- Sorting x-axis
Message-ID: <Pine.LNX.4.33.0304231454070.27163-100000@stat56.stat.auckland.ac.nz>

Hi,

Say I have a factor with 20-levels: 1, 2, 3, ..., 20, called foo.

If I do 
  plot(foo)
it will draw a barplot.  But the x-axis is sorted alphanumerically, i.e. 
1, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2, 3, ..., 9, which is not what 
I want.  I'd like to x-axis to be in the order of 1 ~ 20 numerically.  So, 
the question is, how do I change the order on the x-axis in this case?

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From mschwartz at medanalytics.com  Wed Apr 23 05:39:24 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 22 Apr 2003 22:39:24 -0500
Subject: [R] Plotting Factors -- Sorting x-axis
In-Reply-To: <Pine.LNX.4.33.0304231454070.27163-100000@stat56.stat.auckland.ac.nz>
Message-ID: <000001c30949$effa3280$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ko-Kang 
>Kevin Wang
>Sent: Tuesday, April 22, 2003 9:57 PM
>To: R Help
>Subject: [R] Plotting Factors -- Sorting x-axis
>
>
>Hi,
>
>Say I have a factor with 20-levels: 1, 2, 3, ..., 20, called foo.
>
>If I do 
>  plot(foo)
>it will draw a barplot.  But the x-axis is sorted 
>alphanumerically, i.e. 
>1, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2, 3, ..., 9, which 
>is not what 
>I want.  I'd like to x-axis to be in the order of 1 ~ 20 
>numerically.  So, 
>the question is, how do I change the order on the x-axis in this
case?
>
>-- 
>Cheers,
>
>Kevin


How about this:

# Create vector as you have with chars
# Note the factor level values
> x <- factor(as.character(1:20))
> x
 [1] 1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18
[19] 19 20
20 Levels: 1 10 11 12 13 14 15 16 17 18 19 2 20 3 4 ... 9

# Now sort factor levels by numeric value
# Note the factor level values
> x <- factor(x, levels = sort(as.numeric(x)))
> x
 [1] 1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18
[19] 19 20
20 Levels: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ... 20

Now plot(x).

Hope that helps.

Marc Schwartz


From ligges at statistik.uni-dortmund.de  Wed Apr 23 08:50:22 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Apr 2003 08:50:22 +0200
Subject: [R] changing dir to network drive in Rgui caused crash (1.7.0)
In-Reply-To: <003a01c3093b$ef41c050$0201a8c0@MARC>
References: <003a01c3093b$ef41c050$0201a8c0@MARC>
Message-ID: <3EA637AE.9050909@statistik.uni-dortmund.de>

Marc Schwartz wrote:
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Liaw, Andy
>>Sent: Tuesday, April 22, 2003 7:26 PM
>>To: 'R-help at stat.math.ethz.ch'
>>Subject: [R] changing dir to network drive in Rgui caused crash
> 
> (1.7.0)
> 
>>
>>Dear R-help,
>>
>>Has anyone experienced similar problem?  On WinNT4(sp6), 
>>running Rgui from 1.7.0, when try to change directory to some 
>>network drive using the "File / Change dir..." menu, Rgui gets 
>>a visit by Dr. Watson.  If I first change dir to a local 
>>drive, then again to a network drive, it works fine.  It also 
>>works fine with setwd() from the command prompt.
>>
>>Best,
>>Andy
> 
> 
> 
> It does not happen on WinXP Pro using 1.7.0, whether I explicitly
> enter the network path (ie. \\ServerName\Drive\Folder) in the dialog
> or browse to it. 

Works as well on my WinNT4.0 (SP6) installation, starting "as is" and 
with "rgui --vanilla". Does the latter configuration still produce the 
crash for you, Andy?

Uwe Ligges


> Are you using a mapped network drive (ie. 'M:') or a non-mapped target
> path?


From ligges at statistik.uni-dortmund.de  Wed Apr 23 08:54:55 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Apr 2003 08:54:55 +0200
Subject: [R] Social Network Analysis and R
In-Reply-To: <1051051402.3ea5c58a8b304@webmail.utoronto.ca>
References: <1051051402.3ea5c58a8b304@webmail.utoronto.ca>
Message-ID: <3EA638BF.2030806@statistik.uni-dortmund.de>

Emmanuel F. Koku wrote:
> I'm interested in computing densities of a number of small ego-centred or local 
> networks. I've installed both the R program and the sna package.  My next task 
> is importing the data into R. 
> 
> Our data was entered into Spss in an edgelist format in which each case 
> specifies the link between an alter and an ego. For example: 
> 
> 10101  10102  1 
> 10101  10103  3 
> 10102  10104  2 
> 10201  10203  4 
> 10203  10204  2 
> 
> The following data fragment for example shows an ego-centred network of 2 
> persons: 101 and 102. Person 101 for example reports of a closeness of ties 
> between alters 01 and 02 = value of 1; alters 01 and 03 - value of 3, etc. 
> Similarly Person 102 reports on the closeness of ties between his alters 01 
> and 03 = value of 4; and alters 03 and 04=value of 2. 
> 
> We have about 350 of these small ego networks represented as 560 cases in 
> edgelist format in spss (each line or ego-alter relational link represents a 
> case in spss). 
> 
> First, how do I write out the commands in R to read the edgelists ? 
> 
> Secondly, is there any way to tell R that the first 3 characters of the ego 
> and alter values are actually identifiers for the ego networks -- so that 
> densities are computed for each these? 
> 
> I've begun reading the reference manual on data reading and import facilities 
> and hope that would help me get further along. 

[The question arises why you did not finish it before asking.]

See ?read.fwf for importing the data.

Uwe Ligges


From ligges at statistik.uni-dortmund.de  Wed Apr 23 09:32:59 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Apr 2003 09:32:59 +0200
Subject: [R] Default value for title in postscript function
In-Reply-To: <20030422220800.GF14368@hortresearch.co.nz>
References: <20030422220800.GF14368@hortresearch.co.nz>
Message-ID: <3EA641AB.4090802@statistik.uni-dortmund.de>

Patrick Connolly wrote:
> I like the fact that the postscript function enables the possbiility
> of a more useful title than before.  However, I'd prefer the default
> to be the file name.  
> 
> It's very simple for me to make my own postscript function that does
> just that simply by setting title = file.  I always use onefile =
> TRUE, so it always works (so far).  However, I'm a little reluctant to
> do that in case some future changes cause conflicts.  I've been warned
> off tinkering with .Internal
> 
> My question is: What is the tidiest way of doing such a thing?  Should
> I make a private function that calls the standard postscript function,
> or should I go the whole hog and make an S4 type method to handle it?

A private function that calls postscript() seems to be a very clean 
solution.

mypostscript <- function(file = ifelse(onefile, "Rplots.ps", 
"Rplot%03d.ps"), onefile = TRUE, title = NULL, ...){
   if(is.null(title)) title <- basename(file[1])
   postscript(file = file, onefile = onefile, title = title, ...)
}

Uwe Ligges

> Or would it be simpler for the standard function to be changed
> (assuming, of course, there aren't good reasons against doing that)?
> 
> best
>


From ligges at statistik.uni-dortmund.de  Wed Apr 23 09:39:55 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Apr 2003 09:39:55 +0200
Subject: [R] Quick query on output
In-Reply-To: <Pine.SUN.4.10.10304221356240.7799-100000@davis.demog.berkeley.edu>
References: <Pine.SUN.4.10.10304221356240.7799-100000@davis.demog.berkeley.edu>
Message-ID: <3EA6434B.6090608@statistik.uni-dortmund.de>

SamL wrote:
> I am attempting to estimate a very complex glmmPQL model.  I have
> (apparently) gotten working syntax.  But, I don't want to wait a long time
> only to find I have not made the correct syntax to see the output.  So,
> what I've written is:
> 
> EXCERPT FROM COMMAND FILE:
> 
> glmmPQL(plfp ~ -1 + bmrd4 + bmsd4 + wmrd4 + wmsd4 + bfrd4 + bfsd4 +
>              wfrd4 + wfsd4 + y4yrsed + y4age + y4age2,
>         data=PLFPANAL,
>         random=~ bm4 + wm4 + bf4 + wf4 | state,
>         family=binomial,
>         weights=wt1)
> 
> summary(fm1)
> 
> q
> 
> END OF EXCERPT FROM COMMAND FILE
> 
> I bet the "suummary(fm1)" line is wrong, it was apparently a holdover from
> some other code I tried to emulate.  At any rate, what do I do to get the
> output?  Have I done enough?  Is something else required?  Assistance or
> reassurance greatly appreciated!


I don't get the point. You don't want to wait a long time --- for R to 
finish or reading the manuals or ...?
What about trying with small exmaple data at first? There is much 
literature around with example code, at least for similar problems.


Anyway, you might want to assign the results of your computations to a 
variable:
   mycalcs <- glmmPQL(plfp .....)
then you can print the object:
   mycalcs # or print(mycalcs)
and "summarize" it:
   summary(mycalcs)

Does this answer your question?

Uwe Ligges


From maechler at stat.math.ethz.ch  Wed Apr 23 09:52:18 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 23 Apr 2003 09:52:18 +0200
Subject: [R] Re: Default value for title in postscript()
In-Reply-To: <20030422220800.GF14368@hortresearch.co.nz>
References: <20030422220800.GF14368@hortresearch.co.nz>
Message-ID: <16038.17970.797442.963291@gargle.gargle.HOWL>


[ This really should have gone to R-devel instead of R-help.
  I'm now diverting -- and please leave off "R-help" when replying again.
]

>>>>> "PaCo" == Patrick Connolly <p.connolly at hortresearch.co.nz>
>>>>>     on Wed, 23 Apr 2003 10:08:00 +1200 writes:

    PaCo> I like the fact that the postscript function enables
    PaCo> the possbiility of a more useful title than before.
    PaCo> However, I'd prefer the default to be the file name.

    PaCo> It's very simple for me to make my own postscript
    PaCo> function that does just that simply by setting title =
    PaCo> file.  I always use onefile = TRUE, so it always works
    PaCo> (so far).  However, I'm a little reluctant to do that
    PaCo> in case some future changes cause conflicts.  I've
    PaCo> been warned off tinkering with .Internal

    PaCo> My question is: What is the tidiest way of doing such
    PaCo> a thing?  Should I make a private function that calls
    PaCo> the standard postscript function, 

yes, your own function calling the standard high-level postscript(),
not some low-level {.Internal(), .Call(), .C() or .For..... } --
these all may be changed "without notice" !}

    PaCo> or should I go the whole hog and make an S4 type method to handle it?

    PaCo> Or would it be simpler for the standard function to be changed

certainly simpler for you.. ;-)

I tend to agree that a change might be useful --
For the new default, I'd actually go further and propose
something like (when file = "Rplots.ps")

   "Rplots.ps [from R 1.7.0]"

    PaCo> (assuming, of course, there aren't good reasons
    PaCo> against doing that)?

Unfortunately, there's a good reason: back-compatibility.
In spite of that, I do advocate a change.

Martin


From wettenhall at wehi.edu.au  Wed Apr 23 10:29:57 2003
From: wettenhall at wehi.edu.au (James Wettenhall)
Date: Wed, 23 Apr 2003 18:29:57 +1000 (EST)
Subject: [R] iwidgets in tcltk in R 1.7.0
In-Reply-To: <200304221004.h3MA4MUa023501@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.44.0304231813530.20899-100000@unix24.alpha.wehi.edu.au>

Hi,

I have successfully installed R 1.7.0 and ActiveTcl 8.4.2.0 in 
Windows 2000.  Yes, I know that Tcl is already bundled with 
R 1.7.0, but I want to use the iwidgets package to create a 
drop-down listbox, and I don't think iwidgets is included in the 
bundled R 1.7.0/TclTk installation package.  I have set the 
environment variables TCL_LIBRARY and MY_TCLTK to the directory 
where I installed ActiveTcl and I have added the Tcl\bin 
directory containing the DLLs to my PATH environment variable.  
I can load the tcltk package with library(tcltk) and use all of 
the standard widgets, but tclRequire("iwidgets") fails :

> tclRequire("iwidgets")
Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), 
class = "tclObj") : 
        [tcl] can't find package iwidgets.

Any suggestions would be greatly appreciated.

Thanks,
James


--------------------------------------------------------------------------
James Wettenhall                                  Tel: (+61 3) 9345 2629
Division of Genetics and Bioinformatics           Fax: (+61 3) 9347 0852
The Walter & Eliza Hall Institute         E-mail: wettenhall at wehi.edu.au
 of Medical Research,                     Mobile: (+61 / 0 ) 438 527 921    
1G Royal Parade,
Parkville, Vic 3050, Australia
http://www.wehi.edu.au


From laurent.faisnel at ariase.com  Wed Apr 23 10:55:15 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Wed, 23 Apr 2003 10:55:15 +0200
Subject: [R] list of loaded packages
Message-ID: <3EA654F3.4010808@ariase.com>

Probably an easy question for most of you R-users :
library() returns the list of available packages, but how is it possible 
to get the list of all loaded packages ?

Laurent


From laurent.faisnel at ariase.com  Wed Apr 23 11:07:29 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Wed, 23 Apr 2003 11:07:29 +0200
Subject: [R] getting started with RMySQL
Message-ID: <3EA657D1.2050708@ariase.com>

Hi all,
I'm trying to make the connection between R and MySQL. I set connection 
parameters such as dbname, user, host in file .my.cnf

 >library(DBI)
 >library(RMySQL)
 > drv <- dbDriver("MySQL")
 > con <- dbConnect(drv)

Until here evrything's ok.

But there are lots of commands I found in R docs which are "not found", 
such as getTable. Deprecated (I successfully used dbListTables) or do I 
simply miss a package ?
How should I use resultSets ? I am not able to close neither a 
connection nor a ResultSet. I tried with close(con).

Thanks for any help.

Laurent


From ligges at statistik.uni-dortmund.de  Wed Apr 23 11:10:33 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Apr 2003 11:10:33 +0200
Subject: [R] list of loaded packages
In-Reply-To: <3EA654F3.4010808@ariase.com>
References: <3EA654F3.4010808@ariase.com>
Message-ID: <3EA65889.8030008@statistik.uni-dortmund.de>

Laurent Faisnel wrote:
> Probably an easy question for most of you R-users :
> library() returns the list of available packages, but how is it possible 
> to get the list of all loaded packages ?
> 
> Laurent
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


?search

Uwe Ligges


From flelay at irisa.fr  Wed Apr 23 11:16:20 2003
From: flelay at irisa.fr (=?iso-8859-1?q?Fran=E7ois=20Le=20Lay?=)
Date: Wed, 23 Apr 2003 11:16:20 +0200
Subject: [R] list of loaded packages
In-Reply-To: <3EA654F3.4010808@ariase.com>
References: <3EA654F3.4010808@ariase.com>
Message-ID: <200304231116.20833.flelay@irisa.fr>

On Wednesday 23 April 2003 10:55, Laurent Faisnel wrote:
> Probably an easy question for most of you R-users :
> library() returns the list of available packages, but how is it possible
> to get the list of all loaded packages ?
>
> Laurent

(.packages())

++
Fanch

-- 
IRISA-INRIA, Campus de Beaulieu, 35042 Rennes cedex, France
T?l: +33 (0) 2 99 84 71 00, Fax: +33 (0) 2 99 84 71 71


From fharrell at virginia.edu  Wed Apr 23 12:42:19 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed, 23 Apr 2003 06:42:19 -0400
Subject: [R] Data Analysis/Graphics/Regression Modeling Strategies Courses
Message-ID: <20030423064219.7a8dccaa.fharrell@virginia.edu>

I am presenting two courses in Philadelphia in May-June organized by Insightful Corporation.  These courses have hands-on workshops and have received excellent reviews from past participants (let me know if you want to see the reviews from previous years' courses).  Both courses are applicable to S-Plus and R users.  The second course covers regression modeling methods that are of interest to those who don't use either statistical computing package.
---------------------------------------------------------------------
S-Plus for Statistical Data Analysis and Graphics: May 28-30

This course covers data manipulation and overviews the use of S for bootstrapping, simulation, and sample size/power calculations.  General elements of constructing good graphics (with much reference to the work of Bill Cleveland) are covered after presenting a series of graphical horrors, and exploratory data analysis and Trellis/Lattice graphics are emphasized.  LaTeX, advanced statistical table making, statistical reporting, and reproducible research are covered briefly.  Many functions from the Hmisc library are covered.  For a full course description see http://www.insightful.com/services/course.asp?CID=26
---------------------------------------------------------------------
Regression Modeling Strategies: June 2-4

This course emphasizes statistical modeling methodology from my book Regression Modeling Strategies (Springer, 2001) and has workshops using the Design library.
Some of the key topics covered are how and where to "spend" degrees of freedom, data reduction, multiple imputation of missing predictor variables, relaxing nonlinearity assumptions, hazards of stepwise variable selection, handling interactions, model validation, and graphically displaying complex regression models.  A full course description may be found at http://www.insightful.com/services/course.asp?CID=27


To Register:	- Web: http://www.insightful.com/services/register.asp
		- Email: kkelly at insightful.com
		- Call Kim Kelly at: 800-569-0123 x278
-- 
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From laurent.faisnel at ariase.com  Wed Apr 23 12:41:14 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Wed, 23 Apr 2003 12:41:14 +0200
Subject: [R] problems with RMySQL connections
Message-ID: <3EA66DCA.2050400@ariase.com>

I'm gonna give some details about the problems I have with RMySQL.

These are the packages I have loaded :
 > (.packages())
[1] "MASS"    "RMySQL"  "methods" "DBI"     "tools"   "ctest"   "base"

This is what I did to make the connection :
 > drv <- dbDriver("MySQL")
 > con <- dbConnect(drv)

Then I should be able to send requests. But when I try this :
 > dbListTables(con)
character(0)
Warning messages:
1: RS-DBI driver warning: (error while fetching rows)
2: pending rows in: mysqlQuickSQL(conn, statement, ...)

Obviously, the problem is that I should close something because there 
are things to clean in memory.
So I try this (I have no ResultSet opened)
 > close(con1)
Error in close(con1) : no applicable method for "close"

This seems to be the good way to proceed (according to docs - any other 
close-like command returns "function not found") but I do not know how 
to do after this... Anyway, I cannot submit any queries since
apparently connections have to be cleaned first.

Thanks in advance for your help.
Laurent


From rjporter at mindspring.com  Wed Apr 23 13:24:12 2003
From: rjporter at mindspring.com (Bob Porter)
Date: Wed, 23 Apr 2003 07:24:12 -0400
Subject: [R] fisher exact vs. simulated chi-square
Message-ID: <0d3f01c3098a$de191b30$6501a8c0@HydePark>

The Chi-Square test is based upon the assumption that the sample is large enough
to allow approximation of a (nearly symetric) binomial by a normal distribution.
(Chi Sqare is z^2).  When expected (NOT observed) cells are too small, that
suggests a very asymetric binomial and, consequently a poor fit for the
assumption.  The exact test calculates the exact probability of the observed
values, or more extreme ones, given the assumed probabilities generating the
expected values.  As someone else noted, exact is exact, Chi-square is not
(unless, of course, assumptions are exactly met.)
Bob Porter,

Robert J. Porter, Ph.D.
Clinical and Consulting Psychologist
308 East Oak Street
Tampa, FL, 33603
Office Phone: 813-810-8110
813-225-5678 FAX
www.mindspring.com/~rjporter

-----Original Message-----
From: Dirk Janssen [mailto:dirkj at rz.uni-leipzig.de]
Sent: Tuesday, April 22, 2003 8:08 PM
To: r-help at stat.math.ethz.ch
Subject: [fisher exact vs. simulated chi-square (Dirk Janssen
Dear All,

I have a problem understanding the difference between the outcome of a
fisher exact test and a chi-square test (with simulated p.value).

For some sample data (see below), fisher reports p=.02337. The normal
chi-square test complains about "approximation may be incorrect",
because there is a column with cells with very small values. I therefore
tried the chi-square with simulated p-values, but this still gives
p=.04037. I also simulated the p-value myself, using r2dtable, getting
the same result, p=0.04 (approx).

Why is this substantially higher than what the fisher exact says? Do the
two tests make different assumptions? I noticed that the discrepancy
gets smaller when I increase the number of observations for column A3.
Does this mean that the simulated chi-square is still sensitive to cells
with small counts, even though it does not give me the warning?


Thanks in advance,
Dirk Janssen


From wl at eimb.ru  Wed Apr 23 13:30:04 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Wed, 23 Apr 2003 15:30:04 +0400
Subject: [R] MySQL
Message-ID: <3645.030423@eimb.ru>

Dear laurent,

> But there are lots of commands I found in R docs which are "not found",
> such as getTable. Deprecated (I successfully used dbListTables) or do I 
> simply miss a package ?

>From RMySQL\NEWS:
* added (almost) trivial convenience RS-DBI functions getTable(),
  assignTable(), existsTable(), and removeTable().  They all mimic the 
  corresponding R/S get(), assign(), exists(), and remove(), and they 
  all work with a connection object and an sql table name (NOT generic 
  SQL queries); assignTable() assigns a data.frame object (or coerceable) 
  to the database. (These functions provide the basis for "user-defined
  databases in S -- see below.)

> How should I use resultSets ? I am not able to close neither a 
> connection nor a ResultSet. I tried with close(con).
  
> Thanks for any help.

I used the following script:

library(RMySQL);
con <- dbConnect(dbDriver("MySQL"), dbname = "area");

regionarea <- dbGetQuery(con,
                         "select area from region_areas \
                          where region like \"Arctic Ocean\""
                  )$area;

mynn <- dbGetQuery(con,
                   paste("select year(date) as year,",
                         "avg(area1)/",regionarea,"*100 as area1,",
                         "avg(area2)/",regionarea,"*100 as area2",
                         "from ArcticOcean_MYNN",
                         "where month(date)<=3 and empty<465",
                         "group by year(date)",
                         sep=" "
                        )
                   );
dbDisconnect(con);

-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru

==========================================================================
Research Scientist                                Leninsky Prospect 33,
Space Monitoring & Ecoinformation Systems Sector, Moscow, Russia, 119071,
Institute of Ecology,                             Phone: (095) 135-9972;
Russian Academy of Sciences                       Fax: (095) 954-5534


From Friedrich.Leisch at univie.ac.at  Wed Apr 23 14:01:25 2003
From: Friedrich.Leisch at univie.ac.at (Friedrich.Leisch@univie.ac.at)
Date: Wed, 23 Apr 2003 14:01:25 +0200
Subject: [R] Problem with pixmap on R 1.7.0?
In-Reply-To: <oprn1h0iilfaouaq@200.24.8.4>
References: <oprn1h0iilfaouaq@200.24.8.4>
Message-ID: <16038.32917.345112.393898@ci.tuwien.ac.at>

>>>>> On Tue, 22 Apr 2003 11:42:08 -0500,
>>>>> Kenneth Cabrera (KC) wrote:

  > Hi R users:
  > I got the following message when I use the pixmap library
  > on R 1.7.0 over w2K platform (on R 1.6.2 it runs right).

  > pixmapGrey(matrix(c(0,1),128,128))
  > Error in .class1(object) : Object "from" not found

  > I download the library .zip file from:

  > http://cran.r-project.org/bin/windows/contrib/1.7/pixmap_0.3-2.zip

Hmm, works for me on debian linux, will have to check on windows
(today I have no access to a windows machine).

best,

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f?r Statistik & DSS                Tel: (+43 1) 4277 38613
Universit?t Wien  		            Fax: (+43 1) 4277 38639
Universit?tsstra?e 5                  Friedrich.Leisch at univie.ac.at
1010 Wien, Austria     http://mailbox.univie.ac.at/Friedrich.Leisch


From spencer.graves at pdf.com  Wed Apr 23 14:05:40 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 23 Apr 2003 05:05:40 -0700
Subject: [R] documentation for survival5?  
Message-ID: <3EA68194.4020902@pdf.com>

Dear R-Helpers:

	  What other references are there on the capabilities of the survival5 
package other than the help files and the chapter on survival analysis 
in every edition of Modern Applied Statistics with S?  I'm thinking of 
something like "An Introduction to Survival Analysis in R" with worked 
examples that might complement or extend the chapter in MASS.

Thanks,
Spencer Graves


From ligges at statistik.uni-dortmund.de  Wed Apr 23 14:13:07 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Apr 2003 14:13:07 +0200
Subject: [R] Problem with pixmap on R 1.7.0?
In-Reply-To: <oprn1h0iilfaouaq@200.24.8.4>
References: <oprn1h0iilfaouaq@200.24.8.4>
Message-ID: <3EA68353.1050901@statistik.uni-dortmund.de>

Kenneth Cabrera wrote:
> Hi R users:
> I got the following message when I use the pixmap library
> on R 1.7.0 over w2K platform (on R 1.6.2 it runs right).
> 
> pixmapGrey(matrix(c(0,1),128,128))
> Error in .class1(object) : Object "from" not found
> 
> I download the library .zip file from:
> 
> http://cran.r-project.org/bin/windows/contrib/1.7/pixmap_0.3-2.zip

It seems to be a problem with this specific binary file for windows.

Installing from sources solves the problem. I made a fresh bundled 
binary available at 
http://www.statistik.uni-dortmund.de/~ligges/pixmap_0.3-2.zip while

Brian seems to be away for recompiling these days.


> Other question:
> 
> When I try to "Install package(s) from bioconductor" I got the
> following message:
> 
> local({a<-CRAN.packages(CRAN=getOption("BIOC"))
> + install.packages(select.list(a[,1],,TRUE), .libPaths()[1], 
> available=a, CRAN=getOption("BIOC"))})
> 
> trying URL `http://www.bioconductor.org/bin/windows/contrib/1.7/PACKAGES'
> Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  
> : cannot open: HTTP status was `404 Not Found'
> 
> Are the packages in other path of www.bioconductor.org? Which one?

This seems to be solved now.

> Thank you for your help.
> 
> Kenneth


Uwe Ligges


From friendly at yorku.ca  Wed Apr 23 14:37:39 2003
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 23 Apr 2003 08:37:39 -0400
Subject: [R] rw08.exe (R 1.7.0 for windows)
Message-ID: <3EA68913.30507@yorku.ca>


-- 
Michael Friendly              friendly at yorku.ca
York University               http://www.math.yorku.ca/SCS/friendly.html
Psychology Department
4700 Keele Street             Tel:  (416) 736-5115 x66249
Toronto, Ontario, M3J 1P3     Fax:  (416) 736-5814


From angel_lul at hotmail.com  Wed Apr 23 14:29:44 2003
From: angel_lul at hotmail.com (Angel -)
Date: Wed, 23 Apr 2003 12:29:44 +0000
Subject: [R] 
	nls: Missing value or an Infinity produced when evaluating the model
Message-ID: <Law11-F780fpsiYLZlm000033fd@hotmail.com>

Hi,
I am trying to fit a sigmoid curve to some data with nls but I am getting 
into some trouble.
Seems that the optimization method is getting down to some parameter 
estimates that make the equation unsolvable. This is an example:

>growth<-data.frame(Time=c(5,7,9,11,13,15,17,19,21,23,25,27),BodyMass=c(45,85,125,210,300,485,570,700,830,940,1030,1120))

>GrowthModel<-nls(BodyMass~(((1-(1-((BirthMass/MaxMass)^0.25))*exp(-a*Time/(4*MaxMass^0.25)))^4)*MaxMass),data=growth,start=c(BirthMass=3,MaxMass=2500,a=1.5),trace=TRUE)

56043.86 :     3.0 2500.0    1.5
Error in numericDeriv(form[[3]], names(ind), env) :
        Missing value or an Infinity produced when evaluating the model

Is there anyway I can restrict the parameter values used so it doesn't get 
to this no return point.
Any other alternatives are also very welcome!
Thanks in advance,
Angel





_________________________________________________________________
Hotmail messages direct to your mobile phone http://www.msn.co.uk/mobile


From ligges at statistik.uni-dortmund.de  Wed Apr 23 14:35:44 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Apr 2003 14:35:44 +0200
Subject: [R] R(D) Com under R1070
In-Reply-To: <JLEPLGAANFCEAEDCAGJNEEMPCEAA.dieter.menne@menne-biomed.de>
References: <JLEPLGAANFCEAEDCAGJNEEMPCEAA.dieter.menne@menne-biomed.de>
Message-ID: <3EA688A0.8060300@statistik.uni-dortmund.de>

Dieter Menne wrote:
> Dear List,
> 
> I have unregistered the working installation of R(D)COM from r1060 as
> described in http://cran.r-project.org/contrib/extra/dcom/ReadMe.txt,
> and have re-installed it for r1070.
> 
> Now, vbtest gives the following message:
> 
> Loading StatConnector Server... Done
> Initializing R...Function call failed
>   Code: -2147221485
>   Text: installation problem: unable to load connector
> Box: Method '~' of object '~' failed.
> 
> Releasing StatConnector Server...Done
> 
> Any ideas?
> 
> Dieter Menne

Suggestions:
a) Reinstall R *and* the DCOM Server.
b) Maybe environment variable R_HOME pointing to a non-existing version 
of R?
c) Ask the DCOM server's author (Thomas Baier) directly.

Uwe Ligges


From wettenhall at wehi.edu.au  Wed Apr 23 14:42:20 2003
From: wettenhall at wehi.edu.au (James Wettenhall)
Date: Wed, 23 Apr 2003 22:42:20 +1000 (EST)
Subject: [R] iwidgets in tcltk in R 1.7.0
In-Reply-To: <x2sms9zgoj.fsf@biostat.ku.dk>
Message-ID: <Pine.LNX.4.44.0304232239460.21560-100000@unix24.alpha.wehi.edu.au>

Thanks Peter,

Yes, the capitalization was the problem.  My code previously 
used tclRequire("iwidgets") which worked OK in R 1.6.x on 
Windows but now I have changed it to tclRequire("Iwidgets") 
which has solved the problem!

Regards,
James

On 23 Apr 2003, Peter Dalgaard BSA wrote:

> > library(tcltk)
> > tclRequire("iwidgets")
> > Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), 
> > class = "tclObj") : 
> >         [tcl] can't find package iwidgets.
> > 
> > Any suggestions would be greatly appreciated.
> 
> Check the capitalization. I suspect it is "Iwidgets" (it is on Unix,
> but the namespace is "iwidgets"...)


From dieter.menne at menne-biomed.de  Wed Apr 23 14:46:12 2003
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Wed, 23 Apr 2003 14:46:12 +0200
Subject: [R] R(D) Com under R1070
In-Reply-To: <3EA688A0.8060300@statistik.uni-dortmund.de>
Message-ID: <JLEPLGAANFCEAEDCAGJNOENFCEAA.dieter.menne@menne-biomed.de>


Uwe Ligges wrote:

> Suggestions:
> a) Reinstall R *and* the DCOM Server.

> b) Maybe environment variable R_HOME pointing to a non-existing version 
> of R?

Must be C:\progra~1\R\r1070. The default setting (e.g. in registry) 
of C:\program files\R\r1070 reproducably generates the error message.
This error probably does not occur in German versions of Windows,
as C:\Programme is 8.3 compatible.

Dieter


From andy_liaw at merck.com  Wed Apr 23 14:53:32 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 23 Apr 2003 08:53:32 -0400
Subject: [R] changing dir to network drive in Rgui caused crash (
 1.7.	0)
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FA35@usrymx25.merck.com>

Uwe & Marc,

Adding the --vanilla flag doesn't help.  Actually, the crash happens if I
browse to a folder on a mapped drive.  I.e., if I type in "q:\Andy" in the
text box, it works, but if I try to browse to Q:\Andy and then click on OK,
that's when it crashes.

Andy

> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
> 
> Marc Schwartz wrote:
> >>-----Original Message-----
> >>From: r-help-bounces at stat.math.ethz.ch 
> >>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Liaw, Andy
> >>Sent: Tuesday, April 22, 2003 7:26 PM
> >>To: 'R-help at stat.math.ethz.ch'
> >>Subject: [R] changing dir to network drive in Rgui caused crash
> > 
> > (1.7.0)
> > 
> >>
> >>Dear R-help,
> >>
> >>Has anyone experienced similar problem?  On WinNT4(sp6), 
> >>running Rgui from 1.7.0, when try to change directory to some 
> >>network drive using the "File / Change dir..." menu, Rgui gets 
> >>a visit by Dr. Watson.  If I first change dir to a local 
> >>drive, then again to a network drive, it works fine.  It also 
> >>works fine with setwd() from the command prompt.
> >>
> >>Best,
> >>Andy
> > 
> > 
> > 
> > It does not happen on WinXP Pro using 1.7.0, whether I explicitly
> > enter the network path (ie. \\ServerName\Drive\Folder) in the dialog
> > or browse to it. 
> 
> Works as well on my WinNT4.0 (SP6) installation, starting "as is" and 
> with "rgui --vanilla". Does the latter configuration still 
> produce the 
> crash for you, Andy?
> 
> Uwe Ligges
> 
> 
> > Are you using a mapped network drive (ie. 'M:') or a 
> non-mapped target
> > path?
> 
> 
> 
>


From jfox at mcmaster.ca  Wed Apr 23 15:03:04 2003
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 23 Apr 2003 09:03:04 -0400
Subject: [R] documentation for survival5?  
In-Reply-To: <3EA68194.4020902@pdf.com>
Message-ID: <5.1.0.14.2.20030423090023.01e7fa28@mcmail.cis.mcmaster.ca>

Dear Spencer,

There is a book by Therneau and Grambsch, Modeling Survival Data (Springer, 
2000); Therneau is the author of the survival library for S-PLUS, ported to 
R. The book covers survival analysis in S-PLUS and SAS.

Regards,
  John

At 05:05 AM 4/23/2003 -0700, Spencer Graves wrote:

>           What other references are there on the capabilities of the 
> survival5 package other than the help files and the chapter on survival 
> analysis in every edition of Modern Applied Statistics with S?  I'm 
> thinking of something like "An Introduction to Survival Analysis in R" 
> with worked examples that might complement or extend the chapter in MASS.

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox


From v_bill_pikounis at merck.com  Wed Apr 23 15:14:26 2003
From: v_bill_pikounis at merck.com (Pikounis, Bill)
Date: Wed, 23 Apr 2003 09:14:26 -0400
Subject: [R] documentation for survival5?
Message-ID: <CFBD404F5E0C9547B4E10B7BDC3DFA2F662206@usrymx18.merck.com>

Spencer,
Regression Modeling Strategies by FE Harrell is another good reference to
compliment Therneau & Grambsch as well as MASS, particularly in regards to
"worked examples".

Best,
Bill


> -----Original Message-----
> From: John Fox [mailto:jfox at mcmaster.ca]
> Sent: Wednesday, April 23, 2003 9:03 AM
> To: Spencer Graves
> Cc: R-help
> Subject: Re: [R] documentation for survival5?
> 
> 
> Dear Spencer,
> 
> There is a book by Therneau and Grambsch, Modeling Survival 
> Data (Springer, 
> 2000); Therneau is the author of the survival library for 
> S-PLUS, ported to 
> R. The book covers survival analysis in S-PLUS and SAS.
> 
> Regards,
>   John
> 
> At 05:05 AM 4/23/2003 -0700, Spencer Graves wrote:
> 
> >           What other references are there on the 
> capabilities of the 
> > survival5 package other than the help files and the chapter 
> on survival 
> > analysis in every edition of Modern Applied Statistics with S?  I'm 
> > thinking of something like "An Introduction to Survival 
> Analysis in R" 
> > with worked examples that might complement or extend the 
> chapter in MASS.
> 
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From flelay at irisa.fr  Wed Apr 23 15:16:53 2003
From: flelay at irisa.fr (=?iso-8859-1?q?Fran=E7ois=20Le=20Lay?=)
Date: Wed, 23 Apr 2003 15:16:53 +0200
Subject: [R] Text on a boxplot graph
Message-ID: <200304231516.53538.flelay@irisa.fr>

Hi all,

Could anybody help me figure out how to write text on a boxplot. I have to 
plot 9 boxplots side by side on a single graph. On the x-axis I write numeric 
values with the 'names' argument but I'd like to add one label (character 
value) in the middle of each box. I know how to use the text() function for 
regular y~x plots but in this particular case, I'm kinda lost...
Here is my code:

# creating labels for x-axis labelling 
lb <- c()
for( n in names(o) )
  lb <- c(lb, paste("\n",n,"\n",o[[n]], sep=""))

boxplot(x[,-c(10,11)],
        varwidth=TRUE,         			 
col=c("#FF0000","#EE0000","#DD0000","#00FF00","#0000FF","#0000DD","#0000BB","#000099"),	
        col.lab="dark red",
        col.axis="blue",
        main="Boxplots for Polling results, 1868 clusters, 9604 simulated 
requests",
        names=lb,
        xlab="RED BOXPLOTS: precision dependent - GREEN BOXPLOT: null radius - 
BLUE BOXPLOTS: percent of exact radius",
 	       ylab="P(ID) values")


Thanks for your help,
Fanch
 
-- 
IRISA-INRIA, Campus de Beaulieu, 35042 Rennes cedex, France
T?l: +33 (0) 2 99 84 71 00, Fax: +33 (0) 2 99 84 71 71


From uth at zhwin.ch  Wed Apr 23 15:18:04 2003
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Wed, 23 Apr 2003 15:18:04 +0200
Subject: [R] tk windows position
Message-ID: <6A4BCEF0FD65344A8F496D7E520DD8B9023E9097@lobster.zhwin.ch>


Dear r-hackers,

I want to split my screen into four screens (like split it do in Rgui). To get this I do the following:

Window1 <- tktoplevel()
Window1 <- tktoplevel()
Window1 <- tktoplevel()



Thomas Untern?hrer                               E-Mail:  thomas.unternaehrer at zhwin.ch
Institut f?r Datenanalyse und Prozessdesign      Tel:     052/ 267 7813
Z?rcher Hochschule Winterthur                    Fax:     052/ 268 7813
Technopark / J?gerstrasse 2 
Postfach
CH-8400 Winterthur                               http://www.idp.zhwin.ch


From ritz at dina.kvl.dk  Wed Apr 23 15:22:37 2003
From: ritz at dina.kvl.dk (Christian Ritz)
Date: Wed, 23 Apr 2003 15:22:37 +0200
Subject: [R] nls: Missing value or an Infinity produced when evaluating
	the model
References: <Law11-F780fpsiYLZlm000033fd@hotmail.com>
Message-ID: <004c01c3099b$68cafc20$e728e182@santamaria>

Hi Angel,

I tried reparametrise your model, setting:

BirthMass^0.25=u
MaxMass^0.25=v

and giving the following formula in R:

GrowthModel<-nls(BodyMass~(((1-(1-u/v)*exp(-a*Time/(4*v)))^4)*v^4),data=grow
th,start=c(u=4,v=5,a=1.5),trace=TRUE)

And this works for me, but the u estimate is negative (not significantly
different from 0, though).

Christian

----- Original Message -----
From: "Angel -" <angel_lul at hotmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, April 23, 2003 2:29 PM
Subject: [R] nls: Missing value or an Infinity produced when evaluating the
model


> Hi,
> I am trying to fit a sigmoid curve to some data with nls but I am getting
> into some trouble.
> Seems that the optimization method is getting down to some parameter
> estimates that make the equation unsolvable. This is an example:
>
...


From uth at zhwin.ch  Wed Apr 23 15:26:36 2003
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Wed, 23 Apr 2003 15:26:36 +0200
Subject: [R] tkl window position
Message-ID: <6A4BCEF0FD65344A8F496D7E520DD8B9023E9098@lobster.zhwin.ch>

Dear r-hackers,

I want to split my screen into four screens (like split it do in Rgui). To get this I do the following:

Window1 <- tktoplevel()
Window2 <- tktoplevel()
Window3 <- tktoplevel()
Window4 <- tktoplevel()

How can I position this windows on my screen.

The help-site on activstate says that I can use the command Tk_MoveResizeWindow(tkwin, x, y, width, height).
But no command like tkMoveResizeWindow exists in R.
I try the command tkmove() but found no documentation (tkmove(Window, x=xx,y=yy) doesn't work).

Can you help me?


Thanks a lot 

Thomas

Ps: don't look at my english. It is terrible.
Sorry, my first mail was a mistake.


From rdiaz at cnio.es  Wed Apr 23 15:27:21 2003
From: rdiaz at cnio.es (Ramon Diaz)
Date: Wed, 23 Apr 2003 15:27:21 +0200
Subject: [R] documentation for survival5?
In-Reply-To: <5.1.0.14.2.20030423090023.01e7fa28@mcmail.cis.mcmaster.ca>
References: <5.1.0.14.2.20030423090023.01e7fa28@mcmail.cis.mcmaster.ca>
Message-ID: <200304231527.21749.rdiaz@cnio.es>

Dear Spencer,

On addition to John's suggestion, you might want to check Frank Harrell's 
"Regression modeling strategies" (Springer, 2001) which devotes several 
chapters to survival analysis. It includes discussion of both survival5 and 
Harrell's additions (in the Hmisc and Design packages).

Best,

Ram?n

On Wednesday 23 April 2003 15:03, John Fox wrote:
> Dear Spencer,
>
> There is a book by Therneau and Grambsch, Modeling Survival Data (Springer,
> 2000); Therneau is the author of the survival library for S-PLUS, ported to
> R. The book covers survival analysis in S-PLUS and SAS.
>
> Regards,
>   John
>
> At 05:05 AM 4/23/2003 -0700, Spencer Graves wrote:
> >           What other references are there on the capabilities of the
> > survival5 package other than the help files and the chapter on survival
> > analysis in every edition of Modern Applied Statistics with S?  I'm
> > thinking of something like "An Introduction to Survival Analysis in R"
> > with worked examples that might complement or extend the chapter in MASS.
>
> -----------------------------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario, Canada L8S 4M4
> email: jfox at mcmaster.ca
> phone: 905-525-9140x23604
> web: www.socsci.mcmaster.ca/jfox
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-- 
Ram?n D?az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol?gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern?ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://bioinfo.cnio.es/~rdiaz


From ligges at statistik.uni-dortmund.de  Wed Apr 23 15:45:06 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Apr 2003 15:45:06 +0200
Subject: [R] changing dir to network drive in Rgui caused crash ( 1.7.0)
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4FA35@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD5C4FA35@usrymx25.merck.com>
Message-ID: <3EA698E2.5060409@statistik.uni-dortmund.de>

Liaw, Andy wrote:
> Uwe & Marc,
> 
> Adding the --vanilla flag doesn't help.  Actually, the crash happens if I
> browse to a folder on a mapped drive.  I.e., if I type in "q:\Andy" in the
> text box, it works, but if I try to browse to Q:\Andy and then click on OK,
> that's when it crashes.


OK, confirmed. Happens TODAY with ANY drive (local ones as well) on my 
machine. Can you file a bug report, please [so we will also move any 
discussion to R-devel]. Thanks!
Strange thing: I was not able to reproduce it a few days ago.....

Uwe Ligges


> Andy
> 
> 
>>From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de]
>>
>>Marc Schwartz wrote:
>>
>>>>-----Original Message-----
>>>>From: r-help-bounces at stat.math.ethz.ch 
>>>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Liaw, Andy
>>>>Sent: Tuesday, April 22, 2003 7:26 PM
>>>>To: 'R-help at stat.math.ethz.ch'
>>>>Subject: [R] changing dir to network drive in Rgui caused crash
>>>
>>>(1.7.0)
>>>
>>>
>>>>Dear R-help,
>>>>
>>>>Has anyone experienced similar problem?  On WinNT4(sp6), 
>>>>running Rgui from 1.7.0, when try to change directory to some 
>>>>network drive using the "File / Change dir..." menu, Rgui gets 
>>>>a visit by Dr. Watson.  If I first change dir to a local 
>>>>drive, then again to a network drive, it works fine.  It also 
>>>>works fine with setwd() from the command prompt.
>>>>
>>>>Best,
>>>>Andy
>>>
>>>
>>>
>>>It does not happen on WinXP Pro using 1.7.0, whether I explicitly
>>>enter the network path (ie. \\ServerName\Drive\Folder) in the dialog
>>>or browse to it. 
>>
>>Works as well on my WinNT4.0 (SP6) installation, starting "as is" and 
>>with "rgui --vanilla". Does the latter configuration still 
>>produce the 
>>crash for you, Andy?
>>
>>Uwe Ligges
>>
>>
>>
>>>Are you using a mapped network drive (ie. 'M:') or a 
>>
>>non-mapped target
>>
>>>path?


From mschwartz at medanalytics.com  Wed Apr 23 15:47:19 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Wed, 23 Apr 2003 08:47:19 -0500
Subject: [R] changing dir to network drive in Rgui caused crash ( 1.7.0)
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4FA35@usrymx25.merck.com>
Message-ID: <000c01c3099e$dd161300$0201a8c0@MARC>

>-----Original Message-----
>From: Liaw, Andy [mailto:andy_liaw at merck.com] 
>Sent: Wednesday, April 23, 2003 7:54 AM
>To: 'Uwe Ligges'; mschwartz at medanalytics.com
>Cc: R-help at stat.math.ethz.ch
>Subject: RE: [R] changing dir to network drive in Rgui caused 
>crash ( 1.7. 0)
>
>
>Uwe & Marc,
>
>Adding the --vanilla flag doesn't help.  Actually, the crash 
>happens if I browse to a folder on a mapped drive.  I.e., if I 
>type in "q:\Andy" in the text box, it works, but if I try to 
>browse to Q:\Andy and then click on OK, that's when it crashes.
>
>Andy

Andy,

I have to run out of the office for a few hours, but a couple of
thoughts:

1. Try to map another drive letter to the same drive to see if there
is something with that particular mapping.
2. Try to map another drive letter to the 'Andy' folder, so that the
drive letter maps to that folder directly, not to the main directory
on the drive

These won't help with a resolution, but may help to isolate the
problem if there is an issue with the mapping as it is currently set
or perhaps with your network browsing.

It has been a few years, but my recollection is that on the server
side, there are both defacto scripts for all accounts which can
include mappings and there are account specific scripts which may
include the same. Is it possible that there is something in the
scripts/mapping or in your workstation environment that is
compromising the integrity of network browsing?

I'll check back when I return later this afternoon.

Regards,

Marc Schwartz


From ligges at statistik.uni-dortmund.de  Wed Apr 23 15:55:14 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Apr 2003 15:55:14 +0200
Subject: [R] Text on a boxplot graph
In-Reply-To: <200304231516.53538.flelay@irisa.fr>
References: <200304231516.53538.flelay@irisa.fr>
Message-ID: <3EA69B42.2000604@statistik.uni-dortmund.de>

Fran?ois Le Lay wrote:
> Hi all,
> 
> Could anybody help me figure out how to write text on a boxplot. I have to 
> plot 9 boxplots side by side on a single graph. On the x-axis I write numeric 
> values with the 'names' argument but I'd like to add one label (character 
> value) in the middle of each box. I know how to use the text() function for 
> regular y~x plots but in this particular case, I'm kinda lost...
> Here is my code:
> 
> # creating labels for x-axis labelling 
> lb <- c()
> for( n in names(o) )
>   lb <- c(lb, paste("\n",n,"\n",o[[n]], sep=""))
> 
> boxplot(x[,-c(10,11)],
>         varwidth=TRUE,         			 
> col=c("#FF0000","#EE0000","#DD0000","#00FF00","#0000FF","#0000DD","#0000BB","#000099"),	
>         col.lab="dark red",
>         col.axis="blue",
>         main="Boxplots for Polling results, 1868 clusters, 9604 simulated 
> requests",
>         names=lb,
>         xlab="RED BOXPLOTS: precision dependent - GREEN BOXPLOT: null radius - 
> BLUE BOXPLOTS: percent of exact radius",
>  	       ylab="P(ID) values")
> 
> 
> Thanks for your help,
> Fanch
>  


As an example how to write text in the boxes directly below the median 
line, I'd suggest to use:

temp <- boxplot(.... your boxplot arguments ....)
text(seq(along = temp$n), temp$stats[3, ],
     labels = c("text.box.1", "text.box.2"), pos = 1)

Uwe Ligges


From faziza at vet-alfort.fr  Wed Apr 23 16:12:44 2003
From: faziza at vet-alfort.fr (Fanny AZIZA)
Date: Wed, 23 Apr 2003 16:12:44 +0200
Subject: [R] Technical problem
Message-ID: <000901c309a2$68de7ff0$3d0c050a@vetalfort.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030423/a4e562b3/attachment.pl

From macq at llnl.gov  Wed Apr 23 16:14:02 2003
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 23 Apr 2003 07:14:02 -0700
Subject: [R] How do I get 10^4 to become 10000?
In-Reply-To: <20030422015115.GA14368@hortresearch.co.nz>
References: <20030422015115.GA14368@hortresearch.co.nz>
Message-ID: <p05210600bacc4f6eab29@[128.115.153.6]>

How about this?

>  a <- c('10^4','1.2^3','2.3')

>  as.numeric(gsub('\\^','E',a))
[1] 1.0e+05 1.2e+03 2.3e+00

This solution doesn't work for "10^(-5)" but does work for "10^-5".

-Don

At 1:51 PM +1200 4/22/03, Patrick Connolly wrote:
>Of course, that's as trivial as it gets on the command line, but I
>can't work out how to get a column of numbers that are entered as
>"10^5" from its 'character' format into a numeric one?
>
>I feel a bit embarrassed asking such a simple question.  Too much
>Easter....
>
>Thanks
>
>
>
>--
>Patrick Connolly
>HortResearch
>Mt Albert
>Auckland
>New Zealand
>Ph: +64-9 815 4200 x 7188
>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
>I have the world`s largest collection of seashells. I keep it on all
>the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright
>~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA


From spencer.graves at pdf.com  Wed Apr 23 16:26:23 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 23 Apr 2003 07:26:23 -0700
Subject: [R] Technical problem
References: <000901c309a2$68de7ff0$3d0c050a@vetalfort.fr>
Message-ID: <3EA6A28F.8050603@pdf.com>

Hi, Fanny:

If someone selects "reply to all", you get one copy directly and a 
second via "r-help at ...".  Some people write to "r-help at ..." without 
subscribing.  If the addressee list were edited to reply only to 
"r-help at ...", then the original questioner would not see the reply.

Best Wishes,
Spencer Graves

Fanny AZIZA wrote:
> Hello,
>  
> Instead of receiving only one message when somebody send a question or a
> answer,
> I receive 2 messages with exactly the same contents inside.
>  
> Is it the same for you?
>  
> Thank you,
> Fanny
>  
> --------------------------
> Fanny AZIZA
> ?cole Nationale V?t?rinaire d'Alfort
> Mail: faziza at vet-alfort.fr
> T?l. 01 43 96 70 33
>  
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From fharrell at virginia.edu  Wed Apr 23 16:35:01 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Wed, 23 Apr 2003 10:35:01 -0400
Subject: [R] documentation for survival5?
In-Reply-To: <200304231527.21749.rdiaz@cnio.es>
References: <5.1.0.14.2.20030423090023.01e7fa28@mcmail.cis.mcmaster.ca>
	<200304231527.21749.rdiaz@cnio.es>
Message-ID: <20030423103501.432a3037.fharrell@virginia.edu>

On Wed, 23 Apr 2003 15:27:21 +0200
Ramon Diaz <rdiaz at cnio.es> wrote:

> Dear Spencer,
> 
> On addition to John's suggestion, you might want to check Frank Harrell's 
> "Regression modeling strategies" (Springer, 2001) which devotes several 
> chapters to survival analysis. It includes discussion of both survival5 and 
> Harrell's additions (in the Hmisc and Design packages).
> 
> Best,
> 
> Ram?n
>

Thanks for the note Ramon.  The Therneau and Grambsch book goes into much more detail about survival analysis, especially time-dependent covariables, random effects, and multiple events.  -Frank
 
> On Wednesday 23 April 2003 15:03, John Fox wrote:
> > Dear Spencer,
> >
> > There is a book by Therneau and Grambsch, Modeling Survival Data (Springer,
> > 2000); Therneau is the author of the survival library for S-PLUS, ported to
> > R. The book covers survival analysis in S-PLUS and SAS.
> >
> > Regards,
> >   John
> >
> > At 05:05 AM 4/23/2003 -0700, Spencer Graves wrote:
> > >           What other references are there on the capabilities of the
> > > survival5 package other than the help files and the chapter on survival
> > > analysis in every edition of Modern Applied Statistics with S?  I'm
> > > thinking of something like "An Introduction to Survival Analysis in R"
> > > with worked examples that might complement or extend the chapter in MASS.
> >
> > -----------------------------------------------------
> > John Fox
> > Department of Sociology
> > McMaster University
> > Hamilton, Ontario, Canada L8S 4M4
> > email: jfox at mcmaster.ca
> > phone: 905-525-9140x23604
> > web: www.socsci.mcmaster.ca/jfox
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> -- 
> Ram?n D?az-Uriarte
> Bioinformatics Unit
> Centro Nacional de Investigaciones Oncol?gicas (CNIO)
> (Spanish National Cancer Center)
> Melchor Fern?ndez Almagro, 3
> 28029 Madrid (Spain)
> Fax: +-34-91-224-6972
> Phone: +-34-91-224-6900
> 
> http://bioinfo.cnio.es/~rdiaz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From tlumley at u.washington.edu  Wed Apr 23 16:44:04 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 23 Apr 2003 07:44:04 -0700 (PDT)
Subject: [R] fisher exact vs. simulated chi-square
In-Reply-To: <0d3f01c3098a$de191b30$6501a8c0@HydePark>
Message-ID: <Pine.A41.4.44.0304230743030.13728-100000@homer40.u.washington.edu>

On Wed, 23 Apr 2003, Bob Porter wrote:

> The Chi-Square test is based upon the assumption that the sample is large enough
> to allow approximation of a (nearly symetric) binomial by a normal distribution.
> (Chi Sqare is z^2).  When expected (NOT observed) cells are too small, that
> suggests a very asymetric binomial and, consequently a poor fit for the
> assumption.  The exact test calculates the exact probability of the observed
> values, or more extreme ones, given the assumed probabilities generating the
> expected values.  As someone else noted, exact is exact, Chi-square is not
> (unless, of course, assumptions are exactly met.)

This is true but not the issue.  The question was about the difference
between the Fisher p.value and a Monte Carlo estimate of the exact p value
for the chisquared statisic.

	-thomas


From tlumley at u.washington.edu  Wed Apr 23 16:46:11 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 23 Apr 2003 07:46:11 -0700 (PDT)
Subject: [R] documentation for survival5?  
In-Reply-To: <3EA68194.4020902@pdf.com>
Message-ID: <Pine.A41.4.44.0304230744190.13728-100000@homer40.u.washington.edu>

On Wed, 23 Apr 2003, Spencer Graves wrote:

> Dear R-Helpers:
>
> 	  What other references are there on the capabilities of the survival5
> package other than the help files and the chapter on survival analysis
> in every edition of Modern Applied Statistics with S?  I'm thinking of
> something like "An Introduction to Survival Analysis in R" with worked
> examples that might complement or extend the chapter in MASS.
>

THere's a book by Therneau and Grambsch called something like "survival
analysis: extending the Cox model".

By December there may be some R vignettes, since I'm teaching survival
analysis in autumn quarter this year.

	-thomas


From EdwardSeelefant at aol.com  Wed Apr 23 17:11:47 2003
From: EdwardSeelefant at aol.com (EdwardSeelefant@aol.com)
Date: Wed, 23 Apr 2003 11:11:47 -0400
Subject: [R] clustering
Message-ID: <3EA979C9.621D4DB6.A88433CE@aol.com>

Dear R-users,

I have a two - dimensional data set which needs to be clustered into
groups:
I'm searching for groups of points which show a positive
correlation (in a twodimensional plot of the data set), but I do not have
any knowledge about how many groups there might be.
Do you know of a clustering algorithm in R (or
in general) which can use a-priori information about the cluster's shape,
in particular that the points of a given cluster should lie on a line?
The "EMclust" algorithm does allow to chose a general shape, such as
"elliptical" for example. However, this method proved not to be
successful.

Thank you very much,
Yours sincererly

Philip


From rab at nauticom.net  Wed Apr 23 17:24:28 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Wed, 23 Apr 2003 11:24:28 -0400
Subject: [R] unique
In-Reply-To: <16037.50437.848602.939080@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
References: <16037.50437.848602.939080@0-e0-98-8a-c5-4a.dhcp.lbl.gov>
Message-ID: <3EA6B02C.80807@nauticom.net>

Francisco J Molina wrote:

>Subject: Eliminate repeated components from a vector
>X-Mailer: VM 7.00 under 21.4 (patch 6) "Common Lisp" XEmacs Lucid
>Reply-To: fjmolina at lbl.gov
>FCC: /home/f/.xemacs/mail/sent
>
>
>Does anyone know how I can eliminate repeated elements from a vector?
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
>  
>
Try "unique".

Rick B.


From p.dalgaard at biostat.ku.dk  Wed Apr 23 17:42:31 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 23 Apr 2003 17:42:31 +0200
Subject: [R] How do I get 10^4 to become 10000?
In-Reply-To: <p05210600bacc4f6eab29@[128.115.153.6]>
References: <20030422015115.GA14368@hortresearch.co.nz>
	<p05210600bacc4f6eab29@[128.115.153.6]>
Message-ID: <x27k9lz0d4.fsf@biostat.ku.dk>

Don MacQueen <macq at llnl.gov> writes:

> How about this?
> 
> >  a <- c('10^4','1.2^3','2.3')
> 
> >  as.numeric(gsub('\\^','E',a))
> [1] 1.0e+05 1.2e+03 2.3e+00
> 
> This solution doesn't work for "10^(-5)" but does work for "10^-5".
> 

Didn't work too well for 1.2^3 by some standards... 

> a <- c('10^4','1.2^3','2.3')
> sapply(parse(text=a),eval)
[1] 10000.000     1.728     2.300

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From sandrine.mainard1 at etud.univ-ubs.fr  Wed Apr 23 17:44:05 2003
From: sandrine.mainard1 at etud.univ-ubs.fr (sandrine.mainard1@etud.univ-ubs.fr)
Date: Wed, 23 Apr 2003 17:44:05 +0200
Subject: [R] about multtest...
Message-ID: <1051112645.3ea6b4c5d60ba@homae.univ-ubs.fr>

Hello,

I'm wondering which correspond "-Inf" and "Inf", in a mt.rawp2adjp, for SidakSS 
and SidakSD. It's a little bit strange,no?!?!

Thanks in advance for any help

Sandrine


--------------------------------------------------------------------------------
Universit de Bretagne sud                               http://www.univ-ubs.fr/


From sandrine.mainard1 at etud.univ-ubs.fr  Wed Apr 23 17:50:19 2003
From: sandrine.mainard1 at etud.univ-ubs.fr (sandrine.mainard1@etud.univ-ubs.fr)
Date: Wed, 23 Apr 2003 17:50:19 +0200
Subject: [R] about multtest...
Message-ID: <1051113019.3ea6b63b7124a@homae.univ-ubs.fr>

Hello,

I'm wondering what mean "-inf" et "inf" for SidakSS and SidakSD in the case of 
a mt.rawp2adjp(in the multtest package).

Thanks a lot in advance.

Sandrine



--------------------------------------------------------------------------------
Universit de Bretagne sud                               http://www.univ-ubs.fr/


From macq at llnl.gov  Wed Apr 23 18:11:05 2003
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 23 Apr 2003 09:11:05 -0700
Subject: [R] How do I get 10^4 to become 10000?
In-Reply-To: <x27k9lz0d4.fsf@biostat.ku.dk>
References: <20030422015115.GA14368@hortresearch.co.nz>
 <p05210600bacc4f6eab29@[128.115.153.6]> <x27k9lz0d4.fsf@biostat.ku.dk>
Message-ID: <p05210604bacc6b823fc6@[128.115.153.6]>

Oops.
Red face here.
-Don

At 5:42 PM +0200 4/23/03, Peter Dalgaard BSA wrote:
>Don MacQueen <macq at llnl.gov> writes:
>
>>  How about this?
>>
>>  >  a <- c('10^4','1.2^3','2.3')
>>
>>  >  as.numeric(gsub('\\^','E',a))
>>  [1] 1.0e+05 1.2e+03 2.3e+00
>>
>>  This solution doesn't work for "10^(-5)" but does work for "10^-5".
>>
>
>Didn't work too well for 1.2^3 by some standards...
>
>>  a <- c('10^4','1.2^3','2.3')
>>  sapply(parse(text=a),eval)
>[1] 10000.000     1.728     2.300
>
>--
>    O__  ---- Peter Dalgaard             Blegdamsvej 3 
>   c/ /'_ --- Dept. of Biostatistics     2200 Cph. N  
>  (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
>~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA


From hennig at stat.math.ethz.ch  Wed Apr 23 18:46:19 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Wed, 23 Apr 2003 18:46:19 +0200 (CEST)
Subject: [R] clustering
In-Reply-To: <3EA979C9.621D4DB6.A88433CE@aol.com>
Message-ID: <Pine.LNX.4.44.0304231839470.12219-100000@florence>

Dear Philip,

as you have already suggested, mclust would be the first choice. Did you
try to run EMclust with emModelNames="VEV"? If you send me the data, I can
take a look at it and see what went wrong.

There is also methodology for clusterwise linear regression (CLR), where the
points of a cluster lie on a line, but there is a distinction between
dependent and independent variable, which may or may not be what you
want. As far as I know, there is nothing for CLR on CRAN, but my R-package
fpc contains a function fixreg for linear regression fixed point clusters
(reference Hennig, Journal of Classification 19, 249-276 (2002)). It can be
obtained under
http://www.math.uni-hamburg.de/home/hennig/fixreg/fixreg.html

Furthermore I have a program for ML-estimation of linear regression
mixtures (reference deSarbo and Cron, Journal of Classification 5, 249-282 
(1988)), but undocumented and for private use. Ask me if you are
interested.

Best,
Christian

On Wed, 23 Apr 2003 EdwardSeelefant at aol.com wrote:

> Dear R-users,
> 
> I have a two - dimensional data set which needs to be clustered into
> groups:
> I'm searching for groups of points which show a positive
> correlation (in a twodimensional plot of the data set), but I do not have
> any knowledge about how many groups there might be.
> Do you know of a clustering algorithm in R (or
> in general) which can use a-priori information about the cluster's shape,
> in particular that the points of a given cluster should lie on a line?
> The "EMclust" algorithm does allow to chose a general shape, such as
> "elliptical" for example. However, this method proved not to be
> successful.
> 
> Thank you very much,
> Yours sincererly
> 
> Philip
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de


From tlumley at u.washington.edu  Wed Apr 23 18:51:16 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 23 Apr 2003 09:51:16 -0700 (PDT)
Subject: [R] about multtest...
In-Reply-To: <1051113019.3ea6b63b7124a@homae.univ-ubs.fr>
Message-ID: <Pine.A41.4.44.0304230929010.72224-100000@homer20.u.washington.edu>

On Wed, 23 Apr 2003 sandrine.mainard1 at etud.univ-ubs.fr wrote:

> Hello,
>
> I'm wondering what mean "-inf" et "inf" for SidakSS and SidakSD in the case of
> a mt.rawp2adjp(in the multtest package).
>

Please don't send these messages to r-announce. r-announce is for
announcements.

Since you are asking about a Bioconductor package, the bioconductor
mailing list might be a better place.


The +Inf and -Inf probably result from taking min() and max() of an empty
set.  Either they should be changed to 1 and 0 respectively or they
indicate that the result is undefined.

	-thomas


From andy_liaw at merck.com  Wed Apr 23 19:07:33 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 23 Apr 2003 13:07:33 -0400
Subject: r-announce (was RE: [R] about multtest...)
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FA3E@usrymx25.merck.com>

> From: Thomas Lumley [mailto:tlumley at u.washington.edu]
> 
> Please don't send these messages to r-announce. r-announce is for
> announcements.

Isn't r-announce supposed to be moderated?  I posted to r-announce about a
minor update in randomForest and was rejected.  I was told that it's meant
for new or significant upgrades in packages, etc.

Andy


From tpapp at axelero.hu  Wed Apr 23 19:44:00 2003
From: tpapp at axelero.hu (Tamas Papp)
Date: Wed, 23 Apr 2003 19:44:00 +0200
Subject: [R] Setting up Xemacs + Sweave
Message-ID: <20030423174359.GA1573@localhost>

Dear list,

I have tried to setup my Xemacs for use with Sweave, which I indend to learn.
I have followed the instructions in the Sweave FAQ, that is to say, I put

(defun Rnw-mode ()
  (require 'ess-noweb)
  (noweb-mode)
  (if (fboundp 'R-mode)
      (setq noweb-default-code-mode 'R-mode)))
(add-to-list 'auto-mode-alist '("\\.Rnw\\'" . Rnw-mode))
(add-to-list 'auto-mode-alist '("\\.Snw\\'" . Rnw-mode))

(setq reftex-file-extensions
      '(("Snw" "Rnw" "nw" "tex" ".tex" ".ltx") ("bib" ".bib")))
(setq TeX-file-extensions
      '("Snw" "Rnw" "nw" "tex" "sty" "cls" "ltx" "texi" "texinfo"))

in my init.el. However, if I open an Rnw file
(/usr/lib/R/library/tools/Sweave/Sweave-test-1.Rnw) it is not treated
as one, only if I evaluate (Rnw-mode) using M-: on the buffer. My
auto-mode-alist looks like this:

(("\\.Snw\\'" . Rnw-mode) ("\\.Rnw\\'" . Rnw-mode) ("\\.lout\\'"
. lout-mode) ("\\.tex\\'" . latex-mode) ("\\.tex$" . yatex-mode)
... ) (I have left the end off)

so it should be working correctly. One strange thing: immediately
after I open the Rnw file, Xemacs gives the following warning:

(1) (local-variables/warning) File local-variables error: Symbol's
function definition is void: noweb-font-lock-mode

I don't know whether this is relevant. I am using debian/testing, the
package versions are:

ii  xemacs21                  21.4.6-8
ii  xemacs21-basesupport      2003.01.27-1.1
ii  xemacs21-bin              21.4.6-8
ii  xemacs21-gnome-nomule     21.4.6-8
ii  xemacs21-support          21.4.6-8
ii  ess                       5.1.24-3
ii  r-base                    1.7.0-0.cran.1
ii  r-base-core               1.6.0.rel-1
ii  r-recommended             1.4.1-1

Regards,

Tamas Papp

-- 
Tam?s K. Papp
E-mail: tpapp at axelero.hu (preferred, especially for large messages)
        tpapp at westel900.net
Please try to send only (latin-2) plain text, not HTML or other garbage.


From rpeng at stat.ucla.edu  Wed Apr 23 19:50:19 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 23 Apr 2003 10:50:19 -0700 (PDT)
Subject: [R] Problem with pixmap on R 1.7.0?
In-Reply-To: <oprn1h0iilfaouaq@200.24.8.4>
Message-ID: <Pine.GSO.4.10.10304231035140.18144-100000@quetelet.stat.ucla.edu>

I think I've gotten this same error on a Linux (Red Hat 8.0) machine.
Here's the traceback:

> z <- read.pnm("llama.pnm")
Error in .class1(object) : Object "from" not found
> traceback()
10: .class1(object)
9: as(from, "pixmapChannels")
8: asMethod(object, Class, value)
7: "as<-"(*tmp*, Classi, value = obj)
6: initialize(value, ...)
5: initialize(value, ...)
4: new("pixmapRGB", pixmap(data, ...))
3: pixmapRGB(0, ncol = dim(res)[2], nrow = dim(res)[3], ...)
2: read.pnmdata(con, pnmhead, ...)
1: read.pnm("llama.pnm")

The image I used is at http://www.stat.ucla.edu/~rpeng/llama.pnm.  One
other thing -- this image used to be a JPEG file and I converted it to pnm
using the `convert' program from ImageMagick.  It's possible that
ImageMagick is screwing something up to but I'm not sure how to figure
that out.  

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Tue, 22 Apr 2003, Kenneth Cabrera wrote:

> Hi R users:
> I got the following message when I use the pixmap library
> on R 1.7.0 over w2K platform (on R 1.6.2 it runs right).
> 
> pixmapGrey(matrix(c(0,1),128,128))
> Error in .class1(object) : Object "from" not found
> 
> I download the library .zip file from:
> 
> http://cran.r-project.org/bin/windows/contrib/1.7/pixmap_0.3-2.zip
> 
> Other question:
> 
> When I try to "Install package(s) from bioconductor" I got the
> following message:
> 
> local({a<-CRAN.packages(CRAN=getOption("BIOC"))
> + install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a, 
> CRAN=getOption("BIOC"))})
> 
> trying URL `http://www.bioconductor.org/bin/windows/contrib/1.7/PACKAGES'
> Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  : 
> cannot open: HTTP status was `404 Not Found'
> 
> Are the packages in other path of www.bioconductor.org? Which one?
> 
> Thank you for your help.
> 
> Kenneth
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From info at rhkoning.com  Wed Apr 23 19:56:09 2003
From: info at rhkoning.com (Ruud H. Koning)
Date: Wed, 23 Apr 2003 19:56:09 +0200
Subject: [R] equipment
Message-ID: <200304231956090741.001FA343@192.168.1.66>

Hello, it is likely that I will have to analyze a rather sizeable dataset:
60000 records, 10 to 15 variables. I will have to make descriptive
statistics, and estimate linear models, glm's and maybe Cox proportional
hazard model with time varying covariates. In theory, this is possible in
R, but I would like to get some feedback on the equipment I should get for
this. At this moment, I have a Pentium 3 laptop running windows 2000 with
384MB ram. What type of cpu-speed and/or how much memory should I get?
Thanks for some ideas, Ruud


From lm.silva at sapo.pt  Wed Apr 23 19:57:30 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Wed, 23 Apr 2003 18:57:30 +0100 (WEST)
Subject: [R] sum
Message-ID: <1051120650.3ea6d40a13183@webmail.sapo.pt>

Dear helpers

I have a list where each element is a matrix (the list is 
obtained with lapply). I want to sum those matrices. Is there a 
function to do that? The sum function sums all the elements...
--


http://adsl.sapo.pt


From vograno at arbitrade.com  Wed Apr 23 20:25:13 2003
From: vograno at arbitrade.com (Vadim Ogranovich)
Date: Wed, 23 Apr 2003 13:25:13 -0500
Subject: [R] sum
Message-ID: <AFD78192EC49D311BFAE00902798AB8F23DDA9@jupiter.arbitrade.com>

Luis,

I use this:

# sum of list l
l.sum <- l[[1]]  # just to create the result matrix with proper dimensions
and dimnames
l.sum[] <- colSums(do.call("rbind", l))

There might (or might not) be a problem if your matrix is stored by row.
Just a word caution as I never checked this out.

Hope this helps,
Vadim

> -----Original Message-----
> From: Luis Silva [mailto:lm.silva at sapo.pt]
> Sent: Wednesday, April 23, 2003 10:58 AM
> To: R help
> Subject: [R] sum
> 
> 
> Dear helpers
> 
> I have a list where each element is a matrix (the list is 
> obtained with lapply). I want to sum those matrices. Is there a 
> function to do that? The sum function sums all the elements...
> --
> 
> 
> http://adsl.sapo.pt
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-------------------------------------------------- 
DISCLAIMER\ This e-mail, and any attachments thereto, is intende... {{dropped}}


From jerome at hivnet.ubc.ca  Wed Apr 23 20:29:03 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Wed, 23 Apr 2003 11:29:03 -0700
Subject: [R] sum
In-Reply-To: <1051120650.3ea6d40a13183@webmail.sapo.pt>
References: <1051120650.3ea6d40a13183@webmail.sapo.pt>
Message-ID: <200304231834.LAA03026@hivnet.ubc.ca>


The only way I can see is to vectorize your list of matrices. Here's an 
example.

matlist <- lapply(1:10,function(i) matrix(rnorm(12),3,4))
summat <- matrix(sapply(matlist,I)%*%rep(1,10),3,4)

You can use the loop below to verify that the above solution is correct.

forsum <- matrix(0,3,4)
for(i in 1:10)
forsum <- forsum+matlist[[i]]

"summat" and "forsum" should be the same.

HTH,
Jerome

On April 23, 2003 10:57 am, Luis Silva wrote:
> Dear helpers
>
> I have a list where each element is a matrix (the list is
> obtained with lapply). I want to sum those matrices. Is there a
> function to do that? The sum function sums all the elements...


From p.dalgaard at biostat.ku.dk  Wed Apr 23 20:34:15 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 23 Apr 2003 20:34:15 +0200
Subject: [R] equipment
In-Reply-To: <200304231956090741.001FA343@192.168.1.66>
References: <200304231956090741.001FA343@192.168.1.66>
Message-ID: <x21xztawrc.fsf@biostat.ku.dk>

"Ruud H. Koning" <info at rhkoning.com> writes:

> Hello, it is likely that I will have to analyze a rather sizeable dataset:
> 60000 records, 10 to 15 variables. I will have to make descriptive
> statistics, and estimate linear models, glm's and maybe Cox proportional
> hazard model with time varying covariates. In theory, this is possible in
> R, but I would like to get some feedback on the equipment I should get for
> this. At this moment, I have a Pentium 3 laptop running windows 2000 with
> 384MB ram. What type of cpu-speed and/or how much memory should I get?
> Thanks for some ideas, Ruud

Except for the time-varying Cox thing, this doesn't seem too hard:

> d <- as.data.frame(matrix(rnorm(60000*15),60000,15))
> names(d)
 [1] "V1"  "V2"  "V3"  "V4"  "V5"  "V6"  "V7"  "V8"  "V9"  "V10" "V11" "V12"
[13] "V13" "V14" "V15"
> system.time(lm(V15~.,data=d))
[1] 2.62 0.61 3.24 0.00 0.00
> gc()
          used (Mb) gc trigger (Mb)
Ncells  431614 11.6     741108 19.8
Vcells 1079809  8.3    6817351 52.1

That's on the fastest machine I have access to, a 2.8GHz Xeon (Dual,
but not with threaded BLAS lib). About three times slower on a 900 MHz
PIII. For GLM you'll do similar  operations iterated say 5 times, and
if you have factors and interactions among your predictors, you'll get
essentially an increase proportional to the number of parameters in
the model. 

Time-dependent Cox in full generality has complexity proportional to
the square of the data set (one regression computation per death)
which could be prohibitive, but there are often simplifications,
depending on the nature of the time dependency.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From B.Rowlingson at lancaster.ac.uk  Wed Apr 23 20:37:01 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 23 Apr 2003 19:37:01 +0100
Subject: [R] sum
In-Reply-To: <1051120650.3ea6d40a13183@webmail.sapo.pt>
References: <1051120650.3ea6d40a13183@webmail.sapo.pt>
Message-ID: <3EA6DD4D.4090603@lancaster.ac.uk>

Luis Silva wrote:
> Dear helpers
> 
> I have a list where each element is a matrix (the list is 
> obtained with lapply). I want to sum those matrices. Is there a 
> function to do that? The sum function sums all the elements...

  Since your matrix elements must be all the same shape (rows x columns) 
for you to sum them, you could store them in an array (see ?array) 
rather than a list. Then all you need do is apply 'sum' to two 
dimensions of the array.

  Here's a one-liner that converts your list into an array (by unlisting 
it and then packing into an array with the right three dimensions) and 
then runs apply(...,c(1,2),sum) to get the answer you want:

  First some sample data:

 > foo
[[1]]
      [,1] [,2] [,3]
[1,]    1    3    5
[2,]    2    4    6

[[2]]
           [,1]      [,2]      [,3]
[1,] 0.1666667 0.5000000 0.8333333
[2,] 0.3333333 0.6666667 1.0000000

[[3]]
      [,1] [,2] [,3]
[1,]  0.5  0.5  0.5
[2,]  0.5  0.5  0.5

[[4]]
      [,1] [,2] [,3]
[1,] 0.01 0.01 0.01
[2,] 0.01 0.01 0.01

 > 
apply(array(unlist(foo),c(dim(foo[[1]])[1],dim(foo[[1]])[2],length(foo))),c(1,2),sum)
          [,1]     [,2]     [,3]
[1,] 1.676667 4.010000 6.343333
[2,] 2.843333 5.176667 7.510000

I'm sure there's a better way.

Baz


From sundar.dorai-raj at pdf.com  Wed Apr 23 20:42:03 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 23 Apr 2003 13:42:03 -0500
Subject: [R] sum
References: <1051120650.3ea6d40a13183@webmail.sapo.pt>
Message-ID: <3EA6DE7B.2080005@pdf.com>



Luis Silva wrote:
> Dear helpers
> 
> I have a list where each element is a matrix (the list is 
> obtained with lapply). I want to sum those matrices. Is there a 
> function to do that? The sum function sums all the elements...
> --
> 

How about:

R> r = list(matrix(1:4,2,2),matrix(5:8,2,2),matrix(9:12,2,2))
R> expr = paste("r[[",seq(along = r),"]]", collapse="+")
R> eval(parse(text = expr))
      [,1] [,2]
[1,]   15   21
[2,]   18   24


Regards,
Sundar


From tblackw at umich.edu  Wed Apr 23 20:45:18 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 23 Apr 2003 14:45:18 -0400 (EDT)
Subject: [R] equipment
In-Reply-To: <200304231956090741.001FA343@192.168.1.66>
Message-ID: <Pine.SOL.4.44.0304231435490.29809-100000@rygar.gpcc.itd.umich.edu>

Ruud  -

Use your existing machine.  Here's a rough calculation:

60,000 rows x 15 columns x 8 bytes = 7.2 Mb per copy of the
data set x 10 - 20 copies of the data set in memory while
you do the calculations = 72 - 144 Mb memory requirements.

Is it 12 bytes per double instead of 8 in this implementation
of the S language ?  (I think it is 12 for S-Plus.)  Have I
missed a factor of 10 somewhere here ?

I think you should be okay with your existing machine.
Close other processes when you do the analysis.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 23 Apr 2003, Ruud H. Koning wrote:

> Hello, it is likely that I will have to analyze a rather sizeable dataset:
> 60000 records, 10 to 15 variables. I will have to make descriptive
> statistics, and estimate linear models, glm's and maybe Cox proportional
> hazard model with time varying covariates. In theory, this is possible in
> R, but I would like to get some feedback on the equipment I should get for
> this. At this moment, I have a Pentium 3 laptop running windows 2000 with
> 384MB ram. What type of cpu-speed and/or how much memory should I get?
> Thanks for some ideas, Ruud


From spencer.graves at pdf.com  Wed Apr 23 20:49:07 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 23 Apr 2003 11:49:07 -0700
Subject: [R] sum
References: <1051120650.3ea6d40a13183@webmail.sapo.pt>
	<200304231834.LAA03026@hivnet.ubc.ca>
Message-ID: <3EA6E023.9070101@pdf.com>

Can you create a 3-d array rather than a list?  If yes, "apply" will work.

hth.  spencer graves

Jerome Asselin wrote:
> The only way I can see is to vectorize your list of matrices. Here's an 
> example.
> 
> matlist <- lapply(1:10,function(i) matrix(rnorm(12),3,4))
> summat <- matrix(sapply(matlist,I)%*%rep(1,10),3,4)
> 
> You can use the loop below to verify that the above solution is correct.
> 
> forsum <- matrix(0,3,4)
> for(i in 1:10)
> forsum <- forsum+matlist[[i]]
> 
> "summat" and "forsum" should be the same.
> 
> HTH,
> Jerome
> 
> On April 23, 2003 10:57 am, Luis Silva wrote:
> 
>>Dear helpers
>>
>>I have a list where each element is a matrix (the list is
>>obtained with lapply). I want to sum those matrices. Is there a
>>function to do that? The sum function sums all the elements...
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From bates at stat.wisc.edu  Wed Apr 23 20:51:34 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 23 Apr 2003 13:51:34 -0500
Subject: [R] equipment
In-Reply-To: <200304231956090741.001FA343@192.168.1.66>
References: <200304231956090741.001FA343@192.168.1.66>
Message-ID: <6rn0ih2gjt.fsf@bates4.stat.wisc.edu>

"Ruud H. Koning" <info at rhkoning.com> writes:

> Hello, it is likely that I will have to analyze a rather sizeable dataset:
> 60000 records, 10 to 15 variables. I will have to make descriptive
> statistics, and estimate linear models, glm's and maybe Cox proportional
> hazard model with time varying covariates. In theory, this is possible in
> R, but I would like to get some feedback on the equipment I should get for
> this. At this moment, I have a Pentium 3 laptop running windows 2000 with
> 384MB ram. What type of cpu-speed and/or how much memory should I get?
> Thanks for some ideas, Ruud

If you are buying a new computer then CPU speed will be less important
than memory.  Most new computers using Intel or AMD processors have
CPU speeds in excess of 1 GHz - frequently 2 GHz or more.  You probably
wouldn't be able to notice the difference between a 1.8 GHz processor
and a 2.8 GHz processor for most work in R so paying extra for a
nominally faster processor is not a good bargain.

Try to get as much memory as your budget will allow.  For a laptop
that may be 512 MB.  For a desktop computer consider 1 GB.

We have fit linear mixed-effects models on 300,000 observations and
with 40 or 50 columns in the model matrix in about 5 minutes on
a 2.0 GHz machine with 1 GB memory using recent versions of R.  Linear
models and glms should be faster than this.


From lm.silva at sapo.pt  Wed Apr 23 21:03:35 2003
From: lm.silva at sapo.pt (Luis Silva)
Date: Wed, 23 Apr 2003 20:03:35 +0100 (WEST)
Subject: [R] sum
In-Reply-To: <3EA6DE7B.2080005@pdf.com>
References: <1051120650.3ea6d40a13183@webmail.sapo.pt>
	<3EA6DE7B.2080005@pdf.com>
Message-ID: <1051124615.3ea6e3877697a@webmail.sapo.pt>

It worked! thanks

luis

P.S. I realy don't know nothing about R..
--


http://adsl.sapo.pt


From rpeng at stat.ucla.edu  Wed Apr 23 21:08:15 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 23 Apr 2003 12:08:15 -0700 (PDT)
Subject: [R] sum
In-Reply-To: <1051120650.3ea6d40a13183@webmail.sapo.pt>
Message-ID: <Pine.GSO.4.10.10304231206120.24600-100000@quetelet.stat.ucla.edu>

How about something like:

> matlist <- list(matrix(1:16, 4, 4), matrix(2, 4, 4))
> do.call("+", matlist)
     [,1] [,2] [,3] [,4]
[1,]    3    7   11   15
[2,]    4    8   12   16
[3,]    5    9   13   17
[4,]    6   10   14   18
> 

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Wed, 23 Apr 2003, Luis Silva wrote:

> Dear helpers
> 
> I have a list where each element is a matrix (the list is 
> obtained with lapply). I want to sum those matrices. Is there a 
> function to do that? The sum function sums all the elements...
> --
> 
> 
> http://adsl.sapo.pt
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From fzagmutt at hotmail.com  Wed Apr 23 21:27:54 2003
From: fzagmutt at hotmail.com (Francisco J. Zagmutt Vergara)
Date: Wed, 23 Apr 2003 19:27:54 +0000
Subject: [R] predicted means on mixed models
Message-ID: <Law15-F4Z2wleBC5RH20000a4aa@hotmail.com>

Hi everybody

I am trying to move from SAS to R and there is a couple of things that I 
have not been able to obtain from the nlme3 module (mixed models)
I want to compare the differences between different levels of a categorical 
variable in presence of a non-ignorable interaction compromising this 
variable. To do this I SAS gives you the possibility to extract predicted 
population margins (they call them least squares means or LS means) for each 
level of a categorical fixed effect in the model, so these values can then 
be used to perform multiple comparisons and look for meaningful differences 
between levels of a categorical fixed effect. I guess that in R I could do 
this manually by using the augPred() function for each possible combination 
and then performing multiple comparisons over these values but I just want 
to know if there is and already built-in function to do this.  Also In SAS 
exists an option to "slice" the LSMeans output so you can obtain
separated outputs for each level of the variable (test of simple effects).  
This is very handy when it comes to evaluate levels of nested
and/or interaction terms. Is there sometihing similar available in R?

Thanks for your help!


Francisco





_________________________________________________________________

http://messenger.yupimsn.com/


From andy_liaw at merck.com  Wed Apr 23 21:31:50 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 23 Apr 2003 15:31:50 -0400
Subject: [R] sum
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FA47@usrymx25.merck.com>

Won't work if the list has more than 2 matrices.

Andy

> From: Roger Peng [mailto:rpeng at stat.ucla.edu]
> 
> How about something like:
> 
> > matlist <- list(matrix(1:16, 4, 4), matrix(2, 4, 4))
> > do.call("+", matlist)
>      [,1] [,2] [,3] [,4]
> [1,]    3    7   11   15
> [2,]    4    8   12   16
> [3,]    5    9   13   17
> [4,]    6   10   14   18
> > 
> 
> -roger
> _______________________________
> UCLA Department of Statistics
> http://www.stat.ucla.edu/~rpeng
> 
> On Wed, 23 Apr 2003, Luis Silva wrote:
> 
> > Dear helpers
> > 
> > I have a list where each element is a matrix (the list is 
> > obtained with lapply). I want to sum those matrices. Is there a 
> > function to do that? The sum function sums all the elements...
> > --
> > 
> > 
> > http://adsl.sapo.pt
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, cont... {{dropped}}


From deepayan at stat.wisc.edu  Wed Apr 23 21:33:29 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 23 Apr 2003 14:33:29 -0500
Subject: [R] sum
In-Reply-To: <1051120650.3ea6d40a13183@webmail.sapo.pt>
References: <1051120650.3ea6d40a13183@webmail.sapo.pt>
Message-ID: <200304231433.29193.deepayan@stat.wisc.edu>


On Wednesday 23 April 2003 12:57 pm, Luis Silva wrote:
> Dear helpers
>
> I have a list where each element is a matrix (the list is
> obtained with lapply). I want to sum those matrices. Is there a
> function to do that? The sum function sums all the elements...

If the list is not too long, perhaps

sumlist <- 
    function(x) 
        if (length(x) > 2) sumlist(x[1:2]) + 
             sumlist(x[-(1:2)]) else do.call("+", x) 



sumlist(<whatever your list is>)


-Deepayan


From rpeng at stat.ucla.edu  Wed Apr 23 22:50:29 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 23 Apr 2003 13:50:29 -0700 (PDT)
Subject: [R] sum
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4FA47@usrymx25.merck.com>
Message-ID: <Pine.GSO.4.10.10304231347080.1906-100000@quetelet.stat.ucla.edu>

Yes, the definition of "binary operator" seems to have escaped me this
morning.  I was looking for something along the lines of Deepayan's
answer.

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Wed, 23 Apr 2003, Liaw, Andy wrote:

> Won't work if the list has more than 2 matrices.
> 
> Andy
> 
> > From: Roger Peng [mailto:rpeng at stat.ucla.edu]
> > 
> > How about something like:
> > 
> > > matlist <- list(matrix(1:16, 4, 4), matrix(2, 4, 4))
> > > do.call("+", matlist)
> >      [,1] [,2] [,3] [,4]
> > [1,]    3    7   11   15
> > [2,]    4    8   12   16
> > [3,]    5    9   13   17
> > [4,]    6   10   14   18
> > > 
> > 
> > -roger
> > _______________________________
> > UCLA Department of Statistics
> > http://www.stat.ucla.edu/~rpeng
> > 
> > On Wed, 23 Apr 2003, Luis Silva wrote:
> > 
> > > Dear helpers
> > > 
> > > I have a list where each element is a matrix (the list is 
> > > obtained with lapply). I want to sum those matrices. Is there a 
> > > function to do that? The sum function sums all the elements...
> > > --
> > > 
> > > 
> > > http://adsl.sapo.pt
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> ------------------------------------------------------------------------------
> Notice: This e-mail message, together with any attachments, cont... {{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From jfox at mcmaster.ca  Wed Apr 23 22:52:45 2003
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 23 Apr 2003 16:52:45 -0400
Subject: [R] sum
In-Reply-To: <200304231433.29193.deepayan@stat.wisc.edu>
References: <1051120650.3ea6d40a13183@webmail.sapo.pt>
 <1051120650.3ea6d40a13183@webmail.sapo.pt>
Message-ID: <5.1.0.14.2.20030423164949.01e86df0@mcmail.cis.mcmaster.ca>

Dear Luis,

On Wednesday 23 April 2003 12:57 pm, Luis Silva wrote:
 > I have a list where each element is a matrix (the list is
 > obtained with lapply). I want to sum those matrices. Is there a
 > function to do that? The sum function sums all the elements...

Here's a recursive function that works with a list of two or more matrices:

     sumMatrices <- function(matrices){
         if (length(matrices) > 2) matrices[[1]] + Recall(matrices[-1])
         else matrices[[1]] + matrices[[2]]
         }

Regards,
  John



-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox


From anderson at unt.edu  Wed Apr 23 23:11:33 2003
From: anderson at unt.edu (Richard Anderson)
Date: Wed, 23 Apr 2003 16:11:33 -0500
Subject: [R] Changing the size of the bounding box
Message-ID: <20030423211133.GA24645@sushi.infosec.unt.edu>

Greetings all:

I have to create a graph that has very specific dimensions for
publication purposes.  The graph is a semilog scaled graph and the
axes must range from 1 to 1,000,000 on the y axis and 0 to 100 on the
x axis.  The x axis should be exactly 8 inches and the y axis should
be exactly 5.25 inches.  I've been able to set the plot area to 8 x
5.25 using the par(pin=c(8,5.25)).  The problem that I'm running into
is that R seems to extend my data range by 4% to create a "bounding
box" and this throws off the layout of my graph.  Is there some way
to change this behavior?  Thanks in advance for any help.

-- 
Richard L. Anderson, MS
Security Analyst, University of North Texas
UNT Computing Center
<mailto:anderson at unt.edu>


From tomas.willebrand at szooek.slu.se  Thu Apr 24 00:18:45 2003
From: tomas.willebrand at szooek.slu.se (Tomas Willebrand)
Date: Wed, 23 Apr 2003 23:18:45 +0100
Subject: [R] Unable to install Hmisc
Message-ID: <200304232318.46038.tomas.willebrand@szooek.slu.se>

Hi!

I am trying to add library Hmisc(1.5-4) to R-base(1.6.2-1) on a Linux box with 
a SuSE 8.2 installed but get the following error message:

gcc -shared -L/usr/local/lib -o Hmisc.so cidxcn.o cidxcp.o hoeffd.o largrec.o 
ranksort.o rcorr.o wclosest.o  -L/usr/local/lib 
-L/usr/lib/gcc-lib/i486-suse-linux/3.2 
-L/usr/lib/gcc-lib/i486-suse-linux/3.2/../../../../i486-suse-linux/lib 
-L/usr/lib/gcc-lib/i486-suse-linux/3.2/../../.. -lreadline -ldl -lncurses 
-lfrtbegin -lg2c -lm -lgcc_s -L/usr/lib/R/bin -lR
/usr/lib/gcc-lib/i486-suse-linux/3.2/../../../../i486-suse-linux/bin/ld: kan 
inte hitta -lreadline
collect2: ld returned 1 exit status
make: *** [Hmisc.so] Error 1
ERROR: compilation failed for package 'Hmisc'
............................................................................
Other libraries install OK. 

Yours

Tomas


From ligges at statistik.uni-dortmund.de  Wed Apr 23 23:21:11 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 23 Apr 2003 23:21:11 +0200
Subject: [R] Problem with pixmap on R 1.7.0?
In-Reply-To: <Pine.GSO.4.10.10304231035140.18144-100000@quetelet.stat.ucla.edu>
References: <Pine.GSO.4.10.10304231035140.18144-100000@quetelet.stat.ucla.edu>
Message-ID: <3EA703C7.7000404@statistik.uni-dortmund.de>

Roger Peng wrote:
> I think I've gotten this same error on a Linux (Red Hat 8.0) machine.
> Here's the traceback:
> 
> 
>>z <- read.pnm("llama.pnm")
> 
> Error in .class1(object) : Object "from" not found
> 
>>traceback()
> 
> 10: .class1(object)
> 9: as(from, "pixmapChannels")
> 8: asMethod(object, Class, value)
> 7: "as<-"(*tmp*, Classi, value = obj)
> 6: initialize(value, ...)
> 5: initialize(value, ...)
> 4: new("pixmapRGB", pixmap(data, ...))
> 3: pixmapRGB(0, ncol = dim(res)[2], nrow = dim(res)[3], ...)
> 2: read.pnmdata(con, pnmhead, ...)
> 1: read.pnm("llama.pnm")
> 
> The image I used is at http://www.stat.ucla.edu/~rpeng/llama.pnm.  One
> other thing -- this image used to be a JPEG file and I converted it to pnm
> using the `convert' program from ImageMagick.  It's possible that
> ImageMagick is screwing something up to but I'm not sure how to figure
> that out.  

Was this installed on R-1.6.2 and not reinstalled after upgarding?
Try to reinstall teh package.

Uwe Ligges


> -roger
> _______________________________
> UCLA Department of Statistics
> http://www.stat.ucla.edu/~rpeng
> 
> On Tue, 22 Apr 2003, Kenneth Cabrera wrote:
> 
> 
>>Hi R users:
>>I got the following message when I use the pixmap library
>>on R 1.7.0 over w2K platform (on R 1.6.2 it runs right).
>>
>>pixmapGrey(matrix(c(0,1),128,128))
>>Error in .class1(object) : Object "from" not found
>>
>>I download the library .zip file from:
>>
>>http://cran.r-project.org/bin/windows/contrib/1.7/pixmap_0.3-2.zip
>>
>>Other question:
>>
>>When I try to "Install package(s) from bioconductor" I got the
>>following message:
>>
>>local({a<-CRAN.packages(CRAN=getOption("BIOC"))
>>+ install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a, 
>>CRAN=getOption("BIOC"))})
>>
>>trying URL `http://www.bioconductor.org/bin/windows/contrib/1.7/PACKAGES'
>>Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  : 
>>cannot open: HTTP status was `404 Not Found'
>>
>>Are the packages in other path of www.bioconductor.org? Which one?
>>
>>Thank you for your help.
>>
>>Kenneth
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ihaka at stat.auckland.ac.nz  Wed Apr 23 23:21:57 2003
From: ihaka at stat.auckland.ac.nz (Ross Ihaka)
Date: Thu, 24 Apr 2003 09:21:57 +1200
Subject: [R] Changing the size of the bounding box
References: <20030423211133.GA24645@sushi.infosec.unt.edu>
Message-ID: <3EA703F5.9080807@stat.auckland.ac.nz>

Richard Anderson wrote:
> Greetings all:
> 
> I have to create a graph that has very specific dimensions for
> publication purposes.  The graph is a semilog scaled graph and the
> axes must range from 1 to 1,000,000 on the y axis and 0 to 100 on the
> x axis.  The x axis should be exactly 8 inches and the y axis should
> be exactly 5.25 inches.  I've been able to set the plot area to 8 x
> 5.25 using the par(pin=c(8,5.25)).  The problem that I'm running into
> is that R seems to extend my data range by 4% to create a "bounding
> box" and this throws off the layout of my graph.  Is there some way
> to change this behavior?  Thanks in advance for any help.

You can use "xaxs" and "yaxs".  For example

   plot(1:10, xaxs="i", yaxs="i")

or use par() to set these permanantly.

   ?par

will gt you documentation.

-- 
Ross Ihaka                         Email:  ihaka at stat.auckland.ac.nz
Department of Statistics           Phone:  (64-9) 373-7599 x 85054
University of Auckland             Fax:    (64-9) 373-7018
Private Bag 92019, Auckland
New Zealand


From rpeng at stat.ucla.edu  Wed Apr 23 23:32:01 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 23 Apr 2003 14:32:01 -0700 (PDT)
Subject: [R] Problem with pixmap on R 1.7.0?
In-Reply-To: <3EA703C7.7000404@statistik.uni-dortmund.de>
Message-ID: <Pine.GSO.4.10.10304231430410.4575-100000@quetelet.stat.ucla.edu>

Removing the `pixmap' package (i.e. via remove.packages() ) and
reinstalling it fixed this problem.  Thanks.

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Wed, 23 Apr 2003, Uwe Ligges wrote:

> Roger Peng wrote:
> > I think I've gotten this same error on a Linux (Red Hat 8.0) machine.
> > Here's the traceback:
> > 
> > 
> >>z <- read.pnm("llama.pnm")
> > 
> > Error in .class1(object) : Object "from" not found
> > 
> >>traceback()
> > 
> > 10: .class1(object)
> > 9: as(from, "pixmapChannels")
> > 8: asMethod(object, Class, value)
> > 7: "as<-"(*tmp*, Classi, value = obj)
> > 6: initialize(value, ...)
> > 5: initialize(value, ...)
> > 4: new("pixmapRGB", pixmap(data, ...))
> > 3: pixmapRGB(0, ncol = dim(res)[2], nrow = dim(res)[3], ...)
> > 2: read.pnmdata(con, pnmhead, ...)
> > 1: read.pnm("llama.pnm")
> > 
> > The image I used is at http://www.stat.ucla.edu/~rpeng/llama.pnm.  One
> > other thing -- this image used to be a JPEG file and I converted it to pnm
> > using the `convert' program from ImageMagick.  It's possible that
> > ImageMagick is screwing something up to but I'm not sure how to figure
> > that out.  
> 
> Was this installed on R-1.6.2 and not reinstalled after upgarding?
> Try to reinstall teh package.
> 
> Uwe Ligges
> 
> 
> > -roger
> > _______________________________
> > UCLA Department of Statistics
> > http://www.stat.ucla.edu/~rpeng
> > 
> > On Tue, 22 Apr 2003, Kenneth Cabrera wrote:
> > 
> > 
> >>Hi R users:
> >>I got the following message when I use the pixmap library
> >>on R 1.7.0 over w2K platform (on R 1.6.2 it runs right).
> >>
> >>pixmapGrey(matrix(c(0,1),128,128))
> >>Error in .class1(object) : Object "from" not found
> >>
> >>I download the library .zip file from:
> >>
> >>http://cran.r-project.org/bin/windows/contrib/1.7/pixmap_0.3-2.zip
> >>
> >>Other question:
> >>
> >>When I try to "Install package(s) from bioconductor" I got the
> >>following message:
> >>
> >>local({a<-CRAN.packages(CRAN=getOption("BIOC"))
> >>+ install.packages(select.list(a[,1],,TRUE), .libPaths()[1], available=a, 
> >>CRAN=getOption("BIOC"))})
> >>
> >>trying URL `http://www.bioconductor.org/bin/windows/contrib/1.7/PACKAGES'
> >>Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  : 
> >>cannot open: HTTP status was `404 Not Found'
> >>
> >>Are the packages in other path of www.bioconductor.org? Which one?
> >>
> >>Thank you for your help.
> >>
> >>Kenneth
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >>
> > 
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>


From p.dalgaard at biostat.ku.dk  Wed Apr 23 23:50:06 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 23 Apr 2003 23:50:06 +0200
Subject: [R] sum
In-Reply-To: <3EA6DD4D.4090603@lancaster.ac.uk>
References: <1051120650.3ea6d40a13183@webmail.sapo.pt>
	<3EA6DD4D.4090603@lancaster.ac.uk>
Message-ID: <x2wuhkanox.fsf@biostat.ku.dk>

Barry Rowlingson <B.Rowlingson at lancaster.ac.uk> writes:

> Luis Silva wrote:
> > Dear helpers
> > I have a list where each element is a matrix (the list is obtained
> > with lapply). I want to sum those matrices. Is there a function to
> > do that? The sum function sums all the elements...

>   Here's a one-liner that converts your list into an array (by
> unlisting it and then packing into an array with the right three
> dimensions) and then runs apply(...,c(1,2),sum) to get the answer you
> want:

Didn't someone do an abind() function at some point? (Generalizing
cbind/rbind) 
 
> apply(array(unlist(foo),c(dim(foo[[1]])[1],dim(foo[[1]])[2],length(foo))),c(1,2),sum)
>           [,1]     [,2]     [,3]
> [1,] 1.676667 4.010000 6.343333
> [2,] 2.843333 5.176667 7.510000
> 
> I'm sure there's a better way.

l <- foo
apply(array(unlist(l),c(dim(l[[1]]),length(l))),c(1,2),sum)

is a bit shorter.

Even shorter, although I'm not sure better in all senses of the word,
same basic idea:

matrix(apply(sapply(l,c),1,sum),dim(l[[1]]))

However, aren't we ignoring the obvious?:

s<-0;(for(a in l)s<-s+a)


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From jerome at hivnet.ubc.ca  Wed Apr 23 23:53:50 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Wed, 23 Apr 2003 14:53:50 -0700
Subject: [R] Changing the size of the bounding box
In-Reply-To: <20030423211133.GA24645@sushi.infosec.unt.edu>
References: <20030423211133.GA24645@sushi.infosec.unt.edu>
Message-ID: <200304232159.OAA11977@hivnet.ubc.ca>


If you are using postscript files, see ?postscript to specify the width 
and height of the plot.
See also Section 12.5.3 (Figure margins) of the manual "An Introduction to 
R". Hopefully, it'll help you fix your apparent margins problem.
See also "xlim" and "ylim" in plot() to specify the range. And see "xlog" 
and "ylog" of par() to use log-scale.

Jerome

On April 23, 2003 02:11 pm, Richard Anderson wrote:
> Greetings all:
>
> I have to create a graph that has very specific dimensions for
> publication purposes.  The graph is a semilog scaled graph and the
> axes must range from 1 to 1,000,000 on the y axis and 0 to 100 on the
> x axis.  The x axis should be exactly 8 inches and the y axis should
> be exactly 5.25 inches.  I've been able to set the plot area to 8 x
> 5.25 using the par(pin=c(8,5.25)).  The problem that I'm running into
> is that R seems to extend my data range by 4% to create a "bounding
> box" and this throws off the layout of my graph.  Is there some way
> to change this behavior?  Thanks in advance for any help.


From Jeff.Breiwick at noaa.gov  Thu Apr 24 00:03:51 2003
From: Jeff.Breiwick at noaa.gov (Jeff Breiwick)
Date: Wed, 23 Apr 2003 15:03:51 -0700
Subject: [R] Comparing formulas
In-Reply-To: <200304231004.h3NA4RUb002432@hypatia.math.ethz.ch>
Message-ID: <000001c309e4$3968d170$84b037a1@nmml1012breiwxp>

Dear All,

I want to compare formulas resulting from using stepAIC() on glm() objects.
I have 2 different formulas, say F1 and F2, which consist of about 10
factors (Y~A+B+C+...) but one has an interaction term (A:B) while the other
doesn't. But when I perform F1==F2 it comes back as TRUE. Is there a proper
way to compare formulas? 

-------------------------------------------
Jeffrey M Breiwick, Ph.D.
National Marine Mammal Lab., AFSC, NOAA
7600 Sand Point Way NE, Bldg. 4
Seattle, Washington 98115    USA


From spencer.graves at pdf.com  Thu Apr 24 00:31:06 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 23 Apr 2003 15:31:06 -0700
Subject: [R] Comparing formulas
References: <000001c309e4$3968d170$84b037a1@nmml1012breiwxp>
Message-ID: <3EA7142A.3090009@pdf.com>

Could you please provided specific examples?  This would allow others to 
more easily see if they can replicate the problem and then test their 
favorite solution.

spencer graves

Jeff Breiwick wrote:
> Dear All,
> 
> I want to compare formulas resulting from using stepAIC() on glm() objects.
> I have 2 different formulas, say F1 and F2, which consist of about 10
> factors (Y~A+B+C+...) but one has an interaction term (A:B) while the other
> doesn't. But when I perform F1==F2 it comes back as TRUE. Is there a proper
> way to compare formulas? 
> 
> -------------------------------------------
> Jeffrey M Breiwick, Ph.D.
> National Marine Mammal Lab., AFSC, NOAA
> 7600 Sand Point Way NE, Bldg. 4
> Seattle, Washington 98115    USA
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From erich.neuwirth at univie.ac.at  Thu Apr 24 00:38:36 2003
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Thu, 24 Apr 2003 00:38:36 +0200
Subject: [R] R (D)COM server 1.2 and RExcel 1.0 available
Message-ID: <3EA715EC.6020404@univie.ac.at>

We have uploaded a major upgrade of our packages

R (D)COM Server V1.2
and
RExcel 1.0

The combined package is available in the
Software->Other
section of CRAN

 From the documentation:
This package contains a COM server used to connect a client application 
(e.g. Microsoft Excel) with R.
An Add-In for Microsoft Excel is provided as well as Active X controls 
to  be included in your applications.

Thomas Baier
Erich Neuwirth


From pocernic at rap.ucar.edu  Thu Apr 24 00:44:26 2003
From: pocernic at rap.ucar.edu (Matt Pocernich)
Date: Wed, 23 Apr 2003 16:44:26 -0600 (MDT)
Subject: [R] .libPaths
Message-ID: <Pine.LNX.4.44.0304231642340.27746-100000@markov.rap.ucar.edu>

What file would I modify to add an additional libPath on startup?  In
addition the the default directory, I would like to add a second path.

Thanks,


Matt Pocernich
NCAR - Research Applications Program
303-497-8312


From paulda at BATTELLE.ORG  Thu Apr 24 00:51:39 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Wed, 23 Apr 2003 18:51:39 -0400
Subject: [R] regression parms var-cov matrix
Message-ID: 
 <940250A9EB37A24CBE28D858EF077749136CE1@ws-bco-mse3.milky-way.battelle.org>

Win2k, R1.6.2.

I've been using Splus 6.1 and wanted to try the same 
regression analysis in R.  Using "names( blah.lm )" 
in R yields

 [1] "coefficients"  "residuals"     "effects"     "rank"          
 [5] "fitted.values" "assign"        "qr"          "df.residual"   
 [9] "xlevels"       "call"          "terms"       "model"

In Splus, the same command yields

 [1] "coefficients"  "residuals"     "fitted.values" "effects"      
 [5] "R"             "rank"          "assign"        "df.residual"  
 [9] "contrasts"     "terms"         "call"

and blah.lm$R gives the variance-covariance matrix of the 
model parameters.  How do get the variance-covariance matrix out 
of R?  Apologies for such a simple question.

Much thanks in advance,
   david paul


From jfox at mcmaster.ca  Thu Apr 24 01:31:57 2003
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 23 Apr 2003 19:31:57 -0400
Subject: [R] regression parms var-cov matrix
In-Reply-To: <940250A9EB37A24CBE28D858EF077749136CE1@ws-bco-mse3.milky-w
 ay.battelle.org>
Message-ID: <5.1.0.14.2.20030423192909.01e89210@mcmail.cis.mcmaster.ca>

Dear David,

vcov(blah.lm) will do the trick.

John

At 06:51 PM 4/23/2003 -0400, Paul, David  A wrote:
>Win2k, R1.6.2.
>
>I've been using Splus 6.1 and wanted to try the same
>regression analysis in R.  Using "names( blah.lm )"
>in R yields
>
>  [1] "coefficients"  "residuals"     "effects"     "rank"
>  [5] "fitted.values" "assign"        "qr"          "df.residual"
>  [9] "xlevels"       "call"          "terms"       "model"
>
>In Splus, the same command yields
>
>  [1] "coefficients"  "residuals"     "fitted.values" "effects"
>  [5] "R"             "rank"          "assign"        "df.residual"
>  [9] "contrasts"     "terms"         "call"
>
>and blah.lm$R gives the variance-covariance matrix of the
>model parameters.  How do get the variance-covariance matrix out
>of R?  Apologies for such a simple question.
>
>Much thanks in advance,
>    david paul
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox


From andy_liaw at merck.com  Thu Apr 24 01:58:15 2003
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 23 Apr 2003 19:58:15 -0400
Subject: [R] sum
Message-ID: <3A822319EB35174CA3714066D590DCD5C4FA4C@usrymx25.merck.com>

> From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
> 
> Barry Rowlingson <B.Rowlingson at lancaster.ac.uk> writes:
> 
> > Luis Silva wrote:
> > > Dear helpers
> > > I have a list where each element is a matrix (the list is obtained
> > > with lapply). I want to sum those matrices. Is there a function to
> > > do that? The sum function sums all the elements...
> 
> >   Here's a one-liner that converts your list into an array (by
> > unlisting it and then packing into an array with the right three
> > dimensions) and then runs apply(...,c(1,2),sum) to get the 
> answer you
> > want:
> 
> Didn't someone do an abind() function at some point? (Generalizing
> cbind/rbind) 

I believe there's an abind for Splus on StatLib, if I remember correctly by
Tony Plate & Rich Heiberger.  Do not believe it was made available for R,
though I believe it'd be very useful.

[snipped]
> However, aren't we ignoring the obvious?:
> 
> s<-0;(for(a in l)s<-s+a)

Indeed!  (I guess somehow the evil of for loops in the old S in deeply
engrained in some of us.)  Altough I like Sundar's version, too.

Cheers,
Andy


------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, cont... {{dropped}}


From rpeng at stat.ucla.edu  Thu Apr 24 02:10:38 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 23 Apr 2003 17:10:38 -0700 (PDT)
Subject: [R] .libPaths
In-Reply-To: <Pine.LNX.4.44.0304231642340.27746-100000@markov.rap.ucar.edu>
Message-ID: <Pine.GSO.4.10.10304231708020.13646-100000@quetelet.stat.ucla.edu>

In your home directory you can create a file called .Renviron and put in
the line:

R_LIBS=/path/to/my/library

Or you could insert the same line in the sitewide Renviron file.

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Wed, 23 Apr 2003, Matt Pocernich wrote:

> What file would I modify to add an additional libPath on startup?  In
> addition the the default directory, I would like to add a second path.
> 
> Thanks,
> 
> 
> Matt Pocernich
> NCAR - Research Applications Program
> 303-497-8312
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From rpeng at stat.ucla.edu  Thu Apr 24 02:20:06 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Wed, 23 Apr 2003 17:20:06 -0700 (PDT)
Subject: [R] sum
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4FA4C@usrymx25.merck.com>
Message-ID: <Pine.GSO.4.10.10304231716180.14837-100000@quetelet.stat.ucla.edu>

There's an abind() posted by Jonathan Rougier at
http://finzi.psych.upenn.edu/R/Rhelp02/archive/9580.html.  It doesn't look
like the same thing as the one on StatLib but it seems to work.

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Wed, 23 Apr 2003, Liaw, Andy wrote:

> > From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
> > 
> > Barry Rowlingson <B.Rowlingson at lancaster.ac.uk> writes:
> > 
> > > Luis Silva wrote:
> > > > Dear helpers
> > > > I have a list where each element is a matrix (the list is obtained
> > > > with lapply). I want to sum those matrices. Is there a function to
> > > > do that? The sum function sums all the elements...
> > 
> > >   Here's a one-liner that converts your list into an array (by
> > > unlisting it and then packing into an array with the right three
> > > dimensions) and then runs apply(...,c(1,2),sum) to get the 
> > answer you
> > > want:
> > 
> > Didn't someone do an abind() function at some point? (Generalizing
> > cbind/rbind) 
> 
> I believe there's an abind for Splus on StatLib, if I remember correctly by
> Tony Plate & Rich Heiberger.  Do not believe it was made available for R,
> though I believe it'd be very useful.
> 
> [snipped]
> > However, aren't we ignoring the obvious?:
> > 
> > s<-0;(for(a in l)s<-s+a)
> 
> Indeed!  (I guess somehow the evil of for loops in the old S in deeply
> engrained in some of us.)  Altough I like Sundar's version, too.
> 
> Cheers,
> Andy
> 
> 
> ------------------------------------------------------------------------------
> Notice: This e-mail message, together with any attachments, cont... {{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From whitep at fern.dsto.defence.gov.au  Thu Apr 24 02:30:24 2003
From: whitep at fern.dsto.defence.gov.au (Paul White)
Date: Thu, 24 Apr 2003 00:30:24 -0000
Subject: [R] advice on anlysing the spacing of growth rings
Message-ID: <20030404124041.A672@fern.dsto.defence.gov.au>

Hello,

I have an image of a fatigue crack that I want to analyse. It is simular 
to a photograph of the cross section of a (non-circular) tree showing the 
tree rings that indicate the growth of the tree. I would like to determine 
the spacing of the repeated growth patterns without actually picking off 
individual points (there are too many). Could someone give me an 
indication of how I could tackle this. It may be similar to a geographical 
mapping approach. Can anyone recommand any R packages that I should look 
at ?

Thanks
Paul

Paul White
Defence Science and Technology Organisation
Department of Defence
Melbourne, Australia


From tplate at blackmesacapital.com  Thu Apr 24 05:08:03 2003
From: tplate at blackmesacapital.com (Tony Plate)
Date: Wed, 23 Apr 2003 21:08:03 -0600
Subject: [R] sum
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4FA4C@usrymx25.merck.com>
Message-ID: <5.2.1.1.2.20030423205737.037a6ba8@mailhost.blackmesacapital.com>

I've been meaning to submit the abind package to CRAN for a long time 
now.  I just did it.
Here's how one could do the matrix-list-sum using abind():

 > library(abind)
 > set.seed(1)
 > m <- lapply(1:3,function(i) matrix(sample(10,8,rep=T),2,4))
 > m
[[1]]
      [,1] [,2] [,3] [,4]
[1,]    1    1    1    4
[2,]    6    7    1    7

[[2]]
      [,1] [,2] [,3] [,4]
[1,]    7   10    1    7
[2,]    7    6    3    2

[[3]]
      [,1] [,2] [,3] [,4]
[1,]   10    6    9    1
[2,]    3    4    2    2

 > a <- do.call("abind", c(m, list(along=3)))
 > apply(a, 1:2, sum)
      [,1] [,2] [,3] [,4]
[1,]   18   17   11   12
[2,]   16   17    6   11
 > m[[1]] + m[[2]] + m[[3]]
      [,1] [,2] [,3] [,4]
[1,]   18   17   11   12
[2,]   16   17    6   11
 > all(apply(a, 1:2, sum) == m[[1]] + m[[2]] + m[[3]])
[1] TRUE
 >

-- Tony Plate

At Wednesday 07:58 PM 4/23/2003 -0400, Liaw, Andy wrote:
> > From: Peter Dalgaard BSA [mailto:p.dalgaard at biostat.ku.dk]
> >
> > Barry Rowlingson <B.Rowlingson at lancaster.ac.uk> writes:
> >
> > > Luis Silva wrote:
> > > > Dear helpers
> > > > I have a list where each element is a matrix (the list is obtained
> > > > with lapply). I want to sum those matrices. Is there a function to
> > > > do that? The sum function sums all the elements...
> >
> > >   Here's a one-liner that converts your list into an array (by
> > > unlisting it and then packing into an array with the right three
> > > dimensions) and then runs apply(...,c(1,2),sum) to get the
> > answer you
> > > want:
> >
> > Didn't someone do an abind() function at some point? (Generalizing
> > cbind/rbind)
>
>I believe there's an abind for Splus on StatLib, if I remember correctly by
>Tony Plate & Rich Heiberger.  Do not believe it was made available for R,
>though I believe it'd be very useful.
>
>[snipped]
> > However, aren't we ignoring the obvious?:
> >
> > s<-0;(for(a in l)s<-s+a)
>
>Indeed!  (I guess somehow the evil of for loops in the old S in deeply
>engrained in some of us.)  Altough I like Sundar's version, too.
>
>Cheers,
>Andy
>
>
>------------------------------------------------------------------------------
>Notice: This e-mail message, together with any attachments, cont... 
>{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From s195404 at student.uq.edu.au  Thu Apr 24 05:17:57 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Thu, 24 Apr 2003 03:17:57 +0000
Subject: [R] Fast R implementation of Gini mean difference
Message-ID: <1051154277.3ea757654bbb4@my.uq.edu.au>

I have written the following function to calculate the weighted mean
difference for univariate data (see 
http://www.xycoon.com/gini_mean_difference.htm for a related 
formula). Unsurprisingly, the function is slow (compared to sd or mad)
for long vectors. I wonder if there's a way to make the function
faster, short of creating an external C function. Thanks very much
for your advice.


gmd <- function(x, w) { # x=data vector, w=weights vector
   n <- length(x)
   tmp <- 0
   for (i in 1:n) {
      for (j in 1:n) {
         tmp <- tmp + w[i]*abs(x[i]-x[j])
      }
   }
   retval <- 0.5*sqrt(pi)*tmp/((n-1)*sum(w))
}

gmd(rnorm(100))



Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au


From deepayan at stat.wisc.edu  Thu Apr 24 06:05:45 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 23 Apr 2003 23:05:45 -0500
Subject: [R] Fast R implementation of Gini mean difference
In-Reply-To: <1051154277.3ea757654bbb4@my.uq.edu.au>
References: <1051154277.3ea757654bbb4@my.uq.edu.au>
Message-ID: <200304232305.45215.deepayan@stat.wisc.edu>


You can avoid the for loops with outer, but that will use more memory.

gmd <- 
   function(x, w) 0.5 * sqrt(pi) * sum(w * abs(outer(x, x, "-"))) /
       ((length(x)-1)*sum(w))


On Wednesday 23 April 2003 10:17 pm, Andrew C. Ward wrote:
> I have written the following function to calculate the weighted mean
> difference for univariate data (see
> http://www.xycoon.com/gini_mean_difference.htm for a related
> formula). Unsurprisingly, the function is slow (compared to sd or mad)
> for long vectors. I wonder if there's a way to make the function
> faster, short of creating an external C function. Thanks very much
> for your advice.
>
>
> gmd <- function(x, w) { # x=data vector, w=weights vector
>    n <- length(x)
>    tmp <- 0
>    for (i in 1:n) {
>       for (j in 1:n) {
>          tmp <- tmp + w[i]*abs(x[i]-x[j])
>       }
>    }
>    retval <- 0.5*sqrt(pi)*tmp/((n-1)*sum(w))
> }
>
> gmd(rnorm(100))
>
>
>
> Regards,
>
> Andrew C. Ward
>
> CAPE Centre
> Department of Chemical Engineering
> The University of Queensland
> Brisbane Qld 4072 Australia
> andreww at cheque.uq.edu.au
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From s195404 at student.uq.edu.au  Thu Apr 24 06:23:51 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Thu, 24 Apr 2003 04:23:51 +0000
Subject: [R] Fast R implementation of Gini mean difference
In-Reply-To: <200304232305.45215.deepayan@stat.wisc.edu>
References: <1051154277.3ea757654bbb4@my.uq.edu.au>
	<200304232305.45215.deepayan@stat.wisc.edu>
Message-ID: <1051158231.3ea766d7ce7d7@my.uq.edu.au>

Thank you to Deepayan Sarkar and Berwin Turlach for reminding me of
the outer() function. A quick comparison shows outer() to be more than
10 times faster than the nested for() loop. The memory does blow out a
bit (ran out of memory with a vector of 10000 elements), but it would
be rare for me to calculate a mean difference for that many. Thanks 
again!


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au

Quoting Deepayan Sarkar <deepayan at stat.wisc.edu>:

> 
> You can avoid the for loops with outer, but that will use more
> memory.
> 
> gmd <- 
>    function(x, w) 0.5 * sqrt(pi) * sum(w * abs(outer(x, x, "-")))
> /
>        ((length(x)-1)*sum(w))
> 
> 
> On Wednesday 23 April 2003 10:17 pm, Andrew C. Ward wrote:
> > I have written the following function to calculate the weighted
> mean
> > difference for univariate data (see
> > http://www.xycoon.com/gini_mean_difference.htm for a related
> > formula). Unsurprisingly, the function is slow (compared to sd or
> mad)
> > for long vectors. I wonder if there's a way to make the function
> > faster, short of creating an external C function. Thanks very
> much
> > for your advice.
> >
> >
> > gmd <- function(x, w) { # x=data vector, w=weights vector
> >    n <- length(x)
> >    tmp <- 0
> >    for (i in 1:n) {
> >       for (j in 1:n) {
> >          tmp <- tmp + w[i]*abs(x[i]-x[j])
> >       }
> >    }
> >    retval <- 0.5*sqrt(pi)*tmp/((n-1)*sum(w))
> > }
> >
> > gmd(rnorm(100))
> >
> >
> >
> > Regards,
> >
> > Andrew C. Ward
> >
> > CAPE Centre
> > Department of Chemical Engineering
> > The University of Queensland
> > Brisbane Qld 4072 Australia
> > andreww at cheque.uq.edu.au
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From DJNordlund at aol.com  Thu Apr 24 08:53:11 2003
From: DJNordlund at aol.com (DJNordlund@aol.com)
Date: Thu, 24 Apr 2003 02:53:11 EDT
Subject: [R] Fast R implementation of Gini mean difference
Message-ID: <c6.1bd85f54.2bd8e3d7@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030424/aa2cbe94/attachment.pl

From andel at ifi.unizh.ch  Thu Apr 24 09:40:48 2003
From: andel at ifi.unizh.ch (David Andel)
Date: 24 Apr 2003 09:40:48 +0200
Subject: [R] "export" an object froma function for access by ls()
Message-ID: <20030424094048.1.10758.qmail@ifi.unizh.ch>

I struggle with this very simple problem:

ls()
(empty)

giveval <- function() {
	x <- foo
	eval (x, envir=parent.frame(1))
}

ls()
(still empty)

I did not find anything more promising than eval for this purpose, but how 
only can I make it to have ls() return x?

David


From nusbj at hotmail.com  Thu Apr 24 09:48:55 2003
From: nusbj at hotmail.com (Zhen Pang)
Date: Thu, 24 Apr 2003 15:48:55 +0800
Subject: [R] GAUSS dataset
Message-ID: <Sea2-F58dr9FJXTdoif000030ce@hotmail.com>




Dear all,

Could R open the GAUSS dataset under windows?

Or some other statistics software such as S+, SAS, SPSS or Minitab can do 
this work. Thanks.


_________________________________________________________________
Send a fun phone greeting to your friend!


From ripley at stats.ox.ac.uk  Thu Apr 24 10:04:22 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Apr 2003 09:04:22 +0100 (BST)
Subject: [R] regression parms var-cov matrix
In-Reply-To: <5.1.0.14.2.20030423192909.01e89210@mcmail.cis.mcmaster.ca>
Message-ID: <Pine.LNX.4.44.0304240901330.19234-100000@gannet.stats>

On Wed, 23 Apr 2003, John Fox wrote:

> vcov(blah.lm) will do the trick.

Well, it will do what David *said* blah.lm$R is, but in fact it is the
triangular decomposition of the model matrix which is part of the qr 
component in R.  So if David had been porting R code he would need to be
careful.

> At 06:51 PM 4/23/2003 -0400, Paul, David  A wrote:
> >Win2k, R1.6.2.
> >
> >I've been using Splus 6.1 and wanted to try the same
> >regression analysis in R.  Using "names( blah.lm )"
> >in R yields
> >
> >  [1] "coefficients"  "residuals"     "effects"     "rank"
> >  [5] "fitted.values" "assign"        "qr"          "df.residual"
> >  [9] "xlevels"       "call"          "terms"       "model"
> >
> >In Splus, the same command yields
> >
> >  [1] "coefficients"  "residuals"     "fitted.values" "effects"
> >  [5] "R"             "rank"          "assign"        "df.residual"
> >  [9] "contrasts"     "terms"         "call"
> >
> >and blah.lm$R gives the variance-covariance matrix of the
> >model parameters.  How do get the variance-covariance matrix out
> >of R?  Apologies for such a simple question.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Thu Apr 24 10:10:19 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 24 Apr 2003 10:10:19 +0200
Subject: r-announce (was RE: [R] about multtest...)
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4FA3E@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD5C4FA3E@usrymx25.merck.com>
Message-ID: <16039.39915.543940.879510@gargle.gargle.HOWL>

>>>>> "AndyL" == Liaw, Andy <andy_liaw at merck.com>
>>>>>     on Wed, 23 Apr 2003 13:07:33 -0400 writes:

    >> From: Thomas Lumley [mailto:tlumley at u.washington.edu]
    >> 
    >> Please don't send these messages to r-announce. r-announce is for
    >> announcements.

    AndyL> Isn't r-announce supposed to be moderated?  I posted
    AndyL> to r-announce about a minor update in randomForest
    AndyL> and was rejected.  I was told that it's meant for new
    AndyL> or significant upgrades in packages, etc.

Yes, indeed.
Of course, it *is* moderated -- BUT it's gatewayed to R-help
before moderation.  And that's where Sandrine's (two identical!)
messages went to (any yes, I manually needed to discard them from R-announce).

Regards,
Martin

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From maechler at stat.math.ethz.ch  Thu Apr 24 10:48:05 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 24 Apr 2003 10:48:05 +0200
Subject: [R] Setting up Xemacs + Sweave
In-Reply-To: <20030423174359.GA1573@localhost>
References: <20030423174359.GA1573@localhost>
Message-ID: <16039.42181.656608.521933@gargle.gargle.HOWL>

>>>>> "Tamas" == Tamas Papp <tpapp at axelero.hu>
>>>>>     on Wed, 23 Apr 2003 19:44:00 +0200 writes:


    Tamas> I have tried to setup my Xemacs for use with Sweave,
    Tamas> which I indend to learn.  I have followed the
    Tamas> instructions in the Sweave FAQ, that is to say, I put

	(defun Rnw-mode ()
	  (require 'ess-noweb)
	  (noweb-mode)
	  (if (fboundp 'R-mode)
	      (setq noweb-default-code-mode 'R-mode)))
	(add-to-list 'auto-mode-alist '("\\.Rnw\\'" . Rnw-mode))
	(add-to-list 'auto-mode-alist '("\\.Snw\\'" . Rnw-mode))

	(setq reftex-file-extensions
	      '(("Snw" "Rnw" "nw" "tex" ".tex" ".ltx") ("bib" ".bib")))
	(setq TeX-file-extensions
	      '("Snw" "Rnw" "nw" "tex" "sty" "cls" "ltx" "texi" "texinfo"))

    Tamas> in my init.el. However, if I open an Rnw file
    Tamas> (/usr/lib/R/library/tools/Sweave/Sweave-test-1.Rnw) it is not treated
    Tamas> as one, only if I evaluate (Rnw-mode) using M-: on the buffer. My
    Tamas> auto-mode-alist looks like this:

Tamas, have you loaded/enable ESS  at all in your  init.el file?
e.g., does
      M-x R
call R?
ess-noweb I think is supposed to be called in to a `loaded' ESS
environment.

(but then I'm only rarely using Xemacs, but rather GNU emacs and
I also don't know about the Debian package setup of these).

    Tamas> (("\\.Snw\\'" . Rnw-mode) ("\\.Rnw\\'" . Rnw-mode) ("\\.lout\\'"
    Tamas> . lout-mode) ("\\.tex\\'" . latex-mode) ("\\.tex$" . yatex-mode)
    Tamas> ... ) (I have left the end off)

    Tamas> so it should be working correctly. One strange thing: immediately
    Tamas> after I open the Rnw file, Xemacs gives the following warning:

    Tamas> (1) (local-variables/warning) File local-variables error: Symbol's
    Tamas> function definition is void: noweb-font-lock-mode

    Tamas> I don't know whether this is relevant. I am using debian/testing, the
    Tamas> package versions are:

    Tamas> ii  xemacs21                  21.4.6-8
    Tamas> ii  xemacs21-basesupport      2003.01.27-1.1
    Tamas> ii  xemacs21-bin              21.4.6-8
    Tamas> ii  xemacs21-gnome-nomule     21.4.6-8
    Tamas> ii  xemacs21-support          21.4.6-8
    Tamas> ii  ess                       5.1.24-3
    Tamas> ii  r-base                    1.7.0-0.cran.1
    Tamas> ii  r-base-core               1.6.0.rel-1
    Tamas> ii  r-recommended             1.4.1-1

    Tamas> Regards,

    Tamas> Tamas Papp

    Tamas> -- 
    Tamas> Tam?s K. Papp
    Tamas> E-mail: tpapp at axelero.hu (preferred, especially for large messages)
    Tamas> tpapp at westel900.net
    Tamas> Please try to send only (latin-2) plain text, not HTML or other garbage.

    Tamas> ______________________________________________
    Tamas> R-help at stat.math.ethz.ch mailing list
    Tamas> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Ted.Harding at nessie.mcc.ac.uk  Thu Apr 24 10:51:28 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 24 Apr 2003 09:51:28 +0100 (BST)
Subject: [R] "Missing links": Hmisc and Design docs
Message-ID: <XFMail.030424095128.Ted.Harding@nessie.mcc.ac.uk>

Hi folks,

Using R Version 1.6.2  (2003-01-10)
on    SuSE Linux 7.2,
I just installed Hmisc_1.5-3.tar.gz and Design_1.1-5.tar.gz
These were taken from
   http://hesweb1.med.virginia.edu/biostat/s/library/r

Checked the dependencies:

Hmisc: grid, lattice, mva, acepack -- all already installed

Design: Hmisc, survival -- survival already installed, so
        installed Hmisc first

All seems to go well till the "help" docs are compiled,
whereupon I get several reports of "missing links", as below
(where I omit cases with no such reports). I can't recall
seeing "missing links" when installing other libraries.

Two questions:
1. Have I overlooked something here, which I should have done?
2. Do these "missing links" matter?

Or is this simply a manifestation of Frank Harrell's comment, on the
above site, that "I still have not had time to fix details in the
documentation that will allow R CMD check to be passed, which would
allow me to submit the libraries to CRAN."

If that is the explanation, then I withdraw all the rest of this, with
sincere thanks to Frank for generating these packages and making them
available (and with experience-based sympathy for the task of getting
such details right!).

With thanks, and best wishes to all,
Ted.

Misc:
=====
  abs.error.pred                    text    html    latex   example
     missing link(s):  ols validate.ols
  aregImpute                        text    html    latex   example
     missing link(s):  mice
  bootkm                            text    html    latex   example
     missing link(s):  Survival.cph Quantile.cph
  data.frame.create.modify.check    text    html    latex   example
     missing link(s):  hist.data.frame merge.levels
  dataRep                           text    html    latex   example
     missing link(s):  crosstabs
  deff                              text    html    latex   example
     missing link(s):  bootcov robcov
  impute                            text    html    latex   example
     missing link(s):  na.include
  labcurve                          text    html    latex   example
     missing link(s):  key
  mtitle                            text    html    latex   example
     missing link(s):  pstamp
  panel.bpplot                      text    html    latex   example
     missing link(s):  trellis
  plsmo                             text    html    latex   example
     missing link(s):  trellis
  ps.slide                          text    html    latex   example
     missing link(s):  win.slide fig mgp.axis.labels pdf.graph
  rcspline.eval                     text    html    latex   example
     missing link(s):  Design.trans
  rcspline.plot                     text    html    latex   example
     missing link(s):  lrm cph lrm.fit
  rcspline.restate                  text    html    latex   example
     missing link(s):  Design.trans
  reShape                           text    html    latex   example
     missing link(s):  crosstabs
  rm.boot                           text    html    latex   example
     missing link(s):  lm.fit.qr Design bootcov rm.impute
  scat1d                            text    html    latex   example
     missing link(s):  plot.Design nomogram.Design hist.data.frame
                       datadensity.plot.Design
  spower                            text    html    latex   example
     missing link(s):  cph
  summary.formula                   text    html    latex   example
     missing link(s):  crosstabs trellis lattice
  sys                               text    html    latex
     missing link(s):  dos
  transace                          text    html    latex   example
     missing link(s):  ols validate predab.resample nomogram
  transcan                          text    html    latex   example
     missing link(s):  mice
  upData                            text    html    latex   example
     missing link(s):  importData exportData timeDate format.timeDate
  varclus                           text    html    latex   example
     missing link(s):  na.pattern
  xYplot                            text    html    latex   example
     missing link(s):  trellis error.bar axis.time
  sas.get                           text    html    latex   example
     missing link(s):  sas.contents sas.datasets timeDate format.timeDate

Design:
=======
  cph                               text    html    latex   example
     missing link(s):  validate.Design calibrate.Design
  gendata                           text    html    latex   example
     missing link(s):  data.ed ed using.X
  latex.Design                      text    html    latex   example
     missing link(s):  print.latex
  lrm                               text    html    latex   example
     missing link(s):  latex.lrm
  ols                               text    html    latex   example
     missing link(s):  validate.Design latex.ols
  pentrace                          text    html    latex   example
     missing link(s):  nlminb
  plot.Design                       text    html    latex   example
     missing link(s):  key matxv survest key mgp.axis.labels win.slide
     gs.slide
  pphsm                             text    html    latex   example
     missing link(s):  print.pphsm
  print.cph                         text    html    latex
     missing link(s):  print.cphfit print.coxreg
  print.cph.fit                     text    html    latex
     missing link(s):  print.coxreg
  psm                               text    html    latex   example
     missing link(s):  survest
  summary.Design                    text    html    latex   example
     missing link(s):  confbar
  survplot                          text    html    latex   example
     missing link(s):  survest key mgp.axis.labels win.slide gs.slide


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 24-Apr-03                                       Time: 09:51:28
------------------------------ XFMail ------------------------------


From maechler at stat.math.ethz.ch  Thu Apr 24 11:23:20 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 24 Apr 2003 11:23:20 +0200
Subject: [R] regression parms var-cov matrix
In-Reply-To: <940250A9EB37A24CBE28D858EF077749136CE1@ws-bco-mse3.milky-way.battelle.org>
References: <940250A9EB37A24CBE28D858EF077749136CE1@ws-bco-mse3.milky-way.battelle.org>
Message-ID: <16039.44296.813807.885472@gargle.gargle.HOWL>

>>>>> "DavidP" == Paul, David A <paulda at BATTELLE.ORG>
>>>>>     on Wed, 23 Apr 2003 18:51:39 -0400 writes:

    DavidP> Win2k, R1.6.2.
    DavidP> I've been using Splus 6.1 and wanted to try the same 
    DavidP> regression analysis in R.  Using "names( blah.lm )" 
    DavidP> in R yields

    DavidP> [1] "coefficients"  "residuals"     "effects"     "rank"          
    DavidP> [5] "fitted.values" "assign"        "qr"          "df.residual"   
    DavidP> [9] "xlevels"       "call"          "terms"       "model"

    DavidP> In Splus, the same command yields

    DavidP> [1] "coefficients"  "residuals"     "fitted.values" "effects"      
    DavidP> [5] "R"             "rank"          "assign"        "df.residual"  
    DavidP> [9] "contrasts"     "terms"         "call"

    DavidP> and blah.lm$R gives the variance-covariance matrix of the 
    DavidP> model parameters.  How do get the variance-covariance matrix out 
    DavidP> of R?  Apologies for such a simple question.

The most recommended way is to use the generic function  vcov()
which has methods for many classes, included "lm".

A bit more low level, but still reliable approach is to do what
vcov.lm does:
    vcov.lm <- function (object, ...) 
    {
	so <- summary.lm(object, corr = FALSE)
	so$sigma^2 * so$cov.unscaled
    }

A much more low level (non-recommended) way would be to look at
<your lm object> $ qr  etc and replicate what summary.lm() is doing
for its $sigma and $cov.unscaled computations.

    DavidP> Much thanks in advance,

you're welcome!
Martin Maechler ETH Zurich


From maechler at stat.math.ethz.ch  Thu Apr 24 11:36:53 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 24 Apr 2003 11:36:53 +0200
Subject: [R] "export" an object froma function for access by ls()
In-Reply-To: <20030424094048.1.10758.qmail@ifi.unizh.ch>
References: <20030424094048.1.10758.qmail@ifi.unizh.ch>
Message-ID: <16039.45109.690685.290835@gargle.gargle.HOWL>

>>>>> "DavidA" == David Andel <andel at ifi.unizh.ch>
>>>>>     on 24 Apr 2003 09:40:48 +0200 writes:

    DavidA> I struggle with this very simple problem:

    DavidA> ls()
    DavidA> (empty)

    DavidA> giveval <- function() {
    DavidA>   x <- foo
    DavidA>   eval (x, envir=parent.frame(1))
    DavidA> }

    DavidA> ls()
    DavidA> (still empty)
probably not.
At least "giveval" should be there..

    DavidA> I did not find anything more promising than eval for
    DavidA> this purpose, but how only can I make it to have
    DavidA> ls() return x?

Use  assign() instead of eval()    ==>  ?assign 

{interesting to hear that computer scientists "across the street"
 here in Zurich are going into using R !!}

Vill Gl?ck,
Martin

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From p.dalgaard at biostat.ku.dk  Thu Apr 24 11:43:51 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 24 Apr 2003 11:43:51 +0200
Subject: [R] "Missing links": Hmisc and Design docs
In-Reply-To: <XFMail.030424095128.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.030424095128.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <x2y9208c2w.fsf@biostat.ku.dk>

(Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:

> Hi folks,
> 
> Using R Version 1.6.2  (2003-01-10)
> on    SuSE Linux 7.2,
> I just installed Hmisc_1.5-3.tar.gz and Design_1.1-5.tar.gz
> These were taken from
>    http://hesweb1.med.virginia.edu/biostat/s/library/r
> 
> Checked the dependencies:
> 
> Hmisc: grid, lattice, mva, acepack -- all already installed
> 
> Design: Hmisc, survival -- survival already installed, so
>         installed Hmisc first
> 
> All seems to go well till the "help" docs are compiled,
> whereupon I get several reports of "missing links", as below
> (where I omit cases with no such reports). I can't recall
> seeing "missing links" when installing other libraries.
> 
> Two questions:
> 1. Have I overlooked something here, which I should have done?
> 2. Do these "missing links" matter?
> 
> Or is this simply a manifestation of Frank Harrell's comment, on the
> above site, that "I still have not had time to fix details in the
> documentation that will allow R CMD check to be passed, which would
> allow me to submit the libraries to CRAN."

In general, you get the missing links if there's a reference to
something that isn't there. Sometimes, it means that you need to
install some other package before this one (e.g. with the set of
recommended packages that ship with R we need to build survival before
boot), but in Frank's case, I think a fair proportion of them are due
to S-PLUS references that he hasn't quite ferreted out yet. Certainly,
trellis and nlminb are S-PLUS items that are not in R (it might
actually be an idea to have help pages that said "foo is an S-PLUS
function that is not in R, you probably want to use bar instead";
anyone want to contribute?)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From wl at eimb.ru  Thu Apr 24 11:49:31 2003
From: wl at eimb.ru (Wladimir Eremeev)
Date: Thu, 24 Apr 2003 13:49:31 +0400
Subject: [R] RMySQL
Message-ID: <17576.030424@eimb.ru>

Dear laurent,

> This is what I did to make the connection :
>  > drv <- dbDriver("MySQL")
>  > con <- dbConnect(drv)

Here's the error.
You should give the database name.
drv <-dbConnect(drv, dbname="dfghdfgsdfgsdfgsdfgsdfgsdfgsdf")
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> Then I should be able to send requests. But when I try this :
>  > dbListTables(con)
> character(0)

Of course.
Tables are stored in the database. You didn't provide its name.
Function dbListTables doesn't know which tables should it list.
  
-- 
Best regards
Wladimir Eremeev                                     mailto:wl at eimb.ru

==========================================================================
Research Scientist                                Leninsky Prospect 33,
Space Monitoring & Ecoinformation Systems Sector, Moscow, Russia, 119071,
Institute of Ecology,                             Phone: (095) 135-9972;
Russian Academy of Sciences                       Fax: (095) 954-5534


From laurent.faisnel at ariase.com  Thu Apr 24 11:51:27 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Thu, 24 Apr 2003 11:51:27 +0200
Subject: [R] Re: RMySQL
References: <17576.030424@eimb.ru>
Message-ID: <3EA7B39F.9090104@ariase.com>

Wladimir Eremeev wrote:

>Dear laurent,
>
>  
>
>>This is what I did to make the connection :
>> > drv <- dbDriver("MySQL")
>> > con <- dbConnect(drv)
>>    
>>
>
>Here's the error.
>You should give the database name.
>
It is indicated in the config file my.cnf , no problem. In fact the 
database I tried to work on had a little problem yesterday, all tables 
disappeared a few hours long. Hence it was difficult to get any result. 
Thank you anyway.
Parameters such as dbname, user, passwd, host, port can be given either 
in the config file my.cnf or at the time you define the connection in R 
(the solution you advised me).

>drv <-dbConnect(drv, dbname="dfghdfgsdfgsdfgsdfgsdfgsdfgsdf")
>                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>  
>
>>Then I should be able to send requests. But when I try this :
>> > dbListTables(con)
>>character(0)
>>    
>>
>
>Of course.
>Tables are stored in the database. You didn't provide its name.
>Function dbListTables doesn't know which tables should it list.
>  
>  
>


From use at eio.uva.es  Thu Apr 24 12:23:42 2003
From: use at eio.uva.es (=?Windows-1252?Q?Eusebio_Arenal_Guti=E9rrez?=)
Date: Thu, 24 Apr 2003 12:23:42 +0200
Subject: [R] rw1.7.0 spend much time to open
Message-ID: <000701c30a4b$9559c860$6958589d@juanito>

I've just installed R for windows 1.7.0 on windows 2000 SP2 from the
binaries on CRAN. It takes at least 1:30 minutes to completely open Rgui,
Rterm o R in Emacs. It this normal?

Data about the platform:

C:\>ver

Microsoft Windows 2000 [Versi?n 5.00.2195]

> Sys.info()
                      sysname                       release
                    "Windows"                      "NT 5.0"
                      version                      nodename
"(build 2195) Service Pack 2"                     "xxxxxxx"
                      machine                         login
                        "x86"                         "xxx"
                         user
                        "xxx"

Thanks in advance,

Eusebio Arenal


From vincent.stoliaroff at socgen.com  Thu Apr 24 12:27:50 2003
From: vincent.stoliaroff at socgen.com (vincent.stoliaroff@socgen.com)
Date: Thu, 24 Apr 2003 12:27:50 +0200
Subject: [R] Missing Value And cor() function
Message-ID: <OF23157B6F.FAB166E8-ONC1256D12.0038D0FD@ges.marc.societe-generale.fr>



Hi r lovers!

I 'd like to apply the cor() function to a matrix which have some missing values
As a matter of fact and quite logically indeed it doesn't work
Is there a trick to replace the missing value by the mean of each variable or by any other relevant figures ?
Or should I apply a special derivate of the cor() function, (I don't have any idea if it exists and have some trouble to figure out how it could)
to skip this trouble?
Thanks a lot for any suggestions and help

Vincent





*************************************************************************
Ce message et toutes les pieces jointes (ci-apres le "message") sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite. 
Tout message electronique est susceptible d'alteration. 
La SOCIETE GENERALE et ses filiales declinent toute responsabilite au 
titre de ce message s'il a ete altere, deforme ou falsifie.
				********
This message and any attachments (the "message") are confidentia... {{dropped}}


From fharrell at virginia.edu  Thu Apr 24 12:49:32 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu, 24 Apr 2003 06:49:32 -0400
Subject: [R] "Missing links": Hmisc and Design docs
In-Reply-To: <x2y9208c2w.fsf@biostat.ku.dk>
References: <XFMail.030424095128.Ted.Harding@nessie.mcc.ac.uk>
	<x2y9208c2w.fsf@biostat.ku.dk>
Message-ID: <20030424064932.4136b803.fharrell@virginia.edu>

On 24 Apr 2003 11:43:51 +0200
Peter Dalgaard BSA <p.dalgaard at biostat.ku.dk> wrote:

> (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk> writes:
> 
> > Hi folks,
> > 
> > Using R Version 1.6.2  (2003-01-10)
> > on    SuSE Linux 7.2,
> > I just installed Hmisc_1.5-3.tar.gz and Design_1.1-5.tar.gz
> > These were taken from
> >    http://hesweb1.med.virginia.edu/biostat/s/library/r
> > 
> > Checked the dependencies:
> > 
> > Hmisc: grid, lattice, mva, acepack -- all already installed
> > 
> > Design: Hmisc, survival -- survival already installed, so
> >         installed Hmisc first
> > 
> > All seems to go well till the "help" docs are compiled,
> > whereupon I get several reports of "missing links", as below
> > (where I omit cases with no such reports). I can't recall
> > seeing "missing links" when installing other libraries.
> > 
> > Two questions:
> > 1. Have I overlooked something here, which I should have done?
> > 2. Do these "missing links" matter?
> > 
> > Or is this simply a manifestation of Frank Harrell's comment, on the
> > above site, that "I still have not had time to fix details in the
> > documentation that will allow R CMD check to be passed, which would
> > allow me to submit the libraries to CRAN."
> 
> In general, you get the missing links if there's a reference to
> something that isn't there. Sometimes, it means that you need to
> install some other package before this one (e.g. with the set of
> recommended packages that ship with R we need to build survival before
> boot), but in Frank's case, I think a fair proportion of them are due
> to S-PLUS references that he hasn't quite ferreted out yet. Certainly,
> trellis and nlminb are S-PLUS items that are not in R (it might
> actually be an idea to have help pages that said "foo is an S-PLUS
> function that is not in R, you probably want to use bar instead";
> anyone want to contribute?)

Peter is correct.  I wish there were a way to give R a file containing a list of function names whose links are to be ignored.  Then when I convert the Rd file for S-Plus I could still have one base source file.  -Frank

---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From gisar at nus.edu.sg  Thu Apr 24 13:06:18 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Thu, 24 Apr 2003 19:06:18 +0800
Subject: [R] Invalid font in bitmap() 
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F248@MBXSRV03.stf.nus.edu.sg>

Dear all,

A few weeks ago I asked about X11() availability using CGI-perl. The
general advice was to use bitmap which requires ghostscript (Xvnc and
Xvbf were the other alternatives). My system administrator got around to
installing Aladin Ghostscript 6.0 and the setting the R_GSCMD
environment variable. Other system specification is given below.


But now I have a new problem that says that font is invalid and this is
not even through the CGI-perl web mode. As per the 'Family' section of
postscript I tried experimenting with the various options given but with
the same problem. Here is an example

###### Code #######
> x <- -10:10
> bitmap("bitmaptest.png", family="URWGothic")
> plot(x, x^2); title("A quadratic plot"); dev.off()
Error: /invalidfont in findfont
Operand stack:
   URWGothicL-Book   Font   URWGothicL-Book   236230   URWGothicL-Book
--nostringval--   NewCenturySchlbk-Roman   CenturySchL-Roma
Execution stack:
   %interp_exit   .runexec2   --nostringval--   --nostringval--
--nostringval--   2   %stopped_push   --nostringval--   --nostringval--
--nostringval--   false   1   %stopped_push   1   3   %oparray_pop
.runexec2   --nostringval--   --nostringval--   --nostringval--   2
%stopped_push   --nostringval--   1   3   %oparray_pop   2   3
%oparray_pop   --nostringval--   --nostringval--   --nostringval--
--nostringval--   --nostringval--   false   1   %stopped_push   5   4
%oparray_pop   --nostringval--   --nostringval--   --nostringval--   1
-1   1   --nostringval--   %for_neg_int_continue   --nostringval--
--nostringval--
Dictionary stack:
   --dict:951/983(ro)(G)--   --dict:0/20(G)--   --dict:90/200(L)--
--dict:16/24(G)--   --dict:951/983(ro)(G)--
Current allocation mode is local
Last OS error: 2
Current file position is 1438
Aladdin Ghostscript 6.0: Unrecoverable error, exit code 1
####################


Can anyone help please ?



R Version 1.6.1  (2002-11-01)
Aladdin Ghostscript 6.0
R_GSCMD : /usr/local/bin/gs
Platform: SunOS 
Release : 5.8 
Version : Generic_112953-02
Machine : sun4u

--
Adaikalavan Ramasamy			gisar at nus.edu.sg
Research Assistant
http://giscompute.gis.nus.edu.sg/~adai
Microarray & Expression Genomics	Tel: 65-6827 5247
Information & Mathematical Sciences	Fax: 65 6827 5204
Genome Institute of Singapore		www.genomeinstitute.org


From dmurdoch at pair.com  Thu Apr 24 12:56:05 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 24 Apr 2003 06:56:05 -0400
Subject: [R] changing dir to network drive in Rgui caused crash ( 1.7. 0)
In-Reply-To: <3A822319EB35174CA3714066D590DCD5C4FA35@usrymx25.merck.com>
References: <3A822319EB35174CA3714066D590DCD5C4FA35@usrymx25.merck.com>
Message-ID: <skgfavo794at20aikl1s2fhdkq5r3ndc5h@4ax.com>

On Wed, 23 Apr 2003 08:53:32 -0400, you wrote:

>Uwe & Marc,
>
>Adding the --vanilla flag doesn't help.  Actually, the crash happens if I
>browse to a folder on a mapped drive.  I.e., if I type in "q:\Andy" in the
>text box, it works, but if I try to browse to Q:\Andy and then click on OK,
>that's when it crashes.
>
>Andy

I still can't reproduce this one.  If anyone can get a reproducible
sequence, please let me know.

Duncan Murdoch


From fharrell at virginia.edu  Thu Apr 24 12:55:41 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Thu, 24 Apr 2003 06:55:41 -0400
Subject: [R] Missing Value And cor() function
In-Reply-To: <OF23157B6F.FAB166E8-ONC1256D12.0038D0FD@ges.marc.societe-generale.fr>
References: <OF23157B6F.FAB166E8-ONC1256D12.0038D0FD@ges.marc.societe-generale.fr>
Message-ID: <20030424065541.30569688.fharrell@virginia.edu>

On Thu, 24 Apr 2003 12:27:50 +0200
vincent.stoliaroff at socgen.com wrote:

> 
> 
> Hi r lovers!
> 
> I 'd like to apply the cor() function to a matrix which have some missing values
> As a matter of fact and quite logically indeed it doesn't work
> Is there a trick to replace the missing value by the mean of each variable or by any other relevant figures ?
> Or should I apply a special derivate of the cor() function, (I don't have any idea if it exists and have some trouble to figure out how it could)
> to skip this trouble?
> Thanks a lot for any suggestions and help
> 
> Vincent
> 
> 

Even though using pairwise deletion of NAs will result sometimes in a singular correlation matrix, it is better to do that than to replace NAs with constants, which will distort the correlations.

You may want to look at the rcorr function in the Hmisc package, which does pairwise deletion of NAs for Pearson and Spearman correlations.  See http://hesweb1.med.virginia.edu/biostat/s/Hmisc.html

> 
> 
> 
> *************************************************************************
> Ce message et toutes les pieces jointes (ci-apres le "message") sont
> confidentiels et etablis a l'intention exclusive de ses destinataires.
> Toute utilisation ou diffusion non autorisee est interdite. 
> Tout message electronique est susceptible d'alteration. 
> La SOCIETE GENERALE et ses filiales declinent toute responsabilite au 
> titre de ce message s'il a ete altere, deforme ou falsifie.
> 				********
> This message and any attachments (the "message") are confidentia... {{dropped}}

Please do not include such long disclaimers in your messages.

---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From V.Khamenia at BioVisioN.de  Thu Apr 24 13:14:33 2003
From: V.Khamenia at BioVisioN.de (Khamenia, Valery)
Date: Thu, 24 Apr 2003 13:14:33 +0200
Subject: [R] estimating number of clusters ("Null or more")
Message-ID: <D15343265276D31197BC00A024A6C110773FFF@EXS_BDC>

Hi all,

  once more about the old subj :-)

  My data has too much various distribution families and for every
particular experiment 
  I need just to decide whether the data is "quite homogeneous" or it has
two or more 
  clusters. I've revisited the following libraries: 
         amap, clust, cclust, mclust, multiv, normix, survey.

  And I didn't find any ready-to-use general purpose criterion for answering

  the question whether the data is "quite homogeneous" or has two or more 
  clusters. Even for one dimension data.

  However, in "cclust" a "clustIndex" might be used as a raw criteria.
  But nothing ready to use as far as I understand. Or maybe I am wrong?!

  Q: are there any libraries in R with ready-to-use functions for estimation

       number of clusters...
       - ... with criterion based on entropy?
       - ... with criterion based on ecdf?

Please Cc to:

   vkhamenia at biovision.de

kind thanks.
---------------------------------------------------------------------------
Valery A.Khamenya
Bioinformatics Department
BioVisioN AG, Hannover


From ripley at stats.ox.ac.uk  Thu Apr 24 13:23:09 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Apr 2003 12:23:09 +0100 (BST)
Subject: [R] rw1.7.0 spend much time to open
In-Reply-To: <000701c30a4b$9559c860$6958589d@juanito>
Message-ID: <Pine.LNX.4.44.0304241220410.5273-100000@gannet.stats>

No: a couple of seconds on a fast machine is normal.

See the top of the CHANGES file for things you can do to speed it up.

Most likely there is a problem with your system though: are
you loading from a networked drive?

On Thu, 24 Apr 2003, [Windows-1252] Eusebio Arenal Guti?rrez wrote:

> I've just installed R for windows 1.7.0 on windows 2000 SP2 from the
> binaries on CRAN. It takes at least 1:30 minutes to completely open Rgui,
> Rterm o R in Emacs. It this normal?
> 
> Data about the platform:
> 
> C:\>ver
> 
> Microsoft Windows 2000 [Versi?n 5.00.2195]
> 
> > Sys.info()
>                       sysname                       release
>                     "Windows"                      "NT 5.0"
>                       version                      nodename
> "(build 2195) Service Pack 2"                     "xxxxxxx"
>                       machine                         login
>                         "x86"                         "xxx"
>                          user
>                         "xxx"

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ozric at web.de  Thu Apr 24 13:23:32 2003
From: ozric at web.de (Christian Schulz)
Date: Thu, 24 Apr 2003 13:23:32 +0200
Subject: [R] Missing Value And cor() function
References: <OF23157B6F.FAB166E8-ONC1256D12.0038D0FD@ges.marc.societe-generale.fr>
Message-ID: <001301c30a53$f0a25680$0100a8c0@pc>

replace.na.m <- function (x){
    X<-mean(x,na.rm=TRUE)
    ifelse ( is.na(x)=="TRUE",X,x)
}

apply(data.frame,2,replace.na.m)

another way is using cor() and the option
 use: an optional character string giving a method for computing
          covariances in the presence of missing values.  This must be
          (an abbreviation of) one of the strings `"all.obs"',
          `"complete.obs"' or `"pairwise.complete.obs"'.

perhaps this helps you,
regards,christian


----- Original Message -----
From: <vincent.stoliaroff at socgen.com>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, April 24, 2003 12:27 PM
Subject: [R] Missing Value And cor() function


>
>
> Hi r lovers!
>
> I 'd like to apply the cor() function to a matrix which have some missing
values
> As a matter of fact and quite logically indeed it doesn't work
> Is there a trick to replace the missing value by the mean of each variable
or by any other relevant figures ?
> Or should I apply a special derivate of the cor() function, (I don't have
any idea if it exists and have some trouble to figure out how it could)
> to skip this trouble?
> Thanks a lot for any suggestions and help
>
> Vincent
>
>
>
>
>
> *************************************************************************
> Ce message et toutes les pieces jointes (ci-apres le "message") sont
> confidentiels et etablis a l'intention exclusive de ses destinataires.
> Toute utilisation ou diffusion non autorisee est interdite.
> Tout message electronique est susceptible d'alteration.
> La SOCIETE GENERALE et ses filiales declinent toute responsabilite au
> titre de ce message s'il a ete altere, deforme ou falsifie.
> ********
> This message and any attachments (the "message") are confidentia...
{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Thu Apr 24 13:28:01 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Apr 2003 12:28:01 +0100 (BST)
Subject: [R] Invalid font in bitmap() 
In-Reply-To: <024D6AEFCB92CB47BA1085751D184BB80105F248@MBXSRV03.stf.nus.edu.sg>
Message-ID: <Pine.LNX.4.44.0304241226100.5273-100000@gannet.stats>

It's a problem in your ghostscript installation. Your example works in
RH8.0, for example.

(BTW, it is nowadays AFPL ghostscript 8.x or GNU ghostscript 7.03 or
later.)

On Thu, 24 Apr 2003, Adaikalavan Ramasamy wrote:

> Dear all,
> 
> A few weeks ago I asked about X11() availability using CGI-perl. The
> general advice was to use bitmap which requires ghostscript (Xvnc and
> Xvbf were the other alternatives). My system administrator got around to
> installing Aladin Ghostscript 6.0 and the setting the R_GSCMD
> environment variable. Other system specification is given below.
> 
> 
> But now I have a new problem that says that font is invalid and this is
> not even through the CGI-perl web mode. As per the 'Family' section of
> postscript I tried experimenting with the various options given but with
> the same problem. Here is an example
> 
> ###### Code #######
> > x <- -10:10
> > bitmap("bitmaptest.png", family="URWGothic")
> > plot(x, x^2); title("A quadratic plot"); dev.off()
> Error: /invalidfont in findfont
> Operand stack:
>    URWGothicL-Book   Font   URWGothicL-Book   236230   URWGothicL-Book
> --nostringval--   NewCenturySchlbk-Roman   CenturySchL-Roma
> Execution stack:
>    %interp_exit   .runexec2   --nostringval--   --nostringval--
> --nostringval--   2   %stopped_push   --nostringval--   --nostringval--
> --nostringval--   false   1   %stopped_push   1   3   %oparray_pop
> .runexec2   --nostringval--   --nostringval--   --nostringval--   2
> %stopped_push   --nostringval--   1   3   %oparray_pop   2   3
> %oparray_pop   --nostringval--   --nostringval--   --nostringval--
> --nostringval--   --nostringval--   false   1   %stopped_push   5   4
> %oparray_pop   --nostringval--   --nostringval--   --nostringval--   1
> -1   1   --nostringval--   %for_neg_int_continue   --nostringval--
> --nostringval--
> Dictionary stack:
>    --dict:951/983(ro)(G)--   --dict:0/20(G)--   --dict:90/200(L)--
> --dict:16/24(G)--   --dict:951/983(ro)(G)--
> Current allocation mode is local
> Last OS error: 2
> Current file position is 1438
> Aladdin Ghostscript 6.0: Unrecoverable error, exit code 1
> ####################
> 
> 
> Can anyone help please ?
> 
> 
> 
> R Version 1.6.1  (2002-11-01)
> Aladdin Ghostscript 6.0
> R_GSCMD : /usr/local/bin/gs
> Platform: SunOS 
> Release : 5.8 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Thu Apr 24 13:32:12 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 24 Apr 2003 13:32:12 +0200
Subject: [R] "Missing links": Hmisc and Design docs
In-Reply-To: <20030424064932.4136b803.fharrell@virginia.edu>
References: <XFMail.030424095128.Ted.Harding@nessie.mcc.ac.uk>
	<x2y9208c2w.fsf@biostat.ku.dk>
	<20030424064932.4136b803.fharrell@virginia.edu>
Message-ID: <x2ptnc872b.fsf@biostat.ku.dk>

Frank E Harrell Jr <fharrell at virginia.edu> writes:

> Peter is correct. I wish there were a way to give R a file
> containing a list of function names whose links are to be ignored.
> Then when I convert the Rd file for S-Plus I could still have one
> base source file. -Frank

You might take a look at the way we handle Defunct routines in the R
help pages. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From rossini at blindglobe.net  Thu Apr 24 14:13:13 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Thu, 24 Apr 2003 05:13:13 -0700
Subject: [R] Setting up Xemacs + Sweave
In-Reply-To: <16039.42181.656608.521933@gargle.gargle.HOWL> (Martin
 Maechler's message of "Thu, 24 Apr 2003 10:48:05 +0200")
References: <20030423174359.GA1573@localhost>
	<16039.42181.656608.521933@gargle.gargle.HOWL>
Message-ID: <878yu0qejq.fsf@jeeves.blindglobe.net>

Martin Maechler <maechler at stat.math.ethz.ch> writes:


>>>>>> "Tamas" == Tamas Papp <tpapp at axelero.hu>
>>>>>>     on Wed, 23 Apr 2003 19:44:00 +0200 writes:
>
>
>     Tamas> I have tried to setup my Xemacs for use with Sweave,
>     Tamas> which I indend to learn.  I have followed the
>     Tamas> instructions in the Sweave FAQ, that is to say, I put
>
> 	(defun Rnw-mode ()
> 	  (require 'ess-noweb)
> 	  (noweb-mode)
> 	  (if (fboundp 'R-mode)
> 	      (setq noweb-default-code-mode 'R-mode)))
> 	(add-to-list 'auto-mode-alist '("\\.Rnw\\'" . Rnw-mode))
> 	(add-to-list 'auto-mode-alist '("\\.Snw\\'" . Rnw-mode))
>
> 	(setq reftex-file-extensions
> 	      '(("Snw" "Rnw" "nw" "tex" ".tex" ".ltx") ("bib" ".bib")))
> 	(setq TeX-file-extensions
> 	      '("Snw" "Rnw" "nw" "tex" "sty" "cls" "ltx" "texi" "texinfo"))
>
>     Tamas> in my init.el. However, if I open an Rnw file
>     Tamas> (/usr/lib/R/library/tools/Sweave/Sweave-test-1.Rnw) it is not treated
>     Tamas> as one, only if I evaluate (Rnw-mode) using M-: on the buffer. My
>     Tamas> auto-mode-alist looks like this:
>
> Tamas, have you loaded/enable ESS  at all in your  init.el file?
> e.g., does
>       M-x R
> call R?
> ess-noweb I think is supposed to be called in to a `loaded' ESS
> environment.
>
> (but then I'm only rarely using Xemacs, but rather GNU emacs and
> I also don't know about the Debian package setup of these).

They are pretty much the same, so your advice is correct, Martin.

best,
-tony

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center 
FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 
CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}


From hennig at stat.math.ethz.ch  Thu Apr 24 14:25:20 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Thu, 24 Apr 2003 14:25:20 +0200 (CEST)
Subject: [R] estimating number of clusters ("Null or more")
In-Reply-To: <D15343265276D31197BC00A024A6C110773FFF@EXS_BDC>
Message-ID: <Pine.LNX.4.44.0304241412370.1929-100000@florence>

Hi,

there are at least two methods to estimate the number of clusters in R:
In library(cluster), you can use the information coming with the 
silhouette plot. This is a bit difficult to figure out from the help pages
(it got better in the recent version, I think), and you can find it out
reading help pages of pam, pam.object and partition.object.

EMclust of library mclust decides about an optimal number of mixture
components using the BIC.

As far as I know, there is no direct answer to the problem of testing
homogeneity vs. clustering in R. There are lots of theoretical difficulties
and there is no "standard routine" to do this, neither in R, nor
elsewhere. I would suggest to invent a null model for your data modelled as
homogeneous and to estimate the distribution of a suitable clustering
statistics (such as the silhouette avg.width in pam, BIC, average
distance of the points to kth nearest neighbor or ratio between 25% largest
and smallest distances in the dataset) by Monte
Carlo/parametric bootstrap. Perhaps I say this too quickly; it's
non-trivial and at least you have to design the simulation so that
rejection/acceptance is not a consequence of different scaling of data and
null model. 

Hope that helps,
Christian

On Thu, 24 Apr 2003, Khamenia, Valery wrote:

> Hi all,
> 
>   once more about the old subj :-)
> 
>   My data has too much various distribution families and for every
> particular experiment 
>   I need just to decide whether the data is "quite homogeneous" or it has
> two or more 
>   clusters. I've revisited the following libraries: 
>          amap, clust, cclust, mclust, multiv, normix, survey.
> 
>   And I didn't find any ready-to-use general purpose criterion for answering
> 
>   the question whether the data is "quite homogeneous" or has two or more 
>   clusters. Even for one dimension data.
> 
>   However, in "cclust" a "clustIndex" might be used as a raw criteria.
>   But nothing ready to use as far as I understand. Or maybe I am wrong?!
> 
>   Q: are there any libraries in R with ready-to-use functions for estimation
> 
>        number of clusters...
>        - ... with criterion based on entropy?
>        - ... with criterion based on ecdf?
> 
> Please Cc to:
> 
>    vkhamenia at biovision.de
> 
> kind thanks.
> ---------------------------------------------------------------------------
> Valery A.Khamenya
> Bioinformatics Department
> BioVisioN AG, Hannover
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de


From krcabrer at perseus.unalmed.edu.co  Thu Apr 24 14:40:37 2003
From: krcabrer at perseus.unalmed.edu.co (Kenneth Cabrera)
Date: Thu, 24 Apr 2003 07:40:37 -0500
Subject: [R] How %% and %/% work on negative numbers?
Message-ID: <oprn4v5zz2faouaq@200.24.8.4>

Hi R developers and users:

How do "mod" and "integer division" work with negative integers on R?

I mean why you obtain different results if you work on C or anywhere else 
and in R?

I see R guarantees that `x  ==  (x %% y)  +  y * ( x %/% y )', but
it looks rare the individual (x %% y) and y * ( x %/% y ) results when
you use negative integers, because is contradictory to what is expected, 
e.g.
-17 mod 15 should be -2, but R shows 13 and
-17 integer division 15 should be -1, but R shows -2
because the reconstruction formula should be 15*(-1)+(-2) == -17
Or am I wrong?

Thank you for your help

Kenneth


From Alexander.Ploner at mep.ki.se  Thu Apr 24 14:34:53 2003
From: Alexander.Ploner at mep.ki.se (Alexander Ploner)
Date: Thu, 24 Apr 2003 14:34:53 +0200
Subject: [R] Windows: Graphics appear only partially
Message-ID: <JJEBKFOIJAKFKJKPEKIFOENJCAAA.Alexander.Ploner@mep.ki.se>

Dear all,

we have installed R in one of our computer labs. Running demo(grpahics)
works, kindof, in that it produces all the usual plots without crashing, but
the plots are incomplete: no color wheel, no pie chart, no boxplots, just
some labelling, titles, and in rare cases, axes. We have tried this with
both 1.7 and 1.6.2, with the same results. The computers are running Windows
2000, with somewhat elderly video cards (NVidia Vanta with 8 mb of video
RAM), the monitor is set to 1024x768 and "true colors" (32 bit).

Has anyone suggestions why this might be? What might be done?

Thanks!

alex

Alexander.Ploner at mep.ki.se
Phone: 46-8-524-82329
Fax  : 46-8-314975
Medical Epidemiology & Biostatistics
Karolinska Institutet,
P.O. Box 281, SE-171 77 Stockholm


From ripley at stats.ox.ac.uk  Thu Apr 24 14:59:29 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 24 Apr 2003 13:59:29 +0100 (GMT Daylight Time)
Subject: [R] Windows: Graphics appear only partially
In-Reply-To: <JJEBKFOIJAKFKJKPEKIFOENJCAAA.Alexander.Ploner@mep.ki.se>
Message-ID: <Pine.WNT.4.44.0304241356240.3136-100000@gannet.stats.ox.ac.uk>

On Thu, 24 Apr 2003, Alexander Ploner wrote:

> we have installed R in one of our computer labs. Running demo(grpahics)
> works, kindof, in that it produces all the usual plots without crashing, but
> the plots are incomplete: no color wheel, no pie chart, no boxplots, just
> some labelling, titles, and in rare cases, axes. We have tried this with
> both 1.7 and 1.6.2, with the same results. The computers are running Windows
> 2000, with somewhat elderly video cards (NVidia Vanta with 8 mb of video
> RAM), the monitor is set to 1024x768 and "true colors" (32 bit).
>
> Has anyone suggestions why this might be? What might be done?

I've no real idea: I used to run R happily on a W2k laptop with only 2.5Mb
of video memory (1024x768, 24bit).  Looks like a graphics driver problem to
me: can you try 24bit or failing that 16bit?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From B.Rowlingson at lancaster.ac.uk  Thu Apr 24 15:03:09 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 24 Apr 2003 14:03:09 +0100
Subject: [R] How %% and %/% work on negative numbers?
In-Reply-To: <oprn4v5zz2faouaq@200.24.8.4>
References: <oprn4v5zz2faouaq@200.24.8.4>
Message-ID: <3EA7E08D.2080407@lancaster.ac.uk>

Kenneth Cabrera wrote:

> I mean why you obtain different results if you work on C or anywhere 
> else and in R?

  Because R is not C, and they are doing different things.

> -17 mod 15 should be -2, but R shows 13 and
> -17 integer division 15 should be -1, but R shows -2
> because the reconstruction formula should be 15*(-1)+(-2) == -17
> Or am I wrong?

  R is doing "arithmetic modulo N" (which can only take values from 0 to 
N-1) and C is doing 'remainder when divided by N' which can be negative.

  These are two different (but related) things. R's %% operator is 
documented as "x mod y" - which means it does modulo-y arithmetic. The 
man page for 'fmod' in C says: "The  fmod()  function  computes  the 
remainder of dividing x by y". I dont have my K+R C book handy to see 
how they define the x % y operator, but I suspect its the same.

Baz


From ripley at stats.ox.ac.uk  Thu Apr 24 15:07:51 2003
From: ripley at stats.ox.ac.uk (Prof Brian D Ripley)
Date: Thu, 24 Apr 2003 14:07:51 +0100 (GMT Daylight Time)
Subject: [R] good source for explaining input and output parameters of
 R functions
In-Reply-To: <Pine.SOL.4.33.0304161629070.29530-100000@panther.cs.ucla.edu>
Message-ID: <Pine.WNT.4.44.0304241403120.3136-100000@gannet.stats.ox.ac.uk>

1) surf.ls is not part of R: it is in package spatial.

2) Its help page does explain *4* fields in the value, and says

       `and others for internal use only.'

That means what it says: they are not for use by you, and hence not
documented.

I think you have unrealistic expectations: my uncredited software was
written to support a book (see its DESCRIPTION file), and the *book* does
explain how it works. All you need to do is to buy the book ... or read the
sources, as R is Open Source and that package is GPL-ed.


On Wed, 16 Apr 2003, Yan Yu wrote:

> Hello,
>    thank you all for answering my previous Qs.. I have a new Q:
>    I am wondering is there good source for explaning input and output
> parameters of R function?
>   In that aspect, I found the help documents in R is not that helpful:)
> I am struggling with trying to understand what some of the returned value
> means..
> for example, for surf.ls() function, the help in R only describes 3
> fields(the wierd thing is that those explained 3 fields are identical to
> the input) of returned value, and leave a bunch of others(e.g., like "f"
> and "wz"which looks pretty interesting, but i had no clue what they are
> about..) unexplained.
>
> Is there any good source if I want to understand the input and output of ,
> or how to use a particular R function?
>
> Many thanks,
> yan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From V.Khamenia at BioVisioN.de  Thu Apr 24 15:11:34 2003
From: V.Khamenia at BioVisioN.de (Khamenia, Valery)
Date: Thu, 24 Apr 2003 15:11:34 +0200
Subject: AW: [R] estimating number of clusters ("Null or more")
Message-ID: <D15343265276D31197BC00A024A6C110774000@EXS_BDC>

Dear Christian,

  first of all thank you for your answer. I am going to parse through 
  the pages you told me. Meanwhile I'd like to note that probably it 
  is a good idea to put 2-3 lines of R-code demonstrating such a 
  simple needs somnewhere in docs of `cluster' package. E.g.

  x<-rnorm(500)
  ... # output means we have rather 1 claster

  x<-c(rnorm(500), rnorm(500)+5)
  ... # output means we have rather 2 or more claster

  It would be nice not only for me.

> EMclust of library mclust decides about an optimal number of mixture
> components using the BIC.

It is not clear for me whether one could use BIC without a
statement about the familiy of distribution. Indeed BIC is based 
on likelihood, and what the likelihood should be if the only 
adequate statement about the destribution is the ECDF itself?..
 
> As far as I know, there is no direct answer to the problem of testing
> homogeneity vs. clustering in R. There are lots of 
> theoretical difficultiesand there is no "standard routine" to 
> do this, neither in R, nor elsewhere.

I am not looking for the Holy Grail, or I hope so :-)

In particular, I beleive some entropy-based criteria should 
fully satisfy me here. BIC might be also good if it might be 
applied to a ECDF.

> I would suggest to invent a null model for your  
> data modelled as
> homogeneous and to estimate the distribution of a 
> suitable clustering
> statistics (such as the silhouette avg.width in pam, 
> BIC, average
> distance of the points to kth nearest neighbor or ratio 
> between 25% largest
> and smallest distances in the dataset) by Monte
> Carlo/parametric bootstrap. Perhaps I say this too quickly; 

a bit compressed, but something is clear anyway :-)

> it's non-trivial and at least you have to design the 
> simulation so that rejection/acceptance is not a 
> consequence of different scaling of data and null model. 

not clear here :-)

thanks again
Valery A.Khamenya


From paulda at BATTELLE.ORG  Thu Apr 24 15:15:30 2003
From: paulda at BATTELLE.ORG (Paul, David  A)
Date: Thu, 24 Apr 2003 09:15:30 -0400
Subject: [R] regression parms var-cov matrix
Message-ID: 
 <940250A9EB37A24CBE28D858EF077749136CE3@ws-bco-mse3.milky-way.battelle.org>

I would like to thank Drs. Ripley, Maechler, Murphy, and
Fox for their helpful advice to use vcov( ) to extract
the variance-covariance matrix of the estimated regression
parameters --

Sincerely,
  david paul


From ayalahec at msu.edu  Thu Apr 24 15:23:26 2003
From: ayalahec at msu.edu (Hector L. Ayala-del-Rio)
Date: Thu, 24 Apr 2003 09:23:26 -0400
Subject: [R] write.table problem
Message-ID: <EE89D47A-7657-11D7-9CC9-000393DB5846@msu.edu>

Dear R helpers,
   I have been using the loadings function from the multiv library and I 
get the typical output (see below).  When I try to export these results 
to a file using a write.table() I get the following error message 
"Error in as.data.frame.default(x[[i]], optional = TRUE) : can't coerce 
loadings into a data.frame"  Any idea why write.table is doing that and 
any possible solutions??

thanks

hector

 > loadings(M2.princomp.corr)

Loadings:
         Comp.1 Comp.2 Comp.3 Comp.4 Comp.5 Comp.6 Comp.7 Comp.8 Comp.9 
Comp.10
f61      0.158               -0.138        -0.341
f63                                         0.234 -0.359
f67      0.178               -0.113        -0.329
f75      0.187               -0.199                0.143  0.135         
0.160
f78     -0.166 -0.193               -0.168                0.154
f81     -0.123 -0.102        -0.125 -0.284                0.297
f115     0.161                0.203 -0.199        -0.103               
-0.225
f117     0.166                0.198 -0.198                             
-0.241
f123     0.184                      -0.111 -0.157  0.209               
-0.231
f125     0.224               -0.169
f135     0.159                0.205 -0.200        -0.103               
-0.226
f138                   0.248         0.210                0.151  0.123 
-0.282
f161    -0.152 -0.242 -0.114
f163           -0.212 -0.183  0.133  0.196
f176                   0.248         0.210                0.151  0.123 
-0.282
f180                   0.162  0.191  0.225                0.206 -0.104  
0.324
f182            0.229 -0.229                                    -0.178
f185     0.226                0.125 -0.109
f190            0.227 -0.233                                    -0.201 
-0.103
f193    -0.158         0.214                             -0.327 -0.106
f196    -0.158         0.212                             -0.332 -0.108
f199    -0.156         0.212                             -0.335 -0.109
f203    -0.202 -0.168                0.113
f210.2          0.175 -0.175                      -0.107         0.415
f216                         -0.214  0.125  0.227  0.223               
-0.145
f225    -0.181  0.234
f227    -0.198  0.214
f230                                       -0.391               -0.126

  Comp.1 Comp.2 Comp.3 Comp.4 Comp.5 Comp.6 Comp.7 Comp.8 Comp.9
SS loadings     1.000  1.000  1.000  1.000  1.000  1.000  1.000  1.000  
1.000
Proportion Var  0.018  0.018  0.018  0.018  0.018  0.018  0.018  0.018  
0.018
Cumulative Var  0.018  0.036  0.054  0.071  0.089  0.107  0.125  0.143  
0.161
                Comp.10 Comp.11 Comp.12 Comp.13 Comp.14 Comp.15 Comp.16 
Comp.17
SS loadings      1.000   1.000   1.000   1.000   1.000   1.000   1.000  
  1.000
Proportion Var   0.018   0.018   0.018   0.018   0.018   0.018   0.018  
  0.018
Cumulative Var   0.179   0.196   0.214   0.232   0.250   0.268   0.286  
  0.304
                Comp.18 Comp.19 Comp.20 Comp.21 Comp.22 Comp.23 Comp.24 
Comp.25
SS loadings      1.000   1.000   1.000   1.000   1.000   1.000   1.000  
  1.000
Proportion Var   0.018   0.018   0.018   0.018   0.018   0.018   0.018  
  0.018
Cumulative Var   0.321   0.339   0.357   0.375   0.393   0.411   0.429  
  0.446
                Comp.26 Comp.27 Comp.28 Comp.29 Comp.30 Comp.31 Comp.32 
Comp.33
SS loadings      1.000   1.000   1.000   1.000   1.000   1.000   1.000  
  1.000
Proportion Var   0.018   0.018   0.018   0.018   0.018   0.018   0.018  
  0.018
Cumulative Var   0.464   0.482   0.500   0.518   0.536   0.554   0.571  
  0.589
                Comp.34 Comp.35 Comp.36 Comp.37 Comp.38 Comp.39 Comp.40 
Comp.41
SS loadings      1.000   1.000   1.000   1.000   1.000   1.000   1.000  
  1.000
Proportion Var   0.018   0.018   0.018   0.018   0.018   0.018   0.018  
  0.018
Cumulative Var   0.607   0.625   0.643   0.661   0.679   0.696   0.714  
  0.732
                Comp.42 Comp.43 Comp.44 Comp.45 Comp.46 Comp.47 Comp.48 
Comp.49
SS loadings      1.000   1.000   1.000   1.000   1.000   1.000   1.000  
  1.000
Proportion Var   0.018   0.018   0.018   0.018   0.018   0.018   0.018  
  0.018
Cumulative Var   0.750   0.768   0.786   0.804   0.821   0.839   0.857  
  0.875

 > write.table(loadings(M2.princomp.corr))
Error in as.data.frame.default(x[[i]], optional = TRUE) :
         can't coerce loadings into a data.frame


From lamac_k at hotmail.com  Thu Apr 24 15:25:23 2003
From: lamac_k at hotmail.com (lamack lamack)
Date: Thu, 24 Apr 2003 13:25:23 +0000
Subject: [R] bootstraping sensitivity and specificity
Message-ID: <BAY7-F13Ksp3MSi6xzm00002d4b@hotmail.com>

  Dear all, I have a standard method and two alternatives to perform a test, 
called method A and method B.

I have calculated the sensitivity and specificity for
standard method vs. method A and standard method vs. method B.
Hence, I have two sensitivity values an two specificity values.

To be clear, sensitivity and specificity was calculated from:

		     Disease(A) No Disease(Ac) Total
Positive Screen(T)        a 		b 	a+b
Negative Screen(Tc) 	  c 		d 	c+d
Total			 a+c 	       b+d    a+b+c+d

where  	sensitivity:   P(T | A)=a/(a+c) and
specificity: P(Tc | Ac)=d/(b+d).

My questions:

How can I compare this quantities? That is, how method have high sensitivity 
or specificity?
Could I get the empirical distributions for sensitivity and specificity from 
Bootstrap?

If yes, Could I sampling from the set of "all" contingency tables
with given marginals, and works only if the marginals are positive?
It is the technique used by chisq.test when simulate.p.value is TRUE.

Best Regards.

LB.


From hennig at stat.math.ethz.ch  Thu Apr 24 15:30:41 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Thu, 24 Apr 2003 15:30:41 +0200 (CEST)
Subject: AW: [R] estimating number of clusters ("Null or more")
In-Reply-To: <D15343265276D31197BC00A024A6C110774000@EXS_BDC>
Message-ID: <Pine.LNX.4.44.0304241515210.1929-100000@florence>

Dear Valery,

On Thu, 24 Apr 2003, Khamenia, Valery wrote:

>  Meanwhile I'd like to note that probably it 
>   is a good idea to put 2-3 lines of R-code demonstrating such a 
>   simple needs somnewhere in docs of `cluster' package. E.g.
> 
>   x<-rnorm(500)
>   ... # output means we have rather 1 claster
> 
>   x<-c(rnorm(500), rnorm(500)+5)
>   ... # output means we have rather 2 or more claster
> 
>   It would be nice not only for me.

I agree totally.

> > EMclust of library mclust decides about an optimal number of mixture
> > components using the BIC.
> 
> It is not clear for me whether one could use BIC without a
> statement about the familiy of distribution. Indeed BIC is based 
> on likelihood, and what the likelihood should be if the only 
> adequate statement about the destribution is the ECDF itself?..

The problem is that you have to formalize what a cluster is, and this is
not a well defined notion. It has different meanings in different
applications. My interpretation of the normal mixture/BIC approach is that
it should work well if *your* concept of a cluster is that it looks
normal-shaped (and the clusters do not need to be separated too strongly).
Normal mixtures (sometimes with lots of components) are reasonable
approximations to a wide class of distributions, so the validity of the
approach is rather a question of your cluster concept than of the
distribution of the data. (However, if your concept of "homogeneity" does
not look normal, BIC may often decide for more than one component for
*in your sense* homogeneous data.)

Some material about my own point of view is given in "What clusters are
generated by Normal mixtures?" on
http://www.math.uni-hamburg.de/home/hennig/ -> Papers/publications
with associated R-software (fixed point clusters) on the same website. 

> > it's non-trivial and at least you have to design the 
> > simulation so that rejection/acceptance is not a 
> > consequence of different scaling of data and null model. 
> 
> not clear here :-)

This means: Do not use N(0,1) as null distribution for homogeneous data if your
data has variance 5 and the test statistics is not scale equivariant (as
k-nearest neighbors and others). A bit more general you have to think about
which features of your data should enter into your homogeneous null model
(which makes the procedure a parametric bootstrap with non-guaranteed
validity of p-values). 

Best,
Christian

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de


From azzalini at stat.unipd.it  Thu Apr 24 15:41:42 2003
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Thu, 24 Apr 2003 15:41:42 +0200
Subject: [R] Fast R implementation of Gini mean difference
In-Reply-To: <1051154277.3ea757654bbb4@my.uq.edu.au>
References: <1051154277.3ea757654bbb4@my.uq.edu.au>
Message-ID: <20030424134143.66C927CA824@tango.stat.unipd.it>

On Thursday 24 April 2003 05:17, you wrote:
> I have written the following function to calculate the weighted mean
> difference for univariate data (see
> http://www.xycoon.com/gini_mean_difference.htm?for a related
> formula). Unsurprisingly, the function is slow (compared to sd or mad)
> for long vectors. I wonder if there's a way to make the function
> faster, short of creating an external C function. Thanks very much
> for your advice.
>
>
> gmd <- function(x, w) { # x=data vector, w=weights vector
> ? ?n <- length(x)
> ? ?tmp <- 0
> ? ?for (i in 1:n) {
> ? ? ? for (j in 1:n) {
> ? ? ? ? ?tmp <- tmp + w[i]*abs(x[i]-x[j])
> ? ? ? }
> ? ?}
> ? ?retval <- 0.5*sqrt(pi)*tmp/((n-1)*sum(w))
> }

I have a few remarks on the "definition" of Gini index, and one on the most 
suitable way to compute it.

(a) there no 0.5*sqrt(pi) neither in the standard definition of the index, nor
   in the quoted source, at http://www.xycoon.com/gini_mean_difference.htm
(b) when the values of x vector have frequencies, then the common
   definition knwon to me is not the above one, but one such that the nested line 
   above should be replaced by
? ? ? ? ?tmp <- tmp + w[i]*w[j]*abs(x[i]-x[j])
   and the final assignment should be
          0.5*sqrt(pi)*tmp/((sum(w)-1)*sum(w))
  In fact, the above function produces inconsident results; see this:
>  gmd(c(1,2,2,4),c(1,1,1,1))
[1] 1.329
> gmd(c(1,2,4), c(1,2,1))
[1] 1.662

while the above modifications lead again to 
 > gmd(c(1,2,4), c(1,2,1))
[1] 1.329


(c) from the computational viewpoint, there is a much more convenient equivalent 
   expression, based on the order statistics, leading to the following function:

gini.md<- function(x)
  { # x=data vector
    j <-order(x)
    n <-length(x)
    return(4*sum((1:length(x))*x[j])/(n*(n-1))
          -2*mean(x)*(n+1)/(n-1))
  }

This is intendend for the basic case of unreplicated data. With some algebraic work 
one should be able to obtain a similar expression for the general case ...once an
agreement has been achieved on the definition of the index.

Clearly, to convert the output from gini.md() to gmd..() one must multiply by
0.5*sqrt(pi).

Here is a short comparison of timing, following the one prepared by Dan Nordlund.

> x<-rnorm(5000)
>  n<-rpois(5000,5)
> w<-n/sum(n)

>  system.time(gmd(x, w))
[1] 241.44   0.21 250.20   0.00   0.00
>  system.time(gmd.1(x, w))
[1]   5.01   8.69 129.95   0.00   0.00
>  system.time(gmd.2(x, w))
[1]  1.21  1.55 10.19  0.00  0.00
> system.time(gini.md(x))
[1] 0 0 0 0 0

also, the new function is  requires little memory

regards

Adelchi Azzalini

-- 
Adelchi Azzalini  <azzalini at stat.unipd.it>
Dipart.Scienze Statistiche, Universit? di Padova, Italia
http://azzalini.stat.unipd.it/


From phgrosjean at sciviews.org  Thu Apr 24 15:50:01 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Thu, 24 Apr 2003 15:50:01 +0200
Subject: [R] Windows: Graphics appear only partially
In-Reply-To: <Pine.WNT.4.44.0304241356240.3136-100000@gannet.stats.ox.ac.uk>
Message-ID: <MABBLJDICACNFOLGIHJOKEFNDGAA.phgrosjean@sciviews.org>

On Thu, 24 Apr 2003, Alexander Ploner wrote:

> we have installed R in one of our computer labs. Running demo(grpahics)
> works, kindof, in that it produces all the usual plots without crashing,
but
> the plots are incomplete: no color wheel, no pie chart, no boxplots, just
> some labelling, titles, and in rare cases, axes. We have tried this with
> both 1.7 and 1.6.2, with the same results. The computers are running
Windows
> 2000, with somewhat elderly video cards (NVidia Vanta with 8 mb of video
> RAM), the monitor is set to 1024x768 and "true colors" (32 bit).
>
> Has anyone suggestions why this might be? What might be done?

Brian Ripley wrote:
>I've no real idea: I used to run R happily on a W2k laptop with only 2.5Mb
>of video memory (1024x768, 24bit).  Looks like a graphics driver problem to
>me: can you try 24bit or failing that 16bit?

... or even safest: try to switch to the standard VGA driver if your graphic
cards allows it (supporting maximum resolution of 800x600). This way, you
will know if it is the graphic driver that causes the trouble. Then, if
answer is yes, three possibilities:
1) Look at NVidia web site if they propose a more recent driver that perhaps
corrects these bugs,
2) Go to control panel -> display -> settings -> advanced -> troubleshoot,
and move the slider to the left (hardware acceleration: none). If it works,
try sliding a little bit to the right and recheck R graphs, etc... until you
find the best compromise between hardware accelaration level and correct
graph display in R,
3) Change the graphic card as a last solution if everything fails :-(

Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oceanologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.18, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................



--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From Alexander.Ploner at mep.ki.se  Thu Apr 24 15:48:20 2003
From: Alexander.Ploner at mep.ki.se (Alexander Ploner)
Date: Thu, 24 Apr 2003 15:48:20 +0200
Subject: [R] Windows: Graphics appear only partially
In-Reply-To: <Pine.WNT.4.44.0304241356240.3136-100000@gannet.stats.ox.ac.uk>
Message-ID: <JJEBKFOIJAKFKJKPEKIFKENMCAAA.Alexander.Ploner@mep.ki.se>

> On Thu, 24 Apr 2003, Alexander Ploner wrote:
>
> > we have installed R in one of our computer labs. Running demo(grpahics)
> > works, kindof, in that it produces all the usual plots without
> crashing, but
> > the plots are incomplete: no color wheel, no pie chart, no
> boxplots, just
> > some labelling, titles, and in rare cases, axes. We have tried this with
> > both 1.7 and 1.6.2, with the same results. The computers are
> running Windows
> > 2000, with somewhat elderly video cards (NVidia Vanta with 8 mb of video
> > RAM), the monitor is set to 1024x768 and "true colors" (32 bit).
> >
> > Has anyone suggestions why this might be? What might be done?
>
> I've no real idea: I used to run R happily on a W2k laptop with only 2.5Mb
> of video memory (1024x768, 24bit).  Looks like a graphics driver
> problem to
> me: can you try 24bit or failing that 16bit?

We tried everything down to 8bit and 800x600 resolution, with the same
results.

alex

Alexander.Ploner at mep.ki.se
Phone: 46-8-524-82329
Fax  : 46-8-314975
Medical Epidemiology & Biostatistics
Karolinska Institutet,
P.O. Box 281, SE-171 77 Stockholm


From ripley at stats.ox.ac.uk  Thu Apr 24 16:19:18 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Apr 2003 15:19:18 +0100 (BST)
Subject: [R] write.table problem
In-Reply-To: <EE89D47A-7657-11D7-9CC9-000393DB5846@msu.edu>
Message-ID: <Pine.LNX.4.44.0304241514350.1108-100000@gannet.stats>

On Thu, 24 Apr 2003, Hector L. Ayala-del-Rio wrote:

> Dear R helpers,
>    I have been using the loadings function from the multiv library and I 

Looks like loadings() from the *mva* package to me, or more precisely
the result of the print method for loadings.

> get the typical output (see below).  When I try to export these results 
> to a file using a write.table() I get the following error message 
> "Error in as.data.frame.default(x[[i]], optional = TRUE) : can't coerce 
> loadings into a data.frame"  Any idea why write.table is doing that and 
> any possible solutions??

?write.table says

     `write.table' prints its required argument `x' (after converting
     it to a data frame if it is not one already) to `file'.

There is no in-built way to convert a `loadings' object to a data frame,
but as it is a matrix (see ?princomp), unclass(loadings(foo)) will work.


>  > write.table(loadings(M2.princomp.corr))
                 ^unclass(                 ^)

Note that you do get just the loadings, not the full output from
print.loadings.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wettenhall at wehi.edu.au  Thu Apr 24 16:23:46 2003
From: wettenhall at wehi.edu.au (James Wettenhall)
Date: Fri, 25 Apr 2003 00:23:46 +1000 (EST)
Subject: [R] R TclTk Examples
Message-ID: <Pine.LNX.4.44.0304250014310.24465-100000@unix24.alpha.wehi.edu.au>

Hi,

I've been learning how to use R TclTk in Windows over the last 
few months.  

I have recently put together a collection of examples of 
some common widgets and their corresponding R code, at

http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/

I would be interested in any feedback - Is it useful? Does it 
contain any significant errors or bad coding style?  Does anyone 
else want to contribute similar examples with screenshots?

Regards,
James

--------------------------------------------------------------------------
James Wettenhall                                  Tel: (+61 3) 9345 2629
Division of Genetics and Bioinformatics           Fax: (+61 3) 9347 0852
The Walter & Eliza Hall Institute         E-mail: wettenhall at wehi.edu.au
 of Medical Research,                     Mobile: (+61 / 0 ) 438 527 921    
1G Royal Parade,
Parkville, Vic 3050, Australia
http://www.wehi.edu.au


From V.Khamenia at BioVisioN.de  Thu Apr 24 16:30:14 2003
From: V.Khamenia at BioVisioN.de (Khamenia, Valery)
Date: Thu, 24 Apr 2003 16:30:14 +0200
Subject: AW: AW: [R] estimating number of clusters ("Null or more")
Message-ID: <D15343265276D31197BC00A024A6C110774002@EXS_BDC>

> >   It would be nice not only for me.
> 
> I agree totally.

If you belong to R-contributors group then thanks a lot 
in advance!
 
> The problem is that you have to formalize what a cluster is, 
> and this is not a well defined notion. 
> It has different meanings in different applications. 

you are right if one follows the idea of full formalization of 
the notion it should rather lead to a fail. Should one really 
take this extreme way then?

Let's take a small analogy with statistical tests.
Statistical tests never answer "yes" or "no". 
One should interpret/treat p-values instead on his/her own.
Thus, say, nice formed statistics just help us to focus on 
particular properties of a given distribution.

Now back to our case. Why not to build some statistics (in 
cclust package they are named as `indices') to help
focusing our attention on properties of the distribution 
given?

> My interpretation of the normal mixture/BIC 
> approach is that it should work well if *your* concept of 
> a cluster is that it looks normal-shaped 
> (and the clusters do not need to be separated 
> too strongly).

fine. I'd like to emphasize here that as long as possible 
one should rather deny taking any decision about how 
much clusters we have. Like with those p-values.

> Normal mixtures (sometimes with lots of components) are reasonable
> approximations to a wide class of distributions, so the 
> validity of the approach is rather a question of your 
> cluster concept than of the distribution of the data.

I do agree that multimodal normal mixture is a very powerful 
approximation basis for a wider class of distributions.

But in context of data homogeneity criterion it is rather 
a weak basis. Indeed, simple lognormal distribution will 
be adequately approximated with more then one mode only.
That pushes us automatically to a false conclusion that 
lognormal distribution is not homogeneous one.

I estimate the very idea of using entropy as quite adequate 
idea for describing homogeneity of the set, and therefore, good
enough to be a basis for taking decision about having cluster 
or having no cluster.

> Some material about my own point of view is given in "What 
> clusters are generated by Normal mixtures?" on
> http://www.math.uni-hamburg.de/home/hennig/ -> Papers/publications
> with associated R-software (fixed point clusters) on the same 
> website. 

I am reading.

> This means: Do not use N(0,1) as null distribution for 
> homogeneous data if your
> ...

a bit more clear now. thank you.


Well, could I ask what is your own opinion about some 
statistics (or so called cluster indices) which could 
focus on properties of data with respect to being 
homogeneously spread or being attracted to some 
clusters?

In particular do you believe that entropy-based statistics 
should be adequate according to *your* own comprehension of 
what the clusters are?

And there is still an open question for me whether one could 
calculate BIC based on ECDF.

kind regards,
Valery A.Khamenya


From phgrosjean at sciviews.org  Thu Apr 24 16:41:26 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Thu, 24 Apr 2003 16:41:26 +0200
Subject: [R] RMySQL crash under R 1.7.0, but not 1.6.2
Message-ID: <MABBLJDICACNFOLGIHJOAEFPDGAA.phgrosjean@sciviews.org>

Hi,

I was able to connect to a MySQL database (called "zooscan" and with a table
"serie" under Win XP with R 1.6.2 using:

> library(DBI)
> library(RMySQL)
Warning message:
DLL attempted to change FPU control word from 8001f to 9001f
> drv <- dbDriver("MySQL")
> con <- dbConnect(drv, dbname="zooscan")
> dbExistsTable(con, "serie")
[1] TRUE
> dbDisconnect(con)
[1] TRUE

Notice the warning message, but apparently without other incidence.

Now, when I try this with R 1.7.0, R crashes at the line:
> con <- dbConnect(drv, dbname="zooscan")

with the error report containing:
AppName: rgui.exe  AppVer: 1.70.30416.0   ModName: msvcrt.dll
ModVer: 7.0.2600.0  Offser: 00033730

indicating that the error occurs in a call to msvcrt.dll, which is the
following:
msvcrt.dll
Image Base: 0x77c10000   Image Size: 0x00053000
CheckSum: 0x00055a85     Time Stamp: 0x3b7dfe0e
Version Information
 Signature:       feef04bd
 StrucVer:        000100000
 FileVer:         (7.0:2600.0)
 ProdVer:         (6.1:8638.0)
 FlagMask:        0000003f
 Flags:           00000000
 OS:              00040004
 FileType:        00000001
 SubType:         00000000
 FileDate:        00000000:00000000

I have also:
> version
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    7.0
year     2003
month    04
day      16
language R

and:
C:\Program Files\\mysql\bin>mysqladmin --user=root version
mysqladmin  Ver 8.23 Distrib 3.23.49, for Win95/Win98 on i32
Copyright (C) 2000 MySQL AB & MySQL Finland AB & TCX DataKonsult AB
This software comes with ABSOLUTELY NO WARRANTY. This is free software,
and you are welcome to modify and redistribute it under the GPL license

Server version          3.23.49-max-nt
Protocol version        10
Connection              . via named pipe
UNIX socket             MySQL
Uptime:                 2 hours 7 min 30 sec

Threads: 1  Questions: 18  Slow queries: 0  Opens: 6  Flush tables: 1  Open
tabl
es: 0 Queries per second avg: 0.002




Notice also that I've got the same crash in R 1.7.0 under Windows 98 using:
> ....
> con <- dbConnect(drv, dbname="zooscan", port=3306)

I tested this on various machines with either Win XP or Win 98, and it
consistently succeed in R 1.6.2 and crashes in R 1.7.0. So, it seems that
some changes made in R itself is involved. By the way, do I have to
recompile RMySQL for R 1.7.0 (I used the compiled version on CRAN at
/windows/contrib/1.7).
Best,

Philippe Grosjean

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.18, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................


From ozric at web.de  Thu Apr 24 16:56:44 2003
From: ozric at web.de (Christian Schulz)
Date: Thu, 24 Apr 2003 16:56:44 +0200
Subject: [R] R TclTk Examples
References: <Pine.LNX.4.44.0304250014310.24465-100000@unix24.alpha.wehi.edu.au>
Message-ID: <007101c30a71$b8fb8760$0100a8c0@pc>

many thanks for this contribution, perhaps
i add in near future some snippets with your starting points!

..here is one simple, but nice for anybody works often with spss-data.
regards,christian


getfile <- function()  {
    name <- tclvalue(tkgetOpenFile(filetypes="{{SPSS Files} {.sav}} {{All
files} *}"))
    if (name=="") return;
    zz <- read.spss(name,use.value.label=T,to.data.frame=T)
    assign("myData",zz,envir=.GlobalEnv)
}
tt <- tktoplevel()
button.widget <- tkbutton(tt,text="Select SPSS File",command=getfile)
tkpack(button.widget)



> Hi,
>
> I've been learning how to use R TclTk in Windows over the last
> few months.
>
> I have recently put together a collection of examples of
> some common widgets and their corresponding R code, at
>
> http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/
>
> I would be interested in any feedback - Is it useful? Does it
> contain any significant errors or bad coding style?  Does anyone
> else want to contribute similar examples with screenshots?
>
> Regards,
> James
>
> --------------------------------------------------------------------------
> James Wettenhall                                  Tel: (+61 3) 9345 2629
> Division of Genetics and Bioinformatics           Fax: (+61 3) 9347 0852
> The Walter & Eliza Hall Institute         E-mail: wettenhall at wehi.edu.au
>  of Medical Research,                     Mobile: (+61 / 0 ) 438 527 921
> 1G Royal Parade,
> Parkville, Vic 3050, Australia
> http://www.wehi.edu.au
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ayalahec at msu.edu  Thu Apr 24 17:00:18 2003
From: ayalahec at msu.edu (Hector L. Ayala-del-Rio)
Date: Thu, 24 Apr 2003 11:00:18 -0400
Subject: [R] write.table problem
In-Reply-To: <Pine.LNX.4.44.0304241514350.1108-100000@gannet.stats>
Message-ID: <769BA6F1-7665-11D7-9CC9-000393DB5846@msu.edu>

THANKS!!!!  That is what I needed.

Hector

On Thursday, April 24, 2003, at 10:19  AM, Prof Brian Ripley wrote:

> On Thu, 24 Apr 2003, Hector L. Ayala-del-Rio wrote:
>
>> Dear R helpers,
>>    I have been using the loadings function from the multiv library 
>> and I
>
> Looks like loadings() from the *mva* package to me, or more precisely
> the result of the print method for loadings.
>
>> get the typical output (see below).  When I try to export these 
>> results
>> to a file using a write.table() I get the following error message
>> "Error in as.data.frame.default(x[[i]], optional = TRUE) : can't 
>> coerce
>> loadings into a data.frame"  Any idea why write.table is doing that 
>> and
>> any possible solutions??
>
> ?write.table says
>
>      `write.table' prints its required argument `x' (after converting
>      it to a data frame if it is not one already) to `file'.
>
> There is no in-built way to convert a `loadings' object to a data 
> frame,
> but as it is a matrix (see ?princomp), unclass(loadings(foo)) will 
> work.
>
>
>>> write.table(loadings(M2.princomp.corr))
>                  ^unclass(                 ^)
>
> Note that you do get just the loadings, not the full output from
> print.loadings.
>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>


H?ctor L. Ayala-del-R?o, Ph.D.
Center for Microbial Ecology &
Center for Genomic and Evolutionary Studies
on Microbial Life at Low Temperatures
Michigan State University
545 Plant & Soil Sciences Building
East Lansing, MI 48824-1325
Phone: 517-353-9021
Fax: 517-353-2917


From robertl at sm.luth.se  Thu Apr 24 17:02:24 2003
From: robertl at sm.luth.se (Robert Lundqvist)
Date: Thu, 24 Apr 2003 17:02:24 +0200 (MEST)
Subject: [R] Unable to create directory?
Message-ID: <Pine.GSO.4.53.0304241654480.19924@delta5.sm.luth.se>

I have tried to install the pls.pcr package, but as a install newbie, I
wasn't too successful. I tried the command
"install.package("pls.pcr",lib="~/lib/R/",CRAN="http://mirrors.sunsite.dk/cran").
The download seemed to run smoothly, but in the end I got the response
"ERROR: cannot write to or create directory '~/lib/R'"

Before I try to get my sysadmins to work on this, is it a non-R
problem (i e something wrong with directory premissions) or is it
some R detail I've missed? Hints anyone?

(I run R in a Unix environment: a SunRay/Solaris combination.)

--robert


From otoomet at econ.dk  Thu Apr 24 16:36:52 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Thu, 24 Apr 2003 16:36:52 +0200
Subject: [R] problem compiling R 1.7.0/RH 7.2
Message-ID: <200304241436.h3OEaq602175@punik.econ.au.dk>

Dear all,

I have tried to compile R for RH 7.2 on i686 but there is an error
with package methods.  I loaded R 1.7.0.tgz today from the Danish
mirror.  It looks like the function character() is undefined...

Can anyone help?

Ott



I did:

configure --prefix=$HOME
make

.... everything seems to work nice until .....

make[5]: Leaving directory `/home/otoomet/a/R-1.7.0/src/library/methods/src'
make[4]: Leaving directory `/home/otoomet/a/R-1.7.0/src/library/methods/src'
make[4]: Entering directory `/home/otoomet/a/R-1.7.0/src/library/methods'
dumping R code in package 'methods'
Error in eval(expr, envir, enclos) : couldn't find function "character"
Execution halted
make[4]: *** [../../../library/methods/R/all.rda] Error 1
make[4]: Leaving directory `/home/otoomet/a/R-1.7.0/src/library/methods'
make[3]: *** [all] Error 2
make[3]: Leaving directory `/home/otoomet/a/R-1.7.0/src/library/methods'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/home/otoomet/a/R-1.7.0/src/library'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/otoomet/a/R-1.7.0/src'
make: *** [R] Error 1


From p.dalgaard at biostat.ku.dk  Thu Apr 24 17:30:33 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 24 Apr 2003 17:30:33 +0200
Subject: [R] R TclTk Examples
In-Reply-To: <Pine.LNX.4.44.0304250014310.24465-100000@unix24.alpha.wehi.edu.au>
References: <Pine.LNX.4.44.0304250014310.24465-100000@unix24.alpha.wehi.edu.au>
Message-ID: <x2d6jb9ali.fsf@biostat.ku.dk>

James Wettenhall <wettenhall at wehi.edu.au> writes:

> Hi,
> 
> I've been learning how to use R TclTk in Windows over the last 
> few months.  
> 
> I have recently put together a collection of examples of 
> some common widgets and their corresponding R code, at
> 
> http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/
> 
> I would be interested in any feedback - Is it useful? Does it 
> contain any significant errors or bad coding style?  Does anyone 
> else want to contribute similar examples with screenshots?

Just a few notes:

* The tkscript example seems to have lost all indentation, and I think
  that the info relating to 1.6.0 can be safely lost by now.

* Tktable can be handled more easily using callbacks in R-1.7.x. I
  have an example somewhere on the laptop, I think. Interfacing to Tcl
  arrays is quite a pain as I'm sure you already found out; something
  I hope to straighten out in the future.

* You're describing the pack manager as superseded by the grid
  manager, which I think is not quite right. Both are useful in
  different contexts; some layouts are really awkward to lay out
  on a grid, so knowing the pack manager can pay off.

Re. examples and screenshots, you might be better off just taking
examples and doing your own screenshots. Things get more consistent
that way. A few examples of how things look like in the Linux
interface might be useful, though (maybe Aqua too, anyone?)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From tlumley at u.washington.edu  Thu Apr 24 17:30:07 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 24 Apr 2003 08:30:07 -0700 (PDT)
Subject: [R] Fast R implementation of Gini mean difference
In-Reply-To: <1051158231.3ea766d7ce7d7@my.uq.edu.au>
Message-ID: <Pine.A41.4.44.0304240827590.27484-100000@homer36.u.washington.edu>

On Thu, 24 Apr 2003, Andrew C. Ward wrote:

> Thank you to Deepayan Sarkar and Berwin Turlach for reminding me of
> the outer() function. A quick comparison shows outer() to be more than
> 10 times faster than the nested for() loop. The memory does blow out a
> bit (ran out of memory with a vector of 10000 elements), but it would
> be rare for me to calculate a mean difference for that many. Thanks
> again!
>

For larger vectors you could probably divide it up into blocks of a few
thousand and use outer inside a loop.

For really large vectors it would probably help to tabulate the data and
work with the unique values.

	-thomas


From anderson at unt.edu  Thu Apr 24 17:30:48 2003
From: anderson at unt.edu (Richard Anderson)
Date: Thu, 24 Apr 2003 10:30:48 -0500
Subject: [R] Changing the size of the bounding box
In-Reply-To: <20030423211133.GA24645@sushi.infosec.unt.edu>
References: <20030423211133.GA24645@sushi.infosec.unt.edu>
Message-ID: <20030424153048.GA26920@sushi.infosec.unt.edu>

On Wed, Apr 23, 2003 at 04:11:33PM -0500, Richard Anderson wrote:
> Greetings all:
> 
> I have to create a graph that has very specific dimensions for
> publication purposes.  The graph is a semilog scaled graph and the
> axes must range from 1 to 1,000,000 on the y axis and 0 to 100 on the
> x axis.  The x axis should be exactly 8 inches and the y axis should
> be exactly 5.25 inches.  I've been able to set the plot area to 8 x
> 5.25 using the par(pin=c(8,5.25)).  The problem that I'm running into
> is that R seems to extend my data range by 4% to create a "bounding
> box" and this throws off the layout of my graph.  Is there some way
> to change this behavior?  Thanks in advance for any help.
> 

Thanks everyone.  The combination of xaxs, yaxs, pin, xlim, and ylim
did the trick for me.

-- 
Richard L. Anderson, MS
Security Analyst, University of North Texas
UNT Computing Center
<mailto:anderson at unt.edu>


From tlumley at u.washington.edu  Thu Apr 24 17:34:59 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 24 Apr 2003 08:34:59 -0700 (PDT)
Subject: [R] Missing Value And cor() function
In-Reply-To: <OF23157B6F.FAB166E8-ONC1256D12.0038D0FD@ges.marc.societe-generale.fr>
Message-ID: <Pine.A41.4.44.0304240833550.27484-100000@homer36.u.washington.edu>

On Thu, 24 Apr 2003 vincent.stoliaroff at socgen.com wrote:

>
>
> Hi r lovers!
>
> I 'd like to apply the cor() function to a matrix which have some
> missing values As a matter of fact and quite logically indeed it doesn't
> work Is there a trick to replace the missing value by the mean of each
> variable or by any other relevant figures ? Or should I apply a special
> derivate of the cor() function, (I don't have any idea if it exists and
> have some trouble to figure out how it could) to skip this trouble?

The cor() function has two options for handling missing values, which are
described on its help page.

	-thomas


From ripley at stats.ox.ac.uk  Thu Apr 24 18:04:21 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Apr 2003 17:04:21 +0100 (BST)
Subject: [R] RMySQL crash under R 1.7.0, but not 1.6.2
In-Reply-To: <MABBLJDICACNFOLGIHJOAEFPDGAA.phgrosjean@sciviews.org>
Message-ID: <Pine.LNX.4.44.0304241656130.1373-100000@gannet.stats>

Did you read the ReadMe in the download area, or the rw-FAQ?  Please do
so, and don't send bug reports on contributed packages you have not
compiled yourself.

Let me give you a hint: the rw1062 version is comnpiled for MySQL 3.x 
and the rw1070 version for MySQL 4.0: AS IT SAYS in the INSTALL.win file.
The client DLLs do not interwork, so there is no way both could work on 
the same machine.

Now, do you understand how annoying you have been?


On Thu, 24 Apr 2003, Philippe Grosjean wrote:

> Hi,
> 
> I was able to connect to a MySQL database (called "zooscan" and with a table
> "serie" under Win XP with R 1.6.2 using:
> 
> > library(DBI)
> > library(RMySQL)
> Warning message:
> DLL attempted to change FPU control word from 8001f to 9001f
> > drv <- dbDriver("MySQL")
> > con <- dbConnect(drv, dbname="zooscan")
> > dbExistsTable(con, "serie")
> [1] TRUE
> > dbDisconnect(con)
> [1] TRUE
> 
> Notice the warning message, but apparently without other incidence.
> 
> Now, when I try this with R 1.7.0, R crashes at the line:
> > con <- dbConnect(drv, dbname="zooscan")
> 
> with the error report containing:
> AppName: rgui.exe  AppVer: 1.70.30416.0   ModName: msvcrt.dll
> ModVer: 7.0.2600.0  Offser: 00033730
> 
> indicating that the error occurs in a call to msvcrt.dll, which is the
> following:
> msvcrt.dll
> Image Base: 0x77c10000   Image Size: 0x00053000
> CheckSum: 0x00055a85     Time Stamp: 0x3b7dfe0e
> Version Information
>  Signature:       feef04bd
>  StrucVer:        000100000
>  FileVer:         (7.0:2600.0)
>  ProdVer:         (6.1:8638.0)
>  FlagMask:        0000003f
>  Flags:           00000000
>  OS:              00040004
>  FileType:        00000001
>  SubType:         00000000
>  FileDate:        00000000:00000000
> 
> I have also:
> > version
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    1
> minor    7.0
> year     2003
> month    04
> day      16
> language R
> 
> and:
> C:\Program Files\\mysql\bin>mysqladmin --user=root version
> mysqladmin  Ver 8.23 Distrib 3.23.49, for Win95/Win98 on i32
> Copyright (C) 2000 MySQL AB & MySQL Finland AB & TCX DataKonsult AB
> This software comes with ABSOLUTELY NO WARRANTY. This is free software,
> and you are welcome to modify and redistribute it under the GPL license
> 
> Server version          3.23.49-max-nt
> Protocol version        10
> Connection              . via named pipe
> UNIX socket             MySQL
> Uptime:                 2 hours 7 min 30 sec
> 
> Threads: 1  Questions: 18  Slow queries: 0  Opens: 6  Flush tables: 1  Open
> tabl
> es: 0 Queries per second avg: 0.002
> 
> 
> 
> 
> Notice also that I've got the same crash in R 1.7.0 under Windows 98 using:
> > ....
> > con <- dbConnect(drv, dbname="zooscan", port=3306)
> 
> I tested this on various machines with either Win XP or Win 98, and it
> consistently succeed in R 1.6.2 and crashes in R 1.7.0. So, it seems that
> some changes made in R itself is involved. By the way, do I have to
> recompile RMySQL for R 1.7.0 (I used the compiled version on CRAN at
> /windows/contrib/1.7).
> Best,
> 
> Philippe Grosjean
> 
> ...........]<(({?<...............<?}))><...............................
>  ) ) ) ) )
> ( ( ( ( (       Dr. Philippe Grosjean
>  ) ) ) ) )
> ( ( ( ( (       LOV, UMR 7093
>  ) ) ) ) )      Station Zoologique
> ( ( ( ( (       Observatoire Oc?anologique
>  ) ) ) ) )      BP 28
> ( ( ( ( (       06234 Villefranche sur mer cedex
>  ) ) ) ) )      France
> ( ( ( ( (
>  ) ) ) ) )      tel: +33.4.93.76.38.18, fax: +33.4.93.76.38.34
> ( ( ( ( (
>  ) ) ) ) )      e-mail: phgrosjean at sciviews.org
> ( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
>  ) ) ) ) )
> .......................................................................
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From g.heberto at lycos.com  Thu Apr 24 18:07:22 2003
From: g.heberto at lycos.com (heberto ghezzo)
Date: Thu, 24 Apr 2003 12:07:22 -0400
Subject: [R] problems with max.col()
Message-ID: <PKAHOFDKPLJALEAA@mailcity.com>

Hello, I think the following qualify as a bug
given:
x<-c(1,2,3,4,2,4,2,2,4,2,2,2,4,3,2,1)
z<-embed(x,4)
z
      [,1] [,2] [,3] [,4]
 [1,]    4    3    2    1
 [2,]    2    4    3    2
 [3,]    4    2    4    3
 [4,]    2    4    2    4
 [5,]    2    2    4    2
 [6,]    4    2    2    4
 [7,]    2    4    2    2
 [8,]    2    2    4    2
 [9,]    2    2    2    4
[10,]    4    2    2    2
[11,]    3    4    2    2
[12,]    2    3    4    2
[13,]    1    2    3    4
>
max.col(z)
 [1] 1 2 3 4 3 1 2 3 4 1 2 3 4
Why?     ^ ^
>        1 2
or should be
 [1] 1 2 3 4 3 4 2 3 4 1 2 3 4
i.e. the first column with the max, or the last column
same if
z <- embed(x,5)
 max.col(z)
 [1] 2 1 2 5 1 5 3 4 1 2 3 4
where it should be either of:
 2 1 2 3 1 2 3 4 1 2 3 4
 2 3 4 5 4 5 3 4 5 2 3 4
or I am missing something?
?max.col does not return anything
R 1.7.0 on Win98
.
Heberto.Ghezzo at McGill.ca


From ripley at stats.ox.ac.uk  Thu Apr 24 18:10:49 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Apr 2003 17:10:49 +0100 (BST)
Subject: [R] Multinomial logistic regression under R and Stata
In-Reply-To: <3EA41543.6000700@sociology.oxford.ac.uk>
Message-ID: <Pine.LNX.4.44.0304241709311.1373-100000@gannet.stats>

On Mon, 21 Apr 2003, Tak Wing Chan wrote:

> the Hessian when the scale of a variable is very small. I talked to a 
> colleague, David Firth, about this, and he suggests
> 
>  > Possibly it would be worth implementing an algebraic vcov method for 
> multinomial logit models [in R]?

Yes, and I look forward to receiving your contribution of it. (See the
R startup banner.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Apr 24 18:23:28 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Apr 2003 17:23:28 +0100 (BST)
Subject: [R] help.start in R-1.7.0 with Netscape 7.0.
In-Reply-To: <200304212107.h3LL7rP6004500@erdos.math.unb.ca>
Message-ID: <Pine.LNX.4.44.0304241714380.1373-100000@gannet.stats>

On Mon, 21 Apr 2003, Rolf Turner wrote:

> No avuncular advice has been forthcoming from the list about
> my problem with getting html-help, but I've been fiddling around
> with it myself and have had a certain amount of insight.  (???)
> 
> The source of the problem seems to be the way that the variable
> isLocal is defined in browseURL():
> 
> 	isLocal <- length(grep("^(localhost|):",
>                           Sys.getenv("DISPLAY"))) > 0
> 
> This seems to make isLocal FALSE in any context in which I work.
> 
> For instance, I am currently sitting at an NCD Xwindows terminal,
> logged into host ``erdos''.  If I execute
> 
> 	> Sys.getenv("DISPLAY")
> 
> I get
>               DISPLAY 
> "131.202.169.153:0.0"
> 
> the string of digits being the IP address of the terminal.  Not
> a "^(localhost|):" in sight.

That's deliberate, and necessary to work around loopholes in Netscape's
remote access protocols.

> I thought to rectify this --- in a kludgy and perhaps dangerous
> way --- by creating for myself a local version of browseURL()
> in which isLocal is always TRUE.  But a funny thing happened:
> 
> I ***still*** got the annoying phenomenon of Netscape's trying
> to open a new browser window (and wanting a new ``profile'')
> every time I asked for help on another function.

Yes, that's intentional, see below.

> To investigate a bit, I created a local version of help() in
> which I could stick some browser() calls to find out the values
> of certain variables.  Blow me down, but didn't things now
> work just fine!  Took out the browser() calls; things still
> worked.  Removed the local help() --- back to not working.
> 
> Even more mysterious to me is the fact that if I just put in
> a local help(), by doing
> 
> 	> help <- help
> 
> then things don't work.  But (ah-ha!) the way I created my local copy
> of help() was to make a local ascii file of the code of help() (with
> a ``help <- '' added at the beginning) and then source this file.
> When this procedure is followed, things ***do*** work!
> 
> This applies even though
> 
> 	> all.equal(help,get("help",pos=grep("base",search()))
> 
> yields TRUE, so that nothing has actually changed in my local copy.
> 
> So help() doesn't find the local copy of browseURL() unless there is
> also a local copy of help() --- and that local copy needs to have
> been created by sourcing a text file!!!  This doesn't make any sense
> to me.  It verges on the mystical.  What on earth is going on?

Namespaces.

> More to the point is there any way that I can persuade help()
> that ``isLocal'' should be taken to be TRUE?
> 
> I don't follow the rationale of ``isLocal'' anyhow.  If I'm sitting
> at machine melvin, but am typing away into a window that is connected
> to host clyde, and I start R in that window, then help.start() will
> invoke the Netscape that lives on clyde.  (Steps must of course have
> been taken to permit clyde to open a Netscape window on melvin's
> display, but that's all done in the normal course of events.)  Hence
> the Netscape that gets fired up will look for the *.html help files
> on clyde and everything will work just as if I were sitting at
> clyde's console.  So why would ``isLocal'' ***ever*** need to be
> FALSE?

That's not how it works.  You would be using *any* netscape window on
melvin, not just one started from clyde.

You are shouting at the wrong audience here: the problem is the Netscape
protocol and how it is implemented (or not) in various versions of
Netscape.  Under Linux/Unix it does not even start a window if not exists 
in 7.0, but did before, yet it does not allow multiple windows which it 
did before.  That `verges on the mystical' indeed.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From maechler at stat.math.ethz.ch  Thu Apr 24 18:25:52 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 24 Apr 2003 18:25:52 +0200
Subject: [R] problems with max.col()
In-Reply-To: <PKAHOFDKPLJALEAA@mailcity.com>
References: <PKAHOFDKPLJALEAA@mailcity.com>
Message-ID: <16040.4112.637025.95143@gargle.gargle.HOWL>

The only problem is that in your R installation

  ?max.col

does (as you say) not give you the help information.
==> problem with your installation only

Because help pages says

>> Details:
>> 
>>      Ties are broken at random.  The determination of ``tie'' assumes
>>      that the entries are probabilities: there is a relative tolerance
>>      of 1e-5, relative to the largest entry in the row.

and you *do* have ties, hence the result is random.

Regards,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><



>>>>> "heberto" == heberto ghezzo <g.heberto at lycos.com>
>>>>>     on Thu, 24 Apr 2003 12:07:22 -0400 writes:

    heberto> Hello, I think the following qualify as a bug
    heberto> given:
    heberto> x<-c(1,2,3,4,2,4,2,2,4,2,2,2,4,3,2,1)
    heberto> z<-embed(x,4)
    heberto> z
    heberto> [,1] [,2] [,3] [,4]
    heberto> [1,]    4    3    2    1
    heberto> [2,]    2    4    3    2
    heberto> [3,]    4    2    4    3
    heberto> [4,]    2    4    2    4
    heberto> [5,]    2    2    4    2
    heberto> [6,]    4    2    2    4
    heberto> [7,]    2    4    2    2
    heberto> [8,]    2    2    4    2
    heberto> [9,]    2    2    2    4
    heberto> [10,]    4    2    2    2
    heberto> [11,]    3    4    2    2
    heberto> [12,]    2    3    4    2
    heberto> [13,]    1    2    3    4
    >> 
    heberto> max.col(z)
    heberto> [1] 1 2 3 4 3 1 2 3 4 1 2 3 4
    heberto> Why?     ^ ^
    >> 1 2
    heberto> or should be
    heberto> [1] 1 2 3 4 3 4 2 3 4 1 2 3 4
    heberto> i.e. the first column with the max, or the last column
    heberto> same if
    heberto> z <- embed(x,5)
    heberto> max.col(z)
    heberto> [1] 2 1 2 5 1 5 3 4 1 2 3 4
    heberto> where it should be either of:
    heberto> 2 1 2 3 1 2 3 4 1 2 3 4
    heberto> 2 3 4 5 4 5 3 4 5 2 3 4
    heberto> or I am missing something?
    heberto> ?max.col does not return anything
    heberto> R 1.7.0 on Win98
    heberto> .
    heberto> Heberto.Ghezzo at McGill.ca

    heberto> ______________________________________________
    heberto> R-help at stat.math.ethz.ch mailing list
    heberto> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From ripley at stats.ox.ac.uk  Thu Apr 24 18:27:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Apr 2003 17:27:58 +0100 (BST)
Subject: [R] problems with max.col()
In-Reply-To: <PKAHOFDKPLJALEAA@mailcity.com>
Message-ID: <Pine.LNX.4.44.0304241724560.1373-100000@gannet.stats>

On Thu, 24 Apr 2003, heberto ghezzo wrote:

> Hello, I think the following qualify as a bug.

>From ?max.col

Details:

     Ties are broken at random.  The determination of ``tie'' assumes
     ^^^^^^^^^^^^^^^^^^^^^^^^^^
     that the entries are probabilities: there is a relative tolerance
     of 1e-5, relative to the largest entry in the row.


> given:
> x<-c(1,2,3,4,2,4,2,2,4,2,2,2,4,3,2,1)
> z<-embed(x,4)
> z
>       [,1] [,2] [,3] [,4]
>  [1,]    4    3    2    1
>  [2,]    2    4    3    2
>  [3,]    4    2    4    3
>  [4,]    2    4    2    4
>  [5,]    2    2    4    2
>  [6,]    4    2    2    4
>  [7,]    2    4    2    2
>  [8,]    2    2    4    2
>  [9,]    2    2    2    4
> [10,]    4    2    2    2
> [11,]    3    4    2    2
> [12,]    2    3    4    2
> [13,]    1    2    3    4
> >
> max.col(z)
>  [1] 1 2 3 4 3 1 2 3 4 1 2 3 4
> Why?     ^ ^
> >        1 2
> or should be
>  [1] 1 2 3 4 3 4 2 3 4 1 2 3 4
> i.e. the first column with the max, or the last column
> same if
> z <- embed(x,5)
>  max.col(z)
>  [1] 2 1 2 5 1 5 3 4 1 2 3 4
> where it should be either of:
>  2 1 2 3 1 2 3 4 1 2 3 4
>  2 3 4 5 4 5 3 4 5 2 3 4
> or I am missing something?

Reading the help page.

> ?max.col does not return anything

It does on my system.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tmurph6 at po-box.mcgill.ca  Thu Apr 24 18:28:35 2003
From: tmurph6 at po-box.mcgill.ca (Tanya Murphy)
Date: Thu, 24 Apr 2003 12:28:35 -0400
Subject: [R] Plotting frequencies as a tree diagram
Message-ID: <3F03C2A1@webmail.mcgill.ca>

Hello,

I would like to plot the frequencies of a bunch of categorical variables--the 
results of a cross-tabs, I guess--as a tree diagram. I've been playing with 
the tree package, but I don't want to estimate or predict anything--I don't 
have a response variable. I just want to show, visually, how candidates for a 
study have been excluded from a final study population. Any suggestions?

Thanks!

Tanya Murphy


From jfkincaidsu at netscape.net  Thu Apr 24 18:29:20 2003
From: jfkincaidsu at netscape.net (Joel Kincaid)
Date: Thu, 24 Apr 2003 12:29:20 -0400
Subject: [R] R 1.7.0 (Windows) Crashes After using "Install Package from Cran
 option" within
Message-ID: <3EA810E0.7030502@netscape.net>

R-Community,

(System Details at end)
I recently downloaded R 1.7.0 win95 binaries from

http://cran.us.r-project.org .

After installing the program with no hitch  I used the the 'Install 
Packages from Cran' optinon in the drop down menu from Rgui. (This may 
be bad form, if so let me know): I selected all paackages to install and 
everything was fine until the 'dse' package was downloading. There was 
some error statement (I believe) involving the phrase 'failure to find 
.lib.loc' . At which point R hung. I closed R and then restarted it and 
the repeated the process being at dse and continuing to 
yap....everything was fine. Closed R and then attempted to restart at 
which point the program hung.

Uninstalled and then reinstalled R: Repeated process, got a similar 
problem of the downloading process hanging (though this time on 
'fracdiff'' package). Plowed on and Rgui started: However, when I 
rebooted my computer and attempted to start the Rgui I'm getting the 
same old problem.

Interesting enough, while Rgui crashes I can get Rterm to work---However 
I get the following at startup
After all of the intial text something to the effect:
"Error in inherits(x, "factor") :Unimplemented feature in  type2str
An error occured in collecting methods for function "initialize", 
perhaps  from C-level dispatch"

System Details:
Windows XP (Home Edition) Service Pack 1 Version 2002
Intel PIII Mobile CPU 1133mherz 384mb ram

When Rgui crashes there is a filed sent to microsoft I have included the 
contents of this file in the body of the text below and I'll try to 
attach the thing as well. If there is more info I can provide, or if 
something I'm doing is screwing my installation (most probable) please 
let me know.

Thanks,
Joel

<?xml version="1.0" encoding="UTF-16"?>
<DATABASE>
<EXE NAME="SYSTEM INFO" FILTER="GRABMI_FILTER_SYSTEM">
    <MATCHING_FILE NAME="advapi32.dll" SIZE="558080" 
CHECKSUM="0x7B6E5DDA" BIN_FILE_VERSION="5.1.2600.1106" 
BIN_PRODUCT_VERSION="5.1.2600.1106" PRODUCT_VERSION="5.1.2600.1106" 
FILE_DESCRIPTION="Advanced Windows 32 Base API" COMPANY_NAME="Microsoft 
Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="advapi32.dll" INTERNAL_NAME="advapi32.dll" 
LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x9315E" 
LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="gdi32.dll" SIZE="250368" CHECKSUM="0x29850525" 
BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="GDI Client DLL" 
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="gdi32" INTERNAL_NAME="gdi32" LEGAL_COPYRIGHT="? 
Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
MODULE_TYPE="WIN32" PE_CHECKSUM="0x4285C" LINKER_VERSION="0x50001" 
UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:39" 
UPTO_LINK_DATE="08/29/2002 10:40:39" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="kernel32.dll" SIZE="930304" 
CHECKSUM="0xCBCCF8A9" BIN_FILE_VERSION="5.1.2600.1106" 
BIN_PRODUCT_VERSION="5.1.2600.1106" PRODUCT_VERSION="5.1.2600.1106" 
FILE_DESCRIPTION="Windows NT BASE API Client DLL" 
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="kernel32" INTERNAL_NAME="kernel32" LEGAL_COPYRIGHT="? 
Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
MODULE_TYPE="WIN32" PE_CHECKSUM="0xE7ED3" LINKER_VERSION="0x50001" 
UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="ntdll.dll" SIZE="668672" CHECKSUM="0x2149BD76" 
BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="NT Layer DLL" 
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="ntdll.dll" INTERNAL_NAME="ntdll.dll" 
LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0xA92F6" 
LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="ole32.dll" SIZE="1169920" CHECKSUM="0x3E53EB37" 
BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="Microsoft OLE for 
Windows" COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? 
Windows? Operating System" FILE_VERSION="5.1.2600.1106 
(xpsp1.020828-1920)" ORIGINAL_FILENAME="OLE32.DLL" 
INTERNAL_NAME="OLE32.DLL" LEGAL_COPYRIGHT="? Microsoft Corporation. All 
rights reserved." VERFILEDATEHI="0x0" VERFILEDATELO="0x0" 
VERFILEOS="0x40004" VERFILETYPE="0x2" MODULE_TYPE="WIN32" 
PE_CHECKSUM="0x121E6B" LINKER_VERSION="0x50001" 
UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:34" 
UPTO_LINK_DATE="08/29/2002 10:40:34" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="oleaut32.dll" SIZE="569344" 
CHECKSUM="0x276CFFB1" BIN_FILE_VERSION="3.50.5016.0" 
BIN_PRODUCT_VERSION="3.50.5016.0" PRODUCT_VERSION="3.50.5016.0" 
FILE_DESCRIPTION="Microsoft OLE 3.50  for Windows NT(TM) and Windows 
95(TM) Operating Systems" COMPANY_NAME="Microsoft Corporation" 
PRODUCT_NAME="Microsoft OLE 3.50  for Windows NT(TM) and Windows 95(TM) 
Operating Systems" FILE_VERSION="3.50.5016.0" 
INTERNAL_NAME="OLEAUT32.DLL" LEGAL_COPYRIGHT="Copyright ? Microsoft 
Corp. 1993-1999." VERFILEDATEHI="0x0" VERFILEDATELO="0x0" 
VERFILEOS="0x40004" VERFILETYPE="0x2" MODULE_TYPE="WIN32" 
PE_CHECKSUM="0x999AF" LINKER_VERSION="0x0" 
UPTO_BIN_FILE_VERSION="3.50.5016.0" 
UPTO_BIN_PRODUCT_VERSION="3.50.5016.0" LINK_DATE="08/29/2002 10:40:34" 
UPTO_LINK_DATE="08/29/2002 10:40:34" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="shell32.dll" SIZE="8336384" 
CHECKSUM="0x1220BF03" BIN_FILE_VERSION="6.0.2800.1106" 
BIN_PRODUCT_VERSION="6.0.2800.1106" PRODUCT_VERSION="6.00.2800.1106" 
FILE_DESCRIPTION="Windows Shell Common Dll" COMPANY_NAME="Microsoft 
Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
FILE_VERSION="6.00.2800.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="SHELL32.DLL" INTERNAL_NAME="SHELL32" 
LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x7F8609" 
LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="6.0.2800.1106" 
UPTO_BIN_PRODUCT_VERSION="6.0.2800.1106" LINK_DATE="08/29/2002 10:40:35" 
UPTO_LINK_DATE="08/29/2002 10:40:35" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="user32.dll" SIZE="560128" CHECKSUM="0x200CFDED" 
BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="Windows XP USER API 
Client DLL" COMPANY_NAME="Microsoft Corporation" 
PRODUCT_NAME="Microsoft? Windows? Operating System" 
FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="user32" INTERNAL_NAME="user32" LEGAL_COPYRIGHT="? 
Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
MODULE_TYPE="WIN32" PE_CHECKSUM="0x936BC" LINKER_VERSION="0x50001" 
UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="wininet.dll" SIZE="599040" 
CHECKSUM="0xBEF20B21" BIN_FILE_VERSION="6.0.2800.1106" 
BIN_PRODUCT_VERSION="6.0.2800.1106" PRODUCT_VERSION="6.00.2800.1106" 
FILE_DESCRIPTION="Internet Extensions for Win32" COMPANY_NAME="Microsoft 
Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
FILE_VERSION="6.00.2800.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="wininet.dll" INTERNAL_NAME="wininet.dll" 
LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x96179" 
LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="6.0.2800.1106" 
UPTO_BIN_PRODUCT_VERSION="6.0.2800.1106" LINK_DATE="08/29/2002 10:40:28" 
UPTO_LINK_DATE="08/29/2002 10:40:28" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="winsock.dll" SIZE="2864" CHECKSUM="0x73AE8088" 
BIN_FILE_VERSION="3.10.0.103" BIN_PRODUCT_VERSION="3.10.0.103" 
PRODUCT_VERSION="3.10" FILE_DESCRIPTION="Windows Socket 16-Bit DLL" 
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? 
Windows(TM) Operating System" FILE_VERSION="3.10" 
ORIGINAL_FILENAME="WINSOCK.DLL" INTERNAL_NAME="WINSOCK" 
LEGAL_COPYRIGHT="Copyright ? Microsoft Corp. 1981-1996" 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x10001" 
VERFILETYPE="0x2" MODULE_TYPE="WIN16" S16BIT_DESCRIPTION="BSD Socket API 
for Windows" S16BIT_MODULE_NAME="WINSOCK" 
UPTO_BIN_FILE_VERSION="3.10.0.103" UPTO_BIN_PRODUCT_VERSION="3.10.0.103" 
VER_LANGUAGE="English (United States) [0x409]" />
</EXE>
</DATABASE>



??<?xml version="1.0" encoding="UTF-16"?>

<DATABASE>

<EXE NAME="SYSTEM INFO" FILTER="GRABMI_FILTER_SYSTEM">

     <MATCHING_FILE NAME="advapi32.dll" SIZE="558080" 
CHECKSUM="0x7B6E5DDA" BIN_FILE_VERSION="5.1.2600.1106" 
BIN_PRODUCT_VERSION="5.1.2600.1106" PRODUCT_VERSION="5.1.2600.1106" 
FILE_DESCRIPTION="Advanced Windows 32 Base API" COMPANY_NAME="Microsoft 
Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="advapi32.dll" INTERNAL_NAME="advapi32.dll" 
LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x9315E" 
LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
States) [0x409]" />

     <MATCHING_FILE NAME="gdi32.dll" SIZE="250368" CHECKSUM="0x29850525" 
BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="GDI Client DLL" 
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="gdi32" INTERNAL_NAME="gdi32" LEGAL_COPYRIGHT="? 
Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
MODULE_TYPE="WIN32" PE_CHECKSUM="0x4285C" LINKER_VERSION="0x50001" 
UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:39" 
UPTO_LINK_DATE="08/29/2002 10:40:39" VER_LANGUAGE="English (United 
States) [0x409]" />

     <MATCHING_FILE NAME="kernel32.dll" SIZE="930304" 
CHECKSUM="0xCBCCF8A9" BIN_FILE_VERSION="5.1.2600.1106" 
BIN_PRODUCT_VERSION="5.1.2600.1106" PRODUCT_VERSION="5.1.2600.1106" 
FILE_DESCRIPTION="Windows NT BASE API Client DLL" 
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="kernel32" INTERNAL_NAME="kernel32" LEGAL_COPYRIGHT="? 
Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
MODULE_TYPE="WIN32" PE_CHECKSUM="0xE7ED3" LINKER_VERSION="0x50001" 
UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
States) [0x409]" />

     <MATCHING_FILE NAME="ntdll.dll" SIZE="668672" CHECKSUM="0x2149BD76" 
BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="NT Layer DLL" 
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="ntdll.dll" INTERNAL_NAME="ntdll.dll" 
LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0xA92F6" 
LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
States) [0x409]" />

     <MATCHING_FILE NAME="ole32.dll" SIZE="1169920" 
CHECKSUM="0x3E53EB37" BIN_FILE_VERSION="5.1.2600.1106" 
BIN_PRODUCT_VERSION="5.1.2600.1106" PRODUCT_VERSION="5.1.2600.1106" 
FILE_DESCRIPTION="Microsoft OLE for Windows" COMPANY_NAME="Microsoft 
Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="OLE32.DLL" INTERNAL_NAME="OLE32.DLL" 
LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x121E6B" 
LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:34" 
UPTO_LINK_DATE="08/29/2002 10:40:34" VER_LANGUAGE="English (United 
States) [0x409]" />

     <MATCHING_FILE NAME="oleaut32.dll" SIZE="569344" 
CHECKSUM="0x276CFFB1" BIN_FILE_VERSION="3.50.5016.0" 
BIN_PRODUCT_VERSION="3.50.5016.0" PRODUCT_VERSION="3.50.5016.0" 
FILE_DESCRIPTION="Microsoft OLE 3.50  for Windows NT(TM) and Windows 
95(TM) Operating Systems" COMPANY_NAME="Microsoft Corporation" 
PRODUCT_NAME="Microsoft OLE 3.50  for Windows NT(TM) and Windows 95(TM) 
Operating Systems" FILE_VERSION="3.50.5016.0" 
INTERNAL_NAME="OLEAUT32.DLL" LEGAL_COPYRIGHT="Copyright ? Microsoft 
Corp. 1993-1999." VERFILEDATEHI="0x0" VERFILEDATELO="0x0" 
VERFILEOS="0x40004" VERFILETYPE="0x2" MODULE_TYPE="WIN32" 
PE_CHECKSUM="0x999AF" LINKER_VERSION="0x0" 
UPTO_BIN_FILE_VERSION="3.50.5016.0" 
UPTO_BIN_PRODUCT_VERSION="3.50.5016.0" LINK_DATE="08/29/2002 10:40:34" 
UPTO_LINK_DATE="08/29/2002 10:40:34" VER_LANGUAGE="English (United 
States) [0x409]" />

     <MATCHING_FILE NAME="shell32.dll" SIZE="8336384" 
CHECKSUM="0x1220BF03" BIN_FILE_VERSION="6.0.2800.1106" 
BIN_PRODUCT_VERSION="6.0.2800.1106" PRODUCT_VERSION="6.00.2800.1106" 
FILE_DESCRIPTION="Windows Shell Common Dll" COMPANY_NAME="Microsoft 
Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
FILE_VERSION="6.00.2800.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="SHELL32.DLL" INTERNAL_NAME="SHELL32" 
LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x7F8609" 
LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="6.0.2800.1106" 
UPTO_BIN_PRODUCT_VERSION="6.0.2800.1106" LINK_DATE="08/29/2002 10:40:35" 
UPTO_LINK_DATE="08/29/2002 10:40:35" VER_LANGUAGE="English (United 
States) [0x409]" />

     <MATCHING_FILE NAME="user32.dll" SIZE="560128" 
CHECKSUM="0x200CFDED" BIN_FILE_VERSION="5.1.2600.1106" 
BIN_PRODUCT_VERSION="5.1.2600.1106" PRODUCT_VERSION="5.1.2600.1106" 
FILE_DESCRIPTION="Windows XP USER API Client DLL" 
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="user32" INTERNAL_NAME="user32" LEGAL_COPYRIGHT="? 
Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
MODULE_TYPE="WIN32" PE_CHECKSUM="0x936BC" LINKER_VERSION="0x50001" 
UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
States) [0x409]" />

     <MATCHING_FILE NAME="wininet.dll" SIZE="599040" 
CHECKSUM="0xBEF20B21" BIN_FILE_VERSION="6.0.2800.1106" 
BIN_PRODUCT_VERSION="6.0.2800.1106" PRODUCT_VERSION="6.00.2800.1106" 
FILE_DESCRIPTION="Internet Extensions for Win32" COMPANY_NAME="Microsoft 
Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
FILE_VERSION="6.00.2800.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="wininet.dll" INTERNAL_NAME="wininet.dll" 
LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x96179" 
LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="6.0.2800.1106" 
UPTO_BIN_PRODUCT_VERSION="6.0.2800.1106" LINK_DATE="08/29/2002 10:40:28" 
UPTO_LINK_DATE="08/29/2002 10:40:28" VER_LANGUAGE="English (United 
States) [0x409]" />

     <MATCHING_FILE NAME="winsock.dll" SIZE="2864" CHECKSUM="0x73AE8088" 
BIN_FILE_VERSION="3.10.0.103" BIN_PRODUCT_VERSION="3.10.0.103" 
PRODUCT_VERSION="3.10" FILE_DESCRIPTION="Windows Socket 16-Bit DLL" 
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? 
Windows(TM) Operating System" FILE_VERSION="3.10" 
ORIGINAL_FILENAME="WINSOCK.DLL" INTERNAL_NAME="WINSOCK" 
LEGAL_COPYRIGHT="Copyright ? Microsoft Corp. 1981-1996" 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x10001" 
VERFILETYPE="0x2" MODULE_TYPE="WIN16" S16BIT_DESCRIPTION="BSD Socket API 
for Windows" S16BIT_MODULE_NAME="WINSOCK" 
UPTO_BIN_FILE_VERSION="3.10.0.103" UPTO_BIN_PRODUCT_VERSION="3.10.0.103" 
VER_LANGUAGE="English (United States) [0x409]" />

</EXE>

</DATABASE>


From thecore06 at aol.com  Thu Apr 24 18:27:06 2003
From: thecore06 at aol.com (thecore06)
Date: Thu, 24 Apr 2003 12:27:06 -0400
Subject: [R] R 1.7.0 (Windows) Crashes After using "Install Package from Cran
 option" within 
Message-ID: <3EA8105A.1010506@aol.com>

R-Community,

(System Details at end)
I recently downloaded R 1.7.0 win95 binaries from

http://cran.us.r-project.org .

After installing the program with no hitch  I used the the 'Install 
Packages from Cran' optinon in the drop down menu from Rgui. (This may 
be bad form, if so let me know): I selected all paackages to install and 
everything was fine until the 'dse' package was downloading. There was 
some error statement (I believe) involving the phrase 'failure to find 
.lib.loc' . At which point R hung. I closed R and then restarted it and 
the repeated the process being at dse and continuing to 
yap....everything was fine. Closed R and then attempted to restart at 
which point the program hung.

Uninstalled and then reinstalled R: Repeated process, got a similar 
problem of the downloading process hanging (though this time on 
'fracdiff'' package). Plowed on and Rgui started: However, when I 
rebooted my computer and attempted to start the Rgui I'm getting the 
same old problem.

Interesting enough, while Rgui crashes I can get Rterm to work---However 
I get the following at startup
After all of the intial text something to the effect:
"Error in inherits(x, "factor") :Unimplemented feature in  type2str
An error occured in collecting methods for function "initialize", 
perhaps  from C-level dispatch"

System Details:
Windows XP (Home Edition) Service Pack 1 Version 2002
Intel PIII Mobile CPU 1133mherz 384mb ram

When Rgui crashes there is a filed sent to microsoft I have included the 
contents of this file in the body of the text below and I'll try to 
attach the thing as well. If there is more info I can provide, or if 
something I'm doing is screwing my installation (most probable) please 
let me know.

Thanks,
Joel

<?xml version="1.0" encoding="UTF-16"?>
<DATABASE>
<EXE NAME="SYSTEM INFO" FILTER="GRABMI_FILTER_SYSTEM">
    <MATCHING_FILE NAME="advapi32.dll" SIZE="558080" 
CHECKSUM="0x7B6E5DDA" BIN_FILE_VERSION="5.1.2600.1106" 
BIN_PRODUCT_VERSION="5.1.2600.1106" PRODUCT_VERSION="5.1.2600.1106" 
FILE_DESCRIPTION="Advanced Windows 32 Base API" COMPANY_NAME="Microsoft 
Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="advapi32.dll" INTERNAL_NAME="advapi32.dll" 
LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x9315E" 
LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="gdi32.dll" SIZE="250368" CHECKSUM="0x29850525" 
BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="GDI Client DLL" 
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="gdi32" INTERNAL_NAME="gdi32" LEGAL_COPYRIGHT="? 
Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
MODULE_TYPE="WIN32" PE_CHECKSUM="0x4285C" LINKER_VERSION="0x50001" 
UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:39" 
UPTO_LINK_DATE="08/29/2002 10:40:39" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="kernel32.dll" SIZE="930304" 
CHECKSUM="0xCBCCF8A9" BIN_FILE_VERSION="5.1.2600.1106" 
BIN_PRODUCT_VERSION="5.1.2600.1106" PRODUCT_VERSION="5.1.2600.1106" 
FILE_DESCRIPTION="Windows NT BASE API Client DLL" 
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="kernel32" INTERNAL_NAME="kernel32" LEGAL_COPYRIGHT="? 
Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
MODULE_TYPE="WIN32" PE_CHECKSUM="0xE7ED3" LINKER_VERSION="0x50001" 
UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="ntdll.dll" SIZE="668672" CHECKSUM="0x2149BD76" 
BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="NT Layer DLL" 
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="ntdll.dll" INTERNAL_NAME="ntdll.dll" 
LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0xA92F6" 
LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="ole32.dll" SIZE="1169920" CHECKSUM="0x3E53EB37" 
BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="Microsoft OLE for 
Windows" COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? 
Windows? Operating System" FILE_VERSION="5.1.2600.1106 
(xpsp1.020828-1920)" ORIGINAL_FILENAME="OLE32.DLL" 
INTERNAL_NAME="OLE32.DLL" LEGAL_COPYRIGHT="? Microsoft Corporation. All 
rights reserved." VERFILEDATEHI="0x0" VERFILEDATELO="0x0" 
VERFILEOS="0x40004" VERFILETYPE="0x2" MODULE_TYPE="WIN32" 
PE_CHECKSUM="0x121E6B" LINKER_VERSION="0x50001" 
UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:34" 
UPTO_LINK_DATE="08/29/2002 10:40:34" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="oleaut32.dll" SIZE="569344" 
CHECKSUM="0x276CFFB1" BIN_FILE_VERSION="3.50.5016.0" 
BIN_PRODUCT_VERSION="3.50.5016.0" PRODUCT_VERSION="3.50.5016.0" 
FILE_DESCRIPTION="Microsoft OLE 3.50  for Windows NT(TM) and Windows 
95(TM) Operating Systems" COMPANY_NAME="Microsoft Corporation" 
PRODUCT_NAME="Microsoft OLE 3.50  for Windows NT(TM) and Windows 95(TM) 
Operating Systems" FILE_VERSION="3.50.5016.0" 
INTERNAL_NAME="OLEAUT32.DLL" LEGAL_COPYRIGHT="Copyright ? Microsoft 
Corp. 1993-1999." VERFILEDATEHI="0x0" VERFILEDATELO="0x0" 
VERFILEOS="0x40004" VERFILETYPE="0x2" MODULE_TYPE="WIN32" 
PE_CHECKSUM="0x999AF" LINKER_VERSION="0x0" 
UPTO_BIN_FILE_VERSION="3.50.5016.0" 
UPTO_BIN_PRODUCT_VERSION="3.50.5016.0" LINK_DATE="08/29/2002 10:40:34" 
UPTO_LINK_DATE="08/29/2002 10:40:34" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="shell32.dll" SIZE="8336384" 
CHECKSUM="0x1220BF03" BIN_FILE_VERSION="6.0.2800.1106" 
BIN_PRODUCT_VERSION="6.0.2800.1106" PRODUCT_VERSION="6.00.2800.1106" 
FILE_DESCRIPTION="Windows Shell Common Dll" COMPANY_NAME="Microsoft 
Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
FILE_VERSION="6.00.2800.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="SHELL32.DLL" INTERNAL_NAME="SHELL32" 
LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x7F8609" 
LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="6.0.2800.1106" 
UPTO_BIN_PRODUCT_VERSION="6.0.2800.1106" LINK_DATE="08/29/2002 10:40:35" 
UPTO_LINK_DATE="08/29/2002 10:40:35" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="user32.dll" SIZE="560128" CHECKSUM="0x200CFDED" 
BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="Windows XP USER API 
Client DLL" COMPANY_NAME="Microsoft Corporation" 
PRODUCT_NAME="Microsoft? Windows? Operating System" 
FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="user32" INTERNAL_NAME="user32" LEGAL_COPYRIGHT="? 
Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
MODULE_TYPE="WIN32" PE_CHECKSUM="0x936BC" LINKER_VERSION="0x50001" 
UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="wininet.dll" SIZE="599040" 
CHECKSUM="0xBEF20B21" BIN_FILE_VERSION="6.0.2800.1106" 
BIN_PRODUCT_VERSION="6.0.2800.1106" PRODUCT_VERSION="6.00.2800.1106" 
FILE_DESCRIPTION="Internet Extensions for Win32" COMPANY_NAME="Microsoft 
Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
FILE_VERSION="6.00.2800.1106 (xpsp1.020828-1920)" 
ORIGINAL_FILENAME="wininet.dll" INTERNAL_NAME="wininet.dll" 
LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x96179" 
LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="6.0.2800.1106" 
UPTO_BIN_PRODUCT_VERSION="6.0.2800.1106" LINK_DATE="08/29/2002 10:40:28" 
UPTO_LINK_DATE="08/29/2002 10:40:28" VER_LANGUAGE="English (United 
States) [0x409]" />
    <MATCHING_FILE NAME="winsock.dll" SIZE="2864" CHECKSUM="0x73AE8088" 
BIN_FILE_VERSION="3.10.0.103" BIN_PRODUCT_VERSION="3.10.0.103" 
PRODUCT_VERSION="3.10" FILE_DESCRIPTION="Windows Socket 16-Bit DLL" 
COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? 
Windows(TM) Operating System" FILE_VERSION="3.10" 
ORIGINAL_FILENAME="WINSOCK.DLL" INTERNAL_NAME="WINSOCK" 
LEGAL_COPYRIGHT="Copyright ? Microsoft Corp. 1981-1996" 
VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x10001" 
VERFILETYPE="0x2" MODULE_TYPE="WIN16" S16BIT_DESCRIPTION="BSD Socket API 
for Windows" S16BIT_MODULE_NAME="WINSOCK" 
UPTO_BIN_FILE_VERSION="3.10.0.103" UPTO_BIN_PRODUCT_VERSION="3.10.0.103" 
VER_LANGUAGE="English (United States) [0x409]" />
</EXE>
</DATABASE>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: appcompat.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030424/e55ccdb1/appcompat.txt

From juli at ceam.es  Thu Apr 24 18:26:55 2003
From: juli at ceam.es (juli g. pausas)
Date: Thu, 24 Apr 2003 18:26:55 +0200
Subject: [R] matrix to coordinates
Message-ID: <3EA8104F.1020905@ceam.es>

Dear R-users,
I'm sure it must be a specific function or a better way to convert 
matrix to x,y,z coordinates (and viceversa), than my function below (it 
works). Any help?

m2coord <- function(m)
{
k <- nrow(m)*ncol(m)
aa <- data.frame(r=1:k, c=1:k, v=1:k)
k <- 0
  for (i in 1:nrow(m))
  for (j in 1:ncol(m))
  {
  k <- k+1
  aa$f[k]=i; aa$c[k]=j; aa$v[k]=m[i,j]
  }
aa
}

Juli

-- 
Juli G. Pausas
Centro de Estudios Ambientales del Mediterraneo (CEAM)
C/ C.R. Darwin 14, Parc Tecnologic,
46980 Paterna, Valencia, SPAIN
Tel: (+ 34) 96 131 8227; Fax: (+ 34) 96 131 8190
mailto:juli at ceam.es 
http://www.gva.es/ceam 

GCTE Fire Network - http://www.gva.es/ceam/FireNetwork

--
"Wars do not solve problems, wars generate even more problems"


From ligges at statistik.uni-dortmund.de  Thu Apr 24 18:36:28 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 24 Apr 2003 18:36:28 +0200
Subject: [R] problems with max.col()
In-Reply-To: <PKAHOFDKPLJALEAA@mailcity.com>
References: <PKAHOFDKPLJALEAA@mailcity.com>
Message-ID: <3EA8128C.60301@statistik.uni-dortmund.de>

heberto ghezzo wrote:
> Hello, I think the following qualify as a bug
> given:
> x<-c(1,2,3,4,2,4,2,2,4,2,2,2,4,3,2,1)
> z<-embed(x,4)
> z
>       [,1] [,2] [,3] [,4]
>  [1,]    4    3    2    1
>  [2,]    2    4    3    2
>  [3,]    4    2    4    3
>  [4,]    2    4    2    4
>  [5,]    2    2    4    2
>  [6,]    4    2    2    4
>  [7,]    2    4    2    2
>  [8,]    2    2    4    2
>  [9,]    2    2    2    4
> [10,]    4    2    2    2
> [11,]    3    4    2    2
> [12,]    2    3    4    2
> [13,]    1    2    3    4
> 
> max.col(z)
>  [1] 1 2 3 4 3 1 2 3 4 1 2 3 4
> Why?     ^ ^
> 
>>       1 2
> 
> or should be
>  [1] 1 2 3 4 3 4 2 3 4 1 2 3 4
> i.e. the first column with the max, or the last column
> same if
> z <- embed(x,5)
>  max.col(z)
>  [1] 2 1 2 5 1 5 3 4 1 2 3 4
> where it should be either of:
>  2 1 2 3 1 2 3 4 1 2 3 4
>  2 3 4 5 4 5 3 4 5 2 3 4
> or I am missing something?

Reading the word "random" in its help file:

"Find the maximum position for each row of a matrix, breaking ties at 
random."


You observed another bug: The Compiled HTML help file (on Windows) 
doesn't come up with ?max.col. Nevertheless, brosing through the index 
results in a working link (and a page).

I'm not sure whether the bug is in R or in Microsoft's help compiler ...
I will take a look later (and move the thread to R-devel in case of 
further investigations).

Uwe Ligges


> ?max.col does not return anything
> R 1.7.0 on Win98
> .
> Heberto.Ghezzo at McGill.ca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tomas.larsson at gm.com  Thu Apr 24 18:42:21 2003
From: tomas.larsson at gm.com (tomas.larsson@gm.com)
Date: Thu, 24 Apr 2003 12:42:21 -0400
Subject: [R] matrix subset question
Message-ID: <OF6E561127.2B33AF51-ON85256D12.0059F861@mail.gm.com>

Dear R-helpers,

If P is a matrix and I want to obtains one column from P I write:

x<-P[,k]

I always want to maintain the data as a matrix, even if the data is a
single row, to do that I have to write:

x<-P[,k,drop=FALSE]

Here is my question:
Is there any way that I can change my default to be drop=FALSE so that I do
not have to add this every single time?

Tomas,


From p.dalgaard at biostat.ku.dk  Thu Apr 24 18:51:13 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 24 Apr 2003 18:51:13 +0200
Subject: [OT] Re: [R] help.start in R-1.7.0 with Netscape 7.0.
In-Reply-To: <Pine.LNX.4.44.0304241714380.1373-100000@gannet.stats>
References: <Pine.LNX.4.44.0304241714380.1373-100000@gannet.stats>
Message-ID: <x28ytz96v2.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> You are shouting at the wrong audience here: the problem is the Netscape
> protocol and how it is implemented (or not) in various versions of
> Netscape.  Under Linux/Unix it does not even start a window if not exists 
> in 7.0, but did before, yet it does not allow multiple windows which it 
> did before.  That `verges on the mystical' indeed.

Right. There seems to a lot of ill thought out design of that variety
going on these days. E.g.: put my laptop on the net, work on it from
the desktop, open a local file with NS/Mozilla. Up till a year or two
ago, that would work fine. Now, it detects that I have a browser open
on the desktop machine and that of course complains that it cannot
find the file on that machine. Same thing if I want to browse the Web
and download something to the laptop - need to close down whatever I
was doing beforehand or the download goes to the wrong machine. Login
at two machines simultaneously and browse from both? Forget it... Even
on the same machine you can get in trouble if you work on two things
at the same time and closing the browser in one workspace also kills
the one in the other workspace. Grrrr....

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From f0z6305 at labs.tamu.edu  Thu Apr 24 19:07:43 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Thu, 24 Apr 2003 12:07:43 -0500
Subject: [R] Matrix Equation Help?
Message-ID: <006001c30a84$0888cdd0$8bd75ba5@IE.TAMU.EDU>

Dear R-listers

Now I have a Matrix Equation to solve,
A -- m by n matrix, where n>>m, known matrix;
X -- n by m unknown matrix;
B -- m by m known matrix.

So given the equation A*X=B, how to solve X?
I first tried to take X = inv((A'*A))*A'. But since
A'*A is singular, this is no way to go.

Please give me some point on this.
Thanks

Fred


From ripley at stats.ox.ac.uk  Thu Apr 24 19:44:18 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Apr 2003 18:44:18 +0100 (BST)
Subject: [R] matrix subset question
In-Reply-To: <OF6E561127.2B33AF51-ON85256D12.0059F861@mail.gm.com>
Message-ID: <Pine.LNX.4.44.0304241841260.1577-100000@gannet.stats>

On Thu, 24 Apr 2003 tomas.larsson at gm.com wrote:

> Dear R-helpers,
> 
> If P is a matrix and I want to obtains one column from P I write:
> 
> x<-P[,k]
> 
> I always want to maintain the data as a matrix, even if the data is a
> single row, to do that I have to write:
> 
> x<-P[,k,drop=FALSE]

> Here is my question:
> Is there any way that I can change my default to be drop=FALSE so that I do
> not have to add this every single time?

No.

And you would not want to, for much of R is itself written in R and relies 
on the default behaviour of subsetting.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mt at michaelltaylor.com  Thu Apr 24 19:52:35 2003
From: mt at michaelltaylor.com (michaell taylor)
Date: 24 Apr 2003 13:52:35 -0400
Subject: [R] pause during execution
Message-ID: <1051206755.7207.15.camel@xeon>


I am trying to figure out how to pause the execution of a script and
release the R command prompt to users and then continue execution of the
script from the point it was stopped.  This operation is analogous to
the "pause" command in stata.  

If I remember correctly, insertion of a pause command in a stata script
stopped script execution and allows users to manipulate objects that
currently exist.  Upon "quiting" the script picks up where it left off.

I am sure there is such a facility, but I can't find it.

Michaell Taylor


From tblackw at umich.edu  Thu Apr 24 20:06:26 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 24 Apr 2003 14:06:26 -0400 (EDT)
Subject: [R] matrix to coordinates
In-Reply-To: <3EA8104F.1020905@ceam.es>
Message-ID: <Pine.SOL.4.44.0304241403270.26646-100000@rygar.gpcc.itd.umich.edu>


The two functions  row(), col()  are useful here:

aa <- data.frame(r=as.vector(row(m)), c=as.vector(col(m)), v=as.vector(m))

There's no other ready-made function for this, AFAIK.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 24 Apr 2003, juli g. pausas wrote:

> Dear R-users,
> I'm sure it must be a specific function or a better way to convert
> matrix to x,y,z coordinates (and viceversa), than my function below (it
> works). Any help?
>
> m2coord <- function(m)
> {
> k <- nrow(m)*ncol(m)
> aa <- data.frame(r=1:k, c=1:k, v=1:k)
> k <- 0
>   for (i in 1:nrow(m))
>   for (j in 1:ncol(m))
>   {
>   k <- k+1
>   aa$f[k]=i; aa$c[k]=j; aa$v[k]=m[i,j]
>   }
> aa
> }
>
> Juli
> --
> Juli G. Pausas
> Centro de Estudios Ambientales del Mediterraneo (CEAM)
> C/ C.R. Darwin 14, Parc Tecnologic,
> 46980 Paterna, Valencia, SPAIN
> Tel: (+ 34) 96 131 8227; Fax: (+ 34) 96 131 8190
> mailto:juli at ceam.es
> http://www.gva.es/ceam


From ripley at stats.ox.ac.uk  Thu Apr 24 20:07:37 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 24 Apr 2003 19:07:37 +0100 (BST)
Subject: [R] Problem with pixmap on R 1.7.0?
In-Reply-To: <3EA68353.1050901@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.44.0304241901530.1577-100000@gannet.stats>

On Wed, 23 Apr 2003, Uwe Ligges wrote:

> Kenneth Cabrera wrote:
> > Hi R users:
> > I got the following message when I use the pixmap library
> > on R 1.7.0 over w2K platform (on R 1.6.2 it runs right).
> > 
> > pixmapGrey(matrix(c(0,1),128,128))
> > Error in .class1(object) : Object "from" not found
> > 
> > I download the library .zip file from:
> > 
> > http://cran.r-project.org/bin/windows/contrib/1.7/pixmap_0.3-2.zip
> 
> It seems to be a problem with this specific binary file for windows.

R has changed since it was compiled and it needed to be re-dumped.
That's a problem with S4-using packages, and of course I haven't had a 
released version of 1.7.0 to build them against until today (see below).

> Installing from sources solves the problem. I made a fresh bundled 
> binary available at 
> http://www.statistik.uni-dortmund.de/~ligges/pixmap_0.3-2.zip while
> 
> Brian seems to be away for recompiling these days.

Yes, he has holidays sometimes.
The Vienna master site should be up to date tomorrow, including this.

> > Other question:
> > 
> > When I try to "Install package(s) from bioconductor" I got the
> > following message:
> > 
> > local({a<-CRAN.packages(CRAN=getOption("BIOC"))
> > + install.packages(select.list(a[,1],,TRUE), .libPaths()[1], 
> > available=a, CRAN=getOption("BIOC"))})
> > 
> > trying URL `http://www.bioconductor.org/bin/windows/contrib/1.7/PACKAGES'
> > Error in download.file(url = paste(contriburl, "PACKAGES", sep = "/"),  
> > : cannot open: HTTP status was `404 Not Found'
> > 
> > Are the packages in other path of www.bioconductor.org? Which one?
> 
> This seems to be solved now.

bioC needed to catch up with R 1.7.x, that's all.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Thu Apr 24 20:11:56 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 24 Apr 2003 20:11:56 +0200
Subject: [R] Matrix Equation Help?
In-Reply-To: <006001c30a84$0888cdd0$8bd75ba5@IE.TAMU.EDU>
References: <006001c30a84$0888cdd0$8bd75ba5@IE.TAMU.EDU>
Message-ID: <3EA828EC.2060101@statistik.uni-dortmund.de>

Feng Zhang wrote:
> Dear R-listers
> 
> Now I have a Matrix Equation to solve,
> A -- m by n matrix, where n>>m, known matrix;
> X -- n by m unknown matrix;
> B -- m by m known matrix.
> 
> So given the equation A*X=B, how to solve X?

You already mentioned it:
?solve

Uwe Ligges

> I first tried to take X = inv((A'*A))*A'. But since
> A'*A is singular, this is no way to go.
> 
> Please give me some point on this.
> Thanks
> 
> Fred
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From baron at psych.upenn.edu  Thu Apr 24 20:35:58 2003
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 24 Apr 2003 14:35:58 -0400
Subject: [R] pause during execution
In-Reply-To: <1051206755.7207.15.camel@xeon>
References: <1051206755.7207.15.camel@xeon>
Message-ID: <20030424183558.GA3434@mail2.sas.upenn.edu>

On 04/24/03 13:52, michaell taylor wrote:
>
>I am trying to figure out how to pause the execution of a script and
>release the R command prompt to users and then continue execution of the
>script from the point it was stopped.  This operation is analogous to
>the "pause" command in stata.  

readline

-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
R page:               http://finzi.psych.upenn.edu/


From heberto.ghezzo at mcgill.ca  Thu Apr 24 20:52:32 2003
From: heberto.ghezzo at mcgill.ca (R.Heberto Ghezzo)
Date: Thu, 24 Apr 2003 14:52:32 -0400
Subject: [R] problems with max.col ()
Message-ID: <3EA83270.9060601@mcgill.ca>

Hello, I think the following qualify as a bug
given:
x<-c(1,2,3,4,2,4,2,2,4,2,2,2,4,3,2,1)
z<-embed(x,4)
z
       [,1] [,2] [,3] [,4]
  [1,]    4    3    2    1
  [2,]    2    4    3    2
  [3,]    4    2    4    3
  [4,]    2    4    2    4
  [5,]    2    2    4    2
  [6,]    4    2    2    4
  [7,]    2    4    2    2
  [8,]    2    2    4    2
  [9,]    2    2    2    4
[10,]    4    2    2    2
[11,]    3    4    2    2
[12,]    2    3    4    2
[13,]    1    2    3    4
 >
max.col(z)
  [1] 1 2 3 4 3 1 2 3 4 1 2 3 4
Why?     ^ ^
 >        1 2
or should be
  [1] 1 2 3 4 3 4 2 3 4 1 2 3 4
i.e. the first column with the max, or the last column
same if
z <- embed(x,5)
  max.col(z)
  [1] 2 1 2 5 1 5 3 4 1 2 3 4
where it should be either of:
  2 1 2 3 1 2 3 4 1 2 3 4
  2 3 4 5 4 5 3 4 5 2 3 4
or I am missing something?
?max.col does not return anything
R 1.7.0 on Win98
As always thanks for any help


From krparker at sonic.net  Thu Apr 24 21:02:51 2003
From: krparker at sonic.net (Keith R. Parker)
Date: Thu, 24 Apr 2003 12:02:51 -0700
Subject: [R] gee?
Message-ID: <5.1.0.14.0.20030424115855.00b38bc8@mailbox.sonic.net>

All -

I would like to run a repeated measures analysis using non normal error 
(glm). Is "gee" the appropriate package? Else? Any real life examples using 
longitudinal data?

Thanks, Keith


From MZodet at ahrq.gov  Thu Apr 24 22:20:53 2003
From: MZodet at ahrq.gov (MZodet@ahrq.gov)
Date: Thu, 24 Apr 2003 16:20:53 -0400
Subject: [R] Detailed contingency tables
Message-ID: <3598558AD728D41183350008C7CF291C0A5CD151@exchange1.ahrq.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030424/c91272c2/attachment.pl

From ozric at web.de  Thu Apr 24 22:41:28 2003
From: ozric at web.de (Christian Schulz)
Date: Thu, 24 Apr 2003 22:41:28 +0200
Subject: [R] Detailed contingency tables
References: <3598558AD728D41183350008C7CF291C0A5CD151@exchange1.ahrq.gov>
Message-ID: <002601c30aa1$e21f2450$0100a8c0@pc>

...perhaps  CrossTable in gregmisc help you?

christian

----- Original Message ----- 
From: <MZodet at ahrq.gov>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, April 24, 2003 10:20 PM
Subject: [R] Detailed contingency tables


> Is there any existing function for creating contingency tables that will
> display counts, row, column, and cell percentages in the same
> tables....anything similar to crosstabs in S? 
> 
> Marc W. Zodet, MS
> Health Statistician
> Center for Cost and Financing Studies
> Division of Statistical Research and Methods
> 2101 East Jefferson Street, Suite 500
> Rockville, Maryland 20852
> Phone: 301-594-7072
> Fax: 301-594-2166
> E-mail: mzodet at ahrq.gov <mailto:mzodet at ahrq.gov> 
> 
> 
> [[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From csillery at selway.umt.edu  Thu Apr 24 22:46:09 2003
From: csillery at selway.umt.edu (Katalin Csillery)
Date: Thu, 24 Apr 2003 14:46:09 -0600 (MDT)
Subject: [R] bca ci's and NaN's in boot.out
Message-ID: <Pine.OSF.4.21.0304241421030.6835-100000@selway.umt.edu>


Dear All,

I am trying to use the bca.ci function on a boot.out object which consists
a few NaN's and I want to ignore those NaN's, and get a ci
only for the "normal" values. 
boot.out$t has R number of values for 3000 different statistics, so when I
use boot.ci(boot.out, index=i) and i happens to be a column in boot.out$t
with some NaN's in there I get an error message. I tried na.omit for the
problematic columns, but bca.ci needs a boot.out object so I cannot feed
in a single column. The number of NaN's varies, and for some statistics 
there isn't any.

Interestingly the standard errors that the boot() calculates and returns
there is an automatic NA exclusion.
(A side question, in S+ the se's are saved in boot.out$statistics$SE, but
in R boot.out I couldn't find them. Are they saved somewhere in boot.out?)

Any idea would be greatly appreaciated!

Kati

___
Katalin Csillery
Division of Biological Sciences
University of Montana, Missoula MT 59801
Phone: 406 243 6106, E-mail: csillery at selway.umt.edu


From tblackw at umich.edu  Fri Apr 25 00:04:48 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Thu, 24 Apr 2003 18:04:48 -0400 (EDT)
Subject: [R] bca ci's and NaN's in boot.out
In-Reply-To: <Pine.OSF.4.21.0304241421030.6835-100000@selway.umt.edu>
Message-ID: <Pine.SOL.4.44.0304241728130.24900-100000@mspacman.gpcc.itd.umich.edu>

Katalin  -

I think that calling  bca.ci()  with argument  type="reg"
in addition to the arguments you've used already MIGHT do
the trick.

This argument will be passed to  empinf() and it ought
to guarantee that the method  empinf.reg() is used.  That
method looks as though it will tolerate NAs.  I've never
used any of this stuff, so I don't know.  I'm just looking
at the function definitions for  bca.ci(), empinf() and
empinf.reg(), inf.jack(), usual.jack(), positive.jack().
These last four functions are called by  empinf() under
various conditions.

For more details, I encourage you to look at the function
definitions yourself, and try to trace exactly which ones
will be called for the particular set of arguments you are
using.  To see a function definition, type the name of the
function at the command prompt without any parentheses ()
after the function name.

It's quite possible that you are testing the package with
a combination of arguments that has never been used before,
and that some default setting isn't quite doing its job.
I'm afraid I will leave the more detailed investigation to
you.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Thu, 24 Apr 2003, Katalin  Csillery wrote:

> Dear All,
>
> I am trying to use the bca.ci function on a boot.out object
> which consists a few NaN's and I want to ignore those NaN's,
> and get a ci only for the "normal" values.
>
> boot.out$t has R number of values for 3000 different statistics,
> so when I use boot.ci(boot.out, index=i) and i happens to be a
> column in boot.out$t with some NaN's in there I get an error
> message. I tried na.omit for the problematic columns, but bca.ci
> needs a boot.out object so I cannot feed in a single column.
> The number of NaN's varies, and for some statistics
> there isn't any.
>
> Interestingly the standard errors that the boot() calculates
> and returns there is an automatic NA exclusion.
>
> (A side question, in S+ the se's are saved in boot.out$statistics$SE, but
> in R boot.out I couldn't find them. Are they saved somewhere in boot.out?)
>
> Any idea would be greatly appreaciated!
>
> Kati
> ___
> Katalin Csillery
> Division of Biological Sciences
> University of Montana, Missoula MT 59801
> Phone: 406 243 6106, E-mail: csillery at selway.umt.edu


From jfkincaidsu at netscape.net  Fri Apr 25 01:56:37 2003
From: jfkincaidsu at netscape.net (Joel Kincaid)
Date: Thu, 24 Apr 2003 19:56:37 -0400
Subject: [R] R 1.7.0 (Windows) Crashes After using "Install Package from
 Cran option" within
References: <3EA810E0.7030502@netscape.net>
Message-ID: <3EA879B5.1040803@netscape.net>

I should have added to my previous email that the work around mentioned 
at 2.17(a) does not correct the problem.....
Also as mentioned earlier I can get Rterm to 'work' though I get the 
error messages mentioned earlier.
For instance demo(image) produces the expected results, etc.
My understanding is that now the 'methods' pacakge is loaded by default. 
When I search() in Rterm methods is not present in the path and 
furthermore I get messages to the effect of 'methods' not loaded:

When I first extecuted demo() I get
"warning message:
package methods in options '(defaultpackages)' not found."

so if I issue library(methods)
the package is found....

So the problem seem to be with Rgui and intialization....or me and 
misunderstanding the help,
Cheers,










Joel Kincaid wrote:
> R-Community,
> 
> (System Details at end)
> I recently downloaded R 1.7.0 win95 binaries from
> 
> http://cran.us.r-project.org .
> 
> After installing the program with no hitch  I used the the 'Install 
> Packages from Cran' optinon in the drop down menu from Rgui. (This may 
> be bad form, if so let me know): I selected all paackages to install and 
> everything was fine until the 'dse' package was downloading. There was 
> some error statement (I believe) involving the phrase 'failure to find 
> .lib.loc' . At which point R hung. I closed R and then restarted it and 
> the repeated the process being at dse and continuing to 
> yap....everything was fine. Closed R and then attempted to restart at 
> which point the program hung.
> 
> Uninstalled and then reinstalled R: Repeated process, got a similar 
> problem of the downloading process hanging (though this time on 
> 'fracdiff'' package). Plowed on and Rgui started: However, when I 
> rebooted my computer and attempted to start the Rgui I'm getting the 
> same old problem.
> 
> Interesting enough, while Rgui crashes I can get Rterm to work---However 
> I get the following at startup
> After all of the intial text something to the effect:
> "Error in inherits(x, "factor") :Unimplemented feature in  type2str
> An error occured in collecting methods for function "initialize", 
> perhaps  from C-level dispatch"
> 
> System Details:
> Windows XP (Home Edition) Service Pack 1 Version 2002
> Intel PIII Mobile CPU 1133mherz 384mb ram
> 
> When Rgui crashes there is a filed sent to microsoft I have included the 
> contents of this file in the body of the text below and I'll try to 
> attach the thing as well. If there is more info I can provide, or if 
> something I'm doing is screwing my installation (most probable) please 
> let me know.
> 
> Thanks,
> Joel
> 
> <?xml version="1.0" encoding="UTF-16"?>
> <DATABASE>
> <EXE NAME="SYSTEM INFO" FILTER="GRABMI_FILTER_SYSTEM">
>    <MATCHING_FILE NAME="advapi32.dll" SIZE="558080" 
> CHECKSUM="0x7B6E5DDA" BIN_FILE_VERSION="5.1.2600.1106" 
> BIN_PRODUCT_VERSION="5.1.2600.1106" PRODUCT_VERSION="5.1.2600.1106" 
> FILE_DESCRIPTION="Advanced Windows 32 Base API" COMPANY_NAME="Microsoft 
> Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
> FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
> ORIGINAL_FILENAME="advapi32.dll" INTERNAL_NAME="advapi32.dll" 
> LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
> VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
> VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x9315E" 
> LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
> UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
> UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
> States) [0x409]" />
>    <MATCHING_FILE NAME="gdi32.dll" SIZE="250368" CHECKSUM="0x29850525" 
> BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
> PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="GDI Client DLL" 
> COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
> Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
> ORIGINAL_FILENAME="gdi32" INTERNAL_NAME="gdi32" LEGAL_COPYRIGHT="? 
> Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
> VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
> MODULE_TYPE="WIN32" PE_CHECKSUM="0x4285C" LINKER_VERSION="0x50001" 
> UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
> UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:39" 
> UPTO_LINK_DATE="08/29/2002 10:40:39" VER_LANGUAGE="English (United 
> States) [0x409]" />
>    <MATCHING_FILE NAME="kernel32.dll" SIZE="930304" 
> CHECKSUM="0xCBCCF8A9" BIN_FILE_VERSION="5.1.2600.1106" 
> BIN_PRODUCT_VERSION="5.1.2600.1106" PRODUCT_VERSION="5.1.2600.1106" 
> FILE_DESCRIPTION="Windows NT BASE API Client DLL" 
> COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
> Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
> ORIGINAL_FILENAME="kernel32" INTERNAL_NAME="kernel32" LEGAL_COPYRIGHT="? 
> Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
> VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
> MODULE_TYPE="WIN32" PE_CHECKSUM="0xE7ED3" LINKER_VERSION="0x50001" 
> UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
> UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
> UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
> States) [0x409]" />
>    <MATCHING_FILE NAME="ntdll.dll" SIZE="668672" CHECKSUM="0x2149BD76" 
> BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
> PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="NT Layer DLL" 
> COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
> Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
> ORIGINAL_FILENAME="ntdll.dll" INTERNAL_NAME="ntdll.dll" 
> LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
> VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
> VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0xA92F6" 
> LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
> UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
> UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
> States) [0x409]" />
>    <MATCHING_FILE NAME="ole32.dll" SIZE="1169920" CHECKSUM="0x3E53EB37" 
> BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
> PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="Microsoft OLE for 
> Windows" COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? 
> Windows? Operating System" FILE_VERSION="5.1.2600.1106 
> (xpsp1.020828-1920)" ORIGINAL_FILENAME="OLE32.DLL" 
> INTERNAL_NAME="OLE32.DLL" LEGAL_COPYRIGHT="? Microsoft Corporation. All 
> rights reserved." VERFILEDATEHI="0x0" VERFILEDATELO="0x0" 
> VERFILEOS="0x40004" VERFILETYPE="0x2" MODULE_TYPE="WIN32" 
> PE_CHECKSUM="0x121E6B" LINKER_VERSION="0x50001" 
> UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
> UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:34" 
> UPTO_LINK_DATE="08/29/2002 10:40:34" VER_LANGUAGE="English (United 
> States) [0x409]" />
>    <MATCHING_FILE NAME="oleaut32.dll" SIZE="569344" 
> CHECKSUM="0x276CFFB1" BIN_FILE_VERSION="3.50.5016.0" 
> BIN_PRODUCT_VERSION="3.50.5016.0" PRODUCT_VERSION="3.50.5016.0" 
> FILE_DESCRIPTION="Microsoft OLE 3.50  for Windows NT(TM) and Windows 
> 95(TM) Operating Systems" COMPANY_NAME="Microsoft Corporation" 
> PRODUCT_NAME="Microsoft OLE 3.50  for Windows NT(TM) and Windows 95(TM) 
> Operating Systems" FILE_VERSION="3.50.5016.0" 
> INTERNAL_NAME="OLEAUT32.DLL" LEGAL_COPYRIGHT="Copyright ? Microsoft 
> Corp. 1993-1999." VERFILEDATEHI="0x0" VERFILEDATELO="0x0" 
> VERFILEOS="0x40004" VERFILETYPE="0x2" MODULE_TYPE="WIN32" 
> PE_CHECKSUM="0x999AF" LINKER_VERSION="0x0" 
> UPTO_BIN_FILE_VERSION="3.50.5016.0" 
> UPTO_BIN_PRODUCT_VERSION="3.50.5016.0" LINK_DATE="08/29/2002 10:40:34" 
> UPTO_LINK_DATE="08/29/2002 10:40:34" VER_LANGUAGE="English (United 
> States) [0x409]" />
>    <MATCHING_FILE NAME="shell32.dll" SIZE="8336384" 
> CHECKSUM="0x1220BF03" BIN_FILE_VERSION="6.0.2800.1106" 
> BIN_PRODUCT_VERSION="6.0.2800.1106" PRODUCT_VERSION="6.00.2800.1106" 
> FILE_DESCRIPTION="Windows Shell Common Dll" COMPANY_NAME="Microsoft 
> Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
> FILE_VERSION="6.00.2800.1106 (xpsp1.020828-1920)" 
> ORIGINAL_FILENAME="SHELL32.DLL" INTERNAL_NAME="SHELL32" 
> LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
> VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
> VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x7F8609" 
> LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="6.0.2800.1106" 
> UPTO_BIN_PRODUCT_VERSION="6.0.2800.1106" LINK_DATE="08/29/2002 10:40:35" 
> UPTO_LINK_DATE="08/29/2002 10:40:35" VER_LANGUAGE="English (United 
> States) [0x409]" />
>    <MATCHING_FILE NAME="user32.dll" SIZE="560128" CHECKSUM="0x200CFDED" 
> BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
> PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="Windows XP USER API 
> Client DLL" COMPANY_NAME="Microsoft Corporation" 
> PRODUCT_NAME="Microsoft? Windows? Operating System" 
> FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
> ORIGINAL_FILENAME="user32" INTERNAL_NAME="user32" LEGAL_COPYRIGHT="? 
> Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
> VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
> MODULE_TYPE="WIN32" PE_CHECKSUM="0x936BC" LINKER_VERSION="0x50001" 
> UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
> UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
> UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
> States) [0x409]" />
>    <MATCHING_FILE NAME="wininet.dll" SIZE="599040" CHECKSUM="0xBEF20B21" 
> BIN_FILE_VERSION="6.0.2800.1106" BIN_PRODUCT_VERSION="6.0.2800.1106" 
> PRODUCT_VERSION="6.00.2800.1106" FILE_DESCRIPTION="Internet Extensions 
> for Win32" COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? 
> Windows? Operating System" FILE_VERSION="6.00.2800.1106 
> (xpsp1.020828-1920)" ORIGINAL_FILENAME="wininet.dll" 
> INTERNAL_NAME="wininet.dll" LEGAL_COPYRIGHT="? Microsoft Corporation. 
> All rights reserved." VERFILEDATEHI="0x0" VERFILEDATELO="0x0" 
> VERFILEOS="0x40004" VERFILETYPE="0x2" MODULE_TYPE="WIN32" 
> PE_CHECKSUM="0x96179" LINKER_VERSION="0x50001" 
> UPTO_BIN_FILE_VERSION="6.0.2800.1106" 
> UPTO_BIN_PRODUCT_VERSION="6.0.2800.1106" LINK_DATE="08/29/2002 10:40:28" 
> UPTO_LINK_DATE="08/29/2002 10:40:28" VER_LANGUAGE="English (United 
> States) [0x409]" />
>    <MATCHING_FILE NAME="winsock.dll" SIZE="2864" CHECKSUM="0x73AE8088" 
> BIN_FILE_VERSION="3.10.0.103" BIN_PRODUCT_VERSION="3.10.0.103" 
> PRODUCT_VERSION="3.10" FILE_DESCRIPTION="Windows Socket 16-Bit DLL" 
> COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? 
> Windows(TM) Operating System" FILE_VERSION="3.10" 
> ORIGINAL_FILENAME="WINSOCK.DLL" INTERNAL_NAME="WINSOCK" 
> LEGAL_COPYRIGHT="Copyright ? Microsoft Corp. 1981-1996" 
> VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x10001" 
> VERFILETYPE="0x2" MODULE_TYPE="WIN16" S16BIT_DESCRIPTION="BSD Socket API 
> for Windows" S16BIT_MODULE_NAME="WINSOCK" 
> UPTO_BIN_FILE_VERSION="3.10.0.103" UPTO_BIN_PRODUCT_VERSION="3.10.0.103" 
> VER_LANGUAGE="English (United States) [0x409]" />
> </EXE>
> </DATABASE>
> 
> 
> 
> ??<?xml version="1.0" encoding="UTF-16"?>
> 
> <DATABASE>
> 
> <EXE NAME="SYSTEM INFO" FILTER="GRABMI_FILTER_SYSTEM">
> 
>     <MATCHING_FILE NAME="advapi32.dll" SIZE="558080" 
> CHECKSUM="0x7B6E5DDA" BIN_FILE_VERSION="5.1.2600.1106" 
> BIN_PRODUCT_VERSION="5.1.2600.1106" PRODUCT_VERSION="5.1.2600.1106" 
> FILE_DESCRIPTION="Advanced Windows 32 Base API" COMPANY_NAME="Microsoft 
> Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
> FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
> ORIGINAL_FILENAME="advapi32.dll" INTERNAL_NAME="advapi32.dll" 
> LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
> VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
> VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x9315E" 
> LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
> UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
> UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
> States) [0x409]" />
> 
>     <MATCHING_FILE NAME="gdi32.dll" SIZE="250368" CHECKSUM="0x29850525" 
> BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
> PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="GDI Client DLL" 
> COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
> Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
> ORIGINAL_FILENAME="gdi32" INTERNAL_NAME="gdi32" LEGAL_COPYRIGHT="? 
> Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
> VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
> MODULE_TYPE="WIN32" PE_CHECKSUM="0x4285C" LINKER_VERSION="0x50001" 
> UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
> UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:39" 
> UPTO_LINK_DATE="08/29/2002 10:40:39" VER_LANGUAGE="English (United 
> States) [0x409]" />
> 
>     <MATCHING_FILE NAME="kernel32.dll" SIZE="930304" 
> CHECKSUM="0xCBCCF8A9" BIN_FILE_VERSION="5.1.2600.1106" 
> BIN_PRODUCT_VERSION="5.1.2600.1106" PRODUCT_VERSION="5.1.2600.1106" 
> FILE_DESCRIPTION="Windows NT BASE API Client DLL" 
> COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
> Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
> ORIGINAL_FILENAME="kernel32" INTERNAL_NAME="kernel32" LEGAL_COPYRIGHT="? 
> Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
> VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
> MODULE_TYPE="WIN32" PE_CHECKSUM="0xE7ED3" LINKER_VERSION="0x50001" 
> UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
> UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
> UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
> States) [0x409]" />
> 
>     <MATCHING_FILE NAME="ntdll.dll" SIZE="668672" CHECKSUM="0x2149BD76" 
> BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
> PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="NT Layer DLL" 
> COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? Windows? 
> Operating System" FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
> ORIGINAL_FILENAME="ntdll.dll" INTERNAL_NAME="ntdll.dll" 
> LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
> VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
> VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0xA92F6" 
> LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
> UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
> UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
> States) [0x409]" />
> 
>     <MATCHING_FILE NAME="ole32.dll" SIZE="1169920" CHECKSUM="0x3E53EB37" 
> BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
> PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="Microsoft OLE for 
> Windows" COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? 
> Windows? Operating System" FILE_VERSION="5.1.2600.1106 
> (xpsp1.020828-1920)" ORIGINAL_FILENAME="OLE32.DLL" 
> INTERNAL_NAME="OLE32.DLL" LEGAL_COPYRIGHT="? Microsoft Corporation. All 
> rights reserved." VERFILEDATEHI="0x0" VERFILEDATELO="0x0" 
> VERFILEOS="0x40004" VERFILETYPE="0x2" MODULE_TYPE="WIN32" 
> PE_CHECKSUM="0x121E6B" LINKER_VERSION="0x50001" 
> UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
> UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:34" 
> UPTO_LINK_DATE="08/29/2002 10:40:34" VER_LANGUAGE="English (United 
> States) [0x409]" />
> 
>     <MATCHING_FILE NAME="oleaut32.dll" SIZE="569344" 
> CHECKSUM="0x276CFFB1" BIN_FILE_VERSION="3.50.5016.0" 
> BIN_PRODUCT_VERSION="3.50.5016.0" PRODUCT_VERSION="3.50.5016.0" 
> FILE_DESCRIPTION="Microsoft OLE 3.50  for Windows NT(TM) and Windows 
> 95(TM) Operating Systems" COMPANY_NAME="Microsoft Corporation" 
> PRODUCT_NAME="Microsoft OLE 3.50  for Windows NT(TM) and Windows 95(TM) 
> Operating Systems" FILE_VERSION="3.50.5016.0" 
> INTERNAL_NAME="OLEAUT32.DLL" LEGAL_COPYRIGHT="Copyright ? Microsoft 
> Corp. 1993-1999." VERFILEDATEHI="0x0" VERFILEDATELO="0x0" 
> VERFILEOS="0x40004" VERFILETYPE="0x2" MODULE_TYPE="WIN32" 
> PE_CHECKSUM="0x999AF" LINKER_VERSION="0x0" 
> UPTO_BIN_FILE_VERSION="3.50.5016.0" 
> UPTO_BIN_PRODUCT_VERSION="3.50.5016.0" LINK_DATE="08/29/2002 10:40:34" 
> UPTO_LINK_DATE="08/29/2002 10:40:34" VER_LANGUAGE="English (United 
> States) [0x409]" />
> 
>     <MATCHING_FILE NAME="shell32.dll" SIZE="8336384" 
> CHECKSUM="0x1220BF03" BIN_FILE_VERSION="6.0.2800.1106" 
> BIN_PRODUCT_VERSION="6.0.2800.1106" PRODUCT_VERSION="6.00.2800.1106" 
> FILE_DESCRIPTION="Windows Shell Common Dll" COMPANY_NAME="Microsoft 
> Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
> FILE_VERSION="6.00.2800.1106 (xpsp1.020828-1920)" 
> ORIGINAL_FILENAME="SHELL32.DLL" INTERNAL_NAME="SHELL32" 
> LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
> VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
> VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x7F8609" 
> LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="6.0.2800.1106" 
> UPTO_BIN_PRODUCT_VERSION="6.0.2800.1106" LINK_DATE="08/29/2002 10:40:35" 
> UPTO_LINK_DATE="08/29/2002 10:40:35" VER_LANGUAGE="English (United 
> States) [0x409]" />
> 
>     <MATCHING_FILE NAME="user32.dll" SIZE="560128" CHECKSUM="0x200CFDED" 
> BIN_FILE_VERSION="5.1.2600.1106" BIN_PRODUCT_VERSION="5.1.2600.1106" 
> PRODUCT_VERSION="5.1.2600.1106" FILE_DESCRIPTION="Windows XP USER API 
> Client DLL" COMPANY_NAME="Microsoft Corporation" 
> PRODUCT_NAME="Microsoft? Windows? Operating System" 
> FILE_VERSION="5.1.2600.1106 (xpsp1.020828-1920)" 
> ORIGINAL_FILENAME="user32" INTERNAL_NAME="user32" LEGAL_COPYRIGHT="? 
> Microsoft Corporation. All rights reserved." VERFILEDATEHI="0x0" 
> VERFILEDATELO="0x0" VERFILEOS="0x40004" VERFILETYPE="0x2" 
> MODULE_TYPE="WIN32" PE_CHECKSUM="0x936BC" LINKER_VERSION="0x50001" 
> UPTO_BIN_FILE_VERSION="5.1.2600.1106" 
> UPTO_BIN_PRODUCT_VERSION="5.1.2600.1106" LINK_DATE="08/29/2002 10:40:40" 
> UPTO_LINK_DATE="08/29/2002 10:40:40" VER_LANGUAGE="English (United 
> States) [0x409]" />
> 
>     <MATCHING_FILE NAME="wininet.dll" SIZE="599040" 
> CHECKSUM="0xBEF20B21" BIN_FILE_VERSION="6.0.2800.1106" 
> BIN_PRODUCT_VERSION="6.0.2800.1106" PRODUCT_VERSION="6.00.2800.1106" 
> FILE_DESCRIPTION="Internet Extensions for Win32" COMPANY_NAME="Microsoft 
> Corporation" PRODUCT_NAME="Microsoft? Windows? Operating System" 
> FILE_VERSION="6.00.2800.1106 (xpsp1.020828-1920)" 
> ORIGINAL_FILENAME="wininet.dll" INTERNAL_NAME="wininet.dll" 
> LEGAL_COPYRIGHT="? Microsoft Corporation. All rights reserved." 
> VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x40004" 
> VERFILETYPE="0x2" MODULE_TYPE="WIN32" PE_CHECKSUM="0x96179" 
> LINKER_VERSION="0x50001" UPTO_BIN_FILE_VERSION="6.0.2800.1106" 
> UPTO_BIN_PRODUCT_VERSION="6.0.2800.1106" LINK_DATE="08/29/2002 10:40:28" 
> UPTO_LINK_DATE="08/29/2002 10:40:28" VER_LANGUAGE="English (United 
> States) [0x409]" />
> 
>     <MATCHING_FILE NAME="winsock.dll" SIZE="2864" CHECKSUM="0x73AE8088" 
> BIN_FILE_VERSION="3.10.0.103" BIN_PRODUCT_VERSION="3.10.0.103" 
> PRODUCT_VERSION="3.10" FILE_DESCRIPTION="Windows Socket 16-Bit DLL" 
> COMPANY_NAME="Microsoft Corporation" PRODUCT_NAME="Microsoft? 
> Windows(TM) Operating System" FILE_VERSION="3.10" 
> ORIGINAL_FILENAME="WINSOCK.DLL" INTERNAL_NAME="WINSOCK" 
> LEGAL_COPYRIGHT="Copyright ? Microsoft Corp. 1981-1996" 
> VERFILEDATEHI="0x0" VERFILEDATELO="0x0" VERFILEOS="0x10001" 
> VERFILETYPE="0x2" MODULE_TYPE="WIN16" S16BIT_DESCRIPTION="BSD Socket API 
> for Windows" S16BIT_MODULE_NAME="WINSOCK" 
> UPTO_BIN_FILE_VERSION="3.10.0.103" UPTO_BIN_PRODUCT_VERSION="3.10.0.103" 
> VER_LANGUAGE="English (United States) [0x409]" />
> 
> </EXE>
> 
> </DATABASE>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 


-- 
Your favorite stores, helpful shopping tools and great gift ideas.
Experience the convenience of buying online with Shop at Netscape!
http://shopnow.netscape.com/


From dmurdoch at pair.com  Fri Apr 25 03:04:37 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Thu, 24 Apr 2003 21:04:37 -0400
Subject: [R] R 1.7.0 (Windows) Crashes After using "Install Package from
	Cran option" within
In-Reply-To: <3EA879B5.1040803@netscape.net>
References: <3EA810E0.7030502@netscape.net> <3EA879B5.1040803@netscape.net>
Message-ID: <lm1havs37uljt9pf6um8j5ckh5albgf94r@4ax.com>

On Thu, 24 Apr 2003 19:56:37 -0400, you wrote:

>I should have added to my previous email that the work around mentioned 
>at 2.17(a) does not correct the problem.....

What is 2.17(a)??

>Also as mentioned earlier I can get Rterm to 'work' though I get the 
>error messages mentioned earlier.
>For instance demo(image) produces the expected results, etc.
>My understanding is that now the 'methods' pacakge is loaded by default. 

Yes, it should be.

>When I search() in Rterm methods is not present in the path and 
>furthermore I get messages to the effect of 'methods' not loaded:
>
>When I first extecuted demo() I get
>"warning message:
>package methods in options '(defaultpackages)' not found."

That's a sign that there is something wrong with your installation.
If you look in the R home directory, do you see a subdirectory called
library/methods?

>> 
>> After installing the program with no hitch  I used the the 'Install 
>> Packages from Cran' optinon in the drop down menu from Rgui. (This may 
>> be bad form, if so let me know): I selected all paackages to install and 
>> everything was fine until the 'dse' package was downloading. 

It's probably not a good idea to install all of the packages that are
available 
 - it uses a lot of bandwidth to CRAN (unless you've chosen a mirror
closer to you)
 - it uses a lot of your disk space
 - it gives you lots of hits whenever you do a search for help -
you'll find way more than is useful.

But it should work (except that it will fail on dse, unless you're
using the patched version of 1.7.0, along with a not-yet-available
repackaging of dse).  However, the fact that methods is missing from
your installation indicates you've got serious problems.

>> <?xml version="1.0" encoding="UTF-16"?>
>> <DATABASE>
>> <EXE NAME="SYSTEM INFO" FILTER="GRABMI_FILTER_SYSTEM">
>>    <MATCHING_FILE NAME="advapi32.dll" SIZE="558080" 

Most of this information isn't any use.  If you have DrWatson or a
similar crash analyzer, there may be a few lines of useful information
(e.g. the location of the instruction pointer at the time of the
crash), but mostly it's not all that helpful.  Easily executed
instructions for reproducing the crash are the most useful information
you can give.

Duncan Murdoch


From apjaworski at mmm.com  Fri Apr 25 03:38:19 2003
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Thu, 24 Apr 2003 20:38:19 -0500
Subject: [R] tcltk tkfilefind demo problem
Message-ID: <OFDCE0315C.9015B5D9-ON86256D13.00080E23@mmm.com>

Hi everyone,

I wonder if anybody observed the crash of the tkfilefind demo.  I looked
into the code and it seems to crash executing

        dirtree<-tkwidget(base, "hierarchy_dir",
                          root=path,
                          showparent="Parent",
                          showfiles=1,
                          showall=all.names,
                          selectmode=if(multiple) "multiple" else "browse")

with the following error message

Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class
= "tclObj") :
        [tcl] megawidget initialization error: expected integer but got "
--1".


I have a fresh binary install of 1.7.0 on Win2000 machine.  I observed this
behavior with the Tcl library included with R and with ActiveTcl 8.4.2 I
just installed.  I think I have it set-up correctly: my TCL_LIBRARY and
MY_TCLTK both point to c:/Tcl where I installed ActiveTcl.  I also have
c:/Tcl/bin on my path - to avoid possible interference with cygwin Tcl I
have the following in my Rprofile:

      Sys.putenv("Path"="c:/Tcl/bin;c:/cygwin/bin")

I can run the other demos successfully.  I also just ran all the examples
posted recently by James Wettenhall with no problems.

Any comments will be welcome.  Thanks in advance,

Andy

__________________________________
Andy Jaworski
Engineering Systems Technology Center
3M Center, 518-1-01
St. Paul, MN 55144-1000
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


From jfkincaidsu at netscape.net  Fri Apr 25 03:58:42 2003
From: jfkincaidsu at netscape.net (Joel Kincaid)
Date: Thu, 24 Apr 2003 21:58:42 -0400
Subject: [R] R 1.7.0 (Windows) Crashes After using "Install Package from
 Cran option" within
References: <3EA810E0.7030502@netscape.net> <3EA879B5.1040803@netscape.net>
	<lm1havs37uljt9pf6um8j5ckh5albgf94r@4ax.com>
Message-ID: <3EA89652.5070707@netscape.net>



dmurdoch at pair.com wrote:
> On Thu, 24 Apr 2003 19:56:37 -0400, you wrote:
> 
> 
>>I should have added to my previous email that the work around mentioned 
>>at 2.17(a) does not correct the problem.....
> 
> 
> What is 2.17(a)??
Sorry: in the R faq for windows port installed with R1.7.0 and reaD in a 
browser generated from help.start() in Rterm is sectioned as
2.17 -- downloading files,
two options exist--a and b. I've tried (a) (using internet2.dll) and I'm 
  still trying to figure out (b).

>>When I search() in Rterm methods is not present in the path and 
>>furthermore I get messages to the effect of 'methods' not loaded:
>>
>>When I first extecuted demo() I get
>>"warning message:
>>package methods in options '(defaultpackages)' not found."
> That's a sign that there is something wrong with your installation.
> If you look in the R home directory, do you see a subdirectory called
> library/methods?
YES:    indeed if i call 'library(methods)' the package is loaded. If I 
then call demon() again -- I get no error message.

>>>After installing the program with no hitch  I used the the 'Install 
>>>Packages from Cran' optinon in the drop down menu from Rgui. (This may 
>>>be bad form, if so let me know): I selected all paackages to install and 
>>>everything was fine until the 'dse' package was downloading. 
>>
> 
> It's probably not a good idea to install all of the packages that are
> available 
>  - it uses a lot of bandwidth to CRAN (unless you've chosen a mirror
> closer to you)
>  - it uses a lot of your disk space
>  - it gives you lots of hits whenever you do a search for help -
> you'll find way more than is useful.
> 
> But it should work (except that it will fail on dse, unless you're
> using the patched version of 1.7.0, along with a not-yet-available
> repackaging of dse).  However, the fact that methods is missing from
> your installation indicates you've got serious problems.
> 
Yes I used a mirror and I'm a bit of a packrat (and the marginal cost 
---to me--of an additional MB of storage is zero (and this is true 
unforuntaly of bandwidth too).

> Most of this information isn't any use.  If you have DrWatson or a
> similar crash analyzer, there may be a few lines of useful information
> (e.g. the location of the instruction pointer at the time of the
> crash), but mostly it's not all that helpful.  Easily executed
> instructions for reproducing the crash are the most useful information
> you can give.
> 
> Duncan Murdoch

I'll try to dig up dr watson and see what I get. But the odd thing is 
that Rgui works when intally installed: it just failed after I try 
grabbing all of the packages.

In terms of reproducing the results (I've done this twice with the same 
results)
1. download and install the 21 MB file (from a mirror close to you),
2. bring Rgui up
3. ---works like a charm
4. gunk up the works by trying to (from the menu) install all pacakges.
5. wait for this to hang.
6. upon hanging, exit Rgui
7. try to start-up
8. finish installing all pacakges (again from menu)
9. exit Rgui
10. try to restart Rgui---it should then fail to load.

can the process of hanging and then using having give the three finger 
salute be corrupting some file????

thanks for taking the time to look into this,
joel


From sdfrost at ucsd.edu  Fri Apr 25 04:43:45 2003
From: sdfrost at ucsd.edu (Simon Frost)
Date: Thu, 24 Apr 2003 19:43:45 -0700
Subject: [R] Bivariate lme
Message-ID: <5.1.0.14.0.20030424193911.01ed1ef0@popmail.ucsd.edu>

Dear R Help,

Does anyone know off-hand the syntax for a bivariate (two-outcome) lme? 
It's straightforward to fit a standard random-intercept random-slope model 
to each of the two outcome variables:

lme(Y~X,random=list(ID=~X)...)
lme(Z~X,random=list(ID~X)...)

But it would be nice to fit the data (Y,Z) against X so that I can obtain 
estimates of the correlation between the slopes and the intercepts; the 
measurement errors are also different, so I'd need to use weights as well.

On a slightly more advanced level, let's assume that there is no 
correlation between the intercept and the slope for the two outcome 
variables, but that fluctuations about a linear trend are correlated. What 
kinds of techniques can be used to estimate the correlation in fluctuations?

Best
Simon

Simon D.W. Frost, M.A., D.Phil.
Department of Pathology
University of California, San Diego
Antiviral Research Center
150 W. Washington St., Suite 100
San Diego, CA 92103
USA

Tel: +1 619 543 8080 x275
Fax: +1 619 298 0177
Email: sdfrost at ucsd.edu

The information transmitted in this e-mail is intended only for the
person(s) or entity to which it is addressed and may contain
CONFIDENTIAL and/or privileged material. Any review, re-transmission,
dissemination or other use of or taking of any action in reliance upon
this information by persons or entities other than the intended
recipient is prohibited. If you received this e-mail in error, please
contact the sender and delete/destroy the material/information from any
computer.


From spencer.graves at pdf.com  Fri Apr 25 06:21:58 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 24 Apr 2003 21:21:58 -0700
Subject: [R] Matrix Equation Help?
References: <006001c30a84$0888cdd0$8bd75ba5@IE.TAMU.EDU>
	<3EA828EC.2060101@statistik.uni-dortmund.de>
Message-ID: <3EA8B7E6.3000709@pdf.com>

If n>>m, then solve does not work.  Consider:

 > A <- array(1:6, dim=c(2,3))
 > B <- array(1:4, dim=c(2,2))
 > solve(A, B)
Error in solve.default(A, B) : singular matrix `a' in solve

In this case, we have 6 = 3 x 2 unknowns but only 4 equations.

It raises questions about what you mean by solve.  S-Plus 2000 and 6 
have "ginverse" that will produce an answer.  You can construct such 
using "qr" or "svd".

However, before coding that, I will ask, what do you mean by "solve"?

hth.  spencer graves

Uwe Ligges wrote:
> Feng Zhang wrote:
> 
>> Dear R-listers
>>
>> Now I have a Matrix Equation to solve,
>> A -- m by n matrix, where n>>m, known matrix;
>> X -- n by m unknown matrix;
>> B -- m by m known matrix.
>>
>> So given the equation A*X=B, how to solve X?
> 
> 
> You already mentioned it:
> ?solve
> 
> Uwe Ligges
> 
>> I first tried to take X = inv((A'*A))*A'. But since
>> A'*A is singular, this is no way to go.
>>
>> Please give me some point on this.
>> Thanks
>>
>> Fred
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From uth at zhwin.ch  Fri Apr 25 09:33:40 2003
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Fri, 25 Apr 2003 09:33:40 +0200
Subject: [R] R TclTk Examples
Message-ID: <6A4BCEF0FD65344A8F496D7E520DD8B902C36105@lobster.zhwin.ch>

Great Examples!!

I was looking for exactly some exaples like you did.

Thanks a lot

(I haven't yet study the code)



Thomas Untern?hrer                               E-Mail:  thomas.unternaehrer at zhwin.ch
Institut f?r Datenanalyse und Prozessdesign      Tel:     052/ 267 7813
Z?rcher Hochschule Winterthur                    Fax:     052/ 268 7813
Technopark / J?gerstrasse 2 
Postfach
CH-8400 Winterthur                               http://www.idp.zhwin.ch


From sandrine.mainard1 at etud.univ-ubs.fr  Fri Apr 25 09:48:24 2003
From: sandrine.mainard1 at etud.univ-ubs.fr (sandrine.mainard1@etud.univ-ubs.fr)
Date: Fri, 25 Apr 2003 09:48:24 +0200
Subject: [R] About qvalue
Message-ID: <1051256904.3ea8e8489be59@homae.univ-ubs.fr>

Hello, 

I'm apologize to have made failure before. 
I wrote this : p<-scan("teststat.txt") on R and R returns Error in scan 
("teststat.txt") : "scan" expected a real, got "x". I don't really 
understand,because teststat has been created, so........ 

Thanks a lot. 

Sandrine 










--------------------------------------------------------------------------------
Universit de Bretagne sud                               http://www.univ-ubs.fr/


From p.dalgaard at biostat.ku.dk  Fri Apr 25 10:44:19 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 25 Apr 2003 10:44:19 +0200
Subject: [R] tcltk tkfilefind demo problem
In-Reply-To: <OFDCE0315C.9015B5D9-ON86256D13.00080E23@mmm.com>
References: <OFDCE0315C.9015B5D9-ON86256D13.00080E23@mmm.com>
Message-ID: <x2fzo7t198.fsf@biostat.ku.dk>

apjaworski at mmm.com writes:

> Hi everyone,
> 
> I wonder if anybody observed the crash of the tkfilefind demo.  I looked
> into the code and it seems to crash executing
> 
>         dirtree<-tkwidget(base, "hierarchy_dir",
>                           root=path,
>                           showparent="Parent",
>                           showfiles=1,
>                           showall=all.names,
>                           selectmode=if(multiple) "multiple" else "browse")
> 
> with the following error message
> 
> Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class
> = "tclObj") :
>         [tcl] megawidget initialization error: expected integer but got "
> --1".
> 
> 
> I have a fresh binary install of 1.7.0 on Win2000 machine.  I observed this
> behavior with the Tcl library included with R and with ActiveTcl 8.4.2 I
> just installed.  I think I have it set-up correctly: my TCL_LIBRARY and
> MY_TCLTK both point to c:/Tcl where I installed ActiveTcl.  I also have
> c:/Tcl/bin on my path - to avoid possible interference with cygwin Tcl I
> have the following in my Rprofile:
> 
>       Sys.putenv("Path"="c:/Tcl/bin;c:/cygwin/bin")
> 
> I can run the other demos successfully.  I also just ran all the examples
> posted recently by James Wettenhall with no problems.
> 
> Any comments will be welcome.  Thanks in advance,

I have two systems, both RH8 with RPM installs of R-1.7.0, and see a
similar error on only one of them... On the system where it breaks, it
works after changing directory, so I suspect the code is not resilient
to weird filenames (I found a "!lpr" file).

The tkfilefind demo is mainly a programming example of how to work
with larger pieces of Tcl code, not an instruction in how to select
files (tkgetOpenFile/tkgetSaveFile do that much better). If the bug is
actually in the internals of the not very good megawidget, I'd be
loath to spend time in trying to fix it. This could be a bug that
needs fixing in the veterinarian sense... (i.e. by removal of the
demo).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From brostaux.y at fsagx.ac.be  Fri Apr 25 10:48:47 2003
From: brostaux.y at fsagx.ac.be (Yves Brostaux)
Date: Fri, 25 Apr 2003 10:48:47 +0200
Subject: [R] R compilation problem on Sun Solaris 2.5.1
Message-ID: <5.1.0.14.1.20030425103728.00af8870@fusamail.fsagx.ac.be>

Dear members,

I'm not very used with Unix systems, but I got an old Sun/UltraSparc 
workstation running Solaris 2.5.1 and I tried to install R on it to able 
able to do some batch R processing while working on my pc.

I downloaded and installed following required and recommanded programs 
before installing R : perl 5.8.0, readline 4.3, gzip 1.3.5, zlib 1.1.4, 
make 3.80, jpeg 6b, libpng 1.2.4 and gcc 3.2.

I downloaded and unpacked R-1.7.0.tgz to /usr/src and ran
 > ./configure --prefix=/usr/local
 > make

During make execution, I get following error :

initializing class and method definition now... done
Error in gzfile (file, "wb"): unable to open connection
In addition: Warning message:
cannot open compressed file 'usr/share/src/R-1.7.0/library/methods/R/all.rda'
Execution halted

Does anybody know what mistake I made ? Thanks in advance,

-- 
Ir. Yves Brostaux - Statistics and Computer Science Dpt.
Gembloux Agricultural University
8, avenue de la Facult? B-5030 Gembloux (Belgium)
T?l : +32 (0)81 62 24 69
E-mail : brostaux.y at fsagx.ac.be
Web : http://www.fsagx.ac.be/si/


From ozric at web.de  Fri Apr 25 11:04:58 2003
From: ozric at web.de (Christian Schulz)
Date: Fri, 25 Apr 2003 11:04:58 +0200
Subject: [R] sjava w2k
Message-ID: <000401c30b1b$ba3eb480$7800ebd9@pc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030425/6f46640d/attachment.pl

From andreww at cheque.uq.edu.au  Fri Apr 25 13:26:50 2003
From: andreww at cheque.uq.edu.au (Andrew C. Ward)
Date: Fri, 25 Apr 2003 21:26:50 +1000
Subject: [R] sjava w2k
References: <000401c30b1b$ba3eb480$7800ebd9@pc>
Message-ID: <002601c30b1d$93df2de0$6ce86682@hansw>

Christian, this may occur if the environment variable JAVA_HOME is not set.
Windows help ("environment variables, adding") explains how to do this.

Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au

----- Original Message ----- 
From: "Christian Schulz" <ozric at web.de>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, April 25, 2003 7:04 PM
Subject: [R] sjava w2k


> ..sorry for this "repeated" off-topic question, but i look
> for any suggestion in the manuals, find nothing related?
>
> library(Sjava)
> Error in firstlib(which.lib.loc, package) :
>         JAVA_HOME is not set
> Error in library(Sjava) : .First.lib failed
>
> ...what i have to done?
>
>
>
> many thanks & regards,christian
>
>
>
"C:\\WINNT\\system32\\os2\\dll;"
>
Path
>
"C:\\latex\\texmf\\miktex\\bin\\;C:\\server\\cvs;C:\\server\\perl\\bin;C:\\s
erver\\apache\\php;C:\\server\\mysql\\bin;C:\\WINNT\\system32;C:\\WINNT;C:\\
WINNT\\System32\\Wbem;C:\\chris\\Tcl\\bin;C:\\chris\\dm\\SUPERQ~1;c:\\chris\
\dm\\rw1070\\library\\Sjava\\libs;"
>
PATHEXT
>

".COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH"
>
PROCESSOR_ARCHITECTURE
>
"x86"
>
PROCESSOR_IDENTIFIER
>
"x86 Family 6 Model 7 Stepping 1, AuthenticAMD"
>
PROCESSOR_LEVEL
>
"6"
>
PROCESSOR_REVISION
>
"0701"
>
ProgramFiles
>
"C:\\Programme"
>
R_HOME
>
"C:\\chris\\dm\\rw1070"
>
R_USER
>
"C:"
>
                                                 SystemDrive
>
"C:"
>
SystemRoot
>
"C:\\WINNT"
>
TCL_LIBRARY
>
"C:\\chris\\dm\\rw1070/Tcl/lib/tcl8.4"
>
>
>
> [[alternate HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From V.Khamenia at BioVisioN.de  Fri Apr 25 13:31:26 2003
From: V.Khamenia at BioVisioN.de (Khamenia, Valery)
Date: Fri, 25 Apr 2003 13:31:26 +0200
Subject: [R] numericDeriv and ecdf
Message-ID: <D15343265276D31197BC00A024A6C110774008@EXS_BDC>

Hi All,

following expression:

  x <- sort(rnorm(10)); e <- ecdf(x); d <- numericDeriv(e(x),"x");

makes d far from approximation of one dimensional pdf.

What's wrong then here?

Kind regards.
---------------------------------------------------------------------------
Valery A.Khamenya
Bioinformatics Department
BioVisioN AG, Hannover


From ripley at stats.ox.ac.uk  Fri Apr 25 13:35:35 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 25 Apr 2003 12:35:35 +0100 (BST)
Subject: [R] sjava w2k
In-Reply-To: <000401c30b1b$ba3eb480$7800ebd9@pc>
Message-ID: <Pine.LNX.4.44.0304251229290.10000-100000@gannet.stats>

On Fri, 25 Apr 2003, Christian Schulz wrote:

> ..sorry for this "repeated" off-topic question, but i look
> for any suggestion in the manuals, find nothing related?
> 
> library(Sjava)
> Error in firstlib(which.lib.loc, package) : 
>         JAVA_HOME is not set
> Error in library(Sjava) : .First.lib failed
> 
> ...what i have to done?

Set JAVA_HOME!  I am presuming that this is from my build, but you didn't
give the origin.  You probably also need to follow the rest of the
installation instructions in

http://www.stats.ox.ac.uk/pub/bdr/SJava/ReadMe

The essence is

Sjava.zip -- unzip in ...\rw1062\library.  Having installed a Sun Java
JRE from java.sun.com (e.g. j2re-1_4_1_02-windows-i586-i.exe), you need to
set the environment variable JAVA_HOME to point to its top-level
directory.  The simplest way to so this is to create a file .Renviron
in either the working directory or your home directory (see the rw-FAQ)
and insert a line like

JAVA_HOME=c:/Program Files/Java/j2re1.4.1_02

For rw1070 you can (I believe) use install.packages to get the correct 
compiled version of SJava.zip, then set JAVA_HOME as above.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ozric at web.de  Fri Apr 25 13:41:48 2003
From: ozric at web.de (Christian Schulz)
Date: Fri, 25 Apr 2003 13:41:48 +0200
Subject: [R] sjava w2k
References: <000401c30b1b$ba3eb480$7800ebd9@pc>
	<002601c30b1d$93df2de0$6ce86682@hansw>
Message-ID: <000d01c30b1f$a8bf0ad0$1c02ebd9@pc>

andrew,

sorry if i'm "standing on a tube"
I have the possibilities to set path and classpath  environment variables.
Ok , i have a path to my jdk1.4/bin   and  to c:/rw1070/library/sjava/libs
(, the latter  may not necessary?)

...should i set a classpath to something else?
i.e to:
C:/rw1070\library\SJava\org\omegahat\Jars

...i'm try it now!

many thanks & regards,
Christian






----- Original Message -----
From: "Andrew C. Ward" <andreww at cheque.uq.edu.au>
To: "Christian Schulz" <ozric at web.de>; <r-help at stat.math.ethz.ch>
Sent: Friday, April 25, 2003 1:26 PM
Subject: Re: [R] sjava w2k


> Christian, this may occur if the environment variable JAVA_HOME is not
set.
> Windows help ("environment variables, adding") explains how to do this.
>
> Regards,
>
> Andrew C. Ward
>
> CAPE Centre
> Department of Chemical Engineering
> The University of Queensland
> Brisbane Qld 4072 Australia
> andreww at cheque.uq.edu.au
>
> ----- Original Message -----
> From: "Christian Schulz" <ozric at web.de>
> To: <r-help at stat.math.ethz.ch>
> Sent: Friday, April 25, 2003 7:04 PM
> Subject: [R] sjava w2k
>
>
> > ..sorry for this "repeated" off-topic question, but i look
> > for any suggestion in the manuals, find nothing related?
> >
> > library(Sjava)
> > Error in firstlib(which.lib.loc, package) :
> >         JAVA_HOME is not set
> > Error in library(Sjava) : .First.lib failed
> >
> > ...what i have to done?
> >
> >
> >
> > many thanks & regards,christian
> >
> >
> >
> "C:\\WINNT\\system32\\os2\\dll;"
> >
> Path
> >
>
"C:\\latex\\texmf\\miktex\\bin\\;C:\\server\\cvs;C:\\server\\perl\\bin;C:\\s
>
erver\\apache\\php;C:\\server\\mysql\\bin;C:\\WINNT\\system32;C:\\WINNT;C:\\
>
WINNT\\System32\\Wbem;C:\\chris\\Tcl\\bin;C:\\chris\\dm\\SUPERQ~1;c:\\chris\
> \dm\\rw1070\\library\\Sjava\\libs;"
> >
> PATHEXT
> >
>
> ".COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH"
> >
> PROCESSOR_ARCHITECTURE
> >
> "x86"
> >
> PROCESSOR_IDENTIFIER
> >
> "x86 Family 6 Model 7 Stepping 1, AuthenticAMD"
> >
> PROCESSOR_LEVEL
> >
> "6"
> >
> PROCESSOR_REVISION
> >
> "0701"
> >
> ProgramFiles
> >
> "C:\\Programme"
> >
> R_HOME
> >
> "C:\\chris\\dm\\rw1070"
> >
> R_USER
> >
> "C:"
> >
>                                                  SystemDrive
> >
> "C:"
> >
> SystemRoot
> >
> "C:\\WINNT"
> >
> TCL_LIBRARY
> >
> "C:\\chris\\dm\\rw1070/Tcl/lib/tcl8.4"
> >
> >
> >
> > [[alternate HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
>


From uth at zhwin.ch  Fri Apr 25 13:55:39 2003
From: uth at zhwin.ch (=?iso-8859-1?Q?=22Untern=E4hrer_Thomas=2C_uth=22?=)
Date: Fri, 25 Apr 2003 13:55:39 +0200
Subject: [R] Rcmd vs. Rterm.exe
Message-ID: <6A4BCEF0FD65344A8F496D7E520DD8B902C36106@lobster.zhwin.ch>


Hi r-hackers,

What exactly is the difference in call r from a batch between this two ways:

Rterm.exe ...

Rcmd BATCH ... (I have to install perl first, I know)


I haven't found any documentation about the difference (readme, FAQs, ...).
I use rterm.exe, but is there a benefit in using rcmd?

Can you explain me that or give me a link?

Thanks

Thomas



Thomas Untern?hrer                               E-Mail:  thomas.unternaehrer at zhwin.ch
Institut f?r Datenanalyse und Prozessdesign      Tel:     052/ 267 7813
Z?rcher Hochschule Winterthur                    Fax:     052/ 268 7813
Technopark / J?gerstrasse 2 
Postfach
CH-8400 Winterthur                               http://www.idp.zhwin.ch


From bitwrit at ozemail.com.au  Fri Apr 25 14:04:23 2003
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Fri, 25 Apr 2003 22:04:23 +1000
Subject: [R] Detailed contingency tables
Message-ID: <20030425120945.LGRR9300.mta04.mail.mel.aone.net.au@there>

MZodet wrote:
>
> Is there any existing function for creating contingency tables that will
> display counts, row, column, and cell percentages in the same
> tables....anything similar to crosstabs in S? 

You might want to look at xtab() in "Kickstarting R" at:

http://cran.r-project.org

under Contributed Documentation.

Jim


From aknaust at hygiene.uni-wuerzburg.de  Fri Apr 25 14:26:59 2003
From: aknaust at hygiene.uni-wuerzburg.de (Andreas Knaust)
Date: Fri, 25 Apr 2003 14:26:59 +0200
Subject: [R] rotation of names.arg
Message-ID: <3EA92993.4070408@hygiene.uni-wuerzburg.de>

Hallo everybody,

is there a possibility to rotate the strings given with names.arg in a plot?

andreas


From andreww at cheque.uq.edu.au  Fri Apr 25 14:33:07 2003
From: andreww at cheque.uq.edu.au (Andrew C. Ward)
Date: Fri, 25 Apr 2003 22:33:07 +1000
Subject: [R] rotation of names.arg
References: <3EA92993.4070408@hygiene.uni-wuerzburg.de>
Message-ID: <008c01c30b26$d68fffd0$6ce86682@hansw>

Andreas, if I want rotated text I simply use the text() command after I've
done
the plot. For instance

   plot(1:10, 1:10)
   par(srt=45)
   text(5, 6, "I feel strange")
   par(srt=0)
   text(5, 4, "Well, I'm fine")

Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au

----- Original Message ----- 
From: "Andreas Knaust" <aknaust at hygiene.uni-wuerzburg.de>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, April 25, 2003 10:26 PM
Subject: [R] rotation of names.arg


> Hallo everybody,
>
> is there a possibility to rotate the strings given with names.arg in a
plot?
>
> andreas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From sundar.dorai-raj at pdf.com  Fri Apr 25 14:42:54 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri, 25 Apr 2003 07:42:54 -0500
Subject: [R] Matrix Equation Help?
References: <006001c30a84$0888cdd0$8bd75ba5@IE.TAMU.EDU>
	<3EA828EC.2060101@statistik.uni-dortmund.de> <3EA8B7E6.3000709@pdf.com>
Message-ID: <3EA92D4E.5020306@pdf.com>

See also ?ginv in package MASS.

Spencer Graves wrote:
> If n>>m, then solve does not work.  Consider:
> 
>  > A <- array(1:6, dim=c(2,3))
>  > B <- array(1:4, dim=c(2,2))
>  > solve(A, B)
> Error in solve.default(A, B) : singular matrix `a' in solve
> 
> In this case, we have 6 = 3 x 2 unknowns but only 4 equations.
> 
> It raises questions about what you mean by solve.  S-Plus 2000 and 6 
> have "ginverse" that will produce an answer.  You can construct such 
> using "qr" or "svd".
> 
> However, before coding that, I will ask, what do you mean by "solve"?
> 
> hth.  spencer graves
> 
> Uwe Ligges wrote:
> 
>> Feng Zhang wrote:
>>
>>> Dear R-listers
>>>
>>> Now I have a Matrix Equation to solve,
>>> A -- m by n matrix, where n>>m, known matrix;
>>> X -- n by m unknown matrix;
>>> B -- m by m known matrix.
>>>
>>> So given the equation A*X=B, how to solve X?
>>
>>
>>
>> You already mentioned it:
>> ?solve
>>
>> Uwe Ligges
>>
>>> I first tried to take X = inv((A'*A))*A'. But since
>>> A'*A is singular, this is no way to go.
>>>
>>> Please give me some point on this.
>>> Thanks
>>>
>>> Fred
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From roger at ysidro.econ.uiuc.edu  Fri Apr 25 14:53:23 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Fri, 25 Apr 2003 07:53:23 -0500 (CDT)
Subject: [R] make? on Macos 10.2.4
Message-ID: <Pine.SOL.4.30.0304250734420.29960-100000@ysidro.econ.uiuc.edu>

Greetings on A.N. Kolmogorov's 100th birthday:

I am sure that this is a resolved problem, certainly it has been raised in R help
several times before, but I can't seem to find the right clue.  I've recently
upgraded a G4 to OS 10.2.5 and I thought I would have another go at installing
R from source, after failing to accomplish this in 10.1.

So with 1.7.0 from CRAN configure seems to be fine, but make dies with the following

gcc -dynamiclib -install_name /usr/local/lib/R/bin/libRlapack.dylib -L/sw/lib -L/usr/local/lib -o libRlapack.dylib dlapack0.lo dlapack1.lo dlapack2.lo dlapack3.lo cmplx.lo  -lf77blas -latlas -L/sw/lib -L/usr/local/lib -L/sw/lib/gcc-lib/powerpc-apple-darwin6.5/3.1 -L/sw/lib/gcc-lib/powerpc-apple-darwin6.5/3.1/../../.. -lfrtbegin -lg2c -lSystem
ld: common symbols not allowed with MH_DYLIB output format with the -multi_module option
/sw/lib/libg2c.a(err.o) definition of common _f__cblank (size 4)
/sw/lib/libg2c.a(fmt.o) definition of common _f__cnt (size 40)
.
.
[more of this]
.
.
/sw/lib/libg2c.a(err.o) definition of common _f__icptr (size 4)
/sw/lib/libg2c.a(err.o) definition of common f(short, void, int, char) (size 4)
/usr/bin/libtool: internal link edit command failed
make[4]: *** [libRlapack.dylib] Error 1
make[3]: *** [R] Error 2
make[2]: *** [R] Error 1
make[1]: *** [R] Error 1
make: *** [R] Error 1

Configure produces:

R is now configured for powerpc-apple-darwin6.5

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                gcc  -g -O2
  C++ compiler:              g++  -g -O2
  Fortran compiler:          g77  -g -O2

  Interfaces supported:      X11
  External libraries:        BLAS(ATLAS)
  Additional capabilities:   PNG, JPEG, bzip2, PCRE
  Options enabled:           R profiling

  Recommended packages:      yes


And the g77, gcc info is:

rudjer: g77 -v
Reading specs from /sw/lib/gcc-lib/powerpc-apple-darwin6.5/3.1/specs
Configured with: ../gcc3/configure --prefix=/sw --enable-languages=f77 --infodir=${prefix}/share/info
Thread model: single
Apple Computer, Inc. GCC version 1151, based on gcc version 3.1 20020420 (prerelease)
rudjer: gcc -v
Reading specs from /usr/libexec/gcc/darwin/ppc/3.1/specs
Thread model: posix
Apple Computer, Inc. GCC version 1175, based on gcc version 3.1 20020420 (prerelease)

Any suggestions would be most welcome.

Roger

url:	www.econ.uiuc.edu	Roger Koenker		Dept. of Economics UCL,
email	rkoenker at uiuc.edu	Department of Economics Drayton House,
vox: 	217-333-4558		University of Illinois	30 Gordon St,
fax:   	217-244-6678		Champaign, IL 61820	London,WC1H 0AX, UK
							vox:	020-7679-5838


From tblackw at umich.edu  Fri Apr 25 14:55:49 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 25 Apr 2003 08:55:49 -0400 (EDT)
Subject: [R] numericDeriv and ecdf
In-Reply-To: <D15343265276D31197BC00A024A6C110774008@EXS_BDC>
Message-ID: <Pine.SOL.4.44.0304250851320.19695-100000@robotron.gpcc.itd.umich.edu>


On only ten points, what did you expect ?  Even with 1000
observations, estimating a density is difficult, and has
been the subject of a century of research.  Kernel density
estimates are among the most successful.  For your immediate
application, try  plot(density(rnorm(10)), type="l"), etc.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 25 Apr 2003, Khamenia, Valery wrote:

> Hi All,
>
> following expression:
>
>   x <- sort(rnorm(10)); e <- ecdf(x); d <- numericDeriv(e(x),"x");
>
> makes d far from approximation of one dimensional pdf.
>
> What's wrong then here?
>
> Kind regards.
> ---------------------------------------------------------------------------
> Valery A.Khamenya
> Bioinformatics Department
> BioVisioN AG, Hannover


From ripley at stats.ox.ac.uk  Fri Apr 25 15:00:13 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 25 Apr 2003 14:00:13 +0100 (BST)
Subject: [R] Rcmd BATCH vs. Rterm.exe
In-Reply-To: <6A4BCEF0FD65344A8F496D7E520DD8B902C36106@lobster.zhwin.ch>
Message-ID: <Pine.LNX.4.44.0304251356160.10244-100000@gannet.stats>

[I've corrected the subject.]

On Fri, 25 Apr 2003, "Untern?hrer Thomas, uth" wrote:

> What exactly is the difference in call r from a batch between this two ways:
> 
> Rterm.exe ...
> 
> Rcmd BATCH ... (I have to install perl first, I know)
> 
> 
> I haven't found any documentation about the difference (readme, FAQs, ...).
> I use rterm.exe, but is there a benefit in using rcmd?
> 
> Can you explain me that or give me a link?

It depends on the `...' you had in mind.

Rcmd BATCH is

1) compatible with R CMD BATCH under Unix-alikes
2) saves remembering complicated commands.
3) works the same way across R versions (whereas direct use of rterm
does not work the same way in 1.6.2 and 1.7.0).

The references are

a) the rw-FAQ
b) the source code.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From V.Khamenia at BioVisioN.de  Fri Apr 25 15:02:39 2003
From: V.Khamenia at BioVisioN.de (Khamenia, Valery)
Date: Fri, 25 Apr 2003 15:02:39 +0200
Subject: AW: [R] numericDeriv and ecdf
Message-ID: <D15343265276D31197BC00A024A6C110774009@EXS_BDC>

> On only ten points, what did you expect ?  Even with 1000
> observations, estimating a density is difficult, and has
> been the subject of a century of research.  Kernel density
> estimates are among the most successful.  For your immediate
> application, try  plot(density(rnorm(10)), type="l"), etc.

wait, you misunderstood me!

I'd like to see 10 or 9 points with estimated values of 
*numerical* derivatives according to ecdf output. 
And that's it.

Now look into output of numericDerivative in my example:

[1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
attr(,"gradient")
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]    0    0    0    0    0    0    0    0    0     0
 [2,]    0    0    0    0    0    0    0    0    0     0
 [3,]    0    0    0    0    0    0    0    0    0     0
 [4,]    0    0    0    0    0    0    0    0    0     0
 [5,]    0    0    0    0    0    0    0    0    0     0
 [6,]    0    0    0    0    0    0    0    0    0     0
 [7,]    0    0    0    0    0    0    0    0    0     0
 [8,]    0    0    0    0    0    0    0    0    0     0
 [9,]    0    0    0    0    0    0    0    0    0     0
[10,]    0    0    0    0    0    0    0    0    0     0

What could you say now?

With kind regards,
Valery A.Khamenya
---------------------------------------------------------------------------
Bioinformatics Department
BioVisioN AG, Hannover


From ripley at stats.ox.ac.uk  Fri Apr 25 15:08:37 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 25 Apr 2003 14:08:37 +0100 (BST)
Subject: [R] make? on Macos 10.2.4
In-Reply-To: <Pine.SOL.4.30.0304250734420.29960-100000@ysidro.econ.uiuc.edu>
Message-ID: <Pine.LNX.4.44.0304251400500.10244-100000@gannet.stats>

It is a known problem with the version of g77 you used: specifically with
libg2c, so Fortran code cannot be included in a dynamic library.  Jan de
Leeuw said gcc 3.3 (alpha)  worked, but otherwise you can use veclib: see
the R-admin manual under `MacOS X'.  Specifically, configure with

--with-blas="-framework vecLib" --with-lapack


On Fri, 25 Apr 2003, Roger Koenker wrote:

> Greetings on A.N. Kolmogorov's 100th birthday:
> 
> I am sure that this is a resolved problem, certainly it has been raised in R help
> several times before, but I can't seem to find the right clue.  I've recently
> upgraded a G4 to OS 10.2.5 and I thought I would have another go at installing
> R from source, after failing to accomplish this in 10.1.
> 
> So with 1.7.0 from CRAN configure seems to be fine, but make dies with the following
> 
> gcc -dynamiclib -install_name /usr/local/lib/R/bin/libRlapack.dylib -L/sw/lib -L/usr/local/lib -o libRlapack.dylib dlapack0.lo dlapack1.lo dlapack2.lo dlapack3.lo cmplx.lo  -lf77blas -latlas -L/sw/lib -L/usr/local/lib -L/sw/lib/gcc-lib/powerpc-apple-darwin6.5/3.1 -L/sw/lib/gcc-lib/powerpc-apple-darwin6.5/3.1/../../.. -lfrtbegin -lg2c -lSystem
> ld: common symbols not allowed with MH_DYLIB output format with the -multi_module option
> /sw/lib/libg2c.a(err.o) definition of common _f__cblank (size 4)
> /sw/lib/libg2c.a(fmt.o) definition of common _f__cnt (size 40)
> .
> .
> [more of this]
> .
> .
> /sw/lib/libg2c.a(err.o) definition of common _f__icptr (size 4)
> /sw/lib/libg2c.a(err.o) definition of common f(short, void, int, char) (size 4)
> /usr/bin/libtool: internal link edit command failed
> make[4]: *** [libRlapack.dylib] Error 1
> make[3]: *** [R] Error 2
> make[2]: *** [R] Error 1
> make[1]: *** [R] Error 1
> make: *** [R] Error 1
> 
> Configure produces:
> 
> R is now configured for powerpc-apple-darwin6.5
> 
>   Source directory:          .
>   Installation directory:    /usr/local
> 
>   C compiler:                gcc  -g -O2
>   C++ compiler:              g++  -g -O2
>   Fortran compiler:          g77  -g -O2
> 
>   Interfaces supported:      X11
>   External libraries:        BLAS(ATLAS)
>   Additional capabilities:   PNG, JPEG, bzip2, PCRE
>   Options enabled:           R profiling
> 
>   Recommended packages:      yes
> 
> 
> And the g77, gcc info is:
> 
> rudjer: g77 -v
> Reading specs from /sw/lib/gcc-lib/powerpc-apple-darwin6.5/3.1/specs
> Configured with: ../gcc3/configure --prefix=/sw --enable-languages=f77 --infodir=${prefix}/share/info
> Thread model: single
> Apple Computer, Inc. GCC version 1151, based on gcc version 3.1 20020420 (prerelease)
> rudjer: gcc -v
> Reading specs from /usr/libexec/gcc/darwin/ppc/3.1/specs
> Thread model: posix
> Apple Computer, Inc. GCC version 1175, based on gcc version 3.1 20020420 (prerelease)
> 
> Any suggestions would be most welcome.
> 
> Roger
> 
> url:	www.econ.uiuc.edu	Roger Koenker		Dept. of Economics UCL,
> email	rkoenker at uiuc.edu	Department of Economics Drayton House,
> vox: 	217-333-4558		University of Illinois	30 Gordon St,
> fax:   	217-244-6678		Champaign, IL 61820	London,WC1H 0AX, UK
> 							vox:	020-7679-5838
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sway at tanox.com  Fri Apr 25 15:21:20 2003
From: sway at tanox.com (Shawn Way)
Date: Fri, 25 Apr 2003 08:21:20 -0500
Subject: [R] Posix data in Lattice
Message-ID: <2F3262756375D411B0CC00B0D049775DAFB367@westpark.tanox.net>

I have a number of plots that I'm trying to do using the lattice package,
unfortunately, they involve Posix values.

A small sample of the data is as follows:

                   Time   TC.1  <Snipped>
1   2003-04-24 13:29:15  26.61
2   2003-04-24 13:29:30  26.48
3   2003-04-24 13:30:00  26.53
4   2003-04-24 13:30:30  27.85
<Snipped>

where

str(data)
`data.frame':	415 obs. of  22 variables:
 $ Time :`POSIXlt', format: chr  "2003-04-24 13:29:15" "2003-04-24 13:29:30"
"2003-04-24 13:30:00" "2003-04-24 13:30:30" ...
 $ TC.1 : num   26.6  26.5  26.5  27.9 100.0 ...
<Snipped>

What I'm trying to do is plot TC.1 vs Time (which I can do easily), but I
need the xaxis to represent the Time instead of a numeric such as
105121000,etc.

I also need to rotate the times, but I think I have that figured out...

Any thoughts?


Shawn Way
Engineering Manager
Tanox, Inc.


From ripley at stats.ox.ac.uk  Fri Apr 25 15:29:02 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 25 Apr 2003 14:29:02 +0100 (BST)
Subject: AW: [R] numericDeriv and ecdf
In-Reply-To: <D15343265276D31197BC00A024A6C110774009@EXS_BDC>
Message-ID: <Pine.LNX.4.44.0304251423210.12740-100000@gannet.stats>

An empirical CDF is a step function: it does not have a derivative at the 
jump points, and has a zero derivative everywhere else.

What is this function `numericDerivative': do you mean `numericDeriv'?
If so, it seems to be intended for differentiable functions, and
calculates one-sided derivatives.  In your example the one-sided 
derivatives are all zero.

On Fri, 25 Apr 2003, Khamenia, Valery wrote:

> > On only ten points, what did you expect ?  Even with 1000
> > observations, estimating a density is difficult, and has
> > been the subject of a century of research.  Kernel density
> > estimates are among the most successful.  For your immediate
> > application, try  plot(density(rnorm(10)), type="l"), etc.
> 
> wait, you misunderstood me!
> 
> I'd like to see 10 or 9 points with estimated values of 
> *numerical* derivatives according to ecdf output. 
> And that's it.
> 
> Now look into output of numericDerivative in my example:
> 
> [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
> attr(,"gradient")
>       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
>  [1,]    0    0    0    0    0    0    0    0    0     0
>  [2,]    0    0    0    0    0    0    0    0    0     0
>  [3,]    0    0    0    0    0    0    0    0    0     0
>  [4,]    0    0    0    0    0    0    0    0    0     0
>  [5,]    0    0    0    0    0    0    0    0    0     0
>  [6,]    0    0    0    0    0    0    0    0    0     0
>  [7,]    0    0    0    0    0    0    0    0    0     0
>  [8,]    0    0    0    0    0    0    0    0    0     0
>  [9,]    0    0    0    0    0    0    0    0    0     0
> [10,]    0    0    0    0    0    0    0    0    0     0
> 
> What could you say now?
> 
> With kind regards,
> Valery A.Khamenya
> ---------------------------------------------------------------------------
> Bioinformatics Department
> BioVisioN AG, Hannover
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Saghir.Bashir at UCB-Group.com  Fri Apr 25 15:44:19 2003
From: Saghir.Bashir at UCB-Group.com (Bashir Saghir (Aztek Global))
Date: Fri, 25 Apr 2003 15:44:19 +0200
Subject: [R] Creating objects from values in a "meta" dataframe
Message-ID: <3EBA5559F490D61189430002A5F0AE890301859B@ntexcrd.braine.ucb>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030425/e5b75f8b/attachment.pl

From roger at ysidro.econ.uiuc.edu  Fri Apr 25 15:50:15 2003
From: roger at ysidro.econ.uiuc.edu (Roger Koenker)
Date: Fri, 25 Apr 2003 08:50:15 -0500 (CDT)
Subject: [R] make? on Macos 10.2.4
In-Reply-To: <Pine.LNX.4.44.0304251400500.10244-100000@gannet.stats>
Message-ID: <Pine.SOL.4.30.0304250847110.29960-100000@ysidro.econ.uiuc.edu>

Thanks, configurng  with
>
> --with-blas="-framework vecLib" --with-lapack
>
worked smoothly.


url:	www.econ.uiuc.edu	Roger Koenker		Dept. of Economics UCL,
email	rkoenker at uiuc.edu	Department of Economics Drayton House,
vox: 	217-333-4558		University of Illinois	30 Gordon St,
fax:   	217-244-6678		Champaign, IL 61820	London,WC1H 0AX, UK
							vox:	020-7679-5838

On Fri, 25 Apr 2003, Prof Brian Ripley wrote:

> It is a known problem with the version of g77 you used: specifically with
> libg2c, so Fortran code cannot be included in a dynamic library.  Jan de
> Leeuw said gcc 3.3 (alpha)  worked, but otherwise you can use veclib: see
> the R-admin manual under `MacOS X'.  Specifically, configure with
>
> --with-blas="-framework vecLib" --with-lapack
>
>


From spencer.graves at pdf.com  Fri Apr 25 15:52:34 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 25 Apr 2003 06:52:34 -0700
Subject: [R] About qvalue
References: <1051256904.3ea8e8489be59@homae.univ-ubs.fr>
Message-ID: <3EA93DA2.3010101@pdf.com>

Did you try specifying the full path?  [Also, is "\" an escape character 
in R as it is in S-Plus?  In that case you need to write "\\" to get one 
"\" -- or use "/".]

hope this helps.  spencer graves

sandrine.mainard1 at etud.univ-ubs.fr wrote:
> Hello, 
> 
> I'm apologize to have made failure before. 
> I wrote this : p<-scan("teststat.txt") on R and R returns Error in scan 
> ("teststat.txt") : "scan" expected a real, got "x". I don't really 
> understand,because teststat has been created, so........ 
> 
> Thanks a lot. 
> 
> Sandrine 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> --------------------------------------------------------------------------------
> Universit? de Bretagne sud                               http://www.univ-ubs.fr/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tlumley at u.washington.edu  Fri Apr 25 16:22:38 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 25 Apr 2003 07:22:38 -0700 (PDT)
Subject: AW: [R] numericDeriv and ecdf
In-Reply-To: <D15343265276D31197BC00A024A6C110774009@EXS_BDC>
Message-ID: <Pine.A41.4.44.0304250720140.69574-100000@homer08.u.washington.edu>

On Fri, 25 Apr 2003, Khamenia, Valery wrote:

> > On only ten points, what did you expect ?  Even with 1000
> > observations, estimating a density is difficult, and has
> > been the subject of a century of research.  Kernel density
> > estimates are among the most successful.  For your immediate
> > application, try  plot(density(rnorm(10)), type="l"), etc.
>
> wait, you misunderstood me!
>
> I'd like to see 10 or 9 points with estimated values of
> *numerical* derivatives according to ecdf output.

The output of ecdf() is a step function, so mathematically its derivative
is zero except where it is undefined.

Everywhere except the jumps numericDeriv() gives the right answer
Exactly at the jumps the derivative is undefined, so it isn't surprising
that numericDeriv gives the wrong answer.

What result did you want?

	-thomas


From spencer.graves at pdf.com  Fri Apr 25 16:24:10 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 25 Apr 2003 07:24:10 -0700
Subject: [R] Creating objects from values in a "meta" dataframe
References: <3EBA5559F490D61189430002A5F0AE890301859B@ntexcrd.braine.ucb>
Message-ID: <3EA9450A.2090601@pdf.com>

 From what I read of your problem statement, there should be a solution 
along the lines you outlined.  Could you cut down the problem still 
further and give us an example of something you've done that did NOT 
work, so we can see how it did not work.

hth.  spencer graves

Bashir Saghir (Aztek Global) wrote:
> I am trying to use a meta data set with information about some repetative
> analysis that I have to do for a variables measured on multiple occasions. 
> 
> I think the best way to explain the problem is by using a simplified
> example. So here goes:
> 
> I have a data frame called "meta" say with the following content:
> 
> Test  Min  Max  Low  High
> APS    0    40  -10   10
> TPP    0   120   -8    8
> NOS    0    25  -15   12
> ... etc ...
> 
> I want to create an object based on each of the Test names, for example:
> 
> cADS <- function(ADS1, min=0, max=40; low=-10, high=10)
> cTPP <- function(TPP1, 0, 120, -8, 8)
> cNOS <- function(NOS1, 0, 25, -15, 12)
> .. etc ...
> 
> where ADS1, TPP1, NOS1, etc. are columns from a second data frame, say,
> "study".
> 
> So in summary how do I create a variable based on the entries in "meta"
> (e.g. from 'APS' I want to create 'cAPS') using a column in another data
> frame again based on the entry in "meta" (eg, ADS0, ADS12, etc...).
> 
> I hope that this explains my problem clearly, if not please let me know.
> 
> Thanks for your help in advance,
> Saghir
> 
> 
> Before I get flamed for what might be a simple solution to a previously
> discussed problem on this list or addressed in the FAQs, I have tried
> extensively (for 3 days now!!!!) to find a solution myself. None of my
> colleagues can help as I am their "R help" most of the time!!! I have tried
> various helps terms on google with and without "r-help", looked at various
> Splus books, and I even looked at all the functions on HTML version of R
> help - I still have no idea what I am looking for. In the past I have
> succeed in doing such things in Stata and SAS. 
> 
> 
> 
> 
> --------------------------------------------------------- 
> Legal Notice: This electronic mail and its attachments are inten... {{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From p.dalgaard at biostat.ku.dk  Fri Apr 25 16:30:30 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 25 Apr 2003 16:30:30 +0200
Subject: AW: [R] numericDeriv and ecdf
In-Reply-To: <Pine.LNX.4.44.0304251423210.12740-100000@gannet.stats>
References: <Pine.LNX.4.44.0304251423210.12740-100000@gannet.stats>
Message-ID: <x2ptnasl89.fsf@biostat.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> An empirical CDF is a step function: it does not have a derivative at the 
> jump points, and has a zero derivative everywhere else.
> 
> What is this function `numericDerivative': do you mean `numericDeriv'?
> If so, it seems to be intended for differentiable functions, and
> calculates one-sided derivatives.  In your example the one-sided 
> derivatives are all zero.

Also, the call must be wrong, try this:

> z <- 0
> numericDeriv(quote(e(x-z)),"z");
 [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
attr(,"gradient")
          [,1]
 [1,] -6710886
 [2,] -6710886
 [3,] -6710886
 [4,] -6710886
 [5,] -6710886
 [6,] -6710886
 [7,] -6710886
 [8,] -6710886
 [9,] -6710886
[10,] -6710886

whereas e(x+z) gives you all zeroes. (An option for deciding between
left-sided, right-sided, and central derivates could be a nice
extension, BTW).

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From luke at inpharmatica.co.uk  Fri Apr 25 16:28:19 2003
From: luke at inpharmatica.co.uk (Luke Whitaker)
Date: Fri, 25 Apr 2003 15:28:19 +0100 (BST)
Subject: [R] Unable to create directory?
In-Reply-To: <Pine.GSO.4.53.0304241654480.19924@delta5.sm.luth.se>
Message-ID: <Pine.LNX.4.21.0304251523440.3022-100000@dollis-hill.inpharmatica.co.uk>

On Thu, 24 Apr 2003, Robert Lundqvist wrote:

> I have tried to install the pls.pcr package, but as a install newbie, I
> wasn't too successful. I tried the command
> "install.package("pls.pcr",lib="~/lib/R/",CRAN="http://mirrors.sunsite.dk/cran").
> The download seemed to run smoothly, but in the end I got the response
> "ERROR: cannot write to or create directory '~/lib/R'"
> 
> Before I try to get my sysadmins to work on this, is it a non-R
> problem (i e something wrong with directory premissions) or is it
> some R detail I've missed? Hints anyone?
> 
> (I run R in a Unix environment: a SunRay/Solaris combination.)
> 
> --robert
> 
> 
> ------------------------------
> 

Just guessing, but I think the problem is with using '~' to mean
your home directory. The shell normally interprets the '~', but
I don't think the shell is doing anything here. I suspect R is
trying to create a directory with the literal name '~/lib/R'.

Replace '~' with the full path of your home directory, and make sure that
the 'lib' part already exists before you do the install.package.
(ie do "mkdir ~/lib" first if it doesn't exist).

Luke


From spok_1 at yahoo.com  Fri Apr 25 16:45:16 2003
From: spok_1 at yahoo.com (spok)
Date: Fri, 25 Apr 2003 07:45:16 -0700 (PDT)
Subject: [R] 
	validate function in Design library does not work with small samples
Message-ID: <20030425144516.94010.qmail@web20414.mail.yahoo.com>

Hi,

I am using the validate function in the design library
to get corrected Somer's Dxy for cox ph models.  When
my sample size is reduced from 300 to 150, the
function complains (length of dimnames[1] not equal to
array) and does not produce any results.  There are no
missing values in the data.  Any suggestions for a
work-around?

Thank you in Advance.

>
f.total=cph(Surv(fu,censor)~predictor+pred2+pred3,data=data,x=T,y=T,surv=T)
> set.seed(6)
> val.step=validate(f.total,B=155,bw=T)

                Backwards Step-down - Original Model

No Factors Deleted

Factors in Final Model

[1] pred2
.Random.seed: 1 -1021164091 1170333634 in .GlobalEnv 
Iteration:
1 2 3 4 5 6 7 Error in fit(NULL, y[train, , drop =
FALSE], iter = i, tol = tol, ...) : 
        length of dimnames[1] not equal to array
extent
> val.step


From juergen.pilz at uni-klu.ac.at  Fri Apr 25 17:13:18 2003
From: juergen.pilz at uni-klu.ac.at (juergen.pilz@uni-klu.ac.at)
Date: Fri, 25 Apr 2003 15:13:18 -0000
Subject: [R] Call for papers: Int. Workshop StatGIS03
Message-ID: <twig.1051283598.90532@uni-klu.ac.at>

Dear colleagues and friends,

We are organizing the INTERNATIONAL WORKSHOP 

StatGIS 2003 - Interfacing (Geo)Statistics, GIS and Spatial Data Bases
Sept. 29 - Oct. 1, 2003
Poertschach, Austria.
 
Main Sections:
- Geostatistics: Theory and New Methods
  (Conveners: W.G. M?ller, J. Pilz)
- Combining Statistics and GIS
  (Conveners: R. Bivand, G. Dubois)
- Geostatistical Applications
  (Conveners: H. Glass, M. Kanevsky)
- Spatial Data Bases and Mapping
  (Conveners: V. Gomez, B. Rowlingson))
- Geostatistical Software Developments
  (Conveners: E. Pebesma, P. Ribeiro)

Detailed information can be found at

http://www-stat.uni-klu.ac.at/Tagungen/StatGIS-03/

We invite you to contribute papers to the above mentioned sections.
Papers on implementations using R are particularly welcome.

Deadline for submission of abstracts: August 1, 2003
Notification of acceptance: August 15, 2003

For further questions and correspondence please reply to
statgis03 at uni-klu.ac.at


On behalf of the Programme Committee and Local Organizing Committee,
Juergen Pilz

Prof. Dr. Juergen Pilz
University of Klagenfurt
Dept. of Mathematics
Applied Statistics Group
Univ. Street 65
A- 9020 Klagenfurt
Tel.: +43- 463- 2700 3113
Fax:  +43- 463- 2700 3198
email: jpilz at uni-klu.ac.at


From vincent.stoliaroff at socgen.com  Fri Apr 25 17:15:47 2003
From: vincent.stoliaroff at socgen.com (vincent.stoliaroff@socgen.com)
Date: Fri, 25 Apr 2003 17:15:47 +0200
Subject: [R] Code bug unresolved involving if condition
Message-ID: <OFD453E56B.54A9F86E-ONC1256D13.00530B0D@ges.marc.societe-generale.fr>

Hi R lovers!

I am a beginner in coding with R so my question may be very easily solved
but I don't know how.

I have written the following function in a .txt file


ClearDelta <- function(Matrix)
{
ncol<-ncol(Matrix);nrow<-nrow(Matrix);
for (i in 1:nrow) {
                  for (j in 1:(ncol-1))
                        {if (Matrix[i,j]==NA) (NA->Matrix[i,j+1])}
                  }
}

I can charge it with the source() command
But I get the following message when applied to a matrix

> ClearDelta(MatCor)
Error in if (Matrix[i, j] == NA) (Matrix[i, j + 1] <- NA) :
        missing value where logical needed

MatCor is the following Matrix

> MatCor
           [,1]         [,2]       [,3]
[1,]         NA          0.9870676  0.04648933
[2,] 0.98706757  1.0000000 -0.17353590
[3,] 0.04648933 -0.1735359  1.00000000

Do you know why I get such an unpleasant message from so polite a software?

Thanks to anybody who could help.







*************************************************************************
Ce message et toutes les pieces jointes (ci-apres le "message") sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite. 
Tout message electronique est susceptible d'alteration. 
La SOCIETE GENERALE et ses filiales declinent toute responsabilite au 
titre de ce message s'il a ete altere, deforme ou falsifie.
				********
This message and any attachments (the "message") are confidentia... {{dropped}}


From fharrell at virginia.edu  Fri Apr 25 17:16:25 2003
From: fharrell at virginia.edu (Frank E Harrell Jr)
Date: Fri, 25 Apr 2003 11:16:25 -0400
Subject: [R]  validate function in Design library does not work with
 small samples
In-Reply-To: <20030425144516.94010.qmail@web20414.mail.yahoo.com>
References: <20030425144516.94010.qmail@web20414.mail.yahoo.com>
Message-ID: <20030425111625.52ea3f1c.fharrell@virginia.edu>

On Fri, 25 Apr 2003 07:45:16 -0700 (PDT)
spok <spok_1 at yahoo.com> wrote:

> Hi,
> 
> I am using the validate function in the design library
> to get corrected Somer's Dxy for cox ph models.  When
> my sample size is reduced from 300 to 150, the
> function complains (length of dimnames[1] not equal to
> array) and does not produce any results.  There are no
> missing values in the data.  Any suggestions for a
> work-around?
> 
> Thank you in Advance.
> 
> >
> f.total=cph(Surv(fu,censor)~predictor+pred2+pred3,data=data,x=T,y=T,surv=T)
> > set.seed(6)
> > val.step=validate(f.total,B=155,bw=T)
> 
>                 Backwards Step-down - Original Model
> 
> No Factors Deleted
> 
> Factors in Final Model
> 
> [1] pred2
> .Random.seed: 1 -1021164091 1170333634 in .GlobalEnv 
> Iteration:
> 1 2 3 4 5 6 7 Error in fit(NULL, y[train, , drop =
> FALSE], iter = i, tol = tol, ...) : 
>         length of dimnames[1] not equal to array
> extent
> > val.step

In general it is best to contact the package maintainer directly.  Also, be sure to give the output of typing the command 

  version

and the version number of the package you are using.  For your problem please run save( ) to save f.total and e-mail it to me as an attachment, then I'll debug.  I'm glad you issued the set.seed command which should help me replicate the problem.

Frank

---
Frank E Harrell Jr              Prof. of Biostatistics & Statistics
Div. of Biostatistics & Epidem. Dept. of Health Evaluation Sciences
U. Virginia School of Medicine  http://hesweb1.med.virginia.edu/biostat


From f0z6305 at labs.tamu.edu  Fri Apr 25 17:19:05 2003
From: f0z6305 at labs.tamu.edu (Feng Zhang)
Date: Fri, 25 Apr 2003 10:19:05 -0500
Subject: [R] Matrix Equation Help?
References: <006001c30a84$0888cdd0$8bd75ba5@IE.TAMU.EDU>
	<3EA828EC.2060101@statistik.uni-dortmund.de> <3EA8B7E6.3000709@pdf.com>
Message-ID: <007801c30b3e$02c94a90$8bd75ba5@IE.TAMU.EDU>

"solve" in my question means to get a unique
solution for X given A and B.

If solve in R cannot do this, what else function
would be helpful?

In R, there are 'backsolve' and 'qr.solve'. So if
these two functions are appropreciate for my
problem?

Thanks
----- Original Message -----
From: "Spencer Graves" <spencer.graves at PDF.COM>
To: "Uwe Ligges" <ligges at statistik.uni-dortmund.de>
Cc: "Feng Zhang" <f0z6305 at labs.tamu.edu>; "R-Help"
<r-help at stat.math.ethz.ch>
Sent: Thursday, April 24, 2003 11:21 PM
Subject: Re: [R] Matrix Equation Help?


> If n>>m, then solve does not work.  Consider:
>
>  > A <- array(1:6, dim=c(2,3))
>  > B <- array(1:4, dim=c(2,2))
>  > solve(A, B)
> Error in solve.default(A, B) : singular matrix `a' in solve
>
> In this case, we have 6 = 3 x 2 unknowns but only 4 equations.
>
> It raises questions about what you mean by solve.  S-Plus 2000 and 6
> have "ginverse" that will produce an answer.  You can construct such
> using "qr" or "svd".
>
> However, before coding that, I will ask, what do you mean by "solve"?
>
> hth.  spencer graves
>
> Uwe Ligges wrote:
> > Feng Zhang wrote:
> >
> >> Dear R-listers
> >>
> >> Now I have a Matrix Equation to solve,
> >> A -- m by n matrix, where n>>m, known matrix;
> >> X -- n by m unknown matrix;
> >> B -- m by m known matrix.
> >>
> >> So given the equation A*X=B, how to solve X?
> >
> >
> > You already mentioned it:
> > ?solve
> >
> > Uwe Ligges
> >
> >> I first tried to take X = inv((A'*A))*A'. But since
> >> A'*A is singular, this is no way to go.
> >>
> >> Please give me some point on this.
> >> Thanks
> >>
> >> Fred
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>


From ripley at stats.ox.ac.uk  Fri Apr 25 17:34:47 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 25 Apr 2003 16:34:47 +0100 (BST)
Subject: [R] Code bug unresolved involving if condition
In-Reply-To: <OFD453E56B.54A9F86E-ONC1256D13.00530B0D@ges.marc.societe-generale.fr>
Message-ID: <Pine.LNX.4.44.0304251632340.13071-100000@gannet.stats>

The message is both pleasant and accurate!  It indicates that you have 
made an error, and tells you what the error is.

foo == NA is always missing, since NA denotes a missing value.
Use is.na(foo): see ?is.na.

On Fri, 25 Apr 2003 vincent.stoliaroff at socgen.com wrote:

> Hi R lovers!
> 
> I am a beginner in coding with R so my question may be very easily solved
> but I don't know how.
> 
> I have written the following function in a .txt file
> 
> 
> ClearDelta <- function(Matrix)
> {
> ncol<-ncol(Matrix);nrow<-nrow(Matrix);
> for (i in 1:nrow) {
>                   for (j in 1:(ncol-1))
>                         {if (Matrix[i,j]==NA) (NA->Matrix[i,j+1])}
>                   }
> }
> 
> I can charge it with the source() command
> But I get the following message when applied to a matrix
> 
> > ClearDelta(MatCor)
> Error in if (Matrix[i, j] == NA) (Matrix[i, j + 1] <- NA) :
>         missing value where logical needed
> 
> MatCor is the following Matrix
> 
> > MatCor
>            [,1]         [,2]       [,3]
> [1,]         NA          0.9870676  0.04648933
> [2,] 0.98706757  1.0000000 -0.17353590
> [3,] 0.04648933 -0.1735359  1.00000000
> 
> Do you know why I get such an unpleasant message from so polite a software?
> 
> Thanks to anybody who could help.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From vincent.stoliaroff at socgen.com  Fri Apr 25 17:45:18 2003
From: vincent.stoliaroff at socgen.com (vincent.stoliaroff@socgen.com)
Date: Fri, 25 Apr 2003 17:45:18 +0200
Subject: [R] Code bug unresolved involving if condition
Message-ID: <OFA24DB6BF.8606D711-ONC1256D13.0055BB53@ges.marc.societe-generale.fr>


Thanks a lot
I had corrected that already after thinking for a while about the cause of
the bug

However I still have some trouble in trying to set the Matrix[i,j+1] term
to Missingness.

I am not sure how to use the generic function `is.na<-' which sets elements
to `NA'.

      {if (is.na(Matrix[i,j])) (is.na(Matrix[i,j+1])<-1)}

does not work to set my  Matrix[i,j+1]  term to NA

Thanks in advance for any help




|---------+---------------------------->
|         |           ripley at stats.ox.a|
|         |           c.uk             |
|         |                            |
|         |           04/25/03 05:34 PM|
|         |                            |
|---------+---------------------------->
  >------------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                              |
  |       To:       Vincent STOLIAROFF/fr/socgen at socgen                                                                          |
  |       cc:       r-help at stat.math.ethz.ch                                                                                     |
  |       Subject:  Re: [R] Code bug unresolved involving if condition                                                           |
  >------------------------------------------------------------------------------------------------------------------------------|



The message is both pleasant and accurate!  It indicates that you have
made an error, and tells you what the error is.

foo == NA is always missing, since NA denotes a missing value.
Use is.na(foo): see ?is.na.

On Fri, 25 Apr 2003 vincent.stoliaroff at socgen.com wrote:

> Hi R lovers!
>
> I am a beginner in coding with R so my question may be very easily solved
> but I don't know how.
>
> I have written the following function in a .txt file
>
>
> ClearDelta <- function(Matrix)
> {
> ncol<-ncol(Matrix);nrow<-nrow(Matrix);
> for (i in 1:nrow) {
>                   for (j in 1:(ncol-1))
>                         {if (Matrix[i,j]==NA) (NA->Matrix[i,j+1])}
>                   }
> }
>
> I can charge it with the source() command
> But I get the following message when applied to a matrix
>
> > ClearDelta(MatCor)
> Error in if (Matrix[i, j] == NA) (Matrix[i, j + 1] <- NA) :
>         missing value where logical needed
>
> MatCor is the following Matrix
>
> > MatCor
>            [,1]         [,2]       [,3]
> [1,]         NA          0.9870676  0.04648933
> [2,] 0.98706757  1.0000000 -0.17353590
> [3,] 0.04648933 -0.1735359  1.00000000
>
> Do you know why I get such an unpleasant message from so polite a software?
>
> Thanks to anybody who could help.

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595







*************************************************************************
Ce message et toutes les pieces jointes (ci-apres le "message") sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite. 
Tout message electronique est susceptible d'alteration. 
La SOCIETE GENERALE et ses filiales declinent toute responsabilite au 
titre de ce message s'il a ete altere, deforme ou falsifie.
				********
This message and any attachments (the "message") are confidentia... {{dropped}}


From ripley at stats.ox.ac.uk  Fri Apr 25 17:54:32 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 25 Apr 2003 16:54:32 +0100 (BST)
Subject: [R] Code bug unresolved involving if condition
In-Reply-To: <OFA24DB6BF.8606D711-ONC1256D13.0055BB53@ges.marc.societe-generale.fr>
Message-ID: <Pine.LNX.4.44.0304251653540.15137-100000@gannet.stats>

On Fri, 25 Apr 2003 vincent.stoliaroff at socgen.com wrote:

> 
> Thanks a lot
> I had corrected that already after thinking for a while about the cause of
> the bug
> 
> However I still have some trouble in trying to set the Matrix[i,j+1] term
> to Missingness.

Why?  Setting it to NA works.

> 
> I am not sure how to use the generic function `is.na<-' which sets elements
> to `NA'.
> 
>       {if (is.na(Matrix[i,j])) (is.na(Matrix[i,j+1])<-1)}
> 
> does not work to set my  Matrix[i,j+1]  term to NA
> 
> Thanks in advance for any help
> 
> 
> 
> 
> |---------+---------------------------->
> |         |           ripley at stats.ox.a|
> |         |           c.uk             |
> |         |                            |
> |         |           04/25/03 05:34 PM|
> |         |                            |
> |---------+---------------------------->
>   >------------------------------------------------------------------------------------------------------------------------------|
>   |                                                                                                                              |
>   |       To:       Vincent STOLIAROFF/fr/socgen at socgen                                                                          |
>   |       cc:       r-help at stat.math.ethz.ch                                                                                     |
>   |       Subject:  Re: [R] Code bug unresolved involving if condition                                                           |
>   >------------------------------------------------------------------------------------------------------------------------------|
> 
> 
> 
> The message is both pleasant and accurate!  It indicates that you have
> made an error, and tells you what the error is.
> 
> foo == NA is always missing, since NA denotes a missing value.
> Use is.na(foo): see ?is.na.
> 
> On Fri, 25 Apr 2003 vincent.stoliaroff at socgen.com wrote:
> 
> > Hi R lovers!
> >
> > I am a beginner in coding with R so my question may be very easily solved
> > but I don't know how.
> >
> > I have written the following function in a .txt file
> >
> >
> > ClearDelta <- function(Matrix)
> > {
> > ncol<-ncol(Matrix);nrow<-nrow(Matrix);
> > for (i in 1:nrow) {
> >                   for (j in 1:(ncol-1))
> >                         {if (Matrix[i,j]==NA) (NA->Matrix[i,j+1])}
> >                   }
> > }
> >
> > I can charge it with the source() command
> > But I get the following message when applied to a matrix
> >
> > > ClearDelta(MatCor)
> > Error in if (Matrix[i, j] == NA) (Matrix[i, j + 1] <- NA) :
> >         missing value where logical needed
> >
> > MatCor is the following Matrix
> >
> > > MatCor
> >            [,1]         [,2]       [,3]
> > [1,]         NA          0.9870676  0.04648933
> > [2,] 0.98706757  1.0000000 -0.17353590
> > [3,] 0.04648933 -0.1735359  1.00000000
> >
> > Do you know why I get such an unpleasant message from so polite a software?
> >
> > Thanks to anybody who could help.
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> 
> 
> 
> 
> 
> 
> *************************************************************************
> Ce message et toutes les pieces jointes (ci-apres le "message") sont
> confidentiels et etablis a l'intention exclusive de ses destinataires.
> Toute utilisation ou diffusion non autorisee est interdite. 
> Tout message electronique est susceptible d'alteration. 
> La SOCIETE GENERALE et ses filiales declinent toute responsabilite au 
> titre de ce message s'il a ete altere, deforme ou falsifie.
> 				********
> This message and any attachments (the "message") are confidential and
> intended solely for the addressees.
> Any unauthorised use or dissemination is prohibited. 
> E-mails are susceptible to alteration.   
> Neither SOCIETE GENERALE nor any of its subsidiaries or affiliates 
> shall be liable for the message if altered, changed or falsified. 
> 
> *************************************************************************
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tlumley at u.washington.edu  Fri Apr 25 17:56:24 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 25 Apr 2003 08:56:24 -0700 (PDT)
Subject: [R] Code bug unresolved involving if condition
In-Reply-To: <OFD453E56B.54A9F86E-ONC1256D13.00530B0D@ges.marc.societe-generale.fr>
Message-ID: <Pine.A41.4.44.0304250848001.50688-100000@homer39.u.washington.edu>

On Fri, 25 Apr 2003 vincent.stoliaroff at socgen.com wrote:

> Hi R lovers!
>
> I am a beginner in coding with R so my question may be very easily solved
> but I don't know how.
>
> I have written the following function in a .txt file
>
>
> ClearDelta <- function(Matrix)
> {
> ncol<-ncol(Matrix);nrow<-nrow(Matrix);
> for (i in 1:nrow) {
>                   for (j in 1:(ncol-1))
>                         {if (Matrix[i,j]==NA) (NA->Matrix[i,j+1])}
>                   }
> }
>
> I can charge it with the source() command
> But I get the following message when applied to a matrix
>
> > ClearDelta(MatCor)
> Error in if (Matrix[i, j] == NA) (Matrix[i, j + 1] <- NA) :
>         missing value where logical needed
>

>
> Do you know why I get such an unpleasant message from so polite a software?
>

The test (Matrix[i,j] ==NA) returns NA, not TRUE or FALSE as you expected.
Think of NA as meaning "I don't know what this value is", so you are
asking if Matrix[i,j] is equal to a number that you don't know. The answer
is that R doesn't know whether this is TRUE or FALSE, The value NA in a
logical variable means just that "This is TRUE or FALSE but I don't know
which".  You can use is.na() test for NA, ie

  if(is.na(Matrix[i, j]))


I can't resist also pointing out that for large matrices there is a more
efficient answer

for(i in 1:nrow(Matrix))
	Matrix[i,]<- diff(c(0,cumsum(Matrix[i,])))


	-thomas


From edgar at uprm.edu  Fri Apr 25 18:10:37 2003
From: edgar at uprm.edu (edgar@uprm.edu)
Date: Fri, 25 Apr 2003 12:10:37 -0400 (AST)
Subject: [R] 
Message-ID: <4521.136.145.154.108.1051287037.squirrel@math.uprm.edu>

Hello,
Does anybody know where I can find an R function to carry out variable
selection using stepwise similar (or even better) to the stepwise function
available in S-Plus?. I have tried the mle.stepwise function available in
the wle package but I am not getting accurate results.
I have tried also the leaps package but it does not handle the options
f-in and f-out like in either MINITAB or SAS.

Thanks in advance

Dr. Edgar Acuna
University of Puerto Rico at Mayaguez


From sway at tanox.com  Fri Apr 25 18:13:18 2003
From: sway at tanox.com (Shawn Way)
Date: Fri, 25 Apr 2003 11:13:18 -0500
Subject: [R] Posix data in Lattice
Message-ID: <2F3262756375D411B0CC00B0D049775DAFB368@westpark.tanox.net>

A variation of this did the trick.  I had to manually scale the number of
ticks, but it works out well.

Thank you..

-----Original Message-----
From: Renaud Lancelot [mailto:renaud.lancelot at cirad.fr] 
Sent: Friday, April 25, 2003 10:48 AM
To: Shawn Way
Subject: Re: [R] Posix data in Lattice


Shawn Way wrote:
> I have a number of plots that I'm trying to do using the lattice 
> package, unfortunately, they involve Posix values.
> 
> A small sample of the data is as follows:
> 
>                    Time   TC.1  <Snipped>
> 1   2003-04-24 13:29:15  26.61
> 2   2003-04-24 13:29:30  26.48
> 3   2003-04-24 13:30:00  26.53
> 4   2003-04-24 13:30:30  27.85
> <Snipped>
> 
> where
> 
> str(data)
> `data.frame':	415 obs. of  22 variables:
>  $ Time :`POSIXlt', format: chr  "2003-04-24 13:29:15" "2003-04-24 
> 13:29:30" "2003-04-24 13:30:00" "2003-04-24 13:30:30" ...
>  $ TC.1 : num   26.6  26.5  26.5  27.9 100.0 ...
> <Snipped>
> 
> What I'm trying to do is plot TC.1 vs Time (which I can do easily), 
> but I need the xaxis to represent the Time instead of a numeric such 
> as 105121000,etc.
> 
> I also need to rotate the times, but I think I have that figured 
> out...

format looks what you need (see below). Here is a start, but I am not 
very easy with as.POSIX**. In particular, I don't know how to convert 
from numeric to POSIX**.

x    <- as.POSIXlt(ISOdate(2002, 4, 25, 12) + seq(0, 3600 * 3, 1800))
y    <- rnorm(length(x$min))
nlab <- as.numeric(as.POSIXct(x))
clab <- format(x, format = "%H:%M")
foo <- data.frame(Y = y, X = nlab)
rm(x, y, nlab, clab)
x    <- as.POSIXlt(ISOdate(2002, 4, 25, 12) + seq(0, 3600 * 3, 1800))
y    <- rnorm(length(x$min))
nlab <- as.numeric(as.POSIXct(x))
clab <- format(x, format = "%H:%M")
foo <- data.frame(y = y, x = nlab)
rm(x, y)
library(lattice)
xyplot(y ~ x, data=foo, scales=list(x = list(at=nlab, labels=clab)))

Best,

Renaud



-- 
Dr Renaud Lancelot, v?t?rinaire
CIRAD, D?partement Elevage et M?decine V?t?rinaire (CIRAD-Emvt) Programme
Productions Animales http://www.cirad.fr/fr/pg_recherche/page.php?id=14

ISRA-LNERV                      tel    +221 832 49 02
BP 2057 Dakar-Hann              fax    +221 821 18 79 (CIRAD)
Senegal                         e-mail renaud.lancelot at cirad.fr


From josephkyari at netscape.net  Fri Apr 25 09:26:00 2003
From: josephkyari at netscape.net (MR JOSEPH KYARI)
Date: vr, 25 apr 2003 09:26:00
Subject: [R] Dear  Friend
Message-ID: <200304251626.h3PGQ1bi021858@hypatia.math.ethz.ch>


I'm an accountant with the South Africa National petroleum Corporation (SANPC)and, I'm also a member of the contract committee in the South Africa National petroleum Corporation.I'm on a special diplomatic duty in the South Africa foreign office in Amsterdam,the Netherlands.Sometime ago a contract was awarded to a foreign firm in by my committee. 
This contract was over invoiced to the tune of $15,500,000.00(Fifteen Million Five Hundred Thousand Dollars Only)the over invoicing was a deal by my committee to benefit from the project.We now desire to transfer this money which is presently in a suspense account of the Central Bank of South Africa(CBSA)into any overseas account which we expect
you to provide for us.  For providing, the account where we shall remit the money,you will be entitled to 25% of the money 70% will be for myself and my partners,the remaining 5%
will be set aside to settle all expenses incurred by both parties. I would require the following:
1.Your full name and address,as the beneficiary of the fund.
2.Your telephone,fax Numbers. 
3.Bank details where you would want the money remited. 
The above information would be use to make formal application as a matter of procedure for the release of the money and onward transfer to the nominated account you would provide.It does not matter whether or not your company dose contract project of this nature described here,the assumption is that your company won the major contract and subcontracted it
out to other companies.We have strong and reliable connections and contacts at the Apex Bank and the Federal Ministry of Finance and trust worthy partners to assist us in this mutual/beneficial deal. 
Therefore,when the business is successfully concluded,we shall through our same connections
withdraw all document used from all the concerned Government Ministries for 100%security.We are civil servant and we will not miss this opportunity. Please contact me immediately through my private telephone +31-613428347or e-mail address: josephkyari at netscape.netwhether or not you are interested in this deal.If you are not,it will enable me scout for another foreign partner to carry out this deal.But where you are interested, send the required informations aforementioned herein without delay,as time is of great essence in this deal. 
I await your anticipated co-operation and response. 
Best regards, 
Mr.Josephkyari


From josephkyari at netscape.net  Fri Apr 25 09:27:49 2003
From: josephkyari at netscape.net (MR JOSEPH KYARI)
Date: vr, 25 apr 2003 09:27:49
Subject: [R] Dear  Friend
Message-ID: <200304251628.h3PGSDbi022062@hypatia.math.ethz.ch>


I'm an accountant with the South Africa National petroleum Corporation (SANPC)and, I'm also a member of the contract committee in the South Africa National petroleum Corporation.I'm on a special diplomatic duty in the South Africa foreign office in Amsterdam,the Netherlands.Sometime ago a contract was awarded to a foreign firm in by my committee. 
This contract was over invoiced to the tune of $15,500,000.00(Fifteen Million Five Hundred Thousand Dollars Only)the over invoicing was a deal by my committee to benefit from the project.We now desire to transfer this money which is presently in a suspense account of the Central Bank of South Africa(CBSA)into any overseas account which we expect
you to provide for us.  For providing, the account where we shall remit the money,you will be entitled to 25% of the money 70% will be for myself and my partners,the remaining 5%
will be set aside to settle all expenses incurred by both parties. I would require the following:
1.Your full name and address,as the beneficiary of the fund.
2.Your telephone,fax Numbers. 
3.Bank details where you would want the money remited. 
The above information would be use to make formal application as a matter of procedure for the release of the money and onward transfer to the nominated account you would provide.It does not matter whether or not your company dose contract project of this nature described here,the assumption is that your company won the major contract and subcontracted it
out to other companies.We have strong and reliable connections and contacts at the Apex Bank and the Federal Ministry of Finance and trust worthy partners to assist us in this mutual/beneficial deal. 
Therefore,when the business is successfully concluded,we shall through our same connections
withdraw all document used from all the concerned Government Ministries for 100%security.We are civil servant and we will not miss this opportunity. Please contact me immediately through my private telephone +31-613428347or e-mail address: josephkyari at netscape.netwhether or not you are interested in this deal.If you are not,it will enable me scout for another foreign partner to carry out this deal.But where you are interested, send the required informations aforementioned herein without delay,as time is of great essence in this deal. 
I await your anticipated co-operation and response. 
Best regards, 
Mr.Josephkyari


From deepayan at stat.wisc.edu  Fri Apr 25 18:33:19 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 25 Apr 2003 11:33:19 -0500
Subject: [R] Posix data in Lattice
In-Reply-To: <2F3262756375D411B0CC00B0D049775DAFB367@westpark.tanox.net>
References: <2F3262756375D411B0CC00B0D049775DAFB367@westpark.tanox.net>
Message-ID: <200304251133.19594.deepayan@stat.wisc.edu>

On Friday 25 April 2003 08:21 am, Shawn Way wrote:
> I have a number of plots that I'm trying to do using the lattice package,
> unfortunately, they involve Posix values.
>
> A small sample of the data is as follows:
>
>                    Time   TC.1  <Snipped>
> 1   2003-04-24 13:29:15  26.61
> 2   2003-04-24 13:29:30  26.48
> 3   2003-04-24 13:30:00  26.53
> 4   2003-04-24 13:30:30  27.85
> <Snipped>
>
> where
>
> str(data)
> `data.frame':	415 obs. of  22 variables:
>  $ Time :`POSIXlt', format: chr  "2003-04-24 13:29:15" "2003-04-24
> 13:29:30" "2003-04-24 13:30:00" "2003-04-24 13:30:30" ...
>  $ TC.1 : num   26.6  26.5  26.5  27.9 100.0 ...
> <Snipped>
>
> What I'm trying to do is plot TC.1 vs Time (which I can do easily), but I
> need the xaxis to represent the Time instead of a numeric such as
> 105121000,etc.

Try converting Time to POSIXct and use it normally in a lattice call (maybe 
lattice should do the conversion itself). This should display the times 
properly, however, the formatting definitely needs some improvement.

Let me know if this doesn't solve your problem.

Deepayan


From J.Illian at abertay.ac.uk  Fri Apr 25 18:32:35 2003
From: J.Illian at abertay.ac.uk (J.Illian@abertay.ac.uk)
Date: Fri, 25 Apr 2003 17:32:35 +0100
Subject: [R] stepwise discriminant analysis
Message-ID: <F934BF2710426B44833B8677AF47F246748728@mail3.tay.ac.uk>

Hi all,
some days ago I sent off a query on stepwise discriminat analysis and hardly
got any reply. That's why I am trying this again now. I probably wasn;t
specific enough the last time I did it.

I now about the step function for glm etc. and I also know how to do
discriminat analysis in R but I was wondering whether there is an equivalent
of the step funcion for dicrimant analysis models?

Any help would be very much appreciated.

Thanks

Janine

------------------------------------------
Janine Illian
lecturer in statistics
SIMBIOS
School of Computing and Advanced Technologies
University of Abertay Dundee
Bell Street
Dundee, DD1 1HG 
Scotland, UK
Tel: +44-(0)1382-308488
Fax: +44-(0)1382-308537


From tblackw at umich.edu  Fri Apr 25 19:12:12 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Fri, 25 Apr 2003 13:12:12 -0400 (EDT)
Subject: [R] 
In-Reply-To: <4521.136.145.154.108.1051287037.squirrel@math.uprm.edu>
Message-ID: <Pine.SOL.4.44.0304251309570.19028-100000@tetris.gpcc.itd.umich.edu>

Probably you've already found the function  step()  in the base
package, and its sub-functions  add1(), drop1().  See the help
for these.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 25 Apr 2003 edgar at uprm.edu wrote:

> Hello,
> Does anybody know where I can find an R function to carry out variable
> selection using stepwise similar (or even better) to the stepwise function
> available in S-Plus?. I have tried the mle.stepwise function available in
> the wle package but I am not getting accurate results.
> I have tried also the leaps package but it does not handle the options
> f-in and f-out like in either MINITAB or SAS.
>
> Thanks in advance
>
> Dr. Edgar Acuna
> University of Puerto Rico at Mayaguez


From ripley at stats.ox.ac.uk  Fri Apr 25 19:19:15 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 25 Apr 2003 18:19:15 +0100 (BST)
Subject: [R] stepwise discriminant analysis
In-Reply-To: <F934BF2710426B44833B8677AF47F246748728@mail3.tay.ac.uk>
Message-ID: <Pine.LNX.4.44.0304251815420.20029-100000@gannet.stats>

On Fri, 25 Apr 2003 J.Illian at abertay.ac.uk wrote:

> Hi all,
> some days ago I sent off a query on stepwise discriminat analysis and hardly
> got any reply. That's why I am trying this again now. I probably wasn;t
> specific enough the last time I did it.
> 
> I now about the step function for glm etc. and I also know how to do
> discriminat analysis in R but I was wondering whether there is an equivalent
> of the step funcion for dicrimant analysis models?

Not that I know of.  If there were, it would not be what is usually known 
as `stepwise discriminant analysis', since that usually means a series of 
T tests, not selection by AIC.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From sway at tanox.com  Fri Apr 25 21:27:53 2003
From: sway at tanox.com (Shawn Way)
Date: Fri, 25 Apr 2003 14:27:53 -0500
Subject: [R] Rep command
Message-ID: <2F3262756375D411B0CC00B0D049775DAFB369@WESTPARK>

I'm trying to use the rep command to replicate a POSIX value, the result is
interesting, maybe a bug?

a <- data$Time[1]
> a
[1] "2003-04-24 13:29:15 Central Daylight Time"
> b <- rep(a,3)
> b
[1] 1051208955 1051208955 1051208955

> version
         _                           
platform i386-pc-mingw32             
arch     i386                        
os       mingw32                     
system   i386, mingw32               
status   Under development (unstable)
major    1                           
minor    7.0                         
year     2003                        
month    03                          
day      10                          
language R                           
> 

I couldn't find this in the bug reports, either...

Shawn Way
Engineering Manager


From john_hendrickx at yahoo.com  Fri Apr 25 21:38:58 2003
From: john_hendrickx at yahoo.com (John Hendrickx)
Date: Fri, 25 Apr 2003 12:38:58 -0700 (PDT)
Subject: [R] Detailed contingency tables
In-Reply-To: <20030425120945.LGRR9300.mta04.mail.mel.aone.net.au@there>
Message-ID: <20030425193858.57460.qmail@web14208.mail.yahoo.com>


--- Jim Lemon <bitwrit at ozemail.com.au> wrote:
> MZodet wrote:
> >
> > Is there any existing function for creating contingency tables
> that will
> > display counts, row, column, and cell percentages in the same
> > tables....anything similar to crosstabs in S? 
> 
> You might want to look at xtab() in "Kickstarting R" at:
> 
> http://cran.r-project.org
> 
> under Contributed Documentation.
> 
Try CrossTable in the package gregmisc


From Benjamin.STABLER at odot.state.or.us  Fri Apr 25 21:39:18 2003
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Fri, 25 Apr 2003 12:39:18 -0700
Subject: [R] Open an r+b file connection on Windows
Message-ID: <76A000A82289D411952F001083F9DD06047FE04B@exsalem4-bu.odot.state.or.us>

I am trying to open an existing binary file, seek to a position in the
middle, and then write one byte, while keeping the already existing data
after that byte.  It seems to me that I am unable to open a connection to a
binary file in both read and write mode.  I can open the "r+b" binary file
connection and seek around, but I can't write to the file.  And looking at
the function definition for writeBin, it seems that writeBin automatically
creates a connection of type "wb" not what is specified by the R file
object.  I am working on Windows Nt 4.0 with R 1.7.  Any ideas?  Thanks in
advance.

#Create file
x<-1:50
myfile <- file("test","wb")
writeBin(as.real(x),myfile, 4)
close(myfile)

myfile <- file("test","r+b")
myfile
description       class        mode        text      opened    can read
can write 
     "test"      "file"       "r+b"    "binary"    "opened"       "yes"
"no"  

seek(myfile,where=40,origin="start")
readBin(myfile, real(), 10, 4)
[1] 11 12 13 14 15 16 17 18 19 20

#Write the number 99 to file
seek(myfile,where=40,origin="start")
writeBin(as.real(99),myfile, 4)

Error in writeBin(as.real(99), myfile, 4) : 
        cannot write to this connection

Benjamin Stabler
Transportation Planning Analysis Unit
Oregon Department of Transportation
555 13th Street NE, Suite 2
Salem, OR 97301  Ph: 503-986-4104


From pingzhao at waffle.cs.dal.ca  Fri Apr 25 21:45:19 2003
From: pingzhao at waffle.cs.dal.ca (pingzhao)
Date: Fri, 25 Apr 2003 16:45:19 -0300
Subject: [R] plot clusters
Message-ID: <3EAE68C9@webmail.ucis.dal.ca>

Hi,

I have a dataset which has more than two clusters (say 3 clusters).
I used kmeans to cluster the dataset.

I am wondering how I can plot the clustering result on a two-dimensional
figure????

The example in the kmeans help file is as follows:

 x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
                matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2))
     cl <- kmeans(x, 2, 20)
     plot(x, col = cl$cluster)

It seems that this is only working for 2 clusters. When my dataset has more
than two clusters, the plot results are obvious wrong.

Any suggestions to plot more than two clusters.

Thanks!!!


From ripley at stats.ox.ac.uk  Fri Apr 25 22:17:32 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 25 Apr 2003 21:17:32 +0100 (BST)
Subject: [R] Open an r+b file connection on Windows
In-Reply-To: <76A000A82289D411952F001083F9DD06047FE04B@exsalem4-bu.odot.state.or.us>
Message-ID: <Pine.LNX.4.44.0304252104240.22726-100000@gannet.stats>

On Fri, 25 Apr 2003 Benjamin.STABLER at odot.state.or.us wrote:

> I am trying to open an existing binary file, seek to a position in the
> middle, and then write one byte, while keeping the already existing data
> after that byte.  It seems to me that I am unable to open a connection to a
> binary file in both read and write mode.  I can open the "r+b" binary file
> connection and seek around, but I can't write to the file.  And looking at
> the function definition for writeBin, it seems that writeBin automatically
> creates a connection of type "wb" not what is specified by the R file
> object.  

Only if con is a character string, which it is not here ....

> I am working on Windows Nt 4.0 with R 1.7.  Any ideas?  Thanks in
> advance.
> 
> #Create file
> x<-1:50
> myfile <- file("test","wb")
> writeBin(as.real(x),myfile, 4)
> close(myfile)
> 
> myfile <- file("test","r+b")
> myfile
> description       class        mode        text      opened    can read
> can write 
>      "test"      "file"       "r+b"    "binary"    "opened"       "yes"
> "no"  

That is what is wrong:  try w+b (it's a bug, and I've fixed it for
R-devel).

> seek(myfile,where=40,origin="start")
> readBin(myfile, real(), 10, 4)
> [1] 11 12 13 14 15 16 17 18 19 20
> 
> #Write the number 99 to file
> seek(myfile,where=40,origin="start")
> writeBin(as.real(99),myfile, 4)
> 
> Error in writeBin(as.real(99), myfile, 4) : 
>         cannot write to this connection

Did you mean to seek the *write* here: you seek-ed the read position and 
so wrote at the beginning?  R connections have separate read and write 
positions.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Benjamin.STABLER at odot.state.or.us  Fri Apr 25 22:32:43 2003
From: Benjamin.STABLER at odot.state.or.us (Benjamin.STABLER@odot.state.or.us)
Date: Fri, 25 Apr 2003 13:32:43 -0700
Subject: [R] Open an r+b file connection on Windows
Message-ID: <76A000A82289D411952F001083F9DD06047FE04C@exsalem4-bu.odot.state.or.us>

Professor Ripley,

Thanks for the quick response.  It is my understanding that "w+b" will open
a file for reading and writing but if a file with the same name already
exists then its contents are erased before the file is open.  So "w+b" is
not quite what I want.  I think I need "r+b".  And yes, I meant to seek the
*write* - sorry that I left off the rw argument to seek.  


Ben Stabler
Transportation Planning Analysis Unit
Oregon Department of Transportation
555 13th Street NE, Suite 2
Salem, OR 97301  Ph: 503-986-4104

>-----Original Message-----
>From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
>Sent: Friday, April 25, 2003 1:18 PM
>To: STABLER Benjamin
>Cc: r-help at stat.math.ethz.ch
>Subject: Re: [R] Open an r+b file connection on Windows
>
>
>On Fri, 25 Apr 2003 Benjamin.STABLER at odot.state.or.us wrote:
>
>> I am trying to open an existing binary file, seek to a 
>position in the
>> middle, and then write one byte, while keeping the already 
>existing data
>> after that byte.  It seems to me that I am unable to open a 
>connection to a
>> binary file in both read and write mode.  I can open the 
>"r+b" binary file
>> connection and seek around, but I can't write to the file.  
>And looking at
>> the function definition for writeBin, it seems that writeBin 
>automatically
>> creates a connection of type "wb" not what is specified by the R file
>> object.  
>
>Only if con is a character string, which it is not here ....
>
>> I am working on Windows Nt 4.0 with R 1.7.  Any ideas?  Thanks in
>> advance.
>> 
>> #Create file
>> x<-1:50
>> myfile <- file("test","wb")
>> writeBin(as.real(x),myfile, 4)
>> close(myfile)
>> 
>> myfile <- file("test","r+b")
>> myfile
>> description       class        mode        text      opened  
>  can read
>> can write 
>>      "test"      "file"       "r+b"    "binary"    "opened"  
>     "yes"
>> "no"  
>
>That is what is wrong:  try w+b (it's a bug, and I've fixed it for
>R-devel).
>
>> seek(myfile,where=40,origin="start")
>> readBin(myfile, real(), 10, 4)
>> [1] 11 12 13 14 15 16 17 18 19 20
>> 
>> #Write the number 99 to file
>> seek(myfile,where=40,origin="start")
>> writeBin(as.real(99),myfile, 4)
>> 
>> Error in writeBin(as.real(99), myfile, 4) : 
>>         cannot write to this connection
>
>Did you mean to seek the *write* here: you seek-ed the read 
>position and 
>so wrote at the beginning?  R connections have separate read and write 
>positions.
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From rpeng at stat.ucla.edu  Fri Apr 25 22:41:04 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Fri, 25 Apr 2003 13:41:04 -0700 (PDT)
Subject: [R] Rep command
In-Reply-To: <2F3262756375D411B0CC00B0D049775DAFB369@WESTPARK>
Message-ID: <Pine.GSO.4.10.10304251339310.23939-100000@quetelet.stat.ucla.edu>

That's not a bug, but the internal representation of the date as the
number of seconds since the beginning of 1970.  See ?DateTimeClasses.  I
guess rep coerces the argument to be numeric.

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Fri, 25 Apr 2003, Shawn Way wrote:

> I'm trying to use the rep command to replicate a POSIX value, the result is
> interesting, maybe a bug?
> 
> a <- data$Time[1]
> > a
> [1] "2003-04-24 13:29:15 Central Daylight Time"
> > b <- rep(a,3)
> > b
> [1] 1051208955 1051208955 1051208955
> 
> > version
>          _                           
> platform i386-pc-mingw32             
> arch     i386                        
> os       mingw32                     
> system   i386, mingw32               
> status   Under development (unstable)
> major    1                           
> minor    7.0                         
> year     2003                        
> month    03                          
> day      10                          
> language R                           
> > 
> 
> I couldn't find this in the bug reports, either...
> 
> Shawn Way
> Engineering Manager
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From tlumley at u.washington.edu  Sat Apr 26 00:19:32 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 25 Apr 2003 15:19:32 -0700 (PDT)
Subject: [R] Rep command
In-Reply-To: <Pine.GSO.4.10.10304251339310.23939-100000@quetelet.stat.ucla.edu>
Message-ID: <Pine.A41.4.44.0304251502020.196212-100000@homer06.u.washington.edu>

On Fri, 25 Apr 2003, Roger Peng wrote:

> That's not a bug, but the internal representation of the date as the
> number of seconds since the beginning of 1970.  See ?DateTimeClasses.  I
> guess rep coerces the argument to be numeric.
>

It's at least an infelicity (in Bill Venables' wonderful phrase) as there
is no way to recover the date without using the internal representation.
There isn't a simple fix, since rep() is not generic and it isn't
possible just to copy attributes over from the argument.

One general solution is to use rep() on a sequence of indexes into your
vector:

eg with a<-.leap.seconds

ind<-seq(length(a))
a[rep(ind,3)]
a[rep(ind,each=3)]
etc

and a special solution for converting numbers back into dates is to add
ISOdate(1970,1,1,hour=0).  It might be useful to have this as a variable,
something like

 .Epoch <- ISOdate(1970,1,1,hour=0)


	-thomas


From ibanez27 at inwind.it  Sat Apr 26 00:32:31 2003
From: ibanez27 at inwind.it (=?iso-8859-1?Q?Simona_Avanzo?=)
Date: Sat, 26 Apr 2003 00:32:31 +0200
Subject: [R] problem in a glm model.
Message-ID: <HDX7Y7$909739BCA8E8339FC66D1B83417BECD8@libero.it>

Hallo all, 

I have a problem in a glm model.

The glm model has, among the other variables, 4 dummy variables: 
flg.a2 (takes values 0 or 1) 
flg.d.na2 (takes values 0 or 1) 
flg.v2 (takes values 0 or 1) 
flg.cc2 (takes values 0 or 1) 
In addition to these variables, I have included their interaction, with the order:  
(flg.a2+flg.d.na2+flg.v2+flg.cc2)^2 

In the model?s summary there are not some interactions (flg.a2:flg.cc2 e flg.d.na2:flg.cc2), because there are not cases that present these interactions. 
Then, the model?s summary shows that the p-value of  the interaction flg.a2:flg.d.na2 is 0.66, and so this interaction can be eliminated. 
But when I apply the test anova between the model whit this interaction and the model without this interaction, the p-value is 0.004, and so, the interaction is significative. 
Why I obtain this difference?
Many thanks for any help, 

Simona


From lcoggins at usgs.gov  Sat Apr 26 00:45:13 2003
From: lcoggins at usgs.gov (Lewis G Coggins)
Date: Fri, 25 Apr 2003 15:45:13 -0700
Subject: [R] New user having problem with mcmc
Message-ID: <OF1B30E53F.60F58302-ON07256D13.007CD9EA@wr.usgs.gov>

I get the following error when I try to use mcmc.  It occurs at the end of
the first chain.

Error in cov(x.mon[2:m1, ] - x.mon[1:(m1 - 1), ]) :
        supply both x and y or a matrix-like x

Any ideas?

Thanks,

Lew


From ross at biostat.ucsf.edu  Sat Apr 26 00:49:55 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 25 Apr 2003 15:49:55 -0700
Subject: [R] Apparent namespace problem
Message-ID: <20030425224955.GC22596@epibiosun115-4.libaux.ucsf.edu>

I'm seeing some strange behavior while using the snow package for
networked computers.  I believe it's caused by name space resolution
issues, and would appreciate any suggestions tracking it down.

First, is there a way to find out what frame (as in frames in
environments, not data frames) a name is being obtained from or put
into?

Second, how closely does the evaluation environment in the
browser/debugger match what you would get in the function at the same
point?  I ask because if I evaluate a statement in the browser it
seems to work one way, but if I execute it it works another way.

The statement is
clusterEvalQ(cl, crossval.setup(x, y, groups, theta.fit,
theta.predict))

This evaluates the crossval.setup function across the cluster cl.

crossval.setup is a function which puts its arguments in a list g (a
local variable) and then does gcv <<- g.  The intent is to stuff the
data into a global variable for use by later function calls.

When I execute the statement interactively, even in the debugger in
the function that executes the statement, it seems to work.  But if it
executes in the function, gcv appears to remain unset.

I assume gcv is getting set in some other frame, but where it is and
how to track it down I don't know.

In an effort to get around this I did gcv <- list() in the global
namespace (on the distributed nodes), but this doesn't seem to help.
I'm just left with the empty list, even after calls to crossval.setup.

Any ideas?

Thanks.


From arrayprofile at yahoo.com  Sat Apr 26 02:44:14 2003
From: arrayprofile at yahoo.com (array chip)
Date: Fri, 25 Apr 2003 17:44:14 -0700 (PDT)
Subject: [R] PCA
Message-ID: <20030426004414.51033.qmail@web41210.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030425/42f5a5bd/attachment.pl

From andreww at cheque.uq.edu.au  Sat Apr 26 16:12:50 2003
From: andreww at cheque.uq.edu.au (Andrew C. Ward)
Date: Sat, 26 Apr 2003 14:12:50 -0000
Subject: [R] PCA
Message-ID: <01C30BFD.EC1F46D0.andreww@cheque.uq.edu.au>

What about trying a sub-set of the data?

Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



On Saturday, April 26, 2003 10:44 AM, array chip 
[SMTP:arrayprofile at yahoo.com] wrote:
> Hi, I have a dataset of dimensions 50 x 15000, and tried to use
> princomp or prcomp on this dataset with 15000 columns as
> variables, but it seems that the 2 functions can;t handle this
> large number of columns, anyone has nay suggestions to get
> around this? Thanks
>
>
> ---------------------------------
>
>
> 	[[alternate HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Sat Apr 26 06:13:34 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 25 Apr 2003 21:13:34 -0700
Subject: [R]
References: <Pine.SOL.4.44.0304251309570.19028-100000@tetris.gpcc.itd.umich.edu>
Message-ID: <3EAA076E.2010202@pdf.com>

stepAIC in MASS.

hope this helps.  spencer graves

Thomas W Blackwell wrote:
> Probably you've already found the function  step()  in the base
> package, and its sub-functions  add1(), drop1().  See the help
> for these.
> 
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -
> 
> On Fri, 25 Apr 2003 edgar at uprm.edu wrote:
> 
> 
>>Hello,
>>Does anybody know where I can find an R function to carry out variable
>>selection using stepwise similar (or even better) to the stepwise function
>>available in S-Plus?. I have tried the mle.stepwise function available in
>>the wle package but I am not getting accurate results.
>>I have tried also the leaps package but it does not handle the options
>>f-in and f-out like in either MINITAB or SAS.
>>
>>Thanks in advance
>>
>>Dr. Edgar Acuna
>>University of Puerto Rico at Mayaguez
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From skeens at NKU.EDU  Sat Apr 26 06:54:23 2003
From: skeens at NKU.EDU (Matt Skeen)
Date: Sat, 26 Apr 2003 00:54:23 -0400
Subject: [R] Graduate student survey
Message-ID: <417-22003462645423751@HP>

I am currently pursuing a Master of Public Administration degree at
Northern Kentucky University.  I am conducting a survey for a class in organizational theory.  The goal of the survey is to try to point out how employees in the public and private sectors are motivated differently, if at all.  Please take a moment to fill out my brief, anonymous survey at the following link.  The survey takes less than 5 minutes to complete.  The only qualification is that you be employed somewhere.  I apologize if you receive this request more than once.

Thank you for your time and opinions!

-Matt Skeen

SURVEY:
http://webpages.marshall.edu/~skeen2/survey.htm
 -OR-
http://www.nku.edu/~skeens/survey.htm

NOTE:
This research project and the survey it is based on has Institutional Review Board (IRB) approval at NKU.  If you don't know what this it, don't worry about it.


From ripley at stats.ox.ac.uk  Sat Apr 26 09:13:30 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 26 Apr 2003 08:13:30 +0100 (BST)
Subject: [R] PCA
In-Reply-To: <20030426004414.51033.qmail@web41210.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0304260757410.23555-100000@gannet.stats>

On Fri, 25 Apr 2003, array chip wrote:

> Hi, I have a dataset of dimensions 50 x 15000, and tried to use princomp
> or prcomp on this dataset with 15000 columns as variables, but it seems
> that the 2 functions can;t handle this large number of columns, anyone
> has nay suggestions to get around this? Thanks

Which version of R?

In the current version (1.7.0) princomp will complain if there are more
columns than rows, but prcomp will work.  (It ran for me in a few seconds
on a synthetic dataset of that size.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Sat Apr 26 09:26:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 26 Apr 2003 08:26:39 +0100 (BST)
Subject: [R] Problme with <<- (was Apparent namespace problem)
In-Reply-To: <20030425224955.GC22596@epibiosun115-4.libaux.ucsf.edu>
Message-ID: <Pine.LNX.4.44.0304260817030.23645-100000@gannet.stats>

On Fri, 25 Apr 2003, Ross Boylan wrote:

> I'm seeing some strange behavior while using the snow package for
> networked computers.  I believe it's caused by name space resolution
> issues, and would appreciate any suggestions tracking it down.

`namespace' is a technical term in R (some packages have namespaces), and
not I think involved here. I think you meant `scoping issues', although
the exact issue seems to be an inappropriate use of <<-.

> First, is there a way to find out what frame (as in frames in
> environments, not data frames) a name is being obtained from or put
> into?

?find.

> Second, how closely does the evaluation environment in the
> browser/debugger match what you would get in the function at the same
> point?  I ask because if I evaluate a statement in the browser it
> seems to work one way, but if I execute it it works another way.
> 
> The statement is
> clusterEvalQ(cl, crossval.setup(x, y, groups, theta.fit,
> theta.predict))
> 
> This evaluates the crossval.setup function across the cluster cl.
> 
> crossval.setup is a function which puts its arguments in a list g (a
> local variable) and then does gcv <<- g.  The intent is to stuff the
> data into a global variable for use by later function calls.

If that is the intention, please use assign() explicitly.  That is not
what <<- is intended to do in R and it probably should only be used to
change an already existing value somewhere in the environment tree.

assign("gcv", g, envir=NULL), I believe

[...]

I have ignored the `snow' aspect, as I don't understand enough of how you 
are using it: it might be relevant.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jmagalhaes at oninetspeed.pt  Sat Apr 26 11:06:27 2003
From: jmagalhaes at oninetspeed.pt (Jorge =?iso-8859-15?q?Magalh=E3es?=)
Date: Sat, 26 Apr 2003 10:06:27 +0100
Subject: [R] array to data.frame
Message-ID: <200304261006.27258.jmagalhaes@oninetspeed.pt>

Hi,

How i can convert a array in to data.frame structure?

For example,

vinteesete<-array(c(1,0,6,4,22,29,11,7,6,2,8,7,21,25,5,6,1,0,11,6,14,24,13,10,2,2,15,13,14,17,9,8,1,2,16,9,14,23,9,6,6,2,17,13,10,20,7,5), 
dim=c(2,4,6), dimnames=list(grupo=c("I","II"), 
opiniao=c("Ma","Regular","Boa","MBoa",), 
relacao=c("atencao","sensibilidade","compreensao","tertempo","ouvir","envolvencia")))

Thanks very much,

J. Magalh?es


From horevguy at post.tau.ac.il  Sat Apr 26 12:07:26 2003
From: horevguy at post.tau.ac.il (Guy Horev)
Date: Sat, 26 Apr 2003 12:07:26 +0200
Subject: [R] Building R-1.7.0 on cygwin
Message-ID: <3EAA5A5E.1020109@post.tau.ac.il>

Dear helpers

I tried to build R-1.7.0 on CygWin. the following errors apeared after 
'make check'

make[1]: Entering directory `/bin/R/R-1.7.0/tests'
make[2]: Entering directory `/bin/R/R-1.7.0/tests'
make[3]: Entering directory `/bin/R/R-1.7.0/tests/Examples'
make[4]: Entering directory `/bin/R/R-1.7.0/tests/Examples'
make[4]: `Makedeps' is up to date.
make[4]: Leaving directory `/bin/R/R-1.7.0/tests/Examples'
make[4]: Entering directory `/bin/R/R-1.7.0/tests/Examples'
make[4]: *** No rule to make target `../../bin/R.bin', needed by 
`base-Ex.Rout'.
  Stop.
make[4]: Leaving directory `/bin/R/R-1.7.0/tests/Examples'
make[3]: *** [test-Examples-Base] Error 2
make[3]: Leaving directory `/bin/R/R-1.7.0/tests/Examples'
make[2]: *** [test-Examples] Error 2
make[2]: Leaving directory `/bin/R/R-1.7.0/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/bin/R/R-1.7.0/tests'
make: *** [check] Error 2

Can you please explain what are Error 1 and Error 2?
 I know there are missing tex and Tcl/Tk packages on my CygWin installation
How should I proceed

10X
Guy


From Roger.Bivand at nhh.no  Sat Apr 26 11:42:51 2003
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 26 Apr 2003 11:42:51 +0200 (CEST)
Subject: [R] Building R-1.7.0 on cygwin
In-Reply-To: <3EAA5A5E.1020109@post.tau.ac.il>
Message-ID: <Pine.LNX.4.44.0304261132220.4096-100000@reclus.nhh.no>

On Sat, 26 Apr 2003, Guy Horev wrote:

> Dear helpers
> 
> I tried to build R-1.7.0 on CygWin. the following errors apeared after 
> 'make check'

From: http://www.stats.ox.ac.uk/pub/Rtools/ (entitled: "Building R for 
Windows"):

"Support for the Cygwin compiler suite has been withdrawn: it has 
perennially been broken in the -mno-cygwin mode used with R."

The portal gives comprehensive instructions for building R, with links to 
the tools needed. R built for Windows (including the binaries on CRAN) can 
be used from within cygwin if you like - including Rterm, but should be 
built following the standard instructions, which are based on a great deal 
of hard work and experience. Again, if you need to use R under cygwin, use 
the regular build.

> 
> make[1]: Entering directory `/bin/R/R-1.7.0/tests'
> make[2]: Entering directory `/bin/R/R-1.7.0/tests'
> make[3]: Entering directory `/bin/R/R-1.7.0/tests/Examples'
> make[4]: Entering directory `/bin/R/R-1.7.0/tests/Examples'
> make[4]: `Makedeps' is up to date.
> make[4]: Leaving directory `/bin/R/R-1.7.0/tests/Examples'
> make[4]: Entering directory `/bin/R/R-1.7.0/tests/Examples'
> make[4]: *** No rule to make target `../../bin/R.bin', needed by 
> `base-Ex.Rout'.

I think you will find traces of why the main R binary, R.bin, has not been 
made in the output from the ./configure and make steps.

>   Stop.
> make[4]: Leaving directory `/bin/R/R-1.7.0/tests/Examples'
> make[3]: *** [test-Examples-Base] Error 2
> make[3]: Leaving directory `/bin/R/R-1.7.0/tests/Examples'
> make[2]: *** [test-Examples] Error 2
> make[2]: Leaving directory `/bin/R/R-1.7.0/tests'
> make[1]: *** [test-all-basics] Error 1
> make[1]: Leaving directory `/bin/R/R-1.7.0/tests'
> make: *** [check] Error 2
> 
> Can you please explain what are Error 1 and Error 2?
>  I know there are missing tex and Tcl/Tk packages on my CygWin installation
> How should I proceed
> 
> 10X
> Guy
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Breiviksveien 40, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 93 93
e-mail: Roger.Bivand at nhh.no


From p.dalgaard at biostat.ku.dk  Sat Apr 26 12:15:06 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 26 Apr 2003 12:15:06 +0200
Subject: [R] array to data.frame
In-Reply-To: <200304261006.27258.jmagalhaes@oninetspeed.pt>
References: <200304261006.27258.jmagalhaes@oninetspeed.pt>
Message-ID: <x2el3psgyd.fsf@biostat.ku.dk>

Jorge Magalh?es <jmagalhaes at oninetspeed.pt> writes:

> Hi,
> 
> How i can convert a array in to data.frame structure?
> 
> For example,
> 
> vinteesete<-array(c(1,0,6,4,22,29,11,7,6,2,8,7,21,25,5,6,1,0,11,6,14,24,13,10,2,2,15,13,14,17,9,8,1,2,16,9,14,23,9,6,6,2,17,13,10,20,7,5), 
> dim=c(2,4,6), dimnames=list(grupo=c("I","II"), 
> opiniao=c("Ma","Regular","Boa","MBoa",), 
> relacao=c("atencao","sensibilidade","compreensao","tertempo","ouvir","envolvencia")))

as.data.frame(as.table(vinteesete))

(or as.data.frame.table(vinteesete), but with S4 methods coming in it
is increasingly considered bad style to apply methods to objects that
are not of the requisite class.)

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From mt at michaelltaylor.com  Sat Apr 26 14:11:15 2003
From: mt at michaelltaylor.com (michaell taylor)
Date: 26 Apr 2003 08:11:15 -0400
Subject: [R] predict/residual
Message-ID: <1051359075.16491.45.camel@xeon>

I am having trouble understanding the way naresid is used when using
predict/residual in a new data frame. 

>From the example below, the NAs are displayed when predicting inside the
original frame, but are dropped when applied to a new frame.

ultimately I need to cbind the residuals and predictions to a dataframe.
Any help would be appreciated. Thanks in advance.

> a_data.frame(y=rnorm(10),x=rnorm(10))
> m<- lm(y~x,data=a,na.action=na.exclude)
> a_data.frame(y=rnorm(10),x=rnorm(10))


# CREATE A MISSING VALUE
> a[5,2]<-NA
> m<- lm(y~x,data=a,na.action=na.exclude)
> predict(m)
         1          2          3          4          5         
6          7 
 0.9152478  1.5665630  1.1444221  0.4781361         NA  0.1659269 
0.6856764 
         8          9         10 
 1.5615913 -0.1687372  0.4164926 

# MAKE A COPY OF A, THEN CHANGE A COUPLE OF VALUES
> b<-a
> b[1,2]<-NA
> b[3,2] <-100 # just to make sure the correct frame is used
> predict(m,b)
          2           3           4           6           7           8 
  1.5665630 -44.9938287   0.4781361   0.1659269   0.6856764   1.5615913 
          9          10 
 -0.1687372   0.4164926 
> 
#  THE PROBLEM IS OF COURSE THAT I NO LONGER HAVE APPROPRIATE MISSING
VALUES IN THE VECTOR - obs 1 and 5 are no-shows.


Michaell


From ndey00 at yahoo.com  Sat Apr 26 14:56:59 2003
From: ndey00 at yahoo.com (N Dey)
Date: Sat, 26 Apr 2003 05:56:59 -0700 (PDT)
Subject: [R] Multiple Integration
Message-ID: <20030426125659.8825.qmail@web41310.mail.yahoo.com>

Dear all,

May I do multiple integration using R? I was looking
adapt but it is saying it integrates a scalar function
over a multidimensional rectangle. I have integrand of
several variable and upper, lower limit too variable.

I wanted to see the result using adapt (though it is
not for this purpose, I suppose)

Func<-function(x){(x[1]*x[2])}
adapt(2, lo=c(0,1), up=c(1,x[1]), functn=Func)

it is not giving any error(it should, if it is not the
correct way of putting up) but also not giving correct
result.

Is there any package to handle multiple integration in
R??

Thanking you,
with best regards,
N. Dey


From ripley at stats.ox.ac.uk  Sat Apr 26 15:03:08 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 26 Apr 2003 14:03:08 +0100 (BST)
Subject: [R] predict/residual
In-Reply-To: <1051359075.16491.45.camel@xeon>
Message-ID: <Pine.LNX.4.44.0304261351470.27248-100000@gannet.stats>

On 26 Apr 2003, michaell taylor wrote:

> I am having trouble understanding the way naresid is used when using
> predict/residual in a new data frame. 

[From the example, for an lm fit, and for predict: you cannot use 
`residual in a new data frame'.]

It isn't: what makes you think otherwise?  naresid is *never* used for 
prediction, and napredict is only used for predictions on the fitted data 
set.

I think you want to set na.action=na.pass whilst making your predictions,
which you will have to do via options() as predict.lm uses the default, 
na.omit.  (I would call that a design error in predict.lm: some other 
predict methods handle this better.)

BTW `_' is stringly deprecated, and defunct in R-devel.

> 
> >From the example below, the NAs are displayed when predicting inside the
> original frame, but are dropped when applied to a new frame.
> 
> ultimately I need to cbind the residuals and predictions to a dataframe.
> Any help would be appreciated. Thanks in advance.
> 
> > a_data.frame(y=rnorm(10),x=rnorm(10))
> > m<- lm(y~x,data=a,na.action=na.exclude)
> > a_data.frame(y=rnorm(10),x=rnorm(10))
> 
> 
> # CREATE A MISSING VALUE
> > a[5,2]<-NA
> > m<- lm(y~x,data=a,na.action=na.exclude)
> > predict(m)
>          1          2          3          4          5         
> 6          7 
>  0.9152478  1.5665630  1.1444221  0.4781361         NA  0.1659269 
> 0.6856764 
>          8          9         10 
>  1.5615913 -0.1687372  0.4164926 
> 
> # MAKE A COPY OF A, THEN CHANGE A COUPLE OF VALUES
> > b<-a
> > b[1,2]<-NA
> > b[3,2] <-100 # just to make sure the correct frame is used
> > predict(m,b)
>           2           3           4           6           7           8 
>   1.5665630 -44.9938287   0.4781361   0.1659269   0.6856764   1.5615913 
>           9          10 
>  -0.1687372   0.4164926 
> > 
> #  THE PROBLEM IS OF COURSE THAT I NO LONGER HAVE APPROPRIATE MISSING
> VALUES IN THE VECTOR - obs 1 and 5 are no-shows.
> 
> 
> Michaell
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From spencer.graves at pdf.com  Sat Apr 26 16:34:49 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 26 Apr 2003 07:34:49 -0700
Subject: [R] PCA
References: <01C30BFD.EC1F46D0.andreww@cheque.uq.edu.au>
Message-ID: <3EAA9909.8090404@pdf.com>

I think you can get what you want with the "svd" or "La.svd".  Consider 
the following:

	  The singular value decomposition ("svd" or "La.svd" in R 1.6.2) is 
something like the following:  Any n x m matrix A can be written in the 
following format:

	 A = P Lam Q,

where P and Q are orthogonal, and Lam ia diagonal.  If n < m, then we 
can consider P to be n x n, so P'P = PP' = I, Lam = n x n diagonal, and 
Q = n x m with QQ' = I.

	  Now suppose A = your data matrix minus the column means.  Then the 
sample covariance matrix, Var.A, can be written as follows:

	Var.A = AA'/(n-1) = P Lam^2 P' / (n-1).

P gives the principle components and Q the corresponding loadings or 
vice versa, I forget which now, and Lam^2/(n-1) are their associated 
variances.

If you have trouble with the details, please let us know.

hope this helps. spencer graves

Andrew C. Ward wrote:
> What about trying a sub-set of the data?
> 
> Regards,
> 
> Andrew C. Ward
> 
> CAPE Centre
> Department of Chemical Engineering
> The University of Queensland
> Brisbane Qld 4072 Australia
> andreww at cheque.uq.edu.au
> 
> 
> 
> On Saturday, April 26, 2003 10:44 AM, array chip 
> [SMTP:arrayprofile at yahoo.com] wrote:
> 
>>Hi, I have a dataset of dimensions 50 x 15000, and tried to use
>>princomp or prcomp on this dataset with 15000 columns as
>>variables, but it seems that the 2 functions can;t handle this
>>large number of columns, anyone has nay suggestions to get
>>around this? Thanks
>>
>>
>>---------------------------------
>>
>>
>>	[[alternate HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Sat Apr 26 16:38:31 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 26 Apr 2003 07:38:31 -0700
Subject: [R] array to data.frame
References: <200304261006.27258.jmagalhaes@oninetspeed.pt>
	<x2el3psgyd.fsf@biostat.ku.dk>
Message-ID: <3EAA99E7.5080306@pdf.com>

Dear Peter:

Does the following not work in certain situations:

A <- array(1:4, dim=c(2,2))
dimnames(A) <- list(NULL, c("a", "b"))
as.data.frame(A)

Or is it deprecated for other reasons?

Thanks,
Spencer Graves

Peter Dalgaard BSA wrote:
> Jorge Magalh?es <jmagalhaes at oninetspeed.pt> writes:
> 
> 
>>Hi,
>>
>>How i can convert a array in to data.frame structure?
>>
>>For example,
>>
>>vinteesete<-array(c(1,0,6,4,22,29,11,7,6,2,8,7,21,25,5,6,1,0,11,6,14,24,13,10,2,2,15,13,14,17,9,8,1,2,16,9,14,23,9,6,6,2,17,13,10,20,7,5), 
>>dim=c(2,4,6), dimnames=list(grupo=c("I","II"), 
>>opiniao=c("Ma","Regular","Boa","MBoa",), 
>>relacao=c("atencao","sensibilidade","compreensao","tertempo","ouvir","envolvencia")))
> 
> 
> as.data.frame(as.table(vinteesete))
> 
> (or as.data.frame.table(vinteesete), but with S4 methods coming in it
> is increasingly considered bad style to apply methods to objects that
> are not of the requisite class.)
>


From spencer.graves at pdf.com  Sat Apr 26 16:46:28 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 26 Apr 2003 07:46:28 -0700
Subject: [R] Multiple Integration
References: <20030426125659.8825.qmail@web41310.mail.yahoo.com>
Message-ID: <3EAA9BC4.60101@pdf.com>

	  Have you considered Monte Carlo integration?  If the function is 
bounded on the rectangular region of integration (or if its square is 
integrable), then you can generate N random points inside the rectangle, 
and evaluate the function at each point.  Their mean is the integral, 
and from their sample variance, you can get a confidence interval on 
that estimate.  With modern computers, you can get any degree of 
accuracy you want just by waiting longer.

	  You can improve on this using kernals, but I'm not familiar with 
those methods.

hope this helps.  spencer graves

N Dey wrote:
> Dear all,
> 
> May I do multiple integration using R? I was looking
> adapt but it is saying it integrates a scalar function
> over a multidimensional rectangle. I have integrand of
> several variable and upper, lower limit too variable.
> 
> I wanted to see the result using adapt (though it is
> not for this purpose, I suppose)
> 
> Func<-function(x){(x[1]*x[2])}
> adapt(2, lo=c(0,1), up=c(1,x[1]), functn=Func)
> 
> it is not giving any error(it should, if it is not the
> correct way of putting up) but also not giving correct
> result.
> 
> Is there any package to handle multiple integration in
> R??
> 
> Thanking you,
> with best regards,
> N. Dey
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From maechler at stat.math.ethz.ch  Sat Apr 26 18:30:22 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 26 Apr 2003 18:30:22 +0200
Subject: [R] array to data.frame
In-Reply-To: <3EAA99E7.5080306@pdf.com>
References: <200304261006.27258.jmagalhaes@oninetspeed.pt>
	<x2el3psgyd.fsf@biostat.ku.dk>
	<3EAA99E7.5080306@pdf.com>
Message-ID: <16042.46110.394229.912519@gargle.gargle.HOWL>


    Spencer> Dear Peter:
    Spencer> Does the following not work in certain situations:

    Spencer> A <- array(1:4, dim=c(2,2))
    Spencer> dimnames(A) <- list(NULL, c("a", "b"))
    Spencer> as.data.frame(A)

Of course,  array -> data.frame is trivial for 2-dim arrays aka
matrices.  But Jorge had a 3-dim. array (of a special type,
namely a contingency table!) for which Peter gave the solution.

For most other 3-or-more-dim.arrays, there's no corresponding
data frame structure I can think of.

    Spencer> Or is it deprecated for other reasons?

    Spencer> Thanks,
    Spencer> Spencer Graves

Peter Dalgaard BSA wrote:
> Jorge Magalh?es <jmagalhaes at oninetspeed.pt> writes:
> 
> 
>>Hi,
>>
>>How i can convert a array in to data.frame structure?
>>
>>For example,
>>
>>vinteesete<-array(c(1,0,6,4,22,29,11,7,6,2,8,7,21,25,5,6,1,0,11,6,14,24,13,10,2,2,15,13,14,17,9,8,1,2,16,9,14,23,9,6,6,2,17,13,10,20,7,5), 
>>dim=c(2,4,6), dimnames=list(grupo=c("I","II"), 
>>opiniao=c("Ma","Regular","Boa","MBoa",), 
>>relacao=c("atencao","sensibilidade","compreensao","tertempo","ouvir","envolvencia")))
> 
> 
> as.data.frame(as.table(vinteesete))
> 
> (or as.data.frame.table(vinteesete), but with S4 methods coming in it
> is increasingly considered bad style to apply methods to objects that
> are not of the requisite class.)
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From maechler at stat.math.ethz.ch  Sat Apr 26 18:43:00 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 26 Apr 2003 18:43:00 +0200
Subject: [R] plot clusters
In-Reply-To: <3EAE68C9@webmail.ucis.dal.ca>
References: <3EAE68C9@webmail.ucis.dal.ca>
Message-ID: <16042.46868.653311.930418@gargle.gargle.HOWL>

>>>>> "pingzhao" == pingzhao  <pingzhao at waffle.cs.dal.ca>
>>>>>     on Fri, 25 Apr 2003 16:45:19 -0300 writes:

    pingzhao> Hi,
    pingzhao> I have a dataset which has more than two clusters (say 3 clusters).
    pingzhao> I used kmeans to cluster the dataset.

    pingzhao> I am wondering how I can plot the clustering result on a two-dimensional
    pingzhao> figure????

    pingzhao> The example in the kmeans help file is as follows:

    pingzhao> x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
    pingzhao>            matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2))
    pingzhao> cl <- kmeans(x, 2, 20)
    pingzhao> plot(x, col = cl$cluster)

    pingzhao> It seems that this is only working for 2 clusters. When my dataset has more
    pingzhao> than two clusters, the plot results are obvious wrong.

Huh?!
Probably the clustering (method) wasn't what you expected, 
but the plot results are obviously correct!

 x3 <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
	     matrix(rnorm(100, mean = 1,  sd = 0.3), ncol = 2),
	     matrix(rnorm(100, mean = 1.8, sd = 0.3), ncol = 2))
 cl3 <- kmeans(x3, 3, 20)
 plot(x3, col = cl3$cluster)

## or even more clear, and also usable on black & white :

 plot(x3, col = cl3$cluster, pch = cl3$cluster)

-----

The much more interesting question is what to do when `x' has
more than two *dimensions*.
The easiest is to then plot on the first two principal
components, but I'm sure Christian Hennig will tell about much
more sophisticated solutions coming Monday...

Regards,
Martin


From chrysopa at insecta.ufv.br  Sat Apr 26 19:18:38 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Sat, 26 Apr 2003 14:18:38 -0300
Subject: [R] Help to make a program
Message-ID: <200304261418.39762.chrysopa@insecta.ufv.br>

Hi all,

I try to make a program for comparison between matrix cells.

Here um simple example:

3 |a b a
2 |b b b
1 |a b a
  -------
   1 2 3

This is tabulated like this:

x y sp
1 1 a
1 2 b
1 3 a
2 1 b
2 2 b
2 3 b
3 1 a
3 2 b
3 3 a

Then, I need to make the follow calcule:

==============================================
Change in sp levels from 1x1 area to 2x2 area:
----------------------------------------------
from (1:1) to (1:2) change of the "a" to "b"
change count = 1

from (1:1) to (2:2) change of the "a" to "b"
change count = 1

from (1:1) to (2:1) change of the "a" to "b"
change count = 1
----------------------------------------------
Total change counts = 3
==============================================

==============================================
Change in sp levels from 2x2 area to 3x3 area:
----------------------------------------------
from (1:2) to (1:3) change of the "b" to "a"
change count = 1

from (1:2) to (2:3) change of the "b" to "b" (not change)
change count = 0

from (2:2) to (1:3) change of the "b" to "a"
change count = 1

from (2:2) to (2:3) change of the "b" to "b"
change count = 0

from (2:2) to (3:3) change of the "b" to "a"
change count = 1

from (2:2) to (3:2) change of the "b" to "b"
change count = 0

from (2:2) to (3:1) change of the "b" to "a"
change count = 1
----------------------------------------------
Total change counts = 4
==============================================

The result is a table like this

area changecounts
1      0
4      3
9      4

Anybody have any idea for solve this?

Any sugestions?

Thanks for all

Ronaldo






-- 
Before destruction a man's heart is haughty, but humility goes before honour.
		-- Psalms 18:12
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From shutnik_xx at yahoo.co.uk  Sat Apr 26 20:15:21 2003
From: shutnik_xx at yahoo.co.uk (=?iso-8859-1?q?Shutnik?=)
Date: Sat, 26 Apr 2003 19:15:21 +0100 (BST)
Subject: [R] R help
Message-ID: <20030426181521.10083.qmail@web10907.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030426/ea598805/attachment.pl

From spencer.graves at pdf.com  Sat Apr 26 20:40:08 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 26 Apr 2003 11:40:08 -0700
Subject: [R] R help
References: <20030426181521.10083.qmail@web10907.mail.yahoo.com>
Message-ID: <3EAAD288.3040809@pdf.com>

 > Var <- array(c(4, 1, 1, 4), dim=c(2,2))
 > Sd <- sqrt(diag(Var))
 > Var/outer(Sd, Sd)
      [,1] [,2]
[1,] 1.00 0.25
[2,] 0.25 1.00

hope this helps.  spencer graves

Shutnik wrote:
> Hi, How to convert a var-covar matrix to correlation matrix. Thanks
> 
> 
> 
> ---------------------------------
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From pburns at pburns.seanet.com  Sat Apr 26 22:44:40 2003
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 26 Apr 2003 20:44:40 +0000
Subject: [R] R help
References: <20030426181521.10083.qmail@web10907.mail.yahoo.com>
	<3EAAD288.3040809@pdf.com>
Message-ID: <3EAAEFB8.9020709@pburns.seanet.com>

If the variance matrix is large, then

t(Var / Sd) / Sd

is probably more efficient.

Patrick Burns

Burns Statistics
patrick at burns-stat.com
+44 (0) 208 525 0696
http://www.burns-stat.com/  
(home of S Poetry and "A Guide for the Unwilling S User")

Spencer Graves wrote:

> > Var <- array(c(4, 1, 1, 4), dim=c(2,2))
> > Sd <- sqrt(diag(Var))
> > Var/outer(Sd, Sd)
>      [,1] [,2]
> [1,] 1.00 0.25
> [2,] 0.25 1.00
>
> hope this helps.  spencer graves
>
> Shutnik wrote:
>
>> Hi, How to convert a var-covar matrix to correlation matrix. Thanks
>>
>>
>>
>> ---------------------------------
>>
>>
>>     [[alternate HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>


From jfox at mcmaster.ca  Sat Apr 26 21:53:53 2003
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 26 Apr 2003 15:53:53 -0400
Subject: [R] new package: effects
Message-ID: <5.1.0.14.2.20030426155142.01e2de28@mcmail.cis.mcmaster.ca>

I've uploaded to CRAN a new package called effects. The package contains 
functions for tabular or graphical display of terms in a linear or 
generalized linear model, and is particularly suitable for models that 
contain terms -- such as main effects and interactions, or polynomial 
regressors -- related by marginality (hierarchy). A draft paper describing 
the package is located at 
<http://www.socsci.mcmaster.ca/jfox/Papers/effect-displays.pdf>.

John
-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox


From highstat at highstat.com  Sun Apr 27 00:48:14 2003
From: highstat at highstat.com (Alain Zuur)
Date: Sat, 26 Apr 2003 23:48:14 +0100
Subject: [R] R interface
Message-ID: <5.2.0.9.2.20030426234544.0200bc20@mail.highstat.com>

We would like to announce version 2.0.8 of Brodgar.

Software Package for Multivariate Analysis and Multivariate Time Series 
Analysis

NEW: INTERFACE TO R SOFTWARE

Examples:
http://www.brodgar.com/brodgarandr.htm
and
http://www.brodgar.com/ordination.htm
http://www.brodgar.com/timeseries.htm


Key phrases:
Interface to R, dynamic factor analysis, MAFA, (partial) canonical
correspondence analysis, discriminant analysis, (partial) redundancy
analysis, variance partitioning, principal component analysis, factor
analysis, correspondence analysis, multidimensional scaling, index
functions, structural time series, boxplots, dotplots, lattice graphs,
conditional boxplots, coplots, histograms, pairplots, linear
regression, generalised additive modelling (GAM), generalised linear modelling
(GLM), partial linear regression, regression trees, clustering.


Kind regards,

Highland Statistics Ltd.
http://www.brodgar.com


From ozric at web.de  Sun Apr 27 01:00:46 2003
From: ozric at web.de (Christian Schulz)
Date: Sun, 27 Apr 2003 01:00:46 +0200
Subject: [R] polymars
Message-ID: <000a01c30c47$ac5af7c0$8408ebd9@pc>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030427/871d199c/attachment.pl

From Art.tautz at gems2.gov.bc.ca  Sun Apr 27 01:41:22 2003
From: Art.tautz at gems2.gov.bc.ca (Tautz, Art WLAP:EX)
Date: Sat, 26 Apr 2003 16:41:22 -0700
Subject: [R] Windows metafiles from lattice plots
Message-ID: <B24A7581D0A70C4C98E8E9862F89F9CB02AF554D@guide.gov.bc.ca>

Could  someone please tell me if it is possible to automate the production
of a series of windows metafiles for each page of a multipage trellis plot?
The problem is  that I have a number of conditioned plots, each  consisting
of 1-30 individual conditioned regressions for each of 20-30 subsets of a
factor. The graphics work as expected, with each page consistent with the
layout specified for each factor.   However, if I attempt to automate the
creation  of a wmf for each page, I only get a portion of the output. 

Any help would be greatly appreciated 

Art Tautz


From tord.snall at ebc.uu.se  Sun Apr 27 15:42:34 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Sun, 27 Apr 2003 15:42:34 +0200
Subject: [R] no response of the tab key
Message-ID: <3.0.6.32.20030427154234.00dcaaa0@mail.anst.uu.se>

Dear all,
I want to produce a tab separated text file but R 1.6.2 does not respond to
the tab key on my keyboard. 

When I paste:
write.table(alla.obt.rar0, "obt.txt", sep="	", quote=F, row.names=F)

into the console it looks like this:

write.table(alla.obt.rar0, "obt.txt", sep="", quote=F, row.names=F)

Has anyone had a similar problem? 

I use Win Xp on a Dell machine.


Thanks in advance!


Sincerely,
Tord

-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!


From Philippe.Hupe at wanadoo.fr  Sun Apr 27 18:00:38 2003
From: Philippe.Hupe at wanadoo.fr (=?ISO-8859-1?Q?Philippe_Hup=E9?=)
Date: Sun, 27 Apr 2003 17:00:38 +0100
Subject: [R] no response of the tab key
In-Reply-To: <3.0.6.32.20030427154234.00dcaaa0@mail.anst.uu.se>
References: <3.0.6.32.20030427154234.00dcaaa0@mail.anst.uu.se>
Message-ID: <3EABFEA6.6060408@wanadoo.fr>

try :

write.table(alla.obt.rar0, "obt.txt", sep="\t", quote=F, row.names=F)





Tord Snall wrote:

>Dear all,
>I want to produce a tab separated text file but R 1.6.2 does not respond to
>the tab key on my keyboard. 
>
>When I paste:
>write.table(alla.obt.rar0, "obt.txt", sep="	", quote=F, row.names=F)
>
>into the console it looks like this:
>
>write.table(alla.obt.rar0, "obt.txt", sep="", quote=F, row.names=F)
>
>Has anyone had a similar problem? 
>
>I use Win Xp on a Dell machine.
>
>
>Thanks in advance!
>
>
>Sincerely,
>Tord
>
>-----------------------------------------------------------------------
>Tord Sn?ll
>Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
>Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
>Villav?gen 14			
>SE-752 36 Uppsala, Sweden
>Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
>Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
>Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
>E-mail: Tord.Snall at ebc.uu.se
>Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>
>.
>
>  
>


From sundar.dorai-raj at pdf.com  Sun Apr 27 16:00:41 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Sun, 27 Apr 2003 09:00:41 -0500
Subject: [R] Windows metafiles from lattice plots
References: <B24A7581D0A70C4C98E8E9862F89F9CB02AF554D@guide.gov.bc.ca>
Message-ID: <3EABE289.2070901@pdf.com>



Tautz, Art WLAP:EX wrote:
> Could  someone please tell me if it is possible to automate the production
> of a series of windows metafiles for each page of a multipage trellis plot?
> The problem is  that I have a number of conditioned plots, each  consisting
> of 1-30 individual conditioned regressions for each of 20-30 subsets of a
> factor. The graphics work as expected, with each page consistent with the
> layout specified for each factor.   However, if I attempt to automate the
> creation  of a wmf for each page, I only get a portion of the output. 
> 
> Any help would be greatly appreciated 
> 
> Art Tautz
> 

How about this?

library(lattice)

set.seed(100)
dframe <- data.frame(y = rnorm(100),
                      x = rnorm(100),
                      g = rep(1:4, 25))
win.metafile(width = 10,
              height = 7.5,
              file = "rplot%02d.wmf")
lset(col.whitebg())
print(xyplot(y ~ x | g,
              data = dframe,
              layout = c(1, 1)))
dev.off()

regards,
sundar


From sundar.dorai-raj at pdf.com  Sun Apr 27 16:04:26 2003
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Sun, 27 Apr 2003 09:04:26 -0500
Subject: [R] no response of the tab key
References: <3.0.6.32.20030427154234.00dcaaa0@mail.anst.uu.se>
Message-ID: <3EABE36A.606@pdf.com>



Tord Snall wrote:
> Dear all,
> I want to produce a tab separated text file but R 1.6.2 does not respond to
> the tab key on my keyboard. 
> 
> When I paste:
> write.table(alla.obt.rar0, "obt.txt", sep="	", quote=F, row.names=F)
> 
> into the console it looks like this:
> 
> write.table(alla.obt.rar0, "obt.txt", sep="", quote=F, row.names=F)
> 
> Has anyone had a similar problem? 
> 
> I use Win Xp on a Dell machine.
> 
> 


Use sep="\t" to insert tabs.

regards,
sundar


From tord.snall at ebc.uu.se  Sun Apr 27 16:15:02 2003
From: tord.snall at ebc.uu.se (Tord Snall)
Date: Sun, 27 Apr 2003 16:15:02 +0200
Subject: [R] Thanks for: no response of the tab key
Message-ID: <3.0.6.32.20030427161502.00e18330@mail.anst.uu.se>

Dear G?tz Wiegand and Corey Moffet,

Thanks for answering while I went to get a cup of coffee. This list is
really excellent!

The answer, for you other beginners, is 

in R a tab is represented "\t"

Tord


>
>Dear all,
>I want to produce a tab separated text file but R 1.6.2 does not respond to
>the tab key on my keyboard. 
>
>When I paste:
>write.table(alla.obt.rar0, "obt.txt", sep="	", quote=F, row.names=F)
>
>into the console it looks like this:
>
>write.table(alla.obt.rar0, "obt.txt", sep="", quote=F, row.names=F)
>
>Has anyone had a similar problem? 
>
>I use Win Xp on a Dell machine.
>
>
>Thanks in advance!
>
>
>Sincerely,
>Tord

-----------------------------------------------------------------------
Tord Sn?ll
Avd. f v?xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav?gen 14			
SE-752 36 Uppsala, Sweden
Tel: 018-471 28 82 (int +46 18 471 28 82) (work)
Tel: 018-25 71 33 (int +46 18 25 71 33) (home)
Fax: 018-55 34 19 (int +46 18 55 34 19) (work)
E-mail: Tord.Snall at ebc.uu.se
Check this: http://www.vaxtbio.uu.se/resfold/snall.htm!


From xiao.gang.fan1 at libertysurf.fr  Sun Apr 27 18:14:28 2003
From: xiao.gang.fan1 at libertysurf.fr (=?iso-8859-1?Q?Fan?=)
Date: Sun, 27 Apr 2003 18:14:28 +0200
Subject: [R] Basic date time arithmetics operations
Message-ID: <HE0FS4$2E3B89086EAFD45D4CD3E4E7428A22AD@tiscali.fr>

Hello,

For basic date time arithmetics operations, AFAK, there're 
actually the function difftime() and the (dt + num) operations.

I'm wondering if other basic operations exist, like
add(dt, num, unit) where unit would be "y", "q", "m", etc. 

Also for the function seq.dates (or seq.POSIXt), the 
case for by="months" would be more useful if it takes
the situation of the end of month into account. 
For example,

> seq(ISOdate(2002,1,31), by="months", length=3)

"2002-01-31 13:00:00 CET" 
"2002-03-03 13:00:00 CET" 
"2002-03-31 13:00:00 CET"

rather than

"2002-01-31 13:00:00 CET" 
"2002-02-28 13:00:00 CET" 
"2002-03-31 13:00:00 CET"

Thanks
--
Fan

************ VITE, C'EST LE MOMENT DE VOUS ABONNER A L'ADSL !!! **********
Du 3 avril au 5 mai, s?rie limit?e ADSL 128K, cliquez vite ici : http://register.tiscali.fr/adsl/ 
Offre promotionnelle soumise ? conditions, r?serv?e aux nouveaux abonn?s ADSL Tiscali.


From dmurdoch at pair.com  Sun Apr 27 19:01:35 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Sun, 27 Apr 2003 13:01:35 -0400
Subject: [R] Basic date time arithmetics operations
In-Reply-To: <HE0FS4$2E3B89086EAFD45D4CD3E4E7428A22AD@tiscali.fr>
References: <HE0FS4$2E3B89086EAFD45D4CD3E4E7428A22AD@tiscali.fr>
Message-ID: <et1oav4tpi8us0utkva12og7v5r5rs3pue@4ax.com>

On Sun, 27 Apr 2003 18:14:28 +0200, you wrote:

>Also for the function seq.dates (or seq.POSIXt), the 
>case for by="months" would be more useful if it takes
>the situation of the end of month into account. 
>For example,
>
>> seq(ISOdate(2002,1,31), by="months", length=3)
>
>"2002-01-31 13:00:00 CET" 
>"2002-03-03 13:00:00 CET" 
>"2002-03-31 13:00:00 CET"
>
>rather than
>
>"2002-01-31 13:00:00 CET" 
>"2002-02-28 13:00:00 CET" 
>"2002-03-31 13:00:00 CET"

I don't think that's a well-defined request.  What would you want from

 seq(ISOdate(2002,12,30), by="months", length=5)

Should it give February 27, since you asked for the day before the end
of the month?  What should it do in April?

I think the current behaviour is doing what it should doing.  If you
really want the last day of the month in three successive months, then
you should probably get a sequence of first days of months, and then
subtract a day from each.  Wish I could tell you how to do that!
Hopefully someone else will.

By the way, I noticed a typo in the help for difftime() (it was
missing an escape on one of the % signs, so the end of the line
disappeared), and I've committed a fix to R-patched.

Duncan Murdoch


From spencer.graves at pdf.com  Sun Apr 27 20:13:15 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 27 Apr 2003 11:13:15 -0700
Subject: [R] stepwise regression
References: <Pine.SOL.4.44.0304251309570.19028-100000@tetris.gpcc.itd.umich.edu>
Message-ID: <3EAC1DBB.6090001@pdf.com>

	  An incompletely debugged revision of the stepAIC function called 
"stepAIC.c" is available for downloading from "prodsyse.com".  This 
version allows three modifications of "stepAIC":

	  1.  It offers three different 'hierarchy' options:  'include', 
'exclude' and 'ignore'.  The 'include' option will test A^2 as 'A+A^2' 
with 2 degrees of freedom if a the linear term is not already in the 
model, with comparable adjustments for interactions and for backwards 
deletion.

	  2.  The use of "AIC.c" for model selection, following  Burnham and 
Anderson (2002) Model Selection and Multimodel Inference, 2nd ed. 
(Springer).

	  3.  The output includes an attribute "models" summarizing all the 
models fit sorted by the posterior probability that each model is the 
best to use given the available data assuming a uniform prior over all 
models tested.  If you assume that the "best" model will likely have 
either a dominant main effect or parabolic or two-factor interaction, 
then this should be equivalent to a posterior over all models in the 
specified scope.

	  This has been lightly tested with lm in S-Plus 6.1 and R 1.6.2.  It 
carries the standard GNU warranty, which is nothing.  I am actively 
working to improve this, and would appreciate your comments, questions, 
and suggestions.  However, I also have other commitments, so I can't 
promise to respond any more than I respond to "r-help".

	  I hope some of you find this useful -- and maybe get excited enough 
to improve it yourself.

Best Wishes,
Spencer Graves

################################
stepAIC in MASS.

hope this helps.  spencer graves

Thomas W Blackwell wrote:
 > Probably you've already found the function  step()  in the base
 > package, and its sub-functions  add1(), drop1().  See the help
 > for these.
 >
 > -  tom blackwell  -  u michigan medical school  -  ann arbor  -
 >
 > On Fri, 25 Apr 2003 edgar at uprm.edu wrote:
 >
 >
 >>Hello,
 >>Does anybody know where I can find an R function to carry out variable
 >>selection using stepwise similar (or even better) to the stepwise 
function
 >>available in S-Plus?. I have tried the mle.stepwise function available in
 >>the wle package but I am not getting accurate results.
 >>I have tried also the leaps package but it does not handle the options
 >>f-in and f-out like in either MINITAB or SAS.
 >>
 >>Thanks in advance
 >>
 >>Dr. Edgar Acuna
 >>University of Puerto Rico at Mayaguez
 >
 >
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
 >


From rsadler at agric.uwa.edu.au  Mon Apr 28 09:02:06 2003
From: rsadler at agric.uwa.edu.au (rohan sadler)
Date: Mon, 28 Apr 2003 15:02:06 +0800
Subject: [R] sum(..., na.rm=TRUE) oddity
Message-ID: <3EACD1EE.8050804@agric.uwa.edu.au>

Hi all,

I get two different results when using sum() and the switch na.rm. The 
result is correct when na.rm=FALSE.
Linux Redhat 7.3, R version 1.6.1.

I've had no luck searching the mail archives, so I was hoping somebody 
could explain/check this one for me. I will need to apply the function 
to missing data, simple as it is.

Code:

 x<-matrix(runif(20,0,5)%/%1,4,5)      # random matrix data set 4x5, 
values are integers between 0 and 4

coords<-c(2,3,3,4)     # choose any sub-matrix, with 
c(ymin,ymax,xmin,xmax) being row and column indices.

 occupied.counter<-function(coords){sum(x[coords[3]:coords[4],coords[1]:coords[2]])}

 occupied.counter(coords)
[1] 7

 occupied.counter<-function(coords){sum(x[coords[3]:coords[4],coords[1]:coords[2]], 
na.rm=TRUE)}

 occupied.counter(coords)
[1] 8


Cheers in advance

Rohan Sadler

-- 
Ecosystems Research Group (ERGO)
School of Plant Biology (Botany), Faculty of Natural & Agricultural Sciences,
The University of Western Australia, 35 Stirling Highway, Crawley  WA  6009, Australia

Ph:  +61 8 9380 7914
Fax: +61 8 9380 7925
email: rsadler at agric.uwa.edu.au
ERGO's web site:<http://www.botany.uwa.edu.au/ergo>


From hennig at stat.math.ethz.ch  Mon Apr 28 09:32:47 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Mon, 28 Apr 2003 09:32:47 +0200 (CEST)
Subject: [R] plot clusters
In-Reply-To: <16042.46868.653311.930418@gargle.gargle.HOWL>
Message-ID: <Pine.LNX.4.44.0304280930420.1916-100000@florence>

Hi,

On Sat, 26 Apr 2003, Martin Maechler wrote:

> >>>>> "pingzhao" == pingzhao  <pingzhao at waffle.cs.dal.ca>
> >>>>>     on Fri, 25 Apr 2003 16:45:19 -0300 writes:
> 
>     pingzhao> Hi,
>     pingzhao> I have a dataset which has more than two clusters (say 3 clusters).
>     pingzhao> I used kmeans to cluster the dataset.
> 
>     pingzhao> I am wondering how I can plot the clustering result on a two-dimensional
>     pingzhao> figure????
> 
>     pingzhao> The example in the kmeans help file is as follows:
> 
>     pingzhao> x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
>     pingzhao>            matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2))
>     pingzhao> cl <- kmeans(x, 2, 20)
>     pingzhao> plot(x, col = cl$cluster)
> 
>     pingzhao> It seems that this is only working for 2 clusters. When my dataset has more
>     pingzhao> than two clusters, the plot results are obvious wrong.
 
> The much more interesting question is what to do when `x' has
> more than two *dimensions*.
> The easiest is to then plot on the first two principal
> components, but I'm sure Christian Hennig will tell about much
> more sophisticated solutions coming Monday...

...not without being asked explicitly;-)

Christian


-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de


From petr.pikal at precheza.cz  Mon Apr 28 09:54:28 2003
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 28 Apr 2003 09:54:28 +0200
Subject: [R] 
In-Reply-To: <4521.136.145.154.108.1051287037.squirrel@math.uprm.edu>
Message-ID: <3EACFA54.12616.62BD0C@localhost>

Hi

On 25 Apr 2003 at 12:10, edgar at uprm.edu wrote:

> Hello,
> Does anybody know where I can find an R function to carry out variable
> selection using stepwise similar (or even better) to the stepwise
> function available in S-Plus?. I have tried the mle.stepwise function
> available in the wle package but I am not getting accurate results. I
> have tried also the leaps package but it does not handle the options
> f-in and f-out like in either MINITAB or SAS.

what about

stepAIC from MASS library

> 
> Thanks in advance
> 
> Dr. Edgar Acuna
> University of Puerto Rico at Mayaguez
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

Cheers
Petr
petr.pikal at precheza.cz
p.pik at volny.cz


From adrian.trapletti at lmttrading.com  Mon Apr 28 10:01:55 2003
From: adrian.trapletti at lmttrading.com (Adrian Trapletti)
Date: Mon, 28 Apr 2003 10:01:55 +0200
Subject: [R] Re: Testing for Stationarity of time series
References: <200304172110.h3HLAvUZ012714@hypatia.math.ethz.ch>
Message-ID: <3EACDFF3.F6B7DAC@lmttrading.com>

> Subject: [R] Testing for Stationarity of time series
> Date: Thu, 17 Apr 2003 15:52:43 +0100
> From: Wayne Jones <JonesW at kssg.com>
> To: "'r-help at stat.math.ethz.ch'" <r-help at stat.math.ethz.ch>
>
> Hi there,
>
> Does anyone know if R has a function for testing whether a time series is
> stationary??

kpss.test
related tests are pp.test and adf.test

all from tseries


> Thanks in advance,
>
> Wayne
>
> Dr Wayne R. Jones
> Statistician / Research Analyst
> KSS Group plc
> St James's Buildings
> 79 Oxford Street
> Manchester M1 6SS
> Tel: +44(0)161 609 4084
> Mob: +44(0)7810 523 713
>
> KSS Ltd
> A division of Knowledge Support Systems Group plc
> Seventh Floor  St James's Buildings  79 Oxford Street  Manchester  M1 6SS  England
> Company Registration Number 2800886 (Limited) 3449594 (plc)
> Tel: +44 (0) 161 228 0040       Fax: +44 (0) 161 236 6305
> mailto:kssg at kssg.com           http://www.kssg.com
>
> The information in this Internet email is confidential and may b... {{dropped}}

best
Adrian

--
Dr. Adrian Trapletti             Phone :             +41 (0) 1 994 5631
Trapletti Statistical Computing  Mobile:             +41 (0)76 370 5631
Wildsbergstrasse 31              Fax   :             +41 (0) 1 994 5631
CH-8610 Uster                    Email :  mailto:a.trapletti at bluewin.ch
Switzerland                      WWW   : http://trapletti.homelinux.com


From V.Khamenia at BioVisioN.de  Mon Apr 28 10:18:37 2003
From: V.Khamenia at BioVisioN.de (Khamenia, Valery)
Date: Mon, 28 Apr 2003 10:18:37 +0200
Subject: AW: AW: [R] numericDeriv and ecdf
Message-ID: <D15343265276D31197BC00A024A6C11077400B@EXS_BDC>

Dear Prof. Brian Ripley,

  first of all thank you for your answer, I do appreciate 
  how do you manage to keep successfully all your 
  activities and answer posts in this forum!

> An empirical CDF is a step function: it does not have a 
> derivative at the jump points, and has a zero 
> derivative everywhere else.

of course!

Let me add few words concerning my simple motivation. 

1. I need estimation for differential entropy.

2. I don't need estimation for differential entropy affected 
   by any smoothing kernels or other hypothesizes implicitly 
   coming as explained below.

3. Formula for differential entropy based on density

4. Density estimations based on real data are possible with 
   smoothing kernels only.

5. Application of smoothing kernels is not adequate if a priori 
   known that the family of distributions for my data is 
   extremely wide (Indeed, I don't need any extra hypothesizes 
   coming with smoothing kernels)

6. CDF is quite OK as "ascetic" estimation of distribution, i.e.
   CDF adds _nothing_ to (and removes _nothing_ from) the 
   hypothesizes about data distribution -- unlike those density 
   estimations based on smoothing kernels.

7. I don't know formula for differential entropy estimation 
   based on CDF.

8. Therefore I should try estimate differential entropy relying
   on density-based approach.   

9. Histogram is quite natural way for estimation of density.

10. Classical histograms are not adequate if a priori known 
   that family of distribution for my data is extremely wide. 
   Indeed:

   a) one should have some assumptions concerning the distribution
      in order to have reasonable breaks for binning.

   b) any binning reasonable in terms of histogram properties 
      tends to destroy knowledge about the distribution _within_ 
      a bin -- only a trivial histogram with breaks situated next 
      to the data points is really acceptable for keeping 
      knowledge about the distribution like ECDF does.

11. So we come to "empirical density", which is rather uncommon 
    term today. In order to feel my thoughts try please:

      x <- sort( rnorm(10000) )
      dx <- diff(x)
	ed <- 1/10000/dx
      plot(x[-1], ed, log="y") # my "empirical density"
      lines(x,dnorm(x),col=2)

Now I could have estimation for differential entropy like this:

      -sum(ed*log(ed)*dx)

That's it. 

> What is this function `numericDerivative': do you mean `numericDeriv'?

yes. Sorry, there is no auto-completion function in my non-emacs 
email client as in emacs' ESS environment ;-)

kind regards,
Valery A.Khamenya
---------------------------------------------------------------------------
Bioinformatics Department
BioVisioN AG, Hannover


From azzalini at stat.unipd.it  Mon Apr 28 10:55:08 2003
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Mon, 28 Apr 2003 10:55:08 +0200
Subject: [R] Fast R implementation of Gini mean difference
In-Reply-To: <1051154277.3ea757654bbb4@my.uq.edu.au>
References: <1051154277.3ea757654bbb4@my.uq.edu.au>
Message-ID: <20030428085508.88B327CA824@tango.stat.unipd.it>


This is to complement my previous contribution on computation of Gini mean  
difference - a discussion started by Andrew Ward. The index is "defined" as
    gini  <- 0
      for (i in 1:n) 
         {
         for (j in 1:n)  gini <- gini + freq[i]*freq[j]*abs(x[i]-x[j])
         }
    gini<- gini/((sum(freq)-1)*sum(freq))

This is  the so-called form "without repetition"; the variant "with repetition"
does not have -1 in the final line.

Since computaation via the definition is totally inefficient, alternative
approaches have been put forward, following Andrew's message.

My first version of a computationally convenient implementation was
essentially this:

gini.md0<- function(x)
 { # x=data vector
   n <-length(x)
   return(4*sum((1:length(x))*sort(x)/(n*(n-1)))
       -2*mean(x)*(n+1)/(n-1))
  }


Since Andrew (private message) has stressed the importance in his problem
of allowing for replicated data, here is a more general version, obtained by 
elaborating on the previous one with a bit of algebra:

gini.md <- function(x, freq=rep(1,length(x)))
{# x=data vector, freq=vector of frequencies
  if(!is.vector(x)) stop("x must be a vector")
  if(length(x) != length(freq)) 
       stop("x and freq must have same length")  
  if(min(freq)<0 | sum(freq)==0 | any(freq != as.integer(freq)) ) 
             stop("freq must be counts")
     x <- x[freq>0]
     freq <- freq[freq>0]
     j <- order(x)
     x <- x[j]
     n <- as.integer(freq[j])
     n. <- sum(n)
     u <- (cumsum(n)-n)*n+ n*(n+1)/2
     return(4*sum(u*x)/(n.*(n.-1))
         -2*weighted.mean(x,n)*(n.+1)/(n.-1))
}
  
Notice that gini.md(x,freq) gives the same of mini.md0(rep(x,freq)), but the latter 
is obviously less efficient. Either are however far more efficient that straight
implementation of the "definition".

regards

Adelchi Azzalini

-- 
Adelchi Azzalini  <azzalini at stat.unipd.it>
Dipart.Scienze Statistiche, Universit? di Padova, Italia
http://azzalini.stat.unipd.it/


From ripley at stats.ox.ac.uk  Mon Apr 28 12:01:44 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 28 Apr 2003 11:01:44 +0100 (BST)
Subject: [R] sum(..., na.rm=TRUE) oddity
In-Reply-To: <3EACD1EE.8050804@agric.uwa.edu.au>
Message-ID: <Pine.LNX.4.44.0304281057060.1247-100000@gannet.stats>

I can't reproduce this: can you give us the random seed used or a 
reproducible example in some other way.  (Preferably some actual data, as 
the random-number generator default has changed since 1.6.1.)

On Mon, 28 Apr 2003, rohan sadler wrote:

> I get two different results when using sum() and the switch na.rm. The 
> result is correct when na.rm=FALSE.
> Linux Redhat 7.3, R version 1.6.1.
> 
> I've had no luck searching the mail archives, so I was hoping somebody 
> could explain/check this one for me. I will need to apply the function 
> to missing data, simple as it is.
> 
> Code:
> 
>  x<-matrix(runif(20,0,5)%/%1,4,5)      # random matrix data set 4x5, 
> values are integers between 0 and 4
> 
> coords<-c(2,3,3,4)     # choose any sub-matrix, with 
> c(ymin,ymax,xmin,xmax) being row and column indices.
> 
>  occupied.counter<-function(coords){sum(x[coords[3]:coords[4],coords[1]:coords[2]])}
> 
>  occupied.counter(coords)
> [1] 7
> 
>  occupied.counter<-function(coords){sum(x[coords[3]:coords[4],coords[1]:coords[2]], 
> na.rm=TRUE)}
> 
>  occupied.counter(coords)
> [1] 8

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From andreww at cheque.uq.edu.au  Mon Apr 28 22:02:04 2003
From: andreww at cheque.uq.edu.au (Andrew C. Ward)
Date: Mon, 28 Apr 2003 20:02:04 -0000
Subject: [R] Fast R implementation of Gini mean difference
Message-ID: <01C30DC1.0A2AC450.andreww@cheque.uq.edu.au>

Thank you again to Professor Azzalini for taking the time to
expound this issue for me. It's been very instructive to look
in detail at the definition of Gini mean difference and at the
incorporation of weights. Noting suggestions for improving the
speed of my function has also been very helpful.

With my application, the weights refer to the "reliability" of
a measurement, with a weight of 1 signifying high reliability
and a weight close to zero indicating low reliability. The
mean difference is used as a robust estimate of the standard
deviation of the vector of measurements (the 0.5*sqrt(pi)
multiplier is for this purpose).

It seems to me that Professor Azzalini's result may be used for
non-integer weights if the weights are scaled to sum to the
number of measurements (ie. w <- w * length(x)/sum(w)). In this
case, I think that gmd(x=c(1,2,4), w=c(1,2,1)) gives the same
result at gmd(x=c(1,2,2,4), w=c(1,1,1,1)).

Thank you again to all who have contributed to my understanding
and R implementation of the mean difference.


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au



On Monday, April 28, 2003 6:55 PM, Adelchi Azzalini 
[SMTP:azzalini at stat.unipd.it] wrote:
>
> This is to complement my previous contribution on computation 
of
> Gini mean
> difference - a discussion started by Andrew Ward. The index is
> "defined" as
>     gini  <- 0
>       for (i in 1:n)
>          {
>          for (j in 1:n)  gini <- gini + freq[i]*freq[j]*abs(x
>          [i]-x[j])
>          }
>     gini<- gini/((sum(freq)-1)*sum(freq))
>
> This is  the so-called form "without repetition"; the variant
> "with repetition"
> does not have -1 in the final line.
>
> Since computaation via the definition is totally inefficient,
> alternative
> approaches have been put forward, following Andrew's message.
>
> My first version of a computationally convenient implementation
> was
> essentially this:
>
> gini.md0<- function(x)
>  { # x=data vector
>    n <-length(x)
>    return(4*sum((1:length(x))*sort(x)/(n*(n-1)))
>        -2*mean(x)*(n+1)/(n-1))
>   }
>
>
> Since Andrew (private message) has stressed the importance in
> his problem
> of allowing for replicated data, here is a more general 
version,
> obtained by
> elaborating on the previous one with a bit of algebra:
>
> gini.md <- function(x, freq=rep(1,length(x)))
> {# x=data vector, freq=vector of frequencies
>   if(!is.vector(x)) stop("x must be a vector")
>   if(length(x) != length(freq))
>        stop("x and freq must have same length")
>   if(min(freq)<0 | sum(freq)==0 | any(freq != as.integer(freq))
>   )
>              stop("freq must be counts")
>      x <- x[freq>0]
>      freq <- freq[freq>0]
>      j <- order(x)
>      x <- x[j]
>      n <- as.integer(freq[j])
>      n. <- sum(n)
>      u <- (cumsum(n)-n)*n+ n*(n+1)/2
>      return(4*sum(u*x)/(n.*(n.-1))
>          -2*weighted.mean(x,n)*(n.+1)/(n.-1))
> }
>
> Notice that gini.md(x,freq) gives the same of mini.md0(rep
> (x,freq)), but the latter
> is obviously less efficient. Either are however far more
> efficient that straight
> implementation of the "definition".
>
> regards
>
> Adelchi Azzalini
>
> --
> Adelchi Azzalini  <azzalini at stat.unipd.it>
> Dipart.Scienze Statistiche, Universita di Padova, Italia
> http://azzalini.stat.unipd.it/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From vincent.stoliaroff at socgen.com  Mon Apr 28 12:18:51 2003
From: vincent.stoliaroff at socgen.com (vincent.stoliaroff@socgen.com)
Date: Mon, 28 Apr 2003 12:18:51 +0200
Subject: [R] Writing a function
Message-ID: <OF765DF177.C3E3F9A6-ONC1256D16.0037E61E@ges.marc.societe-generale.fr>


Hi r lovers,

I have written the following  function

> ClearDeltaBis
function(Matrix){
for (i in 1:3)
                        {
                        for (j in 1:2)
                                {if (is.na(Matrix[i,j]))
NA->(Matrix[i,j+1])}
                        }
Matrix
}

it looks correct but when I try to implement it on the MatCor Matrix I get
this error message

> ClearDeltaBis(MatCor)
Error: couldn't find function "(<-"

I don't understand where does it come from since I have no string like (<-
in my code


Thanks for any help that could be provided.





*************************************************************************
Ce message et toutes les pieces jointes (ci-apres le "message") sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite. 
Tout message electronique est susceptible d'alteration. 
La SOCIETE GENERALE et ses filiales declinent toute responsabilite au 
titre de ce message s'il a ete altere, deforme ou falsifie.
				********
This message and any attachments (the "message") are confidentia... {{dropped}}


From sandrine.mainard1 at etud.univ-ubs.fr  Mon Apr 28 12:18:20 2003
From: sandrine.mainard1 at etud.univ-ubs.fr (sandrine.mainard1@etud.univ-ubs.fr)
Date: Mon, 28 Apr 2003 12:18:20 +0200
Subject: [R] Problem graf-qvalue
Message-ID: <1051525100.3eacffecb035d@homae.univ-ubs.fr>


Hello,

I work with the package qvalue. I'm wondering why have i found results,i.e. the 
qvalues,but the graphics don't correspond. The only graphic (i believe it is 
right), is the first :"the estimated pi0 versus the tuning parameter lambda".

Thanks a lot

Sandrine


--------------------------------------------------------------------------------
Universit de Bretagne sud                               http://www.univ-ubs.fr/


From rsadler at agric.uwa.edu.au  Mon Apr 28 12:27:07 2003
From: rsadler at agric.uwa.edu.au (rohan sadler)
Date: Mon, 28 Apr 2003 18:27:07 +0800
Subject: [R] sum(..., na.rm=TRUE) oddity
References: <3EACD1EE.8050804@agric.uwa.edu.au>
Message-ID: <3EAD01FB.4000407@agric.uwa.edu.au>

Okay,

This is one of the cases where I can answer my own foolishness. If I 
don't define the switch as na.rm=TRUE, but instead just as TRUE - which 
is my usual practice with other functions - then sum counts the TRUE as 
another vector object, and counts it as one. So much for saving keystrokes.

rohan sadler wrote:

> Hi all,
>
> I get two different results when using sum() and the switch na.rm. The 
> result is correct when na.rm=FALSE.
> Linux Redhat 7.3, R version 1.6.1.
>
> I've had no luck searching the mail archives, so I was hoping somebody 
> could explain/check this one for me. I will need to apply the function 
> to missing data, simple as it is.
>
> Code:
>
> x<-matrix(runif(20,0,5)%/%1,4,5) # random matrix data set 4x5, values 
> are integers between 0 and 4
>
> coords<-c(2,3,3,4) # choose any sub-matrix, with 
> c(ymin,ymax,xmin,xmax) being row and column indices.
>
> occupied.counter<-function(coords){sum(x[coords[3]:coords[4],coords[1]:coords[2]])} 
>
>
> occupied.counter(coords)
> [1] 7
>
> occupied.counter<-function(coords){sum(x[coords[3]:coords[4],coords[1]:coords[2]], 
> na.rm=TRUE)}
>
> occupied.counter(coords)
> [1] 8
>
>
> Cheers in advance
>
> Rohan Sadler
>

-- 
PhD Student, Ecosystems Research Group (ERGO)
School of Plant Biology (Botany), Faculty of Natural & Agricultural Sciences,
The University of Western Australia, 35 Stirling Highway, Crawley  WA  6009, Australia

Ph:  +61 8 9380 7914
Fax: +61 8 9380 7925
email: rsadler at agric.uwa.edu.au
ERGO's web site:<http://www.botany.uwa.edu.au/ergo>


From ripley at stats.ox.ac.uk  Mon Apr 28 12:42:19 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 28 Apr 2003 11:42:19 +0100 (BST)
Subject: [R] Writing a function
In-Reply-To: <OF765DF177.C3E3F9A6-ONC1256D16.0037E61E@ges.marc.societe-generale.fr>
Message-ID: <Pine.LNX.4.44.0304281137440.23613-100000@gannet.stats>

On Mon, 28 Apr 2003 vincent.stoliaroff at socgen.com wrote:

> I have written the following  function
> 
> > ClearDeltaBis
> function(Matrix){
> for (i in 1:3)
>                         {
>                         for (j in 1:2)
>                                 {if (is.na(Matrix[i,j]))
> NA->(Matrix[i,j+1])}
>                         }
> Matrix
> }
> 
> it looks correct but when I try to implement it on the MatCor Matrix I get
> this error message
> 
> > ClearDeltaBis(MatCor)
> Error: couldn't find function "(<-"
> 
> I don't understand where does it come from since I have no string like (<-
> in my code

You do, in the line

NA->(Matrix[i,j+1])

That's an unusual way of writing

(Matrix[i,j+1]) <- NA

and you have a set of parentheses there on the LHS of the assignment.
R is looking for a function "(<-" to implement this as

Matrix[i,j+1] <- "(<-"(NA)

You don't need (or want) the parentheses.

You might want to look up how functions on the LHS of assignments are 
supposed to work in R.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.uni-dortmund.de  Mon Apr 28 13:00:48 2003
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 28 Apr 2003 13:00:48 +0200
Subject: [R] Writing a function
In-Reply-To: <OF765DF177.C3E3F9A6-ONC1256D16.0037E61E@ges.marc.societe-generale.fr>
References: <OF765DF177.C3E3F9A6-ONC1256D16.0037E61E@ges.marc.societe-generale.fr>
Message-ID: <3EAD09E0.2010409@statistik.uni-dortmund.de>

vincent.stoliaroff at socgen.com wrote:
> Hi r lovers,
> 
> I have written the following  function
> 
> 
>>ClearDeltaBis
> 
> function(Matrix){
> for (i in 1:3)
>                         {
>                         for (j in 1:2)
>                                 {if (is.na(Matrix[i,j]))
> NA->(Matrix[i,j+1])}
>                         }
> Matrix
> }
> 
> it looks correct but when I try to implement it on the MatCor Matrix I get
> this error message
> 
> 
>>ClearDeltaBis(MatCor)
> 
> Error: couldn't find function "(<-"
> 
> I don't understand where does it come from since I have no string like (<-
> in my code
> 
> 
> Thanks for any help that could be provided.

Hint:

   NA->(Matrix[i,j+1])

is syntactically almost the same as

   (Matrix[i,j+1]) <- NA

but the latter (without the brackets) is less confusing.

Uwe Ligges


From vincent.stoliaroff at socgen.com  Mon Apr 28 13:16:04 2003
From: vincent.stoliaroff at socgen.com (vincent.stoliaroff@socgen.com)
Date: Mon, 28 Apr 2003 13:16:04 +0200
Subject: [R] Re: [R Thanks for help Writing a function
Message-ID: <OFB656E454.A23FC7C2-ONC1256D16.003D626E@ges.marc.societe-generale.fr>


Thank you very much

It works perfectly well

Have a wonderful day




|---------+---------------------------->
|         |           ripley at stats.ox.a|
|         |           c.uk             |
|         |                            |
|         |           04/28/03 12:58 PM|
|         |                            |
|---------+---------------------------->
  >------------------------------------------------------------------------------------------------------------------------------|
  |                                                                                                                              |
  |       To:       Vincent STOLIAROFF/fr/socgen at socgen                                                                          |
  |       cc:       r-help at stat.math.ethz.ch                                                                                     |
  |       Subject:  Re: [R] Writing a function                                                                                   |
  >------------------------------------------------------------------------------------------------------------------------------|



On Mon, 28 Apr 2003 vincent.stoliaroff at socgen.com wrote:

> I have written the following  function
>
> > ClearDeltaBis
> function(Matrix){
> for (i in 1:3)
>                         {
>                         for (j in 1:2)
>                                 {if (is.na(Matrix[i,j]))
> NA->(Matrix[i,j+1])}
>                         }
> Matrix
> }
>
> it looks correct but when I try to implement it on the MatCor Matrix I get
> this error message
>
> > ClearDeltaBis(MatCor)
> Error: couldn't find function "(<-"
>
> I don't understand where does it come from since I have no string like (<-
> in my code

You do, in the line

NA->(Matrix[i,j+1])

That's an unusual way of writing

(Matrix[i,j+1]) <- NA

and you have a set of parentheses there on the LHS of the assignment.
R is looking for a function "(<-" to implement this as

Matrix[i,j+1] <- "(<-"(NA)

You don't need (or want) the parentheses.

You might want to look up how functions on the LHS of assignments are
supposed to work in R.

--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595







*************************************************************************
Ce message et toutes les pieces jointes (ci-apres le "message") sont
confidentiels et etablis a l'intention exclusive de ses destinataires.
Toute utilisation ou diffusion non autorisee est interdite. 
Tout message electronique est susceptible d'alteration. 
La SOCIETE GENERALE et ses filiales declinent toute responsabilite au 
titre de ce message s'il a ete altere, deforme ou falsifie.
				********
This message and any attachments (the "message") are confidentia... {{dropped}}


From B.Rowlingson at lancaster.ac.uk  Mon Apr 28 13:28:32 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 28 Apr 2003 12:28:32 +0100
Subject: [R] sum(..., na.rm=TRUE) oddity
In-Reply-To: <3EAD01FB.4000407@agric.uwa.edu.au>
References: <3EACD1EE.8050804@agric.uwa.edu.au>
	<3EAD01FB.4000407@agric.uwa.edu.au>
Message-ID: <3EAD1060.8010309@lancaster.ac.uk>

rohan sadler wrote:
> Okay,
> 
> This is one of the cases where I can answer my own foolishness. If I 
> don't define the switch as na.rm=TRUE, but instead just as TRUE - which 
> is my usual practice with other functions - then sum counts the TRUE as 
> another vector object, and counts it as one. So much for saving keystrokes.

  Are you certain you typed 'na.rm'? I have occasionally typed 'rm.na' 
instead, and something like that might explain things:


 > sum(1,1,na.rm=TRUE)
[1] 2

 > sum(1,1,rm.na=TRUE)
[1] 3

Baz


From Alexander.Ploner at mep.ki.se  Mon Apr 28 13:50:55 2003
From: Alexander.Ploner at mep.ki.se (Alexander Ploner)
Date: Mon, 28 Apr 2003 13:50:55 +0200
Subject: [R] Windows: Graphics appear only partially - resolved
In-Reply-To: <MABBLJDICACNFOLGIHJOKEFNDGAA.phgrosjean@sciviews.org>
Message-ID: <JJEBKFOIJAKFKJKPEKIFIEAECBAA.Alexander.Ploner@mep.ki.se>

Last week, I asked the list about help because graphics were not displayed
properly on Windows 2000 machines in our computer lab. Brain Ripley and
Philippe Grosjean kindly offered support and advice; it turned out that
Philippe's suggestion to install the latest drivers for the elderly video
cards in the machines (NVidia Vanta with 8 mb of video RAM) solved the
problem. Thanks!

alex

Alexander.Ploner at mep.ki.se
Phone: 46-8-524-82329
Fax  : 46-8-314975
Medical Epidemiology & Biostatistics
Karolinska Institutet,
P.O. Box 281, SE-171 77 Stockholm


From dmurdoch at pair.com  Mon Apr 28 14:15:08 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Mon, 28 Apr 2003 08:15:08 -0400
Subject: [R] sum(..., na.rm=TRUE) oddity
In-Reply-To: <3EAD1060.8010309@lancaster.ac.uk>
References: <3EACD1EE.8050804@agric.uwa.edu.au>
	<3EAD01FB.4000407@agric.uwa.edu.au> <3EAD1060.8010309@lancaster.ac.uk>
Message-ID: <p46qav82rg5gqrcgngr8amsp9c70hmfm75@4ax.com>

On Mon, 28 Apr 2003 12:28:32 +0100, Barry Rowlingson
<B.Rowlingson at lancaster.ac.uk> wrote:

>  Are you certain you typed 'na.rm'? I have occasionally typed 'rm.na' 
>instead, and something like that might explain things:
>
>
> > sum(1,1,na.rm=TRUE)
>[1] 2
>
> > sum(1,1,rm.na=TRUE)
>[1] 3

Is there ever any reason to name the summands?  I'd think it would be
reasonable to generate an error, or at least a warning, in a case
where any of the arguments to be summed are named.  For example 

sum <- function (..., na.rm = FALSE) {
  if (!is.null(names(list(...)))) 
      stop(paste('Named summands:',paste(names(list(...)),collapse='
')))
  .Internal(sum(..., na.rm = na.rm))
}

gives this:

> sum(1,1,rm.na=TRUE)
Error in sum(1, 1, rm.na = TRUE) : Named summands:   rm.na

Duncan Murdoch


From p.dalgaard at biostat.ku.dk  Mon Apr 28 14:32:48 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 28 Apr 2003 14:32:48 +0200
Subject: [R] sum(..., na.rm=TRUE) oddity
In-Reply-To: <p46qav82rg5gqrcgngr8amsp9c70hmfm75@4ax.com>
References: <3EACD1EE.8050804@agric.uwa.edu.au>
	<3EAD01FB.4000407@agric.uwa.edu.au> <3EAD1060.8010309@lancaster.ac.uk>
	<p46qav82rg5gqrcgngr8amsp9c70hmfm75@4ax.com>
Message-ID: <x2llxu3iq7.fsf@biostat.ku.dk>

Duncan Murdoch <dmurdoch at pair.com> writes:

> Is there ever any reason to name the summands?  I'd think it would be
> reasonable to generate an error, or at least a warning, in a case
> where any of the arguments to be summed are named.  For example 
> 
> sum <- function (..., na.rm = FALSE) {
>   if (!is.null(names(list(...)))) 
>       stop(paste('Named summands:',paste(names(list(...)),collapse='
> ')))
>   .Internal(sum(..., na.rm = na.rm))
> }
> 
> gives this:
> 
> > sum(1,1,rm.na=TRUE)
> Error in sum(1, 1, rm.na = TRUE) : Named summands:   rm.na

I think you would quickly run into problems with cod that was using
constructions like do.call("sum",l) or sum(...) if you tried that. 

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From bitwrit at ozemail.com.au  Mon Apr 28 14:34:16 2003
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Mon, 28 Apr 2003 22:34:16 +1000
Subject: [R] sum(..., na.rm=TRUE) oddity
In-Reply-To: <p46qav82rg5gqrcgngr8amsp9c70hmfm75@4ax.com>
References: <3EACD1EE.8050804@agric.uwa.edu.au>
	<3EAD1060.8010309@lancaster.ac.uk>
	<p46qav82rg5gqrcgngr8amsp9c70hmfm75@4ax.com>
Message-ID: <20030428123416.BMJT28068.mta09.mail.mel.aone.net.au@there>

Duncan Murdoch wrote:
>
> ...Is there ever any reason to name the summands?  I'd think it would be
> reasonable to generate an error, or at least a warning, in a case
> where any of the arguments to be summed are named.  For example
>
In parsing functions with an ellipsis in the argument list, R appears to 
consume unnamed arguments until it finds a recognized argument name or 
encounters an unresolvable data conflict. This is pretty reasonable 
behavior.

> sum <- function (..., na.rm = FALSE) {
>   if (!is.null(names(list(...))))
>       stop(paste('Named summands:',paste(names(list(...)),collapse='
> ')))
>   .Internal(sum(..., na.rm = na.rm))
> }
>
> gives this:
> > sum(1,1,rm.na=TRUE)
>
> Error in sum(1, 1, rm.na = TRUE) : Named summands:   rm.na
>
What seems to be happening here is that you have explicitly named the 
argument, then supplied an argument with an name that cannot be resolved. 
I think the "misspelled argument name" is irrelevant to your original 
question.

Jim


From chrysopa at insecta.ufv.br  Mon Apr 28 15:39:54 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Mon, 28 Apr 2003 10:39:54 -0300
Subject: [R] [OFF] File name completation on XEmacs+ESS.
Message-ID: <200304281039.54173.chrysopa@insecta.ufv.br>

Hi,

I try to make a key alias to XEmacs+ESS function Complete File Name.
But I dont know the name of this funcion.

Anybody know how this funcion is call?

(global-set-key "\C-tab" 'name of the function Complete File Name)

Thanks for all

Inte
Ronaldo

-- 
To beer or not to beer.
                -- ShakesBeer
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From cuffer at maths.tcd.ie  Mon Apr 28 16:06:13 2003
From: cuffer at maths.tcd.ie (Robert Cuffe)
Date: Mon, 28 Apr 2003 15:06:13 +0100
Subject: [R] stepAIC/lme problem (1.7.0 only)
Message-ID: <20030428150613.A26999@stokes.maths.tcd.ie>

I can use stepAIC on an lme object in 1.6.2, but 
I get the following error if I try to do the same
in 1.7.0:

Error in lme(fixed = resp ~ cov1 + cov2, data = a, random = structure(list( : 
        unused argument(s) (formula ...)

Does anybody know why?

Here's an example:

library(nlme)
library(MASS)
a <- data.frame( resp=rnorm(250), cov1=rnorm(250),
                 cov2=rnorm(250), group=rep(letters[1:10],25) )
mod1 <- lme(resp~cov1, a, ~cov1|group, method="ML")
mod2 <- stepAIC(mod1, scope=list(upper=~(cov1+cov2)^2,
                                 lower=~cov1) )
					 
# it doesn't happen for normal linear models:

mod3 <- lm(resp~cov1, data=a)
mod4 <- stepAIC(mod3, scope=list(upper=~(cov1+cov2)^2,
                                 lower=~cov1) )

Thanks, 

Robert


From spencer.graves at pdf.com  Mon Apr 28 16:20:34 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 28 Apr 2003 07:20:34 -0700
Subject: [R] Stepwise regression?  
References: <3EACFA54.12616.62BD0C@localhost>
Message-ID: <3EAD38B2.4070200@pdf.com>

If you are willing to try lightly tested software, consider "stepAIC.c" 
from "www.prodsyse.com".  This was produced by modifying "stepAIC" from 
MASS.  This can find significant interactions when neither main effect 
is already in the model and forces the linear term in the model when 
testing parabolics.  The output includes an attribute "models" giving a 
posterior distribution over all models tested assuming a uniform prior, 
as described in Burnham and Anderson (2002) Model Selection and 
Multimodel Inference (Springer).

hope this helps.  spencer graves

Petr Pikal wrote:
> Hi
> 
> On 25 Apr 2003 at 12:10, edgar at uprm.edu wrote:
> 
> 
>>Hello,
>>Does anybody know where I can find an R function to carry out variable
>>selection using stepwise similar (or even better) to the stepwise
>>function available in S-Plus?. I have tried the mle.stepwise function
>>available in the wle package but I am not getting accurate results. I
>>have tried also the leaps package but it does not handle the options
>>f-in and f-out like in either MINITAB or SAS.
> 
> 
> what about
> 
> stepAIC from MASS library
> 
> 
>>Thanks in advance
>>
>>Dr. Edgar Acuna
>>University of Puerto Rico at Mayaguez
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> 
> Cheers
> Petr
> petr.pikal at precheza.cz
> p.pik at volny.cz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From tlumley at u.washington.edu  Mon Apr 28 16:40:23 2003
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 28 Apr 2003 07:40:23 -0700 (PDT)
Subject: [R] stepAIC/lme problem (1.7.0 only)
In-Reply-To: <20030428150613.A26999@stokes.maths.tcd.ie>
Message-ID: <Pine.A41.4.44.0304280732310.200966-100000@homer03.u.washington.edu>

On Mon, 28 Apr 2003, Robert Cuffe wrote:

> I can use stepAIC on an lme object in 1.6.2, but
> I get the following error if I try to do the same
> in 1.7.0:
>
> Error in lme(fixed = resp ~ cov1 + cov2, data = a, random = structure(list( :
>         unused argument(s) (formula ...)
>
> Does anybody know why?

It's presumably related to the fact that the first argument to lme is
called `fixed' rather than `formula'.  It looks as though an `addterm.lme'
may be needed.

	-thomas


From tblackw at umich.edu  Mon Apr 28 16:42:56 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 28 Apr 2003 10:42:56 -0400 (EDT)
Subject: [R] Apparent namespace problem
In-Reply-To: <20030425224955.GC22596@epibiosun115-4.libaux.ucsf.edu>
Message-ID: <Pine.SOL.4.44.0304281032570.12889-100000@asteroids.gpcc.itd.umich.edu>

Ross  -

Inside whatever function defines the variable gcv,
do:  assign("gcv", gcv, 1)  after you've defined gcv
and before the function exits.  help("assign") gives
other ways to specify the target namespace (not all
of which I quite understand).

My hunch is this has nothing to do with snow or the
cluster architecture.  (I could be totally wrong.)

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 25 Apr 2003, Ross Boylan wrote:

> I'm seeing some strange behavior while using the snow package
> for networked computers.  I believe it's caused by name space
> resolution issues, and would appreciate any suggestions tracking
> it down.
>
> First, is there a way to find out what frame (as in frames in
> environments, not data frames) a name is being obtained from
> or put into?
>
> Second, how closely does the evaluation environment in the
> browser/debugger match what you would get in the function at
> the same point?  I ask because if I evaluate a statement in
> the browser it seems to work one way, but if I execute it
> it works another way.
>
> The statement is
> clusterEvalQ(cl, crossval.setup(x, y, groups, theta.fit,
> theta.predict))
>
> This evaluates the crossval.setup function across the cluster cl.
>
> crossval.setup is a function which puts its arguments in a list g
> (a local variable) and then does gcv <<- g.  The intent is to stuff
> the data into a global variable for use by later function calls.
>
> When I execute the statement interactively, even in the debugger
> in the function that executes the statement, it seems to work.
> But if it executes in the function, gcv appears to remain unset.
>
> I assume gcv is getting set in some other frame, but where it is
> and how to track it down I don't know.
>
> In an effort to get around this I did gcv <- list() in the global
> namespace (on the distributed nodes), but this doesn't seem to help.
> I'm just left with the empty list, even after calls to crossval.setup.
>
> Any ideas?


From otoomet at econ.dk  Mon Apr 28 15:56:41 2003
From: otoomet at econ.dk (Ott Toomet)
Date: Mon, 28 Apr 2003 15:56:41 +0200
Subject: [R] [OFF] File name completation on XEmacs+ESS.
In-Reply-To: <200304281039.54173.chrysopa@insecta.ufv.br>
References: <200304281039.54173.chrysopa@insecta.ufv.br>
Message-ID: <200304281356.h3SDufd08288@punik.econ.au.dk>

Hi,

if you try C-h k TAB, it says the function is

comint-dynamic-complete

I have not tested it.

Ott

 | From: "Ronaldo Reis Jr." <chrysopa at insecta.ufv.br>
 | Date: Mon, 28 Apr 2003 10:39:54 -0300
 | Hi,
 | 
 | I try to make a key alias to XEmacs+ESS function Complete File Name.
 | But I dont know the name of this funcion.
 | 
 | Anybody know how this funcion is call?
 | 
 | (global-set-key "\C-tab" 'name of the function Complete File Name)
 | 
 | Thanks for all
 | 
 | Inte
 | Ronaldo


From tblackw at umich.edu  Mon Apr 28 16:47:21 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Mon, 28 Apr 2003 10:47:21 -0400 (EDT)
Subject: [R] New user having problem with mcmc
In-Reply-To: <OF1B30E53F.60F58302-ON07256D13.007CD9EA@wr.usgs.gov>
Message-ID: <Pine.SOL.4.44.0304281043200.12889-100000@asteroids.gpcc.itd.umich.edu>

Lewis  -

Could it be that  x.mon[]  has only one column ?

I'm not familiar with the package, but I would try
running a more complicated example that would have
at least two columns in  x.mon[].  Also, read the
help, or write to the package maintainers directly.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Fri, 25 Apr 2003, Lewis G Coggins wrote:

> I get the following error when I try to use mcmc.
> It occurs at the end of the first chain.
>
> Error in cov(x.mon[2:m1, ] - x.mon[1:(m1 - 1), ]) :
>         supply both x and y or a matrix-like x
>
> Any ideas?
>
> Thanks,  Lew


From phineas at blueyonder.co.uk  Mon Apr 28 16:50:01 2003
From: phineas at blueyonder.co.uk (Phineas Campbell)
Date: Mon, 28 Apr 2003 15:50:01 +0100
Subject: [R] Sorry
Message-ID: <NGECIFANPOJAGABBAEAPAENACDAA.phineas@blueyonder.co.uk>

On my previous message I gave incorrect URL's for the configuration output.
They should be
www.phineas.pwp.blueyonder.co.uk/config.log and
www.phineas.pwp.blueyonder.co.uk/config.out
Also this technique appears to work with Netscape on Solaris, but not IE on
Windows. If this is not a sensible way to post diagnostic output let me know
and I will post them in a different way.

Phineas Campbell
pcampbell at econ.bbk.ac.uk


From ripley at stats.ox.ac.uk  Mon Apr 28 17:19:49 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 28 Apr 2003 16:19:49 +0100 (BST)
Subject: [R] stepAIC/lme problem (1.7.0 only)
In-Reply-To: <20030428150613.A26999@stokes.maths.tcd.ie>
Message-ID: <Pine.LNX.4.44.0304281611050.15089-100000@gannet.stats>

There are changes to improve scoping in stepAIC that assume that update
works in ways that update.lme does not:

> mod2 <- addterm(mod1, ~(cov1+cov2)^2)
Error in lme(fixed = resp ~ cov1 + cov2, data = a, random = structure(list( : 
        unused argument(s) (evaluate ...)

The actual problem is in stepAIC which now has the line

    object$call$formula <- object$formula <- Terms

but fixing that one only opens up others (as above).

I was vaguely aware of this: I don't know of an easy fix.


On Mon, 28 Apr 2003, Robert Cuffe wrote:

> I can use stepAIC on an lme object in 1.6.2, but 
> I get the following error if I try to do the same
> in 1.7.0:
> 
> Error in lme(fixed = resp ~ cov1 + cov2, data = a, random = structure(list( : 
>         unused argument(s) (formula ...)
> 
> Does anybody know why?
> 
> Here's an example:
> 
> library(nlme)
> library(MASS)
> a <- data.frame( resp=rnorm(250), cov1=rnorm(250),
>                  cov2=rnorm(250), group=rep(letters[1:10],25) )
> mod1 <- lme(resp~cov1, a, ~cov1|group, method="ML")
> mod2 <- stepAIC(mod1, scope=list(upper=~(cov1+cov2)^2,
>                                  lower=~cov1) )
> 					 
> # it doesn't happen for normal linear models:
> 
> mod3 <- lm(resp~cov1, data=a)
> mod4 <- stepAIC(mod3, scope=list(upper=~(cov1+cov2)^2,
>                                  lower=~cov1) )
> 
> Thanks, 
> 
> Robert
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kurt.sys at rug.ac.be  Mon Apr 28 17:26:22 2003
From: kurt.sys at rug.ac.be (Kurt Sys)
Date: Mon, 28 Apr 2003 17:26:22 +0200
Subject: [R] spectra processing
Message-ID: <16045.18462.42636.310083@ksys.rug.ac.be>

Hello,

I'm just wondering: are there any spectra processing packages
available? I found some packages which can be used for image analysis,
transformations etc. The most important thing for me to do is (local)
background substraction. The 'rolling ball' or 'rolling circle' is
quite often used, and, as far is I know, it behaves very well, but
other methods would be ok too (as long as they perform well).

tnx,
Kurt.


From Laetitia.Laine at gov.ky  Mon Apr 28 18:04:54 2003
From: Laetitia.Laine at gov.ky (Laine, Laetitia)
Date: Mon, 28 Apr 2003 11:04:54 -0500
Subject: [R] Algorithm did not converge
Message-ID: <FE4965577B60D711B885000BCD03D60F011514A2@mail.gov.ky>

Help! Being a bit of a novice, please bear with me if this is a stupid
question!

I am trying to fit a saturated model to some count data that I have:

model<-glm(COUNT~SP*LOC*COL*TIME*TREAT,poisson)

but R keeps on crashing and coming up with (occasionally before crashing) an
error that states:

Algorithm did not converge in: (if(is.empty.model(mt)) glm.fit.null else
glm.fit)(x = X, y = Y,

What am I doing wrong?

Thanks

Laetitia


From spencer.graves at pdf.com  Mon Apr 28 18:43:00 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 28 Apr 2003 09:43:00 -0700
Subject: [R] Algorithm did not converge
References: <FE4965577B60D711B885000BCD03D60F011514A2@mail.gov.ky>
Message-ID: <3EAD5A14.2010405@pdf.com>

	  "glm" tries to maximize the likelihood.  In certain cases, the 
likelihood is maximized at infinite.  This may be the case with your 
saturated model.

	  I suggest you think carefully about what you want to do, and then fit 
one or several models that avoid this problem.

hope this helps.  spencer graves


Laine, Laetitia wrote:
> Help! Being a bit of a novice, please bear with me if this is a stupid
> question!
> 
> I am trying to fit a saturated model to some count data that I have:
> 
> model<-glm(COUNT~SP*LOC*COL*TIME*TREAT,poisson)
> 
> but R keeps on crashing and coming up with (occasionally before crashing) an
> error that states:
> 
> Algorithm did not converge in: (if(is.empty.model(mt)) glm.fit.null else
> glm.fit)(x = X, y = Y,
> 
> What am I doing wrong?
> 
> Thanks
> 
> Laetitia
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From alessandro.semeria at cramont.it  Mon Apr 28 18:53:11 2003
From: alessandro.semeria at cramont.it (alessandro.semeria@cramont.it)
Date: Mon, 28 Apr 2003 18:53:11 +0200
Subject: [R] plot(pam.object) error with R-1.7.0 on Red-Hat 8.0 i686
Message-ID: <OFDC403BD0.F4E8F75B-ONC1256D16.005B2931-C1256D16.005BE816@tomware.it>

I don't know if there is some fault in compiling or a bug of the new 
R-1.7.0 version:

cl.pam.2 <- pam(as.dist(1-cor(mel.data)),2)
plot(cl.pam.2)

perform a right partitioning and silhouette plot on the old R-1.6.2
instead 
"Error in clusplot.default(x$diss,...... ;
        x is not numeric"
is the output on the new R-1.7.0.
 Same platform: RH8.0 i686. 
Some suggestions?

A.S.

----------------------------

Alessandro Semeria 
Models and Simulations Laboratory
The Environment Research Center - Montecatini (Edison Group), 
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: asemeria at cramont.it


From jfox at mcmaster.ca  Mon Apr 28 19:16:07 2003
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 28 Apr 2003 13:16:07 -0400
Subject: [R] Algorithm did not converge
In-Reply-To: <FE4965577B60D711B885000BCD03D60F011514A2@mail.gov.ky>
Message-ID: <5.0.2.1.0.20030428131432.028ca8f0@mcmail.cis.mcmaster.ca>

Dear Laetitia,

At 11:04 AM 4/28/2003 -0500, Laine, Laetitia wrote:
>Help! Being a bit of a novice, please bear with me if this is a stupid
>question!
>
>I am trying to fit a saturated model to some count data that I have:
>
>model<-glm(COUNT~SP*LOC*COL*TIME*TREAT,poisson)
>
>but R keeps on crashing and coming up with (occasionally before crashing) an
>error that states:
>
>Algorithm did not converge in: (if(is.empty.model(mt)) glm.fit.null else
>glm.fit)(x = X, y = Y,
>
>What am I doing wrong?

Perhaps there's a 0 count in COUNT (which doesn't explain a crash but would 
explain lack of convergence).

I hope that this helps,
  John

____________________________
John Fox
Department of Sociology
McMaster University
email: jfox at mcmaster.ca
web: http://www.socsci.mcmaster.ca/jfox


From pcampbell at econ.bbk.ac.uk  Mon Apr 28 16:27:39 2003
From: pcampbell at econ.bbk.ac.uk (Phineas Campbell)
Date: Mon, 28 Apr 2003 15:27:39 +0100
Subject: [R] Installtion
Message-ID: <3EAD3A5B.4000406@econ.bbk.ac.uk>

I've spent the past couple of months trying to install R-1.6.2 on my 
Sunblade 100 running SunOS 5.9, so I am getting desparate.  I tried the 
gcc 3.2 compiler, but I understand this is still a bit buggy.  So I 
downloaded an evaluation copy of Sun Forte Developer 7 compiler and ran 
the configure script. I've piped the configure command output to 
www.phineas.blueyonder.co.uk/config.out where there is an <Fortran name 
mangling scheme error> and the config.log output is at 
www.phineas.blueyonder.co.uk/config.log.  The complier will build c 
executables but I have not tried compiling either C++ or Fortan code. 
 I've installed readline.3..  I will do anything it takes to R working.

Phineas Campbell
pcampbell at econ.bbk.ac.uk


From stuart at feerick.org.uk  Mon Apr 28 19:50:57 2003
From: stuart at feerick.org.uk (Stuart Feerick)
Date: Mon, 28 Apr 2003 18:50:57 +0100
Subject: [R] Compiling R-1.7.0 on Mac OS X
Message-ID: <F6EEA1D8-79A1-11D7-A993-000393D3DD4E@feerick.org.uk>

I'm having trouble compiling the latest version of R (1.7.0) under OS 
(10.2.5), after running ./configure then make, building fails on the 
file main/Rdynload.c with the following error message.

gcc   -I../../src/extra/pcre -no-cpp-precomp -I. -I../../src/include 
-I../../src/include -I/sw/include -DHAVE_CONFIG_H   -g -O2 -c 
Rdynload.c -o Rdynload.o
Rdynload.c: In function `R_FindSymbol':
Rdynload.c:1036: `CFunTab' undeclared (first use in this function)
Rdynload.c:1036: (Each undeclared identifier is reported only once
Rdynload.c:1036: for each function it appears in.)


Looking back through the list, I saw this problem was discussed last 
year (http://maths.newcastle.edu.au/~rking/R/help/02a/4840.html), and I 
have tried the solution proposed there, using the Fink version of 
dlcompat, but with no success.  Does anyone have another suggestion?

If people reply to me in the first instance I will summarize the 
replies to thee list.

Thanks for any help,

Stuart

--
stuart at feerick.org.uk


From rvaradha at jhsph.edu  Mon Apr 28 19:52:44 2003
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Mon, 28 Apr 2003 13:52:44 -0400
Subject: [R] Multiple Integration
Message-ID: <6ecebe6ebbc0.6ebbc06ecebe@jhsph.edu>

You should get an error message from "adapt" since it doesn't 
understand what value to use for x[1]. However, in your case you are 
not getting an error message probably because you already have an 
object named "x" somewhere in your current working directory. This may 
explain the error.

If you want to use "adapt", your integration region must 
be "rectangular", which is not the case in your problem. But using 
indicator function, it is easy to turn your region into a rectangular 
region and then use "adapt".

Hope this helps,

Ravi.


----- Original Message -----
From: N Dey <ndey00 at yahoo.com>
Date: Saturday, April 26, 2003 8:56 am
Subject: [R] Multiple Integration

> Dear all,
> 
> May I do multiple integration using R? I was looking
> adapt but it is saying it integrates a scalar function
> over a multidimensional rectangle. I have integrand of
> several variable and upper, lower limit too variable.
> 
> I wanted to see the result using adapt (though it is
> not for this purpose, I suppose)
> 
> Func<-function(x){(x[1]*x[2])}
> adapt(2, lo=c(0,1), up=c(1,x[1]), functn=Func)
> 
> it is not giving any error(it should, if it is not the
> correct way of putting up) but also not giving correct
> result.
> 
> Is there any package to handle multiple integration in
> R??
> 
> Thanking you,
> with best regards,
> N. Dey
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From kevin.werner at noaa.gov  Mon Apr 28 21:08:30 2003
From: kevin.werner at noaa.gov (Kevin Werner)
Date: Mon, 28 Apr 2003 13:08:30 -0600
Subject: [R] tcl on linux
Message-ID: <3EAD7C2E.8020300@noaa.gov>

Hello: I am a new R user trying to integrate existing tcl/tk code into 
R. I installed R on a linux system and was able to access the tcl 
interpreter that came with R just fine. However I am unable to access 
some tcl packages with the tcl package require command. Is it possible 
for R to use the tcl interpreter that already exists on the system in 
place the one that (apparently) came with R?

Thanks,
Kevin

Kevin Werner
Hydrologist, NWS/CBRFC


From kevin.werner at noaa.gov  Mon Apr 28 21:10:02 2003
From: kevin.werner at noaa.gov (Kevin Werner)
Date: Mon, 28 Apr 2003 13:10:02 -0600
Subject: [R] Informix database
Message-ID: <3EAD7C8A.3060908@noaa.gov>

Hello: Has anyone interfaced R with an Informix database? Any suggestions?

Thanks,
Kevin

Kevin Werner
Hydrologist, NWS/CBRFC


From dbcfmp at unileon.es  Mon Apr 28 21:57:58 2003
From: dbcfmp at unileon.es (Felipe)
Date: Mon, 28 Apr 2003 21:57:58 +0200
Subject: [R] Compiling R-1.7.0 on Mac OS X
In-Reply-To: <F6EEA1D8-79A1-11D7-A993-000393D3DD4E@feerick.org.uk>
Message-ID: <B5B4E33C-79B3-11D7-9DE6-0003936778C4@unileon.es>

I have the same system. R 1.7.0 compiles perfectly using fink. I cannot 
provide further help, sorry. Good luck.
Felipe

El Lunes, 28 abril, 2003, a las 07:50 PM, Stuart Feerick escribi?:

> I'm having trouble compiling the latest version of R (1.7.0) under OS 
> (10.2.5), after running ./configure then make, building fails on the 
> file main/Rdynload.c with the following error message.
>
> gcc   -I../../src/extra/pcre -no-cpp-precomp -I. -I../../src/include 
> -I../../src/include -I/sw/include -DHAVE_CONFIG_H   -g -O2 -c 
> Rdynload.c -o Rdynload.o
> Rdynload.c: In function `R_FindSymbol':
> Rdynload.c:1036: `CFunTab' undeclared (first use in this function)
> Rdynload.c:1036: (Each undeclared identifier is reported only once
> Rdynload.c:1036: for each function it appears in.)
>
>
> Looking back through the list, I saw this problem was discussed last 
> year (http://maths.newcastle.edu.au/~rking/R/help/02a/4840.html), and 
> I have tried the solution proposed there, using the Fink version of 
> dlcompat, but with no success.  Does anyone have another suggestion?
>
> If people reply to me in the first instance I will summarize the 
> replies to thee list.
>
> Thanks for any help,
>
> Stuart
>
> --
> stuart at feerick.org.uk
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From rgrubbfink at cox.net  Mon Apr 28 22:35:54 2003
From: rgrubbfink at cox.net (rgrubbfink@cox.net)
Date: Mon, 28 Apr 2003 16:35:54 -0400
Subject: [R] R.exp file on AIX 4.3.3
Message-ID: <20030428203554.UBYZ7627.lakemtao08.cox.net@smtp.central.cox.net>

I tried to compile R 1.7.0 on AIX 4.3.3 today. My initial error message was that ../../etc/R.exp could not be found.

I traced my way through the Makefiles to find where it should have been created, and found it in src/main/Makefile. I then tried typing make ../../etc/R.exp (in the src/main directory), but ldAIX4 created a nearly empty file (contains only "#! ." on line one).

So can anyone tell me why the normal make process doesn't create R.exp and how can I fix it? I am using GNU make 3.79.1, and gcc 2.95.3 (Fortran Front End version 0.5.25)

Thanks


From xiao.gang.fan1 at libertysurf.fr  Mon Apr 28 22:46:43 2003
From: xiao.gang.fan1 at libertysurf.fr (=?iso-8859-1?Q?Fan?=)
Date: Mon, 28 Apr 2003 22:46:43 +0200
Subject: =?iso-8859-1?Q?Re:_[R]_Basic_date_time_arithmetics_operations?=
Message-ID: <HE2N1V$9667B37A0D5EE8C13EB4A92466BEA481@tiscali.fr>

>>Also for the function seq.dates (or seq.POSIXt), the 
>>case for by="months" would be more useful if it takes
>>the situation of the end of month into account. 
>>For example,
>>
>>> seq(ISOdate(2002,1,31), by="months", length=3)
>>
>>"2002-01-31 13:00:00 CET" 
>>"2002-03-03 13:00:00 CET" 
>>"2002-03-31 13:00:00 CET"
>>
>>rather than
>>
>>"2002-01-31 13:00:00 CET" 
>>"2002-02-28 13:00:00 CET" 
>>"2002-03-31 13:00:00 CET"
>
>I don't think that's a well-defined request.  What would you want from
>
> seq(ISOdate(2002,12,30), by="months", length=5)
>
>Should it give February 27, since you asked for the day before the end
>of the month?  What should it do in April?
>
>I think the current behaviour is doing what it should doing.  If you
>really want the last day of the month in three successive months, then
>you should probably get a sequence of first days of months, and then
>subtract a day from each.  Wish I could tell you how to do that!
>Hopefully someone else will.
>
>By the way, I noticed a typo in the help for difftime() (it was
>missing an escape on one of the % signs, so the end of the line
>disappeared), and I've committed a fix to R-patched.
>
>Duncan Murdoch
>

1. When we shift or add/substract n month(s) from a date, n should be
refleted in the month level (or more precisely YYYYMM level) arithmetics 
between the resulting date and the original date,

2. For the day of month level, some sort of alignment should be considered. 

The simplest way would be like what's doing the Oracle SQL function 
add_months(d,n): If d is the last day of the month or if the resulting month 
has fewer days than the day component of d, then the result is the last day 
of the resulting month. Otherwise, the result has the same day component as d.

In a time series specialized software like Fame, the function SHIFTMTH
seems having more sophisticated options.

Best
--
Fan


************ VITE, C'EST LE MOMENT DE VOUS ABONNER A L'ADSL !!! **********
Du 3 avril au 5 mai, s?rie limit?e ADSL 128K, cliquez vite ici : http://register.tiscali.fr/adsl/ 
Offre promotionnelle soumise ? conditions, r?serv?e aux nouveaux abonn?s ADSL Tiscali.


From jonathan_li at agilent.com  Mon Apr 28 22:51:17 2003
From: jonathan_li at agilent.com (jonathan_li@agilent.com)
Date: Mon, 28 Apr 2003 13:51:17 -0700
Subject: [R] how to present a table in powerpoint?
Message-ID: <FC0B9DA2600ED4118F76009027AA5DDD05ABD462@ALEX2>

Hi,

I have a nicely printed table of results generated by R's 
> print(myresult)
where myresult is a "data frame".
 
I am trying to put this table into a powerpoint slide for presentation without re-typing and re-formating, i.e.,
present it as it is in the R window. This saves time when there are a lot of tables to be presented.

I tried 
> sink("myresult.txt")
> print(myresult)
> sink()

resulting text file looks nice, but how can I insert it into powerpoint without losing its formatting? When I think more carefully about it, it seems to me that we need a way to convert this text presentation into graphical presentation such as postscript, then it would be easy to paste it into powerpoint without losing its formatting. 

I suspect that this is a problem many other may also face sometimes. After doing searching in R-help archive with keywords like "powerpoint", "presentation", I came up with many entries about presenting graphs in powerpoint, but not one about presenting tables of numbers.

Your help is highly appreciated.
Jonathan


From kwan022 at stat.auckland.ac.nz  Mon Apr 28 23:15:03 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 29 Apr 2003 09:15:03 +1200 (NZST)
Subject: [R] how to present a table in powerpoint?
In-Reply-To: <FC0B9DA2600ED4118F76009027AA5DDD05ABD462@ALEX2>
Message-ID: <Pine.LNX.4.44.0304290914360.2780-100000@stat56.stat.auckland.ac.nz>

Have you tried to change the fonts of the table (in PowerPoint) to Courier 
or Courier New?

Kevin


On Mon, 28 Apr 2003 jonathan_li at agilent.com wrote:

> Date: Mon, 28 Apr 2003 13:51:17 -0700
> From: jonathan_li at agilent.com
> To: r-help at stat.math.ethz.ch
> Cc: jonathan_li at agilent.com
> Subject: [R] how to present a table in powerpoint?
> 
> Hi,
> 
> I have a nicely printed table of results generated by R's 
> > print(myresult)
> where myresult is a "data frame".
>  
> I am trying to put this table into a powerpoint slide for presentation without re-typing and re-formating, i.e.,
> present it as it is in the R window. This saves time when there are a lot of tables to be presented.
> 
> I tried 
> > sink("myresult.txt")
> > print(myresult)
> > sink()
> 
> resulting text file looks nice, but how can I insert it into powerpoint without losing its formatting? When I think more carefully about it, it seems to me that we need a way to convert this text presentation into graphical presentation such as postscript, then it would be easy to paste it into powerpoint without losing its formatting. 
> 
> I suspect that this is a problem many other may also face sometimes. After doing searching in R-help archive with keywords like "powerpoint", "presentation", I came up with many entries about presenting graphs in powerpoint, but not one about presenting tables of numbers.
> 
> Your help is highly appreciated.
> Jonathan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From ross at biostat.ucsf.edu  Tue Apr 29 00:25:04 2003
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 28 Apr 2003 15:25:04 -0700
Subject: [R] Problme with <<- (was Apparent namespace problem)
In-Reply-To: <Pine.LNX.4.44.0304260817030.23645-100000@gannet.stats>
References: <20030425224955.GC22596@epibiosun115-4.libaux.ucsf.edu>
	<Pine.LNX.4.44.0304260817030.23645-100000@gannet.stats>
Message-ID: <20030428222504.GE21975@epibiosun115-4.libaux.ucsf.edu>

I'd like to thank both Thomas Blackwell and Brian Ripley for their help.

The source of the problem was a snow-related think-o
	clusterEvalQ(cl, crossval.setup(x, y, groups, theta.fit,
			theta.predict))
evaluates crossval.setup on remote nodes, using the values of x, y,
etc *on those nodes*.  But this was precisely the data that was to be
distributed.  So the call failed, and the assignment statement never
had a chance to execute.

For those who follow, I note the proper code is
      clusterCall(cl, crossval.setup,
			x, y, groups, theta.fit, theta.predict)

I do have a couple more comments and questions on the message below,
if anyone would care to respond.


On Sat, Apr 26, 2003 at 08:26:39AM +0100, Prof Brian Ripley wrote:
> On Fri, 25 Apr 2003, Ross Boylan wrote:
> 
> > I'm seeing some strange behavior while using the snow package for
> > networked computers.  I believe it's caused by name space resolution
> > issues, and would appreciate any suggestions tracking it down.
> 
> `namespace' is a technical term in R (some packages have namespaces), and
> not I think involved here. I think you meant `scoping issues', although
> the exact issue seems to be an inappropriate use of <<-.

Yes, it's scoping.  I was using namespace generically.

I'm not sure what the best way is to describe the actual problem I
had, namely that variables known on one the parent node were not known
on the child.  "scoping" seems to imply a single process on a single
machine, and "namespace" is already taken for something else.


> 
> > First, is there a way to find out what frame (as in frames in
> > environments, not data frames) a name is being obtained from or put
> > into?
> 
> ?find.

Here's where I have a question.  find appears to operate on the search
path.  I thought that was a different concept from environments and
frames.  The search path, I think, doesn't include dynamically created
frames from the course of function execution.

> 
> > Second, how closely does the evaluation environment in the
> > browser/debugger match what you would get in the function at the same
> > point?  I ask because if I evaluate a statement in the browser it
> > seems to work one way, but if I execute it it works another way.
> > 
> > The statement is
> > clusterEvalQ(cl, crossval.setup(x, y, groups, theta.fit,
> > theta.predict))
> > 
> > This evaluates the crossval.setup function across the cluster cl.
> > 
> > crossval.setup is a function which puts its arguments in a list g (a
> > local variable) and then does gcv <<- g.  The intent is to stuff the
> > data into a global variable for use by later function calls.
> 
> If that is the intention, please use assign() explicitly.  That is not
> what <<- is intended to do in R and it probably should only be used to
> change an already existing value somewhere in the environment tree.

As a precaution, I had created the variable in the global space.

> 
> assign("gcv", g, envir=NULL), I believe

I used pos=.GlobalEnv

> 
> [...]
> 
> I have ignored the `snow' aspect, as I don't understand enough of how you 
> are using it: it might be relevant.

Yes, it was.

> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


From mschwartz at medanalytics.com  Tue Apr 29 00:28:46 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Mon, 28 Apr 2003 17:28:46 -0500
Subject: [R] how to present a table in powerpoint?
In-Reply-To: <FC0B9DA2600ED4118F76009027AA5DDD05ABD462@ALEX2>
Message-ID: <006001c30dd5$899c1a90$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
>jonathan_li at agilent.com
>Sent: Monday, April 28, 2003 3:51 PM
>To: r-help at stat.math.ethz.ch
>Cc: jonathan_li at agilent.com
>Subject: [R] how to present a table in powerpoint?
>
>
>Hi,
>
>I have a nicely printed table of results generated by R's 
>> print(myresult)
>where myresult is a "data frame".
> 
>I am trying to put this table into a powerpoint slide for 
>presentation without re-typing and re-formating, i.e., present 
>it as it is in the R window. This saves time when there are a 
>lot of tables to be presented.
>
>I tried 
>> sink("myresult.txt")
>> print(myresult)
>> sink()
>
>resulting text file looks nice, but how can I insert it into 
>powerpoint without losing its formatting? When I think more 
>carefully about it, it seems to me that we need a way to 
>convert this text presentation into graphical presentation 
>such as postscript, then it would be easy to paste it into 
>powerpoint without losing its formatting. 
>
>I suspect that this is a problem many other may also face 
>sometimes. After doing searching in R-help archive with 
>keywords like "powerpoint", "presentation", I came up with 
>many entries about presenting graphs in powerpoint, but not 
>one about presenting tables of numbers.
>
>Your help is highly appreciated.
>Jonathan


This is less an R issue and more a fixed width font versus variable
width font issue.

The default font in PP is usually a variable width font, such as
Arial.  It makes for easier and more natural reading. As a result, an
'I' take up less width than a "W" and therefore the text cannot line
up properly from one line to another.

R's console uses a fixed width font by default so that columns of
characters (including spaces) can align vertically and give you the
nicely aligned columns of numbers, etc.

You will need to change the font in PP to a fixed width font like
Courier (or Courier New, which is the scalable TrueType Font version)
to be able to have your columns align vertically, as they do in R's
console.  Highlight the text you paste into PP and change the font to
Courier New and to a size that fits your slide appropriately.

If this is something that you do frequently, you can create a slide
template in PP that has Courier New as the default font, specifically
for use in this situation.

HTH,

Marc Schwartz


From fredrik.lundgren at norrkoping.mail.telia.com  Tue Apr 29 02:23:32 2003
From: fredrik.lundgren at norrkoping.mail.telia.com (Fredrik Lundgren)
Date: Tue, 29 Apr 2003 02:23:32 +0200
Subject: [R] "prediction intervals for glm"
Message-ID: <200304290223.32871.fredrik.lundgren@norrkoping.mail.telia.com>

Hello R,

Where can i find prediction intervals for glm in R?

Sincerely Fredrik Lundgren


From spencer.graves at pdf.com  Tue Apr 29 05:43:38 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 28 Apr 2003 20:43:38 -0700
Subject: [R] "prediction intervals for glm"
References: <200304290223.32871.fredrik.lundgren@norrkoping.mail.telia.com>
Message-ID: <3EADF4EA.6040204@pdf.com>

"?predict.glm" produced something in my copy of R 1.6.2 under Windows 
2000.

hth.  spencer graves

Fredrik Lundgren wrote:
> Hello R,
> 
> Where can i find prediction intervals for glm in R?
> 
> Sincerely Fredrik Lundgren
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From faheem at email.unc.edu  Tue Apr 29 07:08:44 2003
From: faheem at email.unc.edu (Faheem Mitha)
Date: Tue, 29 Apr 2003 01:08:44 -0400 (EDT)
Subject: [R] thick plot lines
Message-ID: <Pine.LNX.4.44.0304290047350.29823-100000@Chrestomanci>


Dear People,

In a qqplot I am doing, I get lines/points that are very thick. I've tried
setting the lwd variable to 0.1, but it doesn't seem to have any effect.
Also, I have set the value of lty to dashed, but I still get dots. The
command looks like

qqplot(cdf.inv(seq(0,1,length=size),theta,pos,len),empmargdistvec(len,theta,pos,size),
       xlim=c(-theta,theta), ylim=c(-theta,theta), lwd=0.1,
       xlab="Marginal Quartiles", ylab="Empirical Marginal", col="red", lty="dashed")

I tried putting

par(lty="dashed",lwd=0.1)

before this, but this doesn't have any effect either.

I'm now wondering if I am doing something wrong. Does qqplot perhaps not
accept these parameters? What should I do to make the lines/points
thinner?

                                              Faheem.


From gisar at nus.edu.sg  Tue Apr 29 08:02:33 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Tue, 29 Apr 2003 14:02:33 +0800
Subject: [R] thick plot lines
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F24C@MBXSRV03.stf.nus.edu.sg>

Please give us a reproducible example. I don't know of cdf.inv, theta,
empmargdistvec, ...

Why should qqplot produce lines ? If you meant to say the axis, then
look under axis(). If you meant the plotting symbols, then use the pch
argument as bellow. One trick would be to plot using the character '.'
instead. 

y <- rt(200, df = 5)
qqplot(y, rt(300, df = 5), pch=".")

If you meant the qqline, then you can supply the lty, col argument
inside qqline().

y <- rt(200, df = 5)
qqnorm(y)
qqline(y, col = 2, lty=3)

Reading par() might be useful.

Regards, Adai.


-----Original Message-----
From: Faheem Mitha [mailto:faheem at email.unc.edu] 
Sent: Tuesday, April 29, 2003 1:09 PM
To: r-help at stat.math.ethz.ch
Subject: [R] thick plot lines



Dear People,

In a qqplot I am doing, I get lines/points that are very thick. I've
tried setting the lwd variable to 0.1, but it doesn't seem to have any
effect. Also, I have set the value of lty to dashed, but I still get
dots. The command looks like

qqplot(cdf.inv(seq(0,1,length=size),theta,pos,len),empmargdistvec(len,th
eta,pos,size),
       xlim=c(-theta,theta), ylim=c(-theta,theta), lwd=0.1,
       xlab="Marginal Quartiles", ylab="Empirical Marginal", col="red",
lty="dashed")

I tried putting

par(lty="dashed",lwd=0.1)

before this, but this doesn't have any effect either.

I'm now wondering if I am doing something wrong. Does qqplot perhaps not
accept these parameters? What should I do to make the lines/points
thinner?

                                              Faheem.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From jerome at hivnet.ubc.ca  Tue Apr 29 09:31:07 2003
From: jerome at hivnet.ubc.ca (Jerome Asselin)
Date: Tue, 29 Apr 2003 00:31:07 -0700
Subject: [R] thick plot lines
In-Reply-To: <Pine.LNX.4.44.0304290047350.29823-100000@Chrestomanci>
References: <Pine.LNX.4.44.0304290047350.29823-100000@Chrestomanci>
Message-ID: <200304290736.AAA04444@hivnet.ubc.ca>


Try the "cex" parameter. (See ?par.)
Here is an example.

par(mfrow=c(2,1))
plot(1,1)
plot(1,1,cex=.5)

Cheers,
Jerome

On April 28, 2003 10:08 pm, Faheem Mitha wrote:
> Dear People,
>
> In a qqplot I am doing, I get lines/points that are very thick. I've
> tried setting the lwd variable to 0.1, but it doesn't seem to have any
> effect. Also, I have set the value of lty to dashed, but I still get
> dots. The command looks like
>
> qqplot(cdf.inv(seq(0,1,length=size),theta,pos,len),empmargdistvec(len,th
>eta,pos,size), xlim=c(-theta,theta), ylim=c(-theta,theta), lwd=0.1,
>        xlab="Marginal Quartiles", ylab="Empirical Marginal", col="red",
> lty="dashed")
>
> I tried putting
>
> par(lty="dashed",lwd=0.1)
>
> before this, but this doesn't have any effect either.
>
> I'm now wondering if I am doing something wrong. Does qqplot perhaps not
> accept these parameters? What should I do to make the lines/points
> thinner?
>
>                                               Faheem.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From phgrosjean at sciviews.org  Tue Apr 29 09:56:22 2003
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue, 29 Apr 2003 09:56:22 +0200
Subject: [R] Feedback about SciViews?
Message-ID: <MABBLJDICACNFOLGIHJOMEIIDGAA.phgrosjean@sciviews.org>

Hello,

This message is little off-topic in R-help. Sorry for that, but not all
interested people are wired yet to r-sig-gui
(http://www.stat.math.ethz.ch/mailman/listinfo/r-sig-gui). Thanks for your
comprehension.

A preview version of SciViews (a Graphical User Interface for R under
Windows, http://www.sciviews.org) was released a few weeks ago. Since then,
the Web site recorded several thousands of downloads. I would really
appreciate your feedback:
- What you like,
- What you don't like,
- Wich features you would like to get in the next release.

I got already some comments. I will post a summary in a while in r-sig-gui.

Best,

Philippe Grosjean

P.S.: we are working now mainly on features like a complete object explorer
and "libraries" (that is, graphical menus in the form of graph galleries,
electronic reference cards, assistants,...).

...........]<(({?<...............<?}))><...............................
 ) ) ) ) )
( ( ( ( (       Dr. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (       LOV, UMR 7093
 ) ) ) ) )      Station Zoologique
( ( ( ( (       Observatoire Oc?anologique
 ) ) ) ) )      BP 28
( ( ( ( (       06234 Villefranche sur mer cedex
 ) ) ) ) )      France
( ( ( ( (
 ) ) ) ) )      tel: +33.4.93.76.38.18, fax: +33.4.93.76.38.34
( ( ( ( (
 ) ) ) ) )      e-mail: phgrosjean at sciviews.org
( ( ( ( (       SciViews project coordinator (http://www.sciviews.org)
 ) ) ) ) )
.......................................................................


From mkondrin at hppi.troitsk.ru  Tue Apr 29 14:20:00 2003
From: mkondrin at hppi.troitsk.ru (M.Kondrin)
Date: Tue, 29 Apr 2003 12:20:00 +0000
Subject: [R] .Rd file with multiple help entries?
Message-ID: <3EAE6DF0.9040801@hppi.troitsk.ru>

Hello!
I wrote a small package and want to write a help for it. I look through 
"recommended"  packages and it seems to me that writing one .Rd files 
with multiple entries for help topics is OK. But I can not do it myself. 
Here is an abridged version of my Rd:
 \name{
  Airy
}
\alias{
  Airy
}
\title{
    Airy special functions in complex domain
}
\description{
  Airy function of complex argument
}
\usage{Airy( x, diff = FALSE, scaled = FALSE )}
\arguments{
  \item{x}{
    Complex vector.
  }
  \item{diff}{
    If TRUE return value is first derivative of Airy function.
  }
  \item{scaled}{
    If TRUE return value is scaled
  }
}
\value{
  Complex vector of the same size as x.
}
\keyword{
  math
}
\eof
\name{
  Biry
}
\alias{
  Biry
}
\title{
  Bi - second Airy special functions in complex domain
}
\description{
    Second Airy function of complex argument
}
\usage{
Biry( x, diff = FALSE, scaled = FALSE )
}
\arguments{
  \item{x}{
    Complex vector.
  }
  \item{diff}{
    If TRUE return value is first derivative of Bi function.
  }
  \item{scaled}{
      If TRUE return value is scaled
  }
}
\value{
  Complex vector of the same size as x.
}
\keyword{
  math
}
\eof
But R CMD check ./MyPackage does not like this file and complains about 
multiple \name \alias \description etc. entries in Rd file. As a result 
it produce latex help file with help notes only for Airy function (there 
is nothing about Biry).
Thank you very much if you can help me with this dumb problem.


From chrysopa at insecta.ufv.br  Tue Apr 29 02:58:24 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Mon, 28 Apr 2003 21:58:24 -0300
Subject: [R] [OFF] File name completation on XEmacs+ESS.
In-Reply-To: <200304281356.h3SDufd08288@punik.econ.au.dk>
References: <200304281039.54173.chrysopa@insecta.ufv.br>
	<200304281356.h3SDufd08288@punik.econ.au.dk>
Message-ID: <200304282158.24815.chrysopa@insecta.ufv.br>

Em Seg 28 Abr 2003 10:56, Ott Toomet escreveu:
> Hi,
>
> if you try C-h k TAB, it says the function is
>
> comint-dynamic-complete
>
> I have not tested it.
>
> Ott
>
Ott,

this describe the function used for object and function completations. Not for 
file name completation.

Thanks
Ronaldo

-- 
	"What do you do when your real life exceeds your wildest fantasies?"
	"You keep it to yourself."
		-- Broadcast News
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From chrysopa at insecta.ufv.br  Tue Apr 29 03:16:05 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Mon, 28 Apr 2003 22:16:05 -0300
Subject: [R] Testing for scale e mu in survreg
Message-ID: <200304282216.05599.chrysopa@insecta.ufv.br>

Hi,

Normally I make survival analysis using survreg in survival package.

It is simple to compare curves for different levels. But in this case all 
curves have the same estimated scale parameter.

In some cases, curves are graphically different in your behaviour.
One curve is like type I curve (1/scale > 1).
Other curve is like type III curve (1/scale < 1).
All graphics made normal and with y log scale to compare.

If I make an analysis separate for each factor, I can get obtain different 
scale parameters, but is not possible to compare the mean time for death of 
this two curves with different scales.

Existe any mean to make a survival model in R that test difference of scale 
for and difference of mean time for dead for factors?

Or I'm crazy for think in this?

Thanks
Ronaldo
-- 
<Flav> Win 98 Psychic edition: We'll tell you where you're going tomorrow
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From chrysopa at insecta.ufv.br  Tue Apr 29 03:17:17 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Mon, 28 Apr 2003 22:17:17 -0300
Subject: [R] Help to make a simple function
Message-ID: <200304282217.17108.chrysopa@insecta.ufv.br>

Hi all,

I try to make a program for comparison between matrix cells.

Here um simple example:

3 |a b a
2 |b b b
1 |a b a
  -------
   1 2 3

This is tabulated like this:

x y sp
1 1 a
1 2 b
1 3 a
2 1 b
2 2 b
2 3 b
3 1 a
3 2 b
3 3 a

Then, I need to make the follow calcule:

==============================================
Change in sp levels from 1x1 area to 2x2 area:
----------------------------------------------
from (1:1) to (1:2) change of the "a" to "b"
change count = 1

from (1:1) to (2:2) change of the "a" to "b"
change count = 1

from (1:1) to (2:1) change of the "a" to "b"
change count = 1
----------------------------------------------
Total change counts = 3
==============================================

==============================================
Change in sp levels from 2x2 area to 3x3 area:
----------------------------------------------
from (1:2) to (1:3) change of the "b" to "a"
change count = 1

from (1:2) to (2:3) change of the "b" to "b" (not change)
change count = 0

from (2:2) to (1:3) change of the "b" to "a"
change count = 1

from (2:2) to (2:3) change of the "b" to "b"
change count = 0

from (2:2) to (3:3) change of the "b" to "a"
change count = 1

from (2:2) to (3:2) change of the "b" to "b"
change count = 0

from (2:2) to (3:1) change of the "b" to "a"
change count = 1
----------------------------------------------
Total change counts = 4
==============================================

The result is a table like this

area changecounts
1      0
4      3
9      4

Anybody have any idea for solve this?

Any sugestions?

Thanks for all

Ronaldo






-- 
Before destruction a man's heart is haughty, but humility goes before honour.
		-- Psalms 18:12
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From maechler at stat.math.ethz.ch  Tue Apr 29 11:08:30 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 29 Apr 2003 11:08:30 +0200
Subject: [R] Re: SunOS 2.9 Installation (was "Sorry")
In-Reply-To: <NGECIFANPOJAGABBAEAPAENACDAA.phineas@blueyonder.co.uk>
References: <3EAD3A5B.4000406@econ.bbk.ac.uk>
	<NGECIFANPOJAGABBAEAPAENACDAA.phineas@blueyonder.co.uk>
Message-ID: <16046.16654.630639.394965@gargle.gargle.HOWL>

>>>>> "Phineas" == Phineas Campbell <phineas at blueyonder.co.uk>
>>>>>     on Mon, 28 Apr 2003 15:50:01 +0100 writes:

    Phineas> On my previous message I gave incorrect URL's for
    Phineas> the configuration output.  They should be
    Phineas> http://www.phineas.pwp.blueyonder.co.uk/config.log
    Phineas> and
    Phineas> http://www.phineas.pwp.blueyonder.co.uk/config.out

    Phineas> Also this technique appears to work with Netscape
    Phineas> on Solaris, but not IE on Windows. 
(no real problem; I doubt that IE users will be able to help
 with SunOS configuration ;-)

    Phineas> on Solaris, but not IE on Windows. If this is not a
    Phineas> sensible way to post diagnostic output let me know
    Phineas> and I will post them in a different way.

yes, it's a good way, particularly for the large config.out file. 
Note that I've  prepended  "http://" in order to get proper URLs

One first comment: I see this is about installation of 1.6.2.
Could you please "repeat the exercise" with the current 1.7.0
instead?

Regards,

-- 
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From maechler at stat.math.ethz.ch  Tue Apr 29 11:31:44 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 29 Apr 2003 11:31:44 +0200
Subject: [R] Feedback about SciViews?
In-Reply-To: <MABBLJDICACNFOLGIHJOMEIIDGAA.phgrosjean@sciviews.org>
References: <MABBLJDICACNFOLGIHJOMEIIDGAA.phgrosjean@sciviews.org>
Message-ID: <16046.18048.201681.890183@gargle.gargle.HOWL>

>>>>> "PhGr" == Philippe Grosjean <phgrosjean at sciviews.org>
>>>>>     on Tue, 29 Apr 2003 09:56:22 +0200 writes:

    PhGr> Hello, This message is little off-topic in
    PhGr> R-help. Sorry for that, but not all interested people
    PhGr> are wired yet to r-sig-gui
    PhGr> (http://www.stat.math.ethz.ch/mailman/listinfo/r-sig-gui). Thanks
    PhGr> for your comprehension.

    PhGr> A preview version of SciViews 
    PhGr> (a Graphical User Interface for R under Windows,
					    =============

    PhGr> http://www.sciviews.org)  was released a few weeks ago.

R for Windows already comes with a (simple) GUI.
Many of the R developers would rather think mostly about GUI
efforts that are platform INDEPENDENT, such as the standard Tcl/Tk
package (try "library(tcltk)" and the demos from "demo(package =
"tcltk")" in R), and the RGtk (http://www.omegahat.org/RGtk/) one.

For that reason, in the Bioconductor project (http://www.bioconductor.org),
the  "tkWidgets" package has been developed (built on top of R's
standard "tcltk" package -- which from 1.7.0 on does not need
extra efforts for installation on Windows).

Excuse that this sounds a bit negative, but platform independence
is one of the strengths of R.

Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From Saghir.Bashir at UCB-Group.com  Tue Apr 29 11:56:08 2003
From: Saghir.Bashir at UCB-Group.com (Bashir Saghir (Aztek Global))
Date: Tue, 29 Apr 2003 11:56:08 +0200
Subject: [R] how to present a table in powerpoint?
Message-ID: <3EBA5559F490D61189430002A5F0AE89030185A4@ntexcrd.braine.ucb>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030429/c58bb5f6/attachment.pl

From gemireni at qubisoft.it  Tue Apr 29 11:57:33 2003
From: gemireni at qubisoft.it (Gianluca Emireni)
Date: Tue, 29 Apr 2003 11:57:33 +0200
Subject: [R] (OFF):R2HTML
Message-ID: <HBEKIOBADKJHAGANMFFHEEMACAAA.gemireni@qubisoft.it>

Hi all,
I have a problem with the output given by package R2HTML: long column names
in matrices, data frames and tables appears in HTML page with no
"interspaces", does anyone knows how I can modify the file "r2html.css" to
format these first lines?
Thank you, Gianluca.


From B.Rowlingson at lancaster.ac.uk  Tue Apr 29 12:06:21 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 29 Apr 2003 11:06:21 +0100
Subject: [R] how to present a table in powerpoint?
In-Reply-To: <3EBA5559F490D61189430002A5F0AE89030185A4@ntexcrd.braine.ucb>
References: <3EBA5559F490D61189430002A5F0AE89030185A4@ntexcrd.braine.ucb>
Message-ID: <3EAE4E9D.5060906@lancaster.ac.uk>


>>resulting text file looks nice, but how can I insert it into powerpoint
>>without losing its formatting? When I think more carefully about it, it
>>seems to me that we need a way to convert this text presentation into
>>graphical presentation such as postscript, then it would be easy to paste
>>it into powerpoint without losing its formatting. 

  I dont have a Windows machine to hand, but wouldn't it be better to 
insert the table as an Excel spreadsheet? Get the data from R into Excel 
and then you should be able to insert the sheet into Powerpoint. Then it 
will look pretty.

  Write the table out with comma separators, and read into Excel. Or 
maybe the DCOM package will help:

http://cran.r-project.org/contrib/extra/dcom

Disclaimer: All untested, I'm using LaTeX for presentations!

Baz


From Fabrizio.DeAmicis at git.generali.ch  Tue Apr 29 12:07:51 2003
From: Fabrizio.DeAmicis at git.generali.ch (De Amicis Fabrizio (G.I.T.))
Date: Tue, 29 Apr 2003 12:07:51 +0200
Subject: [R] easy question
Message-ID: <6C9A2D9477234140A56E9D1B073B28E901DB42@gitmanex01.git.generali.ch>

Dear R.List,
I am starting to use R. I have an easy question. In a dataset of 15
variables, I am not able run correctly the index i of the do loop. 
Do you have any suggestion? 

NC <- function(x)

    for (i in 1:15) {  
    print(dim(table(dt[,"Vi"])))
    
}


Thank you in advance,
Fabrizio


---------------------------------------------------------------
Fabrizio De Amicis

IT Department
Generali Information Technologies - (GIT)

Centro Galleria 2,
Via Cantonale
CH - 6928 Manno - Switzerland
Tel  +41 91 806 6220
Fax +41 91 806 6298
E-mail: fabrizio.deamicis at git.generali.ch  




************************************************************************
The information in this email is confidential and may be legally... {{dropped}}


From kwan022 at stat.auckland.ac.nz  Tue Apr 29 12:51:57 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Tue, 29 Apr 2003 22:51:57 +1200 (NZST)
Subject: [R] easy question
In-Reply-To: <6C9A2D9477234140A56E9D1B073B28E901DB42@gitmanex01.git.generali.ch>
Message-ID: <Pine.LNX.4.44.0304292246270.17690-100000@stat56.stat.auckland.ac.nz>

Hi,

On Tue, 29 Apr 2003, De Amicis Fabrizio (G.I.T.) wrote:

> Dear R.List,
> I am starting to use R. I have an easy question. In a dataset of 15
> variables, I am not able run correctly the index i of the do loop. 
> Do you have any suggestion? 
> 
> NC <- function(x)
> 
>     for (i in 1:15) {  
>     print(dim(table(dt[,"Vi"])))

Why do you have "Vi" with quotes?  Your counter i isn't used anywhere in 
the loop.  I am assuming your dataset of 15 variables is a data frame or 
matrix?  Then you'll need dt[, i] instead.  It will read the $i^{th}$ 
column each time it runs through the loop.

On a side note.  The above function isn't right.  The NC function will 
need a variable x, which isn't used anywhere in the function.  You don't 
need to put the for() loop into the function at all.  (I'm assuming you 
have got a data frame or matrix called dt).

>     
> }



-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From brostaux.y at fsagx.ac.be  Tue Apr 29 13:11:41 2003
From: brostaux.y at fsagx.ac.be (Yves Brostaux)
Date: Tue, 29 Apr 2003 13:11:41 +0200
Subject: [R] R compilation problem on Sun Solaris 2.5.1
Message-ID: <5.1.0.14.1.20030429131014.00ae7ec0@fusamail.fsagx.ac.be>

Dear members,

Sorry for asking the same question again, but I was not able to solve this 
since my last post.

I'm not very used with Unix systems, but I got an old Sun/UltraSparc 
workstation running Solaris 2.5.1 and I tried to install R on it to able 
able to do some batch R processing while working on my pc.

I downloaded and installed following required and recommanded programs 
before installing R : perl 5.8.0, readline 4.3, gzip 1.3.5, zlib 1.1.4, 
make 3.80, jpeg 6b, libpng 1.2.4 and gcc 3.2.

I downloaded and unpacked R-1.7.0.tgz to /usr/src and ran
 > ./configure --prefix=/usr/local
 > make

During make execution, I get following error :

initializing class and method definition now... done
Error in gzfile (file, "wb"): unable to open connection
In addition: Warning message:
cannot open compressed file 'usr/share/src/R-1.7.0/library/methods/R/all.rda'
Execution halted

Does anybody know what mistake I made ? Thanks in advance,

-- 
Ir. Yves Brostaux - Statistics and Computer Science Dpt.
Gembloux Agricultural University
8, avenue de la Facult? B-5030 Gembloux (Belgium)
T?l : +32 (0)81 62 24 69
E-mail : brostaux.y at fsagx.ac.be
Web : http://www.fsagx.ac.be/si/


From dmurdoch at pair.com  Tue Apr 29 13:13:12 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Tue, 29 Apr 2003 07:13:12 -0400
Subject: [R] Feedback about SciViews?
In-Reply-To: <16046.18048.201681.890183@gargle.gargle.HOWL>
References: <MABBLJDICACNFOLGIHJOMEIIDGAA.phgrosjean@sciviews.org>
	<16046.18048.201681.890183@gargle.gargle.HOWL>
Message-ID: <r5nsavsd74t9rnlnpcnkd8mut67h1bivoa@4ax.com>

On Tue, 29 Apr 2003 11:31:44 +0200, you wrote:

>R for Windows already comes with a (simple) GUI.
>Many of the R developers would rather think mostly about GUI
>efforts that are platform INDEPENDENT, such as the standard Tcl/Tk
>package (try "library(tcltk)" and the demos from "demo(package =
>"tcltk")" in R), and the RGtk (http://www.omegahat.org/RGtk/) one.

That's true, but as the Windows maintainer, I would *love* to have an
alternative to Rgui.  The Graphapp package that underlies it is not
easy to work with.

I think the best long term strategy is to have a clean division
between the user interface aspects of R (which are necessarily
platform dependent) and the underlying computing engine (which should
be platform independent).  It should be as easy to experiment with the
user interface as it is to experiment with other aspects of
statistical computing.  TCL/TK is one way to realize this, but should
not be the only one.

Duncan Murdoch


From jfox at mcmaster.ca  Tue Apr 29 13:27:23 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 29 Apr 2003 07:27:23 -0400
Subject: [R] easy question
In-Reply-To: <6C9A2D9477234140A56E9D1B073B28E901DB42@gitmanex01.git.gene
 rali.ch>
Message-ID: <5.1.0.14.2.20030429065802.01e44d10@mcmail.cis.mcmaster.ca>

Dear Fabrizio

At 12:07 PM 4/29/2003 +0200, De Amicis Fabrizio (G.I.T.) wrote:
>Dear R.List,
>I am starting to use R. I have an easy question. In a dataset of 15
>variables, I am not able run correctly the index i of the do loop.
>Do you have any suggestion?
>
>NC <- function(x)
>
>     for (i in 1:15) {
>     print(dim(table(dt[,"Vi"])))
>
>}
>

The short answer is that you need to paste the number in i to "V" in order 
to create a proper column index. I assume that the columns of dt are named 
"V1", ..., "V15":

     print(dim(table(dt[,paste("V",i,sep="")])))

Alternatively, you could use something like

     for (i in paste("V",1:15,sep="")) print(dim(table(dt[,i])))

or even more simply, just index the columns by number

     for (i in 1:15) print(dim(table(x[,i])))

Some other points, however:

(1) The argument to your function is x, but you're indexing a variable 
called dt.

(2) A simpler approach to counting the unique elements in each column is

         apply(dt, 2, function(x) length(unique(x)))

(3) Since this apparently applies to a particular matrix or data frame, why 
write a function to perform the operation?

I hope that this helps,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox


From jfox at mcmaster.ca  Tue Apr 29 13:27:23 2003
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 29 Apr 2003 07:27:23 -0400
Subject: [R] easy question
In-Reply-To: <6C9A2D9477234140A56E9D1B073B28E901DB42@gitmanex01.git.gene
 rali.ch>
Message-ID: <5.1.0.14.2.20030429065802.01e44d10@mcmail.cis.mcmaster.ca>

Dear Fabrizio

At 12:07 PM 4/29/2003 +0200, De Amicis Fabrizio (G.I.T.) wrote:
>Dear R.List,
>I am starting to use R. I have an easy question. In a dataset of 15
>variables, I am not able run correctly the index i of the do loop.
>Do you have any suggestion?
>
>NC <- function(x)
>
>     for (i in 1:15) {
>     print(dim(table(dt[,"Vi"])))
>
>}
>

The short answer is that you need to paste the number in i to "V" in order 
to create a proper column index. I assume that the columns of dt are named 
"V1", ..., "V15":

     print(dim(table(dt[,paste("V",i,sep="")])))

Alternatively, you could use something like

     for (i in paste("V",1:15,sep="")) print(dim(table(dt[,i])))

or even more simply, just index the columns by number

     for (i in 1:15) print(dim(table(x[,i])))

Some other points, however:

(1) The argument to your function is x, but you're indexing a variable 
called dt.

(2) A simpler approach to counting the unique elements in each column is

         apply(dt, 2, function(x) length(unique(x)))

(3) Since this apparently applies to a particular matrix or data frame, why 
write a function to perform the operation?

I hope that this helps,
  John

-----------------------------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario, Canada L8S 4M4
email: jfox at mcmaster.ca
phone: 905-525-9140x23604
web: www.socsci.mcmaster.ca/jfox


From matthew_wiener at merck.com  Tue Apr 29 14:49:52 2003
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Tue, 29 Apr 2003 08:49:52 -0400
Subject: [R] thick plot lines
Message-ID: <AEBD81486231A343B1813FE62D335225013178C1@usrymx15.merck.com>

If you include 'type = "l"' (or type = "line") in the qqplot command, you'll
get a line.

Hope this helps,

Matt

-----Original Message-----
From: Faheem Mitha [mailto:faheem at email.unc.edu] 
Sent: Tuesday, April 29, 2003 1:09 AM
To: r-help at stat.math.ethz.ch
Subject: [R] thick plot lines



Dear People,

In a qqplot I am doing, I get lines/points that are very thick. I've tried
setting the lwd variable to 0.1, but it doesn't seem to have any effect.
Also, I have set the value of lty to dashed, but I still get dots. The
command looks like

qqplot(cdf.inv(seq(0,1,length=size),theta,pos,len),empmargdistvec(len,theta,
pos,size),
       xlim=c(-theta,theta), ylim=c(-theta,theta), lwd=0.1,
       xlab="Marginal Quartiles", ylab="Empirical Marginal", col="red",
lty="dashed")

I tried putting

par(lty="dashed",lwd=0.1)

before this, but this doesn't have any effect either.

I'm now wondering if I am doing something wrong. Does qqplot perhaps not
accept these parameters? What should I do to make the lines/points
thinner?

                                              Faheem.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help

------------------------------------------------------------------------------
Notice: This e-mail message, together with any attachments, cont... {{dropped}}


From alessandro.semeria at cramont.it  Tue Apr 29 15:13:39 2003
From: alessandro.semeria at cramont.it (alessandro.semeria@cramont.it)
Date: Tue, 29 Apr 2003 15:13:39 +0200
Subject: [R] plot(pam.object) error with R-1.7.0 on Red-Hat 8.0 i686
Message-ID: <OF0C611D67.53457FAD-ONC1256D17.00479094-C1256D17.0047D0E2@tomware.it>

Hello Martin!
Here the script to create mel.data from data set freely 
available attached to"Molecular Classification 
of Cutaneous Malignant Melanoma
        by Gene Expression Profiling" (Bittner et al., 2000):
(melanoma.csv is an ASCII comma separeted containing data and 
with first raw= conditions names)

library(mva)
cond<- scan(file="melanoma.csv",what=character(38), sep=",",nlines=1)
mel<- matrix(scan("melanoma.csv",sep=",",skip=1),ncol=38,byrow=T)
dim(mel)

mel.bittner <- mel[1:3613,1:31]
cond.bittner <- cond[1:31]
mel.bittner[mel.bittner<0.02] <- 0.02
mel.bittner[mel.bittner>50] <- 50
mel.bittner <- log2(mel.bittner)

mel.bittner.median <- apply(mel.bittner,2,median)
mel.bittner.mean <- apply(mel.bittner,2,mean)
mel.bittner.sd <- apply(mel.bittner,2,sd)
mel.data <- sweep(data.matrix(mel.bittner),2,mel.bittner.median)

Thanks!
A.S.

----------------------------

Alessandro Semeria 
Models and Simulations Laboratory
The Environment Research Center - Montecatini (Edison Group), 
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: asemeria at cramont.it


From tblackw at umich.edu  Tue Apr 29 15:10:36 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Tue, 29 Apr 2003 09:10:36 -0400 (EDT)
Subject: [R] how to present a table in powerpoint?
In-Reply-To: <006001c30dd5$899c1a90$0201a8c0@MARC>
Message-ID: <Pine.SOL.4.44.0304290856380.176-100000@timepilot.gpcc.itd.umich.edu>

I'm surprised that no one has yet mentioned "Sweave".
I've never used it, but it seems to solve exactly the
general problem of R-to-postscript formatting that
Jonathan Li sees a use for.  However, it works via
TeX/LaTeX rather than by commercial software.

http://www.ci.tuwien.ac.at/~leisch/Sweave/Sweave-manual-20021007.pdf

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Mon, 28 Apr 2003, Jonathan Li wrote:

> >I have a nicely printed table of results generated by R's
> >print(myresult) where myresult is a "data frame".
> >
> >I am trying to put this table into a powerpoint slide for
> >presentation without re-typing and re-formating, i.e., present
> >it as it is in the R window. This saves time when there are a
> >lot of tables to be presented.
> >
> >I tried
> >> sink("myresult.txt")
> >> print(myresult)
> >> sink()
> >
> >resulting text file looks nice, but how can I insert it into
> >powerpoint without losing its formatting? When I think more
> >carefully about it, it seems to me that we need a way to
> >convert this text presentation into graphical presentation
> >such as postscript, then it would be easy to paste it into
> >powerpoint without losing its formatting.
> >
> >I suspect that this is a problem many other may also face
> >sometimes. After doing searching in R-help archive with
> >keywords like "powerpoint", "presentation", I came up with
> >many entries about presenting graphs in powerpoint, but not
> >one about presenting tables of numbers.
> >
> >Your help is highly appreciated.
> >Jonathan


From bellis at hsph.harvard.edu  Tue Apr 29 15:30:48 2003
From: bellis at hsph.harvard.edu (Byron Ellis)
Date: Tue, 29 Apr 2003 09:30:48 -0400
Subject: [R-gui] Re: [R] Feedback about SciViews?
In-Reply-To: <r5nsavsd74t9rnlnpcnkd8mut67h1bivoa@4ax.com>
Message-ID: <C9DFD144-7A46-11D7-9CA5-000393BDE1EC@hsph.harvard.edu>


On Tuesday, April 29, 2003, at 07:13  AM, Duncan Murdoch wrote:

> On Tue, 29 Apr 2003 11:31:44 +0200, you wrote:
>
>> R for Windows already comes with a (simple) GUI.
>> Many of the R developers would rather think mostly about GUI
>> efforts that are platform INDEPENDENT, such as the standard Tcl/Tk
>> package (try "library(tcltk)" and the demos from "demo(package =
>> "tcltk")" in R), and the RGtk (http://www.omegahat.org/RGtk/) one.
>
> That's true, but as the Windows maintainer, I would *love* to have an
> alternative to Rgui.  The Graphapp package that underlies it is not
> easy to work with.
>
> I think the best long term strategy is to have a clean division
> between the user interface aspects of R (which are necessarily
> platform dependent) and the underlying computing engine (which should

Precisely. I would actually say that R is -not- platform independent in 
that it expects a certain type of GUI--- a shell process living on 
STDIN and STDOUT that talks to an out-of-process Window Server of some 
sort. Most of the work done in the Windows GUI is spent faking that 
environment to make R think its still running on a X Server somewhere 
and similar work was done for the Mac/Carbon port (obviously, Darwin R 
can happily use Apple's X server). REventLoop takes some steps as does 
the work on embedding, but its still safer to run the "GUI" stuff 
out-of-process and even then not foolproof.

If you want true platform independence you really have to consider 
independence in terms of style of interaction as well as operating 
system. Some people really dig on ESS, some like to click things. 
Personally, I like my plots inline with my code. All should be able to 
first-class GUI citizens if they so desire.


> be platform independent).  It should be as easy to experiment with the
> user interface as it is to experiment with other aspects of
> statistical computing.  TCL/TK is one way to realize this, but should
> not be the only one.
>
> Duncan Murdoch
>
> _______________________________________________
> R-SIG-GUI mailing list
> R-SIG-GUI at stat.math.ethz.ch
> https://www.stat.math.ethz.ch/mailman/listinfo/r-sig-gui
>
Byron Ellis (bellis at hsph.harvard.edu)
"Oook" - The Librarian


From dieter.menne at menne-biomed.de  Tue Apr 29 15:53:48 2003
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Tue, 29 Apr 2003 15:53:48 +0200
Subject: [R] Estimates with lme(...varPower())
Message-ID: <JLEPLGAANFCEAEDCAGJNOEPECEAA.dieter.menne@menne-biomed.de>

Dear R-List,

we have a 2*3 factorial design, where 2 out of the 3 treatment levels
are tested on each subject on two different days, each before and after a
meal (When)

There is strong evidence for heteroscedascticity. The lme-analysis with
varPower-weighting has significantly lower AIC, estimated power is 1.33.

Estimated values are physiologically reasonable and close to averages for
the unweighted case (e.g. 130.3+184.8=315 for WhenPost at the base level),
but for the weighted case they are not (110.2+134.9=245).

Does using weighted estimates make sense at all? Or did I misuse weighted
lme here? Is there any warning signal I overlooked?

Dieter Menne

-------------------
No weigthing

> vTonus.lme<-lme(vTonus~Treat*When,data=to,random=~1|Subj/Day)
  AIC BIC logLik
  844 864   -413
....
                  Value Std.Error DF t-value p-value
(Intercept)       130.3      35.3 33    3.69  0.0008
TreatCel           62.3      45.4 16    1.37  0.1890
TreatDic           63.4      45.4 16    1.40  0.1818
WhenPost          184.8      34.8 33    5.32  <.0001
TreatCel:WhenPost -59.8      49.1 33   -1.22  0.2320
TreatDic:WhenPost -68.4      49.1 33   -1.39  0.1735
 Correlation:
                  (Intr) TretCl TretDc WhnPst TrC:WP
TreatCel          -0.642
TreatDic          -0.642  0.500
WhenPost          -0.492  0.383  0.383
TreatCel:WhenPost  0.348 -0.541 -0.271 -0.707
TreatDic:WhenPost  0.348 -0.271 -0.541 -0.707  0.500

With vaPower weighting:

>vTonusW.lme<-lme(vTonus~Treat*When,data=to,
+    weights=varPower(form=~vTonus),random=~1|Subj/Day)

  AIC BIC logLik
  830 852   -405
..
 Parameter estimates:
power  1.33
..
                  Value Std.Error DF t-value p-value
(Intercept)       110.2      20.9 33    5.27  <.0001
TreatCel           54.0      28.5 16    1.90  0.0762
TreatDic           31.9      28.2 16    1.13  0.2744
WhenPost          134.9      26.2 33    5.15  <.0001
TreatCel:WhenPost -84.4      28.7 33   -2.94  0.0060
TreatDic:WhenPost -96.5      32.9 33   -2.93  0.0061
 Correlation:
                  (Intr) TretCl TretDc WhnPst TrC:WP
TreatCel          -0.562
TreatDic          -0.554  0.386
WhenPost          -0.125  0.093  0.091
TreatCel:WhenPost  0.111 -0.119 -0.078 -0.912
TreatDic:WhenPost  0.096 -0.070 -0.195 -0.794  0.724


From HStevens at muohio.edu  Tue Apr 29 16:03:23 2003
From: HStevens at muohio.edu (Hank Stevens)
Date: Tue, 29 Apr 2003 10:03:23 -0400
Subject: [R] plot with nlme
Message-ID: <5.1.0.14.2.20030429094524.01835e98@po.muohio.edu>

Using R v. 1.7.0 on Windows 2000

I would like to plot the fitted values of a model as a function of a 
continuous covariate, augmented with data (e.g., augPred) grouping by 
combinations of fixed effects. I have not been able to use augPred 
effectively, and am wondering if it does not handle unbalanced data (3 out 
of 192 missing).
I include below the model and an xyplot that almost does the job. I would 
happily send anyone the data if they would be willing to help.
Many Thanks in advance.
Hank

The model:

fm <- lme( log(S,2) ~ Fert*Litter*Seed*Density, data = collimd, random = 
~1|block/plot/Seed )

# The following is close, but fits lines within each panel rather than 
giving me the fitted values generated by the model.

xyplot( log(S,2)  ~  log10(Nper0.5m)  |  Fert*Seed, data = 
collimd,  groups=Litter,
        scales = list( alternating =FALSE, tck=c(1,0)), layout = c(4,2,1), 
aspect = 1, as.table = T,
          key = list(space="top", transparent = TRUE,
                    points=list(pch=c(1,3)),
                      #trellis.par.get("superpose.symbol")$pch[1:2],
                    lines=list(lty=1:2),
                    text = list(c("With Litter", "Litter Removed"))   ) ,

        panel = function(x, y, subscripts,...) {
            panel.grid(h=-1, v= -1)
            panel.superpose(x, y,subscripts, pch=c(1,3),col=1,...)
             panel.superpose(x, y, 
panel.groups="panel.lmline",lty=1:2,subscripts,...)

            })



Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology


From alessandro.semeria at cramont.it  Tue Apr 29 16:15:16 2003
From: alessandro.semeria at cramont.it (alessandro.semeria@cramont.it)
Date: Tue, 29 Apr 2003 16:15:16 +0200
Subject: [R] plot(pam.object) error with R-1.7.0 on Red-Hat 8.0 i686
Message-ID: <OF3539D042.4C3DC314-ONC1256D17.004CD15B-C1256D17.004D7502@tomware.it>

Frome here 
http://www.nature.com/nature/journal/v406/n6795/extref/406536ai3.xls 
I copied cells  from 2F to  8069AQ (only values and string, no formatting) 
of 
CUTANEOUSMELANOMA sheet to a new
file with excell97 on winXP than I saved it as melanoma.csv (as comma 
separeted 
value). Now I'll try to set verbose level option to the maximum to look 
something.
Thanke more!
A.S.

----------------------------

Alessandro Semeria 
Models and Simulations Laboratory
The Environment Research Center - Montecatini (Edison Group), 
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: asemeria at cramont.it


From Ted.Harding at nessie.mcc.ac.uk  Tue Apr 29 16:19:57 2003
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 29 Apr 2003 15:19:57 +0100 (BST)
Subject: [R] Shafer's MIX: Query on code
Message-ID: <XFMail.030429151957.Ted.Harding@nessie.mcc.ac.uk>

Thanks to Fernando Tusell and especially to Brian Ripley for
their work on 'mix', leading to an apparently good package
mow available on CRAN.

Going through the R code for the function prelim.mix, I am
wondering why the following method of calculation is used
at one point:

  umd <- as.integer(round(exp(cumsum(log(d)))))

(d is a vector containing, in effect, the numbers of levels of
the factors in col1, col2, ... of the categorical variables.
Therefore umd is a vector containing the numbers of possible
combinations of factor levels in col1, col1&col2, ... )

But why not do it as

  umd <- as.integer(cumprod(d))

?? [It can't be that this number could go out or range, since
that would be equally true of exp(cumsum(log(d)))) ]

With thanks, and best wishes to all,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 167 1972
Date: 29-Apr-03                                       Time: 15:19:57
------------------------------ XFMail ------------------------------


From bates at stat.wisc.edu  Tue Apr 29 16:32:49 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 29 Apr 2003 09:32:49 -0500
Subject: [R] Estimates with lme(...varPower())
In-Reply-To: <JLEPLGAANFCEAEDCAGJNOEPECEAA.dieter.menne@menne-biomed.de>
References: <JLEPLGAANFCEAEDCAGJNOEPECEAA.dieter.menne@menne-biomed.de>
Message-ID: <6rllxt4bn2.fsf@bates4.stat.wisc.edu>

"Dieter Menne" <dieter.menne at menne-biomed.de> writes:

> we have a 2*3 factorial design, where 2 out of the 3 treatment levels
> are tested on each subject on two different days, each before and after a
> meal (When)
> 
> There is strong evidence for heteroscedascticity. The lme-analysis with
> varPower-weighting has significantly lower AIC, estimated power is 1.33.
> 
> Estimated values are physiologically reasonable and close to averages for
> the unweighted case (e.g. 130.3+184.8=315 for WhenPost at the base level),
> but for the weighted case they are not (110.2+134.9=245).
> 
> Does using weighted estimates make sense at all? Or did I misuse weighted
> lme here? Is there any warning signal I overlooked?
> 
> Dieter Menne
> 
> -------------------
> No weigthing
> 
> > vTonus.lme<-lme(vTonus~Treat*When,data=to,random=~1|Subj/Day)
>   AIC BIC logLik
>   844 864   -413
> ....
>                   Value Std.Error DF t-value p-value
> (Intercept)       130.3      35.3 33    3.69  0.0008
> TreatCel           62.3      45.4 16    1.37  0.1890
> TreatDic           63.4      45.4 16    1.40  0.1818
> WhenPost          184.8      34.8 33    5.32  <.0001
> TreatCel:WhenPost -59.8      49.1 33   -1.22  0.2320
> TreatDic:WhenPost -68.4      49.1 33   -1.39  0.1735
>  Correlation:
>                   (Intr) TretCl TretDc WhnPst TrC:WP
> TreatCel          -0.642
> TreatDic          -0.642  0.500
> WhenPost          -0.492  0.383  0.383
> TreatCel:WhenPost  0.348 -0.541 -0.271 -0.707
> TreatDic:WhenPost  0.348 -0.271 -0.541 -0.707  0.500
> 
> With vaPower weighting:
> 
> >vTonusW.lme<-lme(vTonus~Treat*When,data=to,
> +    weights=varPower(form=~vTonus),random=~1|Subj/Day)
> 
>   AIC BIC logLik
>   830 852   -405
> ..
>  Parameter estimates:
> power  1.33
> ..
>                   Value Std.Error DF t-value p-value
> (Intercept)       110.2      20.9 33    5.27  <.0001
> TreatCel           54.0      28.5 16    1.90  0.0762
> TreatDic           31.9      28.2 16    1.13  0.2744
> WhenPost          134.9      26.2 33    5.15  <.0001
> TreatCel:WhenPost -84.4      28.7 33   -2.94  0.0060
> TreatDic:WhenPost -96.5      32.9 33   -2.93  0.0061
>  Correlation:
>                   (Intr) TretCl TretDc WhnPst TrC:WP
> TreatCel          -0.562
> TreatDic          -0.554  0.386
> WhenPost          -0.125  0.093  0.091
> TreatCel:WhenPost  0.111 -0.119 -0.078 -0.912
> TreatDic:WhenPost  0.096 -0.070 -0.195 -0.794  0.724

It would be more common to use the predicted response rather than the
observed response for the varPower weights, as in 
 varPower(form = ~fitted(.))

If you use the observed responses then abnormally low observed
responses will have unusually high weights in the fit, leading to low
predictions, as you observed.


From laurent.faisnel at ariase.com  Tue Apr 29 16:34:05 2003
From: laurent.faisnel at ariase.com (Laurent Faisnel)
Date: Tue, 29 Apr 2003 16:34:05 +0200
Subject: [R] calling R from PHP and saving outputs
Message-ID: <3EAE8D5D.5060309@ariase.com>

Hi all,
I have to call R from PHP code. I manage to run R and to make it parse 
my script (see below) but I have an error which I cannot cope with yet 
while running the PHP page:

Error in file("/home/faisnel/Rscripts/testphp2.Rout", open = "wt") : 
unable to open connection In addition: Warning message: cannot open file 
`/home/faisnel/Rscripts/testphp2.Rout' Execution halted

I am not sure about the "open" option I used (see R script). Does anyone 
have an idea about why the connection/file cannot be opened ? I checked 
I had the rights on the directory.
I give you my PHP main file and my R script below. Thanks in advance for 
any help.

Laurent
_
PHP :_

<?php

class Essai
{
  var $RPath; // path to R executable
  var $sortie; // display

  function Essai()
    {
      $this->RPath = "/usr/lib/R/bin/R";
      $this->sortie = $this->calcul();
    }
 
  function calcul()
    {
            $cmd = <<<EOD
echo 'source("commande.R")' | $this->RPath --slave
EOD;
        echo "\n";
        echo $cmd."\n";
        $result = shell_exec($cmd);
  
        echo($result);
        return ($result);
    }
}

$essai = new Essai();
?>

<table border='2' cellpadding='5'>
<tr>
<th align='right'> ESSAI : </th>
<td> ... </td>
<td>
<?php echo($essai->sortie);
?>
</td>
</tr>
</table>

_R script :_ (commande.R)

zz <- file("/home/faisnel/Rscripts/testphp2.Rout", open="wt");
sink(zz);
library(RMySQL);
con2 <- dbConnect("MySQL");
result <- dbGetQuery(con2,"select URL from isp_info");
dbListTables(con2);
result;
dbDisconnect(con2);
sink();


From ripley at stats.ox.ac.uk  Tue Apr 29 16:40:43 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 29 Apr 2003 15:40:43 +0100 (BST)
Subject: [R] Shafer's MIX: Query on code
In-Reply-To: <XFMail.030429151957.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <Pine.LNX.4.44.0304291536410.12493-100000@gannet.stats>

On Tue, 29 Apr 2003 Ted.Harding at nessie.mcc.ac.uk wrote:

> Thanks to Fernando Tusell and especially to Brian Ripley for
> their work on 'mix', leading to an apparently good package
> mow available on CRAN.
> 
> Going through the R code for the function prelim.mix, I am
> wondering why the following method of calculation is used
> at one point:
> 
>   umd <- as.integer(round(exp(cumsum(log(d)))))
> 
> (d is a vector containing, in effect, the numbers of levels of
> the factors in col1, col2, ... of the categorical variables.
> Therefore umd is a vector containing the numbers of possible
> combinations of factor levels in col1, col1&col2, ... )
> 
> But why not do it as
> 
>   umd <- as.integer(cumprod(d))
> 
> ?? [It can't be that this number could go out or range, since
> that would be equally true of exp(cumsum(log(d)))) ]

I expect the author didn't know about cumprod.  It isn't in the Blue Book, 
which even does a similar calculation this way (on page 361).

There's a lot of other code that is not idiomatic S in mix.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From p.dalgaard at biostat.ku.dk  Tue Apr 29 16:48:23 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 29 Apr 2003 16:48:23 +0200
Subject: [R] "prediction intervals for glm"
In-Reply-To: <3EADF4EA.6040204@pdf.com>
References: <200304290223.32871.fredrik.lundgren@norrkoping.mail.telia.com>
	<3EADF4EA.6040204@pdf.com>
Message-ID: <x2he8hl5qg.fsf@biostat.ku.dk>

Spencer Graves <spencer.graves at pdf.com> writes:

> "?predict.glm" produced something in my copy of R 1.6.2 under Windows
> 2000.

.. but probably not what Fredrik wanted. Prediction intervals (i.e.
intervals with 95% probability of catching a new observation) are
somewhat tricky even to define for glms. For Normal responses you have
the formula yhat +- qt(.975,df)* sqrt(s^2+se(yhat)^2), for other
continuous responses that would become (approximately!) the error
distribution convolved with a Gaussian density, for discrete responses
- say 0/1 - I wouldn't know what to do.

> 
> Fredrik Lundgren wrote:

> > Where can i find prediction intervals for glm in R?


-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From jrogers at cantatapharm.com  Tue Apr 29 16:49:55 2003
From: jrogers at cantatapharm.com (Jim Rogers)
Date: Tue, 29 Apr 2003 10:49:55 -0400
Subject: [R] Specifying search position for attached package
Message-ID: <99A12772DCDEEB458B996332957B0D530117BE@mercury.cantatapharm.com>

When I load an add-on package, is there any way to specify where it ends
up in the search path (as with the pos argument to attach())? From the
documentation for library(), this doesn't seem like an option. 

(I know I can detach packages and then reload them in the order I want;
I'm looking for a less clumsy way.)

Thanks, 
Jim 

James A. Rogers, Ph.D. <rogers at cantatapharm.com>
Statistical Scientist
Cantata Pharmaceuticals
300 Technology Square, 5th floor
Cambridge, MA  02139
617.225.9009 x312
Fax 617.225.9010


From dieter.menne at menne-biomed.de  Tue Apr 29 16:50:41 2003
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Tue, 29 Apr 2003 16:50:41 +0200
Subject: [R] Estimates with lme(...varPower())
Message-ID: <JLEPLGAANFCEAEDCAGJNEEPICEAA.dieter.menne@menne-biomed.de>

Dear Douglas Bates,

> It would be more common to use the predicted response rather than the
> observed response for the varPower weights, as in
>  varPower(form = ~fitted(.))

Following the example on page 223 of PB, I had used that first, but did not
achieve convergence. Will try with more iterations.

> If you use the observed responses then abnormally low observed
> responses will have unusually high weights in the fit, leading to low
> predictions, as you observed.


Dieter Menne


From anna at ptolemy.arc.nasa.gov  Tue Apr 29 18:04:31 2003
From: anna at ptolemy.arc.nasa.gov (Anna  H. Pryor)
Date: Tue, 29 Apr 2003 09:04:31 -0700
Subject: [R] labels
Message-ID: <200304290904.31658.anna@ptolemy.arc.nasa.gov>


I don't know how to retain my row labels.  I read in a table with row labels, 
ie:  

Price   Floor  Area  Rooms
52.      111.   830    5
54.      128.   710    5
47.4    101   1000   4
...

but then I need to transform the data

raggedRidzeros <- function(x){
	 	  
	y = list(ridzeros(x[[1]]))
	for(i in 2:length(x)){
	  y = c(y,list(ridzeros(x[[i]])))
	}
	y

}

(where ridzeros is a function that I call to get rid of the zeros in the 
vector) 
When I do this, I no longer have row labels.  Is there any way to insert the 
row labels from the original calling function into this function?

Anna


From B.Rowlingson at lancaster.ac.uk  Tue Apr 29 18:26:41 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 29 Apr 2003 17:26:41 +0100
Subject: [R] labels
In-Reply-To: <200304290904.31658.anna@ptolemy.arc.nasa.gov>
References: <200304290904.31658.anna@ptolemy.arc.nasa.gov>
Message-ID: <3EAEA7C1.6090601@lancaster.ac.uk>

Anna H. Pryor wrote:
> I don't know how to retain my row labels.  I read in a table with row labels, 
> ie:  
> 
> Price   Floor  Area  Rooms
> 52.      111.   830    5
> 54.      128.   710    5
> 47.4    101   1000   4

  I dont see any row labels. I assume you mean column labels!

> 
> but then I need to transform the data
> 
> raggedRidzeros <- function(x){
> 	 	  
> 	y = list(ridzeros(x[[1]]))
> 	for(i in 2:length(x)){
> 	  y = c(y,list(ridzeros(x[[i]])))
> 	}
> 	y
> 
> }


  This can all be done in one line! Here's some data that does have row 
and column labels:

 > tm
         Foo       Bar Baz
Mercury   1 0.6961034   0
Venus     2 0.3137058   0
Earth     3 0.7692529   1
Mars      0 0.2598111   0
Jupiter   1 0.8375288   0
Saturn    0 0.5866152   0

  Now I want to sweep through columns and return a list without the 
zeroes. I do this:

 > nonZero <- apply(tm,2,function(x){x[x!=0]})

  and I get a list:

$Foo
Mercury   Venus   Earth Jupiter
       1       2       3       1

$Bar
   Mercury     Venus     Earth      Mars   Jupiter    Saturn
0.6961034 0.3137058 0.7692529 0.2598111 0.8375288 0.5866152

$Baz
Earth
     1

  Note this preserves column names (as the names of the list elements, 
so I can do nonZero$Foo), and keeps the row names (as names of 
individual elements).

 > nonZero$Bar['Earth']
     Earth
0.7692529

  How it works:

   function(x){x[x!=0]}   is my 'ridzeros' function.

  I use 'apply(tm,2,function(x){x[x!=0]})' to apply the ridzeros 
function to columns (thats the '2')  of the matrix. To do the same by 
rows, use '1'.

  Hardly rocket science :)

Baz


From maechler at stat.math.ethz.ch  Tue Apr 29 18:39:30 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 29 Apr 2003 18:39:30 +0200
Subject: [R] plot(pam.object) error with R-1.7.0 on Red-Hat 8.0 i686
In-Reply-To: <OFDC403BD0.F4E8F75B-ONC1256D16.005B2931-C1256D16.005BE816@tomware.it>
References: <OFDC403BD0.F4E8F75B-ONC1256D16.005B2931-C1256D16.005BE816@tomware.it>
Message-ID: <16046.43714.126885.458290@gargle.gargle.HOWL>

>>>>> "alessandro" == alessandro semeria <alessandro.semeria at cramont.it>
>>>>>     on Mon, 28 Apr 2003 18:53:11 +0200 writes:

    alessandro> I don't know if there is some fault in compiling
    alessandro> or a bug of the new R-1.7.0 version:

    > cl.pam.2 <- pam(as.dist(1-cor(mel.data)),2)
    > plot(cl.pam.2)

    alessandro> perform a right partitioning and silhouette plot
    alessandro> on the old R-1.6.2 instead "Error in
    alessandro> clusplot.default(x$diss,...... ; x is not
    alessandro> numeric" is the output on the new R-1.7.0.  Same
    alessandro> platform: RH8.0 i686.  Some suggestions?

yes.  
This is a bug in the cluster package I'm maintaining.
(I'll file a bug report myself).
One workaround is to say

    cl.pam.2 <- pam(as.dist(1-cor(mel.data)), k=2, keep.diss = TRUE)
    ##                                            ^^^^^^^^^^^^^^^^^^
    plot(cl.pam.2)

{this is a workaround and unnecessary and *not* recommended for
 the next release  of the cluster package !}


Note that the `keep.diss' is a new argument to pam() {and agnes() and others},
which is not anymore always TRUE by default -- for a good reason:

This allows quite a bit larger datasets than previously,
and also improves on speed (for memory allocation!!) in these
cases.

BUT as you found above,  I have overlooked to adapt  plot()
method for pam() results to this case.

PS: I think I was able to entirely reproduce what you did, but
the clustering (of the 31 variables) is pretty "bad":
30 variables in 1st cluster; and variable "M93.007" alone in the
2nd cluster.
If you look at   silhouette(cl.pam.2)   {which is implicitly
used in the above plot() statement} you'll realize that the
silhouette width is really not useful for this case {all widths
are 0}.


Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From p.dalgaard at biostat.ku.dk  Tue Apr 29 18:44:38 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 29 Apr 2003 18:44:38 +0200
Subject: [R] labels
In-Reply-To: <3EAEA7C1.6090601@lancaster.ac.uk>
References: <200304290904.31658.anna@ptolemy.arc.nasa.gov>
	<3EAEA7C1.6090601@lancaster.ac.uk>
Message-ID: <x2d6j5l0cp.fsf@biostat.ku.dk>

Barry Rowlingson <B.Rowlingson at lancaster.ac.uk> writes:

>   Now I want to sweep through columns and return a list without the
> zeroes. I do this:
> 
>  > nonZero <- apply(tm,2,function(x){x[x!=0]})
> 
>   and I get a list:
> 
> $Foo
> Mercury   Venus   Earth Jupiter
>        1       2       3       1
> 
> $Bar
>    Mercury     Venus     Earth      Mars   Jupiter    Saturn
> 0.6961034 0.3137058 0.7692529 0.2598111 0.8375288 0.5866152
> 
> $Baz
> Earth
>      1
> 
>   Note this preserves column names (as the names of the list elements,
> so I can do nonZero$Foo), and keeps the row names (as names of
> individual elements).
> 
>  > nonZero$Bar['Earth']
>      Earth
> 0.7692529
> 
>   How it works:
> 
>    function(x){x[x!=0]}   is my 'ridzeros' function.
> 
>   I use 'apply(tm,2,function(x){x[x!=0]})' to apply the ridzeros
> function to columns (thats the '2')  of the matrix. To do the same by
> rows, use '1'.
> 
>   Hardly rocket science :)

...but slightly dangerous if you have a risk of ending up with all
lists elements equally long, because then you get a matrix instead of
a list. If you want to make damn sure that you get a list, I think you
need something like

do.call("c",apply(tm,2,function(x)list(x[x!=0]))

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From raf1729 at hotmail.com  Tue Apr 29 18:42:06 2003
From: raf1729 at hotmail.com (R A F)
Date: Tue, 29 Apr 2003 16:42:06 +0000
Subject: [R] Remove leading brackets in print?
Message-ID: <Law11-F40oYAPNXRPmc000132f2@hotmail.com>

Hi, I can't seem to get an answer for this by searching through the
R-help archives:  How does one remove leading brackets in print?

For example,
>print( 3 )
>[1] 3

Would it be possible to get rid of the "[1]"?

Of course the effect is the same without "print", as in,
>3
>[1] 3
but I would only be interested in omitting brackets in printing, if
that's possible.

Thanks very much!


From spencer.graves at pdf.com  Tue Apr 29 18:51:25 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 29 Apr 2003 09:51:25 -0700
Subject: [R] Shafer's MIX: Query on code
References: <Pine.LNX.4.44.0304291536410.12493-100000@gannet.stats>
Message-ID: <3EAEAD8D.6030504@pdf.com>

exp(cusum(log(d))) is numerically more stable.

Consider the following:
 > cumprod(10^(30:(-30)))
  [1]  1e+30  1e+59  1e+87 1e+114 1e+140 1e+165 1e+189 1e+212 1e+234 1e+255
[11] 1e+275 1e+294    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
[21]    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
[31]    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
[41]    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
[51]    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
[61]    Inf
 > exp(cumsum(log(10^(30:(-30)))))
  [1]  1e+30  1e+59  1e+87 1e+114 1e+140 1e+165 1e+189 1e+212 1e+234 1e+255
[11] 1e+275 1e+294    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
[21]    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
[31]    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
[41]    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf 1e+294 1e+275
[51] 1e+255 1e+234 1e+212 1e+189 1e+165 1e+140 1e+114  1e+87  1e+59  1e+30
[61]  1e+00
 >
hth.  spencer graves

Prof Brian Ripley wrote:
> On Tue, 29 Apr 2003 Ted.Harding at nessie.mcc.ac.uk wrote:
> 
> 
>>Thanks to Fernando Tusell and especially to Brian Ripley for
>>their work on 'mix', leading to an apparently good package
>>mow available on CRAN.
>>
>>Going through the R code for the function prelim.mix, I am
>>wondering why the following method of calculation is used
>>at one point:
>>
>>  umd <- as.integer(round(exp(cumsum(log(d)))))
>>
>>(d is a vector containing, in effect, the numbers of levels of
>>the factors in col1, col2, ... of the categorical variables.
>>Therefore umd is a vector containing the numbers of possible
>>combinations of factor levels in col1, col1&col2, ... )
>>
>>But why not do it as
>>
>>  umd <- as.integer(cumprod(d))
>>
>>?? [It can't be that this number could go out or range, since
>>that would be equally true of exp(cumsum(log(d)))) ]
> 
> 
> I expect the author didn't know about cumprod.  It isn't in the Blue Book, 
> which even does a similar calculation this way (on page 361).
> 
> There's a lot of other code that is not idiomatic S in mix.
>


From ripley at stats.ox.ac.uk  Tue Apr 29 19:02:33 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 29 Apr 2003 18:02:33 +0100 (BST)
Subject: [R] Shafer's MIX: Query on code
In-Reply-To: <3EAEAD8D.6030504@pdf.com>
Message-ID: <Pine.LNX.4.44.0304291759380.24020-100000@gannet.stats>

On Tue, 29 Apr 2003, Spencer Graves wrote:

> exp(cusum(log(d))) is numerically more stable.

Only if you allow numbers less than one, which cannot happen here.
(Ted had already made an equivalent comment.)

> Consider the following:
>  > cumprod(10^(30:(-30)))
>   [1]  1e+30  1e+59  1e+87 1e+114 1e+140 1e+165 1e+189 1e+212 1e+234 1e+255
> [11] 1e+275 1e+294    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
> [21]    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
> [31]    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
> [41]    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
> [51]    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
> [61]    Inf
>  > exp(cumsum(log(10^(30:(-30)))))
>   [1]  1e+30  1e+59  1e+87 1e+114 1e+140 1e+165 1e+189 1e+212 1e+234 1e+255
> [11] 1e+275 1e+294    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
> [21]    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
> [31]    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf
> [41]    Inf    Inf    Inf    Inf    Inf    Inf    Inf    Inf 1e+294 1e+275
> [51] 1e+255 1e+234 1e+212 1e+189 1e+165 1e+140 1e+114  1e+87  1e+59  1e+30
> [61]  1e+00
>  >
> hth.  spencer graves
> 
> Prof Brian Ripley wrote:
> > On Tue, 29 Apr 2003 Ted.Harding at nessie.mcc.ac.uk wrote:
> > 
> > 
> >>Thanks to Fernando Tusell and especially to Brian Ripley for
> >>their work on 'mix', leading to an apparently good package
> >>mow available on CRAN.
> >>
> >>Going through the R code for the function prelim.mix, I am
> >>wondering why the following method of calculation is used
> >>at one point:
> >>
> >>  umd <- as.integer(round(exp(cumsum(log(d)))))
> >>
> >>(d is a vector containing, in effect, the numbers of levels of
> >>the factors in col1, col2, ... of the categorical variables.
> >>Therefore umd is a vector containing the numbers of possible
> >>combinations of factor levels in col1, col1&col2, ... )
> >>
> >>But why not do it as
> >>
> >>  umd <- as.integer(cumprod(d))
> >>
> >>?? [It can't be that this number could go out or range, since
> >>that would be equally true of exp(cumsum(log(d)))) ]
> > 
> > 
> > I expect the author didn't know about cumprod.  It isn't in the Blue Book, 
> > which even does a similar calculation this way (on page 361).
> > 
> > There's a lot of other code that is not idiomatic S in mix.
> > 
> 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mschwartz at medanalytics.com  Tue Apr 29 19:08:50 2003
From: mschwartz at medanalytics.com (Marc Schwartz)
Date: Tue, 29 Apr 2003 12:08:50 -0500
Subject: [R] Remove leading brackets in print?
In-Reply-To: <Law11-F40oYAPNXRPmc000132f2@hotmail.com>
Message-ID: <000401c30e72$0300a3a0$0201a8c0@MARC>

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of R A F
>Sent: Tuesday, April 29, 2003 11:42 AM
>To: r-help at stat.math.ethz.ch
>Cc: raf1729 at hotmail.com
>Subject: [R] Remove leading brackets in print?
>
>
>Hi, I can't seem to get an answer for this by searching 
>through the R-help archives:  How does one remove leading 
>brackets in print?
>
>For example,
>>print( 3 )
>>[1] 3
>
>Would it be possible to get rid of the "[1]"?
>
>Of course the effect is the same without "print", as in,
>>3
>>[1] 3
>but I would only be interested in omitting brackets in 
>printing, if that's possible.
>
>Thanks very much!


Use cat() instead of print().

You will also generally need to append a newline character ("\n") to
the output, as I do below.

Thus, you would use:

> cat(3, "\n")
3 

See ?cat for more information.

HTH,

Marc Schwartz


From ripley at stats.ox.ac.uk  Tue Apr 29 19:09:51 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 29 Apr 2003 18:09:51 +0100 (BST)
Subject: [R] stepAIC/lme problem (1.7.0 only)
In-Reply-To: <Pine.LNX.4.44.0304281611050.15089-100000@gannet.stats>
Message-ID: <Pine.LNX.4.44.0304291806330.24038-100000@gannet.stats>

On Mon, 28 Apr 2003, Prof Brian Ripley wrote:

> There are changes to improve scoping in stepAIC that assume that update
> works in ways that update.lme does not:
> 
> > mod2 <- addterm(mod1, ~(cov1+cov2)^2)
> Error in lme(fixed = resp ~ cov1 + cov2, data = a, random = structure(list( : 
>         unused argument(s) (evaluate ...)
> 
> The actual problem is in stepAIC which now has the line
> 
>     object$call$formula <- object$formula <- Terms
> 
> but fixing that one only opens up others (as above).
> 
> I was vaguely aware of this: I don't know of an easy fix.

I found one thanks to the magic of namespaces: see VR_7.1-5, shortly to be 
sent to CRAN.  As rw1070's install.packages() is broken and cannot install 
bundles, I have put a zip file for Windows at

http://www.stats.ox.ac.uk/pub/RWin/VR_7.1-5.zip

that you need to unzip in rw1070/library (perhaps by using zip.unpack in R).

> 
> 
> On Mon, 28 Apr 2003, Robert Cuffe wrote:
> 
> > I can use stepAIC on an lme object in 1.6.2, but 
> > I get the following error if I try to do the same
> > in 1.7.0:
> > 
> > Error in lme(fixed = resp ~ cov1 + cov2, data = a, random = structure(list( : 
> >         unused argument(s) (formula ...)
> > 
> > Does anybody know why?
> > 
> > Here's an example:
> > 
> > library(nlme)
> > library(MASS)
> > a <- data.frame( resp=rnorm(250), cov1=rnorm(250),
> >                  cov2=rnorm(250), group=rep(letters[1:10],25) )
> > mod1 <- lme(resp~cov1, a, ~cov1|group, method="ML")
> > mod2 <- stepAIC(mod1, scope=list(upper=~(cov1+cov2)^2,
> >                                  lower=~cov1) )
> > 					 
> > # it doesn't happen for normal linear models:
> > 
> > mod3 <- lm(resp~cov1, data=a)
> > mod4 <- stepAIC(mod3, scope=list(upper=~(cov1+cov2)^2,
> >                                  lower=~cov1) )
> > 
> > Thanks, 
> > 
> > Robert
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> > 
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From s-thapa-11 at alumni.uchicago.edu  Tue Apr 29 18:56:05 2003
From: s-thapa-11 at alumni.uchicago.edu (Suchandra Thapa)
Date: 29 Apr 2003 11:56:05 -0500
Subject: [R] polynomial fitting
Message-ID: <1051635365.1455.1027.camel@hepcat>

I'm trying to find a way to fit a polynomial of degree n in x  and y to
a set of x, y, and z data that I have and obtain the coefficients for
the terms of the fitted polynomial.  However, when I try to use the
surf.ls function I'm getting odd results.  

> x <- seq(0, 10, length=50)
> y <- x
> f <- function (x, y) {x^2 + y}  
> library(spatial)
> test <- data.frame(x=x, y=y, z=f(x, y))
> test.kr <- surf.ls(2, test)
> test.kr$beta
[1] 0 0 0 0 0 0

When I try the example from the help I get:

>      library(MASS)
>      data(topo, package="MASS")
>      topo.kr <- surf.ls(2, topo)
> topo.kr$beta
[1] 801.217617 -11.018887  68.229148 -73.992968   3.343573   8.342717

Why is my test data causing problems?  Also it seems that the beta
attribute from the object returned the surf.ls correspond with the terms
of the fitted polynomial.  If this is correct, in what order are the
coefficients for the fitted polynomial given?  Finally, the R source
code for the spatial library indicate that both surf.ls and surf.gls are
limited to polynomials of degree 6 or below.  Is there another function
that will work with higher order polynomials.  

I'm working with R 1.7.0 using the binary rpm for Redhat 7.3 from CRAN. 

> version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    1                
minor    7.0              
year     2003             
month    04               
day      16               
language R


From rpeng at stat.ucla.edu  Tue Apr 29 19:35:33 2003
From: rpeng at stat.ucla.edu (Roger Peng)
Date: Tue, 29 Apr 2003 10:35:33 -0700 (PDT)
Subject: [R] .Rd file with multiple help entries?
In-Reply-To: <3EAE6DF0.9040801@hppi.troitsk.ru>
Message-ID: <Pine.GSO.4.10.10304291034310.4994-100000@quetelet.stat.ucla.edu>

As far as I know, you cannot have help files with more than one title.
However, you can have a help file which has more than one alias.  For
example,

\name{Airy}
\alias{Airy}
\alias{Biry}
[...]

And go on to describe both functions in the same help entry.

-roger
_______________________________
UCLA Department of Statistics
http://www.stat.ucla.edu/~rpeng

On Tue, 29 Apr 2003, M.Kondrin wrote:

> Hello!
> I wrote a small package and want to write a help for it. I look through 
> "recommended"  packages and it seems to me that writing one .Rd files 
> with multiple entries for help topics is OK. But I can not do it myself. 
> Here is an abridged version of my Rd:
>  \name{
>   Airy
> }
> \alias{
>   Airy
> }
> \title{
>     Airy special functions in complex domain
> }
> \description{
>   Airy function of complex argument
> }
> \usage{Airy( x, diff = FALSE, scaled = FALSE )}
> \arguments{
>   \item{x}{
>     Complex vector.
>   }
>   \item{diff}{
>     If TRUE return value is first derivative of Airy function.
>   }
>   \item{scaled}{
>     If TRUE return value is scaled
>   }
> }
> \value{
>   Complex vector of the same size as x.
> }
> \keyword{
>   math
> }
> \eof
> \name{
>   Biry
> }
> \alias{
>   Biry
> }
> \title{
>   Bi - second Airy special functions in complex domain
> }
> \description{
>     Second Airy function of complex argument
> }
> \usage{
> Biry( x, diff = FALSE, scaled = FALSE )
> }
> \arguments{
>   \item{x}{
>     Complex vector.
>   }
>   \item{diff}{
>     If TRUE return value is first derivative of Bi function.
>   }
>   \item{scaled}{
>       If TRUE return value is scaled
>   }
> }
> \value{
>   Complex vector of the same size as x.
> }
> \keyword{
>   math
> }
> \eof
> But R CMD check ./MyPackage does not like this file and complains about 
> multiple \name \alias \description etc. entries in Rd file. As a result 
> it produce latex help file with help notes only for Airy function (there 
> is nothing about Biry).
> Thank you very much if you can help me with this dumb problem.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From jzhang at jimmy.harvard.edu  Tue Apr 29 20:11:26 2003
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Tue, 29 Apr 2003 14:11:26 -0400 (EDT)
Subject: [R] Re: Unzip gz files in R under Windows
Message-ID: <200304291811.OAA00791@blaise.dfci.harvard.edu>

I tried zip.unpack to unzip a gz file under Windows and got "error 1 in 
extracting from zip file". Did I do something wrong or is there a better way of 
unziping a gz file in Windows? The gz file is fine as I could unzip it visually 
throught Windows. Thanks.

Jianhua


From lamkelj at yahoo.com  Tue Apr 29 20:15:04 2003
From: lamkelj at yahoo.com (=?iso-8859-1?q?Kel?=)
Date: Tue, 29 Apr 2003 11:15:04 -0700 (PDT)
Subject: [R] Holt Winters Error
In-Reply-To: <200304290904.31658.anna@ptolemy.arc.nasa.gov>
Message-ID: <20030429181504.6641.qmail@web12507.mail.yahoo.com>

Dear Group,

I have come across with the following error while
running HoltWinters().

optim(c(0.3, 0.1, 0.1), error, method = "L-BFGS-B", 
lower = c(0, 0, 0), upper = c(1, 1, 1))

It only happens to multiplicative seasonality but not
additive.  I read the program but still couldn't
understand it.  

Thanks!


From ayalahec at msu.edu  Tue Apr 29 20:34:14 2003
From: ayalahec at msu.edu (Hector L. Ayala-del-Rio)
Date: Tue, 29 Apr 2003 14:34:14 -0400
Subject: [R] Cluster analysis and bootstraps
Message-ID: <2D88364A-7A71-11D7-9CC9-000393DB5846@msu.edu>

Hi R helpers,

   I was wondering if anybody knows if is possible to generate bootstrap 
values for a cluster analysis in R.  What I am trying to do is obtain 
some confidence on the clusters formed by resampling the data set.  A 
similar type of analysis is used in molecular taxonomy and the 
confidence values of each cluster are placed in the nodes of the 
dendogram.  Any ideas on how to do this in R will be appreciated.

Thanks

H?ctor L. Ayala-del-R?o, Ph.D.
Center for Microbial Ecology &
Center for Genomic and Evolutionary Studies
on Microbial Life at Low Temperatures
Michigan State University
545 Plant & Soil Sciences Building
East Lansing, MI 48824-1325
Phone: 517-353-9021
Fax: 517-353-2917


From Jim_Garrett at bd.com  Tue Apr 29 21:01:07 2003
From: Jim_Garrett at bd.com (Jim_Garrett@bd.com)
Date: Tue, 29 Apr 2003 15:01:07 -0400
Subject: [R] Validating R--last call for participants
Message-ID: <OF24700C22.07985243-ON85256D17.00677541@bd.com>

A couple of people responded to my e-mail last week inviting people to
explore issues relating to validating R in a regulatory environment.  I
just sent an e-mail to those respondents.  If you didn't respond before but
would like to participate, let me know.  Or if you did let me know but fail
to receive the confirmatory e-mail I sent out moments ago, let me know.
This is the last you'll hear of this from me until we learn something.  We
will certainly report to this list when we have something to offer.

Jim Garrett
Becton Dickinson Diagnostic Systems
Baltimore, Maryland, USA

**********************************************************************
This message is intended only for the designated recipient(s).  ... {{dropped}}


From p.dalgaard at biostat.ku.dk  Tue Apr 29 21:09:04 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 29 Apr 2003 21:09:04 +0200
Subject: [R] Re: Unzip gz files in R under Windows
In-Reply-To: <200304291811.OAA00791@blaise.dfci.harvard.edu>
References: <200304291811.OAA00791@blaise.dfci.harvard.edu>
Message-ID: <x2r87lm88f.fsf@biostat.ku.dk>

John Zhang <jzhang at jimmy.harvard.edu> writes:

> I tried zip.unpack to unzip a gz file under Windows and got "error 1 in 
> extracting from zip file". Did I do something wrong or is there a better way of 
> unziping a gz file in Windows? The gz file is fine as I could unzip it visually 
> throught Windows. Thanks.

It's not a ZIP file though. Some popular Windows programs will unpack
many different compressed formats, but zip.unpack will only do the
true ZIP format. To unpack a .gz file you need the gunzip program (or
gzip with suitable option). Notice that R can read gz files using a
(surprise...) gzfile() connection.

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From kwan022 at stat.auckland.ac.nz  Tue Apr 29 21:06:07 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 30 Apr 2003 07:06:07 +1200 (NZST)
Subject: Sweave (was RE: [R] how to present a table in powerpoint?)
In-Reply-To: <Pine.SOL.4.44.0304290856380.176-100000@timepilot.gpcc.itd.umich.edu>
Message-ID: <Pine.LNX.4.44.0304300703400.19732-100000@stat56.stat.auckland.ac.nz>

On Tue, 29 Apr 2003, Thomas W Blackwell wrote:

> Date: Tue, 29 Apr 2003 09:10:36 -0400 (EDT)
> From: Thomas W Blackwell <tblackw at umich.edu>
> To: Marc Schwartz <mschwartz at medanalytics.com>
> Cc: kwan022 at stat.auckland.ac.nz, jonathan_li at agilent.com,
>      r-help at stat.math.ethz.ch
> Subject: RE: [R] how to present a table in powerpoint?
> 
> I'm surprised that no one has yet mentioned "Sweave".
> I've never used it, but it seems to solve exactly the
> general problem of R-to-postscript formatting that
> Jonathan Li sees a use for.  However, it works via
> TeX/LaTeX rather than by commercial software.
> 
> http://www.ci.tuwien.ac.at/~leisch/Sweave/Sweave-manual-20021007.pdf

When I do my presentations I always produce PDF plots from R, insert into 
a LaTeX document which uses pdfscreen package, convert to pdf via 
pdflatex. 

I've heard of Sweave but am not aware its abilities.  Has anyone used it?  
What is it like?

(Sorry if this is a bit off-topic...)

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From kwan022 at stat.auckland.ac.nz  Tue Apr 29 21:08:05 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 30 Apr 2003 07:08:05 +1200 (NZST)
Subject: [R] Remove leading brackets in print?
In-Reply-To: <Law11-F40oYAPNXRPmc000132f2@hotmail.com>
Message-ID: <Pine.LNX.4.44.0304300707401.19732-100000@stat56.stat.auckland.ac.nz>

Something like:
> cat(3, "\n")
3 

Is this what you are looking for?

On Tue, 29 Apr 2003, R A F wrote:

> Date: Tue, 29 Apr 2003 16:42:06 +0000
> From: R A F <raf1729 at hotmail.com>
> To: r-help at stat.math.ethz.ch
> Cc: raf1729 at hotmail.com
> Subject: [R] Remove leading brackets in print?
> 
> Hi, I can't seem to get an answer for this by searching through the
> R-help archives:  How does one remove leading brackets in print?
> 
> For example,
> >print( 3 )
> >[1] 3
> 
> Would it be possible to get rid of the "[1]"?
> 
> Of course the effect is the same without "print", as in,
> >3
> >[1] 3
> but I would only be interested in omitting brackets in printing, if
> that's possible.
> 
> Thanks very much!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From zeileis at ci.tuwien.ac.at  Tue Apr 29 21:48:21 2003
From: zeileis at ci.tuwien.ac.at (Achim Zeileis)
Date: Tue, 29 Apr 2003 21:48:21 +0200
Subject: Sweave (was RE: [R] how to present a table in powerpoint?)
In-Reply-To: <Pine.LNX.4.44.0304300703400.19732-100000@stat56.stat.auckland.ac.nz>
References: <Pine.LNX.4.44.0304300703400.19732-100000@stat56.stat.auckland.ac.nz>
Message-ID: <200304291948.h3TJmLPp011300@thorin.ci.tuwien.ac.at>

On Tuesday 29 April 2003 21:06, Ko-Kang Kevin Wang wrote:

> On Tue, 29 Apr 2003, Thomas W Blackwell wrote:
> > Date: Tue, 29 Apr 2003 09:10:36 -0400 (EDT)
> > From: Thomas W Blackwell <tblackw at umich.edu>
> > To: Marc Schwartz <mschwartz at medanalytics.com>
> > Cc: kwan022 at stat.auckland.ac.nz, jonathan_li at agilent.com,
> >      r-help at stat.math.ethz.ch
> > Subject: RE: [R] how to present a table in powerpoint?
> >
> > I'm surprised that no one has yet mentioned "Sweave".
> > I've never used it, but it seems to solve exactly the
> > general problem of R-to-postscript formatting that
> > Jonathan Li sees a use for.  However, it works via
> > TeX/LaTeX rather than by commercial software.
> >
> > http://www.ci.tuwien.ac.at/~leisch/Sweave/Sweave-manual-20021007.p
> >df
>
> When I do my presentations I always produce PDF plots from R, insert
> into a LaTeX document which uses pdfscreen package, convert to pdf
> via pdflatex.
>
> I've heard of Sweave but am not aware its abilities.  Has anyone
> used it? What is it like?

Yes, a lot of people already have used it and for a lot of us mixing 
R/S code and LaTeX documentation was exactly what we always wanted.
 
There have been several discussions about Sweave on the list, so you 
could browse the archives to look for further opinions. And look on 
Fritz' web page (already indicated above) for documentation of the 
features of Sweave.

What hasn't been mentioned explicitely on R-help (as it is very 
obvious, I suppose) is that you can not only generate reproducible 
reports using Sweave but also pdf slides for presentations. This is 
very convenient if you need to change some of your graphics (greater 
line width, different colors, etc.) to be properly seen on the 
projector at some conference, say. You just change the R code in the 
Sweave file and recompile.

Best,
Z

> (Sorry if this is a bit off-topic...)


From shutnik_xx at yahoo.co.uk  Tue Apr 29 21:54:25 2003
From: shutnik_xx at yahoo.co.uk (=?iso-8859-1?q?Shutnik?=)
Date: Tue, 29 Apr 2003 20:54:25 +0100 (BST)
Subject: [R] R help
Message-ID: <20030429195425.18439.qmail@web10904.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030429/2331409c/attachment.pl

From spencer.graves at pdf.com  Tue Apr 29 22:28:07 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 29 Apr 2003 13:28:07 -0700
Subject: [R] R help
References: <20030429195425.18439.qmail@web10904.mail.yahoo.com>
Message-ID: <3EAEE057.8040509@pdf.com>

	  No solution exists, because the mean of a sum of n random variables 
each with mean mu is n*mu, which is different from mu if n > 1.

	  Beyond this, it is not clear to me what you want, but the following 
might help, if my understanding of your problem is close to correct:

y <- rnorm(1)
n <- 3
x <- rnorm(n)/sqrt(3)
x <- y*x/sum(x)
x; sum(x); y

hth.  spencer graves

Shutnik wrote:
>  Hello,
>  I have the normal random variables y(t)~N(mu, sigma.sq) and want to decompose them into n normal variables:
> 
>  y(t) = x(t,1) + ? + x(t,n) 
> 
> x(t,i)~N(mu, sigma.sq/n) 
> 
>  The problem is not as simple as can appear. All my experiments didn?t give me anything so far. Are there any tools to do this?
> 
> 
> Thanks
> 
> 
> 
> ---------------------------------
> 
> 
> 	[[alternate HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From p.dalgaard at biostat.ku.dk  Tue Apr 29 22:34:09 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 29 Apr 2003 22:34:09 +0200
Subject: [R] R help
In-Reply-To: <20030429195425.18439.qmail@web10904.mail.yahoo.com>
References: <20030429195425.18439.qmail@web10904.mail.yahoo.com>
Message-ID: <x2n0i9m4am.fsf@biostat.ku.dk>

Shutnik <shutnik_xx at yahoo.co.uk> writes:

>  Hello,
>  I have the normal random variables y(t)~N(mu, sigma.sq) and want to decompose them into n normal variables:
> 
>  y(t) = x(t,1) + 
 + x(t,n) 
> 
> x(t,i)~N(mu, sigma.sq/n) 
> 
>  The problem is not as simple as can appear. All my experiments didn?t give me anything so far. Are there any tools to do this?
> 

This should work, provided I understand the problem correctly:

x <- rnorm(n,sd=sqrt(sigma.sq/n))
x <- x - mean(x) + y/n

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From clists at perrin.socsci.unc.edu  Tue Apr 29 22:30:29 2003
From: clists at perrin.socsci.unc.edu (Andrew Perrin)
Date: Tue, 29 Apr 2003 16:30:29 -0400 (EDT)
Subject: [R] Data manipulation help
Message-ID: <Pine.LNX.4.53.0304291623030.28395@perrin.socsci.unc.edu>

I have a data frame that contains two ratings on several variables for
each case. My objective at the moment is to calculate a Cohen's Kappa
score for each of these variables between the two raters. Jim Lemon has
kindly provided me with kappa.nom() to do the calculation, but I'm having
trouble getting the data into the right format.

Consider the variable "conv".  It's now stored in a data frame such that
letters.df$first.conv contains the first coder's evaluation for conv, and
letters.df$second.conv contains the second coder's evaluation for conv.
The levels for all these factors are c(-1,0,1). kappa.nom() requires a
frequency table, such that for each case we have:

      -1    0      1
       2    0      0

That is, the count of ratings of -1 (in this case, both coders assigned
-1), the count of 0, and the count of 1.  Is there a relatively easy way
to do this?

Many thanks.

----------------------------------------------------------------------
Andrew J Perrin - http://www.unc.edu/~aperrin
Assistant Professor of Sociology, U of North Carolina, Chapel Hill
clists at perrin.socsci.unc.edu * andrew_perrin (at) unc.edu


From murdoch at stats.uwo.ca  Tue Apr 29 22:36:09 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 29 Apr 2003 16:36:09 -0400
Subject: [R] R help
In-Reply-To: <20030429195425.18439.qmail@web10904.mail.yahoo.com>
References: <20030429195425.18439.qmail@web10904.mail.yahoo.com>
Message-ID: <1botav4nbo3u9gn1oo4gjlcgpqkgm5b3ef@4ax.com>

On Tue, 29 Apr 2003 20:54:25 +0100 (BST), you wrote in message
<20030429195425.18439.qmail at web10904.mail.yahoo.com>:

> Hello,
> I have the normal random variables y(t)~N(mu, sigma.sq) and want to decompose them into n normal variables:
>
> y(t) = x(t,1) + 
 + x(t,n) 
>
>x(t,i)~N(mu, sigma.sq/n) 
>
> The problem is not as simple as can appear. All my experiments didn?t give me anything so far. Are there any tools to do this?

Work out the joint distribution of the x's conditional on y, then
sample from that.  This sort of calculation appears in lots of places,
e.g. Searle (1971), Linear Models, p. 47.

Duncan Murdoch


From faheem at email.unc.edu  Tue Apr 29 23:32:16 2003
From: faheem at email.unc.edu (Faheem Mitha)
Date: Tue, 29 Apr 2003 17:32:16 -0400 (EDT)
Subject: [R] Re: thick plot lines
In-Reply-To: <Pine.LNX.4.44.0304290047350.29823-100000@Chrestomanci>
Message-ID: <Pine.LNX.4.44.0304291640540.29823-100000@Chrestomanci>



On Tue, 29 Apr 2003, Faheem Mitha wrote:

>
> Dear People,
>
> In a qqplot I am doing, I get lines/points that are very thick. I've tried
> setting the lwd variable to 0.1, but it doesn't seem to have any effect.
> Also, I have set the value of lty to dashed, but I still get dots. The
> command looks like
>
> qqplot(cdf.inv(seq(0,1,length=size),theta,pos,len),empmargdistvec(len,theta,pos,size),
>        xlim=c(-theta,theta), ylim=c(-theta,theta), lwd=0.1,
>        xlab="Marginal Quartiles", ylab="Empirical Marginal", col="red", lty="dashed")
>
> I tried putting
>
> par(lty="dashed",lwd=0.1)
>
> before this, but this doesn't have any effect either.
>
> I'm now wondering if I am doing something wrong. Does qqplot perhaps not
> accept these parameters? What should I do to make the lines/points
> thinner?

Thanks to the numerous people who replied. I stupidly did not realise that
the parameters lwd and lty would not apply unless I was plotting a line. I
think I assumed that the default points would turn into dashes and also
become smaller or something. :-) I should have realised that line type and
line width meant what they said. Excuse me, it was late at night.

Adding type="line" does indeed work. I suppose that if I wanted to shrink
the points I would use cex?

I think I need to look at a graphing tutorial. I see the "Contributed"
page has

    * Using R for Data Analysis and Graphics?  by John Maindonald.
    * Statistical Computing and Graphics Course Notes? by Frank E.
      Harrell.

Any other suggestions? Google (usually invaluable) is useless for this,
since searching for "R" is not very productive. Now if it was only called
SuperDuperStatPackage...

                                                   Faheem.


From anna at ptolemy.arc.nasa.gov  Tue Apr 29 23:46:26 2003
From: anna at ptolemy.arc.nasa.gov (Anna  H. Pryor)
Date: Tue, 29 Apr 2003 14:46:26 -0700
Subject: [R] plots
Message-ID: <200304291446.26476.anna@ptolemy.arc.nasa.gov>


I have two separate questions.

The first is when I use xlab, the labels on my tic marks disappear.  Is there 
a way to make them reappear?  Also, is there a way to make my own labels for 
the tick marks?

My second question is, after I have spent a lot of time getting my plot to 
look just right, I want to save it to a file, but the only way I seem to know 
how to do it is to first use postscript() and then make the plot and then use 
dev.off().  I keep forgetting to do this, and I am wasting so much time.  Is 
there a way to save the plot after I have already made it?

Anna


From rolf at math.unb.ca  Tue Apr 29 23:49:47 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Tue, 29 Apr 2003 18:49:47 -0300 (ADT)
Subject: [R] R help
Message-ID: <200304292149.h3TLnl1L029148@erdos.math.unb.ca>

Peter Dalgaard writes:

> Shutnik <shutnik_xx at yahoo.co.uk> writes:
> 
> >  Hello,
> >  I have the normal random variables y(t)~N(mu, sigma.sq) and want
> >  to decompose them into n normal variables:
> > 
> >  y(t) = x(t,1) + 
 + x(t,n) 

	I presume this means y(t) = x(t,1) + ... + x(t,n)  (R.T.)

> > 
> > x(t,i)~N(mu, sigma.sq/n) 

	I presume you want x(t,i)~N(mu/n, sigma.sq/n),
	elsewise the question doesn't make sense.

	I also presume you want the x(t,i) to be independent,
	elsewise the question is trivial.                  (R.T.)

> > 
> >  The problem is not as simple as can appear. All my experiments
> >  didnt give me anything so far. Are there any tools to do this?
> > 
> 
> This should work, provided I understand the problem correctly:
> 
> x <- rnorm(n,sd=sqrt(sigma.sq/n))
> x <- x - mean(x) + y/n

I don't think it's that simple:  By my calculations,

	Var(x_i) = 2*sigma.sq/n - sigma.sq/n^2,  not sigma.sq/n.

I think the problem is actually fairly subtle (although I may
be overlooking something simple).  Something like a Gramm-Schmidt
approach should work, but I can't quite suss it out.

					cheers,

						Rolf Turner
						rolf at math.unb.ca


From spencer.graves at pdf.com  Tue Apr 29 23:50:05 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 29 Apr 2003 14:50:05 -0700
Subject: [R] Re: thick plot lines
References: <Pine.LNX.4.44.0304291640540.29823-100000@Chrestomanci>
Message-ID: <3EAEF38D.9070409@pdf.com>

	  "Modern Applied Statistics with S" provides a reasonable 
introduction, I think.

	  For people who already know more or less what they want, the 
documentation for "par" is useful.

hth.  spencer graves

Faheem Mitha wrote:
> 
> On Tue, 29 Apr 2003, Faheem Mitha wrote:
> 
> 
>>Dear People,
>>
>>In a qqplot I am doing, I get lines/points that are very thick. I've tried
>>setting the lwd variable to 0.1, but it doesn't seem to have any effect.
>>Also, I have set the value of lty to dashed, but I still get dots. The
>>command looks like
>>
>>qqplot(cdf.inv(seq(0,1,length=size),theta,pos,len),empmargdistvec(len,theta,pos,size),
>>       xlim=c(-theta,theta), ylim=c(-theta,theta), lwd=0.1,
>>       xlab="Marginal Quartiles", ylab="Empirical Marginal", col="red", lty="dashed")
>>
>>I tried putting
>>
>>par(lty="dashed",lwd=0.1)
>>
>>before this, but this doesn't have any effect either.
>>
>>I'm now wondering if I am doing something wrong. Does qqplot perhaps not
>>accept these parameters? What should I do to make the lines/points
>>thinner?
> 
> 
> Thanks to the numerous people who replied. I stupidly did not realise that
> the parameters lwd and lty would not apply unless I was plotting a line. I
> think I assumed that the default points would turn into dashes and also
> become smaller or something. :-) I should have realised that line type and
> line width meant what they said. Excuse me, it was late at night.
> 
> Adding type="line" does indeed work. I suppose that if I wanted to shrink
> the points I would use cex?
> 
> I think I need to look at a graphing tutorial. I see the "Contributed"
> page has
> 
>     * Using R for Data Analysis and Graphics?  by John Maindonald.
>     * Statistical Computing and Graphics Course Notes? by Frank E.
>       Harrell.
> 
> Any other suggestions? Google (usually invaluable) is useless for this,
> since searching for "R" is not very productive. Now if it was only called
> SuperDuperStatPackage...
> 
>                                                    Faheem.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From kwan022 at stat.auckland.ac.nz  Tue Apr 29 23:56:29 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Wed, 30 Apr 2003 09:56:29 +1200 (NZST)
Subject: [R] plots
In-Reply-To: <200304291446.26476.anna@ptolemy.arc.nasa.gov>
Message-ID: <Pine.LNX.4.44.0304300951090.20823-100000@stat56.stat.auckland.ac.nz>

Hi,

On Tue, 29 Apr 2003, Anna  H. Pryor wrote:

> The first is when I use xlab, the labels on my tic marks disappear.  Is there 
> a way to make them reappear?  Also, is there a way to make my own labels for 
> the tick marks?

Which version of R are you using on which platform?  Which plot were you 
trying to draw that cause this?  Can you give us some reproducible 
examples?  

The example seems to work fine:

plot(1:10, xlab = "A Label", ylab = "Another Label",
     axes = FALSE)
axis(1, at = seq(1, 10, by = 2),
     labels = c("a", "b", "c", "d", "e"))
axis(2, at = seq(1, 10, by = 2),
     labels = c("f", "g", "h", "i", "j"))

box()

> My second question is, after I have spent a lot of time getting my plot to 
> look just right, I want to save it to a file, but the only way I seem to know 
> how to do it is to first use postscript() and then make the plot and then use 
> dev.off().  I keep forgetting to do this, and I am wasting so much time.  Is 
> there a way to save the plot after I have already made it?

You should be typing your R codes in a text editor (whatever platform 
you're working on).  Then copy and paste the codes into R.  This way you 
are not only able to make changes easily but also you have a good way to 
keep your history.

There are other graphics formats available, such as png(), pdf()...etc.

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From ericjons001 at europe.com  Wed Apr 30 00:00:30 2003
From: ericjons001 at europe.com (ERIC JONES)
Date: Wed, 30 Apr 2003 00:00:30
Subject: [R] INVESTMENT
Message-ID: <200304292200.h3TM0Fbi005385@hypatia.math.ethz.ch>

ATTN:

MY NAME IS MR ERIC JONES CHAIRMAN OF CONTRACT
AWARD AND MONITORING COMMITTEE OF THE MINISTRY OF INDUSTRY AND 
INTERNATIONAL TRADE DEVELOPMENT ,MY DUTY AS EMPOWERED BY THE MAURITIUS 
GOVERNMENT IS TO PROVIDE THE BASIC AMENITIES,SOCIAL RECREATIONAL ACTIVITIES IN 
URBAN AND RURAL AREAS.

THIS PROGRAMME INCLUDES ASSISTANCE TO DEPRIVED LOCAL COMMUNITIES AND TO 
CO-ORDINATE PROJECTS AND DEVELOPMENT AT THE NATIONAL LEVEL, 
FURTHERMORE, FROM THIS PROJECTS WE HAVE BEEN ABLE TO SECURED SOME REASONABLE 
AMOUNT OF U.S.$21.8(TWENTY ONE MILLION EIGHT HUNDRED THOUSAND 
U.S.DOLLARSONLY) AS COMISSION
FROM VARIOUS CONTRACTORS RESULTING FROM OVERINVOICING ,HENCE ALL THE 
NECESSARRY APPROVALS HAS BEEN COMPLETED.

THESE APPROVED FUND WAS PACKAGED AND DESPATCHED
THROUGH A SECURITY COMPANY FOR ONWARD DELIVERY TO ITS DESTINATION IN 
EUROPE. 
THESE FUND WAS FIRST DEPOSITED INTO A  SECURITY VAULT BEFORE WE ARRANGE 
FOR ITS MOVEMENT TO EUROPE THROUGH DIPLOMATIC CHANNEL USING DECOY 
PURPORTING THAT THE FUND BELONGS TO AN EXPATRIATE/COMPANY, AS WE ARE
GOVERNMENT OFFICIALS,WE ARE NOT ALLOWED TO OPERATE FOREIGN BANK 
ACCOUNT,HENCE WE NEED YOU TO STAND AS THE BENEFICIARY AND CLAIM THE FUND ON 
OUR BEHALF FROM THE SECURITY COMPANY.

PRESENTLY I AM NOW IN EUROPE TO SEARCH FOR A RELIABLE PERSON/COMPANY OF 
HIGH  INTERGRITY /DIGNITY AND ONE WITH CONSCIENCE WHO WILL CLAIM THIS 
FUND ON OUR BEHALF
AS THE BENEFICIARY ,AND WE HAVE AGREED TO GIVE YOU 25%OF THE TOTAL SUM 
AS COMMISSION FOR YOUR
ASSISTANCE/EFFORT.AND 5% WILL BE USED TO SETTLE EVERY EXPENSES INCURRED 
WE WILL USE 70%TO INVEST UNDER YOUR RECOMMENDATION AND GUIDE AND GO 
INTO JOINT VENTURE BUSINESS WITH YOU.

I WOULD GREATLY APPRECIATE YOUR ASSISTANCE . I LOOK FORWARD TO YOUR 
RESPONSE AS SOON AS POSSIBLE.

BEST REGARDS

ERIC JONES

REPLY TO:ericjons001 at europe.com
or call 008821651156647.


From p.dalgaard at biostat.ku.dk  Wed Apr 30 00:27:33 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 30 Apr 2003 00:27:33 +0200
Subject: [R] R help
In-Reply-To: <200304292149.h3TLnl1L029148@erdos.math.unb.ca>
References: <200304292149.h3TLnl1L029148@erdos.math.unb.ca>
Message-ID: <x2el3llz1m.fsf@biostat.ku.dk>

Rolf Turner <rolf at math.unb.ca> writes:

> Peter Dalgaard writes:
> 
> > Shutnik <shutnik_xx at yahoo.co.uk> writes:
> > 
> > >  Hello,
> > >  I have the normal random variables y(t)~N(mu, sigma.sq) and want
> > >  to decompose them into n normal variables:
> > > 
> > >  y(t) = x(t,1) + 
 + x(t,n) 
> 
> 	I presume this means y(t) = x(t,1) + ... + x(t,n)  (R.T.)
> 
> > > 
> > > x(t,i)~N(mu, sigma.sq/n) 
> 
> 	I presume you want x(t,i)~N(mu/n, sigma.sq/n),
> 	elsewise the question doesn't make sense.
> 
> 	I also presume you want the x(t,i) to be independent,
> 	elsewise the question is trivial.                  (R.T.)
> 
> > > 
> > >  The problem is not as simple as can appear. All my experiments
> > >  didnt give me anything so far. Are there any tools to do this?
> > > 
> > 
> > This should work, provided I understand the problem correctly:
> > 
> > x <- rnorm(n,sd=sqrt(sigma.sq/n))
> > x <- x - mean(x) + y/n
> 
> I don't think it's that simple:  By my calculations,
> 
> 	Var(x_i) = 2*sigma.sq/n - sigma.sq/n^2,  not sigma.sq/n.

Try again... Var(y/n) = sigma.sq/n^2, not sigma.sq/n so it cancels the
second term rather than doubling the first.
 
> I think the problem is actually fairly subtle (although I may
> be overlooking something simple).  Something like a Gramm-Schmidt
> approach should work, but I can't quite suss it out.

You just need to orhtogonalize against the vector (1,1,...,1), which
is what I did, effectively. The residuals x-mean(x) are independent of
mean(x) by the Fisher-Cochran theorem (if I remember the name
correctly...) and y/n has same distribution as mean(x) so you can
substitute y/n for mean(x) and paste things back together again.

But where does the t in y(t) and x(t,i) enter in all of this??

-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From p.dalgaard at biostat.ku.dk  Wed Apr 30 00:45:35 2003
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard BSA)
Date: 30 Apr 2003 00:45:35 +0200
Subject: [R] Re: thick plot lines
In-Reply-To: <Pine.LNX.4.44.0304291640540.29823-100000@Chrestomanci>
References: <Pine.LNX.4.44.0304291640540.29823-100000@Chrestomanci>
Message-ID: <x2ade8ncs0.fsf@biostat.ku.dk>

Faheem Mitha <faheem at email.unc.edu> writes:

> On Tue, 29 Apr 2003, Faheem Mitha wrote:

> Any other suggestions? Google (usually invaluable) is useless for this,
> since searching for "R" is not very productive. Now if it was only called
> SuperDuperStatPackage...

Actually, Google does find a fair number of relevant hits if you look
for "R graphics". It does turn up quite a few registered trademarks
relating to graphics as well, though, and also a couple of curiosities
like

    http://members.tripod.com/sandrgraphics/
and
    http://www.apl-385.demon.co.uk/rcs/programs/r/gref.htm
-- 
   O__  ---- Peter Dalgaard             Blegdamsvej 3  
  c/ /'_ --- Dept. of Biostatistics     2200 Cph. N   
 (*) \(*) -- University of Copenhagen   Denmark      Ph: (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)             FAX: (+45) 35327907


From pkleiber at honlab.nmfs.hawaii.edu  Wed Apr 30 00:43:59 2003
From: pkleiber at honlab.nmfs.hawaii.edu (Pierre Kleiber)
Date: Tue, 29 Apr 2003 12:43:59 -1000
Subject: [R] plots
References: <200304291446.26476.anna@ptolemy.arc.nasa.gov>
Message-ID: <3EAF002F.3060909@honlab.nmfs.hawaii.edu>

Anna H. Pryor wrote:
> I have two separate questions.
> 
> The first is when I use xlab, the labels on my tic marks disappear.  Is there 
> a way to make them reappear?  Also, is there a way to make my own labels for 
> the tick marks?
> 
> My second question is, after I have spent a lot of time getting my plot to 
> look just right, I want to save it to a file, but the only way I seem to know 
> how to do it is to first use postscript() and then make the plot and then use 
> dev.off().  I keep forgetting to do this, and I am wasting so much time.  Is 
> there a way to save the plot after I have already made it?

Once you have the plot looking just right on the screen, it is not 
necessary to replot in order to save it as a file.  Check out the 
functions dev.copy(), dev.copy2eps, and dev.print()

Pierre Kleiber


> 
> Anna
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>


From mitsrayi at chem.ucla.edu  Wed Apr 30 00:45:30 2003
From: mitsrayi at chem.ucla.edu (mitsrayi@chem.ucla.edu)
Date: Tue, 29 Apr 2003 22:45:30 -0000
Subject: [R] C algorithm to call R?
Message-ID: <200304292245.h3TMjUN5011534@carbon.chem.ucla.edu>

Does anyone have a C or C++ algorithm to call "R"? Thank you for your help.


From fzagmutt at hotmail.com  Wed Apr 30 01:15:53 2003
From: fzagmutt at hotmail.com (Francisco J. Zagmutt Vergara)
Date: Tue, 29 Apr 2003 23:15:53 +0000
Subject: [R] plot with nlme
Message-ID: <Law15-F35M0mkhcQZt00000530a@hotmail.com>





>>>From: Hank Stevens <HStevens at muohio.edu>
>>>To: r-help at stat.math.ethz.ch
>>>Subject: [R] plot with nlme
>>>Date: Tue, 29 Apr 2003 10:03:23 -0400
>>>
>>>Using R v. 1.7.0 on Windows 2000
>>>
>>>I would like to plot the fitted values of a model as a function of a 
>>>continuous covariate, augmented with data (e.g., augPred) grouping by 
>>>combinations of fixed effects. I have not been able to use augPred 
>>>effectively, and am wondering if it does not handle unbalanced data (3 
>>>out of 192 missing).
>>>I include below the model and an xyplot that almost does the job. I would 
>>>happily send anyone the data if they would be willing to help.
>>>Many Thanks in advance.
>>>Hank
>>>
>>>The model:
>>>
>>>fm <- lme( log(S,2) ~ Fert*Litter*Seed*Density, data = collimd, random = 
>>>~1|block/plot/Seed )
>>>
>>># The following is close, but fits lines within each panel rather than 
>>>giving me the fitted values generated by the model.
>>>
>>>xyplot( log(S,2)  ~  log10(Nper0.5m)  |  Fert*Seed, data = collimd,
>>>groups=Litter,
>>>        scales = list( alternating =FALSE, tck=c(1,0)), layout = 
>>>c(4,2,1), aspect = 1, as.table = T,
>>>          key = list(space="top", transparent = TRUE,
>>>                    points=list(pch=c(1,3)),
>>>                      #trellis.par.get("superpose.symbol")$pch[1:2],
>>>                    lines=list(lty=1:2),
>>>                    text = list(c("With Litter", "Litter Removed"))   ) ,
>>>
>>>        panel = function(x, y, subscripts,...) {
>>>            panel.grid(h=-1, v= -1)
>>>            panel.superpose(x, y,subscripts, pch=c(1,3),col=1,...)
>>>             panel.superpose(x, y, 
>>>panel.groups="panel.lmline",lty=1:2,subscripts,...)
>>>
>>>            })
>>>
>>>
>>>
>>>Martin Henry H. Stevens, Assistant Professor
>>>338 Pearson Hall
>>>Botany Department
>>>Miami University
>>>Oxford, OH 45056
>>>
>>>Office: (513) 529-4206
>>>Lab: (513) 529-4262
>>>FAX: (513) 529-4243
>>>http://www.cas.muohio.edu/botany/bot/henry.html
>>>http://www.muohio.edu/ecology
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>>
>>
>>_________________________________________________________________
>>Charla con tus amigos en l?nea mediante MSN Messenger: 
>>http://messenger.yupimsn.com/
>
>Martin Henry H. Stevens, Assistant Professor
>338 Pearson Hall
>Botany Department
>Miami University
>Oxford, OH 45056
>
>Office: (513) 529-4206
>Lab: (513) 529-4262
>FAX: (513) 529-4243
>http://www.cas.muohio.edu/botany/bot/henry.html
>http://www.muohio.edu/ecology



>At 10:54 AM 4/29/2003, Francisco Zagmutt wrote:
>>Hi there
>>
>>I had that problem before and apparently it has to be with the log 
>>transformation that you used in the formula. R will not recognize the 
>>variable name and hence will just give you a plot with the fitted values 
>>and will give you a warning about the variable name.
>>Try creating a new variable with the log transformed values (i.e. log.y) 
>>of your original predictor and then use this new variable as your 
>>predictor.
>>
>>fm <- lme( log.y ~ Fert*Litter*Seed*Density, data = collimd,
>>>random = ~1|block/plot/Seed )
>>
>>
>>Let me know if this worked
>>
>>Francisco




>From: Hank Stevens <HStevens at muohio.edu>
>To: "Francisco J. Zagmutt Vergara" <fzagmutt at hotmail.com>
>Subject: Re: [R] plot with nlme
>Date: Tue, 29 Apr 2003 11:06:27 -0400
>
>Francisco!
>Thanks!
>
>plot( augPred( fm) )
>
>worked!
>
>Now, however, I would like to group by fixed effects, not random variables 
>(e.g., Subjects). Any thoughts?
>
>
>
>>
>>
>>


From pcampbell at econ.bbk.ac.uk  Tue Apr 29 22:47:28 2003
From: pcampbell at econ.bbk.ac.uk (Phineas Campbell)
Date: Tue, 29 Apr 2003 21:47:28 +0100
Subject: [R] Installing On Solaris
Message-ID: <3EAEE4E0.1060702@econ.bbk.ac.uk>

I've downloaded gcc 2.95, and installed R-1.7.0
It appears to config properly, the config.out is at the following URL:
http://www.phineas.pwp.blueyonder.co.uk/config.log
Running make does not appear to work
the errors are summarized:
bash: ar: command not found
*** Error code 127
make: Fatal error Command failed for target 'libappl.a'
*** Error code 1
make: Fatal error: Command failed for target 'R'
Current Working directory /R_HOME/R-1.7.0/src/appl
*** Error code 1
make: Fatal error: Command failed for target 'R'
Current  working directory /R_HOME/R-1.7.0/src
*** Error code 1
make: Fatal error: Command failed for target 'R'

Running make check FORCE=FORCE
gives

'Makedeps' is up to date
make: Fatal error don't know how to make target '../../bin/R.bin

<SNIP>

I run the R script and get /.../.../../R-1.7.0/bin/R.bin: not found

Phineas
pcampbell at econ.bbk.ac.uk


From zedshaw at telus.net  Wed Apr 30 01:36:00 2003
From: zedshaw at telus.net (Zed Shaw)
Date: Tue, 29 Apr 2003 16:36:00 -0700
Subject: [R] C algorithm to call R?
Message-ID: <E19Aedk-0000u5-00@s216-232-85-43.bc.hsia.telus.net>

Hi,

I might be able to help you with that.  Check out this file from the 
Obversive project:

http://cvs.sourceforge.net/cgi-
bin/viewcvs.cgi/obversive/obversive/src/backend/Attic/RService_i.cpp?
rev=1.1.2.11&content-type=text/vnd.viewcvs-markup

The link is really long, so make sure you have everything on the above 
line.

The file you are looking at is from our RBackend component, which is a 
CORBA interface directly to the R system for running most basic code.  
I don't know what your R calling needs are specifically, but this code 
has lots of goodies you can probably use, and it is heavily commented.

The two methods to look at are RService_i::parse and 
RService_i::syntax.  In the syntax function I use a hand written 
parser I developed to return better error messages--which happens in 
the "check_syntax" method--so you can just ignore the rest.

I hope that helps.

Zed A. Shaw
http://www.zedshaw.com/


> Does anyone have a C or C++ algorithm to call "R"? Thank you for 
your help.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
>


From luke at stat.uiowa.edu  Wed Apr 30 02:40:55 2003
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 29 Apr 2003 19:40:55 -0500 (CDT)
Subject: [R] Problme with <<- (was Apparent namespace problem)
In-Reply-To: <20030428222504.GE21975@epibiosun115-4.libaux.ucsf.edu>
Message-ID: <Pine.LNX.4.44.0304291935070.6415-100000@nokomis2.stat.umn.edu>

On Mon, 28 Apr 2003, Ross Boylan wrote:

> > > First, is there a way to find out what frame (as in frames in
> > > environments, not data frames) a name is being obtained from or put
> > > into?
> > 
> > ?find.
> 
> Here's where I have a question.  find appears to operate on the search
> path.  I thought that was a different concept from environments and
> frames.  The search path, I think, doesn't include dynamically created
> frames from the course of function execution.

Don't recall if there is anything built in, but you can use parent.env
to walk up the environment frames.  Using that, something like

findVarEnv<-function(name, env = parent.frame()) {
    while (! is.null(env)) 
        if (exists(name, env = env, inherits = FALSE)) return(env)
        else env <- parent.env(env)
    if (exists(name, env=NULL)) return(NULL)
    else return(NA)
}

should return the first environment in which a variable identified by
the 'name' argument exists.

luke

-- 
Luke Tierney
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
   Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From s195404 at student.uq.edu.au  Wed Apr 30 02:43:12 2003
From: s195404 at student.uq.edu.au (Andrew C. Ward)
Date: Wed, 30 Apr 2003 00:43:12 +0000
Subject: [R] Cluster analysis and bootstraps
In-Reply-To: <2D88364A-7A71-11D7-9CC9-000393DB5846@msu.edu>
References: <2D88364A-7A71-11D7-9CC9-000393DB5846@msu.edu>
Message-ID: <1051663392.3eaf1c207f90b@my.uq.edu.au>

You could try function fanny() in package cluster. This function does
fuzzy clustering, and returns a coefficient for each object/cluster
of how fuzzy or crisp the clustering was.

It's hard to imagine bootstrapping a confidence interval around a
categorical value such as a cluster. Perhaps someone else can explain
this.


Regards,

Andrew C. Ward

CAPE Centre
Department of Chemical Engineering
The University of Queensland
Brisbane Qld 4072 Australia
andreww at cheque.uq.edu.au




Quoting "Hector L. Ayala-del-Rio" <ayalahec at msu.edu>:

> Hi R helpers,
> 
>    I was wondering if anybody knows if is possible to generate
> bootstrap 
> values for a cluster analysis in R.  What I am trying to do is
> obtain 
> some confidence on the clusters formed by resampling the data set. 
> A 
> similar type of analysis is used in molecular taxonomy and the 
> confidence values of each cluster are placed in the nodes of the 
> dendogram.  Any ideas on how to do this in R will be appreciated.
> 
> Thanks
> 
> H?ctor L. Ayala-del-R?o, Ph.D.
> Center for Microbial Ecology &
> Center for Genomic and Evolutionary Studies
> on Microbial Life at Low Temperatures
> Michigan State University
> 545 Plant & Soil Sciences Building
> East Lansing, MI 48824-1325
> Phone: 517-353-9021
> Fax: 517-353-2917
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
>


From gisar at nus.edu.sg  Wed Apr 30 02:53:48 2003
From: gisar at nus.edu.sg (Adaikalavan Ramasamy)
Date: Wed, 30 Apr 2003 08:53:48 +0800
Subject: [R] C algorithm to call R?
Message-ID: <024D6AEFCB92CB47BA1085751D184BB80105F24E@MBXSRV03.stf.nus.edu.sg>

See Chapter 4 and 5 of Writing R Extensions or
http://www2.cs.washington.edu/uns/cgi/info2www.pl?(R-exts)Numerical+anal
ysis+subroutines

If you want to use R functions as standalone for C then read the very
last section of Chapter 5 on building libRmath.



-----Original Message-----
From: mitsrayi at chem.ucla.edu [mailto:mitsrayi at chem.ucla.edu] 
Sent: Wednesday, April 30, 2003 6:46 AM
To: r-help at stat.math.ethz.ch
Subject: [R] C algorithm to call R?


Does anyone have a C or C++ algorithm to call "R"? Thank you for your
help.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From meb at dataventures.com  Wed Apr 30 00:41:41 2003
From: meb at dataventures.com (Mike Beddo)
Date: 29 Apr 2003 16:41:41 -0600
Subject: [R] reconstructing contingency tables in R
Message-ID: <1051656111.3670.34.camel@newmiketop>

Dear R-help,

I need help reconstructing contingency tables from (sort-of) marginals,
so that I can use loglin to model the table. I'm working with category
variables that are binary. However, my data have already been summed
over other variables and I need to un-sum it, i.e. if my variables are A
and B, I would like to have the cell (Nij) frequencies

N total trials
N(A=0, B=0) = N00 times
N(A=0, B=1) = N01
N(A=1, B=0) = N10
N(A=1, B=1) = N11

but instead I have N(A=1) = N_1+ [summed over B], N(B=1) = N_+1 [summed
over B], N(A=1, B=1) = N_11 data available to me. For 2x2 it's
straightforward to compute Nij:

N00 = N - N_1+ - N_+1 + N_11
N01 = N_+1 - N_11
N10 = N_1+ - N_11
N11 = N_11

and then I can use xtabs. But it gets more complicated as the number of
category variables increases. I know how to do it on paper, but I don't
know how to do it in a generic way within R.

- Mike


From Simon.Blomberg at anu.edu.au  Wed Apr 30 03:46:52 2003
From: Simon.Blomberg at anu.edu.au (Simon Blomberg)
Date: Wed, 30 Apr 2003 11:46:52 +1000
Subject: [R] Cluster analysis and bootstraps
Message-ID: <7A3A13F416B40842BD2C1753E044B359B13385@CASEVS02.cas.anu.edu.au>


> It's hard to imagine bootstrapping a confidence interval around a
> categorical value such as a cluster. Perhaps someone else can explain
> this.

Bootstrap support indices are not confidence intervals. The process is, I think, (in a nutshell):

Assume that there are N objects to be clustered, based on the similarity of C variables measured on each of the N objects.

1. Create a bootstrap dataset by resampling the C variables with replacement on the N objects.

2. Run the clustering algorithm on the bootstrap dataset to cluster the N objects.

3. Repeat steps 1 and 2 a large number of times.

4. Construct a majority-rule  consensus tree from all the bootstrapped cluster analyses.

4. Calculate the bootstrap support index for each cluster in the consensus tree as the percentage of times each cluster was recovered in the set of bootstrapped cluster analyses.

See Felsenstein, J. 1985. Confidence limits on phylogenies: an approach using the bootstrap. Evolution 39: 783-791. 

No, I don't know how to do this in R, but I agree that it would be useful!

Simon.

Simon Blomberg
Depression & Anxiety Consumer Research Unit
Centre for Mental Health Research
Australian National University
http://www.anu.edu.au/cmhr/
Simon.Blomberg at anu.edu.au  +61 (2) 6125 3379


From eclassic at hotmail.com  Wed Apr 30 07:26:49 2003
From: eclassic at hotmail.com (Progressive Economist)
Date: Wed, 30 Apr 2003 05:26:49 +0000
Subject: [R] Getting rate of return
Message-ID: <Law15-F10uITqfnfEni0000c9f2@hotmail.com>



Dear R help.
I have a beginner's question to ask you. I faced a difficulty in getting 
rate of return for some target data.
I finished data importing and some manipulations. but I have any idea after 
that.
Anyone who answer this question?

Thanks in advance

Park H.J


From sbarbar at gwdg.de  Wed Apr 30 08:50:47 2003
From: sbarbar at gwdg.de (Salvatore Barbaro)
Date: Wed, 30 Apr 2003 08:50:47 +0200
Subject: [R] Getting rate of return
In-Reply-To: <Law15-F10uITqfnfEni0000c9f2@hotmail.com>
Message-ID: <3EAF8E67.24861.1E7E37@localhost>

# Hi,

# define as r the revenue and as c the cost
# for example:
r<- 60
c<- 50
# function to obtain the rate of return:
ror<- function(r,c){
foo<- r/c-1
return(foo)
}
# the command ror(r,c) gives you the required rate of return
ror(r,c)

best regards

s.







On 30 Apr 2003 at 5:26, Progressive Economist wrote:



Dear R help.
I have a beginner's question to ask you. I faced a difficulty in
getting rate of return for some target data. I finished data importing
and some manipulations. but I have any idea after that. Anyone 
who
answer this question?

Thanks in advance

Park H.J

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help
salvatore barbaro
department of public economics
platz der g?ttinger sieben 3
37073 g?ttingen
tel.: +49 551 3919704
fax:  +49 551 39 7353
http://www.gwdg.de/~sbarbar


From ripley at stats.ox.ac.uk  Wed Apr 30 08:59:57 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 30 Apr 2003 07:59:57 +0100 (BST)
Subject: [R] Installing On Solaris
In-Reply-To: <3EAEE4E0.1060702@econ.bbk.ac.uk>
Message-ID: <Pine.LNX.4.44.0304300753540.26176-100000@gannet.stats>

On Solaris ar is in /usr/ccs/bin: do you have that in your path? It
contains other tools needed to compile/build programs. (I suspect one can
install Solaris without those tools.)

On Tue, 29 Apr 2003, Phineas Campbell wrote:

> I've downloaded gcc 2.95, and installed R-1.7.0

Where did you get gcc from?  For the version on www.sunfreeware.com you
need binutils too (see the R-admin manual).  (BTW 2.95 looks strange:
3.2.3 is current, but some people still use 2.95.3, but not 2.95.)

> It appears to config properly, the config.out is at the following URL:
> http://www.phineas.pwp.blueyonder.co.uk/config.log
> Running make does not appear to work
> the errors are summarized:
> bash: ar: command not found
> *** Error code 127
> make: Fatal error Command failed for target 'libappl.a'
> *** Error code 1
> make: Fatal error: Command failed for target 'R'
> Current Working directory /R_HOME/R-1.7.0/src/appl
> *** Error code 1
> make: Fatal error: Command failed for target 'R'
> Current  working directory /R_HOME/R-1.7.0/src
> *** Error code 1
> make: Fatal error: Command failed for target 'R'
> 
> Running make check FORCE=FORCE
> gives
> 
> 'Makedeps' is up to date
> make: Fatal error don't know how to make target '../../bin/R.bin
> 
> <SNIP>
> 
> I run the R script and get /.../.../../R-1.7.0/bin/R.bin: not found
> 
> Phineas
> pcampbell at econ.bbk.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Apr 30 09:16:58 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 30 Apr 2003 08:16:58 +0100 (BST)
Subject: [R] Holt Winters Error
In-Reply-To: <20030429181504.6641.qmail@web12507.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0304300815320.26176-100000@gannet.stats>

That's not an error, but a line of R code.

If you could post an example which generates the error and the actual 
error message, we could try to investigate it.

On Tue, 29 Apr 2003, Kel wrote:

> I have come across with the following error while
> running HoltWinters().
> 
> optim(c(0.3, 0.1, 0.1), error, method = "L-BFGS-B", 
> lower = c(0, 0, 0), upper = c(1, 1, 1))
> 
> It only happens to multiplicative seasonality but not
> additive.  I read the program but still couldn't
> understand it.  

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Apr 30 09:36:30 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 30 Apr 2003 08:36:30 +0100 (BST)
Subject: [R] polynomial fitting
In-Reply-To: <1051635365.1455.1027.camel@hepcat>
Message-ID: <Pine.LNX.4.44.0304300820400.26176-100000@gannet.stats>

On 29 Apr 2003, Suchandra Thapa wrote:

> I'm trying to find a way to fit a polynomial of degree n in x  and y to
> a set of x, y, and z data that I have and obtain the coefficients for
> the terms of the fitted polynomial.  However, when I try to use the
> surf.ls function I'm getting odd results.  
> 
> > x <- seq(0, 10, length=50)
> > y <- x
> > f <- function (x, y) {x^2 + y}  
> > library(spatial)
> > test <- data.frame(x=x, y=y, z=f(x, y))
> > test.kr <- surf.ls(2, test)
> > test.kr$beta
> [1] 0 0 0 0 0 0
> 
> When I try the example from the help I get:
> 
> >      library(MASS)
> >      data(topo, package="MASS")
> >      topo.kr <- surf.ls(2, topo)
> > topo.kr$beta
> [1] 801.217617 -11.018887  68.229148 -73.992968   3.343573   8.342717
> 
> Why is my test data causing problems?  

They lie on a line in the x-y plane, so there is collinearity in the fit
and you cannot fit a 2-dimensional trend surface uniquely.

> Also it seems that the beta
> attribute from the object returned the surf.ls correspond with the terms
> of the fitted polynomial.  If this is correct, in what order are the
> coefficients for the fitted polynomial given?  

It is not fully correct, as there is scaling of the data going on before 
fitting the polynomial.

> Finally, the R source
> code for the spatial library indicate that both surf.ls and surf.gls are
> limited to polynomials of degree 6 or below.  Is there another function
> that will work with higher order polynomials.  

You can use the R function poly() to fit orthogonal polynomials using lm
(provided you have genuinely two-dimensional data).

> lm(z ~ poly(x,y, degree= 2), data=topo)
Coefficients:
              (Intercept)  poly(x, y, degree = 2)1.0  
                   827.07                     -20.54  
poly(x, y, degree = 2)2.0  poly(x, y, degree = 2)0.1  
                   167.27                    -337.40  
poly(x, y, degree = 2)1.1  poly(x, y, degree = 2)0.2  
                    67.26                      20.13  


Reminder: spatial is part of the VR bundle, whose DESCRIPTION file says it
is software to support a book.  It is not intended to be comprehensive,
just sufficient for the techniques covered in that book.  I have never
seen a real application of trend surfaces of degree more than 6.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Apr 30 09:50:20 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 30 Apr 2003 08:50:20 +0100 (BST)
Subject: [R] Building R on Solaris: gcc 3.2.3 works
Message-ID: <Pine.LNX.4.44.0304300847300.26406-100000@gannet.stats>

gcc 3.2.3 released on Friday fixes the optimization bug in 3.2.2 and 3.2.1
on Solaris that caused R to crash:  after a couple of days of tests 3.2.3 
seems to have produced a solid installation.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From wegmann at biozentrum.uni-wuerzburg.de  Wed Apr 30 11:40:40 2003
From: wegmann at biozentrum.uni-wuerzburg.de (Martin Wegmann)
Date: Wed, 30 Apr 2003 11:40:40 +0200
Subject: [R] pca
Message-ID: <3EAF9A18.5F7A5F4@biozentrum.uni-wuerzburg.de>

Hello,
I tried to compute a PCA of values derived from satellite imagery but
with princomp I get the following output:

>  pca.late <- princomp(late, na.action=na.fail)
Error in cov.wt(z) : x must contain finite values only>

the datasets are values from satellite imagery, therfore I assume they
are finite. But if not is there a way to minimize the decimal place?

I tried prccomp as well but I don't understand this output at all and I
can't add "na.action=na.pass" what I thought could be the problem.

 pcalate<-prcomp(late,scale=T)
Error in svd(x, nu = 0) : NA/NaN/Inf in foreign function call (arg 1)

any idea how to fix it?

thanks in advance, cheers Martin


--
Martin Wegmann
Department of Animal Ecology and Tropical Biology
Zoology III, Biocenter
Am Hubland
97074 W?rzburg
Germany
0931/888-4378
wegmann at biozentrum.uni-wuerzburg.de
m.wegmann at web.de


From hennig at stat.math.ethz.ch  Wed Apr 30 11:59:01 2003
From: hennig at stat.math.ethz.ch (Christian Hennig)
Date: Wed, 30 Apr 2003 11:59:01 +0200 (CEST)
Subject: [R] pca
In-Reply-To: <3EAF9A18.5F7A5F4@biozentrum.uni-wuerzburg.de>
Message-ID: <Pine.LNX.4.44.0304301155410.1919-100000@florence>

Hello,

the first thing you should do is to look at your data. You should know if
there are Inf, NaN, or NA values. I do not more about princomp's facilities
to handle such values than the help page says, but PCA with infinite values
does definitely not make sense. You should omit, correct or replace these
values (the latter two options only if you have subject-matter information how
to do this properly). 

Christian

On Wed, 30 Apr 2003, Martin Wegmann wrote:

> Hello,
> I tried to compute a PCA of values derived from satellite imagery but
> with princomp I get the following output:
> 
> >  pca.late <- princomp(late, na.action=na.fail)
> Error in cov.wt(z) : x must contain finite values only>
> 
> the datasets are values from satellite imagery, therfore I assume they
> are finite. But if not is there a way to minimize the decimal place?
> 
> I tried prccomp as well but I don't understand this output at all and I
> can't add "na.action=na.pass" what I thought could be the problem.
> 
>  pcalate<-prcomp(late,scale=T)
> Error in svd(x, nu = 0) : NA/NaN/Inf in foreign function call (arg 1)
> 
> any idea how to fix it?
> 
> thanks in advance, cheers Martin
> 
> 
> --
> Martin Wegmann
> Department of Animal Ecology and Tropical Biology
> Zoology III, Biocenter
> Am Hubland
> 97074 W?rzburg
> Germany
> 0931/888-4378
> wegmann at biozentrum.uni-wuerzburg.de
> m.wegmann at web.de
> 
> 

-- 
***********************************************************************
Christian Hennig
Seminar fuer Statistik, ETH-Zentrum (LEO), CH-8092 Zuerich (currently)
and Fachbereich Mathematik-SPST/ZMS, Universitaet Hamburg
hennig at stat.math.ethz.ch, http://stat.ethz.ch/~hennig/
hennig at math.uni-hamburg.de, http://www.math.uni-hamburg.de/home/hennig/
#######################################################################
ich empfehle www.boag.de


From sebastian-huber at web.de  Wed Apr 30 13:46:30 2003
From: sebastian-huber at web.de (Sebastian Huber)
Date: Wed, 30 Apr 2003 13:46:30 +0200
Subject: [R] Interactive Input Problem
Message-ID: <200304301346.30947.sebastian-huber@web.de>

Hi,
I built and installed R-base-1.7.0 on SuSE 8.2 without any problems, but the 
interactive R interpreter, has problems with cursor movement:

> ls()
character(0)
> ^[[A^[[B^[[D^[[C^[[A^[[D^[[C^[[B^[[D^[[A

These ugly characters are produced by the arrow keys. Does anyone know how to 
fix that problem?

Ciao
	Sebastian


From raf1729 at hotmail.com  Wed Apr 30 13:51:00 2003
From: raf1729 at hotmail.com (R A F)
Date: Wed, 30 Apr 2003 11:51:00 +0000
Subject: [R] Scanning data files line-by-line
Message-ID: <Law11-F111cYUhN5HyR00012433@hotmail.com>

Hi all, is there a way to read a data file into R line-by-line, akin
to what fscanf does in C, say?

It seems that "scan" and "read.table" both read the entire data file
in at once, whereas "readLines" allows one to read a file partially,
but doesn't quite read line-by-line either.

I guess what I was hoping to do is something like this:

while( linebyline( "file" ) != end of file )
{
    process each line
    ....
}

Thanks.


From maechler at stat.math.ethz.ch  Wed Apr 30 13:56:43 2003
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 30 Apr 2003 13:56:43 +0200
Subject: [R] pca
In-Reply-To: <3EAF9A18.5F7A5F4@biozentrum.uni-wuerzburg.de>
References: <3EAF9A18.5F7A5F4@biozentrum.uni-wuerzburg.de>
Message-ID: <16047.47611.738382.594593@gargle.gargle.HOWL>

>>>>> "Martin" == Martin Wegmann <wegmann at biozentrum.uni-wuerzburg.de>
>>>>>     on Wed, 30 Apr 2003 11:40:40 +0200 writes:

    Martin> Hello, I tried to compute a PCA of values derived
    Martin> from satellite imagery but with princomp I get the
    Martin> following output:

    >> pca.late <- princomp(late, na.action=na.fail)
    Martin> Error in cov.wt(z) : x must contain finite values only

    Martin> the datasets are values from satellite imagery,
    Martin> therfore I assume they are finite. But if not is
    Martin> there a way to minimize the decimal place?

    Martin> I tried prccomp as well but I don't understand this
    Martin> output at all and I can't add "na.action=na.pass"
    Martin> what I thought could be the problem.

    Martin>  pcalate<-prcomp(late,scale=T) 
    Martin> Error in svd(x, nu=0) : NA/NaN/Inf in foreign function call (arg 1)

    Martin> any idea how to fix it?

As Christian has suggested, look at your data.  I'm sure there
are non-finite values.

To find these, quickly, you can use

   which(!is.finite(data.matrix(late)), arr.ind = TRUE)

which will give you the row and column numbers of the non-finite
entries.

Hoping this helps,
Martin Maechler <maechler at stat.math.ethz.ch>	http://stat.ethz.ch/~maechler/
Seminar fuer Statistik, ETH-Zentrum  LEO C16	Leonhardstr. 27
ETH (Federal Inst. Technology)	8092 Zurich	SWITZERLAND
phone: x-41-1-632-3408		fax: ...-1228			<><


From alessandro.semeria at cramont.it  Wed Apr 30 14:17:53 2003
From: alessandro.semeria at cramont.it (alessandro.semeria@cramont.it)
Date: Wed, 30 Apr 2003 14:17:53 +0200
Subject: [R] plot(pam.object) error with R-1.7.0 on Red-Hat 8.0 i686
Message-ID: <OF03B0E3CF.0E6AB502-ONC1256D18.003D8855-C1256D18.0042B672@tomware.it>

Hello Martin!
I modified script with your suggestion 
"cl.pam.2 <- pam(as.dist(1-cor(mel.data)), k=2, keep.diss = TRUE)" 
obtaining the same "bad" cluster as your, 
then I performed pam without setting "keep.diss "
and looking to cl.pam.2$cluster I found
the same "good" parition as in R-1.6.2.
Then I think that your workaround is good to 
plot something but "destroy" the  job of pam!
A.S.

----------------------------

Alessandro Semeria 
Models and Simulations Laboratory
The Environment Research Center - Montecatini (Edison Group), 
Via Ciro Menotti 48,
48023 Marina di Ravenna (RA), Italy
Tel. +39 544 536811
Fax. +39 544 538663
E-mail: asemeria at cramont.it


From dmurdoch at pair.com  Wed Apr 30 14:26:26 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 30 Apr 2003 08:26:26 -0400
Subject: [R] Scanning data files line-by-line
In-Reply-To: <Law11-F111cYUhN5HyR00012433@hotmail.com>
References: <Law11-F111cYUhN5HyR00012433@hotmail.com>
Message-ID: <34gvavkrj9p49tuvhjgnp2l78nmo0vsbcs@4ax.com>

On Wed, 30 Apr 2003 11:51:00 +0000, you wrote:

>Hi all, is there a way to read a data file into R line-by-line, akin
>to what fscanf does in C, say?
>
>It seems that "scan" and "read.table" both read the entire data file
>in at once, whereas "readLines" allows one to read a file partially,
>but doesn't quite read line-by-line either.

That's what readLines(con, n=1) is supposed to do; in what way does it
not quite work?

Duncan


From wegmann at biozentrum.uni-wuerzburg.de  Wed Apr 30 14:33:26 2003
From: wegmann at biozentrum.uni-wuerzburg.de (Martin Wegmann)
Date: Wed, 30 Apr 2003 14:33:26 +0200
Subject: [R] Interactive Input Problem
References: <200304301346.30947.sebastian-huber@web.de>
Message-ID: <3EAFC295.D7993163@biozentrum.uni-wuerzburg.de>

Hi Sebastian,

that looks more like a problem with your shell. which one are you using? perhaps
it it solved by using another one e.g. bash.  otherwise you can find at the end
of the *.pdf "R-intro" http://cran.r-project.org/doc/manuals/R-intro.pdf  a
chapter called: the command line editor perhaps that helps.

cheers Martin


Sebastian Huber wrote:

> Hi,
> I built and installed R-base-1.7.0 on SuSE 8.2 without any problems, but the
> interactive R interpreter, has problems with cursor movement:
>
> > ls()
> character(0)
> > ^[[A^[[B^[[D^[[C^[[A^[[D^[[C^[[B^[[D^[[A
>
> These ugly characters are produced by the arrow keys. Does anyone know how to
> fix that problem?
>
> Ciao
>         Sebastian
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help

--
Martin Wegmann
Department of Animal Ecology and Tropical Biology
Zoology III, Biocenter
Am Hubland
97074 W?rzburg
Germany
0931/888-4378
wegmann at biozentrum.uni-wuerzburg.de
m.wegmann at web.de


From TyagiAnupam at aol.com  Wed Apr 30 14:35:28 2003
From: TyagiAnupam at aol.com (TyagiAnupam@aol.com)
Date: Wed, 30 Apr 2003 08:35:28 EDT
Subject: [R] Getting rate of return
Message-ID: <160.1fa51be7.2be11d10@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030430/b226c337/attachment.pl

From raf1729 at hotmail.com  Wed Apr 30 14:45:33 2003
From: raf1729 at hotmail.com (R A F)
Date: Wed, 30 Apr 2003 12:45:33 +0000
Subject: [R] Scanning data files line-by-line
Message-ID: <Law11-F26qXItMcx4vv00017679@hotmail.com>

Maybe I'm missing something.  When I do readLines( "file", n = 1) and
repeat, it always reads the first line of "file".  I've to be able to
advance to the next line, no?

I'll take a look at the command file(), as someone else suggested.

Thanks.

>From: Duncan Murdoch <dmurdoch at pair.com>
>To: "R A F" <raf1729 at hotmail.com>
>CC: R-help at stat.math.ethz.ch
>Subject: Re: [R] Scanning data files line-by-line
>Date: Wed, 30 Apr 2003 08:26:26 -0400
>
>On Wed, 30 Apr 2003 11:51:00 +0000, you wrote:
>
> >Hi all, is there a way to read a data file into R line-by-line, akin
> >to what fscanf does in C, say?
> >
> >It seems that "scan" and "read.table" both read the entire data file
> >in at once, whereas "readLines" allows one to read a file partially,
> >but doesn't quite read line-by-line either.
>
>That's what readLines(con, n=1) is supposed to do; in what way does it
>not quite work?
>
>Duncan


From rab at nauticom.net  Wed Apr 30 14:48:20 2003
From: rab at nauticom.net (Richard A. Bilonick)
Date: Wed, 30 Apr 2003 08:48:20 -0400
Subject: [R] Bug in arima?
Message-ID: <3EAFC614.5090900@nauticom.net>

I'm using the fixed argument in arima. Shouldn't ar4, ar5, and ar6 
display as zero in the output?

Call:
arima(x = window(log(hhprice), start = c(1990, 1), end = c(2003, 3)), 
order = c(7,
    1, 0), xreg = window(ts.union(exa1 = lag(exa, -1), exa12 = lag(exa,
    -12), exb1 = lag(exb, -1), exc1 = lag(exc, -1), exc12 = lag(exc,
    -12)), start = c(1990, 1), end = c(2003, 3)), include.mean = FALSE, 
fixed = c(NA,
    NA, NA, 0, 0, 0, NA, NA, NA, NA, NA, NA))

Coefficients:
         ar1      ar2      ar3      ar4      ar5   ar6      ar7      
exa1      exa12      exb1      exc1      exc12
      0.0922  -0.1279  -0.2661  -0.0577  -0.0277  0.02  -0.2167   
-0.3015     0.3424    0.0281    0.0519     0.1715
s.e.  0.0789   0.0801   0.0742   0.0000   0.0000  0.00   0.0853    
0.0503     0.0515    0.0295    0.0257     0.0329

Also, is the documentation wrong?

 From ?arima:

fixed: optional numeric vector of the same length as the total
          number of parameters.  If supplied, only non-`NA' entries in
          `fixed' will be varied.  `transform.pars = TRUE' will be
          overridden if any AR parameters are fixed.

The non-NA entries in my fixed argument are zeroes. Aren't these "fixed" 
to zero so they don't vary when a call is made to optim? I thought that 
was the purpose of the argument. I only wan ar1, ar2, ar3, and ar7 in 
the model so I'm setting ar4, ar5, and ar6 to zero.

My main concern is that the predict.Arima function works correctly when 
using the fixed argument. I'm assuming, output display notwithstanding, 
that ar4-ar6 are actually fixed to zero when using fixed. When I try to 
manually make the forecast, the result is slightly different than what 
predict.Arima reports. I'm wondering if that is due to these 
coefficients not being set to zero?

Rick B.


From ripley at stats.ox.ac.uk  Wed Apr 30 15:07:30 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 30 Apr 2003 14:07:30 +0100 (BST)
Subject: [R] Interactive Input Problem
In-Reply-To: <3EAFC295.D7993163@biozentrum.uni-wuerzburg.de>
Message-ID: <Pine.LNX.4.44.0304301401270.6018-100000@gannet.stats>

On Wed, 30 Apr 2003, Martin Wegmann wrote:

> that looks more like a problem with your shell. which one are you using? perhaps
> it it solved by using another one e.g. bash.  otherwise you can find at the end
> of the *.pdf "R-intro" http://cran.r-project.org/doc/manuals/R-intro.pdf  a
> chapter called: the command line editor perhaps that helps.

Sorry, no, no shell is involved.  This is what happens in Unix R if the 
readline library is not compiled in/activated (you can start R with
--no-readline).

Since you said you built `R-base-1.7.0' (not sure what that is: an SRPM?)
my guess is that you don't have the readline development tools on your
system.  Take a look at the configure output, and see what it said about
readline. You may need to install libreadline-devel or something like
that.

> Sebastian Huber wrote:
> 
> > Hi,
> > I built and installed R-base-1.7.0 on SuSE 8.2 without any problems, but the
> > interactive R interpreter, has problems with cursor movement:
> >
> > > ls()
> > character(0)
> > > ^[[A^[[B^[[D^[[C^[[A^[[D^[[C^[[B^[[D^[[A
> >
> > These ugly characters are produced by the arrow keys. Does anyone know how to
> > fix that problem?
> >
> > Ciao
> >         Sebastian
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 
> --
> Martin Wegmann
> Department of Animal Ecology and Tropical Biology
> Zoology III, Biocenter
> Am Hubland
> 97074 W?rzburg
> Germany
> 0931/888-4378
> wegmann at biozentrum.uni-wuerzburg.de
> m.wegmann at web.de
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Apr 30 15:13:26 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 30 Apr 2003 14:13:26 +0100 (BST)
Subject: [R] Scanning data files line-by-line
In-Reply-To: <Law11-F26qXItMcx4vv00017679@hotmail.com>
Message-ID: <Pine.LNX.4.44.0304301407360.6018-100000@gannet.stats>

On Wed, 30 Apr 2003, R A F wrote:

> Maybe I'm missing something.  When I do readLines( "file", n = 1) and
> repeat, it always reads the first line of "file".  I've to be able to
> advance to the next line, no?

You need to open the connection first.  readLines( "file", n = 1)
opens file "file", reads a line and then closes "file".  It has no idea
that you want to keep reading the same file.

> I'll take a look at the command file(), as someone else suggested.

It's open() you need, as in

con <- file("file")
open(con)
for(i in 1:10) print(readLines(con, n=1))
close(con)

In C you would need to (f)open a file to read it line-by-line, just as 
here.

The first two lines can be collapsed to

con <- file("file", "r")


> 
> Thanks.
> 
> >From: Duncan Murdoch <dmurdoch at pair.com>
> >To: "R A F" <raf1729 at hotmail.com>
> >CC: R-help at stat.math.ethz.ch
> >Subject: Re: [R] Scanning data files line-by-line
> >Date: Wed, 30 Apr 2003 08:26:26 -0400
> >
> >On Wed, 30 Apr 2003 11:51:00 +0000, you wrote:
> >
> > >Hi all, is there a way to read a data file into R line-by-line, akin
> > >to what fscanf does in C, say?
> > >
> > >It seems that "scan" and "read.table" both read the entire data file
> > >in at once, whereas "readLines" allows one to read a file partially,
> > >but doesn't quite read line-by-line either.
> >
> >That's what readLines(con, n=1) is supposed to do; in what way does it
> >not quite work?
> >
> >Duncan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dmurdoch at pair.com  Wed Apr 30 15:19:20 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 30 Apr 2003 09:19:20 -0400
Subject: [R] Scanning data files line-by-line
In-Reply-To: <Law11-F26qXItMcx4vv00017679@hotmail.com>
References: <Law11-F26qXItMcx4vv00017679@hotmail.com>
Message-ID: <k9jvavcjn05ooo68br61sk8i9dsj9moaas@4ax.com>

On Wed, 30 Apr 2003 12:45:33 +0000, RAF wrote:

>Maybe I'm missing something.  When I do readLines( "file", n = 1) and
>repeat, it always reads the first line of "file".  I've to be able to
>advance to the next line, no?
>
>I'll take a look at the command file(), as someone else suggested.

Yes, that's your solution.  

con <- file("foo") 

will open the file called foo and attach it to a connection called
con.  You pass con to readLines, and since the file stays open between
calls, you'll get successive lines.  Remember close(con) when you're
done.

Duncan Murdoch


From raf1729 at hotmail.com  Wed Apr 30 15:25:00 2003
From: raf1729 at hotmail.com (R A F)
Date: Wed, 30 Apr 2003 13:25:00 +0000
Subject: [R] Scanning data files line-by-line
Message-ID: <Law11-F40HDXE2sCRBH00017b8a@hotmail.com>

Thanks very much.  I guess the answer leads to more questions:

(a) What if I don't know the number of lines?  So I would like to use
    a while loop until readLines hits an EOF character.  Would that
    be possible?

(b) When readLines is used, a string is returned.  I'd like to split
    the string into fields, and Andy Liaw suggested strsplit, but the
    number of spaces between fields is variable.  So for example, one
    line could be 1 space 2 space space 3 and the next line could be
    4 space space 5 space 6, so I could not do a strsplit using " ".

    Really what I know is the variable type of each field -- for
    example, each line is double, string, then double, etc.  How
    would one use this information to split the string given by
    readLines?

Thanks very much again!

>From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>To: R A F <raf1729 at hotmail.com>
>CC: R-help at stat.math.ethz.ch
>Subject: Re: [R] Scanning data files line-by-line
>Date: Wed, 30 Apr 2003 14:13:26 +0100 (BST)
>
>It's open() you need, as in
>
>con <- file("file")
>open(con)
>for(i in 1:10) print(readLines(con, n=1))
>close(con)
>
>In C you would need to (f)open a file to read it line-by-line, just as
>here.
>
>The first two lines can be collapsed to
>
>con <- file("file", "r")


From ripley at stats.ox.ac.uk  Wed Apr 30 15:26:41 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 30 Apr 2003 14:26:41 +0100 (BST)
Subject: [R] Bug in arima?
In-Reply-To: <3EAFC614.5090900@nauticom.net>
Message-ID: <Pine.LNX.4.44.0304301418500.6018-100000@gannet.stats>

Here's a reproducible example (R 1.7.0)

set.seed(1)
x <- rnorm(100)
arima(x, order=c(7, 1, 0), fixed = c(NA, NA, NA, 0, 0, 0, NA),
      transform.pars = FALSE)

Coefficients:
          ar1      ar2      ar3  ar4  ar5  ar6     ar7
      -0.6838  -0.4126  -0.2236    0    0    0  0.0454
s.e.   0.0986   0.1115   0.0988    0    0    0  0.0843

and you did not set transform.pars.

Looks like the comment

   fixed: optional numeric vector of the same length as the total
          number of parameters.  If supplied, only non-`NA' entries in
          `fixed' will be varied.  `transform.pars = TRUE' will be
          overridden if any AR parameters are fixed.

has been copied from help(arima0) and is unimplemented in arima.


On Wed, 30 Apr 2003, Richard A. Bilonick wrote:

> I'm using the fixed argument in arima. Shouldn't ar4, ar5, and ar6 
> display as zero in the output?
> 
> Call:
> arima(x = window(log(hhprice), start = c(1990, 1), end = c(2003, 3)), 
> order = c(7,
>     1, 0), xreg = window(ts.union(exa1 = lag(exa, -1), exa12 = lag(exa,
>     -12), exb1 = lag(exb, -1), exc1 = lag(exc, -1), exc12 = lag(exc,
>     -12)), start = c(1990, 1), end = c(2003, 3)), include.mean = FALSE, 
> fixed = c(NA,
>     NA, NA, 0, 0, 0, NA, NA, NA, NA, NA, NA))
> 
> Coefficients:
>          ar1      ar2      ar3      ar4      ar5   ar6      ar7      
> exa1      exa12      exb1      exc1      exc12
>       0.0922  -0.1279  -0.2661  -0.0577  -0.0277  0.02  -0.2167   
> -0.3015     0.3424    0.0281    0.0519     0.1715
> s.e.  0.0789   0.0801   0.0742   0.0000   0.0000  0.00   0.0853    
> 0.0503     0.0515    0.0295    0.0257     0.0329
> 
> Also, is the documentation wrong?
> 
>  From ?arima:
> 
> fixed: optional numeric vector of the same length as the total
>           number of parameters.  If supplied, only non-`NA' entries in
>           `fixed' will be varied.  `transform.pars = TRUE' will be
>           overridden if any AR parameters are fixed.
> 
> The non-NA entries in my fixed argument are zeroes. Aren't these "fixed" 
> to zero so they don't vary when a call is made to optim? I thought that 
> was the purpose of the argument. I only wan ar1, ar2, ar3, and ar7 in 
> the model so I'm setting ar4, ar5, and ar6 to zero.
> 
> My main concern is that the predict.Arima function works correctly when 
> using the fixed argument. I'm assuming, output display notwithstanding, 
> that ar4-ar6 are actually fixed to zero when using fixed. When I try to 
> manually make the forecast, the result is slightly different than what 
> predict.Arima reports. I'm wondering if that is due to these 
> coefficients not being set to zero?
> 
> Rick B.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Wed Apr 30 15:31:08 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 30 Apr 2003 14:31:08 +0100 (BST)
Subject: [R] Scanning data files line-by-line
In-Reply-To: <Law11-F40HDXE2sCRBH00017b8a@hotmail.com>
Message-ID: <Pine.LNX.4.44.0304301426490.6018-100000@gannet.stats>

On Wed, 30 Apr 2003, R A F wrote:

> Thanks very much.  I guess the answer leads to more questions:
> 
> (a) What if I don't know the number of lines?  So I would like to use
>     a while loop until readLines hits an EOF character.  Would that
>     be possible?

Yes. After you reach the end of the file you will get character(0) since

Value:

     A character vector of length the number of lines read.

and zero lines would have been read.

> (b) When readLines is used, a string is returned.  

Not quite: a character vector is returned.

> I'd like to split
>     the string into fields, and Andy Liaw suggested strsplit, but the
>     number of spaces between fields is variable.  So for example, one
>     line could be 1 space 2 space space 3 and the next line could be
>     4 space space 5 space 6, so I could not do a strsplit using " ".
> 
>     Really what I know is the variable type of each field -- for
>     example, each line is double, string, then double, etc.  How
>     would one use this information to split the string given by
>     readLines?

You could use scan on the line: it works on textConnections.

> Thanks very much again!
> 
> >From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> >To: R A F <raf1729 at hotmail.com>
> >CC: R-help at stat.math.ethz.ch
> >Subject: Re: [R] Scanning data files line-by-line
> >Date: Wed, 30 Apr 2003 14:13:26 +0100 (BST)
> >
> >It's open() you need, as in
> >
> >con <- file("file")
> >open(con)
> >for(i in 1:10) print(readLines(con, n=1))
> >close(con)
> >
> >In C you would need to (f)open a file to read it line-by-line, just as
> >here.
> >
> >The first two lines can be collapsed to
> >
> >con <- file("file", "r")
> 
> 
> _________________________________________________________________

> http://join.msn.com/?page=features/junkmail
> 
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From solares at unsl.edu.ar  Wed Apr 30 15:36:48 2003
From: solares at unsl.edu.ar (solares@unsl.edu.ar)
Date: Wed, 30 Apr 2003 10:36:48 -0300 (ART)
Subject: [R] skins
Message-ID: <48766.170.210.173.216.1051709808.squirrel@inter14.unsl.edu.ar>

Hello, 
I wrote a for if exist a tcltk package .... essentially I wanted 
to give a widget with corner rounded , tkbutton , tkframe, radiobuttons, etc
and skins for toplevels.
Any help will be greatly appreciated.... thanks

Ruben Solares


From HStevens at muohio.edu  Wed Apr 30 15:38:35 2003
From: HStevens at muohio.edu (Hank Stevens)
Date: Wed, 30 Apr 2003 09:38:35 -0400
Subject: [R] Pinheiro and Bates fig. 412
Message-ID: <5.1.0.14.2.20030430093411.0173fdf8@po.muohio.edu>


I would love to make a response vs. covariate figure analogous to Pinheiro 
and Bates (2000) Fig. 4.12 of lme model predicted values augmented with 
data, but instead of plotting these by specified random groups, I would 
like to plot them by fixed factors.
Any ideas?

Many thanks,
Hank Stevens

Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology


From brahm at alum.mit.edu  Wed Apr 30 15:54:28 2003
From: brahm at alum.mit.edu (David Brahm)
Date: Wed, 30 Apr 2003 09:54:28 -0400
Subject: [R] Specifying search position for attached package
References: <99A12772DCDEEB458B996332957B0D530117BE@mercury.cantatapharm.com>
Message-ID: <16047.54676.224620.589988@arbres1a.fmr.com>

Jim Rogers <jrogers at cantatapharm.com> wrote:
> When I load an add-on package, is there any way to specify where it ends
> up in the search path (as with the pos argument to attach())? From the
> documentation for library(), this doesn't seem like an option. 

I wrote a local version of library (g.library) which has an additional "pos=2"
argument.  It's an exact copy of library except for the one line:
   env <- attach(NULL, name = pkgname)
which becomes:
   env <- attach(NULL, pos, name=pkgname)

There may be subtle reasons why this could fail (and why it's not part of the
standard library function), but it's always worked just fine for me (in version
1.6.2 on Solaris 2.6; I haven't upgraded to 1.7.0 yet).

I also wrote a g.sync function that allows me to detach and re-attach (in the
same position) a package that has been modified and rebuilt.  It boils down to:
  g.sync <- function(pos=2) {
    pkg <- sub("package:", "", search()[pos])
    detach(pos=pos)
    g.library(pkg, char=TRUE, pos=pos)
  }
-- 
                              -- David Brahm (brahm at alum.mit.edu)


From wegmann at biozentrum.uni-wuerzburg.de  Wed Apr 30 15:55:21 2003
From: wegmann at biozentrum.uni-wuerzburg.de (Martin Wegmann)
Date: Wed, 30 Apr 2003 15:55:21 +0200
Subject: [R] acf() with two df?
Message-ID: <3EAFD5C9.D74C8307@biozentrum.uni-wuerzburg.de>

Hello,

I have two dataframes, one with a time series of variables and another
one with biological data of each plot. the column names correspond to
each other


        plot1 plot 2.......
1983  ...     ....
1984  ...     ....
...

and

        plot 1 plot2
  1      ...         ...
  2

is it somehow possible to use acf() with two data frames and get a p
values for the whole correaltion of these two frames? AND to have the
lag function with p values? otherwise I think that cor() could do the
job but this one hasn't implemented the lag function.

an idea? thanks Martin




--
Martin Wegmann
Department of Animal Ecology and Tropical Biology
Zoology III, Biocenter
Am Hubland
97074 W?rzburg
Germany
0931/888-4378
wegmann at biozentrum.uni-wuerzburg.de
m.wegmann at web.de


From spencer.graves at pdf.com  Wed Apr 30 16:20:48 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 30 Apr 2003 07:20:48 -0700
Subject: [R] acf() with two df?
References: <3EAFD5C9.D74C8307@biozentrum.uni-wuerzburg.de>
Message-ID: <3EAFDBC0.3020307@pdf.com>

Have you considered merge or cbind to create one data.frame from the two?

hth.  spencer graves

Martin Wegmann wrote:
> Hello,
> 
> I have two dataframes, one with a time series of variables and another
> one with biological data of each plot. the column names correspond to
> each other
> 
> 
>         plot1 plot 2.......
> 1983  ...     ....
> 1984  ...     ....
> ...
> 
> and
> 
>         plot 1 plot2
>   1      ...         ...
>   2
> 
> is it somehow possible to use acf() with two data frames and get a p
> values for the whole correaltion of these two frames? AND to have the
> lag function with p values? otherwise I think that cor() could do the
> job but this one hasn't implemented the lag function.
> 
> an idea? thanks Martin
> 
> 
> 
> 
> --
> Martin Wegmann
> Department of Animal Ecology and Tropical Biology
> Zoology III, Biocenter
> Am Hubland
> 97074 W?rzburg
> Germany
> 0931/888-4378
> wegmann at biozentrum.uni-wuerzburg.de
> m.wegmann at web.de
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From spencer.graves at pdf.com  Wed Apr 30 16:28:03 2003
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 30 Apr 2003 07:28:03 -0700
Subject: [R] Scanning data files line-by-line
References: <Pine.LNX.4.44.0304301426490.6018-100000@gannet.stats>
Message-ID: <3EAFDD73.50401@pdf.com>

With a "connection" instead of a "file", there is no counterpart to 
"count.fields" to summarize what's available?

Thanks,
Spencer Graves

Prof Brian Ripley wrote:
> On Wed, 30 Apr 2003, R A F wrote:
> 
> 
>>Thanks very much.  I guess the answer leads to more questions:
>>
>>(a) What if I don't know the number of lines?  So I would like to use
>>    a while loop until readLines hits an EOF character.  Would that
>>    be possible?
> 
> 
> Yes. After you reach the end of the file you will get character(0) since
> 
> Value:
> 
>      A character vector of length the number of lines read.
> 
> and zero lines would have been read.
> 
> 
>>(b) When readLines is used, a string is returned.  
> 
> 
> Not quite: a character vector is returned.
> 
> 
>>I'd like to split
>>    the string into fields, and Andy Liaw suggested strsplit, but the
>>    number of spaces between fields is variable.  So for example, one
>>    line could be 1 space 2 space space 3 and the next line could be
>>    4 space space 5 space 6, so I could not do a strsplit using " ".
>>
>>    Really what I know is the variable type of each field -- for
>>    example, each line is double, string, then double, etc.  How
>>    would one use this information to split the string given by
>>    readLines?
> 
> 
> You could use scan on the line: it works on textConnections.
> 
> 
>>Thanks very much again!
>>
>>
>>>From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>>>To: R A F <raf1729 at hotmail.com>
>>>CC: R-help at stat.math.ethz.ch
>>>Subject: Re: [R] Scanning data files line-by-line
>>>Date: Wed, 30 Apr 2003 14:13:26 +0100 (BST)
>>>
>>>It's open() you need, as in
>>>
>>>con <- file("file")
>>>open(con)
>>>for(i in 1:10) print(readLines(con, n=1))
>>>close(con)
>>>
>>>In C you would need to (f)open a file to read it line-by-line, just as
>>>here.
>>>
>>>The first two lines can be collapsed to
>>>
>>>con <- file("file", "r")
>>
>>
>>_________________________________________________________________
> 
> 
>>http://join.msn.com/?page=features/junkmail
>>
>>
> 
>


From dmurdoch at pair.com  Wed Apr 30 16:55:33 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 30 Apr 2003 10:55:33 -0400
Subject: [R] Scanning data files line-by-line
In-Reply-To: <k9jvavcjn05ooo68br61sk8i9dsj9moaas@4ax.com>
References: <Law11-F26qXItMcx4vv00017679@hotmail.com>
	<k9jvavcjn05ooo68br61sk8i9dsj9moaas@4ax.com>
Message-ID: <irovavs9811ur8ofmqisiulaob7g4idduf@4ax.com>

On Wed, 30 Apr 2003 09:19:20 -0400, I wrote:

>con <- file("foo") 
>
>will open the file called foo and attach it to a connection called
>con.

Whoops, believe Brian, not me.  You need 

 con <- file("file", "r")

Duncan Murdoch


From dmurdoch at pair.com  Wed Apr 30 16:58:05 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 30 Apr 2003 10:58:05 -0400
Subject: [R] Scanning data files line-by-line
In-Reply-To: <3EAFDD73.50401@pdf.com>
References: <Pine.LNX.4.44.0304301426490.6018-100000@gannet.stats>
	<3EAFDD73.50401@pdf.com>
Message-ID: <32pvav0rb8ksg6ubtits3jrridhvsu0bbf@4ax.com>

On Wed, 30 Apr 2003 07:28:03 -0700, Spencer Graves
<spencer.graves at pdf.com> wrote:

>With a "connection" instead of a "file", there is no counterpart to 
>"count.fields" to summarize what's available?

The help for count.fields says a connection can be used...

Duncan Murdoch


From reynies at genoscope.cns.fr  Wed Apr 30 17:03:16 2003
From: reynies at genoscope.cns.fr (Aurelien de Reynies)
Date: Wed, 30 Apr 2003 17:03:16 +0200
Subject: [R] How to put 2 or more graphics in the same page ?
Message-ID: <3EAFE5B4.549DFB7B@genoscope.cns.fr>

Hi,

I have a naive question...

I have produced about 60 graphics and want to put them in one postscipt
file ,  possibly 4 graphics on each page. I can put all of them in the
same file (that's ok), but I can't find the way  to put 2 or more
(precisely 4, in my case) graphics on the same page (each graphics is
about 6 inches (width) X 4 inches (height)).

Any help would be very much appreciated...

Aur?lien


From luke at inpharmatica.co.uk  Wed Apr 30 17:21:03 2003
From: luke at inpharmatica.co.uk (Luke Whitaker)
Date: Wed, 30 Apr 2003 16:21:03 +0100 (BST)
Subject: [R] About qvalue
In-Reply-To: <1051256904.3ea8e8489be59@homae.univ-ubs.fr>
Message-ID: <Pine.LNX.4.21.0304301605170.22965-100000@dollis-hill.inpharmatica.co.uk>

On Fri, 25 Apr 2003 sandrine.mainard1 at etud.univ-ubs.fr wrote:

> Hello, 
> 
> I'm apologize to have made failure before. 
> I wrote this : p<-scan("teststat.txt") on R and R returns Error in scan 
> ("teststat.txt") : "scan" expected a real, got "x". I don't really 
> understand,because teststat has been created, so........ 
> 
> Thanks a lot. 
> 
> Sandrine 

It seems that you have character data in your file. By default, scan()
expects to read numerical values.

If you want scan() to read character values, then you can do:
p <- scan(what="")

To read multiple variables, the "what" argument can be a list, and scan
expects the variables to be the same type as those in the list
    e.g. p <- scan(what=list(a="", b=0))
to read a character variable (which will be called "a") and a numeric
variable (which will be called "b"). The second variable will be floating
point, not integer, by the way.

It may be easier to use the "read.table" function instead of scan.

Do you know how to access the help system and the documentation
in R ?  At the R prompt type e.g. "help(scan)" or "?scan" to get
the help page. Look at the examples if there are any.  Also, with
your R distribution, you should have a set of html and pdf format
documentation which is worth looking at.

Hope this helps,

Luke


From raf1729 at hotmail.com  Wed Apr 30 17:21:23 2003
From: raf1729 at hotmail.com (R A F)
Date: Wed, 30 Apr 2003 15:21:23 +0000
Subject: [R] Scanning data files line-by-line
Message-ID: <F71v4gBlkViyp4Z9hPY00012d5f@hotmail.com>

Hi all, thanks to everyone again for helping out.  I don't want to
generate too many messages, but this problem seems common enough that
maybe it's worth a summary.

What I can do is this.  Let's say "file" has lines of double, string,
double with variable number of spaces between fields followed by EOF.

aaa <- file( "file", "r" )

while( length( ( x <- scan( aaa, nlines = 1, list( 0, "", 0 ) ) )[[1]] )
 > 0 )
{
   check to see if x is empty again (by length( x[[1]] ) > 0 ) since
   we would read in the EOF character into x still

   if not empty
      start processing
}

close( aaa )

Here x is a list and x[[1]] is the first field, etc.

Professor Ripley also suggested textConnections, but I didn't
experiment -- I'm usually happy to find something that works.  :-)

Thanks again.

>From: Spencer Graves <spencer.graves at pdf.com>
>To: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>CC: R-help at stat.math.ethz.ch, R A F <raf1729 at hotmail.com>
>Subject: Re: [R] Scanning data files line-by-line
>Date: Wed, 30 Apr 2003 07:28:03 -0700
>
>With a "connection" instead of a "file", there is no counterpart to 
>"count.fields" to summarize what's available?
>
>Thanks,
>Spencer Graves
>
>Prof Brian Ripley wrote:
>>On Wed, 30 Apr 2003, R A F wrote:
>>
>>
>>>Thanks very much.  I guess the answer leads to more questions:
>>>
>>>(a) What if I don't know the number of lines?  So I would like to use
>>>    a while loop until readLines hits an EOF character.  Would that
>>>    be possible?
>>
>>
>>Yes. After you reach the end of the file you will get character(0) since
>>
>>Value:
>>
>>      A character vector of length the number of lines read.
>>
>>and zero lines would have been read.
>>
>>
>>>(b) When readLines is used, a string is returned.
>>
>>
>>Not quite: a character vector is returned.
>>
>>
>>>I'd like to split
>>>    the string into fields, and Andy Liaw suggested strsplit, but the
>>>    number of spaces between fields is variable.  So for example, one
>>>    line could be 1 space 2 space space 3 and the next line could be
>>>    4 space space 5 space 6, so I could not do a strsplit using " ".
>>>
>>>    Really what I know is the variable type of each field -- for
>>>    example, each line is double, string, then double, etc.  How
>>>    would one use this information to split the string given by
>>>    readLines?
>>
>>
>>You could use scan on the line: it works on textConnections.
>>
>>
>>>Thanks very much again!


From sebastian-huber at web.de  Wed Apr 30 17:28:42 2003
From: sebastian-huber at web.de (Sebastian Huber)
Date: Wed, 30 Apr 2003 17:28:42 +0200
Subject: [R] Interactive Input Problem
In-Reply-To: <Pine.LNX.4.44.0304301401270.6018-100000@gannet.stats>
References: <Pine.LNX.4.44.0304301401270.6018-100000@gannet.stats>
Message-ID: <200304301644.07477.sebastian-huber@web.de>

Hello,
thanks for the kind help.

On Wednesday 30 April 2003 15:07, you wrote:
> On Wed, 30 Apr 2003, Martin Wegmann wrote:
> > that looks more like a problem with your shell. which one are you using?
> > perhaps it it solved by using another one e.g. bash.  otherwise you can
> > find at the end of the *.pdf "R-intro"
> > http://cran.r-project.org/doc/manuals/R-intro.pdf  a chapter called: the
> > command line editor perhaps that helps.

I looked only into the FAQs, but without success.

> Sorry, no, no shell is involved.  This is what happens in Unix R if the
> readline library is not compiled in/activated (you can start R with
> --no-readline).
>
> Since you said you built `R-base-1.7.0' (not sure what that is: an SRPM?)

It is R-1.7.0.tar.gz in combination with R-base-1.7.0.spec, works really good.

> my guess is that you don't have the readline development tools on your
> system.  Take a look at the configure output, and see what it said about
> readline. You may need to install libreadline-devel or something like
> that.

I guess that's it:

checking for pwd.h... yes
checking readline/history.h usability... no
checking readline/history.h presence... no
checking for readline/history.h... no
checking readline/readline.h usability... no
checking readline/readline.h presence... no
checking for readline/readline.h... no
checking for strings.h... (cached) yes

I wasn't aware that readline-devel exists.

Thanks
	Sebastian


From rolf at math.unb.ca  Wed Apr 30 17:37:10 2003
From: rolf at math.unb.ca (Rolf Turner)
Date: Wed, 30 Apr 2003 12:37:10 -0300 (ADT)
Subject: [R] Bug in arima?
Message-ID: <200304301537.h3UFbAFh020954@erdos.math.unb.ca>


Is it just me being lysdexic or is the help file saying things
backwards???

Brian Ripley wrote:

> Here's a reproducible example (R 1.7.0)
> 
> set.seed(1)
> x <- rnorm(100)
> arima(x, order=c(7, 1, 0), fixed = c(NA, NA, NA, 0, 0, 0, NA),
>       transform.pars = FALSE)
> 
> Coefficients:
>           ar1      ar2      ar3  ar4  ar5  ar6     ar7
>       -0.6838  -0.4126  -0.2236    0    0    0  0.0454
> s.e.   0.0986   0.1115   0.0988    0    0    0  0.0843
> 
> and you did not set transform.pars.
> 
> Looks like the comment
> 
>    fixed: optional numeric vector of the same length as the total
>           number of parameters.  If supplied, only non-`NA' entries in
>           `fixed' will be varied.  `transform.pars = TRUE' will be
>           overridden if any AR parameters are fixed.
> 
> has been copied from help(arima0) and is unimplemented in arima.

Is it not the case that the parameters corresponding to ***NA***
entries in ``fixed'' are being ``varied'' (estimated) and those
corresponding to ***non-NA*** values are indeed fixed --- at the
given non-NA value?


				cheers,

					Rolf Turner
					rolf at math.unb.ca


From ripley at stats.ox.ac.uk  Wed Apr 30 18:06:40 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 30 Apr 2003 17:06:40 +0100 (BST)
Subject: [R] Bug in arima?
In-Reply-To: <200304301537.h3UFbAFh020954@erdos.math.unb.ca>
Message-ID: <Pine.LNX.4.44.0304301705520.6449-100000@gannet.stats>

It is backwards, but that doesn't seem to have caused the problem here.

On Wed, 30 Apr 2003, Rolf Turner wrote:

> 
> Is it just me being lysdexic or is the help file saying things
> backwards???
> 
> Brian Ripley wrote:
> 
> > Here's a reproducible example (R 1.7.0)
> > 
> > set.seed(1)
> > x <- rnorm(100)
> > arima(x, order=c(7, 1, 0), fixed = c(NA, NA, NA, 0, 0, 0, NA),
> >       transform.pars = FALSE)
> > 
> > Coefficients:
> >           ar1      ar2      ar3  ar4  ar5  ar6     ar7
> >       -0.6838  -0.4126  -0.2236    0    0    0  0.0454
> > s.e.   0.0986   0.1115   0.0988    0    0    0  0.0843
> > 
> > and you did not set transform.pars.
> > 
> > Looks like the comment
> > 
> >    fixed: optional numeric vector of the same length as the total
> >           number of parameters.  If supplied, only non-`NA' entries in
> >           `fixed' will be varied.  `transform.pars = TRUE' will be
> >           overridden if any AR parameters are fixed.
> > 
> > has been copied from help(arima0) and is unimplemented in arima.
> 
> Is it not the case that the parameters corresponding to ***NA***
> entries in ``fixed'' are being ``varied'' (estimated) and those
> corresponding to ***non-NA*** values are indeed fixed --- at the
> given non-NA value?
> 
> 
> 				cheers,
> 
> 					Rolf Turner
> 					rolf at math.unb.ca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From luke at inpharmatica.co.uk  Wed Apr 30 18:29:36 2003
From: luke at inpharmatica.co.uk (Luke Whitaker)
Date: Wed, 30 Apr 2003 17:29:36 +0100 (BST)
Subject: [R-gui] Re: [R] Feedback about SciViews?
In-Reply-To: <C9DFD144-7A46-11D7-9CA5-000393BDE1EC@hsph.harvard.edu>
Message-ID: <Pine.LNX.4.21.0304301716310.22965-100000@dollis-hill.inpharmatica.co.uk>

On Tue, 29 Apr 2003, Byron Ellis wrote:

> On Tuesday, April 29, 2003, at 07:13  AM, Duncan Murdoch wrote:

> > I think the best long term strategy is to have a clean division
> > between the user interface aspects of R (which are necessarily
> > platform dependent) and the underlying computing engine (which should
> 
> Precisely. I would actually say that R is -not- platform independent in 
> that it expects a certain type of GUI--- a shell process living on 
> STDIN and STDOUT that talks to an out-of-process Window Server of some 
> sort. Most of the work done in the Windows GUI is spent faking that 
> environment to make R think its still running on a X Server somewhere 
> and similar work was done for the Mac/Carbon port (obviously, Darwin R 
> can happily use Apple's X server). REventLoop takes some steps as does 
> the work on embedding, but its still safer to run the "GUI" stuff 
> out-of-process and even then not foolproof.

At the risk of starting a religous war, isn't java the obvious choice
for a platform independent GUI ? I know java suffered a lot from 
early over hypeing when it wasn't really ready, but in the last year
or two I've seen some very impressive platform independent GUI's
built with java.

just my tuppence worth...

Luke


From lamkelj at yahoo.com  Wed Apr 30 18:37:13 2003
From: lamkelj at yahoo.com (Kel)
Date: Wed, 30 Apr 2003 09:37:13 -0700 (PDT)
Subject: [R] Holt Winters Error
In-Reply-To: <Pine.LNX.4.44.0304300815320.26176-100000@gannet.stats>
Message-ID: <20030430163713.29062.qmail@web12505.mail.yahoo.com>

Here's the time series (Jan 1994 - Dec 1998)

> test5

Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep  
Oct   Nov   Dec
1994  16.0  17.4  19.2  21.4  24.0  27.0  29.0  29.4 
29.4  29.0  28.2  27.0
1995  28.0  31.8  36.0  40.6  45.6  51.0  53.0  51.0 
48.6  45.8  42.6  39.0
1996  40.0  46.2  52.8  59.8  67.2  75.0  77.0  72.6 
67.8  62.6  57.0  51.0
1997  52.0  60.6  69.6  79.0  88.8  99.0 101.0  94.2 
87.0  79.4  71.4  63.0
1998  64.0  75.0  86.4  98.2 110.4 123.0 125.0 115.8
106.2  96.2  85.8  75.0

> HoltWinters(test5,seasonal="mult")

Here's the message I get:

Error in optim(c(0.3, 0.1, 0.1), error, method =
"L-BFGS-B", lower = c(0,  : 
L-BFGS-B needs finite values of fn"

Thanks again.





--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> That's not an error, but a line of R code.
> 
> If you could post an example which generates the
> error and the actual 
> error message, we could try to investigate it.
> 
> On Tue, 29 Apr 2003, Kel wrote:
> 
> > I have come across with the following error while
> > running HoltWinters().
> > 
> > optim(c(0.3, 0.1, 0.1), error, method =
> "L-BFGS-B", 
> > lower = c(0, 0, 0), upper = c(1, 1, 1))
> > 
> > It only happens to multiplicative seasonality but
> not
> > additive.  I read the program but still couldn't
> > understand it.  
> 
> -- 
> Brian D. Ripley,                 
> ripley at stats.ox.ac.uk
> Professor of Applied Statistics, 
> http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865
> 272861 (self)
> 1 South Parks Road,                     +44 1865
> 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865
> 272595
>


From luke at inpharmatica.co.uk  Wed Apr 30 18:38:34 2003
From: luke at inpharmatica.co.uk (Luke Whitaker)
Date: Wed, 30 Apr 2003 17:38:34 +0100 (BST)
Subject: [R] how to present a table in powerpoint?
Message-ID: <Pine.LNX.4.21.0304301736100.22965-100000@dollis-hill.inpharmatica.co.uk>

On Tue, 29 Apr 2003, Thomas W Blackwell wrote:

> I'm surprised that no one has yet mentioned "Sweave".
> I've never used it, but it seems to solve exactly the
> general problem of R-to-postscript formatting that
> Jonathan Li sees a use for.  However, it works via
> TeX/LaTeX rather than by commercial software.
> 
> http://www.ci.tuwien.ac.at/~leisch/Sweave/Sweave-manual-20021007.pdf
> 
> -  tom blackwell  -  u michigan medical school  -  ann arbor  -

The URL has changed - it's now

 http://www.ci.tuwien.ac.at/~leisch/Sweave/Sweave-manual-20030423.pdf

Luke


From B.Rowlingson at lancaster.ac.uk  Wed Apr 30 18:44:13 2003
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 30 Apr 2003 17:44:13 +0100
Subject: [R-gui] Re: [R] Feedback about SciViews?
In-Reply-To: <Pine.LNX.4.21.0304301716310.22965-100000@dollis-hill.inpharmatica.co.uk>
References: <Pine.LNX.4.21.0304301716310.22965-100000@dollis-hill.inpharmatica.co.uk>
Message-ID: <3EAFFD5D.8010109@lancaster.ac.uk>

Luke Whitaker wrote:

> At the risk of starting a religous war, isn't java the obvious choice
> for a platform independent GUI ? I know java suffered a lot from 
> early over hypeing when it wasn't really ready, but in the last year
> or two I've seen some very impressive platform independent GUI's
> built with java.

  As long as it doesn't end up like Matlab's java gui. Last summer 
vacation our systems guys upgraded matlab to the latest version with the 
new gui. On the first day of term in September, 25 students sat down to 
a lab session, typed 'matlab' and the very hefty Sun machine to which 
they (and many other people round campus) were connected fell rapidly to 
its knees.

  I suggested to the systems guys that they hard-code the '-nojvm' 
option into the startup script, the other option being to tattoo the 
same option onto every matlab user's knuckles. I think they liked the 
latter, and offered to provide rusty needles.

  Yes, java GUIs are a great idea with the platform independence and the 
swing toolkit configurability (it looks like Windows! no, its Motif! no 
its CDE! a new skin every day) but on a multi-user machine its very easy 
to kill it.

  There are other cross-platform UI toolkits around that dont use Java. 
FLTK springs to mind: http://www.fltk.org/

> just my tuppence worth...

  I've probably thrown in halfpence.

Baz


From xiaoleili at wisc.edu  Wed Apr 30 18:46:30 2003
From: xiaoleili at wisc.edu (Xiaolei Li)
Date: Wed, 30 Apr 2003 11:46:30 -0500
Subject: [R] Help on Regress GMM
Message-ID: <000801c30f38$0ceb7a90$1fc65c90@Lei>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030430/8b254158/attachment.pl

From dmurdoch at pair.com  Wed Apr 30 18:53:12 2003
From: dmurdoch at pair.com (Duncan Murdoch)
Date: Wed, 30 Apr 2003 12:53:12 -0400
Subject: [R-gui] Re: [R] Feedback about SciViews?
In-Reply-To: <Pine.LNX.4.21.0304301716310.22965-100000@dollis-hill.inpharmatica.co.uk>
References: <C9DFD144-7A46-11D7-9CA5-000393BDE1EC@hsph.harvard.edu>
	<Pine.LNX.4.21.0304301716310.22965-100000@dollis-hill.inpharmatica.co.uk>
Message-ID: <6mvvavk97rgg4e1fraiifnfqtelsmidb29@4ax.com>

On Wed, 30 Apr 2003 17:29:36 +0100 (BST), you wrote:


>At the risk of starting a religous war, isn't java the obvious choice
>for a platform independent GUI ? I know java suffered a lot from 
>early over hypeing when it wasn't really ready, but in the last year
>or two I've seen some very impressive platform independent GUI's
>built with java.

I think the issue is that it's hard now to write any GUI at all,
because too much UI is in R itself.  As we move towards a separation
of UI and computation, it may well make sense to write a GUI in Java.

Duncan Murdoch


From rossini at blindglobe.net  Wed Apr 30 18:50:06 2003
From: rossini at blindglobe.net (A.J. Rossini)
Date: Wed, 30 Apr 2003 09:50:06 -0700
Subject: [R-gui] Re: [R] Feedback about SciViews?
In-Reply-To: 
	<Pine.LNX.4.21.0304301716310.22965-100000@dollis-hill.inpharmatica.co.uk>
	(Luke Whitaker's message of "Wed, 30 Apr 2003 17:29:36 +0100 (BST)")
References: <Pine.LNX.4.21.0304301716310.22965-100000@dollis-hill.inpharmatica.co.uk>
Message-ID: <87k7dcorpd.fsf@jeeves.blindglobe.net>

Luke Whitaker <luke at inpharmatica.co.uk> writes:

> At the risk of starting a religous war, isn't java the obvious choice
> for a platform independent GUI ? I know java suffered a lot from 
> early over hypeing when it wasn't really ready, but in the last year
> or two I've seen some very impressive platform independent GUI's
> built with java.

Not for R.  One could argue for Python in the same light, as well. 

Or even Emacs :-) (yes, it can be done-up with GUI-like features).

best,
-tony

-- 
A.J. Rossini rossini at u.washington.edu http://software.biostat.washington.edu/ 
Biostatistics, U Washington and Fred Hutchinson Cancer Research Center

FHCRC:Tu: 206-667-7025 (fax=4812)|Voicemail is pretty sketchy/use Email 
UW  : Th: 206-543-1044 (fax=3286)|Change last 4 digits of phone to FAX 

CONFIDENTIALITY NOTICE: This e-mail message and any attachments ... {{dropped}}


From gina.joue at ucd.ie  Wed Apr 30 18:33:00 2003
From: gina.joue at ucd.ie (g)
Date: Wed, 30 Apr 2003 17:33:00 +0100
Subject: [R] sorting factors
Message-ID: <200304301733.00437.gina.joue@ucd.ie>

Hi,

I've been trying to sort the values of the factors of contingency tables 
generated with xtabs. For example, I have a factor called "artic" with three 
possible values that I would like to order in a specific way -- but I'm not 
sure how to go about this.

> test <- read.table("test.tab",header=TRUE,sep="\t")
> artic = factor(artic,levels=c("lowlip","dental","apex"))
> test.frame <- as.data.frame(test)
> test.xtabs <- xtabs(freq ~ artic + var, test.frame)
> mosaicplot(test.xtabs,shade=TRUE)

Any help appreciated,
Gina


From tpapp at axelero.hu  Wed Apr 30 19:11:01 2003
From: tpapp at axelero.hu (Tamas Papp)
Date: Wed, 30 Apr 2003 19:11:01 +0200
Subject: [R] Working comfortably with (X)Emacs + Sweave
Message-ID: <20030430171101.GA739@localhost>

Dear List,

I am trying to become more familiar with Sweave at the moment, beacuse
I am convinced that it will eventually make my life easier. However,
I have not found anything relevant in the mail archives about the
following problem.

Both the article in R-News and the Sweave FAQ suggest that Emacs would
be a great development environment for working with Sweave. So far, it
doesn't seem to fit that description... Maybe I'm doing something
wrong. I am going to describe the way I do things, and hope that
people on this list can suggest something more comfortable.

I edit the file in one buffer and keep one open for the R prompt.
Every time I need to recompile the whole document (Sweave to, say,
DVI) I go through the following:

1. call sweave manually via the R prompt
2. open the resulting LaTeX file (I have not found a way to refresh
this, maybe there's some magical XEmacs keystroke that rereads the
file from the disk?, so I keep opening/closing it)
3. compile the LaTeX file

This is a bit tedious as I like to compile often, because I like to
see the way my document looks (I know that TeX is WYSIWYM, but I
prefer to check my formulas instantly).

I would appreciate if people told me how they solve these problems or
have found any other way to make Xemacs more comfortable. A
"call sweave and then latex on this file in one go" and "show the DVI
that was produced from this Rnw file" command would be very
useful. Emacs init.el files and similar would help a lot, too.

Or maybe I am just trying to use things the wrong way, if so, please
enlighten me ;-) If this is not how people use Sweave+Emacs, then tell
me how I should do it.

Thanks in advance,

Tamas Papp

-- 
Tam?s K. Papp
E-mail: tpapp at axelero.hu (preferred, especially for large messages)
        tpapp at westel900.net
Please try to send only (latin-2) plain text, not HTML or other garbage.


From edd at debian.org  Wed Apr 30 19:41:18 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 30 Apr 2003 12:41:18 -0500
Subject: [R] Working comfortably with (X)Emacs + Sweave
In-Reply-To: <20030430171101.GA739@localhost>
References: <20030430171101.GA739@localhost>
Message-ID: <20030430174118.GA3908@sonny.eddelbuettel.com>

On Wed, Apr 30, 2003 at 07:11:01PM +0200, Tamas Papp wrote:
> I would appreciate if people told me how they solve these problems or
> have found any other way to make Xemacs more comfortable. A
> "call sweave and then latex on this file in one go" and "show the DVI
> that was produced from this Rnw file" command would be very
> useful. Emacs init.el files and similar would help a lot, too.

Excellent question. Below is my pedestrian answer. I edit in XEmacs,
and then call this shellscript. You could also bind it to what gets 
called from latex/auctex when you 'compile' the input file.

Dirk


#!/bin/bash -e

function errorexit () {
    echo "Error: $1"
    exit 1
}	

function filetest () {
    if [ ! -f $1 ]; then
       errorexit "File $1 not found"
    fi
    return 0
}
		       
	       
if [ "$#" -lt 1 ]; then
    errorexit "Need to specify argument file"
fi
			   
		   
BASENAME=$(basename $1 .Rnw)
			   
RNWFILE=$BASENAME.Rnw
filetest $RNWFILE
echo "library(tools); Sweave(\"$RNWFILE\")" \
      | Rterm --no-save --no-restore --slave
			       
LATEXFILE=$BASENAME.tex
filetest $LATEXFILE && pdflatex $LATEXFILE
			       
PDFFILE=$BASENAME.pdf
filetest $PDFFILE && acroread 


-- 
Don't drink and derive. Alcohol and algebra don't mix.


From ripley at stats.ox.ac.uk  Wed Apr 30 19:50:39 2003
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 30 Apr 2003 18:50:39 +0100 (BST)
Subject: [R] Holt Winters Error
In-Reply-To: <20030430163713.29062.qmail@web12505.mail.yahoo.com>
Message-ID: <Pine.LNX.4.44.0304301840350.6742-100000@gannet.stats>

That's a very short series to expect to fit a seasonal HW model to whilst
choosing the degree of smoothing. and the optimization code is failing,
because the initial guesses are too far away.

The following should give you a clue:

HoltWinters(test5, seasonal = "additive") 

Smoothing parameters:
 alpha:  1 
 beta :  0.8108822 
 gamma:  1 

and using alpha=1 will work with the multiplicative model too.

You can edit the function and choose other starting values than c(0.3,
0.1, 0.1) and thereby get it to converge, but I would have little
confidence in the values found.

On Wed, 30 Apr 2003, Kel wrote:

> Here's the time series (Jan 1994 - Dec 1998)
> 
> > test5
> 
> Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep  
> Oct   Nov   Dec
> 1994  16.0  17.4  19.2  21.4  24.0  27.0  29.0  29.4 
> 29.4  29.0  28.2  27.0
> 1995  28.0  31.8  36.0  40.6  45.6  51.0  53.0  51.0 
> 48.6  45.8  42.6  39.0
> 1996  40.0  46.2  52.8  59.8  67.2  75.0  77.0  72.6 
> 67.8  62.6  57.0  51.0
> 1997  52.0  60.6  69.6  79.0  88.8  99.0 101.0  94.2 
> 87.0  79.4  71.4  63.0
> 1998  64.0  75.0  86.4  98.2 110.4 123.0 125.0 115.8
> 106.2  96.2  85.8  75.0
> 
> > HoltWinters(test5,seasonal="mult")
> 
> Here's the message I get:
> 
> Error in optim(c(0.3, 0.1, 0.1), error, method =
> "L-BFGS-B", lower = c(0,  : 
> L-BFGS-B needs finite values of fn"
> 
> Thanks again.
> 
> 
> 
> 
> 
> --- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> > That's not an error, but a line of R code.
> > 
> > If you could post an example which generates the
> > error and the actual 
> > error message, we could try to investigate it.
> > 
> > On Tue, 29 Apr 2003, Kel wrote:
> > 
> > > I have come across with the following error while
> > > running HoltWinters().
> > > 
> > > optim(c(0.3, 0.1, 0.1), error, method =
> > "L-BFGS-B", 
> > > lower = c(0, 0, 0), upper = c(1, 1, 1))
> > > 
> > > It only happens to multiplicative seasonality but
> > not
> > > additive.  I read the program but still couldn't
> > > understand it.  
> > 
> > -- 
> > Brian D. Ripley,                 
> > ripley at stats.ox.ac.uk
> > Professor of Applied Statistics, 
> > http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865
> > 272861 (self)
> > 1 South Parks Road,                     +44 1865
> > 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865
> > 272595
> > 
> 
> 
> __________________________________
> Do you Yahoo!?

> http://search.yahoo.com
> 

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From edd at debian.org  Wed Apr 30 20:01:54 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 30 Apr 2003 13:01:54 -0500
Subject: [R] Working comfortably with (X)Emacs + Sweave
In-Reply-To: <20030430174118.GA3908@sonny.eddelbuettel.com>
References: <20030430171101.GA739@localhost>
	<20030430174118.GA3908@sonny.eddelbuettel.com>
Message-ID: <20030430180154.GA4112@sonny.eddelbuettel.com>

On Wed, Apr 30, 2003 at 12:41:18PM -0500, Dirk Eddelbuettel wrote:
> On Wed, Apr 30, 2003 at 07:11:01PM +0200, Tamas Papp wrote:
> > I would appreciate if people told me how they solve these problems or
> > have found any other way to make Xemacs more comfortable. A
> > "call sweave and then latex on this file in one go" and "show the DVI
> > that was produced from this Rnw file" command would be very
> > useful. Emacs init.el files and similar would help a lot, too.
> 
> Excellent question. Below is my pedestrian answer. I edit in XEmacs,
> and then call this shellscript. You could also bind it to what gets 
> called from latex/auctex when you 'compile' the input file.
> 
> Dirk
> 
> 
> #!/bin/bash -e
> 
> function errorexit () {
>     echo "Error: $1"
>     exit 1
> }	
> 
> function filetest () {
>     if [ ! -f $1 ]; then
>        errorexit "File $1 not found"
>     fi
>     return 0
> }
> 		       
> 	       
> if [ "$#" -lt 1 ]; then
>     errorexit "Need to specify argument file"
> fi
> 			   
> 		   
> BASENAME=$(basename $1 .Rnw)
> 			   
> RNWFILE=$BASENAME.Rnw
> filetest $RNWFILE
> echo "library(tools); Sweave(\"$RNWFILE\")" \
>       | Rterm --no-save --no-restore --slave
> 			       
> LATEXFILE=$BASENAME.tex
> filetest $LATEXFILE && pdflatex $LATEXFILE
> 			       
> PDFFILE=$BASENAME.pdf
> filetest $PDFFILE && acroread 

Sorry - the last line lacks "$PDFFILE &" missing, and I forgot to mention
that this is the Cygwin version of the script, where acroread is another
wrapper that calls the pdf viewer. A Unix version would use R instead of
Rterm.

Dirk


-- 
Don't drink and derive. Alcohol and algebra don't mix.


From deepayan at stat.wisc.edu  Wed Apr 30 20:05:23 2003
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Wed, 30 Apr 2003 13:05:23 -0500
Subject: [R] Working comfortably with (X)Emacs + Sweave
In-Reply-To: <20030430171101.GA739@localhost>
References: <20030430171101.GA739@localhost>
Message-ID: <200304301305.23177.deepayan@stat.wisc.edu>



Assuming that you work on GNU/Linux, here's my setup (mostly borrowed from 
Doug Bates):

My .emacs has (apart from the usual ESS and auc-tex stuff):


(defun Rnw-mode ()
  (require 'ess-noweb)
  (noweb-mode)
  (if (fboundp 'R-mode)
      (setq noweb-default-code-mode 'R-mode)))
(add-to-list 'auto-mode-alist '("\\.Rnw\\'" . Rnw-mode))
(add-to-list 'auto-mode-alist '("\\.Snw\\'" . Rnw-mode))
(setq reftex-file-extensions
      '(("Snw" "Rnw" "nw" "tex" ".tex" ".ltx") ("bib" ".bib")))
(setq TeX-file-extensions
      '("Snw" "Rnw" "nw" "tex" "sty" "cls" "ltx" "texi" "texinfo"))



I have the following script installed:

deepayan 12:59:03 $ cat /usr/local/bin/Sweave.sh
#!/bin/sh
echo "library(tools);Sweave('"$1"')" | /usr/bin/R --vanilla --silent




In the working directory, I have a Makefile similar to:

deepayan 13:01:15 $ cat Makefile

DEFAULT_PDF = filename
DEFAULT_PS = filename

all : $(DEFAULT_PDF:=.pdf) $(DEFAULT_PS:=.ps)

%.tex : %.Rnw
        Sweave.sh $<

%.pdf : %.tex
        texi2dvi --pdf $<

%.dvi : %.tex
        texi2dvi $<

%.ps : %.dvi
        dvips -o -q $<




With all this (customized according to your tastes), just edit the 
filename.Rnw file, and invoke make (I tend to keep a gv open in 'watch file' 
mode).

Hope that helps.

Deepayan

On Wednesday 30 April 2003 12:11 pm, Tamas Papp wrote:
> Dear List,
>
> I am trying to become more familiar with Sweave at the moment, beacuse
> I am convinced that it will eventually make my life easier. However,
> I have not found anything relevant in the mail archives about the
> following problem.
>
> Both the article in R-News and the Sweave FAQ suggest that Emacs would
> be a great development environment for working with Sweave. So far, it
> doesn't seem to fit that description... Maybe I'm doing something
> wrong. I am going to describe the way I do things, and hope that
> people on this list can suggest something more comfortable.
>
> I edit the file in one buffer and keep one open for the R prompt.
> Every time I need to recompile the whole document (Sweave to, say,
> DVI) I go through the following:
>
> 1. call sweave manually via the R prompt
> 2. open the resulting LaTeX file (I have not found a way to refresh
> this, maybe there's some magical XEmacs keystroke that rereads the
> file from the disk?, so I keep opening/closing it)
> 3. compile the LaTeX file
>
> This is a bit tedious as I like to compile often, because I like to
> see the way my document looks (I know that TeX is WYSIWYM, but I
> prefer to check my formulas instantly).
>
> I would appreciate if people told me how they solve these problems or
> have found any other way to make Xemacs more comfortable. A
> "call sweave and then latex on this file in one go" and "show the DVI
> that was produced from this Rnw file" command would be very
> useful. Emacs init.el files and similar would help a lot, too.
>
> Or maybe I am just trying to use things the wrong way, if so, please
> enlighten me ;-) If this is not how people use Sweave+Emacs, then tell
> me how I should do it.
>
> Thanks in advance,
>
> Tamas Papp


From raf1729 at hotmail.com  Wed Apr 30 20:06:56 2003
From: raf1729 at hotmail.com (R A F)
Date: Wed, 30 Apr 2003 18:06:56 +0000
Subject: [R] Scanning data files line-by-line
Message-ID: <Law11-F85PZGGxWalhX00017a85@hotmail.com>

I'm sorry to have to ask another question related to this.  What if
the lines have variable number of fields?

For example, all I know is that each line starts with double, string,
double, say, but some lines may have some more fields afterwards.  So
the data file may look like

1 A 2
3 B 4 5
6   DD 7
etc.

If I use scan with list( 0, "", 0 ), each line is treated as if it
has a multiple of 3 elements, but really, what I want is to discard
all fields after the third.

I tried the nmax = 3 option but that did not seem to work.  Maybe I'm
doing this wrong.

Thanks again!

>From: "R A F" <raf1729 at hotmail.com>
>To: spencer.graves at pdf.com, ripley at stats.ox.ac.uk
>CC: R-help at stat.math.ethz.ch
>Subject: Re: [R] Scanning data files line-by-line
>Date: Wed, 30 Apr 2003 15:21:23 +0000
>
>Hi all, thanks to everyone again for helping out.  I don't want to
>generate too many messages, but this problem seems common enough that
>maybe it's worth a summary.
>
>What I can do is this.  Let's say "file" has lines of double, string,
>double with variable number of spaces between fields followed by EOF.
>
>aaa <- file( "file", "r" )
>
>while( length( ( x <- scan( aaa, nlines = 1, list( 0, "", 0 ) ) )[[1]] )
> > 0 )
>{
>   check to see if x is empty again (by length( x[[1]] ) > 0 ) since
>   we would read in the EOF character into x still
>
>   if not empty
>      start processing
>}
>
>close( aaa )
>
>Here x is a list and x[[1]] is the first field, etc.
>
>Professor Ripley also suggested textConnections, but I didn't
>experiment -- I'm usually happy to find something that works.  :-)
>
>Thanks again.


From hastie at stanford.edu  Wed Apr 30 20:19:29 2003
From: hastie at stanford.edu (Trevor Hastie)
Date: Wed, 30 Apr 2003 11:19:29 -0700
Subject: [R] Least Angle Regression  packages for R
Message-ID: <00d601c30f45$0b30bf50$1b6640ab@stanford.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030430/9d9f297b/attachment.pl

From tobias_verbeke at skynet.be  Wed Apr 30 20:31:54 2003
From: tobias_verbeke at skynet.be (Tobias Verbeke)
Date: Wed, 30 Apr 2003 20:31:54 +0200
Subject: [R] How to put 2 or more graphics in the same page ?
Message-ID: <20030430203154.7e054e82.tobias_verbeke@skynet.be>

> I can't find the way  to put
> 2 or more(precisely 4, in my case) graphics on the same page (each
> graphics is about 6 inches (width) X 4 inches (height)).
 
I'm not sure this is about using R,
but you can use `psutils' and in
particular the `psnup'-command.

To make a new PS-file `quater.ps', putting
four pages from the file `semel.ps' on each
page, type

psnup -4 semel.ps quater.ps

It is possible to rescale page sizes, 
change orientation etc.
A nice tutorial is Chapter 21 from 
The Linux Cookbook. You can find it
in the `Guides'-section on www.tldp.org

Regards,

Tobias


From james.holtman at convergys.com  Wed Apr 30 20:45:08 2003
From: james.holtman at convergys.com (james.holtman@convergys.com)
Date: Wed, 30 Apr 2003 14:45:08 -0400
Subject: [R] textConnection taking a long time to open a big string
Message-ID: <OF0691E15A.3A7DBE33-ON85256D18.00660A73@convergys.com>

I was using 'textConnection' to read in a file with about 11,000 lines so I
could detect lines with incomplete data and delete them and then read them
in with 'scan'.  I am using 1.7.0 on Windows.  Here is the output from the
script and it was using 51 seconds just to do the textConnection.

Is there a limit on how large a text object can be to be used with
'textConnection'?

########   script output    ################
> x.1 <- scan("/mpstat.ssgdbsv4.030430.txt",what='',sep='\n')
Read 11299 items
> str(x.1)
 chr [1:11299] "8.3155  32   71   4 1907   122    0 1130  105  167  216
0  3686   32  13  37  18" ...
> unix.time(x.in <- textConnection(x.1))  # this takes a long time
[1] 51.96  0.01 53.20    NA    NA
> sum(nchar(x.1))  # total number of characters in the vector
[1] 944525
> unix.time(x.c <- count.fields(x.in))    # this goes pretty fast
[1] 0.14 0.00 0.14   NA   NA
> table(x.c)      # detect incomplete lines
x.c
    3     6    17
    1     1 11297
>
> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    1
minor    7.0
year     2003
month    04
day      16
language R
>

--
"NOTICE:  The information contained in this electronic mail tran... {{dropped}}


From gavin.simpson at ucl.ac.uk  Wed Apr 30 20:54:19 2003
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Wed, 30 Apr 2003 19:54:19 +0100
Subject: [R] How to put 2 or more graphics in the same page ?
In-Reply-To: <20030430203154.7e054e82.tobias_verbeke@skynet.be>
Message-ID: <002a01c30f49$e80ab170$4c202880@gsimpson>

see ?par and in particular the parameters mfrow and mfcol
see ?layout for more complex ways of splitting up a graphics device

Gavin

%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpson at ucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tobias Verbeke
Sent: 30 April 2003 19:32
To: r-help at stat.math.ethz.ch
Subject: Re: [R] How to put 2 or more graphics in the same page ?


> I can't find the way  to put
> 2 or more(precisely 4, in my case) graphics on the same page (each
> graphics is about 6 inches (width) X 4 inches (height)).
 
I'm not sure this is about using R,
but you can use `psutils' and in
particular the `psnup'-command.

To make a new PS-file `quater.ps', putting
four pages from the file `semel.ps' on each
page, type

psnup -4 semel.ps quater.ps

It is possible to rescale page sizes, 
change orientation etc.
A nice tutorial is Chapter 21 from 
The Linux Cookbook. You can find it
in the `Guides'-section on www.tldp.org

Regards,

Tobias

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://www.stat.math.ethz.ch/mailman/listinfo/r-help


From kwan022 at stat.auckland.ac.nz  Wed Apr 30 20:54:28 2003
From: kwan022 at stat.auckland.ac.nz (Ko-Kang Kevin Wang)
Date: Thu, 1 May 2003 06:54:28 +1200 (NZST)
Subject: [R] How to put 2 or more graphics in the same page ?
In-Reply-To: <3EAFE5B4.549DFB7B@genoscope.cns.fr>
Message-ID: <Pine.LNX.4.44.0305010654030.29278-100000@stat56.stat.auckland.ac.nz>

Take a look at ?par.  More precisely, par(mfrow = c(2, 2)) may be what you 
want.

On Wed, 30 Apr 2003, Aurelien de Reynies wrote:

> Date: Wed, 30 Apr 2003 17:03:16 +0200
> From: Aurelien de Reynies <reynies at genoscope.cns.fr>
> To: r-help at stat.math.ethz.ch
> Subject: [R] How to put 2 or more graphics in the same page ?
> 
> Hi,
> 
> I have a naive question...
> 
> I have produced about 60 graphics and want to put them in one postscipt
> file ,  possibly 4 graphics on each page. I can put all of them in the
> same file (that's ok), but I can't find the way  to put 2 or more
> (precisely 4, in my case) graphics on the same page (each graphics is
> about 6 inches (width) X 4 inches (height)).
> 
> Any help would be very much appreciated...
> 
> Aur?lien
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://www.stat.math.ethz.ch/mailman/listinfo/r-help
> 

-- 
Cheers,

Kevin

------------------------------------------------------------------------------
/* Time is the greatest teacher, unfortunately it kills its students */

--
Ko-Kang Kevin Wang
Master of Science (MSc) Student
SLC Tutor and Lab Demonstrator
Department of Statistics
University of Auckland
New Zealand
Homepage: http://www.stat.auckland.ac.nz/~kwan022
Ph: 373-7599
    x88475 (City)
    x88480 (Tamaki)


From partha_bagchi at hgsi.com  Wed Apr 30 20:50:29 2003
From: partha_bagchi at hgsi.com (partha_bagchi@hgsi.com)
Date: Wed, 30 Apr 2003 14:50:29 -0400
Subject: [R] How to put 2 or more graphics in the same page ?
Message-ID: <OFDB0DD6D4.68196D9A-ON85256D18.00674280-85256D18.00678049@hgsi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030430/58d7c418/attachment.pl

From kademan at phz.com  Wed Apr 30 21:10:52 2003
From: kademan at phz.com (Ed Kademan)
Date: 30 Apr 2003 15:10:52 -0400
Subject: [R] ylab in plot.POSIXct
Message-ID: <ulgptn3rebn.fsf@phz.com>

I am using R-1.7.0 and have some data which consist of one vector of
numbers and a second corresponding vector of dates belonging to the
POSIXct class.  I would like to plot the numbers against the dates.
What is the best way to do this?

It almost works to just call `plot.'  However if I do this while using
the `ylab' parameter I get a warning message:

  parameter "ylab" couldn't be set in high-level plot() function 

Here is a function that demonstrates the behavior.

  ylabProblem <- function() {
    x <- ISOdate(2003, 4, 1:10)           # POSIXct vector
    y <- rnorm(10)
    plot(x, y, ylab = 'I am y')
  }

It works to invoke the low-level plotting routines by hand as follows:

  ylabNoProblem <- function() {
    x <- ISOdate(2003, 4, 1:10)           # POSIXct vector
    y <- rnorm(10)
    plot.default(x, y, xaxt = 'n', xlab = '', ylab = 'I am y')
    axis.POSIXct(1, x)
  }

But I don't like calling methods explicitly like this.


From chrysopa at insecta.ufv.br  Wed Apr 30 20:41:21 2003
From: chrysopa at insecta.ufv.br (Ronaldo Reis Jr.)
Date: Wed, 30 Apr 2003 15:41:21 -0300
Subject: [R] 
	How to calculate the x to assymptotic value and curve inflection .
Message-ID: <200304301541.21103.chrysopa@insecta.ufv.br>

Hi,

I have this non-linear function:

y=115.251 - 118.69 * exp(-0.123517*x)

I try to discovery the x value for the assyntoptic value of y and the x value 
where the behavior of curve change, the inflection point.

How to make this? Is poss?ble to make this on R?

Thanks
Ronaldo
-- 
O Flamengo e o Bangu terminaram o jogo em 0 x 0. Quem fez o gol?
A Volkswagen
--
|   // | \\   [*****************************][*******************]
|| ( ?   ? )  [Ronaldo Reis J?nior          ][PentiumIII-600     ]
|      V      [UFV/DBA-Entomologia          ][HD: 30 + 10 Gb     ]
||  /     \   [36571-000 Vi?osa - MG        ][RAM: 128 Mb        ]
|  /(.''`.)\  [Fone: 31-3899-2532           ][Video: SiS620-8Mb  ]
||/(: :'  :)\ [chrysopa at insecta.ufv.br      ][Modem: Pctel-onboar]
|/ (`. `'` ) \[ICQ#: 5692561                ][Kernel: 2.4.18     ]
||  ( `-  )   [*****************************][*******************]
||| _/   \_Powered by GNU/Debian W/Sarge D+ || Lxuser#: 205366


From tblackw at umich.edu  Wed Apr 30 21:23:08 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 30 Apr 2003 15:23:08 -0400 (EDT)
Subject: [R] textConnection taking a long time to open a big string
In-Reply-To: <OF0691E15A.3A7DBE33-ON85256D18.00660A73@convergys.com>
Message-ID: <Pine.SOL.4.44.0304301510510.4936-100000@millipede.gpcc.itd.umich.edu>

Two alternate ways to the same result:

x.1 <- scan(file=, what=rep(list(0),17), fill=T, multi.line=F)
incomplete.lines <- seq(length(x.1[[17]]))[ is.na(x.1[[17]] ]

x.1 <- scan(file=, what='')
x.2 <- strsplit(x.1, "[\\t ]")
incomplete.lines <- seq(length(x.1))[ unlist(lapply(x.2, length)) < 17 ]

Please read the help for these functions.

HTH  -  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 30 Apr 2003 james.holtman at convergys.com wrote:

> I was using 'textConnection' to read in a file with about 11,000 lines so I
> could detect lines with incomplete data and delete them and then read them
> in with 'scan'.  I am using 1.7.0 on Windows.  Here is the output from the
> script and it was using 51 seconds just to do the textConnection.
>
> Is there a limit on how large a text object can be to be used with
> 'textConnection'?
>
> ########   script output    ################
> > x.1 <- scan("/mpstat.ssgdbsv4.030430.txt",what='',sep='\n')
> Read 11299 items
> > str(x.1)
>  chr [1:11299] "8.3155  32   71   4 1907   122    0 1130  105  167  216
> 0  3686   32  13  37  18" ...
> > unix.time(x.in <- textConnection(x.1))  # this takes a long time
> [1] 51.96  0.01 53.20    NA    NA
> > sum(nchar(x.1))  # total number of characters in the vector
> [1] 944525
> > unix.time(x.c <- count.fields(x.in))    # this goes pretty fast
> [1] 0.14 0.00 0.14   NA   NA
> > table(x.c)      # detect incomplete lines
> x.c
>     3     6    17
>     1     1 11297


From tblackw at umich.edu  Wed Apr 30 21:33:41 2003
From: tblackw at umich.edu (Thomas W Blackwell)
Date: Wed, 30 Apr 2003 15:33:41 -0400 (EDT)
Subject: [R] sorting factors
In-Reply-To: <200304301733.00437.gina.joue@ucd.ie>
Message-ID: <Pine.SOL.4.44.0304301526570.4936-100000@millipede.gpcc.itd.umich.edu>

Try

artic <- factor(as.character(artic),
	levels=c("lowlip","dental","apex"),
	ordered=T)

Or use the function ordered() instead of factor(),
and omit the last argument above ("ordered=T").
See  help("ordered").  I'm not sure whether I even
need the  as.character()  syntax in there after
read.table(),  but it can't hurt.

This is just a guess at an answer, because I'm not
sure I understand quite what question you are asking.

-  tom blackwell  -  u michigan medical school  -  ann arbor  -

On Wed, 30 Apr 2003, g wrote:

> I've been trying to sort the values of the factors of contingency tables
> generated with xtabs. For example, I have a factor called "artic" with three
> possible values that I would like to order in a specific way -- but I'm not
> sure how to go about this.
>
> > test <- read.table("test.tab",header=TRUE,sep="\t")
> > artic = factor(artic,levels=c("lowlip","dental","apex"))
> > test.frame <- as.data.frame(test)
> > test.xtabs <- xtabs(freq ~ artic + var, test.frame)
> > mosaicplot(test.xtabs,shade=TRUE)
>
> Any help appreciated,
> Gina


From edd at debian.org  Wed Apr 30 21:36:23 2003
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 30 Apr 2003 14:36:23 -0500
Subject: [R] ylab in plot.POSIXct
In-Reply-To: <ulgptn3rebn.fsf@phz.com>
References: <ulgptn3rebn.fsf@phz.com>
Message-ID: <20030430193623.GA5159@sonny.eddelbuettel.com>

On Wed, Apr 30, 2003 at 03:10:52PM -0400, Ed Kademan wrote:
> I am using R-1.7.0 and have some data which consist of one vector of
> numbers and a second corresponding vector of dates belonging to the
> POSIXct class.  I would like to plot the numbers against the dates.
> What is the best way to do this?
> 
> It almost works to just call `plot.'  However if I do this while using
> the `ylab' parameter I get a warning message:
> 
>   parameter "ylab" couldn't be set in high-level plot() function 
> 
> Here is a function that demonstrates the behavior.
> 
>   ylabProblem <- function() {
>     x <- ISOdate(2003, 4, 1:10)           # POSIXct vector
>     y <- rnorm(10)
>     plot(x, y, ylab = 'I am y')
>   }
> 
> It works to invoke the low-level plotting routines by hand as follows:
> 
>   ylabNoProblem <- function() {
>     x <- ISOdate(2003, 4, 1:10)           # POSIXct vector
>     y <- rnorm(10)
>     plot.default(x, y, xaxt = 'n', xlab = '', ylab = 'I am y')
>     axis.POSIXct(1, x)
>   }
> 
> But I don't like calling methods explicitly like this.


ylabThisWorks <- function() {
   x <- ISOdate(2003, 4, 1:10)           # POSIXct vector
   y <- rnorm(10)
   plot(x,y, ann=FALSE)     # use ann=F, not axes=F
   title(ylab="I am y")     # and add the desired label
}   

Hth, Dirk

-- 
Don't drink and derive. Alcohol and algebra don't mix.


From murdoch at stats.uwo.ca  Wed Apr 30 21:46:04 2003
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 30 Apr 2003 15:46:04 -0400
Subject: [R] Scanning data files line-by-line
In-Reply-To: <Law11-F85PZGGxWalhX00017a85@hotmail.com>
References: <Law11-F85PZGGxWalhX00017a85@hotmail.com>
Message-ID: <rq90bvob40n1ls1ibpqvf5qgbntqnl7fcu@4ax.com>

On Wed, 30 Apr 2003 18:06:56 +0000, you wrote in message
<Law11-F85PZGGxWalhX00017a85 at hotmail.com>:

>I'm sorry to have to ask another question related to this.  What if
>the lines have variable number of fields?
 ...
>If I use scan with list( 0, "", 0 ), each line is treated as if it
>has a multiple of 3 elements, but really, what I want is to discard
>all fields after the third.

I'd try working with the fill=TRUE option, and give excess fields in
your list.

Duncan Murdoch


From SuzieBlatt at netscape.net  Wed Apr 30 21:48:48 2003
From: SuzieBlatt at netscape.net (Suzanne E. Blatt)
Date: Wed, 30 Apr 2003 15:48:48 -0400
Subject: [R] mpl in spatstat
Message-ID: <2A5E377E.09E83E90.0D1322AF@netscape.net>

Hello all,
I'm attempting to conduct spatial analysis of trees within a plot.  I want to see if the trees are spatially correlated to soil characteristics, say pH, or   moisture content.  I think one way to do it is with mpl, however, my soil characteristics were not taken at exactly the same locations as my trees and further, the vectors aren't the same length.  I'm getting the impression, largely from the error messages, that length matters, ie. they must be the same.  In my case this is impossible.  The example listed in the file:///tmp/Rtmp1608/.R/library/spatstat/html/mpl.html regarding 'soilsurvey' using 'soilchem' as the covariate does not seem to be located in library(spatstat) nor library(splancs).  I'm trying to see how that example works, but can't locate it.  Can anyone tell me how to circumvent the 'length' problem or direct me to the location of 'soilsurvey' and 'soilchem' so I can see how those datasets are set up.
Thanks,Suzanne 
__________________________________________________________________Try AOL and get 1045 hours FREE for 45 days!http://free.aol.com/tryaolfree/index.adp?375380


From shutnik_xx at yahoo.co.uk  Wed Apr 30 21:54:21 2003
From: shutnik_xx at yahoo.co.uk (=?iso-8859-1?q?Shutnik?=)
Date: Wed, 30 Apr 2003 20:54:21 +0100 (BST)
Subject: [R] R help
In-Reply-To: <x2el3llz1m.fsf@biostat.ku.dk>
Message-ID: <20030430195421.97861.qmail@web10908.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20030430/dc24cfbc/attachment.pl

From bates at stat.wisc.edu  Wed Apr 30 21:57:06 2003
From: bates at stat.wisc.edu (Douglas Bates)
Date: 30 Apr 2003 14:57:06 -0500
Subject: [R]  How to calculate the x to assymptotic value and curve
	inflection .
In-Reply-To: <200304301541.21103.chrysopa@insecta.ufv.br>
References: <200304301541.21103.chrysopa@insecta.ufv.br>
Message-ID: <6rvfwvdai5.fsf@bates4.stat.wisc.edu>

I think you need to refine your questions.  To me, the answers to the
questions that you asked are: "x = Inf (by definition)" and "there
isn't an inflection point".  I don't think those are what you had in
mind.

"Ronaldo Reis Jr." <chrysopa at insecta.ufv.br> writes:

> Hi,
> 
> I have this non-linear function:
> 
> y=115.251 - 118.69 * exp(-0.123517*x)
> 
> I try to discovery the x value for the assyntoptic value of y 
> and the x value where the behavior of curve change, the inflection
> point.
> 
> How to make this? Is poss?ble to make this on R?
> 
> Thanks
> Ronaldo


