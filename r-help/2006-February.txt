From HDoran at air.org  Wed Feb  1 00:34:52 2006
From: HDoran at air.org (Doran, Harold)
Date: Tue, 31 Jan 2006 18:34:52 -0500
Subject: [R] Help with boot()
Message-ID: <F5ED48890E2ACB468D0F3A64989D335A01ADE8D1@dc1ex3.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060131/e9ead3bf/attachment.pl

From stgries_lists at arcor.de  Wed Feb  1 02:02:36 2006
From: stgries_lists at arcor.de (Stefan Th. Gries)
Date: Wed, 1 Feb 2006 02:02:36 +0100 (CET)
Subject: [R] Word boundaries and gregexpr in R 2.2.1
Message-ID: <1991909.1138755756088.JavaMail.ngmail@webmail-06.arcor-online.net>

Hi

I have a question concerning how to match word boundaries which I bet has a very simple answer, but I haven't found it with trial and error nor by searching the help archives for the terms in the subject line. The problem is this: I have a vector of two character strings.

text<-c("This is a first example sentence.", "And this is a second example 	sentence.")

If I now look for word boundaries with regexpr, this is what I get:
> regexpr("\\b", text, perl=TRUE)
[1] 1 1
attr(,"match.length")
[1] 0 0

So far, so good. But with gregexpr I get:

> gregexpr("\\b", text, perl=TRUE)
Error: cannot allocate vector of size 524288 Kb
In addition: Warning messages:
1: Reached total allocation of 1015Mb: see help(memory.size) 
2: Reached total allocation of 1015Mb: see help(memory.size) 

Why don't I get the locations and extensions of all word boundaries?

I am using R 2.2.1 on a machine running Windows XP:
> R.version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    2.1
year     2005
month    12
day      20
svn rev  36812
language R

Thanks a lot,
STG
-- 
Stefan Th. Gries
----------------------------------------
University of California, Santa Barbara
http://people.freenet.de/Stefan_Th_Gries



From ggrothendieck at gmail.com  Wed Feb  1 02:26:22 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 31 Jan 2006 20:26:22 -0500
Subject: [R] Word boundaries and gregexpr in R 2.2.1
In-Reply-To: <1991909.1138755756088.JavaMail.ngmail@webmail-06.arcor-online.net>
References: <1991909.1138755756088.JavaMail.ngmail@webmail-06.arcor-online.net>
Message-ID: <971536df0601311726v55bf4037k630347092d44319e@mail.gmail.com>

When I tried it on Windows XP there was a grinding sound, probably memory
being swapped and it just seemed to go on forever and I finally had to kill R.
I am using "R version 2.2.1, 2005-12-20".   What did seem to work was this:

 gregexpr("X", gsub("\\b\\w|\\w\\b", "X", text))

where "X" should be replaced with some character not in the text.


On 1/31/06, Stefan Th. Gries <stgries_lists at arcor.de> wrote:
> Hi
>
> I have a question concerning how to match word boundaries which I bet has a very simple answer, but I haven't found it with trial and error nor by searching the help archives for the terms in the subject line. The problem is this: I have a vector of two character strings.
>
> text<-c("This is a first example sentence.", "And this is a second example      sentence.")
>
> If I now look for word boundaries with regexpr, this is what I get:
> > regexpr("\\b", text, perl=TRUE)
> [1] 1 1
> attr(,"match.length")
> [1] 0 0
>
> So far, so good. But with gregexpr I get:
>
> > gregexpr("\\b", text, perl=TRUE)
> Error: cannot allocate vector of size 524288 Kb
> In addition: Warning messages:
> 1: Reached total allocation of 1015Mb: see help(memory.size)
> 2: Reached total allocation of 1015Mb: see help(memory.size)
>
> Why don't I get the locations and extensions of all word boundaries?
>
> I am using R 2.2.1 on a machine running Windows XP:
> > R.version
>         _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    2.1
> year     2005
> month    12
> day      20
> svn rev  36812
> language R
>
> Thanks a lot,
> STG
> --
> Stefan Th. Gries
> ----------------------------------------
> University of California, Santa Barbara
> http://people.freenet.de/Stefan_Th_Gries
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From bpontar at amazon.com  Wed Feb  1 02:57:54 2006
From: bpontar at amazon.com (Pontarelli, Brett)
Date: Tue, 31 Jan 2006 17:57:54 -0800
Subject: [R] Removing specific v1:v2 combinations from a formula.
Message-ID: <2047FEBD93E8744D8A82C2510BB823C4E8D8AC@exchg-sea3-02.ant.amazon.com>

Suppose I have a formula

	mfTest = (y ~ a + b + c + d1 + d2 + d3);

When I update the formula

	mfTest2nd = update(mfTest, .~.^2);

I get all the combinations a:b, a:c, etc.  But I don't want the d1:d2, d2:d3, etc. interactions.  I've tried

	mfTest2nd = update(fmTest, .~.^2 - (d1+d2+d3)^2);

But that removes the 1st order variables as well.  Is there a way to remove (with minimal typing) the d_i:d_j interactions only?  Thanks.

--Brett



From sell_mirage_ne at hotmail.com  Wed Feb  1 03:03:25 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Tue, 31 Jan 2006 20:03:25 -0600
Subject: [R] calculating goodness-of-fit statistics
Message-ID: <BAY110-F77B9768F72CA98C97F6E2C70B0@phx.gbl>

Hi R users

I have a simple data for calculating goodness-of-fit statistics (e.g., X2 by 
Pearson, G2 by Wilks)

#################################################
observed<-c(424,174,0,402)
expected<-c(282.7174, 314.2972, 142.3142, 260.6712)
2*sum(observed*log(observed/expected)) # for X2
sum((observed-expected)^2/expected)  # for G2
#################################################

(note. expected ones were calculating by a model I used, not by marginal of 
observed ones.)

The third element of the observed vector is zero.

For third element, 0 * log(0/142.3142) is NaN. That is why I got NaN for G2.

I think 0 multiplied by anything should be zero. Am I wrong ?

Is there any R functions to correct zero cells for calculating G2? If there 
is, I like to know some

references justifying the correction.

Thank you in advance

TM



From bpontar at amazon.com  Wed Feb  1 03:11:26 2006
From: bpontar at amazon.com (Pontarelli, Brett)
Date: Tue, 31 Jan 2006 18:11:26 -0800
Subject: [R] calculating goodness-of-fit statistics
Message-ID: <2047FEBD93E8744D8A82C2510BB823C4E8D8B6@exchg-sea3-02.ant.amazon.com>

The trouble is log(0/anything) = log(0) = NaN.  If you want them to evaulate to zero you might try zeroing out the values you know will be NaN:

X2 = 2*sum(observed*log(observed/expected));
X2[observed==0] = 0;

--Brett
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Taka Matzmoto
Sent: Tuesday, January 31, 2006 6:03 PM
To: r-help at stat.math.ethz.ch
Subject: [R] calculating goodness-of-fit statistics

Hi R users

I have a simple data for calculating goodness-of-fit statistics (e.g., X2 by Pearson, G2 by Wilks)

#################################################
observed<-c(424,174,0,402)
expected<-c(282.7174, 314.2972, 142.3142, 260.6712)
2*sum(observed*log(observed/expected)) # for X2
sum((observed-expected)^2/expected)  # for G2 #################################################

(note. expected ones were calculating by a model I used, not by marginal of observed ones.)

The third element of the observed vector is zero.

For third element, 0 * log(0/142.3142) is NaN. That is why I got NaN for G2.

I think 0 multiplied by anything should be zero. Am I wrong ?

Is there any R functions to correct zero cells for calculating G2? If there is, I like to know some

references justifying the correction.

Thank you in advance

TM

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dmaneesh at hotmail.com  Wed Feb  1 03:37:13 2006
From: dmaneesh at hotmail.com (maneesh deshpande)
Date: Tue, 31 Jan 2006 21:37:13 -0500
Subject: [R] : Model formula question
Message-ID: <BAY107-F10B65367C4216065914EDCD20B0@phx.gbl>

Hi,

I have a data set with a continuous predictor X, a factor A and a continuous 
dependent
variable Y.
I am trying to build a linear model of the form:

Y = (b0 + b1*X1)*B(A)

where B(A) is a constant for each level of the factor A.
I am not quite sure how to formulate the appropriate model formula. If I 
write:

Y ~ ( 1 + X)/A

, I get estimates for as many constants and slopes as the number of levels 
of A.
What I really need is an overall multiplicative constant which depends on 
the factor A.

Thanks in advance,

Maneesh



From wasquith at austin.rr.com  Wed Feb  1 04:14:50 2006
From: wasquith at austin.rr.com (William Asquith)
Date: Tue, 31 Jan 2006 21:14:50 -0600
Subject: [R]  Cauchy distribution limits
Message-ID: <39BEF92E-BA27-4079-9BE1-D6B4CF2422E4@austin.rr.com>

I have question (curiosity) regarding returned values of R's qcauchy 
() function,
for nonexceedance probability (F). It seems the ideal returned range  
of cauchy distribution should be [-Inf,Inf].

For F=0
 > qcauchy(0)
[1] -Inf

but for F=1
 > qcauchy(1)
[1] 8.16562e+15

It seems to me that the proper return value should be Inf???

For default (location=0,scale=1) quantile function of cauchy

x(F) = tan(pi * (F - 0.5))

For F = 0
 > tan(pi*(-0.5))
[1] -1.633124e+16

For F = 1
 > tan(pi*(0.5))
[1] 1.633124e+16

So I conclude that qcauchy(0) properly handles the -Inf result and  
the qcauchy(1) returns a very large number, curiously not equal to tan 
(0.5*pi), but certainly not Inf.

As double check,
 > tan(pi*(0.99999-0.5))
[1] 31830.99
 > qcauchy(0.99999)
[1] 31830.99

william



From weeksjp at colorado.edu  Wed Feb  1 04:40:35 2006
From: weeksjp at colorado.edu (Jonathan Weeks)
Date: Tue, 31 Jan 2006 20:40:35 -0700
Subject: [R] Using a console application from within R
Message-ID: <BAY0-SMTP086A12715966A2BB234D5FB00B0@phx.gbl>

I would like to open a console application from within R and then send input
to the newly opened console. I can use the following to open the application
...

setwd(path)
system(paste(path,"icl.exe",sep=""))

This allows me to type in what want, but I would like to do something like
this

setwd(path)
system(paste(path,"icl.exe",sep=""),input=c("icl sim.tcl",
"exit"),wait=TRUE)

If I include input as part of the system function the application opens and
then closes immediately without processing the input.

Any assistance that you can offer would be greatly appreciated.

Jonathan Weeks
Doctoral Student
School of Education
University of Colorado, Boulder
jonathan.weeks at colorado.edu
303-517-9666



From ggrothendieck at gmail.com  Wed Feb  1 05:07:59 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 31 Jan 2006 23:07:59 -0500
Subject: [R] Using a console application from within R
In-Reply-To: <BAY0-SMTP086A12715966A2BB234D5FB00B0@phx.gbl>
References: <BAY0-SMTP086A12715966A2BB234D5FB00B0@phx.gbl>
Message-ID: <971536df0601312007n4b0f21d0vf3ba6d4dfa224511@mail.gmail.com>

Don't know how you tell if its working but you need to write

   intern = TRUE

in order to get the output back.  For example, this works for me:

   system("findstr [a-m]", input = letters, intern = TRUE)

On 1/31/06, Jonathan Weeks <weeksjp at colorado.edu> wrote:
> I would like to open a console application from within R and then send input
> to the newly opened console. I can use the following to open the application
> ...
>
> setwd(path)
> system(paste(path,"icl.exe",sep=""))
>
> This allows me to type in what want, but I would like to do something like
> this
>
> setwd(path)
> system(paste(path,"icl.exe",sep=""),input=c("icl sim.tcl",
> "exit"),wait=TRUE)
>
> If I include input as part of the system function the application opens and
> then closes immediately without processing the input.
>
> Any assistance that you can offer would be greatly appreciated.
>
> Jonathan Weeks
> Doctoral Student
> School of Education
> University of Colorado, Boulder
> jonathan.weeks at colorado.edu
> 303-517-9666
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Wed Feb  1 08:39:05 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Feb 2006 07:39:05 +0000 (GMT)
Subject: [R] approximation to ln \Phi(x)
In-Reply-To: <88BEBEB4755E5D4BBEAE3A1ED85B1603022F698D@UM-EMAIL06.um.umsystem.edu>
References: <88BEBEB4755E5D4BBEAE3A1ED85B1603022F698D@UM-EMAIL06.um.umsystem.edu>
Message-ID: <Pine.LNX.4.61.0602010725550.24417@gannet.stats>

On Tue, 31 Jan 2006, Morey, Richard D (UMC-Student) wrote:

> I am using pnorm() with the log.p=T argument to get approximations to ln 
> \Phi(x) and qnorm with the log.p=T argument to get estimates of 
> \Phi^{-1}(exp(x)). What approximations are used in these two functions 
> (I noticed in the source pnorm.c it doesn't look like Abramowitz and 
> Stegen) and where can I find the citation?

?qnorm says

      'qnorm' is based on Wichura's algorithm AS 241 which provides
      precise results up to about 16 digits.

You can also see this at src/nmath/qnorm.c in the sources.

For pnorm.c, the comments describe the origins of the main approximation.

There are other distribution function approximations in R which are based 
on undocumented ideas, but these are fairly well documented, especially 
qnorm.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Wed Feb  1 08:54:12 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 01 Feb 2006 08:54:12 +0100
Subject: [R] SVM question
In-Reply-To: <Pine.LNX.4.58.0601312031200.10519@bach.ebgm.jussieu.fr>
References: <Pine.LNX.4.58.0601312031200.10519@bach.ebgm.jussieu.fr>
Message-ID: <43E06924.3090705@statistik.uni-dortmund.de>

Georges Orlowski wrote:

> I'm running SVM from e1071 package on a data with ~150 columns (variables) 
> and 50000 lines of data (it takes a bit of time) for radial kernel for 
> different gamma and cost values. 
> 
> I get a very large models with at least 
> 30000 vectors and the prediction I get is not the best one. What does it 
> mean and what could I do to ameliorate my model ?

Do you mean 30000 *support vectors* in 50000 observations? So you are 
heavily overfitting. Try to tune the svm better.

Uwe Ligges


> 
> Jerzy Orlowski
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Wed Feb  1 09:14:36 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Feb 2006 08:14:36 +0000 (GMT)
Subject: [R] calculating goodness-of-fit statistics
In-Reply-To: <2047FEBD93E8744D8A82C2510BB823C4E8D8B6@exchg-sea3-02.ant.amazon.com>
References: <2047FEBD93E8744D8A82C2510BB823C4E8D8B6@exchg-sea3-02.ant.amazon.com>
Message-ID: <Pine.LNX.4.61.0602010806380.24763@gannet.stats>

On Tue, 31 Jan 2006, Pontarelli, Brett wrote:

> The trouble is log(0/anything) = log(0) = NaN.

Hmm: log(0) = -Inf.

Taka Matzmoto said

> I think 0 multiplied by anything should be zero. Am I wrong ?

Yes!  0 * Inf = NaN, 0 * -Inf = NaN, and 0 * NaN = NaN.

Conventionally 0 log0 = 0, since this is the limit of x log x as x -> 0.
That is also what is appropriate in the G^2 formula since it refers to a 
Poisson(0).

> If you want them to evaulate to zero you might try zeroing out the 
values you know will be NaN:
>
> X2 = 2*sum(observed*log(observed/expected));
> X2[observed==0] = 0;

A trick from way back by Bill Venables is to use pmax(observed, 1) inside 
the log.

> --Brett
>
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Taka Matzmoto
> Sent: Tuesday, January 31, 2006 6:03 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] calculating goodness-of-fit statistics
>
> Hi R users
>
> I have a simple data for calculating goodness-of-fit statistics (e.g., 
> X2 by Pearson, G2 by Wilks)

You have these labelled backwards!

> #################################################
> observed<-c(424,174,0,402)
> expected<-c(282.7174, 314.2972, 142.3142, 260.6712)
> 2*sum(observed*log(observed/expected)) # for X2
> sum((observed-expected)^2/expected)  # for G2
> #################################################
>
> (note. expected ones were calculating by a model I used, not by marginal of observed ones.)
>
> The third element of the observed vector is zero.
>
> For third element, 0 * log(0/142.3142) is NaN. That is why I got NaN for G2.
>
> I think 0 multiplied by anything should be zero. Am I wrong ?
>
> Is there any R functions to correct zero cells for calculating G2? If there is, I like to know some
>
> references justifying the correction.
>
> Thank you in advance
>
> TM
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Wed Feb  1 09:42:21 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 1 Feb 2006 09:42:21 +0100
Subject: [R] Cauchy distribution limits
In-Reply-To: <39BEF92E-BA27-4079-9BE1-D6B4CF2422E4@austin.rr.com>
References: <39BEF92E-BA27-4079-9BE1-D6B4CF2422E4@austin.rr.com>
Message-ID: <17376.29805.700098.684243@stat.math.ethz.ch>

>>>>> "William" == William Asquith <wasquith at austin.rr.com>
>>>>>     on Tue, 31 Jan 2006 21:14:50 -0600 writes:

    William> I have question (curiosity) regarding returned values of R's qcauchy 
    William> () function,
    William> for nonexceedance probability (F). It seems the ideal returned range  
    William> of cauchy distribution should be [-Inf,Inf].

    William> For F=0
    >> qcauchy(0)
    William> [1] -Inf

    William> but for F=1
    >> qcauchy(1)
    William> [1] 8.16562e+15

    William> It seems to me that the proper return value should be Inf???

yes,  but istn't  8 * 10^15 a good approximation to +Inf ?  :-) :-)

    William> For default (location=0,scale=1) quantile function of cauchy

    William> x(F) = tan(pi * (F - 0.5))

    William> For F = 0
    >> tan(pi*(-0.5))
    William> [1] -1.633124e+16

    William> For F = 1
    >> tan(pi*(0.5))
    William> [1] 1.633124e+16

    William> So I conclude that qcauchy(0) properly handles the -Inf result and  
    William> the qcauchy(1) returns a very large number,
    William>  curiously not equal to tan  (0.5*pi), but certainly not Inf.

The reason for the current behavior is the following part of
qcauchy.c :

    return location + (lower_tail ? -scale : scale) / tan(M_PI * p);
    /*	-1/tan(pi * p) = -cot(pi * p) = tan(pi * (p - 1/2))  */


(note the comment!)

I'll fix this, since I had wanted to do it in the past (and
then thought it wasn't important enough to warrant an extra if()
in the code).

Martin Maechler, ETH Zurich

    William> As double check,
    >> tan(pi*(0.99999-0.5))
    William> [1] 31830.99
    >> qcauchy(0.99999)
    William> [1] 31830.99



From dieter.menne at menne-biomed.de  Wed Feb  1 09:42:58 2006
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Wed, 1 Feb 2006 09:42:58 +0100
Subject: [R] Passing additional paramaters to nlsList(nlme) fit function
Message-ID: <LPEJLJACLINDNMBMFAFIKEBJCCAA.dieter.menne@menne-biomed.de>

Hello, nls-users,

is it possible to pass additional parameters to the model function that are
known and groupwise constant with nlsList? I could not find something like a
"keep this fixed" option in the documentation and the code (my fault...?)

The current workaround is to break the problem down into groups and use
globals to pass the constant parameters, but it is ugly code and won't work
when an over-all nlme is needed.

Dieter Menne



From anil_rohilla at rediffmail.com  Wed Feb  1 06:29:33 2006
From: anil_rohilla at rediffmail.com (anil kumar rohilla)
Date: 1 Feb 2006 05:29:33 -0000
Subject: [R] Time series filtering
Message-ID: <20060201052933.15034.qmail@webmail62.rediffmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/e1ad035a/attachment.pl

From freeyun2003 at yahoo.com  Wed Feb  1 06:46:47 2006
From: freeyun2003 at yahoo.com (liu)
Date: Tue, 31 Jan 2006 21:46:47 -0800 (PST)
Subject: [R] output hessian matrix in constrOptim
Message-ID: <20060201054647.3159.qmail@web34711.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060131/06eaec8c/attachment.pl

From Markus.Preisetanz at clientvela.com  Wed Feb  1 10:14:59 2006
From: Markus.Preisetanz at clientvela.com (Markus Preisetanz)
Date: Wed, 1 Feb 2006 10:14:59 +0100
Subject: [R] RODBC: How to Retrieve a Column as Rownames?
Message-ID: <79799E69EA1DA246A51F983B5663BEA2CD34A4@server2.hq.clientvela.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/25a564d8/attachment.pl

From orlowski at ebgm.jussieu.fr  Wed Feb  1 10:24:45 2006
From: orlowski at ebgm.jussieu.fr (Georges Orlowski)
Date: Wed, 1 Feb 2006 10:24:45 +0100 (CET)
Subject: [R] SVM question
In-Reply-To: <43E06924.3090705@statistik.uni-dortmund.de>
References: <Pine.LNX.4.58.0601312031200.10519@bach.ebgm.jussieu.fr>
	<43E06924.3090705@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.58.0602011021460.13129@bach.ebgm.jussieu.fr>

Well, I know there must be something wrong with the way I'm running the 
SVM but I tried all the posiible ranges of parameters gamma and cost and 
it does not improve? Could You suggest anything? 


On Wed, 1 Feb 2006, Uwe Ligges wrote:

> Georges Orlowski wrote:
> 
> > I'm running SVM from e1071 package on a data with ~150 columns (variables) 
> > and 50000 lines of data (it takes a bit of time) for radial kernel for 
> > different gamma and cost values. 
> > 
> > I get a very large models with at least 
> > 30000 vectors and the prediction I get is not the best one. What does it 
> > mean and what could I do to ameliorate my model ?
> 
> Do you mean 30000 *support vectors* in 50000 observations? So you are 
> heavily overfitting. Try to tune the svm better.> 
> Uwe Ligges
> 
> 
> > 
> > Jerzy Orlowski
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Wed Feb  1 11:02:31 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Feb 2006 10:02:31 +0000 (GMT)
Subject: [R] RODBC: How to Retrieve a Column as Rownames?
In-Reply-To: <79799E69EA1DA246A51F983B5663BEA2CD34A4@server2.hq.clientvela.net>
References: <79799E69EA1DA246A51F983B5663BEA2CD34A4@server2.hq.clientvela.net>
Message-ID: <Pine.LNX.4.61.0602010952310.17582@gannet.stats>

On Wed, 1 Feb 2006, Markus Preisetanz wrote:

> Dear Collegues,
>
> when using sqlQuery from the package RODBC I always get a data frame with automatically generated rownames, even if:
>
> *  the first column of the query is called rownames using "Select ... AS rownames, ... From ..."
>
> *  and: the values from this column are unique
>
> *  and: the values are inevitably forced to character data with e.g. " 'rn_' + CAST(xy AS NVARCHAR) "
>
> It works with sqlFetch but I would have to define a view for every 
> query. Does anybody know help?

Well, you use ?sqlQuery to find out, as I just did.  What is so hard about 
that?

This is documented feature of sqlFetch, and not mentioned at all as
supported by sqlQuery.  As sqlFetch is a wrapper for sqlQuery you can just
write your own wrapper based on it.

The (unacknowledged) maintainer of RODBC, and author of this feature.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From suwak at lexx.eu.org  Wed Feb  1 11:24:29 2006
From: suwak at lexx.eu.org (Krzysztof Suwada)
Date: Wed, 1 Feb 2006 11:24:29 +0100 (CET)
Subject: [R] Randomised Block Design
Message-ID: <Pine.LNX.4.58L.0602011121120.21528@lexx.eu.org>

Hi, I'm studying math, and i have to make an analysys using Randomised 
Block Design. I have two factors, i know how to do this in Statistica, but 
how to do this in R, i read some manuals but the only thing that i have 
found was 2 factor ANOVA.

Please could someone help me, or give some usefull links ??


Krzytsztof Suwada



From d.firth at warwick.ac.uk  Wed Feb  1 11:28:07 2006
From: d.firth at warwick.ac.uk (David Firth)
Date: Wed, 1 Feb 2006 10:28:07 +0000
Subject: [R] : Model formula question
In-Reply-To: <BAY107-F10B65367C4216065914EDCD20B0@phx.gbl>
References: <BAY107-F10B65367C4216065914EDCD20B0@phx.gbl>
Message-ID: <200602011028.07627.d.firth@warwick.ac.uk>

On Wednesday 01 February 2006 02:37, maneesh deshpande 
wrote:
> Hi,
>
> I have a data set with a continuous predictor X, a factor
> A and a continuous dependent
> variable Y.
> I am trying to build a linear model of the form:
>
> Y = (b0 + b1*X1)*B(A)
>
> where B(A) is a constant for each level of the factor A.
> I am not quite sure how to formulate the appropriate
> model formula. If I write:
>
> Y ~ ( 1 + X)/A
>
> , I get estimates for as many constants and slopes as the
> number of levels of A.

Yes, that's right: the / symbol has a special 
(non-arithmetic) meaning when used like this in a model 
formula.  See for example p151 onwards in the reference 
that is given by ?formula.

> What I really need is an overall multiplicative constant
> which depends on the factor A.

The gnm (generalized nonlinear models) package has 
facilities for this.  The model above could be specified 
there as
    Y ~ -1 + Mult(X, -1 + A)
(where the first "-1" removes the intercept, and the second 
one says to estimate a separate multiplier for each level 
of A rather than using contrasts in A).  Or, if you want to 
constrain all of your multipliers to have the same sign, 
you can use
    Y ~ -1 + Mult(X, Exp(-1 + A))
(note the capital E there!).

It is unclear to me that using the *same* set of multipliers 
for both intercept and slope will typically be the right 
thing to do, though.  It would not, for example, be 
invariant to transformation of X to X-c, with c constant. 
That is to say, your X variable needs to be on a scale for 
which the zero value has a special meaning, in order to 
allow the above model to make sense.  But presumably you 
have thought about this already.

Hoping that helps,
David

-- 
Professor David Firth
http://www.warwick.ac.uk/go/dfirth



From paladini at rz.uni-potsdam.de  Wed Feb  1 11:28:05 2006
From: paladini at rz.uni-potsdam.de (paladini@rz.uni-potsdam.de)
Date: Wed,  1 Feb 2006 11:28:05 +0100
Subject: [R] plot-function: How to change the font of the titles
Message-ID: <1138789685.43e08d35e4af9@webmail.uni-potsdam.de>

Hello!
I want to create a plot with x- and y-labels writen in times or arial.
How can I change the font?

Thank you very much. Best regards

Claudia



From paladini at rz.uni-potsdam.de  Wed Feb  1 11:28:09 2006
From: paladini at rz.uni-potsdam.de (paladini@rz.uni-potsdam.de)
Date: Wed,  1 Feb 2006 11:28:09 +0100
Subject: [R] plot-function: How to change the font of the titles
Message-ID: <1138789689.43e08d3983051@webmail.uni-potsdam.de>

Hello!
I want to create a plot with x- and y-labels writen in times or arial.
How can I change the font?

Thank you very much. Best regards

Claudia



From Marco.Giannitrapani at shell.com  Wed Feb  1 11:28:17 2006
From: Marco.Giannitrapani at shell.com (Giannitrapani, Marco GSUK-GSSC)
Date: Wed, 1 Feb 2006 10:28:17 -0000
Subject: [R] =?iso-8859-1?q?Gauss-Kr=FCger_coordinates_system?=
Message-ID: <DC768C412F1C394192A8108281818F2B02CA616C@wyt-s-019.europe.shell.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/80f35f62/attachment.pl

From paladini at rz.uni-potsdam.de  Wed Feb  1 11:30:09 2006
From: paladini at rz.uni-potsdam.de (paladini@rz.uni-potsdam.de)
Date: Wed,  1 Feb 2006 11:30:09 +0100
Subject: [R] How to save R-grafics in eps format
Message-ID: <1138789809.43e08db1cc445@webmail.uni-potsdam.de>

Hello!
I used to save R-Grafics like this: postscript("file.ps").
Is there alsoa way to save them as eps?


Thank you very much


Claudia



From p.dalgaard at biostat.ku.dk  Wed Feb  1 11:56:40 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Feb 2006 11:56:40 +0100
Subject: [R] How to save R-grafics in eps format
In-Reply-To: <1138789809.43e08db1cc445@webmail.uni-potsdam.de>
References: <1138789809.43e08db1cc445@webmail.uni-potsdam.de>
Message-ID: <x2zmlbz6s7.fsf@viggo.kubism.ku.dk>

paladini at rz.uni-potsdam.de writes:

> Hello!
> I used to save R-Grafics like this: postscript("file.ps").
> Is there alsoa way to save them as eps?

from ?postscript: 

     The postscript produced by R is EPS (_Encapsulated PostScript_)
     compatible, and can be included into other documents, e.g., into
     LaTeX, using '\includegraphics{<filename>}'.  For use in this way
     you will probably want to set 'horizontal = FALSE, onefile =
     FALSE, paper = "special"'.

Also, there is dev.copy2eps for copying from screen to EPS. Watch out
for pointsize and geometry differences though.


 
> 
> Thank you very much
> 
> 
> Claudia
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Wed Feb  1 11:54:38 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Feb 2006 10:54:38 +0000 (GMT)
Subject: [R] plot-function: How to change the font of the titles
In-Reply-To: <1138789685.43e08d35e4af9@webmail.uni-potsdam.de>
References: <1138789685.43e08d35e4af9@webmail.uni-potsdam.de>
Message-ID: <Pine.LNX.4.61.0602011048350.20244@gannet.stats>

On Wed, 1 Feb 2006 paladini at rz.uni-potsdam.de wrote:

> Hello!
> I want to create a plot with x- and y-labels writen in times or arial.
> How can I change the font?

Well, is it `titles' (subject) or `x- and y-labels', and if the latter do 
you mean 'labels' (as in axis) or 'xlab' (as in title)?

Do you want some or all of the annotation in Times or Arial, or some in 
each.  (On devices which support Arial it is the default.)

And on which device and which version of R?

If this is on Windows, see the rw-FAQ and the help on Rdevga, and choose 
an appropriate value of the graphics par 'font' (normally 1 for Arial and 
6 for Times).  Otherwise, consider par(family).

[And please do read the posting guide and not send posts twice or more.]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From JeeBee at troefpunt.nl  Wed Feb  1 12:02:26 2006
From: JeeBee at troefpunt.nl (JeeBee)
Date: Wed, 01 Feb 2006 12:02:26 +0100
Subject: [R] several plots in one
Message-ID: <pan.2006.02.01.11.02.26.506929@troefpunt.nl>

Can anyone tell me how I can supply more than one graph to plotCI
(gplots) at once?

Below is what I tried, also with rbind instead of cbind.
What is the way to do this (in general, I think)?

Problem is that lines of 1-st and 2-nd series are mixed, while they have
nothing to do with each other.

I also tried calling plotCI with argument add=TRUE, which didn't seem to
work (that is actually what I wanted I think).
(It should look the same as if I called plotCI twice with same
labels/xlim/ylim/etc.)

  plotCI(x = cbind(x1,x2),
         y = cbind(means1,means2), # means1 == ci1["Estimate",]
         xlim = c(0,100), #ylim = c(0.2,0.5),
         ylab = "System welfare", 
         pch = 7, col = c("red","blue"), type = "b",
         uiw = cbind(uiw1,uiw2))

Thanks in advance,
JeeBee.



From scruveil at genoscope.cns.fr  Wed Feb  1 12:00:09 2006
From: scruveil at genoscope.cns.fr (Stephane CRUVEILLER)
Date: Wed, 1 Feb 2006 12:00:09 +0100
Subject: [R] List of lists???
In-Reply-To: <971536df0601310650o498b3f2ds9c446e600deb70da@mail.gmail.com>
References: <200601311530.41705.scruveil@genoscope.cns.fr>
	<971536df0601310650o498b3f2ds9c446e600deb70da@mail.gmail.com>
Message-ID: <200602011200.10030.scruveil@genoscope.cns.fr>

Thx for the hint...
the div <- factor(c(1,1,1,2,2)) did exactly what I was expecting...

St??phane.

Le Mardi 31 Janvier 2006 15:50, Gabor Grothendieck a ??crit :
> Your post seems to be messed up but I will assume you have a
> 5 column data frame and the questino is how to run f on the first
> three columns and separately on the last two.  I think the
> easiest is just the following where I have used the builtin iris
> data set where I have assumed that the operation you want
> to perform is summary for purposes of example:
>
> summary(iris[,1:3])
> summary(iris[,4:5])
>
> If this is not your real problem and the real problem has many more
> divisions then try this where div is a factor that defines the division
> of columns into sets:
>
> div <- factor(c(1,1,1,2,2))
> lapply(split(names(iris), div), function(n) summary(iris[n]))
>
> On 1/31/06, Stephane CRUVEILLER <scruveil at genoscope.cns.fr> wrote:
> > Hi,
> >
> > I would like to perform computations on some variables belonging to the
> > same dataframe. For instance my data frame has the following shape:
> > toto1toto2toto3toto4toto5
> > 1 12345
> > 2678910
> >
> > I would like to perform the calculation on c("toto1","toto2","toto3") and
> > then the same calculation on c("toto4","toto5"). Is there a way to tell R
> > to do it using 3 loop (a list of lists)??
> >
> > Stephane.
> > --
> > ==========================================================
> > Stephane CRUVEILLER Ph. D.
> > Genoscope - Centre National de Sequencage
> > Atelier de Genomique Comparative
> > 2, Rue Gaston Cremieux   CP 5706
> > 91057 Evry Cedex - France
> > Phone: +33 (0)1 60 87 84 58
> > Fax: +33 (0)1 60 87 25 14
> > EMails: scruveil at genoscope.cns.fr ,scruvell at infobiogen.fr
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html

-- 
==========================================================
Stephane CRUVEILLER Ph. D.
Genoscope - Centre National de Sequencage
Atelier de Genomique Comparative
2, Rue Gaston Cremieux   CP 5706
91057 Evry Cedex - France
Phone: +33 (0)1 60 87 84 58
Fax: +33 (0)1 60 87 25 14
EMails: scruveil at genoscope.cns.fr ,scruvell at infobiogen.fr



From petr.pikal at precheza.cz  Wed Feb  1 12:08:17 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 01 Feb 2006 12:08:17 +0100
Subject: [R] plot-function: How to change the font of the titles
In-Reply-To: <1138789685.43e08d35e4af9@webmail.uni-potsdam.de>
Message-ID: <43E0A4B1.15429.CC3315@localhost>

Hi
Almost all graphic manipulation is done by par() setting. Sometimes 
you can issue a par argument directly in plot() command so for 
Windows

plot(...., font.lab = integer.number.to specify.predefined.font)

however I believe that font issue is device and OS specific and you 
shall read (and try)

?par
?plot
?text
?axis
....

see also Rdevga file for predefined fonts

HTH
Petr




On 1 Feb 2006 at 11:28, paladini at rz.uni-potsdam.de wrote:

Date sent:      	Wed, 1 Feb 2006 11:28:05 +0100
From:           	paladini at rz.uni-potsdam.de
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] plot-function: How to change the font of the titles

> Hello!
> I want to create a plot with x- and y-labels writen in times or arial.
> How can I change the font?
> 
> Thank you very much. Best regards
> 
> Claudia
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From Reinecke at consultic.com  Wed Feb  1 12:31:08 2006
From: Reinecke at consultic.com (Michael Reinecke)
Date: Wed, 1 Feb 2006 12:31:08 +0100
Subject: [R] Write.table: change points to commas when object contains a row
	of characters
Message-ID: <D1A363788EC8F946A56DAF95C0FBE7CF196CDA@sbs2003.CMI.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/8aa8e78e/attachment.pl

From ana.quiterio at ine.pt  Wed Feb  1 12:55:52 2006
From: ana.quiterio at ine.pt (=?iso-8859-1?Q?Ana_Quit=E9rio?=)
Date: Wed, 1 Feb 2006 11:55:52 -0000 
Subject: [R]  sort columns
Message-ID: <E97312684A84D511BDD40002A50968D607170283@lxpobw01.ine.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/054cb099/attachment.pl

From Roger.Bivand at nhh.no  Wed Feb  1 13:04:02 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 1 Feb 2006 13:04:02 +0100 (CET)
Subject: [R] =?iso-8859-1?q?Gauss-Kr=FCger_coordinates_system?=
In-Reply-To: <DC768C412F1C394192A8108281818F2B02CA616C@wyt-s-019.europe.shell.com>
Message-ID: <Pine.LNX.4.44.0602011245580.6077-100000@reclus.nhh.no>

On Wed, 1 Feb 2006, Giannitrapani, Marco GSUK-GSSC wrote:

> Dear All, 
> 
> I need to convert some Northing-Easting coordinates from the
> Gauss-Kr??ger system into latitude-longitude.
> 
> Any suggestions on how to do it?

(The "Spatial" Task View on CRAN and/or the R-sig-geo mailing lists might 
have helped).

Yes, the off-CRAN package spproj using classes from the sp package and the 
underlying PROJ.4 projection library should be able to do it:

rSpatial <- "http://r-spatial.sourceforge.net/R"
install.packages("spproj", repos=rSpatial)

# if you don't have it already; on Mac OSX and Linux/Unix, you need to 
# install PROJ.4 first; on Windows the binary package should install OK

library(spproj)

lon <- 2*runif(20)+9
lat <- 2*runif(20)+50
coords <- cbind(lon, lat)

# generate some coordinates

coords_sp <- SpatialPoints(coords,
 proj4string=CRS("+proj=longlat +ellps=WGS84"))
plot(coords_sp, axes=TRUE)

coords_sp_GK <- transform(coords_sp, CRS("+init=epsg:2166"))
plot(coords_sp_GK, axes=TRUE)

#
# and make them Pulkovo 1942(83) / Gauss Kruger zone 3 (see 
# system.file("proj/epsg", package="spproj")[1]
# for PROJ.4 definitions of thousands of projections
#
# EPSG was founded and funded by oil companies fed up with
# projection metadata being treated as top secret, and it seems to
# be well-maintained
#
# The first argument to transform() must be a "Spatial" class object
# with its proj4string slot set to the appropriate projection.
# If you set it wrong, you may be surprised/disappointed
#

coords_sp_LL <- transform(coords_sp_GK, CRS("+proj=longlat +ellps=WGS84"))

# and back again (your question) for your choice of datum and/or ellipsoid

all.equal(slot(coords_sp_LL, "coords"), slot(coords_sp, "coords"))

Roger

> 
> Regards,
> 
> Marco
> 
> Marco Giannitrapani
> Statistical Consultant

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From andy_liaw at merck.com  Wed Feb  1 14:05:05 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 1 Feb 2006 08:05:05 -0500
Subject: [R] SVM question
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7A2@usctmx1106.merck.com>

Have you tried the range of parameters suggested in 

  http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf

?

Please do read the posting guide to help you phrase the question better.
Without showing us exactly what you did, we have no way of telling what
might have gone wrong.  The only information you gave us is that you tried
SVM on your data and it didn't do so well.  What is anyone supposed to do
with that info?

Andy

From: Georges Orlowski
 
> 
> Well, I know there must be something wrong with the way I'm 
> running the 
> SVM but I tried all the posiible ranges of parameters gamma 
> and cost and 
> it does not improve? Could You suggest anything? 
> 
> 
> On Wed, 1 Feb 2006, Uwe Ligges wrote:
> 
> > Georges Orlowski wrote:
> > 
> > > I'm running SVM from e1071 package on a data with ~150 
> columns (variables) 
> > > and 50000 lines of data (it takes a bit of time) for 
> radial kernel for 
> > > different gamma and cost values. 
> > > 
> > > I get a very large models with at least 
> > > 30000 vectors and the prediction I get is not the best 
> one. What does it 
> > > mean and what could I do to ameliorate my model ?
> > 
> > Do you mean 30000 *support vectors* in 50000 observations? 
> So you are 
> > heavily overfitting. Try to tune the svm better.> 
> > Uwe Ligges
> > 
> > 
> > > 
> > > Jerzy Orlowski
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From dimitris.rizopoulos at med.kuleuven.be  Wed Feb  1 14:10:14 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 1 Feb 2006 14:10:14 +0100
Subject: [R] sort columns
References: <E97312684A84D511BDD40002A50968D607170283@lxpobw01.ine.pt>
Message-ID: <00e301c62730$d7a66e80$0540210a@www.domain>

try something like the following:

data[, order(as.numeric(gsub("v", "", names(data))))]


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm



----- Original Message ----- 
From: "Ana Quit??rio" <ana.quiterio at ine.pt>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, February 01, 2006 12:55 PM
Subject: [R] sort columns


Hi.



I have a simple (I think) question



My dataset have these variables:



names(data)

  [1] "v1"   "v2"   "v3"   "v4"   "v5"   "v6"   "v7"   "v8"   "v9" 
"v10"
"v11"  "v12"  "v13"  "v14"  "v15"  "v16"  "v17"  "v18"  "v52"

 [20] "v53"  "v54"  "v55"  "v56"  "v57"  "v58"  "v59"  "v60"  "v61" 
"v62"
"v63"  "v64"  "v65"  "v66"  "v67"  "v68"  "v69"  "v70"  "v71"

 [39] "v72"  "v73"  "v74"  "v75"  "v76"  "v77"  "v78"  "v79"  "v80" 
"v81"
"v19"  "v20"  "v21"  "v22"  "v23"  "v24"  "v25"  "v26"  "v27"

 [58] "v28"  "v29"  "v30"  "v31"  "v32"  "v33"  "v34"  "v35"  "v36" 
"v37"
"v38"  "v39"  "v40"  "v41"  "v42"  "v43"  "v44"  "v45"  "v46"

 [77] "v47"  "v48"  "v49"  "v50"  "v51"  "v82"  "v83"  "v84"  "v85" 
"v86"
"v87"  "v88"  "v89"  "v90"  "v91"  "v92"  "v93"  "v94"  "v95"

 [96] "v96"  "v97"  "v98"  "v99"  "v100" "v101" "v102" "v103" "v104" 
"v105"
"v106" "v107" "v108" "v109" "v110" "v111" "v112" "v113" "v114"

(...)

 [856] "v856" "v857" "v858" "v859" "v860" "v861" "v862" "v863" "v864" 
"v865"
"v866" "v867" "v868" "v869" "v870" "v871" "v872" "v873" "v874"

[875] "v875" "v876" "v877" "v878" "v879" "v880" "v881" "v882" "v883" 
"v884"
"v885" "v886" "v887" "v888" "v889" "v890" "v891" "v892" "v893"

[894] "v894" "v895" "v896" "v897" "v898" "v899" "v900" "v901" "v902" 
"v903"
"v904" "v905" "v906" "v907" "v908" "v909" "v910" "v911" "v912"

[913] "v913" "v914" "v915" "v916" "v917" "v918" "v919" "v920" "v921" 
"v922"
"v923" "v924" "v925" "v926" "v927" "v928" "v929" "v930" "v931"



And I want obtain another dataset with sort columns names, and I do 
this:



data1<-data[,sort(colnames(data))]



names(data1)



[1] "v1"   "v10"  "v100" "v101" "v102" "v103" "v104" "v105" "v106" 
"v107"
"v108" "v109" "v11"  "v110" "v111" "v112" "v113" "v114" "v115"

 [20] "v116" "v117" "v118" "v119" "v12"  "v120" "v121" "v122" "v123" 
"v124"
"v125" "v126" "v127" "v128" "v129" "v13"  "v130" "v131" "v132"

 [39] "v133" "v134" "v135" "v136" "v137" "v138" "v139" "v14"  "v140" 
"v141"
"v142" "v143" "v144" "v145" "v146" "v147" "v148" "v149" "v15"

 [58] "v150" "v151" "v152" "v153" "v154" "v155" "v156" "v157" "v158" 
"v159"
"v16"  "v160" "v161" "v162" "v163" "v164" "v165" "v166" "v167"

 [77] "v168" "v169" "v17"  "v170" "v171" "v172" "v173" "v174" "v175" 
"v176"
"v177" "v178" "v179" "v18"  "v180" "v181" "v182" "v183" "v184"

 [96] "v185" "v186" "v187" "v188" "v189" "v19"  "v190" "v191" "v192" 
"v193"
"v194" "v195" "v196" "v197" "v198" "v199" "v2"   "v20"  "v200"

[115] "v201" "v202" "v203" "v204" "v205" "v206" "v207" "v208" "v209" 
"v21"
"v210" "v211" "v212" "v213" "v214" "v215" "v216" "v217" "v218"

[134] "v219" "v22"  "v220" "v221" "v222" "v223" "v224" "v225" "v226" 
"v227"
"v228" "v229" "v23"  "v230" "v231" "v232" "v233" "v234" "v235"

(...)

[856] "v87"  "v870" "v871" "v872" "v873" "v874" "v875" "v876" "v877" 
"v878"
"v879" "v88"  "v880" "v881" "v882" "v883" "v884" "v885" "v886"

[875] "v887" "v888" "v889" "v89"  "v890" "v891" "v892" "v893" "v894" 
"v895"
"v896" "v897" "v898" "v899" "v9"   "v90"  "v900" "v901" "v902"

[894] "v903" "v904" "v905" "v906" "v907" "v908" "v909" "v91"  "v910" 
"v911"
"v912" "v913" "v914" "v915" "v916" "v917" "v918" "v919" "v92"

[913] "v920" "v921" "v922" "v923" "v924" "v925" "v926" "v927" "v928" 
"v929"
"v93"  "v930" "v931" "v94"  "v95"  "v96"  "v97"  "v98"  "v99"





But I would like obtain, something like this: "v1"  "v2"  "v3" "v4" 
"v5"
"v6"  (...)   "v928"  "v929"  "v930" "v931"



It's possible?



Thanks in advance



Ana Quiterio



Ana Quiterio

INE - DME
Servi??o de Metodos Estatisticos
Tel: +351 21 842 61 00 (Ext: 3222)
E-mail: ana.quiterio at ine.pt <mailto:ana.quiterio at ine.pt>

Lisbon/Portugal












[[alternative HTML version deleted]]




--------------------------------------------------------------------------------


> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From Alexander.Ploner at meb.ki.se  Wed Feb  1 14:24:35 2006
From: Alexander.Ploner at meb.ki.se (Alexander Ploner)
Date: Wed, 1 Feb 2006 14:24:35 +0100
Subject: [R] R CMD check barfs at 'suggested' package
Message-ID: <EE1E4081-5E46-4475-A468-FB9C4040000F@meb.ki.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/ce3a15e7/attachment.pl

From Gerbehj at unisa.ac.za  Wed Feb  1 14:29:48 2006
From: Gerbehj at unisa.ac.za (H J Gerber)
Date: Wed, 01 Feb 2006 15:29:48 +0200
Subject: [R] Off topic: nonparametric regression
Message-ID: <s3e0d3fb.064@CONN-GW.unisa.ac.za>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/7dfef6b8/attachment.pl

From Reinecke at consultic.com  Wed Feb  1 15:14:03 2006
From: Reinecke at consultic.com (Michael Reinecke)
Date: Wed, 1 Feb 2006 15:14:03 +0100
Subject: [R] Off topic: nonparametric regression
Message-ID: <D1A363788EC8F946A56DAF95C0FBE7CF196D52@sbs2003.CMI.local>

 
I think H??rdle is a good author, but I just know some parts of his book "Applied Multivariate Statistical Analysis". In case you don ??t know, you find both books as full text on the site http://www.xplore-stat.de/ebooks/ebooks.html . So if you don ??t have it at home/office, you may easily have a look, without running to the library.
 

-----Urspr??ngliche Nachricht-----
Von: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] Im Auftrag von H J Gerber
Gesendet: Mittwoch, 1. Februar 2006 14:46
An: r-help at stat.math.ethz.ch
Betreff: [R] Off topic: nonparametric regression

Hi All,
 
What do you consider to be the best book(reference) on nonparametric regression? 
I am currently reading the book of Kunio Takezawa(2006): "Introduction to nonparametric regression".
Is the book of Hardle(1990): "Applied nonparametric regression"  better? or maybe another book?
This is off topic, but most of the books is using R or S-plus.
 
Thanks
Hennie 


---------------------------------------------------------------------------
This message (and attachments) is subject to restrictions and a disclaimer.
Please refer to http://www.unisa.ac.za/disclaimer for full details.
---------------------------------------------------------------------------
<<<<gwavasig>>>>
<<<< gwavasig >>>>
	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Lucy.Crooks at env.ethz.ch  Wed Feb  1 15:14:41 2006
From: Lucy.Crooks at env.ethz.ch (Lucy Crooks)
Date: Wed, 1 Feb 2006 15:14:41 +0100
Subject: [R] memory limit in aov
Message-ID: <9ACED283-2FE7-4E10-A845-E7BF4D6F69D7@env.ethz.ch>

I want to do an unbalanced anova on 272,992 observations with 405  
factors including 2-way interactions between 1 of these factors and  
the other 404. After fitting only 11 factors and their interactions I  
get error messages like:

Error: cannot allocate vector of size 1433066 Kb
R(365,0xa000ed68) malloc: *** vm_allocate(size=1467461632) failed  
(error code=3)
R(365,0xa000ed68) malloc: *** error: can't allocate region
R(365,0xa000ed68) malloc: *** set a breakpoint in szone_error to debug

I think that the anova involves a matrix of 272,992 rows by 29025  
columns (using dummy variables)=7,900 million elements. I realise  
this is a lot! Could I solve this if I had more RAM or is it just too  
big?

Another possibility is to do 16 separate analyses on 17,062  
observations with 404 factors (although statistically I think the  
first approach is preferable). I get similar error messages then:

Error: cannot allocate vector of size 175685 Kb
R(365,0xa000ed68) malloc: *** vm_allocate(size=179904512) failed  
(error code=3)

I think this analysis requires a 31 million element matrix.

I am using R version 2.2.1 on a Mac G5 with 1 GB RAM running OS  
10.4.4. Can somebody tell me what the limitations of my machine (or  
R) are likely to be? Whether this smaller analysis is feasible? and  
if so how much more memory I might require?

The data is in R in a data frame of 272,992 rows by 406 columns. I  
would really appreciate any helpful input.

Lucy Crooks
Theoretical Biology
ETH Zurich



From deshon at msu.edu  Wed Feb  1 15:23:14 2006
From: deshon at msu.edu (Rick DeShon)
Date: Wed, 1 Feb 2006 09:23:14 -0500
Subject: [R] Scatterplot color options in CAR package?
Message-ID: <c3cb73d50602010623k123d995cu88c899c4b61b385e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/7265aacc/attachment.pl

From lizzylaws at yahoo.com  Wed Feb  1 15:43:26 2006
From: lizzylaws at yahoo.com (Elizabeth Lawson)
Date: Wed, 1 Feb 2006 06:43:26 -0800 (PST)
Subject: [R] norm package prelim.norm
Message-ID: <20060201144326.67982.qmail@web32108.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/e07d0bf2/attachment.pl

From jfox at mcmaster.ca  Wed Feb  1 15:43:46 2006
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 1 Feb 2006 09:43:46 -0500
Subject: [R] Scatterplot color options in CAR package?
In-Reply-To: <c3cb73d50602010623k123d995cu88c899c4b61b385e@mail.gmail.com>
Message-ID: <20060201144343.TKNZ23065.tomts43-srv.bellnexxia.net@JohnDesktop8300>

Dear Rick,

Setting par(col="red") will change the axes, frame, and tick labels, to red.
Setting par(col.lab="red") will change the axis label to red as well. For
more information, and possibly other relevant graphical parameters, see
?par.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Rick DeShon
> Sent: Wednesday, February 01, 2006 9:23 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Scatterplot color options in CAR package?
> 
> Hi All.
> 
> I'd like to change the default plotting colors used to 
> construct a scatterplot with regression line in the CAR package.
> 
> So,
> 
> scatterplot(y~pred,smooth=FALSE, xlab="X", ylab="Y", lwd=2)
> 
> If I change the palette (e.g., palette(ranbow(6)), I can 
> change the color of the lines and points.
> 
> However, the axes and labels remain in black (i.e., the first 
> color in the default palette).
> 
> Is there a way to change the color used to when forming the 
> axes, labels, and ticks in the Scatterplot routine?
> 
> Thanks in advance for any ideas!
> 
> Rick
> 
> 
> 
> --
> Rick DeShon
> 306 Psychology Building
> Department of Psychology
> Michigan State University
> East Lansing, MI 48824-1116
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Wed Feb  1 15:45:52 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Feb 2006 15:45:52 +0100
Subject: [R] memory limit in aov
In-Reply-To: <9ACED283-2FE7-4E10-A845-E7BF4D6F69D7@env.ethz.ch>
References: <9ACED283-2FE7-4E10-A845-E7BF4D6F69D7@env.ethz.ch>
Message-ID: <x2r76nyw67.fsf@viggo.kubism.ku.dk>

Lucy Crooks <Lucy.Crooks at env.ethz.ch> writes:

> I want to do an unbalanced anova on 272,992 observations with 405  
> factors including 2-way interactions between 1 of these factors and  
> the other 404. After fitting only 11 factors and their interactions I  
> get error messages like:
> 
> Error: cannot allocate vector of size 1433066 Kb
> R(365,0xa000ed68) malloc: *** vm_allocate(size=1467461632) failed  
> (error code=3)
> R(365,0xa000ed68) malloc: *** error: can't allocate region
> R(365,0xa000ed68) malloc: *** set a breakpoint in szone_error to debug
> 
> I think that the anova involves a matrix of 272,992 rows by 29025  
> columns (using dummy variables)=7,900 million elements. I realise  
> this is a lot! Could I solve this if I had more RAM or is it just too  
> big?
> 
> Another possibility is to do 16 separate analyses on 17,062  
> observations with 404 factors (although statistically I think the  
> first approach is preferable). I get similar error messages then:
> 
> Error: cannot allocate vector of size 175685 Kb
> R(365,0xa000ed68) malloc: *** vm_allocate(size=179904512) failed  
> (error code=3)
> 
> I think this analysis requires a 31 million element matrix.
> 
> I am using R version 2.2.1 on a Mac G5 with 1 GB RAM running OS  
> 10.4.4. Can somebody tell me what the limitations of my machine (or  
> R) are likely to be? Whether this smaller analysis is feasible? and  
> if so how much more memory I might require?
> 
> The data is in R in a data frame of 272,992 rows by 406 columns. I  
> would really appreciate any helpful input.


You do not want to use aov() on unbalanced data, and especially not on
large data sets if random effects are involved. Rather, you need to
look at lmer() or just lm() if no random effects are present. 

However, even so, if you really have 29025 parameters to estimate, I
think you're out of luck. 8 billion (US) elements is 64G and R is not
able to handle objects of that size - the limit is that the size must
fit in a 32 bit integer (about 2 billion elements).

A quick calculation suggests that your factors have around 8 levels
each. Is that really necessary, or can you perhaps collapse some
levels? 



-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Wed Feb  1 16:05:04 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Feb 2006 16:05:04 +0100
Subject: [R] norm package prelim.norm
In-Reply-To: <20060201144326.67982.qmail@web32108.mail.mud.yahoo.com>
References: <20060201144326.67982.qmail@web32108.mail.mud.yahoo.com>
Message-ID: <x2ek2nyva7.fsf@viggo.kubism.ku.dk>

Elizabeth Lawson <lizzylaws at yahoo.com> writes:

> Hey eveyone!  I hope someone can help wiht this question.  I have a matirux of all zeros and ones and I would like to indentify all unique patterns in the rows andthe number of times the pattern occurs.   I changed all zeros to NA tried to use prelim.norm to identify all patterns of missing data in the rows.  I got the message 
>    
>   Warning message:
> NAs introduced by coercion 
> 
>   Any ideas of how to get this to work?  Or are there any way to indentify all the unique patterns in a huge matrix? ( 10000 x 71)
>    
>   Thanks for any suggestions!!

unique() has a matrix method.

For tabulation, you might consider a modification of unique.matrix. Or
maybe aggregate() or by() will do the trick.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From rvaradhan at jhmi.edu  Wed Feb  1 16:08:53 2006
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Wed, 1 Feb 2006 10:08:53 -0500
Subject: [R] Multiple xyplots on the same page
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED792@usctmx1106.merck.com>
Message-ID: <000001c62741$6a31e490$7c94100a@win.ad.jhu.edu>

Thank you very much, Andy.  It was quite helpful, and I was able to plot 4
xyplots on one page, but I still couldn't get the legends to fit properly
within each plot, as they were not scaled down automatically. Any hints on
how I can shrink the size of legend in each plot to fit?

Thanks,
Ravi.


> -----Original Message-----
> From: Liaw, Andy [mailto:andy_liaw at merck.com]
> Sent: Tuesday, January 31, 2006 1:04 PM
> To: 'Ravi Varadhan'; r-help at stat.math.ethz.ch
> Subject: RE: [R] Multiple xyplots on the same page
> 
> See ?print.trellis.
> 
> Andy
> 
> From: Ravi Varadhan
> >
> > Hi,
> >
> >
> >
> > I am using the "xyplot" function in the "lattice" package to generate
> > multiple plots, but I would like to have them plotted on the
> > same page.  I
> > would like to set something equivalent to the command:
> > par(mfrow=c(2,2)),
> > in order that I can plot 4 xyplots on the same page.  How can
> > I do this in
> > "xyplot"?
> >
> > I am using R version 2.1.1 on Windows.
> >
> >
> >
> > Thanks very much,
> >
> > Ravi.
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >
> 
> 
> --------------------------------------------------------------------------
> ----
> Notice:  This e-mail message, together with any attachment...{{dropped}}



From ccleland at optonline.net  Wed Feb  1 16:11:23 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 01 Feb 2006 10:11:23 -0500
Subject: [R] norm package prelim.norm
In-Reply-To: <20060201144326.67982.qmail@web32108.mail.mud.yahoo.com>
References: <20060201144326.67982.qmail@web32108.mail.mud.yahoo.com>
Message-ID: <43E0CF9A.7060802@optonline.net>

   Others will certainly suggest more efficient ways to do this, but 
here is an inefficient approach:

 > X <- matrix(sample(c(0,1), 10000*3, replace=TRUE), ncol=3)
 > t(t(table(apply(X, 1, paste, collapse=""))))

       [,1]
   000 1197
   001 1238
   010 1245
   011 1230
   100 1331
   101 1259
   110 1247
   111 1253

   You are getting a warning and not an error from prelim.norm(), and 
the answer it gives seems to match the approach above.

 > library(norm)
 > X <- apply(X, 2, function(x){replace(x, x == 0, NA)})
 > prelim.norm(X)$r
      [,1] [,2] [,3]
1253    1    1    1
1230    0    1    1
1259    1    0    1
1238    0    0    1
1247    1    1    0
1245    0    1    0
1331    1    0    0
1197    0    0    0

hope this helps,

Chuck

Elizabeth Lawson wrote:
> Hey eveyone!  I hope someone can help wiht this question.  I have a matirux of all zeros and ones and I would like to indentify all unique patterns in the rows andthe number of times the pattern occurs.   I changed all zeros to NA tried to use prelim.norm to identify all patterns of missing data in the rows.  I got the message 
>    
>   Warning message:
> NAs introduced by coercion 
> 
>   Any ideas of how to get this to work?  Or are there any way to indentify all the unique patterns in a huge matrix? ( 10000 x 71)
>    
>   Thanks for any suggestions!!
>    
>   Elizabeth Lawson
> 
> 			
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ripley at stats.ox.ac.uk  Wed Feb  1 16:12:38 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Feb 2006 15:12:38 +0000 (GMT)
Subject: [R] R CMD check barfs at 'suggested' package
In-Reply-To: <EE1E4081-5E46-4475-A468-FB9C4040000F@meb.ki.se>
References: <EE1E4081-5E46-4475-A468-FB9C4040000F@meb.ki.se>
Message-ID: <Pine.LNX.4.61.0602011455510.22886@gannet.stats>

R never reloads a package if not asked to, and it is usually users (not R) 
who `get confused'.

Specifying Suggests: multtest just tells 'check' that it needs to be 
available: it does not tell R to load it.  (It also tells install.packages 
enough to install it if you asked for dependencies to be installed.)

This appears to stem from an error in multtest.  The example-checking 
tests (and not R generically) do try to reset the environment after each 
example, and that includes detaching packages that the example caused to 
be loaded.  Detaching a package does not unload its DLL, but a package's 
.Last.lib can do so.  However, multtest does so incorrectly, via a call to 
dyn.unload not library.dynam.unload.

Namespaces will not help as multtest does not have one (at least in the 
version I looked at).

I suggest R-devel would be a better list for questions about developing 
packages.  (But for now please take this up with multtest maintainer.)


On Wed, 1 Feb 2006, Alexander Ploner wrote:

> I have been running R CMD check for the first time on of our own
> packages, which otherwise builds, installs and runs just fine. The
> package depends on package akima and suggests package multtest;
> suggesting multtest is indicated because a) it loads a lot of other
> Bioconductor packages, very slowly, and b) it is only needed for one
> specific subroutine, which executes require(multtest) every time it's
> called.
>
> Now, when I run R CMD check on our package, it terminates when
> checking the examples in the documentation, claiming that
>
> Error in .C("get_stat", as.double(tmp$X), as.integer(tmp$m),
> as.integer(tmp$n),  :
>         "C" function name not in DLL for package 'multtest'
> Execution halted
>
> A closer look at  the output in the -Ex.Rout file shows that this
> does indeed happen when calling the function mt.teststat in multtest,
> to which this piece of code belongs. It also shows however, that this
> only happens in the *second* chunk of example code containing the
> calling function; before that, three calls to the offending function
> in the first chunk (ie in a different .Rd file) are executed just
> fine. Furthermore, if I change the status of multtest from Suggests
> to Depends in the DESCRIPTION file, R CMD check processes our package
> without problem.
>
> My impression is that R gets confused when re-loading multtest for
> the second chunk of example code (for what it's worth, the
> offending .C("get_stat"...) does have a PACKAGE argument).
>
> My question now: Is there any way of avoiding this problem without
> loading multtest by default? Would e.g. using a namespace help? If
> so, how specifically? Etc.?
>
> Thanks for your time (and expertise),
>
> alexander
>
>
> platform powerpc-apple-darwin7.9.0
> arch     powerpc
> os       darwin7.9.0
> system   powerpc, darwin7.9.0
> status   Patched
> major    2
> minor    1.0
> year     2005
> month    05
> day      12
> language R
>
>
> Alexander.Ploner at ki.se
> Medical Epidemiology & Biostatistics
> Karolinska Institutet, Stockholm
> Tel: ++46-8-524-82329
> Fax: ++46-8-31 49 75
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pinard at iro.umontreal.ca  Wed Feb  1 16:21:35 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Wed, 1 Feb 2006 10:21:35 -0500
Subject: [R] Difficulty with qqline in logarithmic context
Message-ID: <20060201152135.GA10720@phenix.sram.qc.ca>

Hi, R friends.  I had some difficulty with the following code:

   qqnorm(freq, log='y')
   qqline(freq)

as the line drawn was seemingly random.  The exact data I used appears 
below.  After wandering a bit within the source code for "abline", 
I figured out I should rather write:

   qqnorm(freq, log='y')
   par(ylog=FALSE)
   qqline(log10(freq))
   par(ylog=TRUE)

I'm proposing that this little stunt be rather be hidden and 
automatically effected within "qqline" proper, whenever par('ylog') is 
TRUE.  I thought about providing a patch, as "qqline" is so small.  Yet 
it would be more noise than useful, as I'm not familiar with the "datax" 
argument usage, which should probably be addressed as well.



Here is the data, in case useful:

freq <-
as.integer(c(33, 79, 21, 436, 58, 18, 1106, 498, 1567, 393, 2, 
104, 50, 67, 113, 76, 327, 331, 196, 145, 86, 59, 12, 215, 293, 
154, 500, 314, 246, 587, 85, 23, 323, 3, 13, 576, 29, 37, 24, 
21, 1230, 137, 13, 93, 3, 101, 72, 218, 59, 17, 2, 8, 86, 143, 
150, 22, 19, 234, 119, 157, 4, 255, 146, 126, 76, 15, 271, 170, 
4, 6, 16, 3048, 2175, 3350, 5017, 5706, 1610, 665, 322, 1, 16, 
47, 51, 168, 94, 66, 154, 99, 11, 547, 953, 1, 1071, 80, 184, 
168, 52, 187, 103, 187, 361, 46, 85, 135, 597, 121, 283, 26, 
12, 20, 169, 9, 79, 15, 114, 75, 30, 111, 556, 173, 32, 99, 438, 
2, 2, 1, 117, 5, 3, 51, 8, 41, 12, 23, 2, 13, 5, 1, 9, 4, 1, 
7, 15, 5, 48, 16, 112, 6, 1, 39, 60, 5, 23, 5, 19, 1, 8, 32, 
4, 13, 1, 14, 71, 5, 1, 35, 30, 100, 389, 22, 8, 1, 192, 40, 
6, 3, 17, 2, 14, 71, 14, 1, 5, 4, 32, 21, 18, 13, 2, 2, 45, 342, 
46, 144, 18, 131, 188, 112, 37, 85, 90, 8, 195, 173, 5, 53, 96, 
37, 16, 16, 281, 64, 50, 92, 336, 31, 744, 4, 134, 74, 1, 227, 
6, 48, 418, 64, 66, 59, 20, 45, 20, 370, 148, 22, 7, 30, 601, 
29, 82, 113, 938, 252, 65, 137, 72, 22, 98, 12, 152, 212, 13, 
8, 35, 3, 77))

Yet this really is the value of "courriel$freq" after "data(courriel)", 
with a file ".../R/data/courriel.R" here, holding:

courriel <- read.table(pipe('grep -c \'^From \' ../courriel/*'),
                       sep=':', as.is=T, row.names=1,
                       col.names=c('fichier', 'freq'))

My goal, which is nothing serious, was merely to toy with the number of 
messages per folder, for folders massaged out of R archives.



Version:
 platform = i686-pc-linux-gnu
 arch = i686
 os = linux-gnu
 system = i686, linux-gnu
 status = 
 major = 2
 minor = 2.1
 year = 2005
 month = 12
 day = 20
 svn rev = 36812
 language = R

Locale:
LC_CTYPE=fr_CA.UTF-8;LC_NUMERIC=C;LC_TIME=fr_CA.UTF-8;LC_COLLATE=fr_CA.UTF-8;LC_MONETARY=fr_CA.UTF-8;LC_MESSAGES=fr_CA.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C

Search Path:
 .GlobalEnv, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, fp.etc, Autoloads, package:base


-- 
Fran??ois Pinard   http://pinard.progiciels-bpi.ca



From ripley at stats.ox.ac.uk  Wed Feb  1 16:24:18 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Feb 2006 15:24:18 +0000 (GMT)
Subject: [R] Write.table: change points to commas when object contains a
 row of characters
In-Reply-To: <D1A363788EC8F946A56DAF95C0FBE7CF196CDA@sbs2003.CMI.local>
References: <D1A363788EC8F946A56DAF95C0FBE7CF196CDA@sbs2003.CMI.local>
Message-ID: <Pine.LNX.4.61.0602011516511.22886@gannet.stats>

You cannot have a matrix or a data frame which is partially numeric and 
partially character (within a column for a data frame).  You seem rather 
to have a list matrix.  Then ?write.table does say

      Any columns in a data frame which are lists or have a class (e.g.
      dates) will be converted by the appropriate 'as.character' method:
      such columns are unquoted by default.  On the other hand, any
      class information for a matrix is discarded.

Although it does not say so, the same happens with a matrix.

You need to get a table before you try outputting it: I suggest using 
format() to help you.

On Wed, 1 Feb 2006, Michael Reinecke wrote:

> Dear Group! I asked write.table to change the decimal point from "." to
> "," , but apparently it would only do so if the object to be written
> does not contain any character elements. I would like to understand, why
> this has to be so and - of course - find a solution for my matrix object
> jjmat, that I tried to write out by
>
>
>
> write.table(jjmat, file="jjmat.txt", row.names=TRUE,
> col.names=NA,sep="\t",dec=",")
>
>
>
> I also tried "options(OutDec=",")" , which changes the presentation on
> the console, but seems to have no influence on write table: jjmat is
> still written out with points instead of commas.
>
>
>
> The object looks like this:
>
>
>
>> jjmat
>
>         f2a1       f2b1       f5a1       f5b1       f5c1
>
> rowname1 "coltext1" "coltext2" "coltext3" "coltext4" "coltext5"
>
> rowname2 4,428571   4,326531   4,265306   3,959184   3,306122
>
> rowname3 0,469665   0,3328301  0,1776079  -0,1758072 0,0870965
>
> rowname4 4,275862   4,206897   4,137931   3,931034   3,379310
>
>
>
>> deparse(jjmat)
>
> [1] "structure(list(\"coltext1\", 4.42857142857143, 0.469664970752337, "
>
>
> [2] "    4.27586206896552, \"coltext2\", 4.3265306122449,
> 0.332830055973803, "
>
> [3] "    4.20689655172414, \"coltext3\", 4.26530612244898,
> 0.177607859264292, "
>
> [4] "    4.13793103448276, \"coltext4\", 3.95918367346939,
> -0.175807245137424, "
>
> [5] "    3.93103448275862, \"coltext5\", 3.30612244897959,
> 0.087096493847482, "
>
> [6] "    3.37931034482759), .Dim = c(4, 5), .Dimnames =
> list(c(\"rowname1\", "
>
> [7] "\"rowname2\", \"rowname3\", \"rowname4\"), c(\"f2a1\", \"f2b1\",
> \"f5a1\", "
>
> [8] "\"f5b1\", \"f5c1\")))"
>
>
>
>
>
> Do I have to change the structure of jjmat? Thanks for your comments!
>
>
>
> Greetings,
>
>
>
> Michael
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lizzylaws at yahoo.com  Wed Feb  1 16:30:30 2006
From: lizzylaws at yahoo.com (Elizabeth Lawson)
Date: Wed, 1 Feb 2006 07:30:30 -0800 (PST)
Subject: [R] norm package prelim.norm
In-Reply-To: <43E0CF9A.7060802@optonline.net>
Message-ID: <20060201153030.97386.qmail@web32114.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/312d7414/attachment.pl

From Ted.Harding at nessie.mcc.ac.uk  Wed Feb  1 16:44:38 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 01 Feb 2006 15:44:38 -0000 (GMT)
Subject: [R] norm package prelim.norm
In-Reply-To: <20060201144326.67982.qmail@web32108.mail.mud.yahoo.com>
Message-ID: <XFMail.060201154438.Ted.Harding@nessie.mcc.ac.uk>

On 01-Feb-06 Elizabeth Lawson wrote:
> Hey eveyone!  I hope someone can help wiht this question.  I have a
> matirux of all zeros and ones and I would like to indentify all unique
> patterns in the rows andthe number of times the pattern occurs.   I
> changed all zeros to NA tried to use prelim.norm to identify all
> patterns of missing data in the rows.  I got the message 
>    
>   Warning message:
> NAs introduced by coercion 
> 
>   Any ideas of how to get this to work?  Or are there any way to
> indentify all the unique patterns in a huge matrix? ( 10000 x 71)
>    
>   Thanks for any suggestions!!
>    
>   Elizabeth Lawson

I think Chuck Celand has pretty well answered it: Don't worry
about the warning, since I'm pretty sure it is generated when
prelim.norm is calculating something else (e.g. the covariance
matrix) and it is not related to generating prelim.norm(X)$r
which is the list of patterns and the numbers of times they occur.

Best wsihes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 01-Feb-06                                       Time: 15:44:34
------------------------------ XFMail ------------------------------



From andy_liaw at merck.com  Wed Feb  1 17:01:28 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 1 Feb 2006 11:01:28 -0500
Subject: [R] Multiple xyplots on the same page
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7A6@usctmx1106.merck.com>

Sorry, that's beyond me.  I've never tried that myself.

Andy

From: Ravi Varadhan 
> 
> Thank you very much, Andy.  It was quite helpful, and I was 
> able to plot 4
> xyplots on one page, but I still couldn't get the legends to 
> fit properly
> within each plot, as they were not scaled down automatically. 
> Any hints on
> how I can shrink the size of legend in each plot to fit?
> 
> Thanks,
> Ravi.
> 
> 
> > -----Original Message-----
> > From: Liaw, Andy [mailto:andy_liaw at merck.com]
> > Sent: Tuesday, January 31, 2006 1:04 PM
> > To: 'Ravi Varadhan'; r-help at stat.math.ethz.ch
> > Subject: RE: [R] Multiple xyplots on the same page
> > 
> > See ?print.trellis.
> > 
> > Andy
> > 
> > From: Ravi Varadhan
> > >
> > > Hi,
> > >
> > >
> > >
> > > I am using the "xyplot" function in the "lattice" package 
> to generate
> > > multiple plots, but I would like to have them plotted on the
> > > same page.  I
> > > would like to set something equivalent to the command:
> > > par(mfrow=c(2,2)),
> > > in order that I can plot 4 xyplots on the same page.  How can
> > > I do this in
> > > "xyplot"?
> > >
> > > I am using R version 2.1.1 on Windows.
> > >
> > >
> > >
> > > Thanks very much,
> > >
> > > Ravi.
> > >
> > >
> > > 	[[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> > >
> > 
> > 
> > 
> --------------------------------------------------------------
> ------------
> > ----
> > Notice:  This e-mail message, together with any 
> attachments, contains
> > information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New
> > Jersey, USA 08889), and/or its affiliates (which may be 
> known outside the
> > United States as Merck Frosst, Merck Sharp & Dohme or MSD 
> and in Japan, as
> > Banyu) that may be confidential, proprietary copyrighted 
> and/or legally
> > privileged. It is intended solely for the use of the 
> individual or entity
> > named on this message.  If you are not the intended 
> recipient, and have
> > received this message in error, please notify us 
> immediately by reply e-
> > mail and then delete it from your system.
> > 
> --------------------------------------------------------------
> ------------
> > ----
> 
>



From ginsburg at uthscsa.edu  Wed Feb  1 17:06:04 2006
From: ginsburg at uthscsa.edu (Brett Ginsburg)
Date: Wed, 01 Feb 2006 10:06:04 -0600
Subject: [R] Broken x-axis?
Message-ID: <C006388C.2E8%ginsburg@uthscsa.edu>

Hello, 
Sorry for the double post, but I just subscribed....

Does anyone have experience creating a graph with a segmented x-axis?

Specifically, as a pharmacologist, I frequently need to create a graph with
2 segments, one for vehicle, and one for active doses.

Here is an example...

|
|
|
|
 |----|   |----------------|
 Vehicle    1  3  10  30  etc..
              Doses

Any help is appreciated!

Thanks,

Dr. Brett C. Ginsburg
Division of Alcohol and Drug Addiction
Department of Psychiatry
The University of Texas Health Science Center at San Antonio
7703 Floyd Curl Dr.
San Antonio, TX 78229

Phone: 210-567-0871
FAX:   210-567-5381



From ripley at stats.ox.ac.uk  Wed Feb  1 17:06:16 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Feb 2006 16:06:16 +0000 (GMT)
Subject: [R] Difficulty with qqline in logarithmic context
In-Reply-To: <20060201152135.GA10720@phenix.sram.qc.ca>
References: <20060201152135.GA10720@phenix.sram.qc.ca>
Message-ID: <Pine.LNX.4.61.0602011552110.23477@gannet.stats>

Is there a good reason to use qqnorm in a single-log context?  Should one 
not rather use

> qqnorm(log(freq))
> qqline(log(freq))

since you are (I guess) looking at log-normality of freq?  Another way 
to look at that is

> qqplot(qlnorm(ppoints(length(freq))), freq, log="xy")

the same plot, different scales.  (I believe a QQ plot should always have 
comparable scales on the two axes.)

The point is that qqline is tied to normality, not to log-normality.

On Wed, 1 Feb 2006, Fran?ois Pinard wrote:

> Hi, R friends.  I had some difficulty with the following code:
>
>   qqnorm(freq, log='y')
>   qqline(freq)
>
> as the line drawn was seemingly random.  The exact data I used appears
> below.  After wandering a bit within the source code for "abline",
> I figured out I should rather write:
>
>   qqnorm(freq, log='y')
>   par(ylog=FALSE)
>   qqline(log10(freq))
>   par(ylog=TRUE)
>
> I'm proposing that this little stunt be rather be hidden and
> automatically effected within "qqline" proper, whenever par('ylog') is
> TRUE.  I thought about providing a patch, as "qqline" is so small.  Yet
> it would be more noise than useful, as I'm not familiar with the "datax"
> argument usage, which should probably be addressed as well.
>
>
>
> Here is the data, in case useful:
>
> freq <-
> as.integer(c(33, 79, 21, 436, 58, 18, 1106, 498, 1567, 393, 2,
> 104, 50, 67, 113, 76, 327, 331, 196, 145, 86, 59, 12, 215, 293,
> 154, 500, 314, 246, 587, 85, 23, 323, 3, 13, 576, 29, 37, 24,
> 21, 1230, 137, 13, 93, 3, 101, 72, 218, 59, 17, 2, 8, 86, 143,
> 150, 22, 19, 234, 119, 157, 4, 255, 146, 126, 76, 15, 271, 170,
> 4, 6, 16, 3048, 2175, 3350, 5017, 5706, 1610, 665, 322, 1, 16,
> 47, 51, 168, 94, 66, 154, 99, 11, 547, 953, 1, 1071, 80, 184,
> 168, 52, 187, 103, 187, 361, 46, 85, 135, 597, 121, 283, 26,
> 12, 20, 169, 9, 79, 15, 114, 75, 30, 111, 556, 173, 32, 99, 438,
> 2, 2, 1, 117, 5, 3, 51, 8, 41, 12, 23, 2, 13, 5, 1, 9, 4, 1,
> 7, 15, 5, 48, 16, 112, 6, 1, 39, 60, 5, 23, 5, 19, 1, 8, 32,
> 4, 13, 1, 14, 71, 5, 1, 35, 30, 100, 389, 22, 8, 1, 192, 40,
> 6, 3, 17, 2, 14, 71, 14, 1, 5, 4, 32, 21, 18, 13, 2, 2, 45, 342,
> 46, 144, 18, 131, 188, 112, 37, 85, 90, 8, 195, 173, 5, 53, 96,
> 37, 16, 16, 281, 64, 50, 92, 336, 31, 744, 4, 134, 74, 1, 227,
> 6, 48, 418, 64, 66, 59, 20, 45, 20, 370, 148, 22, 7, 30, 601,
> 29, 82, 113, 938, 252, 65, 137, 72, 22, 98, 12, 152, 212, 13,
> 8, 35, 3, 77))
>
> Yet this really is the value of "courriel$freq" after "data(courriel)",
> with a file ".../R/data/courriel.R" here, holding:
>
> courriel <- read.table(pipe('grep -c \'^From \' ../courriel/*'),
>                       sep=':', as.is=T, row.names=1,
>                       col.names=c('fichier', 'freq'))
>
> My goal, which is nothing serious, was merely to toy with the number of
> messages per folder, for folders massaged out of R archives.
>
>
>
> Version:
> platform = i686-pc-linux-gnu
> arch = i686
> os = linux-gnu
> system = i686, linux-gnu
> status =
> major = 2
> minor = 2.1
> year = 2005
> month = 12
> day = 20
> svn rev = 36812
> language = R
>
> Locale:
> LC_CTYPE=fr_CA.UTF-8;LC_NUMERIC=C;LC_TIME=fr_CA.UTF-8;LC_COLLATE=fr_CA.UTF-8;LC_MONETARY=fr_CA.UTF-8;LC_MESSAGES=fr_CA.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C
>
> Search Path:
> .GlobalEnv, package:methods, package:stats, package:graphics, package:grDevices, package:utils, package:datasets, fp.etc, Autoloads, package:base
>
>
> -- 
> Fran?ois Pinard   http://pinard.progiciels-bpi.ca
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From gregory.r.warnes at pfizer.com  Wed Feb  1 17:09:23 2006
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Wed, 1 Feb 2006 11:09:23 -0500
Subject: [R] several plots in one
Message-ID: <915D2D65A9986440A277AC5C98AA466F0186383D@groamrexm02.amer.pfizer.com>

If you want two series of plotted confidence intervals, first plot one series using plotCI with the standard arguments, then call plotCI a second time with add=TRUE.  For example:


       data(state)
       tmp   <- split(state.area, state.region)
       means <- sapply(tmp, mean)
       stdev <- sqrt(sapply(tmp, var))
       n     <- sapply(tmp,length)
       ciw   <- qt(0.975, n) * stdev / sqrt(n)

       # First series
       plotCI(x=means, uiw=ciw)

	 # Second series
       plotCI(x=means+1e5, uiw=ciw, add=T)


Note that you may need to manually specify xlim and ylim to ensure that the second series fits on the plot.

-Greg

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of JeeBee
> Sent: Wednesday, February 01, 2006 6:02 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] several plots in one
> 
> 
> Can anyone tell me how I can supply more than one graph to plotCI
> (gplots) at once?
> 
> Below is what I tried, also with rbind instead of cbind.
> What is the way to do this (in general, I think)?
> 
> Problem is that lines of 1-st and 2-nd series are mixed, 
> while they have
> nothing to do with each other.
> 
> I also tried calling plotCI with argument add=TRUE, which 
> didn't seem to
> work (that is actually what I wanted I think).
> (It should look the same as if I called plotCI twice with same
> labels/xlim/ylim/etc.)
> 
>   plotCI(x = cbind(x1,x2),
>          y = cbind(means1,means2), # means1 == ci1["Estimate",]
>          xlim = c(0,100), #ylim = c(0.2,0.5),
>          ylab = "System welfare", 
>          pch = 7, col = c("red","blue"), type = "b",
>          uiw = cbind(uiw1,uiw2))
> 
> Thanks in advance,
> JeeBee.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html
----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From assampryseley at yahoo.com  Wed Feb  1 17:52:58 2006
From: assampryseley at yahoo.com (Pryseley Assam)
Date: Wed, 1 Feb 2006 08:52:58 -0800 (PST)
Subject: [R] Help with functions
Message-ID: <20060201165258.46494.qmail@web37101.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/d924d7a5/attachment.pl

From emanuela_parlato at hotmail.com  Wed Feb  1 18:01:14 2006
From: emanuela_parlato at hotmail.com (emanuela parlato)
Date: Wed,  1 Feb 2006 09:01:14 -0800 (PST)
Subject: [R] Let's share photos
Message-ID: <142105158.1138813274920.JavaMail.ringo@ringo13.tickle.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/d15c923e/attachment.pl

From ana.pmartins at ine.pt  Wed Feb  1 18:04:06 2006
From: ana.pmartins at ine.pt (Ana Patricia Martins)
Date: Wed, 1 Feb 2006 17:04:06 -0000 
Subject: [R]  problem with cbind
Message-ID: <E97312684A84D511BDD40002A50968D607170CE0@lxpobw01.ine.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/5355ce28/attachment.pl

From p.dalgaard at biostat.ku.dk  Wed Feb  1 18:12:50 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Feb 2006 18:12:50 +0100
Subject: [R] Broken x-axis?
In-Reply-To: <C006388C.2E8%ginsburg@uthscsa.edu>
References: <C006388C.2E8%ginsburg@uthscsa.edu>
Message-ID: <x28xsvypd9.fsf@viggo.kubism.ku.dk>

Brett Ginsburg <ginsburg at uthscsa.edu> writes:

> Hello, 
> Sorry for the double post, but I just subscribed....
> 
> Does anyone have experience creating a graph with a segmented x-axis?
> 
> Specifically, as a pharmacologist, I frequently need to create a graph with
> 2 segments, one for vehicle, and one for active doses.
> 
> Here is an example...
> 
> |
> |
> |
> |
>  |----|   |----------------|
>  Vehicle    1  3  10  30  etc..
>               Doses
> 
> Any help is appreciated!

axis.break() in the plotrix package springs to mind. Or, simply use
plot(....axes=F) followed by axis() multiple times with labels= and
at= to get override the default numeric labels (some assembly may be
required if you need to "cheat" the coordinate system).

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From gregory.r.warnes at pfizer.com  Wed Feb  1 18:27:44 2006
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Wed, 1 Feb 2006 12:27:44 -0500
Subject: [R] beginner Q:  hashtable or dictionary?
Message-ID: <915D2D65A9986440A277AC5C98AA466F01863844@groamrexm02.amer.pfizer.com>


Standard R vectors and list elements can given names, and can be accessed by them.  This allows them to be used like the dictionaries or hashes of other languages.

For example

>  x = c("a"=1, "b"=2, "c"=3)
>  x["a"]
a 
1 
> x["foo"] = "bar"
> x["foo"]
  foo 
"bar" 
> x
    a     b     c   foo 
  "1"   "2"   "3" "bar" 

-Greg

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of context grey
> Sent: Sunday, January 29, 2006 8:35 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] beginner Q: hashtable or dictionary?
> 
> 
> Hi,
> 
> Is there something like a hashtable or (python)
> dictionary in R/Splus?
> 
> (If not, is there a reason why it's not needed /
> typical way to accomplish the same thing?)
> 
> Thank you
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From Reinecke at consultic.com  Wed Feb  1 18:30:33 2006
From: Reinecke at consultic.com (Michael Reinecke)
Date: Wed, 1 Feb 2006 18:30:33 +0100
Subject: [R] Write.table: change points to commas when object contains a
	row of characters
Message-ID: <D1A363788EC8F946A56DAF95C0FBE7CF196D73@sbs2003.CMI.local>

Thank you very much! I wonder why I did not yet come across that function format(). Guess this won ??t be the last time that I use it. The following did exactly what I was looking for:

temp<-attributes(jjmat)

jjmat<-format(jjmat, decimal.mark=",")

attributes(jjmat)<-temp

With these changes jjmat was perfect for export to excel.


-----Urspr??ngliche Nachricht-----
Von: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Gesendet: Mittwoch, 1. Februar 2006 16:31
An: Michael Reinecke
Cc: R-help at stat.math.ethz.ch
Betreff: Re: [R] Write.table: change points to commas when object contains a row of characters

You cannot have a matrix or a data frame which is partially numeric and partially character (within a column for a data frame).  You seem rather to have a list matrix.  Then ?write.table does say

      Any columns in a data frame which are lists or have a class (e.g.
      dates) will be converted by the appropriate 'as.character' method:
      such columns are unquoted by default.  On the other hand, any
      class information for a matrix is discarded.

Although it does not say so, the same happens with a matrix.

You need to get a table before you try outputting it: I suggest using
format() to help you.

On Wed, 1 Feb 2006, Michael Reinecke wrote:

> Dear Group! I asked write.table to change the decimal point from "." 
> to "," , but apparently it would only do so if the object to be 
> written does not contain any character elements. I would like to 
> understand, why this has to be so and - of course - find a solution 
> for my matrix object jjmat, that I tried to write out by
>
>
>
> write.table(jjmat, file="jjmat.txt", row.names=TRUE,
> col.names=NA,sep="\t",dec=",")
>
>
>
> I also tried "options(OutDec=",")" , which changes the presentation on 
> the console, but seems to have no influence on write table: jjmat is 
> still written out with points instead of commas.
>
>
>
> The object looks like this:
>
>
>
>> jjmat
>
>         f2a1       f2b1       f5a1       f5b1       f5c1
>
> rowname1 "coltext1" "coltext2" "coltext3" "coltext4" "coltext5"
>
> rowname2 4,428571   4,326531   4,265306   3,959184   3,306122
>
> rowname3 0,469665   0,3328301  0,1776079  -0,1758072 0,0870965
>
> rowname4 4,275862   4,206897   4,137931   3,931034   3,379310
>
>
>
>> deparse(jjmat)
>
> [1] "structure(list(\"coltext1\", 4.42857142857143, 0.469664970752337, "
>
>
> [2] "    4.27586206896552, \"coltext2\", 4.3265306122449,
> 0.332830055973803, "
>
> [3] "    4.20689655172414, \"coltext3\", 4.26530612244898,
> 0.177607859264292, "
>
> [4] "    4.13793103448276, \"coltext4\", 3.95918367346939,
> -0.175807245137424, "
>
> [5] "    3.93103448275862, \"coltext5\", 3.30612244897959,
> 0.087096493847482, "
>
> [6] "    3.37931034482759), .Dim = c(4, 5), .Dimnames =
> list(c(\"rowname1\", "
>
> [7] "\"rowname2\", \"rowname3\", \"rowname4\"), c(\"f2a1\", \"f2b1\", 
> \"f5a1\", "
>
> [8] "\"f5b1\", \"f5c1\")))"
>
>
>
>
>
> Do I have to change the structure of jjmat? Thanks for your comments!
>
>
>
> Greetings,
>
>
>
> Michael
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mailing-lists at rhkoning.com  Wed Feb  1 18:49:48 2006
From: mailing-lists at rhkoning.com (RH Koning)
Date: Wed, 01 Feb 2006 18:49:48 +0100
Subject: [R] inserting one backslash
Message-ID: <43E0F4BC.60404@rhkoning.com>

Hello, I am not very familiar with regular expressions and escaping. I 
need to replace the %-signs in a character vector with elements as 
"income 0%-33%# to be replaced by "income 0\%-33\%" (for later use in 
LaTeX). Using

gsub("%","\\%","income 0%-33%")

does not give the desired result. However, gsub("%","\\\\%","income 
0%-33%") gives "income 0\\%-33\\%", one backslash too much. What is the 
appropriate expression to get the desired output (one backslash before 
each %-sign)?

I am using R 2.1.0 on suse linux 9.2.

Thanks, Ruud



From deepayan.sarkar at gmail.com  Wed Feb  1 18:51:04 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 1 Feb 2006 11:51:04 -0600
Subject: [R] Multiple xyplots on the same page
In-Reply-To: <000001c62741$6a31e490$7c94100a@win.ad.jhu.edu>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED792@usctmx1106.merck.com>
	<000001c62741$6a31e490$7c94100a@win.ad.jhu.edu>
Message-ID: <eb555e660602010951u29560881y68f31d38d99d985c@mail.gmail.com>

On 2/1/06, Ravi Varadhan <rvaradhan at jhmi.edu> wrote:
> Thank you very much, Andy.  It was quite helpful, and I was able to plot 4
> xyplots on one page, but I still couldn't get the legends to fit properly
> within each plot, as they were not scaled down automatically. Any hints on
> how I can shrink the size of legend in each plot to fit?

The parameter to `shrink' things is usually called 'cex' (or some
variation of that). There is (or at least should be) a way to control
the size of each component of a key (described in the documentation).
There's no global way to shrink or expand a key.

Deepayan
--
http://www.stat.wisc.edu/~deepayan/



From valle at di.unito.it  Wed Feb  1 18:57:22 2006
From: valle at di.unito.it (andrea valle)
Date: Wed, 1 Feb 2006 18:57:22 +0100
Subject: [R] 3d from file
Message-ID: <1e96d61e04a8e3940aa6b1d144120e07@di.unito.it>

Dear all,
sorry if it's obvious but I wasn't able to find a solution by myself.

I have a text file filled with 3 colums representing xyz coodinates 
(i.e. positions) of an objects.
Can I have in R a 3d plot representig  my object' s positions?
I guess that I can but I don't know how.

Any help is much appreciated

Thanks a lot


-a-




Andrea Valle
DAMS - Facolt?? di Scienze della Formazione
Universit?? degli Studi di Torino
http://www.semiotiche.it/andrea
andrea.valle at unito.it



From sundar.dorai-raj at pdf.com  Wed Feb  1 19:02:33 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 01 Feb 2006 12:02:33 -0600
Subject: [R] Multiple xyplots on the same page
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7A6@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7A6@usctmx1106.merck.com>
Message-ID: <43E0F7B9.8010205@pdf.com>

Hi, Ravi,

How are you creating the legend? Here's a trivial example where you can 
add a cex argument to "auto.key":

library(lattice)
trellis.par.set(theme = col.whitebg())
xy <- xyplot(decrease ~ treatment, OrchardSprays,
              groups = rowpos, type = "a",
              auto.key = list(x = 0.2, y = 0.9,
                cex = 0.75, points = FALSE, lines = TRUE))

print(xy, pos = c(0.0, 0.0, 0.5, 0.5), more = TRUE)
print(xy, pos = c(0.0, 0.5, 0.5, 1.0), more = TRUE)
print(xy, pos = c(0.5, 0.0, 1.0, 0.5), more = TRUE)
print(xy, pos = c(0.5, 0.5, 1.0, 1.0), more = FALSE)

HTH,

--sundar

Liaw, Andy wrote:
> Sorry, that's beyond me.  I've never tried that myself.
> 
> Andy
> 
> From: Ravi Varadhan 
> 
>>Thank you very much, Andy.  It was quite helpful, and I was 
>>able to plot 4
>>xyplots on one page, but I still couldn't get the legends to 
>>fit properly
>>within each plot, as they were not scaled down automatically. 
>>Any hints on
>>how I can shrink the size of legend in each plot to fit?
>>
>>Thanks,
>>Ravi.
>>
>>
>>
>>>-----Original Message-----
>>>From: Liaw, Andy [mailto:andy_liaw at merck.com]
>>>Sent: Tuesday, January 31, 2006 1:04 PM
>>>To: 'Ravi Varadhan'; r-help at stat.math.ethz.ch
>>>Subject: RE: [R] Multiple xyplots on the same page
>>>
>>>See ?print.trellis.
>>>
>>>Andy
>>>
>>>From: Ravi Varadhan
>>>
>>>>Hi,
>>>>
>>>>
>>>>
>>>>I am using the "xyplot" function in the "lattice" package 
>>
>>to generate
>>
>>>>multiple plots, but I would like to have them plotted on the
>>>>same page.  I
>>>>would like to set something equivalent to the command:
>>>>par(mfrow=c(2,2)),
>>>>in order that I can plot 4 xyplots on the same page.  How can
>>>>I do this in
>>>>"xyplot"?
>>>>
>>>>I am using R version 2.1.1 on Windows.
>>>>
>>>>
>>>>
>>>>Thanks very much,
>>>>
>>>>Ravi.
>>>>
>>>>
>>>>	[[alternative HTML version deleted]]
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide!
>>>>http://www.R-project.org/posting-guide.html
>>>>
>>>>
>>>
>>>
>>>
>>--------------------------------------------------------------
>>------------
>>
>>>----
>>>Notice:  This e-mail message, together with any 
>>
>>attachments, contains
>>
>>>information of Merck & Co., Inc. (One Merck Drive, 
>>
>>Whitehouse Station, New
>>
>>>Jersey, USA 08889), and/or its affiliates (which may be 
>>
>>known outside the
>>
>>>United States as Merck Frosst, Merck Sharp & Dohme or MSD 
>>
>>and in Japan, as
>>
>>>Banyu) that may be confidential, proprietary copyrighted 
>>
>>and/or legally
>>
>>>privileged. It is intended solely for the use of the 
>>
>>individual or entity
>>
>>>named on this message.  If you are not the intended 
>>
>>recipient, and have
>>
>>>received this message in error, please notify us 
>>
>>immediately by reply e-
>>
>>>mail and then delete it from your system.
>>>
>>
>>--------------------------------------------------------------
>>------------
>>
>>>----
>>
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sundar.dorai-raj at pdf.com  Wed Feb  1 19:05:26 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 01 Feb 2006 12:05:26 -0600
Subject: [R] inserting one backslash
In-Reply-To: <43E0F4BC.60404@rhkoning.com>
References: <43E0F4BC.60404@rhkoning.com>
Message-ID: <43E0F866.90101@pdf.com>


RH Koning wrote:
> Hello, I am not very familiar with regular expressions and escaping. I 
> need to replace the %-signs in a character vector with elements as 
> "income 0%-33%# to be replaced by "income 0\%-33\%" (for later use in 
> LaTeX). Using
> 
> gsub("%","\\%","income 0%-33%")
> 
> does not give the desired result. However, gsub("%","\\\\%","income 
> 0%-33%") gives "income 0\\%-33\\%", one backslash too much. What is the 
> appropriate expression to get the desired output (one backslash before 
> each %-sign)?

Actually, you got the answer. See the difference between:

 > gsub("%","\\\\%","income 0%-33%")
[1] "income 0\\%-33\\%"
 > cat(gsub("%","\\\\%","income 0%-33%"))
income 0\%-33\%

HTH,

--sundar



From ripley at stats.ox.ac.uk  Wed Feb  1 19:24:36 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 1 Feb 2006 18:24:36 +0000 (GMT)
Subject: [R] inserting one backslash
In-Reply-To: <43E0F4BC.60404@rhkoning.com>
References: <43E0F4BC.60404@rhkoning.com>
Message-ID: <Pine.LNX.4.61.0602011818130.25212@gannet.stats>

On Wed, 1 Feb 2006, RH Koning wrote:

> Hello, I am not very familiar with regular expressions and escaping. I
> need to replace the %-signs in a character vector with elements as
> "income 0%-33%# to be replaced by "income 0\%-33\%" (for later use in
> LaTeX). Using

You are confusing the object and the printed representation: see ?regexp.

> cat(gsub("%","\\\\%","income 0%-33%"), "\n")
income 0\%-33\%

You really do want the object which prints in R "income 0\\%-33\\%".

> gsub("%","\\%","income 0%-33%")
>
> does not give the desired result. However, gsub("%","\\\\%","income
> 0%-33%") gives "income 0\\%-33\\%", one backslash too much. What is the
> appropriate expression to get the desired output (one backslash before
> each %-sign)?
>
> I am using R 2.1.0 on suse linux 9.2.

Time for an undate (not that it affects this, but how objects print has 
been changed).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Camarda at demogr.mpg.de  Wed Feb  1 19:31:21 2006
From: Camarda at demogr.mpg.de (Camarda, Carlo Giovanni)
Date: Wed, 1 Feb 2006 19:31:21 +0100
Subject: [R] glm-logistic on discrete-time methods with individual and
 aggregated data
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E6C0C3F3@HERMES.demogr.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/e10c7780/attachment.pl

From sfalcon at fhcrc.org  Wed Feb  1 19:40:13 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 01 Feb 2006 10:40:13 -0800
Subject: [R] inserting one backslash
In-Reply-To: <43E0F4BC.60404@rhkoning.com> (RH Koning's message of "Wed,
	01 Feb 2006 18:49:48 +0100")
References: <43E0F4BC.60404@rhkoning.com>
Message-ID: <m2irryexde.fsf@fhcrc.org>

On  1 Feb 2006, mailing-lists at rhkoning.com wrote:

> Hello, I am not very familiar with regular expressions and
> escaping. I need to replace the %-signs in a character vector with
> elements as "income 0%-33%# to be replaced by "income 0\%-33\%" (for
> later use in LaTeX). Using
>
> gsub("%","\\%","income 0%-33%")
>
> does not give the desired result. However, gsub("%","\\\\%","income
> 0%-33%") gives "income 0\\%-33\\%", one backslash too much. What is
> the appropriate expression to get the desired output (one backslash
> before each %-sign)?

I think you are on the right track with the second pattern "\\\\%".
There is a difference between what print(s) will display and what
cat(s) will display.  


> gsub("%", "\\\\%", "income 0%-33%")
[1] "income 0\\%-33\\%"

> cat(gsub("%", "\\\\%", "income 0%-33%"), "\n")
income 0\%-33\%  

The string "\\" in R contains one character (see nchar()), not two.  
It can be confusing.

HTH,

+ seth



From david.reitter at gmail.com  Wed Feb  1 20:42:26 2006
From: david.reitter at gmail.com (David Reitter)
Date: Wed, 1 Feb 2006 19:42:26 +0000
Subject: [R] predict.lme / glmmPQL: "non-conformable arguments"
Message-ID: <B2F7B09B-8C9C-4D80-A9FC-326D68076DA7@gmail.com>

 > I'm trying to use "predict" with a linear mixed-effects logistic
 > regression model fitted with nlmmPQL from the MASS library.
 > Unfortunately, I'm getting an error "non-conformable arguments" in
 > predict.lme, and I would like to understand why.

I'd like to briefly describe how I ended up working around this problem.

The issue is that predict.lme (nlme package) is unhappy when not all  
factor levels actually occur in the data given to it via "newdata".

Therefore I had to add a few dummy data points to the data frame  
given to "predict", containing examples of all factor levels. The  
predictions for these dummies can, of course, later be removed from  
the result. Specifying the possible levels with factor(X, levels=c 
(...)) does NOT do the job.

Thanks to Jonathan Williams, who set me on the right track.



From gelman at stat.columbia.edu  Wed Feb  1 20:43:32 2006
From: gelman at stat.columbia.edu (Andrew Gelman)
Date: Wed, 01 Feb 2006 14:43:32 -0500
Subject: [R] student-t regression in R?
Message-ID: <43E10F64.7080706@stat.columbia.edu>

Is there a quick way to fit student-t regressions (that is, a regression 
with t-distributed error, ideally with the degrees-of-freedom parameter 
estimated from the data)?  I can do it easily enough in Bugs, or I can 
program the log-likelihood in R and optimize using optim(), but an R 
version (if it's already been written by somebody) would be convenient, 
especially for teaching purposes.  I couldn't find the Student-t as one 
of the families in "glm" but maybe it's somewhere else?
Thanks.
Andrew

-- 
Andrew Gelman
Professor, Department of Statistics
Professor, Department of Political Science
gelman at stat.columbia.edu
www.stat.columbia.edu/~gelman

Tues, Wed, Thurs:  
  Social Work Bldg (Amsterdam Ave at 122 St), Room 1016
  212-851-2142
Mon, Fri:
  International Affairs Bldg (Amsterdam Ave at 118 St), Room 711
  212-854-7075

Mailing address:
  1255 Amsterdam Ave, Room 1016
  Columbia University
  New York, NY 10027-5904
  212-851-2142
  (fax) 212-851-2164



From tmlammail at yahoo.com  Wed Feb  1 20:54:16 2006
From: tmlammail at yahoo.com (Martin Lam)
Date: Wed, 1 Feb 2006 11:54:16 -0800 (PST)
Subject: [R] How to save R-grafics in eps format
In-Reply-To: <1138789809.43e08db1cc445@webmail.uni-potsdam.de>
Message-ID: <20060201195416.91140.qmail@web34703.mail.mud.yahoo.com>

Dear Claudia,

This is how I save the plots as *.eps.

postscript(file="testplot.eps",
            paper="special",
            width=10,
            height=10,
            horizontal=FALSE)

yvalues = runif(100)
plot(yvalues)

dev.off()

HTH,

Martin Lam


--- paladini at rz.uni-potsdam.de wrote:

> Hello!
> I used to save R-Grafics like this:
> postscript("file.ps").
> Is there alsoa way to save them as eps?
> 
> 
> Thank you very much
> 
> 
> Claudia
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From rvaradhan at jhmi.edu  Wed Feb  1 21:09:36 2006
From: rvaradhan at jhmi.edu (Ravi Varadhan)
Date: Wed, 1 Feb 2006 15:09:36 -0500
Subject: [R] student-t regression in R?
In-Reply-To: <43E10F64.7080706@stat.columbia.edu>
Message-ID: <000001c6276b$6c966f60$7c94100a@win.ad.jhu.edu>

Look at the "tlm" function in "hett" package.

Ravi.


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-
> bounces at stat.math.ethz.ch] On Behalf Of Andrew Gelman
> Sent: Wednesday, February 01, 2006 2:44 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] student-t regression in R?
> 
> Is there a quick way to fit student-t regressions (that is, a regression
> with t-distributed error, ideally with the degrees-of-freedom parameter
> estimated from the data)?  I can do it easily enough in Bugs, or I can
> program the log-likelihood in R and optimize using optim(), but an R
> version (if it's already been written by somebody) would be convenient,
> especially for teaching purposes.  I couldn't find the Student-t as one
> of the families in "glm" but maybe it's somewhere else?
> Thanks.
> Andrew
> 
> --
> Andrew Gelman
> Professor, Department of Statistics
> Professor, Department of Political Science
> gelman at stat.columbia.edu
> www.stat.columbia.edu/~gelman
> 
> Tues, Wed, Thurs:
>   Social Work Bldg (Amsterdam Ave at 122 St), Room 1016
>   212-851-2142
> Mon, Fri:
>   International Affairs Bldg (Amsterdam Ave at 118 St), Room 711
>   212-854-7075
> 
> Mailing address:
>   1255 Amsterdam Ave, Room 1016
>   Columbia University
>   New York, NY 10027-5904
>   212-851-2142
>   (fax) 212-851-2164
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From arrayprofile at yahoo.com  Wed Feb  1 21:16:10 2006
From: arrayprofile at yahoo.com (array chip)
Date: Wed, 1 Feb 2006 12:16:10 -0800 (PST)
Subject: [R] format of 2x2 table
Message-ID: <20060201201610.55348.qmail@web34803.mail.mud.yahoo.com>

Does anyone know how I can generate a 2x2 table in a
format where in each cell of the table, it contains a)
count (frequency) b) total percentage c) row
percentage d) column percentage. SAS can generate this
format easily, is there a R package that can do this?

Frequency |
Percent   |
Row Pct   |
Col Pct   | positive  negative  |  Total
--------------------------------|-------
disease   |        6        22  |     28
          |    20.69     75.86  |  96.55
          |    21.43     78.57  |
          |   100.00     95.65  |
----------|---------------------|-------
normal    |        0         1  |      1
          |     0.00      3.45  |   3.45
          |     0.00    100.00  |
          |     0.00      4.35  |
----------|---------------------|-------
Total     |        6        23  |     29
          |    20.69     79.31  | 100.00

Thanks



From mschwartz at mn.rr.com  Wed Feb  1 21:26:56 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Wed, 01 Feb 2006 14:26:56 -0600
Subject: [R] format of 2x2 table
In-Reply-To: <20060201201610.55348.qmail@web34803.mail.mud.yahoo.com>
References: <20060201201610.55348.qmail@web34803.mail.mud.yahoo.com>
Message-ID: <1138825616.4308.31.camel@localhost.localdomain>

On Wed, 2006-02-01 at 12:16 -0800, array chip wrote:
> Does anyone know how I can generate a 2x2 table in a
> format where in each cell of the table, it contains a)
> count (frequency) b) total percentage c) row
> percentage d) column percentage. SAS can generate this
> format easily, is there a R package that can do this?
> 
> Frequency |
> Percent   |
> Row Pct   |
> Col Pct   | positive  negative  |  Total
> --------------------------------|-------
> disease   |        6        22  |     28
>           |    20.69     75.86  |  96.55
>           |    21.43     78.57  |
>           |   100.00     95.65  |
> ----------|---------------------|-------
> normal    |        0         1  |      1
>           |     0.00      3.45  |   3.45
>           |     0.00    100.00  |
>           |     0.00      4.35  |
> ----------|---------------------|-------
> Total     |        6        23  |     29
>           |    20.69     79.31  | 100.00
> 
> Thanks



See the CrossTable() function in the 'gmodels' package on CRAN.


HTH,

Marc Schwartz



From Greg.Snow at intermountainmail.org  Wed Feb  1 21:32:18 2006
From: Greg.Snow at intermountainmail.org (Gregory Snow)
Date: Wed, 1 Feb 2006 13:32:18 -0700
Subject: [R] format of 2x2 table
Message-ID: <07E228A5BE53C24CAD490193A7381BBB202135@LP-EXCHVS07.CO.IHC.COM>

Look at the CrossTable function in the gmodels package.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of array chip
> Sent: Wednesday, February 01, 2006 1:16 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] format of 2x2 table
> 
> Does anyone know how I can generate a 2x2 table in a format 
> where in each cell of the table, it contains a) count 
> (frequency) b) total percentage c) row percentage d) column 
> percentage. SAS can generate this format easily, is there a R 
> package that can do this?
> 
> Frequency |
> Percent   |
> Row Pct   |
> Col Pct   | positive  negative  |  Total
> --------------------------------|-------
> disease   |        6        22  |     28
>           |    20.69     75.86  |  96.55
>           |    21.43     78.57  |
>           |   100.00     95.65  |
> ----------|---------------------|-------
> normal    |        0         1  |      1
>           |     0.00      3.45  |   3.45
>           |     0.00    100.00  |
>           |     0.00      4.35  |
> ----------|---------------------|-------
> Total     |        6        23  |     29
>           |    20.69     79.31  | 100.00
> 
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ccleland at optonline.net  Wed Feb  1 21:32:36 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 01 Feb 2006 15:32:36 -0500
Subject: [R] format of 2x2 table
In-Reply-To: <20060201201610.55348.qmail@web34803.mail.mud.yahoo.com>
References: <20060201201610.55348.qmail@web34803.mail.mud.yahoo.com>
Message-ID: <43E11AE4.4010603@optonline.net>

library(gmodels)
?CrossTable

array chip wrote:
> Does anyone know how I can generate a 2x2 table in a
> format where in each cell of the table, it contains a)
> count (frequency) b) total percentage c) row
> percentage d) column percentage. SAS can generate this
> format easily, is there a R package that can do this?
> 
> Frequency |
> Percent   |
> Row Pct   |
> Col Pct   | positive  negative  |  Total
> --------------------------------|-------
> disease   |        6        22  |     28
>           |    20.69     75.86  |  96.55
>           |    21.43     78.57  |
>           |   100.00     95.65  |
> ----------|---------------------|-------
> normal    |        0         1  |      1
>           |     0.00      3.45  |   3.45
>           |     0.00    100.00  |
>           |     0.00      4.35  |
> ----------|---------------------|-------
> Total     |        6        23  |     29
>           |    20.69     79.31  | 100.00
> 
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From bin999 at lycos.com  Wed Feb  1 21:35:46 2006
From: bin999 at lycos.com (bin999@lycos.com)
Date: Wed, 01 Feb 2006 14:35:46 -0600
Subject: [R] cor/group by???
Message-ID: <20060201203546.262AECA09D@ws7-4.us4.outblaze.com>

Can someone help me calculate correlations for grouped values?

Heres what my first few line of data look like:

> head(cmexpr)
  LLID  GMID    CEXPR    MEXPR
1 1005 10831 2.057462 -0.08486
2 1005 10831 2.057515 -0.08486
3 1005 10831 2.057462  0.01209
4 1005 10831 2.057515  0.01209
5 1005 10836 2.050980  0.17237
6 1005 10836 2.018576  0.17237

LLID is gene id, GMID is cell line id, the EXPR columns are gene expression is two different microarray experiments.

I'd like to get correlations for each gene id (1005, 1006, etc)

Heres what I've tried so far:

sapply(by(cmexpr[3:4],cmexpr$LLID, function(x) cor(cmexpr$CEXPR,cmexpr$MEXPR, use = "pairwise.complete.obs")), function(x) x,simplify=T)

I think this is close to what I need, but its giving me the same corr for each gene, which is not right:

       1005       10083       10146       10158       10174       10206
-0.04751543 -0.04751543 -0.04751543 -0.04751543 -0.04751543 -0.04751543
      10211       10212       10219       10363       10484       10492
-0.04751543 -0.04751543 -0.04751543 -0.04751543 -0.04751543 -0.04751543

Sorry if this sounds like a newbie question; it seems like it ought to be pretty straightforward, but I've wrestled with both the R documenation and mailing list archive and can't seem to get it right.

Thanks

B



-- 
_______________________________________________

Search for businesses by name, location, or phone number.  -Lycos Yellow Pages

http://r.lycos.com/r/yp_emailfooter/http://yellowpages.lycos.com/default.asp?SRC=lycos10



From ana.pmartins at ine.pt  Wed Feb  1 15:37:33 2006
From: ana.pmartins at ine.pt (Ana Patricia Martins)
Date: Wed, 1 Feb 2006 14:37:33 -0000 
Subject: [R] strange question...
Message-ID: <E97312684A84D511BDD40002A50968D6071705D3@lxpobw01.ine.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/69708e25/attachment.pl

From brettginsburg at sbcglobal.net  Wed Feb  1 15:53:09 2006
From: brettginsburg at sbcglobal.net (brettginsburg@sbcglobal.net)
Date: Wed, 1 Feb 2006 08:53:09 -0600
Subject: [R] Broken x-axis
Message-ID: <000201c6273f$609de020$660010ac@Ezekiel>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/bf73ac44/attachment.pl

From anainesvs at hotmail.com  Wed Feb  1 17:00:15 2006
From: anainesvs at hotmail.com (=?iso-8859-1?B?QW5hIElu6XMgVuF6cXVleiBTYXJhdmlh?=)
Date: Wed, 01 Feb 2006 13:00:15 -0300
Subject: [R] Mixed-effects models / heterogeneous covariances
In-Reply-To: <40e66e0b0601311456r57850ec9k1a9ca2164d46548a@mail.gmail.com>
Message-ID: <BAY16-F6EC3F583859728094071EB50B0@phx.gbl>

You can solve your problem assuming independence between the animals (not 
considering relatives information). This gives you less precision in the 
results, but is what you can do right now. The variance structures are more 
for longitudinal data or cases where you can predict in that way the 
variance structure. In your case the variance structure is determined by the 
relationships between the animals. Animal is the random effect (you will 
have as many Z columns as animals, and Zrows as animals*observations per 
animal).
I am working now in adding the pedigree information, to have ZAZ(Var ui) 
instead of ZIZ(Var ui) as one of the components of the variance of your 
response variable (y). To use it you will need to have the animals pedigree.
(Note: Z: design matrix for the random effects ?the animals-
A: relationship matrix between animals,
ui: random effect i; i=1...n. For a population of n total animals.
y: your data points vector of responses)

Best, Ana Ines.

>From: Douglas Bates <dmbates at gmail.com>
>To: "Lutz Ph. Breitling" <lutz.breitling at gmail.com>, Ana In??s V??zquez 
>Saravia <anainesvs at hotmail.com>, "Doran, Harold" <HDoran at air.org>, "J.R. 
>Lockwood" <lockwood at rand.org>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] Mixed-effects models / heterogeneous covariances
>Date: Tue, 31 Jan 2006 16:56:08 -0600
>
>On 1/31/06, Lutz Ph. Breitling <lutz.breitling at gmail.com> wrote:
> > Dear R-list,
> >
> > maybe someone can help me with the following mixed-effects models
> > problem, as I am unable to figure it out with the 'nlme-bible'.
> >
> > I would like to fit (in R, obviously) a so-called animal model (google
> > e. g. "Heritability and genetic constraints of life-history" by Pettay
> > et al.) to estimate the variance component that is due to genetic
> > effects. The covariances of the genetic random effects between
> > observations are given by the different degrees of relatedness between
> > the individuals examined. (I find it difficult to explain, but Pettay
> > et al. describe it nicely in their methods section...)
> >
> > Is there any straight-forward way to fit such a model with R? I first
> > thought I could handle it somehow with nlme's correlation structures,
> > but these within-group structures are quite a different thing, right?
>
>Sorry to say, yes they are quite a different thing.
>
>I am aware of  models like the animal model and the sire model in
>animal breeding.  A student in our Animal Sciences Department, Ana
>In??s V??zquez Saravia, is working with me on developing extensions to
>the lmer function to handle such models.  The actual calculations are
>not extraordinarily difficult - the difficulty is in deciding how to
>specify the model and in massaging the data to convert the model
>specification to model matrices.
>
>The model specification for an lmer model assumes that each predicted
>response is affected by one and only one random effects vector
>associated with each of the grouping factors.  That is, the random
>effects have only an instantaneous effect and there is no "carry-over"
>of random effects from other levels of the grouping factor.  This is
>not the case for the animal model or for the sire model.  A given
>predicted response is affects by the random effects for each of the
>ancestors of the animal on which the observation is made.  The "no
>carry-over" assumption is also violated in longitudinal "value-added"
>models for student achievement where the effect of a teacher in a
>given year can carry over to subsequent years. J.R. Lockwood and
>Harold Doran are very interested in these models.
>
>All of these are important practical models but, as I said, it is
>tricky to decide how to specify the model in these cases.



From p.dalgaard at biostat.ku.dk  Wed Feb  1 22:18:22 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Feb 2006 22:18:22 +0100
Subject: [R] cor/group by???
In-Reply-To: <20060201203546.262AECA09D@ws7-4.us4.outblaze.com>
References: <20060201203546.262AECA09D@ws7-4.us4.outblaze.com>
Message-ID: <x23bj2dbhd.fsf@turmalin.kubism.ku.dk>

bin999 at lycos.com writes:

> Can someone help me calculate correlations for grouped values?
> 
> Heres what my first few line of data look like:
> 
> > head(cmexpr)
>   LLID  GMID    CEXPR    MEXPR
> 1 1005 10831 2.057462 -0.08486
> 2 1005 10831 2.057515 -0.08486
> 3 1005 10831 2.057462  0.01209
> 4 1005 10831 2.057515  0.01209
> 5 1005 10836 2.050980  0.17237
> 6 1005 10836 2.018576  0.17237
> 
> LLID is gene id, GMID is cell line id, the EXPR columns are gene expression is two different microarray experiments.
> 
> I'd like to get correlations for each gene id (1005, 1006, etc)
> 
> Heres what I've tried so far:
> 
> sapply(by(cmexpr[3:4],cmexpr$LLID, function(x) cor(cmexpr$CEXPR,cmexpr$MEXPR, use = "pairwise.complete.obs")), function(x) x,simplify=T)
> 
> I think this is close to what I need, but its giving me the same corr for each gene, which is not right:
> 
>        1005       10083       10146       10158       10174       10206
> -0.04751543 -0.04751543 -0.04751543 -0.04751543 -0.04751543 -0.04751543
>       10211       10212       10219       10363       10484       10492
> -0.04751543 -0.04751543 -0.04751543 -0.04751543 -0.04751543 -0.04751543
> 
> Sorry if this sounds like a newbie question; it seems like it ought to be pretty straightforward, but I've wrestled with both the R documenation and mailing list archive and can't seem to get it right.

You're passing a function to by() whose result does not depend
on the argument x ...

This might be clearer:

c(by(cmexpr, cmexpr$LLID, with, cor(CEXPR, MEXPR, use="pair")))

or

sapply(split(cmexpr, cmexpr$LLID), with, cor(CEXPR, MEXPR, use="pair"))

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From lawremi at iastate.edu  Wed Feb  1 19:54:57 2006
From: lawremi at iastate.edu (Michael Lawrence)
Date: Wed, 01 Feb 2006 12:54:57 -0600
Subject: [R] [R-pkgs] RGtk2 released
Message-ID: <43E10401.1010503@iastate.edu>

I am pleased to announce the first beta release of RGtk2, the R binding 
to GTK 2.0 (actually 2.8.0). RGtk2 works on all three major platforms 
(Linux, Mac, and Windows) and allows one to construct full-featured 
GUI's from within R.

RGtk2 offers virtually complete bindings to the latest GTK, as well as 
some of its dependencies, including Cairo and Pango, and some extras 
like libglade and GtkMozEmbed (on Linux). Almost the entire package was 
documented by transforming the original (C language oriented) API 
documentation to the R perspective.

Please see the following website for details and downloads: 
http://www.ggobi.org/rgtk2.

You'll also find the Cairo R graphics device there, which lets you 
display R graphics within your RGtk2 GUI.

Please send any bug reports to me.

Thanks,
Michael Lawrence

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From andy_liaw at merck.com  Wed Feb  1 22:35:30 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 1 Feb 2006 16:35:30 -0500
Subject: [R] problem with cbind
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7A9@usctmx1106.merck.com>

That's because:

> as.numeric(factor(c(0, 1)))
[1] 1 2

The underlying representation of a factor, say `x', is to use integers 1
through nlevels(x).  If you do anything that simply convert the factor to
numeric, you just get these codes.

If you create a data frame (instead of simply cbind()ing them together)
you'll retain them as factors.

Andy

From: Ana Patricia Martins
> 
> Hello,
> 
>  
> 
> I think this is Sill question but it's happens......
> 
>  
> 
>  
> 
> am$e_isell <- factor( with( am, ifelse( e_iacc == 1 & C5 == 1, 1, 0)))
> 
>  
> 
> summary (am$e_isell)
> 
>    0    1 
> 
> 3966  296
> 
> (Ok)
> 
>  
> 
> am$e_isell [4256]
> 
> [1] 1
> 
> Levels: 0 1
> 
> (OK)
> 
>  
> 
>  
> 
>  cbind( am$e_isell[4256], am$C6[4256])
> 
>      [,1] [,2]
> 
> [1,] "2"  "1"
> 
> (??)
> 
>  
> 
> cbind( am$e_isell[4256])
> 
>      [,1] 
> 
> [1,] "2"  
> 
> (??)
> 
>  
> 
>  
> 
> Does anyone understand why this happens?
> 
>  
> 
>  
> 
> Atenciosamente
> 
> Ana Patricia Martins
> 
> -------------------------------------------
> 
> Servi??o M??todos Estat??sticos
> 
> Departamento de Metodologia Estat??stica
> 
> Telef:  218 426 100 - Ext: 3210
> 
> E-mail:  <mailto:ana.pmartins at ine.pt> ana.pmartins at ine.pt
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
>



From sfalcon at fhcrc.org  Wed Feb  1 22:47:45 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 01 Feb 2006 13:47:45 -0800
Subject: [R] strange question...
In-Reply-To: <E97312684A84D511BDD40002A50968D6071705D3@lxpobw01.ine.pt> (Ana
	Patricia Martins's message of "Wed, 1 Feb 2006 14:37:33 -0000")
References: <E97312684A84D511BDD40002A50968D6071705D3@lxpobw01.ine.pt>
Message-ID: <m2r76mbvjy.fsf@fhcrc.org>

On  1 Feb 2006, ana.pmartins at ine.pt wrote:
> am$e_isell <- factor( with( am, ifelse( e_iacc == 1 & C5 == 1, 1,
> 0)))
>
>
> cbind( am$e_isell[4256], am$C6[4256])
>
> [,1] [,2]
>
> [1,] "2"  "1"
>
>
>
> (????????????? :(  )
>
>
>
> Does anyone understand why this happens?

A factor is an integer vector with levels.  Although there are many
operations one can perform on a factor that will "work" because of
automagic convertion of the factor to its underlying integer vector,
it is rarely useful, IMHO.

The following may help you see what is going on:

f = factor(c(0, 1, 1, 0))

unclass(f)

as.numeric(f)
as.integer(f)

as.character(f)
as.integer(as.character(f))

+ seth



From andy_liaw at merck.com  Wed Feb  1 22:57:37 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 1 Feb 2006 16:57:37 -0500
Subject: [R] Help with functions
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7AB@usctmx1106.merck.com>

Just remember that you are writing _functions_, not _macros_.  If you want
the function to be able to see an object, pass that object to the function
as one of the arguments.  Alternatively, you can use the lexical scoping in
R and define the (sub)functions inside the `main' function.

Andy

From: Pryseley Assam
> 
> Dear R-users
>    
>   I intend to create a function which calls some smaller 
> other functions in return. Some of these smaller functions 
> all call some functions. I do not know a good way to do this. 
> I tried using the source() function to include the smaller 
> functions within the main functions before they are called. 
> This does not work, or maybe i am not doing the right thing. 
>   For example:
>    
>   the following quantities are computed in the main function 
> (only a part of the main function is shown below)
>    
>     ###############################################################
>   # quantities for bootstrap confidence intervals
>   ###############################################################
>   r.value<- cor(x,y)
>   npb.B <- mean(r)-r.value
>   npb.mean <- mean(r)
>   npb.var <- var(r)
>   r.star <- sort(r)
>   z.star <- (r.star - mean(r.star))/sqrt(var(r.star))
> 
>    
>   after which the main function calls the function 
> (i.s.conf.int) shown below, which is saved in a different script file
>    
>   ################################################### 
>     # Confidence Interval 
>   ###################################################
>   i.s.conf.int <- function(type) {
>   switch(type,
>   a = nci(),
>   b = inci(),
>   c = bbi(),
>   d = pi(),
>   e = si())
>   }
>    
>   Also, this 'sub' function (i.s.conf.int) may call one of 5 
> other smaller functions saved in yet another file, or the 
> same file as the function "i.s.conf.int".
>    
>   However, these 5 functions need the quantities calculated 
> in the main function. One of these functions is shown below:
>    
>   ###############################################################
>   # nonparametric bootstrap normal confidence interval
>   ###############################################################
>   nci <-function () {
>   npb.n.L <- r.value - 1.96*sqrt(npb.var)
>   npb.n.U <- r.value + 1.96*sqrt(npb.var)
>   npb.n <- array(data = c( npb.n.L, npb.n.U), 
>   dim = c(1,2), 
>   dimnames = list("Estimates" ,c("LowerBound","UpperBound")))
>   
>   npb.n.CI <- list( Type = "Normal Confidence Interval",
>   ConfidenceInterval= npb.n)
>   npb.n.CI
>   }
>    
>   I use the source() function to include these 
> "secondary/sub" functions, just before they are called the 
> main function. I get an Error message when any of the 5 small 
> functions is executing : that it can not find the quantities 
> calculated in the main function. 
>    
>   So my question boils down to how can i call functions from 
> different files in the main function, so that the recognise 
> quantities already calculated in the main function or passed 
> as arguements to the main function ?
>    
>   Thanks 
>   Pryseley.
>    
> 
> 
> 		
> ---------------------------------
> Bring words and photos together (easily) with
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From vivek.satsangi at gmail.com  Wed Feb  1 23:10:32 2006
From: vivek.satsangi at gmail.com (Vivek Satsangi)
Date: Wed, 1 Feb 2006 17:10:32 -0500
Subject: [R] (Newbie) Merging two data frames
Message-ID: <bcb171920602011410uaa7f8ady3c91240649ebf753@mail.gmail.com>

This one is an easy question. I am looking for the "idiomatic" way to do it.

I have two large data frames. I want to "merge" them. What is the
idiomatic way to say "match the rows from dataframe 1 to the rows in
dataframe2 which have the following fields the same: Identifier, Year
and Quarter? (These three fields form something like a composite
primary key in SQL). Then tell me which rows you could not find a
match for.... etc.

-- Vivek Satsangi
Student, Rochester, NY USA



From milferst at uiuc.edu  Wed Feb  1 23:12:29 2006
From: milferst at uiuc.edu (Kim Milferstedt)
Date: Wed, 01 Feb 2006 16:12:29 -0600
Subject: [R] extracting and summarizing data from data.frame with table-like
 output
Message-ID: <6.2.5.6.2.20060201161220.01c7c260@uiuc.edu>

Hello,

I would like to summarize and extract statistics (calculate means, 
stderr etc) from a data set that comes as a large table. This table 
needs to be sorted according to certain categories (in the example 
below "day", "angle", "distance" and "location"). I would like to 
have the output in a table similar to the original data, but now with 
the mean (or stderr etc) for all individual measurement of "res.1" at 
any "location" in one column, in a second colum the means for "res.2" 
at any "location" etc.

1. How can I get the means that I extract from my data set into a 
format similar to the initial data and not as a matrix as I get it 
with tapply()?
2. How can I calculate the means for many variables at once and not 
just for one as in tapply()?
3. How does R know what data to use with the function "order()" or "tapply()"?

Thanks for your help,

Kim

Here is an example:

## The code below creates an artificial data set "jj" that resembles 
my real data.
res.1       <-  c(rbinom(36, size=50, prob=0.6))
res.2       <-  c(rbinom(36, size=20, prob=0.4))
day         <-  rep(rep(1:3,rep(6,3)),2)
angle       <-  rep(1:3, 12)
distance    <-  rep(rep(1:2,rep(3,2)),6)
location    <-  rep(1:2,c(18,18))
jj          <-  cbind(res.1,res.2,day,angle,distance, location)

## I order the data
pp          <-  order(day, angle, distance)
jj[pp,]

## Now I calculate the mean for "res.1" over the variable "location"
ss          <-  tapply(res.1,list(day, angle, distance, location), mean)
ss

## The result "ss" are four matrices but I want a table like output, 
possibly also with the means for res.2.


__________________________________________

Kim Milferstedt
University of Illinois at Urbana-Champaign
Department of Civil and Environmental Engineering
4125 Newmark Civil Engineering Building
205 North Mathews Avenue MC 250
Urbana, IL 61801
USA
phone: (001) 217 333-9663
fax: (001) 217 333-6968
email: milferst at uiuc.edu
http://cee.uiuc.edu/research/morgenroth/index.asp



From mschwartz at mn.rr.com  Wed Feb  1 23:19:34 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Wed, 01 Feb 2006 16:19:34 -0600
Subject: [R] (Newbie) Merging two data frames
In-Reply-To: <bcb171920602011410uaa7f8ady3c91240649ebf753@mail.gmail.com>
References: <bcb171920602011410uaa7f8ady3c91240649ebf753@mail.gmail.com>
Message-ID: <1138832374.4308.45.camel@localhost.localdomain>

On Wed, 2006-02-01 at 17:10 -0500, Vivek Satsangi wrote:
> This one is an easy question. I am looking for the "idiomatic" way to do it.
> 
> I have two large data frames. I want to "merge" them. What is the
> idiomatic way to say "match the rows from dataframe 1 to the rows in
> dataframe2 which have the following fields the same: Identifier, Year
> and Quarter? (These three fields form something like a composite
> primary key in SQL). Then tell me which rows you could not find a
> match for.... etc.


You answered your own question...  :-)

See ?merge

which will perform SQL-like joins.

HTH,

Marc Schwartz



From rroth at neurocrine.com  Wed Feb  1 23:46:59 2006
From: rroth at neurocrine.com (Roth, Richard)
Date: Wed, 1 Feb 2006 14:46:59 -0800
Subject: [R] GetBioC install issue
Message-ID: <3E7270E9D0A68A4CA47B1A6BF44926E702BDCA91@nbiexchange.neurocrine.local>

Hi, I am trying to install the BioC package from bioconductor onto a Windows Server 2003 machine.  I can connect to bioconductor and when I run the getBioC("affy","release") function it starts to download but then it stops with the following error:

Error: unable to create temporary directory 'C:\Program Files\R\R-2.2.1\release\file1eb26e9'

The download just ends there.


Does anyone have any idea what the problem is?

Thanks, Rich

Rich Roth, PhD
Senior Scientist, Bioinformatics
Molecular Medicine
Neurocrine Biosciences
858-617-7204


-------------- next part --------------
"MMS <neurocrine.com>" made the following
 annotations on 02/01/2006 02:47:16 PM
------------------------------------------------------------------------------
This email may contain confidential and privileged material ...{{dropped}}


From gunter.berton at gene.com  Thu Feb  2 01:46:24 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 1 Feb 2006 16:46:24 -0800
Subject: [R] R Reference Card (especially useful for Newbies)
Message-ID: <200602020046.k120kOq8010854@meitner.gene.com>

 

Newbies (and others!) may find useful the R Reference Card made available by
Tom Short and Rpad at http://www.rpad.org/Rpad/Rpad-refcard.pdf  or through
the "Contributed" link on CRAN (where some other reference cards are also
linked). It categorizes and organizes a bunch of R's basic, most used
functions so that they can be easily found. For example, paste() is under
the "Strings" heading and expand.grid() is under "Data Creation." For
newbies struggling to find the right R function as well as veterans who
can't quite remember the function name, it's very handy.
 
-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA



From arrayprofile at yahoo.com  Thu Feb  2 02:21:14 2006
From: arrayprofile at yahoo.com (array chip)
Date: Wed, 1 Feb 2006 17:21:14 -0800 (PST)
Subject: [R] fisher table probability
Message-ID: <20060202012114.83085.qmail@web34801.mail.mud.yahoo.com>

Hi, is there a way to generate the table's probability
when doing the fisher's exact test on a 2x2 table? The
fisher's exact test gives the p value, but not the
probability for the table.



From Ted.Harding at nessie.mcc.ac.uk  Thu Feb  2 02:42:16 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 02 Feb 2006 01:42:16 -0000 (GMT)
Subject: [R] norm package prelim.norm
In-Reply-To: <XFMail.060201154438.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.060202014216.Ted.Harding@nessie.mcc.ac.uk>

On 01-Feb-06 Ted Harding wrote:
> On 01-Feb-06 Elizabeth Lawson wrote:
>> Hey eveyone!  I hope someone can help wiht this question.  I have a
>> matirux of all zeros and ones and I would like to indentify all unique
>> patterns in the rows andthe number of times the pattern occurs.   I
>> changed all zeros to NA tried to use prelim.norm to identify all
>> patterns of missing data in the rows.  I got the message 
>>    
>>   Warning message:
>> NAs introduced by coercion 
>> 
>>   Any ideas of how to get this to work?  Or are there any way to
>> indentify all the unique patterns in a huge matrix? ( 10000 x 71)
>>    
>>   Thanks for any suggestions!!
>>    
>>   Elizabeth Lawson
> 
> I think Chuck Celand has pretty well answered it: Don't worry
> about the warning, since I'm pretty sure it is generated when
> prelim.norm is calculating something else (e.g. the covariance
> matrix) and it is not related to generating prelim.norm(X)$r
> which is the list of patterns and the numbers of times they occur.
> 
> Best wsihes,
> Ted.

Sorry -- I should have read the detail of your original message
more carefully. In short, you have too many columns for prelim.norm
to work.

The long answer: prelim.norm analyses the missing data patterns
by representing the locations of NAs as integers, where the jth
bit in the binary representation of the integer is 1 for an NA,
0 for a non-NA. Hence the representation of the pattern runs out
of steam when there are more than a certain number of columns,
corresponding to the highest power of 2 that can be represented
as an integer in R.

  .Machine$integer.max
  [1] 2147483647

  2^31 -1
  [1] 2147483647

so that prelim.norm can only encode NA-patterns in an R integer
for up to 31 columns. More than that, and it will not work properly
or at all.

Check:

  X<-matrix(sample(c(0,1),87,replace=TRUE),ncol=29)
  Y<-X; Y[Y==0]<-NA
  prelim.norm(Y)$r
  [...] (no warning, 3 rows)

  X<-matrix(sample(c(0,1),90,replace=TRUE),ncol=30)
  Y<-X; Y[Y==0]<-NA
  prelim.norm(Y)$r
  [...] (no warning, 3 rows)

  X<-matrix(sample(c(0,1),93,replace=TRUE),ncol=31)
  Y<-X; Y[Y==0]<-NA
  prelim.norm(Y)$r
  [...] (no warning, 3 rows)

  X<-matrix(sample(c(0,1),93,replace=TRUE),ncol=32)
  Y<-X; Y[Y==0]<-NA
  prelim.norm(Y)$r
  [...] (3 rows, "Warning message: NAs introduced by coercion")

  X<-matrix(sample(c(0,1),93,replace=TRUE),ncol=33)
  Y<-X; Y[Y==0]<-NA
  prelim.norm(Y)$r
  [...] (2 rows, "Warning message: NAs introduced by coercion")

  X<-matrix(sample(c(0,1),93,replace=TRUE),ncol=34)
  Y<-X; Y[Y==0]<-NA
  prelim.norm(Y)$r
  [...] (1 row, "Warning message: NAs introduced by coercion")

(Try a few of these for yourself; it is very unlikely that you get
one 1 or 2 distinct rows when you have 3 rows of 30+ 0s and 1s
sampled at random).

A similar issue came up some time ago (I can't locate the thread
in the archive at the moment) in vennection with the 'mix'
package.

However, you can have as many columns as you like if you use
'unique' to identify the distinct patterns of 0s and 1s, rather
than using 'prelim.norm'.

Hoping this helps,
Ted.



--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 02-Feb-06                                       Time: 01:42:13
------------------------------ XFMail ------------------------------



From bpontar at amazon.com  Thu Feb  2 04:11:37 2006
From: bpontar at amazon.com (Pontarelli, Brett)
Date: Wed, 1 Feb 2006 19:11:37 -0800
Subject: [R] Computing s^2 for non-negative least squares.
Message-ID: <2047FEBD93E8744D8A82C2510BB823C4F3390D@exchg-sea3-02.ant.amazon.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/43e37268/attachment.pl

From Keith.Chamberlain at colorado.edu  Thu Feb  2 05:14:50 2006
From: Keith.Chamberlain at colorado.edu (Keith Chamberlain)
Date: Wed, 1 Feb 2006 21:14:50 -0700
Subject: [R] How do I normalize a PSD?
In-Reply-To: <mailman.9.1138791602.8328.r-help@stat.math.ethz.ch>
Message-ID: <000c01c627af$365b9710$742b8a80@komelandpc>

Dear Tom,

Short answer, if your using spec.pgram(), use the smoothing kernel to get a
better estimate at the frequency centered in the bandwidth. If your
frequency bin of interest is wider than the bandwidth of the kernel, average
across frequencies (I think). The estimate appears to be normalized already.

If you are calculating your PSD independently, then oversample (e.g. 2,
perhaps 4 or more times the highest frequency you need to characterize, and
sum (not average) across the frequency bin to get the power estimate of the
center frequency in that bin. Shove the whole signal into memory and don't
window it if you can. The oversampling improves your estimate and reduces
the variance. Getting the FFT of the whole signal at once eliminates edge
effects that would occur if you segmented the data. Whatever your PSD is
normalized to, the sum across frequencies in your bin will maintain that
property. 

If you are really wanting to see the PSD plotted by period rather than
frequency, plot the inverse of your frequency values.

The normalization part is a separate (and huge, perhaps neglected, perhaps
overrated) subject. Here is how I have tried to make sense out of it.

I do not have years and years of experience in spectral analysis, but
perhaps you may find this a more simple (minded?) description. I was taught
the definition of the power spectrum using "Numerical Recipes" from Press,
et al (e.g. any of 1988, 1992, and 2002, for FORTRAN, C, and C++
respectively). Their description seems different (as Leif suggested) from
other sources. They also happen to caution (strongly) about the distinction
between "one-sided" and "two-sided" PSDs, but I'm not sure to what extent
other authors have concerned themselves with that point, or that it is even
necessary in most practical applications (warning: non-expert opinion).

In the definition I learned, a periodogram is considered "normalized" in the
sense that the sum across the frequency range has something to do with some
quantity (Sum Squared, Mean Squared, etc.) of a signal in the time domain. 

Let
N = Number of samples
Fc = Nyquist critical frequency
C = Normalization parameter

P2(f) = C * Mod(fft(signal))^2 from -fc to fc: Press et al call a
"two-sided" estimate, even if just the power at positive frequencies is
returned.

P1(f) = C * Mod(fft(signal))^2 from DC to fc, but all frequencies excluding
DC and Nyquist are multiplied by 2. Press et al. consider this the
"one-sided" estimate. 

The reason they call those "one" or "two" sided is that the sum of the power
over all of the frequencies will be equivalent even though the one sided
estimate has only half the data points.
Sum(P2) == sum(P1)

The parameter C is what I think I understand as the normalization parameter,
and besides the one/two sided nomenclature issue, is where authors seem to
differ. Regardless of which definition of the PSD is used, where C = 1/N,
the periodogram (to Press, et al.) would be normed to the Sum Squared of the
signal in the time domain. I believe some authors might call that form
un-normalized, depending on whether or not 1/N was included in the
definition of a periodogram that they happen to have been working from.
Where C = 1/N^2, the periodogram would be normed to the Mean Squared of the
signal in the time-domain. Where C = some other factor, the periodogram is
normed to the equivalent of that factor from the time-domain. That's my
(perhaps oversimplified) understanding.

>From Venables & Ripley, listed as a source on >?spec.pgram, the definition
used for that function seems comparable - though I wouldn't count out the
possibility that I missed or misread something. The factor C in that case is
1/N so the PSD estimate should sum to the Sum Squared in the time domain.
There are 2 caveats. The first is a point that Leif pointed out, that the
periodogram from spec.pgram() is normalized to frequency. I need to reread
that section in Venables & Ripley and look at the link provided in another
recent reply in more detail to be certain. For now, I am making the
assumption that the parameter would be used 'in addition' to the 1/N factor.
I highly recommend that you reference the sources from the spec.pgram help
page.

Second, smoothing and tapering are defined separately from the PSD, so I do
not think the equalities hold up as well between a quantity of the
(unsmoothed) time-domain signal, and its normalized (smoothed &/or tapered)
power spectrum.

I hope this helps, wasn't to long, and that my weak editing skills did not
make to grand an appearance.

Regards,
KeithC.


Message: 30
Date: Tue, 31 Jan 2006 13:02:03 -0800
From: Leif Kirschenbaum <leif at reflectivity.com>
Subject: Re: [R] How do I "normalise" a power spectral density
To: r-help at stat.math.ethz.ch, Tom C Cameron <bgytcc at leeds.ac.uk>
Message-ID: <200601312102.k0VL29fS003509 at hypatia.math.ethz.ch>
Content-Type: text/plain; charset=iso-8859-1

I have done a fair bit of spectral analysis, and hadn't finished collecting
my thoughts for a reply, so hadn't replied yet.

What exactly do you mean by normalize?
  I have not used the functons periodogram or spectrum, however from the
description for periodogram it appears that it returns the spectral density,
which is already normalized by frequency, so you don't have to worry about
changing the appearance of your periodogram or power spectrum if you change
the time intervals of your data. With a normal Fourier Transform, not only
do you need to complex square the terms but you also need to divide by a
normalizing factor to give power-per-frequency-bin, which the periodogram
appears to do.

  However, if you look in various textbooks, the definition of the Fourier
Transform (FT) varies from author to author in the magnitude of the
prepended scaling factor. Since the periodogram is related to the FT
(periodogram ultimately uses the function mvfft), without examination of the
code for periodogram you cannot know the scaling factor, which is almost
always one of the following:
  1.0
  1/2
  1/(2*pi)
  SQRT(1/2)
  SQRT(1/(2*pi))
  In fact, if you obtain an FT (or FFT or DFT) from a piece of electronics
(say an electronic spectrum analyzer), the prepending factor can vary from
manufacturer to manufacturer.
  Fortunately, there is a strict relationship between the variance of your
signal and the integrated spectral density. If your time signal is x(t), the
spectral density is S(f), and fc = frequency(x)/2 the Nyquist cutoff
frequency, then this may be expressed as:

  variance(x(t)) = constant * {Integral from 0 to fc of S(f)}

In R-code: let x be your time series, and "constant" be the unknown scaling
factor (1/2, 1/2pi, etc.)
  p <- periodogram(x)
  var(x) == constant * sum(p[[1]])/length(p[[1]])

Or:
  constant = sum(p[[1]])/length(p[[1]])/var(x)

and we find that the appropriate scaling constant is 1.0.

  As regards plotting versus period, the periodogram returns arrays of
spectral amplitude and frequencies. The frequencies are in inverse units of
the intervals of your time series. i.e. if your time series is 1-point per
day, then the frequencies are in 1/day units. Thus if you wish to plot
amplitude versus period in weeks you have a little math to do.
  I believe that plotting is usually versus frequency since most observers
are interested in how things vary versus frequency: multiple evenly spaced
peaks on a linear frequency scale indicates the presence of harmonics; this
is not so simply seen in a plot versus period. ex. peaks of 10 Hz, 20 Hz, 30
Hz, 40 Hz,... in period would be at periods of 100 ms, 50 ms, 25 ms, 12.5
ms, and the peaks are not evenly spaced.
  Additionally, there are all kinds of typical responses versus frequency
(1/f, 1/f^2) which are clearly seen in plots versus frequency as straight
lines (log power vs log frequency), but would come out as curves in plots
versus period.
  I can see how ecological studies may indeed be more interested in the
periods.

  However, I would be wary of using the periodogram function, for if I
calculate periodograms of the same sinewave but for differing lengths of the
sample, the spectral density does not come out the same. All 4 of the plots
produced by the code below should overlay, and yet as the time series
becomes longer there appears to be an increasing offset of the magnitudes
returned. (black-brown-blue-red)

x0<-ts(data=sin(2*pi*1.1*(1:1000)/10),frequency=10)
p0<-periodogram(x0)
var(x0)

x1<-ts(data=sin(2*pi*1.1*(1:10000)/10),frequency=10)
p1<-periodogram(x1)
var(x1)

x2<-ts(data=sin(2*pi*1.1*(1:100000)/10),frequency=10)
p2<-periodogram(x2)
var(x2)

x3<-ts(data=sin(2*pi*1.1*(1:1000000)/10),frequency=10)
p3<-periodogram(x3)
var(x3)

plot(p3[[2]],p3[[1]],col="red",type="p",pch=19,cex=0.05,log="y",
	xlim=c(0.1,0.12),ylim=c(1e-30,1e-15))
points(p2[[2]],p2[[1]],type="l",col="blue")
points(p1[[2]],p1[[1]],type="l",col="brown")
points(p0[[2]],p0[[1]],type="o",col="black")


> Message: 113
> Date: Mon, 30 Jan 2006 17:45:58 -0800
> From: Spencer Graves <spencer.graves at pdf.com>
> Subject: Re: [R] How do I "normalise" a power spectral density
> 	analysis?
> To: Tom C Cameron <bgytcc at leeds.ac.uk>
> Cc: r-help at stat.math.ethz.ch
> Message-ID: <43DEC156.2090900 at pdf.com>
> Content-Type: text/plain; charset=us-ascii; format=flowed
> 
> 	  Since I have not seen a reply to this post, I will 
> offer a comment, 
> even though I have not used spectral analysis myself and 
> therefore have 
> you intuition about it.  First, from the definitions I read in the 
> results from, e.g., RSiteSearch("time series power spectral density") 
> [e.g., 
> http://finzi.psych.upenn.edu/R/library/GeneTS/html/periodogram
> .html] and 
> "spectral analysis" in Venables and Ripley (2002) Modern Applied 
> Statistics with S (Springer), I see no reason why you 
> couldn't plot the 
> spectrum vs. the period rather than the frequency.  Someone else may 
> help us understand why it is usually plotted vs. the frequency;  I'd 
> guess that the standard plot looks more like the integrand in the 
> standard Fourier inversion formula, but I'm not sure.
> 
> 	  If you'd like more help from this listserve, you 
> might briefly 
> describe the problem you are trying to solve, why you think spectral 
> analysis analysis should help, and include a toy example with some 
> self-contained R code to illustrate what you tried and what you don't 
> understand about it.  (And PLEASE do read the posting guide! 
> "www.R-project.org/posting-guide.html".  Nothing is certain but 
> following that posting guide will, I believe, tend to 
> increase the speed 
> and utility of response.)
> 
> 	  hope this helps.
> 	  spencer graves
> 
> Tom C Cameron wrote:
> 
> > Hi everyone
> > 
> > Can anyone tell me how I normalise a power spectral density 
> (PSD) plot of a
> > periodical time-series. At present I get the graphical 
> output of spectrum VS
> > frequency.
> > 
> > What I want to acheive is period VS spectrum? Are these the 
> same things but the
> > x-axis scale needs transformed ?
> > 
> > Any help would be greatly appreciated
> > 
> > Tom
> > 
> ..............................................................
> .............
> > Dr Tom C Cameron                        office: 0113 34 
> 32837 (10.23 Miall)
> > Ecology & Evolution Res. Group.         lab: 0113 34 32884 
> (10.20 Miall)
> > School of Biological Sciences           Mobile: 07966160266
> > University of Leeds                     email: 
> t.c.cameron at leeds.ac.uk
> > Leeds LS2 9JT
> > LS2 9JT
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Thu Feb  2 05:16:57 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 01 Feb 2006 20:16:57 -0800
Subject: [R] Filtering the time series
In-Reply-To: <20060130092840.17635.qmail@webmail24.rediffmail.com>
References: <20060130092840.17635.qmail@webmail24.rediffmail.com>
Message-ID: <43E187B9.6080906@pdf.com>

	  The Nyquist frequency is shockingly easy:  Google just produced for 
me about 766,000 hits.  The first two I checked said the Nyquist 
frequency is half the sampling rate (e.g., 
http://en.wikipedia.org/wiki/Nyquist_frequency).  Therefore, with daily 
numbers, the Nyquist frequency is 0.5 days, which means you can detect 
patterns that occur on alternate days.

	  If it were my problem, I would spend my time trying to correlate any 
cycles with known physical phenomena, like the annual weather patterns 
and the phases of the moon.  I hope some spectral wizard will enlighten 
me, but the primary value I've gotten from things like spectral analysis 
is to push me and others to think of other phenomena that occur at the 
special identified frequencies.

	  This logic pushes me to ask why you think there might be oscillations 
with periods of 10-20 days?

	  Beyond this, I suggest you consider the functions arima and 
KalmanLike in the Stats package, the time series chapter in Venables and 
Ripley (2002) Modern Applied Statistics with S, 4th ed. (Springer).  If 
you do not have reasonable access to this latter book, I encourage you 
to tell your management that it comes most highly recommended, and that 
the purchase of a copy will be an exceptionally good investment, in my 
judgment.

	  Hope this helps.
	  spencer graves

anil kumar rohilla wrote:

>   
> Hi List,
>     I have a time series of 122 values, actualy it is 
a time series of daily indian monsoon rainfall. now i want to
filter this time series for a particular oscilation say 10 to
20days oscilation. i want to find out what amount of variance
is explained by this mode. Which package is available in R for
this purpose. and how to calculate nquest frequancy of this
series. any help is much appriciated.
> 
> thanks in advance
> anil 
> 
> 
> ANIL KUMAR( METEOROLOGIST)
> LRF SECTION 
> NATIONAL CLIMATE CENTER 
> ADGM(RESEARCH)
> INDIA METEOROLOGICAL DEPARTMENT
> SHIVIJI NAGAR
> PUNE-411005 INDIA
> MOBILE +919422023277
> anilkumar at imdpune.gov.in
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Augusto.Sanabria at ga.gov.au  Thu Feb  2 06:30:50 2006
From: Augusto.Sanabria at ga.gov.au (Augusto.Sanabria@ga.gov.au)
Date: Thu, 2 Feb 2006 16:30:50 +1100
Subject: [R] 15-min mean  values
Message-ID: <9707EBA615A57747A0668CECD4638A3081E35A@mail.agso.gov.au>


Good day everyone,

I want to use zoo(aggregate) to calculate
15-min mean values from a wind dataset which
has 1-min values. The data I have looks like this:

     vector VDATE           vector WS
1   1998-10-22:02:11          12.5
2   1998-10-22:02:12          10.1
3   1998-10-22:02:13          11.2
4   1998-10-22:02:14          10.5
5   1998-10-22:02:15          11.5
      .
      .
      .
n   2005-06-30:23:59           9.1


I want to use:

aggregate(zoo(WS),'in 15-min intervals',mean)

How do you specify 'in 15-min intervals' using
vector VDATE? The length of VDATE cannot be 
changed, otherwise it would be a trivial problem
because I can generate a 15-min spaced vector
using 'seq'.

Am I missing something?

Thanks a lot,

Augusto


--------------------------------------------
Augusto Sanabria. MSc, PhD.
Mathematical Modeller
Risk Research Group
Geospatial & Earth Monitoring Division
Geoscience Australia (www.ga.gov.au)
Cnr. Jerrabomberra Av. & Hindmarsh Dr.
Symonston ACT 2609
Ph. (02) 6249-9155



From bitwrit at ozemail.com.au  Thu Feb  2 23:28:08 2006
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Thu, 02 Feb 2006 17:28:08 -0500
Subject: [R] Broken x-axis
In-Reply-To: <000201c6273f$609de020$660010ac@Ezekiel>
References: <000201c6273f$609de020$660010ac@Ezekiel>
Message-ID: <43E28778.4090400@ozemail.com.au>

brettginsburg at sbcglobal.net wrote:
> Does anyone have experience creating a plot with a broken x-axis?
>  
> Specifically, as a pharmacologist, I typically need to present graphs
> with 2 segments, one for vehicle and one for active doses..
>  
>   |
>   | 
>   |
>     |----|   |------------------------------------------|
>      V       1    3    10    30   100  etc.
>                          Dose
>  
> Any help would be most appreciated!

Hi Brett,

Have a look at the function gap.plot in the plotrix package.

Jim



From nawlnz at yahoo.com  Thu Feb  2 07:35:05 2006
From: nawlnz at yahoo.com (Dennis Malandro)
Date: Wed, 1 Feb 2006 22:35:05 -0800 (PST)
Subject: [R] Titles in plots generated within tapply
Message-ID: <20060202063505.93154.qmail@web50505.mail.yahoo.com>

How would one go about putting titles in each of several plots
that are generated from within a call to tapply?  For example I'd
like the following two barplots to have titles 'Group 1' and
'Group 2', where '1' and '2' come from the levels of 'group'.

group <- gl(2, 10)
result <- sample(c('A', 'B'), size=length(group), replace=TRUE)
windows(7, 4)
par(mfrow = c(1, 2))
tapply(result, group,
       function(x) barplot(table(x), xlab = 'Result'))


I found something close to what I'm looking for here
http://tolstoy.newcastle.edu.au/R/help/04/09/3219.html.  So I
tried

mapply(function(x) barplot(table(x), xlab = 'Result'),
  split(result, group), main = levels(group))

Error in function (x)  : unused argument(s) (main ...)

(I expected to get titles of '1' and '2'.  Not exactly what I
asked for in the question, but it would have been progress.)

Much obliged,
Dennis



From ggrothendieck at gmail.com  Thu Feb  2 07:44:18 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 2 Feb 2006 01:44:18 -0500
Subject: [R] 15-min mean values
In-Reply-To: <9707EBA615A57747A0668CECD4638A3081E35A@mail.agso.gov.au>
References: <9707EBA615A57747A0668CECD4638A3081E35A@mail.agso.gov.au>
Message-ID: <971536df0602012244v46fcd819t9e6c09444932051b@mail.gmail.com>

Assume VDATE is a character vector.  If its a
factor first convert it using

	VDATE <- as.character(VDATE)

Lets assume we only need the times portion
and later we handle the full case which may or
may be needed.

We create a times object from the times portion of
vdate and then in the aggregate statement we use
trunc.times -- note that trunc.times is a recent
addition to the chron package so make sure you have
the latest chron and R 2.2.1.    See ?trunc.times

# test data
library(chron)
library(zoo)
VDATE <- c("1998-10-22:02:11", "1998-10-22:02:12",
"1998-10-22:02:13", "1998-10-22:02:14", "1998-10-22:02:15")
WS <- c(12.5, 10.1, 11.2, 10.5, 11.5)

# convert VDATES to times class and aggregate
vtimes <- times(sub(".*:(..:..)", "\\1:00", VDATE))
aggregate(zoo(WS), trunc(vtimes, "00:15:00"), mean)

If we need the day part too then its only a little
harder.

Represent VDATE as a chron object, vdate.  We do this
by extracting out the date and time portions
and converting each separately.  We use regular
expressions to do that conversion but show in a
comment how to do it without regular expressions.
See R News 4/1 Help Desk for more info on this and
the table at the end of the article in particular.

# alternative way to convert to vdate would be:
# vdate <- chron(dates = as.numeric(as.Date(substring(VDATE, 1, 10))),
#	       times = paste(substring(VDATE, 12), 0, sep =":"))


vdate <- chron(dates = sub("(....)-(..)-(..).*", "\\2/\\3/\\1", VDATE),
	times = sub(".*:(..:..)", "\\1:00", VDATE))
aggregate(zoo(WS), chron(trunc(times(vdate), "00:15:00")), mean)

On 2/2/06, Augusto.Sanabria at ga.gov.au <Augusto.Sanabria at ga.gov.au> wrote:
>
> Good day everyone,
>
> I want to use zoo(aggregate) to calculate
> 15-min mean values from a wind dataset which
> has 1-min values. The data I have looks like this:
>
>     vector VDATE           vector WS
> 1   1998-10-22:02:11          12.5
> 2   1998-10-22:02:12          10.1
> 3   1998-10-22:02:13          11.2
> 4   1998-10-22:02:14          10.5
> 5   1998-10-22:02:15          11.5
>      .
>      .
>      .
> n   2005-06-30:23:59           9.1
>
>
> I want to use:
>
> aggregate(zoo(WS),'in 15-min intervals',mean)
>
> How do you specify 'in 15-min intervals' using
> vector VDATE? The length of VDATE cannot be
> changed, otherwise it would be a trivial problem
> because I can generate a 15-min spaced vector
> using 'seq'.
>
> Am I missing something?
>
> Thanks a lot,
>
> Augusto
>
>
> --------------------------------------------
> Augusto Sanabria. MSc, PhD.
> Mathematical Modeller
> Risk Research Group
> Geospatial & Earth Monitoring Division
> Geoscience Australia (www.ga.gov.au)
> Cnr. Jerrabomberra Av. & Hindmarsh Dr.
> Symonston ACT 2609
> Ph. (02) 6249-9155
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Thu Feb  2 07:52:26 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Feb 2006 06:52:26 +0000 (GMT)
Subject: [R] fisher table probability
In-Reply-To: <20060202012114.83085.qmail@web34801.mail.mud.yahoo.com>
References: <20060202012114.83085.qmail@web34801.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.61.0602020651140.8971@gannet.stats>

On Wed, 1 Feb 2006, array chip wrote:

> Hi, is there a way to generate the table's probability
> when doing the fisher's exact test on a 2x2 table? The
> fisher's exact test gives the p value, but not the
> probability for the table.

Call dhyper, as fisher.test itself does.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From DrJones at alum.MIT.edu  Thu Feb  2 07:56:52 2006
From: DrJones at alum.MIT.edu (Thomas L Jones)
Date: Thu, 2 Feb 2006 01:56:52 -0500
Subject: [R] Defining and running a simple function
Message-ID: <000301c627c5$d9304e20$2f01a8c0@DrJones>

I am trying, with extremely limited success, to get the R software to 
do some simple computations. Specifically, I defined a test function 
as follows:

fn <- function () {

hw <- "hello world"

hw

s <- seq (0, 0.98, 0.02)

s

}

The output should just be the words "hello world," followed by a 
sequence going from 0 to 0.98.

However, when I call the little test function:

fn ()

the words "hello world" get lost and do not come out. Instead, the 
output begins with

[1] 0.00 0.02, etc

However, when I write a test function for just the words "hello 
world," the words come out just fine.

Here is the setup:

R-2.2.0 using the English language and the console
Windows XP Home Edition Service Pack 2
AVG Antivirus Free Version
Windows built-in firewall
The R buffered output is disabled.
Mozilla Firefox 1.5
Administrator privileges are enabled.

Your advice?

Tom Jones



From ripley at stats.ox.ac.uk  Thu Feb  2 08:03:11 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Feb 2006 07:03:11 +0000 (GMT)
Subject: [R] Titles in plots generated within tapply
In-Reply-To: <20060202063505.93154.qmail@web50505.mail.yahoo.com>
References: <20060202063505.93154.qmail@web50505.mail.yahoo.com>
Message-ID: <Pine.LNX.4.61.0602020656141.8971@gannet.stats>

On Wed, 1 Feb 2006, Dennis Malandro wrote:

> How would one go about putting titles in each of several plots
> that are generated from within a call to tapply?  For example I'd
> like the following two barplots to have titles 'Group 1' and
> 'Group 2', where '1' and '2' come from the levels of 'group'.
>
> group <- gl(2, 10)
> result <- sample(c('A', 'B'), size=length(group), replace=TRUE)
> windows(7, 4)
> par(mfrow = c(1, 2))
> tapply(result, group,
>       function(x) barplot(table(x), xlab = 'Result'))

You don't need tapply here (it is just lapply on split). Try

X <- split(result, group)
for(i in levels(group))
     barplot(table(X[[i]]), xlab = 'Result', main = paste("Group", i))

You could use lapply() rather than for(), but there would be no 
benefit.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at gmail.com  Thu Feb  2 08:17:00 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 2 Feb 2006 02:17:00 -0500
Subject: [R] Defining and running a simple function
In-Reply-To: <000301c627c5$d9304e20$2f01a8c0@DrJones>
References: <000301c627c5$d9304e20$2f01a8c0@DrJones>
Message-ID: <971536df0602012317t4d3b31fai27cc90420e45ff40@mail.gmail.com>

Placing a variable on a line by itself only invokes print if you type
it in from the console.  In a function you must use an explicit
print.

On 2/2/06, Thomas L Jones <DrJones at alum.mit.edu> wrote:
> I am trying, with extremely limited success, to get the R software to
> do some simple computations. Specifically, I defined a test function
> as follows:
>
> fn <- function () {
>
> hw <- "hello world"
>
> hw
>
> s <- seq (0, 0.98, 0.02)
>
> s
>
> }
>
> The output should just be the words "hello world," followed by a
> sequence going from 0 to 0.98.
>
> However, when I call the little test function:
>
> fn ()
>
> the words "hello world" get lost and do not come out. Instead, the
> output begins with
>
> [1] 0.00 0.02, etc
>
> However, when I write a test function for just the words "hello
> world," the words come out just fine.
>
> Here is the setup:
>
> R-2.2.0 using the English language and the console
> Windows XP Home Edition Service Pack 2
> AVG Antivirus Free Version
> Windows built-in firewall
> The R buffered output is disabled.
> Mozilla Firefox 1.5
> Administrator privileges are enabled.
>
> Your advice?
>
> Tom Jones
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From christos at nuverabio.com  Thu Feb  2 08:28:57 2006
From: christos at nuverabio.com (Christos Hatzis)
Date: Thu, 2 Feb 2006 02:28:57 -0500
Subject: [R] Titles in plots generated within tapply
In-Reply-To: <20060202063505.93154.qmail@web50505.mail.yahoo.com>
Message-ID: <000001c627ca$573e3710$0202a8c0@headquarters>

You were close with mapply.  You can pass the labels as a second argument to
your function
To take advantage of the vectorized nature of mapply:

mapply(function(x,y) barplot(table(x), xlab = 'Result',
main=paste("Group",y,sep="-")),
 split(result, group), levels(group)) 

-Christos

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dennis Malandro
Sent: Thursday, February 02, 2006 1:35 AM
To: R-help at stat.math.ethz.ch
Subject: [R] Titles in plots generated within tapply

How would one go about putting titles in each of several plots that are
generated from within a call to tapply?  For example I'd like the following
two barplots to have titles 'Group 1' and 'Group 2', where '1' and '2' come
from the levels of 'group'.

group <- gl(2, 10)
result <- sample(c('A', 'B'), size=length(group), replace=TRUE) windows(7,
4) par(mfrow = c(1, 2)) tapply(result, group,
       function(x) barplot(table(x), xlab = 'Result'))


I found something close to what I'm looking for here
http://tolstoy.newcastle.edu.au/R/help/04/09/3219.html.  So I tried

mapply(function(x) barplot(table(x), xlab = 'Result'),
  split(result, group), main = levels(group))

Error in function (x)  : unused argument(s) (main ...)

(I expected to get titles of '1' and '2'.  Not exactly what I asked for in
the question, but it would have been progress.)

Much obliged,
Dennis

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Thu Feb  2 08:49:58 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Feb 2006 07:49:58 +0000 (GMT)
Subject: [R] Defining and running a simple function
In-Reply-To: <000301c627c5$d9304e20$2f01a8c0@DrJones>
References: <000301c627c5$d9304e20$2f01a8c0@DrJones>
Message-ID: <Pine.LNX.4.61.0602020746560.23404@gannet.stats>

To print something you use print().

Auto-printing ensures that the value of an expression is (usually) printed 
at the top-level prompt and not otherwise.  So your function could be

fn <- function() {
     print("hello world")
     seq(0, 0.98, 0.2)
}

(Please use a more informative subject line.)


On Thu, 2 Feb 2006, Thomas L Jones wrote:

> I am trying, with extremely limited success, to get the R software to
> do some simple computations. Specifically, I defined a test function
> as follows:
>
> fn <- function () {
>
> hw <- "hello world"
>
> hw
>
> s <- seq (0, 0.98, 0.02)
>
> s
>
> }
>
> The output should just be the words "hello world," followed by a
> sequence going from 0 to 0.98.
>
> However, when I call the little test function:
>
> fn ()
>
> the words "hello world" get lost and do not come out. Instead, the
> output begins with
>
> [1] 0.00 0.02, etc
>
> However, when I write a test function for just the words "hello
> world," the words come out just fine.
>
> Here is the setup:
>
> R-2.2.0 using the English language and the console
> Windows XP Home Edition Service Pack 2
> AVG Antivirus Free Version
> Windows built-in firewall
> The R buffered output is disabled.
> Mozilla Firefox 1.5
> Administrator privileges are enabled.
>
> Your advice?
>
> Tom Jones
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From comtech.usa at gmail.com  Thu Feb  2 08:57:31 2006
From: comtech.usa at gmail.com (Michael)
Date: Wed, 1 Feb 2006 23:57:31 -0800
Subject: [R] How to force a vector to be column or row vector?
Message-ID: <b1f16d9d0602012357k11eb3314u702c4789edfb84e3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060201/92d92a20/attachment.pl

From ggrothendieck at gmail.com  Thu Feb  2 09:00:54 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 2 Feb 2006 03:00:54 -0500
Subject: [R] How to force a vector to be column or row vector?
In-Reply-To: <b1f16d9d0602012357k11eb3314u702c4789edfb84e3@mail.gmail.com>
References: <b1f16d9d0602012357k11eb3314u702c4789edfb84e3@mail.gmail.com>
Message-ID: <971536df0602020000g43ecc0fbkb3422ca969f2b6c6@mail.gmail.com>

Try this:


rbind(c(x))
cbind(c(x))
t(c(x))

On 2/2/06, Michael <comtech.usa at gmail.com> wrote:
> Hi all,
>
> I tended to use rbind, or cbind to force a vector be be deemed as a column
> or row vector. This is very important if I want to do things like u' * A *
> u, where u' is a row vector and u is a column vector, regardless of what
> originall format  the "u" is... I want to recast it to column vector or row
> vector...  How can I do that?
>
> ----------------------------------------------------
>
>
> b_hat=solve(t(X) %*% X) %*% t(X) %*% Y;
>
> attr(b_hat, "dim")
> [1] 4 1
>
> rbind(b_hat)
>       [,1]
>  -4.814763
> V -5.804245
>  -5.122668
>  -4.308326
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From comtech.usa at gmail.com  Thu Feb  2 09:39:13 2006
From: comtech.usa at gmail.com (Michael)
Date: Thu, 2 Feb 2006 00:39:13 -0800
Subject: [R] is there a way to visualize 3D normal distributions?
Message-ID: <b1f16d9d0602020039t5604b508m11d857f67f903e91@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060202/f7a3fd52/attachment.pl

From buser at stat.math.ethz.ch  Thu Feb  2 09:45:16 2006
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Thu, 2 Feb 2006 09:45:16 +0100
Subject: [R] Randomised Block Design
In-Reply-To: <Pine.LNX.4.58L.0602011121120.21528@lexx.eu.org>
References: <Pine.LNX.4.58L.0602011121120.21528@lexx.eu.org>
Message-ID: <17377.50844.496663.304031@stat.math.ethz.ch>

Hi

try ?aov

That's a good starting point with references to other functions
in R and some literature.

Regards,

Christoph Buser

--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C13
ETH (Federal Inst. Technology)	8092 Zurich	 SWITZERLAND
phone: x-41-44-632-4673		fax: 632-1228
http://stat.ethz.ch/~buser/
--------------------------------------------------------------


Krzysztof Suwada writes:
 > Hi, I'm studying math, and i have to make an analysys using Randomised 
 > Block Design. I have two factors, i know how to do this in Statistica, but 
 > how to do this in R, i read some manuals but the only thing that i have 
 > found was 2 factor ANOVA.
 > 
 > Please could someone help me, or give some usefull links ??
 > 
 > 
 > Krzytsztof Suwada
 > 
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From tmlammail at yahoo.com  Thu Feb  2 09:47:58 2006
From: tmlammail at yahoo.com (Martin Lam)
Date: Thu, 2 Feb 2006 00:47:58 -0800 (PST)
Subject: [R] How to force a vector to be column or row vector?
In-Reply-To: <b1f16d9d0602012357k11eb3314u702c4789edfb84e3@mail.gmail.com>
Message-ID: <20060202084758.84382.qmail@web34710.mail.mud.yahoo.com>

Hi,

Perhaps you should try the transpose function t(). It
converts a row into a column and vice versa.

HTH,

Martin Lam

--- Michael <comtech.usa at gmail.com> wrote:

> Hi all,
> 
> I tended to use rbind, or cbind to force a vector be
> be deemed as a column
> or row vector. This is very important if I want to
> do things like u' * A *
> u, where u' is a row vector and u is a column
> vector, regardless of what
> originall format  the "u" is... I want to recast it
> to column vector or row
> vector...  How can I do that?
> 
> ----------------------------------------------------
> 
> 
> b_hat=solve(t(X) %*% X) %*% t(X) %*% Y;
> 
> attr(b_hat, "dim")
> [1] 4 1
> 
> rbind(b_hat)
>        [,1]
>   -4.814763
> V -5.804245
>   -5.122668
>   -4.308326
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Thu Feb  2 10:03:23 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 02 Feb 2006 10:03:23 +0100
Subject: [R] GetBioC install issue
In-Reply-To: <3E7270E9D0A68A4CA47B1A6BF44926E702BDCA91@nbiexchange.neurocrine.local>
References: <3E7270E9D0A68A4CA47B1A6BF44926E702BDCA91@nbiexchange.neurocrine.local>
Message-ID: <43E1CADB.3030204@statistik.uni-dortmund.de>

Roth, Richard wrote:

> Hi, I am trying to install the BioC package from bioconductor onto a Windows Server 2003 machine.  I can connect to bioconductor and when I run the getBioC("affy","release") function it starts to download but then it stops with the following error:
> 
> Error: unable to create temporary directory 'C:\Program Files\R\R-2.2.1\release\file1eb26e9'
>

If this is not a connection, permission or free-space issue you can only 
resolve yourself, please ask on the BioC mailing list.

Uwe Ligges



> The download just ends there.
> 
> 
> Does anyone have any idea what the problem is?
> 
> Thanks, Rich
> 
> Rich Roth, PhD
> Senior Scientist, Bioinformatics
> Molecular Medicine
> Neurocrine Biosciences
> 858-617-7204
> 
> 
> 
> 
> ------------------------------------------------------------------------
> 
> "MMS <neurocrine.com>" made the following
>  annotations on 02/01/2006 02:47:16 PM
> ------------------------------------------------------------------------------
> This email may contain confidential and privileged material ...{{dropped}}
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From r.hankin at noc.soton.ac.uk  Thu Feb  2 10:02:27 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Thu, 2 Feb 2006 09:02:27 +0000
Subject: [R] 3d from file
In-Reply-To: <1e96d61e04a8e3940aa6b1d144120e07@di.unito.it>
References: <1e96d61e04a8e3940aa6b1d144120e07@di.unito.it>
Message-ID: <3BA94C1E-BF2C-4FAA-90E4-579FDF741811@soc.soton.ac.uk>

Hi


try p3d() in package onion.


HTH


rksh


On 1 Feb 2006, at 17:57, andrea valle wrote:

> Dear all,
> sorry if it's obvious but I wasn't able to find a solution by myself.
>
> I have a text file filled with 3 colums representing xyz coodinates
> (i.e. positions) of an objects.
> Can I have in R a 3d plot representig  my object' s positions?
> I guess that I can but I don't know how.
>
> Any help is much appreciated
>
> Thanks a lot
>
>
> -a-
>
>
>
>
> Andrea Valle
> DAMS - Facolt?? di Scienze della Formazione
> Universit?? degli Studi di Torino
> http://www.semiotiche.it/andrea
> andrea.valle at unito.it
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From Arne.Muller at sanofi-aventis.com  Thu Feb  2 11:04:22 2006
From: Arne.Muller at sanofi-aventis.com (Arne.Muller@sanofi-aventis.com)
Date: Thu, 2 Feb 2006 11:04:22 +0100
Subject: [R] calculating IC50
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADE02C8B811@CRBSMXSUSR04>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060202/58b74dee/attachment.pl

From Lucy.Crooks at env.ethz.ch  Thu Feb  2 11:35:03 2006
From: Lucy.Crooks at env.ethz.ch (Lucy Crooks)
Date: Thu, 2 Feb 2006 11:35:03 +0100
Subject: [R] memory limit in aov
In-Reply-To: <x2r76nyw67.fsf@viggo.kubism.ku.dk>
References: <9ACED283-2FE7-4E10-A845-E7BF4D6F69D7@env.ethz.ch>
	<x2r76nyw67.fsf@viggo.kubism.ku.dk>
Message-ID: <74C51E77-1F30-4457-9F18-90198630312F@env.ethz.ch>

Thanks for your reply.

Thanks for info on aov-hadn't been able to tell which to use from  
help pages. There are no random effects so will switch to lm().

The data are amino acid sequences, with factor being position and  
level which amino acid is present. There are indeed an average of  
around 8 per position (from 2 to 20). I don't think I can collapse  
the levels at least to start with as I don't know in advance which  
effect fitness (the y variable).

 From what you say R should be able to do the smaller analysis. So  
have increased the RAM and will try this again.

Lucy Crooks

On Feb 1, 2006, at 3:45 PM, Peter Dalgaard wrote:
> You do not want to use aov() on unbalanced data, and especially not on
> large data sets if random effects are involved. Rather, you need to
> look at lmer() or just lm() if no random effects are present.
>
> However, even so, if you really have 29025 parameters to estimate, I
> think you're out of luck. 8 billion (US) elements is 64G and R is not
> able to handle objects of that size - the limit is that the size must
> fit in a 32 bit integer (about 2 billion elements).
>
> A quick calculation suggests that your factors have around 8 levels
> each. Is that really necessary, or can you perhaps collapse some
> levels?
>
>
>
> -- 
>    O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)  
> 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)  
> 35327907


> Lucy Crooks <Lucy.Crooks at env.ethz.ch> writes:
>> I want to do an unbalanced anova on 272,992 observations with 405
>> factors including 2-way interactions between 1 of these factors and
>> the other 404. After fitting only 11 factors and their interactions I
>> get error messages like:
>>
>> Error: cannot allocate vector of size 1433066 Kb
>> R(365,0xa000ed68) malloc: *** vm_allocate(size=1467461632) failed
>> (error code=3)
>> R(365,0xa000ed68) malloc: *** error: can't allocate region
>> R(365,0xa000ed68) malloc: *** set a breakpoint in szone_error to  
>> debug
>>
>> I think that the anova involves a matrix of 272,992 rows by 29025
>> columns (using dummy variables)=7,900 million elements. I realise
>> this is a lot! Could I solve this if I had more RAM or is it just too
>> big?
>>
>> Another possibility is to do 16 separate analyses on 17,062
>> observations with 404 factors (although statistically I think the
>> first approach is preferable). I get similar error messages then:
>>
>> Error: cannot allocate vector of size 175685 Kb
>> R(365,0xa000ed68) malloc: *** vm_allocate(size=179904512) failed
>> (error code=3)
>>
>> I think this analysis requires a 31 million element matrix.
>>
>> I am using R version 2.2.1 on a Mac G5 with 1 GB RAM running OS
>> 10.4.4. Can somebody tell me what the limitations of my machine (or
>> R) are likely to be? Whether this smaller analysis is feasible? and
>> if so how much more memory I might require?
>>
>> The data is in R in a data frame of 272,992 rows by 406 columns. I
>> would really appreciate any helpful input.
>>



From ripley at stats.ox.ac.uk  Thu Feb  2 11:40:41 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Feb 2006 10:40:41 +0000 (GMT)
Subject: [R] calculating IC50
In-Reply-To: <C80ECAFA2ACC1B45BE45D133ED660ADE02C8B811@CRBSMXSUSR04>
References: <C80ECAFA2ACC1B45BE45D133ED660ADE02C8B811@CRBSMXSUSR04>
Message-ID: <Pine.LNX.4.61.0602021038290.32251@gannet.stats>

On Thu, 2 Feb 2006 Arne.Muller at sanofi-aventis.com wrote:

> I was wondering if there is an R-package to automatically calculate the 
> IC50 value (concentration of a substrance that inhibits cell growth to 
> 50%) for some measurements.

Function dose.p in recommended package MASS.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From murdoch at stats.uwo.ca  Thu Feb  2 12:51:03 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 02 Feb 2006 06:51:03 -0500
Subject: [R] is there a way to visualize 3D normal distributions?
In-Reply-To: <b1f16d9d0602020039t5604b508m11d857f67f903e91@mail.gmail.com>
References: <b1f16d9d0602020039t5604b508m11d857f67f903e91@mail.gmail.com>
Message-ID: <43E1F227.7000602@stats.uwo.ca>

On 2/2/2006 3:39 AM, Michael wrote:
> Hi all,
> 
> How do I visualize a contour of a tri-variate normal distribution?
> 
> I just like to see the ellipsoid very much. I hope there is a easy way or
> existing method in R.

The misc3d package includes a function for 3d contour plots; that should 
do what you want.

There are some errors in the rendering when plotting multiple contours, 
due to limitations in rgl (the underlying package that does the 
rendering).  The problem is that transparent surfaces need to be 
rendered in order from back to front, and rgl doesn't do that.  But it 
still looks good.

Duncan Murdoch



From Robert.Calver at informa.com  Thu Feb  2 13:49:09 2006
From: Robert.Calver at informa.com (Robert.Calver@informa.com)
Date: Thu, 2 Feb 2006 12:49:09 -0000
Subject: [R] ANNOUNCEMENT: 20% discount on new R books from Chapman &
	Hall/CRC
Message-ID: <5C8D1755908F324C9EF0207518D99AB2EA1438@UKEXBE01.UK.CorpLAN.net>

20% discount on four new R books from Chapman & Hall/CRC

Chapman and Hall/CRC is pleased to announce the publication of four new books on R, all available through our website at 20% discount to users of R. To take advantage of this permanent offer, which is valid across all of our R books, simply visit http://www.crcpress.com/, choose your titles, and insert the online discount code - 585HHXXXX - in the 'Promotion Code' field at checkout.

** NEW TITLES! **

A Handbook of Statistical Analyses using R
Brian S. Everitt and Torsten Hothorn

With emphasis on the use of R and the interpretation of results rather than the theory behind the methods, this book addresses particular statistical techniques and demonstrates how they can be applied to one or more data sets using R. The authors provide a concise introduction to R, including a summary of its most important features. They cover a variety of topics, such as simple inference, generalized linear models, multilevel models, longitudinal data, cluster analysis, principal components analysis, and discriminant analysis. With numerous figures and exercises, A Handbook of Statistical Analysis using R provides useful information for students as well as statisticians and data analysts. All datasets and code used in the book are available as a downloadable package from CRAN.

Discounted Price: $39.96/??23.99

For more details and to order:
http://www.crcpress.com/shopping_cart/products/product_detail.asp?sku=C5394&parent_id=&pc=

***

Generalized Additive Models: An Introduction with R
Simon N. Wood

This book aims to provide readers with a thorough understanding of the theory and practical applications of GAMs, to enable informed use of these very flexible tools and related advanced models. The author's approach is based on a framework of penalized regression splines, and he provides a well grounded introduction through motivating chapters on linear and generalized linear models, as well as covering more advanced extensions via a final chapter on mixed models, including GAMMs. The author uses the R software throughout to explain the underlying theory and illustrate the practicalities of linear, generalized linear and generalized additive models, as well as their mixed effect extensions. Background theory on likelihood, matrix algebra and the geometry of model estimation is also provided, so that the book is reasonably self contained. Each chapter has exercises for which complete solutions are provided in an appendix. An R package containing the featured datasets is also freely available through CRAN.

Discounted Price: $63.96/??31.99

For more details and to order:
http://www.crcpress.com/shopping_cart/products/product_detail.asp?sku=C4746&parent_id=&pc=

***

Extending Linear models with R: Generalized Linear, Mixed Effects and Nonparametric Regression Models
Julian J. Faraway

This book surveys the techniques that grow from the regression model, presenting three extensions to that framework: generalized linear models (GLMs), mixed effect models, and nonparametric regression models. The author's treatment is thoroughly modern and covers topics that include GLM diagnostics, generalized linear mixed models, trees, and even the use of neural networks in statistics. To demonstrate the interplay of theory and practice, throughout the book the author weaves the use of the R software environment to analyze the data of real examples, providing all of the R commands necessary to reproduce the analyses.

Discounted Price: $63.96/??31.99

For more details and to order:
http://www.crcpress.com/shopping_cart/products/product_detail.asp?sku=C424X&parent_id=&pc=

***

Robust Statistical Methods with R
Jana Jureckova and Jan Picek

This book provides a systematic treatment of robust procedures with an emphasis on practical application. The authors work from underlying mathematical tools to implementation, paying special attention to the computational aspects. They cover the whole range of robust methods, including differentiable statistical functions, distance of measures, influence functions, and asymptotic distributions, in a rigorous yet approachable manner. Highlighting hands-on problem solving, many examples and computational algorithms using the R software supplement the discussion. The book examines the characteristics of robustness, estimators of real parameter, large sample properties, and goodness-of-fit tests. It also includes a brief overview of R in an appendix for those with little experience using the software.

Discounted Price: $63.96/??35.99

For more details and to order:
http://www.crcpress.com/shopping_cart/products/product_detail.asp?sku=C4541&parent_id=&pc=

** OTHER TITLES! **

R Graphics
Paul Murrell

A description of the core graphics features of R including: a brief introduction to R; an introduction to general R graphics features. The base graphics system of R: traditional S graphics. The power and flexibility of grid graphics. Building on top of the base or grid graphics: Trellis graphics and developing new graphics functions. 

Discounted Price: $55.96/??31.99

For more details and to order:
http://www.crcpress.com/shopping_cart/products/product_detail.asp?sku=C486X&parent_id=&pc

***

Using R for Introductory Statistics
John Verzani  

This book fills a gap as a true introduction to statistics using R. With emphasis on data analysis and practical examples, it encourages understanding rather than focusing on learning the underlying theory. It includes a large collection of exercises and numerous practical examples from a broad range of scientific disciplines. It comes complete with an online resource containing datasets, R functions, selected solutions to exercises, and updates to the latest features. A full solutions manual is available from Chapman & Hall/CRC.
 
Discounted Price: $35.96/??19.99

For more details and to order:
http://www.crcpress.com/shopping_cart/products/product_detail.asp?sku=C4509&parent_id=&pc

***

Linear Models with R
Julian J. Faraway

Focussed on the practice of regression and analysis of variance, this book clearly demonstrates the different methods available and in which situations each one applies. It covers all of the standard topics, from the basics of estimation to missing data, factorial designs, and block designs, but it also includes discussion of topics, such as model uncertainty, rarely addressed in books of this type. The presentation incorporates an abundance of examples that clarify both the use of each technique and the conclusions one can draw from the results. 

Discounted Price: $55.96/??31.99

For more details and to order:
http://www.crcpress.com/shopping_cart/products/product_detail.asp?sku=C4258&parent_id=&pc

***

Correspondence Analysis and Data Coding with Java and R
Fionn Murtagh

Provides an introduction to methods and applications of correspondence analysis, with an emphasis on data coding - the first step in correspondence analysis. It features a practical presentation of the theory with a range of applications from data mining, financial engineering, and the biosciences. Implementation of the methods is presented using Java and R software.  

Discounted Price: $63.96/??35.99

For more details and to order:
http://www.crcpress.com/shopping_cart/products/product_detail.asp?sku=C5289&parent_id=&pc

** CALL FOR AUTHORS **

If you are working on a manuscript or have an idea for a book, and are interested in publishing with Chapman & Hall/CRC, we would be delighted to hear from you. Please do not hesitate to contact us if you would like to discuss publishing, or have any questions about any of our titles.

Rob Calver
Acquisitions Editor, Statistics
Chapman & Hall/CRC
Taylor & Francis Group
Informa
24 Blades Court
Deodar Road
London SW15 2NU, UK

Tel: +44 (0)20 7017 6334
Fax: +44 (0)20 7017 6747
Email: mailto:rob.calver at informa.com



********************************************************************************

If you have received this message in error, please notify us by return and delete the message and any attachments.  Further enquiries/returns can be sent to postmaster at informa.com



From wettenhall at wehi.EDU.AU  Thu Feb  2 13:53:20 2006
From: wettenhall at wehi.EDU.AU (James Wettenhall)
Date: Thu, 2 Feb 2006 23:53:20 +1100 (EST)
Subject: [R] Request for users of my R-Tcl/Tk examples, limmaGUI or affylmGUI
Message-ID: <22723.61.9.148.22.1138884800.squirrel@homebase.wehi.edu.au>

[PLEASE REPLY _OFF_ THE LIST, i.e. DON'T CC to r-help at ...]

Hi,

I don't see this sort of thing very often on the mailing lists, so list
moderators and others should feel free to tell me if it breaches list
etiquette and/or delete my post if necessary.  But I can't see what harm
it could do...

I am just wondering approximately how many people use / have used some of
the R stuff I've developed (and in how many countries).  In particular I'm
talking about the R-Tcl/Tk examples I've put at
http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/ and/or my two BioC
packages limmaGUI and affylmGUI (now maintained by Keith Satterley),
and/or the IBC2004 and JSM2005 microarray analysis course websites.

If it's not too much trouble, could you please tell me [OFF THE LIST] if
you use / have used any of these things (otherwise don't reply) and what
country you are from, and if there are many other people where you work
who use them but would not reply on the R mailing list themself? e.g.

"I use / have used your R-Tcl/Tk Examples.  I am from Canada.  Two other
people I work with have also used them, but they don't read the R mailing
lists so won't reply themselves."

If I get an absolutely massive response, I may have to set up some harsh
email filters and delete some of the incoming replies, but I think I can
handle the sort of response I am expecting.

Apologies if anyone feels that I am misusing the mailing list(s).

Best wishes to all,
James



From Roel.May at nina.no  Thu Feb  2 14:04:32 2006
From: Roel.May at nina.no (May, Roel)
Date: Thu, 2 Feb 2006 14:04:32 +0100
Subject: [R] error message in cox regression cph()
Message-ID: <BBD6B096C5BCAE4E80CC7423CD9532D728BFE0@DL140.nina.no>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060202/cd13d8e4/attachment.pl

From d.firth at warwick.ac.uk  Thu Feb  2 14:07:23 2006
From: d.firth at warwick.ac.uk (David Firth)
Date: Thu, 2 Feb 2006 13:07:23 +0000
Subject: [R] Request for users of my R-Tcl/Tk examples,
	limmaGUI or affylmGUI
In-Reply-To: <22723.61.9.148.22.1138884800.squirrel@homebase.wehi.edu.au>
References: <22723.61.9.148.22.1138884800.squirrel@homebase.wehi.edu.au>
Message-ID: <200602021307.23600.d.firth@warwick.ac.uk>

I have used your R-Tcl/Tk Examples.  (Thanks!  The ideas 
were much appreciated.) 
I am from the United Kingdom. 

David

-- 
Professor David Firth
http://www.warwick.ac.uk/go/dfirth



From b.otto at uke.uni-hamburg.de  Thu Feb  2 14:09:45 2006
From: b.otto at uke.uni-hamburg.de (Benjamin Otto)
Date: Thu, 2 Feb 2006 14:09:45 +0100
Subject: [R] readline detection problems
Message-ID: <NOEOKKCPBGIAIPPDONMGAEGICBAA.b.otto@uke.uni-hamburg.de>

Dear community,

I'm trying to install R-2.2.1 on an IRIX 6.2 (Unix System V Release 4)
system without root access. Unfortunately readline is not installed in
default, so I installed it locally in my home directory, more precisely in:
$HOME/vol/readline-5.1, where $HOME is "/home3/fa/faga001". Afterwards I
appended the path to the library with several $PATH variable, which now
looks like:

PATH=:/usr/sbin:/usr/bsd:/sbin:/usr/bin:/bin:/usr/bin/X11:/usr/local/bin:/us
r/freeware/bin:/usr/local/bin:.:/home3/fa/faga001/vol:/home3/fa/faga001/vol/
readline-5.1:/home3/fa/faga001/vol/readline-5.1/lib

Still, readline is not detected by the configure script. I tried the
commands:

./configure --with-readline="-L/$HOME/vol/readline"
./configure --with-readline="/$HOME/vol/readline"
./configure --with-readline=/$HOME/vol/readline
./configure --x-includes="-L/$HOME/vol/readline"
./configure --x-includes="/$HOME/vol/readline"
./configure --x-libraries="-L/$HOME/vol/readline"
./configure --x-libraries="/$HOME/vol/readline"

trying out the different path variants which I previously included in the
$PATH variable. Nothing helps yet. According to printenv there is currently
no kind of $LIBRARY or sth. like that defined, but maybe the path should
rather be included in such an env. variable, I didn't find any hint in the
documentation.

Has someone an idea how I should link my local readline correctly, so that
the library is found not only during installtion but afterwards too?

regards,
Benjamin



From d.firth at warwick.ac.uk  Thu Feb  2 14:13:27 2006
From: d.firth at warwick.ac.uk (David Firth)
Date: Thu, 2 Feb 2006 13:13:27 +0000
Subject: [R] Request for users of my R-Tcl/Tk examples,
	limmaGUI or affylmGUI
In-Reply-To: <22723.61.9.148.22.1138884800.squirrel@homebase.wehi.edu.au>
References: <22723.61.9.148.22.1138884800.squirrel@homebase.wehi.edu.au>
Message-ID: <200602021313.27791.d.firth@warwick.ac.uk>

On Thursday 02 February 2006 12:53, you wrote:
...
> [PLEASE REPLY _OFF_ THE LIST, i.e. DON'T CC to
> r-help at ...]

oops!  I just realised that I hit the wrong button and 
replied to r-help just now...

Sorry!

I guess that *is* one of the perils of sending a request 
such as this to a mailing list, where clumsy fat-fingered 
people such as me might reply.

apologies all round,
David



From leog at anicca-vijja.de  Thu Feb  2 14:31:35 2006
From: leog at anicca-vijja.de (=?ISO-8859-1?Q?Leo_G=FCrtler?=)
Date: Thu, 02 Feb 2006 14:31:35 +0100
Subject: [R] norm package prelim.norm
In-Reply-To: <XFMail.060202014216.Ted.Harding@nessie.mcc.ac.uk>
References: <XFMail.060202014216.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <43E209B7.5050201@anicca-vijja.de>

(Ted Harding) schrieb:

Dear Elizabeth,

the R-package "mice" has

?md.pattern

and "Hmisc" also contains some software to describe missing data. I 
think both do not have limitations like prelim.norm.

best wishes,

leo


>On 01-Feb-06 Ted Harding wrote:
>  
>
>>On 01-Feb-06 Elizabeth Lawson wrote:
>>    
>>
>>>Hey eveyone!  I hope someone can help wiht this question.  I have a
>>>matirux of all zeros and ones and I would like to indentify all unique
>>>patterns in the rows andthe number of times the pattern occurs.   I
>>>changed all zeros to NA tried to use prelim.norm to identify all
>>>patterns of missing data in the rows.  I got the message 
>>>   
>>>  Warning message:
>>>NAs introduced by coercion 
>>>
>>>  Any ideas of how to get this to work?  Or are there any way to
>>>indentify all the unique patterns in a huge matrix? ( 10000 x 71)
>>>   
>>>  Thanks for any suggestions!!
>>>   
>>>  Elizabeth Lawson
>>>      
>>>
>>I think Chuck Celand has pretty well answered it: Don't worry
>>about the warning, since I'm pretty sure it is generated when
>>prelim.norm is calculating something else (e.g. the covariance
>>matrix) and it is not related to generating prelim.norm(X)$r
>>which is the list of patterns and the numbers of times they occur.
>>
>>Best wsihes,
>>Ted.
>>    
>>
>
>Sorry -- I should have read the detail of your original message
>more carefully. In short, you have too many columns for prelim.norm
>to work.
>
>The long answer: prelim.norm analyses the missing data patterns
>by representing the locations of NAs as integers, where the jth
>bit in the binary representation of the integer is 1 for an NA,
>0 for a non-NA. Hence the representation of the pattern runs out
>of steam when there are more than a certain number of columns,
>corresponding to the highest power of 2 that can be represented
>as an integer in R.
>
>  .Machine$integer.max
>  [1] 2147483647
>
>  2^31 -1
>  [1] 2147483647
>
>so that prelim.norm can only encode NA-patterns in an R integer
>for up to 31 columns. More than that, and it will not work properly
>or at all.
>
>Check:
>
>  X<-matrix(sample(c(0,1),87,replace=TRUE),ncol=29)
>  Y<-X; Y[Y==0]<-NA
>  prelim.norm(Y)$r
>  [...] (no warning, 3 rows)
>
>  X<-matrix(sample(c(0,1),90,replace=TRUE),ncol=30)
>  Y<-X; Y[Y==0]<-NA
>  prelim.norm(Y)$r
>  [...] (no warning, 3 rows)
>
>  X<-matrix(sample(c(0,1),93,replace=TRUE),ncol=31)
>  Y<-X; Y[Y==0]<-NA
>  prelim.norm(Y)$r
>  [...] (no warning, 3 rows)
>
>  X<-matrix(sample(c(0,1),93,replace=TRUE),ncol=32)
>  Y<-X; Y[Y==0]<-NA
>  prelim.norm(Y)$r
>  [...] (3 rows, "Warning message: NAs introduced by coercion")
>
>  X<-matrix(sample(c(0,1),93,replace=TRUE),ncol=33)
>  Y<-X; Y[Y==0]<-NA
>  prelim.norm(Y)$r
>  [...] (2 rows, "Warning message: NAs introduced by coercion")
>
>  X<-matrix(sample(c(0,1),93,replace=TRUE),ncol=34)
>  Y<-X; Y[Y==0]<-NA
>  prelim.norm(Y)$r
>  [...] (1 row, "Warning message: NAs introduced by coercion")
>
>(Try a few of these for yourself; it is very unlikely that you get
>one 1 or 2 distinct rows when you have 3 rows of 30+ 0s and 1s
>sampled at random).
>
>A similar issue came up some time ago (I can't locate the thread
>in the archive at the moment) in vennection with the 'mix'
>package.
>
>However, you can have as many columns as you like if you use
>'unique' to identify the distinct patterns of 0s and 1s, rather
>than using 'prelim.norm'.
>
>Hoping this helps,
>Ted.
>
>
>
>--------------------------------------------------------------------
>E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
>Fax-to-email: +44 (0)870 094 0861
>Date: 02-Feb-06                                       Time: 01:42:13
>------------------------------ XFMail ------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>


-- 

email: leog at anicca-vijja.de
www: http://www.anicca-vijja.de/



From f.harrell at vanderbilt.edu  Thu Feb  2 14:42:12 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 02 Feb 2006 07:42:12 -0600
Subject: [R] error message in cox regression cph()
In-Reply-To: <BBD6B096C5BCAE4E80CC7423CD9532D728BFE0@DL140.nina.no>
References: <BBD6B096C5BCAE4E80CC7423CD9532D728BFE0@DL140.nina.no>
Message-ID: <43E20C34.8020309@vanderbilt.edu>

May, Roel wrote:
> Hi,
>  
> I have been trying to get the cph() function of the Design package to work but get an error message I don't understand:
>  
> Error in if (!length(fname) || !any(fname == zname)) { : 
>         missing value where TRUE/FALSE needed
> 
> I have tried the same for a dummy dataset I made, and than it seems to work fine. However, it doesn't do it for my own data. Does anyone have a clue as to what this message means, whether I have made a mistake somewhere(although it seems ok to me?) and especially how to solve this problem. I know I could have used coxph() instead, but I'd like to predict the outcome on another dataset and coxph() does not allow for interaction terms...
>  
> I hope anyone can help me here. Underneath is the code I used for my data, if it's of any use...
>  
> Thanks, cheers Roel
>  
> Roel May
> NINA, Norway
> modeldata <- as.data.frame(modeldata)
> 
> survchoice<-Surv(2-modeldata$USED,is.element(modeldata$USED,1))


> 
> d <- datadist(modeldata$ID,modeldata$ASP_NW,modeldata$ALT,modeldata$SLOPE,modeldata$PLACEMENT,modeldata$DTL,modeldata$TRACK,modeldata$PRIVATE,modeldata$BUSH,modeldata$ROCK,modeldata$GRASS,modeldata$WATER,modeldata$RUGGED,modeldata$CABIN,data=modeldata)
>

Don't use $ in input arguments to datadist.  Use the whole data frame or 
use with( ).


> options(datadist="d")
> 
> options(contrasts=c("contr.treatment","contr.treatment"))

Remove.  This is the default.

> 
> interactmodel <- cph(survchoice~(ASP_NW+RUGGED+SLOPE+GRASS:PLACEMENT+PRIVATE+BUSH:ROCK+RUGGED:ROCK+DTL)+strat(ID),data=modeldata,method="breslow",y=TRUE,x=TRUE,surv=TRUE)

Use * for interactions and to make sure your model follows the hierarchy 
principle.

Next time please also give the version of Design you are using.

Frank

> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From andy_liaw at merck.com  Thu Feb  2 15:01:53 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 2 Feb 2006 09:01:53 -0500
Subject: [R] calculating IC50
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7AF@usctmx1106.merck.com>

Perhaps also of interest is the `drc' package on CRAN.  There's an article
in JSS describing it (probably the same as the package vignette--- haven't
checked).

Andy

From: Prof Brian Ripley
> 
> On Thu, 2 Feb 2006 Arne.Muller at sanofi-aventis.com wrote:
> 
> > I was wondering if there is an R-package to automatically 
> calculate the 
> > IC50 value (concentration of a substrance that inhibits 
> cell growth to 
> > 50%) for some measurements.
> 
> Function dose.p in recommended package MASS.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From gescati at yahoo.com.ar  Thu Feb  2 14:25:13 2006
From: gescati at yahoo.com.ar (=?iso-8859-1?q?gabriela=20escati=20pe=F1aloza?=)
Date: Thu, 2 Feb 2006 13:25:13 +0000 (GMT)
Subject: [R] Significance of degrees of freedom in nlme
Message-ID: <20060202132513.22628.qmail@web37103.mail.mud.yahoo.com>

Dear Dr. Bates,
Thank you very much for your response. I had consulted
the algorithm described in Pinheiro and Bates.
However, what I don't understand (among other things)
is why my two parameters appear to be estimated at
different grouping levels (based on the DF values).
Affect this different values of DF at the estimates
parameters? The estimates fixed effects were get at
the same level of grouping?
I apreciate any response.




Lic. Gabriela Escati Pe??aloza
Biolog??a y Manejo de Recursos Acu??ticos
Centro Nacional Patag??nico(CENPAT). 
CONICET
Bvd. Brown s/n??.
(U9120ACV)Pto. Madryn 
Chubut
Argentina

Tel: 54-2965/451301/451024/451375/45401 (Int:277)
Fax: 54-29657451543


	


	
		
___________________________________________________________ 
1GB gratis, Antivirus y Antispam 
Correo Yahoo!, el mejor correo web del mundo 
http://correo.yahoo.com.ar



From depire at inrets.fr  Thu Feb  2 15:11:42 2006
From: depire at inrets.fr (depire@inrets.fr)
Date: Thu, 02 Feb 2006 15:11:42 +0100
Subject: [R] Matrix variable in C code
Message-ID: <1138889502.43e2131e68fe9@webmail.inrets.fr>

Dear all,
I try to compute some piece of my R code in C.

My problem is about matrix.

My code in R is the following:
=============================================
VPEfron<-function(XType,ZType,dX,G,c0,c1)
{
	XS<-sort(XType)
	rang<-sort.list(XType)

     	ZS<-matrix(0,k,max(dX))
	ZS<-ZType[rang,]
	S<-rep(0,length(XType))
	for(i in 1:length(XType))
		S[i]<-sum(ZS[i,])

      VPCEfron<-function(f,S,ZS,dX,tailleS=length(XType))
      {
		f.check<-function(x) {
            x<-f(x)
            }
     
.Call("VPCEfron",body(f.check),as.double(S),as.double(ZS),as.integer(dX),as.integer(tailleS),new.env())
	}
GG<-function(z) G(z,c0,c1)

Vraisemblancepartielle<-VPCEfron(GG,S,ZS,dX)
}
=============================================

and my test code in C is:
================================================
SEXP VPCEfron(SEXP f, SEXP SR, SEXP ZR, SEXP DIR, SEXP nsR, SEXP rho)
{
	int taille=INTEGER(nsR)[0];
	int* DI=INTEGER(DIR);
	double* S=REAL(SR);
	double* Z=(ZR);

// just to check the value
	printf("verifie de S: %f - %f - %f\n",S[0],S[1],S[2]);
	printf("verifie dX: %d %d %d\n",DI[0],DI[1],DI[2]);
	printf("verifie k: %d\n",taille);
	printf("verifie de Z\n");
	printf("%f %f\n",Z[0][0]);
	printf("%f %f\n",Z[1][1]);
	printf("%f %f\n",Z[2][1]);
	somme=0.0;
	printf("STOP\n");
return(somme);
}
=========================================


All works, except ZS, the variable ZS is a matrix in R, and when i try to give
to C code, with ZR, ZR is only a vector.

How to obtain a matrix variable in C ?



From Mani.Lakshminarayanan at pfizer.com  Thu Feb  2 15:19:31 2006
From: Mani.Lakshminarayanan at pfizer.com (Lakshminarayanan, Mani)
Date: Thu, 2 Feb 2006 09:19:31 -0500
Subject: [R] Help with ldBands(Hmisc)
Message-ID: <93881773336F8947BB4A57D9EF3BE6FDDFD62A@mopamrexm19.amer.pfizer.com>

Hello My Fellow Users,

Under the details it is given that the ld98 executable should be in a subdirectory that is in the system.  Should ld98.exe be included under Hmisc (where it is stored) or under the lib subdirectory within Hmisc?  I am getting the following error message: Error in (head + 1):length(w) : NA/NaN argument.  Does this mean that I didn't store the ld98.exe in the right place or something else?  Please help.

Mani



From ripley at stats.ox.ac.uk  Thu Feb  2 15:21:41 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Feb 2006 14:21:41 +0000 (GMT)
Subject: [R] Date Not Staying in Date Format
In-Reply-To: <BAY107-F67D36AB649EEE07832946C3090@phx.gbl>
References: <BAY107-F67D36AB649EEE07832946C3090@phx.gbl>
Message-ID: <Pine.LNX.4.61.0602021420200.12062@gannet.stats>

tapply(df$Date, df$SomeFactor, max, simplify=FALSE)

works, i.e. it is the unlist() which is losing the class (and perhaps 
unlist or tapply should be a bit cleverer).

On Mon, 30 Jan 2006, David Randel wrote:

> I have a column in a data frame that has a class of "Date" and a mode of
> "numeric".  When I:
>
> max(df$Date)
>
> My output stays in Date format, i.e. "2006-01-03".
>
> However, when I run the following statment:
>
> tapply(df$Date, df$SomeFactor, max)
>
> my output looks like this:  9129   9493   9861  10226  10591  10956  11320
> 11687  12052  12417
>
> The returned object is of mode "numeric" and class "array".  Each array
> element is of mode "numeric" and class "numeric".  I believe that this is
> the integer representation of my date.  I can't seem to convert it back to a
> date.
>
> How do I get these to be intrepreted as a date instead of a number?
>
> Thanks,
> ~Dave R.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Thu Feb  2 15:27:15 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 2 Feb 2006 09:27:15 -0500
Subject: [R] How to force a vector to be column or row vector?
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7B2@usctmx1106.merck.com>

From: Gabor Grothendieck
> 
> Try this:
> 
> 
> rbind(c(x))
> cbind(c(x))
> t(c(x))

The c() is not needed above.

Also, this might be a better way of computing a quadratic form:

> x <- 1:3
> m <- matrix(sample(1:9), 3, 3)
> crossprod(crossprod(m, x), x) 
     [,1]
[1,]  202
> t(x) %*% m %*% x   # Just checking...
     [,1]
[1,]  202

In R, it usually makes little difference whether a vector is row-vector or
column-vector.

Andy

 
> On 2/2/06, Michael <comtech.usa at gmail.com> wrote:
> > Hi all,
> >
> > I tended to use rbind, or cbind to force a vector be be 
> deemed as a column
> > or row vector. This is very important if I want to do 
> things like u' * A *
> > u, where u' is a row vector and u is a column vector, 
> regardless of what
> > originall format  the "u" is... I want to recast it to 
> column vector or row
> > vector...  How can I do that?
> >
> > ----------------------------------------------------
> >
> >
> > b_hat=solve(t(X) %*% X) %*% t(X) %*% Y;
> >
> > attr(b_hat, "dim")
> > [1] 4 1
> >
> > rbind(b_hat)
> >       [,1]
> >  -4.814763
> > V -5.804245
> >  -5.122668
> >  -4.308326
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From csardi at rmki.kfki.hu  Thu Feb  2 15:32:46 2006
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Thu, 2 Feb 2006 15:32:46 +0100
Subject: [R] Matrix variable in C code
In-Reply-To: <1138889502.43e2131e68fe9@webmail.inrets.fr>
References: <1138889502.43e2131e68fe9@webmail.inrets.fr>
Message-ID: <20060202143246.GD24989@rmki.kfki.hu>

On Thu, Feb 02, 2006 at 03:11:42PM +0100, depire at inrets.fr wrote:
[...]
> 
> and my test code in C is:
> ================================================
> SEXP VPCEfron(SEXP f, SEXP SR, SEXP ZR, SEXP DIR, SEXP nsR, SEXP rho)
> {
> 	int taille=INTEGER(nsR)[0];
[...]
> 
> All works, except ZS, the variable ZS is a matrix in R, and when i try to give
> to C code, with ZR, ZR is only a vector.
> 
> How to obtain a matrix variable in C ?

A matrix is the same as a vector (stored columnwise), except that is has a 
dim attribute. Use can use SET_DIM to set the dim attribute, and GET_dim to
query it. Eg:

int nrow=INTEGER(GET_DIM(ZR))[0];
int ncol=INTEGER(GET_DIM(ZR))[1];

To access the values in the matrix you might use something like:

#define RMATRIX(m,i,j) (REAL(m)[ INTEGER(GET_DIM(m))[0]*(j)+(i) ])

and then 

RMATRIX(ZR, 0, 1), etc. works. Note that according to this #define the matrix
is indexed from zero.

Gabor


-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK



From andy_liaw at merck.com  Thu Feb  2 15:34:12 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 2 Feb 2006 09:34:12 -0500
Subject: [R] memory limit in aov
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7B3@usctmx1106.merck.com>

I don't know what the goal of the analysis is, but I have a suspicion that
the `gbm' package might be a more fruitful way...

Cheers,
Andy

From: Lucy Crooks
> 
> Thanks for your reply.
> 
> Thanks for info on aov-hadn't been able to tell which to use from  
> help pages. There are no random effects so will switch to lm().
> 
> The data are amino acid sequences, with factor being position and  
> level which amino acid is present. There are indeed an average of  
> around 8 per position (from 2 to 20). I don't think I can collapse  
> the levels at least to start with as I don't know in advance which  
> effect fitness (the y variable).
> 
>  From what you say R should be able to do the smaller analysis. So  
> have increased the RAM and will try this again.
> 
> Lucy Crooks
> 
> On Feb 1, 2006, at 3:45 PM, Peter Dalgaard wrote:
> > You do not want to use aov() on unbalanced data, and 
> especially not on
> > large data sets if random effects are involved. Rather, you need to
> > look at lmer() or just lm() if no random effects are present.
> >
> > However, even so, if you really have 29025 parameters to estimate, I
> > think you're out of luck. 8 billion (US) elements is 64G 
> and R is not
> > able to handle objects of that size - the limit is that the 
> size must
> > fit in a 32 bit integer (about 2 billion elements).
> >
> > A quick calculation suggests that your factors have around 8 levels
> > each. Is that really necessary, or can you perhaps collapse some
> > levels?
> >
> >
> >
> > -- 
> >    O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
> >   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> >  (*) \(*) -- University of Copenhagen   Denmark          
> Ph:  (+45)  
> > 35327918
> > ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  
> FAX: (+45)  
> > 35327907
> 
> 
> > Lucy Crooks <Lucy.Crooks at env.ethz.ch> writes:
> >> I want to do an unbalanced anova on 272,992 observations with 405
> >> factors including 2-way interactions between 1 of these factors and
> >> the other 404. After fitting only 11 factors and their 
> interactions I
> >> get error messages like:
> >>
> >> Error: cannot allocate vector of size 1433066 Kb
> >> R(365,0xa000ed68) malloc: *** vm_allocate(size=1467461632) failed
> >> (error code=3)
> >> R(365,0xa000ed68) malloc: *** error: can't allocate region
> >> R(365,0xa000ed68) malloc: *** set a breakpoint in szone_error to  
> >> debug
> >>
> >> I think that the anova involves a matrix of 272,992 rows by 29025
> >> columns (using dummy variables)=7,900 million elements. I realise
> >> this is a lot! Could I solve this if I had more RAM or is 
> it just too
> >> big?
> >>
> >> Another possibility is to do 16 separate analyses on 17,062
> >> observations with 404 factors (although statistically I think the
> >> first approach is preferable). I get similar error messages then:
> >>
> >> Error: cannot allocate vector of size 175685 Kb
> >> R(365,0xa000ed68) malloc: *** vm_allocate(size=179904512) failed
> >> (error code=3)
> >>
> >> I think this analysis requires a 31 million element matrix.
> >>
> >> I am using R version 2.2.1 on a Mac G5 with 1 GB RAM running OS
> >> 10.4.4. Can somebody tell me what the limitations of my machine (or
> >> R) are likely to be? Whether this smaller analysis is feasible? and
> >> if so how much more memory I might require?
> >>
> >> The data is in R in a data frame of 272,992 rows by 406 columns. I
> >> would really appreciate any helpful input.
> >>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ritz at bioassay.dk  Thu Feb  2 15:39:04 2006
From: ritz at bioassay.dk (Christian Ritz)
Date: Thu, 02 Feb 2006 15:39:04 +0100
Subject: [R] calculating IC50
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7AF@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7AF@usctmx1106.merck.com>
Message-ID: <43E21988.4090805@bioassay.dk>

Hi!

Yes, the 'drc' package can be used to obtain IC50 or any other ICx value 
for several, commonly used dose-response models.

The vignette is more up-to-date than the article in JSS (which dates 
back to the start of 2005).

Christian


Liaw, Andy wrote:

>Perhaps also of interest is the `drc' package on CRAN.  There's an article
>in JSS describing it (probably the same as the package vignette--- haven't
>checked).
>
>Andy
>
>From: Prof Brian Ripley
>  
>
>>On Thu, 2 Feb 2006 Arne.Muller at sanofi-aventis.com wrote:
>>
>>    
>>
>>>I was wondering if there is an R-package to automatically 
>>>      
>>>
>>calculate the 
>>    
>>
>>>IC50 value (concentration of a substrance that inhibits 
>>>      
>>>
>>cell growth to 
>>    
>>
>>>50%) for some measurements.
>>>      
>>>
>>Function dose.p in recommended package MASS.
>>
>>-- 
>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>University of Oxford,             Tel:  +44 1865 272861 (self)
>>1 South Parks Road,                     +44 1865 272866 (PA)
>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From ggrothendieck at gmail.com  Thu Feb  2 15:43:10 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 2 Feb 2006 09:43:10 -0500
Subject: [R] How to force a vector to be column or row vector?
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7B2@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7B2@usctmx1106.merck.com>
Message-ID: <971536df0602020643t13f2cf78jd5191ac08106b794@mail.gmail.com>

On 2/2/06, Liaw, Andy <andy_liaw at merck.com> wrote:
> From: Gabor Grothendieck
> >
> > Try this:
> >
> >
> > rbind(c(x))
> > cbind(c(x))
> > t(c(x))
>
> The c() is not needed above.

The poster asked for an expression that would work "regardless of
the original form" of the vector -- row, column or neither.  The c
gets it into a known form first.  For example:

> cbind(matrix(1,1,3))  # not a column vector!
     [,1] [,2] [,3]
[1,]    1    1    1



From dataanalytics at earthlink.net  Thu Feb  2 15:44:18 2006
From: dataanalytics at earthlink.net (Walter R. Paczkowski)
Date: Thu, 02 Feb 2006 09:44:18 -0500
Subject: [R] Handling survey data issue
Message-ID: <7.0.1.0.2.20060202094418.033d64a0@earthlink.net>


Good morning,

I have a survey from a client that has a variable, say number of 
pills taken per day, that is coded as a numeric - in part.  The 
survey respondents were asked to state the number of pills and this 
number was recorded.  But, for those who took more than 10, the 
answer was recorded as 10+.  I have to calculate a mean and do other 
estimations. How do I handle the 10+?  Any suggestions on handling 
the 10+?  Is there a way to estimate a number for 10+?  I seem to 
recall a paper years ago that addressed the issue of a censored 
answer such as 10+ to find a number that could then be used in 
calculations.  This should be a common problem.  My next question, of 
course, is: Is there an R function for this?

Thanks for any help.

Walt Paczkowski

________________________

Walter R. Paczkowski, Ph.D.
Data Analytics Corp.
44 Hamilton Lane
Plainsboro, NJ  08536
(V) 609-936-8999
(F) 609-936-3733



From bolker at ufl.edu  Thu Feb  2 15:53:20 2006
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 2 Feb 2006 14:53:20 +0000 (UTC)
Subject: [R] is there a way to visualize 3D normal distributions?
References: <b1f16d9d0602020039t5604b508m11d857f67f903e91@mail.gmail.com>
	<43E1F227.7000602@stats.uwo.ca>
Message-ID: <loom.20060202T155042-992@post.gmane.org>

Duncan Murdoch <murdoch <at> stats.uwo.ca> writes:

> 
> On 2/2/2006 3:39 AM, Michael wrote:
> > Hi all,
> > 
> > How do I visualize a contour of a tri-variate normal distribution?
> > 
> > I just like to see the ellipsoid very much. I hope there is a easy way or
> > existing method in R.
> 
> The misc3d package includes a function for 3d contour plots; that should 
> do what you want.
> 

  is contour3d really necessary or could you just plot ellipsoids?
(library(rgl); demo(shapes3d)) -- still a little bit of figuring 
to do, but this should get you most of the way there.

  Ben Bolker



From jfox at mcmaster.ca  Thu Feb  2 16:03:33 2006
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 2 Feb 2006 10:03:33 -0500
Subject: [R] is there a way to visualize 3D normal distributions?
In-Reply-To: <b1f16d9d0602020039t5604b508m11d857f67f903e91@mail.gmail.com>
Message-ID: <20060202150330.FRDT5032.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Michael,

Some time ago, I posted to r-help a solution to a problem very close to
this, which adapts the scatter3d() function in the Rcmdr package so that it
plots concentration ellipsoids. You'll find the code at
<http://finzi.psych.upenn.edu/R/Rhelp02a/archive/61156.html>.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Michael
> Sent: Thursday, February 02, 2006 3:39 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] is there a way to visualize 3D normal distributions?
> 
> Hi all,
> 
> How do I visualize a contour of a tri-variate normal distribution?
> 
> I just like to see the ellipsoid very much. I hope there is a 
> easy way or existing method in R.
> 
> Thank you a lot!
> 
> Michael.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From br44114 at gmail.com  Thu Feb  2 16:47:16 2006
From: br44114 at gmail.com (bogdan romocea)
Date: Thu, 2 Feb 2006 10:47:16 -0500
Subject: [R] 15-min mean values
Message-ID: <8d5a36350602020747g68ddf26bv837cfeb8c73c0571@mail.gmail.com>

Here's another approach which can be easily implemented in SQL.
1. Start with the dates as character vectors,
   dt <- as.character(Sys.time())
2. Extract the minutes and round them to 0,15,30,45:
   minutes <- floor(as.numeric(substr(dt,15,16))/15)*15
   final.mins <- as.character(minutes)
   final.mins[final.mins == "0"] <- "00"
3. Get the dates you need for aggregating:
   final.dt <- paste(substr(dt,1,14),final.mins,":00",sep="")
(If you had wanted to use 10 minutes, it would have been enough to
transform MM:SS to M0:00.)
4. Use aggregate(), SQL GROUP BY etc
5. Finally, convert final.dt from character to datettime.


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Gabor
> Grothendieck
> Sent: Thursday, February 02, 2006 1:44 AM
> To: Augusto.Sanabria at ga.gov.au
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] 15-min mean values
>
> Assume VDATE is a character vector.  If its a
> factor first convert it using
>
> VDATE <- as.character(VDATE)
>
> Lets assume we only need the times portion
> and later we handle the full case which may or
> may be needed.
>
> We create a times object from the times portion of
> vdate and then in the aggregate statement we use
> trunc.times -- note that trunc.times is a recent
> addition to the chron package so make sure you have
> the latest chron and R 2.2.1.    See ?trunc.times
>
> # test data
> library(chron)
> library(zoo)
> VDATE <- c("1998-10-22:02:11", "1998-10-22:02:12",
> "1998-10-22:02:13", "1998-10-22:02:14", "1998-10-22:02:15")
> WS <- c(12.5, 10.1, 11.2, 10.5, 11.5)
>
> # convert VDATES to times class and aggregate
> vtimes <- times(sub(".*:(..:..)", "\\1:00", VDATE))
> aggregate(zoo(WS), trunc(vtimes, "00:15:00"), mean)
>
> If we need the day part too then its only a little
> harder.
>
> Represent VDATE as a chron object, vdate.  We do this
> by extracting out the date and time portions
> and converting each separately.  We use regular
> expressions to do that conversion but show in a
> comment how to do it without regular expressions.
> See R News 4/1 Help Desk for more info on this and
> the table at the end of the article in particular.
>
> # alternative way to convert to vdate would be:
> # vdate <- chron(dates = as.numeric(as.Date(substring(VDATE, 1, 10))),
> #        times = paste(substring(VDATE, 12), 0, sep =":"))
>
>
> vdate <- chron(dates = sub("(....)-(..)-(..).*",
> "\\2/\\3/\\1", VDATE),
> times = sub(".*:(..:..)", "\\1:00", VDATE))
> aggregate(zoo(WS), chron(trunc(times(vdate), "00:15:00")), mean)
>
> On 2/2/06, Augusto.Sanabria at ga.gov.au
> <Augusto.Sanabria at ga.gov.au> wrote:
> >
> > Good day everyone,
> >
> > I want to use zoo(aggregate) to calculate
> > 15-min mean values from a wind dataset which
> > has 1-min values. The data I have looks like this:
> >
> >     vector VDATE           vector WS
> > 1   1998-10-22:02:11          12.5
> > 2   1998-10-22:02:12          10.1
> > 3   1998-10-22:02:13          11.2
> > 4   1998-10-22:02:14          10.5
> > 5   1998-10-22:02:15          11.5
> >      .
> >      .
> >      .
> > n   2005-06-30:23:59           9.1
> >
> >
> > I want to use:
> >
> > aggregate(zoo(WS),'in 15-min intervals',mean)
> >
> > How do you specify 'in 15-min intervals' using
> > vector VDATE? The length of VDATE cannot be
> > changed, otherwise it would be a trivial problem
> > because I can generate a 15-min spaced vector
> > using 'seq'.
> >
> > Am I missing something?
> >
> > Thanks a lot,
> >
> > Augusto
> >
> >
> > --------------------------------------------
> > Augusto Sanabria. MSc, PhD.
> > Mathematical Modeller
> > Risk Research Group
> > Geospatial & Earth Monitoring Division
> > Geoscience Australia (www.ga.gov.au)
> > Cnr. Jerrabomberra Av. & Hindmarsh Dr.
> > Symonston ACT 2609
> > Ph. (02) 6249-9155
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From fsaldan1 at gmail.com  Thu Feb  2 16:56:27 2006
From: fsaldan1 at gmail.com (Fernando Saldanha)
Date: Thu, 2 Feb 2006 10:56:27 -0500
Subject: [R] How to get the namespace of a function?
Message-ID: <10dee4690602020756r199bd4fbh8fd5f688f0ad35ad@mail.gmail.com>

I declared the environment of the function myfun to be NULL as follows:

environment(myfun) <- NULL

Later on I called that myfun and got an error message because the
function index() in the zoo package was called inside myfun and was
not visible:

Error in myfun(args) : couldn't find function "index"

I tried to use zoo::index() instead of index(), but that did not work.
In fact, zoo::index does not work even in the command line:

> z<-ts(1:5)
> z
Time Series:
Start = 1
End = 5
Frequency = 1
[1] 1 2 3 4 5
> index(z)
[1] 1 2 3 4 5
> zoo::index(z)
Error in loadNamespace(name) : package 'zoo' does not have a name space

How can I qualify index() so that it is visible inside the body of myfun?

Thanks for any suggestions,

FS



From ggrothendieck at gmail.com  Thu Feb  2 17:04:21 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 2 Feb 2006 11:04:21 -0500
Subject: [R] How to get the namespace of a function?
In-Reply-To: <10dee4690602020756r199bd4fbh8fd5f688f0ad35ad@mail.gmail.com>
References: <10dee4690602020756r199bd4fbh8fd5f688f0ad35ad@mail.gmail.com>
Message-ID: <971536df0602020804u3ae33709vfd95a1da89bd3783@mail.gmail.com>

Try:

f <- function() get("index", "package:zoo")


On 2/2/06, Fernando Saldanha <fsaldan1 at gmail.com> wrote:
> I declared the environment of the function myfun to be NULL as follows:
>
> environment(myfun) <- NULL
>
> Later on I called that myfun and got an error message because the
> function index() in the zoo package was called inside myfun and was
> not visible:
>
> Error in myfun(args) : couldn't find function "index"
>
> I tried to use zoo::index() instead of index(), but that did not work.
> In fact, zoo::index does not work even in the command line:
>
> > z<-ts(1:5)
> > z
> Time Series:
> Start = 1
> End = 5
> Frequency = 1
> [1] 1 2 3 4 5
> > index(z)
> [1] 1 2 3 4 5
> > zoo::index(z)
> Error in loadNamespace(name) : package 'zoo' does not have a name space
>
> How can I qualify index() so that it is visible inside the body of myfun?
>
> Thanks for any suggestions,
>
> FS
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Rau at demogr.mpg.de  Thu Feb  2 17:12:02 2006
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Thu, 2 Feb 2006 17:12:02 +0100
Subject: [R] sort columns
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E6013DAF33@HERMES.demogr.mpg.de>

Hi,

is this what you were looking for?

> sort(c("v1", "v9090", "v910", "v990", "v908"))
[1] "v1"    "v908"  "v9090" "v910"  "v990" 
> library(gtools)
> mixedsort(c("v1", "v9090", "v910", "v990", "v908"))
[1] "v1"    "v908"  "v910"  "v990"  "v9090"
> 

Best,
Roland



> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ana Quit??rio
> Sent: Wednesday, February 01, 2006 12:56 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] sort columns
> 
> Hi. 
> 
>  
> 
> I have a simple (I think) question
> 
>  
> 
> My dataset have these variables:
> 
>  
> 
> names(data)
> 
>   [1] "v1"   "v2"   "v3"   "v4"   "v5"   "v6"   "v7"   "v8"   
> "v9"   "v10"
> "v11"  "v12"  "v13"  "v14"  "v15"  "v16"  "v17"  "v18"  "v52" 
> 
>  [20] "v53"  "v54"  "v55"  "v56"  "v57"  "v58"  "v59"  "v60"  
> "v61"  "v62"
> "v63"  "v64"  "v65"  "v66"  "v67"  "v68"  "v69"  "v70"  "v71" 
> 
>  [39] "v72"  "v73"  "v74"  "v75"  "v76"  "v77"  "v78"  "v79"  
> "v80"  "v81"
> "v19"  "v20"  "v21"  "v22"  "v23"  "v24"  "v25"  "v26"  "v27" 
> 
>  [58] "v28"  "v29"  "v30"  "v31"  "v32"  "v33"  "v34"  "v35"  
> "v36"  "v37"
> "v38"  "v39"  "v40"  "v41"  "v42"  "v43"  "v44"  "v45"  "v46" 
> 
>  [77] "v47"  "v48"  "v49"  "v50"  "v51"  "v82"  "v83"  "v84"  
> "v85"  "v86"
> "v87"  "v88"  "v89"  "v90"  "v91"  "v92"  "v93"  "v94"  "v95" 
> 
>  [96] "v96"  "v97"  "v98"  "v99"  "v100" "v101" "v102" "v103" 
> "v104" "v105"
> "v106" "v107" "v108" "v109" "v110" "v111" "v112" "v113" "v114"
> 
> (...)
> 
>  [856] "v856" "v857" "v858" "v859" "v860" "v861" "v862" 
> "v863" "v864" "v865"
> "v866" "v867" "v868" "v869" "v870" "v871" "v872" "v873" "v874"
> 
> [875] "v875" "v876" "v877" "v878" "v879" "v880" "v881" "v882" 
> "v883" "v884"
> "v885" "v886" "v887" "v888" "v889" "v890" "v891" "v892" "v893"
> 
> [894] "v894" "v895" "v896" "v897" "v898" "v899" "v900" "v901" 
> "v902" "v903"
> "v904" "v905" "v906" "v907" "v908" "v909" "v910" "v911" "v912"
> 
> [913] "v913" "v914" "v915" "v916" "v917" "v918" "v919" "v920" 
> "v921" "v922"
> "v923" "v924" "v925" "v926" "v927" "v928" "v929" "v930" "v931"
> 
>  
> 
> And I want obtain another dataset with sort columns names, 
> and I do this:
> 
>  
> 
> data1<-data[,sort(colnames(data))]
> 
>  
> 
> names(data1)
> 
>  
> 
> [1] "v1"   "v10"  "v100" "v101" "v102" "v103" "v104" "v105" 
> "v106" "v107"
> "v108" "v109" "v11"  "v110" "v111" "v112" "v113" "v114" "v115"
> 
>  [20] "v116" "v117" "v118" "v119" "v12"  "v120" "v121" "v122" 
> "v123" "v124"
> "v125" "v126" "v127" "v128" "v129" "v13"  "v130" "v131" "v132"
> 
>  [39] "v133" "v134" "v135" "v136" "v137" "v138" "v139" "v14"  
> "v140" "v141"
> "v142" "v143" "v144" "v145" "v146" "v147" "v148" "v149" "v15" 
> 
>  [58] "v150" "v151" "v152" "v153" "v154" "v155" "v156" "v157" 
> "v158" "v159"
> "v16"  "v160" "v161" "v162" "v163" "v164" "v165" "v166" "v167"
> 
>  [77] "v168" "v169" "v17"  "v170" "v171" "v172" "v173" "v174" 
> "v175" "v176"
> "v177" "v178" "v179" "v18"  "v180" "v181" "v182" "v183" "v184"
> 
>  [96] "v185" "v186" "v187" "v188" "v189" "v19"  "v190" "v191" 
> "v192" "v193"
> "v194" "v195" "v196" "v197" "v198" "v199" "v2"   "v20"  "v200"
> 
> [115] "v201" "v202" "v203" "v204" "v205" "v206" "v207" "v208" 
> "v209" "v21"
> "v210" "v211" "v212" "v213" "v214" "v215" "v216" "v217" "v218"
> 
> [134] "v219" "v22"  "v220" "v221" "v222" "v223" "v224" "v225" 
> "v226" "v227"
> "v228" "v229" "v23"  "v230" "v231" "v232" "v233" "v234" "v235"
> 
> (...)
> 
> [856] "v87"  "v870" "v871" "v872" "v873" "v874" "v875" "v876" 
> "v877" "v878"
> "v879" "v88"  "v880" "v881" "v882" "v883" "v884" "v885" "v886"
> 
> [875] "v887" "v888" "v889" "v89"  "v890" "v891" "v892" "v893" 
> "v894" "v895"
> "v896" "v897" "v898" "v899" "v9"   "v90"  "v900" "v901" "v902"
> 
> [894] "v903" "v904" "v905" "v906" "v907" "v908" "v909" "v91"  
> "v910" "v911"
> "v912" "v913" "v914" "v915" "v916" "v917" "v918" "v919" "v92" 
> 
> [913] "v920" "v921" "v922" "v923" "v924" "v925" "v926" "v927" 
> "v928" "v929"
> "v93"  "v930" "v931" "v94"  "v95"  "v96"  "v97"  "v98"  "v99"
> 
>  
> 
>  
> 
> But I would like obtain, something like this: "v1"  "v2"  
> "v3" "v4" "v5"
> "v6"  (...)   "v928"  "v929"  "v930" "v931" 
> 
>  
> 
> It's possible?
> 
>  
> 
> Thanks in advance
> 
>  
> 
> Ana Quiterio
> 
>  
> 
> Ana Quiterio
> 
> INE - DME 
> Servi??o de Metodos Estatisticos 
> Tel: +351 21 842 61 00 (Ext: 3222) 
> E-mail: ana.quiterio at ine.pt <mailto:ana.quiterio at ine.pt> 
> 
> Lisbon/Portugal
> 
>  
> 
>  
> 
>  
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 

+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From bernarduse1 at yahoo.fr  Thu Feb  2 17:12:04 2006
From: bernarduse1 at yahoo.fr (Marc Bernard)
Date: Thu, 2 Feb 2006 17:12:04 +0100 (CET)
Subject: [R] re-coding variables
Message-ID: <20060202161204.70476.qmail@web25804.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060202/0062d713/attachment.pl

From kkiely at insightful.com  Thu Feb  2 17:20:49 2006
From: kkiely at insightful.com (Kathy Kiely)
Date: Thu, 2 Feb 2006 16:20:49 -0000
Subject: [R] Training: Approaches to Statistical Modelling with Dr. Bill
	Venables
Message-ID: <B796B8C05975394DA24E457D1985BDB478BF28@uk2kexch01.insightful.com>

Subject : Training with Dr. Bill Venables
Traditional and Modern Approaches to Statistical Modelling
 
Insightful are pleased to announce Bill Venables is giving three courses in
Europe within the next 6 weeks :
 
Dates and Locations
Feb 20 - 22 :    Basingstoke - UK
Feb 27 - Mar1:   Zurich - Switzerland
Mar 6 - 8 :      Paris - France
 
This is a unique opportunity to extend your knowledge with one of the
foremost lecturers on the subject.  Dr. Bill Venables is a well-known
personality in the S-PLUS/ R communities, not least through the two books he
has written with Professor Brian Ripley, namely Modern Applied Statistics
with S [MASS] and S Programming, both of which have become minor classics and
perhaps the most widely used third party books for the S software system.
 
This three-day course will present classical and modern approaches to
statistical modelling using the facilities provided by S-PLUS and will use
both the standard software and the S programming language to offer strategies
for handling both standard and non-standard statistical modelling problems.
 
For full course details please go to:
 
http://www.insightful.com/uk/services/venables_UK.asp  
 
 
To register for UK course:
http://www.insightful.com/uk/services/register_uk.asp  
To register for Zurich course:
http://www.insightful.com/switzerland/us/services/venables_CH.asp: 
To register for Paris course:
http://www.insightful.com/france/services/venables_FR.asp
 
Please do not hesitate to contact me if you require any further information.
 
Regards,
 
 
Kathy Kiely
Sales & Marketing Administrator
Insightful Limited
Network House, Basing View Basingstoke, Hampshire, RG21 4HG
Tel : 01256 339822
Fax : 01256 339839
e mail : kkiely at insightful.com



From christos at nuverabio.com  Thu Feb  2 17:29:29 2006
From: christos at nuverabio.com (Christos Hatzis)
Date: Thu, 2 Feb 2006 11:29:29 -0500
Subject: [R] re-coding variables
In-Reply-To: <20060202161204.70476.qmail@web25804.mail.ukl.yahoo.com>
Message-ID: <000d01c62815$dadae280$0e010a0a@headquarters>

Look at function recode() in library("car").

-Christos 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marc Bernard
Sent: Thursday, February 02, 2006 11:12 AM
To: r-help at stat.math.ethz.ch
Subject: [R] re-coding variables

Dear All,
   
  I wonder how to re-code  a categorical variable without using the ifelse
loops. For example:
  Let X be a categorical variable with 6 levels, levels(X) = c(1,2,3,4,5,6)
   
  How to create a new categorical variable Y with levels, 10,11,12, say ,
such that:
  Y = 10 if X =1 or X=2
  Y = 11 if X =3 or 4
  Y =11 if X = 5 or 6
   
  many thanks,
   
  Bernard
   

		
---------------------------------

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From madhurima_b at persistent.co.in  Thu Feb  2 17:33:50 2006
From: madhurima_b at persistent.co.in (madhurima bhattacharjee)
Date: Thu, 02 Feb 2006 22:03:50 +0530
Subject: [R] problem with nnet
Message-ID: <43E2346E.1000205@persistent.co.in>

Hello All,

I am working with samr and nnet packages.
I am following the steps given below:
1> I take a  input file with signal values for 9506 genes and 36  chips 
, belonging to two classes.
2> I perform samr analysis on 80% of chip data from both the 
classes.(selected by random sampling)
3> I then use the data of only the significant genes from this samr 
analysis to train nnet.
4> The parameters I am currently using for nnet are:
result <- nnet(traindata[sortsamp,], targets[sortsamp,], size = nnetsize 
, rang =0.00000003 ,decay = 0.00009, maxit = 100, MaxNWts =100000)
           traindata is the significant gene's data, sortsamp is the 
randomly sampled number out of those genes and targets is the class 
indicator of the significant genes.
5>  Then I am using the data from the chips left out from samr(20% chip 
data) to test the nnet.
      I use the following command for this:
      pred <-predict(result, testdata) #result is the nnet output(given 
above) and testdata is the chipdata of remainder chips.
6>I run the nnet part for 100 runs using the same significant genes in 
all runs.

The problem is that the pred  in each run gives same values for both the 
classes.
Example:
[1] "pred----->"
           cer    noncer
[1,] 0.4990032 0.5009930
[2,] 0.4990032 0.5009930
[3,] 0.4990030 0.5009933
[4,] 0.4989994 0.5009968
[5,] 0.4990030 0.5009932
[6,] 0.4990032 0.5009930
[7,] 0.4990032 0.5009930

This is really weird result.

I have checked the data and code several times but couldn't figure out 
the problem.
I am really stuck in this.
Can anyone help me as soon as possible?

Thanks in advance,
Madhurima.



From p.dalgaard at biostat.ku.dk  Thu Feb  2 17:32:54 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Feb 2006 17:32:54 +0100
Subject: [R] re-coding variables
In-Reply-To: <20060202161204.70476.qmail@web25804.mail.ukl.yahoo.com>
References: <20060202161204.70476.qmail@web25804.mail.ukl.yahoo.com>
Message-ID: <x2k6cdpvpl.fsf@viggo.kubism.ku.dk>

Marc Bernard <bernarduse1 at yahoo.fr> writes:

> Dear All,
>    
>   I wonder how to re-code  a categorical variable without using the ifelse loops. For example:

(What's an "ifelse loop"???)

>   Let X be a categorical variable with 6 levels, levels(X) = c(1,2,3,4,5,6)
>    
>   How to create a new categorical variable Y with levels, 10,11,12, say , such that:
>   Y = 10 if X =1 or X=2
>   Y = 11 if X =3 or 4
>   Y =11 if X = 5 or 6

One way is the recode() function in the car package. Another is 

Y <- X
levels(Y) <- c(10,10,11,11,12,12)

or 

levels(Y) <- list("10"=c(1,2),"11"=c(3,4),"12"=c(5,6))

and a 4th one could be

Y <- factor(c(10,10,11,11,12,12)[X])

(which may need a safeguarding "levels=c(10,11,12)" in case not all
levels are present).
-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From liufang at uchicago.edu  Thu Feb  2 17:47:32 2006
From: liufang at uchicago.edu (liufang@uchicago.edu)
Date: Thu, 2 Feb 2006 05:47:32 -1100
Subject: [R] the meaning of the B-spline coefficients
Message-ID: <81c326b7.845d6f15.823ed00@m4500-02.uchicago.edu>

Dear all,

I'm trying to figure out the exact meaning of the B-spline
coefficients generated by the R command bs(). After reading a
lot of things, I still have no clue...

Here's my data.

> test
    time        f0
1      1  94.76328
2      2 102.47954
3      3 105.01234
4      4 107.21387
5      5 108.63279
6      6 109.54507
7      7 113.87931
8      8 118.21356
9      9 121.08652
10    10 121.78338
11    11 118.84742
12    12 112.15230
13    13  99.64756
14    14  85.87430
15    15  80.15959
16    16  78.16951
17    17  76.85120
18    18  76.64255
19    19  75.23007
20    20  74.18679
21    21  97.82914
22    22  97.99156
23    23  98.24108
24    24  99.96225
25    25 100.91948
26    26 101.75905
27    27 114.88339
28    28 125.78792
29    29 130.62168
30    30 132.42147
31    31 120.75498
32    32 116.46438
33    33  95.83809
34    34  83.55815
35    35  83.49363
36    36  83.42912
37    37  83.43273
38    38  83.49382
39    39  83.55078
40    40  83.55078
41    41  89.22781
42    42  93.01460
43    43  94.13982
44    44  95.12909
45    45  97.24925
46    46 100.00507
47    47 108.08150
48    48 115.54357
49    49 126.74814
50    50 127.63650
51    51 123.09723
52    52 115.97800
53    53 107.58863
54    54  99.78626
55    55  90.47310
56    56  81.92469
57    57  79.50943
58    58  75.78710
59    59  73.05736
60    60  72.26699
61    61  93.12932
62    62  91.30452
63    63  91.02817
64    64  91.16687
65    65  93.74704
66    66  96.39891
67    67  99.64934
68    68 104.37769
69    69 110.45508
70    70 111.70428
71    71  93.69037
72    72  85.67118
73    73  85.06033
74    74  84.44947
75    75  83.83862
76    76  82.93448
77    77  80.80928
78    78  78.70249
79    79  78.70249
80    80  78.70249
81    81 140.00112
82    82 139.98659
83    83 142.49656
84    84 145.00654
85    85 147.25728
86    86 149.06518
87    87 151.23441
88    88 156.06892
89    89 160.21311
90    90 162.04904
91    91 124.28610
92    92  86.27715
93    93  69.96150
94    94  70.23389
95    95  74.23542
96    96  78.23695
97    97  82.23848
98    98  86.24001
99    99  92.06214
100  100 114.89530

Here's my R output.
> bsp = lm(f0~bs(time,df=13),data=test)
> summary(bsp)

Call:
lm(formula = f0 ~ bs(time, df = 13), data = test)

Residuals:
     Min       1Q   Median       3Q      Max 
-31.6519  -7.1230   0.1433   6.1755  25.2094 

Coefficients:
                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)           97.307     10.343   9.408 7.26e-15 ***
bs(time, df = 13)1     5.029     20.150   0.250 0.803490    
bs(time, df = 13)2    50.806     14.396   3.529 0.000672 ***
bs(time, df = 13)3   -66.700     15.579  -4.281 4.81e-05 ***
bs(time, df = 13)4    73.981     13.516   5.474 4.29e-07 ***
bs(time, df = 13)5   -59.803     14.225  -4.204 6.40e-05 ***
bs(time, df = 13)6    46.817     13.740   3.407 0.001000 ***
bs(time, df = 13)7   -23.807     13.982  -1.703 0.092235 .  
bs(time, df = 13)8     8.090     13.889   0.582 0.561776    
bs(time, df = 13)9   -22.132     14.100  -1.570 0.120170    
bs(time, df = 13)10   16.759     14.566   1.151 0.253083    
bs(time, df = 13)11   98.630     16.566   5.954 5.55e-08 ***
bs(time, df = 13)12 -102.236     16.784  -6.091 3.06e-08 ***
bs(time, df = 13)13   31.919     14.629   2.182 0.031839 *  
---
Signif. codes:  0 *** 0.001 ** 0.01 * 0.05 . 0.1   1 

Residual standard error: 12.46 on 86 degrees of freedom
Multiple R-Squared: 0.7316,	Adjusted R-squared: 0.691 
F-statistic: 18.03 on 13 and 86 DF,  p-value: < 2.2e-16 
 

Do the above coefficients imply the feature of the independent
variable "f0"? For example, does "intercept" approximate the
initial value of "f0" at "time" 1? I specified df=13, so there
are 10 knots in this case. Do bs(time, df = 13)4 through
bs(time, df = 13)13 indicate the slope or intercept of the
original curve (of "f0") within the 10 knot spans? What's the
meaning of bs(time, df = 13)1 - 3 then?

I'm reading "B(asic)-Spline Basics" by Carl de Boor, but
really don't understand those formula of splines. I'd really
appreciate it if someone could help me with this.

Many thanks!

Fang Liu
liufang at uchicago.edu
Ph.D. student
Department of linguistics
University of Chicago



From depire at inrets.fr  Thu Feb  2 18:27:47 2006
From: depire at inrets.fr (depire@inrets.fr)
Date: Thu, 02 Feb 2006 18:27:47 +0100
Subject: [R] Matrix variable in C code
In-Reply-To: <20060202143246.GD24989@rmki.kfki.hu>
References: <1138889502.43e2131e68fe9@webmail.inrets.fr>
	<20060202143246.GD24989@rmki.kfki.hu>
Message-ID: <1138901267.43e24113d6de1@webmail.inrets.fr>

Selon Gabor Csardi <csardi at rmki.kfki.hu>:

> On Thu, Feb 02, 2006 at 03:11:42PM +0100, depire at inrets.fr wrote:
> [...]
> > 
> > and my test code in C is:
> > ================================================
> > SEXP VPCEfron(SEXP f, SEXP SR, SEXP ZR, SEXP DIR, SEXP nsR, SEXP rho)
> > {
> > 	int taille=INTEGER(nsR)[0];
> [...]
> > 
> > All works, except ZS, the variable ZS is a matrix in R, and when i try to
> give
> > to C code, with ZR, ZR is only a vector.
> > 
> > How to obtain a matrix variable in C ?
> 
> A matrix is the same as a vector (stored columnwise), except that is has a 
> dim attribute. Use can use SET_DIM to set the dim attribute, and GET_dim to
> query it. Eg:
> 
> int nrow=INTEGER(GET_DIM(ZR))[0];
> int ncol=INTEGER(GET_DIM(ZR))[1];
> 
> To access the values in the matrix you might use something like:
> 
> #define RMATRIX(m,i,j) (REAL(m)[ INTEGER(GET_DIM(m))[0]*(j)+(i) ])
> 
> and then 
> 
> RMATRIX(ZR, 0, 1), etc. works. Note that according to this #define the
> matrix
> is indexed from zero.
> 
> Gabor
> 
> 
> -- 
> Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 

I try but i think that i make some mistake because i obtain segment fault.
To be sure, i reduce the code to permit to test it, the goal is just to print
the variable, i try with vector variables (real X and integer dX in the
following), it works; but with matrix it doesn't work.

The code of the R program - Test.R
=====================================
X<-c(4,2,3,2)
Z<-c(40,21,30,20)
dX<-c(2,1,1)

dyn.load("test.so")

Phi<-function(z,a,b)
{
	Phi<-z
}

VPEfron<-function(XType,ZType,dXType,G,c0,c1)
{
	# A OPTIMISER
      VPCEfron<-function(f,XT,ZT,dXT,tailleS=length(XT))
      {
		f.check<-function(x) {
            x<-f(x)
            }
     
.Call("VPCEfron",body(f.check),as.double(XT),as.double(ZT),as.integer(dXT),as.integer(tailleS),new.env())
	}
GG<-function(z) G(z,c0,c1)

Vraisemblancepartielle<-VPCEfron(GG,XType,ZType,dXType)
}

resultat<-VPEfron(X,Z,dX,Phi,0,0)
==============================

The code of C code - test.c and test.so is obtained by "R CMD SHLIB test.c"
================================
#include <R.h>
#include <Rdefines.h>

#define RMATRIX(m,i,j) (REAL(m)[ INTEGER(GET_DIM(m))[0]*(j)+(i) ])

SEXP mkans(double x)
{
	SEXP ans;
	PROTECT(ans = allocVector(REALSXP,1));
	REAL(ans)[0]=x;
	UNPROTECT(1);
	return ans;
}

SEXP VPCEfron(SEXP f, SEXP XR, SEXP ZR, SEXP DIR, SEXP rho)
{
	double* X=REAL(XR);
	int* DI=INTEGER(DIR);
	int nligne=INTEGER(GET_DIM(ZR))[0];
	int ncol=INTEGER(GET_DIM(ZR))[1];

	printf("verifie de X: %f - %f - %f - %f\n",X[0],X[1],X[2],X[3]);
	printf("verifie dX: %d %d %d\n",DI[0],DI[1],DI[2]);
	printf("verifie de Z\n");
	printf("%d %d\n",nligne,ncol);
	printf("%f %f\n",RMATRIX(ZR,0,0));
	printf("%f %f\n",RMATRIX(ZR,0,1));
	printf("%f %f\n",RMATRIX(ZR,1,0));
	printf("%f %f\n",RMATRIX(ZR,2,0));

	return mkans(0.0);
}
=====================================

You can save these two simple programs in order to test my code.

Thanks.



From spencer.graves at pdf.com  Thu Feb  2 18:40:29 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 02 Feb 2006 09:40:29 -0800
Subject: [R] non linear 3SLS with constraints
In-Reply-To: <28F23EB76AB6184983FDF87CEC412EB410B8F9@xmail02.ad.ua.ac.be>
References: <28F23EB76AB6184983FDF87CEC412EB410B8F9@xmail02.ad.ua.ac.be>
Message-ID: <43E2440D.9000607@pdf.com>

	  RSiteSearch("3SLS") produced 27 hits for me just now.  This 
identified several functions in contributed packages that offer 3SLS.  I 
didn't look at all of them, but I didn't see any mention of constraints 
in the ones I skimmed.  RSiteSearch("nonlinear least squares with 
constraints") returned 13, including 
"http://finzi.psych.upenn.edu/R/Rhelp02a/archive/13304.html".  This is a 
comment from Doug Bates, who is one of the world's leading experts on 
nonlinear regression.  He suggests eliminating the constraints by 
transformation, and provides a reference to his book on the subject 
(which I highly recommend, if you are not already familiar with it).

	  I can't think of any sensible technique related to statistical 
computing that can NOT be done in R.  Moreover, the more obscure or 
nonstandard the technique, the more likely it will be more easily done 
in R than anything else.  For me, R is the premier platform for new 
statistical algorithm development.  Much of what is available in other 
packages is already available in R or in a contributed package.

	  Without this listserve, R has a pretty steep learning curve. 
However, that difficulty is substantially reduced by the ready 
availability of an international network of people who contribute their 
time to helping others via this listserve.  Some questions are answered 
in minutes.  A few never receive an answer.  Questions that don't get 
answered often seem to require specialized knowledge that relatively few 
people have.  For example, I don't know what percentage of those who 
follow this listserve know '3SLS', but I'd guess it might be rather low. 
  If you are persistent, recasting a question in alternative, more 
generic terms, or decribing briefly why you want to do something (not 
just asking about a specific technique you've heard about), you will get 
an answer.  (I believe the posting guide, 
"www.R-project.org/posting-guide.html", is also quite helpful.)

	  In particular, if you think you need 3SLS rather than some more 
general nonlinear least squares or maximum likelihood, or if you don't 
think transformations are appropriate, please submit another question to 
this listserve explaining as clearly and succinctly as you can why you 
think so.

	  hope this helps.
	  spencer graves

Van Campenhout Bjorn wrote:

> hi,
> 
> i am new here and wanted to know, before i start learning yet another statistical package:
> 
> I want to estimate a system of equations that is 
on linear in the parameters, using 3SLS.  However,
i will probably have to constrain some of the parameters
to be between, say, zero and one.  Is this possible with
R, and better, is this easy?  If so, since i am an absolute
beginner, any pointers where to start would be greatly appreciated.
> 
> Bjorn
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From gunter.berton at gene.com  Thu Feb  2 18:43:53 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 2 Feb 2006 09:43:53 -0800
Subject: [R] the meaning of the B-spline coefficients
In-Reply-To: <81c326b7.845d6f15.823ed00@m4500-02.uchicago.edu>
Message-ID: <200602021743.k12HhrAH003964@hertz.gene.com>

Check out:

**The Elements of Statistical Learning ** by Hastie, Tibshirani, and
Friedman.

-- Bert Gunter
 Genentech

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of liufang at uchicago.edu
Sent: Thursday, February 02, 2006 8:48 AM
To: r-help at stat.math.ethz.ch
Subject: [R] the meaning of the B-spline coefficients

Dear all,

I'm trying to figure out the exact meaning of the B-spline
coefficients generated by the R command bs(). After reading a
lot of things, I still have no clue...

Here's my data.

> test
    time        f0
1      1  94.76328
2      2 102.47954
3      3 105.01234
4      4 107.21387
5      5 108.63279
6      6 109.54507
7      7 113.87931
8      8 118.21356
9      9 121.08652
10    10 121.78338
11    11 118.84742
12    12 112.15230
13    13  99.64756
14    14  85.87430
15    15  80.15959
16    16  78.16951
17    17  76.85120
18    18  76.64255
19    19  75.23007
20    20  74.18679
21    21  97.82914
22    22  97.99156
23    23  98.24108
24    24  99.96225
25    25 100.91948
26    26 101.75905
27    27 114.88339
28    28 125.78792
29    29 130.62168
30    30 132.42147
31    31 120.75498
32    32 116.46438
33    33  95.83809
34    34  83.55815
35    35  83.49363
36    36  83.42912
37    37  83.43273
38    38  83.49382
39    39  83.55078
40    40  83.55078
41    41  89.22781
42    42  93.01460
43    43  94.13982
44    44  95.12909
45    45  97.24925
46    46 100.00507
47    47 108.08150
48    48 115.54357
49    49 126.74814
50    50 127.63650
51    51 123.09723
52    52 115.97800
53    53 107.58863
54    54  99.78626
55    55  90.47310
56    56  81.92469
57    57  79.50943
58    58  75.78710
59    59  73.05736
60    60  72.26699
61    61  93.12932
62    62  91.30452
63    63  91.02817
64    64  91.16687
65    65  93.74704
66    66  96.39891
67    67  99.64934
68    68 104.37769
69    69 110.45508
70    70 111.70428
71    71  93.69037
72    72  85.67118
73    73  85.06033
74    74  84.44947
75    75  83.83862
76    76  82.93448
77    77  80.80928
78    78  78.70249
79    79  78.70249
80    80  78.70249
81    81 140.00112
82    82 139.98659
83    83 142.49656
84    84 145.00654
85    85 147.25728
86    86 149.06518
87    87 151.23441
88    88 156.06892
89    89 160.21311
90    90 162.04904
91    91 124.28610
92    92  86.27715
93    93  69.96150
94    94  70.23389
95    95  74.23542
96    96  78.23695
97    97  82.23848
98    98  86.24001
99    99  92.06214
100  100 114.89530

Here's my R output.
> bsp = lm(f0~bs(time,df=13),data=test)
> summary(bsp)

Call:
lm(formula = f0 ~ bs(time, df = 13), data = test)

Residuals:
     Min       1Q   Median       3Q      Max 
-31.6519  -7.1230   0.1433   6.1755  25.2094 

Coefficients:
                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)           97.307     10.343   9.408 7.26e-15 ***
bs(time, df = 13)1     5.029     20.150   0.250 0.803490    
bs(time, df = 13)2    50.806     14.396   3.529 0.000672 ***
bs(time, df = 13)3   -66.700     15.579  -4.281 4.81e-05 ***
bs(time, df = 13)4    73.981     13.516   5.474 4.29e-07 ***
bs(time, df = 13)5   -59.803     14.225  -4.204 6.40e-05 ***
bs(time, df = 13)6    46.817     13.740   3.407 0.001000 ***
bs(time, df = 13)7   -23.807     13.982  -1.703 0.092235 .  
bs(time, df = 13)8     8.090     13.889   0.582 0.561776    
bs(time, df = 13)9   -22.132     14.100  -1.570 0.120170    
bs(time, df = 13)10   16.759     14.566   1.151 0.253083    
bs(time, df = 13)11   98.630     16.566   5.954 5.55e-08 ***
bs(time, df = 13)12 -102.236     16.784  -6.091 3.06e-08 ***
bs(time, df = 13)13   31.919     14.629   2.182 0.031839 *  
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Residual standard error: 12.46 on 86 degrees of freedom
Multiple R-Squared: 0.7316,	Adjusted R-squared: 0.691 
F-statistic: 18.03 on 13 and 86 DF,  p-value: < 2.2e-16 
 

Do the above coefficients imply the feature of the independent
variable "f0"? For example, does "intercept" approximate the
initial value of "f0" at "time" 1? I specified df=13, so there
are 10 knots in this case. Do bs(time, df = 13)4 through
bs(time, df = 13)13 indicate the slope or intercept of the
original curve (of "f0") within the 10 knot spans? What's the
meaning of bs(time, df = 13)1 - 3 then?

I'm reading "B(asic)-Spline Basics" by Carl de Boor, but
really don't understand those formula of splines. I'd really
appreciate it if someone could help me with this.

Many thanks!

Fang Liu
liufang at uchicago.edu
Ph.D. student
Department of linguistics
University of Chicago



From csardi at rmki.kfki.hu  Thu Feb  2 18:47:06 2006
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Thu, 2 Feb 2006 18:47:06 +0100
Subject: [R] Matrix variable in C code
In-Reply-To: <1138901267.43e24113d6de1@webmail.inrets.fr>
References: <1138889502.43e2131e68fe9@webmail.inrets.fr>
	<20060202143246.GD24989@rmki.kfki.hu>
	<1138901267.43e24113d6de1@webmail.inrets.fr>
Message-ID: <20060202174706.GI26788@rmki.kfki.hu>

On Thu, Feb 02, 2006 at 06:27:47PM +0100, depire at inrets.fr wrote:
[...]

The problem is that as.double drops the dim attribute:
> b <- matrix( 1:4, 2, 2)
> b
     [,1] [,2]
[1,]    1    3
[2,]    2    4
> as.double(b)
[1] 1 2 3 4
> 

You can try: 

> b <- matrix( 1:4, 2, 2)
> d <- dim(b)
> b <- as.double(b)
> b
[1] 1 2 3 4
> dim(b) <- d
> b
     [,1] [,2]
[1,]    1    3
[2,]    2    4

Another thing is that i cannot really see why the ZT parameter of the .Call
should be a matrix anyway. It's just the vector (40 21 30 20). Or am i
missing something?

Also, this is an unrelated issue but your VPCEfron C function takes five
parameters and the R code provides six....

Gabor

> =====================================
> 
> You can save these two simple programs in order to test my code.
> 
> Thanks.
> 
[...]

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK



From ronggui.huang at gmail.com  Thu Feb  2 19:04:35 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Fri, 3 Feb 2006 02:04:35 +0800
Subject: [R] how to use mle?
Message-ID: <38b9f0350602021004r35bf0b44q@mail.gmail.com>

>Y
      [,1] [,2] [,3]
 [1,]    0    1    0
 [2,]    0    1    0
 [3,]    0    0    1
 [4,]    1    0    0
 [5,]    0    0    1
 [6,]    0    0    1
 [7,]    1    0    0
 [8,]    1    0    0
 [9,]    0    0    1
[10,]    1    0    0

>X
   pri82 pan82
1      0     0
2      0     0
3      1     0
4      1     0
5      0     1
6      0     0
7      1     0
8      1     0
9      0     0
10     0     0

>K=2
>J=3


LL <- function(b=rep(0,(J-1)*K)){
B=matrix(c(b,rep(0,K)),ncol=J,nrow=K)
fit <- X%*%B
p<-exp(fit)/rowSums(exp(fit))
sum(Y*log(p))
}

grad<- function(b=rep(0,(J-1)*K)){
B=matrix(c(b,rep(0,K)),ncol=J,nrow=K)
fit <- X%*%B
p<-exp(fit)/rowSums(exp(fit))
Yp <- Y-p
Yp<-matrix(rep(t(Yp),each=K),ncol=K*J,by=T)
X <- matrix(rep(X,J) ,ncol=K*J)
apply(Yp*X,2,sum)
}

library(stats4)
mle(LL)
Error in validObject(.Object) : invalid class "mle" object: invalid
object for slot "fullcoef" in class "mle": got class "list", should be
or extend class "numeric"

mle(LL,gr=grad)
Error in optim(start, f, method = method, hessian = TRUE, ...) :
        gradient in optim evaluated to length 6 not 0

what is wrong with my code?I try to fix it myself but fails,anyone
helps me ?Thank you!

--
Deparment of Sociology
Fudan University



From russell.walker at capitalone.com  Thu Feb  2 19:05:51 2006
From: russell.walker at capitalone.com (Walker, Russell)
Date: Thu, 2 Feb 2006 13:05:51 -0500
Subject: [R] R training courses
Message-ID: <EF691D4805C12C4294D2A8515372EAF30448E842@kdcp4pmbx05.cof.ds.capitalone.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060202/2a4ebf68/attachment.pl

From wqiu at nmr.mgh.harvard.edu  Thu Feb  2 19:12:14 2006
From: wqiu at nmr.mgh.harvard.edu (Wei Qiu)
Date: Thu, 2 Feb 2006 13:12:14 -0500 (EST)
Subject: [R] R training courses
In-Reply-To: <EF691D4805C12C4294D2A8515372EAF30448E842@kdcp4pmbx05.cof.ds.capitalone.com>
References: <EF691D4805C12C4294D2A8515372EAF30448E842@kdcp4pmbx05.cof.ds.capitalone.com>
Message-ID: <Pine.LNX.4.62.0602021311260.28543@gate.nmr.mgh.harvard.edu>

I am also looking for this kind of courses. Any suggestion will be greatly 
appreciated. Lucy

On Thu, 2 Feb 2006, Walker, Russell wrote:

> Hi All,
>
>
>
> I am interested in learning about people's experience with R training or
> courses. What worked, what didn't? What do you recommend?
>
>
>
> Also, if there any groups or individuals that have and can offer R
> training courses, please contact me directly. I would like to learn
> about your services.
>
>
>
> Thanks for your input and help. Please feel free to contact me directly.
>
>
>
>
>
> Russ
>
>
>
>
>
> Russell Walker, Ph.D.
>
>
>
> Senior Strategist
>
>
>
> CapitalOne Financial, Inc.
>
>
>
> 1500 Capital One Drive
>
>
>
> Richmond, VA 23238 USA
>
>
>
> Internal Zip 12074-0340
>
>
>
> External +1 804 855-3512
>
>
>
> russell.walker at capitalone.com
>
>
>
>
>
>
>
>
>
>
>
>
> The information contained in this e-mail is confidential and...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>



From jjrr at wi.rr.com  Thu Feb  2 19:23:31 2006
From: jjrr at wi.rr.com (Joseph Retzer)
Date: Thu, 2 Feb 2006 12:23:31 -0600
Subject: [R] Heatmap.2 axes question
Message-ID: <001201c62825$c5f9eef0$6401a8c0@Cerberus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060202/430f0196/attachment.pl

From roger.bos at gmail.com  Thu Feb  2 19:24:35 2006
From: roger.bos at gmail.com (roger bos)
Date: Thu, 2 Feb 2006 13:24:35 -0500
Subject: [R] R training courses
In-Reply-To: <Pine.LNX.4.62.0602021311260.28543@gate.nmr.mgh.harvard.edu>
References: <EF691D4805C12C4294D2A8515372EAF30448E842@kdcp4pmbx05.cof.ds.capitalone.com>
	<Pine.LNX.4.62.0602021311260.28543@gate.nmr.mgh.harvard.edu>
Message-ID: <1db726800602021024q4a49fedbye9ac91e27c6f4b67@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060202/7d543644/attachment.pl

From sell_mirage_ne at hotmail.com  Thu Feb  2 19:40:25 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Thu, 02 Feb 2006 12:40:25 -0600
Subject: [R] table() command
Message-ID: <BAY110-F8A7BCCADD92B1FA363EF6C70A0@phx.gbl>

Hi R users

I am trying to get cross-tabulation tables using tables.

All variables used are binary ones (0 and 1).

Each time I constructed cross-tabluation table using a different variable 
pair (e.g., variable 1 and variable 2, variable 1 and variable 3 etc)

In doing so, I ran into some problems

    i.V2
i.V1  1
   0 17
   1 33

For variable 2 (i.V2) there was no one belonging to ZERO category but I like 
to have a cross tabulation table looking like this

       i.V2
i.V1  0   1
   0   0  17
   1   0  33

Is there any other functoin I can use instead of using table() or is there 
any options I can add to table() ?

Any help or advice would be appreciated

Thanks

TM

_________________________________________________________________
Dont just search. Find. Check out the new MSN Search!



From ggrothendieck at gmail.com  Thu Feb  2 19:55:12 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 2 Feb 2006 13:55:12 -0500
Subject: [R] table() command
In-Reply-To: <BAY110-F8A7BCCADD92B1FA363EF6C70A0@phx.gbl>
References: <BAY110-F8A7BCCADD92B1FA363EF6C70A0@phx.gbl>
Message-ID: <971536df0602021055g6c935483tff4996731774cbc1@mail.gmail.com>

Create factors from your variables that include the missing levels.
e.g.

x <- factor(c(1,1,1))
x0 <- factor(c(1,1,1), levels = 0:1)
y <- factor(c(0,1,0))
table(x,y) # no zero for x
table(x0,y) # zero for x


On 2/2/06, Taka Matzmoto <sell_mirage_ne at hotmail.com> wrote:
> Hi R users
>
> I am trying to get cross-tabulation tables using tables.
>
> All variables used are binary ones (0 and 1).
>
> Each time I constructed cross-tabluation table using a different variable
> pair (e.g., variable 1 and variable 2, variable 1 and variable 3 etc)
>
> In doing so, I ran into some problems
>
>    i.V2
> i.V1  1
>   0 17
>   1 33
>
> For variable 2 (i.V2) there was no one belonging to ZERO category but I like
> to have a cross tabulation table looking like this
>
>       i.V2
> i.V1  0   1
>   0   0  17
>   1   0  33
>
> Is there any other functoin I can use instead of using table() or is there
> any options I can add to table() ?
>
> Any help or advice would be appreciated
>
> Thanks
>
> TM
>
> _________________________________________________________________
> Don't just search. Find. Check out the new MSN Search!
>
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From p.dalgaard at biostat.ku.dk  Thu Feb  2 19:55:43 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Feb 2006 19:55:43 +0100
Subject: [R] how to use mle?
In-Reply-To: <38b9f0350602021004r35bf0b44q@mail.gmail.com>
References: <38b9f0350602021004r35bf0b44q@mail.gmail.com>
Message-ID: <x2oe1ptwsw.fsf@turmalin.kubism.ku.dk>

ronggui <ronggui.huang at gmail.com> writes:

> >Y
>       [,1] [,2] [,3]
>  [1,]    0    1    0
>  [2,]    0    1    0
>  [3,]    0    0    1
>  [4,]    1    0    0
>  [5,]    0    0    1
>  [6,]    0    0    1
>  [7,]    1    0    0
>  [8,]    1    0    0
>  [9,]    0    0    1
> [10,]    1    0    0
> 
> >X
>    pri82 pan82
> 1      0     0
> 2      0     0
> 3      1     0
> 4      1     0
> 5      0     1
> 6      0     0
> 7      1     0
> 8      1     0
> 9      0     0
> 10     0     0
> 
> >K=2
> >J=3
> 
> 
> LL <- function(b=rep(0,(J-1)*K)){
> B=matrix(c(b,rep(0,K)),ncol=J,nrow=K)
> fit <- X%*%B
> p<-exp(fit)/rowSums(exp(fit))
> sum(Y*log(p))
> }
> 
> grad<- function(b=rep(0,(J-1)*K)){
> B=matrix(c(b,rep(0,K)),ncol=J,nrow=K)
> fit <- X%*%B
> p<-exp(fit)/rowSums(exp(fit))
> Yp <- Y-p
> Yp<-matrix(rep(t(Yp),each=K),ncol=K*J,by=T)
> X <- matrix(rep(X,J) ,ncol=K*J)
> apply(Yp*X,2,sum)
> }
> 
> library(stats4)
> mle(LL)
> Error in validObject(.Object) : invalid class "mle" object: invalid
> object for slot "fullcoef" in class "mle": got class "list", should be
> or extend class "numeric"

It is a bit strange that it gets dicovered so late (when the mle
object is printed), but the issue is that the negative log likelihood
has to be a function of a number of *scalar* parameters.

Vector parameters are not allowed (yet? this is not the
first case where people have expected or desired that they were
allowed).

 
> mle(LL,gr=grad)
> Error in optim(start, f, method = method, hessian = TRUE, ...) :
>         gradient in optim evaluated to length 6 not 0
> 
> what is wrong with my code?I try to fix it myself but fails,anyone
> helps me ?Thank you!
> 
> --
> Deparment of Sociology
> Fudan University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ltorgo at liacc.up.pt  Thu Feb  2 20:02:39 2006
From: ltorgo at liacc.up.pt (=?iso-8859-1?q?Lu=EDs_Torgo?=)
Date: Thu, 2 Feb 2006 19:02:39 +0000
Subject: [R] R training courses
In-Reply-To: <EF691D4805C12C4294D2A8515372EAF30448E842@kdcp4pmbx05.cof.ds.capitalone.com>
References: <EF691D4805C12C4294D2A8515372EAF30448E842@kdcp4pmbx05.cof.ds.capitalone.com>
Message-ID: <200602021902.39954.ltorgo@liacc.up.pt>

On Thursday 02 February 2006 18:05, Walker, Russell wrote:
> I am interested in learning about people's experience with R training or
> courses. What worked, what didn't? What do you recommend?
In the last few years I have been doing several short (around 10 hours) 
courses on Data Mining using R. I've prepared them around the same ideas that 
guide the unfinished book I'm writing on the same topic 
(http://www.liacc.up.pt/~ltorgo/DataMiningWithR/) , that is learning by case 
studies. I think that for a tool like R, with a learning curve that people 
tend to think as kind of steep, and for short courses, the hands on approach 
is a good means to motivate students. This obviously requires properly 
equipped classrooms but that is not difficult to get nowadays, particularly 
when using free software as R. The feedback I got from these courses was 
quite good and several students came back to me later on with further 
questions which is a good indication that they continued their involvement 
with R. 

These courses were usually organized by proving short, non-demanding 
introductions to the key concepts, and then followed by longer hands on 
sessions where students try by themselves with real case studies. Because of 
this I tend to prefer a short number of students (15-25) to increase the 
interaction during the hands on parts. Still, I gave this course at last year 
ACAI summer school (http://www.ktschool.org/) and eventhough there where 
about 50 students the course was successful.

Regarding topics I tend to start by simple case studies where I can illustrate 
basic concepts of data analysis using R together with the language itself, 
and then select larger cases studies depending on the interests of the 
audience.

Luis 

-- 
Luis Torgo
    FEP/LIACC, University of Porto   Phone : (+351) 22 339 20 93
    Machine Learning Group           Fax   : (+351) 22 339 20 99
    R. de Ceuta, 118, 6o             email : ltorgo at liacc.up.pt
    4050-190 PORTO - PORTUGAL        WWW   : http://www.liacc.up.pt/~ltorgo



From fsaldan1 at gmail.com  Thu Feb  2 20:03:01 2006
From: fsaldan1 at gmail.com (Fernando Saldanha)
Date: Thu, 2 Feb 2006 14:03:01 -0500
Subject: [R] How to get the namespace of a function?
In-Reply-To: <971536df0602020804u3ae33709vfd95a1da89bd3783@mail.gmail.com>
References: <10dee4690602020756r199bd4fbh8fd5f688f0ad35ad@mail.gmail.com>
	<971536df0602020804u3ae33709vfd95a1da89bd3783@mail.gmail.com>
Message-ID: <10dee4690602021103g1ea14b34r4f063ce804f1fac1@mail.gmail.com>

Thanks, Gabor. I tried this without success:

> z <- ts(1:5)
> f <- function(x) {f1 <- function() get("index", "package:zoo"); f1()(x)}
> environment(f) <- NULL
> f(z)
Error in f1()(x) : no applicable method for "index"

I also tried this, which seemed simpler, with the same outcome:

> z <- ts(1:5)
> f <- function(x) {f1 <- get("index", "package:zoo"); f1(x)}
> environment(f) <- NULL
> f(z)
Error in f1(x) : no applicable method for "index"

FS



On 2/2/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Try:
>
> f <- function() get("index", "package:zoo")
>
>
> On 2/2/06, Fernando Saldanha <fsaldan1 at gmail.com> wrote:
> > I declared the environment of the function myfun to be NULL as follows:
> >
> > environment(myfun) <- NULL
> >
> > Later on I called that myfun and got an error message because the
> > function index() in the zoo package was called inside myfun and was
> > not visible:
> >
> > Error in myfun(args) : couldn't find function "index"
> >
> > I tried to use zoo::index() instead of index(), but that did not work.
> > In fact, zoo::index does not work even in the command line:
> >
> > > z<-ts(1:5)
> > > z
> > Time Series:
> > Start = 1
> > End = 5
> > Frequency = 1
> > [1] 1 2 3 4 5
> > > index(z)
> > [1] 1 2 3 4 5
> > > zoo::index(z)
> > Error in loadNamespace(name) : package 'zoo' does not have a name space
> >
> > How can I qualify index() so that it is visible inside the body of myfun?
> >
> > Thanks for any suggestions,
> >
> > FS
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>



From dpowers at mail.la.utexas.edu  Thu Feb  2 21:04:10 2006
From: dpowers at mail.la.utexas.edu (Daniel A. Powers)
Date: Thu, 2 Feb 2006 14:04:10 -0600 (CST)
Subject: [R] RHOME
Message-ID: <Pine.GSO.4.33.0602021358400.20430-100000@honoria.la.utexas.edu>


R-help --

I built R-2.2.1 in my own directory on a sun (solaris). Now I would like
the sysadmin to move the contents to /usr/local/lib and place the binary
in /usr/local/bin. No problem.  However, the RHOME variable defaults to
the directory from which R was built so it is not usable by anyone but me
or ROOT. I would like to avoid building this again if possible. Any ideas?

Thanks,
Dan

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Daniel A. Powers, Ph.D.
Department of Sociology
University of Texas at Austin
1 University Station A1700
Austin, TX  78712-0118
phone: 512-232-6335
fax:   512-471-1748
dpowers at mail.la.utexas.edu



From murdoch at stats.uwo.ca  Thu Feb  2 21:43:23 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 02 Feb 2006 15:43:23 -0500
Subject: [R] How to get the namespace of a function?
In-Reply-To: <10dee4690602020756r199bd4fbh8fd5f688f0ad35ad@mail.gmail.com>
References: <10dee4690602020756r199bd4fbh8fd5f688f0ad35ad@mail.gmail.com>
Message-ID: <43E26EEB.5070606@stats.uwo.ca>

On 2/2/2006 10:56 AM, Fernando Saldanha wrote:
> I declared the environment of the function myfun to be NULL as follows:
> 
> environment(myfun) <- NULL

Since version 2.1.0, it's been recommended that you use

environment(myfun) <- baseenv()

and since 2.2.0, you'll get a warning when using NULL (and you'll get an 
error in 2.3.0).  But why would you want to do that?  What are you 
trying to achieve?

Duncan Murdoch


> 
> Later on I called that myfun and got an error message because the
> function index() in the zoo package was called inside myfun and was
> not visible:
> 
> Error in myfun(args) : couldn't find function "index"
> 
> I tried to use zoo::index() instead of index(), but that did not work.
> In fact, zoo::index does not work even in the command line:
> 
>> z<-ts(1:5)
>> z
> Time Series:
> Start = 1
> End = 5
> Frequency = 1
> [1] 1 2 3 4 5
>> index(z)
> [1] 1 2 3 4 5
>> zoo::index(z)
> Error in loadNamespace(name) : package 'zoo' does not have a name space
> 
> How can I qualify index() so that it is visible inside the body of myfun?
> 
> Thanks for any suggestions,
> 
> FS
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From depire at inrets.fr  Thu Feb  2 21:45:32 2006
From: depire at inrets.fr (depire@inrets.fr)
Date: Thu, 02 Feb 2006 21:45:32 +0100
Subject: [R] Matrix variable in C code
In-Reply-To: <20060202174706.GI26788@rmki.kfki.hu>
References: <1138889502.43e2131e68fe9@webmail.inrets.fr>
	<20060202143246.GD24989@rmki.kfki.hu>
	<1138901267.43e24113d6de1@webmail.inrets.fr>
	<20060202174706.GI26788@rmki.kfki.hu>
Message-ID: <1138913132.43e26f6ce3183@webmail.inrets.fr>

Selon Gabor Csardi <csardi at rmki.kfki.hu>:

> On Thu, Feb 02, 2006 at 06:27:47PM +0100, depire at inrets.fr wrote:
> [...]
> 
> The problem is that as.double drops the dim attribute:
> > b <- matrix( 1:4, 2, 2)
> > b
>      [,1] [,2]
> [1,]    1    3
> [2,]    2    4
> > as.double(b)
> [1] 1 2 3 4
> > 
> 
> You can try: 
> 
> > b <- matrix( 1:4, 2, 2)
> > d <- dim(b)
> > b <- as.double(b)
> > b
> [1] 1 2 3 4
> > dim(b) <- d
> > b
>      [,1] [,2]
> [1,]    1    3
> [2,]    2    4
> 
> Another thing is that i cannot really see why the ZT parameter of the .Call
> should be a matrix anyway. It's just the vector (40 21 30 20). Or am i
> missing something?

Sorry, i make a mistake writing the small code, the correct one is the following
with the correct dim for ZT

========================================
X<-c(4,2,3,2)
Z<-c(40,21,30,20)
dX<-c(2,1,1)

dyn.load("test.so")

Phi<-function(z,a,b)
{
	Phi<-z
}

VPEfron<-function(XType,ZType,dXType,G,c0,c1)
{
	####################
	ZT<-matrix(0,3,2)
	ZT[1,1]<-Z[2]
	ZT[1,2]<-Z[4]
	ZT[2,1]<-Z[3]
	ZT[3,1]<-Z[1]
	####################

	# A OPTIMISER
      VPCEfron<-function(f,XT,ZT,dXT,tailleS=length(XT))
      {
		f.check<-function(x) {
            x<-f(x)
            }
     
.Call("VPCEfron",body(f.check),as.double(XT),as.double(ZT),as.integer(dXT),as.integer(tailleS),new.env())
	}
GG<-function(z) G(z,c0,c1)

Vraisemblancepartielle<-VPCEfron(GG,XType,ZType,dXType)
}

resultat<-VPEfron(X,Z,dX,Phi,0,0)
==========================================

The new piece of code is between ###.


Thanks,

Alex



From f.harrell at vanderbilt.edu  Thu Feb  2 22:00:13 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 02 Feb 2006 15:00:13 -0600
Subject: [R] Help with ldBands(Hmisc)
In-Reply-To: <93881773336F8947BB4A57D9EF3BE6FDDFD62A@mopamrexm19.amer.pfizer.com>
References: <93881773336F8947BB4A57D9EF3BE6FDDFD62A@mopamrexm19.amer.pfizer.com>
Message-ID: <43E272DD.8010109@vanderbilt.edu>

Lakshminarayanan, Mani wrote:
> Hello My Fellow Users,
> 
> Under the details it is given that the ld98 executable should be in a subdirectory that is in the system.  Should ld98.exe be included under Hmisc (where it is stored) or under the lib subdirectory within Hmisc?  I am getting the following error message: Error in (head + 1):length(w) : NA/NaN argument.  Does this mean that I didn't store the ld98.exe in the right place or something else?  Please help.
> 

I doubt it - I think you would get a more severe error.  Usually exe 
files are not in the same directory as a package but they can be.  In 
linux I put such executables in /usr/local/bin - see what is the analogy 
for Windows.  Wherever you put it make sure it's in the system PATH.

Frank

> Mani
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From ggrothendieck at gmail.com  Thu Feb  2 22:05:18 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 2 Feb 2006 16:05:18 -0500
Subject: [R] How to get the namespace of a function?
In-Reply-To: <10dee4690602021103g1ea14b34r4f063ce804f1fac1@mail.gmail.com>
References: <10dee4690602020756r199bd4fbh8fd5f688f0ad35ad@mail.gmail.com>
	<971536df0602020804u3ae33709vfd95a1da89bd3783@mail.gmail.com>
	<10dee4690602021103g1ea14b34r4f063ce804f1fac1@mail.gmail.com>
Message-ID: <971536df0602021305m35d393e3n676ca83ca55ca08@mail.gmail.com>

It actually did find index -- in fact, the error message is coming from index.
I forgot that in this case index is a generic which in turn is calling
index.ts and that is what it can't find.  How about one of these:

> library(zoo)
> f <- function(x) eval(substitute(index(x), list(x = x)),
+ envir = as.environment("package:zoo"))
> environment(f) <- NULL
> x <- ts(1:4)
> f(x)
[1] 1 2 3 4

or

> library(zoo)
> f <- function(x) eval.parent(substitute(index(x)))
> environment(f) <- NULL
> x <- ts(1:4)
> f(x)
[1] 1 2 3 4




On 2/2/06, Fernando Saldanha <fsaldan1 at gmail.com> wrote:
> Thanks, Gabor. I tried this without success:
>
> > z <- ts(1:5)
> > f <- function(x) {f1 <- function() get("index", "package:zoo"); f1()(x)}
> > environment(f) <- NULL
> > f(z)
> Error in f1()(x) : no applicable method for "index"
>
> I also tried this, which seemed simpler, with the same outcome:
>
> > z <- ts(1:5)
> > f <- function(x) {f1 <- get("index", "package:zoo"); f1(x)}
> > environment(f) <- NULL
> > f(z)
> Error in f1(x) : no applicable method for "index"
>
> FS
>
>
>
> On 2/2/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > Try:
> >
> > f <- function() get("index", "package:zoo")
> >
> >
> > On 2/2/06, Fernando Saldanha <fsaldan1 at gmail.com> wrote:
> > > I declared the environment of the function myfun to be NULL as follows:
> > >
> > > environment(myfun) <- NULL
> > >
> > > Later on I called that myfun and got an error message because the
> > > function index() in the zoo package was called inside myfun and was
> > > not visible:
> > >
> > > Error in myfun(args) : couldn't find function "index"
> > >
> > > I tried to use zoo::index() instead of index(), but that did not work.
> > > In fact, zoo::index does not work even in the command line:
> > >
> > > > z<-ts(1:5)
> > > > z
> > > Time Series:
> > > Start = 1
> > > End = 5
> > > Frequency = 1
> > > [1] 1 2 3 4 5
> > > > index(z)
> > > [1] 1 2 3 4 5
> > > > zoo::index(z)
> > > Error in loadNamespace(name) : package 'zoo' does not have a name space
> > >
> > > How can I qualify index() so that it is visible inside the body of myfun?
> > >
> > > Thanks for any suggestions,
> > >
> > > FS
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > >
> >
>



From plummer at iarc.fr  Thu Feb  2 22:34:23 2006
From: plummer at iarc.fr (plummer@iarc.fr)
Date: Thu, 02 Feb 2006 22:34:23 +0100
Subject: [R] RHOME
In-Reply-To: <Pine.GSO.4.33.0602021358400.20430-100000@honoria.la.utexas.edu>
References: <Pine.GSO.4.33.0602021358400.20430-100000@honoria.la.utexas.edu>
Message-ID: <1138916063.43e27adf6393b@webmail.iarc.fr>

Quoting "Daniel A. Powers" <dpowers at mail.la.utexas.edu>:

>
> R-help --
>
> I built R-2.2.1 in my own directory on a sun (solaris). Now I would like
> the sysadmin to move the contents to /usr/local/lib and place the binary
> in /usr/local/bin. No problem.  However, the RHOME variable defaults to
> the directory from which R was built so it is not usable by anyone but me
> or ROOT. I would like to avoid building this again if possible. Any ideas?
>
> Thanks,
> Dan

R is designed to run from its build directory.  But if your sysadmin installs it
with "make install" (as root), then the shell wrapper that is installed in
/usr/local/bin/R will have R_HOME pointing to the right location
(/usr/local/lib/R).  Literally moving the build directory to another location
is the wrong thing to do.
-----------------------------------------------------------------------
This message and its attachments are strictly confidential. ...{{dropped}}



From dpowers at mail.la.utexas.edu  Thu Feb  2 22:37:32 2006
From: dpowers at mail.la.utexas.edu (Daniel A. Powers)
Date: Thu, 2 Feb 2006 15:37:32 -0600 (CST)
Subject: [R] RHOME
In-Reply-To: <1138916063.43e27adf6393b@webmail.iarc.fr>
Message-ID: <Pine.GSO.4.33.0602021536290.20430-100000@honoria.la.utexas.edu>

Thanks --
I was trying not to burden the sysadmin with this task, but it seems that
it should be done right.
Cheers,
Dan

=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
Daniel A. Powers, Ph.D.
Department of Sociology
University of Texas at Austin
1 University Station A1700
Austin, TX  78712-0118
phone: 512-232-6335
fax:   512-471-1748
dpowers at mail.la.utexas.edu


On Thu, 2 Feb 2006 plummer at iarc.fr wrote:

> Quoting "Daniel A. Powers" <dpowers at mail.la.utexas.edu>:
>
> >
> > R-help --
> >
> > I built R-2.2.1 in my own directory on a sun (solaris). Now I would like
> > the sysadmin to move the contents to /usr/local/lib and place the binary
> > in /usr/local/bin. No problem.  However, the RHOME variable defaults to
> > the directory from which R was built so it is not usable by anyone but me
> > or ROOT. I would like to avoid building this again if possible. Any ideas?
> >
> > Thanks,
> > Dan
>
> R is designed to run from its build directory.  But if your sysadmin installs it
> with "make install" (as root), then the shell wrapper that is installed in
> /usr/local/bin/R will have R_HOME pointing to the right location
> (/usr/local/lib/R).  Literally moving the build directory to another location
> is the wrong thing to do.
> -----------------------------------------------------------------------
> This message and its attachments are strictly confidential...{{dropped}}



From arrayprofile at yahoo.com  Thu Feb  2 22:53:42 2006
From: arrayprofile at yahoo.com (array chip)
Date: Thu, 2 Feb 2006 13:53:42 -0800 (PST)
Subject: [R] fisher table probability
In-Reply-To: <Pine.LNX.4.61.0602020651140.8971@gannet.stats>
Message-ID: <20060202215342.30297.qmail@web34805.mail.mud.yahoo.com>

Thanks for the suggestion! what if the dimensions of
the table is greater than 2, say 3x4?

--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On Wed, 1 Feb 2006, array chip wrote:
> 
> > Hi, is there a way to generate the table's
> probability
> > when doing the fisher's exact test on a 2x2 table?
> The
> > fisher's exact test gives the p value, but not the
> > probability for the table.
> 
> Call dhyper, as fisher.test itself does.
> 
> -- 
> Brian D. Ripley,                 
> ripley at stats.ox.ac.uk
> Professor of Applied Statistics, 
> http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865
> 272861 (self)
> 1 South Parks Road,                     +44 1865
> 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865
> 272595
>



From comtech.usa at gmail.com  Thu Feb  2 23:01:19 2006
From: comtech.usa at gmail.com (Michael)
Date: Thu, 2 Feb 2006 14:01:19 -0800
Subject: [R] is there a way to visualize 3D normal distributions?
In-Reply-To: <loom.20060202T155042-992@post.gmane.org>
References: <b1f16d9d0602020039t5604b508m11d857f67f903e91@mail.gmail.com>
	<43E1F227.7000602@stats.uwo.ca>
	<loom.20060202T155042-992@post.gmane.org>
Message-ID: <b1f16d9d0602021401k9655566n214c6e68c6215043@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060202/cfc3f4e7/attachment.pl

From comtech.usa at gmail.com  Thu Feb  2 23:02:33 2006
From: comtech.usa at gmail.com (Michael)
Date: Thu, 2 Feb 2006 14:02:33 -0800
Subject: [R] is there a way to visualize 3D normal distributions?
In-Reply-To: <20060202150330.FRDT5032.tomts36-srv.bellnexxia.net@JohnDesktop8300>
References: <b1f16d9d0602020039t5604b508m11d857f67f903e91@mail.gmail.com>
	<20060202150330.FRDT5032.tomts36-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <b1f16d9d0602021402x15357bd3v7a9d86e37f5a1a07@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060202/7752518a/attachment.pl

From ripley at stats.ox.ac.uk  Thu Feb  2 23:03:18 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 2 Feb 2006 22:03:18 +0000 (GMT)
Subject: [R] fisher table probability
In-Reply-To: <20060202215342.30297.qmail@web34805.mail.mud.yahoo.com>
References: <20060202215342.30297.qmail@web34805.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.61.0602022159330.26036@gannet.stats>

On Thu, 2 Feb 2006, array chip wrote:

> Thanks for the suggestion! what if the dimensions of
> the table is greater than 2, say 3x4?

Look at the references quoted on the help page for the formula: the 
simulation code for p-values in R-devel makes use of it and it is easy to 
compute via lgamma.

>
> --- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
>> On Wed, 1 Feb 2006, array chip wrote:
>>
>>> Hi, is there a way to generate the table's
>> probability
>>> when doing the fisher's exact test on a 2x2 table?
>> The
>>> fisher's exact test gives the p value, but not the
>>> probability for the table.
>>
>> Call dhyper, as fisher.test itself does.
>>
>> --
>> Brian D. Ripley,
>> ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,
>> http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865
>> 272861 (self)
>> 1 South Parks Road,                     +44 1865
>> 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865
>> 272595
>>
>
>
> __________________________________________________
> Do You Yahoo!?
> Tired of spam?  Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fsaldan1 at gmail.com  Thu Feb  2 23:05:31 2006
From: fsaldan1 at gmail.com (Fernando Saldanha)
Date: Thu, 2 Feb 2006 17:05:31 -0500
Subject: [R] How to get the namespace of a function?
In-Reply-To: <43E26EEB.5070606@stats.uwo.ca>
References: <10dee4690602020756r199bd4fbh8fd5f688f0ad35ad@mail.gmail.com>
	<43E26EEB.5070606@stats.uwo.ca>
Message-ID: <10dee4690602021405g19656bcck162ed198804b6f10@mail.gmail.com>

I am trying to imitate "encapsulation" from other languages like Java
or C++. Coming from that background, it bothers me that I can commit
errors like the following:

> x <- 1
> f <- function(z) { y <- x; y + 1 } # Mistake: I should have written y <- z
> f(10)
[1] 2

In a language like Java the interpreter would have noticed that x was
an undeclared variable and an error message would be issued. R, on the
other hand, allows the code to run, as x exists in the global
environment. I was trying to avoid such situations by  setting the
environment of f to be NULL. If there is a better way to catch this
type of errors I would be interested in knowing about it.

FS

On 2/2/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 2/2/2006 10:56 AM, Fernando Saldanha wrote:
> > I declared the environment of the function myfun to be NULL as follows:
> >
> > environment(myfun) <- NULL
>
> Since version 2.1.0, it's been recommended that you use
>
> environment(myfun) <- baseenv()
>
> and since 2.2.0, you'll get a warning when using NULL (and you'll get an
> error in 2.3.0).  But why would you want to do that?  What are you
> trying to achieve?
>
> Duncan Murdoch
>
>
> >
> > Later on I called that myfun and got an error message because the
> > function index() in the zoo package was called inside myfun and was
> > not visible:
> >
> > Error in myfun(args) : couldn't find function "index"
> >
> > I tried to use zoo::index() instead of index(), but that did not work.
> > In fact, zoo::index does not work even in the command line:
> >
> >> z<-ts(1:5)
> >> z
> > Time Series:
> > Start = 1
> > End = 5
> > Frequency = 1
> > [1] 1 2 3 4 5
> >> index(z)
> > [1] 1 2 3 4 5
> >> zoo::index(z)
> > Error in loadNamespace(name) : package 'zoo' does not have a name space
> >
> > How can I qualify index() so that it is visible inside the body of myfun?
> >
> > Thanks for any suggestions,
> >
> > FS
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From jporzak at gmail.com  Thu Feb  2 23:14:27 2006
From: jporzak at gmail.com (Jim Porzak)
Date: Thu, 2 Feb 2006 14:14:27 -0800
Subject: [R] R training courses
In-Reply-To: <Pine.LNX.4.62.0602021311260.28543@gate.nmr.mgh.harvard.edu>
References: <EF691D4805C12C4294D2A8515372EAF30448E842@kdcp4pmbx05.cof.ds.capitalone.com>
	<Pine.LNX.4.62.0602021311260.28543@gate.nmr.mgh.harvard.edu>
Message-ID: <2a9c000c0602021414y481bb25dk85862587ece3eea2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060202/544f36c1/attachment.pl

From murdoch at stats.uwo.ca  Thu Feb  2 23:15:53 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 02 Feb 2006 17:15:53 -0500
Subject: [R] How to get the namespace of a function?
In-Reply-To: <10dee4690602021405g19656bcck162ed198804b6f10@mail.gmail.com>
References: <10dee4690602020756r199bd4fbh8fd5f688f0ad35ad@mail.gmail.com>	
	<43E26EEB.5070606@stats.uwo.ca>
	<10dee4690602021405g19656bcck162ed198804b6f10@mail.gmail.com>
Message-ID: <43E28499.5030402@stats.uwo.ca>

On 2/2/2006 5:05 PM, Fernando Saldanha wrote:
> I am trying to imitate "encapsulation" from other languages like Java
> or C++. Coming from that background, it bothers me that I can commit
> errors like the following:
> 
>> x <- 1
>> f <- function(z) { y <- x; y + 1 } # Mistake: I should have written y <- z
>> f(10)
> [1] 2
> 
> In a language like Java the interpreter would have noticed that x was
> an undeclared variable and an error message would be issued. R, on the
> other hand, allows the code to run, as x exists in the global
> environment. I was trying to avoid such situations by  setting the
> environment of f to be NULL. If there is a better way to catch this
> type of errors I would be interested in knowing about it.

Put your code in a package, and use a namespace.  This isn't perfect, 
but it gives you more control than you have when running scripts at the 
console.

There's an article by Luke Tierney in one of R News 3/1 that explains 
the search order when namespaces are involved.

Duncan Murdoch
> 
> FS
> 
> On 2/2/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 2/2/2006 10:56 AM, Fernando Saldanha wrote:
>>> I declared the environment of the function myfun to be NULL as follows:
>>>
>>> environment(myfun) <- NULL
>> Since version 2.1.0, it's been recommended that you use
>>
>> environment(myfun) <- baseenv()
>>
>> and since 2.2.0, you'll get a warning when using NULL (and you'll get an
>> error in 2.3.0).  But why would you want to do that?  What are you
>> trying to achieve?
>>
>> Duncan Murdoch
>>
>>
>>> Later on I called that myfun and got an error message because the
>>> function index() in the zoo package was called inside myfun and was
>>> not visible:
>>>
>>> Error in myfun(args) : couldn't find function "index"
>>>
>>> I tried to use zoo::index() instead of index(), but that did not work.
>>> In fact, zoo::index does not work even in the command line:
>>>
>>>> z<-ts(1:5)
>>>> z
>>> Time Series:
>>> Start = 1
>>> End = 5
>>> Frequency = 1
>>> [1] 1 2 3 4 5
>>>> index(z)
>>> [1] 1 2 3 4 5
>>>> zoo::index(z)
>>> Error in loadNamespace(name) : package 'zoo' does not have a name space
>>>
>>> How can I qualify index() so that it is visible inside the body of myfun?
>>>
>>> Thanks for any suggestions,
>>>
>>> FS
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>



From colchero at duke.edu  Thu Feb  2 23:20:57 2006
From: colchero at duke.edu (colchero@duke.edu)
Date: Thu, 2 Feb 2006 17:20:57 -0500 (EST)
Subject: [R] Conflict between julian from base and from chron
Message-ID: <Pine.GSO.4.58.0602021713150.18567@godzilla.acpub.duke.edu>


I used to run the julian function from chron but this new version of R has
also a julian function in the base package that doesn't do exactly what I
need. Is there a way of telling R to run the function from chron and not
from base?

Thanks,

  Fernando

      __________________________

       Fernando Colchero
       Doctoral Fellow
       Duke University
       Department of Ecology
       A322 Levine Science and
       Research  Center (LSRC)
       Durham, NC 27708 USA
       Phone: (919) 613 80 57
      __________________________



From ggrothendieck at gmail.com  Thu Feb  2 23:31:38 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 2 Feb 2006 17:31:38 -0500
Subject: [R] How to get the namespace of a function?
In-Reply-To: <10dee4690602021405g19656bcck162ed198804b6f10@mail.gmail.com>
References: <10dee4690602020756r199bd4fbh8fd5f688f0ad35ad@mail.gmail.com>
	<43E26EEB.5070606@stats.uwo.ca>
	<10dee4690602021405g19656bcck162ed198804b6f10@mail.gmail.com>
Message-ID: <971536df0602021431o18144dat74c0598db5e78e3d@mail.gmail.com>

R largely makes everything open (at least relative to languages that
have strict encapsulation) and I think you simply need to accept that
when using R.  There are benefits to both approaches (the R approach
generally involves less code which is particularly important when entering
code into the console and in small programs which are more the domain
of R whereas the encapsulation approach can catch more
errors which is more important in large programs).    You could use a
variable name convention that makes collisions
less likely but overall R is not java and I think one just has to accept that
or use a different language.

Also, there are some tools in the codetools package that you could use
to check your variables.

On 2/2/06, Fernando Saldanha <fsaldan1 at gmail.com> wrote:
> I am trying to imitate "encapsulation" from other languages like Java
> or C++. Coming from that background, it bothers me that I can commit
> errors like the following:
>
> > x <- 1
> > f <- function(z) { y <- x; y + 1 } # Mistake: I should have written y <- z
> > f(10)
> [1] 2
>
> In a language like Java the interpreter would have noticed that x was
> an undeclared variable and an error message would be issued. R, on the
> other hand, allows the code to run, as x exists in the global
> environment. I was trying to avoid such situations by  setting the
> environment of f to be NULL. If there is a better way to catch this
> type of errors I would be interested in knowing about it.
>
> FS
>
> On 2/2/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > On 2/2/2006 10:56 AM, Fernando Saldanha wrote:
> > > I declared the environment of the function myfun to be NULL as follows:
> > >
> > > environment(myfun) <- NULL
> >
> > Since version 2.1.0, it's been recommended that you use
> >
> > environment(myfun) <- baseenv()
> >
> > and since 2.2.0, you'll get a warning when using NULL (and you'll get an
> > error in 2.3.0).  But why would you want to do that?  What are you
> > trying to achieve?
> >
> > Duncan Murdoch
> >
> >
> > >
> > > Later on I called that myfun and got an error message because the
> > > function index() in the zoo package was called inside myfun and was
> > > not visible:
> > >
> > > Error in myfun(args) : couldn't find function "index"
> > >
> > > I tried to use zoo::index() instead of index(), but that did not work.
> > > In fact, zoo::index does not work even in the command line:
> > >
> > >> z<-ts(1:5)
> > >> z
> > > Time Series:
> > > Start = 1
> > > End = 5
> > > Frequency = 1
> > > [1] 1 2 3 4 5
> > >> index(z)
> > > [1] 1 2 3 4 5
> > >> zoo::index(z)
> > > Error in loadNamespace(name) : package 'zoo' does not have a name space
> > >
> > > How can I qualify index() so that it is visible inside the body of myfun?
> > >
> > > Thanks for any suggestions,
> > >
> > > FS
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From arrayprofile at yahoo.com  Thu Feb  2 23:54:32 2006
From: arrayprofile at yahoo.com (array chip)
Date: Thu, 2 Feb 2006 14:54:32 -0800 (PST)
Subject: [R] fisher table probability
In-Reply-To: <Pine.LNX.4.61.0602022159330.26036@gannet.stats>
Message-ID: <20060202225432.19024.qmail@web34814.mail.mud.yahoo.com>

Thanks for pointing. This is my simple function for
doing this, just like to share if anyone ever needs
it:

   ## x is a rxc table
tabprob<-function (x) {
  tmp<-0
  for (i in 1:dim(x)[1]) {
    tmp<-tmp+lgamma(sum(x[i,])+1)
    for (j in 1:dim(x)[2]) {
      if (i==1) tmp<-tmp+lgamma(sum(x[,j])+1)
      tmp<-tmp-lgamma(x[i,j]+1)
    }
  }
  tmp<-tmp-lgamma(sum(x)+1)
  exp(tmp)
}



--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On Thu, 2 Feb 2006, array chip wrote:
> 
> > Thanks for the suggestion! what if the dimensions
> of
> > the table is greater than 2, say 3x4?
> 
> Look at the references quoted on the help page for
> the formula: the 
> simulation code for p-values in R-devel makes use of
> it and it is easy to 
> compute via lgamma.
> 
> >
> > --- Prof Brian Ripley <ripley at stats.ox.ac.uk>
> wrote:
> >
> >> On Wed, 1 Feb 2006, array chip wrote:
> >>
> >>> Hi, is there a way to generate the table's
> >> probability
> >>> when doing the fisher's exact test on a 2x2
> table?
> >> The
> >>> fisher's exact test gives the p value, but not
> the
> >>> probability for the table.
> >>
> >> Call dhyper, as fisher.test itself does.
> >>
> >> --
> >> Brian D. Ripley,
> >> ripley at stats.ox.ac.uk
> >> Professor of Applied Statistics,
> >> http://www.stats.ox.ac.uk/~ripley/
> >> University of Oxford,             Tel:  +44 1865
> >> 272861 (self)
> >> 1 South Parks Road,                     +44 1865
> >> 272866 (PA)
> >> Oxford OX1 3TG, UK                Fax:  +44 1865
> >> 272595
> >>
> >
> >
> > __________________________________________________
> > Do You Yahoo!?

> protection around
> > http://mail.yahoo.com
> >
> >
> 
> -- 
> Brian D. Ripley,                 
> ripley at stats.ox.ac.uk
> Professor of Applied Statistics, 
> http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865
> 272861 (self)
> 1 South Parks Road,                     +44 1865
> 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865
> 272595
>



From bolker at zoo.ufl.edu  Thu Feb  2 23:55:47 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Thu, 02 Feb 2006 17:55:47 -0500
Subject: [R] is there a way to visualize 3D normal distributions?
In-Reply-To: <b1f16d9d0602021401k9655566n214c6e68c6215043@mail.gmail.com>
References: <b1f16d9d0602020039t5604b508m11d857f67f903e91@mail.gmail.com>	
	<43E1F227.7000602@stats.uwo.ca>	
	<loom.20060202T155042-992@post.gmane.org>
	<b1f16d9d0602021401k9655566n214c6e68c6215043@mail.gmail.com>
Message-ID: <43E28DF3.3060107@zoo.ufl.edu>

Michael wrote:
> shape3d only gives rigid sphere... not the free form ellipsoid that I 
> want...
> 

   one or the other of us is missing something.

    after running demo(shapes3d)
[to define ellipsoid3d] and rgl.clear(),

s1 <- ellipsoid3d(qmesh = TRUE, trans = diag(4))
shade3d(rotate3d(scale3d(s1, 1, 1, 2),
                  angle=pi/4, x=0, y=1, z=0),
         col = "red")
axis3d()

  produces an ellipsoid with radii (1,1,2) rotated by pi/4 around
the y axis.  I'm too lazy to figure out how to
translate a variance-covariance matrix into
a scaling/rotation matrix (the scale will want
to be something like eigen(v)$values*qnorm(0.975)
for a 95% contour, the rotation matrix is some
function of the eigenvectors), but it seems to
me that this will produce any ("free form"?) ellipsoid
you want.

   cheers
     Ben Bolker



From gunter.berton at gene.com  Thu Feb  2 23:56:44 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 2 Feb 2006 14:56:44 -0800
Subject: [R] How to get the namespace of a function?
In-Reply-To: <43E28499.5030402@stats.uwo.ca>
Message-ID: <200602022256.k12Mui2W017683@volta.gene.com>

Just echoing and slightly amplifying Gabor's comment...

The semantics of R are really based on functional programming (LISP-like)
rather than OOP (JAVA-like)? R's behavior is "proper" from that point of
view; what is "improper" is Fernando's expectation that it should behave
some other way. Of course, one can simulate anything with a Turing machine,
but I consider Fernando's criticisms somewhat "unfair" because he is
expecting R to behave like something he is familiar with rather than as it
was designed to. For this reason, what bothers him seems wholly desirable to
me -- I want there to be well-defined scoping convention (lexical scoping)
for R to find free variables.

Cheers,

Bert



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Duncan Murdoch
Sent: Thursday, February 02, 2006 2:16 PM
To: fsaldanha at alum.mit.edu
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] How to get the namespace of a function?

On 2/2/2006 5:05 PM, Fernando Saldanha wrote:
> I am trying to imitate "encapsulation" from other languages like Java
> or C++. Coming from that background, it bothers me that I can commit
> errors like the following:
> 
>> x <- 1
>> f <- function(z) { y <- x; y + 1 } # Mistake: I should have written y <-
z
>> f(10)
> [1] 2
> 
> In a language like Java the interpreter would have noticed that x was
> an undeclared variable and an error message would be issued. R, on the
> other hand, allows the code to run, as x exists in the global
> environment. I was trying to avoid such situations by  setting the
> environment of f to be NULL. If there is a better way to catch this
> type of errors I would be interested in knowing about it.

Put your code in a package, and use a namespace.  This isn't perfect, 
but it gives you more control than you have when running scripts at the 
console.

There's an article by Luke Tierney in one of R News 3/1 that explains 
the search order when namespaces are involved.

Duncan Murdoch
> 
> FS
> 
> On 2/2/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 2/2/2006 10:56 AM, Fernando Saldanha wrote:
>>> I declared the environment of the function myfun to be NULL as follows:
>>>
>>> environment(myfun) <- NULL
>> Since version 2.1.0, it's been recommended that you use
>>
>> environment(myfun) <- baseenv()
>>
>> and since 2.2.0, you'll get a warning when using NULL (and you'll get an
>> error in 2.3.0).  But why would you want to do that?  What are you
>> trying to achieve?
>>
>> Duncan Murdoch
>>
>>
>>> Later on I called that myfun and got an error message because the
>>> function index() in the zoo package was called inside myfun and was
>>> not visible:
>>>
>>> Error in myfun(args) : couldn't find function "index"
>>>
>>> I tried to use zoo::index() instead of index(), but that did not work.
>>> In fact, zoo::index does not work even in the command line:
>>>
>>>> z<-ts(1:5)
>>>> z
>>> Time Series:
>>> Start = 1
>>> End = 5
>>> Frequency = 1
>>> [1] 1 2 3 4 5
>>>> index(z)
>>> [1] 1 2 3 4 5
>>>> zoo::index(z)
>>> Error in loadNamespace(name) : package 'zoo' does not have a name space
>>>
>>> How can I qualify index() so that it is visible inside the body of
myfun?
>>>
>>> Thanks for any suggestions,
>>>
>>> FS
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ggrothendieck at gmail.com  Fri Feb  3 00:08:34 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 2 Feb 2006 18:08:34 -0500
Subject: [R] Conflict between julian from base and from chron
In-Reply-To: <Pine.GSO.4.58.0602021713150.18567@godzilla.acpub.duke.edu>
References: <Pine.GSO.4.58.0602021713150.18567@godzilla.acpub.duke.edu>
Message-ID: <971536df0602021508t568f6c1cm137e42168efa0098@mail.gmail.com>

Perhaps you can provide an example of your problem.

The session below is from R 2.2.1 on Windows XP.  The base
contains a generic and Date and POSIXt methods
whereas chron currently contains a default method
so in principle they can all coexist.


> methods(julian)
[1] julian.Date     julian.default* julian.POSIXt



On 2/2/06, colchero at duke.edu <colchero at duke.edu> wrote:
>
> I used to run the julian function from chron but this new version of R has
> also a julian function in the base package that doesn't do exactly what I
> need. Is there a way of telling R to run the function from chron and not
> from base?
>
> Thanks,
>
>  Fernando
>
>      __________________________
>
>       Fernando Colchero
>       Doctoral Fellow
>       Duke University
>       Department of Ecology
>       A322 Levine Science and
>       Research  Center (LSRC)
>       Durham, NC 27708 USA
>       Phone: (919) 613 80 57
>      __________________________
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From colchero at duke.edu  Fri Feb  3 00:10:49 2006
From: colchero at duke.edu (colchero@duke.edu)
Date: Thu, 2 Feb 2006 18:10:49 -0500 (EST)
Subject: [R] Conflict between julian from base and from chron
In-Reply-To: <971536df0602021508t568f6c1cm137e42168efa0098@mail.gmail.com>
References: <Pine.GSO.4.58.0602021713150.18567@godzilla.acpub.duke.edu>
	<971536df0602021508t568f6c1cm137e42168efa0098@mail.gmail.com>
Message-ID: <Pine.GSO.4.58.0602021809170.18567@godzilla.acpub.duke.edu>


Thanks to all for the replies, actually I found that I had a problem
downloading chron. It's running now.

  Fernando


On Thu, 2 Feb 2006, Gabor Grothendieck wrote:

> Perhaps you can provide an example of your problem.
>
> The session below is from R 2.2.1 on Windows XP.  The base
> contains a generic and Date and POSIXt methods
> whereas chron currently contains a default method
> so in principle they can all coexist.
>
>
> > methods(julian)
> [1] julian.Date     julian.default* julian.POSIXt
>
>
>
> On 2/2/06, colchero at duke.edu <colchero at duke.edu> wrote:
> >
> > I used to run the julian function from chron but this new version of R has
> > also a julian function in the base package that doesn't do exactly what I
> > need. Is there a way of telling R to run the function from chron and not
> > from base?
> >
> > Thanks,
> >
> >  Fernando
> >
> >      __________________________
> >
> >       Fernando Colchero
> >       Doctoral Fellow
> >       Duke University
> >       Department of Ecology
> >       A322 Levine Science and
> >       Research  Center (LSRC)
> >       Durham, NC 27708 USA
> >       Phone: (919) 613 80 57
> >      __________________________
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>


      __________________________

       Fernando Colchero
       Doctoral Fellow
       Duke University
       Department of Ecology
       A322 Levine Science and
       Research  Center (LSRC)
       Durham, NC 27708 USA
       Phone: (919) 613 80 57
      __________________________



From ggrothendieck at gmail.com  Fri Feb  3 00:16:09 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 2 Feb 2006 18:16:09 -0500
Subject: [R] How to get the namespace of a function?
In-Reply-To: <200602022256.k12Mui2W017683@volta.gene.com>
References: <43E28499.5030402@stats.uwo.ca>
	<200602022256.k12Mui2W017683@volta.gene.com>
Message-ID: <971536df0602021516j44f3b6e5qf52c470a650417aa@mail.gmail.com>

I don't want to put words in anyone's mouth but I don't think
the poster was voicing an unfair criticism so much as explaining
his expectation coming from a java background.

On 2/2/06, Berton Gunter <gunter.berton at gene.com> wrote:
> Just echoing and slightly amplifying Gabor's comment...
>
> The semantics of R are really based on functional programming (LISP-like)
> rather than OOP (JAVA-like)? R's behavior is "proper" from that point of
> view; what is "improper" is Fernando's expectation that it should behave
> some other way. Of course, one can simulate anything with a Turing machine,
> but I consider Fernando's criticisms somewhat "unfair" because he is
> expecting R to behave like something he is familiar with rather than as it
> was designed to. For this reason, what bothers him seems wholly desirable to
> me -- I want there to be well-defined scoping convention (lexical scoping)
> for R to find free variables.
>
> Cheers,
>
> Bert
>
>
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Duncan Murdoch
> Sent: Thursday, February 02, 2006 2:16 PM
> To: fsaldanha at alum.mit.edu
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] How to get the namespace of a function?
>
> On 2/2/2006 5:05 PM, Fernando Saldanha wrote:
> > I am trying to imitate "encapsulation" from other languages like Java
> > or C++. Coming from that background, it bothers me that I can commit
> > errors like the following:
> >
> >> x <- 1
> >> f <- function(z) { y <- x; y + 1 } # Mistake: I should have written y <-
> z
> >> f(10)
> > [1] 2
> >
> > In a language like Java the interpreter would have noticed that x was
> > an undeclared variable and an error message would be issued. R, on the
> > other hand, allows the code to run, as x exists in the global
> > environment. I was trying to avoid such situations by  setting the
> > environment of f to be NULL. If there is a better way to catch this
> > type of errors I would be interested in knowing about it.
>
> Put your code in a package, and use a namespace.  This isn't perfect,
> but it gives you more control than you have when running scripts at the
> console.
>
> There's an article by Luke Tierney in one of R News 3/1 that explains
> the search order when namespaces are involved.
>
> Duncan Murdoch
> >
> > FS
> >
> > On 2/2/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> On 2/2/2006 10:56 AM, Fernando Saldanha wrote:
> >>> I declared the environment of the function myfun to be NULL as follows:
> >>>
> >>> environment(myfun) <- NULL
> >> Since version 2.1.0, it's been recommended that you use
> >>
> >> environment(myfun) <- baseenv()
> >>
> >> and since 2.2.0, you'll get a warning when using NULL (and you'll get an
> >> error in 2.3.0).  But why would you want to do that?  What are you
> >> trying to achieve?
> >>
> >> Duncan Murdoch
> >>
> >>
> >>> Later on I called that myfun and got an error message because the
> >>> function index() in the zoo package was called inside myfun and was
> >>> not visible:
> >>>
> >>> Error in myfun(args) : couldn't find function "index"
> >>>
> >>> I tried to use zoo::index() instead of index(), but that did not work.
> >>> In fact, zoo::index does not work even in the command line:
> >>>
> >>>> z<-ts(1:5)
> >>>> z
> >>> Time Series:
> >>> Start = 1
> >>> End = 5
> >>> Frequency = 1
> >>> [1] 1 2 3 4 5
> >>>> index(z)
> >>> [1] 1 2 3 4 5
> >>>> zoo::index(z)
> >>> Error in loadNamespace(name) : package 'zoo' does not have a name space
> >>>
> >>> How can I qualify index() so that it is visible inside the body of
> myfun?
> >>>
> >>> Thanks for any suggestions,
> >>>
> >>> FS
> >>>
> >>> ______________________________________________
> >>> R-help at stat.math.ethz.ch mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Fri Feb  3 00:21:33 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 02 Feb 2006 18:21:33 -0500
Subject: [R] is there a way to visualize 3D normal distributions?
In-Reply-To: <b1f16d9d0602021401k9655566n214c6e68c6215043@mail.gmail.com>
References: <b1f16d9d0602020039t5604b508m11d857f67f903e91@mail.gmail.com>	<43E1F227.7000602@stats.uwo.ca>	<loom.20060202T155042-992@post.gmane.org>
	<b1f16d9d0602021401k9655566n214c6e68c6215043@mail.gmail.com>
Message-ID: <43E293FD.4040700@stats.uwo.ca>

On 2/2/2006 5:01 PM, Michael wrote:
> shape3d only gives rigid sphere... not the free form ellipsoid that I
> want...

? If you run the demo, you'll see ellipsoids...

You just need to work out the appropriate transform to apply to a sphere 
to get the ellipsoid you want.  I imagine something like this:

sphere <- ellipsoid3d(2,2,2, qmesh=TRUE)
ellipsoid <- translate3d(rotate3d(sphere, matrix=chol(S)), xbar, ybar, zbar)

shade3d(ellipsoid)

is what you want, where S is the covariance matrix, and xbar,ybar,zbar 
have the obvious meaning.  (rotate3d() is used with a matrix that isn't 
a rotation matrix; it may not be obvious that this is allowed, but it is.)

Duncan Murdoch


> 
> On 2/2/06, Ben Bolker <bolker at ufl.edu> wrote:
>> Duncan Murdoch <murdoch <at> stats.uwo.ca> writes:
>>
>>> On 2/2/2006 3:39 AM, Michael wrote:
>>>> Hi all,
>>>>
>>>> How do I visualize a contour of a tri-variate normal distribution?
>>>>
>>>> I just like to see the ellipsoid very much. I hope there is a easy way
>> or
>>>> existing method in R.
>>> The misc3d package includes a function for 3d contour plots; that should
>>> do what you want.
>>>
>>   is contour3d really necessary or could you just plot ellipsoids?
>> (library(rgl); demo(shapes3d)) -- still a little bit of figuring
>> to do, but this should get you most of the way there.
>>
>>   Ben Bolker
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From murdoch at stats.uwo.ca  Fri Feb  3 00:29:39 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 02 Feb 2006 18:29:39 -0500
Subject: [R] How to get the namespace of a function?
In-Reply-To: <200602022256.k12Mui2W017683@volta.gene.com>
References: <200602022256.k12Mui2W017683@volta.gene.com>
Message-ID: <43E295E3.6030904@stats.uwo.ca>

On 2/2/2006 5:56 PM, Berton Gunter wrote:
> Just echoing and slightly amplifying Gabor's comment...
> 
> The semantics of R are really based on functional programming (LISP-like)
> rather than OOP (JAVA-like)? R's behavior is "proper" from that point of
> view; what is "improper" is Fernando's expectation that it should behave
> some other way.

I don't think it's that so much as trying not to break old code.  It 
doesn't make sense to me that the search order within a namespace should 
pass through the global environment, but something would break if it 
didn't.  (I suspect it's probably the old S3 object system, which 
predates namespaces by a long time, but it's been a while since I've 
thought about this.)

Duncan Murdoch


 > Of course, one can simulate anything with a Turing machine,
> but I consider Fernando's criticisms somewhat "unfair" because he is
> expecting R to behave like something he is familiar with rather than as it
> was designed to. For this reason, what bothers him seems wholly desirable to
> me -- I want there to be well-defined scoping convention (lexical scoping)
> for R to find free variables.
> 
> Cheers,
> 
> Bert
> 
> 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Duncan Murdoch
> Sent: Thursday, February 02, 2006 2:16 PM
> To: fsaldanha at alum.mit.edu
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] How to get the namespace of a function?
> 
> On 2/2/2006 5:05 PM, Fernando Saldanha wrote:
>> I am trying to imitate "encapsulation" from other languages like Java
>> or C++. Coming from that background, it bothers me that I can commit
>> errors like the following:
>>
>>> x <- 1
>>> f <- function(z) { y <- x; y + 1 } # Mistake: I should have written y <-
> z
>>> f(10)
>> [1] 2
>>
>> In a language like Java the interpreter would have noticed that x was
>> an undeclared variable and an error message would be issued. R, on the
>> other hand, allows the code to run, as x exists in the global
>> environment. I was trying to avoid such situations by  setting the
>> environment of f to be NULL. If there is a better way to catch this
>> type of errors I would be interested in knowing about it.
> 
> Put your code in a package, and use a namespace.  This isn't perfect, 
> but it gives you more control than you have when running scripts at the 
> console.
> 
> There's an article by Luke Tierney in one of R News 3/1 that explains 
> the search order when namespaces are involved.
> 
> Duncan Murdoch
>> FS
>>
>> On 2/2/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>> On 2/2/2006 10:56 AM, Fernando Saldanha wrote:
>>>> I declared the environment of the function myfun to be NULL as follows:
>>>>
>>>> environment(myfun) <- NULL
>>> Since version 2.1.0, it's been recommended that you use
>>>
>>> environment(myfun) <- baseenv()
>>>
>>> and since 2.2.0, you'll get a warning when using NULL (and you'll get an
>>> error in 2.3.0).  But why would you want to do that?  What are you
>>> trying to achieve?
>>>
>>> Duncan Murdoch
>>>
>>>
>>>> Later on I called that myfun and got an error message because the
>>>> function index() in the zoo package was called inside myfun and was
>>>> not visible:
>>>>
>>>> Error in myfun(args) : couldn't find function "index"
>>>>
>>>> I tried to use zoo::index() instead of index(), but that did not work.
>>>> In fact, zoo::index does not work even in the command line:
>>>>
>>>>> z<-ts(1:5)
>>>>> z
>>>> Time Series:
>>>> Start = 1
>>>> End = 5
>>>> Frequency = 1
>>>> [1] 1 2 3 4 5
>>>>> index(z)
>>>> [1] 1 2 3 4 5
>>>>> zoo::index(z)
>>>> Error in loadNamespace(name) : package 'zoo' does not have a name space
>>>>
>>>> How can I qualify index() so that it is visible inside the body of
> myfun?
>>>> Thanks for any suggestions,
>>>>
>>>> FS
>>>>
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From munguiar at posgrado.ecologia.edu.mx  Fri Feb  3 00:31:10 2006
From: munguiar at posgrado.ecologia.edu.mx (roberto munguia)
Date: Thu, 02 Feb 2006 17:31:10 -0600
Subject: [R] Canonical analysis
Message-ID: <43E2963E.2060000@posgrado.ecologia.edu.mx>

Hi,

I would like to know if someone has written a function to perform
canonical analysis, sensu (Box and Wilson 1951, Box and Draper 1987).
Searching the r-help list and the packages I have only found information
about canonical correlation analysis and canonical variate analysis.


Thanks a lot

Roberto

Box GEP and KB Wilson. 1951. On the experimental attainment of optimum
conditions. J. Roy. Stat. Soc. B 13:1-38.

Box GEP and NR Draper. 1987. Empirical Model-Building and Response
surfaces. Wiley, N.Y. pages 332-345.


-- 
Bi??l. Roberto Mungu??a Steyer
Instituto de Ecolog??a, A.C.
Dpto. Biolog??a Evolutiva
Xalapa, Veracruz
MEXICO
Tel 01 22 88 42 18 00 ext 3009
munguiar at posgrado.ecologia.edu.mx
robermunguia at gmail.com



From Q.Bui at ms.unimelb.edu.au  Fri Feb  3 01:55:46 2006
From: Q.Bui at ms.unimelb.edu.au (bui)
Date: Fri, 3 Feb 2006 11:55:46 +1100
Subject: [R] header intact
Message-ID: <0ccc584d9cd07c32ef45fe28b111a0b8@ms.unimelb.edu.au>



------------------------------------------------------------------------ 
-----------------------
Quang M Bui, Ph.D
Department of Mathematics & Statistics
The University of Melbourne
Victoria 3010 Australia

Ph (W): +61 3 8344 8862
Fax: +61 3 8344 4599
E-mail: Q.Bui at ms.unimelb.edu.au



From ggrothendieck at gmail.com  Fri Feb  3 02:12:40 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 2 Feb 2006 20:12:40 -0500
Subject: [R] How to get the namespace of a function?
In-Reply-To: <43E295E3.6030904@stats.uwo.ca>
References: <200602022256.k12Mui2W017683@volta.gene.com>
	<43E295E3.6030904@stats.uwo.ca>
Message-ID: <971536df0602021712w357c45d5n857daf1bd7c20c55@mail.gmail.com>

I think the issue in this case is the following aspect of UseMethod
from ?UseMethod:

    "'UseMethod' and 'NextMethod' search for methods in
     two places: first in the environment in which the generic function
     is called, and then in the registration data base for the
     environment in which the generic is defined"

Even if one is successful in calling a generic function such as index
from a function f with NULL environment UseMethod will look into
the environment within f (and not find it since its parent was set to
NULL) and since in this case the methods were not registered by the
package it does not find them in the package either.  This could have
worked somewhat more smoothly had the methods been registered.

On 2/2/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 2/2/2006 5:56 PM, Berton Gunter wrote:
> > Just echoing and slightly amplifying Gabor's comment...
> >
> > The semantics of R are really based on functional programming (LISP-like)
> > rather than OOP (JAVA-like)? R's behavior is "proper" from that point of
> > view; what is "improper" is Fernando's expectation that it should behave
> > some other way.
>
> I don't think it's that so much as trying not to break old code.  It
> doesn't make sense to me that the search order within a namespace should
> pass through the global environment, but something would break if it
> didn't.  (I suspect it's probably the old S3 object system, which
> predates namespaces by a long time, but it's been a while since I've
> thought about this.)
>
> Duncan Murdoch
>
>
>  > Of course, one can simulate anything with a Turing machine,
> > but I consider Fernando's criticisms somewhat "unfair" because he is
> > expecting R to behave like something he is familiar with rather than as it
> > was designed to. For this reason, what bothers him seems wholly desirable to
> > me -- I want there to be well-defined scoping convention (lexical scoping)
> > for R to find free variables.
> >
> > Cheers,
> >
> > Bert
> >
> >
> >
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Duncan Murdoch
> > Sent: Thursday, February 02, 2006 2:16 PM
> > To: fsaldanha at alum.mit.edu
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] How to get the namespace of a function?
> >
> > On 2/2/2006 5:05 PM, Fernando Saldanha wrote:
> >> I am trying to imitate "encapsulation" from other languages like Java
> >> or C++. Coming from that background, it bothers me that I can commit
> >> errors like the following:
> >>
> >>> x <- 1
> >>> f <- function(z) { y <- x; y + 1 } # Mistake: I should have written y <-
> > z
> >>> f(10)
> >> [1] 2
> >>
> >> In a language like Java the interpreter would have noticed that x was
> >> an undeclared variable and an error message would be issued. R, on the
> >> other hand, allows the code to run, as x exists in the global
> >> environment. I was trying to avoid such situations by  setting the
> >> environment of f to be NULL. If there is a better way to catch this
> >> type of errors I would be interested in knowing about it.
> >
> > Put your code in a package, and use a namespace.  This isn't perfect,
> > but it gives you more control than you have when running scripts at the
> > console.
> >
> > There's an article by Luke Tierney in one of R News 3/1 that explains
> > the search order when namespaces are involved.
> >
> > Duncan Murdoch
> >> FS
> >>
> >> On 2/2/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >>> On 2/2/2006 10:56 AM, Fernando Saldanha wrote:
> >>>> I declared the environment of the function myfun to be NULL as follows:
> >>>>
> >>>> environment(myfun) <- NULL
> >>> Since version 2.1.0, it's been recommended that you use
> >>>
> >>> environment(myfun) <- baseenv()
> >>>
> >>> and since 2.2.0, you'll get a warning when using NULL (and you'll get an
> >>> error in 2.3.0).  But why would you want to do that?  What are you
> >>> trying to achieve?
> >>>
> >>> Duncan Murdoch
> >>>
> >>>
> >>>> Later on I called that myfun and got an error message because the
> >>>> function index() in the zoo package was called inside myfun and was
> >>>> not visible:
> >>>>
> >>>> Error in myfun(args) : couldn't find function "index"
> >>>>
> >>>> I tried to use zoo::index() instead of index(), but that did not work.
> >>>> In fact, zoo::index does not work even in the command line:
> >>>>
> >>>>> z<-ts(1:5)
> >>>>> z
> >>>> Time Series:
> >>>> Start = 1
> >>>> End = 5
> >>>> Frequency = 1
> >>>> [1] 1 2 3 4 5
> >>>>> index(z)
> >>>> [1] 1 2 3 4 5
> >>>>> zoo::index(z)
> >>>> Error in loadNamespace(name) : package 'zoo' does not have a name space
> >>>>
> >>>> How can I qualify index() so that it is visible inside the body of
> > myfun?
> >>>> Thanks for any suggestions,
> >>>>
> >>>> FS
> >>>>
> >>>> ______________________________________________
> >>>> R-help at stat.math.ethz.ch mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From David.Duffy at qimr.edu.au  Fri Feb  3 02:33:32 2006
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Fri, 3 Feb 2006 11:33:32 +1000 (EST)
Subject: [R]  Mixed-effects models / heterogenous covariances
In-Reply-To: <mailman.9.1138791602.8328.r-help@stat.math.ethz.ch>
References: <mailman.9.1138791602.8328.r-help@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0602031130560.17579@orpheus.qimr.edu.au>

> Message: 24
> Date: Tue, 31 Jan 2006 18:22:52 +0000
> From: "Lutz Ph. Breitling" <lutz.breitling at gmail.com>
> Subject: [R] Mixed-effects models / heterogeneous covariances
> To: r-help at stat.math.ethz.ch
> Message-ID:
> 	<2e38a1c80601311022i2e1be92doa60b80b50b69eb0c at mail.gmail.com>
> Content-Type: text/plain; charset=ISO-8859-1
>
> Dear R-list,
>
> maybe someone can help me with the following mixed-effects models
> problem, as I am unable to figure it out with the 'nlme-bible'.
>
> I would like to fit (in R, obviously) a so-called animal model (google
> e. g. "Heritability and genetic constraints of life-history" by Pettay
> et al.) to estimate the variance component that is due to genetic
> effects. The covariances of the genetic random effects between
> observations are given by the different degrees of relatedness between
> the individuals examined. (I find it difficult to explain, but Pettay
> et al. describe it nicely in their methods section...)
>
> Is there any straight-forward way to fit such a model with R? I first
> thought I could handle it somehow with nlme's correlation structures,
> but these within-group structures are quite a different thing, right?
>
> Any suggestions would be highly appreciated-
> Lutz
>
> --
> Lutz Ph. Breitling
> University of Leeds/UK

lmekin and coxme in Terry Therneau's kinship package may help.

David Duffy.



From jfox at mcmaster.ca  Fri Feb  3 02:56:22 2006
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 2 Feb 2006 20:56:22 -0500
Subject: [R] is there a way to visualize 3D normal distributions?
In-Reply-To: <43E293FD.4040700@stats.uwo.ca>
Message-ID: <20060203015622.KHVN20927.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Duncan, Michael, and Ben,

The code to which I referred Michael works by deforming a sphere. Here's the
central function:

ellipsoid <- function(center=c(0, 0, 0), radius=1, shape=diag(3), n=30){
# adapted from the shapes3d demo in the rgl package
  degvec <- seq(0, 2*pi, length=n)
  ecoord2 <- function(p) c(cos(p[1])*sin(p[2]), sin(p[1])*sin(p[2]),
cos(p[2]))
  v <- t(apply(expand.grid(degvec,degvec), 1, ecoord2))
  v <- center + radius * t(v %*% chol(shape))
  v <- rbind(v, rep(1,ncol(v))) 
  e <- expand.grid(1:(n-1), 1:n)
  i1 <- apply(e, 1, function(z) z[1] + n*(z[2] - 1))
  i2 <- i1 + 1
  i3 <- (i1 + n - 1) %% n^2 + 1
  i4 <- (i2 + n - 1) %% n^2 + 1
  i <- rbind(i1, i2, i4, i3)
  qmesh3d(v, i)
  }

Here are the key lines from scatter3d() for the shape and radius (slightly
edited to remove the context):

	dfn <- 3
	dfd <- length(x) - 1
      radius <- sqrt(dfn * qf(level, dfn, dfd))
      ellips <- ellipsoid(center=c(mean(x), mean(y), mean(z)), 
            shape=cov(cbind(x,y,z)), radius=radius)
      shade3d(ellips, col=surface.col[1], alpha=0.1, lit=FALSE)
      wire3d(ellips, col=surface.col[1], lit=FALSE)

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Duncan Murdoch
> Sent: Thursday, February 02, 2006 6:22 PM
> To: Michael
> Cc: r-help at stat.math.ethz.ch; Ben Bolker
> Subject: Re: [R] is there a way to visualize 3D normal distributions?
> 
> On 2/2/2006 5:01 PM, Michael wrote:
> > shape3d only gives rigid sphere... not the free form 
> ellipsoid that I 
> > want...
> 
> ? If you run the demo, you'll see ellipsoids...
> 
> You just need to work out the appropriate transform to apply 
> to a sphere to get the ellipsoid you want.  I imagine 
> something like this:
> 
> sphere <- ellipsoid3d(2,2,2, qmesh=TRUE) ellipsoid <- 
> translate3d(rotate3d(sphere, matrix=chol(S)), xbar, ybar, zbar)
> 
> shade3d(ellipsoid)
> 
> is what you want, where S is the covariance matrix, and 
> xbar,ybar,zbar have the obvious meaning.  (rotate3d() is used 
> with a matrix that isn't a rotation matrix; it may not be 
> obvious that this is allowed, but it is.)
> 
> Duncan Murdoch
> 
> 
> > 
> > On 2/2/06, Ben Bolker <bolker at ufl.edu> wrote:
> >> Duncan Murdoch <murdoch <at> stats.uwo.ca> writes:
> >>
> >>> On 2/2/2006 3:39 AM, Michael wrote:
> >>>> Hi all,
> >>>>
> >>>> How do I visualize a contour of a tri-variate normal 
> distribution?
> >>>>
> >>>> I just like to see the ellipsoid very much. I hope there 
> is a easy 
> >>>> way
> >> or
> >>>> existing method in R.
> >>> The misc3d package includes a function for 3d contour plots; that 
> >>> should do what you want.
> >>>
> >>   is contour3d really necessary or could you just plot ellipsoids?
> >> (library(rgl); demo(shapes3d)) -- still a little bit of 
> figuring to 
> >> do, but this should get you most of the way there.
> >>
> >>   Ben Bolker
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list 
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide!
> >> http://www.R-project.org/posting-guide.html
> >>
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From DrJones at alum.MIT.edu  Fri Feb  3 03:20:09 2006
From: DrJones at alum.MIT.edu (Thomas L Jones)
Date: Thu, 2 Feb 2006 21:20:09 -0500
Subject: [R] (newbie) Saving the workspace in .txt format
Message-ID: <000301c62868$5bc70fc0$2f01a8c0@DrJones>

(newbie question) How do I save the workspace in Windows text format 
(with the file extension .txt)? Also, having saved it and edited it, 
how do I load it back into the workspace?

The setup is:

Windows XP Home Edition Service Pack 2
R 2.2.0
English language
Administrator privileges are enabled

Tom Jones, a veteran computer professional who is a newbie to R



From spencer.graves at pdf.com  Fri Feb  3 05:07:39 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 02 Feb 2006 20:07:39 -0800
Subject: [R] fExtreme packages
In-Reply-To: <1138637773.43de3bcd1cea8@webmail2.hut.fi>
References: <1138637773.43de3bcd1cea8@webmail2.hut.fi>
Message-ID: <43E2D70B.3030508@pdf.com>

Hello:

	  The problem is not you.  I just tried:

library(fBasics)
xmpfBasics()

	  I run R under XEmacs, and this command caused my version of XEmacs to 
hang.  After waiting 15 minutes, I was able to break out of it. 
However, I did not get the intended result.  This is tragically typical 
of my personal experience with Rmetrics packages.

	  The Rmetrics project is breathtaking in scope but deficient in 
execution.  I believe it works well for Prof. Diethelp Wuertz's classes 
at the Swiss Federal Institute of Technology, and he is to be commended 
for making it available for others.  Indeed, he has done a superhuman 
job with what he has created.  However, the Rmetrics packages would be 
much more useful if Prof. Wuertz could find a way to recruit a team of 
collaborators who would prioritize needed improvements and attack them 
as a team, in roughly the way the R Project itself is managed.  I 
sincerely hope that these comments are not interpreted as criticisms of 
Prof. Wuertz;  he certainly has accomplished more than I could have. 
Rather, I hope only to suggest a possible vision of potentially broader, 
more collaborative effort.

	  If you want to learn time series (and financial time series) in R, I 
will recommend to you the path that I have found most useful in my own 
stidy of time series capabilities in R:

	  1.  Read the chapter on time series in Venable and Ripley (2002) 
Modern Applied Statistics with S, 4th ed. (Springer).  This book is my 
primary reference for almost anything R other than "help", 
"help.search", "RSiteSearch" and the other free documentation.  The 
chapter on time series is an excellent introduction to basic R time 
series capabilities.

	  2.  I'd follow this by studying carefully the "R Help Desk" article 
on "Date and Time Classes in R" by Gabor Grothendieck and Thomas 
Petzoldt in R News, vol. 4/1, June 2004.

	  3.  Install the "zoo" package and work through the two "vignettes" 
associated therewith.  (Note:  The "vignette" documentation is a bit 
sparse.  If you work through the examples NOT using Emacs, you will find 
that you can create a "*.R" file containing the R commands in the 
vignette.  I've found this a very powerful way to learn.  For a way to 
do this with Emacs, try RSiteSearch for that.)

	  4.  Depending on your interests, you might follow this with the "dse" 
bundle.

	  5.  Subscribe to "R-sig-finance" if you don't already.  Questions 
like this might get a better reception from this specialized list. 
However, I don't have adequate experience to say that.  Thus, I would 
suggest persistence.  Some questions generate a genuine "feeding frenzy" 
of responses, while others never get answered.  To increase your chances 
of moving away from "unanswered" towards "feeding frenzy", I encourage 
you to follow the posting guide! "www.R-project.org/posting-guide.html". 
  Your question below suggests you may have already done so, but I felt 
obligated to repeat the suggestion nonetheless.  If you don't get an 
answer in 24 hours, feel free to post a similar question.  However, 
please reword your question to clarify and simplify the issue as much as 
possible.

	  6.  I'm currently trying to create a companion package for Ruey Tsay 
(2005) Analysis of Financial Time Series, 2nd ed. (Wiley).  I've found 
this book to be quite useful for study of financial time series, though 
not for study of R capabilities in that area.

	  7.  Finally, continue doing what you already are doing.  I think R 
has substantial capabilities for what you want, but they are not 
unfortunately well organized.

	  hope this helps.
	  spencer graves

morlanes at cc.hut.fi wrote:

>  
> Hello, 
>  
> I am a new user of R. I am trying to use the packages fBasics and fExtremes 
> when i am running the examples I get few error. Could someone tell me what is 
> happenig? Thank you beforehand. 
>  
> from Fbasics packages: 
>  
>  xmpfBasics() 
> Error in file(file, "r") : unable to open connection 
> In addition: Warning message: 
> cannot open file '/usr/lib/R/library/fBasics/demoIndex'  
>  
> 
>>source("fBasics-xmpTools") 
> 
> Error in file(file, "r", encoding = encoding) :  
> 	unable to open connection 
> In addition: Warning message: 
> cannot open file 'fBasics-xmpTools'  
>  
> from fExtremes: 
>  
>  data(danish) 
> xmpExtremes("\nStart: Simulate a GPD Distributed Sample > ") 
>  x = gpdSim(model = list(shape = 0.25, location = 0, scale = 1), n = 1000) 
> Error in rgpd(n = n, xi = model$shape, mu = model$location, beta = 
> model$scale) : unused argument(s) (mu ...) 
>  
>  fit = gpdFit(danish, threshold = 10, type = "mle") 
> 
>> par(mfrow = c(1, 1)) 
>> gpdtailPlot(fit, main = "Danish Fire: GPD Tail Estimate", col = 
> 
> "steelblue4")  
> Error in as.numeric(gpd.obj$upper.exceed) :  
> 	argument "gpd.obj" is missing, with no default
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From phawkins at connact.com  Thu Feb  2 23:50:30 2006
From: phawkins at connact.com (Patricia J. Hawkins)
Date: Thu, 02 Feb 2006 17:50:30 -0500
Subject: [R] Glossay of available R functions
In-Reply-To: <20060131143604.GA12731@psych.upenn.edu> (Jonathan Baron's
	message of "Tue, 31 Jan 2006 09:36:04 -0500")
References: <Pine.LNX.4.61.0601310801310.4916@gannet.stats>
	<001b01c62672$825d7d10$0e010a0a@headquarters>
	<20060131143604.GA12731@psych.upenn.edu>
Message-ID: <wky80tz87d.fsf@connact.com>

>>>>> "JB" == Jonathan Baron <baron at psych.upenn.edu> writes:

JB> In addition, the search page at
JB> http://finzi.psych.upenn.edu

JB> can search all functions of all CRAN packages.

JB> This is also available through

JB> RSiteSearch(string,restrict="functions").

Thank you all!  In fact, what I was looking for was just the glossary
of objects in the base package; the effective equivalent of the Python
Standard Library, or for C, Harbison & Steele's _C, A Reference Manual_.

I assume that's what the original poster wanted too, since he was
commenting that subset was new to him, though he did say "list of
functions in R".  I'd searched through everything _else_ in the help
system looking for such a glossary; I hadn't thought to look under
*Packages*, as those are, of course, add-ons.

So a comment such as "For an index of R basic objects, see the 'base'
package under *Packages*" on the help.start() index page would be
helpful.   Also perhaps a link from the Language Reference Manual,
since that's where I looked first.

By the way, in general the documentation and help facilities are
stellar.

-- 
Patricia J. Hawkins 
Hawkins Internet Applications 
www.hawkinsia.com



From ggrothendieck at gmail.com  Fri Feb  3 05:54:30 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 2 Feb 2006 23:54:30 -0500
Subject: [R] How to get the namespace of a function?
In-Reply-To: <971536df0602021712w357c45d5n857daf1bd7c20c55@mail.gmail.com>
References: <200602022256.k12Mui2W017683@volta.gene.com>
	<43E295E3.6030904@stats.uwo.ca>
	<971536df0602021712w357c45d5n857daf1bd7c20c55@mail.gmail.com>
Message-ID: <971536df0602022054j4acc3e09lf10975a97d2cf352@mail.gmail.com>

In thinking about this some more here is a slightly simpler
solution than my previous one:

library(zoo)
z <- ts(1:3)
f <- function(y) {
   index <- local(function(x) index(x), .GlobalEnv)
   index(y)
}
environment(f) <- baseenv()
f(z)


On 2/2/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> I think the issue in this case is the following aspect of UseMethod
> from ?UseMethod:
>
>    "'UseMethod' and 'NextMethod' search for methods in
>     two places: first in the environment in which the generic function
>     is called, and then in the registration data base for the
>     environment in which the generic is defined"
>
> Even if one is successful in calling a generic function such as index
> from a function f with NULL environment UseMethod will look into
> the environment within f (and not find it since its parent was set to
> NULL) and since in this case the methods were not registered by the
> package it does not find them in the package either.  This could have
> worked somewhat more smoothly had the methods been registered.
>
> On 2/2/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > On 2/2/2006 5:56 PM, Berton Gunter wrote:
> > > Just echoing and slightly amplifying Gabor's comment...
> > >
> > > The semantics of R are really based on functional programming (LISP-like)
> > > rather than OOP (JAVA-like)? R's behavior is "proper" from that point of
> > > view; what is "improper" is Fernando's expectation that it should behave
> > > some other way.
> >
> > I don't think it's that so much as trying not to break old code.  It
> > doesn't make sense to me that the search order within a namespace should
> > pass through the global environment, but something would break if it
> > didn't.  (I suspect it's probably the old S3 object system, which
> > predates namespaces by a long time, but it's been a while since I've
> > thought about this.)
> >
> > Duncan Murdoch
> >
> >
> >  > Of course, one can simulate anything with a Turing machine,
> > > but I consider Fernando's criticisms somewhat "unfair" because he is
> > > expecting R to behave like something he is familiar with rather than as it
> > > was designed to. For this reason, what bothers him seems wholly desirable to
> > > me -- I want there to be well-defined scoping convention (lexical scoping)
> > > for R to find free variables.
> > >
> > > Cheers,
> > >
> > > Bert
> > >
> > >
> > >
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Duncan Murdoch
> > > Sent: Thursday, February 02, 2006 2:16 PM
> > > To: fsaldanha at alum.mit.edu
> > > Cc: r-help at stat.math.ethz.ch
> > > Subject: Re: [R] How to get the namespace of a function?
> > >
> > > On 2/2/2006 5:05 PM, Fernando Saldanha wrote:
> > >> I am trying to imitate "encapsulation" from other languages like Java
> > >> or C++. Coming from that background, it bothers me that I can commit
> > >> errors like the following:
> > >>
> > >>> x <- 1
> > >>> f <- function(z) { y <- x; y + 1 } # Mistake: I should have written y <-
> > > z
> > >>> f(10)
> > >> [1] 2
> > >>
> > >> In a language like Java the interpreter would have noticed that x was
> > >> an undeclared variable and an error message would be issued. R, on the
> > >> other hand, allows the code to run, as x exists in the global
> > >> environment. I was trying to avoid such situations by  setting the
> > >> environment of f to be NULL. If there is a better way to catch this
> > >> type of errors I would be interested in knowing about it.
> > >
> > > Put your code in a package, and use a namespace.  This isn't perfect,
> > > but it gives you more control than you have when running scripts at the
> > > console.
> > >
> > > There's an article by Luke Tierney in one of R News 3/1 that explains
> > > the search order when namespaces are involved.
> > >
> > > Duncan Murdoch
> > >> FS
> > >>
> > >> On 2/2/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > >>> On 2/2/2006 10:56 AM, Fernando Saldanha wrote:
> > >>>> I declared the environment of the function myfun to be NULL as follows:
> > >>>>
> > >>>> environment(myfun) <- NULL
> > >>> Since version 2.1.0, it's been recommended that you use
> > >>>
> > >>> environment(myfun) <- baseenv()
> > >>>
> > >>> and since 2.2.0, you'll get a warning when using NULL (and you'll get an
> > >>> error in 2.3.0).  But why would you want to do that?  What are you
> > >>> trying to achieve?
> > >>>
> > >>> Duncan Murdoch
> > >>>
> > >>>
> > >>>> Later on I called that myfun and got an error message because the
> > >>>> function index() in the zoo package was called inside myfun and was
> > >>>> not visible:
> > >>>>
> > >>>> Error in myfun(args) : couldn't find function "index"
> > >>>>
> > >>>> I tried to use zoo::index() instead of index(), but that did not work.
> > >>>> In fact, zoo::index does not work even in the command line:
> > >>>>
> > >>>>> z<-ts(1:5)
> > >>>>> z
> > >>>> Time Series:
> > >>>> Start = 1
> > >>>> End = 5
> > >>>> Frequency = 1
> > >>>> [1] 1 2 3 4 5
> > >>>>> index(z)
> > >>>> [1] 1 2 3 4 5
> > >>>>> zoo::index(z)
> > >>>> Error in loadNamespace(name) : package 'zoo' does not have a name space
> > >>>>
> > >>>> How can I qualify index() so that it is visible inside the body of
> > > myfun?
> > >>>> Thanks for any suggestions,
> > >>>>
> > >>>> FS
> > >>>>
> > >>>> ______________________________________________
> > >>>> R-help at stat.math.ethz.ch mailing list
> > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>



From ripley at stats.ox.ac.uk  Fri Feb  3 08:11:42 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Feb 2006 07:11:42 +0000 (GMT)
Subject: [R] Glossay of available R functions
In-Reply-To: <wky80tz87d.fsf@connact.com>
References: <Pine.LNX.4.61.0601310801310.4916@gannet.stats>
	<001b01c62672$825d7d10$0e010a0a@headquarters>
	<20060131143604.GA12731@psych.upenn.edu>
	<wky80tz87d.fsf@connact.com>
Message-ID: <Pine.LNX.4.61.0602030701370.4544@gannet.stats>

On Thu, 2 Feb 2006, Patricia J. Hawkins wrote:

>>>>>> "JB" == Jonathan Baron <baron at psych.upenn.edu> writes:
>
> JB> In addition, the search page at
> JB> http://finzi.psych.upenn.edu
>
> JB> can search all functions of all CRAN packages.
>
> JB> This is also available through
>
> JB> RSiteSearch(string,restrict="functions").
>
> Thank you all!  In fact, what I was looking for was just the glossary
> of objects in the base package; the effective equivalent of the Python
> Standard Library, or for C, Harbison & Steele's _C, A Reference Manual_.

Those are misleading analogies (not least because C has an ISO standard 
giving all the functions/macros you can expect to find in C). It is like 
saying you want to know about libc and not libm, despite the latter being 
described in the ISO standard and in Harbison & Steele.

> I assume that's what the original poster wanted too, since he was

I would assume other people were able to express themselves accurately.

> commenting that subset was new to him, though he did say "list of
> functions in R".  I'd searched through everything _else_ in the help
> system looking for such a glossary; I hadn't thought to look under
> *Packages*, as those are, of course, add-ons.

`Of course' is incorrect here.  Everything in R is in a package.

> So a comment such as "For an index of R basic objects, see the 'base'
> package under *Packages*" on the help.start() index page would be
> helpful.

But (as I originally pointed out), that is not a correct interpretation of 
`basic'.  It might have been in R 1.8.0, but the 'base' package is now 
intended to support only some scripting operations (where speed is 
essential so it is minimal).  Unlike Python, R is not primarily a 
scripting language.

The analogue of the Python Standard Library is I think the standard 
packages.

>   Also perhaps a link from the Language Reference Manual,
> since that's where I looked first.
>
> By the way, in general the documentation and help facilities are
> stellar.
>
> -- 
> Patricia J. Hawkins
> Hawkins Internet Applications
> www.hawkinsia.com
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at gmail.com  Fri Feb  3 08:12:31 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 3 Feb 2006 02:12:31 -0500
Subject: [R] How to get the namespace of a function?
In-Reply-To: <971536df0602022054j4acc3e09lf10975a97d2cf352@mail.gmail.com>
References: <200602022256.k12Mui2W017683@volta.gene.com>
	<43E295E3.6030904@stats.uwo.ca>
	<971536df0602021712w357c45d5n857daf1bd7c20c55@mail.gmail.com>
	<971536df0602022054j4acc3e09lf10975a97d2cf352@mail.gmail.com>
Message-ID: <971536df0602022312w2b06d6c3i89c58ed3890380d4@mail.gmail.com>

And one further simplification:

library(zoo)
z <- ts(1:3)
f <- local(function(y) {
  index <- local(function(x) index(x), .GlobalEnv)
  index(y)
}, baseenv())
f(z)


On 2/2/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> In thinking about this some more here is a slightly simpler
> solution than my previous one:
>
> library(zoo)
> z <- ts(1:3)
> f <- function(y) {
>   index <- local(function(x) index(x), .GlobalEnv)
>   index(y)
> }
> environment(f) <- baseenv()
> f(z)
>
>
> On 2/2/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > I think the issue in this case is the following aspect of UseMethod
> > from ?UseMethod:
> >
> >    "'UseMethod' and 'NextMethod' search for methods in
> >     two places: first in the environment in which the generic function
> >     is called, and then in the registration data base for the
> >     environment in which the generic is defined"
> >
> > Even if one is successful in calling a generic function such as index
> > from a function f with NULL environment UseMethod will look into
> > the environment within f (and not find it since its parent was set to
> > NULL) and since in this case the methods were not registered by the
> > package it does not find them in the package either.  This could have
> > worked somewhat more smoothly had the methods been registered.
> >
> > On 2/2/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > > On 2/2/2006 5:56 PM, Berton Gunter wrote:
> > > > Just echoing and slightly amplifying Gabor's comment...
> > > >
> > > > The semantics of R are really based on functional programming (LISP-like)
> > > > rather than OOP (JAVA-like)? R's behavior is "proper" from that point of
> > > > view; what is "improper" is Fernando's expectation that it should behave
> > > > some other way.
> > >
> > > I don't think it's that so much as trying not to break old code.  It
> > > doesn't make sense to me that the search order within a namespace should
> > > pass through the global environment, but something would break if it
> > > didn't.  (I suspect it's probably the old S3 object system, which
> > > predates namespaces by a long time, but it's been a while since I've
> > > thought about this.)
> > >
> > > Duncan Murdoch
> > >
> > >
> > >  > Of course, one can simulate anything with a Turing machine,
> > > > but I consider Fernando's criticisms somewhat "unfair" because he is
> > > > expecting R to behave like something he is familiar with rather than as it
> > > > was designed to. For this reason, what bothers him seems wholly desirable to
> > > > me -- I want there to be well-defined scoping convention (lexical scoping)
> > > > for R to find free variables.
> > > >
> > > > Cheers,
> > > >
> > > > Bert
> > > >
> > > >
> > > >
> > > > -----Original Message-----
> > > > From: r-help-bounces at stat.math.ethz.ch
> > > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Duncan Murdoch
> > > > Sent: Thursday, February 02, 2006 2:16 PM
> > > > To: fsaldanha at alum.mit.edu
> > > > Cc: r-help at stat.math.ethz.ch
> > > > Subject: Re: [R] How to get the namespace of a function?
> > > >
> > > > On 2/2/2006 5:05 PM, Fernando Saldanha wrote:
> > > >> I am trying to imitate "encapsulation" from other languages like Java
> > > >> or C++. Coming from that background, it bothers me that I can commit
> > > >> errors like the following:
> > > >>
> > > >>> x <- 1
> > > >>> f <- function(z) { y <- x; y + 1 } # Mistake: I should have written y <-
> > > > z
> > > >>> f(10)
> > > >> [1] 2
> > > >>
> > > >> In a language like Java the interpreter would have noticed that x was
> > > >> an undeclared variable and an error message would be issued. R, on the
> > > >> other hand, allows the code to run, as x exists in the global
> > > >> environment. I was trying to avoid such situations by  setting the
> > > >> environment of f to be NULL. If there is a better way to catch this
> > > >> type of errors I would be interested in knowing about it.
> > > >
> > > > Put your code in a package, and use a namespace.  This isn't perfect,
> > > > but it gives you more control than you have when running scripts at the
> > > > console.
> > > >
> > > > There's an article by Luke Tierney in one of R News 3/1 that explains
> > > > the search order when namespaces are involved.
> > > >
> > > > Duncan Murdoch
> > > >> FS
> > > >>
> > > >> On 2/2/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > > >>> On 2/2/2006 10:56 AM, Fernando Saldanha wrote:
> > > >>>> I declared the environment of the function myfun to be NULL as follows:
> > > >>>>
> > > >>>> environment(myfun) <- NULL
> > > >>> Since version 2.1.0, it's been recommended that you use
> > > >>>
> > > >>> environment(myfun) <- baseenv()
> > > >>>
> > > >>> and since 2.2.0, you'll get a warning when using NULL (and you'll get an
> > > >>> error in 2.3.0).  But why would you want to do that?  What are you
> > > >>> trying to achieve?
> > > >>>
> > > >>> Duncan Murdoch
> > > >>>
> > > >>>
> > > >>>> Later on I called that myfun and got an error message because the
> > > >>>> function index() in the zoo package was called inside myfun and was
> > > >>>> not visible:
> > > >>>>
> > > >>>> Error in myfun(args) : couldn't find function "index"
> > > >>>>
> > > >>>> I tried to use zoo::index() instead of index(), but that did not work.
> > > >>>> In fact, zoo::index does not work even in the command line:
> > > >>>>
> > > >>>>> z<-ts(1:5)
> > > >>>>> z
> > > >>>> Time Series:
> > > >>>> Start = 1
> > > >>>> End = 5
> > > >>>> Frequency = 1
> > > >>>> [1] 1 2 3 4 5
> > > >>>>> index(z)
> > > >>>> [1] 1 2 3 4 5
> > > >>>>> zoo::index(z)
> > > >>>> Error in loadNamespace(name) : package 'zoo' does not have a name space
> > > >>>>
> > > >>>> How can I qualify index() so that it is visible inside the body of
> > > > myfun?
> > > >>>> Thanks for any suggestions,
> > > >>>>
> > > >>>> FS
> > > >>>>
> > > >>>> ______________________________________________
> > > >>>> R-help at stat.math.ethz.ch mailing list
> > > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>>> PLEASE do read the posting guide!
> > > > http://www.R-project.org/posting-guide.html
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide!
> > > > http://www.R-project.org/posting-guide.html
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > >
> >
>



From ripley at stats.ox.ac.uk  Fri Feb  3 08:30:11 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Feb 2006 07:30:11 +0000 (GMT)
Subject: [R] How to get the namespace of a function?
In-Reply-To: <10dee4690602021405g19656bcck162ed198804b6f10@mail.gmail.com>
References: <10dee4690602020756r199bd4fbh8fd5f688f0ad35ad@mail.gmail.com>
	<43E26EEB.5070606@stats.uwo.ca>
	<10dee4690602021405g19656bcck162ed198804b6f10@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0602030719560.4544@gannet.stats>

On Thu, 2 Feb 2006, Fernando Saldanha wrote:

> I am trying to imitate "encapsulation" from other languages like Java
> or C++. Coming from that background, it bothers me that I can commit
> errors like the following:
>
>> x <- 1
>> f <- function(z) { y <- x; y + 1 } # Mistake: I should have written y <- z
>> f(10)
> [1] 2
>
> In a language like Java the interpreter would have noticed that x was
> an undeclared variable and an error message would be issued. R, on the
> other hand, allows the code to run, as x exists in the global
> environment. I was trying to avoid such situations by  setting the
> environment of f to be NULL. If there is a better way to catch this
> type of errors I would be interested in knowing about it.

The codetools package.  See http://www.stat.uiowa.edu/~luke/R/codetools.

(They are not R errors, but the codetools package can tell you that 'x' is 
not necessarily in scope.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From srini_iyyer_bio at yahoo.com  Fri Feb  3 08:38:27 2006
From: srini_iyyer_bio at yahoo.com (Srinivas Iyyer)
Date: Thu, 2 Feb 2006 23:38:27 -0800 (PST)
Subject: [R] ERROR: compilation failed for package 'RdbiPgSQL'
In-Reply-To: <440230C3.1030609@gmail.com>
Message-ID: <20060203073827.12821.qmail@web34504.mail.mud.yahoo.com>

Dear Group, 
 I have been trying to connect postgres with R.  I
followed the instructions from :
http://grass.itc.it/statsgrass/r_and_dbms.html.

However, RdbiPgSQL fails to install and throws up
error. 

Could any one please help me where the things are
going wrong. 

I have attached the log, and the necessary files for
postgresql stuff. 

Sorry for long message.  Looking forward for some help
please. 

thanks
sri


>install.packages(contriburl="http://www.bioconductor.org/repository/devel/package/Source/",
"Rdbi")

**snip***
** building package indices ...
* DONE (Rdbi)

>
install.packages(contriburl="http://www.bioconductor.org/repository/devel/package/Source/",
"RdbiPgSQL")
trying URL
'http://www.bioconductor.org/repository/devel/package/Source//RdbiPgSQL_1.5.1.tar.gz'
Content type 'application/x-gzip' length 28297 bytes
opened URL
==================================================
downloaded 27Kb

* Installing *source* package 'RdbiPgSQL' ...
creating cache ./config.cache
updating cache ./config.cache
creating ./config.status
creating src/Makevars
** libs
gcc -I/usr/local/lib64/R/include -I/usr/local/include
-I/usr/local/include   -fPIC  -g -O2 -c PgSQL.c -o
PgSQL.o
PgSQL.c:10:22: libpq-fe.h: No such file or directory
In file included from PgSQL.c:11:
PgSQL.h:33: error: syntax error before '*' token
PgSQL.h: In function `fetchPgString':
PgSQL.h:37: error: `result' undeclared (first use in
this function)
PgSQL.h:37: error: (Each undeclared identifier is
reported only once
PgSQL.h:37: error: for each function it appears in.)
PgSQL.h:37: error: `row' undeclared (first use in this
function)
PgSQL.h:37: error: `col' undeclared (first use in this
function)
PgSQL.h:39: warning: assignment makes pointer from
integer without a cast
PgSQL.h: At top level:
PgSQL.h:46: error: syntax error before '*' token
PgSQL.h: In function `fetchPgInteger':
PgSQL.h:51: error: `result' undeclared (first use in
this function)
PgSQL.h:51: error: `row' undeclared (first use in this
function)
PgSQL.h:51: error: `col' undeclared (first use in this
function)
PgSQL.h:53: warning: assignment makes pointer from
integer without a cast
PgSQL.h: At top level:
PgSQL.h:64: error: syntax error before '*' token
PgSQL.h: In function `fetchPgDouble':
PgSQL.h:73: error: `result' undeclared (first use in
this function)
PgSQL.h:73: error: `row' undeclared (first use in this
function)
PgSQL.h:73: error: `col' undeclared (first use in this
function)
PgSQL.h:75: warning: assignment makes pointer from
integer without a cast
PgSQL.h: At top level:
PgSQL.h:86: error: syntax error before '*' token
PgSQL.h: In function `fetchPgLogical':
PgSQL.h:88: error: `result' undeclared (first use in
this function)
PgSQL.h:88: error: `row' undeclared (first use in this
function)
PgSQL.h:88: error: `col' undeclared (first use in this
function)
PgSQL.h:95: warning: passing arg 1 of `strlen' makes
pointer from integer without a cast
PgSQL.h:95: warning: cast to pointer from integer of
different size
PgSQL.h:95: warning: cast to pointer from integer of
different size
PgSQL.h:95: warning: passing arg 1 of
`__builtin_strcmp' makes pointer from integer without
a cast
PgSQL.h:95: warning: cast to pointer from integer of
different size
PgSQL.h:95: warning: cast to pointer from integer of
different size
PgSQL.h:95: warning: passing arg 1 of `strlen' makes
pointer from integer without a cast
PgSQL.h:95: warning: passing arg 1 of
`__builtin_strcmp' makes pointer from integer without
a cast
PgSQL.h:95: warning: cast to pointer from integer of
different size
PgSQL.h:95: warning: cast to pointer from integer of
different size
PgSQL.h:95: warning: cast to pointer from integer of
different size
PgSQL.h:95: warning: cast to pointer from integer of
different size
PgSQL.h:95: warning: cast to pointer from integer of
different size
PgSQL.h:95: warning: cast to pointer from integer of
different size
PgSQL.h:95: warning: passing arg 1 of
`__builtin_strcmp' makes pointer from integer without
a cast
PgSQL.h:95: warning: cast to pointer from integer of
different size
PgSQL.h:95: warning: passing arg 1 of
`__builtin_strcmp' makes pointer from integer without
a cast
PgSQL.c: In function `PgSQLcloseConnection':
PgSQL.c:20: error: `PGconn' undeclared (first use in
this function)
PgSQL.c:20: error: `conn' undeclared (first use in
this function)
PgSQL.c:20: error: syntax error before ')' token
PgSQL.c:21: error: `CONNECTION_OK' undeclared (first
use in this function)
PgSQL.c: In function `PgSQLconnect':
PgSQL.c:27: error: `PGconn' undeclared (first use in
this function)
PgSQL.c:27: error: `conn' undeclared (first use in
this function)
PgSQL.c: In function `PgSQLconnectionInfo':
PgSQL.c:51: error: `PGconn' undeclared (first use in
this function)
PgSQL.c:51: error: `conn' undeclared (first use in
this function)
PgSQL.c:51: error: syntax error before ')' token
PgSQL.c:59: warning: passing arg 1 of `mkString_safe'
makes pointer from integer without a cast
PgSQL.c:62: warning: passing arg 1 of `mkString_safe'
makes pointer from integer without a cast
PgSQL.c:65: warning: passing arg 1 of `mkString_safe'
makes pointer from integer without a cast
PgSQL.c:68: warning: passing arg 1 of `mkString_safe'
makes pointer from integer without a cast
PgSQL.c:71: warning: passing arg 1 of `mkString_safe'
makes pointer from integer without a cast
PgSQL.c:74: warning: passing arg 1 of `mkString_safe'
makes pointer from integer without a cast
PgSQL.c:77: warning: passing arg 1 of `mkString_safe'
makes pointer from integer without a cast
PgSQL.c:80: warning: passing arg 1 of `mkString_safe'
makes pointer from integer without a cast
PgSQL.c: In function `PgSQLclearResult':
PgSQL.c:104: error: `PGresult' undeclared (first use
in this function)
PgSQL.c:104: error: syntax error before ')' token
PgSQL.c: In function `PgSQLsendQuery':
PgSQL.c:111: error: `PGresult' undeclared (first use
in this function)
PgSQL.c:111: error: `result' undeclared (first use in
this function)
PgSQL.c:112: error: `PGconn' undeclared (first use in
this function)
PgSQL.c:112: error: `conn' undeclared (first use in
this function)
PgSQL.c:112: error: syntax error before ')' token
PgSQL.c:115: error: `CONNECTION_OK' undeclared (first
use in this function)
PgSQL.c: In function `PgSQLresultInfo':
PgSQL.c:141: error: `PGresult' undeclared (first use
in this function)
PgSQL.c:141: error: `result' undeclared (first use in
this function)
PgSQL.c:141: error: syntax error before ')' token
PgSQL.c:150: warning: passing arg 1 of `mkString_safe'
makes pointer from integer without a cast
PgSQL.c:153: warning: passing arg 1 of `mkString_safe'
makes pointer from integer without a cast
PgSQL.c:165: warning: passing arg 1 of `mkString_safe'
makes pointer from integer without a cast
PgSQL.c:168: warning: passing arg 1 of `mkString_safe'
makes pointer from integer without a cast
PgSQL.c: In function `PgSQLcolumnInfo':
PgSQL.c:182: error: `PGresult' undeclared (first use
in this function)
PgSQL.c:182: error: `result' undeclared (first use in
this function)
PgSQL.c:182: error: syntax error before ')' token
PgSQL.c:184: error: `PGRES_TUPLES_OK' undeclared
(first use in this function)
PgSQL.c:197: warning: passing arg 1 of `Rf_mkChar'
makes pointer from integer without a cast
PgSQL.c: In function `PgSQLgetResult':
PgSQL.c:227: error: `PGresult' undeclared (first use
in this function)
PgSQL.c:227: error: `result' undeclared (first use in
this function)
PgSQL.c:227: error: syntax error before ')' token
PgSQL.c:231: error: `PGRES_TUPLES_OK' undeclared
(first use in this function)
PgSQL.c:232: warning: passing arg 1 of `Rf_error'
makes pointer from integer without a cast
PgSQL.c:283: warning: passing arg 1 of `Rf_mkChar'
makes pointer from integer without a cast
make: *** [PgSQL.o] Error 1
ERROR: compilation failed for package 'RdbiPgSQL'
** Removing '/usr/local/lib64/R/library/RdbiPgSQL'

The downloaded packages are in
        /tmp/RtmpR27533/downloaded_packages
Warning message:
installation of package 'RdbiPgSQL' had non-zero exit
status in: install.packages(contriburl =
"http://www.bioconductor.org/repository/devel/package/Source/",



-->
 /var/lib/pgsql/
backups  data  initdb.i18n

-->
/usr/bin/psql
-->
/usr/bin/postgres

-->
/usr/share/pgsql/
contrib                 pg_hba.conf.sample     
postgres.bki            sql_features.txt
conversion_create.sql   pg_ident.conf.sample   
postgres.description    unknown.pltcl
information_schema.sql  pg_service.conf.sample 
postgresql.conf.sample
-->
psql lib files:
/usr/lib64/pgsql
ascii_and_mic.so     euc_kr_and_mic.so      ltree.so  
     refint.so          utf8_and_big5.so      
utf8_and_sjis.so
autoinc.so           euc_tw_and_big5.so    
misc_utils.so   rserv.so          
utf8_and_cyrillic.so   utf8_and_tcvn.so
btree_gist.so        fti.so                
moddatetime.so  rtree_gist.so      utf8_and_euc_cn.so 
   utf8_and_uhc.so
chkpass.so           fuzzystrmatch.so       noup.so   
     seg.so             utf8_and_euc_jp.so    
utf8_and_win1250.so
cube.so              insert_username.so     pending.so
     string_io.so       utf8_and_euc_kr.so    
utf8_and_win1256.so
cyrillic_and_mic.so  int_aggregate.so      
pgcrypto.so     tablefunc.so       utf8_and_euc_tw.so 
   utf8_and_win874.so
dblink.so            _int.so               
pgstattuple.so  timetravel.so      utf8_and_gb18030.so
dbsize.so            isbn_issn.so           plperl.so 
     tsearch2.so        utf8_and_gbk.so
earthdistance.so     latin2_and_win1250.so  plpgsql.so
     tsearch.so         utf8_and_iso8859_1.so
euc_cn_and_mic.so    latin_and_mic.so      
plpython.so     user_locks.so      utf8_and_iso8859.so
euc_jp_and_sjis.so   lo.so                  pltcl.so  
     utf8_and_ascii.so  utf8_and_johab.so





/usr/lib/libodbcpsql.so
/usr/lib/libodbcpsql.so.2
/usr/lib/libodbcpsql.so.1.0.0
/usr/lib/libodbcpsql.so.1
/usr/lib/libodbcpsql.so.2.0.0
/usr/lib64/libodbcpsql.so
/usr/lib64/libodbcpsql.so.2
/usr/lib64/libodbcpsql.so.1.0.0
/usr/lib64/libodbcpsql.so.1
/usr/lib64/libodbcpsql.so.2.0.0



From ripley at stats.ox.ac.uk  Fri Feb  3 08:41:36 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Feb 2006 07:41:36 +0000 (GMT)
Subject: [R] (newbie) Saving the workspace in .txt format
In-Reply-To: <000301c62868$5bc70fc0$2f01a8c0@DrJones>
References: <000301c62868$5bc70fc0$2f01a8c0@DrJones>
Message-ID: <Pine.LNX.4.61.0602030734360.4544@gannet.stats>

On Thu, 2 Feb 2006, Thomas L Jones wrote:

> (newbie question) How do I save the workspace in Windows text format
> (with the file extension .txt)? Also, having saved it and edited it,
> how do I load it back into the workspace?

`save' is a command in R, and it has a ascii argument.  So you could do
save.image("workspace.txt", ascii=TRUE) to save, and load("workspace.txt") 
to reload.

The underlying assumption seems to be that text format files are editable 
(by a human).  Lots of data formats are text files but have many rigid 
restrictions:  PDF is one example and R save formats are others.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From depire at inrets.fr  Fri Feb  3 09:11:42 2006
From: depire at inrets.fr (depire@inrets.fr)
Date: Fri, 03 Feb 2006 09:11:42 +0100
Subject: [R] Matrix variable in C code
In-Reply-To: <20060202174706.GI26788@rmki.kfki.hu>
References: <1138889502.43e2131e68fe9@webmail.inrets.fr>
	<20060202143246.GD24989@rmki.kfki.hu>
	<1138901267.43e24113d6de1@webmail.inrets.fr>
	<20060202174706.GI26788@rmki.kfki.hu>
Message-ID: <1138954302.43e3103ee7f27@webmail.inrets.fr>

Selon Gabor Csardi <csardi at rmki.kfki.hu>:

> On Thu, Feb 02, 2006 at 06:27:47PM +0100, depire at inrets.fr wrote:
> [...]
>
> The problem is that as.double drops the dim attribute:
> > b <- matrix( 1:4, 2, 2)
> > b
>      [,1] [,2]
> [1,]    1    3
> [2,]    2    4
> > as.double(b)
> [1] 1 2 3 4
> >
>
> You can try:
>
> > b <- matrix( 1:4, 2, 2)
> > d <- dim(b)
> > b <- as.double(b)
> > b
> [1] 1 2 3 4
> > dim(b) <- d
> > b
>      [,1] [,2]
> [1,]    1    3
> [2,]    2    4
>
> Another thing is that i cannot really see why the ZT parameter of the .Call
> should be a matrix anyway. It's just the vector (40 21 30 20). Or am i
> missing something?

Sorry, i made a mistake writing the small code, the correct one is the following
with the correct dim for ZT. But it doesn't work...

========================================
X<-c(4,2,3,2)
Z<-c(40,21,30,20)
dX<-c(2,1,1)

dyn.load("test.so")

Phi<-function(z,a,b)
{
        Phi<-z
}

VPEfron<-function(XType,ZType,dXType,G,c0,c1)
{
        ####################
        ZT<-matrix(0,3,2)
        ZT[1,1]<-Z[2]
        ZT[1,2]<-Z[4]
        ZT[2,1]<-Z[3]
        ZT[3,1]<-Z[1]
        ####################

        # A OPTIMISER
      VPCEfron<-function(f,XT,ZT,dXT,tailleS=length(XT))
      {
                f.check<-function(x) {
            x<-f(x)
            }

.Call("VPCEfron",body(f.check),as.double(XT),as.double(ZT),as.integer(dXT),as.integer(tailleS),new.env())
        }
GG<-function(z) G(z,c0,c1)

Vraisemblancepartielle<-VPCEfron(GG,XType,ZType,dXType)
}

resultat<-VPEfron(X,Z,dX,Phi,0,0)
==========================================

The new piece of code is between ###.

Thanks,

Alex



From petr.pikal at precheza.cz  Fri Feb  3 10:04:32 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 03 Feb 2006 10:04:32 +0100
Subject: [R] (newbie) Saving the workspace in .txt format
In-Reply-To: <Pine.LNX.4.61.0602030734360.4544@gannet.stats>
References: <000301c62868$5bc70fc0$2f01a8c0@DrJones>
Message-ID: <43E32AB0.26052.2AE274@localhost>

Hi

you can also try to look at

?savehistory

which enables you to save your latest commands to a file. Or use menu 
item save history. You can edit this saved file and you can use part 
of it or whole by loadhistory or just by copy/paste to R console.

HTH
Petr



On 3 Feb 2006 at 7:41, Prof Brian Ripley wrote:

Date sent:      	Fri, 3 Feb 2006 07:41:36 +0000 (GMT)
From:           	Prof Brian Ripley <ripley at stats.ox.ac.uk>
To:             	Thomas L Jones <DrJones at alum.mit.edu>
Copies to:      	R-project help <r-help at stat.math.ethz.ch>
Subject:        	Re: [R] (newbie) Saving the workspace in .txt format

> On Thu, 2 Feb 2006, Thomas L Jones wrote:
> 
> > (newbie question) How do I save the workspace in Windows text format
> > (with the file extension .txt)? Also, having saved it and edited it,
> > how do I load it back into the workspace?
> 
> `save' is a command in R, and it has a ascii argument.  So you could
> do save.image("workspace.txt", ascii=TRUE) to save, and
> load("workspace.txt") to reload.
> 
> The underlying assumption seems to be that text format files are
> editable (by a human).  Lots of data formats are text files but have
> many rigid restrictions:  PDF is one example and R save formats are
> others.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self) 1 South
> Parks Road,                     +44 1865 272866 (PA) Oxford OX1 3TG,
> UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From maechler at stat.math.ethz.ch  Fri Feb  3 10:10:19 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 3 Feb 2006 10:10:19 +0100
Subject: [R] RHOME
In-Reply-To: <1138916063.43e27adf6393b@webmail.iarc.fr>
References: <Pine.GSO.4.33.0602021358400.20430-100000@honoria.la.utexas.edu>
	<1138916063.43e27adf6393b@webmail.iarc.fr>
Message-ID: <17379.7675.195068.676026@stat.math.ethz.ch>

>>>>> "Martyn" == Martyn Plummer <plummer at iarc.fr>
>>>>>     on Thu, 02 Feb 2006 22:34:23 +0100 writes:

    Martyn> Quoting "Daniel A. Powers"
    Martyn> <dpowers at mail.la.utexas.edu>:
    >>  R-help --
    >> 
    >> I built R-2.2.1 in my own directory on a sun
    >> (solaris). Now I would like the sysadmin to move the
    >> contents to /usr/local/lib and place the binary in
    >> /usr/local/bin. No problem.  However, the RHOME variable
    >> defaults to the directory from which R was built so it is
    >> not usable by anyone but me or ROOT. I would like to
    >> avoid building this again if possible. Any ideas?
    >> 
    >> Thanks, Dan

    Martyn> R is designed to run from its build directory.  But
    Martyn> if your sysadmin installs it with "make install" (as
    Martyn> root), then the shell wrapper that is installed in
    Martyn> /usr/local/bin/R will have R_HOME pointing to the
    Martyn> right location (/usr/local/lib/R).  Literally moving
    Martyn> the build directory to another location is the wrong
    Martyn> thing to do.

well, but very easily fixable, and that's what Daniel is asking
for:

The default value of R_HOME is only set in exactly one place,
namely the 'R' shell script; editing that script - once after
the move - is really a piece o'cake.



From depire at inrets.fr  Fri Feb  3 11:45:24 2006
From: depire at inrets.fr (depire@inrets.fr)
Date: Fri, 03 Feb 2006 11:45:24 +0100
Subject: [R] Matrix variable in C code
In-Reply-To: <20060202174706.GI26788@rmki.kfki.hu>
References: <1138889502.43e2131e68fe9@webmail.inrets.fr>
	<20060202143246.GD24989@rmki.kfki.hu>
	<1138901267.43e24113d6de1@webmail.inrets.fr>
	<20060202174706.GI26788@rmki.kfki.hu>
Message-ID: <1138963524.43e33444c5c94@webmail.inrets.fr>

I correct a little my code, in R code, i use "as.matrix" for ZT, so i haven't
got "segment fault" but it seems that i transmit only the first colon and
because "ncol" gives "1" and not "2".

So what happen ?

Programs

==== R CODE - test.R =====
X<-c(4,2,3,2)
Z<-c(40,21,30,20)
dX<-c(2,1,1)

dyn.load("test.so")

Phi<-function(z,a,b)
{
	Phi<-z
}

VPEfron<-function(XType,ZType,dXType,G,c0,c1)
{
	####################
	ZT<-matrix(0,3,2)
	ZT[1,1]<-Z[2]
	ZT[1,2]<-Z[4]
	ZT[2,1]<-Z[3]
	ZT[3,1]<-Z[1]
	####################
	
	print(ZT)
	# A OPTIMISER
      VPCEfron<-function(f,XT,ZT,dXT,tailleS)
      {
		f.check<-function(x) {
            x<-f(x)
            }
     
.Call("VPCEfron",body(f.check),as.double(XT),as.matrix(ZT),as.integer(dXT),as.integer(tailleS),new.env())
	}

	GG<-function(z) G(z,c0,c1)

VPEfron<-VPCEfron(GG,XType,ZType,dXType,length(XType))
}

resultat<-VPEfron(X,Z,dX,Phi,0,0)
==== END R CODE ==========

==== C CODE of test.c ============
#include <R.h>
#include <Rdefines.h>
#include <Rinternals.h>

#define RMATRIX(m,i,j) (REAL(m)[ INTEGER(GET_DIM(m))[0]*(j)+(i) ])

SEXP mkans(double x)
{
	SEXP ans;
	PROTECT(ans = allocVector(REALSXP,1));
	REAL(ans)[0]=x;
	UNPROTECT(1);
	return ans;
}

SEXP VPCEfron(SEXP f, SEXP XR, SEXP ZR, SEXP DIR, SEXP tailleR, SEXP rho)
{
	double* X=REAL(XR);
	int* DI=INTEGER(DIR);
	int taille=INTEGER(tailleR)[0];
	int nligne=INTEGER(GET_DIM(ZR))[0];
	int ncol=INTEGER(GET_DIM(ZR))[1];

	printf("verifie taille: %d\n",taille);
	printf("verifie de X: %f - %f - %f - %f\n",X[0],X[1],X[2],X[3]);
	printf("verifie dX: %d %d %d\n",DI[0],DI[1],DI[2]);

	printf("verifie de Z\n");
	printf("%d %d\n",nligne,ncol);
	printf("%f %f\n",RMATRIX(ZR,0,0),RMATRIX(ZR,0,1));
	printf("%f %f\n",RMATRIX(ZR,1,0),RMATRIX(ZR,1,1));
	printf("%f %f\n",RMATRIX(ZR,2,0),RMATRIX(ZR,2,1));

	return mkans(0.0);
}
==== END CODE =====



From csardi at rmki.kfki.hu  Fri Feb  3 12:11:14 2006
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Fri, 3 Feb 2006 12:11:14 +0100
Subject: [R] Matrix variable in C code
In-Reply-To: <1138963524.43e33444c5c94@webmail.inrets.fr>
References: <1138889502.43e2131e68fe9@webmail.inrets.fr>
	<20060202143246.GD24989@rmki.kfki.hu>
	<1138901267.43e24113d6de1@webmail.inrets.fr>
	<20060202174706.GI26788@rmki.kfki.hu>
	<1138963524.43e33444c5c94@webmail.inrets.fr>
Message-ID: <20060203111114.GA26893@rmki.kfki.hu>

No idea, your code (now that you're not using as.double) kinda works for me.

> source("test.R")
     [,1] [,2]
[1,]   21   20
[2,]   30    0
[3,]   40    0
verifie taille: 4
verifie de X: 4.000000 - 2.000000 - 3.000000 - 2.000000
verifie dX: 2 1 1
verifie de Z
4 1
40.000000 0.000000
21.000000 0.000000
30.000000 0.000000
> 

The only thing is that your code is very messy (for me at least), and it's
true that you print the value of ZT and it is a 3x3 matrix, but if you print
its value just before the .Call it is just a vector of length 4. Then
as.matrix() creates a 4x1 matrix of this. 

Look at this simple R code, it works with your test.c file fine:

##########################
dyn.load("test.so")

f.check <- function(a) a
XT <- 1:4
ZT <- matrix( c(21,30,40,20,0,0), nr=3, nc=2)
dXT <- 1:3
tailleS <- 5

.Call("VPCEfron",body(f.check),as.double(XT),as.matrix(ZT),as.integer(dXT),
      as.integer(tailleS),new.env()) 
#########################      

Gabor

On Fri, Feb 03, 2006 at 11:45:24AM +0100, depire at inrets.fr wrote:
> I correct a little my code, in R code, i use "as.matrix" for ZT, so i haven't
> got "segment fault" but it seems that i transmit only the first colon and
> because "ncol" gives "1" and not "2".
> 
> So what happen ?
> 
> Programs
> 
> ==== R CODE - test.R =====
> X<-c(4,2,3,2)
> Z<-c(40,21,30,20)
> dX<-c(2,1,1)
> 
> dyn.load("test.so")
> 
> Phi<-function(z,a,b)
> {
> 	Phi<-z
> }
> 
> VPEfron<-function(XType,ZType,dXType,G,c0,c1)
> {
> 	####################
> 	ZT<-matrix(0,3,2)
> 	ZT[1,1]<-Z[2]
> 	ZT[1,2]<-Z[4]
> 	ZT[2,1]<-Z[3]
> 	ZT[3,1]<-Z[1]
> 	####################
> 	
> 	print(ZT)
> 	# A OPTIMISER
>       VPCEfron<-function(f,XT,ZT,dXT,tailleS)
>       {
> 		f.check<-function(x) {
>             x<-f(x)
>             }
>      
> .Call("VPCEfron",body(f.check),as.double(XT),as.matrix(ZT),as.integer(dXT),as.integer(tailleS),new.env())
> 	}
> 
> 	GG<-function(z) G(z,c0,c1)
> 
> VPEfron<-VPCEfron(GG,XType,ZType,dXType,length(XType))
> }
> 
> resultat<-VPEfron(X,Z,dX,Phi,0,0)
> ==== END R CODE ==========
> 
> ==== C CODE of test.c ============
> #include <R.h>
> #include <Rdefines.h>
> #include <Rinternals.h>
> 
> #define RMATRIX(m,i,j) (REAL(m)[ INTEGER(GET_DIM(m))[0]*(j)+(i) ])
> 
> SEXP mkans(double x)
> {
> 	SEXP ans;
> 	PROTECT(ans = allocVector(REALSXP,1));
> 	REAL(ans)[0]=x;
> 	UNPROTECT(1);
> 	return ans;
> }
> 
> SEXP VPCEfron(SEXP f, SEXP XR, SEXP ZR, SEXP DIR, SEXP tailleR, SEXP rho)
> {
> 	double* X=REAL(XR);
> 	int* DI=INTEGER(DIR);
> 	int taille=INTEGER(tailleR)[0];
> 	int nligne=INTEGER(GET_DIM(ZR))[0];
> 	int ncol=INTEGER(GET_DIM(ZR))[1];
> 
> 	printf("verifie taille: %d\n",taille);
> 	printf("verifie de X: %f - %f - %f - %f\n",X[0],X[1],X[2],X[3]);
> 	printf("verifie dX: %d %d %d\n",DI[0],DI[1],DI[2]);
> 
> 	printf("verifie de Z\n");
> 	printf("%d %d\n",nligne,ncol);
> 	printf("%f %f\n",RMATRIX(ZR,0,0),RMATRIX(ZR,0,1));
> 	printf("%f %f\n",RMATRIX(ZR,1,0),RMATRIX(ZR,1,1));
> 	printf("%f %f\n",RMATRIX(ZR,2,0),RMATRIX(ZR,2,1));
> 
> 	return mkans(0.0);
> }
> ==== END CODE =====
> 
> ----------------------------------------------------------------
> This message was sent using IMP, the Internet Messaging Program.

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK



From pensterfuzzer at yahoo.de  Fri Feb  3 12:55:48 2006
From: pensterfuzzer at yahoo.de (Werner Wernersen)
Date: Fri, 3 Feb 2006 12:55:48 +0100 (CET)
Subject: [R] Accessing row names
Message-ID: <20060203115548.2943.qmail@web25811.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060203/470cfc5e/attachment.pl

From andywongcw at gmail.com  Fri Feb  3 13:24:00 2006
From: andywongcw at gmail.com (Andy Wong)
Date: Fri, 3 Feb 2006 20:24:00 +0800
Subject: [R] Application of R
Message-ID: <cafcabf80602030424r423565e4j4702049b2a6b8139@mail.gmail.com>

Could somebody gives me some advice what is the problem of my analysis as
per attached printed file showing the steps of the input and the error
occured.  I have also attached my data file in Excel file format for your
reference.

Thanks.

Andy
-------------- next part --------------
A non-text attachment was scrubbed...
Name: result.pdf
Type: application/pdf
Size: 29819 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20060203/8c1e4047/result.pdf

From petr.pikal at precheza.cz  Fri Feb  3 13:51:05 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 03 Feb 2006 13:51:05 +0100
Subject: [R] Application of R
In-Reply-To: <cafcabf80602030424r423565e4j4702049b2a6b8139@mail.gmail.com>
Message-ID: <43E35FC9.20080.FA57F3@localhost>

Hi

I do not know anything about mnp but the variables in your data frame 
has names V1:V23 and you request mnp to use variables x1..., y1..., 
and z1.... Unless you have them somewhere, where do you suppose mnp 
to know about them?

Try to read some basic text about data structures and manipulation 
with them e.g. R-intro.pdf which is probably in doc directory.

HTH
Petr


On 3 Feb 2006 at 20:24, Andy Wong wrote:

Date sent:      	Fri, 3 Feb 2006 20:24:00 +0800
From:           	Andy Wong <andywongcw at gmail.com>
To:             	r-help at stat.math.ethz.ch
Subject:        	[R] Application of R

> Could somebody gives me some advice what is the problem of my analysis
> as per attached printed file showing the steps of the input and the
> error occured.  I have also attached my data file in Excel file format
> for your reference.
> 
> Thanks.
> 
> Andy
> 

Petr Pikal
petr.pikal at precheza.cz



From Xiao.Zhao at newcastle.ac.uk  Fri Feb  3 14:07:30 2006
From: Xiao.Zhao at newcastle.ac.uk (Xiao Zhao)
Date: Fri, 3 Feb 2006 13:07:30 -0000
Subject: [R] question
Message-ID: <4165CF7A7F12DE4B96622CCBB905864705078582@largo.campus.ncl.ac.uk>

Hello,
I am a research student and I am using R to access my research. I want
to know how to multiple plot , such as for the exponetial distribution,
if I give the covariate different value, how to plot these in the same
figure,
And also I want to add the density plot in the histogramm.
How to do these?
Thank u in advance
nessie



From p.dalgaard at biostat.ku.dk  Fri Feb  3 14:08:25 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 Feb 2006 14:08:25 +0100
Subject: [R] How to get the namespace of a function?
In-Reply-To: <Pine.LNX.4.61.0602030719560.4544@gannet.stats>
References: <10dee4690602020756r199bd4fbh8fd5f688f0ad35ad@mail.gmail.com>
	<43E26EEB.5070606@stats.uwo.ca>
	<10dee4690602021405g19656bcck162ed198804b6f10@mail.gmail.com>
	<Pine.LNX.4.61.0602030719560.4544@gannet.stats>
Message-ID: <x23bj0wpx2.fsf@viggo.kubism.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> On Thu, 2 Feb 2006, Fernando Saldanha wrote:
> 
> > I am trying to imitate "encapsulation" from other languages like Java
> > or C++. Coming from that background, it bothers me that I can commit
> > errors like the following:
> >
> >> x <- 1
> >> f <- function(z) { y <- x; y + 1 } # Mistake: I should have written y <- z
> >> f(10)
> > [1] 2
> >
> > In a language like Java the interpreter would have noticed that x was
> > an undeclared variable and an error message would be issued. R, on the
> > other hand, allows the code to run, as x exists in the global
> > environment. I was trying to avoid such situations by  setting the
> > environment of f to be NULL. If there is a better way to catch this
> > type of errors I would be interested in knowing about it.
> 
> The codetools package.  See http://www.stat.uiowa.edu/~luke/R/codetools.
> 
> (They are not R errors, but the codetools package can tell you that 'x' is 
> not necessarily in scope.)

Yep, and nor is "<-", "+", and "{"... 

(Does codetools actually check those? Probably not, but it goes to
show why full encapsulation is hard or impossible to achieve in a
language where "everything", including functions and operators, are
objects.)

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From luke at stat.uiowa.edu  Fri Feb  3 14:09:20 2006
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Fri, 3 Feb 2006 07:09:20 -0600 (CST)
Subject: [R] How to get the namespace of a function?
In-Reply-To: <43E295E3.6030904@stats.uwo.ca>
References: <200602022256.k12Mui2W017683@volta.gene.com>
	<43E295E3.6030904@stats.uwo.ca>
Message-ID: <Pine.LNX.4.63.0602030704240.17891@itasca2.wildberry.org>

On Thu, 2 Feb 2006, Duncan Murdoch wrote:

> On 2/2/2006 5:56 PM, Berton Gunter wrote:
>> Just echoing and slightly amplifying Gabor's comment...
>>
>> The semantics of R are really based on functional programming (LISP-like)
>> rather than OOP (JAVA-like)? R's behavior is "proper" from that point of
>> view; what is "improper" is Fernando's expectation that it should behave
>> some other way.
>
> I don't think it's that so much as trying not to break old code.  It
> doesn't make sense to me that the search order within a namespace should
> pass through the global environment, but something would break if it
> didn't.  (I suspect it's probably the old S3 object system, which
> predates namespaces by a long time, but it's been a while since I've
> thought about this.)

S3 dispatch was the primary reason for this design.  At some point we
may be able to revisit this but probably not very soon.

Once code analysis becomes a standard part of R, either via byte code
compilation or as bart of R CMD check, there should be warnings issued
automatically for this sort of thing.  For now manually using the
codetools ackage Brian pointed to is one option.

Best,

luke

>
> Duncan Murdoch
>
>
> > Of course, one can simulate anything with a Turing machine,
>> but I consider Fernando's criticisms somewhat "unfair" because he is
>> expecting R to behave like something he is familiar with rather than as it
>> was designed to. For this reason, what bothers him seems wholly desirable to
>> me -- I want there to be well-defined scoping convention (lexical scoping)
>> for R to find free variables.
>>
>> Cheers,
>>
>> Bert
>>
>>
>>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Duncan Murdoch
>> Sent: Thursday, February 02, 2006 2:16 PM
>> To: fsaldanha at alum.mit.edu
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] How to get the namespace of a function?
>>
>> On 2/2/2006 5:05 PM, Fernando Saldanha wrote:
>>> I am trying to imitate "encapsulation" from other languages like Java
>>> or C++. Coming from that background, it bothers me that I can commit
>>> errors like the following:
>>>
>>>> x <- 1
>>>> f <- function(z) { y <- x; y + 1 } # Mistake: I should have written y <-
>> z
>>>> f(10)
>>> [1] 2
>>>
>>> In a language like Java the interpreter would have noticed that x was
>>> an undeclared variable and an error message would be issued. R, on the
>>> other hand, allows the code to run, as x exists in the global
>>> environment. I was trying to avoid such situations by  setting the
>>> environment of f to be NULL. If there is a better way to catch this
>>> type of errors I would be interested in knowing about it.
>>
>> Put your code in a package, and use a namespace.  This isn't perfect,
>> but it gives you more control than you have when running scripts at the
>> console.
>>
>> There's an article by Luke Tierney in one of R News 3/1 that explains
>> the search order when namespaces are involved.
>>
>> Duncan Murdoch
>>> FS
>>>
>>> On 2/2/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>> On 2/2/2006 10:56 AM, Fernando Saldanha wrote:
>>>>> I declared the environment of the function myfun to be NULL as follows:
>>>>>
>>>>> environment(myfun) <- NULL
>>>> Since version 2.1.0, it's been recommended that you use
>>>>
>>>> environment(myfun) <- baseenv()
>>>>
>>>> and since 2.2.0, you'll get a warning when using NULL (and you'll get an
>>>> error in 2.3.0).  But why would you want to do that?  What are you
>>>> trying to achieve?
>>>>
>>>> Duncan Murdoch
>>>>
>>>>
>>>>> Later on I called that myfun and got an error message because the
>>>>> function index() in the zoo package was called inside myfun and was
>>>>> not visible:
>>>>>
>>>>> Error in myfun(args) : couldn't find function "index"
>>>>>
>>>>> I tried to use zoo::index() instead of index(), but that did not work.
>>>>> In fact, zoo::index does not work even in the command line:
>>>>>
>>>>>> z<-ts(1:5)
>>>>>> z
>>>>> Time Series:
>>>>> Start = 1
>>>>> End = 5
>>>>> Frequency = 1
>>>>> [1] 1 2 3 4 5
>>>>>> index(z)
>>>>> [1] 1 2 3 4 5
>>>>>> zoo::index(z)
>>>>> Error in loadNamespace(name) : package 'zoo' does not have a name space
>>>>>
>>>>> How can I qualify index() so that it is visible inside the body of
>> myfun?
>>>>> Thanks for any suggestions,
>>>>>
>>>>> FS
>>>>>
>>>>> ______________________________________________
>>>>> R-help at stat.math.ethz.ch mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From mike_saunders at umenfa.maine.edu  Fri Feb  3 14:30:28 2006
From: mike_saunders at umenfa.maine.edu (Mike Saunders)
Date: Fri, 3 Feb 2006 08:30:28 -0500
Subject: [R] SVS tree lists
Message-ID: <000601c628c5$ffaf8880$b5a76f82@CFRU0204>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060203/7e8e22c3/attachment.pl

From csardi at rmki.kfki.hu  Fri Feb  3 14:34:02 2006
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Fri, 3 Feb 2006 14:34:02 +0100
Subject: [R] question
In-Reply-To: <4165CF7A7F12DE4B96622CCBB905864705078582@largo.campus.ncl.ac.uk>
References: <4165CF7A7F12DE4B96622CCBB905864705078582@largo.campus.ncl.ac.uk>
Message-ID: <20060203133402.GA3146@rmki.kfki.hu>

> x <- seq(0, 10, by=.1)
> plot(x,pexp(x, rate=1))
> points(x,pexp(x, rate=2), pch=2, col="blue")

See help(plot), help(points), help(lines).

Gabor

On Fri, Feb 03, 2006 at 01:07:30PM -0000, Xiao Zhao wrote:
> Hello,
> I am a research student and I am using R to access my research. I want
> to know how to multiple plot , such as for the exponetial distribution,
> if I give the covariate different value, how to plot these in the same
> figure,
> And also I want to add the density plot in the histogramm.
> How to do these?
> Thank u in advance
> nessie
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK



From p.dalgaard at biostat.ku.dk  Fri Feb  3 14:48:59 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 Feb 2006 14:48:59 +0100
Subject: [R] RHOME
In-Reply-To: <17379.7675.195068.676026@stat.math.ethz.ch>
References: <Pine.GSO.4.33.0602021358400.20430-100000@honoria.la.utexas.edu>
	<1138916063.43e27adf6393b@webmail.iarc.fr>
	<17379.7675.195068.676026@stat.math.ethz.ch>
Message-ID: <x2y80sv9h0.fsf@viggo.kubism.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

>     Martyn> R is designed to run from its build directory.  But
>     Martyn> if your sysadmin installs it with "make install" (as
>     Martyn> root), then the shell wrapper that is installed in
>     Martyn> /usr/local/bin/R will have R_HOME pointing to the
>     Martyn> right location (/usr/local/lib/R).  Literally moving
>     Martyn> the build directory to another location is the wrong
>     Martyn> thing to do.
> 
> well, but very easily fixable, and that's what Daniel is asking
> for:
> 
> The default value of R_HOME is only set in exactly one place,
> namely the 'R' shell script; editing that script - once after
> the move - is really a piece o'cake.

Hmm, I was about to say the same, but there seems to be unexpected
references in other places.

find `R RHOME` | xargs grep `R RHOME`
/usr/lib64/R/bin/R:R_HOME_DIR=/usr/lib64/R
/usr/lib64/R/bin/R:R_SHARE_DIR=/usr/lib64/R/share
/usr/lib64/R/bin/R:R_INCLUDE_DIR=/usr/lib64/R/include
/usr/lib64/R/bin/R:R_DOC_DIR=/usr/lib64/R/doc

(this doesn't normally happen - a SUSE RPM specialty, or due to
configure flag settings?)


Once you start building packages, you also have things like

viggo:~/>find ~/Rlibrary | xargs grep `R RHOME`
Binary file /home/bs/pd/Rlibrary/rgl/libs/rgl.so matches


viggo:~/>find ~/Rlibrary | xargs grep Rlibrary
Binary file /home/bs/pd/Rlibrary/rgl/Meta/hsearch.rds matches
Binary file /home/bs/pd/Rlibrary/ISwR/Meta/hsearch.rds matches
Binary file /home/bs/pd/Rlibrary/mvtnorm/Meta/hsearch.rds matches
Binary file /home/bs/pd/Rlibrary/nlmeODE/Meta/hsearch.rds matches
B.....

on my laptop I had a hit on one of the Sweave support files too.

Most likely these are quite harmless, but all in all I think Martyn
has the safest advice: Use "make install", as root (don't forget
"umask 022").

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From mathematician4 at hotmail.com  Fri Feb  3 15:36:43 2006
From: mathematician4 at hotmail.com (Emanuele Mazzola)
Date: Fri, 03 Feb 2006 14:36:43 +0000
Subject: [R] Problems with ks.test
Message-ID: <BAY107-F334CDB4C6630F935B1F34C9A0D0@phx.gbl>

Hi everybody,

while performing ks.test for a standard exponential distribution on samples 
of dimension 2500, generated everytime as new, i had this strange behaviour:

>data<-rexp(2500,0.4)
>ks.test(data,"pexp",0.4)

	One-sample Kolmogorov-Smirnov test

data:  data
D = 0.0147, p-value = 0.6549
alternative hypothesis: two.sided

>data<-rexp(2500,0.4)
>ks.test(data,"pexp",0.4)

	One-sample Kolmogorov-Smirnov test

data:  data
D = 0.019, p-value = 0.3305
alternative hypothesis: two.sided

>data<-rexp(2500,0.4)
>ks.test(data,"pexp",0.4)

	One-sample Kolmogorov-Smirnov test

data:  data
D = 0.0171, p-value = 0.4580
alternative hypothesis: two.sided

>data<-rexp(2500,0.4)
>ks.test(data,"pexp",0.4)

	One-sample Kolmogorov-Smirnov test

data:  data
D = 0.0143, p-value = 0.6841
alternative hypothesis: two.sided

>data<-rexp(2500,0.4)
>ks.test(data,"pexp",0.4)

	One-sample Kolmogorov-Smirnov test

data:  data
D = 0.0145, p-value = 0.6684
alternative hypothesis: two.sided

>data<-rexp(2500,0.4)
>ks.test(data,"pexp",0.4)

	One-sample Kolmogorov-Smirnov test

data:  data
D = 0.0123, p-value = 0.8435
alternative hypothesis: two.sided

>data<-rexp(2500,0.4)
>ks.test(data,"pexp",0.4)

	One-sample Kolmogorov-Smirnov test

data:  data
D = 0.0186, p-value = 0.3532
alternative hypothesis: two.sided


It seems kind of strange to me that max p-value obtained is 0.8435 and all 
the best i can have from the rest is a 0.66-0.68.
I'm probably not so expert in running this kind of test, but am I doing 
something wrong?
I would expect p values ranging from 0.75 (to be kind) to 0.9, 0.95. How is 
this possible?

Thank you in advance for your answers.
See you soon
EM



From pmilin at ff.ns.ac.yu  Fri Feb  3 16:03:10 2006
From: pmilin at ff.ns.ac.yu (Petar Milin)
Date: Fri, 03 Feb 2006 16:03:10 +0100
Subject: [R] How to decide between two theoretical distributions?
Message-ID: <1138978990.9536.10.camel@localhost.localdomain>

Question that I have to ask has two parts: first, related to statistics,
in principle, and second, related to R-how-to, in particular.
In very brief, I have collected pretty solid sample for a phenomenon
that has two possible interpretation of how it is distributed in the
population; for example, beta and gamma distributed.
How it can be tested which model (theoretical distribution) suits better
actual data? Except some vague idea that bootstrapping or jackknifing
could be used, I have no further thoughts on that matter.
Could it be tested in R and how?

Sincerely,
Petar Milin



From pmilin at gmail.com  Fri Feb  3 16:11:22 2006
From: pmilin at gmail.com (Petar Milin)
Date: Fri, 03 Feb 2006 16:11:22 +0100
Subject: [R] How to decide between two theoretical distributions?
Message-ID: <1138979482.9536.11.camel@localhost.localdomain>

Question that I have to ask has two parts: first, related to statistics,
in principle, and second, related to R-how-to, in particular.
In very brief, I have collected pretty solid sample for a phenomenon
that has two possible interpretation of how it is distributed in the
population; for example, beta and gamma distributed.
How it can be tested which model (theoretical distribution) suits better
actual data? Except some vague idea that bootstrapping or jackknifing
could be used, I have no further thoughts on that matter.
Could it be tested in R and how?

Sincerely,
Petar Milin



From dmbates at gmail.com  Fri Feb  3 16:15:54 2006
From: dmbates at gmail.com (Douglas Bates)
Date: Fri, 3 Feb 2006 09:15:54 -0600
Subject: [R] Matrix variable in C code
In-Reply-To: <1138901267.43e24113d6de1@webmail.inrets.fr>
References: <1138889502.43e2131e68fe9@webmail.inrets.fr>
	<20060202143246.GD24989@rmki.kfki.hu>
	<1138901267.43e24113d6de1@webmail.inrets.fr>
Message-ID: <40e66e0b0602030715n15d1e09cp1fa011d08ab59fd7@mail.gmail.com>

On 2/2/06, depire at inrets.fr <depire at inrets.fr> wrote:
> Selon Gabor Csardi <csardi at rmki.kfki.hu>:
>
> > On Thu, Feb 02, 2006 at 03:11:42PM +0100, depire at inrets.fr wrote:
> > [...]
> > >
> > > and my test code in C is:
> > > ================================================
> > > SEXP VPCEfron(SEXP f, SEXP SR, SEXP ZR, SEXP DIR, SEXP nsR, SEXP rho)
> > > {
> > >     int taille=INTEGER(nsR)[0];
> > [...]
> > >
> > > All works, except ZS, the variable ZS is a matrix in R, and when i try to
> > give
> > > to C code, with ZR, ZR is only a vector.
> > >
> > > How to obtain a matrix variable in C ?
> >
> > A matrix is the same as a vector (stored columnwise), except that is has a
> > dim attribute. Use can use SET_DIM to set the dim attribute, and GET_dim to
> > query it. Eg:
> >
> > int nrow=INTEGER(GET_DIM(ZR))[0];
> > int ncol=INTEGER(GET_DIM(ZR))[1];
> >
> > To access the values in the matrix you might use something like:
> >
> > #define RMATRIX(m,i,j) (REAL(m)[ INTEGER(GET_DIM(m))[0]*(j)+(i) ])
> >
> > and then
> >
> > RMATRIX(ZR, 0, 1), etc. works. Note that according to this #define the
> > matrix
> > is indexed from zero.
> >
> > Gabor
> >
> >
> > --
> > Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
>
> I try but i think that i make some mistake because i obtain segment fault.
> To be sure, i reduce the code to permit to test it, the goal is just to print
> the variable, i try with vector variables (real X and integer dX in the
> following), it works; but with matrix it doesn't work.
>
> The code of the R program - Test.R
> =====================================
> X<-c(4,2,3,2)
> Z<-c(40,21,30,20)
> dX<-c(2,1,1)
>
> dyn.load("test.so")
>
> Phi<-function(z,a,b)
> {
>         Phi<-z
> }
>
> VPEfron<-function(XType,ZType,dXType,G,c0,c1)
> {
>         # A OPTIMISER
>       VPCEfron<-function(f,XT,ZT,dXT,tailleS=length(XT))
>       {
>                 f.check<-function(x) {
>             x<-f(x)
>             }
>
> .Call("VPCEfron",body(f.check),as.double(XT),as.double(ZT),as.integer(dXT),as.integer(tailleS),new.env())
>         }
> GG<-function(z) G(z,c0,c1)
>
> Vraisemblancepartielle<-VPCEfron(GG,XType,ZType,dXType)
> }
>
> resultat<-VPEfron(X,Z,dX,Phi,0,0)
> ==============================
>
> The code of C code - test.c and test.so is obtained by "R CMD SHLIB test.c"
> ================================
> #include <R.h>
> #include <Rdefines.h>
>
> #define RMATRIX(m,i,j) (REAL(m)[ INTEGER(GET_DIM(m))[0]*(j)+(i) ])
>
> SEXP mkans(double x)
> {
>         SEXP ans;
>         PROTECT(ans = allocVector(REALSXP,1));
>         REAL(ans)[0]=x;
>         UNPROTECT(1);
>         return ans;
> }
>
> SEXP VPCEfron(SEXP f, SEXP XR, SEXP ZR, SEXP DIR, SEXP rho)
> {
>         double* X=REAL(XR);
>         int* DI=INTEGER(DIR);
>         int nligne=INTEGER(GET_DIM(ZR))[0];
>         int ncol=INTEGER(GET_DIM(ZR))[1];
>
>         printf("verifie de X: %f - %f - %f - %f\n",X[0],X[1],X[2],X[3]);
>         printf("verifie dX: %d %d %d\n",DI[0],DI[1],DI[2]);
>         printf("verifie de Z\n");
>         printf("%d %d\n",nligne,ncol);
>         printf("%f %f\n",RMATRIX(ZR,0,0));
>         printf("%f %f\n",RMATRIX(ZR,0,1));
>         printf("%f %f\n",RMATRIX(ZR,1,0));
>         printf("%f %f\n",RMATRIX(ZR,2,0));
>
>         return mkans(0.0);
> }
> =====================================
>
> You can save these two simple programs in order to test my code.

It's a small point but there is no need to write the C function mkans
- you can use the function ScalarReal (or ScalarLogical, ScalarInt,
...).



From macq at llnl.gov  Fri Feb  3 16:25:42 2006
From: macq at llnl.gov (Don MacQueen)
Date: Fri, 3 Feb 2006 07:25:42 -0800
Subject: [R] Problems with ks.test
In-Reply-To: <BAY107-F334CDB4C6630F935B1F34C9A0D0@phx.gbl>
References: <BAY107-F334CDB4C6630F935B1F34C9A0D0@phx.gbl>
Message-ID: <p06210209c009256697e1@[128.115.153.6]>

7 repetitions is not nearly enough to get a good estimate of the 
variability of the test statistic.
Try this:

nrep <- 500
pvals <- tstvals <- numeric(nrep)

for (i in seq(nrep)) {
   tmp <-  ks.test(rexp(2500,0.4),"pexp",0.4)
   pvals[i] <- tmp$p.value
   tstvals[i] <- tmp$statistic
}

hist(pvals)
hist(tstvals)
round(quantile(pvals,pr=seq(0.05,.95,.05)),2)

At 2:36 PM +0000 2/3/06, Emanuele Mazzola wrote:
>Hi everybody,
>
>while performing ks.test for a standard exponential distribution on samples
>of dimension 2500, generated everytime as new, i had this strange behaviour:
>
>>data<-rexp(2500,0.4)
>>ks.test(data,"pexp",0.4)
>
>	One-sample Kolmogorov-Smirnov test
>
>data:  data
>D = 0.0147, p-value = 0.6549
>alternative hypothesis: two.sided
>
>>data<-rexp(2500,0.4)
>>ks.test(data,"pexp",0.4)
>
>	One-sample Kolmogorov-Smirnov test
>
>data:  data
>D = 0.019, p-value = 0.3305
>alternative hypothesis: two.sided
>
>>data<-rexp(2500,0.4)
>>ks.test(data,"pexp",0.4)
>
>	One-sample Kolmogorov-Smirnov test
>
>data:  data
>D = 0.0171, p-value = 0.4580
>alternative hypothesis: two.sided
>
>>data<-rexp(2500,0.4)
>>ks.test(data,"pexp",0.4)
>
>	One-sample Kolmogorov-Smirnov test
>
>data:  data
>D = 0.0143, p-value = 0.6841
>alternative hypothesis: two.sided
>
>>data<-rexp(2500,0.4)
>>ks.test(data,"pexp",0.4)
>
>	One-sample Kolmogorov-Smirnov test
>
>data:  data
>D = 0.0145, p-value = 0.6684
>alternative hypothesis: two.sided
>
>>data<-rexp(2500,0.4)
>>ks.test(data,"pexp",0.4)
>
>	One-sample Kolmogorov-Smirnov test
>
>data:  data
>D = 0.0123, p-value = 0.8435
>alternative hypothesis: two.sided
>
>  >data<-rexp(2500,0.4)
>>ks.test(data,"pexp",0.4)
>
>	One-sample Kolmogorov-Smirnov test
>
>data:  data
>D = 0.0186, p-value = 0.3532
>alternative hypothesis: two.sided
>
>
>It seems kind of strange to me that max p-value obtained is 0.8435 and all
>the best i can have from the rest is a 0.66-0.68.
>I'm probably not so expert in running this kind of test, but am I doing
>something wrong?
>I would expect p values ranging from 0.75 (to be kind) to 0.9, 0.95. How is
>this possible?
>
>Thank you in advance for your answers.
>See you soon
>EM
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From pburns at pburns.seanet.com  Fri Feb  3 16:30:08 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Fri, 03 Feb 2006 15:30:08 +0000
Subject: [R] Problems with ks.test
In-Reply-To: <BAY107-F334CDB4C6630F935B1F34C9A0D0@phx.gbl>
References: <BAY107-F334CDB4C6630F935B1F34C9A0D0@phx.gbl>
Message-ID: <43E37700.1040304@pburns.seanet.com>

The distribution of p-values should be uniform under
the null hypothesis.  When I do:

 > jj <- numeric(10000)
 > for(i in 1:10000) jj[i] <- ks.test(rexp(2500, .4), 'pexp', .4)$p.value
Warning messages:
1: cannot compute correct p-values with ties in: ks.test(rexp(2500, 
0.4), "pexp", 0.4)
2: cannot compute correct p-values with ties in: ks.test(rexp(2500, 
0.4), "pexp", 0.4)
3: cannot compute correct p-values with ties in: ks.test(rexp(2500, 
0.4), "pexp", 0.4)
4: cannot compute correct p-values with ties in: ks.test(rexp(2500, 
0.4), "pexp", 0.4)
 > hist(jj, 50, col='yellow'); abline(h=200, col='green')

I get a histogram that looks reasonably flat to me.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")


Emanuele Mazzola wrote:

>Hi everybody,
>
>while performing ks.test for a standard exponential distribution on samples 
>of dimension 2500, generated everytime as new, i had this strange behaviour:
>
>  
>
>>data<-rexp(2500,0.4)
>>ks.test(data,"pexp",0.4)
>>    
>>
>
>	One-sample Kolmogorov-Smirnov test
>
>data:  data
>D = 0.0147, p-value = 0.6549
>alternative hypothesis: two.sided
>
>  
>
>>data<-rexp(2500,0.4)
>>ks.test(data,"pexp",0.4)
>>    
>>
>
>	One-sample Kolmogorov-Smirnov test
>
>data:  data
>D = 0.019, p-value = 0.3305
>alternative hypothesis: two.sided
>
>  
>
>>data<-rexp(2500,0.4)
>>ks.test(data,"pexp",0.4)
>>    
>>
>
>	One-sample Kolmogorov-Smirnov test
>
>data:  data
>D = 0.0171, p-value = 0.4580
>alternative hypothesis: two.sided
>
>  
>
>>data<-rexp(2500,0.4)
>>ks.test(data,"pexp",0.4)
>>    
>>
>
>	One-sample Kolmogorov-Smirnov test
>
>data:  data
>D = 0.0143, p-value = 0.6841
>alternative hypothesis: two.sided
>
>  
>
>>data<-rexp(2500,0.4)
>>ks.test(data,"pexp",0.4)
>>    
>>
>
>	One-sample Kolmogorov-Smirnov test
>
>data:  data
>D = 0.0145, p-value = 0.6684
>alternative hypothesis: two.sided
>
>  
>
>>data<-rexp(2500,0.4)
>>ks.test(data,"pexp",0.4)
>>    
>>
>
>	One-sample Kolmogorov-Smirnov test
>
>data:  data
>D = 0.0123, p-value = 0.8435
>alternative hypothesis: two.sided
>
>  
>
>>data<-rexp(2500,0.4)
>>ks.test(data,"pexp",0.4)
>>    
>>
>
>	One-sample Kolmogorov-Smirnov test
>
>data:  data
>D = 0.0186, p-value = 0.3532
>alternative hypothesis: two.sided
>
>
>It seems kind of strange to me that max p-value obtained is 0.8435 and all 
>the best i can have from the rest is a 0.66-0.68.
>I'm probably not so expert in running this kind of test, but am I doing 
>something wrong?
>I would expect p values ranging from 0.75 (to be kind) to 0.9, 0.95. How is 
>this possible?
>
>Thank you in advance for your answers.
>See you soon
>EM
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From bioflash at gmail.com  Fri Feb  3 16:29:16 2006
From: bioflash at gmail.com (Vincent Deng)
Date: Fri, 3 Feb 2006 23:29:16 +0800
Subject: [R] How to get all the data in a specific column from a dataframe?
Message-ID: <455343d90602030729w85586dds2c3ae49d0c6c2946@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060203/f917c851/attachment.pl

From plummer at iarc.fr  Fri Feb  3 16:46:17 2006
From: plummer at iarc.fr (Martyn Plummer)
Date: Fri, 03 Feb 2006 16:46:17 +0100
Subject: [R] RHOME
In-Reply-To: <x2y80sv9h0.fsf@viggo.kubism.ku.dk>
References: <Pine.GSO.4.33.0602021358400.20430-100000@honoria.la.utexas.edu>
	<1138916063.43e27adf6393b@webmail.iarc.fr>
	<17379.7675.195068.676026@stat.math.ethz.ch>
	<x2y80sv9h0.fsf@viggo.kubism.ku.dk>
Message-ID: <1138981577.2873.58.camel@seurat.iarc.fr>

Far be it for me to tell people what they can and cannot do. Perhaps I
can rephrase myself in a less inflammatory way.  

R runs from the build directory as a convenience for developers, so you
don't have to reinstall R every time you change something. But for
users, the standard mechanism "make install" has a number of advantages
over moving the build directory to a publicly accessible location: it is
guaranteed to work, you don't have to do any post-hoc editing of files,
it takes up a lot less space, about 4.6 times less on my system

[martyn at seurat r-devel]$ du -sh R
356M    R
[martyn at seurat r-devel]$ du -sh /usr/local/lib64/R
77M     /usr/local/lib64/R

But if you do want to copy the build directory the, as Martin says,
you can edit the file bin/R so that the line that starts
R_HOME_DIR points to the correct location, e.g.
 
R_HOME_DIR="/usr/local/lib/R"

M.

On Fri, 2006-02-03 at 14:48 +0100, Peter Dalgaard wrote:
> Martin Maechler <maechler at stat.math.ethz.ch> writes:
> 
> >     Martyn> R is designed to run from its build directory.  But
> >     Martyn> if your sysadmin installs it with "make install" (as
> >     Martyn> root), then the shell wrapper that is installed in
> >     Martyn> /usr/local/bin/R will have R_HOME pointing to the
> >     Martyn> right location (/usr/local/lib/R).  Literally moving
> >     Martyn> the build directory to another location is the wrong
> >     Martyn> thing to do.
> > 
> > well, but very easily fixable, and that's what Daniel is asking
> > for:
> > 
> > The default value of R_HOME is only set in exactly one place,
> > namely the 'R' shell script; editing that script - once after
> > the move - is really a piece o'cake.
> 
> Hmm, I was about to say the same, but there seems to be unexpected
> references in other places.
> 
> find `R RHOME` | xargs grep `R RHOME`
> /usr/lib64/R/bin/R:R_HOME_DIR=/usr/lib64/R
> /usr/lib64/R/bin/R:R_SHARE_DIR=/usr/lib64/R/share
> /usr/lib64/R/bin/R:R_INCLUDE_DIR=/usr/lib64/R/include
> /usr/lib64/R/bin/R:R_DOC_DIR=/usr/lib64/R/doc
> 
> (this doesn't normally happen - a SUSE RPM specialty, or due to
> configure flag settings?)

I think this is normal. But the RedHat RPM behaves differently.

(because the RPM build process installs into a temporary build root
which is distinct from the final installation directory, requiring more
sed voodoo).

> 
> Once you start building packages, you also have things like
> 
> viggo:~/>find ~/Rlibrary | xargs grep `R RHOME`
> Binary file /home/bs/pd/Rlibrary/rgl/libs/rgl.so matches
> 
> 
> viggo:~/>find ~/Rlibrary | xargs grep Rlibrary
> Binary file /home/bs/pd/Rlibrary/rgl/Meta/hsearch.rds matches
> Binary file /home/bs/pd/Rlibrary/ISwR/Meta/hsearch.rds matches
> Binary file /home/bs/pd/Rlibrary/mvtnorm/Meta/hsearch.rds matches
> Binary file /home/bs/pd/Rlibrary/nlmeODE/Meta/hsearch.rds matches
> B.....
> 
> on my laptop I had a hit on one of the Sweave support files too.
> 
> Most likely these are quite harmless, but all in all I think Martyn
> has the safest advice: Use "make install", as root (don't forget
> "umask 022").
> 

-----------------------------------------------------------------------
This message and its attachments are strictly confidential. ...{{dropped}}



From erithid at bellsouth.net  Fri Feb  3 17:04:45 2006
From: erithid at bellsouth.net (BJ)
Date: Fri, 03 Feb 2006 11:04:45 -0500
Subject: [R] Infinite loop running Mod_R/Rapache
Message-ID: <43E37F1D.3050309@bellsouth.net>

I installed mod_r according to the specifications, and have been trying 
to get the demo script to work correctly. I am running debian, the 
latest build of R, apache 2 with prefork mpm, and the latest mod_r. Is 
anyone else using this module successfully? I added:

LoadModule R_module mod_R.so
<Location /test/hello>
    SetHandler r-handler
    Rsource /var/www/html/test.R
    RreqHandler handler
</Location>

to my http.conf and

test.R in /var/www/html is:

handler<-function(r){
    apache.write(r,"<h1>Hello World!</h1>")
OK
}

When I start apache2, my /tmp directory fills with rtmp directories 
until memory is exausted. The first time it created 32,000 before I 
noticed. Does anyone have any idea as to what I could be doing wrong, or 
have a software configuration that works? Thank you for all of your 
help. ~BJ



From ccleland at optonline.net  Fri Feb  3 17:08:42 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 03 Feb 2006 11:08:42 -0500
Subject: [R] How to get all the data in a specific column from a
	dataframe?
In-Reply-To: <455343d90602030729w85586dds2c3ae49d0c6c2946@mail.gmail.com>
References: <455343d90602030729w85586dds2c3ae49d0c6c2946@mail.gmail.com>
Message-ID: <43E3800A.9060506@optonline.net>

test_frame[,"col3"]

or

subset(test_frame, select = col3)

Vincent Deng wrote:
> Dear R-helpers:
> 
> Suppose I have a datafram called "test_frame" like this
>      col1   col2  col3  col4
> r1   x        x        x     x
> r2   x        x        x     x
> r3   x        x        x     x
> ..    x        x        x     x
> rn   x        x        x     x
> 
> I know I can get data of col3 by using test_frame[,3].
> 
> My question is, if I want to do this by specifying "col3" rather than 3,
> what should I do?
> 
> Many thanks....
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From p.dalgaard at biostat.ku.dk  Fri Feb  3 17:13:24 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 Feb 2006 17:13:24 +0100
Subject: [R] How to get all the data in a specific column from a
	dataframe?
In-Reply-To: <43E3800A.9060506@optonline.net>
References: <455343d90602030729w85586dds2c3ae49d0c6c2946@mail.gmail.com>
	<43E3800A.9060506@optonline.net>
Message-ID: <x2acd8a09n.fsf@viggo.kubism.ku.dk>

Chuck Cleland <ccleland at optonline.net> writes:

> test_frame[,"col3"]
> 
> or
> 
> subset(test_frame, select = col3)

or 

test_frame$col3

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From bszk at uoguelph.ca  Fri Feb  3 17:22:49 2006
From: bszk at uoguelph.ca (Bill Szkotnicki)
Date: Fri, 3 Feb 2006 11:22:49 -0500
Subject: [R] statistical modelling SAS vs R
In-Reply-To: <43E37F1D.3050309@bellsouth.net>
Message-ID: <001d01c628de$13522880$0100000a@bszklgtab>

Hello,

Recently I have been reading a lot of material about statistical modeling
using R. There seems to be conflicting opinions about what the best approach
is between the SAS community and the R community.
1) In R one might start with a model that has all possible effects of
interest in it and then simplify by eliminating/adding insignificant effects
using a stepwise procedure.
2) In SAS one may starts with a "reasonable" model and look at type 3 SS's
to test hypotheses and report LSMEANS. This can be done in R too I think.

Does anyone have current opinions about this? I know it's been discussed
before but I would be very interested in hearing about the advantages and
pitfalls of both approaches.

Bill



From afshart at exchange.sba.miami.edu  Fri Feb  3 17:20:40 2006
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Fri, 3 Feb 2006 11:20:40 -0500
Subject: [R] workspace question
Message-ID: <6BCB4D493A447546A8126F24332056E8027C8BF9@school1.business.edu>


All,

When starting R, how does one prevent the loading the previous 
workspace which was saved?  I'd like to start a new project
and save the new image in a different directory, but I'd like to 
partition this from the old project.  Does there exist a better
way than just deleting the files associated w/ the old project
manually?  I looked in the Intro to R manual and searched for 
"workspace" and didn't see anything on this aspect.

Kind regards,
Dave

ps - please reply directly to afshar at miami.edu



From f.harrell at vanderbilt.edu  Fri Feb  3 17:36:29 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 03 Feb 2006 10:36:29 -0600
Subject: [R] statistical modelling SAS vs R
In-Reply-To: <001d01c628de$13522880$0100000a@bszklgtab>
References: <001d01c628de$13522880$0100000a@bszklgtab>
Message-ID: <43E3868D.4060001@vanderbilt.edu>

Bill Szkotnicki wrote:
> Hello,
> 
> Recently I have been reading a lot of material about statistical modeling
> using R. There seems to be conflicting opinions about what the best approach
> is between the SAS community and the R community.
> 1) In R one might start with a model that has all possible effects of
> interest in it and then simplify by eliminating/adding insignificant effects
> using a stepwise procedure.
> 2) In SAS one may starts with a "reasonable" model and look at type 3 SS's
> to test hypotheses and report LSMEANS. This can be done in R too I think.
> 
> Does anyone have current opinions about this? I know it's been discussed
> before but I would be very interested in hearing about the advantages and
> pitfalls of both approaches.
> 
> Bill

You'll get lots of opinions about this.  Both R and SAS can be abused 
terribly, and both approaches you mentioned have major problems if you 
use P-values to specify models.  Better and more replicable results can 
be obtained using modern shrinkage methods and being more liberal with 
inclusion of variables, or by using Bayesian model averaging.

Note that LSMEANS and Type III tests are SAS concoctions and that if you 
have interactions in the model, type III tests have been criticized.  If 
there are no interactions, type Type III = Type II.

Frank Harrell

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From lamkelj at yahoo.com  Fri Feb  3 17:47:36 2006
From: lamkelj at yahoo.com (Kel Lam)
Date: Fri, 3 Feb 2006 08:47:36 -0800 (PST)
Subject: [R] Clustering for social/complex networks
Message-ID: <20060203164736.65384.qmail@web52702.mail.yahoo.com>

Hi group,

Here is another clustering question.  Is there
anything available in R that I can cluster groups with
overlaps?  It looks like a Venn Diagram with two or
more circles overlapping one another.  

I realize that Hierarchical Clustering (hclust in
Stats) only group individuals into distinct groups. 
My scenario is I have to group Physicians that each of
them may belong to more than one group.  That reflects
the complexity of relationhip, something analogous to
Social Network.  

Thanks!

kel



From bolker at zoo.ufl.edu  Fri Feb  3 18:35:10 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Fri, 03 Feb 2006 12:35:10 -0500
Subject: [R] is there a way to visualize 3D normal distributions?
In-Reply-To: <43E293FD.4040700@stats.uwo.ca>
References: <b1f16d9d0602020039t5604b508m11d857f67f903e91@mail.gmail.com>	<43E1F227.7000602@stats.uwo.ca>	<loom.20060202T155042-992@post.gmane.org>
	<b1f16d9d0602021401k9655566n214c6e68c6215043@mail.gmail.com>
	<43E293FD.4040700@stats.uwo.ca>
Message-ID: <43E3944E.3090301@zoo.ufl.edu>


   In response to your last question --

   Duncan already gave you the answer in his last e-mail -- to give
an explicit example, for a particular set of means and
variance-covariance matrix:

library(rgl)
demo(shapes3d)
rgl.clear()
sphere <- ellipsoid3d(2,2,2,qmesh=TRUE)
means <- c(0,0,0)
S <- matrix(c(3,1,-1,1,2,-1,-1,-1,2),nrow=3)
ellipsoid <- translate3d(rotate3d(sphere,matrix=chol(S)*qnorm(0.975)),
                                     means[1],means[2],means[3])
shade3d(ellipsoid)
axis3d()


Duncan Murdoch wrote:
> On 2/2/2006 5:01 PM, Michael wrote:
> 
>> shape3d only gives rigid sphere... not the free form ellipsoid that I
>> want...
> 
> 
> ? If you run the demo, you'll see ellipsoids...
> 
> You just need to work out the appropriate transform to apply to a sphere 
> to get the ellipsoid you want.  I imagine something like this:
> 
> sphere <- ellipsoid3d(2,2,2, qmesh=TRUE)
> ellipsoid <- translate3d(rotate3d(sphere, matrix=chol(S)), xbar, ybar, 
> zbar)
> 
> shade3d(ellipsoid)
> 
> is what you want, where S is the covariance matrix, and xbar,ybar,zbar 
> have the obvious meaning.  (rotate3d() is used with a matrix that isn't 
> a rotation matrix; it may not be obvious that this is allowed, but it is.)
> 
> Duncan Murdoch
> 
> 
>>
>> On 2/2/06, Ben Bolker <bolker at ufl.edu> wrote:
>>
>>> Duncan Murdoch <murdoch <at> stats.uwo.ca> writes:
>>>
>>>> On 2/2/2006 3:39 AM, Michael wrote:
>>>>
>>>>> Hi all,
>>>>>
>>>>> How do I visualize a contour of a tri-variate normal distribution?
>>>>>
>>>>> I just like to see the ellipsoid very much. I hope there is a easy way
>>>
>>> or
>>>
>>>>> existing method in R.
>>>>
>>>> The misc3d package includes a function for 3d contour plots; that 
>>>> should
>>>> do what you want.
>>>>
>>>   is contour3d really necessary or could you just plot ellipsoids?
>>> (library(rgl); demo(shapes3d)) -- still a little bit of figuring
>>> to do, but this should get you most of the way there.
>>>
>>>   Ben Bolker
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>>
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html


-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From jeff.horner at vanderbilt.edu  Fri Feb  3 18:40:40 2006
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Fri, 03 Feb 2006 11:40:40 -0600
Subject: [R] Infinite loop running Mod_R/Rapache
In-Reply-To: <43E37F1D.3050309@bellsouth.net>
References: <43E37F1D.3050309@bellsouth.net>
Message-ID: <43E39598.90908@vanderbilt.edu>

BJ wrote:
> I installed mod_r according to the specifications, and have been trying 
> to get the demo script to work correctly. I am running debian, the 
> latest build of R, apache 2 with prefork mpm, and the latest mod_r. Is 
> anyone else using this module successfully? I added:
> 
> LoadModule R_module mod_R.so
> <Location /test/hello>
>     SetHandler r-handler
>     Rsource /var/www/html/test.R
>     RreqHandler handler
> </Location>
> 
> to my http.conf and
> 
> test.R in /var/www/html is:
> 
> handler<-function(r){
>     apache.write(r,"<h1>Hello World!</h1>")
> OK
> }
> 
> When I start apache2, my /tmp directory fills with rtmp directories 
> until memory is exausted. The first time it created 32,000 before I 
> noticed. Does anyone have any idea as to what I could be doing wrong, or 
> have a software configuration that works? Thank you for all of your 
> help. ~BJ

This is definitely an apache configuration problem. After responding to 
you privately about this issue, I got paranoid and checked the latest 
R/Apache code release (rapache-0.1.1) with the following debian packages:

apache2-common/unstable uptodate 2.0.55-4
apache2-utils/unstable uptodate 2.0.55-4
apache2-mpm-prefork/unstable uptodate 2.0.55-4
apache2-prefork-dev/unstable uptodate 2.0.55-4

I could not reproduce the behavior you are witnessing. Maybe you can 
send me (off-list) your /etc/apache2/apache2.conf, 
/etc/apache2/sites-enabled/* and  see if I can't help you troubleshoot.

But this bit of R creating a temp dir (for transient files?) needs to be 
handled more delicately in a server environment. I'm going to do some 
more digging in the R source... I hope I haven't made some glaringly 
wrong assumptions.

-- 
Jeffrey Horner       Computer Systems Analyst         School of Medicine
615-322-8606         Department of Biostatistics   Vanderbilt University



From Gautam.Bhola at pfizer.com  Fri Feb  3 19:21:45 2006
From: Gautam.Bhola at pfizer.com (Bhola, Gautam)
Date: Fri, 3 Feb 2006 13:21:45 -0500
Subject: [R] R-2.2.1-INSTALL Issue with TCLTK
Message-ID: <E04D0A5FF70E854582D33D93A880799B0399BCCF@groamrexm03.amer.pfizer.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060203/1e4cfbab/attachment.pl

From andy_liaw at merck.com  Fri Feb  3 19:58:18 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 3 Feb 2006 13:58:18 -0500
Subject: [R] workspace question
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7C5@usctmx1106.merck.com>

If you start R with the argument --no-restore (or even --vanilla, I think),
no workspace will be loaded.

Personally I almost never save a workspace image.  Whatever I need I
explicitly save() and load() or attach().

Andy

From: Afshartous, David
> 
> All,
> 
> When starting R, how does one prevent the loading the previous 
> workspace which was saved?  I'd like to start a new project
> and save the new image in a different directory, but I'd like to 
> partition this from the old project.  Does there exist a better
> way than just deleting the files associated w/ the old project
> manually?  I looked in the Intro to R manual and searched for 
> "workspace" and didn't see anything on this aspect.
> 
> Kind regards,
> Dave
> 
> ps - please reply directly to afshar at miami.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From pinard at iro.umontreal.ca  Fri Feb  3 20:08:32 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Fri, 3 Feb 2006 14:08:32 -0500
Subject: [R] Difficulty with qqline in logarithmic context
In-Reply-To: <Pine.LNX.4.61.0602011552110.23477@gannet.stats>
References: <20060201152135.GA10720@phenix.sram.qc.ca>
	<Pine.LNX.4.61.0602011552110.23477@gannet.stats>
Message-ID: <20060203190832.GA3592@alcyon.progiciels-bpi.ca>

[Brian Ripley]
>Is there a good reason to use qqnorm in a single-log context?

Yes.  Googling around reveals this is not so uncommon.

> Should one not rather use

>>qqnorm(log(freq))
>>qqline(log(freq))

In the display produced by "qqnorm", the y-axis would then show 
"log(value)" labels, while the user (me!) expects "value" labels.

>since you are (I guess) looking at log-normality of freq?

Once again, I was merely toying with "qqplot".  I found intriguing that, 
while shuffling messages around between folders, for a good while, the 
distribution of log(number of messages) per folder appears vagueley 
normal, as I do not quickly see a reasonable justification for this.

>Another way to look at that is

>>qqplot(qlnorm(ppoints(length(freq))), freq, log="xy")

>the same plot, different scales.

Interesting, thanks for teaching me about "ppoints".  Yet, I stay more 
happy with the abcissa scale produced by "qqnorm".  Besides, how would 
one uses "qqline" with the above?

>(I believe a QQ plot should always have comparable scales on the two 
>axes.)

While comparable scales are somewhat simpler to compare, this is not 
necessarily what is most adequate for the user.  Proof is that while 
quantiles are being compared here, scales do not show quantiles, but 
units as meaningful to the user.  One might want to compare variables 
scaled very differently, maybe because of different units from the same 
distribution, of from different but similar distributions using 
different scales and shifted to different means.  Or even, why not, if 
this is what is meaningful for users, a log scale.

>The point is that qqline is tied to normality, not to log-normality.

As it stands, yes.  As a convenience, it could be extended (probably 
easily) to log-normality.  "qqnorm" already does something sensible in 
log-context, so a user might expect "qqline" to do equally well.

The real point might be that "qqline" is tied to "abline" a bit too 
blindly.  What is the meaning of intercept and slope of a straight line 
on a graphic in log context?  First, the intercept might not even exist.  
Second, "abline" interpretation depends on the clippling, and possibly 
on the extrema of the pretty breakpoints chosen for scales, so making it 
hard to predict on average use.   There ought to be some reason for the 
log-aware code in "abline", yet I did not find documentation for it.

The wisest for "abline", in my very humble opinion, would be for it to 
complain if ever called in log context.  Then, "qqline" would indirectly 
complain through "abline", if "qqline" is not modified to do something 
more proper.  Moreover, if it is definitely out of question that 
"qqline" be ever meaningfully called in log context, then so "qqnorm", 
which should then complain as well.

Currently, "qqline" misbehaves, in that it silently produces 
a meaningless result, while it could either diagnose that the result is 
meaningless, or produce a mearningful result.


[Remainder of the reply top-quoted, as usual on r-help.]

>On Wed, 1 Feb 2006, Fran??ois Pinard wrote:

>>Hi, R friends.  I had some difficulty with the following code:

>>   qqnorm(freq, log='y')
>>   qqline(freq)

>>as the line drawn was seemingly random.  The exact data I used appears
>>below.  After wandering a bit within the source code for "abline",
>>I figured out I should rather write:

>>   qqnorm(freq, log='y')
>>   par(ylog=FALSE)
>>   qqline(log10(freq))
>>   par(ylog=TRUE)

>>I'm proposing that this little stunt be rather be hidden and
>>automatically effected within "qqline" proper, whenever par('ylog') is
>>TRUE.  I thought about providing a patch, as "qqline" is so small.  Yet
>>it would be more noise than useful, as I'm not familiar with the "datax"
>>argument usage, which should probably be addressed as well.



>>Here is the data, in case useful:

>>freq <-
>>as.integer(c(33, 79, 21, 436, 58, 18, 1106, 498, 1567, 393, 2,
>>104, 50, 67, 113, 76, 327, 331, 196, 145, 86, 59, 12, 215, 293,
>>154, 500, 314, 246, 587, 85, 23, 323, 3, 13, 576, 29, 37, 24,
>>21, 1230, 137, 13, 93, 3, 101, 72, 218, 59, 17, 2, 8, 86, 143,
>>150, 22, 19, 234, 119, 157, 4, 255, 146, 126, 76, 15, 271, 170,
>>4, 6, 16, 3048, 2175, 3350, 5017, 5706, 1610, 665, 322, 1, 16,
>>47, 51, 168, 94, 66, 154, 99, 11, 547, 953, 1, 1071, 80, 184,
>>168, 52, 187, 103, 187, 361, 46, 85, 135, 597, 121, 283, 26,
>>12, 20, 169, 9, 79, 15, 114, 75, 30, 111, 556, 173, 32, 99, 438,
>>2, 2, 1, 117, 5, 3, 51, 8, 41, 12, 23, 2, 13, 5, 1, 9, 4, 1,
>>7, 15, 5, 48, 16, 112, 6, 1, 39, 60, 5, 23, 5, 19, 1, 8, 32,
>>4, 13, 1, 14, 71, 5, 1, 35, 30, 100, 389, 22, 8, 1, 192, 40,
>>6, 3, 17, 2, 14, 71, 14, 1, 5, 4, 32, 21, 18, 13, 2, 2, 45, 342,
>>46, 144, 18, 131, 188, 112, 37, 85, 90, 8, 195, 173, 5, 53, 96,
>>37, 16, 16, 281, 64, 50, 92, 336, 31, 744, 4, 134, 74, 1, 227,
>>6, 48, 418, 64, 66, 59, 20, 45, 20, 370, 148, 22, 7, 30, 601,
>>29, 82, 113, 938, 252, 65, 137, 72, 22, 98, 12, 152, 212, 13,
>>8, 35, 3, 77))

>>Yet this really is the value of "courriel$freq" after "data(courriel)",
>>with a file ".../R/data/courriel.R" here, holding:

>>courriel <- read.table(pipe('grep -c \'^From \' ../courriel/*'),
>>                       sep=':', as.is=T, row.names=1,
>>                       col.names=c('fichier', 'freq'))

>>My goal, which is nothing serious, was merely to toy with the number of
>>messages per folder, for folders massaged out of R archives.



>>Version:
>>platform = i686-pc-linux-gnu
>>arch = i686
>>os = linux-gnu
>>system = i686, linux-gnu
>>status =
>>major = 2
>>minor = 2.1
>>year = 2005
>>month = 12
>>day = 20
>>svn rev = 36812
>>language = R

>>Locale:
>>LC_CTYPE=fr_CA.UTF-8;LC_NUMERIC=C;LC_TIME=fr_CA.UTF-8;LC_COLLATE=fr_CA.UTF-8;LC_MONETARY=fr_CA.UTF-8;LC_MESSAGES=fr_CA.UTF-8;LC_PAPER=C;LC_NAME=C;LC_ADDRESS=C;LC_TELEPHONE=C;LC_MEASUREMENT=C;LC_IDENTIFICATION=C

>>Search Path:
>>.GlobalEnv, package:methods, package:stats, package:graphics, 
>>package:grDevices, package:utils, package:datasets, fp.etc, Autoloads, 
>>package:base


>>-- 
>>Fran??ois Pinard   http://pinard.progiciels-bpi.ca

>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html


>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-- 
Fran??ois Pinard   http://pinard.progiciels-bpi.ca



From ozric at web.de  Fri Feb  3 20:16:24 2006
From: ozric at web.de (Christian Schulz)
Date: Fri, 03 Feb 2006 20:16:24 +0100
Subject: [R] Clustering for social/complex networks
In-Reply-To: <20060203164736.65384.qmail@web52702.mail.yahoo.com>
References: <20060203164736.65384.qmail@web52702.mail.yahoo.com>
Message-ID: <43E3AC08.2000402@web.de>

try:

cmeans "Fuzzy C-Means Clustering" in library(e1071)

regards, christian

>Hi group,
>
>Here is another clustering question.  Is there
>anything available in R that I can cluster groups with
>overlaps?  It looks like a Venn Diagram with two or
>more circles overlapping one another.  
>
>I realize that Hierarchical Clustering (hclust in
>Stats) only group individuals into distinct groups. 
>My scenario is I have to group Physicians that each of
>them may belong to more than one group.  That reflects
>the complexity of relationhip, something analogous to
>Social Network.  
>
>Thanks!
>
>kel
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From marvena at tin.it  Fri Feb  3 20:46:22 2006
From: marvena at tin.it (Marco Venanzi)
Date: Fri, 3 Feb 2006 20:46:22 +0100
Subject: [R] Function "assign"
Message-ID: <002c01c628fa$8331c590$0701a8c0@acerc5ropxp63k>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060203/ed4cf008/attachment.pl

From falimadhi at iq.harvard.edu  Fri Feb  3 21:09:31 2006
From: falimadhi at iq.harvard.edu (Ferdinand Alimadhi)
Date: Fri, 03 Feb 2006 15:09:31 -0500
Subject: [R] Function "assign"
In-Reply-To: <002c01c628fa$8331c590$0701a8c0@acerc5ropxp63k>
References: <002c01c628fa$8331c590$0701a8c0@acerc5ropxp63k>
Message-ID: <43E3B87B.8040209@iq.harvard.edu>

example<-matrix(nrow=5,ncol=5)
example[c(1,3),]<-matrix(1:10,nrow=2,ncol=5)



Marco Venanzi wrote:

>I'm trying to apply the function "assign( )" to a subset of a matrix, but it doesn't work...
>
>i.e.
>
>example<-matrix(nrow=5,ncol=5)
>assign("example[c(1,3),]",matrix(1:10,nrow=2,ncol=5))
>
>but matrix "example" doesn't change ( get("example[c(1,3),]") is not useful to me)...how can I do this assignment?
>Thanks in advance,
>
>                                          Marco
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>


-- 
Ferdinand Alimadhi
Programmer / Analyst
Harvard University
The Institute for Quantitative Social Science
(617) 496-0187
falimadhi at iq.harvard.edu
www.iq.harvard.edu



From ripley at stats.ox.ac.uk  Fri Feb  3 21:20:10 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Feb 2006 20:20:10 +0000 (GMT)
Subject: [R] R-2.2.1-INSTALL Issue with TCLTK
In-Reply-To: <E04D0A5FF70E854582D33D93A880799B0399BCCF@groamrexm03.amer.pfizer.com>
References: <E04D0A5FF70E854582D33D93A880799B0399BCCF@groamrexm03.amer.pfizer.com>
Message-ID: <Pine.LNX.4.61.0602032014150.28974@gannet.stats>

Those don't look like valid paths to config files to me.  On FC3 they 
would be

/usr/lib/tclConfig.sh
/usr/lib/tkConfig.sh

So even if you have users tcl-8.4.12 and tk-8.4.12 (do you?), your paths 
are almost surely not to config files.

Configure reports what works, including that it is not going to build 
tcl/tk support.  Look back at the relevant parts of its output.

On Fri, 3 Feb 2006, Bhola, Gautam wrote:

> Hi
>
>
>
> I am not able to have a working tcltk library in R-2.2.1 inspite of
> trying different options suggested in the FAQ's. I am using the
> following configure option and I do get the tcltk package installed but
> with a missing libs folder.
>
>
>
> ./configure -prefix= "~R-2.2.1"  --enable-R-shlib --enable-linux-lfs
> --with-zlib --with-gnu-ld --with-tcltk
> --with-tcl-config="~tcl-8.4.12/lib" --with-tk-config="~tk-8.4.12/lib"
>
>
>
> I have ensured that I have a valid tclsh in my path and have even
> provided the include path for covering the tcl.h
>
>
>
> Operating system: RHEL
>
>
>
> The error I get while trying to invoke the libarary for tcltk is:
>
>
>
> Error in firstlib(which.lib.loc, package) :
>
> Tcl/Tk support is not available on this system
>
> Error in library(tcltk) : .First.lib failed for 'tcltk'
>
> Execution halted
>
>
>
> Any help to identify the cause is highly appreciated.
>
>
>
> Respectfully
>
> Gautam
>
> ----------------------------------------------------------------------
> LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tom at maladmin.com  Fri Feb  3 16:41:00 2006
From: tom at maladmin.com (tom wright)
Date: Fri, 03 Feb 2006 10:41:00 -0500
Subject: [R] all.equal() and which()
Message-ID: <1138981260.4488.4.camel@localhost.localdomain>

Please excuse the lack of a complete dataset here, if its needed I'll be
happy to provide it.
Can anyone show me how to rewrite this?

Browse[1]> time(data)[24210:24220]
[1] 24.209 24.210 24.211 24.212 24.213 24.214 24.215 24.216 24.217 
[10] 24.218 24.219

Browse[1]> which(time(data)==24.211)
numeric(0)

I'm assuming its an eps fault but
which(all.equal(time(data),24.211))

dosnt seem to work



From mschwartz at mn.rr.com  Fri Feb  3 21:51:17 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Fri, 03 Feb 2006 14:51:17 -0600
Subject: [R] all.equal() and which()
In-Reply-To: <1138981260.4488.4.camel@localhost.localdomain>
References: <1138981260.4488.4.camel@localhost.localdomain>
Message-ID: <1138999878.5335.8.camel@localhost.localdomain>

On Fri, 2006-02-03 at 10:41 -0500, tom wright wrote:
> Please excuse the lack of a complete dataset here, if its needed I'll be
> happy to provide it.
> Can anyone show me how to rewrite this?
> 
> Browse[1]> time(data)[24210:24220]
> [1] 24.209 24.210 24.211 24.212 24.213 24.214 24.215 24.216 24.217 
> [10] 24.218 24.219
> 
> Browse[1]> which(time(data)==24.211)
> numeric(0)
> 
> I'm assuming its an eps fault but
> which(all.equal(time(data),24.211))
> 
> dosnt seem to work


There might be an easier way, but here is one approach:

> mydat
 [1] 24.209 24.210 24.211 24.212 24.213 24.214 24.215 24.216 24.217
[10] 24.218 24.219

> which(sapply(mydat, function(x) isTRUE(all.equal(24.211, x))))
[1] 3


This uses sapply() to check each element of 'mydat' against the target
value of 24.211.  The use of 'isTRUE(all.equal(...))' returns a boolean
result of either TRUE or FALSE, enabling the use of which() against the
vector returned from sapply():

> sapply(mydat, function(x) isTRUE(all.equal(24.211, x)))
 [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE

See ?all.equal and ?isTRUE for more information.

HTH,

Marc Schwartz



From kmm at brown.edu  Fri Feb  3 22:41:11 2006
From: kmm at brown.edu (Kevin Middleton)
Date: Fri, 3 Feb 2006 13:41:11 -0800
Subject: [R] Using string vectors as for loop arguments
Message-ID: <A254A2CA-0493-462C-9D38-68B5FA7C1D21@brown.edu>

Is there a mechanism to interate through a vector of strings? Say I  
have a data frame of 50 variables (VAR1 to VAR50), each with 100  
measurements along with some coding factors (EXP and DOSE). I want to  
calculate the mean of a subset of each of VAR1 to VAR 50 (selecting  
by EXP and DOSE). Rather than just copy/pasting the same code 50  
times, I thought of using a for loop to go through a vector of VAR1  
to VAR50 (VAR.LIST below). Each iteration would be the variable name  
for which the mean would be calculated.

Trying this, I get an error that the argument is not numeric or  
logical. So I assume that for loops with vectors of strings are  
disallowed. What I am wondering is whether there a way to mimic this  
sort of procedure?

The code looked something like this:

VAR.LIST<-paste(c("VAR"), 1:50, sep="")

for (i in VAR.LIST){
	mean(i[EXP==1 & DOSE==1], na.rm=T)
	}



Thanks
Kevin Middleton



From liuwensui at gmail.com  Fri Feb  3 22:41:47 2006
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 3 Feb 2006 16:41:47 -0500
Subject: [R] statistical modelling SAS vs R
In-Reply-To: <001d01c628de$13522880$0100000a@bszklgtab>
References: <43E37F1D.3050309@bellsouth.net>
	<001d01c628de$13522880$0100000a@bszklgtab>
Message-ID: <1115a2b00602031341x270336e5qe40dd7d0234f4e99@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060203/d41bd8c9/attachment.pl

From attenka at utu.fi  Fri Feb  3 22:45:22 2006
From: attenka at utu.fi (Atte Tenkanen)
Date: Fri, 03 Feb 2006 23:45:22 +0200 (EET)
Subject: [R] How to generate pitch strings
Message-ID: <61156.130.232.44.35.1139003122.squirrel@webmail2.utu.fi>

If I calculate a transition probability matrix, first order markov 12x12
or second order 144x144 from musical pitch classes (0-11), is it possible
to generate pitch class strings similar as those original strings using
those probability matrix with R? If, how?

Atte Tenkanen, Turku, Finland



From gunter.berton at gene.com  Fri Feb  3 22:53:57 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 3 Feb 2006 13:53:57 -0800
Subject: [R] Using string vectors as for loop arguments
In-Reply-To: <A254A2CA-0493-462C-9D38-68B5FA7C1D21@brown.edu>
Message-ID: <200602032153.k13Lrv1V008754@ohm.gene.com>

?apply

as in:

answer<-apply(yourframe,2,function(x)x[EXP==1 & DOSE==1])

Note that there are slicker ways to do this call.
Note also for that for the particular case of column means, you have a
built-in much faster alternative:

answer<-colMeans(yourframe[EXP==1 & DOSE==1,],na.rm=TRUE)

Also note that the == construction may be problematic if EXP or DOSE are not
factors, say.

Finally, you need to start reading the R docs to learn about this yourself.
"An Introduction to R" is a good place to start.

Oh... and your attempt below will certainly not work. After you read the
basic docs, you'll see why not.


-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Kevin Middleton
> Sent: Friday, February 03, 2006 1:41 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Using string vectors as for loop arguments
> 
> Is there a mechanism to interate through a vector of strings? Say I  
> have a data frame of 50 variables (VAR1 to VAR50), each with 100  
> measurements along with some coding factors (EXP and DOSE). I 
> want to  
> calculate the mean of a subset of each of VAR1 to VAR 50 (selecting  
> by EXP and DOSE). Rather than just copy/pasting the same code 50  
> times, I thought of using a for loop to go through a vector of VAR1  
> to VAR50 (VAR.LIST below). Each iteration would be the variable name  
> for which the mean would be calculated.
> 
> Trying this, I get an error that the argument is not numeric or  
> logical. So I assume that for loops with vectors of strings are  
> disallowed. What I am wondering is whether there a way to mimic this  
> sort of procedure?
> 
> The code looked something like this:
> 
> VAR.LIST<-paste(c("VAR"), 1:50, sep="")
> 
> for (i in VAR.LIST){
> 	mean(i[EXP==1 & DOSE==1], na.rm=T)
> 	}
> 
> 
> 
> Thanks
> Kevin Middleton
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Fri Feb  3 18:00:58 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 3 Feb 2006 17:00:58 +0000 (GMT)
Subject: [R] RHOME
In-Reply-To: <x2y80sv9h0.fsf@viggo.kubism.ku.dk>
References: <Pine.GSO.4.33.0602021358400.20430-100000@honoria.la.utexas.edu>
	<1138916063.43e27adf6393b@webmail.iarc.fr>
	<17379.7675.195068.676026@stat.math.ethz.ch>
	<x2y80sv9h0.fsf@viggo.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0602031656570.25945@gannet.stats>

On Fri, 3 Feb 2006, Peter Dalgaard wrote:

> Martin Maechler <maechler at stat.math.ethz.ch> writes:
>
>>     Martyn> R is designed to run from its build directory.  But
>>     Martyn> if your sysadmin installs it with "make install" (as
>>     Martyn> root), then the shell wrapper that is installed in
>>     Martyn> /usr/local/bin/R will have R_HOME pointing to the
>>     Martyn> right location (/usr/local/lib/R).  Literally moving
>>     Martyn> the build directory to another location is the wrong
>>     Martyn> thing to do.
>>
>> well, but very easily fixable, and that's what Daniel is asking
>> for:
>>
>> The default value of R_HOME is only set in exactly one place,
>> namely the 'R' shell script; editing that script - once after
>> the move - is really a piece o'cake.
>
> Hmm, I was about to say the same, but there seems to be unexpected
> references in other places.
>
> find `R RHOME` | xargs grep `R RHOME`
> /usr/lib64/R/bin/R:R_HOME_DIR=/usr/lib64/R
> /usr/lib64/R/bin/R:R_SHARE_DIR=/usr/lib64/R/share
> /usr/lib64/R/bin/R:R_INCLUDE_DIR=/usr/lib64/R/include
> /usr/lib64/R/bin/R:R_DOC_DIR=/usr/lib64/R/doc
>
> (this doesn't normally happen - a SUSE RPM specialty, or due to
> configure flag settings?)

That only happens in the installed copy.  Martin is right if one is 
talking about moving the build tree (and Martyn is right that there is a 
lot of stuff that does not need to be installed in the build tree and that 
`make install' takes all the strain of copying the right bits).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From abitbol at sent.com  Sat Feb  4 00:02:15 2006
From: abitbol at sent.com (Jean-Louis Abitbol)
Date: Sat, 04 Feb 2006 00:02:15 +0100
Subject: [R] Cause of Error 1:nrow(X) : argument NA / NaN
Message-ID: <1139007735.7403.253508653@webmail.messagingengine.com>

Dear R Helpers

I am trying to get function smedian.hilow to work using Hmisc summarize
on variable conc in dataframe pkindivmtd by time and dose using:

attach(pkindivmtd)
sconc <- summarize(conc,llist(time,dose),smedian.hilow)

I get the error message

Erreur dans 1:nrow(X) : argument NA / NaN

Contents of pkindivmtd is 

> contents(pkindivmtd)

Data frame:pkindivmtd   1296 observations and 9 variables    Maximum #
NAs:0

                Labels Units Levels Storage
dose              Dose    mg        integer
day                                 integer
hour                                integer
subject        Subject              integer
conc     Concentration ng/mL         double
fday                             10 integer
fsubject                         37 integer
fdose             Dose            4 integer
time              Time hours        integer

.....
> 

What I am doing wrong ?

Sorry for not providing a reproducible example as when I generate
randomly the 3 variables it works ! 

Many thanks,

Jean-Louis



From bambang.pramono at gmail.com  Sat Feb  4 00:33:19 2006
From: bambang.pramono at gmail.com (bambang pramono)
Date: Sat, 4 Feb 2006 06:33:19 +0700
Subject: [R] Tobit Regression
Message-ID: <830480cb0602031533q74ecdd84k@mail.gmail.com>

I'm statistician
I have thesis : Tobit Regression
my book : Greene, William H. 1997. Econometric Analysis. Third
Edition, prentice Hall
Is there the program in R ?
may I ask the manual how make the program? and also how to test the assumption ?
If there are anyone have Amemiya journal may I asked ?

please help me! I already googling and I don't get the answer.
Before i use STATA 6 to analyze. but I don't get the manual.



From choid at ohsu.edu  Sat Feb  4 00:37:50 2006
From: choid at ohsu.edu (Dongseok Choi)
Date: Fri, 03 Feb 2006 15:37:50 -0800
Subject: [R] rgl install problem on Solaris 10 X86
Message-ID: <s3e378d4.064@ohsu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060203/17ed1103/attachment.pl

From murdoch at stats.uwo.ca  Sat Feb  4 01:37:13 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 03 Feb 2006 19:37:13 -0500
Subject: [R] rgl install problem on Solaris 10 X86
In-Reply-To: <s3e378d4.064@ohsu.edu>
References: <s3e378d4.064@ohsu.edu>
Message-ID: <43E3F739.1060002@stats.uwo.ca>

On 2/3/2006 6:37 PM, Dongseok Choi wrote:
> Hi,
>  
>   Could you help me to install the rgl package on Solaris 10 x86?

No, but there have been a lot of changes to it since the last upload to 
CRAN.  You might want to grab a new copy from 
http://rgl.neoscientists.org/About.html by getting the latest Subversion 
checkout.

Duncan Murdoch


>   I tried and got the following error messages.
>   When I compiled my R as 64bit, I used the SUN ProW compilers.
>   However, gcc seems to being used below as well as missing some information.
>  
> Thank you in advance,
> Dongseok
>  
>> install.packages("rgl")
> --- Please select a CRAN mirror for use in this session ---
> * Installing *source* package 'rgl' ...
> checking for gcc... gcc
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ANSI C... none needed
> checking how to run the C preprocessor... gcc -E
> checking for X... libraries /usr/openwin/lib, headers /usr/openwin/include
>  
> checking for libpng-config... yes
> configure: creating ./config.status
> config.status: creating src/Makevars
> ** libs
> CC -xtarget=generic64 -I/export/home/choid/bin/R2.2.1/lib/R/include -I/usr/openwin/include -DHAVE_PNG_H -I/usr/include/libpng12 -I/mounts/devel/SUNWspro/prd/include -I/mounts/devel/GNU/repoz/readline43/include   -KPIC  -O -xlibmil -dalign -I/mounts/devel/SUNWspro/prod/include -c api.cpp -o api.o
> CC: Warning: Option -dalign passed to ld, if ld is invoked, ignored otherwise
> CC -xtarget=generic64 -I/export/home/choid/bin/R2.2.1/lib/R/include -I/usr/openwin/include -DHAVE_PNG_H -I/usr/include/libpng12 -I/mounts/devel/SUNWspro/prd/include -I/mounts/devel/GNU/repoz/readline43/include   -KPIC  -O -xlibmil -dalign -I/mounts/devel/SUNWspro/prod/include -c Background.cpp -o Background.o
> CC: Warning: Option -dalign passed to ld, if ld is invoked, ignored otherwise
> "Background.cpp", line 54: Warning: boundingBox hides Shape::boundingBox.
> 1 Warning(s) detected.
> CC -xtarget=generic64 -I/export/home/choid/bin/R2.2.1/lib/R/include -I/usr/openwin/include -DHAVE_PNG_H -I/usr/include/libpng12 -I/mounts/devel/SUNWspro/prd/include -I/mounts/devel/GNU/repoz/readline43/include   -KPIC  -O -xlibmil -dalign -I/mounts/devel/SUNWspro/prod/include -c BBoxDeco.cpp -o BBoxDeco.o
> CC: Warning: Option -dalign passed to ld, if ld is invoked, ignored otherwise
> CC -xtarget=generic64 -I/export/home/choid/bin/R2.2.1/lib/R/include -I/usr/openwin/include -DHAVE_PNG_H -I/usr/include/libpng12 -I/mounts/devel/SUNWspro/prd/include -I/mounts/devel/GNU/repoz/readline43/include   -KPIC  -O -xlibmil -dalign -I/mounts/devel/SUNWspro/prod/include -c Color.cpp -o Color.oCC: Warning: Option -dalign passed to ld, if ld is invoked, ignored otherwise
> "Color.cpp", line 142: Error: The function "realloc" must have a prototype.
> "Color.cpp", line 159: Error: The function "realloc" must have a prototype.
> "Color.cpp", line 160: Error: The function "memcpy" must have a prototype.
> "Color.cpp", line 168: Error: The function "free" must have a prototype.
> "Color.cpp", line 175: Error: The function "realloc" must have a prototype.
> "Color.cpp", line 196: Error: The function "realloc" must have a prototype.
> "Color.cpp", line 247: Error: The function "realloc" must have a prototype.
> 7 Error(s) detected.
> *** Error code 7
> make: Fatal error: Command failed for target `Color.o'
> ERROR: compilation failed for package 'rgl'
> ** Removing '/export/home/choid/bin/R2.2.1/lib/R/library/rgl'
>  
> The downloaded packages are in
>         /tmp/Rtmp9Yaawc/downloaded_packages
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dpowers at mail.la.utexas.edu  Sat Feb  4 03:58:10 2006
From: dpowers at mail.la.utexas.edu (Dan Powers)
Date: Fri, 3 Feb 2006 20:58:10 -0600
Subject: [R] RHOME
In-Reply-To: <1138981577.2873.58.camel@seurat.iarc.fr>
Message-ID: <LNEJLMFCHNJCEIHBIMHPCEEKCBAA.dpowers@mail.la.utexas.edu>

R-help

My thanks goes out to all who responded to this. I am tying to avoid
burdening the sysadmin with this project so I opted for the simple fix of
modifying the shell script. My aim here is to build the libraries in my
local directory and copy those as needed to /usr/local/lib/R/library. I will
have to direct the sysadmin in the installation of future versions of R.

Cheers,
Dan

%%%%%%%%%%%%%%%%%%%%%%%%
Daniel A. Powers, Ph.D.
Department of Sociology
University of Texas at Austin
1 University Station A1700
Austin, TX  78712-0118
phone: 512-232-6335
fax:   512-471-1748
dpowers at mail.la.utexas.edu


-----Original Message-----
From: Martyn Plummer [mailto:plummer at iarc.fr]
Sent: Friday, February 03, 2006 9:46 AM
To: Peter Dalgaard
Cc: Martin Maechler; Daniel A. Powers; r-help at stat.math.ethz.ch
Subject: Re: [R] RHOME


Far be it for me to tell people what they can and cannot do. Perhaps I
can rephrase myself in a less inflammatory way.

R runs from the build directory as a convenience for developers, so you
don't have to reinstall R every time you change something. But for
users, the standard mechanism "make install" has a number of advantages
over moving the build directory to a publicly accessible location: it is
guaranteed to work, you don't have to do any post-hoc editing of files,
it takes up a lot less space, about 4.6 times less on my system

[martyn at seurat r-devel]$ du -sh R
356M    R
[martyn at seurat r-devel]$ du -sh /usr/local/lib64/R
77M     /usr/local/lib64/R

But if you do want to copy the build directory the, as Martin says,
you can edit the file bin/R so that the line that starts
R_HOME_DIR points to the correct location, e.g.

R_HOME_DIR="/usr/local/lib/R"

M.

On Fri, 2006-02-03 at 14:48 +0100, Peter Dalgaard wrote:
> Martin Maechler <maechler at stat.math.ethz.ch> writes:
>
> >     Martyn> R is designed to run from its build directory.  But
> >     Martyn> if your sysadmin installs it with "make install" (as
> >     Martyn> root), then the shell wrapper that is installed in
> >     Martyn> /usr/local/bin/R will have R_HOME pointing to the
> >     Martyn> right location (/usr/local/lib/R).  Literally moving
> >     Martyn> the build directory to another location is the wrong
> >     Martyn> thing to do.
> >
> > well, but very easily fixable, and that's what Daniel is asking
> > for:
> >
> > The default value of R_HOME is only set in exactly one place,
> > namely the 'R' shell script; editing that script - once after
> > the move - is really a piece o'cake.
>
> Hmm, I was about to say the same, but there seems to be unexpected
> references in other places.
>
> find `R RHOME` | xargs grep `R RHOME`
> /usr/lib64/R/bin/R:R_HOME_DIR=/usr/lib64/R
> /usr/lib64/R/bin/R:R_SHARE_DIR=/usr/lib64/R/share
> /usr/lib64/R/bin/R:R_INCLUDE_DIR=/usr/lib64/R/include
> /usr/lib64/R/bin/R:R_DOC_DIR=/usr/lib64/R/doc
>
> (this doesn't normally happen - a SUSE RPM specialty, or due to
> configure flag settings?)

I think this is normal. But the RedHat RPM behaves differently.

(because the RPM build process installs into a temporary build root
which is distinct from the final installation directory, requiring more
sed voodoo).

>
> Once you start building packages, you also have things like
>
> viggo:~/>find ~/Rlibrary | xargs grep `R RHOME`
> Binary file /home/bs/pd/Rlibrary/rgl/libs/rgl.so matches
>
>
> viggo:~/>find ~/Rlibrary | xargs grep Rlibrary
> Binary file /home/bs/pd/Rlibrary/rgl/Meta/hsearch.rds matches
> Binary file /home/bs/pd/Rlibrary/ISwR/Meta/hsearch.rds matches
> Binary file /home/bs/pd/Rlibrary/mvtnorm/Meta/hsearch.rds matches
> Binary file /home/bs/pd/Rlibrary/nlmeODE/Meta/hsearch.rds matches
> B.....
>
> on my laptop I had a hit on one of the Sweave support files too.
>
> Most likely these are quite harmless, but all in all I think Martyn
> has the safest advice: Use "make install", as root (don't forget
> "umask 022").
>

-----------------------------------------------------------------------
This message and its attachments are strictly confidential. ...{{dropped}}



From spencer.graves at pdf.com  Sat Feb  4 03:55:35 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 03 Feb 2006 18:55:35 -0800
Subject: [R] weights argument in the lmer function in lme4
In-Reply-To: <20060130205116.GV18619@hortresearch.co.nz>
References: <20060130205116.GV18619@hortresearch.co.nz>
Message-ID: <43E417A7.9050901@pdf.com>

	  I agree:  The lmer weights argument seems not to have any effect.  To 
check this, I modified the first example in the "lmer" documentation as 
follows:

Sleep <- sleepstudy
Sleep$wts <- 1:180
(fm1 <- lmer(Reaction ~ Days + (Days|Subject), Sleep))
(fm1w <- lmer(Reaction ~ Days + (Days|Subject),
                      weights=wts, Sleep))

	  The numbers from both seemed to be the same.  To try to help diagnose 
this, I listed "lmer", and found that it consisted of a call to 
"standardGeneric".  Then 'getMethods("lmer")' listed only one "method" 
for the case where the argument "formula" had class "formula".  I tried 
to trace this further, e.g., by giving it a different name and using 
"debug".  After being stopped a couple of time by functions hidden in 
the "Matrix" namespace, I gave ups.

	  However, at least you know that it's not you.  And I've included Doug 
Bates as a "cc" so he can use this info as he sees fit.

	  hope this helps.
	  spencer graves
	
 > sessionInfo()
R version 2.2.1, 2005-12-20, i386-pc-mingw32

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"

other attached packages:
      lme4   lattice    Matrix
"0.995-2" "0.12-11" "0.995-4"
 > 	

Patrick Connolly wrote:

> I suspect the weights argument is not having any effect.
> 
> Package:              Matrix
> Version:              0.995-2
> Date:                 2006-01-19
> 
> 
> Beginning with this:
> 
> Browse[1]>   resp.lmer <- lmer(SensSSC ~ Block + Season + (1 | Plot) + (1 | Ma) + (1 | Pa) + 
> +     (1 | MaPa), weights = SensSSC.N, data = xx)
> 
> I group the output into a table with my ran.eff function and get this:
> 
> Browse[1]> ran.eff(resp.lmer)
>           01     02     03     04     05     06     07   GCAf RankF
> A     13.714 13.709 13.886 14.124 15.120 13.546 14.586  0.472     1
> B     13.452     NA 13.426 13.632 14.439 13.512 13.713  0.069     3
> C     13.922 13.770 14.353     NA 14.661 13.529 14.367  0.453     2
> D         NA     NA 13.353     NA     NA     NA     NA -0.051     4
> E     12.775 12.767 12.823 12.767 14.036 12.631 13.645 -0.495     6
> F     13.043 13.338 12.641 12.977 13.848 12.425 13.530 -0.448     5
> GCAm  -0.200 -0.169 -0.165 -0.103  0.736 -0.428  0.329     NA    NA
> RankM  6.000  5.000  4.000  3.000  1.000  7.000  2.000     NA    NA
> 
> 
> Despite any shortcomings in my ran.eff function, those values look
> alright, but they're the same (to any number of decimal places) as I'd
> get without a weights argument.  Just to check that the weights really
> don't effect it, I tried using only the rows with a weight of 5
> (almost 90% of the data) but it was substantially different.
> 
> Browse[1]>   resp.lmer5 <- lmer(SensSSC ~ Block + Season + (1 | Plot) + (1 | Ma) + (1 | Pa) + 
> +     (1 | MaPa), subset = SensSSC.N == 5, data = xx)
> 
> Browse[1]> ran.eff(resp.lmer5)
>           01     02     03     04     05     06     07   GCAf RankF
> A     13.435 13.349 13.595 13.914 14.722 13.161 14.414  0.345     2
> B     13.068     NA 13.110 13.447 14.121 13.296 13.637 -0.014     4
> C     13.702 13.537 14.256     NA 14.371 13.575 14.247  0.469     1
> D         NA     NA 13.276     NA     NA     NA     NA -0.001     3
> E     12.717 12.659 12.786 12.719 13.642 12.659 13.556 -0.425     6
> F     13.015 13.101 12.549 12.920 13.629 12.438 13.474 -0.374     5
> GCAm  -0.210 -0.230 -0.146 -0.049  0.596 -0.353  0.391     NA    NA
> RankM  5.000  6.000  4.000  3.000  1.000  7.000  2.000     NA    NA
> 
> That seems to indicate that weights cannot be readily ignored.
> 
> Has anyone had experience to indicate that the weights argument does
> produce a difference, and so I should be looking somewhere else for
> the reason why I'm getting such results?
> 
> 
> TIA
>



From spencer.graves at pdf.com  Sat Feb  4 05:31:25 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 03 Feb 2006 20:31:25 -0800
Subject: [R] Density estimation with monotonic constaints
In-Reply-To: <Pine.LNX.4.63.0601311404300.10007@argos.its.yale.edu>
References: <Pine.LNX.4.63.0601311404300.10007@argos.its.yale.edu>
Message-ID: <43E42E1D.1020800@pdf.com>

	  There are multiple functions for density estimation in R, but I don't 
know of any for estimating a "monotonically decreasing density".  If you 
haven't already, I encourage you to use, e.g., the help.search and 
RSiteSearch functions to find and explore their capabililties.

	  Why do you ask?  Are you interested in analyzing particular data 
set(s) or are you doing research on density estimation?

	  If it were my problem, I might just try something like the function 
"density" and then evaluate the results to find out if it satisfied my 
constraints.  If it did and if I were only interested in that data set, 
I'd be done.  If not, I'd increase the smoothing until I got something 
that was monotonic.  If I wanted a more general method, I might wrap a 
call to a function like "density" inside another function, and 
automatically adjust the smoothing until it satisfied some optimality 
criterion I might devise.  If I didn't get what I wanted doing that, I 
might list, e.g., the "density" function and walk through it line by 
line until I figured out what I needed to change to get what I wanted. 
I just listed "density" and found that it consists solely of a call to 
"UseMethod".  To get beyond that, I tried 'methods("density"), which 
told me there was only one "method" called "density.default".  Then 
requesting "density.default" gave me the code for that.  Another tip:  I 
find "debug" extrememly helpeful for walking through code like this.

	  I suspect this will not solve your problem, but I hope at least it 
helps.  If you'd like further assistance from this listserve, please 
submit another post.  However, I encourage you first to PLEASE do read 
the posting guide! "www.R-project.org/posting-guide.html".  Doing so 
might increase your chances for getting useful information more quickly.

	  spencer graves

Debayan Datta wrote:
> Hi All,
>    I have a sample x={x1,x2,..,xn} fom a distribution with density f. I 
> wish to estimate the density. I know a priori that the density is 
> monotonically decreasing. Is there a way to do this in R?
> Thanks
> Debayan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Sat Feb  4 05:50:20 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 03 Feb 2006 20:50:20 -0800
Subject: [R] output hessian matrix in constrOptim
In-Reply-To: <20060201054647.3159.qmail@web34711.mail.mud.yahoo.com>
References: <20060201054647.3159.qmail@web34711.mail.mud.yahoo.com>
Message-ID: <43E4328C.5070902@pdf.com>

	  The documentation for "constrOptim" says it has a "..." argument, 
which can contain "Other arguments passed to 'optim', which will pass 
them to 'f' and 'grad' if it does not used them."  I routinely get an 
estimated "hessian" from 'optim' just by specifying the argument 
'hessian=TRUE'.  This led me to try the following

# an example from 'constrOptim' that works:
      fQP <- function(b) {-sum(c(0,5,0)*b)+0.5*sum(b*b)}
      Amat       <- matrix(c(-4,-3,0,2,1,0,0,-2,1),3,3)
      bvec       <- c(-8,2,0)
      constrOptim(c(2,-1,-1), fQP, NULL, ui=t(Amat),ci=bvec)

# The following generated an error:
constrOptim(c(2,-1,-1), fQP, NULL, ui=t(Amat),ci=bvec,
                     hessian=TRUE)
Error in f(theta, ...) : unused argument(s) (hessian ...)

	  If it were my problem, I might first try 'fit <- constrOptim(...)'. 
Then if the optimum was NOT at a constraint, I'd use the outpt from 
'constrOptim' as an input to "optim" with 'hessian=TRUE'.  If it was at 
a constraint, I'd have to think very carefully about what I wanted in 
terms of a "hessian", because that does not seem obvious to me at the 
moment.  Then I'd program something to get that.  If I wanted more than 
that, I'd list 'constrOptim' and / or 'optim', and walk through them 
line by line using "debug" until I figured out what I wanted to do next.

	  If you'd like more help from this listserve, please submit another 
post -- but first, PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html.

	  hope this helps,
	  spencer graves

liu wrote:

> Hi, 
> 
> Is there any way to get the hessian matrix from the "constrOptim"  
function without supplying gradient function?   Thanks.
> 
> 
> 
> 		
> ---------------------------------
> Bring words and photos together (easily) with
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sskim.box at gmail.com  Sat Feb  4 07:46:59 2006
From: sskim.box at gmail.com (Sung Soo Kim)
Date: Sat, 4 Feb 2006 01:46:59 -0500
Subject: [R] RUnit - need advice on a good directory structure or tips...
Message-ID: <edc66abd0602032246x34b2b9cbkf2a17933a350666c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060204/1a7c375d/attachment.pl

From comtech.usa at gmail.com  Sat Feb  4 09:03:01 2006
From: comtech.usa at gmail.com (Michael)
Date: Sat, 4 Feb 2006 00:03:01 -0800
Subject: [R] R command line: need intelligent command history recall?
Message-ID: <b1f16d9d0602040003y4d0381a4q61c8579a14a366f0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060204/51072101/attachment.pl

From phgrosjean at sciviews.org  Sat Feb  4 09:12:12 2006
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sat, 04 Feb 2006 09:12:12 +0100
Subject: [R] R command line: need intelligent command history recall?
In-Reply-To: <b1f16d9d0602040003y4d0381a4q61c8579a14a366f0@mail.gmail.com>
References: <b1f16d9d0602040003y4d0381a4q61c8579a14a366f0@mail.gmail.com>
Message-ID: <43E461DC.7030406@sciviews.org>

Michael wrote:
> Hi all,
> 
> I am not sure if this feature exists in the R-console command line prompt:
> 
> In Matlab, if I want to enter a command which is similar to what I have
> entered before,
> 
> I can enter a few prefix, then press "->", the previous command that matches
> with this prefix will then appear on this command line, and it saves a lot
> of our time.
> 
> For example:
> 
> 
>>abline(lm(new~old))
>>cor(new, old)
> 
> ...
> ...
> ... many lines entered
> ...
> ...
> 
> now I want to reuse "abline(lm(new~old))",
> 
> R-console provides "->" functionality to recall old commands, but it trace
> back one by one, it is slow if "abline" is way back, say 50 lines above my
> current command line... it is too slow.
> 
> In Matlab, I just need to enter "ab", then press "->", if there is no other
> "ab******" between the "abline" and my current command line, then the
> console will intelligently recall "abline" back to me... Very convinient.
> 
> Does this feature exist in R?
> 
> Any other good Integrated Developement Environment for R?
> 
> Perhaps R users are mathematicians and statisticians; but as a software
> engineer myself, I found a Visual C++-like integrated developement
> environment is really efficient and time-saving. It and Borland C++ Builder
> basically sets standard for modern UI design for programming IDEs.
> 
> To be a good IDE, it really needs to have an embedded inline debugger. I've
> asked a statistician, he said he never debugged using a break-point,
> line-by-line execution debugger -- I cannot imagine this. Where is the
> productivity?
> 
> I've used Tinn-R. Frankly it is quite creative. It solved the line-by-line
> execution problem by copying the line and pasted it to R-console
> automatically. But a lot of times clipboard generates error. And often times
> the copy and paste within Tinn editor itself are problemetic. For example, I
> have been never able to select a portion of a line. When I paste a
> paragraph, it always erases the current line and the following lines,
> instead of inserting, ...  and if I want to select one line, it always
> select two lines for me... etc.
> 
> Anyway, I hope there is IDEs that are better than Tinn-R.
> 
> Thanks a lot!

Please, submit a bug report to Tinn-R authors, if you want to see it 
improved.
Best,

Philippe Grosjean



From ripley at stats.ox.ac.uk  Sat Feb  4 09:20:05 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 4 Feb 2006 08:20:05 +0000 (GMT)
Subject: [R] rgl install problem on Solaris 10 X86
In-Reply-To: <43E3F739.1060002@stats.uwo.ca>
References: <s3e378d4.064@ohsu.edu> <43E3F739.1060002@stats.uwo.ca>
Message-ID: <Pine.LNX.4.61.0602040813550.3714@gannet.stats>

On Fri, 3 Feb 2006, Duncan Murdoch wrote:

> On 2/3/2006 6:37 PM, Dongseok Choi wrote:
>> Hi,
>>
>>   Could you help me to install the rgl package on Solaris 10 x86?
>
> No, but there have been a lot of changes to it since the last upload to
> CRAN.  You might want to grab a new copy from
> http://rgl.neoscientists.org/About.html by getting the latest Subversion
> checkout.

I tried to reproduce this, but our Solaris box does not have GL installed. 
My understanding is that the real problem seems to be that Color.cpp is 
using undeclared ISO C functions and needs to include

#include <stdlib.h> // for realoc and free
#include <string.h> // for memcpy

so please try adding them.

As for the -dalign messages, I presume you included them (like -xlibmil) 
in CXXFLAGS.  They are supported by our SunPro compiler, so which version 
is yours?  (In any case, you need to remove it, if I guessed right.)

>
> Duncan Murdoch
>
>
>>   I tried and got the following error messages.
>>   When I compiled my R as 64bit, I used the SUN ProW compilers.
>>   However, gcc seems to being used below as well as missing some information.
>>
>> Thank you in advance,
>> Dongseok
>>
>>> install.packages("rgl")
>> --- Please select a CRAN mirror for use in this session ---
>> * Installing *source* package 'rgl' ...
>> checking for gcc... gcc
>> checking for C compiler default output file name... a.out
>> checking whether the C compiler works... yes
>> checking whether we are cross compiling... no
>> checking for suffix of executables...
>> checking for suffix of object files... o
>> checking whether we are using the GNU C compiler... yes
>> checking whether gcc accepts -g... yes
>> checking for gcc option to accept ANSI C... none needed
>> checking how to run the C preprocessor... gcc -E
>> checking for X... libraries /usr/openwin/lib, headers /usr/openwin/include
>>
>> checking for libpng-config... yes
>> configure: creating ./config.status
>> config.status: creating src/Makevars
>> ** libs
>> CC -xtarget=generic64 -I/export/home/choid/bin/R2.2.1/lib/R/include -I/usr/openwin/include -DHAVE_PNG_H -I/usr/include/libpng12 -I/mounts/devel/SUNWspro/prd/include -I/mounts/devel/GNU/repoz/readline43/include   -KPIC  -O -xlibmil -dalign -I/mounts/devel/SUNWspro/prod/include -c api.cpp -o api.o
>> CC: Warning: Option -dalign passed to ld, if ld is invoked, ignored otherwise
>> CC -xtarget=generic64 -I/export/home/choid/bin/R2.2.1/lib/R/include -I/usr/openwin/include -DHAVE_PNG_H -I/usr/include/libpng12 -I/mounts/devel/SUNWspro/prd/include -I/mounts/devel/GNU/repoz/readline43/include   -KPIC  -O -xlibmil -dalign -I/mounts/devel/SUNWspro/prod/include -c Background.cpp -o Background.o
>> CC: Warning: Option -dalign passed to ld, if ld is invoked, ignored otherwise
>> "Background.cpp", line 54: Warning: boundingBox hides Shape::boundingBox.
>> 1 Warning(s) detected.
>> CC -xtarget=generic64 -I/export/home/choid/bin/R2.2.1/lib/R/include -I/usr/openwin/include -DHAVE_PNG_H -I/usr/include/libpng12 -I/mounts/devel/SUNWspro/prd/include -I/mounts/devel/GNU/repoz/readline43/include   -KPIC  -O -xlibmil -dalign -I/mounts/devel/SUNWspro/prod/include -c BBoxDeco.cpp -o BBoxDeco.o
>> CC: Warning: Option -dalign passed to ld, if ld is invoked, ignored otherwise
>> CC -xtarget=generic64 -I/export/home/choid/bin/R2.2.1/lib/R/include -I/usr/openwin/include -DHAVE_PNG_H -I/usr/include/libpng12 -I/mounts/devel/SUNWspro/prd/include -I/mounts/devel/GNU/repoz/readline43/include   -KPIC  -O -xlibmil -dalign -I/mounts/devel/SUNWspro/prod/include -c Color.cpp -o Color.oCC: Warning: Option -dalign passed to ld, if ld is invoked, ignored otherwise
>> "Color.cpp", line 142: Error: The function "realloc" must have a prototype.
>> "Color.cpp", line 159: Error: The function "realloc" must have a prototype.
>> "Color.cpp", line 160: Error: The function "memcpy" must have a prototype.
>> "Color.cpp", line 168: Error: The function "free" must have a prototype.
>> "Color.cpp", line 175: Error: The function "realloc" must have a prototype.
>> "Color.cpp", line 196: Error: The function "realloc" must have a prototype.
>> "Color.cpp", line 247: Error: The function "realloc" must have a prototype.
>> 7 Error(s) detected.
>> *** Error code 7
>> make: Fatal error: Command failed for target `Color.o'
>> ERROR: compilation failed for package 'rgl'
>> ** Removing '/export/home/choid/bin/R2.2.1/lib/R/library/rgl'
>>
>> The downloaded packages are in
>>         /tmp/Rtmp9Yaawc/downloaded_packages
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Feb  4 10:20:45 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 4 Feb 2006 09:20:45 +0000 (GMT)
Subject: [R] R command line: need intelligent command history recall?
In-Reply-To: <b1f16d9d0602040003y4d0381a4q61c8579a14a366f0@mail.gmail.com>
References: <b1f16d9d0602040003y4d0381a4q61c8579a14a366f0@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0602040822520.3714@gannet.stats>

I guess you are using Windows, as you do not tell us.

History search facilities are available in Rterm.exe, and also in readline 
as used in the interface on Unix-alikes.  Many people use Emacs+ESS.  (In 
all cases I think the search mode is slicker than you describe for 
Matlab.) And RGui has another mechanism (read on) that is more suited to a 
GUI.

If you would like a history search in RGui.exe, please contribute the code 
to do so.  R is a volunteer project, and this was deliberately not 
implemented as no Windows user expressed an interest.

I think you will find `the productivity' is in using a higher-level 
language than C.  R does have a line-by-line debugger (called debug, so 
not hard to find).  If you want to set breakpoints etc, see package 
`debug' on CRAN.  And the `Writing R Extensions' manual in the R-devel 
version of R (to become 2.3.0) has a chapter on `Debugging'.

I teach 50 or so people to use R/S a year.  They end up with different 
patterns of working.  Some use script windows all the time, some use 
Emacs+ESS, some use a Linux command line/Rterm.exe.  I believe it is a 
mistake to think that `one size fits all'.

On Sat, 4 Feb 2006, Michael wrote:

> Hi all,
>
> I am not sure if this feature exists in the R-console command line prompt:
>
> In Matlab, if I want to enter a command which is similar to what I have
> entered before,
>
> I can enter a few prefix, then press "->", the previous command that matches
> with this prefix will then appear on this command line, and it saves a lot
> of our time.
>
> For example:
>
>> abline(lm(new~old))
>> cor(new, old)
> ...
> ...
> ... many lines entered
> ...
> ...
>
> now I want to reuse "abline(lm(new~old))",

Try history().  This pops up a window from which you can submit one or 
more command lines (or parts of lines).

> R-console provides "->" functionality to recall old commands, but it trace
> back one by one, it is slow if "abline" is way back, say 50 lines above my
> current command line... it is too slow.
>
> In Matlab, I just need to enter "ab", then press "->", if there is no other
> "ab******" between the "abline" and my current command line, then the
> console will intelligently recall "abline" back to me... Very convinient.
>
> Does this feature exist in R?

Yes.

> Any other good Integrated Developement Environment for R?
>
> Perhaps R users are mathematicians and statisticians; but as a software
> engineer myself, I found a Visual C++-like integrated developement
> environment is really efficient and time-saving. It and Borland C++ Builder
> basically sets standard for modern UI design for programming IDEs.

That is a matter of opinion.  If you want us to accept your opinion, you 
need to give your credentials, and you haven't even told us your name and 
affiliation.

> To be a good IDE, it really needs to have an embedded inline debugger. I've
> asked a statistician, he said he never debugged using a break-point,
> line-by-line execution debugger -- I cannot imagine this. Where is the
> productivity?
>
> I've used Tinn-R. Frankly it is quite creative. It solved the line-by-line
> execution problem by copying the line and pasted it to R-console
> automatically. But a lot of times clipboard generates error. And often times
> the copy and paste within Tinn editor itself are problemetic. For example, I
> have been never able to select a portion of a line. When I paste a
> paragraph, it always erases the current line and the following lines,
> instead of inserting, ...  and if I want to select one line, it always
> select two lines for me... etc.
>
> Anyway, I hope there is IDEs that are better than Tinn-R.
>
> Thanks a lot!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mikael.anderson at gmail.com  Sat Feb  4 10:43:39 2006
From: mikael.anderson at gmail.com (Mikael Anderson)
Date: Sat, 4 Feb 2006 20:43:39 +1100
Subject: [R] Permanent assignments
Message-ID: <bdc992b40602040143p57007a89y4c433d36dfcb2569@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060204/5a920fa5/attachment.pl

From ripley at stats.ox.ac.uk  Sat Feb  4 10:58:32 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 4 Feb 2006 09:58:32 +0000 (GMT)
Subject: [R] Permanent assignments
In-Reply-To: <bdc992b40602040143p57007a89y4c433d36dfcb2569@mail.gmail.com>
References: <bdc992b40602040143p57007a89y4c433d36dfcb2569@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0602040951290.5651@gannet.stats>

On Sat, 4 Feb 2006, Mikael Anderson wrote:

> I was wondering if it is possible to have permanent assignments in R pretty
> much in the same sense that S-Plus works.

It is not possible (a consequence of the scoping differences is that R 
objects are not self-contained).  If you want S-PLUS, you know where to 
get it.

> The reason I am asking this is that I was trying to load a FORTRAN 
> subroutine to R and for some reason it didn't work and R crashed and I 
> lost everything which I hadn't saved with save.image() or other similar 
> functions. I tried adding on.exit(save.image()) to .Last() but it seems 
> that if R crashes it doesn't get executed either.

Take a look at the R-devel version of R.  That has a signal handler that
allows you to save your work when it catches a segfault etc.  Or you could 
ensure that you call save.image() before doing anything error-prone.

> I am not saying that this should be the default behaviour in R but I was
> wondering if one could  have this as an option in R as well.
>
> /Mikael
>
> PS. In case it matters, I run R 2.2.1 under sparc-sun-solaris2.9.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at gmail.com  Sat Feb  4 11:03:48 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 4 Feb 2006 05:03:48 -0500
Subject: [R] Permanent assignments
In-Reply-To: <bdc992b40602040143p57007a89y4c433d36dfcb2569@mail.gmail.com>
References: <bdc992b40602040143p57007a89y4c433d36dfcb2569@mail.gmail.com>
Message-ID: <971536df0602040203u59072b8fo61c4ab3cd57d408a@mail.gmail.com>

You may be able to get checkpoint software that will periodically
save the state of the computer, including memory, allowing you
to roll back to any point.   That would not be R specific.  I don't
know specifically where to get it but maybe someone else knows
of or uses such software.

On 2/4/06, Mikael Anderson <mikael.anderson at gmail.com> wrote:
> I was wondering if it is possible to have permanent assignments in R pretty
> much in the same sense that S-Plus works.The reason I am asking this is that
> I was  trying to load  a FORTRAN subroutine to R and for some reason it
> didn't work and R crashed and I lost everything which I hadn't saved with
> save.image() or other similar functions. I tried adding on.exit(save.image())
> to .Last() but it seems that if R crashes it doesn't get executed either.
>
> I am not saying that this should be the default behaviour in R but I was
> wondering if one could  have this as an option in R as well.
>
> /Mikael
>
> PS. In case it matters, I run R 2.2.1 under sparc-sun-solaris2.9.
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From pburns at pburns.seanet.com  Sat Feb  4 12:40:40 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 04 Feb 2006 11:40:40 +0000
Subject: [R] all.equal() and which()
In-Reply-To: <1138981260.4488.4.camel@localhost.localdomain>
References: <1138981260.4488.4.camel@localhost.localdomain>
Message-ID: <43E492B8.6080509@pburns.seanet.com>

How about

which(abs(time(data) - 24.211) < 1e-7)

or the tolerance of your choice.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

tom wright wrote:

>Please excuse the lack of a complete dataset here, if its needed I'll be
>happy to provide it.
>Can anyone show me how to rewrite this?
>
>Browse[1]> time(data)[24210:24220]
>[1] 24.209 24.210 24.211 24.212 24.213 24.214 24.215 24.216 24.217 
>[10] 24.218 24.219
>
>Browse[1]> which(time(data)==24.211)
>numeric(0)
>
>I'm assuming its an eps fault but
>which(all.equal(time(data),24.211))
>
>dosnt seem to work
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From stevenmh at muohio.edu  Sat Feb  4 13:17:38 2006
From: stevenmh at muohio.edu (Martin Henry H. Stevens)
Date: Sat, 4 Feb 2006 07:17:38 -0500
Subject: [R] workspace question
In-Reply-To: <6BCB4D493A447546A8126F24332056E8027C8BF9@school1.business.edu>
References: <6BCB4D493A447546A8126F24332056E8027C8BF9@school1.business.edu>
Message-ID: <2D4FDF5E-51E6-47A2-887D-97899463DB49@muohio.edu>

Hi Dave,
Look at "save" in Help. R automatically loads the workspace called  
".Rdata" at the beginning of a session. You could rename workspace,  
and load or save whatever you like.
Hank
On Feb 3, 2006, at 11:20 AM, Afshartous, David wrote:

>
> All,
>
> When starting R, how does one prevent the loading the previous
> workspace which was saved?  I'd like to start a new project
> and save the new image in a different directory, but I'd like to
> partition this from the old project.  Does there exist a better
> way than just deleting the files associated w/ the old project
> manually?  I looked in the Intro to R manual and searched for
> "workspace" and didn't see anything on this aspect.
>
> Kind regards,
> Dave
>
> ps - please reply directly to afshar at miami.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html



From stevenmh at muohio.edu  Sat Feb  4 13:22:40 2006
From: stevenmh at muohio.edu (Martin Henry H. Stevens)
Date: Sat, 4 Feb 2006 07:22:40 -0500
Subject: [R] Glossay of available R functions
In-Reply-To: <wkvew1e16o.fsf@connact.com>
References: <200601302031.k0UKVGob001618@hypatia.math.ethz.ch>
	<43DE78E7.5040209@optonline.net>
	<200601301900.50123.asaguiar@spsconsultoria.com>
	<wkvew1e16o.fsf@connact.com>
Message-ID: <68AC17E6-6784-4D77-9C21-78536223CD99@muohio.edu>

Hi Patricia and Alexandre,
Start R help, and select the Search Engine & Keywords link. This will  
take you to a page where keywords (including functions) are arranged  
by topic. It includes base and "recommended" packages. Also not that  
on the CRAN website (and mirrors) is a link for Task Views. There,  
packages are grouped by topic.
Hank
On Jan 30, 2006, at 6:38 PM, Patricia J. Hawkins wrote:

>>>>>> "ASA" == Alexandre Santos Aguiar <asaguiar at spsconsultoria.com>  
>>>>>> writes:
>
> ASA> I am new to R and read this list to learn. It is amazing how
> ASA> frequently new functions pop in messages. Useful and timesaving
> ASA> functions like subset (above) must be documented somewhere.
>
> ASA> Is there a glossary of functions?
>
> I'm also new to R, and was wondering the same thing.  Took a bunch of
> tries, but if you run start.help() and then choose Packages, then
> Base, you will get the list of functions.
>
> As a newcomer, I hesitate to suggest this, but maybe there should be a
> comment on the index page to that effect?
>
> -- 
> Patricia J. Hawkins
> Hawkins Internet Applications
> www.hawkinsia.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html



From murdoch at stats.uwo.ca  Sat Feb  4 15:01:47 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 04 Feb 2006 09:01:47 -0500
Subject: [R] R command line: need intelligent command history recall?
In-Reply-To: <b1f16d9d0602040003y4d0381a4q61c8579a14a366f0@mail.gmail.com>
References: <b1f16d9d0602040003y4d0381a4q61c8579a14a366f0@mail.gmail.com>
Message-ID: <43E4B3CB.3040701@stats.uwo.ca>

On 2/4/2006 3:03 AM, Michael wrote:
> Hi all,
> 
> I am not sure if this feature exists in the R-console command line prompt:
> 
> In Matlab, if I want to enter a command which is similar to what I have
> entered before,
> 
> I can enter a few prefix, then press "->", the previous command that matches
> with this prefix will then appear on this command line, and it saves a lot
> of our time.
> 
> For example:
> 
>> abline(lm(new~old))
>> cor(new, old)
> ...
> ...
> ... many lines entered
> ...
> ...
> 
> now I want to reuse "abline(lm(new~old))",
> 
> R-console provides "->" functionality to recall old commands, but it trace
> back one by one, it is slow if "abline" is way back, say 50 lines above my
> current command line... it is too slow.
> 
> In Matlab, I just need to enter "ab", then press "->", if there is no other
> "ab******" between the "abline" and my current command line, then the
> console will intelligently recall "abline" back to me... Very convinient.
> 
> Does this feature exist in R?
> 
> Any other good Integrated Developement Environment for R?
> 
> Perhaps R users are mathematicians and statisticians; but as a software
> engineer myself, I found a Visual C++-like integrated developement
> environment is really efficient and time-saving. It and Borland C++ Builder
> basically sets standard for modern UI design for programming IDEs.
> 
> To be a good IDE, it really needs to have an embedded inline debugger. I've
> asked a statistician, he said he never debugged using a break-point,
> line-by-line execution debugger -- I cannot imagine this. Where is the
> productivity?

Writing such a thing is a little tricky, but should be possible if 
someone devotes enough time to it.  A couple of issues are:

  - R source code currently maintains no connection to the file it came 
from.  That would need to be added for a source level debugger.

  - Not all R functions come from source code in a file; they may have 
been entered at the console, produced as the result returned by another 
function, etc.

  - Such IDEs tend to be very platform-specific.  You can do a lot of 
work to make a nice IDE on Windows, and not be able to re-use much of it 
in other platforms.

Currently I don't know of anyone actively working on such a thing.  I 
agree with you that source-level IDEs are great for productivity, and 
I'd probably switch to one if someone else wrote it.  However, I am 
unlikely to ever have time to do the work myself.

Duncan Murdoch

> 
> I've used Tinn-R. Frankly it is quite creative. It solved the line-by-line
> execution problem by copying the line and pasted it to R-console
> automatically. But a lot of times clipboard generates error. And often times
> the copy and paste within Tinn editor itself are problemetic. For example, I
> have been never able to select a portion of a line. When I paste a
> paragraph, it always erases the current line and the following lines,
> instead of inserting, ...  and if I want to select one line, it always
> select two lines for me... etc.
> 
> Anyway, I hope there is IDEs that are better than Tinn-R.
> 
> Thanks a lot!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jporzak at gmail.com  Sat Feb  4 16:49:16 2006
From: jporzak at gmail.com (Jim Porzak)
Date: Sat, 4 Feb 2006 07:49:16 -0800
Subject: [R] Glossay of available R functions
In-Reply-To: <wkvew1e16o.fsf@connact.com>
References: <200601302031.k0UKVGob001618@hypatia.math.ethz.ch>
	<43DE78E7.5040209@optonline.net>
	<200601301900.50123.asaguiar@spsconsultoria.com>
	<wkvew1e16o.fsf@connact.com>
Message-ID: <2a9c000c0602040749u2a7b83d9i3058d87d280603c1@mail.gmail.com>

Alexandre & Patricia,

As Bert Gunter periodically points out:
"Newbies (and others!) may find useful the R Reference Card made available by
Tom Short and Rpad at http://www.rpad.org/Rpad/Rpad-refcard.pdf  or through
the "Contributed" link on CRAN (where some other reference cards are also
linked). It categorizes and organizes a bunch of R's basic, most used
functions so that they can be easily found. For example, paste() is under
the "Strings" heading and expand.grid() is under "Data Creation." For
newbies struggling to find the right R function as well as veterans who
can't quite remember the function name, it's very handy."

I still keep a hard copy of Tom Short's referncece card handy, as do
most of my colleagues at Loyalty Matrix.

--
HTH,
Jim Porzak
Loyalty Matrix Inc.
San Francisco, CA

On 1/30/06, Patricia J. Hawkins <phawkins at connact.com> wrote:
> >>>>> "ASA" == Alexandre Santos Aguiar <asaguiar at spsconsultoria.com> writes:
>
> ASA> I am new to R and read this list to learn. It is amazing how
> ASA> frequently new functions pop in messages. Useful and timesaving
> ASA> functions like subset (above) must be documented somewhere.
>
> ASA> Is there a glossary of functions?
>
> I'm also new to R, and was wondering the same thing.  Took a bunch of
> tries, but if you run start.help() and then choose Packages, then
> Base, you will get the list of functions.
>
> As a newcomer, I hesitate to suggest this, but maybe there should be a
> comment on the index page to that effect?
>
> --
> Patricia J. Hawkins
> Hawkins Internet Applications
> www.hawkinsia.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From erich.neuwirth at univie.ac.at  Sat Feb  4 19:28:02 2006
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Sat, 04 Feb 2006 19:28:02 +0100
Subject: [R] functional programming question
Message-ID: <43E4F232.6090209@univie.ac.at>

Many functional programming languages have a metafunction
which does the following:
it has two arguments, a function and a list of objects, all of the same
type.
The argument function itself has two arguments of the same type as all
the list objects, and the result of this function also is of the same type.
then
metafunction(f,list(x1,x2,....xn)) produces
f(x1,f(x2,f(x3,....,f(xn-1,xn)))..)
Does R have such a function, or do I need to code it myself?
In Scheme (Mathematica), this metafunction is called fold (Fold).


-- 
Erich Neuwirth, University of Vienna
Faculty of Computer Science
Computer Supported Didactics Working Group
Visit our SunSITE at http://sunsite.univie.ac.at
Phone: +43-1-4277-39464 Fax: +43-1-4277-39459



From ggrothendieck at gmail.com  Sat Feb  4 19:34:07 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 4 Feb 2006 13:34:07 -0500
Subject: [R] functional programming question
In-Reply-To: <43E4F232.6090209@univie.ac.at>
References: <43E4F232.6090209@univie.ac.at>
Message-ID: <971536df0602041034s6d4b00c3s7590a93fbbc47ec9@mail.gmail.com>

See:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/54896.html

On 2/4/06, Erich Neuwirth <erich.neuwirth at univie.ac.at> wrote:
> Many functional programming languages have a metafunction
> which does the following:
> it has two arguments, a function and a list of objects, all of the same
> type.
> The argument function itself has two arguments of the same type as all
> the list objects, and the result of this function also is of the same type.
> then
> metafunction(f,list(x1,x2,....xn)) produces
> f(x1,f(x2,f(x3,....,f(xn-1,xn)))..)
> Does R have such a function, or do I need to code it myself?
> In Scheme (Mathematica), this metafunction is called fold (Fold).
>
>
> --
> Erich Neuwirth, University of Vienna
> Faculty of Computer Science
> Computer Supported Didactics Working Group
> Visit our SunSITE at http://sunsite.univie.ac.at
> Phone: +43-1-4277-39464 Fax: +43-1-4277-39459
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Sat Feb  4 20:44:31 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 04 Feb 2006 11:44:31 -0800
Subject: [R] Passing additional paramaters to nlsList(nlme) fit function
In-Reply-To: <LPEJLJACLINDNMBMFAFIKEBJCCAA.dieter.menne@menne-biomed.de>
References: <LPEJLJACLINDNMBMFAFIKEBJCCAA.dieter.menne@menne-biomed.de>
Message-ID: <43E5041F.2020007@pdf.com>

	  The "nlsList" function does NOT have the common ellipsis ("..." ) 
argument to support that.

	  An alternative is use "vector" to create an object of mode "list" of 
the desired length, then in a loop call "nls" (which does support "...") 
and store the results in a list.  However, this won't produce an object 
of class "nlsList", which means that the methods writted for "nlsList" 
will not be available to you.

	  If it were my problem, I might make a local copy of the "nlsList" 
function and try to modify it to work, at least for my problem.  In this 
case, "nlsList" is merely a call to "UseMethods".  To get beyond that, I 
requested 'methods("nlsList")' with the following result:

	  nlsList.formula    nlsList.selfStart*

	  If you supply your own starting values, you don't need 
"nlsList.selfStart".  If you do need it, you can get it via 
'getAnywhere("nlsList.selfStart")';  the asterisk ("*") says that this 
function is "non-visible", which means that just typing its name won't 
get it.  Then I might use "debug" to figure out what it's doing and what 
I want to change.

	  hope this helps.
	  spencer graves

Dieter Menne wrote:

> Hello, nls-users,
> 
> is it possible to pass additional parameters to the model function that are
> known and groupwise constant with nlsList? I could not find something like a
> "keep this fixed" option in the documentation and the code (my fault...?)
> 
> The current workaround is to break the problem down into groups and use
> globals to pass the constant parameters, but it is ugly code and won't work
> when an over-all nlme is needed.
> 
> Dieter Menne
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Ted.Harding at nessie.mcc.ac.uk  Sat Feb  4 20:47:49 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 04 Feb 2006 19:47:49 -0000 (GMT)
Subject: [R] Refreshing X11 plots
Message-ID: <XFMail.060204194749.Ted.Harding@nessie.mcc.ac.uk>

Hi Folks,

This question (or very similar) seems to have been
asked before, acorsding to R Site Search:

Timur Elzhov on June 23 2003
David B. Dahl on March 01 2002
(though the latter appears to have date April 10 2003 according
to the search result, but the above is the archive date).

Situation: I plot a lot of stuff in an X11 window (device #2),
and then with X11() open a new X11 wibdow (device #3) and plot
a lot of similar stuff. So, at this stage, device 3 is active.

Now I move away from that screen (switching to a different
"desktop"), to do something else; and when I move back to
where I was the "active" display (#3) refreshes itself, but
the "inactive" one (#2) is blank and I have found no trick to
get it to refresh itself short of replaying all the commands
needed to draw the plot in the first place.

This is a similar issue to the one stated in the two mails referred
to above, neither of which seems to have received an answer.

Is there a way to refresh the plot without re-plotting it from
scratch? (R on Linux with X11).

With thanks, and best wishes to all,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 04-Feb-06                                       Time: 19:47:42
------------------------------ XFMail ------------------------------



From Ted.Harding at nessie.mcc.ac.uk  Sat Feb  4 21:11:21 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 04 Feb 2006 20:11:21 -0000 (GMT)
Subject: [R] Refreshing X11 plots
In-Reply-To: <XFMail.060204194749.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <XFMail.060204201121.Ted.Harding@nessie.mcc.ac.uk>

Correction to description: see below.

On 04-Feb-06 Ted Harding wrote:
> Hi Folks,
> 
> This question (or very similar) seems to have been
> asked before, acorsding to R Site Search:
> 
> Timur Elzhov on June 23 2003
> David B. Dahl on March 01 2002
> (though the latter appears to have date April 10 2003 according
> to the search result, but the above is the archive date).
> 
> Situation: I plot a lot of stuff in an X11 window (device #2),
> and then with X11() open a new X11 wibdow (device #3) and plot
> a lot of similar stuff. So, at this stage, device 3 is active.
> 
> Now I move away from that screen (switching to a different
> "desktop"), to do something else; and when I move back to
> where I was the "active" display (#3) refreshes itself, but
> the "inactive" one (#2) is blank and I have found no trick to
> get it to refresh itself short of replaying all the commands
> needed to draw the plot in the first place.

In fact it is apparently the plot on device #2 (the first device
opened) which refreshes itself, and the second plot (on device #3)
which goes blank and stays blank, regardless of the order in which
the plots are created and which device is currently active. Apologies!

> This is a similar issue to the one stated in the two mails referred
> to above, neither of which seems to have received an answer.
> 
> Is there a way to refresh the plot without re-plotting it from
> scratch? (R on Linux with X11).
> 
> With thanks, and best wishes to all,
> Ted.
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 04-Feb-06                                       Time: 19:47:42
> ------------------------------ XFMail ------------------------------

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 04-Feb-06                                       Time: 20:11:18
------------------------------ XFMail ------------------------------



From ivowel at gmail.com  Sat Feb  4 21:28:24 2006
From: ivowel at gmail.com (ivo welch)
Date: Sat, 4 Feb 2006 15:28:24 -0500
Subject: [R] srt relative to figure
Message-ID: <50d1c22d0602041228l6f09161cn49a591c25e014a6b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060204/9c5a7c9f/attachment.pl

From dieter.menne at menne-biomed.de  Sat Feb  4 21:29:36 2006
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Sat, 4 Feb 2006 20:29:36 +0000 (UTC)
Subject: [R] Passing additional paramaters to nlsList(nlme) fit function
References: <LPEJLJACLINDNMBMFAFIKEBJCCAA.dieter.menne@menne-biomed.de>
	<43E5041F.2020007@pdf.com>
Message-ID: <loom.20060204T212030-57@post.gmane.org>

Original question...

> > is it possible to pass additional parameters to the model function that are
> > known and groupwise constant with nlsList? I could not find something like a
> > "keep this fixed" option in the documentation and the code (my fault...?)

Spencer Graves <spencer.graves <at> pdf.com> writes:

> 
> 	  The "nlsList" function does NOT have the common ellipsis ("..." ) 
> argument to support that.
...
> 	  If it were my problem, I might make a local copy of the "nlsList" 
> function and try to modify it to work, at least for my problem.  In this 
> case, "nlsList" is merely a call to "UseMethods".  To get beyond that, I 
> requested 'methods("nlsList")' with the following result:
> 
> 	  nlsList.formula    nlsList.selfStart*

Thanks, Spencer. When I studied the quinModel example (page 380, 
Pinheiro/Bates) I noted that it is possible to pass non-varying parameters to 
nlme by not including them in the fixed=... parameter. As quite a few examples 
in PB used nlsList for the first approximation (and, as far I understand, nlme 
does it internally anyway) I had missed this feature of nlme, even if the PB-
book heavily use-stained.

Dieter



From ivowel at gmail.com  Sat Feb  4 21:50:21 2006
From: ivowel at gmail.com (ivo welch)
Date: Sat, 4 Feb 2006 15:50:21 -0500
Subject: [R] srt --- slope text with function?
Message-ID: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>

[resent, plus small addition; I do not understand why gmail sent a
weird charset.]

Dear R wizards:

I would love to write a general function that matches the slope of a plotted
line in an xy-plot at a particular x,y location.  something like

   x<- (1:10)^2; y<- 40:50;
   plot( x,y, type="l", xlim=c(0,90) )
   srt.at5 = text.at.current.plot.with.slope( x, y,  5);
   text( x[5],y[5], pos=3, srt=srt.at.5);

to do this, I first need to compute the function slope around x[5], which is
an easy task.  alas, the harder task is that I need to scale this by the
plot aspect ratio and the axes.  How can a function read this from the
current plot?

(Has someone written such a function, perhaps more embellished, to save me
the debugging effort?)

Or, is there an alternative to srt, which slopes the text relative to the
existing scale?

  *** come to think of it, what I would really like is the ability of
text to 'snake' itself along the line itself.  I doubt that this is
easily possible, but I just wanted to ask.

help appreciated.

sincerely,

/ivo welch



From andrej.kastrin at siol.net  Sat Feb  4 21:50:43 2006
From: andrej.kastrin at siol.net (Andrej Kastrin)
Date: Sat, 04 Feb 2006 21:50:43 +0100
Subject: [R] image() and text
Message-ID: <43E513A3.8010406@siol.net>

Dear useRs,

I have 44 symmetrical matrix ; then I use

image(log(my.matrix)) to visualise it.

Is there any 'simple' way to add text labels into each cell lie on 
diagonal of the image plot? Thanks for any pointers...

Cheers, Andrej



From murdoch at stats.uwo.ca  Sat Feb  4 22:19:59 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 04 Feb 2006 16:19:59 -0500
Subject: [R] srt --- slope text with function?
In-Reply-To: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>
References: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>
Message-ID: <43E51A7F.8080002@stats.uwo.ca>

On 2/4/2006 3:50 PM, ivo welch wrote:
> [resent, plus small addition; I do not understand why gmail sent a
> weird charset.]
> 
> Dear R wizards:
> 
> I would love to write a general function that matches the slope of a plotted
> line in an xy-plot at a particular x,y location.  something like
> 
>    x<- (1:10)^2; y<- 40:50;
>    plot( x,y, type="l", xlim=c(0,90) )
>    srt.at5 = text.at.current.plot.with.slope( x, y,  5);
>    text( x[5],y[5], pos=3, srt=srt.at.5);
> 
> to do this, I first need to compute the function slope around x[5], which is
> an easy task.  alas, the harder task is that I need to scale this by the
> plot aspect ratio and the axes.  How can a function read this from the
> current plot?

I haven't done this, but you can presumably work it out from the 
conversions implied by the "fig", "fin", "plt", and/or "usr" values.
> 
> (Has someone written such a function, perhaps more embellished, to save me
> the debugging effort?)
> 
> Or, is there an alternative to srt, which slopes the text relative to the
> existing scale?
> 
>   *** come to think of it, what I would really like is the ability of
> text to 'snake' itself along the line itself.  I doubt that this is
> easily possible, but I just wanted to ask.

Using strsplit and strwidth you should be able to do it, but it will 
probably look quite ugly.

Duncan Murdoch



From ivowel at gmail.com  Sat Feb  4 23:19:45 2006
From: ivowel at gmail.com (ivo welch)
Date: Sat, 4 Feb 2006 17:19:45 -0500
Subject: [R] srt --- slope text with function?
In-Reply-To: <43E51A7F.8080002@stats.uwo.ca>
References: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>
	<43E51A7F.8080002@stats.uwo.ca>
Message-ID: <50d1c22d0602041419y46761eb1x4f41fc82a5da9b60@mail.gmail.com>

Thank you, Duncan.  This led me to the info I needed.  Here is a
simple utility function that does what I needed---maybe it will come
in helpful for others.

################################################################
#### native.slope computes a suitable srt from a function around
#### a point on a function.  This is useful until text() gets
#### an srt parameter that is relative to the coordinate system.
####   (Ideally, R would be able to slope along a function.)
################################################################

native.slope <- function( x, y, where.i,
			 xlim = par()$xaxp, ylim= par()$yaxp,
			 asp.ratio = (par()$fin)[1]/(par()$fin)[2] ) {
  if (where.i<=1) { return(0); }
  if (where.i>=length(y)) { return(0); }
  if (length(x)!=length(y)) {
    stop("native.slope: Sorry, but x and y must have equal dimensions,
not ", length(x), " and ", length(y), "\n"); }

  # native slope in a 1:1 coordinate system
  d= ( (y[where.i-1]-y[where.i+1])/(x[where.i-1]-x[where.i+1]) );
  if (is.na(d)) return(0); # we do not know how to handle an undefined
spot at a function!

  d.m= (ylim[2]-ylim[1])/(xlim[2]-xlim[1]); # now adjust by the axis scale
  if (is.na(d)) stop("native.slope: internal error, I do not have
sensible axis dimensions (", xlim, ylim, ")\n");

  if (is.na(asp.ratio)) stop("native.slope: internal error, I do not
have a reasonable drawing aspect ratio");

  net.slope= d/asp.ratio/d.m;
  return(slope = atan(net.slope)/pi*180.0 )
}


# some test code
x<- seq(-10,20,by=0.1)
y<- x*x;

plot( x, y, type="l" );

display= ((1:length(y))%%40 == 0)

for (i in 1:(length(y))) {
  if (display[i]) {
    points(x[i],y[i], pch=19);
    srt= native.slope( x, y, i );
    text( x[i], y[i], paste(i,"=",x[i],"=",srt), srt=srt, cex=0.9 );
  }
}



On 2/4/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 2/4/2006 3:50 PM, ivo welch wrote:
> > [resent, plus small addition; I do not understand why gmail sent a
> > weird charset.]
> >
> > Dear R wizards:
> >
> > I would love to write a general function that matches the slope of a plotted
> > line in an xy-plot at a particular x,y location.  something like
> >
> >    x<- (1:10)^2; y<- 40:50;
> >    plot( x,y, type="l", xlim=c(0,90) )
> >    srt.at5 = text.at.current.plot.with.slope( x, y,  5);
> >    text( x[5],y[5], pos=3, srt=srt.at.5);
> >
> > to do this, I first need to compute the function slope around x[5], which is
> > an easy task.  alas, the harder task is that I need to scale this by the
> > plot aspect ratio and the axes.  How can a function read this from the
> > current plot?
>
> I haven't done this, but you can presumably work it out from the
> conversions implied by the "fig", "fin", "plt", and/or "usr" values.
> >
> > (Has someone written such a function, perhaps more embellished, to save me
> > the debugging effort?)
> >
> > Or, is there an alternative to srt, which slopes the text relative to the
> > existing scale?
> >
> >   *** come to think of it, what I would really like is the ability of
> > text to 'snake' itself along the line itself.  I doubt that this is
> > easily possible, but I just wanted to ask.
>
> Using strsplit and strwidth you should be able to do it, but it will
> probably look quite ugly.
>
> Duncan Murdoch
>



From ivowel at gmail.com  Sun Feb  5 00:02:22 2006
From: ivowel at gmail.com (ivo welch)
Date: Sat, 4 Feb 2006 18:02:22 -0500
Subject: [R] srt --- slope text with function?
In-Reply-To: <50d1c22d0602041419y46761eb1x4f41fc82a5da9b60@mail.gmail.com>
References: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>
	<43E51A7F.8080002@stats.uwo.ca>
	<50d1c22d0602041419y46761eb1x4f41fc82a5da9b60@mail.gmail.com>
Message-ID: <50d1c22d0602041502g48841217nd39e1f9814a218ba@mail.gmail.com>

Some more experimentation reveals that I need to also adjust for the
plot dimensions.  (And there are other issues I probably do not know
yet and totally misprogrammed...just trying to be helpful.)

native.slope <- function( x, y, where.i,
			 xlim = par()$xaxp, ylim= par()$yaxp,
			 asp.ratio = (par()$fin)[1]/(par()$fin)[2],
			 debug =0) {
  if (where.i<=1) { return(0); }
  if (where.i>=length(y)) { return(0); }
  if (length(x)!=length(y)) {
    stop("native.slope: Sorry, but x and y must have equal dimensions,
not ", length(x), " and ", length(y), "\n"); }

  # native slope in a 1:1 coordinate system
  d= ( (y[where.i-1]-y[where.i+1])/(x[where.i-1]-x[where.i+1]) );
  if (is.na(d)) return(0); # we do not know how to handle an undefined
spot at a function!

  d.m= (ylim[2]-ylim[1])/(xlim[2]-xlim[1]); # now adjust by the axis scale
  if (is.na(d)) stop("native.slope: internal error, I do not have
sensible axis dimensions (", xlim, ylim, ")\n");

  if (is.na(asp.ratio)) stop("native.slope: internal error, I do not
have a reasonable drawing aspect ratio");

  ## alas, we also need to take into account the plot region:
  pq= par()$plt; plt.distort= (pq[2]-pq[1])/(pq[4]-pq[3]);

  net.slope= d/asp.ratio/d.m / plt.distort;

  slope = atan(net.slope)/pi*180.0;


  if (debug) {
    cat("xlim=", par()$xaxp, "\n");
    cat("ylim=", par()$yaxp, "\n\n");

    cat("native.slope: d=", d, " (",y[where.i-1],y[where.i+1],
x[where.i-1], x[where.i+1],")",
	"d.m=",d.m, " (", ylim[2],ylim[1],xlim[2],xlim[1], ")",
	"asp.ratio=", (par()$fin)[1], ":", (par()$fin)[2], "==>", net.slope,
"=", slope, "deg\n");
  }

  return( slope = slope );
}





On 2/4/06, ivo welch <ivowel at gmail.com> wrote:
> Thank you, Duncan.  This led me to the info I needed.  Here is a
> simple utility function that does what I needed---maybe it will come
> in helpful for others.
>
> ################################################################
> #### native.slope computes a suitable srt from a function around
> #### a point on a function.  This is useful until text() gets
> #### an srt parameter that is relative to the coordinate system.
> ####   (Ideally, R would be able to slope along a function.)
> ################################################################
>  [old function deleted]
>
> # some test code
> x<- seq(-10,20,by=0.1)
> y<- x*x;
>
> plot( x, y, type="l" );
>
> display= ((1:length(y))%%40 == 0)
>
> for (i in 1:(length(y))) {
>   if (display[i]) {
>     points(x[i],y[i], pch=19);
>     srt= native.slope( x, y, i );
>     text( x[i], y[i], paste(i,"=",x[i],"=",srt), srt=srt, cex=0.9 );
>   }
> }
>
>
>
> On 2/4/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> > On 2/4/2006 3:50 PM, ivo welch wrote:
> > > [resent, plus small addition; I do not understand why gmail sent a
> > > weird charset.]
> > >
> > > Dear R wizards:
> > >
> > > I would love to write a general function that matches the slope of a plotted
> > > line in an xy-plot at a particular x,y location.  something like
> > >
> > >    x<- (1:10)^2; y<- 40:50;
> > >    plot( x,y, type="l", xlim=c(0,90) )
> > >    srt.at5 = text.at.current.plot.with.slope( x, y,  5);
> > >    text( x[5],y[5], pos=3, srt=srt.at.5);
> > >
> > > to do this, I first need to compute the function slope around x[5], which is
> > > an easy task.  alas, the harder task is that I need to scale this by the
> > > plot aspect ratio and the axes.  How can a function read this from the
> > > current plot?
> >
> > I haven't done this, but you can presumably work it out from the
> > conversions implied by the "fig", "fin", "plt", and/or "usr" values.
> > >
> > > (Has someone written such a function, perhaps more embellished, to save me
> > > the debugging effort?)
> > >
> > > Or, is there an alternative to srt, which slopes the text relative to the
> > > existing scale?
> > >
> > >   *** come to think of it, what I would really like is the ability of
> > > text to 'snake' itself along the line itself.  I doubt that this is
> > > easily possible, but I just wanted to ask.
> >
> > Using strsplit and strwidth you should be able to do it, but it will
> > probably look quite ugly.
> >
> > Duncan Murdoch
> >
>



From murdoch at stats.uwo.ca  Sun Feb  5 00:24:15 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 04 Feb 2006 18:24:15 -0500
Subject: [R] srt --- slope text with function?
In-Reply-To: <50d1c22d0602041419y46761eb1x4f41fc82a5da9b60@mail.gmail.com>
References: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>	
	<43E51A7F.8080002@stats.uwo.ca>
	<50d1c22d0602041419y46761eb1x4f41fc82a5da9b60@mail.gmail.com>
Message-ID: <43E5379F.3080806@stats.uwo.ca>

I don't think it's got the slope exactly right - you'll see this if you 
go to a really extreme aspect ratio by changing the shape of a window to 
be long and thin before you call your code.  To fix this:

  - use "usr" rather than "xaxp" and "yaxp" to get the limits of the 
plot region in user coordinates; those two refer to the ticks, not the 
whole plot region as "usr" does.

- "fin" is the whole figure region, not just the plot region; you need 
to use "plt" to modify it to find the plot region within it.  So I think 
the aspect ratio should really be done as

   pars <- par("fin", "plt")

   asp.ratio <- (diff(pars$plt)[1]*pars$fin[1]) /
                (diff(pars$plt)[3]*pars$fin[2])

Some other suggestions:

  - split the function into two:  one that determines a slope from the 
data, and one that converts a slope to an angle suitable for "srt".  (I 
think the latter would have pretty wide use; the former is pretty 
specialized for data the way you're using it).

  - use the fact that defaults in a function call can be local variables 
in the function, so that you only need one call to par() instead of 4. 
(The 4 calls probably take a negigible amount of time, but it just looks 
wasteful to make them.)

Duncan Murdoch

On 2/4/2006 5:19 PM, ivo welch wrote:
> Thank you, Duncan.  This led me to the info I needed.  Here is a
> simple utility function that does what I needed---maybe it will come
> in helpful for others.
> 
> ################################################################
> #### native.slope computes a suitable srt from a function around
> #### a point on a function.  This is useful until text() gets
> #### an srt parameter that is relative to the coordinate system.
> ####   (Ideally, R would be able to slope along a function.)
> ################################################################
> 
> native.slope <- function( x, y, where.i,
> 			 xlim = par()$xaxp, ylim= par()$yaxp,
> 			 asp.ratio = (par()$fin)[1]/(par()$fin)[2] ) {
>   if (where.i<=1) { return(0); }
>   if (where.i>=length(y)) { return(0); }
>   if (length(x)!=length(y)) {
>     stop("native.slope: Sorry, but x and y must have equal dimensions,
> not ", length(x), " and ", length(y), "\n"); }
> 
>   # native slope in a 1:1 coordinate system
>   d= ( (y[where.i-1]-y[where.i+1])/(x[where.i-1]-x[where.i+1]) );
>   if (is.na(d)) return(0); # we do not know how to handle an undefined
> spot at a function!
> 
>   d.m= (ylim[2]-ylim[1])/(xlim[2]-xlim[1]); # now adjust by the axis scale
>   if (is.na(d)) stop("native.slope: internal error, I do not have
> sensible axis dimensions (", xlim, ylim, ")\n");
> 
>   if (is.na(asp.ratio)) stop("native.slope: internal error, I do not
> have a reasonable drawing aspect ratio");
> 
>   net.slope= d/asp.ratio/d.m;
>   return(slope = atan(net.slope)/pi*180.0 )
> }
> 
> 
> # some test code
> x<- seq(-10,20,by=0.1)
> y<- x*x;
> 
> plot( x, y, type="l" );
> 
> display= ((1:length(y))%%40 == 0)
> 
> for (i in 1:(length(y))) {
>   if (display[i]) {
>     points(x[i],y[i], pch=19);
>     srt= native.slope( x, y, i );
>     text( x[i], y[i], paste(i,"=",x[i],"=",srt), srt=srt, cex=0.9 );
>   }
> }
> 
> 
> 
> On 2/4/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 2/4/2006 3:50 PM, ivo welch wrote:
>>> [resent, plus small addition; I do not understand why gmail sent a
>>> weird charset.]
>>>
>>> Dear R wizards:
>>>
>>> I would love to write a general function that matches the slope of a plotted
>>> line in an xy-plot at a particular x,y location.  something like
>>>
>>>    x<- (1:10)^2; y<- 40:50;
>>>    plot( x,y, type="l", xlim=c(0,90) )
>>>    srt.at5 = text.at.current.plot.with.slope( x, y,  5);
>>>    text( x[5],y[5], pos=3, srt=srt.at.5);
>>>
>>> to do this, I first need to compute the function slope around x[5], which is
>>> an easy task.  alas, the harder task is that I need to scale this by the
>>> plot aspect ratio and the axes.  How can a function read this from the
>>> current plot?
>> I haven't done this, but you can presumably work it out from the
>> conversions implied by the "fig", "fin", "plt", and/or "usr" values.
>>> (Has someone written such a function, perhaps more embellished, to save me
>>> the debugging effort?)
>>>
>>> Or, is there an alternative to srt, which slopes the text relative to the
>>> existing scale?
>>>
>>>   *** come to think of it, what I would really like is the ability of
>>> text to 'snake' itself along the line itself.  I doubt that this is
>>> easily possible, but I just wanted to ask.
>> Using strsplit and strwidth you should be able to do it, but it will
>> probably look quite ugly.
>>
>> Duncan Murdoch
>>



From sell_mirage_ne at hotmail.com  Sun Feb  5 00:46:22 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Sat, 04 Feb 2006 17:46:22 -0600
Subject: [R] saving a character vector
Message-ID: <BAY110-F170482C70DED614751321EC70C0@phx.gbl>

Hi R users

I wrote a function that generates some character strings.

generate.index<-function(n.item){
for (i in 1:n.item)
    {
        for (j in ((i+1):n.item))
            {
                
cat("i",formatC(i,digits=2,flag="0"),".",formatC(j,digits=2,flag="0"),"\n",sep="")

            }

    }
                                }

I like to save what appears on the screen when I run using 
generate.index(10) as a character vector

I used
temp <- generate.index(10)

but it didn't work.

Could you provide some advice on this issue?

Thanks in advance

TM



From Simon.Blanchet at giroq.ulaval.ca  Sun Feb  5 00:49:13 2006
From: Simon.Blanchet at giroq.ulaval.ca (Simon Blanchet)
Date: Sat, 04 Feb 2006 18:49:13 -0500
Subject: [R] Mixed models and missing p-value...
Message-ID: <6.2.1.2.2.20060204183433.01ee52c8@hermes.ulaval.ca>

Dear R-users,

I computed a simple mixed models which was:

         mod<-lmer(nb ~ site + (1|patelle),tr)

The output was:

Linear mixed-effects model fit by REML
Formula: nb ~ site + (1 | patelle)
    Data: tr
       AIC      BIC    logLik MLdeviance REMLdeviance
  1157.437 1168.686 -574.7184   1164.523     1149.437
Random effects:
  Groups   Name        Variance Std.Dev.
  patelle  (Intercept)  34.995   5.9157
  Residual             744.736  27.2899
# of obs: 123, groups: patelle, 33

Fixed effects:
             Estimate Std. Error t value
(Intercept)  60.3483     4.3929 13.7378
siteLCN     -20.1969     7.8070 -2.5870
siteLCS     -18.2154     6.1514 -2.9612

Correlation of Fixed Effects:
         (Intr) sitLCN
siteLCN -0.563
siteLCS -0.714  0.402

I don't understand why D.F. and p-values associated to the fixed-effects 
coefficients are missing.
Could anyone help me?

When I tried another model (mod2<-lmer(nb ~ site + 
(1|patelle),tr,family=poisson)), D.F. and p-values were given...

Thank you in advance.

Very sincerely, Simon



BLANCHET Simon
PhD student
Universit?? Laval - Qu??bec-Oc??an / CIRSA
Pavillon Alexandre-Vachon
Local 8022
Qu??bec (Qu??bec), Canada G1K 7P4
T??l??phone : (418) 656-2131 poste 8022
courriel : simon.blanchet at giroq.ulaval.ca



From dominik.heier at uni-bielefeld.de  Sun Feb  5 00:56:41 2006
From: dominik.heier at uni-bielefeld.de (Dominik Heier)
Date: Sun, 05 Feb 2006 00:56:41 +0100
Subject: [R] saving a character vector
In-Reply-To: <BAY110-F170482C70DED614751321EC70C0@phx.gbl>
References: <BAY110-F170482C70DED614751321EC70C0@phx.gbl>
Message-ID: <1139097401.11035.15.camel@localhost.localdomain>

Am Samstag, den 04.02.2006, 17:46 -0600 schrieb Taka Matzmoto:
> Hi R users
> 
> I wrote a function that generates some character strings.
> 
> generate.index<-function(n.item){
> for (i in 1:n.item)
>     {
>         for (j in ((i+1):n.item))
>             {
>                 
> cat("i",formatC(i,digits=2,flag="0"),".",formatC(j,digits=2,flag="0"),"\n",sep="")
   ^
replace "cat" with "return"
>             }
> 
>     }
>                                 }
> 
> I like to save what appears on the screen when I run using 
> generate.index(10) as a character vector
> 
> I used
> temp <- generate.index(10)
> 
> but it didn't work.
> 
> Could you provide some advice on this issue?
> 
> Thanks in advance
> 
> TM
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jfox at mcmaster.ca  Sun Feb  5 01:08:11 2006
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 4 Feb 2006 19:08:11 -0500
Subject: [R] saving a character vector
In-Reply-To: <1139097401.11035.15.camel@localhost.localdomain>
Message-ID: <20060205000810.CILR5216.tomts40-srv.bellnexxia.net@JohnDesktop8300>

Dear Dominik,

Replacing cat() with return() won't do the trick, I think: First, it will
return only the first time through the inner loop; second, it will call
return with several values.

I think that Taka probably had in mind something like:

generate.index<-function(n.item){
    result <- rep("", n.item*(n.item-1)/2)
    index <- 0
    for (i in 1:(n.item - 1))
        {
            for (j in ((i+1):n.item))
                {
                index <- index + 1                
                result[index] <- paste("i", formatC(i, digits=2, flag="0"),
".",
                    formatC(j, digits=2, flag="0"), sep="")
                }
        }
    result
    }

For example:

> generate.index(4)
[1] "i001.002" "i001.003" "i001.004" "i002.003" "i002.004" "i003.004"

Note that I corrected the range of the outer (i) loop.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dominik Heier
> Sent: Saturday, February 04, 2006 6:57 PM
> To: Taka Matzmoto
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] saving a character vector
> 
> Am Samstag, den 04.02.2006, 17:46 -0600 schrieb Taka Matzmoto:
> > Hi R users
> > 
> > I wrote a function that generates some character strings.
> > 
> > generate.index<-function(n.item){
> > for (i in 1:n.item)
> >     {
> >         for (j in ((i+1):n.item))
> >             {
> >                 
> > 
> cat("i",formatC(i,digits=2,flag="0"),".",formatC(j,digits=2,flag="0"),
> > "\n",sep="")
>    ^
> replace "cat" with "return"
> >             }
> > 
> >     }
> >                                 }
> > 
> > I like to save what appears on the screen when I run using
> > generate.index(10) as a character vector
> > 
> > I used
> > temp <- generate.index(10)
> > 
> > but it didn't work.
> > 
> > Could you provide some advice on this issue?
> > 
> > Thanks in advance
> > 
> > TM
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From dominik.heier at uni-bielefeld.de  Sun Feb  5 01:10:09 2006
From: dominik.heier at uni-bielefeld.de (Dominik Heier)
Date: Sun, 05 Feb 2006 01:10:09 +0100
Subject: [R] saving a character vector
In-Reply-To: <1139097401.11035.15.camel@localhost.localdomain>
References: <BAY110-F170482C70DED614751321EC70C0@phx.gbl>
	<1139097401.11035.15.camel@localhost.localdomain>
Message-ID: <1139098209.11035.28.camel@localhost.localdomain>

Sorry. Forget my last post. I seem to be brain dead. Going to bed now
(its late in Germany). Sorry again.. 



Am Sonntag, den 05.02.2006, 00:56 +0100 schrieb Dominik Heier:
> Am Samstag, den 04.02.2006, 17:46 -0600 schrieb Taka Matzmoto:
> > Hi R users
> > 
> > I wrote a function that generates some character strings.
> > 
> > generate.index<-function(n.item){
> > for (i in 1:n.item)
> >     {
> >         for (j in ((i+1):n.item))
> >             {
> >                 
> > cat("i",formatC(i,digits=2,flag="0"),".",formatC(j,digits=2,flag="0"),"\n",sep="")
>    ^
> replace "cat" with "return"
    ^
WRONG!! Append it to an array or list and return it at the end of the
function (wich R does by its self)


> >             }
> > 
> >     }
> >                                 }
> > 
> > I like to save what appears on the screen when I run using 
> > generate.index(10) as a character vector
> > 
> > I used
> > temp <- generate.index(10)
> > 
> > but it didn't work.
> > 
> > Could you provide some advice on this issue?
> > 
> > Thanks in advance
> > 
> > TM
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From falimadhi at iq.harvard.edu  Sun Feb  5 01:11:07 2006
From: falimadhi at iq.harvard.edu (Ferdinand Alimadhi)
Date: Sat, 04 Feb 2006 19:11:07 -0500
Subject: [R] saving a character vector
In-Reply-To: <1139097401.11035.15.camel@localhost.localdomain>
References: <BAY110-F170482C70DED614751321EC70C0@phx.gbl>
	<1139097401.11035.15.camel@localhost.localdomain>
Message-ID: <43E5429B.2060604@iq.harvard.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060204/e64a4e4f/attachment.pl

From jholtman at gmail.com  Sun Feb  5 01:13:55 2006
From: jholtman at gmail.com (jim holtman)
Date: Sat, 4 Feb 2006 19:13:55 -0500
Subject: [R] saving a character vector
In-Reply-To: <BAY110-F170482C70DED614751321EC70C0@phx.gbl>
References: <BAY110-F170482C70DED614751321EC70C0@phx.gbl>
Message-ID: <644e1f320602041613l4a88632by75337b28426a51d2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060204/303ac9e1/attachment.pl

From chabotd at globetrotter.net  Sun Feb  5 01:54:35 2006
From: chabotd at globetrotter.net (Denis Chabot)
Date: Sat, 04 Feb 2006 19:54:35 -0500
Subject: [R] how to extract predicted values from a quantreg fit?
Message-ID: <61B38643-917E-4F9D-83D0-820FB32FA893@globetrotter.net>

Hi,

I have used package quantreg to estimate a non-linear fit to the  
lowest part of my data points. It works great, by the way.

But I'd like to extract the predicted values. The help for  
predict.qss1 indicates this:

predict.qss1(object, newdata, ...)
and states that newdata is a data frame describing the observations  
at which prediction is to be made.

I used the same technique I used to extract predicted values of GAM  
fits with mgcv package: if I fit a GAM using x as the x variable on  
which I smooth, I then create such a dataframe like this

MyX <- data.frame(x=seq(-1,60))

This works fine with GAM (mgcv) but not with quantreg:

 > y <- rnorm(500, 10, 5)
 > x <- rep(seq(1,50,1), 10)
 > My.data <- data.frame(x, y)
 > My.x <- data.frame(x=seq(5,45))
 >
 > fit <- rqss(y ~ qss(x, lambda=5), tau=0.05)
 > pred <- predict.qss1(fit, My.x)

Could someone please help me creating a dataframe "newdata" that  
would satisfy predict.qss1?

Thanks in advance,

Denis Chabot



From andywongcw at gmail.com  Sun Feb  5 03:32:25 2006
From: andywongcw at gmail.com (Andy Wong)
Date: Sun, 5 Feb 2006 10:32:25 +0800
Subject: [R] Application of R with Multinomial Probit Model
Message-ID: <cafcabf80602041832h109d045cud54d4dd9848cfd7a@mail.gmail.com>

Dear All,

I still cannot solve the error (see attached printed pdf file).  Can
somebody give me some advice?  I have also attached my data file in Excel
and text formats for your reference.  I have already assigned the
y1,y2,....x1,x12,z1,z2.....z14 as V1....V23 but still can't work.  Please
try out and advise.  Thanks.

Andy
-------------- next part --------------
A non-text attachment was scrubbed...
Name: result.pdf
Type: application/pdf
Size: 29819 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20060205/54ab9bc1/result.pdf

From sell_mirage_ne at hotmail.com  Sun Feb  5 04:16:00 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Sat, 04 Feb 2006 21:16:00 -0600
Subject: [R] generating strings in a tricky order
Message-ID: <BAY110-F6EF8028934CE68AC5F6E7C70F0@phx.gbl>

Hi R users

I like to generate some strings (a character vector) in a special way like

If i have 5 variables

"002.001",
"003.001", "003.002",
"004.001", "004.002", "004.003",
"005.001", "005.002", "005.003", "005.004"

so the created string vector's elements are

"002.001", "003.001", "003.002","004.001", "004.002", "004.003","005.001", 
"005.002", "005.003", "005.004"

I tried to come up with for loop with two indexes (i and j) but I kept 
failing to generate that kind of order of strings. The order of the element 
in the character vector is very improtant.

Any advice or help would be appreciated

Thanks in advance

TM,



From jholtman at gmail.com  Sun Feb  5 04:51:04 2006
From: jholtman at gmail.com (jim holtman)
Date: Sat, 4 Feb 2006 22:51:04 -0500
Subject: [R] generating strings in a tricky order
In-Reply-To: <BAY110-F6EF8028934CE68AC5F6E7C70F0@phx.gbl>
References: <BAY110-F6EF8028934CE68AC5F6E7C70F0@phx.gbl>
Message-ID: <644e1f320602041951s6c3515a4k488554287a05e037@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060204/ea6abff5/attachment.pl

From ggrothendieck at gmail.com  Sun Feb  5 05:10:17 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 4 Feb 2006 23:10:17 -0500
Subject: [R] generating strings in a tricky order
In-Reply-To: <BAY110-F6EF8028934CE68AC5F6E7C70F0@phx.gbl>
References: <BAY110-F6EF8028934CE68AC5F6E7C70F0@phx.gbl>
Message-ID: <971536df0602042010o6539f569w4ff00a34a035ca99@mail.gmail.com>

Try this:

x <- outer(1:5, 1:5, sprintf, fmt = "%03d.%03d")
sort(x[lower.tri(x)])

On 2/4/06, Taka Matzmoto <sell_mirage_ne at hotmail.com> wrote:
> Hi R users
>
> I like to generate some strings (a character vector) in a special way like
>
> If i have 5 variables
>
> "002.001",
> "003.001", "003.002",
> "004.001", "004.002", "004.003",
> "005.001", "005.002", "005.003", "005.004"
>
> so the created string vector's elements are
>
> "002.001", "003.001", "003.002","004.001", "004.002", "004.003","005.001",
> "005.002", "005.003", "005.004"
>
> I tried to come up with for loop with two indexes (i and j) but I kept
> failing to generate that kind of order of strings. The order of the element
> in the character vector is very improtant.
>
> Any advice or help would be appreciated
>
> Thanks in advance
>
> TM,
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From attenka at utu.fi  Sun Feb  5 08:13:05 2006
From: attenka at utu.fi (Atte Tenkanen)
Date: Sun, 05 Feb 2006 09:13:05 +0200 (EET)
Subject: [R] How to generate pitch strings
In-Reply-To: <61156.130.232.44.35.1139003123.squirrel@webmail2.utu.fi>
References: <61156.130.232.44.35.1139003123.squirrel@webmail2.utu.fi>
Message-ID: <64282.130.232.44.35.1139123585.squirrel@webmail2.utu.fi>

> If I calculate a transition probability matrix, first order markov 12x12
> or second order 144x144 from musical pitch classes (0-11), is it possible
> to generate pitch class strings similar as those original strings using
> those probability matrix with R? If, how?
>
> Atte Tenkanen, Turku, Finland
>

I found this kind of solution:

j=1; a1=c();
Generated_Melody=c(1); #first note as a seed
a1=sample(1:12, size=1, prob=PT_matrix[j,]) # a seed for the loop following

for (i in 1:100){ # length of the generated melody will be 100
	Generated_Melody=c(Generated_Melody,a1)
	a1=sample(1:12, size=1, prob=PT_matrix[a1,])
}

# Generated_Melody=Generated_Melody-1;  # to picht classes
# Generated_Melody=Generated_Melody+59; # or to midi pitches


Atte Tenkanen

PS. Here is my page considering the course in which we use R for music
analysis...
http://musiikintutkimus.blogspot.com/



From sell_mirage_ne at hotmail.com  Sun Feb  5 08:27:08 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Sun, 05 Feb 2006 01:27:08 -0600
Subject: [R] reading in a tricky computer program output
Message-ID: <BAY110-F209B90446EFBC59FB9EAB0C70F0@phx.gbl>

Hi R user

I need to read in some values from a computer program output.

I can't change the output format because the developer of the program 
doesn't allow to change the format of output.

There are two formats.

First one looks like this

if I have 10 variables,

------------------------------------------------------------------------------------------------------
       [ 1]              [2]           [3]              [4]            [5]
[ 1]  0.000
[ 2]  0.001         0.000
[ 3] -0.002         0.019         0.000
[ 4]  0.012        -0.004        -0.020         0.000
[ 5] -0.015         0.003         0.011         0.008         0.000
[ 6]  0.005        -0.008        -0.005         0.002         0.005
[ 7]  0.008        -0.007         0.013         0.003         0.007
[ 8] -0.014        -0.011        -0.010        -0.025         0.002
[ 9]  0.006         0.003        -0.010         0.002        -0.020
[10] 0.006         0.010        -0.006         0.005         0.008
[ 6]  0.000
[ 7] -0.037         0.000
[ 8]  0.010         0.027         0.000
[ 9]  0.032        -0.004         0.008         0.000
[10] -0.008        -0.011         0.015        -0.020         0.000

------------------------------------------------------------------------------------------------
NOTE: I put [number] to show that this output is similar to a lower diagonal 
matrix including diagonal. In an ouput there is no [number]


The second format looks like this
--------------------------------------------------------------------------------------
       [1]              [2]             [3]           [4]              [5]
[ 2] -0.002
[ 3]  0.003        -0.053
[ 4] -0.026         0.010         0.045
[ 5]  0.023        -0.008        -0.025        -0.016
[ 6] -0.012         0.023         0.013        -0.005        -0.011
[ 7] -0.031         0.031        -0.054        -0.013        -0.027
[ 8]  0.040         0.042         0.031         0.075        -0.007
[ 9] -0.012        -0.009         0.023        -0.005         0.037
[10] -0.013        -0.027         0.014        -0.013        -0.020
[ 7]  0.127
[ 8] -0.035        -0.166
[ 9] -0.083         0.015        -0.027
[10]  0.021         0.047        -0.052         0.048
---------------------------------------------------------------------------------------------------------
NOTE: I put [number] to show that this output is similar to a lower diagonal 
matrix without diagonal. In an ouput there is no [number]

The problem of this format is the fixed column length ( 5 columns)

To make matter worse, the number of variables keep changing (10, 20, 30, 40, 
50, 60,70,80,90, and 100) so I need to take into the number of variables 
when I write a R function to read in these numbers.

If the number of variables is 80, the output is very long.

I only came up with this tedious one.

First I read in the output using scan() and then make it a numeric vector

I created 10 character vectors. Creating a 100 variable character vector is 
the most boring things

I have ever done.

one of the character vectors that matchs with the first 10 variable output 
is

first.10<-c(
            "i.001.001",
            "i.002.001","i.002.002",
            "i.003.001","i.003.002","i.003.003",
            "i.004.001","i.004.002","i.004.003","i.004.004",
            "i.005.001","i.005.002","i.005.003","i.005.004","i.005.005",
            "i.006.001","i.006.002","i.006.003","i.006.004","i.006.005",
            "i.007.001","i.007.002","i.007.003","i.007.004","i.007.005",
            "i.008.001","i.008.002","i.008.003","i.008.004","i.008.005",
            "i.009.001","i.009.002","i.009.003","i.009.004","i.009.005",
            "i.010.001","i.010.002","i.010.003","i.010.004","i.010.005",
            "i.006.006",
            "i.007.006","i.007.007",
            "i.008.006","i.008.007","i.008.008",
            "i.009.006","i.009.007","i.009.008","i.009.009",
            "i.010.006","i.010.007","i.010.008","i.010.009","i.010.010"
           )

one of the character vectors that matchs with the second 10 variable output 
is

second.10<-c(
            "i.002.001",
            "i.003.001","i.003.002",
            "i.004.001","i.004.002","i.004.003",
            "i.005.001","i.005.002","i.005.003","i.005.004",
            "i.006.001","i.006.002","i.006.003","i.006.004","i.006.005",
            "i.007.001","i.007.002","i.007.003","i.007.004","i.007.005",
            "i.008.001","i.008.002","i.008.003","i.008.004","i.008.005",
            "i.009.001","i.009.002","i.009.003","i.009.004","i.009.005",
            "i.010.001","i.010.002","i.010.003","i.010.004","i.010.005",
            "i.007.006",
            "i.008.006","i.008.007",
            "i.009.006","i.009.007","i.009.008",
            "i.010.006","i.010.007","i.010.008","i.010.009"
           )

and then assign the character vector to the numeric vector by

names<-first.10
first.10 = numeric.vector
combined.one <- cbind(names,first.10)
container <- diag(10)
for (i in 1:(10*10))
    {
        k   <- as.numeric(substr(combined.one[i,1],7,9))
        l   <- as.numeric(substr(combined.one [i,1],3,5))
        val <- as.numeric(combined.one [i,2])
        container [k,l] <- val
    }

container <- t(container )

Is there any other neat way to do this?

Any help would be appreciated

TM



From phgrosjean at sciviews.org  Sun Feb  5 09:22:55 2006
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sun, 05 Feb 2006 09:22:55 +0100
Subject: [R] saving a character vector
In-Reply-To: <644e1f320602041613l4a88632by75337b28426a51d2@mail.gmail.com>
References: <BAY110-F170482C70DED614751321EC70C0@phx.gbl>
	<644e1f320602041613l4a88632by75337b28426a51d2@mail.gmail.com>
Message-ID: <43E5B5DF.5010201@sciviews.org>

If I understand the question correctly, both Jim Holtman's and John 
Fox's answers are correct solutions. However, they are not optimal ones 
(that was not the question -optimize my code, please-, but one can talk 
about it a little bit).

- Jim proposes (I rework a little bit his code):
generateIndex1 <- function(n.item) {
     Res <- character(0)  # initialize vector
     for (i in 1:(n.item - 1)) { # John Fox's correction introduced
         for (j in ((i+1):n.item)) {
             # concatenate the results
             Res <- c(Res, paste("i", formatC(i, digits = 2, flag = "0"),
                 ".", formatC(j, digits = 2, flag = "0"), sep = ""))
         }
     }
     Res
}

- John Fox proposes:
generateIndex2 <- function(n.item) {
     result <- rep("", n.item * (n.item - 1) / 2)
     index <- 0
     for (i in 1:(n.item - 1)) {
         for (j in ((i + 1):n.item)) {
             index <- index + 1
             result[index] <- paste("i",
                 formatC(i, digits = 2, flag = "0"), ".",
                 formatC(j, digits = 2, flag = "0"), sep = "")
         }
     }
     result
}

The difference is that Jim creates an empty character vector and 
concatenate to it (simplest code), and John creates a vector of empty 
characters of the correct size [result <- rep("", n.item * (n.item - 1) 
/ 2)]. The second solution is supposed to be better, because "result" is 
supposed to be of the right size, limiting useless memory pagination 
inside each loop iteration. However:

 > system.time(generateIndex1(100))
[1] 4.86 0.00 4.86   NA   NA
 > system.time(generateIndex2(100))
[1] 4.68 0.00 4.68   NA   NA

There is not much difference (well, indeed, the loops and what's 
calculated repreatedly inside takes much more time in this case). 
However, I wonder what happens if I allocate a vector of the right size 
with strings having also the right size:

generateIndex3 <- function(n.item) {
     result <- rep("i000.000", n.item * (n.item - 1) / 2)
     index <- 0
     for (i in 1:(n.item - 1)) {
         for (j in ((i + 1):n.item)) {
             index <- index + 1
             result[index] <- paste("i",
                 formatC(i, digits = 2, flag = "0"), ".",
                 formatC(j, digits = 2, flag = "0"), sep = "")
         }
     }
     result
}

 > system.time(generateIndex3(100))
[1] 4.63 0.02 4.66   NA   NA

... About the same. **Could someone explain me here, please?**

Now, where is the bottleneck?

 > Rprof()
 > res <- generateIndex3(100)
 > Rprof(NULL)
 > ?summaryRprof
 > summaryRprof()
$by.self
                    self.time self.pct total.time total.pct
formatC                 0.48     10.5       4.30      93.9
paste                   0.46     10.0       4.54      99.1
pmax                    0.44      9.6       0.66      14.4
as.integer              0.30      6.6       0.34       7.4
as.logical              0.24      5.2       0.34       7.4
names                   0.20      4.4       0.24       5.2
...

Gosh! For sure: Why do I call FormatC() every time twice in the loop? I 
can increase speed by formatting my character strings only once!

generateIndex4 <- function(n.item) {
     result <- rep("i000.000", n.item * (n.item - 1) / 2)
     index <- 0
     id <- formatC(1:n.item, digits = 2, flag = "0")
     for (i in 1:(n.item - 1)) {
         for (j in ((i + 1):n.item)) {
             index <- index + 1
             result[index] <- paste("i", id[i], ".", id[j], sep = "")
         }
     }
     result
}

 > system.time(generateIndex4(100))
[1] 0.33 0.00 0.33   NA   NA

Yes! That's much better.
Now, recall that it is better to use a vectorized algorithm than loops, 
could I get rid of these two ugly loops? Here is something using outer() 
and lower.tri():

generateIndex5 <- function(n.item) {
     idx <- function(x, y) paste("i", x, ".", y, sep = "")
     id <- formatC(1:n.item, digits = 2, flag = "0")
     allidx <- t(outer(id, id, idx))
     allidx[lower.tri(allidx)]
}

 > system.time(generateIndex5(100))
[1] 0.02 0.00 0.02   NA   NA

Indeed! That code is much, much faster!
Now, let's compare generateIndex1() with generateIndex5().

- generateIndex5() is optimized for speed (4.86/0.02, about 250 times 
faster!)

- generateIndex5() is more concise code: 4 lines, no loops, compared to 
8 lines with two loops.

- but... generateIndex1() is the code that comes to mind more easily 
(except, perhaps for some R experts (?) because thinking with vectors is 
their second nature).

- but... generateIndex1() is much easier to understand, when someone 
else read the code (for the same reason).

Final conclusion:
generateIndex5() is a better R code (I am sure one can do even better!), 
but it is a little bit more intellectual work to arrive to this result 
(i.e., rethink the problem using matrix calculation). However, the 
result is worth the effort.

(note: this will be introduced in the future R Wiki. This is the reson 
why this email is so long: I took a good occasion to speak about code 
optimization).

Best,

Philippe Grosjean

..............................................<??}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (
..............................................................

jim holtman wrote:
> Is this what you want?  It returns a character vector with the values:
> 
> 
>>generate.index<-function(n.item){
> 
> + .return <- character()  # initialize vector
> + for (i in 1:n.item)
> +    {
> +        for (j in ((i+1):n.item))
> +            {
> + # concatenate the results
> + .return <- c(.return,
> paste("i",formatC(i,digits=2,flag="0"),".",formatC(j,digits=2,flag="0"),sep=""))
> +
> +            }
> +
> +    }
> +    .return
> +  }
> 
>>
>>generate.index(10)
> 
>  [1] "i001.002" "i001.003" "i001.004" "i001.005" "i001.006" "i001.007"
>  [7] "i001.008" "i001.009" "i001.010" "i002.003" "i002.004" "i002.005"
> [13] "i002.006" "i002.007" "i002.008" "i002.009" "i002.010" "i003.004"
> [19] "i003.005" "i003.006" "i003.007" "i003.008" "i003.009" "i003.010"
> [25] "i004.005" "i004.006" "i004.007" "i004.008" "i004.009" "i004.010"
> [31] "i005.006" "i005.007" "i005.008" "i005.009" "i005.010" "i006.007"
> [37] "i006.008" "i006.009" "i006.010" "i007.008" "i007.009" "i007.010"
> [43] "i008.009" "i008.010" "i009.010" "i010.011" "i010.010"
> 
> 
> 
> 
> On 2/4/06, Taka Matzmoto <sell_mirage_ne at hotmail.com> wrote:
> 
>>Hi R users
>>
>>I wrote a function that generates some character strings.
>>
>>generate.index<-function(n.item){
>>for (i in 1:n.item)
>>   {
>>       for (j in ((i+1):n.item))
>>           {
>>
>>
>>cat("i",formatC(i,digits=2,flag="0"),".",formatC(j,digits=2,flag="0"),"\n",sep="")
>>
>>           }
>>
>>   }
>>                               }
>>
>>I like to save what appears on the screen when I run using
>>generate.index(10) as a character vector
>>
>>I used
>>temp <- generate.index(10)
>>
>>but it didn't work.
>>
>>Could you provide some advice on this issue?
>>
>>Thanks in advance
>>
>>TM
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
>>
> 
> 
> 
> 
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 247 0281
> 
> What the problem you are trying to solve?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From berwin at maths.uwa.edu.au  Sun Feb  5 09:51:02 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sun, 5 Feb 2006 16:51:02 +0800
Subject: [R] reading in a tricky computer program output
In-Reply-To: <BAY110-F209B90446EFBC59FB9EAB0C70F0@phx.gbl>
References: <BAY110-F209B90446EFBC59FB9EAB0C70F0@phx.gbl>
Message-ID: <17381.48246.60855.997052@bossiaea.maths.uwa.edu.au>

G'day Taka,

>>>>> "TM" == Taka Matzmoto <sell_mirage_ne at hotmail.com> writes:

    TM> and then assign the character vector to the numeric vector by

    TM> names<-first.10
    TM> first.10 = numeric.vector
    TM> combined.one <- cbind(names,first.10)
    TM> container <- diag(10)
    TM> for (i in 1:(10*10))
I don't really understand this loop.  If I reverse-engineer this code
correctly thenthe matrix `combined.one' is not a 2*100 matrix, so you
should get an error while exectuting this loop.

    TM> Is there any other neat way to do this?
Neat way to create those character vectors?  Or a neat way to read in
the data from a file?

If the latter, I would use the following code:

      matzmoto <- function(file, diag=TRUE){
      
        dat <- scan(file)
        if(diag){
          nvar <- sqrt(2*length(dat)+0.25) - 0.5
          nn <- nvar
        }else{
          nvar <- sqrt(2*length(dat)+0.25) + 0.5
          nn <- nvar - 1
        }
        res <- matrix(0,nvar,nvar)
        ind <- upper.tri(res, diag=diag)
      
        rind <- 1:5
        while(nn > 0){
          if( nn < 5 ){
            rind <- rind[1:nn]
            tmp <- matrix(0,nn,nvar)
          }else{
            tmp <- matrix(0,5,nvar)
          }
      
          how.many <- sum(ind[rind,])
          tmp[ind[rind,]] <- dat[1:how.many]
          res[rind,] <- tmp
      
          dat <- dat[-(1:how.many)]
      
          rind <- rind + 5
          nn <- nn - 5
        }
        t(res)
      }
      
      res <- matzmoto("matzmoto1.dat", TRUE)
      print(res)
      
      res <- matzmoto("matzmoto2.dat", FALSE)
      print(res)


After storing the two examples that you posted into the files
matzmoto1.dat and matzmoto2.dat, respectively, and removing the part
that you said you have added, I get the following result on my machine
when sourcing the above code:

      > source("matzmoto.R")
      Read 55 items
              [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]  [,8]  [,9] [,10]
       [1,]  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000  0.00     0
       [2,]  0.001  0.000  0.000  0.000  0.000  0.000  0.000 0.000  0.00     0
       [3,] -0.002  0.019  0.000  0.000  0.000  0.000  0.000 0.000  0.00     0
       [4,]  0.012 -0.004 -0.020  0.000  0.000  0.000  0.000 0.000  0.00     0
       [5,] -0.015  0.003  0.011  0.008  0.000  0.000  0.000 0.000  0.00     0
       [6,]  0.005 -0.008 -0.005  0.002  0.005  0.000  0.000 0.000  0.00     0
       [7,]  0.008 -0.007  0.013  0.003  0.007 -0.037  0.000 0.000  0.00     0
       [8,] -0.014 -0.011 -0.010 -0.025  0.002  0.010  0.027 0.000  0.00     0
       [9,]  0.006  0.003 -0.010  0.002 -0.020  0.032 -0.004 0.008  0.00     0
      [10,]  0.006  0.010 -0.006  0.005  0.008 -0.008 -0.011 0.015 -0.02     0
      Read 45 items
              [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]   [,8]  [,9] [,10]
       [1,]  0.000  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000     0
       [2,] -0.002  0.000  0.000  0.000  0.000  0.000  0.000  0.000 0.000     0
       [3,]  0.003 -0.053  0.000  0.000  0.000  0.000  0.000  0.000 0.000     0
       [4,] -0.026  0.010  0.045  0.000  0.000  0.000  0.000  0.000 0.000     0
       [5,]  0.023 -0.008 -0.025 -0.016  0.000  0.000  0.000  0.000 0.000     0
       [6,] -0.012  0.023  0.013 -0.005 -0.011  0.000  0.000  0.000 0.000     0
       [7,] -0.031  0.031 -0.054 -0.013 -0.027  0.127  0.000  0.000 0.000     0
       [8,]  0.040  0.042  0.031  0.075 -0.007 -0.035 -0.166  0.000 0.000     0
       [9,] -0.012 -0.009  0.023 -0.005  0.037 -0.083  0.015 -0.027 0.000     0
      [10,] -0.013 -0.027  0.014 -0.013 -0.020  0.021  0.047 -0.052 0.048     0

The documentation of the function is quite simple.  Just pass the name
of the file in which the output is and whether it is a file that
includes the output of the diagonal or not.  If you don't trust the
calculation of how many variables are involved, then you might want to
change the function so that this is another input paramter.

HTH.

Cheers,

        Berwin



From mhofert at mathematik.uni-ulm.de  Sun Feb  5 10:12:32 2006
From: mhofert at mathematik.uni-ulm.de (Marius Hofert)
Date: Sun, 5 Feb 2006 10:12:32 +0100 (MET)
Subject: [R] wireframe zlim option
Message-ID: <20060205091232.12802.qmail@turing.mathematik.uni-ulm.de>

Hello,

I would like to plot a wireframe of a function which is defined on the
unit square using the lattice library (for trellis-like plots). The plot
contains z-values of about 100 (only in the neighborhood of zero) although
most of the z-values are in the range of -let's say- 0 to 10. If I
evaluate this function on an equidistant grid of 25 points on the unit
square the plot quality is not very good, but I can see the rough shape of
the plot (i.e. I can see the that the points in the range of 0 to 10 have
different heights). If I increase the grid points to 100 (so the function
is evaluated on an equidistant grid with 100^2 points), the plot quality
increases (i.e. the plot gets smooth), but I can hardly see any structure
of the plot as the points in the neighborhood of zero of course dominate
the plot (and all points in the range from 0 to 10 seem to just have the
same height) and as I evaluate more of the points close to 0 this behavior
is obvious. Therefore I would like to restrict the z-values plotted. I
couldn't find any help for that and the usual "zlim=c(0,30)" (which should
only plot the z-values lying in the range from 0 to 30) did not work for
the wireframe function of the lattice package.
The call I tried was

>library(lattice)
>wireframe(z~x*y,zlim=c(0,30),drape=T,distance=0,colorkey=list(tick.number=6))

Any hints are appreciated

Thanks in advance

Marius

mhofert at mathematik.uni-ulm.de



From berwin at maths.uwa.edu.au  Sun Feb  5 10:14:12 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sun, 5 Feb 2006 17:14:12 +0800
Subject: [R] reading in a tricky computer program output
In-Reply-To: <17381.48246.60855.997052@bossiaea.maths.uwa.edu.au>
References: <BAY110-F209B90446EFBC59FB9EAB0C70F0@phx.gbl>
	<17381.48246.60855.997052@bossiaea.maths.uwa.edu.au>
Message-ID: <17381.49636.352885.867111@bossiaea.maths.uwa.edu.au>

>>>>> "BAT" == Berwin A Turlach <berwin at maths.uwa.edu.au> writes:

>>>>> "TM" == Taka Matzmoto <sell_mirage_ne at hotmail.com> writes:

    TM> and then assign the character vector to the numeric vector by

    TM> names<-first.10
    TM> first.10 = numeric.vector
    TM> combined.one <- cbind(names,first.10)
    TM> container <- diag(10)
    TM> for (i in 1:(10*10))
    BAT> I don't really understand this loop.  If I reverse-engineer this code
    BAT> correctly thenthe matrix `combined.one' is not a 2*100 matrix, so you
    BAT> should get an error while exectuting this loop.
This should have been:  ... `combined.one' is not a 100*2 matrix ...

    TM> Is there any other neat way to do this?
    BAT> Neat way to create those character vectors?  Or a neat way to read in
    BAT> the data from a file?

    BAT> If the latter, I would use the following code:
Before somebody else points out the obvious optimisation of my code,
here is a (slightly) improved version of the function

      matzmoto <- function(file, diag=TRUE){
      
        dat <- scan(file)
        nn <- nvar <- sqrt(2*length(dat)+0.25) - 0.5
        if(!diag){
          nvar <- nvar + 1
        }
        res <- matrix(0,nvar,nvar)
        ind <- upper.tri(res, diag=diag)
      
        rind <- 1:5
        while(nn > 0){
          if( nn < 5 ){
            rind <- rind[1:nn]
          }
      
          how.many <- sum(ind[rind,])
          res[rind,][ind[rind,]] <- dat[1:how.many]
          
          dat <- dat[-(1:how.many)]
      
          rind <- rind + 5
          nn <- nn - 5
        }
        t(res)
      }

Cheers,

        Berwin



From stratja at auburn.edu  Sun Feb  5 13:36:08 2006
From: stratja at auburn.edu (Jeffrey Stratford)
Date: Sun, 05 Feb 2006 06:36:08 -0600
Subject: [R] 3-dimensional table
Message-ID: <43E59CD8020000F200007265@TMIA1.AUBURN.EDU>

Hi,

Last week my class conducted an experiment by putting out clay
caterpillars to look at the effects of urbanization, color, and location
on caterpillar predation.  There were two sites (urban, rural), three
colors (green, yellow, red) and two locations at each site (edge,
interior).  The entire data set is below.  I've checked out the MASS
book, Dalgaard's book, and the R-help archives and I haven't found
anything that suggests how to set up a spreadsheet for the xtab function
(say, xtab(predation ~ location + site + color, data=class).   It would
not be a problem to input the data by hand but I wouldn't know how to
set that up either.  Any suggestions would be greatly appreciated.  The
class is mostly college sophmores and juniors and biology and education
majors.  We are using R 2.2.1 on Windows XP.   

Again, many thanks,

Jeff

site	location	color	predated
Urban	Edge	Green	5
Urban	Edge	Red	30
Urban	Edge	Yellow	11
Urban	Interior	Green	11
Urban	Interior	Red	22
Urban	Interior	Yellow	22
Rural	Edge	Green	94
Rural	Edge	Red	40
Rural	Edge	Yellow	67
Rural	Interior	Green	40
Rural	Interior	Red	70
Rural	Interior	Yellow	33


****************************************
Jeffrey A. Stratford, Ph.D.
Postdoctoral Associate
331 Funchess Hall
Department of Biological Sciences
Auburn University
Auburn, AL 36849
334-329-9198
FAX 334-844-9234
http://www.auburn.edu/~stratja



From choid at ohsu.edu  Sun Feb  5 16:25:37 2006
From: choid at ohsu.edu (Dongseok Choi)
Date: Sun, 05 Feb 2006 07:25:37 -0800
Subject: [R] rgl install problem on Solaris 10 X86
Message-ID: <s3e5a877.050@OHSU.EDU>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060205/d820f21b/attachment.pl

From ggrothendieck at gmail.com  Sun Feb  5 16:29:18 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 5 Feb 2006 10:29:18 -0500
Subject: [R] reading in a tricky computer program output
In-Reply-To: <BAY110-F209B90446EFBC59FB9EAB0C70F0@phx.gbl>
References: <BAY110-F209B90446EFBC59FB9EAB0C70F0@phx.gbl>
Message-ID: <971536df0602050729u2eaa8f3cqae3d0e1e6dc68d5c@mail.gmail.com>

Its not clear to me what format you want to put the data in but this
will read it into a list, one list element per lower triangular matrix.
Modify to suit.

DF <- read.table("myfile.dat", fill = TRUE)
id <- cumsum(is.na(DF[,2]))
result <- by(DF, id, as.matrix)

# if the input is in the second format add this line after the above
result2 <- lapply(result, function(x) rbind(NA, x))


On 2/5/06, Taka Matzmoto <sell_mirage_ne at hotmail.com> wrote:
> Hi R user
>
> I need to read in some values from a computer program output.
>
> I can't change the output format because the developer of the program
> doesn't allow to change the format of output.
>
> There are two formats.
>
> First one looks like this
>
> if I have 10 variables,
>
> ------------------------------------------------------------------------------------------------------
>       [ 1]              [2]           [3]              [4]            [5]
> [ 1]  0.000
> [ 2]  0.001         0.000
> [ 3] -0.002         0.019         0.000
> [ 4]  0.012        -0.004        -0.020         0.000
> [ 5] -0.015         0.003         0.011         0.008         0.000
> [ 6]  0.005        -0.008        -0.005         0.002         0.005
> [ 7]  0.008        -0.007         0.013         0.003         0.007
> [ 8] -0.014        -0.011        -0.010        -0.025         0.002
> [ 9]  0.006         0.003        -0.010         0.002        -0.020
> [10] 0.006         0.010        -0.006         0.005         0.008
> [ 6]  0.000
> [ 7] -0.037         0.000
> [ 8]  0.010         0.027         0.000
> [ 9]  0.032        -0.004         0.008         0.000
> [10] -0.008        -0.011         0.015        -0.020         0.000
>
> ------------------------------------------------------------------------------------------------
> NOTE: I put [number] to show that this output is similar to a lower diagonal
> matrix including diagonal. In an ouput there is no [number]
>
>
> The second format looks like this
> --------------------------------------------------------------------------------------
>       [1]              [2]             [3]           [4]              [5]
> [ 2] -0.002
> [ 3]  0.003        -0.053
> [ 4] -0.026         0.010         0.045
> [ 5]  0.023        -0.008        -0.025        -0.016
> [ 6] -0.012         0.023         0.013        -0.005        -0.011
> [ 7] -0.031         0.031        -0.054        -0.013        -0.027
> [ 8]  0.040         0.042         0.031         0.075        -0.007
> [ 9] -0.012        -0.009         0.023        -0.005         0.037
> [10] -0.013        -0.027         0.014        -0.013        -0.020
> [ 7]  0.127
> [ 8] -0.035        -0.166
> [ 9] -0.083         0.015        -0.027
> [10]  0.021         0.047        -0.052         0.048
> ---------------------------------------------------------------------------------------------------------
> NOTE: I put [number] to show that this output is similar to a lower diagonal
> matrix without diagonal. In an ouput there is no [number]
>
> The problem of this format is the fixed column length ( 5 columns)
>
> To make matter worse, the number of variables keep changing (10, 20, 30, 40,
> 50, 60,70,80,90, and 100) so I need to take into the number of variables
> when I write a R function to read in these numbers.
>
> If the number of variables is 80, the output is very long.
>
> I only came up with this tedious one.
>
> First I read in the output using scan() and then make it a numeric vector
>
> I created 10 character vectors. Creating a 100 variable character vector is
> the most boring things
>
> I have ever done.
>
> one of the character vectors that matchs with the first 10 variable output
> is
>
> first.10<-c(
>            "i.001.001",
>            "i.002.001","i.002.002",
>            "i.003.001","i.003.002","i.003.003",
>            "i.004.001","i.004.002","i.004.003","i.004.004",
>            "i.005.001","i.005.002","i.005.003","i.005.004","i.005.005",
>            "i.006.001","i.006.002","i.006.003","i.006.004","i.006.005",
>            "i.007.001","i.007.002","i.007.003","i.007.004","i.007.005",
>            "i.008.001","i.008.002","i.008.003","i.008.004","i.008.005",
>            "i.009.001","i.009.002","i.009.003","i.009.004","i.009.005",
>            "i.010.001","i.010.002","i.010.003","i.010.004","i.010.005",
>            "i.006.006",
>            "i.007.006","i.007.007",
>            "i.008.006","i.008.007","i.008.008",
>            "i.009.006","i.009.007","i.009.008","i.009.009",
>            "i.010.006","i.010.007","i.010.008","i.010.009","i.010.010"
>           )
>
> one of the character vectors that matchs with the second 10 variable output
> is
>
> second.10<-c(
>            "i.002.001",
>            "i.003.001","i.003.002",
>            "i.004.001","i.004.002","i.004.003",
>            "i.005.001","i.005.002","i.005.003","i.005.004",
>            "i.006.001","i.006.002","i.006.003","i.006.004","i.006.005",
>            "i.007.001","i.007.002","i.007.003","i.007.004","i.007.005",
>            "i.008.001","i.008.002","i.008.003","i.008.004","i.008.005",
>            "i.009.001","i.009.002","i.009.003","i.009.004","i.009.005",
>            "i.010.001","i.010.002","i.010.003","i.010.004","i.010.005",
>            "i.007.006",
>            "i.008.006","i.008.007",
>            "i.009.006","i.009.007","i.009.008",
>            "i.010.006","i.010.007","i.010.008","i.010.009"
>           )
>
> and then assign the character vector to the numeric vector by
>
> names<-first.10
> first.10 = numeric.vector
> combined.one <- cbind(names,first.10)
> container <- diag(10)
> for (i in 1:(10*10))
>    {
>        k   <- as.numeric(substr(combined.one[i,1],7,9))
>        l   <- as.numeric(substr(combined.one [i,1],3,5))
>        val <- as.numeric(combined.one [i,2])
>        container [k,l] <- val
>    }
>
> container <- t(container )
>
> Is there any other neat way to do this?
>
> Any help would be appreciated
>
> TM
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Sun Feb  5 17:04:36 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 05 Feb 2006 11:04:36 -0500
Subject: [R] rgl install problem on Solaris 10 X86
In-Reply-To: <s3e5a877.050@OHSU.EDU>
References: <s3e5a877.050@OHSU.EDU>
Message-ID: <43E62214.2070103@stats.uwo.ca>

On 2/5/2006 10:25 AM, Dongseok Choi wrote:
> Hi,
>  
> Thank you very much for your prompt help.
>  
> 1)
> I downloaded 'rgl' package from CRAN and its version is 0.65.
> This seems to be the lasted.

That's the latest on CRAN, but not the latest available.  See my message 
below.  I have put Brian's suggested changes into the repository.

I can't help you with the other problems; I don't have any experience on 
Solaris.

Duncan Murdoch

>  
> 2)
>  I added those two lines and now Color.cpp is compiled OK.
>  However, I have a different error as following:
>  
> CC -xtarget=generic64 -I/export/home/choid/bin/R2.2.1/lib/R/include -I/usr/openwin/include -DHAVE_PNG_H -I/usr/include/libpng12 -I/mounts/devel/SUNWspro/prd/include -I/mounts/devel/GNU/repoz/readline43/include   -KPIC  -O -xlibmil -dalign -I/mounts/devel/SUNWspro/prod/include -c devicemanager.cpp -o devicemanager.o
> CC: Warning: Option -dalign passed to ld, if ld is invoked, ignored otherwise
> "devicemanager.cpp", line 19: Error: Could not find a match for std::vector<Device*>::vector(std::list<Device*>::iterator, std::list<Device*>::iterator) needed in DeviceManager::~DeviceManager().
> 1 Error(s) detected.
> *** Error code 1
> make: Fatal error: Command failed for target `devicemanager.o'
> ERROR: compilation failed for package 'rgl'
> 
>  
> 3) I am using,
> choi2100{choid}202: CC -V
> CC: Sun C++ 5.7 Patch 117831-02 2005/03/30
> 
> 4) Yes, -xlibmil and -dalign were used when I compiled the R with --with-lapack. 
> I think that I just followed the section for Sun Solaris for Sparc in "R-install" although I have Sparc x86.
> I saw that they are automatically added whenever I install any add-on packages.
> I'll try without them.
>  
> Thank you very much again,
> Dongseok
>  
> 
>>>> "Prof Brian Ripley" <ripley at stats.ox.ac.uk> 02/04/06 12:20 AM >>>
> 
> On Fri, 3 Feb 2006, Duncan Murdoch wrote:
> 
>> On 2/3/2006 6:37 PM, Dongseok Choi wrote:
>>> Hi,
>>>
>>>   Could you help me to install the rgl package on Solaris 10 x86?
>> No, but there have been a lot of changes to it since the last upload to
>> CRAN.  You might want to grab a new copy from
>> http://rgl.neoscientists.org/About.html by getting the latest Subversion
>> checkout.
> 
> I tried to reproduce this, but our Solaris box does not have GL installed. 
> My understanding is that the real problem seems to be that Color.cpp is 
> using undeclared ISO C functions and needs to include
> 
> #include <stdlib.h> // for realoc and free
> #include <string.h> // for memcpy
> 
> so please try adding them.
> 
> As for the -dalign messages, I presume you included them (like -xlibmil) 
> in CXXFLAGS.  They are supported by our SunPro compiler, so which version 
> is yours?  (In any case, you need to remove it, if I guessed right.)
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From john.janmaat at acadiau.ca  Sun Feb  5 17:50:53 2006
From: john.janmaat at acadiau.ca (John Janmaat)
Date: Sun,  5 Feb 2006 12:50:53 -0400
Subject: [R] Cluster Analysis
In-Reply-To: <43E62214.2070103@stats.uwo.ca>
References: <s3e5a877.050@OHSU.EDU> <43E62214.2070103@stats.uwo.ca>
Message-ID: <1139158253.43e62ced36709@webmail.acadiau.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060205/8c0eab15/attachment.pl

From francoisromain at free.fr  Sun Feb  5 18:03:47 2006
From: francoisromain at free.fr (Romain Francois)
Date: Sun, 05 Feb 2006 18:03:47 +0100
Subject: [R] Cluster Analysis
In-Reply-To: <1139158253.43e62ced36709@webmail.acadiau.ca>
References: <s3e5a877.050@OHSU.EDU> <43E62214.2070103@stats.uwo.ca>
	<1139158253.43e62ced36709@webmail.acadiau.ca>
Message-ID: <43E62FF3.2010408@free.fr>

Le 05.02.2006 17:50, John Janmaat a ??crit :

>Hello,
>
>I'm trying some cluster analysis, using the hclust command.  I am looking for 
>some help in selecting the 'best' number of clusters.  Some software reports 
>pseudo-F and pseudo-T^2 statistics, for each cluster merge.  Is there any way 
>to generate such statistics simply in R?
>
>Thanks,
>
>John.
>============================================================================
>Dr. John Janmaat                       Tel: 902-585-1461
>Department of Economics                Fax: 902-585-1461
>Acadia University,                     Email: jjanmaat at acadiau.ca
>Wolfville, Nova Scotia, Canada.        Web: ace.acadiau.ca/~jjanmaat/
>B4P 1H5
>  
>
Hi,

The package fpc have things like that.

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From pau.carre at gmail.com  Sun Feb  5 18:50:59 2006
From: pau.carre at gmail.com (pau carre)
Date: Sun, 5 Feb 2006 18:50:59 +0100
Subject: [R] R socket communication
Message-ID: <4b7300ee0602050950nf690204t@mail.gmail.com>

Hello, I tried to code a R socket server but I did not succeed.
The problem is that once the R socket server is created,
I call the readLines function and then R gets blocked.
The client seems to work fine since I tested it with a PERL server.
I tried many combination of params in the socketConnection but
none of them worked.

I have seen some examples where the server sends something to a
client but I need the opposite example.

Thanks,
Pau.

The R server

FSsocket() <- function(){
print("Creating server on localhost")
conn <- socketConnection(server = TRUE, port = 7890, open = "r+")
print("Reading data")
aa <- readLines(conn)
print("end reading lines")
close(conn)
pirnt("Connection closed")
}
Note: I receive a "Creating server on localhost" and a "Reading data"
in the R console, but nothing else.

The PERL client

#! /usr/bin/perl
use strict;
use Socket;

# initialize host and port
my $host = shift || 'localhost';
my $port = shift || 7890;

my $proto = getprotobyname('tcp');

my $iaddr = inet_aton($host);
my $paddr = sockaddr_in($port, $iaddr);

socket(SOCKET, PF_INET, SOCK_STREAM, $proto) or die "socket: $!";
connect(SOCKET, $paddr) or die "connect: $!";
print SOCKET "Hello \n";
close SOCKET or die "close: $!";

The PERL server

#! /usr/bin/perl -w

use strict;
use Socket;

my $port = shift || 7890;
my $proto = getprotobyname('tcp');

socket(SERVER, PF_INET, SOCK_STREAM, $proto) or die "socket: $!";
setsockopt(SERVER, SOL_SOCKET, SO_REUSEADDR, 1) or die "setsock: $!";

my $paddr = sockaddr_in($port, INADDR_ANY);

bind(SERVER, $paddr) or die "bind: $!";
listen(SERVER, SOMAXCONN) or die "listen: $!";
print "SERVER started on port $port ";

my $client_addr;
while ($client_addr = accept(CLIENT, SERVER))
{
my ($client_port, $client_ip) = sockaddr_in($client_addr);
my $client_ipnum = inet_ntoa($client_ip);
my $client_host = gethostbyaddr($client_ip, AF_INET);
print "Connection from: $client_host","[$client_ipnum] ";
while(<CLIENT>){
print "$_";
}
close CLIENT;
}



From phgrosjean at sciviews.org  Sun Feb  5 19:01:29 2006
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sun, 05 Feb 2006 19:01:29 +0100
Subject: [R] R socket communication
In-Reply-To: <4b7300ee0602050950nf690204t@mail.gmail.com>
References: <4b7300ee0602050950nf690204t@mail.gmail.com>
Message-ID: <43E63D79.8070403@sciviews.org>

See package svSocket in the SciViews bundle. It uses a socket server 
written in tcltk and it is not blocking the command line.

Philippe Grosjean

pau carre wrote:
> Hello, I tried to code a R socket server but I did not succeed.
> The problem is that once the R socket server is created,
> I call the readLines function and then R gets blocked.
> The client seems to work fine since I tested it with a PERL server.
> I tried many combination of params in the socketConnection but
> none of them worked.
> 
> I have seen some examples where the server sends something to a
> client but I need the opposite example.
> 
> Thanks,
> Pau.
> 
> The R server
> 
> FSsocket() <- function(){
> print("Creating server on localhost")
> conn <- socketConnection(server = TRUE, port = 7890, open = "r+")
> print("Reading data")
> aa <- readLines(conn)
> print("end reading lines")
> close(conn)
> pirnt("Connection closed")
> }
> Note: I receive a "Creating server on localhost" and a "Reading data"
> in the R console, but nothing else.
> 
> The PERL client
> 
> #! /usr/bin/perl
> use strict;
> use Socket;
> 
> # initialize host and port
> my $host = shift || 'localhost';
> my $port = shift || 7890;
> 
> my $proto = getprotobyname('tcp');
> 
> my $iaddr = inet_aton($host);
> my $paddr = sockaddr_in($port, $iaddr);
> 
> socket(SOCKET, PF_INET, SOCK_STREAM, $proto) or die "socket: $!";
> connect(SOCKET, $paddr) or die "connect: $!";
> print SOCKET "Hello \n";
> close SOCKET or die "close: $!";
> 
> The PERL server
> 
> #! /usr/bin/perl -w
> 
> use strict;
> use Socket;
> 
> my $port = shift || 7890;
> my $proto = getprotobyname('tcp');
> 
> socket(SERVER, PF_INET, SOCK_STREAM, $proto) or die "socket: $!";
> setsockopt(SERVER, SOL_SOCKET, SO_REUSEADDR, 1) or die "setsock: $!";
> 
> my $paddr = sockaddr_in($port, INADDR_ANY);
> 
> bind(SERVER, $paddr) or die "bind: $!";
> listen(SERVER, SOMAXCONN) or die "listen: $!";
> print "SERVER started on port $port ";
> 
> my $client_addr;
> while ($client_addr = accept(CLIENT, SERVER))
> {
> my ($client_port, $client_ip) = sockaddr_in($client_addr);
> my $client_ipnum = inet_ntoa($client_ip);
> my $client_host = gethostbyaddr($client_ip, AF_INET);
> print "Connection from: $client_host","[$client_ipnum] ";
> while(<CLIENT>){
> print "$_";
> }
> close CLIENT;
> }
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From pau.carre at gmail.com  Sun Feb  5 20:00:20 2006
From: pau.carre at gmail.com (pau carre)
Date: Sun, 5 Feb 2006 20:00:20 +0100
Subject: [R] R socket communication
Message-ID: <4b7300ee0602051100j62d388c7o@mail.gmail.com>

Hello, thank you for your help but I need to use the standard R
packages as I am developing an academic project and I the use of
external R packages is not allowed.
Pau.

2006/2/5, Philippe Grosjean <phgrosjean at sciviews.org>:
> See package svSocket in the SciViews bundle. It uses a socket server
> written in tcltk and it is not blocking the command line.
>
> Philippe Grosjean
>
> pau carre wrote:
> > Hello, I tried to code a R socket server but I did not succeed.
> > The problem is that once the R socket server is created,
> > I call the readLines function and then R gets blocked.
> > The client seems to work fine since I tested it with a PERL server.
> > I tried many combination of params in the socketConnection but
> > none of them worked.
> >
> > I have seen some examples where the server sends something to a
> > client but I need the opposite example.
> >
> > Thanks,
> > Pau.
> >
> > The R server
> >
> > FSsocket() <- function(){
> > print("Creating server on localhost")
> > conn <- socketConnection(server = TRUE, port = 7890, open = "r+")
> > print("Reading data")
> > aa <- readLines(conn)
> > print("end reading lines")
> > close(conn)
> > pirnt("Connection closed")
> > }
> > Note: I receive a "Creating server on localhost" and a "Reading data"
> > in the R console, but nothing else.
> >
> > The PERL client
> >
> > #! /usr/bin/perl
> > use strict;
> > use Socket;
> >
> > # initialize host and port
> > my $host = shift || 'localhost';
> > my $port = shift || 7890;
> >
> > my $proto = getprotobyname('tcp');
> >
> > my $iaddr = inet_aton($host);
> > my $paddr = sockaddr_in($port, $iaddr);
> >
> > socket(SOCKET, PF_INET, SOCK_STREAM, $proto) or die "socket: $!";
> > connect(SOCKET, $paddr) or die "connect: $!";
> > print SOCKET "Hello \n";
> > close SOCKET or die "close: $!";
> >
> > The PERL server
> >
> > #! /usr/bin/perl -w
> >
> > use strict;
> > use Socket;
> >
> > my $port = shift || 7890;
> > my $proto = getprotobyname('tcp');
> >
> > socket(SERVER, PF_INET, SOCK_STREAM, $proto) or die "socket: $!";
> > setsockopt(SERVER, SOL_SOCKET, SO_REUSEADDR, 1) or die "setsock: $!";
> >
> > my $paddr = sockaddr_in($port, INADDR_ANY);
> >
> > bind(SERVER, $paddr) or die "bind: $!";
> > listen(SERVER, SOMAXCONN) or die "listen: $!";
> > print "SERVER started on port $port ";
> >
> > my $client_addr;
> > while ($client_addr = accept(CLIENT, SERVER))
> > {
> > my ($client_port, $client_ip) = sockaddr_in($client_addr);
> > my $client_ipnum = inet_ntoa($client_ip);
> > my $client_host = gethostbyaddr($client_ip, AF_INET);
> > print "Connection from: $client_host","[$client_ipnum] ";
> > while(<CLIENT>){
> > print "$_";
> > }
> > close CLIENT;
> > }
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
>
>



From andrej.kastrin at siol.net  Sun Feb  5 21:21:20 2006
From: andrej.kastrin at siol.net (Andrej Kastrin)
Date: Sun, 05 Feb 2006 21:21:20 +0100
Subject: [R] for each element in matrix...
Message-ID: <43E65E40.8080307@siol.net>

Dead R useRs,

I wrote function, which plot dotchart from given matrix, compute mean 
from diagonal elements and plot it with abline. In addition, if 
particular element of matrix is greater then mean value (i.e. 
mead.diagonal), it should be plot in red, otherwise in green color.

graph <- function(a) {
    rownames(a) <- 1:nrow(a)
    colnames(a) <- 1:ncol(a)
    mean.diagonal <- mean(a[row(a) == col(a)])
    par(bg = "gray95")
    dotchart(a, cex = 0.9, main = "MeSH Plot", xlab = "frequency",
        bg = ifelse((a) > mean.diagonal,"red", "green2"),  # !!!
            pch = 21,labels = rownames(a))
    abline(v = mean.diagonal, col = "red", lty = 4)
}

And now the main problem: I suppose that there is some mismatch in 
ifelse statement while I produce two totally different plots:
first input matrix:  A <-matrix(rep(c(1,3,4),3),3,3) # seem that works
second input matrix B <-matrix(rnorm(9),3,3) # total confusion between 
green and red points

Any advice would be appreciated,

Cheers, Andrej



From ivowel at gmail.com  Sun Feb  5 22:28:50 2006
From: ivowel at gmail.com (ivo welch)
Date: Sun, 5 Feb 2006 16:28:50 -0500
Subject: [R] srt --- slope text with function?
In-Reply-To: <644e1f320602041605y48295b4bs263c2d58589d73a3@mail.gmail.com>
References: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>
	<43E51A7F.8080002@stats.uwo.ca>
	<50d1c22d0602041419y46761eb1x4f41fc82a5da9b60@mail.gmail.com>
	<644e1f320602041605y48295b4bs263c2d58589d73a3@mail.gmail.com>
Message-ID: <50d1c22d0602051328t5f3e9fbeh4ef4283a76e8ac07@mail.gmail.com>

Dear R Wizards:  To bore everyone to death, below is an improved and
hopefully final version of my native.slope() function.  (Thanks, Jim.)
 In case you are not asleep yet reading yet another post of mine, may
I ask the experts some programming questions?

  [I just saw yesterday's threat---I think it would be very, very, very nice if
  R would remember from what files with what linenumbers code came from.
  thus ignore below questions that mention this feature.  ALAS, I understand
  that this cannot be done generally.  But could not function definitions at
  least have a component that remembers this?]

* Is there a way that I can print an R functional backtrace?  Instead
of passing my subroutine name to my function "assert()" below, it
would be nice if I could just print the whole call tree [preferably
with file names+line numbers] when I want my program to gracefully
bonk out.  (PS: I think that this is also what R should print when any
user program bonks out, not just the stop message.)  Actually, I just
learned about traceback(), which functions nicely AFTER the program
stops, not before.  But it gives no traceback earlier---and it does
not give filename+lineno.

* is there a way to print all my user defined functions?  I have an
init file, in which I am defining all sorts of useful utility
functions, and I would like to print what I have defined (for memory)
upon a read of this init file?  that is, something that has
functionality like
   note.all.local.definitions.now.in.vector( all.local.functions )
   a <- function() { }
   b <- function() { }
   cat( all.local.functions ); # should print 'a' and 'b'.

* is there a string variable that gives me the name of the current
function I am in?

* SUGGESTION: can we please offer the "?:" operator ala C in addition
to ifelse()?  This would make R code prettier.  Similarly, perl has a
nice construct, which would be lovely, but which may not jive with the
R syntax:
    condition  or die("the condition", condition, "has failed");
    condition  and cat("my condition", condition, "is met");
I believe "or" and "and" are not defined, so this may be possible...

* has it now become possible to embed sample data sets in R code?  (I
asked this a while back, but there were nly kludges, no standard
"pretty" solutions.)

* SUGGESTION: The ?"function" docs would be terrific if they had a
small example at the end that showed how to return multiple arguments,
and then pick them up.  I believe this is best done through lists, but
I am not sure.

I find myself programming more and more in R, so I am beginning to see
it as my standard language, rather than as a statistical program.

Regards,

/iaw


################################################################
#### native.slope computes a suitable srt from a function around
#### a point on a function.  This is useful until text() gets
#### an srt parameter that is relative to the coordinate system.
####   (Ideally, R would be able to slope along a function.)
################################################################

native.slope <- function( x, y, where.i, debug =0) {

  assert <- function( condition, routine, ... ) {
    if (condition) return(NULL);
    cat(paste(routine,...));
    stop("THIS IS A FATAL ERROR!\n");
  }

  subname= "native.slope";  # until I discover how to print a complete
backtrace, this is it.

  assert( length(x) == length(y), subname,
	 "Sorry, but x and y must have equal dimensions, not ", length(x), "
and ", length(y), "\n");

  ## try to take a symmetric field around the point to be described
  l0= ifelse( where.i<=1, 1, where.i-1);
  l1= ifelse( where.i>=length(y), length(y), where.i+1);

  assert( !is.na(x[l0]), subname, "Sorry, but x[",l0,"] is NaN");
  assert( !is.na(x[l1]), subname, "Sorry, but x[",l1,"] is NaN");
  assert( !is.na(y[l0]), subname, "Sorry, but y[",l0,"] is NaN");
  assert( !is.na(y[l0]), subname, "Sorry, but y[",l1,"] is NaN");

  assert( y[l1] != y[l0], subname, "Sorry, but you cannot draw a slope
on a point");

  ## native slope in a 1:1 coordinate system
  d= ( (y[l0]-y[l1])/(x[l0]-x[l1]) );
  if (is.na(d)) return(0); # we do not know how to handle an undefined
spot at a function!

  ## now adjust by the axis scale and size of plot area
  .usr <- par('usr')  # dimensions of user units
  .plt <- par('plt') # percent of figure area that plot region is
  d.m <- (.usr[4] - .usr[3]) / (.usr[2] - .usr[1]) * (.plt[2] -
.plt[1]) / (.plt[4] - .plt[3])
  assert( !is.na(d.m), subname, "Internal Error: I do not have
sensible axis dimensions (", d.m, ")\n");

  ## now handle the drawing system
  .fin = par('fin');
  asp.ratio = .fin[1]/.fin[2];
  assert( !is.na(asp.ratio), subname, "Internal Error: I do not have a
reasonable drawing aspect ratio");

  net.slope= d/asp.ratio/d.m;
  slope = atan(net.slope)/pi*180.0;

  if (debug) {
    cat("\t", subname, "debug: d=", d, " (",y[where.i-1],y[where.i+1],
x[where.i-1], x[where.i+1],")\n",
	"\t\td.m=",d.m, " (", .usr, ",", .plt, ")\n",
	"\t\tasp.ratio=", .fin, "\n\t\t==> slope=", net.slope, "=", slope, "deg\n");
    points( x[where.i], y[where.i], pch=19 );
  }

  return( slope = slope );
}



From spencer.graves at pdf.com  Sun Feb  5 23:02:56 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 05 Feb 2006 14:02:56 -0800
Subject: [R] glm-logistic on discrete-time methods with individual and
 aggregated data
In-Reply-To: <8B08A3A1EA7AAC41BE24C750338754E6C0C3F3@HERMES.demogr.mpg.de>
References: <8B08A3A1EA7AAC41BE24C750338754E6C0C3F3@HERMES.demogr.mpg.de>
Message-ID: <43E67610.5000007@pdf.com>

	  You've found a region of infinite extent over which the likelihood 
function is for all practical purposes flat.  This means that the 
maximum likelihood estimates (MLEs) are not unique.  To see this 
consider the following properties of your datiINDa:

 > with(datiINDa, table(statusINDa, timesINDa))
           timesINDa
statusINDa  1  2  3  4
          0 10  8  6  4
          1  0  2  2  2
 > sapply(datiINDa, class)
  timesINDa statusINDa
   "factor"  "numeric"

	  You are estimating 4 parameters, an intercept plus one parameter for 
each level of the factor "timesInda".  The first level occurs only with 
statusINDa = 0, never with statusINDa = 1.  Therefore, the theoretical 
MLE for that level of timesINDa would have slope = +/-Inf (and the 
intercept would also be adjusted to +/-Inf to compensate).  However, glm 
doesn't bother pushing it that far, and gives up with still moderately 
small values for the parameters.  To understand this better, first 
modify your example to store the glm fitted object as follows:

fit.a <- glm(statusINDa ~ timesINDa, family=binomial, data=datiINDa)

	  Then apply "predict" to that object:

predict(fit.a, type="response")

	  The result is that the 10 cases with timesInda = 1 all have a 
Pr{statusINDa = 1} = 3e-9, which glm thinks is essentially 0 and quits.

	  Now let's do the same with your weighted version:

fit.wa <- glm(statusAGGa ~ timesAGGa, family=binomial, data=datiAGGa,
weights=weightAGGa)
sort(predict(fit.wa, type="response"))

	  Those 10 cases now have Pr{statusINDa = 1} = 5.4e-9.  This is 
essentially the issue of "complete separation".  We can request more 
precision as follows:

 > fit.a3 <- glm(statusINDa ~ timesINDa, family=binomial, data=datiINDa,
+           control=glm.control(epsilon=1e-13,
+             maxit=250))
Warning message:
fitted probabilities numerically 0 or 1 occurred in: glm.fit(x = X, y = 
Y, weights = weights, start = start, etastart = etastart,

	  In this case, we get a warning.  For more on this, try 
RSiteSearch("complete separation with logistic regression").

	  Sehr interessant, nicht?
	  hope this helps.
	  spencer graves

Camarda, Carlo Giovanni wrote:

> Dear R-Users,
> without going into details I tried to prepare a simple example to show
> you where I would need help.
> In particular I prepare two examples-template for a study I'm conduction
> on discrete-time methods for survival analysis.
> Each of this example has two datasets which are basically equal, with
> the exception that in the former one has individual data and in the
> latter one aggregated data.
> The difference between the two examples is on a single subject: I
> substituted to the first example a censored case with a subject who died
> at the first time-unit.
> Afterward I fitted a logistic model (Fahrmeir and Tutz, 2001) in the glm
> context, but whereas there is not difference between individual and
> aggregated dataset in the first example, I noted some discrepancies in
> the second example. I might guess that something with weights is going
> on, but I did not manage to clearly understand.
> Hope that the following example will be more clear than my explanations,
> Thanks in advance,
> Carlo Giovanni Camarda
> 
> 
> rm(list = ls())
> # working one
> 
> timesIND  <- c(rep(1:4, 3), 1, rep(1:2,2), rep(1:3     , 2), rep(1:4,
> 2))
> statusIND <- c(rep(0  ,12), 1, rep(0:1,2), rep(c(0,0,1), 2),
> rep(c(0,0,0,1),2))
> datiIND <- as.data.frame(cbind(timesIND, statusIND))
> datiIND$timesIND <- as.factor(datiIND$timesIND)
> 
> timesAGG  <- c(  1:4,    1,   1:2,      1:3,       1:4)
> statusAGG <- c(rep(0,4), 1,   0:1,    c(0,0,1), c(0,0,0,1))
> weightAGG <- c(rep(3,4), 1, rep(2,2), rep(2,3), rep(2,4))   
> datiAGG <- as.data.frame(cbind(timesAGG, statusAGG, weightAGG))
> datiAGG$timesAGG <- as.factor(datiAGG$timesAGG)
> 
> coef(glm(statusIND ~ timesIND, family=binomial, data=datiIND))
> coef(glm(statusAGG ~ timesAGG, family=binomial, data=datiAGG,
> weights=weightAGG))
> 
> # not working one
> 
> timesINDa  <- c(rep(1:4, 4), rep(1:2,2), rep(1:3     , 2), rep(1:4,
> 2))
> statusINDa <- c(rep(0  ,16), rep(0:1,2), rep(c(0,0,1), 2),
> rep(c(0,0,0,1),2))
> datiINDa <- as.data.frame(cbind(timesINDa, statusINDa))
> datiINDa$timesINDa <- as.factor(datiINDa$timesINDa)
> 
> timesAGGa  <- c( 1:4,        1:2,     1:3,      1:4)
> statusAGGa <- c(rep(0,4),    0:1,   c(0,0,1), c(0,0,0,1))
> weightAGGa <- c(rep(4,4), rep(2,2), rep(2,3),  rep(2,4))   
> datiAGGa <- as.data.frame(cbind(timesAGGa, statusAGGa, weightAGGa))
> datiAGGa$timesAGGa <- as.factor(datiAGGa$timesAGGa)
> 
> coef(glm(statusINDa ~ timesINDa, family=binomial, data=datiINDa))
> coef(glm(statusAGGa ~ timesAGGa, family=binomial, data=datiAGGa,
> weights=weightAGGa))
> 
> +++++
> This mail has been sent through the MPI for Demographic Rese...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From pkleiber at hawaii.rr.com  Mon Feb  6 01:35:45 2006
From: pkleiber at hawaii.rr.com (Pierre Kleiber)
Date: Sun, 05 Feb 2006 14:35:45 -1000
Subject: [R] srt --- slope text with function? (list user defined
	functions)
In-Reply-To: <50d1c22d0602051328t5f3e9fbeh4ef4283a76e8ac07@mail.gmail.com>
References: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>
	<43E51A7F.8080002@stats.uwo.ca>
	<50d1c22d0602041419y46761eb1x4f41fc82a5da9b60@mail.gmail.com>
	<644e1f320602041605y48295b4bs263c2d58589d73a3@mail.gmail.com>
	<50d1c22d0602051328t5f3e9fbeh4ef4283a76e8ac07@mail.gmail.com>
Message-ID: <43E699E1.4080108@hawaii.rr.com>

I'll respond to one of your multitude of queries below.  Suggest that you 
confine your postings to a single issue so that the subject heading is more 
meaningful.

Cheers, Pierre


ivo welch offered the following remark on 02/05/06 11:28...
[...]
> 
> * is there a way to print all my user defined functions?  I have an
> init file, in which I am defining all sorts of useful utility
> functions, and I would like to print what I have defined (for memory)
> upon a read of this init file?  that is, something that has
> functionality like
>    note.all.local.definitions.now.in.vector( all.local.functions )
>    a <- function() { }
>    b <- function() { }
>    cat( all.local.functions ); # should print 'a' and 'b'.

The following lists the functions defined in a (default current) environment:

"lsf" <- function (pos = 1)
{
   junk <- ls(pos, all.names = TRUE)
   junk[sapply(junk, function(x) is.function(eval(as.symbol(x))))]
}

> 
[...]
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
-----------------------------------------------------------------
Pierre Kleiber, Ph.D               Email: pierre.kleiber at noaa.gov
Pacific Island Fisheries Science Center         Tel: 808 983-5399
NOAA Fisheries
2570 Dole St., Honolulu, HI 96822-2396
-----------------------------------------------------------------
  "God could have told Moses about galaxies and mitochondria and
   all.  But behold... It was good enough for government work."



From murdoch at stats.uwo.ca  Mon Feb  6 02:22:21 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 05 Feb 2006 20:22:21 -0500
Subject: [R] srt --- slope text with function?
In-Reply-To: <50d1c22d0602051328t5f3e9fbeh4ef4283a76e8ac07@mail.gmail.com>
References: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>	<43E51A7F.8080002@stats.uwo.ca>	<50d1c22d0602041419y46761eb1x4f41fc82a5da9b60@mail.gmail.com>	<644e1f320602041605y48295b4bs263c2d58589d73a3@mail.gmail.com>
	<50d1c22d0602051328t5f3e9fbeh4ef4283a76e8ac07@mail.gmail.com>
Message-ID: <43E6A4CD.8080800@stats.uwo.ca>

On 2/5/2006 4:28 PM, ivo welch wrote:
> Dear R Wizards:  To bore everyone to death, below is an improved and
> hopefully final version of my native.slope() function.  (Thanks, Jim.)
>  In case you are not asleep yet reading yet another post of mine, may
> I ask the experts some programming questions?
> 
>   [I just saw yesterday's threat---I think it would be very, very, very nice if
>   R would remember from what files with what linenumbers code came from.
>   thus ignore below questions that mention this feature.  ALAS, I understand
>   that this cannot be done generally.  But could not function definitions at
>   least have a component that remembers this?]
> 
> * Is there a way that I can print an R functional backtrace?  Instead
> of passing my subroutine name to my function "assert()" below, it
> would be nice if I could just print the whole call tree [preferably
> with file names+line numbers] when I want my program to gracefully
> bonk out.  (PS: I think that this is also what R should print when any
> user program bonks out, not just the stop message.)  Actually, I just
> learned about traceback(), which functions nicely AFTER the program
> stops, not before.  But it gives no traceback earlier---and it does
> not give filename+lineno.

There's going to be a new section on debugging in the R 2.3.0 "Writing R 
Extensions" manual (written by Brian Ripley).  You can see it now if you 
build R-devel (or download a binary build from CRAN; I put Windows 
builds there approximately daily).  I also put together a 
Windows-oriented debugging page at 
http://www.stats.uwo.ca/faculty/murdoch/software/debuggingR/.


> 
> * is there a way to print all my user defined functions?  I have an
> init file, in which I am defining all sorts of useful utility
> functions, and I would like to print what I have defined (for memory)
> upon a read of this init file?  that is, something that has
> functionality like
>    note.all.local.definitions.now.in.vector( all.local.functions )
>    a <- function() { }
>    b <- function() { }
>    cat( all.local.functions ); # should print 'a' and 'b'.

ls.str() includes an option to select only functions.  You could also 
write your own filter for ls() output.
> 
> * is there a string variable that gives me the name of the current
> function I am in?

I don't think so, but sys.call() gets close.  Watch out though:  the 
name you see will be the name used by the caller, which may not be the 
name used when the function was written.  For example, in a function 
called from apply(), you'll see FUN, not the original name.  Objects 
don't know their own names in general, because they keep getting passed 
around.

> * SUGGESTION: can we please offer the "?:" operator ala C in addition
> to ifelse()?  This would make R code prettier.  Similarly, perl has a
> nice construct, which would be lovely, but which may not jive with the
> R syntax:
>     condition  or die("the condition", condition, "has failed");
>     condition  and cat("my condition", condition, "is met");
> I believe "or" and "and" are not defined, so this may be possible...

The ? operator is already used as a prefix and infix operator (for the 
help system), so this seems unlikely.

> * has it now become possible to embed sample data sets in R code?  (I
> asked this a while back, but there were nly kludges, no standard
> "pretty" solutions.)

I don't understand the question.  dump() produces R code that can 
reconstruct a dataset; is that what you want?
> 
> * SUGGESTION: The ?"function" docs would be terrific if they had a
> small example at the end that showed how to return multiple arguments,
> and then pick them up.  I believe this is best done through lists, but
> I am not sure.

I'd guess most people learn about functions from the Intro to R manual 
rather than the "function" man page, but this is a good suggestion.

Duncan Murdoch
> 
> I find myself programming more and more in R, so I am beginning to see
> it as my standard language, rather than as a statistical program.
> 
> Regards,
> 
> /iaw
> 
> 
> ################################################################
> #### native.slope computes a suitable srt from a function around
> #### a point on a function.  This is useful until text() gets
> #### an srt parameter that is relative to the coordinate system.
> ####   (Ideally, R would be able to slope along a function.)
> ################################################################
> 
> native.slope <- function( x, y, where.i, debug =0) {
> 
>   assert <- function( condition, routine, ... ) {
>     if (condition) return(NULL);
>     cat(paste(routine,...));
>     stop("THIS IS A FATAL ERROR!\n");
>   }
> 
>   subname= "native.slope";  # until I discover how to print a complete
> backtrace, this is it.
> 
>   assert( length(x) == length(y), subname,
> 	 "Sorry, but x and y must have equal dimensions, not ", length(x), "
> and ", length(y), "\n");
> 
>   ## try to take a symmetric field around the point to be described
>   l0= ifelse( where.i<=1, 1, where.i-1);
>   l1= ifelse( where.i>=length(y), length(y), where.i+1);
> 
>   assert( !is.na(x[l0]), subname, "Sorry, but x[",l0,"] is NaN");
>   assert( !is.na(x[l1]), subname, "Sorry, but x[",l1,"] is NaN");
>   assert( !is.na(y[l0]), subname, "Sorry, but y[",l0,"] is NaN");
>   assert( !is.na(y[l0]), subname, "Sorry, but y[",l1,"] is NaN");
> 
>   assert( y[l1] != y[l0], subname, "Sorry, but you cannot draw a slope
> on a point");
> 
>   ## native slope in a 1:1 coordinate system
>   d= ( (y[l0]-y[l1])/(x[l0]-x[l1]) );
>   if (is.na(d)) return(0); # we do not know how to handle an undefined
> spot at a function!
> 
>   ## now adjust by the axis scale and size of plot area
>   .usr <- par('usr')  # dimensions of user units
>   .plt <- par('plt') # percent of figure area that plot region is
>   d.m <- (.usr[4] - .usr[3]) / (.usr[2] - .usr[1]) * (.plt[2] -
> .plt[1]) / (.plt[4] - .plt[3])
>   assert( !is.na(d.m), subname, "Internal Error: I do not have
> sensible axis dimensions (", d.m, ")\n");
> 
>   ## now handle the drawing system
>   .fin = par('fin');
>   asp.ratio = .fin[1]/.fin[2];
>   assert( !is.na(asp.ratio), subname, "Internal Error: I do not have a
> reasonable drawing aspect ratio");
> 
>   net.slope= d/asp.ratio/d.m;
>   slope = atan(net.slope)/pi*180.0;
> 
>   if (debug) {
>     cat("\t", subname, "debug: d=", d, " (",y[where.i-1],y[where.i+1],
> x[where.i-1], x[where.i+1],")\n",
> 	"\t\td.m=",d.m, " (", .usr, ",", .plt, ")\n",
> 	"\t\tasp.ratio=", .fin, "\n\t\t==> slope=", net.slope, "=", slope, "deg\n");
>     points( x[where.i], y[where.i], pch=19 );
>   }
> 
>   return( slope = slope );
> }
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From phawkins at connact.com  Sun Feb  5 23:48:14 2006
From: phawkins at connact.com (Patricia J. Hawkins)
Date: Sun, 05 Feb 2006 17:48:14 -0500
Subject: [R] Glossay of available R functions
In-Reply-To: <Pine.LNX.4.61.0602030701370.4544@gannet.stats> (Brian Ripley's
	message of "Fri, 3 Feb 2006 07:11:42 +0000 (GMT)")
References: <Pine.LNX.4.61.0601310801310.4916@gannet.stats>
	<001b01c62672$825d7d10$0e010a0a@headquarters>
	<20060131143604.GA12731@psych.upenn.edu> <wky80tz87d.fsf@connact.com>
	<Pine.LNX.4.61.0602030701370.4544@gannet.stats>
Message-ID: <wk3bixtob5.fsf@connact.com>

>>>>> "PBR" == Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

>> commenting that subset was new to him, though he did say "list of
>> functions in R".  I'd searched through everything _else_ in the help
>> system looking for such a glossary; I hadn't thought to look under
>> *Packages*, as those are, of course, add-ons.

PBR> `Of course' is incorrect here.  Everything in R is in a package.

Just my thinking at the time; once I realized that everything in R is
a package, it occurred to me to look under the "packages" heading.
But that was after reading the R Language Reference Manual, and
working through a good bit of the Introduction To R.

>> So a comment such as "For an index of R basic objects, see the
>> 'base' package under *Packages*" on the help.start() index page
>> would be helpful.

PBR> But (as I originally pointed out), that is not a correct
PBR> interpretation of `basic'.  It might have been in R 1.8.0, but
PBR> the 'base' package is now intended to support only some scripting
PBR> operations (where speed is essential so it is minimal).  Unlike
PBR> Python, R is not primarily a scripting language.

Oh -- I understand; thank you.  In retrospect, I was looking for the
things clueless (or cluefull) newcomers should be familiar with before
coming and bothering R-help with clueless newcomer questions.

I didn't mean to try your patience -- just to suggest a couple of
links in the documentation so that well-written information that
exists, and that *ought* to hit newcomers like a brick, would in fact
hit us like a brick.

PBR> The analogue of the Python Standard Library is I think the
PBR> standard packages.

Thank you!  That's helpful.

-- 
Patricia J. Hawkins
Hawkins Internet Applications
www.hawkinsia.com
"blundering through software language manuals since 1979"



From phawkins at connact.com  Mon Feb  6 02:18:16 2006
From: phawkins at connact.com (Patricia J. Hawkins)
Date: Sun, 05 Feb 2006 20:18:16 -0500
Subject: [R] readline detection problems
In-Reply-To: <NOEOKKCPBGIAIPPDONMGAEGICBAA.b.otto@uke.uni-hamburg.de> (Benjamin
	Otto's message of "Thu, 2 Feb 2006 14:09:45 +0100")
References: <NOEOKKCPBGIAIPPDONMGAEGICBAA.b.otto@uke.uni-hamburg.de>
Message-ID: <wkoe1ls2sn.fsf@connact.com>

>>>>> "BO" == Benjamin Otto <b.otto at uke.uni-hamburg.de> writes:

BO> Dear community,
BO> I'm trying to install R-2.2.1 on an IRIX 6.2 (Unix System V Release 4)
BO> system without root access. Unfortunately readline is not installed in
BO> default, so I installed it locally in my home directory, more precisely in:
BO> $HOME/vol/readline-5.1, where $HOME is "/home3/fa/faga001". Afterwards I
BO> appended the path to the library with several $PATH variable, which now
BO> looks like:

BO> PATH=:/usr/sbin:/usr/bsd:/sbin:/usr/bin:/bin:/usr/bin/X11:/usr/local/bin:/us
BO> r/freeware/bin:/usr/local/bin:.:/home3/fa/faga001/vol:/home3/fa/faga001/vol/
BO> readline-5.1:/home3/fa/faga001/vol/readline-5.1/lib

Ok, on Unix-alikes, libraries and executables are treated differently;
PATH is for executables only.  So you're looking for something to do
with libraries.

BO> Still, readline is not detected by the configure script. I tried the
BO> commands:

BO> ./configure --with-readline="-L/$HOME/vol/readline"
BO> ./configure --with-readline="/$HOME/vol/readline"
BO> ./configure --with-readline=/$HOME/vol/readline

If you run "./configure --help", it tells you that --with-readline
takes the values 'yes' and 'no', with the default being 'yes', so you
don't need to set it.

BO> ./configure --x-includes="-L/$HOME/vol/readline"
BO> ./configure --x-includes="/$HOME/vol/readline"

This is for telling configure where to find X window system header
files (.h or .hh files)

BO> ./configure --x-libraries="-L/$HOME/vol/readline"
BO> ./configure --x-libraries="/$HOME/vol/readline"

This is for telling configure where to find X window system libraries.

If you look at the R Installation and Administration help page, and
search on "compilation flags" (or just search repeatedly on "readline"!),
you'll find that what you want to set is the environment variable
LDFLAGS -- probably like this:
export LDFLAGS="-L/home3/fa/faga001/vol/readline-5.1/"
or
export LDFLAGS="-L/home3/fa/faga001/vol/readline-5.1/ -L/usr/local/lib"

BO> trying out the different path variants which I previously included
BO> in the $PATH variable. Nothing helps yet. According to printenv
BO> there is currently no kind of $LIBRARY or sth. like that defined,
BO> but maybe the path should rather be included in such an
BO> env. variable, I didn't find any hint in the documentation.

When all else fails, I resort to pulling the configure script into my
favorite text editor and reading that...

-- 
Patricia J. Hawkins
Hawkins Internet Applications
www.hawkinsia.com



From phawkins at connact.com  Mon Feb  6 00:20:22 2006
From: phawkins at connact.com (Patricia J. Hawkins)
Date: Sun, 05 Feb 2006 18:20:22 -0500
Subject: [R] Glossay of available R functions
In-Reply-To: <2a9c000c0602040749u2a7b83d9i3058d87d280603c1@mail.gmail.com> (Jim
	Porzak's message of "Sat, 4 Feb 2006 07:49:16 -0800")
References: <200601302031.k0UKVGob001618@hypatia.math.ethz.ch>
	<43DE78E7.5040209@optonline.net>
	<200601301900.50123.asaguiar@spsconsultoria.com>
	<wkvew1e16o.fsf@connact.com>
	<2a9c000c0602040749u2a7b83d9i3058d87d280603c1@mail.gmail.com>
Message-ID: <wkvevts895.fsf@connact.com>


>>>>> "MHHS" == Martin Henry H Stevens <stevenmh at muohio.edu> writes:

MHHS> Start R help, and select the Search Engine & Keywords link. This
MHHS> will take you to a page where keywords (including functions) are
MHHS> arranged by topic. It includes base and "recommended"
MHHS> packages. Also not that on the CRAN website (and mirrors) is a
MHHS> link for Task Views. There, packages are grouped by topic.

Thank you, that's useful.

>>>>> "JP" == Jim Porzak <jporzak at gmail.com> writes:

JP> Alexandre & Patricia,
JP> As Bert Gunter periodically points out:

JP> "Newbies (and others!) may find useful the R Reference Card made available by
JP> Tom Short and Rpad at http://www.rpad.org/Rpad/Rpad-refcard.pdf  or through
JP> the "Contributed" link on CRAN (where some other reference cards are also
JP> linked)
....

JP> I still keep a hard copy of Tom Short's referncece card handy, as do
JP> most of my colleagues at Loyalty Matrix.

Got it!  Thank you, very handy.

-- 
Patricia J. Hawkins
Hawkins Internet Applications
www.hawkinsia.com



From jholtman at gmail.com  Mon Feb  6 04:13:31 2006
From: jholtman at gmail.com (jim holtman)
Date: Sun, 5 Feb 2006 22:13:31 -0500
Subject: [R] reading in a tricky computer program output
In-Reply-To: <BAY110-F209B90446EFBC59FB9EAB0C70F0@phx.gbl>
References: <BAY110-F209B90446EFBC59FB9EAB0C70F0@phx.gbl>
Message-ID: <644e1f320602051913s6440a2ffk24aa8046aceac8f8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060205/544b8651/attachment.pl

From asaguiar at spsconsultoria.com  Mon Feb  6 04:17:50 2006
From: asaguiar at spsconsultoria.com (Alexandre Santos Aguiar)
Date: Mon, 6 Feb 2006 01:17:50 -0200
Subject: [R] readline detection problems
In-Reply-To: <wkoe1ls2sn.fsf@connact.com>
References: <NOEOKKCPBGIAIPPDONMGAEGICBAA.b.otto@uke.uni-hamburg.de>
	<wkoe1ls2sn.fsf@connact.com>
Message-ID: <200602060117.51468.asaguiar@spsconsultoria.com>

> without root access.

Benjamin,

In a "normal" Unix environment non root users can't install software. This is 
one of the reasons why Unix systems are more secure.

When you compile readline by "./configure; make; make install"  some system 
files must be created: headers must be installed to include path used by cc 
and gcc, the compiled files must be copied to their proper location and 
perhaps a few symbolic links created.

All these steps are missing in your readline  compilation due to lack of 
privilege and this is probably reported by make.

If readline was installed as a package by the system administrator, perhaps 
you need another package like readline-devel with library headers.

When you run ./configure for R compilation those readline headers are searched 
for and inspected for version and functionality, not only (and less likely) 
binaries.

Your attempt of changing shell variables will not work since kernels search 
for lib files only in root-only access disk regions and kernels do not care 
for shell variables exactly to avoid overriding legitimate libraries with 
code by non root users. It's a matter of security.

Actually your attempts may be taken as attempts of hacking the system... :-)

-- 

          Alexandre Santos Aguiar, MD
- independent consultant for health research -
       R Botucatu, 591 cj 81 - 04037-005
            S??o Paulo - SP - Brazil
             tel +55-11-9320-2046
             fax +55-11-5549-8760
            www.spsconsultoria.com



From bitwrit at ozemail.com.au  Mon Feb  6 20:28:39 2006
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Mon, 06 Feb 2006 14:28:39 -0500
Subject: [R] 3-dimensional table
In-Reply-To: <43E59CD8020000F200007265@TMIA1.AUBURN.EDU>
References: <43E59CD8020000F200007265@TMIA1.AUBURN.EDU>
Message-ID: <43E7A367.30106@ozemail.com.au>

Jeffrey Stratford wrote:
> Hi,
> 
> Last week my class conducted an experiment by putting out clay
> caterpillars to look at the effects of urbanization, color, and location
> on caterpillar predation.  There were two sites (urban, rural), three
> colors (green, yellow, red) and two locations at each site (edge,
> interior).  The entire data set is below.  I've checked out the MASS
> book, Dalgaard's book, and the R-help archives and I haven't found
> anything that suggests how to set up a spreadsheet for the xtab function
> (say, xtab(predation ~ location + site + color, data=class).   It would
> not be a problem to input the data by hand but I wouldn't know how to
> set that up either.  Any suggestions would be greatly appreciated.  The
> class is mostly college sophmores and juniors and biology and education
> majors.  We are using R 2.2.1 on Windows XP.   
> 
Hi Jeff,

For some unknown reason, you used the name of a function that I wrote 
some years ago that may do what you want. Just call it the way you have 
above and it should work.

Jim

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: xtab.R
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060206/08f342cd/xtab.pl
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: xtab.Rd
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060206/08f342cd/xtab-0001.pl

From daniel.c.medina at gmail.com  Mon Feb  6 04:59:03 2006
From: daniel.c.medina at gmail.com (Daniel Medina)
Date: Sun, 5 Feb 2006 22:59:03 -0500
Subject: [R] Fixing AR coefficients in VAR model
Message-ID: <550c175b0602051959m6b5e3496m48f5346326c31e07@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060205/b1778425/attachment.pl

From ivowel at gmail.com  Mon Feb  6 05:24:38 2006
From: ivowel at gmail.com (ivo welch)
Date: Sun, 5 Feb 2006 23:24:38 -0500
Subject: [R] drawing outside a plot region
Message-ID: <50d1c22d0602052024s7d13afe9t193931401b01488b@mail.gmail.com>

Dear R wizards:  First, thank you for all the responses to my earlier
queries.  Will keep me busy tomorrow morning.  Can I add one graphics
question to my ever changing set of bothering questions, please?

plot( c(0,1), c(0,1) );
crop.to.plot.off();   # what I want; does not exist
text( -0.3, 0.1, " this is 0.1 "); arrows(-0.1,0.1,0,0.1);
crop.to.plot.on();   # what I want; does not exist

of course, the text and most of the arrow is cropped.  for most of my
graph, I like the crop, but here I would like to turn it off.

possible?

regards,

/iaw



From hodgess at gator.dt.uh.edu  Mon Feb  6 05:30:57 2006
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Sun, 5 Feb 2006 22:30:57 -0600
Subject: [R]  decomposed.ts class and method
Message-ID: <200602060430.k164Uv1X023560@gator.dt.uh.edu>

Dear R People:

In the function "decompose", the object has the class of "decomposed.ts".
(from package stats)

I would like to see the class definition and the method for the plotting.

However, when I use
isClass("decomposed.ts")

I get "FALSE".

When I check getMethods("plot")

there is no method for plot on decomposed.ts

Any suggestions, please?

Thanks in advance!

R Version 2.2.1 Windows

Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu



From ggrothendieck at gmail.com  Mon Feb  6 05:36:47 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 5 Feb 2006 23:36:47 -0500
Subject: [R] decomposed.ts class and method
In-Reply-To: <200602060430.k164Uv1X023560@gator.dt.uh.edu>
References: <200602060430.k164Uv1X023560@gator.dt.uh.edu>
Message-ID: <971536df0602052036i13bf5bd9ndc59315f119d3706@mail.gmail.com>

Try:

getAnywhere(plot.decomposed.ts)
getAnywhere(print.decomposed.ts) # not found; its using print.default

Also note this gives an S3 generic's methods:

methods(plot)

On 2/5/06, Erin Hodgess <hodgess at gator.dt.uh.edu> wrote:
> Dear R People:
>
> In the function "decompose", the object has the class of "decomposed.ts".
> (from package stats)
>
> I would like to see the class definition and the method for the plotting.
>
> However, when I use
> isClass("decomposed.ts")
>
> I get "FALSE".
>
> When I check getMethods("plot")
>
> there is no method for plot on decomposed.ts
>
> Any suggestions, please?
>
> Thanks in advance!
>
> R Version 2.2.1 Windows
>
> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Mon Feb  6 05:37:14 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 5 Feb 2006 23:37:14 -0500
Subject: [R] drawing outside a plot region
In-Reply-To: <50d1c22d0602052024s7d13afe9t193931401b01488b@mail.gmail.com>
References: <50d1c22d0602052024s7d13afe9t193931401b01488b@mail.gmail.com>
Message-ID: <971536df0602052037p21872addpe971bd2f83290b35@mail.gmail.com>

Check xpd= in ?par

On 2/5/06, ivo welch <ivowel at gmail.com> wrote:
> Dear R wizards:  First, thank you for all the responses to my earlier
> queries.  Will keep me busy tomorrow morning.  Can I add one graphics
> question to my ever changing set of bothering questions, please?
>
> plot( c(0,1), c(0,1) );
> crop.to.plot.off();   # what I want; does not exist
> text( -0.3, 0.1, " this is 0.1 "); arrows(-0.1,0.1,0,0.1);
> crop.to.plot.on();   # what I want; does not exist
>
> of course, the text and most of the arrow is cropped.  for most of my
> graph, I like the crop, but here I would like to turn it off.
>
> possible?
>
> regards,
>
> /iaw
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From deepayan.sarkar at gmail.com  Mon Feb  6 06:58:30 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Sun, 5 Feb 2006 23:58:30 -0600
Subject: [R] wireframe zlim option
In-Reply-To: <20060205091232.12802.qmail@turing.mathematik.uni-ulm.de>
References: <20060205091232.12802.qmail@turing.mathematik.uni-ulm.de>
Message-ID: <eb555e660602052158w1311b820s933dd10088373e0d@mail.gmail.com>

On 2/5/06, Marius Hofert <mhofert at mathematik.uni-ulm.de> wrote:
> Hello,
>
> I would like to plot a wireframe of a function which is defined on the
> unit square using the lattice library (for trellis-like plots). The plot
> contains z-values of about 100 (only in the neighborhood of zero) although
> most of the z-values are in the range of -let's say- 0 to 10. If I
> evaluate this function on an equidistant grid of 25 points on the unit
> square the plot quality is not very good, but I can see the rough shape of
> the plot (i.e. I can see the that the points in the range of 0 to 10 have
> different heights). If I increase the grid points to 100 (so the function
> is evaluated on an equidistant grid with 100^2 points), the plot quality
> increases (i.e. the plot gets smooth), but I can hardly see any structure
> of the plot as the points in the neighborhood of zero of course dominate
> the plot (and all points in the range from 0 to 10 seem to just have the
> same height) and as I evaluate more of the points close to 0 this behavior
> is obvious. Therefore I would like to restrict the z-values plotted. I
> couldn't find any help for that and the usual "zlim=c(0,30)" (which should
> only plot the z-values lying in the range from 0 to 30) did not work for
> the wireframe function of the lattice package.
> The call I tried was
>
> >library(lattice)
> >wireframe(z~x*y,zlim=c(0,30),drape=T,distance=0,colorkey=list(tick.number=6))
>
> Any hints are appreciated

If I understand you correctly, setting

z[z > 30] <- NA

before the call to wireframe may help.

Deepayan
--
http://www.stat.wisc.edu/~deepayan/



From sumantab at ambaresearch.com  Mon Feb  6 07:42:12 2006
From: sumantab at ambaresearch.com (Sumanta Basak)
Date: Mon, 6 Feb 2006 12:12:12 +0530
Subject: [R] Help In Sequence of Dates
Message-ID: <14850601FF012647A90A5DB31F96DB374106D2@INBLRDC01.BANG.irpvl.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060206/ebc221cb/attachment.pl

From ggrothendieck at gmail.com  Mon Feb  6 08:02:21 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 6 Feb 2006 02:02:21 -0500
Subject: [R] Help In Sequence of Dates
In-Reply-To: <14850601FF012647A90A5DB31F96DB374106D2@INBLRDC01.BANG.irpvl.com>
References: <14850601FF012647A90A5DB31F96DB374106D2@INBLRDC01.BANG.irpvl.com>
Message-ID: <971536df0602052302n240c6a0fu1f7b1246ceadcd6b@mail.gmail.com>

Try

?seq.Date

On 2/6/06, Sumanta Basak <sumantab at ambaresearch.com> wrote:
>
>
> Dear R-users,
>
>
>
> First of all, I'm sorry if this is a simple question.  I want a daily
> date series which will be a sequence. E.g. starting from 07/03/1962 to
> 12/03/1997. Thanks in advance. I want to paste this date series with the
> data series I have.
>
>
>
> Thanks & Regards,
>
> Sumanta Basak.
>
>
> -------------------------------------------------------------------------------------------------------------------
> This e-mail may contain confidential and/or privileged infor...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Mon Feb  6 08:30:15 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 6 Feb 2006 07:30:15 +0000 (GMT)
Subject: [R] srt --- slope text with function? (list user defined
	functions)
In-Reply-To: <43E699E1.4080108@hawaii.rr.com>
References: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>
	<43E51A7F.8080002@stats.uwo.ca>
	<50d1c22d0602041419y46761eb1x4f41fc82a5da9b60@mail.gmail.com>
	<644e1f320602041605y48295b4bs263c2d58589d73a3@mail.gmail.com>
	<50d1c22d0602051328t5f3e9fbeh4ef4283a76e8ac07@mail.gmail.com>
	<43E699E1.4080108@hawaii.rr.com>
Message-ID: <Pine.LNX.4.61.0602060724390.7548@gannet.stats>

On Sun, 5 Feb 2006, Pierre Kleiber wrote:

> I'll respond to one of your multitude of queries below.  Suggest that you
> confine your postings to a single issue so that the subject heading is more
> meaningful.
>
> Cheers, Pierre
>
>
> ivo welch offered the following remark on 02/05/06 11:28...
> [...]
>>
>> * is there a way to print all my user defined functions?  I have an
>> init file, in which I am defining all sorts of useful utility
>> functions, and I would like to print what I have defined (for memory)
>> upon a read of this init file?  that is, something that has
>> functionality like
>>    note.all.local.definitions.now.in.vector( all.local.functions )
>>    a <- function() { }
>>    b <- function() { }
>>    cat( all.local.functions ); # should print 'a' and 'b'.
>
> The following lists the functions defined in a (default current) environment:
>
> "lsf" <- function (pos = 1)
> {
>   junk <- ls(pos, all.names = TRUE)
>   junk[sapply(junk, function(x) is.function(eval(as.symbol(x))))]
> }

I am sorry, it does not in general (since eval is not looking in that 
environment).  See ls.str (in utils) for a more elegant way to do this via 
exists(mode = "function")

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Feb  6 08:32:26 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 6 Feb 2006 07:32:26 +0000 (GMT)
Subject: [R] drawing outside a plot region
In-Reply-To: <50d1c22d0602052024s7d13afe9t193931401b01488b@mail.gmail.com>
References: <50d1c22d0602052024s7d13afe9t193931401b01488b@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0602060730480.7548@gannet.stats>

On Sun, 5 Feb 2006, ivo welch wrote:

> Dear R wizards:  First, thank you for all the responses to my earlier
> queries.  Will keep me busy tomorrow morning.  Can I add one graphics
> question to my ever changing set of bothering questions, please?
>
> plot( c(0,1), c(0,1) );
> crop.to.plot.off();   # what I want; does not exist
> text( -0.3, 0.1, " this is 0.1 "); arrows(-0.1,0.1,0,0.1);
> crop.to.plot.on();   # what I want; does not exist
>
> of course, the text and most of the arrow is cropped.  for most of my
> graph, I like the crop, but here I would like to turn it off.

See par(xpd) which does exactly this (and also allows cropping to the 
figure region).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Feb  6 08:33:53 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 6 Feb 2006 07:33:53 +0000 (GMT)
Subject: [R] decomposed.ts class and method
In-Reply-To: <200602060430.k164Uv1X023560@gator.dt.uh.edu>
References: <200602060430.k164Uv1X023560@gator.dt.uh.edu>
Message-ID: <Pine.LNX.4.61.0602060732380.7548@gannet.stats>

This is an S3 class, not an S4 class.  (Package stats does not use S4 
classes: only package stats4 in the R tarball does.)

On Sun, 5 Feb 2006, Erin Hodgess wrote:

> Dear R People:
>
> In the function "decompose", the object has the class of "decomposed.ts".
> (from package stats)
>
> I would like to see the class definition and the method for the plotting.
>
> However, when I use
> isClass("decomposed.ts")
>
> I get "FALSE".
>
> When I check getMethods("plot")
>
> there is no method for plot on decomposed.ts
>
> Any suggestions, please?
>
> Thanks in advance!
>
> R Version 2.2.1 Windows
>
> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Feb  6 08:49:03 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 6 Feb 2006 07:49:03 +0000 (GMT)
Subject: [R] srt --- slope text with function?
In-Reply-To: <43E6A4CD.8080800@stats.uwo.ca>
References: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>
	<43E51A7F.8080002@stats.uwo.ca>
	<50d1c22d0602041419y46761eb1x4f41fc82a5da9b60@mail.gmail.com>
	<644e1f320602041605y48295b4bs263c2d58589d73a3@mail.gmail.com>
	<50d1c22d0602051328t5f3e9fbeh4ef4283a76e8ac07@mail.gmail.com>
	<43E6A4CD.8080800@stats.uwo.ca>
Message-ID: <Pine.LNX.4.61.0602060734580.7548@gannet.stats>

On Sun, 5 Feb 2006, Duncan Murdoch wrote:

> On 2/5/2006 4:28 PM, ivo welch wrote:
>> Dear R Wizards:  To bore everyone to death, below is an improved and
>> hopefully final version of my native.slope() function.  (Thanks, Jim.)
>>  In case you are not asleep yet reading yet another post of mine, may
>> I ask the experts some programming questions?
>>
>>   [I just saw yesterday's threat---I think it would be very, very, very nice if
>>   R would remember from what files with what linenumbers code came from.
>>   thus ignore below questions that mention this feature.  ALAS, I understand
>>   that this cannot be done generally.  But could not function definitions at
>>   least have a component that remembers this?]
>>
>> * Is there a way that I can print an R functional backtrace?  Instead
>> of passing my subroutine name to my function "assert()" below, it
>> would be nice if I could just print the whole call tree [preferably
>> with file names+line numbers] when I want my program to gracefully
>> bonk out.  (PS: I think that this is also what R should print when any
>> user program bonks out, not just the stop message.)
>> Actually, I just learned about traceback(), which functions nicely 
>> AFTER the program stops, not before.  But it gives no traceback 
>> earlier---and it does not give filename+lineno.

'Actually', R does what you ask it to: see options(error).  But before the 
program stops, there is no error to report.  In interactive use I see no 
problem in typing traceback() or using recover() (see below), but for 
batch use we are looking at alternatives.  For example, in R 2.3.0 
(modern) Unix users will get a traceback after a segfault.

> There's going to be a new section on debugging in the R 2.3.0 "Writing R
> Extensions" manual (written by Brian Ripley).  You can see it now if you
> build R-devel (or download a binary build from CRAN; I put Windows
> builds there approximately daily).  I also put together a
> Windows-oriented debugging page at
> http://www.stats.uwo.ca/faculty/murdoch/software/debuggingR/.

filename+lineno makes no sense: R functions are not (in the main) from 
files.  They can be autogenerated (and often are).  And I can 'fix' them.

As for the call stack, try options(error=recover) and 'where': see the 
chapter Duncan pointed you to.

>> * is there a way to print all my user defined functions?  I have an
>> init file, in which I am defining all sorts of useful utility
>> functions, and I would like to print what I have defined (for memory)
>> upon a read of this init file?  that is, something that has
>> functionality like
>>    note.all.local.definitions.now.in.vector( all.local.functions )
>>    a <- function() { }
>>    b <- function() { }
>>    cat( all.local.functions ); # should print 'a' and 'b'.
>
> ls.str() includes an option to select only functions.  You could also
> write your own filter for ls() output.
>>
>> * is there a string variable that gives me the name of the current
>> function I am in?
>
> I don't think so, but sys.call() gets close.  Watch out though:  the
> name you see will be the name used by the caller, which may not be the
> name used when the function was written.  For example, in a function
> called from apply(), you'll see FUN, not the original name.  Objects
> don't know their own names in general, because they keep getting passed
> around.

In the debugging context the command 'where' tells you the sequence of 
calls (which can be more helpful).

More generally, functions need not even have names (Bill Venables calls 
them 'anonymous functions'), as in

     r <- sapply(nms,
                 function(n) if (exists(n, envir = envir, mode = mode))n
                             else as.character(NA))

from ls.str.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Mon Feb  6 08:49:39 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 06 Feb 2006 08:49:39 +0100
Subject: [R] Embedding datasets, was Re:  srt --- slope text with function?
In-Reply-To: <43E6A4CD.8080800@stats.uwo.ca>
References: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>
	<43E51A7F.8080002@stats.uwo.ca>
	<50d1c22d0602041419y46761eb1x4f41fc82a5da9b60@mail.gmail.com>
	<644e1f320602041605y48295b4bs263c2d58589d73a3@mail.gmail.com>
	<50d1c22d0602051328t5f3e9fbeh4ef4283a76e8ac07@mail.gmail.com>
	<43E6A4CD.8080800@stats.uwo.ca>
Message-ID: <x2zml5apv0.fsf_-_@turmalin.kubism.ku.dk>

Duncan Murdoch <murdoch at stats.uwo.ca> writes:

> On 2/5/2006 4:28 PM, ivo welch wrote:

> > * has it now become possible to embed sample data sets in R code?  (I
> > asked this a while back, but there were nly kludges, no standard
> > "pretty" solutions.)
> 
> I don't understand the question.  dump() produces R code that can 
> reconstruct a dataset; is that what you want?

Or dput(). You can also read from a text connection, using
constructions like

data <- read.table(
textConnection(
"a b c d
2 1 3 5
0 2 4 1
1 2 3 4"), header=TRUE)

(The quotes have to placed as shown, or you get extra blank lines).
-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From buser at stat.math.ethz.ch  Mon Feb  6 09:35:23 2006
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Mon, 6 Feb 2006 09:35:23 +0100
Subject: [R] Mixed models and missing p-value...
In-Reply-To: <6.2.1.2.2.20060204183433.01ee52c8@hermes.ulaval.ca>
References: <6.2.1.2.2.20060204183433.01ee52c8@hermes.ulaval.ca>
Message-ID: <17383.2635.685252.841510@stat.math.ethz.ch>

Dear Simon

There was a discussion about degrees of freedom in linear mixed
models on the R-list last week. Have a look at

https://stat.ethz.ch/pipermail/r-help/2006-January/085560.html

and following. There have been earlier discussions about that
topic. Try also:

RSiteSearch("degree freedom mixed")


Regards,

Christoph Buser

--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C13
ETH (Federal Inst. Technology)	8092 Zurich	 SWITZERLAND
phone: x-41-44-632-4673		fax: 632-1228
http://stat.ethz.ch/~buser/
--------------------------------------------------------------


Simon Blanchet writes:
 > Dear R-users,
 > 
 > I computed a simple mixed models which was:
 > 
 >          mod<-lmer(nb ~ site + (1|patelle),tr)
 > 
 > The output was:
 > 
 > Linear mixed-effects model fit by REML
 > Formula: nb ~ site + (1 | patelle)
 >     Data: tr
 >        AIC      BIC    logLik MLdeviance REMLdeviance
 >   1157.437 1168.686 -574.7184   1164.523     1149.437
 > Random effects:
 >   Groups   Name        Variance Std.Dev.
 >   patelle  (Intercept)  34.995   5.9157
 >   Residual             744.736  27.2899
 > # of obs: 123, groups: patelle, 33
 > 
 > Fixed effects:
 >              Estimate Std. Error t value
 > (Intercept)  60.3483     4.3929 13.7378
 > siteLCN     -20.1969     7.8070 -2.5870
 > siteLCS     -18.2154     6.1514 -2.9612
 > 
 > Correlation of Fixed Effects:
 >          (Intr) sitLCN
 > siteLCN -0.563
 > siteLCS -0.714  0.402
 > 
 > I don't understand why D.F. and p-values associated to the fixed-effects 
 > coefficients are missing.
 > Could anyone help me?
 > 
 > When I tried another model (mod2<-lmer(nb ~ site + 
 > (1|patelle),tr,family=poisson)), D.F. and p-values were given...
 > 
 > Thank you in advance.
 > 
 > Very sincerely, Simon
 > 
 > 
 > 
 > BLANCHET Simon
 > PhD student
 > Universit?? Laval - Qu??bec-Oc??an / CIRSA
 > Pavillon Alexandre-Vachon
 > Local 8022
 > Qu??bec (Qu??bec), Canada G1K 7P4
 > T??l??phone : (418) 656-2131 poste 8022
 > courriel : simon.blanchet at giroq.ulaval.ca
 > 
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dieter.menne at menne-biomed.de  Mon Feb  6 09:37:01 2006
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 6 Feb 2006 08:37:01 +0000 (UTC)
Subject: [R] how to extract predicted values from a quantreg fit?
References: <61B38643-917E-4F9D-83D0-820FB32FA893@globetrotter.net>
Message-ID: <loom.20060206T093627-261@post.gmane.org>

Denis Chabot <chabotd <at> globetrotter.net> writes:

.... Quantreg package ....

> But I'd like to extract the predicted values. The help for  
> predict.qss1 indicates this:
.. 
> predict.qss1(object, newdata, ...)
> and states that newdata is a data frame describing the observations  
> at which prediction is to be made.
..
> 
>  > y <- rnorm(500, 10, 5)
>  > x <- rep(seq(1,50,1), 10)
>  > My.data <- data.frame(x, y)
>  > My.x <- data.frame(x=seq(5,45))
>  >
>  > fit <- rqss(y ~ qss(x, lambda=5), tau=0.05)
>  > pred <- predict.qss1(fit, My.x)
> 
> Could someone please help me creating a dataframe "newdata" that  
> would satisfy predict.qss1?

Looks like quantreg has been reworked, but predict was not tested. 
Checking the code, I got a (hopefully) working solution

pred <- predict.qss1(fit$qss[[1]]$xyz, My.x$x)

but this follow neither convention nor documentation. Maybe you should contact
the author of the package to provide an example in the documentation, which
would have show the problem earlier.

Dieter



From taranpen at yahoo.co.uk  Mon Feb  6 05:26:22 2006
From: taranpen at yahoo.co.uk (Norman Goodacre)
Date: Mon, 6 Feb 2006 04:26:22 +0000 (GMT)
Subject: [R] generating markov chain
Message-ID: <20060206042622.35326.qmail@web27411.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060206/b19f4767/attachment.pl

From taranpen at yahoo.co.uk  Mon Feb  6 07:22:21 2006
From: taranpen at yahoo.co.uk (Norman Goodacre)
Date: Mon, 6 Feb 2006 06:22:21 +0000 (GMT)
Subject: [R] problem with simple if() statement
Message-ID: <20060206062221.92796.qmail@web27402.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060206/f85c01b0/attachment.pl

From I.Visser at uva.nl  Mon Feb  6 10:52:35 2006
From: I.Visser at uva.nl (Ingmar Visser)
Date: Mon, 6 Feb 2006 10:52:35 +0100
Subject: [R] generating markov chain
Message-ID: <3FA98898AEAA88478AD68CEE89A68C48029BECF1@rea04.fmg.uva.nl>

You can use the following, with x your transition matrix
y=numeric(100)
x=matrix(runif(16),4,4)
for(i in 2:100) {
y[i]=which(rmultinom(1, size = 1, prob = x[y[i-1], ])==1)
}
hth, ingmar

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Norman Goodacre
Sent: maandag 6 februari 2006 5:26
To: r-help at stat.math.ethz.ch
Subject: [R] generating markov chain


Dear help group,
  
    Just fyi a markov chain is a sequence of transitions between  states (say A,T,G,C - on a gene) with a given probability for each  transition. In this case there'd be 16 different kinds, each with a  different weight. 
    Given a transition matrix (4x4) filled with all transition  probabilities of course, how can I generate a random sequence of a  given length, say 200?
  
   -Norman Goodacre
  
		
---------------------------------

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Mon Feb  6 10:57:11 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 06 Feb 2006 10:57:11 +0100
Subject: [R] problem with simple if() statement
In-Reply-To: <20060206062221.92796.qmail@web27402.mail.ukl.yahoo.com>
References: <20060206062221.92796.qmail@web27402.mail.ukl.yahoo.com>
Message-ID: <43E71D77.2040002@statistik.uni-dortmund.de>

Norman Goodacre wrote:

> the following code apprantely, for some grand old reason, induces a syntax error:
>   
>   if (seq[i] = "A") m <- trans[1,]
>   
>   where seq is a vector and trans is a matrix. I cannot for the life of me see why this is wrong. Syntax error is: 
>   
>   Error: syntax error in "if (seq[i] ="

I guess you mean "==" ....

Uwe Ligges


>   
>   Sincerely,
>   
>   Norman Goodacre
>   
>   
> 		
> ---------------------------------
> 
> ---------------------------------
>   
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From portnoy at supereva.it  Mon Feb  6 10:58:26 2006
From: portnoy at supereva.it (portnoy@supereva.it)
Date: Mon, 06 Feb 2006 10:58:26 +0100
Subject: [R] Classification of Imbalanced Data
Message-ID: <43E71DC2.50801@supereva.it>

Hi,
I'm looking to perform  a classification analysis on an imbalanced data 
set  using random Forest and I'd like to reproduce the weighted random 
forest analysis proposed in the Chen, Liaw & Breiman paper "Using Random 
Forest to Learn Imbalanced Data"; can I use the R package randomForest 
to perform such analysis? What is the easiest way to accomplish this task?
Thanks,
Paolo Sonego



From asaguiar at spsconsultoria.com  Mon Feb  6 11:05:35 2006
From: asaguiar at spsconsultoria.com (Alexandre Santos Aguiar)
Date: Mon, 6 Feb 2006 08:05:35 -0200
Subject: [R] problem with simple if() statement
In-Reply-To: <20060206062221.92796.qmail@web27402.mail.ukl.yahoo.com>
References: <20060206062221.92796.qmail@web27402.mail.ukl.yahoo.com>
Message-ID: <200602060805.35977.asaguiar@spsconsultoria.com>

Em Seg 06 Fev 2006 04:22, Norman Goodacre escreveu:
>   if (seq[i] = "A") m <- trans[1,]

I'll guess that it is the use you are making of the name 'seq'. :-)
'seq' is an R function. Try some other name.


-- 

          Alexandre



From phgrosjean at sciviews.org  Mon Feb  6 11:22:06 2006
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Mon, 06 Feb 2006 11:22:06 +0100
Subject: [R] problem with simple if() statement
In-Reply-To: <20060206062221.92796.qmail@web27402.mail.ukl.yahoo.com>
References: <20060206062221.92796.qmail@web27402.mail.ukl.yahoo.com>
Message-ID: <43E7234E.6030804@sciviews.org>

Norman Goodacre wrote:
> the following code apprantely, for some grand old reason, induces a syntax error:
>   
>   if (seq[i] = "A") m <- trans[1,]
>   
>   where seq is a vector and trans is a matrix. I cannot for the life of me see why this is wrong. Syntax error is: 
>   
>   Error: syntax error in "if (seq[i] ="
>   
>   Sincerely,
>   
>   Norman Goodacre

Please, read "An Introduction to R" provided with any version of R. The 
correct syntax for an equality condition is "==", not "=", so:

 > if (seq[i] == "A") ....

Best,

Philippe Grosjean



From c.beale at macaulay.ac.uk  Mon Feb  6 11:25:15 2006
From: c.beale at macaulay.ac.uk (Colin Beale)
Date: Mon, 06 Feb 2006 10:25:15 +0000
Subject: [R] problem with simple if() statement
Message-ID: <s3e7242e.002@macaulay.ac.uk>

Norman, 
you probably want:
 
  if (seq[i] == "A") m <- trans[1,]
  
hth,
Colin

>>> Norman Goodacre <taranpen at yahoo.co.uk> 06/02/2006 06:22 >>>
the following code apprantely, for some grand old reason, induces a
syntax error:
  
  if (seq[i] = "A") m <- trans[1,]
  
  where seq is a vector and trans is a matrix. I cannot for the life of
me see why this is wrong. Syntax error is: 
  
  Error: syntax error in "if (seq[i] ="
  
  Sincerely,
  
  Norman Goodacre
  
  
		
---------------------------------

---------------------------------
  
	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From r.hankin at noc.soton.ac.uk  Mon Feb  6 11:44:20 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Mon, 6 Feb 2006 10:44:20 +0000
Subject: [R] partition functions
Message-ID: <7CEF34AD-DBE9-4B6C-B2CE-58406AF5D030@soc.soton.ac.uk>

Before I reinvent the wheel, has anyone coded up the partition  
function p()?

[
for any integer p, p(n) is the number of distinct ways
of writing n as the sum of positive integers, with
order not considered.

For 5, we have

5 = 4+1 = 3+2 = 2+2+1 = 2+1+1+1 = 1+1+1+1+1

(ie 6 different ways)

so p(5) = 6.
]


--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From piet.vanremortel at gmail.com  Mon Feb  6 11:53:33 2006
From: piet.vanremortel at gmail.com (Piet van Remortel)
Date: Mon, 6 Feb 2006 11:53:33 +0100
Subject: [R] for-loop with multiple variables changing
Message-ID: <2D5EB0DD-C8BB-457C-8205-D4A5E3F81A01@gmail.com>

Hi all,

Never really managed to build a for-loop with multiple running  
variables in an elegant way.

Can anybody hint ?

See below for an example of what I would like.

EXAMPLE
a<-c(1,2,3)
b<-c("name1","name2","name3")

for( number in a, name in b ) {
	print( number ) ##take a value
	print( name ) ##and have its name available from a second list
}

Does R support this natively ?

thanks !

Piet
(Univ. of Antwerp - Belgium)



From sdavis2 at mail.nih.gov  Mon Feb  6 12:23:02 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 06 Feb 2006 06:23:02 -0500
Subject: [R] for-loop with multiple variables changing
In-Reply-To: <2D5EB0DD-C8BB-457C-8205-D4A5E3F81A01@gmail.com>
Message-ID: <C00C9BC6.5269%sdavis2@mail.nih.gov>




On 2/6/06 5:53 AM, "Piet van Remortel" <piet.vanremortel at gmail.com> wrote:

> Hi all,
> 
> Never really managed to build a for-loop with multiple running
> variables in an elegant way.
> 
> Can anybody hint ?
> 
> See below for an example of what I would like.
> 
> EXAMPLE
> a<-c(1,2,3)
> b<-c("name1","name2","name3")
> 
> for( number in a, name in b ) {
> print( number ) ##take a value
> print( name ) ##and have its name available from a second list
> }
> 
> Does R support this natively ?

I'm not sure what language does support this construct natively?  In any
case, what about:

 for (j in a) {
    print(a[j])
    print(b[j])
 }

You may be thinking of a "hash" structure.  If you are, you could look at
using lists.  See the R-intro on using list data structures.

Sean



From ramasamy at cancer.org.uk  Mon Feb  6 12:31:20 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 06 Feb 2006 11:31:20 +0000
Subject: [R] for-loop with multiple variables changing
In-Reply-To: <2D5EB0DD-C8BB-457C-8205-D4A5E3F81A01@gmail.com>
References: <2D5EB0DD-C8BB-457C-8205-D4A5E3F81A01@gmail.com>
Message-ID: <1139225480.3214.7.camel@dhcp-82.wolf.ox.ac.uk>

If you want a one-to-one action between corresponding pairs of "a" and
"b", then how about simply :

 for( i in 1:length(a) ){
  print( number[i] )
  print( name[i] )
 }

If you want the first element of "a" to work with all elements of "b",
the second element of "a" to work with all elements of "b", ... then you
may find functions such as outer, sapply, mapply helpful.

Regards, Adai



On Mon, 2006-02-06 at 11:53 +0100, Piet van Remortel wrote:
> Hi all,
> 
> Never really managed to build a for-loop with multiple running  
> variables in an elegant way.
> 
> Can anybody hint ?
> 
> See below for an example of what I would like.
> 
> EXAMPLE
> a<-c(1,2,3)
> b<-c("name1","name2","name3")
> 
> for( number in a, name in b ) {
> 	print( number ) ##take a value
> 	print( name ) ##and have its name available from a second list
> }
> 
> Does R support this natively ?
> 
> thanks !
> 
> Piet
> (Univ. of Antwerp - Belgium)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From samrobertsmith at gmail.com  Mon Feb  6 12:37:13 2006
From: samrobertsmith at gmail.com (linda.s)
Date: Mon, 6 Feb 2006 03:37:13 -0800
Subject: [R] generating markov chain
In-Reply-To: <3FA98898AEAA88478AD68CEE89A68C48029BECF1@rea04.fmg.uva.nl>
References: <3FA98898AEAA88478AD68CEE89A68C48029BECF1@rea04.fmg.uva.nl>
Message-ID: <1d987df30602060337q6ab8e073k399442d293c001d8@mail.gmail.com>

On 2/6/06, Ingmar Visser <I.Visser at uva.nl> wrote:
> You can use the following, with x your transition matrix
> y=numeric(100)
> x=matrix(runif(16),4,4)
> for(i in 2:100) {
> y[i]=which(rmultinom(1, size = 1, prob = x[y[i-1], ])==1)
> }
> hth, ingmar
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Norman Goodacre
> Sent: maandag 6 februari 2006 5:26
> To: r-help at stat.math.ethz.ch
> Subject: [R] generating markov chain
>
>
> Dear help group,
>
>    Just fyi a markov chain is a sequence of transitions between  states (say A,T,G,C - on a gene) with a given probability for each  transition. In this case there'd be 16 different kinds, each with a  different weight.
>    Given a transition matrix (4x4) filled with all transition  probabilities of course, how can I generate a random sequence of a  given length, say 200?
>
>   -Norman Goodacre
Sorry, I am very new to this issue.
Is there any tutorial to do Markov Chain?
Thanks,
Linda.



From sdavis2 at mail.nih.gov  Mon Feb  6 12:37:08 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 06 Feb 2006 06:37:08 -0500
Subject: [R] for-loop with multiple variables changing
In-Reply-To: <C00C9BC6.5269%sdavis2@mail.nih.gov>
Message-ID: <C00C9F14.5345%sdavis2@mail.nih.gov>




On 2/6/06 6:23 AM, "Sean Davis" <sdavis2 at mail.nih.gov> wrote:

> 
> 
> 
> On 2/6/06 5:53 AM, "Piet van Remortel" <piet.vanremortel at gmail.com> wrote:
> 
>> Hi all,
>> 
>> Never really managed to build a for-loop with multiple running
>> variables in an elegant way.
>> 
>> Can anybody hint ?
>> 
>> See below for an example of what I would like.
>> 
>> EXAMPLE
>> a<-c(1,2,3)
>> b<-c("name1","name2","name3")
>> 
>> for( number in a, name in b ) {
>> print( number ) ##take a value
>> print( name ) ##and have its name available from a second list
>> }
>> 
>> Does R support this natively ?
> 
> I'm not sure what language does support this construct natively?  In any
> case, what about:
> 
>  for (j in a) {

OOPs.  Should be:
 for(j in 1:length(a)) {

(thanks, Adai--too early in the morning here)

>     print(a[j])
>     print(b[j])
>  }
> 
> You may be thinking of a "hash" structure.  If you are, you could look at
> using lists.  See the R-intro on using list data structures.
> 
> Sean
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From petr.pikal at precheza.cz  Mon Feb  6 12:42:49 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 06 Feb 2006 12:42:49 +0100
Subject: [R] for-loop with multiple variables changing
In-Reply-To: <2D5EB0DD-C8BB-457C-8205-D4A5E3F81A01@gmail.com>
Message-ID: <43E74449.23744.CCC747@localhost>

Hi

do you want this?

for(i in a) {print(a[i]); print(b[i])}

HTH
Petr


On 6 Feb 2006 at 11:53, Piet van Remortel wrote:

To:             	r-help at stat.math.ethz.ch
From:           	Piet van Remortel <piet.vanremortel at gmail.com>
Date sent:      	Mon, 6 Feb 2006 11:53:33 +0100
Subject:        	[R] for-loop with multiple variables changing

> Hi all,
> 
> Never really managed to build a for-loop with multiple running  
> variables in an elegant way.
> 
> Can anybody hint ?
> 
> See below for an example of what I would like.
> 
> EXAMPLE
> a<-c(1,2,3)
> b<-c("name1","name2","name3")
> 
> for( number in a, name in b ) {
>  print( number ) ##take a value
>  print( name ) ##and have its name available from a second list
> }
> 
> Does R support this natively ?
> 
> thanks !
> 
> Piet
> (Univ. of Antwerp - Belgium)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From I.Visser at uva.nl  Mon Feb  6 12:45:37 2006
From: I.Visser at uva.nl (Ingmar Visser)
Date: Mon, 06 Feb 2006 12:45:37 +0100
Subject: [R] generating markov chain
In-Reply-To: <1d987df30602060337q6ab8e073k399442d293c001d8@mail.gmail.com>
Message-ID: <C00CF571.2656%I.Visser@uva.nl>

Linda,
That depends on what you want to do. There are a number of packages dealing
with Markov type models: msm, depmix and hmm.discnp, and then there are all
the graphical models packages, some of which can do similar stuff.
Hth, ingmar


> From: "linda.s" <samrobertsmith at gmail.com>
> Date: Mon, 6 Feb 2006 03:37:13 -0800
> To: Ingmar Visser <I.Visser at uva.nl>
> Cc: Norman Goodacre <taranpen at yahoo.co.uk>, <r-help at stat.math.ethz.ch>
> Subject: Re: [R] generating markov chain
> 
> On 2/6/06, Ingmar Visser <I.Visser at uva.nl> wrote:
>> You can use the following, with x your transition matrix
>> y=numeric(100)
>> x=matrix(runif(16),4,4)
>> for(i in 2:100) {
>> y[i]=which(rmultinom(1, size = 1, prob = x[y[i-1], ])==1)
>> }
>> hth, ingmar
>> 
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Norman Goodacre
>> Sent: maandag 6 februari 2006 5:26
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] generating markov chain
>> 
>> 
>> Dear help group,
>> 
>>    Just fyi a markov chain is a sequence of transitions between  states (say
>> A,T,G,C - on a gene) with a given probability for each  transition. In this
>> case there'd be 16 different kinds, each with a  different weight.
>>    Given a transition matrix (4x4) filled with all transition  probabilities
>> of course, how can I generate a random sequence of a  given length, say 200?
>> 
>>   -Norman Goodacre
> Sorry, I am very new to this issue.
> Is there any tutorial to do Markov Chain?
> Thanks,
> Linda.



From andy_liaw at merck.com  Mon Feb  6 12:45:45 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 6 Feb 2006 06:45:45 -0500
Subject: [R] Classification of Imbalanced Data
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7CC@usctmx1106.merck.com>

The implementation of weighted RF is still on the to-do list for the
package.  Use Breiman & Cutler's Fortran code for now.

Andy

From: portnoy at supereva.it
> 
> Hi,
> I'm looking to perform  a classification analysis on an 
> imbalanced data 
> set  using random Forest and I'd like to reproduce the 
> weighted random 
> forest analysis proposed in the Chen, Liaw & Breiman paper 
> "Using Random 
> Forest to Learn Imbalanced Data"; can I use the R package 
> randomForest 
> to perform such analysis? What is the easiest way to 
> accomplish this task?
> Thanks,
> Paolo Sonego
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From mbrabec at szu.cz  Mon Feb  6 12:58:32 2006
From: mbrabec at szu.cz (Ing. Marek Brabec PhD)
Date: Mon, 06 Feb 2006 12:58:32 +0100
Subject: [R] question about corStruct
Message-ID: <43E739E8.2010008@szu.cz>

dear list,
I am wondering if one can find examples and/or more detailed 
descriptions of modifications needed when going beyond standard 
corStruct classes (i.e. those already provided for use in lme/nlme)? 
When I looked at pages 238-239 of Pinheiro/Bates (2000): Mixed-effects 
models in S and S-plus, I found that I would need a bit more explicit 
guidance what to do for implementing a new correlation structure than 
that presented there.
I am thinking e.g. of random walk as of a non-stationary example 
corStruct to implement.
Thanks for any help and/or pointing me to a source of general instructions.
All the Best
Marek Brabec



From samrobertsmith at gmail.com  Mon Feb  6 13:12:49 2006
From: samrobertsmith at gmail.com (linda.s)
Date: Mon, 6 Feb 2006 04:12:49 -0800
Subject: [R] generating markov chain
In-Reply-To: <C00CF571.2656%I.Visser@uva.nl>
References: <1d987df30602060337q6ab8e073k399442d293c001d8@mail.gmail.com>
	<C00CF571.2656%I.Visser@uva.nl>
Message-ID: <1d987df30602060412t58d6424fpa4485a93c4f31a63@mail.gmail.com>

On 2/6/06, Ingmar Visser <I.Visser at uva.nl> wrote:
> Linda,
> That depends on what you want to do. There are a number of packages dealing
> with Markov type models: msm, depmix and hmm.discnp, and then there are all
> the graphical models packages, some of which can do similar stuff.
> Hth, ingmar
I want to use it to detect the change of the class for each polygon at
different time points. I have a very vague understanding of Markov
type models. I hope there is a detailed tutorial about it (them). Is
there any?
Linda.



From petr.pikal at precheza.cz  Mon Feb  6 13:13:19 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 06 Feb 2006 13:13:19 +0100
Subject: [R] for each element in matrix...
In-Reply-To: <43E65E40.8080307@siol.net>
Message-ID: <43E74B6F.11754.E8B3F5@localhost>

Hi

a bit of organisetion in colour sequence will do it.

graph1 <- function(a) {
    rownames(a) <- 1:nrow(a)
    colnames(a) <- 1:ncol(a)
    mean.diagonal <- mean(diag(a))

 bar<-c("red","green")[(a>mean(diag(a)))+1]
 bar<-matrix(bar[9:1],3,3)[3:1,]  # you need to set these according # 
# to actual dimensions of your matrices e.g. 
# bar<-matrix(bar[length(a):1],dim(a)[1],dim(a)[2])[dim(a)[1]:1,]

    par(bg = "gray95")
    dotchart(a, cex = 0.9, main = "MeSH Plot", xlab = "frequency",
        bg = bar,  # !!!
            pch = 21,labels = rownames(a))
    abline(v = mean.diagonal, col = "red", lty = 4)
}

HTH
Petr


On 5 Feb 2006 at 21:21, Andrej Kastrin wrote:

Date sent:      	Sun, 05 Feb 2006 21:21:20 +0100
From:           	Andrej Kastrin <andrej.kastrin at siol.net>
To:             	R-help <r-help at stat.math.ethz.ch>
Subject:        	[R] for each element in matrix...

> Dead R useRs,
> 
> I wrote function, which plot dotchart from given matrix, compute mean
> from diagonal elements and plot it with abline. In addition, if
> particular element of matrix is greater then mean value (i.e.
> mead.diagonal), it should be plot in red, otherwise in green color.
> 
> graph <- function(a) {
>     rownames(a) <- 1:nrow(a)
>     colnames(a) <- 1:ncol(a)
>     mean.diagonal <- mean(a[row(a) == col(a)])
>     par(bg = "gray95")
>     dotchart(a, cex = 0.9, main = "MeSH Plot", xlab = "frequency",
>         bg = ifelse((a) > mean.diagonal,"red", "green2"),  # !!!
>             pch = 21,labels = rownames(a))
>     abline(v = mean.diagonal, col = "red", lty = 4)
> }
> 
> And now the main problem: I suppose that there is some mismatch in
> ifelse statement while I produce two totally different plots: first
> input matrix:  A <-matrix(rep(c(1,3,4),3),3,3) # seem that works
> second input matrix B <-matrix(rnorm(9),3,3) # total confusion between
> green and red points
> 
> Any advice would be appreciated,
> 
> Cheers, Andrej
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From p.dalgaard at biostat.ku.dk  Mon Feb  6 13:24:34 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 06 Feb 2006 13:24:34 +0100
Subject: [R] for-loop with multiple variables changing
In-Reply-To: <C00C9BC6.5269%sdavis2@mail.nih.gov>
References: <C00C9BC6.5269%sdavis2@mail.nih.gov>
Message-ID: <x2d5i0n08t.fsf@viggo.kubism.ku.dk>

Sean Davis <sdavis2 at mail.nih.gov> writes:

> On 2/6/06 5:53 AM, "Piet van Remortel" <piet.vanremortel at gmail.com> wrote:
> 
> > Hi all,
> > 
> > Never really managed to build a for-loop with multiple running
> > variables in an elegant way.
> > 
> > Can anybody hint ?
> > 
> > See below for an example of what I would like.
> > 
> > EXAMPLE
> > a<-c(1,2,3)
> > b<-c("name1","name2","name3")
> > 
> > for( number in a, name in b ) {
> > print( number ) ##take a value
> > print( name ) ##and have its name available from a second list
> > }
> > 
> > Does R support this natively ?
> 
> I'm not sure what language does support this construct natively?  In any
> case, what about:

(Genstat has (had?) a "parallel for" structure, I believe.)
 
>  for (j in a) {
>     print(a[j])
>     print(b[j])
>  }

I think you mean "for (i in 1:3) {...}". 

Also, check out the mapply() construct for related functionality.

> You may be thinking of a "hash" structure.  If you are, you could look at
> using lists.  See the R-intro on using list data structures.
> 
> Sean


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From john.janmaat at acadiau.ca  Sun Feb  5 12:26:15 2006
From: john.janmaat at acadiau.ca (John Janmaat)
Date: Sun, 05 Feb 2006 07:26:15 -0400
Subject: [R] Cluster Analysis - Number of Clusters
Message-ID: <43E5E0D7.40503@acadiau.ca>

Hello,

I'm playing around with cluster analysis, and am looking for methods to 
select the number of clusters.  I am aware of methods based on a 'pseudo 
F' or a 'pseudo T^2'.  Are there packages in R that will generate these 
statistics, and/or other statistics to aid in cluster number selection?

Thanks,

John.
-- 
===========================================================================
Dr. John Janmaat                       Tel: 902-585-1461
Department of Economics                Fax: 902-585-1070
Acadia University                      Email: jjanmaat at acadiau.ca
Wolfville, Nova Scotia, Canada.        Web: ace.acadiau.ca/~jjanmaat/



From p.dalgaard at biostat.ku.dk  Mon Feb  6 13:54:05 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 06 Feb 2006 13:54:05 +0100
Subject: [R] question about corStruct
In-Reply-To: <43E739E8.2010008@szu.cz>
References: <43E739E8.2010008@szu.cz>
Message-ID: <x28xsomyvm.fsf@viggo.kubism.ku.dk>

"Ing. Marek Brabec PhD" <mbrabec at szu.cz> writes:

> dear list,
> I am wondering if one can find examples and/or more detailed 
> descriptions of modifications needed when going beyond standard 
> corStruct classes (i.e. those already provided for use in lme/nlme)? 
> When I looked at pages 238-239 of Pinheiro/Bates (2000): Mixed-effects 
> models in S and S-plus, I found that I would need a bit more explicit 
> guidance what to do for implementing a new correlation structure than 
> that presented there.
> I am thinking e.g. of random walk as of a non-stationary example 
> corStruct to implement.
> Thanks for any help and/or pointing me to a source of general instructions.
> All the Best
> Marek Brabec

Hi Marek,

I don't think there is any better way than to try deciphering and
modifying an existing cor-class. Notice that there is a handful of
methods to be dealt with, like these for the compund symmetry case

> ls(pattern=".*corCompSymm", environment(gls))
[1] "Initialize.corCompSymm" "coef.corCompSymm"       "coef<-.corCompSymm"
[4] "corCompSymm"            "corMatrix.corCompSymm"  "recalc.corCompSymm"
[7] "summary.corCompSymm"


You might want to start off trying your hand by writing your own
variance class. This is somewhat easier since preexisting ones are
generally written in R whereas corClasses have .C calls inside.

        -p

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From olsson1 at gmail.com  Mon Feb  6 14:04:16 2006
From: olsson1 at gmail.com (P. Olsson)
Date: Mon, 6 Feb 2006 14:04:16 +0100
Subject: [R] Cluster Analysis - Number of Clusters
In-Reply-To: <43E5E0D7.40503@acadiau.ca>
References: <43E5E0D7.40503@acadiau.ca>
Message-ID: <e984efc60602060504j1c875ca8k@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060206/ed2dde27/attachment.pl

From chrish at stats.ucl.ac.uk  Mon Feb  6 14:38:36 2006
From: chrish at stats.ucl.ac.uk (Christian Hennig)
Date: Mon, 6 Feb 2006 13:38:36 +0000 (GMT)
Subject: [R] Cluster Analysis - Number of Clusters
In-Reply-To: <43E5E0D7.40503@acadiau.ca>
References: <43E5E0D7.40503@acadiau.ca>
Message-ID: <Pine.LNX.4.64.0602061332030.26606@egon.stats.ucl.ac.uk>

Hi,

as said before, some statistics to estimate the number of clusters are in 
the cluster.stats function of package fpc. These are distance-based, 
not "pseudo F or T^2". They are documented in the book 
of Gordon (1999) Classification (see ?cluster.stats for more references). 
It also includes the average silhouette width of Kaufman and Rousseeuw 
(1990) (exact reference in ?plot.agnes), which is also part of the output 
of some functions in package cluster (pam, agnes,...?).

An alternative way to estimate the number of clusters is the use of the 
BIC together with a (normal) mixture model, see package mclust.

Best,
Christian


On Sun, 5 Feb 2006, John Janmaat wrote:

> Hello,
>
> I'm playing around with cluster analysis, and am looking for methods to
> select the number of clusters.  I am aware of methods based on a 'pseudo
> F' or a 'pseudo T^2'.  Are there packages in R that will generate these
> statistics, and/or other statistics to aid in cluster number selection?
>
> Thanks,
>
> John.
> -- 
> ===========================================================================
> Dr. John Janmaat                       Tel: 902-585-1461
> Department of Economics                Fax: 902-585-1070
> Acadia University                      Email: jjanmaat at acadiau.ca
> Wolfville, Nova Scotia, Canada.        Web: ace.acadiau.ca/~jjanmaat/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

*** --- ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche



From Matthias.Templ at statistik.gv.at  Mon Feb  6 14:48:40 2006
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Mon, 6 Feb 2006 14:48:40 +0100
Subject: [R] Cluster Analysis - Number of Clusters
Message-ID: <83536658864BC243BE3C06D7E936ABD5027BAE44@xchg1.statistik.local>

Dear John,

You can play around with cluster.stats function in library fpc, e.g. you
can try:

library(fpc)
library(cluster)
data(xclara)
dM <- dist(xclara)
cl <- vector()
for(i in 2:7){
  cl[i] <- cluster.stats(d=dM, clustering=clara(d,i)$cluster,
silhouette=FALSE)$wb.ratio
}
plot(1:6,cl[2:7], xaxt="n")
axis(1, at=1:6, labels=2:7)

(..takes some minutes time)
indicates that 3 clusters are "optimal" for this data.

Best,
Matthias


> 
> Hello,
> 
> I'm playing around with cluster analysis, and am looking for 
> methods to 
> select the number of clusters.  I am aware of methods based 
> on a 'pseudo 
> F' or a 'pseudo T^2'.  Are there packages in R that will 
> generate these 
> statistics, and/or other statistics to aid in cluster number 
> selection?
> 
> Thanks,
> 
> John.
> -- 
> ==============================================================
> =============
> Dr. John Janmaat                       Tel: 902-585-1461
> Department of Economics                Fax: 902-585-1070
> Acadia University                      Email: jjanmaat at acadiau.ca
> Wolfville, Nova Scotia, Canada.        Web: ace.acadiau.ca/~jjanmaat/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read 
> the posting guide! http://www.R-project.org/posting-guide.html
>



From cmdrnorton at poczta.onet.pl  Mon Feb  6 15:00:45 2006
From: cmdrnorton at poczta.onet.pl (cmdrnorton@poczta.onet.pl)
Date: Mon, 06 Feb 2006 15:00:45 +0100
Subject: [R] marginal distribution wrt time of  time series ?
Message-ID: <20060206140055Z4340971-32684+1799@kps4.test.onet.pl>

Dear all,

In many papers regarding time series analysis 
of acquired data, the authors analyze 'marginal 
distribution' (i.e. marginal with respect to time) 
of their data by for example checking 
'cdf heavy tail' hypothesis. 

For i.i.d data this is ok, but what if samples are 
correlated, nonstationary etc.? 

Are there limit theorems which for example allow 
us to claim that for weak dependent, stationary 
and ergodic time series such a 'marginal distribution 
w.r. to time' converges to marginal distribution 
of random variable x_t , defined on basis of joint 
distribution for (x_1,&#8230;,x_T) ? 

What if the correlation is strong (say stationary 
and ergodic FARIMA model) ? 

Many thanks for your input

Norton



From wib2004 at med.cornell.edu  Mon Feb  6 17:28:32 2006
From: wib2004 at med.cornell.edu (William Briggs)
Date: Mon, 06 Feb 2006 11:28:32 -0500
Subject: [R] turn off selected axes in bwplot
Message-ID: <f96f327b2e6.43e732e0@med.cornell.edu>


I want to turn off selected axes in bwplot.  I would like to only have the bottom axis drawn, with the others off.

I have a series of bwplots that I want on one device, like this:

p1<-bwplot(x1,box.ratio=.1)
p2<-bwplot(x2,box.ratio=.1)
...
print(p1,position=c(0,.8,1,1),more=T)
print(p2,position=c(0,.6,1,.8),more=T)
...

I know about the panel functions panel.bwplot() and panel.axis(), but I don't know how to directly call them and change, for example, the side parameter of panel.axis(), leaving all the other parameters of both panel functions untouched.  

The axis can be turned off altogether with:

trellis.par.set(axis.line = list( color="transparent"))

but this is obviously not what I need.



From macmanes at berkeley.edu  Mon Feb  6 18:03:08 2006
From: macmanes at berkeley.edu (Matthew MacManes)
Date: Mon, 06 Feb 2006 09:03:08 -0800
Subject: [R] Evaluate output after each rep()
Message-ID: <43E7814C.4020503@berkeley.edu>

Hi R-Help,

I'm trying a develop a test simulation where i evaluate the probability 
of not getting a value of 100 from the function rbinom(6000, 200, .5) 
[indeed, a very small probability].  At the end of each rep, I would 
like to evaluate the output, continue with the loop if the output 
contains the value 100, stop if the output lacks a 100.

How do I get R to evaluate the output after each rep?


 >sim <- function(nn){
 >   for (ii in 1:nn){
 >      ee=rep(rbinom(6000, 200, .5), ii)
 >         if (any(ee==100))
 >      }

Thanks,
Matt MacManes
********************************************************
Matthew D. MacManes
PhD Student
UC- Berkeley
Department of Integrative Biology
Museum of Vertebrate Zoology
3101 VLSB #3140
Berkeley, CA 94720
(510)642-7782
EMAIL: macmanes at berkeley.edu
WEBSITE: http://ib.berkeley.edu/labs/lacey/



From sfalcon at fhcrc.org  Mon Feb  6 18:30:08 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Mon, 06 Feb 2006 09:30:08 -0800
Subject: [R] RUnit - need advice on a good directory structure or tips...
In-Reply-To: <edc66abd0602032246x34b2b9cbkf2a17933a350666c@mail.gmail.com>
	(Sung Soo Kim's message of "Sat, 4 Feb 2006 01:46:59 -0500")
References: <edc66abd0602032246x34b2b9cbkf2a17933a350666c@mail.gmail.com>
Message-ID: <m2fymwl7j3.fsf@ziti.local>

On  3 Feb 2006, sskim.box at gmail.com wrote:

> I made my own RUnit testing convention, and I want to introduce this
> to one of my friends.  Before that, I'd like to review my codes.
>
> The problem that I met when I tried to polish my codes is: How can I
> get the file path in the file???
> I.e., I want to get the path to the file that I'm writing using some magic R
> functions. But I couldn't find any good magic.
> Is there any magic?

I think the best thing would be to put your code into a package and
then decide upon a convention for RUnit testing that relies upon the
known structure of the package.

I've been putting RUnit tests in inst/unitTests in some of the
packages I work on and have a makefile in that directory that can
reinstall the package and run the tests.  It isn't all that elegant,
but I don't have to do any guessing about where the code is.

HTH,

+ seth



From ramasamy at cancer.org.uk  Mon Feb  6 18:35:02 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 06 Feb 2006 17:35:02 +0000
Subject: [R] Evaluate output after each rep()
In-Reply-To: <43E7814C.4020503@berkeley.edu>
References: <43E7814C.4020503@berkeley.edu>
Message-ID: <1139247302.3439.23.camel@localhost.localdomain>

I do not fully understand what you mean by "stop". If you mean terminate
the whole function, then something like

 sim <- function(nn, mustExist=100){

   for (ii in 1:nn){
       ee <- rep(rbinom(6000, 200, .5), ii)

       if( any(ee!=mustExist) )
           stop( paste("Iteration", ii, "did not contain", mustExist, 
                       ". Terminating function \n") )
   }
 
   ## Do something further ##
 }


But generally, I want to just resample again till I get the desired length.

 sim <- function(nn, mustExist=100){

   counter <- 0;  ii <- 1

   while( counter <= nn ){

       ee <- rep(rbinom(6000, 200, .5), ii)

       if( any(ee!=mustExist) ){
           warning(paste( "Iteration", ii, "did not contain", mustExist, 
                           ". Resampling again\n") )
       } else {
         counter <- counter + 1
         ii      <- ii + 1
         ## Do something further ##
      }
   }
 }

You can turn off the branch that returns the warnings if it gets annoying.

BTW, why do you want to use rep(.., ii) ?

Regards, Adai




If you want to count how many times out



On Mon, 2006-02-06 at 09:03 -0800, Matthew MacManes wrote:
> Hi R-Help,
> 
> I'm trying a develop a test simulation where i evaluate the probability 
> of not getting a value of 100 from the function rbinom(6000, 200, .5) 
> [indeed, a very small probability].  At the end of each rep, I would 
> like to evaluate the output, continue with the loop if the output 
> contains the value 100, stop if the output lacks a 100.
> 
> How do I get R to evaluate the output after each rep?
> 
> 
>  >sim <- function(nn){
>  >   for (ii in 1:nn){
>  >      ee=rep(rbinom(6000, 200, .5), ii)
>  >         if (any(ee==100))
>  >      }
> 
> Thanks,
> Matt MacManes
> ********************************************************
> Matthew D. MacManes
> PhD Student
> UC- Berkeley
> Department of Integrative Biology
> Museum of Vertebrate Zoology
> 3101 VLSB #3140
> Berkeley, CA 94720
> (510)642-7782
> EMAIL: macmanes at berkeley.edu
> WEBSITE: http://ib.berkeley.edu/labs/lacey/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From gunter.berton at gene.com  Mon Feb  6 19:10:08 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 6 Feb 2006 10:10:08 -0800
Subject: [R] Evaluate output after each rep()
In-Reply-To: <1139247302.3439.23.camel@localhost.localdomain>
Message-ID: <200602061810.k16IA8mG027583@ohm.gene.com>

Of course I assume that everyone realizes that the simulation estimates (1 -
dbinom(100,200,p=.5))^6000. The loge of this quantity is -348, btw. So this
is trivially computable, but I assume that this is an exercise of some sort.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Adaikalavan Ramasamy
> Sent: Monday, February 06, 2006 9:35 AM
> To: macmanes at berkeley.edu
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Evaluate output after each rep()
> 
> I do not fully understand what you mean by "stop". If you 
> mean terminate
> the whole function, then something like
> 
>  sim <- function(nn, mustExist=100){
> 
>    for (ii in 1:nn){
>        ee <- rep(rbinom(6000, 200, .5), ii)
> 
>        if( any(ee!=mustExist) )
>            stop( paste("Iteration", ii, "did not contain", mustExist, 
>                        ". Terminating function \n") )
>    }
>  
>    ## Do something further ##
>  }
> 
> 
> But generally, I want to just resample again till I get the 
> desired length.
> 
>  sim <- function(nn, mustExist=100){
> 
>    counter <- 0;  ii <- 1
> 
>    while( counter <= nn ){
> 
>        ee <- rep(rbinom(6000, 200, .5), ii)
> 
>        if( any(ee!=mustExist) ){
>            warning(paste( "Iteration", ii, "did not contain", 
> mustExist, 
>                            ". Resampling again\n") )
>        } else {
>          counter <- counter + 1
>          ii      <- ii + 1
>          ## Do something further ##
>       }
>    }
>  }
> 
> You can turn off the branch that returns the warnings if it 
> gets annoying.
> 
> BTW, why do you want to use rep(.., ii) ?
> 
> Regards, Adai
> 
> 
> 
> 
> If you want to count how many times out
> 
> 
> 
> On Mon, 2006-02-06 at 09:03 -0800, Matthew MacManes wrote:
> > Hi R-Help,
> > 
> > I'm trying a develop a test simulation where i evaluate the 
> probability 
> > of not getting a value of 100 from the function 
> rbinom(6000, 200, .5) 
> > [indeed, a very small probability].  At the end of each 
> rep, I would 
> > like to evaluate the output, continue with the loop if the output 
> > contains the value 100, stop if the output lacks a 100.
> > 
> > How do I get R to evaluate the output after each rep?
> > 
> > 
> >  >sim <- function(nn){
> >  >   for (ii in 1:nn){
> >  >      ee=rep(rbinom(6000, 200, .5), ii)
> >  >         if (any(ee==100))
> >  >      }
> > 
> > Thanks,
> > Matt MacManes
> > ********************************************************
> > Matthew D. MacManes
> > PhD Student
> > UC- Berkeley
> > Department of Integrative Biology
> > Museum of Vertebrate Zoology
> > 3101 VLSB #3140
> > Berkeley, CA 94720
> > (510)642-7782
> > EMAIL: macmanes at berkeley.edu
> > WEBSITE: http://ib.berkeley.edu/labs/lacey/
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From calstats05 at yahoo.com  Mon Feb  6 19:16:02 2006
From: calstats05 at yahoo.com (Cal Stats)
Date: Mon, 6 Feb 2006 10:16:02 -0800 (PST)
Subject: [R] Periodic B-spline surface
Message-ID: <20060206181602.67913.qmail@web34005.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060206/8c0002ea/attachment.pl

From deepayan.sarkar at gmail.com  Mon Feb  6 19:29:48 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 6 Feb 2006 12:29:48 -0600
Subject: [R] turn off selected axes in bwplot
In-Reply-To: <f96f327b2e6.43e732e0@med.cornell.edu>
References: <f96f327b2e6.43e732e0@med.cornell.edu>
Message-ID: <eb555e660602061029j6e9f6cfavb4ce91b3313223ab@mail.gmail.com>

On 2/6/06, William Briggs <wib2004 at med.cornell.edu> wrote:
>
> I want to turn off selected axes in bwplot.  I would like to only have the
> bottom axis drawn, with the others off.

Does this do what you want?

bwplot(<...>,
       scales = list(x = list(alternating = 1, tck = c(1, 0))))

This is described in detail under 'scales' in ?bwplot.

-Deepayan

> I have a series of bwplots that I want on one device, like this:
>
> p1<-bwplot(x1,box.ratio=.1)
> p2<-bwplot(x2,box.ratio=.1)
> ...
> print(p1,position=c(0,.8,1,1),more=T)
> print(p2,position=c(0,.6,1,.8),more=T)
> ...
>
> I know about the panel functions panel.bwplot() and panel.axis(), but I
> don't know how to directly call them and change, for example, the side
> parameter of panel.axis(), leaving all the other parameters of both panel
> functions untouched.
>
> The axis can be turned off altogether with:
>
> trellis.par.set(axis.line = list( color="transparent"))
>
> but this is obviously not what I need.



From caf at gis.usu.edu  Mon Feb  6 19:44:15 2006
From: caf at gis.usu.edu (Craig A Faulhaber)
Date: Mon, 06 Feb 2006 11:44:15 -0700
Subject: [R] power and sample size for a GLM with poisson response variable
Message-ID: <43E798FF.9020504@gis.usu.edu>

Hi all,

I would like to estimate power and necessary sample size for a GLM with 
a response variable that has a poisson distribution.  Do you have any 
suggestions for how I can do this in R?  Thank you for your help.

Sincerely,
Craig

-- 
Craig A. Faulhaber
Department of Forest, Range, and Wildlife Sciences
Utah State University
5230 Old Main Hill
Logan, UT 84322
(435)797-3892



From kjetilbrinchmannhalvorsen at gmail.com  Mon Feb  6 19:56:34 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Mon, 06 Feb 2006 14:56:34 -0400
Subject: [R] power and sample size for a GLM with poisson response
	variable
In-Reply-To: <43E798FF.9020504@gis.usu.edu>
References: <43E798FF.9020504@gis.usu.edu>
Message-ID: <43E79BE2.6040302@gmail.com>

Craig A Faulhaber wrote:
> Hi all,
> 
> I would like to estimate power and necessary sample size for a GLM with 
> a response variable that has a poisson distribution.  Do you have any 
> suggestions for how I can do this in R?  Thank you for your help.
> 
> Sincerely,
> Craig
> 
package asypow (on CRAN) or simulation.

Kjetil



From wib2004 at med.cornell.edu  Mon Feb  6 20:17:37 2006
From: wib2004 at med.cornell.edu (William Briggs)
Date: Mon, 06 Feb 2006 14:17:37 -0500
Subject: [R] turn off selected axes in bwplot
Message-ID: <119daf3bf7ab.43e75a81@med.cornell.edu>

 
> Does this do what you want?
> 
> bwplot(<...>,
>       scales = list(x = list(alternating = 1, tck = c(1, 0))))
> 
> This is described in detail under 'scales' in ?bwplot.

Not quite.   This controls, if I've understood it correctly, the axis tick marks and such (I also tried the argument "draw=FALSE" in the list above).  

The analogue I have in mind is the simple plot axes control like this

    plot(<...>, axes=FALSE)
    axis(1)

which would only draw the bottom axis, with tick marks and label.  Those arguments, of course, don't work for the lattice graphics, but I did notice a similar control in the panel.aixs() function, but I just don't know how to get to it.



From ivowel at gmail.com  Mon Feb  6 20:48:14 2006
From: ivowel at gmail.com (ivo welch)
Date: Mon, 6 Feb 2006 14:48:14 -0500
Subject: [R] srt --- slope text with function?
In-Reply-To: <Pine.LNX.4.61.0602060734580.7548@gannet.stats>
References: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>
	<43E51A7F.8080002@stats.uwo.ca>
	<50d1c22d0602041419y46761eb1x4f41fc82a5da9b60@mail.gmail.com>
	<644e1f320602041605y48295b4bs263c2d58589d73a3@mail.gmail.com>
	<50d1c22d0602051328t5f3e9fbeh4ef4283a76e8ac07@mail.gmail.com>
	<43E6A4CD.8080800@stats.uwo.ca>
	<Pine.LNX.4.61.0602060734580.7548@gannet.stats>
Message-ID: <50d1c22d0602061148tf2eafedg3f007444db4c191b@mail.gmail.com>

Thank you, as always.

May I disagree with you and offer a suggestion?

In the best of worlds, a function should have multiple attributes.  In
addition to the function name and its argument list, two mandatory
attributes should be a filename and lineno.  If the function is
interactively created, perhaps we can call the filename "-" and the
lineno a count that could come from the history().   Yes, it will
*NOT* be perfect, but it would be a big improvement.

If functions can have attributes, in addition to keeping the filename
and lineno,  it would be great if it could have an immediate
association with a short documentation message?  This could be a neat
documentation crutch, useful, e.g., in ls.str() or a describe().  the
best syntax that I can think of just stinks, but maybe a standard
argument does the job and should be encouraged.
  xyz <- function(args, doc="xyz returns 0") { return(0); }
I do not think the following syntax would work stylewise:
  xyz <- function "xyz returns 0" (args) { return(0); }
but it would be nicer in noting the difference between a normal
argument and a short function descriptor.

regards,

/iaw

by traceback(), do you mean the gdb() like traceback of the R
internals?  This would not be too helpful to most users.  I would be
more interested in my R call stack, not my underlying C call stack.

[and thanks again for all the other info].

regards,

/iaw



On 2/6/06, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> 'Actually', R does what you ask it to: see options(error).  But before the
> program stops, there is no error to report.  In interactive use I see no
> problem in typing traceback() or using recover() (see below), but for
> batch use we are looking at alternatives.  For example, in R 2.3.0
> (modern) Unix users will get a traceback after a segfault.
>
> > There's going to be a new section on debugging in the R 2.3.0 "Writing R
> > Extensions" manual (written by Brian Ripley).  You can see it now if you
> > build R-devel (or download a binary build from CRAN; I put Windows
> > builds there approximately daily).  I also put together a
> > Windows-oriented debugging page at
> > http://www.stats.uwo.ca/faculty/murdoch/software/debuggingR/.
>
> filename+lineno makes no sense: R functions are not (in the main) from
> files.  They can be autogenerated (and often are).  And I can 'fix' them.
>
> As for the call stack, try options(error=recover) and 'where': see the
> chapter Duncan pointed you to.
>
> >> * is there a way to print all my user defined functions?  I have an
> >> init file, in which I am defining all sorts of useful utility
> >> functions, and I would like to print what I have defined (for memory)
> >> upon a read of this init file?  that is, something that has
> >> functionality like
> >>    note.all.local.definitions.now.in.vector( all.local.functions )
> >>    a <- function() { }
> >>    b <- function() { }
> >>    cat( all.local.functions ); # should print 'a' and 'b'.
> >
> > ls.str() includes an option to select only functions.  You could also
> > write your own filter for ls() output.
> >>
> >> * is there a string variable that gives me the name of the current
> >> function I am in?
> >
> > I don't think so, but sys.call() gets close.  Watch out though:  the
> > name you see will be the name used by the caller, which may not be the
> > name used when the function was written.  For example, in a function
> > called from apply(), you'll see FUN, not the original name.  Objects
> > don't know their own names in general, because they keep getting passed
> > around.
>
> In the debugging context the command 'where' tells you the sequence of
> calls (which can be more helpful).
>
> More generally, functions need not even have names (Bill Venables calls
> them 'anonymous functions'), as in
>
>      r <- sapply(nms,
>                  function(n) if (exists(n, envir = envir, mode = mode))n
>                              else as.character(NA))
>
> from ls.str.
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From khans at ornl.gov  Mon Feb  6 20:53:35 2006
From: khans at ornl.gov (Khan, Shiraj)
Date: Mon, 06 Feb 2006 14:53:35 -0500
Subject: [R] gpd.fit in 'isemv' package
Message-ID: <428543BBA8AC7443BA10B0F491C6B05601611C57@ORNLEXCHANGE.ornl.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060206/135574ef/attachment.pl

From deepayan.sarkar at gmail.com  Mon Feb  6 20:52:44 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 6 Feb 2006 13:52:44 -0600
Subject: [R] turn off selected axes in bwplot
In-Reply-To: <119daf3bf7ab.43e75a81@med.cornell.edu>
References: <119daf3bf7ab.43e75a81@med.cornell.edu>
Message-ID: <eb555e660602061152u19f1fdb8qe3d56d5a9782598b@mail.gmail.com>

On 2/6/06, William Briggs <wib2004 at med.cornell.edu> wrote:
>
> > Does this do what you want?
> >
> > bwplot(<...>,
> >       scales = list(x = list(alternating = 1, tck = c(1, 0))))
> >
> > This is described in detail under 'scales' in ?bwplot.
>
> Not quite.   This controls, if I've understood it correctly, the axis tick
> marks and such (I also tried the argument "draw=FALSE" in the list above).
>
> The analogue I have in mind is the simple plot axes control like this
>
>     plot(<...>, axes=FALSE)
>     axis(1)

OK, so you don't want any y-axes at all? In that case, how about

bwplot(<...>,
      scales = list(x = list(alternating = 1, tck = c(1, 0)),
                     y = list(draw = FALSE)))

?

> which would only draw the bottom axis, with tick marks and label.  Those
> arguments, of course, don't work for the lattice graphics, but I did notice
> a similar control in the panel.aixs() function, but I just don't know how to
> get to it.

You can't easily.

--
http://www.stat.wisc.edu/~deepayan/



From ivowel at gmail.com  Mon Feb  6 21:06:55 2006
From: ivowel at gmail.com (ivo welch)
Date: Mon, 6 Feb 2006 15:06:55 -0500
Subject: [R] R loop
Message-ID: <50d1c22d0602061206i4cfb79eci7195593dc6e6d75@mail.gmail.com>

I am not an R expert, but I think the R idea of this task is to work
with a data frame (where you make a and b are columns), and then to
iterate over the rows.

data <- read.table( textConnection(
"a b
1 name1
2 name2
3 name3"), header=TRUE) ;  # just learned this one

for (i in 1:nrow(data)) print( data[i,] );
or just  data[1:3,]


apropos, R does not support native hashes (like perl), unfortunately,
but it has something similar:

data$a=="b"   # gives F T F
data[ data$a == "name2" ]  # does not work and gives a weird result,  yuck
subset(data, data$a=="name2")   # this does work.


data frame sorting by column (using order) could also be simpler to
understand for novices---IMHO, there should be a wrapper function that
is in standard R like
  data.sorted = sort( data, by=data$b );

regards,

/iaw



From hvermei1 at vrcbe.jnj.com  Mon Feb  6 21:18:00 2006
From: hvermei1 at vrcbe.jnj.com (Vermeiren, Hans [VRCBE])
Date: Mon, 6 Feb 2006 21:18:00 +0100 
Subject: [R] panel.levelplot() for 2D histograms
Message-ID: <9AC105024CEA64458BF66D1DE13CA50D070FB4F9@tibbemeexs1.eu.jnj.com>

Dear R-wizards,
I'm trying to plot "binned scatterplots", or 2d histograms, if you wish, for
a number of groups by using the lattice functionality
it works fine for one group at a time, and probably I could find a
work-around, but I prefer to do it the elegant way
here's an example of what I want, what I tried and where it goes wrong:

require(gregmisc)
require(lattice)
#toy dataset:
ds<-data.frame(x=rnorm(3000),y=rnorm(3000),group=rep(factor(c("A","B","C")),
1000))

# this binscatter-function shows what I want,
# I just would like to have it as a panel function

binscatter<-function(x,y){
 col<-rev(gray.colors(5))
 breaks=c(1,5,10,100,500,100000)
 h2d<-hist2d(x=x,y=y,nbins=10,same.scale=T,show=F)
 image(h2d$x,h2d$y,h2d$counts,breaks=breaks,col=col,axes=T)
}


# for one group, this works fine
A<-subset(ds,group=="A")
binscatter(A$x,A$y)

# simple xyplot does too (of course)
xyplot(y~x|group,data=ds)

# but my lattice-ified version of binscatter does not:
# 1st attempt
panel.binscatter<-function(x,y,subscripts,...){
 col<-gray.colors(5)
 breaks=c(1,5,10,100,500,100000)
 h2d<-hist2d(x=x,y=y,nbins=10,same.scale=T,show=F)
 
panel.levelplot(h2d$x,h2d$y,h2d$counts,subscripts=1:length(h2d$x),at=breaks,
col.regions=col,region=T)
}

xyplot(y~x|group,data=ds,panel=panel.binscatter)

# but, this doesnt work either for one group using levelplot() :
Ah2d<-hist2d(A$x,A$y,nbins=10,same.scale=T,show=F)
levelplot(Ah2d$counts~Ah2d$x*Ah2d$y)

# but this DOES:
grid<-expand.grid(x=Ah2d$x,y=Ah2d$y)
levelplot(Ah2d$counts~grid$x*grid$y)

#2nd attempt doesn't work, I give up..
panel.binscatter<-function(x,y,subscripts,...){
col<-gray.colors(5)
breaks=c(1,5,10,100,500,100000)
h2d<-hist2d(x=x,y=y,nbins=10,same.scale=T,show=F)
grid<-expand.grid(x=h2d$x,y=h2d$y)
panel.levelplot(grid$x,grid$y,h2d$counts,subscripts=1:length(h2d$x),at=break
s,col.regions=col)
}

xyplot(y~x|group,data=ds,panel=panel.binscatter)

all suggestions welcome, thanks a lot

Hans



From ivowel at gmail.com  Mon Feb  6 21:34:28 2006
From: ivowel at gmail.com (ivo welch)
Date: Mon, 6 Feb 2006 15:34:28 -0500
Subject: [R] appeal --- add sd to summary for univariates
Message-ID: <50d1c22d0602061234u28cd4d56wa9e9839208296294@mail.gmail.com>

just a short beg for the next R 2.3 version:

I know it is easy to add the sd into summary() in the source bowels of
R---but everytime R is updated, my change disappears.  :-(.  I do not
believe that R has an easy extension mechanism for univariate
summaries, short of a function rewrite here.  Could this please be
added into R 2.3?

Aside, a logical ordering might also be:
   mean sd min q1 med q3 max
rather than have mean buried in between order statistics.

regards,

/iaw



From rkoenker at uiuc.edu  Mon Feb  6 21:39:39 2006
From: rkoenker at uiuc.edu (roger koenker)
Date: Mon, 6 Feb 2006 14:39:39 -0600
Subject: [R] appeal --- add sd to summary for univariates
In-Reply-To: <50d1c22d0602061234u28cd4d56wa9e9839208296294@mail.gmail.com>
References: <50d1c22d0602061234u28cd4d56wa9e9839208296294@mail.gmail.com>
Message-ID: <7748DEC9-5B2F-4DC1-91A3-87B744BF0440@uiuc.edu>


On Feb 6, 2006, at 2:34 PM, ivo welch wrote:
>
> Aside, a logical ordering might also be:
>    mean sd min q1 med q3 max
> rather than have mean buried in between order statistics.

		Just where it belongs, IMHO....

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820



From deepayan.sarkar at gmail.com  Mon Feb  6 21:51:31 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 6 Feb 2006 14:51:31 -0600
Subject: [R] panel.levelplot() for 2D histograms
In-Reply-To: <9AC105024CEA64458BF66D1DE13CA50D070FB4F9@tibbemeexs1.eu.jnj.com>
References: <9AC105024CEA64458BF66D1DE13CA50D070FB4F9@tibbemeexs1.eu.jnj.com>
Message-ID: <eb555e660602061251v4ab70149q88f2d190a4c05180@mail.gmail.com>

On 2/6/06, Vermeiren, Hans [VRCBE] <hvermei1 at vrcbe.jnj.com> wrote:
> Dear R-wizards,
> I'm trying to plot "binned scatterplots", or 2d histograms, if you wish, for
> a number of groups by using the lattice functionality
> it works fine for one group at a time, and probably I could find a
> work-around, but I prefer to do it the elegant way
> here's an example of what I want, what I tried and where it goes wrong:

If you are doing this for fun, read on. Otherwise, I suggest that you
look at the hexbin package (available from bioconductor) for a better
solution. The development version (to be released after R 2.3.0)
already has a lattice-ified interface called 'hexbinplot'.


> require(gregmisc)
> require(lattice)
> #toy dataset:
> ds<-data.frame(x=rnorm(3000),y=rnorm(3000),group=rep(factor(c("A","B","C")),
> 1000))
>
> # this binscatter-function shows what I want,
> # I just would like to have it as a panel function
>
> binscatter<-function(x,y){
>  col<-rev(gray.colors(5))
>  breaks=c(1,5,10,100,500,100000)
>  h2d<-hist2d(x=x,y=y,nbins=10,same.scale=T,show=F)
>  image(h2d$x,h2d$y,h2d$counts,breaks=breaks,col=col,axes=T)
> }
>
>
> # for one group, this works fine
> A<-subset(ds,group=="A")
> binscatter(A$x,A$y)
>
> # simple xyplot does too (of course)
> xyplot(y~x|group,data=ds)
>
> # but my lattice-ified version of binscatter does not:
> # 1st attempt
> panel.binscatter<-function(x,y,subscripts,...){
>  col<-gray.colors(5)
>  breaks=c(1,5,10,100,500,100000)
>  h2d<-hist2d(x=x,y=y,nbins=10,same.scale=T,show=F)
>
> panel.levelplot(h2d$x,h2d$y,h2d$counts,subscripts=1:length(h2d$x),at=breaks,
> col.regions=col,region=T)
> }

'image' requires the z-values as a matrix and x,y values as the
margins; whereas 'panel.levelplot' needs them as vectors of the same
length (so row and column positions are repeated). To call
'panel.levelplot', you need to construct the suitable x and y values.
If I were you, I would forget about 'panel.levelplot' and construct a
call to 'grid.rect' (in the grid package) which 'panel.levelplot' ends
up doing after jumping through a lot of hoops that are irrelevant
here.

Deepayan

>
> xyplot(y~x|group,data=ds,panel=panel.binscatter)
>
> # but, this doesnt work either for one group using levelplot() :
> Ah2d<-hist2d(A$x,A$y,nbins=10,same.scale=T,show=F)
> levelplot(Ah2d$counts~Ah2d$x*Ah2d$y)
>
> # but this DOES:
> grid<-expand.grid(x=Ah2d$x,y=Ah2d$y)
> levelplot(Ah2d$counts~grid$x*grid$y)
>
> #2nd attempt doesn't work, I give up..
> panel.binscatter<-function(x,y,subscripts,...){
> col<-gray.colors(5)
> breaks=c(1,5,10,100,500,100000)
> h2d<-hist2d(x=x,y=y,nbins=10,same.scale=T,show=F)
> grid<-expand.grid(x=h2d$x,y=h2d$y)
> panel.levelplot(grid$x,grid$y,h2d$counts,subscripts=1:length(h2d$x),at=break
> s,col.regions=col)
> }
>
> xyplot(y~x|group,data=ds,panel=panel.binscatter)
>
> all suggestions welcome, thanks a lot
>
> Hans



From sdavis2 at mail.nih.gov  Mon Feb  6 21:51:47 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 06 Feb 2006 15:51:47 -0500
Subject: [R] R loop
In-Reply-To: <50d1c22d0602061206i4cfb79eci7195593dc6e6d75@mail.gmail.com>
Message-ID: <C00D2113.5401%sdavis2@mail.nih.gov>




On 2/6/06 3:06 PM, "ivo welch" <ivowel at gmail.com> wrote:

> I am not an R expert, but I think the R idea of this task is to work
> with a data frame (where you make a and b are columns), and then to
> iterate over the rows.
> 
> data <- read.table( textConnection(
> "a b
> 1 name1
> 2 name2
> 3 name3"), header=TRUE) ;  # just learned this one
> 
> for (i in 1:nrow(data)) print( data[i,] );
> or just  data[1:3,]
> 
> 
> apropos, R does not support native hashes (like perl), unfortunately,
> but it has something similar:
> 
> data$a=="b"   # gives F T F
> data[ data$a == "name2" ]  # does not work and gives a weird result,  yuck

 data[data$a=="name2",]

Notice the difference from what you did.

> data frame sorting by column (using order) could also be simpler to
> understand for novices---IMHO, there should be a wrapper function that
> is in standard R like
>   data.sorted = sort( data, by=data$b );

Look at ?order.  

Sean



From ivowel at gmail.com  Mon Feb  6 21:57:30 2006
From: ivowel at gmail.com (ivo welch)
Date: Mon, 6 Feb 2006 15:57:30 -0500
Subject: [R] R loop
In-Reply-To: <C00D2113.5401%sdavis2@mail.nih.gov>
References: <50d1c22d0602061206i4cfb79eci7195593dc6e6d75@mail.gmail.com>
	<C00D2113.5401%sdavis2@mail.nih.gov>
Message-ID: <50d1c22d0602061257h78e9a562x245ce0f2e6cb1dc@mail.gmail.com>

> > data[ data$a == "name2" ]  # does not work and gives a weird result,  yuck
>
>  data[data$a=="name2",]
>

sorry about this.  I believe a few versions back, one could not subset
data frames, so I did not even check what I wrote.  Works now.

> Look at ?order.

I know.  This is why I suggested only that we need a wrapper that
plugs an order() functionality into the sort() function (which
fortunately points in its docs to order)---but novices would find the
sort syntax easier.

regards,

/iaw



From robert-mcfadden at o2.pl  Mon Feb  6 21:59:32 2006
From: robert-mcfadden at o2.pl (Robert Mcfadden)
Date: Mon, 6 Feb 2006 21:59:32 +0100
Subject: [R] iteration history
Message-ID: <000001c62b60$3ad3ed60$1191680a@robert>

Dear R Users
I would like to use optim function to optimize a function. I read help but I
couldn't find what I need: is it possible to get information after each
iteration, for example as there is in MATLAB:
                                                        Gradient's 
 Iteration  Func-count       f(x)        Step-size      infinity-norm
     0          24          388.976                            14
     1          72           385.67      0.0292637           16.8  
     2          96           383.54              1           4.15  
     3         120          383.412              1          0.108  
     4         144          383.412              1          0.002  
     5         168          383.412              1        0.00149  
     6         192          383.412              1      6.23e-005  
     7         216          383.412              1      1.01e-005  
   

It is useful when iteration takes long time - I know what's happen
I would appreciate any suggestion

Robert



From Gautam.Bhola at pfizer.com  Mon Feb  6 22:11:42 2006
From: Gautam.Bhola at pfizer.com (Bhola, Gautam)
Date: Mon, 6 Feb 2006 16:11:42 -0500
Subject: [R] R-2.2.1-INSTALL Issue with TCLTK
Message-ID: <E04D0A5FF70E854582D33D93A880799B0399BF83@groamrexm03.amer.pfizer.com>

I haven't seen any updates/suggestions on this topic, so just
wondering??


-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Friday, February 03, 2006 3:20 PM
To: Bhola, Gautam
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] R-2.2.1-INSTALL Issue with TCLTK

Those don't look like valid paths to config files to me.  On FC3 they 
would be

/usr/lib/tclConfig.sh
/usr/lib/tkConfig.sh

So even if you have users tcl-8.4.12 and tk-8.4.12 (do you?), your paths

are almost surely not to config files.

Configure reports what works, including that it is not going to build 
tcl/tk support.  Look back at the relevant parts of its output.

On Fri, 3 Feb 2006, Bhola, Gautam wrote:

> Hi
>
>
>
> I am not able to have a working tcltk library in R-2.2.1 inspite of
> trying different options suggested in the FAQ's. I am using the
> following configure option and I do get the tcltk package installed
but
> with a missing libs folder.
>
>
>
> ./configure -prefix= "~R-2.2.1"  --enable-R-shlib --enable-linux-lfs
> --with-zlib --with-gnu-ld --with-tcltk
> --with-tcl-config="~tcl-8.4.12/lib" --with-tk-config="~tk-8.4.12/lib"
>
>
>
> I have ensured that I have a valid tclsh in my path and have even
> provided the include path for covering the tcl.h
>
>
>
> Operating system: RHEL
>
>
>
> The error I get while trying to invoke the libarary for tcltk is:
>
>
>
> Error in firstlib(which.lib.loc, package) :
>
> Tcl/Tk support is not available on this system
>
> Error in library(tcltk) : .First.lib failed for 'tcltk'
>
> Execution halted
>
>
>
> Any help to identify the cause is highly appreciated.
>
>
>
> Respectfully
>
> Gautam
>
> ----------------------------------------------------------------------
> LEGAL NOTICE\ Unless expressly stated otherwise, this
messag...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595
----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From ggrothendieck at gmail.com  Mon Feb  6 22:13:11 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 6 Feb 2006 16:13:11 -0500
Subject: [R] iteration history
In-Reply-To: <000001c62b60$3ad3ed60$1191680a@robert>
References: <000001c62b60$3ad3ed60$1191680a@robert>
Message-ID: <971536df0602061313s7139a327v813d07a41b74b88@mail.gmail.com>

Check out:

https://www.stat.math.ethz.ch/pipermail/r-devel/2006-January/036034.html

On 2/6/06, Robert Mcfadden <robert-mcfadden at o2.pl> wrote:
> Dear R Users
> I would like to use optim function to optimize a function. I read help but I
> couldn't find what I need: is it possible to get information after each
> iteration, for example as there is in MATLAB:
>                                                        Gradient's
>  Iteration  Func-count       f(x)        Step-size      infinity-norm
>     0          24          388.976                            14
>     1          72           385.67      0.0292637           16.8
>     2          96           383.54              1           4.15
>     3         120          383.412              1          0.108
>     4         144          383.412              1          0.002
>     5         168          383.412              1        0.00149
>     6         192          383.412              1      6.23e-005
>     7         216          383.412              1      1.01e-005
>
>
> It is useful when iteration takes long time - I know what's happen
> I would appreciate any suggestion
>
> Robert
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From revans at jlab.org  Mon Feb  6 22:34:39 2006
From: revans at jlab.org (Richard Evans)
Date: Mon, 6 Feb 2006 16:34:39 -0500
Subject: [R] novice questions about programming in "R"
Message-ID: <000001c62b65$22bc39d0$de173981@revansx>

folks, 

I have been struggling with the "R" documentation for too long now and 
I need a simple answer on two questions. The documentation does not 
have adequate examples. Please help. 

given two equal vector lists: 
   A <- c(0,1,2,3) 
   B <- c(5,6,7,8) 

[Question #1] 
how do I dump them to a text file with the following format: 
------------------------------------------------------------ 
[line 1] 0.0000000    5.0000000 
[line 2] 1.0000000    6.0000000 
[line 3] 2.0000000    7.0000000 
[line 4] 3.0000000    8.0000000 
------------------------------------------------------------ 

[Question #2] 
------------------------------------------------------------ 
how do you make log-log plot that looks 
like it was plotted on log-log graph paper? 
------------------------------------------------------------ 

many thanks, 
- revansx



From rab45+ at pitt.edu  Mon Feb  6 22:51:37 2006
From: rab45+ at pitt.edu (Rick Bilonick)
Date: Mon, 06 Feb 2006 16:51:37 -0500
Subject: [R] Error in fun(...) : couldn't find function "assignInNamespace"
Message-ID: <1139262697.3431.7.camel@localhost.localdomain>

I started my laptop, opened a shell and get this error message:

R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.2.1  (2005-12-20 r36812)
ISBN 3-900051-07-0

lines deleted

Error in fun(...) : couldn't find function "assignInNamespace"
Error: .onLoad failed in 'loadNamespace' for 'Matrix'
Fatal error: unable to restore saved data in .RData

Here is some directory information:

-rw-rw-r--   1 chippy chippy 1222666 Feb  2 07:20 .RData
-rw-------   1 chippy chippy   21897 Feb  2 07:20 .Rhistory

Is .RData corrupted? I can run R in other directories.

Rick B.



From ggrothendieck at gmail.com  Mon Feb  6 23:01:13 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 6 Feb 2006 17:01:13 -0500
Subject: [R] novice questions about programming in "R"
In-Reply-To: <000001c62b65$22bc39d0$de173981@revansx>
References: <000001c62b65$22bc39d0$de173981@revansx>
Message-ID: <971536df0602061401u22efa41cudfad93d487de7416@mail.gmail.com>

Try this:

	write.table(sprintf("%10.5f%10.5f", A, B), file = "myfile.dat",
		quote = FALSE, row = FALSE, col = FALSE)

	plot(1:100, 1:100, log = "xy")
	grid()  # only if you want a grid


?plot.default has info on the log= argument.  Use ? with the other
commands to find out more about them.


On 2/6/06, Richard Evans <revans at jlab.org> wrote:
> folks,
>
> I have been struggling with the "R" documentation for too long now and
> I need a simple answer on two questions. The documentation does not
> have adequate examples. Please help.
>
> given two equal vector lists:
>   A <- c(0,1,2,3)
>   B <- c(5,6,7,8)
>
> [Question #1]
> how do I dump them to a text file with the following format:
> ------------------------------------------------------------
> [line 1] 0.0000000    5.0000000
> [line 2] 1.0000000    6.0000000
> [line 3] 2.0000000    7.0000000
> [line 4] 3.0000000    8.0000000
> ------------------------------------------------------------
>
> [Question #2]
> ------------------------------------------------------------
> how do you make log-log plot that looks
> like it was plotted on log-log graph paper?
> ------------------------------------------------------------
>
> many thanks,
> - revansx
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From stats at psyctc.org  Mon Feb  6 23:29:59 2006
From: stats at psyctc.org (Chris Evans)
Date: Mon, 6 Feb 2006 22:29:59 +0000
Subject: [R] lme4: Error in getResponseFormula(form) : "Form" must be a two
	sided formula
Message-ID: <1994687269.20060206222959@psyctc.org>

I'm sure I'm being stupid so flame away...

R2.2.1 on Windoze (boohoo) latest updates of packages.

I'm exploring a dataset (land) with three variables looking at an
narrowly unbalanced two group (GROUP) ANCOVA of a randomised
controlled trial analysing endpoint score (SFQ.LOCF.ENDPOINT) entering
the baseline score (SFQ.BASELINE) as covariate and the following work
fine:

> res.same <- lm(SFQ.LOCF.ENDPOINT ~ SFQ.BASELINE + GROUP,land)
> res.diff <- lm(SFQ.LOCF.ENDPOINT ~ SFQ.BASELINE + GROUP + SFQ.BASELINE*GROUP,land)
> anova(res.same,res.diff)

I try:

> lmList(SFQ.LOCF.ENDPOINT ~ SFQ.BASELINE | GROUP, land)
Call:
Error in getResponseFormula(form) : "Form" must be a two sided formula

I'm puzzled.  That looks like a two sided formula very like the one in
the help for lme4 (which had been loaded) and the data look OK:

> table(land$SFQ.LOCF.ENDPOINT)
 3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 23
 1  1  2  4  8  5 16  9  7 14 18  7 16  9  6  8  4  6  2  3 
> table(land$SFQ.BASELINE)
 3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 1  1  3  3  4 11  7  7 10 12  9 16 14  9  8  7  8  6  1  1 
> table(land$GROUP)
 1  2
87 89

Advice accepted gratefully and flames ruefully!

Chris

-- 
Chris Evans <chris at psyctc.org>
Consultant Psychiatrist in Psychotherapy, Rampton Hospital; 
Research Programmes Director, Nottinghamshire NHS Trust, 
Hon. Professor of Psychotherapy, Nottingham University,
Hon. SL Institute of Psychiatry
*** My views are my own and not representative of those institutions ***



From statistical.model at googlemail.com  Tue Feb  7 00:06:33 2006
From: statistical.model at googlemail.com (statistical.model@googlemail.com)
Date: Mon, 6 Feb 2006 23:06:33 -0000
Subject: [R] Shapley Values
Message-ID: <EMEELGDEKHMIAKDGLCDCOEHNCKAA.Statistical.model@gmail.com>

Hi,
I am trying to compute the Shapley Values between a set of p independent
variables (x1, ..., xp) and the dependent variable y to study the
relationships.

I believe that the package "kappalab" could be an appropriate choice.

Is anybody able to give me some hints about the code I should write?
Any better package?

thanks in advance!

Roberto Furlan
University of Turin




----------------------------------------
La mia Cartella di Posta in Arrivo e protetta da SPAMfighter
201 messaggi contenenti spam sono stati bloccati con successo.
Scarica gratuitamente SPAMfighter!



From jfox at mcmaster.ca  Tue Feb  7 00:33:04 2006
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 6 Feb 2006 18:33:04 -0500
Subject: [R] novice questions about programming in "R"
In-Reply-To: <000001c62b65$22bc39d0$de173981@revansx>
Message-ID: <20060206233304.XRBA5032.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Richard,


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Richard Evans
> Sent: Monday, February 06, 2006 4:35 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] novice questions about programming in "R"
> 
> folks, 
> 
> I have been struggling with the "R" documentation for too 
> long now and I need a simple answer on two questions. The 
> documentation does not have adequate examples. Please help. 
> 
> given two equal vector lists: 
>    A <- c(0,1,2,3) 
>    B <- c(5,6,7,8) 
> 
> [Question #1]
> how do I dump them to a text file with the following format: 
> ------------------------------------------------------------ 
> [line 1] 0.0000000    5.0000000 
> [line 2] 1.0000000    6.0000000 
> [line 3] 2.0000000    7.0000000 
> [line 4] 3.0000000    8.0000000 
> ------------------------------------------------------------ 


One way to do this is

Data <- cbind(A,B)
rownames(Data) <- paste("[line ", 1:4, "]", sep="")
write.table(formatC(Data, digits=7, format="f"), 
    file="c:/temp/test.txt", col.names=FALSE, quote=FALSE)

[Note that the two vectors are not lists and are not equal. If you don't
really want the line numbers in the file, then omit the second command and
use the argument row.names=FALSE to write.table().] 

> 
> [Question #2]
> ------------------------------------------------------------
> how do you make log-log plot that looks like it was plotted 
> on log-log graph paper? 
> ------------------------------------------------------------ 
>

plot(x, y, log="xy")

[I assume that you don't want the graph-paper grid, though you could add
that with abline(h=values, v=values, col="gray") if you do.]

I hope this helps,
 John

> many thanks,
> - revansx
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From dmbates at gmail.com  Tue Feb  7 00:39:10 2006
From: dmbates at gmail.com (Douglas Bates)
Date: Mon, 6 Feb 2006 17:39:10 -0600
Subject: [R] lme4: Error in getResponseFormula(form) : "Form" must be a
	two sided formula
In-Reply-To: <1994687269.20060206222959@psyctc.org>
References: <1994687269.20060206222959@psyctc.org>
Message-ID: <40e66e0b0602061539q384ecfe0hc935e7c07010ea9@mail.gmail.com>

Please check which packages you have attached when you call lmList. 
That error message looks as if it is coming from the version of lmList
that is in the nlme package, not the one in lme4.

On 2/6/06, Chris Evans <stats at psyctc.org> wrote:
> I'm sure I'm being stupid so flame away...
>
> R2.2.1 on Windoze (boohoo) latest updates of packages.
>
> I'm exploring a dataset (land) with three variables looking at an
> narrowly unbalanced two group (GROUP) ANCOVA of a randomised
> controlled trial analysing endpoint score (SFQ.LOCF.ENDPOINT) entering
> the baseline score (SFQ.BASELINE) as covariate and the following work
> fine:
>
> > res.same <- lm(SFQ.LOCF.ENDPOINT ~ SFQ.BASELINE + GROUP,land)
> > res.diff <- lm(SFQ.LOCF.ENDPOINT ~ SFQ.BASELINE + GROUP + SFQ.BASELINE*GROUP,land)
> > anova(res.same,res.diff)
>
> I try:
>
> > lmList(SFQ.LOCF.ENDPOINT ~ SFQ.BASELINE | GROUP, land)
> Call:
> Error in getResponseFormula(form) : "Form" must be a two sided formula
>
> I'm puzzled.  That looks like a two sided formula very like the one in
> the help for lme4 (which had been loaded) and the data look OK:
>
> > table(land$SFQ.LOCF.ENDPOINT)
>  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 23
>  1  1  2  4  8  5 16  9  7 14 18  7 16  9  6  8  4  6  2  3
> > table(land$SFQ.BASELINE)
>  3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
>  1  1  3  3  4 11  7  7 10 12  9 16 14  9  8  7  8  6  1  1
> > table(land$GROUP)
>  1  2
> 87 89
>
> Advice accepted gratefully and flames ruefully!
>
> Chris
>
> --
> Chris Evans <chris at psyctc.org>
> Consultant Psychiatrist in Psychotherapy, Rampton Hospital;
> Research Programmes Director, Nottinghamshire NHS Trust,
> Hon. Professor of Psychotherapy, Nottingham University,
> Hon. SL Institute of Psychiatry
> *** My views are my own and not representative of those institutions ***
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From marcodoc75 at yahoo.com  Tue Feb  7 00:47:39 2006
From: marcodoc75 at yahoo.com (Marco Geraci)
Date: Mon, 6 Feb 2006 15:47:39 -0800 (PST)
Subject: [R] iteration history
In-Reply-To: <000001c62b60$3ad3ed60$1191680a@robert>
Message-ID: <20060206234739.21162.qmail@web31307.mail.mud.yahoo.com>

Hi, I never used the function 'optim' so I took a look
at ?optim.
you'll find the following

The 'control' argument is a list that can supply any
of the following components:
     'trace' Non-negative integer. If positive,
tracing information on the progress of the
optimization is produced. Higher values may produce
more tracing information: for method '"L-BFGS-B"'
there are six levels of tracing

so the usage for 'trace' is
> optim(..., control=list(trace = k))
where k is >= 0. 
You might want to "play" with different methods and
values for 'trace' and see if you can get what you
want.

hope this helps,

Marco Geraci

--- Robert Mcfadden <robert-mcfadden at o2.pl> wrote:

> Dear R Users
> I would like to use optim function to optimize a
> function. I read help but I
> couldn't find what I need: is it possible to get
> information after each
> iteration, for example as there is in MATLAB:
>                                                     
>    Gradient's 
>  Iteration  Func-count       f(x)        Step-size  
>    infinity-norm
>      0          24          388.976                 
>           14
>      1          72           385.67      0.0292637  
>         16.8  
>      2          96           383.54              1  
>         4.15  
>      3         120          383.412              1  
>        0.108  
>      4         144          383.412              1  
>        0.002  
>      5         168          383.412              1  
>      0.00149  
>      6         192          383.412              1  
>    6.23e-005  
>      7         216          383.412              1  
>    1.01e-005  
>    
> 
> It is useful when iteration takes long time - I know
> what's happen
> I would appreciate any suggestion
> 
> Robert
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Tue Feb  7 00:56:24 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 07 Feb 2006 00:56:24 +0100
Subject: [R] R-2.2.1-INSTALL Issue with TCLTK
In-Reply-To: <E04D0A5FF70E854582D33D93A880799B0399BF83@groamrexm03.amer.pfizer.com>
References: <E04D0A5FF70E854582D33D93A880799B0399BF83@groamrexm03.amer.pfizer.com>
Message-ID: <x2vevsm47r.fsf@turmalin.kubism.ku.dk>

"Bhola, Gautam" <Gautam.Bhola at pfizer.com> writes:

> I haven't seen any updates/suggestions on this topic, so just
> wondering??

As far as I can see, the ball is on your half, so why are you
expecting any? Did you do as Brian suggested?
 
> 
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Friday, February 03, 2006 3:20 PM
> To: Bhola, Gautam
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] R-2.2.1-INSTALL Issue with TCLTK
> 
> Those don't look like valid paths to config files to me.  On FC3 they 
> would be
> 
> /usr/lib/tclConfig.sh
> /usr/lib/tkConfig.sh
> 
> So even if you have users tcl-8.4.12 and tk-8.4.12 (do you?), your paths
> 
> are almost surely not to config files.
> 
> Configure reports what works, including that it is not going to build 
> tcl/tk support.  Look back at the relevant parts of its output.
> 
> On Fri, 3 Feb 2006, Bhola, Gautam wrote:
> 
> > Hi
> >
> >
> >
> > I am not able to have a working tcltk library in R-2.2.1 inspite of
> > trying different options suggested in the FAQ's. I am using the
> > following configure option and I do get the tcltk package installed
> but
> > with a missing libs folder.
> >
> >
> >
> > ./configure -prefix= "~R-2.2.1"  --enable-R-shlib --enable-linux-lfs
> > --with-zlib --with-gnu-ld --with-tcltk
> > --with-tcl-config="~tcl-8.4.12/lib" --with-tk-config="~tk-8.4.12/lib"
> >
> >
> >
> > I have ensured that I have a valid tclsh in my path and have even
> > provided the include path for covering the tcl.h
> >
> >
> >
> > Operating system: RHEL
> >
> >
> >
> > The error I get while trying to invoke the libarary for tcltk is:
> >
> >
> >
> > Error in firstlib(which.lib.loc, package) :
> >
> > Tcl/Tk support is not available on this system
> >
> > Error in library(tcltk) : .First.lib failed for 'tcltk'
> >
> > Execution halted
> >
> >
> >
> > Any help to identify the cause is highly appreciated.
> >
> >
> >
> > Respectfully
> >
> > Gautam
> >
> > ----------------------------------------------------------------------
> > LEGAL NOTICE\ Unless expressly stated otherwise, this
> messag...{{dropped}}
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> ----------------------------------------------------------------------
> LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From smimholt at excite.com  Tue Feb  7 01:06:34 2006
From: smimholt at excite.com (Susan  Imholt)
Date: Mon,  6 Feb 2006 19:06:34 -0500 (EST)
Subject: [R] sampling and nls formula
Message-ID: <20060207000634.DAB2C1E416@xprdmailfe24.nwk.excite.com>


Hello,

I am trying to bootstrap a function that extracts the log-likelihood value and the nls coefficients from an nls object.  I want to sample my dataset (pdd) with replacement and for each sampled dataset, I want to run nls and output the nls coefficients and the log-likelihood value.

Code:
x<-c(1,2,3,4,5,6,7,8,9,10)
y<-c(10,11,12,15,19,23,26,28,28,30)
pdd<-data.frame(x,y)

i<-sample(10, replace=TRUE)

pdd.lik.coef<-function(data,i){
     d<-data[i,]
     pdd.nls<-nls(d$y~(a*(d$x)^2)/(b+(d$x)^2), data=pdd, start = list(a = 30, b = 36), trace=FALSE)
     pdd.logLik<-logLik(pdd.nls)
     coeff <- coef(pdd.nls)
     lik.coef <- c(pdd.logLik, coeff)
}

pdd.boot<-boot(data=pdd, statistic=pdd.lik.coef, R=1000)
pdd.boot$t

My problem lies in the pdd.lik.coef function. It seems that nls recognizes all letters in the formula d$y~(a*(d$x)^2)/(b+(d$x)^2) as parameters, so "d$y" and "d$x" in the formula aren't being recognized properly to be sampled, rather the "d" is interpreted as a parameter.  When I try to bootstrap this function, I get an error message: "Error in eval(expr, envir, enclos) : object "d" not found" (because I didn't specify an estimate for d as a parameter, since I didn't intend for it to be a parameter).  

Any suggestions?

Thanks,
Susie Imholt
Master's Candidate
Huxley College of the Environment
Western Washington University
Bellingham, WA  USA




_______________________________________________
Join Excite! - http://www.excite.com
The most personalized portal on the Web!



From Soren.Hojsgaard at agrsci.dk  Tue Feb  7 01:02:14 2006
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Tue, 7 Feb 2006 01:02:14 +0100
Subject: [R] lme and Assay data: Test for block effect when block is
	systematic - anova/summary goes wrong
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC038781A3@DJFPOST01.djf.agrsci.dk>

Consider the Assay data where block, sample within block and dilut within block is random.
This model can be fitted with (where I define Assay2 to get an ordinary data frame rather
than a grouped data object):
 
Assay2 <- as.data.frame(Assay)
fm2<-lme(logDens~sample*dilut, data=Assay2,
  random=list(Block = pdBlocked(list(pdIdent(~1), pdIdent(~sample-1),pdIdent(~dilut-1))) ))
 
Now, block has only 2 levels so I prefer to treat it as fixed:
 
fm3<-lme(logDens~Block+sample*dilut, data=Assay2,
  random=list(Block = pdBlocked(list(pdIdent(~sample-1),pdIdent(~dilut-1))) ))
 
This works fine until I try a summary() or anova(), e.g.
 
> anova(fm3)
             numDF denDF  F-value p-value
(Intercept)      1    29 824.2612  <.0001
Block              1     0   1.5320     NaN
sample            5    29  11.2133  <.0001
dilut               4    29 420.7901  <.0001
sample:dilut    20    29   1.6069  0.1193
Warning messages:
1: NaNs produced in: pf(q, df1, df2, lower.tail, log.p)
2: NAs introduced by coercion
 
The output from SAS (when I request residual denominator dfs)
     Type 1 Tests of Fixed Effects
                   Num     Den
Effect              DF      DF    F Value    Pr > F
Block                 1      29       1.53    0.2257
sample               5      29      11.21    <.0001
dilut                  4      29     420.79    <.0001
sample*dilut      20      29       1.61    0.1193
 
The test for block effect is usually not of interest. Moreover, I don't want to enroll into the "degree of freedom police force", but 0 dfs is certainly wrong. Maybe it would be better if lme simply used the residual df's (when no better choice is available??)
 
Best regards
S??ren



From lewinger at usc.edu  Tue Feb  7 01:17:35 2006
From: lewinger at usc.edu (Juan Pablo Lewinger)
Date: Mon, 06 Feb 2006 16:17:35 -0800
Subject: [R] cdf of multivariate normal
Message-ID: <000801c62b7b$e61b04e0$5be07d80@NIEHS.usc.edu>

I was wondering if anybody has written R code to compute the cdf of a
multivariate (or at least a bivariate) normal distribution with given
covariance structure.



From jfox at mcmaster.ca  Tue Feb  7 01:39:37 2006
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 6 Feb 2006 19:39:37 -0500
Subject: [R] [R-pkgs] New car package with new linear.hypothesis function
Message-ID: <20060207003936.CDLZ8316.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear R-packages list members,

Last month, Peter Muhlberger posted a message to the r-help list that
suggested, among other things, a desire for a more convenient method of
performing Wald tests for statistical models fit in R. 

Thanks largely to Achim Zeleis's help, the linear.hypothesis function in the
car package has been reworked so that (1) it is applicable to any model
object that responds to the generic coef() and vcov() functions (along with
specific methods for lm and glm objects); and (2) permits symbolic
specification of hypotheses as linear equations in the named parameters of
the model. I'd be particularly interested in people's reactions to the new
interface and to learn of any problems that arise

The new version 1.1-0 of the car package (with some other, less significant
changes and additions) is now on CRAN.

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From marcodoc75 at yahoo.com  Tue Feb  7 02:05:20 2006
From: marcodoc75 at yahoo.com (Marco Geraci)
Date: Mon, 6 Feb 2006 17:05:20 -0800 (PST)
Subject: [R] sampling and nls formula
In-Reply-To: <20060207000634.DAB2C1E416@xprdmailfe24.nwk.excite.com>
Message-ID: <20060207010520.50972.qmail@web31307.mail.mud.yahoo.com>

Hi

--- Susan  Imholt <smimholt at excite.com> wrote:

> 
> Hello,
> 
> I am trying to bootstrap a function that extracts
> the log-likelihood value and the nls coefficients
> from an nls object.  I want to sample my dataset
> (pdd) with replacement and for each sampled dataset,
> I want to run nls and output the nls coefficients
> and the log-likelihood value.
> 
> Code:
> x<-c(1,2,3,4,5,6,7,8,9,10)
> y<-c(10,11,12,15,19,23,26,28,28,30)
> pdd<-data.frame(x,y)
> 
> i<-sample(10, replace=TRUE)

i don't think you need a starting sample of the
'index'. You can omit 
> i<-sample(10, replace=TRUE)

 
> pdd.lik.coef<-function(data,i){
>      d<-data[i,]
>      pdd.nls<-nls(d$y~(a*(d$x)^2)/(b+(d$x)^2),
> data=pdd, start = list(a = 30, b = 36), trace=FALSE)

there's a programming error here
The argument 'data' of 'nls' must match the one that
you pass through 'pdd.lik.coef' or the one that you
redefine ('d'). Also, when a function like 'nls' has
the argument 'data' you don't need to use '$' in the
formula (providing that 'data' contains the variables
named in the formula). 

>     pdd.logLik<-logLik(pdd.nls)
>     coeff <- coef(pdd.nls)
>     lik.coef <- c(pdd.logLik, coeff)
>}

to gain some speed you might want to avoid assigning
the result to 'lik.coef', 'coeff', and 'lik.coef'.

Summarizing, the following code should work. 'should'
means that might not work. I tried with few boot
samples, and it did work. When I tried with R=1000,
the program stopped because 'nls' didn't like a
particular sample of the data and it reached maxit=50
(default). I added a 'control=list(maxiter=100)' to
'nls' to your code. I suggest you to 
work on that.

code:

x<-c(1,2,3,4,5,6,7,8,9,10)
y<-c(10,11,12,15,19,23,26,28,28,30)
pdd<-data.frame(x,y)

pdd.lik.coef<-function(data,i){
     d<-data[i,]
     pdd.nls<-nls(y~(a*x^2)/(b+x^2), data=d, start =
list(a = 30, b = 36), trace=FALSE,
control=list(maxiter=100))
     c(logLik(pdd.nls), coef(pdd.nls))
}

pdd.boot<-boot(data=pdd, statistic=pdd.lik.coef,
R=1000)
pdd.boot$t

hope this helps

Marco

> _______________________________________________
> Join Excite! - http://www.excite.com
> The most personalized portal on the Web!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From DrJones at alum.MIT.edu  Tue Feb  7 05:10:54 2006
From: DrJones at alum.MIT.edu (Thomas L Jones)
Date: Mon, 6 Feb 2006 23:10:54 -0500
Subject: [R] Scatterplot with corner at (0, 0)
Message-ID: <000601c62b9c$7df1d0d0$2f01a8c0@DrJones>

I have two vectors, x and y, and I want to create a scatterplot. I 
want the lower left corner to be at (0, 0). I can create a scatterplot 
just by calling plot (x, y), but I am quite throroughly stymied and 
frustrated by the problem of putting the lower left corner at (0, 0), 
despite many tries.

Thomas L. Jones, Ph.D., Computer Science



From narguea at ihmc.us  Tue Feb  7 05:48:34 2006
From: narguea at ihmc.us (Nestor Arguea)
Date: Mon, 6 Feb 2006 22:48:34 -0600
Subject: [R] Scatterplot with corner at (0, 0)
In-Reply-To: <000601c62b9c$7df1d0d0$2f01a8c0@DrJones>
References: <000601c62b9c$7df1d0d0$2f01a8c0@DrJones>
Message-ID: <200602062248.34606.narguea@ihmc.us>

> plot(x,y,xlim=c(0,max(x)),ylim=c(0,max(y)))

Nestor
On Monday 06 February 2006 10:10 pm, you wrote:
> I have two vectors, x and y, and I want to create a scatterplot. I
> want the lower left corner to be at (0, 0). I can create a scatterplot
> just by calling plot (x, y), but I am quite throroughly stymied and
> frustrated by the problem of putting the lower left corner at (0, 0),
> despite many tries.
>
> Thomas L. Jones, Ph.D., Computer Science
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Nestor M. Arguea, Chair
Department of Marketing and Economics
University of West Florida
11000 University Parkway
Pensacola, FL 32514
Phone: (850)474-3071
Fax: (850)474-3069



From sell_mirage_ne at hotmail.com  Tue Feb  7 07:07:11 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Tue, 07 Feb 2006 00:07:11 -0600
Subject: [R] creating a certain type of matrix
Message-ID: <BAY110-F14F3517767A02162915ADDC7010@phx.gbl>

Hi R users

I like to generate a certain type of  matrix.
If there are 10 variables, the matrix will have nrow=10, ncol=((10/2))/5+1. 
so the resulting matrix's dimension 10 by 2. If there are 50 variables the 
dimension of the resulting matrix will be 50 by 6.

The arrangement of elements of this matrix is important to me and I can't 
figure out how to arrange elements.

If I have 20 variables. The resulting matrix will be 20 by 3
The first half of first column of the matrix will be 1s. The all elements on 
the second half of the first column of the matrix will be random numbers 
coming from rnorm(1,0,1). The first half of the second column of the matrix 
will be zeros. The first five elements of the second half of the second 
column of the matrix will be random numbers coming from rnorm(1,0,1). After 
that, the remaining elements of the second half will be zeros. The first 
half of the third column of the matrix will be zeors. The first five 
elements of the second half of the third column will be zeros too and then 5 
random numbers coming from rnorm(1,0,1).

If there are 40 variables the resulting matrix will be 40*5
The first half of first column of the matrix will be 1s. The all elements on 
the second half of the first column of the matrix will be random numbers 
coming from rnorm(1,0,1).

The first half of the second column of the matrix will be zeros. The first 
five elements of the second half of the second column of the matrix will be 
random numbers coming from rnorm(1,0,1). After that, the remaining elements 
of the second half will be zeros.

The first half of the third column of the matrix will be zeors. The first 
FIVE elements of the second half of the third column will be zeros too and 
then 5 random numbers coming from rnorm(1,0,1) and then the rest of elements 
of the third column will be zeros.

The first half of the fourth column of the matrix will be zeors.The first 
TEN elements of the second half of the fourth column will be zeros too and 
then 5 random numbers coming from rnorm(1,0,1) and then the rest of elements 
of the third column will be zeros.

The first half of the fifth column of the matrix will be zeors.The first 
FIFTEEN elements of the second half of the fourth column will be zeros too 
and then 5 random numbers coming from rnorm(1,0,1).

I tried to create 10 different functions ( one for 10, 20, 30, 40, .... , 
100 variables) but it's not efficient.

Any help or advice for creating one function that can do all 10 kind of 
variable cases would be appreciated.

Thans in advance

Taka



From petr.pikal at precheza.cz  Tue Feb  7 08:03:04 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 07 Feb 2006 08:03:04 +0100
Subject: [R] R loop
In-Reply-To: <50d1c22d0602061257h78e9a562x245ce0f2e6cb1dc@mail.gmail.com>
References: <C00D2113.5401%sdavis2@mail.nih.gov>
Message-ID: <43E85438.7457.4BBCAC@localhost>

Hi

On 6 Feb 2006 at 15:57, ivo welch wrote:

Date sent:      	Mon, 6 Feb 2006 15:57:30 -0500
From:           	ivo welch <ivowel at gmail.com>
To:             	Sean Davis <sdavis2 at mail.nih.gov>
Copies to:      	piet.vanremortel at gmail.com, r-help <r-help at stat.math.ethz.ch>
Subject:        	Re: [R] R loop

> > > data[ data$a == "name2" ]  # does not work and gives a weird
> > > result,  yuck
> >
> >  data[data$a=="name2",]
> >
> 
> sorry about this.  I believe a few versions back, one could not subset
> data frames, so I did not even check what I wrote.  Works now.

It depends on what you consider few versions back. I started with R 
vesion 1.2.0 about 10 years ago and I believe that data frame 
subsetting was done in **very** similar manner as it is performed 
now.

Cheers
Petr

> 
> > Look at ?order.
> 
> I know.  This is why I suggested only that we need a wrapper that
> plugs an order() functionality into the sort() function (which
> fortunately points in its docs to order)---but novices would find the
> sort syntax easier.
> 
> regards,
> 
> /iaw
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From ripley at stats.ox.ac.uk  Tue Feb  7 08:21:07 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 7 Feb 2006 07:21:07 +0000 (GMT)
Subject: [R] Error in fun(...) : couldn't find function
	"assignInNamespace"
In-Reply-To: <1139262697.3431.7.camel@localhost.localdomain>
References: <1139262697.3431.7.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.61.0602070716190.24004@gannet.stats>

On Mon, 6 Feb 2006, Rick Bilonick wrote:

> I started my laptop, opened a shell and get this error message:
>
> R : Copyright 2005, The R Foundation for Statistical Computing
> Version 2.2.1  (2005-12-20 r36812)
> ISBN 3-900051-07-0
>
> lines deleted
>
> Error in fun(...) : couldn't find function "assignInNamespace"
> Error: .onLoad failed in 'loadNamespace' for 'Matrix'
> Fatal error: unable to restore saved data in .RData
>
> Here is some directory information:
>
> -rw-rw-r--   1 chippy chippy 1222666 Feb  2 07:20 .RData
> -rw-------   1 chippy chippy   21897 Feb  2 07:20 .Rhistory
>
> Is .RData corrupted? I can run R in other directories.

No.  You've saved a reference to the Matrix namespace, and your Matrix has 
references to package utils in its startup without ensure utils is loaded.

The problem is in package Matrix: it has been reported before so 
hopefully will be fixed soon.

For now, load R --no-restore and start with load(".RData").

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Feb  7 08:25:03 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 7 Feb 2006 07:25:03 +0000 (GMT)
Subject: [R] Scatterplot with corner at (0, 0)
In-Reply-To: <200602062248.34606.narguea@ihmc.us>
References: <000601c62b9c$7df1d0d0$2f01a8c0@DrJones>
	<200602062248.34606.narguea@ihmc.us>
Message-ID: <Pine.LNX.4.61.0602070723490.24004@gannet.stats>

On Mon, 6 Feb 2006, Nestor Arguea wrote:

>> plot(x,y,xlim=c(0,max(x)),ylim=c(0,max(y)))

You also need xaxs="i", yaxs="i"

>
> Nestor
> On Monday 06 February 2006 10:10 pm, you wrote:
>> I have two vectors, x and y, and I want to create a scatterplot. I
>> want the lower left corner to be at (0, 0). I can create a scatterplot
>> just by calling plot (x, y), but I am quite throroughly stymied and
>> frustrated by the problem of putting the lower left corner at (0, 0),
>> despite many tries.
>>
>> Thomas L. Jones, Ph.D., Computer Science
>
> -- 
> Nestor M. Arguea, Chair
> Department of Marketing and Economics
> University of West Florida
> 11000 University Parkway
> Pensacola, FL 32514
> Phone: (850)474-3071
> Fax: (850)474-3069


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Tue Feb  7 08:56:10 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 07 Feb 2006 08:56:10 +0100
Subject: [R] R loop
In-Reply-To: <43E85438.7457.4BBCAC@localhost>
References: <C00D2113.5401%sdavis2@mail.nih.gov>
	<43E85438.7457.4BBCAC@localhost>
Message-ID: <43E8529A.9040609@statistik.uni-dortmund.de>

Petr Pikal wrote:

> Hi
> 
> On 6 Feb 2006 at 15:57, ivo welch wrote:
> 
> Date sent:      	Mon, 6 Feb 2006 15:57:30 -0500
> From:           	ivo welch <ivowel at gmail.com>
> To:             	Sean Davis <sdavis2 at mail.nih.gov>
> Copies to:      	piet.vanremortel at gmail.com, r-help <r-help at stat.math.ethz.ch>
> Subject:        	Re: [R] R loop
> 
> 
>>>>data[ data$a == "name2" ]  # does not work and gives a weird
>>>>result,  yuck
>>>
>>> data[data$a=="name2",]
>>>
>>
>>sorry about this.  I believe a few versions back, one could not subset
>>data frames, so I did not even check what I wrote.  Works now.
> 
> 
> It depends on what you consider few versions back. I started with R 
> vesion 1.2.0 about 10 years 

I bet 200$ (or EUR) you have not used R 10 years ago. ;-)

People certainly remember the 1.0.0 release at the remarkable day 
29-FEB-2000.
1.2.0 was released in December 2000, about 5 years ago.
I started with 0.62.x in 1998.
The oldest version I found on CRAN is a pre-alpha R.sea.hqx for the Mac 
               dated 07-Nov-1996.


Uwe Ligges





> ago and I believe that data frame 
> subsetting was done in **very** similar manner as it is performed 
> now.
> 
> Cheers
> Petr
> 
> 
>>>Look at ?order.
>>
>>I know.  This is why I suggested only that we need a wrapper that
>>plugs an order() functionality into the sort() function (which
>>fortunately points in its docs to order)---but novices would find the
>>sort syntax easier.
>>
>>regards,
>>
>>/iaw
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
> 
> 
> Petr Pikal
> petr.pikal at precheza.cz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From petr.pikal at precheza.cz  Tue Feb  7 08:58:59 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 07 Feb 2006 08:58:59 +0100
Subject: [R] creating a certain type of matrix
In-Reply-To: <BAY110-F14F3517767A02162915ADDC7010@phx.gbl>
Message-ID: <43E86153.32740.7EEF2D@localhost>

Hi

as only you know perfectly which halves and other portions of your 
matrices contain zeroes and which contain random numbers you has to 
finalize the function yourself.
Here are few ideas.

n<-20
mat<-matrix(0,n,(n/2)/5+1) #matrix of zeroes
dd<-dim(mat) # actual dimensions
mat[1:(dd[1]/2),1]<-1 #put 1 in first half of first column
mat[((dd[1]/2)+1):dd[1],1]<-rnorm(dd[1]/2,0,1) #put random numbers in 
following part of the matrix column 1
mat[((dd[1]/2)+1):(dd[1]/2)+dd[1]/4,2]<-rnorm(dd[1]/4,0,1) #put 
random numbers in column2

than according to n and dd values you can put any numbers anywhere in 
your matrix e.g. in for loop (not.tested :-)

for (i in 3:dd[2]) {

arrange everything into following desired columns
e.g.

length.of.rand.numbers <- (i-2)*5
my.rand.num<- rnorm(length.of.rand.numbers, 0,1)
start <- dd[1]/2+dd[1]/4
end <- start + length.of.rand.numbers
mat[start:end, i]<- my.rand.num

}

HTH
Petr

On 7 Feb 2006 at 0:07, Taka Matzmoto wrote:

From:           	"Taka Matzmoto" <sell_mirage_ne at hotmail.com>
To:             	r-help at stat.math.ethz.ch
Date sent:      	Tue, 07 Feb 2006 00:07:11 -0600
Subject:        	[R] creating a certain type of matrix

> Hi R users
> 
> I like to generate a certain type of  matrix.
> If there are 10 variables, the matrix will have nrow=10,
> ncol=((10/2))/5+1. so the resulting matrix's dimension 10 by 2. If
> there are 50 variables the dimension of the resulting matrix will be
> 50 by 6.
> 
> The arrangement of elements of this matrix is important to me and I
> can't figure out how to arrange elements.
> 
> If I have 20 variables. The resulting matrix will be 20 by 3
> The first half of first column of the matrix will be 1s. The all
> elements on the second half of the first column of the matrix will be
> random numbers coming from rnorm(1,0,1). The first half of the second
> column of the matrix will be zeros. The first five elements of the
> second half of the second column of the matrix will be random numbers
> coming from rnorm(1,0,1). After that, the remaining elements of the
> second half will be zeros. The first half of the third column of the
> matrix will be zeors. The first five elements of the second half of
> the third column will be zeros too and then 5 random numbers coming
> from rnorm(1,0,1).
> 
> If there are 40 variables the resulting matrix will be 40*5
> The first half of first column of the matrix will be 1s. The all
> elements on the second half of the first column of the matrix will be
> random numbers coming from rnorm(1,0,1).
> 
> The first half of the second column of the matrix will be zeros. The
> first five elements of the second half of the second column of the
> matrix will be random numbers coming from rnorm(1,0,1). After that,
> the remaining elements of the second half will be zeros.
> 
> The first half of the third column of the matrix will be zeors. The
> first FIVE elements of the second half of the third column will be
> zeros too and then 5 random numbers coming from rnorm(1,0,1) and then
> the rest of elements of the third column will be zeros.
> 
> The first half of the fourth column of the matrix will be zeors.The
> first TEN elements of the second half of the fourth column will be
> zeros too and then 5 random numbers coming from rnorm(1,0,1) and then
> the rest of elements of the third column will be zeros.
> 
> The first half of the fifth column of the matrix will be zeors.The
> first FIFTEEN elements of the second half of the fourth column will be
> zeros too and then 5 random numbers coming from rnorm(1,0,1).
> 
> I tried to create 10 different functions ( one for 10, 20, 30, 40,
> .... , 100 variables) but it's not efficient.
> 
> Any help or advice for creating one function that can do all 10 kind
> of variable cases would be appreciated.
> 
> Thans in advance
> 
> Taka
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From petr.pikal at precheza.cz  Tue Feb  7 09:08:07 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 07 Feb 2006 09:08:07 +0100
Subject: [R] R loop
In-Reply-To: <43E8529A.9040609@statistik.uni-dortmund.de>
References: <43E85438.7457.4BBCAC@localhost>
Message-ID: <43E86377.7065.874CB8@localhost>

Hi

you are correct as usually. It is about 10 versions 1.2.0 - 2.2.1 and 
as there are 2 versions per year it is about 4-5 years.

But nevertheless it seems to me as if I used R forever (and hopefully 
it will continue)

Anyway subsetting data frames **was** similar in the old versions as 
it is now, wasn't it?

Cheers
Petr

On 7 Feb 2006 at 8:56, Uwe Ligges wrote:

Date sent:      	Tue, 07 Feb 2006 08:56:10 +0100
From:           	Uwe Ligges <ligges at statistik.uni-dortmund.de>
Organization:   	Fachbereich Statistik, Universitaet Dortmund
To:             	Petr Pikal <petr.pikal at precheza.cz>
Copies to:      	r-help at stat.math.ethz.ch, ivo welch <ivowel at gmail.com>
Subject:        	Re: [R] R loop

> Petr Pikal wrote:
> 
> > Hi
> > 
> > On 6 Feb 2006 at 15:57, ivo welch wrote:
> > 
> > Date sent:      	Mon, 6 Feb 2006 15:57:30 -0500
> > From:           	ivo welch <ivowel at gmail.com>
> > To:             	Sean Davis <sdavis2 at mail.nih.gov>
> > Copies to:      	piet.vanremortel at gmail.com, r-help
> > <r-help at stat.math.ethz.ch> Subject:        	Re: [R] R loop
> > 
> > 
> >>>>data[ data$a == "name2" ]  # does not work and gives a weird
> >>>>result,  yuck
> >>>
> >>> data[data$a=="name2",]
> >>>
> >>
> >>sorry about this.  I believe a few versions back, one could not
> >>subset data frames, so I did not even check what I wrote.  Works
> >>now.
> > 
> > 
> > It depends on what you consider few versions back. I started with R
> > vesion 1.2.0 about 10 years 
> 
> I bet 200$ (or EUR) you have not used R 10 years ago. ;-)
> 
> People certainly remember the 1.0.0 release at the remarkable day
> 29-FEB-2000. 1.2.0 was released in December 2000, about 5 years ago. I
> started with 0.62.x in 1998. The oldest version I found on CRAN is a
> pre-alpha R.sea.hqx for the Mac 
>                dated 07-Nov-1996.
> 
> 
> Uwe Ligges
> 
> 
> 
> 
> 
> > ago and I believe that data frame 
> > subsetting was done in **very** similar manner as it is performed
> > now.
> > 
> > Cheers
> > Petr
> > 
> > 
> >>>Look at ?order.
> >>
> >>I know.  This is why I suggested only that we need a wrapper that
> >>plugs an order() functionality into the sort() function (which
> >>fortunately points in its docs to order)---but novices would find
> >>the sort syntax easier.
> >>
> >>regards,
> >>
> >>/iaw
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide!
> >>http://www.R-project.org/posting-guide.html
> > 
> > 
> > Petr Pikal
> > petr.pikal at precheza.cz
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From glaxowell at gmail.com  Tue Feb  7 09:08:57 2006
From: glaxowell at gmail.com (Rhett Eckstein)
Date: Tue, 7 Feb 2006 16:08:57 +0800
Subject: [R] install package in Mac
Message-ID: <d06710120602070008t3c85acdbn@mail.gmail.com>

Hi, all

I have problem about installing package (built in Windows) in Mac.

In the R for MacOS X FAQ, it mentioned that Mac required the

prebuilt package named as XXX.tgz.   However, the package built

under Windows named as XXX.zip.  So how should I do to let the

package (built in Windows) to install in Mac.

Thanks in advance !!



From ligges at statistik.uni-dortmund.de  Tue Feb  7 09:20:30 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 07 Feb 2006 09:20:30 +0100
Subject: [R] R loop
In-Reply-To: <43E86377.7065.874CB8@localhost>
References: <43E85438.7457.4BBCAC@localhost> <43E86377.7065.874CB8@localhost>
Message-ID: <43E8584E.3090408@statistik.uni-dortmund.de>

Petr Pikal wrote:

> Hi
> 
> you are correct as usually. It is about 10 versions 1.2.0 - 2.2.1 and 
> as there are 2 versions per year it is about 4-5 years.
> 
> But nevertheless it seems to me as if I used R forever (and hopefully 
> it will continue)
> 
> Anyway subsetting data frames **was** similar in the old versions as 
> it is now, wasn't it?

Yes, AFAIR, and just tested in 1.2.2.

Uwe Ligges

> Cheers
> Petr
> 
> On 7 Feb 2006 at 8:56, Uwe Ligges wrote:
> 
> Date sent:      	Tue, 07 Feb 2006 08:56:10 +0100
> From:           	Uwe Ligges <ligges at statistik.uni-dortmund.de>
> Organization:   	Fachbereich Statistik, Universitaet Dortmund
> To:             	Petr Pikal <petr.pikal at precheza.cz>
> Copies to:      	r-help at stat.math.ethz.ch, ivo welch <ivowel at gmail.com>
> Subject:        	Re: [R] R loop
> 
> 
>>Petr Pikal wrote:
>>
>>
>>>Hi
>>>
>>>On 6 Feb 2006 at 15:57, ivo welch wrote:
>>>
>>>Date sent:      	Mon, 6 Feb 2006 15:57:30 -0500
>>>From:           	ivo welch <ivowel at gmail.com>
>>>To:             	Sean Davis <sdavis2 at mail.nih.gov>
>>>Copies to:      	piet.vanremortel at gmail.com, r-help
>>><r-help at stat.math.ethz.ch> Subject:        	Re: [R] R loop
>>>
>>>
>>>
>>>>>>data[ data$a == "name2" ]  # does not work and gives a weird
>>>>>>result,  yuck
>>>>>
>>>>>data[data$a=="name2",]
>>>>>
>>>>
>>>>sorry about this.  I believe a few versions back, one could not
>>>>subset data frames, so I did not even check what I wrote.  Works
>>>>now.
>>>
>>>
>>>It depends on what you consider few versions back. I started with R
>>>vesion 1.2.0 about 10 years 
>>
>>I bet 200$ (or EUR) you have not used R 10 years ago. ;-)
>>
>>People certainly remember the 1.0.0 release at the remarkable day
>>29-FEB-2000. 1.2.0 was released in December 2000, about 5 years ago. I
>>started with 0.62.x in 1998. The oldest version I found on CRAN is a
>>pre-alpha R.sea.hqx for the Mac 
>>               dated 07-Nov-1996.
>>
>>
>>Uwe Ligges
>>
>>
>>
>>
>>
>>
>>>ago and I believe that data frame 
>>>subsetting was done in **very** similar manner as it is performed
>>>now.
>>>
>>>Cheers
>>>Petr
>>>
>>>
>>>
>>>>>Look at ?order.
>>>>
>>>>I know.  This is why I suggested only that we need a wrapper that
>>>>plugs an order() functionality into the sort() function (which
>>>>fortunately points in its docs to order)---but novices would find
>>>>the sort syntax easier.
>>>>
>>>>regards,
>>>>
>>>>/iaw
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide!
>>>>http://www.R-project.org/posting-guide.html
>>>
>>>
>>>Petr Pikal
>>>petr.pikal at precheza.cz
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>>http://www.R-project.org/posting-guide.html
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
> 
> 
> Petr Pikal
> petr.pikal at precheza.cz



From ligges at statistik.uni-dortmund.de  Tue Feb  7 09:22:27 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 07 Feb 2006 09:22:27 +0100
Subject: [R] install package in Mac
In-Reply-To: <d06710120602070008t3c85acdbn@mail.gmail.com>
References: <d06710120602070008t3c85acdbn@mail.gmail.com>
Message-ID: <43E858C3.2070403@statistik.uni-dortmund.de>

Rhett Eckstein wrote:

> Hi, all
> 
> I have problem about installing package (built in Windows) in Mac.
> 
> In the R for MacOS X FAQ, it mentioned that Mac required the
> 
> prebuilt package named as XXX.tgz.   However, the package built
> 
> under Windows named as XXX.zip.  So how should I do to let the
> 
> package (built in Windows) to install in Mac.


On Windows, build a source package (hence ending .tar.gz) and install 
this source package on the Mac. You cannot use Windows binary packages 
on the Mac.

Uwe Ligges


> Thanks in advance !!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Feb  7 09:23:23 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 07 Feb 2006 09:23:23 +0100
Subject: [R] cdf of multivariate normal
In-Reply-To: <000801c62b7b$e61b04e0$5be07d80@NIEHS.usc.edu>
References: <000801c62b7b$e61b04e0$5be07d80@NIEHS.usc.edu>
Message-ID: <43E858FB.3060704@statistik.uni-dortmund.de>

Juan Pablo Lewinger wrote:

> I was wondering if anybody has written R code to compute the cdf of a
> multivariate (or at least a bivariate) normal distribution with given
> covariance structure.

See ?pmvnorm in package "mvtnorm".

Uwe Ligges


> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Tue Feb  7 09:47:47 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 07 Feb 2006 09:47:47 +0100
Subject: [R] R loop
In-Reply-To: <43E8584E.3090408@statistik.uni-dortmund.de>
References: <43E85438.7457.4BBCAC@localhost> <43E86377.7065.874CB8@localhost>
	<43E8584E.3090408@statistik.uni-dortmund.de>
Message-ID: <x27j87eerw.fsf@turmalin.kubism.ku.dk>

Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:

> Petr Pikal wrote:
> 
> > Hi
> > 
> > you are correct as usually. It is about 10 versions 1.2.0 - 2.2.1 and 
> > as there are 2 versions per year it is about 4-5 years.

[That calculus only goes back to 2001, though, previous to that the
release rate was higher (and the numbering stranger). And it is of
course a coincidence that 2.0.0 followed 1.9.x.]

> > But nevertheless it seems to me as if I used R forever (and hopefully 
> > it will continue)
> > 
> > Anyway subsetting data frames **was** similar in the old versions as 
> > it is now, wasn't it?
> 
> Yes, AFAIR, and just tested in 1.2.2.

AFAIR, the current data frame code was adopted in late 1997 from the
code that John Chambers had donated to Statlib...

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From hvermei1 at vrcbe.jnj.com  Tue Feb  7 09:53:57 2006
From: hvermei1 at vrcbe.jnj.com (Vermeiren, Hans [VRCBE])
Date: Tue, 7 Feb 2006 09:53:57 +0100 
Subject: [R] panel.levelplot() for 2D histograms
Message-ID: <9AC105024CEA64458BF66D1DE13CA50D070FB4FB@tibbemeexs1.eu.jnj.com>



-----Original Message-----
From: Deepayan Sarkar [mailto:deepayan.sarkar at gmail.com]
Sent: Monday, February 06, 2006 9:52 PM
To: Vermeiren, Hans [VRCBE]
Cc: r-help at lists.R-project.org
Subject: Re: panel.levelplot() for 2D histograms


On 2/6/06, Vermeiren, Hans [VRCBE] <hvermei1 at vrcbe.jnj.com> wrote:
> Dear R-wizards,
> I'm trying to plot "binned scatterplots", or 2d histograms, if you wish,
for
> a number of groups by using the lattice functionality
> it works fine for one group at a time, and probably I could find a
> work-around, but I prefer to do it the elegant way
> here's an example of what I want, what I tried and where it goes wrong:

If you are doing this for fun, read on. Otherwise, I suggest that you
look at the hexbin package (available from bioconductor) for a better
solution. The development version (to be released after R 2.3.0)
already has a lattice-ified interface called 'hexbinplot'.

>>	for fun ? yes and no, I really need this for my job, but otoh,
working with R is always fun
>>	thanks a lot for the pointer to hexbin, that's really what I was
looking for, but i did read on and I'll try the grid.rect hint as well (just
for fun)
>>	thanks again,
	
>>	Hans



From bitwrit at ozemail.com.au  Wed Feb  8 02:51:46 2006
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Tue, 07 Feb 2006 20:51:46 -0500
Subject: [R] Scatterplot with corner at (0, 0)
Message-ID: <43E94EB2.8000203@ozemail.com.au>

Thomas L Jones wrote:
 >
 > I have two vectors, x and y, and I want to create a scatterplot. I
 > want the lower left corner to be at (0, 0). I can create a scatterplot
 > just by calling plot (x, y), but I am quite throroughly stymied and
 > frustrated by the problem of putting the lower left corner at (0, 0),
 > despite many tries.

plot(x,y,xlim=c(0,max(x)),ylim=c(0,max(y)),xaxs="i",yaxs="i")

You may want to leave a bit of extra room at the higher values either 
like this:

xlim=c(0,1.05*max(x))

or by using an arbitrary value that is above the maximum:

ylim=c(0,5)

Jim



From maechler at stat.math.ethz.ch  Tue Feb  7 11:59:08 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 7 Feb 2006 11:59:08 +0100
Subject: [R] prehistoric versions of R --> 1995!
In-Reply-To: <43E8529A.9040609@statistik.uni-dortmund.de>
References: <C00D2113.5401%sdavis2@mail.nih.gov>
	<43E85438.7457.4BBCAC@localhost>
	<43E8529A.9040609@statistik.uni-dortmund.de>
Message-ID: <17384.32124.247311.749610@stat.math.ethz.ch>

>>>>> "UweL" == Uwe Ligges <ligges at statistik.uni-dortmund.de>
>>>>>     on Tue, 07 Feb 2006 08:56:10 +0100 writes:

    UweL> Petr Pikal wrote:
    >> Hi
    >> 
    >> On 6 Feb 2006 at 15:57, ivo welch wrote:
    >> 
    >> Date sent:      	Mon, 6 Feb 2006 15:57:30 -0500
    >> From:           	ivo welch <ivowel at gmail.com>
    >> To:             	Sean Davis <sdavis2 at mail.nih.gov>
    >> Copies to:      	piet.vanremortel at gmail.com, r-help <r-help at stat.math.ethz.ch>
    >> Subject:        	Re: [R] R loop
    >> 
    >> 
    >>>>> data[ data$a == "name2" ]  # does not work and gives a weird
    >>>>> result,  yuck
    >>>> 
    >>>> data[data$a=="name2",]
    >>>> 
    >>> 
    >>> sorry about this.  I believe a few versions back, one could not subset
    >>> data frames, so I did not even check what I wrote.  Works now.
    >> 
    >> 
    >> It depends on what you consider few versions back. I started with R 
    >> vesion 1.2.0 about 10 years 

    UweL> I bet 200$ (or EUR) you have not used R 10 years ago. ;-)

    UweL> People certainly remember the 1.0.0 release at the remarkable day 
    UweL> 29-FEB-2000.
    UweL> 1.2.0 was released in December 2000, about 5 years ago.
    UweL> I started with 0.62.x in 1998.
    UweL> The oldest version I found on CRAN is a pre-alpha R.sea.hqx for the Mac 
    UweL> dated 07-Nov-1996.

Eehm; that has a wrong date (or then it would not be pre-alpha):
I've always entertained the prehistoric directory of R sources
at ftp://stat.ethz.ch/Software/R/alpha/PreHistoric/
and its oldest file is 
         Name	           Size    Date        
         R-0.1alpha.tar.gz 861464  Feb 12 1996 

(which will be 10 years coming Sunday -- what a jubilee!!)
So, even that is not pre-alpha; and yes, that was a bit before CRAN existed. 

Now to the pre-alpha history.  I've digged some more and found

1) that the mac file mentioned above would have
   correct date 'Nov 6 1995' (at least that's the date I saved
   when I looked at the Auckland FTP server through Emacs ange-ftp).

2) The oldest stuff that I have is all from 1995;
   The source I (think I) had first used is dated June 20 1995;
   notably the  R-unix-src.tar.gz with accompanying README and
   INSTALL files
   (There was also ./win subdirectory which I did not use, with
    files all from July 15, 1995; AFAIK done by Robert Gentleman)

 I've now put a bit of these oldest files into
  ftp://stat.ethz.ch/Software/R/alpha/PreHistoric/pre-alpha/

3) I've kept an e-mail that Ross had sent me on July 28 with
   two small patches to the (June 20) sources.
   
   Yes, chances are pretty high that I was the first one outside
   of the Auckland(NZ)-community to actively use R.
 
Note it might be interesting to find even older sources, but that
would most probably have to be by Robert and Ross (or a
sysadmin at Auckland).


Martin Maechler, ETH Zurich



From vince_bioinfo at yahoo.fr  Mon Feb  6 15:59:31 2006
From: vince_bioinfo at yahoo.fr (Vincent Negre)
Date: Mon, 6 Feb 2006 15:59:31 +0100 (CET)
Subject: [R]  qqplot
Message-ID: <20060206145931.86769.qmail@web26404.mail.ukl.yahoo.com>

Hello,
I would like to use qqplot() to compare two
experimental distributions. But I do not understand
how qqplot() compute quantiles. In fact, quantile() do
not return the same results.
Thank you for your help.
Vincent.



From murdoch at stats.uwo.ca  Tue Feb  7 13:18:10 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 07 Feb 2006 07:18:10 -0500
Subject: [R] qqplot
In-Reply-To: <20060206145931.86769.qmail@web26404.mail.ukl.yahoo.com>
References: <20060206145931.86769.qmail@web26404.mail.ukl.yahoo.com>
Message-ID: <43E89002.9010309@stats.uwo.ca>

On 2/6/2006 9:59 AM, Vincent Negre wrote:
> Hello,
> I would like to use qqplot() to compare two
> experimental distributions. But I do not understand
> how qqplot() compute quantiles. In fact, quantile() do
> not return the same results.

Take a look at the source code.  qqplot replaces the longer vector with 
one calculated by linear interpolation (that's what approx does) between 
the values of the other.

Duncan Murdoch



From Gautam.Bhola at pfizer.com  Tue Feb  7 13:32:40 2006
From: Gautam.Bhola at pfizer.com (Bhola, Gautam)
Date: Tue, 7 Feb 2006 07:32:40 -0500
Subject: [R] R-2.2.1-INSTALL Issue with TCLTK
Message-ID: <E04D0A5FF70E854582D33D93A880799B0399BFC2@groamrexm03.amer.pfizer.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060207/17733efa/attachment.pl

From marcodoc75 at yahoo.com  Tue Feb  7 13:50:10 2006
From: marcodoc75 at yahoo.com (Marco Geraci)
Date: Tue, 7 Feb 2006 04:50:10 -0800 (PST)
Subject: [R] cdf of multivariate normal
In-Reply-To: <000801c62b7b$e61b04e0$5be07d80@NIEHS.usc.edu>
Message-ID: <20060207125010.37643.qmail@web31313.mail.mud.yahoo.com>

Hi,
you can check ?pmvnorm in package 'mvtnorm'

Marco

--- Juan Pablo Lewinger <lewinger at usc.edu> wrote:

> I was wondering if anybody has written R code to
> compute the cdf of a
> multivariate (or at least a bivariate) normal
> distribution with given
> covariance structure.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From pinard at iro.umontreal.ca  Tue Feb  7 14:28:30 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Tue, 7 Feb 2006 08:28:30 -0500
Subject: [R] qqplot
In-Reply-To: <20060206145931.86769.qmail@web26404.mail.ukl.yahoo.com>
References: <20060206145931.86769.qmail@web26404.mail.ukl.yahoo.com>
Message-ID: <20060207132830.GA7132@phenix.sram.qc.ca>

[Vincent Negre]

>[...] I do not understand how qqplot() compute quantiles.

Just type ``qqplot`` (without the parentheses) at the R prompt, to see 
the source code.  ``qqplot`` does not especially compute quantiles, 
which are rather obtained directly through sorting its arguments.

-- 
Fran??ois Pinard   http://pinard.progiciels-bpi.ca



From dirk.debecker at biw.kuleuven.be  Tue Feb  7 14:38:43 2006
From: dirk.debecker at biw.kuleuven.be (Dirk De Becker)
Date: Tue, 07 Feb 2006 14:38:43 +0100
Subject: [R] Using R to process spectroscopic data
Message-ID: <43E8A2E3.7010100@biw.kuleuven.be>

Dear R-users,

I would like to process some spectroscopic data with R, and I was hoping 
some people might have some example code on how to do this.
I would like to be able to do the following things:
* Detect outlier-spectra -> This can be done by using scoreplot from the 
pls package
* Determine the range of the spectrum to be used -> For this, I should 
be able to calculate the regression coefficients
* Determine the optimal number of elements in a model
* Anything else that you guys think could be useful :-)

Any help is greatly appreciated

Dirk

-- 
Dirk De Becker
Work: Kasteelpark Arenberg 30
      3001 Heverlee
      phone: ++32(0)16/32.14.44
      fax: ++32(0)16/32.85.90
Home: Waversebaan 90
      3001 Heverlee
      phone: ++32(0)16/23.36.65
dirk.debecker at biw.kuleuven.be
mobile phone: ++32(0)498/51.19.86


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From Antonio_Paredes at aphis.usda.gov  Tue Feb  7 14:50:15 2006
From: Antonio_Paredes at aphis.usda.gov (Antonio_Paredes@aphis.usda.gov)
Date: Tue, 7 Feb 2006 07:50:15 -0600
Subject: [R] R- License
Message-ID: <OF85F52FE5.F47B1DAF-ON8625710E.004BD459-8625710E.004BC6B6@aphis.usda.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060207/ff7bf907/attachment.pl

From andywongcw at gmail.com  Tue Feb  7 14:52:03 2006
From: andywongcw at gmail.com (Andy Wong)
Date: Tue, 7 Feb 2006 21:52:03 +0800
Subject: [R] Application of R
Message-ID: <cafcabf80602070552p6ec38ba6xfc5aa7cb6a61f01c@mail.gmail.com>

I have applied the R and MNP to carry out the data analysis.  However, there
is an error called SWP : singular matrix.  Can someone tell me what is the
problem of my formula or the file "mydata".

I have attached the data file "mydata" in Excel format and the result
printed in pdf format for your information.

Thanks for your advice.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: result 20060207.pdf
Type: application/pdf
Size: 30153 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20060207/09bde74d/result20060207.pdf

From HDoran at air.org  Tue Feb  7 15:00:38 2006
From: HDoran at air.org (Doran, Harold)
Date: Tue, 7 Feb 2006 09:00:38 -0500
Subject: [R] R- License
Message-ID: <F5ED48890E2ACB468D0F3A64989D335A01ADEC3E@dc1ex3.air.org>

Type license() for this info

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
Antonio_Paredes at aphis.usda.gov
Sent: Tuesday, February 07, 2006 8:50 AM
To: r-help at stat.math.ethz.ch
Subject: [R] R- License

Hello. We are trying to install R on our network, and I wanted to ask if
there is a user license agreement. I will be grateful if somebody can
send me a link to it; if one exists.

Thank you very much



*******************************************
Antonio Paredes
USDA- Center for Veterinary Biologics
Biometrics Unit
510 South 17th Street, Suite 104
Ames, IA 50010
(515) 232-5785


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From Rau at demogr.mpg.de  Tue Feb  7 15:13:34 2006
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Tue, 7 Feb 2006 15:13:34 +0100
Subject: [R] R- License
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E6013DAF74@HERMES.demogr.mpg.de>

Hi,

> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Antonio_Paredes at aphis.usda.gov
> Subject: [R] R- License
> 
> Hello. We are trying to install R on our network, and I 
> wanted to ask if 
> there is a user license agreement. I will be grateful if 
> somebody can send 
> me a link to it; if one exists.


if you have it installed already (maybe on your own computer), you can
enter
licence()
or
license()

which should give you, hopefully, what you are looking for. If you
haven't installed it, I pasted the output below.
Hope this helps,
Roland

> licence()

This software is distributed under the terms of the GNU GENERAL
PUBLIC LICENSE Version 2, June 1991.  The terms of this license
are in a file called COPYING which you should have received with
this software.

If you have not received a copy of this file, you can obtain one
via WWW at http://www.gnu.org/copyleft/gpl.html, or by writing to:

   The Free Software Foundation, Inc.,
   59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.

A small number of files (the API header files and export files,
listed in R_HOME/COPYRIGHTS) are distributed under the
LESSER GNU GENERAL PUBLIC LICENSE version 2.1.
This can be obtained via WWW at
http://www.gnu.org/copyleft/lgpl.html, or by writing to the
address above

``Share and Enjoy.''

+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From Roger.Bivand at nhh.no  Tue Feb  7 15:23:11 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 7 Feb 2006 15:23:11 +0100 (CET)
Subject: [R] R- License
In-Reply-To: <OF85F52FE5.F47B1DAF-ON8625710E.004BD459-8625710E.004BC6B6@aphis.usda.gov>
Message-ID: <Pine.LNX.4.44.0602071514570.5276-100000@reclus.nhh.no>

On Tue, 7 Feb 2006 Antonio_Paredes at aphis.usda.gov wrote:

> Hello. We are trying to install R on our network, and I wanted to ask if 
> there is a user license agreement. I will be grateful if somebody can send 
> me a link to it; if one exists.

In addition to license() from an installed R, you can link through:

http://www.r-project.org/about.html

to:

http://www.r-project.org/COPYING

The same information is in the FAQ:

http://cran.r-project.org/doc/FAQ/R-FAQ.html#What-is-R_003f

Please also note:

http://www.r-project.org/foundation/main.html

> 
> Thank you very much
> 
> 
> 
> *******************************************
> Antonio Paredes
> USDA- Center for Veterinary Biologics
> Biometrics Unit
> 510 South 17th Street, Suite 104
> Ames, IA 50010
> (515) 232-5785
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From amsa36060 at yahoo.com  Tue Feb  7 15:24:20 2006
From: amsa36060 at yahoo.com (Amir Safari)
Date: Tue, 7 Feb 2006 06:24:20 -0800 (PST)
Subject: [R] Prediction method for lowess,loess,lokerns,lpepa,ksmooth
Message-ID: <20060207142420.99529.qmail@web60419.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060207/94605acb/attachment.pl

From gavin.simpson at ucl.ac.uk  Tue Feb  7 16:04:08 2006
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 07 Feb 2006 15:04:08 +0000
Subject: [R] Prediction method for lowess,loess,lokerns,lpepa,ksmooth
In-Reply-To: <20060207142420.99529.qmail@web60419.mail.yahoo.com>
References: <20060207142420.99529.qmail@web60419.mail.yahoo.com>
Message-ID: <1139324649.25255.45.camel@gsimpson.geog.ucl.ac.uk>

On Tue, 2006-02-07 at 06:24 -0800, Amir Safari wrote:
>   
>   Hi Every Body,
>   I don't know why some regression functions have no related
> prediction  function. For example lowess, loess, lokerns, lpridge,
> lpepa, and  ksmooth.
>   What could help? Is there any global or wrapper function so that can
> help?
>   Regards,
>   Amir Safari

loess() /does/ have a predict method [7]:

> methods("predict")
 [1] predict.ar*                predict.Arima*
 [3] predict.arima0*            predict.glm
 [5] predict.HoltWinters*       predict.lm
 [7] predict.loess*             predict.mlm
 [9] predict.nls*               predict.poly
[11] predict.ppr*               predict.prcomp*
[13] predict.princomp*          predict.smooth.spline*
[15] predict.smooth.spline.fit* predict.StructTS*

   Non-visible functions are asterisked

The other functions (except ksmooth) I can't find in base R 2.2.1-
patched, so they are likely from contributed packages. As such, you
should contact the package maintainers for help, to make a feature
request, or offer your help in writing predict methods for these
functions.

?ksmooth states:

Note:

     This function is implemented purely for compatibility with S,
     although it is nowhere near as slow as the S function. Better
     kernel smoothers are available in other packages.

So perhaps you could look in the contributed packages section of the
CRAN website for something that meets your needs?

HTH

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From f.harrell at vanderbilt.edu  Tue Feb  7 16:10:11 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 07 Feb 2006 09:10:11 -0600
Subject: [R] Prediction method for lowess,loess,lokerns,lpepa,ksmooth
In-Reply-To: <20060207142420.99529.qmail@web60419.mail.yahoo.com>
References: <20060207142420.99529.qmail@web60419.mail.yahoo.com>
Message-ID: <43E8B853.2060007@vanderbilt.edu>

Amir Safari wrote:
>   
>   Hi Every Body,
>   I don't know why some regression functions have no related prediction  function. For example lowess, loess, lokerns, lpridge, lpepa, and  ksmooth.
>   What could help? Is there any global or wrapper function so that can help?
>   Regards,
>   Amir Safari
>   
> 			
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

This is somewhat related to what you want.  In the Hmisc package look at 
the areg.boot function.

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From Antigen_PEGASUS at cug1.umt.edu  Tue Feb  7 16:07:34 2006
From: Antigen_PEGASUS at cug1.umt.edu (Antigen_PEGASUS@cug1.umt.edu)
Date: 7 Feb 2006 08:07:34 -0700
Subject: [R] Antigen forwarded attachment
Message-ID: <PEGASUSyki4jsGvs0Qz00000146@pegasus.cfc.umt.edu>

The entire message "[R] install package in Mac", originally sent to you by r-help-bounces at stat.math.ethz.ch (r-help-bounces at stat.math.ethz.ch), has been forwarded to you from the Antigen Quarantine area.
This message may have been re-scanned by Antigen and handled according to the appropriate scan job's settings.



<<Entire Message.eml>>
-------------- next part --------------
An embedded message was scrubbed...
From: Rhett Eckstein <glaxowell at gmail.com>
Subject: [R] install package in Mac
Date: Tue, 7 Feb 2006 16:08:57 +0800
Size: 4372
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060207/a74ed8ce/attachment.mht

From Antigen_PEGASUS at cug1.umt.edu  Tue Feb  7 16:07:34 2006
From: Antigen_PEGASUS at cug1.umt.edu (Antigen_PEGASUS@cug1.umt.edu)
Date: 7 Feb 2006 08:07:34 -0700
Subject: [R] Antigen forwarded attachment
Message-ID: <PEGASUSfud7bqV0tpw400000147@pegasus.cfc.umt.edu>

The entire message "Re: [R] install package in Mac", originally sent to you by r-help-bounces at stat.math.ethz.ch (r-help-bounces at stat.math.ethz.ch), has been forwarded to you from the Antigen Quarantine area.
This message may have been re-scanned by Antigen and handled according to the appropriate scan job's settings.



<<Entire Message.eml>>
-------------- next part --------------
An embedded message was scrubbed...
From: Uwe Ligges <ligges at statistik.uni-dortmund.de>
Subject: Re: [R] install package in Mac
Date: Tue, 07 Feb 2006 09:22:27 +0100
Size: 5028
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060207/738b0bfe/attachment.mht

From ripley at stats.ox.ac.uk  Tue Feb  7 17:07:39 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 7 Feb 2006 16:07:39 +0000 (GMT)
Subject: [R] Prediction method for lowess,loess,lokerns,lpepa,ksmooth
In-Reply-To: <1139324649.25255.45.camel@gsimpson.geog.ucl.ac.uk>
References: <20060207142420.99529.qmail@web60419.mail.yahoo.com>
	<1139324649.25255.45.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <Pine.LNX.4.61.0602071603520.13665@gannet.stats>

On Tue, 7 Feb 2006, Gavin Simpson wrote:

> On Tue, 2006-02-07 at 06:24 -0800, Amir Safari wrote:
>>
>>   Hi Every Body,
>>   I don't know why some regression functions have no related
>> prediction  function. For example lowess, loess, lokerns, lpridge,
>> lpepa, and  ksmooth.
>>   What could help? Is there any global or wrapper function so that can
>> help?
>>   Regards,
>>   Amir Safari
>
> loess() /does/ have a predict method [7]:
>
>> methods("predict")
> [1] predict.ar*                predict.Arima*
> [3] predict.arima0*            predict.glm
> [5] predict.HoltWinters*       predict.lm
> [7] predict.loess*             predict.mlm
> [9] predict.nls*               predict.poly
> [11] predict.ppr*               predict.prcomp*
> [13] predict.princomp*          predict.smooth.spline*
> [15] predict.smooth.spline.fit* predict.StructTS*
>
>   Non-visible functions are asterisked
>
> The other functions (except ksmooth) I can't find in base R 2.2.1-
> patched, so they are likely from contributed packages. As such, you
> should contact the package maintainers for help, to make a feature
> request, or offer your help in writing predict methods for these
> functions.
>
> ?ksmooth states:
>
> Note:
>
>     This function is implemented purely for compatibility with S,
>     although it is nowhere near as slow as the S function. Better
>     kernel smoothers are available in other packages.
>
> So perhaps you could look in the contributed packages section of the
> CRAN website for something that meets your needs?

However, the _only_ thing kernel smoothing does is prediction. As in

  range.x: the range of points to be covered in the output.

n.points: the number of points at which to evaluate the fit.

x.points: points at which to evaluate the smoothed fit. If missing,
           'n.points' are chosen uniformly to cover 'range.x'.

I would suggest rather using packages KernSmooth (ships with R) or sm.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rlevy at inf.ed.ac.uk  Tue Feb  7 17:11:03 2006
From: rlevy at inf.ed.ac.uk (Roger Levy)
Date: Tue, 07 Feb 2006 16:11:03 +0000
Subject: [R] displaying Cyrillic in RGui under Windows
Message-ID: <43E8C697.20004@inf.ed.ac.uk>

I have a data frame with Cyrillic text that I would like to be able to 
view under RGui.  Unfortunately I can't figure out from the manuals how 
to make this happen -- can someone point me in the right direction?

Thanks,

Roger Levy



From michael.coeurdassier at univ-fcomte.fr  Tue Feb  7 17:16:41 2006
From: michael.coeurdassier at univ-fcomte.fr (=?ISO-8859-1?Q?Micha=EBl_Coeurdassier?=)
Date: Tue, 07 Feb 2006 17:16:41 +0100
Subject: [R] post-hoc comparisons following glmm
Message-ID: <43E8C7E9.4080000@univ-fcomte.fr>

Dear R community,

I performed a generalized linear mixed model using glmmPQL (MASS 
library) to analyse my data i.e : y is the response with a poisson 
distribution, t and Trait are the independent variables which are 
continuous and categorical (3 categories C, M and F) respectively, ind 
is the random variable.

mydata<-glmmPQL(y~t+Trait,random=~1|ind,family=poisson,data=tab)
Do you think it is OK?

Trait is significant (p < 0.0001) and I would like to perform post-hoc 
comparisons  to check  where the difference among  Trait categories but 
I did not find  a solution  in R help list or others.

Thank you in advance for your help

Michael



From laura at env.leeds.ac.uk  Tue Feb  7 17:23:59 2006
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Tue, 7 Feb 2006 16:23:59 +0000 (GMT)
Subject: [R] symbol() function in 3d
Message-ID: <Pine.LNX.4.44.0602071620510.527-100000@gw.env.leeds.ac.uk>

Hello,

I was wondering if there is anything within the 3d rgl library that is
similar to the symbol() function? I am hoping to overlay a surface3d()
plot with some circles of varying size/color. I tried using the points3d()
function, but this only allows me to add circles all of the same size.

Thanks,
Laura

Laura Quinn
Institute of Atmospheric Science
School of Earth and Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk



From ripley at stats.ox.ac.uk  Tue Feb  7 17:46:30 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 7 Feb 2006 16:46:30 +0000 (GMT)
Subject: [R] displaying Cyrillic in RGui under Windows
In-Reply-To: <43E8C697.20004@inf.ed.ac.uk>
References: <43E8C697.20004@inf.ed.ac.uk>
Message-ID: <Pine.LNX.4.61.0602071643190.14207@gannet.stats>

On Tue, 7 Feb 2006, Roger Levy wrote:

> I have a data frame with Cyrillic text that I would like to be able to
> view under RGui.  Unfortunately I can't figure out from the manuals how
> to make this happen -- can someone point me in the right direction?

You can only do this if you run RGui in a Cyrillic locale.  Unfortunately 
there are several incompatible Cyrillic encodings, so let's hope this is 
the Windows one.  If so, set Windows to Russian as per the rw-FAQ, select 
LANGUAGE=en and it should work.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pgilbert at bank-banque-canada.ca  Tue Feb  7 17:53:00 2006
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Tue, 07 Feb 2006 11:53:00 -0500
Subject: [R] prehistoric versions of R --> 1995!
In-Reply-To: <17384.32124.247311.749610@stat.math.ethz.ch>
References: <C00D2113.5401%sdavis2@mail.nih.gov>	<43E85438.7457.4BBCAC@localhost>	<43E8529A.9040609@statistik.uni-dortmund.de>
	<17384.32124.247311.749610@stat.math.ethz.ch>
Message-ID: <43E8D06C.9020407@bank-banque-canada.ca>



Martin Maechler wrote:

>>>>>>"UweL" == Uwe Ligges <ligges at statistik.uni-dortmund.de>
>>>>>>    on Tue, 07 Feb 2006 08:56:10 +0100 writes:
>>>>>>            
>>>>>>
>
>    UweL> Petr Pikal wrote:
>    >> Hi
>    >> 
>    >> On 6 Feb 2006 at 15:57, ivo welch wrote:
>    >> 
>    >> Date sent:      	Mon, 6 Feb 2006 15:57:30 -0500
>    >> From:           	ivo welch <ivowel at gmail.com>
>    >> To:             	Sean Davis <sdavis2 at mail.nih.gov>
>    >> Copies to:      	piet.vanremortel at gmail.com, r-help <r-help at stat.math.ethz.ch>
>    >> Subject:        	Re: [R] R loop
>    >> 
>    >> 
>    >>>>> data[ data$a == "name2" ]  # does not work and gives a weird
>    >>>>> result,  yuck
>    >>>> 
>    >>>> data[data$a=="name2",]
>    >>>> 
>    >>> 
>    >>> sorry about this.  I believe a few versions back, one could not subset
>    >>> data frames, so I did not even check what I wrote.  Works now.
>    >> 
>    >> 
>    >> It depends on what you consider few versions back. I started with R 
>    >> vesion 1.2.0 about 10 years 
>
>    UweL> I bet 200$ (or EUR) you have not used R 10 years ago. ;-)
>  
>
Is that an open bet or just for Petr?

>    UweL> People certainly remember the 1.0.0 release at the remarkable day 
>    UweL> 29-FEB-2000.
>    UweL> 1.2.0 was released in December 2000, about 5 years ago.
>    UweL> I started with 0.62.x in 1998.
>    UweL> The oldest version I found on CRAN is a pre-alpha R.sea.hqx for the Mac 
>    UweL> dated 07-Nov-1996.
>
>Eehm; that has a wrong date (or then it would not be pre-alpha):
>I've always entertained the prehistoric directory of R sources
>at ftp://stat.ethz.ch/Software/R/alpha/PreHistoric/
>and its oldest file is 
>         Name	           Size    Date        
>         R-0.1alpha.tar.gz 861464  Feb 12 1996 
>  
>
I'm pretty sure I was using R 0.16 in the fall of 1996 on Linux, which 
was when I got dse largely converted from S. I had a slightly  earlier 
version in the spring of 1996 on Solaris. (I think the numbering would 
have been 0.11 -0.15 in the spring of 1996.)  I don't think the 
numbering was the same on other platforms.

>(which will be 10 years coming Sunday -- what a jubilee!!)
>So, even that is not pre-alpha; and yes, that was a bit before CRAN existed. 
>
>Now to the pre-alpha history.  I've digged some more and found
>
>1) that the mac file mentioned above would have
>   correct date 'Nov 6 1995' (at least that's the date I saved
>   when I looked at the Auckland FTP server through Emacs ange-ftp).
>
>2) The oldest stuff that I have is all from 1995;
>   The source I (think I) had first used is dated June 20 1995;
>   notably the  R-unix-src.tar.gz with accompanying README and
>   INSTALL files
>   (There was also ./win subdirectory which I did not use, with
>    files all from July 15, 1995; AFAIK done by Robert Gentleman)
>
> I've now put a bit of these oldest files into
>  ftp://stat.ethz.ch/Software/R/alpha/PreHistoric/pre-alpha/
>
>3) I've kept an e-mail that Ross had sent me on July 28 with
>   two small patches to the (June 20) sources.
>   
>   Yes, chances are pretty high that I was the first one outside
>   of the Auckland(NZ)-community to actively use R.
>  
>
I wouldn't be really sure of that (but it's a fair bet).

> 
>Note it might be interesting to find even older sources, but that
>would most probably have to be by Robert and Ross (or a
>sysadmin at Auckland).
>  
>
I used to have some floppy disks somewhere...

Paul Gilbert

>
>Martin Maechler, ETH Zurich
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>
====================================================================================

La version fran??aise suit le texte anglais.

------------------------------------------------------------------------------------

This email message from the Bank of Canada is given in good faith, and shall not be
binding or construed as constituting any obligation on the part of the Bank.

This email may contain privileged and/or confidential inform...{{dropped}}



From sell_mirage_ne at hotmail.com  Tue Feb  7 18:03:14 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Tue, 07 Feb 2006 11:03:14 -0600
Subject: [R] (second round) creating a certain type of matrix
Message-ID: <BAY110-F325D0A435A24692F05365C7010@phx.gbl>


Hi R users
Here is what I got with help from Petr Pikal (Thanks Petr Pikal). I modified 
Petr Pikal's code to a little
to meet my purpose.

I created a function to generate a matrix

generate.matrix<-function(n.variable)
{
mat<-matrix(0,n.variable,(n.variable/2)/5+1) #matrix of zeroes
dd<-dim(mat) # actual dimensions
mat[1:(dd[1]/2),1]<-1 #put 1 in first half of first column
mat[((dd[1]/2)+1):dd[1],1]<-rnorm(dd[1]/2,0,1) #put random numbers in 
following part of the matrix column 1
mat[((dd[1]/2)+1):((dd[1]/2)+5),2]<-rnorm(5,0,1) #put random numbers in 
column2
for (i in 3:(dd[2]))
    {
        length.of.rand.numbers <- 5
        my.rand.num<- rnorm(length.of.rand.numbers, 0,1)
        start <- dd[1]/2+5*(i-2)+1
        end <- start + length.of.rand.numbers-1
        mat[((start):end), i]<- my.rand.num
    }
mat
}

Do you (any R users) have any suggestion to this function to make this 
function work better or efficiently?

Taka
It works but I

>From: "Petr Pikal" <petr.pikal at precheza.cz>
>To: "Taka Matzmoto" <sell_mirage_ne at hotmail.com>,r-help at stat.math.ethz.ch
>Subject: Re: [R] creating a certain type of matrix
>Date: Tue, 07 Feb 2006 08:58:59 +0100
>MIME-Version: 1.0
>Received: from mail.precheza.cz ([80.188.29.243]) by 
>bay0-mc8-f13.bay0.hotmail.com with Microsoft SMTPSVC(6.0.3790.211); Mon, 6 
>Feb 2006 23:59:02 -0800
>Received: from localhost (localhost [127.0.0.1])by mail.precheza.cz 
>(Mailer) with ESMTP id A636C34E584;Tue,  7 Feb 2006 08:59:00 +0100 (CET)
>Received: from mail.precheza.cz ([127.0.0.1])by localhost (mail.precheza.cz 
>[127.0.0.1]) (amavisd-new, port 10024)with LMTP id 28608-02-30; Tue, 7 Feb 
>2006 08:58:59 +0100 (CET)
>Received: from n1en1.precheza.cz (smtp.precheza.cz [192.168.210.31])by 
>mail.precheza.cz (Mailer) with ESMTP id 35E8634E582;Tue,  7 Feb 2006 
>08:58:59 +0100 (CET)
>Received: from pikal ([192.168.210.65])          by n1en1.precheza.cz 
>(Lotus Domino Release 6.5.4FP2)          with ESMTP id 2006020708585800-252 
>;          Tue, 7 Feb 2006 08:58:58 +0100 X-Message-Info: 
>JGTYoYF78jEHjJx36Oi8+Z3TmmkSEdPtfpLB7P/ybN8=
>X-Confirm-Reading-To: "Petr Pikal" <petr.pikal at precheza.cz>
>X-pmrqc: 1
>Return-Receipt-To: "Petr Pikal" <petr.pikal at precheza.cz>
>Priority: normal
>X-mailer: Pegasus Mail for Windows (4.21c)
>X-MIMETrack: Itemize by SMTP Server on SRVDomino/PRECHEZA(Release 6.5.4FP2 
>| September 26, 2005) at 07.02.2006 08:58:58,Serialize by Router on 
>SRVDomino/PRECHEZA(Release 6.5.4FP2 | September 26, 2005) at 07.02.2006 
>08:58:58,Serialize complete at 07.02.2006 08:58:58
>X-Virus-Scanned: by amavisd-new-20030616-p10 (Debian) at precheza.cz
>Return-Path: petr.pikal at precheza.cz
>X-OriginalArrivalTime: 07 Feb 2006 07:59:03.0289 (UTC) 
>FILETIME=[5C87D690:01C62BBC]
>
>Hi
>
>as only you know perfectly which halves and other portions of your
>matrices contain zeroes and which contain random numbers you has to
>finalize the function yourself.
>Here are few ideas.
>
>n<-20
>mat<-matrix(0,n,(n/2)/5+1) #matrix of zeroes
>dd<-dim(mat) # actual dimensions
>mat[1:(dd[1]/2),1]<-1 #put 1 in first half of first column
>mat[((dd[1]/2)+1):dd[1],1]<-rnorm(dd[1]/2,0,1) #put random numbers in
>following part of the matrix column 1
>mat[((dd[1]/2)+1):(dd[1]/2)+dd[1]/4,2]<-rnorm(dd[1]/4,0,1) #put
>random numbers in column2
>
>than according to n and dd values you can put any numbers anywhere in
>your matrix e.g. in for loop (not.tested :-)
>
>for (i in 3:dd[2]) {
>
>arrange everything into following desired columns
>e.g.
>
>length.of.rand.numbers <- (i-2)*5
>my.rand.num<- rnorm(length.of.rand.numbers, 0,1)
>start <- dd[1]/2+dd[1]/4
>end <- start + length.of.rand.numbers
>mat[start:end, i]<- my.rand.num
>
>}
>
>HTH
>Petr
>
>On 7 Feb 2006 at 0:07, Taka Matzmoto wrote:
>
>From:           	"Taka Matzmoto" <sell_mirage_ne at hotmail.com>
>To:             	r-help at stat.math.ethz.ch
>Date sent:      	Tue, 07 Feb 2006 00:07:11 -0600
>Subject:        	[R] creating a certain type of matrix
>
> > Hi R users
> >
> > I like to generate a certain type of  matrix.
> > If there are 10 variables, the matrix will have nrow=10,
> > ncol=((10/2))/5+1. so the resulting matrix's dimension 10 by 2. If
> > there are 50 variables the dimension of the resulting matrix will be
> > 50 by 6.
> >
> > The arrangement of elements of this matrix is important to me and I
> > can't figure out how to arrange elements.
> >
> > If I have 20 variables. The resulting matrix will be 20 by 3
> > The first half of first column of the matrix will be 1s. The all
> > elements on the second half of the first column of the matrix will be
> > random numbers coming from rnorm(1,0,1). The first half of the second
> > column of the matrix will be zeros. The first five elements of the
> > second half of the second column of the matrix will be random numbers
> > coming from rnorm(1,0,1). After that, the remaining elements of the
> > second half will be zeros. The first half of the third column of the
> > matrix will be zeors. The first five elements of the second half of
> > the third column will be zeros too and then 5 random numbers coming
> > from rnorm(1,0,1).
> >
> > If there are 40 variables the resulting matrix will be 40*5
> > The first half of first column of the matrix will be 1s. The all
> > elements on the second half of the first column of the matrix will be
> > random numbers coming from rnorm(1,0,1).
> >
> > The first half of the second column of the matrix will be zeros. The
> > first five elements of the second half of the second column of the
> > matrix will be random numbers coming from rnorm(1,0,1). After that,
> > the remaining elements of the second half will be zeros.
> >
> > The first half of the third column of the matrix will be zeors. The
> > first FIVE elements of the second half of the third column will be
> > zeros too and then 5 random numbers coming from rnorm(1,0,1) and then
> > the rest of elements of the third column will be zeros.
> >
> > The first half of the fourth column of the matrix will be zeors.The
> > first TEN elements of the second half of the fourth column will be
> > zeros too and then 5 random numbers coming from rnorm(1,0,1) and then
> > the rest of elements of the third column will be zeros.
> >
> > The first half of the fifth column of the matrix will be zeors.The
> > first FIFTEEN elements of the second half of the fourth column will be
> > zeros too and then 5 random numbers coming from rnorm(1,0,1).
> >
> > I tried to create 10 different functions ( one for 10, 20, 30, 40,
> > .... , 100 variables) but it's not efficient.
> >
> > Any help or advice for creating one function that can do all 10 kind
> > of variable cases would be appreciated.
> >
> > Thans in advance
> >
> > Taka
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
>
>Petr Pikal
>petr.pikal at precheza.cz
>



From cg.pettersson at evp.slu.se  Tue Feb  7 18:15:08 2006
From: cg.pettersson at evp.slu.se (CG Pettersson)
Date: Tue, 7 Feb 2006 18:15:08 +0100 (CET)
Subject: [R] Start problem after package update
Message-ID: <38911.62.119.38.100.1139332508.squirrel@webmail.slu.se>

Hello all!

R2.2.1, W2k.

When I used "update.packages()" today, R wanted to update VR, cluster and
nlme packages. I did so using the Danish mirror.

Everything worked as usual during update, but after closing R and trying
to restart I got an error message saying that the .Rdata could not be
restored.

Re-installing from my downloaded .exe file cured this, but what happened
and what package could have caused the problem?

/CG


-- 
CG Pettersson, MSci, PhD Stud.
Swedish University of Agricultural Sciences (SLU)
Dep. of Crop Production Ekology. Box 7043.
SE-750 07 Uppsala, Sweden
cg.pettersson at vpe.slu.se



From gavin.simpson at ucl.ac.uk  Tue Feb  7 18:21:35 2006
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 07 Feb 2006 17:21:35 +0000
Subject: [R] symbol() function in 3d
In-Reply-To: <Pine.LNX.4.44.0602071620510.527-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0602071620510.527-100000@gw.env.leeds.ac.uk>
Message-ID: <1139332895.25255.57.camel@gsimpson.geog.ucl.ac.uk>

On Tue, 2006-02-07 at 16:23 +0000, Laura Quinn wrote:
> Hello,
> 
> I was wondering if there is anything within the 3d rgl library that is
> similar to the symbol() function? I am hoping to overlay a surface3d()
> plot with some circles of varying size/color. I tried using the points3d()
> function, but this only allows me to add circles all of the same size.
> 
> Thanks,
> Laura

Hi Laura,

Are spheres OK rather than circles? If so, then will the following
work?:

x <- rnorm(12)
y <- rnorm(12)
z <- rnorm(12)
rgl.open()
spheres3d(x,y,z, radius = 1:12 * 0.05, color = colors()[1:12])

the color argument is described in ?rgl.material where unfortunately the
size argument can not be a vector our you could have used that with
points3d() to achieve what you wanted.

Example with surface from ?surface3d

data(volcano)
z <- 2 * volcano        # Exaggerate the relief
x <- 10 * (1:nrow(z))   # 10 meter spacing (S to N)
y <- 10 * (1:ncol(z))   # 10 meter spacing (E to W)
zlim <- range(y)
zlen <- zlim[2] - zlim[1] + 1
colorlut <- terrain.colors(zlen) # height color lookup table
col <- colorlut[ z-zlim[1]+1 ] # assign colors to heights for each point
rgl.clear()
surface3d(x, y, z, color=col, back="lines")
## choose some co-ords
samp <- sample(seq(along = y), 20)
## draw the spheres
spheres3d(x[samp], y[samp], z[samp] * 1.75, radius = 1:20 * 2,
            color = colors()[samp])

HTH

G

> 
> Laura Quinn
> Institute of Atmospheric Science
> School of Earth and Environment
> University of Leeds
> Leeds
> LS2 9JT
> 
> tel: +44 113 343 1596
> fax: +44 113 343 6716
> mail: laura at env.leeds.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From atcdias at biologia.ufrj.br  Tue Feb  7 18:27:59 2006
From: atcdias at biologia.ufrj.br (andre tavares correa dias)
Date: Tue, 7 Feb 2006 14:27:59 -0300
Subject: [R] elements from 'sem' function
Message-ID: <20060207172616.M28837@biologia.ufrj.br>

Hi, 
I would like to print elements from sem (structural equation modeling) 
function (e.g., model-reproduced covariance matrix (C); estimated asymptotic 
covariance matrix of parameter estimates (cov)). 

How can I  do this? 

Thanks, 
Andr?? 

--
Andr?? Tavares Corr??a Dias
Laborat??rio de Ecologia Vegetal
Universidade Federal do Rio de Janeiro
CCS-IB-Departamento de Ecologia
Caixa Postal 68020
21941-970 Rio de Janeiro ? RJ, Brazil
tel: +55 21 25626377
Fax: + 55 21 25626320
atcdias at biologia.ufrj.br



From www.brook at gmail.com  Tue Feb  7 18:35:59 2006
From: www.brook at gmail.com (www.brook@gmail)
Date: Tue, 7 Feb 2006 12:35:59 -0500
Subject: [R] question about binary data file and data.frame
Message-ID: <43e8da80.09f43e94.444a.54f7@mx.gmail.com>

I have a binary file with data sequence in the order

[age,weight][age,weight] ....

I know the length of the data and I want to load it into a data.frame. of course a way to do this is to 
read age and weight seperately and then use cbin(age,weight) to combine them into a dataframe, but is there a better
solution?

Thanks in advance!



From m_osm at gmx.net  Tue Feb  7 18:41:01 2006
From: m_osm at gmx.net (Mahdi Osman)
Date: Tue, 7 Feb 2006 18:41:01 +0100 (MET)
Subject: [R] lme question
Message-ID: <19409.1139334061@www018.gmx.net>

Hi list,


I am fitting microarray data (intensity) model using the lme package in R
environment. I have 5 fixed variables in the model. One of the fixed
variables is genes. I am trying to get p-values for  different genes. But I
am getting only one p-value for all genes together. I can get a list of
p-value when I run lm. Why can't this work in lme?


I was wondering if some one can help me solve this problem. That is getting
a list of p-value for each gene in the model using the lme.


Thanks in advance for your help


Regards



Mahdi

-- 
-----------------------------------
Mahdi Osman (PhD)
E-mail: m_osm at gmx.net
-----------------------------------

DSL-Aktion wegen groer Nachfrage bis 28.2.2006 verlngert:
GMX DSL-Flatrate 1 Jahr kostenlos* http://www.gmx.net/de/go/dsl



From adi at roda.ro  Tue Feb  7 17:09:02 2006
From: adi at roda.ro (Adrian DUSA)
Date: Tue, 7 Feb 2006 18:09:02 +0200
Subject: [R] [R-pkgs] new package QCA
Message-ID: <200602071809.02167.adi@roda.ro>


Dear list members,

I am pleased to let you know that R met with QCA - Qualitative Comparative 
Analysis.
This package has a few functions that implement the Quine-McCluskey algorithm, 
adapted to social sciences by Charles Ragin (as describes in his book from 
1987 "The Comparative Method").
Future versions of this package will have more functions to address the 
fuzzy-set minimization problems, as well.

Big thanks to the r-help list members, supportive as ever, especially to Gabor 
Grothendieck and Martin Maechler for excellent ideas in the key parts of the 
algorithm.

-- 
Adrian DUSA
Romanian Social Data Archive
1, Schitu Magureanu Bd
050025 Bucharest sector 5
Romania
Tel./Fax: +40 21 3126618 \
          +40 21 3120210 / int.101

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From spencer.graves at pdf.com  Tue Feb  7 19:01:30 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 07 Feb 2006 10:01:30 -0800
Subject: [R] Significance of degrees of freedom in nlme
In-Reply-To: <20060202132513.22628.qmail@web37103.mail.mud.yahoo.com>
References: <20060202132513.22628.qmail@web37103.mail.mud.yahoo.com>
Message-ID: <43E8E07A.1010103@pdf.com>

	  Your question begins, "Dear Dr. Bates", yet Bates does not appear as 
an addressee in the copy of your question that I recieved via r-help.  I 
will offer a couple of suggestions in the hopes that they might help 
you.  Since your question did not include enough detail for anyone to 
answer without additional information, I used 'RSiteSearch("gabriela 
escati pe??aloza")' to find earlier posts that might be related.  This 
generated 14 hits, the most relevant of which seemed to be 
"http://finzi.psych.upenn.edu/R/Rhelp02a/archive/69466.html".  From 
this, I copy the following:  	

formula(my data.gd)
dLt ~ Lt | ID
TasavB<- function(Lt, Linf, K) (K*(Linf-Lt))
my model.nlme <- nlme (dLt ~ TasavB(Lt, Linf, K),
data = my data.gd,
fixed = list(Linf ~ 1, K ~ 1),
start = list(fixed = c(70, 0.4)),
na.action= na.include, naPattern = ~!is.na(dLt))

	  I assume something got garbled here, because constructs like "my 
data.gd" generate a 'syntax error' for me;  I therefore assume it is 
"my_data.gd" (with an underscore between "my" and "data.gd".)  Try the 
following:

sapply(my_data.gd, class)

	  What columns of my_data.gd are factors, and how do they relate to 
Linf and K?  You can explore this using "table".

	  If you would like more help from this listserve, please submit 
another post.  Before you do, however, PLEASE do read the posting guide! 
"www.R-project.org/posting-guide.html", and try some of the things 
suggested there.  In particular, if you haven't already, try RSiteSearch 
for "nlme degrees of freedom" and anything else that seems relevant to 
you.  Also, before your next post, I encourage you to try to develop the 
simplest, self-contained example that illustrates your question.  I 
believe you will more likely receive faster, more useful replies if you 
make it easier for people to help you.

	  hope this helps,
	  spencer graves

gabriela escati pe??aloza wrote:

> Dear Dr. Bates,
> Thank you very much for your response. I had consulted
> the algorithm described in Pinheiro and Bates.
> However, what I don't understand (among other things)
> is why my two parameters appear to be estimated at
> different grouping levels (based on the DF values).
> Affect this different values of DF at the estimates
> parameters? The estimates fixed effects were get at
> the same level of grouping?
> I apreciate any response.
> 
> 
> 
> 
> Lic. Gabriela Escati Pe??aloza
> Biolog??a y Manejo de Recursos Acu??ticos
> Centro Nacional Patag??nico(CENPAT). 
> CONICET
> Bvd. Brown s/n??.
> (U9120ACV)Pto. Madryn 
> Chubut
> Argentina
> 
> Tel: 54-2965/451301/451024/451375/45401 (Int:277)
> Fax: 54-29657451543
> 
> 
> 	
> 
> 
> 	
> 		
> ___________________________________________________________ 
> 1GB gratis, Antivirus y Antispam 
> Correo Yahoo!, el mejor correo web del mundo 
> http://correo.yahoo.com.ar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From B.Rowlingson at lancaster.ac.uk  Tue Feb  7 19:03:17 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 07 Feb 2006 18:03:17 +0000
Subject: [R] question about binary data file and data.frame
In-Reply-To: <43e8da80.09f43e94.444a.54f7@mx.gmail.com>
References: <43e8da80.09f43e94.444a.54f7@mx.gmail.com>
Message-ID: <43E8E0E5.5090705@lancaster.ac.uk>

www.brook at gmail wrote:
> I have a binary file with data sequence in the order

 What do you mean by 'binary file'?

> [age,weight][age,weight] ....

 How are age and weight encoded in this 'binary file'?

> I know the length of the data and I want to load it into a
> data.frame. of course a way to do this is to read age and weight
> seperately and then use cbin(age,weight) to combine them into a
> dataframe, but is there a better solution?
> 

 Is it really an ASCII file? With age and weight separated by commas,
and then age-weight pairs separated by spaces? Are there really square
bracket pairs in there too?

 Or is it really a binary file, a series of 4 or 8-byte binary
representations of age and weight?

 Barry



From rlevy at inf.ed.ac.uk  Tue Feb  7 19:03:43 2006
From: rlevy at inf.ed.ac.uk (Roger Levy)
Date: Tue, 07 Feb 2006 18:03:43 +0000
Subject: [R] displaying Cyrillic in RGui under Windows
In-Reply-To: <Pine.LNX.4.61.0602071643190.14207@gannet.stats>
References: <43E8C697.20004@inf.ed.ac.uk>
	<Pine.LNX.4.61.0602071643190.14207@gannet.stats>
Message-ID: <43E8E0FF.8040607@inf.ed.ac.uk>

Prof Brian Ripley wrote:
> On Tue, 7 Feb 2006, Roger Levy wrote:
> 
>> I have a data frame with Cyrillic text that I would like to be able to
>> view under RGui.  Unfortunately I can't figure out from the manuals how
>> to make this happen -- can someone point me in the right direction?
> 
> You can only do this if you run RGui in a Cyrillic locale.  
> Unfortunately there are several incompatible Cyrillic encodings, so 
> let's hope this is the Windows one.  If so, set Windows to Russian as 
> per the rw-FAQ, select LANGUAGE=en and it should work.

Thanks, I understand better now.  Apparently the only usable encoding is 
Windows-1251, which R switches to upon the command 
Sys.setlocale(,"russian").  After converting my data files to that 
encoding and switching the Windows locale, everything works great.

Many thanks.

Roger



From frank.samuelson at fda.hhs.gov  Tue Feb  7 17:44:56 2006
From: frank.samuelson at fda.hhs.gov (FWS)
Date: Tue, 07 Feb 2006 11:44:56 -0500
Subject: [R] writing R shell scripts?
In-Reply-To: <Pine.GSO.4.60.0511071937020.1739@taxa.epi.umn.edu>
References: <Pine.GSO.4.60.0511071937020.1739@taxa.epi.umn.edu>
Message-ID: <dsaiq9$kj0$1@sea.gmane.org>

Use the all powerful "here document" feature of bash:

R --vanilla << "EOF" #  Pipe all subsequent lines into R.
####### Here's my R code

require(tcltk)
tkmessageBox(message="It works")

###### the end
EOF


Mike Miller wrote:
> I'm new to the list.  I've used R and S-PLUS a bit for about 15 years but 
> am now working to make R my main program for all numerical and statistical 
> computing.  I also use Octave for this kind of work and I recommend it (it 
> is also under the GPL).  Here's my question:  In Octave I can write shell 
> scripts in the Linux/UNIX environment that begin with a line like this...
> 
> #!/usr/local/bin/octave -q
> 
> ...and the remaining lines are octave commands.  Is it possible to do this 
> sort of thing in R using something like this?:
> 
> #!/usr/lib/R/bin/R.bin
> 
> Well, that isn't quite it because I tried it and it didn't work!
> 
> Any advice greatly appreciated.  Thanks in advance.
> 
> Mike
>



From elvis at xlsolutions-corp.com  Tue Feb  7 19:49:28 2006
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Tue, 07 Feb 2006 11:49:28 -0700
Subject: [R] March course @ 8 locations *** R/Splus Fundamentals and
	Programming Techniques
Message-ID: <20060207114928.9f08cc34deb45d78e54b3b5664e21546.00b92f2116.wbe@email.secureserver.net>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud to
announce  2-day "R/S-plus Fundamentals and Programming
Techniques" in San Francisco: www.xlsolutions-corp.com/Rfund.htm

**** Philadelphia,           March 9-10 
**** Seattle,                  March 13-14 
**** San Diego,              March 16-17
**** Portland, OR           March  16-17
**** Washington DC,      March 16-17

**** New York                March  20-21
**** San Francisco         March  30-31
**** Atlanta                    March  30-31

Reserve your seat now at the early bird rates! Payment due AFTER
the class

Course Description:

This two-day beginner to intermediate R/S-plus course focuses on a
broad spectrum of topics, from reading raw data to a comparison of R
and S. We will learn the essentials of data manipulation, graphical
visualization and R/S-plus programming. We will explore statistical
data analysis tools,including graphics with data sets. How to enhance
your plots, build your own packages (librairies) and connect via
ODBC,etc.
We will perform some statistical modeling and fit linear regression
models. Participants are encouraged to bring data for interactive
sessions

With the following outline:

- An Overview of R and S
- Data Manipulation and Graphics
- Using Lattice Graphics
- A Comparison of R and S-Plus
- How can R Complement SAS?
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling
- Project Management
- Techniques for Effective use of R and S
- Enhancing Plots
- Using High-level Plotting Functions
- Building and Distributing Packages (libraries)
- Connecting; ODBC, Rweb, Orca via sockets and via Rjava


Email us for group discounts.
Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578
Visit us: www.xlsolutions-corp.com/training.htm
Please let us know if you and your colleagues are interested in this
classto take advantage of group discount. Register now to secure your
seat!

Interested in R/Splus Advanced course? email us.


Cheers,
Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com
elvis at xlsolutions-corp.com



From statistical.model at googlemail.com  Tue Feb  7 20:13:37 2006
From: statistical.model at googlemail.com (statistical.model@googlemail.com)
Date: Tue, 7 Feb 2006 19:13:37 -0000
Subject: [R] Shapley Values
Message-ID: <EMEELGDEKHMIAKDGLCDCMEIHCKAA.Statistical.model@gmail.com>

Hi,
I am trying to compute the Shapley Values between a set of p independent
variables (x1, ..., xp) and the dependent variable y to study the
relationships.

I believe that the package "kappalab" could be an appropriate choice.
Is anybody able to give me some hints about the code I should write?
Any better package?

thanks in advance!

Roberto Furlan
University of Turin

----------------------------------------
La mia Cartella di Posta in Arrivo ?? protetta da SPAMfighter
202 messaggi contenenti spam sono stati bloccati con successo.
Scarica gratuitamente SPAMfighter!



From aleid2001 at yahoo.com  Tue Feb  7 20:18:08 2006
From: aleid2001 at yahoo.com (aleid2001@yahoo.com)
Date: Tue, 7 Feb 2006 19:18:08 +0000 (GMT)
Subject: [R] hi frinds
Message-ID: <20060207191808.26828.qmail@web52813.mail.yahoo.com>

Hello,

i hope that every body are OK there.

I would like to calculate the inverse of the cdf of
mixture of normal distribution (with 2 components,
p,(1-p)) from uniform points (0,1] using R. In this
case i have to specify the 2 means and 2 variances and
the mixing proportions (p, (1-p)). I am seeking help
from any one who knows how to use R functions to do
this. Also, i want to know how to read the results to
text.file.


many thanks to any help


my E-mail is aleid2001 at yahoo.com



From jfox at mcmaster.ca  Tue Feb  7 21:22:06 2006
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 7 Feb 2006 15:22:06 -0500
Subject: [R] elements from 'sem' function
In-Reply-To: <20060207172616.M28837@biologia.ufrj.br>
Message-ID: <20060207202205.JMYL20622.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Andr??,

The components of the "sem" object returned by sem() are explained on the
help page ?sem. There are several methods for "sem" objects:

> methods(class="sem")
[1] mod.indices.sem*            normalized.residuals.sem*  
[3] path.diagram.sem*           print.sem*                 
[5] residuals.sem*              standardized.residuals.sem*
[7] summary.sem*  

To retrieve components of the object directly, just use, e.g., object$C (for
the reproduced covariance matrix), or object$coeff (for estimates of free
parameters), in the normal manner for indexing a list. It would probably be
better for me to provide accessor functions [e.g., for the coef() generic]
for at least some of these, so I'll put that on the list of things to do.

I hope this helps,
 John 

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of andre 
> tavares correa dias
> Sent: Tuesday, February 07, 2006 12:28 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] elements from 'sem' function
> 
> Hi,
> I would like to print elements from sem (structural equation 
> modeling) function (e.g., model-reproduced covariance matrix 
> (C); estimated asymptotic covariance matrix of parameter 
> estimates (cov)). 
> 
> How can I  do this? 
> 
> Thanks,
> Andr?? 
> 
> --
> Andr?? Tavares Corr??a Dias
> Laborat??rio de Ecologia Vegetal
> Universidade Federal do Rio de Janeiro
> CCS-IB-Departamento de Ecologia
> Caixa Postal 68020
> 21941-970 Rio de Janeiro ? RJ, Brazil
> tel: +55 21 25626377
> Fax: + 55 21 25626320
> atcdias at biologia.ufrj.br
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From thayes at uwo.ca  Tue Feb  7 21:30:40 2006
From: thayes at uwo.ca (Tyler Hayes)
Date: Tue, 07 Feb 2006 15:30:40 -0500
Subject: [R] Reading in FORTRAN data using R
Message-ID: <43E90370.4070706@uwo.ca>

Hi There:

I was wondering if there is a way to read FORTRAN list data (similar to 
IDL's readf function).  I often use FORTRAN for most of my number 
crunching, and use something like IDL to visualize and perform 
statistical analysis on that data.  Since the each file is rather large 
(>100 Mb), formatting the output into columns or tables is impractical, 
hence the "list" style.  Please note, this is NOT binary data, but text 
output with no FORMAT.  For example:

My FORTRAN code writes out:

      open(unit=30,name=fnout,status='old')
           
      write(30,'(a20)') fnmod
      write(30,'(a20)') fnstr
      write(30,*) nfault,hpl,vplx,vply,taua,tauf,amuu,
     &      tminn,tstepp,itime,TBIS,bulkms,ntm,ncycle,pdcy
      write(30,*) ptrad
      write(30,'(a1)') respfb
      write(30,*) (timi(n), n=1,nfault)
      write(30,*) (taub(n), n=1,nfault)
      write(30,*) (delts(n), n=1,nf)
      write(30,*) (cfr(n), n=1,nfault)
      write(30,*) (dfr(n), n=1,nfault)
      write(30,*) (slpdf(n), n=1,nf2)
      write(30,*) (slpv(n), n=1,nfault)
      write(30,*) (rhofcc(n), n=1,nfault)
      write(30,*) (islip(n), n=1,nfault)

(NOTE: not all variables are the same length!)

I subsequently read in back the data as:

      open(unit=30,name=fnin,status='old')

      read(30,'(a20)') fnmod
      read(30,'(a20)') fnstr
      read(30,*) nfault,hpl,vplx,vply,taua,tauf,amuu,
     &     tminn,tstepp,ntime,TBIS,bulkms,ntm,ncycle,pdcy
      read(30,*) ptrad
      read(30,'(a1)') respfb
      read(30,*) (timi(n), n=1,nfault)
      read(30,*) (taub(n), n=1,nfault)
      read(30,*) (delts(n), n=1,nf)
      read(30,*) (cfr(n), n=1,nfault)
      read(30,*) (dfr(n), n=1,nfault)
      read(30,*) (slpdf(n), n=1,nf2)
      read(30,*) (slpv(n), n=1,nfault)
      read(30,*) (rhofcc(n), n=1,nfault)
      read(30,*) (islip(n), n=1,nfault)


read.fwf is not what I need from what I read and neither is read.fortran.

How would I go about reading in the above unformatted Fortran file within R?

Sorry if the question is somewhat trivial, but I am a complete nube to R 
(installed it 2 weeks ago) and am just getting caught up to speed.

Thanks for any advice you may have.

Cheers,

t.

-- 
Tyler Joseph Hayes
PhD Candidate, Geophysics
The University of Western Ontario
Department of Earth Sciences
B & GS Building - RM 154
London, Ontario N6A 5B7
CANADA 

email: thayes at uwo.ca
TEL  : 519.661.3187 (main office)
FAX  : 519.661.3198
CELL : 416.655.7897



From ericpante at hotmail.com  Tue Feb  7 22:22:09 2006
From: ericpante at hotmail.com (Eric Pante)
Date: Tue, 7 Feb 2006 16:22:09 -0500
Subject: [R] matching tables
Message-ID: <BAY106-DAV98A0C9454B3EC57DD0BDCBC010@phx.gbl>

Dear Listers,

I am trying to match tables that DO NOT have the same length. The 
tables result from the function "table()" so they look like this:

table 1
2 3 4
3 5 7

table 2
1 2 3
6 4 5

I need the following output: (NOTICE THE ZEROS)
             1 2 3 4
table1 0 3 5 7
table2 6 4 5 0

Unfortunately, I was not successful using "match()". Previous postings 
explain how to do similar matching, but for tables for same length, 
specifically. Any thoughts ?

Thanks !
eric

Eric Pante
----------------------------------------------------------------
College of Charleston, Grice Marine Laboratory
205 Fort Johnson Road, Charleston SC 29412
Phone: 843-953-9190 (lab)  -9200 (main office)
----------------------------------------------------------------

	"On ne force pas la curiosite, on l'eveille ..."
	Daniel Pennac



From br44114 at gmail.com  Tue Feb  7 22:33:17 2006
From: br44114 at gmail.com (bogdan romocea)
Date: Tue, 7 Feb 2006 16:33:17 -0500
Subject: [R] matching tables
Message-ID: <8d5a36350602071333i632b5dccmcea4a7a2bbe2dd3@mail.gmail.com>

t1 <- as.data.frame(table(1:10)) ; colnames(t1)[2] <- "A"
t2 <- as.data.frame(table(5:20)) ; colnames(t2)[2] <- "B"
t3 <- merge(t1,t2,all=TRUE)


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Eric Pante
> Sent: Tuesday, February 07, 2006 4:22 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] matching tables
>
> Dear Listers,
>
> I am trying to match tables that DO NOT have the same length. The
> tables result from the function "table()" so they look like this:
>
> table 1
> 2 3 4
> 3 5 7
>
> table 2
> 1 2 3
> 6 4 5
>
> I need the following output: (NOTICE THE ZEROS)
>              1 2 3 4
> table1 0 3 5 7
> table2 6 4 5 0
>
> Unfortunately, I was not successful using "match()". Previous
> postings
> explain how to do similar matching, but for tables for same length,
> specifically. Any thoughts ?
>
> Thanks !
> eric
>
> Eric Pante
> ----------------------------------------------------------------
> College of Charleston, Grice Marine Laboratory
> 205 Fort Johnson Road, Charleston SC 29412
> Phone: 843-953-9190 (lab)  -9200 (main office)
> ----------------------------------------------------------------
>
> 	"On ne force pas la curiosite, on l'eveille ..."
> 	Daniel Pennac
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Tue Feb  7 22:54:32 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 07 Feb 2006 22:54:32 +0100
Subject: [R] prehistoric versions of R --> 1995!
In-Reply-To: <43E8D06C.9020407@bank-banque-canada.ca>
References: <C00D2113.5401%sdavis2@mail.nih.gov>	<43E85438.7457.4BBCAC@localhost>	<43E8529A.9040609@statistik.uni-dortmund.de>	<17384.32124.247311.749610@stat.math.ethz.ch>
	<43E8D06C.9020407@bank-banque-canada.ca>
Message-ID: <43E91718.8020104@statistik.uni-dortmund.de>

Paul Gilbert wrote:

> 
> Martin Maechler wrote:
> 
> 
>>>>>>>"UweL" == Uwe Ligges <ligges at statistik.uni-dortmund.de>
>>>>>>>   on Tue, 07 Feb 2006 08:56:10 +0100 writes:
>>>>>>>           
>>>>>>>
>>
>>   UweL> Petr Pikal wrote:
>>   >> Hi
>>   >> 
>>   >> On 6 Feb 2006 at 15:57, ivo welch wrote:
>>   >> 
>>   >> Date sent:      	Mon, 6 Feb 2006 15:57:30 -0500
>>   >> From:           	ivo welch <ivowel at gmail.com>
>>   >> To:             	Sean Davis <sdavis2 at mail.nih.gov>
>>   >> Copies to:      	piet.vanremortel at gmail.com, r-help <r-help at stat.math.ethz.ch>
>>   >> Subject:        	Re: [R] R loop
>>   >> 
>>   >> 
>>   >>>>> data[ data$a == "name2" ]  # does not work and gives a weird
>>   >>>>> result,  yuck
>>   >>>> 
>>   >>>> data[data$a=="name2",]
>>   >>>> 
>>   >>> 
>>   >>> sorry about this.  I believe a few versions back, one could not subset
>>   >>> data frames, so I did not even check what I wrote.  Works now.
>>   >> 
>>   >> 
>>   >> It depends on what you consider few versions back. I started with R 
>>   >> vesion 1.2.0 about 10 years 
>>
>>   UweL> I bet 200$ (or EUR) you have not used R 10 years ago. ;-)
>> 
>>
> 
> Is that an open bet or just for Petr?

Was intended just for Petr, I know Martin came in very early and would 
not have made a bet for him. I try not to waste money. ;-)

Uwe



> 
>>   UweL> People certainly remember the 1.0.0 release at the remarkable day 
>>   UweL> 29-FEB-2000.
>>   UweL> 1.2.0 was released in December 2000, about 5 years ago.
>>   UweL> I started with 0.62.x in 1998.
>>   UweL> The oldest version I found on CRAN is a pre-alpha R.sea.hqx for the Mac 
>>   UweL> dated 07-Nov-1996.
>>
>>Eehm; that has a wrong date (or then it would not be pre-alpha):
>>I've always entertained the prehistoric directory of R sources
>>at ftp://stat.ethz.ch/Software/R/alpha/PreHistoric/
>>and its oldest file is 
>>        Name	           Size    Date        
>>        R-0.1alpha.tar.gz 861464  Feb 12 1996 
>> 
>>
> 
> I'm pretty sure I was using R 0.16 in the fall of 1996 on Linux, which 
> was when I got dse largely converted from S. I had a slightly  earlier 
> version in the spring of 1996 on Solaris. (I think the numbering would 
> have been 0.11 -0.15 in the spring of 1996.)  I don't think the 
> numbering was the same on other platforms.
> 
> 
>>(which will be 10 years coming Sunday -- what a jubilee!!)
>>So, even that is not pre-alpha; and yes, that was a bit before CRAN existed. 
>>
>>Now to the pre-alpha history.  I've digged some more and found
>>
>>1) that the mac file mentioned above would have
>>  correct date 'Nov 6 1995' (at least that's the date I saved
>>  when I looked at the Auckland FTP server through Emacs ange-ftp).
>>
>>2) The oldest stuff that I have is all from 1995;
>>  The source I (think I) had first used is dated June 20 1995;
>>  notably the  R-unix-src.tar.gz with accompanying README and
>>  INSTALL files
>>  (There was also ./win subdirectory which I did not use, with
>>   files all from July 15, 1995; AFAIK done by Robert Gentleman)
>>
>>I've now put a bit of these oldest files into
>> ftp://stat.ethz.ch/Software/R/alpha/PreHistoric/pre-alpha/
>>
>>3) I've kept an e-mail that Ross had sent me on July 28 with
>>  two small patches to the (June 20) sources.
>>  
>>  Yes, chances are pretty high that I was the first one outside
>>  of the Auckland(NZ)-community to actively use R.
>> 
>>
> 
> I wouldn't be really sure of that (but it's a fair bet).
> 
> 
>>Note it might be interesting to find even older sources, but that
>>would most probably have to be by Robert and Ross (or a
>>sysadmin at Auckland).
>> 
>>
> 
> I used to have some floppy disks somewhere...
> 
> Paul Gilbert
> 
> 
>>Martin Maechler, ETH Zurich
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>> 
>>
> 
> ====================================================================================
> 
> La version fran??aise suit le texte anglais.
> 
> ------------------------------------------------------------------------------------
> 
> This email message from the Bank of Canada is given in good faith, and shall not be
> binding or construed as constituting any obligation on the part of the Bank.
> 
> This email may contain privileged and/or confidential inform...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From www.brook at gmail.com  Tue Feb  7 22:57:51 2006
From: www.brook at gmail.com (www.brook@gmail)
Date: Tue, 7 Feb 2006 16:57:51 -0500
Subject: [R] question about binary data file and data.frame
Message-ID: <43e917df.22f46967.5476.7d45@mx.gmail.com>

Each data (edge,weight) is numerical data with type double (4 bytes)

df<-file("d:/sim.data","rb")
age[1]<-readBin(df,double())
weigt[1]<-readBin(df,double())
...
age[10]<-readBin(df,double())
weigt[10]<-readBin(df,double())

it is not asc file.

	

======= 2006-02-07 13:03:17 =======

>www.brook at gmail wrote:
>> I have a binary file with data sequence in the order
>
> What do you mean by 'binary file'?
>
>> [age,weight][age,weight] ....
>
> How are age and weight encoded in this 'binary file'?
>
>> I know the length of the data and I want to load it into a
>> data.frame. of course a way to do this is to read age and weight
>> seperately and then use cbin(age,weight) to combine them into a
>> dataframe, but is there a better solution?
>> 
>
> Is it really an ASCII file? With age and weight separated by commas,
>and then age-weight pairs separated by spaces? Are there really square
>bracket pairs in there too?
>
> Or is it really a binary file, a series of 4 or 8-byte binary
>representations of age and weight?
>
> Barry

= = = = = = = = = = = = = = = = = = = =
			


 
				 
www.brook
www.brook at gmail.com
2006-02-07



From firas at cs.technion.ac.il  Tue Feb  7 23:10:27 2006
From: firas at cs.technion.ac.il (Firas Swidan)
Date: Wed, 8 Feb 2006 00:10:27 +0200 (IST)
Subject: [R] Calculating Kuiper/Watson test p-value
Message-ID: <Pine.LNX.4.63.0602072250540.7084@csd.cs.technion.ac.il>

Hi,

I am trying to use the Kuiper and Watson U^2 tests available in the 
CircStats or circular packages to test for uniformity on a circle. 
However, the implementation of these tests gives ranges of p-values that 
are not dependent on n, the size of sample.

Are there any methods (including/excluding implementation) for calculating 
the p-values (with respect to n) of these tests with arbitrary precision? 
The closest thing that I found was an asymptotic approximation for the 
Kuiper p-value implemented in MatLab.

Many thanks and all the best,
Firas.



From Mike.Prager at noaa.gov  Tue Feb  7 23:15:43 2006
From: Mike.Prager at noaa.gov (Michael H. Prager)
Date: Tue, 07 Feb 2006 17:15:43 -0500
Subject: [R] Reading in FORTRAN data using R
In-Reply-To: <43E90370.4070706@uwo.ca>
References: <43E90370.4070706@uwo.ca>
Message-ID: <43E91C0F.4070600@noaa.gov>

Tyler,

One relatively easy way to get structured model data into R is to use 
output routines I have written with my colleagues.  They are called 
For2R and are available at

http://shrimp.ccfhrb.noaa.gov/~mprager/Rinter.html

To go that route, you would replace (or supplement) your Fortran write 
statements with a series of calls to our output routines. When you read 
the data from the resulting file, you won't need to specify variable 
names, lengths, or anything else, as they will all be stored in the 
output file.  A single R statement will read everything into an R "list" 
object. 

The alternative would be using the the R scan() function to read your 
variables into R.  In that case, you would need to specify the length of 
each and give it a name, similar to how you read your data into another 
Fortran program.

By the way, watch out for the term "unformatted" in a Fortran context.  
"Unformatted" in Fortran is a specific term that means something close 
to what "binary" data I/O means to a C programmer.  Your I/O is 
"list-directed," but perhaps you know that already.

Regards,
...Mike Prager




on 2/7/2006 3:30 PM Tyler Hayes said the following:
> Hi There:
>
> I was wondering if there is a way to read FORTRAN list data (similar to 
> IDL's readf function).  I often use FORTRAN for most of my number 
> crunching, and use something like IDL to visualize and perform 
> statistical analysis on that data.  Since the each file is rather large 
> (>100 Mb), formatting the output into columns or tables is impractical, 
> hence the "list" style.  Please note, this is NOT binary data, but text 
> output with no FORMAT.  For example:
>
> My FORTRAN code writes out:
>
>       open(unit=30,name=fnout,status='old')
>            
>       write(30,'(a20)') fnmod
>       write(30,'(a20)') fnstr
>       write(30,*) nfault,hpl,vplx,vply,taua,tauf,amuu,
>      &      tminn,tstepp,itime,TBIS,bulkms,ntm,ncycle,pdcy
>       write(30,*) ptrad
>       write(30,'(a1)') respfb
>       write(30,*) (timi(n), n=1,nfault)
>       write(30,*) (taub(n), n=1,nfault)
>       write(30,*) (delts(n), n=1,nf)
>       write(30,*) (cfr(n), n=1,nfault)
>       write(30,*) (dfr(n), n=1,nfault)
>       write(30,*) (slpdf(n), n=1,nf2)
>       write(30,*) (slpv(n), n=1,nfault)
>       write(30,*) (rhofcc(n), n=1,nfault)
>       write(30,*) (islip(n), n=1,nfault)
>
> (NOTE: not all variables are the same length!)
>
> I subsequently read in back the data as:
>
>       open(unit=30,name=fnin,status='old')
>
>       read(30,'(a20)') fnmod
>       read(30,'(a20)') fnstr
>       read(30,*) nfault,hpl,vplx,vply,taua,tauf,amuu,
>      &     tminn,tstepp,ntime,TBIS,bulkms,ntm,ncycle,pdcy
>       read(30,*) ptrad
>       read(30,'(a1)') respfb
>       read(30,*) (timi(n), n=1,nfault)
>       read(30,*) (taub(n), n=1,nfault)
>       read(30,*) (delts(n), n=1,nf)
>       read(30,*) (cfr(n), n=1,nfault)
>       read(30,*) (dfr(n), n=1,nfault)
>       read(30,*) (slpdf(n), n=1,nf2)
>       read(30,*) (slpv(n), n=1,nfault)
>       read(30,*) (rhofcc(n), n=1,nfault)
>       read(30,*) (islip(n), n=1,nfault)
>
>
> read.fwf is not what I need from what I read and neither is read.fortran.
>
> How would I go about reading in the above unformatted Fortran file within R?
>
> Sorry if the question is somewhat trivial, but I am a complete nube to R 
> (installed it 2 weeks ago) and am just getting caught up to speed.
>
> Thanks for any advice you may have.
>
> Cheers,
>
> t.
>
>   

-- 

Michael Prager, Ph.D.
Population Dynamics Team, NMFS SE Fisheries Science Center
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516
http://shrimp.ccfhrb.noaa.gov/~mprager/
Opinions expressed are personal, not official.  No
government endorsement of any product is made or implied.



From tyler.smith at mail.mcgill.ca  Tue Feb  7 23:37:50 2006
From: tyler.smith at mail.mcgill.ca (Tyler Smith)
Date: Tue, 07 Feb 2006 17:37:50 -0500
Subject: [R] Subsetting matrices
Message-ID: <20060207173750.rov2mijyp6ogs48w@webmail.mcgill.ca>

Dear R-Helpers,

I am working on a dataset containing ca. 500 specimens of 17 different 
species. The data is three text columns, followed by ca 70 columns of 
binary data.

I'm trying to write a function that will allow me to interactively 
exclude species using the inofrmation in the third text column. My 
function, matrix.slicer, appears to work as I intend. However, when I 
pass the resulting matrix to my homemade principal coordinates 
function, pcoa, the results include all of the data, with nothing 
excluded.

I've read the help for factors, levels, subset, [, and some threads 
here relating to subsetting and drop=true issues, but I'm afraid I just 
don't understand what I need to do. I've pasted the functions below - 
any help would be appreciated. Thanks!

Tyler Smith


matrix.slicer <- function(mat, label.vector){

  selector <- 999

  print("Select species to remove from the matrix, 0 to finish")
   while (selector != 0){
    selector <-  menu( levels( factor(mat[,label.vector])))
    if (selector==0)break
    print (c("Removed: ", levels(factor(mat[,label.vector]))[selector]))
    mat <- subset (mat, mat[,label.vector]!=levels (factor (mat 
[,label.vector]))[selector])
         }

  return (mat)
  }


gel.data <- matrix.slicer (gel.data,3)

disttemp <- as.matrix(vegdist(gel.data[,-(1:3)], method="jaccard"))

dist <- sqrt(disttemp)

PCOA <- pcoa (dist)


-- 
Tyler Smith



From p.murrell at auckland.ac.nz  Tue Feb  7 23:39:57 2006
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Wed, 08 Feb 2006 11:39:57 +1300
Subject: [R] image() and text
In-Reply-To: <43E513A3.8010406@siol.net>
References: <43E513A3.8010406@siol.net>
Message-ID: <43E921BD.7090900@stat.auckland.ac.nz>

Hi


Andrej Kastrin wrote:
> Dear useRs,
> 
> I have 44 symmetrical matrix ; then I use
> 
> image(log(my.matrix)) to visualise it.
> 
> Is there any 'simple' way to add text labels into each cell lie on 
> diagonal of the image plot? Thanks for any pointers...


Do you mean something like ...?

m <- matrix(rnorm(100), ncol=10)
image(m)
text(0:9/9, 0:9/9, 0:9)

Paul
-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From jeff.hamann at forestinformatics.com  Wed Feb  8 00:23:15 2006
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Tue, 7 Feb 2006 15:23:15 -0800 (PST)
Subject: [R] getting strata/cluster level values with survey package?
Message-ID: <3065.128.193.140.221.1139354595.squirrel@www.forestinformatics.com>

First, I appoligise for the rooky question, but...

I'm trying to obtain standard errors, confidence intervals, etc. from a
sample design and have been trouble getting the results for anything other
than the basic total or mean for the overall survey from the survey
package.

For example, using the following dataset,

strata,cluster,vol
A,1,18.58556192
A,1,12.55175443
A,1,21.65882438
A,1,17.11172946
A,1,15.41713348
A,2,13.9344623
A,2,17.13104821
A,2,14.6806479
A,2,14.68357291
A,2,18.86017714
A,2,20.67642515
A,2,15.15295351
A,2,13.82121102
A,2,12.9110477
A,2,14.83153677
A,2,21.90772687
A,3,18.69795427
A,3,18.45636428
A,3,15.77175793
A,3,15.54715217
A,3,20.31948393
A,3,19.26391445
A,3,15.54750775
A,3,19.18724018
A,4,12.89572151
A,4,12.92047701
A,4,12.64958757
A,4,19.85888418
A,4,19.64057669
A,4,19.19188964
A,4,18.81619298
A,4,21.73670878
A,5,15.99430802
A,5,18.66666517
A,5,21.80441654
A,5,14.22081904
A,5,16.01576433
A,5,14.92497202
A,5,17.95123218
A,5,19.82027165
A,5,19.35698273
A,5,19.10826519
B,6,13.40892677
B,6,14.3956207
B,6,13.82113391
B,6,16.37338569
B,6,19.70159575
B,7,14.74334178
B,7,16.55125245
B,7,12.38329798
B,7,18.16472408
B,7,16.32938475
B,7,16.06465494
B,7,12.63086062
B,7,14.46114813
B,7,21.90134013
B,7,13.81025827
B,7,15.85805494
B,7,20.18195326
B,8,19.05120792
B,8,12.83856639
B,8,12.61360139
B,8,21.30434314
B,8,14.19960469
B,8,17.38397826
B,8,15.66477339
B,8,22.07182834
B,8,12.07487394
B,8,20.36357359
B,8,20.2543677
B,9,14.44499362
B,9,17.77235228
B,9,13.01620902
B,9,18.10976359
B,10,18.22350661
B,10,18.41504728
B,10,17.94735486
B,10,18.39173938
B,10,14.21729704
B,10,16.95753684
B,10,21.11643087
B,10,16.09688752
B,10,19.54707452
B,10,22.00450065
B,10,15.15308873
B,10,14.72488972
B,10,17.65280737
B,10,14.61615255
B,10,12.89525607
B,11,22.35831089
B,11,18.0853187
B,11,22.12815791
B,11,17.74562214
B,11,21.45724242
B,11,20.57933779
B,11,19.97397415
B,11,16.34967424
B,12,22.14385376
B,12,17.82816113
B,12,18.37056381
B,12,16.13152759
B,12,22.06764318
B,12,12.80924472
B,12,18.95522175
B,13,20.40554286
B,13,19.72951878
C,14,15.51581
C,14,15.4836358
C,14,13.35882363
C,14,13.16072916
C,14,21.69168971
C,14,19.09686303
C,14,14.47450457
C,14,12.04870424
C,14,13.33096141
C,14,17.38388981
C,14,16.29015289
C,14,16.32707754
C,14,16.2784054
C,15,15.0170597
C,15,14.95767365
C,15,15.20739614
C,15,22.10458509
C,15,12.3362457
C,15,19.87895753
C,15,18.8363682
C,15,16.43738666
C,15,12.84570744
C,15,15.99869357
C,15,14.42551321
C,15,13.63489872
C,15,15.67179885
C,16,14.61700901
C,16,14.64864676
C,16,14.13014582
C,16,21.7637441
C,16,20.66825543
C,16,17.05977818
C,16,17.80118916
C,16,15.16641698

where this is read into stand.data. When I use the following survey designs,

srv1 <- svydesign(ids=~1, strata=~strata, data=stand.data )

or,

srv1 <- svydesign(ids=~cluster, strata=~strata, data=stand.data )

with,

print( svytotal( ~vol, srv1 ) )

I only obtain the total,

> print( svytotal( ~vol, srv1 ) )
    total     SE
vol  2377 34.464

or worse,

print( svytotal( ~vol + strata, srv1 ) )
         total     SE
vol     2377.0 34.464
strataA   42.0  0.000
strataB   64.0  0.000
strataC   34.0  0.000

which reports the number of observations in each of the strata. I'm sure
this is a RTFM question, but I just need a start. The size of each "plot"
is 0.04 units (hectares) and I want to be able to quickly examine working
up each sample with and without clusters (this is going to be part of a
larger simulation study).

I'm trying to not use SAS for this and hate to admit defeat.

Thanks,
Jeff.



From jeff.hamann at forestinformatics.com  Wed Feb  8 00:24:35 2006
From: jeff.hamann at forestinformatics.com (Jeff D. Hamann)
Date: Tue, 7 Feb 2006 15:24:35 -0800 (PST)
Subject: [R] getting strata/cluster level values with survey package?
Message-ID: <3076.128.193.140.221.1139354675.squirrel@www.forestinformatics.com>

First, I appoligise for the rookie question, but...

I'm trying to obtain standard errors, confidence intervals, etc. from a
sample design and have been trouble getting the results for anything other
than the basic total or mean for the overall survey from the survey
package.

For example, using the following dataset,

strata,cluster,vol
A,1,18.58556192
A,1,12.55175443
A,1,21.65882438
A,1,17.11172946
A,1,15.41713348
A,2,13.9344623
A,2,17.13104821
A,2,14.6806479
A,2,14.68357291
A,2,18.86017714
A,2,20.67642515
A,2,15.15295351
A,2,13.82121102
A,2,12.9110477
A,2,14.83153677
A,2,21.90772687
A,3,18.69795427
A,3,18.45636428
A,3,15.77175793
A,3,15.54715217
A,3,20.31948393
A,3,19.26391445
A,3,15.54750775
A,3,19.18724018
A,4,12.89572151
A,4,12.92047701
A,4,12.64958757
A,4,19.85888418
A,4,19.64057669
A,4,19.19188964
A,4,18.81619298
A,4,21.73670878
A,5,15.99430802
A,5,18.66666517
A,5,21.80441654
A,5,14.22081904
A,5,16.01576433
A,5,14.92497202
A,5,17.95123218
A,5,19.82027165
A,5,19.35698273
A,5,19.10826519
B,6,13.40892677
B,6,14.3956207
B,6,13.82113391
B,6,16.37338569
B,6,19.70159575
B,7,14.74334178
B,7,16.55125245
B,7,12.38329798
B,7,18.16472408
B,7,16.32938475
B,7,16.06465494
B,7,12.63086062
B,7,14.46114813
B,7,21.90134013
B,7,13.81025827
B,7,15.85805494
B,7,20.18195326
B,8,19.05120792
B,8,12.83856639
B,8,12.61360139
B,8,21.30434314
B,8,14.19960469
B,8,17.38397826
B,8,15.66477339
B,8,22.07182834
B,8,12.07487394
B,8,20.36357359
B,8,20.2543677
B,9,14.44499362
B,9,17.77235228
B,9,13.01620902
B,9,18.10976359
B,10,18.22350661
B,10,18.41504728
B,10,17.94735486
B,10,18.39173938
B,10,14.21729704
B,10,16.95753684
B,10,21.11643087
B,10,16.09688752
B,10,19.54707452
B,10,22.00450065
B,10,15.15308873
B,10,14.72488972
B,10,17.65280737
B,10,14.61615255
B,10,12.89525607
B,11,22.35831089
B,11,18.0853187
B,11,22.12815791
B,11,17.74562214
B,11,21.45724242
B,11,20.57933779
B,11,19.97397415
B,11,16.34967424
B,12,22.14385376
B,12,17.82816113
B,12,18.37056381
B,12,16.13152759
B,12,22.06764318
B,12,12.80924472
B,12,18.95522175
B,13,20.40554286
B,13,19.72951878
C,14,15.51581
C,14,15.4836358
C,14,13.35882363
C,14,13.16072916
C,14,21.69168971
C,14,19.09686303
C,14,14.47450457
C,14,12.04870424
C,14,13.33096141
C,14,17.38388981
C,14,16.29015289
C,14,16.32707754
C,14,16.2784054
C,15,15.0170597
C,15,14.95767365
C,15,15.20739614
C,15,22.10458509
C,15,12.3362457
C,15,19.87895753
C,15,18.8363682
C,15,16.43738666
C,15,12.84570744
C,15,15.99869357
C,15,14.42551321
C,15,13.63489872
C,15,15.67179885
C,16,14.61700901
C,16,14.64864676
C,16,14.13014582
C,16,21.7637441
C,16,20.66825543
C,16,17.05977818
C,16,17.80118916
C,16,15.16641698

where this is read into stand.data. When I use the following survey designs,

srv1 <- svydesign(ids=~1, strata=~strata, data=stand.data )

or,

srv1 <- svydesign(ids=~cluster, strata=~strata, data=stand.data )

with,

print( svytotal( ~vol, srv1 ) )

I only obtain the total,

> print( svytotal( ~vol, srv1 ) )
    total     SE
vol  2377 34.464

or worse,

print( svytotal( ~vol + strata, srv1 ) )
         total     SE
vol     2377.0 34.464
strataA   42.0  0.000
strataB   64.0  0.000
strataC   34.0  0.000

which reports the number of observations in each of the strata. I'm sure
this is a RTFM question, but I just need a start. The size of each "plot"
is 0.04 units (hectares) and I want to be able to quickly examine working
up each sample with and without clusters (this is going to be part of a
larger simulation study).

I'm trying to not use SAS for this and hate to admit defeat.

Thanks,
Jeff.



From kalar1 at wp.pl  Wed Feb  8 00:35:51 2006
From: kalar1 at wp.pl (Kuba)
Date: Wed, 08 Feb 2006 00:35:51 +0100
Subject: [R] explanation of data sets variables
Message-ID: <43e92ed764991@wp.pl>

Dear all,
  where I can find explanation of data sets variables, for 
example what does (u,x) variables means in "city" data?

Thank you in advance,

Kuba

----------------------------------------------------
Jennifer Anistron, Mark Rufallo, Shirley Maclaine, 
Kevin Costner, Kathy Bates w komedii romantycznej 
"Z UST DO UST". W kinach od 10 lutego! 
http://klik.wp.pl/?adr=http%3A%2F%2Fadv.reklama.wp.pl%2Fas%2Fzustdoust.html&sid=651



From rossibarra at gmail.com  Wed Feb  8 01:06:41 2006
From: rossibarra at gmail.com (Jeffrey Ross-Ibarra)
Date: Tue, 7 Feb 2006 19:06:41 -0500
Subject: [R] empty wireframe
Message-ID: <23f82cc70602071606s6e44d74bha13f241bbf2840b8@mail.gmail.com>

Perhaps I am missing something incredibly basic, but I can't get the
wireframe function to plot anything other than an empty graph with
axes (and the correct scale).  Cloud() works just fine, as does
scatterplot3d(), and wireframe() works fine for other data sets I
have.  Are there some data sets that can't be plotted with
wireframe()?  If so, what are the characteristics that prevent
wireframe() from plotting?

Thanks in advance,

Jeff

--
_____

Jeffrey Ross-Ibarra                                        email:
rossibarra at gmail.com
Dept. Genetics                                             phone: 706-542-0290
Fred C. Davison Life Sciences Complex
University of Georgia
Athens, Ga. 30602
_____

Please tell me what is wrong with Darwinism. I can't see anything
wrong with Darwinism.

Ernst Mayr



From gerifalte28 at hotmail.com  Wed Feb  8 01:19:13 2006
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Wed, 08 Feb 2006 00:19:13 +0000
Subject: [R] explanation of data sets variables
In-Reply-To: <43e92ed764991@wp.pl>
Message-ID: <BAY103-F3158170A17080EF783DA24A6000@phx.gbl>

library(boot)
?city

Francisco

>From: Kuba <kalar1 at wp.pl>
>To: R-help at stat.math.ethz.ch
>Subject: [R] explanation of data sets variables
>Date: Wed, 08 Feb 2006 00:35:51 +0100
>
>Dear all,
>   where I can find explanation of data sets variables, for
>example what does (u,x) variables means in "city" data?
>
>Thank you in advance,
>
>Kuba
>
>----------------------------------------------------
>Jennifer Anistron, Mark Rufallo, Shirley Maclaine,
>Kevin Costner, Kathy Bates w komedii romantycznej
>"Z UST DO UST". W kinach od 10 lutego!
>http://klik.wp.pl/?adr=http%3A%2F%2Fadv.reklama.wp.pl%2Fas%2Fzustdoust.html&sid=651
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From deepayan.sarkar at gmail.com  Wed Feb  8 01:32:36 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 7 Feb 2006 18:32:36 -0600
Subject: [R] empty wireframe
In-Reply-To: <23f82cc70602071606s6e44d74bha13f241bbf2840b8@mail.gmail.com>
References: <23f82cc70602071606s6e44d74bha13f241bbf2840b8@mail.gmail.com>
Message-ID: <eb555e660602071632q5bf06e5gfaaee1126631f144@mail.gmail.com>

On 2/7/06, Jeffrey Ross-Ibarra <rossibarra at gmail.com> wrote:
> Perhaps I am missing something incredibly basic, but I can't get the
> wireframe function to plot anything other than an empty graph with
> axes (and the correct scale).  Cloud() works just fine, as does
> scatterplot3d(), and wireframe() works fine for other data sets I
> have.  Are there some data sets that can't be plotted with
> wireframe()?

Evidently, there are.

> If so, what are the characteristics that prevent
> wireframe() from plotting?

Since you have access to one such data set and we don't, perhaps you
can tell us.

> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Deepayan



From jholtman at gmail.com  Wed Feb  8 01:45:11 2006
From: jholtman at gmail.com (jim holtman)
Date: Tue, 7 Feb 2006 19:45:11 -0500
Subject: [R] question about binary data file and data.frame
In-Reply-To: <43e917df.22f46967.5476.7d45@mx.gmail.com>
References: <43e917df.22f46967.5476.7d45@mx.gmail.com>
Message-ID: <644e1f320602071645s72f7a8besd5da9f70d49a3cff@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060207/4aa57ab6/attachment.pl

From spencer.graves at pdf.com  Wed Feb  8 03:18:14 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 07 Feb 2006 18:18:14 -0800
Subject: [R] how to use mle?
In-Reply-To: <38b9f0350602021004r35bf0b44q@mail.gmail.com>
References: <38b9f0350602021004r35bf0b44q@mail.gmail.com>
Message-ID: <43E954E6.90701@pdf.com>

	  I see two problems:

	  First, "mle" expects its first argument to return (-log(likelihood)); 
  your "LL" is closer to "+log(likelihood)", but it seems to be missing 
something beyond that.  In particular, "Y" is 10 x 3, but "fit" is only 
10 x 2.

	  Second, I'm not sure, but it looks to me like "mle" wants to optimize 
over scalar arguments its first argument, "LL" in your case, and you 
want it to optimize over a vector.  I can't see where the help page for 
"mle" spells it out, but unless I missed something, the examples all 
used scalar arguments.  Moreover, I walked through your call to "mle" 
line by line after 'debug(mle)'.  The argument "start" that "mle" passes 
to "optim" was of length 0.  Therefore, you need to do something 
different to convince "mle" that it needs to optimize by varying more 
than 0 parameters.

	  Have you considered changing the sign of the output of "LL" (which 
you need to do anway) and giving it directly to "optim"?  That should 
work.

	  Moreover, it looks to me like you want to do multinomial logistic 
regression.  If that is so, have you considered searching for that in 
particular?  RSiteSearch("multinomial logistic regression") returned 130 
hits for me just now.

	  hope this helps.
	  spencer graves

ronggui wrote:

>>Y
> 
>       [,1] [,2] [,3]
>  [1,]    0    1    0
>  [2,]    0    1    0
>  [3,]    0    0    1
>  [4,]    1    0    0
>  [5,]    0    0    1
>  [6,]    0    0    1
>  [7,]    1    0    0
>  [8,]    1    0    0
>  [9,]    0    0    1
> [10,]    1    0    0
> 
> 
>>X
> 
>    pri82 pan82
> 1      0     0
> 2      0     0
> 3      1     0
> 4      1     0
> 5      0     1
> 6      0     0
> 7      1     0
> 8      1     0
> 9      0     0
> 10     0     0
> 
> 
>>K=2
>>J=3
> 
> 
> 
> LL <- function(b=rep(0,(J-1)*K)){
> B=matrix(c(b,rep(0,K)),ncol=J,nrow=K)
> fit <- X%*%B
> p<-exp(fit)/rowSums(exp(fit))
> sum(Y*log(p))
> }
> 
> grad<- function(b=rep(0,(J-1)*K)){
> B=matrix(c(b,rep(0,K)),ncol=J,nrow=K)
> fit <- X%*%B
> p<-exp(fit)/rowSums(exp(fit))
> Yp <- Y-p
> Yp<-matrix(rep(t(Yp),each=K),ncol=K*J,by=T)
> X <- matrix(rep(X,J) ,ncol=K*J)
> apply(Yp*X,2,sum)
> }
> 
> library(stats4)
> mle(LL)
> Error in validObject(.Object) : invalid class "mle" object: invalid
> object for slot "fullcoef" in class "mle": got class "list", should be
> or extend class "numeric"
> 
> mle(LL,gr=grad)
> Error in optim(start, f, method = method, hessian = TRUE, ...) :
>         gradient in optim evaluated to length 6 not 0
> 
> what is wrong with my code?I try to fix it myself but fails,anyone
> helps me ?Thank you!
> 
> --
> Deparment of Sociology
> Fudan University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From chabotd at globetrotter.net  Wed Feb  8 03:29:20 2006
From: chabotd at globetrotter.net (Denis Chabot)
Date: Tue, 07 Feb 2006 21:29:20 -0500
Subject: [R] plotting lines that break if data break
Message-ID: <8FA2A35E-09A0-45F2-8ADD-9876564C5AD8@globetrotter.net>

Hi,

Sometimes data series (not necessarily time series) suffer breaks  
where data were expected, but not collected. Often the regular  
"lines" command to add such data to a plot is what I want, but other  
times I'd like the line to break where the data series is  
interrupted, instead of the line jumping to the next point in the  
series uninterrupted. Usually my data file contain one value of x but  
none of y, but alternatively a break could also appear as a NA value  
for both x and y.

I have found I could use the "segments" command instead of "lines",  
but this seems to require I manipulate my data (which may or may not  
contain breaks, and the number of breaks can vary if there are breaks  
at all).

Is there another command that works like "lines" but will break the  
line if the data series suffer an interruption?

Sincerely,

Denis Chabot



From ggrothendieck at gmail.com  Wed Feb  8 04:06:59 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 7 Feb 2006 22:06:59 -0500
Subject: [R] plotting lines that break if data break
In-Reply-To: <8FA2A35E-09A0-45F2-8ADD-9876564C5AD8@globetrotter.net>
References: <8FA2A35E-09A0-45F2-8ADD-9876564C5AD8@globetrotter.net>
Message-ID: <971536df0602071906o311b2fa1y6d4f5222cda027d8@mail.gmail.com>

It does break already.  Try this:

plot(1:10, c(1:5,NA,7:10), type = "l")
plot(c(1:5,NA,7:10), 1:10, type = "l")



On 2/7/06, Denis Chabot <chabotd at globetrotter.net> wrote:
> Hi,
>
> Sometimes data series (not necessarily time series) suffer breaks
> where data were expected, but not collected. Often the regular
> "lines" command to add such data to a plot is what I want, but other
> times I'd like the line to break where the data series is
> interrupted, instead of the line jumping to the next point in the
> series uninterrupted. Usually my data file contain one value of x but
> none of y, but alternatively a break could also appear as a NA value
> for both x and y.
>
> I have found I could use the "segments" command instead of "lines",
> but this seems to require I manipulate my data (which may or may not
> contain breaks, and the number of breaks can vary if there are breaks
> at all).
>
> Is there another command that works like "lines" but will break the
> line if the data series suffer an interruption?
>
> Sincerely,
>
> Denis Chabot
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From sell_mirage_ne at hotmail.com  Wed Feb  8 04:21:43 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Tue, 07 Feb 2006 21:21:43 -0600
Subject: [R] difference between rnorm(1000, 0, 1) and running rnorm(500, 0,
	1) twice
Message-ID: <BAY110-F4B7483709FF7485B32C6FC7000@phx.gbl>

Hi R users

This looks a simple question

Is there any difference between between rnorm(1000,0,1) and running 
rnorm(500,0,1) twice in terms of outcome ?

TM



From chabotd at globetrotter.net  Wed Feb  8 04:33:50 2006
From: chabotd at globetrotter.net (Denis Chabot)
Date: Tue, 07 Feb 2006 22:33:50 -0500
Subject: [R] plotting lines that break if data break
In-Reply-To: <971536df0602071906o311b2fa1y6d4f5222cda027d8@mail.gmail.com>
References: <8FA2A35E-09A0-45F2-8ADD-9876564C5AD8@globetrotter.net>
	<971536df0602071906o311b2fa1y6d4f5222cda027d8@mail.gmail.com>
Message-ID: <F71B17C9-3A16-4825-9F90-21A7B92CBAB9@globetrotter.net>

I'm sorry, too long without coffee.

Lately I have done numerous plots with superimposed non-linear  
quantile regression fits, and those do not break (which is fine), and  
I wrongly transposed this to "lines" in my head.

Denis
Le 06-02-07 ?? 22:06, Gabor Grothendieck a ??crit :

> It does break already.  Try this:
>
> plot(1:10, c(1:5,NA,7:10), type = "l")
> plot(c(1:5,NA,7:10), 1:10, type = "l")
>
>
>
> On 2/7/06, Denis Chabot <chabotd at globetrotter.net> wrote:
>> Hi,
>>
>> Sometimes data series (not necessarily time series) suffer breaks
>> where data were expected, but not collected. Often the regular
>> "lines" command to add such data to a plot is what I want, but other
>> times I'd like the line to break where the data series is
>> interrupted, instead of the line jumping to the next point in the
>> series uninterrupted. Usually my data file contain one value of x but
>> none of y, but alternatively a break could also appear as a NA value
>> for both x and y.
>>
>> I have found I could use the "segments" command instead of "lines",
>> but this seems to require I manipulate my data (which may or may not
>> contain breaks, and the number of breaks can vary if there are breaks
>> at all).
>>
>> Is there another command that works like "lines" but will break the
>> line if the data series suffer an interruption?
>>
>> Sincerely,
>>
>> Denis Chabot
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting- 
>> guide.html
>>



From paul.cossens at thewarehouse.co.nz  Wed Feb  8 06:08:21 2006
From: paul.cossens at thewarehouse.co.nz (Paul Cossens)
Date: Wed, 8 Feb 2006 18:08:21 +1300
Subject: [R] lme syntax for P&B examples
Message-ID: <780EF47148B1D44ABE849DBA0A93548F0DF21F@whaklexch1.thewarehousegroup.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060208/666e5de6/attachment.pl

From Augusto.Sanabria at ga.gov.au  Wed Feb  8 06:19:01 2006
From: Augusto.Sanabria at ga.gov.au (Augusto.Sanabria@ga.gov.au)
Date: Wed, 8 Feb 2006 16:19:01 +1100
Subject: [R] 15-min mean values
Message-ID: <9707EBA615A57747A0668CECD4638A3001680292@mail.agso.gov.au>


Thanks a lot to Gabor for his help with the solution
of this problem. 

The solution using "zoo(aggregate)"
is easy to implement & efficient. I have calculated 
the 15min mean values of a 1min wind speed file 
containing 2.9 million records x 16 columns 
(size 179 MB) in just 144 seconds 
(R-2.1.1 running in a GNU/LINUX machine). 

Thanks to Bogdan too for his suggested solution using
SQL, I have not tried that one yet.

Augusto



From stepanchuk at wiwi.uni-frankfurt.de  Wed Feb  8 09:49:27 2006
From: stepanchuk at wiwi.uni-frankfurt.de (Tetyana Stepanchuk)
Date: Wed, 8 Feb 2006 09:49:27 +0100
Subject: [R] bayesm, rmnlIndepMetrop
Message-ID: <20060208085118.8A089A4C920@much-magic.wiwi.uni-frankfurt.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060208/5162b6eb/attachment.pl

From francoisromain at free.fr  Wed Feb  8 09:51:26 2006
From: francoisromain at free.fr (Romain Francois)
Date: Wed, 08 Feb 2006 09:51:26 +0100
Subject: [R] difference between rnorm(1000, 0, 1) and running rnorm(500,
 0, 1) twice
In-Reply-To: <BAY110-F4B7483709FF7485B32C6FC7000@phx.gbl>
References: <BAY110-F4B7483709FF7485B32C6FC7000@phx.gbl>
Message-ID: <43E9B10E.6080409@free.fr>

Le 08.02.2006 04:21, Taka Matzmoto a ??crit :

>Hi R users
>
>This looks a simple question
>
>Is there any difference between between rnorm(1000,0,1) and running 
>rnorm(500,0,1) twice in terms of outcome ?
>
>TM
>  
>
Not here :

R> set.seed(1)
R> x <- rnorm(1000, 0, 1)
R> set.seed(1)
R> y <- rnorm(500, 0, 1)
R> z <- rnorm(500, 0, 1)
R> all(x == c(y,z))
[1] TRUE

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From Markus.Preisetanz at clientvela.com  Wed Feb  8 10:06:58 2006
From: Markus.Preisetanz at clientvela.com (Markus Preisetanz)
Date: Wed, 8 Feb 2006 10:06:58 +0100
Subject: [R] ARULES --> Filtering Rules by RHS
Message-ID: <79799E69EA1DA246A51F983B5663BEA2CD34B9@server2.hq.clientvela.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060208/49e86039/attachment.pl

From phgrosjean at sciviews.org  Wed Feb  8 10:08:18 2006
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed, 08 Feb 2006 10:08:18 +0100
Subject: [R] difference between rnorm(1000, 0, 1) and running rnorm(500,
 0, 1) twice
In-Reply-To: <43E9B10E.6080409@free.fr>
References: <BAY110-F4B7483709FF7485B32C6FC7000@phx.gbl>
	<43E9B10E.6080409@free.fr>
Message-ID: <43E9B502.8030602@sciviews.org>

Romain Francois wrote:
> Le 08.02.2006 04:21, Taka Matzmoto a ??crit :
> 
> 
>>Hi R users
>>
>>This looks a simple question
>>
>>Is there any difference between between rnorm(1000,0,1) and running 
>>rnorm(500,0,1) twice in terms of outcome ?
>>
>>TM
>> 
>>
> 
> Not here :
> 
> R> set.seed(1)
> R> x <- rnorm(1000, 0, 1)
> R> set.seed(1)
> R> y <- rnorm(500, 0, 1)
> R> z <- rnorm(500, 0, 1)
> R> all(x == c(y,z))
> [1] TRUE
> 
> Romain

Indeed! The pseudo-random number generator is initialized at the same 
state, and thus, returns the same 1000 pseudo-random numbers in both 
cases. So, no differences.
Best,

Philippe Grosjean



From Markus.Preisetanz at clientvela.com  Wed Feb  8 10:15:08 2006
From: Markus.Preisetanz at clientvela.com (Markus Preisetanz)
Date: Wed, 8 Feb 2006 10:15:08 +0100
Subject: [R] Graphics Package --> stars()
Message-ID: <79799E69EA1DA246A51F983B5663BEA2CD34BC@server2.hq.clientvela.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060208/e93eb502/attachment.pl

From srjafarzadeh at gmail.com  Wed Feb  8 10:21:43 2006
From: srjafarzadeh at gmail.com (Seyed Reza Jafarzadeh)
Date: Wed, 8 Feb 2006 01:21:43 -0800
Subject: [R] How to install the server version of rpad
Message-ID: <83217d00602080121x5c1aa36cx1451250ac5703f88@mail.gmail.com>

Hi,

How can I install the server version of rpad on a website. I have read
the instructions in http://www.rpad.org/Rpad/ServerNotes.html, but
could not figure out how. Do I have to have something like Apache on
the website? Is there any instructions in addition to those on
http://www.rpad.org/Rpad/.

Thanks,
- Reza



From m_osm at gmx.net  Wed Feb  8 10:42:43 2006
From: m_osm at gmx.net (Mahdi Osman)
Date: Wed, 8 Feb 2006 10:42:43 +0100 (MET)
Subject: [R] lme help
Message-ID: <10633.1139391763@www052.gmx.net>

Hi list,


I am fitting microarray data (intensity) model using the lme package in R
environment. I have 5 fixed variables in the model. One of the fixed
variables is genes. I am trying to get p-values for  different genes. But I
am getting only one p-value for all genes together. I can get a list of
p-value when I run lm. Why can't this work in lme?

My aim is to do multiple comaprison of all the genes that I have and I can
only do this if I have a list of their p-vales


I was wondering if you can help me solve this problem. That is getting
a list of p-value for each gene in the model using the lme.


Thanks in advance for your help


Regards



Mahdi 

-- 
-----------------------------------
Mahdi Osman (PhD)
E-mail: m_osm at gmx.net



From bhs2 at mevik.net  Wed Feb  8 10:53:42 2006
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Wed, 08 Feb 2006 10:53:42 +0100
Subject: [R] difference between rnorm(1000, 0, 1) and running rnorm(500,
 0, 1) twice
In-Reply-To: <BAY110-F4B7483709FF7485B32C6FC7000@phx.gbl> (Taka Matzmoto's
	message of "Tue, 07 Feb 2006 21:21:43 -0600")
References: <BAY110-F4B7483709FF7485B32C6FC7000@phx.gbl>
Message-ID: <m0d5hy9nx5.fsf@bar.nemo-project.org>

Why don't you test it yourself?

E.g.,

set.seed(42)
bob1 <- rnorm(1000,0,1)
set.seed(42)
bob2 <- rnorm(500,0,1)
bob3 <- rnorm(500,0,1)
identical(bob1, c(bob2, bob3))

I won't tell you the answer. :-)

-- 
Bj??rn-Helge Mevik



From hvillalo at ipn.mx  Wed Feb  8 10:56:27 2006
From: hvillalo at ipn.mx (Hector Villalobos Ortiz)
Date: Wed, 08 Feb 2006 03:56:27 -0600
Subject: [R] problem with maptree
Message-ID: <web-6800345@ipn.mx>

Hello,

I'm trying to draw a simplified tree of a cluster object 
with maptree, but I get an error message:

	> class(vars.agn)
	[1] "agnes" "twins"

	> draw.clust (clip.clust (vars.agn, k=5))
	Error in "names<-.default"(`*tmp*`, value = c("merge", 
"height", "order",'names' attribute [8] must be the same 
length as the vector [7]

Trying converting first to object of class "hclust":

	> draw.clust (clip.clust (as.hclust(vars.agn), k=5))
	Error in split(x, f) : first argument must be a vector

But conversion seems to work fine:

	> vars.hclust=as.hclust(vars.agn)
	> vars.hclust

	Call:
	agnes(x = daisy(vars.cluster), diss = TRUE, method = 
"ward")

	Cluster method   : ward
	Number of objects: 295


	> draw.clust (clip.clust (vars.hclust, k=5))
	Error in split(x, f) : first argument must be a vector


A previous version of maptree successfully clipped the 
three from the same data. Any orientation will be greatly 
appreciated.
Thank you in advance.

-- 
H??ctor Villalobos <hvillalo at ipn.mx>
  IPN-CICIMAR. A.P. 592. Col. Centro
  La Paz, Baja California Sur, M??XICO. 23000



From sumantab at ambaresearch.com  Wed Feb  8 11:21:13 2006
From: sumantab at ambaresearch.com (Sumanta Basak)
Date: Wed, 8 Feb 2006 15:51:13 +0530
Subject: [R] Bloomberg Data Import to R
Message-ID: <14850601FF012647A90A5DB31F96DB37410CF7@INBLRDC01.BANG.irpvl.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060208/c210e95e/attachment.pl

From iaingallagher at btopenworld.com  Wed Feb  8 11:33:53 2006
From: iaingallagher at btopenworld.com (Iain Gallagher)
Date: Wed, 08 Feb 2006 10:33:53 +0000
Subject: [R] rotating axis / mtext labels
Message-ID: <43E9C911.8070609@btopenworld.com>

Hello list.

Is it possible to use par(srt=45) to rotate text by 45 degrees along the 
x-axis of a plot. Using:

<code>

x_names<-c("C57 Nv", "C57 Vacc", "129 Nv", "129 Vacc", "IFNgR Nv", "IFNgR Vacc")
par(srt=45)
mtext(font=2, x_names, side=1, line=1, at=l, cex=1.2)
par(srt=0)

</code>

doesn't seem to work in R 2.2.0 on SUSE linux.

Suggestions would be appreciated thanks.

Iain



From sara at gmesintra.com  Wed Feb  8 11:45:18 2006
From: sara at gmesintra.com (Sara Mouro)
Date: Wed, 8 Feb 2006 10:45:18 -0000
Subject: [R] Reference for R
Message-ID: <200602081045.k18AjJsa030919@hypatia.math.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060208/c8c6c553/attachment.pl

From jsandblom at gmail.com  Wed Feb  8 11:57:13 2006
From: jsandblom at gmail.com (Johan Sandblom)
Date: Wed, 8 Feb 2006 11:57:13 +0100
Subject: [R] Reference for R
In-Reply-To: <200602081045.k18AjJsa030919@hypatia.math.ethz.ch>
References: <200602081045.k18AjJsa030919@hypatia.math.ethz.ch>
Message-ID: <97a06f070602080257p170c8904q@mail.gmail.com>

citation()

2006/2/8, Sara Mouro <sara at gmesintra.com>:
> Hello!
>
>
>
> Could anyone please tell me how should I include R in a text section for
> References?
>
>
>
> Regards,
>
> Sara Mouro
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--
Johan Sandblom  N8, MRC, Karolinska sjh
t +46851776108  17176 Stockholm
m +46735521477  Sweden
"What is wanted is not the will to believe, but the
will to find out, which is the exact opposite"
- Bertrand Russell



From iaingallagher at btopenworld.com  Wed Feb  8 11:57:44 2006
From: iaingallagher at btopenworld.com (IAIN GALLAGHER)
Date: Wed, 8 Feb 2006 10:57:44 +0000 (GMT)
Subject: [R] Reference for R
In-Reply-To: <200602081045.k18AjJsa030919@hypatia.math.ethz.ch>
Message-ID: <20060208105744.62804.qmail@web86702.mail.ukl.yahoo.com>

Hi Sara.

>From the R faq here:
http://cran.r-project.org/doc/FAQ/R-FAQ.html#Citing-R

2.8 Citing R

To cite R in publications, use

     @Manual{,
       title        = {R: A Language and Environment
for Statistical
                       Computing},
       author       = {{R Development Core Team}},
       organization = {R Foundation for Statistical
Computing},
       address      = {Vienna, Austria},
       year         = 2005,
       note         = {{ISBN} 3-900051-07-0},
       url          = {http://www.R-project.org}
     }

Citation strings (or BibTeX entries) for R and R
packages can also be obtained by citation(). 

Cheers

Iain

--- Sara Mouro <sara at gmesintra.com> wrote:

> Hello!
> 
>  
> 
> Could anyone please tell me how should I include R
> in a text section for
> References?
> 
>  
> 
> Regards,
> 
> Sara Mouro
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From sara at gmesintra.com  Wed Feb  8 12:55:19 2006
From: sara at gmesintra.com (Sara Mouro)
Date: Wed, 8 Feb 2006 11:55:19 -0000
Subject: [R] large lines of data
Message-ID: <200602081155.k18BtOee017303@hypatia.math.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060208/986c650a/attachment.pl

From B.Rowlingson at lancaster.ac.uk  Wed Feb  8 13:00:36 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 08 Feb 2006 12:00:36 +0000
Subject: [R] large lines of data
In-Reply-To: <200602081155.k18BtOee017303@hypatia.math.ethz.ch>
References: <200602081155.k18BtOee017303@hypatia.math.ethz.ch>
Message-ID: <43E9DD64.30408@lancaster.ac.uk>

Sara Mouro wrote:
> Dear All,
> 
>  
> 
> I have to enter many lines of data in the same object.
> 
> I usually use copy-paste to transfer data from an Word file to R.
> 

> What is the best way to do that?

  Use 'Save As' to save your Word file - or rather just the data section 
- as a plain text or Ascii file. Then read into R with scan() or 
read.table() as appropriate.


Barry



From sdavis2 at mail.nih.gov  Wed Feb  8 12:59:56 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 08 Feb 2006 06:59:56 -0500
Subject: [R] large lines of data
In-Reply-To: <200602081155.k18BtOee017303@hypatia.math.ethz.ch>
Message-ID: <C00F476C.5603%sdavis2@mail.nih.gov>




On 2/8/06 6:55 AM, "Sara Mouro" <sara at gmesintra.com> wrote:

> Dear All,
> 
>  
> 
> I have to enter many lines of data in the same object.
> 
> I usually use copy-paste to transfer data from an Word file to R.
> 
> But, for large lines of data, R gets "confused" and gives an error message,
> i.e. it breaks one line somewhere, and lines get no meaning at all.
> 
>  
> 
> Some times I solve that problem adding "enters" and making each line
> shorter, before I do copy-paste. Some times I add "spaces" in the word
> document, until R breaks each line (automatically adds a +) in any point
> where it still correct..
> 
> But it stills too "subjective" for me!   :o\
> 
>  
> 
> What is the best way to do that?

I assume you mean that you are editing "code" and then pasting into R.  If
so, you might look into using one of several editors that "work with" R.
Look in the mail archives for some of these.

Sean



From ramasamy at cancer.org.uk  Wed Feb  8 13:05:36 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 08 Feb 2006 12:05:36 +0000
Subject: [R] (second round) creating a certain type of matrix
In-Reply-To: <BAY110-F325D0A435A24692F05365C7010@phx.gbl>
References: <BAY110-F325D0A435A24692F05365C7010@phx.gbl>
Message-ID: <1139400336.3242.21.camel@dhcp-82.wolf.ox.ac.uk>

I cleaned up your function a bit but please double check

 generate.matrix <- function(nr, runs=5){

   h   <- nr/2                                ## half of nr
   nc  <- nr/10 + 1

   mat <- matrix(0, nr, nc)                   ## initialize
   
   mat[ ,1] <- c( rep(1, h), rnorm(h) )       ## 1st column
   mat[ (h+1):(h+5), 2] <- rnorm(5)           ## 2nd column
  
   if( nc > 3 ){
    for (i in 3:nc){                          ## column 3 - end
    
      start <-  h + 5*(i-2) + 1
      end   <-  start + runs - 1
    
      mat[ start:end, i] <- rnorm( runs )    
    }
   }
   return(mat)
 } 


However you can simplify this greatly. If you ignore the first column
(which looks like some initialisation column in simulation process),
then you have a matrix with nr/2 rows and nr/10 columns with diagonal
blocks 5 runs filled with rnorm values. Here is what I propose :


 gen.mat <- function(x, runs=5){

   if( (x %% 2*runs)!=0 ) stop(x, " is not a multiple of ", 2*runs)

   nr  <- x/2                   
   nc  <- x/(2*runs)

   mat <- matrix(0, nr, nc)  
   for (i in 1:nc) mat[ ((i-1)*runs + 1) : (i*runs), i ] <- rnorm(runs)
  
   down <- cbind( rnorm(nr), mat )
   top  <- cbind( 1, matrix( 0, nr=nr, nc=nc ) )
   out  <- rbind( top, down )
  
   return(out)
 }

# Examples 
 gen.mat(50)
 gen.mat(55)         ## should generate an error
 gen.mat(24, runs=6)


Does this function do what you want to ?

Regards, Adai





On Tue, 2006-02-07 at 11:03 -0600, Taka Matzmoto wrote:
> Hi R users
> Here is what I got with help from Petr Pikal (Thanks Petr Pikal). I modified 
> Petr Pikal's code to a little
> to meet my purpose.
> 
> I created a function to generate a matrix
> 
> generate.matrix<-function(n.variable)
> {
> mat<-matrix(0,n.variable,(n.variable/2)/5+1) #matrix of zeroes
> dd<-dim(mat) # actual dimensions
> mat[1:(dd[1]/2),1]<-1 #put 1 in first half of first column
> mat[((dd[1]/2)+1):dd[1],1]<-rnorm(dd[1]/2,0,1) #put random numbers in 
> following part of the matrix column 1
> mat[((dd[1]/2)+1):((dd[1]/2)+5),2]<-rnorm(5,0,1) #put random numbers in 
> column2
> for (i in 3:(dd[2]))
>     {
>         length.of.rand.numbers <- 5
>         my.rand.num<- rnorm(length.of.rand.numbers, 0,1)
>         start <- dd[1]/2+5*(i-2)+1
>         end <- start + length.of.rand.numbers-1
>         mat[((start):end), i]<- my.rand.num
>     }
> mat
> }
> 
> Do you (any R users) have any suggestion to this function to make this 
> function work better or efficiently?
> 
> Taka
> It works but I
> 
> >From: "Petr Pikal" <petr.pikal at precheza.cz>
> >To: "Taka Matzmoto" <sell_mirage_ne at hotmail.com>,r-help at stat.math.ethz.ch
> >Subject: Re: [R] creating a certain type of matrix
> >Date: Tue, 07 Feb 2006 08:58:59 +0100
> >MIME-Version: 1.0
> >Received: from mail.precheza.cz ([80.188.29.243]) by 
> >bay0-mc8-f13.bay0.hotmail.com with Microsoft SMTPSVC(6.0.3790.211); Mon, 6 
> >Feb 2006 23:59:02 -0800
> >Received: from localhost (localhost [127.0.0.1])by mail.precheza.cz 
> >(Mailer) with ESMTP id A636C34E584;Tue,  7 Feb 2006 08:59:00 +0100 (CET)
> >Received: from mail.precheza.cz ([127.0.0.1])by localhost (mail.precheza.cz 
> >[127.0.0.1]) (amavisd-new, port 10024)with LMTP id 28608-02-30; Tue, 7 Feb 
> >2006 08:58:59 +0100 (CET)
> >Received: from n1en1.precheza.cz (smtp.precheza.cz [192.168.210.31])by 
> >mail.precheza.cz (Mailer) with ESMTP id 35E8634E582;Tue,  7 Feb 2006 
> >08:58:59 +0100 (CET)
> >Received: from pikal ([192.168.210.65])          by n1en1.precheza.cz 
> >(Lotus Domino Release 6.5.4FP2)          with ESMTP id 2006020708585800-252 
> >;          Tue, 7 Feb 2006 08:58:58 +0100 X-Message-Info: 
> >JGTYoYF78jEHjJx36Oi8+Z3TmmkSEdPtfpLB7P/ybN8=
> >X-Confirm-Reading-To: "Petr Pikal" <petr.pikal at precheza.cz>
> >X-pmrqc: 1
> >Return-Receipt-To: "Petr Pikal" <petr.pikal at precheza.cz>
> >Priority: normal
> >X-mailer: Pegasus Mail for Windows (4.21c)
> >X-MIMETrack: Itemize by SMTP Server on SRVDomino/PRECHEZA(Release 6.5.4FP2 
> >| September 26, 2005) at 07.02.2006 08:58:58,Serialize by Router on 
> >SRVDomino/PRECHEZA(Release 6.5.4FP2 | September 26, 2005) at 07.02.2006 
> >08:58:58,Serialize complete at 07.02.2006 08:58:58
> >X-Virus-Scanned: by amavisd-new-20030616-p10 (Debian) at precheza.cz
> >Return-Path: petr.pikal at precheza.cz
> >X-OriginalArrivalTime: 07 Feb 2006 07:59:03.0289 (UTC) 
> >FILETIME=[5C87D690:01C62BBC]
> >
> >Hi
> >
> >as only you know perfectly which halves and other portions of your
> >matrices contain zeroes and which contain random numbers you has to
> >finalize the function yourself.
> >Here are few ideas.
> >
> >n<-20
> >mat<-matrix(0,n,(n/2)/5+1) #matrix of zeroes
> >dd<-dim(mat) # actual dimensions
> >mat[1:(dd[1]/2),1]<-1 #put 1 in first half of first column
> >mat[((dd[1]/2)+1):dd[1],1]<-rnorm(dd[1]/2,0,1) #put random numbers in
> >following part of the matrix column 1
> >mat[((dd[1]/2)+1):(dd[1]/2)+dd[1]/4,2]<-rnorm(dd[1]/4,0,1) #put
> >random numbers in column2
> >
> >than according to n and dd values you can put any numbers anywhere in
> >your matrix e.g. in for loop (not.tested :-)
> >
> >for (i in 3:dd[2]) {
> >
> >arrange everything into following desired columns
> >e.g.
> >
> >length.of.rand.numbers <- (i-2)*5
> >my.rand.num<- rnorm(length.of.rand.numbers, 0,1)
> >start <- dd[1]/2+dd[1]/4
> >end <- start + length.of.rand.numbers
> >mat[start:end, i]<- my.rand.num
> >
> >}
> >
> >HTH
> >Petr
> >
> >On 7 Feb 2006 at 0:07, Taka Matzmoto wrote:
> >
> >From:           	"Taka Matzmoto" <sell_mirage_ne at hotmail.com>
> >To:             	r-help at stat.math.ethz.ch
> >Date sent:      	Tue, 07 Feb 2006 00:07:11 -0600
> >Subject:        	[R] creating a certain type of matrix
> >
> > > Hi R users
> > >
> > > I like to generate a certain type of  matrix.
> > > If there are 10 variables, the matrix will have nrow=10,
> > > ncol=((10/2))/5+1. so the resulting matrix's dimension 10 by 2. If
> > > there are 50 variables the dimension of the resulting matrix will be
> > > 50 by 6.
> > >
> > > The arrangement of elements of this matrix is important to me and I
> > > can't figure out how to arrange elements.
> > >
> > > If I have 20 variables. The resulting matrix will be 20 by 3
> > > The first half of first column of the matrix will be 1s. The all
> > > elements on the second half of the first column of the matrix will be
> > > random numbers coming from rnorm(1,0,1). The first half of the second
> > > column of the matrix will be zeros. The first five elements of the
> > > second half of the second column of the matrix will be random numbers
> > > coming from rnorm(1,0,1). After that, the remaining elements of the
> > > second half will be zeros. The first half of the third column of the
> > > matrix will be zeors. The first five elements of the second half of
> > > the third column will be zeros too and then 5 random numbers coming
> > > from rnorm(1,0,1).
> > >
> > > If there are 40 variables the resulting matrix will be 40*5
> > > The first half of first column of the matrix will be 1s. The all
> > > elements on the second half of the first column of the matrix will be
> > > random numbers coming from rnorm(1,0,1).
> > >
> > > The first half of the second column of the matrix will be zeros. The
> > > first five elements of the second half of the second column of the
> > > matrix will be random numbers coming from rnorm(1,0,1). After that,
> > > the remaining elements of the second half will be zeros.
> > >
> > > The first half of the third column of the matrix will be zeors. The
> > > first FIVE elements of the second half of the third column will be
> > > zeros too and then 5 random numbers coming from rnorm(1,0,1) and then
> > > the rest of elements of the third column will be zeros.
> > >
> > > The first half of the fourth column of the matrix will be zeors.The
> > > first TEN elements of the second half of the fourth column will be
> > > zeros too and then 5 random numbers coming from rnorm(1,0,1) and then
> > > the rest of elements of the third column will be zeros.
> > >
> > > The first half of the fifth column of the matrix will be zeors.The
> > > first FIFTEEN elements of the second half of the fourth column will be
> > > zeros too and then 5 random numbers coming from rnorm(1,0,1).
> > >
> > > I tried to create 10 different functions ( one for 10, 20, 30, 40,
> > > .... , 100 variables) but it's not efficient.
> > >
> > > Any help or advice for creating one function that can do all 10 kind
> > > of variable cases would be appreciated.
> > >
> > > Thans in advance
> > >
> > > Taka
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> >
> >Petr Pikal
> >petr.pikal at precheza.cz
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ramasamy at cancer.org.uk  Wed Feb  8 13:15:18 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 08 Feb 2006 12:15:18 +0000
Subject: [R] large lines of data
In-Reply-To: <200602081155.k18BtOee017303@hypatia.math.ethz.ch>
References: <200602081155.k18BtOee017303@hypatia.math.ethz.ch>
Message-ID: <1139400919.3242.27.camel@dhcp-82.wolf.ox.ac.uk>

How does the data look and how are you storing in R (e.g. matrix, list)?

I think this an issue related to Word where it is using either unequal
spaces or different carriage returns. I would not recommend storing
data, especially numerical ones in the form of a matrix, in Word files. 

I would recommend that you try to copy-and-paste into Excel first and
clean it up there. Next save the file as tab delimited and use
read.delim() in R. 

My experience is that that Excel seems understands the oddities of Word
better than R does.

Regards, Adai


On Wed, 2006-02-08 at 11:55 +0000, Sara Mouro wrote:
> Dear All,
> 
>  
> 
> I have to enter many lines of data in the same object.
> 
> I usually use copy-paste to transfer data from an Word file to R.
> 
> But, for large lines of data, R gets "confused" and gives an error message,
> i.e. it breaks one line somewhere, and lines get no meaning at all.
> 
>  
> 
> Some times I solve that problem adding "enters" and making each line
> shorter, before I do copy-paste. Some times I add "spaces" in the word
> document, until R breaks each line (automatically adds a +) in any point
> where it still correct..
> 
> But it stills too "subjective" for me!   :o\
> 
>  
> 
> What is the best way to do that?
> 
>  
> 
> 
> 
> Regards,
> 
> Sara Mouro
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Wed Feb  8 13:17:28 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 08 Feb 2006 13:17:28 +0100
Subject: [R] rotating axis / mtext labels
In-Reply-To: <43E9C911.8070609@btopenworld.com>
References: <43E9C911.8070609@btopenworld.com>
Message-ID: <43E9E158.1020204@statistik.uni-dortmund.de>

Iain Gallagher wrote:

> Hello list.
> 
> Is it possible to use par(srt=45) to rotate text by 45 degrees along the 
> x-axis of a plot. Using:
> 
> <code>
> 
> x_names<-c("C57 Nv", "C57 Vacc", "129 Nv", "129 Vacc", "IFNgR Nv", "IFNgR Vacc")
> par(srt=45)
> mtext(font=2, x_names, side=1, line=1, at=l, cex=1.2)
> par(srt=0)
> 
> </code>
> 
> doesn't seem to work in R 2.2.0 on SUSE linux.
> 
> Suggestions would be appreciated thanks.


mtext does not support string rotation. You can rather use text() with 
par(xpd=TRUE) if you need it.

Uwe Ligges

> Iain
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ramasamy at cancer.org.uk  Wed Feb  8 13:16:48 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 08 Feb 2006 12:16:48 +0000
Subject: [R] lme help
In-Reply-To: <10633.1139391763@www052.gmx.net>
References: <10633.1139391763@www052.gmx.net>
Message-ID: <1139401008.3242.30.camel@dhcp-82.wolf.ox.ac.uk>

Please read the posting 
1) I think BioConductor mailing list might be better as some of these
could be implemented via LIMMA (I believe)
2) Provide sufficient information and perhaps a simple example.

Regards, Adai



On Wed, 2006-02-08 at 10:42 +0100, Mahdi Osman wrote:
> Hi list,
> 
> 
> I am fitting microarray data (intensity) model using the lme package in R
> environment. I have 5 fixed variables in the model. One of the fixed
> variables is genes. I am trying to get p-values for  different genes. But I
> am getting only one p-value for all genes together. I can get a list of
> p-value when I run lm. Why can't this work in lme?
> 
> My aim is to do multiple comaprison of all the genes that I have and I can
> only do this if I have a list of their p-vales
> 
> 
> I was wondering if you can help me solve this problem. That is getting
> a list of p-value for each gene in the model using the lme.
> 
> 
> Thanks in advance for your help
> 
> 
> Regards
> 
> 
> 
> Mahdi 
>



From aleid2001 at yahoo.com  Wed Feb  8 13:18:23 2006
From: aleid2001 at yahoo.com (aleid2001@yahoo.com)
Date: Wed, 8 Feb 2006 12:18:23 +0000 (GMT)
Subject: [R] Mixture normal distribution
Message-ID: <20060208121823.11165.qmail@web52802.mail.yahoo.com>

Dear R helper,


I hope that u can help me to sort out my problem
because I sent an E-mail last night to R-list but I
have not receive any help and at the same time I think
this problem is not so hard.

I have used the following functions before 

> K<-10
> prime<-c(2,3,5,7,11,13,17)
> UN<-seq(1:K)%*%t(sqrt(prime))
> U1<-UN-as.integer(UN)
> U<-matrix(qnorm(U1),K,7)
> U

            [,1]        [,2]        [,3]        [,4]  
     [,5]       [,6]
 [1,] -0.2167193  0.61902728 -0.71900806  0.37387492
-0.47715805  0.2677426
 [2,]  0.9479680 -0.09010569 -0.06990169 -0.54900030 
0.34047235 -0.8026015
 [3,] -0.6978334 -0.85544499  0.54814530  1.53212280 
1.64363675  0.9026864
 [4,]  0.4038929  1.46253909  1.59168198  0.20958766
-0.62343558 -0.1962555
 [5,] -1.4678844  0.41315654 -0.91407055 -0.74294809 
0.20989183 -1.9148412
 [6,] -0.0369025 -0.27331681 -0.21109168  1.14796196 
1.28012119  0.3406266
 [7,]  1.2786790 -1.15348516  0.39201340  0.05080407
-0.78449952 -0.7099779
 [8,] -0.4853656  1.06431267  1.21882042 -0.97005119 
0.08280907  1.0127500
 [9,]  0.6065405  0.22357828 -1.15223725  0.88440727 
1.03481830 -0.1257587
[10,] -1.0707736 -0.46627852 -0.35664238 -0.10670096
-0.96909898 -1.5936006
             [,7]
 [1,] -1.15960110
 [2,] -0.68646092
 [3,] -0.33366316
 [4,] -0.01899511
 [5,]  0.29375681
 [6,]  0.63913903
 [7,]  1.08816734
 [8,]  2.16601566
 [9,] -1.23750068
[10,] -0.73537275


Now I want instead of using (qnorm) the inverse of
slandered normal distribution, I want to use the
mixture of normal distribution, and also, I want to
know how to read the data to txt file.


Many thanks for your help in advance.

Al-Eid



		
___________________________________________________________ 
Win a BlackBerry device from O2 with Yahoo!. Enter now. http://www.yahoo.co.uk/blackberry



From ramasamy at cancer.org.uk  Wed Feb  8 13:23:38 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 08 Feb 2006 12:23:38 +0000
Subject: [R] Application of R
In-Reply-To: <cafcabf80602070552p6ec38ba6xfc5aa7cb6a61f01c@mail.gmail.com>
References: <cafcabf80602070552p6ec38ba6xfc5aa7cb6a61f01c@mail.gmail.com>
Message-ID: <1139401418.3242.37.camel@dhcp-82.wolf.ox.ac.uk>

No Excel attachment came through. 

Just taking a guess here but there seems to be very little variation the
columns V10 till column V23.

BTW, can you not issue the following call :

 mydata[ , 1:7] ~ mydata[ , 8] + mydata[ ,9]

instead of creating y1, y2, ... separately then cbind-ing them ?

Regards, Adai




On Tue, 2006-02-07 at 21:52 +0800, Andy Wong wrote:
> I have applied the R and MNP to carry out the data analysis.  However, there
> is an error called SWP : singular matrix.  Can someone tell me what is the
> problem of my formula or the file "mydata".
> 
> I have attached the data file "mydata" in Excel format and the result
> printed in pdf format for your information.
> 
> Thanks for your advice.
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From murdoch at stats.uwo.ca  Wed Feb  8 13:22:09 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 08 Feb 2006 07:22:09 -0500
Subject: [R] difference between rnorm(1000, 0, 1) and running rnorm(500,
 0, 1) twice
In-Reply-To: <m0d5hy9nx5.fsf@bar.nemo-project.org>
References: <BAY110-F4B7483709FF7485B32C6FC7000@phx.gbl>
	<m0d5hy9nx5.fsf@bar.nemo-project.org>
Message-ID: <43E9E271.7060905@stats.uwo.ca>

On 2/8/2006 4:53 AM, Bj??rn-Helge Mevik wrote:
> Why don't you test it yourself?
> 
> E.g.,
> 
> set.seed(42)
> bob1 <- rnorm(1000,0,1)
> set.seed(42)
> bob2 <- rnorm(500,0,1)
> bob3 <- rnorm(500,0,1)
> identical(bob1, c(bob2, bob3))
> 
> I won't tell you the answer. :-)

This isn't really something that can be proved by a test.  Perhaps the 
current implementation makes those equal only because 500 is even, or 
divisible by 5, or whatever...

I think the intention is that those should be equal, but in a quick 
search I've been unable to find a documented guarantee of that.  So I 
would take a defensive stance and assume that there may be conditions 
where c(rnorm(m), rnorm(n)) is not equal to rnorm(m+n).

If someone can point out the document I missed, I'd appreciate it.

Duncan Murdoch



From roger.bos at gmail.com  Wed Feb  8 13:50:10 2006
From: roger.bos at gmail.com (roger bos)
Date: Wed, 8 Feb 2006 07:50:10 -0500
Subject: [R] How to install the server version of rpad
In-Reply-To: <83217d00602080121x5c1aa36cx1451250ac5703f88@mail.gmail.com>
References: <83217d00602080121x5c1aa36cx1451250ac5703f88@mail.gmail.com>
Message-ID: <1db726800602080450s4342b079y57c1274896317b4d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060208/fe4b0257/attachment.pl

From HDoran at air.org  Wed Feb  8 14:01:03 2006
From: HDoran at air.org (Doran, Harold)
Date: Wed, 8 Feb 2006 08:01:03 -0500
Subject: [R] lme syntax for P&B examples
Message-ID: <F5ED48890E2ACB468D0F3A64989D335A01ADED95@dc1ex3.air.org>

Paul:

It is a little difficult to understand what you are trying to translate
since you do not show what the model would look like using lme. If you
show lme, then it is easy to translate into lmer syntax.

A few thoughts, first, use lmer in the Matrix package and not in lme4.
Second, see the Bates article in R news at the link below for dealing
with nesting structures. Last, a colleague and I have a paper in press
showing how to fit models using lme which we submitted a year or so ago.
Since lme has evolved to lmer, we created an appendix that translates
all of our lme models to the lmer syntax so readers can see
equivalences. I am happy to send this to you (or others) upon request.

http://cran.r-project.org/doc/Rnews/Rnews_2005-1.pdf

Harold


 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Paul Cossens
Sent: Wednesday, February 08, 2006 12:08 AM
To: r-help at stat.math.ethz.ch
Subject: [R] lme syntax for P&B examples

Hi helpeRs,
 
I've been working through some examples in Pinhiero & Bates( 2000)
trying to understand how to translate to the new Lme4 syntax but without
much luck.
Below is what I think I should do, but either the answers don't come out
the same or I get errors. 
In the Oxide problems I'm particularly interested in obtaining the
levels coeficients but this options no longer seems to be available in
lme4. How can levels infor be obtained in lme4?
 
If someone can recreate the examples below in lme4 syntax so I can
follow what is happening in the text I'd be grateful. 
 
Cheers
 
Paul Cossens
 
 
#Pixel
# P&B(2000) p40-45
 
Pixel<-read.csv("Pixel.csv",header=TRUE);
Pixel$Side<-as.factor(Pixel$Side)
Pixel$Dog<-as.factor(Pixel$Dog)
 
(fm1Pixel <- lmer(pixel ~ day + I(day^2) +(day|Dog)+(1|Side), data =
Pixel))
(fm2Pixel <- lmer(pixel ~ day + I(day^2) +(day|Dog), data = Pixel))
(fm3Pixel <- lmer(pixel ~ day + I(day^2) +(1|Dog:Side), data = Pixel))
or should I do it this way?
Pixel$DS<-with(Pixel,Dog:Side)[drop=TRUE]
(fm3Pixel <- lmer(pixel ~ day + I(day^2) +(1|DS), data = Pixel))
 
(fm4Pixel <- lmer(pixel ~ day + I(day^2) +Side , data = Pixel))
 

#Oxide
# P&B(2000) p167-170
 
Oxide<-read.csv("Oxide.csv",header=TRUE);
Oxide$Source<-as.factor(Oxide$Source)
Oxide$Lot<-as.factor(Oxide$Lot)
Oxide$Wafer<-as.factor(Oxide$Wafer)
Oxide$Site<-as.factor(Oxide$Site)
fm1Oxide<-lmer(Thickness~ (1|Lot)+(1|Lot:Wafer),data=Oxide) )
(fm2Oxide<-lmer(Thickness~ (1|Lot),data=Oxide) )
coef(fm1Oxide)

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From Bernhard_Pfaff at fra.invesco.com  Wed Feb  8 14:10:22 2006
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Wed, 8 Feb 2006 13:10:22 -0000 
Subject: [R] Bloomberg Data Import to R
Message-ID: <25D1C2585277D311B9A20000F6CCC71B077C03FE@DEFRAEX02>

Hello Sumanto,

your question might be more appropriately been posted to the R-sig-finance
list:

r-sig-finance at stat.math.ethz.ch (I have cc'ed this mail to this list).

To my knowledge neither a function nor a CRAN-package does exist. However,
on the last useR! conference Dirk Edelbuettel presented a proprietary
package that utilised the C API of Bloomberg (type WAPI <GO> on a Bloomberg
terminal). I am not sure whether Dirk is nowadays inclined or allowed by his
employee to share this package.

As an alternative, you could download data from Bloomberg into Excel, first
(assuming that you are working in a Windows environment) and then load it
into R via RODBC, for example.

Cheers,
Bernhard



Hi R-Experts,

 

Can anyone tell me how Bloomberg data can be directly downloaded to R?
Is there any package?

Sumanta Basak.


----------------------------------------------------------------------------
---------------------------------------
This e-mail may contain confidential and/or privileged infor...{{dropped}}

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
*****************************************************************
Confidentiality Note: The information contained in this mess...{{dropped}}



From j.hadfield at sheffield.ac.uk  Wed Feb  8 14:26:24 2006
From: j.hadfield at sheffield.ac.uk (Jarrod Hadfield)
Date: Wed, 8 Feb 2006 13:26:24 +0000
Subject: [R] nested random effects in glmm.admb
Message-ID: <66f57c99f38d827ee1ef6ff06a498f09@shef.ac.uk>

Hello all,

In a previous posting regarding glmm.admb it is stated that glmm.admb 
can handle 2 nested random effects.   I can only fit a single random 
term at the moment, and wondered if anyone could  provide me with some 
information on how to specify  a model with 2 (nested or 
cross-classified) random terms?

Thanks,

Jarrod.



From MSchwartz at mn.rr.com  Wed Feb  8 14:18:57 2006
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Wed, 08 Feb 2006 07:18:57 -0600
Subject: [R] rotating axis / mtext labels
In-Reply-To: <43E9C911.8070609@btopenworld.com>
References: <43E9C911.8070609@btopenworld.com>
Message-ID: <1139404737.4502.6.camel@localhost.localdomain>

On Wed, 2006-02-08 at 10:33 +0000, Iain Gallagher wrote:
> Hello list.
> 
> Is it possible to use par(srt=45) to rotate text by 45 degrees along the 
> x-axis of a plot. Using:
> 
> <code>
> 
> x_names<-c("C57 Nv", "C57 Vacc", "129 Nv", "129 Vacc", "IFNgR Nv", "IFNgR Vacc")
> par(srt=45)
> mtext(font=2, x_names, side=1, line=1, at=l, cex=1.2)
> par(srt=0)
> 
> </code>
> 
> doesn't seem to work in R 2.2.0 on SUSE linux.
> 
> Suggestions would be appreciated thanks.
> 
> Iain


See R FAQ 7.27 How can I create rotated axis labels:

http://cran.r-project.org/doc/FAQ/R-FAQ.html#How-can-I-create-rotated-axis-labels_003f

HTH,

Marc Schwartz



From Ted.Harding at nessie.mcc.ac.uk  Wed Feb  8 14:26:13 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 08 Feb 2006 13:26:13 -0000 (GMT)
Subject: [R] difference between rnorm(1000, 0, 1) and running rnorm(5
In-Reply-To: <43E9E271.7060905@stats.uwo.ca>
Message-ID: <XFMail.060208132613.Ted.Harding@nessie.mcc.ac.uk>

On 08-Feb-06 Duncan Murdoch wrote:
> On 2/8/2006 4:53 AM, Bj??rn-Helge Mevik wrote:
>> Why don't you test it yourself?
>> 
>> E.g.,
>> 
>> set.seed(42)
>> bob1 <- rnorm(1000,0,1)
>> set.seed(42)
>> bob2 <- rnorm(500,0,1)
>> bob3 <- rnorm(500,0,1)
>> identical(bob1, c(bob2, bob3))
>> 
>> I won't tell you the answer. :-)
> 
> This isn't really something that can be proved by a test.  Perhaps the 
> current implementation makes those equal only because 500 is even, or 
> divisible by 5, or whatever...
> 
> I think the intention is that those should be equal, but in a quick 
> search I've been unable to find a documented guarantee of that.  So I 
> would take a defensive stance and assume that there may be conditions 
> where c(rnorm(m), rnorm(n)) is not equal to rnorm(m+n).
> 
> If someone can point out the document I missed, I'd appreciate it.
> 
> Duncan Murdoch

On my understanding, once the seed is set the sequence generated
by the underlying RNG is determined, whether it is the result of
a single call to produce a long sequence or multiple calls to
generate many shorter sequences. Example:

> set.seed(42)
> multi<-numeric(20)
> set.seed(42)
> single<-rnorm(20)
> set.seed(42)
> for(i in (1:20)) multi[i]<-rnorm(1)
> print(max(multi-single),digits=22)
[1] 0
> print(min(multi-single),digits=22)
[1] 0

In other words: identical!

Whether there are possible exceptions, in some implementations
of r<dist> where <dist> is other than "norm", has to be answered
by people who are familiar with the internals of these functions.

Best wishes to all,
Ted.




--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 08-Feb-06                                       Time: 13:26:10
------------------------------ XFMail ------------------------------



From ripley at stats.ox.ac.uk  Wed Feb  8 14:28:39 2006
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Wed, 8 Feb 2006 13:28:39 +0000 (GMT)
Subject: [R] Mixture normal distribution
In-Reply-To: <20060208121823.11165.qmail@web52802.mail.yahoo.com>
Message-ID: <Pine.GSO.4.31.0602081325320.26426-100000@markov.stats>

We did get your previous message.  See the posting guide about what to do
if you do not get an answer.

See MASS4, chapter 16 (and see the FAQ for what MASS4 is) for fitting
mixtures of normals and testing their fit.

> I want to know how to read the data to txt file.

What does that mean?  (You 'read from' or 'write to'.)

On Wed, 8 Feb 2006 aleid2001 at yahoo.com wrote:

> Dear R helper,
>
>
> I hope that u can help me to sort out my problem
> because I sent an E-mail last night to R-list but I
> have not receive any help and at the same time I think
> this problem is not so hard.
>
> I have used the following functions before
>
> > K<-10
> > prime<-c(2,3,5,7,11,13,17)
> > UN<-seq(1:K)%*%t(sqrt(prime))
> > U1<-UN-as.integer(UN)
> > U<-matrix(qnorm(U1),K,7)
> > U
>
>             [,1]        [,2]        [,3]        [,4]
>      [,5]       [,6]
>  [1,] -0.2167193  0.61902728 -0.71900806  0.37387492
> -0.47715805  0.2677426
>  [2,]  0.9479680 -0.09010569 -0.06990169 -0.54900030
> 0.34047235 -0.8026015
>  [3,] -0.6978334 -0.85544499  0.54814530  1.53212280
> 1.64363675  0.9026864
>  [4,]  0.4038929  1.46253909  1.59168198  0.20958766
> -0.62343558 -0.1962555
>  [5,] -1.4678844  0.41315654 -0.91407055 -0.74294809
> 0.20989183 -1.9148412
>  [6,] -0.0369025 -0.27331681 -0.21109168  1.14796196
> 1.28012119  0.3406266
>  [7,]  1.2786790 -1.15348516  0.39201340  0.05080407
> -0.78449952 -0.7099779
>  [8,] -0.4853656  1.06431267  1.21882042 -0.97005119
> 0.08280907  1.0127500
>  [9,]  0.6065405  0.22357828 -1.15223725  0.88440727
> 1.03481830 -0.1257587
> [10,] -1.0707736 -0.46627852 -0.35664238 -0.10670096
> -0.96909898 -1.5936006
>              [,7]
>  [1,] -1.15960110
>  [2,] -0.68646092
>  [3,] -0.33366316
>  [4,] -0.01899511
>  [5,]  0.29375681
>  [6,]  0.63913903
>  [7,]  1.08816734
>  [8,]  2.16601566
>  [9,] -1.23750068
> [10,] -0.73537275
>
>
> Now I want instead of using (qnorm) the inverse of
> slandered normal distribution, I want to use the
> mixture of normal distribution, and also, I want to
> know how to read the data to txt file.
>
>
> Many thanks for your help in advance.
>
> Al-Eid
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Feb  8 14:30:54 2006
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Wed, 8 Feb 2006 13:30:54 +0000 (GMT)
Subject: [R] difference between rnorm(1000, 0, 1) and running rnorm(500,
 0, 1) twice
In-Reply-To: <43E9E271.7060905@stats.uwo.ca>
Message-ID: <Pine.GSO.4.31.0602081329160.26426-100000@markov.stats>

On Wed, 8 Feb 2006, Duncan Murdoch wrote:

> On 2/8/2006 4:53 AM, Bjrn-Helge Mevik wrote:
> > Why don't you test it yourself?
> >
> > E.g.,
> >
> > set.seed(42)
> > bob1 <- rnorm(1000,0,1)
> > set.seed(42)
> > bob2 <- rnorm(500,0,1)
> > bob3 <- rnorm(500,0,1)
> > identical(bob1, c(bob2, bob3))
> >
> > I won't tell you the answer. :-)
>
> This isn't really something that can be proved by a test.  Perhaps the
> current implementation makes those equal only because 500 is even, or
> divisible by 5, or whatever...
>
> I think the intention is that those should be equal, but in a quick
> search I've been unable to find a documented guarantee of that.  So I
> would take a defensive stance and assume that there may be conditions
> where c(rnorm(m), rnorm(n)) is not equal to rnorm(m+n).
>
> If someone can point out the document I missed, I'd appreciate it.

It's various source files in R_HOME/src/main.

Barring bugs, they will be the same.  As you know

	R is free software and comes with ABSOLUTELY NO WARRANTY.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dieter.menne at menne-biomed.de  Wed Feb  8 14:33:48 2006
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Wed, 8 Feb 2006 13:33:48 +0000 (UTC)
Subject: [R] lme question
References: <19409.1139334061@www018.gmx.net>
Message-ID: <loom.20060208T143118-859@post.gmane.org>

Mahdi Osman <m_osm <at> gmx.net> writes:

> 
> Hi list,
> 
> I am fitting microarray data (intensity) model using the lme package in R
> environment. I have 5 fixed variables in the model. One of the fixed
> variables is genes. I am trying to get p-values for  different genes. But I
> am getting only one p-value for all genes together. I can get a list of
> p-value when I run lm. Why can't this work in lme?
> 
> I was wondering if some one can help me solve this problem. That is getting
> a list of p-value for each gene in the model using the lme.
> 

The bioconductor list might be a better place for this question, and an example 
would haven been welcome. So my only guess is: could it be that  you forgot to 
make genes a factor variable? When genes is a number, you get a linear 
regression which is probably not what you want.


Dieter



From finbref.2006 at gmail.com  Wed Feb  8 14:47:13 2006
From: finbref.2006 at gmail.com (Thomas Steiner)
Date: Wed, 8 Feb 2006 14:47:13 +0100
Subject: [R] print formula on plot
Message-ID: <d0f55a670602080547p1bf96d9ar@mail.gmail.com>

I estimate some parameters and I want to print them (pretty) on my plot:

# somehow estimated parameters
z<-c(1.543523e+00, 1.23453e+00, 3.454000e+00)

x<-seq(-1,1,length=100)
plot(x,z[3]*x^2+z[2]*x+z[3],type="l", main="My nice plot of the
estimated function")
zs<-format(z,digits=4,scientific=FALSE,trim=TRUE)

text(-0.9,7,expression(1.54*x^2))                   # is what I want,
but DYNAMIC
text(-0.9,6,expression(paste(zf[1],x^3)))         # not really
text(-0.9,5,expression(paste(toSting(zf[1]),x^3)))  # not really
#using z (double) instead of zf (string) does not help.

So my question is:
How do I evaluate zf[1] from the variable to it's (String) value? Here
it is used within an expression: this makes all the trouble.

Thanks for help, I tried 2 hrs now...
Thomas



From finbref.2006 at gmail.com  Wed Feb  8 15:05:16 2006
From: finbref.2006 at gmail.com (Thomas Steiner)
Date: Wed, 8 Feb 2006 15:05:16 +0100
Subject: [R] print formula on plot
In-Reply-To: <d0f55a670602080547p1bf96d9ar@mail.gmail.com>
References: <d0f55a670602080547p1bf96d9ar@mail.gmail.com>
Message-ID: <d0f55a670602080605y5229ca95j@mail.gmail.com>

I found it immediately after posting :(

substitute is my friend:

text(0.5,5,substitute(f[Sv] ==k*x^2, list(k=zf[1])))



From murdoch at stats.uwo.ca  Wed Feb  8 15:07:50 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 08 Feb 2006 09:07:50 -0500
Subject: [R] difference between rnorm(1000, 0, 1) and running rnorm(500,
 0, 1) twice
In-Reply-To: <Pine.GSO.4.31.0602081329160.26426-100000@markov.stats>
References: <Pine.GSO.4.31.0602081329160.26426-100000@markov.stats>
Message-ID: <43E9FB36.3000100@stats.uwo.ca>

On 2/8/2006 8:30 AM, Brian D Ripley wrote:
> On Wed, 8 Feb 2006, Duncan Murdoch wrote:
> 
>> On 2/8/2006 4:53 AM, Bjrn-Helge Mevik wrote:
>> > Why don't you test it yourself?
>> >
>> > E.g.,
>> >
>> > set.seed(42)
>> > bob1 <- rnorm(1000,0,1)
>> > set.seed(42)
>> > bob2 <- rnorm(500,0,1)
>> > bob3 <- rnorm(500,0,1)
>> > identical(bob1, c(bob2, bob3))
>> >
>> > I won't tell you the answer. :-)
>>
>> This isn't really something that can be proved by a test.  Perhaps the
>> current implementation makes those equal only because 500 is even, or
>> divisible by 5, or whatever...
>>
>> I think the intention is that those should be equal, but in a quick
>> search I've been unable to find a documented guarantee of that.  So I
>> would take a defensive stance and assume that there may be conditions
>> where c(rnorm(m), rnorm(n)) is not equal to rnorm(m+n).
>>
>> If someone can point out the document I missed, I'd appreciate it.
> 
> It's various source files in R_HOME/src/main.
> 
> Barring bugs, they will be the same.  As you know
> 
> 	R is free software and comes with ABSOLUTELY NO WARRANTY.

I didn't mean guarantee in the sense of warranty, just guarantee in the 
sense that if someone found a situation where they weren't equal, we 
would consider it a bug and fix it or document it as an exception.

Should we add a statement to the RNG man page or manuals somewhere that 
says this is the intention?

For others who aren't as familiar with the issues as Brian: this isn't 
necessarily a good idea.  We have a lot of RNGs, and it's fairly easy to 
write one so that this isn't true.  For example, the Box-Muller method 
naturally generates pairs of normals; a naive implementation would just 
throw one away at the end if asked for an odd number.  (Ours doesn't do 
that.)

Duncan Murdoch



From karin.lagesen at medisin.uio.no  Wed Feb  8 15:18:08 2006
From: karin.lagesen at medisin.uio.no (Karin Lagesen)
Date: Wed, 08 Feb 2006 15:18:08 +0100
Subject: [R] font size/disappearing labels
Message-ID: <ypx6vevqorxb.fsf@uracil.uio.no>


I am using vioplot to make nice boxplots, which I am outputting to
postscript. I am using the paper=special and width and height to get
the graphs to look nice. I do however have a problem with the size of
the labels and titles. When I set fontsize as an option to the
postscript call too high, one of the labels disappear, although there
is enough space for it (imo, that is). This I have understood is an
effect of the system trying to avoid overlapping numbers. Is there a
way I can override this function though? Can I force it to show all of
the labels, although they might be "too close"?

Karin
-- 
Karin Lagesen, PhD student
karin.lagesen at medisin.uio.no
http://www.cmbn.no/rognes/



From bhs2 at mevik.net  Wed Feb  8 15:21:54 2006
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Wed, 08 Feb 2006 15:21:54 +0100
Subject: [R] Using R to process spectroscopic data
In-Reply-To: <43E8A2E3.7010100@biw.kuleuven.be> (Dirk De Becker's message of
	"Tue, 07 Feb 2006 14:38:43 +0100")
References: <43E8A2E3.7010100@biw.kuleuven.be>
Message-ID: <m08xsm9bi5.fsf@bar.nemo-project.org>

Dirk De Becker wrote:

> * Determine the range of the spectrum to be used -> For this, I should 
> be able to calculate the regression coefficients

You can get the regression coefficients from a PLSR/PCR with the
coef() function.  See ?coef.mvr  However, using the regression
coefficients alone for selecting variables/regions, can be 'dangerous'
because the variables are highly correlated.

One alternative is 'variable importance' measures, e.g. VIP (variable
importance in projections) as described in Chong, Il-Gyo & Jun,
Chi-Hyuck, 2005, Performance of some variable selection methods when
multicollinearity is present, Chemometrics and Intelligent Laboratory
Systems 78, 103--112.  A crude implementation of VIP can be found in
http://mevik.net/work/software/pls.html

Another alternative is to use jackknife-estimated uncertainties of the
regression coefficients in significance tests.  (I don't have any
reference or implementation, sorry. :-)

The correlation loadings can also give valuable information about
which variables that might be important for the regression.  See
?corrplot in the pls package.

-- 
Bj??rn-Helge Mevik



From bernhard.baumgartner at wiwi.uni-regensburg.de  Wed Feb  8 15:21:46 2006
From: bernhard.baumgartner at wiwi.uni-regensburg.de (Bernhard Baumgartner)
Date: Wed, 08 Feb 2006 15:21:46 +0100
Subject: [R] dataframe subset
Message-ID: <20060208142219.E7FB01C51D@rrzmta2.rz.uni-regensburg.de>

I have a dataframe with a column, say "x" consisting of values, each 
value appearing different times, e.g.
x: 1,1,1,1,2,2,4,4,4,9,10,10,10,10,10 ...
and a vector, including e.g.:
y: 2,9,10,...
I need a subset of the dataframe: all rows where x is equal to one of 
the values in y. Currently I use a loop for this, but because x and y 
are large this is very slow. 
Is there any idea how to solve this problem faster?
Thank you,
Bernhard



From rbaer at atsu.edu  Wed Feb  8 15:25:40 2006
From: rbaer at atsu.edu (Robert Baer)
Date: Wed, 8 Feb 2006 08:25:40 -0600
Subject: [R] print formula on plot
References: <d0f55a670602080547p1bf96d9ar@mail.gmail.com>
Message-ID: <006101c62cbb$89a1d9f0$a00c010a@BigBaer>

Only put the expression inside the expression?

> plot(x,z[3]*x^2+z[2]*x+z[3],type="l", main="My nice plot")
> text(-0.9,5,paste(zs[1],' ',expression(x^3)))  # should work

____________________________
Robert W. Baer, Ph.D.
Associate Professor
Department of Physiology
A. T. Still University of Health Science
800 W. Jefferson St.
Kirksville, MO 63501-1497 USA
----- Original Message ----- 
From: "Thomas Steiner" <finbref.2006 at gmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, February 08, 2006 7:47 AM
Subject: [R] print formula on plot


> I estimate some parameters and I want to print them (pretty) on my plot:
>
> # somehow estimated parameters
> z<-c(1.543523e+00, 1.23453e+00, 3.454000e+00)
>
> x<-seq(-1,1,length=100)
> plot(x,z[3]*x^2+z[2]*x+z[3],type="l", main="My nice plot of the
> estimated function")
> zs<-format(z,digits=4,scientific=FALSE,trim=TRUE)
>
> text(-0.9,7,expression(1.54*x^2))                   # is what I want,
> but DYNAMIC
> text(-0.9,6,expression(paste(zf[1],x^3)))         # not really
> text(-0.9,5,expression(paste(toSting(zf[1]),x^3)))  # not really
> #using z (double) instead of zf (string) does not help.
>
> So my question is:
> How do I evaluate zf[1] from the variable to it's (String) value? Here
> it is used within an expression: this makes all the trouble.
>
> Thanks for help, I tried 2 hrs now...
> Thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Wed Feb  8 15:37:09 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 8 Feb 2006 09:37:09 -0500
Subject: [R] print formula on plot
In-Reply-To: <d0f55a670602080605y5229ca95j@mail.gmail.com>
References: <d0f55a670602080547p1bf96d9ar@mail.gmail.com>
	<d0f55a670602080605y5229ca95j@mail.gmail.com>
Message-ID: <971536df0602080637l6b160471m7160e299745a7b5@mail.gmail.com>

Also see ?bquote

On 2/8/06, Thomas Steiner <finbref.2006 at gmail.com> wrote:
> I found it immediately after posting :(
>
> substitute is my friend:
>
> text(0.5,5,substitute(f[Sv] ==k*x^2, list(k=zf[1])))
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From finbref.2006 at gmail.com  Wed Feb  8 15:44:11 2006
From: finbref.2006 at gmail.com (Thomas Steiner)
Date: Wed, 8 Feb 2006 15:44:11 +0100
Subject: [R] print formula on plot
In-Reply-To: <006101c62cbb$89a1d9f0$a00c010a@BigBaer>
References: <d0f55a670602080547p1bf96d9ar@mail.gmail.com>
	<006101c62cbb$89a1d9f0$a00c010a@BigBaer>
Message-ID: <d0f55a670602080644m70bb20e2m@mail.gmail.com>

> > text(-0.9,5,paste(zs[1],' ',expression(x^3)))  # should work

this produces a 2x^3 and not 2x"superscript"(3) - just execute it and
you see what I mean. anyway, substitute helps and bquote could shorten
it a bit.
Anywa thanks!
Thomas



From murdoch at stats.uwo.ca  Wed Feb  8 15:47:03 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 08 Feb 2006 09:47:03 -0500
Subject: [R] dataframe subset
In-Reply-To: <20060208142219.E7FB01C51D@rrzmta2.rz.uni-regensburg.de>
References: <20060208142219.E7FB01C51D@rrzmta2.rz.uni-regensburg.de>
Message-ID: <43EA0467.5040706@stats.uwo.ca>

On 2/8/2006 9:21 AM, Bernhard Baumgartner wrote:
> I have a dataframe with a column, say "x" consisting of values, each 
> value appearing different times, e.g.
> x: 1,1,1,1,2,2,4,4,4,9,10,10,10,10,10 ...
> and a vector, including e.g.:
> y: 2,9,10,...
> I need a subset of the dataframe: all rows where x is equal to one of 
> the values in y. Currently I use a loop for this, but because x and y 
> are large this is very slow. 
> Is there any idea how to solve this problem faster?

It's actually very easy.  Assume your dataframe is df, then

subset(df, x %in% y)

will give you what you want (assuming there is no column y in the 
dataframe).

Duncan Murdoch

> Thank you,
> Bernhard
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ccleland at optonline.net  Wed Feb  8 15:48:51 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 08 Feb 2006 09:48:51 -0500
Subject: [R] dataframe subset
In-Reply-To: <20060208142219.E7FB01C51D@rrzmta2.rz.uni-regensburg.de>
References: <20060208142219.E7FB01C51D@rrzmta2.rz.uni-regensburg.de>
Message-ID: <43EA04D3.9050503@optonline.net>

Bernhard Baumgartner wrote:
> I have a dataframe with a column, say "x" consisting of values, each 
> value appearing different times, e.g.
> x: 1,1,1,1,2,2,4,4,4,9,10,10,10,10,10 ...
> and a vector, including e.g.:
> y: 2,9,10,...
> I need a subset of the dataframe: all rows where x is equal to one of 
> the values in y. Currently I use a loop for this, but because x and y 
> are large this is very slow. 
> Is there any idea how to solve this problem faster?

mydata <- data.frame(X = sample(1:10, 10000, replace=TRUE),
                      Y = sample(c(2,9,10), 10000, replace=TRUE))

newdata <- mydata[mydata$X %in% unique(mydata$Y),]

?"%in%"

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From Stefano.Guazzetti at ausl.re.it  Wed Feb  8 15:52:42 2006
From: Stefano.Guazzetti at ausl.re.it (Guazzetti Stefano)
Date: Wed, 8 Feb 2006 15:52:42 +0100
Subject: [R] R:  dataframe subset
Message-ID: <B8A1EED732379B44A7E59D22E82E4442020D6A4D@IMHOTEP.ausl.org>

Dear Bernhard,
if I understand correctly your question
may be you want something like

 df<-data.frame(x=sample(1:10, 100, repl=T), 
                y=sample(1:5, 100, repl=T))
 subset(df, x%in%y)

Regards, 

Stefano

   >-----Messaggio originale-----
   >Da: r-help-bounces at stat.math.ethz.ch
   >[mailto:r-help-bounces at stat.math.ethz.ch]Per conto di Bernhard
   >Baumgartner
   >Inviato: 08 February 2006 15:22
   >A: r-help at stat.math.ethz.ch
   >Oggetto: [R] dataframe subset
   >
   >
   >I have a dataframe with a column, say "x" consisting of 
   >values, each 
   >value appearing different times, e.g.
   >x: 1,1,1,1,2,2,4,4,4,9,10,10,10,10,10 ...
   >and a vector, including e.g.:
   >y: 2,9,10,...
   >I need a subset of the dataframe: all rows where x is equal 
   >to one of 
   >the values in y. Currently I use a loop for this, but 
   >because x and y 
   >are large this is very slow. 
   >Is there any idea how to solve this problem faster?
   >Thank you,
   >Bernhard
   >
   >______________________________________________
   >R-help at stat.math.ethz.ch mailing list
   >https://stat.ethz.ch/mailman/listinfo/r-help
   >PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From ramasamy at cancer.org.uk  Wed Feb  8 16:06:37 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 08 Feb 2006 15:06:37 +0000
Subject: [R] dataframe subset
In-Reply-To: <20060208142219.E7FB01C51D@rrzmta2.rz.uni-regensburg.de>
References: <20060208142219.E7FB01C51D@rrzmta2.rz.uni-regensburg.de>
Message-ID: <1139411197.5126.75.camel@dhcp-82.wolf.ox.ac.uk>

Sounds like you may need no use match().

On Wed, 2006-02-08 at 15:21 +0100, Bernhard Baumgartner wrote:
> I have a dataframe with a column, say "x" consisting of values, each 
> value appearing different times, e.g.
> x: 1,1,1,1,2,2,4,4,4,9,10,10,10,10,10 ...
> and a vector, including e.g.:
> y: 2,9,10,...
> I need a subset of the dataframe: all rows where x is equal to one of 
> the values in y. Currently I use a loop for this, but because x and y 
> are large this is very slow. 
> Is there any idea how to solve this problem faster?
> Thank you,
> Bernhard
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From petr.pikal at precheza.cz  Wed Feb  8 16:07:38 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 08 Feb 2006 16:07:38 +0100
Subject: [R] dataframe subset
In-Reply-To: <20060208142219.E7FB01C51D@rrzmta2.rz.uni-regensburg.de>
Message-ID: <43EA174A.4174.1BDC8D9@localhost>

Hi

something like

xx<-data.frame(x=sample(1:10,100,replace=T))
y<-c(2,5,8)
xx[xx$x%in%y,]

HTH
Petr



On 8 Feb 2006 at 15:21, Bernhard Baumgartner wrote:

From:           	"Bernhard Baumgartner" <bernhard.baumgartner at wiwi.uni-regensburg.de>
Organization:   	Universitaet Regensburg
To:             	r-help at stat.math.ethz.ch
Date sent:      	Wed, 08 Feb 2006 15:21:46 +0100
Priority:       	normal
Subject:        	[R] dataframe subset

> I have a dataframe with a column, say "x" consisting of values, each
> value appearing different times, e.g. x:
> 1,1,1,1,2,2,4,4,4,9,10,10,10,10,10 ... and a vector, including e.g.:
> y: 2,9,10,... I need a subset of the dataframe: all rows where x is
> equal to one of the values in y. Currently I use a loop for this, but
> because x and y are large this is very slow. Is there any idea how to
> solve this problem faster? Thank you, Bernhard
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From charles.edwin.white at us.army.mil  Wed Feb  8 16:16:25 2006
From: charles.edwin.white at us.army.mil (White, Charles E WRAIR-Wash DC)
Date: Wed, 8 Feb 2006 10:16:25 -0500
Subject: [R] Compiling errors for Matrix_0.995-5.tar.gz under XP
Message-ID: <8BAEC5E546879B4FAA536200A292C614FE8981@AMEDMLNARMC135.amed.ds.army.mil>

I installed the MinGW-5.0.0 compilers today (gcc-3.4.2 is now contained in the 'Current' distribution. When the current compilers failed to compile the referenced Matrix update and not knowing how to check the exact version numbers for individual files, I applied the Id.exe and f771.exe fixes from the 'Building R for Windows' page (http://www.murdoch-sutherland.com/Rtools/#ldbug). More compiler errors were obtained. I then checked my Pearl version (5.8.7) and updated my R tools since I couldn't tell how old they were. At that point, I obtained the following output:


C:\Documents and Settings\Whitece.AMED\My Documents\1 Pocket Office\R Repository
\lme4>rcmd install matrix_0.995-5.tar.gz

latex: not found
latex: not found
latex: not found

---------- Making package matrix ------------
latex: not found
  adding build stamp to DESCRIPTION
latex: not found
  installing NAMESPACE file and metadata
latex: not found
  running src/Makefile.win ...
latex: not found
make[3]: `Matrix.dll' is up to date.
  ... done
  installing DLL
latex: not found
  installing R files
latex: not found
  installing inst files
FIND: Parameter format not correct
make[2]: *** [C:/PROGRA~1/R/R-22~1.1/library/matrix/inst] Error 2
make[1]: *** [all] Error 2
make: *** [pkg-matrix] Error 2
*** Installation of matrix failed ***

Removing 'C:/PROGRA~1/R/R-22~1.1/library/matrix'
Restoring previous 'C:/PROGRA~1/R/R-22~1.1/library/matrix'

If I need to read one of R's many friendly manuals, I'd appreciate a reference to which one and approximately which section.

Thanks.

Chuck

Charles E. White, Senior Biostatistician, MS
Walter Reed Army Institute of Research
503 Robert Grant Ave., Room 1w102
Silver Spring, MD 20910-1557
301 319-9781
Personal/Professional Site:??http://users.starpower.net/cwhite571/professional/



From bernhard.baumgartner at wiwi.uni-regensburg.de  Wed Feb  8 16:17:07 2006
From: bernhard.baumgartner at wiwi.uni-regensburg.de (Bernhard Baumgartner)
Date: Wed, 08 Feb 2006 16:17:07 +0100
Subject: [R] dataframe subset
Message-ID: <20060208151720.2FD441DAE6@rrzmta2.rz.uni-regensburg.de>

Thanks to all,

the %in% function solved my problem!

Bernhard



From br44114 at gmail.com  Wed Feb  8 16:19:23 2006
From: br44114 at gmail.com (bogdan romocea)
Date: Wed, 8 Feb 2006 10:19:23 -0500
Subject: [R] dataframe subset
Message-ID: <8d5a36350602080719s7179cf67t8f207d41d67ee82d@mail.gmail.com>

Here's one way,
  x <- data.frame(V=c(1,1,1,1,2,2,4,4,4,9,10,10,10,10,10))
  y <- data.frame(V=c(2,9,10))
  xy <- merge(x,y,all=FALSE)
Pay close attention to what happens if you have duplicate values in y, say
  y <- data.frame(V=c(2,9,10,10))


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
> Bernhard Baumgartner
> Sent: Wednesday, February 08, 2006 9:22 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] dataframe subset
>
> I have a dataframe with a column, say "x" consisting of values, each
> value appearing different times, e.g.
> x: 1,1,1,1,2,2,4,4,4,9,10,10,10,10,10 ...
> and a vector, including e.g.:
> y: 2,9,10,...
> I need a subset of the dataframe: all rows where x is equal to one of
> the values in y. Currently I use a loop for this, but because x and y
> are large this is very slow.
> Is there any idea how to solve this problem faster?
> Thank you,
> Bernhard
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Wed Feb  8 16:25:39 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 Feb 2006 16:25:39 +0100
Subject: [R] difference between rnorm(1000, 0, 1) and running rnorm(500,
	0, 1) twice
In-Reply-To: <43E9E271.7060905@stats.uwo.ca>
References: <BAY110-F4B7483709FF7485B32C6FC7000@phx.gbl>
	<m0d5hy9nx5.fsf@bar.nemo-project.org> <43E9E271.7060905@stats.uwo.ca>
Message-ID: <x2d5hxna8c.fsf@viggo.kubism.ku.dk>

Duncan Murdoch <murdoch at stats.uwo.ca> writes:

> This isn't really something that can be proved by a test.  Perhaps the 
> current implementation makes those equal only because 500 is even, or 
> divisible by 5, or whatever...
> 
> I think the intention is that those should be equal, but in a quick 
> search I've been unable to find a documented guarantee of that.  So I 
> would take a defensive stance and assume that there may be conditions 
> where c(rnorm(m), rnorm(n)) is not equal to rnorm(m+n).
> 
> If someone can point out the document I missed, I'd appreciate it.

I think it's a fair assumption that *uniform* random numbers have the
property, since these are engines that produce a continuous stream of
values, of which we select the next n and m values. 

As long as the normal.kind (see ?RNGkind) is "Inversion", we can be
sure that the property carries to rnorm, but it might not be the case
for other methods. In particular the ones that generate normal
variates in batches are suspect. However, empirically, I can't seem to
provoke the effect with any of R's built-in generators. One *could* of
course check the source code and see whether there is state
information being kept between invokations...

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From sfalcon at fhcrc.org  Wed Feb  8 16:26:22 2006
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 08 Feb 2006 07:26:22 -0800
Subject: [R] ARULES --> Filtering Rules by RHS
In-Reply-To: <79799E69EA1DA246A51F983B5663BEA2CD34B9@server2.hq.clientvela.net>
	(Markus Preisetanz's message of "Wed, 8 Feb 2006 10:06:58 +0100")
References: <79799E69EA1DA246A51F983B5663BEA2CD34B9@server2.hq.clientvela.net>
Message-ID: <m2fymtdg81.fsf@ziti.local>

On  8 Feb 2006, Markus.Preisetanz at clientvela.com wrote:
> I would like to only inspect rules that contain a certain label
> substring on the rhs. In this special case the item labels are built
> like this:
>
> <itemtype>_<itemvalue> e.g. "Artikelgruppe_E0815" what I want to do
> is only show rules where "Artikelgruppe" is contained in the rhs -
> has anybody an idea how this could work?

I think there is a rhs() method you can use to get an itemMatrix
instance containing just the RHS.  Then one options might be something
like (untested):

isets <- LIST(items(rhs(foo)))

lapply(isets, function(x) grep("Artikelgruppe", isets))

oop, I just realized: do you mean RHS of the association rule or RHS
of the <foo>_<bar>?

hth,

+ seth



From nhy303 at abdn.ac.uk  Wed Feb  8 16:27:19 2006
From: nhy303 at abdn.ac.uk (nhy303@abdn.ac.uk)
Date: Wed, 8 Feb 2006 15:27:19 -0000 (GMT)
Subject: [R] logLik == -Inf in gls
Message-ID: <2805.139.133.94.35.1139412439.squirrel@www.abdn.ac.uk>

I am trying to fit a generalised least squares model using gls in the nlme
package.

The model seems to fit very well when I plot the fitted values against the
original

values, and the model parameters have quite narrow confidence intervals
(all are

significant at p<5%).

The problem is that the log likelihood is always given as -Inf.  This
doesn't seem to make sense because the model seems to fit my data so well.
 I have checked that the residuals are stationary using an adf test.  I
can't work out whether
  - the model really doesn't fit at all
  - there is something in my data that stops the implementation of logLik
working correctly (the -Inf value says the calculation hasn't worked)

Possible causes are:
  - There are lots of NAs in my data (model and response variables)
  - There is some autocorrelation in the data that is not accounted for by
the model (most is accounted for).

But, I've tried recreating the problem using a simpler data set, and have
never found the same problem.

The command I use to fit the model is...



result2 <- gls(lci4150 ~ propCapInStomachs +
                        temperature +
                        as.factor(monthNumber) +
                        lagLci1 +
                        lagcap1 +
                        lagcap2,
              data = monthly,
              subset = subset1985,
              na.action = na.approx,
              weights = varFixed( ~ 1/numob4150)
             )



The output I get is...



Generalized least squares fit by REML
  Model: lci4150 ~ propCapInStomachs + temperature + as.factor(monthNumber) +

lagLci1 + lagcap1 + lagcap2
  Data: monthly
  Subset: subset1985
  AIC BIC logLik
  Inf Inf   -Inf

Variance function:
 Structure: fixed weights
 Formula: ~1/numob4150

Coefficients:
                              Value Std.Error   t-value p-value
(Intercept)              -0.3282412 0.5795665 -0.566356  0.5717
propCapInStomachs         0.0093283 0.0039863  2.340107  0.0202
temperature               0.4342514 0.1526104  2.845490  0.0048
as.factor(monthNumber)2   0.3990717 0.3869991  1.031195  0.3036
as.factor(monthNumber)3   1.3788334 0.3675690  3.751223  0.0002
as.factor(monthNumber)4   1.4037195 0.3857764  3.638686  0.0003
as.factor(monthNumber)5   0.9903316 0.3436177  2.882074  0.0043
as.factor(monthNumber)6   0.3453741 0.3043698  1.134719  0.2577
as.factor(monthNumber)7   0.3948442 0.3035142  1.300909  0.1946
as.factor(monthNumber)8   0.5021812 0.3532413  1.421638  0.1565
as.factor(monthNumber)9  -0.0794319 0.3598981 -0.220707  0.8255
as.factor(monthNumber)10  0.3536805 0.3790538  0.933061  0.3518
as.factor(monthNumber)11  0.7874834 0.3557116  2.213826  0.0278
as.factor(monthNumber)12  0.1854279 0.3178320  0.583415  0.5602
lagLci1                   0.5488437 0.0576144  9.526151  0.0000
lagcap1                   0.0110994 0.0043669  2.541714  0.0117
lagcap2                  -0.0088080 0.0041099 -2.143127  0.0332



Does anyone have any suggestions of how I can get a meaningful value for
logLik?  Or some other way that I can compare models.

Thankyou for your help,

Lillian.

-- 
Lillian Sandeman
PhD Student
School of Biological Sciences
University of Aberdeen
AB24 2TZ

Tel.: 01224 272648
E-mail: l.sandeman at abdn.ac.uk



From stephen.cox at ttu.edu  Wed Feb  8 16:28:27 2006
From: stephen.cox at ttu.edu (Cox, Stephen)
Date: Wed, 8 Feb 2006 09:28:27 -0600
Subject: [R] Logistic regression - confidence intervals
Message-ID: <CB39400C59062045950FAEB4A28F10A5013ECB2C@BRIAREUS.net.ttu.edu>

Please forgive a rather na??ve question... 

Could someone please give a quick explanation for the differences in conf intervals achieved via confint.glm (based on profile liklihoods) and the intervals achieved using the Design library.

For example, the intervals in the following two outputs are different.

library(Design)
x = rnorm(100)
y = gl(2,50)
d = data.frame(x = x, y = y)
dd = datadist(d); options(datadist = 'dd')
m1 = lrm(y~x, data = d)
summary(m1)

m2 = glm(y~x, family = binomial, data = d)
confint(m2)

I have spent time trying to figure this out via archives, but have not had much luck.

Regards

Stephen



From Camarda at demogr.mpg.de  Wed Feb  8 16:29:21 2006
From: Camarda at demogr.mpg.de (Camarda, Carlo Giovanni)
Date: Wed, 8 Feb 2006 16:29:21 +0100
Subject: [R] Changing labels on the scale of image.plot(fields)
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E6C0C446@HERMES.demogr.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060208/f2b2fa04/attachment.pl

From ripley at stats.ox.ac.uk  Wed Feb  8 16:34:56 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Feb 2006 15:34:56 +0000 (GMT)
Subject: [R] difference between rnorm(1000, 0, 1) and running rnorm(500,
 0, 1) twice
In-Reply-To: <43E9FB36.3000100@stats.uwo.ca>
References: <Pine.GSO.4.31.0602081329160.26426-100000@markov.stats>
	<43E9FB36.3000100@stats.uwo.ca>
Message-ID: <Pine.LNX.4.64.0602081529250.8305@gannet.stats.ox.ac.uk>

On Wed, 8 Feb 2006, Duncan Murdoch wrote:

> On 2/8/2006 8:30 AM, Brian D Ripley wrote:
> On Wed, 8 Feb 2006, Duncan Murdoch wrote:
> >> On 2/8/2006 4:53 AM, Bj????rn-Helge Mevik wrote:
>> > Why don't you test it yourself?
>> >>> > E.g.,>> >>> > set.seed(42)>> > bob1 <- rnorm(1000,0,1)>> > set.seed(42)>> > bob2 <- rnorm(500,0,1)>> > bob3 <- rnorm(500,0,1)>> > identical(bob1, c(bob2, bob3))>> >>> > I won't tell you the answer. :-)

>> This isn't really something that can be proved by a test.  Perhaps the
>> current implementation makes those equal only because 500 is even, or
>> divisible by 5, or whatever...
>> I think the intention is that those should be equal, but in a quick
>> search I've been unable to find a documented guarantee of that.  So I
>> would take a defensive stance and assume that there may be conditions
>> where c(rnorm(m), rnorm(n)) is not equal to rnorm(m+n).
>>
>> If someone can point out the document I missed, I'd appreciate it.
> > It's various source files in R_HOME/src/main.
> > Barring bugs, they will be the same.  As you know
> > 	R is free software and comes with ABSOLUTELY NO WARRANTY.

> I didn't mean guarantee in the sense of warranty, just guarantee in the 
> sense that if someone found a situation where they weren't equal, we 
> would consider it a bug and fix it or document it as an exception.

> Should we add a statement to the RNG man page or manuals somewhere that 
> says this is the intention?

I think that is part of the sense of `no warranty': we allow ourselves to 
change anything which is not documented, and so things are as a result 
deliberately not documented.

> For others who aren't as familiar with the issues as Brian: this isn't 
> necessarily a good idea.  We have a lot of RNGs, and it's fairly easy to 
> write one so that this isn't true.  For example, the Box-Muller method 
> naturally generates pairs of normals; a naive implementation would just 
> throw one away at the end if asked for an odd number.  (Ours doesn't do 
> that.)

I think we should allow future methods to do things like that, and 
preferably document that they do them.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Jesse.Whittington at pc.gc.ca  Wed Feb  8 16:49:05 2006
From: Jesse.Whittington at pc.gc.ca (Jesse.Whittington@pc.gc.ca)
Date: Wed, 8 Feb 2006 08:49:05 -0700
Subject: [R] Logistic regression model selection with
 overdispersed/autocorrelated data
Message-ID: <OF7E2E1E34.9A5BFEE5-ON8725710F.00550BDA@pc.gc.ca>


Thanks for pointing out the aod package and the beta-binomial logistic
models Renaud.

While I see how betabinom could be applied to some of our other analyses ,
I don't see how it can be used in our habitat selection analysis where
individual locations are coded as 0 or 1 rather than proportions.  Gee
models (geeglm from geepack) could be used for our analyses.  Even though
these models are fit using maximum likelihood estimation, they do not solve
our model selection problem.

Beta-coefficients from gee, glm, glmm's, and lrm are nearly identical.  The
only thing that varies is the variance-covariance matrix and the resulting
standard errors.  Consequently, the deviances should be similar because
predicted values (p) are calculated from the beta-coefficients.  For an
individual data point, the loglikelihood = y * log(p) + (1 - y) * log(1-p)
and the deviance = -2 * sum(loglikelihoods).  Consequently, the difference
in deviance between two models is amplified by autocorrelated data and
causes models to be overparamaterized when using AIC or likelihood ratio
tests.

I am curious how others select models with autocorrelated data.

Thanks for your help,

Jesse





                                                                                                                                       
                      Renaud Lancelot                                                                                                  
                      <renaud.lancelot@        To:       "Jesse.Whittington at pc.gc.ca" <Jesse.Whittington at pc.gc.ca>                     
                      gmail.com>               cc:       r-help at stat.math.ethz.ch                                                      
                                               Subject:  Re: [R] Logistic regression model selection with overdispersed/autocorrelated 
                      31/01/2006 01:02          data                                                                                   
                                                                                                                                       
                                                                                                                                       




If you're not interested in fitting caribou-specific responses, you
can use beta-binomial logistic models. There are several package
available for this purpose on CRAN, among which aod. Because these
models are fitted using maximum-likelihood methods, you can use AIC
(or other information criteria) to compare different models.

Best,

Renaud

2006/1/30, Jesse.Whittington at pc.gc.ca <Jesse.Whittington at pc.gc.ca>:
>
>
> I am creating habitat selection models for caribou and other species with
> data collected from GPS collars.  In my current situation the
radio-collars
> recorded the locations of 30 caribou every 6 hours.  I am then comparing
> resources used at caribou locations to random locations using logistic
> regression (standard habitat analysis).
>
> The data is therefore highly autocorrelated and this causes Type I error
> two ways  small standard errors around beta-coefficients and
> over-paramaterization during model selection.  Robust standard errors are
> easily calculated by block-bootstrapping the data using "animal" as a
> cluster with the Design library, however I haven't found a satisfactory
> solution for model selection.
>
> A couple options are:
> 1.  Using QAIC where the deviance is divided by a variance inflation
factor
> (Burnham & Anderson).  However, this VIF can vary greatly depending on
the
> data set and the set of covariates used in the global model.
> 2.  Manual forward stepwise regression using both changes in deviance and
> robust p-values for the beta-coefficients.
>
> I have been looking for a solution to this problem for a couple years and
> would appreciate any advice.
>
> Jesse
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html


--
Renaud LANCELOT
Dpartement Elevage et Mdecine Vtrinaire (EMVT) du CIRAD
Directeur adjoint charg des affaires scientifiques

CIRAD, Animal Production and Veterinary Medicine Department
Deputy director for scientific affairs

Campus international de Baillarguet
TA 30 / B (Bt. B, Bur. 214)
34398 Montpellier Cedex 5 - France
Tl   +33 (0)4 67 59 37 17
Secr. +33 (0)4 67 59 39 04
Fax   +33 (0)4 67 59 37 95



From vivek.satsangi at gmail.com  Wed Feb  8 16:58:15 2006
From: vivek.satsangi at gmail.com (Vivek Satsangi)
Date: Wed, 8 Feb 2006 10:58:15 -0500
Subject: [R] Bloomberg Data Import to R
Message-ID: <bcb171920602080758n27ab5f3dif7c94294bda878b4@mail.gmail.com>

Hi Sumanta,

1. This messages is much more appropriate for the sig-finance DL
instead. Consider signing up (I read up on Amba, so I am sure you have
good contributions to make in that forum).

2. To my knowledge, there isn't a direct package. However, if you use
Bloomberg's excel plugin, just get the data into excel, save and then
bring it in "as usual". I suspect that that's what you are doing
already.

3. You may have better luck with the S-Plus plugins. I am just getting
started (an don't have any support/maintenace contract), so I don't
know what all Insightful has up its sleeve, but I talked to Carol
Wedekind about this just thing yesterday. Dr. Yollin, who also listens
in on the sig-finance list, may be able to advise you better about
what exists.

With warm regards,

Vivek

>Message: 70
>Date: Wed, 8 Feb 2006 15:51:13 +0530
>From: "Sumanta Basak" <sumantab at ambaresearch.com>
>Subject: [R] Bloomberg Data Import to R
>To: <r-help at stat.math.ethz.ch>
>Message-ID:
>	<14850601FF012647A90A5DB31F96DB37410CF7 at INBLRDC01.BANG.irpvl.com>
>Content-Type: text/plain

>Hi R-Experts,

>Can anyone tell me how Bloomberg data can be directly downloaded to R?
>Is there any package?

>Sumanta Basak.



From Hans.Skaug at mi.uib.no  Wed Feb  8 17:05:50 2006
From: Hans.Skaug at mi.uib.no (Hans Skaug)
Date: Wed, 8 Feb 2006 17:05:50 +0100
Subject: [R]  nested random effects in glmm.admb
Message-ID: <5BCBA62ECB426A47AE66567CDF930F9882981B@HUGIN.uib.no>

Hi Jarrod ,

I think you are right that neither nested or cross-classified models can be specified
in glmm.admb() as it stands (except in ad-hoc ways). This is not a restriction of the underlying
software AD Model Builder, but it is a feature of how I wrote the R-interface.
I will try to figure out how to do 2-level nesting, and include that in future releases.

hans

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jarrod Hadfield
>Sent: Wednesday, February 08, 2006 2:26 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] nested random effects in glmm.admb
>
>Hello all,
>
>In a previous posting regarding glmm.admb it is stated that glmm.admb 
>can handle 2 nested random effects.   I can only fit a single random 
>term at the moment, and wondered if anyone could  provide me with some 
>information on how to specify  a model with 2 (nested or 
>cross-classified) random terms?
>
>Thanks,
>
>Jarrod.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
>



From secchi at sssup.it  Wed Feb  8 17:22:44 2006
From: secchi at sssup.it (Angelo Secchi)
Date: Wed, 8 Feb 2006 17:22:44 +0100
Subject: [R] rob var/cov + LAD regression
Message-ID: <20060208172244.116d59f8.secchi@sssup.it>


Hi,
after looking around I was not able to get info about these two questions:

1. Is there a function to have a  "jackknifed corrected  var/cov estimate" (as described in MacKinnon and White 1985) in a standard OLS regression? 

2. Does R possess a LAD (Least Absolute Deviation) regression function?

Any help?
Thanks

-- 
========================================================
 Angelo Secchi                     PGP Key ID:EA280337



From wl at eimb.ru  Wed Feb  8 17:23:08 2006
From: wl at eimb.ru (Wladimir Eremeev)
Date: Wed, 8 Feb 2006 19:23:08 +0300
Subject: [R] envi clone in R
Message-ID: <172918418.20060208192308@eimb.ru>

Hello all,

  Research Systems (www.rsinc.com) have developed and distributes the language IDL,
  and the GIS ENVI, written in IDL.

  To my oppinion, R language is superior, compared to IDL, in all aspects.
  However, ENVI is the rather convenient and feature rich tool.

  Is anyone aware about any work, dedicated to the creation of
  something, similar to the ENVI, but in R?
  
  Also, recently, the R bindings to the GTK library have appeared...

---
Best regards,
Wladimir                mailto:wl at eimb.ru



From adrian at atstatconsulting.com  Wed Feb  8 18:00:52 2006
From: adrian at atstatconsulting.com (Adrian Katschke)
Date: Wed, 8 Feb 2006 09:00:52 -0800 (PST)
Subject: [R] insert value according to indice
Message-ID: <20060208170052.61494.qmail@web309.biz.mail.mud.yahoo.com>

  R-Helpers,
   
  I am trying to insert a value into a dataframe. This value is a proportion calculated by counting the number of those individuals with that value and then inserting the proportion at the end of the dataframe to only those individuals with the given value. The problem I am running into is that the proportions are not being attached to only those individuals with the specified value for that proportion. 
   
  Below is an example of the code that I am using. I have also attached the data file that I am using to create this dataframe.
   
    #Read in Data
  age.int <- read.csv('C:/intage.csv',header = TRUE)
   

    asubs112 <- subset(age.int, rs1042364 != "(2,2)")

   
    ages112 <- sort(unique(na.omit(asubs112$first_drink)))
   
  for ( i in ages112) {
    indce <- which(na.omit(asubs112$first_drink == i))
    prop <- length(indce)/nrow(asubs112)
    asubs112[indce,5] <- prop
    asubs112[indce,]
  }
   
  Below is the output that I get from the script above. Notice the proportion for the first NA but not any of the others. Not sure what I am doing wrong, any suggestions are a big help.
   
  TIA,
  Adrian
   
   asubs112[1:50,]
      IND_ID rs1042364 first_drink age_int          V5
4   10008007     (1,2)          NA      16 0.003891051
6   10013012     (1,2)          13      14 0.116731518
7   10015006     (1,2)          12      17 0.105058366
8   10015007     (1,1)          12      16 0.105058366
10  10021009     (1,2)          NA      15          NA
14  10039036     (1,2)          NA      15          NA
15  10039037     (1,2)          NA      13          NA
17  10045005     (1,2)          13      17 0.116731518
18  10045014     (1,2)          13      14 0.116731518
21  10055022     (1,2)          NA      15          NA
22  10059006     (1,2)          12      NA 0.105058366
23  10060021     (1,2)          NA      15          NA
24  10060022     (1,2)          NA      13          NA
27  10069028     (1,2)          16      17 0.066147860
29  10071022     (1,1)          14      16 0.116731518
30  10071026     (1,2)          NA      13          NA
31  10071028     (1,2)          NA      13          NA
32  10071032     (1,2)          16      16 0.066147860
34  10072004     (1,2)          16      17 0.066147860
37  10073021     (1,2)          12      NA 0.105058366
39  10077013     (1,2)          NA      14          NA
40  10077076     (1,2)          15      15 0.062256809
41  10084005     (1,2)          14      15 0.116731518
44  10088017     (1,2)          15      15 0.062256809
50  10093005     (1,2)          NA      NA          NA
51  10096003     (1,2)          17      NA 0.023346304
56  10108005     (1,2)          14      NA 0.116731518
57  10112001     (1,2)           6      16 0.003891051
58  10114003     (1,1)          13      17 0.116731518
59  10114004     (1,1)          11      NA 0.027237354
60  10114005     (1,2)          12      14 0.105058366
61  10114006     (1,1)          13      17 0.116731518
62  10114007     (1,2)          15      15 0.062256809
63  10115006     (1,2)          13      14 0.116731518
69  10118011     (1,2)          14      14 0.116731518
70  10118012     (1,2)          16      17 0.066147860
73  10123024     (1,2)          13      15 0.116731518
76  10130019     (1,2)          NA      13          NA
77  10130020     (1,2)          12      15 0.105058366
78  10130021     (1,2)          NA      14          NA
87  10144039     (1,2)          12      13 0.105058366
91  10155016     (1,2)          NA      13          NA
92  10156004     (1,2)          14      15 0.116731518
99  10170009     (1,2)          16      17 0.066147860
100 10171016     (1,2)          NA      15          NA
104 10171027     (1,2)          13      14 0.116731518
107 10175013     (1,2)           9      16 0.011673152
108 10181013     (1,2)          11      13 0.027237354
110 10181017     (1,1)          14      16 0.116731518
111 10181024     (1,1)          16      17 0.066147860





From ripley at stats.ox.ac.uk  Wed Feb  8 18:11:56 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Feb 2006 17:11:56 +0000 (GMT)
Subject: [R] Compiling errors for Matrix_0.995-5.tar.gz under XP
In-Reply-To: <8BAEC5E546879B4FAA536200A292C614FE8981@AMEDMLNARMC135.amed.ds.army.mil>
References: <8BAEC5E546879B4FAA536200A292C614FE8981@AMEDMLNARMC135.amed.ds.army.mil>
Message-ID: <Pine.LNX.4.64.0602081709020.15865@gannet.stats.ox.ac.uk>

Please read the R-admin manual and as it suggests use the candidate 
compilers, now gcc 3.4.5.

You also need the Rtools at the front of your path, so you find find.exe 
not FIND.exe.

Finally, it seems to be requiring latex, so you may need to install that 
(I am really not sure why though).

On Wed, 8 Feb 2006, White, Charles E WRAIR-Wash DC wrote:

> I installed the MinGW-5.0.0 compilers today (gcc-3.4.2 is now contained in the 'Current' distribution. When the current compilers failed to compile the referenced Matrix update and not knowing how to check the exact version numbers for individual files, I applied the Id.exe and f771.exe fixes from the 'Building R for Windows' page (http://www.murdoch-sutherland.com/Rtools/#ldbug). More compiler errors were obtained. I then checked my Pearl version (5.8.7) and updated my R tools since I couldn't tell how old they were. At that point, I obtained the following output:
>
>
> C:\Documents and Settings\Whitece.AMED\My Documents\1 Pocket Office\R Repository
> \lme4>rcmd install matrix_0.995-5.tar.gz
>
> latex: not found
> latex: not found
> latex: not found
>
> ---------- Making package matrix ------------
> latex: not found
>  adding build stamp to DESCRIPTION
> latex: not found
>  installing NAMESPACE file and metadata
> latex: not found
>  running src/Makefile.win ...
> latex: not found
> make[3]: `Matrix.dll' is up to date.
>  ... done
>  installing DLL
> latex: not found
>  installing R files
> latex: not found
>  installing inst files
> FIND: Parameter format not correct
> make[2]: *** [C:/PROGRA~1/R/R-22~1.1/library/matrix/inst] Error 2
> make[1]: *** [all] Error 2
> make: *** [pkg-matrix] Error 2
> *** Installation of matrix failed ***
>
> Removing 'C:/PROGRA~1/R/R-22~1.1/library/matrix'
> Restoring previous 'C:/PROGRA~1/R/R-22~1.1/library/matrix'
>
> If I need to read one of R's many friendly manuals, I'd appreciate a reference to which one and approximately which section.
>
> Thanks.
>
> Chuck
>
> Charles E. White, Senior Biostatistician, MS
> Walter Reed Army Institute of Research
> 503 Robert Grant Ave., Room 1w102
> Silver Spring, MD 20910-1557
> 301 319-9781
> Personal/Professional Site:??http://users.starpower.net/cwhite571/professional/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From christian.bieli at unibas.ch  Wed Feb  8 18:17:44 2006
From: christian.bieli at unibas.ch (Christian Bieli)
Date: Wed, 08 Feb 2006 18:17:44 +0100
Subject: [R] GEE Modelle in Stata und R
Message-ID: <43EA27B8.6040308@unibas.ch>

Hall Christian

Ich habe Dir hier den Output desselben Models mir den selben Daten mit R 
und mit Stata gerechnet angeh??ngt.
Wie Du siehst sind die Unterschiede nicht unbetr??chtlich. Da Du bestimmt 
schon ??hnliche Erfahrungen gemacht hast, wollte ich Dich fragen, ob 
diese Unterschiede im Rahmen  dessen sind, wie man sie zwischen zwei 
verschiedenen packages erwarten kann, oder nicht.

F??r eine kurze Antwort w??re ich Dir sehr dankbar.
Liebe Gr??sse
Christian

R output:

     GEE:  GENERALIZED LINEAR MODELS FOR DEPENDENT DATA
     gee S-function, version 4.13 modified 98/01/27 (1998)

    Model:
     Link:                      Logit
     Variance to Mean Relation: Binomial
     Correlation Structure:     Exchangeable

    Call:
    gee(formula = y ~ Var1 * Var2 + Var3, id = Var4,
        data = mydata, family = binomial, corstr = "exchangeable",
        scale.fix = TRUE)

    Summary of Residuals:
            Min          1Q      Median          3Q         Max
    -0.16457139 -0.10916961 -0.05774320 -0.01334249  0.98519918

    Coefficients:
                       Estimate Naive S.E.     Naive z Robust S.E.    
    Robust z
    (Intercept)     -2.02946378  0.6152142 -3.29879234   0.6276423 
    -3.23347186
    Var1med         -0.06978758  0.8108207 -0.08607031   0.8280726 
    -0.08427713
    Var1hi           0.08988940  0.9738316  0.09230487   0.9851523  
    0.09124417
    Var2yes         -2.16869738  1.2386945 -1.75079278   1.4269696 
    -1.51979227
    Var3yes         -0.10520805  0.5724176 -0.18379597   0.6881670 
    -0.15288157
    Var1med:Var2yes  1.58088457  1.3503015  1.17076411   1.3682419  
    1.15541309
    Var1hi:Var2yes   2.48367129  1.4694804  1.69016976   1.4707481  
    1.68871291

    Estimated Scale Parameter:  1

Stata Output:

    xi: xtgee y i.Var1*i.Var2 Var3, family(binomial) link(logit) i(Var4)

    GEE population-averaged model                   Number of obs     
    =       309
    Group variable:                       Var4      Number of groups  
    =       215
    Link:                                logit      Obs per group: min
    =         1
    Family:                           binomial                     avg
    =       1.4
    Correlation:                  exchangeable                     max
    =         8
                                                    Wald chi2(6)      
    =      7.68
    Scale parameter:                         1      Prob > chi2       
    =    0.2628

    ------------------------------------------------------------------------------
               y |      Coef.   Std. Err.      z    P>|z|     [95% Conf.
    Interval]
    -------------+----------------------------------------------------------------
           _cons |  -1.938584   .8662878    -2.24   0.025    -3.636477  
    -.2406913
        _IVar1_2 |  -.0610133   .8087995    -0.08   0.940   
    -1.646231    1.524205
        _IVar1_3 |   .0944082   .9720986     0.10   0.923    
    -1.81087    1.999686
        _IVar2_2 |  -2.178428   1.240422    -1.76   0.079    
    -4.60961    .2527538
            Var3 |  -.0977918   .5719084    -0.17   0.864   
    -1.218712    1.023128
    _IVarXVa~2_2 |   1.575095   1.351553     1.17   0.244   
    -1.073901     4.22409
    _IVarXVa~3_2 |   2.483814   1.470152     1.69   0.091   
    -.3976316     5.36526
    ------------------------------------------------------------------------------


Christian

-- 
Christian Bieli, project assistant
Institute of Social and Preventive Medicine
University of Basel, Switzerland
Steinengraben 49
CH-4051 Basel
Tel.: +41 61 270 22 12
Fax:  +41 61 270 22 25
christian.bieli at unibas.ch
www.unibas.ch/ispmbs



From ripley at stats.ox.ac.uk  Wed Feb  8 18:19:31 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Feb 2006 17:19:31 +0000 (GMT)
Subject: [R] Logistic regression - confidence intervals
In-Reply-To: <CB39400C59062045950FAEB4A28F10A5013ECB2C@BRIAREUS.net.ttu.edu>
References: <CB39400C59062045950FAEB4A28F10A5013ECB2C@BRIAREUS.net.ttu.edu>
Message-ID: <Pine.LNX.4.64.0602081714380.15865@gannet.stats.ox.ac.uk>

On Wed, 8 Feb 2006, Cox, Stephen wrote:

> Please forgive a rather na??ve question...
>
> Could someone please give a quick explanation for the differences in 
> conf intervals achieved via confint.glm (based on profile liklihoods) 
> and the intervals achieved using the Design library.

Well, the Design library is not giving you confidence intervals for 
parameters, is it?  (Since there is no summary method for lrm it is a long 
haul to find out what it is giving you, which I leave to you.)

> For example, the intervals in the following two outputs are different.
>
> library(Design)
> x = rnorm(100)
> y = gl(2,50)
> d = data.frame(x = x, y = y)
> dd = datadist(d); options(datadist = 'dd')
> m1 = lrm(y~x, data = d)
> summary(m1)
>
> m2 = glm(y~x, family = binomial, data = d)
> confint(m2)
>
> I have spent time trying to figure this out via archives, but have not had much luck.
>
> Regards
>
> Stephen

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From f.harrell at vanderbilt.edu  Wed Feb  8 18:20:26 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Wed, 08 Feb 2006 11:20:26 -0600
Subject: [R] Logistic regression - confidence intervals
In-Reply-To: <CB39400C59062045950FAEB4A28F10A5013ECB2C@BRIAREUS.net.ttu.edu>
References: <CB39400C59062045950FAEB4A28F10A5013ECB2C@BRIAREUS.net.ttu.edu>
Message-ID: <43EA285A.6020603@vanderbilt.edu>

Cox, Stephen wrote:
> Please forgive a rather na??ve question... 
> 
> Could someone please give a quick explanation for the differences in conf intervals achieved via confint.glm (based on profile liklihoods) and the intervals achieved using the Design library.
> 
> For example, the intervals in the following two outputs are different.
> 
> library(Design)
> x = rnorm(100)
> y = gl(2,50)
> d = data.frame(x = x, y = y)
> dd = datadist(d); options(datadist = 'dd')
> m1 = lrm(y~x, data = d)
> summary(m1)
> 
> m2 = glm(y~x, family = binomial, data = d)
> confint(m2)
> 
> I have spent time trying to figure this out via archives, but have not had much luck.
> 
> Regards
> 
> Stephen

Design uses Wald(large sample normality of parameter estimates) -based 
confidence intervals.  These are good for most situations but profile 
confidence intervals are preferred.   Someday I'll make Design do those.

One advantage to Wald statistics is that they extend readily to cluster 
sampling (e.g., using cluster sandwich covariance estimators) and other 
complications (e.g., adjustment of variances for multiple imputation), 
whereas likelihood ratio statistics do not (unless e.g. you have an 
explicit model for the correlation structure or other facits of the model).

Also note that confint is probably giving a confidence interval for a 
one-unit change in x whereas summary.Design is computing an 
interquartile-range effect (difference in x-values is shown in the 
summary output).

When posting a nice simulated example it's best to do 
set.seed(something) so everyone will get the same data.

Frank

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From Gary.Nelson at state.ma.us  Wed Feb  8 18:19:24 2006
From: Gary.Nelson at state.ma.us (Nelson, Gary (FWE))
Date: Wed, 8 Feb 2006 12:19:24 -0500
Subject: [R] (no subject)
Message-ID: <74BDE31AFD6EC54DB026E6CD11FF0A7E01D21F86@ES-MSG-008.es.govt.state.ma.us>



************************************************************************
*
Gary A. Nelson, Ph.D
Massachusetts Division of Marine Fisheries
30 Emerson Avenue
Gloucester, MA 01930
Phone: (978) 282-0308 x114
Fax: (617) 727-3337
Email: Gary.Nelson at state.ma.us



From Gary.Nelson at state.ma.us  Wed Feb  8 18:25:49 2006
From: Gary.Nelson at state.ma.us (Nelson, Gary (FWE))
Date: Wed, 8 Feb 2006 12:25:49 -0500
Subject: [R] Help with the ts function
Message-ID: <74BDE31AFD6EC54DB026E6CD11FF0A7E12473B@ES-MSG-008.es.govt.state.ma.us>

I have a time series of temperature data recorded every 2 hours and I
would like to generate a spectrogram using the spectrum function that
examines cycles per day.  My statement for coding the series using the
ts function is

bevtemp<-ts(bevtemp,deltat=0.0833334) 

where 0.0833334 is 2 hours/24 hours.

I am wondering if this is the correct way to code the data?


Thanks for your help.

Gary Nelson.



************************************************************************
*
Gary A. Nelson
Massachusetts Division of Marine Fisheries
30 Emerson Avenue
Gloucester, MA 01930
Phone: (978) 282-0308 x114
Fax: (617) 727-3337
Email: Gary.Nelson at state.ma.us



From mbmiller at taxa.epi.umn.edu  Wed Feb  8 18:28:39 2006
From: mbmiller at taxa.epi.umn.edu (Mike Miller)
Date: Wed, 8 Feb 2006 11:28:39 -0600 (CST)
Subject: [R] what are the limits on R array sizes?
Message-ID: <Pine.GSO.4.60.0602081123490.27862@taxa.epi.umn.edu>

I have some computers with a massive amount of memory, and I have some 
jobs that could use very large matrix sizes.  Can R handle matrices of 
larger than 2GB?  If I were to create a matrix of 1,000,000 x 1,000, it 
would use about 8GB.  Can R work with an array of that size if I have 
compiled R on an IA64 Linux system with 15GB of RAM?

Mike



From adrian at atstatconsulting.com  Wed Feb  8 18:40:43 2006
From: adrian at atstatconsulting.com (Adrian Katschke)
Date: Wed, 8 Feb 2006 09:40:43 -0800 (PST)
Subject: [R] adding variable into dataframe by indice
Message-ID: <20060208174043.49245.qmail@web313.biz.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060208/6bf93565/attachment.pl

From Camarda at demogr.mpg.de  Wed Feb  8 18:42:55 2006
From: Camarda at demogr.mpg.de (Camarda, Carlo Giovanni)
Date: Wed, 8 Feb 2006 18:42:55 +0100
Subject: [R] Lexis maps in R
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E6C0C44D@HERMES.demogr.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060208/52a2401b/attachment.pl

From p.dalgaard at biostat.ku.dk  Wed Feb  8 18:44:01 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 Feb 2006 18:44:01 +0100
Subject: [R] Compiling errors for Matrix_0.995-5.tar.gz under XP
In-Reply-To: <8BAEC5E546879B4FAA536200A292C614FE8981@AMEDMLNARMC135.amed.ds.army.mil>
References: <8BAEC5E546879B4FAA536200A292C614FE8981@AMEDMLNARMC135.amed.ds.army.mil>
Message-ID: <x28xsln3tq.fsf@viggo.kubism.ku.dk>

"White, Charles E WRAIR-Wash DC" <charles.edwin.white at us.army.mil> writes:

> I installed the MinGW-5.0.0 compilers today (gcc-3.4.2 is now
> contained in the 'Current' distribution. When the current compilers
> failed to compile the referenced Matrix update and not knowing how
> to check the exact version numbers for individual files, I applied
> the Id.exe and f771.exe fixes from the 'Building R for Windows' page
> (http://www.murdoch-sutherland.com/Rtools/#ldbug). More compiler
> errors were obtained. I then checked my Pearl version (5.8.7) and
> updated my R tools since I couldn't tell how old they were. At that
> point, I obtained the following output:
> 
> 
> C:\Documents and Settings\Whitece.AMED\My Documents\1 Pocket Office\R Repository
> \lme4>rcmd install matrix_0.995-5.tar.gz
> 
> latex: not found
> latex: not found
> latex: not found
> 
> ---------- Making package matrix ------------
> latex: not found
>   adding build stamp to DESCRIPTION
> latex: not found
>   installing NAMESPACE file and metadata
> latex: not found
>   running src/Makefile.win ...
> latex: not found
> make[3]: `Matrix.dll' is up to date.
>   ... done
>   installing DLL
> latex: not found
>   installing R files
> latex: not found
>   installing inst files
> FIND: Parameter format not correct

This looks like an issue with your PATH setting. You're picking up the
wrong "find" command.

> make[2]: *** [C:/PROGRA~1/R/R-22~1.1/library/matrix/inst] Error 2
> make[1]: *** [all] Error 2
> make: *** [pkg-matrix] Error 2
> *** Installation of matrix failed ***
> 
> Removing 'C:/PROGRA~1/R/R-22~1.1/library/matrix'
> Restoring previous 'C:/PROGRA~1/R/R-22~1.1/library/matrix'
> 
> If I need to read one of R's many friendly manuals, I'd appreciate a
> reference to which one and approximately which section.

According to README.packages,

Instructions for installing the toolset and building packages using the
standard methods are in the `R Installation and Administration' manual
(which is available in various formats as R-admin.* in the doc/manual
directory).

As fara as I can see Appendix F is the most relevant part, but also
look in Ch 3 and 6.



> Thanks.
> 
> Chuck
> 
> Charles E. White, Senior Biostatistician, MS
> Walter Reed Army Institute of Research
> 503 Robert Grant Ave., Room 1w102
> Silver Spring, MD 20910-1557
> 301 319-9781
> Personal/Professional Site:??http://users.starpower.net/cwhite571/professional/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From neuro3000 at hotmail.com  Wed Feb  8 18:45:21 2006
From: neuro3000 at hotmail.com (=?iso-8859-1?B?TmV1cm8gTGVTdXBlckjpcm9z?=)
Date: Wed, 08 Feb 2006 12:45:21 -0500
Subject: [R] Bloomberg Data Import to R
In-Reply-To: <14850601FF012647A90A5DB31F96DB37410CF7@INBLRDC01.BANG.irpvl.com>
Message-ID: <BAY112-F15D714A960A2EB194EA6A2AF000@phx.gbl>

Check this out:

https://stat.ethz.ch/pipermail/r-sig-finance/2004q3/000051.html

You should consider adapting it with rcom instead of RDCOMClient

Neuro


>From: "Sumanta Basak" <sumantab at ambaresearch.com>
>To: <r-help at stat.math.ethz.ch>
>Subject: [R] Bloomberg Data Import to R
>Date: Wed, 8 Feb 2006 15:51:13 +0530
>
>
>
>Hi R-Experts,
>
>
>
>Can anyone tell me how Bloomberg data can be directly downloaded to R?
>Is there any package?
>
>Sumanta Basak.
>
>
>-------------------------------------------------------------------------------------------------------------------
>This e-mail may contain confidential and/or privileged infor...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From laura at env.leeds.ac.uk  Wed Feb  8 18:50:26 2006
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Wed, 8 Feb 2006 17:50:26 +0000 (GMT)
Subject: [R] slightly off-topic re prcomp()
Message-ID: <Pine.LNX.4.44.0602081746190.6410-100000@gw.env.leeds.ac.uk>

Hi,

I was wondering if anyone could tell me why prcomp() will "Invent" modes
of variation in a PCA on identical replicates of data? I would have
expected 50 (or whatever number) of identical replicates to return a null
score in such an analysis (or at the least, all variables would share the
same PC score). This is not the case and I was wondering could someone
point me in the direction of some literature to explain the reason behind
this?

Laura Quinn
Institute of Atmospheric Science
School of Earth and Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk



From bolker at zoo.ufl.edu  Wed Feb  8 18:57:26 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Wed, 08 Feb 2006 12:57:26 -0500
Subject: [R] tutorials on "statistical aspects" of R
Message-ID: <43EA3106.2090609@zoo.ufl.edu>


benn at bgu.ac.il wrote:

> >There are lots of tutorials at 
> <http://cran.r-project.org/other-docs.html>.
>
> I have those of course. I was looking for further tutorials.
>
> >What do you mean the "statistical aspect" of R?
>
> I mean using and building statistical models for data analysis 
> specifying the possibilities of variations appearing in R. An example 
> would be specifying Split-plot ANOVA with both random and fixed factors.
> A lot of the tutorials in above url try to explain R as a programming 
> language and therefore cannot allow too many explanation. That is the 
> case of "Jack of all trades... etc." R is useful for quite a lot of 
> things, however I'm looking for something like a statistics course in R.
> Just to prevent misunderstanding, I do own, and am familiar with, 
> exhaustive statistical texts. So I don't exactly need a course in 
> statistics.
>
> Thanks in advance,
>
>     Gil

 (I'm redirecting this to the general R list, since it's not 
particularly Mac specific any more.)
 Despite your claim,  there are statistics-oriented tutorials available in
the "other docs" section (esp. Faraway and Fox).  However, if I recall 
correctly
and if you need split-plot ANOVA etc., these may not be quite advanced 
enough
(statistically) for you (Faraway has about 5 pages on block designs).  
You may need to buy or
borrow a book: I would recommend Crawley's
books (Statistics: an Introduction using R has only 4 or so pages, 
Statistical Computing
has a whole 16-page chapter); Venables and Ripley (the bible) has a 
chapter on random and
mixed effects, and Pinheiro and Bates is an entire book on mixed models 
... all of these
except Statistical Computing are listed on the R books page.  Faraway 
also has
"Linear models with R", which has a chapter on block designs.

  That should give you some starting points ...

 Ben Bolker



From gunter.berton at gene.com  Wed Feb  8 18:58:58 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 8 Feb 2006 09:58:58 -0800
Subject: [R] rob var/cov + LAD regression
In-Reply-To: <20060208172244.116d59f8.secchi@sssup.it>
Message-ID: <200602081758.k18Hww3V003833@meitner.gene.com>

RSiteSearch() is your friend.

For 1) Try RSiteSearch('Jackknife',restrict='functions')

For 2) see package quantreg

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Angelo Secchi
> Sent: Wednesday, February 08, 2006 8:23 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] rob var/cov + LAD regression
> 
> 
> Hi,
> after looking around I was not able to get info about these 
> two questions:
> 
> 1. Is there a function to have a  "jackknifed corrected  
> var/cov estimate" (as described in MacKinnon and White 1985) 
> in a standard OLS regression? 
> 
> 2. Does R possess a LAD (Least Absolute Deviation) regression 
> function?
> 
> Any help?
> Thanks
> 
> -- 
> ========================================================
>  Angelo Secchi                     PGP Key ID:EA280337
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ltorgo at liacc.up.pt  Wed Feb  8 19:08:40 2006
From: ltorgo at liacc.up.pt (=?iso-8859-1?q?Lu=EDs_Torgo?=)
Date: Wed, 8 Feb 2006 18:08:40 +0000
Subject: [R] expand.grid without expanding
Message-ID: <200602081808.40593.ltorgo@liacc.up.pt>

Dear list,
I've recently came across a problem that I think I've solved and that I wanted 
to share with you for two reasons:
- Maybe others come across the same problem.
- Maybe someone has a much simpler solution that wants to share with me ;-)

The problem is as follows: expand.grid() allows you to generate a data.frame 
with all combinations of a set of values, e.g.:
> expand.grid(par1=-1:1,par2=c('a','b'))
  par1 par2
1   -1    a
2    0    a
3    1    a
4   -1    b
5    0    b
6    1    b

There is nothing wrong with this nice function except when you have too many 
combinations to fit in your computer memory, and that was my problem: I 
wanted to do something for each combination of a set of variants, but this 
set was to large for storing in memory in a data.frame generated by 
expand.grid. A possible solution would be to have a set of nested for() 
cycles but I preferred a solution that involved a single for() cycle going 
from 1 to the number of combinations and then at each iteration having some 
form of generating the combination "i". And this was the "real problem": how 
to generate a function that picks the same style of arguments as 
expand.grid() and provides me with the values corresponding to line "i" of 
the data frame that would have been created bu expand.grid(). For instance, 
if I wanted the line 4 of the above call to expand.grid() I should get the 
same as doing:
> expand.grid(par1=-1:1,par2=c('a','b'))[4,]
  par1 par2
4   -1    b

but obviously without having to use expand.grid() as that involves generating 
a data frame that in my case wouldn't fit in the memory of my computer.

Now, the function I've created was the following:
--------------------------------------------
getVariant <- function(id,vars) {

  if (!is.list(vars)) stop('vars needs to be a list!')

  nv <- length(vars)

  lims <- sapply(vars,length)
  if (id > prod(lims)) stop('id above the number of combinations!')
  
  res <- vector("list",nv)

  for(i in nv:2) {

    f <- prod(lims[1:(i-1)])
    
    res[[i]] <- vars[[i]][ceiling(id / f)]

    id <- id - (ceiling(id/f)-1)*f
  }

  res[[1]] <- vars[[1]][id]
  names(res) <- names(vars)
  res

}
--------------------------------------
> expand.grid(par1=-1:1,par2=c('a','b'))[4,]
  par1 par2
4   -1    b
> getVariant(4,list(par1=-1:1,par2=c('a','b')))
$par1
[1] -1

$par2
[1] "b"

I would be glad to know if somebody came across the same problem and has a 
better suggestion on how to solve this.

Thanks,
Luis

-- 
Luis Torgo
    FEP/LIACC, University of Porto   Phone : (+351) 22 339 20 93
    Machine Learning Group           Fax   : (+351) 22 339 20 99
    R. de Ceuta, 118, 6o             email : ltorgo at liacc.up.pt
    4050-190 PORTO - PORTUGAL        WWW   : http://www.liacc.up.pt/~ltorgo



From kjetilbrinchmannhalvorsen at gmail.com  Wed Feb  8 19:07:51 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Wed, 08 Feb 2006 14:07:51 -0400
Subject: [R] rob var/cov + LAD regression
In-Reply-To: <20060208172244.116d59f8.secchi@sssup.it>
References: <20060208172244.116d59f8.secchi@sssup.it>
Message-ID: <43EA3377.5030907@gmail.com>

Angelo Secchi wrote:
> Hi,
> after looking around I was not able to get info about these two questions:
> 
> 1. Is there a function to have a  "jackknifed corrected  var/cov estimate" (as described in MacKinnon 

and White 1985) in a standard OLS regression?

Not sure, but look at package  sandwich  (on CRAN).

> 
> 2. Does R possess a LAD (Least Absolute Deviation) regression function?

This can be done with package quantreg  (on CRAN).

Kjetil

> 
> Any help?
> Thanks
>



From andbelo at gmail.com  Wed Feb  8 19:08:45 2006
From: andbelo at gmail.com (=?ISO-8859-1?Q?Andr=E9_Bel=F3?=)
Date: Wed, 08 Feb 2006 13:08:45 -0500
Subject: [R] problem to install R on linux
Message-ID: <43EA33AD.5040005@gmail.com>

Dear members,

this can sound trivial for some people but I don't have experience on 
compilation.

I'm trying to install R-2.2.1 on a laptop running Mandriva 2006. I 
already installed many of the recommended packages/libraries but it 
seems that something is still missing. The problem is that I cannot 
identify... Could somebody give me some advise?

I put the output of the command "./configure" bellow. When I tryed to 
install the R-2.0.0-1mdk.i586.rpm I got:

[root at localhost Download]# rpm -i R-2.0.0-1mdk.i586.rpm
warning: R-2.0.0-1mdk.i586.rpm: Header V3 DSA signature: NOKEY, key ID 
6c60ceea
error: Failed dependencies:
        info is needed by R-2.0.0-1mdk.i586
[root at localhost Download]#


Thanks in advance,
AB


[root at localhost R-2.2.1]# ./configure
checking build system type... i686-pc-linux-gnu
checking host system type... i686-pc-linux-gnu
loading site script './config.site'
loading build specific script './config.site'
checking for pwd... /bin/pwd
checking whether builddir is srcdir... yes
checking for working aclocal... found
checking for working autoconf... found
checking for working automake... found
checking for working autoheader... found
checking for working makeinfo... found
checking for gawk... gawk
checking for egrep... grep -E
checking whether ln -s works... yes
checking for ranlib... ranlib
checking for bison... no
checking for byacc... no
checking for ar... ar
checking for a BSD-compatible install... /usr/bin/install -c
checking for sed... /bin/sed
checking for less... /usr/bin/less
checking for perl... /usr/bin/perl
checking whether perl version is at least 5.004... yes
checking for dvips... /usr/bin/dvips
checking for tex... /usr/bin/tex
checking for latex... /usr/bin/latex
checking for makeindex... /usr/bin/makeindex
checking for pdftex... /usr/bin/pdftex
checking for pdflatex... /usr/bin/pdflatex
checking for makeinfo... /usr/bin/makeinfo
checking for unzip... /usr/bin/unzip
checking for zip... /usr/bin/zip
checking for gzip... /bin/gzip
checking for firefox... no
checking for mozilla... no
checking for netscape... no
checking for galeon... no
checking for kfmclient... no
checking for opera... no
checking for gnome-moz-remote... /usr/bin/gnome-moz-remote
using default browser ... /usr/bin/gnome-moz-remote
checking for acroread... /usr/bin/acroread
checking for gcc... gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ANSI C... none needed
checking how to run the C preprocessor... gcc -E
checking whether gcc needs -traditional... no
checking how to run the C preprocessor... gcc -E
checking for gfortran... gfortran
checking whether we are using the GNU Fortran 77 compiler... no
checking whether gfortran accepts -g... no
checking for g++... g++
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking how to run the C++ preprocessor... g++ -E
checking for a sed that does not truncate output... /bin/sed
checking for ld used by gcc... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking for /usr/bin/ld option to reload object files... -r
checking for BSD-compatible nm... /usr/bin/nm -B
checking how to recognise dependent libraries... pass_all
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking dlfcn.h usability... yes
checking dlfcn.h presence... yes
checking for dlfcn.h... yes
checking the maximum length of command line arguments... 32768
checking command to parse /usr/bin/nm -B output from gcc object... ok
checking for objdir... .libs
checking for ranlib... (cached) ranlib
checking for strip... strip
checking if gcc static flag  works... yes
checking if gcc supports -fno-rtti -fno-exceptions... no
checking for gcc option to produce PIC... -fPIC
checking if gcc PIC flag -fPIC works... yes
checking if gcc supports -c -o file.o... yes
checking whether the gcc linker (/usr/bin/ld) supports shared 
libraries... yes
checking whether -lc should be explicitly linked in... no
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... no
configure: creating libtool
appending configuration tag "CXX" to libtool
checking for ld used by g++... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking whether the g++ linker (/usr/bin/ld) supports shared 
libraries... yes
checking for g++ option to produce PIC... -fPIC
checking if g++ PIC flag -fPIC works... yes
checking if g++ supports -c -o file.o... yes
checking whether the g++ linker (/usr/bin/ld) supports shared 
libraries... yes
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
appending configuration tag "F77" to libtool
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... no
checking for gfortran option to produce PIC... -fPIC
checking if gfortran PIC flag -fPIC works... no
checking if gfortran supports -c -o file.o... no
checking whether the gfortran linker (/usr/bin/ld) supports shared 
libraries... yes
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking whether makeinfo version is at least 4.7... yes
checking for cos in -lm... yes
checking for sin in -lm... yes
checking for dlopen in -ldl... yes
checking readline/history.h usability... no
checking readline/history.h presence... no
checking for readline/history.h... no
checking readline/readline.h usability... no
checking readline/readline.h presence... no
checking for readline/readline.h... no
checking for rl_callback_read_char in -lreadline... no
checking for main in -lncurses... yes
checking for rl_callback_read_char in -lreadline... no
checking for history_truncate_file... no
configure: error: --with-readline=yes (default) and headers/libs are not 
available
[root at localhost R-2.2.1]#



From B.Rowlingson at lancaster.ac.uk  Wed Feb  8 19:09:19 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 08 Feb 2006 18:09:19 +0000
Subject: [R] [R-sig-Geo] envi clone in R
In-Reply-To: <172918418.20060208192308@eimb.ru>
References: <172918418.20060208192308@eimb.ru>
Message-ID: <43EA33CF.3080605@lancaster.ac.uk>

Wladimir Eremeev wrote:
> Hello all,
> 
>   Research Systems (www.rsinc.com) have developed and distributes the language IDL,
>   and the GIS ENVI, written in IDL.

  I find it hard to believe they wrote it all in IDL! I'm guessing its 
probably scriptable in IDL, but underneath its written in something 
else... I could be wrong though!

>   To my oppinion, R language is superior, compared to IDL, in all aspects.
>   However, ENVI is the rather convenient and feature rich tool.

  I clicked on 'Product Documentation' on the ENVI site and it wanted me 
to log in or create a new user. To see the documentation? To find out 
what the program is about?

  Oh, what I really wanted was the Feature Tour..

>   Is anyone aware about any work, dedicated to the creation of
>   something, similar to the ENVI, but in R?

  Last year I looked at GIS-R linkages, with the added criteria of being 
open source and cross-platform. There are now a few free GIS packages 
that can do this kind of thing, with a little added glue.

  I settled on OpenEV - it has vector and raster support, its extensible 
in Python and uses Gtk for dialogs which you can customise. All I needed 
was to get Python talking to R, so I wrote some Python bindings to 
Rserve. Now I've got a GIS with a menu that drops down, you choose the 
point layers you want to work on, click 'Go', and R does some analysis 
that ends up as a raster layer back in the GIS. The user doesnt care 
that R did it.

Other GIS solutions are available!

Barry



From f.calboli at imperial.ac.uk  Wed Feb  8 19:12:37 2006
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 08 Feb 2006 18:12:37 +0000
Subject: [R] logical condition in vector operation
Message-ID: <1139422357.22690.12.camel@localhost.localdomain>

HI All,

I have a data frame such as:

> test
     x y  p  d
[1,] 1 0 10 21 0
[2,] 2 3 11 12 0
[3,] 3 4 12 23 0
[4,] 3 5 13 24 0


and I want to perfor some operations on the first two coulums,
conditional on the uneqaulity values on the 3rd and 4th columns.

For instance:

j = 3
test[test[,1] == j, 5] = test[test[,1] == j,2] + test[test[,2] == j,1]

gives me the result:

test:

     x y  p  d
[1,] 1 0 10 21 0
[2,] 2 3 11 12 0
[3,] 3 4 12 23 6
[4,] 3 5 13 24 7


My probblem is the following: I want to perform the operation
test[test[,1] == j,2] + test[test[,2] == j,1] only if the value of
column p and column d are different at the positions where x or y = j.
In practice, I don't want to perform the first operation because
test[2,4 is 12 and test[1,3] is 12 as well.

I tried an if statement with little success:

if(test[test[,1] == j,3] != test[test[,2] == j,4]){
test[test[,1] == j, 5] = test[test[,1] == j,2] + test[test[,2] == j,1]
}
Warning message:
the condition has length > 1 and only the first element will be used in:
if (test[test[, 1] == j, 3] != test[test[, 2] == j, 4]) {

Could anyone lend some advice?

Cheers,

Federico
-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From druau at ukaachen.de  Wed Feb  8 19:47:16 2006
From: druau at ukaachen.de (David Ruau)
Date: Wed, 08 Feb 2006 19:47:16 +0100
Subject: [R] last command history???
Message-ID: <f80bccfd2e25773d4caf9fdb10043a39@ukaachen.de>

Hi,

I am using R 2.2.0 on Mac OS X 10.3.9. But I test the issue also with R 
2.2.1 on OS X 10.4 (Tiger)
I have a question regarding the functioning of the history from the 
command line.
When I press the 'up-arrow' I call back the last command (everything 
ok), let's say that I go back until the level n-5, but when I get down 
to return to the empty line, I cannot reach the empty line... The empty 
line 'level' show me the content of the line n-4.
example, let's say I did this sequence of command:
 > x <- c(1:10)
 > mean(x)
[1] 5.5
 > sd(x)
[1] 3.027650
 > x
  [1]  1  2  3  4  5  6  7  8  9 10
 >
# If I return to the command 'x <- c(1:10)' and then get down the 
bottom line is :
 > mean(x)

Well it doesn't work like that under Windows and I guess under Linux. 
What is the setting that I should change?
Or where is the error I made...

David



From rkoenker at uiuc.edu  Wed Feb  8 20:08:36 2006
From: rkoenker at uiuc.edu (roger koenker)
Date: Wed, 8 Feb 2006 13:08:36 -0600
Subject: [R] rob var/cov + LAD regression
In-Reply-To: <20060208172244.116d59f8.secchi@sssup.it>
References: <20060208172244.116d59f8.secchi@sssup.it>
Message-ID: <F7D95B57-D6A5-455A-8DD1-E6C65E6A6CDD@uiuc.edu>


On Feb 8, 2006, at 10:22 AM, Angelo Secchi wrote:

>
> 1. Is there a function to have a  "jackknifed corrected  var/cov  
> estimate" (as described in MacKinnon and White 1985) in a standard  
> OLS regression?

package:  sandwich
>
> 2. Does R possess a LAD (Least Absolute Deviation) regression  
> function?
>
package:  quantreg

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820



From gunter.berton at gene.com  Wed Feb  8 20:37:36 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 8 Feb 2006 11:37:36 -0800
Subject: [R] slightly off-topic re prcomp()
In-Reply-To: <Pine.LNX.4.44.0602081746190.6410-100000@gw.env.leeds.ac.uk>
Message-ID: <200602081937.k18JbaOU016749@faraday.gene.com>

If you don't get a response:

reproducible example, please.

I suspect that you're looking at numerical analysis artifacts, assuming I
have correctly interpreted you.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Laura Quinn
> Sent: Wednesday, February 08, 2006 9:50 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] slightly off-topic re prcomp()
> 
> Hi,
> 
> I was wondering if anyone could tell me why prcomp() will 
> "Invent" modes
> of variation in a PCA on identical replicates of data? I would have
> expected 50 (or whatever number) of identical replicates to 
> return a null
> score in such an analysis (or at the least, all variables 
> would share the
> same PC score). This is not the case and I was wondering could someone
> point me in the direction of some literature to explain the 
> reason behind
> this?
> 
> Laura Quinn
> Institute of Atmospheric Science
> School of Earth and Environment
> University of Leeds
> Leeds
> LS2 9JT
> 
> tel: +44 113 343 1596
> fax: +44 113 343 6716
> mail: laura at env.leeds.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Wed Feb  8 20:38:31 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 08 Feb 2006 14:38:31 -0500
Subject: [R] slightly off-topic re prcomp()
In-Reply-To: <Pine.LNX.4.44.0602081746190.6410-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0602081746190.6410-100000@gw.env.leeds.ac.uk>
Message-ID: <43EA48B7.3070800@stats.uwo.ca>

On 2/8/2006 12:50 PM, Laura Quinn wrote:
> Hi,
> 
> I was wondering if anyone could tell me why prcomp() will "Invent" modes
> of variation in a PCA on identical replicates of data? I would have
> expected 50 (or whatever number) of identical replicates to return a null
> score in such an analysis (or at the least, all variables would share the
> same PC score). This is not the case and I was wondering could someone
> point me in the direction of some literature to explain the reason behind
> this?

I think you'll need to show us an example.  I just tried what I think 
you described, and got all the components with 0 standard deviation, as 
I would have expected.

Duncan Murdoch


> 
> Laura Quinn
> Institute of Atmospheric Science
> School of Earth and Environment
> University of Leeds
> Leeds
> LS2 9JT
> 
> tel: +44 113 343 1596
> fax: +44 113 343 6716
> mail: laura at env.leeds.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Wed Feb  8 20:44:31 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 8 Feb 2006 19:44:31 +0000 (GMT)
Subject: [R] what are the limits on R array sizes?
In-Reply-To: <Pine.GSO.4.60.0602081123490.27862@taxa.epi.umn.edu>
References: <Pine.GSO.4.60.0602081123490.27862@taxa.epi.umn.edu>
Message-ID: <Pine.LNX.4.64.0602081941090.27423@gannet.stats.ox.ac.uk>

On Wed, 8 Feb 2006, Mike Miller wrote:

> I have some computers with a massive amount of memory, and I have some
> jobs that could use very large matrix sizes.  Can R handle matrices of
> larger than 2GB?  If I were to create a matrix of 1,000,000 x 1,000, it
> would use about 8GB.  Can R work with an array of that size if I have
> compiled R on an IA64 Linux system with 15GB of RAM?

Yes. See ?"Memory-limits".

help.search("limits") gets you there.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Gautam.Bhola at pfizer.com  Wed Feb  8 21:01:06 2006
From: Gautam.Bhola at pfizer.com (Bhola, Gautam)
Date: Wed, 8 Feb 2006 15:01:06 -0500
Subject: [R] problem to install R on linux
Message-ID: <E04D0A5FF70E854582D33D93A880799B0399C2CB@groamrexm03.amer.pfizer.com>

Hi

I had similar issue which was resolved by ensuring that I have the lib/include folder for readline in my LD_LIBRARY_PATH and PATH respectively.


Thanks 
Gautam Bhola



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Andr?? Bel??
Sent: Wednesday, February 08, 2006 1:09 PM
To: r-help at stat.math.ethz.ch
Subject: [R] problem to install R on linux

Dear members,

this can sound trivial for some people but I don't have experience on 
compilation.

I'm trying to install R-2.2.1 on a laptop running Mandriva 2006. I 
already installed many of the recommended packages/libraries but it 
seems that something is still missing. The problem is that I cannot 
identify... Could somebody give me some advise?

I put the output of the command "./configure" bellow. When I tryed to 
install the R-2.0.0-1mdk.i586.rpm I got:

[root at localhost Download]# rpm -i R-2.0.0-1mdk.i586.rpm
warning: R-2.0.0-1mdk.i586.rpm: Header V3 DSA signature: NOKEY, key ID 
6c60ceea
error: Failed dependencies:
        info is needed by R-2.0.0-1mdk.i586
[root at localhost Download]#


Thanks in advance,
AB


[root at localhost R-2.2.1]# ./configure
checking build system type... i686-pc-linux-gnu
checking host system type... i686-pc-linux-gnu
loading site script './config.site'
loading build specific script './config.site'
checking for pwd... /bin/pwd
checking whether builddir is srcdir... yes
checking for working aclocal... found
checking for working autoconf... found
checking for working automake... found
checking for working autoheader... found
checking for working makeinfo... found
checking for gawk... gawk
checking for egrep... grep -E
checking whether ln -s works... yes
checking for ranlib... ranlib
checking for bison... no
checking for byacc... no
checking for ar... ar
checking for a BSD-compatible install... /usr/bin/install -c
checking for sed... /bin/sed
checking for less... /usr/bin/less
checking for perl... /usr/bin/perl
checking whether perl version is at least 5.004... yes
checking for dvips... /usr/bin/dvips
checking for tex... /usr/bin/tex
checking for latex... /usr/bin/latex
checking for makeindex... /usr/bin/makeindex
checking for pdftex... /usr/bin/pdftex
checking for pdflatex... /usr/bin/pdflatex
checking for makeinfo... /usr/bin/makeinfo
checking for unzip... /usr/bin/unzip
checking for zip... /usr/bin/zip
checking for gzip... /bin/gzip
checking for firefox... no
checking for mozilla... no
checking for netscape... no
checking for galeon... no
checking for kfmclient... no
checking for opera... no
checking for gnome-moz-remote... /usr/bin/gnome-moz-remote
using default browser ... /usr/bin/gnome-moz-remote
checking for acroread... /usr/bin/acroread
checking for gcc... gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ANSI C... none needed
checking how to run the C preprocessor... gcc -E
checking whether gcc needs -traditional... no
checking how to run the C preprocessor... gcc -E
checking for gfortran... gfortran
checking whether we are using the GNU Fortran 77 compiler... no
checking whether gfortran accepts -g... no
checking for g++... g++
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking how to run the C++ preprocessor... g++ -E
checking for a sed that does not truncate output... /bin/sed
checking for ld used by gcc... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking for /usr/bin/ld option to reload object files... -r
checking for BSD-compatible nm... /usr/bin/nm -B
checking how to recognise dependent libraries... pass_all
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking dlfcn.h usability... yes
checking dlfcn.h presence... yes
checking for dlfcn.h... yes
checking the maximum length of command line arguments... 32768
checking command to parse /usr/bin/nm -B output from gcc object... ok
checking for objdir... .libs
checking for ranlib... (cached) ranlib
checking for strip... strip
checking if gcc static flag  works... yes
checking if gcc supports -fno-rtti -fno-exceptions... no
checking for gcc option to produce PIC... -fPIC
checking if gcc PIC flag -fPIC works... yes
checking if gcc supports -c -o file.o... yes
checking whether the gcc linker (/usr/bin/ld) supports shared 
libraries... yes
checking whether -lc should be explicitly linked in... no
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... no
configure: creating libtool
appending configuration tag "CXX" to libtool
checking for ld used by g++... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking whether the g++ linker (/usr/bin/ld) supports shared 
libraries... yes
checking for g++ option to produce PIC... -fPIC
checking if g++ PIC flag -fPIC works... yes
checking if g++ supports -c -o file.o... yes
checking whether the g++ linker (/usr/bin/ld) supports shared 
libraries... yes
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
appending configuration tag "F77" to libtool
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... no
checking for gfortran option to produce PIC... -fPIC
checking if gfortran PIC flag -fPIC works... no
checking if gfortran supports -c -o file.o... no
checking whether the gfortran linker (/usr/bin/ld) supports shared 
libraries... yes
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking whether makeinfo version is at least 4.7... yes
checking for cos in -lm... yes
checking for sin in -lm... yes
checking for dlopen in -ldl... yes
checking readline/history.h usability... no
checking readline/history.h presence... no
checking for readline/history.h... no
checking readline/readline.h usability... no
checking readline/readline.h presence... no
checking for readline/readline.h... no
checking for rl_callback_read_char in -lreadline... no
checking for main in -lncurses... yes
checking for rl_callback_read_char in -lreadline... no
checking for history_truncate_file... no
configure: error: --with-readline=yes (default) and headers/libs are not 
available
[root at localhost R-2.2.1]#

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From darrenleeweber at gmail.com  Wed Feb  8 21:25:51 2006
From: darrenleeweber at gmail.com (Darren Weber)
Date: Wed, 8 Feb 2006 12:25:51 -0800
Subject: [R] ERROR: no applicable method for "TukeyHSD"
Message-ID: <d2095b8c0602081225i2c505ad8ud49f23394592e3d2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060208/c5027e39/attachment.pl

From dsonneborn at ucdavis.edu  Wed Feb  8 22:10:43 2006
From: dsonneborn at ucdavis.edu (Dean Sonneborn)
Date: Wed, 08 Feb 2006 13:10:43 -0800
Subject: [R] jpeg or tiff file formats
Message-ID: <43EA5E53.10704@yellow.ucdavis.edu>

I have been creating some graphic postscript files using xyplot but now 
I find that I need then in either the jpeg or tiff format.  I have tried 
re-running just the lattice plot so that it is on the screen and then 
using the jpeg(filename="myplot"..... from the "bmp, jpec and png 
graphics devices" documentation. It seems to create an empty file. Is it 
that this function can not work with lattice plots? Can R directly write 
a jpeg or pgn file?

-- 
Dean Sonneborn, MS
Programmer Analyst
Department of Public Health Sciences
University of California, Davis
(530) 754-9516



From tkeitt at mail.utexas.edu  Wed Feb  8 22:13:44 2006
From: tkeitt at mail.utexas.edu (Tim Keitt)
Date: Wed, 08 Feb 2006 15:13:44 -0600
Subject: [R] [R-sig-Geo] envi clone in R
In-Reply-To: <43EA33CF.3080605@lancaster.ac.uk>
References: <172918418.20060208192308@eimb.ru>
	<43EA33CF.3080605@lancaster.ac.uk>
Message-ID: <1139433224.10999.26.camel@patagonicus.keittlab.net>

Barry,

I hope you will share your code! We've been using QGIS and I have in
mind just such an interface to R.

We have ENVI in the lab and it is very powerful for image processing. It
would take many many person years to reproduce all of the advanced
algorithms in that package. (It does a lot of simple operations as well
and those could easily be recoded in R.)

THK

On Wed, 2006-02-08 at 18:09 +0000, Barry Rowlingson wrote:
> Wladimir Eremeev wrote:
> > Hello all,
> > 
> >   Research Systems (www.rsinc.com) have developed and distributes the language IDL,
> >   and the GIS ENVI, written in IDL.
> 
>   I find it hard to believe they wrote it all in IDL! I'm guessing its 
> probably scriptable in IDL, but underneath its written in something 
> else... I could be wrong though!
> 
> >   To my oppinion, R language is superior, compared to IDL, in all aspects.
> >   However, ENVI is the rather convenient and feature rich tool.
> 
>   I clicked on 'Product Documentation' on the ENVI site and it wanted me 
> to log in or create a new user. To see the documentation? To find out 
> what the program is about?
> 
>   Oh, what I really wanted was the Feature Tour..
> 
> >   Is anyone aware about any work, dedicated to the creation of
> >   something, similar to the ENVI, but in R?
> 
>   Last year I looked at GIS-R linkages, with the added criteria of being 
> open source and cross-platform. There are now a few free GIS packages 
> that can do this kind of thing, with a little added glue.
> 
>   I settled on OpenEV - it has vector and raster support, its extensible 
> in Python and uses Gtk for dialogs which you can customise. All I needed 
> was to get Python talking to R, so I wrote some Python bindings to 
> Rserve. Now I've got a GIS with a menu that drops down, you choose the 
> point layers you want to work on, click 'Go', and R does some analysis 
> that ends up as a raster layer back in the GIS. The user doesnt care 
> that R did it.
> 
> Other GIS solutions are available!
> 
> Barry
> 
> _______________________________________________
> R-sig-Geo mailing list
> R-sig-Geo at stat.math.ethz.ch
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
-- 
Timothy H. Keitt
Assistant Professor
http://www.keittlab.org/
http://www.utexas.edu/directory/index.php?q=Keitt



From cbehr at edesigndynamics.com  Wed Feb  8 22:14:04 2006
From: cbehr at edesigndynamics.com (Chris Behr)
Date: Wed, 8 Feb 2006 16:14:04 -0500
Subject: [R] bwplot: how to display response variables separately in same
	panel?
Message-ID: <EBECLABIMNBHDFCEHCFHIEDKCGAA.cbehr@edesigndynamics.com>

Hi -

I have two response variables 'y1' and 'y2' and a factor 'x'. I would like
to create paired box-whiskers plots for y1~x and y2~x and labeled for the
same x. the b-w plots would be side-by-side in the same panel - almost like
a barchart with two parallel columns for the same x.

the code 'bwplot(y1+y2~x, outer=T)' gives me two side-by-side panels. this
is ok, but not exactly what i am looking for.
any ideas?

thanks, chris


Christopher Behr
Principal Analyst

eDesign Dynamics
www.edesigndynamics.com

4024 Calvert St. NW
Washington DC 20007
(202) 298-6437 (t/f)
(551) 998-4823 (c)



From Roger.Bivand at nhh.no  Wed Feb  8 22:28:37 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Wed, 8 Feb 2006 22:28:37 +0100 (CET)
Subject: [R] jpeg or tiff file formats
In-Reply-To: <43EA5E53.10704@yellow.ucdavis.edu>
Message-ID: <Pine.LNX.4.44.0602082228130.7121-100000@reclus.nhh.no>

On Wed, 8 Feb 2006, Dean Sonneborn wrote:

> I have been creating some graphic postscript files using xyplot but now 
> I find that I need then in either the jpeg or tiff format.  I have tried 
> re-running just the lattice plot so that it is on the screen and then 
> using the jpeg(filename="myplot"..... from the "bmp, jpec and png 
> graphics devices" documentation. It seems to create an empty file. Is it 
> that this function can not work with lattice plots? Can R directly write 
> a jpeg or pgn file?

Either FAQ 7.22 or dev.off()?

> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ray at mcs.vuw.ac.nz  Wed Feb  8 22:34:07 2006
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Thu, 9 Feb 2006 10:34:07 +1300 (NZDT)
Subject: [R] expand.grid without expanding
Message-ID: <200602082134.k18LY7rV010307@tahi.mcs.vuw.ac.nz>

> From: =?iso-8859-1?q?Lu=EDs_Torgo?= <ltorgo at liacc.up.pt>
> Date: Wed, 8 Feb 2006 18:08:40 +0000
> 
> Dear list,
> I've recently came across a problem that I think I've solved and that I wanted 
> to share with you for two reasons:
> - Maybe others come across the same problem.
> - Maybe someone has a much simpler solution that wants to share with me ;-)
> 
> The problem is as follows: expand.grid() allows you to generate a data.frame 
> with all combinations of a set of values, e.g.:
> > expand.grid(par1=-1:1,par2=c('a','b'))
>   par1 par2
> 1   -1    a
> 2    0    a
> 3    1    a
> 4   -1    b
> 5    0    b
> 6    1    b
> 
> There is nothing wrong with this nice function except when you have too many 
> combinations to fit in your computer memory, and that was my problem: I 
> wanted to do something for each combination of a set of variants, but this 
> set was to large for storing in memory in a data.frame generated by 
> expand.grid. A possible solution would be to have a set of nested for() 
> cycles but I preferred a solution that involved a single for() cycle going 
> from 1 to the number of combinations and then at each iteration having some 
> form of generating the combination "i". And this was the "real problem": how 
> to generate a function that picks the same style of arguments as 
> expand.grid() and provides me with the values corresponding to line "i" of 
> the data frame that would have been created bu expand.grid(). For instance, 
> if I wanted the line 4 of the above call to expand.grid() I should get the 
> same as doing:
> > expand.grid(par1=-1:1,par2=c('a','b'))[4,]
>   par1 par2
> 4   -1    b
> 
> but obviously without having to use expand.grid() as that involves generating 
> a data frame that in my case wouldn't fit in the memory of my computer.
> 
> Now, the function I've created was the following:
> --------------------------------------------
> getVariant <- function(id,vars) {
>   if (!is.list(vars)) stop('vars needs to be a list!')
>   nv <- length(vars)
>   lims <- sapply(vars,length)
>   if (id > prod(lims)) stop('id above the number of combinations!')
>   res <- vector("list",nv)
>   for(i in nv:2) {
>     f <- prod(lims[1:(i-1)])
>     res[[i]] <- vars[[i]][ceiling(id / f)]
>     id <- id - (ceiling(id/f)-1)*f
>   }
>   res[[1]] <- vars[[1]][id]
>   names(res) <- names(vars)
>   res
> }
> --------------------------------------
> > expand.grid(par1=-1:1,par2=c('a','b'))[4,]
>   par1 par2
> 4   -1    b
> > getVariant(4,list(par1=-1:1,par2=c('a','b')))
> $par1
> [1] -1
> 
> $par2
> [1] "b"
> 
> I would be glad to know if somebody came across the same problem and has a 
> better suggestion on how to solve this.
> 
A few minor improvements:
1) let id be a vector of indices
2) use %% and %/% instead of ceiling (perhaps debateable)
3) return a data frame as does expand.grid

So your function now looks like:

getVariant <- function(id, vars) {
  if (!is.list(vars)) stop('vars needs to be a list!')
  nv <- length(vars)
  lims <- sapply(vars, length)
  if (any(id > prod(lims))) stop('id above the number of combinations!')
  res <- vector("list", nv)
  for(i in nv:2) {
    f <- prod(lims[1:(i-1)])
    res[[i]] <- vars[[i]][(id - 1)%/%f + 1]
    id <- (id - 1)%%f + 1
  }
  res[[1]] <- vars[[1]][id]
  names(res) <- names(vars)
  return(as.data.frame(res))
}

Now, for example, you get:

> expand.grid(par1=-1:1,par2=c('a','b'),par3=c('w','x','y','z'))[12:15,]
   par1 par2 par3
12    1    b    x
13   -1    a    y
14    0    a    y
15    1    a    y
> getVariant(12:15,list(par1=-1:1,par2=c('a','b'), par3=c('w','x','y','z')))
  par1 par2 par3
1    1    b    x
2   -1    a    y
3    0    a    y
4    1    a    y
>                              

Note that you will run into trouble when the product of the lengths is
greater than the largest representable integer on your system.

Hope this helps,
Ray Brownrigg



From carsten.steinhoff at gmx.de  Wed Feb  8 22:50:12 2006
From: carsten.steinhoff at gmx.de (Carsten Steinhoff)
Date: Wed, 8 Feb 2006 22:50:12 +0100
Subject: [R] Simple optim - question
In-Reply-To: <mailman.13.1139396403.2737.r-help@stat.math.ethz.ch>
Message-ID: <200602082151.k18LpS6B029765@hypatia.math.ethz.ch>

Hello,

I want to find the parameters mu and sigma that minimize the following
function.
It's important, that mu and sigma are strictly positive.

-----------------
optimiere = function(fmean,smean,d,x,mu,sigma)
{
merk = c()
for (i in 1:length(d))
  merk=c(merk,1/(d[i]^2)*(d[i]-1/(fmean*(1-plnorm(x[i],mu,sigma))))^2)
return(sum(merk))
}
-----------------

To do that I'm using the nlm function, but I only get results for ONE of the
two parameters.
I cannot cope with optimizing the two parameter problem simultaneously.
I've started with:

nlm(optimiere,p=5,fmean=10,smean=10000,d=c(40,10),x=c(500000,50000),sigma=3.
5)

Then I tried to combine mu and sigma in one Vector. I get back two
parameters but the results are unreasonable since mu and sigma are
-0.3247726 and 4.7905308 but have to be strictly positive.

I've given up after hours and hope to get your help..
I'm sure the problem should be easily solved by one of the experts.

Thanks a lot.



From voodooochild at gmx.de  Wed Feb  8 23:00:57 2006
From: voodooochild at gmx.de (voodooochild@gmx.de)
Date: Wed, 08 Feb 2006 23:00:57 +0100
Subject: [R] Plotting a count process
Message-ID: <43EA6A19.7030909@gmx.de>

hello everybody,

i want to plot a count process in the following way, but i don't know
how i can do that. i have data for example x<-(0,2,6,2,8,4,.....) and
dates y which is a vector of weekly dates for example
(01/01/06, 08/01/06, 15/01/06, 22/01/06, ....), now i want to plot the
y's an the horizontal axis. On each date the count process jumps upwards
1 unit, so the vertical axis is 0, 1, 2, 3, ......
the distance between the dates is shown in vector x, so for example the
distance between 08/01/06 and 15/01/06 should be 2. maybe i can use some
times series functions for doing this?

i would be very thankful for any advice.

best regards
Andreas



From mathieu.drapeau at mcgill.ca  Thu Feb  9 00:17:49 2006
From: mathieu.drapeau at mcgill.ca (Mathieu Drapeau)
Date: Wed, 08 Feb 2006 18:17:49 -0500
Subject: [R] ROracle installation problem with R2.2
Message-ID: <43EA7C1D.80505@mcgill.ca>

Hi,
I just installed R version 2.2.1, I installed DBI package and worked 
fine and then I installed ROracle but I got this error:

[drapeau at 217w-mathieu bin]$ R CMD INSTALL 
--configure-args='--enable-extralibs' ../../ROracle_0.5-5.tar.gz
* Installing *source* package 'ROracle' ...
creating cache ./config.cache
checking how to run the C preprocessor... cc -E
updating cache ./config.cache
creating ./config.status
creating src/Makevars
sed: file conftest.s1 line 29: Unterminated `s' command
creating src/Makefile
sed: file conftest.s1 line 29: Unterminated `s' command
** libs
make: *** No targets.  Stop.
ERROR: compilation failed for package 'ROracle'
** Removing '/home/drapeau/download/R-2.2.1/library/ROracle'


Any idea what could cause this problem?
I used to install the same ROracle version with R version 1.9 and it worked.

Thanks,
Mathieu



From deepayan.sarkar at gmail.com  Thu Feb  9 02:10:51 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 8 Feb 2006 19:10:51 -0600
Subject: [R] bwplot: how to display response variables separately in
	same panel?
In-Reply-To: <EBECLABIMNBHDFCEHCFHIEDKCGAA.cbehr@edesigndynamics.com>
References: <EBECLABIMNBHDFCEHCFHIEDKCGAA.cbehr@edesigndynamics.com>
Message-ID: <eb555e660602081710k3a9277d1l1f71524df01981de@mail.gmail.com>

On 2/8/06, Chris Behr <cbehr at edesigndynamics.com> wrote:
> Hi -
>
> I have two response variables 'y1' and 'y2' and a factor 'x'. I would like
> to create paired box-whiskers plots for y1~x and y2~x and labeled for the
> same x. the b-w plots would be side-by-side in the same panel - almost like
> a barchart with two parallel columns for the same x.
>
> the code 'bwplot(y1+y2~x, outer=T)' gives me two side-by-side panels. this
> is ok, but not exactly what i am looking for.
> any ideas?

Unless you want to write your own panel function, you need to start by
coercing the data into the `long' format, e.g.

df <- data.frame(y = c(y1, y2), x = rep(x, 2), which = gl(2, length(x)))

Then you can probably do [untested]

bwplot(y ~ which | x, df, layout = c(nlevels(x), 1))

or

bwplot(y ~ x:which, df)

Deepayan



From fjohannes at fastmail.fm  Thu Feb  9 03:03:13 2006
From: fjohannes at fastmail.fm (Frank Johannes)
Date: Wed, 08 Feb 2006 18:03:13 -0800
Subject: [R] Newton-Raphson algorithm
Message-ID: <1139450593.14336.253928062@webmail.messagingengine.com>

Hi,
I want to maximize a liklihood function with multiple parameters. There
is no closed-form analytical solution to the estimates of the
parameters, and I would like to implement a Newton-Raphson iterrative
approach. Is there a maximization procedure, such as the Newton-Raphson
algorithm, available in R? If not, does anybody have an idea how to best
go about solving simultenous equations numerically in R?

Thanks for your help.
Frank.

-- 

                          love email again



From liz392 at mail.com  Thu Feb  9 04:21:41 2006
From: liz392 at mail.com (Liz Dem)
Date: Wed, 08 Feb 2006 22:21:41 -0500
Subject: [R] List Conversion
Message-ID: <20060209032141.536D71CE304@ws1-6.us4.outblaze.com>

Hello,

I have a list (mode and class are list) in R that is many elements long and of the form:
>length(list)
[1] 5778
>list[1:4]
$ID1
[1] "num1"
$ID2
[1] "num2" "num3"
$ID3
[1] "num4"
$ID4
[1] NA

I'd like to convert the $ID2 value to be in one element rather than in two.?? It shows up as c(\"num2\", \"num3\") if I try to use paste(list[2], collapse="").  I need to do this over the length of the entire list, however list2 <- apply(list, 1, paste, collapse="") tells me 'Error in apply : dim(X) must have a positive length'.  dim(list) does not have a positive length, which I think is due to the fact that it's a list and not a matrix or data frame.  

What I want to get is:
>list[1:4]
$ID1
[1] "num1"
$ID2
[1] "num2 num3"
$ID3
[1] "num4"
$ID4
[1] NA

Thanks.
Liz

-- 
___________________________________________________
Play 100s of games for FREE! http://games.mail.com/



From berwin at maths.uwa.edu.au  Thu Feb  9 04:35:53 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Thu, 9 Feb 2006 11:35:53 +0800
Subject: [R] List Conversion
In-Reply-To: <20060209032141.536D71CE304@ws1-6.us4.outblaze.com>
References: <20060209032141.536D71CE304@ws1-6.us4.outblaze.com>
Message-ID: <17386.47257.59889.910452@bossiaea.maths.uwa.edu.au>

>>>>> "LD" == Liz Dem <liz392 at mail.com> writes:

    LD> I have a list (mode and class are list) in R that is many elements long and of the form:
    >> length(list)
    LD> [1] 5778
    >> list[1:4]
    LD> $ID1
    LD> [1] "num1"
    LD> $ID2
    LD> [1] "num2" "num3"
    LD> $ID3
    LD> [1] "num4"
    LD> $ID4
    LD> [1] NA

    LD> I'd like to convert the $ID2 value to be in one element rather
    LD> than in two.?? It shows up as c(\"num2\", \"num3\") if I try to
    LD> use paste(list[2], collapse="").
You want list[[2]], not list[2]:

> tt <- list(ID1="num1", ID2=c("num2", "num3"), ID3 = "num4", ID4 =NA)
> tt
$ID1
[1] "num1"

$ID2
[1] "num2" "num3"

$ID3
[1] "num4"

$ID4
[1] NA

> paste(tt[2], collapse="")
[1] "c(\"num2\", \"num3\")"
>  paste(tt[[2]], collapse="")
[1] "num2num3"
>  paste(tt[[2]], collapse=" ")
[1] "num2 num3"


    LD> I need to do this over the length of the entire list, however
    LD> list2 <- apply(list, 1, paste, collapse="") tells me 'Error in
    LD> apply : dim(X) must have a positive length'.
You want to use `lapply' not `apply':
> tt1 <- lapply(tt, paste, collapse=" ")
> tt1
$ID1
[1] "num1"

$ID2
[1] "num2 num3"

$ID3
[1] "num4"

$ID4
[1] "NA"

    LD> What I want to get is:
    >> list[1:4]
    LD> $ID1
    LD> [1] "num1"
    LD> $ID2
    LD> [1] "num2 num3"
    LD> $ID3
    LD> [1] "num4"
    LD> $ID4
    LD> [1] NA
In that case, if you don't want NA's to turn into strings:

> tt2 <- lapply(tt, function(x) if(is.na(x[1])) NA else paste(x, collapse=" "))
> tt2
$ID1
[1] "num1"

$ID2
[1] "num2 num3"

$ID3
[1] "num4"

$ID4
[1] NA

HTH.

Cheers,

        Berwin

========================== Full address ============================
Berwin A Turlach                      Tel.: +61 (8) 6488 3338 (secr)   
School of Mathematics and Statistics        +61 (8) 6488 3383 (self)      
The University of Western Australia   FAX : +61 (8) 6488 1028
35 Stirling Highway                   
Crawley WA 6009                e-mail: berwin at maths.uwa.edu.au
Australia                        http://www.maths.uwa.edu.au/~berwin



From goedman at mac.com  Thu Feb  9 06:02:59 2006
From: goedman at mac.com (Rob J Goedman)
Date: Wed, 8 Feb 2006 21:02:59 -0800
Subject: [R] last command history???
In-Reply-To: <f80bccfd2e25773d4caf9fdb10043a39@ukaachen.de>
References: <f80bccfd2e25773d4caf9fdb10043a39@ukaachen.de>
Message-ID: <E9F7E2D7-C350-4E7E-A554-4A43C0746092@mac.com>

Thanks David,

I'll have a look at this tomorrow.

A quick check on 10.4/R2.2.1/R Cocoa GUI 1.14 (2217) didn't
reproduce the behavior you described. Can you send me your
plist (~/Library/Preferences/org.R-project.R.plist)?

As this is Mac specific, R-Sig-Mac is a better alias.

Rob


On Feb 8, 2006, at 10:47 AM, David Ruau wrote:

> Hi,
>
> I am using R 2.2.0 on Mac OS X 10.3.9. But I test the issue also  
> with R
> 2.2.1 on OS X 10.4 (Tiger)
> I have a question regarding the functioning of the history from the
> command line.
> When I press the 'up-arrow' I call back the last command (everything
> ok), let's say that I go back until the level n-5, but when I get down
> to return to the empty line, I cannot reach the empty line... The  
> empty
> line 'level' show me the content of the line n-4.
> example, let's say I did this sequence of command:
>> x <- c(1:10)
>> mean(x)
> [1] 5.5
>> sd(x)
> [1] 3.027650
>> x
>   [1]  1  2  3  4  5  6  7  8  9 10
>>
> # If I return to the command 'x <- c(1:10)' and then get down the
> bottom line is :
>> mean(x)
>
> Well it doesn't work like that under Windows and I guess under Linux.
> What is the setting that I should change?
> Or where is the error I made...
>
> David
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html



From paul.cossens at thewarehouse.co.nz  Thu Feb  9 06:21:17 2006
From: paul.cossens at thewarehouse.co.nz (Paul Cossens)
Date: Thu, 9 Feb 2006 18:21:17 +1300
Subject: [R] lme syntax for P&B examples
Message-ID: <780EF47148B1D44ABE849DBA0A93548F0DF222@whaklexch1.thewarehousegroup.net>

Hi Harold,


Thanks for your reply. I had already looked at all the reading material
you suggested but updated to the latest Matrix 
as recommneded then spent all day trying to figure out what is
happening.  

I worked through the problems and give my workings below that others may
find useful. 
(My notation is to use lme> to show lme commands and lmer> to show lmer
commands. 
I worked on two sessions in parallel. My comments are preceded by double
hashes '##' and
questions '##??'. I haven't included the datasets.)   

I have a couple of comments and outstanding issues:

1. In the Pixel data set and formulas I think the formulas are printed
incorrectly in the 
book as some use 'I(day^2)' while others use just 'day^2'. I have used
'I(day^2)'. I'm not sure why the I() function is used. In the fm4Pixel
example below the answers don't match up exactly but are close.

The lme example is 
fm1Pixel<-lme(pixel~day+I(day^2),data=Pixel,random = list(Dog=~day
,Side=~1))
fm5Pixel <- update(fm1Pixel,pixel ~ day + I(day^2) + Side)
which I have converted to lmer:
fm4Pixel <- lmer(pixel ~ day + I(day^2) +Side +(day|Dog), data = Pixel)

The t-values for Side are close (sse below) but different enough to
wonder if I am still doing something wrong? 

2. To me the specification description in the R-News article is
confusing as it seems 
to suggest that nesting does not need to be completely specified if the
groupings and nestings are clear in data set. 

Prof Bates article in R news vol 5/1 P 30  states "It happens in this
case that the grouping factors 'id' and 'sch' are not nested but if they
were nested there would be no change in the model specification"

If the lme formula is 
fm1Oxide<-lme(Thickness~1,Oxide)

I have found the formula lmer parlance should be:
'fm1Oxide<-lmer(Thickness~ (1|Lot)+(1|Lot:Wafer),data=Oxide)'
not 'fm1Oxide<-lmer(Thickness~ (1|Lot)+(1|Wafer),data=Oxide)'
as the article reads to me. 

In other words you always need to explicitly specify nesting levels.

3. I still can't figue out how to replicate the lme formula
fm2Oxide<-update(fm1Oxide,random =~1|Lot)
i.e 
formula(fm2Oxide)
Thickness ~ 1

If I simply drop the Lot:Wafer term as in 'fm2Oxide<-lmer(Thickness~
(1|Lot),data=Oxide)'
I get the error

'Error in x[[3]] : object is not subsettable'

what's the solution?

I'd be interested to read you article for further insights.

Thanks

Paul



#############################################################
#Oxide
# P&B(2000) p167-170

#NLME lme example

lme>data(Oxide)
lme>formula(Oxide)
lme>Thickness ~ 1 | Lot/Wafer
lme>fm1Oxide<-lme(Thickness~1,Oxide)
lme> fm1Oxide
Linear mixed-effects model fit by REML
  Data: Oxide 
  Log-restricted-likelihood: -227.0110
  Fixed: Thickness ~ 1 
(Intercept) 
   2000.153 

Random effects:
 Formula: ~1 | Lot
        (Intercept)
StdDev:    11.39768

 Formula: ~1 | Wafer %in% Lot
        (Intercept) Residual
StdDev:    5.988802 3.545341

Number of Observations: 72
Number of Groups: 
           Lot Wafer %in% Lot 
             8             24 

lme> intervals(fm1Oxide, which = "var-cov")
Approximate 95% confidence intervals

 Random Effects:
  Level: Lot 
                  lower     est.    upper
sd((Intercept)) 6.38881 11.39768 20.33355
  Level: Wafer 
                   lower     est.    upper
sd((Intercept)) 4.063919 5.988802 8.825408

 Within-group standard error:
   lower     est.    upper 
2.902491 3.545341 4.330572 
fm2Oxide<-update(fm1Oxide,random =~1|Lot)
lme> fm2Oxide
Linear mixed-effects model fit by REML
  Data: Oxide 
  Log-restricted-likelihood: -245.5658
  Fixed: Thickness ~ 1 
(Intercept) 
   2000.153 

Random effects:
 Formula: ~1 | Lot
        (Intercept) Residual
StdDev:    11.78447 6.282416

Number of Observations: 72
Number of Groups: 8

lme>intervals(fm2Oxide, which = "var-cov")
Approximate 95% confidence intervals

 Random Effects:
  Level: Lot 
                   lower     est.    upper
sd((Intercept)) 6.864617 11.78447 20.23035

 Within-group standard error:
   lower     est.    upper 
5.283116 6.282416 7.470733 

lme> coef(fm1Oxide, level=1)
  (Intercept)
1    1996.689
2    1988.931
3    2001.022
4    1995.682
5    2013.616
6    2019.561
7    1991.954
8    1993.767
coef(fm1Oxide, level=1)
  (Intercept)
1    1996.689
2    1988.931
3    2001.022
4    1995.682
5    2013.616
6    2019.561
7    1991.954
8    1993.767
> coef(fm1Oxide, level=2)
    (Intercept)
1/1    2003.235
1/2    1984.730
1/3    2001.146
2/1    1989.590
2/2    1988.097
2/3    1986.008
3/1    2002.495
3/2    2000.405
3/3    2000.405
4/1    1995.668
4/2    1998.951
4/3    1991.191
5/1    2009.184
5/2    2016.646
5/3    2018.735
6/1    2031.296
6/2    2021.745
6/3    2011.000
7/1    1990.204
7/2    1991.398
7/3    1991.995
8/1    1993.677
8/2    1995.170
8/3    1990.693


######## the is the lmer example using Matrix 0.995-5


lmer>Oxide<-read.csv("Oxide.csv",header=TRUE);
lmer>Oxide$Source<-as.factor(Oxide$Source)
lmer>Oxide$Lot<-as.factor(Oxide$Lot)
lmer>Oxide$Wafer<-as.factor(Oxide$Wafer)
Lmer>Oxide$Site<-as.factor(Oxide$Site)


## Bates article in R news vol5/1 says specifying nesting explicity
isn't necessary: 
## P 30 "It happens in this case that the grouping factors 'id' and
'sch' are not 
## nested but if they were nested there would be no change in the model
specification"
## Following this one would expect that the following statement would
automatically 
## detect nesting

lmer>fm1Oxide<-lmer(Thickness~ (1|Lot)+(1|Wafer),data=Oxide)


lmer> fm1Oxide
Linear mixed-effects model fit by REML
Formula: Thickness ~ (1 | Lot) + (1 | Wafer) 
   Data: Oxide 
      AIC      BIC    logLik MLdeviance REMLdeviance
 496.6093 503.4393 -245.3046   495.3528     490.6093
Random effects:
 Groups   Name        Variance Std.Dev.
 Lot      (Intercept) 138.9981 11.7897 
 Wafer    (Intercept)   1.4930  1.2219 
 Residual              38.3490  6.1927 
# of obs: 72, groups: Lot, 8; Wafer, 3

Fixed effects:
             Estimate Std. Error t value
(Intercept) 2000.1528     4.2901  466.22

## The lme vs lmer std.devs for Lot are 11.39768 : 11.7987  
## The lme vs lmer std.devs for Wafer are 5.988802 : 1.2219 
## If my lmer specifcation is correct then the Wafer std.dev seems too
big.
## also the levels aren't specifed correctly as the following ranef()
function
## shows

lmer> ranef(fm1Oxide)
An object of class "lmer.ranef"
[[1]]
  (Intercept)
1  -3.7058415
2 -12.0069264
3   0.9298293
4  -4.7839045
5  14.4056166
6  20.7661881
7  -8.7727375
8  -6.8322241

[[2]]
  (Intercept)
1   0.9526407
2  -0.2750582
3  -0.6775825

###There is no nesting of wafers within lots
###Note however that the following appears to work the same as in the
P&B text
 
lmer> fm3Oxide<-lmer(Thickness~ (1|Lot)+(1|Lot:Wafer),data=Oxide)
lmer> fm3Oxide
Linear mixed-effects model fit by REML
Formula: Thickness ~ (1 | Lot) + (1 | Lot:Wafer) 
   Data: Oxide 
      AIC      BIC    logLik MLdeviance REMLdeviance
 460.0221 466.8521 -227.0110   458.7378     454.0221
Random effects:
 Groups    Name        Variance Std.Dev.
 Lot:Wafer (Intercept)  35.866   5.9888 
 Lot       (Intercept) 129.853  11.3953 
 Residual               12.570   3.5454 
# of obs: 72, groups: Lot:Wafer, 24; Lot, 8

Fixed effects:
             Estimate Std. Error t value
(Intercept) 2000.1528     4.2309  472.75

## the following gives the coefficients for levels however the number of
levels is 
## in reverse order to lme
## Also note that the order of levels seems to have changed from the
lmer model 
## fm1Oxide where Lot coefficnets are in [[1]] and Wafer [[2]] 
lmer>ranef(fm3Oxide)
An object of class "lmer.ranef"
[[1]]
     (Intercept)
1:1   6.54582998
1:2 -11.95898390
1:3   4.45657680
2:1   0.65819690
2:2  -0.83412680
2:3  -2.92337998
3:1   1.47284009
3:2  -0.61641309
3:3  -0.61641309
4:1  -0.01366505
4:2   3.26944709
4:3  -4.49063615
5:1  -4.43133801
5:2   3.03028049
5:3   5.11953367
6:1  11.73559478
6:2   2.18472310
6:3  -8.56000754
7:1  -1.74970878
7:2  -0.55584982
7:3   0.04107966
8:1  -0.09041889
8:2   1.40190481
8:3  -3.07506629

[[2]]
  (Intercept)
1   -3.463334
2  -11.221203
3    0.868982
4   -4.470850
5   13.462925
6   19.407266
7   -8.198657
8   -6.385129

##?? given that the fm3Oxide works one would expect that dropping the 
##?? (1|Lot:Wafer) term would work however it give the following error

lmer>fm2Oxide<-lmer(Thickness~ (1|Lot),data=Oxide)
Error in x[[3]] : object is not subsettable

##?? the question is how to specify the lme model
fm2Oxide<-update(fm1Oxide,random =~1|Lot)
##?? in lme syntax


######################################################################

#Pixel
# P&B(2000) p40-45

## the lme example is as follows

lme>data(Pixel)

## firstly the book may have an error on P 42 line 1
lme_wrong> fm1Pixel<-lme(pixel~day+day^2,data=Pixel,random = list(Dog= ~
day ,Side= ~ 1))
###which gives: 
lme_wrong> intervals(fm1Pixel)
Approximate 95% confidence intervals

 Fixed effects:
                  lower       est.       upper
(Intercept) 1071.415167 1093.21538 1115.015590
day           -1.126053   -0.14867    0.828713
attr(,"label")
[1] "Fixed effects:"

 Random Effects:
  Level: Dog 
                          lower       est.      upper
sd((Intercept))      17.3485293 31.4936604 57.1720308
sd(day)               0.3586459  1.0719672  3.2040342
cor((Intercept),day) -0.9822311 -0.7863546  0.2294876
  Level: Side 
                   lower     est.    upper
sd((Intercept)) 8.519543 15.08995 26.72755

 Within-group standard error:
   lower     est.    upper 
12.35975 14.53391 17.09052 

## the book should probably give I(day^2) instead of day^2 on p42 line 1
where 
## as this gives the answer in the book
lme> fm1Pixel<-lme(pixel~day+I(day^2),data=Pixel,random = list(Dog=~day
,Side=~1))
lme> intervals(fm1Pixel)
Approximate 95% confidence intervals

 Fixed effects:
                   lower         est.        upper
(Intercept) 1053.0968388 1073.3391382 1093.5814376
day            4.3796925    6.1295971    7.8795016
I(day^2)      -0.4349038   -0.3673503   -0.2997967
attr(,"label")
[1] "Fixed effects:"

 Random Effects:
  Level: Dog 
                          lower       est.      upper
sd((Intercept))      15.9284469 28.3699038 50.5291851
sd(day)               1.0812133  1.8437505  3.1440751
cor((Intercept),day) -0.8944371 -0.5547222  0.1909581
  Level: Side 
                   lower     est.    upper
sd((Intercept)) 10.41726 16.82431 27.17195

 Within-group standard error:
    lower      est.     upper 
 7.634522  8.989606 10.585209 

lme>VarCorr(fm1Pixel) 
            Variance       StdDev    Corr  
Dog =       pdLogChol(day)                 
(Intercept) 804.851443     28.369904 (Intr)
day           3.399416      1.843750 -0.555
Side =      pdLogChol(1)                   
(Intercept) 283.057248     16.824305       
Residual     80.813009      8.989606

lme>  summary(fm1Pixel)
Linear mixed-effects model fit by REML
 Data: Pixel 
       AIC      BIC    logLik
  841.2102 861.9712 -412.6051

Random effects:
 Formula: ~day | Dog
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev    Corr  
(Intercept) 28.369904 (Intr)
day          1.843750 -0.555

 Formula: ~1 | Side %in% Dog
        (Intercept) Residual
StdDev:    16.82431 8.989606

Fixed effects: pixel ~ day + I(day^2) 
                Value Std.Error DF   t-value p-value
(Intercept) 1073.3391 10.171686 80 105.52225       0
day            6.1296  0.879321 80   6.97083       0
I(day^2)      -0.3674  0.033945 80 -10.82179       0
 Correlation: 
         (Intr) day   
day      -0.517       
I(day^2)  0.186 -0.668

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-2.82905723 -0.44918107  0.02554930  0.55721629  2.75196509 

Number of Observations: 102
Number of Groups: 
          Dog Side %in% Dog 
           10            20  

## Note thate the formula in the book is on P44 sect 1.5.1 summary table
is
##  Fixed effects: pixel ~ day + day^2 
## compared to above:
## Fixed effects: pixel ~ day + I(day^2)
## but the anova on page 45 is the same

lme>fm2Pixel <- update(fm1Pixel,random = ~day | Dog)
lme>anova(fm1Pixel,fm2Pixel)
         Model df      AIC      BIC    logLik   Test L.Ratio p-value
fm1Pixel     1  8 841.2102 861.9712 -412.6051                       
fm2Pixel     2  7 884.5196 902.6854 -435.2598 1 vs 2 45.3094  <.0001


lme> fm3Pixel <- update(fm1Pixel,random = ~1 | Dog/Side)
lme > anova(fm1Pixel,fm3Pixel)
         Model df      AIC      BIC    logLik   Test  L.Ratio p-value
fm1Pixel     1  8 841.2102 861.9712 -412.6051                        
fm3Pixel     2  6 876.8390 892.4098 -432.4195 1 vs 2 39.62885  <.0001


##again there following seems to be a mistake in the book

lme> fm4Pixel <- update(fm1Pixel,pixel ~ day + day^2 + Side)
lme> summary(fm4Pixel)
Linear mixed-effects model fit by REML
 Data: Pixel 
      AIC     BIC    logLik
  895.071 915.832 -439.5355

Random effects:
 Formula: ~day | Dog
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev    Corr  
(Intercept) 31.520129 (Intr)
day          1.073342 -0.786

 Formula: ~1 | Side %in% Dog
        (Intercept) Residual
StdDev:    15.01697 14.50742

Fixed effects: pixel ~ day + Side 
                Value Std.Error DF  t-value p-value
(Intercept) 1097.5272 11.562590 81 94.92053  0.0000
day           -0.1496  0.491218 81 -0.30451  0.7615
SideR         -8.6098  7.379984  9 -1.16664  0.2733
 Correlation: 
      (Intr) day   
day   -0.633       
SideR -0.319  0.000

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-3.73906417 -0.38367706  0.04758941  0.39690056  2.23720545 

Number of Observations: 102
Number of Groups: 
          Dog Side %in% Dog 
           10            20 

###the book should probably give I(day^2) instead of day^2
### as the fixed effect coefficient names in the summary table 
##  differ from the formula given
##  the following seems a partial correction   
lme> fm5Pixel <- update(fm1Pixel,pixel ~ day + I(day^2) + Side)
lme>summary(fm5Pixel)

Linear mixed-effects model fit by REML
 Data: Pixel 
       AIC      BIC    logLik
  835.8546 859.1193 -408.9273

Random effects:
 Formula: ~day | Dog
 Structure: General positive-definite, Log-Cholesky parametrization
            StdDev    Corr  
(Intercept) 28.463605 (Intr)
day          1.843823 -0.553

 Formula: ~1 | Side %in% Dog
        (Intercept) Residual
StdDev:     16.5072 8.983614

Fixed effects: pixel ~ day + I(day^2) + Side 
                Value Std.Error DF   t-value p-value
(Intercept) 1077.9484 10.862705 80  99.23388  0.0000
day            6.1296  0.879023 80   6.97323  0.0000
I(day^2)      -0.3674  0.033923 80 -10.82914  0.0000
SideR         -9.2175  7.626768  9  -1.20858  0.2576
 Correlation: 
         (Intr) day    I(d^2)
day      -0.484              
I(day^2)  0.174 -0.667       
SideR    -0.351  0.000  0.000

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-2.80982455 -0.47133415  0.02610263  0.54115378  2.77470104 

Number of Observations: 102
Number of Groups: 
          Dog Side %in% Dog 
           10            20 


## Note however that the Fixed effects Values above differ from the
values in the book  

####### the is the lmer example for Pixel using Matrix 0.995-5

##the lmer example for the Pixel data is exported and reimported as a
csv file
lmer>Pixel<-read.csv("Pixel.csv",header=TRUE);
lmer>Pixel$Side<-as.factor(Pixel$Side)
lmer>Pixel$Dog<-as.factor(Pixel$Dog)
lmer>Pixel$DS<-with(Pixel,Dog:Side)[drop=TRUE]
 
lmer>fm1Pixel <- lmer(pixel ~ day + I(day^2) +(day|Dog)+(1|Dog:Side),
data = Pixel)
lmer>fm1Pixel
Linear mixed-effects model fit by REML
Formula: pixel ~ day + I(day^2) + (day | Dog) + (1 | Dog:Side) 
   Data: Pixel 
      AIC     BIC    logLik MLdeviance REMLdeviance
 839.2102 857.585 -412.6051   827.3298     825.2102
Random effects:
 Groups   Name        Variance Std.Dev. Corr   
 Dog:Side (Intercept) 283.0567 16.8243         
 Dog      (Intercept) 804.8460 28.3698         
          day           3.3994  1.8438  -0.555 
 Residual              80.8130  8.9896         
# of obs: 102, groups: Dog:Side, 20; Dog, 10

Fixed effects:
               Estimate  Std. Error t value
(Intercept) 1073.339126   10.171658 105.523
day            6.129599    0.879321   6.971
I(day^2)      -0.367350    0.033945 -10.822

Correlation of Fixed Effects:
         (Intr) day   
day      -0.517       
I(day^2)  0.186 -0.668

## 

lme> VarCorr(fm1Pixel)
$"Dog:Side"
1 x 1 Matrix of class "dpoMatrix"
            (Intercept)
(Intercept)    283.0567

$Dog
2 x 2 Matrix of class "dpoMatrix"
            (Intercept)        day
(Intercept)   804.84605 -29.015418
day           -29.01542   3.399415

attr(,"sc")
[1] 8.989606

lmer> fm2Pixel <- lmer(pixel ~ day + I(day^2) +(day|Dog), data = Pixel)
lmer> fm2Pixel
Linear mixed-effects model fit by REML
Formula: pixel ~ day + I(day^2) + (day | Dog) 
   Data: Pixel 
      AIC      BIC    logLik MLdeviance REMLdeviance
 882.5196 898.2694 -435.2598   873.5964     870.5196
Random effects:
 Groups   Name        Variance Std.Dev. Corr   
 Dog      (Intercept) 892.7720 29.8793         
          day           3.0772  1.7542  -0.488 
 Residual             197.5767 14.0562         
# of obs: 102, groups: Dog, 10

Fixed effects:
              Estimate Std. Error t value
(Intercept) 1072.92725   10.44452 102.726
day            6.08910    1.14699   5.309
I(day^2)      -0.35677    0.05221  -6.833

Correlation of Fixed Effects:
         (Intr) day   
day      -0.541       
I(day^2)  0.286 -0.799

lmer> anova(fm1Pixel,fm2Pixel)

Data: Pixel
Models:
fm2Pixel: pixel ~ day + I(day^2) + (day | Dog)
fm1Pixel: pixel ~ day + I(day^2) + (day | Dog) + (1 | Dog:Side)
         Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)    
fm2Pixel  6  882.52  898.27 -435.26                             
fm1Pixel  7  839.21  857.59 -412.61 45.309      1  1.682e-11 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

## Some of the statistics here are slightly different from above,
notably the Df 
## but I guess the result is the same

lmer> fm3Pixel <- lmer(pixel ~ day + I(day^2) +(1|Dog:Side), data =
Pixel)
lmer> anova(fm1Pixel,fm3Pixel)

Data: Pixel
Models:
fm3Pixel: pixel ~ day + I(day^2) + (1 | Dog:Side)
fm1Pixel: pixel ~ day + I(day^2) + (day | Dog) + (1 | Dog:Side)
         Df     AIC     BIC  logLik Chisq Chi Df Pr(>Chisq)    
fm3Pixel  4  877.88  888.38 -434.94                            
fm1Pixel  7  839.21  857.59 -412.61 44.67      3  1.087e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

## Some of the statistics are slightly different again

lmer>fm4Pixel <- lmer(pixel ~ day + I(day^2) +Side +(day|Dog), data =
Pixel)
lmer>fm4Pixel

Linear mixed-effects model fit by REML
Formula: pixel ~ day + I(day^2) + Side + (day | Dog) 
   Data: Pixel 
      AIC      BIC    logLik MLdeviance REMLdeviance
 876.8204 895.1952 -431.4102   869.6765     862.8204
Random effects:
 Groups   Name        Variance Std.Dev. Corr   
 Dog      (Intercept) 896.1278 29.9354         
          day           3.0972  1.7599  -0.490 
 Residual             190.9227 13.8175         
# of obs: 102, groups: Dog, 10

Fixed effects:
               Estimate  Std. Error t value
(Intercept) 1075.649999   10.521427 102.234
day            6.091506    1.133983   5.372
I(day^2)      -0.357334    0.051369  -6.956
SideR         -5.401961    2.736268  -1.974

Correlation of Fixed Effects:
         (Intr) day    I(d^2)
day      -0.535              
I(day^2)  0.279 -0.795       
SideR    -0.130  0.000  0.000

##?? Fixed effects estimates are sligtly different 
##?? As df and p-values are missing I assume that it can be concluded
that as 
##?? t-value is less than 1.96 that 'Side' is not sigificant. 
##?? In the lme example for fm4Pixel the t-value for Side is -1.21
##?? have i specified fm4Pixel correctly?

-----Original Message-----
From: Doran, Harold [mailto:HDoran at air.org] 
Sent: Thursday, 9 February 2006 02:01
To: Paul Cossens; r-help at stat.math.ethz.ch
Subject: RE: [R] lme syntax for P&B examples


Paul:

It is a little difficult to understand what you are trying to translate
since you do not show what the model would look like using lme. If you
show lme, then it is easy to translate into lmer syntax.

A few thoughts, first, use lmer in the Matrix package and not in lme4.
Second, see the Bates article in R news at the link below for dealing
with nesting structures. Last, a colleague and I have a paper in press
showing how to fit models using lme which we submitted a year or so ago.
Since lme has evolved to lmer, we created an appendix that translates
all of our lme models to the lmer syntax so readers can see
equivalences. I am happy to send this to you (or others) upon request.

http://cran.r-project.org/doc/Rnews/Rnews_2005-1.pdf

Harold


 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Paul Cossens
Sent: Wednesday, February 08, 2006 12:08 AM
To: r-help at stat.math.ethz.ch
Subject: [R] lme syntax for P&B examples

Hi helpeRs,
 
I've been working through some examples in Pinhiero & Bates( 2000)
trying to understand how to translate to the new Lme4 syntax but without
much luck. Below is what I think I should do, but either the answers
don't come out the same or I get errors. 
In the Oxide problems I'm particularly interested in obtaining the
levels coeficients but this options no longer seems to be available in
lme4. How can levels infor be obtained in lme4?
 
If someone can recreate the examples below in lme4 syntax so I can
follow what is happening in the text I'd be grateful. 
 
Cheers
 
Paul Cossens
 
 
#Pixel
# P&B(2000) p40-45
 
Pixel<-read.csv("Pixel.csv",header=TRUE);
Pixel$Side<-as.factor(Pixel$Side)
Pixel$Dog<-as.factor(Pixel$Dog)
 
(fm1Pixel <- lmer(pixel ~ day + I(day^2) +(day|Dog)+(1|Side), data =
Pixel))
(fm2Pixel <- lmer(pixel ~ day + I(day^2) +(day|Dog), data = Pixel))
(fm3Pixel <- lmer(pixel ~ day + I(day^2) +(1|Dog:Side), data = Pixel))
or should I do it this way? Pixel$DS<-with(Pixel,Dog:Side)[drop=TRUE]
(fm3Pixel <- lmer(pixel ~ day + I(day^2) +(1|DS), data = Pixel))
 
(fm4Pixel <- lmer(pixel ~ day + I(day^2) +Side , data = Pixel))
 

#Oxide
# P&B(2000) p167-170
 
Oxide<-read.csv("Oxide.csv",header=TRUE);
Oxide$Source<-as.factor(Oxide$Source)
Oxide$Lot<-as.factor(Oxide$Lot)
Oxide$Wafer<-as.factor(Oxide$Wafer)
Oxide$Site<-as.factor(Oxide$Site)
fm1Oxide<-lmer(Thickness~ (1|Lot)+(1|Lot:Wafer),data=Oxide) )
(fm2Oxide<-lmer(Thickness~ (1|Lot),data=Oxide) )
coef(fm1Oxide)

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Thu Feb  9 08:22:34 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Feb 2006 07:22:34 +0000 (GMT)
Subject: [R] Newton-Raphson algorithm
In-Reply-To: <1139450593.14336.253928062@webmail.messagingengine.com>
References: <1139450593.14336.253928062@webmail.messagingengine.com>
Message-ID: <Pine.LNX.4.64.0602090719290.26108@gannet.stats.ox.ac.uk>

To maximize a function numerically it not usual do not solve equations: it 
is less efficient.

help.search("optimize")

will show you what is available for maximization.

Or see chapter 16 of MASS4.

On Wed, 8 Feb 2006, Frank Johannes wrote:

> Hi,
> I want to maximize a liklihood function with multiple parameters. There
> is no closed-form analytical solution to the estimates of the
> parameters, and I would like to implement a Newton-Raphson iterrative
> approach. Is there a maximization procedure, such as the Newton-Raphson
> algorithm, available in R? If not, does anybody have an idea how to best
> go about solving simultenous equations numerically in R?
>
> Thanks for your help.
> Frank.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sell_mirage_ne at hotmail.com  Thu Feb  9 08:26:15 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Thu, 09 Feb 2006 01:26:15 -0600
Subject: [R] writing a file using both cat() and paste()
Message-ID: <BAY110-F8061D150F575064B6404DC7030@phx.gbl>

Hi R users

I like to create a ASCII type file using cat() and paste()

x <- round(runif(30),3)
cat("vector =( ", paste(x,sep=""), " )\n", file = "vector.dat",sep=",")

when I open vector.dat it was a long ugly file

vector =( 
,0.463,0.515,0.202,0.232,0.852,0.367,0.432,0.74,0.413,0.022,0.302,0.114,0.583,0.002,0.919,0.066,0.829,0.405,0.363,0.665,0.109,0.38,0.187,0.322,0.582,0.011,0.586,0.112,0.873,0.671, 
)

Also there was some problems right after opening parenthesis and before the 
closing parenthesis. Two comma were there

I like to to have a nice formatted one like below. That is, 5 random values 
per a line

vector =( 0.463,0.515,0.202,0.232,0.852,
0.367,0.432,0.74,0.413,0.022,
0.302,0.114,0.583,0.002,0.919,
0.066,0.829,0.405,0.363,0.665,
0.109,0.38,0.187,0.322,0.582,
0.011,0.586,0.112,0.873,0.671)

I would be appreciative if I get some help

TM



From ripley at stats.ox.ac.uk  Thu Feb  9 08:29:43 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Feb 2006 07:29:43 +0000 (GMT)
Subject: [R] lme syntax for P&B examples
In-Reply-To: <780EF47148B1D44ABE849DBA0A93548F0DF222@whaklexch1.thewarehousegroup.net>
References: <780EF47148B1D44ABE849DBA0A93548F0DF222@whaklexch1.thewarehousegroup.net>
Message-ID: <Pine.LNX.4.64.0602090723110.26108@gannet.stats.ox.ac.uk>

On Thu, 9 Feb 2006, Paul Cossens wrote:

> Hi Harold,
>
>
> Thanks for your reply. I had already looked at all the reading material
> you suggested but updated to the latest Matrix
> as recommneded then spent all day trying to figure out what is
> happening.
>
> I worked through the problems and give my workings below that others may
> find useful.
> (My notation is to use lme> to show lme commands and lmer> to show lmer
> commands.
> I worked on two sessions in parallel. My comments are preceded by double
> hashes '##' and
> questions '##??'. I haven't included the datasets.)
>
> I have a couple of comments and outstanding issues:
>
> 1. In the Pixel data set and formulas I think the formulas are printed
> incorrectly in the
> book as some use 'I(day^2)' while others use just 'day^2'. I have used
> 'I(day^2)'. I'm not sure why the I() function is used. In the fm4Pixel
> example below the answers don't match up exactly but are close.

That is an R/S difference (documented in the FAQ).  In R day^2 is the same 
as day in a formula.

The book is about S, not R (as its title tells you).

> The lme example is
> fm1Pixel<-lme(pixel~day+I(day^2),data=Pixel,random = list(Dog=~day
> ,Side=~1))
> fm5Pixel <- update(fm1Pixel,pixel ~ day + I(day^2) + Side)
> which I have converted to lmer:
> fm4Pixel <- lmer(pixel ~ day + I(day^2) +Side +(day|Dog), data = Pixel)
>
> The t-values for Side are close (sse below) but different enough to
> wonder if I am still doing something wrong?
>
> 2. To me the specification description in the R-News article is
> confusing as it seems
> to suggest that nesting does not need to be completely specified if the
> groupings and nestings are clear in data set.
>
> Prof Bates article in R news vol 5/1 P 30  states "It happens in this
> case that the grouping factors 'id' and 'sch' are not nested but if they
> were nested there would be no change in the model specification"
>
> If the lme formula is
> fm1Oxide<-lme(Thickness~1,Oxide)
>
> I have found the formula lmer parlance should be:
> 'fm1Oxide<-lmer(Thickness~ (1|Lot)+(1|Lot:Wafer),data=Oxide)'
> not 'fm1Oxide<-lmer(Thickness~ (1|Lot)+(1|Wafer),data=Oxide)'
> as the article reads to me.
>
> In other words you always need to explicitly specify nesting levels.

You cannot deduce `always' from one example.  It depends if (in your case) 
the Wafers are numbered uniquely or the same in each Lot.  This comes up 
frequently with muiti-stratum aov and lme.

Notice that Dr Bates carefully said `It happens in this case', so he did 
not generalize from a single example.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From wl at eimb.ru  Thu Feb  9 08:58:28 2006
From: wl at eimb.ru (Wladimir Eremeev)
Date: Thu, 9 Feb 2006 10:58:28 +0300
Subject: [R] [R-sig-Geo] envi clone in R
In-Reply-To: <43EA33CF.3080605@lancaster.ac.uk>
References: <172918418.20060208192308@eimb.ru>
	<43EA33CF.3080605@lancaster.ac.uk>
Message-ID: <5810595588.20060209105828@eimb.ru>

Dear Barry,

Wednesday, February 8, 2006, 9:09:19 PM, you wrote:

BR> Wladimir Eremeev wrote:
>> Hello all,
>> 
>>   Research Systems (www.rsinc.com) have developed and distributes the language IDL,
>>   and the GIS ENVI, written in IDL.

BR>   I find it hard to believe they wrote it all in IDL! I'm guessing its
BR> probably scriptable in IDL, but underneath its written in something
BR> else... I could be wrong though!

Well, not in IDL completely, I think, there is also C and Fortran code
underneath.

>>   To my oppinion, R language is superior, compared to IDL, in all aspects.
>>   However, ENVI is the rather convenient and feature rich tool.

By the way, even the interface to an external code is implemented in R
much more conveniently, compared to IDL.
It took me several hours to make IDL to call my C functions from DLL.
I have read the documentation carefully 2 or 3 times...

And I have done the same task in R in several minutes.

---
Best regards,
Wladimir                mailto:wl at eimb.ru



From dieter.menne at menne-biomed.de  Thu Feb  9 09:08:29 2006
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Thu, 9 Feb 2006 08:08:29 +0000 (UTC)
Subject: [R] Plotting a count process
References: <43EA6A19.7030909@gmx.de>
Message-ID: <loom.20060209T090654-531@post.gmane.org>

 <voodooochild <at> gmx.de> writes:

> i want to plot a count process in the following way, but i don't know
> how i can do that. i have data for example x<-(0,2,6,2,8,4,.....) and
> dates y which is a vector of weekly dates for example
> (01/01/06, 08/01/06, 15/01/06, 22/01/06, ....), now i want to plot the
> y's an the horizontal axis. On each date the count process jumps upwards
> 1 unit, so the vertical axis is 0, 1, 2, 3, ......
> the distance between the dates is shown in vector x, so for example the
> distance between 08/01/06 and 15/01/06 should be 2. maybe i can use some
> times series functions for doing this?
> 

If I understand you correctly, this means plotting equidistant point against 
the cumulative sum. Forgetting about the dates now, this would do it.

x = floor(pmax(rnorm(30,5,2),1))
xcum = cumsum(x)
plot(xcum,1:30)

Dieter



From dieter.menne at menne-biomed.de  Thu Feb  9 09:17:38 2006
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Thu, 9 Feb 2006 08:17:38 +0000 (UTC)
Subject: [R] Simple optim - question
References: <mailman.13.1139396403.2737.r-help@stat.math.ethz.ch>
	<200602082151.k18LpS6B029765@hypatia.math.ethz.ch>
Message-ID: <loom.20060209T091523-518@post.gmane.org>

Carsten Steinhoff <carsten.steinhoff <at> gmx.de> writes:

> I want to find the parameters mu and sigma that minimize the following
> function.
> It's important, that mu and sigma are strictly positive.
> 
> -----------------
> optimiere = function(fmean,smean,d,x,mu,sigma)
> {
> merk = c()
> for (i in 1:length(d))
>   merk=c(merk,1/(d[i]^2)*(d[i]-1/(fmean*(1-plnorm(x[i],mu,sigma))))^2)
> return(sum(merk))
> }
> -----------------
> 
....

Try optim or nlminb, both can be used with constraints. Or, as your example 
looks like a least-square problem, reformulate optim and use nls.

Dieter



From buser at stat.math.ethz.ch  Thu Feb  9 09:22:30 2006
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Thu, 9 Feb 2006 09:22:30 +0100
Subject: [R] logical condition in vector operation
In-Reply-To: <1139422357.22690.12.camel@localhost.localdomain>
References: <1139422357.22690.12.camel@localhost.localdomain>
Message-ID: <17386.64454.662868.47685@stat.math.ethz.ch>

Dear Frederico

>From your example it is not clear to me what you like to obtain: 
Please have a look on the slightly changed example here (I
changed two values to show a potentially undesired side effect of
your coding.


test <- data.frame(rbind(c(3,3,10,21,0), c(2,3,11,12,0), c(3,4,12,23,0),
                         c(3,5,13,24,0)))
names(test) <- c("x","y","p","d","su")
test

>>   x y  p  d su
>> 1 3 3 10 21  0
>> 2 2 3 11 12  0
>> 3 3 4 12 23  0
>> 4 3 5 13 24  0

j <- 3
test[test[,1] == j, 5] <- test[test[,1] == j,2] + test[test[,2] == j,1]

>> > > Warning message:
>> longer object length
>> 	is not a multiple of shorter object length in: 
>>         test[test[, 1] == j, 2] + test[test[, 2] == j, 1] 

Your code example produces now a warning for the adapted
data frame "test", since one tries to add two vectors of length 2
and 3, respectively. The result is based on recycling of the
smaller vector. In your example there was no warning since the
second column had only one entry.
The result with the adapted data frame is:

test
>>   x y  p  d su
>> 1 3 3 10 21  6
>> 2 2 3 11 12  0
>> 3 3 4 12 23  6
>> 4 3 5 13 24  8

Is that kind of recycling desired in your application. Otherwise
you should be careful with the coding example above.

Regards,

Christoph Buser

--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C13
ETH (Federal Inst. Technology)	8092 Zurich	 SWITZERLAND
phone: x-41-44-632-4673		fax: 632-1228
http://stat.ethz.ch/~buser/
--------------------------------------------------------------






Federico Calboli writes:
 > HI All,
 > 
 > I have a data frame such as:
 > 
 > > test
 >      x y  p  d
 > [1,] 1 0 10 21 0
 > [2,] 2 3 11 12 0
 > [3,] 3 4 12 23 0
 > [4,] 3 5 13 24 0
 > 
 > 
 > and I want to perfor some operations on the first two coulums,
 > conditional on the uneqaulity values on the 3rd and 4th columns.
 > 
 > For instance:
 > 
 > j = 3
 > test[test[,1] == j, 5] = test[test[,1] == j,2] + test[test[,2] == j,1]
 > 
 > gives me the result:
 > 
 > test:
 > 
 >      x y  p  d
 > [1,] 1 0 10 21 0
 > [2,] 2 3 11 12 0
 > [3,] 3 4 12 23 6
 > [4,] 3 5 13 24 7
 > 
 > 
 > My probblem is the following: I want to perform the operation
 > test[test[,1] == j,2] + test[test[,2] == j,1] only if the value of
 > column p and column d are different at the positions where x or y = j.
 > In practice, I don't want to perform the first operation because
 > test[2,4 is 12 and test[1,3] is 12 as well.
 > 
 > I tried an if statement with little success:
 > 
 > if(test[test[,1] == j,3] != test[test[,2] == j,4]){
 > test[test[,1] == j, 5] = test[test[,1] == j,2] + test[test[,2] == j,1]
 > }
 > Warning message:
 > the condition has length > 1 and only the first element will be used in:
 > if (test[test[, 1] == j, 3] != test[test[, 2] == j, 4]) {
 > 
 > Could anyone lend some advice?
 > 
 > Cheers,
 > 
 > Federico
 > -- 
 > Federico C. F. Calboli
 > Department of Epidemiology and Public Health
 > Imperial College, St Mary's Campus
 > Norfolk Place, London W2 1PG
 > 
 > Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193
 > 
 > f.calboli [.a.t] imperial.ac.uk
 > f.calboli [.a.t] gmail.com
 > 
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From bitwrit at ozemail.com.au  Fri Feb 10 01:29:57 2006
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Thu, 09 Feb 2006 19:29:57 -0500
Subject: [R] writing a file using both cat() and paste()
In-Reply-To: <BAY110-F8061D150F575064B6404DC7030@phx.gbl>
References: <BAY110-F8061D150F575064B6404DC7030@phx.gbl>
Message-ID: <43EBDE85.2000108@ozemail.com.au>

Taka Matzmoto wrote:
> Hi R users
> 
> I like to create a ASCII type file using cat() and paste()
> 
> x <- round(runif(30),3)
> cat("vector =( ", paste(x,sep=""), " )\n", file = "vector.dat",sep=",")
> 
> when I open vector.dat it was a long ugly file
> 
> vector =( 
> ,0.463,0.515,0.202,0.232,0.852,0.367,0.432,0.74,0.413,0.022,0.302,0.114,0.583,0.002,0.919,0.066,0.829,0.405,0.363,0.665,0.109,0.38,0.187,0.322,0.582,0.011,0.586,0.112,0.873,0.671, 
> )
> 
> Also there was some problems right after opening parenthesis and before the 
> closing parenthesis. Two comma were there
> 
> I like to to have a nice formatted one like below. That is, 5 random values 
> per a line
> 
> vector =( 0.463,0.515,0.202,0.232,0.852,
> 0.367,0.432,0.74,0.413,0.022,
> 0.302,0.114,0.583,0.002,0.919,
> 0.066,0.829,0.405,0.363,0.665,
> 0.109,0.38,0.187,0.322,0.582,
> 0.011,0.586,0.112,0.873,0.671)
> 
First, you might want to avoid using "vector", as that is the name of an 
R function. Say you have a 30 element data vector as above. If you 
wanted to write a fairly general function to do this, here is a start:

vector2file<-function(x,file="",values.per.line=5) {
  if(nchar(file)) sink(file)
  cat(deparse(substitute(x)),"<-c(\n")
  xlen<-length(x)
  for(i in 1:xlen) {
   cat(x[i])
   if(i<xlen) cat(",")
   if(i%%values.per.line == 0) cat("\n")
  }
  cat(")")
  if(i%%values.per.line) cat("\n")
  if(nchar(file))sink()
}

Jim



From voodooochild at gmx.de  Thu Feb  9 09:30:58 2006
From: voodooochild at gmx.de (voodooochild@gmx.de)
Date: Thu, 09 Feb 2006 09:30:58 +0100
Subject: [R] Plotting a count process
In-Reply-To: <loom.20060209T090654-531@post.gmane.org>
References: <43EA6A19.7030909@gmx.de> <loom.20060209T090654-531@post.gmane.org>
Message-ID: <43EAFDC2.1090203@gmx.de>

Thank you for your advice, but this is not the exaxt thing i'm looking for
http://robotics.caltech.edu/~zoran/Research/poisson/img1.png
this picture gives an example what i want to get. instead of t0, t1, 
t2,.... i want to draw my dates.
In my description i forgot the the horizontal line, which indicates the 
time between two dates each, sorry for that.

regards
andreas


Dieter Menne wrote:

> <voodooochild <at> gmx.de> writes:
>
>  
>
>>i want to plot a count process in the following way, but i don't know
>>how i can do that. i have data for example x<-(0,2,6,2,8,4,.....) and
>>dates y which is a vector of weekly dates for example
>>(01/01/06, 08/01/06, 15/01/06, 22/01/06, ....), now i want to plot the
>>y's an the horizontal axis. On each date the count process jumps upwards
>>1 unit, so the vertical axis is 0, 1, 2, 3, ......
>>the distance between the dates is shown in vector x, so for example the
>>distance between 08/01/06 and 15/01/06 should be 2. maybe i can use some
>>times series functions for doing this?
>>
>>    
>>
>
>If I understand you correctly, this means plotting equidistant point against 
>the cumulative sum. Forgetting about the dates now, this would do it.
>
>x = floor(pmax(rnorm(30,5,2),1))
>xcum = cumsum(x)
>plot(xcum,1:30)
>
>Dieter
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From u9370004 at cc.kmu.edu.tw  Thu Feb  9 09:30:52 2006
From: u9370004 at cc.kmu.edu.tw (Chun-Ying Lee)
Date: Thu, 9 Feb 2006 16:30:52 +0800
Subject: [R] echo output to screen
Message-ID: <20060209081819.M1112@cc.kmu.edu.tw>

Hi all,
 
  I want to echo output to screen before next step, 
like the following when i type library(pkname),

>library(pkname)

a few description about the package
........

>
>
>

how should I do to get this?
Thanks in advanced!!



From wl at eimb.ru  Thu Feb  9 09:51:11 2006
From: wl at eimb.ru (Wladimir Eremeev)
Date: Thu, 9 Feb 2006 11:51:11 +0300
Subject: [R] [R-sig-Geo] envi clone in R
In-Reply-To: <43EA33CF.3080605@lancaster.ac.uk>
References: <172918418.20060208192308@eimb.ru>
	<43EA33CF.3080605@lancaster.ac.uk>
Message-ID: <1574214371.20060209115111@eimb.ru>

Dear Barry,

By the way...
BR>   I settled on OpenEV - it has vector and raster support, its extensible
BR> in Python and uses Gtk for dialogs which you can customise.

I have seen OpenEV.
Unfortunately, I could not find a documentation or user guide for
quick start and had not too much time to realize what is what and
how to use its features with 'mouse point-and-click' :)

Do you have a link to such a document?

---
Best regards,
Wladimir                mailto:wl at eimb.ru



From ripley at stats.ox.ac.uk  Thu Feb  9 10:00:18 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Feb 2006 09:00:18 +0000 (GMT)
Subject: [R] (user) ERROR: no applicable method for "TukeyHSD"
In-Reply-To: <d2095b8c0602081225i2c505ad8ud49f23394592e3d2@mail.gmail.com>
References: <d2095b8c0602081225i2c505ad8ud49f23394592e3d2@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602082302320.29455@gannet.stats.ox.ac.uk>

On Wed, 8 Feb 2006, Darren Weber wrote:

> Why do I see this error?

Because there _is_ no applicable method.

Please don't name objects after R functions, but in your case you need to
do

class(aov)
?TukeyHSD
?aov

and see what TukeyHSD says it handles and what aov says it returns.

This question has been answered at length on this list quite recently, so 
please also search the archives.


>> library(stats)
>> require(stats)
> [1] TRUE
>>
>> tHSD <- TukeyHSD(aov)
> Error in TukeyHSD(aov) : no applicable method for "TukeyHSD"
>
>
> In case it helps:
>
>
>> aov
>
> Call:
> aov(formula = roi ~ (Cue * Hemisphere) + Error(Subject/(Cue *
>    Hemisphere)), data = roiDataframe)
>
> Grand Mean: 8.195069
>
> Stratum 1: Subject
>
> Terms:
>                Residuals
> Sum of Squares   645.7444
> Deg. of Freedom         7
>
> Residual standard error: 9.604645
>
> Stratum 2: Subject:Cue
>
> Terms:
>                     Cue Residuals
> Sum of Squares  0.386987  4.015740
> Deg. of Freedom        1         7
>
> Residual standard error: 0.7574148
> 1 out of 2 effects not estimable
> Estimated effects are balanced
>
> Stratum 3: Subject:Hemisphere
>
> Terms:
>                Hemisphere Residuals
> Sum of Squares    153.4860  827.6699
> Deg. of Freedom          1         7
>
> Residual standard error: 10.87376
> 1 out of 2 effects not estimable
> Estimated effects are balanced
>
> Stratum 4: Subject:Cue:Hemisphere
>
> Terms:
>                Cue:Hemisphere Residuals
> Sum of Squares        5.085930  4.279707
> Deg. of Freedom              1         7
>
> Residual standard error: 0.7819122
> Estimated effects are balanced
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Thu Feb  9 10:02:49 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 09 Feb 2006 10:02:49 +0100
Subject: [R] echo output to screen
In-Reply-To: <20060209081819.M1112@cc.kmu.edu.tw>
References: <20060209081819.M1112@cc.kmu.edu.tw>
Message-ID: <43EB0539.8040901@statistik.uni-dortmund.de>

Chun-Ying Lee wrote:
> Hi all,
>  
>   I want to echo output to screen before next step, 
> like the following when i type library(pkname),
> 
> 
>>library(pkname)
> 
> 
> a few description about the package
> ........
> 
> 
>>
>>
> 
> how should I do to get this?

?cat

Uwe Ligges

> Thanks in advanced!!
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From u9370004 at cc.kmu.edu.tw  Thu Feb  9 10:09:53 2006
From: u9370004 at cc.kmu.edu.tw (Chun-Ying Lee)
Date: Thu, 9 Feb 2006 17:09:53 +0800
Subject: [R]  echo output to screen
In-Reply-To: <43EB0539.8040901@statistik.uni-dortmund.de>
References: <20060209081819.M1112@cc.kmu.edu.tw>
	<43EB0539.8040901@statistik.uni-dortmund.de>
Message-ID: <20060209090641.M37811@cc.kmu.edu.tw>

On Thu, 09 Feb 2006 10:02:49 +0100, Uwe Ligges wrote
> Chun-Ying Lee wrote:
> > Hi all,
> >  
> >   I want to echo output to screen before next step, 
> > like the following when i type library(pkname),
> > 
> > 
> >>library(pkname)
> > 
> > 
> > a few description about the package
> > ........
> > 
> > 
> >>
> >>
> > 
> > how should I do to get this?
> 
> ?cat

I know the use of "cat"

but I mean that the description appear automatically
when I type library(pkname)

> 
> Uwe Ligges
> 
> > Thanks in advanced!!
> > 
> >



From ligges at statistik.uni-dortmund.de  Thu Feb  9 10:18:52 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 09 Feb 2006 10:18:52 +0100
Subject: [R] echo output to screen
In-Reply-To: <20060209090641.M37811@cc.kmu.edu.tw>
References: <20060209081819.M1112@cc.kmu.edu.tw>	<43EB0539.8040901@statistik.uni-dortmund.de>
	<20060209090641.M37811@cc.kmu.edu.tw>
Message-ID: <43EB08FC.3060200@statistik.uni-dortmund.de>

Chun-Ying Lee wrote:

> On Thu, 09 Feb 2006 10:02:49 +0100, Uwe Ligges wrote
> 
>>Chun-Ying Lee wrote:
>>
>>>Hi all,
>>> 
>>>  I want to echo output to screen before next step, 
>>>like the following when i type library(pkname),
>>>
>>>
>>>
>>>>library(pkname)
>>>
>>>
>>>a few description about the package
>>>........
>>>
>>>
>>>
>>>>
>>>how should I do to get this?
>>
>>?cat
> 
> 
> I know the use of "cat"
> 
> but I mean that the description appear automatically
> when I type library(pkname)

See ?.onAttach (or ?.First.lib if you do not use a NAMESPACE).

Uwe Ligges


> 
>>Uwe Ligges
>>
>>
>>>Thanks in advanced!!
>>>
>>>
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From francoisromain at free.fr  Thu Feb  9 10:19:30 2006
From: francoisromain at free.fr (Romain Francois)
Date: Thu, 09 Feb 2006 10:19:30 +0100
Subject: [R] echo output to screen
In-Reply-To: <20060209090641.M37811@cc.kmu.edu.tw>
References: <20060209081819.M1112@cc.kmu.edu.tw>	<43EB0539.8040901@statistik.uni-dortmund.de>
	<20060209090641.M37811@cc.kmu.edu.tw>
Message-ID: <43EB0922.2030707@free.fr>

Le 09.02.2006 10:09, Chun-Ying Lee a crit :

>On Thu, 09 Feb 2006 10:02:49 +0100, Uwe Ligges wrote
>  
>
>>Chun-Ying Lee wrote:
>>    
>>
>>>Hi all,
>>> 
>>>  I want to echo output to screen before next step, 
>>>like the following when i type library(pkname),
>>>
>>>
>>>      
>>>
>>>>library(pkname)
>>>>        
>>>>
>>>a few description about the package
>>>........
>>>
>>>
>>>      
>>>
>>>>        
>>>>
>>>how should I do to get this?
>>>      
>>>
>>?cat
>>    
>>
>
>I know the use of "cat"
>
>but I mean that the description appear automatically
>when I type library(pkname)
>  
>
Hi,

Your question was not too clear about that.
See Writing R extensions.
?.First.lib if you don't have a NAMESPACE
?.onLoad if you do

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From rfluss at netvision.net.il  Thu Feb  9 10:39:16 2006
From: rfluss at netvision.net.il (fluss)
Date: Thu, 09 Feb 2006 11:39:16 +0200
Subject: [R] write.table
Message-ID: <004301c62d5c$b21d3ea0$7ecc1dac@barry>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060209/92901911/attachment.pl

From sundar.dorai-raj at pdf.com  Thu Feb  9 10:48:54 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 09 Feb 2006 03:48:54 -0600
Subject: [R] write.table
In-Reply-To: <004301c62d5c$b21d3ea0$7ecc1dac@barry>
References: <004301c62d5c$b21d3ea0$7ecc1dac@barry>
Message-ID: <43EB1006.90201@pdf.com>

See the "scipen" argument in ?options.

write.table(data.frame(x = 0.0005))
options(scipen = 1)
write.table(data.frame(x = 0.0005))

--sundar

fluss wrote:
> Hello!
> When using the command "write.table" I want to convert the format: 5e-04
> to  .0005. How can I do it?
> The only option I found is to use write.matrix but then I cant add rownames.
> Thank you
> Ronen
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Thu Feb  9 10:50:25 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Feb 2006 09:50:25 +0000 (GMT)
Subject: [R] write.table
In-Reply-To: <004301c62d5c$b21d3ea0$7ecc1dac@barry>
References: <004301c62d5c$b21d3ea0$7ecc1dac@barry>
Message-ID: <Pine.LNX.4.64.0602090949010.4384@gannet.stats.ox.ac.uk>

> Hello!
> When using the command "write.table" I want to convert the format: 5e-04
> to  .0005. How can I do it?
> The only option I found is to use write.matrix but then I cant add rownames.
> Thank you
> Ronen

?options, see scipen.

Or, use format() to convert table before writing it.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From petr.pikal at precheza.cz  Thu Feb  9 11:23:17 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 09 Feb 2006 11:23:17 +0100
Subject: [R] adding variable into dataframe by indice
In-Reply-To: <20060208174043.49245.qmail@web313.biz.mail.mud.yahoo.com>
Message-ID: <43EB2625.8046.653D5B@localhost>

Hi

not sure if I understand correctly but table() can be used

ttt <- table(asubs112$fir)
prop <- ttt/nrow(asubs112)
asubs112$prop <-
prop[match(asubs112$first_drink,as.numeric(names(prop)))]

> asubs112
   IND_ID rs1042364 first_drink      prop
2      11     (1,2)           7 0.3333333
5      41     (1,2)          11 0.1111111
6      51     (1,2)           7 0.3333333
7      61     (1,1)           7 0.3333333
8      71     (1,1)          12 0.2222222
10     91     (1,1)           6 0.1111111
11    101     (1,2)           5 0.1111111
12    111     (1,2)          13 0.1111111
14    131     (1,2)          12 0.2222222
> 

HTH
Petr


On 8 Feb 2006 at 9:40, Adrian Katschke wrote:

Date sent:      	Wed, 8 Feb 2006 09:40:43 -0800 (PST)
From:           	Adrian Katschke <adrian at atstatconsulting.com>
To:             	RHelp <r-help at stat.math.ethz.ch>
Subject:        	[R] adding variable into dataframe by indice

>   R-Helpers,
> 
>   I am trying to insert a value into a dataframe. This value is a
>   proportion calculated by counting the number of those individuals
>   with that value and then inserting the proportion at the end of the
>   dataframe to only those individuals with the given value. The
>   problem I am running into is that the proportions are not being
>   attached to only those individuals with the specified value for that
>   proportion. 
> 
>   Below is an example of the code that I am using. The data is made up
>   for the dataframe. Should give you an idea, but the original has
>   'NA' in many rows. The original data is what is reported in the
>   output below.
> 
>     #Read in Data
>   age.int <- data.frame(IND_ID = seq(1, 140, 10),   rs1042364 =
>   sample( c("(1,1)","(1,2)","(2,2)"),14,replace = T), first_drink =
>   sample(5:17,14,replace = T))
> 
> 
> 
>     asubs112 <- subset(age.int, rs1042364 != "(2,2)")
> 
> 
>     ages112 <- sort(unique(na.omit(asubs112$first_drink)))
> 
>   for ( i in ages112) {
>     indce <- which(na.omit(asubs112$first_drink == i))
>     prop <- length(indce)/nrow(asubs112)
>     asubs112[indce,4] <- prop
>     asubs112[indce,]
>   }
> 
>   Below is the output that I get from the script above. Notice the
>   proportion for the first NA but not any of the others. Not sure what
>   I am doing wrong, any suggestions are a big help.
> 
>   TIA,
>   Adrian
> 
>    asubs112[1:50,]
>       IND_ID rs1042364 first_drink age_int          V5
> 4   10008007     (1,2)          NA      16 0.003891051
> 6   10013012     (1,2)          13      14 0.116731518
> 7   10015006     (1,2)          12      17 0.105058366
> 8   10015007     (1,1)          12      16 0.105058366
> 10  10021009     (1,2)          NA      15          NA
> 14  10039036     (1,2)          NA      15          NA
> 15  10039037     (1,2)          NA      13          NA
> 17  10045005     (1,2)          13      17 0.116731518
> 18  10045014     (1,2)          13      14 0.116731518
> 21  10055022     (1,2)          NA      15          NA
> 
> 
> 
> 
> 
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From f.calboli at imperial.ac.uk  Thu Feb  9 11:20:46 2006
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Thu, 09 Feb 2006 10:20:46 +0000
Subject: [R] logical condition in vector operation
In-Reply-To: <17386.64454.662868.47685@stat.math.ethz.ch>
References: <1139422357.22690.12.camel@localhost.localdomain>
	<17386.64454.662868.47685@stat.math.ethz.ch>
Message-ID: <1139480446.22708.14.camel@localhost.localdomain>

On Thu, 2006-02-09 at 09:22 +0100, Christoph Buser wrote:
> Dear Frederico
> 
> From your example it is not clear to me what you like to obtain: 
> Please have a look on the slightly changed example here (I
> changed two values to show a potentially undesired side effect of
> your coding.
> 
> 
> test <- data.frame(rbind(c(3,3,10,21,0), c(2,3,11,12,0), c(3,4,12,23,0),
>                          c(3,5,13,24,0)))
> names(test) <- c("x","y","p","d","su")
> test
> 
> >>   x y  p  d su
> >> 1 3 3 10 21  0
> >> 2 2 3 11 12  0
> >> 3 3 4 12 23  0
> >> 4 3 5 13 24  0
> 
> j <- 3
> test[test[,1] == j, 5] <- test[test[,1] == j,2] + test[test[,2] == j,1]
> 
> >> > > Warning message:
> >> longer object length
> >> 	is not a multiple of shorter object length in: 
> >>         test[test[, 1] == j, 2] + test[test[, 2] == j, 1] 
> 
> Your code example produces now a warning for the adapted
> data frame "test", since one tries to add two vectors of length 2
> and 3, respectively. The result is based on recycling of the
> smaller vector. In your example there was no warning since the
> second column had only one entry.
> The result with the adapted data frame is:
> 
> test
> >>   x y  p  d su
> >> 1 3 3 10 21  6
> >> 2 2 3 11 12  0
> >> 3 3 4 12 23  6
> >> 4 3 5 13 24  8
> 
> Is that kind of recycling desired in your application. Otherwise
> you should be careful with the coding example above.

Recycling was and is integral part of my plan.

Cheers,

Federico

-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From petr.pikal at precheza.cz  Thu Feb  9 11:27:20 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 09 Feb 2006 11:27:20 +0100
Subject: [R] logical condition in vector operation
In-Reply-To: <1139422357.22690.12.camel@localhost.localdomain>
Message-ID: <43EB2718.4729.68F255@localhost>

Hi

try
ifelse()

but I you probably shall put your problem clearer.

HTH
Petr


On 8 Feb 2006 at 18:12, Federico Calboli wrote:

From:           	Federico Calboli <f.calboli at imperial.ac.uk>
To:             	r-help <r-help at stat.math.ethz.ch>
Organization:   	Imperial College London
Date sent:      	Wed, 08 Feb 2006 18:12:37 +0000
Subject:        	[R] logical condition in vector operation
Send reply to:  	f.calboli at imperial.ac.uk
	<mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
	<mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>

> HI All,
> 
> I have a data frame such as:
> 
> > test
>      x y  p  d
> [1,] 1 0 10 21 0
> [2,] 2 3 11 12 0
> [3,] 3 4 12 23 0
> [4,] 3 5 13 24 0
> 
> 
> and I want to perfor some operations on the first two coulums,
> conditional on the uneqaulity values on the 3rd and 4th columns.
> 
> For instance:
> 
> j = 3
> test[test[,1] == j, 5] = test[test[,1] == j,2] + test[test[,2] == j,1]
> 
> gives me the result:
> 
> test:
> 
>      x y  p  d
> [1,] 1 0 10 21 0
> [2,] 2 3 11 12 0
> [3,] 3 4 12 23 6
> [4,] 3 5 13 24 7
> 
> 
> My probblem is the following: I want to perform the operation
> test[test[,1] == j,2] + test[test[,2] == j,1] only if the value of
> column p and column d are different at the positions where x or y = j.
> In practice, I don't want to perform the first operation because
> test[2,4 is 12 and test[1,3] is 12 as well.
> 
> I tried an if statement with little success:
> 
> if(test[test[,1] == j,3] != test[test[,2] == j,4]){
> test[test[,1] == j, 5] = test[test[,1] == j,2] + test[test[,2] == j,1]
> } Warning message: the condition has length > 1 and only the first
> element will be used in: if (test[test[, 1] == j, 3] != test[test[, 2]
> == j, 4]) {
> 
> Could anyone lend some advice?
> 
> Cheers,
> 
> Federico
> -- 
> Federico C. F. Calboli
> Department of Epidemiology and Public Health
> Imperial College, St Mary's Campus
> Norfolk Place, London W2 1PG
> 
> Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193
> 
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From voodooochild at gmx.de  Thu Feb  9 12:08:37 2006
From: voodooochild at gmx.de (voodooochild@gmx.de)
Date: Thu, 09 Feb 2006 12:08:37 +0100
Subject: [R] Plotting a count process
In-Reply-To: <43EAFDC2.1090203@gmx.de>
References: <43EA6A19.7030909@gmx.de> <loom.20060209T090654-531@post.gmane.org>
	<43EAFDC2.1090203@gmx.de>
Message-ID: <43EB22B5.1000204@gmx.de>

Now my problem is solved, i thinked a while about it and rearanged my 
plot in the following way for everybody how is interested

x<-0:3
y<-c(0,5,8,3)
dates<-c("","01.01.05","08.01.05","15.01.05")
plot(x,cumsum(y),type="p",axes=FALSE,xlab="Date",ylab="Failure 
Number",pch=20)

axis(side = 1,0:3 ,labels = dates)
axis(side = 2)
box()

i<-seq(along=x)
segments(x[i],cumsum(y)[i],x[i+1],cumsum(y)[i])
segments(x[length(x)],cumsum(y)[length(y)],x[length(x)]+1,cumsum(y)[length(y)])


regards
andreas


voodooochild at gmx.de wrote:

>Thank you for your advice, but this is not the exaxt thing i'm looking for
>http://robotics.caltech.edu/~zoran/Research/poisson/img1.png
>this picture gives an example what i want to get. instead of t0, t1, 
>t2,.... i want to draw my dates.
>In my description i forgot the the horizontal line, which indicates the 
>time between two dates each, sorry for that.
>
>regards
>andreas
>
>
>Dieter Menne wrote:
>
>  
>
>><voodooochild <at> gmx.de> writes:
>>
>> 
>>
>>    
>>
>>>i want to plot a count process in the following way, but i don't know
>>>how i can do that. i have data for example x<-(0,2,6,2,8,4,.....) and
>>>dates y which is a vector of weekly dates for example
>>>(01/01/06, 08/01/06, 15/01/06, 22/01/06, ....), now i want to plot the
>>>y's an the horizontal axis. On each date the count process jumps upwards
>>>1 unit, so the vertical axis is 0, 1, 2, 3, ......
>>>the distance between the dates is shown in vector x, so for example the
>>>distance between 08/01/06 and 15/01/06 should be 2. maybe i can use some
>>>times series functions for doing this?
>>>
>>>   
>>>
>>>      
>>>
>>If I understand you correctly, this means plotting equidistant point against 
>>the cumulative sum. Forgetting about the dates now, this would do it.
>>
>>x = floor(pmax(rnorm(30,5,2),1))
>>xcum = cumsum(x)
>>plot(xcum,1:30)
>>
>>Dieter
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>
>> 
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>  
>



From andy_liaw at merck.com  Thu Feb  9 12:13:11 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 9 Feb 2006 06:13:11 -0500
Subject: [R] echo output to screen
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED7E2@usctmx1106.merck.com>

Is something like this what you want?

> load_and_describe <- function(pkg) {
+     eval(substitute(library(pkg)))
+     packageDescription(pkg)
+ }
> load_and_describe("e1071")
Package: e1071
Version: 1.5-12
Date: 2006-01-11
Title: Misc Functions of the Department of Statistics (e1071), TU Wien
Depends: class
Imports: graphics, stats
Suggests: cluster, mlbench, nnet, randomForest, rpart, SparseM, xtable
Author: Evgenia Dimitriadou, Kurt Hornik, Friedrich Leisch, David
        Meyer, and Andreas Weingessel
Maintainer: Friedrich Leisch <Friedrich.Leisch at ci.tuwien.ac.at>
Description: Functions for latent class analysis, short time Fourier
        transform, fuzzy clustering, support vector machines, shortest
        path computation, bagged clustering, naive Bayes classifier,
        ...
License: GPL version 2.  See COPYRIGHT.svm.cpp for the copyright of the
        svm C++ code.
SaveImage: no
LazyLoad: yes
Packaged: Wed Jan 11 17:37:06 2006; leisch
Built: R 2.2.1; i386-pc-mingw32; 2006-01-12 09:52:56; windows


Andy


From: Chun-Ying Lee
> 
> On Thu, 09 Feb 2006 10:02:49 +0100, Uwe Ligges wrote
> > Chun-Ying Lee wrote:
> > > Hi all,
> > >  
> > >   I want to echo output to screen before next step, 
> > > like the following when i type library(pkname),
> > > 
> > > 
> > >>library(pkname)
> > > 
> > > 
> > > a few description about the package
> > > ........
> > > 
> > > 
> > >>
> > >>
> > > 
> > > how should I do to get this?
> > 
> > ?cat
> 
> I know the use of "cat"
> 
> but I mean that the description appear automatically
> when I type library(pkname)
> 
> > 
> > Uwe Ligges
> > 
> > > Thanks in advanced!!
> > > 
> > >
> 
>



From kate at few.vu.nl  Thu Feb  9 12:53:30 2006
From: kate at few.vu.nl (Katharine Mullen)
Date: Thu, 9 Feb 2006 12:53:30 +0100 (CET)
Subject: [R] Using R to process spectroscopic data
Message-ID: <Pine.GSO.4.56.0602091246440.8932@laurel.few.vu.nl>

In the biophysics group of Vrije Universiteit Amsterdam we are working on
an R package implementing a problem solving environment for multi-way
spectroscopic modeling.  We do not have a public version yet, but one will
be made available in the future.  We plan to describe the package at
useR2006.

If you are interested in the sort of (parametric model-based) analysis we
are doing, you can see some project documentation at
http://www.nat.vu.nl/comp/proj4.html.

To reply to one of your questions, for determination of the optimal number
of spectrally distinct components, you could simply take the SVD of your
measurements and plot the singular values.  The number of values that
"stand out" may be used as an estimate of the number of components.

Feel free to contact me for more information.  We look forward to
providing a complete and powerful package soon!

----
Katharine Mullen
Department of Physics and Astronomy
Faculty of Sciences
Vrije Universiteit Amsterdam
de Boelelaan 1081
1081 HV Amsterdam
The Netherlands
room: T.1.06
tel: +31 205987870
fax: +31 205987992
e-mail: kate at nat.vu.nl
http://www.nat.vu.nl/~kate/



From stefano.sofia at regione.marche.it  Thu Feb  9 12:51:02 2006
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Thu, 09 Feb 2006 11:51:02 +0000
Subject: [R] about Cox-Box transformation
Message-ID: <1139485862.13270.8.camel@aion.regionemarche.intra>

Dear R-users,
I am using R version 1.8.0-1 under Suse 8.2. 
I need to use the boxcox command because I want to apply a Cox-Box
transformation to a vector of rainfall values. 
Within the libraries, the MASS library is present, but I don't know
whether this means that is automatically installed or not.
The command doesn't work. What do I have to do in order to make it
working? Is just a problem of installation or simply of recalling the
right command?

thank you for your help
Stefano



From ripley at stats.ox.ac.uk  Thu Feb  9 13:17:07 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Feb 2006 12:17:07 +0000 (GMT)
Subject: [R] about Cox-Box transformation
In-Reply-To: <1139485862.13270.8.camel@aion.regionemarche.intra>
References: <1139485862.13270.8.camel@aion.regionemarche.intra>
Message-ID: <Pine.LNX.4.64.0602091215510.27201@gannet.stats.ox.ac.uk>

On Thu, 9 Feb 2006, Stefano Sofia wrote:

> Dear R-users,
> I am using R version 1.8.0-1 under Suse 8.2.

That is *really* old.

> I need to use the boxcox command because I want to apply a Cox-Box
> transformation to a vector of rainfall values.
> Within the libraries, the MASS library is present, but I don't know
> whether this means that is automatically installed or not.
> The command doesn't work. What do I have to do in order to make it
> working? Is just a problem of installation or simply of recalling the
> right command?

library(MASS), I presume.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From petr.pikal at precheza.cz  Thu Feb  9 13:18:05 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 09 Feb 2006 13:18:05 +0100
Subject: [R] about Cox-Box transformation
In-Reply-To: <1139485862.13270.8.camel@aion.regionemarche.intra>
Message-ID: <43EB410D.6685.CE640F@localhost>

Hi

1. 	upgrade
2.	read Introduction to R shipped with the distribution
3.	read documentation to MASS
4.	packages not libraries
5.	use library(MASS) to make functions from MASS package available
6. 	now you can use boxcox() but not on vectors AFAIK

probably not completely correct but this

box.cox <- function(x, lambda,inv=F)
{	if (!inv)
		{if(missing(lambda))
			log(x)
		else (x^lambda - 1)/lambda}
	else (lambda*x+1)^(1/lambda)
}

you can use to perform Box-Cox transformation on vectors.

HTH
Petr


On 9 Feb 2006 at 11:51, Stefano Sofia wrote:

From:           	Stefano Sofia <stefano.sofia at regione.marche.it>
To:             	r-help at stat.math.ethz.ch
Date sent:      	Thu, 09 Feb 2006 11:51:02 +0000
Subject:        	[R] about Cox-Box transformation

> Dear R-users,
> I am using R version 1.8.0-1 under Suse 8.2. 
> I need to use the boxcox command because I want to apply a Cox-Box
> transformation to a vector of rainfall values. Within the libraries,
> the MASS library is present, but I don't know whether this means that
> is automatically installed or not. The command doesn't work. What do I
> have to do in order to make it working? Is just a problem of
> installation or simply of recalling the right command?
> 
> thank you for your help
> Stefano
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From ramasamy at cancer.org.uk  Thu Feb  9 13:45:16 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 09 Feb 2006 12:45:16 +0000
Subject: [R] writing a file using both cat() and paste()
In-Reply-To: <43EBDE85.2000108@ozemail.com.au>
References: <BAY110-F8061D150F575064B6404DC7030@phx.gbl>
	<43EBDE85.2000108@ozemail.com.au>
Message-ID: <1139489116.3229.35.camel@dhcp-82.wolf.ox.ac.uk>

With regards to the saving bit, you might want to try dput() or save()
as well.

On Thu, 2006-02-09 at 19:29 -0500, Jim Lemon wrote:
> Taka Matzmoto wrote:
> > Hi R users
> > 
> > I like to create a ASCII type file using cat() and paste()
> > 
> > x <- round(runif(30),3)
> > cat("vector =( ", paste(x,sep=""), " )\n", file = "vector.dat",sep=",")
> > 
> > when I open vector.dat it was a long ugly file
> > 
> > vector =( 
> > ,0.463,0.515,0.202,0.232,0.852,0.367,0.432,0.74,0.413,0.022,0.302,0.114,0.583,0.002,0.919,0.066,0.829,0.405,0.363,0.665,0.109,0.38,0.187,0.322,0.582,0.011,0.586,0.112,0.873,0.671, 
> > )
> > 
> > Also there was some problems right after opening parenthesis and before the 
> > closing parenthesis. Two comma were there
> > 
> > I like to to have a nice formatted one like below. That is, 5 random values 
> > per a line
> > 
> > vector =( 0.463,0.515,0.202,0.232,0.852,
> > 0.367,0.432,0.74,0.413,0.022,
> > 0.302,0.114,0.583,0.002,0.919,
> > 0.066,0.829,0.405,0.363,0.665,
> > 0.109,0.38,0.187,0.322,0.582,
> > 0.011,0.586,0.112,0.873,0.671)
> > 
> First, you might want to avoid using "vector", as that is the name of an 
> R function. Say you have a 30 element data vector as above. If you 
> wanted to write a fairly general function to do this, here is a start:
> 
> vector2file<-function(x,file="",values.per.line=5) {
>   if(nchar(file)) sink(file)
>   cat(deparse(substitute(x)),"<-c(\n")
>   xlen<-length(x)
>   for(i in 1:xlen) {
>    cat(x[i])
>    if(i<xlen) cat(",")
>    if(i%%values.per.line == 0) cat("\n")
>   }
>   cat(")")
>   if(i%%values.per.line) cat("\n")
>   if(nchar(file))sink()
> }
> 
> Jim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From nhy303 at abdn.ac.uk  Thu Feb  9 13:56:17 2006
From: nhy303 at abdn.ac.uk (nhy303@abdn.ac.uk)
Date: Thu, 9 Feb 2006 12:56:17 -0000 (GMT)
Subject: [R] logLik == -Inf in gls
Message-ID: <1415.139.133.94.35.1139489777.squirrel@www.abdn.ac.uk>

I am trying to fit a generalised least squares model using gls in the nlme
package.

The model seems to fit very well when I plot the fitted values against the
original values, and the model parameters have quite narrow confidence
intervals (all are significant at p<5%).

The problem is that the log likelihood is always given as -Inf.  This
doesn't seem to make sense because the model seems to fit my data so well.
 I have checked that the residuals are stationary using an adf test.  I
can't work out whether
  - the model really doesn't fit at all
  - there is something in my data that stops the implementation of logLik
working correctly (the -Inf value says the calculation hasn't worked)

Possible causes are:
  - There are lots of NAs in my data (model and response variables)
  - There is some autocorrelation in the data that is not accounted for by
the model (most is accounted for).

But, I've tried recreating the problem using a simpler data set, and have
never found the same problem.

The command I use to fit the model is...



result2 <- gls(lci4150 ~ propCapInStomachs +
                        temperature +
                        as.factor(monthNumber) +
                        lagLci1 +
                        lagcap1 +
                        lagcap2,
              data = monthly,
              subset = subset1985,
              na.action = na.approx,
              weights = varFixed( ~ 1/numob4150)
             )



The output I get is...



Generalized least squares fit by REML
  Model: lci4150 ~ propCapInStomachs + temperature +
as.factor(monthNumber) +      lagLci1 + lagcap1 + lagcap2
  Data: monthly
  Subset: subset1985
  AIC BIC logLik
  Inf Inf   -Inf

Variance function:
 Structure: fixed weights
 Formula: ~1/numob4150

Coefficients:
                              Value Std.Error   t-value p-value
(Intercept)              -0.3282412 0.5795665 -0.566356  0.5717
propCapInStomachs         0.0093283 0.0039863  2.340107  0.0202
temperature               0.4342514 0.1526104  2.845490  0.0048
as.factor(monthNumber)2   0.3990717 0.3869991  1.031195  0.3036
as.factor(monthNumber)3   1.3788334 0.3675690  3.751223  0.0002
as.factor(monthNumber)4   1.4037195 0.3857764  3.638686  0.0003
as.factor(monthNumber)5   0.9903316 0.3436177  2.882074  0.0043
as.factor(monthNumber)6   0.3453741 0.3043698  1.134719  0.2577
as.factor(monthNumber)7   0.3948442 0.3035142  1.300909  0.1946
as.factor(monthNumber)8   0.5021812 0.3532413  1.421638  0.1565
as.factor(monthNumber)9  -0.0794319 0.3598981 -0.220707  0.8255
as.factor(monthNumber)10  0.3536805 0.3790538  0.933061  0.3518
as.factor(monthNumber)11  0.7874834 0.3557116  2.213826  0.0278
as.factor(monthNumber)12  0.1854279 0.3178320  0.583415  0.5602
lagLci1                   0.5488437 0.0576144  9.526151  0.0000
lagcap1                   0.0110994 0.0043669  2.541714  0.0117
lagcap2                  -0.0088080 0.0041099 -2.143127  0.0332



Does anyone have any suggestions of how I can get a meaningful value for
logLik?  Or some other way that I can compare models.

Thankyou,

Lillian.
-- 
Lillian Sandeman
PhD Student
School of Biological Sciences
University of Aberdeen
AB24 2TZ

Tel.: 01224 272648
E-mail: l.sandeman at abdn.ac.uk



From ripley at stats.ox.ac.uk  Thu Feb  9 13:59:15 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Feb 2006 12:59:15 +0000 (GMT)
Subject: [R] about Cox-Box transformation
In-Reply-To: <43EB410D.6685.CE640F@localhost>
References: <43EB410D.6685.CE640F@localhost>
Message-ID: <Pine.LNX.4.64.0602091254070.27334@gannet.stats.ox.ac.uk>

On Thu, 9 Feb 2006, Petr Pikal wrote:

> Hi
>
> 1. 	upgrade
> 2.	read Introduction to R shipped with the distribution
> 3.	read documentation to MASS
> 4.	packages not libraries
> 5.	use library(MASS) to make functions from MASS package available
> 6. 	now you can use boxcox() but not on vectors AFAIK

You can by

boxcox(y ~ 1)

but car's box.cox does similar things.  (I did not mention that as adding 
packages to R 1.8.0 is unlikely to be easy.)

> probably not completely correct but this
>
> box.cox <- function(x, lambda,inv=F)
> {	if (!inv)
> 		{if(missing(lambda))
> 			log(x)
> 		else (x^lambda - 1)/lambda}
> 	else (lambda*x+1)^(1/lambda)
> }
>
> you can use to perform Box-Cox transformation on vectors.
>
> HTH
> Petr
>
>
> On 9 Feb 2006 at 11:51, Stefano Sofia wrote:
>
> From:           	Stefano Sofia <stefano.sofia at regione.marche.it>
> To:             	r-help at stat.math.ethz.ch
> Date sent:      	Thu, 09 Feb 2006 11:51:02 +0000
> Subject:        	[R] about Cox-Box transformation
>
>> Dear R-users,
>> I am using R version 1.8.0-1 under Suse 8.2.
>> I need to use the boxcox command because I want to apply a Cox-Box
>> transformation to a vector of rainfall values. Within the libraries,
>> the MASS library is present, but I don't know whether this means that
>> is automatically installed or not. The command doesn't work. What do I
>> have to do in order to make it working? Is just a problem of
>> installation or simply of recalling the right command?
>>
>> thank you for your help
>> Stefano

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From reilly at stat.auckland.ac.nz  Thu Feb  9 14:17:13 2006
From: reilly at stat.auckland.ac.nz (James Reilly)
Date: Fri, 10 Feb 2006 02:17:13 +1300
Subject: [R] getting strata/cluster level values with survey package?
In-Reply-To: <3065.128.193.140.221.1139354595.squirrel@www.forestinformatics.com>
References: <3065.128.193.140.221.1139354595.squirrel@www.forestinformatics.com>
Message-ID: <43EB40D9.2010600@stat.auckland.ac.nz>


Try the examples here:
?ftable.svystat

On 8/02/2006 12:23 p.m., Jeff D. Hamann wrote:
> First, I appoligise for the rooky question, but...
> 
> I'm trying to obtain standard errors, confidence intervals, etc. from a
> sample design and have been trouble getting the results for anything other
> than the basic total or mean for the overall survey from the survey
> package.
> 
> For example, using the following dataset,
> 
> strata,cluster,vol
> A,1,18.58556192
> A,1,12.55175443
> A,1,21.65882438
> A,1,17.11172946
> A,1,15.41713348
> A,2,13.9344623
> A,2,17.13104821
> A,2,14.6806479
> A,2,14.68357291
> A,2,18.86017714
> A,2,20.67642515
> A,2,15.15295351
> A,2,13.82121102
> A,2,12.9110477
> A,2,14.83153677
> A,2,21.90772687
> A,3,18.69795427
> A,3,18.45636428
> A,3,15.77175793
> A,3,15.54715217
> A,3,20.31948393
> A,3,19.26391445
> A,3,15.54750775
> A,3,19.18724018
> A,4,12.89572151
> A,4,12.92047701
> A,4,12.64958757
> A,4,19.85888418
> A,4,19.64057669
> A,4,19.19188964
> A,4,18.81619298
> A,4,21.73670878
> A,5,15.99430802
> A,5,18.66666517
> A,5,21.80441654
> A,5,14.22081904
> A,5,16.01576433
> A,5,14.92497202
> A,5,17.95123218
> A,5,19.82027165
> A,5,19.35698273
> A,5,19.10826519
> B,6,13.40892677
> B,6,14.3956207
> B,6,13.82113391
> B,6,16.37338569
> B,6,19.70159575
> B,7,14.74334178
> B,7,16.55125245
> B,7,12.38329798
> B,7,18.16472408
> B,7,16.32938475
> B,7,16.06465494
> B,7,12.63086062
> B,7,14.46114813
> B,7,21.90134013
> B,7,13.81025827
> B,7,15.85805494
> B,7,20.18195326
> B,8,19.05120792
> B,8,12.83856639
> B,8,12.61360139
> B,8,21.30434314
> B,8,14.19960469
> B,8,17.38397826
> B,8,15.66477339
> B,8,22.07182834
> B,8,12.07487394
> B,8,20.36357359
> B,8,20.2543677
> B,9,14.44499362
> B,9,17.77235228
> B,9,13.01620902
> B,9,18.10976359
> B,10,18.22350661
> B,10,18.41504728
> B,10,17.94735486
> B,10,18.39173938
> B,10,14.21729704
> B,10,16.95753684
> B,10,21.11643087
> B,10,16.09688752
> B,10,19.54707452
> B,10,22.00450065
> B,10,15.15308873
> B,10,14.72488972
> B,10,17.65280737
> B,10,14.61615255
> B,10,12.89525607
> B,11,22.35831089
> B,11,18.0853187
> B,11,22.12815791
> B,11,17.74562214
> B,11,21.45724242
> B,11,20.57933779
> B,11,19.97397415
> B,11,16.34967424
> B,12,22.14385376
> B,12,17.82816113
> B,12,18.37056381
> B,12,16.13152759
> B,12,22.06764318
> B,12,12.80924472
> B,12,18.95522175
> B,13,20.40554286
> B,13,19.72951878
> C,14,15.51581
> C,14,15.4836358
> C,14,13.35882363
> C,14,13.16072916
> C,14,21.69168971
> C,14,19.09686303
> C,14,14.47450457
> C,14,12.04870424
> C,14,13.33096141
> C,14,17.38388981
> C,14,16.29015289
> C,14,16.32707754
> C,14,16.2784054
> C,15,15.0170597
> C,15,14.95767365
> C,15,15.20739614
> C,15,22.10458509
> C,15,12.3362457
> C,15,19.87895753
> C,15,18.8363682
> C,15,16.43738666
> C,15,12.84570744
> C,15,15.99869357
> C,15,14.42551321
> C,15,13.63489872
> C,15,15.67179885
> C,16,14.61700901
> C,16,14.64864676
> C,16,14.13014582
> C,16,21.7637441
> C,16,20.66825543
> C,16,17.05977818
> C,16,17.80118916
> C,16,15.16641698
> 
> where this is read into stand.data. When I use the following survey designs,
> 
> srv1 <- svydesign(ids=~1, strata=~strata, data=stand.data )
> 
> or,
> 
> srv1 <- svydesign(ids=~cluster, strata=~strata, data=stand.data )
> 
> with,
> 
> print( svytotal( ~vol, srv1 ) )
> 
> I only obtain the total,
> 
>> print( svytotal( ~vol, srv1 ) )
>     total     SE
> vol  2377 34.464
> 
> or worse,
> 
> print( svytotal( ~vol + strata, srv1 ) )
>          total     SE
> vol     2377.0 34.464
> strataA   42.0  0.000
> strataB   64.0  0.000
> strataC   34.0  0.000
> 
> which reports the number of observations in each of the strata. I'm sure
> this is a RTFM question, but I just need a start. The size of each "plot"
> is 0.04 units (hectares) and I want to be able to quickly examine working
> up each sample with and without clusters (this is going to be part of a
> larger simulation study).
> 
> I'm trying to not use SAS for this and hate to admit defeat.
> 
> Thanks,
> Jeff.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
James Reilly
Department of Statistics, University of Auckland
Private Bag 92019, Auckland, New Zealand



From ripley at stats.ox.ac.uk  Thu Feb  9 14:24:02 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Feb 2006 13:24:02 +0000 (GMT)
Subject: [R] logLik == -Inf in gls
In-Reply-To: <1415.139.133.94.35.1139489777.squirrel@www.abdn.ac.uk>
References: <1415.139.133.94.35.1139489777.squirrel@www.abdn.ac.uk>
Message-ID: <Pine.LNX.4.64.0602091317200.5967@gannet.stats.ox.ac.uk>

Please do not repeatedly post the same thing.  This is the same as

https://stat.ethz.ch/pipermail/r-help/2006-February/086381.html

(except you remembered to sign that one).

You are fitting a weighted not a generalised least squares model: lm() 
will do that.

On Thu, 9 Feb 2006, nhy303 at abdn.ac.uk wrote:

> I am trying to fit a generalised least squares model using gls in the nlme
> package.
>
> The model seems to fit very well when I plot the fitted values against the
> original values, and the model parameters have quite narrow confidence
> intervals (all are significant at p<5%).
>
> The problem is that the log likelihood is always given as -Inf.  This
> doesn't seem to make sense because the model seems to fit my data so well.
> I have checked that the residuals are stationary using an adf test.  I
> can't work out whether
>  - the model really doesn't fit at all
>  - there is something in my data that stops the implementation of logLik
> working correctly (the -Inf value says the calculation hasn't worked)
>
> Possible causes are:
>  - There are lots of NAs in my data (model and response variables)
>  - There is some autocorrelation in the data that is not accounted for by
> the model (most is accounted for).
>
> But, I've tried recreating the problem using a simpler data set, and have
> never found the same problem.

Well, how then do you expect us to be able to recreate it?

As a pure guess, look at your weights.  Are any numob4150 zero?


> The command I use to fit the model is...
>
>
>
> result2 <- gls(lci4150 ~ propCapInStomachs +
>                        temperature +
>                        as.factor(monthNumber) +
>                        lagLci1 +
>                        lagcap1 +
>                        lagcap2,
>              data = monthly,
>              subset = subset1985,
>              na.action = na.approx,
>              weights = varFixed( ~ 1/numob4150)
>             )
>
>
>
> The output I get is...
>
>
>
> Generalized least squares fit by REML
>  Model: lci4150 ~ propCapInStomachs + temperature +
> as.factor(monthNumber) +      lagLci1 + lagcap1 + lagcap2
>  Data: monthly
>  Subset: subset1985
>  AIC BIC logLik
>  Inf Inf   -Inf
>
> Variance function:
> Structure: fixed weights
> Formula: ~1/numob4150
>
> Coefficients:
>                              Value Std.Error   t-value p-value
> (Intercept)              -0.3282412 0.5795665 -0.566356  0.5717
> propCapInStomachs         0.0093283 0.0039863  2.340107  0.0202
> temperature               0.4342514 0.1526104  2.845490  0.0048
> as.factor(monthNumber)2   0.3990717 0.3869991  1.031195  0.3036
> as.factor(monthNumber)3   1.3788334 0.3675690  3.751223  0.0002
> as.factor(monthNumber)4   1.4037195 0.3857764  3.638686  0.0003
> as.factor(monthNumber)5   0.9903316 0.3436177  2.882074  0.0043
> as.factor(monthNumber)6   0.3453741 0.3043698  1.134719  0.2577
> as.factor(monthNumber)7   0.3948442 0.3035142  1.300909  0.1946
> as.factor(monthNumber)8   0.5021812 0.3532413  1.421638  0.1565
> as.factor(monthNumber)9  -0.0794319 0.3598981 -0.220707  0.8255
> as.factor(monthNumber)10  0.3536805 0.3790538  0.933061  0.3518
> as.factor(monthNumber)11  0.7874834 0.3557116  2.213826  0.0278
> as.factor(monthNumber)12  0.1854279 0.3178320  0.583415  0.5602
> lagLci1                   0.5488437 0.0576144  9.526151  0.0000
> lagcap1                   0.0110994 0.0043669  2.541714  0.0117
> lagcap2                  -0.0088080 0.0041099 -2.143127  0.0332
>
>
>
> Does anyone have any suggestions of how I can get a meaningful value for
> logLik?  Or some other way that I can compare models.
>
> Thankyou,
>
> Lillian.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From henric.nilsson at statisticon.se  Thu Feb  9 14:25:17 2006
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Thu, 09 Feb 2006 14:25:17 +0100
Subject: [R] lme syntax for P&B examples
In-Reply-To: <780EF47148B1D44ABE849DBA0A93548F0DF222@whaklexch1.thewarehousegroup.net>
References: <780EF47148B1D44ABE849DBA0A93548F0DF222@whaklexch1.thewarehousegroup.net>
Message-ID: <43EB42BD.5080003@statisticon.se>

Paul Cossens said the following on 2006-02-09 06:21:
> Hi Harold,
> 
> 
> Thanks for your reply. I had already looked at all the reading material
> you suggested but updated to the latest Matrix 
> as recommneded then spent all day trying to figure out what is
> happening.  
> 
> I worked through the problems and give my workings below that others may
> find useful. 
> (My notation is to use lme> to show lme commands and lmer> to show lmer
> commands. 
> I worked on two sessions in parallel. My comments are preceded by double
> hashes '##' and
> questions '##??'. I haven't included the datasets.)   
> 
> I have a couple of comments and outstanding issues:
> 
> 1. In the Pixel data set and formulas I think the formulas are printed
> incorrectly in the 
> book as some use 'I(day^2)' while others use just 'day^2'. I have used
> 'I(day^2)'. I'm not sure why the I() function is used. In the fm4Pixel
> example below the answers don't match up exactly but are close.
> 
> The lme example is 
> fm1Pixel<-lme(pixel~day+I(day^2),data=Pixel,random = list(Dog=~day
> ,Side=~1))
> fm5Pixel <- update(fm1Pixel,pixel ~ day + I(day^2) + Side)
> which I have converted to lmer:
> fm4Pixel <- lmer(pixel ~ day + I(day^2) +Side +(day|Dog), data = Pixel)
> 
> The t-values for Side are close (sse below) but different enough to
> wonder if I am still doing something wrong? 

It's wrong. Try

fm6Pixel <- lmer(pixel ~ day + I(day^2) + Side + (day|Dog) + 
(1|Side:Dog), data = Pixel)

> 2. To me the specification description in the R-News article is
> confusing as it seems 
> to suggest that nesting does not need to be completely specified if the
> groupings and nestings are clear in data set. 
> 
> Prof Bates article in R news vol 5/1 P 30  states "It happens in this
> case that the grouping factors 'id' and 'sch' are not nested but if they
> were nested there would be no change in the model specification"
> 
> If the lme formula is 
> fm1Oxide<-lme(Thickness~1,Oxide)
> 
> I have found the formula lmer parlance should be:
> 'fm1Oxide<-lmer(Thickness~ (1|Lot)+(1|Lot:Wafer),data=Oxide)'
> not 'fm1Oxide<-lmer(Thickness~ (1|Lot)+(1|Wafer),data=Oxide)'
> as the article reads to me. 
> 
> In other words you always need to explicitly specify nesting levels.
> 
> 3. I still can't figue out how to replicate the lme formula
> fm2Oxide<-update(fm1Oxide,random =~1|Lot)
> i.e 
> formula(fm2Oxide)
> Thickness ~ 1
> 
> If I simply drop the Lot:Wafer term as in 'fm2Oxide<-lmer(Thickness~
> (1|Lot),data=Oxide)'
> I get the error
> 
> 'Error in x[[3]] : object is not subsettable'
> 
> what's the solution?

fm3Oxide <- lmer(Thickness ~ 1 + (1|Lot), data = Oxide)

This seems to be a bug in `lmer', since one doesn't have to specifiy the 
intercept explicitly in e.g.

lmer(Thickness ~ (1|Lot) + (1|Wafer), data = Oxide)


HTH,
Henric



> 
> I'd be interested to read you article for further insights.
> 
> Thanks
> 
> Paul
> 
> 
> 
> #############################################################
> #Oxide
> # P&B(2000) p167-170
> 
> #NLME lme example
> 
> lme>data(Oxide)
> lme>formula(Oxide)
> lme>Thickness ~ 1 | Lot/Wafer
> lme>fm1Oxide<-lme(Thickness~1,Oxide)
> lme> fm1Oxide
> Linear mixed-effects model fit by REML
>   Data: Oxide 
>   Log-restricted-likelihood: -227.0110
>   Fixed: Thickness ~ 1 
> (Intercept) 
>    2000.153 
> 
> Random effects:
>  Formula: ~1 | Lot
>         (Intercept)
> StdDev:    11.39768
> 
>  Formula: ~1 | Wafer %in% Lot
>         (Intercept) Residual
> StdDev:    5.988802 3.545341
> 
> Number of Observations: 72
> Number of Groups: 
>            Lot Wafer %in% Lot 
>              8             24 
> 
> lme> intervals(fm1Oxide, which = "var-cov")
> Approximate 95% confidence intervals
> 
>  Random Effects:
>   Level: Lot 
>                   lower     est.    upper
> sd((Intercept)) 6.38881 11.39768 20.33355
>   Level: Wafer 
>                    lower     est.    upper
> sd((Intercept)) 4.063919 5.988802 8.825408
> 
>  Within-group standard error:
>    lower     est.    upper 
> 2.902491 3.545341 4.330572 
> fm2Oxide<-update(fm1Oxide,random =~1|Lot)
> lme> fm2Oxide
> Linear mixed-effects model fit by REML
>   Data: Oxide 
>   Log-restricted-likelihood: -245.5658
>   Fixed: Thickness ~ 1 
> (Intercept) 
>    2000.153 
> 
> Random effects:
>  Formula: ~1 | Lot
>         (Intercept) Residual
> StdDev:    11.78447 6.282416
> 
> Number of Observations: 72
> Number of Groups: 8
> 
> lme>intervals(fm2Oxide, which = "var-cov")
> Approximate 95% confidence intervals
> 
>  Random Effects:
>   Level: Lot 
>                    lower     est.    upper
> sd((Intercept)) 6.864617 11.78447 20.23035
> 
>  Within-group standard error:
>    lower     est.    upper 
> 5.283116 6.282416 7.470733 
> 
> lme> coef(fm1Oxide, level=1)
>   (Intercept)
> 1    1996.689
> 2    1988.931
> 3    2001.022
> 4    1995.682
> 5    2013.616
> 6    2019.561
> 7    1991.954
> 8    1993.767
> coef(fm1Oxide, level=1)
>   (Intercept)
> 1    1996.689
> 2    1988.931
> 3    2001.022
> 4    1995.682
> 5    2013.616
> 6    2019.561
> 7    1991.954
> 8    1993.767
>> coef(fm1Oxide, level=2)
>     (Intercept)
> 1/1    2003.235
> 1/2    1984.730
> 1/3    2001.146
> 2/1    1989.590
> 2/2    1988.097
> 2/3    1986.008
> 3/1    2002.495
> 3/2    2000.405
> 3/3    2000.405
> 4/1    1995.668
> 4/2    1998.951
> 4/3    1991.191
> 5/1    2009.184
> 5/2    2016.646
> 5/3    2018.735
> 6/1    2031.296
> 6/2    2021.745
> 6/3    2011.000
> 7/1    1990.204
> 7/2    1991.398
> 7/3    1991.995
> 8/1    1993.677
> 8/2    1995.170
> 8/3    1990.693
> 
> 
> ######## the is the lmer example using Matrix 0.995-5
> 
> 
> lmer>Oxide<-read.csv("Oxide.csv",header=TRUE);
> lmer>Oxide$Source<-as.factor(Oxide$Source)
> lmer>Oxide$Lot<-as.factor(Oxide$Lot)
> lmer>Oxide$Wafer<-as.factor(Oxide$Wafer)
> Lmer>Oxide$Site<-as.factor(Oxide$Site)
> 
> 
> ## Bates article in R news vol5/1 says specifying nesting explicity
> isn't necessary: 
> ## P 30 "It happens in this case that the grouping factors 'id' and
> 'sch' are not 
> ## nested but if they were nested there would be no change in the model
> specification"
> ## Following this one would expect that the following statement would
> automatically 
> ## detect nesting
> 
> lmer>fm1Oxide<-lmer(Thickness~ (1|Lot)+(1|Wafer),data=Oxide)
> 
> 
> lmer> fm1Oxide
> Linear mixed-effects model fit by REML
> Formula: Thickness ~ (1 | Lot) + (1 | Wafer) 
>    Data: Oxide 
>       AIC      BIC    logLik MLdeviance REMLdeviance
>  496.6093 503.4393 -245.3046   495.3528     490.6093
> Random effects:
>  Groups   Name        Variance Std.Dev.
>  Lot      (Intercept) 138.9981 11.7897 
>  Wafer    (Intercept)   1.4930  1.2219 
>  Residual              38.3490  6.1927 
> # of obs: 72, groups: Lot, 8; Wafer, 3
> 
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept) 2000.1528     4.2901  466.22
> 
> ## The lme vs lmer std.devs for Lot are 11.39768 : 11.7987  
> ## The lme vs lmer std.devs for Wafer are 5.988802 : 1.2219 
> ## If my lmer specifcation is correct then the Wafer std.dev seems too
> big.
> ## also the levels aren't specifed correctly as the following ranef()
> function
> ## shows
> 
> lmer> ranef(fm1Oxide)
> An object of class "lmer.ranef"
> [[1]]
>   (Intercept)
> 1  -3.7058415
> 2 -12.0069264
> 3   0.9298293
> 4  -4.7839045
> 5  14.4056166
> 6  20.7661881
> 7  -8.7727375
> 8  -6.8322241
> 
> [[2]]
>   (Intercept)
> 1   0.9526407
> 2  -0.2750582
> 3  -0.6775825
> 
> ###There is no nesting of wafers within lots
> ###Note however that the following appears to work the same as in the
> P&B text
>  
> lmer> fm3Oxide<-lmer(Thickness~ (1|Lot)+(1|Lot:Wafer),data=Oxide)
> lmer> fm3Oxide
> Linear mixed-effects model fit by REML
> Formula: Thickness ~ (1 | Lot) + (1 | Lot:Wafer) 
>    Data: Oxide 
>       AIC      BIC    logLik MLdeviance REMLdeviance
>  460.0221 466.8521 -227.0110   458.7378     454.0221
> Random effects:
>  Groups    Name        Variance Std.Dev.
>  Lot:Wafer (Intercept)  35.866   5.9888 
>  Lot       (Intercept) 129.853  11.3953 
>  Residual               12.570   3.5454 
> # of obs: 72, groups: Lot:Wafer, 24; Lot, 8
> 
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept) 2000.1528     4.2309  472.75
> 
> ## the following gives the coefficients for levels however the number of
> levels is 
> ## in reverse order to lme
> ## Also note that the order of levels seems to have changed from the
> lmer model 
> ## fm1Oxide where Lot coefficnets are in [[1]] and Wafer [[2]] 
> lmer>ranef(fm3Oxide)
> An object of class "lmer.ranef"
> [[1]]
>      (Intercept)
> 1:1   6.54582998
> 1:2 -11.95898390
> 1:3   4.45657680
> 2:1   0.65819690
> 2:2  -0.83412680
> 2:3  -2.92337998
> 3:1   1.47284009
> 3:2  -0.61641309
> 3:3  -0.61641309
> 4:1  -0.01366505
> 4:2   3.26944709
> 4:3  -4.49063615
> 5:1  -4.43133801
> 5:2   3.03028049
> 5:3   5.11953367
> 6:1  11.73559478
> 6:2   2.18472310
> 6:3  -8.56000754
> 7:1  -1.74970878
> 7:2  -0.55584982
> 7:3   0.04107966
> 8:1  -0.09041889
> 8:2   1.40190481
> 8:3  -3.07506629
> 
> [[2]]
>   (Intercept)
> 1   -3.463334
> 2  -11.221203
> 3    0.868982
> 4   -4.470850
> 5   13.462925
> 6   19.407266
> 7   -8.198657
> 8   -6.385129
> 
> ##?? given that the fm3Oxide works one would expect that dropping the 
> ##?? (1|Lot:Wafer) term would work however it give the following error
> 
> lmer>fm2Oxide<-lmer(Thickness~ (1|Lot),data=Oxide)
> Error in x[[3]] : object is not subsettable
> 
> ##?? the question is how to specify the lme model
> fm2Oxide<-update(fm1Oxide,random =~1|Lot)
> ##?? in lme syntax
> 
> 
> ######################################################################
> 
> #Pixel
> # P&B(2000) p40-45
> 
> ## the lme example is as follows
> 
> lme>data(Pixel)
> 
> ## firstly the book may have an error on P 42 line 1
> lme_wrong> fm1Pixel<-lme(pixel~day+day^2,data=Pixel,random = list(Dog= ~
> day ,Side= ~ 1))
> ###which gives: 
> lme_wrong> intervals(fm1Pixel)
> Approximate 95% confidence intervals
> 
>  Fixed effects:
>                   lower       est.       upper
> (Intercept) 1071.415167 1093.21538 1115.015590
> day           -1.126053   -0.14867    0.828713
> attr(,"label")
> [1] "Fixed effects:"
> 
>  Random Effects:
>   Level: Dog 
>                           lower       est.      upper
> sd((Intercept))      17.3485293 31.4936604 57.1720308
> sd(day)               0.3586459  1.0719672  3.2040342
> cor((Intercept),day) -0.9822311 -0.7863546  0.2294876
>   Level: Side 
>                    lower     est.    upper
> sd((Intercept)) 8.519543 15.08995 26.72755
> 
>  Within-group standard error:
>    lower     est.    upper 
> 12.35975 14.53391 17.09052 
> 
> ## the book should probably give I(day^2) instead of day^2 on p42 line 1
> where 
> ## as this gives the answer in the book
> lme> fm1Pixel<-lme(pixel~day+I(day^2),data=Pixel,random = list(Dog=~day
> ,Side=~1))
> lme> intervals(fm1Pixel)
> Approximate 95% confidence intervals
> 
>  Fixed effects:
>                    lower         est.        upper
> (Intercept) 1053.0968388 1073.3391382 1093.5814376
> day            4.3796925    6.1295971    7.8795016
> I(day^2)      -0.4349038   -0.3673503   -0.2997967
> attr(,"label")
> [1] "Fixed effects:"
> 
>  Random Effects:
>   Level: Dog 
>                           lower       est.      upper
> sd((Intercept))      15.9284469 28.3699038 50.5291851
> sd(day)               1.0812133  1.8437505  3.1440751
> cor((Intercept),day) -0.8944371 -0.5547222  0.1909581
>   Level: Side 
>                    lower     est.    upper
> sd((Intercept)) 10.41726 16.82431 27.17195
> 
>  Within-group standard error:
>     lower      est.     upper 
>  7.634522  8.989606 10.585209 
> 
> lme>VarCorr(fm1Pixel) 
>             Variance       StdDev    Corr  
> Dog =       pdLogChol(day)                 
> (Intercept) 804.851443     28.369904 (Intr)
> day           3.399416      1.843750 -0.555
> Side =      pdLogChol(1)                   
> (Intercept) 283.057248     16.824305       
> Residual     80.813009      8.989606
> 
> lme>  summary(fm1Pixel)
> Linear mixed-effects model fit by REML
>  Data: Pixel 
>        AIC      BIC    logLik
>   841.2102 861.9712 -412.6051
> 
> Random effects:
>  Formula: ~day | Dog
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev    Corr  
> (Intercept) 28.369904 (Intr)
> day          1.843750 -0.555
> 
>  Formula: ~1 | Side %in% Dog
>         (Intercept) Residual
> StdDev:    16.82431 8.989606
> 
> Fixed effects: pixel ~ day + I(day^2) 
>                 Value Std.Error DF   t-value p-value
> (Intercept) 1073.3391 10.171686 80 105.52225       0
> day            6.1296  0.879321 80   6.97083       0
> I(day^2)      -0.3674  0.033945 80 -10.82179       0
>  Correlation: 
>          (Intr) day   
> day      -0.517       
> I(day^2)  0.186 -0.668
> 
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max 
> -2.82905723 -0.44918107  0.02554930  0.55721629  2.75196509 
> 
> Number of Observations: 102
> Number of Groups: 
>           Dog Side %in% Dog 
>            10            20  
> 
> ## Note thate the formula in the book is on P44 sect 1.5.1 summary table
> is
> ##  Fixed effects: pixel ~ day + day^2 
> ## compared to above:
> ## Fixed effects: pixel ~ day + I(day^2)
> ## but the anova on page 45 is the same
> 
> lme>fm2Pixel <- update(fm1Pixel,random = ~day | Dog)
> lme>anova(fm1Pixel,fm2Pixel)
>          Model df      AIC      BIC    logLik   Test L.Ratio p-value
> fm1Pixel     1  8 841.2102 861.9712 -412.6051                       
> fm2Pixel     2  7 884.5196 902.6854 -435.2598 1 vs 2 45.3094  <.0001
> 
> 
> lme> fm3Pixel <- update(fm1Pixel,random = ~1 | Dog/Side)
> lme > anova(fm1Pixel,fm3Pixel)
>          Model df      AIC      BIC    logLik   Test  L.Ratio p-value
> fm1Pixel     1  8 841.2102 861.9712 -412.6051                        
> fm3Pixel     2  6 876.8390 892.4098 -432.4195 1 vs 2 39.62885  <.0001
> 
> 
> ##again there following seems to be a mistake in the book
> 
> lme> fm4Pixel <- update(fm1Pixel,pixel ~ day + day^2 + Side)
> lme> summary(fm4Pixel)
> Linear mixed-effects model fit by REML
>  Data: Pixel 
>       AIC     BIC    logLik
>   895.071 915.832 -439.5355
> 
> Random effects:
>  Formula: ~day | Dog
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev    Corr  
> (Intercept) 31.520129 (Intr)
> day          1.073342 -0.786
> 
>  Formula: ~1 | Side %in% Dog
>         (Intercept) Residual
> StdDev:    15.01697 14.50742
> 
> Fixed effects: pixel ~ day + Side 
>                 Value Std.Error DF  t-value p-value
> (Intercept) 1097.5272 11.562590 81 94.92053  0.0000
> day           -0.1496  0.491218 81 -0.30451  0.7615
> SideR         -8.6098  7.379984  9 -1.16664  0.2733
>  Correlation: 
>       (Intr) day   
> day   -0.633       
> SideR -0.319  0.000
> 
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max 
> -3.73906417 -0.38367706  0.04758941  0.39690056  2.23720545 
> 
> Number of Observations: 102
> Number of Groups: 
>           Dog Side %in% Dog 
>            10            20 
> 
> ###the book should probably give I(day^2) instead of day^2
> ### as the fixed effect coefficient names in the summary table 
> ##  differ from the formula given
> ##  the following seems a partial correction   
> lme> fm5Pixel <- update(fm1Pixel,pixel ~ day + I(day^2) + Side)
> lme>summary(fm5Pixel)
> 
> Linear mixed-effects model fit by REML
>  Data: Pixel 
>        AIC      BIC    logLik
>   835.8546 859.1193 -408.9273
> 
> Random effects:
>  Formula: ~day | Dog
>  Structure: General positive-definite, Log-Cholesky parametrization
>             StdDev    Corr  
> (Intercept) 28.463605 (Intr)
> day          1.843823 -0.553
> 
>  Formula: ~1 | Side %in% Dog
>         (Intercept) Residual
> StdDev:     16.5072 8.983614
> 
> Fixed effects: pixel ~ day + I(day^2) + Side 
>                 Value Std.Error DF   t-value p-value
> (Intercept) 1077.9484 10.862705 80  99.23388  0.0000
> day            6.1296  0.879023 80   6.97323  0.0000
> I(day^2)      -0.3674  0.033923 80 -10.82914  0.0000
> SideR         -9.2175  7.626768  9  -1.20858  0.2576
>  Correlation: 
>          (Intr) day    I(d^2)
> day      -0.484              
> I(day^2)  0.174 -0.667       
> SideR    -0.351  0.000  0.000
> 
> Standardized Within-Group Residuals:
>         Min          Q1         Med          Q3         Max 
> -2.80982455 -0.47133415  0.02610263  0.54115378  2.77470104 
> 
> Number of Observations: 102
> Number of Groups: 
>           Dog Side %in% Dog 
>            10            20 
> 
> 
> ## Note however that the Fixed effects Values above differ from the
> values in the book  
> 
> ####### the is the lmer example for Pixel using Matrix 0.995-5
> 
> ##the lmer example for the Pixel data is exported and reimported as a
> csv file
> lmer>Pixel<-read.csv("Pixel.csv",header=TRUE);
> lmer>Pixel$Side<-as.factor(Pixel$Side)
> lmer>Pixel$Dog<-as.factor(Pixel$Dog)
> lmer>Pixel$DS<-with(Pixel,Dog:Side)[drop=TRUE]
>  
> lmer>fm1Pixel <- lmer(pixel ~ day + I(day^2) +(day|Dog)+(1|Dog:Side),
> data = Pixel)
> lmer>fm1Pixel
> Linear mixed-effects model fit by REML
> Formula: pixel ~ day + I(day^2) + (day | Dog) + (1 | Dog:Side) 
>    Data: Pixel 
>       AIC     BIC    logLik MLdeviance REMLdeviance
>  839.2102 857.585 -412.6051   827.3298     825.2102
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr   
>  Dog:Side (Intercept) 283.0567 16.8243         
>  Dog      (Intercept) 804.8460 28.3698         
>           day           3.3994  1.8438  -0.555 
>  Residual              80.8130  8.9896         
> # of obs: 102, groups: Dog:Side, 20; Dog, 10
> 
> Fixed effects:
>                Estimate  Std. Error t value
> (Intercept) 1073.339126   10.171658 105.523
> day            6.129599    0.879321   6.971
> I(day^2)      -0.367350    0.033945 -10.822
> 
> Correlation of Fixed Effects:
>          (Intr) day   
> day      -0.517       
> I(day^2)  0.186 -0.668
> 
> ## 
> 
> lme> VarCorr(fm1Pixel)
> $"Dog:Side"
> 1 x 1 Matrix of class "dpoMatrix"
>             (Intercept)
> (Intercept)    283.0567
> 
> $Dog
> 2 x 2 Matrix of class "dpoMatrix"
>             (Intercept)        day
> (Intercept)   804.84605 -29.015418
> day           -29.01542   3.399415
> 
> attr(,"sc")
> [1] 8.989606
> 
> lmer> fm2Pixel <- lmer(pixel ~ day + I(day^2) +(day|Dog), data = Pixel)
> lmer> fm2Pixel
> Linear mixed-effects model fit by REML
> Formula: pixel ~ day + I(day^2) + (day | Dog) 
>    Data: Pixel 
>       AIC      BIC    logLik MLdeviance REMLdeviance
>  882.5196 898.2694 -435.2598   873.5964     870.5196
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr   
>  Dog      (Intercept) 892.7720 29.8793         
>           day           3.0772  1.7542  -0.488 
>  Residual             197.5767 14.0562         
> # of obs: 102, groups: Dog, 10
> 
> Fixed effects:
>               Estimate Std. Error t value
> (Intercept) 1072.92725   10.44452 102.726
> day            6.08910    1.14699   5.309
> I(day^2)      -0.35677    0.05221  -6.833
> 
> Correlation of Fixed Effects:
>          (Intr) day   
> day      -0.541       
> I(day^2)  0.286 -0.799
> 
> lmer> anova(fm1Pixel,fm2Pixel)
> 
> Data: Pixel
> Models:
> fm2Pixel: pixel ~ day + I(day^2) + (day | Dog)
> fm1Pixel: pixel ~ day + I(day^2) + (day | Dog) + (1 | Dog:Side)
>          Df     AIC     BIC  logLik  Chisq Chi Df Pr(>Chisq)    
> fm2Pixel  6  882.52  898.27 -435.26                             
> fm1Pixel  7  839.21  857.59 -412.61 45.309      1  1.682e-11 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
> 
> ## Some of the statistics here are slightly different from above,
> notably the Df 
> ## but I guess the result is the same
> 
> lmer> fm3Pixel <- lmer(pixel ~ day + I(day^2) +(1|Dog:Side), data =
> Pixel)
> lmer> anova(fm1Pixel,fm3Pixel)
> 
> Data: Pixel
> Models:
> fm3Pixel: pixel ~ day + I(day^2) + (1 | Dog:Side)
> fm1Pixel: pixel ~ day + I(day^2) + (day | Dog) + (1 | Dog:Side)
>          Df     AIC     BIC  logLik Chisq Chi Df Pr(>Chisq)    
> fm3Pixel  4  877.88  888.38 -434.94                            
> fm1Pixel  7  839.21  857.59 -412.61 44.67      3  1.087e-09 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 
> 
> ## Some of the statistics are slightly different again
> 
> lmer>fm4Pixel <- lmer(pixel ~ day + I(day^2) +Side +(day|Dog), data =
> Pixel)
> lmer>fm4Pixel
> 
> Linear mixed-effects model fit by REML
> Formula: pixel ~ day + I(day^2) + Side + (day | Dog) 
>    Data: Pixel 
>       AIC      BIC    logLik MLdeviance REMLdeviance
>  876.8204 895.1952 -431.4102   869.6765     862.8204
> Random effects:
>  Groups   Name        Variance Std.Dev. Corr   
>  Dog      (Intercept) 896.1278 29.9354         
>           day           3.0972  1.7599  -0.490 
>  Residual             190.9227 13.8175         
> # of obs: 102, groups: Dog, 10
> 
> Fixed effects:
>                Estimate  Std. Error t value
> (Intercept) 1075.649999   10.521427 102.234
> day            6.091506    1.133983   5.372
> I(day^2)      -0.357334    0.051369  -6.956
> SideR         -5.401961    2.736268  -1.974
> 
> Correlation of Fixed Effects:
>          (Intr) day    I(d^2)
> day      -0.535              
> I(day^2)  0.279 -0.795       
> SideR    -0.130  0.000  0.000
> 
> ##?? Fixed effects estimates are sligtly different 
> ##?? As df and p-values are missing I assume that it can be concluded
> that as 
> ##?? t-value is less than 1.96 that 'Side' is not sigificant. 
> ##?? In the lme example for fm4Pixel the t-value for Side is -1.21
> ##?? have i specified fm4Pixel correctly?
> 
> -----Original Message-----
> From: Doran, Harold [mailto:HDoran at air.org] 
> Sent: Thursday, 9 February 2006 02:01
> To: Paul Cossens; r-help at stat.math.ethz.ch
> Subject: RE: [R] lme syntax for P&B examples
> 
> 
> Paul:
> 
> It is a little difficult to understand what you are trying to translate
> since you do not show what the model would look like using lme. If you
> show lme, then it is easy to translate into lmer syntax.
> 
> A few thoughts, first, use lmer in the Matrix package and not in lme4.
> Second, see the Bates article in R news at the link below for dealing
> with nesting structures. Last, a colleague and I have a paper in press
> showing how to fit models using lme which we submitted a year or so ago.
> Since lme has evolved to lmer, we created an appendix that translates
> all of our lme models to the lmer syntax so readers can see
> equivalences. I am happy to send this to you (or others) upon request.
> 
> http://cran.r-project.org/doc/Rnews/Rnews_2005-1.pdf
> 
> Harold
> 
> 
>  
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Paul Cossens
> Sent: Wednesday, February 08, 2006 12:08 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] lme syntax for P&B examples
> 
> Hi helpeRs,
>  
> I've been working through some examples in Pinhiero & Bates( 2000)
> trying to understand how to translate to the new Lme4 syntax but without
> much luck. Below is what I think I should do, but either the answers
> don't come out the same or I get errors. 
> In the Oxide problems I'm particularly interested in obtaining the
> levels coeficients but this options no longer seems to be available in
> lme4. How can levels infor be obtained in lme4?
>  
> If someone can recreate the examples below in lme4 syntax so I can
> follow what is happening in the text I'd be grateful. 
>  
> Cheers
>  
> Paul Cossens
>  
>  
> #Pixel
> # P&B(2000) p40-45
>  
> Pixel<-read.csv("Pixel.csv",header=TRUE);
> Pixel$Side<-as.factor(Pixel$Side)
> Pixel$Dog<-as.factor(Pixel$Dog)
>  
> (fm1Pixel <- lmer(pixel ~ day + I(day^2) +(day|Dog)+(1|Side), data =
> Pixel))
> (fm2Pixel <- lmer(pixel ~ day + I(day^2) +(day|Dog), data = Pixel))
> (fm3Pixel <- lmer(pixel ~ day + I(day^2) +(1|Dog:Side), data = Pixel))
> or should I do it this way? Pixel$DS<-with(Pixel,Dog:Side)[drop=TRUE]
> (fm3Pixel <- lmer(pixel ~ day + I(day^2) +(1|DS), data = Pixel))
>  
> (fm4Pixel <- lmer(pixel ~ day + I(day^2) +Side , data = Pixel))
>  
> 
> #Oxide
> # P&B(2000) p167-170
>  
> Oxide<-read.csv("Oxide.csv",header=TRUE);
> Oxide$Source<-as.factor(Oxide$Source)
> Oxide$Lot<-as.factor(Oxide$Lot)
> Oxide$Wafer<-as.factor(Oxide$Wafer)
> Oxide$Site<-as.factor(Oxide$Site)
> fm1Oxide<-lmer(Thickness~ (1|Lot)+(1|Lot:Wafer),data=Oxide) )
> (fm2Oxide<-lmer(Thickness~ (1|Lot),data=Oxide) )
> coef(fm1Oxide)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From stefano.sofia at regione.marche.it  Thu Feb  9 14:24:02 2006
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Thu, 09 Feb 2006 13:24:02 +0000
Subject: [R] about Cox-Box transformation
In-Reply-To: <Pine.LNX.4.63.0602091056100.26089@est.ufpr.br>
References: <1139485862.13270.8.camel@aion.regionemarche.intra>
	<Pine.LNX.4.63.0602091056100.26089@est.ufpr.br>
Message-ID: <1139491442.13270.16.camel@aion.regionemarche.intra>

Paulo, 
thank you for the straightforward hint. 
But then, I should use the Box-Cox transformation to a set of data,
whose class at the moment is data.frame. 
The help says only lm and aov objects can be handled. What should I do?


thank you
Stefano


On Thu, 2006-02-09 at 10:56 -0200, Paulo Justiniano Ribeiro Jr wrote:
> first load the package with:
> 
> require(MASS)
> 
> and then use the boxcox() function
> 
> 
> On Thu, 9 Feb 2006, Stefano Sofia wrote:
> 
> > Date: Thu, 09 Feb 2006 11:51:02 +0000
> > From: Stefano Sofia <stefano.sofia at regione.marche.it>
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] about Cox-Box transformation
> > 
> > Dear R-users,
> > I am using R version 1.8.0-1 under Suse 8.2.
> > I need to use the boxcox command because I want to apply a Cox-Box
> > transformation to a vector of rainfall values.
> > Within the libraries, the MASS library is present, but I don't know
> > whether this means that is automatically installed or not.
> > The command doesn't work. What do I have to do in order to make it
> > working? Is just a problem of installation or simply of recalling the
> > right command?
> >
> > thank you for your help
> > Stefano
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
> 
> Paulo Justiniano Ribeiro Jr
> LEG (Laboratrio de Estatstica e Geoinformao)
> Departamento de Estatstica
> Universidade Federal do Paran
> Caixa Postal 19.081
> CEP 81.531-990
> Curitiba, PR  -  Brasil
> Tel: (+55) 41 3361 3573
> Fax: (+55) 41 3361 3141
> e-mail: paulojus at est.ufpr.br
> http://www.est.ufpr.br/~paulojus



From karin.lagesen at medisin.uio.no  Thu Feb  9 14:32:53 2006
From: karin.lagesen at medisin.uio.no (Karin Lagesen)
Date: Thu, 09 Feb 2006 14:32:53 +0100
Subject: [R] font size/disappearing labels
Message-ID: <ypx6bqxgpshm.fsf@uracil.uio.no>


I am sorry if you get this email twice, but it did not show up in the
digest nor on the web archive, so I am taking the chance of resending
it.

I am using vioplot to make nice boxplots, which I am outputting to
postscript. I am using the paper=special and width and height to get
the graphs to look nice. I do however have a problem with the size of
the labels and titles. When I set fontsize as an option to the
postscript call too high, one of the labels disappear, although there
is enough space for it (imo, that is). This I have understood is an
effect of the system trying to avoid overlapping numbers. Is there a
way I can override this function though? Can I force it to show all of
the labels, although they might be "too close"?


Karin
-- 
Karin Lagesen, PhD student
karin.lagesen at medisin.uio.no
http://www.cmbn.no/rognes/



From saskia.sandring at ebc.uu.se  Thu Feb  9 14:45:41 2006
From: saskia.sandring at ebc.uu.se (Saskia Sandring)
Date: Thu, 09 Feb 2006 14:45:41 +0100
Subject: [R] bootstrapping lambda values from projections matrices
Message-ID: <3.0.6.32.20060209144541.0199ad48@pop.uu.se>

Dear all,

I'm working with a population projections matrix model from demographic
data. The dominant eigenvalue of the matrix is the growth rate of the
population (lambda). I would like to estimate confidence intervals for the
lambda values with bootstrap. 
The function for calculating the eigenvalue I wrote like this: 

mat.fun <- function(d,i){
    mat<-matrix(c(0,
    sum(d$klyear1[i]==1&d$classyear2[i]==2)/sum(d$classyear1[i]==1),
    sum(d$classyear1[i]==1&d$classyear2[i]==3)/sum(d$classyear1[i]==1), 0,
    sum(d$classyear1[i]==2&d$classyear2[i]==2)/sum(d$classyear1[i]==2),
    sum(d$classyear1[i]==2&d$classyear2[i]==3)/sum(d$classyear1[i]==2),
    sum(d$classyear1[i]==0&d$classyear2[i]==1)/sum(d$classyear1[i]==3),
    sum(d$classyear1[i]==3&d$classyear2[i]==2)/sum(d$classyear1[i]==3),
    sum(d$classyear1[i]==3&d$classyear2[i]==2)/sum(d$classyear1[i]==3),

sum(d$classyear1[i]==3&d$classyear2[i]==3)/sum(d$classyear1[i]==3)),ncol=3)
    abs(eigen(mat,only.values=T)$values[1])
}

Now, in the pooled matrix from all years I would like to sample in a way
that the number of bootstrap samples taken from each year is equal to the
number of data points from each year. Therefore I'm defining strata=year. 

boot1 <- boot(myfile, mat.fun, 5000, strata=myfile$year); boot1

Is this the correct way to do it or did I misunderstand the
strata-argument? I checked in Davison, A.C. and Hinkley, D.V. (1997), but
I'm still not quite sure.

Thanks very much in advance for your help!

Sincerely,
Saskia Sandring

_________________________________________________________________________
Saskia Sandring

Avd. f??r v??xtekologi, Evolutionsbiologiskt centrum, Uppsala universitet
Dept. of Plant Ecology, Evolutionary Biology Centre, Uppsala University
Villav??gen 14			tel: 018-471 2870 (int +46 18 4712870)
SE-752 36 Uppsala		fax: 018-55 34 19 (int +46 18 553419)
SWEDEN				email: saskia.sandring at ebc.uu.se

http://www.vaxtbio.uu.se/resfold/sandring.htm



From adrian at atstatconsulting.com  Thu Feb  9 15:13:17 2006
From: adrian at atstatconsulting.com (Adrian Katschke)
Date: Thu, 9 Feb 2006 06:13:17 -0800 (PST)
Subject: [R] adding variable into dataframe by indice
In-Reply-To: <43EB2625.8046.653D5B@localhost>
Message-ID: <20060209141317.93776.qmail@web308.biz.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060209/7cd4f0e4/attachment.pl

From backer at psych.uib.no  Thu Feb  9 15:41:09 2006
From: backer at psych.uib.no (Tom Backer Johnsen)
Date: Thu, 09 Feb 2006 15:41:09 +0100
Subject: [R] Tranferring R results to word prosessors
Message-ID: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>

I have just started looking at R, and are getting more and more irritated 
at myself for not having done that before.

However, one of the things I have not found in the documentation is some 
way of preparing output from R for convenient formatting into something 
like MS Word.  An example:  If you use summary(lm(....)) you get nice 
output.  However, if you try to paste that output into the word processor, 
all the text elements are separated by blanks, and that is not optimal for 
the creation of a table (in the word processing sense).

Is there an option to generate tab-separated output in R ? That would solve 
the problem.

Tom

+----------------------------------------------------------------+
| Tom Backer Johnsen, Psychometrics Unit,  Faculty of Psychology |
| University of Bergen, Christies gt. 12, N-5015 Bergen,  NORWAY |
| Tel : +47-5558-9185                        Fax : +47-5558-9879 |
| Email : backer at psych.uib.no    URL : http://www.galton.uib.no/ |
+----------------------------------------------------------------+



From HDoran at air.org  Thu Feb  9 15:47:26 2006
From: HDoran at air.org (Doran, Harold)
Date: Thu, 9 Feb 2006 09:47:26 -0500
Subject: [R] Tranferring R results to word prosessors
Message-ID: <F5ED48890E2ACB468D0F3A64989D335A01ADEE82@dc1ex3.air.org>

Well, I don't know if it can be used with Word or not, but you might
consider Sweave for use with LaTeX. Maybe if you use the sink() command
this might work, but I haven't tried it. 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tom Backer
Johnsen
Sent: Thursday, February 09, 2006 9:41 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Tranferring R results to word prosessors

I have just started looking at R, and are getting more and more
irritated at myself for not having done that before.

However, one of the things I have not found in the documentation is some
way of preparing output from R for convenient formatting into something
like MS Word.  An example:  If you use summary(lm(....)) you get nice
output.  However, if you try to paste that output into the word
processor, all the text elements are separated by blanks, and that is
not optimal for the creation of a table (in the word processing sense).

Is there an option to generate tab-separated output in R ? That would
solve the problem.

Tom

+----------------------------------------------------------------+
| Tom Backer Johnsen, Psychometrics Unit,  Faculty of Psychology | 
| University of Bergen, Christies gt. 12, N-5015 Bergen,  NORWAY |
| Tel : +47-5558-9185                        Fax : +47-5558-9879 |
| Email : backer at psych.uib.no    URL : http://www.galton.uib.no/ |
+----------------------------------------------------------------+

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ggrothendieck at gmail.com  Thu Feb  9 15:47:31 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 9 Feb 2006 09:47:31 -0500
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
References: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
Message-ID: <971536df0602090647x3ce913bajaa4e09c1c930ead3@mail.gmail.com>

In Word use a fixed font such as Courier rather than a proportional
font and it will look ok.

On 2/9/06, Tom Backer Johnsen <backer at psych.uib.no> wrote:
> I have just started looking at R, and are getting more and more irritated
> at myself for not having done that before.
>
> However, one of the things I have not found in the documentation is some
> way of preparing output from R for convenient formatting into something
> like MS Word.  An example:  If you use summary(lm(....)) you get nice
> output.  However, if you try to paste that output into the word processor,
> all the text elements are separated by blanks, and that is not optimal for
> the creation of a table (in the word processing sense).
>
> Is there an option to generate tab-separated output in R ? That would solve
> the problem.
>
> Tom
>
> +----------------------------------------------------------------+
> | Tom Backer Johnsen, Psychometrics Unit,  Faculty of Psychology |
> | University of Bergen, Christies gt. 12, N-5015 Bergen,  NORWAY |
> | Tel : +47-5558-9185                        Fax : +47-5558-9879 |
> | Email : backer at psych.uib.no    URL : http://www.galton.uib.no/ |
> +----------------------------------------------------------------+
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From francoisromain at free.fr  Thu Feb  9 15:54:27 2006
From: francoisromain at free.fr (Romain Francois)
Date: Thu, 09 Feb 2006 15:54:27 +0100
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
References: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
Message-ID: <43EB57A3.8080106@free.fr>

Le 09.02.2006 15:41, Tom Backer Johnsen a ??crit :

>I have just started looking at R, and are getting more and more irritated 
>at myself for not having done that before.
>
>However, one of the things I have not found in the documentation is some 
>way of preparing output from R for convenient formatting into something 
>like MS Word.  An example:  If you use summary(lm(....)) you get nice 
>output.  However, if you try to paste that output into the word processor, 
>all the text elements are separated by blanks, and that is not optimal for 
>the creation of a table (in the word processing sense).
>
>Is there an option to generate tab-separated output in R ? That would solve 
>the problem.
>
>Tom
>  
>
Hi ,

One way could be to output in html format from R (with the R2HTML 
package) and then read back the html from your word processor

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From spluque at gmail.com  Thu Feb  9 16:17:46 2006
From: spluque at gmail.com (Sebastian Luque)
Date: Thu, 09 Feb 2006 09:17:46 -0600
Subject: [R] Tranferring R results to word prosessors
References: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
Message-ID: <87mzh0blyd.fsf@arctocephalus.homelinux.org>

Tom Backer Johnsen <backer at psych.uib.no> wrote:

[...]

> However, one of the things I have not found in the documentation is some
> way of preparing output from R for convenient formatting into something 
> like MS Word.

In case you're not talking about table-like output exclusively, reading
?Devices describes all the available kinds of graphical output.  Most of
these can then easily be included in MS Word.

Cheers,

-- 
Sebastian P. Luque



From maechler at stat.math.ethz.ch  Thu Feb  9 16:19:41 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 9 Feb 2006 16:19:41 +0100
Subject: [R] lme syntax for P&B examples
In-Reply-To: <F5ED48890E2ACB468D0F3A64989D335A01ADED95@dc1ex3.air.org>
References: <F5ED48890E2ACB468D0F3A64989D335A01ADED95@dc1ex3.air.org>
Message-ID: <17387.23949.430567.957934@stat.math.ethz.ch>

>>>>> "HaroldD" == Doran, Harold <HDoran at air.org>
>>>>>     on Wed, 8 Feb 2006 08:01:03 -0500 writes:

    HaroldD> ................

    HaroldD> A few thoughts, first, use lmer in the Matrix
    HaroldD> package and not in lme4. 

Well, that's potentially misleading advice:  If both lme4 and
Matrix are (more or less) current, it is actually better to call
library(lme4) if you want to use  lmer() .

A more extensive advice + explanation :

  - "lme4" is the package you should use when using lmer().
    Using "Matrix" *instead* works as well *currently*
    (and yes, *currently* lmer is in the Matrix namespace).

  - At the moment, "lme4" is an almost empty wrapper around using
    package "Matrix", since the C code for lmer() needs to be
    able to call C code inside "Matrix" and that is not yet
    portably possible.
    For that reason, everything for lmer() is currently inside
    "Matrix", but that should change when R will have the
    infrastructure for R packages to export their C API such that
    other R packages can reliably use that C API.


    HaroldD> ................

    HaroldD> Last, a colleague and I have a paper in press
    HaroldD> showing how to fit models using lme which we
    HaroldD> submitted a year or so ago.

    HaroldD> Since lme has evolved to lmer, we created an
    HaroldD> appendix that translates all of our lme models to
    HaroldD> the lmer syntax so readers can see equivalences. I
    HaroldD> am happy to send this to you (or others) upon request.

That sounds quite interesting; I'll be glad to receive it as
well.

Martin Maechler, ETH Zurich


    HaroldD> http://cran.r-project.org/doc/Rnews/Rnews_2005-1.pdf

    HaroldD> Harold



From Rau at demogr.mpg.de  Thu Feb  9 16:26:30 2006
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Thu, 9 Feb 2006 16:26:30 +0100
Subject: [R] Tranferring R results to word prosessors
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E6013DAF9B@HERMES.demogr.mpg.de>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Romain Francois
> Sent: Thursday, February 09, 2006 3:54 PM
> To: Tom Backer Johnsen
> 
> One way could be to output in html format from R (with the R2HTML 
> package) and then read back the html from your word processor
> 
> Romain

If you go along the HTML path, the package xtable might be also your
friend:

library(xtable)
mymat <- matrix(1:9, ncol=3)
print.xtable(xtable(mymat), type="HTML")


Hope this is useful for you,
Roland

+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From rimbak at yahoo.fr  Thu Feb  9 16:28:42 2006
From: rimbak at yahoo.fr (Karim Bakir)
Date: Thu, 9 Feb 2006 16:28:42 +0100
Subject: [R] (no subject)
Message-ID: <008901c62d8d$826566c0$02654252@k9ce1ea559da84>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060209/d200d280/attachment.pl

From tvanengeland at yahoo.co.uk  Thu Feb  9 16:30:59 2006
From: tvanengeland at yahoo.co.uk (Tom Van Engeland)
Date: Thu, 9 Feb 2006 15:30:59 +0000 (GMT)
Subject: [R] quote problem
Message-ID: <20060209153059.28450.qmail@web27015.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060209/1cbbb64c/attachment.pl

From ramasamy at cancer.org.uk  Thu Feb  9 16:34:33 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 09 Feb 2006 15:34:33 +0000
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <971536df0602090647x3ce913bajaa4e09c1c930ead3@mail.gmail.com>
References: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
	<971536df0602090647x3ce913bajaa4e09c1c930ead3@mail.gmail.com>
Message-ID: <1139499274.3229.44.camel@dhcp-82.wolf.ox.ac.uk>

I agree that this is the best way. 

I often use Courier font with font size 10 that gives very good results.


On Thu, 2006-02-09 at 09:47 -0500, Gabor Grothendieck wrote:
> In Word use a fixed font such as Courier rather than a proportional
> font and it will look ok.
> 
> On 2/9/06, Tom Backer Johnsen <backer at psych.uib.no> wrote:
> > I have just started looking at R, and are getting more and more irritated
> > at myself for not having done that before.
> >
> > However, one of the things I have not found in the documentation is some
> > way of preparing output from R for convenient formatting into something
> > like MS Word.  An example:  If you use summary(lm(....)) you get nice
> > output.  However, if you try to paste that output into the word processor,
> > all the text elements are separated by blanks, and that is not optimal for
> > the creation of a table (in the word processing sense).
> >
> > Is there an option to generate tab-separated output in R ? That would solve
> > the problem.
> >
> > Tom
> >
> > +----------------------------------------------------------------+
> > | Tom Backer Johnsen, Psychometrics Unit,  Faculty of Psychology |
> > | University of Bergen, Christies gt. 12, N-5015 Bergen,  NORWAY |
> > | Tel : +47-5558-9185                        Fax : +47-5558-9879 |
> > | Email : backer at psych.uib.no    URL : http://www.galton.uib.no/ |
> > +----------------------------------------------------------------+
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From phgrosjean at sciviews.org  Thu Feb  9 16:32:48 2006
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Thu, 09 Feb 2006 16:32:48 +0100
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <43EB57A3.8080106@free.fr>
References: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
	<43EB57A3.8080106@free.fr>
Message-ID: <43EB60A0.6050109@sciviews.org>

I have added several convenient methods for sending data directly from R 
to Microsoft Word (report() function) in the svViews package (SciViews 
bundle). However, I still have to upload it to CRAN. I do it right now. 
It should be available in a couple of days.
Best,

Philippe Grosjean

Romain Francois wrote:
> Le 09.02.2006 15:41, Tom Backer Johnsen a ??crit :
> 
> 
>>I have just started looking at R, and are getting more and more irritated 
>>at myself for not having done that before.
>>
>>However, one of the things I have not found in the documentation is some 
>>way of preparing output from R for convenient formatting into something 
>>like MS Word.  An example:  If you use summary(lm(....)) you get nice 
>>output.  However, if you try to paste that output into the word processor, 
>>all the text elements are separated by blanks, and that is not optimal for 
>>the creation of a table (in the word processing sense).
>>
>>Is there an option to generate tab-separated output in R ? That would solve 
>>the problem.
>>
>>Tom
>> 
>>
> 
> Hi ,
> 
> One way could be to output in html format from R (with the R2HTML 
> package) and then read back the html from your word processor
> 
> Romain
>



From itsme_410 at yahoo.com  Wed Feb  8 16:31:08 2006
From: itsme_410 at yahoo.com (Globe Trotter)
Date: Wed, 8 Feb 2006 07:31:08 -0800 (PST)
Subject: [R] callling R from C
Message-ID: <20060208153108.4121.qmail@web54501.mail.yahoo.com>

Can anyone please provide me with a simple example on calling R from C? 

Many thanks and best wishes!
GT



From pinard at iro.umontreal.ca  Tue Feb  7 14:43:28 2006
From: pinard at iro.umontreal.ca (=?iso-8859-1?Q?Fran=E7ois?= Pinard)
Date: Tue, 7 Feb 2006 08:43:28 -0500
Subject: [R] prehistoric versions of R --> 1995!
In-Reply-To: <17384.32124.247311.749610@stat.math.ethz.ch>
References: <C00D2113.5401%sdavis2@mail.nih.gov>
	<43E85438.7457.4BBCAC@localhost>
	<43E8529A.9040609@statistik.uni-dortmund.de>
	<17384.32124.247311.749610@stat.math.ethz.ch>
Message-ID: <20060207134328.GB7132@phenix.sram.qc.ca>

[Martin Maechler]

>2) The oldest stuff that I have is all from 1995;

Mailing lists seem to go back into 1995 too.  I found a few messages 
from around 1994 on topics to be later found within R, but I'm not sure 
where I got these old messages from.  I did find a message really 
related to R-pre-alpha, which itself quotes a message written in 1994.

-- 
Fran??ois Pinard   http://pinard.progiciels-bpi.ca



From anil_rohilla at rediffmail.com  Wed Feb  8 07:18:01 2006
From: anil_rohilla at rediffmail.com (anil kumar rohilla)
Date: 8 Feb 2006 06:18:01 -0000
Subject: [R] Baysian model averaging method
Message-ID: <20060208061801.13380.qmail@webmail36.rediffmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060208/28c2fa3d/attachment.pl

From maechler at stat.math.ethz.ch  Thu Feb  9 16:47:39 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 9 Feb 2006 16:47:39 +0100
Subject: [R] font size/disappearing labels
In-Reply-To: <ypx6bqxgpshm.fsf@uracil.uio.no>
References: <ypx6bqxgpshm.fsf@uracil.uio.no>
Message-ID: <17387.25627.16969.238216@stat.math.ethz.ch>

>>>>> "Karin" == Karin Lagesen <karin.lagesen at medisin.uio.no>
>>>>>     on Thu, 09 Feb 2006 14:32:53 +0100 writes:

    Karin> I am sorry if you get this email twice, but it did not show up in the
    Karin> digest nor on the web archive, so I am taking the chance of resending
    Karin> it.

But it's definitely there in both the digest and the web archive;
here the archive entry:
https://stat.ethz.ch/pipermail/r-help/2006-February/086365.html

I rather think nobody felt compelled to answer you,
because you didn't follow the posting guide (see link at end of
*every* R-help mesage) well (look for "reproducible" in the guide!).

Regards,
Martin Maechler, ETH Zurich



From B.Rowlingson at lancaster.ac.uk  Thu Feb  9 16:53:18 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 09 Feb 2006 15:53:18 +0000
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
References: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
Message-ID: <43EB656E.10809@lancaster.ac.uk>

Tom Backer Johnsen wrote:
> I have just started looking at R, and are getting more and more irritated 
> at myself for not having done that before.
> 
> However, one of the things I have not found in the documentation is some 
> way of preparing output from R for convenient formatting into something 
> like MS Word.  

  Well whatever you do, don't start looking at LaTeX, because that will 
get you even more irritated at yourself for not having done it before.

  LaTeX is to Word as R is to what? SPSS?

  I've still not seen a pretty piece of mathematics - or even text - in 
Word.

Barry



From keele.4 at polisci.osu.edu  Thu Feb  9 16:53:39 2006
From: keele.4 at polisci.osu.edu (Luke Keele)
Date: Thu, 09 Feb 2006 10:53:39 -0500
Subject: [R] Point Size in plot.cox.zph
Message-ID: <43EB6583.6010106@polisci.osu.edu>


I would like control over the point size (and the type of points) when
plotting a cox.zph object, but it returns the same error as when one
tries to change the y-axis.  I have searched the web for an answer (and
the r-help list) but to no avail.  What I have done is make a blank plot
and use the points command as follows:

plot(time, war.zph$y[,7], type="n")
points(war.zph[7],  ann=F, pch = ".")

But this causes you to lose the spline fit and seems rather cumbersome.
  A way to do this using the standard plot.cox.zph framework would be
very helpful.

Thanks

   Luke

-- 
Luke Keele
Assistant Professor
Dept. Of Political Science
Ohio State University



From vasu.akkineni at gmail.com  Thu Feb  9 17:03:55 2006
From: vasu.akkineni at gmail.com (Vasundhara Akkineni)
Date: Thu, 9 Feb 2006 11:03:55 -0500
Subject: [R] Color key in Heat map
Message-ID: <3b67376c0602090803s3bb99af2m6016f91e7c096544@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060209/44e5b1cf/attachment.pl

From adrian_d at eskimo.com  Thu Feb  9 17:11:52 2006
From: adrian_d at eskimo.com (Adrian Dragulescu)
Date: Thu, 9 Feb 2006 08:11:52 -0800 (PST)
Subject: [R] how to clear the last error?
Message-ID: <Pine.SUN.4.58.0602090809090.23510@eskimo.com>


Hello,

I would like to clear the last error that I get with geterrmessage().  Not
even rm(list=ls()) clears it.  Can I set it to NULL somehow?

Thank you,
Adrian



From finbref.2006 at gmail.com  Thu Feb  9 17:18:06 2006
From: finbref.2006 at gmail.com (Thomas Steiner)
Date: Thu, 9 Feb 2006 17:18:06 +0100
Subject: [R] putting text in the corner
Message-ID: <d0f55a670602090818j33e664d6l@mail.gmail.com>

I want to write some text in a corner of my plot.
Is it possible to get the xlim and ylim of an open window?
Or is there anything similar like
legend(x="bottomright", inset=0.01,legend=...)
for
text(x=1,y=2, "test")

Thomas



From tmlammail at yahoo.com  Thu Feb  9 17:18:50 2006
From: tmlammail at yahoo.com (Martin Lam)
Date: Thu, 9 Feb 2006 08:18:50 -0800 (PST)
Subject: [R]  How to calculate the generalization error of random forests?
Message-ID: <20060209161851.29698.qmail@web34710.mail.mud.yahoo.com>

Hi,

Perhaps this is not the proper place to ask this
question but I am out of options, therefore I
apologize in advance.

I want to know how the (upper bound?) generalization
error of the random forest is determined using the
out-of-bag estimate. I read in Breiman's paper that s
and p determine the generalization error:
p(1-s^2)/s^2.
Does s stands for the strength of the individual tree
or of the entire ensemble? p stands for the
correlation between the trees.

If I have, let's say, built 3 trees in my forest and I
know for each tree the instances that were left out
during training, how do I calculate s and p, so I can
calculate the error?

Thanks in advance,

Martin



From mschwartz at mn.rr.com  Thu Feb  9 17:22:23 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 09 Feb 2006 10:22:23 -0600
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <F5ED48890E2ACB468D0F3A64989D335A01ADEE82@dc1ex3.air.org>
References: <F5ED48890E2ACB468D0F3A64989D335A01ADEE82@dc1ex3.air.org>
Message-ID: <1139502143.4484.16.camel@localhost.localdomain>

In follow up to Harold's thought of using LaTeX, I have an approach when
the use of nicely formatted tables is required in a document where LaTeX
is not being used for the entire document. In other words, where you
need to use Word, OO.org's Writer or similar application for the
majority of the document body.

This involves outputting R results to LaTeX table code in a text file,
processing the file with 'latex' and 'dvips' and creating an EPS file.
Of course, the LaTeX text file is fully complete with preamble, etc.

One can then import the EPS file to a page in the document processor
file. The most recent versions of the aforementioned applications will
generate a bitmapped preview of the table content to aid in placement
and review.

You can then print the document to a PS printer or file for subsequent
use. OO.org's Writer can also use Ghostscript to print to a PDF file
using a "PDF Converter" in the printer selection dialog. This,
importantly, is different than the "Export to PDF" function. The latter
does not properly print embedded EPS images and prints the bitmapped
preview instead.

The advantage of this approach is that you don't have to mess around in
the word processing program doing a 'text to table' conversion and then
go through the formatting of the resultant columns, borders, etc.

HTH,

Marc Schwartz

On Thu, 2006-02-09 at 09:47 -0500, Doran, Harold wrote:
> Well, I don't know if it can be used with Word or not, but you might
> consider Sweave for use with LaTeX. Maybe if you use the sink() command
> this might work, but I haven't tried it. 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tom Backer
> Johnsen
> Sent: Thursday, February 09, 2006 9:41 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Tranferring R results to word prosessors
> 
> I have just started looking at R, and are getting more and more
> irritated at myself for not having done that before.
> 
> However, one of the things I have not found in the documentation is some
> way of preparing output from R for convenient formatting into something
> like MS Word.  An example:  If you use summary(lm(....)) you get nice
> output.  However, if you try to paste that output into the word
> processor, all the text elements are separated by blanks, and that is
> not optimal for the creation of a table (in the word processing sense).
> 
> Is there an option to generate tab-separated output in R ? That would
> solve the problem.
> 
> Tom



From maechler at stat.math.ethz.ch  Thu Feb  9 17:43:46 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 9 Feb 2006 17:43:46 +0100
Subject: [R] prehistoric versions of R --> 1995!
In-Reply-To: <20060207134328.GB7132@phenix.sram.qc.ca>
References: <C00D2113.5401%sdavis2@mail.nih.gov>
	<43E85438.7457.4BBCAC@localhost>
	<43E8529A.9040609@statistik.uni-dortmund.de>
	<17384.32124.247311.749610@stat.math.ethz.ch>
	<20060207134328.GB7132@phenix.sram.qc.ca>
Message-ID: <17387.28994.18006.683206@stat.math.ethz.ch>

>>>>> "FrPi" == Fran??ois Pinard <pinard at iro.umontreal.ca>
>>>>>     on Tue, 7 Feb 2006 08:43:28 -0500 writes:

    FrPi> [Martin Maechler]
    >> 2) The oldest stuff that I have is all from 1995;

    FrPi> Mailing lists seem to go back into 1995 too.  I found a few messages 
    FrPi> from around 1994 on topics to be later found within R, but I'm not sure 
    FrPi> where I got these old messages from.  I did find a message really 
    FrPi> related to R-pre-alpha, which itself quotes a message written in 1994.

Hmm, I am interested to find these.

I am pretty sure the first "R list" was the one Ross and Robert
initiated with the following e-mail (the date of which also
points to that 10th anniversary date coming Sunday!):

  >> From: R Home <r at stat.auckland.ac.nz>
  >> To: r-alpha-testers at stat.auckland.ac.nz
  >> Subject: R Code Alpha Test
  >> Date: Mon, 12 Feb 1996 16:15:53 +1300
  >> 
  >> At some point in the past you have provided comments on R which
  >> indicated that you would make a useful alpha-tester for the version
  >> we plan to release to statlib.
  >> 
  >> We have put your name on a mailing list
  >> 
  >>    r-alpha-testers at stat.auckland.ac.nz
  >> 
  >> which we will use for discussion of problems and for distributing
  >> bug-fixes and patches.  We intend that that the list will only
  >> function for a short testing period.  Assuming that the testing
  >> isn't too much of a disaster, we will set up a real discussion
  >> mailing list.
  >> 
  >> If you don't wish to take part in the testing cycle and would like to
  >> be taken off the list please send some mail to "r at stat.auckland.ac.nz".
  >> If you have suggestions for other who could take part in testing let
  >> us know too.
  >> 
  >> There are a number of types of input we are interested in.
  >> 
  >>    1) PORTABILITY
  >>    We are interested in seeing R ported to as many Unix
  >>    platforms as possible.  We are interested in hearing about
  >>    portability and any fixes neccessary to get R running on
  >>    platforms other than those we have available  (SunOS,
  >>    Solaris, FreeBSD, Linux, HP, SGI Irix).
  >> 
  >>    2) DIFFERENCES
  >>    We would like feedback on differences between R and S.  We
  >>    have made the decision to make R as compatible with S as
  >>    possible, but have not had the chance to systematically
  >>    look for differences.
  >> 
  >>    3) BUGS
  >>    We want to know about the bugs which are present in R.
  >> 
  >>    4) EXTENSIONS
  >>    What should we do next?
  >> 
  >> The source code is now available by anonymous ftp from
  >> 
  >>    stat3.stat.auckland.ac.nz
  >> 
  >> (note that this is not the usual place).
  >> 
  >>    Ross Ihaka + Robert Gentleman
  >>

BTW, note the many (Unixy) platforms mentioned on which R was
running even then.

Definitely older than the above are private e-mails between
Ross, Robert and various people, but these were private.

An interesting one would be the first announcement of R on the
S-news mailing list which I think *was* in 1994 (as you indicate
above). Unfortunately the archives of S-news currently only go
back to 1998.

Also, further, to what I said previously on this thread,
I have a nice paperback book "Data Analysis - An Introduction
base on R" written by Alan Lee, Dept. Statistics, Auckland
labeled as "Course Notes of University of Auckland Papers 528.218/288"
(a kind of lecture notes) which I received as gift from Ross and
Robert at the Heidelberg workshop, March 25, 1995.
The book has a Copyright ?? 1994.  
That seems high evidence for R to have been in use at U. of
Auckland in 1994.

Now if we heard even more "history of R"  (with dates!)
from Ross / Robert / Alan Lee ?

Regards, 
Martin Maechler, ETH Zurich



From leog at anicca-vijja.de  Thu Feb  9 17:45:22 2006
From: leog at anicca-vijja.de (=?ISO-8859-15?Q?Leo_G=FCrtler?=)
Date: Thu, 09 Feb 2006 17:45:22 +0100
Subject: [R] effect sizes in lme/ multi-level models
Message-ID: <43EB71A2.2030308@anicca-vijja.de>

Dear alltogether,

I am searching for a way to determine "effect size" in multi-level 
models by using lme().
Coming from Psychology, for ordinary OLS there are measures (for 
meta-analysis, etc.) like

CohensD <- (mean_EG - mean_CG) / SD_pooled

or

(p)eta^2 <- SS_effect / (SS_effect + SS_error)

I do not intend to lead a discussion of the usefulness of such measures 
as long as the standards of psychological journals (e.g. as defined by 
the APA) order them.
However, I wondered how to determine measures of effect size in lme. 
Pinheiro&Bates (2000) do not touch that topic.
I assume that as long as a grouping structure is present, the formular 
of CohensD (see above) has to be corrected to give respect to the 
grouping structure. Is there any equivalent measure like eta^2, 
partial-eta^2, etc.?

Can anybody help me with formulas, R code or some references?

Thank you very much,

thanks in advance,

leo g??rtler

-- 

email: leog at anicca-vijja.de
www: http://www.anicca-vijja.de/



From tcodilean at geog.gla.ac.uk  Thu Feb  9 18:02:28 2006
From: tcodilean at geog.gla.ac.uk (Alexandru Codilean)
Date: Thu, 09 Feb 2006 17:02:28 +0000
Subject: [R] nice log-log plots
Message-ID: <1139504548.81bf18bctcodilean@geog.gla.ac.uk>

Dear All,

I am trying to produce log-log plots in R and I was wondering if any of you have a 'template' for generating these with 'nice' labels and log-log grids?

I know I can set up axes individually and use the intervals I want, however, I will be producing a large number of these plots and would not like to do this manually for each of them + I am very new to R and at the moment do not have much time that I could spend figuring this out by myself.....

Any help would be greatly appreciated!
Thanks
Tibi
____________________________________________________

Alexandru Tiberiu CODILEAN
PhD Candidate
Departmental IT Committee PG Rep.

Department of Geographical and Earth Sciences 
East Quadrangle, Room 309 
University Avenue 
University of Glasgow 
Glasgow G12 8QQ UK 

Tel: +44 (0) 141 330 4872 ext. 0935 
Fax: +44 (0) 141 330 4894
Email: tcodilean at ges.gla.ac.uk

Home: http://web.ges.gla.ac.uk/~tcodilean/
GRASS Mirror: http://pc188.geog.gla.ac.uk/grass/

A gleekzorp without a tornpee is like a quop without a fertsneet (sort of)



From spencer.graves at pdf.com  Thu Feb  9 18:14:21 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 09 Feb 2006 09:14:21 -0800
Subject: [R] Fixing AR coefficients in VAR model
In-Reply-To: <550c175b0602051959m6b5e3496m48f5346326c31e07@mail.gmail.com>
References: <550c175b0602051959m6b5e3496m48f5346326c31e07@mail.gmail.com>
Message-ID: <43EB786D.3040806@pdf.com>

	  I know of no existing functions in R that support fitting a 
multivariate autoregression while fixing some of the parameters.

	  Of course, as Simon Blomberg famously said in April 2005, "This is R. 
There is no if. Only how."  [With library(fortunes), try 'fortune("This 
is R")'.]  If I had to do fit a multivariate AR today with some 
parameters fixed, I might write a function to compute the determinant of 
the sample covariance matrix, and give it to "optim" or "nlminb".

	  I hope someone else will provide us with an easier way.

	  hope this helps,
	  spencer graves

Daniel Medina wrote:

> Dear Colleague,
> 
> I would like to set a few AR coefficients (not order) to zero in the
> multivariate AR function (mAr.est; mAr library); however, the manual for
> this function does not provide this information. I would appreciate any
> suggestions along this line.
> 
> Thankfully yours,
> 
> Daniel C Medina
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From roger.bos at gmail.com  Thu Feb  9 18:33:38 2006
From: roger.bos at gmail.com (roger bos)
Date: Thu, 9 Feb 2006 12:33:38 -0500
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <43EB656E.10809@lancaster.ac.uk>
References: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
	<43EB656E.10809@lancaster.ac.uk>
Message-ID: <1db726800602090933m1e08922bj6b2a56344b80da47@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060209/2fd37dba/attachment.pl

From gerifalte28 at hotmail.com  Thu Feb  9 18:38:38 2006
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Thu, 09 Feb 2006 17:38:38 +0000
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
Message-ID: <BAY103-F330992B553E4195C83B95A6030@phx.gbl>

Take a look at the facilities to write HTML output in library(R2HTML).  If 
you write an HTML file, you can then easily copy and paste it into your Word 
document, or from MS Word you can use the Insert menu. i.e.

library(R2HTML)
x=ftable(Titanic, row.vars = 1:3)
HTML(x,"Titanic.html")

Then from MS Word use Insert-> File and select Titanic.html and see the 
results.

I hope this helps

Francisco



>From: Tom Backer Johnsen <backer at psych.uib.no>
>To: r-help at stat.math.ethz.ch
>Subject: [R] Tranferring R results to word prosessors
>Date: Thu, 09 Feb 2006 15:41:09 +0100
>
>I have just started looking at R, and are getting more and more irritated
>at myself for not having done that before.
>
>However, one of the things I have not found in the documentation is some
>way of preparing output from R for convenient formatting into something
>like MS Word.  An example:  If you use summary(lm(....)) you get nice
>output.  However, if you try to paste that output into the word processor,
>all the text elements are separated by blanks, and that is not optimal for
>the creation of a table (in the word processing sense).
>
>Is there an option to generate tab-separated output in R ? That would solve
>the problem.
>
>Tom
>
>+----------------------------------------------------------------+
>| Tom Backer Johnsen, Psychometrics Unit,  Faculty of Psychology |
>| University of Bergen, Christies gt. 12, N-5015 Bergen,  NORWAY |
>| Tel : +47-5558-9185                        Fax : +47-5558-9879 |
>| Email : backer at psych.uib.no    URL : http://www.galton.uib.no/ |
>+----------------------------------------------------------------+
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From mschwartz at mn.rr.com  Thu Feb  9 18:41:04 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 09 Feb 2006 11:41:04 -0600
Subject: [R] putting text in the corner
In-Reply-To: <d0f55a670602090818j33e664d6l@mail.gmail.com>
References: <d0f55a670602090818j33e664d6l@mail.gmail.com>
Message-ID: <1139506864.4484.33.camel@localhost.localdomain>

On Thu, 2006-02-09 at 17:18 +0100, Thomas Steiner wrote:
> I want to write some text in a corner of my plot.
> Is it possible to get the xlim and ylim of an open window?
> Or is there anything similar like
> legend(x="bottomright", inset=0.01,legend=...)
> for
> text(x=1,y=2, "test")
> 
> Thomas


Try this:

 plot(1:10)

 # par("usr") defines the x/y coordinates of the plot region
 usr <- par("usr")

 # Upper Left Hand Corner
 text(usr[1], usr[4], "test", adj = c(0, 1))

 # Lower Left Hand Corner
 text(usr[1], usr[3], "test", adj = c(0, 0))

 # Lower Right Hand Corner
 text(usr[2], usr[3], "test", adj = c(1, 0))

 # Upper Right Hand Corner
 text(usr[2], usr[4], "test", adj = c(1, 1))



See ?par and ?text for more information including the 'adj' argument to
text().

HTH,

Marc Schwartz



From cadet at giant.ams.sunysb.edu  Thu Feb  9 18:44:02 2006
From: cadet at giant.ams.sunysb.edu (J Cad)
Date: Thu, 9 Feb 2006 12:44:02 -0500 (EST)
Subject: [R] make: Target `all' not remade because of errors.
Message-ID: <Pine.LNX.4.44.0602091242160.27900-100000@giant.ams.sunysb.edu>


Hi:   I don't know if it is a bug or what?
	I followed instructions.  
Jean

R version: R-2.2.1
OS:   Linux RedHat 9




I followed the instructions. tar -xvf, configure, then make.
I get these error messages at the end of make and with make check.  
==================================================================
==================================================================
In file included from rbitmap.c:45:
/usr/include/png.h:318:18: zlib.h: No such file or directory
In file included from /usr/include/png.h:321,
                 from rbitmap.c:45:
/usr/include/pngconf.h:1091: error: parse error before '*' token
/usr/include/pngconf.h:1092: error: parse error before '*' token
/usr/include/pngconf.h:1093: error: parse error before '*' token
In file included from rbitmap.c:45:
/usr/include/png.h:1034: error: parse error before "z_stream"
/usr/include/png.h:1262: error: parse error before '}' token
/usr/include/png.h:1821: error: parse error before "png_zalloc"
/usr/include/png.h:1821: error: parse error before "png_ptr"
/usr/include/png.h:1825: error: parse error before "png_ptr"
rbitmap.c: In function `my_png_error':
rbitmap.c:72: error: dereferencing pointer to incomplete type
rbitmap.c: In function `R_SaveAsPng':
rbitmap.c:121: error: dereferencing pointer to incomplete type
make[4]: *** [rbitmap.lo] Error 1
make[4]: Target `R_X11.so' not remade because of errors.
make[4]: Leaving directory `/users/cadet/R-2.2.1/src/modules/X11'
make[3]: *** [R] Error 2
make[3]: Leaving directory `/users/cadet/R-2.2.1/src/modules/X11'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/users/cadet/R-2.2.1/src/modules'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/users/cadet/R-2.2.1/src'
make: *** [R] Error 1
make: Target `all' not remade because of errors.
giant {122} make check
make[1]: Entering directory `/users/cadet/R-2.2.1/tests'
make[2]: Entering directory `/users/cadet/R-2.2.1/tests'
make[3]: Entering directory `/users/cadet/R-2.2.1/tests/Examples'
make[4]: Entering directory `/users/cadet/R-2.2.1/tests/Examples'
make[4]: `Makedeps' is up to date.
make[4]: Leaving directory `/users/cadet/R-2.2.1/tests/Examples'
make[4]: Entering directory `/users/cadet/R-2.2.1/tests/Examples'
make[4]: *** No rule to make target `../../src/library/base/all.R', needed 
by `base-Ex.Rout'.  Stop.
make[4]: Leaving directory `/users/cadet/R-2.2.1/tests/Examples'
make[3]: *** [test-Examples-Base] Error 2
make[3]: Leaving directory `/users/cadet/R-2.2.1/tests/Examples'
make[2]: *** [test-Examples] Error 2
make[2]: Leaving directory `/users/cadet/R-2.2.1/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/users/cadet/R-2.2.1/tests'
make: *** [check] Error 2
============================================================
============================================================



--



From bagchi.r at gmail.com  Thu Feb  9 18:46:39 2006
From: bagchi.r at gmail.com (Robert Bagchi)
Date: Thu, 09 Feb 2006 17:46:39 +0000
Subject: [R] glmm.admb -  bug and possible solution??
Message-ID: <43EB7FFF.2080208@shef.ac.uk>

Dear Dr Skaug  and R users,

just discovered glmm.admb in R, and it seems a very useful tool. 
However, I ran into a problem when I compare two models:

m1<-glmm.admb(survival~light*species*damage, random=~1, group="table", 
data=bm, family="binomial", link="logit")

m1.1<-glmm.admb(survival~(light+species+damage)^2, random=~1, 
group="table", data=bm, family="binomial", link="logit")

anova(m1, m1.1)

I get the following output with the warning

Analysis of Variance Table

Model 1: survival ~ light * species * damage
Model 2: survival ~ (light + damage + species)^2
NoPar LogLik Df -2logQ P.value
1 9.000 -103.307
2 9.000 -103.781 0 -0.948
Warning message:
NaNs produced in: pchisq(q, df, lower.tail, log.p)

The warning is generated because the df=0. This appears to be because 
the number of parameters is being incorrectly calculated (they should be 
9 and 8 respectively). I had a look at the function call in R, and the 
problem appears to be because npar is obtained from the file nbmm.par on 
line 140 of the function

out$npar <- as.numeric(scan("nbmm.par", what = "", quiet = TRUE)[6])

which doesn't appear to change between calculations (the file seems to 
hvae been created the first time I ran glmm.admb, and not to have been 
modified since).

Replacing this line with the following
out$npar<-p+m
seemed to work ok. Is this a legitimate solution?

I noticed that this isn't necessary for when I run the example for 
anova.glmm.admb (although this uses a different family). This seems to 
overwrite the nbmm.par file. Couldn't work out where this happens 
though, and take it that this occurs during the call to the ADMB 
program.  Any thoughts?

Many thanks
Robert

Below is the version information for R

platform i386-pc-mingw32
arch i386
os mingw32
system i386, mingw32
status
major 2
minor 2.0
year 2005
month 10
day 06
svn rev 35749
language R


ADMB version
Package: glmmADMB
Version: 0.2
License: GPL
Packaged: Thu Dec 1 07:02:40 2005; andersn
Built: R 2.2.0; ; 2005-12-01 07:13:48; unix

-- 
Robert Bagchi
Animal & Plant Science
Alfred Denny Building
University of Sheffield
Western Bank
Sheffield S10 2TN
UK

t: +44 (0)114 2220062
e: r.bagchi at sheffield.ac.uk
   bagchi.r at gmail.com

http://www.shef.ac.uk/aps/apsrtp/bagchi-r



From fernandomayer at gmail.com  Thu Feb  9 18:46:58 2006
From: fernandomayer at gmail.com (Fernando Mayer)
Date: Thu, 09 Feb 2006 15:46:58 -0200
Subject: [R] putting text in the corner
In-Reply-To: <d0f55a670602090818j33e664d6l@mail.gmail.com>
References: <d0f55a670602090818j33e664d6l@mail.gmail.com>
Message-ID: <43EB8012.9050504@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060209/adce6a34/attachment.pl

From f.harrell at vanderbilt.edu  Thu Feb  9 18:56:52 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 09 Feb 2006 11:56:52 -0600
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <1139502143.4484.16.camel@localhost.localdomain>
References: <F5ED48890E2ACB468D0F3A64989D335A01ADEE82@dc1ex3.air.org>
	<1139502143.4484.16.camel@localhost.localdomain>
Message-ID: <43EB8264.3@vanderbilt.edu>

Marc Schwartz (via MN) wrote:
> In follow up to Harold's thought of using LaTeX, I have an approach when
> the use of nicely formatted tables is required in a document where LaTeX
> is not being used for the entire document. In other words, where you
> need to use Word, OO.org's Writer or similar application for the
> majority of the document body.
> 
> This involves outputting R results to LaTeX table code in a text file,
> processing the file with 'latex' and 'dvips' and creating an EPS file.
> Of course, the LaTeX text file is fully complete with preamble, etc.
> 
> One can then import the EPS file to a page in the document processor
> file. The most recent versions of the aforementioned applications will
> generate a bitmapped preview of the table content to aid in placement
> and review.
> 
> You can then print the document to a PS printer or file for subsequent
> use. OO.org's Writer can also use Ghostscript to print to a PDF file
> using a "PDF Converter" in the printer selection dialog. This,
> importantly, is different than the "Export to PDF" function. The latter
> does not properly print embedded EPS images and prints the bitmapped
> preview instead.
> 
> The advantage of this approach is that you don't have to mess around in
> the word processing program doing a 'text to table' conversion and then
> go through the formatting of the resultant columns, borders, etc.
> 
> HTH,
> 
> Marc Schwartz

In addition to Marc's nice idea, I have had luck with Linux programs 
latex2rtf (.tex to .rtf) and hevea (.tex to .html).  Most often I use 
hevea and let Word users quickly convert from .html to .doc.  Of course 
doing everything in LaTeX is far better, using either Sweave or 
http://biostat.mc.vanderbilt.edu/StatReport .  Personal productivity 
with LaTeX is amazingly greater than with Word.

Frank

> 
> On Thu, 2006-02-09 at 09:47 -0500, Doran, Harold wrote:
> 
>>Well, I don't know if it can be used with Word or not, but you might
>>consider Sweave for use with LaTeX. Maybe if you use the sink() command
>>this might work, but I haven't tried it. 
>>
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tom Backer
>>Johnsen
>>Sent: Thursday, February 09, 2006 9:41 AM
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] Tranferring R results to word prosessors
>>
>>I have just started looking at R, and are getting more and more
>>irritated at myself for not having done that before.
>>
>>However, one of the things I have not found in the documentation is some
>>way of preparing output from R for convenient formatting into something
>>like MS Word.  An example:  If you use summary(lm(....)) you get nice
>>output.  However, if you try to paste that output into the word
>>processor, all the text elements are separated by blanks, and that is
>>not optimal for the creation of a table (in the word processing sense).
>>
>>Is there an option to generate tab-separated output in R ? That would
>>solve the problem.
>>
>>Tom
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From gunter.berton at gene.com  Thu Feb  9 19:00:07 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 9 Feb 2006 10:00:07 -0800
Subject: [R] "main" parameter in plot.default vs plot.formula
Message-ID: <200602091800.k19I0725018811@meitner.gene.com>


Folks:

R 2.2.0 on Windows.

I find the following somewhat puzzling:

> a<-1; x<-0:1; y<-x

## following works fine:
> plot(x,y ,main= bquote(n[1] == .(a) ))

## following produces an error:
> plot(y~x ,main= bquote(n[1] == .(a) ))
Error in paste(n[1] == 1, " and ", n[2] == 2) : object "n" not found

*******************************

Note 1: I assume that this is due to the following documented behavior of
plot.formula():

"Both the terms in the formula and the ... arguments are evaluated in data
enclosed in parent.frame() if data is a list or a data frame."

Nevertheless, the behavior seems inconsistent to me. Am I missing something
(including the "I assume ..." comment)?

Note 2: If one uses substitute() instead, it works fine:

plot(y~x ,main= substitute(bquote(n[1] == a),list(a=a)))


Any illumination, public or private, would be appreciated.

Cheers,
Bert

 
-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box



From mnair at iusb.edu  Thu Feb  9 19:04:32 2006
From: mnair at iusb.edu (Nair, Murlidharan T)
Date: Thu, 9 Feb 2006 13:04:32 -0500
Subject: [R] minimum adequate model using contrasts
Message-ID: <9B1DF4652801764B909C4ADCA6523A2453B8F1@iu-mssg-mbx09.exchange.iu.edu>

I am trying to model a set of data that I am working on using contrasts.
Since the data set is too large, I am interested in scripting the entire
process to arrive at the minimum adequate model. Has anyone in the group
done this before? If you I would appreciate their comments. 
Cheers ../Murli



From murdoch at stats.uwo.ca  Thu Feb  9 19:04:50 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 09 Feb 2006 13:04:50 -0500
Subject: [R] how to clear the last error?
In-Reply-To: <Pine.SUN.4.58.0602090809090.23510@eskimo.com>
References: <Pine.SUN.4.58.0602090809090.23510@eskimo.com>
Message-ID: <43EB8442.1080600@stats.uwo.ca>

On 2/9/2006 11:11 AM, Adrian Dragulescu wrote:
> Hello,
> 
> I would like to clear the last error that I get with geterrmessage().  Not
> even rm(list=ls()) clears it.  Can I set it to NULL somehow?

Not from R, but there is a C-level way to do it in src/main/errors.c. 
It's marked as "temporary", but it's been there since R 1.3.x.

The declaration is

void R_SetErrmessage(char *s);

Alternatively, you could just cover up the last error with a new one by 
calling stop, e.g.

 > try(stop(""),TRUE)
 > geterrmessage()
[1] "Error in try(stop(\"\"), TRUE) : \n"

Duncan Murdoch



From murdoch at stats.uwo.ca  Thu Feb  9 19:05:37 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 09 Feb 2006 13:05:37 -0500
Subject: [R] putting text in the corner
In-Reply-To: <d0f55a670602090818j33e664d6l@mail.gmail.com>
References: <d0f55a670602090818j33e664d6l@mail.gmail.com>
Message-ID: <43EB8471.9050402@stats.uwo.ca>

On 2/9/2006 11:18 AM, Thomas Steiner wrote:
> I want to write some text in a corner of my plot.
> Is it possible to get the xlim and ylim of an open window?
> Or is there anything similar like
> legend(x="bottomright", inset=0.01,legend=...)
> for
> text(x=1,y=2, "test")

par("usr")

gives you the limits.

Duncan Murdoch



From ripley at stats.ox.ac.uk  Thu Feb  9 19:12:14 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 9 Feb 2006 18:12:14 +0000 (GMT)
Subject: [R] putting text in the corner
In-Reply-To: <d0f55a670602090818j33e664d6l@mail.gmail.com>
References: <d0f55a670602090818j33e664d6l@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602091809470.30598@gannet.stats.ox.ac.uk>

?par, look at "usr"  (which is how legend does it)

On Thu, 9 Feb 2006, Thomas Steiner wrote:

> I want to write some text in a corner of my plot.
> Is it possible to get the xlim and ylim of an open window?
> Or is there anything similar like
> legend(x="bottomright", inset=0.01,legend=...)
> for
> text(x=1,y=2, "test")

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mnair at iusb.edu  Thu Feb  9 19:34:40 2006
From: mnair at iusb.edu (Nair, Murlidharan T)
Date: Thu, 9 Feb 2006 13:34:40 -0500
Subject: [R] minimal adequate model
Message-ID: <9B1DF4652801764B909C4ADCA6523A2453B8FE@iu-mssg-mbx09.exchange.iu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060209/60d68898/attachment.pl

From mschwartz at mn.rr.com  Thu Feb  9 19:39:09 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 09 Feb 2006 12:39:09 -0600
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <1db726800602090933m1e08922bj6b2a56344b80da47@mail.gmail.com>
References: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
	<43EB656E.10809@lancaster.ac.uk>
	<1db726800602090933m1e08922bj6b2a56344b80da47@mail.gmail.com>
Message-ID: <1139510350.4484.42.camel@localhost.localdomain>

There is some documentation online at:

http://www.latex-project.org/guides/

which would be a good starting place.

If you prefer a good book, The LaTeX Companion (aka TLC) is the place to
begin:

http://www.amazon.com/gp/product/0201362996


There is also a boxed set (expensive) of several books (including TLC)
available:

http://www.amazon.com/gp/product/0321269446


Finally, for dealing with EPS (or PDF) graphics (ie. R plots), the
online document "Using Imported Graphics in LaTeX and pdfLaTeX" is
excellent:

http://www.ctan.org/tex-archive/info/epslatex.pdf


HTH,

Marc Schwartz

On Thu, 2006-02-09 at 12:33 -0500, roger bos wrote:
> Yeah, but I don't understand LaTeX at all.  Can you point me to a good
> beginners guide?
> 
> Thanks,
> 
> Roger
> 
> 
> On 2/9/06, Barry Rowlingson <B.Rowlingson at lancaster.ac.uk> wrote:
> >
> > Tom Backer Johnsen wrote:
> > > I have just started looking at R, and are getting more and more
> > irritated
> > > at myself for not having done that before.
> > >
> > > However, one of the things I have not found in the documentation is some
> > > way of preparing output from R for convenient formatting into something
> > > like MS Word.
> >
> > Well whatever you do, don't start looking at LaTeX, because that will
> > get you even more irritated at yourself for not having done it before.
> >
> > LaTeX is to Word as R is to what? SPSS?
> >
> > I've still not seen a pretty piece of mathematics - or even text - in
> > Word.
> >
> > Barry
> >



From tarmo.remmel at sympatico.ca  Thu Feb  9 19:41:45 2006
From: tarmo.remmel at sympatico.ca (Tarmo Remmel)
Date: Thu, 9 Feb 2006 13:41:45 -0500
Subject: [R] Shapefiles
Message-ID: <BAYC1-PASMTP02E44014CDFDBCC42ACE62E4030@CEZ.ICE>

Dear List,

I have examined the sp, maptools, and shapefiles packages (Windows) but
cannot seem to figure out a solution for writing shapefiles for 'curvy
shapes'.  The scenario is that I generate a series of polygons, circles, and
ellipses on a plot and would like to convert them to shapefiles.  Since the
circles and ellipses are do not return a coordinate list during the plotting
sequence (e.g., all I need supply are the lengths of axes and rotation
angle), is there an easy way by which the plot window can be converted to a
shapefile?

Thank you,

Tarmo

__________________________________________
Tarmo Remmel  Ph.D.
GUESS Lab, Department of Geography
University of Toronto at Mississauga
Mississauga, Ontario, L5L 1C6
Tel: 905-569-4382
Lab: 905-828-3868
Fax: 905-828-5273
Skype: tarmoremmel
http://eratos.erin.utoronto.ca/remmelt



From jan.danielsson at gmail.com  Thu Feb  9 20:02:33 2006
From: jan.danielsson at gmail.com (Jan Danielsson)
Date: Thu, 09 Feb 2006 20:02:33 +0100
Subject: [R] New user: Custom probability distribution
Message-ID: <43EB91C9.8060205@gmail.com>

Hello,

   Given a probability function: p(x) = 12 / (25(x+1)) , x=0, 1, 2, 3 we
generate the following values:

  C1  C2
  0   0.48
  1   0.24
  2   0.16
  3   0.12

   Now, I'm supposed to create 50 random values using this table. In
MiniTab, I simply selected Calc -> Random Data -> Discrete, and selected
the columns, and it created 50 random values in a new column.[1]

How do I do the same thing in R?

   [1] You may be wondering why I'm telling you this. Well, it's because
if I were in your shoes, I'd think "Oh, someone wants me to solve his
homework.". I have already solved it using MiniTab, but I want to be
able to use R instead (since I prefer NetBSD).

-- 
Kind Regards,
Jan Danielsson
Te audire non possum. Musa sapientum fixa est in aure.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 187 bytes
Desc: OpenPGP digital signature
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20060209/e59910e7/signature.bin

From secchi at sssup.it  Thu Feb  9 20:02:48 2006
From: secchi at sssup.it (Angelo Secchi)
Date: Thu, 9 Feb 2006 20:02:48 +0100
Subject: [R] New psi with rlm
Message-ID: <20060209200248.f0f29be6.secchi@sssup.it>


Hi,
How can I define a new psi function in the rlm comand?
In particular  I would like to implement the case for

\rho(u)=0.5*(u^2) and \psi(u)=u

in order to assume normally distributed errors.
Any help?
Thanks




-- 
========================================================
 Angelo Secchi                     PGP Key ID:EA280337



From pburns at pburns.seanet.com  Thu Feb  9 20:08:19 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu, 09 Feb 2006 19:08:19 +0000
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <1db726800602090933m1e08922bj6b2a56344b80da47@mail.gmail.com>
References: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>	<43EB656E.10809@lancaster.ac.uk>
	<1db726800602090933m1e08922bj6b2a56344b80da47@mail.gmail.com>
Message-ID: <43EB9323.8080000@pburns.seanet.com>

One approach is to use LyX (http://www.lyx.org/).
This is a lot like using Word or other word processors
but it creates LaTeX.  You probably won't need to
know anything about TeX for a long time unless you
are doing really weird things.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

roger bos wrote:

>Yeah, but I don't understand LaTeX at all.  Can you point me to a good
>beginners guide?
>
>Thanks,
>
>Roger
>
>
>On 2/9/06, Barry Rowlingson <B.Rowlingson at lancaster.ac.uk> wrote:
>  
>
>>Tom Backer Johnsen wrote:
>>    
>>
>>>I have just started looking at R, and are getting more and more
>>>      
>>>
>>irritated
>>    
>>
>>>at myself for not having done that before.
>>>
>>>However, one of the things I have not found in the documentation is some
>>>way of preparing output from R for convenient formatting into something
>>>like MS Word.
>>>      
>>>
>>Well whatever you do, don't start looking at LaTeX, because that will
>>get you even more irritated at yourself for not having done it before.
>>
>>LaTeX is to Word as R is to what? SPSS?
>>
>>I've still not seen a pretty piece of mathematics - or even text - in
>>Word.
>>
>>Barry
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
>>
>>    
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From Flom at ndri.org  Thu Feb  9 20:11:03 2006
From: Flom at ndri.org (Peter Flom)
Date: Thu, 09 Feb 2006 14:11:03 -0500
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <1db726800602090933m1e08922bj6b2a56344b80da47@mail.gmail.com>
References: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
	<43EB656E.10809@lancaster.ac.uk>
	<1db726800602090933m1e08922bj6b2a56344b80da47@mail.gmail.com>
Message-ID: <43EB4D75.B875.00C9.0@ndri.org>

>>> roger bos <roger.bos at gmail.com> 2/9/2006 12:33 pm >>> wrote
<<<
Yeah, but I don't understand LaTeX at all.  Can you point me to a good
beginners guide?
>>>

I like Math into LaTeX, by Gratzer.  
For a real beginners guide, there's one called first steps in LaTeX.
You might also want to look at issues of the PracTEX journal, many of which are for beginners (It's an online journal)

Peter

Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
http://cduhr.ndri.org
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)



From justin_bem at yahoo.fr  Thu Feb  9 20:17:14 2006
From: justin_bem at yahoo.fr (justin bem)
Date: Thu, 9 Feb 2006 20:17:14 +0100 (CET)
Subject: [R] iteration history
In-Reply-To: <000001c62b60$3ad3ed60$1191680a@robert>
Message-ID: <20060209191714.64170.qmail@web25701.mail.ukl.yahoo.com>

Hi Bob !

It possible See the first element of controle argument
set it to a positive integer ! 



--- Robert Mcfadden <robert-mcfadden at o2.pl> a ??crit??:

> Dear R Users
> I would like to use optim function to optimize a
> function. I read help but I
> couldn't find what I need: is it possible to get
> information after each
> iteration, for example as there is in MATLAB:
>                                                     
>    Gradient's 
>  Iteration  Func-count       f(x)        Step-size  
>    infinity-norm
>      0          24          388.976                 
>           14
>      1          72           385.67      0.0292637  
>         16.8  
>      2          96           383.54              1  
>         4.15  
>      3         120          383.412              1  
>        0.108  
>      4         144          383.412              1  
>        0.002  
>      5         168          383.412              1  
>      0.00149  
>      6         192          383.412              1  
>    6.23e-005  
>      7         216          383.412              1  
>    1.01e-005  
>    
> 
> It is useful when iteration takes long time - I know
> what's happen
> I would appreciate any suggestion
> 
> Robert
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From cbehr at edesigndynamics.com  Thu Feb  9 20:20:38 2006
From: cbehr at edesigndynamics.com (Chris Behr)
Date: Thu, 9 Feb 2006 14:20:38 -0500
Subject: [R] R2WinBUGS - formating data for winbugs
Message-ID: <EBECLABIMNBHDFCEHCFHMEEBCGAA.cbehr@edesigndynamics.com>

I am currently running analyses in winbugs with two different formats of
data: matrix and list. The data in the list have different dimensions than
the matrix. Do I need to create a single format for entry into R which R
passes to WinBUGS?

Thanks, Chris

Christopher Behr
Principal Analyst

eDesign Dynamics
www.edesigndynamics.com

4024 Calvert St. NW
Washington DC 20007
(202) 298-6437 (t/f)
(551) 998-4823 (c)



From justin_bem at yahoo.fr  Thu Feb  9 20:32:10 2006
From: justin_bem at yahoo.fr (justin bem)
Date: Thu, 9 Feb 2006 20:32:10 +0100 (CET)
Subject: [R] problem with simple if() statement
In-Reply-To: <43E7234E.6030804@sciviews.org>
Message-ID: <20060209193210.61932.qmail@web25709.mail.ukl.yahoo.com>

Hi Norman !
 
I observe that R syntax is very close to C/C++ or Java

--- Philippe Grosjean <phgrosjean at sciviews.org> a
??crit??:

> Norman Goodacre wrote:
> > the following code apprantely, for some grand old
> reason, induces a syntax error:
> >   
> >   if (seq[i] = "A") m <- trans[1,]
> >   
> >   where seq is a vector and trans is a matrix. I
> cannot for the life of me see why this is wrong.
> Syntax error is: 
> >   
> >   Error: syntax error in "if (seq[i] ="
> >   
> >   Sincerely,
> >   
> >   Norman Goodacre
> 
> Please, read "An Introduction to R" provided with
> any version of R. The 
> correct syntax for an equality condition is "==",
> not "=", so:
> 
>  > if (seq[i] == "A") ....
> 
> Best,
> 
> Philippe Grosjean
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From pgilbert at bank-banque-canada.ca  Thu Feb  9 20:41:19 2006
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Thu, 09 Feb 2006 14:41:19 -0500
Subject: [R] Fixing AR coefficients in VAR model
In-Reply-To: <43EB786D.3040806@pdf.com>
References: <550c175b0602051959m6b5e3496m48f5346326c31e07@mail.gmail.com>
	<43EB786D.3040806@pdf.com>
Message-ID: <43EB9ADF.2010309@bank-banque-canada.ca>

You can do this with dse. See

   require("dse1")
  ?fixConstants

Paul Gilbert

Spencer Graves wrote:

>	  I know of no existing functions in R that support fitting a 
>multivariate autoregression while fixing some of the parameters.
>
>	  Of course, as Simon Blomberg famously said in April 2005, "This is R. 
>There is no if. Only how."  [With library(fortunes), try 'fortune("This 
>is R")'.]  If I had to do fit a multivariate AR today with some 
>parameters fixed, I might write a function to compute the determinant of 
>the sample covariance matrix, and give it to "optim" or "nlminb".
>
>	  I hope someone else will provide us with an easier way.
>
>	  hope this helps,
>	  spencer graves
>
>Daniel Medina wrote:
>
>  
>
>>Dear Colleague,
>>
>>I would like to set a few AR coefficients (not order) to zero in the
>>multivariate AR function (mAr.est; mAr library); however, the manual for
>>this function does not provide this information. I would appreciate any
>>suggestions along this line.
>>
>>Thankfully yours,
>>
>>Daniel C Medina
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>
====================================================================================

La version fran??aise suit le texte anglais.

------------------------------------------------------------------------------------

This email message from the Bank of Canada is given in good faith, and shall not be
binding or construed as constituting any obligation on the part of the Bank.

This email may contain privileged and/or confidential inform...{{dropped}}



From srini_iyyer_bio at yahoo.com  Thu Feb  9 20:52:34 2006
From: srini_iyyer_bio at yahoo.com (Srinivas Iyyer)
Date: Thu, 9 Feb 2006 11:52:34 -0800 (PST)
Subject: [R] Plotting 27 line plots in one page
In-Reply-To: <43EBDE85.2000108@ozemail.com.au>
Message-ID: <20060209195234.79674.qmail@web34505.mail.mud.yahoo.com>

Dear group, 
 I am a novice programmer in R.  I have a list that
has a length of 27 elements. Each element is derived
from table function. 

>lls <- table(drres)

>legnth(lls)
27

I want to plot all these elements in 9x3 plot (9 rows
and 3 columns)
par(9,3)
> mypltfunc <- function(mydata){
+ for (i in 1:27){
+ plot(unlist(mydata[i]))
+ }
+ }

> mypltfunc(lls)
> 

In the graphics window, all 27 figures are drawn in
fraction of sec, one by one and I get to see the last
graph.  It is not drawing into this 9X3 grid. 

Could any one help me please. 

Thanks
sri



From jatwood at montana.edu  Thu Feb  9 20:58:31 2006
From: jatwood at montana.edu (jatwood)
Date: Thu, 09 Feb 2006 12:58:31 -0700
Subject: [R] converting lat-long coordinates to Albers Conical Equal Area
 coordinates
Message-ID: <5.2.0.9.0.20060209125604.00c22770@gemini.msu.montana.edu>

####################################################################################
We have used maptools to construct state, county, township, census-tract, 
and zipcode
level R maps with an Albers Conical Equal Area projection.  We would like 
to be able to
plot the location of weather stations or other point locations on the 
maps.  The data
the point locations are in latitude-longitude units and we must convert the 
coordinates
to the Albers Conical Equal Area coordinates.

However, as of yet, we have not been able to obtain satisfactory results 
using mapproj.
Given the specs below can someone please tell us how to use mapproj (or 
some other R
library) to convert lat-long coordinates into the appropriate Albers 
Conical Equal Area
coordinates?

Thanks in advance
Joe Atwood
Montana State University
jatwood at montana.edu

####################################################################################
The material at the bottom of this message is the metadata from
the shapefile we are using (as created in Arc-GIS).
####################################################################################

-----------------------------------
Horizontal coordinate system
Projected coordinate system name: NAD_1927_Albers
Geographic coordinate system name: GCS_North_American_1927
Details
Map Projection Name: Albers Conical Equal Area
Standard Parallel: 29.500000
Standard Parallel: 45.500000
Longitude of Central Meridian: -96.000000
Latitude of Projection Origin: 23.000000
False Easting: 0.000000
False Northing: 0.000000


Planar Coordinate Information
Planar Distance Units: meters
Coordinate Encoding Method: coordinate pair
Coordinate Representation
Abscissa Resolution: 0.008192
Ordinate Resolution: 0.008192


Geodetic Model
Horizontal Datum Name: North American Datum of 1927
Ellipsoid Name: Clarke 1866
Semi-major Axis: 6378206.400000
Denominator of Flattening Ratio: 294.978698
_________________

Bounding coordinates
Horizontal
In decimal degrees
West: -127.889829
East: -65.349890
North: 51.606167
South: 22.862978
In projected or local coordinates
Left: -2356341.706499
Right: 2257925.009693
Top: 3172647.320063
Bottom: 268329.067476

###################################################################################



From ggrothendieck at gmail.com  Thu Feb  9 21:03:50 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 9 Feb 2006 15:03:50 -0500
Subject: [R] "main" parameter in plot.default vs plot.formula
In-Reply-To: <200602091800.k19I0725018811@meitner.gene.com>
References: <200602091800.k19I0725018811@meitner.gene.com>
Message-ID: <971536df0602091203q612f4f99xaf530e9686c78984@mail.gmail.com>

I cannot explain it but I must have come across it since
I noticed in various places in some of my code I have
used, in terms of your example, the following:

plot(y ~ x, main = as.expression(bquote(m[1] == .(a))))

plot(y ~ x, main = list(bquote(m[1] == .(a))))

both of which work as expected.

On 2/9/06, Berton Gunter <gunter.berton at gene.com> wrote:
>
> Folks:
>
> R 2.2.0 on Windows.
>
> I find the following somewhat puzzling:
>
> > a<-1; x<-0:1; y<-x
>
> ## following works fine:
> > plot(x,y ,main= bquote(n[1] == .(a) ))
>
> ## following produces an error:
> > plot(y~x ,main= bquote(n[1] == .(a) ))
> Error in paste(n[1] == 1, " and ", n[2] == 2) : object "n" not found
>
> *******************************
>
> Note 1: I assume that this is due to the following documented behavior of
> plot.formula():
>
> "Both the terms in the formula and the ... arguments are evaluated in data
> enclosed in parent.frame() if data is a list or a data frame."
>
> Nevertheless, the behavior seems inconsistent to me. Am I missing something
> (including the "I assume ..." comment)?
>
> Note 2: If one uses substitute() instead, it works fine:
>
> plot(y~x ,main= substitute(bquote(n[1] == a),list(a=a)))
>
>
> Any illumination, public or private, would be appreciated.
>
> Cheers,
> Bert
>
>
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Thu Feb  9 21:16:07 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 09 Feb 2006 12:16:07 -0800
Subject: [R] Fixing AR coefficients in VAR model
In-Reply-To: <43EB9ADF.2010309@bank-banque-canada.ca>
References: <550c175b0602051959m6b5e3496m48f5346326c31e07@mail.gmail.com>	<43EB786D.3040806@pdf.com>
	<43EB9ADF.2010309@bank-banque-canada.ca>
Message-ID: <43EBA307.50907@pdf.com>

Hi, Paul:

	  Thanks very much.  I'd forgotten that.

	  Moreover, you provide very nice vignettes.

Daniel C Medina:  If you are not familiar with vignettes, you may wish 
to review "http://finzi.psych.upenn.edu/R/Rhelp02a/archive/67006.html" 
in addition to the vignette help page.

	  Best Wishes,
	  spencer graves

Paul Gilbert wrote:

> You can do this with dse. See
> 
>   require("dse1")
>  ?fixConstants
> 
> Paul Gilbert
> 
> Spencer Graves wrote:
> 
>>       I know of no existing functions in R that support fitting a 
>> multivariate autoregression while fixing some of the parameters.
>>
>>       Of course, as Simon Blomberg famously said in April 2005, "This 
>> is R. There is no if. Only how."  [With library(fortunes), try 
>> 'fortune("This is R")'.]  If I had to do fit a multivariate AR today 
>> with some parameters fixed, I might write a function to compute the 
>> determinant of the sample covariance matrix, and give it to "optim" or 
>> "nlminb".
>>
>>       I hope someone else will provide us with an easier way.
>>
>>       hope this helps,
>>       spencer graves
>>
>> Daniel Medina wrote:
>>
>>  
>>
>>> Dear Colleague,
>>>
>>> I would like to set a few AR coefficients (not order) to zero in the
>>> multivariate AR function (mAr.est; mAr library); however, the manual for
>>> this function does not provide this information. I would appreciate any
>>> suggestions along this line.
>>>
>>> Thankfully yours,
>>>
>>> Daniel C Medina
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>>   
>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>  
>>
> ==================================================================================== 
> 
> 
> La version fran??aise suit le texte anglais.
> 
> ------------------------------------------------------------------------------------ 
> 
> 
> This email message from the Bank of Canada is given in good faith, and 
> shall not be
> binding or construed as constituting any obligation on the part of the 
> Bank.
> 
> This email may contain privileged and/or confidential information, and 
> the Bank of
> Canada does not waive any related rights. Any distribution, use, or 
> copying of this
> email or the information it contains by other than the intended 
> recipient is
> unauthorized. If you received this email in error please delete it 
> immediately from
> your system and notify the sender promptly by email that you have done so.
> Recipients are advised to apply their own virus checks to this message 
> upon receipt.
> 
> ------------------------------------------------------------------------------------ 
> 
> 
> L'information communiqu??e dans les courriels en provenance de la Banque 
> du Canada
> est soumise de bonne foi, mais elle ne saurait lier la Banque et ne doit 
> aucunement
> ??tre interpr??t??e comme constituant une obligation de sa part.
> 
> Le pr??sent courriel peut contenir de l'information privil??gi??e ou 
> confidentielle.
> La Banque du Canada ne renonce pas aux droits qui s'y rapportent. Toute 
> diffusion,
> utilisation ou copie de ce courriel ou des renseignements qu'il contient 
> par une
> personne autre que le ou les destinataires d??sign??s est interdite. Si 
> vous recevez
> ce courriel par erreur, veuillez le supprimer imm??diatement et envoyer 
> sans d??lai ??
> l'exp??diteur un message ??lectronique pour l'aviser que vous avez ??limin?? 
> de votre
> ordinateur toute copie du courriel re??u.
> 
> D??s la r??ception du pr??sent message, le ou les destinataires doivent 
> activer leur
> programme de d??tection de virus pour ??viter toute contamination possible.
>



From murdoch at stats.uwo.ca  Thu Feb  9 21:35:25 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 09 Feb 2006 15:35:25 -0500
Subject: [R] New user: Custom probability distribution
In-Reply-To: <43EB91C9.8060205@gmail.com>
References: <43EB91C9.8060205@gmail.com>
Message-ID: <43EBA78D.2080502@stats.uwo.ca>

On 2/9/2006 2:02 PM, Jan Danielsson wrote:
> Hello,
> 
>    Given a probability function: p(x) = 12 / (25(x+1)) , x=0, 1, 2, 3 we
> generate the following values:
> 
>   C1  C2
>   0   0.48
>   1   0.24
>   2   0.16
>   3   0.12
> 
>    Now, I'm supposed to create 50 random values using this table. In
> MiniTab, I simply selected Calc -> Random Data -> Discrete, and selected
> the columns, and it created 50 random values in a new column.[1]
> 
> How do I do the same thing in R?
> 
>    [1] You may be wondering why I'm telling you this. Well, it's because
> if I were in your shoes, I'd think "Oh, someone wants me to solve his
> homework.". I have already solved it using MiniTab, but I want to be
> able to use R instead (since I prefer NetBSD).

You want to use the sample() function.  See ?sample.

Duncan Murdoch



From tom at sickkids.ca  Thu Feb  9 16:46:02 2006
From: tom at sickkids.ca (tom wright)
Date: Thu, 09 Feb 2006 10:46:02 -0500
Subject: [R] New user: Custom probability distribution
In-Reply-To: <43EB91C9.8060205@gmail.com>
References: <43EB91C9.8060205@gmail.com>
Message-ID: <1139499962.5606.7.camel@localhost.localdomain>

rbinom(50,5,c(0.48,0.24,0.16,0.12))


On Thu, 2006-09-02 at 20:02 +0100, Jan Danielsson wrote:
> Hello,
> 
>    Given a probability function: p(x) = 12 / (25(x+1)) , x=0, 1, 2, 3 we
> generate the following values:
> 
>   C1  C2
>   0   0.48
>   1   0.24
>   2   0.16
>   3   0.12
> 
>    Now, I'm supposed to create 50 random values using this table. In
> MiniTab, I simply selected Calc -> Random Data -> Discrete, and selected
> the columns, and it created 50 random values in a new column.[1]
> 
> How do I do the same thing in R?
> 
>    [1] You may be wondering why I'm telling you this. Well, it's because
> if I were in your shoes, I'd think "Oh, someone wants me to solve his
> homework.". I have already solved it using MiniTab, but I want to be
> able to use R instead (since I prefer NetBSD).
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Greg.Snow at intermountainmail.org  Thu Feb  9 21:59:34 2006
From: Greg.Snow at intermountainmail.org (Gregory Snow)
Date: Thu, 9 Feb 2006 13:59:34 -0700
Subject: [R] putting text in the corner
Message-ID: <07E228A5BE53C24CAD490193A7381BBB12A002@LP-EXCHVS07.CO.IHC.COM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060209/478ceb0b/attachment.pl

From Roger.Bivand at nhh.no  Thu Feb  9 22:04:34 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 9 Feb 2006 22:04:34 +0100 (CET)
Subject: [R] Shapefiles
In-Reply-To: <BAYC1-PASMTP02E44014CDFDBCC42ACE62E4030@CEZ.ICE>
	<BEEKLAMKBJMOPPLNMKNLAEPMDCAA.tarmo.remmel@sympatico.ca>
Message-ID: <Pine.LNX.4.44.0602092154340.11075-100000@reclus.nhh.no>

On Thu, 9 Feb 2006, Tarmo Remmel wrote:

> Dear List,
> 
> I have examined the sp, maptools, and shapefiles packages (Windows) but
> cannot seem to figure out a solution for writing shapefiles for 'curvy
> shapes'.  The scenario is that I generate a series of polygons, circles, and
> ellipses on a plot and would like to convert them to shapefiles.  Since the
> circles and ellipses are do not return a coordinate list during the plotting
> sequence (e.g., all I need supply are the lengths of axes and rotation
> angle), is there an easy way by which the plot window can be converted to a
> shapefile?

No, the plot window is committed to the device, and (re)-capturing the 
objects there as polygon objects will be messy. You'll need to generate an 
object that can be drawn as a sequence of straight line segments, and 
create a polygon object from that, from the x,y coordinates of the centre 
and the radius, or major/minor axes lengths and orientations. There is 
some code on:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/56190.html

(see RSiteSearch("circle"))

but I don't know if it will suit your purposes. Once constructed, the 
polygons can be built into an object for exporting.

> 
> Thank you,
> 
> Tarmo
> 
> __________________________________________
> Tarmo Remmel  Ph.D.
> GUESS Lab, Department of Geography
> University of Toronto at Mississauga
> Mississauga, Ontario, L5L 1C6
> Tel: 905-569-4382
> Lab: 905-828-3868
> Fax: 905-828-5273
> Skype: tarmoremmel
> http://eratos.erin.utoronto.ca/remmelt
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From kjetilbrinchmannhalvorsen at gmail.com  Thu Feb  9 22:04:40 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Thu, 09 Feb 2006 17:04:40 -0400
Subject: [R] putting text in the corner
In-Reply-To: <43EB8012.9050504@gmail.com>
References: <d0f55a670602090818j33e664d6l@mail.gmail.com>
	<43EB8012.9050504@gmail.com>
Message-ID: <43EBAE68.7080901@gmail.com>

Fernando Mayer wrote:
> You can get the x and y position of any place of an open graphic device 
> with the mouse cursor, using the function locator(), and even assing 
> this values to an object, as in:
> 
> xy<-locator()
> 
> You will have a list with x and y positions. Then you can use:
> 
> text(xy$x,xy$y,...)

or even
    text(locator(), "test", ...)

Kjetil


> 
> See ?locator.
> 
> HTH,
> Fernando Mayer.
> 
> Thomas Steiner escreveu:
> 
>> I want to write some text in a corner of my plot.
>> Is it possible to get the xlim and ylim of an open window?
>> Or is there anything similar like
>> legend(x="bottomright", inset=0.01,legend=...)
>> for
>> text(x=1,y=2, "test")
>>
>> Thomas
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>  
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From kjetilbrinchmannhalvorsen at gmail.com  Thu Feb  9 22:08:53 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Thu, 09 Feb 2006 17:08:53 -0400
Subject: [R] New user: Custom probability distribution
In-Reply-To: <43EB91C9.8060205@gmail.com>
References: <43EB91C9.8060205@gmail.com>
Message-ID: <43EBAF65.5090003@gmail.com>

Jan Danielsson wrote:
> Hello,
> 
>    Given a probability function: p(x) = 12 / (25(x+1)) , x=0, 1, 2, 3 we
> generate the following values:
> 
>   C1  C2
>   0   0.48
>   1   0.24
>   2   0.16
>   3   0.12
> 
>    Now, I'm supposed to create 50 random values using this table. In
> MiniTab, I simply selected Calc -> Random Data -> Discrete, and selected
> the columns, and it created 50 random values in a new column.[1]
> 
> How do I do the same thing in R?

sample( 0:3, 50, prob=c(0.48, 0.24, 0.26, 0.12))

Kjetil

> 
>    [1] You may be wondering why I'm telling you this. Well, it's because
> if I were in your shoes, I'd think "Oh, someone wants me to solve his
> homework.". I have already solved it using MiniTab, but I want to be
> able to use R instead (since I prefer NetBSD).
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From expiregmane1104.m.cudgle at neverbox.com  Thu Feb  9 15:34:49 2006
From: expiregmane1104.m.cudgle at neverbox.com (Frank Samuelson)
Date: Thu, 09 Feb 2006 09:34:49 -0500
Subject: [R] problem to install R on linux
In-Reply-To: <43EA33AD.5040005@gmail.com>
References: <43EA33AD.5040005@gmail.com>
Message-ID: <dsfjuj$cte$1@sea.gmane.org>

For the rpm install you may also need to install a package called info-x.x.x.x-x.rpm.
For the compilation you'll need to be certain that you've installed
readline-x.x.x.x.x.rpm and and perhaps readline-devel-x.x.x.x.rpm
Those should be in your mandriva distn


Andr?? Bel?? wrote:
> Dear members,
> 
> this can sound trivial for some people but I don't have experience on 
> compilation.
> 
> I'm trying to install R-2.2.1 on a laptop running Mandriva 2006. I 
> already installed many of the recommended packages/libraries but it 
> seems that something is still missing. The problem is that I cannot 
> identify... Could somebody give me some advise?
> 
> I put the output of the command "./configure" bellow. When I tryed to 
> install the R-2.0.0-1mdk.i586.rpm I got:
> 
> [root at localhost Download]# rpm -i R-2.0.0-1mdk.i586.rpm
> warning: R-2.0.0-1mdk.i586.rpm: Header V3 DSA signature: NOKEY, key ID 
> 6c60ceea
> error: Failed dependencies:
>         info is needed by R-2.0.0-1mdk.i586
> [root at localhost Download]#
> 
> 
> Thanks in advance,
> AB
> 
> 
> [root at localhost R-2.2.1]# ./configure
> checking build system type... i686-pc-linux-gnu
> checking host system type... i686-pc-linux-gnu
> loading site script './config.site'
> loading build specific script './config.site'
> checking for pwd... /bin/pwd
> checking whether builddir is srcdir... yes
> checking for working aclocal... found
> checking for working autoconf... found
> checking for working automake... found
> checking for working autoheader... found
> checking for working makeinfo... found
> checking for gawk... gawk
> checking for egrep... grep -E
> checking whether ln -s works... yes
> checking for ranlib... ranlib
> checking for bison... no
> checking for byacc... no
> checking for ar... ar
> checking for a BSD-compatible install... /usr/bin/install -c
> checking for sed... /bin/sed
> checking for less... /usr/bin/less
> checking for perl... /usr/bin/perl
> checking whether perl version is at least 5.004... yes
> checking for dvips... /usr/bin/dvips
> checking for tex... /usr/bin/tex
> checking for latex... /usr/bin/latex
> checking for makeindex... /usr/bin/makeindex
> checking for pdftex... /usr/bin/pdftex
> checking for pdflatex... /usr/bin/pdflatex
> checking for makeinfo... /usr/bin/makeinfo
> checking for unzip... /usr/bin/unzip
> checking for zip... /usr/bin/zip
> checking for gzip... /bin/gzip
> checking for firefox... no
> checking for mozilla... no
> checking for netscape... no
> checking for galeon... no
> checking for kfmclient... no
> checking for opera... no
> checking for gnome-moz-remote... /usr/bin/gnome-moz-remote
> using default browser ... /usr/bin/gnome-moz-remote
> checking for acroread... /usr/bin/acroread
> checking for gcc... gcc
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ANSI C... none needed
> checking how to run the C preprocessor... gcc -E
> checking whether gcc needs -traditional... no
> checking how to run the C preprocessor... gcc -E
> checking for gfortran... gfortran
> checking whether we are using the GNU Fortran 77 compiler... no
> checking whether gfortran accepts -g... no
> checking for g++... g++
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> checking how to run the C++ preprocessor... g++ -E
> checking for a sed that does not truncate output... /bin/sed
> checking for ld used by gcc... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking for /usr/bin/ld option to reload object files... -r
> checking for BSD-compatible nm... /usr/bin/nm -B
> checking how to recognise dependent libraries... pass_all
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking dlfcn.h usability... yes
> checking dlfcn.h presence... yes
> checking for dlfcn.h... yes
> checking the maximum length of command line arguments... 32768
> checking command to parse /usr/bin/nm -B output from gcc object... ok
> checking for objdir... .libs
> checking for ranlib... (cached) ranlib
> checking for strip... strip
> checking if gcc static flag  works... yes
> checking if gcc supports -fno-rtti -fno-exceptions... no
> checking for gcc option to produce PIC... -fPIC
> checking if gcc PIC flag -fPIC works... yes
> checking if gcc supports -c -o file.o... yes
> checking whether the gcc linker (/usr/bin/ld) supports shared 
> libraries... yes
> checking whether -lc should be explicitly linked in... no
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... no
> configure: creating libtool
> appending configuration tag "CXX" to libtool
> checking for ld used by g++... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking whether the g++ linker (/usr/bin/ld) supports shared 
> libraries... yes
> checking for g++ option to produce PIC... -fPIC
> checking if g++ PIC flag -fPIC works... yes
> checking if g++ supports -c -o file.o... yes
> checking whether the g++ linker (/usr/bin/ld) supports shared 
> libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> appending configuration tag "F77" to libtool
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... no
> checking for gfortran option to produce PIC... -fPIC
> checking if gfortran PIC flag -fPIC works... no
> checking if gfortran supports -c -o file.o... no
> checking whether the gfortran linker (/usr/bin/ld) supports shared 
> libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking whether makeinfo version is at least 4.7... yes
> checking for cos in -lm... yes
> checking for sin in -lm... yes
> checking for dlopen in -ldl... yes
> checking readline/history.h usability... no
> checking readline/history.h presence... no
> checking for readline/history.h... no
> checking readline/readline.h usability... no
> checking readline/readline.h presence... no
> checking for readline/readline.h... no
> checking for rl_callback_read_char in -lreadline... no
> checking for main in -lncurses... yes
> checking for rl_callback_read_char in -lreadline... no
> checking for history_truncate_file... no
> configure: error: --with-readline=yes (default) and headers/libs are not 
> available
> [root at localhost R-2.2.1]#
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Matthias.Kohl at stamats.de  Thu Feb  9 22:27:42 2006
From: Matthias.Kohl at stamats.de (Matthias Kohl)
Date: Thu, 09 Feb 2006 22:27:42 +0100
Subject: [R] New user: Custom probability distribution
In-Reply-To: <43EB91C9.8060205@gmail.com>
References: <43EB91C9.8060205@gmail.com>
Message-ID: <43EBB3CE.1010303@stamats.de>

Hi,

you can use our package distr respectively distrEx.
require(distrEx)
D1 <- DiscreteDistribution(supp=0:3, prob = 12/(25*(1:4)))
plot(D1)
r(D1)(50)

hth
Matthias

>Hello,
>
>   Given a probability function: p(x) = 12 / (25(x+1)) , x=0, 1, 2, 3 we
>generate the following values:
>
>  C1  C2
>  0   0.48
>  1   0.24
>  2   0.16
>  3   0.12
>
>   Now, I'm supposed to create 50 random values using this table. In
>MiniTab, I simply selected Calc -> Random Data -> Discrete, and selected
>the columns, and it created 50 random values in a new column.[1]
>
>How do I do the same thing in R?
>
>   [1] You may be wondering why I'm telling you this. Well, it's because
>if I were in your shoes, I'd think "Oh, someone wants me to solve his
>homework.". I have already solved it using MiniTab, but I want to be
>able to use R instead (since I prefer NetBSD).
>
>  
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


-- 
StaMatS - Statistik + Mathematik Service
Dr. rer. nat. Matthias Kohl
Gottlieb-Keim-Stra??e 60
95448 Bayreuth
Phone: +49 921 50736457
E-Mail: matthias.kohl at stamats.de
Home: www.stamats.de



From lisawang at uhnres.utoronto.ca  Thu Feb  9 22:31:04 2006
From: lisawang at uhnres.utoronto.ca (Lisa Wang)
Date: Thu, 09 Feb 2006 16:31:04 -0500
Subject: [R] latent class modle for rater agreement
Message-ID: <43EBB498.A55ED707@uhnres.utoronto.ca>

Hello there,

I would like to test the agreement amongst 6 raters for nominal data on
a scale from 1-4, and conduct a latent class analysis in R. How should
the data be formatted and what code should I use?

Thank you very much

Lisa Wang
Princess Margaret Hospital
Biostatistics
tel:416 946 4501



From backer at psych.uib.no  Thu Feb  9 22:37:26 2006
From: backer at psych.uib.no (Tom Backer Johnsen)
Date: Thu, 09 Feb 2006 22:37:26 +0100
Subject: [R]  Transferring R results to word prosessors
Message-ID: <5.2.0.8.2.20060209212028.020ec3d8@alf.uib.no>

There has been an incredible number of responses in a short time, with a 
number of different suggestions.  With hindsight, I must admit I have not 
been quite clear, so additional (somewhat lengthy) explanation is needed.

I want to use R in an introductory course on multiple regression (among 
other things) starting in two weeks time for students of psychology at my 
University.  These students are very much used to MS Word, it is in 
principle possible to get them to adopt OpenOffice (which I would like to), 
but I regard Latex to be out of the question.

One of the things they are drilled on is that they have to produce term 
papers etc. based on a template in APA (American Psychological Association) 
format.  Among other things, this means that the document must be all text 
apart from the graphics.  Therefore any kind of solution involving pictures 
of tables rather than the tables / results as text is out.  Same holds for 
all kinds of "mixed" output, so combinations of text with PDF 
elements.  Besides, the tables in R are not that nice in respect to the 
formatting.  Since the content is the main thing anyhow, that does not 
matter.  In most cases, the tables have to be tweaked as least to some 
extent.  Given my inexperience, it seems that the R2HTML path is so far the 
most promising (but for me untried so far)

One of the nice things about SPSS and Statistica is that it is VERY easy to 
copy and paste output from the program right into the paper / paper.  A 
commmon trick when using SPSS is to first paste the output into a 
spreadsheet (e.g. Excel), and from there into the document.  In any case, 
the outcome is that the output is a table (not a table in the R sense) in 
the document, which may be edited, tweaked, adding borders etc..  So, what 
I am looking for is a process starting with output from R (like what is 
obtained from the summary(lm (...)) command, the output of a correlation 
matrix, or ...) that could end up as a table in MS Word (and probably in 
OpenOffice as well) in the smallest number of steps.

For instance, if there was an option in R which had the effect that the 
spaces separating things (e.g. the columns in the output of a correlation 
matrix or the elements in an ANOVA table) were replaced by tabs, everything 
would be very simple.  Then, you could (a) paste the output into the 
document, and (b) do a simple text-to-table conversion in Word after the 
paste.  A simple affair with a few simple steps.  Ideally, what I want for 
me and my students is this or a similar solution to this problem.  That 
might be a good selling argument for R as well.

Tom



From sarah.goslee at gmail.com  Thu Feb  9 22:46:56 2006
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 9 Feb 2006 16:46:56 -0500
Subject: [R] Plotting 27 line plots in one page
In-Reply-To: <20060209195234.79674.qmail@web34505.mail.mud.yahoo.com>
References: <43EBDE85.2000108@ozemail.com.au>
	<20060209195234.79674.qmail@web34505.mail.mud.yahoo.com>
Message-ID: <efb536d50602091346wc0ebca9nffcdf27d72c9b93a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060209/295299af/attachment.pl

From Flom at ndri.org  Thu Feb  9 22:49:06 2006
From: Flom at ndri.org (Peter Flom)
Date: Thu, 09 Feb 2006 16:49:06 -0500
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <1139510350.4484.42.camel@localhost.localdomain>
References: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
	<43EB656E.10809@lancaster.ac.uk>
	<1db726800602090933m1e08922bj6b2a56344b80da47@mail.gmail.com>
	<1139510350.4484.42.camel@localhost.localdomain>
Message-ID: <43EB7281.B875.00C9.0@ndri.org>

>>> "Marc Schwartz (via MN)" <mschwartz at mn.rr.com> 2/9/2006 
<<<
If you prefer a good book, The LaTeX Companion (aka TLC) is the place
to begin:

http://www.amazon.com/gp/product/0201362996 

Peter L. Flom, PhD
Assistant Director, Statistics and Data Analysis Core
Center for Drug Use and HIV Research
National Development and Research Institutes
71 W. 23rd St
http://cduhr.ndri.org
www.peterflom.com
New York, NY 10010
(212) 845-4485 (voice)
(917) 438-0894 (fax)



>>>

I respectfully disagree.  TLC is a great book.  Absolutely.  But I
think it is overwhelming for a beginner.  

Peter



From Roger.Bivand at nhh.no  Thu Feb  9 23:01:12 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 9 Feb 2006 23:01:12 +0100 (CET)
Subject: [R] converting lat-long coordinates to Albers Conical Equal
 Area coordinates
In-Reply-To: <5.2.0.9.0.20060209125604.00c22770@gemini.msu.montana.edu>
Message-ID: <Pine.LNX.4.44.0602092258230.11075-100000@reclus.nhh.no>

On Thu, 9 Feb 2006, jatwood wrote:

> ####################################################################################
> We have used maptools to construct state, county, township, census-tract, 
> and zipcode
> level R maps with an Albers Conical Equal Area projection.  We would like 
> to be able to
> plot the location of weather stations or other point locations on the 
> maps.  The data
> the point locations are in latitude-longitude units and we must convert the 
> coordinates
> to the Albers Conical Equal Area coordinates.
> 
> However, as of yet, we have not been able to obtain satisfactory results 
> using mapproj.
> Given the specs below can someone please tell us how to use mapproj (or 
> some other R
> library) to convert lat-long coordinates into the appropriate Albers 
> Conical Equal Area
> coordinates?

Please look in spproj on the r-spatial sourceforge site, entrance via the 
Spatial Task View on CRAN. Look for function project() and visit the proj4 
website to work out the arguments needed. 

If this isn't sufficient, please continue this thread on the R-sig-geo
mailing list.

> 
> Thanks in advance
> Joe Atwood
> Montana State University
> jatwood at montana.edu
> 
> ####################################################################################
> The material at the bottom of this message is the metadata from
> the shapefile we are using (as created in Arc-GIS).
> ####################################################################################
> 
> -----------------------------------
> Horizontal coordinate system
> Projected coordinate system name: NAD_1927_Albers
> Geographic coordinate system name: GCS_North_American_1927
> Details
> Map Projection Name: Albers Conical Equal Area
> Standard Parallel: 29.500000
> Standard Parallel: 45.500000
> Longitude of Central Meridian: -96.000000
> Latitude of Projection Origin: 23.000000
> False Easting: 0.000000
> False Northing: 0.000000
> 
> 
> Planar Coordinate Information
> Planar Distance Units: meters
> Coordinate Encoding Method: coordinate pair
> Coordinate Representation
> Abscissa Resolution: 0.008192
> Ordinate Resolution: 0.008192
> 
> 
> Geodetic Model
> Horizontal Datum Name: North American Datum of 1927
> Ellipsoid Name: Clarke 1866
> Semi-major Axis: 6378206.400000
> Denominator of Flattening Ratio: 294.978698
> _________________
> 
> Bounding coordinates
> Horizontal
> In decimal degrees
> West: -127.889829
> East: -65.349890
> North: 51.606167
> South: 22.862978
> In projected or local coordinates
> Left: -2356341.706499
> Right: 2257925.009693
> Top: 3172647.320063
> Bottom: 268329.067476
> 
> ###################################################################################
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From srini_iyyer_bio at yahoo.com  Thu Feb  9 23:05:29 2006
From: srini_iyyer_bio at yahoo.com (Srinivas Iyyer)
Date: Thu, 9 Feb 2006 14:05:29 -0800 (PST)
Subject: [R] Plotting 27 line plots in one page
In-Reply-To: <efb536d50602091346wc0ebca9nffcdf27d72c9b93a@mail.gmail.com>
Message-ID: <20060209220529.64671.qmail@web34512.mail.mud.yahoo.com>

hi sarah, 
 thanks for your mail. 

#################################################
> par(mfrow=c(9,3))
> mypltfunc(lls)
Error in plot.new() : figure margins too large
> par(mfcol=c(9, 3))
> mypltfunc(lls)
Error in plot.new() : figure margins too large

##################################################

unfortunately I had this problem before. Thats the
reason, I went on using more simply,  par(9,3).

I tried the following too, although, truely I did not
understand the much after doing ?par:

> mar = c(1,1,1,1)
> oma = c(1,1,1,1)
> par(mar,oma)
[[1]]
NULL

[[2]]
NULL

> mypltfunc(lls)
> 

By doing this the problem turned out that it printed
all 27 figures, one after other in fraction of second,
and I see the last figure.



given my background (molecular biology) sometimes it
is very very difficult to understand the documentation
due to terminology problem.

thanks
sri



--- Sarah Goslee <sarah.goslee at gmail.com> wrote:

> >
> > I want to plot all these elements in 9x3 plot (9
> rows
> > and 3 columns)
> > par(9,3)
> 
> 
> You need to specify what par you want - see ?par for
> details.
> In this case, either
> 
> par(mfrow=c(9,3))
> or
> par(mfcol=c(9, 3))
> 
> will do what you want.
> 
> Sarah
> --
> Sarah Goslee
> http://www.stringpage.com
>



From BHunsicker at rfmd.com  Thu Feb  9 23:41:40 2006
From: BHunsicker at rfmd.com (Bill Hunsicker)
Date: Thu, 9 Feb 2006 17:41:40 -0500
Subject: [R] fft
Message-ID: <3EA9CDD20D8E694F92C01B7BA7FC5AC80437E487@mail.internal.rfmd.com>

R-help:

I need to do a fft on a data set.  I was wondering if any guidance may
be available.

Regards,
Bill

Bill Hunsicker
RF Micro Devices
7625 Thorndike Road
Greensboro, NC  27409
336-678-5260
610-597-9985(m)



From f.harrell at vanderbilt.edu  Fri Feb 10 00:10:51 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 09 Feb 2006 17:10:51 -0600
Subject: [R] Transferring R results to word prosessors
In-Reply-To: <5.2.0.8.2.20060209212028.020ec3d8@alf.uib.no>
References: <5.2.0.8.2.20060209212028.020ec3d8@alf.uib.no>
Message-ID: <43EBCBFB.7090708@vanderbilt.edu>

Tom Backer Johnsen wrote:
> There has been an incredible number of responses in a short time, with a 
> number of different suggestions.  With hindsight, I must admit I have not 
> been quite clear, so additional (somewhat lengthy) explanation is needed.
> 
> I want to use R in an introductory course on multiple regression (among 
> other things) starting in two weeks time for students of psychology at my 
> University.  These students are very much used to MS Word, it is in 
> principle possible to get them to adopt OpenOffice (which I would like to), 
> but I regard Latex to be out of the question.
> 
> One of the things they are drilled on is that they have to produce term 
> papers etc. based on a template in APA (American Psychological Association) 

There's nothing wrong with the APA template; it will work well with LaTeX.

> format.  Among other things, this means that the document must be all text 
> apart from the graphics.  Therefore any kind of solution involving pictures 
> of tables rather than the tables / results as text is out.  Same holds for 
> all kinds of "mixed" output, so combinations of text with PDF 
> elements.  Besides, the tables in R are not that nice in respect to the 
> formatting.  Since the content is the main thing anyhow, that does not 

You have not seen the various R/latex interfaces for tables then.

> matter.  In most cases, the tables have to be tweaked as least to some 
> extent.  Given my inexperience, it seems that the R2HTML path is so far the 
> most promising (but for me untried so far)
> 
> One of the nice things about SPSS and Statistica is that it is VERY easy to 
> copy and paste output from the program right into the paper / paper.  A 
> commmon trick when using SPSS is to first paste the output into a 
> spreadsheet (e.g. Excel), and from there into the document.  In any case, 
> the outcome is that the output is a table (not a table in the R sense) in 
> the document, which may be edited, tweaked, adding borders etc..  So, what 
> I am looking for is a process starting with output from R (like what is 
> obtained from the summary(lm (...)) command, the output of a correlation 
> matrix, or ...) that could end up as a table in MS Word (and probably in 
> OpenOffice as well) in the smallest number of steps.

It sounds as if you are not interested in teaching students the 
principles of reproducible research, which is too bad. [See references 
towards the bottom of http://biostat.mc.vanderbilt.edu/StatReport].

> 
> For instance, if there was an option in R which had the effect that the 
> spaces separating things (e.g. the columns in the output of a correlation 
> matrix or the elements in an ANOVA table) were replaced by tabs, everything 
> would be very simple.  Then, you could (a) paste the output into the 
> document, and (b) do a simple text-to-table conversion in Word after the 
> paste.  A simple affair with a few simple steps.  Ideally, what I want for 
> me and my students is this or a similar solution to this problem.  That 
> might be a good selling argument for R as well.
> 
> Tom

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From ramasamy at cancer.org.uk  Fri Feb 10 00:30:42 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 09 Feb 2006 23:30:42 +0000
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <43EB4D75.B875.00C9.0@ndri.org>
References: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
	<43EB656E.10809@lancaster.ac.uk>
	<1db726800602090933m1e08922bj6b2a56344b80da47@mail.gmail.com>
	<43EB4D75.B875.00C9.0@ndri.org>
Message-ID: <1139527843.10783.5.camel@dhcp-82.wolf.ox.ac.uk>

As much as I love LaTeX, I would be cautious on recommending it for
someone with a short term objective or does not really need to write
equations etc. 

Part of the reason is the initial step of getting the different
softwares required to make LaTeX work properly can be difficult.
However, I think this webpage does a good job of explaining it
http://www.math.aau.dk/~dethlef/Tips/introduction.html

WinEdt (http://www.winedt.com/) might also be worth checking out.

Regards, Adai


On Thu, 2006-02-09 at 14:11 -0500, Peter Flom wrote:
> >>> roger bos <roger.bos at gmail.com> 2/9/2006 12:33 pm >>> wrote
> <<<
> Yeah, but I don't understand LaTeX at all.  Can you point me to a good
> beginners guide?
> >>>
> 
> I like Math into LaTeX, by Gratzer.  
> For a real beginners guide, there's one called first steps in LaTeX.
> You might also want to look at issues of the PracTEX journal, many of which are for beginners (It's an online journal)
> 
> Peter
> 
> Peter L. Flom, PhD
> Assistant Director, Statistics and Data Analysis Core
> Center for Drug Use and HIV Research
> National Development and Research Institutes
> 71 W. 23rd St
> http://cduhr.ndri.org
> www.peterflom.com
> New York, NY 10010
> (212) 845-4485 (voice)
> (917) 438-0894 (fax)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ramasamy at cancer.org.uk  Fri Feb 10 00:34:45 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 09 Feb 2006 23:34:45 +0000
Subject: [R] Plotting 27 line plots in one page
In-Reply-To: <20060209195234.79674.qmail@web34505.mail.mud.yahoo.com>
References: <20060209195234.79674.qmail@web34505.mail.mud.yahoo.com>
Message-ID: <1139528086.10783.10.camel@dhcp-82.wolf.ox.ac.uk>

Try 

 par( mfrow=c(9,3) )
 for(i in 1:27) plot( lls[[i] )

but I think it might be a little crowded to put 9 rows in a page. 

Also check out the lattice package which is bit more complicated to
learn but gives prettier output.

Regards, Adai


On Thu, 2006-02-09 at 11:52 -0800, Srinivas Iyyer wrote:
> Dear group, 
>  I am a novice programmer in R.  I have a list that
> has a length of 27 elements. Each element is derived
> from table function. 
> 
> >lls <- table(drres)
> 
> >legnth(lls)
> 27
> 
> I want to plot all these elements in 9x3 plot (9 rows
> and 3 columns)
> par(9,3)
> > mypltfunc <- function(mydata){
> + for (i in 1:27){
> + plot(unlist(mydata[i]))
> + }
> + }
> 
> > mypltfunc(lls)
> > 
> 
> In the graphics window, all 27 figures are drawn in
> fraction of sec, one by one and I get to see the last
> graph.  It is not drawing into this 9X3 grid. 
> 
> Could any one help me please. 
> 
> Thanks
> sri
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From rotunnom at mail.nih.gov  Fri Feb 10 00:43:37 2006
From: rotunnom at mail.nih.gov (Rotunno, Melissa (NIH/NCI) [F])
Date: Thu, 9 Feb 2006 18:43:37 -0500
Subject: [R] library(microarr); functions image.view() treeview()
Message-ID: <5ED58A706B5CE84281BDBB960A842BCA0A70D9@NIHCESMLBX11.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060209/5a4d6e74/attachment.pl

From ramasamy at cancer.org.uk  Fri Feb 10 00:49:55 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 09 Feb 2006 23:49:55 +0000
Subject: [R] Plotting 27 line plots in one page
In-Reply-To: <20060209220529.64671.qmail@web34512.mail.mud.yahoo.com>
References: <20060209220529.64671.qmail@web34512.mail.mud.yahoo.com>
Message-ID: <1139528995.10783.14.camel@dhcp-82.wolf.ox.ac.uk>

This works :

 # simulate some data
 mylist <- list(NULL)
 for(i in 1:27) mylist[[i]] <- rnorm( rpois( 1, lambda=20 ) )

 # execute
 par( mfrow=c(9,3) )
 par(mar = c(1,1,1,1), oma = c(1,1,1,1))
 for(i in 1:27) plot( mylist[[i]] )

Also if you just want to plot the distribution values etc, then you can
also try different possibilities such as
 
 boxplot( mylist )

Regards, Adai




On Thu, 2006-02-09 at 14:05 -0800, Srinivas Iyyer wrote:
> hi sarah, 
>  thanks for your mail. 
> 
> #################################################
> > par(mfrow=c(9,3))
> > mypltfunc(lls)
> Error in plot.new() : figure margins too large
> > par(mfcol=c(9, 3))
> > mypltfunc(lls)
> Error in plot.new() : figure margins too large
> 
> ##################################################
> 
> unfortunately I had this problem before. Thats the
> reason, I went on using more simply,  par(9,3).
> 
> I tried the following too, although, truely I did not
> understand the much after doing ?par:
> 
> > mar = c(1,1,1,1)
> > oma = c(1,1,1,1)
> > par(mar,oma)
> [[1]]
> NULL
> 
> [[2]]
> NULL
> 
> > mypltfunc(lls)
> > 
> 
> By doing this the problem turned out that it printed
> all 27 figures, one after other in fraction of second,
> and I see the last figure.
> 
> 
> 
> given my background (molecular biology) sometimes it
> is very very difficult to understand the documentation
> due to terminology problem.
> 
> thanks
> sri
> 
> 
> 
> --- Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> > >
> > > I want to plot all these elements in 9x3 plot (9
> > rows
> > > and 3 columns)
> > > par(9,3)
> > 
> > 
> > You need to specify what par you want - see ?par for
> > details.
> > In this case, either
> > 
> > par(mfrow=c(9,3))
> > or
> > par(mfcol=c(9, 3))
> > 
> > will do what you want.
> > 
> > Sarah
> > --
> > Sarah Goslee
> > http://www.stringpage.com
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ct_zero at yahoo.com  Fri Feb 10 01:02:46 2006
From: ct_zero at yahoo.com (Colby Tanner)
Date: Thu, 9 Feb 2006 16:02:46 -0800 (PST)
Subject: [R] 3-dim splinefun?
Message-ID: <20060210000247.27893.qmail@web34706.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060209/19066881/attachment.pl

From subhabratapal at sraindia.com  Fri Feb 10 07:04:59 2006
From: subhabratapal at sraindia.com (Subhabrata)
Date: Fri, 10 Feb 2006 11:34:59 +0530
Subject: [R] Fw:  Controling the x or y limit
Message-ID: <000f01c62e07$ecf1dbc0$f608a8c0@srai37>

 Hello - R-experts,

This may sound simple to many --- 
We can specify the x limit by saying xlim = c(0, 20) for example.
 Then the graph will show the range of x -axis between 0 - 20.
 But the coordinate gap will be automatic like 0 then 5 then 15 and 20. 
 Is there any way by which we can set it in a gap of 2 or any number.

 Thank you for any help.
 
 With Regards

 Subhabrata



From subhabratapal at sraindia.com  Fri Feb 10 05:49:38 2006
From: subhabratapal at sraindia.com (Subhabrata)
Date: Fri, 10 Feb 2006 10:19:38 +0530
Subject: [R] Controling the x or y limit
Message-ID: <003b01c62dfd$659112e0$f608a8c0@srai37>

Hello - R-experts,

This may sound simple to many --- 

We can specify the x limit by saying xlim = c(0, 20) for example.
Then the graph will show the range of x -axis between 0 - 20.
But the coordinate gap will be automatic like 0 then 5 then 15 and 20. 
Is there any way by which we can set it in a gap of 2 or any number.


Thank you for any help.

With Regards

Subhabrata



From ggrothendieck at gmail.com  Fri Feb 10 05:06:31 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 9 Feb 2006 23:06:31 -0500
Subject: [R] expand.grid without expanding
In-Reply-To: <200602082134.k18LY7rV010307@tahi.mcs.vuw.ac.nz>
References: <200602082134.k18LY7rV010307@tahi.mcs.vuw.ac.nz>
Message-ID: <971536df0602092006hac2e9c8mb78bf0b9271d4d91@mail.gmail.com>

I have made a few more improvements:

expand.grid.id  <- function(id, ...) {
 vars <- list(...)
 nv <- length(vars)
 lims <- sapply(vars,length)
 stopifnot(length(lims) > 0, id <= prod(lims), length(names(vars)) == nv)
 res <- structure(vector("list",nv), .Names = names(vars))
 if (nv > 1) for(i in nv:2) {
   f <- prod(lims[1:(i-1)])
   res[[i]] <- vars[[i]][(id - 1)%/%f + 1]
   id <- (id - 1)%%f + 1
 }
 res[[1]] <- vars[[1]][id]
 as.data.frame(res)
}

# test
expand.grid(A = 1:2, B = letters[1:3])
expand.grid.id(1:6, A = 1:2, B = letters[1:3])


On 2/8/06, Ray Brownrigg <ray at mcs.vuw.ac.nz> wrote:
> > From: =?iso-8859-1?q?Lu=EDs_Torgo?= <ltorgo at liacc.up.pt>
> > Date: Wed, 8 Feb 2006 18:08:40 +0000
> >
> > Dear list,
> > I've recently came across a problem that I think I've solved and that I wanted
> > to share with you for two reasons:
> > - Maybe others come across the same problem.
> > - Maybe someone has a much simpler solution that wants to share with me ;-)
> >
> > The problem is as follows: expand.grid() allows you to generate a data.frame
> > with all combinations of a set of values, e.g.:
> > > expand.grid(par1=-1:1,par2=c('a','b'))
> >   par1 par2
> > 1   -1    a
> > 2    0    a
> > 3    1    a
> > 4   -1    b
> > 5    0    b
> > 6    1    b
> >
> > There is nothing wrong with this nice function except when you have too many
> > combinations to fit in your computer memory, and that was my problem: I
> > wanted to do something for each combination of a set of variants, but this
> > set was to large for storing in memory in a data.frame generated by
> > expand.grid. A possible solution would be to have a set of nested for()
> > cycles but I preferred a solution that involved a single for() cycle going
> > from 1 to the number of combinations and then at each iteration having some
> > form of generating the combination "i". And this was the "real problem": how
> > to generate a function that picks the same style of arguments as
> > expand.grid() and provides me with the values corresponding to line "i" of
> > the data frame that would have been created bu expand.grid(). For instance,
> > if I wanted the line 4 of the above call to expand.grid() I should get the
> > same as doing:
> > > expand.grid(par1=-1:1,par2=c('a','b'))[4,]
> >   par1 par2
> > 4   -1    b
> >
> > but obviously without having to use expand.grid() as that involves generating
> > a data frame that in my case wouldn't fit in the memory of my computer.
> >
> > Now, the function I've created was the following:
> > --------------------------------------------
> > getVariant <- function(id,vars) {
> >   if (!is.list(vars)) stop('vars needs to be a list!')
> >   nv <- length(vars)
> >   lims <- sapply(vars,length)
> >   if (id > prod(lims)) stop('id above the number of combinations!')
> >   res <- vector("list",nv)
> >   for(i in nv:2) {
> >     f <- prod(lims[1:(i-1)])
> >     res[[i]] <- vars[[i]][ceiling(id / f)]
> >     id <- id - (ceiling(id/f)-1)*f
> >   }
> >   res[[1]] <- vars[[1]][id]
> >   names(res) <- names(vars)
> >   res
> > }
> > --------------------------------------
> > > expand.grid(par1=-1:1,par2=c('a','b'))[4,]
> >   par1 par2
> > 4   -1    b
> > > getVariant(4,list(par1=-1:1,par2=c('a','b')))
> > $par1
> > [1] -1
> >
> > $par2
> > [1] "b"
> >
> > I would be glad to know if somebody came across the same problem and has a
> > better suggestion on how to solve this.
> >
> A few minor improvements:
> 1) let id be a vector of indices
> 2) use %% and %/% instead of ceiling (perhaps debateable)
> 3) return a data frame as does expand.grid
>
> So your function now looks like:
>
> getVariant <- function(id, vars) {
>  if (!is.list(vars)) stop('vars needs to be a list!')
>  nv <- length(vars)
>  lims <- sapply(vars, length)
>  if (any(id > prod(lims))) stop('id above the number of combinations!')
>  res <- vector("list", nv)
>  for(i in nv:2) {
>    f <- prod(lims[1:(i-1)])
>    res[[i]] <- vars[[i]][(id - 1)%/%f + 1]
>    id <- (id - 1)%%f + 1
>  }
>  res[[1]] <- vars[[1]][id]
>  names(res) <- names(vars)
>  return(as.data.frame(res))
> }
>
> Now, for example, you get:
>
> > expand.grid(par1=-1:1,par2=c('a','b'),par3=c('w','x','y','z'))[12:15,]
>   par1 par2 par3
> 12    1    b    x
> 13   -1    a    y
> 14    0    a    y
> 15    1    a    y
> > getVariant(12:15,list(par1=-1:1,par2=c('a','b'), par3=c('w','x','y','z')))
>  par1 par2 par3
> 1    1    b    x
> 2   -1    a    y
> 3    0    a    y
> 4    1    a    y
> >
>
> Note that you will run into trouble when the product of the lengths is
> greater than the largest representable integer on your system.
>
> Hope this helps,
> Ray Brownrigg
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From andbelo at gmail.com  Fri Feb 10 05:23:38 2006
From: andbelo at gmail.com (=?ISO-8859-1?Q?Andr=E9_Bel=F3?=)
Date: Thu, 09 Feb 2006 23:23:38 -0500
Subject: [R] problem to install R on linux
In-Reply-To: <E04D0A5FF70E854582D33D93A880799B0399C2CB@groamrexm03.amer.pfizer.com>
References: <E04D0A5FF70E854582D33D93A880799B0399C2CB@groamrexm03.amer.pfizer.com>
Message-ID: <43EC154A.8020507@gmail.com>

Hi, thanks for your e-mail, but it was not the case. I found the lines 
with the "readline/readline.h" information. This was because I did not 
have the realine package installed. After installing it I was able to 
install the R-2.0.0 using the .rpm binary version, however, I'm still 
not able to install the v2.2.1 from the source. Now I'm getting the 
following error after the ./configure command:

"...
checking whether we can compute C Make dependencies... yes, using gcc -MM
checking whether gcc supports -c -o FILE.lo... yes
checking how to get verbose linking output from gfortran... configure: 
WARNING: c ompilation failed

checking for Fortran libraries of gfortran...
checking how to get verbose linking output from gcc... -v
checking for C libraries of gcc...  -L/usr/local/lib 
-L/usr/lib/gcc/i586-mandriva -linux-gnu/4.0.1 
-L/usr/lib/gcc/i586-mandriva-linux-gnu/4.0.1/../../.. -lgcc_s
checking for dummy main to link with Fortran libraries... none
checking for Fortran name-mangling scheme... configure: error: cannot 
compile a s imple Fortran program
See `config.log' for more details."

I guess this is related to my compiler but I have no clue about how to 
fix it...
Thanks,
AB







Bhola, Gautam wrote:
> Hi
>
> I had similar issue which was resolved by ensuring that I have the lib/include folder for readline in my LD_LIBRARY_PATH and PATH respectively.
>
>
> Thanks 
> Gautam Bhola
>
>
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Andr?? Bel??
> Sent: Wednesday, February 08, 2006 1:09 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] problem to install R on linux
>
> Dear members,
>
> this can sound trivial for some people but I don't have experience on 
> compilation.
>
> I'm trying to install R-2.2.1 on a laptop running Mandriva 2006. I 
> already installed many of the recommended packages/libraries but it 
> seems that something is still missing. The problem is that I cannot 
> identify... Could somebody give me some advise?
>
> I put the output of the command "./configure" bellow. When I tryed to 
> install the R-2.0.0-1mdk.i586.rpm I got:
>
> [root at localhost Download]# rpm -i R-2.0.0-1mdk.i586.rpm
> warning: R-2.0.0-1mdk.i586.rpm: Header V3 DSA signature: NOKEY, key ID 
> 6c60ceea
> error: Failed dependencies:
>         info is needed by R-2.0.0-1mdk.i586
> [root at localhost Download]#
>
>
> Thanks in advance,
> AB
>
>
> [root at localhost R-2.2.1]# ./configure
> checking build system type... i686-pc-linux-gnu
> checking host system type... i686-pc-linux-gnu
> loading site script './config.site'
> loading build specific script './config.site'
> checking for pwd... /bin/pwd
> checking whether builddir is srcdir... yes
> checking for working aclocal... found
> checking for working autoconf... found
> checking for working automake... found
> checking for working autoheader... found
> checking for working makeinfo... found
> checking for gawk... gawk
> checking for egrep... grep -E
> checking whether ln -s works... yes
> checking for ranlib... ranlib
> checking for bison... no
> checking for byacc... no
> checking for ar... ar
> checking for a BSD-compatible install... /usr/bin/install -c
> checking for sed... /bin/sed
> checking for less... /usr/bin/less
> checking for perl... /usr/bin/perl
> checking whether perl version is at least 5.004... yes
> checking for dvips... /usr/bin/dvips
> checking for tex... /usr/bin/tex
> checking for latex... /usr/bin/latex
> checking for makeindex... /usr/bin/makeindex
> checking for pdftex... /usr/bin/pdftex
> checking for pdflatex... /usr/bin/pdflatex
> checking for makeinfo... /usr/bin/makeinfo
> checking for unzip... /usr/bin/unzip
> checking for zip... /usr/bin/zip
> checking for gzip... /bin/gzip
> checking for firefox... no
> checking for mozilla... no
> checking for netscape... no
> checking for galeon... no
> checking for kfmclient... no
> checking for opera... no
> checking for gnome-moz-remote... /usr/bin/gnome-moz-remote
> using default browser ... /usr/bin/gnome-moz-remote
> checking for acroread... /usr/bin/acroread
> checking for gcc... gcc
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ANSI C... none needed
> checking how to run the C preprocessor... gcc -E
> checking whether gcc needs -traditional... no
> checking how to run the C preprocessor... gcc -E
> checking for gfortran... gfortran
> checking whether we are using the GNU Fortran 77 compiler... no
> checking whether gfortran accepts -g... no
> checking for g++... g++
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> checking how to run the C++ preprocessor... g++ -E
> checking for a sed that does not truncate output... /bin/sed
> checking for ld used by gcc... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking for /usr/bin/ld option to reload object files... -r
> checking for BSD-compatible nm... /usr/bin/nm -B
> checking how to recognise dependent libraries... pass_all
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking dlfcn.h usability... yes
> checking dlfcn.h presence... yes
> checking for dlfcn.h... yes
> checking the maximum length of command line arguments... 32768
> checking command to parse /usr/bin/nm -B output from gcc object... ok
> checking for objdir... .libs
> checking for ranlib... (cached) ranlib
> checking for strip... strip
> checking if gcc static flag  works... yes
> checking if gcc supports -fno-rtti -fno-exceptions... no
> checking for gcc option to produce PIC... -fPIC
> checking if gcc PIC flag -fPIC works... yes
> checking if gcc supports -c -o file.o... yes
> checking whether the gcc linker (/usr/bin/ld) supports shared 
> libraries... yes
> checking whether -lc should be explicitly linked in... no
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... no
> configure: creating libtool
> appending configuration tag "CXX" to libtool
> checking for ld used by g++... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking whether the g++ linker (/usr/bin/ld) supports shared 
> libraries... yes
> checking for g++ option to produce PIC... -fPIC
> checking if g++ PIC flag -fPIC works... yes
> checking if g++ supports -c -o file.o... yes
> checking whether the g++ linker (/usr/bin/ld) supports shared 
> libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> appending configuration tag "F77" to libtool
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... no
> checking for gfortran option to produce PIC... -fPIC
> checking if gfortran PIC flag -fPIC works... no
> checking if gfortran supports -c -o file.o... no
> checking whether the gfortran linker (/usr/bin/ld) supports shared 
> libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking whether makeinfo version is at least 4.7... yes
> checking for cos in -lm... yes
> checking for sin in -lm... yes
> checking for dlopen in -ldl... yes
> checking readline/history.h usability... no
> checking readline/history.h presence... no
> checking for readline/history.h... no
> checking readline/readline.h usability... no
> checking readline/readline.h presence... no
> checking for readline/readline.h... no
> checking for rl_callback_read_char in -lreadline... no
> checking for main in -lncurses... yes
> checking for rl_callback_read_char in -lreadline... no
> checking for history_truncate_file... no
> configure: error: --with-readline=yes (default) and headers/libs are not 
> available
> [root at localhost R-2.2.1]#
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> ----------------------------------------------------------------------
> LEGAL NOTICE
> Unless expressly stated otherwise, this message is confidential and may be privileged.  It is intended for the addressee(s) only.  Access to this E-mail by anyone else is unauthorized.  If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful.  If you are not an addressee, please inform the sender immediately.
>
>



From pecqueur at esbs.u-strasbg.fr  Thu Feb  9 10:53:45 2006
From: pecqueur at esbs.u-strasbg.fr (pecqueur@esbs.u-strasbg.fr)
Date: Thu, 9 Feb 2006 10:53:45 +0100 (CET)
Subject: [R] translation of the matlab PPVAL function
Message-ID: <64757.194.206.242.93.1139478825.squirrel@194.206.242.93>

Hello,

I am trying to translate a matlab program into R, and I have some problems
to find out how to translate the PPVAL function.
I know that ppval(pp,xx) returns the value at the points xx of the
piecewise polynomial contained in pp( constructed by spline), but I don't
know how to do the same thing in R.

Thanks for you help


Delphine



From dimitris.rizopoulos at med.kuleuven.be  Fri Feb 10 09:22:40 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 10 Feb 2006 09:22:40 +0100
Subject: [R] Fw:  Controling the x or y limit
References: <000f01c62e07$ecf1dbc0$f608a8c0@srai37>
Message-ID: <00a001c62e1b$28bc46a0$0540210a@www.domain>

try the following:

plot(0:20, axes = FALSE)
axis(2)
axis(1, at = seq(0, 20, 2), labels = seq(0, 20, 2))


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Subhabrata" <subhabratapal at sraindia.com>
To: "r-help" <r-help at stat.math.ethz.ch>
Cc: <mansur at sraindia.com>
Sent: Friday, February 10, 2006 7:04 AM
Subject: [R] Fw: Controling the x or y limit


> Hello - R-experts,
>
> This may sound simple to many --- 
> We can specify the x limit by saying xlim = c(0, 20) for example.
> Then the graph will show the range of x -axis between 0 - 20.
> But the coordinate gap will be automatic like 0 then 5 then 15 and 
> 20.
> Is there any way by which we can set it in a gap of 2 or any number.
>
> Thank you for any help.
>
> With Regards
>
> Subhabrata
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From bambang.pramono at gmail.com  Fri Feb 10 03:38:11 2006
From: bambang.pramono at gmail.com (bambang pramono)
Date: Fri, 10 Feb 2006 09:38:11 +0700
Subject: [R] Tobit regression
Message-ID: <830480cb0602091838k6c00fdb6t861a314c9d5be841@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060210/5028122d/attachment.pl

From ggrothendieck at gmail.com  Fri Feb 10 02:29:25 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 9 Feb 2006 20:29:25 -0500
Subject: [R] Transferring R results to word prosessors
In-Reply-To: <5.2.0.8.2.20060209212028.020ec3d8@alf.uib.no>
References: <5.2.0.8.2.20060209212028.020ec3d8@alf.uib.no>
Message-ID: <971536df0602091729q506ca2d6ud9545900622f40f@mail.gmail.com>

Yes, the R2HTML route is probably the quickest.  Its just one line
of code (plus the call to load in R2HTML).  Try this where iris
is a data set built into R:

   library(R2HTML)
   HTML( iris, file("clipboard","w"), append=FALSE )

Now paste the clipboard into Excel and from there into Word.

(If you are using OO Calc instead of Excel then you need to do:
    Edit | Paste Special | HTML Format | OK
in Calc.)

On 2/9/06, Tom Backer Johnsen <backer at psych.uib.no> wrote:
> There has been an incredible number of responses in a short time, with a
> number of different suggestions.  With hindsight, I must admit I have not
> been quite clear, so additional (somewhat lengthy) explanation is needed.
>
> I want to use R in an introductory course on multiple regression (among
> other things) starting in two weeks time for students of psychology at my
> University.  These students are very much used to MS Word, it is in
> principle possible to get them to adopt OpenOffice (which I would like to),
> but I regard Latex to be out of the question.
>
> One of the things they are drilled on is that they have to produce term
> papers etc. based on a template in APA (American Psychological Association)
> format.  Among other things, this means that the document must be all text
> apart from the graphics.  Therefore any kind of solution involving pictures
> of tables rather than the tables / results as text is out.  Same holds for
> all kinds of "mixed" output, so combinations of text with PDF
> elements.  Besides, the tables in R are not that nice in respect to the
> formatting.  Since the content is the main thing anyhow, that does not
> matter.  In most cases, the tables have to be tweaked as least to some
> extent.  Given my inexperience, it seems that the R2HTML path is so far the
> most promising (but for me untried so far)
>
> One of the nice things about SPSS and Statistica is that it is VERY easy to
> copy and paste output from the program right into the paper / paper.  A
> commmon trick when using SPSS is to first paste the output into a
> spreadsheet (e.g. Excel), and from there into the document.  In any case,
> the outcome is that the output is a table (not a table in the R sense) in
> the document, which may be edited, tweaked, adding borders etc..  So, what
> I am looking for is a process starting with output from R (like what is
> obtained from the summary(lm (...)) command, the output of a correlation
> matrix, or ...) that could end up as a table in MS Word (and probably in
> OpenOffice as well) in the smallest number of steps.
>
> For instance, if there was an option in R which had the effect that the
> spaces separating things (e.g. the columns in the output of a correlation
> matrix or the elements in an ANOVA table) were replaced by tabs, everything
> would be very simple.  Then, you could (a) paste the output into the
> document, and (b) do a simple text-to-table conversion in Word after the
> paste.  A simple affair with a few simple steps.  Ideally, what I want for
> me and my students is this or a similar solution to this problem.  That
> might be a good selling argument for R as well.
>
> Tom
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Stefano.Guazzetti at ausl.re.it  Fri Feb 10 09:41:28 2006
From: Stefano.Guazzetti at ausl.re.it (Guazzetti Stefano)
Date: Fri, 10 Feb 2006 09:41:28 +0100
Subject: [R] R:  Fw:  Controling the x or y limit
Message-ID: <B8A1EED732379B44A7E59D22E82E4442020D6A4E@IMHOTEP.ausl.org>

perhaps you are looking at something like

plot(0, xlim=c(0,20), xaxt="n")
axis(1, at=pretty(0:20, 10))


Stefano
-----Messaggio originale-----
Da: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]Per conto di Subhabrata
Inviato: venerd?? 10 febbraio 2006 7.05
A: r-help
Cc: mansur at sraindia.com
Oggetto: [R] Fw: Controling the x or y limit


 Hello - R-experts,

This may sound simple to many --- 
We can specify the x limit by saying xlim = c(0, 20) for example.
 Then the graph will show the range of x -axis between 0 - 20.
 But the coordinate gap will be automatic like 0 then 5 then 15 and 20. 
 Is there any way by which we can set it in a gap of 2 or any number.

 Thank you for any help.
 
 With Regards

 Subhabrata

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ct_zero at yahoo.com  Fri Feb 10 05:44:23 2006
From: ct_zero at yahoo.com (Colby Tanner)
Date: Thu, 9 Feb 2006 20:44:23 -0800 (PST)
Subject: [R] 3-d splinefun
Message-ID: <20060210044423.66035.qmail@web34702.mail.mud.yahoo.com>

hello,
is it possible to do something like splinefun(x,y), but with a 3rd
dim?
for example, if i have a 2-dim system like:
x<-1:100
y<-rexp(100,1)
func<-splinefun(x,sort(y))

func(n) # returns interpolated value of y (after sorting) given x=n
        # i can check this by: 

plot(x,sort(y))
lines(spline(x,sort(y)))


Can i do the same thing with an x,y, and z? i have found the akima
interp(x,y,z) for building 3-d images, but nothing about the function
aspect.  besides building a nice 3-dim image, i would like to have a
way of finding the interpolated z values if i give an x and y
coordinate.  something like func(x,y) in the above example.

thank you,
colby



From subhabratapal at sraindia.com  Fri Feb 10 05:34:45 2006
From: subhabratapal at sraindia.com (Subhabrata)
Date: Fri, 10 Feb 2006 10:04:45 +0530
Subject: [R] Controling the x or y limit
Message-ID: <000f01c62dfb$52b40ad0$f608a8c0@srai37>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060210/1a3659f1/attachment.pl

From I.Visser at uva.nl  Fri Feb 10 10:16:51 2006
From: I.Visser at uva.nl (Ingmar Visser)
Date: Fri, 10 Feb 2006 10:16:51 +0100
Subject: [R] latent class modle for rater agreement
In-Reply-To: <43EBB498.A55ED707@uhnres.utoronto.ca>
Message-ID: <C0121893.29A2%I.Visser@uva.nl>

Typing latent class on the R project search page gives you at least four
packeges that do latent class models mmlcr, flexmix, gllm, depmix etc
Hth, ingmar


> From: Lisa Wang <lisawang at uhnres.utoronto.ca>
> Organization: UHN\RIS
> Date: Thu, 09 Feb 2006 16:31:04 -0500
> To: R-Help <r-help at stat.math.ethz.ch>
> Subject: [R] latent class modle for rater agreement
> 
> Hello there,
> 
> I would like to test the agreement amongst 6 raters for nominal data on
> a scale from 1-4, and conduct a latent class analysis in R. How should
> the data be formatted and what code should I use?
> 
> Thank you very much
> 
> Lisa Wang
> Princess Margaret Hospital
> Biostatistics
> tel:416 946 4501
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at gmail.com  Fri Feb 10 02:52:34 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 9 Feb 2006 20:52:34 -0500
Subject: [R] "main" parameter in plot.default vs plot.formula
In-Reply-To: <200602091800.k19I0725018811@meitner.gene.com>
References: <200602091800.k19I0725018811@meitner.gene.com>
Message-ID: <971536df0602091752w78111180q510379533951a6@mail.gmail.com>

On 2/9/06, Berton Gunter <gunter.berton at gene.com> wrote:
>
> Folks:
>
> R 2.2.0 on Windows.
>
> I find the following somewhat puzzling:
>
> > a<-1; x<-0:1; y<-x
>
> ## following works fine:
> > plot(x,y ,main= bquote(n[1] == .(a) ))
>
> ## following produces an error:
> > plot(y~x ,main= bquote(n[1] == .(a) ))
> Error in paste(n[1] == 1, " and ", n[2] == 2) : object "n" not found
>
> *******************************
>
> Note 1: I assume that this is due to the following documented behavior of
> plot.formula():
>
> "Both the terms in the formula and the ... arguments are evaluated in data
> enclosed in parent.frame() if data is a list or a data frame."
>
> Nevertheless, the behavior seems inconsistent to me. Am I missing something
> (including the "I assume ..." comment)?
>
> Note 2: If one uses substitute() instead, it works fine:
>
> plot(y~x ,main= substitute(bquote(n[1] == a),list(a=a)))
>

Regarding your note 2,  the key thing that seems to
be necessary is not really substitute vs. bquote but
just doing it twice.  In your example
above you did not replace bquote with substitute but did a
substitute and a bquote so now its two levels deep.  But if we
just did two bquotes or two substitutes that would be ok too.
For example, we can just apply bquote twice and then it works:

plot(y~x ,main = bquote(bquote(n[1] == .(a))))

The various calls must be stripping off one layer so that
you have to protect it twice so that the underlying code
does not get evaluated.



From jporzak at gmail.com  Fri Feb 10 01:34:19 2006
From: jporzak at gmail.com (Jim Porzak)
Date: Thu, 9 Feb 2006 16:34:19 -0800
Subject: [R] fft
In-Reply-To: <3EA9CDD20D8E694F92C01B7BA7FC5AC80437E487@mail.internal.rfmd.com>
References: <3EA9CDD20D8E694F92C01B7BA7FC5AC80437E487@mail.internal.rfmd.com>
Message-ID: <2a9c000c0602091634y39b0f353l211b69ce347b8652@mail.gmail.com>

Bill,

?fft

Do you have a specific question?

On 2/9/06, Bill Hunsicker <BHunsicker at rfmd.com> wrote:
> R-help:
>
> I need to do a fft on a data set.  I was wondering if any guidance may
> be available.
>
> Regards,
> Bill
>
> Bill Hunsicker
> RF Micro Devices
> 7625 Thorndike Road
> Greensboro, NC  27409
> 336-678-5260
> 610-597-9985(m)
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--
HTH,
Jim Porzak
Loyalty Matrix Inc.
San Francisco, CA



From Roger.Bivand at nhh.no  Fri Feb 10 10:32:03 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 10 Feb 2006 10:32:03 +0100 (CET)
Subject: [R] Controling the x or y limit
In-Reply-To: <000f01c62dfb$52b40ad0$f608a8c0@srai37>
Message-ID: <Pine.LNX.4.44.0602101029231.11855-100000@reclus.nhh.no>

On Fri, 10 Feb 2006, Subhabrata wrote:

> Hello - R-experts,
> 
> This may sound simple to many --- 
> 
> We can specify the x limit by saying xlim = c(0, 20) for example.
> Then the graph will show the range of x -axis between 0 - 20.
> But the coordinate gap will be automatic like 0 then 5 then 15 and 20. 
> Is there any way by which we can set it in a gap of 2 or any number.
> 

Use plot() with axes=FALSE, box() to put your box round, and axis() to 
manipulate the axis placings - see:

?axis

> 
> Thank you for any help.
> 
> With Regards
> 
> Subhabrata
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From spencer.graves at pdf.com  Fri Feb 10 05:50:17 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 09 Feb 2006 20:50:17 -0800
Subject: [R] decomposed.ts class and method
In-Reply-To: <200602060430.k164Uv1X023560@gator.dt.uh.edu>
References: <200602060430.k164Uv1X023560@gator.dt.uh.edu>
Message-ID: <43EC1B89.8010701@pdf.com>

Hi, Erin:

	  I tried the example in the help file for 'decompose':

      m <- decompose(co2)
      m$figure
      plot(m)

	  Consistent with your post, I got the following:

 > class(m)
[1] "decomposed.ts"

	  Then I tried the following:

 > methods(class="decomposed.ts")
[1] plot.decomposed.ts*

    Non-visible functions are asterisked

	  Then 'getAnywhere("plot.decomposed.ts")' should produce what you 
want.  Alternatively, consider the following:

 > methods("plot")
  [1] plot.acf*           plot.data.frame*    plot.Date*
  [4] plot.decomposed.ts* plot.default        plot.dendrogram*
<snip...?>

	  Thus, 'getAnywhere' should give you the plot method in this case. 
The class definition is outlined under 'Value' in the "decompose" help 
page.  For an example, try str(m).

	  hope this helps.
	  spencer graves	

Erin Hodgess wrote:

> Dear R People:
> 
> In the function "decompose", the object has the class of "decomposed.ts".
> (from package stats)
> 
> I would like to see the class definition and the method for the plotting.
> 
> However, when I use
> isClass("decomposed.ts")
> 
> I get "FALSE".
> 
> When I check getMethods("plot")
> 
> there is no method for plot on decomposed.ts
> 
> Any suggestions, please?
> 
> Thanks in advance!
> 
> R Version 2.2.1 Windows
> 
> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From h.wickham at gmail.com  Thu Feb  9 20:42:07 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 9 Feb 2006 13:42:07 -0600
Subject: [R] [R-pkgs] Reshape version 0.6
Message-ID: <f8e6ff050602091142n37c74f34u3c72232483c07279@mail.gmail.com>

Reshape version 0.6
===================

Reshape is an R package for flexibly restructuring and aggregating
data.  It's inspired by Excel's pivot tables, and it (hopefully) makes
it very easy to get your data into the shape that you want.  You can find out
more at http://had.co.nz/reshape

What's new in this version?

 * a new function, stamp, which is kind of a cross between by and
cast, and allows for aggregation functions that take an entire data
frame.  See ?stamp for examples

 * deals better with row and column names when subsetting the result

 * a namespace to make it easier to deal with potential name clashes
with other packages

 * better performance

Please let me know if you have any comments or questions.

Regards,

Hadley

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From maechler at stat.math.ethz.ch  Fri Feb 10 11:25:38 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 10 Feb 2006 11:25:38 +0100
Subject: [R] splines in R {"translation of the matlab PPVAL function"}
In-Reply-To: <64757.194.206.242.93.1139478825.squirrel@194.206.242.93>
References: <64757.194.206.242.93.1139478825.squirrel@194.206.242.93>
Message-ID: <17388.27170.147843.348512@stat.math.ethz.ch>

Probably   ?spline  and the builtin  spline() function is
already sufficient for you.

If you need more, use the (standard R) 'splines' package:

library(splines)
library(help = splines)

>>>>> "pecqueur" == pecqueur  <pecqueur at esbs.u-strasbg.fr>
>>>>>     on Thu, 9 Feb 2006 10:53:45 +0100 (CET) writes:

    pecqueur> Hello,
    pecqueur> I am trying to translate a matlab program into R, and I have some problems
    pecqueur> to find out how to translate the PPVAL function.
    pecqueur> I know that ppval(pp,xx) returns the value at the points xx of the
    pecqueur> piecewise polynomial contained in pp( constructed by spline), but I don't
    pecqueur> know how to do the same thing in R.

    pecqueur> Thanks for you help

    pecqueur> Delphine



From ana.pmartins at ine.pt  Fri Feb 10 10:55:46 2006
From: ana.pmartins at ine.pt (Ana Patricia Martins)
Date: Fri, 10 Feb 2006 09:55:46 -0000
Subject: [R]  - Function to export files
Message-ID: <E97312684A84D511BDD40002A50968D60722CFD3@lxpobw01.ine.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060210/475e7246/attachment.pl

From ligges at statistik.uni-dortmund.de  Fri Feb 10 11:43:55 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 10 Feb 2006 11:43:55 +0100
Subject: [R] R2WinBUGS - formating data for winbugs
In-Reply-To: <EBECLABIMNBHDFCEHCFHMEEBCGAA.cbehr@edesigndynamics.com>
References: <EBECLABIMNBHDFCEHCFHMEEBCGAA.cbehr@edesigndynamics.com>
Message-ID: <43EC6E6B.8040500@statistik.uni-dortmund.de>

Chris Behr wrote:

> I am currently running analyses in winbugs with two different formats of
> data: matrix and list. The data in the list have different dimensions than
> the matrix. Do I need to create a single format for entry into R which R
> passes to WinBUGS?


It is not quite clear to me what you mean, you have to be more precise 
and give some code example (possibly in a private mail to Sibylle Sturtz 
or me).

I guess you need to have to types of objects inR that you want to pass 
to WinBUGS, in this case, simply specify a list of those objects as the 
data argument to the bugs() function.

Uwe Ligges


> Thanks, Chris
> 
> Christopher Behr
> Principal Analyst
> 
> eDesign Dynamics
> www.edesigndynamics.com
> 
> 4024 Calvert St. NW
> Washington DC 20007
> (202) 298-6437 (t/f)
> (551) 998-4823 (c)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From HDoran at air.org  Fri Feb 10 12:09:52 2006
From: HDoran at air.org (Doran, Harold)
Date: Fri, 10 Feb 2006 06:09:52 -0500
Subject: [R] Transferring R results to word prosessors
Message-ID: <F5ED48890E2ACB468D0F3A64989D335AC99179@dc1ex3.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060210/8c7cda2e/attachment.pl

From petr.pikal at precheza.cz  Fri Feb 10 12:13:43 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 10 Feb 2006 12:13:43 +0100
Subject: [R] nice log-log plots
In-Reply-To: <1139504548.81bf18bctcodilean@geog.gla.ac.uk>
Message-ID: <43EC8377.22698.E5DE9E@localhost>

Hi

plot(1:100,1:100, log="xy")
abline(v=seq(0,100,10), lty=3)
abline(h=seq(0,100,10), lty=3)
or

plot(1:100,1:100, log="xy", axes=F)
axis(1, at=(seq(0,100,20)))
axis(2, at=(seq(0,100,10)))
abline(v=seq(0,100,20), lty=3)
abline(h=seq(0,100,10), lty=3)

isn't it nice?
See some other magigraphical parameters in

?par

HTH
Petr

BTW I do not have much time to spent it on such a task either 
especially when only you know what you want to achieve.


On 9 Feb 2006 at 17:02, Alexandru Codilean wrote:

From:           	"Alexandru Codilean" <tcodilean at geog.gla.ac.uk>
To:             	r-help at stat.math.ethz.ch
Date sent:      	Thu, 09 Feb 2006 17:02:28 +0000
Subject:        	[R] nice log-log plots
Send reply to:  	tcodilean at ges.gla.ac.uk
	<mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
	<mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>

> Dear All,
> 
> I am trying to produce log-log plots in R and I was wondering if any
> of you have a 'template' for generating these with 'nice' labels and
> log-log grids?
> 
> I know I can set up axes individually and use the intervals I want,
> however, I will be producing a large number of these plots and would
> not like to do this manually for each of them + I am very new to R and
> at the moment do not have much time that I could spend figuring this
> out by myself.....
> 
> Any help would be greatly appreciated!
> Thanks
> Tibi
> ____________________________________________________
> 
> Alexandru Tiberiu CODILEAN
> PhD Candidate
> Departmental IT Committee PG Rep.
> 
> Department of Geographical and Earth Sciences 
> East Quadrangle, Room 309 
> University Avenue 
> University of Glasgow 
> Glasgow G12 8QQ UK 
> 
> Tel: +44 (0) 141 330 4872 ext. 0935 
> Fax: +44 (0) 141 330 4894
> Email: tcodilean at ges.gla.ac.uk
> 
> Home: http://web.ges.gla.ac.uk/~tcodilean/
> GRASS Mirror: http://pc188.geog.gla.ac.uk/grass/
> 
> A gleekzorp without a tornpee is like a quop without a fertsneet (sort
> of)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From p.dalgaard at biostat.ku.dk  Fri Feb 10 12:39:43 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Feb 2006 12:39:43 +0100
Subject: [R] Transferring R results to word prosessors
In-Reply-To: <971536df0602091729q506ca2d6ud9545900622f40f@mail.gmail.com>
References: <5.2.0.8.2.20060209212028.020ec3d8@alf.uib.no>
	<971536df0602091729q506ca2d6ud9545900622f40f@mail.gmail.com>
Message-ID: <x2hd7730jk.fsf@viggo.kubism.ku.dk>

Gabor Grothendieck <ggrothendieck at gmail.com> writes:

> Yes, the R2HTML route is probably the quickest.  Its just one line
> of code (plus the call to load in R2HTML).  Try this where iris
> is a data set built into R:
> 
>    library(R2HTML)
>    HTML( iris, file("clipboard","w"), append=FALSE )
> 
> Now paste the clipboard into Excel and from there into Word.
> 
> (If you are using OO Calc instead of Excel then you need to do:
>     Edit | Paste Special | HTML Format | OK
> in Calc.)

Er, if you need to go via Excel anyway, wouldn't it be easier to just
use write.table or write.csv/write.csv2? The real value in R2HTML
would seem to be if you could go directly to Word/OO Writer.


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From gelman at stat.columbia.edu  Fri Feb 10 13:32:58 2006
From: gelman at stat.columbia.edu (Andrew Gelman)
Date: Fri, 10 Feb 2006 07:32:58 -0500
Subject: [R] mcmcsamp shortening variable names;
	how can i turn this feature off?
Message-ID: <43EC87FA.4020808@stat.columbia.edu>

I have written a function called mcsamp() that is a wrapper that runs 
mcmcsamp() and automatically monitors convergence and structures the 
inferences into vectors and arrays as appropriate.

But I have run into a very little problem, which is that mcmcsamp() 
shortens the variable names.  For example:

 > set.seed (1)
 > group <- rep (1:5,10)
 > a <- rnorm (5,-3,3)
 > y <- rnorm (50, a[group], 2)
 > fit <- lmer (y ~ 1 + (1 | group))
 > mcmcsamp(fit)
     (Intercept) log(sigma^2) log(grop.(In))
[1,]   -2.771979    0.6909418       1.750876
attr(,"mcpar")
[1] 1 1 1
attr(,"class")
[1] "mcmc"


I want "grop" in the above output to be "group", and I want "(In)" to be 
"(Intercept)".  For my purposes (fitting models in general settings) it 
is important to have descriptive variable names, and I gain nothing by 
restricting names to 14 characters.

Is there a way to turn this feature off?
Thanks.

-- 
Andrew Gelman
Professor, Department of Statistics
Professor, Department of Political Science
gelman at stat.columbia.edu
www.stat.columbia.edu/~gelman

Statistics department office:
  Social Work Bldg (Amsterdam Ave at 122 St), Room 1016
  212-851-2142
Political Science department office:
  International Affairs Bldg (Amsterdam Ave at 118 St), Room 731
  212-854-7075

Mailing address:
  1255 Amsterdam Ave, Room 1016
  Columbia University
  New York, NY 10027-5904
  212-851-2142
  (fax) 212-851-2164



From druau at ukaachen.de  Fri Feb 10 13:35:03 2006
From: druau at ukaachen.de (David Ruau)
Date: Fri, 10 Feb 2006 13:35:03 +0100
Subject: [R] command line completion in R?
Message-ID: <aabb1c3fde822af664cd4018c1a31aab@ukaachen.de>

Hi,

I was wondering if there were a option to have command line completion 
in R like in the Bash shell?

Best regards,
David



From gregor.gorjanc at bfro.uni-lj.si  Fri Feb 10 13:35:21 2006
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Fri, 10 Feb 2006 13:35:21 +0100
Subject: [R] Fitdistr and MLE for parameter lambda of Poisson distribution
Message-ID: <43EC8889.9000607@bfro.uni-lj.si>

Hello!

I would like to get MLE for parameter lambda of Poisson distribution. I 
can use fitdistr() for this. After looking a bit into the code of this 
function I can see that value for lambda and its standard error is 
estimated via

estimate <- mean(x)
sds <- sqrt(estimate/n)

Is this MLE? With my poor math/stat knowledge I thought that MLE for 
Poisson parameter is (in mixture of LaTeX code)

l(\lambda|x) \propto \sum^n_{i=1}(-\lambda + x_iln(\lambda)).

Is this really equal to (\sum^n_{i=1} x_i) / n

-- 
Lep pozdrav / With regards,
     Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si 

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888 

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
  you have no certainty until you try." Sophocles ~ 450 B.C.



From r.alberts at rug.nl  Fri Feb 10 13:59:41 2006
From: r.alberts at rug.nl (Rudi Alberts)
Date: Fri, 10 Feb 2006 13:59:41 +0100
Subject: [R] create custom CDF files for Affymetrix chips
In-Reply-To: <1078961485.2229.2.camel@gbic04>
References: <1078961485.2229.2.camel@gbic04>
Message-ID: <1139576381.9627.10.camel@gbic04.biol.rug.nl>

Hello,

Is there any function / package with which you can create your own CDF
files, i.e. you create your own probe sets and based on that a new CDF
file is created?

This doesn't seem possible with makecdfenv (which needs a CDF as input)


The package makecdfenv does this:

Description: This package has two functions. One reads a Affymetrix chip
description file (CDF) and creates a hash table environment containing
the location/probe set membership mapping. The other creates a package
that automatically loads that environment.

regards, R. Alberts



From Gautam.Bhola at pfizer.com  Fri Feb 10 14:17:05 2006
From: Gautam.Bhola at pfizer.com (Bhola, Gautam)
Date: Fri, 10 Feb 2006 08:17:05 -0500
Subject: [R] problem to install R on linux
Message-ID: <E04D0A5FF70E854582D33D93A880799B03B55D8F@groamrexm03.amer.pfizer.com>

I ran into the same issue and again it was not having proper PATH (with include folders set) and LD_LIBRARY_PATH set.

-----Original Message-----
From: Andr?? Bel?? [mailto:andbelo at gmail.com] 
Sent: Thursday, February 09, 2006 11:24 PM
To: Bhola, Gautam
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] problem to install R on linux

Hi, thanks for your e-mail, but it was not the case. I found the lines 
with the "readline/readline.h" information. This was because I did not 
have the realine package installed. After installing it I was able to 
install the R-2.0.0 using the .rpm binary version, however, I'm still 
not able to install the v2.2.1 from the source. Now I'm getting the 
following error after the ./configure command:

"...
checking whether we can compute C Make dependencies... yes, using gcc -MM
checking whether gcc supports -c -o FILE.lo... yes
checking how to get verbose linking output from gfortran... configure: 
WARNING: c ompilation failed

checking for Fortran libraries of gfortran...
checking how to get verbose linking output from gcc... -v
checking for C libraries of gcc...  -L/usr/local/lib 
-L/usr/lib/gcc/i586-mandriva -linux-gnu/4.0.1 
-L/usr/lib/gcc/i586-mandriva-linux-gnu/4.0.1/../../.. -lgcc_s
checking for dummy main to link with Fortran libraries... none
checking for Fortran name-mangling scheme... configure: error: cannot 
compile a s imple Fortran program
See `config.log' for more details."

I guess this is related to my compiler but I have no clue about how to 
fix it...
Thanks,
AB







Bhola, Gautam wrote:
> Hi
>
> I had similar issue which was resolved by ensuring that I have the lib/include folder for readline in my LD_LIBRARY_PATH and PATH respectively.
>
>
> Thanks 
> Gautam Bhola
>
>
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Andr?? Bel??
> Sent: Wednesday, February 08, 2006 1:09 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] problem to install R on linux
>
> Dear members,
>
> this can sound trivial for some people but I don't have experience on 
> compilation.
>
> I'm trying to install R-2.2.1 on a laptop running Mandriva 2006. I 
> already installed many of the recommended packages/libraries but it 
> seems that something is still missing. The problem is that I cannot 
> identify... Could somebody give me some advise?
>
> I put the output of the command "./configure" bellow. When I tryed to 
> install the R-2.0.0-1mdk.i586.rpm I got:
>
> [root at localhost Download]# rpm -i R-2.0.0-1mdk.i586.rpm
> warning: R-2.0.0-1mdk.i586.rpm: Header V3 DSA signature: NOKEY, key ID 
> 6c60ceea
> error: Failed dependencies:
>         info is needed by R-2.0.0-1mdk.i586
> [root at localhost Download]#
>
>
> Thanks in advance,
> AB
>
>
> [root at localhost R-2.2.1]# ./configure
> checking build system type... i686-pc-linux-gnu
> checking host system type... i686-pc-linux-gnu
> loading site script './config.site'
> loading build specific script './config.site'
> checking for pwd... /bin/pwd
> checking whether builddir is srcdir... yes
> checking for working aclocal... found
> checking for working autoconf... found
> checking for working automake... found
> checking for working autoheader... found
> checking for working makeinfo... found
> checking for gawk... gawk
> checking for egrep... grep -E
> checking whether ln -s works... yes
> checking for ranlib... ranlib
> checking for bison... no
> checking for byacc... no
> checking for ar... ar
> checking for a BSD-compatible install... /usr/bin/install -c
> checking for sed... /bin/sed
> checking for less... /usr/bin/less
> checking for perl... /usr/bin/perl
> checking whether perl version is at least 5.004... yes
> checking for dvips... /usr/bin/dvips
> checking for tex... /usr/bin/tex
> checking for latex... /usr/bin/latex
> checking for makeindex... /usr/bin/makeindex
> checking for pdftex... /usr/bin/pdftex
> checking for pdflatex... /usr/bin/pdflatex
> checking for makeinfo... /usr/bin/makeinfo
> checking for unzip... /usr/bin/unzip
> checking for zip... /usr/bin/zip
> checking for gzip... /bin/gzip
> checking for firefox... no
> checking for mozilla... no
> checking for netscape... no
> checking for galeon... no
> checking for kfmclient... no
> checking for opera... no
> checking for gnome-moz-remote... /usr/bin/gnome-moz-remote
> using default browser ... /usr/bin/gnome-moz-remote
> checking for acroread... /usr/bin/acroread
> checking for gcc... gcc
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ANSI C... none needed
> checking how to run the C preprocessor... gcc -E
> checking whether gcc needs -traditional... no
> checking how to run the C preprocessor... gcc -E
> checking for gfortran... gfortran
> checking whether we are using the GNU Fortran 77 compiler... no
> checking whether gfortran accepts -g... no
> checking for g++... g++
> checking whether we are using the GNU C++ compiler... yes
> checking whether g++ accepts -g... yes
> checking how to run the C++ preprocessor... g++ -E
> checking for a sed that does not truncate output... /bin/sed
> checking for ld used by gcc... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking for /usr/bin/ld option to reload object files... -r
> checking for BSD-compatible nm... /usr/bin/nm -B
> checking how to recognise dependent libraries... pass_all
> checking for ANSI C header files... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking dlfcn.h usability... yes
> checking dlfcn.h presence... yes
> checking for dlfcn.h... yes
> checking the maximum length of command line arguments... 32768
> checking command to parse /usr/bin/nm -B output from gcc object... ok
> checking for objdir... .libs
> checking for ranlib... (cached) ranlib
> checking for strip... strip
> checking if gcc static flag  works... yes
> checking if gcc supports -fno-rtti -fno-exceptions... no
> checking for gcc option to produce PIC... -fPIC
> checking if gcc PIC flag -fPIC works... yes
> checking if gcc supports -c -o file.o... yes
> checking whether the gcc linker (/usr/bin/ld) supports shared 
> libraries... yes
> checking whether -lc should be explicitly linked in... no
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... no
> configure: creating libtool
> appending configuration tag "CXX" to libtool
> checking for ld used by g++... /usr/bin/ld
> checking if the linker (/usr/bin/ld) is GNU ld... yes
> checking whether the g++ linker (/usr/bin/ld) supports shared 
> libraries... yes
> checking for g++ option to produce PIC... -fPIC
> checking if g++ PIC flag -fPIC works... yes
> checking if g++ supports -c -o file.o... yes
> checking whether the g++ linker (/usr/bin/ld) supports shared 
> libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> appending configuration tag "F77" to libtool
> checking if libtool supports shared libraries... yes
> checking whether to build shared libraries... yes
> checking whether to build static libraries... no
> checking for gfortran option to produce PIC... -fPIC
> checking if gfortran PIC flag -fPIC works... no
> checking if gfortran supports -c -o file.o... no
> checking whether the gfortran linker (/usr/bin/ld) supports shared 
> libraries... yes
> checking dynamic linker characteristics... GNU/Linux ld.so
> checking how to hardcode library paths into programs... immediate
> checking whether stripping libraries is possible... yes
> checking whether makeinfo version is at least 4.7... yes
> checking for cos in -lm... yes
> checking for sin in -lm... yes
> checking for dlopen in -ldl... yes
> checking readline/history.h usability... no
> checking readline/history.h presence... no
> checking for readline/history.h... no
> checking readline/readline.h usability... no
> checking readline/readline.h presence... no
> checking for readline/readline.h... no
> checking for rl_callback_read_char in -lreadline... no
> checking for main in -lncurses... yes
> checking for rl_callback_read_char in -lreadline... no
> checking for history_truncate_file... no
> configure: error: --with-readline=yes (default) and headers/libs are not 
> available
> [root at localhost R-2.2.1]#
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> ----------------------------------------------------------------------
> LEGAL NOTICE
> Unless expressly stated otherwise, this message is confidential and may be privileged.  It is intended for the addressee(s) only.  Access to this E-mail by anyone else is unauthorized.  If you are not an addressee, any disclosure or copying of the contents of this E-mail or any action taken (or not taken) in reliance on it is unauthorized and may be unlawful.  If you are not an addressee, please inform the sender immediately.
>
>   
----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From p.dalgaard at biostat.ku.dk  Fri Feb 10 14:20:16 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Feb 2006 14:20:16 +0100
Subject: [R] mcmcsamp shortening variable names;
	how can i turn this feature off?
In-Reply-To: <43EC87FA.4020808@stat.columbia.edu>
References: <43EC87FA.4020808@stat.columbia.edu>
Message-ID: <x2d5hv2vvz.fsf@viggo.kubism.ku.dk>

Andrew Gelman <gelman at stat.columbia.edu> writes:

> I have written a function called mcsamp() that is a wrapper that runs 
> mcmcsamp() and automatically monitors convergence and structures the 
> inferences into vectors and arrays as appropriate.
> 
> But I have run into a very little problem, which is that mcmcsamp() 
> shortens the variable names.  For example:
> 
>  > set.seed (1)
>  > group <- rep (1:5,10)
>  > a <- rnorm (5,-3,3)
>  > y <- rnorm (50, a[group], 2)
>  > fit <- lmer (y ~ 1 + (1 | group))
>  > mcmcsamp(fit)
>      (Intercept) log(sigma^2) log(grop.(In))
> [1,]   -2.771979    0.6909418       1.750876
> attr(,"mcpar")
> [1] 1 1 1
> attr(,"class")
> [1] "mcmc"
> 
> 
> I want "grop" in the above output to be "group", and I want "(In)" to be 
> "(Intercept)".  For my purposes (fitting models in general settings) it 
> is important to have descriptive variable names, and I gain nothing by 
> restricting names to 14 characters.
> 
> Is there a way to turn this feature off?
> Thanks.

Looks like they've been run through abbreviate() (which I thought
would be called abbr(), but apparently not...)

> abbreviate("Peter Dalgaard",5)
Peter Dalgaard
       "PtrDl"

Unfortunately, the 2 parts have been abbreviated separately, so the
long names are lost (in fact never generated). I suppose that it could
be possible to hack Matrix:::abbrvNms so that a long version is
returned in names(colnames(mcmc.out)). You have the sources...

Given how close even atanh(Sbj.(I).Dys) is to filling up the label
field of a Trellis plot, I must say that I think there is a case for
abbreviating. Those names easily get *very* long.


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ggrothendieck at gmail.com  Fri Feb 10 14:28:02 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 10 Feb 2006 08:28:02 -0500
Subject: [R] Transferring R results to word prosessors
In-Reply-To: <x2hd7730jk.fsf@viggo.kubism.ku.dk>
References: <5.2.0.8.2.20060209212028.020ec3d8@alf.uib.no>
	<971536df0602091729q506ca2d6ud9545900622f40f@mail.gmail.com>
	<x2hd7730jk.fsf@viggo.kubism.ku.dk>
Message-ID: <971536df0602100528n173c2d71g4592a6e537c12792@mail.gmail.com>

On 10 Feb 2006 12:39:43 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> Gabor Grothendieck <ggrothendieck at gmail.com> writes:
>
> > Yes, the R2HTML route is probably the quickest.  Its just one line
> > of code (plus the call to load in R2HTML).  Try this where iris
> > is a data set built into R:
> >
> >    library(R2HTML)
> >    HTML( iris, file("clipboard","w"), append=FALSE )
> >
> > Now paste the clipboard into Excel and from there into Word.
> >
> > (If you are using OO Calc instead of Excel then you need to do:
> >     Edit | Paste Special | HTML Format | OK
> > in Calc.)
>
> Er, if you need to go via Excel anyway, wouldn't it be easier to just
> use write.table or write.csv/write.csv2? The real value in R2HTML
> would seem to be if you could go directly to Word/OO Writer.

The data frame was just an example.  The real problem stated by
the user included transferring summary.lm and presumably other
classes of object as well. The HTML solution also in those cases
as it has 158 HTML methods including a summary.lm method.

Another poster did point out already one can create a file from R2HTML
and insert that into Word thereby eliminating the Excel step; however,
I think its actually faster to go the Excel route since that way you don't have
to locate the file in Word but I might be wrong about that so try both and
use whichever you prefer.

On the other hand, the file route has the advantage that if you linked
to it (I have not actually tried this but maybe someone wants to figure
out how this works) rather than insert it (Word supports both linking
and embedding) then if the file changed your Word document automatically
would change too which would address the reproducibility comment that
someone on this thread had.



From p.dalgaard at biostat.ku.dk  Fri Feb 10 14:39:19 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Feb 2006 14:39:19 +0100
Subject: [R] Fitdistr and MLE for parameter lambda of Poisson
	distribution
In-Reply-To: <43EC8889.9000607@bfro.uni-lj.si>
References: <43EC8889.9000607@bfro.uni-lj.si>
Message-ID: <x28xsj2v08.fsf@viggo.kubism.ku.dk>

Gregor Gorjanc <gregor.gorjanc at bfro.uni-lj.si> writes:

> Hello!
> 
> I would like to get MLE for parameter lambda of Poisson distribution. I 
> can use fitdistr() for this. After looking a bit into the code of this 
> function I can see that value for lambda and its standard error is 
> estimated via
> 
> estimate <- mean(x)
> sds <- sqrt(estimate/n)
> 
> Is this MLE? With my poor math/stat knowledge I thought that MLE for 
> Poisson parameter is (in mixture of LaTeX code)
> 
> l(\lambda|x) \propto \sum^n_{i=1}(-\lambda + x_iln(\lambda)).
> 
> Is this really equal to (\sum^n_{i=1} x_i) / n

Yes....

Maximizing l(lambda) is the same as maximizing

sum(x)/n ln lambda - lambda

Now either take the derivative and set equal to zero, or
 
rewrite further as equivalent to

ln (lambda/(sum(x)/n)) -  (lambda/(sum(x)/n))

and notice that ln(x) - x has a global maximum at x=1 (since ln is
strictly concave and the tangent at x=1 is the line y = x - 1)
 

(I think this is in the first 20 pages I ever read on theoretical
statistics ...)

> -- 
> Lep pozdrav / With regards,
>      Gregor Gorjanc
> 
> ----------------------------------------------------------------------
> University of Ljubljana     PhD student
> Biotechnical Faculty
> Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
> Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si 
> 
> SI-1230 Domzale             tel: +386 (0)1 72 17 861
> Slovenia, Europe            fax: +386 (0)1 72 17 888 
> 
> ----------------------------------------------------------------------
> "One must learn by doing the thing; for though you think you know it,
>   you have no certainty until you try." Sophocles ~ 450 B.C.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From dingjia at gmail.com  Fri Feb 10 14:43:37 2006
From: dingjia at gmail.com (jia ding)
Date: Fri, 10 Feb 2006 14:43:37 +0100
Subject: [R] histogram error: 'x' must be numeric
Message-ID: <91ae6e350602100543g11f2e212rb1de192ccda584f0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060210/c6ee5824/attachment.pl

From Luisr at frs.fo  Fri Feb 10 14:46:29 2006
From: Luisr at frs.fo (Luis Ridao Cruz)
Date: Fri, 10 Feb 2006 13:46:29 +0000
Subject: [R] plot(...., type = "h", lwd = 10) results in square tops
Message-ID: <s3ec993d.073@ffdata.setur.fo>

R-help,

I'm using the following code:

plot(1985:2005, data, type = "h", lwd = 10) 

which should plot histogram like figure.
The bar tops are square and I was wondering if
it is intended to be so or not (I can of course
use barplot instead).


Thanks



From B.Rowlingson at lancaster.ac.uk  Fri Feb 10 14:59:25 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 10 Feb 2006 13:59:25 +0000
Subject: [R] histogram error: 'x' must be numeric
In-Reply-To: <91ae6e350602100543g11f2e212rb1de192ccda584f0@mail.gmail.com>
References: <91ae6e350602100543g11f2e212rb1de192ccda584f0@mail.gmail.com>
Message-ID: <43EC9C3D.1000103@lancaster.ac.uk>

jia ding wrote:

> Then, I use command:
> score<- read.csv('file.csv', header = FALSE,sep = ",")
> hist(score, main = "score")
> 
> it gives error msg:
> Error in hist.default("score", main = "score") :
>         'x' must be numeric
> 
> Can any of you know about it explain me why?

  Have a look at 'score' in R first. You might get this:

 > score
        V1
1 31.8450
2 24.5980
3 29.1223
4 24.7150
5 23.1847
6 24.2321
7 25.2995
8 23.4261
9 30.7873

  - read.csv reads things in into "data frames" - a bit like a matrix. 
You've read your data into a data frame with one column, so you can do:

  hist(score$V1)

  since V1 is the name of the column.

  If your data is just one column, then you could do:

  score = scan("file.csv")

  and then

  hist(score)

  since scan() has read it into a single vector, not a data frame.

Barry



From lassana.koita at aviation-civile.gouv.fr  Fri Feb 10 15:19:23 2006
From: lassana.koita at aviation-civile.gouv.fr (KOITA Lassana - STAC/ACE)
Date: Fri, 10 Feb 2006 15:19:23 +0100
Subject: [R] Problem to paste the title of the columns and the rows
Message-ID: <OF7715C610.E3A89FCA-ONC1257111.004CBDA5@aviation-civile.gouv.fr>





Hi,
This following function works correctly. However, I would like to improve
it by adding to the table of result the titles of columns and rows. I
prefer to define  vector column by : D = (Dj = debit[j] ,
j=1:length(debit))  and vector row by:  J = (Ji = time [ i ], i = 1:
length(time))

Thank for your help
#################################


forage <- function (time, debit, n,ind)

{
pop <- 16867*(1.025^n)
bes <- pop*ind
requis <- 1.2*ind*pop
#906.83
n <- length(time)
m <- length(debit)
result <- matrix(ncol = m, nrow = n);
for (i in 1:n)
   {
     for(j in 1:m)

      {
       result[i,j] <- (time[i]*debit[j]) - requis;

      }
   }
#result;
round(result,2)
#round(rbind(pop = pop,bes = bes,requis = requis), 2)
}

forage (time <- seq( 10,24, by = 2),
debit <- c( seq(8.17, 51.43, by = 8.57), 55, 60),20, 0.035)






Lassana KOITA
Etudes de S??curit?? et d'Exploitation a??roportuaires / Aerodrome Safety &
Statistical analysis
Service Technique de l'Aviation Civile (STAC) / Civil Aviation Technical
Department
Direction G??n??rale de l'Aviation Civile (DGAC) / French Civil Aviation
Authority
Tel: 01 49 56 80 60
Fax: 01 49 56 82 14
E-mail: Lassana.Koita at aviation-civile.gouv.fr
http://www.stac.aviation-civile.gouv.fr/



From finbref.2006 at gmail.com  Fri Feb 10 15:38:15 2006
From: finbref.2006 at gmail.com (Thomas Steiner)
Date: Fri, 10 Feb 2006 15:38:15 +0100
Subject: [R] putting text in the corner
In-Reply-To: <43EB8471.9050402@stats.uwo.ca>
References: <d0f55a670602090818j33e664d6l@mail.gmail.com>
	<43EB8471.9050402@stats.uwo.ca>
Message-ID: <d0f55a670602100638v703ec214r@mail.gmail.com>

Thank you all.

> par("usr")

is the perfect solution.

It *is* in the help files, but was quite hard to find.

Thomas



From vasu.akkineni at gmail.com  Fri Feb 10 15:43:39 2006
From: vasu.akkineni at gmail.com (Vasundhara Akkineni)
Date: Fri, 10 Feb 2006 09:43:39 -0500
Subject: [R] Heat Map
Message-ID: <3b67376c0602100643t317946a1o6528e4f5a1a0ec8b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060210/b8d737a4/attachment.pl

From aleid2001 at yahoo.com  Fri Feb 10 16:02:09 2006
From: aleid2001 at yahoo.com (aleid2001@yahoo.com)
Date: Fri, 10 Feb 2006 15:02:09 +0000 (GMT)
Subject: [R] mixture normal distributions
Message-ID: <20060210150209.45765.qmail@web52815.mail.yahoo.com>

Dear R helper,

I mange to transform uniform sequences to mixture
normal distributions using the following cods:


> K<-50000
>  prime<-c(29) , where 29 is prim number
> UN<-seq(1:K)%*%t(sqrt(prime))
> U1<-UN-as.integer(UN)
> e<-norMix(mu=c(-0.825,0.275), sig2 = c(0.773,0.773),
w = c(0.25,0.75), name = NULL, long.name = FALSE)
> U<-matrix(qnorMix(e,U1),K,1),

But somtimes if i use ,e.g, 23 or 11 instead of 29 it
will give me the following error. 

> K<-30000
>  prime<-c(23)
> UN<-seq(1:K)%*%t(sqrt(prime))
> U1<-UN-as.integer(UN)
> e<-norMix(mu=c(-0.825,0.275), sig2 = c(0.773,0.773),
w = c(0.25,0.75), name = NULL, long.name = FALSE)
> U<-matrix(qnorMix(e,U1),K,1)
Error in uniroot(function(l) pnorMix(obj, l) - pp[i],
interval = rq) : 
        f() values at end points not of opposite sign


I am seeking help how to avoid this error.

Many thanks for your help in advance.

My E-mail is aleid2001 at yahoo.com

Al-Eid

The university of Manchester.



From ronggui.huang at gmail.com  Fri Feb 10 16:19:59 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Fri, 10 Feb 2006 23:19:59 +0800
Subject: [R] command line completion in R?
In-Reply-To: <aabb1c3fde822af664cd4018c1a31aab@ukaachen.de>
References: <aabb1c3fde822af664cd4018c1a31aab@ukaachen.de>
Message-ID: <38b9f0350602100719t59b7f92fq@mail.gmail.com>

use JGR,see http://stats.math.uni-augsburg.de/JGR/

2006/2/10, David Ruau <druau at ukaachen.de>:
> Hi,
>
> I was wondering if there were a option to have command line completion
> in R like in the Bash shell?
>
> Best regards,
> David
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--

Deparment of Sociology
Fudan University



From droberts at montana.edu  Fri Feb 10 16:28:04 2006
From: droberts at montana.edu (Dave Roberts)
Date: Fri, 10 Feb 2006 08:28:04 -0700
Subject: [R] 3-d splinefun
In-Reply-To: <20060210044423.66035.qmail@web34702.mail.mud.yahoo.com>
References: <20060210044423.66035.qmail@web34702.mail.mud.yahoo.com>
Message-ID: <43ECB104.7040905@montana.edu>

Colby,

     Function surf() in package labdsv uses the gam() function from mgcv 
to do this in conjunction with akima.  You might want to look at that 
routine for an idea.  Currently it fits the gam as z <- gam(s(x) + s(y),
but it's possible in the mgcv version of gam to fit z <- gam(s(x,y)) as 
well.  The gam function gives a good interpolation with measured error 
and appropriate fit statistics.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
David W. Roberts                                     office 406-994-4548
Professor and Head                                      FAX 406-994-3190
Department of Ecology                         email droberts at montana.edu
Montana State University
Bozeman, MT 59717-3460


Colby Tanner wrote:
> hello,
> is it possible to do something like splinefun(x,y), but with a 3rd
> dim?
> for example, if i have a 2-dim system like:
> x<-1:100
> y<-rexp(100,1)
> func<-splinefun(x,sort(y))
> 
> func(n) # returns interpolated value of y (after sorting) given x=n
>         # i can check this by: 
> 
> plot(x,sort(y))
> lines(spline(x,sort(y)))
> 
> 
> Can i do the same thing with an x,y, and z? i have found the akima
> interp(x,y,z) for building 3-d images, but nothing about the function
> aspect.  besides building a nice 3-dim image, i would like to have a
> way of finding the interpolated z values if i give an x and y
> coordinate.  something like func(x,y) in the above example.
> 
> thank you,
> colby
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 


--



From alexfang at stat.rutgers.edu  Fri Feb 10 16:41:10 2006
From: alexfang at stat.rutgers.edu (alexfang@stat.rutgers.edu)
Date: Fri, 10 Feb 2006 15:41:10 +0000
Subject: [R] Question on big JPG plots in function warpping format
Message-ID: <1139586070.43ecb4167c833@outlier.rutgers.edu>



Hello:

I have problems generating big JPG plots in functions.  the following code runs
fine in the script:

#### runs fine in script, generate 40k "test1.jpg" in the given directory
plotPlatesAlong <- c(1:5)
plotDirPath <- paste(dataPath, "OutputPlots\\", sep="")
filename <-   paste(plotDirPath,"test1.jpg", sep="")
jpeg(file=filename)
plotHeatTrellis(dataPath, plotVariable = "Raw", plotPlatesAlong)
    # here plotHeatTrellis() generates a complicate plot, but it works
dev.off()
#### End of script


but if I wrap it in a function, it doesn't work.

######## put it in a function and run test(dataPath)
######## it will make "test1.jpg" in the given directory, but only 6k in size
######## and if I open the file, it's blank
test <- function(dataPath) {
plotPlatesAlong <- c(1:5)
plotDirPath <- paste(dataPath, "OutputPlots\\", sep="")
filename <-   paste(plotDirPath,"test1.jpg", sep="")
jpeg(file=filename) #
plotHeatTrellis(dataPath, plotVariable = "Raw", plotPlatesAlong)
dev.off()
}
######### enf of the program


I've tested the simple plot function, like 

########## works fine both with in script and function wrapping format
testplot <- function(plotDirPath) {
filename1 <- paste(plotDirPath, "test1.jpg",sep="")
jpeg(file=filename1)
plot(1:10, rnorm(10, 0), type="b")
dev.off()
}
###########

Any one have any clues, why this happen and how could I fix my code and my mine
working also in the function wrapping format?  Thanks.


best, Alex



From sentientc at gmail.com  Fri Feb 10 17:09:03 2006
From: sentientc at gmail.com (simon chou)
Date: Sat, 11 Feb 2006 05:09:03 +1300
Subject: [R]  the proper way to use panel functions in lattice package?
Message-ID: <e20b6da0602100809s12172237n76100f408066f191@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060211/a5dce9c4/attachment.pl

From ripley at stats.ox.ac.uk  Fri Feb 10 17:12:58 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 10 Feb 2006 16:12:58 +0000 (GMT)
Subject: [R] Question on big JPG plots in function warpping format
In-Reply-To: <1139586070.43ecb4167c833@outlier.rutgers.edu>
References: <1139586070.43ecb4167c833@outlier.rutgers.edu>
Message-ID: <Pine.LNX.4.64.0602101611070.15643@gannet.stats.ox.ac.uk>

Most likely this is FAQ 7.22.

althogh how we are supposed to know what plotHeatTrellis does is beyond 
me.

On Fri, 10 Feb 2006, alexfang at stat.rutgers.edu wrote:

>
>
> Hello:
>
> I have problems generating big JPG plots in functions.  the following code runs
> fine in the script:
>
> #### runs fine in script, generate 40k "test1.jpg" in the given directory
> plotPlatesAlong <- c(1:5)
> plotDirPath <- paste(dataPath, "OutputPlots\\", sep="")
> filename <-   paste(plotDirPath,"test1.jpg", sep="")
> jpeg(file=filename)
> plotHeatTrellis(dataPath, plotVariable = "Raw", plotPlatesAlong)
>    # here plotHeatTrellis() generates a complicate plot, but it works
> dev.off()
> #### End of script
>
>
> but if I wrap it in a function, it doesn't work.
>
> ######## put it in a function and run test(dataPath)
> ######## it will make "test1.jpg" in the given directory, but only 6k in size
> ######## and if I open the file, it's blank
> test <- function(dataPath) {
> plotPlatesAlong <- c(1:5)
> plotDirPath <- paste(dataPath, "OutputPlots\\", sep="")
> filename <-   paste(plotDirPath,"test1.jpg", sep="")
> jpeg(file=filename) #
> plotHeatTrellis(dataPath, plotVariable = "Raw", plotPlatesAlong)
> dev.off()
> }
> ######### enf of the program
>
>
> I've tested the simple plot function, like
>
> ########## works fine both with in script and function wrapping format
> testplot <- function(plotDirPath) {
> filename1 <- paste(plotDirPath, "test1.jpg",sep="")
> jpeg(file=filename1)
> plot(1:10, rnorm(10, 0), type="b")
> dev.off()
> }
> ###########
>
> Any one have any clues, why this happen and how could I fix my code and my mine
> working also in the function wrapping format?  Thanks.
>
>
> best, Alex
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gregor.gorjanc at gmail.com  Fri Feb 10 17:25:32 2006
From: gregor.gorjanc at gmail.com (Gregor Gorjanc)
Date: Fri, 10 Feb 2006 17:25:32 +0100
Subject: [R] Fitdistr and MLE for parameter lambda of Poisson
	distribution
In-Reply-To: <x28xsj2v08.fsf@viggo.kubism.ku.dk>
References: <43EC8889.9000607@bfro.uni-lj.si>
	<x28xsj2v08.fsf@viggo.kubism.ku.dk>
Message-ID: <43ECBE7C.7070207@bfro.uni-lj.si>

Peter Dalgaard wrote:
> Gregor Gorjanc <gregor.gorjanc at bfro.uni-lj.si> writes:
> 
> 
>>Hello!
>>
>>I would like to get MLE for parameter lambda of Poisson distribution. I 
>>can use fitdistr() for this. After looking a bit into the code of this 
>>function I can see that value for lambda and its standard error is 
>>estimated via
>>
>>estimate <- mean(x)
>>sds <- sqrt(estimate/n)
>>
>>Is this MLE? With my poor math/stat knowledge I thought that MLE for 
>>Poisson parameter is (in mixture of LaTeX code)
>>
>>l(\lambda|x) \propto \sum^n_{i=1}(-\lambda + x_iln(\lambda)).
>>
>>Is this really equal to (\sum^n_{i=1} x_i) / n
> 
> 
> Yes....
> 
> Maximizing l(lambda) is the same as maximizing
> 
> sum(x)/n ln lambda - lambda
> 
> Now either take the derivative and set equal to zero, or
>  
> rewrite further as equivalent to
> 
> ln (lambda/(sum(x)/n)) -  (lambda/(sum(x)/n))
> 
> and notice that ln(x) - x has a global maximum at x=1 (since ln is
> strictly concave and the tangent at x=1 is the line y = x - 1)
>  
> 
> (I think this is in the first 20 pages I ever read on theoretical
> statistics ...)

Thank you very much for this. It shows, how much I still need to learn.

-- 
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.



From Greg.Snow at intermountainmail.org  Fri Feb 10 17:25:51 2006
From: Greg.Snow at intermountainmail.org (Gregory Snow)
Date: Fri, 10 Feb 2006 09:25:51 -0700
Subject: [R] Transferring R results to word prosessors
Message-ID: <07E228A5BE53C24CAD490193A7381BBB12A003@LP-EXCHVS07.CO.IHC.COM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060210/4a617bb6/attachment.pl

From spencer.graves at pdf.com  Fri Feb 10 17:41:52 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 10 Feb 2006 08:41:52 -0800
Subject: [R] marginal distribution wrt time of  time series ?
In-Reply-To: <20060206140055Z4340971-32684+1799@kps4.test.onet.pl>
References: <20060206140055Z4340971-32684+1799@kps4.test.onet.pl>
Message-ID: <43ECC250.2050403@pdf.com>

	  I don't have a citation, but I think as long as the process is 
stationary and not completely deterministic, the concept of a marginal 
distribution is well defined and data from such a process will 
eventially converge to that distribution.  Of course, as the level of 
dependence increases, the number of observations to obtain reasonable 
convergence will increase.

	  Standard goodness of fit test will NOT work with dependent series, 
but that's another issue.

	  Perhaps someone else will provide further details.

	  hope this helps.
	  spencer graves

cmdrnorton at poczta.onet.pl wrote:
> Dear all,
> 
> In many papers regarding time series analysis 
> of acquired data, the authors analyze 'marginal 
> distribution' (i.e. marginal with respect to time) 
> of their data by for example checking 
> 'cdf heavy tail' hypothesis. 
> 
> For i.i.d data this is ok, but what if samples are 
> correlated, nonstationary etc.? 
> 
> Are there limit theorems which for example allow 
> us to claim that for weak dependent, stationary 
> and ergodic time series such a 'marginal distribution 
> w.r. to time' converges to marginal distribution 
> of random variable x_t , defined on basis of joint 
> distribution for (x_1,&#8230;,x_T) ? 
> 
> What if the correlation is strong (say stationary 
> and ergodic FARIMA model) ? 
> 
> Many thanks for your input
> 
> Norton
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From berwin at maths.uwa.edu.au  Fri Feb 10 18:04:33 2006
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Sat, 11 Feb 2006 01:04:33 +0800
Subject: [R] command line completion in R?
In-Reply-To: <aabb1c3fde822af664cd4018c1a31aab@ukaachen.de>
References: <aabb1c3fde822af664cd4018c1a31aab@ukaachen.de>
Message-ID: <17388.51105.739557.471775@bossiaea.maths.uwa.edu.au>

>>>>> "DR" == David Ruau <druau at ukaachen.de> writes:

    DR> Hi, I was wondering if there were a option to have command
    DR> line completion in R like in the Bash shell?
Of course, via Emacs and ESS :-)

For ESS see: http://ess.r-project.org/
For Emacs see: http://www.gnu.org/software/emacs/emacs.html

In fact, I got so used to command line completion, that I am hopeless
on any other interface to R since I cannot remeber the correct spelling
of (some) commands ;-)

HTH.

Cheers,

        Berwin

========================== Full address ============================
Berwin A Turlach                      Tel.: +61 (8) 6488 3338 (secr)   
School of Mathematics and Statistics        +61 (8) 6488 3383 (self)      
The University of Western Australia   FAX : +61 (8) 6488 1028
35 Stirling Highway                   
Crawley WA 6009                e-mail: berwin at maths.uwa.edu.au
Australia                        http://www.maths.uwa.edu.au/~berwin



From spencer.graves at pdf.com  Fri Feb 10 18:09:12 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 10 Feb 2006 09:09:12 -0800
Subject: [R] lme4: Error in getResponseFormula(form) : "Form" must be
 a	two sided formula
In-Reply-To: <40e66e0b0602061539q384ecfe0hc935e7c07010ea9@mail.gmail.com>
References: <1994687269.20060206222959@psyctc.org>
	<40e66e0b0602061539q384ecfe0hc935e7c07010ea9@mail.gmail.com>
Message-ID: <43ECC8B8.30604@pdf.com>

Hi, Doug and Chris:

	  I just got the same error message with the "lmList" example in lme4:

 >      (fm1 <- lmList(breaks ~ wool | tension, warpbreaks))
Call:
Error in getResponseFormula(form) : "Form" must be a two sided formula
 > sessionInfo()
R version 2.2.1, 2005-12-20, i386-pc-mingw32

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"

other attached packages:
      lme4   lattice    Matrix
"0.995-2" "0.12-11" "0.995-5"

	  I quit then restarted R and tried the same example in nlme:  It 
seemed to work fine.

	  Chris, have you tried this in nlme?  If you absolutely need some 
feature of lme4, at least you could do this kind of preliminary work in 
nlme, then switch to lme4 (after quitting and restarting R to avoid 
potential conflicts between nlme and lme4).

	  hope this helps.
	  spencer graves	

Douglas Bates wrote:
> Please check which packages you have attached when you call lmList. 
> That error message looks as if it is coming from the version of lmList
> that is in the nlme package, not the one in lme4.
> 
> On 2/6/06, Chris Evans <stats at psyctc.org> wrote:
> 
>>I'm sure I'm being stupid so flame away...
>>
>>R2.2.1 on Windoze (boohoo) latest updates of packages.
>>
>>I'm exploring a dataset (land) with three variables looking at an
>>narrowly unbalanced two group (GROUP) ANCOVA of a randomised
>>controlled trial analysing endpoint score (SFQ.LOCF.ENDPOINT) entering
>>the baseline score (SFQ.BASELINE) as covariate and the following work
>>fine:
>>
>>
>>>res.same <- lm(SFQ.LOCF.ENDPOINT ~ SFQ.BASELINE + GROUP,land)
>>>res.diff <- lm(SFQ.LOCF.ENDPOINT ~ SFQ.BASELINE + GROUP + SFQ.BASELINE*GROUP,land)
>>>anova(res.same,res.diff)
>>
>>I try:
>>
>>
>>>lmList(SFQ.LOCF.ENDPOINT ~ SFQ.BASELINE | GROUP, land)
>>
>>Call:
>>Error in getResponseFormula(form) : "Form" must be a two sided formula
>>
>>I'm puzzled.  That looks like a two sided formula very like the one in
>>the help for lme4 (which had been loaded) and the data look OK:
>>
>>
>>>table(land$SFQ.LOCF.ENDPOINT)
>>
>> 3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 23
>> 1  1  2  4  8  5 16  9  7 14 18  7 16  9  6  8  4  6  2  3
>>
>>>table(land$SFQ.BASELINE)
>>
>> 3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
>> 1  1  3  3  4 11  7  7 10 12  9 16 14  9  8  7  8  6  1  1
>>
>>>table(land$GROUP)
>>
>> 1  2
>>87 89
>>
>>Advice accepted gratefully and flames ruefully!
>>
>>Chris
>>
>>--
>>Chris Evans <chris at psyctc.org>
>>Consultant Psychiatrist in Psychotherapy, Rampton Hospital;
>>Research Programmes Director, Nottinghamshire NHS Trust,
>>Hon. Professor of Psychotherapy, Nottingham University,
>>Hon. SL Institute of Psychiatry
>>*** My views are my own and not representative of those institutions ***
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dbahrd at unileon.es  Fri Feb 10 18:53:01 2006
From: dbahrd at unileon.es (dbahrd@unileon.es)
Date: Fri, 10 Feb 2006 18:53:01 +0100 (CET)
Subject: [R] glmmPQL and random effects
Message-ID: <6782.143.169.45.37.1139593981.squirrel@www.unileon.es>

Hello R users,

I am trying to run a model with a binary response variable (nesting
success: 0 failure, 1 success) and 8 fixed terms. Nesting success was
examined in 72 cases in 34 territories (TER) during a 6 study years.
Territories are nested within 14 patches (PATCH). I want to run a model
taking into account these nested factors and repeated observation. To do
this, I assume that the best option is to use glmmPQL from MASS package.
Am I wrong?

In glmmPQL, I have included the random terms as follow:
random=~1|YEAR/PATCH/TER, but I am unclear if this syntax is right for
this case (?).

I would greatly appreciate any help!

Regards,

Hugo

Hugo Robles
Department of Animal Biology
University of Le??n (Spain)



From backer at psych.uib.no  Fri Feb 10 19:06:59 2006
From: backer at psych.uib.no (Tom Backer Johnsen)
Date: Fri, 10 Feb 2006 19:06:59 +0100
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <002b01c62e50$28a23be0$a600fd0a@balcarce.inta.gov.ar>
References: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
Message-ID: <5.2.0.8.2.20060210184724.020dc2c0@alf.uib.no>

At 11:42 10.02.2006 -0300, CENDOYA, Maria Gabriela wrote:
>X-UIDL: PE5!!DnS!!np3"!Sl2"!
>
>Hi Tom:
>
>               May be I didn't understand your question but, what I do to cut
>and paste results from say summary.lm, in a word processors without losing
>the nice shape of the R Console, is to choose the same type of letter in
>both,

That works -- to some extent.  But, that means that the formatting of the 
table is completely dependent on the number of spaces between the 
elements.  It is essentially the same kind of formatting of tables I did on 
my first typewriter about 40 years ago.  Any nontrivial change is 
troublesome, and you have to stick to fixed size fonts like 
Courier.  Modern editors have moved far beyond that point.

This is about generating a table in a text document from R type 
output.  This type of table increases flexibility in respect to formatting.

>               I mean, in my R Gui preferences I use Courier New size 10,
>then if I choose that type of letter in my word processors, I see the same
>in both windows.

Yes.

Tom

+----------------------------------------------------------------+
| Tom Backer Johnsen, Psychometrics Unit,  Faculty of Psychology |
| University of Bergen, Christies gt. 12, N-5015 Bergen,  NORWAY |
| Tel : +47-5558-9185                        Fax : +47-5558-9879 |
| Email : backer at psych.uib.no    URL : http://www.galton.uib.no/ |
+----------------------------------------------------------------+



From A.Robinson at ms.unimelb.edu.au  Fri Feb 10 19:18:51 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sat, 11 Feb 2006 05:18:51 +1100 (EST)
Subject: [R] Splitting printed output in Sweave
Message-ID: <57351.129.101.156.212.1139595531.squirrel@webmail.ms.unimelb.edu.au>

Dear R community,

I'm trying to figure out if there is any way to split the printed output
of some commands, for example summary.lme, so that I can intersperse
comments in Sweave.  I don't mind running the command numerous times and
masking various portions of the output, or saving the output as an object
and printing it, but I can't figure out how to do either.  Does anyone
have any suggestions?

Cheers

Andrew

Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344 4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au



From backer at psych.uib.no  Fri Feb 10 19:25:49 2006
From: backer at psych.uib.no (Tom Backer Johnsen)
Date: Fri, 10 Feb 2006 19:25:49 +0100
Subject: [R] Transferring R results to word prosessors
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBB12A003@LP-EXCHVS07.CO.IHC. COM>
Message-ID: <5.2.0.8.2.20060210191329.0217ab08@alf.uib.no>

At 09:25 10.02.2006 -0700, Gregory Snow wrote:

>Just to add a couple of thoughts to the previous suggestions.
>
>If you really want output from things like summary.lm to have tabs instead 
>of spaces then you can type:
>getAnywhere(print.summary.lm)
>
>at the R prompt and it will show you the (not quite) source of code that R 
>uses to do the printing to the console.  Copy this to your favorite text 
>editor and use it to create a new function (tabbed.summary.lm?), go 
>through and find the places where it prints output and change the spaces 
>to tabs (in some cases the inserted space is a default and you will not 
>see it directly).  You could even have the cat functions send the output 
>directly to the clipboard rather than the screen.

Interesting alternative.  However, there are at least two drawbacks for me 
at least.  First, one would have to make special versions of all the 
functions and types of output I might need.  That would easily become a 
major job, and probably not worth the trouble.  I will not need to do this 
operation often.  Second, I would have to distrubute the procedures to my 
students which I would like to avoid.

Tom


+----------------------------------------------------------------+
| Tom Backer Johnsen, Psychometrics Unit,  Faculty of Psychology |
| University of Bergen, Christies gt. 12, N-5015 Bergen,  NORWAY |
| Tel : +47-5558-9185                        Fax : +47-5558-9879 |
| Email : backer at psych.uib.no    URL : http://www.galton.uib.no/ |
+----------------------------------------------------------------+



From secchi at sssup.it  Fri Feb 10 19:44:08 2006
From: secchi at sssup.it (Angelo Secchi)
Date: Fri, 10 Feb 2006 19:44:08 +0100
Subject: [R] precision of std. error in summary
Message-ID: <20060210194408.0b15a3d2.secchi@sssup.it>


Hi,
I'm doing robust regression with the following command

rlm(dip~ind1+ind2-1,method="M",psi=psi,maxit=1000,acc=1e-15)

now when I ask for a summary

summary(rlm(dip~ind1+ind2-1,method="M",psi=psi,maxit=1000,acc=1e-15))

I get

Coefficients:
     Value       Std. Error  t value    
ind1     -0.0377      0.0000 -24203.1415
ind2      1.0370      0.0000 668735.7195

taht is no std error

I've already tryied puuting a "digits = 6" with no success.
What is the proper way to ask R to provide more digits in the std error? 
Thanks


-- 
========================================================
 Angelo Secchi                     PGP Key ID:EA280337



From gunter.berton at gene.com  Fri Feb 10 19:56:32 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 10 Feb 2006 10:56:32 -0800
Subject: [R] precision of std. error in summary
In-Reply-To: <20060210194408.0b15a3d2.secchi@sssup.it>
Message-ID: <200602101856.k1AIuWMA016464@meitner.gene.com>

1. ?options  (Look for "scipen")

2. std error = Value/t value

3. Why do you care with these values?! Seems silly. It's probably off by
more than you're worrying about due to numerical error, deviation from
assumptions, arbitrariness of tuning constants, etc.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Angelo Secchi
> Sent: Friday, February 10, 2006 10:44 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] precision of std. error in summary
> 
> 
> Hi,
> I'm doing robust regression with the following command
> 
> rlm(dip~ind1+ind2-1,method="M",psi=psi,maxit=1000,acc=1e-15)
> 
> now when I ask for a summary
> 
> summary(rlm(dip~ind1+ind2-1,method="M",psi=psi,maxit=1000,acc=1e-15))
> 
> I get
> 
> Coefficients:
>      Value       Std. Error  t value    
> ind1     -0.0377      0.0000 -24203.1415
> ind2      1.0370      0.0000 668735.7195
> 
> taht is no std error
> 
> I've already tryied puuting a "digits = 6" with no success.
> What is the proper way to ask R to provide more digits in the 
> std error? 
> Thanks
> 
> 
> -- 
> ========================================================
>  Angelo Secchi                     PGP Key ID:EA280337
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Roger.Bivand at nhh.no  Fri Feb 10 19:58:33 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Fri, 10 Feb 2006 19:58:33 +0100 (CET)
Subject: [R] Splitting printed output in Sweave
In-Reply-To: <57351.129.101.156.212.1139595531.squirrel@webmail.ms.unimelb.edu.au>
Message-ID: <Pine.LNX.4.44.0602101957080.10722-100000@reclus.nhh.no>

On Sat, 11 Feb 2006, Andrew Robinson wrote:

> Dear R community,
> 
> I'm trying to figure out if there is any way to split the printed output
> of some commands, for example summary.lme, so that I can intersperse
> comments in Sweave.  I don't mind running the command numerous times and
> masking various portions of the output, or saving the output as an object
> and printing it, but I can't figure out how to do either.  Does anyone
> have any suggestions?

?capture.output should help a good deal.

> 
> Cheers
> 
> Andrew
> 
> Andrew Robinson
> Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
> Department of Mathematics and Statistics            Fax: +61-3-8344 4599
> University of Melbourne, VIC 3010 Australia
> Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From backer at psych.uib.no  Fri Feb 10 20:04:05 2006
From: backer at psych.uib.no (Tom Backer Johnsen)
Date: Fri, 10 Feb 2006 20:04:05 +0100
Subject: [R] Transferring R results to word prosessors
In-Reply-To: <F5ED48890E2ACB468D0F3A64989D335AC99179@dc1ex3.air.org>
Message-ID: <5.2.0.8.2.20060210192900.02120f70@alf.uib.no>

At 06:09 10.02.2006 -0500, Doran, Harold wrote:

>I didn't follow this thread entirely, but I did make a LaTeX 
>recommendation and I know that wasn't what you were asking for. But, if I 
>may, let me respond to the ideas you present below in an attempt to be 
>somewhat persuasive.

No, you are correct, I was not looking for a LaTex solution.  I would never 
want to try to wean my students from an office type package.  That would 
not be worth the trouble -- for me.  They should find out about these 
things by themseves.  For my own part, I am curious, and will probably have 
a look at it.

>IMHO, this are horrible inefficiencies of SPSS and other packages, not 
>virtues. To do what you are suggesting requires that one work in two 
>environments, word and SPSS. If the researcher changes their analysis or 
>wants to tweak the data, then you rerun the analysis, go back to SPSS copy 
>and paste again. Why would someone want to do this when a much more 
>efficient method exists?

Hmm.  I would think that most users handle a number of applications for 
different purposes.  I do not expect R to handle my e-mail, nor do I expect 
a spreadsheet to do text formatting.  In itself, that is not a good 
argument IMHO.  As to the trouble with cut and paste, well, I do not do 
that operation that often.  But I do want things do be simple, simply to 
avoid wasting time explaing.

>Instead, with Sweave, you embed your R code inside the LaTeX document and 
>work in a *single* environment. There is no need to copy and paste and if 
>the data or analysis changes, you update your document very easily saving 
>time, effort, and room for errors. In addition, the tables look much 
>better than word, which (again IMHO) is an aggregiously bad program to 
>begin with.

I have always liked the formatting of the documents I have recognized as 
being formatted with LaTex.  And the Sweave concept seems very 
interesting.  I have never heard of that system before, so thank you for 
mentioning it.  I will have a look at it.

>Using this method, you can place any R code in the document, including 
>graphics, tables (say with xtable) or anything. There is never a need to 
>copy and paste as there is a wonderful, seemless effort between the two 
>programs. Because LaTeX has options for presentations, one can easily 
>create slides that look much better than ppt using a similar method saving 
>hours of effort in my experience.
>
>So, instead of getting R to do what other less sophisticated programs do, 
>which is an effort backwards into the old, and inefficient, ways of doing 
>things, R is moving progressively forward and offers these similar 
>capabilities, but in a much more efficient manner.
>
>Last, if your students are doing technical work, I would suggest they 
>should be familiar with TeX anyhow. It is free, easy to use and learn, 
>offers significant advances alongside R, and equations actually look like 
>equations. BTW, creating and numbering equations in word is about the most 
>difficult effort on earth!

This is students of psychology.  Not technical work, and the number of 
formulas per 100 research reports and paper would be closer to 1 per 100 
papers than 1 per 10 papers.  They have been using Office type programs 
almost since Kindergarten.  That is a simple fact of life (for me at least).

Tom



From secchi at sssup.it  Fri Feb 10 20:29:40 2006
From: secchi at sssup.it (Angelo Secchi)
Date: Fri, 10 Feb 2006 20:29:40 +0100
Subject: [R] precision of std. error in summary
In-Reply-To: <200602101856.k1AIuWMA016464@meitner.gene.com>
References: <20060210194408.0b15a3d2.secchi@sssup.it>
	<200602101856.k1AIuWMA016464@meitner.gene.com>
Message-ID: <20060210202940.7017d293.secchi@sssup.it>


Hi,


On Fri, 10 Feb 2006 10:56:32 -0800
Berton Gunter <gunter.berton at gene.com> wrote:

> 1. ?options  (Look for "scipen")

I'll check it

> 
> 2. std error = Value/t value
> 
> 3. Why do you care with these values?! Seems silly. It's probably off by
> more than you're worrying about due to numerical error, deviation from
> assumptions, arbitrariness of tuning constants, etc.

I need to put something in the report I'm writing and make no sense to
write std err=0.
By the way

Thanks a lot



> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>  
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
>  
>  
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Angelo Secchi
> > Sent: Friday, February 10, 2006 10:44 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] precision of std. error in summary
> > 
> > 
> > Hi,
> > I'm doing robust regression with the following command
> > 
> > rlm(dip~ind1+ind2-1,method="M",psi=psi,maxit=1000,acc=1e-15)
> > 
> > now when I ask for a summary
> > 
> > summary(rlm(dip~ind1+ind2-1,method="M",psi=psi,maxit=1000,acc=1e-15))
> > 
> > I get
> > 
> > Coefficients:
> >      Value       Std. Error  t value    
> > ind1     -0.0377      0.0000 -24203.1415
> > ind2      1.0370      0.0000 668735.7195
> > 
> > taht is no std error
> > 
> > I've already tryied puuting a "digits = 6" with no success.
> > What is the proper way to ask R to provide more digits in the 
> > std error? 
> > Thanks
> > 
> > 
> > -- 
> > ========================================================
> >  Angelo Secchi                     PGP Key ID:EA280337
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
>



From backer at psych.uib.no  Fri Feb 10 20:45:44 2006
From: backer at psych.uib.no (Tom Backer Johnsen)
Date: Fri, 10 Feb 2006 20:45:44 +0100
Subject: [R] Transferring R results to word prosessors
In-Reply-To: <Pine.LNX.4.44.0602101004230.11855-100000@reclus.nhh.no>
References: <5.2.0.8.2.20060209212028.020ec3d8@alf.uib.no>
Message-ID: <5.2.0.8.2.20060210200957.0216c5d8@alf.uib.no>

Thank you all for very useful and interesting responses.  After reading the 
comments and after some experiments, I added the following to a text I will 
be handing out to the students (I would not mind comments):

<QUOTE>The contents of the text output from R may be very sophisticated, 
but the formatting of the texts is always very simple, with absolutely no 
frills.  For instance, all formatting of columns is managed with spaces or 
blanks, no tabs, nothing extra apart from line feeds.  This means that 
transferring some types of output, like the summary of the multiple 
regression in part 7.4 directly to MS Word or any other wordprocessor would 
be far from optimal.  To make a decent table for presenting results in a 
paper in APA format, we need a "table" in the word processing sense, an 
arrangement of things in rows and columns.  With output as plain as in R, a 
lot of fiddling would be necessary after a direct copy and paste of the 
text into MS Word.  So, we need a better solution.

The steps involved are really quite simple, the information is transferred 
via a speadsheet:

1. Write the output to the clipboard in HTML format (that is the same 
format as used for writing web pages)

2. When you are finished with that, paste the contents of the clipboard 
into a spreadsheet (e.g. Excel).  This automatically reformats HTML to 
something that both the spreadsheet and the word processor (e.g. MS Word) 
can handle.

3. Copy and paste what you need from the spreadsheet to the document.

The last two steps are the same as when using Statistica or SPSS in a 
anyhow.  Especially SPSS has a tendency include too much formatting when 
pasting, and then Excel is a useful stepping stone to strip off the frills.

The main difference is in the first step.  What we need there is to write 
the output from R to the clipboard in a format that Excel recognizes as 
something with columns and rows.  For an example, consider the "summary ()" 
output from the multiple regression in part 7.4 above.

First, you have to make the library "R2HTML" available to the session:

 > library (R2HTML)

You only need to do this once in a session.  If this package is not 
installed, have a look at part 9 above.  Then we need to attach the data 
set and do the multiple regression:

 > attach (attitude)
 > Results <- lm (rating ~ complaints + privileges + learning)
 > HTML (summary (Results, digits=4), file("clipboard", "w"), append=FALSE)
 > detach (attitude)

If you do this more than a few times, it might be a good idea to write a 
function as a replacement for the HTML command with a reasonable name, e.g. 
"ToClip".  The last command could then be replaced by:

 > ToClip (summary (Results, digits=4))

Which is much simpler.  In any case, the results are now writtten to the 
clipboard.  Open Excel, and paste the contents into a worksheet.  Select 
what you want, copy it to the clipboard, and then open your document where 
the paper is found.  Locate the place where you want the table, and paste 
the clipboard there. </QUOTE>

After showing how the table looks, I mention that some details will have to 
be fixed, like conversion of the lower part of the output to text, removing 
blank rows, adding borders etc., plus rewriting the p value which is in 
scientific notation.  It is still not in an APA format, but very much 
better than it would bave been with a simple "copy and past" operation.

Tom



From A.Robinson at ms.unimelb.edu.au  Fri Feb 10 20:56:36 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sat, 11 Feb 2006 06:56:36 +1100 (EST)
Subject: [R] Splitting printed output in Sweave
In-Reply-To: <Pine.LNX.4.44.0602101957080.10722-100000@reclus.nhh.no>
References: <57351.129.101.156.212.1139595531.squirrel@webmail.ms.unimelb.edu.au>
	<Pine.LNX.4.44.0602101957080.10722-100000@reclus.nhh.no>
Message-ID: <57486.129.101.156.212.1139601396.squirrel@webmail.ms.unimelb.edu.au>

Roger,

that's beautiful -- thanks!

Andrew


On Sat, February 11, 2006 5:58 am, Roger Bivand said:
> On Sat, 11 Feb 2006, Andrew Robinson wrote:
>
>> Dear R community,
>>
>> I'm trying to figure out if there is any way to split the printed output
>> of some commands, for example summary.lme, so that I can intersperse
>> comments in Sweave.  I don't mind running the command numerous times and
>> masking various portions of the output, or saving the output as an
>> object
>> and printing it, but I can't figure out how to do either.  Does anyone
>> have any suggestions?
>
> ?capture.output should help a good deal.
>
>>
>> Cheers
>>
>> Andrew
>>
>> Andrew Robinson
>> Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
>> Department of Mathematics and Statistics            Fax: +61-3-8344 4599
>> University of Melbourne, VIC 3010 Australia
>> Email: a.robinson at ms.unimelb.edu.au    Website:
>> http://www.ms.unimelb.edu.au
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>


Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344 4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au



From Achim.Zeileis at wu-wien.ac.at  Fri Feb 10 21:06:01 2006
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Fri, 10 Feb 2006 21:06:01 +0100
Subject: [R] precision of std. error in summary
In-Reply-To: <20060210202940.7017d293.secchi@sssup.it>
References: <20060210194408.0b15a3d2.secchi@sssup.it>
	<200602101856.k1AIuWMA016464@meitner.gene.com>
	<20060210202940.7017d293.secchi@sssup.it>
Message-ID: <20060210210601.74549fb2.Achim.Zeileis@wu-wien.ac.at>

On Fri, 10 Feb 2006 20:29:40 +0100 Angelo Secchi wrote:

> 
> Hi,
> 
> 
> On Fri, 10 Feb 2006 10:56:32 -0800
> Berton Gunter <gunter.berton at gene.com> wrote:
> 
> > 1. ?options  (Look for "scipen")
> 
> I'll check it
> 
> > 
> > 2. std error = Value/t value
> > 
> > 3. Why do you care with these values?! Seems silly. It's probably
> > off by more than you're worrying about due to numerical error,
> > deviation from assumptions, arbitrariness of tuning constants, etc.
> 
> I need to put something in the report I'm writing and make no sense to
> write std err=0.

You are aware that you can not only print the summary to the screen,
but also compute with the result, right? Look at
  summary(obj)$coefficients
in particular
  summary(obj)$coefficients[,2]
Z

> By the way
> 
> Thanks a lot
> 
> 
> 
> > 
> > -- Bert Gunter
> > Genentech Non-Clinical Statistics
> > South San Francisco, CA
> >  
> > "The business of the statistician is to catalyze the scientific
> > learning process."  - George E. P. Box
> >  
> >  
> > 
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch 
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Angelo
> > > Secchi Sent: Friday, February 10, 2006 10:44 AM
> > > To: r-help at stat.math.ethz.ch
> > > Subject: [R] precision of std. error in summary
> > > 
> > > 
> > > Hi,
> > > I'm doing robust regression with the following command
> > > 
> > > rlm(dip~ind1+ind2-1,method="M",psi=psi,maxit=1000,acc=1e-15)
> > > 
> > > now when I ask for a summary
> > > 
> > > summary(rlm(dip~ind1
> > > +ind2-1,method="M",psi=psi,maxit=1000,acc=1e-15))
> > > 
> > > I get
> > > 
> > > Coefficients:
> > >      Value       Std. Error  t value    
> > > ind1     -0.0377      0.0000 -24203.1415
> > > ind2      1.0370      0.0000 668735.7195
> > > 
> > > taht is no std error
> > > 
> > > I've already tryied puuting a "digits = 6" with no success.
> > > What is the proper way to ask R to provide more digits in the 
> > > std error? 
> > > Thanks
> > > 
> > > 
> > > -- 
> > > ========================================================
> > >  Angelo Secchi                     PGP Key ID:EA280337
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > > http://www.R-project.org/posting-guide.html
> > > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From backer at psych.uib.no  Fri Feb 10 21:21:57 2006
From: backer at psych.uib.no (Tom Backer Johnsen)
Date: Fri, 10 Feb 2006 21:21:57 +0100
Subject: [R] Transferring R results to word prosessors
In-Reply-To: <43EBCBFB.7090708@vanderbilt.edu>
References: <5.2.0.8.2.20060209212028.020ec3d8@alf.uib.no>
	<5.2.0.8.2.20060209212028.020ec3d8@alf.uib.no>
Message-ID: <5.2.0.8.2.20060210205556.02160bd8@alf.uib.no>

At 17:10 09.02.2006 -0600, you wrote:
>Tom Backer Johnsen wrote:
>>There has been an incredible number of responses in a short time, with a 
>>number of different suggestions.  With hindsight, I must admit I have not 
>>been quite clear, so additional (somewhat lengthy) explanation is needed.
>>I want to use R in an introductory course on multiple regression (among 
>>other things) starting in two weeks time for students of psychology at my 
>>University.  These students are very much used to MS Word, it is in 
>>principle possible to get them to adopt OpenOffice (which I would like 
>>to), but I regard Latex to be out of the question.
>>One of the things they are drilled on is that they have to produce term 
>>papers etc. based on a template in APA (American Psychological Association)
>
>There's nothing wrong with the APA template; it will work well with LaTeX.

I am sure you are right.  But I do not think it is worth the trouble, 
neither for me nor the students in respect to this course, to force them 
into learn LaTex.  They have been using this type of package almost since 
kindergarten (well, not quite).  For me, it is a MUCH simple solution to 
show them how the transfer can be done to with simple copy and past 
operations.  They will not be doing that operation very often anyhow.

>>format.  Among other things, this means that the document must be all 
>>text apart from the graphics.  Therefore any kind of solution involving 
>>pictures of tables rather than the tables / results as text is out.  Same 
>>holds for all kinds of "mixed" output, so combinations of text with PDF 
>>elements.  Besides, the tables in R are not that nice in respect to the 
>>formatting.  Since the content is the main thing anyhow, that does not
>
>You have not seen the various R/latex interfaces for tables then.

Correct.  But I intend to have a look in any case.  Sweave has been 
mentioned, which do you recommend?  Are there others?

>>matter.  In most cases, the tables have to be tweaked as least to some 
>>extent.  Given my inexperience, it seems that the R2HTML path is so far 
>>the most promising (but for me untried so far)
>>One of the nice things about SPSS and Statistica is that it is VERY easy 
>>to copy and paste output from the program right into the paper / 
>>paper.  A commmon trick when using SPSS is to first paste the output into 
>>a spreadsheet (e.g. Excel), and from there into the document.  In any 
>>case, the outcome is that the output is a table (not a table in the R 
>>sense) in the document, which may be edited, tweaked, adding borders 
>>etc..  So, what I am looking for is a process starting with output from R 
>>(like what is obtained from the summary(lm (...)) command, the output of 
>>a correlation matrix, or ...) that could end up as a table in MS Word 
>>(and probably in OpenOffice as well) in the smallest number of steps.
>
>It sounds as if you are not interested in teaching students the principles 
>of reproducible research, which is too bad. [See references towards the 
>bottom of http://biostat.mc.vanderbilt.edu/StatReport].

You are jumping at conclusions.  There is after all a difference between 
"not interesting in" and "not knowing about".  That pointer was very nice 
and the page had lots of useful information.  Thank you!

>>For instance, if there was an option in R which had the effect that the 
>>spaces separating things (e.g. the columns in the output of a correlation 
>>matrix or the elements in an ANOVA table) were replaced by tabs, 
>>everything would be very simple.  Then, you could (a) paste the output 
>>into the document, and (b) do a simple text-to-table conversion in Word 
>>after the paste.  A simple affair with a few simple steps.  Ideally, what 
>>I want for me and my students is this or a similar solution to this 
>>problem.  That might be a good selling argument for R as well.
>>Tom
>
>--
>Frank E Harrell Jr   Professor and Chair           School of Medicine
>                      Department of Biostatistics   Vanderbilt University

Tom



From Eric.Archer at noaa.gov  Fri Feb 10 21:30:17 2006
From: Eric.Archer at noaa.gov (Eric Archer)
Date: Fri, 10 Feb 2006 12:30:17 -0800
Subject: [R] Creating multiple copies of rows in data frames
Message-ID: <43ECF7D9.5040300@noaa.gov>

ListeRs,

Within the last two months, I thought I saw mention of an R function 
that would create a new data frame composed of duplicates or multiple 
copies of rows of an input data frame given one or several columns of 
values indicating how many times each row should be copied.  As a simple 
example, given a dataframe:

 > in.df
  x y
1 A 1
2 B 2
3 C 3

"func.name (in.df, in.df$y)" would produce something like:

  x y
1 A 1
2 B 2
3 B 2
4 C 3
5 C 3
6 C 3

For the life of me, I can't remember what that function was called, nor 
can I find it using help.search or RSiteSearch on terms like "duplicate" 
or "copy".  Perhaps it had another primary purpose, but this was a 
side-effect or secondary capability.  Was I hallucinating, or does this 
exist as a function in base R?  Or, will I have to make one with "rep"?
Thanks in advance!

e.

-- 

Eric Archer, Ph.D.
NOAA-SWFSC
8604 La Jolla Shores Dr.
La Jolla, CA 92037
858-546-7121,7003(FAX)
eric.archer at noaa.gov


"Lighthouses are more helpful than churches."
    - Benjamin Franklin

"Cogita tute" - Think for yourself



From sundar.dorai-raj at pdf.com  Fri Feb 10 21:45:17 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri, 10 Feb 2006 14:45:17 -0600
Subject: [R] Creating multiple copies of rows in data frames
In-Reply-To: <43ECF7D9.5040300@noaa.gov>
References: <43ECF7D9.5040300@noaa.gov>
Message-ID: <43ECFB5D.6020401@pdf.com>



Eric Archer wrote:
> ListeRs,
> 
> Within the last two months, I thought I saw mention of an R function 
> that would create a new data frame composed of duplicates or multiple 
> copies of rows of an input data frame given one or several columns of 
> values indicating how many times each row should be copied.  As a simple 
> example, given a dataframe:
> 
>  > in.df
>   x y
> 1 A 1
> 2 B 2
> 3 C 3
> 
> "func.name (in.df, in.df$y)" would produce something like:
> 
>   x y
> 1 A 1
> 2 B 2
> 3 B 2
> 4 C 3
> 5 C 3
> 6 C 3
> 
> For the life of me, I can't remember what that function was called, nor 
> can I find it using help.search or RSiteSearch on terms like "duplicate" 
> or "copy".  Perhaps it had another primary purpose, but this was a 
> side-effect or secondary capability.  Was I hallucinating, or does this 
> exist as a function in base R?  Or, will I have to make one with "rep"?
> Thanks in advance!
> 
> e.
> 


As you mentioned, ?rep should be sufficient:

in.df <- data.frame(x = LETTERS[1:3], y = 1:3)
out.df <- in.df[rep(seq(nrow(in.df)), in.df$y), ]

Then if you want to re-name the row.names

row.names(out.df) <- seq(nrow(out.df))

--sundar



From crizkall at purdue.edu  Fri Feb 10 21:44:33 2006
From: crizkall at purdue.edu (Rizkalla, Carol Elisabeth)
Date: Fri, 10 Feb 2006 15:44:33 -0500
Subject: [R] Tree vs. Rpart
Message-ID: <BD3CD0CBA05F8941B80C4B6A867D53C607AC8B44@EXCH01.purdue.lcl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060210/09eb1b5c/attachment.pl

From maechler at stat.math.ethz.ch  Fri Feb 10 22:20:11 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 10 Feb 2006 22:20:11 +0100
Subject: [R] mixture normal distributions
In-Reply-To: <20060210150209.45765.qmail@web52815.mail.yahoo.com>
References: <20060210150209.45765.qmail@web52815.mail.yahoo.com>
Message-ID: <17389.907.24904.310828@stat.math.ethz.ch>


>> Dear R helper,
>> I mange to transform uniform sequences to mixture
>> normal distributions using the following cods:

you forgot to mention the important fact that you are working
with package  "nor1mix"  (of which I am the maintainer which you
could have seen from   library(help = nor1mix)  or 
packageDescription("nor1mix")


>> > K<-50000
>> >  prime<-c(29) , where 29 is prim number
>> > UN<-seq(1:K)%*%t(sqrt(prime))
>> > U1<-UN-as.integer(UN)
>> > e<-norMix(mu=c(-0.825,0.275), sig2 = c(0.773,0.773),
>> w = c(0.25,0.75), name = NULL, long.name = FALSE)
>> > U<-matrix(qnorMix(e,U1),K,1),

This looks like you want to generate pseudo-random values from
the mixture distribution.

However by the slowest most possible way:  qnorMix() is really
slow because it calls uniroot() for each value.

rnorMix() will generate random values distributed according to
the normal mixture very very efficiently (particularly compared
to using qnorMix()).

But indeed, you have detected a bug in qnorMix() 
(that happens pretty rarely).  Indeed your example also shows
that the algorithm can be much improved in some cases.

The next verion of nor1mix  should  contain a more "robust"
qnorMix() function.



>> But somtimes if i use ,e.g, 23 or 11 instead of 29 it
>> will give me the following error. 
>> 
>> > K<-30000
>> >  prime<-c(23)
>> > UN<-seq(1:K)%*%t(sqrt(prime))
>> > U1<-UN-as.integer(UN)
>> > e<-norMix(mu=c(-0.825,0.275), sig2 = c(0.773,0.773),
>> w = c(0.25,0.75), name = NULL, long.name = FALSE)
>> > U<-matrix(qnorMix(e,U1),K,1)
>> Error in uniroot(function(l) pnorMix(obj, l) - pp[i],
>> interval = rq) : 
>>         f() values at end points not of opposite sign
>> 
>> 
>> I am seeking help how to avoid this error.
>> 
>> Many thanks for your help in advance.
>> 
>> My E-mail is aleid2001 at yahoo.com
>> 
>> Al-Eid
>> 
>> The university of Manchester.



From ligges at statistik.uni-dortmund.de  Fri Feb 10 22:53:32 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 10 Feb 2006 22:53:32 +0100
Subject: [R] plot(...., type = "h", lwd = 10) results in square tops
In-Reply-To: <s3ec993d.073@ffdata.setur.fo>
References: <s3ec993d.073@ffdata.setur.fo>
Message-ID: <43ED0B5C.8040108@statistik.uni-dortmund.de>

Luis Ridao Cruz wrote:

> R-help,
> 
> I'm using the following code:
> 
> plot(1985:2005, data, type = "h", lwd = 10) 
>
> which should plot histogram like figure.
> The bar tops are square and I was wondering if
> it is intended to be so or not (I can of course
> use barplot instead).

For the line endings see ?par and its argument "lend".

Uwe Ligges

> 
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Fri Feb 10 23:16:10 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 10 Feb 2006 23:16:10 +0100
Subject: [R] mixture normal distributions
In-Reply-To: <17389.907.24904.310828@stat.math.ethz.ch>
References: <20060210150209.45765.qmail@web52815.mail.yahoo.com>
	<17389.907.24904.310828@stat.math.ethz.ch>
Message-ID: <17389.4266.716301.979914@stat.math.ethz.ch>

>>>>> "Martin" == Martin Maechler <maechler at stat.math.ethz.ch>
>>>>>     on Fri, 10 Feb 2006 22:20:11 +0100 writes:

    >>> Dear R helper, I mange to transform uniform sequences to
    >>> mixture normal distributions using the following cods:

    Martin> you forgot to mention the important fact that you
    Martin> are working with package "nor1mix" (of which I am
    Martin> the maintainer which you could have seen from
    Martin> library(help = nor1mix) or
    Martin> packageDescription("nor1mix")


    >>> > K<-50000 > prime<-c(29) , where 29 is prim number >
    >>> UN<-seq(1:K)%*%t(sqrt(prime)) > U1<-UN-as.integer(UN) >
    >>> e<-norMix(mu=c(-0.825,0.275), sig2 = c(0.773,0.773), w =
    >>> c(0.25,0.75), name = NULL, long.name = FALSE) >
    >>> U<-matrix(qnorMix(e,U1),K,1),

    Martin> This looks like you want to generate pseudo-random
    Martin> values from the mixture distribution.

    Martin> However by the slowest most possible way: qnorMix()
    Martin> is really slow because it calls uniroot() for each
    Martin> value.

    Martin> rnorMix() will generate random values distributed
    Martin> according to the normal mixture very very
    Martin> efficiently (particularly compared to using
    Martin> qnorMix()).

    Martin> But indeed, you have detected a bug in qnorMix()
    Martin> (that happens pretty rarely).  Indeed your example
    Martin> also shows that the algorithm can be much improved
    Martin> in some cases.

    Martin> The next verion of nor1mix should contain a more
    Martin> "robust" qnorMix() function.

in the mean time, you can use the following which already fixes
the problem you found :

qnorMix <- function(obj, p)
{
  if (!is.norMix(obj))
     stop("'obj' must be a 'Normal Mixture' object!")
  mu <- obj[, "mu"]
  sd <- sqrt(obj[, "sig2"])
  k <- nrow(obj)# = #{components}
  if(k == 1) # one component
      return(qnorm(p, mu, sd))

  ## else

  ## vectorize in `p' :
  r <- p
  left  <- p <= 0 ; r[left] <- -Inf
  right <- p >= 1 ; r[right] <- Inf
  imid <- which(mid <- !left & !right) # 0 < p < 1
  ## p[] increasing for easier root finding start:
  p <- sort(p[mid], index.return = TRUE)
  ip <- imid[p$ix]
  pp <- p$x
  for(i in seq(along=pp)) {
      rq <- range(qnorm(pp[i], mu, sd))
      ## since pp[] is increasing, we can start from last 'root':
      if(i > 1) rq[1] <- root
      ## make sure, 'lower' is such that f(lower) < 0 :
      delta.r <- 0.01*abs(rq[1])
      ff <- function(l) pnorMix(obj,l) - pp[i]
      while(ff(rq[1]) > 0) rq[1] <- rq[1] - delta.r

      root <- uniroot(ff, interval = rq)$root
      r[ip[i]] <- root
  }
  r
}


I hope this helps you.




    >>> But somtimes if i use ,e.g, 23 or 11 instead of 29 it
    >>> will give me the following error.
    >>> 
    >>> > K<-30000 > prime<-c(23) >
    >>> UN<-seq(1:K)%*%t(sqrt(prime)) > U1<-UN-as.integer(UN) >
    >>> e<-norMix(mu=c(-0.825,0.275), sig2 = c(0.773,0.773), w =
    >>> c(0.25,0.75), name = NULL, long.name = FALSE) >
    >>> U<-matrix(qnorMix(e,U1),K,1) Error in
    >>> uniroot(function(l) pnorMix(obj, l) - pp[i], interval =
    >>> rq) : f() values at end points not of opposite sign
    >>> 
    >>> 
    >>> I am seeking help how to avoid this error.
    >>> 
    >>> Many thanks for your help in advance.
    >>> 
    >>> My E-mail is aleid2001 at yahoo.com
    >>> 
    >>> Al-Eid
    >>> 
    >>> The university of Manchester.

    Martin> ______________________________________________
    Martin> R-help at stat.math.ethz.ch mailing list
    Martin> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE
    Martin> do read the posting guide!
    Martin> http://www.R-project.org/posting-guide.html



From Patricia.Kipnis at kp.org  Fri Feb 10 18:06:13 2006
From: Patricia.Kipnis at kp.org (Patricia.Kipnis@kp.org)
Date: Fri, 10 Feb 2006 09:06:13 -0800
Subject: [R] Job opening: Statistician/SAS and S+ programmer
Message-ID: <OFE1676B3B.AB0815D3-ON88257111.005DAA6F-88257111.005DF349@KP.ORG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060210/e4ac014f/attachment.pl

From gregor.gorjanc at gmail.com  Sat Feb 11 00:27:02 2006
From: gregor.gorjanc at gmail.com (Gregor Gorjanc)
Date: Sat, 11 Feb 2006 00:27:02 +0100
Subject: [R] Lmer with weights
Message-ID: <43ED2146.3020201@bfro.uni-lj.si>

Hello!

I would like to use lmer() to fit data, which are some estimates and 
their standard errors i.e kind of a "meta" analysis. I wonder if weights 
argument is the right one to use to include uncertainty (standard 
errors) of "data" into the model. I would like to use lmer(), since I 
would like to have a "freedom" in modeling, if this is at all possible.

For example we can take schools data by Gelman from R2WinBUGS package. 
As you can see bellow use of weights argument did not had influence on 
results.

I do not know if my specification of weights i.e. 1 / sd^2 is ok. Under 
least squares one minimizes sum(e^2_i) or sum(w_i * e^2_i) with weighted 
LS. If I consider that \sigma_i represents uncertainty in my "data" then 
e'_i = e_i / \sigma_i and we minimize sum(e'^2_i) = sum((e_i / 
\sigma_i)^2) = sum(e_i * \sigma^-2_i). Therefore weights i.e. w_i are 
equal to 1 / \sigma^2_i.

Can anyone help me with this issue?

Thank you very much!

 > library("R2WinBUGS")
 > data(schools)
 > schools
 > attach(schools)
 >
 > ## Fit simple model without "weights"
 > lmer(estimate ~ 1 + (1 | school))
Linear mixed-effects model fit by REML
Formula: estimate ~ 1 + (1 | school)
     AIC    BIC  logLik MLdeviance REMLdeviance
  58.882 59.041 -27.441     59.278       54.882
Random effects:
  Groups   Name        Variance Std.Dev.
  school   (Intercept) 80.4     8.97
  Residual             30.1     5.49
# of obs: 8, groups: school, 8

Fixed effects:
             Estimate Std. Error t value
(Intercept)     8.82       3.72    2.37

 > ## Fit simple model with "weights"
 > lmer(estimate ~ 1 + (1 | school), weights = ~ 1 / (sd^2))
Linear mixed-effects model fit by REML
Formula: estimate ~ 1 + (1 | school)
     AIC    BIC  logLik MLdeviance REMLdeviance
  58.882 59.041 -27.441     59.278       54.882
Random effects:
  Groups   Name        Variance Std.Dev.
  school   (Intercept) 80.4     8.97
  Residual             30.1     5.49
# of obs: 8, groups: school, 8

Fixed effects:
             Estimate Std. Error t value
(Intercept)     8.82       3.72    2.37

-- 
Lep pozdrav / With regards,
     Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si 

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888 

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
  you have no certainty until you try." Sophocles ~ 450 B.C.



From ggrothendieck at gmail.com  Sat Feb 11 02:26:24 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 10 Feb 2006 20:26:24 -0500
Subject: [R] Transferring R results to word prosessors
In-Reply-To: <5.2.0.8.2.20060210200957.0216c5d8@alf.uib.no>
References: <5.2.0.8.2.20060209212028.020ec3d8@alf.uib.no>
	<Pine.LNX.4.44.0602101004230.11855-100000@reclus.nhh.no>
	<5.2.0.8.2.20060210200957.0216c5d8@alf.uib.no>
Message-ID: <971536df0602101726l7b83be82sca44020c5cca230c@mail.gmail.com>

Given that this may very well be the most common use of the
R2HTML package I wonder if the R2HTML package developer would
be interested in providing an HTML2clip convenience wrapper
as part of the R2HTML package like this:

   HTML2clip <- function(x, file. = file("clipboard", "w"), append = FALSE, ...)
     HTML(x, file = file., append = append, ...)

so that one could just write:

   HTML2clip(summary(lm(rating ~., attitude)))

On 2/10/06, Tom Backer Johnsen <backer at psych.uib.no> wrote:
> Thank you all for very useful and interesting responses.  After reading the
> comments and after some experiments, I added the following to a text I will
> be handing out to the students (I would not mind comments):
>
> <QUOTE>The contents of the text output from R may be very sophisticated,
> but the formatting of the texts is always very simple, with absolutely no
> frills.  For instance, all formatting of columns is managed with spaces or
> blanks, no tabs, nothing extra apart from line feeds.  This means that
> transferring some types of output, like the summary of the multiple
> regression in part 7.4 directly to MS Word or any other wordprocessor would
> be far from optimal.  To make a decent table for presenting results in a
> paper in APA format, we need a "table" in the word processing sense, an
> arrangement of things in rows and columns.  With output as plain as in R, a
> lot of fiddling would be necessary after a direct copy and paste of the
> text into MS Word.  So, we need a better solution.
>
> The steps involved are really quite simple, the information is transferred
> via a speadsheet:
>
> 1. Write the output to the clipboard in HTML format (that is the same
> format as used for writing web pages)
>
> 2. When you are finished with that, paste the contents of the clipboard
> into a spreadsheet (e.g. Excel).  This automatically reformats HTML to
> something that both the spreadsheet and the word processor (e.g. MS Word)
> can handle.
>
> 3. Copy and paste what you need from the spreadsheet to the document.
>
> The last two steps are the same as when using Statistica or SPSS in a
> anyhow.  Especially SPSS has a tendency include too much formatting when
> pasting, and then Excel is a useful stepping stone to strip off the frills.
>
> The main difference is in the first step.  What we need there is to write
> the output from R to the clipboard in a format that Excel recognizes as
> something with columns and rows.  For an example, consider the "summary ()"
> output from the multiple regression in part 7.4 above.
>
> First, you have to make the library "R2HTML" available to the session:
>
>  > library (R2HTML)
>
> You only need to do this once in a session.  If this package is not
> installed, have a look at part 9 above.  Then we need to attach the data
> set and do the multiple regression:
>
>  > attach (attitude)
>  > Results <- lm (rating ~ complaints + privileges + learning)
>  > HTML (summary (Results, digits=4), file("clipboard", "w"), append=FALSE)
>  > detach (attitude)
>
> If you do this more than a few times, it might be a good idea to write a
> function as a replacement for the HTML command with a reasonable name, e.g.
> "ToClip".  The last command could then be replaced by:
>
>  > ToClip (summary (Results, digits=4))
>
> Which is much simpler.  In any case, the results are now writtten to the
> clipboard.  Open Excel, and paste the contents into a worksheet.  Select
> what you want, copy it to the clipboard, and then open your document where
> the paper is found.  Locate the place where you want the table, and paste
> the clipboard there. </QUOTE>
>
> After showing how the table looks, I mention that some details will have to
> be fixed, like conversion of the lower part of the output to text, removing
> blank rows, adding borders etc., plus rewriting the p value which is in
> scientific notation.  It is still not in an APA format, but very much
> better than it would bave been with a simple "copy and past" operation.
>
> Tom
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Sat Feb 11 02:39:02 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 10 Feb 2006 20:39:02 -0500
Subject: [R] Transferring R results to word prosessors
In-Reply-To: <5.2.0.8.2.20060210205556.02160bd8@alf.uib.no>
References: <5.2.0.8.2.20060209212028.020ec3d8@alf.uib.no>
	<43EBCBFB.7090708@vanderbilt.edu>
	<5.2.0.8.2.20060210205556.02160bd8@alf.uib.no>
Message-ID: <971536df0602101739v13bbe04dldb5c130c0c94041b@mail.gmail.com>

On 2/10/06, Tom Backer Johnsen <backer at psych.uib.no> wrote:
> At 17:10 09.02.2006 -0600, you wrote:
> >Tom Backer Johnsen wrote:
> >>There has been an incredible number of responses in a short time, with a
> >>number of different suggestions.  With hindsight, I must admit I have not
> >>been quite clear, so additional (somewhat lengthy) explanation is needed.
> >>I want to use R in an introductory course on multiple regression (among
> >>other things) starting in two weeks time for students of psychology at my
> >>University.  These students are very much used to MS Word, it is in
> >>principle possible to get them to adopt OpenOffice (which I would like
> >>to), but I regard Latex to be out of the question.
> >>One of the things they are drilled on is that they have to produce term
> >>papers etc. based on a template in APA (American Psychological Association)
> >
> >There's nothing wrong with the APA template; it will work well with LaTeX.
>
> I am sure you are right.  But I do not think it is worth the trouble,
> neither for me nor the students in respect to this course, to force them
> into learn LaTex.  They have been using this type of package almost since
> kindergarten (well, not quite).  For me, it is a MUCH simple solution to
> show them how the transfer can be done to with simple copy and past
> operations.  They will not be doing that operation very often anyhow.
>
> >>format.  Among other things, this means that the document must be all
> >>text apart from the graphics.  Therefore any kind of solution involving
> >>pictures of tables rather than the tables / results as text is out.  Same
> >>holds for all kinds of "mixed" output, so combinations of text with PDF
> >>elements.  Besides, the tables in R are not that nice in respect to the
> >>formatting.  Since the content is the main thing anyhow, that does not
> >
> >You have not seen the various R/latex interfaces for tables then.
>
> Correct.  But I intend to have a look in any case.  Sweave has been
> mentioned, which do you recommend?  Are there others?
>
> >>matter.  In most cases, the tables have to be tweaked as least to some
> >>extent.  Given my inexperience, it seems that the R2HTML path is so far
> >>the most promising (but for me untried so far)
> >>One of the nice things about SPSS and Statistica is that it is VERY easy
> >>to copy and paste output from the program right into the paper /
> >>paper.  A commmon trick when using SPSS is to first paste the output into
> >>a spreadsheet (e.g. Excel), and from there into the document.  In any
> >>case, the outcome is that the output is a table (not a table in the R
> >>sense) in the document, which may be edited, tweaked, adding borders
> >>etc..  So, what I am looking for is a process starting with output from R
> >>(like what is obtained from the summary(lm (...)) command, the output of
> >>a correlation matrix, or ...) that could end up as a table in MS Word
> >>(and probably in OpenOffice as well) in the smallest number of steps.
> >
> >It sounds as if you are not interested in teaching students the principles
> >of reproducible research, which is too bad. [See references towards the
> >bottom of http://biostat.mc.vanderbilt.edu/StatReport].
>
> You are jumping at conclusions.  There is after all a difference between
> "not interesting in" and "not knowing about".  That pointer was very nice
> and the page had lots of useful information.  Thank you!
>

Also I don't think that that approach is limited to LaTeX.  As I
mentioned in this thread, Word supports linking and embedding of objects
so that when the object changes the Word document dynamically
changes as well.  This may actually be superior to what LaTeX can do
in the sense that with LaTeX you have to regenerate the document
after you have created the LaTeX output but with linking and embedding
you don't -- its dynamic.



From jemoore at duke.edu  Sat Feb 11 03:23:26 2006
From: jemoore at duke.edu (Jeffrey Moore)
Date: Fri, 10 Feb 2006 21:23:26 -0500
Subject: [R] how do I "relate" tables in R?
Message-ID: <200602110225.k1B2PF04024865@gallun.acpub.duke.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060210/b49a7611/attachment.pl

From alexfang at stat.rutgers.edu  Sat Feb 11 03:33:06 2006
From: alexfang at stat.rutgers.edu (Alex)
Date: Fri, 10 Feb 2006 21:33:06 -0500 (EST)
Subject: [R] Question on big JPG plots in function warpping format
In-Reply-To: <Pine.LNX.4.64.0602101611070.15643@gannet.stats.ox.ac.uk>
Message-ID: <Pine.SOL.4.10.10602102132480.11759-100000@stat.rutgers.edu>


thanks, it works.

best, Alex


On Fri, 10 Feb 2006, Prof Brian Ripley wrote:

> Most likely this is FAQ 7.22.
> 
> althogh how we are supposed to know what plotHeatTrellis does is beyond 
> me.
> 
> On Fri, 10 Feb 2006, alexfang at stat.rutgers.edu wrote:
> 
> >
> >
> > Hello:
> >
> > I have problems generating big JPG plots in functions.  the following code runs
> > fine in the script:
> >
> > #### runs fine in script, generate 40k "test1.jpg" in the given directory
> > plotPlatesAlong <- c(1:5)
> > plotDirPath <- paste(dataPath, "OutputPlots\\", sep="")
> > filename <-   paste(plotDirPath,"test1.jpg", sep="")
> > jpeg(file=filename)
> > plotHeatTrellis(dataPath, plotVariable = "Raw", plotPlatesAlong)
> >    # here plotHeatTrellis() generates a complicate plot, but it works
> > dev.off()
> > #### End of script
> >
> >
> > but if I wrap it in a function, it doesn't work.
> >
> > ######## put it in a function and run test(dataPath)
> > ######## it will make "test1.jpg" in the given directory, but only 6k in size
> > ######## and if I open the file, it's blank
> > test <- function(dataPath) {
> > plotPlatesAlong <- c(1:5)
> > plotDirPath <- paste(dataPath, "OutputPlots\\", sep="")
> > filename <-   paste(plotDirPath,"test1.jpg", sep="")
> > jpeg(file=filename) #
> > plotHeatTrellis(dataPath, plotVariable = "Raw", plotPlatesAlong)
> > dev.off()
> > }
> > ######### enf of the program
> >
> >
> > I've tested the simple plot function, like
> >
> > ########## works fine both with in script and function wrapping format
> > testplot <- function(plotDirPath) {
> > filename1 <- paste(plotDirPath, "test1.jpg",sep="")
> > jpeg(file=filename1)
> > plot(1:10, rnorm(10, 0), type="b")
> > dev.off()
> > }
> > ###########
> >
> > Any one have any clues, why this happen and how could I fix my code and my mine
> > working also in the function wrapping format?  Thanks.
> >
> >
> > best, Alex
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From jfox at mcmaster.ca  Sat Feb 11 04:13:18 2006
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 10 Feb 2006 22:13:18 -0500
Subject: [R] how do I "relate" tables in R?
In-Reply-To: <200602110225.k1B2PF04024865@gallun.acpub.duke.edu>
Message-ID: <20060211031318.VVTB4713.tomts43-srv.bellnexxia.net@JohnDesktop8300>

Dear Jeff,

Assuming that the column named "z" in the matrix data2 already exists and
has arbitrary content (such as 0's or NA's), how about the following?

data2[,"z"] <- data1[data2[,"ID"], "z"]

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jeffrey Moore
> Sent: Friday, February 10, 2006 9:23 PM
> To: r-help at stat.math.ethz.ch
> Cc: colchero at duke.edu
> Subject: [R] how do I "relate" tables in R?
> 
> Hi all,
>  
> I'm new to the list...pretty new at learning to code in R...
>  
> Is there a way to relate 2 different arrays in R?
>  
> Hypothetical example:
>  
> data1
> ID    z
> 1    100
> 2    250
> 3    75
> 4    12
> 5    89
>  
> data2
> ID    z
> 1
> 1
> 1
> 1
> 2
> 3
> 4
> 3
> 4
> 5
> 5
> 5
> etc.
>  
> Goal is to fill column z in data2 with appropriate z-values 
> from data1 that correspond to a given ID.
>  
> I'm looking for something akin to a relational database, or a 
> lookup table in Excel.
>  
> I can construct a simple for-loop (with if else statement) to 
> fill the z-column in data2, but in my case data2 is 150,000 
> records long, so this approach is not efficient.
>  
> Thanks for any help
> Jeff
>  
> ******************************************
> Jeffrey Moore, Ph.D.
> Postdoctoral Research Scientist
> Duke Center for Marine Conservation
> Duke University Marine Laboratory
> 135 Duke Marine Lab Road
> Beaufort, NC 28516
> Phone: (252) 504-7653
> Fax: (252) 504-7689
> Email: jemoore at duke.edu
> *****************************************
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Sat Feb 11 05:05:31 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 10 Feb 2006 20:05:31 -0800
Subject: [R] post-hoc comparisons following glmm
In-Reply-To: <43E8C7E9.4080000@univ-fcomte.fr>
References: <43E8C7E9.4080000@univ-fcomte.fr>
Message-ID: <43ED628B.1010503@pdf.com>

	  The following appears to be an answer to your question, though I'd be 
pleased to receive critiques from others.  Since your example is NOT 
self contained, I modified an example in the "glmmPQL" help file:

(fit <- glmmPQL(y ~ factor(week)-1+trt, random = ~ 1 | ID,
+                      family = binomial, data = bacteria))
iteration 1
iteration 2
iteration 3
iteration 4
iteration 5
iteration 6
Linear mixed-effects model fit by maximum likelihood
   Data: bacteria
   Log-likelihood: -551.1184
   Fixed: y ~ factor(week) - 1 + trt
  factor(week)0  factor(week)2  factor(week)4  factor(week)6 factor(week)11
      3.3459650      3.5262521      1.9102037      1.7645881      1.7660845
        trtdrug       trtdrug+
     -1.2527642     -0.7570441

Random effects:
  Formula: ~1 | ID
         (Intercept)  Residual
StdDev:    1.426534 0.7747477

Variance function:
  Structure: fixed weights
  Formula: ~invwt
Number of Observations: 220
Number of Groups: 50
 > anova(fit)
              numDF denDF   F-value p-value
factor(week)     5   166 10.821682  <.0001
trt              2    48  1.889473  0.1622
 > (denDF.week <- anova(fit)$denDF[1])
[1] 166
 > (denDF.week <- anova(fit)$denDF[1])
[1] 166
 > (par.week <- fixef(fit)[1:5])
  factor(week)0  factor(week)2  factor(week)4  factor(week)6 factor(week)11
       3.345965       3.526252       1.910204       1.764588       1.766085
 > (vc.week <- vcov(fit)[1:5, 1:5])
                factor(week)0 factor(week)2 factor(week)4 factor(week)6
factor(week)0      0.3351649     0.1799365     0.1705898     0.1694884
factor(week)2      0.1799365     0.3709887     0.1683038     0.1684096
factor(week)4      0.1705898     0.1683038     0.2655072     0.1655673
factor(week)6      0.1694884     0.1684096     0.1655673     0.2674647
factor(week)11     0.1668450     0.1665177     0.1616748     0.1638169
                factor(week)11
factor(week)0       0.1668450
factor(week)2       0.1665177
factor(week)4       0.1616748
factor(week)6       0.1638169
factor(week)11      0.2525962
 > CM <- array(0, dim=c(5*4/2, 5))
 > i1 <- 0
 > for(i in 1:4)for(j in (i+1):5){
+   i1 <- i1+1
+   CM[i1, c(i, j)] <- c(-1, 1)
+ }
 > CM
       [,1] [,2] [,3] [,4] [,5]
  [1,]   -1    1    0    0    0
  [2,]   -1    0    1    0    0
  [3,]   -1    0    0    1    0
  [4,]   -1    0    0    0    1
  [5,]    0   -1    1    0    0
  [6,]    0   -1    0    1    0
  [7,]    0   -1    0    0    1
  [8,]    0    0   -1    1    0
  [9,]    0    0   -1    0    1
[10,]    0    0    0   -1    1
 > library(multcomp)
 > csimint(par.week, df=denDF.week, covm=vc.week,cmatrix=CM)

	Simultaneous confidence intervals: user-defined contrasts

	95 % confidence intervals

       Estimate  2.5 % 97.5 %
  [1,]    0.180 -1.439  1.800
  [2,]   -1.436 -2.838 -0.034
  [3,]   -1.581 -2.995 -0.168
  [4,]   -1.580 -2.967 -0.193
  [5,]   -1.616 -3.123 -0.109
  [6,]   -1.762 -3.273 -0.250
  [7,]   -1.760 -3.244 -0.277
  [8,]   -0.146 -1.382  1.091
  [9,]   -0.144 -1.359  1.070
[10,]    0.001 -1.206  1.209

 > csimtest(par.week, df=denDF.week, covm=vc.week,cmatrix=CM)

	Simultaneous tests: user-defined contrasts

Contrast matrix:
       [,1] [,2] [,3] [,4] [,5]
  [1,]   -1    1    0    0    0
  [2,]   -1    0    1    0    0
  [3,]   -1    0    0    1    0
  [4,]   -1    0    0    0    1
  [5,]    0   -1    1    0    0
  [6,]    0   -1    0    1    0
  [7,]    0   -1    0    0    1
  [8,]    0    0   -1    1    0
  [9,]    0    0   -1    0    1
[10,]    0    0    0   -1    1

Adjusted P-Values

       p adj
  [1,] 0.011
  [2,] 0.013
  [3,] 0.014
  [4,] 0.015
  [5,] 0.020
  [6,] 0.024
  [7,] 0.985
  [8,] 0.985
  [9,] 0.985
[10,] 0.997
 > sessionInfo()
R version 2.2.1, 2005-12-20, i386-pc-mingw32

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"

other attached packages:
   multcomp    mvtnorm       MASS    statmod       nlme
    "0.4-8"    "0.7-2"   "7.2-24"    "1.2.4" "3.1-68.1"

	  If this does NOT answer your question (or even if it does), PLEASE do 
read the posting guide! "www.R-project.org/posting-guide.html".  I'd 
prefer not to have to guess whether you would think the example I chose 
was relevant.

	  hope this helps,
	  spencer graves

Micha??l Coeurdassier wrote:

> Dear R community,
> 
> I performed a generalized linear mixed model using glmmPQL (MASS 
> library) to analyse my data i.e : y is the response with a poisson 
> distribution, t and Trait are the independent variables which are 
> continuous and categorical (3 categories C, M and F) respectively, ind 
> is the random variable.
> 
> mydata<-glmmPQL(y~t+Trait,random=~1|ind,family=poisson,data=tab)
> Do you think it is OK?
> 
> Trait is significant (p < 0.0001) and I would like to perform post-hoc 
> comparisons  to check  where the difference among  Trait categories but 
> I did not find  a solution  in R help list or others.
> 
> Thank you in advance for your help
> 
> Michael
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From zpzhang at uchicago.edu  Sat Feb 11 06:30:38 2006
From: zpzhang at uchicago.edu (Zepu Zhang)
Date: Sat, 11 Feb 2006 11:30:38 +0600
Subject: [R] install.packages() failed
Message-ID: <1d2321fe.88c213bd.819dd00@m4500-03.uchicago.edu>

I use Mac. I installed R with the download from R-project, so R is in /usr/bin/R.  
My TclTk library is installed via fink (although I don't remember I intentionally 
installed it) so libtk8.4.dylib is in /sw/lib.

I tried to install the HDF5 package from within R:

>install.packages('hdf5')

and it failed like this
-------
Loading Tcl/Tk interface ... Error in dyn.load(x, as.logical(local), as.logical(now)) 
: 
        unable to load shared library '/Library/Frameworks/R.framework/
Resources/library/tcltk/libs/tcltk.so':
  dlcompat: dyld: /Library/Frameworks/R.framework/Resources/bin/exec/R 
can't open library: /usr/local/lib/libtk8.4.dylib  (No such file or directory, errno 
= 2)
Error: .onLoad failed in 'loadNamespace' for 'tcltk'
-------

Apparently R looks for libtk8.4.dylib in /usr/local/lib and doesn't know it's in /
sw/lib. How can I tell R about this?

Also, I tried installing the downloaded source with

>R CMD INSTALL hdf5_1.6.0.tar.gz

and it failed because the 'configure' script of the package failed. Anybody had 
experience with this? If I can install with 'R CMD INSTALL', that's also good 
enough.

Thanks.
Zepu



From jemoore at duke.edu  Sat Feb 11 06:48:48 2006
From: jemoore at duke.edu (Jeffrey Moore)
Date: Sat, 11 Feb 2006 00:48:48 -0500
Subject: [R] how do I "relate" tables in R?
In-Reply-To: <20060211031318.VVTB4713.tomts43-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <200602110550.k1B5om04022394@gallun.acpub.duke.edu>

thanks, Andy and John, for suggestions.
worked great.
jeff 


******************************************
Jeffrey Moore, Ph.D.
Postdoctoral Research Scientist
Duke Center for Marine Conservation
Duke University Marine Laboratory
135 Duke Marine Lab Road
Beaufort, NC 28516
Phone: (252) 504-7653
Fax: (252) 504-7689
Email: jemoore at duke.edu
*****************************************

-----Original Message-----
From: John Fox [mailto:jfox at mcmaster.ca] 
Sent: Friday, February 10, 2006 10:13 PM
To: 'Jeffrey Moore'
Cc: colchero at duke.edu; r-help at stat.math.ethz.ch
Subject: RE: [R] how do I "relate" tables in R?

Dear Jeff,

Assuming that the column named "z" in the matrix data2 already exists and
has arbitrary content (such as 0's or NA's), how about the following?

data2[,"z"] <- data1[data2[,"ID"], "z"]

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jeffrey Moore
> Sent: Friday, February 10, 2006 9:23 PM
> To: r-help at stat.math.ethz.ch
> Cc: colchero at duke.edu
> Subject: [R] how do I "relate" tables in R?
> 
> Hi all,
>  
> I'm new to the list...pretty new at learning to code in R...
>  
> Is there a way to relate 2 different arrays in R?
>  
> Hypothetical example:
>  
> data1
> ID    z
> 1    100
> 2    250
> 3    75
> 4    12
> 5    89
>  
> data2
> ID    z
> 1
> 1
> 1
> 1
> 2
> 3
> 4
> 3
> 4
> 5
> 5
> 5
> etc.
>  
> Goal is to fill column z in data2 with appropriate z-values from data1 
> that correspond to a given ID.
>  
> I'm looking for something akin to a relational database, or a lookup 
> table in Excel.
>  
> I can construct a simple for-loop (with if else statement) to fill the 
> z-column in data2, but in my case data2 is 150,000 records long, so 
> this approach is not efficient.
>  
> Thanks for any help
> Jeff
>  
> ******************************************
> Jeffrey Moore, Ph.D.
> Postdoctoral Research Scientist
> Duke Center for Marine Conservation
> Duke University Marine Laboratory
> 135 Duke Marine Lab Road
> Beaufort, NC 28516
> Phone: (252) 504-7653
> Fax: (252) 504-7689
> Email: jemoore at duke.edu
> *****************************************
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From markshanks101 at hotmail.com  Sat Feb 11 07:40:57 2006
From: markshanks101 at hotmail.com (mark shanks)
Date: Sat, 11 Feb 2006 17:40:57 +1100
Subject: [R] Need frequency distribution for x,y coordinates
Message-ID: <BAY105-F2389063915EEC744A8E75EE6050@phx.gbl>

Hi,

I have a set of data in x,y coordinates across the range of -5 to 5 in each 
dimension. I would like to obtain the frequency distribution of the 
different points, and then graph them so you can see which of the points are 
the most frequently occurring.

This would seem to be easy in Matlab, which has the hist3 command for doing 
frequency distributions/histograms in 3 dimensions. However, as far as I can 
tell, R does not have a hist3 command.

Is there any easy way to do this in R? I'm investigating whether matlab or R 
is more suitable for our needs, but don't want to reject R due to my present 
ignorance of its functions.

_________________________________________________________________
realestate.com.au: the biggest address in property   
http://ninemsn.realestate.com.au



From d.scott at auckland.ac.nz  Sat Feb 11 10:24:37 2006
From: d.scott at auckland.ac.nz (David Scott)
Date: Sat, 11 Feb 2006 22:24:37 +1300 (NZDT)
Subject: [R] Errors using update.packages()
Message-ID: <Pine.LNX.4.61.0602112202020.28755@stat12.stat.auckland.ac.nz>


When trying to update packages after the sysadmin updated R on my unix box 
I got errors on some packages. For example for chron:

* DONE (chron)
mkdir: cannot create directory `/usr/lib/R/library/00LOCK': Permission 
denied
ERROR: failed to lock directory '/usr/lib/R/library' for modifying

I got similar messages for spatial and cluster and warnings for other 
packages. Finally I got:

Warning messages:
1: number of rows of result
 	is not a multiple of vector length (arg 1) in: cbind(1, pkgs, lib)
2: number of rows of result
 	is not a multiple of vector length (arg 2) in: cbind(1, 
update[found, , drop = FALSE], file = files)
3: installation of package 'chron' had non-zero exit status in: 
install.packages(update[, "Package"], instlib, contriburl = contriburl,
4: installation of package 'VR' had non-zero exit status in: 
install.packages(update[, "Package"], instlib, contriburl = contriburl,
5: installation of package 'dse' had non-zero exit status in: 
install.packages(update[, "Package"], instlib, contriburl = contriburl,
6: installation of package 'mgcv' had non-zero exit status in: 
install.packages(update[, "Package"], instlib, contriburl = contriburl,
7: installation of package 'nlme' had non-zero exit status in: 
install.packages(update[, "Package"], instlib, contriburl = contriburl,
8: installation of package 'survival' had non-zero exit status in: 
install.packages(update[, "Package"], instlib, contriburl = contriburl,
9: cannot create HTML package index in: 
tools:::unix.packages.html(.Library)

>From Sys.info():
                              sysname                              release
                              "Linux"               "2.6.15-1.1831_FC4smp"

>From the startup:
Version 2.2.1  (2005-12-20 r36812)

I don't have root privileges but am installing in my private library:
stat71/dscott10> echo $R_LIBS
/home/staff/dscott/Computing/R/Rprivatelib

Any suggestions?

David Scott



_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
 		The University of Auckland, PB 92019
 		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz


Graduate Officer, Department of Statistics



From phgrosjean at sciviews.org  Sat Feb 11 10:40:01 2006
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sat, 11 Feb 2006 10:40:01 +0100
Subject: [R] Transferring R results to word prosessors
In-Reply-To: <971536df0602101726l7b83be82sca44020c5cca230c@mail.gmail.com>
References: <5.2.0.8.2.20060209212028.020ec3d8@alf.uib.no>	<Pine.LNX.4.44.0602101004230.11855-100000@reclus.nhh.no>	<5.2.0.8.2.20060210200957.0216c5d8@alf.uib.no>
	<971536df0602101726l7b83be82sca44020c5cca230c@mail.gmail.com>
Message-ID: <43EDB0F1.3040605@sciviews.org>

The copy to clipboard feature is written (by Eric Lecoutre & myself) 
since a couple of years. It is in the SciViews bundle, library svIO. In 
this library, you have:
- copy() that copies an object to the clipboard in various formats 
(icluding HTML, by using R2HTML and LaTeX),

- export() does the same, but save to a file on disk,

- you have also clippaste() to paste data from the clipboard.

Moreover, in the SciViews bundle, you have also svViews that provides 
further interesting functions for reporting:
- view() allows to generate different rich-formatted views on objects,

- report() sends a view to a reporting application (but see hereunder 
the note about SciViews-R),

- reportGraph() is the same for R graphs,

... All these functions exist on CRAN since at least two years. They are 
programmed under Windows(), but most of them should be working on other 
platforms (I would gladly consider patches, of course, if required).

Now, if you want a convenient point and click approach to write a 
report, you should use SciViews-R (http://www.sciviews.org/SciViews-R). 
It has a nice GUI interface on top of these functions. For instance, you 
can access them from the context menu of the object explorer (but see 
the SciViews-R manual at http://www.sciviews.org/SciViews-R/Manual.pdf).

SciViews-R is Windows only, but I am gradually moving code to a 
platform-independent solution (lot of code, lack of time, other 
priorities,... so, you have to be patient!).

Finally, I uploaded the latest version of SciViews this week on CRAN. 
Now, the svViews package has a suite of WordXXX() functions. There are 
intended for sending nicely formatted data to Word. The next version of 
SciViews-R (next week, or so) included the functionnalities in the GUI.

Regarding reproducibility of results, the strategy here is to write a 
template in Word with bookmarks at the locations where you want to put 
material coming from R. Once it is done, you can control entirely the 
process of filling the Word document from within a R script. For 
instance (extracted and reworked from the example in ?WordOpen):


# Install SciViews bundle from CRAN, then...
library(svViews)
repdir <- "c:/temp" # Adapt this for you
WordOpen(file.path(repdir, "report.doc")) # Open your template

# Code to create a graph in a file, for instance
graphfile <- file.path(repdir, "figure1.emf")
win.metafile(filename = graphfile, width = 7, height = 5)
hist(rnorm(500))
dev.off()

# Insert that graph in Word at a location named "picture1":
WordGoto("figure1") # Move to the picture1 bookmark
WordInsertPictureFile(graphfile, TRUE) # Insert the graph

# Create a view in HTML (rich-formatted) and insert it in Word
# for instance, for a simple linear regression, you can do:
data(trees)
trees.lm <- lm(Volume ~ Girth, data = trees)
viewfile <- view(trees.lm, type = "summary", browse = FALSE)
WordGoto("view1") # Go to the regression1 bookmark in your report
WordInsertFile(viewfile, TRUE) # Insert the view in the report

# This is done!
WordActivate(async = TRUE) # Show your report in Word.
# and allow to refine it (add comments according to the results)

# -- or --
# WordExit()  # Close word, possibly prompting to save the doc.


(note that I appended a suitable "myreport.doc" to this email, but it 
will probably be eliminated on the mailing list. so, ask me if you need it).
Best,

Philippe Grosjean

P.S.: the formatting of text and tables in the views is managed through 
CSS files, independently from Word styles. So, you would presumably like 
to make a CSS file in accordance with the style you want in your report.


Gabor Grothendieck wrote:
> Given that this may very well be the most common use of the
> R2HTML package I wonder if the R2HTML package developer would
> be interested in providing an HTML2clip convenience wrapper
> as part of the R2HTML package like this:
> 
>    HTML2clip <- function(x, file. = file("clipboard", "w"), append = FALSE, ...)
>      HTML(x, file = file., append = append, ...)
> 
> so that one could just write:
> 
>    HTML2clip(summary(lm(rating ~., attitude)))
> 
> On 2/10/06, Tom Backer Johnsen <backer at psych.uib.no> wrote:
> 
>>Thank you all for very useful and interesting responses.  After reading the
>>comments and after some experiments, I added the following to a text I will
>>be handing out to the students (I would not mind comments):
>>
>><QUOTE>The contents of the text output from R may be very sophisticated,
>>but the formatting of the texts is always very simple, with absolutely no
>>frills.  For instance, all formatting of columns is managed with spaces or
>>blanks, no tabs, nothing extra apart from line feeds.  This means that
>>transferring some types of output, like the summary of the multiple
>>regression in part 7.4 directly to MS Word or any other wordprocessor would
>>be far from optimal.  To make a decent table for presenting results in a
>>paper in APA format, we need a "table" in the word processing sense, an
>>arrangement of things in rows and columns.  With output as plain as in R, a
>>lot of fiddling would be necessary after a direct copy and paste of the
>>text into MS Word.  So, we need a better solution.
>>
>>The steps involved are really quite simple, the information is transferred
>>via a speadsheet:
>>
>>1. Write the output to the clipboard in HTML format (that is the same
>>format as used for writing web pages)
>>
>>2. When you are finished with that, paste the contents of the clipboard
>>into a spreadsheet (e.g. Excel).  This automatically reformats HTML to
>>something that both the spreadsheet and the word processor (e.g. MS Word)
>>can handle.
>>
>>3. Copy and paste what you need from the spreadsheet to the document.
>>
>>The last two steps are the same as when using Statistica or SPSS in a
>>anyhow.  Especially SPSS has a tendency include too much formatting when
>>pasting, and then Excel is a useful stepping stone to strip off the frills.
>>
>>The main difference is in the first step.  What we need there is to write
>>the output from R to the clipboard in a format that Excel recognizes as
>>something with columns and rows.  For an example, consider the "summary ()"
>>output from the multiple regression in part 7.4 above.
>>
>>First, you have to make the library "R2HTML" available to the session:
>>
>> > library (R2HTML)
>>
>>You only need to do this once in a session.  If this package is not
>>installed, have a look at part 9 above.  Then we need to attach the data
>>set and do the multiple regression:
>>
>> > attach (attitude)
>> > Results <- lm (rating ~ complaints + privileges + learning)
>> > HTML (summary (Results, digits=4), file("clipboard", "w"), append=FALSE)
>> > detach (attitude)
>>
>>If you do this more than a few times, it might be a good idea to write a
>>function as a replacement for the HTML command with a reasonable name, e.g.
>>"ToClip".  The last command could then be replaced by:
>>
>> > ToClip (summary (Results, digits=4))
>>
>>Which is much simpler.  In any case, the results are now writtten to the
>>clipboard.  Open Excel, and paste the contents into a worksheet.  Select
>>what you want, copy it to the clipboard, and then open your document where
>>the paper is found.  Locate the place where you want the table, and paste
>>the clipboard there. </QUOTE>
>>
>>After showing how the table looks, I mention that some details will have to
>>be fixed, like conversion of the lower part of the output to text, removing
>>blank rows, adding borders etc., plus rewriting the p value which is in
>>scientific notation.  It is still not in an APA format, but very much
>>better than it would bave been with a simple "copy and past" operation.
>>
>>Tom
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

From ggrothendieck at gmail.com  Sat Feb 11 10:40:41 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 11 Feb 2006 04:40:41 -0500
Subject: [R] Need frequency distribution for x,y coordinates
In-Reply-To: <BAY105-F2389063915EEC744A8E75EE6050@phx.gbl>
References: <BAY105-F2389063915EEC744A8E75EE6050@phx.gbl>
Message-ID: <971536df0602110140pd6e1004rde7ba46b1e90c151@mail.gmail.com>

Check out:

http://addictedtor.free.fr/graphiques/graphcode.php?graph=116

On 2/11/06, mark shanks <markshanks101 at hotmail.com> wrote:
> Hi,
>
> I have a set of data in x,y coordinates across the range of -5 to 5 in each
> dimension. I would like to obtain the frequency distribution of the
> different points, and then graph them so you can see which of the points are
> the most frequently occurring.
>
> This would seem to be easy in Matlab, which has the hist3 command for doing
> frequency distributions/histograms in 3 dimensions. However, as far as I can
> tell, R does not have a hist3 command.
>
> Is there any easy way to do this in R? I'm investigating whether matlab or R
> is more suitable for our needs, but don't want to reject R due to my present
> ignorance of its functions.
>
> _________________________________________________________________
> realestate.com.au: the biggest address in property
> http://ninemsn.realestate.com.au
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Sat Feb 11 10:50:00 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 11 Feb 2006 10:50:00 +0100
Subject: [R] Errors using update.packages()
In-Reply-To: <Pine.LNX.4.61.0602112202020.28755@stat12.stat.auckland.ac.nz>
References: <Pine.LNX.4.61.0602112202020.28755@stat12.stat.auckland.ac.nz>
Message-ID: <x2lkwicjhz.fsf@turmalin.kubism.ku.dk>

David Scott <d.scott at auckland.ac.nz> writes:

> When trying to update packages after the sysadmin updated R on my unix box 
> I got errors on some packages. For example for chron:
> 
> * DONE (chron)
> mkdir: cannot create directory `/usr/lib/R/library/00LOCK': Permission 
> denied
...
> >From the startup:
> Version 2.2.1  (2005-12-20 r36812)
> 
> I don't have root privileges but am installing in my private library:
> stat71/dscott10> echo $R_LIBS
> /home/staff/dscott/Computing/R/Rprivatelib
> 
> Any suggestions?

update.packages tries to update all available packages, including the
system ones. Try
update.packages("/home/staff/dscott/Computing/R/Rprivatelib")
 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From Roger.Bivand at nhh.no  Sat Feb 11 11:07:08 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sat, 11 Feb 2006 11:07:08 +0100 (CET)
Subject: [R] Need frequency distribution for x,y coordinates
In-Reply-To: <BAY105-F2389063915EEC744A8E75EE6050@phx.gbl>
Message-ID: <Pine.LNX.4.44.0602111053570.11372-100000@reclus.nhh.no>

On Sat, 11 Feb 2006, mark shanks wrote:

> Hi,
> 
> I have a set of data in x,y coordinates across the range of -5 to 5 in each 
> dimension. I would like to obtain the frequency distribution of the 
> different points, and then graph them so you can see which of the points are 
> the most frequently occurring.
> 
> This would seem to be easy in Matlab, which has the hist3 command for doing 
> frequency distributions/histograms in 3 dimensions. However, as far as I can 
> tell, R does not have a hist3 command.

See contributed package ash, function bin2:

> xy <- cbind(x=runif(250,-5,5), y=runif(250,-5,5))
> bins <- bin2(xy, ab=matrix(c(-5,-5,5,5),2,2))
> image(bins$nc)

or

> filled.contour(bins$nc)

Using the x and y arguments to image or filled.contour, you can set the 
axes, and asp=1 to preserve aspect.

See also function kde2d in package MASS - included in the standard 
distribution.

IMO, 3D histograms can mislead because perception depends on viewer 
position. All of the above give readily interpreted visualisations based 
on colour class intervals.

> 
> Is there any easy way to do this in R? I'm investigating whether matlab or R 
> is more suitable for our needs, but don't want to reject R due to my present 
> ignorance of its functions.
> 
> _________________________________________________________________
> realestate.com.au: the biggest address in property   
> http://ninemsn.realestate.com.au
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From ripley at stats.ox.ac.uk  Sat Feb 11 11:38:59 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 11 Feb 2006 10:38:59 +0000 (GMT)
Subject: [R] Need frequency distribution for x,y coordinates
In-Reply-To: <Pine.LNX.4.44.0602111053570.11372-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0602111053570.11372-100000@reclus.nhh.no>
Message-ID: <Pine.LNX.4.64.0602111035540.3704@gannet.stats.ox.ac.uk>

On Sat, 11 Feb 2006, Roger Bivand wrote:

> On Sat, 11 Feb 2006, mark shanks wrote:
>
>> I have a set of data in x,y coordinates across the range of -5 to 5 in each
>> dimension. I would like to obtain the frequency distribution of the
>> different points, and then graph them so you can see which of the points are
>> the most frequently occurring.
>>
>> This would seem to be easy in Matlab, which has the hist3 command for doing
>> frequency distributions/histograms in 3 dimensions. However, as far as I can
>> tell, R does not have a hist3 command.
>
> See contributed package ash, function bin2:
>
>> xy <- cbind(x=runif(250,-5,5), y=runif(250,-5,5))
>> bins <- bin2(xy, ab=matrix(c(-5,-5,5,5),2,2))
>> image(bins$nc)
>
> or
>
>> filled.contour(bins$nc)
>
> Using the x and y arguments to image or filled.contour, you can set the
> axes, and asp=1 to preserve aspect.
>
> See also function kde2d in package MASS - included in the standard
> distribution.

And density plots are usually a lot better than histograms for 
understanding 2D data.

> IMO, 3D histograms can mislead because perception depends on viewer
> position. All of the above give readily interpreted visualisations based
> on colour class intervals.

But if you really want one, see demo("hist3d") in package rgl, which 
allows you to change your position interactively and uses translucency.


>> Is there any easy way to do this in R? I'm investigating whether matlab or R
>> is more suitable for our needs, but don't want to reject R due to my present
>> ignorance of its functions.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tarun30devraj at gmail.com  Sat Feb 11 14:33:05 2006
From: tarun30devraj at gmail.com (Tarun Kumar Singh)
Date: Sat, 11 Feb 2006 19:03:05 +0530
Subject: [R] hclust(stats) merge matrix interpretation
Message-ID: <e5b0e8320602110533m25acb4a6td77672b60254ec1d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060211/281b1d85/attachment.pl

From expiregmane1104.m.cudgle at neverbox.com  Fri Feb 10 16:14:36 2006
From: expiregmane1104.m.cudgle at neverbox.com (Frank Samuelson)
Date: Fri, 10 Feb 2006 10:14:36 -0500
Subject: [R] tk mouse cursor icon widget  tkwinfo tkfocus questions
Message-ID: <dsial0$29r$1@sea.gmane.org>

1. I want to change the mouse cursor over my window into a wait/watch
     icon while R computes.  Can this be done directly?
     Some ancient tcltk mailing lists said change the cursor over every
     widget in the window:

                 foreach widget [winfo children $window] {
                         $widget config -cursor watch
                 }

     To do this I'll need a list of R/tcl widget  objects:
        lapply(widglist, function(z) tkconfigure(z, cursor="watch"))

     From where can I get this widglist?
     I tried:
     > tkwinfo("children",topwindow)
     <Tcl> .1.1 .1.2 .1.3

     I'm guessing this is a string directly returned from tcl.
     Is there a way to turn this into  a list of widgets after some parsing?
     Right now I'm using a hardcoded list for widglist, but if I or others
     change the layout, the coding gets messy.


2. How do I specify the force option with tkfocus?  Or, more generally,
     any option in a tk function that doesn't take a value?
     I can see the force option is available from the errors at my
     failed attempts to specify it.  MS keeps popping up my Tk
     window behind another window.

Thanks for any help.

-Frank



From thomas.wilde at gmx.de  Sat Feb 11 17:21:19 2006
From: thomas.wilde at gmx.de (Thomas Wilde)
Date: Sat, 11 Feb 2006 17:21:19 +0100
Subject: [R] R-newbie-question, fixed effects panel model,
	large number of observations
Message-ID: <200602111621.k1BGLMCr028311@hypatia.math.ethz.ch>

Hi,

I'm trying to fit a fixed effect (LSDV) panelmodel with R. I have a dataset
with y as dependent, x1&x2 as indeps, t as time index and i as an
id-variable for each individual. There are three observations for each
individual (t=1, t=2, t=3).

I want to try a simple regression, but with individual intercepts:

-------------------------------------------------
# reading in some data ...

mydata <- read.csv(...)
attach(mydata)

# fit modell

mymodel <- lm(y ~ -1 + factor(i) + x1 + x2)
summary(mymodel)
-------------------------------------------------

Works fine when the size of my dataset doesn't exceed about n=5000
observations, but I have some more. Can I do a partitioned regression with
R, are there any other options already implemented in R ?

Thanks,
Thomas



From bates at stat.wisc.edu  Sat Feb 11 17:37:19 2006
From: bates at stat.wisc.edu (Douglas Bates)
Date: Sat, 11 Feb 2006 10:37:19 -0600
Subject: [R] lme4: Error in getResponseFormula(form) : "Form" must be a
	two sided formula
In-Reply-To: <43ECC8B8.30604@pdf.com>
References: <1994687269.20060206222959@psyctc.org>
	<40e66e0b0602061539q384ecfe0hc935e7c07010ea9@mail.gmail.com>
	<43ECC8B8.30604@pdf.com>
Message-ID: <40e66e0b0602110837w3215a25etc598e199e280c0d4@mail.gmail.com>

On 2/10/06, Spencer Graves <spencer.graves at pdf.com> wrote:
> Hi, Doug and Chris:
>
>           I just got the same error message with the "lmList" example in lme4:
>
>  >      (fm1 <- lmList(breaks ~ wool | tension, warpbreaks))
> Call:
> Error in getResponseFormula(form) : "Form" must be a two sided formula
>  > sessionInfo()
> R version 2.2.1, 2005-12-20, i386-pc-mingw32
>
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
> [7] "base"
>
> other attached packages:
>       lme4   lattice    Matrix
> "0.995-2" "0.12-11" "0.995-5"

Hmm.  I am unable to reproduce that in either R-devel or R-patched under Linux

> library(lme4)
Loading required package: Matrix
Loading required package: lattice
>    (fm1 <- lmList(breaks ~ wool | tension, warpbreaks))
Call: lmList(formula = breaks ~ wool | tension, data = warpbreaks)
Coefficients:
  (Intercept)      woolB
L    44.55556 -16.333333
M    24.00000   4.777778
H    24.55556  -5.777778

Degrees of freedom: 54 total; 48 residual
Residual standard error: 10.94028
> sessionInfo()
Version 2.3.0 Under development (unstable) (2006-02-11 r37328)
i686-pc-linux-gnu

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"

other attached packages:
     lme4   lattice    Matrix
"0.995-2"  "0.13-3" "0.995-5"


> library(lme4)
Loading required package: Matrix
Loading required package: lattice
> (fm1 <- lmList(breaks ~ wool | tension, warpbreaks))
Call: lmList(formula = breaks ~ wool | tension, data = warpbreaks)
Coefficients:
  (Intercept)      woolB
L    44.55556 -16.333333
M    24.00000   4.777778
H    24.55556  -5.777778

Degrees of freedom: 54 total; 48 residual
Residual standard error: 10.94028
> sessionInfo()
R version 2.2.1, 2005-12-20, i486-pc-linux-gnu

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"

other attached packages:
     lme4   lattice    Matrix
"0.995-2"  "0.12-3" "0.995-5"
>
>           I quit then restarted R and tried the same example in nlme:  It
> seemed to work fine.
>
>           Chris, have you tried this in nlme?  If you absolutely need some
> feature of lme4, at least you could do this kind of preliminary work in
> nlme, then switch to lme4 (after quitting and restarting R to avoid
> potential conflicts between nlme and lme4).
>
>           hope this helps.
>           spencer graves
>
> Douglas Bates wrote:
> > Please check which packages you have attached when you call lmList.
> > That error message looks as if it is coming from the version of lmList
> > that is in the nlme package, not the one in lme4.
> >
> > On 2/6/06, Chris Evans <stats at psyctc.org> wrote:
> >
> >>I'm sure I'm being stupid so flame away...
> >>
> >>R2.2.1 on Windoze (boohoo) latest updates of packages.
> >>
> >>I'm exploring a dataset (land) with three variables looking at an
> >>narrowly unbalanced two group (GROUP) ANCOVA of a randomised
> >>controlled trial analysing endpoint score (SFQ.LOCF.ENDPOINT) entering
> >>the baseline score (SFQ.BASELINE) as covariate and the following work
> >>fine:
> >>
> >>
> >>>res.same <- lm(SFQ.LOCF.ENDPOINT ~ SFQ.BASELINE + GROUP,land)
> >>>res.diff <- lm(SFQ.LOCF.ENDPOINT ~ SFQ.BASELINE + GROUP + SFQ.BASELINE*GROUP,land)
> >>>anova(res.same,res.diff)
> >>
> >>I try:
> >>
> >>
> >>>lmList(SFQ.LOCF.ENDPOINT ~ SFQ.BASELINE | GROUP, land)
> >>
> >>Call:
> >>Error in getResponseFormula(form) : "Form" must be a two sided formula
> >>
> >>I'm puzzled.  That looks like a two sided formula very like the one in
> >>the help for lme4 (which had been loaded) and the data look OK:
> >>
> >>
> >>>table(land$SFQ.LOCF.ENDPOINT)
> >>
> >> 3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 23
> >> 1  1  2  4  8  5 16  9  7 14 18  7 16  9  6  8  4  6  2  3
> >>
> >>>table(land$SFQ.BASELINE)
> >>
> >> 3  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
> >> 1  1  3  3  4 11  7  7 10 12  9 16 14  9  8  7  8  6  1  1
> >>
> >>>table(land$GROUP)
> >>
> >> 1  2
> >>87 89
> >>
> >>Advice accepted gratefully and flames ruefully!
> >>
> >>Chris
> >>
> >>--
> >>Chris Evans <chris at psyctc.org>
> >>Consultant Psychiatrist in Psychotherapy, Rampton Hospital;
> >>Research Programmes Director, Nottinghamshire NHS Trust,
> >>Hon. Professor of Psychotherapy, Nottingham University,
> >>Hon. SL Institute of Psychiatry
> >>*** My views are my own and not representative of those institutions ***
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >>
> >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ronggui.huang at gmail.com  Sat Feb 11 18:03:49 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Sun, 12 Feb 2006 01:03:49 +0800
Subject: [R] R-newbie-question, fixed effects panel model,
	large number of observations
In-Reply-To: <200602111621.k1BGLMCr028311@hypatia.math.ethz.ch>
References: <200602111621.k1BGLMCr028311@hypatia.math.ethz.ch>
Message-ID: <38b9f0350602110903v1a719be0l@mail.gmail.com>

This is one function I wrote.
http://sociology.yculblog.com/post.794856.html



2006/2/12, Thomas Wilde <thomas.wilde at gmx.de>:
> Hi,
>
> I'm trying to fit a fixed effect (LSDV) panelmodel with R. I have a dataset
> with y as dependent, x1&x2 as indeps, t as time index and i as an
> id-variable for each individual. There are three observations for each
> individual (t=1, t=2, t=3).
>
> I want to try a simple regression, but with individual intercepts:
>
> -------------------------------------------------
> # reading in some data ...
>
> mydata <- read.csv(...)
> attach(mydata)
>
> # fit modell
>
> mymodel <- lm(y ~ -1 + factor(i) + x1 + x2)
> summary(mymodel)
> -------------------------------------------------
>
> Works fine when the size of my dataset doesn't exceed about n=5000
> observations, but I have some more. Can I do a partitioned regression with
> R, are there any other options already implemented in R ?
>
> Thanks,
> Thomas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--

Deparment of Sociology
Fudan University



From nojhan at free.fr  Sat Feb 11 17:25:27 2006
From: nojhan at free.fr (nojhan)
Date: Sat, 11 Feb 2006 17:25:27 +0100
Subject: [R] Need frequency distribution for x,y coordinates
References: <BAY105-F2389063915EEC744A8E75EE6050@phx.gbl>
	<971536df0602110140pd6e1004rde7ba46b1e90c151@mail.gmail.com>
Message-ID: <pan.2006.02.11.16.25.26.966226@free.fr>

Le Sat, 11 Feb 2006 04:40:41 -0500, Gabor Grothendieck a ??crit??:
> http://addictedtor.free.fr/graphiques/graphcode.php?graph=116

Or hist2d, in the gplots package :
http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=70

-- 
NoJhan



From statistical.model at googlemail.com  Sat Feb 11 19:44:25 2006
From: statistical.model at googlemail.com (statistical.model@googlemail.com)
Date: Sat, 11 Feb 2006 18:44:25 -0000
Subject: [R] plots
In-Reply-To: <40e66e0b0602110837w3215a25etc598e199e280c0d4@mail.gmail.com>
Message-ID: <EMEELGDEKHMIAKDGLCDCCEMCCKAA.Statistical.model@gmail.com>

Hi all,
I have a basic question. how can i visualize two or more density curves on
the same plot?

ex:
x1<-runif(100,10,80)
x2<-runif(100,1,100)
kernelgraf<-density(x1,kernel = "gaussian", width= 20)
plot(kernelgraf, xlab="Probability", xlim=c(0,100), ylim=c(0,.1),
col=rgb(0,1,0), main="")
kernelgraf<-density(x2,kernel = "gaussian", width= 20)
points(kernelgraf, xlab="Probability", xlim=c(0,100), ylim=c(0,.1),
col=rgb(0,0,1), main="")

here i am using plot + points, but i do not like the graphical output for
points.

can anybody help me?

thanks in advance

Roberto Furlan
University of Turin


----------------------------------------
La mia Cartella di Posta in Arrivo e protetta da SPAMfighter
204 messaggi contenenti spam sono stati bloccati con successo.
Scarica gratuitamente SPAMfighter!


From francoisromain at free.fr  Sat Feb 11 19:55:21 2006
From: francoisromain at free.fr (Romain Francois)
Date: Sat, 11 Feb 2006 19:55:21 +0100
Subject: [R] plots
In-Reply-To: <EMEELGDEKHMIAKDGLCDCCEMCCKAA.Statistical.model@gmail.com>
References: <EMEELGDEKHMIAKDGLCDCCEMCCKAA.Statistical.model@gmail.com>
Message-ID: <43EE3319.4050209@free.fr>

Le 11.02.2006 19:44, statistical.model at googlemail.com a ??crit :
> Hi all,
> I have a basic question. how can i visualize two or more density curves on
> the same plot?
>
> ex:
> x1<-runif(100,10,80)
> x2<-runif(100,1,100)
> kernelgraf<-density(x1,kernel = "gaussian", width= 20)
> plot(kernelgraf, xlab="Probability", xlim=c(0,100), ylim=c(0,.1),
> col=rgb(0,1,0), main="")
> kernelgraf<-density(x2,kernel = "gaussian", width= 20)
> points(kernelgraf, xlab="Probability", xlim=c(0,100), ylim=c(0,.1),
> col=rgb(0,0,1), main="")
>
> here i am using plot + points, but i do not like the graphical output for
> points.
>   
You are almost there, replace your last command by :

points(kernelgraf, type="l", col="blue")

Romain

PS : Maybe a function points.density setting type="l" would be a good 
thing ?
> can anybody help me?
>
> thanks in advance
>
> Roberto Furlan
> University of Turin
>   

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From Charles.Annis at StatisticalEngineering.com  Sat Feb 11 19:54:33 2006
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Sat, 11 Feb 2006 13:54:33 -0500
Subject: [R] plots
In-Reply-To: <EMEELGDEKHMIAKDGLCDCCEMCCKAA.Statistical.model@gmail.com>
Message-ID: <00ea01c62f3c$9962a580$6600a8c0@DD4XFW31>

You could substitute
 
lines(kernelgraf)


for your last line:

points(kernelgraf, xlab="Probability", xlim=c(0,100), ylim=c(0,.1),
col=rgb(0,0,1), main="")



See 
?lines


Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
statistical.model at googlemail.com
Sent: Saturday, February 11, 2006 1:44 PM
To: r-help at stat.math.ethz.ch
Subject: [R] plots

Hi all,
I have a basic question. how can i visualize two or more density curves on
the same plot?

ex:
x1<-runif(100,10,80)
x2<-runif(100,1,100)
kernelgraf<-density(x1,kernel = "gaussian", width= 20)
plot(kernelgraf, xlab="Probability", xlim=c(0,100), ylim=c(0,.1),
col=rgb(0,1,0), main="")
kernelgraf<-density(x2,kernel = "gaussian", width= 20)
points(kernelgraf, xlab="Probability", xlim=c(0,100), ylim=c(0,.1),
col=rgb(0,0,1), main="")

here i am using plot + points, but i do not like the graphical output for
points.

can anybody help me?

thanks in advance

Roberto Furlan
University of Turin


----------------------------------------
La mia Cartella di Posta in Arrivo e protetta da SPAMfighter
204 messaggi contenenti spam sono stati bloccati con successo.
Scarica gratuitamente SPAMfighter!



From murdoch at stats.uwo.ca  Sat Feb 11 19:59:44 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 11 Feb 2006 13:59:44 -0500
Subject: [R] plots
In-Reply-To: <43EE3319.4050209@free.fr>
References: <EMEELGDEKHMIAKDGLCDCCEMCCKAA.Statistical.model@gmail.com>
	<43EE3319.4050209@free.fr>
Message-ID: <43EE3420.8080501@stats.uwo.ca>

Romain Francois wrote:
> Le 11.02.2006 19:44, statistical.model at googlemail.com a ??crit :
> 
>>Hi all,
>>I have a basic question. how can i visualize two or more density curves on
>>the same plot?
>>
>>ex:
>>x1<-runif(100,10,80)
>>x2<-runif(100,1,100)
>>kernelgraf<-density(x1,kernel = "gaussian", width= 20)
>>plot(kernelgraf, xlab="Probability", xlim=c(0,100), ylim=c(0,.1),
>>col=rgb(0,1,0), main="")
>>kernelgraf<-density(x2,kernel = "gaussian", width= 20)
>>points(kernelgraf, xlab="Probability", xlim=c(0,100), ylim=c(0,.1),
>>col=rgb(0,0,1), main="")
>>
>>here i am using plot + points, but i do not like the graphical output for
>>points.
>>  
> 
> You are almost there, replace your last command by :
> 
> points(kernelgraf, type="l", col="blue")
> 
> Romain
> 
> PS : Maybe a function points.density setting type="l" would be a good 
> thing ?

Or maybe use

lines(kernelgraf, type="l", col="blue")

As I always say, when you want lines, use lines().

Duncan Murdoch
> 
>>can anybody help me?
>>
>>thanks in advance
>>
>>Roberto Furlan
>>University of Turin
>>  
> 
>



From francoisromain at free.fr  Sat Feb 11 20:05:08 2006
From: francoisromain at free.fr (Romain Francois)
Date: Sat, 11 Feb 2006 20:05:08 +0100
Subject: [R] plots
In-Reply-To: <43EE3420.8080501@stats.uwo.ca>
References: <EMEELGDEKHMIAKDGLCDCCEMCCKAA.Statistical.model@gmail.com>
	<43EE3319.4050209@free.fr> <43EE3420.8080501@stats.uwo.ca>
Message-ID: <43EE3564.4010401@free.fr>

Le 11.02.2006 19:59, Duncan Murdoch a ??crit :
> Romain Francois wrote:
>> Le 11.02.2006 19:44, statistical.model at googlemail.com a ??crit :
>>
>>> Hi all,
>>> I have a basic question. how can i visualize two or more density 
>>> curves on
>>> the same plot?
>>>
>>> ex:
>>> x1<-runif(100,10,80)
>>> x2<-runif(100,1,100)
>>> kernelgraf<-density(x1,kernel = "gaussian", width= 20)
>>> plot(kernelgraf, xlab="Probability", xlim=c(0,100), ylim=c(0,.1),
>>> col=rgb(0,1,0), main="")
>>> kernelgraf<-density(x2,kernel = "gaussian", width= 20)
>>> points(kernelgraf, xlab="Probability", xlim=c(0,100), ylim=c(0,.1),
>>> col=rgb(0,0,1), main="")
>>>
>>> here i am using plot + points, but i do not like the graphical 
>>> output for
>>> points.
>>>  
>>
>> You are almost there, replace your last command by :
>>
>> points(kernelgraf, type="l", col="blue")
>>
>> Romain
>>
>> PS : Maybe a function points.density setting type="l" would be a good 
>> thing ?
>
> Or maybe use
>
> lines(kernelgraf, type="l", col="blue")
>
> As I always say, when you want lines, use lines().
>
> Duncan Murdoch
You are right Duncan,

I wish there was a coffea() function in R

;-)


-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From phawkins at connact.com  Sat Feb 11 21:30:41 2006
From: phawkins at connact.com (Patricia J. Hawkins)
Date: Sat, 11 Feb 2006 15:30:41 -0500
Subject: [R] srt --- slope text with function?
In-Reply-To: <50d1c22d0602051328t5f3e9fbeh4ef4283a76e8ac07@mail.gmail.com> (ivo
	welch's message of "Sun, 5 Feb 2006 16:28:50 -0500")
References: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>
	<43E51A7F.8080002@stats.uwo.ca>
	<50d1c22d0602041419y46761eb1x4f41fc82a5da9b60@mail.gmail.com>
	<644e1f320602041605y48295b4bs263c2d58589d73a3@mail.gmail.com>
	<50d1c22d0602051328t5f3e9fbeh4ef4283a76e8ac07@mail.gmail.com>
Message-ID: <wky80hvdse.fsf@connact.com>

>>>>> "iw" == ivo welch <ivowel at gmail.com> writes:

iw> * SUGGESTION: can we please offer the "?:" operator ala C in
iw> addition to ifelse()?  This would make R code prettier.

R:
if (condition) xxx else yyy
if (condition) xxx else if (yyy) zzz else qqq

C:
condition ? xxx : yyy;
condition ? xxx : yyy ? zzz : qqq;

If this is a beauty contest, or a readability contest, I'll take R!

?: is pleasant in C because it avoids so much of the C syntactic
sugar, of which R is largely free.

As for ifelse(), for a trivial example, try running:
ifelse(array(rep(c(1,0), 50), dim=c(10,10)), "00", "99")

iw> Similarly, perl has a nice construct, which would be lovely, but
iw> which may not jive with the
iw> R syntax:
iw>     condition  or die("the condition", condition, "has failed");
iw>     condition  and cat("my condition", condition, "is met");

        if (!condition) stop("the condition", condition, "has failed")
        if (condition)  cat("my condition", condition, "is met")

-- 
Patricia J. Hawkins
Hawkins Internet Applications
www.hawkinsia.com



From hans.gardfjell at emg.umu.se  Sat Feb 11 21:49:52 2006
From: hans.gardfjell at emg.umu.se (Hans Gardfjell)
Date: Sat, 11 Feb 2006 21:49:52 +0100
Subject: [R]  how do I "relate" tables in R?
References: 20060211031318.VVTB4713.tomts43-srv.bellnexxia.net@JohnDesktop8300
Message-ID: <43EE4DF0.7080700@emg.umu.se>

?merge

-- 

*********************************
Hans Gardfjell
Ecology and Environmental Science
Ume?? University
90187 Ume??, Sweden
email: hans.gardfjell at emg.umu.se
phone:  +46 907865267
mobile: +46 705984464



From lebouton at msu.edu  Sat Feb 11 22:28:21 2006
From: lebouton at msu.edu (Joseph LeBouton)
Date: Sat, 11 Feb 2006 15:28:21 -0600
Subject: [R] aggregate vs tapply; is there a middle ground?
Message-ID: <43EE56F5.80503@msu.edu>

Dear all,

I'm wanting to do a series of comparisons among 4 categorical variables:

a <- aggregate(y, list(var1, var2, var3, var4), sum)

This gets me a very nice 2-dimensional data frame with one column per 
variable, BUT, as help for aggregate says, <<empty subsets are 
removed>>.  I don't see in help(aggregate) how I can change this.

In contrast,
a <- tapply(y, list(var1, var2, var3, var4), sum)

gives me results for everything including empty subsets, but in an 
awkward 4-dimensional array that takes me another 10 lines of 
inefficient code to turn into a 2D data.frame.

Is there a way to directly do this calculation INCLUDING results for 
empty subsets, and still obtain a 2D array, matrix, or data.frame?  OR 
alternatively is there a simple way to mush the 4D result from the 
tapply into a 2D matrix/data.frame?

thanks very much in advance for any help!

-jlb

-- 
************************************
Joseph P. LeBouton
Forest Ecology PhD Candidate
Department of Forestry
Michigan State University
East Lansing, Michigan 48824

Office phone: 517-355-7744
email: lebouton at msu.edu



From hans.gardfjell at emg.umu.se  Sat Feb 11 23:24:48 2006
From: hans.gardfjell at emg.umu.se (Hans Gardfjell)
Date: Sat, 11 Feb 2006 23:24:48 +0100
Subject: [R]  aggregate vs tapply; is there a middle ground?
Message-ID: <43EE6430.5080908@emg.umu.se>

I faced a similar problem. Here's what I did

tmp <- 
data.frame(A=sample(LETTERS[1:5],10,replace=T),B=sample(letters[1:5],10,replace=T),C=rnorm(10))
tmp1 <- with(tmp,aggregate(C,list(A=A,B=B),sum))
tmp2 <- expand.grid(A=sort(unique(tmp$A)),B=sort(unique(tmp$B)))
merge(tmp2,tmp1,all.x=T)

At least fewer than 10 extra lines of code. Anyone with a simpler solution?

Cheers, Hans


lebouton wrote:
>
>Dear all,
>
>I'm wanting to do a series of comparisons among 4 categorical variables:
>
>a <- aggregate(y, list(var1, var2, var3, var4), sum)
>
>This gets me a very nice 2-dimensional data frame with one column per 
>variable, BUT, as help for aggregate says, <<empty subsets are 
>removed>>.  I don't see in help(aggregate) how I can change this.
>
>In contrast,
>a <- tapply(y, list(var1, var2, var3, var4), sum)
>
>gives me results for everything including empty subsets, but in an 
>awkward 4-dimensional array that takes me another 10 lines of 
>inefficient code to turn into a 2D data.frame.
>
>Is there a way to directly do this calculation INCLUDING results for 
>empty subsets, and still obtain a 2D array, matrix, or data.frame?  OR 
>alternatively is there a simple way to mush the 4D result from the 
>tapply into a 2D matrix/data.frame?
>
>thanks very much in advance for any help!
>
>-jlb
>
>-- 
>************************************
>Joseph P. LeBouton
>Forest Ecology PhD Candidate
>Department of Forestry
>Michigan State University
>East Lansing, Michigan 48824
>
>Office phone: 517-355-7744
>email: lebouton at msu.edu <https://stat.ethz.ch/mailman/listinfo/r-help>


-- 

*********************************
Hans Gardfjell
Ecology and Environmental Science
Ume?? University
90187 Ume??, Sweden
email: hans.gardfjell at emg.umu.se
phone:  +46 907865267
mobile: +46 705984464



From h.wickham at gmail.com  Sat Feb 11 23:44:53 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 11 Feb 2006 16:44:53 -0600
Subject: [R] aggregate vs tapply; is there a middle ground?
In-Reply-To: <43EE6430.5080908@emg.umu.se>
References: <43EE6430.5080908@emg.umu.se>
Message-ID: <f8e6ff050602111444n42affdaer16f94a1fb9ede76b@mail.gmail.com>

> I faced a similar problem. Here's what I did
>
> tmp <-
> data.frame(A=sample(LETTERS[1:5],10,replace=T),B=sample(letters[1:5],10,replace=T),C=rnorm(10))
> tmp1 <- with(tmp,aggregate(C,list(A=A,B=B),sum))
> tmp2 <- expand.grid(A=sort(unique(tmp$A)),B=sort(unique(tmp$B)))
> merge(tmp2,tmp1,all.x=T)
>
> At least fewer than 10 extra lines of code. Anyone with a simpler solution?

Well, you can almost do this in with the reshape package:

tmp <-
data.frame(A=sample(LETTERS[1:5],10,replace=T),B=sample(letters[1:5],10,replace=T),C=rnorm(10))
a <- recast(tmp, A + B ~ ., sum)
# see also recast(tmp, A  ~ B, sum)
add.all.combinations(a, row="A", cols = "B")

Where add.all.combinations basically does what you outlined above --
it would be easy enough to generalise to multiple dimensions.

Hadley



From lebouton at msu.edu  Sat Feb 11 23:45:48 2006
From: lebouton at msu.edu (Joseph LeBouton)
Date: Sat, 11 Feb 2006 16:45:48 -0600
Subject: [R] aggregate vs tapply; is there a middle ground?
In-Reply-To: <Pine.LNX.4.64.0602111359280.29892@springer.berkeley.edu>
References: <43EE56F5.80503@msu.edu>
	<Pine.LNX.4.64.0602111359280.29892@springer.berkeley.edu>
Message-ID: <43EE691C.1060309@msu.edu>

Thanks, Phil!  I've literally spent two hours on my own trying to find 
something that does exactly that.  Thanks for another pair of functions 
added to my (slowly!) growing R vocabulary.

-jlb

Phil Spector wrote:
> Joseph -
>    I'm sure there are clearer and more efficient ways to do it, but 
> here's something
> that seems to do what you want:
> 
> z = tapply(y,list(var1,var2,var3,var4),sum)
> data.frame(do.call('expand.grid',dimnames(z)),y=do.call('rbind',as.list(z))) 
> 
> 
>                                        - Phil Spector
>                      Statistical Computing Facility
>                      Department of Statistics
>                      UC Berkeley
>                      spector at stat.berkeley.edu
> 
> 
> On Sat, 11 Feb 2006, Joseph LeBouton wrote:
> 
>> Dear all,
>>
>> I'm wanting to do a series of comparisons among 4 categorical variables:
>>
>> a <- aggregate(y, list(var1, var2, var3, var4), sum)
>>
>> This gets me a very nice 2-dimensional data frame with one column per
>> variable, BUT, as help for aggregate says, <<empty subsets are
>> removed>>.  I don't see in help(aggregate) how I can change this.
>>
>> In contrast,
>> a <- tapply(y, list(var1, var2, var3, var4), sum)
>>
>> gives me results for everything including empty subsets, but in an
>> awkward 4-dimensional array that takes me another 10 lines of
>> inefficient code to turn into a 2D data.frame.
>>
>> Is there a way to directly do this calculation INCLUDING results for
>> empty subsets, and still obtain a 2D array, matrix, or data.frame?  OR
>> alternatively is there a simple way to mush the 4D result from the
>> tapply into a 2D matrix/data.frame?
>>
>> thanks very much in advance for any help!
>>
>> -jlb
>>
>> -- 
>> ************************************
>> Joseph P. LeBouton
>> Forest Ecology PhD Candidate
>> Department of Forestry
>> Michigan State University
>> East Lansing, Michigan 48824
>>
>> Office phone: 517-355-7744
>> email: lebouton at msu.edu
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
> 
> 

-- 
************************************
Joseph P. LeBouton
Forest Ecology PhD Candidate
Department of Forestry
Michigan State University
East Lansing, Michigan 48824

Office phone: 517-355-7744
email: lebouton at msu.edu



From zpzhang at stanfordalumni.org  Sun Feb 12 00:02:48 2006
From: zpzhang at stanfordalumni.org (Zepu Zhang)
Date: Sat, 11 Feb 2006 15:02:48 -0800
Subject: [R] failed installing hdf5 package--can't find zlib
Message-ID: <185kBkXcW5376S21.1139698968@cmsweb21.cms.usa.net>

I use Mac, tried to install the package hdf5-1.6. Its configuration script
can't find zlib, which 
apparently exists in my /usr directory. I used

R CMD INSTALL --configure-args=--with-hdf5=/sw 
--configure-args=--with-zlib=/usr 
hdf5....tar.gz

It still can't find zlib. Is this a bug? Any pointer is appreciated.

Zepu



From ggrothendieck at gmail.com  Sun Feb 12 00:17:40 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 11 Feb 2006 18:17:40 -0500
Subject: [R] srt --- slope text with function?
In-Reply-To: <wky80hvdse.fsf@connact.com>
References: <50d1c22d0602041250m6ab1fabdr2d49363511dc6c39@mail.gmail.com>
	<43E51A7F.8080002@stats.uwo.ca>
	<50d1c22d0602041419y46761eb1x4f41fc82a5da9b60@mail.gmail.com>
	<644e1f320602041605y48295b4bs263c2d58589d73a3@mail.gmail.com>
	<50d1c22d0602051328t5f3e9fbeh4ef4283a76e8ac07@mail.gmail.com>
	<wky80hvdse.fsf@connact.com>
Message-ID: <971536df0602111517s45db073dubfe1bbd99062609a@mail.gmail.com>

On 2/11/06, Patricia J. Hawkins <phawkins at connact.com> wrote:
> >>>>> "iw" == ivo welch <ivowel at gmail.com> writes:
>
> iw> * SUGGESTION: can we please offer the "?:" operator ala C in
> iw> addition to ifelse()?  This would make R code prettier.
>
> R:
> if (condition) xxx else yyy
> if (condition) xxx else if (yyy) zzz else qqq
>
> C:
> condition ? xxx : yyy;
> condition ? xxx : yyy ? zzz : qqq;
>
> If this is a beauty contest, or a readability contest, I'll take R!
>
> ?: is pleasant in C because it avoids so much of the C syntactic
> sugar, of which R is largely free.
>
> As for ifelse(), for a trivial example, try running:
> ifelse(array(rep(c(1,0), 50), dim=c(10,10)), "00", "99")

Maybe this is not the point but in this particular example
we could write:

matrix(c("00", "99"), 10, 10)

>
> iw> Similarly, perl has a nice construct, which would be lovely, but
> iw> which may not jive with the
> iw> R syntax:
> iw>     condition  or die("the condition", condition, "has failed");
> iw>     condition  and cat("my condition", condition, "is met");
>
>        if (!condition) stop("the condition", condition, "has failed")
>        if (condition)  cat("my condition", condition, "is met")
>

Try this:

stopifnot(condition)


> --
> Patricia J. Hawkins
> Hawkins Internet Applications
> www.hawkinsia.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Sun Feb 12 00:37:46 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 Feb 2006 00:37:46 +0100
Subject: [R] aggregate vs tapply; is there a middle ground?
In-Reply-To: <f8e6ff050602111444n42affdaer16f94a1fb9ede76b@mail.gmail.com>
References: <43EE6430.5080908@emg.umu.se>
	<f8e6ff050602111444n42affdaer16f94a1fb9ede76b@mail.gmail.com>
Message-ID: <x264nlh3g5.fsf@turmalin.kubism.ku.dk>

hadley wickham <h.wickham at gmail.com> writes:

> > I faced a similar problem. Here's what I did
> >
> > tmp <-
> > data.frame(A=sample(LETTERS[1:5],10,replace=T),B=sample(letters[1:5],10,replace=T),C=rnorm(10))
> > tmp1 <- with(tmp,aggregate(C,list(A=A,B=B),sum))
> > tmp2 <- expand.grid(A=sort(unique(tmp$A)),B=sort(unique(tmp$B)))
> > merge(tmp2,tmp1,all.x=T)
> >
> > At least fewer than 10 extra lines of code. Anyone with a simpler solution?
> 
> Well, you can almost do this in with the reshape package:
> 
> tmp <-
> data.frame(A=sample(LETTERS[1:5],10,replace=T),B=sample(letters[1:5],10,replace=T),C=rnorm(10))
> a <- recast(tmp, A + B ~ ., sum)
> # see also recast(tmp, A  ~ B, sum)
> add.all.combinations(a, row="A", cols = "B")
> 
> Where add.all.combinations basically does what you outlined above --
> it would be easy enough to generalise to multiple dimensions.

Anything wrong with

> as.data.frame(with(tmp,as.table(tapply(C,list(A=A,B=B),sum))))
   A B       Freq
1  A a         NA
2  B a -0.2524320
3  C a  3.8539264
4  D a         NA
5  A c  0.7227294
6  B c -0.2694669
7  C c  0.4760957
8  D c         NA
9  A e         NA
10 B e  0.1800500
11 C e         NA
12 D e -1.0350928

(except the silly colname, responseName="sum" should fix that).

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From kubovy at virginia.edu  Sun Feb 12 03:23:27 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Sat, 11 Feb 2006 21:23:27 -0500
Subject: [R] Mathematical typesetting of column heads using the latex
	(Hmisc) function
Message-ID: <D9BB394A-C949-4E01-82A2-6F41C17C3FDB@virginia.edu>

Dear r-helpers,

I would very much appreciate help with the following problem:

The following command (in a .Rnw file)

latex(anova(e7.lmer3, e7.lmer4), file = 'e7lmer34.tex', rowname = c 
('nonlinear', 'linear'), longtable = FALSE, dcolumn = T, booktabs =  
T, table.env = F)

produces the following output after running Sweave:

% latex.default(anova(e7.lmer1, e7.lmer2), file =  
"e7lmer12.tex",      rowname = c("nonlinear", "linear"), longtable =  
FALSE, dcolumn = T,      booktabs = T, table.env = F)
%
\newcolumntype{.}{D{.}{.}{-1}}
\begin{center}
\begin{tabular}{l.......}\toprule
\multicolumn{1}{l}{anova}&
\multicolumn{1}{c}{Df}&
\multicolumn{1}{c}{AIC}&
\multicolumn{1}{c}{BIC}&
\multicolumn{1}{c}{logLik}&
\multicolumn{1}{c}{Chisq}&
\multicolumn{1}{c}{Chi Df}&
\multicolumn{1}{c}{Pr(>Chisq)}
<snip>

I would like it to produce

\newcolumntype{.}{D{.}{.}{-1}}
\begin{center}
\begin{tabular}{l.......}\toprule
&
\multicolumn{1}{c}{d.f.}&
\multicolumn{1}{c}{\textsc{aic}}&
\multicolumn{1}{c}{\textsc{bic}}&
\multicolumn{1}{c}{$\log{(\mathcal{L})}$}&
\multicolumn{1}{c}{$\chi^{2}$}&
\multicolumn{1}{c}{\chi^{2}$ d.f.}&
\multicolumn{1}{c}{Pr($> \chi^{2}$)}
<snip>


_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From patrick.giraudoux at univ-fcomte.fr  Sun Feb 12 08:44:24 2006
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 12 Feb 2006 08:44:24 +0100
Subject: [R] lme, nlsList, nlsList.selfStart
Message-ID: <43EEE758.2050408@univ-fcomte.fr>

Dear listers,

I am trying to fit a model using nlsList() using alternately a SSfol() 
selfstart function or its developped equivalent formulae.

This preliminary trial works well

mydata<-groupedData(Conc~Tps|Organ,data=mydata)
mymod1<-nls(Conc~SSfol(Dose,Tps,lKe,lKa,lCl),data=mydata)

as well as a developped form:

mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) * 
(exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
    data=mydata,
    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
    )

However when trying to fit the model with nlsList, I get:

mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) * 
(exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
     data=mydata,
     start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
     )
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
        variable lengths differ
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
        variable lengths differ
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
        variable lengths differ

Or specifying  the grouping factor explicitely:

mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) * 
(exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe))|Organ,
     data=mydata,
     start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
     )

Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
        variable lengths differ
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
        variable lengths differ
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
        variable lengths differ


I cannot find out why the grouping factor cannot be used (it has the 
same length as the other variables...)

Another strange thing occurs: in the example given in the help of 
nlsList.selfstart, the following command works  well:

 fm1 <- nlsList(SSasympOff, CO2)

However its seemingly equivalent applied to the case above fails:

mymod4<-nlsList(SSfol,data=mydata)
Error in eval(expr, envir, enclos) : object "input" not found
Error in eval(expr, envir, enclos) : object "input" not found
Error in eval(expr, envir, enclos) : object "input" not found


Any hint/suggestion appreciated.

Kind regards,

Patrick Giraudoux



From m_hofert at web.de  Sun Feb 12 09:52:25 2006
From: m_hofert at web.de (Jan Marius Hofert)
Date: Sun, 12 Feb 2006 09:52:25 +0100
Subject: [R] contour lines for levelplot
Message-ID: <B28648E6-C2B1-4153-8F55-E7996F2BBEA5@web.de>

Hi,

I would like to add contour lines to a (trellis/lattice-) levelplot.  
Sure, there is the "contour=TRUE" argument, but this uses  
"cuts=..." (which is usually chosen very high for my plots. I guess  
cuts=99 is the best you can do (?)) for plotting the contour lines.  
Furthermore, I do not like the numbering of the contour lines this  
way. Therefore, I tried to add a standard contour plot. There are 2  
problems to do this. First, as I would like to have the levelplot  
with a colorkey, the contour lines are plotted over the colorkey (see  
example code below). I could not fix this problem by changing the  
aspect argument of the levelplot call or by working with xlim and  
ylim in the contour plot function. Second, I am not sure if the  
contour lines added this way actually represent the points they  
should (e.g. does the contour line labeled with 0.5 really hit the  
points of this height?). So, is there a simple way of how to add the  
contour lines (of the contour function) to the levelplot this way? If  
not, is it possible to plot the levelplot with cuts=99 but only draw  
the contour lines (with the option "contour=TRUE" in the levelplot  
call) at specified points? Is it possible to tell the levelplot  
function (with cuts=99) to plot a specified number of contour lines  
(say, only to plot 10 contour lines in the whole existing range of z- 
values)?

Thank you very much in advance

Marius
m_hofert at web.de

example code:

remove(list=objects())
x.1<-rep(seq(0,1,by=0.04),each=26)
x.2 <- 0.04*(0:25)
y.1<-rep(x.2,26)
y.2 <- 0.04*(0:25)
z.1 <-x.1*y.1
z.2<- matrix(unlist(z.1),ncol=26,byrow=TRUE)
library(lattice) #for trellis-like graphical plots
plot.new()
levelplot(z.1~x.1*y.1,xlim=c(0,1),ylim=c(0,1),aspect=1,scales=list 
(relation="free",tick.number=6),cuts=99,colorkey=list(tick.number=6))
contour(x.2,y.2,z.2,levels=seq(0,1,by=0.1),add=TRUE,col="black")



From szlevine at nana.co.il  Sun Feb 12 10:48:17 2006
From: szlevine at nana.co.il (Stephen)
Date: Sun, 12 Feb 2006 11:48:17 +0200
Subject: [R] frailty
Message-ID: <E76EB96029DCAE4A9CB967D7F6712D1DBFD687@NANAMAILBACK1.nanamail.co.il>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060212/2b38ada1/attachment.pl

From spencer.graves at pdf.com  Sun Feb 12 11:25:24 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 12 Feb 2006 02:25:24 -0800
Subject: [R] Baysian model averaging method
In-Reply-To: <20060208061801.13380.qmail@webmail36.rediffmail.com>
References: <20060208061801.13380.qmail@webmail36.rediffmail.com>
Message-ID: <43EF0D14.2020205@pdf.com>

	  I'm not certain what you are asking.  Do you want to fit a time 
series model using Bayesian Model Averaging (BMA), or do you want to 
predictions with confidence intervals from a BMA fit or both?  For any 
of these, I suggest you start with the posting guide! 
"www.R-project.org/posting-guide.html" and with "RSiteSearch" in 
particular.  I just got 31 hits from 'RSiteSearch("Baysian model 
averaging")', which included discussions of the BMA and ensembleBMA 
packages as well as an article on "BMA:  An R package for Bayesian Model 
Averaging" by Raferty, Painter and Volinsky, 3 of the 4 authors of the 
BMA package.

	  I couldn't find a function for a BMA time series fit.  If I wanted 
that, I'd probably start by asking the maintainers for "BMA" and 
"ensembleBMA" (cc'ed on this reply) and by reading the code for the 
nearest things I could find.  I'd make local copies of one or more 
functions and try to walk through the code line by line until I thought 
I understood it well enough to modify it to do what I wanted.  With 
luck, someone may reply to this email with hints or even code that might 
make that task easier.

	  hope this helps,
	  spencer graves
p.s.  If I had understood your question better, I might have been able 
to supply more useful suggestions.

anil kumar rohilla wrote:
>   
> HI, List 
>      I want to know weather any body has used BMA Package for model 
averaging for prediction of future values.....What are the paprmeters
we have to suplly to the model. Any script for the same.
> 
> thanks in advance
> 
> 
> ANIL KUMAR( METEOROLOGIST)
> LRF SECTION 
> NATIONAL CLIMATE CENTER 
> ADGM(RESEARCH)
> INDIA METEOROLOGICAL DEPARTMENT
> SHIVIJI NAGAR
> PUNE-411005 INDIA
> MOBILE +919422023277
> anilkumar at imdpune.gov.in
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rahmank at frim.gov.my  Mon Feb 13 05:12:45 2006
From: rahmank at frim.gov.my (Abd Rahman Kassim)
Date: Sun, 12 Feb 2006 20:12:45 -0800
Subject: [R] Plotting contour & filled.contour in one graph
Message-ID: <001001c63053$be446510$4202a8c0@DrAbRahmandt7>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060212/499bbb95/attachment.pl

From francoisromain at free.fr  Sun Feb 12 13:27:02 2006
From: francoisromain at free.fr (Romain Francois)
Date: Sun, 12 Feb 2006 13:27:02 +0100
Subject: [R] Plotting contour & filled.contour in one graph
In-Reply-To: <001001c63053$be446510$4202a8c0@DrAbRahmandt7>
References: <001001c63053$be446510$4202a8c0@DrAbRahmandt7>
Message-ID: <43EF2996.2000000@free.fr>

Le 13.02.2006 05:12, Abd Rahman Kassim a ??crit :
> Dear All,
>
> I have a question on overlaying a filled.contour (e.g. on soil properties data) and contour (by elevation) in one graph. Both have the same z matrix dimension. I'm able to overlay both graph, but the plots dimension did not overlap well on the same plots. How can I have both filled.contour and contour on the same graph? The commands that I have written are as follows:
>
> filled.contour(0:15,0:10,t(matrix(Total.C,nrow=11,ncol=16)))
> contour(0:15,0:10,as.matrix(elev),add=T)
>
> Thanks for anay assistance.
>
> Regards.
>
>
> Abd Rahman Kassim
> Forest Research Institute Malaysia
> Kepong 52109
> Selangor, MALAYSIA
>   
Hi,

The trick is to use the argument plot.axes of filled.contour
There are examples of that in ?filled.contour

See also : http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=128

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From rahmank at frim.gov.my  Mon Feb 13 06:28:18 2006
From: rahmank at frim.gov.my (Abd Rahman Kassim)
Date: Sun, 12 Feb 2006 21:28:18 -0800
Subject: [R] Plotting contour & filled.contour in one graph
References: <001001c63053$be446510$4202a8c0@DrAbRahmandt7> 
	<43EF2996.2000000@free.fr>
Message-ID: <001501c6305e$4c123ac0$4202a8c0@DrAbRahmandt7>


Dear Romain,

Thanks a lot for the suggested website and program code. I got it run.

Thanks.

Abd. Rahman Kassim
----- Original Message ----- 
From: "Romain Francois" <francoisromain at free.fr>
To: "Abd Rahman Kassim" <rahmank at frim.gov.my>
Cc: <r-help at stat.math.ethz.ch>
Sent: Sunday, February 12, 2006 4:27 AM
Subject: Re: [R] Plotting contour & filled.contour in one graph


>
> Le 13.02.2006 05:12, Abd Rahman Kassim a ??crit :
>> Dear All,
>>
>> I have a question on overlaying a filled.contour (e.g. on soil properties 
>> data) and contour (by elevation) in one graph. Both have the same z 
>> matrix dimension. I'm able to overlay both graph, but the plots dimension 
>> did not overlap well on the same plots. How can I have both 
>> filled.contour and contour on the same graph? The commands that I have 
>> written are as follows:
>>
>> filled.contour(0:15,0:10,t(matrix(Total.C,nrow=11,ncol=16)))
>> contour(0:15,0:10,as.matrix(elev),add=T)
>>
>> Thanks for anay assistance.
>>
>> Regards.
>>
>>
>> Abd Rahman Kassim
>> Forest Research Institute Malaysia
>> Kepong 52109
>> Selangor, MALAYSIA
>>
> Hi,
>
> The trick is to use the argument plot.axes of filled.contour
> There are examples of that in ?filled.contour
>
> See also : 
> http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=128
>
> Romain
>
> -- 
> visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
> mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
> +---------------------------------------------------------------+
> | Romain FRANCOIS - http://francoisromain.free.fr               |
> | Doctorant INRIA Futurs / EDF                                  |
> +---------------------------------------------------------------+
>
>
>
> *****************************************
> Outgoing mail is certified Virus Free.
> Checked by TrendMicro Interscan Messaging Security.
> For any enquiries, please contact FRIM IT Department.
> *****************************************



From lebouton at msu.edu  Sun Feb 12 16:36:50 2006
From: lebouton at msu.edu (Joseph LeBouton)
Date: Sun, 12 Feb 2006 09:36:50 -0600
Subject: [R] SUMMARY: aggregate vs. tapply
Message-ID: <43EF5612.1010606@msu.edu>

Hi all;

Thanks for the responses to my query of how to make tapply into a table 
instead of an n-dimensional array.  Summary of responses follows:

Peter Dalgaard:
as.data.frame(with(tmp,as.table(tapply(C,list(A=A,B=B),sum))))

Phil Spector wrote:
z = tapply(y,list(var1,var2,var3,var4),sum)
data.frame(do.call('expand.grid',dimnames(z)),y=do.call('rbind',as.list(z)))

Hans Gardfjell:
tmp <- 
data.frame(A=sample(LETTERS[1:5],10,replace=T),B=sample(letters[1:5],10,replace=T),C=rnorm(10))
tmp1 <- with(tmp,aggregate(C,list(A=A,B=B),sum))
tmp2 <- expand.grid(A=sort(unique(tmp$A)),B=sort(unique(tmp$B)))
merge(tmp2,tmp1,all.x=T)

hadley wickham:
Well, you can almost do this in with the reshape package:
tmp <-
data.frame(A=sample(LETTERS[1:5],10,replace=T),B=sample(letters[1:5],10,replace=T),C=rnorm(10))
a <- recast(tmp, A + B ~ ., sum)
# see also recast(tmp, A  ~ B, sum)
add.all.combinations(a, row="A", cols = "B")


Good thing there are so many code cats around, 'cause we have so darn 
many ways to skin 'em. Thanks again to all who took the time to answer!!

-Joseph
-- 
************************************
Joseph P. LeBouton
Forest Ecology PhD Candidate
Department of Forestry
Michigan State University
East Lansing, Michigan 48824

Office phone: 517-355-7744
email: lebouton at msu.edu



From Mike.Prager at noaa.gov  Sun Feb 12 17:25:13 2006
From: Mike.Prager at noaa.gov (Michael Prager)
Date: Sun, 12 Feb 2006 11:25:13 -0500
Subject: [R] Plotting contour & filled.contour in one graph
In-Reply-To: <001001c63053$be446510$4202a8c0@DrAbRahmandt7>
References: <001001c63053$be446510$4202a8c0@DrAbRahmandt7>
Message-ID: <43EF6169.4030509@noaa.gov>

Besides the answers you already have, you might look at my "4D" graph 
example (with code) on the R Graphics Gallery:

http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=90

I think it does exactly what you are asking, and therefore it might fit 
your needs with only slight code modification.

Mike Prager


Abd Rahman Kassim wrote on 2/12/2006 11:12 PM:
> Dear All,
>
> I have a question on overlaying a filled.contour (e.g. on soil properties data) and contour (by elevation) in one graph. Both have the same z matrix dimension. I'm able to overlay both graph, but the plots dimension did not overlap well on the same plots. How can I have both filled.contour and contour on the same graph? The commands that I have written are as follows:
>
> filled.contour(0:15,0:10,t(matrix(Total.C,nrow=11,ncol=16)))
> contour(0:15,0:10,as.matrix(elev),add=T)
>
> Thanks for anay assistance.
>
> Regards.
>
>
> Abd Rahman Kassim
> Forest Research Institute Malaysia
> Kepong 52109
> Selangor, MALAYSIA
>
> *****************************************
>
>
> *****************************************
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>   

-- 
Michael H. Prager, Ph.D.
Population Dynamics Team
NOAA Center for Coastal Habitat and Fisheries Research
NMFS Southeast Fisheries Science Center
Beaufort, North Carolina  28516  USA
http://shrimp.ccfhrb.noaa.gov/~mprager/



From ggrothendieck at gmail.com  Sun Feb 12 17:31:16 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 12 Feb 2006 11:31:16 -0500
Subject: [R] Plotting contour & filled.contour in one graph
In-Reply-To: <43EF6169.4030509@noaa.gov>
References: <001001c63053$be446510$4202a8c0@DrAbRahmandt7>
	<43EF6169.4030509@noaa.gov>
Message-ID: <971536df0602120831i61039355vbe704f043483bdcb@mail.gmail.com>

Could you walk us through, in detail, what that graph is showing?


On 2/12/06, Michael Prager <Mike.Prager at noaa.gov> wrote:
> Besides the answers you already have, you might look at my "4D" graph
> example (with code) on the R Graphics Gallery:
>
> http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=90
>
> I think it does exactly what you are asking, and therefore it might fit
> your needs with only slight code modification.
>
> Mike Prager
>
>
> Abd Rahman Kassim wrote on 2/12/2006 11:12 PM:
> > Dear All,
> >
> > I have a question on overlaying a filled.contour (e.g. on soil properties data) and contour (by elevation) in one graph. Both have the same z matrix dimension. I'm able to overlay both graph, but the plots dimension did not overlap well on the same plots. How can I have both filled.contour and contour on the same graph? The commands that I have written are as follows:
> >
> > filled.contour(0:15,0:10,t(matrix(Total.C,nrow=11,ncol=16)))
> > contour(0:15,0:10,as.matrix(elev),add=T)
> >
> > Thanks for anay assistance.
> >
> > Regards.
> >
> >
> > Abd Rahman Kassim
> > Forest Research Institute Malaysia
> > Kepong 52109
> > Selangor, MALAYSIA
> >
> > *****************************************
> >
> >
> > *****************************************
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>
> --
> Michael H. Prager, Ph.D.
> Population Dynamics Team
> NOAA Center for Coastal Habitat and Fisheries Research
> NMFS Southeast Fisheries Science Center
> Beaufort, North Carolina  28516  USA
> http://shrimp.ccfhrb.noaa.gov/~mprager/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From islandboy1982 at yahoo.com  Sun Feb 12 17:35:06 2006
From: islandboy1982 at yahoo.com (oliver wee)
Date: Sun, 12 Feb 2006 08:35:06 -0800 (PST)
Subject: [R] differencing a time series
Message-ID: <20060212163506.89675.qmail@web33209.mail.mud.yahoo.com>

Hello, I need some help in differencing a time series.

For example I have a data set with 100 data points. I
need to create a new dataset that consists of the
difference of two succeeding data points.

something akin to this formula in java:
for (int i = 0, i < 100, i++)
{
  newdataset[i] = olddataset[i] - olddataset[i-1]
}

any help is appreciated. Thanks



From ripley at stats.ox.ac.uk  Sun Feb 12 17:54:11 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 12 Feb 2006 16:54:11 +0000 (GMT)
Subject: [R] differencing a time series
In-Reply-To: <20060212163506.89675.qmail@web33209.mail.mud.yahoo.com>
References: <20060212163506.89675.qmail@web33209.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0602121649240.11364@gannet.stats.ox.ac.uk>

On Sun, 12 Feb 2006, oliver wee wrote:

> Hello, I need some help in differencing a time series.
>
> For example I have a data set with 100 data points. I
> need to create a new dataset that consists of the
> difference of two succeeding data points.
>
> something akin to this formula in java:
> for (int i = 0, i < 100, i++)
> {
>  newdataset[i] = olddataset[i] - olddataset[i-1]
> }

Surely that is incorrect: what is olddataset[-1] in Java?

R does this right in diff().

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Sun Feb 12 18:20:11 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 12 Feb 2006 09:20:11 -0800
Subject: [R] Plotting contour & filled.contour in one graph
In-Reply-To: <971536df0602120831i61039355vbe704f043483bdcb@mail.gmail.com>
References: <001001c63053$be446510$4202a8c0@DrAbRahmandt7>	<43EF6169.4030509@noaa.gov>
	<971536df0602120831i61039355vbe704f043483bdcb@mail.gmail.com>
Message-ID: <43EF6E4B.5090701@pdf.com>

Hi Michael and Gabor:

GABOR:  Prager's '4D' graph looks to me like superimposed contours of 
both z and zz vs. (x, y), where z is indicated by the colors and pale 
lines, while "black contour lines are values of zz" (as indicated by the 
labeling).  I once wrote a crudely similar function to prepare contour 
plots showing any number of z variables vs. (x, y), with each z variable 
using different colors of contours and filling not with solid colors but 
with cross hatching at different angles.  A reagion of acceptability 
satisfying multiple inequality constraints would appear as all white, 
i.e., with no cross hatching, in such a plot.  (Unfortunately, I never 
found the time to get the function adequately dubugged and packaged so 
others could easily use it.)

MICHAEL:  The "Addicted to R" web site with it's "R Graph Gallery" are 
pretty.  Is a companion package downloadable from CRAN, or are they 
still looking for volunteers to create the necessary help files, etc.?

	  Best Wishes,
	  spencer graves

Gabor Grothendieck wrote:
> Could you walk us through, in detail, what that graph is showing?
> 
> 
> On 2/12/06, Michael Prager <Mike.Prager at noaa.gov> wrote:
> 
>>Besides the answers you already have, you might look at my "4D" graph
>>example (with code) on the R Graphics Gallery:
>>
>>http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=90
>>
>>I think it does exactly what you are asking, and therefore it might fit
>>your needs with only slight code modification.
>>
>>Mike Prager
>>
>>
>>Abd Rahman Kassim wrote on 2/12/2006 11:12 PM:
>>
>>>Dear All,
>>>
>>>I have a question on overlaying a filled.contour (e.g. on soil properties data) and contour (by elevation) in one graph. Both have the same z matrix dimension. I'm able to overlay both graph, but the plots dimension did not overlap well on the same plots. How can I have both filled.contour and contour on the same graph? The commands that I have written are as follows:
>>>
>>>filled.contour(0:15,0:10,t(matrix(Total.C,nrow=11,ncol=16)))
>>>contour(0:15,0:10,as.matrix(elev),add=T)
>>>
>>>Thanks for anay assistance.
>>>
>>>Regards.
>>>
>>>
>>>Abd Rahman Kassim
>>>Forest Research Institute Malaysia
>>>Kepong 52109
>>>Selangor, MALAYSIA
>>>
>>>*****************************************
>>>
>>>
>>>*****************************************
>>>      [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>
>>--
>>Michael H. Prager, Ph.D.
>>Population Dynamics Team
>>NOAA Center for Coastal Habitat and Fisheries Research
>>NMFS Southeast Fisheries Science Center
>>Beaufort, North Carolina  28516  USA
>>http://shrimp.ccfhrb.noaa.gov/~mprager/
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From francoisromain at free.fr  Sun Feb 12 18:38:32 2006
From: francoisromain at free.fr (Romain Francois)
Date: Sun, 12 Feb 2006 18:38:32 +0100
Subject: [R] Plotting contour & filled.contour in one graph
In-Reply-To: <43EF6E4B.5090701@pdf.com>
References: <001001c63053$be446510$4202a8c0@DrAbRahmandt7>	<43EF6169.4030509@noaa.gov>	<971536df0602120831i61039355vbe704f043483bdcb@mail.gmail.com>
	<43EF6E4B.5090701@pdf.com>
Message-ID: <43EF7298.9010605@free.fr>

Le 12.02.2006 18:20, Spencer Graves a ??crit :
> Hi Michael and Gabor:
>
> (...)
>
> MICHAEL:  The "Addicted to R" web site with it's "R Graph Gallery" are 
> pretty.  Is a companion package downloadable from CRAN
Not yet. That's something i've wanted to do in a long time (since the
beginning I think), but ...
> , or are they 
> still looking for volunteers to create the necessary help files, etc.?
>   
Anyone with ideas could volonteer something. Recently, i've done
something so that users can make comments about specified regions of a
graphic. See graph 29 for a first use of that toy, move the mouse on top
of the graphic, you should see it .. . (I hope that works ok with
several browsers, because javascript is involved)

A little sister of the R Graph Gallery could be a movie gallery created
with R. For example :
* illustration of the CLT
* convergence of the EM algorithm (there is an example here :
http://addictedtor.free.fr/misc/smalEM.avi )
* kernel density estimation varying the bandwidth
* etc ....

Let me know if you feel like you want to help doing something

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
mixmod 1.7 is released : http://www-math.univ-fcomte.fr/mixmod/index.php
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From Lucy.Crooks at env.ethz.ch  Sun Feb 12 18:48:04 2006
From: Lucy.Crooks at env.ethz.ch (Lucy Crooks)
Date: Sun, 12 Feb 2006 18:48:04 +0100
Subject: [R] one legend for multiple plots
Message-ID: <76CB891C-FD59-48F3-BDCE-C66864AFE9F2@env.ethz.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060212/38dcc130/attachment.pl

From ligges at statistik.uni-dortmund.de  Sun Feb 12 18:52:20 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 12 Feb 2006 18:52:20 +0100
Subject: [R] one legend for multiple plots
In-Reply-To: <76CB891C-FD59-48F3-BDCE-C66864AFE9F2@env.ethz.ch>
References: <76CB891C-FD59-48F3-BDCE-C66864AFE9F2@env.ethz.ch>
Message-ID: <43EF75D4.8020809@statistik.uni-dortmund.de>

Lucy Crooks wrote:

> Does anyone know how to make one legend above the plots drawn using  
> par(mfrow=c(1,2)), ie in the margin?
> All I've managed is to put a legend inside the plot region of one  
> graph. Although I could write text in the margin I don't know how to  
> draw lines in the margin if I were to construct the legend from scratch.

You can simply use legend, but specify par(xpd=TRUE) before...

Uwe Ligges

> Thanks for any help.
> 
> 
> Lucy Crooks
> Theoretical Biology
> Universit??tstrasse 16
> ETH Zentrum, CHN 75.1
> CH-8092 Zurich
> 
> Tel.: 0041 44 632 8326
> Fax: 0041 44 632 1271
> 
> http://www.eco.ethz.ch/
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Felipe.Martinez at uclm.es  Sun Feb 12 19:10:14 2006
From: Felipe.Martinez at uclm.es (=?ISO-8859-15?Q?Felipe_Mart=EDnez-Pastor?=)
Date: Sun, 12 Feb 2006 19:10:14 +0100
Subject: [R] Discriminant analysis to select best treatment
Message-ID: <43EF7A06.5070702@uclm.es>

I am designing an experiment to trial several analytic techniques on
samples submitted to different treatments. It has occurred to me that I
may use discriminant analysis to find out which kind of analysis best
reveals differences between treatments.

I have found the lda {MASS} in R. However, I am not sure if it is
adequate to my case, since it performs linear discriminant analysis but
--apparently-- not variable selection. In SAS I would use the STEPDISC
procedure, whose description is:
"uses forward selection, backward elimination, or stepwise selection to
try to find a subset of quantitative variables that best reveals
differences among the classes."

I wonder if I could use lda or other function in that way. Maybe you
could point me to any resource (I am really new in discriminant analysis).

Thank you.

--------------------oOo--------------------
Felipe Mart??nez Pastor, Ph. D.
Ciencia y Tecnolog??a Agroforestal
ETSIA-UCLM
Av. Espa??a s/n
02071-Albacete (Spain)
Phone: +34 967 599 200+2581
Fax:   +34 967 599 238+2081
Mobile: +34 687 365 362
e-mail: Felipe.Martinez at uclm.es
Jabber: felipe.martinez at jabberes.org



-- 
Ning??n investigador sin contrato.
Employment rights for Spanish junior researchers.
	http://www.precarios.org



From f.harrell at vanderbilt.edu  Sun Feb 12 19:31:23 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sun, 12 Feb 2006 12:31:23 -0600
Subject: [R] Mathematical typesetting of column heads using the latex
 (Hmisc) function
In-Reply-To: <D9BB394A-C949-4E01-82A2-6F41C17C3FDB@virginia.edu>
References: <D9BB394A-C949-4E01-82A2-6F41C17C3FDB@virginia.edu>
Message-ID: <43EF7EFB.5090709@vanderbilt.edu>

Michael Kubovy wrote:
> Dear r-helpers,
> 
> I would very much appreciate help with the following problem:
> 
> The following command (in a .Rnw file)
> 
> latex(anova(e7.lmer3, e7.lmer4), file = 'e7lmer34.tex', rowname = c 
> ('nonlinear', 'linear'), longtable = FALSE, dcolumn = T, booktabs =  
> T, table.env = F)
> 
> produces the following output after running Sweave:
> 
> % latex.default(anova(e7.lmer1, e7.lmer2), file =  
> "e7lmer12.tex",      rowname = c("nonlinear", "linear"), longtable =  
> FALSE, dcolumn = T,      booktabs = T, table.env = F)
> %
> \newcolumntype{.}{D{.}{.}{-1}}
> \begin{center}
> \begin{tabular}{l.......}\toprule
> \multicolumn{1}{l}{anova}&
> \multicolumn{1}{c}{Df}&
> \multicolumn{1}{c}{AIC}&
> \multicolumn{1}{c}{BIC}&
> \multicolumn{1}{c}{logLik}&
> \multicolumn{1}{c}{Chisq}&
> \multicolumn{1}{c}{Chi Df}&
> \multicolumn{1}{c}{Pr(>Chisq)}
> <snip>
> 
> I would like it to produce
> 
> \newcolumntype{.}{D{.}{.}{-1}}
> \begin{center}
> \begin{tabular}{l.......}\toprule
> &
> \multicolumn{1}{c}{d.f.}&
> \multicolumn{1}{c}{\textsc{aic}}&
> \multicolumn{1}{c}{\textsc{bic}}&
> \multicolumn{1}{c}{$\log{(\mathcal{L})}$}&
> \multicolumn{1}{c}{$\chi^{2}$}&
> \multicolumn{1}{c}{\chi^{2}$ d.f.}&
> \multicolumn{1}{c}{Pr($> \chi^{2}$)}
> <snip>
> 
> 
> _____________________________
> Professor Michael Kubovy
> University of Virginia

Michael - your e-mail is incomplete in a number of ways (output of 
typing "version", which package (Design), reference to documentation for 
function (type ?latex.anova.Design), reference to ?latex.default).  You 
can also check the code for latex.anova.Design to see what it will and 
won't do, and whether it's easy for you to change.  Improvements in the 
code are welcomed.

Frank

> Department of Psychology
> USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
> Parcels:    Room 102        Gilmer Hall
>          McCormick Road    Charlottesville, VA 22903
> Office:    B011    +1-434-982-4729
> Lab:        B019    +1-434-982-4751
> Fax:        +1-434-982-4766
> WWW:    http://www.people.virginia.edu/~mk9y/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From statistical.model at googlemail.com  Sun Feb 12 21:06:12 2006
From: statistical.model at googlemail.com (statistical.model@googlemail.com)
Date: Sun, 12 Feb 2006 20:06:12 -0000
Subject: [R] mean from list
Message-ID: <EMEELGDEKHMIAKDGLCDCGEMICKAA.Statistical.model@gmail.com>

hi all,
I have a simple problem that i am not able to solve. I've a list called
datalist with the following structure:

[...]

[[10]]
[[10]]$a

     -1  0  1
  -1 31  5  2
  0   6  7  5
  1   1  7 36

[[10]]$b

     -1  0  1
  -1 31  5  2
  0   6  7  5
  1   1  7 36

[[10]]$c
[1] 0.855

[[10]]$d
[1] 0.855

[...]

with [[1]] ... [[100]]. How can i get the mean value of datalist[[x]]$d,
where x represents all elements from 1 to 1000 ?

thanks in advance!!!!

Roberto Furlan
University of Turin

----------------------------------------
La mia Cartella di Posta in Arrivo ?? protetta da SPAMfighter
205 messaggi contenenti spam sono stati bloccati con successo.
Scarica gratuitamente SPAMfighter!



From Mike.Prager at noaa.gov  Sun Feb 12 21:15:17 2006
From: Mike.Prager at noaa.gov (Michael Prager)
Date: Sun, 12 Feb 2006 15:15:17 -0500
Subject: [R] Plotting contour & filled.contour in one graph
In-Reply-To: <971536df0602120831i61039355vbe704f043483bdcb@mail.gmail.com>
References: <001001c63053$be446510$4202a8c0@DrAbRahmandt7>
	<43EF6169.4030509@noaa.gov>
	<971536df0602120831i61039355vbe704f043483bdcb@mail.gmail.com>
Message-ID: <43EF9755.9000306@noaa.gov>

GG

Yes, gladly.  It is an idealized example of the following data 
situation:  There are two control or "independent variables."  They are 
represented here as x and y, on the horizontal and vertical axes 
respectively.  There are two different responses or "dependent" 
variables plotted as different types of contours.  The filled contours 
show response z.  The heavy lines show response zz.

Thus such a plot displays two different responses from a two-dimensional 
range of conditions.  As an example, in fishery biology, x might be the 
age at which fish are first subject to capture, y might be the fishing 
mortality rate (intensity) applied, z might be the resulting yield per 
fish, and zz might be the resulting spawning per fish.  There is usually 
a trade-off between yield and spawning potential, and such a graph (if 
done with real data) allows one to look at that trade-off. 

The OP seemed to be seeking a way of contouring two responses against 
two independent variables, and that's what this graph does.

Is that clearer?  Would the graph would be better if I used real data?

MHP



Gabor Grothendieck wrote on 2/12/2006 11:31 AM:
> Could you walk us through, in detail, what that graph is showing?
>
>
> On 2/12/06, Michael Prager <Mike.Prager at noaa.gov> wrote:
>   
>> Besides the answers you already have, you might look at my "4D" graph
>> example (with code) on the R Graphics Gallery:
>>
>> http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=90
>>
>> I think it does exactly what you are asking, and therefore it might fit
>> your needs with only slight code modification.
>>
>> Mike Prager
>>
>>
>> Abd Rahman Kassim wrote on 2/12/2006 11:12 PM:
>>     
>>> Dear All,
>>>
>>> I have a question on overlaying a filled.contour (e.g. on soil properties data) and contour (by elevation) in one graph. Both have the same z matrix dimension. I'm able to overlay both graph, but the plots dimension did not overlap well on the same plots. How can I have both filled.contour and contour on the same graph? The commands that I have written are as follows:
>>>
>>> filled.contour(0:15,0:10,t(matrix(Total.C,nrow=11,ncol=16)))
>>> contour(0:15,0:10,as.matrix(elev),add=T)
>>>
>>> Thanks for anay assistance.
>>>
>>> Regards.
>>>
>>>
>>> Abd Rahman Kassim
>>> Forest Research Institute Malaysia
>>> Kepong 52109
>>> Selangor, MALAYSIA
>>>
>>> *****************************************
>>>
>>>
>>> *****************************************
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>>       
>> --
>> Michael H. Prager, Ph.D.
>> Population Dynamics Team
>> NOAA Center for Coastal Habitat and Fisheries Research
>> NMFS Southeast Fisheries Science Center
>> Beaufort, North Carolina  28516  USA
>> http://shrimp.ccfhrb.noaa.gov/~mprager/
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>     

-- 
Michael H. Prager, Ph.D.
Population Dynamics Team
NOAA Center for Coastal Habitat and Fisheries Research
NMFS Southeast Fisheries Science Center
Beaufort, North Carolina  28516  USA
http://shrimp.ccfhrb.noaa.gov/~mprager/



From statistical.model at googlemail.com  Sun Feb 12 21:19:38 2006
From: statistical.model at googlemail.com (statistical.model@googlemail.com)
Date: Sun, 12 Feb 2006 20:19:38 -0000
Subject: [R] R:  mean from list
In-Reply-To: <200602122014.PAA22735@webmail17.cac.psu.edu>
Message-ID: <EMEELGDEKHMIAKDGLCDCEEMNCKAA.Statistical.model@gmail.com>

great!! thanks very much, mean(unlist(lapply(listdata, function(z) z$c)))
works well.
and what about getting the average table $a (displaying the average elements
across all 1000 matrix)? could you please help me? I am struggling with
this...

thanks in advance
Roberto



mean(unlist(lapply(x, function(z) z$d))) should do the trick

On Sun, 12 Feb 2006 20:06:12 +0000, statistical.model at googlemail.com wrote:

> hi all,
> I have a simple problem that i am not able to solve. I've a list called
> datalist with the following structure:
> 
> [...]
> 
> [[10]]
> [[10]]$a
> 
>      -1  0  1
>   -1 31  5  2
>   0   6  7  5
>   1   1  7 36
> 
> [[10]]$b
> 
>      -1  0  1
>   -1 31  5  2
>   0   6  7  5
>   1   1  7 36
> 
> [[10]]$c
> [1] 0.855
> 
> [[10]]$d
> [1] 0.855
> 
> [...]
> 
> with [[1]] ... [[100]]. How can i get the mean value of datalist[[x]]$d,
> where x represents all elements from 1 to 1000 ?
> 
> thanks in advance!!!!
> 
> Roberto Furlan
> University of Turin
> 
> ----------------------------------------
> La mia Cartella di Posta in Arrivo ?? protetta da SPAMfighter
> 205 messaggi contenenti spam sono stati bloccati con successo.
> Scarica gratuitamente SPAMfighter!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> 
> 
> 

Rajarshi Guha
<rxg218 at psu.edu>
<http://jijo.cjb.net>

----------------------------------------
La mia Cartella di Posta in Arrivo ?? protetta da SPAMfighter
205 messaggi contenenti spam sono stati bloccati con successo.
Scarica gratuitamente SPAMfighter!


From p.dalgaard at biostat.ku.dk  Sun Feb 12 21:31:33 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 12 Feb 2006 21:31:33 +0100
Subject: [R] mean from list
In-Reply-To: <EMEELGDEKHMIAKDGLCDCGEMICKAA.Statistical.model@gmail.com>
References: <EMEELGDEKHMIAKDGLCDCGEMICKAA.Statistical.model@gmail.com>
Message-ID: <x2oe1cs4ii.fsf@turmalin.kubism.ku.dk>

statistical.model at googlemail.com writes:

> hi all,
> I have a simple problem that i am not able to solve. I've a list called
> datalist with the following structure:
> 
> [...]
> 
> [[10]]
> [[10]]$a
> 
>      -1  0  1
>   -1 31  5  2
>   0   6  7  5
>   1   1  7 36
> 
> [[10]]$b
> 
>      -1  0  1
>   -1 31  5  2
>   0   6  7  5
>   1   1  7 36
> 
> [[10]]$c
> [1] 0.855
> 
> [[10]]$d
> [1] 0.855
> 
> [...]
> 
> with [[1]] ... [[100]]. How can i get the mean value of datalist[[x]]$d,
> where x represents all elements from 1 to 1000 ?

I'd try something like

mean(sapply(x,"[[","d"))
 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From spencer.graves at pdf.com  Sun Feb 12 21:40:44 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 12 Feb 2006 12:40:44 -0800
Subject: [R] Plotting contour & filled.contour in one graph
In-Reply-To: <43EF9755.9000306@noaa.gov>
References: <001001c63053$be446510$4202a8c0@DrAbRahmandt7>	<43EF6169.4030509@noaa.gov>	<971536df0602120831i61039355vbe704f043483bdcb@mail.gmail.com>
	<43EF9755.9000306@noaa.gov>
Message-ID: <43EF9D4C.2080205@pdf.com>

Hi, Michael:

	  I'm sure the example would be clearer AND more interesting if you 
used real data AND accompanied it with a description like you gave 
below.  To help motivate the usage, you could add a few words of 
interpretation, e.g., that if you want both z and zz less than 2, x and 
y must be in the upper right corner.

	  Thanks for this.
	  spencer graves

Michael Prager wrote:
> GG
> 
> Yes, gladly.  It is an idealized example of the following data 
> situation:  There are two control or "independent variables."  They are 
> represented here as x and y, on the horizontal and vertical axes 
> respectively.  There are two different responses or "dependent" 
> variables plotted as different types of contours.  The filled contours 
> show response z.  The heavy lines show response zz.
> 
> Thus such a plot displays two different responses from a two-dimensional 
> range of conditions.  As an example, in fishery biology, x might be the 
> age at which fish are first subject to capture, y might be the fishing 
> mortality rate (intensity) applied, z might be the resulting yield per 
> fish, and zz might be the resulting spawning per fish.  There is usually 
> a trade-off between yield and spawning potential, and such a graph (if 
> done with real data) allows one to look at that trade-off. 
> 
> The OP seemed to be seeking a way of contouring two responses against 
> two independent variables, and that's what this graph does.
> 
> Is that clearer?  Would the graph would be better if I used real data?
> 
> MHP
> 
> 
> 
> Gabor Grothendieck wrote on 2/12/2006 11:31 AM:
> 
>>Could you walk us through, in detail, what that graph is showing?
>>
>>
>>On 2/12/06, Michael Prager <Mike.Prager at noaa.gov> wrote:
>>  
>>
>>>Besides the answers you already have, you might look at my "4D" graph
>>>example (with code) on the R Graphics Gallery:
>>>
>>>http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=90
>>>
>>>I think it does exactly what you are asking, and therefore it might fit
>>>your needs with only slight code modification.
>>>
>>>Mike Prager
>>>
>>>
>>>Abd Rahman Kassim wrote on 2/12/2006 11:12 PM:
>>>    
>>>
>>>>Dear All,
>>>>
>>>>I have a question on overlaying a filled.contour (e.g. on soil properties data) and contour (by elevation) in one graph. Both have the same z matrix dimension. I'm able to overlay both graph, but the plots dimension did not overlap well on the same plots. How can I have both filled.contour and contour on the same graph? The commands that I have written are as follows:
>>>>
>>>>filled.contour(0:15,0:10,t(matrix(Total.C,nrow=11,ncol=16)))
>>>>contour(0:15,0:10,as.matrix(elev),add=T)
>>>>
>>>>Thanks for anay assistance.
>>>>
>>>>Regards.
>>>>
>>>>
>>>>Abd Rahman Kassim
>>>>Forest Research Institute Malaysia
>>>>Kepong 52109
>>>>Selangor, MALAYSIA
>>>>
>>>>*****************************************
>>>>
>>>>
>>>>*****************************************
>>>>      [[alternative HTML version deleted]]
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>>
>>>>      
>>>
>>>--
>>>Michael H. Prager, Ph.D.
>>>Population Dynamics Team
>>>NOAA Center for Coastal Habitat and Fisheries Research
>>>NMFS Southeast Fisheries Science Center
>>>Beaufort, North Carolina  28516  USA
>>>http://shrimp.ccfhrb.noaa.gov/~mprager/
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>>    
> 
>



From spencer.graves at pdf.com  Sun Feb 12 21:55:33 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 12 Feb 2006 12:55:33 -0800
Subject: [R] Help with the ts function
In-Reply-To: <74BDE31AFD6EC54DB026E6CD11FF0A7E12473B@ES-MSG-008.es.govt.state.ma.us>
References: <74BDE31AFD6EC54DB026E6CD11FF0A7E12473B@ES-MSG-008.es.govt.state.ma.us>
Message-ID: <43EFA0C5.3070107@pdf.com>

	  What are you asking?  If you want to learn about times series in R, I 
suggest the following:

	  1.  Ch. 14 in Venables and Ripley (2002) Modern Applied Statistics 
with S, 4th ed. (Springer).  This may or may not answer your specific 
question.

	  2.  The article on "Date and Time Classes in R" by Gabor Grothendieck 
and Thomas Petzoldt (2004) in R News, 4-1: 29-32 (dowloadable from 
http://CRAN.R-project.org/doc/Rnews/).

	  3.  The "zoo" vignette in the "zoo" package.  A vignette provides 
both an Adobe Acrobat PDF document and a companion *.R file, which you 
can work through line by line, testing modifications, etc., as you go. 
This is my preferred way to learn about new capabilities in R.  If you 
are not familiar with vignettes, see 
"http://finzi.psych.upenn.edu/R/Rhelp02a/archive/67006.html".

	  hope this helps.
	  spencer graves
p.s.  I believe you will increase your average rate of knowledge 
acquisition about R if you read and follow the posting guide! 
"www.R-project.org/posting-guide.html".

Nelson, Gary (FWE) wrote:

> I have a time series of temperature data recorded every 2 hours and I
> would like to generate a spectrogram using the spectrum function that
> examines cycles per day.  My statement for coding the series using the
> ts function is
> 
> bevtemp<-ts(bevtemp,deltat=0.0833334) 
> 
> where 0.0833334 is 2 hours/24 hours.
> 
> I am wondering if this is the correct way to code the data?
> 
> 
> Thanks for your help.
> 
> Gary Nelson.
> 
> 
> 
> ************************************************************************
> *
> Gary A. Nelson
> Massachusetts Division of Marine Fisheries
> 30 Emerson Avenue
> Gloucester, MA 01930
> Phone: (978) 282-0308 x114
> Fax: (617) 727-3337
> Email: Gary.Nelson at state.ma.us
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From lapotok at gmail.com  Sun Feb 12 22:07:10 2006
From: lapotok at gmail.com (Altshuler Eugeny)
Date: Mon, 13 Feb 2006 00:07:10 +0300
Subject: [R] remote access
Message-ID: <43EFA37E.7000003@gmail.com>

Hello!

I have such trouble: I like R, but often I don't have administrator 
permissions to install R on some (not mine) computers.

Could you give me shell on any server with R installed in order to apply 
R without installing it (simply with PuTTY).

Great thanks!
-- 

   Best regards,
   Altshuler Eugeny



From murdoch at stats.uwo.ca  Sun Feb 12 22:25:46 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 12 Feb 2006 16:25:46 -0500
Subject: [R] remote access
In-Reply-To: <43EFA37E.7000003@gmail.com>
References: <43EFA37E.7000003@gmail.com>
Message-ID: <43EFA7DA.4070104@stats.uwo.ca>

On 2/12/2006 4:07 PM, Altshuler Eugeny wrote:
> Hello!
> 
> I have such trouble: I like R, but often I don't have administrator 
> permissions to install R on some (not mine) computers.

Current versions of R don't need admin access to install.  Just change 
the default directory to one where you have write permission.

Duncan Murdoch

> 
> Could you give me shell on any server with R installed in order to apply 
> R without installing it (simply with PuTTY).
> 
> Great thanks!



From tolga at coubros.com  Sun Feb 12 22:38:22 2006
From: tolga at coubros.com (Tolga Uzuner)
Date: Sun, 12 Feb 2006 21:38:22 +0000
Subject: [R] Gram-Charlier CDF
Message-ID: <43EFAACE.5090202@coubros.com>

Hi there,

Does anyone have something better (read faster) than the following for 
the CDF of an A-type Gram-Charlier expansion ?

Many thanks in advance,
Tolga



fact <- function (x) gamma(1 + x)

gc <- function(w,skew=0,kurtosis=0)
# gram-charlier density
# to be positive, must respect the constraints:
# [-1.0493,1.0493] and [3,7] respectively
{
sapply(w,function(y)
dnorm(y)-
skew/fact(3)*drv(dnorm,y,3)+
kurtosis/fact(4)*drv(dnorm,y,4))
}

gcd <-function(w,skew=0,kurtosis=0)
# gram-charlier cdf
integrate(function(x) gc(x,skew,kurtosis),-Inf,w)$value



From brgordon at andrew.cmu.edu  Sun Feb 12 23:00:56 2006
From: brgordon at andrew.cmu.edu (Brett Gordon)
Date: Sun, 12 Feb 2006 17:00:56 -0500 (EST)
Subject: [R] Multiple plots on a common x-axis, different y-axes
Message-ID: <2970.67.101.226.189.1139781656.squirrel@67.101.226.189>

Hello,

I'd like to plot two functions on the same x-axis, but with two different y-axis. However, I can't seem to find the write plotting function to do this with. Any help would be greatly appreciated.

Thanks,
Brett

brgordon at andrew.cmu.edu



From kjetilbrinchmannhalvorsen at gmail.com  Mon Feb 13 00:21:13 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Sun, 12 Feb 2006 19:21:13 -0400
Subject: [R] R:  mean from list
In-Reply-To: <EMEELGDEKHMIAKDGLCDCEEMNCKAA.Statistical.model@gmail.com>
References: <EMEELGDEKHMIAKDGLCDCEEMNCKAA.Statistical.model@gmail.com>
Message-ID: <43EFC2E9.3090905@gmail.com>

statistical.model at googlemail.com wrote:
> great!! thanks very much, mean(unlist(lapply(listdata, function(z) z$c)))

WHY unlist(lapply(...   when sapply(...
is simpler?

Kjetil


> works well.
> and what about getting the average table $a (displaying the average elements
> across all 1000 matrix)? could you please help me? I am struggling with
> this...
> 
> thanks in advance
> Roberto
> 
> 
> 
> mean(unlist(lapply(x, function(z) z$d))) should do the trick
> 
> On Sun, 12 Feb 2006 20:06:12 +0000, statistical.model at googlemail.com wrote:
> 
>> hi all,
>> I have a simple problem that i am not able to solve. I've a list called
>> datalist with the following structure:
>>
>> [...]
>>
>> [[10]]
>> [[10]]$a
>>
>>      -1  0  1
>>   -1 31  5  2
>>   0   6  7  5
>>   1   1  7 36
>>
>> [[10]]$b
>>
>>      -1  0  1
>>   -1 31  5  2
>>   0   6  7  5
>>   1   1  7 36
>>
>> [[10]]$c
>> [1] 0.855
>>
>> [[10]]$d
>> [1] 0.855
>>
>> [...]
>>
>> with [[1]] ... [[100]]. How can i get the mean value of datalist[[x]]$d,
>> where x represents all elements from 1 to 1000 ?
>>
>> thanks in advance!!!!
>>
>> Roberto Furlan
>> University of Turin
>>
>> ----------------------------------------
>> La mia Cartella di Posta in Arrivo ?? protetta da SPAMfighter
>> 205 messaggi contenenti spam sono stati bloccati con successo.
>> Scarica gratuitamente SPAMfighter!
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>>
>>
> 
> Rajarshi Guha
> <rxg218 at psu.edu>
> <http://jijo.cjb.net>
> 
> ----------------------------------------
> La mia Cartella di Posta in Arrivo ?? protetta da SPAMfighter
> 205 messaggi contenenti spam sono stati bloccati con successo.
> Scarica gratuitamente SPAMfighter!
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From bambang.pramono at gmail.com  Mon Feb 13 00:24:20 2006
From: bambang.pramono at gmail.com (bambang pramono)
Date: Mon, 13 Feb 2006 06:24:20 +0700
Subject: [R] Tobit Regression (residual Assumption)
Message-ID: <830480cb0602121524qb527534g8dd43ab16c99cd22@mail.gmail.com>

I'm statistician
I need help with tobit regression
Is there assumption in tobit regression ?
if any, what kind of that ?

please help me !!



From rxg218 at psu.edu  Mon Feb 13 01:07:01 2006
From: rxg218 at psu.edu (Rajarshi Guha)
Date: Sun, 12 Feb 2006 19:07:01 -0500
Subject: [R] R:  mean from list
In-Reply-To: <43EFC2E9.3090905@gmail.com>
References: <EMEELGDEKHMIAKDGLCDCEEMNCKAA.Statistical.model@gmail.com>
	<43EFC2E9.3090905@gmail.com>
Message-ID: <1139789221.6693.0.camel@localhost.localdomain>

On Sun, 2006-02-12 at 19:21 -0400, Kjetil Brinchmann Halvorsen wrote:
> statistical.model at googlemail.com wrote:
> > great!! thanks very much, mean(unlist(lapply(listdata, function(z) z$c)))
> 
> WHY unlist(lapply(...   when sapply(...
> is simpler?

Aah! Immediately after sending it I realized the simpler form :-/

-------------------------------------------------------------------
Rajarshi Guha <rxg218 at psu.edu> <http://jijo.cjb.net>
GPG Fingerprint: 0CCA 8EE2 2EEB 25E2 AB04 06F7 1BB9 E634 9B87 56EE
-------------------------------------------------------------------
Finally I am becoming stupider no more
- Paul Erdos' epitaph



From Charles.Annis at StatisticalEngineering.com  Mon Feb 13 01:18:40 2006
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Sun, 12 Feb 2006 19:18:40 -0500
Subject: [R] Tobit Regression (residual Assumption)
In-Reply-To: <830480cb0602121524qb527534g8dd43ab16c99cd22@mail.gmail.com>
Message-ID: <011501c63033$0ad319b0$6600a8c0@DD4XFW31>

Go to the R site and look.  http://www.r-project.org/

There has been some recent traffic on this topic.

Click on search: "Tobit"




Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of bambang pramono
Sent: Sunday, February 12, 2006 6:24 PM
To: R-help at stat.math.ethz.ch
Subject: [R] Tobit Regression (residual Assumption)

I'm statistician
I need help with tobit regression
Is there assumption in tobit regression ?
if any, what kind of that ?

please help me !!

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From BPikouni at CNTUS.JNJ.COM  Mon Feb 13 05:19:39 2006
From: BPikouni at CNTUS.JNJ.COM (Pikounis, Bill [CNTUS])
Date: Sun, 12 Feb 2006 23:19:39 -0500
Subject: [R] remote access
Message-ID: <A89517C7FD248040BB71CA3C04C1ACBB04C9EC9A@CNTUSMAEXS4.na.jnj.com>

Hello Altshuler:
Complete, helpful details related to what Duncan Murdoch points out below
are in the R Installation and Administration manual. If you wish to build
and use R without "admin access" in a "Unix-alike", see chapter 2. (Can't
tell from your message except for your message of shell and PuTTY.) 

I am able for example to use R on a orphan Linux machine at work where I
have no influence on configuration: I just built R from source in my home
directory as the manual instructs, and then set an alias in my .bash_profile
file like:

alias R='/home/bpikouni/downloads/R-2.2.1/bin/R'

Works like a charm thru SSH PuTTY (Windows) with X11 forwarding and a local
Cygwin X-server installed for graphical devices.

Hope that helps,
Bill

-------------------------------
Bill Pikounis, PhD
Nonclinical Statistics
Centocor, Inc.

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Duncan Murdoch
> Sent: Sunday, February 12, 2006 4:26 PM
> To: Altshuler Eugeny
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] remote access
> 
> 
> On 2/12/2006 4:07 PM, Altshuler Eugeny wrote:
> > Hello!
> > 
> > I have such trouble: I like R, but often I don't have administrator 
> > permissions to install R on some (not mine) computers.
> 
> Current versions of R don't need admin access to install.  
> Just change 
> the default directory to one where you have write permission.
> 
> Duncan Murdoch
> 
> > 
> > Could you give me shell on any server with R installed in 
> order to apply 
> > R without installing it (simply with PuTTY).
> > 
> > Great thanks!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From rahmank at frim.gov.my  Mon Feb 13 22:25:09 2006
From: rahmank at frim.gov.my (Abd Rahman Kassim)
Date: Mon, 13 Feb 2006 13:25:09 -0800
Subject: [R] Plotting contour & filled.contour in one graph
References: <001001c63053$be446510$4202a8c0@DrAbRahmandt7>	<43EF6169.4030509
	@noaa.gov>	<971536df0602120831i61039355vbe704f043483bdcb@mail.gmail.com>
	<43EF9755.9000306@noaa.gov> <43EF9D4C.2080205@pdf.com>
Message-ID: <003901c630e3$f821c530$4202a8c0@DrAbRahmandt7>


Dear Spencer,

Thanks for the assistance and the website. It will be very helpful for my 
future code programming on graph in R.

Abd. Rahman

----- Original Message ----- 
From: "Spencer Graves" <spencer.graves at pdf.com>
To: "Michael Prager" <Mike.Prager at noaa.gov>
Cc: "Gabor Grothendieck" <ggrothendieck at gmail.com>; "R Help List" 
<r-help at stat.math.ethz.ch>; "Abd Rahman Kassim" <rahmank at frim.gov.my>
Sent: Sunday, February 12, 2006 12:40 PM
Subject: Re: [R] Plotting contour & filled.contour in one graph


>
> Hi, Michael:
>
>   I'm sure the example would be clearer AND more interesting if you used 
> real data AND accompanied it with a description like you gave below.  To 
> help motivate the usage, you could add a few words of interpretation, 
> e.g., that if you want both z and zz less than 2, x and y must be in the 
> upper right corner.
>
>   Thanks for this.
>   spencer graves
>
> Michael Prager wrote:
>> GG
>>
>> Yes, gladly.  It is an idealized example of the following data situation: 
>> There are two control or "independent variables."  They are represented 
>> here as x and y, on the horizontal and vertical axes respectively.  There 
>> are two different responses or "dependent" variables plotted as different 
>> types of contours.  The filled contours show response z.  The heavy lines 
>> show response zz.
>>
>> Thus such a plot displays two different responses from a two-dimensional 
>> range of conditions.  As an example, in fishery biology, x might be the 
>> age at which fish are first subject to capture, y might be the fishing 
>> mortality rate (intensity) applied, z might be the resulting yield per 
>> fish, and zz might be the resulting spawning per fish.  There is usually 
>> a trade-off between yield and spawning potential, and such a graph (if 
>> done with real data) allows one to look at that trade-off. The OP seemed 
>> to be seeking a way of contouring two responses against two independent 
>> variables, and that's what this graph does.
>>
>> Is that clearer?  Would the graph would be better if I used real data?
>>
>> MHP
>>
>>
>>
>> Gabor Grothendieck wrote on 2/12/2006 11:31 AM:
>>
>>>Could you walk us through, in detail, what that graph is showing?
>>>
>>>
>>>On 2/12/06, Michael Prager <Mike.Prager at noaa.gov> wrote:
>>>
>>>>Besides the answers you already have, you might look at my "4D" graph
>>>>example (with code) on the R Graphics Gallery:
>>>>
>>>>http://addictedtor.free.fr/graphiques/RGraphGallery.php?graph=90
>>>>
>>>>I think it does exactly what you are asking, and therefore it might fit
>>>>your needs with only slight code modification.
>>>>
>>>>Mike Prager
>>>>
>>>>
>>>>Abd Rahman Kassim wrote on 2/12/2006 11:12 PM:
>>>>
>>>>>Dear All,
>>>>>
>>>>>I have a question on overlaying a filled.contour (e.g. on soil 
>>>>>properties data) and contour (by elevation) in one graph. Both have the 
>>>>>same z matrix dimension. I'm able to overlay both graph, but the plots 
>>>>>dimension did not overlap well on the same plots. How can I have both 
>>>>>filled.contour and contour on the same graph? The commands that I have 
>>>>>written are as follows:
>>>>>
>>>>>filled.contour(0:15,0:10,t(matrix(Total.C,nrow=11,ncol=16)))
>>>>>contour(0:15,0:10,as.matrix(elev),add=T)
>>>>>
>>>>>Thanks for anay assistance.
>>>>>
>>>>>Regards.
>>>>>
>>>>>
>>>>>Abd Rahman Kassim
>>>>>Forest Research Institute Malaysia
>>>>>Kepong 52109
>>>>>Selangor, MALAYSIA
>>>>>
>>>>>*****************************************
>>>>>
>>>>>
>>>>>*****************************************
>>>>>      [[alternative HTML version deleted]]
>>>>>
>>>>>______________________________________________
>>>>>R-help at stat.math.ethz.ch mailing list
>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>PLEASE do read the posting guide! 
>>>>>http://www.R-project.org/posting-guide.html
>>>>>
>>>>>
>>>>
>>>>--
>>>>Michael H. Prager, Ph.D.
>>>>Population Dynamics Team
>>>>NOAA Center for Coastal Habitat and Fisheries Research
>>>>NMFS Southeast Fisheries Science Center
>>>>Beaufort, North Carolina  28516  USA
>>>>http://shrimp.ccfhrb.noaa.gov/~mprager/
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! 
>>>>http://www.R-project.org/posting-guide.html
>>>>
>>>>
>>
>>
>
>
> *****************************************
> Outgoing mail is certified Virus Free.
> Checked by TrendMicro Interscan Messaging Security.
> For any enquiries, please contact FRIM IT Department.
> *****************************************



From hans.gardfjell at emg.umu.se  Mon Feb 13 08:52:08 2006
From: hans.gardfjell at emg.umu.se (Hans Gardfjell)
Date: Mon, 13 Feb 2006 08:52:08 +0100
Subject: [R] aggregate vs tapply; is there a middle ground?
In-Reply-To: <x264nlh3g5.fsf@turmalin.kubism.ku.dk>
References: <43EE6430.5080908@emg.umu.se>	<f8e6ff050602111444n42affdaer16f94a1fb9ede76b@mail.gmail.com>
	<x264nlh3g5.fsf@turmalin.kubism.ku.dk>
Message-ID: <43F03AA8.40005@emg.umu.se>

Thanks Peter!

I had a "feeling" that there must be a simpler, better, more elegant 
solution.

/Hans


Peter Dalgaard wrote:
> hadley wickham <h.wickham at gmail.com> writes:
>
>   
>>> I faced a similar problem. Here's what I did
>>>
>>> tmp <-
>>> data.frame(A=sample(LETTERS[1:5],10,replace=T),B=sample(letters[1:5],10,replace=T),C=rnorm(10))
>>> tmp1 <- with(tmp,aggregate(C,list(A=A,B=B),sum))
>>> tmp2 <- expand.grid(A=sort(unique(tmp$A)),B=sort(unique(tmp$B)))
>>> merge(tmp2,tmp1,all.x=T)
>>>
>>> At least fewer than 10 extra lines of code. Anyone with a simpler solution?
>>>       
>> Well, you can almost do this in with the reshape package:
>>
>> tmp <-
>> data.frame(A=sample(LETTERS[1:5],10,replace=T),B=sample(letters[1:5],10,replace=T),C=rnorm(10))
>> a <- recast(tmp, A + B ~ ., sum)
>> # see also recast(tmp, A  ~ B, sum)
>> add.all.combinations(a, row="A", cols = "B")
>>
>> Where add.all.combinations basically does what you outlined above --
>> it would be easy enough to generalise to multiple dimensions.
>>     
>
> Anything wrong with
>
>   
>> as.data.frame(with(tmp,as.table(tapply(C,list(A=A,B=B),sum))))
>>     
>    A B       Freq
> 1  A a         NA
> 2  B a -0.2524320
> 3  C a  3.8539264
> 4  D a         NA
> 5  A c  0.7227294
> 6  B c -0.2694669
> 7  C c  0.4760957
> 8  D c         NA
> 9  A e         NA
> 10 B e  0.1800500
> 11 C e         NA
> 12 D e -1.0350928
>
> (except the silly colname, responseName="sum" should fix that).
>
>   


-- 

*********************************
Hans Gardfjell
Ecology and Environmental Science
Ume?? University
90187 Ume??, Sweden
email: hans.gardfjell at emg.umu.se
phone:  +46 907865267
mobile: +46 705984464



From bambang.pramono at gmail.com  Mon Feb 13 09:05:30 2006
From: bambang.pramono at gmail.com (bambang pramono)
Date: Mon, 13 Feb 2006 00:05:30 -0800
Subject: [R] Tobit Regression (residual Assumption)
In-Reply-To: <011701c63049$97fb4310$6600a8c0@DD4XFW31>
References: <830480cb0602121652tb9c6476r98b6862421e0e9c8@mail.gmail.com>
	<011701c63049$97fb4310$6600a8c0@DD4XFW31>
Message-ID: <830480cb0602130005s260c1626yf61cea686960e0ae@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060213/41f4de9b/attachment.pl

From subhabratapal at sraindia.com  Mon Feb 13 09:33:55 2006
From: subhabratapal at sraindia.com (Subhabrata)
Date: Mon, 13 Feb 2006 14:03:55 +0530
Subject: [R] R-help, specifying the places to decimal
Message-ID: <022f01c63078$3c09c5c0$f608a8c0@srai37>

Hello - R-experts,


Is there any way with which we can specify the number after
decimal point to take. Like I have a situation where 
the values are comming 0.160325923 but I only want 
4 place to decimal say 0.1603. Is there any way for that.

I am no expert in R- and this may sound simple to many.sorry


Thanks for any help.

With Regards

Subhabrata



From dimitris.rizopoulos at med.kuleuven.be  Mon Feb 13 09:36:26 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Mon, 13 Feb 2006 09:36:26 +0100
Subject: [R] R-help, specifying the places to decimal
References: <022f01c63078$3c09c5c0$f608a8c0@srai37>
Message-ID: <013601c63078$94589580$0540210a@www.domain>

have a look at ?round()

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Subhabrata" <subhabratapal at sraindia.com>
To: "r-help" <r-help at stat.math.ethz.ch>
Sent: Monday, February 13, 2006 9:33 AM
Subject: [R] R-help, specifying the places to decimal


> Hello - R-experts,
>
>
> Is there any way with which we can specify the number after
> decimal point to take. Like I have a situation where
> the values are comming 0.160325923 but I only want
> 4 place to decimal say 0.1603. Is there any way for that.
>
> I am no expert in R- and this may sound simple to many.sorry
>
>
> Thanks for any help.
>
> With Regards
>
> Subhabrata
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From petr.pikal at precheza.cz  Mon Feb 13 10:59:16 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 13 Feb 2006 10:59:16 +0100
Subject: [R] ?bug? strange factors produced by chron
Message-ID: <43F06684.10463.541B11@localhost>

Hallo all

Please help me. I am lost and do not know what is the problem. I have 
a factor called kvartaly.

> attributes(kvartaly)
$levels
[1] "1Q.04" "2Q.04" "3Q.04" "4Q.04" "1Q.05" "2Q.05" "3Q.05" "4Q.05"
$class
[1] "factor"
> mode(kvartaly)
[1] "numeric"
> str(kvartaly)
 Factor w/ 8 levels "1Q.04","2Q.04",..: 1 1 1 1 1 1 1 1 1 1 ...
>

but if I call split it throws an error

> split(rnorm(731),kvartaly)
Error in split(x, f) : second argument must be a factor

so I tried to make a test example which works if I try to construct 
factor manually but fails if I use chron

vec<-c("1Q.04", "1Q.05", "1Q.06")
fac<-as.factor(rep(vec,c(5,5,5)))

split(rnorm(15),fac)
$"1Q.04"
[1]  1.9803999 -0.3672215 -1.0441346  0.5697196 -0.1350546

$"1Q.05"
[1]  2.40161776 -0.03924000  0.68973936  0.02800216 -0.74327321

$"1Q.06"
[1]  0.1887923 -1.8049586  1.4655549  0.1532533  2.1726117

vec1<-as.Date(Sys.time())
vec1<-c(vec1, vec1-100, vec1-300)
vec1<-rep(vec1,c(5,5,5))
fac1<-interaction(quarters(as.chron(as.POSIXct(vec1))), 
format(vec1,"%y"))
> split(rnorm(15),fac1)
Error in split(x, f) : second argument must be a factor
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Why split does not accept fac1 if according to all tests it **is** a 
factor?

Thank you
Petr

Petr Pikal
petr.pikal at precheza.cz



From goran.brostrom at gmail.com  Mon Feb 13 11:16:14 2006
From: goran.brostrom at gmail.com (=?UTF-8?Q?G=C3=B6ran_Brostr=C3=B6m?=)
Date: Mon, 13 Feb 2006 11:16:14 +0100
Subject: [R] Sweave, mle and curve
Message-ID: <148ed8180602130216m77862294u177493565d682b26@mail.gmail.com>

I am trying to write a lesson on maximum likelihood with Sweave. I get
a surprising result with the following code, lec4.Snw:

\documentclass[a4paper,12pt]{article}
\usepackage[latin1]{inputenc}

\title{Maximum likelihood}

\author{Gran Brostrm}

\begin{document}

\maketitle

<<fig=TRUE>>=
## Simulate Y:
n <- 25
Y <- sum(rpois(n, lambda = 1))
Y
 ## Define minusloglik:
minusloglik <- function(theta) n * theta - Y  * log(theta)
curve(minusloglik, 0.2, 2, xlab = "theta")

library(stats4)
cat("Y is now ", Y, "\n")
fit <- mle(minusloglik, start = list(theta = Y/n))
summary(fit)
@

\end{document}

In R, I get:

> Sweave("lec4.Snw")
Writing to file lec4.tex
Processing code chunks ...
 1 : echo term verbatim eps pdf
Y is now  27
Y is now  24

You can now run LaTeX on 'lec4.tex'
>

and the latex document will have two different mle's,  one in the
figure, and another one from 'mle'.  One uses Y = 27 and the other Y =
24!

I can save the situation by moving "Y <- ..." to a separaye "code chunk".
Does 'fig=TRUE' imply that the code chunk is run twice?

--
Gran Brostrm



From ripley at stats.ox.ac.uk  Mon Feb 13 11:54:21 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Feb 2006 10:54:21 +0000 (GMT)
Subject: [R] ?bug? strange factors produced by chron
In-Reply-To: <43F06684.10463.541B11@localhost>
References: <43F06684.10463.541B11@localhost>
Message-ID: <Pine.LNX.4.64.0602131040390.12212@gannet.stats.ox.ac.uk>

1) The obvious test is via is.factor(), and you have not used that.

2) Your example works for me, so what versions of R and chron is this?

3) Here's my guess. split is using the C-level test isFactor.  That tests 
that the factor is of type integer, so please try

>  typeof(kvartaly)

I suspect you will get "double" and not "integer", and if so you can fix 
this by

storage.mode(kvartaly) <- "integer"

So here's an example which will fail

> fac2 <- rep(c(1,2,3), each=5)
> attr(fac2, "levels") <- as.character(1:3)
> oldClass(fac2) <- "factor"
> is.factor(fac2)
[1] TRUE
> split(rnorm(15), fac2)
Error in split(x, f) : second argument must be a factor

I think it is an error that the R-level and C-level tests for is.factor() 
are different.


On Mon, 13 Feb 2006, Petr Pikal wrote:

> Hallo all
>
> Please help me. I am lost and do not know what is the problem. I have
> a factor called kvartaly.
>
>> attributes(kvartaly)
> $levels
> [1] "1Q.04" "2Q.04" "3Q.04" "4Q.04" "1Q.05" "2Q.05" "3Q.05" "4Q.05"
> $class
> [1] "factor"
>> mode(kvartaly)
> [1] "numeric"
>> str(kvartaly)
> Factor w/ 8 levels "1Q.04","2Q.04",..: 1 1 1 1 1 1 1 1 1 1 ...
>>
>
> but if I call split it throws an error
>
>> split(rnorm(731),kvartaly)
> Error in split(x, f) : second argument must be a factor
>
> so I tried to make a test example which works if I try to construct
> factor manually but fails if I use chron
>
> vec<-c("1Q.04", "1Q.05", "1Q.06")
> fac<-as.factor(rep(vec,c(5,5,5)))
>
> split(rnorm(15),fac)
> $"1Q.04"
> [1]  1.9803999 -0.3672215 -1.0441346  0.5697196 -0.1350546
>
> $"1Q.05"
> [1]  2.40161776 -0.03924000  0.68973936  0.02800216 -0.74327321
>
> $"1Q.06"
> [1]  0.1887923 -1.8049586  1.4655549  0.1532533  2.1726117
>
> vec1<-as.Date(Sys.time())

Why not Sys.Date() ?

> vec1<-c(vec1, vec1-100, vec1-300)
> vec1<-rep(vec1,c(5,5,5))
> fac1<-interaction(quarters(as.chron(as.POSIXct(vec1))),
> format(vec1,"%y"))
>> split(rnorm(15),fac1)
> Error in split(x, f) : second argument must be a factor
> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>
> Why split does not accept fac1 if according to all tests it **is** a
> factor?
>
> Thank you
> Petr
>
> Petr Pikal
> petr.pikal at precheza.cz

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Markus.Preisetanz at clientvela.com  Mon Feb 13 12:24:38 2006
From: Markus.Preisetanz at clientvela.com (Markus Preisetanz)
Date: Mon, 13 Feb 2006 12:24:38 +0100
Subject: [R] Adding dimnames to image()
Message-ID: <79799E69EA1DA246A51F983B5663BEA2CD34CF@server2.hq.clientvela.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060213/ffef6e5e/attachment.pl

From petr.pikal at precheza.cz  Mon Feb 13 12:31:41 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 13 Feb 2006 12:31:41 +0100
Subject: [R] ?bug? strange factors produced by chron
In-Reply-To: <Pine.LNX.4.64.0602131040390.12212@gannet.stats.ox.ac.uk>
References: <43F06684.10463.541B11@localhost>
Message-ID: <43F07C2D.18199.A8C38D@localhost>

Thank you very much.

On 13 Feb 2006 at 10:54, Prof Brian Ripley wrote:

Date sent:      	Mon, 13 Feb 2006 10:54:21 +0000 (GMT)
From:           	Prof Brian Ripley <ripley at stats.ox.ac.uk>
To:             	Petr Pikal <petr.pikal at precheza.cz>
Copies to:      	r-help at stat.math.ethz.ch
Subject:        	Re: [R] ?bug? strange factors produced by chron

> 1) The obvious test is via is.factor(), and you have not used that.

I used it with TRUE result but did not use in my post (mea culpa)
> is.factor(kvartaly)
[1] TRUE

> 2) Your example works for me, so what versions of R and chron is this?

Package: chron
Version: 2.3-1
R 2.2.1 and W2000

but problem is probably in interaction (see below)
> 
> 3) Here's my guess. split is using the C-level test isFactor.  That
> tests that the factor is of type integer, so please try
> 
> >  typeof(kvartaly)

 > typeof(kvartaly)
 [1] "double"
 
Problem is probably not in chron but in interaction, which silently 
transfers factor type to double

> typeof(factor(letters[1:2]))
[1] "integer"

> typeof(interaction(factor(letters[1:2]), factor(letters[3:4])))
[1] "double"
> 

> 
> I suspect you will get "double" and not "integer", and if so you can
> fix this by
> 
> storage.mode(kvartaly) <- "integer"

Thanks, it works.

> 
> So here's an example which will fail
> 
> > fac2 <- rep(c(1,2,3), each=5)
> > attr(fac2, "levels") <- as.character(1:3)
> > oldClass(fac2) <- "factor"
> > is.factor(fac2)
> [1] TRUE
> > split(rnorm(15), fac2)
> Error in split(x, f) : second argument must be a factor
> 
> I think it is an error that the R-level and C-level tests for
> is.factor() are different.

<snip>

> > vec1<-as.Date(Sys.time())
> 
> Why not Sys.Date() ?

I remembered only Sys.time when writing my mail.

> 

<snip>

Thank you again.

Best regards.
PetrPetr Pikal
petr.pikal at precheza.cz



From Friedrich.Leisch at tuwien.ac.at  Mon Feb 13 12:43:07 2006
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Mon, 13 Feb 2006 12:43:07 +0100
Subject: [R] Sweave, mle and curve
In-Reply-To: <148ed8180602130216m77862294u177493565d682b26@mail.gmail.com>
References: <148ed8180602130216m77862294u177493565d682b26@mail.gmail.com>
Message-ID: <17392.28875.182900.821801@celebrian.ci.tuwien.ac.at>

>>>>> On Mon, 13 Feb 2006 11:16:14 +0100,
>>>>> G??ran Brostr??m (GB) wrote:

  > I am trying to write a lesson on maximum likelihood with Sweave. I get
  > a surprising result with the following code, lec4.Snw:

  > \documentclass[a4paper,12pt]{article}
  > \usepackage[latin1]{inputenc}

  > \title{Maximum likelihood}

  > \author{G??ran Brostr??m}

  > \begin{document}

  > \maketitle

  > <<fig=TRUE>>=
  > ## Simulate Y:
  > n <- 25
  > Y <- sum(rpois(n, lambda = 1))
  > Y
  >  ## Define minusloglik:
  > minusloglik <- function(theta) n * theta - Y  * log(theta)
  > curve(minusloglik, 0.2, 2, xlab = "theta")

  > library(stats4)
  > cat("Y is now ", Y, "\n")
  > fit <- mle(minusloglik, start = list(theta = Y/n))
  > summary(fit)
  > @

  > \end{document}

  > In R, I get:

  >> Sweave("lec4.Snw")
  > Writing to file lec4.tex
  > Processing code chunks ...
  >  1 : echo term verbatim eps pdf
  > Y is now  27
  > Y is now  24

  > You can now run LaTeX on 'lec4.tex'
  >> 

  > and the latex document will have two different mle's,  one in the
  > figure, and another one from 'mle'.  One uses Y = 27 and the other Y =
  > 24!

  > I can save the situation by moving "Y <- ..." to a separaye "code chunk".
  > Does 'fig=TRUE' imply that the code chunk is run twice?

Yes, once to get all textual output, and then once for each graphics
format requested.

Best,

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f??r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit??t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra??e 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch



From Roger.Bivand at nhh.no  Mon Feb 13 12:47:05 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 13 Feb 2006 12:47:05 +0100 (CET)
Subject: [R] Adding dimnames to image()
In-Reply-To: <79799E69EA1DA246A51F983B5663BEA2CD34CF@server2.hq.clientvela.net>
Message-ID: <Pine.LNX.4.44.0602131243560.29951-100000@reclus.nhh.no>

On Mon, 13 Feb 2006, Markus Preisetanz wrote:

> Dear Colleagues,
> 
>  
> 
> does anybody know how to add dimnames to an image. Right now I'm using 
> 

I think you are looking for axis labels - they are taken by default from 
your missing x and y arguments. Try something like:

image(matrix(rnorm(200), 10, 20), axes=FALSE)
axis(1, at=seq(0,1,length.out=10), labels=LETTERS[1:10])
axis(2, at=seq(0,1,length.out=20), labels=letters[1:20])
box()

I guess you'll want to set par(mar=) to give a bit more space, and maybe 
rotate the labels too.

>  
> 
> image(as.matrix(df3), col=brewer.pal(9,"Blues"))
> 
>  
> 
> where df3 is a data.frame.
> 
> dimnames(as.matrix(df3)) delivers
> 
>  
> 
> [[1]]
> 
>  [1] "RFM_A1" "RFM_A2" "RFM_A4" "RFM_A5" "RFM_A7" "RFM_B3" "RFM_B6" "RFM_B7" "RFM_B8" "RFM_B9" "RFM_C2" "RFM_C5" "RFM_C7"
> 
> [14] "RFM_D5" "RFM_D7" "RFM_D8" "RFM_A3" "RFM_A6" "RFM_B1" "RFM_B2" "RFM_B4" "RFM_B5" "RFM_C1" "RFM_C3" "RFM_C4" "RFM_C6"
> 
> [27] "RFM_C8" "RFM_C9" "RFM_D1" "RFM_D2" "RFM_D3" "RFM_D4" "RFM_D6" "RFM_D9"
> 
>  
> 
> [[2]]
> 
> [1] "Clus1" "Clus2" "Clus3" "Clus4" "Clus5" "Clus6" "Clus7"
> 
>  
> 
> The entries in the cells of the matrix are numeric.
> 
>  
> 
> All I get are axises with decimal numbers ranging from 0 to 1.
> 
>  
> 
> Thank you, sincerely
> 
> ___________________
> 
> Markus Preisetanz
> 
> Consultant
> 
>  
> 
> Client Vela GmbH
> 
> Albert-Ro??haupter-Str. 32
> 
> 81369 M??nchen
> 
> fon:          +49 (0) 89 742 17-113
> 
> fax:          +49 (0) 89 742 17-150
> 
> mailto:markus.preisetanz at clientvela.com <mailto:markus.preisetanz at clientvela.com> 
> 
> 
> 
> Diese E-Mail enth??lt vertrauliche und/oder rechtlich gesch??tzte Informationen. Wenn Sie nicht der richtige Adressat sind oder diese E-Mail irrt??mlich erhalten haben, informieren Sie bitte sofort den Absender und vernichten Sie diese Mail. Das unerlaubte Kopieren sowie die unbefugte Weitergabe dieser E-Mail ist nicht gestattet.
> 
> This e-mail may contain confidential and/or privileged infor...{{dropped}}
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From laura at env.leeds.ac.uk  Mon Feb 13 12:56:27 2006
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Mon, 13 Feb 2006 11:56:27 +0000 (GMT)
Subject: [R] Saving surface3d Output
Message-ID: <Pine.LNX.4.44.0602131153350.27990-100000@gw.env.leeds.ac.uk>

Hello,

Please could someone advise if it's possible to save the graphical output
from the surface3d() function? I have tried the dev.copy() function to
save as a pdf but an error message says I cannot copy from the null
device.

Laura Quinn
Institute of Atmospheric Science
School of Earth and Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk



From ripley at stats.ox.ac.uk  Mon Feb 13 13:04:49 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Feb 2006 12:04:49 +0000 (GMT)
Subject: [R] ?bug? strange factors produced by chron
In-Reply-To: <43F07C2D.18199.A8C38D@localhost>
References: <43F06684.10463.541B11@localhost> <43F07C2D.18199.A8C38D@localhost>
Message-ID: <Pine.LNX.4.64.0602131201430.9233@gannet.stats.ox.ac.uk>

On Mon, 13 Feb 2006, Petr Pikal wrote:

> Thank you very much.
>
> On 13 Feb 2006 at 10:54, Prof Brian Ripley wrote:
>
> Date sent:      	Mon, 13 Feb 2006 10:54:21 +0000 (GMT)
> From:           	Prof Brian Ripley <ripley at stats.ox.ac.uk>
> To:             	Petr Pikal <petr.pikal at precheza.cz>
> Copies to:      	r-help at stat.math.ethz.ch
> Subject:        	Re: [R] ?bug? strange factors produced by chron
>
>> 1) The obvious test is via is.factor(), and you have not used that.
>
> I used it with TRUE result but did not use in my post (mea culpa)
>> is.factor(kvartaly)
> [1] TRUE
>
>> 2) Your example works for me, so what versions of R and chron is this?
>
> Package: chron
> Version: 2.3-1
> R 2.2.1 and W2000
>
> but problem is probably in interaction (see below)
>>
>> 3) Here's my guess. split is using the C-level test isFactor.  That
>> tests that the factor is of type integer, so please try
>>
>>>  typeof(kvartaly)
>
> > typeof(kvartaly)
> [1] "double"
>
> Problem is probably not in chron but in interaction, which silently
> transfers factor type to double
>
>> typeof(factor(letters[1:2]))
> [1] "integer"
>
>> typeof(interaction(factor(letters[1:2]), factor(letters[3:4])))
> [1] "double"

2.2.1 does not do that for me (and contains ans <- as.integer(ans), and 
has since Sept 2001).  Do you have a private copy?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jcbouette at gmail.com  Mon Feb 13 13:05:04 2006
From: jcbouette at gmail.com (Jean-Christophe BOUETTE)
Date: Mon, 13 Feb 2006 13:05:04 +0100
Subject: [R] Sweave, mle and curve
Message-ID: <11544d000602130405g318f56a0x@mail.gmail.com>

> From: G??ran Brostr??m <goran.brostrom at gmail.com>
> To: r-help at stat.math.ethz.ch
> Date: Mon, 13 Feb 2006 11:16:14 +0100
> Subject: [R] Sweave, mle and curve
> I am trying to write a lesson on maximum likelihood with Sweave. I get
> a surprising result with the following code, lec4.Snw:
>
> \documentclass[a4paper,12pt]{article}
> \usepackage[latin1]{inputenc}
>
> \title{Maximum likelihood}
>
> \author{G??ran Brostr??m}
>
> \begin{document}
>
> \maketitle
>
> <<fig=TRUE>>=
> ## Simulate Y:
> n <- 25
> Y <- sum(rpois(n, lambda = 1))
> Y
>  ## Define minusloglik:
> minusloglik <- function(theta) n * theta - Y  * log(theta)
> curve(minusloglik, 0.2, 2, xlab = "theta")
>
> library(stats4)
> cat("Y is now ", Y, "\n")
> fit <- mle(minusloglik, start = list(theta = Y/n))
> summary(fit)
> @
>
> \end{document}
>
> In R, I get:
>
> > Sweave("lec4.Snw")
> Writing to file lec4.tex
> Processing code chunks ...
>  1 : echo term verbatim eps pdf
> Y is now  27
> Y is now  24
>
> You can now run LaTeX on 'lec4.tex'
> >
>
> and the latex document will have two different mle's,  one in the
> figure, and another one from 'mle'.  One uses Y = 27 and the other Y =
> 24!
>
> I can save the situation by moving "Y <- ..." to a separaye "code chunk".
> Does 'fig=TRUE' imply that the code chunk is run twice?
>
> --
> G??ran Brostr??m

Which figure did you use ? The .eps or the .pdf ? I guess one of them has Y=24.
The problem is that Sweave runs the code twice, to get the .eps plot
and the .pdf plot.
The solution is to isolate the "random" code in a separate chunk. I
think this issue was adressed some time ago in this list.

HTH,
Jean-Christophe Bou??tt??.



From murdoch at stats.uwo.ca  Mon Feb 13 13:20:06 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 13 Feb 2006 07:20:06 -0500
Subject: [R] Saving surface3d Output
In-Reply-To: <Pine.LNX.4.44.0602131153350.27990-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0602131153350.27990-100000@gw.env.leeds.ac.uk>
Message-ID: <43F07976.6050904@stats.uwo.ca>

On 2/13/2006 6:56 AM, Laura Quinn wrote:
> Hello,
> 
> Please could someone advise if it's possible to save the graphical output
> from the surface3d() function? I have tried the dev.copy() function to
> save as a pdf but an error message says I cannot copy from the null
> device.

Are you talking about surface3d in the rgl package?  It doesn't use the 
standard R graphics system, so dev.copy() won't help.  You need 
rgl.snapshot, which can create png files.  You'll need some other 
utility to convert those to pdf.

Duncan Murdoch



From Ita.Cirovic-Donev at hypo-alpe-adria.com  Mon Feb 13 13:30:21 2006
From: Ita.Cirovic-Donev at hypo-alpe-adria.com (Ita.Cirovic-Donev@hypo-alpe-adria.com)
Date: Mon, 13 Feb 2006 13:30:21 +0100
Subject: [R] search algorithm
Message-ID: <OF8521F65F.22ABF752-ONC1257114.0043D762-C1257114.0044B1E0@arz.co.at>





Hi!

I have a problem of finding a specific value in a column. For example, I
have a matrix with say 2 columns

           X                       Y
1    -2.0341602   9.036689e-05
2    -1.4287230   1.807338e-04
3    -1.1194402   2.711007e-04
4    -1.0327582   3.614676e-04
5    -0.8130556   4.518344e-04
6    -0.7138212   5.422013e-04
7    -0.6634425   6.325682e-04
8    -0.6512083   7.229351e-04
9    -0.6176286   8.133020e-04
10  -0.5897241    9.036689e-04

Now if I have some value of x=-0.6523. I need to find a value in the X
column  that is the closest to my value of x then read off the row number
and then take the corresponding value in column Y. What I am not sure is
how to do the first search where I would search by decimal places and take
the smallest absolute distance between the numbers. For example if he finds
the first value which is correct in this case - and then 0 and then 6 and
then 5 but now there is no 2 for that specific decimal place so he would
calculate the distance between the one before and the one after and see
which one is smaller. For that which is smaller would be the final X value.
Can someone please give me a hint on how to proceed. Thanks.



From r.hankin at noc.soton.ac.uk  Mon Feb 13 13:40:12 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Mon, 13 Feb 2006 12:40:12 +0000
Subject: [R] zero extent arrays and apply()
Message-ID: <39C43A2B-6FFD-4F37-B37C-3AB18BCB7E5E@soc.soton.ac.uk>

Hi

I am having difficulty making apply() work as expected (and desired)  
with arrays
that have zero-extent dimensions.

?apply says

   If each call to 'FUN' returns a vector of length 'n', then 'apply'
      returns an array of dimension 'c(n, dim(X)[MARGIN])' if 'n > 1'.
      If 'n' equals '1', 'apply' returns a vector if 'MARGIN' has length
      1 and an array of dimension 'dim(X)[MARGIN]' otherwise. If 'n' is
      '0', the result has length 0 but not necessarily the "correct"
      dimension.


My reading of this is that if n=1 and MARGIN has length >1 an array
of dimension dim(X)[MARGIN] is returned.  But:

 > a <- array(0,c(3,0,4))
 > dimnames(a) <- list(a=letters[1:3],b=NULL,c=LETTERS[1:4])
 > f <- function(x){5}
 > apply(a,1:2,f)
numeric(0)
 >

I want  an array of dimension c(3,0,4)[1:2]  here, ie c(3,0).  In my  
application,
the dimnames are the important thing.

Any comments anyone?


--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From dimitris.rizopoulos at med.kuleuven.be  Mon Feb 13 13:55:11 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Mon, 13 Feb 2006 13:55:11 +0100
Subject: [R] search algorithm
References: <OF8521F65F.22ABF752-ONC1257114.0043D762-C1257114.0044B1E0@arz.co.at>
Message-ID: <01b701c6309c$b9b02cc0$0540210a@www.domain>

maybe something like this could be of help:

mat <- matrix(rnorm(20), 10, 2)
val <- -0.6523
###################
ind <- which.min(abs(mat[, 1] - val))
mat
mat[ind, ]


Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: <Ita.Cirovic-Donev at hypo-alpe-adria.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, February 13, 2006 1:30 PM
Subject: [R] search algorithm


>
>
>
>
> Hi!
>
> I have a problem of finding a specific value in a column. For 
> example, I
> have a matrix with say 2 columns
>
>           X                       Y
> 1    -2.0341602   9.036689e-05
> 2    -1.4287230   1.807338e-04
> 3    -1.1194402   2.711007e-04
> 4    -1.0327582   3.614676e-04
> 5    -0.8130556   4.518344e-04
> 6    -0.7138212   5.422013e-04
> 7    -0.6634425   6.325682e-04
> 8    -0.6512083   7.229351e-04
> 9    -0.6176286   8.133020e-04
> 10  -0.5897241    9.036689e-04
>
> Now if I have some value of x=-0.6523. I need to find a value in the 
> X
> column  that is the closest to my value of x then read off the row 
> number
> and then take the corresponding value in column Y. What I am not 
> sure is
> how to do the first search where I would search by decimal places 
> and take
> the smallest absolute distance between the numbers. For example if 
> he finds
> the first value which is correct in this case - and then 0 and then 
> 6 and
> then 5 but now there is no 2 for that specific decimal place so he 
> would
> calculate the distance between the one before and the one after and 
> see
> which one is smaller. For that which is smaller would be the final X 
> value.
> Can someone please give me a hint on how to proceed. Thanks.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From B.Rowlingson at lancaster.ac.uk  Mon Feb 13 13:34:54 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Mon, 13 Feb 2006 12:34:54 +0000
Subject: [R] Saving surface3d Output
In-Reply-To: <43F07976.6050904@stats.uwo.ca>
References: <Pine.LNX.4.44.0602131153350.27990-100000@gw.env.leeds.ac.uk>
	<43F07976.6050904@stats.uwo.ca>
Message-ID: <43F07CEE.1020305@lancaster.ac.uk>

Duncan Murdoch wrote:

> Are you talking about surface3d in the rgl package?  It doesn't use the 
> standard R graphics system, so dev.copy() won't help.  You need 
> rgl.snapshot, which can create png files.  You'll need some other 
> utility to convert those to pdf.
> 

  Or screen-grab them somehow. In Windows: hit 'Print Scrn' - or is it 
shift-Print Scrn - then open a graphics program (Photoshop) and create a 
new picture and then 'Paste' it in. That'll give you the whole screen, 
so crop to size and save. There are other screen grabber utilities 
available.

  On Linux, I'd run Gimp and then capture the graphics window with the 
'Acquire... Screen Shot' function. Save as required.

Barry



From james.muller at anu.edu.au  Mon Feb 13 14:03:11 2006
From: james.muller at anu.edu.au (James Muller)
Date: Tue, 14 Feb 2006 00:03:11 +1100
Subject: [R] search algorithm
In-Reply-To: <OF8521F65F.22ABF752-ONC1257114.0043D762-C1257114.0044B1E0@arz.co.at>
References: <OF8521F65F.22ABF752-ONC1257114.0043D762-C1257114.0044B1E0@arz.co.at>
Message-ID: <20060213130311.GA1167@reventlov.com>

Hi,

I'm not sure how much weight you're putting on efficiency for your
algorithm, but that sounds unnecessarily complicated. If your matrices
are not too big then maybe something like this would work. Let your
matrix be M and your value be a, then


yoursearch <- function(M, a) {
	# generate abs dist vector
	dist <- abs(M[,"X"]-a)

	# which element is min dist
	argmin <- which.min(dist)

	# return corresponding Y value
	M[argmin,"Y"]
}


There are so many ways to do this faster (google for search algorithms
if you feel so inclined), but I think simplicity is good unless you
have enormous matrices or need to do it a very large number of times.

Anyway, hope this helps

James


On Mon, Feb 13, 2006 at 01:30:21PM +0100, Ita.Cirovic-Donev at hypo-alpe-adria.com wrote:
> I have a problem of finding a specific value in a column. For example, I
> have a matrix with say 2 columns
> 
> Now if I have some value of x=-0.6523. I need to find a value in the X
> column  that is the closest to my value of x then read off the row number
> and then take the corresponding value in column Y. What I am not sure is
> how to do the first search where I would search by decimal places and take
> the smallest absolute distance between the numbers. For example if he finds
> the first value which is correct in this case - and then 0 and then 6 and
> then 5 but now there is no 2 for that specific decimal place so he would
> calculate the distance between the one before and the one after and see
> which one is smaller. For that which is smaller would be the final X value.
> Can someone please give me a hint on how to proceed. Thanks.



From vivek.satsangi at gmail.com  Mon Feb 13 15:01:24 2006
From: vivek.satsangi at gmail.com (Vivek Satsangi)
Date: Mon, 13 Feb 2006 09:01:24 -0500
Subject: [R] R-help, specifying the places to decimal
Message-ID: <bcb171920602130601n4d3d20cfv21c38d9c927455da@mail.gmail.com>

In addition to round() mentioned earlier, if you are merely looking to
*display* your results differently, you may want to check out the
digits option, e.g. in summary():

(This is the method signature for data.frame 's):

     summary(object, maxsum = 7,
            digits = max(3, getOption("digits")-3), ...)


(Begin quoted message)
>Date: Mon, 13 Feb 2006 14:03:55 +0530
>From: "Subhabrata" <subhabratapal at sraindia.com>
>Subject: [R] R-help, specifying the places to decimal
>To: "r-help" <r-help at stat.math.ethz.ch>
>Message-ID: <022f01c63078$3c09c5c0$f608a8c0 at srai37>
>Content-Type: text/plain;       charset="iso-8859-1"

>Hello - R-experts,


>Is there any way with which we can specify the number after
>decimal point to take. Like I have a situation where
>the values are comming 0.160325923 but I only want
>4 place to decimal say 0.1603. Is there any way for that.

>I am no expert in R- and this may sound simple to many.sorry


>Thanks for any help.

>With Regards

>Subhabrata

--
-- Vivek Satsangi
Student, Rochester, NY USA



From ana.quiterio at ine.pt  Mon Feb 13 15:27:27 2006
From: ana.quiterio at ine.pt (=?iso-8859-1?Q?Ana_Quit=E9rio?=)
Date: Mon, 13 Feb 2006 14:27:27 -0000
Subject: [R]  export files - write.table
Message-ID: <E97312684A84D511BDD40002A50968D60725E6A1@lxpobw01.ine.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060213/67e4f709/attachment.pl

From petr.pikal at precheza.cz  Mon Feb 13 15:30:35 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 13 Feb 2006 15:30:35 +0100
Subject: [R] ?bug? strange factors produced by chron
In-Reply-To: <Pine.LNX.4.64.0602131201430.9233@gannet.stats.ox.ac.uk>
References: <43F07C2D.18199.A8C38D@localhost>
Message-ID: <43F0A61B.9458.14C89F1@localhost>

Hi

On 13 Feb 2006 at 12:04, Prof Brian Ripley wrote:

Date sent:      	Mon, 13 Feb 2006 12:04:49 +0000 (GMT)
From:           	Prof Brian Ripley <ripley at stats.ox.ac.uk>
To:             	Petr Pikal <petr.pikal at precheza.cz>
Copies to:      	r-help at stat.math.ethz.ch
Subject:        	Re: [R] ?bug? strange factors produced by chron

> On Mon, 13 Feb 2006, Petr Pikal wrote:
> 
> > Thank you very much.
> >
> > On 13 Feb 2006 at 10:54, Prof Brian Ripley wrote:
> >
> > Date sent:      	Mon, 13 Feb 2006 10:54:21 +0000 (GMT)
> > From:           	Prof Brian Ripley <ripley at stats.ox.ac.uk>
> > To:             	Petr Pikal <petr.pikal at precheza.cz>
> > Copies to:      	r-help at stat.math.ethz.ch
> > Subject:        	Re: [R] ?bug? strange factors produced by chron
> >
> >> 1) The obvious test is via is.factor(), and you have not used that.
> >
> > I used it with TRUE result but did not use in my post (mea culpa)
> >> is.factor(kvartaly)
> > [1] TRUE
> >
> >> 2) Your example works for me, so what versions of R and chron is
> >> this?
> >
> > Package: chron
> > Version: 2.3-1
> > R 2.2.1 and W2000
> >
> > but problem is probably in interaction (see below)
> >>
> >> 3) Here's my guess. split is using the C-level test isFactor.  That
> >> tests that the factor is of type integer, so please try
> >>
> >>>  typeof(kvartaly)
> >
> > > typeof(kvartaly)
> > [1] "double"
> >
> > Problem is probably not in chron but in interaction, which silently
> > transfers factor type to double
> >
> >> typeof(factor(letters[1:2]))
> > [1] "integer"
> >
> >> typeof(interaction(factor(letters[1:2]), factor(letters[3:4])))
> > [1] "double"
> 
> 2.2.1 does not do that for me (and contains ans <- as.integer(ans),
> and has since Sept 2001).  Do you have a private copy?

Yes, you have got it. I used (probably due to different handling of 
drop) a copy of interaction from Hmisc package from 2001, where there 
is no as.integer(ans). I'll switch to base version and see if there 
is no other problems with some of my code. 

As I noticed this behaviour only recently and use interaction from 
time to time so some other change had to sneaked around me without 
noticing.

Thank you again.

Best regards.
Petr

> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self) 1 South
> Parks Road,                     +44 1865 272866 (PA) Oxford OX1 3TG,
> UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From Ita.Cirovic-Donev at hypo-alpe-adria.com  Mon Feb 13 16:01:19 2006
From: Ita.Cirovic-Donev at hypo-alpe-adria.com (Ita.Cirovic-Donev@hypo-alpe-adria.com)
Date: Mon, 13 Feb 2006 16:01:19 +0100
Subject: [R]   export files - write.table
Message-ID: <OFF9D0649D.5E17AAB1-ONC1257114.00524849-C1257114.005284A5@arz.co.at>





for write.table in R I use the following:

# table to be stored in excel for example
sum.stat <- data.frame(sum.stat)        # data to be stored
write.table(sum.stat, file="D:/..../my_table.xls", sep="\t", dec=",",
row.names=TRUE, col.names=TRUE, qmethod="double")



From macq at llnl.gov  Mon Feb 13 16:38:42 2006
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 13 Feb 2006 07:38:42 -0800
Subject: [R] search algorithm
In-Reply-To: <OF8521F65F.22ABF752-ONC1257114.0043D762-C1257114.0044B1E0@arz.co.at>
References: <OF8521F65F.22ABF752-ONC1257114.0043D762-C1257114.0044B1E0@arz.co.at>
Message-ID: <p06210200c016579366b3@[128.115.153.6]>

There is a function in the Hmisc package that will help.

Example:

>  require(Hmisc)
>  x <- sort(runif(10))
>  x
  [1] 0.1225542 0.1620869 0.2197772 0.3187375 0.5498879 0.5644445 
0.5812717 0.7380532 0.8187384 0.9063713
>  whichClosest(x,.41)
[1] 4
>  x[4]
[1] 0.3187375

Or for your matrix (yourmat), this should work (but I haven't tested it)

    yourmat[ whichClosest(yourmat[,'X'] , -0.6523) , 'Y']

-Don

At 1:30 PM +0100 2/13/06, Ita.Cirovic-Donev at hypo-alpe-adria.com wrote:
>Hi!
>
>I have a problem of finding a specific value in a column. For example, I
>have a matrix with say 2 columns
>
>            X                       Y
>1    -2.0341602   9.036689e-05
>2    -1.4287230   1.807338e-04
>3    -1.1194402   2.711007e-04
>4    -1.0327582   3.614676e-04
>5    -0.8130556   4.518344e-04
>6    -0.7138212   5.422013e-04
>7    -0.6634425   6.325682e-04
>8    -0.6512083   7.229351e-04
>9    -0.6176286   8.133020e-04
>10  -0.5897241    9.036689e-04
>
>Now if I have some value of x=-0.6523. I need to find a value in the X
>column  that is the closest to my value of x then read off the row number
>and then take the corresponding value in column Y. What I am not sure is
>how to do the first search where I would search by decimal places and take
>the smallest absolute distance between the numbers. For example if he finds
>the first value which is correct in this case - and then 0 and then 6 and
>then 5 but now there is no 2 for that specific decimal place so he would
>calculate the distance between the one before and the one after and see
>which one is smaller. For that which is smaller would be the final X value.
>Can someone please give me a hint on how to proceed. Thanks.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From Ita.Cirovic-Donev at hypo-alpe-adria.com  Mon Feb 13 16:47:11 2006
From: Ita.Cirovic-Donev at hypo-alpe-adria.com (Ita.Cirovic-Donev@hypo-alpe-adria.com)
Date: Mon, 13 Feb 2006 16:47:11 +0100
Subject: [R] search algorithm
In-Reply-To: <p06210200c016579366b3@[128.115.153.6]>
Message-ID: <OF2B1F49E4.EA096B37-ONC1257114.0056762D-C1257114.0056B7A6@arz.co.at>





thanks a lot for the help. I tried some stuff and now it works.

____________________
Ita Cirovic-Donev
Risk Controlling

HYPO ALPE-ADRIA-BANK D.D.
Amruseva 6, HR-10000 Zagreb
Phone:      +385 1 4899 269
Fax:  +385 1 6063 344
E-Mail:     ita.cirovic-donev at hypo-alpe-adria.com
Web:  www.hypo-alpe-adria.hr



                                                                           
             Don MacQueen                                                  
             <macq at llnl.gov>                                               
                                                                        To 
             13.02.2006 16:38             Ita.Cirovic-Donev at hypo-alpe-adri 
                                          a.com, r-help at stat.math.ethz.ch  
                                                                        cc 
                                                                           
                                                                   Subject 
                                          Re: [R] search algorithm         
                                                                           
                                                                           
                                                                Importance 
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           
                                                                           




There is a function in the Hmisc package that will help.

Example:

>  require(Hmisc)
>  x <- sort(runif(10))
>  x
  [1] 0.1225542 0.1620869 0.2197772 0.3187375 0.5498879 0.5644445
0.5812717 0.7380532 0.8187384 0.9063713
>  whichClosest(x,.41)
[1] 4
>  x[4]
[1] 0.3187375

Or for your matrix (yourmat), this should work (but I haven't tested it)

    yourmat[ whichClosest(yourmat[,'X'] , -0.6523) , 'Y']

-Don

At 1:30 PM +0100 2/13/06, Ita.Cirovic-Donev at hypo-alpe-adria.com wrote:
>Hi!
>
>I have a problem of finding a specific value in a column. For example, I
>have a matrix with say 2 columns
>
>            X                       Y
>1    -2.0341602   9.036689e-05
>2    -1.4287230   1.807338e-04
>3    -1.1194402   2.711007e-04
>4    -1.0327582   3.614676e-04
>5    -0.8130556   4.518344e-04
>6    -0.7138212   5.422013e-04
>7    -0.6634425   6.325682e-04
>8    -0.6512083   7.229351e-04
>9    -0.6176286   8.133020e-04
>10  -0.5897241    9.036689e-04
>
>Now if I have some value of x=-0.6523. I need to find a value in the X
>column  that is the closest to my value of x then read off the row number
>and then take the corresponding value in column Y. What I am not sure is
>how to do the first search where I would search by decimal places and take
>the smallest absolute distance between the numbers. For example if he
finds
>the first value which is correct in this case - and then 0 and then 6 and
>then 5 but now there is no 2 for that specific decimal place so he would
>calculate the distance between the one before and the one after and see
>which one is smaller. For that which is smaller would be the final X
value.
>Can someone please give me a hint on how to proceed. Thanks.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html


--
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From rkrishnan8216 at yahoo.com  Mon Feb 13 16:48:54 2006
From: rkrishnan8216 at yahoo.com (Krish Krishnan)
Date: Mon, 13 Feb 2006 07:48:54 -0800 (PST)
Subject: [R] NA values in principal components
Message-ID: <20060213154854.7829.qmail@web60923.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060213/4f611a5d/attachment.pl

From phawkins at connact.com  Sat Feb 11 23:09:47 2006
From: phawkins at connact.com (Patricia J. Hawkins)
Date: Sat, 11 Feb 2006 17:09:47 -0500
Subject: [R] appeal --- add sd to summary for univariates
In-Reply-To: <50d1c22d0602061234u28cd4d56wa9e9839208296294@mail.gmail.com> (ivo
	welch's message of "Mon, 6 Feb 2006 15:34:28 -0500")
References: <50d1c22d0602061234u28cd4d56wa9e9839208296294@mail.gmail.com>
Message-ID: <wk64nlv978.fsf@connact.com>

>>>>> "iw" == ivo welch <ivowel at gmail.com> writes:

iw> just a short beg for the next R 2.3 version:
iw> I know it is easy to add the sd into summary() in the source bowels of
iw> R---but everytime R is updated, my change disappears.  :-(.  I do not
iw> believe that R has an easy extension mechanism for univariate
iw> summaries, short of a function rewrite here.  Could this please be
iw> added into R 2.3?

Surely this is the sort of change one puts in a profile file,
presumably .RProfile?  Or is there a reason against that?

-- 
Patricia J. Hawkins
Hawkins Internet Applications
www.hawkinsia.com



From phawkins at connact.com  Sat Feb 11 22:25:56 2006
From: phawkins at connact.com (Patricia J. Hawkins)
Date: Sat, 11 Feb 2006 16:25:56 -0500
Subject: [R] Turning on helpful errors in interpreter? was Re: problem with
 simple if() statement
In-Reply-To: <20060206062221.92796.qmail@web27402.mail.ukl.yahoo.com> (Norman
	Goodacre's message of "Mon, 6 Feb 2006 06:22:21 +0000 (GMT)")
References: <20060206062221.92796.qmail@web27402.mail.ukl.yahoo.com>
Message-ID: <wkaccxvb8b.fsf@connact.com>

Evidently, my R has some feature of error messages disabled.

>>>>> "NG" == Norman Goodacre <taranpen at yahoo.co.uk> writes:

NG> the following code apprantely, for some grand old reason, induces a syntax error:
NG>   if (seq[i] = "A") m <- trans[1,]

NG>   Error: syntax error in "if (seq[i] ="

Where Norman gets this nice error message pointing to the exact
location of the error, all I get is:

> if (1=1) 5
Error: syntax error
>

How do I turn on more-verbose error messages? Is this an environmental
issue, or a build issue?

This is a debian (ubuntu breezy) build; happens even when I run R --vanilla

R.version
         _                
platform i486-pc-linux-gnu
arch     i486             
os       linux-gnu        
system   i486, linux-gnu  
status                    
major    2                
minor    1.1              
year     2005             
month    06               
day      20               
language R                

TIA!

-- 
Patricia J. Hawkins
Hawkins Internet Applications
www.hawkinsia.com



From Scott.Waichler at pnl.gov  Mon Feb 13 17:26:18 2006
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Mon, 13 Feb 2006 08:26:18 -0800
Subject: [R] Package compiling problem in Linux
Message-ID: <7E4C06F49D6FEB49BE4B60E5FC92ED7A038CB2F9@pnlmse35.pnl.gov>


Hi,

I am trying to install packages in R-2.2.1 on a Redhat WS4 system.  I
get the following error messages trying to install, for example, the
akima package:

> R.version.string
[1] "R version 2.2.1, 2005-12-20"
> install.packages("akima", lib="/usr/lib/R/library", repos =
"http://cran.fhcrc.org/")
.
.
.
gcc -shared -L/usr/local/lib -o akima.so akima433.o akima697.o
akima.new.o idbvip.o idcldp.o idgrid.o idlctn.o idpdrv.o idptip.o
idptli.o idsfft.o idtang.o idxchg.o init.o tripack.o ttidbs.o  -lg2c -lm
-lgcc_s -L/usr/lib/R/lib -lR
/usr/bin/ld: skipping incompatible /usr/lib/R/lib/libR.so when searching
for -lR
/usr/bin/ld: cannot find -lR
collect2: ld returned 1 exit status
make: *** [akima.so] Error 1

I don't understand the -lR flag.  What is missing in the system toolkit?

Scott Waichler
Pacific Northwest National Laboratory
scott.waichler _at_ pnl.gov



From leinweber at neuro.mpg.de  Mon Feb 13 17:31:47 2006
From: leinweber at neuro.mpg.de (Marcus Leinweber)
Date: Mon, 13 Feb 2006 17:31:47 +0100
Subject: [R] export files - write.table
Message-ID: <059DE74C2765E04284021ACFDB7A22DD8765CD@s6.neuro.mpg.de>

Ana,

the following code may help:

teste="P:/test"
cc="pt"
yy="03"
data=matrix(1:12,3,4)

dir=paste(teste,cc,yy,sep="/")

# does directory already exist? if not, then create it
if (!is.null(try(setwd(dir),silent=TRUE))) {dir.create(dir,recursive=T)}

# write data to desired location 
write.table(data,file=paste(dir,"/",cc,yy,".txt",sep=""))

cheers,
marcus 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ana Quit??rio
> Sent: Monday, February 13, 2006 3:27 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] export files - write.table
> 
> Hi user
> 
> I have a question about export files.
> 
> I run my program for different countries and different years. 
> 
>  
> 
> For export files I do this in SAS:
> 
>  
> 
> (1) Path to data files
> 
> %let teste=C:\Documents and Settings\MEALQ\My Documents;
> 
>  
> 
> (2) Country code;
> 
> %let cc=pt;
> 
>  
> 
> (3) Survey year;
> 
> %let yy=03;
> 
>  
> 
> Output in: &teste\&cc\&yy\cc&yy.txt
> 
>  
> 
> How can I do a similar command in R?
> 
>  
> 
> Thanks in advance,
> 
>  
> 
> Ana Quiterio
> 
> Lisbon/Portugal
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Mon Feb 13 17:46:38 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 13 Feb 2006 08:46:38 -0800
Subject: [R] effect sizes in lme/ multi-level models
In-Reply-To: <43EB71A2.2030308@anicca-vijja.de>
References: <43EB71A2.2030308@anicca-vijja.de>
Message-ID: <43F0B7EE.1020606@pdf.com>

	  The "eta^2" you describe looks something like an R^2 (or maybe a 
partial R^2), and CohensD looks like a Student's t, at least to me.  The 
problem with generalizing these to multi-level models is deciding which 
components of variance to include where.  If you can answer that, I 
think you can find all the pieces you need by trying 
'methods(class="lme")'.  I just got 32 items on that list, but you might 
get a different number unless you have exactly the same packages (and 
versions) attached as I did just now.  From this list of 32, I suggest 
you look first at "fixef", "ranef", and "VarCorr".

	  hope this helps.
	  spencer graves

Leo G??rtler wrote:

> Dear alltogether,
> 
> I am searching for a way to determine "effect size" in multi-level 
> models by using lme().
> Coming from Psychology, for ordinary OLS there are measures (for 
> meta-analysis, etc.) like
> 
> CohensD <- (mean_EG - mean_CG) / SD_pooled
> 
> or
> 
> (p)eta^2 <- SS_effect / (SS_effect + SS_error)
> 
> I do not intend to lead a discussion of the usefulness of such measures 
> as long as the standards of psychological journals (e.g. as defined by 
> the APA) order them.
> However, I wondered how to determine measures of effect size in lme. 
> Pinheiro&Bates (2000) do not touch that topic.
> I assume that as long as a grouping structure is present, the formular 
> of CohensD (see above) has to be corrected to give respect to the 
> grouping structure. Is there any equivalent measure like eta^2, 
> partial-eta^2, etc.?
> 
> Can anybody help me with formulas, R code or some references?
> 
> Thank you very much,
> 
> thanks in advance,
> 
> leo g??rtler
>



From stephen.j.richards at gmail.com  Mon Feb 13 17:45:27 2006
From: stephen.j.richards at gmail.com (Stephen Richards)
Date: Mon, 13 Feb 2006 16:45:27 +0000
Subject: [R] Survreg(), Surv() and interval-censored data
Message-ID: <f301bda0602130845n3520c139k@mail.gmail.com>

Can survreg() handle interval-censored data like the documentation
says?  I ask because the command:

     survreg(Surv(start, stop, event) ~ 1, data = heart)

fails with the error message

     Invalid survival type

yet the documentation for Surv() states:

     "Presently, the only methods allowing interval censored data are
      the parametric models computed by 'survreg'"

Any pointers as to what I'm missing?

Stephen

--
Richards Consulting
+44(0)131 315 4470
Visit http://www.richardsconsulting.co.uk to download presentations
and papers on longevity risk, or to use our online calculation tools.

A subscription service is available for those companies wishing to
stay at the forefront of understanding the financial aspects of
longevity risk.
Visit http://www.richardsconsulting.co.uk/service.html for more details.

Services are provided by Stephen Richards Consulting Ltd, a
limited-liability company registered in Scotland, number SC144342.



From ligges at statistik.uni-dortmund.de  Mon Feb 13 17:51:27 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 13 Feb 2006 17:51:27 +0100
Subject: [R] Turning on helpful errors in interpreter? was Re: problem
 with simple if() statement
In-Reply-To: <wkaccxvb8b.fsf@connact.com>
References: <20060206062221.92796.qmail@web27402.mail.ukl.yahoo.com>
	<wkaccxvb8b.fsf@connact.com>
Message-ID: <43F0B90F.9080203@statistik.uni-dortmund.de>

Patricia J. Hawkins wrote:

> Evidently, my R has some feature of error messages disabled.
> 
> 
>>>>>>"NG" == Norman Goodacre <taranpen at yahoo.co.uk> writes:
> 
> 
> NG> the following code apprantely, for some grand old reason, induces a syntax error:
> NG>   if (seq[i] = "A") m <- trans[1,]
> 
> NG>   Error: syntax error in "if (seq[i] ="
> 
> Where Norman gets this nice error message pointing to the exact
> location of the error, all I get is:
> 
> 
>>if (1=1) 5
> 
> Error: syntax error
> 
> 
> How do I turn on more-verbose error messages? Is this an environmental
> issue, or a build issue?

It's a version issue! Please update.

Uwe Ligges


> 
> This is a debian (ubuntu breezy) build; happens even when I run R --vanilla
> 
> R.version
>          _                
> platform i486-pc-linux-gnu
> arch     i486             
> os       linux-gnu        
> system   i486, linux-gnu  
> status                    
> major    2                
> minor    1.1              
> year     2005             
> month    06               
> day      20               
> language R                
> 
> TIA!
>



From gunter.berton at gene.com  Mon Feb 13 17:58:50 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 13 Feb 2006 08:58:50 -0800
Subject: [R] Windows GUI package install annoyance
Message-ID: <200602131658.k1DGwogI020339@hertz.gene.com>

Folks:

A minor (R 2.2.0) Windows package install annoyance, but I can't figure out
how to fix it. If someone could tell me how or point me to the appropriate
docs, I would appreciate it. 

I set my CRAN mirror in my Rprofile.site file. After startup, I get:

> getOption('repos')
                          CRAN 
"http:/cran.cnr.berkeley.edu/" 
> 

However, when I then go to the GUI "Packages" menu item and click on
"Install packages..." I get:

> utils:::menuInstallPkgs()
Warning: unable to access index for repository
http:/cran.cnr.berkeley.edu/bin/windows/contrib/2.2
Error in install.packages(NULL, .libPaths()[1], dependencies = TRUE, type =
type) : 
        no packages were specified


However, If I now manually set my mirror (through the menu: "Set Cran
mirror" item, which invokes chooseCRANmirror()) , and now check my repos
option, I get again:

> getOption('repos')
                          CRAN 
"http://cran.cnr.Berkeley.edu" 


## but now the "install packages.." menu choice works! 
Is there an easy way to avoid having to manually re-specify my CRAN mirror?

My apologies for wasted bandwidth if I have overlooked something obvious,
which I believe is the case.

Many thanks.

-- Bert

Bert Gunter
Genentech



From Charles.Annis at StatisticalEngineering.com  Mon Feb 13 18:25:33 2006
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Mon, 13 Feb 2006 12:25:33 -0500
Subject: [R] Survreg(), Surv() and interval-censored data
In-Reply-To: <f301bda0602130845n3520c139k@mail.gmail.com>
Message-ID: <013f01c630c2$7eeeb680$6600a8c0@DD4XFW31>

How have you defined "event?"

library(survival)
?Surv

event: The status indicator, normally 0=alive, 1=dead.  Other
          choices are T/F (TRUE = death) or 1/2 (2=death). For interval
          censored data, the status indicator is 0=right censored, 1=
          event at 'time', 2=left censored, 3=interval censored.
          Although unusual, the event indicator can be omitted, in
          which case all subjects are assumed to have an event.



Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Stephen Richards
Sent: Monday, February 13, 2006 11:45 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Survreg(), Surv() and interval-censored data

Can survreg() handle interval-censored data like the documentation
says?  I ask because the command:

     survreg(Surv(start, stop, event) ~ 1, data = heart)

fails with the error message

     Invalid survival type

yet the documentation for Surv() states:

     "Presently, the only methods allowing interval censored data are
      the parametric models computed by 'survreg'"

Any pointers as to what I'm missing?

Stephen

--
Richards Consulting
+44(0)131 315 4470
Visit http://www.richardsconsulting.co.uk to download presentations
and papers on longevity risk, or to use our online calculation tools.

A subscription service is available for those companies wishing to
stay at the forefront of understanding the financial aspects of
longevity risk.
Visit http://www.richardsconsulting.co.uk/service.html for more details.

Services are provided by Stephen Richards Consulting Ltd, a
limited-liability company registered in Scotland, number SC144342.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Mon Feb 13 18:27:45 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 13 Feb 2006 18:27:45 +0100
Subject: [R] Windows GUI package install annoyance
In-Reply-To: <200602131658.k1DGwogI020339@hertz.gene.com>
References: <200602131658.k1DGwogI020339@hertz.gene.com>
Message-ID: <43F0C191.9030505@statistik.uni-dortmund.de>

Berton Gunter wrote:

> Folks:
> 
> A minor (R 2.2.0) Windows package install annoyance, but I can't figure out
> how to fix it. If someone could tell me how or point me to the appropriate
> docs, I would appreciate it. 
> 
> I set my CRAN mirror in my Rprofile.site file. After startup, I get:
> 
> 
>>getOption('repos')
> 
>                           CRAN 
> "http:/cran.cnr.berkeley.edu/" 
> 
> 
> However, when I then go to the GUI "Packages" menu item and click on
> "Install packages..." I get:
> 
> 
>>utils:::menuInstallPkgs()
> 
> Warning: unable to access index for repository
> http:/cran.cnr.berkeley.edu/bin/windows/contrib/2.2
> Error in install.packages(NULL, .libPaths()[1], dependencies = TRUE, type =
> type) : 
>         no packages were specified
> 
> 
> However, If I now manually set my mirror (through the menu: "Set Cran
> mirror" item, which invokes chooseCRANmirror()) , and now check my repos
> option, I get again:
> 
> 
>>getOption('repos')
> 
>                           CRAN 
> "http://cran.cnr.Berkeley.edu" 
> 
> 
> ## but now the "install packages.." menu choice works! 
> Is there an easy way to avoid having to manually re-specify my CRAN mirror?

Yes: do not omit the second "/" after "http:" in 
"http://cran.cnr.berkeley.edu/" .....

Uwe Ligges


> My apologies for wasted bandwidth if I have overlooked something obvious,
> which I believe is the case.
> 
> Many thanks.
> 
> -- Bert
> 
> Bert Gunter
> Genentech
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From gunter.berton at gene.com  Mon Feb 13 18:39:38 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 13 Feb 2006 09:39:38 -0800
Subject: [R] Windows GUI package install annoyance
In-Reply-To: <43F0C191.9030505@statistik.uni-dortmund.de>
Message-ID: <200602131739.k1DHdcA9023603@faraday.gene.com>


Thanks, Uwe. I knew it was something stupid, but I could have stared at it
forever and still missed it.


-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA

 

> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.uni-dortmund.de] 
> Sent: Monday, February 13, 2006 9:28 AM
> To: Berton Gunter
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Windows GUI package install annoyance
> 
> Berton Gunter wrote:
> 
> > Folks:
> > 
> > A minor (R 2.2.0) Windows package install annoyance, but I 
> can't figure out
> > how to fix it. If someone could tell me how or point me to 
> the appropriate
> > docs, I would appreciate it. 
> > 
> > I set my CRAN mirror in my Rprofile.site file. After startup, I get:
> > 
> > 
> >>getOption('repos')
> > 
> >                           CRAN 
> > "http:/cran.cnr.berkeley.edu/" 
> > 
> > 
> > However, when I then go to the GUI "Packages" menu item and click on
> > "Install packages..." I get:
> > 
> > 
> >>utils:::menuInstallPkgs()
> > 
> > Warning: unable to access index for repository
> > http:/cran.cnr.berkeley.edu/bin/windows/contrib/2.2
> > Error in install.packages(NULL, .libPaths()[1], 
> dependencies = TRUE, type =
> > type) : 
> >         no packages were specified
> > 
> > 
> > However, If I now manually set my mirror (through the menu: 
> "Set Cran
> > mirror" item, which invokes chooseCRANmirror()) , and now 
> check my repos
> > option, I get again:
> > 
> > 
> >>getOption('repos')
> > 
> >                           CRAN 
> > "http://cran.cnr.Berkeley.edu" 
> > 
> > 
> > ## but now the "install packages.." menu choice works! 
> > Is there an easy way to avoid having to manually re-specify 
> my CRAN mirror?
> 
> Yes: do not omit the second "/" after "http:" in 
> "http://cran.cnr.berkeley.edu/" .....
> 
> Uwe Ligges
> 
> 
> > My apologies for wasted bandwidth if I have overlooked 
> something obvious,
> > which I believe is the case.
> > 
> > Many thanks.
> > 
> > -- Bert
> > 
> > Bert Gunter
> > Genentech
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From rmason at esd.mun.ca  Mon Feb 13 18:48:11 2006
From: rmason at esd.mun.ca (Roger Mason)
Date: Mon, 13 Feb 2006 14:18:11 -0330
Subject: [R] reshaping data
Message-ID: <y654q33no9w.fsf@minnie.esd.mun.ca>

Hello,

I have data in a frame:

1 2 3 4 5 6 7 8
9 10 11 12 13 14 15 16

I would like them arranged in a single column:

1
2
3
4
.
.
8
9
.
.
16

etc.

I believe this should be possible using reshape, but I can't see how
to do it.

Thanks for sparing time to help a neophyte,

Roger Mason



From tariq.khan at gmail.com  Mon Feb 13 19:01:22 2006
From: tariq.khan at gmail.com (=?ISO-8859-1?Q?=A8Tariq_Khan?=)
Date: Mon, 13 Feb 2006 18:01:22 +0000
Subject: [R] reshaping data
In-Reply-To: <y654q33no9w.fsf@minnie.esd.mun.ca>
References: <y654q33no9w.fsf@minnie.esd.mun.ca>
Message-ID: <2310043c0602131001q726f14c3tb2e37904548a945c@mail.gmail.com>

You might just want to try this, it is quite efficient:

as.numeric(t(as.matrix(x)))

On 2/13/06, Roger Mason <rmason at esd.mun.ca> wrote:
> Hello,
>
> I have data in a frame:
>
> 1 2 3 4 5 6 7 8
> 9 10 11 12 13 14 15 16
>
> I would like them arranged in a single column:
>
> 1
> 2
> 3
> 4
> .
> .
> 8
> 9
> .
> .
> 16
>
> etc.
>
> I believe this should be possible using reshape, but I can't see how
> to do it.
>
> Thanks for sparing time to help a neophyte,
>
> Roger Mason
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From nli at fhcrc.org  Mon Feb 13 19:05:25 2006
From: nli at fhcrc.org (Nianhua Li)
Date: Mon, 13 Feb 2006 10:05:25 -0800
Subject: [R] [BioC] ANN: Introductory R and Bioconductor Mini Course ,
 Seattle, April 12-14
Message-ID: <43F0CA65.2090109@fhcrc.org>

[BioC] ANN: Introductory R and Bioconductor Mini Course , Seattle, April 
12-14

We will present a short course on using Bioconductor, primarily aimed at 
analyzing microarray data, over 2 1/2 days in April. The course will be 
a mix of lectures and practical labs.

Instructors:
   Robert Gentleman, Seth Falcon, Martin Morgan, and Nolwenn Le Meur
Topics:
   Introduction to R
   Preprocessing of Affymetrix expression arrays using Bioconductor
   Analysis of cDNA microarrays
   Machine Learning
   Accessing microarray annotation with Bioconductor tools
Details:
   April 12th - 14th
   Fred Hutchinson Cancer Research Center
   Seattle, WA, USA

Please see http://www.bioconductor.org/biocintro/ for more details and 
registration.

Contact biocworkshop at fhcrc.org for more details.



From bret at tamu.edu  Mon Feb 13 19:24:22 2006
From: bret at tamu.edu (Bret Collier)
Date: Mon, 13 Feb 2006 12:24:22 -0600
Subject: [R] JRG Console Output
Message-ID: <s3f07a8c.028@wfscgate.tamu.edu>

All,
I had a question about the JGR console and whether or not I can
manipulate the location where line wrapping occurs.  I have searched
'JGR' in the R listserve archives and attempted to find console
manipulation on the JGR website to no avail and could use some
direction.

TIA, Bret

As an example, the below output wraps every 4th value, leaving about
2/3 of the console empty.

> rnorm(20, 50, 17)
 [1] 43.42240 39.94807  8.94276 15.19369
 [5] 82.56500 17.96678 80.58936 48.61693
 [9] 75.92249 71.86615 53.39025 24.08080
[13] 23.92690 35.96344 61.29200 63.37290
[17] 77.71882 56.54847 70.16172 51.61530

where the below increases the 'after decimal' range 1 unit and cuts
back to 3 values per line.

> rnorm(1000, 50, 17)
   [1]  64.805808  54.770722  46.552925
   [4]  34.371987  61.971183  37.327260
   [7]  60.403990  47.783683  51.744272
  [10]  32.671062  31.395127  69.085938
  [13]  77.554024  48.579639  48.111326
  [16]  44.994786  65.241722  65.852035
  [19]  53.254482  43.217719  30.255150


Reading in some data, the 'mydat' line extends across the console, but
the output is wrapped around again?

> mydat<-data.frame(ID, Year = factor(Year), Dayrelease, Agerelease,
Survivorship, Entry, Exit, Fate, Gender)
> mydat
       ID Year Dayrelease Agerelease
1   16240 1996        205         95
2   16319 1996        205         88
3   16378 1996        248        108
.
.
.
576  3094 2005        251        136
577  2667 2005        264        861
578  3035 2005        264        497
    Survivorship Entry Exit Fate Gender
1            164   205  369    1      0
2            140   205  345    1      0
3            100   248  348    1      0
4            204   241  445    1      0
5            227   219  446    1      0


>version
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    2.1            
year     2005           
month    12             
day      20             
svn rev  36812          
language R



From rmason at esd.mun.ca  Mon Feb 13 19:27:43 2006
From: rmason at esd.mun.ca (Roger Mason)
Date: Mon, 13 Feb 2006 14:57:43 -0330
Subject: [R] reshaping data
In-Reply-To: <2310043c0602131001q726f14c3tb2e37904548a945c@mail.gmail.com> 
	=?iso-8859-1?q?=28=A8Tariq?= Khan's message of "Mon,
	13 Feb 2006 18:01:22 +0000")
References: <y654q33no9w.fsf@minnie.esd.mun.ca>
	<2310043c0602131001q726f14c3tb2e37904548a945c@mail.gmail.com>
Message-ID: <y65wtfzm7vk.fsf@minnie.esd.mun.ca>

Thank you Tariq.  That works perfectly.

Roger

??Tariq Khan <tariq.khan at gmail.com> writes:

> You might just want to try this, it is quite efficient:
>
> as.numeric(t(as.matrix(x)))
>



From rlevy at inf.ed.ac.uk  Mon Feb 13 19:29:03 2006
From: rlevy at inf.ed.ac.uk (Roger Levy)
Date: Mon, 13 Feb 2006 18:29:03 +0000
Subject: [R] indexing via a character matrix?
Message-ID: <43F0CFEF.3070900@inf.ed.ac.uk>

Hi,

Is it possible to index via a character matrix?  For example, I would 
like to do the following:

cont.table <- table(df1$A,df1$B) # df1 a data frame with factors A and B
cont.table[cbind(df2$A,df2$B)]   # df2 a smaller data frame with some
                                  # pairings of values for A and B

but the second step does not work -- I guess that matrices to be used 
for indexing this way must be numeric.  Is there a way to index multiple 
character tuples out of a contingency table without resorting to writing 
loops?

Many thanks,

Roger Levy



From deshon at msu.edu  Mon Feb 13 19:40:15 2006
From: deshon at msu.edu (Rick DeShon)
Date: Mon, 13 Feb 2006 13:40:15 -0500
Subject: [R] Help scoring a matrix of item responses
Message-ID: <c3cb73d50602131040p4c172252u56fc6e4ef9cb9dd6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060213/6681db8d/attachment.pl

From deshon at msu.edu  Mon Feb 13 19:45:13 2006
From: deshon at msu.edu (Rick DeShon)
Date: Mon, 13 Feb 2006 13:45:13 -0500
Subject: [R] Fwd: Help scoring a matrix of item responses
In-Reply-To: <c3cb73d50602131040p4c172252u56fc6e4ef9cb9dd6@mail.gmail.com>
References: <c3cb73d50602131040p4c172252u56fc6e4ef9cb9dd6@mail.gmail.com>
Message-ID: <c3cb73d50602131045u7cac8134r101ac7a77461f757@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060213/16e8f324/attachment.pl

From lisawang at uhnres.utoronto.ca  Mon Feb 13 19:46:15 2006
From: lisawang at uhnres.utoronto.ca (Lisa Wang)
Date: Mon, 13 Feb 2006 13:46:15 -0500
Subject: [R] LCA in e1071
Message-ID: <43F0D3F7.F37BD0FF@uhnres.utoronto.ca>

Hello there,

In the e1071 package,'lca' function only works for binary data for
Latent class analysis. Am I right?

 I would like to test the agreement amongst 6 raters for nominal data
ona scale from 1-4, and conduct a latent class analysis. What package
and what function may I use?

Thank you very much

Lisa Wang
Princess Margaret Hospital
tel: 416 946 4501



From ggrothendieck at gmail.com  Mon Feb 13 19:53:56 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 13 Feb 2006 13:53:56 -0500
Subject: [R] Fwd: Help scoring a matrix of item responses
In-Reply-To: <c3cb73d50602131045u7cac8134r101ac7a77461f757@mail.gmail.com>
References: <c3cb73d50602131040p4c172252u56fc6e4ef9cb9dd6@mail.gmail.com>
	<c3cb73d50602131045u7cac8134r101ac7a77461f757@mail.gmail.com>
Message-ID: <971536df0602131053g3801a402g55cd826b9e170b51@mail.gmail.com>

Assuming this test data:

iris2 <- round(iris[1:10, 1:4])

Try this:

t(t(iris2) == c(iris2[1,])) + 0

On 2/13/06, Rick DeShon <deshon at msu.edu> wrote:
> Hi All.
>
> I'm new to R and trying to learn the data manipulation routines.  At the
> moment, this is the one that has me stumped.
>
> Imagine n test takers provide responses to k multiple choice items.  The
> result is a (n+1) x k matrix of responses where the first row of the matrix
> is a correct answer key.
>
> How could you transform the raw item responses into 1s (correct response)
> and 0s (incorrect responses) by comparing each test takers response to the
> correct answer key?
>
> Any direction would be appreciated!
>
> Rick
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From terrywschulz at comcast.net  Mon Feb 13 20:01:48 2006
From: terrywschulz at comcast.net (Terry W. Schulz)
Date: Mon, 13 Feb 2006 12:01:48 -0700
Subject: [R] Extracting data elements from simpleboot
Message-ID: <43F0D79C.5010802@comcast.net>

Hello,
I am new to R, so forgive my ignorance on what is probably simple.
I find package simpleboot quite useful for LOESS bootstrapping and 
generation of plots.
I want to calculate the standard error for x=60 from the 100 grid points 
and 50 bootstraps.
The code below gives the first fitted value.
How can I grab the other 49 values easily?
I could do it one at a time for 50 bootstraps, but this becomes tedious 
for say 2000 bootstraps.
Thanks for any help.

library(simpleboot)
library(bootstrap)
attach(cholost)
set.seed(13579)
lo <- loess(y ~ z, data=cholost, span=.5, degree=2, family="gaussian", 
method="loess")
lo.b <- loess.boot(lo, R=50, rows = TRUE, new.xpts = NULL, ngrid = 100, 
weights = NULL)
lo.b$boot.list$"1"$fitted[60]

-- 
Terry W. Schulz
Applied Statistician
1218 Pomegranate Lane
Golden, CO 80401

terrywschulz at comcast.net
(303) 526-1461



From ripley at stats.ox.ac.uk  Mon Feb 13 20:11:01 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Feb 2006 19:11:01 +0000 (GMT)
Subject: [R] Package compiling problem in Linux
In-Reply-To: <7E4C06F49D6FEB49BE4B60E5FC92ED7A038CB2F9@pnlmse35.pnl.gov>
References: <7E4C06F49D6FEB49BE4B60E5FC92ED7A038CB2F9@pnlmse35.pnl.gov>
Message-ID: <Pine.LNX.4.64.0602131907040.17719@gannet.stats.ox.ac.uk>

On Mon, 13 Feb 2006, Waichler, Scott R wrote:

> I am trying to install packages in R-2.2.1 on a Redhat WS4 system.  I

What architecture is this?  How did you install R?

> get the following error messages trying to install, for example, the
> akima package:
>
>> R.version.string
> [1] "R version 2.2.1, 2005-12-20"
>> install.packages("akima", lib="/usr/lib/R/library", repos =
> "http://cran.fhcrc.org/")
> .
> .
> .
> gcc -shared -L/usr/local/lib -o akima.so akima433.o akima697.o
> akima.new.o idbvip.o idcldp.o idgrid.o idlctn.o idpdrv.o idptip.o
> idptli.o idsfft.o idtang.o idxchg.o init.o tripack.o ttidbs.o  -lg2c -lm
> -lgcc_s -L/usr/lib/R/lib -lR
> /usr/bin/ld: skipping incompatible /usr/lib/R/lib/libR.so when searching
> for -lR
> /usr/bin/ld: cannot find -lR
> collect2: ld returned 1 exit status
> make: *** [akima.so] Error 1
>
> I don't understand the -lR flag.  What is missing in the system toolkit?

It is not a flag: it is an instruction to link against libR.

The only way I can see this happening is if you installed a ix86 RPM on a 
x86_86 system.  You can do that and R will run, but you will not be able 
to build packages out of the box.

What I am quite sure about is that R was not built on the system you are 
running here, since this error would have occurred whilst building R.
The solution is to build R from the sources.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Feb 13 20:18:31 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 13 Feb 2006 19:18:31 +0000 (GMT)
Subject: [R] indexing via a character matrix?
In-Reply-To: <43F0CFEF.3070900@inf.ed.ac.uk>
References: <43F0CFEF.3070900@inf.ed.ac.uk>
Message-ID: <Pine.LNX.4.64.0602131912400.17719@gannet.stats.ox.ac.uk>

On Mon, 13 Feb 2006, Roger Levy wrote:

> Hi,
>
> Is it possible to index via a character matrix?  For example, I would
> like to do the following:
>
> cont.table <- table(df1$A,df1$B) # df1 a data frame with factors A and B
> cont.table[cbind(df2$A,df2$B)]   # df2 a smaller data frame with some
>                                  # pairings of values for A and B
>
> but the second step does not work -- I guess that matrices to be used
> for indexing this way must be numeric.  Is there a way to index multiple

Numeric or logical.

> character tuples out of a contingency table without resorting to writing
> loops?

What are you trying to do here?  One possibility is that you meant

comt.table[df2$A, df2$B]

and another is

ind1 <- match(df2$A, df1$A)
ind2 <- match(df2$B, df1$B)
cont.table[cbind(ind1, ind2)]

and I am not certain which.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Marco.Kienzle at noaa.gov  Mon Feb 13 20:17:14 2006
From: Marco.Kienzle at noaa.gov (Marco Kienzle)
Date: Mon, 13 Feb 2006 09:17:14 -1000
Subject: [R] problem with ROracle - Internal heap ERROR 17177
Message-ID: <43F0DB3A.7040202@noaa.gov>

Dear R-users,

here is an error that you might encounter when using ROracle.

> library(ROracle)
Loading required package: DBI
> con <- dbConnect(dbDriver("Oracle"), "mkienzle/******@tabs")
> dbListTables(con)
********** Internal heap ERROR 17177 addr=0x0 *********


******************************************************
HEAP DUMP heap name="Alloc statemen"  desc=0x9163cc4
....
etc...
....
Segmentation fault


People have been reporting such an error when different version of the 
Oracle client and server are used 
(http://homepage.internet.lu/dbacomp/html/9i.html). David James
suggests compiling ROracle using ProC/C++ argument PREFETCH=0.

To do so and fix this problem, you have to re-install ROracle using a 
modified Makefile.in file. Below is a description of how to do so under 
Linux.

	(1) REMOVE the currently installed ROracle package
	(2) un-pack ROracle-<version>.tar.gz
	(3) modify ROracle/src/Makefile.in by adding the PREFETCH=0 		 
    argument to the ProC/C++ command
	
	----original version----
	RS-Oracle.c: RS-Oracle.h RS-Oracle.pc
         $(PROC) CODE=$(CODE) MODE=$(MODE) INCLUDE=$(RHOME)/include \
                 PARSE=$(PARSE) LINES=$(LINES) RS-Oracle.pc

	----modified version----
	RS-Oracle.c: RS-Oracle.h RS-Oracle.pc
         $(PROC) CODE=$(CODE) MODE=$(MODE) INCLUDE=$(RHOME)/include \
                 PARSE=$(PARSE) LINES=$(LINES) PREFETCH=0 RS-Oracle.pc

	(4) INSTALL the "modified" ROracle package


cheers,
marco



From SETH.A.BLANCHARD at saic.com  Mon Feb 13 20:49:25 2006
From: SETH.A.BLANCHARD at saic.com (Blanchard, Seth A. )
Date: Mon, 13 Feb 2006 14:49:25 -0500
Subject: [R] X,Y,Z, scatter plot
Message-ID: <798C56D36FEBA946B00DFB5ADBEB9C0964C2AB@0641-its-exmb01.us.saic.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060213/e9512905/attachment.pl

From kjetilbrinchmannhalvorsen at gmail.com  Mon Feb 13 21:10:30 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Mon, 13 Feb 2006 16:10:30 -0400
Subject: [R] LCA in e1071
In-Reply-To: <43F0D3F7.F37BD0FF@uhnres.utoronto.ca>
References: <43F0D3F7.F37BD0FF@uhnres.utoronto.ca>
Message-ID: <43F0E7B6.6020100@gmail.com>

Lisa Wang wrote:
> Hello there,
> 
> In the e1071 package,'lca' function only works for binary data for
> Latent class analysis. Am I right?
> 
>  I would like to test the agreement amongst 6 raters for nominal data
> ona scale from 1-4, and conduct a latent class analysis. What package

package irr (on CRAN) might help.

Kjetil

> and what function may I use?
> 
> Thank you very much
> 
> Lisa Wang
> Princess Margaret Hospital
> tel: 416 946 4501
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Mon Feb 13 21:12:44 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 13 Feb 2006 15:12:44 -0500
Subject: [R] X,Y,Z, scatter plot
In-Reply-To: <798C56D36FEBA946B00DFB5ADBEB9C0964C2AB@0641-its-exmb01.us.saic.com>
References: <798C56D36FEBA946B00DFB5ADBEB9C0964C2AB@0641-its-exmb01.us.saic.com>
Message-ID: <43F0E83C.4000906@stats.uwo.ca>

On 2/13/2006 2:49 PM, Blanchard, Seth A. wrote:
> Hey All,
>  
>           I am trying to create a scatter plot of x,y,z data where the
> points are color coded by their z value. So far I have:
>           plot(BGx, BGy, pch=22, type="p", col=heat.colors(20)) is this
> right? 

If the z values go from 1 to 20, that looks fine.  If not, you need to 
pay attention to them somehow.

Duncan Murdoch



From chabotd at globetrotter.net  Mon Feb 13 22:07:32 2006
From: chabotd at globetrotter.net (Denis Chabot)
Date: Mon, 13 Feb 2006 16:07:32 -0500
Subject: [R] transforming data frame for use with persp
Message-ID: <89097FF2-B4A8-49E9-B7AE-4E18BBA4D3E4@globetrotter.net>

Hi,

This is probably documented, but I cannot find the right words or  
expression for a search. My attempts failed.

I have a data frame of 3 vectors (x, y and z) and would like to  
transform this so that I could use persp. Presently I have y-level  
copies of each x level, and a z value for each x-y pair. I need 2  
columns giving the possible levels of x and y, and then a  
transformation of z from a long vector into a matrix of x-level rows  
and y-level columns. How do I accomplish this?

In this example, I made a set of x and y values to get predictions  
from a GAM, then combined them with the predictions into a data  
frame. This is the one I'd like to transform as described above:

My.data <- expand.grid(Depth=seq(40,220, 20), Temp=seq(-1, 6, 0.5))
predgam <- predict.gam(dxt.gam, My.data, type="response")
pred.data <- data.frame(My.data, predgam)

pred.data has 150 lines and 3 columns.

Thanks for your help,

Denis Chabot



From rkoenker at uiuc.edu  Mon Feb 13 22:19:23 2006
From: rkoenker at uiuc.edu (roger koenker)
Date: Mon, 13 Feb 2006 15:19:23 -0600
Subject: [R] transforming data frame for use with persp
In-Reply-To: <89097FF2-B4A8-49E9-B7AE-4E18BBA4D3E4@globetrotter.net>
References: <89097FF2-B4A8-49E9-B7AE-4E18BBA4D3E4@globetrotter.net>
Message-ID: <D58FDD17-CEF3-43C6-B960-8F4F035ACD07@uiuc.edu>


a strategy for this that I  use is just

	persp(interp(x,y,z))

where interp is from the Akima package, and x,y,z are all
of the same length.


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Champaign, IL 61820


On Feb 13, 2006, at 3:07 PM, Denis Chabot wrote:

> Hi,
>
> This is probably documented, but I cannot find the right words or
> expression for a search. My attempts failed.
>
> I have a data frame of 3 vectors (x, y and z) and would like to
> transform this so that I could use persp. Presently I have y-level
> copies of each x level, and a z value for each x-y pair. I need 2
> columns giving the possible levels of x and y, and then a
> transformation of z from a long vector into a matrix of x-level rows
> and y-level columns. How do I accomplish this?
>
> In this example, I made a set of x and y values to get predictions
> from a GAM, then combined them with the predictions into a data
> frame. This is the one I'd like to transform as described above:
>
> My.data <- expand.grid(Depth=seq(40,220, 20), Temp=seq(-1, 6, 0.5))
> predgam <- predict.gam(dxt.gam, My.data, type="response")
> pred.data <- data.frame(My.data, predgam)
>
> pred.data has 150 lines and 3 columns.
>
> Thanks for your help,
>
> Denis Chabot
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html



From deepayan.sarkar at gmail.com  Mon Feb 13 22:23:49 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 13 Feb 2006 15:23:49 -0600
Subject: [R] contour lines for levelplot
In-Reply-To: <B28648E6-C2B1-4153-8F55-E7996F2BBEA5@web.de>
References: <B28648E6-C2B1-4153-8F55-E7996F2BBEA5@web.de>
Message-ID: <eb555e660602131323v5aebe1fmf1e40f1925fd7af1@mail.gmail.com>

I'm not sure what gave you the idea that there's a limit of 99 contour
lines, but no such limit is intended. You need to read the
documentation of panel.contourplot and use it in a panel function.
Hint:

library(lattice)

levelplot(volcano,
          panel = function(..., at, contour = FALSE, labels = NULL) {
              panel.levelplot(..., at = at, contour = contour, labels = labels)
              panel.contourplot(..., at = c(137, 141), contour = TRUE,
labels = FALSE)
          })

contour (and plot.new) are base graphics functions, they do not
(easily) mix with lattice functions (which are based on the grid
package).

Deepayan

On 2/12/06, Jan Marius Hofert <m_hofert at web.de> wrote:
> Hi,
>
> I would like to add contour lines to a (trellis/lattice-) levelplot.
> Sure, there is the "contour=TRUE" argument, but this uses
> "cuts=..." (which is usually chosen very high for my plots. I guess
> cuts=99 is the best you can do (?)) for plotting the contour lines.
> Furthermore, I do not like the numbering of the contour lines this
> way. Therefore, I tried to add a standard contour plot. There are 2
> problems to do this. First, as I would like to have the levelplot
> with a colorkey, the contour lines are plotted over the colorkey (see
> example code below). I could not fix this problem by changing the
> aspect argument of the levelplot call or by working with xlim and
> ylim in the contour plot function. Second, I am not sure if the
> contour lines added this way actually represent the points they
> should (e.g. does the contour line labeled with 0.5 really hit the
> points of this height?). So, is there a simple way of how to add the
> contour lines (of the contour function) to the levelplot this way? If
> not, is it possible to plot the levelplot with cuts=99 but only draw
> the contour lines (with the option "contour=TRUE" in the levelplot
> call) at specified points? Is it possible to tell the levelplot
> function (with cuts=99) to plot a specified number of contour lines
> (say, only to plot 10 contour lines in the whole existing range of z-
> values)?
>
> Thank you very much in advance
>
> Marius
> m_hofert at web.de
>
> example code:
>
> remove(list=objects())
> x.1<-rep(seq(0,1,by=0.04),each=26)
> x.2 <- 0.04*(0:25)
> y.1<-rep(x.2,26)
> y.2 <- 0.04*(0:25)
> z.1 <-x.1*y.1
> z.2<- matrix(unlist(z.1),ncol=26,byrow=TRUE)
> library(lattice) #for trellis-like graphical plots
> plot.new()
> levelplot(z.1~x.1*y.1,xlim=c(0,1),ylim=c(0,1),aspect=1,scales=list
> (relation="free",tick.number=6),cuts=99,colorkey=list(tick.number=6))
> contour(x.2,y.2,z.2,levels=seq(0,1,by=0.1),add=TRUE,col="black")



From ross at biostat.ucsf.edu  Mon Feb 13 22:24:11 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 13 Feb 2006 13:24:11 -0800
Subject: [R] Dictionaries with integer indices
Message-ID: <1139865851.19067.4.camel@iron.psg.net>

Some past threads have pointed out that lists can be used as
dictionaries storing data with an associated key (environments do this
too).

I have the seemingly simpler case with integer values for the
indices--however, the integers are not necessarily contiguous low
numbers.  My concern is that if id is 3000 then
d <- list()
d[[id]] <- some data

and later retrieval with
d[[id]]
is going to be wasteful (e.g., produce something with 3000 elements).

I could turn id into a string, but that seems pretty indirect.

Is there any problem with the naive scheme outlined above?  If so,
what's a good way around it?
-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062



From deepayan.sarkar at gmail.com  Mon Feb 13 22:37:07 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Mon, 13 Feb 2006 15:37:07 -0600
Subject: [R] the proper way to use panel functions in lattice package?
In-Reply-To: <e20b6da0602100809s12172237n76100f408066f191@mail.gmail.com>
References: <e20b6da0602100809s12172237n76100f408066f191@mail.gmail.com>
Message-ID: <eb555e660602131337u68833da2mea1333a554981e00@mail.gmail.com>

On 2/10/06, simon chou <sentientc at gmail.com> wrote:
> Hi,
> I was trying to stack a topographic map readed in from esri shapefile with a
> contour map and a vector map. However, the plotMap(maptools) and
> contourplot(lattice) do not seem to work well on top of each other. Here is
> part of my code.
>
>
>       xrange<-range(225000:350000)
>
>       yrange<-range(2685000:2810000)
>
>       basemap <- read.shape("Twn25_town_dxf_Polygon.shp")
>
>       plot.Map(basemap,xlim=xrange,ylim=yrange,fg=0,ol=8,xlab="",ylab="")
>
>
>
>       contourplot(var1.pred~x+y, spcgrid, aspect = "xy",label.style="align")
>
>
>
> I have tried to put panel function under plot.Map() but it gave some error
> message about  some argoument matches other arguments.
>
>
>
>       >plot.Map
> (basemap,xlim=xrange,ylim=yrange,fg=0,ol=8,xlab="",ylab="",panel=function(x,y){
>
>       +contourplot(var1.pred~x+y, spcgrid, aspect = "xy",label.style=
> "align")})
>
>       Error in plot.default(xylims$x,xylims$y, asp=1,type="n",...):
>
>         argument 9 matches multiple formal arguments
>
>
>
> I also tried to put plotMap() into contourplot()'s panel but plotMap cover
> up the conour. Maybe, there is something I miss in here.

Yes, namely that `standard graphics' (the 'graphics' package)
functions (like plotMap) don't (easily) work with grid graphics (the
'grid' package) which lattice uses. Unfortunately, I have no idea if
there are any grid compatible equivalents of plotMap.

> What went wrong there? Also, is there any diffeence between
> contourplot(lattice) and counterLine(base)? These 2 functions seem to give
> difference contour from the same data set. contourplot(lattice) seem to give
> better looking contour than contourLine() or contour().

contourplot uses contourLines (which I assume is what you meant)
internally, so any differences probably stem from the choice of
default arguments.

>
> ps. I krige 1700+ simulated observations into 4000+ regular spaced data to
> get contour.

Deepayan



From Felipe.Martinez at uclm.es  Mon Feb 13 23:04:33 2006
From: Felipe.Martinez at uclm.es (=?ISO-8859-15?Q?Felipe_Mart=EDnez-Pastor?=)
Date: Mon, 13 Feb 2006 23:04:33 +0100
Subject: [R] Discriminant analysis to select best treatment
In-Reply-To: <200602122214.50241.asaguiar@spsconsultoria.com>
References: <43EF7A06.5070702@uclm.es>
	<200602122214.50241.asaguiar@spsconsultoria.com>
Message-ID: <43F10271.9010508@uclm.es>

Hi.
I have found stepclass {klaR}, which is similar to what I was looking
for. However, I take note of your advice en stepwise variable selection.
Greetings.

Felipe

Alexandre Santos Aguiar wrote:
> Em Dom 12 Fev 2006 16:10, Felipe Mart??nez-Pastor escreveu:
>> --apparently-- not variable selection.
> 
> About automatic variable selection one should read this: 
> http://www.pitt.edu/~wpilib/statfaq/regrfaq.html
> 
> 

-- 
Ning??n investigador sin contrato.
Employment rights for Spanish junior researchers.
	http://www.precarios.org



From bret at tamu.edu  Mon Feb 13 23:09:22 2006
From: bret at tamu.edu (Bret Collier)
Date: Mon, 13 Feb 2006 16:09:22 -0600
Subject: [R] JRG Console Output
Message-ID: <s3f0af53.087@wfscgate.tamu.edu>

The obvious answer was options(width=).

Bret

>>> "Bret Collier" <bret at tamu.edu> 2/13/2006 12:24:22 PM >>>
All,
I had a question about the JGR console and whether or not I can
manipulate the location where line wrapping occurs.  I have searched
'JGR' in the R listserve archives and attempted to find console
manipulation on the JGR website to no avail and could use some
direction.

TIA, Bret

As an example, the below output wraps every 4th value, leaving about
2/3 of the console empty.

> rnorm(20, 50, 17)
 [1] 43.42240 39.94807  8.94276 15.19369
 [5] 82.56500 17.96678 80.58936 48.61693
 [9] 75.92249 71.86615 53.39025 24.08080
[13] 23.92690 35.96344 61.29200 63.37290
[17] 77.71882 56.54847 70.16172 51.61530

where the below increases the 'after decimal' range 1 unit and cuts
back to 3 values per line.

> rnorm(1000, 50, 17)
   [1]  64.805808  54.770722  46.552925
   [4]  34.371987  61.971183  37.327260
   [7]  60.403990  47.783683  51.744272
  [10]  32.671062  31.395127  69.085938
  [13]  77.554024  48.579639  48.111326
  [16]  44.994786  65.241722  65.852035
  [19]  53.254482  43.217719  30.255150


Reading in some data, the 'mydat' line extends across the console, but
the output is wrapped around again?

> mydat<-data.frame(ID, Year = factor(Year), Dayrelease, Agerelease,
Survivorship, Entry, Exit, Fate, Gender)
> mydat
       ID Year Dayrelease Agerelease
1   16240 1996        205         95
2   16319 1996        205         88
3   16378 1996        248        108
.
.
.
576  3094 2005        251        136
577  2667 2005        264        861
578  3035 2005        264        497
    Survivorship Entry Exit Fate Gender
1            164   205  369    1      0
2            140   205  345    1      0
3            100   248  348    1      0
4            204   241  445    1      0
5            227   219  446    1      0


>version
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    2.1            
year     2005           
month    12             
day      20             
svn rev  36812          
language R

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From he at hcp.med.harvard.edu  Mon Feb 13 23:11:30 2006
From: he at hcp.med.harvard.edu (He, Yulei )
Date: Mon, 13 Feb 2006 17:11:30 -0500
Subject: [R] bivariate normal distribution
Message-ID: <1EC991FAE7B1EC4B9B225DF7DF1F9F2908D3C1@MAILSERVER01.MED.HARVARD.EDU>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060213/42feda20/attachment.pl

From terrywschulz at comcast.net  Mon Feb 13 23:16:48 2006
From: terrywschulz at comcast.net (Terry W. Schulz)
Date: Mon, 13 Feb 2006 15:16:48 -0700
Subject: [R] Extracting Data form Simpleboot Output
Message-ID: <43F10550.3020402@comcast.net>

Hello,
I am new to R, so forgive my ignorance on what is probably simple.
I find package simpleboot quite useful for LOESS bootstrapping and 
generation of plots.
I want to calculate the standard error for x=60 of the 100 grid points 
and 50 bootstraps.
The code below gives the first fitted value.
How can I grab the other 49 values easily?
I could do it one at a time for 50 bootstraps, but this becomes tedious 
for say 2000 bootstraps.
Thanks for any help.

library(simpleboot)
library(bootstrap)
attach(cholost)
set.seed(13579)
lo <- loess(y ~ z, data=cholost, span=.5, degree=2, family="gaussian", 
method="loess")
lo.b <- loess.boot(lo, R=50, rows = TRUE, new.xpts = NULL, ngrid = 100, 
weights = NULL)
lo.b$boot.list$"1"$fitted[60]

-- 
Terry W. Schulz
Applied Statistician
1218 Pomegranate Lane
Golden, CO 80401

terrywschulz at comcast.net
(303) 526-1461



From apjaworski at mmm.com  Mon Feb 13 23:25:25 2006
From: apjaworski at mmm.com (apjaworski@mmm.com)
Date: Mon, 13 Feb 2006 16:25:25 -0600
Subject: [R] bivariate normal distribution
In-Reply-To: <1EC991FAE7B1EC4B9B225DF7DF1F9F2908D3C1@MAILSERVER01.MED.HARVARD.EDU>
Message-ID: <OFFAE51D6F.E4C9C1B3-ON86257114.007B1EB5-86257114.007B2DBD@mmm.com>

Check out the mvtnorm package.

Cheers,

Andy

__________________________________
Andy Jaworski
518-1-01
Process Laboratory
3M Corporate Research Laboratory
-----
E-mail: apjaworski at mmm.com
Tel:  (651) 733-6092
Fax:  (651) 736-3122


                                                                           
             "He, Yulei "                                                  
             <he at hcp.med.harva                                             
             rd.edu>                                                    To 
             Sent by:                  <r-help at stat.math.ethz.ch>          
             r-help-bounces at st                                          cc 
             at.math.ethz.ch                                               
                                                                   Subject 
                                       [R] bivariate normal distribution   
             02/13/2006 04:11                                              
             PM                                                            
                                                                           
                                                                           
                                                                           
                                                                           




Hi, there.



Does anyone know the R function for calculating the cdf of bivariate
normal distribution function?



Thanks.



Yulei




             [[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ross at biostat.ucsf.edu  Mon Feb 13 23:26:54 2006
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Mon, 13 Feb 2006 14:26:54 -0800
Subject: [R] Turning control back over to the terminal
Message-ID: <1139869614.19068.12.camel@iron.psg.net>

I'm invoking R from withing a shell script like this
R --no-save --no-restore --gui=none > `hostname`  2>&1 <<BYE
# various commands here
BYE

I would like to regain control from the invoking terminal at some point.
I tried source(stdin()) but got a syntax error, presumably stdin is the
little shell here snippet (the part between <<BYE
and BYE).

Is there some way to accomplish this?  I am trying to regain control
inside an R session that has been launched inside an MPI environment
(and I'm usually running inside emacs).  This is on a Mac OS X cluster.

I suppose there might be a way to do this with expect, but I'm hoping
for something simpler.  Potentially, I could make the script itself act
differently on the head node (the only one I want to debug right now),
including changing the redirection there.


-- 
Ross Boylan                                      wk:  (415) 514-8146
185 Berry St #5700                               ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
University of California, San Francisco
San Francisco, CA 94107-1739                     hm:  (415) 550-1062



From Scott.Waichler at pnl.gov  Mon Feb 13 23:42:26 2006
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Mon, 13 Feb 2006 14:42:26 -0800
Subject: [R] Package compiling problem in Linux
Message-ID: <7E4C06F49D6FEB49BE4B60E5FC92ED7A038CB714@pnlmse35.pnl.gov>

> The only way I can see this happening is if you installed a 
> ix86 RPM on a
> x86_86 system.  You can do that and R will run, but you will 
> not be able to build packages out of the box.

This is exactly what happened.  Now I know to use 'uname -a' to check
machine architecture first.  I was able to install the x86_64 version
and then packages successfully.

Thanks very much,
Scott Waichler



From rlevy at inf.ed.ac.uk  Mon Feb 13 23:51:26 2006
From: rlevy at inf.ed.ac.uk (Roger Levy)
Date: Mon, 13 Feb 2006 22:51:26 +0000
Subject: [R] indexing via a character matrix?
In-Reply-To: <Pine.LNX.4.64.0602131912400.17719@gannet.stats.ox.ac.uk>
References: <43F0CFEF.3070900@inf.ed.ac.uk>
	<Pine.LNX.4.64.0602131912400.17719@gannet.stats.ox.ac.uk>
Message-ID: <43F10D6E.9020805@inf.ed.ac.uk>

Prof Brian Ripley wrote:
> On Mon, 13 Feb 2006, Roger Levy wrote:
> 
>> Hi,
>>
>> Is it possible to index via a character matrix?  For example, I would
>> like to do the following:
>>
>> cont.table <- table(df1$A,df1$B) # df1 a data frame with factors A and B
>> cont.table[cbind(df2$A,df2$B)]   # df2 a smaller data frame with some
>>                                  # pairings of values for A and B
>>
>> but the second step does not work -- I guess that matrices to be used
>> for indexing this way must be numeric.  Is there a way to index multiple
> 
> Numeric or logical.
> 
>> character tuples out of a contingency table without resorting to writing
>> loops?
> 
> What are you trying to do here?  One possibility is that you meant
> 
> comt.table[df2$A, df2$B]
> 
> and another is
> 
> ind1 <- match(df2$A, df1$A)
> ind2 <- match(df2$B, df1$B)
> cont.table[cbind(ind1, ind2)]
> 
> and I am not certain which.
> 

Hmm, I think neither one is what I wanted.  After thinking more about 
it, I think what I would need is

ind1 <- match(df2$A,levels(df1$A))
ind2 <- match(df2$B,levels(df2$B))
cont.table[cbind(ind1,ind2)]

Does this make sense?  Is there a more natural way to express this?

Many thanks,

Roger



From ihok at hotmail.com  Fri Feb 10 17:40:15 2006
From: ihok at hotmail.com (Jack Tanner)
Date: Fri, 10 Feb 2006 11:40:15 -0500
Subject: [R] latent class modle for rater agreement
In-Reply-To: <43EBB498.A55ED707@uhnres.utoronto.ca>
References: <43EBB498.A55ED707@uhnres.utoronto.ca>
Message-ID: <dsiflf$k5m$1@sea.gmane.org>

Lisa Wang wrote:
> I would like to test the agreement amongst 6 raters for nominal data on
> a scale from 1-4, and conduct a latent class analysis in R. How should
> the data be formatted and what code should I use?

This kind of agreement test seems to call for Krippendorf's alpha. See 
http://www.asc.upenn.edu/usr/krippendorff/webreliability2.pdf



From joseclaudio.faria at terra.com.br  Tue Feb 14 01:35:47 2006
From: joseclaudio.faria at terra.com.br (Jose Claudio Faria)
Date: Mon, 13 Feb 2006 21:35:47 -0300
Subject: [R] ANOVA: Help with SSQ decomposition and contrasts
Message-ID: <43F125E3.90506@terra.com.br>

# Dear R list,
#
# A have a doubt about SSQ decomposition and contrasts with ANOVAs.
# So, I would like a tip from more advanced R users.

# Below my data, the basic script and my doubts:

# Data
r   = paste('r', gl(3, 8), sep='')
e   = paste('e', rep(gl(2, 4), 3), sep='')
tra = sort(paste('t', rep(1:6, 4), sep=''))
y   = c(26.2, 26.0, 25.0, 25.4, 24.8, 24.6, 26.7, 25.2,
         25.7, 26.3, 25.1, 26.4, 19.6, 21.1, 19.0, 18.6,
         22.8, 19.4, 18.8, 19.2, 19.8, 21.4, 22.8, 21.3)
dF  = data.frame(r, e, tra, y)

# Graphic
par(mfrow=c(2,1))
interaction.plot(dF$r, dF$e, dF$y,
                  col = 'blue', ylab = 'Y', xlab = 'R')

interaction.plot(dF$e, dF$r, dF$y,
                  col = 'blue', ylab = 'Y', xlab = 'R')

# ANOVAs
av0 = aov(y ~ tra, data=dF)
summary(av0)

av1 = aov(y ~ r*e, data=dF)
summary(av1)

av2 = aov(y ~ r/e, data=dF)
e_r = summary(av2, split = list('r:e' = list(
               'e1 vs e2/r1' = 1, 'e1 vs e2/r2' = 2, 'e1 vs e2/r3' = 3)))
e_r

av3 = aov(y ~ e/r, data=dF)
r_e = summary(av3, split = list('e:r' = list(
              'r/e1' = c(1,3), 'r/e2' = c(2,4))))
r_e

# My Doubts

# a) How to make SSQ decomposition to complete the ANOVA below?

#                    Df  Sum Sq Mean Sq F value    Pr(>F)
# e                    1  19.082  19.082  14.875  0.001155
# e:r                  4 156.622  39.155  30.524 8.438e-08
#   e:r: r/e1          2  87.122  43.561  33.958 7.776e-07
#     r1 vs (r2, r3)   1       ?       ?       ?         ?
#     r2 vs r3         1       ?       ?       ?         ?
#   e:r: r/e2          2  69.500  34.750  27.090 3.730e-06
#     r1 vs (r2, r3)   1       ?       ?       ?         ?
#     r2 vs r3         1       ?       ?       ?         ?
# Residuals   18  23.090   1.283

# b) How to make SSQ decomposition to complete the ANOVA below?

#                    Df  Sum Sq Mean Sq F value    Pr(>F)
# e                    1  19.082  19.082  14.875  0.001155
# e:r                  4 156.622  39.155  30.524 8.438e-08
#   e:r: r/e1          2  87.122  43.561  33.958 7.776e-07
#     r2 vs (r1, r3)   1       ?       ?       ?         ?
#     r1 vs r3         1       ?       ?       ?         ?
#   e:r: r/e2          2  69.500  34.750  27.090 3.730e-06
#     r2 vs (r1, r3)   1       ?       ?       ?         ?
#     r1 vs r3         1       ?       ?       ?         ?
# Residuals   18  23.090   1.283

# TIA,
-- 
Jose Claudio Faria
Brasil/Bahia/UESC/DCET
Estatistica Experimental/Prof. Adjunto
mails:
  joseclaudio.faria at terra.com.br
  joseclaudio.faria at oi.com.br
  jc_faria at uesc.br
  jc_faria at uol.com.br
tel: 73-3634.2779



From krcabrer at epm.net.co  Tue Feb 14 01:53:32 2006
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Mon, 13 Feb 2006 19:53:32 -0500
Subject: [R] Update problems of Rcmdr?
In-Reply-To: <440230C3.1030609@gmail.com>
References: <Pine.LNX.4.61.0601261347210.9567@echidna.fhcrc.org>
	<440230C3.1030609@gmail.com>
Message-ID: <43F12A0C.2050204@epm.net.co>

Hi R users:

I got this messages when I try to use the Rcmdr library, after
I make an update with update.packages() command.
I am using R221 in windows environment.

 > library(Rcmdr)
Loading required package: tcltk
Loading Tcl/Tk interface ... done
Loading required package: car
Error in parse(file, n, text, prompt) : syntax error in "*"
Error: .onAttach failed in 'attachNamespace'
Error: package/namespace load failed for 'Rcmdr'

Thank you for your help

Kenneth

From wuertz at itp.phys.ethz.ch  Tue Feb 14 02:04:36 2006
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Tue, 14 Feb 2006 01:04:36 +0000
Subject: [R] read.table
Message-ID: <43F12CA4.2050604@itp.phys.ethz.ch>



I have a file named "test.csv" with the following 3 lines:

%y-%m-%d;VALUE
1999-01-01;100
2000-12-31;999


 > read.table("test.csv", header = TRUE, sep = ";")

delivers:

   X.y..m..d VALUE
1 1999-01-01   100
2 2000-12-31   999


I would like to see the following ...

    %y-%m-%d VALUE
1 1999-01-01   100
2 2000-12-31   999


Note,

 > readLines("test.csv", 1)

delivers

[1] "%y-%m-%d;VALUE"


Is this possible ???


Thanks DW



From jholtman at gmail.com  Tue Feb 14 02:09:48 2006
From: jholtman at gmail.com (jim holtman)
Date: Mon, 13 Feb 2006 20:09:48 -0500
Subject: [R] read.table
In-Reply-To: <43F12CA4.2050604@itp.phys.ethz.ch>
References: <43F12CA4.2050604@itp.phys.ethz.ch>
Message-ID: <644e1f320602131709r7b2ef7ddre8a3fd5b46d8bf0b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060213/c24718e4/attachment.pl

From ggrothendieck at gmail.com  Tue Feb 14 02:11:50 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 13 Feb 2006 20:11:50 -0500
Subject: [R] read.table
In-Reply-To: <43F12CA4.2050604@itp.phys.ethz.ch>
References: <43F12CA4.2050604@itp.phys.ethz.ch>
Message-ID: <971536df0602131711i77880cb5o8ca0fa679e3a5f04@mail.gmail.com>

You can do it manually by reading in the headers separately:

headers <- read.table(test, header = FALSE, nrow = 1, sep = ";", as.is = TRUE)
read.table(test, header = FALSE, skip = 1, sep = ";", col.names = headers)

On 2/13/06, Diethelm Wuertz <wuertz at itp.phys.ethz.ch> wrote:
>
>
> I have a file named "test.csv" with the following 3 lines:
>
> %y-%m-%d;VALUE
> 1999-01-01;100
> 2000-12-31;999
>
>
>  > read.table("test.csv", header = TRUE, sep = ";")
>
> delivers:
>
>   X.y..m..d VALUE
> 1 1999-01-01   100
> 2 2000-12-31   999
>
>
> I would like to see the following ...
>
>    %y-%m-%d VALUE
> 1 1999-01-01   100
> 2 2000-12-31   999
>
>
> Note,
>
>  > readLines("test.csv", 1)
>
> delivers
>
> [1] "%y-%m-%d;VALUE"
>
>
> Is this possible ???
>
>
> Thanks DW
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From wuertz at itp.phys.ethz.ch  Tue Feb 14 02:41:11 2006
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Tue, 14 Feb 2006 01:41:11 +0000
Subject: [R] read.table
In-Reply-To: <Pine.LNX.4.64.0602131713340.2135@springer.berkeley.edu>
References: <43F12CA4.2050604@itp.phys.ethz.ch>
	<Pine.LNX.4.64.0602131713340.2135@springer.berkeley.edu>
Message-ID: <43F13537.2030708@itp.phys.ethz.ch>

Thanks a lot that works fine!

Next problem, if I would have my own package, and the file "test.csv"
would be located in the data directory

How to use the function data to get

 > data(test)

resulting in:

 > test

    %y-%m-%d VALUE
1 1999-01-01   100
2 2000-12-31   999


Again Thanks in advance Diethelm Wuertz




Phil Spector wrote:

> Look at the check.names= argument to read.table -- you want to set it
> to FALSE.  But rememeber that you'l have to put quotes around the name
> whenever you use it, as in x$'%y-%m-%d'
>
>                                        - Phil Spector
>                      Statistical Computing Facility
>                      Department of Statistics
>                      UC Berkeley
>                      spector at stat.berkeley.edu
>
> On Tue, 14 Feb 2006, Diethelm Wuertz wrote:
>
>>
>>
>> I have a file named "test.csv" with the following 3 lines:
>>
>> %y-%m-%d;VALUE
>> 1999-01-01;100
>> 2000-12-31;999
>>
>>
>> > read.table("test.csv", header = TRUE, sep = ";")
>>
>> delivers:
>>
>>   X.y..m..d VALUE
>> 1 1999-01-01   100
>> 2 2000-12-31   999
>>
>>
>> I would like to see the following ...
>>
>>    %y-%m-%d VALUE
>> 1 1999-01-01   100
>> 2 2000-12-31   999
>>
>>
>> Note,
>>
>> > readLines("test.csv", 1)
>>
>> delivers
>>
>> [1] "%y-%m-%d;VALUE"
>>
>>
>> Is this possible ???
>>
>>
>> Thanks DW
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>



From spencer.graves at pdf.com  Tue Feb 14 02:45:20 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 13 Feb 2006 17:45:20 -0800
Subject: [R] glmmPQL and random effects
In-Reply-To: <6782.143.169.45.37.1139593981.squirrel@www.unileon.es>
References: <6782.143.169.45.37.1139593981.squirrel@www.unileon.es>
Message-ID: <43F13630.2050605@pdf.com>

	  With repeated measures, you will want to use the "correlation" 
argument in "glmmPQL".  For help with how to do that, you need to know 
that "glmmPQL" calls "lme" repeatedly.  Therefore, if you have any 
trouble using it, I suggest you consult Pinheiro and Bates (2000) 
Mixed-Effects Models in S and S-PLUS (Springer).  Over the past five 
years, I may have consulted this book more frequently than any other, 
second only perhaps to Venables and Ripley (2002) Modern Applied 
Statistics with S, 4th ed. (Springer).  If you don't have these books, I 
suggest you consider purchasing them -- and / or recommending to your 
university library that they obtain copies.  I see on 
"http://www.unileon.es/servicios/unileoncat/acquire_web_spi.htm" that 
they invite "Sugerencias de Adquisiti??n".

	  If you can't get "glmmPQL" to work with your favorite model, I 
suggest you try passing the problem directly to "lme", possibly with 
random numbers for a response.  After I was confident I understood the 
"lme" syntax, I'd then return to "glmmPQL".

	  If you still have troubles, please submit another post -- after first 
the posting guide! "www.R-project.org/posting-guide.html".  I believe 
the people who more closely follow the procedure in the Posting Guide 
are on average rewarded by a faster rate of new knowledge acquisition. 
I have only anecdotes to support that conjecture, but anecdotes can be 
valuable in the absence of more systematic data collection and analysis.

	  Espero que estos commentos le ayude.

	  Spencer Graves
	
dbahrd at unileon.es wrote:

> Hello R users,
> 
> I am trying to run a model with a binary response variable (nesting
> success: 0 failure, 1 success) and 8 fixed terms. Nesting success was
> examined in 72 cases in 34 territories (TER) during a 6 study years.
> Territories are nested within 14 patches (PATCH). I want to run a model
> taking into account these nested factors and repeated observation. To do
> this, I assume that the best option is to use glmmPQL from MASS package.
> Am I wrong?
> 
> In glmmPQL, I have included the random terms as follow:
> random=~1|YEAR/PATCH/TER, but I am unclear if this syntax is right for
> this case (?).
> 
> I would greatly appreciate any help!
> 
> Regards,
> 
> Hugo
> 
> Hugo Robles
> Department of Animal Biology
> University of Le??n (Spain)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ucblack2 at hotmail.com  Tue Feb 14 02:59:31 2006
From: ucblack2 at hotmail.com (Court Arning)
Date: Tue, 14 Feb 2006 01:59:31 +0000
Subject: [R] Trying to save a *.jpg file from a PHP system call
Message-ID: <BAY103-F25894B07A3B566AF5543558C060@phx.gbl>


   This  is  my first time making a request so please feel free to school
   me  on how to improve on how to make an inquiry.  I am running R-1.9.1
   in  UNIX  via  a  PHP script with a system command to generate a *.jpg
   image  from  a list created by a perl script.  This R script runs fine
   when  run  from  a  Unix command line or through a system command from
   Perl.   In  my  debug  efforts  I  had PHP print out the last executed
   command  from  R.  The R script hangs on my jpeg(), touch(), and X11()
   commands in the script.  If I comment these out the rest of the script
   will  run  through.  I am running R under my html directory and I have
   ensured  all  permissions  are fully open.  I also set Sys.putenv() to
   the  machine  I  am  working  on.   Your constructive response will be
   appreciated.


   Thanks


From maj at stats.waikato.ac.nz  Tue Feb 14 03:07:52 2006
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Tue, 14 Feb 2006 15:07:52 +1300
Subject: [R] nonlinear model:  pseudo-design matrix
Message-ID: <43F13B78.2050601@stats.waikato.ac.nz>

Given a nonlinear model formula and a set of values for all the
parameters defining a point in parameter space, is there a neat way to
extract the pseudodesign matrix of the model at the point? That is the
matrix of partial derivatives of the fitted values w.r.t. the parameters
evaluated at the point.

(I have figured out how to extract the gradient information from an nls 
fitted model using the nlsModel part, but I wish to implement a score 
test, so I need to be able to extract the information at points other 
than the mle.)

Thanks, Murray Jorgensen
-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441    Mobile 021 1395 862



From jfox at mcmaster.ca  Tue Feb 14 03:36:45 2006
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 13 Feb 2006 21:36:45 -0500
Subject: [R] Update problems of Rcmdr?
In-Reply-To: <43F12A0C.2050204@epm.net.co>
Message-ID: <20060214023643.KOZP18394.tomts5-srv.bellnexxia.net@JohnDesktop8300>

Dear Kenneth,

After just running update.packages() myself, I can't duplicate this error
(using R 2.2.1 under Win XP). 

Can you provide a little more information? Are any but the standard packages
loaded when you issue the library(Rcmdr) command? Have you made any
modifications to a startup file, such as Rprofile.site?

I'm sorry that I can't offer any additional suggestions at this point.

John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Kenneth Cabrera
> Sent: Monday, February 13, 2006 7:54 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Update problems of Rcmdr?
> Importance: High
> 
> Hi R users:
> 
> I got this messages when I try to use the Rcmdr library, 
> after I make an update with update.packages() command.
> I am using R221 in windows environment.
> 
>  > library(Rcmdr)
> Loading required package: tcltk
> Loading Tcl/Tk interface ... done
> Loading required package: car
> Error in parse(file, n, text, prompt) : syntax error in "*"
> Error: .onAttach failed in 'attachNamespace'
> Error: package/namespace load failed for 'Rcmdr'
> 
> Thank you for your help
> 
> Kenneth
>



From adrian_d at eskimo.com  Tue Feb 14 04:05:27 2006
From: adrian_d at eskimo.com (Adrian Dragulescu)
Date: Mon, 13 Feb 2006 19:05:27 -0800 (PST)
Subject: [R] weird behavior of nsmall in format
Message-ID: <Pine.SUN.4.58.0602131852120.25515@eskimo.com>



>From the help page of format, nsmall should control the number of digits.

>      format(0.123456789, nsmall = 10)
[1] "0.1234567890"
>      format(0.123456789, nsmall = 1)
[1] "0.1234568"
>      format(0.123456789, nsmall = 2)
[1] "0.1234568"
>      format(0.123456789, nsmall = 8)
[1] "0.12345679"

It adds zeros fine but for format(0.123456789, nsmall = 1) I want the
result to be 0.1.

I want to format numbers with a fixed number of digits.  A combination of
round and format + nsmall does the job.  sprintf will do it too, but I
wondered if the current implementation of nsmall in format is correct.

Thanks,

Adrian



From quin.wills at googlemail.com  Tue Feb 14 04:18:00 2006
From: quin.wills at googlemail.com (Quin Wills)
Date: Tue, 14 Feb 2006 03:18:00 -0000
Subject: [R] How to access values returned by R functions (to put into
	vectors)?
Message-ID: <000101c63115$43c7f550$0fae01a3@notebookquin>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060214/3c8211ab/attachment.pl

From spencer.graves at pdf.com  Tue Feb 14 05:01:21 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 13 Feb 2006 20:01:21 -0800
Subject: [R] Lmer with weights
In-Reply-To: <43ED2146.3020201@bfro.uni-lj.si>
References: <43ED2146.3020201@bfro.uni-lj.si>
Message-ID: <43F15611.9090801@pdf.com>

	  Will your data support using "lme" in the 'nlme' package?  If yes, I 
suggest you switch.  This is consistent with a response given recently 
by Doug Bates to a crudely related question 
(http://finzi.psych.upenn.edu/R/Rhelp02a/archive/68340.html).

	  You probably know that "lmer" and associated software are Doug Bates' 
development platform.  There have been recent email exchanges on 
problems with weights in "lmer".  RSiteSearch("lmer with weights") and 
RSiteSearch("weights in lmer") both preduced the same 30 hits.  On 31 
Jan. 2006, Patrick Connolly reported, "I suspect the weights argument is 
not having any effect." 
(http://finzi.psych.upenn.edu/R/Rhelp02a/archive/69397.html)  I couldn't 
find any replies in the R-help archives, but my reply of 3 Feb. is 
copied below.  If you would like further help from this list, please 
submit another question.

	  hope this helps.
	  spencer graves	

##############################
	  I agree:  The lmer weights argument seems not to have any
effect.  To check this, I modified the first example in the "lmer" 
documentation as follows:

Sleep <- sleepstudy
Sleep$wts <- 1:180
(fm1 <- lmer(Reaction ~ Days + (Days|Subject), Sleep))
(fm1w <- lmer(Reaction ~ Days + (Days|Subject),
                      weights=wts, Sleep))

	  The numbers from both seemed to be the same.  To try to help
diagnose this, I listed "lmer", and found that it consisted of a call to
"standardGeneric".  Then 'getMethods("lmer")' listed only one "method"
for the case where the argument "formula" had class "formula".  I tried
to trace this further, e.g., by giving it a different name and using
"debug".  After being stopped a couple of time by functions hidden in
the "Matrix" namespace, I gave up.
	
############################
Gregor Gorjanc wrote:

> Hello!
> 
> I would like to use lmer() to fit data, which are some estimates and 
> their standard errors i.e kind of a "meta" analysis. I wonder if weights 
> argument is the right one to use to include uncertainty (standard 
> errors) of "data" into the model. I would like to use lmer(), since I 
> would like to have a "freedom" in modeling, if this is at all possible.
> 
> For example we can take schools data by Gelman from R2WinBUGS package. 
> As you can see bellow use of weights argument did not had influence on 
> results.
> 
> I do not know if my specification of weights i.e. 1 / sd^2 is ok. Under 
> least squares one minimizes sum(e^2_i) or sum(w_i * e^2_i) with weighted 
> LS. If I consider that \sigma_i represents uncertainty in my "data" then 
> e'_i = e_i / \sigma_i and we minimize sum(e'^2_i) = sum((e_i / 
> \sigma_i)^2) = sum(e_i * \sigma^-2_i). Therefore weights i.e. w_i are 
> equal to 1 / \sigma^2_i.
> 
> Can anyone help me with this issue?
> 
> Thank you very much!
> 
>  > library("R2WinBUGS")
>  > data(schools)
>  > schools
>  > attach(schools)
>  >
>  > ## Fit simple model without "weights"
>  > lmer(estimate ~ 1 + (1 | school))
> Linear mixed-effects model fit by REML
> Formula: estimate ~ 1 + (1 | school)
>      AIC    BIC  logLik MLdeviance REMLdeviance
>   58.882 59.041 -27.441     59.278       54.882
> Random effects:
>   Groups   Name        Variance Std.Dev.
>   school   (Intercept) 80.4     8.97
>   Residual             30.1     5.49
> # of obs: 8, groups: school, 8
> 
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)     8.82       3.72    2.37
> 
>  > ## Fit simple model with "weights"
>  > lmer(estimate ~ 1 + (1 | school), weights = ~ 1 / (sd^2))
> Linear mixed-effects model fit by REML
> Formula: estimate ~ 1 + (1 | school)
>      AIC    BIC  logLik MLdeviance REMLdeviance
>   58.882 59.041 -27.441     59.278       54.882
> Random effects:
>   Groups   Name        Variance Std.Dev.
>   school   (Intercept) 80.4     8.97
>   Residual             30.1     5.49
> # of obs: 8, groups: school, 8
> 
> Fixed effects:
>              Estimate Std. Error t value
> (Intercept)     8.82       3.72    2.37
>



From d.scott at auckland.ac.nz  Tue Feb 14 05:03:36 2006
From: d.scott at auckland.ac.nz (David Scott)
Date: Tue, 14 Feb 2006 17:03:36 +1300 (NZDT)
Subject: [R] read.table
In-Reply-To: <43F13537.2030708@itp.phys.ethz.ch>
References: <43F12CA4.2050604@itp.phys.ethz.ch>
	<Pine.LNX.4.64.0602131713340.2135@springer.berkeley.edu>
	<43F13537.2030708@itp.phys.ethz.ch>
Message-ID: <Pine.LNX.4.61.0602141644340.14782@stat12.stat.auckland.ac.nz>

On Tue, 14 Feb 2006, Diethelm Wuertz wrote:

> Thanks a lot that works fine!
>
> Next problem, if I would have my own package, and the file "test.csv"
> would be located in the data directory
>
> How to use the function data to get
>
> > data(test)
>
> resulting in:
>
> > test
>
>    %y-%m-%d VALUE
> 1 1999-01-01   100
> 2 2000-12-31   999
>
>

I think you might be stuck in a particular mindset about this.

Does the .csv file have to be called test.csv?

If not then if it is called data.csv say, you can have in your data 
directory a file test.R with the code:

read.table("data.csv", header = TRUE, sep = ";", check.names = FALSE)

Alternatively you can have the data in the file test.R, plus the code to 
read it in as desired. Creating a data structure and reading it back in 
with dput and dget is one way to do this.

See page 11 of the Writing R Extensions manual for the possible formats of 
files in the data directory:

"The data subdirectory is for additional data files the package makes 
available for loading using data(). Currently, data files can have one of 
three types as indicated by their extension: plain R code (.R or .r), 
tables (.tab, .txt, or .csv), or save() images (.RData or .rda). (All 
ports of R use the same binary (XDR) format and can read compressed 
images. Use images saved with save(, compress = TRUE) to save space.) Note 
that R code should be self-sufficient and not make use of extra 
functionality provided by the package, so that the data file can also be 
used without having to load the package."

David Scott



_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
 		The University of Auckland, PB 92019
 		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz


Graduate Officer, Department of Statistics



From ggrothendieck at gmail.com  Tue Feb 14 05:03:49 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 13 Feb 2006 23:03:49 -0500
Subject: [R] How to access values returned by R functions (to put into
	vectors)?
In-Reply-To: <000101c63115$43c7f550$0fae01a3@notebookquin>
References: <000101c63115$43c7f550$0fae01a3@notebookquin>
Message-ID: <971536df0602132003t33ceed30o5a8fd79896581391@mail.gmail.com>

Try this:

coef(A)

On 2/13/06, Quin Wills <quin.wills at googlemail.com> wrote:
> The question is general for all functions, but here is a specific example -
>
>
>
> # For the logistic regression of the following correlated variables:
>
> C <- c(457,   1371,   4113,  12339,  37017, 111051, 333153, 999459)
>
> E <- c(0.003858377, 0.014334578, 0.014092836, 0.737950754, 0.996371828,
> 0.997482379, 1.005569257, 0.994382856)
>
>
>
> #  The nls function:
>
> A = nls(E~(Em*C^p)/(C50^p + C^p), start = list(Em=0.8, p=3, C50=1e3))
>
>
>
> # Returns the following parameter estimates for Em, p and C50:
>
> Nonlinear regression model
>
>  model:  E ~ (Em * C^p)/(C50^p + C^p)
>
>   data:  parent.frame()
>
>          Em            p          C50
>
>   0.9989113    4.7957189 9934.6481397
>
>  residual sum-of-squares:  0.0002856567
>
>
>
> How do I access these parameter values from this output/function so that it
> would go into a vector c(Em,p,C50)?
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ronggui.huang at gmail.com  Tue Feb 14 05:03:53 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Tue, 14 Feb 2006 12:03:53 +0800
Subject: [R] How to access values returned by R functions (to put into
	vectors)?
In-Reply-To: <000101c63115$43c7f550$0fae01a3@notebookquin>
References: <000101c63115$43c7f550$0fae01a3@notebookquin>
Message-ID: <38b9f0350602132003k26b1b270s@mail.gmail.com>

06.02.14>whatyouwant<-coef(A)
06.02.14>whatyouwant
          Em            p          C50
   0.9989113    4.7957189 9934.6481222

2006/2/14, Quin Wills <quin.wills at googlemail.com>:
> The question is general for all functions, but here is a specific example -
>
>
>
> # For the logistic regression of the following correlated variables:
>
> C <- c(457,   1371,   4113,  12339,  37017, 111051, 333153, 999459)
>
> E <- c(0.003858377, 0.014334578, 0.014092836, 0.737950754, 0.996371828,
> 0.997482379, 1.005569257, 0.994382856)
>
>
>
> #  The nls function:
>
> A = nls(E~(Em*C^p)/(C50^p + C^p), start = list(Em=0.8, p=3, C50=1e3))
>
>
>
> # Returns the following parameter estimates for Em, p and C50:
>
> Nonlinear regression model
>
>   model:  E ~ (Em * C^p)/(C50^p + C^p)
>
>    data:  parent.frame()
>
>           Em            p          C50
>
>    0.9989113    4.7957189 9934.6481397
>
>  residual sum-of-squares:  0.0002856567
>
>
>
> How do I access these parameter values from this output/function so that it
> would go into a vector c(Em,p,C50)?
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--

Deparment of Sociology
Fudan University



From Scott.Waichler at pnl.gov  Tue Feb 14 06:11:28 2006
From: Scott.Waichler at pnl.gov (Waichler, Scott R)
Date: Mon, 13 Feb 2006 21:11:28 -0800
Subject: [R] Parallel computing in R for dummies--how to optimize an
	external model?
Message-ID: <7E4C06F49D6FEB49BE4B60E5FC92ED7A038CB86F@pnlmse35.pnl.gov>


I am trying to use the optimizing function genoud() with the snow
package on a couple of i686 machines running Redhat Linux WS4 .  I don't
know anything about PVM or MPI, so I just followed the directions in
snow and rgenoud for the simplest method and started a socket cluster.
My function fn for genoud involves updating an input file for a separate
numerical model with the latest parameter set from the optimizer,
running the (compiled) model on the input file with system(), and
processing the output including calculation of objective function.  The
whole process works on the localhost machine in one cpu, and I can see
that an R session is created in the second, non-localhost machine, but
it doesn't seem to be doing anything.  All of the model runs generated
by the application of genoud take place in the cpu.  What am I missing?
I can see where there would be a conflict in having multiple processors
trying to access the same system model input file at once, but I don't
see any indication of that type of problem.

Grateful for any help,

Scott Waichler
Pacific Northwest National Laboratory
scott.waichler at pnl.gov



From hodgess at gator.dt.uh.edu  Tue Feb 14 07:46:42 2006
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Tue, 14 Feb 2006 00:46:42 -0600
Subject: [R]  R and Power Point
Message-ID: <200602140646.k1E6kgWk005773@gator.dt.uh.edu>

Dear R People:

I'm using R in a time series class.  This class is being
broadcast live to 2 remote sites via closed circuit TV.

My people at the remote sites are having a terrible time
seeing the computer screen as it is broadcast(resolution issues).  I have
decided to put together Power Point slides for the teaching.

I am currently saving the R screen as WMF files and inserting them
into PowerPoint.  While this works, it seems that there
might be a simpler method.  

Does anyone have any suggestions for the Power Point, please?

Thanks so much!
R Version 2.2.1 Windows
Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu



From jan.danielsson at gmail.com  Tue Feb 14 07:48:26 2006
From: jan.danielsson at gmail.com (Jan Danielsson)
Date: Tue, 14 Feb 2006 07:48:26 +0100
Subject: [R] Inverse cumulative probability
Message-ID: <43F17D3A.2020708@gmail.com>

Hello all,

   (First of all, I'd like to thank all who replied to my previous
question. I have never encountered such a helpful community before.
Thanks for making a R so welcoming.)

   To calculate a quantile for normal distributions, one simply uses
qnorm(1-a). But if I would want to do the same for a t-test function,
how would I go about doing that? Is there a simple way to do it? (Yes, I
could look in a table, but it's the procedure I'm looking for, not the
values :-)

   I'm studying interference theory, and we got a few exercises to solve
in MiniTab. That was pretty simple, but now I want to solve them in R
instead (this is not a part of the course, so you won't be helping me
with my home work).

-- 
Kind Regards,
Jan Danielsson
Te audire non possum. Musa sapientum fixa est in aure.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 187 bytes
Desc: OpenPGP digital signature
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20060214/f75c5648/signature.bin

From arun.kumar.saha at gmail.com  Tue Feb 14 08:28:32 2006
From: arun.kumar.saha at gmail.com (Arun Kumar Saha)
Date: Tue, 14 Feb 2006 12:58:32 +0530
Subject: [R] how I can perform Multivariate Garch analysis in R
Message-ID: <d4c57560602132328v6ba96253re2488f0207906f6f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060214/8342b6cb/attachment.pl

From ripley at stats.ox.ac.uk  Tue Feb 14 08:35:27 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Feb 2006 07:35:27 +0000 (GMT)
Subject: [R] Correct (was 'weird') behavior of nsmall in format
In-Reply-To: <Pine.SUN.4.58.0602131852120.25515@eskimo.com>
References: <Pine.SUN.4.58.0602131852120.25515@eskimo.com>
Message-ID: <Pine.LNX.4.64.0602140730420.26457@gannet.stats.ox.ac.uk>

On Mon, 13 Feb 2006, Adrian Dragulescu wrote:

>> From the help page of format, nsmall should control the number of digits.

That's not a quote from the help page.

>>      format(0.123456789, nsmall = 10)
> [1] "0.1234567890"
>>      format(0.123456789, nsmall = 1)
> [1] "0.1234568"
>>      format(0.123456789, nsmall = 2)
> [1] "0.1234568"
>>      format(0.123456789, nsmall = 8)
> [1] "0.12345679"
>
> It adds zeros fine but for format(0.123456789, nsmall = 1) I want the
> result to be 0.1.
>
> I want to format numbers with a fixed number of digits.  A combination of
> round and format + nsmall does the job.  sprintf will do it too, but I
> wondered if the current implementation of nsmall in format is correct.

It is, but your reading of the help page is not.  The help page 
actually says

   digits: how many significant digits are to be used for numeric and
           complex 'x'.  The default, 'NULL', uses 'getOption(digits)'.
           This is a suggestion: enough decimal places will be used so
           that the smallest (in magnitude) number has this many
           significant digits, and also to satisfy 'nsmall'. (For the
           intepretation for complex numbers see 'signif'.)

   nsmall: number of digits which will always appear to the right of the
           decimal point in formatting real/complex numbers in
           non-scientific formats.  Allowed values are '0 <= nsmall <=
           20'.

Note the `always'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Feb 14 08:52:17 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Feb 2006 07:52:17 +0000 (GMT)
Subject: [R] Inverse cumulative probability
In-Reply-To: <43F17D3A.2020708@gmail.com>
References: <43F17D3A.2020708@gmail.com>
Message-ID: <Pine.LNX.4.64.0602140739380.26457@gannet.stats.ox.ac.uk>

On Tue, 14 Feb 2006, Jan Danielsson wrote:

> Hello all,
>
>   (First of all, I'd like to thank all who replied to my previous
> question. I have never encountered such a helpful community before.
> Thanks for making a R so welcoming.)
>
>   To calculate a quantile for normal distributions, one simply uses
> qnorm(1-a).

If a is small, it is better to use qnorm(a, lower.tail=FALSE).

> But if I would want to do the same for a t-test function,
> how would I go about doing that? Is there a simple way to do it? (Yes, I
> could look in a table, but it's the procedure I'm looking for, not the
> values :-)

qt(a, nu, lower.tail=FALSE),  assuming by `t-test function' you mean 
Student's t distribution on nu degrees of freedom (which might be n-1 or 
n-2 for a t test).

For more on this see `An Introduction to R', specifically section 8.1 in 
the HTML version I just looked at.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Roger.Bivand at nhh.no  Tue Feb 14 09:00:53 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 14 Feb 2006 09:00:53 +0100 (CET)
Subject: [R] the proper way to use panel functions in lattice package?
In-Reply-To: <eb555e660602131337u68833da2mea1333a554981e00@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0602140837100.30695-100000@reclus.nhh.no>

On Mon, 13 Feb 2006, Deepayan Sarkar wrote:

> On 2/10/06, simon chou <sentientc at gmail.com> wrote:
> > Hi,
> > I was trying to stack a topographic map readed in from esri shapefile with a
> > contour map and a vector map. However, the plotMap(maptools) and
> > contourplot(lattice) do not seem to work well on top of each other. Here is
> > part of my code.
> >
> >
> >       xrange<-range(225000:350000)
> >
> >       yrange<-range(2685000:2810000)
> >
> >       basemap <- read.shape("Twn25_town_dxf_Polygon.shp")
> >
> >       plot.Map(basemap,xlim=xrange,ylim=yrange,fg=0,ol=8,xlab="",ylab="")
> >
> >
> >
> >       contourplot(var1.pred~x+y, spcgrid, aspect = "xy",label.style="align")
> >
> >
> >
> > I have tried to put panel function under plot.Map() but it gave some error
> > message about  some argoument matches other arguments.
> >
> >
> >
> >       >plot.Map
> > (basemap,xlim=xrange,ylim=yrange,fg=0,ol=8,xlab="",ylab="",panel=function(x,y){
> >
> >       +contourplot(var1.pred~x+y, spcgrid, aspect = "xy",label.style=
> > "align")})
> >
> >       Error in plot.default(xylims$x,xylims$y, asp=1,type="n",...):
> >
> >         argument 9 matches multiple formal arguments
> >
> >
> >
> > I also tried to put plotMap() into contourplot()'s panel but plotMap cover
> > up the conour. Maybe, there is something I miss in here.
> 
> Yes, namely that `standard graphics' (the 'graphics' package)
> functions (like plotMap) don't (easily) work with grid graphics (the
> 'grid' package) which lattice uses. Unfortunately, I have no idea if
> there are any grid compatible equivalents of plotMap.

In `standard graphics' this is not a problem, and can be built up by just 
by using the add=TRUE argument (using contour). You may find that, with 
many polygon boundaries and contours, you need to set line widths and/or 
colours to differentiate what is representing what.

The lattice contourplot function also fills the inter-contour surfaces, so 
you would need to draw the polygon boundaries on top of the filled colour. 
As you can see from the example in the spatial graph gallery:

http://r-spatial.sourceforge.net/gallery/#fig20.R

this is far from easy, but with determination can be done (recall that 
lattice graphics are excellent for multiple plots conditioning on other 
variables, which is not the case here as far as you have explained). The 
example in the graph gallery is for kriged output, by the way.

Using the maptools package and sp classes (see R-News), I would say:

library(maptools)
col <- readShapePoly(system.file("shapes/columbus.shp", package="maptools")[1])
plot(col, border="grey")
library(akima) # to make a grid
crds <- coordinates(col)
contour(interp(crds[,1], crds[,2], col$CRIME), add=TRUE)

or for an image:

image(interp(crds[,1], crds[,2], col$CRIME), axes=FALSE)
plot(col, border="grey35", add=TRUE)

For these kinds of questions, the Task View (left panel on CRAN) called 
"Spatial" and the R-sig-geo mailing list might have helped.

> 
> > What went wrong there? Also, is there any diffeence between
> > contourplot(lattice) and counterLine(base)? These 2 functions seem to give
> > difference contour from the same data set. contourplot(lattice) seem to give
> > better looking contour than contourLine() or contour().
> 
> contourplot uses contourLines (which I assume is what you meant)
> internally, so any differences probably stem from the choice of
> default arguments.
> 
> >
> > ps. I krige 1700+ simulated observations into 4000+ regular spaced data to
> > get contour.
> 
> Deepayan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From Roger.Bivand at nhh.no  Tue Feb 14 09:24:06 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 14 Feb 2006 09:24:06 +0100 (CET)
Subject: [R] transforming data frame for use with persp
In-Reply-To: <89097FF2-B4A8-49E9-B7AE-4E18BBA4D3E4@globetrotter.net>
Message-ID: <Pine.LNX.4.44.0602140910240.30695-100000@reclus.nhh.no>

On Mon, 13 Feb 2006, Denis Chabot wrote:

> Hi,
> 
> This is probably documented, but I cannot find the right words or  
> expression for a search. My attempts failed.
> 
> I have a data frame of 3 vectors (x, y and z) and would like to  
> transform this so that I could use persp. Presently I have y-level  
> copies of each x level, and a z value for each x-y pair. I need 2  
> columns giving the possible levels of x and y, and then a  
> transformation of z from a long vector into a matrix of x-level rows  
> and y-level columns. How do I accomplish this?

Well, image() and friends have a rather strange representation, so it 
isn't obvious (see the help page:

     "Notice that 'image' interprets the 'z' matrix as a table of
     'f(x[i], y[j])' values, so that the x axis corresponds to row
     number and the y axis to column number, with column 1 at the
     bottom, i.e. a 90 degree counter-clockwise rotation of the
     conventional printed layout of a matrix.").

So:

Depth <- seq(40,220, 20)
Temp <- seq(-1, 6, 0.5)
My.data <- expand.grid(Depth=Depth, Temp=Temp)
predgam <- -0.5*My.data$Depth + 12.5*My.data$Temp + 8*rnorm(nrow(My.data))
pred.data <- data.frame(My.data, predgam)
library(lattice)
levelplot(predgam ~ Depth + Temp, pred.data) # for sanity check
z <- t(matrix(predgam, nrow=length(Temp), byrow=TRUE)) # see "Notice" 
image(Depth, Temp, z)
persp(Depth, Temp, z)

should do it, since the data are already in a regular grid.

> 
> In this example, I made a set of x and y values to get predictions  
> from a GAM, then combined them with the predictions into a data  
> frame. This is the one I'd like to transform as described above:
> 
> My.data <- expand.grid(Depth=seq(40,220, 20), Temp=seq(-1, 6, 0.5))
> predgam <- predict.gam(dxt.gam, My.data, type="response")
> pred.data <- data.frame(My.data, predgam)
> 
> pred.data has 150 lines and 3 columns.
> 
> Thanks for your help,
> 
> Denis Chabot
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From sell_mirage_ne at hotmail.com  Tue Feb 14 09:32:50 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Tue, 14 Feb 2006 02:32:50 -0600
Subject: [R] combine elements of a character vector into a character
Message-ID: <BAY110-F38C9566CD659E9E5495A76C7060@phx.gbl>

Hi R users

I have a simple question to ask

x <- c("a","b","c")
x
[1] "a" "b" "c"

I like to have "abc" instead of having "a" "b" "c"

I tried to use paste and other functions related to character.

Is there any function (command) that enable me to combine elements of a 
character vector into one character ?

Thanks



From tura at centroin.com.br  Tue Feb 14 10:30:10 2006
From: tura at centroin.com.br (Bernardo Rangel tura)
Date: Tue, 14 Feb 2006 06:30:10 -0300
Subject: [R] Fitdistr and MLE for parameter lambda of Poisson
 distribution
In-Reply-To: <43EC8889.9000607@bfro.uni-lj.si>
References: <43EC8889.9000607@bfro.uni-lj.si>
Message-ID: <7.0.0.16.2.20060214062650.02453db0@centroin.com.br>

At 09:35 AM 2/10/2006, Gregor Gorjanc wrote:
>Hello!
>
>I would like to get MLE for parameter lambda of Poisson distribution. I
>can use fitdistr() for this. After looking a bit into the code of this
>function I can see that value for lambda and its standard error is
>estimated via
>
>estimate <- mean(x)
>sds <- sqrt(estimate/n)
>
>Is this MLE? With my poor math/stat knowledge I thought that MLE for
>Poisson parameter is (in mixture of LaTeX code)
>
>l(\lambda|x) \propto \sum^n_{i=1}(-\lambda + x_iln(\lambda)).
>
>Is this really equal to (\sum^n_{i=1} x_i) / n
>
>--
>Lep pozdrav / With regards,
>      Gregor Gorjanc

Gregor,

If I understood your LaTeX You is rigth.

If you don??t know have a command wich make this for you:  fitdistr()

Look:


 > d<- rpois(50,5)
 > d
  [1]  6  4  6  4  5  5  4 11  7  5  7  3  5 
10  4  9  4  2  4  5  4  4  9  3 10
[26]  4  3  9  6  7  5  4  2  7  3  6  7  8  6  6  3  3  3  2  5  4  3  8  5  7
 > library(MASS)
 > fitdistr(d,"Poisson")
     lambda
   5.3200000
  (0.3261901)






[]s
Tura



From wp1 at tiscali.fr  Tue Feb 14 09:35:59 2006
From: wp1 at tiscali.fr (WPhantom)
Date: Tue, 14 Feb 2006 09:35:59 +0100
Subject: [R] A concrete type I/III Sum of square problem
Message-ID: <7.0.0.16.2.20060214091550.02578e88@univ-lille3.fr>

Hi R-help members,

I have read a lot in the Archive about the "Type I" vs "Type III" sum 
of square. I think I have read confusing post so
I want to have a clear idea of the problem.

Here is an example.
I have 3 groups of subjects of unequal sample size (G1 (n=7), G2 
(n=7), G3 (n=4)).
for Each subject I have 4 measures corresponding to  the crossing of 
2 factor  (A & B) of two levels each.

my dependant variable is X.

After reading a lot of tutorials on R I have tried the
summary(aov(X~GROUP*A*B+Error(SUJECT/(A*B) )

This results are with "type I SS".

What's wrong with these results ? Should I use type III SS and, if so 
how to enter my design in Anova (car package, I still have not the 
J.  Fox's book) ?
I have clearly not understood the difference between type I & III 
(with the limits of each approach).  A link to a good tutorial on 
this topic will help me a lot.



Sylvain CLEMENT
"Neuropsychology & Auditory Cognition Team"
Lille, FRANCE



From dimitris.rizopoulos at med.kuleuven.be  Tue Feb 14 09:38:49 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 14 Feb 2006 09:38:49 +0100
Subject: [R] combine elements of a character vector into a character
References: <BAY110-F38C9566CD659E9E5495A76C7060@phx.gbl>
Message-ID: <001501c63142$139a4e00$0540210a@www.domain>

probably you missed the 'collapse' argument of paste(); try this:

paste(x, collapse = "")


Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Taka Matzmoto" <sell_mirage_ne at hotmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, February 14, 2006 9:32 AM
Subject: [R] combine elements of a character vector into a character


> Hi R users
>
> I have a simple question to ask
>
> x <- c("a","b","c")
> x
> [1] "a" "b" "c"
>
> I like to have "abc" instead of having "a" "b" "c"
>
> I tried to use paste and other functions related to character.
>
> Is there any function (command) that enable me to combine elements 
> of a
> character vector into one character ?
>
> Thanks
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From wuertz at itp.phys.ethz.ch  Tue Feb 14 09:55:08 2006
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Tue, 14 Feb 2006 08:55:08 +0000
Subject: [R] combine elements of a character vector into a character
In-Reply-To: <BAY110-F38C9566CD659E9E5495A76C7060@phx.gbl>
References: <BAY110-F38C9566CD659E9E5495A76C7060@phx.gbl>
Message-ID: <43F19AEC.1050803@itp.phys.ethz.ch>

Taka Matzmoto wrote:

>Hi R users
>
>I have a simple question to ask
>
>x <- c("a","b","c")
>x
>[1] "a" "b" "c"
>  
>
Try

paste(x, collapse = "")


DW

>I like to have "abc" instead of having "a" "b" "c"
>
>I tried to use paste and other functions related to character.
>
>Is there any function (command) that enable me to combine elements of a 
>character vector into one character ?
>
>Thanks
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From gregor.gorjanc at bfro.uni-lj.si  Tue Feb 14 09:57:48 2006
From: gregor.gorjanc at bfro.uni-lj.si (Gregor Gorjanc)
Date: Tue, 14 Feb 2006 09:57:48 +0100
Subject: [R] Fitdistr and MLE for parameter lambda of Poisson
	distribution
In-Reply-To: <7.0.0.16.2.20060214062650.02453db0@centroin.com.br>
References: <43EC8889.9000607@bfro.uni-lj.si>
	<7.0.0.16.2.20060214062650.02453db0@centroin.com.br>
Message-ID: <43F19B8C.10407@bfro.uni-lj.si>

Bernardo Rangel tura wrote:
> At 09:35 AM 2/10/2006, Gregor Gorjanc wrote:
> 
>> Hello!
>>
>> I would like to get MLE for parameter lambda of Poisson distribution. I
>> can use fitdistr() for this. After looking a bit into the code of this
>> function I can see that value for lambda and its standard error is
>> estimated via
>>
>> estimate <- mean(x)
>> sds <- sqrt(estimate/n)
>>
>> Is this MLE? With my poor math/stat knowledge I thought that MLE for
>> Poisson parameter is (in mixture of LaTeX code)
>>
>> l(\lambda|x) \propto \sum^n_{i=1}(-\lambda + x_iln(\lambda)).
>>
>> Is this really equal to (\sum^n_{i=1} x_i) / n
>>
>> -- 
>> Lep pozdrav / With regards,
>>      Gregor Gorjanc
> 
> 
> Gregor,
> 
> If I understood your LaTeX You is rigth.
> 
> If you don??t know have a command wich make this for you:  fitdistr()
> 
> Look:
> 
> 
>> d<- rpois(50,5)
>> d
>  [1]  6  4  6  4  5  5  4 11  7  5  7  3  5 10  4  9  4  2  4  5  4  4 
> 9  3 10
> [26]  4  3  9  6  7  5  4  2  7  3  6  7  8  6  6  3  3  3  2  5  4  3 
> 8  5  7
>> library(MASS)
>> fitdistr(d,"Poisson")
>     lambda
>   5.3200000
>  (0.3261901)

Thanks for this, but I have already said in the first mail, that
fitdistr can help me with this. I was just "surprised" or knowledge
undernourished, that there is closed form solution for this. Look into
the source of fitdistr.

-- 
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.



From ripley at stats.ox.ac.uk  Tue Feb 14 09:58:38 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Feb 2006 08:58:38 +0000 (GMT)
Subject: [R] indexing via a character matrix?
In-Reply-To: <43F10D6E.9020805@inf.ed.ac.uk>
References: <43F0CFEF.3070900@inf.ed.ac.uk>
	<Pine.LNX.4.64.0602131912400.17719@gannet.stats.ox.ac.uk>
	<43F10D6E.9020805@inf.ed.ac.uk>
Message-ID: <Pine.LNX.4.64.0602140847270.27375@gannet.stats.ox.ac.uk>

On Mon, 13 Feb 2006, Roger Levy wrote:

> Prof Brian Ripley wrote:
>> On Mon, 13 Feb 2006, Roger Levy wrote:
>> 
>>> Hi,
>>> 
>>> Is it possible to index via a character matrix?  For example, I would
>>> like to do the following:
>>> 
>>> cont.table <- table(df1$A,df1$B) # df1 a data frame with factors A and B
>>> cont.table[cbind(df2$A,df2$B)]   # df2 a smaller data frame with some
>>>                                  # pairings of values for A and B
>>> 
>>> but the second step does not work -- I guess that matrices to be used
>>> for indexing this way must be numeric.  Is there a way to index multiple
>> 
>> Numeric or logical.
>> 
>>> character tuples out of a contingency table without resorting to writing
>>> loops?
>> 
>> What are you trying to do here?  One possibility is that you meant
>> 
>> comt.table[df2$A, df2$B]
>> 
>> and another is
>> 
>> ind1 <- match(df2$A, df1$A)
>> ind2 <- match(df2$B, df1$B)
>> cont.table[cbind(ind1, ind2)]
>> 
>> and I am not certain which.
>> 
>
> Hmm, I think neither one is what I wanted.  After thinking more about it, I 
> think what I would need is
>
> ind1 <- match(df2$A,levels(df1$A))
> ind2 <- match(df2$B,levels(df2$B))
> cont.table[cbind(ind1,ind2)]
>
> Does this make sense?  Is there a more natural way to express this?

Not really.

You said character, but you seem to have a factor (by the use of levels). 
It is the case that cont.table will have dims indexed by the levels of 
df1$A and df1$B, so perhaps you want

ind1 <- match(df2$A,levels(df1$A))
ind2 <- match(df2$B,levels(df1$B))
cont.table[cbind(ind1,ind2)]

That gives you a vector along rows of df2 giving the count of that A,B
combination in df1 (provide all such occur).  If some might not occur,
use matchdf2$A,levels(df1$A), NA) etc.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From xmeng at capitalbio.com  Tue Feb 14 10:41:55 2006
From: xmeng at capitalbio.com (XinMeng)
Date: Tue, 14 Feb 2006 17:41:55 +0800
Subject: [R] about list
Message-ID: <339910115.11332@capitalbio.com>

Hello sir:
A question about the usage of list:

The data of a list:

[[1]]
      genename  comp      diff       lwr       upr        p.adj
g2-g1  NewU1-R g2-g1 -242.6667 -337.9602 -147.3732 1.754308e-04
g3-g1  NewU1-R g3-g1 -266.6667 -361.9602 -171.3732 8.869357e-05
g4-g1  NewU1-R g4-g1  440.6667  345.3732  535.9602 2.055929e-06

[[2]]
      genename  comp      diff       lwr        upr        p.adj
g2-g1  NewU1-R g2-g1 -242.6667 -337.9602 -147.37315 1.754308e-04
g3-g2  NewU1-R g3-g2  -24.0000 -119.2935   71.29352 8.497181e-01
g4-g2  NewU1-R g4-g2  683.3333  588.0398  778.62685 4.785440e-08

[[3]]
      genename  comp      diff       lwr        upr        p.adj
g3-g1  NewU2-R g3-g1 -266.6667 -361.9602 -171.37315 8.869357e-05
g3-g2  NewU2-R g3-g2  -24.0000 -119.2935   71.29352 8.497181e-01
g4-g3  NewU2-R g4-g3  707.3333  612.0398  802.62685 3.713499e-08

[[4]]
      genename  comp     diff      lwr      upr        p.adj
g4-g1  NewU2-R g4-g1 440.6667 345.3732 535.9602 2.055929e-06
g4-g2  NewU2-R g4-g2 683.3333 588.0398 778.6268 4.785440e-08
g4-g3  NewU2-R g4-g3 707.3333 612.0398 802.6268 3.713499e-08


Actually, [[1]] and [[2]] are from the same group, [[3]] and [[4]] are from the same group.
And how can I arrange [[1]] [[2]] together(the same as [[3]] and [[4]])?
In other words,the result I want is:

group1
      genename  comp      diff       lwr       upr        p.adj
g2-g1  NewU1-R g2-g1 -242.6667 -337.9602 -147.3732 1.754308e-04
g3-g1  NewU1-R g3-g1 -266.6667 -361.9602 -171.3732 8.869357e-05
g4-g1  NewU1-R g4-g1  440.6667  345.3732  535.9602 2.055929e-06


group1
      genename  comp      diff       lwr        upr        p.adj
g2-g1  NewU1-R g2-g1 -242.6667 -337.9602 -147.37315 1.754308e-04
g3-g2  NewU1-R g3-g2  -24.0000 -119.2935   71.29352 8.497181e-01
g4-g2  NewU1-R g4-g2  683.3333  588.0398  778.62685 4.785440e-08


group2
      genename  comp      diff       lwr        upr        p.adj
g3-g1  NewU2-R g3-g1 -266.6667 -361.9602 -171.37315 8.869357e-05
g3-g2  NewU2-R g3-g2  -24.0000 -119.2935   71.29352 8.497181e-01
g4-g3  NewU2-R g4-g3  707.3333  612.0398  802.62685 3.713499e-08


group2
      genename  comp     diff      lwr      upr        p.adj
g4-g1  NewU2-R g4-g1 440.6667 345.3732 535.9602 2.055929e-06
g4-g2  NewU2-R g4-g2 683.3333 588.0398 778.6268 4.785440e-08
g4-g3  NewU2-R g4-g3 707.3333 612.0398 802.6268 3.713499e-08

Thanks!  

My best



From pburns at pburns.seanet.com  Tue Feb 14 10:46:00 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 14 Feb 2006 09:46:00 +0000
Subject: [R] how I can perform Multivariate Garch analysis in R
In-Reply-To: <d4c57560602132328v6ba96253re2488f0207906f6f@mail.gmail.com>
References: <d4c57560602132328v6ba96253re2488f0207906f6f@mail.gmail.com>
Message-ID: <43F1A6D8.2070902@pburns.seanet.com>

It is too late now, but this would have been better
asked on the R-sig-finance list.

On 2005-09-22 there was an answer to a question
on R-help "MGARCH estimation" that gave the address
of a package for BEKK estimation.

There is a working paper on the Burns Statistics website
that explains how to do multivariate GARCH estimation
when you only have software for univariate estimation.


Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Arun Kumar Saha wrote:

>Dear aDVISOR,
>Hope I am not disturbing you. Can you tell me how I can perform Multivariate
>Garch analysis in R. Also please, it is my humble request let me know some
>resource materials on Multivariate Garch analysis itself.
>
>Sincerely yours,
>
>
>
>--
>Arun Kumar Saha, M.Sc.[C.U.]
>S T A T I S T I C I A N    [Analyst]
>Transgraph Consulting [www.transgraph.com]
>Hyderabad, INDIA
>Contact # Home: +91-033-25558038
>               Office: +91-040-55755003
>               Mobile: 919849957010
>E-Mail: arun.kumar.saha at gmail.com
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From ligges at statistik.uni-dortmund.de  Tue Feb 14 11:03:27 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 14 Feb 2006 11:03:27 +0100
Subject: [R] about list
In-Reply-To: <339910115.11332@capitalbio.com>
References: <339910115.11332@capitalbio.com>
Message-ID: <43F1AAEF.4020605@statistik.uni-dortmund.de>

XinMeng wrote:

> Hello sir:
> A question about the usage of list:
> 
> The data of a list:
> 
> [[1]]
>       genename  comp      diff       lwr       upr        p.adj
> g2-g1  NewU1-R g2-g1 -242.6667 -337.9602 -147.3732 1.754308e-04
> g3-g1  NewU1-R g3-g1 -266.6667 -361.9602 -171.3732 8.869357e-05
> g4-g1  NewU1-R g4-g1  440.6667  345.3732  535.9602 2.055929e-06
> 
> [[2]]
>       genename  comp      diff       lwr        upr        p.adj
> g2-g1  NewU1-R g2-g1 -242.6667 -337.9602 -147.37315 1.754308e-04
> g3-g2  NewU1-R g3-g2  -24.0000 -119.2935   71.29352 8.497181e-01
> g4-g2  NewU1-R g4-g2  683.3333  588.0398  778.62685 4.785440e-08
> 
> [[3]]
>       genename  comp      diff       lwr        upr        p.adj
> g3-g1  NewU2-R g3-g1 -266.6667 -361.9602 -171.37315 8.869357e-05
> g3-g2  NewU2-R g3-g2  -24.0000 -119.2935   71.29352 8.497181e-01
> g4-g3  NewU2-R g4-g3  707.3333  612.0398  802.62685 3.713499e-08
> 
> [[4]]
>       genename  comp     diff      lwr      upr        p.adj
> g4-g1  NewU2-R g4-g1 440.6667 345.3732 535.9602 2.055929e-06
> g4-g2  NewU2-R g4-g2 683.3333 588.0398 778.6268 4.785440e-08
> g4-g3  NewU2-R g4-g3 707.3333 612.0398 802.6268 3.713499e-08
> 
> 
> Actually, [[1]] and [[2]] are from the same group, [[3]] and [[4]] are from the same group.
> And how can I arrange [[1]] [[2]] together(the same as [[3]] and [[4]])?
> In other words,the result I want is:

For example for a List L:

   list(L[1:2], L[3:4])

Uwe Ligges


> group1
>       genename  comp      diff       lwr       upr        p.adj
> g2-g1  NewU1-R g2-g1 -242.6667 -337.9602 -147.3732 1.754308e-04
> g3-g1  NewU1-R g3-g1 -266.6667 -361.9602 -171.3732 8.869357e-05
> g4-g1  NewU1-R g4-g1  440.6667  345.3732  535.9602 2.055929e-06
> 
> 
> group1
>       genename  comp      diff       lwr        upr        p.adj
> g2-g1  NewU1-R g2-g1 -242.6667 -337.9602 -147.37315 1.754308e-04
> g3-g2  NewU1-R g3-g2  -24.0000 -119.2935   71.29352 8.497181e-01
> g4-g2  NewU1-R g4-g2  683.3333  588.0398  778.62685 4.785440e-08
> 
> 
> group2
>       genename  comp      diff       lwr        upr        p.adj
> g3-g1  NewU2-R g3-g1 -266.6667 -361.9602 -171.37315 8.869357e-05
> g3-g2  NewU2-R g3-g2  -24.0000 -119.2935   71.29352 8.497181e-01
> g4-g3  NewU2-R g4-g3  707.3333  612.0398  802.62685 3.713499e-08
> 
> 
> group2
>       genename  comp     diff      lwr      upr        p.adj
> g4-g1  NewU2-R g4-g1 440.6667 345.3732 535.9602 2.055929e-06
> g4-g2  NewU2-R g4-g2 683.3333 588.0398 778.6268 4.785440e-08
> g4-g3  NewU2-R g4-g3 707.3333 612.0398 802.6268 3.713499e-08
> 
> Thanks!  
> 
> My best
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Feb 14 11:07:49 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 14 Feb 2006 11:07:49 +0100
Subject: [R] Trying to save a *.jpg file from a PHP system call
In-Reply-To: <BAY103-F25894B07A3B566AF5543558C060@phx.gbl>
References: <BAY103-F25894B07A3B566AF5543558C060@phx.gbl>
Message-ID: <43F1ABF5.4000704@statistik.uni-dortmund.de>

Court Arning wrote:

>    This  is  my first time making a request so please feel free to school
>    me  on how to improve on how to make an inquiry.  I am running R-1.9.1
>    in  UNIX  via  a  PHP script with a system command to generate a *.jpg
>    image  from  a list created by a perl script.  This R script runs fine
>    when  run  from  a  Unix command line or through a system command from
>    Perl.   In  my  debug  efforts  I  had PHP print out the last executed
>    command  from  R.  The R script hangs on my jpeg(), touch(), and X11()
>    commands in the script.  If I comment these out the rest of the script
>    will  run  through.  I am running R under my html directory and I have
>    ensured  all  permissions  are fully open.  I also set Sys.putenv() to
>    the  machine  I  am  working  on.   Your constructive response will be
>    appreciated.

I guess you cannot open an X11 device ...

Uwe Ligges


> 
> 
>    Thanks
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Feb 14 11:12:25 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 14 Feb 2006 11:12:25 +0100
Subject: [R] Extracting Data form Simpleboot Output
In-Reply-To: <43F10550.3020402@comcast.net>
References: <43F10550.3020402@comcast.net>
Message-ID: <43F1AD09.8020105@statistik.uni-dortmund.de>

Terry W. Schulz wrote:

> Hello,
> I am new to R, so forgive my ignorance on what is probably simple.
> I find package simpleboot quite useful for LOESS bootstrapping and 
> generation of plots.
> I want to calculate the standard error for x=60 of the 100 grid points 
> and 50 bootstraps.
> The code below gives the first fitted value.
> How can I grab the other 49 values easily?
> I could do it one at a time for 50 bootstraps, but this becomes tedious 
> for say 2000 bootstraps.
> Thanks for any help.
> 
> library(simpleboot)
> library(bootstrap)
> attach(cholost)
> set.seed(13579)
> lo <- loess(y ~ z, data=cholost, span=.5, degree=2, family="gaussian", 
> method="loess")
> lo.b <- loess.boot(lo, R=50, rows = TRUE, new.xpts = NULL, ngrid = 100, 
> weights = NULL)
> lo.b$boot.list$"1"$fitted[60]
> 


   sapply(lo.b$boot.list, function(x) x$fitted)

gives you the corresponding 100x50 matrix ...

Uwe Ligges



From Markus.Preisetanz at clientvela.com  Tue Feb 14 11:15:04 2006
From: Markus.Preisetanz at clientvela.com (Markus Preisetanz)
Date: Tue, 14 Feb 2006 11:15:04 +0100
Subject: [R] AID / Tree Analysis in R
Message-ID: <79799E69EA1DA246A51F983B5663BEA2CD34D5@server2.hq.clientvela.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060214/308bf840/attachment.pl

From sekhon at berkeley.edu  Tue Feb 14 12:02:26 2006
From: sekhon at berkeley.edu (Jasjeet Singh Sekhon)
Date: Tue, 14 Feb 2006 03:02:26 -0800
Subject: [R] Parallel computing in R for dummies--how to optimize an
	external	model?
In-Reply-To: <7E4C06F49D6FEB49BE4B60E5FC92ED7A038CB86F@pnlmse35.pnl.gov>
References: <7E4C06F49D6FEB49BE4B60E5FC92ED7A038CB86F@pnlmse35.pnl.gov>
Message-ID: <17393.47298.547406.294122@musil.localdomain>


Hi Scott,

It is difficult to debug your issue without more information.  Would
it be possible to email me code of a simple example?

Cheers,
Jas.

=======================================
Jasjeet S. Sekhon                     
                                      
Associate Professor             
Travers Department of Political Science
Survey Research Center          
UC Berkeley                     

http://sekhon.polisci.berkeley.edu/
V: 510-642-9974  F: 617-507-5524
=======================================


Waichler, Scott R writes:
 > 
 > I am trying to use the optimizing function genoud() with the snow
 > package on a couple of i686 machines running Redhat Linux WS4 .  I don't
 > know anything about PVM or MPI, so I just followed the directions in
 > snow and rgenoud for the simplest method and started a socket cluster.
 > My function fn for genoud involves updating an input file for a separate
 > numerical model with the latest parameter set from the optimizer,
 > running the (compiled) model on the input file with system(), and
 > processing the output including calculation of objective function.  The
 > whole process works on the localhost machine in one cpu, and I can see
 > that an R session is created in the second, non-localhost machine, but
 > it doesn't seem to be doing anything.  All of the model runs generated
 > by the application of genoud take place in the cpu.  What am I missing?
 > I can see where there would be a conflict in having multiple processors
 > trying to access the same system model input file at once, but I don't
 > see any indication of that type of problem.
 > 
 > Grateful for any help,
 > 
 > Scott Waichler
 > Pacific Northwest National Laboratory
 > scott.waichler at pnl.gov
 > 
 >



From ripley at stats.ox.ac.uk  Tue Feb 14 12:34:39 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Feb 2006 11:34:39 +0000 (GMT)
Subject: [R] AID / Tree Analysis in R
In-Reply-To: <79799E69EA1DA246A51F983B5663BEA2CD34D5@server2.hq.clientvela.net>
References: <79799E69EA1DA246A51F983B5663BEA2CD34D5@server2.hq.clientvela.net>
Message-ID: <Pine.LNX.4.64.0602141133490.32531@gannet.stats.ox.ac.uk>

On Tue, 14 Feb 2006, Markus Preisetanz wrote:

> I've been looking for a function that can perform a tree analysis, 
> similar to CHAID or QUEST. The key point is that in this case the 
> variables are not binary but nominal (10 different values), so "tree" 
> (from the tree package) won't work. Does anybody know help?

What makes you say that?  It comes with examples of categorical variables.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Feb 14 12:38:06 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Feb 2006 11:38:06 +0000 (GMT)
Subject: [R] A concrete type I/III Sum of square problem
In-Reply-To: <7.0.0.16.2.20060214091550.02578e88@univ-lille3.fr>
References: <7.0.0.16.2.20060214091550.02578e88@univ-lille3.fr>
Message-ID: <Pine.LNX.4.64.0602141136060.32531@gannet.stats.ox.ac.uk>

More to the point, you are confusing multistratum AOV with single-stratuam 
AOV.  For a good tutorial, see MASS4 (bibliographic information in the R 
FAQ).  For unbalanced data we suggest you use lme() instead.

On Tue, 14 Feb 2006, WPhantom wrote:

> Hi R-help members,
>
> I have read a lot in the Archive about the "Type I" vs "Type III" sum
> of square. I think I have read confusing post so
> I want to have a clear idea of the problem.
>
> Here is an example.
> I have 3 groups of subjects of unequal sample size (G1 (n=7), G2
> (n=7), G3 (n=4)).
> for Each subject I have 4 measures corresponding to  the crossing of
> 2 factor  (A & B) of two levels each.
>
> my dependant variable is X.
>
> After reading a lot of tutorials on R I have tried the
> summary(aov(X~GROUP*A*B+Error(SUJECT/(A*B) )
>
> This results are with "type I SS".
>
> What's wrong with these results ? Should I use type III SS and, if so
> how to enter my design in Anova (car package, I still have not the
> J.  Fox's book) ?
> I have clearly not understood the difference between type I & III
> (with the limits of each approach).  A link to a good tutorial on
> this topic will help me a lot.
>
>
>
> Sylvain CLEMENT
> "Neuropsychology & Auditory Cognition Team"
> Lille, FRANCE

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From singyee.ling at googlemail.com  Tue Feb 14 12:58:19 2006
From: singyee.ling at googlemail.com (singyee ling)
Date: Tue, 14 Feb 2006 11:58:19 +0000
Subject: [R] question about plotting survfit object on log-log scale
Message-ID: <ca33a9890602140358i473be9cax@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060214/4dae4554/attachment.pl

From sw283 at maths.bath.ac.uk  Tue Feb 14 13:08:11 2006
From: sw283 at maths.bath.ac.uk (Simon Wood)
Date: Tue, 14 Feb 2006 12:08:11 +0000 (GMT)
Subject: [R] Periodic B-spline surface
In-Reply-To: <20060206181602.67913.qmail@web34005.mail.mud.yahoo.com>
References: <20060206181602.67913.qmail@web34005.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.56.0602141205110.16841@bast.maths.bath.ac.uk>

There's a periodic cubic spline smoother built into package mgcv's gam
function (although it happens not to use a B-spline basis). This can be
used in tensor product smooth surfaces. e.g.

gam(y~te(x,z,bs=c("cc","cc")))

best,
Simon

> Hi..,
>
>      is there any funcrion in R to fit a periodic B-spline Surface
>
>   Harsh
>
>
> ---------------------------------
> Brings words and photos together (easily) with
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Feb 14 13:23:56 2006
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 14 Feb 2006 13:23:56 +0100 (CET)
Subject: [R] AID / Tree Analysis in R
In-Reply-To: <79799E69EA1DA246A51F983B5663BEA2CD34D5@server2.hq.clientvela.net>
References: <79799E69EA1DA246A51F983B5663BEA2CD34D5@server2.hq.clientvela.net>
Message-ID: <Pine.LNX.4.64.0602141316490.21657@artemis.imbe.med.uni-erlangen.de>


On Tue, 14 Feb 2006, Markus Preisetanz wrote:

> Dear Colleagues,
>
>
>
> I've been looking for a function that can perform a tree analysis, similar to CHAID or QUEST.

`ctree' in package `party' implements unbiased recursive partitioning in a 
way inspired by CHAID. The methodological details are in

@article{party2006,
     key = {566},
     author = {Torsten Hothorn and Kurt Hornik and Achim Zeileis},
     title = {Unbiased Recursive Partitioning: A Conditional Inference
              Framework},
     journal = {Journal of Computational and Graphical Statistics},
     year = 2006,
     note = {in press}
}

A preprint is available from
http://statmath.wu-wien.ac.at/~zeileis/papers/Hothorn+Hornik+Zeileis-2006.pdf

The package vignette explains the operational details.

HTH,

Torsten

> The key point is that in this case the variables are not binary but 
> nominal (10 different values), so "tree" (from the tree package) won't 
> work. Does anybody know help?
>
>
>
> Sincerely,
>
>
>
> ___________________
>
> Markus Preisetanz
>
> Consultant
>
>
>
> Client Vela GmbH
>
> Albert-Ro?haupter-Str. 32
>
> 81369 M?nchen
>
> fon:          +49 (0) 89 742 17-113
>
> fax:          +49 (0) 89 742 17-150
>
> mailto:markus.preisetanz at clientvela.com <mailto:markus.preisetanz at clientvela.com>
>
>
>
> Diese E-Mail enth?lt vertrauliche und/oder rechtlich gesch?tzte Informationen. Wenn Sie nicht der richtige Adressat sind oder diese E-Mail irrt?mlich erhalten haben, informieren Sie bitte sofort den Absender und vernichten Sie diese Mail. Das unerlaubte Kopieren sowie die unbefugte Weitergabe dieser E-Mail ist nicht gestattet.
>
> This e-mail may contain confidential and/or privileged infor...{{dropped}}
>
>

From rjohnson at ncifcrf.gov  Tue Feb 14 13:34:36 2006
From: rjohnson at ncifcrf.gov (Randall C Johnson [Contr.])
Date: Tue, 14 Feb 2006 07:34:36 -0500
Subject: [R] R and Power Point
In-Reply-To: <200602140646.k1E6kgWk005773@gator.dt.uh.edu>
Message-ID: <C017388C.762C%rjohnson@ncifcrf.gov>

Hello Erin,
Have you tried changing the font to a large, bold face font in the GUI
preferences? This may take care of the resolution issues without needing to
use power point, and give you the flexibility of a live R session.

Best,
Randy

On 2/14/06 1:46 AM, "Erin Hodgess" <hodgess at gator.dt.uh.edu> wrote:

> Dear R People:
> 
> I'm using R in a time series class.  This class is being
> broadcast live to 2 remote sites via closed circuit TV.
> 
> My people at the remote sites are having a terrible time
> seeing the computer screen as it is broadcast(resolution issues).  I have
> decided to put together Power Point slides for the teaching.
> 
> I am currently saving the R screen as WMF files and inserting them
> into PowerPoint.  While this works, it seems that there
> might be a simpler method.
> 
> Does anyone have any suggestions for the Power Point, please?
> 
> Thanks so much!
> R Version 2.2.1 Windows
> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Randall C Johnson
Bioinformatics Analyst
SAIC-Frederick, Inc (Contractor)
Laboratory of Genomic Diversity
NCI-Frederick, P.O. Box B
Bldg 560, Rm 11-85
Frederick, MD 21702
Phone: (301) 846-1304
Fax: (301) 846-1686
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From kjetilbrinchmannhalvorsen at gmail.com  Tue Feb 14 14:00:18 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Tue, 14 Feb 2006 09:00:18 -0400
Subject: [R] read.table
In-Reply-To: <43F13537.2030708@itp.phys.ethz.ch>
References: <43F12CA4.2050604@itp.phys.ethz.ch>	<Pine.LNX.4.64.0602131713340.2135@springer.berkeley.edu>
	<43F13537.2030708@itp.phys.ethz.ch>
Message-ID: <43F1D462.1030802@gmail.com>

Diethelm Wuertz wrote:
> Thanks a lot that works fine!
> 
> Next problem, if I would have my own package, and the file "test.csv"
> would be located in the data directory
> 
> How to use the function data to get
> 
>  > data(test)

Also put in the data subdirectory the file test.R
with the commands to read  test.csv

Kjetil

> 
> resulting in:
> 
>  > test
> 
>     %y-%m-%d VALUE
> 1 1999-01-01   100
> 2 2000-12-31   999
> 
> 
> Again Thanks in advance Diethelm Wuertz
> 
> 
> 
> 
> Phil Spector wrote:
> 
>> Look at the check.names= argument to read.table -- you want to set it
>> to FALSE.  But rememeber that you'l have to put quotes around the name
>> whenever you use it, as in x$'%y-%m-%d'
>>
>>                                        - Phil Spector
>>                      Statistical Computing Facility
>>                      Department of Statistics
>>                      UC Berkeley
>>                      spector at stat.berkeley.edu
>>
>> On Tue, 14 Feb 2006, Diethelm Wuertz wrote:
>>
>>>
>>> I have a file named "test.csv" with the following 3 lines:
>>>
>>> %y-%m-%d;VALUE
>>> 1999-01-01;100
>>> 2000-12-31;999
>>>
>>>
>>>> read.table("test.csv", header = TRUE, sep = ";")
>>> delivers:
>>>
>>>   X.y..m..d VALUE
>>> 1 1999-01-01   100
>>> 2 2000-12-31   999
>>>
>>>
>>> I would like to see the following ...
>>>
>>>    %y-%m-%d VALUE
>>> 1 1999-01-01   100
>>> 2 2000-12-31   999
>>>
>>>
>>> Note,
>>>
>>>> readLines("test.csv", 1)
>>> delivers
>>>
>>> [1] "%y-%m-%d;VALUE"
>>>
>>>
>>> Is this possible ???
>>>
>>>
>>> Thanks DW
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From rmason at esd.mun.ca  Tue Feb 14 14:17:27 2006
From: rmason at esd.mun.ca (Roger Mason)
Date: Tue, 14 Feb 2006 09:47:27 -0330
Subject: [R] reshaping data
In-Reply-To: <200602131759.k1DHxkdw029310@volta.gene.com> (Berton Gunter's
	message of "Mon, 13 Feb 2006 09:59:46 -0800")
References: <200602131759.k1DHxkdw029310@volta.gene.com>
Message-ID: <y65r766gjvc.fsf@minnie.esd.mun.ca>

Thank you Berton, I will look into that method.

Roger

Berton Gunter <gunter.berton at gene.com> writes:

> ?unlist
>
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>



From kjetilbrinchmannhalvorsen at gmail.com  Tue Feb 14 14:26:16 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Tue, 14 Feb 2006 09:26:16 -0400
Subject: [R] how I can perform Multivariate Garch analysis in R
In-Reply-To: <d4c57560602132328v6ba96253re2488f0207906f6f@mail.gmail.com>
References: <d4c57560602132328v6ba96253re2488f0207906f6f@mail.gmail.com>
Message-ID: <43F1DA78.8030101@gmail.com>

Arun Kumar Saha wrote:
> Dear aDVISOR,
> Hope I am not disturbing you. Can you tell me how I can perform Multivariate
> Garch analysis in R. Also please, it is my humble request let me know some
> resource materials on Multivariate Garch analysis itself.

You could try    help.search("garch")   or
RSiteSearch("garch")

But for me this only leads to univariate garch (at least two 
implementations).

Kjetil

> 
> Sincerely yours,
> 
> 
> 
> --
> Arun Kumar Saha, M.Sc.[C.U.]
> S T A T I S T I C I A N    [Analyst]
> Transgraph Consulting [www.transgraph.com]
> Hyderabad, INDIA
> Contact # Home: +91-033-25558038
>                Office: +91-040-55755003
>                Mobile: 919849957010
> E-Mail: arun.kumar.saha at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From michael.coeurdassier at univ-fcomte.fr  Tue Feb 14 14:52:56 2006
From: michael.coeurdassier at univ-fcomte.fr (=?ISO-8859-1?Q?Micha=EBl_Coeurdassier?=)
Date: Tue, 14 Feb 2006 14:52:56 +0100
Subject: [R] post-hoc comparisons following glmm
In-Reply-To: <43ED628B.1010503@pdf.com>
References: <43E8C7E9.4080000@univ-fcomte.fr> <43ED628B.1010503@pdf.com>
Message-ID: <43F1E0B8.4080107@univ-fcomte.fr>

Dear Mr Graves,

this seems work on my data. Thank you very much for your help.

Sincerely

Michael Coeurdassier

Spencer Graves a ??crit :
>       The following appears to be an answer to your question, though 
> I'd be pleased to receive critiques from others.  Since your example 
> is NOT self contained, I modified an example in the "glmmPQL" help file:
>
> (fit <- glmmPQL(y ~ factor(week)-1+trt, random = ~ 1 | ID,
> +                      family = binomial, data = bacteria))
> iteration 1
> iteration 2
> iteration 3
> iteration 4
> iteration 5
> iteration 6
> Linear mixed-effects model fit by maximum likelihood
>   Data: bacteria
>   Log-likelihood: -551.1184
>   Fixed: y ~ factor(week) - 1 + trt
>  factor(week)0  factor(week)2  factor(week)4  factor(week)6 
> factor(week)11
>      3.3459650      3.5262521      1.9102037      1.7645881      
> 1.7660845
>        trtdrug       trtdrug+
>     -1.2527642     -0.7570441
>
> Random effects:
>  Formula: ~1 | ID
>         (Intercept)  Residual
> StdDev:    1.426534 0.7747477
>
> Variance function:
>  Structure: fixed weights
>  Formula: ~invwt
> Number of Observations: 220
> Number of Groups: 50
> > anova(fit)
>              numDF denDF   F-value p-value
> factor(week)     5   166 10.821682  <.0001
> trt              2    48  1.889473  0.1622
> > (denDF.week <- anova(fit)$denDF[1])
> [1] 166
> > (denDF.week <- anova(fit)$denDF[1])
> [1] 166
> > (par.week <- fixef(fit)[1:5])
>  factor(week)0  factor(week)2  factor(week)4  factor(week)6 
> factor(week)11
>       3.345965       3.526252       1.910204       1.764588       
> 1.766085
> > (vc.week <- vcov(fit)[1:5, 1:5])
>                factor(week)0 factor(week)2 factor(week)4 factor(week)6
> factor(week)0      0.3351649     0.1799365     0.1705898     0.1694884
> factor(week)2      0.1799365     0.3709887     0.1683038     0.1684096
> factor(week)4      0.1705898     0.1683038     0.2655072     0.1655673
> factor(week)6      0.1694884     0.1684096     0.1655673     0.2674647
> factor(week)11     0.1668450     0.1665177     0.1616748     0.1638169
>                factor(week)11
> factor(week)0       0.1668450
> factor(week)2       0.1665177
> factor(week)4       0.1616748
> factor(week)6       0.1638169
> factor(week)11      0.2525962
> > CM <- array(0, dim=c(5*4/2, 5))
> > i1 <- 0
> > for(i in 1:4)for(j in (i+1):5){
> +   i1 <- i1+1
> +   CM[i1, c(i, j)] <- c(-1, 1)
> + }
> > CM
>       [,1] [,2] [,3] [,4] [,5]
>  [1,]   -1    1    0    0    0
>  [2,]   -1    0    1    0    0
>  [3,]   -1    0    0    1    0
>  [4,]   -1    0    0    0    1
>  [5,]    0   -1    1    0    0
>  [6,]    0   -1    0    1    0
>  [7,]    0   -1    0    0    1
>  [8,]    0    0   -1    1    0
>  [9,]    0    0   -1    0    1
> [10,]    0    0    0   -1    1
> > library(multcomp)
> > csimint(par.week, df=denDF.week, covm=vc.week,cmatrix=CM)
>
>     Simultaneous confidence intervals: user-defined contrasts
>
>     95 % confidence intervals
>
>       Estimate  2.5 % 97.5 %
>  [1,]    0.180 -1.439  1.800
>  [2,]   -1.436 -2.838 -0.034
>  [3,]   -1.581 -2.995 -0.168
>  [4,]   -1.580 -2.967 -0.193
>  [5,]   -1.616 -3.123 -0.109
>  [6,]   -1.762 -3.273 -0.250
>  [7,]   -1.760 -3.244 -0.277
>  [8,]   -0.146 -1.382  1.091
>  [9,]   -0.144 -1.359  1.070
> [10,]    0.001 -1.206  1.209
>
> > csimtest(par.week, df=denDF.week, covm=vc.week,cmatrix=CM)
>
>     Simultaneous tests: user-defined contrasts
>
> Contrast matrix:
>       [,1] [,2] [,3] [,4] [,5]
>  [1,]   -1    1    0    0    0
>  [2,]   -1    0    1    0    0
>  [3,]   -1    0    0    1    0
>  [4,]   -1    0    0    0    1
>  [5,]    0   -1    1    0    0
>  [6,]    0   -1    0    1    0
>  [7,]    0   -1    0    0    1
>  [8,]    0    0   -1    1    0
>  [9,]    0    0   -1    0    1
> [10,]    0    0    0   -1    1
>
> Adjusted P-Values
>
>       p adj
>  [1,] 0.011
>  [2,] 0.013
>  [3,] 0.014
>  [4,] 0.015
>  [5,] 0.020
>  [6,] 0.024
>  [7,] 0.985
>  [8,] 0.985
>  [9,] 0.985
> [10,] 0.997
> > sessionInfo()
> R version 2.2.1, 2005-12-20, i386-pc-mingw32
>
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     
> "datasets"
> [7] "base"
>
> other attached packages:
>   multcomp    mvtnorm       MASS    statmod       nlme
>    "0.4-8"    "0.7-2"   "7.2-24"    "1.2.4" "3.1-68.1"
>
>       If this does NOT answer your question (or even if it does), 
> PLEASE do read the posting guide! 
> "www.R-project.org/posting-guide.html".  I'd prefer not to have to 
> guess whether you would think the example I chose was relevant.
>
>       hope this helps,
>       spencer graves
>
> Micha??l Coeurdassier wrote:
>
>> Dear R community,
>>
>> I performed a generalized linear mixed model using glmmPQL (MASS 
>> library) to analyse my data i.e : y is the response with a poisson 
>> distribution, t and Trait are the independent variables which are 
>> continuous and categorical (3 categories C, M and F) respectively, 
>> ind is the random variable.
>>
>> mydata<-glmmPQL(y~t+Trait,random=~1|ind,family=poisson,data=tab)
>> Do you think it is OK?
>>
>> Trait is significant (p < 0.0001) and I would like to perform 
>> post-hoc comparisons  to check  where the difference among  Trait 
>> categories but I did not find  a solution  in R help list or others.
>>
>> Thank you in advance for your help
>>
>> Michael
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>



From wolfram at fischer-zim.ch  Tue Feb 14 14:56:06 2006
From: wolfram at fischer-zim.ch (Wolfram Fischer)
Date: Tue, 14 Feb 2006 14:56:06 +0100
Subject: [R] lattice: calling functions
Message-ID: <20060214135606.GA3185@s1x.local>

I defined three functions:

> fun0 <- function( x=1:5, y=1:5, ... ) xyplot( y ~ x, ... )

> fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, ... )
> fun2 <- function( ... ) xyplot( ... )

The call of fun0() works as expected.

The call of fun1() causes the following error:
    'Error in eval(expr, envir, enclos) : object "y" not found'

How should I define fun2 to avoid the error?

Thanks - Wolfram



From kubovy at virginia.edu  Tue Feb 14 15:08:12 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Tue, 14 Feb 2006 09:08:12 -0500
Subject: [R] R and Power Point
In-Reply-To: <200602140646.k1E6kgWk005773@gator.dt.uh.edu>
References: <200602140646.k1E6kgWk005773@gator.dt.uh.edu>
Message-ID: <D92BDCEF-EE65-498D-BE02-1780C2F438E6@virginia.edu>

On Feb 14, 2006, at 1:46 AM, Erin Hodgess wrote:
> I'm using R in a time series class. ... I have decided to put  
> together Power Point slides for the teaching. ... I am currently  
> saving the R screen as WMF files and inserting them into  
> PowerPoint.  While this works, it seems that there might be a  
> simpler method.

Hi Erin,

For presentations I use LaTeX with beamer.cls and Sweave to access R.  
The results are legible and attractive. The method is not simple at  
first, since you must understand how to use beamer.cls and Sweave.  
But once you're in production mode, it's a delight.

I'd be happy to share templates.
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From murdoch at stats.uwo.ca  Tue Feb 14 15:18:12 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 14 Feb 2006 09:18:12 -0500
Subject: [R] lattice: calling functions
In-Reply-To: <20060214135606.GA3185@s1x.local>
References: <20060214135606.GA3185@s1x.local>
Message-ID: <43F1E6A4.5050304@stats.uwo.ca>

On 2/14/2006 8:56 AM, Wolfram Fischer wrote:
> I defined three functions:
> 
>> fun0 <- function( x=1:5, y=1:5, ... ) xyplot( y ~ x, ... )
> 
>> fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, ... )
>> fun2 <- function( ... ) xyplot( ... )
> 
> The call of fun0() works as expected.
> 
> The call of fun1() causes the following error:
>     'Error in eval(expr, envir, enclos) : object "y" not found'
> 
> How should I define fun2 to avoid the error?

fun2 is fine, it's fun1 that has problems.  It is passing a formula 
through fun2 to xyplot without telling xyplot where to evaluate the 
arguments.  If you change it to

fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, data=enviroment(), ... )

it will tell xyplot to look in the current environment at the time of 
the call, i.e. the fun1 evaluation environment where x and y live.

Duncan Murdoch



From christian.bieli at unibas.ch  Tue Feb 14 15:24:23 2006
From: christian.bieli at unibas.ch (Christian Bieli)
Date: Tue, 14 Feb 2006 15:24:23 +0100
Subject: [R] How to handle large dataframes?
Message-ID: <43F1E817.5040006@unibas.ch>

Dear all

I imported a Stata .dta file with the read.dta-function from the 
foreign-package. The dataframe's dimensions are

 > dim(d.apc)
[1] 15806  1300

Importing needs up to 15 min and calculations with these data are rather 
slow  (although I subset the data before starting analyses).

My questions are:
1. Has someone experiences importing Stata files (alternatives to 
read.dta) ?
2. To my knowledge R should not have problems handling dataframes of 
this size. Is there something I can do after importing that makes data 
handling faster?

My hardware is up-to-date (Intel P4, 3 Ghz, 1 GB RAM) and I work on a 
Windows XP platform.
I am working on a Windows XP platform with R version 2.1 (all packages 
updated).

Thanks for your answers.
Christian

-- 
Christian Bieli, project assistant
Institute of Social and Preventive Medicine
University of Basel, Switzerland
Steinengraben 49
CH-4051 Basel
Tel.: +41 61 270 22 12
Fax:  +41 61 270 22 25
christian.bieli at unibas.ch
www.unibas.ch/ispmbs



From murdoch at stats.uwo.ca  Tue Feb 14 15:26:01 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 14 Feb 2006 09:26:01 -0500
Subject: [R] R and Power Point
In-Reply-To: <D92BDCEF-EE65-498D-BE02-1780C2F438E6@virginia.edu>
References: <200602140646.k1E6kgWk005773@gator.dt.uh.edu>
	<D92BDCEF-EE65-498D-BE02-1780C2F438E6@virginia.edu>
Message-ID: <43F1E879.2030101@stats.uwo.ca>

On 2/14/2006 9:08 AM, Michael Kubovy wrote:
> On Feb 14, 2006, at 1:46 AM, Erin Hodgess wrote:
>> I'm using R in a time series class. ... I have decided to put  
>> together Power Point slides for the teaching. ... I am currently  
>> saving the R screen as WMF files and inserting them into  
>> PowerPoint.  While this works, it seems that there might be a  
>> simpler method.
> 
> Hi Erin,
> 
> For presentations I use LaTeX with beamer.cls and Sweave to access R.  
> The results are legible and attractive. The method is not simple at  
> first, since you must understand how to use beamer.cls and Sweave.  
> But once you're in production mode, it's a delight.
> 
> I'd be happy to share templates.

Please put some up on the web somewhere!  I'm just learning beamer, and 
don't need it for R right now, but I'm sure I will eventually.

Duncan Murdoch

P.S.  How do I add page numbers to slides?  I see in the manual a 
section called "The Headline and Footline" that apparently tells me how 
to do it using an option "[page number]", but I don't see where to put that.



From ggrothendieck at gmail.com  Tue Feb 14 15:38:38 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 14 Feb 2006 09:38:38 -0500
Subject: [R] lattice: calling functions
In-Reply-To: <43F1E6A4.5050304@stats.uwo.ca>
References: <20060214135606.GA3185@s1x.local> <43F1E6A4.5050304@stats.uwo.ca>
Message-ID: <971536df0602140638t502239bdo949e6d0d20638ba@mail.gmail.com>

On 2/14/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 2/14/2006 8:56 AM, Wolfram Fischer wrote:
> > I defined three functions:
> >
> >> fun0 <- function( x=1:5, y=1:5, ... ) xyplot( y ~ x, ... )
> >
> >> fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, ... )
> >> fun2 <- function( ... ) xyplot( ... )
> >
> > The call of fun0() works as expected.
> >
> > The call of fun1() causes the following error:
> >     'Error in eval(expr, envir, enclos) : object "y" not found'
> >
> > How should I define fun2 to avoid the error?
>
> fun2 is fine, it's fun1 that has problems.  It is passing a formula
> through fun2 to xyplot without telling xyplot where to evaluate the
> arguments.  If you change it to
>
> fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, data=enviroment(), ... )
>
> it will tell xyplot to look in the current environment at the time of
> the call, i.e. the fun1 evaluation environment where x and y live.
>

Although this does seem to be how xyplot works, I think it indicates
there is a problem with it.

The help file for xyplot indicates that for the xyplot formula method
the default
environment is the caller environment whereas it ought to be the environment
of the formula:

    data: For the 'formula' method, a data frame containing values for
          any variables in the formula, as well as 'groups' and
          'subset' if applicable.  By default the environment where the
          function was called from is used.

For example, if we replace xyplot with lm it does work as expected:

   fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, ... )
   fun2 <- function( ... ) lm( ... )
   fun1()



From rdiaz at cnio.es  Tue Feb 14 15:38:00 2006
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Tue, 14 Feb 2006 15:38:00 +0100
Subject: [R] R, AMD Opteron 64, and Rmpi
Message-ID: <200602141538.00376.rdiaz@cnio.es>

Dear All,

I found Andy Liaw's suggestion about using a NUMA (instead of SMP) kernel when 
running R on amd64 with > 1 CPU

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/35109.html


A couple of questions:

1. Is this still the case with the newer dual-core opterons (e.g., the 275 et 
al., families) running Linux (kernel 2.6)?

2. How does this affect using Rmpi (and snow, papply, et al.) on multi-server 
clusters with > 1 CPU? If I understand correctly, and if the situation is 
what Andy described, if we use a SMP kernel we will suffer a within-node 
penalty in one of the Rmpi processes. Is this correct?

Thanks,

R.


-- 
Ram??n D??az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol??gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern??ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://ligarto.org/rdiaz
PGP KeyID: 0xE89B3462
(http://ligarto.org/rdiaz/0xE89B3462.asc)



**NOTA DE CONFIDENCIALIDAD** Este correo electr??nico, y en s...{{dropped}}



From murdoch at stats.uwo.ca  Tue Feb 14 15:50:39 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 14 Feb 2006 09:50:39 -0500
Subject: [R] lattice: calling functions
In-Reply-To: <971536df0602140638t502239bdo949e6d0d20638ba@mail.gmail.com>
References: <20060214135606.GA3185@s1x.local> <43F1E6A4.5050304@stats.uwo.ca>
	<971536df0602140638t502239bdo949e6d0d20638ba@mail.gmail.com>
Message-ID: <43F1EE3F.1020107@stats.uwo.ca>

On 2/14/2006 9:38 AM, Gabor Grothendieck wrote:
> On 2/14/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 2/14/2006 8:56 AM, Wolfram Fischer wrote:
>> > I defined three functions:
>> >
>> >> fun0 <- function( x=1:5, y=1:5, ... ) xyplot( y ~ x, ... )
>> >
>> >> fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, ... )
>> >> fun2 <- function( ... ) xyplot( ... )
>> >
>> > The call of fun0() works as expected.
>> >
>> > The call of fun1() causes the following error:
>> >     'Error in eval(expr, envir, enclos) : object "y" not found'
>> >
>> > How should I define fun2 to avoid the error?
>>
>> fun2 is fine, it's fun1 that has problems.  It is passing a formula
>> through fun2 to xyplot without telling xyplot where to evaluate the
>> arguments.  If you change it to
>>
>> fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, data=enviroment(), ... )
>>
>> it will tell xyplot to look in the current environment at the time of
>> the call, i.e. the fun1 evaluation environment where x and y live.
>>
> 
> Although this does seem to be how xyplot works, I think it indicates
> there is a problem with it.
> 
> The help file for xyplot indicates that for the xyplot formula method
> the default
> environment is the caller environment whereas it ought to be the environment
> of the formula:
> 
>     data: For the 'formula' method, a data frame containing values for
>           any variables in the formula, as well as 'groups' and
>           'subset' if applicable.  By default the environment where the
>           function was called from is used.
> 
> For example, if we replace xyplot with lm it does work as expected:
> 
>    fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, ... )
>    fun2 <- function( ... ) lm( ... )
>    fun1()

You're right, I forgot formulas have associated environments.  I've 
added the lattice maintainer to the cc list.

Duncan Murdoch



From Soren.Hojsgaard at agrsci.dk  Tue Feb 14 16:24:45 2006
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Tue, 14 Feb 2006 16:24:45 +0100
Subject: [R] How to handle large dataframes?
References: <43F1E817.5040006@unibas.ch>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC038781C1@DJFPOST01.djf.agrsci.dk>

I think it is well worth the effort to start using a database system like e.g. MySql for such purposes.
 
If you look at http://gbi.agrsci.dk/~sorenh/misc/R-SAS-MySql/R-SAS-MySql.html
then you'll find a short - and rudimentary - description of how to use MySql in connection with R and SAS (on Windows). 
 
The time you'll have to spend to get it up and running (about 30 minutes) is well spent. I suppose you can take your stata data and save as a comma separate file. Such a file is easy to put into a MySql database (although I haven't written how). Perhaps Stata can connect directly to MySql?
 
Best regards
S??ren

________________________________

Fra: r-help-bounces at stat.math.ethz.ch p?? vegne af Christian Bieli
Sendt: ti 14-02-2006 15:24
Til: R help list
Emne: [R] How to handle large dataframes?



Dear all

I imported a Stata .dta file with the read.dta-function from the
foreign-package. The dataframe's dimensions are

 > dim(d.apc)
[1] 15806  1300

Importing needs up to 15 min and calculations with these data are rather
slow  (although I subset the data before starting analyses).

My questions are:
1. Has someone experiences importing Stata files (alternatives to
read.dta) ?
2. To my knowledge R should not have problems handling dataframes of
this size. Is there something I can do after importing that makes data
handling faster?

My hardware is up-to-date (Intel P4, 3 Ghz, 1 GB RAM) and I work on a
Windows XP platform.
I am working on a Windows XP platform with R version 2.1 (all packages
updated).

Thanks for your answers.
Christian

--
Christian Bieli, project assistant
Institute of Social and Preventive Medicine
University of Basel, Switzerland
Steinengraben 49
CH-4051 Basel
Tel.: +41 61 270 22 12
Fax:  +41 61 270 22 25
christian.bieli at unibas.ch
www.unibas.ch/ispmbs

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From liuwensui at gmail.com  Tue Feb 14 16:36:09 2006
From: liuwensui at gmail.com (Wensui Liu)
Date: Tue, 14 Feb 2006 10:36:09 -0500
Subject: [R] How to handle large dataframes?
In-Reply-To: <43F1E817.5040006@unibas.ch>
References: <43F1E817.5040006@unibas.ch>
Message-ID: <1115a2b00602140736qdab7b90s43424330661d7a41@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060214/a8d7552e/attachment.pl

From roger.bos at gmail.com  Tue Feb 14 16:38:03 2006
From: roger.bos at gmail.com (roger bos)
Date: Tue, 14 Feb 2006 10:38:03 -0500
Subject: [R] How to handle large dataframes?
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC038781C1@DJFPOST01.djf.agrsci.dk>
References: <43F1E817.5040006@unibas.ch>
	<C83C5E3DEEE97E498B74729A33F6EAEC038781C1@DJFPOST01.djf.agrsci.dk>
Message-ID: <1db726800602140738w6d67adc0n85078dbc30d1ccf1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060214/32f21e4a/attachment.pl

From terrywschulz at comcast.net  Tue Feb 14 16:40:52 2006
From: terrywschulz at comcast.net (Terry W. Schulz)
Date: Tue, 14 Feb 2006 08:40:52 -0700
Subject: [R] Extracting Data form Simpleboot Output
In-Reply-To: <43F1AD09.8020105@statistik.uni-dortmund.de>
References: <43F10550.3020402@comcast.net>
	<43F1AD09.8020105@statistik.uni-dortmund.de>
Message-ID: <43F1FA04.6030901@comcast.net>

Thank you for the perfect solution. 

Uwe Ligges wrote:
> Terry W. Schulz wrote:
>
>> Hello,
>> I am new to R, so forgive my ignorance on what is probably simple.
>> I find package simpleboot quite useful for LOESS bootstrapping and 
>> generation of plots.
>> I want to calculate the standard error for x=60 of the 100 grid 
>> points and 50 bootstraps.
>> The code below gives the first fitted value.
>> How can I grab the other 49 values easily?
>> I could do it one at a time for 50 bootstraps, but this becomes 
>> tedious for say 2000 bootstraps.
>> Thanks for any help.
>>
>> library(simpleboot)
>> library(bootstrap)
>> attach(cholost)
>> set.seed(13579)
>> lo <- loess(y ~ z, data=cholost, span=.5, degree=2, 
>> family="gaussian", method="loess")
>> lo.b <- loess.boot(lo, R=50, rows = TRUE, new.xpts = NULL, ngrid = 
>> 100, weights = NULL)
>> lo.b$boot.list$"1"$fitted[60]
>>
>
>
>   sapply(lo.b$boot.list, function(x) x$fitted)
>
> gives you the corresponding 100x50 matrix ...
>
> Uwe Ligges
>
>

-- 
Terry W. Schulz
Applied Statistician
1218 Pomegranate Lane
Golden, CO 80401

terrywschulz at comcast.net
(303) 526-1461



From Soren.Hojsgaard at agrsci.dk  Tue Feb 14 16:43:05 2006
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Tue, 14 Feb 2006 16:43:05 +0100
Subject: [R] Using optim() with a function which returns more than a scalar
	- alternatives?
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC038781C2@DJFPOST01.djf.agrsci.dk>

I want to numerically maximize a function with optim (maximization over several arguments). optim() needs a function which returns a scalar only. However, it could be nice to be able to "take other things out" from the function as well. I'tried to create an attribute to the scalar with what I want to take out, but that attribute disappears in optim(). I looked into the code to see if it could (easily) be modified such that it could work on a function which returns e.g. a list or a vector (and then it should be maximized over the first element). But I gave up... Any suggestion will be appreciated...
Best regards
S??ren



From wp1 at tiscali.fr  Tue Feb 14 16:44:43 2006
From: wp1 at tiscali.fr (WPhantom)
Date: Tue, 14 Feb 2006 16:44:43 +0100
Subject: [R] A concrete type I/III Sum of square problem
In-Reply-To: <Pine.LNX.4.64.0602141136060.32531@gannet.stats.ox.ac.uk>
References: <7.0.0.16.2.20060214091550.02578e88@univ-lille3.fr>
	<Pine.LNX.4.64.0602141136060.32531@gannet.stats.ox.ac.uk>
Message-ID: <7.0.0.16.2.20060214164028.025bf240@tiscali.fr>

Thanks Brian for the reference.
  I just discover that it is available in our 
library so I going to take it & read it soon.
Actually, I don't even know the difference 
between a multistratum vs a single-stratum AOV. A 
quick search on google returned me the R materials so that I imagine
that these concepts are quite specific to R.

I will read the book first before asking for more informations.

Thanks

Sylvain Cl??ment

At 12:38 14/02/2006, you wrote:
>More to the point, you are confusing 
>multistratum AOV with single-stratuam AOV.  For 
>a good tutorial, see MASS4 (bibliographic 
>information in the R FAQ).  For unbalanced data 
>we suggest you use lme() instead.
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk



From Ita.Cirovic-Donev at hypo-alpe-adria.com  Tue Feb 14 17:01:12 2006
From: Ita.Cirovic-Donev at hypo-alpe-adria.com (Ita.Cirovic-Donev@hypo-alpe-adria.com)
Date: Tue, 14 Feb 2006 17:01:12 +0100
Subject: [R] Inf values in a matrix
Message-ID: <OF0A6746A4.DE2E7FF1-ONC1257115.0057D370-C1257115.00580057@arz.co.at>





Hello,

I have some Inf values in a matrix, but I don't want to replace them with
some value but rather remove the rows that contain the Inf values. Also I
would like to record the rows which were removed. Is there an easy way to
do this instead of writing loops over the matrix? Thanks.

Ita Cirovic Donev



From Mike.Prager at noaa.gov  Tue Feb 14 17:03:21 2006
From: Mike.Prager at noaa.gov (Michael Prager)
Date: Tue, 14 Feb 2006 11:03:21 -0500
Subject: [R] R and Power Point
In-Reply-To: <200602140646.k1E6kgWk005773@gator.dt.uh.edu>
References: <200602140646.k1E6kgWk005773@gator.dt.uh.edu>
Message-ID: <43F1FF49.1020106@noaa.gov>

Erin,

 From an Rgui graphics window (windows() device), Ctrl-W will save the 
current graph to the clipboard as a metafile; Ctrl-C will save as a 
bitmap.  In PPt, Ctrl-V will paste either into a blank spot on a slide.

The metafile is a Windows vector spec that will be sharper and smaller.  
However, I have had trouble when viewing them on different PCs with 
different fonts installed.  Bitmaps will get around that but have all 
the usual limitations of ... bitmaps.

MHP


Erin Hodgess wrote on 2/14/2006 1:46 AM:
> Dear R People:
>
> I'm using R in a time series class.  This class is being
> broadcast live to 2 remote sites via closed circuit TV.
>
> My people at the remote sites are having a terrible time
> seeing the computer screen as it is broadcast(resolution issues).  I have
> decided to put together Power Point slides for the teaching.
>
> I am currently saving the R screen as WMF files and inserting them
> into PowerPoint.  While this works, it seems that there
> might be a simpler method.  
>
> Does anyone have any suggestions for the Power Point, please?
>
> Thanks so much!
> R Version 2.2.1 Windows
> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>   

-- 
Michael H. Prager, Ph.D.
Population Dynamics Team
NOAA Center for Coastal Habitat and Fisheries Research
NMFS Southeast Fisheries Science Center
Beaufort, North Carolina  28516  USA
http://shrimp.ccfhrb.noaa.gov/~mprager/



From B.Rowlingson at lancaster.ac.uk  Tue Feb 14 17:06:14 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 14 Feb 2006 16:06:14 +0000
Subject: [R] Using optim() with a function which returns more than a
 scalar - alternatives?
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC038781C2@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC038781C2@DJFPOST01.djf.agrsci.dk>
Message-ID: <43F1FFF6.7000702@lancaster.ac.uk>

S??ren H??jsgaard wrote:

> I want to numerically maximize a function with optim (maximization
> over several arguments). optim() needs a function which returns a
> scalar only. However, it could be nice to be able to "take other
> things out" from the function as well. I'tried to create an attribute
> to the scalar with what I want to take out, but that attribute
> disappears in optim(). I looked into the code to see if it could
> (easily) be modified such that it could work on a function which
> returns e.g. a list or a vector (and then it should be maximized over
> the first element). But I gave up... Any suggestion will be
> appreciated...

  Have your function return a scalar value and any additional data in an 
attribute, and then optimise. Then call your function one more time 
using the resulting parameters found by optim(), and you'll get the 
attributes.

  Pro: No need to mess with the code of optim()
  Con: One more function call required. Probably not a problem since 
optim() will have called it a few times anyway.

BArry



From kubovy at virginia.edu  Tue Feb 14 17:10:06 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Tue, 14 Feb 2006 11:10:06 -0500
Subject: [R] R and Power Point
In-Reply-To: <43F1E879.2030101@stats.uwo.ca>
References: <200602140646.k1E6kgWk005773@gator.dt.uh.edu>
	<D92BDCEF-EE65-498D-BE02-1780C2F438E6@virginia.edu>
	<43F1E879.2030101@stats.uwo.ca>
Message-ID: <A651CA67-E5DD-4898-AE66-179063C5524C@virginia.edu>

Hi Duncan,

On Feb 14, 2006, at 9:26 AM, Duncan Murdoch wrote:

> On 2/14/2006 9:08 AM, Michael Kubovy wrote:
>> On Feb 14, 2006, at 1:46 AM, Erin Hodgess wrote:
>>> I'm using R in a time series class. ... I have decided to put   
>>> together Power Point slides for the teaching. ... I am currently   
>>> saving the R screen as WMF files and inserting them into   
>>> PowerPoint.  While this works, it seems that there might be a   
>>> simpler method.
>> Hi Erin,
>> For presentations I use LaTeX with beamer.cls and Sweave to access  
>> R.  The results are legible and attractive. The method is not  
>> simple at  first, since you must understand how to use beamer.cls  
>> and Sweave.  But once you're in production mode, it's a delight.
>> I'd be happy to share templates.
>
> Please put some up on the web somewhere!  I'm just learning beamer,  
> and don't need it for R right now, but I'm sure I will eventually.

I'll do so soon, and let the list know. Before that, please ask, and  
I'll send you the .Rnw and .tex files.

> P.S.  How do I add page numbers to slides?  I see in the manual a  
> section called "The Headline and Footline" that apparently tells me  
> how to do it using an option "[page number]", but I don't see where  
> to put that.

\setbeamertemplate{footline}[page number]

This works, but has side effects on the appearance of my theme (I use  
Warsaw) that I don't know yet how to deal with.
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From hb at maths.lth.se  Tue Feb 14 17:12:43 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 14 Feb 2006 17:12:43 +0100
Subject: [R] R and Power Point
In-Reply-To: <43F1E879.2030101@stats.uwo.ca>
References: <200602140646.k1E6kgWk005773@gator.dt.uh.edu>
	<D92BDCEF-EE65-498D-BE02-1780C2F438E6@virginia.edu>
	<43F1E879.2030101@stats.uwo.ca>
Message-ID: <59d7961d0602140812y7a165df3q56b427de2c601633@mail.gmail.com>

On 2/14/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 2/14/2006 9:08 AM, Michael Kubovy wrote:
> > On Feb 14, 2006, at 1:46 AM, Erin Hodgess wrote:
> >> I'm using R in a time series class. ... I have decided to put
> >> together Power Point slides for the teaching. ... I am currently
> >> saving the R screen as WMF files and inserting them into
> >> PowerPoint.  While this works, it seems that there might be a
> >> simpler method.
> >
> > Hi Erin,
> >
> > For presentations I use LaTeX with beamer.cls and Sweave to access R.
> > The results are legible and attractive. The method is not simple at
> > first, since you must understand how to use beamer.cls and Sweave.
> > But once you're in production mode, it's a delight.
> >
> > I'd be happy to share templates.
>
> Please put some up on the web somewhere!  I'm just learning beamer, and
> don't need it for R right now, but I'm sure I will eventually.
>
> Duncan Murdoch
>
> P.S.  How do I add page numbers to slides?  I see in the manual a
> section called "The Headline and Footline" that apparently tells me how
> to do it using an option "[page number]", but I don't see where to put that.

A "ten second - I have to run - cross my fingers that I'm correct"
reply: one way is to use pre-defined templates. Try to add

\useoutertheme{infolines}

which should give you a line of author, short title, date, and *frame* number.

/Henrik

> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From efg at stowers-institute.org  Tue Feb 14 17:00:25 2006
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Tue, 14 Feb 2006 10:00:25 -0600
Subject: [R] R and Power Point
References: <200602140646.k1E6kgWk005773@gator.dt.uh.edu>
Message-ID: <dssur1$3lt$1@sea.gmane.org>

"Erin Hodgess" <hodgess at gator.dt.uh.edu> wrote in message
news:200602140646.k1E6kgWk005773 at gator.dt.uh.edu...
> I am currently saving the R screen as WMF files and inserting them
> into PowerPoint.  While this works, it seems that there
> might be a simpler method.
>
> Does anyone have any suggestions for the Power Point, please?

Instead of saving to a file first, have you tried cutting from R and pasting
directly to PowerPoint?



File | Copy to Clipboard | As a Metafile



Paste onto PowerPoint page



In PowerPoint, the graphic has no background.  Set a background color (if
desired):



Right click on graphic | Format Picture | Colors and Lines | Fill | Change
from "No Fill" to white, or desired background color



Sometimes resizing even with a metafile is a problem in PowerPoint (or
Word).  Drawing the "right" size in R before cutting and pasting often
solves that problem.



For some very complicated graphics (e.g., a large heatmap), use Copy to
Clipboard | As a Bitmap to avoid delays in redrawing the graphic whenever
the page is shown.



efg



From murdoch at stats.uwo.ca  Tue Feb 14 17:18:37 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 14 Feb 2006 11:18:37 -0500
Subject: [R] R and Power Point
In-Reply-To: <59d7961d0602140812y7a165df3q56b427de2c601633@mail.gmail.com>
References: <200602140646.k1E6kgWk005773@gator.dt.uh.edu>	
	<D92BDCEF-EE65-498D-BE02-1780C2F438E6@virginia.edu>	
	<43F1E879.2030101@stats.uwo.ca>
	<59d7961d0602140812y7a165df3q56b427de2c601633@mail.gmail.com>
Message-ID: <43F202DD.6060202@stats.uwo.ca>

On 2/14/2006 11:12 AM, Henrik Bengtsson wrote:
> On 2/14/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 2/14/2006 9:08 AM, Michael Kubovy wrote:
>> > On Feb 14, 2006, at 1:46 AM, Erin Hodgess wrote:
>> >> I'm using R in a time series class. ... I have decided to put
>> >> together Power Point slides for the teaching. ... I am currently
>> >> saving the R screen as WMF files and inserting them into
>> >> PowerPoint.  While this works, it seems that there might be a
>> >> simpler method.
>> >
>> > Hi Erin,
>> >
>> > For presentations I use LaTeX with beamer.cls and Sweave to access R.
>> > The results are legible and attractive. The method is not simple at
>> > first, since you must understand how to use beamer.cls and Sweave.
>> > But once you're in production mode, it's a delight.
>> >
>> > I'd be happy to share templates.
>>
>> Please put some up on the web somewhere!  I'm just learning beamer, and
>> don't need it for R right now, but I'm sure I will eventually.
>>
>> Duncan Murdoch
>>
>> P.S.  How do I add page numbers to slides?  I see in the manual a
>> section called "The Headline and Footline" that apparently tells me how
>> to do it using an option "[page number]", but I don't see where to put that.
> 
> A "ten second - I have to run - cross my fingers that I'm correct"
> reply: one way is to use pre-defined templates. Try to add
> 
> \useoutertheme{infolines}
> 
> which should give you a line of author, short title, date, and *frame* number.

Thanks.  That gives a bit more than I want, but it gives me some leads 
to go fixing things...

Duncan Murdoch



From terrywschulz at comcast.net  Tue Feb 14 17:21:56 2006
From: terrywschulz at comcast.net (Terry W. Schulz)
Date: Tue, 14 Feb 2006 09:21:56 -0700
Subject: [R] R and Power Point
In-Reply-To: <43F1E879.2030101@stats.uwo.ca>
References: <200602140646.k1E6kgWk005773@gator.dt.uh.edu>	<D92BDCEF-EE65-498D-BE02-1780C2F438E6@virginia.edu>
	<43F1E879.2030101@stats.uwo.ca>
Message-ID: <43F203A4.9080406@comcast.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060214/4cfb70bf/attachment.pl

From dimitris.rizopoulos at med.kuleuven.be  Tue Feb 14 17:24:19 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 14 Feb 2006 17:24:19 +0100
Subject: [R] Inf values in a matrix
References: <OF0A6746A4.DE2E7FF1-ONC1257115.0057D370-C1257115.00580057@arz.co.at>
Message-ID: <00c001c63183$1b4129d0$0540210a@www.domain>

try the following:

mat <- matrix(rnorm(40), 10, 4)
mat[sample(20, 5)] <- Inf
mat
##########
index <- rowSums(!is.finite(mat)) >= 1
mat. <- mat[!index, ]

which(index)
mat.


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: <Ita.Cirovic-Donev at hypo-alpe-adria.com>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, February 14, 2006 5:01 PM
Subject: [R] Inf values in a matrix


>
>
>
>
> Hello,
>
> I have some Inf values in a matrix, but I don't want to replace them 
> with
> some value but rather remove the rows that contain the Inf values. 
> Also I
> would like to record the rows which were removed. Is there an easy 
> way to
> do this instead of writing loops over the matrix? Thanks.
>
> Ita Cirovic Donev
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From p.dalgaard at biostat.ku.dk  Tue Feb 14 17:26:27 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 14 Feb 2006 17:26:27 +0100
Subject: [R] A concrete type I/III Sum of square problem
In-Reply-To: <7.0.0.16.2.20060214164028.025bf240@tiscali.fr>
References: <7.0.0.16.2.20060214091550.02578e88@univ-lille3.fr>
	<Pine.LNX.4.64.0602141136060.32531@gannet.stats.ox.ac.uk>
	<7.0.0.16.2.20060214164028.025bf240@tiscali.fr>
Message-ID: <x2slqlrjnw.fsf@viggo.kubism.ku.dk>

WPhantom <wp1 at tiscali.fr> writes:

> Thanks Brian for the reference.
>   I just discover that it is available in our 
> library so I going to take it & read it soon.
> Actually, I don't even know the difference 
> between a multistratum vs a single-stratum AOV. A 
> quick search on google returned me the R materials so that I imagine
> that these concepts are quite specific to R.

You have to be careful not to confuse Google's view of the world with
Reality...

The concept of error strata is much older than R, and existed for
instance in Genstat, anno 1977 or so. However, Genstat seems to have
left little impression on the Internet. 
 
> I will read the book first before asking for more informations.

The executive summary is that the concept of error strata relies
substantially on having a balanced design (at least for the random
effects), so that the analysis can be decomposed into analyses of
means, contrasts, and contrasts of means. For unbalanced designs, you
usually get meaningless analyses.


> Thanks
> 
> Sylvain Cl??ment
> 
> At 12:38 14/02/2006, you wrote:
> >More to the point, you are confusing 
> >multistratum AOV with single-stratuam AOV.  For 
> >a good tutorial, see MASS4 (bibliographic 
> >information in the R FAQ).  For unbalanced data 
> >we suggest you use lme() instead.
> >
> >--
> >Brian D. Ripley,                  ripley at stats.ox.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From petr.pikal at precheza.cz  Tue Feb 14 17:28:34 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 14 Feb 2006 17:28:34 +0100
Subject: [R] Inf values in a matrix
In-Reply-To: <OF0A6746A4.DE2E7FF1-ONC1257115.0057D370-C1257115.00580057@arz.co.at>
Message-ID: <43F21342.11040.2022287@localhost>

Hi

see
?is.infinite
?which
something like

y <- x[-which(is.infinite(x), arr.ind=T)[,1],]
y.removed <-x[which(is.infinite(x), arr.ind=T)[,1],]
shall make the trick.



On 14 Feb 2006 at 17:01, Ita.Cirovic-Donev at hypo-alpe-a wrote:

To:             	r-help at stat.math.ethz.ch
From:           	Ita.Cirovic-Donev at hypo-alpe-adria.com
Date sent:      	Tue, 14 Feb 2006 17:01:12 +0100
Subject:        	[R] Inf values in a matrix

> 
> 
> 
> 
> Hello,
> 
> I have some Inf values in a matrix, but I don't want to replace them
> with some value but rather remove the rows that contain the Inf
> values. Also I would like to record the rows which were removed. Is
> there an easy way to do this instead of writing loops over the matrix?
> Thanks.
> 
> Ita Cirovic Donev
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From ligges at statistik.uni-dortmund.de  Tue Feb 14 18:12:52 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 14 Feb 2006 18:12:52 +0100
Subject: [R] Inf values in a matrix
In-Reply-To: <OF0A6746A4.DE2E7FF1-ONC1257115.0057D370-C1257115.00580057@arz.co.at>
References: <OF0A6746A4.DE2E7FF1-ONC1257115.0057D370-C1257115.00580057@arz.co.at>
Message-ID: <43F20F94.2020608@statistik.uni-dortmund.de>

Ita.Cirovic-Donev at hypo-alpe-adria.com wrote:

> 
> 
> 
> Hello,
> 
> I have some Inf values in a matrix, but I don't want to replace them with
> some value but rather remove the rows that contain the Inf values. Also I
> would like to record the rows which were removed. Is there an easy way to
> do this instead of writing loops over the matrix? Thanks.
> 
> Ita Cirovic Donev
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


Example:

  A <- matrix(1:100, 10)
  A[cbind(3:4, 5:6)] <- Inf
  recorded <- which(apply(A, 1, function(x) any(is.infinite(x))))
  A[-recorded,]


Uwe Ligges



From deepayan.sarkar at gmail.com  Tue Feb 14 18:13:58 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 14 Feb 2006 11:13:58 -0600
Subject: [R] R and Power Point
In-Reply-To: <43F1E879.2030101@stats.uwo.ca>
References: <200602140646.k1E6kgWk005773@gator.dt.uh.edu>
	<D92BDCEF-EE65-498D-BE02-1780C2F438E6@virginia.edu>
	<43F1E879.2030101@stats.uwo.ca>
Message-ID: <eb555e660602140913l57956539tf0ed24908cbf3f75@mail.gmail.com>

On 2/14/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 2/14/2006 9:08 AM, Michael Kubovy wrote:
> > On Feb 14, 2006, at 1:46 AM, Erin Hodgess wrote:
> >> I'm using R in a time series class. ... I have decided to put
> >> together Power Point slides for the teaching. ... I am currently
> >> saving the R screen as WMF files and inserting them into
> >> PowerPoint.  While this works, it seems that there might be a
> >> simpler method.
> >
> > Hi Erin,
> >
> > For presentations I use LaTeX with beamer.cls and Sweave to access R.
> > The results are legible and attractive. The method is not simple at
> > first, since you must understand how to use beamer.cls and Sweave.
> > But once you're in production mode, it's a delight.
> >
> > I'd be happy to share templates.
>
> Please put some up on the web somewhere!  I'm just learning beamer, and
> don't need it for R right now, but I'm sure I will eventually.

I recently packaged up a small example for someone else; it's still
available at

http://www.stat.wisc.edu/~deepayan/R/gridbasics.zip

YMMV.

Deepayan



From mtmorgan at fhcrc.org  Tue Feb 14 18:23:58 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 14 Feb 2006 09:23:58 -0800
Subject: [R] Turning control back over to the terminal
In-Reply-To: <1139869614.19068.12.camel@iron.psg.net> (Ross Boylan's message
	of "Mon, 13 Feb 2006 14:26:54 -0800")
References: <1139869614.19068.12.camel@iron.psg.net>
Message-ID: <6phbqx9n9ap.fsf@wellington.fhcrc.org>

Hi Ross --

Not a direct answer to your question, but here's an idea.

I guess you've got some script in a file batch.sh

#! /bin/bash
R --no-save --no-restore --gui=none > `hostname`  2>&1 <<BYE
# some mpi commands
# other mpi commands
BYE

and you do something like

mpiexec -np 10 batch.sh

Instead, you might create a file script.R

script.R
--------

library("Rmpi")
mpi.spawn.Rslaves(nslaves=10)

variousCmds <- function() {
  ## some mpi commands
  if( mpi.comm.rank() == 0 && interactive()) {
    while( (res <- readline( prompt=" > ")) != "DONE" ) {
      try(cat(eval(parse(text=res)), "\n"))
      ## or other, e.g., browser()
    }
  }
  ## other mpi commands
}

mpi.bcast.Robj2slave( variousCmds )
mpi.bcast.cmd( variousCmds())
variousCmds()

mpi.close.Rslaves()

Then just run R and

source("script.R")

to debug, and

R --vanilla < script.R

to run. This assumes that the 'some' and 'other' mpi commands include
communication of results between nodes, so that you don't have to rely
on the the return value of variousCmds to harvest the results. This
could be great fun, because you can edit the script file (in emacs,
for e.g.) and rerun without exiting R.

http://ace.acadiau.ca/math/ACMMaC/Rmpi/index.html provided some
inspiration for this, thanks!

Martin

Ross Boylan <ross at biostat.ucsf.edu> writes:

> I'm invoking R from withing a shell script like this
> R --no-save --no-restore --gui=none > `hostname`  2>&1 <<BYE
> # various commands here
> BYE
>
> I would like to regain control from the invoking terminal at some point.
> I tried source(stdin()) but got a syntax error, presumably stdin is the
> little shell here snippet (the part between <<BYE
> and BYE).
>
> Is there some way to accomplish this?  I am trying to regain control
> inside an R session that has been launched inside an MPI environment
> (and I'm usually running inside emacs).  This is on a Mac OS X cluster.
>
> I suppose there might be a way to do this with expect, but I'm hoping
> for something simpler.  Potentially, I could make the script itself act
> differently on the head node (the only one I want to debug right now),
> including changing the redirection there.
>
>
> -- 
> Ross Boylan                                      wk:  (415) 514-8146
> 185 Berry St #5700                               ross at biostat.ucsf.edu
> Dept of Epidemiology and Biostatistics           fax: (415) 514-8150
> University of California, San Francisco
> San Francisco, CA 94107-1739                     hm:  (415) 550-1062
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From yangj at student.ethz.ch  Tue Feb 14 18:25:43 2006
From: yangj at student.ethz.ch (Jing Yang)
Date: Tue, 14 Feb 2006 18:25:43 +0100
Subject: [R] how to add the 95% confidence bands for the normal QQ plot?
Message-ID: <XFE0b6uIU1Gj03oHMwV00001e21@xfe0.d.ethz.ch>

I had the problem to do this.



From MaximilianOtto at gmx.at  Tue Feb 14 20:28:22 2006
From: MaximilianOtto at gmx.at (Max Kauer)
Date: Tue, 14 Feb 2006 20:28:22 +0100 (MET)
Subject: [R] read.table
Message-ID: <15421.1139945302@www075.gmx.net>

Hi
it appears to me that read.table is very slow for reading large data files
(mine are 200,000 rows). Is there a better way?
Thanks!
Max

-- 
Maximilian O. Kauer, Ph.D.
Department of Genetics, White lab
333 Cedar St, NSB 386
PO Box 208005
New Haven, CT 06510



From roger.bos at gmail.com  Tue Feb 14 20:34:18 2006
From: roger.bos at gmail.com (roger bos)
Date: Tue, 14 Feb 2006 14:34:18 -0500
Subject: [R] read.table
In-Reply-To: <15421.1139945302@www075.gmx.net>
References: <15421.1139945302@www075.gmx.net>
Message-ID: <1db726800602141134x11a1bbc9h@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060214/8765e459/attachment.pl

From rodrigo.tsai at gmail.com  Tue Feb 14 21:06:47 2006
From: rodrigo.tsai at gmail.com (Rodrigo Tsai)
Date: Tue, 14 Feb 2006 18:06:47 -0200
Subject: [R] figs parameter for split.screen()
Message-ID: <a9801f600602141206g62f101a7na9b3c0112a16772a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060214/c89d743d/attachment.pl

From elvis at xlsolutions-corp.com  Tue Feb 14 21:43:49 2006
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Tue, 14 Feb 2006 13:43:49 -0700
Subject: [R] R/Splus April course *** (Raleigh, Miami, Houston,
	Baltimore etc)  R/Splus Fundamentals and Programming Techniques
Message-ID: <20060214134349.9f08cc34deb45d78e54b3b5664e21546.53b584311c.wbe@email.secureserver.net>


   XLSolutions Corporation (www.xlsolutions-corp.com) is proud to
   announce  2-day "R/S-plus Fundamentals and Programming
   Techniques" in San Francisco: www.xlsolutions-corp.com/Rfund.htm
   **** Raleigh,                April  3-4
   **** Miami,                  April 10-11
   **** Houston,                April 13-14
   **** Boston,                 April 20-21
   **** Baltimore,              April 27-28
   Reserve your seat now at the early bird rates! Payment due AFTER
   the class
   Course Description:
   This two-day beginner to intermediate R/S-plus course focuses on a
   broad spectrum of topics, from reading raw data to a comparison of R
   and S. We will learn the essentials of data manipulation, graphical
   visualization and R/S-plus programming. We will explore statistical
   data analysis tools,including graphics with data sets. How to enhance
   your plots, build your own packages (librairies) and connect via
   ODBC,etc.
   We will perform some statistical modeling and fit linear regression
   models. Participants are encouraged to bring data for interactive
   sessions
   With the following outline:
   - An Overview of R and S
   - Data Manipulation and Graphics
   - Using Lattice Graphics
   - A Comparison of R and S-Plus
   - How can R Complement SAS?
   - Writing Functions
   - Avoiding Loops
   - Vectorization
   - Statistical Modeling
   - Project Management
   - Techniques for Effective use of R and S
   - Enhancing Plots
   - Using High-level Plotting Functions
   - Building and Distributing Packages (libraries)
   - Connecting; ODBC, Rweb, Orca via sockets and via Rjava
   Email us for group discounts.
   Email Sue Turner: sue at xlsolutions-corp.com
   Phone: 206-686-1578
   Visit us: www.xlsolutions-corp.com/training.htm
   Please let us know if you and your colleagues are interested in this
   classto take advantage of group discount. Register now to secure your
   seat!
   Interested in R/Splus Advanced course? email us.
   Cheers,
   Elvis Miller, PhD
   Manager Training.
   XLSolutions Corporation
   206 686 1578
   www.xlsolutions-corp.com
   elvis at xlsolutions-corp.com


From vasu.akkineni at louisville.edu  Tue Feb 14 21:50:19 2006
From: vasu.akkineni at louisville.edu (Akkineni,Vasundhara)
Date: Tue, 14 Feb 2006 15:50:19 -0500
Subject: [R] Legend in a HeatMap
Message-ID: <1139950219.9417e1csvakki01@netmail.louisville.edu>

List,
 
Is it possible to add a color legend to a heatmap , similar to the one in levelplot and filled.contour plot. The legend will represent the colors used in the heatmap along with values for each color range. Can this be done? Please help. 
 
Thanks,
Svakki.



From ripley at stats.ox.ac.uk  Tue Feb 14 22:13:39 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Feb 2006 21:13:39 +0000 (GMT)
Subject: [R] figs parameter for split.screen()
In-Reply-To: <a9801f600602141206g62f101a7na9b3c0112a16772a@mail.gmail.com>
References: <a9801f600602141206g62f101a7na9b3c0112a16772a@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602142109220.15315@gannet.stats.ox.ac.uk>

On Tue, 14 Feb 2006, Rodrigo Tsai wrote:

> Dear all,
>
> I would be pleased if anyone could help me.
>
> The Rhelp description for the figs parameter is "a two-element vector
> describing
> the number of rows and colunns in a screen matrix".
>
> So, why does my code (below) produce a 2x1 screen matrix instead of
> a 1x2 one?

Does it? There is no way we can reproduce it as it is incomplete, but

split.screen(figs=c(1,2))
screen(1)
plot(1:2)
screen(2)
plot(10:1)

does produce a 1x2 layout.

Perhaps your error is call plot.new() in a subdivided layout: it makes no 
sense to select a screen and then move to the next frame.

>
> Thanks in advance,
> rodrigo.
>
> -----------------------------------------------------------
> plot.new()
>
> split.screen(figs=c(1,2))
>
>
>
> screen(1)
>
> plot.new()
>
> plot(v16[vd==0], vdep[vd==0], bg="aliceblue", cex= 0.5,
> xlab="Age",ylab="AvWei", main="", ylim=c(x1,xn), cex.lab=1.1)
>
> title(main = "Female", cex.main = 1.1 , font.main = 1, col.main = "black")
>
>
>
> screen(2)
>
> plot.new()
>
> plot(v16[vd==1], vdep[vd==1], bg="aliceblue", cex= 0.5,
> xlab="Age",ylab="AvWei", main="", ylim=c(x1,xn), cex.lab=1.1)
>
> title(main = "Male", cex.main = 1.1 , font.main = 1, col.main = "black")
>
> *-----------------------------------------------------------  *
>
> **
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rodrigo.tsai at gmail.com  Tue Feb 14 22:30:41 2006
From: rodrigo.tsai at gmail.com (Rodrigo Tsai)
Date: Tue, 14 Feb 2006 19:30:41 -0200
Subject: [R] figs parameter for split.screen()
In-Reply-To: <Pine.LNX.4.64.0602142109220.15315@gannet.stats.ox.ac.uk>
References: <a9801f600602141206g62f101a7na9b3c0112a16772a@mail.gmail.com>
	<Pine.LNX.4.64.0602142109220.15315@gannet.stats.ox.ac.uk>
Message-ID: <a9801f600602141330k3c258211l775c4b54708deb61@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060214/475801eb/attachment.pl

From gunter.berton at gene.com  Tue Feb 14 22:52:09 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 14 Feb 2006 13:52:09 -0800
Subject: [R] figs parameter for split.screen()
In-Reply-To: <a9801f600602141330k3c258211l775c4b54708deb61@mail.gmail.com>
Message-ID: <200602142152.k1ELq9tR005567@ohm.gene.com>

You may find that ?layout is an easier way to handle multiple plots on the
screen (I do), if you are not already aware of it.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Rodrigo Tsai
> Sent: Tuesday, February 14, 2006 1:31 PM
> To: Prof Brian Ripley
> Cc: R-help at stat.math.ethz.ch
> Subject: Re: [R] figs parameter for split.screen()
> 
> Dear Prof Brian Ripley,
> 
> Many thanks for your help. Before trying to split.screen 
> (1x2) I had set the
> "mar" parameter in par( ) in order to move each graph of another (2x1)
> splitted figure. This setting might have caused the problem. 
> Now it works.
> 
> Best regards,
> Rodrigo.
> 
> 
> On 2/14/06, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> >
> > On Tue, 14 Feb 2006, Rodrigo Tsai wrote:
> >
> > > Dear all,
> > >
> > > I would be pleased if anyone could help me.
> > >
> > > The Rhelp description for the figs parameter is "a 
> two-element vector
> > > describing
> > > the number of rows and colunns in a screen matrix".
> > >
> > > So, why does my code (below) produce a 2x1 screen matrix 
> instead of
> > > a 1x2 one?
> >
> > Does it? There is no way we can reproduce it as it is 
> incomplete, but
> >
> > split.screen(figs=c(1,2))
> > screen(1)
> > plot(1:2)
> > screen(2)
> > plot(10:1)
> >
> > does produce a 1x2 layout.
> >
> > Perhaps your error is call plot.new() in a subdivided 
> layout: it makes no
> > sense to select a screen and then move to the next frame.
> >
> > >
> > > Thanks in advance,
> > > rodrigo.
> > >
> > > -----------------------------------------------------------
> > > plot.new()
> > >
> > > split.screen(figs=c(1,2))
> > >
> > >
> > >
> > > screen(1)
> > >
> > > plot.new()
> > >
> > > plot(v16[vd==0], vdep[vd==0], bg="aliceblue", cex= 0.5,
> > > xlab="Age",ylab="AvWei", main="", ylim=c(x1,xn), cex.lab=1.1)
> > >
> > > title(main = "Female", cex.main = 1.1 , font.main = 1, col.main =
> > "black")
> > >
> > >
> > >
> > > screen(2)
> > >
> > > plot.new()
> > >
> > > plot(v16[vd==1], vdep[vd==1], bg="aliceblue", cex= 0.5,
> > > xlab="Age",ylab="AvWei", main="", ylim=c(x1,xn), cex.lab=1.1)
> > >
> > > title(main = "Male", cex.main = 1.1 , font.main = 1, 
> col.main = "black")
> > >
> > > *-----------------------------------------------------------  *
> > >
> > > **
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From malfonso at sinu.unicordoba.edu.co  Tue Feb 14 17:45:19 2006
From: malfonso at sinu.unicordoba.edu.co (Mario Alfonso Morales Rivera)
Date: Tue, 14 Feb 2006 11:45:19 -0500 (COT)
Subject: [R] Installing packages without clicking
Message-ID: <2583.172.16.1.31.1139935519.squirrel@sinu.unicordoba.edu.co>

I need to install several (too many) packages from local *.zip
files.

is there any form to do it  without clicking?

I'm asking for a R code that allow me perform these task.



-----------------------------------
Mario Alfonso Morales Rivera.
Profesor Asistente.
Departamento de Matem??ticas y estad??stica.
Universidad de C??rdoba.



From ripley at stats.ox.ac.uk  Tue Feb 14 23:09:21 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 14 Feb 2006 22:09:21 +0000 (GMT)
Subject: [R] Installing packages without clicking
In-Reply-To: <2583.172.16.1.31.1139935519.squirrel@sinu.unicordoba.edu.co>
References: <2583.172.16.1.31.1139935519.squirrel@sinu.unicordoba.edu.co>
Message-ID: <Pine.LNX.4.64.0602142205150.15910@gannet.stats.ox.ac.uk>

On Tue, 14 Feb 2006, Mario Alfonso Morales Rivera wrote:

> I need to install several (too many) packages from local *.zip
> files.
>
> is there any form to do it  without clicking?
>
> I'm asking for a R code that allow me perform these task.

See ?install.packages.

You seem to be using Windows (you did not say).  So the help page says

    repos: character vector, the base URL(s) of the repositories to use,
           i.e., the URL of the CRAN master such as
           '"http://cran.r-project.org"' or its Statlib mirror,
           '"http://lib.stat.cmu.edu/R/CRAN"'. Can be 'NULL' to install
           from local '.zip' files.

and so all you need is

install.packages(c("my1.zip", "my2.zip"), repos = NULL)



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ray at mcs.vuw.ac.nz  Tue Feb 14 23:13:40 2006
From: ray at mcs.vuw.ac.nz (Ray Brownrigg)
Date: Wed, 15 Feb 2006 11:13:40 +1300 (NZDT)
Subject: [R] Installing packages without clicking
Message-ID: <200602142213.k1EMDetP028379@tahi.mcs.vuw.ac.nz>

> I need to install several (too many) packages from local *.zip
> files.
> 
Are you aware of being able to select multiple .zip files at one time
using SHIFT-click or CTRL-click?

> is there any form to do it  without clicking?
> 
> I'm asking for a R code that allow me perform these task.
> 
You could just do what the clicking does, i.e. call the function
install.packages() with appropriate parameters.  See
utils:::menuInstallLocal

Hope this helps,
Ray Brownrigg



From bambang.pramono at gmail.com  Tue Feb 14 23:15:28 2006
From: bambang.pramono at gmail.com (bambang pramono)
Date: Wed, 15 Feb 2006 05:15:28 +0700
Subject: [R] Assumption in Bassic Tobit regression
Message-ID: <830480cb0602141415x71f6ac19u150a6b15c4431027@mail.gmail.com>

Is it assumption Tobit regression like OLS ? :
1. Normal
2. No autocorrelation
3. Homogeneity of variance
4. No Multicolinearity

please make sure me !
I need answer because i want to Judisium/ kompre/thesis test



From Achim.Zeileis at wu-wien.ac.at  Tue Feb 14 23:32:28 2006
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Tue, 14 Feb 2006 23:32:28 +0100
Subject: [R] Assumption in Bassic Tobit regression
In-Reply-To: <830480cb0602141415x71f6ac19u150a6b15c4431027@mail.gmail.com>
References: <830480cb0602141415x71f6ac19u150a6b15c4431027@mail.gmail.com>
Message-ID: <20060214233228.4afb3a4b.Achim.Zeileis@wu-wien.ac.at>

On Wed, 15 Feb 2006 05:15:28 +0700 bambang pramono wrote:

> Is it assumption Tobit regression like OLS ? :
> 1. Normal
> 2. No autocorrelation
> 3. Homogeneity of variance
> 4. No Multicolinearity
> 
> please make sure me !
> I need answer because i want to Judisium/ kompre/thesis test

This is the third time you ask the same question and it did not get
more meaningful! Please consult an econometrics textbook (e.g. Greene
or Cameron & Trivedi) for the theoretical background of tobit models.

Concerning available R implementations of various tobit flavours, you
have already been pointed to a useful thread in the mailing list
archives.
Z

> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From comet137 at optonline.net  Tue Feb 14 11:36:41 2006
From: comet137 at optonline.net (Edgar Urdas)
Date: Tue, 14 Feb 2006 05:36:41 -0500
Subject: [R] How to generate a report with graphics and tables?
Message-ID: <000601c63152$8b80ef40$ff0c5443@hppav>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060214/43333915/attachment.pl

From rainer.hahnekamp at aon.at  Wed Feb 15 00:24:12 2006
From: rainer.hahnekamp at aon.at (Rainer Hahnekamp)
Date: Wed, 15 Feb 2006 00:24:12 +0100
Subject: [R] Simple network diagram
Message-ID: <dstoqs$gk4$1@sea.gmane.org>

Hello,

I'm trying to create a simple network diagram like that on 
http://www.pauck.de/marco/photo/infrared/comparison_of_films/diagram3.gif. 
Unfortunately I've not yet found any function that could do this.

I think this should not be a difficult task since I only need two 
vectors and perhaps the names of the dimensions as data source.

Could somebody help me please?

Greetings,
-Rainer



From spluque at gmail.com  Wed Feb 15 00:59:07 2006
From: spluque at gmail.com (Sebastian Luque)
Date: Tue, 14 Feb 2006 17:59:07 -0600
Subject: [R] analysis of residual sum of squares in R
Message-ID: <8764nhtruc.fsf@arctocephalus.homelinux.org>

Dear R-helpers,

There's a method named as in this message's subject that has been proposed
by:

Chen Y, Jackson DA, Harvey HH (1992) A comparison of von Bertalanffy and
polynomial functions in modelling fish growth data.  Canadian Journal of
Fisheries and Aquatic Sciences 49:1228-1235.

which is used to compare a group of non linear models.  The method tests
whether all the fitted curves describe the same population of data.  The
test is an F ratio:

F = (RSSp - sum(RSSi) / DFp - sum(DFi)) / (sum(RSSi) / sum(DFi))

where the RSS and DF are the residual sum of squares and degrees of
freedom, respectively.  The 'p' and 'i' subscripts denote the pooled or
each individual curve, respectively.  If this procedure has already been
implemented in a package, I'd be happy to hear about it.  A search of the
archives and other sources didn't help.

Cheers,

-- 
Sebastian Luque



From krcabrer at epm.net.co  Wed Feb 15 01:05:02 2006
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Tue, 14 Feb 2006 19:05:02 -0500
Subject: [R] Update problems of Rcmdr?
In-Reply-To: <20060214023643.KOZP18394.tomts5-srv.bellnexxia.net@JohnDesktop8300>
References: <20060214023643.KOZP18394.tomts5-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <43F2702E.3010404@epm.net.co>

Hi R users:

I am not sure how do I  fix it.
But I erase an old R library installation (2.2.0), and also I erase all 
"filexxxx" directories on the
R.2.2.1 library directory, and then I try library(Rcmdr) again and it 
works!.

Any way, how could I trace or debug, so I get a hint whats going on with 
a similar problem in the future?

Thank you very much for your help.

Kenneth

John Fox wrote:

>Dear Kenneth,
>
>After just running update.packages() myself, I can't duplicate this error
>(using R 2.2.1 under Win XP). 
>
>Can you provide a little more information? Are any but the standard packages
>loaded when you issue the library(Rcmdr) command? Have you made any
>modifications to a startup file, such as Rprofile.site?
>
>I'm sorry that I can't offer any additional suggestions at this point.
>
>John
>
>--------------------------------
>John Fox
>Department of Sociology
>McMaster University
>Hamilton, Ontario
>Canada L8S 4M4
>905-525-9140x23604
>http://socserv.mcmaster.ca/jfox 
>-------------------------------- 
>
>  
>
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Kenneth Cabrera
>>Sent: Monday, February 13, 2006 7:54 PM
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] Update problems of Rcmdr?
>>Importance: High
>>
>>Hi R users:
>>
>>I got this messages when I try to use the Rcmdr library, 
>>after I make an update with update.packages() command.
>>I am using R221 in windows environment.
>>
>> > library(Rcmdr)
>>Loading required package: tcltk
>>Loading Tcl/Tk interface ... done
>>Loading required package: car
>>Error in parse(file, n, text, prompt) : syntax error in "*"
>>Error: .onAttach failed in 'attachNamespace'
>>Error: package/namespace load failed for 'Rcmdr'
>>
>>Thank you for your help
>>
>>Kenneth
>>
>>    
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>

From ggrothendieck at gmail.com  Wed Feb 15 01:58:09 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 14 Feb 2006 19:58:09 -0500
Subject: [R] Simple network diagram
In-Reply-To: <dstoqs$gk4$1@sea.gmane.org>
References: <dstoqs$gk4$1@sea.gmane.org>
Message-ID: <971536df0602141658o5d7b1bbbxc1d1a5473c646ed1@mail.gmail.com>

Check out ?stars


On 2/14/06, Rainer Hahnekamp <rainer.hahnekamp at aon.at> wrote:
> Hello,
>
> I'm trying to create a simple network diagram like that on
> http://www.pauck.de/marco/photo/infrared/comparison_of_films/diagram3.gif.
> Unfortunately I've not yet found any function that could do this.
>
> I think this should not be a difficult task since I only need two
> vectors and perhaps the names of the dimensions as data source.
>
> Could somebody help me please?
>
> Greetings,
> -Rainer
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From m.gardiner-garden at garvan.org.au  Wed Feb 15 03:04:21 2006
From: m.gardiner-garden at garvan.org.au (Margaret Gardiner-Garden)
Date: Wed, 15 Feb 2006 13:04:21 +1100
Subject: [R] no convergence using lme
Message-ID: <000001c631d4$2326c910$0ce15e81@dg3qn71s>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060215/67780376/attachment.pl

From jfox at mcmaster.ca  Wed Feb 15 03:22:16 2006
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 14 Feb 2006 21:22:16 -0500
Subject: [R] Update problems of Rcmdr?
In-Reply-To: <43F2702E.3010404@epm.net.co>
Message-ID: <20060215022214.JRDH4713.tomts43-srv.bellnexxia.net@JohnDesktop8300>

Dear Kenneth,

It's very difficult for me to tell from the information that you've given
what the problem might have been. I'm glad, however, that things are working
now.

One thought: Do you have the R_LIBS environment variable set? If so, it's
possible that you were picking up an old version of a package. Perhaps
someone else will come up with a better explanation.

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Kenneth Cabrera
> Sent: Tuesday, February 14, 2006 7:05 PM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Update problems of Rcmdr?
> Importance: High
> 
> Hi R users:
> 
> I am not sure how do I  fix it.
> But I erase an old R library installation (2.2.0), and also I 
> erase all "filexxxx" directories on the
> R.2.2.1 library directory, and then I try library(Rcmdr) 
> again and it works!.
> 
> Any way, how could I trace or debug, so I get a hint whats 
> going on with a similar problem in the future?
> 
> Thank you very much for your help.
> 
> Kenneth
> 
> John Fox wrote:
> 
> >Dear Kenneth,
> >
> >After just running update.packages() myself, I can't duplicate this 
> >error (using R 2.2.1 under Win XP).
> >
> >Can you provide a little more information? Are any but the standard 
> >packages loaded when you issue the library(Rcmdr) command? Have you 
> >made any modifications to a startup file, such as Rprofile.site?
> >
> >I'm sorry that I can't offer any additional suggestions at 
> this point.
> >
> >John
> >
> >--------------------------------
> >John Fox
> >Department of Sociology
> >McMaster University
> >Hamilton, Ontario
> >Canada L8S 4M4
> >905-525-9140x23604
> >http://socserv.mcmaster.ca/jfox
> >--------------------------------
> >
> >  
> >
> >>-----Original Message-----
> >>From: r-help-bounces at stat.math.ethz.ch 
> >>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Kenneth Cabrera
> >>Sent: Monday, February 13, 2006 7:54 PM
> >>To: r-help at stat.math.ethz.ch
> >>Subject: [R] Update problems of Rcmdr?
> >>Importance: High
> >>
> >>Hi R users:
> >>
> >>I got this messages when I try to use the Rcmdr library, 
> after I make 
> >>an update with update.packages() command.
> >>I am using R221 in windows environment.
> >>
> >> > library(Rcmdr)
> >>Loading required package: tcltk
> >>Loading Tcl/Tk interface ... done
> >>Loading required package: car
> >>Error in parse(file, n, text, prompt) : syntax error in "*"
> >>Error: .onAttach failed in 'attachNamespace'
> >>Error: package/namespace load failed for 'Rcmdr'
> >>
> >>Thank you for your help
> >>
> >>Kenneth
> >>
> >>    
> >>
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> >http://www.R-project.org/posting-guide.html
> >
> >  
> >
>



From jonvaz at stud.ibg.uit.no  Wed Feb 15 09:21:40 2006
From: jonvaz at stud.ibg.uit.no (jonvaz@stud.ibg.uit.no)
Date: Wed, 15 Feb 2006 08:21:40 GMT
Subject: [R]  repeated measurements and lme
Message-ID: <200602150817.k1F8Hhjk000727@morgan.ibg.uit.no>

I am trying to do a repeated measurement anova using an lme. I have the
    following variables:
    -ID, the identification of the individual
    -trail, with 2 levels
    -treatment, with 3
    -time, measure 5 times the same individual
    -VCL, the response variable
    I tried the following in R,
    within.gr<-groupedData(VCL~time|ID/treatment/time,data=within)
    summary(lme(fixed=VCL~time*treatment,random=~1,data=within.gr))
    I am not sure if it is correct at all. Can anyone help me? It will be very
    helpful.

    Sincerely, 

    Jonathan
Vaz

---------------------------------------------
This message was sent using Endymion MailMan.
http://www.endymion.com/products/mailman/



From ecoinformatics at gmail.com  Wed Feb 15 09:59:17 2006
From: ecoinformatics at gmail.com (ecoinfo)
Date: Wed, 15 Feb 2006 10:59:17 +0200
Subject: [R] Multiple comparison for circular data
Message-ID: <15f8e67d0602150059q44f74b79m91a9e4f83959ddfa@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060215/a368edb9/attachment.pl

From rdiaz at cnio.es  Wed Feb 15 10:33:58 2006
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Wed, 15 Feb 2006 10:33:58 +0100
Subject: [R] Tranferring R results to word prosessors
In-Reply-To: <43EB9323.8080000@pburns.seanet.com>
References: <5.2.0.8.2.20060209151140.020e69d0@alf.uib.no>
	<1db726800602090933m1e08922bj6b2a56344b80da47@mail.gmail.com>
	<43EB9323.8080000@pburns.seanet.com>
Message-ID: <200602151033.58417.rdiaz@cnio.es>

I started using LyX; it is very straightforward. Then, I started exporting to 
LaTeX and playing around with the LaTeX file (I found it faster than using 
LyX, and could take my file anywhere they had something that could manipulate 
text ---emacs, vim, nedit, whatever).

Googling you'll find _many_ LaTeX tutorials. Which one is best probably 
depends a lot on your preferences and learning style. 

As for books, I find "Guide to LaTeX" by Kopka & Daly (I think now in its 
fourth edition) far easier to use (to learn and for reference) than the 
series of LaTeX books by Goossens et al. and Lamport. (And I only need to 
haul around a single book, not 2 to 5). But then, again, this is surely a 
matter of personal taste.

HTH,

R.


On Thursday 09 February 2006 20:08, Patrick Burns wrote:
> One approach is to use LyX (http://www.lyx.org/).
> This is a lot like using Word or other word processors
> but it creates LaTeX.  You probably won't need to
> know anything about TeX for a long time unless you
> are doing really weird things.
>
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
>
> roger bos wrote:
> >Yeah, but I don't understand LaTeX at all.  Can you point me to a good
> >beginners guide?
> >
> >Thanks,
> >
> >Roger
> >
> >On 2/9/06, Barry Rowlingson <B.Rowlingson at lancaster.ac.uk> wrote:
> >>Tom Backer Johnsen wrote:
> >>>I have just started looking at R, and are getting more and more
> >>
> >>irritated
> >>
> >>>at myself for not having done that before.
> >>>
> >>>However, one of the things I have not found in the documentation is some
> >>>way of preparing output from R for convenient formatting into something
> >>>like MS Word.
> >>
> >>Well whatever you do, don't start looking at LaTeX, because that will
> >>get you even more irritated at yourself for not having done it before.
> >>
> >>LaTeX is to Word as R is to what? SPSS?
> >>
> >>I've still not seen a pretty piece of mathematics - or even text - in
> >>Word.
> >>
> >>Barry
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide!
> >>http://www.R-project.org/posting-guide.html
> >
> >	[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Ram??n D??az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol??gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern??ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://ligarto.org/rdiaz
PGP KeyID: 0xE89B3462
(http://ligarto.org/rdiaz/0xE89B3462.asc)



**NOTA DE CONFIDENCIALIDAD** Este correo electr??nico, y en s...{{dropped}}



From comtech.usa at gmail.com  Wed Feb 15 10:54:01 2006
From: comtech.usa at gmail.com (Michael)
Date: Wed, 15 Feb 2006 01:54:01 -0800
Subject: [R] a basic question about standardization?
Message-ID: <b1f16d9d0602150154x693133d3qff1842859c88920f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060215/95a13b0a/attachment.pl

From Markus.Preisetanz at clientvela.com  Wed Feb 15 11:13:37 2006
From: Markus.Preisetanz at clientvela.com (Markus Preisetanz)
Date: Wed, 15 Feb 2006 11:13:37 +0100
Subject: [R] aggregate data.frame using column-specific functions
Message-ID: <79799E69EA1DA246A51F983B5663BEA2CD34DB@server2.hq.clientvela.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060215/0bc9f94a/attachment.pl

From Laetitia.Marisa at cgm.cnrs-gif.fr  Wed Feb 15 11:20:55 2006
From: Laetitia.Marisa at cgm.cnrs-gif.fr (Laetitia Marisa)
Date: Wed, 15 Feb 2006 11:20:55 +0100
Subject: [R] Setting intial path under windows to MyComputer in Interactive
 file browser
Message-ID: <43F30087.9080903@cgm.cnrs-gif.fr>

Hello everyone,

How can I specify in tcltk file browser the initial directory to 
"MyComputer" in Windows where Drives and Partition are accessible?

And just a little question if anyone knows, is there a way to use the 
function choose.files under windows to select a directory?

Thanks a lot for your help.

Laetitia.



From jacques.veslot at cirad.fr  Wed Feb 15 11:19:37 2006
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Wed, 15 Feb 2006 14:19:37 +0400
Subject: [R] aggregate data.frame using column-specific functions
In-Reply-To: <79799E69EA1DA246A51F983B5663BEA2CD34DB@server2.hq.clientvela.net>
References: <79799E69EA1DA246A51F983B5663BEA2CD34DB@server2.hq.clientvela.net>
Message-ID: <43F30039.5030905@cirad.fr>

you can use mapply()...

z <- as.data.frame(matrix(1:3,3,3,T))
mapply(function(x,y) x(y), c(sum,prod,sum), z)


Markus Preisetanz a ??crit :

>Dear Colleagues, 
>
> 
>
>does anybody know how to aggregate a data.frame using different functions for different columns?
>
> 
>
>Sincerely
>
> 
>
>___________________
>
>Markus Preisetanz
>
>Consultant
>
> 
>
>Client Vela GmbH
>
>Albert-Ro??haupter-Str. 32
>
>81369 M??nchen
>
>fon:          +49 (0) 89 742 17-113
>
>fax:          +49 (0) 89 742 17-150
>
>mailto:markus.preisetanz at clientvela.com <mailto:markus.preisetanz at clientvela.com> 
>
>
>
>Diese E-Mail enth??lt vertrauliche und/oder rechtlich gesch??tzte Informationen. Wenn Sie nicht der richtige Adressat sind oder diese E-Mail irrt??mlich erhalten haben, informieren Sie bitte sofort den Absender und vernichten Sie diese Mail. Das unerlaubte Kopieren sowie die unbefugte Weitergabe dieser E-Mail ist nicht gestattet.
>
>This e-mail may contain confidential and/or privileged infor...{{dropped}}
>
>  
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From bitwrit at ozemail.com.au  Thu Feb 16 03:56:37 2006
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Wed, 15 Feb 2006 21:56:37 -0500
Subject: [R] Simple network diagram
In-Reply-To: <dstoqs$gk4$1@sea.gmane.org>
References: <dstoqs$gk4$1@sea.gmane.org>
Message-ID: <43F3E9E5.9030904@ozemail.com.au>

Rainer Hahnekamp wrote:
> Hello,
> 
> I'm trying to create a simple network diagram like that on 
> http://www.pauck.de/marco/photo/infrared/comparison_of_films/diagram3.gif. 
> Unfortunately I've not yet found any function that could do this.
> 
> I think this should not be a difficult task since I only need two 
> vectors and perhaps the names of the dimensions as data source.
> 
Have a look at the radial.plot function in the plotrix package. While 
the diagram will be on a circular grid, it might do what you want.

Jim



From jonvaz at stud.ibg.uit.no  Wed Feb 15 12:02:30 2006
From: jonvaz at stud.ibg.uit.no (jonvaz@stud.ibg.uit.no)
Date: Wed, 15 Feb 2006 11:02:30 GMT
Subject: [R]  repeated measurements and lme
Message-ID: <200602151058.k1FAwWPX001829@morgan.ibg.uit.no>

I am trying to do a repeated measurement anova using an lme. I have the
    following variables:
    -ID, the identification of the individual
    -trail, with 2 levels
    -treatment, with 3
    -time, measure 5 times the same individual
    -VCL, the response variable
    I tried the following in R,
    within.gr<-groupedData(VCL~time|ID/treatment/time,data=within)
    summary(lme(fixed=VCL~time*treatment,random=~1,data=within.gr))
    I am not sure if it is correct at all. Can anyone help me? It will be very
    helpful.
    Sincerely,
    Jonathan
   
Vaz

---------------------------------------------
This message was sent using Endymion MailMan.
http://www.endymion.com/products/mailman/



From dimitris.rizopoulos at med.kuleuven.be  Wed Feb 15 12:14:31 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 15 Feb 2006 12:14:31 +0100
Subject: [R] repeated measurements and lme
References: <200602151058.k1FAwWPX001829@morgan.ibg.uit.no>
Message-ID: <004c01c63220$fe757290$0540210a@www.domain>

before fitting any model you should first think which is the question 
you want to answer; a possible model is:

fit <- lme(VCL ~ time * treatment + trail, random = ~ 1 | ID, data = 
within)

you don't have to use groupedData(); you can directly use lme().

note: you have also consider how you want to put 'time' in your model: 
factor or continuous?

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: <jonvaz at stud.ibg.uit.no>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, February 15, 2006 12:02 PM
Subject: [R] repeated measurements and lme


>I am trying to do a repeated measurement anova using an lme. I have 
>the
>    following variables:
>    -ID, the identification of the individual
>    -trail, with 2 levels
>    -treatment, with 3
>    -time, measure 5 times the same individual
>    -VCL, the response variable
>    I tried the following in R,
>    within.gr<-groupedData(VCL~time|ID/treatment/time,data=within)
>    summary(lme(fixed=VCL~time*treatment,random=~1,data=within.gr))
>    I am not sure if it is correct at all. Can anyone help me? It 
> will be very
>    helpful.
>    Sincerely,
>    Jonathan
>
> Vaz
>
> ---------------------------------------------
> This message was sent using Endymion MailMan.
> http://www.endymion.com/products/mailman/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From islandboy1982 at yahoo.com  Wed Feb 15 12:20:27 2006
From: islandboy1982 at yahoo.com (oliver wee)
Date: Wed, 15 Feb 2006 03:20:27 -0800 (PST)
Subject: [R] question about the results given by the Box.test?
Message-ID: <20060215112027.25970.qmail@web33211.mail.mud.yahoo.com>

Hello, I am using the Ljung Box test in R to compute
if the resiudals of my fitted model is random or not.

I am not sure though what the results mean, I have
looked at various sources on the internet and have
come up with contrasting explanations (mainly because
these info deal with different program languages, like
SAS, SPSS, etc).

I know that my residuals should appropriate white
noise( is random) since a check of its ACF shows it to
be so (signifant correlation only at lag 1, decays
very quickly to zero).

But I am not sure how to interpret the ljung-box
result given by R.

To check for randomness of residuals, should the
p-value be small or large? How small and how large?
And at what lags should I check for the randomness of
the residuals? Is a p-value > 0.05 (or < 0.05) enough?
What if I have a very large p-value of 0.9796 at lag
1, but its value is 0.0139 at lag 8? 

For example, here's what I got for the first 10 lags
of the residuals I'm testing:
-------------------
 Box.test(SP500DataSetFitMA2$residuals, type =
"Ljung", lag =1)

        Box-Ljung test

data:  SP500DataSetFitMA2$residuals 
X-squared = 7e-04, df = 1, p-value = 0.9796

> Box.test(SP500DataSetFitMA2$residuals, type =
"Ljung", lag =2)

        Box-Ljung test

data:  SP500DataSetFitMA2$residuals 
X-squared = 0.1088, df = 2, p-value = 0.947

> Box.test(SP500DataSetFitMA2$residuals, type =
"Ljung", lag =3)

        Box-Ljung test

data:  SP500DataSetFitMA2$residuals 
X-squared = 1.4179, df = 3, p-value = 0.7014

> Box.test(SP500DataSetFitMA2$residuals, type =
"Ljung", lag =4)

        Box-Ljung test

data:  SP500DataSetFitMA2$residuals 
X-squared = 3.866, df = 4, p-value = 0.4244

> Box.test(SP500DataSetFitMA2$residuals, type =
"Ljung", lag =5)

        Box-Ljung test

data:  SP500DataSetFitMA2$residuals 
X-squared = 6.0251, df = 5, p-value = 0.3038

> Box.test(SP500DataSetFitMA2$residuals, type =
"Ljung", lag =6)

        Box-Ljung test

data:  SP500DataSetFitMA2$residuals 
X-squared = 12.11, df = 6, p-value = 0.05956

> Box.test(SP500DataSetFitMA2$residuals, type =
"Ljung", lag =7)

        Box-Ljung test

data:  SP500DataSetFitMA2$residuals 
X-squared = 13.0307, df = 7, p-value = 0.07137

> Box.test(SP500DataSetFitMA2$residuals, type =
"Ljung", lag =8)

        Box-Ljung test

data:  SP500DataSetFitMA2$residuals 
X-squared = 19.1766, df = 8, p-value = 0.01394

> Box.test(SP500DataSetFitMA2$residuals, type =
"Ljung", lag =9)

        Box-Ljung test

data:  SP500DataSetFitMA2$residuals 
X-squared = 19.6753, df = 9, p-value = 0.02003

> Box.test(SP500DataSetFitMA2$residuals, type =
"Ljung", lag =10)

        Box-Ljung test

data:  SP500DataSetFitMA2$residuals 
X-squared = 19.7124, df = 10, p-value = 0.03209

--------------

I know this is not really a programming question, so I
apologize if it is inappropriate or if the question is
too elementary.

Thank you very much for your help.



From pmt1rew at leeds.ac.uk  Wed Feb 15 12:36:35 2006
From: pmt1rew at leeds.ac.uk (pmt1rew@leeds.ac.uk)
Date: Wed, 15 Feb 2006 11:36:35 +0000
Subject: [R] wilcox.test returned estimates
Message-ID: <1140003395.e05fb852a6490@webmail5.leeds.ac.uk>

Hi all,

I have being using wilcox.test to test for differences between 2 independent
samples.  I had understood the difference in location to be conventionally the
difference in the sample medians however this is not the case when implemented
in R.  I have tied ranks and therefore non-exact p-value and confidence
intervals are calculated due to the normal approximation.  But what exactly is
this normal approximation i.e. how is it involved in estimating the location
difference?

Further, is it then wrong to refer to the difference in location as the
difference between the medians?  Does anyone have a more appropriate
description?

Thanks

Rebecca



From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Feb 15 12:59:01 2006
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 15 Feb 2006 12:59:01 +0100 (CET)
Subject: [R] wilcox.test returned estimates
In-Reply-To: <1140003395.e05fb852a6490@webmail5.leeds.ac.uk>
References: <1140003395.e05fb852a6490@webmail5.leeds.ac.uk>
Message-ID: <Pine.LNX.4.64.0602151252480.6220@artemis.imbe.med.uni-erlangen.de>


On Wed, 15 Feb 2006, pmt1rew at leeds.ac.uk wrote:

> Hi all,
>
> I have being using wilcox.test to test for differences between 2 independent
> samples.  I had understood the difference in location to be conventionally the
> difference in the sample medians however this is not the case when implemented
> in R. I have tied ranks and therefore non-exact p-value and confidence
> intervals are calculated due to the normal approximation.  But what exactly is
> this normal approximation i.e. how is it involved in estimating the location
> difference?

the reference distribution is not involved in _estimating_ the difference 
in location. `wilcox.test' implements the Hodges-Lehmann estimator:

from `stats/R/wilcox.test.R'

                 ## Exact confidence interval for the location parameter
                 ## mean(x) - mean(y) in the two-sample case (cf. the
                 ## one-sample case).
                 alpha <- 1 - conf.level
                 diffs <- sort(outer(x, y, "-"))
                 ...
                 ESTIMATE <- median(diffs)
                 names(ESTIMATE) <- "difference in location"

which simply is the median of all pairwise differences.

However, the usual normal approximation to the exact conditional 
distribution (in case of ties) of the Wilcoxon-Mann-Whitney statistic 
(see Hajek, Sidak, Sen for example) is involved in computing a confidence 
interval for the difference in location.

Hope that helps,

Torsten

>
> Further, is it then wrong to refer to the difference in location as the
> difference between the medians?  Does anyone have a more appropriate
> description?
>
> Thanks
>
> Rebecca
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From pburns at pburns.seanet.com  Wed Feb 15 13:17:24 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Wed, 15 Feb 2006 12:17:24 +0000
Subject: [R] question about the results given by the Box.test?
In-Reply-To: <20060215112027.25970.qmail@web33211.mail.mud.yahoo.com>
References: <20060215112027.25970.qmail@web33211.mail.mud.yahoo.com>
Message-ID: <43F31BD4.7010307@pburns.seanet.com>

Hopefully the test is the same no matter what software
you are using.  A small p-value is an indication that there
is structure in the data.  So in your case there is no
indication of autocorrelation up to lag 5, but it appears
that there might be something going on at around lags 6
to 9.

"How small is too small?" is not a reasonable question
to ask in general.  It depends on how likely it is that
there is structure near that lag, how much data you have,
how important it is to capture all of the structure in your
model versus the harm of overfitting, ...

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

oliver wee wrote:

>Hello, I am using the Ljung Box test in R to compute
>if the resiudals of my fitted model is random or not.
>
>I am not sure though what the results mean, I have
>looked at various sources on the internet and have
>come up with contrasting explanations (mainly because
>these info deal with different program languages, like
>SAS, SPSS, etc).
>
>I know that my residuals should appropriate white
>noise( is random) since a check of its ACF shows it to
>be so (signifant correlation only at lag 1, decays
>very quickly to zero).
>
>But I am not sure how to interpret the ljung-box
>result given by R.
>
>To check for randomness of residuals, should the
>p-value be small or large? How small and how large?
>And at what lags should I check for the randomness of
>the residuals? Is a p-value > 0.05 (or < 0.05) enough?
>What if I have a very large p-value of 0.9796 at lag
>1, but its value is 0.0139 at lag 8? 
>
>For example, here's what I got for the first 10 lags
>of the residuals I'm testing:
>-------------------
> Box.test(SP500DataSetFitMA2$residuals, type =
>"Ljung", lag =1)
>
>        Box-Ljung test
>
>data:  SP500DataSetFitMA2$residuals 
>X-squared = 7e-04, df = 1, p-value = 0.9796
>
>  
>
>>Box.test(SP500DataSetFitMA2$residuals, type =
>>    
>>
>"Ljung", lag =2)
>
>        Box-Ljung test
>
>data:  SP500DataSetFitMA2$residuals 
>X-squared = 0.1088, df = 2, p-value = 0.947
>
>  
>
>>Box.test(SP500DataSetFitMA2$residuals, type =
>>    
>>
>"Ljung", lag =3)
>
>        Box-Ljung test
>
>data:  SP500DataSetFitMA2$residuals 
>X-squared = 1.4179, df = 3, p-value = 0.7014
>
>  
>
>>Box.test(SP500DataSetFitMA2$residuals, type =
>>    
>>
>"Ljung", lag =4)
>
>        Box-Ljung test
>
>data:  SP500DataSetFitMA2$residuals 
>X-squared = 3.866, df = 4, p-value = 0.4244
>
>  
>
>>Box.test(SP500DataSetFitMA2$residuals, type =
>>    
>>
>"Ljung", lag =5)
>
>        Box-Ljung test
>
>data:  SP500DataSetFitMA2$residuals 
>X-squared = 6.0251, df = 5, p-value = 0.3038
>
>  
>
>>Box.test(SP500DataSetFitMA2$residuals, type =
>>    
>>
>"Ljung", lag =6)
>
>        Box-Ljung test
>
>data:  SP500DataSetFitMA2$residuals 
>X-squared = 12.11, df = 6, p-value = 0.05956
>
>  
>
>>Box.test(SP500DataSetFitMA2$residuals, type =
>>    
>>
>"Ljung", lag =7)
>
>        Box-Ljung test
>
>data:  SP500DataSetFitMA2$residuals 
>X-squared = 13.0307, df = 7, p-value = 0.07137
>
>  
>
>>Box.test(SP500DataSetFitMA2$residuals, type =
>>    
>>
>"Ljung", lag =8)
>
>        Box-Ljung test
>
>data:  SP500DataSetFitMA2$residuals 
>X-squared = 19.1766, df = 8, p-value = 0.01394
>
>  
>
>>Box.test(SP500DataSetFitMA2$residuals, type =
>>    
>>
>"Ljung", lag =9)
>
>        Box-Ljung test
>
>data:  SP500DataSetFitMA2$residuals 
>X-squared = 19.6753, df = 9, p-value = 0.02003
>
>  
>
>>Box.test(SP500DataSetFitMA2$residuals, type =
>>    
>>
>"Ljung", lag =10)
>
>        Box-Ljung test
>
>data:  SP500DataSetFitMA2$residuals 
>X-squared = 19.7124, df = 10, p-value = 0.03209
>
>--------------
>
>I know this is not really a programming question, so I
>apologize if it is inappropriate or if the question is
>too elementary.
>
>Thank you very much for your help.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From Felipe.Martinez at uclm.es  Wed Feb 15 13:39:03 2006
From: Felipe.Martinez at uclm.es (=?ISO-8859-15?Q?Felipe_Mart=EDnez-Pastor?=)
Date: Wed, 15 Feb 2006 13:39:03 +0100
Subject: [R] Pairwise comparison after repeated measures ANOVA
Message-ID: <43F320E7.8080907@uclm.es>

I am analyzing some data obtained after measuring some parameters at
different times in samples obtained from many subjects. The model is
quite simple: aov(parameter ~ Time + Error(Subject/Time))

Now I want to make a pairwise comparison between the levels of Time.
However, I have not find how to do such a thing. I cannot use TukeyHSD
or pairwise.t.test, I supposse. Maybe using contrasts?

Could you aim me at some kind of information? All I have found is
information on ANOVA, but not how to compare the levels of the factors
afterwards.

Maybe I simply do not understand how this really works, my background is
not very deep in statistics.
Thank you.

Felipe

--------------------oOo--------------------
Felipe Mart??nez Pastor, Ph. D.
Ciencia y Tecnolog??a Agroforestal
ETSIA-UCLM
Av. Espa??a s/n
02071-Albacete (Spain)
Phone: +34 967 599 200+2581
Fax:   +34 967 599 238+2081
Mobile: +34 687 365 362
e-mail: Felipe.Martinez at uclm.es
Jabber: felipe.martinez at jabberes.org
website: http://www.germplasm.all.at



-- 
Ning??n investigador sin contrato.
Employment rights for Spanish junior researchers.
	http://www.precarios.org



From islandboy1982 at yahoo.com  Wed Feb 15 13:41:23 2006
From: islandboy1982 at yahoo.com (oliver wee)
Date: Wed, 15 Feb 2006 04:41:23 -0800 (PST)
Subject: [R] Generating random walks
Message-ID: <20060215124123.96570.qmail@web33207.mail.mud.yahoo.com>

Hello, here is another question, how do I generate
random walk models in R? Basically, I need an AR(1)
model with the phi^1 value equal to 1:

Yt = c + Yt-1 + E

where E is random white noise.

I tried using the arima.sim command:

arima.sim(list(ar=c(1)), n = 1000, rand.gen = rnorm)

but got this error since the model I am generating is
not stationary:

Error in arima.sim(list(ar = c(1)), n = 1000, rand.gen
= rnorm) : 
        'ar' part of model is not stationary

I found arima.sim sufficient for generating stationary
models, but how about non-stationary models?

Thanks again for your help.



From azzalini at stat.unipd.it  Wed Feb 15 13:56:54 2006
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Wed, 15 Feb 2006 13:56:54 +0100
Subject: [R] bivariate normal distribution
In-Reply-To: <1EC991FAE7B1EC4B9B225DF7DF1F9F2908D3C1@MAILSERVER01.MED.HARVARD.EDU>
References: <1EC991FAE7B1EC4B9B225DF7DF1F9F2908D3C1@MAILSERVER01.MED.HARVARD.EDU>
Message-ID: <20060215135654.18326eb0.azzalini@stat.unipd.it>

On Mon, 13 Feb 2006 17:11:30 -0500, He, Yulei wrote:

HY> Hi, there.
HY> 
HY>  
HY> 
HY> Does anyone know the R function for calculating the cdf of
HY> bivariate normal distribution function?
HY> 
HY>  

choose among packages "mvtnorm" and "mnormt" the one best suited
for your purpose

best wishes,

Adelchi Azzalini



From ripley at stats.ox.ac.uk  Wed Feb 15 13:56:54 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 15 Feb 2006 12:56:54 +0000 (GMT)
Subject: [R] Setting intial path under windows to MyComputer in
 Interactive file browser
In-Reply-To: <43F30087.9080903@cgm.cnrs-gif.fr>
References: <43F30087.9080903@cgm.cnrs-gif.fr>
Message-ID: <Pine.LNX.4.64.0602151235420.23306@gannet.stats.ox.ac.uk>

On Wed, 15 Feb 2006, Laetitia Marisa wrote:

> Hello everyone,
>
> How can I specify in tcltk file browser the initial directory to
> "MyComputer" in Windows where Drives and Partition are accessible?

That is a Tk question, not an R question.  I presume you might mean via
tk_getOpenFile -initialdir ?   It's a subtle one, as 'My Computer' (sic, 
with a space') is not an actual directory and you need to ask elsewhere.

> And just a little question if anyone knows, is there a way to use the
> function choose.files under windows to select a directory?

Only if there is a file in the directory.  Then select any file and use 
dirname() on the result.

R-devel has a function choose.dir that makes this easier using the same 
widget used for the 'Change dir ...' item on RGui's file menu.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pcampbell at econ.bbk.ac.uk  Wed Feb 15 14:01:20 2006
From: pcampbell at econ.bbk.ac.uk (Phineas Campbell)
Date: Wed, 15 Feb 2006 13:01:20 -0000
Subject: [R] Generating random walks
In-Reply-To: <20060215124123.96570.qmail@web33207.mail.mud.yahoo.com>
Message-ID: <NGECIFANPOJAGABBAEAPMEHIFJAA.pcampbell@econ.bbk.ac.uk>


cumsum(rnorm(100)+c)

HTH

phineas

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of oliver wee
Sent: Wednesday, February 15, 2006 12:41 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Generating random walks


Hello, here is another question, how do I generate
random walk models in R? Basically, I need an AR(1)
model with the phi^1 value equal to 1:

Yt = c + Yt-1 + E

where E is random white noise.

I tried using the arima.sim command:

arima.sim(list(ar=c(1)), n = 1000, rand.gen = rnorm)

but got this error since the model I am generating is
not stationary:

Error in arima.sim(list(ar = c(1)), n = 1000, rand.gen
= rnorm) :
        'ar' part of model is not stationary

I found arima.sim sufficient for generating stationary
models, but how about non-stationary models?

Thanks again for your help.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ggrothendieck at gmail.com  Wed Feb 15 14:05:41 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 15 Feb 2006 08:05:41 -0500
Subject: [R] Setting intial path under windows to MyComputer in
	Interactive file browser
In-Reply-To: <43F30087.9080903@cgm.cnrs-gif.fr>
References: <43F30087.9080903@cgm.cnrs-gif.fr>
Message-ID: <971536df0602150505t5f43b123q2a6c7b09a6cfec2b@mail.gmail.com>

On 2/15/06, Laetitia Marisa <Laetitia.Marisa at cgm.cnrs-gif.fr> wrote:
> Hello everyone,
>
> How can I specify in tcltk file browser the initial directory to
> "MyComputer" in Windows where Drives and Partition are accessible?
>
> And just a little question if anyone knows, is there a way to use the
> function choose.files under windows to select a directory?

Use:

   tkchooseDirectory()

>
> Thanks a lot for your help.
>
> Laetitia.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Wed Feb 15 15:03:56 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 15 Feb 2006 09:03:56 -0500
Subject: [R] How to generate a report with graphics and tables?
In-Reply-To: <000601c63152$8b80ef40$ff0c5443@hppav>
References: <000601c63152$8b80ef40$ff0c5443@hppav>
Message-ID: <971536df0602150603g2aa6867ame1754cc26c38e2a@mail.gmail.com>

Read up about vignettes and Sweave which allows
one to intersperse R code and latex.

On 2/14/06, Edgar Urdas <comet137 at optonline.net> wrote:
> how do i perform the stuff i just recorded?!



From dieter.menne at menne-biomed.de  Wed Feb 15 16:06:36 2006
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Wed, 15 Feb 2006 15:06:36 +0000 (UTC)
Subject: [R] Pairwise comparison after repeated measures ANOVA
References: <43F320E7.8080907@uclm.es>
Message-ID: <loom.20060215T154856-79@post.gmane.org>

Felipe Martnez-Pastor <Felipe.Martinez <at> uclm.es> writes:

> 
> I am analyzing some data obtained after measuring some parameters at
> different times in samples obtained from many subjects. The model is
> quite simple: aov(parameter ~ Time + Error(Subject/Time))
> 
> Now I want to make a pairwise comparison between the levels of Time.
> However, I have not find how to do such a thing. I cannot use TukeyHSD
> or pairwise.t.test, I supposse. Maybe using contrasts?
> 

I would suggest that you use lme from package nlme for this type of a problem, 
because it provides a MUCH better toolbox fro what noadays is called mixed-
effect models. And get the book by Pinheiro/Bates (Mixed-Effect Models in S and 
S-PLUS), which is full of practical examples of this type.

With the results of <lme>, you can use <estimable> from package gmodels to 
estimate contrasts, and p.adjust to adjust for multiple comparison. However, as 
you parameter is called Time, you should really rethink if this is the right 
way to go. Why not treat Time as and continuous variable, effectively 
estimating a slope? Or at least as an ordered variable? I know from my clients 
that, after measuring a parameter 6 instances in time, they insist on a star-
spangled list of all 15 pairwise comparisons. If they do, I take out  
Bonferroni's Iron Claw even if I know better methods.

The question: "At what time intervals is the difference significant" is mostly 
nonsense.

Try to rephrase as "Is there a significant linear trend in time?". Would adding 
a quadratic component improve the quality of the fit (use AIC for this, see 
Pinheiro/Bates or Venables/Ripley). In many biological applications I know, a 
linear trend is perfectly fine, and it often has an easy interpretation. You 
only have to fight "but it's not linear" faculty, who mostly would not object 
to computing the mean without ever thinking to ask "but it's not constant".

Soapbox off. You see, I just had a discussion on the subject with a client.

Dieter



From pcampbell at econ.bbk.ac.uk  Wed Feb 15 16:11:28 2006
From: pcampbell at econ.bbk.ac.uk (Phineas Campbell)
Date: Wed, 15 Feb 2006 15:11:28 -0000
Subject: [R] Generating random walks
In-Reply-To: <NGECIFANPOJAGABBAEAPMEHIFJAA.pcampbell@econ.bbk.ac.uk>
Message-ID: <NGECIFANPOJAGABBAEAPEEHKFJAA.pcampbell@econ.bbk.ac.uk>

In retrospect

	x<-cumsum(rnorm(n=100, mean=c))

will probably work quicker

Phineas



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Phineas Campbell
Sent: Wednesday, February 15, 2006 1:01 PM
To: 'R-Help
Subject: Re: [R] Generating random walks



cumsum(rnorm(100)+c)

HTH

phineas

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of oliver wee
Sent: Wednesday, February 15, 2006 12:41 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Generating random walks


Hello, here is another question, how do I generate
random walk models in R? Basically, I need an AR(1)
model with the phi^1 value equal to 1:

Yt = c + Yt-1 + E

where E is random white noise.

I tried using the arima.sim command:

arima.sim(list(ar=c(1)), n = 1000, rand.gen = rnorm)

but got this error since the model I am generating is
not stationary:

Error in arima.sim(list(ar = c(1)), n = 1000, rand.gen
= rnorm) :
        'ar' part of model is not stationary

I found arima.sim sufficient for generating stationary
models, but how about non-stationary models?

Thanks again for your help.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From jjrr at wi.rr.com  Wed Feb 15 16:15:48 2006
From: jjrr at wi.rr.com (Joseph Retzer)
Date: Wed, 15 Feb 2006 09:15:48 -0600
Subject: [R] 2 variable partial dependence plot for Random Forest
Message-ID: <000301c63242$b436fa10$6401a8c0@Cerberus>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060215/fb3e0a34/attachment.pl

From justin_bem at yahoo.fr  Wed Feb 15 17:09:32 2006
From: justin_bem at yahoo.fr (justin bem)
Date: Wed, 15 Feb 2006 17:09:32 +0100 (CET)
Subject: [R] aggregate data.frame using column-specific functions
In-Reply-To: <79799E69EA1DA246A51F983B5663BEA2CD34DB@server2.hq.clientvela.net>
Message-ID: <20060215160932.58610.qmail@web25701.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060215/813400c0/attachment.pl

From rodrigo.tsai at gmail.com  Wed Feb 15 17:22:48 2006
From: rodrigo.tsai at gmail.com (Rodrigo Tsai)
Date: Wed, 15 Feb 2006 14:22:48 -0200
Subject: [R] common title for graphs in a (1x2) layout
Message-ID: <a9801f600602150822j57421ab9n304432297dead02b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060215/2cdee060/attachment.pl

From abunn at whrc.org  Wed Feb 15 18:28:17 2006
From: abunn at whrc.org (Andy Bunn)
Date: Wed, 15 Feb 2006 12:28:17 -0500
Subject: [R] shading under the lines in a lattice xyplot?
Message-ID: <NEBBIPHDAMMOKDKPOFFIOELJDPAA.abunn@whrc.org>

In the lattice plot below I want to fill-in the areas under each lines that
are greater than zero in gray. Is there a straightforward way to go about
this? Thanks, Andy

library(lattice)
foo <- data.frame(Yrs=rep(1:50,4), Y=rnorm(200),
                  Id=unlist(lapply(letters[1:4],rep,50)))
xyplot(Y~Yrs|Id, data = foo,
       panel = function(x,y) {
          panel.abline(h=0)
          panel.lines(x,y, col = "black")
       })



From heinrichs at dkrz.de  Wed Feb 15 18:43:20 2006
From: heinrichs at dkrz.de (Anne Katrin Heinrichs)
Date: Wed, 15 Feb 2006 18:43:20 +0100
Subject: [R] labelling dots in plots
In-Reply-To: <mailman.9.1139914801.6090.r-help@stat.math.ethz.ch>
Message-ID: <BAEPLAOEEMNCBLKKCPIEMELHCBAA.heinrichs@dkrz.de>

Hello,

I would like to label outliers (or all dots) in a plot

plot(as.matrix(ValAddInd_byYear), as.matrix(Cons_Elec_Ind_byYear))

ideally by the 30 different row.names, but anything else (x or y values, for example)
would already be helpful.
I've tried various things with pch, but they didn't work and I can't find anything else.

Any hint appreciated!
Thanks,

Katrin



From gerifalte28 at hotmail.com  Wed Feb 15 18:46:16 2006
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Wed, 15 Feb 2006 17:46:16 +0000
Subject: [R] labelling dots in plots
In-Reply-To: <BAEPLAOEEMNCBLKKCPIEMELHCBAA.heinrichs@dkrz.de>
Message-ID: <BAY103-F323E2A3DCF0BFED0D33A55A6FA0@phx.gbl>

Take a look at ?identify

Francisco


>From: "Anne Katrin Heinrichs" <heinrichs at dkrz.de>
>To: <r-help at stat.math.ethz.ch>
>Subject: [R] labelling dots in plots
>Date: Wed, 15 Feb 2006 18:43:20 +0100
>
>Hello,
>
>I would like to label outliers (or all dots) in a plot
>
>plot(as.matrix(ValAddInd_byYear), as.matrix(Cons_Elec_Ind_byYear))
>
>ideally by the 30 different row.names, but anything else (x or y values, 
>for example)
>would already be helpful.
>I've tried various things with pch, but they didn't work and I can't find 
>anything else.
>
>Any hint appreciated!
>Thanks,
>
>Katrin
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From Mike.Prager at noaa.gov  Wed Feb 15 18:54:56 2006
From: Mike.Prager at noaa.gov (Michael H. Prager)
Date: Wed, 15 Feb 2006 12:54:56 -0500
Subject: [R] common title for graphs in a (1x2) layout
In-Reply-To: <a9801f600602150822j57421ab9n304432297dead02b@mail.gmail.com>
References: <a9801f600602150822j57421ab9n304432297dead02b@mail.gmail.com>
Message-ID: <43F36AF0.1030005@noaa.gov>

Something like this?

def.par <- par(no.readonly = TRUE)
nf <- layout(matrix(c(1,2), 1,2,byrow=T), c(1,1), c(1,1), T)
plot(rnorm(10,0,1))
plot(rnorm(10,0,0.1))
mtext("Common Title", adj=-1.0, line=2)
par(def.par)


on 2/15/2006 11:22 AM Rodrigo Tsai said the following:
> Dear all,
>
> Many thanks for the help suggesting the use of "layout" cmd.
>
> How to insert a title in a 1x2 layout? The title is related to both graphs.
> I looked for it in help, unsuccessfully.
>
> Thanks in advance,
> Rodrigo.
>
> my reproductible code:
> ----------------------------------------------------------------------
>
> def.par <- par(no.readonly = TRUE)
>
> nf <- layout(matrix(c(1,2), 1,2,byrow=T), c(1,1), c(1,1), T)
>
> layout.show(nf)
>
>
>
> plot(rnorm(10,0,1))
>
> plot(rnorm(10,0,0.1))
>
> par(def.par)
>
> ----------------------------------------------------------------------
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>   

-- 

Michael Prager, Ph.D.
Population Dynamics Team, NMFS SE Fisheries Science Center
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516
http://shrimp.ccfhrb.noaa.gov/~mprager/
Opinions expressed are personal, not official.  No
government endorsement of any product is made or implied.



From ccleland at optonline.net  Wed Feb 15 19:00:08 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 15 Feb 2006 13:00:08 -0500
Subject: [R] common title for graphs in a (1x2) layout
In-Reply-To: <a9801f600602150822j57421ab9n304432297dead02b@mail.gmail.com>
References: <a9801f600602150822j57421ab9n304432297dead02b@mail.gmail.com>
Message-ID: <43F36C28.6000701@optonline.net>

Rodrigo Tsai wrote:
> Dear all,
> 
> Many thanks for the help suggesting the use of "layout" cmd.
> 
> How to insert a title in a 1x2 layout? The title is related to both graphs.
> I looked for it in help, unsuccessfully.
> 
> Thanks in advance,
> Rodrigo.
> 
> my reproductible code:
> ----------------------------------------------------------------------
> 
> def.par <- par(no.readonly = TRUE)
> 
> nf <- layout(matrix(c(1,2), 1,2,byrow=T), c(1,1), c(1,1), T)
> 
> layout.show(nf)
> 
> 
> 
> plot(rnorm(10,0,1))
> 
> plot(rnorm(10,0,0.1))
> 
> par(def.par)
> 
> ----------------------------------------------------------------------
> 
> 	[[alternative HTML version deleted]]

RSiteSearch("Overall Title")

def.par <- par(no.readonly = TRUE)

par(oma = c(0, 0, 3, 0))

nf <- layout(matrix(c(1,2), 1,2,byrow=T), c(1,1), c(1,1), T)

layout.show(nf)

plot(rnorm(10,0,1))

plot(rnorm(10,0,0.1))

mtext("Centered Overall Title", outer = TRUE)

par(def.par)

Or without layout(), something like this:

par(mfrow=c(1,2), oma=c(0,0,2,0))
plot(1:10)
plot(1:10)
title("Centered Overall Title", outer=TRUE)

> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From sundar.dorai-raj at pdf.com  Wed Feb 15 19:39:56 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 15 Feb 2006 12:39:56 -0600
Subject: [R] shading under the lines in a lattice xyplot?
In-Reply-To: <NEBBIPHDAMMOKDKPOFFIOELJDPAA.abunn@whrc.org>
References: <NEBBIPHDAMMOKDKPOFFIOELJDPAA.abunn@whrc.org>
Message-ID: <43F3757C.7030804@pdf.com>



Andy Bunn wrote:
> In the lattice plot below I want to fill-in the areas under each lines that
> are greater than zero in gray. Is there a straightforward way to go about
> this? Thanks, Andy
> 
> library(lattice)
> foo <- data.frame(Yrs=rep(1:50,4), Y=rnorm(200),
>                   Id=unlist(lapply(letters[1:4],rep,50)))
> xyplot(Y~Yrs|Id, data = foo,
>        panel = function(x,y) {
>           panel.abline(h=0)
>           panel.lines(x,y, col = "black")
>        })
> 

Hi, Andy,

The following seems to work. It relies on two functions I have in my 
personal package: find.zero, lpolygon. Let me know what you think.

library(lattice)

foo <- data.frame(Yrs = rep(1:50, 4), Y = rnorm(200),
                   Id = unlist(lapply(letters[1:4], rep, 50)))

lpolygon <- function (x, y = NULL, border = NULL, col = NULL, ...) {
   require(grid, TRUE)
   xy <- xy.coords(x, y)
   x <- xy$x
   y <- xy$y
   gp <- list(...)
   if (!is.null(border)) gp$col <- border
   if (!is.null(col)) gp$fill <- col
   gp <- do.call("gpar", gp)
   grid.polygon(x, y, gp = gp, default.units = "native")
}

find.zero <- function(x, y) {
   n <- length(y)
   yy <- c(0, y)
   wy <- which(yy[-1] * yy[-n - 1] < 0)
   if(!length(wy)) return(NULL)
   xout <- sapply(wy, function(i) {
     n <- length(x)
     ii <- c(i - 1, i)
     approx(y[ii], x[ii], 0)$y
   })
   xout
}

trellis.par.set(theme = col.whitebg())
xyplot(Y ~ Yrs | Id, data = foo,
        panel = function(x,y) {
           x.zero <- find.zero(x, y)
           y.zero <- y > 0
           yy <- c(y[y.zero], rep(0, length(x.zero)))
           xx <- c(x[y.zero], x.zero)
           ord <- order(xx)
           xx <- xx[ord]
           xx <- c(xx[1], xx, xx[length(xx)])
           yy <- c(0, yy[ord], 0)
           lpolygon(xx, yy, col = "gray")
           yy <- c(y[!y.zero], rep(0, length(x.zero)))
           xx <- c(x[!y.zero], x.zero)
           ord <- order(xx)
           xx <- xx[ord]
           xx <- c(xx[1], xx, xx[length(xx)])
           yy <- c(0, yy[ord], 0)
           lpolygon(xx, yy, col = "red", border = FALSE)
           panel.lines(x, y, col = "black")
           panel.abline(h = 0)
        })



From abunn at whrc.org  Wed Feb 15 19:52:19 2006
From: abunn at whrc.org (Andy Bunn)
Date: Wed, 15 Feb 2006 13:52:19 -0500
Subject: [R] shading under the lines in a lattice xyplot?
In-Reply-To: <43F3757C.7030804@pdf.com>
Message-ID: <NEBBIPHDAMMOKDKPOFFIAELNDPAA.abunn@whrc.org>

> -----Original Message-----
> From: Sundar Dorai-Raj [mailto:sundar.dorai-raj at pdf.com]
> Sent: Wednesday, February 15, 2006 1:40 PM
> To: Andy Bunn
> Cc: R-Help
> Subject: Re: [R] shading under the lines in a lattice xyplot?
>
>
>
>
> Andy Bunn wrote:
> > In the lattice plot below I want to fill-in the areas under
> each lines that
> > are greater than zero in gray. Is there a straightforward way
> to go about
> > this? Thanks, Andy
> >
> > library(lattice)
> > foo <- data.frame(Yrs=rep(1:50,4), Y=rnorm(200),
> >                   Id=unlist(lapply(letters[1:4],rep,50)))
> > xyplot(Y~Yrs|Id, data = foo,
> >        panel = function(x,y) {
> >           panel.abline(h=0)
> >           panel.lines(x,y, col = "black")
> >        })
> >
>
> Hi, Andy,
>
> The following seems to work. It relies on two functions I have in my
> personal package: find.zero, lpolygon. Let me know what you think.
>
> library(lattice)
>
> foo <- data.frame(Yrs = rep(1:50, 4), Y = rnorm(200),
>                    Id = unlist(lapply(letters[1:4], rep, 50)))
>
> lpolygon <- function (x, y = NULL, border = NULL, col = NULL, ...) {
>    require(grid, TRUE)
>    xy <- xy.coords(x, y)
>    x <- xy$x
>    y <- xy$y
>    gp <- list(...)
>    if (!is.null(border)) gp$col <- border
>    if (!is.null(col)) gp$fill <- col
>    gp <- do.call("gpar", gp)
>    grid.polygon(x, y, gp = gp, default.units = "native")
> }
>
> find.zero <- function(x, y) {
>    n <- length(y)
>    yy <- c(0, y)
>    wy <- which(yy[-1] * yy[-n - 1] < 0)
>    if(!length(wy)) return(NULL)
>    xout <- sapply(wy, function(i) {
>      n <- length(x)
>      ii <- c(i - 1, i)
>      approx(y[ii], x[ii], 0)$y
>    })
>    xout
> }
>
> trellis.par.set(theme = col.whitebg())
> xyplot(Y ~ Yrs | Id, data = foo,
>         panel = function(x,y) {
>            x.zero <- find.zero(x, y)
>            y.zero <- y > 0
>            yy <- c(y[y.zero], rep(0, length(x.zero)))
>            xx <- c(x[y.zero], x.zero)
>            ord <- order(xx)
>            xx <- xx[ord]
>            xx <- c(xx[1], xx, xx[length(xx)])
>            yy <- c(0, yy[ord], 0)
>            lpolygon(xx, yy, col = "gray")
>            yy <- c(y[!y.zero], rep(0, length(x.zero)))
>            xx <- c(x[!y.zero], x.zero)
>            ord <- order(xx)
>            xx <- xx[ord]
>            xx <- c(xx[1], xx, xx[length(xx)])
>            yy <- c(0, yy[ord], 0)
>            lpolygon(xx, yy, col = "red", border = FALSE)
>            panel.lines(x, y, col = "black")
>            panel.abline(h = 0)
>         })
>

Sundar: That is exactly what I wanted. I had been trying something along
those lines and just realized I needed to find the zeros when your email
came in. That's perfect. Thanks, Andy



From rodrigo.tsai at gmail.com  Wed Feb 15 20:04:31 2006
From: rodrigo.tsai at gmail.com (Rodrigo Tsai)
Date: Wed, 15 Feb 2006 17:04:31 -0200
Subject: [R] Fwd:  common title for graphs in a (1x2) layout
In-Reply-To: <43F36C28.6000701@optonline.net>
References: <a9801f600602150822j57421ab9n304432297dead02b@mail.gmail.com>
	<43F36C28.6000701@optonline.net>
Message-ID: <a9801f600602151104r29518d10x9c1688023cb83773@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060215/7774fc62/attachment.pl

From kubovy at virginia.edu  Wed Feb 15 20:08:16 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Wed, 15 Feb 2006 14:08:16 -0500
Subject: [R] R and Power Point
In-Reply-To: <43F1E879.2030101@stats.uwo.ca>
References: <200602140646.k1E6kgWk005773@gator.dt.uh.edu>
	<D92BDCEF-EE65-498D-BE02-1780C2F438E6@virginia.edu>
	<43F1E879.2030101@stats.uwo.ca>
Message-ID: <de056429509aacbf52f27b6357c832f6@virginia.edu>

Dear r-helpers,

I've had several request for templates using Sweave with R and the  
LaTeX beamer.cls.

They are now available at
http://kubovylab.psyc.virginia.edu/index.php/TeX_Templates
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS: 	P.O.Box 400400	Charlottesville, VA 22904-4400
Parcels:	Room 102		Gilmer Hall
		McCormick Road	Charlottesville, VA 22903
Office:	B011	+1-434-982-4729
Lab:		B019	+1-434-982-4751
Fax:		+1-434-982-4766
WWW:	http://www.people.virginia.edu/~mk9y/
iCal:		http://ical.mac.com/WebObjects/iCal.woa/wa/default? 
u=mk9y&n=UVa.ics



From nli at fhcrc.org  Wed Feb 15 20:28:39 2006
From: nli at fhcrc.org (Nianhua Li)
Date: Wed, 15 Feb 2006 11:28:39 -0800
Subject: [R] [BioC] ANN: BioC2006 Conference Scheduled for August in Seattle
Message-ID: <43F380E7.9010603@fhcrc.org>

==================================
    BioC2006
Where Software and Biology Connect
==================================

This conference will highlight current developments within and
beyond Bioconductor, a world-wide open source and open development
software project for the analysis and comprehension of genomic data.

Our goal is to provide a forum in which to discuss the use and
design of software for analyzing data arising in biology with a
focus on Bioconductor and genomic data.

Where: Fred Hutchinson Cancer Research Center
Seattle WA.

When: August 3 and 4, 2006

What:    Morning Talks: 8:30-12:00
    Afternoon Practicals: 2:00-5:00
    Thursday Evening 5:00-7:30 Posters and Wine & Cheese

Fees:    300 USD for attendees registered before July 1
    250 USD for Bioconductor package maintainers
            or FHCRC employees
    125 USD for enrolled full-time students
    
The online registration form and conference details are now available at
    http://www.bioconductor.org/BioC2006
(You will be redirected to our secure server: 
https://cobra.fhcrc.org/BioC2006



From bartjoosen at hotmail.com  Wed Feb 15 20:36:47 2006
From: bartjoosen at hotmail.com (Bart Joosen)
Date: Wed, 15 Feb 2006 20:36:47 +0100
Subject: [R] Tranferring R results to word prosessors
References: <mailman.11.1140001208.21738.r-help@stat.math.ethz.ch>
Message-ID: <BAY111-DAV155D867A0C16534A7D2976D8FA0@phx.gbl>

When transferring data frame output to word it's easy to use:
write.table(df, file="clipboard",sep="\t")  #df is your dataframe in this 
case

Now you can go to Word en paste your table with tabs.

Good luck

Bart Joosen

> On Thursday 09 February 2006 20:08, Patrick Burns wrote:
>> One approach is to use LyX (http://www.lyx.org/).
>> This is a lot like using Word or other word processors
>> but it creates LaTeX.  You probably won't need to
>> know anything about TeX for a long time unless you
>> are doing really weird things.
>>
>> Patrick Burns
>> patrick at burns-stat.com
>> +44 (0)20 8525 0696
>> http://www.burns-stat.com
>> (home of S Poetry and "A Guide for the Unwilling S User")
>>
>> roger bos wrote:
>> >Yeah, but I don't understand LaTeX at all.  Can you point me to a good
>> >beginners guide?
>> >
>> >Thanks,
>> >
>> >Roger
>> >
>> >On 2/9/06, Barry Rowlingson <B.Rowlingson at lancaster.ac.uk> wrote:
>> >>Tom Backer Johnsen wrote:
>> >>>I have just started looking at R, and are getting more and more
>> >>
>> >>irritated
>> >>
>> >>>at myself for not having done that before.
>> >>>
>> >>>However, one of the things I have not found in the documentation is 
>> >>>some
>> >>>way of preparing output from R for convenient formatting into 
>> >>>something
>> >>>like MS Word.
>> >>
>> >>Well whatever you do, don't start looking at LaTeX, because that will
>> >>get you even more irritated at yourself for not having done it before.
>> >>
>> >>LaTeX is to Word as R is to what? SPSS?
>> >>
>> >>I've still not seen a pretty piece of mathematics - or even text - in
>> >>Word.
>> >>
>> >>Barry



From Galina_Glazko at URMC.Rochester.edu  Wed Feb 15 20:39:53 2006
From: Galina_Glazko at URMC.Rochester.edu (Glazko, Galina)
Date: Wed, 15 Feb 2006 14:39:53 -0500
Subject: [R] distribution fitting
Message-ID: <1AFEC6AD98A0AA4D948216A768A1578C480D33@e2k3ms3.urmc-sh.rochester.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060215/891a1eb4/attachment.pl

From gpagnon at emory.edu  Wed Feb 15 20:55:37 2006
From: gpagnon at emory.edu (Giuseppe Pagnoni)
Date: Wed, 15 Feb 2006 14:55:37 -0500
Subject: [R] arrays of lists in R ("cell arrays" in Matlab)
Message-ID: <43F38739.3010206@emory.edu>

Dear all

I would like to have some data in the form of a 2-dimensional array 
(matrix) of lists, so that I can easily find the desired list object by 
indexing the structure by rows and columns.  In matlab there exists a 
data type called "cell array": a matrix of "cells", which are composite 
objects very similar to R lists. 

I know that in R you can create 1-dimensional arrays of lists, either 
with the vector() function or by making a list of lists, but it is not 
clear to me whether it is actually possible to have 2-dimensional arrays 
of lists.

thank you very much for any suggestion

best

    giuseppe

-- 
-----
Giuseppe Pagnoni
Psychiatry and Behavioral Sciences
Emory University School of Medicine
101 Woodruff Circle, Suite 4000
Atlanta, GA, 30322
tel: 404.712.8431
fax: 404.727.3233



From ggrothendieck at gmail.com  Wed Feb 15 21:10:32 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 15 Feb 2006 15:10:32 -0500
Subject: [R] arrays of lists in R ("cell arrays" in Matlab)
In-Reply-To: <43F38739.3010206@emory.edu>
References: <43F38739.3010206@emory.edu>
Message-ID: <971536df0602151210j1b63b963r34c32fcb6b08eba4@mail.gmail.com>

Try this:

L <- list(sqrt, letters, pi, 1:4)
dim(L) <- c(2,2)
L[[1,1]](4) # 2


On 2/15/06, Giuseppe Pagnoni <gpagnon at emory.edu> wrote:
> Dear all
>
> I would like to have some data in the form of a 2-dimensional array
> (matrix) of lists, so that I can easily find the desired list object by
> indexing the structure by rows and columns.  In matlab there exists a
> data type called "cell array": a matrix of "cells", which are composite
> objects very similar to R lists.
>
> I know that in R you can create 1-dimensional arrays of lists, either
> with the vector() function or by making a list of lists, but it is not
> clear to me whether it is actually possible to have 2-dimensional arrays
> of lists.
>
> thank you very much for any suggestion
>
> best
>
>    giuseppe
>
> --
> -----
> Giuseppe Pagnoni
> Psychiatry and Behavioral Sciences
> Emory University School of Medicine
> 101 Woodruff Circle, Suite 4000
> Atlanta, GA, 30322
> tel: 404.712.8431
> fax: 404.727.3233
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From revans at jlab.org  Wed Feb 15 21:32:02 2006
From: revans at jlab.org (Richard Evans)
Date: Wed, 15 Feb 2006 15:32:02 -0500
Subject: [R] R web interfaces for windows IIS
Message-ID: <000001c6326e$e3fe6810$de173981@revansx>

Hi folks,

can anyone point me to an R add-on package that will work with the
MS-windows IIS server as is?
I know from trying that the "CGIwithR" package was not written with IIS
in mind.
I'm hoping to find package that will work with IIS without having to do
any deep magic.

much obliged :-)

- revansx



From tlumley at u.washington.edu  Wed Feb 15 21:54:44 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 15 Feb 2006 12:54:44 -0800 (PST)
Subject: [R] wilcox.test returned estimates
In-Reply-To: <1140003395.e05fb852a6490@webmail5.leeds.ac.uk>
References: <1140003395.e05fb852a6490@webmail5.leeds.ac.uk>
Message-ID: <Pine.LNX.4.64.0602151250520.20737@homer24.u.washington.edu>

On Wed, 15 Feb 2006, pmt1rew at leeds.ac.uk wrote:

> Hi all,
>
> I have being using wilcox.test to test for differences between 2 independent
> samples.  I had understood the difference in location to be conventionally the
> difference in the sample medians however this is not the case when implemented
> in R.  I have tied ranks and therefore non-exact p-value and confidence
> intervals are calculated due to the normal approximation.  But what exactly is
> this normal approximation i.e. how is it involved in estimating the location
> difference?

It isn't.  The only assumption is that the distribution is the same apart 
from location in the two groups.

> Further, is it then wrong to refer to the difference in location as the
> difference between the medians?  Does anyone have a more appropriate
> description?

Well, this gets more complicated.  Since the method assumes that the 
population distributions differ only by location the population difference 
in medians is the same as the difference in means or in 16.34th 
percentile, or 42%-trimmed mean or whatever. If the assumption is not true 
then seriously weird things can happen (consider the distributions given 
by http://mathworld.wolfram.com/EfronsDice.html)

However, the estimate is not the difference in sample medians. It is the 
median pairwise difference.


 	-thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From tlumley at u.washington.edu  Wed Feb 15 21:58:26 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 15 Feb 2006 12:58:26 -0800 (PST)
Subject: [R] Survreg(), Surv() and interval-censored data
In-Reply-To: <f301bda0602130845n3520c139k@mail.gmail.com>
References: <f301bda0602130845n3520c139k@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602151255320.20737@homer24.u.washington.edu>

On Mon, 13 Feb 2006, Stephen Richards wrote:

> Can survreg() handle interval-censored data like the documentation
> says?  I ask because the command:
>
>     survreg(Surv(start, stop, event) ~ 1, data = heart)
>
> fails with the error message
>
>     Invalid survival type
>
> yet the documentation for Surv() states:
>
>     "Presently, the only methods allowing interval censored data are
>      the parametric models computed by 'survreg'"
>
> Any pointers as to what I'm missing?
>

You are specifying left-truncated, right-censored data, not 
interval-censored. You need the type= argument, eg

> Surv(c(1,1,NA,3),c(2,NA,2,3),type="interval2")
[1] [1, 2] 1+     2-     3

specifies interval censoring at [1,2], right-censoring at 1, 
left-censoring at 2, and an observed event at 3.

 	-thomas



From tlumley at u.washington.edu  Wed Feb 15 22:01:39 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 15 Feb 2006 13:01:39 -0800 (PST)
Subject: [R] getting strata/cluster level values with survey package?
In-Reply-To: <3076.128.193.140.221.1139354675.squirrel@www.forestinformatics.com>
References: <3076.128.193.140.221.1139354675.squirrel@www.forestinformatics.com>
Message-ID: <Pine.LNX.4.64.0602151259460.20737@homer24.u.washington.edu>

On Tue, 7 Feb 2006, Jeff D. Hamann wrote:

> First, I appoligise for the rookie question, but...
>
> I'm trying to obtain standard errors, confidence intervals, etc. from a
> sample design and have been trouble getting the results for anything other
> than the basic total or mean for the overall survey from the survey
> package.

You want svyby() and then perhaps ftable() for formatting. (?svyby, 
?ftable.svyby).

(You also want to send only one copy of the email message, not three).

 	-thomas



>
> For example, using the following dataset,
>
> strata,cluster,vol
> A,1,18.58556192
> A,1,12.55175443
> A,1,21.65882438
> A,1,17.11172946
> A,1,15.41713348
> A,2,13.9344623
> A,2,17.13104821
> A,2,14.6806479
> A,2,14.68357291
> A,2,18.86017714
> A,2,20.67642515
> A,2,15.15295351
> A,2,13.82121102
> A,2,12.9110477
> A,2,14.83153677
> A,2,21.90772687
> A,3,18.69795427
> A,3,18.45636428
> A,3,15.77175793
> A,3,15.54715217
> A,3,20.31948393
> A,3,19.26391445
> A,3,15.54750775
> A,3,19.18724018
> A,4,12.89572151
> A,4,12.92047701
> A,4,12.64958757
> A,4,19.85888418
> A,4,19.64057669
> A,4,19.19188964
> A,4,18.81619298
> A,4,21.73670878
> A,5,15.99430802
> A,5,18.66666517
> A,5,21.80441654
> A,5,14.22081904
> A,5,16.01576433
> A,5,14.92497202
> A,5,17.95123218
> A,5,19.82027165
> A,5,19.35698273
> A,5,19.10826519
> B,6,13.40892677
> B,6,14.3956207
> B,6,13.82113391
> B,6,16.37338569
> B,6,19.70159575
> B,7,14.74334178
> B,7,16.55125245
> B,7,12.38329798
> B,7,18.16472408
> B,7,16.32938475
> B,7,16.06465494
> B,7,12.63086062
> B,7,14.46114813
> B,7,21.90134013
> B,7,13.81025827
> B,7,15.85805494
> B,7,20.18195326
> B,8,19.05120792
> B,8,12.83856639
> B,8,12.61360139
> B,8,21.30434314
> B,8,14.19960469
> B,8,17.38397826
> B,8,15.66477339
> B,8,22.07182834
> B,8,12.07487394
> B,8,20.36357359
> B,8,20.2543677
> B,9,14.44499362
> B,9,17.77235228
> B,9,13.01620902
> B,9,18.10976359
> B,10,18.22350661
> B,10,18.41504728
> B,10,17.94735486
> B,10,18.39173938
> B,10,14.21729704
> B,10,16.95753684
> B,10,21.11643087
> B,10,16.09688752
> B,10,19.54707452
> B,10,22.00450065
> B,10,15.15308873
> B,10,14.72488972
> B,10,17.65280737
> B,10,14.61615255
> B,10,12.89525607
> B,11,22.35831089
> B,11,18.0853187
> B,11,22.12815791
> B,11,17.74562214
> B,11,21.45724242
> B,11,20.57933779
> B,11,19.97397415
> B,11,16.34967424
> B,12,22.14385376
> B,12,17.82816113
> B,12,18.37056381
> B,12,16.13152759
> B,12,22.06764318
> B,12,12.80924472
> B,12,18.95522175
> B,13,20.40554286
> B,13,19.72951878
> C,14,15.51581
> C,14,15.4836358
> C,14,13.35882363
> C,14,13.16072916
> C,14,21.69168971
> C,14,19.09686303
> C,14,14.47450457
> C,14,12.04870424
> C,14,13.33096141
> C,14,17.38388981
> C,14,16.29015289
> C,14,16.32707754
> C,14,16.2784054
> C,15,15.0170597
> C,15,14.95767365
> C,15,15.20739614
> C,15,22.10458509
> C,15,12.3362457
> C,15,19.87895753
> C,15,18.8363682
> C,15,16.43738666
> C,15,12.84570744
> C,15,15.99869357
> C,15,14.42551321
> C,15,13.63489872
> C,15,15.67179885
> C,16,14.61700901
> C,16,14.64864676
> C,16,14.13014582
> C,16,21.7637441
> C,16,20.66825543
> C,16,17.05977818
> C,16,17.80118916
> C,16,15.16641698
>
> where this is read into stand.data. When I use the following survey designs,
>
> srv1 <- svydesign(ids=~1, strata=~strata, data=stand.data )
>
> or,
>
> srv1 <- svydesign(ids=~cluster, strata=~strata, data=stand.data )
>
> with,
>
> print( svytotal( ~vol, srv1 ) )
>
> I only obtain the total,
>
>> print( svytotal( ~vol, srv1 ) )
>    total     SE
> vol  2377 34.464
>
> or worse,
>
> print( svytotal( ~vol + strata, srv1 ) )
>         total     SE
> vol     2377.0 34.464
> strataA   42.0  0.000
> strataB   64.0  0.000
> strataC   34.0  0.000
>
> which reports the number of observations in each of the strata. I'm sure
> this is a RTFM question, but I just need a start. The size of each "plot"
> is 0.04 units (hectares) and I want to be able to quickly examine working
> up each sample with and without clusters (this is going to be part of a
> larger simulation study).
>
> I'm trying to not use SAS for this and hate to admit defeat.
>
> Thanks,
> Jeff.
>
>
>
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From ulf.mehlig at gmx.net  Wed Feb 15 22:21:31 2006
From: ulf.mehlig at gmx.net (Ulf Mehlig)
Date: Wed, 15 Feb 2006 22:21:31 +0100
Subject: [R] readline() for passwords?
In-Reply-To: <loom.20060215T154856-79@post.gmane.org>
References: <43F320E7.8080907@uclm.es> <loom.20060215T154856-79@post.gmane.org>
Message-ID: <1140038491.5079.34.camel@localhost.localdomain>

Hello,

I am using RODBC to access a password-protected database. Is there a
possibility to prevent that the password appears on the screen when
issuing the odbcConnect() command? I thought of something like
readline() without echo. I guess that a getpass()-based solution
wouldn't work for ESS/Emacs, anyway, would it?

Thanks for your attention!
Ulf

R 2.2.1, i386-pc-linux-gnu

-- 
 Ulf Mehlig    <ulf.mehlig at gmx.net>



From roger.bos at gmail.com  Wed Feb 15 22:36:17 2006
From: roger.bos at gmail.com (roger bos)
Date: Wed, 15 Feb 2006 16:36:17 -0500
Subject: [R] R web interfaces for windows IIS
In-Reply-To: <000001c6326e$e3fe6810$de173981@revansx>
References: <000001c6326e$e3fe6810$de173981@revansx>
Message-ID: <1db726800602151336q6ab7789cq5c0b38f95ee3b007@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060215/16056ae6/attachment.pl

From Greg.Snow at intermountainmail.org  Wed Feb 15 23:02:42 2006
From: Greg.Snow at intermountainmail.org (Gregory Snow)
Date: Wed, 15 Feb 2006 15:02:42 -0700
Subject: [R] wilcox.test returned estimates
Message-ID: <07E228A5BE53C24CAD490193A7381BBB12A00A@LP-EXCHVS07.CO.IHC.COM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060215/b6254819/attachment.pl

From ripley at stats.ox.ac.uk  Wed Feb 15 23:11:20 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 15 Feb 2006 22:11:20 +0000 (GMT)
Subject: [R] arrays of lists in R ("cell arrays" in Matlab)
In-Reply-To: <43F38739.3010206@emory.edu>
References: <43F38739.3010206@emory.edu>
Message-ID: <Pine.LNX.4.64.0602152205070.32611@gannet.stats.ox.ac.uk>

On Wed, 15 Feb 2006, Giuseppe Pagnoni wrote:

> I would like to have some data in the form of a 2-dimensional array
> (matrix) of lists, so that I can easily find the desired list object by
> indexing the structure by rows and columns.  In matlab there exists a
> data type called "cell array": a matrix of "cells", which are composite
> objects very similar to R lists.
>
> I know that in R you can create 1-dimensional arrays of lists, either
> with the vector() function or by making a list of lists, but it is not

Neither of those is the same thing as a 1D array, which does exist in R.
(Using 'array' in the C sense is going to lead to confusion.)

> clear to me whether it is actually possible to have 2-dimensional arrays
> of lists.

It is, and also 1D and 3D and 17D arrays of lists. You can create a matrix 
list by assigning a dim() or by using matrix().

An array in R is just a vector with a dimension (and optionally dimnames), 
and a list is a type of vector.

Such topics are covered in the more advanced books on the S/R language.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Soren.Hojsgaard at agrsci.dk  Wed Feb 15 23:19:32 2006
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Wed, 15 Feb 2006 23:19:32 +0100
Subject: [R] Plotting two 3-dimensional time series in a 3 x 2 plot -
	alternatives to par(mfrow())
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC038781C8@DJFPOST01.djf.agrsci.dk>

I am trying to plot two 3-dimensional time series in one window (such that there will be 3 rows and 2 columns). For zoo and ts objects the par(mfrow...) option does not work. I can get xyplot to make the plots, but data are on widely different scales in the three dimensions, and xyplot uses the same scale on all y-axis which means that in some dimensions the curves will be almost horizontal lines. Any suggestions?
Thanks in advance
S??ren



From mdalphin at amgen.com  Wed Feb 15 23:36:40 2006
From: mdalphin at amgen.com (Dalphin, Mark)
Date: Wed, 15 Feb 2006 14:36:40 -0800
Subject: [R] readline() for passwords?
Message-ID: <567ACB2E39C83543B746F1AD7F5E5E0407D18976@wa-mb2-sea.amgen.com>

I don't like to have my password exposed by typing at all. I also don't like
to enter it each time that I wish to open a database (or when I run scripts
automatically across a Linux cluster). My solution has been to keep a file
in my HOME directory containing the username and password for the databases.
This file has read and write permission set so only I (and root) can read
it; this is something of a security hole, but it is the best I have come up
with so far.

I then wrap my dbConnect() or in your case, odbcConnect(), in a function
that picks up the information. I've included my function below.

While I use this function often, I have not tested some of it. My files for
the databases all contain one username and one password. Multiple names and
passwords have not been tested.

Mark Dalphin

openDB <- function(dbname, user=Sys.getenv('USER'), dbg=FALSE) {
  if(length(grep('ROracle', search())) == 0)
    stop("Libraries not loaded: library(DBI) and library(ROracle)")

  path <- paste(Sys.getenv('HOME'), paste('.', dbname, sep=''), sep='/')
  if(dbg) cat("Reading file:", path, "\n")

  input <- scan(file=path, what='character', quiet=TRUE)
  if(dbg) cat("Found", length(input), "items in file\n")

  ## Generally, 'input' will contain two items: username and password.
  ## Assume it will always contain pairs:
  ##   username \t password \n username \t password \n
  ## Match the username to 'user' and then pickup the password as the next
  ## item.
  i.1 <- seq(1, length(input), by=2)
  usr <- input[i.1]
  psd <- input[i.1 + 1]

  inx <- usr==user
  if(dbg) cat("\tUser=", usr[inx], "\n")
  if(sum(inx) < 1)
    stop(paste("User, '", user, "', not present in file: ", path, sep=''))
  if(sum(inx) > 1) stop("Unable to locate unique USER in input")
  if(dbg) cat("\tPass=", psd[inx], "\n")
  return(dbConnect('Oracle', dbname=dbname, user=usr[inx], pass=psd[inx]))
}

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Ulf Mehlig
Sent: Wednesday, February 15, 2006 1:22 PM
To: r-help at stat.math.ethz.ch
Subject: [R] readline() for passwords?


Hello,

I am using RODBC to access a password-protected database. Is there a
possibility to prevent that the password appears on the screen when
issuing the odbcConnect() command? I thought of something like
readline() without echo. I guess that a getpass()-based solution
wouldn't work for ESS/Emacs, anyway, would it?

Thanks for your attention!
Ulf

R 2.2.1, i386-pc-linux-gnu

-- 
 Ulf Mehlig    <ulf.mehlig at gmx.net>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Wed Feb 15 23:55:34 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 15 Feb 2006 23:55:34 +0100
Subject: [R] wilcox.test returned estimates
In-Reply-To: <07E228A5BE53C24CAD490193A7381BBB12A00A@LP-EXCHVS07.CO.IHC.COM>
References: <07E228A5BE53C24CAD490193A7381BBB12A00A@LP-EXCHVS07.CO.IHC.COM>
Message-ID: <x21wy49qqh.fsf@turmalin.kubism.ku.dk>

"Gregory Snow" <Greg.Snow at intermountainmail.org> writes:

> If you really want to look at the difference between 2 medians, then
> consider using permutation tests and bootstrapping for the interval.

Also notice that contrary to popular belief, distributions with
identical medians can be significantly different. Simplest example is
performance scales where one group scores full marks in 90%  of the
cases and another group scores full marks in 60% of the cases.
 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch on behalf of pmt1rew at leeds.ac.uk
> Sent: Wed 2/15/2006 4:36 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] wilcox.test returned estimates
>  
> Hi all,
> 
> I have being using wilcox.test to test for differences between 2 independent
> samples.  I had understood the difference in location to be conventionally the
> difference in the sample medians however this is not the case when implemented
> in R.  I have tied ranks and therefore non-exact p-value and confidence
> intervals are calculated due to the normal approximation.  But what exactly is
> this normal approximation i.e. how is it involved in estimating the location
> difference?
> 
> Further, is it then wrong to refer to the difference in location as the
> difference between the medians?  Does anyone have a more appropriate
> description?
> 
> Thanks
> 
> Rebecca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From Antonio_Paredes at aphis.usda.gov  Thu Feb 16 00:02:56 2006
From: Antonio_Paredes at aphis.usda.gov (Antonio_Paredes@aphis.usda.gov)
Date: Wed, 15 Feb 2006 17:02:56 -0600
Subject: [R] Delta method for glm
Message-ID: <OF48156898.78B177A3-ON86257116.007E16E3-86257116.007E61F8@aphis.usda.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060215/1f2bda1f/attachment.pl

From srini_iyyer_bio at yahoo.com  Thu Feb 16 00:07:43 2006
From: srini_iyyer_bio at yahoo.com (Srinivas Iyyer)
Date: Wed, 15 Feb 2006 15:07:43 -0800 (PST)
Subject: [R] how can I write two objects together, problem with cbind()
In-Reply-To: <1140038491.5079.34.camel@localhost.localdomain>
Message-ID: <20060215230743.12679.qmail@web34508.mail.mud.yahoo.com>

Hi Group,
 I have two objects
1. A data.frame with 2 columns

Apple  4
Boy    2
Cat    5
Dog    10
Eel    9
...
Zebra  10
(26 rows)

I have another object which was obtained as vector of
integers with names as character.

Fruit 10
King 20
Eel  19
Boy 20
Apple 15
...
(26 rows)

Now I wanted to combine the two objects and wanted a
result that would look like this:

Apple  4 15
Boy    2 20
Cat    5 28
Dog    10 25
Eel    9 19


result <- cbind(obj1, obj2)

My result is now jumbled:

Apple  4 34
Boy    2 21
Cat    5 234
Dog    10 23
Eel    9  12

I want to write identical row names elements together.


What could be done here. Could any one please help me.


thanks
Srini



From rbaer at atsu.edu  Thu Feb 16 00:18:43 2006
From: rbaer at atsu.edu (Robert Baer)
Date: Wed, 15 Feb 2006 17:18:43 -0600
Subject: [R] labelling dots in plots
References: <BAEPLAOEEMNCBLKKCPIEMELHCBAA.heinrichs@dkrz.de>
Message-ID: <00c201c63286$2a2b6010$a00c010a@BigBaer>

Is this something like what you want?

# make test data
x=1:10;  y=x;  names(y)=letters[1:length(y)]
# Now plot
plot(x, y, pch='', xlab='ValAddInd_byYear',  ylab='Cons_Elec_Ind_byYear')
text(x,names(y),1:length(x),cex=0.6)



HTH,
Rob

____________________________
Robert W. Baer, Ph.D.
Associate Professor
Department of Physiology
A. T. Still University of Health Science
800 W. Jefferson St.
Kirksville, MO 63501-1497 USA
----- Original Message ----- 
From: "Anne Katrin Heinrichs" <heinrichs at dkrz.de>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, February 15, 2006 11:43 AM
Subject: [R] labelling dots in plots


> Hello,
>
> I would like to label outliers (or all dots) in a plot
>
> plot(as.matrix(ValAddInd_byYear), as.matrix(Cons_Elec_Ind_byYear))
>
> ideally by the 30 different row.names, but anything else (x or y values,
for example)
> would already be helpful.
> I've tried various things with pch, but they didn't work and I can't find
anything else.
>
> Any hint appreciated!
> Thanks,
>
> Katrin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From deepayan.sarkar at gmail.com  Thu Feb 16 00:19:16 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 15 Feb 2006 17:19:16 -0600
Subject: [R] Plotting two 3-dimensional time series in a 3 x 2 plot -
	alternatives to par(mfrow())
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC038781C8@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC038781C8@DJFPOST01.djf.agrsci.dk>
Message-ID: <eb555e660602151519h42f2e422y597fc98ae27a2ed0@mail.gmail.com>

On 2/15/06, Sren Hjsgaard <Soren.Hojsgaard at agrsci.dk> wrote:
> I am trying to plot two 3-dimensional time series in one window (such that
> there will be 3 rows and 2 columns). For zoo and ts objects the
> par(mfrow...) option does not work. I can get xyplot to make the plots, but
> data are on widely different scales in the three dimensions, and xyplot uses
> the same scale on all y-axis which means that in some dimensions the curves
> will be almost horizontal lines. Any suggestions?

You can instruct xyplot to choose separate y-limits for each panel by
specifying

xyplot(..., scales = list(y = "free"))

Deepayan
--
http://www.stat.wisc.edu/~deepayan/



From dlr32 at cornell.edu  Thu Feb 16 00:28:25 2006
From: dlr32 at cornell.edu (Dan Rabosky)
Date: Wed, 15 Feb 2006 18:28:25 -0500
Subject: [R] using kernel density estimates to infer mode of distribution
Message-ID: <5.2.1.1.2.20060215172856.0127c948@postoffice9.mail.cornell.edu>


Hello...

Is it possible to use "density" or another kernel density estimator to 
identify the mode of a distribution?  When I use 'density', the resulting 
density plot of my data is much cleaner than the original noisy histogram, 
and I can clearly see the signal that I am interested in.  E.g., suppose my 
data is actually drawn from two or more normal (or other) 
distributions.  Looking at the kernel density plots, it seems that the 
estimator gives a good approximation of the modal values of each 
distribution, but I can't figure out how to obtain these values short of 
visually estimating the location of the mode using the plot(density).

Is there a relatively easy way to do this?

Thanks in advance for your help!
Dan Rabosky



Dan Rabosky
Department of Ecology and Evolutionary Biology
Cornell University
Ithaca, NY14853-2701 USA
web: http://www.birds.cornell.edu/evb/Graduates_Dan.htm



From andy_liaw at merck.com  Thu Feb 16 01:43:03 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 15 Feb 2006 19:43:03 -0500
Subject: [R] how can I write two objects together, problem with cbind( )
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED811@usctmx1106.merck.com>

See ?merge.

Andy

From: Srinivas Iyyer
> 
> Hi Group,
>  I have two objects
> 1. A data.frame with 2 columns
> 
> Apple  4
> Boy    2
> Cat    5
> Dog    10
> Eel    9
> ...
> Zebra  10
> (26 rows)
> 
> I have another object which was obtained as vector of
> integers with names as character.
> 
> Fruit 10
> King 20
> Eel  19
> Boy 20
> Apple 15
> ...
> (26 rows)
> 
> Now I wanted to combine the two objects and wanted a
> result that would look like this:
> 
> Apple  4 15
> Boy    2 20
> Cat    5 28
> Dog    10 25
> Eel    9 19
> 
> 
> result <- cbind(obj1, obj2)
> 
> My result is now jumbled:
> 
> Apple  4 34
> Boy    2 21
> Cat    5 234
> Dog    10 23
> Eel    9  12
> 
> I want to write identical row names elements together.
> 
> 
> What could be done here. Could any one please help me.
> 
> 
> thanks
> Srini
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From john.maindonald at anu.edu.au  Thu Feb 16 02:04:43 2006
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 16 Feb 2006 12:04:43 +1100
Subject: [R] Strata and Degrees of freedom in anova and multi-level modeling
In-Reply-To: <mailman.10.1140001208.21738.r-help@stat.math.ethz.ch>
References: <mailman.10.1140001208.21738.r-help@stat.math.ethz.ch>
Message-ID: <A1962FE4-5A9D-4C5D-B268-CAA1E7818715@anu.edu.au>

I am changing the title because this is really about the history of  
anova,
and about strata in analysis of variance.  As this kind of question  
has been
arising very frequently, an extended comment may be in order.

The ideas, and the sums of squares breakdowns, go back to Fisher; see
in particular his "Design of Experiments", first published in 1935.   
This
book is still a good read.  I'm not sure that Fisher talked about  
error strata,
but he certainly did emphasize the need to choose the error sum of  
squares
that was appropriate to the inference that was of interest.

It is unfortunate that, in later developments, analysis of variance  
was often
presented in a manner that forgot important parts of Fisher's  
insights.  One
of my complaints about the data mining community is that it seems
remarkably resistant to the notion that the distribution of the error  
term in a
model can matter a lot.

Thus in an experiment that has blocks, plots within blocks and subplots
(I'll use as an example the kiwishade data set in the DAAG package),
treatments that are assigned at random to subplots are compared using  
the
within plot residual (this ignores the possibility of a  
plot:subplotTreatment
interaction, so that such designs must be used with care and/or  
finesse),
treatments that are applied to whole plots are compared using the within
block residual, and so on.

In the kiwishade experiment, there were three blocks, four plots per  
block
(one for each of 4 treatments) and four subplots (vines) per treatment.
See Maindonald and Braun (the book we've been calling DAAGUR),
pp.230-239, for a detailed exposition of the analysis of these data,
comparing the aov() output with the lme() output.  [Details of this  
and other
R-related books can be obtained from a CRAN site.]

For this experiment, the error structure is hierarchical, and it thus  
makes sense
to equate strata with levels, in the sense in which this word is used  
in the
documentation for lme().  The strata are: within plots [level 0 in lme 
()], within
blocks between plots (level 1), and between blocks (level 2).  To see  
the
aov() output, type:

   aov(yield ~ shade + Error(block/plot), data=kiwishade)
[Blocks might alternatively be regarded as a fixed effect.]

To understand the use of the between plot sum of squares, observe  
that there
are 12 independent pieces of information at the plot level, i.e. 12  
plots.
However, 2 (3-1) of these can be explained as due to differences  
between blocks,
and 3 of them can be explained as due to differences between treatments.
Thus, we are left with 7 independent (in an algebraic sense) items of  
information.
The corresponding error variance [the usual sum of squares about the  
mean
divided by number of values less 1] has 6 degrees of freedom.

The within plot residual mean square has 36 degrees of freedom.  This  
experiment
did not have treatment that was applied at the subplot level, and  
this is not the
correct mean squares for any treatment comparison.  The analysis is  
readily
simplified by calculating plot means, and basing all analyses on  
those.  In just the
same way:
1) treatments may be applied to whole apples, there may be multiple
measurements on an apple, and a reasonable way to do the analysis may be
to calculate means for each apple.
2) Commonly, in laboratory experiments, treatments are applied to whole
samples, and multiple measurements or assays are made on the one sample.
3) In a comparison of prescribing habits between registrars and  
specialists,
there might be data from 50 registrars and 50 specialists in each  
hospital,
but perhaps only 3 hospitals.  So, do we have
   (a) 3 pieces of information (3 hospitals with two items to compare  
per hospital;
    there'll be 2 degrees of freedom for the mean square), or
    (b) closer to 300 [a split plot type comparison will give a mean  
square with
    (50+50-2)*3 degrees of freedom].

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Mathematical Sciences Institute, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.



Genstat's achievement was to push to the limit, based on ideas of JA  
Nelder
(a theory) and GN Wilkinson (an algorithm), ideas of balance that  
made it
possible to retain the conceptual simplicity of analysis of variance  
type strata.
Estimates of effects of interest may for crossed designs use an error  
term that
combines variances across strata, so that "t"-statistics (with a  
fudge used to get
degrees of freedom) may at best be reasonably approximated by a t- 
distribution.

The methodology that is used in lme(), and other software that uses a  
similar
approach, gives up the attempt to form an analysis of variance table.  
The
model specifies the variance-covariance structure, and an important  
part of the
analysis is the estimation of that variance-covariance structure.   
Estimates of
effects that are of interest no longer have a t-distribution under  
the standard
normality etc assumptions.  Standard fudges (calculate a df for a t- 
distribution
approximation) often work quite well.  Doug Bates is right to keep  
reminding
everyone that they are fudges.

The fudges are important for another more pervasive reason.  It is  
important
to know whether a variance is estimated with 2 or with ~300 degrees of
freedom.  If there are only 2 pieces of information the normality  
assumptions
matter a lot.  Was one of those hospitals an outlier?  Problems with  
the fudge
used for calculate degrees of freedom for a t-approximation may be  
the least
of the matters that should be a concern.

There's a nice account of Fisher's contribution to experimental design
(as well as a few complaints about some of Fisher's comments on  
inference) in:
R. A. Fisher and Experimental Design: A Review
D. A. Preece
Biometrics, Vol. 46, No. 4 (Dec., 1990) , pp. 925-935

John Maindonald


On 15 Feb 2006, at 10:00 PM, r-help-request at stat.math.ethz.ch wrote:

> From: Peter Dalgaard <p.dalgaard at biostat.ku.dk>
> Date: 15 February 2006 3:26:27 AM
> To: WPhantom <wp1 at tiscali.fr>
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] A concrete type I/III Sum of square problem
>
>
> WPhantom <wp1 at tiscali.fr> writes:
>
>> Thanks Brian for the reference.
>>   I just discover that it is available in our
>> library so I going to take it & read it soon.
>> Actually, I don't even know the difference
>> between a multistratum vs a single-stratum AOV. A
>> quick search on google returned me the R materials so that I imagine
>> that these concepts are quite specific to R.
>
> You have to be careful not to confuse Google's view of the world with
> Reality...
>
> The concept of error strata is much older than R, and existed for
> instance in Genstat, anno 1977 or so. However, Genstat seems to have
> left little impression on the Internet.
>
>> I will read the book first before asking for more informations.
>
> The executive summary is that the concept of error strata relies
> substantially on having a balanced design (at least for the random
> effects), so that the analysis can be decomposed into analyses of
> means, contrasts, and contrasts of means. For unbalanced designs, you
> usually get meaningless analyses.
>
>
>> Thanks
>>
>> Sylvain Cl??ment
>>
>> At 12:38 14/02/2006, you wrote:
>>> More to the point, you are confusing
>>> multistratum AOV with single-stratuam AOV.  For
>>> a good tutorial, see MASS4 (bibliographic
>>> information in the R FAQ).  For unbalanced data
>>> we suggest you use lme() instead.
>>>
>>> --
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting- 
>> guide.html
>>
>
> -- 
>    O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)  
> 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)  
> 35327907



From john.maindonald at anu.edu.au  Thu Feb 16 02:09:29 2006
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 16 Feb 2006 12:09:29 +1100
Subject: [R] A concrete type I/III Sum of square problem
In-Reply-To: <mailman.10.1140001208.21738.r-help@stat.math.ethz.ch>
References: <mailman.10.1140001208.21738.r-help@stat.math.ethz.ch>
Message-ID: <3F969DE8-E3A9-439B-A077-DB3DD75AA03C@anu.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/5f484b58/attachment.pl

From ggrothendieck at gmail.com  Thu Feb 16 02:30:32 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 15 Feb 2006 20:30:32 -0500
Subject: [R] Plotting two 3-dimensional time series in a 3 x 2 plot -
	alternatives to par(mfrow())
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC038781C8@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC038781C8@DJFPOST01.djf.agrsci.dk>
Message-ID: <971536df0602151730h47f52440nf4a9d954a74ee58c@mail.gmail.com>

plot.zoo takes the nc= argument which specifies the number of columns
it uses, e.g.

library(zoo)
library(tseries)
data(USeconomic)
z <- as.zoo(USeconomic)
plot(z, nc = 2)

On 2/15/06, S??ren H??jsgaard <Soren.Hojsgaard at agrsci.dk> wrote:
> I am trying to plot two 3-dimensional time series in one window (such that there will be 3 rows and 2 columns). For zoo and ts objects the par(mfrow...) option does not work. I can get xyplot to make the plots, but data are on widely different scales in the three dimensions, and xyplot uses the same scale on all y-axis which means that in some dimensions the curves will be almost horizontal lines. Any suggestions?
> Thanks in advance
> S??ren
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ll9f at cms.mail.virginia.edu  Thu Feb 16 04:07:02 2006
From: ll9f at cms.mail.virginia.edu (Lei  Liu)
Date: Wed, 15 Feb 2006 22:07:02 -0500
Subject: [R] how to retrieve robust se in coxph
Message-ID: <web-176910030@cgatepro-4.mail.virginia.edu>

Hi,

I am using coxph in simulations and I want to store the "robust se" (or 
"se2" in frailty models) for each replicate. Is there a function to retrieve 
it, like vcov() for the variance estimate? Thanks!
  
Lei Liu
Assistant Professor
Division of Biostatistics and Epidemiology
Dept. of Public Health Sciences
School of Medicine
University of Virginia

3181 Hospital West Complex
Charlottesville, VA 22908-0717

1-434-982-3364 (o)
1-434-806-8086 (c)

liulei at virginia.edu
ll9f at virginia.edu



From joseclaudio.faria at terra.com.br  Thu Feb 16 04:33:16 2006
From: joseclaudio.faria at terra.com.br (Jose Claudio Faria)
Date: Thu, 16 Feb 2006 00:33:16 -0300
Subject: [R] SSQ decomposition and contrasts with ANOVA
Message-ID: <43F3F27C.3070408@terra.com.br>

Dear R list,

Please, could someone help me with SSQ decomposition and contrasts.
Below my data, graphic, ANOVAs and my doubt:

# Data
a   = paste('a', gl(3, 8), sep='')
b   = paste('b', gl(2, 4, 24), sep='')
tra = sort(paste('t', rep(1:6, 4), sep=''))
y   = c(26.2, 26.0, 25.0, 25.4, 24.8, 24.6, 26.7, 25.2,
         25.7, 26.3, 25.1, 26.4, 19.6, 21.1, 19.0, 18.6,
         22.8, 19.4, 18.8, 19.2, 19.8, 21.4, 22.8, 21.3)
dF  = data.frame(a, b, tra, y)

# Graphic
par(mfrow=c(2,1))
interaction.plot(dF$a, dF$b, dF$y,
                  ylab = 'y', xlab = 'a')

interaction.plot(dF$b, dF$a, dF$y,
                  ylab = 'y', xlab = 'b')

# ANOVAs
av0 = aov(y ~ tra, data=dF)
summary(av0)

av1 = aov(y ~ a*b, data=dF)
summary(av1)

av2 = aov(y ~ a/b, data=dF)
b_a = summary(av2, split = list('a:b' = list(
               'b1 vs b2/a1' = 1, 'b1 vs b2/a2' = 2, 'b1 vs b2/a3' = 3)))
b_a

av3 = aov(y ~ b/a, data=dF)
a_b = summary(av3, split = list('b:a' = list(
              'a/b1' = c(1,3), 'a/b2' = c(2,4))))
a_b

# My doubts
a) How to make the SSQ decomposition to complete the ANOVA below?
--------------------------------------------------------
                    Df   Sum Sq Mean Sq F value    Pr(>F)
b                   1   19.082  19.082  14.875  0.001155
b:a                 4  156.622  39.155  30.524 8.438e-08
--------------------------------------------------------
  b:a: a/b1         (2) (87.122) 43.561  33.958 7.776e-07
--------------------------------------------------------
    a1 vs (a2, a3)   1        ?       ?       ?         ?
    a2 vs a3         1        ?       ?       ?         ?
--------------------------------------------------------
  b:a: a/b2         (2) (69.500) 34.750  27.090 3.730e-06
--------------------------------------------------------
    a1 vs (a2, a3)   1        ?       ?       ?         ?
    a2 vs a3         1        ?       ?       ?         ?
--------------------------------------------------------
Residuals   18  23.090   1.283
--------------------------------------------------------

b) How to make the SSQ decomposition to complete the ANOVA below?
--------------------------------------------------------
                    Df   Sum Sq Mean Sq F value    Pr(>F)
b                   1   19.082  19.082  14.875  0.001155
b:a                 4  156.622  39.155  30.524 8.438e-08
--------------------------------------------------------
  b:a: a/b1         (2) (87.122) 43.561  33.958 7.776e-07
--------------------------------------------------------
    a2 vs (a1, a3)   1        ?       ?       ?         ?
    a1 vs a3         1        ?       ?       ?         ?
--------------------------------------------------------
  b:a: a/b2         (2) (69.500) 34.750  27.090 3.730e-06
--------------------------------------------------------
    a2 vs (a1, a3)   1        ?       ?       ?         ?
    a1 vs a3         1        ?       ?       ?         ?
--------------------------------------------------------
Residuals   18  23.090   1.283
--------------------------------------------------------

Or, In this case, how can I to test these constrasts?

Thanks for any help,
-- 
Jose Claudio Faria
Brasil/Bahia/UESC/DCET
Estatistica Experimental/Prof. Adjunto
mails:
  joseclaudio.faria at terra.com.br
  joseclaudio.faria at oi.com.br
  jc_faria at uesc.br
  jc_faria at uol.com.br
tel: 73-3634.2779



From subhabratapal at sraindia.com  Thu Feb 16 04:50:37 2006
From: subhabratapal at sraindia.com (Subhabrata)
Date: Thu, 16 Feb 2006 09:20:37 +0530
Subject: [R] R-help - Problem in drawing braplot with a huge value of data
Message-ID: <010801c632ac$265de810$f608a8c0@srai37>

Hello R-experts,

I am facing a strange problem while creating a barplot. I have serise of
data of which the first
on is around 162589 while the remaining data are around 0-150. so when I am
ploting the barplot
with all the data I am getting a single line -> test1.jpg.

But If I remove the 1st value i.e 162589 then I am getting a normal
barplot -> test2.jpg

Can some one help me regarding this matter.

Thank you for any help.

Regards

Subhabrata

From emfoster at unc.edu  Thu Feb 16 02:38:52 2006
From: emfoster at unc.edu (E. Michael Foster)
Date: Wed, 15 Feb 2006 20:38:52 -0500
Subject: [R] looping through tasks
Message-ID: <43F3D7AC.9070304@unc.edu>

Hi,

I'm moving (slowly) to R from STATA.
I often have need to move through a set of tasks across a series of years.
In this case, you can see that I'm mimicking -reshape- in STATA, but I'm 
less interested in the
task than in programming R.

    library(foreign)
    mydata<-read.dta("z:\example.dta")
    for (y in 2000:2002) {
    myvar<-paste("score",y,sep="") # x is available for each year
    assign( eval(myvar),
    data.frame(cbind(mydata[,c("var1", eval(myvar))],c(eval(y)))))
    colnames(eval(myvar))<-c("person","score","year")
    }

I"m getting the error, "
Error in "colnames<-"(`*tmp*`, value = c("newid", "score", "year")) :
attempt to set colnames on object with less than two dimensions
Whether I set up a data frame or not doesn't matter.

As you might guess, what I want to do at the end is rbind the little 
files, and the lack of consistent column names causes the program to choke.

Suggestions? /m


-- 

________________________________________________
E. Michael Foster				

download vcard: www.unc.edu/~emfoster/Foster.vcf

Professor 	of Maternal and Child Health
		of Health Policy and
Administration
		
Associate Chair for Faculty Advancement

(W) 919-966-3773
(F) 919-966-0458

Office: 407C Rosenau Hall << use for FEDEX

School of Public Health
University of North Carolina, Chapel Hill
Rosenau Hall, Campus Box# 7445
Chapel Hill, NC 27599-7445

Visit the new FAQ section of my web site where I
address questions such as "What's on your IPOD?" or
"Who's your person of the year?"

www.FosterFAQ.blogspot.com

www.personal.psu.edu/emf10

"What do you mean, this jacket makes me look like John Kerry on a pheasant hunt.  I'll fill your ass with bird shot, you old coot."
-- Dick Cheney, just before shooting his homie.

"But the one thing we can all agree, all faiths and ideologies, is that God is with the vulnerable and poor.  God is in the slums, in the cardboard boxes where the poor play house? God is in the silence of a mother who has infected her child with a virus that will end both their lives? God is in the cries heard under the rubble of war? God is in the debris of wasted opportunity and lives, and God is with us if we are with them.  'If you remove the yolk from your midst, the pointing of the finger and speaking wickedness, and if you give yourself to the hungry and satisfy the desire of the afflicted, then your light will rise in darkness and your gloom with become like midday and the Lord will continually guide you and satisfy your desire in scorched places'

It?s not a coincidence that in the Scriptures, poverty is mentioned more than 2,100 times.  It?s not an accident.  That?s a lot of air time, 2,100 mentions.  [You know, the only time Christ is judgmental is on the subject of the poor.]   ?As you have done it unto the least of these my brethren, you have done it unto me.?  (Matthew 25:40).   As I say, good news to the poor."
- Bono



From sell_mirage_ne at hotmail.com  Thu Feb 16 05:30:49 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Wed, 15 Feb 2006 22:30:49 -0600
Subject: [R] logistic regression
Message-ID: <BAY110-F1FBF55F74104A358E2143C7FB0@phx.gbl>

Hi R users

I have two bianry variables (X and Y) and one continuous variable (Z).

I like to know, after controlling for the continuous variable, where one of 
the binary is significantly related to the other binary variable using 
logistic regression


model <- glm(Y ~ X + Z, family=binomial)

Is checking the significance of the coefficient of X  a proper way for doing 
that ?

Any suggestion for this problem ?

Thanks

_________________________________________________________________
Dont just search. Find. Check out the new MSN Search!



From ronggui.huang at gmail.com  Thu Feb 16 05:41:14 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Thu, 16 Feb 2006 12:41:14 +0800
Subject: [R] looping through tasks
In-Reply-To: <43F3D7AC.9070304@unc.edu>
References: <43F3D7AC.9070304@unc.edu>
Message-ID: <38b9f0350602152041u713b2067q@mail.gmail.com>

R has the reshape function do the familiar task as -reshape- in stata.

?reshape
Description:

     This function reshapes a data frame between 'wide' format with
     repeated measurements in separate columns of the same record and
     'long' format with the repeated measurements in separate records.


2006/2/16, E. Michael Foster <emfoster at unc.edu>:
> Hi,
>
> I'm moving (slowly) to R from STATA.
> I often have need to move through a set of tasks across a series of years.
> In this case, you can see that I'm mimicking -reshape- in STATA, but I'm
> less interested in the
> task than in programming R.
>
>     library(foreign)
>     mydata<-read.dta("z:\example.dta")
>     for (y in 2000:2002) {
>     myvar<-paste("score",y,sep="") # x is available for each year
>     assign( eval(myvar),
>     data.frame(cbind(mydata[,c("var1", eval(myvar))],c(eval(y)))))
>     colnames(eval(myvar))<-c("person","score","year")
>     }
>
> I"m getting the error, "
> Error in "colnames<-"(`*tmp*`, value = c("newid", "score", "year")) :
> attempt to set colnames on object with less than two dimensions
> Whether I set up a data frame or not doesn't matter.
>
> As you might guess, what I want to do at the end is rbind the little
> files, and the lack of consistent column names causes the program to choke.
>
> Suggestions? /m
>
>
> --
>
> ________________________________________________
> E. Michael Foster
>
> download vcard: www.unc.edu/~emfoster/Foster.vcf
>
> Professor       of Maternal and Child Health
>                 of Health Policy and
> Administration
>
> Associate Chair for Faculty Advancement
>
> (W) 919-966-3773
> (F) 919-966-0458
>
> Office: 407C Rosenau Hall << use for FEDEX
>
> School of Public Health
> University of North Carolina, Chapel Hill
> Rosenau Hall, Campus Box# 7445
> Chapel Hill, NC 27599-7445
>
> Visit the new FAQ section of my web site where I
> address questions such as "What's on your IPOD?" or
> "Who's your person of the year?"
>
> www.FosterFAQ.blogspot.com
>
> www.personal.psu.edu/emf10
>
> "What do you mean, this jacket makes me look like John Kerry on a pheasant hunt.  I'll fill your ass with bird shot, you old coot."
> -- Dick Cheney, just before shooting his homie.
>
> "But the one thing we can all agree, all faiths and ideologies, is that God is with the vulnerable and poor.  God is in the slums, in the cardboard boxes where the poor play house God is in the silence of a mother who has infected her child with a virus that will end both their lives God is in the cries heard under the rubble of war God is in the debris of wasted opportunity and lives, and God is with us if we are with them.  'If you remove the yolk from your midst, the pointing of the finger and speaking wickedness, and if you give yourself to the hungry and satisfy the desire of the afflicted, then your light will rise in darkness and your gloom with become like midday and the Lord will continually guide you and satisfy your desire in scorched places'
>
> It's not a coincidence that in the Scriptures, poverty is mentioned more than 2,100 times.  It's not an accident.  That's a lot of air time, 2,100 mentions.  [You know, the only time Christ is judgmental is on the subject of the poor.]   'As you have done it unto the least of these my brethren, you have done it unto me.'  (Matthew 25:40).   As I say, good news to the poor."
> - Bono
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--

Deparment of Sociology
Fudan University



From ronggui.huang at gmail.com  Thu Feb 16 05:47:56 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Thu, 16 Feb 2006 12:47:56 +0800
Subject: [R] how to retrieve robust se in coxph
In-Reply-To: <web-176910030@cgatepro-4.mail.virginia.edu>
References: <web-176910030@cgatepro-4.mail.virginia.edu>
Message-ID: <38b9f0350602152047la19c7bbu@mail.gmail.com>

see robcov in Design package.

2006/2/16, Lei  Liu <ll9f at cms.mail.virginia.edu>:
> Hi,
>
> I am using coxph in simulations and I want to store the "robust se" (or
> "se2" in frailty models) for each replicate. Is there a function to retrieve
> it, like vcov() for the variance estimate? Thanks!
>
> Lei Liu
> Assistant Professor
> Division of Biostatistics and Epidemiology
> Dept. of Public Health Sciences
> School of Medicine
> University of Virginia
>
> 3181 Hospital West Complex
> Charlottesville, VA 22908-0717
>
> 1-434-982-3364 (o)
> 1-434-806-8086 (c)
>
> liulei at virginia.edu
> ll9f at virginia.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--

Deparment of Sociology
Fudan University



From MSchwartz at mn.rr.com  Thu Feb 16 05:50:34 2006
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Wed, 15 Feb 2006 22:50:34 -0600
Subject: [R] R-help - Problem in drawing braplot with a huge value
	of	data
In-Reply-To: <010801c632ac$265de810$f608a8c0@srai37>
References: <010801c632ac$265de810$f608a8c0@srai37>
Message-ID: <1140065434.6285.22.camel@localhost.localdomain>

On Thu, 2006-02-16 at 09:20 +0530, Subhabrata wrote:
> Hello R-experts,
> 
> I am facing a strange problem while creating a barplot. I have serise of
> data of which the first
> on is around 162589 while the remaining data are around 0-150. so when I am
> ploting the barplot
> with all the data I am getting a single line -> test1.jpg.
> 
> But If I remove the 1st value i.e 162589 then I am getting a normal
> barplot -> test2.jpg
> 
> Can some one help me regarding this matter.
> 
> Thank you for any help.
> 
> Regards
> 
> Subhabrata


You have a wide range for your data, so the smaller values are getting
lost.

You can try to use a log scale on the y axis and then set the tick marks
to reasonable values:

 # Do the barplot, setting 'log = "y"' to use a log
 # scale.
 # Set the range of the y axis to nice values. Note of
 # course that you cannot have 0 since log10(0) = -Inf
 # Also set the y axis so that the tick marks are not
 # drawn here

 barplot(c(162589,  50, 100, 150), log = "y", 
         ylim = c(1, 200000), yaxt = "n")


 # Use axTicks to get 'nice' values for the tick marks
 # The 'y' axis is '2'

 at <- axTicks(2)


 # Now use axis() to set the tick mark values and use
 # 'las' to make the labels horizontal
 # Use sprintf() to force non "1e+XX" labels

 axis(2, at = at, label = sprintf("%d", at), las = 2)


You can then add further annotation as you require.

If you would prefer nicer 10^x exponential notations where the exponent
is superscripted for the y axis tick marks, you could use 'plotmath' and
do something like this:

 barplot(c(162589,  50, 100, 150), log = "y", 
         ylim = c(1, 200000), yaxt = "n")

 at <- axTicks(2)

 axis(2, at = at, labels = parse(text = paste("10 ^", log10(at))), 
      las = 2)


The final line uses parse() to create math expressions for the tick mark
notations. The result of the paste() call is:

> paste("10 ^", log10(at))
[1] "10 ^ 0" "10 ^ 1" "10 ^ 2" "10 ^ 3" "10 ^ 4" "10 ^ 5"

These are then converted into expressions using parse() that can be
drawn on the axis by plotmath.

See ?axis, ?axTicks, ?sprintf, ?plotmath, ?parse and ?paste for more
information here.

HTH,

Marc Schwartz



From mbeger at zen.uq.edu.au  Thu Feb 16 06:20:14 2006
From: mbeger at zen.uq.edu.au (Maria Beger)
Date: Thu, 16 Feb 2006 15:20:14 +1000
Subject: [R] cv.glm function error message in a loop
Message-ID: <003401c632b8$aabe0930$81db17ac@uq.edu.au>

Dear list,
I am modelling fish distributions using the glm-function followed by the
step-function, and then want to cross-validate the model via the
cv.glm-function from the {boot} package. I am working on fish
distributions on coral reefs.  The code I have works for one fish
species. Since I have 227 fishes, I wrote a loop.  Now the
cv.glm-function comes up with an error message: "Error in
model.frame(formula, rownames, variables, varnames, extras, extranames,
: variable lengths differ" and I cannot work out what the problem is.
All the data are the same length and I double-checked all.  I think its
to do with how cv.glm addresses the fish data columns for the
crossvalidation within "data".  

Any help would be appreciated, the code is below.  I can send more
detail if required. 

Thank you very much for your help!!!  Maria



"data" is a dataframe with the first 227 columns with fish
presence/absence data (=response), then 10 columns of predictor
variables.

Code that doesn't work:

for (i in 1:length(datafish))  #this is 227 columns within "data"
{
#run glm & step of fish.[i] with all parameters no interactions
modelfish<-glm(data[,i]~ECO.NAME+ISLAND+DISTANCE.EST+DEPTH500M,
binomial)
stepmodfi<-step(modelfish,trace=1,scope=list(lower= ~1,
upper=~ECO.NAME+ISLAND+DISTANCE.EST+DEPTH500M) ,direction="both")
#run cross-validation
fish.vali<-cv.glm(data,stepmodfi)
}

Code for one fish that works:
modelfish.355<-glm(fi355~ECO.NAME+ISLAND+DISTANCE.EST+DEPTH500M,
binomial, data=data)
stepmodfi.355<-step(modelfish.355,trace=1,scope=list(lower= ~1,
upper=~ECO.NAME*ISLAND*DISTANCE.EST*DEPTH500M) ,direction="both")
fish.vali<-cv.glm(data,stepmodfi.355)


Maria Beger
PhD Candidate
The Ecology Centre
School of Integrative Biology
University of Queensland
St Lucia, QLD 4072, Australia
Tel: +61 7 3365 1671
mbeger at zen.uq.edu.au
http://www.uq.edu.au/spatialecology/  

NRAS - Marshall Islands
Natural Resource Assessment Surveys Project 
www.nras-conservation.org

Chuuk Lagoon Project
http://www.earthwatch.org/



From chris at lordsutch.com  Thu Feb 16 06:49:34 2006
From: chris at lordsutch.com (Chris Lawrence)
Date: Thu, 16 Feb 2006 00:49:34 -0500
Subject: [R] logistic regression
In-Reply-To: <BAY110-F1FBF55F74104A358E2143C7FB0@phx.gbl>
References: <BAY110-F1FBF55F74104A358E2143C7FB0@phx.gbl>
Message-ID: <e2e0e3d30602152149h1c1f8090laa0bb51dc9991ac7@mail.gmail.com>

On 2/15/06, Taka Matzmoto <sell_mirage_ne at hotmail.com> wrote:
> I have two bianry variables (X and Y) and one continuous variable (Z).
>
> I like to know, after controlling for the continuous variable, where one of
> the binary is significantly related to the other binary variable using
> logistic regression
>
> model <- glm(Y ~ X + Z, family=binomial)
>
> Is checking the significance of the coefficient of X  a proper way for doing
> that ?

Yes, that will do it.


Chris



From gregor.gorjanc at gmail.com  Thu Feb 16 07:37:20 2006
From: gregor.gorjanc at gmail.com (Gregor Gorjanc)
Date: Thu, 16 Feb 2006 07:37:20 +0100
Subject: [R] A concrete type I/III Sum of square problem
Message-ID: <43F41DA0.2010806@gmail.com>

> WPhantom <wp1 at tiscali.fr> writes:
> 
>>> Thanks Brian for the reference.
>>>   I just discover that it is available in our 
>>> library so I going to take it & read it soon.
>>> Actually, I don't even know the difference 
>>> between a multistratum vs a single-stratum AOV. A 
>>> quick search on google returned me the R materials so that I imagine
>>> that these concepts are quite specific to R.
> 
> You have to be careful not to confuse Google's view of the world with
> Reality...
> 
> The concept of error strata is much older than R, and existed for
> instance in Genstat, anno 1977 or so. However, Genstat seems to have
> left little impression on the Internet. 
>  
>>> I will read the book first before asking for more informations.
> 
> The executive summary is that the concept of error strata relies
> substantially on having a balanced design (at least for the random
> effects), so that the analysis can be decomposed into analyses of
> means, contrasts, and contrasts of means. For unbalanced designs, you
> usually get meaningless analyses.
> 

Can you (prof. Dalgaard) please point us to relevant book with these
topics. I am very interested in it since my data are often unbalanced.

>>> Thanks
>>> 
>>> Sylvain Cl?ment
>>> 
>>> At 12:38 14/02/2006, you wrote:
>>
>>>> >More to the point, you are confusing 
>>>> >multistratum AOV with single-stratuam AOV.  For 
>>>> >a good tutorial, see MASS4 (bibliographic 
>>>> >information in the R FAQ).  For unbalanced data 
>>>> >we suggest you use lme() instead.

I do not have the whole book in my head as prof. Ripley probably does,
but I can not recall to read about this in MASS4. I am sure I am wrong
and would you (prof. Ripley) be please so kind and point us to relevant
chapters/pages.

Many thanks.

-- 
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana     PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si

SI-1230 Domzale             tel: +386 (0)1 72 17 861
Slovenia, Europe            fax: +386 (0)1 72 17 888

----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.



From ripley at stats.ox.ac.uk  Thu Feb 16 08:13:14 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Feb 2006 07:13:14 +0000 (GMT)
Subject: [R] logistic regression
In-Reply-To: <e2e0e3d30602152149h1c1f8090laa0bb51dc9991ac7@mail.gmail.com>
References: <BAY110-F1FBF55F74104A358E2143C7FB0@phx.gbl>
	<e2e0e3d30602152149h1c1f8090laa0bb51dc9991ac7@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602160709230.6035@gannet.stats.ox.ac.uk>

On Thu, 16 Feb 2006, Chris Lawrence wrote:

> On 2/15/06, Taka Matzmoto <sell_mirage_ne at hotmail.com> wrote:
>> I have two bianry variables (X and Y) and one continuous variable (Z).
>>
>> I like to know, after controlling for the continuous variable, where one of
>> the binary is significantly related to the other binary variable using
>> logistic regression
>>
>> model <- glm(Y ~ X + Z, family=binomial)
>>
>> Is checking the significance of the coefficient of X  a proper way for doing
>> that ?
>
> Yes, that will do it.

Sorry, not so.  That is a Wald test, and its power goes to zero as the 
true effect increases.  You need to do a likelihood ratio test via 
anova() to get a reasonable test.

Details in MASS (see the FAQ).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Feb 16 08:21:21 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Feb 2006 07:21:21 +0000 (GMT)
Subject: [R] cv.glm function error message in a loop
In-Reply-To: <003401c632b8$aabe0930$81db17ac@uq.edu.au>
References: <003401c632b8$aabe0930$81db17ac@uq.edu.au>
Message-ID: <Pine.LNX.4.64.0602160716320.6035@gannet.stats.ox.ac.uk>

Please study the help page for cv.glm.  You have not specified `data' 
correctly in the loop case.  The help page says

Arguments:

     data: A matrix or data frame containing the data.  The rows should
           be cases and the columns correspond to variables, one of
           which is the response.

   glmfit: An object of class '"glm"' containing the results of a
           generalized linear model fitted to 'data'.
                                    ^^^^^^^^^^^^^^^^ 
and that is not what you specified.

On Thu, 16 Feb 2006, Maria Beger wrote:

> Dear list,
> I am modelling fish distributions using the glm-function followed by the
> step-function, and then want to cross-validate the model via the
> cv.glm-function from the {boot} package. I am working on fish
> distributions on coral reefs.  The code I have works for one fish
> species. Since I have 227 fishes, I wrote a loop.  Now the
> cv.glm-function comes up with an error message: "Error in
> model.frame(formula, rownames, variables, varnames, extras, extranames,
> : variable lengths differ" and I cannot work out what the problem is.
> All the data are the same length and I double-checked all.  I think its
> to do with how cv.glm addresses the fish data columns for the
> crossvalidation within "data".
>
> Any help would be appreciated, the code is below.  I can send more
> detail if required.
>
> Thank you very much for your help!!!  Maria
>
>
>
> "data" is a dataframe with the first 227 columns with fish
> presence/absence data (=response), then 10 columns of predictor
> variables.
>
> Code that doesn't work:
>
> for (i in 1:length(datafish))  #this is 227 columns within "data"
> {
> #run glm & step of fish.[i] with all parameters no interactions
> modelfish<-glm(data[,i]~ECO.NAME+ISLAND+DISTANCE.EST+DEPTH500M,
> binomial)
> stepmodfi<-step(modelfish,trace=1,scope=list(lower= ~1,
> upper=~ECO.NAME+ISLAND+DISTANCE.EST+DEPTH500M) ,direction="both")
> #run cross-validation
> fish.vali<-cv.glm(data,stepmodfi)
> }
>
> Code for one fish that works:
> modelfish.355<-glm(fi355~ECO.NAME+ISLAND+DISTANCE.EST+DEPTH500M,
> binomial, data=data)
> stepmodfi.355<-step(modelfish.355,trace=1,scope=list(lower= ~1,
> upper=~ECO.NAME*ISLAND*DISTANCE.EST*DEPTH500M) ,direction="both")
> fish.vali<-cv.glm(data,stepmodfi.355)
>
>
> Maria Beger
> PhD Candidate
> The Ecology Centre
> School of Integrative Biology
> University of Queensland
> St Lucia, QLD 4072, Australia
> Tel: +61 7 3365 1671
> mbeger at zen.uq.edu.au
> http://www.uq.edu.au/spatialecology/
>
> NRAS - Marshall Islands
> Natural Resource Assessment Surveys Project
> www.nras-conservation.org
>
> Chuuk Lagoon Project
> http://www.earthwatch.org/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Thu Feb 16 08:27:10 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 16 Feb 2006 08:27:10 +0100
Subject: [R] how can I write two objects together, problem with cbind()
In-Reply-To: <20060215230743.12679.qmail@web34508.mail.mud.yahoo.com>
References: <20060215230743.12679.qmail@web34508.mail.mud.yahoo.com>
Message-ID: <43F4294E.9090405@statistik.uni-dortmund.de>

Srinivas Iyyer wrote:

> Hi Group,
>  I have two objects
> 1. A data.frame with 2 columns
> 
> Apple  4
> Boy    2
> Cat    5
> Dog    10
> Eel    9
> ...
> Zebra  10
> (26 rows)
> 
> I have another object which was obtained as vector of
> integers with names as character.
> 
> Fruit 10
> King 20
> Eel  19
> Boy 20
> Apple 15
> ...
> (26 rows)
> 
> Now I wanted to combine the two objects and wanted a
> result that would look like this:
> 
> Apple  4 15
> Boy    2 20
> Cat    5 28
> Dog    10 25
> Eel    9 19
> 
> 
> result <- cbind(obj1, obj2)
> 
> My result is now jumbled:
> 
> Apple  4 34
> Boy    2 21
> Cat    5 234
> Dog    10 23
> Eel    9  12
> 
> I want to write identical row names elements together.
> 
> 
> What could be done here. Could any one please help me.
> 


See ?merge

Uwe Ligges


> thanks
> Srini
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From chris at lordsutch.com  Thu Feb 16 08:55:01 2006
From: chris at lordsutch.com (Chris Lawrence)
Date: Thu, 16 Feb 2006 02:55:01 -0500
Subject: [R] logistic regression
In-Reply-To: <Pine.LNX.4.64.0602160709230.6035@gannet.stats.ox.ac.uk>
References: <BAY110-F1FBF55F74104A358E2143C7FB0@phx.gbl>
	<e2e0e3d30602152149h1c1f8090laa0bb51dc9991ac7@mail.gmail.com>
	<Pine.LNX.4.64.0602160709230.6035@gannet.stats.ox.ac.uk>
Message-ID: <e2e0e3d30602152355g6d3ce1carac8f06590a586536@mail.gmail.com>

On 2/16/06, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Thu, 16 Feb 2006, Chris Lawrence wrote:
>
> > On 2/15/06, Taka Matzmoto <sell_mirage_ne at hotmail.com> wrote:
> >> I have two bianry variables (X and Y) and one continuous variable (Z).
> >>
> >> I like to know, after controlling for the continuous variable, where one of
> >> the binary is significantly related to the other binary variable using
> >> logistic regression
> >>
> >> model <- glm(Y ~ X + Z, family=binomial)
> >>
> >> Is checking the significance of the coefficient of X  a proper way for doing
> >> that ?
> >
> > Yes, that will do it.
>
> Sorry, not so.  That is a Wald test, and its power goes to zero as the
> true effect increases.  You need to do a likelihood ratio test via
> anova() to get a reasonable test.

MASS, 3rd edition - p. 225-26.  (I haven't collected my pennies yet
for MASS 4.)  Incidentally, at least the 3rd ed. doesn't suggest doing
the LR test as an alternative to relying on the Wald chi-square test
or z/t test.

For what it's worth, Long's Regression Models for Categorical and
Limited Dependent Variables (1997, p. 97) disagrees in terms of the
practical significance of Hauck and Donner's result (sorry, no JASA
access from home to check):

"In general, it is unclear whether one test is to be preferred to the
other [e.g., Wald or LR].  Rothenberg (1984) suggests that neither
test is uniformly superior, while Hauck and Donner (1977) suggest that
the Wald test is less powerful than the LR test.  In practice, the
choice of which test to use is often determined by convenience." 
(Long then goes on to discuss the need to estimate nested models for
the LR test, versus the need to do matrix algebra to calculate the
Wald test, as an illustration of the contrast in convenience.)

Rothenberg (1984) is in Econometrika vol 52, pp. 827-42, according to
Long's bibliography, for anyone fascinated enough by this question to
go digging.

Off to bed...


Chris



From nshephard at gmail.com  Thu Feb 16 08:59:46 2006
From: nshephard at gmail.com (Neil Shephard)
Date: Thu, 16 Feb 2006 15:59:46 +0800
Subject: [R] Sweave - problems with underscores in variable names...
Message-ID: <31b34fca0602152359k28bc82bex3c432a3c41e79cff@mail.gmail.com>

Hi all,

I've just started using the Friedrich Leisch's Sweave package to
generate LaTeX reports with results of my analyses embedded as
required.

I've encountered a bit of a problem though in the processing of the
resulting *.tex file that is as far as I can tell, down to the fact
that my variable names have underscores ('_') in their names.

The relevant section of code is....

 <<missing_data,echo=false,results=tex>>=
## Lists observations with missing data
miss_1431 <- subset(gen, PPARG1.2_1431GA == "", select=
c(AAA_ID,PPARG1.2_1431GA))
xtable(miss_1431, caption="Missing data for PPARG1.2-1431GA")
miss_p12a <- subset(gen, PPARG2_P12A_CG == "", select= c(AAA_ID,PPARG2_P12A_CG))
xtable(miss_p12a, caption="Missing data for PPARG2-P12A_CG")

@

and the variables in my data set have the following names...

> names(gen)
[1] "AAA_ID"          "OPN_1083AG"      "OPN_1239AC"      "OPN_282TC"
[5] "OPN_750CT"       "OPN_443CT"       "PPARG1.2_1431GA" "PPARG2_P12A_CG"
[9] "OPG_1181GC"

In tables that are generated have the character after the subscript
subscripted, as opposed to being displayed as desired (see pg 4 of
example output at
http://slack.ser.man.ac.uk/files/genetic_analysis.pdf , please ignore
the table on pg 3, as I said I'm just starting :-).

After googling and searching R-help archives didn't reveal any obvious
problems with this (other than in older versions of R underscores were
not allowed in variable names).

My question is, other than the obvious of renaming my variables, or
manually editing the .tex file that Sweave produces, is there any way
to have variable names with underscores correctly represented in the
resulting tex file?

The error log-file generated when running pdflatex on the .tex file
can be viewed at http://slack.ser.man.ac.uk/files/genetic_analysis.log

Please let me know if I need to provide any more information, and my
thanks in advance,

Neil

> version
         _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    2.1
year     2005
month    12
day      20
svn rev  36812
language R

--
"Once, adv. - Enough
Twice, adv. - Once too often"
 - Ambrose Bierce, The Devil's Dictionary

Email - nshephard at gmail.com
Website - http://slack.ser.man.ac.uk/
Blog - http://slack---line.blogspot.com/
Flickr - http://www.flickr.com/photos/slackline/



From Roger.Bivand at nhh.no  Thu Feb 16 09:18:54 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 16 Feb 2006 09:18:54 +0100 (CET)
Subject: [R] Sweave - problems with underscores in variable names...
In-Reply-To: <31b34fca0602152359k28bc82bex3c432a3c41e79cff@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0602160910380.658-100000@reclus.nhh.no>

On Thu, 16 Feb 2006, Neil Shephard wrote:

> Hi all,
> 
> I've just started using the Friedrich Leisch's Sweave package to
> generate LaTeX reports with results of my analyses embedded as
> required.
> 
> I've encountered a bit of a problem though in the processing of the
> resulting *.tex file that is as far as I can tell, down to the fact
> that my variable names have underscores ('_') in their names.

Can you replace the default row and/or column names with strings that
LaTeX will digest, such as c("AAA\\_ID", "OPN\\_1083AG", ...), since you
are using results=tex? You could automate it by something like:

> z <- c("AAA_ID", "OPN_1083AG") # really colnames(my_xtable)
> gsub("[_]", "\\\\_", z) # and assign back as colnames
[1] "AAA\\_ID"     "OPN\\_1083AG"

after assigning the output of xtable to an object (untried).

> 
> The relevant section of code is....
> 
>  <<missing_data,echo=false,results=tex>>=
> ## Lists observations with missing data
> miss_1431 <- subset(gen, PPARG1.2_1431GA == "", select=
> c(AAA_ID,PPARG1.2_1431GA))
> xtable(miss_1431, caption="Missing data for PPARG1.2-1431GA")
> miss_p12a <- subset(gen, PPARG2_P12A_CG == "", select= c(AAA_ID,PPARG2_P12A_CG))
> xtable(miss_p12a, caption="Missing data for PPARG2-P12A_CG")
> 
> @
> 
> and the variables in my data set have the following names...
> 
> > names(gen)
> [1] "AAA_ID"          "OPN_1083AG"      "OPN_1239AC"      "OPN_282TC"
> [5] "OPN_750CT"       "OPN_443CT"       "PPARG1.2_1431GA" "PPARG2_P12A_CG"
> [9] "OPG_1181GC"
> 
> In tables that are generated have the character after the subscript
> subscripted, as opposed to being displayed as desired (see pg 4 of
> example output at
> http://slack.ser.man.ac.uk/files/genetic_analysis.pdf , please ignore
> the table on pg 3, as I said I'm just starting :-).
> 
> After googling and searching R-help archives didn't reveal any obvious
> problems with this (other than in older versions of R underscores were
> not allowed in variable names).
> 
> My question is, other than the obvious of renaming my variables, or
> manually editing the .tex file that Sweave produces, is there any way
> to have variable names with underscores correctly represented in the
> resulting tex file?
> 
> The error log-file generated when running pdflatex on the .tex file
> can be viewed at http://slack.ser.man.ac.uk/files/genetic_analysis.log
> 
> Please let me know if I need to provide any more information, and my
> thanks in advance,
> 
> Neil
> 
> > version
>          _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    2
> minor    2.1
> year     2005
> month    12
> day      20
> svn rev  36812
> language R
> 
> --
> "Once, adv. - Enough
> Twice, adv. - Once too often"
>  - Ambrose Bierce, The Devil's Dictionary
> 
> Email - nshephard at gmail.com
> Website - http://slack.ser.man.ac.uk/
> Blog - http://slack---line.blogspot.com/
> Flickr - http://www.flickr.com/photos/slackline/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From azzalini at stat.unipd.it  Thu Feb 16 09:24:05 2006
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Thu, 16 Feb 2006 09:24:05 +0100
Subject: [R] distribution fitting
In-Reply-To: <1AFEC6AD98A0AA4D948216A768A1578C480D33@e2k3ms3.urmc-sh.rochester.edu>
References: <1AFEC6AD98A0AA4D948216A768A1578C480D33@e2k3ms3.urmc-sh.rochester.edu>
Message-ID: <20060216092405.4b43a911.azzalini@stat.unipd.it>

On Wed, 15 Feb 2006 14:39:53 -0500, Glazko, Galina wrote:

GG> Dear list,
GG> 
GG>  
GG> 
GG> Does anyone know how to fit the power law distribution?
GG> 
GG> I have the empirical distribution and would like to check whether
GG> it fits
GG> 
GG> the power law (with the power estimated from the data).
GG> 


you can you fitdistr() from MASS, as indicated below

notice that the so-called "exponential power" (Subbotin, 1923) 
distribution has been used with many different sort of parametrizations; 
the form used below is proportional to  exp(-|x|^p/p).

best regards,
Adelchi Azzalini
--
library(MASS)
dep<- function(x,location,scale,tail) # Exponential power (=Subbotin)
{
  const<- 2*tail^(1/tail-1) *gamma(1/tail)
  z<- (x-location)/scale
  exp(-abs(z)^tail/tail)/(scale*const)
}


x <- rt(100,df=3)
a <- fitdistr(x, dep, start=list(location=0, scale=1, tail=1.5))
print(a$estimate)
print(a$sd)

-- 
Adelchi Azzalini  <azzalini at stat.unipd.it>
Dipart.Scienze Statistiche, Universit?? di Padova, Italia
tel. +39 049 8274147,  http://azzalini.stat.unipd.it/



From comtech.usa at gmail.com  Thu Feb 16 09:27:35 2006
From: comtech.usa at gmail.com (Michael)
Date: Thu, 16 Feb 2006 00:27:35 -0800
Subject: [R] How to plot on new windows?
Message-ID: <b1f16d9d0602160027xa1297eclf788fc90437a0a4e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/44a351a7/attachment.pl

From ahimsa at camposarceiz.com  Thu Feb 16 09:37:05 2006
From: ahimsa at camposarceiz.com (ahimsa campos arceiz)
Date: Thu, 16 Feb 2006 17:37:05 +0900
Subject: [R] How to plot on new windows?
In-Reply-To: <b1f16d9d0602160027xa1297eclf788fc90437a0a4e@mail.gmail.com
 >
References: <b1f16d9d0602160027xa1297eclf788fc90437a0a4e@mail.gmail.com>
Message-ID: <6.0.1.1.0.20060216173554.03a885e0@pop.notfound.org>

  try

?x11( )




At 17:27 16/02/2006, you wrote:
>Hi all,
>
>I am using R-console. However when I do plot(xx, yy), it always overwrites
>the existing plot window.
>
>How can I make it open a new plot window and plot onto the new window?
>
>Thanks a lot!
>
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Ahimsa Campos Arceiz
The University Museum,
The University of Tokyo
Hongo 7-3-1, Bunkyo-ku,
Tokyo 113-0033
phone +81-(0)3-5841-2824
cell +81-(0)80-5402-7702



From cg.pettersson at evp.slu.se  Thu Feb 16 10:15:32 2006
From: cg.pettersson at evp.slu.se (CG Pettersson)
Date: Thu, 16 Feb 2006 10:15:32 +0100 (CET)
Subject: [R] Failure when updating package nlme
Message-ID: <21432.62.119.38.100.1140081332.squirrel@webmail.slu.se>

Hello all,

R2.2.1, W2k

I posted a similar question last week after having problem with a group
update (using update.packages()), without getting any answer.

Now I have updated all packages separately, and found that the problem
comes from nlme:

Everything comes home, the md5 checksums are ok, but then the old version
can??t be removed from my computer, leaving a "nlme" library with only the
"libs" sublibrary left.

As my R doesn??t start without nlme, I am stuck here. R doesn??t start with
only the "libs" left and doesn??t start without nlme. What??s going on?

It??s no big crisis as I have the nlme version from the R installation
file, but I try to keep my installation as updated as possible, so it??s
irritating. :)

/CG


-- 
CG Pettersson, MSci, PhD Stud.
Swedish University of Agricultural Sciences (SLU)
Dep. of Crop Production Ekology. Box 7043.
SE-750 07 Uppsala, Sweden
cg.pettersson at vpe.slu.se



From j.hall at beatson.gla.ac.uk  Thu Feb 16 10:24:30 2006
From: j.hall at beatson.gla.ac.uk (Jacqueline Hall)
Date: Thu, 16 Feb 2006 09:24:30 -0000
Subject: [R] brookmeyer & crowley CI for median survival time
Message-ID: <000001c632da$ca2c7b90$16e814ac@o1jh>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/14b33b00/attachment.pl

From azzalini at stat.unipd.it  Thu Feb 16 10:28:41 2006
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Thu, 16 Feb 2006 10:28:41 +0100
Subject: [R] using kernel density estimates to infer mode of distribution
In-Reply-To: <5.2.1.1.2.20060215172856.0127c948@postoffice9.mail.cornell.edu>
References: <5.2.1.1.2.20060215172856.0127c948@postoffice9.mail.cornell.edu>
Message-ID: <20060216102841.0997c0b4.azzalini@stat.unipd.it>

On Wed, 15 Feb 2006 18:28:25 -0500, Dan Rabosky wrote:

DR> 
DR>  Is it possible to use "density" or another kernel density
DR>  estimator to  identify the mode of a distribution?  When I use
DR>  'density', the resulting 

a simple option is of the form
   fit$eval[fit$estimate==max(fit$estimate)]
assuming that fit$eval is the vector of evaluation points,
and fit$estimate the corrisponding density estimates (this is
the sort of output produced by sm.density)

Here I have assumed there is single mode and we are in the scalar
case, for simplicity. Some variant required in the more general case.


best regards,

Adelchi Azzalini
-- 
Adelchi Azzalini  <azzalini at stat.unipd.it>
Dipart.Scienze Statistiche, Universit?? di Padova, Italia
tel. +39 049 8274147,  http://azzalini.stat.unipd.it/



From ligges at statistik.uni-dortmund.de  Thu Feb 16 10:33:17 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 16 Feb 2006 10:33:17 +0100
Subject: [R] Failure when updating package nlme
In-Reply-To: <21432.62.119.38.100.1140081332.squirrel@webmail.slu.se>
References: <21432.62.119.38.100.1140081332.squirrel@webmail.slu.se>
Message-ID: <43F446DD.4020201@statistik.uni-dortmund.de>

CG Pettersson wrote:

> Hello all,
> 
> R2.2.1, W2k
> 
> I posted a similar question last week after having problem with a group
> update (using update.packages()), without getting any answer.
> 
> Now I have updated all packages separately, and found that the problem
> comes from nlme:
> 
> Everything comes home, the md5 checksums are ok, but then the old version
> can??t be removed from my computer, leaving a "nlme" library with only the
> "libs" sublibrary left.
> 
> As my R doesn??t start without nlme, I am stuck here. R doesn??t start with
> only the "libs" left and doesn??t start without nlme. What??s going on?
> 
> It??s no big crisis as I have the nlme version from the R installation
> file, but I try to keep my installation as updated as possible, so it??s
> irritating. :)


You cannot update a package if it is loaded, because Windows locks the dll.
Hence start R without loading nlme (that it is loaded might be because 
you mentioned it in some Startup file such as .Rprofile or a saved 
Workspace image loads the package for some reason - don't know whether 
this could happen for nlme).
Hence RGui --vanilla might be right for you. Then update.packages().

Uwe Ligges






> /CG
> 
>



From anni22 at libero.it  Thu Feb 16 10:35:51 2006
From: anni22 at libero.it (anni22@libero.it)
Date: Thu, 16 Feb 2006 10:35:51 +0100
Subject: [R] Hybrid Multidimensional Scaling
Message-ID: <IURXBR$10732057852CE042C765B043A4D46AEE@libero.it>

Hi all,

Does anyone know if there's R code available for doing Hybrid Multidimensional Scaling (or Semi-Strong HMDS, e.g. Belbin 1991 J. Veg. Sci. 2:491-)? I've found only commercial software that does it.

Thanks,
Anni



From beline.jesson at univ-rennes1.fr  Thu Feb 16 10:38:06 2006
From: beline.jesson at univ-rennes1.fr (b=?ISO-8859-1?B?6Q==?=line jesson)
Date: Thu, 16 Feb 2006 10:38:06 +0100
Subject: [R] Interaction between R and Perl
Message-ID: <C01A068E.1D8%beline.jesson@univ-rennes1.fr>

Hello!

I'm calling R from Perl with Statistics-R perl module for a microarray
analysis integrated web tool.
I have some questions for a multi-users utilisation:
- Can I change the directory where R is running in order to have a directory
per user? Then no problem of erasing R data of an other user.
 
- If it's not possible, can I limite the number of users at the same time? I
see "lock", "is_blocked" and  "is_started" options in Statistics-R module.
How can I use them?

Thanks!

B??line



From comtech.usa at gmail.com  Thu Feb 16 10:38:39 2006
From: comtech.usa at gmail.com (Michael)
Date: Thu, 16 Feb 2006 01:38:39 -0800
Subject: [R] MANOVA: how do I read off within and between Sum-of-Squares
	info from the manova result?
Message-ID: <b1f16d9d0602160138q1bb2a477t4c53c35cf518cf3e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/ee262691/attachment.pl

From pburns at pburns.seanet.com  Thu Feb 16 10:58:35 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu, 16 Feb 2006 09:58:35 +0000
Subject: [R] looping through tasks
In-Reply-To: <43F3D7AC.9070304@unc.edu>
References: <43F3D7AC.9070304@unc.edu>
Message-ID: <43F44CCB.2060008@pburns.seanet.com>

S Poetry is one place to look for hints about R
programming.  Some of the details are not quite
right, and there are simple solutions to some of
the topics, but for the most part it is good for R.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

E. Michael Foster wrote:

>Hi,
>
>I'm moving (slowly) to R from STATA.
>I often have need to move through a set of tasks across a series of years.
>In this case, you can see that I'm mimicking -reshape- in STATA, but I'm 
>less interested in the
>task than in programming R.
>
>    library(foreign)
>    mydata<-read.dta("z:\example.dta")
>    for (y in 2000:2002) {
>    myvar<-paste("score",y,sep="") # x is available for each year
>    assign( eval(myvar),
>    data.frame(cbind(mydata[,c("var1", eval(myvar))],c(eval(y)))))
>    colnames(eval(myvar))<-c("person","score","year")
>    }
>
>I"m getting the error, "
>Error in "colnames<-"(`*tmp*`, value = c("newid", "score", "year")) :
>attempt to set colnames on object with less than two dimensions
>Whether I set up a data frame or not doesn't matter.
>
>As you might guess, what I want to do at the end is rbind the little 
>files, and the lack of consistent column names causes the program to choke.
>
>Suggestions? /m
>
>
>  
>



From Markus.Preisetanz at clientvela.com  Thu Feb 16 11:03:26 2006
From: Markus.Preisetanz at clientvela.com (Markus Preisetanz)
Date: Thu, 16 Feb 2006 11:03:26 +0100
Subject: [R] scatterplot3d: how to show scatterpoints in 2D-space with color
	as 3rd dimension?
Message-ID: <79799E69EA1DA246A51F983B5663BEA2CE6591@server2.hq.clientvela.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/ba8afce2/attachment.pl

From r.hankin at noc.soton.ac.uk  Thu Feb 16 11:10:45 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Thu, 16 Feb 2006 10:10:45 +0000
Subject: [R] scatterplot3d: how to show scatterpoints in 2D-space with
	color as 3rd dimension?
In-Reply-To: <79799E69EA1DA246A51F983B5663BEA2CE6591@server2.hq.clientvela.net>
References: <79799E69EA1DA246A51F983B5663BEA2CE6591@server2.hq.clientvela.net>
Message-ID: <A60A6160-ADA9-46AB-9D92-EF21D7EC43ED@soc.soton.ac.uk>

Hi

p3d() of the onion package does this.


best wishes


Robin



On 16 Feb 2006, at 10:03, Markus Preisetanz wrote:

> Dear Colleagues:
>
>
>
> I have 3 numeric variables (say x, y, z) in a data.frame and want  
> to draw a 2D-scatterplot with the 3rd dimension as color, if  
> possible without having to convert the whole thing to an appropiate  
> matrix for image() manually.
>
>
>
> Can e.g. scatterplot3d do something like this? There's a function  
> xyz.convert, but I couldn't find the way to use it properly.
>
>
>
> Sincerly,
>
>
>
> ___________________
>
> Markus Preisetanz
>
> Consultant
>
>
>
> Client Vela GmbH
>
> Albert-Ro??haupter-Str. 32
>
> 81369 M??nchen
>
> fon:          +49 (0) 89 742 17-113
>
> fax:          +49 (0) 89 742 17-150
>
> mailto:markus.preisetanz at clientvela.com  
> <mailto:markus.preisetanz at clientvela.com>
>
>
>
> Diese E-Mail enth??lt vertrauliche und/oder rechtlich gesch??tzte  
> Informationen. Wenn Sie nicht der richtige Adressat sind oder diese  
> E-Mail irrt??mlich erhalten haben, informieren Sie bitte sofort den  
> Absender und vernichten Sie diese Mail. Das unerlaubte Kopieren  
> sowie die unbefugte Weitergabe dieser E-Mail ist nicht gestattet.
>
> This e-mail may contain confidential and/or privileged infor... 
> {{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From B.Rowlingson at lancaster.ac.uk  Thu Feb 16 11:27:45 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 16 Feb 2006 10:27:45 +0000
Subject: [R] readline() for passwords?
In-Reply-To: <1140038491.5079.34.camel@localhost.localdomain>
References: <43F320E7.8080907@uclm.es> <loom.20060215T154856-79@post.gmane.org>
	<1140038491.5079.34.camel@localhost.localdomain>
Message-ID: <43F453A1.1040608@lancaster.ac.uk>

Ulf Mehlig wrote:

> I am using RODBC to access a password-protected database. Is there a
> possibility to prevent that the password appears on the screen when
> issuing the odbcConnect() command? I thought of something like
> readline() without echo. I guess that a getpass()-based solution
> wouldn't work for ESS/Emacs, anyway, would it?

tk has a way of doing this, so you can build a function that uses the 
tcltk package. Something like:

getPassword <- function(){
   require(tcltk)
   tt <- tktoplevel()
   pass=tclVar("")
   label.widget <- tklabel(tt, text="Enter Password")
   password.widget <-  tkentry(tt,show="*",textvariable=pass)
   ok <- tkbutton(tt,text="Ok",command=function()tkdestroy(tt))
   tkpack(label.widget, password.widget,ok)
   tkwait.window(tt)
   return(tclvalue(pass))
}

The vital part here is the 'show="*"' option in the tkentry widget.

Of course this is no use if you aren't in a graphical environment at the 
time.

Barry



From comtech.usa at gmail.com  Thu Feb 16 11:33:10 2006
From: comtech.usa at gmail.com (Michael)
Date: Thu, 16 Feb 2006 02:33:10 -0800
Subject: [R] how to clear screen in R-console?
Message-ID: <b1f16d9d0602160233r1a95ba81qd81583b047b7f2af@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/a6420954/attachment.pl

From M.Campbell at erini.ac.uk  Thu Feb 16 11:51:06 2006
From: M.Campbell at erini.ac.uk (Malcolm Campbell)
Date: Thu, 16 Feb 2006 10:51:06 -0000
Subject: [R] how to clear screen in R-console?
Message-ID: <C9328F0EEDC3BC439FDABD12060E9109132E77@erini1.ERINI.local>


Ctrl+L should work

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Michael
Sent: 16 February 2006 10:33
To: R-help at stat.math.ethz.ch
Subject: [R] how to clear screen in R-console?

HI all,

How to clear the screen in R-console?

Thanks a lot@!

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ozric at web.de  Thu Feb 16 11:51:20 2006
From: ozric at web.de (Christian Schulz)
Date: Thu, 16 Feb 2006 11:51:20 +0100
Subject: [R] how to clear screen in R-console?
In-Reply-To: <b1f16d9d0602160233r1a95ba81qd81583b047b7f2af@mail.gmail.com>
References: <b1f16d9d0602160233r1a95ba81qd81583b047b7f2af@mail.gmail.com>
Message-ID: <43F45928.8010902@web.de>

ctrl - e & l

>HI all,
>
>How to clear the screen in R-console?
>
>Thanks a lot@!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From p.dalgaard at biostat.ku.dk  Thu Feb 16 11:55:47 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Feb 2006 11:55:47 +0100
Subject: [R] A concrete type I/III Sum of square problem
In-Reply-To: <43F41DA0.2010806@gmail.com>
References: <43F41DA0.2010806@gmail.com>
Message-ID: <x24q2z374c.fsf@viggo.kubism.ku.dk>

Gregor Gorjanc <gregor.gorjanc at gmail.com> writes:

> > WPhantom <wp1 at tiscali.fr> writes:
> > 
> >>> Thanks Brian for the reference.
> >>>   I just discover that it is available in our 
> >>> library so I going to take it & read it soon.
> >>> Actually, I don't even know the difference 
> >>> between a multistratum vs a single-stratum AOV. A 
> >>> quick search on google returned me the R materials so that I imagine
> >>> that these concepts are quite specific to R.
> > 
> > You have to be careful not to confuse Google's view of the world with
> > Reality...
> > 
> > The concept of error strata is much older than R, and existed for
> > instance in Genstat, anno 1977 or so. However, Genstat seems to have
> > left little impression on the Internet. 
> >  
> >>> I will read the book first before asking for more informations.
> > 
> > The executive summary is that the concept of error strata relies
> > substantially on having a balanced design (at least for the random
> > effects), so that the analysis can be decomposed into analyses of
> > means, contrasts, and contrasts of means. For unbalanced designs, you
> > usually get meaningless analyses.
> > 
> 
> Can you (prof. Dalgaard) please point us to relevant book with these
> topics. I am very interested in it since my data are often unbalanced.

Hmm, the Danish tradition is highly based on lecture notes, so I don't
have a specific book for you. One possible starting point is 

Tue Tjur (1984): Analysis of variance designs in orthogonal designs.
Int.Statist.Review 52, 33-81.

The thing to notice in relation to that paper is that the
decomposition (p.55) of the covariance matrix as sum(lambda_B Q_B^0)
is highly dependent on having an orthogonal design. Without the
orthogonality, it still defines a model, but typically one without a
sensible interpretation.

Look at a simple 1-way anova with three groups of equal size. The Q
matrices will be the projections P_X and I-P_X, where X is the design
matrix for the grouping factor, e.g.

> X <- model.matrix(~factor(rep(1:3,each=2)))
> X
  (Intercept) factor(rep(1:3, each = 2))2 factor(rep(1:3, each = 2))3
1           1                           0                           0
2           1                           0                           0
3           1                           1                           0
4           1                           1                           0
5           1                           0                           1
6           1                           0                           1
...

P_X can be found in the following semi-secret way:

> P <- stats:::proj.matrix(X)
> P
    1   2   3   4   5   6
1 0.5 0.5 0.0 0.0 0.0 0.0
2 0.5 0.5 0.0 0.0 0.0 0.0
3 0.0 0.0 0.5 0.5 0.0 0.0
4 0.0 0.0 0.5 0.5 0.0 0.0
5 0.0 0.0 0.0 0.0 0.5 0.5
6 0.0 0.0 0.0 0.0 0.5 0.5

Suppose we put a random component of 10 on P_X and 1 on (I-P_X).
We then get

> diag(6) - P + 10*P
    1   2   3   4   5   6
1 5.5 4.5 0.0 0.0 0.0 0.0
2 4.5 5.5 0.0 0.0 0.0 0.0
3 0.0 0.0 5.5 4.5 0.0 0.0
4 0.0 0.0 4.5 5.5 0.0 0.0
5 0.0 0.0 0.0 0.0 5.5 4.5
6 0.0 0.0 0.0 0.0 4.5 5.5

which is a perfectly sensible covariance for within-group correlated
data. 

Now try the same stunt with unbalanced data:

> X <- model.matrix(~factor(rep(1:3,1:3))-1)
> P <- stats:::proj.matrix(X)
> diag(6) - P + 10*P
   1   2   3 4 5 6
1 10 0.0 0.0 0 0 0
2  0 5.5 4.5 0 0 0
3  0 4.5 5.5 0 0 0
4  0 0.0 0.0 4 3 3
5  0 0.0 0.0 3 4 3
6  0 0.0 0.0 3 3 4

I.e. we are de facto assuming that observations in the smaller group
have a larger variance than observations in the larger groups.



 
> >>> Thanks
> >>> 
> >>> Sylvain Cl?ment
> >>> 
> >>> At 12:38 14/02/2006, you wrote:
> >>
> >>>> >More to the point, you are confusing 
> >>>> >multistratum AOV with single-stratuam AOV.  For 
> >>>> >a good tutorial, see MASS4 (bibliographic 
> >>>> >information in the R FAQ).  For unbalanced data 
> >>>> >we suggest you use lme() instead.
> 
> I do not have the whole book in my head as prof. Ripley probably does,
> but I can not recall to read about this in MASS4. I am sure I am wrong
> and would you (prof. Ripley) be please so kind and point us to relevant
> chapters/pages.
> 
> Many thanks.
> 
> -- 
> Lep pozdrav / With regards,
>     Gregor Gorjanc
> 
> ----------------------------------------------------------------------
> University of Ljubljana     PhD student
> Biotechnical Faculty
> Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
> Groblje 3                   mail: gregor.gorjanc <at> bfro.uni-lj.si
> 
> SI-1230 Domzale             tel: +386 (0)1 72 17 861
> Slovenia, Europe            fax: +386 (0)1 72 17 888
> 
> ----------------------------------------------------------------------
> "One must learn by doing the thing; for though you think you know it,
>  you have no certainty until you try." Sophocles ~ 450 B.C.
> ----------------------------------------------------------------------
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From comtech.usa at gmail.com  Thu Feb 16 12:22:09 2006
From: comtech.usa at gmail.com (Michael)
Date: Thu, 16 Feb 2006 03:22:09 -0800
Subject: [R] how to clear screen in R-console?
In-Reply-To: <43F45928.8010902@web.de>
References: <b1f16d9d0602160233r1a95ba81qd81583b047b7f2af@mail.gmail.com>
	<43F45928.8010902@web.de>
Message-ID: <b1f16d9d0602160322m6cb6a484mfd6aee2bbf2b758b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/620b7446/attachment.pl

From patrick at pdrechsler.de  Thu Feb 16 12:35:20 2006
From: patrick at pdrechsler.de (Patrick Drechsler)
Date: Thu, 16 Feb 2006 11:35:20 +0000
Subject: [R] Sweave - problems with underscores in variable names...
References: <31b34fca0602152359k28bc82bex3c432a3c41e79cff@mail.gmail.com>
Message-ID: <87slqjv8nb.fsf@pdrechsler.de>


Neil Shephard wrote on 16 Feb 2006 08:59:46 MET:

> I've encountered a bit of a problem though in the processing of
> the resulting *.tex file that is as far as I can tell, down to
> the fact that my variable names have underscores ('_') in their
> names.

<URL:http://www.tex.ac.uk/cgi-bin/texfaq2html?label=underscore>

Adding "\usepackage{underscore}" to your preamble should help.


Patrick
-- 
Die Summe der Intelligenz auf dem Planeten ist eine Konstante.
Die Bevlkerung wchst.



From gregor.gorjanc at gmail.com  Thu Feb 16 12:58:50 2006
From: gregor.gorjanc at gmail.com (Gregor GORJANC)
Date: Thu, 16 Feb 2006 12:58:50 +0100
Subject: [R] A concrete type I/III Sum of square problem
In-Reply-To: <x24q2z374c.fsf@viggo.kubism.ku.dk>
References: <43F41DA0.2010806@gmail.com> <x24q2z374c.fsf@viggo.kubism.ku.dk>
Message-ID: <b20ae6290602160358m3ef96e52o4cea058208183042@mail.gmail.com>

On 16 Feb 2006 11:55:47 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> Gregor Gorjanc <gregor.gorjanc at gmail.com> writes:
>
...
> > Can you (prof. Dalgaard) please point us to relevant book with these
> > topics. I am very interested in it since my data are often unbalanced.
>
> Hmm, the Danish tradition is highly based on lecture notes, so I don't
> have a specific book for you. One possible starting point is

If there are some good lecture notes around I would like to read them
even more ;)

> Tue Tjur (1984): Analysis of variance designs in orthogonal designs.
> Int.Statist.Review 52, 33-81.

Thank you very much for this reference and example code!

--
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------------------------------------
University of Ljubljana          PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                            mail: gregor.gorjanc <at> bfro.uni-lj.si
SI-1230 Domzale                tel: +386 (0)1 72 17 861
Slovenia, Europe                 fax: +386 (0)1 72 17 888
----------------------------------------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.



From frymor at gmail.com  Thu Feb 16 13:12:34 2006
From: frymor at gmail.com (Assa Yeroslaviz)
Date: Thu, 16 Feb 2006 13:12:34 +0100
Subject: [R] factors and contrast matrix
Message-ID: <9086c4f40602160412o77cd3c41n@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/7559e1e0/attachment.pl

From rdiaz at cnio.es  Thu Feb 16 13:16:05 2006
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Thu, 16 Feb 2006 13:16:05 +0100
Subject: [R] Interaction between R and Perl
In-Reply-To: <C01A068E.1D8%beline.jesson@univ-rennes1.fr>
References: <C01A068E.1D8%beline.jesson@univ-rennes1.fr>
Message-ID: <200602161316.05765.rdiaz@cnio.es>

Dear B??line,

On Thursday 16 February 2006 10:38, b??line jesson wrote:
> Hello!
>
> I'm calling R from Perl with Statistics-R perl module for a microarray
> analysis integrated web tool.
> I have some questions for a multi-users utilisation:
> - Can I change the directory where R is running in order to have a
> directory per user? Then no problem of erasing R data of an other user.

see "setwd". 

Alternatively, you can have your CGI copy the R file(s) with commands to the 
newly created directory, and run in there.

>
> - If it's not possible, can I limite the number of users at the same time?
> I see "lock", "is_blocked" and  "is_started" options in Statistics-R
> module. How can I use them?

If your concern is one user deleting/modifying another user's data, I'd just 
use setwd: it is simpler and cleaner.

We use a somewhat similar approach for our web-based applications 
(www.asterias.info), which use R, and create a temporary directory for every 
request.


HTH,

R.
>
> Thanks!
>
> B??line
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Ram??n D??az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol??gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern??ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://ligarto.org/rdiaz
PGP KeyID: 0xE89B3462
(http://ligarto.org/rdiaz/0xE89B3462.asc)



**NOTA DE CONFIDENCIALIDAD** Este correo electr??nico, y en s...{{dropped}}



From sina.muster at web.de  Thu Feb 16 13:23:56 2006
From: sina.muster at web.de (Sina Muster)
Date: Thu, 16 Feb 2006 13:23:56 +0100
Subject: [R] sums of absolute deviations about the median as split function
 in rpart
Message-ID: <43F46EDC.7010802@web.de>

Dear R community,

as stated in Breiman et.al. (1984) and De'Ath & Fabricius (2000) using
sums of absolute deviations about the median as an impurity measure
gives robust trees.

I would like to use this method in rpart.

Has somebody already tried this method in rpart? Is there maybe already
a script available somewhere?

I am aware of the possibility to define usersplits myself with eval,
split and init. As an R beginner, though, I would like to check the
existing experience first.

Thanks
Sina


Writing a thesis on "The effects of land-use change on vegetation
patterns in a Southern-Alpine valley (Switzerland)"

University of Potsdam, Germany
Department of Geoecology



From p.dalgaard at biostat.ku.dk  Thu Feb 16 13:30:31 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Feb 2006 13:30:31 +0100
Subject: [R] A concrete type I/III Sum of square problem
In-Reply-To: <b20ae6290602160358m3ef96e52o4cea058208183042@mail.gmail.com>
References: <43F41DA0.2010806@gmail.com> <x24q2z374c.fsf@viggo.kubism.ku.dk>
	<b20ae6290602160358m3ef96e52o4cea058208183042@mail.gmail.com>
Message-ID: <x2mzgr1o60.fsf@viggo.kubism.ku.dk>

Gregor GORJANC <gregor.gorjanc at gmail.com> writes:

> On 16 Feb 2006 11:55:47 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> > Gregor Gorjanc <gregor.gorjanc at gmail.com> writes:
> >
> ...
> > > Can you (prof. Dalgaard) please point us to relevant book with these
> > > topics. I am very interested in it since my data are often unbalanced.
> >
> > Hmm, the Danish tradition is highly based on lecture notes, so I don't
> > have a specific book for you. One possible starting point is
> 
> If there are some good lecture notes around I would like to read them
> even more ;)

You may find that there is a language barrier....
 
> > Tue Tjur (1984): Analysis of variance designs in orthogonal designs.
> > Int.Statist.Review 52, 33-81.
> 
> Thank you very much for this reference and example code!

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From gregor.gorjanc at gmail.com  Thu Feb 16 13:37:42 2006
From: gregor.gorjanc at gmail.com (Gregor GORJANC)
Date: Thu, 16 Feb 2006 13:37:42 +0100
Subject: [R] A concrete type I/III Sum of square problem
In-Reply-To: <x2mzgr1o60.fsf@viggo.kubism.ku.dk>
References: <43F41DA0.2010806@gmail.com> <x24q2z374c.fsf@viggo.kubism.ku.dk>
	<b20ae6290602160358m3ef96e52o4cea058208183042@mail.gmail.com>
	<x2mzgr1o60.fsf@viggo.kubism.ku.dk>
Message-ID: <b20ae6290602160437w5e8dd10bu35649352cdf5aeee@mail.gmail.com>

On 16 Feb 2006 13:30:31 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> Gregor GORJANC <gregor.gorjanc at gmail.com> writes:
>
> > On 16 Feb 2006 11:55:47 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> > > Gregor Gorjanc <gregor.gorjanc at gmail.com> writes:
> > >
> > ...
> > > > Can you (prof. Dalgaard) please point us to relevant book with these
> > > > topics. I am very interested in it since my data are often unbalanced.
> > >
> > > Hmm, the Danish tradition is highly based on lecture notes, so I don't
> > > have a specific book for you. One possible starting point is
> >
> > If there are some good lecture notes around I would like to read them
> > even more ;)
>
> You may find that there is a language barrier....

Oh, dear. I hoped for lecture notes written in universal language for
stats. i.e. R, you probably heard about it. Just joking. Thanks anyway.

--
Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------------------------------------
University of Ljubljana          PhD student
Biotechnical Faculty
Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
Groblje 3                            mail: gregor.gorjanc <at> bfro.uni-lj.si
SI-1230 Domzale                tel: +386 (0)1 72 17 861
Slovenia, Europe                 fax: +386 (0)1 72 17 888
----------------------------------------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.



From dvumani at hotmail.com  Thu Feb 16 13:53:49 2006
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Thu, 16 Feb 2006 12:53:49 +0000
Subject: [R] symbol decoration and .Call
Message-ID: <BAY110-F111A1AFE635F2492A95EF5A3FB0@phx.gbl>

Dear R-users,
I am a novice user of .Call and am trying to use the C code in R-Ext to 
kickstart my learning process. All the code compiles but when I try to use 
.Call it gives the error (using "out.c" as an example),

Error in .Call("out", x, y) : C entry point "out" not in load table

when i use PEDUMP to check whether the symbol is loaded I find that it is 
loaded as "_Z3outP7SEXPRECS0_" and when I use this instead of "out" the 
program work.

How can I remove the decoration so that only "out" is loaded?

Thanks, Vumani



From hb at maths.lth.se  Thu Feb 16 13:59:29 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Thu, 16 Feb 2006 13:59:29 +0100
Subject: [R] how to clear screen in R-console?
In-Reply-To: <b1f16d9d0602160322m6cb6a484mfd6aee2bbf2b758b@mail.gmail.com>
References: <b1f16d9d0602160233r1a95ba81qd81583b047b7f2af@mail.gmail.com>
	<43F45928.8010902@web.de>
	<b1f16d9d0602160322m6cb6a484mfd6aee2bbf2b758b@mail.gmail.com>
Message-ID: <59d7961d0602160459t493de978na04494e207460e55@mail.gmail.com>

Hi,

depends on what type of terminal you are running.  For example, if you
run R in a VT100 terminal, you can try

cat("The following VT100 escape sequence will clear the screen on a
VT100 terminal\n")
cat("\033[2J")  # <ESC>[2J  == Clear Screen
cat("If the screen was cleared you should only see this sentence.\n")

i.e.

vt100ClearScreen <- function(...) cat("\033[2J")

Some links:
http://www.fh-jena.de/~gmueller/Kurs_halle/esc_vt100.html
http://en.wikipedia.org/wiki/VT100

Note, this is not guaranteed to work everywhere.  To the best of my
knowledge, you will not be able to do anything like this in Rgui on
Windows.

Cheers

Henrik


On 2/16/06, Michael <comtech.usa at gmail.com> wrote:
> Any funcation that is callable from my program, instead of pressing keys?
>
> Thanks a lot!
>
>
> On 2/16/06, Christian Schulz <ozric at web.de> wrote:
> >
> > ctrl - e & l
> >
> > >HI all,
> > >
> > >How to clear the screen in R-console?
> > >
> > >Thanks a lot@!
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help at stat.math.ethz.ch mailing list
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> > >
> > >
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>


--
Henrik Bengtsson
Mobile: +46 708 909208 (+1h UTC)



From ripley at stats.ox.ac.uk  Thu Feb 16 14:08:07 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Feb 2006 13:08:07 +0000 (GMT)
Subject: [R] logistic regression
In-Reply-To: <e2e0e3d30602152355g6d3ce1carac8f06590a586536@mail.gmail.com>
References: <BAY110-F1FBF55F74104A358E2143C7FB0@phx.gbl>
	<e2e0e3d30602152149h1c1f8090laa0bb51dc9991ac7@mail.gmail.com>
	<Pine.LNX.4.64.0602160709230.6035@gannet.stats.ox.ac.uk>
	<e2e0e3d30602152355g6d3ce1carac8f06590a586536@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602161303300.12709@gannet.stats.ox.ac.uk>

On Thu, 16 Feb 2006, Chris Lawrence wrote:

> On 2/16/06, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> On Thu, 16 Feb 2006, Chris Lawrence wrote:
>>
>>> On 2/15/06, Taka Matzmoto <sell_mirage_ne at hotmail.com> wrote:
>>>> I have two bianry variables (X and Y) and one continuous variable (Z).
>>>>
>>>> I like to know, after controlling for the continuous variable, where one of
>>>> the binary is significantly related to the other binary variable using
>>>> logistic regression
>>>>
>>>> model <- glm(Y ~ X + Z, family=binomial)
>>>>
>>>> Is checking the significance of the coefficient of X  a proper way for doing
>>>> that ?
>>>
>>> Yes, that will do it.
>>
>> Sorry, not so.  That is a Wald test, and its power goes to zero as the
>> true effect increases.  You need to do a likelihood ratio test via
>> anova() to get a reasonable test.
>
> MASS, 3rd edition - p. 225-26.  (I haven't collected my pennies yet
> for MASS 4.)  Incidentally, at least the 3rd ed. doesn't suggest doing
> the LR test as an alternative to relying on the Wald chi-square test
> or z/t test.

It certainly does discuss it as the standard against which the Wald test 
falls short, and also discusses examining the profile likelihood.

> For what it's worth, Long's Regression Models for Categorical and
> Limited Dependent Variables (1997, p. 97) disagrees in terms of the
> practical significance of Hauck and Donner's result (sorry, no JASA
> access from home to check):
>
> "In general, it is unclear whether one test is to be preferred to the
> other [e.g., Wald or LR].  Rothenberg (1984) suggests that neither
> test is uniformly superior, while Hauck and Donner (1977) suggest that
> the Wald test is less powerful than the LR test.  In practice, the
> choice of which test to use is often determined by convenience."
> (Long then goes on to discuss the need to estimate nested models for
> the LR test, versus the need to do matrix algebra to calculate the
> Wald test, as an illustration of the contrast in convenience.)

That's not the point.  The Wald test can have very low power in some 
practical circumstances.  Given that the two are equally easy to do in any 
decent piece of software (including R), why not use the one better 
supported theoretically and without a known serious flaw?

> Rothenberg (1984) is in Econometrika vol 52, pp. 827-42, according to
> Long's bibliography, for anyone fascinated enough by this question to
> go digging.
>
> Off to bed...
>
>
> Chris
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Thu Feb 16 14:10:46 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 16 Feb 2006 08:10:46 -0500
Subject: [R] using kernel density estimates to infer mode of distribut
 ion
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED815@usctmx1106.merck.com>

This might be of interest:
http://math.usu.edu/~minnotte/research/software/modetree.r
(I was not able to get to the link, but google has a cached version.)

Prof. Marron's SiZer maps may also be of interest, but AFAIK the code is in
Matlab only.

Andy


From: Dan Rabosky
> 
> 
> Hello...
> 
> Is it possible to use "density" or another kernel density 
> estimator to 
> identify the mode of a distribution?  When I use 'density', 
> the resulting 
> density plot of my data is much cleaner than the original 
> noisy histogram, 
> and I can clearly see the signal that I am interested in.  
> E.g., suppose my 
> data is actually drawn from two or more normal (or other) 
> distributions.  Looking at the kernel density plots, it seems 
> that the 
> estimator gives a good approximation of the modal values of each 
> distribution, but I can't figure out how to obtain these 
> values short of 
> visually estimating the location of the mode using the plot(density).
> 
> Is there a relatively easy way to do this?
> 
> Thanks in advance for your help!
> Dan Rabosky
> 
> 
> 
> Dan Rabosky
> Department of Ecology and Evolutionary Biology
> Cornell University
> Ithaca, NY14853-2701 USA
> web: http://www.birds.cornell.edu/evb/Graduates_Dan.htm
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ripley at stats.ox.ac.uk  Thu Feb 16 14:12:25 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Feb 2006 13:12:25 +0000 (GMT)
Subject: [R] symbol decoration and .Call
In-Reply-To: <BAY110-F111A1AFE635F2492A95EF5A3FB0@phx.gbl>
References: <BAY110-F111A1AFE635F2492A95EF5A3FB0@phx.gbl>
Message-ID: <Pine.LNX.4.64.0602161310160.12709@gannet.stats.ox.ac.uk>

1) Please read the posting guide and use the appropriate list, not R-help.

2) Please tell us exactly what you did, including your OS, R version and 
so on as the guide asks.  Looks to me like you used a C++ compiler to 
compile C.

On Thu, 16 Feb 2006, Vumani Dlamini wrote:

> Dear R-users,
> I am a novice user of .Call and am trying to use the C code in R-Ext to
> kickstart my learning process. All the code compiles but when I try to use
> .Call it gives the error (using "out.c" as an example),
>
> Error in .Call("out", x, y) : C entry point "out" not in load table
>
> when i use PEDUMP to check whether the symbol is loaded I find that it is
> loaded as "_Z3outP7SEXPRECS0_" and when I use this instead of "out" the
> program work.
>
> How can I remove the decoration so that only "out" is loaded?
>
> Thanks, Vumani
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gkkarthikeyann at gmail.com  Thu Feb 16 14:30:57 2006
From: gkkarthikeyann at gmail.com (karthi keyan)
Date: Thu, 16 Feb 2006 19:00:57 +0530
Subject: [R] reg crossvalidation in SVM in R programming
Message-ID: <8e3e33900602160530x750d3980v1785da28fe7cf1fb@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/bbc14054/attachment.pl

From gkkarthikeyann at gmail.com  Thu Feb 16 14:32:15 2006
From: gkkarthikeyann at gmail.com (karthi keyan)
Date: Thu, 16 Feb 2006 19:02:15 +0530
Subject: [R] reg cross validation in svm
Message-ID: <8e3e33900602160532t55f1963dnf4923e768d76f3d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/16f83e2d/attachment.pl

From amsa36060 at yahoo.com  Thu Feb 16 15:15:44 2006
From: amsa36060 at yahoo.com (Amir Safari)
Date: Thu, 16 Feb 2006 06:15:44 -0800 (PST)
Subject: [R] reg cross validation in svm
In-Reply-To: <8e3e33900602160532t55f1963dnf4923e768d76f3d@mail.gmail.com>
Message-ID: <20060216141544.96522.qmail@web60414.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/61af7ebe/attachment.pl

From bianca.vieru at free.fr  Thu Feb 16 15:38:37 2006
From: bianca.vieru at free.fr (Bianca Vieru-Dimulescu)
Date: Thu, 16 Feb 2006 15:38:37 +0100
Subject: [R] (m)simtest  ?
Message-ID: <43F48E6D.9060101@free.fr>

Hi,.

We have 2 values (first formant F1, second formant F2) for a given 
phoneme for six languages. We want to see whether the languages are 
significantly different one from another for this given phoneme.

We have done a manova on our data and it works well, but we doesn't 
allow us to see which pair of  languages are different.

If we have only one formant for the phoneme, we would use simtest to see 
the pairs significantly different... but the simtest doesn't work for 2 
responses, so we look for a multivariate simtest.


Thanks for your advice!



So our data:
#read the data file
 >tous_y <- read.table("moyenne.txt", header=TRUE, sep="\t", 
na.strings="NA", dec=".", strip.white=TRUE)
 >lg<-as.factor(c(rep("anglais",6),rep("allemand",6),rep("arabe",6),rep("espagnol",6), 
rep("italien",6), rep("portugais",6), rep("francais",6)))
 >tousy<-data.frame(tous_y,lg)

#simtest for only one response
 >summary(simtest(F1_nearey~lg, type="Tukey", data=tousy))       

Absolute Error Tolerance:  0.001

Coefficients:
                       Estimate t value Std.Err. p raw p Bonf p adj
lgitalien-lgfrancais     -0.074  -1.898    0.039 0.066      1 0.495
lgitalien-lganglais      -0.064  -1.630    0.039 0.112      1 0.658
lgitalien-lgarabe        -0.055  -1.413    0.039 0.167      1 0.780
lgitalien-lgespagnol     -0.046  -1.166    0.039 0.252      1 0.891
lgportugais-lgfrancais   -0.039  -1.004    0.039 0.322      1 0.938
lgitalien-lgallemand     -0.037  -0.957    0.039 0.345      1 0.948
lgfrancais-lgallemand     0.037  -0.940    0.039 0.353      1 0.948
lgportugais-lgitalien     0.035  -0.894    0.039 0.378      1 0.955
lgportugais-lganglais    -0.029  -0.736    0.039 0.467      1 0.973
lgfrancais-lgespagnol     0.029  -0.732    0.039 0.469      1 0.973
lganglais-lgallemand      0.026  -0.672    0.039 0.506      1 0.978
lgportugais-lgarabe      -0.020  -0.519    0.039 0.607      1 0.992
lgfrancais-lgarabe        0.019  -0.485    0.039 0.631      1 0.994
lgespagnol-lganglais     -0.018  -0.464    0.039 0.646      1 0.994
lgarabe-lgallemand        0.018  -0.455    0.039 0.652      1 0.994
lgportugais-lgespagnol   -0.011  -0.272    0.039 0.787      1 0.999
lgfrancais-lganglais      0.011  -0.268    0.039 0.790      1 0.999
lgespagnol-lgarabe       -0.010  -0.247    0.039 0.807      1 0.999
lgarabe-lganglais        -0.008  -0.217    0.039 0.829      1 0.999
lgespagnol-lgallemand     0.008  -0.208    0.039 0.836      1 0.999
lgportugais-lgallemand   -0.002  -0.064    0.039 0.949      1 0.999


#manova for the two responses
 > fit <- manova(cbind(F1_nearey,F2_nearey)~lg)
 > summary.manova(fit,test = "Pillai")


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: moyenne.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/188ed281/moyenne.txt

From Ita.Cirovic-Donev at hypo-alpe-adria.com  Thu Feb 16 16:24:00 2006
From: Ita.Cirovic-Donev at hypo-alpe-adria.com (Ita.Cirovic-Donev@hypo-alpe-adria.com)
Date: Thu, 16 Feb 2006 16:24:00 +0100
Subject: [R]  search algorithm
Message-ID: <OF0BCE3332.7384AE1B-ONC1257117.00546562-C1257117.0054987F@arz.co.at>





Hello,

the dimension of the matrix is [3565x18]. what would be your suggestion
which method to use?

Ita



From andy_liaw at merck.com  Thu Feb 16 16:37:46 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 16 Feb 2006 10:37:46 -0500
Subject: [R] 2 variable partial dependence plot for Random Forest
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED819@usctmx1106.merck.com>

The basic recipes are all in the code.  Just generate all unique
combinations of the two variables and loop over that.

Andy

From: Joseph Retzer
> 
> Has anyone created a 2 variable partial dependence plot based on a
> randomForest object? Or would anyone have a suggestion as to 
> how to do this?
> Many thanks,
> J. Retzer
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ligges at statistik.uni-dortmund.de  Thu Feb 16 16:46:08 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 16 Feb 2006 16:46:08 +0100
Subject: [R] search algorithm
In-Reply-To: <OF0BCE3332.7384AE1B-ONC1257117.00546562-C1257117.0054987F@arz.co.at>
References: <OF0BCE3332.7384AE1B-ONC1257117.00546562-C1257117.0054987F@arz.co.at>
Message-ID: <43F49E40.20001@statistik.uni-dortmund.de>

Ita.Cirovic-Donev at hypo-alpe-adria.com wrote:

> 
> 
> 
> Hello,
> 
> the dimension of the matrix is [3565x18]. what would be your suggestion
> which method to use?


I think we should apply linear regression on a 3565x18 matrix, but then 
let us think about what the underlying question could have been. Do you 
want to use the search algorithm to look for this question?
Otherwise, if the matrix would have been 1x1 containg the number 42 .... ;-)

Uwe Ligges




> Ita
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From bill.shipley at usherbrooke.ca  Thu Feb 16 16:50:25 2006
From: bill.shipley at usherbrooke.ca (Bill Shipley)
Date: Thu, 16 Feb 2006 10:50:25 -0500
Subject: [R] help downloading lme4 from CRAN
Message-ID: <001201c63310$b421dfd0$a41ad284@BIO041>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/4d79b80a/attachment.pl

From arnejol at hotmail.com  Thu Feb 16 16:58:37 2006
From: arnejol at hotmail.com (Arne Jol)
Date: Thu, 16 Feb 2006 15:58:37 +0000
Subject: [R] prediction function for clogit model
Message-ID: <BAY106-F17ABBCEFB00005D1F5E853BEFB0@phx.gbl>

Dear R-Help,

I wonder if there is a prediction function for a clogit model which can be 
used in the same way as the predict function for the multinom model.

In prediction('multinommodel',testset ...)  it is possible to predict the 
class or the class probabilities for a testset. There is a predict function 
for the coxph model but I cannot find an way to use this to predict the 
classes (1,2 or 3) or the class probabilities (0.2, 0.3, 0.5) for example.

Can someone help me with this?

Regards,
Arne Jol



From tlumley at u.washington.edu  Thu Feb 16 17:04:02 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 16 Feb 2006 08:04:02 -0800 (PST)
Subject: [R] how to retrieve robust se in coxph
In-Reply-To: <web-176910030@cgatepro-4.mail.virginia.edu>
References: <web-176910030@cgatepro-4.mail.virginia.edu>
Message-ID: <Pine.LNX.4.64.0602160802580.29019@homer24.u.washington.edu>

On Wed, 15 Feb 2006, Lei  Liu wrote:

> Hi,
>
> I am using coxph in simulations and I want to store the "robust se" (or
> "se2" in frailty models) for each replicate. Is there a function to retrieve
> it, like vcov() for the variance estimate? Thanks!
>

There isn't a function, so you need to extract the $var2 component of the 
model object to get the variance matrix.

 	-thomas



From tlumley at u.washington.edu  Thu Feb 16 17:05:23 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 16 Feb 2006 08:05:23 -0800 (PST)
Subject: [R] how to retrieve robust se in coxph
In-Reply-To: <38b9f0350602152047la19c7bbu@mail.gmail.com>
References: <web-176910030@cgatepro-4.mail.virginia.edu>
	<38b9f0350602152047la19c7bbu@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602160805100.29019@homer24.u.washington.edu>

On Thu, 16 Feb 2006, ronggui wrote:

> see robcov in Design package.

No, don't.  This is not the same thing at all.

 	-thomas

>
> 2006/2/16, Lei  Liu <ll9f at cms.mail.virginia.edu>:
>> Hi,
>>
>> I am using coxph in simulations and I want to store the "robust se" (or
>> "se2" in frailty models) for each replicate. Is there a function to retrieve
>> it, like vcov() for the variance estimate? Thanks!
>>
>> Lei Liu
>> Assistant Professor
>> Division of Biostatistics and Epidemiology
>> Dept. of Public Health Sciences
>> School of Medicine
>> University of Virginia
>>
>> 3181 Hospital West Complex
>> Charlottesville, VA 22908-0717
>>
>> 1-434-982-3364 (o)
>> 1-434-806-8086 (c)
>>
>> liulei at virginia.edu
>> ll9f at virginia.edu
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>
>
> --
> 
> Deparment of Sociology
> Fudan University
>
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From tlumley at u.washington.edu  Thu Feb 16 17:13:34 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 16 Feb 2006 08:13:34 -0800 (PST)
Subject: [R] prediction function for clogit model
In-Reply-To: <BAY106-F17ABBCEFB00005D1F5E853BEFB0@phx.gbl>
References: <BAY106-F17ABBCEFB00005D1F5E853BEFB0@phx.gbl>
Message-ID: <Pine.LNX.4.64.0602160810470.29019@homer24.u.washington.edu>

On Thu, 16 Feb 2006, Arne Jol wrote:

> Dear R-Help,
>
> I wonder if there is a prediction function for a clogit model which can be
> used in the same way as the predict function for the multinom model.
>
> In prediction('multinommodel',testset ...)  it is possible to predict the
> class or the class probabilities for a testset. There is a predict function
> for the coxph model but I cannot find an way to use this to predict the
> classes (1,2 or 3) or the class probabilities (0.2, 0.3, 0.5) for example.
>

I don't think this is going to be possible. The point of conditional 
logistic regression is that the probabilities depend on stratum parameters 
that cannot be estimated accurately. The conditional likelihood removes 
these parameters, but the resulting model does not contain enough 
information to estimate probabilities.

 	-thomas



From tlumley at u.washington.edu  Thu Feb 16 17:18:48 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 16 Feb 2006 08:18:48 -0800 (PST)
Subject: [R] brookmeyer & crowley CI for median survival time
In-Reply-To: <000001c632da$ca2c7b90$16e814ac@o1jh>
References: <000001c632da$ca2c7b90$16e814ac@o1jh>
Message-ID: <Pine.LNX.4.64.0602160815460.29019@homer24.u.washington.edu>

On Thu, 16 Feb 2006, Jacqueline Hall wrote:

> Hi all,
>
> Does anyone know if there is an implementation of Brookmeyer & Crowley's
> confidence interval for the median survival time in R?
> Reference : Brookmeyer & Crowley, "A confidence interval for the median
> survival time" (1982) Biometircs

This is the confidence interval produced by print.survfit.

 	-thomas



From rangeshk at gmail.com  Thu Feb 16 17:19:04 2006
From: rangeshk at gmail.com (Rangesh Kunnavakkam)
Date: Thu, 16 Feb 2006 10:19:04 -0600
Subject: [R] fitting non-liner curves
Message-ID: <839df10a0602160819h2a47fb5al45adae84a215c19c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/528c55ca/attachment.pl

From ligges at statistik.uni-dortmund.de  Thu Feb 16 17:23:21 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 16 Feb 2006 17:23:21 +0100
Subject: [R] help downloading lme4 from CRAN
In-Reply-To: <001201c63310$b421dfd0$a41ad284@BIO041>
References: <001201c63310$b421dfd0$a41ad284@BIO041>
Message-ID: <43F4A6F9.6020705@statistik.uni-dortmund.de>

Bill Shipley wrote:

> Hello.  I am having trouble downloading the lme4 package from the CRAN
> site.  The error is:
>  
> 
>>local({a <- CRAN.packages()
> 
> + install.packages(select.list(a[,1],,TRUE), .libPaths()[1],
> available=a, dependencies=TRUE)})
> trying URL `http://cran.r-project.org/bin/windows/contrib/2.0/PACKAGES'
> Content type `text/plain; charset=iso-8859-1' length 26129 bytes
> opened URL
> downloaded 25Kb
>  
> also installing the dependencies 'Matrix', 'latticeExtra', 'mlmRev'
>  
> trying URL
> `http://cran.r-project.org/bin/windows/contrib/2.0/Matrix_0.95-5.zip'
> Error in download.file(url, destfile, method, mode = "wb") : 
>         cannot open URL
> `http://cran.r-project.org/bin/windows/contrib/2.0/Matrix_0.95-5.zip'
> In addition: Warning message: 
> cannot open: HTTP status was `404 Not Found' 
>  
> Can someone please explain what I am doing wrong?  

You wrong: please upgrade to R-2.2.1!
The 2.0.x repository is no longer supported (nor the 2.1.x one!)

I wrong: Hmmm, looks like I forgot to finally sync the 2.0 directory 
after moving to newer versions.
The last Matrix version is available from
http://cran.r-project.org/bin/windows/contrib/2.0/last/Matrix_0.95-5.zip
(you can install it manually, for example).

Uwe Ligges


> 
> Bill Shipley
> 
> North American Editor, Annals of Botany
> 
> Editor, "Population and Community Biology" series, Springer Publishing
> 
> D??partement de biologie, Universit?? de Sherbrooke,
> 
> Sherbrooke (Qu??bec) J1K 2R1 CANADA
> 
> Bill.Shipley at USherbrooke.ca
> 
> http://callisto.si.usherb.ca:8080/bshipley/
> 
>  
> 
>  
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From f.harrell at vanderbilt.edu  Thu Feb 16 17:48:08 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 16 Feb 2006 10:48:08 -0600
Subject: [R] how to retrieve robust se in coxph
In-Reply-To: <Pine.LNX.4.64.0602160805100.29019@homer24.u.washington.edu>
References: <web-176910030@cgatepro-4.mail.virginia.edu>	<38b9f0350602152047la19c7bbu@mail.gmail.com>
	<Pine.LNX.4.64.0602160805100.29019@homer24.u.washington.edu>
Message-ID: <43F4ACC8.60003@vanderbilt.edu>

Thomas Lumley wrote:
> On Thu, 16 Feb 2006, ronggui wrote:
> 
>> see robcov in Design package.
> 
> 
> No, don't.  This is not the same thing at all.
> 
>     -thomas

Thomas - it is the same thing.  -Frank

> 
>>
>> 2006/2/16, Lei  Liu <ll9f at cms.mail.virginia.edu>:
>>
>>> Hi,
>>>
>>> I am using coxph in simulations and I want to store the "robust se" (or
>>> "se2" in frailty models) for each replicate. Is there a function to 
>>> retrieve
>>> it, like vcov() for the variance estimate? Thanks!
>>>
>>> Lei Liu
>>> Assistant Professor
>>> Division of Biostatistics and Epidemiology
>>> Dept. of Public Health Sciences
>>> School of Medicine
>>> University of Virginia
>>>
>>> 3181 Hospital West Complex
>>> Charlottesville, VA 22908-0717
>>>
>>> 1-434-982-3364 (o)
>>> 1-434-806-8086 (c)
>>>
>>> liulei at virginia.edu
>>> ll9f at virginia.edu
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>>
>>
>>
>> -- 
>> 
>> Deparment of Sociology
>> Fudan University
>>
>>
> 
> Thomas Lumley            Assoc. Professor, Biostatistics
> tlumley at u.washington.edu    University of Washington, Seattle
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From ligges at statistik.uni-dortmund.de  Thu Feb 16 17:56:26 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 16 Feb 2006 17:56:26 +0100
Subject: [R] fitting non-liner curves
In-Reply-To: <839df10a0602160819h2a47fb5al45adae84a215c19c@mail.gmail.com>
References: <839df10a0602160819h2a47fb5al45adae84a215c19c@mail.gmail.com>
Message-ID: <43F4AEBA.4000606@statistik.uni-dortmund.de>

Rangesh Kunnavakkam wrote:

> Dear Sir/Madam,
>                        I have two vectors say x<-c(0,0,2.73,3.42,3.95,4.26)
> and y<-c(0.0,0.5,1.20,1.90,2.6,3.3). I want to fit y as a function of x and
> get the equation.Do I have to use glm() ?

Depends on which underlying model you assume.

Uwe Ligges



> Rangesh
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From charshaw at presby.edu  Thu Feb 16 17:56:57 2006
From: charshaw at presby.edu (Clint Harshaw)
Date: Thu, 16 Feb 2006 11:56:57 -0500
Subject: [R] Ubuntu and R
Message-ID: <43F4AED9.9070508@presby.edu>

I've recently installed Ubuntu 5.10 on a desktop and need R installed, 
however, even after uncommenting the repos associated with universe, 
backports and multiverse, the packages available for Ubuntu are somewhat 
out of date:

clint at simba:~$ apt-cache policy r-base r-base-core
r-base:
   Installed: (none)
   Candidate: 2.1.1-1
   Version table:
      2.1.1-1 0
         500 http://archive.ubuntu.com breezy/universe Packages
r-base-core:
   Installed: (none)
   Candidate: 2.1.1-1
   Version table:
      2.1.1-1 0
         500 http://archive.ubuntu.com breezy/universe Packages

How should I edit my /etc/apt/sources.list so that I can proplery 
maintain a current version of R, and not break my system? I've searched 
the forums at Ubuntu, and there are several similar requests there, but 
no definitive answer that I found.

What are other Ubuntu users here doing to keep their version of R fresh?

Thanks,
Clint
-- 
Clint Harshaw, PhD               Email: charshaw at presby.edu
Department of Mathematics        Ph: 864.833.8995
Presbyterian College             Fax: 864.938.3769	
Clinton, SC USA  29325           Harrington-Peachtree Rm 412



From jonathan.williams at pharmacology.oxford.ac.uk  Thu Feb 16 17:58:34 2006
From: jonathan.williams at pharmacology.oxford.ac.uk (Jonathan Williams)
Date: Thu, 16 Feb 2006 16:58:34 -0000
Subject: [R] How to convert SPSS date data to dates?
Message-ID: <NGBBKJEMOMLJFCOIEGCECEHBJPAA.jonathan.williams@pharm.ox.ac.uk>

Dear R Helpers,

I have imported an SPSS file that contains date data.
The data appear in R in a numeric format, as follows:

10485849600 10477641600 10561104000 10562745600 etc.

I'd be extremely grateful if someone could tell me
how to make these numbers into comprehensible dates!

Thanks,

Jonathan Williams



From kjetilbrinchmannhalvorsen at gmail.com  Thu Feb 16 18:09:45 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Thu, 16 Feb 2006 13:09:45 -0400
Subject: [R] logistic regression
In-Reply-To: <BAY110-F1FBF55F74104A358E2143C7FB0@phx.gbl>
References: <BAY110-F1FBF55F74104A358E2143C7FB0@phx.gbl>
Message-ID: <43F4B1D9.40805@gmail.com>

Taka Matzmoto wrote:
> Hi R users
> 
> I have two bianry variables (X and Y) and one continuous variable (Z).
> 
> I like to know, after controlling for the continuous variable, where one 
> of the binary is significantly related to the other binary variable 
> using logistic regression
> 
> 
> model <- glm(Y ~ X + Z, family=binomial)
> 
> Is checking the significance of the coefficient of X  a proper way for 
> doing that ?
> 
> Any suggestion for this problem ?

You could try a bivariate logistic regression. That is implemented in 
package VGAM (not on CRAN,but google will find it!).

Kjetil

> 
> Thanks
> 
> _________________________________________________________________
> Don?t just search. Find. Check out the new MSN Search!
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From alexandrarma at yahoo.com.br  Thu Feb 16 18:29:18 2006
From: alexandrarma at yahoo.com.br (Alexandra R. M. de Almeida)
Date: Thu, 16 Feb 2006 14:29:18 -0300 (ART)
Subject: [R] Read a csv file
Message-ID: <20060216172918.93276.qmail@web33305.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/669deecd/attachment.pl

From andrej.kastrin at siol.net  Thu Feb 16 18:39:56 2006
From: andrej.kastrin at siol.net (Andrej Kastrin)
Date: Thu, 16 Feb 2006 18:39:56 +0100
Subject: [R] Ubuntu and R
In-Reply-To: <43F4AED9.9070508@presby.edu>
References: <43F4AED9.9070508@presby.edu>
Message-ID: <43F4B8EC.80801@siol.net>

Clint Harshaw wrote:

>I've recently installed Ubuntu 5.10 on a desktop and need R installed, 
>however, even after uncommenting the repos associated with universe, 
>backports and multiverse, the packages available for Ubuntu are somewhat 
>out of date:
>
>clint at simba:~$ apt-cache policy r-base r-base-core
>r-base:
>   Installed: (none)
>   Candidate: 2.1.1-1
>   Version table:
>      2.1.1-1 0
>         500 http://archive.ubuntu.com breezy/universe Packages
>r-base-core:
>   Installed: (none)
>   Candidate: 2.1.1-1
>   Version table:
>      2.1.1-1 0
>         500 http://archive.ubuntu.com breezy/universe Packages
>
>How should I edit my /etc/apt/sources.list so that I can proplery 
>maintain a current version of R, and not break my system? I've searched 
>the forums at Ubuntu, and there are several similar requests there, but 
>no definitive answer that I found.
>
>What are other Ubuntu users here doing to keep their version of R fresh?
>
>Thanks,
>Clint
>  
>
Hi,

there is no up-to-date R package for Breezy. I have no problem with 
source installation; just follow the instructions and that's all. If you 
prefer package installation, try with checkinstall.

Cheers, Andrej



From p.dalgaard at biostat.ku.dk  Thu Feb 16 18:42:27 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Feb 2006 18:42:27 +0100
Subject: [R] How to convert SPSS date data to dates?
In-Reply-To: <NGBBKJEMOMLJFCOIEGCECEHBJPAA.jonathan.williams@pharm.ox.ac.uk>
References: <NGBBKJEMOMLJFCOIEGCECEHBJPAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <x2mzgrkxoc.fsf@turmalin.kubism.ku.dk>

"Jonathan Williams" <jonathan.williams at pharmacology.oxford.ac.uk> writes:

> Dear R Helpers,
> 
> I have imported an SPSS file that contains date data.
> The data appear in R in a numeric format, as follows:
> 
> 10485849600 10477641600 10561104000 10562745600 etc.
> 
> I'd be extremely grateful if someone could tell me
> how to make these numbers into comprehensible dates!

> c(10485849600,10477641600,10561104000,10562745600)+ISOdate(1582,10,14)
[1] "1915-01-26 13:00:00 CET" "1914-10-23 13:00:00 CET"
[3] "1917-06-15 13:00:00 CET" "1917-07-04 13:00:00 CET"

Does this look right? (If you don't want the times, use as.Date).

BTW: There's a strange asymmetry:

> ISOdate(1582,10,14)+
> c(10485849600,10477641600,10561104000,10562745600)
[1] "1915-01-26 12:00:00 GMT" "1914-10-23 12:00:00 GMT"
[3] "1917-06-15 12:00:00 GMT" "1917-07-04 12:00:00 GMT"

(have we seen this before?).

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ccleland at optonline.net  Thu Feb 16 18:49:48 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 16 Feb 2006 12:49:48 -0500
Subject: [R] How to convert SPSS date data to dates?
In-Reply-To: <NGBBKJEMOMLJFCOIEGCECEHBJPAA.jonathan.williams@pharm.ox.ac.uk>
References: <NGBBKJEMOMLJFCOIEGCECEHBJPAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <43F4BB3C.8080405@optonline.net>

Here is one way:

library(chron)

as.chron(ISOdate(1582, 10, 14) + mydata$SPSSDATE)

Jonathan Williams wrote:
> Dear R Helpers,
> 
> I have imported an SPSS file that contains date data.
> The data appear in R in a numeric format, as follows:
> 
> 10485849600 10477641600 10561104000 10562745600 etc.
> 
> I'd be extremely grateful if someone could tell me
> how to make these numbers into comprehensible dates!
> 
> Thanks,
> 
> Jonathan Williams
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From jjorgensen at fastmail.fm  Thu Feb 16 18:55:54 2006
From: jjorgensen at fastmail.fm (jjorgensen@fastmail.fm)
Date: Thu, 16 Feb 2006 09:55:54 -0800
Subject: [R] plclust and y-axis clipping
Message-ID: <1140112554.10752.254556763@webmail.messagingengine.com>

Hello R-sters,

I was just wondering if anyone had come up with a solution to the y-axis
being clipped off in dendrograms using plclust.  Is there something
similar to the "margin" call within plotting rpart objects for plclust?

Best regards,

Jeff Jorgensen



From ggrothendieck at gmail.com  Thu Feb 16 19:01:10 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 16 Feb 2006 13:01:10 -0500
Subject: [R] fitting non-liner curves
In-Reply-To: <839df10a0602160819h2a47fb5al45adae84a215c19c@mail.gmail.com>
References: <839df10a0602160819h2a47fb5al45adae84a215c19c@mail.gmail.com>
Message-ID: <971536df0602161001u53f4d4e3m3a97d89f982f8b60@mail.gmail.com>

Just eyeballing your data it looks like a simple quadratic might be ok.

plot(y ~ x)
y.lm <- lm(y ~ poly(x, 2))
points(fitted(y.lm) ~ x, type = "b", col = 2)

On 2/16/06, Rangesh Kunnavakkam <rangeshk at gmail.com> wrote:
> Dear Sir/Madam,
>                       I have two vectors say x<-c(0,0,2.73,3.42,3.95,4.26)
> and y<-c(0.0,0.5,1.20,1.90,2.6,3.3). I want to fit y as a function of x and
> get the equation.Do I have to use glm() ?
> Rangesh
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Thu Feb 16 19:02:55 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Feb 2006 18:02:55 +0000 (GMT)
Subject: [R] How to convert SPSS date data to dates?
In-Reply-To: <x2mzgrkxoc.fsf@turmalin.kubism.ku.dk>
References: <NGBBKJEMOMLJFCOIEGCECEHBJPAA.jonathan.williams@pharm.ox.ac.uk>
	<x2mzgrkxoc.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0602161756370.16459@gannet.stats.ox.ac.uk>

On Thu, 16 Feb 2006, Peter Dalgaard wrote:

> "Jonathan Williams" <jonathan.williams at pharmacology.oxford.ac.uk> writes:
>
>> Dear R Helpers,
>>
>> I have imported an SPSS file that contains date data.
>> The data appear in R in a numeric format, as follows:
>>
>> 10485849600 10477641600 10561104000 10562745600 etc.
>>
>> I'd be extremely grateful if someone could tell me
>> how to make these numbers into comprehensible dates!
>
>> c(10485849600,10477641600,10561104000,10562745600)+ISOdate(1582,10,14)
> [1] "1915-01-26 13:00:00 CET" "1914-10-23 13:00:00 CET"
> [3] "1917-06-15 13:00:00 CET" "1917-07-04 13:00:00 CET"
>
> Does this look right? (If you don't want the times, use as.Date).
>
> BTW: There's a strange asymmetry:
>
>> ISOdate(1582,10,14)+
>> c(10485849600,10477641600,10561104000,10562745600)
> [1] "1915-01-26 12:00:00 GMT" "1914-10-23 12:00:00 GMT"
> [3] "1917-06-15 12:00:00 GMT" "1917-07-04 12:00:00 GMT"
>
> (have we seen this before?).

Yes, and the second is correct.  Timezones are taken from the lhs in
+.POSIXt.  (That could probably now safely be changed.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tyler.smith at mail.mcgill.ca  Thu Feb 16 19:13:04 2006
From: tyler.smith at mail.mcgill.ca (Tyler Smith)
Date: Thu, 16 Feb 2006 13:13:04 -0500
Subject: [R] Ubuntu and R
Message-ID: <20060216131304.458zmok7swssg4c4@webmail.mcgill.ca>

You could try the stable/sarge backport from Cran. That's less likely 
to cause problems than using the Etch version, but I'm not using Ubuntu 
so I can't confirm this. Add the following to your sources.list and see 
how it goes:

     deb http://cran.R-project.org/bin/linux/debian stable/

-- 
Tyler Smith



From ggrothendieck at gmail.com  Thu Feb 16 19:18:11 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 16 Feb 2006 13:18:11 -0500
Subject: [R] How to convert SPSS date data to dates?
In-Reply-To: <NGBBKJEMOMLJFCOIEGCECEHBJPAA.jonathan.williams@pharm.ox.ac.uk>
References: <NGBBKJEMOMLJFCOIEGCECEHBJPAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <971536df0602161018i172c8596xe1d5f6706e443b4f@mail.gmail.com>

spss.get in package Hmisc can handle SPSS dates automatically.
This and additional discussion on SPSS dates is available
in the Help Desk article in R News 4/1.

On 2/16/06, Jonathan Williams
<jonathan.williams at pharmacology.oxford.ac.uk> wrote:
> Dear R Helpers,
>
> I have imported an SPSS file that contains date data.
> The data appear in R in a numeric format, as follows:
>
> 10485849600 10477641600 10561104000 10562745600 etc.
>
> I'd be extremely grateful if someone could tell me
> how to make these numbers into comprehensible dates!
>
> Thanks,
>
> Jonathan Williams
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ibanez at bioef.org  Thu Feb 16 19:24:18 2006
From: ibanez at bioef.org (Berta)
Date: Thu, 16 Feb 2006 19:24:18 +0100
Subject: [R] testing the significance of the variance components using lme
Message-ID: <00d401c63326$34bc7e60$3301a8c0@BIOEF.ORG>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/34c5d712/attachment.pl

From axa5797 at rit.edu  Thu Feb 16 19:17:18 2006
From: axa5797 at rit.edu (Anusha Aiyaloo kannan (RIT Student))
Date: Thu, 16 Feb 2006 13:17:18 -0500
Subject: [R] Help to find correlation.
References: <A8211152E29B0F4FBC3F553F684D1F2A18DE5F@svits28.main.ad.rit.edu>
Message-ID: <A8211152E29B0F4FBC3F553F684D1F2A18DE65@svits28.main.ad.rit.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/e97aa126/attachment.pl

From fernandomayer at gmail.com  Thu Feb 16 19:32:15 2006
From: fernandomayer at gmail.com (Fernando Mayer)
Date: Thu, 16 Feb 2006 16:32:15 -0200
Subject: [R] Ubuntu and R
In-Reply-To: <20060216131304.458zmok7swssg4c4@webmail.mcgill.ca>
References: <20060216131304.458zmok7swssg4c4@webmail.mcgill.ca>
Message-ID: <43F4C52F.3040803@gmail.com>

I did this in my Ubuntu 5.10 and it works very well...

Fernando Mayer.

Tyler Smith escreveu:

>You could try the stable/sarge backport from Cran. That's less likely 
>to cause problems than using the Etch version, but I'm not using Ubuntu 
>so I can't confirm this. Add the following to your sources.list and see 
>how it goes:
>
>     deb http://cran.R-project.org/bin/linux/debian stable/
>
>  
>



From tsfeldman at noble.org  Thu Feb 16 19:32:55 2006
From: tsfeldman at noble.org (Feldman, Tracy)
Date: Thu, 16 Feb 2006 12:32:55 -0600
Subject: [R] how can I use lmer on a windows machine?
Message-ID: <497D588A106806408FB0792E4E9A165883662E@mail2.noble.org>

To whom it may concern:

I am using R version 1.9.1 beta on a windows machine, and I am trying to
use a function called lmer (in packages lme4 and Matrix).  I am not sure
if this version will support these packages (when I install them from
the GUI, the function lmer does not work).  I wondered if I need to
install a newer version of R, and if so, which version should I install,
and how should I do that?
 
Thank you so much for your time and help.  Please send replies to
tsfeldman at noble.org

Take care,
Tracy S. Feldman

Postdoc
Noble Foundation



From HStevens at muohio.edu  Thu Feb 16 20:21:53 2006
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Thu, 16 Feb 2006 14:21:53 -0500
Subject: [R] segmentation fault with Hmisc areg.boot()
Message-ID: <BC8A77DD-B116-41E0-A14F-5E0AD78B5087@muohio.edu>

Hi Folks,
Mac OS 10.4.4
R 2.2.1(2005-12-20 r36812)
Hmisc 3.0-10
acepack 1.3-2.2

I keep getting a "segmentation fault" when trying to run areg.boot in  
the Hmisc package. I include below output from two different attempts.
Thank you in advance for any help.

Hank Stevens

The following is taken from the example in the areg.boot  
documentation, run inside Aquamacs Emacs:

 > set.seed(171)  # to be able to reproduce example
 > x1 <- rnorm(200)
 > x2 <- runif(200)  # a variable that is really unrelated to y]
 > x3 <- factor(sample(c('cat','dog','cow'), 200,TRUE))  # also  
unrelated to y
 > y  <- exp(x1 + rnorm(200)/3)
 > f  <- areg.boot(y ~ x1 + x2 + x3, B=40)
Loading required package: acepack

Process R segmentation fault at Thu Feb 16 14:13:44 2006

############
The following is the automated report following the crash from the  
same code in the R GUI:

Date/Time:      2006-02-16 14:18:21.336 -0500
OS Version:     10.4.4 (Build 8G32)
Report Version: 3

Command: R
Path:    /Applications/R.app/Contents/MacOS/R
Parent:  WindowServer [75]

Version: 1.14 (2129)

PID:    902
Thread: 0

Exception:  EXC_BAD_ACCESS (0x0001)
Codes:      KERN_INVALID_ADDRESS (0x0001) at 0x63110304

Thread 0 Crashed:
0   acepack.so               	0x0169a2c0 avas_ + 1752 (avas.f:112)
1   libR.dylib               	0x0024f498 do_dotCode + 1844 (dotcode.c: 
1722)
2   libR.dylib               	0x00265cb0 Rf_eval + 1544 (eval.c:405)
3   libR.dylib               	0x00267ccc do_set + 224 (eval.c:1309)
4   libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
5   libR.dylib               	0x0026744c do_begin + 136 (eval.c:1058)
6   libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
7   libR.dylib               	0x00266150 Rf_applyClosure + 952  
(eval.c:576)
8   libR.dylib               	0x00265d2c Rf_eval + 1668 (eval.c:417)
9   libR.dylib               	0x00268678 do_eval + 700 (eval.c:1568)
10  libR.dylib               	0x0029acec do_internal + 392 (names.c: 
1084)
11  libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
12  libR.dylib               	0x00266150 Rf_applyClosure + 952  
(eval.c:576)
13  libR.dylib               	0x00265d2c Rf_eval + 1668 (eval.c:417)
14  libR.dylib               	0x00267ccc do_set + 224 (eval.c:1309)
15  libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
16  libR.dylib               	0x0026744c do_begin + 136 (eval.c:1058)
17  libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
18  libR.dylib               	0x00266150 Rf_applyClosure + 952  
(eval.c:576)
19  libR.dylib               	0x00265d2c Rf_eval + 1668 (eval.c:417)
20  libR.dylib               	0x00267ccc do_set + 224 (eval.c:1309)
21  libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
22  org.R-project.R          	0x00015884 RGUI_ReplIteration + 500  
(crt.c:300)
23  org.R-project.R          	0x00015674 RGUI_ReplConsole + 148  
(crt.c:300)
24  org.R-project.R          	0x000155c8 run_REngineRmainloop + 156  
(crt.c:300)
25  org.R-project.R          	0x0000e56c -[REngine runREPL] + 76  
(crt.c:300)
26  com.apple.Foundation     	0x928e949c __NSFireTimer + 116
27  com.apple.CoreFoundation 	0x90770aec __CFRunLoopDoTimer + 184
28  com.apple.CoreFoundation 	0x9075d464 __CFRunLoopRun + 1680
29  com.apple.CoreFoundation 	0x9075ca18 CFRunLoopRunSpecific + 268
30  com.apple.HIToolbox      	0x9318e1e0 RunCurrentEventLoopInMode + 264
31  com.apple.HIToolbox      	0x9318d874 ReceiveNextEventCommon + 380
32  com.apple.HIToolbox      	0x9318d6e0  
BlockUntilNextEventMatchingListInMode + 96
33  com.apple.AppKit         	0x9368b104 _DPSNextEvent + 384
34  com.apple.AppKit         	0x9368adc8 -[NSApplication  
nextEventMatchingMask:untilDate:inMode:dequeue:] + 116
35  com.apple.AppKit         	0x9368730c -[NSApplication run] + 472
36  com.apple.AppKit         	0x93777e68 NSApplicationMain + 452
37  org.R-project.R          	0x00002eb0 _start + 392 (crt.c:267)
38  dyld                     	0x8fe01048 _dyld_start + 60

Thread 1:
0   libSystem.B.dylib        	0x9001f20c select + 12
1   org.R-project.R          	0x00004674 -[RController readThread:] +  
524 (crt.c:300)
2   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
3   libSystem.B.dylib        	0x9002b200 _pthread_body + 96

Thread 2:
0   libSystem.B.dylib        	0x90049748 syscall_thread_switch + 8
1   com.apple.Foundation     	0x928fead0 +[NSThread sleepUntilDate:]  
+ 152
2   com.apple.AppKit         	0x93728034 -[NSUIHeartBeat  
_heartBeatThread:] + 1100
3   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
4   libSystem.B.dylib        	0x9002b200 _pthread_body + 96

Thread 0 crashed with PPC Thread State 64:
   srr0: 0x000000000169a2c0 srr1:  
0x100000000200f030                        vrsave: 0x0000000000000000
     cr: 0x48022448          xer: 0x0000000020000000   lr:  
0x000000000169a1c0  ctr: 0x0000000000000000
     r0: 0x0000000000003840   r1: 0x00000000bfffa390   r2:  
0x0000000006dd4e98   r3: 0x0000000000000000
     r4: 0x0000000006dd4858   r5: 0x0000000006dd3598   r6:  
0x0000000006dd3bd8   r7: 0x0000000006dd4218
     r8: 0x0000000063110304   r9: 0x0000000007488658  r10:  
0x00000000000000c7  r11: 0x000000000748a258
    r12: 0x0000000006dd4858  r13: 0x0000000000000640  r14:  
0x000000000748a418  r15: 0x00000000071ec9a8
    r16: 0x0000000007488018  r17: 0x0000000000000004  r18:  
0x0000000007489c18  r19: 0x00000000019fc7c0
    r20: 0x0000000006dd1018  r21: 0x00000000000000c8  r22:  
0x0000000000002580  r23: 0x0000000000003840
    r24: 0x00000000000000c8  r25: 0x00000000000000c7  r26:  
0x0000000000000640  r27: 0x0000000007489c18
    r28: 0x000000000748b3b8  r29: 0x0000000000000098  r30:  
0x0000000006dd4218  r31: 0x0000000001699bf0

Binary Images Description:
     0x1000 -    0x3bfff org.R-project.R 1.14 (2129)	/Applications/ 
R.app/Contents/MacOS/R
    0x55000 -    0x87fff libreadline.5.0.dylib 	/Library/Frameworks/ 
R.framework/Resources/lib/libreadline.5.0.dylib
    0x9b000 -    0xc6fff libncurses.5.dylib 	/usr/lib/libncurses.5.dylib
   0x205000 -   0x398fff libR.dylib 	/Library/Frameworks/R.framework/ 
Resources/lib/libR.dylib
0x1673000 -  0x1675fff Hmisc.so 	/Library/Frameworks/R.framework/ 
Resources/library/Hmisc/libs/Hmisc.so
0x1697000 -  0x16a2fff acepack.so 	/Library/Frameworks/R.framework/ 
Resources/library/acepack/libs/acepack.so
0x175a000 -  0x175dfff methods.so 	/Library/Frameworks/R.framework/ 
Resources/library/methods/libs/methods.so
0x684b000 -  0x6861fff grDevices.so 	/Library/Frameworks/R.framework/ 
Resources/library/grDevices/libs/grDevices.so
0x690d000 -  0x6950fff stats.so 	/Library/Frameworks/R.framework/ 
Resources/library/stats/libs/stats.so
0x6a4d000 -  0x6a54fff internet.so 	/Library/Frameworks/R.framework/ 
Resources/modules/internet.so
0x6d42000 -  0x6d43fff tools.so 	/Library/Frameworks/R.framework/ 
Resources/library/tools/libs/tools.so
0x8fe00000 - 0x8fe54fff dyld 44.2	/usr/lib/dyld
0x90000000 - 0x901b3fff libSystem.B.dylib 	/usr/lib/libSystem.B.dylib
0x9020b000 - 0x9020ffff libmathCommon.A.dylib 	/usr/lib/system/ 
libmathCommon.A.dylib
0x90211000 - 0x90264fff com.apple.CoreText 1.0.1 (???)	/System/ 
Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/CoreText.framework/Versions/A/CoreText
0x90291000 - 0x90342fff ATS 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/ 
Versions/A/ATS
0x90371000 - 0x906aefff com.apple.CoreGraphics 1.256.30 (???)	/System/ 
Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics
0x9073a000 - 0x90813fff com.apple.CoreFoundation 6.4.4 (368.25)	/ 
System/Library/Frameworks/CoreFoundation.framework/Versions/A/ 
CoreFoundation
0x9085c000 - 0x9085cfff com.apple.CoreServices 10.4 (???)	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/CoreServices
0x9085e000 - 0x90960fff libicucore.A.dylib 	/usr/lib/libicucore.A.dylib
0x909ba000 - 0x90a3efff libobjc.A.dylib 	/usr/lib/libobjc.A.dylib
0x90a68000 - 0x90ad6fff com.apple.framework.IOKit 1.4 (???)	/System/ 
Library/Frameworks/IOKit.framework/Versions/A/IOKit
0x90aed000 - 0x90afffff libauto.dylib 	/usr/lib/libauto.dylib
0x90b06000 - 0x90ddefff com.apple.CoreServices.CarbonCore 681.3  
(671.2)	/System/Library/Frameworks/CoreServices.framework/Versions/A/ 
Frameworks/CarbonCore.framework/Versions/A/CarbonCore
0x90e44000 - 0x90ec4fff com.apple.CoreServices.OSServices 4.1	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
OSServices.framework/Versions/A/OSServices
0x90f0e000 - 0x90f4ffff com.apple.CFNetwork 10.4.4 (129.9)	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
CFNetwork.framework/Versions/A/CFNetwork
0x90f64000 - 0x90f7cfff com.apple.WebServices 1.1.2 (1.1.0)	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
WebServicesCore.framework/Versions/A/WebServicesCore
0x90f8c000 - 0x9100dfff com.apple.SearchKit 1.0.5	/System/Library/ 
Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
SearchKit.framework/Versions/A/SearchKit
0x91053000 - 0x9107dfff com.apple.Metadata 10.4.4 (121.34)	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
Metadata.framework/Versions/A/Metadata
0x9108e000 - 0x9109cfff libz.1.dylib 	/usr/lib/libz.1.dylib
0x9109f000 - 0x91262fff com.apple.security 4.3 (25966)	/System/ 
Library/Frameworks/Security.framework/Versions/A/Security
0x91365000 - 0x9136efff com.apple.DiskArbitration 2.1	/System/Library/ 
Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration
0x91375000 - 0x9139cfff com.apple.SystemConfiguration 1.8.2	/System/ 
Library/Frameworks/SystemConfiguration.framework/Versions/A/ 
SystemConfiguration
0x913af000 - 0x913b7fff libgcc_s.1.dylib 	/usr/lib/libgcc_s.1.dylib
0x913bc000 - 0x913dcfff libmx.A.dylib 	/usr/lib/libmx.A.dylib
0x913e2000 - 0x913eafff libbsm.dylib 	/usr/lib/libbsm.dylib
0x913ee000 - 0x9146efff com.apple.audio.CoreAudio 3.0.2	/System/ 
Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio
0x914ad000 - 0x914adfff com.apple.ApplicationServices 10.4 (???)	/ 
System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
ApplicationServices
0x914af000 - 0x914e7fff com.apple.AE 1.5 (297)	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
AE.framework/Versions/A/AE
0x91502000 - 0x915cffff com.apple.ColorSync 4.4.4	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
ColorSync.framework/Versions/A/ColorSync
0x91624000 - 0x916b7fff com.apple.print.framework.PrintCore 4.3  
(172.3)	/System/Library/Frameworks/ApplicationServices.framework/ 
Versions/A/Frameworks/PrintCore.framework/Versions/A/PrintCore
0x916fe000 - 0x917bbfff com.apple.QD 3.8.18 (???)	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
QD.framework/Versions/A/QD
0x917f9000 - 0x91857fff com.apple.HIServices 1.5.1 (???)	/System/ 
Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/HIServices.framework/Versions/A/HIServices
0x91885000 - 0x918a9fff com.apple.LangAnalysis 1.6.1	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
LangAnalysis.framework/Versions/A/LangAnalysis
0x918bd000 - 0x918e2fff com.apple.FindByContent 1.5	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
FindByContent.framework/Versions/A/FindByContent
0x918f5000 - 0x91937fff com.apple.LaunchServices 10.4.6 (168.3)	/ 
System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/LaunchServices.framework/Versions/A/LaunchServices
0x91953000 - 0x91967fff com.apple.speech.synthesis.framework 3.3	/ 
System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis
0x91975000 - 0x919affff com.apple.ImageIO.framework 1.4.4	/System/ 
Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/ImageIO.framework/Versions/A/ImageIO
0x919c4000 - 0x91a8cfff libcrypto.0.9.7.dylib 	/usr/lib/libcrypto. 
0.9.7.dylib
0x91ada000 - 0x91aeffff libcups.2.dylib 	/usr/lib/libcups.2.dylib
0x91af4000 - 0x91b11fff libJPEG.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libJPEG.dylib
0x91b16000 - 0x91b85fff libJP2.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libJP2.dylib
0x91b9c000 - 0x91ba0fff libGIF.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libGIF.dylib
0x91ba2000 - 0x91bd3fff libRaw.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libRaw.dylib
0x91bd7000 - 0x91c1afff libTIFF.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libTIFF.dylib
0x91c21000 - 0x91c3afff libPng.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libPng.dylib
0x91c3f000 - 0x91c42fff libRadiance.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libRadiance.dylib
0x91c44000 - 0x91c44fff com.apple.Accelerate 1.1.1 (Accelerate  
1.1.1)	/System/Library/Frameworks/Accelerate.framework/Versions/A/ 
Accelerate
0x91c46000 - 0x91d30fff com.apple.vImage 2.0	/System/Library/ 
Frameworks/Accelerate.framework/Versions/A/Frameworks/ 
vImage.framework/Versions/A/vImage
0x91d38000 - 0x91d57fff com.apple.Accelerate.vecLib 3.1.1 (vecLib  
3.1.1)	/System/Library/Frameworks/Accelerate.framework/Versions/A/ 
Frameworks/vecLib.framework/Versions/A/vecLib
0x91dc3000 - 0x91e28fff libvMisc.dylib 	/System/Library/Frameworks/ 
Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/ 
A/libvMisc.dylib
0x91e32000 - 0x91ec4fff libvDSP.dylib 	/System/Library/Frameworks/ 
Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/ 
A/libvDSP.dylib
0x91ede000 - 0x9246efff libBLAS.dylib 	/System/Library/Frameworks/ 
Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/ 
A/libBLAS.dylib
0x924b6000 - 0x927c6fff libLAPACK.dylib 	/System/Library/Frameworks/ 
Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/ 
A/libLAPACK.dylib
0x927f3000 - 0x9287ffff com.apple.DesktopServices 1.3.1	/System/ 
Library/PrivateFrameworks/DesktopServicesPriv.framework/Versions/A/ 
DesktopServicesPriv
0x928c1000 - 0x92aebfff com.apple.Foundation 6.4.2 (567.21)	/System/ 
Library/Frameworks/Foundation.framework/Versions/C/Foundation
0x92c09000 - 0x92ce7fff libxml2.2.dylib 	/usr/lib/libxml2.2.dylib
0x92d07000 - 0x92df5fff libiconv.2.dylib 	/usr/lib/libiconv.2.dylib
0x92e07000 - 0x92e25fff libGL.dylib 	/System/Library/Frameworks/ 
OpenGL.framework/Versions/A/Libraries/libGL.dylib
0x92e30000 - 0x92e8afff libGLU.dylib 	/System/Library/Frameworks/ 
OpenGL.framework/Versions/A/Libraries/libGLU.dylib
0x92ea8000 - 0x92ea8fff com.apple.Carbon 10.4 (???)	/System/Library/ 
Frameworks/Carbon.framework/Versions/A/Carbon
0x92eaa000 - 0x92ebefff com.apple.ImageCapture 3.0	/System/Library/ 
Frameworks/Carbon.framework/Versions/A/Frameworks/ 
ImageCapture.framework/Versions/A/ImageCapture
0x92ed6000 - 0x92ee6fff com.apple.speech.recognition.framework 3.4	/ 
System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
SpeechRecognition.framework/Versions/A/SpeechRecognition
0x92ef2000 - 0x92f07fff com.apple.securityhi 2.0 (203)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
SecurityHI.framework/Versions/A/SecurityHI
0x92f19000 - 0x92fa0fff com.apple.ink.framework 101.2 (69)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
Ink.framework/Versions/A/Ink
0x92fb4000 - 0x92fbffff com.apple.help 1.0.3 (32)	/System/Library/ 
Frameworks/Carbon.framework/Versions/A/Frameworks/Help.framework/ 
Versions/A/Help
0x92fc9000 - 0x92ff6fff com.apple.openscripting 1.2.4 (???)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
OpenScripting.framework/Versions/A/OpenScripting
0x93010000 - 0x93020fff com.apple.print.framework.Print 5.0 (190.1)	/ 
System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
Print.framework/Versions/A/Print
0x9302c000 - 0x93092fff com.apple.htmlrendering 1.1.2	/System/Library/ 
Frameworks/Carbon.framework/Versions/A/Frameworks/ 
HTMLRendering.framework/Versions/A/HTMLRendering
0x930c3000 - 0x93115fff com.apple.NavigationServices 3.4.2	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
NavigationServices.framework/Versions/A/NavigationServices
0x93141000 - 0x9315efff com.apple.audio.SoundManager 3.9	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
CarbonSound.framework/Versions/A/CarbonSound
0x93170000 - 0x9317dfff com.apple.CommonPanels 1.2.2 (73)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
CommonPanels.framework/Versions/A/CommonPanels
0x93186000 - 0x93498fff com.apple.HIToolbox 1.4.5 (???)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
HIToolbox.framework/Versions/A/HIToolbox
0x935e4000 - 0x935f0fff com.apple.opengl 1.4.7	/System/Library/ 
Frameworks/OpenGL.framework/Versions/A/OpenGL
0x93681000 - 0x93681fff com.apple.Cocoa 6.4 (???)	/System/Library/ 
Frameworks/Cocoa.framework/Versions/A/Cocoa
0x93683000 - 0x93cb6fff com.apple.AppKit 6.4.4 (824.33)	/System/ 
Library/Frameworks/AppKit.framework/Versions/C/AppKit
0x94043000 - 0x940b3fff com.apple.CoreData 80	/System/Library/ 
Frameworks/CoreData.framework/Versions/A/CoreData
0x940ec000 - 0x941b6fff com.apple.audio.toolbox.AudioToolbox 1.4.1	/ 
System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox
0x9420a000 - 0x9420afff com.apple.audio.units.AudioUnit 1.4	/System/ 
Library/Frameworks/AudioUnit.framework/Versions/A/AudioUnit
0x9420c000 - 0x94384fff com.apple.QuartzCore 1.4.5	/System/Library/ 
Frameworks/QuartzCore.framework/Versions/A/QuartzCore
0x943ce000 - 0x9440bfff libsqlite3.0.dylib 	/usr/lib/libsqlite3.0.dylib
0x94413000 - 0x94463fff libGLImage.dylib 	/System/Library/Frameworks/ 
OpenGL.framework/Versions/A/Libraries/libGLImage.dylib
0x94605000 - 0x94614fff libCGATS.A.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ 
CoreGraphics.framework/Versions/A/Resources/libCGATS.A.dylib
0x9461c000 - 0x94628fff libCSync.A.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ 
CoreGraphics.framework/Versions/A/Resources/libCSync.A.dylib
0x9466e000 - 0x94686fff libRIP.A.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ 
CoreGraphics.framework/Versions/A/Resources/libRIP.A.dylib
0x95663000 - 0x956effff com.apple.WebKit 417.9	/System/Library/ 
Frameworks/WebKit.framework/Versions/A/WebKit
0x9574a000 - 0x9583ffff com.apple.JavaScriptCore 1.2 (417.8)	/System/ 
Library/Frameworks/WebKit.framework/Versions/A/Frameworks/ 
JavaScriptCore.framework/Versions/A/JavaScriptCore
0x9587b000 - 0x95b85fff com.apple.WebCore 417.17	/System/Library/ 
Frameworks/WebKit.framework/Versions/A/Frameworks/WebCore.framework/ 
Versions/A/WebCore
0x95d0c000 - 0x95d35fff libxslt.1.dylib 	/usr/lib/libxslt.1.dylib
0x95fdb000 - 0x95fddfff com.apple.ExceptionHandling 1.2 (???)	/System/ 
Library/Frameworks/ExceptionHandling.framework/Versions/A/ 
ExceptionHandling
0x96fba000 - 0x96fd9fff com.apple.vecLib 3.1.1 (vecLib 3.1.1)	/System/ 
Library/Frameworks/vecLib.framework/Versions/A/vecLib

Model: PowerMac7,2, BootROM 5.0.7f0, 2 processors, PowerPC 970   
(2.2), 2 GHz, 8 GB
Graphics: ATI Radeon 9600 Pro, ATY,RV350, AGP, 64 MB
Memory Module: DIMM0/J11, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM1/J12, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM2/J13, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM3/J14, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM4/J41, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM5/J42, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM6/J43, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM7/J44, 1 GB, DDR SDRAM, PC3200U-30330
Modem: MicroDash, UCJ, V.92, 1.0F, APPLE VERSION 2.6.6
Network Service: Built-in Ethernet, Ethernet, en0
Serial ATA Device: ST3160023AS, 149.05 GB
Parallel ATA Device: PIONEER DVD-RW  DVR-106D,
USB Device: Flash Disk, USB, Up to 480 Mb/sec, 500 mA
USB Device: hp LaserJet 1300, Hewlett-Packard, Up to 12 Mb/sec, 500 mA
USB Device: Hub, , Up to 12 Mb/sec, 500 mA
USB Device: Hub in Apple Pro Keyboard, Mitsumi Electric, Up to 12 Mb/ 
sec, 500 mA
USB Device: Apple Pro Keyboard, Mitsumi Electric, Up to 12 Mb/sec,  
250 mA
USB Device: Studio Display, , Up to 1.5 Mb/sec, 500 mA
USB Device: Apple Optical USB Mouse, Logitech, Up to 1.5 Mb/sec, 500 mA



From charshaw at presby.edu  Thu Feb 16 20:23:17 2006
From: charshaw at presby.edu (Clint Harshaw)
Date: Thu, 16 Feb 2006 14:23:17 -0500
Subject: [R] Ubuntu and R
In-Reply-To: <43F4C52F.3040803@gmail.com>
References: <20060216131304.458zmok7swssg4c4@webmail.mcgill.ca>
	<43F4C52F.3040803@gmail.com>
Message-ID: <43F4D125.4000605@presby.edu>

Thanks for the advice, everyone. I've done what Tyler suggested and have 
a fresh install of R now using the Debian binaries.

Clint

Fernando Mayer wrote:
> I did this in my Ubuntu 5.10 and it works very well...
> 
> Fernando Mayer.
> 
> Tyler Smith escreveu:
> 
>> You could try the stable/sarge backport from Cran. That's less likely 
>> to cause problems than using the Etch version, but I'm not using 
>> Ubuntu so I can't confirm this. Add the following to your sources.list 
>> and see how it goes:
>>
>>     deb http://cran.R-project.org/bin/linux/debian stable/
>>
>>  
>>
>



From HDoran at air.org  Thu Feb 16 20:25:04 2006
From: HDoran at air.org (Doran, Harold)
Date: Thu, 16 Feb 2006 14:25:04 -0500
Subject: [R] how can I use lmer on a windows machine?
Message-ID: <F5ED48890E2ACB468D0F3A64989D335A01ADF4E0@dc1ex3.air.org>

It will not work. You'll need to upgrade to the most recent version on
CRAN. Lme() will work, though 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Feldman, Tracy
Sent: Thursday, February 16, 2006 1:33 PM
To: r-help at stat.math.ethz.ch
Subject: [R] how can I use lmer on a windows machine?

To whom it may concern:

I am using R version 1.9.1 beta on a windows machine, and I am trying to
use a function called lmer (in packages lme4 and Matrix).  I am not sure
if this version will support these packages (when I install them from
the GUI, the function lmer does not work).  I wondered if I need to
install a newer version of R, and if so, which version should I install,
and how should I do that?
 
Thank you so much for your time and help.  Please send replies to
tsfeldman at noble.org

Take care,
Tracy S. Feldman

Postdoc
Noble Foundation

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Thu Feb 16 20:27:29 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Feb 2006 19:27:29 +0000 (GMT)
Subject: [R] how can I use lmer on a windows machine?
In-Reply-To: <497D588A106806408FB0792E4E9A165883662E@mail2.noble.org>
References: <497D588A106806408FB0792E4E9A165883662E@mail2.noble.org>
Message-ID: <Pine.LNX.4.64.0602161923420.17833@gannet.stats.ox.ac.uk>

Well, as you are using a beta version of a version of R released in June 
2004, you certainly should upgrade. (Indeed the R posting guide asked you 
to do so before posting the first time.)

You should probably install R-patched from

http://cran.r-project.org/bin/windows/base/rpatched.html

or your nearest CRAN mirror (we have no idea where you are).  You install 
that the same way you installed the current version: double clicking on 
the installer .exe should be all that is needed.


On Thu, 16 Feb 2006, Feldman, Tracy wrote:

> To whom it may concern:
>
> I am using R version 1.9.1 beta on a windows machine, and I am trying to
> use a function called lmer (in packages lme4 and Matrix).  I am not sure
> if this version will support these packages (when I install them from
> the GUI, the function lmer does not work).  I wondered if I need to
> install a newer version of R, and if so, which version should I install,
> and how should I do that?
>
> Thank you so much for your time and help.  Please send replies to
> tsfeldman at noble.org
>
> Take care,
> Tracy S. Feldman
>
> Postdoc
> Noble Foundation
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bzajdlik at sentex.net  Thu Feb 16 20:29:34 2006
From: bzajdlik at sentex.net (Barry Zajdlik)
Date: Thu, 16 Feb 2006 14:29:34 -0500
Subject: [R] Variance for Vector of Constants is Not Zero
In-Reply-To: <20060216131304.458zmok7swssg4c4@webmail.mcgill.ca>
Message-ID: <000601c6332f$519fbb60$0a00a8c0@Dell2003desktop>


Hi All,

An annoying but not critical problem I am having is that the variance of
a vector of constants is reported as > 0. I imagine there is a simple
workaround for the following but could not find it after having spent an
embarrassing amount of time.

In Splus:

> x<-rep(0.02,10)
> var(x)
> 0

In R:

x<-rep(0.02,10)
var(x)
1.337451e-35

I assumed the problem had to do with machine precision and suitably
modified .Machine$double.eps and .Machine$double.neg.eps which I thought
would fix the problem but without success. Any pointers to a solution
would be appreciated!

Cheers,
Barry Zajdlik



From HStevens at muohio.edu  Thu Feb 16 20:29:41 2006
From: HStevens at muohio.edu (Martin Henry H. Stevens)
Date: Thu, 16 Feb 2006 14:29:41 -0500
Subject: [R] segmentation fault with Hmisc areg.boot(): Now acepack avas
	failure
Message-ID: <9B0A357E-CDB5-4C72-9F97-3C3BA0EB8CF8@muohio.edu>

Hi Folks,
Mac OS 10.4.4
R 2.2.1(2005-12-20 r36812)
Hmisc 3.0-10
acepack 1.3-2.2

I had R crashes while running areg.boot in Hmisc (see old message  
below), but now I realize that the problem appears to be in the avas  
function in acepack. I tried running running the avas example (in  
acepack package), and got an immediate crash.

Any thoughts? The Apple crash report (from R GUI crash) follows.

Hank
Date/Time:      2006-02-16 14:28:39.836 -0500
OS Version:     10.4.4 (Build 8G32)
Report Version: 3

Command: R
Path:    /Applications/R.app/Contents/MacOS/R
Parent:  WindowServer [75]

Version: 1.14 (2129)

PID:    1814
Thread: 0

Exception:  EXC_BAD_ACCESS (0x0001)
Codes:      KERN_INVALID_ADDRESS (0x0001) at 0xfb3513df

Thread 0 Crashed:
0   acepack.so               	0x067c42c0 avas_ + 1752 (avas.f:112)
1   libR.dylib               	0x0024f498 do_dotCode + 1844 (dotcode.c: 
1722)
2   libR.dylib               	0x00265cb0 Rf_eval + 1544 (eval.c:405)
3   libR.dylib               	0x00267ccc do_set + 224 (eval.c:1309)
4   libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
5   libR.dylib               	0x0026744c do_begin + 136 (eval.c:1058)
6   libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
7   libR.dylib               	0x00266150 Rf_applyClosure + 952  
(eval.c:576)
8   libR.dylib               	0x00265d2c Rf_eval + 1668 (eval.c:417)
9   libR.dylib               	0x00267ccc do_set + 224 (eval.c:1309)
10  libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
11  org.R-project.R          	0x00015884 RGUI_ReplIteration + 500  
(crt.c:300)
12  org.R-project.R          	0x00015674 RGUI_ReplConsole + 148  
(crt.c:300)
13  org.R-project.R          	0x000155c8 run_REngineRmainloop + 156  
(crt.c:300)
14  org.R-project.R          	0x0000e56c -[REngine runREPL] + 76  
(crt.c:300)
15  com.apple.Foundation     	0x928e949c __NSFireTimer + 116
16  com.apple.CoreFoundation 	0x90770aec __CFRunLoopDoTimer + 184
17  com.apple.CoreFoundation 	0x9075d464 __CFRunLoopRun + 1680
18  com.apple.CoreFoundation 	0x9075ca18 CFRunLoopRunSpecific + 268
19  com.apple.HIToolbox      	0x9318e1e0 RunCurrentEventLoopInMode + 264
20  com.apple.HIToolbox      	0x9318d874 ReceiveNextEventCommon + 380
21  com.apple.HIToolbox      	0x9318d6e0  
BlockUntilNextEventMatchingListInMode + 96
22  com.apple.AppKit         	0x9368b104 _DPSNextEvent + 384
23  com.apple.AppKit         	0x9368adc8 -[NSApplication  
nextEventMatchingMask:untilDate:inMode:dequeue:] + 116
24  com.apple.AppKit         	0x9368730c -[NSApplication run] + 472
25  com.apple.AppKit         	0x93777e68 NSApplicationMain + 452
26  org.R-project.R          	0x00002eb0 _start + 392 (crt.c:267)
27  dyld                     	0x8fe01048 _dyld_start + 60

Thread 1:
0   libSystem.B.dylib        	0x9001f20c select + 12
1   org.R-project.R          	0x00004674 -[RController readThread:] +  
524 (crt.c:300)
2   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
3   libSystem.B.dylib        	0x9002b200 _pthread_body + 96

Thread 2:
0   libSystem.B.dylib        	0x90049748 syscall_thread_switch + 8
1   com.apple.Foundation     	0x928fead0 +[NSThread sleepUntilDate:]  
+ 152
2   com.apple.AppKit         	0x93728034 -[NSUIHeartBeat  
_heartBeatThread:] + 1100
3   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
4   libSystem.B.dylib        	0x9002b200 _pthread_body + 96

Thread 3:
0   libSystem.B.dylib        	0x9000b208 mach_msg_trap + 8
1   libSystem.B.dylib        	0x9000b15c mach_msg + 60
2   com.apple.CoreFoundation 	0x9075d114 __CFRunLoopRun + 832
3   com.apple.CoreFoundation 	0x9075ca18 CFRunLoopRunSpecific + 268
4   com.apple.Foundation     	0x9290db9c +[NSURLConnection 
(NSURLConnectionInternal) _resourceLoadLoop:] + 264
5   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
6   libSystem.B.dylib        	0x9002b200 _pthread_body + 96

Thread 4:
0   libSystem.B.dylib        	0x9000b208 mach_msg_trap + 8
1   libSystem.B.dylib        	0x9000b15c mach_msg + 60
2   com.apple.CoreFoundation 	0x9075d114 __CFRunLoopRun + 832
3   com.apple.CoreFoundation 	0x9075ca18 CFRunLoopRunSpecific + 268
4   com.apple.Foundation     	0x9290ecdc +[NSURLCache  
_diskCacheSyncLoop:] + 152
5   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
6   libSystem.B.dylib        	0x9002b200 _pthread_body + 96

Thread 5:
0   libSystem.B.dylib        	0x9000b208 mach_msg_trap + 8
1   libSystem.B.dylib        	0x9000b15c mach_msg + 60
2   com.apple.CoreFoundation 	0x9075d114 __CFRunLoopRun + 832
3   com.apple.CoreFoundation 	0x9075ca18 CFRunLoopRunSpecific + 268
4   com.apple.Foundation     	0x928f5664 -[NSRunLoop  
runMode:beforeDate:] + 172
5   com.apple.Foundation     	0x928f559c -[NSRunLoop run] + 76
6   com.apple.WebKit         	0x95665410 +[WebFileDatabase  
_syncLoop:] + 176
7   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
8   libSystem.B.dylib        	0x9002b200 _pthread_body + 96

Thread 0 crashed with PPC Thread State 64:
   srr0: 0x00000000067c42c0 srr1:  
0x100000000200f030                        vrsave: 0x0000000000000000
     cr: 0x42022448          xer: 0x0000000020000000   lr:  
0x00000000067c41c0  ctr: 0x0000000000000000
     r0: 0x0000000000003840   r1: 0x00000000bfffc580   r2:  
0x00000000075f9e98   r3: 0x0000000000000000
     r4: 0x00000000075f9858   r5: 0x00000000075f8598   r6:  
0x00000000075f8bd8   r7: 0x00000000075f9218
     r8: 0x00000000fb3513df   r9: 0x0000000006a5da58  r10:  
0x00000000000000c7  r11: 0x0000000001bbf458
    r12: 0x00000000075f9858  r13: 0x0000000000000640  r14:  
0x0000000001f9d018  r15: 0x0000000001b8f100
    r16: 0x0000000006a5d418  r17: 0x0000000000000002  r18:  
0x0000000001bbee18  r19: 0x0000000006857d40
    r20: 0x00000000075f6018  r21: 0x00000000000000c8  r22:  
0x0000000000002580  r23: 0x0000000000003840
    r24: 0x00000000000000c8  r25: 0x00000000000000c7  r26:  
0x0000000000000640  r27: 0x0000000001bbee18
    r28: 0x0000000001f9d978  r29: 0x0000000000000037  r30:  
0x00000000075f9218  r31: 0x00000000067c3bf0

Binary Images Description:
     0x1000 -    0x3bfff org.R-project.R 1.14 (2129)	/Applications/ 
R.app/Contents/MacOS/R
    0x55000 -    0x87fff libreadline.5.0.dylib 	/Library/Frameworks/ 
R.framework/Resources/lib/libreadline.5.0.dylib
    0x9b000 -    0xc6fff libncurses.5.dylib 	/usr/lib/libncurses.5.dylib
   0x205000 -   0x398fff libR.dylib 	/Library/Frameworks/R.framework/ 
Resources/lib/libR.dylib
0x1756000 -  0x1759fff methods.so 	/Library/Frameworks/R.framework/ 
Resources/library/methods/libs/methods.so
0x54b4000 -  0x54cafff grDevices.so 	/Library/Frameworks/R.framework/ 
Resources/library/grDevices/libs/grDevices.so
0x6681000 -  0x66c4fff stats.so 	/Library/Frameworks/R.framework/ 
Resources/library/stats/libs/stats.so
0x67c1000 -  0x67ccfff acepack.so 	/Library/Frameworks/R.framework/ 
Resources/library/acepack/libs/acepack.so
0x8fe00000 - 0x8fe54fff dyld 44.2	/usr/lib/dyld
0x90000000 - 0x901b3fff libSystem.B.dylib 	/usr/lib/libSystem.B.dylib
0x9020b000 - 0x9020ffff libmathCommon.A.dylib 	/usr/lib/system/ 
libmathCommon.A.dylib
0x90211000 - 0x90264fff com.apple.CoreText 1.0.1 (???)	/System/ 
Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/CoreText.framework/Versions/A/CoreText
0x90291000 - 0x90342fff ATS 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/ 
Versions/A/ATS
0x90371000 - 0x906aefff com.apple.CoreGraphics 1.256.30 (???)	/System/ 
Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics
0x9073a000 - 0x90813fff com.apple.CoreFoundation 6.4.4 (368.25)	/ 
System/Library/Frameworks/CoreFoundation.framework/Versions/A/ 
CoreFoundation
0x9085c000 - 0x9085cfff com.apple.CoreServices 10.4 (???)	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/CoreServices
0x9085e000 - 0x90960fff libicucore.A.dylib 	/usr/lib/libicucore.A.dylib
0x909ba000 - 0x90a3efff libobjc.A.dylib 	/usr/lib/libobjc.A.dylib
0x90a68000 - 0x90ad6fff com.apple.framework.IOKit 1.4 (???)	/System/ 
Library/Frameworks/IOKit.framework/Versions/A/IOKit
0x90aed000 - 0x90afffff libauto.dylib 	/usr/lib/libauto.dylib
0x90b06000 - 0x90ddefff com.apple.CoreServices.CarbonCore 681.3  
(671.2)	/System/Library/Frameworks/CoreServices.framework/Versions/A/ 
Frameworks/CarbonCore.framework/Versions/A/CarbonCore
0x90e44000 - 0x90ec4fff com.apple.CoreServices.OSServices 4.1	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
OSServices.framework/Versions/A/OSServices
0x90f0e000 - 0x90f4ffff com.apple.CFNetwork 10.4.4 (129.9)	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
CFNetwork.framework/Versions/A/CFNetwork
0x90f64000 - 0x90f7cfff com.apple.WebServices 1.1.2 (1.1.0)	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
WebServicesCore.framework/Versions/A/WebServicesCore
0x90f8c000 - 0x9100dfff com.apple.SearchKit 1.0.5	/System/Library/ 
Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
SearchKit.framework/Versions/A/SearchKit
0x91053000 - 0x9107dfff com.apple.Metadata 10.4.4 (121.34)	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
Metadata.framework/Versions/A/Metadata
0x9108e000 - 0x9109cfff libz.1.dylib 	/usr/lib/libz.1.dylib
0x9109f000 - 0x91262fff com.apple.security 4.3 (25966)	/System/ 
Library/Frameworks/Security.framework/Versions/A/Security
0x91365000 - 0x9136efff com.apple.DiskArbitration 2.1	/System/Library/ 
Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration
0x91375000 - 0x9139cfff com.apple.SystemConfiguration 1.8.2	/System/ 
Library/Frameworks/SystemConfiguration.framework/Versions/A/ 
SystemConfiguration
0x913af000 - 0x913b7fff libgcc_s.1.dylib 	/usr/lib/libgcc_s.1.dylib
0x913bc000 - 0x913dcfff libmx.A.dylib 	/usr/lib/libmx.A.dylib
0x913e2000 - 0x913eafff libbsm.dylib 	/usr/lib/libbsm.dylib
0x913ee000 - 0x9146efff com.apple.audio.CoreAudio 3.0.2	/System/ 
Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio
0x914ad000 - 0x914adfff com.apple.ApplicationServices 10.4 (???)	/ 
System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
ApplicationServices
0x914af000 - 0x914e7fff com.apple.AE 1.5 (297)	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
AE.framework/Versions/A/AE
0x91502000 - 0x915cffff com.apple.ColorSync 4.4.4	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
ColorSync.framework/Versions/A/ColorSync
0x91624000 - 0x916b7fff com.apple.print.framework.PrintCore 4.3  
(172.3)	/System/Library/Frameworks/ApplicationServices.framework/ 
Versions/A/Frameworks/PrintCore.framework/Versions/A/PrintCore
0x916fe000 - 0x917bbfff com.apple.QD 3.8.18 (???)	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
QD.framework/Versions/A/QD
0x917f9000 - 0x91857fff com.apple.HIServices 1.5.1 (???)	/System/ 
Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/HIServices.framework/Versions/A/HIServices
0x91885000 - 0x918a9fff com.apple.LangAnalysis 1.6.1	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
LangAnalysis.framework/Versions/A/LangAnalysis
0x918bd000 - 0x918e2fff com.apple.FindByContent 1.5	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
FindByContent.framework/Versions/A/FindByContent
0x918f5000 - 0x91937fff com.apple.LaunchServices 10.4.6 (168.3)	/ 
System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/LaunchServices.framework/Versions/A/LaunchServices
0x91953000 - 0x91967fff com.apple.speech.synthesis.framework 3.3	/ 
System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis
0x91975000 - 0x919affff com.apple.ImageIO.framework 1.4.4	/System/ 
Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/ImageIO.framework/Versions/A/ImageIO
0x919c4000 - 0x91a8cfff libcrypto.0.9.7.dylib 	/usr/lib/libcrypto. 
0.9.7.dylib
0x91ada000 - 0x91aeffff libcups.2.dylib 	/usr/lib/libcups.2.dylib
0x91af4000 - 0x91b11fff libJPEG.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libJPEG.dylib
0x91b16000 - 0x91b85fff libJP2.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libJP2.dylib
0x91b9c000 - 0x91ba0fff libGIF.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libGIF.dylib
0x91ba2000 - 0x91bd3fff libRaw.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libRaw.dylib
0x91bd7000 - 0x91c1afff libTIFF.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libTIFF.dylib
0x91c21000 - 0x91c3afff libPng.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libPng.dylib
0x91c3f000 - 0x91c42fff libRadiance.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libRadiance.dylib
0x91c44000 - 0x91c44fff com.apple.Accelerate 1.1.1 (Accelerate  
1.1.1)	/System/Library/Frameworks/Accelerate.framework/Versions/A/ 
Accelerate
0x91c46000 - 0x91d30fff com.apple.vImage 2.0	/System/Library/ 
Frameworks/Accelerate.framework/Versions/A/Frameworks/ 
vImage.framework/Versions/A/vImage
0x91d38000 - 0x91d57fff com.apple.Accelerate.vecLib 3.1.1 (vecLib  
3.1.1)	/System/Library/Frameworks/Accelerate.framework/Versions/A/ 
Frameworks/vecLib.framework/Versions/A/vecLib
0x91dc3000 - 0x91e28fff libvMisc.dylib 	/System/Library/Frameworks/ 
Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/ 
A/libvMisc.dylib
0x91e32000 - 0x91ec4fff libvDSP.dylib 	/System/Library/Frameworks/ 
Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/ 
A/libvDSP.dylib
0x91ede000 - 0x9246efff libBLAS.dylib 	/System/Library/Frameworks/ 
Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/ 
A/libBLAS.dylib
0x924b6000 - 0x927c6fff libLAPACK.dylib 	/System/Library/Frameworks/ 
Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/ 
A/libLAPACK.dylib
0x927f3000 - 0x9287ffff com.apple.DesktopServices 1.3.1	/System/ 
Library/PrivateFrameworks/DesktopServicesPriv.framework/Versions/A/ 
DesktopServicesPriv
0x928c1000 - 0x92aebfff com.apple.Foundation 6.4.2 (567.21)	/System/ 
Library/Frameworks/Foundation.framework/Versions/C/Foundation
0x92c09000 - 0x92ce7fff libxml2.2.dylib 	/usr/lib/libxml2.2.dylib
0x92d07000 - 0x92df5fff libiconv.2.dylib 	/usr/lib/libiconv.2.dylib
0x92e07000 - 0x92e25fff libGL.dylib 	/System/Library/Frameworks/ 
OpenGL.framework/Versions/A/Libraries/libGL.dylib
0x92e30000 - 0x92e8afff libGLU.dylib 	/System/Library/Frameworks/ 
OpenGL.framework/Versions/A/Libraries/libGLU.dylib
0x92ea8000 - 0x92ea8fff com.apple.Carbon 10.4 (???)	/System/Library/ 
Frameworks/Carbon.framework/Versions/A/Carbon
0x92eaa000 - 0x92ebefff com.apple.ImageCapture 3.0	/System/Library/ 
Frameworks/Carbon.framework/Versions/A/Frameworks/ 
ImageCapture.framework/Versions/A/ImageCapture
0x92ed6000 - 0x92ee6fff com.apple.speech.recognition.framework 3.4	/ 
System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
SpeechRecognition.framework/Versions/A/SpeechRecognition
0x92ef2000 - 0x92f07fff com.apple.securityhi 2.0 (203)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
SecurityHI.framework/Versions/A/SecurityHI
0x92f19000 - 0x92fa0fff com.apple.ink.framework 101.2 (69)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
Ink.framework/Versions/A/Ink
0x92fb4000 - 0x92fbffff com.apple.help 1.0.3 (32)	/System/Library/ 
Frameworks/Carbon.framework/Versions/A/Frameworks/Help.framework/ 
Versions/A/Help
0x92fc9000 - 0x92ff6fff com.apple.openscripting 1.2.4 (???)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
OpenScripting.framework/Versions/A/OpenScripting
0x93010000 - 0x93020fff com.apple.print.framework.Print 5.0 (190.1)	/ 
System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
Print.framework/Versions/A/Print
0x9302c000 - 0x93092fff com.apple.htmlrendering 1.1.2	/System/Library/ 
Frameworks/Carbon.framework/Versions/A/Frameworks/ 
HTMLRendering.framework/Versions/A/HTMLRendering
0x930c3000 - 0x93115fff com.apple.NavigationServices 3.4.2	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
NavigationServices.framework/Versions/A/NavigationServices
0x93141000 - 0x9315efff com.apple.audio.SoundManager 3.9	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
CarbonSound.framework/Versions/A/CarbonSound
0x93170000 - 0x9317dfff com.apple.CommonPanels 1.2.2 (73)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
CommonPanels.framework/Versions/A/CommonPanels
0x93186000 - 0x93498fff com.apple.HIToolbox 1.4.5 (???)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
HIToolbox.framework/Versions/A/HIToolbox
0x935e4000 - 0x935f0fff com.apple.opengl 1.4.7	/System/Library/ 
Frameworks/OpenGL.framework/Versions/A/OpenGL
0x93681000 - 0x93681fff com.apple.Cocoa 6.4 (???)	/System/Library/ 
Frameworks/Cocoa.framework/Versions/A/Cocoa
0x93683000 - 0x93cb6fff com.apple.AppKit 6.4.4 (824.33)	/System/ 
Library/Frameworks/AppKit.framework/Versions/C/AppKit
0x94043000 - 0x940b3fff com.apple.CoreData 80	/System/Library/ 
Frameworks/CoreData.framework/Versions/A/CoreData
0x940ec000 - 0x941b6fff com.apple.audio.toolbox.AudioToolbox 1.4.1	/ 
System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox
0x9420a000 - 0x9420afff com.apple.audio.units.AudioUnit 1.4	/System/ 
Library/Frameworks/AudioUnit.framework/Versions/A/AudioUnit
0x9420c000 - 0x94384fff com.apple.QuartzCore 1.4.5	/System/Library/ 
Frameworks/QuartzCore.framework/Versions/A/QuartzCore
0x943ce000 - 0x9440bfff libsqlite3.0.dylib 	/usr/lib/libsqlite3.0.dylib
0x94413000 - 0x94463fff libGLImage.dylib 	/System/Library/Frameworks/ 
OpenGL.framework/Versions/A/Libraries/libGLImage.dylib
0x94605000 - 0x94614fff libCGATS.A.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ 
CoreGraphics.framework/Versions/A/Resources/libCGATS.A.dylib
0x9461c000 - 0x94628fff libCSync.A.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ 
CoreGraphics.framework/Versions/A/Resources/libCSync.A.dylib
0x9466e000 - 0x94686fff libRIP.A.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ 
CoreGraphics.framework/Versions/A/Resources/libRIP.A.dylib
0x95663000 - 0x956effff com.apple.WebKit 417.9	/System/Library/ 
Frameworks/WebKit.framework/Versions/A/WebKit
0x9574a000 - 0x9583ffff com.apple.JavaScriptCore 1.2 (417.8)	/System/ 
Library/Frameworks/WebKit.framework/Versions/A/Frameworks/ 
JavaScriptCore.framework/Versions/A/JavaScriptCore
0x9587b000 - 0x95b85fff com.apple.WebCore 417.17	/System/Library/ 
Frameworks/WebKit.framework/Versions/A/Frameworks/WebCore.framework/ 
Versions/A/WebCore
0x95d0c000 - 0x95d35fff libxslt.1.dylib 	/usr/lib/libxslt.1.dylib
0x95fdb000 - 0x95fddfff com.apple.ExceptionHandling 1.2 (???)	/System/ 
Library/Frameworks/ExceptionHandling.framework/Versions/A/ 
ExceptionHandling
0x96fba000 - 0x96fd9fff com.apple.vecLib 3.1.1 (vecLib 3.1.1)	/System/ 
Library/Frameworks/vecLib.framework/Versions/A/vecLib

Model: PowerMac7,2, BootROM 5.0.7f0, 2 processors, PowerPC 970   
(2.2), 2 GHz, 8 GB
Graphics: ATI Radeon 9600 Pro, ATY,RV350, AGP, 64 MB
Memory Module: DIMM0/J11, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM1/J12, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM2/J13, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM3/J14, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM4/J41, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM5/J42, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM6/J43, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM7/J44, 1 GB, DDR SDRAM, PC3200U-30330
Modem: MicroDash, UCJ, V.92, 1.0F, APPLE VERSION 2.6.6
Network Service: Built-in Ethernet, Ethernet, en0
Serial ATA Device: ST3160023AS, 149.05 GB
Parallel ATA Device: PIONEER DVD-RW  DVR-106D,
USB Device: Flash Disk, USB, Up to 480 Mb/sec, 500 mA
USB Device: hp LaserJet 1300, Hewlett-Packard, Up to 12 Mb/sec, 500 mA
USB Device: Hub, , Up to 12 Mb/sec, 500 mA
USB Device: Hub in Apple Pro Keyboard, Mitsumi Electric, Up to 12 Mb/ 
sec, 500 mA
USB Device: Apple Pro Keyboard, Mitsumi Electric, Up to 12 Mb/sec,  
250 mA
USB Device: Studio Display, , Up to 1.5 Mb/sec, 500 mA
USB Device: Apple Optical USB Mouse, Logitech, Up to 1.5 Mb/sec, 500 mA


###########################
###OLD from Hmisc crash:
I keep getting a "segmentation fault" when trying to run areg.boot in  
the Hmisc package. I include below output from two different attempts.
Thank you in advance for any help.

Hank Stevens

The following is taken from the example in the areg.boot  
documentation, run inside Aquamacs Emacs:

 > set.seed(171)  # to be able to reproduce example
 > x1 <- rnorm(200)
 > x2 <- runif(200)  # a variable that is really unrelated to y]
 > x3 <- factor(sample(c('cat','dog','cow'), 200,TRUE))  # also  
unrelated to y
 > y  <- exp(x1 + rnorm(200)/3)
 > f  <- areg.boot(y ~ x1 + x2 + x3, B=40)
Loading required package: acepack

Process R segmentation fault at Thu Feb 16 14:13:44 2006

############
The following is the automated report following the crash from the  
same code in the R GUI:

Date/Time:      2006-02-16 14:18:21.336 -0500
OS Version:     10.4.4 (Build 8G32)
Report Version: 3

Command: R
Path:    /Applications/R.app/Contents/MacOS/R
Parent:  WindowServer [75]

Version: 1.14 (2129)

PID:    902
Thread: 0

Exception:  EXC_BAD_ACCESS (0x0001)
Codes:      KERN_INVALID_ADDRESS (0x0001) at 0x63110304

Thread 0 Crashed:
0   acepack.so               	0x0169a2c0 avas_ + 1752 (avas.f:112)
1   libR.dylib               	0x0024f498 do_dotCode + 1844 (dotcode.c: 
1722)
2   libR.dylib               	0x00265cb0 Rf_eval + 1544 (eval.c:405)
3   libR.dylib               	0x00267ccc do_set + 224 (eval.c:1309)
4   libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
5   libR.dylib               	0x0026744c do_begin + 136 (eval.c:1058)
6   libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
7   libR.dylib               	0x00266150 Rf_applyClosure + 952  
(eval.c:576)
8   libR.dylib               	0x00265d2c Rf_eval + 1668 (eval.c:417)
9   libR.dylib               	0x00268678 do_eval + 700 (eval.c:1568)
10  libR.dylib               	0x0029acec do_internal + 392 (names.c: 
1084)
11  libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
12  libR.dylib               	0x00266150 Rf_applyClosure + 952  
(eval.c:576)
13  libR.dylib               	0x00265d2c Rf_eval + 1668 (eval.c:417)
14  libR.dylib               	0x00267ccc do_set + 224 (eval.c:1309)
15  libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
16  libR.dylib               	0x0026744c do_begin + 136 (eval.c:1058)
17  libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
18  libR.dylib               	0x00266150 Rf_applyClosure + 952  
(eval.c:576)
19  libR.dylib               	0x00265d2c Rf_eval + 1668 (eval.c:417)
20  libR.dylib               	0x00267ccc do_set + 224 (eval.c:1309)
21  libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
22  org.R-project.R          	0x00015884 RGUI_ReplIteration + 500  
(crt.c:300)
23  org.R-project.R          	0x00015674 RGUI_ReplConsole + 148  
(crt.c:300)
24  org.R-project.R          	0x000155c8 run_REngineRmainloop + 156  
(crt.c:300)
25  org.R-project.R          	0x0000e56c -[REngine runREPL] + 76  
(crt.c:300)
26  com.apple.Foundation     	0x928e949c __NSFireTimer + 116
27  com.apple.CoreFoundation 	0x90770aec __CFRunLoopDoTimer + 184
28  com.apple.CoreFoundation 	0x9075d464 __CFRunLoopRun + 1680
29  com.apple.CoreFoundation 	0x9075ca18 CFRunLoopRunSpecific + 268
30  com.apple.HIToolbox      	0x9318e1e0 RunCurrentEventLoopInMode + 264
31  com.apple.HIToolbox      	0x9318d874 ReceiveNextEventCommon + 380
32  com.apple.HIToolbox      	0x9318d6e0  
BlockUntilNextEventMatchingListInMode + 96
33  com.apple.AppKit         	0x9368b104 _DPSNextEvent + 384
34  com.apple.AppKit         	0x9368adc8 -[NSApplication  
nextEventMatchingMask:untilDate:inMode:dequeue:] + 116
35  com.apple.AppKit         	0x9368730c -[NSApplication run] + 472
36  com.apple.AppKit         	0x93777e68 NSApplicationMain + 452
37  org.R-project.R          	0x00002eb0 _start + 392 (crt.c:267)
38  dyld                     	0x8fe01048 _dyld_start + 60

Thread 1:
0   libSystem.B.dylib        	0x9001f20c select + 12
1   org.R-project.R          	0x00004674 -[RController readThread:] +  
524 (crt.c:300)
2   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
3   libSystem.B.dylib        	0x9002b200 _pthread_body + 96

Thread 2:
0   libSystem.B.dylib        	0x90049748 syscall_thread_switch + 8
1   com.apple.Foundation     	0x928fead0 +[NSThread sleepUntilDate:]  
+ 152
2   com.apple.AppKit         	0x93728034 -[NSUIHeartBeat  
_heartBeatThread:] + 1100
3   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
4   libSystem.B.dylib        	0x9002b200 _pthread_body + 96

Thread 0 crashed with PPC Thread State 64:
   srr0: 0x000000000169a2c0 srr1:  
0x100000000200f030                        vrsave: 0x0000000000000000
     cr: 0x48022448          xer: 0x0000000020000000   lr:  
0x000000000169a1c0  ctr: 0x0000000000000000
     r0: 0x0000000000003840   r1: 0x00000000bfffa390   r2:  
0x0000000006dd4e98   r3: 0x0000000000000000
     r4: 0x0000000006dd4858   r5: 0x0000000006dd3598   r6:  
0x0000000006dd3bd8   r7: 0x0000000006dd4218
     r8: 0x0000000063110304   r9: 0x0000000007488658  r10:  
0x00000000000000c7  r11: 0x000000000748a258
    r12: 0x0000000006dd4858  r13: 0x0000000000000640  r14:  
0x000000000748a418  r15: 0x00000000071ec9a8
    r16: 0x0000000007488018  r17: 0x0000000000000004  r18:  
0x0000000007489c18  r19: 0x00000000019fc7c0
    r20: 0x0000000006dd1018  r21: 0x00000000000000c8  r22:  
0x0000000000002580  r23: 0x0000000000003840
    r24: 0x00000000000000c8  r25: 0x00000000000000c7  r26:  
0x0000000000000640  r27: 0x0000000007489c18
    r28: 0x000000000748b3b8  r29: 0x0000000000000098  r30:  
0x0000000006dd4218  r31: 0x0000000001699bf0

Binary Images Description:
     0x1000 -    0x3bfff org.R-project.R 1.14 (2129)	/Applications/ 
R.app/Contents/MacOS/R
    0x55000 -    0x87fff libreadline.5.0.dylib 	/Library/Frameworks/ 
R.framework/Resources/lib/libreadline.5.0.dylib
    0x9b000 -    0xc6fff libncurses.5.dylib 	/usr/lib/libncurses.5.dylib
   0x205000 -   0x398fff libR.dylib 	/Library/Frameworks/R.framework/ 
Resources/lib/libR.dylib
0x1673000 -  0x1675fff Hmisc.so 	/Library/Frameworks/R.framework/ 
Resources/library/Hmisc/libs/Hmisc.so
0x1697000 -  0x16a2fff acepack.so 	/Library/Frameworks/R.framework/ 
Resources/library/acepack/libs/acepack.so
0x175a000 -  0x175dfff methods.so 	/Library/Frameworks/R.framework/ 
Resources/library/methods/libs/methods.so
0x684b000 -  0x6861fff grDevices.so 	/Library/Frameworks/R.framework/ 
Resources/library/grDevices/libs/grDevices.so
0x690d000 -  0x6950fff stats.so 	/Library/Frameworks/R.framework/ 
Resources/library/stats/libs/stats.so
0x6a4d000 -  0x6a54fff internet.so 	/Library/Frameworks/R.framework/ 
Resources/modules/internet.so
0x6d42000 -  0x6d43fff tools.so 	/Library/Frameworks/R.framework/ 
Resources/library/tools/libs/tools.so
0x8fe00000 - 0x8fe54fff dyld 44.2	/usr/lib/dyld
0x90000000 - 0x901b3fff libSystem.B.dylib 	/usr/lib/libSystem.B.dylib
0x9020b000 - 0x9020ffff libmathCommon.A.dylib 	/usr/lib/system/ 
libmathCommon.A.dylib
0x90211000 - 0x90264fff com.apple.CoreText 1.0.1 (???)	/System/ 
Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/CoreText.framework/Versions/A/CoreText
0x90291000 - 0x90342fff ATS 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/ 
Versions/A/ATS
0x90371000 - 0x906aefff com.apple.CoreGraphics 1.256.30 (???)	/System/ 
Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics
0x9073a000 - 0x90813fff com.apple.CoreFoundation 6.4.4 (368.25)	/ 
System/Library/Frameworks/CoreFoundation.framework/Versions/A/ 
CoreFoundation
0x9085c000 - 0x9085cfff com.apple.CoreServices 10.4 (???)	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/CoreServices
0x9085e000 - 0x90960fff libicucore.A.dylib 	/usr/lib/libicucore.A.dylib
0x909ba000 - 0x90a3efff libobjc.A.dylib 	/usr/lib/libobjc.A.dylib
0x90a68000 - 0x90ad6fff com.apple.framework.IOKit 1.4 (???)	/System/ 
Library/Frameworks/IOKit.framework/Versions/A/IOKit
0x90aed000 - 0x90afffff libauto.dylib 	/usr/lib/libauto.dylib
0x90b06000 - 0x90ddefff com.apple.CoreServices.CarbonCore 681.3  
(671.2)	/System/Library/Frameworks/CoreServices.framework/Versions/A/ 
Frameworks/CarbonCore.framework/Versions/A/CarbonCore
0x90e44000 - 0x90ec4fff com.apple.CoreServices.OSServices 4.1	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
OSServices.framework/Versions/A/OSServices
0x90f0e000 - 0x90f4ffff com.apple.CFNetwork 10.4.4 (129.9)	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
CFNetwork.framework/Versions/A/CFNetwork
0x90f64000 - 0x90f7cfff com.apple.WebServices 1.1.2 (1.1.0)	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
WebServicesCore.framework/Versions/A/WebServicesCore
0x90f8c000 - 0x9100dfff com.apple.SearchKit 1.0.5	/System/Library/ 
Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
SearchKit.framework/Versions/A/SearchKit
0x91053000 - 0x9107dfff com.apple.Metadata 10.4.4 (121.34)	/System/ 
Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/ 
Metadata.framework/Versions/A/Metadata
0x9108e000 - 0x9109cfff libz.1.dylib 	/usr/lib/libz.1.dylib
0x9109f000 - 0x91262fff com.apple.security 4.3 (25966)	/System/ 
Library/Frameworks/Security.framework/Versions/A/Security
0x91365000 - 0x9136efff com.apple.DiskArbitration 2.1	/System/Library/ 
Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration
0x91375000 - 0x9139cfff com.apple.SystemConfiguration 1.8.2	/System/ 
Library/Frameworks/SystemConfiguration.framework/Versions/A/ 
SystemConfiguration
0x913af000 - 0x913b7fff libgcc_s.1.dylib 	/usr/lib/libgcc_s.1.dylib
0x913bc000 - 0x913dcfff libmx.A.dylib 	/usr/lib/libmx.A.dylib
0x913e2000 - 0x913eafff libbsm.dylib 	/usr/lib/libbsm.dylib
0x913ee000 - 0x9146efff com.apple.audio.CoreAudio 3.0.2	/System/ 
Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio
0x914ad000 - 0x914adfff com.apple.ApplicationServices 10.4 (???)	/ 
System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
ApplicationServices
0x914af000 - 0x914e7fff com.apple.AE 1.5 (297)	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
AE.framework/Versions/A/AE
0x91502000 - 0x915cffff com.apple.ColorSync 4.4.4	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
ColorSync.framework/Versions/A/ColorSync
0x91624000 - 0x916b7fff com.apple.print.framework.PrintCore 4.3  
(172.3)	/System/Library/Frameworks/ApplicationServices.framework/ 
Versions/A/Frameworks/PrintCore.framework/Versions/A/PrintCore
0x916fe000 - 0x917bbfff com.apple.QD 3.8.18 (???)	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
QD.framework/Versions/A/QD
0x917f9000 - 0x91857fff com.apple.HIServices 1.5.1 (???)	/System/ 
Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/HIServices.framework/Versions/A/HIServices
0x91885000 - 0x918a9fff com.apple.LangAnalysis 1.6.1	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
LangAnalysis.framework/Versions/A/LangAnalysis
0x918bd000 - 0x918e2fff com.apple.FindByContent 1.5	/System/Library/ 
Frameworks/ApplicationServices.framework/Versions/A/Frameworks/ 
FindByContent.framework/Versions/A/FindByContent
0x918f5000 - 0x91937fff com.apple.LaunchServices 10.4.6 (168.3)	/ 
System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/LaunchServices.framework/Versions/A/LaunchServices
0x91953000 - 0x91967fff com.apple.speech.synthesis.framework 3.3	/ 
System/Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis
0x91975000 - 0x919affff com.apple.ImageIO.framework 1.4.4	/System/ 
Library/Frameworks/ApplicationServices.framework/Versions/A/ 
Frameworks/ImageIO.framework/Versions/A/ImageIO
0x919c4000 - 0x91a8cfff libcrypto.0.9.7.dylib 	/usr/lib/libcrypto. 
0.9.7.dylib
0x91ada000 - 0x91aeffff libcups.2.dylib 	/usr/lib/libcups.2.dylib
0x91af4000 - 0x91b11fff libJPEG.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libJPEG.dylib
0x91b16000 - 0x91b85fff libJP2.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libJP2.dylib
0x91b9c000 - 0x91ba0fff libGIF.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libGIF.dylib
0x91ba2000 - 0x91bd3fff libRaw.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libRaw.dylib
0x91bd7000 - 0x91c1afff libTIFF.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libTIFF.dylib
0x91c21000 - 0x91c3afff libPng.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libPng.dylib
0x91c3f000 - 0x91c42fff libRadiance.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/ 
Versions/A/Resources/libRadiance.dylib
0x91c44000 - 0x91c44fff com.apple.Accelerate 1.1.1 (Accelerate  
1.1.1)	/System/Library/Frameworks/Accelerate.framework/Versions/A/ 
Accelerate
0x91c46000 - 0x91d30fff com.apple.vImage 2.0	/System/Library/ 
Frameworks/Accelerate.framework/Versions/A/Frameworks/ 
vImage.framework/Versions/A/vImage
0x91d38000 - 0x91d57fff com.apple.Accelerate.vecLib 3.1.1 (vecLib  
3.1.1)	/System/Library/Frameworks/Accelerate.framework/Versions/A/ 
Frameworks/vecLib.framework/Versions/A/vecLib
0x91dc3000 - 0x91e28fff libvMisc.dylib 	/System/Library/Frameworks/ 
Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/ 
A/libvMisc.dylib
0x91e32000 - 0x91ec4fff libvDSP.dylib 	/System/Library/Frameworks/ 
Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/ 
A/libvDSP.dylib
0x91ede000 - 0x9246efff libBLAS.dylib 	/System/Library/Frameworks/ 
Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/ 
A/libBLAS.dylib
0x924b6000 - 0x927c6fff libLAPACK.dylib 	/System/Library/Frameworks/ 
Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/ 
A/libLAPACK.dylib
0x927f3000 - 0x9287ffff com.apple.DesktopServices 1.3.1	/System/ 
Library/PrivateFrameworks/DesktopServicesPriv.framework/Versions/A/ 
DesktopServicesPriv
0x928c1000 - 0x92aebfff com.apple.Foundation 6.4.2 (567.21)	/System/ 
Library/Frameworks/Foundation.framework/Versions/C/Foundation
0x92c09000 - 0x92ce7fff libxml2.2.dylib 	/usr/lib/libxml2.2.dylib
0x92d07000 - 0x92df5fff libiconv.2.dylib 	/usr/lib/libiconv.2.dylib
0x92e07000 - 0x92e25fff libGL.dylib 	/System/Library/Frameworks/ 
OpenGL.framework/Versions/A/Libraries/libGL.dylib
0x92e30000 - 0x92e8afff libGLU.dylib 	/System/Library/Frameworks/ 
OpenGL.framework/Versions/A/Libraries/libGLU.dylib
0x92ea8000 - 0x92ea8fff com.apple.Carbon 10.4 (???)	/System/Library/ 
Frameworks/Carbon.framework/Versions/A/Carbon
0x92eaa000 - 0x92ebefff com.apple.ImageCapture 3.0	/System/Library/ 
Frameworks/Carbon.framework/Versions/A/Frameworks/ 
ImageCapture.framework/Versions/A/ImageCapture
0x92ed6000 - 0x92ee6fff com.apple.speech.recognition.framework 3.4	/ 
System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
SpeechRecognition.framework/Versions/A/SpeechRecognition
0x92ef2000 - 0x92f07fff com.apple.securityhi 2.0 (203)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
SecurityHI.framework/Versions/A/SecurityHI
0x92f19000 - 0x92fa0fff com.apple.ink.framework 101.2 (69)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
Ink.framework/Versions/A/Ink
0x92fb4000 - 0x92fbffff com.apple.help 1.0.3 (32)	/System/Library/ 
Frameworks/Carbon.framework/Versions/A/Frameworks/Help.framework/ 
Versions/A/Help
0x92fc9000 - 0x92ff6fff com.apple.openscripting 1.2.4 (???)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
OpenScripting.framework/Versions/A/OpenScripting
0x93010000 - 0x93020fff com.apple.print.framework.Print 5.0 (190.1)	/ 
System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
Print.framework/Versions/A/Print
0x9302c000 - 0x93092fff com.apple.htmlrendering 1.1.2	/System/Library/ 
Frameworks/Carbon.framework/Versions/A/Frameworks/ 
HTMLRendering.framework/Versions/A/HTMLRendering
0x930c3000 - 0x93115fff com.apple.NavigationServices 3.4.2	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
NavigationServices.framework/Versions/A/NavigationServices
0x93141000 - 0x9315efff com.apple.audio.SoundManager 3.9	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
CarbonSound.framework/Versions/A/CarbonSound
0x93170000 - 0x9317dfff com.apple.CommonPanels 1.2.2 (73)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
CommonPanels.framework/Versions/A/CommonPanels
0x93186000 - 0x93498fff com.apple.HIToolbox 1.4.5 (???)	/System/ 
Library/Frameworks/Carbon.framework/Versions/A/Frameworks/ 
HIToolbox.framework/Versions/A/HIToolbox
0x935e4000 - 0x935f0fff com.apple.opengl 1.4.7	/System/Library/ 
Frameworks/OpenGL.framework/Versions/A/OpenGL
0x93681000 - 0x93681fff com.apple.Cocoa 6.4 (???)	/System/Library/ 
Frameworks/Cocoa.framework/Versions/A/Cocoa
0x93683000 - 0x93cb6fff com.apple.AppKit 6.4.4 (824.33)	/System/ 
Library/Frameworks/AppKit.framework/Versions/C/AppKit
0x94043000 - 0x940b3fff com.apple.CoreData 80	/System/Library/ 
Frameworks/CoreData.framework/Versions/A/CoreData
0x940ec000 - 0x941b6fff com.apple.audio.toolbox.AudioToolbox 1.4.1	/ 
System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox
0x9420a000 - 0x9420afff com.apple.audio.units.AudioUnit 1.4	/System/ 
Library/Frameworks/AudioUnit.framework/Versions/A/AudioUnit
0x9420c000 - 0x94384fff com.apple.QuartzCore 1.4.5	/System/Library/ 
Frameworks/QuartzCore.framework/Versions/A/QuartzCore
0x943ce000 - 0x9440bfff libsqlite3.0.dylib 	/usr/lib/libsqlite3.0.dylib
0x94413000 - 0x94463fff libGLImage.dylib 	/System/Library/Frameworks/ 
OpenGL.framework/Versions/A/Libraries/libGLImage.dylib
0x94605000 - 0x94614fff libCGATS.A.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ 
CoreGraphics.framework/Versions/A/Resources/libCGATS.A.dylib
0x9461c000 - 0x94628fff libCSync.A.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ 
CoreGraphics.framework/Versions/A/Resources/libCSync.A.dylib
0x9466e000 - 0x94686fff libRIP.A.dylib 	/System/Library/Frameworks/ 
ApplicationServices.framework/Versions/A/Frameworks/ 
CoreGraphics.framework/Versions/A/Resources/libRIP.A.dylib
0x95663000 - 0x956effff com.apple.WebKit 417.9	/System/Library/ 
Frameworks/WebKit.framework/Versions/A/WebKit
0x9574a000 - 0x9583ffff com.apple.JavaScriptCore 1.2 (417.8)	/System/ 
Library/Frameworks/WebKit.framework/Versions/A/Frameworks/ 
JavaScriptCore.framework/Versions/A/JavaScriptCore
0x9587b000 - 0x95b85fff com.apple.WebCore 417.17	/System/Library/ 
Frameworks/WebKit.framework/Versions/A/Frameworks/WebCore.framework/ 
Versions/A/WebCore
0x95d0c000 - 0x95d35fff libxslt.1.dylib 	/usr/lib/libxslt.1.dylib
0x95fdb000 - 0x95fddfff com.apple.ExceptionHandling 1.2 (???)	/System/ 
Library/Frameworks/ExceptionHandling.framework/Versions/A/ 
ExceptionHandling
0x96fba000 - 0x96fd9fff com.apple.vecLib 3.1.1 (vecLib 3.1.1)	/System/ 
Library/Frameworks/vecLib.framework/Versions/A/vecLib

Model: PowerMac7,2, BootROM 5.0.7f0, 2 processors, PowerPC 970   
(2.2), 2 GHz, 8 GB
Graphics: ATI Radeon 9600 Pro, ATY,RV350, AGP, 64 MB
Memory Module: DIMM0/J11, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM1/J12, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM2/J13, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM3/J14, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM4/J41, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM5/J42, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM6/J43, 1 GB, DDR SDRAM, PC3200U-30330
Memory Module: DIMM7/J44, 1 GB, DDR SDRAM, PC3200U-30330
Modem: MicroDash, UCJ, V.92, 1.0F, APPLE VERSION 2.6.6
Network Service: Built-in Ethernet, Ethernet, en0
Serial ATA Device: ST3160023AS, 149.05 GB
Parallel ATA Device: PIONEER DVD-RW  DVR-106D,
USB Device: Flash Disk, USB, Up to 480 Mb/sec, 500 mA
USB Device: hp LaserJet 1300, Hewlett-Packard, Up to 12 Mb/sec, 500 mA
USB Device: Hub, , Up to 12 Mb/sec, 500 mA
USB Device: Hub in Apple Pro Keyboard, Mitsumi Electric, Up to 12 Mb/ 
sec, 500 mA
USB Device: Apple Pro Keyboard, Mitsumi Electric, Up to 12 Mb/sec,  
250 mA
USB Device: Studio Display, , Up to 1.5 Mb/sec, 500 mA
USB Device: Apple Optical USB Mouse, Logitech, Up to 1.5 Mb/sec, 500 mA



From tolga at coubros.com  Thu Feb 16 20:38:18 2006
From: tolga at coubros.com (Tolga Uzuner)
Date: Thu, 16 Feb 2006 19:38:18 +0000
Subject: [R] Problem with scoping a variable value
Message-ID: <43F4D4AA.3070905@coubros.com>

Hi there,

I have a function which has a variable called show as an input:

richardson.grad <- function(func, x, d=0.01, eps=1e-4, r=6, show=F){
# do some things
   if(show) {

        cat("\n","first order approximations", "\n")       
        print(a.mtr, 12)


    }
#do more things and return
}

The show variable is being used as a flag to show intermediate results.

Interestingly enough, I have downloaded a package recently which defines 
the show variable as a function:

 > show
standardGeneric for "show" defined from package "methods"

function (object)
standardGeneric("show")
<environment: 01676F7C>
Methods may be defined for arguments: object

 >

Now, all of a sudden, the function I had defined earlier is scoping up 
to this new value, and is thus not working:

 > richardson.grad(function(x) x^2,2)
Error in if (show) { : argument is not interpretable as logical
 >

I could always redefine show in richardson.grad to be something else but 
something seems wrong: why is richardson.grad not looking up show's 
value in the  function ? How would I fix this ?

Thanks in advance,
Tolga



From f.harrell at vanderbilt.edu  Thu Feb 16 20:49:02 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 16 Feb 2006 13:49:02 -0600
Subject: [R] segmentation fault with Hmisc areg.boot()
In-Reply-To: <BC8A77DD-B116-41E0-A14F-5E0AD78B5087@muohio.edu>
References: <BC8A77DD-B116-41E0-A14F-5E0AD78B5087@muohio.edu>
Message-ID: <43F4D72E.2000209@vanderbilt.edu>

Martin Henry H. Stevens wrote:
> Hi Folks,
> Mac OS 10.4.4
> R 2.2.1(2005-12-20 r36812)
> Hmisc 3.0-10
> acepack 1.3-2.2
> 
> I keep getting a "segmentation fault" when trying to run areg.boot in  
> the Hmisc package. I include below output from two different attempts.
> Thank you in advance for any help.
> 
> Hank Stevens
> 
> The following is taken from the example in the areg.boot  
> documentation, run inside Aquamacs Emacs:
> 
>  > set.seed(171)  # to be able to reproduce example
>  > x1 <- rnorm(200)
>  > x2 <- runif(200)  # a variable that is really unrelated to y]
>  > x3 <- factor(sample(c('cat','dog','cow'), 200,TRUE))  # also  
> unrelated to y
>  > y  <- exp(x1 + rnorm(200)/3)
>  > f  <- areg.boot(y ~ x1 + x2 + x3, B=40)

Works fine on debian linux with same versions

Frank

P.S.  In future it's best to omit prompts from lines of code for easy 
pasting into the R prompt.



From HStevens at MUOhio.edu  Thu Feb 16 20:51:14 2006
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Thu, 16 Feb 2006 14:51:14 -0500
Subject: [R] Help to find correlation.
In-Reply-To: <A8211152E29B0F4FBC3F553F684D1F2A18DE65@svits28.main.ad.rit.edu>
References: <A8211152E29B0F4FBC3F553F684D1F2A18DE5F@svits28.main.ad.rit.edu>
	<A8211152E29B0F4FBC3F553F684D1F2A18DE65@svits28.main.ad.rit.edu>
Message-ID: <19DF31AC-9CA7-487F-B0A5-69A0DE0B30AD@MUOhio.edu>

Hi,
See help files for read.csv for input.
See help files for cor.test
dat <- read.csv("whatever-your-file-is", other info...)

# Generate an upper triangular  matrix of Pearson product moment  
correlation coefficients
r.s <- matrix(NA, nr=dim(dat)[2], nc=dim(dat)[2])
rownames(r.s) <- names(dat)
colnames(r.s) <- names(dat)
for(i in 1:(dim(dat)[2]-1)) {
   for(j in i:dim(dat)[2]) r.s[i,j] <- {cor.test(dat[,i], dat[,j]) 
$p.value}}
r.s

# Generate an upper triangular  matrix of P values of the r's
p.s <- matrix(NA, nr=dim(dat)[2], nc=dim(dat)[2])
rownames(p.s) <- names(dat)
colnames(p.s) <- names(dat)
for(i in 1:(dim(dat)[2]-1)) {
   for(j in i:dim(dat)[2]) p.s[i,j] <- {cor.test(dat[,i], dat[,j]) 
$p.value}}
p.s

Please do read the help files.
Hank

On Feb 16, 2006, at 1:17 PM, Anusha Aiyaloo kannan ((RIT Student))  
wrote:

>
> Respected Sir,
>
> I am trying to import excel file into R, but I need to truncate  
> some columns from the original file.
>
>  How to delete unwanted columns when I import data from excel file.
>
> How to use cor.test for the data when I want the output rowwise.
>
> How to do grouping and use cor.test on that data
>
> I need some help regarding how to calculate the correlation.
> I don't know whether you understood my question, but I need help.
>
> Any help is appreciated.
>
> Thanks,
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From HStevens at MUOhio.edu  Thu Feb 16 20:57:07 2006
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Thu, 16 Feb 2006 14:57:07 -0500
Subject: [R] Help to find correlation. Oops
In-Reply-To: <A8211152E29B0F4FBC3F553F684D1F2A18DE65@svits28.main.ad.rit.edu>
References: <A8211152E29B0F4FBC3F553F684D1F2A18DE5F@svits28.main.ad.rit.edu>
	<A8211152E29B0F4FBC3F553F684D1F2A18DE65@svits28.main.ad.rit.edu>
Message-ID: <64CFD60C-E651-4B3D-94A3-04D79745582D@MUOhio.edu>

Hi,
Ignore the previous post-it contained a typo. Sorry! The following is  
ok.
Hank

See help files for read.csv for input.
See help files for cor.test
dat <- read.csv("whatever-your-file-is", other info...)

# Generate an upper triangular  matrix of Pearson product moment  
correlation coefficients
r.s <- matrix(NA, nr=dim(dat)[2], nc=dim(dat)[2])
rownames(r.s) <- names(dat)
colnames(r.s) <- names(dat)
for(i in 1:(dim(dat)[2]-1)) {
   for(j in i:dim(dat)[2]) r.s[i,j] <- {cor.test(dat[,i], dat[,j]) 
$estimate}}
r.s

# Generate an upper triangular  matrix of P values of the r's
p.s <- matrix(NA, nr=dim(dat)[2], nc=dim(dat)[2])
rownames(p.s) <- names(dat)
colnames(p.s) <- names(dat)
for(i in 1:(dim(dat)[2]-1)) {
   for(j in i:dim(dat)[2]) p.s[i,j] <- {cor.test(dat[,i], dat[,j]) 
$p.value}}
p.s

Please do read the help files.
Hank

On Feb 16, 2006, at 1:17 PM, Anusha Aiyaloo kannan ((RIT Student))  
wrote:

>
> Respected Sir,
>
> I am trying to import excel file into R, but I need to truncate  
> some columns from the original file.
>
>  How to delete unwanted columns when I import data from excel file.
>
> How to use cor.test for the data when I want the output rowwise.
>
> How to do grouping and use cor.test on that data
>
> I need some help regarding how to calculate the correlation.
> I don't know whether you understood my question, but I need help.
>
> Any help is appreciated.
>
> Thanks,
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html

Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/~stevenmh/
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From marcodoc75 at yahoo.com  Thu Feb 16 21:01:32 2006
From: marcodoc75 at yahoo.com (Marco Geraci)
Date: Thu, 16 Feb 2006 12:01:32 -0800 (PST)
Subject: [R] testing the significance of the variance components using
	lme
In-Reply-To: <00d401c63326$34bc7e60$3301a8c0@BIOEF.ORG>
Message-ID: <20060216200132.1723.qmail@web31315.mail.mud.yahoo.com>

Hi,
you should say a little more about the data you have.
I guess you refer to longitudinal data. I say so
because if you deal with spatial smoothing splines in
form of mixed models, the answer to your question
would be different. Anyway, a good starting point is
given by the commands

fit.lme <- lme(...) # fitted model
fit.lme$apVar # approx. covariace matrix for the
variance-covariance coefficients (see ?lmeObject)
intervals(fit.lme) # confidence intervals for the
parameter(s)

I believe that Pinhiero and Bates (2000) Mixed-Effects
Models in S and S-Plus (Springer) includes some
answers to your questions. I don't really know what
happens when you use 'intervals' and the caveats of
this command. When it comes to making inference about
the variance components I tend to be suspicious. I
hope some R users can give you a more complete answer
than mine.

Testing whether or not a variance component is zero is
a delicate issue. Check:
- Self and Liang (1987), Asymptotic properties of
maximum likelihood estimators and likelihood ratio
tests under nonstandard conditions. Journal of the
American Statistical Association, 82, 605-610
- Zhang and Lin (2003), Hypothesis testing in
semiparametric additive mixed models. Biometrika, 4,
57-74
- Bottai (2003), Confidence regions when the Fisher
information is zero. Biometrika, 90, 73-84.

hope this helps a little

Marco

--- Berta <ibanez at bioef.org> wrote:

> Hi R-users,
>  
> I am using lme to fit a linear mixed model with the
> nlme package,
> does anyone know if it is possible to obtain
> standard error estimates of the variance components
> estimators and an adequate method to test  the
> significance of the variance component?
>  
> Thanks,
> Berta.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From rodrigo.tsai at gmail.com  Thu Feb 16 21:04:50 2006
From: rodrigo.tsai at gmail.com (Rodrigo Tsai)
Date: Thu, 16 Feb 2006 18:04:50 -0200
Subject: [R] error loading RWinEdt
Message-ID: <a9801f600602161204v799b0ad1xa0b2bbaec7c1329@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/02664dc8/attachment.pl

From jwd at surewest.net  Thu Feb 16 21:22:32 2006
From: jwd at surewest.net (J Dougherty)
Date: Thu, 16 Feb 2006 12:22:32 -0800
Subject: [R] Variance for Vector of Constants is Not Zero
In-Reply-To: <000601c6332f$519fbb60$0a00a8c0@Dell2003desktop>
References: <000601c6332f$519fbb60$0a00a8c0@Dell2003desktop>
Message-ID: <200602161222.33080.jwd@surewest.net>

On Thursday 16 February 2006 11:29, Barry Zajdlik wrote:
> 1.337451e-35

Well, its nearly zero ;-)

JD



From comtech.usa at gmail.com  Thu Feb 16 21:22:40 2006
From: comtech.usa at gmail.com (Michael)
Date: Thu, 16 Feb 2006 12:22:40 -0800
Subject: [R] how to clear screen in R-console?
In-Reply-To: <59d7961d0602160459t493de978na04494e207460e55@mail.gmail.com>
References: <b1f16d9d0602160233r1a95ba81qd81583b047b7f2af@mail.gmail.com>
	<43F45928.8010902@web.de>
	<b1f16d9d0602160322m6cb6a484mfd6aee2bbf2b758b@mail.gmail.com>
	<59d7961d0602160459t493de978na04494e207460e55@mail.gmail.com>
Message-ID: <b1f16d9d0602161222g6f72e36cg93aba58b11fd2a53@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/08506b54/attachment.pl

From ggrothendieck at gmail.com  Thu Feb 16 21:24:02 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 16 Feb 2006 15:24:02 -0500
Subject: [R] Problem with scoping a variable value
In-Reply-To: <43F4D4AA.3070905@coubros.com>
References: <43F4D4AA.3070905@coubros.com>
Message-ID: <971536df0602161224g63dd6d74vf9e852a611f6788f@mail.gmail.com>

Without a reproducible example one can only guess but
perhaps the problem is not show but that you have a variable
F.  Try writing out F as FALSE.


On 2/16/06, Tolga Uzuner <tolga at coubros.com> wrote:
> Hi there,
>
> I have a function which has a variable called show as an input:
>
> richardson.grad <- function(func, x, d=0.01, eps=1e-4, r=6, show=F){
> # do some things
>   if(show) {
>
>        cat("\n","first order approximations", "\n")
>        print(a.mtr, 12)
>
>
>    }
> #do more things and return
> }
>
> The show variable is being used as a flag to show intermediate results.
>
> Interestingly enough, I have downloaded a package recently which defines
> the show variable as a function:
>
>  > show
> standardGeneric for "show" defined from package "methods"
>
> function (object)
> standardGeneric("show")
> <environment: 01676F7C>
> Methods may be defined for arguments: object
>
>  >
>
> Now, all of a sudden, the function I had defined earlier is scoping up
> to this new value, and is thus not working:
>
>  > richardson.grad(function(x) x^2,2)
> Error in if (show) { : argument is not interpretable as logical
>  >
>
> I could always redefine show in richardson.grad to be something else but
> something seems wrong: why is richardson.grad not looking up show's
> value in the  function ? How would I fix this ?
>
> Thanks in advance,
> Tolga
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Thu Feb 16 21:30:04 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 16 Feb 2006 12:30:04 -0800
Subject: [R] Variance for Vector of Constants is Not Zero
In-Reply-To: <000601c6332f$519fbb60$0a00a8c0@Dell2003desktop>
References: <000601c6332f$519fbb60$0a00a8c0@Dell2003desktop>
Message-ID: <43F4E0CC.4000501@pdf.com>

	  Could you please provide "sessionInfo()";  I can't replicate the 
problem:

 > var(x)
[1] 0
 > sessionInfo()
R version 2.2.1, 2005-12-20, i386-pc-mingw32

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"

	  spencer graves

Barry Zajdlik wrote:

> Hi All,
> 
> An annoying but not critical problem I am having is that the variance of
> a vector of constants is reported as > 0. I imagine there is a simple
> workaround for the following but could not find it after having spent an
> embarrassing amount of time.
> 
> In Splus:
> 
> 
>>x<-rep(0.02,10)
>>var(x)
>>0
> 
> 
> In R:
> 
> x<-rep(0.02,10)
> var(x)
> 1.337451e-35
> 
> I assumed the problem had to do with machine precision and suitably
> modified .Machine$double.eps and .Machine$double.neg.eps which I thought
> would fix the problem but without success. Any pointers to a solution
> would be appreciated!
> 
> Cheers,
> Barry Zajdlik
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From roger.bos at gmail.com  Thu Feb 16 21:39:30 2006
From: roger.bos at gmail.com (roger bos)
Date: Thu, 16 Feb 2006 15:39:30 -0500
Subject: [R] getting probabilities from SVM
Message-ID: <1db726800602161239h293d3969vb9b10eff62f78416@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/557d4685/attachment.pl

From kjetilbrinchmannhalvorsen at gmail.com  Thu Feb 16 21:42:56 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Thu, 16 Feb 2006 16:42:56 -0400
Subject: [R] A concrete type I/III Sum of square problem
In-Reply-To: <b20ae6290602160437w5e8dd10bu35649352cdf5aeee@mail.gmail.com>
References: <43F41DA0.2010806@gmail.com>
	<x24q2z374c.fsf@viggo.kubism.ku.dk>	<b20ae6290602160358m3ef96e52o4cea058208183042@mail.gmail.com>	<x2mzgr1o60.fsf@viggo.kubism.ku.dk>
	<b20ae6290602160437w5e8dd10bu35649352cdf5aeee@mail.gmail.com>
Message-ID: <43F4E3D0.3050000@gmail.com>

Gregor GORJANC wrote:
> On 16 Feb 2006 13:30:31 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>> Gregor GORJANC <gregor.gorjanc at gmail.com> writes:
>>
>>> On 16 Feb 2006 11:55:47 +0100, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
>>>> Gregor Gorjanc <gregor.gorjanc at gmail.com> writes:
>>>>
>>> ...
>>>>> Can you (prof. Dalgaard) please point us to relevant book with these
>>>>> topics. I am very interested in it since my data are often unbalanced.
>>>> Hmm, the Danish tradition is highly based on lecture notes, so I don't
>>>> have a specific book for you. One possible starting point is
>>> If there are some good lecture notes around I would like to read them
>>> even more ;)
>> You may find that there is a language barrier....
> 
> Oh, dear. I hoped for lecture notes written in universal language for
> stats. i.e. R, you probably heard about it. Just joking. Thanks anyway.
> 
> --

If that language behind the barrier is Danish, there must be at least a
few persons on the list who could benefit, so url's are welcome!
Would'nt hurt with some Danish lecture notes in my bookshelf, although
Piet Hein certainly have better grooks.

Kjetil

> Lep pozdrav / With regards,
>     Gregor Gorjanc
> 
> ----------------------------------------------------------------------------------------------------
> University of Ljubljana          PhD student
> Biotechnical Faculty
> Zootechnical Department     URI: http://www.bfro.uni-lj.si/MR/ggorjan
> Groblje 3                            mail: gregor.gorjanc <at> bfro.uni-lj.si
> SI-1230 Domzale                tel: +386 (0)1 72 17 861
> Slovenia, Europe                 fax: +386 (0)1 72 17 888
> ----------------------------------------------------------------------------------------------------
> "One must learn by doing the thing; for though you think you know it,
>  you have no certainty until you try." Sophocles ~ 450 B.C.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From islandboy1982 at yahoo.com  Thu Feb 16 21:47:28 2006
From: islandboy1982 at yahoo.com (oliver wee)
Date: Thu, 16 Feb 2006 12:47:28 -0800 (PST)
Subject: [R] function for prediting garch
Message-ID: <20060216204728.39488.qmail@web33211.mail.mud.yahoo.com>

hello,

In my time series data, I was able to successfully fit
its ARIMA model (Box-Jenkins) and its GARCH model and
estimate their parameters. I was also able to forecast
future values of the time series based on my fitted
ARIMA model using the predict() function call. 

However, I'm not sure what is the correct function
command to call in order to forecast  future values of
my time series using both the fitted ARIMA model and
the fitted GARCH model. Using predict() didn't give me
the result I was looking for. And I can't find any
documentation using help.search,

I think what I am looking for is akin to the garchsim
and garchpred commands in Mathlab.

Any help is appreciated. Thanks!



From f.harrell at vanderbilt.edu  Thu Feb 16 21:55:35 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Thu, 16 Feb 2006 14:55:35 -0600
Subject: [R] Help to find correlation. Oops
In-Reply-To: <64CFD60C-E651-4B3D-94A3-04D79745582D@MUOhio.edu>
References: <A8211152E29B0F4FBC3F553F684D1F2A18DE5F@svits28.main.ad.rit.edu>	<A8211152E29B0F4FBC3F553F684D1F2A18DE65@svits28.main.ad.rit.edu>
	<64CFD60C-E651-4B3D-94A3-04D79745582D@MUOhio.edu>
Message-ID: <43F4E6C7.7080805@vanderbilt.edu>

Or simply

library(Hmisc)
rcorr(data matrix)

Frank

Martin Henry H. Stevens wrote:
> Hi,
> Ignore the previous post-it contained a typo. Sorry! The following is  
> ok.
> Hank
> 
> See help files for read.csv for input.
> See help files for cor.test
> dat <- read.csv("whatever-your-file-is", other info...)
> 
> # Generate an upper triangular  matrix of Pearson product moment  
> correlation coefficients
> r.s <- matrix(NA, nr=dim(dat)[2], nc=dim(dat)[2])
> rownames(r.s) <- names(dat)
> colnames(r.s) <- names(dat)
> for(i in 1:(dim(dat)[2]-1)) {
>    for(j in i:dim(dat)[2]) r.s[i,j] <- {cor.test(dat[,i], dat[,j]) 
> $estimate}}
> r.s
> 
> # Generate an upper triangular  matrix of P values of the r's
> p.s <- matrix(NA, nr=dim(dat)[2], nc=dim(dat)[2])
> rownames(p.s) <- names(dat)
> colnames(p.s) <- names(dat)
> for(i in 1:(dim(dat)[2]-1)) {
>    for(j in i:dim(dat)[2]) p.s[i,j] <- {cor.test(dat[,i], dat[,j]) 
> $p.value}}
> p.s
> 
> Please do read the help files.
> Hank
> 
> On Feb 16, 2006, at 1:17 PM, Anusha Aiyaloo kannan ((RIT Student))  
> wrote:
> 
> 
>>Respected Sir,
>>
>>I am trying to import excel file into R, but I need to truncate  
>>some columns from the original file.
>>
>> How to delete unwanted columns when I import data from excel file.
>>
>>How to use cor.test for the data when I want the output rowwise.
>>
>>How to do grouping and use cor.test on that data
>>
>>I need some help regarding how to calculate the correlation.
>>I don't know whether you understood my question, but I need help.
>>
>>Any help is appreciated.
>>
>>Thanks,
>>
>>
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting- 
>>guide.html
> 
> 
> Dr. Martin Henry H. Stevens, Assistant Professor
> 338 Pearson Hall
> Botany Department
> Miami University
> Oxford, OH 45056
> 
> Office: (513) 529-4206
> Lab: (513) 529-4262
> FAX: (513) 529-4243
> http://www.cas.muohio.edu/~stevenmh/
> http://www.muohio.edu/ecology/
> http://www.muohio.edu/botany/
> "E Pluribus Unum"
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From ligges at statistik.uni-dortmund.de  Thu Feb 16 22:07:39 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 16 Feb 2006 22:07:39 +0100
Subject: [R] error loading RWinEdt
In-Reply-To: <a9801f600602161204v799b0ad1xa0b2bbaec7c1329@mail.gmail.com>
References: <a9801f600602161204v799b0ad1xa0b2bbaec7c1329@mail.gmail.com>
Message-ID: <43F4E99B.80805@statistik.uni-dortmund.de>

Rodrigo Tsai wrote:
> Dear R Helpers,
> 
> I would be very pleased with your help, again.
> 
> I have this problem when installing / loading RWinEdt. I use R 2.1.1version.
> The same error message occurs when installing from mirrors.
> 
> thanks in advance,
> Rodrigo Tsai.
> 
> 
> 
> 
>>install.packages("c:/tsai/pessoal/soft/r-project/RWinEdt_1.7-4.zip",
> 
> repos=NULL, method="source")
> package 'RWinEdt' successfully unpacked and MD5 sums checked
> updating HTML package descriptions
> 
> 
>>library(RWinEdt)
> 
> Error in getWinEdt() :
> WinEdt is not installed properly.
> Either reinstall WinEdt or install R-WinEdt manually as described in the
> ReadMe

So, did you try to reinstall WinEdt? Which version of WinEdt are you 
using? RWinEdt tries to collect information on WinEdt from the Windows 
registry and failed, obviously.
Additionally, you might want to upgrade to R-2.2.1.

Uwe Ligges




> In addition: Warning message:
> package 'RWinEdt' was built under R version 2.2.1
> Error: .onAttach failed in 'attachNamespace'
> Error: package/namespace load failed for 'RWinEdt'
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Thu Feb 16 22:17:17 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 16 Feb 2006 22:17:17 +0100
Subject: [R] Variance for Vector of Constants is Not Zero
In-Reply-To: <000601c6332f$519fbb60$0a00a8c0@Dell2003desktop>
References: <000601c6332f$519fbb60$0a00a8c0@Dell2003desktop>
Message-ID: <43F4EBDD.2030603@statistik.uni-dortmund.de>

Barry Zajdlik wrote:

> Hi All,
> 
> An annoying but not critical problem I am having is that the variance of
> a vector of constants is reported as > 0. I imagine there is a simple
> workaround for the following but could not find it after having spent an
> embarrassing amount of time.
> 
> In Splus:
> 
> 
>>x<-rep(0.02,10)
>>var(x)
>>0
> 
> 
> In R:
> 
> x<-rep(0.02,10)
> var(x)
> 1.337451e-35


Which version of R and which OS is this? I get 0 for both Linux and 
Windows with R-2.2.1.
Anyway, 0.02 is not well representable and hence can be very well the 
cause for such a numerical inaccuracy.

> I assumed the problem had to do with machine precision and suitably
> modified .Machine$double.eps and .Machine$double.neg.eps which I thought
> would fix the problem but without success. Any pointers to a solution
> would be appreciated!

Changing .Machine$double.eps does not help to calculate more accurate ...

Uwe Ligges


> Cheers,
> Barry Zajdlik
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From roger.bos at gmail.com  Thu Feb 16 22:16:46 2006
From: roger.bos at gmail.com (roger bos)
Date: Thu, 16 Feb 2006 16:16:46 -0500
Subject: [R] getting probabilities from SVM
In-Reply-To: <1db726800602161239h293d3969vb9b10eff62f78416@mail.gmail.com>
References: <1db726800602161239h293d3969vb9b10eff62f78416@mail.gmail.com>
Message-ID: <1db726800602161316u2f7c71f1rcf8956d166c8fc9e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/41f8c3c2/attachment.pl

From roebuck at mdanderson.org  Thu Feb 16 22:22:07 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Thu, 16 Feb 2006 15:22:07 -0600 (CST)
Subject: [R] Problem with scoping a variable value
In-Reply-To: <43F4D4AA.3070905@coubros.com>
References: <43F4D4AA.3070905@coubros.com>
Message-ID: <Pine.OSF.4.58.0602161508001.48504@wotan.mdacc.tmc.edu>

On Thu, 16 Feb 2006, Tolga Uzuner wrote:

> I have a function which has a variable called show as an input:
>
> richardson.grad <- function(func, x, d=0.01, eps=1e-4, r=6, show=F){
> # do some things
>    if(show) {
>
>         cat("\n","first order approximations", "\n")
>         print(a.mtr, 12)
>
>
>     }
> #do more things and return
> }
>
> The show variable is being used as a flag to show intermediate results.
>
> Interestingly enough, I have downloaded a package recently which defines
> the show variable as a function:
>
>  > show
> standardGeneric for "show" defined from package "methods"
>
> function (object)
> standardGeneric("show")
> <environment: 01676F7C>
> Methods may be defined for arguments: object
>
>  >
>
> Now, all of a sudden, the function I had defined earlier is scoping up
> to this new value, and is thus not working:
>
>  > richardson.grad(function(x) x^2,2)
> Error in if (show) { : argument is not interpretable as logical
>  >
>
> I could always redefine show in richardson.grad to be something else but
> something seems wrong: why is richardson.grad not looking up show's
> value in the  function ? How would I fix this ?

You didn't spell out the logical value 'FALSE' which may
be causing your problem. Consider this alternative also...

richardson.grad <- function(func,
                            x,
                            d = 0.01,
                            eps = 1e-4,
                            r = 6,
                            verbose = getOption("verbose")) {
    ## do some things
    if (verbose) {
         cat("\n", "first order approximations:", "\n")
         print(a.mtr, 12)
    }
    ## do more things and return
}

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From revans at jlab.org  Thu Feb 16 22:53:56 2006
From: revans at jlab.org (Richard Evans)
Date: Thu, 16 Feb 2006 16:53:56 -0500
Subject: [R] how to make plot output to JPG or GIF
Message-ID: <000001c63343$7f3fa260$de173981@revansx>

Hello,

How does one write PLOT() commands that make individual graphic files of
plots that are currently generated to the graphics output window of a
session?

Currently, I have a chron-job that generates a new data input files once
every hour. My goal is to then automatically run my "source.r" file with
the plot commands which then automatically generates a web-ready graphic
file in a folder for my server.

thanks!
-revansx



From ripley at stats.ox.ac.uk  Thu Feb 16 23:02:02 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Feb 2006 22:02:02 +0000 (GMT)
Subject: [R] segmentation fault with Hmisc areg.boot(): Now acepack avas
 failure
In-Reply-To: <9B0A357E-CDB5-4C72-9F97-3C3BA0EB8CF8@muohio.edu>
References: <9B0A357E-CDB5-4C72-9F97-3C3BA0EB8CF8@muohio.edu>
Message-ID: <Pine.LNX.4.64.0602162159380.23563@gannet.stats.ox.ac.uk>

This is a problem in a contributed package, and probably in your OS only 
as the daily package checks on Linux and Windows are not reporting 
errors.

The posting guide suggested contacting the maintainer.  As he has a Mac, 
he may be able to help.


On Thu, 16 Feb 2006, Martin Henry H. Stevens wrote:

> Hi Folks,
> Mac OS 10.4.4
> R 2.2.1(2005-12-20 r36812)
> Hmisc 3.0-10
> acepack 1.3-2.2
>
> I had R crashes while running areg.boot in Hmisc (see old message
> below), but now I realize that the problem appears to be in the avas
> function in acepack. I tried running running the avas example (in
> acepack package), and got an immediate crash.
>
> Any thoughts? The Apple crash report (from R GUI crash) follows.
>
> Hank
> Date/Time:      2006-02-16 14:28:39.836 -0500
> OS Version:     10.4.4 (Build 8G32)
> Report Version: 3
>
> Command: R
> Path:    /Applications/R.app/Contents/MacOS/R
> Parent:  WindowServer [75]
>
> Version: 1.14 (2129)
>
> PID:    1814
> Thread: 0
>
> Exception:  EXC_BAD_ACCESS (0x0001)
> Codes:      KERN_INVALID_ADDRESS (0x0001) at 0xfb3513df
>
> Thread 0 Crashed:
> 0   acepack.so               	0x067c42c0 avas_ + 1752 (avas.f:112)
> 1   libR.dylib               	0x0024f498 do_dotCode + 1844 (dotcode.c:
> 1722)
> 2   libR.dylib               	0x00265cb0 Rf_eval + 1544 (eval.c:405)
> 3   libR.dylib               	0x00267ccc do_set + 224 (eval.c:1309)
> 4   libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
> 5   libR.dylib               	0x0026744c do_begin + 136 (eval.c:1058)
> 6   libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
> 7   libR.dylib               	0x00266150 Rf_applyClosure + 952
> (eval.c:576)
> 8   libR.dylib               	0x00265d2c Rf_eval + 1668 (eval.c:417)
> 9   libR.dylib               	0x00267ccc do_set + 224 (eval.c:1309)
> 10  libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
> 11  org.R-project.R          	0x00015884 RGUI_ReplIteration + 500
> (crt.c:300)
> 12  org.R-project.R          	0x00015674 RGUI_ReplConsole + 148
> (crt.c:300)
> 13  org.R-project.R          	0x000155c8 run_REngineRmainloop + 156
> (crt.c:300)
> 14  org.R-project.R          	0x0000e56c -[REngine runREPL] + 76
> (crt.c:300)
> 15  com.apple.Foundation     	0x928e949c __NSFireTimer + 116
> 16  com.apple.CoreFoundation 	0x90770aec __CFRunLoopDoTimer + 184
> 17  com.apple.CoreFoundation 	0x9075d464 __CFRunLoopRun + 1680
> 18  com.apple.CoreFoundation 	0x9075ca18 CFRunLoopRunSpecific + 268
> 19  com.apple.HIToolbox      	0x9318e1e0 RunCurrentEventLoopInMode + 264
> 20  com.apple.HIToolbox      	0x9318d874 ReceiveNextEventCommon + 380
> 21  com.apple.HIToolbox      	0x9318d6e0
> BlockUntilNextEventMatchingListInMode + 96
> 22  com.apple.AppKit         	0x9368b104 _DPSNextEvent + 384
> 23  com.apple.AppKit         	0x9368adc8 -[NSApplication
> nextEventMatchingMask:untilDate:inMode:dequeue:] + 116
> 24  com.apple.AppKit         	0x9368730c -[NSApplication run] + 472
> 25  com.apple.AppKit         	0x93777e68 NSApplicationMain + 452
> 26  org.R-project.R          	0x00002eb0 _start + 392 (crt.c:267)
> 27  dyld                     	0x8fe01048 _dyld_start + 60
>
> Thread 1:
> 0   libSystem.B.dylib        	0x9001f20c select + 12
> 1   org.R-project.R          	0x00004674 -[RController readThread:] +
> 524 (crt.c:300)
> 2   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
> 3   libSystem.B.dylib        	0x9002b200 _pthread_body + 96
>
> Thread 2:
> 0   libSystem.B.dylib        	0x90049748 syscall_thread_switch + 8
> 1   com.apple.Foundation     	0x928fead0 +[NSThread sleepUntilDate:]
> + 152
> 2   com.apple.AppKit         	0x93728034 -[NSUIHeartBeat
> _heartBeatThread:] + 1100
> 3   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
> 4   libSystem.B.dylib        	0x9002b200 _pthread_body + 96
>
> Thread 3:
> 0   libSystem.B.dylib        	0x9000b208 mach_msg_trap + 8
> 1   libSystem.B.dylib        	0x9000b15c mach_msg + 60
> 2   com.apple.CoreFoundation 	0x9075d114 __CFRunLoopRun + 832
> 3   com.apple.CoreFoundation 	0x9075ca18 CFRunLoopRunSpecific + 268
> 4   com.apple.Foundation     	0x9290db9c +[NSURLConnection
> (NSURLConnectionInternal) _resourceLoadLoop:] + 264
> 5   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
> 6   libSystem.B.dylib        	0x9002b200 _pthread_body + 96
>
> Thread 4:
> 0   libSystem.B.dylib        	0x9000b208 mach_msg_trap + 8
> 1   libSystem.B.dylib        	0x9000b15c mach_msg + 60
> 2   com.apple.CoreFoundation 	0x9075d114 __CFRunLoopRun + 832
> 3   com.apple.CoreFoundation 	0x9075ca18 CFRunLoopRunSpecific + 268
> 4   com.apple.Foundation     	0x9290ecdc +[NSURLCache
> _diskCacheSyncLoop:] + 152
> 5   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
> 6   libSystem.B.dylib        	0x9002b200 _pthread_body + 96
>
> Thread 5:
> 0   libSystem.B.dylib        	0x9000b208 mach_msg_trap + 8
> 1   libSystem.B.dylib        	0x9000b15c mach_msg + 60
> 2   com.apple.CoreFoundation 	0x9075d114 __CFRunLoopRun + 832
> 3   com.apple.CoreFoundation 	0x9075ca18 CFRunLoopRunSpecific + 268
> 4   com.apple.Foundation     	0x928f5664 -[NSRunLoop
> runMode:beforeDate:] + 172
> 5   com.apple.Foundation     	0x928f559c -[NSRunLoop run] + 76
> 6   com.apple.WebKit         	0x95665410 +[WebFileDatabase
> _syncLoop:] + 176
> 7   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
> 8   libSystem.B.dylib        	0x9002b200 _pthread_body + 96
>
> Thread 0 crashed with PPC Thread State 64:
>   srr0: 0x00000000067c42c0 srr1:
> 0x100000000200f030                        vrsave: 0x0000000000000000
>     cr: 0x42022448          xer: 0x0000000020000000   lr:
> 0x00000000067c41c0  ctr: 0x0000000000000000
>     r0: 0x0000000000003840   r1: 0x00000000bfffc580   r2:
> 0x00000000075f9e98   r3: 0x0000000000000000
>     r4: 0x00000000075f9858   r5: 0x00000000075f8598   r6:
> 0x00000000075f8bd8   r7: 0x00000000075f9218
>     r8: 0x00000000fb3513df   r9: 0x0000000006a5da58  r10:
> 0x00000000000000c7  r11: 0x0000000001bbf458
>    r12: 0x00000000075f9858  r13: 0x0000000000000640  r14:
> 0x0000000001f9d018  r15: 0x0000000001b8f100
>    r16: 0x0000000006a5d418  r17: 0x0000000000000002  r18:
> 0x0000000001bbee18  r19: 0x0000000006857d40
>    r20: 0x00000000075f6018  r21: 0x00000000000000c8  r22:
> 0x0000000000002580  r23: 0x0000000000003840
>    r24: 0x00000000000000c8  r25: 0x00000000000000c7  r26:
> 0x0000000000000640  r27: 0x0000000001bbee18
>    r28: 0x0000000001f9d978  r29: 0x0000000000000037  r30:
> 0x00000000075f9218  r31: 0x00000000067c3bf0
>
> Binary Images Description:
>     0x1000 -    0x3bfff org.R-project.R 1.14 (2129)	/Applications/
> R.app/Contents/MacOS/R
>    0x55000 -    0x87fff libreadline.5.0.dylib 	/Library/Frameworks/
> R.framework/Resources/lib/libreadline.5.0.dylib
>    0x9b000 -    0xc6fff libncurses.5.dylib 	/usr/lib/libncurses.5.dylib
>   0x205000 -   0x398fff libR.dylib 	/Library/Frameworks/R.framework/
> Resources/lib/libR.dylib
> 0x1756000 -  0x1759fff methods.so 	/Library/Frameworks/R.framework/
> Resources/library/methods/libs/methods.so
> 0x54b4000 -  0x54cafff grDevices.so 	/Library/Frameworks/R.framework/
> Resources/library/grDevices/libs/grDevices.so
> 0x6681000 -  0x66c4fff stats.so 	/Library/Frameworks/R.framework/
> Resources/library/stats/libs/stats.so
> 0x67c1000 -  0x67ccfff acepack.so 	/Library/Frameworks/R.framework/
> Resources/library/acepack/libs/acepack.so
> 0x8fe00000 - 0x8fe54fff dyld 44.2	/usr/lib/dyld
> 0x90000000 - 0x901b3fff libSystem.B.dylib 	/usr/lib/libSystem.B.dylib
> 0x9020b000 - 0x9020ffff libmathCommon.A.dylib 	/usr/lib/system/
> libmathCommon.A.dylib
> 0x90211000 - 0x90264fff com.apple.CoreText 1.0.1 (???)	/System/
> Library/Frameworks/ApplicationServices.framework/Versions/A/
> Frameworks/CoreText.framework/Versions/A/CoreText
> 0x90291000 - 0x90342fff ATS 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/
> Versions/A/ATS
> 0x90371000 - 0x906aefff com.apple.CoreGraphics 1.256.30 (???)	/System/
> Library/Frameworks/ApplicationServices.framework/Versions/A/
> Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics
> 0x9073a000 - 0x90813fff com.apple.CoreFoundation 6.4.4 (368.25)	/
> System/Library/Frameworks/CoreFoundation.framework/Versions/A/
> CoreFoundation
> 0x9085c000 - 0x9085cfff com.apple.CoreServices 10.4 (???)	/System/
> Library/Frameworks/CoreServices.framework/Versions/A/CoreServices
> 0x9085e000 - 0x90960fff libicucore.A.dylib 	/usr/lib/libicucore.A.dylib
> 0x909ba000 - 0x90a3efff libobjc.A.dylib 	/usr/lib/libobjc.A.dylib
> 0x90a68000 - 0x90ad6fff com.apple.framework.IOKit 1.4 (???)	/System/
> Library/Frameworks/IOKit.framework/Versions/A/IOKit
> 0x90aed000 - 0x90afffff libauto.dylib 	/usr/lib/libauto.dylib
> 0x90b06000 - 0x90ddefff com.apple.CoreServices.CarbonCore 681.3
> (671.2)	/System/Library/Frameworks/CoreServices.framework/Versions/A/
> Frameworks/CarbonCore.framework/Versions/A/CarbonCore
> 0x90e44000 - 0x90ec4fff com.apple.CoreServices.OSServices 4.1	/System/
> Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/
> OSServices.framework/Versions/A/OSServices
> 0x90f0e000 - 0x90f4ffff com.apple.CFNetwork 10.4.4 (129.9)	/System/
> Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/
> CFNetwork.framework/Versions/A/CFNetwork
> 0x90f64000 - 0x90f7cfff com.apple.WebServices 1.1.2 (1.1.0)	/System/
> Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/
> WebServicesCore.framework/Versions/A/WebServicesCore
> 0x90f8c000 - 0x9100dfff com.apple.SearchKit 1.0.5	/System/Library/
> Frameworks/CoreServices.framework/Versions/A/Frameworks/
> SearchKit.framework/Versions/A/SearchKit
> 0x91053000 - 0x9107dfff com.apple.Metadata 10.4.4 (121.34)	/System/
> Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/
> Metadata.framework/Versions/A/Metadata
> 0x9108e000 - 0x9109cfff libz.1.dylib 	/usr/lib/libz.1.dylib
> 0x9109f000 - 0x91262fff com.apple.security 4.3 (25966)	/System/
> Library/Frameworks/Security.framework/Versions/A/Security
> 0x91365000 - 0x9136efff com.apple.DiskArbitration 2.1	/System/Library/
> Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration
> 0x91375000 - 0x9139cfff com.apple.SystemConfiguration 1.8.2	/System/
> Library/Frameworks/SystemConfiguration.framework/Versions/A/
> SystemConfiguration
> 0x913af000 - 0x913b7fff libgcc_s.1.dylib 	/usr/lib/libgcc_s.1.dylib
> 0x913bc000 - 0x913dcfff libmx.A.dylib 	/usr/lib/libmx.A.dylib
> 0x913e2000 - 0x913eafff libbsm.dylib 	/usr/lib/libbsm.dylib
> 0x913ee000 - 0x9146efff com.apple.audio.CoreAudio 3.0.2	/System/
> Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio
> 0x914ad000 - 0x914adfff com.apple.ApplicationServices 10.4 (???)	/
> System/Library/Frameworks/ApplicationServices.framework/Versions/A/
> ApplicationServices
> 0x914af000 - 0x914e7fff com.apple.AE 1.5 (297)	/System/Library/
> Frameworks/ApplicationServices.framework/Versions/A/Frameworks/
> AE.framework/Versions/A/AE
> 0x91502000 - 0x915cffff com.apple.ColorSync 4.4.4	/System/Library/
> Frameworks/ApplicationServices.framework/Versions/A/Frameworks/
> ColorSync.framework/Versions/A/ColorSync
> 0x91624000 - 0x916b7fff com.apple.print.framework.PrintCore 4.3
> (172.3)	/System/Library/Frameworks/ApplicationServices.framework/
> Versions/A/Frameworks/PrintCore.framework/Versions/A/PrintCore
> 0x916fe000 - 0x917bbfff com.apple.QD 3.8.18 (???)	/System/Library/
> Frameworks/ApplicationServices.framework/Versions/A/Frameworks/
> QD.framework/Versions/A/QD
> 0x917f9000 - 0x91857fff com.apple.HIServices 1.5.1 (???)	/System/
> Library/Frameworks/ApplicationServices.framework/Versions/A/
> Frameworks/HIServices.framework/Versions/A/HIServices
> 0x91885000 - 0x918a9fff com.apple.LangAnalysis 1.6.1	/System/Library/
> Frameworks/ApplicationServices.framework/Versions/A/Frameworks/
> LangAnalysis.framework/Versions/A/LangAnalysis
> 0x918bd000 - 0x918e2fff com.apple.FindByContent 1.5	/System/Library/
> Frameworks/ApplicationServices.framework/Versions/A/Frameworks/
> FindByContent.framework/Versions/A/FindByContent
> 0x918f5000 - 0x91937fff com.apple.LaunchServices 10.4.6 (168.3)	/
> System/Library/Frameworks/ApplicationServices.framework/Versions/A/
> Frameworks/LaunchServices.framework/Versions/A/LaunchServices
> 0x91953000 - 0x91967fff com.apple.speech.synthesis.framework 3.3	/
> System/Library/Frameworks/ApplicationServices.framework/Versions/A/
> Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis
> 0x91975000 - 0x919affff com.apple.ImageIO.framework 1.4.4	/System/
> Library/Frameworks/ApplicationServices.framework/Versions/A/
> Frameworks/ImageIO.framework/Versions/A/ImageIO
> 0x919c4000 - 0x91a8cfff libcrypto.0.9.7.dylib 	/usr/lib/libcrypto.
> 0.9.7.dylib
> 0x91ada000 - 0x91aeffff libcups.2.dylib 	/usr/lib/libcups.2.dylib
> 0x91af4000 - 0x91b11fff libJPEG.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/
> Versions/A/Resources/libJPEG.dylib
> 0x91b16000 - 0x91b85fff libJP2.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/
> Versions/A/Resources/libJP2.dylib
> 0x91b9c000 - 0x91ba0fff libGIF.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/
> Versions/A/Resources/libGIF.dylib
> 0x91ba2000 - 0x91bd3fff libRaw.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/
> Versions/A/Resources/libRaw.dylib
> 0x91bd7000 - 0x91c1afff libTIFF.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/
> Versions/A/Resources/libTIFF.dylib
> 0x91c21000 - 0x91c3afff libPng.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/
> Versions/A/Resources/libPng.dylib
> 0x91c3f000 - 0x91c42fff libRadiance.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/
> Versions/A/Resources/libRadiance.dylib
> 0x91c44000 - 0x91c44fff com.apple.Accelerate 1.1.1 (Accelerate
> 1.1.1)	/System/Library/Frameworks/Accelerate.framework/Versions/A/
> Accelerate
> 0x91c46000 - 0x91d30fff com.apple.vImage 2.0	/System/Library/
> Frameworks/Accelerate.framework/Versions/A/Frameworks/
> vImage.framework/Versions/A/vImage
> 0x91d38000 - 0x91d57fff com.apple.Accelerate.vecLib 3.1.1 (vecLib
> 3.1.1)	/System/Library/Frameworks/Accelerate.framework/Versions/A/
> Frameworks/vecLib.framework/Versions/A/vecLib
> 0x91dc3000 - 0x91e28fff libvMisc.dylib 	/System/Library/Frameworks/
> Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/
> A/libvMisc.dylib
> 0x91e32000 - 0x91ec4fff libvDSP.dylib 	/System/Library/Frameworks/
> Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/
> A/libvDSP.dylib
> 0x91ede000 - 0x9246efff libBLAS.dylib 	/System/Library/Frameworks/
> Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/
> A/libBLAS.dylib
> 0x924b6000 - 0x927c6fff libLAPACK.dylib 	/System/Library/Frameworks/
> Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/
> A/libLAPACK.dylib
> 0x927f3000 - 0x9287ffff com.apple.DesktopServices 1.3.1	/System/
> Library/PrivateFrameworks/DesktopServicesPriv.framework/Versions/A/
> DesktopServicesPriv
> 0x928c1000 - 0x92aebfff com.apple.Foundation 6.4.2 (567.21)	/System/
> Library/Frameworks/Foundation.framework/Versions/C/Foundation
> 0x92c09000 - 0x92ce7fff libxml2.2.dylib 	/usr/lib/libxml2.2.dylib
> 0x92d07000 - 0x92df5fff libiconv.2.dylib 	/usr/lib/libiconv.2.dylib
> 0x92e07000 - 0x92e25fff libGL.dylib 	/System/Library/Frameworks/
> OpenGL.framework/Versions/A/Libraries/libGL.dylib
> 0x92e30000 - 0x92e8afff libGLU.dylib 	/System/Library/Frameworks/
> OpenGL.framework/Versions/A/Libraries/libGLU.dylib
> 0x92ea8000 - 0x92ea8fff com.apple.Carbon 10.4 (???)	/System/Library/
> Frameworks/Carbon.framework/Versions/A/Carbon
> 0x92eaa000 - 0x92ebefff com.apple.ImageCapture 3.0	/System/Library/
> Frameworks/Carbon.framework/Versions/A/Frameworks/
> ImageCapture.framework/Versions/A/ImageCapture
> 0x92ed6000 - 0x92ee6fff com.apple.speech.recognition.framework 3.4	/
> System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> SpeechRecognition.framework/Versions/A/SpeechRecognition
> 0x92ef2000 - 0x92f07fff com.apple.securityhi 2.0 (203)	/System/
> Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> SecurityHI.framework/Versions/A/SecurityHI
> 0x92f19000 - 0x92fa0fff com.apple.ink.framework 101.2 (69)	/System/
> Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> Ink.framework/Versions/A/Ink
> 0x92fb4000 - 0x92fbffff com.apple.help 1.0.3 (32)	/System/Library/
> Frameworks/Carbon.framework/Versions/A/Frameworks/Help.framework/
> Versions/A/Help
> 0x92fc9000 - 0x92ff6fff com.apple.openscripting 1.2.4 (???)	/System/
> Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> OpenScripting.framework/Versions/A/OpenScripting
> 0x93010000 - 0x93020fff com.apple.print.framework.Print 5.0 (190.1)	/
> System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> Print.framework/Versions/A/Print
> 0x9302c000 - 0x93092fff com.apple.htmlrendering 1.1.2	/System/Library/
> Frameworks/Carbon.framework/Versions/A/Frameworks/
> HTMLRendering.framework/Versions/A/HTMLRendering
> 0x930c3000 - 0x93115fff com.apple.NavigationServices 3.4.2	/System/
> Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> NavigationServices.framework/Versions/A/NavigationServices
> 0x93141000 - 0x9315efff com.apple.audio.SoundManager 3.9	/System/
> Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> CarbonSound.framework/Versions/A/CarbonSound
> 0x93170000 - 0x9317dfff com.apple.CommonPanels 1.2.2 (73)	/System/
> Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> CommonPanels.framework/Versions/A/CommonPanels
> 0x93186000 - 0x93498fff com.apple.HIToolbox 1.4.5 (???)	/System/
> Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> HIToolbox.framework/Versions/A/HIToolbox
> 0x935e4000 - 0x935f0fff com.apple.opengl 1.4.7	/System/Library/
> Frameworks/OpenGL.framework/Versions/A/OpenGL
> 0x93681000 - 0x93681fff com.apple.Cocoa 6.4 (???)	/System/Library/
> Frameworks/Cocoa.framework/Versions/A/Cocoa
> 0x93683000 - 0x93cb6fff com.apple.AppKit 6.4.4 (824.33)	/System/
> Library/Frameworks/AppKit.framework/Versions/C/AppKit
> 0x94043000 - 0x940b3fff com.apple.CoreData 80	/System/Library/
> Frameworks/CoreData.framework/Versions/A/CoreData
> 0x940ec000 - 0x941b6fff com.apple.audio.toolbox.AudioToolbox 1.4.1	/
> System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox
> 0x9420a000 - 0x9420afff com.apple.audio.units.AudioUnit 1.4	/System/
> Library/Frameworks/AudioUnit.framework/Versions/A/AudioUnit
> 0x9420c000 - 0x94384fff com.apple.QuartzCore 1.4.5	/System/Library/
> Frameworks/QuartzCore.framework/Versions/A/QuartzCore
> 0x943ce000 - 0x9440bfff libsqlite3.0.dylib 	/usr/lib/libsqlite3.0.dylib
> 0x94413000 - 0x94463fff libGLImage.dylib 	/System/Library/Frameworks/
> OpenGL.framework/Versions/A/Libraries/libGLImage.dylib
> 0x94605000 - 0x94614fff libCGATS.A.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/
> CoreGraphics.framework/Versions/A/Resources/libCGATS.A.dylib
> 0x9461c000 - 0x94628fff libCSync.A.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/
> CoreGraphics.framework/Versions/A/Resources/libCSync.A.dylib
> 0x9466e000 - 0x94686fff libRIP.A.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/
> CoreGraphics.framework/Versions/A/Resources/libRIP.A.dylib
> 0x95663000 - 0x956effff com.apple.WebKit 417.9	/System/Library/
> Frameworks/WebKit.framework/Versions/A/WebKit
> 0x9574a000 - 0x9583ffff com.apple.JavaScriptCore 1.2 (417.8)	/System/
> Library/Frameworks/WebKit.framework/Versions/A/Frameworks/
> JavaScriptCore.framework/Versions/A/JavaScriptCore
> 0x9587b000 - 0x95b85fff com.apple.WebCore 417.17	/System/Library/
> Frameworks/WebKit.framework/Versions/A/Frameworks/WebCore.framework/
> Versions/A/WebCore
> 0x95d0c000 - 0x95d35fff libxslt.1.dylib 	/usr/lib/libxslt.1.dylib
> 0x95fdb000 - 0x95fddfff com.apple.ExceptionHandling 1.2 (???)	/System/
> Library/Frameworks/ExceptionHandling.framework/Versions/A/
> ExceptionHandling
> 0x96fba000 - 0x96fd9fff com.apple.vecLib 3.1.1 (vecLib 3.1.1)	/System/
> Library/Frameworks/vecLib.framework/Versions/A/vecLib
>
> Model: PowerMac7,2, BootROM 5.0.7f0, 2 processors, PowerPC 970
> (2.2), 2 GHz, 8 GB
> Graphics: ATI Radeon 9600 Pro, ATY,RV350, AGP, 64 MB
> Memory Module: DIMM0/J11, 1 GB, DDR SDRAM, PC3200U-30330
> Memory Module: DIMM1/J12, 1 GB, DDR SDRAM, PC3200U-30330
> Memory Module: DIMM2/J13, 1 GB, DDR SDRAM, PC3200U-30330
> Memory Module: DIMM3/J14, 1 GB, DDR SDRAM, PC3200U-30330
> Memory Module: DIMM4/J41, 1 GB, DDR SDRAM, PC3200U-30330
> Memory Module: DIMM5/J42, 1 GB, DDR SDRAM, PC3200U-30330
> Memory Module: DIMM6/J43, 1 GB, DDR SDRAM, PC3200U-30330
> Memory Module: DIMM7/J44, 1 GB, DDR SDRAM, PC3200U-30330
> Modem: MicroDash, UCJ, V.92, 1.0F, APPLE VERSION 2.6.6
> Network Service: Built-in Ethernet, Ethernet, en0
> Serial ATA Device: ST3160023AS, 149.05 GB
> Parallel ATA Device: PIONEER DVD-RW  DVR-106D,
> USB Device: Flash Disk, USB, Up to 480 Mb/sec, 500 mA
> USB Device: hp LaserJet 1300, Hewlett-Packard, Up to 12 Mb/sec, 500 mA
> USB Device: Hub, , Up to 12 Mb/sec, 500 mA
> USB Device: Hub in Apple Pro Keyboard, Mitsumi Electric, Up to 12 Mb/
> sec, 500 mA
> USB Device: Apple Pro Keyboard, Mitsumi Electric, Up to 12 Mb/sec,
> 250 mA
> USB Device: Studio Display, , Up to 1.5 Mb/sec, 500 mA
> USB Device: Apple Optical USB Mouse, Logitech, Up to 1.5 Mb/sec, 500 mA
>
>
> ###########################
> ###OLD from Hmisc crash:
> I keep getting a "segmentation fault" when trying to run areg.boot in
> the Hmisc package. I include below output from two different attempts.
> Thank you in advance for any help.
>
> Hank Stevens
>
> The following is taken from the example in the areg.boot
> documentation, run inside Aquamacs Emacs:
>
> > set.seed(171)  # to be able to reproduce example
> > x1 <- rnorm(200)
> > x2 <- runif(200)  # a variable that is really unrelated to y]
> > x3 <- factor(sample(c('cat','dog','cow'), 200,TRUE))  # also
> unrelated to y
> > y  <- exp(x1 + rnorm(200)/3)
> > f  <- areg.boot(y ~ x1 + x2 + x3, B=40)
> Loading required package: acepack
>
> Process R segmentation fault at Thu Feb 16 14:13:44 2006
>
> ############
> The following is the automated report following the crash from the
> same code in the R GUI:
>
> Date/Time:      2006-02-16 14:18:21.336 -0500
> OS Version:     10.4.4 (Build 8G32)
> Report Version: 3
>
> Command: R
> Path:    /Applications/R.app/Contents/MacOS/R
> Parent:  WindowServer [75]
>
> Version: 1.14 (2129)
>
> PID:    902
> Thread: 0
>
> Exception:  EXC_BAD_ACCESS (0x0001)
> Codes:      KERN_INVALID_ADDRESS (0x0001) at 0x63110304
>
> Thread 0 Crashed:
> 0   acepack.so               	0x0169a2c0 avas_ + 1752 (avas.f:112)
> 1   libR.dylib               	0x0024f498 do_dotCode + 1844 (dotcode.c:
> 1722)
> 2   libR.dylib               	0x00265cb0 Rf_eval + 1544 (eval.c:405)
> 3   libR.dylib               	0x00267ccc do_set + 224 (eval.c:1309)
> 4   libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
> 5   libR.dylib               	0x0026744c do_begin + 136 (eval.c:1058)
> 6   libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
> 7   libR.dylib               	0x00266150 Rf_applyClosure + 952
> (eval.c:576)
> 8   libR.dylib               	0x00265d2c Rf_eval + 1668 (eval.c:417)
> 9   libR.dylib               	0x00268678 do_eval + 700 (eval.c:1568)
> 10  libR.dylib               	0x0029acec do_internal + 392 (names.c:
> 1084)
> 11  libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
> 12  libR.dylib               	0x00266150 Rf_applyClosure + 952
> (eval.c:576)
> 13  libR.dylib               	0x00265d2c Rf_eval + 1668 (eval.c:417)
> 14  libR.dylib               	0x00267ccc do_set + 224 (eval.c:1309)
> 15  libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
> 16  libR.dylib               	0x0026744c do_begin + 136 (eval.c:1058)
> 17  libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
> 18  libR.dylib               	0x00266150 Rf_applyClosure + 952
> (eval.c:576)
> 19  libR.dylib               	0x00265d2c Rf_eval + 1668 (eval.c:417)
> 20  libR.dylib               	0x00267ccc do_set + 224 (eval.c:1309)
> 21  libR.dylib               	0x00265af4 Rf_eval + 1100 (eval.c:382)
> 22  org.R-project.R          	0x00015884 RGUI_ReplIteration + 500
> (crt.c:300)
> 23  org.R-project.R          	0x00015674 RGUI_ReplConsole + 148
> (crt.c:300)
> 24  org.R-project.R          	0x000155c8 run_REngineRmainloop + 156
> (crt.c:300)
> 25  org.R-project.R          	0x0000e56c -[REngine runREPL] + 76
> (crt.c:300)
> 26  com.apple.Foundation     	0x928e949c __NSFireTimer + 116
> 27  com.apple.CoreFoundation 	0x90770aec __CFRunLoopDoTimer + 184
> 28  com.apple.CoreFoundation 	0x9075d464 __CFRunLoopRun + 1680
> 29  com.apple.CoreFoundation 	0x9075ca18 CFRunLoopRunSpecific + 268
> 30  com.apple.HIToolbox      	0x9318e1e0 RunCurrentEventLoopInMode + 264
> 31  com.apple.HIToolbox      	0x9318d874 ReceiveNextEventCommon + 380
> 32  com.apple.HIToolbox      	0x9318d6e0
> BlockUntilNextEventMatchingListInMode + 96
> 33  com.apple.AppKit         	0x9368b104 _DPSNextEvent + 384
> 34  com.apple.AppKit         	0x9368adc8 -[NSApplication
> nextEventMatchingMask:untilDate:inMode:dequeue:] + 116
> 35  com.apple.AppKit         	0x9368730c -[NSApplication run] + 472
> 36  com.apple.AppKit         	0x93777e68 NSApplicationMain + 452
> 37  org.R-project.R          	0x00002eb0 _start + 392 (crt.c:267)
> 38  dyld                     	0x8fe01048 _dyld_start + 60
>
> Thread 1:
> 0   libSystem.B.dylib        	0x9001f20c select + 12
> 1   org.R-project.R          	0x00004674 -[RController readThread:] +
> 524 (crt.c:300)
> 2   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
> 3   libSystem.B.dylib        	0x9002b200 _pthread_body + 96
>
> Thread 2:
> 0   libSystem.B.dylib        	0x90049748 syscall_thread_switch + 8
> 1   com.apple.Foundation     	0x928fead0 +[NSThread sleepUntilDate:]
> + 152
> 2   com.apple.AppKit         	0x93728034 -[NSUIHeartBeat
> _heartBeatThread:] + 1100
> 3   com.apple.Foundation     	0x928e66d4 forkThreadForFunction + 108
> 4   libSystem.B.dylib        	0x9002b200 _pthread_body + 96
>
> Thread 0 crashed with PPC Thread State 64:
>   srr0: 0x000000000169a2c0 srr1:
> 0x100000000200f030                        vrsave: 0x0000000000000000
>     cr: 0x48022448          xer: 0x0000000020000000   lr:
> 0x000000000169a1c0  ctr: 0x0000000000000000
>     r0: 0x0000000000003840   r1: 0x00000000bfffa390   r2:
> 0x0000000006dd4e98   r3: 0x0000000000000000
>     r4: 0x0000000006dd4858   r5: 0x0000000006dd3598   r6:
> 0x0000000006dd3bd8   r7: 0x0000000006dd4218
>     r8: 0x0000000063110304   r9: 0x0000000007488658  r10:
> 0x00000000000000c7  r11: 0x000000000748a258
>    r12: 0x0000000006dd4858  r13: 0x0000000000000640  r14:
> 0x000000000748a418  r15: 0x00000000071ec9a8
>    r16: 0x0000000007488018  r17: 0x0000000000000004  r18:
> 0x0000000007489c18  r19: 0x00000000019fc7c0
>    r20: 0x0000000006dd1018  r21: 0x00000000000000c8  r22:
> 0x0000000000002580  r23: 0x0000000000003840
>    r24: 0x00000000000000c8  r25: 0x00000000000000c7  r26:
> 0x0000000000000640  r27: 0x0000000007489c18
>    r28: 0x000000000748b3b8  r29: 0x0000000000000098  r30:
> 0x0000000006dd4218  r31: 0x0000000001699bf0
>
> Binary Images Description:
>     0x1000 -    0x3bfff org.R-project.R 1.14 (2129)	/Applications/
> R.app/Contents/MacOS/R
>    0x55000 -    0x87fff libreadline.5.0.dylib 	/Library/Frameworks/
> R.framework/Resources/lib/libreadline.5.0.dylib
>    0x9b000 -    0xc6fff libncurses.5.dylib 	/usr/lib/libncurses.5.dylib
>   0x205000 -   0x398fff libR.dylib 	/Library/Frameworks/R.framework/
> Resources/lib/libR.dylib
> 0x1673000 -  0x1675fff Hmisc.so 	/Library/Frameworks/R.framework/
> Resources/library/Hmisc/libs/Hmisc.so
> 0x1697000 -  0x16a2fff acepack.so 	/Library/Frameworks/R.framework/
> Resources/library/acepack/libs/acepack.so
> 0x175a000 -  0x175dfff methods.so 	/Library/Frameworks/R.framework/
> Resources/library/methods/libs/methods.so
> 0x684b000 -  0x6861fff grDevices.so 	/Library/Frameworks/R.framework/
> Resources/library/grDevices/libs/grDevices.so
> 0x690d000 -  0x6950fff stats.so 	/Library/Frameworks/R.framework/
> Resources/library/stats/libs/stats.so
> 0x6a4d000 -  0x6a54fff internet.so 	/Library/Frameworks/R.framework/
> Resources/modules/internet.so
> 0x6d42000 -  0x6d43fff tools.so 	/Library/Frameworks/R.framework/
> Resources/library/tools/libs/tools.so
> 0x8fe00000 - 0x8fe54fff dyld 44.2	/usr/lib/dyld
> 0x90000000 - 0x901b3fff libSystem.B.dylib 	/usr/lib/libSystem.B.dylib
> 0x9020b000 - 0x9020ffff libmathCommon.A.dylib 	/usr/lib/system/
> libmathCommon.A.dylib
> 0x90211000 - 0x90264fff com.apple.CoreText 1.0.1 (???)	/System/
> Library/Frameworks/ApplicationServices.framework/Versions/A/
> Frameworks/CoreText.framework/Versions/A/CoreText
> 0x90291000 - 0x90342fff ATS 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ATS.framework/
> Versions/A/ATS
> 0x90371000 - 0x906aefff com.apple.CoreGraphics 1.256.30 (???)	/System/
> Library/Frameworks/ApplicationServices.framework/Versions/A/
> Frameworks/CoreGraphics.framework/Versions/A/CoreGraphics
> 0x9073a000 - 0x90813fff com.apple.CoreFoundation 6.4.4 (368.25)	/
> System/Library/Frameworks/CoreFoundation.framework/Versions/A/
> CoreFoundation
> 0x9085c000 - 0x9085cfff com.apple.CoreServices 10.4 (???)	/System/
> Library/Frameworks/CoreServices.framework/Versions/A/CoreServices
> 0x9085e000 - 0x90960fff libicucore.A.dylib 	/usr/lib/libicucore.A.dylib
> 0x909ba000 - 0x90a3efff libobjc.A.dylib 	/usr/lib/libobjc.A.dylib
> 0x90a68000 - 0x90ad6fff com.apple.framework.IOKit 1.4 (???)	/System/
> Library/Frameworks/IOKit.framework/Versions/A/IOKit
> 0x90aed000 - 0x90afffff libauto.dylib 	/usr/lib/libauto.dylib
> 0x90b06000 - 0x90ddefff com.apple.CoreServices.CarbonCore 681.3
> (671.2)	/System/Library/Frameworks/CoreServices.framework/Versions/A/
> Frameworks/CarbonCore.framework/Versions/A/CarbonCore
> 0x90e44000 - 0x90ec4fff com.apple.CoreServices.OSServices 4.1	/System/
> Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/
> OSServices.framework/Versions/A/OSServices
> 0x90f0e000 - 0x90f4ffff com.apple.CFNetwork 10.4.4 (129.9)	/System/
> Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/
> CFNetwork.framework/Versions/A/CFNetwork
> 0x90f64000 - 0x90f7cfff com.apple.WebServices 1.1.2 (1.1.0)	/System/
> Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/
> WebServicesCore.framework/Versions/A/WebServicesCore
> 0x90f8c000 - 0x9100dfff com.apple.SearchKit 1.0.5	/System/Library/
> Frameworks/CoreServices.framework/Versions/A/Frameworks/
> SearchKit.framework/Versions/A/SearchKit
> 0x91053000 - 0x9107dfff com.apple.Metadata 10.4.4 (121.34)	/System/
> Library/Frameworks/CoreServices.framework/Versions/A/Frameworks/
> Metadata.framework/Versions/A/Metadata
> 0x9108e000 - 0x9109cfff libz.1.dylib 	/usr/lib/libz.1.dylib
> 0x9109f000 - 0x91262fff com.apple.security 4.3 (25966)	/System/
> Library/Frameworks/Security.framework/Versions/A/Security
> 0x91365000 - 0x9136efff com.apple.DiskArbitration 2.1	/System/Library/
> Frameworks/DiskArbitration.framework/Versions/A/DiskArbitration
> 0x91375000 - 0x9139cfff com.apple.SystemConfiguration 1.8.2	/System/
> Library/Frameworks/SystemConfiguration.framework/Versions/A/
> SystemConfiguration
> 0x913af000 - 0x913b7fff libgcc_s.1.dylib 	/usr/lib/libgcc_s.1.dylib
> 0x913bc000 - 0x913dcfff libmx.A.dylib 	/usr/lib/libmx.A.dylib
> 0x913e2000 - 0x913eafff libbsm.dylib 	/usr/lib/libbsm.dylib
> 0x913ee000 - 0x9146efff com.apple.audio.CoreAudio 3.0.2	/System/
> Library/Frameworks/CoreAudio.framework/Versions/A/CoreAudio
> 0x914ad000 - 0x914adfff com.apple.ApplicationServices 10.4 (???)	/
> System/Library/Frameworks/ApplicationServices.framework/Versions/A/
> ApplicationServices
> 0x914af000 - 0x914e7fff com.apple.AE 1.5 (297)	/System/Library/
> Frameworks/ApplicationServices.framework/Versions/A/Frameworks/
> AE.framework/Versions/A/AE
> 0x91502000 - 0x915cffff com.apple.ColorSync 4.4.4	/System/Library/
> Frameworks/ApplicationServices.framework/Versions/A/Frameworks/
> ColorSync.framework/Versions/A/ColorSync
> 0x91624000 - 0x916b7fff com.apple.print.framework.PrintCore 4.3
> (172.3)	/System/Library/Frameworks/ApplicationServices.framework/
> Versions/A/Frameworks/PrintCore.framework/Versions/A/PrintCore
> 0x916fe000 - 0x917bbfff com.apple.QD 3.8.18 (???)	/System/Library/
> Frameworks/ApplicationServices.framework/Versions/A/Frameworks/
> QD.framework/Versions/A/QD
> 0x917f9000 - 0x91857fff com.apple.HIServices 1.5.1 (???)	/System/
> Library/Frameworks/ApplicationServices.framework/Versions/A/
> Frameworks/HIServices.framework/Versions/A/HIServices
> 0x91885000 - 0x918a9fff com.apple.LangAnalysis 1.6.1	/System/Library/
> Frameworks/ApplicationServices.framework/Versions/A/Frameworks/
> LangAnalysis.framework/Versions/A/LangAnalysis
> 0x918bd000 - 0x918e2fff com.apple.FindByContent 1.5	/System/Library/
> Frameworks/ApplicationServices.framework/Versions/A/Frameworks/
> FindByContent.framework/Versions/A/FindByContent
> 0x918f5000 - 0x91937fff com.apple.LaunchServices 10.4.6 (168.3)	/
> System/Library/Frameworks/ApplicationServices.framework/Versions/A/
> Frameworks/LaunchServices.framework/Versions/A/LaunchServices
> 0x91953000 - 0x91967fff com.apple.speech.synthesis.framework 3.3	/
> System/Library/Frameworks/ApplicationServices.framework/Versions/A/
> Frameworks/SpeechSynthesis.framework/Versions/A/SpeechSynthesis
> 0x91975000 - 0x919affff com.apple.ImageIO.framework 1.4.4	/System/
> Library/Frameworks/ApplicationServices.framework/Versions/A/
> Frameworks/ImageIO.framework/Versions/A/ImageIO
> 0x919c4000 - 0x91a8cfff libcrypto.0.9.7.dylib 	/usr/lib/libcrypto.
> 0.9.7.dylib
> 0x91ada000 - 0x91aeffff libcups.2.dylib 	/usr/lib/libcups.2.dylib
> 0x91af4000 - 0x91b11fff libJPEG.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/
> Versions/A/Resources/libJPEG.dylib
> 0x91b16000 - 0x91b85fff libJP2.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/
> Versions/A/Resources/libJP2.dylib
> 0x91b9c000 - 0x91ba0fff libGIF.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/
> Versions/A/Resources/libGIF.dylib
> 0x91ba2000 - 0x91bd3fff libRaw.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/
> Versions/A/Resources/libRaw.dylib
> 0x91bd7000 - 0x91c1afff libTIFF.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/
> Versions/A/Resources/libTIFF.dylib
> 0x91c21000 - 0x91c3afff libPng.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/
> Versions/A/Resources/libPng.dylib
> 0x91c3f000 - 0x91c42fff libRadiance.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/ImageIO.framework/
> Versions/A/Resources/libRadiance.dylib
> 0x91c44000 - 0x91c44fff com.apple.Accelerate 1.1.1 (Accelerate
> 1.1.1)	/System/Library/Frameworks/Accelerate.framework/Versions/A/
> Accelerate
> 0x91c46000 - 0x91d30fff com.apple.vImage 2.0	/System/Library/
> Frameworks/Accelerate.framework/Versions/A/Frameworks/
> vImage.framework/Versions/A/vImage
> 0x91d38000 - 0x91d57fff com.apple.Accelerate.vecLib 3.1.1 (vecLib
> 3.1.1)	/System/Library/Frameworks/Accelerate.framework/Versions/A/
> Frameworks/vecLib.framework/Versions/A/vecLib
> 0x91dc3000 - 0x91e28fff libvMisc.dylib 	/System/Library/Frameworks/
> Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/
> A/libvMisc.dylib
> 0x91e32000 - 0x91ec4fff libvDSP.dylib 	/System/Library/Frameworks/
> Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/
> A/libvDSP.dylib
> 0x91ede000 - 0x9246efff libBLAS.dylib 	/System/Library/Frameworks/
> Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/
> A/libBLAS.dylib
> 0x924b6000 - 0x927c6fff libLAPACK.dylib 	/System/Library/Frameworks/
> Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/
> A/libLAPACK.dylib
> 0x927f3000 - 0x9287ffff com.apple.DesktopServices 1.3.1	/System/
> Library/PrivateFrameworks/DesktopServicesPriv.framework/Versions/A/
> DesktopServicesPriv
> 0x928c1000 - 0x92aebfff com.apple.Foundation 6.4.2 (567.21)	/System/
> Library/Frameworks/Foundation.framework/Versions/C/Foundation
> 0x92c09000 - 0x92ce7fff libxml2.2.dylib 	/usr/lib/libxml2.2.dylib
> 0x92d07000 - 0x92df5fff libiconv.2.dylib 	/usr/lib/libiconv.2.dylib
> 0x92e07000 - 0x92e25fff libGL.dylib 	/System/Library/Frameworks/
> OpenGL.framework/Versions/A/Libraries/libGL.dylib
> 0x92e30000 - 0x92e8afff libGLU.dylib 	/System/Library/Frameworks/
> OpenGL.framework/Versions/A/Libraries/libGLU.dylib
> 0x92ea8000 - 0x92ea8fff com.apple.Carbon 10.4 (???)	/System/Library/
> Frameworks/Carbon.framework/Versions/A/Carbon
> 0x92eaa000 - 0x92ebefff com.apple.ImageCapture 3.0	/System/Library/
> Frameworks/Carbon.framework/Versions/A/Frameworks/
> ImageCapture.framework/Versions/A/ImageCapture
> 0x92ed6000 - 0x92ee6fff com.apple.speech.recognition.framework 3.4	/
> System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> SpeechRecognition.framework/Versions/A/SpeechRecognition
> 0x92ef2000 - 0x92f07fff com.apple.securityhi 2.0 (203)	/System/
> Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> SecurityHI.framework/Versions/A/SecurityHI
> 0x92f19000 - 0x92fa0fff com.apple.ink.framework 101.2 (69)	/System/
> Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> Ink.framework/Versions/A/Ink
> 0x92fb4000 - 0x92fbffff com.apple.help 1.0.3 (32)	/System/Library/
> Frameworks/Carbon.framework/Versions/A/Frameworks/Help.framework/
> Versions/A/Help
> 0x92fc9000 - 0x92ff6fff com.apple.openscripting 1.2.4 (???)	/System/
> Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> OpenScripting.framework/Versions/A/OpenScripting
> 0x93010000 - 0x93020fff com.apple.print.framework.Print 5.0 (190.1)	/
> System/Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> Print.framework/Versions/A/Print
> 0x9302c000 - 0x93092fff com.apple.htmlrendering 1.1.2	/System/Library/
> Frameworks/Carbon.framework/Versions/A/Frameworks/
> HTMLRendering.framework/Versions/A/HTMLRendering
> 0x930c3000 - 0x93115fff com.apple.NavigationServices 3.4.2	/System/
> Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> NavigationServices.framework/Versions/A/NavigationServices
> 0x93141000 - 0x9315efff com.apple.audio.SoundManager 3.9	/System/
> Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> CarbonSound.framework/Versions/A/CarbonSound
> 0x93170000 - 0x9317dfff com.apple.CommonPanels 1.2.2 (73)	/System/
> Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> CommonPanels.framework/Versions/A/CommonPanels
> 0x93186000 - 0x93498fff com.apple.HIToolbox 1.4.5 (???)	/System/
> Library/Frameworks/Carbon.framework/Versions/A/Frameworks/
> HIToolbox.framework/Versions/A/HIToolbox
> 0x935e4000 - 0x935f0fff com.apple.opengl 1.4.7	/System/Library/
> Frameworks/OpenGL.framework/Versions/A/OpenGL
> 0x93681000 - 0x93681fff com.apple.Cocoa 6.4 (???)	/System/Library/
> Frameworks/Cocoa.framework/Versions/A/Cocoa
> 0x93683000 - 0x93cb6fff com.apple.AppKit 6.4.4 (824.33)	/System/
> Library/Frameworks/AppKit.framework/Versions/C/AppKit
> 0x94043000 - 0x940b3fff com.apple.CoreData 80	/System/Library/
> Frameworks/CoreData.framework/Versions/A/CoreData
> 0x940ec000 - 0x941b6fff com.apple.audio.toolbox.AudioToolbox 1.4.1	/
> System/Library/Frameworks/AudioToolbox.framework/Versions/A/AudioToolbox
> 0x9420a000 - 0x9420afff com.apple.audio.units.AudioUnit 1.4	/System/
> Library/Frameworks/AudioUnit.framework/Versions/A/AudioUnit
> 0x9420c000 - 0x94384fff com.apple.QuartzCore 1.4.5	/System/Library/
> Frameworks/QuartzCore.framework/Versions/A/QuartzCore
> 0x943ce000 - 0x9440bfff libsqlite3.0.dylib 	/usr/lib/libsqlite3.0.dylib
> 0x94413000 - 0x94463fff libGLImage.dylib 	/System/Library/Frameworks/
> OpenGL.framework/Versions/A/Libraries/libGLImage.dylib
> 0x94605000 - 0x94614fff libCGATS.A.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/
> CoreGraphics.framework/Versions/A/Resources/libCGATS.A.dylib
> 0x9461c000 - 0x94628fff libCSync.A.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/
> CoreGraphics.framework/Versions/A/Resources/libCSync.A.dylib
> 0x9466e000 - 0x94686fff libRIP.A.dylib 	/System/Library/Frameworks/
> ApplicationServices.framework/Versions/A/Frameworks/
> CoreGraphics.framework/Versions/A/Resources/libRIP.A.dylib
> 0x95663000 - 0x956effff com.apple.WebKit 417.9	/System/Library/
> Frameworks/WebKit.framework/Versions/A/WebKit
> 0x9574a000 - 0x9583ffff com.apple.JavaScriptCore 1.2 (417.8)	/System/
> Library/Frameworks/WebKit.framework/Versions/A/Frameworks/
> JavaScriptCore.framework/Versions/A/JavaScriptCore
> 0x9587b000 - 0x95b85fff com.apple.WebCore 417.17	/System/Library/
> Frameworks/WebKit.framework/Versions/A/Frameworks/WebCore.framework/
> Versions/A/WebCore
> 0x95d0c000 - 0x95d35fff libxslt.1.dylib 	/usr/lib/libxslt.1.dylib
> 0x95fdb000 - 0x95fddfff com.apple.ExceptionHandling 1.2 (???)	/System/
> Library/Frameworks/ExceptionHandling.framework/Versions/A/
> ExceptionHandling
> 0x96fba000 - 0x96fd9fff com.apple.vecLib 3.1.1 (vecLib 3.1.1)	/System/
> Library/Frameworks/vecLib.framework/Versions/A/vecLib
>
> Model: PowerMac7,2, BootROM 5.0.7f0, 2 processors, PowerPC 970
> (2.2), 2 GHz, 8 GB
> Graphics: ATI Radeon 9600 Pro, ATY,RV350, AGP, 64 MB
> Memory Module: DIMM0/J11, 1 GB, DDR SDRAM, PC3200U-30330
> Memory Module: DIMM1/J12, 1 GB, DDR SDRAM, PC3200U-30330
> Memory Module: DIMM2/J13, 1 GB, DDR SDRAM, PC3200U-30330
> Memory Module: DIMM3/J14, 1 GB, DDR SDRAM, PC3200U-30330
> Memory Module: DIMM4/J41, 1 GB, DDR SDRAM, PC3200U-30330
> Memory Module: DIMM5/J42, 1 GB, DDR SDRAM, PC3200U-30330
> Memory Module: DIMM6/J43, 1 GB, DDR SDRAM, PC3200U-30330
> Memory Module: DIMM7/J44, 1 GB, DDR SDRAM, PC3200U-30330
> Modem: MicroDash, UCJ, V.92, 1.0F, APPLE VERSION 2.6.6
> Network Service: Built-in Ethernet, Ethernet, en0
> Serial ATA Device: ST3160023AS, 149.05 GB
> Parallel ATA Device: PIONEER DVD-RW  DVR-106D,
> USB Device: Flash Disk, USB, Up to 480 Mb/sec, 500 mA
> USB Device: hp LaserJet 1300, Hewlett-Packard, Up to 12 Mb/sec, 500 mA
> USB Device: Hub, , Up to 12 Mb/sec, 500 mA
> USB Device: Hub in Apple Pro Keyboard, Mitsumi Electric, Up to 12 Mb/
> sec, 500 mA
> USB Device: Apple Pro Keyboard, Mitsumi Electric, Up to 12 Mb/sec,
> 250 mA
> USB Device: Studio Display, , Up to 1.5 Mb/sec, 500 mA
> USB Device: Apple Optical USB Mouse, Logitech, Up to 1.5 Mb/sec, 500 mA
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Feb 16 23:05:57 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 16 Feb 2006 22:05:57 +0000 (GMT)
Subject: [R] Variance for Vector of Constants is Not Zero
In-Reply-To: <43F4EBDD.2030603@statistik.uni-dortmund.de>
References: <000601c6332f$519fbb60$0a00a8c0@Dell2003desktop>
	<43F4EBDD.2030603@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.64.0602162203220.23563@gannet.stats.ox.ac.uk>

This looks like the known problem, PR#1228.

It is possible to do better, but really users should be aware that 
numerical inaccuracies will occur, and not expect exact results from 
floating-point calculations.

On Thu, 16 Feb 2006, Uwe Ligges wrote:

> Barry Zajdlik wrote:
>
>> Hi All,
>>
>> An annoying but not critical problem I am having is that the variance of
>> a vector of constants is reported as > 0. I imagine there is a simple
>> workaround for the following but could not find it after having spent an
>> embarrassing amount of time.
>>
>> In Splus:
>>
>>
>>> x<-rep(0.02,10)
>>> var(x)
>>> 0
>>
>>
>> In R:
>>
>> x<-rep(0.02,10)
>> var(x)
>> 1.337451e-35
>
>
> Which version of R and which OS is this? I get 0 for both Linux and
> Windows with R-2.2.1.
> Anyway, 0.02 is not well representable and hence can be very well the
> cause for such a numerical inaccuracy.
>
>> I assumed the problem had to do with machine precision and suitably
>> modified .Machine$double.eps and .Machine$double.neg.eps which I thought
>> would fix the problem but without success. Any pointers to a solution
>> would be appreciated!
>
> Changing .Machine$double.eps does not help to calculate more accurate ...
>
> Uwe Ligges
>
>
>> Cheers,
>> Barry Zajdlik
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Thu Feb 16 23:28:19 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Feb 2006 23:28:19 +0100
Subject: [R] A concrete type I/III Sum of square problem
In-Reply-To: <43F4E3D0.3050000@gmail.com>
References: <43F41DA0.2010806@gmail.com> <x24q2z374c.fsf@viggo.kubism.ku.dk>
	<b20ae6290602160358m3ef96e52o4cea058208183042@mail.gmail.com>
	<x2mzgr1o60.fsf@viggo.kubism.ku.dk>
	<b20ae6290602160437w5e8dd10bu35649352cdf5aeee@mail.gmail.com>
	<43F4E3D0.3050000@gmail.com>
Message-ID: <x2irrfkkfw.fsf@turmalin.kubism.ku.dk>

Kjetil Brinchmann Halvorsen <kjetilbrinchmannhalvorsen at gmail.com> writes:

> If that language behind the barrier is Danish, there must be at least a
> few persons on the list who could benefit, so url's are welcome!

URLs??? We're talking ca. 1980 here.... Try "yellowing leaflets in a
corner of my basement". Hand-written or sent to a secretary who was
juggling the golf-ball typehead on an IBM Selectric typewriter to get
mathematical symbols.

Actually, some were in English and published in the Springer Lecture
Notes series - one set by Martin Jacobsen on counting processes and
another by S??ren Johansen on regression analysis topics. Some others
went on to become traditional textbooks (Asmussen, Lauritzen). 

The tradition continues. I see that the current set of Stat 1 notes by
Ernst Hansen are for sale in Naturfagsbogladen for 365 DKK, so you
might be able to get them to send you a set.
 
> Would'nt hurt with some Danish lecture notes in my bookshelf, although
> Piet Hein certainly have better grooks.

"Problems worthy of attack
will prove their worth by fighting back"

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From Galina_Glazko at URMC.Rochester.edu  Thu Feb 16 23:29:42 2006
From: Galina_Glazko at URMC.Rochester.edu (Glazko, Galina)
Date: Thu, 16 Feb 2006 17:29:42 -0500
Subject: [R] how to save the picture with  par(mfrow =  c(1, 3),
	pty='s') setti	ngs?
Message-ID: <1AFEC6AD98A0AA4D948216A768A1578C480DA6@e2k3ms3.urmc-sh.rochester.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/fc8b97c7/attachment.pl

From p.dalgaard at biostat.ku.dk  Thu Feb 16 23:43:27 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Feb 2006 23:43:27 +0100
Subject: [R] how to save the picture with  par(mfrow =  c(1, 3),
	pty='s') setti	ngs?
In-Reply-To: <1AFEC6AD98A0AA4D948216A768A1578C480DA6@e2k3ms3.urmc-sh.rochester.edu>
References: <1AFEC6AD98A0AA4D948216A768A1578C480DA6@e2k3ms3.urmc-sh.rochester.edu>
Message-ID: <x2accqlyb4.fsf@turmalin.kubism.ku.dk>

"Glazko, Galina" <Galina_Glazko at URMC.Rochester.edu> writes:

> Dear list,
> 
>  
> 
> I am trying to place 3 density functions in one Figure, 1 row by 3 columns:
> 
>  -------------------------------------------------------
> 
> op <- par(mfrow =  c(1, 3),pty='s')
> 
> pdf(file="Fig_den.pdf")
....
> -------------------------------------------------------
> 
> Somehow in file Fig_den.pdf these figures are on the separate pages.
> 
> However, I get exactly what I need in the console window.
> 
> Could someone please explain me what I am doing wrong when saving Figure in
> pdf?

You have par() before pdf(). Try it the other way around.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From lawrencc at debian.org  Fri Feb 17 00:07:17 2006
From: lawrencc at debian.org (Chris Lawrence)
Date: Thu, 16 Feb 2006 18:07:17 -0500
Subject: [R] Ubuntu and R
In-Reply-To: <43F4AED9.9070508@presby.edu>
References: <43F4AED9.9070508@presby.edu>
Message-ID: <e2e0e3d30602161507w66012143m7ce85f8e0ae37089@mail.gmail.com>

On 2/16/06, Clint Harshaw <charshaw at presby.edu> wrote:
> I've recently installed Ubuntu 5.10 on a desktop and need R installed,
> however, even after uncommenting the repos associated with universe,
> backports and multiverse, the packages available for Ubuntu are somewhat
> out of date:
>
> clint at simba:~$ apt-cache policy r-base r-base-core
> r-base:
>    Installed: (none)
>    Candidate: 2.1.1-1
>    Version table:
>       2.1.1-1 0
>          500 http://archive.ubuntu.com breezy/universe Packages
> r-base-core:
>    Installed: (none)
>    Candidate: 2.1.1-1
>    Version table:
>       2.1.1-1 0
>          500 http://archive.ubuntu.com breezy/universe Packages
>
> How should I edit my /etc/apt/sources.list so that I can proplery
> maintain a current version of R, and not break my system? I've searched
> the forums at Ubuntu, and there are several similar requests there, but
> no definitive answer that I found.
>
> What are other Ubuntu users here doing to keep their version of R fresh?

I suspect the 2.2.x packages from Debian testing and/or unstable would
run fine on breezy (I don't think there's been any libc6 changes that
would affect things); you could always rebuild from the Debianized
sources for Ubuntu if they don't.

You could use apt pins to make sure that only the R packages from
Debian are pulled in, if you want to use apt to keep it up to date
from Debian's archive.

Something like the following in /etc/apt/preferences should work:

Package: r-*
Pin: release o=Debian
Pin-Priority: 500

Package: *
Pin: release o=Debian
Pin-Priority: -1

Then add a line for the Debian mirror of your choice to
/etc/apt/sources.list, using either testing or unstable as your
release.


Chris



From ehlers at math.ucalgary.ca  Fri Feb 17 00:25:02 2006
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Thu, 16 Feb 2006 16:25:02 -0700
Subject: [R] Read a csv file
In-Reply-To: <20060216172918.93276.qmail@web33305.mail.mud.yahoo.com>
References: <20060216172918.93276.qmail@web33305.mail.mud.yahoo.com>
Message-ID: <43F509CE.9010303@math.ucalgary.ca>

Alexandra,
I haven't seen an answer to your query yet, so let me give it a shot.

First, I would not use R-illegal variable names (I assume you
want 2004-12-30, etc, to be your colnames). Try replacing them
with A,B,C, etc. And delete the empty string at the start.

Then I would make sure that there are linefeeds before "091529",
etc, which I assume are your rownames.

Finally, I would use
  temp <- read.csv("the csv adress")
which will default to header = TRUE, etc.

And if that works for you (it did for me) I would check the
402111632.57 value for possible error.

Here's an abbreviated version of your file that you can test:

A,B,C,D
091529,,40797616.82,40512773.17,40476284.73
091553,,24908681.74,24814586.13,
091571,,12931770.37,12868282.58,12893857.63
091502,,54336162.2999999,54151915.56,53822069.82
126731,,26059305.54,25972063.79,25893131.09


(BTW: I don't see how you were able to read the file that you
say you could read.)

Peter Ehlers


Alexandra R. M. de Almeida wrote:
> Dear R users,
>  
>  I have 14 csv's files that I want read in R, but one of them I can't read (the others 13 don't bring me any problem), and I don't know the problem. I will report the subject of the csv that I can't read, one csv that don't have any problem to read and the script that I use to try do it.
>  
>  CSV THAT I CAN'T READ:
>  *****************************
>        
> "",2004-12-30,2005-01-31,2005-02-28,2005-03-31,2005-04-29,2005-05-31,2005-06-30,2005-07-29,2005-08-31,2005-09-30,2005-10-31,2005-11-30,2005-12-29 091529,,40797616.82,40512773.17,40476284.73,40468557.11,,40437955.3400001,402111632.57,40571892.91,41019554.17,41318962.85,41318962.85, 091553,,24908681.74,24814586.13,,24803248.1,,24788910.05,24779821.29,24752903.91,24734282.39,24751532.07,24689283.78, 091571,,12931770.37,12868282.58,12893857.63,12876237.31,,12849139.41,12813254.18,12805919.98,12732718.7,12750495.16,12723562.95,12699066.57 091502,,54336162.2999999,54151915.56,53822069.82,53485186.1,,53032321.02,53489126.7,53366494.63,53207248.99,52967831.22,52722932.14,53837934.11 126731,,26059305.54,25972063.79,25893131.09,25848060.97,,25693215.97,25608393.62,25457521.32,25369733.73,25254490.23,25136883.19,25039982.16 
> 
>  ONE CSV THAT I CAN READ:
>  *********************************
>        
> "",2004-12-30,2005-01-31,2005-02-28,2005-03-31,2005-04-29,2005-05-31,2005-06-30,2005-07-29,2005-08-31,2005-09-30,2005-10-31,2005-11-30,2005-12-29 118214,6311825.94,5864148.03,5936471.99,5982408.92,5566445.03,5910110,5794680.19,6120773.65,6475695.29,5885656.58,5985008.26,6281223.36,6525932 085472,5770636.05,5637700.86,6128119.74,6271170.01,5613857.19,5094923.46,5057774.93,5353204.26,5460109.01,4731991.51,4847440.19,4532212.61,4237428.03 104231,22008340.08,21376713.76,24301057.75,24424624.42,23915639.41,21113516.09,21111603.24,21873741.8599999,21472396.03,22129567.97,22714447.7,21724517.05,22269561.09 097314,12467272.83,11100942.53,10430991.59,10107819.21,10555168.79,9637592.69,8638577.35,9524544.24,11182677.41,10308354.31,10320002.7,10147418.26,10771015.05 112925,3705133.34,3669389.26,3813722.34,3435817.19,3160329.46,2761649.16,2646939.68,3580033.72,3632261.84,3542923.69,3589498.79,3514793.31,4200379.2
>  086908,6437832.97,6736435.08,6892230.99,5672582.08,6449993.07,5846420.84,4556138.4,4880862.17,4884144.73,4452288.98,4636981.93,5879802.29,6088802.67 132616,1474667.34,1395177.12,1436053.42,1441598.54,470946.89,313116.01,298916.55,307676.31,307406.3,282800.37,284073.67,275566.91,293621.71 118222,6325973.54,5876657.44,5947610.25,5996347.04,5577943.77,5922848.59,5807960.45,6131649.57,6488493.15,5898377.27,5995776.67,6292922.68,6539705.86 097306,10760666.38,9491069.59,8806083.49,8472799.11,7942297.05,7264294.84,7343883.52,8197608.09,8738058.8,7902283.01,8233148.09,8153610.13,8659006.06 087319,1564390.36,1270270.63,1338154.93,1271605.04,1180629.89,1064629.09,1016657.74,3294460.82,3352300.22,805828.7,813883.24,788913.5,831963.24 103780,24756764.0300001,23452918.28,27679174.61,27923631.4,26402941.87,23999304.74,23222666.2000001,25423020.13,25628153.03,23171390.37,25056699.82,24319389.27,27290279.5699999 091456,354883.36,290394.31,291068.59,292289.11,274028.35,249202.14,237436.27
,,!
>  ,,,,
>  145033,,,,3534246.56,2828620.7,2107164.76,2499778.98,3501569.65,2822563.6,2719116.36,3125764.52,2463544.64,2624246.15 101621,1716754.85,1621736.71,1631089.63,1641090.36,2620765.11,2383375.75,1294499.03,1326391.79,2443147.47,2404299.33,2090743.45,1997445.59,2118693.45 
> 
>  SCRIPT:
>  *********
>        
> temp<-read.table("the csv adress",header=T,row.names=1,sep=",",dec=".")
> 
>  Thank's
>  
>  Alexandra Almeida
>  
>  
> 
> 
>   Alexandra R. Mendes de Almeida
> 
>                                                  
> 
> 
> 		
> ---------------------------------
> 
> Internet r??pida e gr??tis. Instale o discador agora!
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From tolga at coubros.com  Fri Feb 17 00:34:37 2006
From: tolga at coubros.com (Tolga Uzuner)
Date: Thu, 16 Feb 2006 23:34:37 -0000
Subject: [R] Problem with scoping a variable value
In-Reply-To: <971536df0602161224g63dd6d74vf9e852a611f6788f@mail.gmail.com>
Message-ID: <000901c63351$99f64920$4001a8c0@phd>

You are a star... that was it. Many thanks,
Tolga

-----Original Message-----
From: Gabor Grothendieck [mailto:ggrothendieck at gmail.com] 
Sent: 16 February 2006 20:24
To: Tolga Uzuner
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Problem with scoping a variable value

Without a reproducible example one can only guess but
perhaps the problem is not show but that you have a variable
F.  Try writing out F as FALSE.


On 2/16/06, Tolga Uzuner <tolga at coubros.com> wrote:
> Hi there,
>
> I have a function which has a variable called show as an input:
>
> richardson.grad <- function(func, x, d=0.01, eps=1e-4, r=6, show=F){
> # do some things
>   if(show) {
>
>        cat("\n","first order approximations", "\n")
>        print(a.mtr, 12)
>
>
>    }
> #do more things and return
> }
>
> The show variable is being used as a flag to show intermediate results.
>
> Interestingly enough, I have downloaded a package recently which defines
> the show variable as a function:
>
>  > show
> standardGeneric for "show" defined from package "methods"
>
> function (object)
> standardGeneric("show")
> <environment: 01676F7C>
> Methods may be defined for arguments: object
>
>  >
>
> Now, all of a sudden, the function I had defined earlier is scoping up
> to this new value, and is thus not working:
>
>  > richardson.grad(function(x) x^2,2)
> Error in if (show) { : argument is not interpretable as logical
>  >
>
> I could always redefine show in richardson.grad to be something else but
> something seems wrong: why is richardson.grad not looking up show's
> value in the  function ? How would I fix this ?
>
> Thanks in advance,
> Tolga
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From t_love at clear.net.nz  Fri Feb 17 01:02:47 2006
From: t_love at clear.net.nz (Tom Love)
Date: Fri, 17 Feb 2006 00:02:47 +0000
Subject: [R] RMySQL problem with more than 1 field
Message-ID: <42BAB680-93A4-4E57-AA4F-A84D49E84935@clear.net.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060217/fc72893e/attachment.pl

From spencer.graves at pdf.com  Fri Feb 17 02:12:31 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 16 Feb 2006 17:12:31 -0800
Subject: [R] lme, nlsList, nlsList.selfStart
In-Reply-To: <43EEE758.2050408@univ-fcomte.fr>
References: <43EEE758.2050408@univ-fcomte.fr>
Message-ID: <43F522FF.9060402@pdf.com>

	  Regarding the following:  	  	

 > mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
 > (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
 >      data=mydata,
 >      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
 > Error in model.frame(formula, rownames, variables, varnames, extras,
 > extranames,  :
 >         variable lengths differ

	  This example is NOT self contained and is entirely too complicated 
for me to try to replicate it myself in a reasonable period of time.  I 
will therefore ask one short question:  Are all the variable names in 
the "nlsList" call either columns of "mydata" or parameters to be 
estimated and therefore spelled out in "start"?  If I were you, I'd 
check this all very carefully, being especially careful about the 
distinction between "lCl" and "lC1", in particular.

	  If you'd like further help with this, I suggest you try to find the 
simplest possible example that generates problem you don't understand, 
then try to recast that example into one that is completely self 
contained, either a data set in the standard R or nlme distribution  or 
numbers that one can generate with a very few lines of code.  If you use 
random numbers, please "set.seed", to increase your confidence that 
someone else will see what you see.  (And please review the posting 
guide! "www.R-project.org/posting-guide.html".  Doing so may increase 
your chances of getting more useful information more quickly.)

	  spencer graves

Patrick Giraudoux wrote:

> Dear listers,
> 
> I am trying to fit a model using nlsList() using alternately a SSfol() 
> selfstart function or its developped equivalent formulae.
> 
> This preliminary trial works well
> 
> mydata<-groupedData(Conc~Tps|Organ,data=mydata)
> mymod1<-nls(Conc~SSfol(Dose,Tps,lKe,lKa,lCl),data=mydata)
> 
> as well as a developped form:
> 
> mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) * 
> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>     data=mydata,
>     start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>     )
> 
> However when trying to fit the model with nlsList, I get:
> 
> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) * 
> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>      data=mydata,
>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>      )
> Error in model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>         variable lengths differ
> Error in model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>         variable lengths differ
> Error in model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>         variable lengths differ
> 
> Or specifying  the grouping factor explicitely:
> 
> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) * 
> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe))|Organ,
>      data=mydata,
>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>      )
> 
> Error in model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>         variable lengths differ
> Error in model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>         variable lengths differ
> Error in model.frame(formula, rownames, variables, varnames, extras, 
> extranames,  :
>         variable lengths differ
> 
> 
> I cannot find out why the grouping factor cannot be used (it has the 
> same length as the other variables...)
> 
> Another strange thing occurs: in the example given in the help of 
> nlsList.selfstart, the following command works  well:
> 
>  fm1 <- nlsList(SSasympOff, CO2)
> 
> However its seemingly equivalent applied to the case above fails:
> 
> mymod4<-nlsList(SSfol,data=mydata)
> Error in eval(expr, envir, enclos) : object "input" not found
> Error in eval(expr, envir, enclos) : object "input" not found
> Error in eval(expr, envir, enclos) : object "input" not found
> 
> 
> Any hint/suggestion appreciated.
> 
> Kind regards,
> 
> Patrick Giraudoux
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From comtech.usa at gmail.com  Fri Feb 17 04:11:09 2006
From: comtech.usa at gmail.com (Michael)
Date: Thu, 16 Feb 2006 19:11:09 -0800
Subject: [R] How to change the number of bins in "hist" function?
Message-ID: <b1f16d9d0602161911y33d2343cx5093bf5649e264a9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/ae175f26/attachment.pl

From ronggui.huang at gmail.com  Fri Feb 17 04:52:21 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Fri, 17 Feb 2006 11:52:21 +0800
Subject: [R] How to change the number of bins in "hist" function?
In-Reply-To: <b1f16d9d0602161911y33d2343cx5093bf5649e264a9@mail.gmail.com>
References: <b1f16d9d0602161911y33d2343cx5093bf5649e264a9@mail.gmail.com>
Message-ID: <38b9f0350602161952r1dc44026x@mail.gmail.com>

?hist will tell you
...
breaks: one of:

             *  a vector giving the breakpoints between histogram
                cells,

             *  a single number giving the number of cells for the
                histogram,

             *  a character string naming an algorithm to compute the
                number of cells (see Details),

             *  a function to compute the number of cells.

          In the last three cases the number is a suggestion only.



2006/2/17, Michael <comtech.usa at gmail.com>:
> Hi all,
>
> I am doing histogram using the "hist" function. For some reason, the
> histogram does not look good... is there a way I can change the number of
> bins, and/or change the way that data gets binned... so that I can obtain a
> better looking histogram?
>
> Thanks a lot!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--

Deparment of Sociology
Fudan University



From spencer.graves at pdf.com  Fri Feb 17 05:25:56 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 16 Feb 2006 20:25:56 -0800
Subject: [R] nonlinear model:  pseudo-design matrix
In-Reply-To: <43F13B78.2050601@stats.waikato.ac.nz>
References: <43F13B78.2050601@stats.waikato.ac.nz>
Message-ID: <43F55054.30308@pdf.com>

	  There doubtless is a way to extract the gradient information you 
desire, but have you considered profiling instead?  Are you familiar 
with the distinction between intrinsic and parameter effects curvature? 
  In brief, part of the nonlinearities involved in nonlinear least 
squares are intrinsic to the problem, and part are due to the how the 
problem is parameterized.  If you change the parameterization, you 
change the parameter effects curvature, but the intrinsic curvature 
remains unchanged.  Roughly 30 years ago, Doug Bates and Don Watts 
reanalized a few dozen published nonlinear regression fits, and found 
that in all but perhaps one or two, the parameter effects were dominant 
and the intrinsic curvature was negligible.  See Bates and Watts (1988) 
Nonlinear Regression Analysis and Its Applications (Wiley) or Seber and 
Wild (1989) Nonlinear Regression (Wiley).

	  Bottom line:

	  1.  You will always get more accurate answers from profiling than 
from the Wald "pseudodesign matrix" approach.  Moreover, often the 
differences are dramatic.

	  2.  I just did RSiteSearch("profiling with nls").  The first hit was 
"http://finzi.psych.upenn.edu/R/library/stats/html/profile.nls.html". 
If this is not satisfactory, please explain why.

	  hope this helps.
	  spencer graves

Murray Jorgensen wrote:
> Given a nonlinear model formula and a set of values for all the
> parameters defining a point in parameter space, is there a neat way to
> extract the pseudodesign matrix of the model at the point? That is the
> matrix of partial derivatives of the fitted values w.r.t. the parameters
> evaluated at the point.
> 
> (I have figured out how to extract the gradient information from an nls 
> fitted model using the nlsModel part, but I wish to implement a score 
> test, so I need to be able to extract the information at points other 
> than the mle.)
> 
> Thanks, Murray Jorgensen



From comtech.usa at gmail.com  Fri Feb 17 06:44:09 2006
From: comtech.usa at gmail.com (Michael)
Date: Thu, 16 Feb 2006 21:44:09 -0800
Subject: [R] how to directly print plots to printer?
Message-ID: <b1f16d9d0602162144t37d91607r6640a241387bfb52@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/4da945f0/attachment.pl

From jari.oksanen at oulu.fi  Fri Feb 17 06:49:53 2006
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Fri, 17 Feb 2006 07:49:53 +0200
Subject: [R] Variance for Vector of Constants is Not Zero
In-Reply-To: <43F4EBDD.2030603@statistik.uni-dortmund.de>
References: <000601c6332f$519fbb60$0a00a8c0@Dell2003desktop>
	<43F4EBDD.2030603@statistik.uni-dortmund.de>
Message-ID: <1e7d4ed7d8c7ba85e78c7a59d9217c78@oulu.fi>


On 16 Feb 2006, at 23:17, Uwe Ligges wrote:

> Barry Zajdlik wrote:
>
>> Hi All,
>>
>> An annoying but not critical problem I am having is that the variance 
>> of
>> a vector of constants is reported as > 0. I imagine there is a simple
>> workaround for the following but could not find it after having spent 
>> an
>> embarrassing amount of time.
>>
>> In Splus:
>>
>>
>>> x<-rep(0.02,10)
>>> var(x)
>>> 0
>>
>>
>> In R:
>>
>> x<-rep(0.02,10)
>> var(x)
>> 1.337451e-35
>
>
> Which version of R and which OS is this? I get 0 for both Linux and
> Windows with R-2.2.1.
> Anyway, 0.02 is not well representable and hence can be very well the
> cause for such a numerical inaccuracy.
>
>> I assumed the problem had to do with machine precision and suitably
>> modified .Machine$double.eps and .Machine$double.neg.eps which I 
>> thought
>> would fix the problem but without success. Any pointers to a solution
>> would be appreciated!
>
> Changing .Machine$double.eps does not help to calculate more accurate 
> ...
>
> Uwe Ligges
>
>
>> Cheers,
>> Barry Zajdlik
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
--
Jari Oksanen, Oulu, Finland



From comtech.usa at gmail.com  Fri Feb 17 07:22:04 2006
From: comtech.usa at gmail.com (Michael)
Date: Thu, 16 Feb 2006 22:22:04 -0800
Subject: [R] how to directly print plots to printer?
In-Reply-To: <b1f16d9d0602162144t37d91607r6640a241387bfb52@mail.gmail.com>
References: <b1f16d9d0602162144t37d91607r6640a241387bfb52@mail.gmail.com>
Message-ID: <b1f16d9d0602162222j785934c4vc2e4cd8deaad7e6e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/a8fc8adf/attachment.pl

From phgrosjean at sciviews.org  Fri Feb 17 08:06:28 2006
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 17 Feb 2006 08:06:28 +0100
Subject: [R] Problem with scoping a variable value
In-Reply-To: <Pine.OSF.4.58.0602161508001.48504@wotan.mdacc.tmc.edu>
References: <43F4D4AA.3070905@coubros.com>
	<Pine.OSF.4.58.0602161508001.48504@wotan.mdacc.tmc.edu>
Message-ID: <43F575F4.2040100@sciviews.org>

Paul Roebuck wrote:
> On Thu, 16 Feb 2006, Tolga Uzuner wrote:
> 
> 
>>I have a function which has a variable called show as an input:
>>
>>richardson.grad <- function(func, x, d=0.01, eps=1e-4, r=6, show=F){
>># do some things
>>   if(show) {
>>
>>        cat("\n","first order approximations", "\n")
>>        print(a.mtr, 12)
>>
>>
>>    }
>>#do more things and return
>>}
>>
>>The show variable is being used as a flag to show intermediate results.
>>
>>Interestingly enough, I have downloaded a package recently which defines
>>the show variable as a function:
>>
>> > show
>>standardGeneric for "show" defined from package "methods"
>>
>>function (object)
>>standardGeneric("show")
>><environment: 01676F7C>
>>Methods may be defined for arguments: object
>>
>> >
>>
>>Now, all of a sudden, the function I had defined earlier is scoping up
>>to this new value, and is thus not working:
>>
>> > richardson.grad(function(x) x^2,2)
>>Error in if (show) { : argument is not interpretable as logical
>> >
>>
>>I could always redefine show in richardson.grad to be something else but
>>something seems wrong: why is richardson.grad not looking up show's
>>value in the  function ? How would I fix this ?
> 
> 
> You didn't spell out the logical value 'FALSE' which may
> be causing your problem. Consider this alternative also...
> 
> richardson.grad <- function(func,
>                             x,
>                             d = 0.01,
>                             eps = 1e-4,
>                             r = 6,
>                             verbose = getOption("verbose")) {
>     ## do some things
>     if (verbose) {
>          cat("\n", "first order approximations:", "\n")
>          print(a.mtr, 12)
>     }
>     ## do more things and return
> }

This is definitely the best solution, and Paul is right: you have to use 
  FALSE in preference to F (FALSE is a reserved word, F is not in R).

Now, you should know that show() *is* a generic function (it is the 
default method for S4 objects), and it is a very bad idea to use it as 
named argument for functions. I would suggest to use Paul's suggestion 
instead, or to change it as 'show.it = FALSE', as a minimum.
Best,

Philippe Grosjean



From ligges at statistik.uni-dortmund.de  Fri Feb 17 08:24:08 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 17 Feb 2006 08:24:08 +0100
Subject: [R] how to make plot output to JPG or GIF
In-Reply-To: <000001c63343$7f3fa260$de173981@revansx>
References: <000001c63343$7f3fa260$de173981@revansx>
Message-ID: <43F57A18.7070700@statistik.uni-dortmund.de>

Richard Evans wrote:
> Hello,
> 
> How does one write PLOT() commands that make individual graphic files of
> plots that are currently generated to the graphics output window of a
> session?
> 
> Currently, I have a chron-job that generates a new data input files once
> every hour. My goal is to then automatically run my "source.r" file with
> the plot commands which then automatically generates a web-ready graphic
> file in a folder for my server.


See ?bitmap

Uwe Ligges


> thanks!
> -revansx
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From maj at stats.waikato.ac.nz  Fri Feb 17 08:23:15 2006
From: maj at stats.waikato.ac.nz (Murray Jorgensen)
Date: Fri, 17 Feb 2006 20:23:15 +1300
Subject: [R] nonlinear model:  pseudo-design matrix
In-Reply-To: <43F55054.30308@pdf.com>
References: <43F13B78.2050601@stats.waikato.ac.nz> <43F55054.30308@pdf.com>
Message-ID: <43F579E3.6060408@stats.waikato.ac.nz>

Hi Spencer,

you were the only one to reply. Yes I am aware of the intrinsic / 
parameter effects distinction and the advantages of LR tests and 
profiling over Wald tests based on the local curvature of the 
loglikelihood surface at the larger of two models being compared. My 
situation is that I am comparing two nested models both of which have 
uncomfortably many parameters for the amount of data available. I am 
able to fit the smaller of the two models but not the larger. In this 
situation neither the the Wald nor the LR test is available to me but 
the score test (a.k.a. the Lagrange Multiplier test) is available to me 
because it is based on the loglikelihood gradient at the smaller model.

I have been able to carry out the test by extracting

X <- smaller.nls$m$gradient()

and obtaining the extra columns of X for the parameters in larger but 
not in smaller by numerical differentiation. It seems that there should 
be some way of obtaining the extra columns without recourse to numerical 
differentiation, though.

Cheers,  Murray Jorgensen

Spencer Graves wrote:
>       There doubtless is a way to extract the gradient information you 
> desire, but have you considered profiling instead?  Are you familiar 
> with the distinction between intrinsic and parameter effects curvature? 
>  In brief, part of the nonlinearities involved in nonlinear least 
> squares are intrinsic to the problem, and part are due to the how the 
> problem is parameterized.  If you change the parameterization, you 
> change the parameter effects curvature, but the intrinsic curvature 
> remains unchanged.  Roughly 30 years ago, Doug Bates and Don Watts 
> reanalized a few dozen published nonlinear regression fits, and found 
> that in all but perhaps one or two, the parameter effects were dominant 
> and the intrinsic curvature was negligible.  See Bates and Watts (1988) 
> Nonlinear Regression Analysis and Its Applications (Wiley) or Seber and 
> Wild (1989) Nonlinear Regression (Wiley).
> 
>       Bottom line:
> 
>       1.  You will always get more accurate answers from profiling than 
> from the Wald "pseudodesign matrix" approach.  Moreover, often the 
> differences are dramatic.
> 
>       2.  I just did RSiteSearch("profiling with nls").  The first hit 
> was 
> "http://finzi.psych.upenn.edu/R/library/stats/html/profile.nls.html". If 
> this is not satisfactory, please explain why.
> 
>       hope this helps.
>       spencer graves
> 
> Murray Jorgensen wrote:
>> Given a nonlinear model formula and a set of values for all the
>> parameters defining a point in parameter space, is there a neat way to
>> extract the pseudodesign matrix of the model at the point? That is the
>> matrix of partial derivatives of the fitted values w.r.t. the parameters
>> evaluated at the point.
>>
>> (I have figured out how to extract the gradient information from an 
>> nls fitted model using the nlsModel part, but I wish to implement a 
>> score test, so I need to be able to extract the information at points 
>> other than the mle.)
>>
>> Thanks, Murray Jorgensen

-- 
Dr Murray Jorgensen      http://www.stats.waikato.ac.nz/Staff/maj.html
Department of Statistics, University of Waikato, Hamilton, New Zealand
Email: maj at waikato.ac.nz                                Fax 7 838 4155
Phone  +64 7 838 4773 wk    Home +64 7 825 0441    Mobile 021 1395 862



From ligges at statistik.uni-dortmund.de  Fri Feb 17 08:28:47 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 17 Feb 2006 08:28:47 +0100
Subject: [R] how to directly print plots to printer?
In-Reply-To: <b1f16d9d0602162222j785934c4vc2e4cd8deaad7e6e@mail.gmail.com>
References: <b1f16d9d0602162144t37d91607r6640a241387bfb52@mail.gmail.com>
	<b1f16d9d0602162222j785934c4vc2e4cd8deaad7e6e@mail.gmail.com>
Message-ID: <43F57B2F.5030800@statistik.uni-dortmund.de>

Michael wrote:

> I am trying to follow the following code examples...
> 
> I am using the latest Rgui on Windows...
> 
> After I issued the first command "win.print()",
> 
> my R console hung completly...
> 
> What's wrong?
> 
> ----------------------------------------------

Works for me:


  win.print() # you have to confirm printing in the dialog
  plot(1:10)
  plot(1:20)
  dev.off() # 2 sheets are printed.

Uwe Ligges


> 
> On 2/16/06, Michael <comtech.usa at gmail.com> wrote:
> 
>>Hi all,
>>
>>How do I directly send plots to printer, instead of showing them on the
>>screen device?
>>
>>That's to say, with my current code for ploting on screen device, how to
>>modify a few lines to send automatically the plots to the printer?
>>
>>If that's not doable in R, could it be possible to automatically generate
>>a multi-page PDF file for all the plots, so that I can print one singal PDF
>>file to the printer manually later?
>>
>>thanks a lot!
>>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From m.blizinski at wit.edu.pl  Fri Feb 17 09:06:21 2006
From: m.blizinski at wit.edu.pl (Maciej =?iso-8859-2?Q?Blizi=F1ski?=)
Date: Fri, 17 Feb 2006 09:06:21 +0100
Subject: [R] Transforming results of the summary function
Message-ID: <1140163581.23615.19.camel@localhost.localnet>

Hi all,

I have a question about transforming the data from summary function.
Let's say I have a data frame like this:

> x = data.frame(a = c(rep("lev1", 5), rep("lev2", 5)), b = c(rnorm(5)+2, rnorm(5)))
> x
      a          b
1  lev1  1.5964765
2  lev1  2.2945609
3  lev1  3.5285787
4  lev1  1.4439838
5  lev1  2.2948826
6  lev2  1.7063506
7  lev2 -0.4042742
8  lev2 -1.6485337
9  lev2 -1.1163817
10 lev2 -0.2023246

I'd like to create quantiles for every level of the "a" column. Looking
into the documentation, I found the function "by" with which I can
perform the calculations...

> xs = by(x, x$a, function(x) summary(x$b))
> xs
x$a: lev1
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  1.444   1.596   2.295   2.232   2.295   3.529
------------------------------------------------------------
x$a: lev2
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
-1.6490 -1.1160 -0.4043 -0.3330 -0.2023  1.7060

...but I need them saved as a CSV file, so I'd like the result to have the form of:

level    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
 lev1   1.444   1.596   2.295   2.232   2.295   3.529
 lev2  -1.6490 -1.1160 -0.4043 -0.3330 -0.2023  1.7060

Can you give me any hints?

Regards,
Maciej

-- 
Maciej Blizi??ski <m.blizinski at wit.edu.pl>
http://automaciej.blogspot.com/



From ggrothendieck at gmail.com  Fri Feb 17 09:13:29 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 17 Feb 2006 03:13:29 -0500
Subject: [R] Transforming results of the summary function
In-Reply-To: <1140163581.23615.19.camel@localhost.localnet>
References: <1140163581.23615.19.camel@localhost.localnet>
Message-ID: <971536df0602170013h15e7a1a6kd488a7363ff5246@mail.gmail.com>

Try this:

do.call("rbind", xs)


On 2/17/06, Maciej Blizi??ski <m.blizinski at wit.edu.pl> wrote:
> Hi all,
>
> I have a question about transforming the data from summary function.
> Let's say I have a data frame like this:
>
> > x = data.frame(a = c(rep("lev1", 5), rep("lev2", 5)), b = c(rnorm(5)+2, rnorm(5)))
> > x
>      a          b
> 1  lev1  1.5964765
> 2  lev1  2.2945609
> 3  lev1  3.5285787
> 4  lev1  1.4439838
> 5  lev1  2.2948826
> 6  lev2  1.7063506
> 7  lev2 -0.4042742
> 8  lev2 -1.6485337
> 9  lev2 -1.1163817
> 10 lev2 -0.2023246
>
> I'd like to create quantiles for every level of the "a" column. Looking
> into the documentation, I found the function "by" with which I can
> perform the calculations...
>
> > xs = by(x, x$a, function(x) summary(x$b))
> > xs
> x$a: lev1
>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>  1.444   1.596   2.295   2.232   2.295   3.529
> ------------------------------------------------------------
> x$a: lev2
>   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
> -1.6490 -1.1160 -0.4043 -0.3330 -0.2023  1.7060
>
> ...but I need them saved as a CSV file, so I'd like the result to have the form of:
>
> level    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>  lev1   1.444   1.596   2.295   2.232   2.295   3.529
>  lev2  -1.6490 -1.1160 -0.4043 -0.3330 -0.2023  1.7060
>
> Can you give me any hints?
>
> Regards,
> Maciej
>
> --
> Maciej Blizi??ski <m.blizinski at wit.edu.pl>
> http://automaciej.blogspot.com/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From nshephard at gmail.com  Fri Feb 17 09:14:29 2006
From: nshephard at gmail.com (Neil Shephard)
Date: Fri, 17 Feb 2006 16:14:29 +0800
Subject: [R] Sweave - problems with underscores in variable names...
Message-ID: <31b34fca0602170014j69a7eff5l2b4da916d8870d1c@mail.gmail.com>

Thanks to all who replied, I opted to go with Patrick Drechsler
solution of installing the underscore.sty package for the time being
but may well end up trying Roger Bivand's solution if at any stage I
wish to include subscripts in my main text (which I can envisage).

Thanks for the rapid and useful responses,

Regards

Neil
--
"Once, adv. - Enough
Twice, adv. - Once too often"
 - Ambrose Bierce, The Devil's Dictionary

Email - nshephard at gmail.com
Website - http://slack.ser.man.ac.uk/
Blog - http://slack---line.blogspot.com/
Flickr - http://www.flickr.com/photos/slackline/



From sell_mirage_ne at hotmail.com  Fri Feb 17 09:53:32 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Fri, 17 Feb 2006 02:53:32 -0600
Subject: [R] creating 3-way tables for mantelhaen.test
Message-ID: <BAY110-F19EB7567F177E04BC87127C7F80@phx.gbl>

Hi R users
I have serveral binary variables (e.g., X1, X2, X3, X4, X5, X,6, and X7) and 
one continuous variable (e.g., Y1).

I combined these variables using data.frame()

mydata <- data.frame(X1,X2,X3,X4,X5,X6,X7,Y1)

after that, I sorted this data.frame

rank.by.Y1<-order(mydata[,8])
sorted.mydata<-mydata[rank.by.Y1,]

after that, I replaced Y1's values with values ranging from 1 to 10 ( 1 
represents the lowest group on Y1 and 10 presents the hight group on Y1). 
Now Y1 becomes a grouping variable.

What I like to do is to apply mantelhaen.test for each binary variable pair 
(e.g, X1 and X2, X1 and X3, X1 and X4, .... , X6 and X7)

In order to apply mantelhaen.test, a 3-dimensional contingency table is 
required.

Could you provide some advice on how to create a 3-dimensional contingency 
table (first dimension represents the first variable of  variable pair, 
second dimension the second variable of  variable  pair, and third dimension 
represents 1 to 10 ) and apply mantelhaen.test ?

I looked at arrary, xtabs, table commands but I couldn't figure out yet.

Thank you



From jacques.veslot at cirad.fr  Fri Feb 17 10:14:41 2006
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Fri, 17 Feb 2006 13:14:41 +0400
Subject: [R] creating 3-way tables for mantelhaen.test
In-Reply-To: <BAY110-F19EB7567F177E04BC87127C7F80@phx.gbl>
References: <BAY110-F19EB7567F177E04BC87127C7F80@phx.gbl>
Message-ID: <43F59401.90400@cirad.fr>


library(gtools)
index <- cbind(combinations(7,2),8)
lapply(as.data.frame(t(index)), function(x) 
mantelhaen.test(table(mydata[,x])))


Taka Matzmoto a ??crit :

>Hi R users
>I have serveral binary variables (e.g., X1, X2, X3, X4, X5, X,6, and X7) and 
>one continuous variable (e.g., Y1).
>
>I combined these variables using data.frame()
>
>mydata <- data.frame(X1,X2,X3,X4,X5,X6,X7,Y1)
>
>after that, I sorted this data.frame
>
>rank.by.Y1<-order(mydata[,8])
>sorted.mydata<-mydata[rank.by.Y1,]
>
>after that, I replaced Y1's values with values ranging from 1 to 10 ( 1 
>represents the lowest group on Y1 and 10 presents the hight group on Y1). 
>Now Y1 becomes a grouping variable.
>
>What I like to do is to apply mantelhaen.test for each binary variable pair 
>(e.g, X1 and X2, X1 and X3, X1 and X4, .... , X6 and X7)
>
>In order to apply mantelhaen.test, a 3-dimensional contingency table is 
>required.
>
>Could you provide some advice on how to create a 3-dimensional contingency 
>table (first dimension represents the first variable of  variable pair, 
>second dimension the second variable of  variable  pair, and third dimension 
>represents 1 to 10 ) and apply mantelhaen.test ?
>
>I looked at arrary, xtabs, table commands but I couldn't figure out yet.
>
>Thank you
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From patrick.giraudoux at univ-fcomte.fr  Fri Feb 17 10:47:21 2006
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Fri, 17 Feb 2006 10:47:21 +0100
Subject: [R] lme, nlsList, nlsList.selfStart
In-Reply-To: <43F522FF.9060402@pdf.com>
References: <43EEE758.2050408@univ-fcomte.fr> <43F522FF.9060402@pdf.com>
Message-ID: <43F59BA9.1010106@univ-fcomte.fr>

Spencer,

Thanks for the hint. I did not dare to bore people with the full data 
set and though that this kind of error may have been trivial and often 
encountered (so leading to a short answer), even though I did not see 
related messages on the r-help list. I already did the checks suggested 
before posting, and was aware of the possible confusion between 1 and l 
(actually the variable names were not given by myself).

It seems that the trouble comes when the grouping variable "Organ" is 
used. The best (?) I can do  is to dump the data.frame here below.

With this example, one can get exactly the same errors:

mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) * 
(exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
    data=mydata2,
    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
    )
   
... works well!!!

but we get then:

mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) * 
(exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)) | Organ,
    data=mydata2,
    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
    )
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
        variable lengths differ
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
        variable lengths differ
Error in model.frame(formula, rownames, variables, varnames, extras, 
extranames,  :
        variable lengths differ


 > mymod4<-nlsList(SSfol,data=mydata2)
Error in eval(expr, envir, enclos) : object "input" not found
Error in eval(expr, envir, enclos) : object "input" not found
Error in eval(expr, envir, enclos) : object "input" not found


Sorry and apologise for the inconvenience met,

Kind regards,

Patrick



# data.frame just to copy and past into R

"mydata2" <-
structure(list(Tps = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3,
3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,
6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9,
9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 14,
14, 14, 14, 14, 17, 17, 17, 17, 17, 20, 20, 20, 20, 25, 28, 29,
50, 50, 50, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4,
4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,
7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10,
10, 10, 11, 11, 11, 11, 11, 11, 14, 14, 14, 14, 14, 17, 17, 17,
17, 17, 20, 20, 20, 20, 25, 28, 29, 50, 50, 50, 136, 136, 136,
136, 136, 136, 136, 136, 136, 136, 1, 1, 1, 1, 1, 1, 2, 2, 2,
2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,
6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8,
8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,
11, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 20, 20, 20, 20,
25, 28, 29, 50, 50, 50, 136, 136, 136, 136, 136, 136, 136, 136,
136, 136), Conc = c(0, 0, 0, 0, 0, 0, 0, 0.807852503274902, 
0.204371494701886,
0.579222129993907, 0.989062273721619, 0, 1.11728297897571, 
1.41057428121324,
0.888883702851307, 1.259907624008, 1.45753269675829, 1.07077516747401,
0.843279379, 0, 0.763110069196737, 1.11297791434297, 1.10087763997637,
0.946929594501016, 1.33112168, 0.654041755, 0.694167499, 1.289548703,
1.117139864, 0.807196192, 0.720221376552025, 0.560082823, 0.476583438,
2.590855204, 0.51510972, 1.072946887, 0.537999938614396, 0.886684225905255,
0.630178116793598, 1.31534758842196, 1.33333958571746, 0.922032210748255,
0.429930193046174, 1.35881467717335, 0.790045927902363, 1.22484702570724,
0.808104508207897, 1.31185966817903, 1.51837686425553, 1.74105163638734,
1.80365598487402, 1.13240352674377, 1.50086243061644, 2.06355364280445,
0.439350890906039, 1.54692793444949, 1.78758216051046, 1.09043400023239,
0.811328376840514, 0.459192443530981, 0.695333473157298, 0.387995007681174,
0.784627063444921, 1.02282256375842, 0.382687104107726, 0.554290634950242,
0.130420456296453, 0.324194753224919, 0.31106140274139, 0.513473505828888,
0.878620320248701, 1.18404358659996, 0.136926837896477, 0, 0,
0.835588760032974, 0.558617235576616, 1.21002805866839, 0.769381068031404,
1.04514254228094, 0.373251847173678, 0.389005898972802, 0.183141006154896,
0.223596336820146, 0.315526423315647, 0.0930349732768131, 
0.169959185212759,
0.161878841748425, 0, 0.0483041009105874, 0, 0, 0, 0.0777005553478052,
0, 0.153175826795441, 0.0428171049833677, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 26.564295705327, 5.5893744508169, 7.22612934071834,
36.6563989567777, 0, 28.8967184437329, 28.4030370337251, 28.0886043901352,
26.1230935842208, 28.8895673910072, 42.6814210131968, 32.3555695551062,
0.76883326657205, 34.6159136622156, 38.329242204291, 56.4476583636484,
26.6249506083603, 31.3001451026823, 23.7339071829084, 23.3702284599355,
36.669903715038, 44.7377244306005, 31.2079335923023, 32.8613384312272,
29.4259634309146, 45.6112405959009, 48.1231689836687, 55.0037961570027,
32.9822316456421, 20.0382768189682, 26.0986380308655, 28.8915584506145,
28.7949023823068, 30.0278417498425, 58.8089779973569, 20.3602570111197,
29.6269605259023, 28.4404986724604, 30.2165182590977, 19.9204461889074,
31.1019196559556, 30.3847467747055, 36.8726911479995, 51.0618036275519,
23.5408013442579, 36.6948355347593, 27.4753860809429, 24.1341667099646,
27.5411488989643, 35.9021799354022, 19.7417897046158, 31.1403887303244,
46.1743622734049, 34.8235854891765, 22.1714704189293, 33.6805966894274,
35.2814908686112, 42.9767437212852, 38.1264997164547, 5.3651357974451,
42.8990434918385, 25.4908883698364, 25.99649502, 36.4958105490917,
40.8004126550705, 5.36867162116895, 0.00898476265269363, 0, 
27.6810997945798,
28.7918300045713, 45.7577183830352, 35.9276318604787, 34.9717618087238,
29.620354272564, 24.6537513599869, 13.5363982464958, 25.8289073574818,
12.0090406245759, 4.753436805, 11.849214652228, 8.41410147611612,
0, 1.80855352862552, 1.1987530031681, 1.01148025243171, 0.495675369574172,
1.62701127228732, 0, 16.6288242287241, 1.23656061354912, 0.323708776035328,
0, 0.566916625204436, 0, 0, 0, 0, 0, 0, 0, 2.53578781871283,
3.50083667130797, 0, 0.98049572179098, 0, 3.57129673217304, 
2.77298867949388,
2.12302645642669, 4.11923869203499, 4.69069462193674, 2.8698666062651,
2.05079837323067, 0.0602771574448942, 5.96454350250626, 2.26267114439802,
3.06911285674854, 2.04233129537404, 2.62181873844029, 1.51813653072598,
1.46193772981073, 2.69864635755833, 3.44016493913122, 2.50834832469627,
3.48170744166168, 1.00637581555435, 1.67065398473081, 4.18855363095027,
3.39649762611015, 1.72804613460423, 1.40053679329531, 2.37032387724109,
3.19332545080983, 2.49474373894248, 2.17800931288708, 2.7601484443213,
0.91266104095844, 1.93485048639199, 1.19692593420788, 1.79537330666258,
2.14020930767983, 3.0122526724942, 2.81112226980754, 3.54890724398174,
3.01022926452999, 2.38263226710738, 3.53569238341869, 3.47869329713911,
0.679333339820719, 2.4764260756438, 3.82615100065366, 2.20449890383871,
1.371303113329, 1.2427787019995, 1.73319133880954, 0.391268883238408,
1.73610193837913, 2.68494324646718, 1.77065393606844, 1.45079980147062,
0.763775702906329, 0.98566725668627, 0.37838763208699, 0.841811919286804,
1.46436462204795, 1.98409602726, 0.507005887891038, 0.465515668274195,
0, 1.873365675227, 1.69023864630648, 2.65530855919137, 2.34392199908302,
1.61917643594837, 1.05165934333345, 0.564642823436471, 0.121621029620328,
0.515007625737071, 0.524345809084086, 0.130898614090571, 0.332427740242623,
0.110214989555118, 0, 0.128642193589, 0.119407067173878, 0.128926224027295,
0.0622331866694357, 0.215645168287442, 0, 0.859343941945178,
0.0500810300696456, 0, 0, 0.0628746592609754), Organ = 
structure(as.integer(c(1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3,
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2)), .Label = c("Carc", "TD", "Foie"), class = c("ordered",
"factor"))), .Names = c("Tps", "Conc", "Organ"), row.names = c("1",
"2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
"14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24",
"25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35",
"36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46",
"47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57",
"58", "59", "60", "61", "62", "63", "64", "65", "66", "67", "68",
"69", "70", "71", "72", "73", "74", "75", "76", "77", "78", "79",
"80", "81", "82", "83", "84", "85", "86", "87", "88", "89", "90",
"91", "92", "93", "94", "95", "96", "97", "98", "99", "100",
"101", "102", "103", "104", "105", "106", "107", "108", "109",
"110", "111", "112", "113", "114", "115", "116", "117", "118",
"119", "120", "121", "122", "123", "124", "125", "126", "127",
"128", "129", "130", "131", "132", "133", "134", "135", "136",
"137", "138", "139", "140", "141", "142", "143", "144", "145",
"146", "147", "148", "149", "150", "151", "152", "153", "154",
"155", "156", "157", "158", "159", "160", "161", "162", "163",
"164", "165", "166", "167", "168", "169", "170", "171", "172",
"173", "174", "175", "176", "177", "178", "179", "180", "181",
"182", "183", "184", "185", "186", "187", "188", "189", "190",
"191", "192", "193", "194", "195", "196", "197", "198", "199",
"200", "201", "202", "203", "204", "205", "206", "207", "208",
"209", "210", "211", "212", "213", "214", "215", "216", "217",
"218", "219", "220", "221", "222", "223", "224", "225", "226",
"227", "228", "229", "230", "231", "232", "233", "234", "235",
"236", "237", "238", "239", "240", "241", "242", "243", "244",
"245", "246", "247", "248", "249", "250", "251", "252", "253",
"254", "255", "256", "257", "258", "259", "260", "261", "262",
"263", "264", "265", "266", "267", "268", "269", "270", "271",
"272", "273", "274", "275", "276", "277", "278", "279", "280",
"281", "282", "283", "284", "285", "286", "287", "288", "289",
"290", "291", "292", "293", "294", "295", "296", "297", "298",
"299", "300"), class = c("nfnGroupedData", "nfGroupedData", "groupedData",
"data.frame"), formula = quote(Conc ~ Tps | Organ), FUN = function (x)
max(x, na.rm = TRUE), order.groups = TRUE)




Spencer Graves a ??crit :
>       Regarding the following:           
>
> > mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
> > (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
> >      data=mydata,
> >      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
> > Error in model.frame(formula, rownames, variables, varnames, extras,
> > extranames,  :
> >         variable lengths differ
>
>       This example is NOT self contained and is entirely too 
> complicated for me to try to replicate it myself in a reasonable 
> period of time.  I will therefore ask one short question:  Are all the 
> variable names in the "nlsList" call either columns of "mydata" or 
> parameters to be estimated and therefore spelled out in "start"?  If I 
> were you, I'd check this all very carefully, being especially careful 
> about the distinction between "lCl" and "lC1", in particular.
>
>       If you'd like further help with this, I suggest you try to find 
> the simplest possible example that generates problem you don't 
> understand, then try to recast that example into one that is 
> completely self contained, either a data set in the standard R or nlme 
> distribution  or numbers that one can generate with a very few lines 
> of code.  If you use random numbers, please "set.seed", to increase 
> your confidence that someone else will see what you see.  (And please 
> review the posting guide! "www.R-project.org/posting-guide.html".  
> Doing so may increase your chances of getting more useful information 
> more quickly.)
>
>       spencer graves
>
> Patrick Giraudoux wrote:
>
>> Dear listers,
>>
>> I am trying to fit a model using nlsList() using alternately a 
>> SSfol() selfstart function or its developped equivalent formulae.
>>
>> This preliminary trial works well
>>
>> mydata<-groupedData(Conc~Tps|Organ,data=mydata)
>> mymod1<-nls(Conc~SSfol(Dose,Tps,lKe,lKa,lCl),data=mydata)
>>
>> as well as a developped form:
>>
>> mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) * 
>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>     data=mydata,
>>     start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>     )
>>
>> However when trying to fit the model with nlsList, I get:
>>
>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) * 
>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>      data=mydata,
>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>      )
>> Error in model.frame(formula, rownames, variables, varnames, extras, 
>> extranames,  :
>>         variable lengths differ
>> Error in model.frame(formula, rownames, variables, varnames, extras, 
>> extranames,  :
>>         variable lengths differ
>> Error in model.frame(formula, rownames, variables, varnames, extras, 
>> extranames,  :
>>         variable lengths differ
>>
>> Or specifying  the grouping factor explicitely:
>>
>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) * 
>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe))|Organ,
>>      data=mydata,
>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>      )
>>
>> Error in model.frame(formula, rownames, variables, varnames, extras, 
>> extranames,  :
>>         variable lengths differ
>> Error in model.frame(formula, rownames, variables, varnames, extras, 
>> extranames,  :
>>         variable lengths differ
>> Error in model.frame(formula, rownames, variables, varnames, extras, 
>> extranames,  :
>>         variable lengths differ
>>
>>
>> I cannot find out why the grouping factor cannot be used (it has the 
>> same length as the other variables...)
>>
>> Another strange thing occurs: in the example given in the help of 
>> nlsList.selfstart, the following command works  well:
>>
>>  fm1 <- nlsList(SSasympOff, CO2)
>>
>> However its seemingly equivalent applied to the case above fails:
>>
>> mymod4<-nlsList(SSfol,data=mydata)
>> Error in eval(expr, envir, enclos) : object "input" not found
>> Error in eval(expr, envir, enclos) : object "input" not found
>> Error in eval(expr, envir, enclos) : object "input" not found
>>
>>
>> Any hint/suggestion appreciated.
>>
>> Kind regards,
>>
>> Patrick Giraudoux
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>



From ehlers at math.ucalgary.ca  Fri Feb 17 10:50:11 2006
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Fri, 17 Feb 2006 02:50:11 -0700
Subject: [R] creating 3-way tables for mantelhaen.test
In-Reply-To: <BAY110-F19EB7567F177E04BC87127C7F80@phx.gbl>
References: <BAY110-F19EB7567F177E04BC87127C7F80@phx.gbl>
Message-ID: <43F59C53.80503@math.ucalgary.ca>

Taka,

Maybe you did something strange when you "replaced Y1's values ....".
Is the result a 10-level factor?
The following works for me.

x1 <- sample(c("y", "n"), 100, replace = TRUE)
x2 <- sample(c("a", "b"), 100, replace = TRUE)
y  <- sample(1:10, 100, replace = TRUE)
y  <- factor(y)

dat <- data.frame(x1, x2, y)
dat.xt <- xtabs(~ x1 + x2 + y, data = dat)
mantelhaen.test(dat.xt)

Peter Ehlers


Taka Matzmoto wrote:

> Hi R users
> I have serveral binary variables (e.g., X1, X2, X3, X4, X5, X,6, and X7) and 
> one continuous variable (e.g., Y1).
> 
> I combined these variables using data.frame()
> 
> mydata <- data.frame(X1,X2,X3,X4,X5,X6,X7,Y1)
> 
> after that, I sorted this data.frame
> 
> rank.by.Y1<-order(mydata[,8])
> sorted.mydata<-mydata[rank.by.Y1,]
> 
> after that, I replaced Y1's values with values ranging from 1 to 10 ( 1 
> represents the lowest group on Y1 and 10 presents the hight group on Y1). 
> Now Y1 becomes a grouping variable.
> 
> What I like to do is to apply mantelhaen.test for each binary variable pair 
> (e.g, X1 and X2, X1 and X3, X1 and X4, .... , X6 and X7)
> 
> In order to apply mantelhaen.test, a 3-dimensional contingency table is 
> required.
> 
> Could you provide some advice on how to create a 3-dimensional contingency 
> table (first dimension represents the first variable of  variable pair, 
> second dimension the second variable of  variable  pair, and third dimension 
> represents 1 to 10 ) and apply mantelhaen.test ?
> 
> I looked at arrary, xtabs, table commands but I couldn't figure out yet.
> 
> Thank you
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From hb at maths.lth.se  Fri Feb 17 10:55:11 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Fri, 17 Feb 2006 10:55:11 +0100
Subject: [R] how to clear screen in R-console?
In-Reply-To: <b1f16d9d0602161222g6f72e36cg93aba58b11fd2a53@mail.gmail.com>
References: <b1f16d9d0602160233r1a95ba81qd81583b047b7f2af@mail.gmail.com>
	<43F45928.8010902@web.de>
	<b1f16d9d0602160322m6cb6a484mfd6aee2bbf2b758b@mail.gmail.com>
	<59d7961d0602160459t493de978na04494e207460e55@mail.gmail.com>
	<b1f16d9d0602161222g6f72e36cg93aba58b11fd2a53@mail.gmail.com>
Message-ID: <59d7961d0602170155s500c2f0cl46e7216f43e06e6e@mail.gmail.com>

On 2/16/06, Michael <comtech.usa at gmail.com> wrote:
> I am actually using Rgui on Windows...
>
> What can I do?

The only way I can think of is to do write a lot of empty lines, e.g.

cat(rep("\n",64))

You will not get the prompt at the upper-left corner.   Better than nothing.

/Henrik

> There is no way to programmatically clear screen?
>
> On 2/16/06, Henrik Bengtsson <hb at maths.lth.se> wrote:
> >
> > Hi,
> >
> > depends on what type of terminal you are running.  For example, if you
> > run R in a VT100 terminal, you can try
> >
> > cat("The following VT100 escape sequence will clear the screen on a
> > VT100 terminal\n")
> > cat("\033[2J")  # <ESC>[2J  == Clear Screen
> > cat("If the screen was cleared you should only see this sentence.\n")
> >
> > i.e.
> >
> > vt100ClearScreen <- function(...) cat("\033[2J")
> >
> > Some links:
> > http://www.fh-jena.de/~gmueller/Kurs_halle/esc_vt100.html
> > http://en.wikipedia.org/wiki/VT100
> >
> > Note, this is not guaranteed to work everywhere.  To the best of my
> > knowledge, you will not be able to do anything like this in Rgui on
> > Windows.
> >
> > Cheers
> >
> > Henrik
> >
> >
> > On 2/16/06, Michael <comtech.usa at gmail.com> wrote:
> > > Any funcation that is callable from my program, instead of pressing
> > keys?
> > >
> > > Thanks a lot!
> > >
> > >
> > > On 2/16/06, Christian Schulz <ozric at web.de> wrote:
> > > >
> > > > ctrl - e & l
> > > >
> > > > >HI all,
> > > > >
> > > > >How to clear the screen in R-console?
> > > > >
> > > > >Thanks a lot@!
> > > > >
> > > > >       [[alternative HTML version deleted]]
> > > > >
> > > > >______________________________________________
> > > > >R-help at stat.math.ethz.ch mailing list
> > > > >https://stat.ethz.ch/mailman/listinfo/r-help
> > > > >PLEASE do read the posting guide!
> > > > http://www.R-project.org/posting-guide.html
> > > > >
> > > > >
> > > > >
> > > >
> > > >
> > > >
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Fri Feb 17 11:43:26 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 17 Feb 2006 10:43:26 +0000 (GMT)
Subject: [R] lme, nlsList, nlsList.selfStart
In-Reply-To: <43F59BA9.1010106@univ-fcomte.fr>
References: <43EEE758.2050408@univ-fcomte.fr> <43F522FF.9060402@pdf.com>
	<43F59BA9.1010106@univ-fcomte.fr>
Message-ID: <Pine.LNX.4.64.0602171040190.13399@gannet.stats.ox.ac.uk>

We don't have Dose, and I think that is where the error lies.  If Dose 
were part of mydata2, this is likely to work, but otherwise it is Dose 
which has the wrong length.

?nlsList says

     data: a data frame in which to interpret the variables named in
           'model'.

and it means it: you must get all the variables from there.


On Fri, 17 Feb 2006, Patrick Giraudoux wrote:

> Spencer,
>
> Thanks for the hint. I did not dare to bore people with the full data
> set and though that this kind of error may have been trivial and often
> encountered (so leading to a short answer), even though I did not see
> related messages on the r-help list. I already did the checks suggested
> before posting, and was aware of the possible confusion between 1 and l
> (actually the variable names were not given by myself).
>
> It seems that the trouble comes when the grouping variable "Organ" is
> used. The best (?) I can do  is to dump the data.frame here below.
>
> With this example, one can get exactly the same errors:
>
> mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) *
> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>    data=mydata2,
>    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>    )
>
> ... works well!!!
>
> but we get then:
>
> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)) | Organ,
>    data=mydata2,
>    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>    )
> Error in model.frame(formula, rownames, variables, varnames, extras,
> extranames,  :
>        variable lengths differ
> Error in model.frame(formula, rownames, variables, varnames, extras,
> extranames,  :
>        variable lengths differ
> Error in model.frame(formula, rownames, variables, varnames, extras,
> extranames,  :
>        variable lengths differ
>
>
> > mymod4<-nlsList(SSfol,data=mydata2)
> Error in eval(expr, envir, enclos) : object "input" not found
> Error in eval(expr, envir, enclos) : object "input" not found
> Error in eval(expr, envir, enclos) : object "input" not found
>
>
> Sorry and apologise for the inconvenience met,
>
> Kind regards,
>
> Patrick
>
>
>
> # data.frame just to copy and past into R
>
> "mydata2" <-
> structure(list(Tps = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3,
> 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,
> 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9,
> 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 14,
> 14, 14, 14, 14, 17, 17, 17, 17, 17, 20, 20, 20, 20, 25, 28, 29,
> 50, 50, 50, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4,
> 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,
> 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10,
> 10, 10, 11, 11, 11, 11, 11, 11, 14, 14, 14, 14, 14, 17, 17, 17,
> 17, 17, 20, 20, 20, 20, 25, 28, 29, 50, 50, 50, 136, 136, 136,
> 136, 136, 136, 136, 136, 136, 136, 1, 1, 1, 1, 1, 1, 2, 2, 2,
> 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,
> 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8,
> 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,
> 11, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 20, 20, 20, 20,
> 25, 28, 29, 50, 50, 50, 136, 136, 136, 136, 136, 136, 136, 136,
> 136, 136), Conc = c(0, 0, 0, 0, 0, 0, 0, 0.807852503274902,
> 0.204371494701886,
> 0.579222129993907, 0.989062273721619, 0, 1.11728297897571,
> 1.41057428121324,
> 0.888883702851307, 1.259907624008, 1.45753269675829, 1.07077516747401,
> 0.843279379, 0, 0.763110069196737, 1.11297791434297, 1.10087763997637,
> 0.946929594501016, 1.33112168, 0.654041755, 0.694167499, 1.289548703,
> 1.117139864, 0.807196192, 0.720221376552025, 0.560082823, 0.476583438,
> 2.590855204, 0.51510972, 1.072946887, 0.537999938614396, 0.886684225905255,
> 0.630178116793598, 1.31534758842196, 1.33333958571746, 0.922032210748255,
> 0.429930193046174, 1.35881467717335, 0.790045927902363, 1.22484702570724,
> 0.808104508207897, 1.31185966817903, 1.51837686425553, 1.74105163638734,
> 1.80365598487402, 1.13240352674377, 1.50086243061644, 2.06355364280445,
> 0.439350890906039, 1.54692793444949, 1.78758216051046, 1.09043400023239,
> 0.811328376840514, 0.459192443530981, 0.695333473157298, 0.387995007681174,
> 0.784627063444921, 1.02282256375842, 0.382687104107726, 0.554290634950242,
> 0.130420456296453, 0.324194753224919, 0.31106140274139, 0.513473505828888,
> 0.878620320248701, 1.18404358659996, 0.136926837896477, 0, 0,
> 0.835588760032974, 0.558617235576616, 1.21002805866839, 0.769381068031404,
> 1.04514254228094, 0.373251847173678, 0.389005898972802, 0.183141006154896,
> 0.223596336820146, 0.315526423315647, 0.0930349732768131,
> 0.169959185212759,
> 0.161878841748425, 0, 0.0483041009105874, 0, 0, 0, 0.0777005553478052,
> 0, 0.153175826795441, 0.0428171049833677, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 26.564295705327, 5.5893744508169, 7.22612934071834,
> 36.6563989567777, 0, 28.8967184437329, 28.4030370337251, 28.0886043901352,
> 26.1230935842208, 28.8895673910072, 42.6814210131968, 32.3555695551062,
> 0.76883326657205, 34.6159136622156, 38.329242204291, 56.4476583636484,
> 26.6249506083603, 31.3001451026823, 23.7339071829084, 23.3702284599355,
> 36.669903715038, 44.7377244306005, 31.2079335923023, 32.8613384312272,
> 29.4259634309146, 45.6112405959009, 48.1231689836687, 55.0037961570027,
> 32.9822316456421, 20.0382768189682, 26.0986380308655, 28.8915584506145,
> 28.7949023823068, 30.0278417498425, 58.8089779973569, 20.3602570111197,
> 29.6269605259023, 28.4404986724604, 30.2165182590977, 19.9204461889074,
> 31.1019196559556, 30.3847467747055, 36.8726911479995, 51.0618036275519,
> 23.5408013442579, 36.6948355347593, 27.4753860809429, 24.1341667099646,
> 27.5411488989643, 35.9021799354022, 19.7417897046158, 31.1403887303244,
> 46.1743622734049, 34.8235854891765, 22.1714704189293, 33.6805966894274,
> 35.2814908686112, 42.9767437212852, 38.1264997164547, 5.3651357974451,
> 42.8990434918385, 25.4908883698364, 25.99649502, 36.4958105490917,
> 40.8004126550705, 5.36867162116895, 0.00898476265269363, 0,
> 27.6810997945798,
> 28.7918300045713, 45.7577183830352, 35.9276318604787, 34.9717618087238,
> 29.620354272564, 24.6537513599869, 13.5363982464958, 25.8289073574818,
> 12.0090406245759, 4.753436805, 11.849214652228, 8.41410147611612,
> 0, 1.80855352862552, 1.1987530031681, 1.01148025243171, 0.495675369574172,
> 1.62701127228732, 0, 16.6288242287241, 1.23656061354912, 0.323708776035328,
> 0, 0.566916625204436, 0, 0, 0, 0, 0, 0, 0, 2.53578781871283,
> 3.50083667130797, 0, 0.98049572179098, 0, 3.57129673217304,
> 2.77298867949388,
> 2.12302645642669, 4.11923869203499, 4.69069462193674, 2.8698666062651,
> 2.05079837323067, 0.0602771574448942, 5.96454350250626, 2.26267114439802,
> 3.06911285674854, 2.04233129537404, 2.62181873844029, 1.51813653072598,
> 1.46193772981073, 2.69864635755833, 3.44016493913122, 2.50834832469627,
> 3.48170744166168, 1.00637581555435, 1.67065398473081, 4.18855363095027,
> 3.39649762611015, 1.72804613460423, 1.40053679329531, 2.37032387724109,
> 3.19332545080983, 2.49474373894248, 2.17800931288708, 2.7601484443213,
> 0.91266104095844, 1.93485048639199, 1.19692593420788, 1.79537330666258,
> 2.14020930767983, 3.0122526724942, 2.81112226980754, 3.54890724398174,
> 3.01022926452999, 2.38263226710738, 3.53569238341869, 3.47869329713911,
> 0.679333339820719, 2.4764260756438, 3.82615100065366, 2.20449890383871,
> 1.371303113329, 1.2427787019995, 1.73319133880954, 0.391268883238408,
> 1.73610193837913, 2.68494324646718, 1.77065393606844, 1.45079980147062,
> 0.763775702906329, 0.98566725668627, 0.37838763208699, 0.841811919286804,
> 1.46436462204795, 1.98409602726, 0.507005887891038, 0.465515668274195,
> 0, 1.873365675227, 1.69023864630648, 2.65530855919137, 2.34392199908302,
> 1.61917643594837, 1.05165934333345, 0.564642823436471, 0.121621029620328,
> 0.515007625737071, 0.524345809084086, 0.130898614090571, 0.332427740242623,
> 0.110214989555118, 0, 0.128642193589, 0.119407067173878, 0.128926224027295,
> 0.0622331866694357, 0.215645168287442, 0, 0.859343941945178,
> 0.0500810300696456, 0, 0, 0.0628746592609754), Organ =
> structure(as.integer(c(1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2)), .Label = c("Carc", "TD", "Foie"), class = c("ordered",
> "factor"))), .Names = c("Tps", "Conc", "Organ"), row.names = c("1",
> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
> "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24",
> "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35",
> "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46",
> "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57",
> "58", "59", "60", "61", "62", "63", "64", "65", "66", "67", "68",
> "69", "70", "71", "72", "73", "74", "75", "76", "77", "78", "79",
> "80", "81", "82", "83", "84", "85", "86", "87", "88", "89", "90",
> "91", "92", "93", "94", "95", "96", "97", "98", "99", "100",
> "101", "102", "103", "104", "105", "106", "107", "108", "109",
> "110", "111", "112", "113", "114", "115", "116", "117", "118",
> "119", "120", "121", "122", "123", "124", "125", "126", "127",
> "128", "129", "130", "131", "132", "133", "134", "135", "136",
> "137", "138", "139", "140", "141", "142", "143", "144", "145",
> "146", "147", "148", "149", "150", "151", "152", "153", "154",
> "155", "156", "157", "158", "159", "160", "161", "162", "163",
> "164", "165", "166", "167", "168", "169", "170", "171", "172",
> "173", "174", "175", "176", "177", "178", "179", "180", "181",
> "182", "183", "184", "185", "186", "187", "188", "189", "190",
> "191", "192", "193", "194", "195", "196", "197", "198", "199",
> "200", "201", "202", "203", "204", "205", "206", "207", "208",
> "209", "210", "211", "212", "213", "214", "215", "216", "217",
> "218", "219", "220", "221", "222", "223", "224", "225", "226",
> "227", "228", "229", "230", "231", "232", "233", "234", "235",
> "236", "237", "238", "239", "240", "241", "242", "243", "244",
> "245", "246", "247", "248", "249", "250", "251", "252", "253",
> "254", "255", "256", "257", "258", "259", "260", "261", "262",
> "263", "264", "265", "266", "267", "268", "269", "270", "271",
> "272", "273", "274", "275", "276", "277", "278", "279", "280",
> "281", "282", "283", "284", "285", "286", "287", "288", "289",
> "290", "291", "292", "293", "294", "295", "296", "297", "298",
> "299", "300"), class = c("nfnGroupedData", "nfGroupedData", "groupedData",
> "data.frame"), formula = quote(Conc ~ Tps | Organ), FUN = function (x)
> max(x, na.rm = TRUE), order.groups = TRUE)
>
>
>
>
> Spencer Graves a ??crit :
>>       Regarding the following:
>>
>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>      data=mydata,
>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>> extranames,  :
>>>         variable lengths differ
>>
>>       This example is NOT self contained and is entirely too
>> complicated for me to try to replicate it myself in a reasonable
>> period of time.  I will therefore ask one short question:  Are all the
>> variable names in the "nlsList" call either columns of "mydata" or
>> parameters to be estimated and therefore spelled out in "start"?  If I
>> were you, I'd check this all very carefully, being especially careful
>> about the distinction between "lCl" and "lC1", in particular.
>>
>>       If you'd like further help with this, I suggest you try to find
>> the simplest possible example that generates problem you don't
>> understand, then try to recast that example into one that is
>> completely self contained, either a data set in the standard R or nlme
>> distribution  or numbers that one can generate with a very few lines
>> of code.  If you use random numbers, please "set.seed", to increase
>> your confidence that someone else will see what you see.  (And please
>> review the posting guide! "www.R-project.org/posting-guide.html".
>> Doing so may increase your chances of getting more useful information
>> more quickly.)
>>
>>       spencer graves
>>
>> Patrick Giraudoux wrote:
>>
>>> Dear listers,
>>>
>>> I am trying to fit a model using nlsList() using alternately a
>>> SSfol() selfstart function or its developped equivalent formulae.
>>>
>>> This preliminary trial works well
>>>
>>> mydata<-groupedData(Conc~Tps|Organ,data=mydata)
>>> mymod1<-nls(Conc~SSfol(Dose,Tps,lKe,lKa,lCl),data=mydata)
>>>
>>> as well as a developped form:
>>>
>>> mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) *
>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>     data=mydata,
>>>     start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>     )
>>>
>>> However when trying to fit the model with nlsList, I get:
>>>
>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>      data=mydata,
>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>      )
>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>> extranames,  :
>>>         variable lengths differ
>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>> extranames,  :
>>>         variable lengths differ
>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>> extranames,  :
>>>         variable lengths differ
>>>
>>> Or specifying  the grouping factor explicitely:
>>>
>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe))|Organ,
>>>      data=mydata,
>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>      )
>>>
>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>> extranames,  :
>>>         variable lengths differ
>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>> extranames,  :
>>>         variable lengths differ
>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>> extranames,  :
>>>         variable lengths differ
>>>
>>>
>>> I cannot find out why the grouping factor cannot be used (it has the
>>> same length as the other variables...)
>>>
>>> Another strange thing occurs: in the example given in the help of
>>> nlsList.selfstart, the following command works  well:
>>>
>>>  fm1 <- nlsList(SSasympOff, CO2)
>>>
>>> However its seemingly equivalent applied to the case above fails:
>>>
>>> mymod4<-nlsList(SSfol,data=mydata)
>>> Error in eval(expr, envir, enclos) : object "input" not found
>>> Error in eval(expr, envir, enclos) : object "input" not found
>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>
>>>
>>> Any hint/suggestion appreciated.
>>>
>>> Kind regards,
>>>
>>> Patrick Giraudoux
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From dvumani at hotmail.com  Fri Feb 17 12:02:54 2006
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Fri, 17 Feb 2006 11:02:54 +0000
Subject: [R] RCMD SHILB uses g++ instead of gcc
In-Reply-To: <Pine.LNX.4.64.0602161310160.12709@gannet.stats.ox.ac.uk>
Message-ID: <BAY110-F38DC661ADC68C9E1FD8024A3F80@phx.gbl>

I am using RCMD SHLIB to make a dll from the convolve2.c code presented with 
R-exts. After an e-mail from Prof Ripley, I noticed that SHLIB is using a 
C++ compiler instead of a C compiler for the code.

Have searched the R-site and the internet for answers and noticed that it is 
possible to change the "makeconf" and "makefile" files to correct this. But 
these files are not present in my system. I downloaded 
"R-2.2.1pat-win32.exe" and installed the traditional windows way.

Thanks for your responses.

Full_Name: Vumani Dlamini
Version: 2.2.1 Patched
OS: Microsoft Windows XP Professional





>From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>To: Vumani Dlamini <dvumani at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] symbol decoration and .Call
>Date: Thu, 16 Feb 2006 13:12:25 +0000 (GMT)
>
>1) Please read the posting guide and use the appropriate list, not R-help.
>
>2) Please tell us exactly what you did, including your OS, R version and so 
>on as the guide asks.  Looks to me like you used a C++ compiler to compile 
>C.
>
>On Thu, 16 Feb 2006, Vumani Dlamini wrote:
>
>>Dear R-users,
>>I am a novice user of .Call and am trying to use the C code in R-Ext to
>>kickstart my learning process. All the code compiles but when I try to use
>>.Call it gives the error (using "out.c" as an example),
>>
>>Error in .Call("out", x, y) : C entry point "out" not in load table
>>
>>when i use PEDUMP to check whether the symbol is loaded I find that it is
>>loaded as "_Z3outP7SEXPRECS0_" and when I use this instead of "out" the
>>program work.
>>
>>How can I remove the decoration so that only "out" is loaded?
>>
>>Thanks, Vumani
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From patrick.giraudoux at univ-fcomte.fr  Fri Feb 17 12:07:36 2006
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Fri, 17 Feb 2006 12:07:36 +0100
Subject: [R] lme, nlsList, nlsList.selfStart
In-Reply-To: <Pine.LNX.4.64.0602171040190.13399@gannet.stats.ox.ac.uk>
References: <43EEE758.2050408@univ-fcomte.fr> <43F522FF.9060402@pdf.com>
	<43F59BA9.1010106@univ-fcomte.fr>
	<Pine.LNX.4.64.0602171040190.13399@gannet.stats.ox.ac.uk>
Message-ID: <43F5AE78.7000908@univ-fcomte.fr>

Well, right, Dose was indeed in the global environment and not in the 
data.frame. Changing it with

mydata2$Dose<-100 # the real dose at the beginning of the experiment

improves the thing in a sense... but I face a new error:

mymod3<-nlsList(Conc+1 ~ Dose * exp(lKe+lKa-lCl) * 
(exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)) | Organ,
data=mydata2,
start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
)

Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
        Non-numeric argument to mathematical function
Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
        Non-numeric argument to mathematical function
Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
        Non-numeric argument to mathematical function

I have checked the variables in the data.frame with:

 > sapply(mydata2,is.factor)
  Tps  Conc Organ  Dose
FALSE FALSE  TRUE FALSE
 > sapply(mydata2,is.character)
  Tps  Conc Organ  Dose
FALSE FALSE FALSE FALSE

So everything looks OK on this side...

Furthermore, I have still this "old" error intact:

 > mymod4<-nlsList(SSfol,data=mydata2)
Error in eval(expr, envir, enclos) : object "input" not found
Error in eval(expr, envir, enclos) : object "input" not found
Error in eval(expr, envir, enclos) : object "input" not found


I am really sorry for calling help and boring everybody on this likely 
trivial issue (this looks like asking a community to participate to 
debogging line by line, a shame!!!), but I must admit that I am really 
lost...

Thanks for your concern,

Kind regards,

Patrick


Prof Brian Ripley a ??crit :
> We don't have Dose, and I think that is where the error lies.  If Dose 
> were part of mydata2, this is likely to work, but otherwise it is Dose 
> which has the wrong length.
>
> ?nlsList says
>
>     data: a data frame in which to interpret the variables named in
>           'model'.
>
> and it means it: you must get all the variables from there.
>
>
> On Fri, 17 Feb 2006, Patrick Giraudoux wrote:
>
>> Spencer,
>>
>> Thanks for the hint. I did not dare to bore people with the full data
>> set and though that this kind of error may have been trivial and often
>> encountered (so leading to a short answer), even though I did not see
>> related messages on the r-help list. I already did the checks suggested
>> before posting, and was aware of the possible confusion between 1 and l
>> (actually the variable names were not given by myself).
>>
>> It seems that the trouble comes when the grouping variable "Organ" is
>> used. The best (?) I can do  is to dump the data.frame here below.
>>
>> With this example, one can get exactly the same errors:
>>
>> mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) *
>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>    data=mydata2,
>>    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>    )
>>
>> ... works well!!!
>>
>> but we get then:
>>
>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)) | Organ,
>>    data=mydata2,
>>    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>    )
>> Error in model.frame(formula, rownames, variables, varnames, extras,
>> extranames,  :
>>        variable lengths differ
>> Error in model.frame(formula, rownames, variables, varnames, extras,
>> extranames,  :
>>        variable lengths differ
>> Error in model.frame(formula, rownames, variables, varnames, extras,
>> extranames,  :
>>        variable lengths differ
>>
>>
>> > mymod4<-nlsList(SSfol,data=mydata2)
>> Error in eval(expr, envir, enclos) : object "input" not found
>> Error in eval(expr, envir, enclos) : object "input" not found
>> Error in eval(expr, envir, enclos) : object "input" not found
>>
>>
>> Sorry and apologise for the inconvenience met,
>>
>> Kind regards,
>>
>> Patrick
>>
>>
>>
>> # data.frame just to copy and past into R
>>
>> "mydata2" <-
>> structure(list(Tps = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3,
>> 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,
>> 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9,
>> 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 14,
>> 14, 14, 14, 14, 17, 17, 17, 17, 17, 20, 20, 20, 20, 25, 28, 29,
>> 50, 50, 50, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
>> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4,
>> 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,
>> 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10,
>> 10, 10, 11, 11, 11, 11, 11, 11, 14, 14, 14, 14, 14, 17, 17, 17,
>> 17, 17, 20, 20, 20, 20, 25, 28, 29, 50, 50, 50, 136, 136, 136,
>> 136, 136, 136, 136, 136, 136, 136, 1, 1, 1, 1, 1, 1, 2, 2, 2,
>> 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,
>> 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8,
>> 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,
>> 11, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 20, 20, 20, 20,
>> 25, 28, 29, 50, 50, 50, 136, 136, 136, 136, 136, 136, 136, 136,
>> 136, 136), Conc = c(0, 0, 0, 0, 0, 0, 0, 0.807852503274902,
>> 0.204371494701886,
>> 0.579222129993907, 0.989062273721619, 0, 1.11728297897571,
>> 1.41057428121324,
>> 0.888883702851307, 1.259907624008, 1.45753269675829, 1.07077516747401,
>> 0.843279379, 0, 0.763110069196737, 1.11297791434297, 1.10087763997637,
>> 0.946929594501016, 1.33112168, 0.654041755, 0.694167499, 1.289548703,
>> 1.117139864, 0.807196192, 0.720221376552025, 0.560082823, 0.476583438,
>> 2.590855204, 0.51510972, 1.072946887, 0.537999938614396, 
>> 0.886684225905255,
>> 0.630178116793598, 1.31534758842196, 1.33333958571746, 
>> 0.922032210748255,
>> 0.429930193046174, 1.35881467717335, 0.790045927902363, 
>> 1.22484702570724,
>> 0.808104508207897, 1.31185966817903, 1.51837686425553, 1.74105163638734,
>> 1.80365598487402, 1.13240352674377, 1.50086243061644, 2.06355364280445,
>> 0.439350890906039, 1.54692793444949, 1.78758216051046, 1.09043400023239,
>> 0.811328376840514, 0.459192443530981, 0.695333473157298, 
>> 0.387995007681174,
>> 0.784627063444921, 1.02282256375842, 0.382687104107726, 
>> 0.554290634950242,
>> 0.130420456296453, 0.324194753224919, 0.31106140274139, 
>> 0.513473505828888,
>> 0.878620320248701, 1.18404358659996, 0.136926837896477, 0, 0,
>> 0.835588760032974, 0.558617235576616, 1.21002805866839, 
>> 0.769381068031404,
>> 1.04514254228094, 0.373251847173678, 0.389005898972802, 
>> 0.183141006154896,
>> 0.223596336820146, 0.315526423315647, 0.0930349732768131,
>> 0.169959185212759,
>> 0.161878841748425, 0, 0.0483041009105874, 0, 0, 0, 0.0777005553478052,
>> 0, 0.153175826795441, 0.0428171049833677, 0, 0, 0, 0, 0, 0, 0,
>> 0, 0, 0, 26.564295705327, 5.5893744508169, 7.22612934071834,
>> 36.6563989567777, 0, 28.8967184437329, 28.4030370337251, 
>> 28.0886043901352,
>> 26.1230935842208, 28.8895673910072, 42.6814210131968, 32.3555695551062,
>> 0.76883326657205, 34.6159136622156, 38.329242204291, 56.4476583636484,
>> 26.6249506083603, 31.3001451026823, 23.7339071829084, 23.3702284599355,
>> 36.669903715038, 44.7377244306005, 31.2079335923023, 32.8613384312272,
>> 29.4259634309146, 45.6112405959009, 48.1231689836687, 55.0037961570027,
>> 32.9822316456421, 20.0382768189682, 26.0986380308655, 28.8915584506145,
>> 28.7949023823068, 30.0278417498425, 58.8089779973569, 20.3602570111197,
>> 29.6269605259023, 28.4404986724604, 30.2165182590977, 19.9204461889074,
>> 31.1019196559556, 30.3847467747055, 36.8726911479995, 51.0618036275519,
>> 23.5408013442579, 36.6948355347593, 27.4753860809429, 24.1341667099646,
>> 27.5411488989643, 35.9021799354022, 19.7417897046158, 31.1403887303244,
>> 46.1743622734049, 34.8235854891765, 22.1714704189293, 33.6805966894274,
>> 35.2814908686112, 42.9767437212852, 38.1264997164547, 5.3651357974451,
>> 42.8990434918385, 25.4908883698364, 25.99649502, 36.4958105490917,
>> 40.8004126550705, 5.36867162116895, 0.00898476265269363, 0,
>> 27.6810997945798,
>> 28.7918300045713, 45.7577183830352, 35.9276318604787, 34.9717618087238,
>> 29.620354272564, 24.6537513599869, 13.5363982464958, 25.8289073574818,
>> 12.0090406245759, 4.753436805, 11.849214652228, 8.41410147611612,
>> 0, 1.80855352862552, 1.1987530031681, 1.01148025243171, 
>> 0.495675369574172,
>> 1.62701127228732, 0, 16.6288242287241, 1.23656061354912, 
>> 0.323708776035328,
>> 0, 0.566916625204436, 0, 0, 0, 0, 0, 0, 0, 2.53578781871283,
>> 3.50083667130797, 0, 0.98049572179098, 0, 3.57129673217304,
>> 2.77298867949388,
>> 2.12302645642669, 4.11923869203499, 4.69069462193674, 2.8698666062651,
>> 2.05079837323067, 0.0602771574448942, 5.96454350250626, 
>> 2.26267114439802,
>> 3.06911285674854, 2.04233129537404, 2.62181873844029, 1.51813653072598,
>> 1.46193772981073, 2.69864635755833, 3.44016493913122, 2.50834832469627,
>> 3.48170744166168, 1.00637581555435, 1.67065398473081, 4.18855363095027,
>> 3.39649762611015, 1.72804613460423, 1.40053679329531, 2.37032387724109,
>> 3.19332545080983, 2.49474373894248, 2.17800931288708, 2.7601484443213,
>> 0.91266104095844, 1.93485048639199, 1.19692593420788, 1.79537330666258,
>> 2.14020930767983, 3.0122526724942, 2.81112226980754, 3.54890724398174,
>> 3.01022926452999, 2.38263226710738, 3.53569238341869, 3.47869329713911,
>> 0.679333339820719, 2.4764260756438, 3.82615100065366, 2.20449890383871,
>> 1.371303113329, 1.2427787019995, 1.73319133880954, 0.391268883238408,
>> 1.73610193837913, 2.68494324646718, 1.77065393606844, 1.45079980147062,
>> 0.763775702906329, 0.98566725668627, 0.37838763208699, 
>> 0.841811919286804,
>> 1.46436462204795, 1.98409602726, 0.507005887891038, 0.465515668274195,
>> 0, 1.873365675227, 1.69023864630648, 2.65530855919137, 2.34392199908302,
>> 1.61917643594837, 1.05165934333345, 0.564642823436471, 
>> 0.121621029620328,
>> 0.515007625737071, 0.524345809084086, 0.130898614090571, 
>> 0.332427740242623,
>> 0.110214989555118, 0, 0.128642193589, 0.119407067173878, 
>> 0.128926224027295,
>> 0.0622331866694357, 0.215645168287442, 0, 0.859343941945178,
>> 0.0500810300696456, 0, 0, 0.0628746592609754), Organ =
>> structure(as.integer(c(1,
>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3,
>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>> 2, 2, 2, 2, 2)), .Label = c("Carc", "TD", "Foie"), class = c("ordered",
>> "factor"))), .Names = c("Tps", "Conc", "Organ"), row.names = c("1",
>> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
>> "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24",
>> "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35",
>> "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46",
>> "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57",
>> "58", "59", "60", "61", "62", "63", "64", "65", "66", "67", "68",
>> "69", "70", "71", "72", "73", "74", "75", "76", "77", "78", "79",
>> "80", "81", "82", "83", "84", "85", "86", "87", "88", "89", "90",
>> "91", "92", "93", "94", "95", "96", "97", "98", "99", "100",
>> "101", "102", "103", "104", "105", "106", "107", "108", "109",
>> "110", "111", "112", "113", "114", "115", "116", "117", "118",
>> "119", "120", "121", "122", "123", "124", "125", "126", "127",
>> "128", "129", "130", "131", "132", "133", "134", "135", "136",
>> "137", "138", "139", "140", "141", "142", "143", "144", "145",
>> "146", "147", "148", "149", "150", "151", "152", "153", "154",
>> "155", "156", "157", "158", "159", "160", "161", "162", "163",
>> "164", "165", "166", "167", "168", "169", "170", "171", "172",
>> "173", "174", "175", "176", "177", "178", "179", "180", "181",
>> "182", "183", "184", "185", "186", "187", "188", "189", "190",
>> "191", "192", "193", "194", "195", "196", "197", "198", "199",
>> "200", "201", "202", "203", "204", "205", "206", "207", "208",
>> "209", "210", "211", "212", "213", "214", "215", "216", "217",
>> "218", "219", "220", "221", "222", "223", "224", "225", "226",
>> "227", "228", "229", "230", "231", "232", "233", "234", "235",
>> "236", "237", "238", "239", "240", "241", "242", "243", "244",
>> "245", "246", "247", "248", "249", "250", "251", "252", "253",
>> "254", "255", "256", "257", "258", "259", "260", "261", "262",
>> "263", "264", "265", "266", "267", "268", "269", "270", "271",
>> "272", "273", "274", "275", "276", "277", "278", "279", "280",
>> "281", "282", "283", "284", "285", "286", "287", "288", "289",
>> "290", "291", "292", "293", "294", "295", "296", "297", "298",
>> "299", "300"), class = c("nfnGroupedData", "nfGroupedData", 
>> "groupedData",
>> "data.frame"), formula = quote(Conc ~ Tps | Organ), FUN = function (x)
>> max(x, na.rm = TRUE), order.groups = TRUE)
>>
>>
>>
>>
>> Spencer Graves a ??crit :
>>>       Regarding the following:
>>>
>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>      data=mydata,
>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>> extranames,  :
>>>>         variable lengths differ
>>>
>>>       This example is NOT self contained and is entirely too
>>> complicated for me to try to replicate it myself in a reasonable
>>> period of time.  I will therefore ask one short question:  Are all the
>>> variable names in the "nlsList" call either columns of "mydata" or
>>> parameters to be estimated and therefore spelled out in "start"?  If I
>>> were you, I'd check this all very carefully, being especially careful
>>> about the distinction between "lCl" and "lC1", in particular.
>>>
>>>       If you'd like further help with this, I suggest you try to find
>>> the simplest possible example that generates problem you don't
>>> understand, then try to recast that example into one that is
>>> completely self contained, either a data set in the standard R or nlme
>>> distribution  or numbers that one can generate with a very few lines
>>> of code.  If you use random numbers, please "set.seed", to increase
>>> your confidence that someone else will see what you see.  (And please
>>> review the posting guide! "www.R-project.org/posting-guide.html".
>>> Doing so may increase your chances of getting more useful information
>>> more quickly.)
>>>
>>>       spencer graves
>>>
>>> Patrick Giraudoux wrote:
>>>
>>>> Dear listers,
>>>>
>>>> I am trying to fit a model using nlsList() using alternately a
>>>> SSfol() selfstart function or its developped equivalent formulae.
>>>>
>>>> This preliminary trial works well
>>>>
>>>> mydata<-groupedData(Conc~Tps|Organ,data=mydata)
>>>> mymod1<-nls(Conc~SSfol(Dose,Tps,lKe,lKa,lCl),data=mydata)
>>>>
>>>> as well as a developped form:
>>>>
>>>> mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) *
>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>     data=mydata,
>>>>     start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>     )
>>>>
>>>> However when trying to fit the model with nlsList, I get:
>>>>
>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>      data=mydata,
>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>      )
>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>> extranames,  :
>>>>         variable lengths differ
>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>> extranames,  :
>>>>         variable lengths differ
>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>> extranames,  :
>>>>         variable lengths differ
>>>>
>>>> Or specifying  the grouping factor explicitely:
>>>>
>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe))|Organ,
>>>>      data=mydata,
>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>      )
>>>>
>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>> extranames,  :
>>>>         variable lengths differ
>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>> extranames,  :
>>>>         variable lengths differ
>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>> extranames,  :
>>>>         variable lengths differ
>>>>
>>>>
>>>> I cannot find out why the grouping factor cannot be used (it has the
>>>> same length as the other variables...)
>>>>
>>>> Another strange thing occurs: in the example given in the help of
>>>> nlsList.selfstart, the following command works  well:
>>>>
>>>>  fm1 <- nlsList(SSasympOff, CO2)
>>>>
>>>> However its seemingly equivalent applied to the case above fails:
>>>>
>>>> mymod4<-nlsList(SSfol,data=mydata)
>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>
>>>>
>>>> Any hint/suggestion appreciated.
>>>>
>>>> Kind regards,
>>>>
>>>> Patrick Giraudoux
>>>>
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide!
>>>> http://www.R-project.org/posting-guide.html
>>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>



From BARRETTJ at email.chop.edu  Fri Feb 17 12:07:31 2006
From: BARRETTJ at email.chop.edu (Jeffrey Barrett)
Date: Fri, 17 Feb 2006 06:07:31 -0500
Subject: [R] R-help Digest, Vol 36, Issue 17
Message-ID: <s3f56831.025@email.chop.edu>

I will be out of the office from Friday (Feb 17) through Wednesday (Feb
22).



From islandboy1982 at yahoo.com  Fri Feb 17 12:44:15 2006
From: islandboy1982 at yahoo.com (oliver wee)
Date: Fri, 17 Feb 2006 03:44:15 -0800 (PST)
Subject: [R]  function for prediting garch
In-Reply-To: <20060216204728.39488.qmail@web33211.mail.mud.yahoo.com>
Message-ID: <20060217114415.1386.qmail@web33203.mail.mud.yahoo.com>


> hello,
> 
> In my time series data, I was able to successfully
> fit
> its ARIMA model (Box-Jenkins) and its GARCH model
> and
> estimate their parameters. I was also able to
> forecast
> future values of the time series based on my fitted
> ARIMA model using the predict() function call. 
> 
> However, I'm not sure what is the correct function
> command to call in order to forecast  future values
> of
> my time series using both the fitted ARIMA model and
> the fitted GARCH model. Using predict() didn't give
> me
> the result I was looking for. And I can't find any
> documentation using help.search,
> 
> I think what I am looking for is akin to the
> garchsim
> and garchpred commands in Mathlab.
> 
> Any help is appreciated. Thanks!



From avilella at gmail.com  Fri Feb 17 12:57:33 2006
From: avilella at gmail.com (Albert Vilella)
Date: Fri, 17 Feb 2006 12:57:33 +0100
Subject: [R] labels inside the bars of horizontal barplot
Message-ID: <1140177453.13591.0.camel@localhost.localdomain>

Dears,

I would like to add labels inside the bars of a horizontal bar
plot like this:

mylabels = c(
  "long text goes here first",
  "long text goes here second",
  "long text goes here third",
  "long text goes here fourth",
  "long text goes here fourth",
  "long text goes here fifth",
  "long text goes here sixth",
  "long text goes here seventh",
  "long text goes here bla bla",
  "long text goes here and more"
)
myvect1 = c(0.25,0.21,0.20,0.22,0.20,0.22,0.20,0.22,0.20,0.22)
myvect2 = c(0.13,0.08,0.09,0.11,0.13,0.08,0.09,0.11,0.13,0.08)
mydf = data.frame(myvect1,myvect2) # Forgive this df<->matrix mess, I
use the df for other stuff
barplot(t(as.matrix(mydf)),
        horiz=TRUE,
        beside=TRUE,
        space=c(-0.9,0.1))

What I would like is to have the labels inside the upper bar.

Any ideas?

Bests,

    Albert.



From jacques.veslot at cirad.fr  Fri Feb 17 13:09:39 2006
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Fri, 17 Feb 2006 16:09:39 +0400
Subject: [R] labels inside the bars of horizontal barplot
In-Reply-To: <1140177453.13591.0.camel@localhost.localdomain>
References: <1140177453.13591.0.camel@localhost.localdomain>
Message-ID: <43F5BD03.60608@cirad.fr>

b <- barplot(t(as.matrix(mydf)),horiz=TRUE,beside=TRUE,space=c(-0.9,0.1))
text(myvect1, b[1,], mylabels, col="white", adj=1)


Albert Vilella a ??crit :

>Dears,
>
>I would like to add labels inside the bars of a horizontal bar
>plot like this:
>
>mylabels = c(
>  "long text goes here first",
>  "long text goes here second",
>  "long text goes here third",
>  "long text goes here fourth",
>  "long text goes here fourth",
>  "long text goes here fifth",
>  "long text goes here sixth",
>  "long text goes here seventh",
>  "long text goes here bla bla",
>  "long text goes here and more"
>)
>myvect1 = c(0.25,0.21,0.20,0.22,0.20,0.22,0.20,0.22,0.20,0.22)
>myvect2 = c(0.13,0.08,0.09,0.11,0.13,0.08,0.09,0.11,0.13,0.08)
>mydf = data.frame(myvect1,myvect2) # Forgive this df<->matrix mess, I
>use the df for other stuff
>barplot(t(as.matrix(mydf)),
>        horiz=TRUE,
>        beside=TRUE,
>        space=c(-0.9,0.1))
>
>What I would like is to have the labels inside the upper bar.
>
>Any ideas?
>
>Bests,
>
>    Albert.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From david.meyer at wu-wien.ac.at  Fri Feb 17 14:07:10 2006
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Fri, 17 Feb 2006 14:07:10 +0100
Subject: [R] getting probabilities from SVM
Message-ID: <20060217140710.ff1f55d4.david.meyer@wu-wien.ac.at>

> Finally figured it out.  You have to extract it from the attributes.
> Tricky.  Thanks anyway.

> attr(pred, "prob")[1:10,]

Correct. 

Just for the records, the rationale behind this `tricky' design:

In addition to probabilites, predict.svm() (more precisely: libsvm) can also compute the decision values. Common ways to handle `polymorph' prediction types are, e.g, using a `type' argument in the predict() function, or to return all variants in one list object. With a `type' argument, you need several calls to predict() if you need, say, hard predictions _and_ the probabilities. On the other hand, the probability and decision values features were added to libsvm only when svm() in e1071 had already been around for a while, so returning a list instead of a vector would have broken a lot of code. So I decided to keep the `standard' predict behavior and to `hide' special predictions in an attribute. If the latter had been available from the beginning, I probably would have used the `type' approach.

Cheers,
David


On 2/16/06, roger bos <roger.bos at gmail.com> wrote:
>
> I am using SVM to classify categorical data and I would like the
> probabilities instead of the classification.  ?predict.svm says that its
> only enabled when you train the model with it enabled, so I did that, but it
> didn't work.  I can't even get it to work with iris.  The help file shows
> that probability = TRUE when training the model, but doesn't show an
> example.  Then I try to predict with probabilities, I still only get
> classifications back.  Anyone get this to work and can help me out?

-- 
Dr. David Meyer
Department of Information Systems and Operations

Vienna University of Economics and Business Administration
Augasse 2-6, A-1090 Wien, Austria, Europe
Fax: +43-1-313 36x746 
Tel: +43-1-313 36x4393
HP:  http://wi.wu-wien.ac.at/~meyer/



From kjetilbrinchmannhalvorsen at gmail.com  Fri Feb 17 14:30:14 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Fri, 17 Feb 2006 09:30:14 -0400
Subject: [R] function for prediting garch
In-Reply-To: <20060216204728.39488.qmail@web33211.mail.mud.yahoo.com>
References: <20060216204728.39488.qmail@web33211.mail.mud.yahoo.com>
Message-ID: <43F5CFE6.5070206@gmail.com>

oliver wee wrote:
> hello,
> 
> In my time series data, I was able to successfully fit
> its ARIMA model (Box-Jenkins) and its GARCH model and
> estimate their parameters. I was also able to forecast
> future values of the time series based on my fitted
> ARIMA model using the predict() function call. 
> 
> However, I'm not sure what is the correct function
> command to call in order to forecast  future values of
> my time series using both the fitted ARIMA model and
> the fitted GARCH model. Using predict() didn't give me
> the result I was looking for. And I can't find any
> documentation using help.search,

You should have given reproducible code!

In my understanding, (g)arch is applied to an
uncorrelated series without autocorrelastions,
as the residuals from a properly estimated ARIMA
model. So to get the predictions for the original
series, you need to
1) predict with the ARIMA model
2) estimate a garch model to the residuals
3) predict the residuals
4) modify the prediction from 1) with the prediction from 3)

Kjetil

> 
> I think what I am looking for is akin to the garchsim
> and garchpred commands in Mathlab.
> 
> Any help is appreciated. Thanks!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From pzs6 at CDC.GOV  Fri Feb 17 14:39:36 2006
From: pzs6 at CDC.GOV (Smith, Phil)
Date: Fri, 17 Feb 2006 08:39:36 -0500
Subject: [R] Windows metafile problem
Message-ID: <2554377D323C9A40BD69956059FD05490ED452F1@mnip1>

Hi All:

I'm using win.metafile() to produce windows metafiles. 

When I use Word to insert the wmf picture, Word gives an error!

I did my homework in posting this question, and couldn't find a fix.

Any suggestions?

Phil Smith
CDC



From ccleland at optonline.net  Fri Feb 17 14:44:27 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 17 Feb 2006 08:44:27 -0500
Subject: [R] Windows metafile problem
In-Reply-To: <2554377D323C9A40BD69956059FD05490ED452F1@mnip1>
References: <2554377D323C9A40BD69956059FD05490ED452F1@mnip1>
Message-ID: <43F5D33B.5070904@optonline.net>

The following:

win.metafile("c:/test.emf")
plot(rnorm(10))
dev.off()

works for me to create the enhanced windows metafile, which I can then 
insert into MS-Word.  How are you creating the metafile in R?  What is 
the error that MS-Word gives?

Smith, Phil wrote:
> Hi All:
> 
> I'm using win.metafile() to produce windows metafiles. 
> 
> When I use Word to insert the wmf picture, Word gives an error!
> 
> I did my homework in posting this question, and couldn't find a fix.
> 
> Any suggestions?
> 
> Phil Smith
> CDC
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From murdoch at stats.uwo.ca  Fri Feb 17 15:05:38 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 17 Feb 2006 09:05:38 -0500
Subject: [R] how to clear screen in R-console?
In-Reply-To: <b1f16d9d0602161222g6f72e36cg93aba58b11fd2a53@mail.gmail.com>
References: <b1f16d9d0602160233r1a95ba81qd81583b047b7f2af@mail.gmail.com>	<43F45928.8010902@web.de>	<b1f16d9d0602160322m6cb6a484mfd6aee2bbf2b758b@mail.gmail.com>	<59d7961d0602160459t493de978na04494e207460e55@mail.gmail.com>
	<b1f16d9d0602161222g6f72e36cg93aba58b11fd2a53@mail.gmail.com>
Message-ID: <43F5D832.8060604@stats.uwo.ca>

On 2/16/2006 3:22 PM, Michael wrote:
> I am actually using Rgui on Windows...
> 
> What can I do?
> 
> There is no way to programmatically clear screen?

Of course there's a way, or Rgui couldn't do it.  The menu item calls 
the function "menuclear", which is exported from R.dll, currently with 
definition

void menuclear(control m)
{
     consoleclear(RConsole);
}

You don't have access to a valid value for m, but since it's not used, 
that shouldn't matter.  Write a C function to import this function from 
R.dll and call it.

You shouldn't count on your function working in any newer release; 
menuclear is not part of the published API.  And you shouldn't expect 
your code to work if you're running in Rterm or on any platform other 
than Windows.  But if you're desperate to call it, you can.

Brian Ripley has made many of the menu operations in Rgui available 
through R functions.  Perhaps they all should be; would you like to 
write the code to do it?  If so, please write up the R interface before 
you go ahead and do all the work.  I expect there will be some 
disagreement there, and it might affect the implementation.

Duncan Murdoch
> 
> On 2/16/06, Henrik Bengtsson <hb at maths.lth.se> wrote:
>>
>> Hi,
>>
>> depends on what type of terminal you are running.  For example, if you
>> run R in a VT100 terminal, you can try
>>
>> cat("The following VT100 escape sequence will clear the screen on a
>> VT100 terminal\n")
>> cat("\033[2J")  # <ESC>[2J  == Clear Screen
>> cat("If the screen was cleared you should only see this sentence.\n")
>>
>> i.e.
>>
>> vt100ClearScreen <- function(...) cat("\033[2J")
>>
>> Some links:
>> http://www.fh-jena.de/~gmueller/Kurs_halle/esc_vt100.html
>> http://en.wikipedia.org/wiki/VT100
>>
>> Note, this is not guaranteed to work everywhere.  To the best of my
>> knowledge, you will not be able to do anything like this in Rgui on
>> Windows.
>>
>> Cheers
>>
>> Henrik
>>
>>
>> On 2/16/06, Michael <comtech.usa at gmail.com> wrote:
>> > Any funcation that is callable from my program, instead of pressing
>> keys?
>> >
>> > Thanks a lot!
>> >
>> >
>> > On 2/16/06, Christian Schulz <ozric at web.de> wrote:
>> > >
>> > > ctrl - e & l
>> > >
>> > > >HI all,
>> > > >
>> > > >How to clear the screen in R-console?
>> > > >
>> > > >Thanks a lot@!
>> > > >
>> > > >       [[alternative HTML version deleted]]
>> > > >
>> > > >______________________________________________
>> > > >R-help at stat.math.ethz.ch mailing list
>> > > >https://stat.ethz.ch/mailman/listinfo/r-help
>> > > >PLEASE do read the posting guide!
>> > > http://www.R-project.org/posting-guide.html
>> > > >
>> > > >
>> > > >
>> > >
>> > >
>> > >
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>> >
>> >
>>
>>
>> --
>> Henrik Bengtsson
>> Mobile: +46 708 909208 (+1h UTC)
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sekemp at glam.ac.uk  Fri Feb 17 14:29:13 2006
From: sekemp at glam.ac.uk (Kemp S E (Comp))
Date: Fri, 17 Feb 2006 13:29:13 -0000
Subject: [R] t-test confidence interval
Message-ID: <0BA7EE4D4646E0409D458D347C508B7801A2C1A9@MAILSERV1.uni.glam.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060217/702f9c41/attachment.pl

From bolker at ufl.edu  Fri Feb 17 15:45:21 2006
From: bolker at ufl.edu (Ben Bolker)
Date: Fri, 17 Feb 2006 14:45:21 +0000 (UTC)
Subject: [R] t-test confidence interval
References: <0BA7EE4D4646E0409D458D347C508B7801A2C1A9@MAILSERV1.uni.glam.ac.uk>
Message-ID: <loom.20060217T154341-918@post.gmane.org>

Kemp S E (Comp <sekemp <at> glam.ac.uk> writes:

> 
> Hi,
> 
> Does anyone know of a pre-existing function where I can get the t-test
> confidence interval for a given mean, sd, degrees of freedom and
> confidence limit.
> 
> I do NOT want to run any data through the t.test function.
> 
> Kind regards,
> 
> Sam.

  how about 

mean+c(-1,1)*sd*qt(1-alpha/2,df)

?



From roger.bos at gmail.com  Fri Feb 17 15:55:24 2006
From: roger.bos at gmail.com (roger bos)
Date: Fri, 17 Feb 2006 09:55:24 -0500
Subject: [R] getting probabilities from SVM
In-Reply-To: <20060217140710.ff1f55d4.david.meyer@wu-wien.ac.at>
References: <20060217140710.ff1f55d4.david.meyer@wu-wien.ac.at>
Message-ID: <1db726800602170655s29253e6jb8c6a488bfc982f7@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060217/7ca8103c/attachment.pl

From prasannaprakash at gmail.com  Fri Feb 17 16:28:46 2006
From: prasannaprakash at gmail.com (Prasanna BALAPRAKASH)
Date: Fri, 17 Feb 2006 16:28:46 +0100
Subject: [R] Grouping and Averaging in Table
Message-ID: <BFE24A36-B282-4317-99F8-5070122CDF67@gmail.com>

Dear Rs

I have a single table with three columns in the following form:

1	100	150
1	45	32
1	99	100
2	150	33
2	22	87
2	71	31
....
....
1000	64	32
1	100	150
1	45	32
1	99	100
2	22	89
2	31	44
2	88	11
....
....
1200	64	32
1	100	150
1	45	32
1	99	100
2	150	33
2	22	87
2	71	31
...
...
1100	31	34

Totally 1000+1200+1100 rows.  Now, I need to group by first column  
and average then second and third column to get a table as follows as  
follows:

1	Avg. of all second col. values whose first col value is 1	Avg. of  
all third col. values whose first col value is 1
2	Avg. of all second col. values whose first col value is 2	Avg. of  
all third col. values whose first col value is 2
..
..
1200	Avg. of all second col. values whose first col value is 1200	 
Avg. of all third col. values whose first col value is 1200


Right now, I have a dirty implementation with a lot of "for" loops  
and "if" conditions. However, I am looking for some built in  
functions and lib. to make the code faster and easier.


Thanks
Prasanna



From Charles.Annis at StatisticalEngineering.com  Fri Feb 17 16:20:28 2006
From: Charles.Annis at StatisticalEngineering.com (Charles Annis, P.E.)
Date: Fri, 17 Feb 2006 10:20:28 -0500
Subject: [R] Windows metafile problem
In-Reply-To: <2554377D323C9A40BD69956059FD05490ED452F1@mnip1>
Message-ID: <03ab01c633d5$af5239d0$6600a8c0@DD4XFW31>

When you open the metafile with something like

win.metafile(filename = file.name, width = 6.5, height = 6.5, pointsize =
12)

Where you have defined the file.name to include the path, you then, of
course, execute the R logic to create the file.

BUT, don't forget to close the file to tidy things up.  Otherwise the file
will be there, but it won't be useable.  So your final statement should be

dev.off()


Charles Annis, P.E.

Charles.Annis at StatisticalEngineering.com
phone: 561-352-9699
eFax:  614-455-3265
http://www.StatisticalEngineering.com
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Smith, Phil
Sent: Friday, February 17, 2006 8:40 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Windows metafile problem

Hi All:

I'm using win.metafile() to produce windows metafiles. 

When I use Word to insert the wmf picture, Word gives an error!

I did my homework in posting this question, and couldn't find a fix.

Any suggestions?

Phil Smith
CDC

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From coforfe at gmail.com  Fri Feb 17 16:24:14 2006
From: coforfe at gmail.com (Carlos Ortega)
Date: Fri, 17 Feb 2006 16:24:14 +0100
Subject: [R] Grouping and Averaging in Table
In-Reply-To: <BFE24A36-B282-4317-99F8-5070122CDF67@gmail.com>
References: <BFE24A36-B282-4317-99F8-5070122CDF67@gmail.com>
Message-ID: <7b18cd4d0602170724o6e5ab5c5s23a61213ff105060@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060217/6658fbc6/attachment.pl

From jholtman at gmail.com  Fri Feb 17 16:26:00 2006
From: jholtman at gmail.com (jim holtman)
Date: Fri, 17 Feb 2006 10:26:00 -0500
Subject: [R] Grouping and Averaging in Table
In-Reply-To: <BFE24A36-B282-4317-99F8-5070122CDF67@gmail.com>
References: <BFE24A36-B282-4317-99F8-5070122CDF67@gmail.com>
Message-ID: <644e1f320602170726h5916f682ma08cc6fa4a4bd3ee@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060217/42be558c/attachment.pl

From peter at prainvestment.com  Fri Feb 17 16:38:53 2006
From: peter at prainvestment.com (Peter Arnold)
Date: Fri, 17 Feb 2006 10:38:53 -0500
Subject: [R] Basic R Problem
Message-ID: <E1FA7h7-0008Vh-UJ@host.darlingcreativegroup.com>


> To: Anyone Who Can Help

I am new to R and am trying to install a couple of packages but receive
this warning/error message.  Please help by providing suggestions or
solutions to this problem


>> chooseCRANmirror()
>> utils:::menuInstallPkgs()
> Warning: unable to access index for repository
> http://www.ibiblio.org/pub/languages/R/CRAN/bin/windows/contrib/2.2
> Warning: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.2
> Error in install.packages(NULL, .libPaths()[1], dependencies = TRUE,
> type = type) :
>         no packages were specified


Best regards,



Peter Arnold, CFA
President
PRA Investment Counsel, Inc.
704-341-8193
www.prainvestment.com



From expiregmane1104.m.cudgle at neverbox.com  Fri Feb 17 16:45:44 2006
From: expiregmane1104.m.cudgle at neverbox.com (Frank Samuelson)
Date: Fri, 17 Feb 2006 10:45:44 -0500
Subject: [R] using kernel density estimates to infer mode of distribution
In-Reply-To: <20060216102841.0997c0b4.azzalini@stat.unipd.it>
References: <5.2.1.1.2.20060215172856.0127c948@postoffice9.mail.cornell.edu>
	<20060216102841.0997c0b4.azzalini@stat.unipd.it>
Message-ID: <dt4r3c$gma$1@sea.gmane.org>

A  density() fit calls the eval x and estimate y:
fit<-density(data)
plot(fit$x,fit$y)


Adelchi Azzalini wrote:
> On Wed, 15 Feb 2006 18:28:25 -0500, Dan Rabosky wrote:
> 
> DR> 
> DR>  Is it possible to use "density" or another kernel density
> DR>  estimator to  identify the mode of a distribution?  When I use
> DR>  'density', the resulting 
> 
> a simple option is of the form
>    fit$eval[fit$estimate==max(fit$estimate)]
> assuming that fit$eval is the vector of evaluation points,
> and fit$estimate the corrisponding density estimates (this is
> the sort of output produced by sm.density)
> 
> Here I have assumed there is single mode and we are in the scalar
> case, for simplicity. Some variant required in the more general case.
> 
> 
> best regards,
> 
> Adelchi Azzalini



From leinweber at neuro.mpg.de  Fri Feb 17 17:26:35 2006
From: leinweber at neuro.mpg.de (Marcus Leinweber)
Date: Fri, 17 Feb 2006 17:26:35 +0100
Subject: [R] how to clear screen in R-console?
Message-ID: <059DE74C2765E04284021ACFDB7A22DD8765D8@s6.neuro.mpg.de>

have already tried this?

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/55752.html

m.


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Michael
> Sent: Thursday, February 16, 2006 9:23 PM
> To: Henrik Bengtsson
> Cc: R-help at stat.math.ethz.ch
> Subject: Re: [R] how to clear screen in R-console?
> 
> I am actually using Rgui on Windows...
> 
> What can I do?
> 
> There is no way to programmatically clear screen?
>



From admin at biostatistic.de  Fri Feb 17 17:33:16 2006
From: admin at biostatistic.de (Knut Krueger)
Date: Fri, 17 Feb 2006 17:33:16 +0100
Subject: [R] showing the integrated number by point size
Message-ID: <43F5FACC.1080804@biostatistic.de>

Is there any function to show the points like this example of SPSS?

http://biostatistic.de/temp/reg.jpg

The point size should represent the number of data at this point.

with regards
Knut Krueger



From aa at tango.stat.unipd.it  Fri Feb 17 17:38:25 2006
From: aa at tango.stat.unipd.it (Adelchi Azzalini)
Date: Fri, 17 Feb 2006 17:38:25 +0100
Subject: [R] using kernel density estimates to infer mode of distribution
In-Reply-To: <dt4r3c$gma$1@sea.gmane.org>
References: <5.2.1.1.2.20060215172856.0127c948@postoffice9.mail.cornell.edu>
	<20060216102841.0997c0b4.azzalini@stat.unipd.it>
	<dt4r3c$gma$1@sea.gmane.org>
Message-ID: <20060217163825.GA27485@tango.stat.unipd.it>

On Fri, Feb 17, 2006 at 10:45:44AM -0500, Frank Samuelson wrote:
> A  density() fit calls the eval x and estimate y:
> fit<-density(data)
> plot(fit$x,fit$y)
> 
> 

in my earlier message, I explained that I was referring to the
ingredients names produced ny sm.density (of package sm);
in case some other function is used, eg density(), then
a little adjustment of names is required

AA

> Adelchi Azzalini wrote:
> > On Wed, 15 Feb 2006 18:28:25 -0500, Dan Rabosky wrote:
> > 
> > DR> 
> > DR>  Is it possible to use "density" or another kernel density
> > DR>  estimator to  identify the mode of a distribution?  When I use
> > DR>  'density', the resulting 
> > 
> > a simple option is of the form
> >    fit$eval[fit$estimate==max(fit$estimate)]
> > assuming that fit$eval is the vector of evaluation points,
> > and fit$estimate the corrisponding density estimates (this is
> > the sort of output produced by sm.density)
> > 
> > Here I have assumed there is single mode and we are in the scalar
> > case, for simplicity. Some variant required in the more general case.
> > 
> > 
> > best regards,
> > 
> > Adelchi Azzalini
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Adelchi Azzalini  <azzalini at stat.unipd.it>
Dipart.Scienze Statistiche, Universit?? di Padova, Italia
tel. +39 049 8274147,  http://azzalini.stat.unipd.it/



From ggrothendieck at gmail.com  Fri Feb 17 17:41:28 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 17 Feb 2006 11:41:28 -0500
Subject: [R] how to clear screen in R-console?
In-Reply-To: <059DE74C2765E04284021ACFDB7A22DD8765D8@s6.neuro.mpg.de>
References: <059DE74C2765E04284021ACFDB7A22DD8765D8@s6.neuro.mpg.de>
Message-ID: <971536df0602170841o204a86e5rc775bc74fc378e83@mail.gmail.com>

Here is a translation of Norm Olsen's vbscript code into pure R.
This is intended for use with the Windows Rgui interface.

cls <- function() {
	require(RDCOMClient)
	wsh <- COMCreate("Wscript.Shell")
	wsh$SendKeys("\014")
	invisible(wsh)
}
cls()  # invoke



On 2/17/06, Marcus Leinweber <leinweber at neuro.mpg.de> wrote:
> have already tried this?
>
> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/55752.html
>
> m.
>
>
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Michael
> > Sent: Thursday, February 16, 2006 9:23 PM
> > To: Henrik Bengtsson
> > Cc: R-help at stat.math.ethz.ch
> > Subject: Re: [R] how to clear screen in R-console?
> >
> > I am actually using Rgui on Windows...
> >
> > What can I do?
> >
> > There is no way to programmatically clear screen?
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Bernhard_Pfaff at fra.invesco.com  Fri Feb 17 17:42:24 2006
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Fri, 17 Feb 2006 16:42:24 -0000
Subject: [R] Basic R Problem
Message-ID: <25D1C2585277D311B9A20000F6CCC71B077C041E@DEFRAEX02>

Hello Peter,

in case your OS is windows and you connect to the Internet via a
Proxy-Server, you can/should set --internet2 in properties of the R icon on
your desktop. See the FAQ for more on this topic.

Bernhard

-----Urspr??ngliche Nachricht-----
Von: Peter Arnold [mailto:peter at prainvestment.com] 
Gesendet: Freitag, 17. Februar 2006 16:39
An: r-help at stat.math.ethz.ch
Betreff: [R] Basic R Problem


> To: Anyone Who Can Help

I am new to R and am trying to install a couple of packages but receive
this warning/error message.  Please help by providing suggestions or
solutions to this problem


>> chooseCRANmirror()
>> utils:::menuInstallPkgs()
> Warning: unable to access index for repository
> http://www.ibiblio.org/pub/languages/R/CRAN/bin/windows/contrib/2.2
> Warning: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.2
> Error in install.packages(NULL, .libPaths()[1], dependencies = TRUE,
> type = type) :
>         no packages were specified


Best regards,



Peter Arnold, CFA
President
PRA Investment Counsel, Inc.
704-341-8193
www.prainvestment.com

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
*****************************************************************
Confidentiality Note: The information contained in this mess...{{dropped}}



From Soren.Hojsgaard at agrsci.dk  Fri Feb 17 17:43:33 2006
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Fri, 17 Feb 2006 17:43:33 +0100
Subject: [R] showing the integrated number by point size
References: <43F5FACC.1080804@biostatistic.de>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC038781CF@DJFPOST01.djf.agrsci.dk>

If number is the number of points, I guess you can write 
plot(...., lwd=number)

________________________________

Fra: r-help-bounces at stat.math.ethz.ch p?? vegne af Knut Krueger
Sendt: fr 17-02-2006 17:33
Til: R-help
Emne: [R] showing the integrated number by point size



Is there any function to show the points like this example of SPSS?

http://biostatistic.de/temp/reg.jpg

The point size should represent the number of data at this point.

with regards
Knut Krueger

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From B.Rowlingson at lancaster.ac.uk  Fri Feb 17 17:44:59 2006
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 17 Feb 2006 16:44:59 +0000
Subject: [R] showing the integrated number by point size
In-Reply-To: <43F5FACC.1080804@biostatistic.de>
References: <43F5FACC.1080804@biostatistic.de>
Message-ID: <43F5FD8B.7010909@lancaster.ac.uk>

Knut Krueger wrote:
> Is there any function to show the points like this example of SPSS?
> 
> http://biostatistic.de/temp/reg.jpg
> 
> The point size should represent the number of data at this point.
> 

plot with cex for the size and pch for solid points:
   xys=data.frame(x=c(0,0,1,2,2,3,3),y=c(0,1,1,1,2,2,3),s=c(4,1,2,1,1,1,2))

plot(xys$x,xys$y,cex=xys$s,pch=19)

or 'symbols', but you need to scale things a bit:

symbols(xys$x,xys$y,circles=xys$s/15,inches=F,bg="black")

Of course if your data is just (x,y) pairs and you want to work out the 
counts then that's another problem...

Barry



From ripley at stats.ox.ac.uk  Fri Feb 17 17:51:06 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 17 Feb 2006 16:51:06 +0000 (GMT)
Subject: [R] Basic R Problem
In-Reply-To: <E1FA7h7-0008Vh-UJ@host.darlingcreativegroup.com>
References: <E1FA7h7-0008Vh-UJ@host.darlingcreativegroup.com>
Message-ID: <Pine.LNX.4.64.0602171650270.30432@gannet.stats.ox.ac.uk>

You need to select a repository that is not broken, as that one appears to 
be (and has been reported before to be).

On Fri, 17 Feb 2006, Peter Arnold wrote:

>
>> To: Anyone Who Can Help
>
> I am new to R and am trying to install a couple of packages but receive
> this warning/error message.  Please help by providing suggestions or
> solutions to this problem
>
>
>>> chooseCRANmirror()
>>> utils:::menuInstallPkgs()
>> Warning: unable to access index for repository
>> http://www.ibiblio.org/pub/languages/R/CRAN/bin/windows/contrib/2.2
>> Warning: unable to access index for repository
>> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.2
>> Error in install.packages(NULL, .libPaths()[1], dependencies = TRUE,
>> type = type) :
>>         no packages were specified
>
>
> Best regards,
>
>
>
> Peter Arnold, CFA
> President
> PRA Investment Counsel, Inc.
> 704-341-8193
> www.prainvestment.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mschwartz at mn.rr.com  Fri Feb 17 17:52:21 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Fri, 17 Feb 2006 10:52:21 -0600
Subject: [R] showing the integrated number by point size
In-Reply-To: <43F5FACC.1080804@biostatistic.de>
References: <43F5FACC.1080804@biostatistic.de>
Message-ID: <1140195141.4543.12.camel@localhost.localdomain>

On Fri, 2006-02-17 at 17:33 +0100, Knut Krueger wrote:
> Is there any function to show the points like this example of SPSS?
> 
> http://biostatistic.de/temp/reg.jpg
> 
> The point size should represent the number of data at this point.
> 
> with regards
> Knut Krueger

There are a couple of functions in CRAN packages I believe that will do
bubble plots.

You might want to do:

  RSiteSearch("Bubble Plot")

which should help.

A better option from a visualization perspective would be 

  ?sunflowerplot

HTH,

Marc Schwartz



From spencer.graves at pdf.com  Fri Feb 17 17:56:54 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 17 Feb 2006 08:56:54 -0800
Subject: [R] no convergence using lme
In-Reply-To: <000001c631d4$2326c910$0ce15e81@dg3qn71s>
References: <000001c631d4$2326c910$0ce15e81@dg3qn71s>
Message-ID: <43F60056.8090505@pdf.com>

	  Without a simple, self-contained, reproducible example, it is 
impossible to say for sure why "lme" did not converge for you.  However, 
if age were constant within animal, that would surely give the symptom 
you describe.  I might try computing the difference in the range within 
subject, something like the following:

### NOT TESTED:
tapply(VC$Age, VC$animal, function(x)diff(range(x)))

	  If these numbers are all 0, that should answer your question.  If 
not, one must dig deeper.  For example, do you get the same error with 
Outcome~1, etc.?

	  hope this helps.
	  spencer graves

Margaret Gardiner-Garden wrote:

> Hi.  I was wondering if anyone might have some suggestions about how I can
> overcome a problem of   "iteration limit reached without convergence" when
> fitting a mixed effects model.
> 
>  
> 
> In this study:
> 
> Outcome is a measure of heart action
> 
> Age is continuous (in weeks)
> 
> Gender is Male or Female (0 or 1)
> 
> Genotype is Wild type or knockout (0 or 1)
> 
> Animal is the Animal ID as a factor
> 
> Gender.Age is Gender*Age
> 
> Genotype.Age is Genotype*Age
> 
> Gender.Genotype.Age is Gender*Genotype*Age
> 
>  
> 
> If I have the intercept (but not the slope) as a random effect the fit
> converges OK
> 
> fit1 <- lme(Outcome~Age + Gender + Genotype  + Gender.Age + Genotype.Age +
> Gender.Genotype.Age,
> 
>                   random=~1|Animal, data=VC)
> 
>  
> 
>  
> 
> If I have the slope (but not the intercept) as a random factor it converges
> OK
> 
> fit2 <- lme(LVDD~Age + Gender + Genotype + Gender.Age + Genotype.Age
> +Gender.Genotype.Age,
> 
>                   random=~Age-1|Animal, data=VC)
> 
>  
> 
>  
> 
> If I have both slope and intercept as random factors it won't converge
> 
> fit3 <- lme(LVDD~Age + Gender + Genotype + Gender.Age + Genotype.Age +
> Gender.Genotype.Age,
> 
>                   random=~ Age|Animal, data=VC)
> 
> Gives error:
> 
> Error in lme.formula(LVDD ~ Age + Gender + Genotype + Gender.Age +
> Genotype.Age +  : 
> 
>       iteration limit reached without convergence (9)
> 
>  
> 
>  
> 
>  
> 
> If I try to increase the number of iterations (even to 1000) by increasing
> maxIter it still doesn't converge
> 
>  
> 
> fit <- lme(LVDD~Age + Gender + Genotype + Gender.Age + Genotype.Age +
> Gender.Genotype.Age,
> 
> +                   random=~ Age|Animal, data=VC, control=list(maxIter=1000,
> msMaxIter=1000, niterEM=1000))
> 
>  
> 
> NB.  I changed maxIter  value in isolation as well as together with two
> other controls with "iter" in their name (as shown above) just to be sure (
> as I don't understand how the actual iterative  fitting of the model works
> mathematically)  
> 
> 
> 
>  
> 
> I was wondering if anyone knew if there was anything else in the control
> values I should try changing.   
> 
> Below are the defaults..
> 
> lmeControl
> 
> function (maxIter = 50, msMaxIter = 50, tolerance = 1e-06, niterEM = 25, 
> 
>     msTol = 1e-07, msScale = lmeScale, msVerbose = FALSE, returnObject =
> FALSE, 
> 
>    gradHess = TRUE, apVar = TRUE, .relStep = (.Machine$double.eps)^(1/3), 
> 
>    minAbsParApVar = 0.05, nlmStepMax = 100, optimMethod = "BFGS", 
> 
>     natural = TRUE)
> 
>  
> 
> I was reading on the R listserve that lmer from the lme4 package may be
> preferable to lme (for convergence problems) but lmer seems to need you to
> put in starting values and I'm not sure how to go about chosing them.  I was
> wondering if anyone had experience with lmer that might help me with this?
> 
>  
> 
> Thanks again for any advice you can provide.
> 
>  
> 
> Regards
> 
> Marg
> 
>  
> 
>  
> 
> Dr Margaret Gardiner-Garden
> 
> Garvan Institute of Medical Research
> 
> 384 Victoria Street
> 
> Darlinghurst Sydney
> 
> NSW 2010 Australia
> 
>  
> 
> Phone: 61 2 9295 8348
> 
> Fax: 61 2 9295 8321
> 
>  
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ritz at kvl.dk  Fri Feb 17 17:58:48 2006
From: ritz at kvl.dk (Christian Ritz)
Date: Fri, 17 Feb 2006 17:58:48 +0100
Subject: [R] Svar: Re:  lme, nlsList, nlsList.selfStart
Message-ID: <43F60EFE02000006002A3173@gwia.kvl.dk>

Hi Patrick,

this is not a solution to your problems with getting 'nls' to work, but
may still be of some use to you.

The package 'drc' on CRAN offers an alternative to 'nls'. See the
following example using your data frame mydata2.


library(drc)


## Defining the non-linear function
"fct1" <- function(dose, parm)
{
   100 * exp(parm[,1]+parm[,2]-parm[,3]) *
   (exp(-exp(parm[,1])*dose)-exp(-exp(parm[,2])*dose))
/(exp(parm[,2])-exp(parm[,1]))
}


## Fitting the model (for details see ?multdrc)
model1 <- multdrc(Conc+1~Tps, Organ, data=mydata2, fct=list(fct1, NULL,
c("lKe","lKa","lCl")), startVal=c(-2.77, -2.77, -2.77, -1.41, -1.41,
-1.41, -1.13, -1.13, -1.13))

summary(model1)  # a lot of parameters could be 0!

plot(model1, log="")

## Plots for each level of Organ
plot(model1, level="Carc", ylim=c(0,5), log="")
plot(model1, level="Foie", log="")
plot(model1, level="TD", ylim=c(0,6), log="")


## Fitting the model with a transform-both-sides Box-Cox transformation
## - in an attempt to adjust for variance inhomogeneity (visible in the
residual plot)
model2 <- multdrc(Conc+1~Tps, Organ, data=mydata2, fct=list(fct1, NULL,
c("lKe","lKa","lCl")), startVal=c(-2.77, -2.77, -2.77, -1.41, -1.41,
-1.41, -1.13, -1.13, -1.13),boxcox=T)

summary(model2)




Hope this is of help to you!?

Best regards

Christian



From gchappi at gmail.com  Fri Feb 17 18:11:10 2006
From: gchappi at gmail.com (Hans-Peter)
Date: Fri, 17 Feb 2006 18:11:10 +0100
Subject: [R] Basic R Problem
In-Reply-To: <E1FA7h7-0008Vh-UJ@host.darlingcreativegroup.com>
References: <E1FA7h7-0008Vh-UJ@host.darlingcreativegroup.com>
Message-ID: <47fce0650602170911l3d221195g@mail.gmail.com>

2006/2/17, Peter Arnold <peter at prainvestment.com>:
>
> > To: Anyone Who Can Help
>
> >> chooseCRANmirror()
> >> utils:::menuInstallPkgs()
> > Warning: unable to access index for repository
> > http://www.ibiblio.org/pub/languages/R/CRAN/bin/windows/contrib/2.2
> > Warning: unable to access index for repository
> > http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.2
> > Error in install.packages(NULL, .libPaths()[1], dependencies = TRUE,
> > type = type) :
> >         no packages were specified

I cannot help you, but maybe I can help you to help yourself:

1) go to the archiv: http://tolstoy.newcastle.edu.au/~rking/R/about.html
2) I tried with the search term: "Warning: unable to access index for
repository"
3) in the result page I took the first entry:
(http://tolstoy.newcastle.edu.au/~rking/R/help/05/10/13619.html)
4) which gave me the answer:
>I expect you need to set a proxy. This is covered in the rw-FAQ that
we do ask you to >read before posting. See the item
>
>         The internet download functions fail.

5) The rw-FAQ is the Windows FAQ. As I didn't remember where it is, I
just looked at the posting guide
http://www.R-project.org/posting-guide.html which gave me:

6) http://cran.r-project.org/bin/windows/base/rw-FAQ.html or more exactly:
http://cran.r-project.org/bin/windows/base/rw-FAQ.html#The-internet-download-functions-fail_002e

I don't know if this helps, but I think these are the steps that you
should/could do for yourself before asking on the maillist. Of course
it's not always as simple to get the right answers out of the archiv.

--
Regards,
Hans-Peter



From ml-r-help at epigenomics.com  Fri Feb 17 18:17:52 2006
From: ml-r-help at epigenomics.com (ml-r-help@epigenomics.com)
Date: 17 Feb 2006 18:17:52 +0100
Subject: [R] EpiR.base - namespace changes
Message-ID: <dt50g0$8da$1@perl.epigenomics.epi>



Hi,

as some might have noticed over the last few days a variing but large number of
unit tests failed. This should now be resolved.

The changes made to the namespace exports aim at provideing a clear,
maintainable (and thus minimal) set of public methods availabel for use by other
packages and at the R prompt.
Changes are motivated by recent changes in R devel which indicate a series of
issues we have to overcome for the R 2.3.0 release.

For the future, please
 - check the NAMESPACE file to find out which functions and methods are public
   and use them, only.
   (If you have to rely on a private method do so via the prefix EpiR.base:::
    although this is not advised and not guaranteed to work at all times.)

  - make an effort to check for meaningful method names for new methods,
    check if a similar name has already been in use for the same task and
    reuse it in order to keep the method list concise.

Package maintainers for the remaining packages should update their NAMESPACE
files over the next few weeks.


Regards,

  Matthias

-- 
Matthias Burger                     Project Manager/ Biostatistician
Epigenomics AG    Kleine Praesidentenstr. 1    10178 Berlin, Germany
phone:+49-30-24345-371                          fax:+49-30-24345-555
http://www.epigenomics.com           matthias.burger at epigenomics.com



From spencer.graves at pdf.com  Fri Feb 17 18:20:08 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 17 Feb 2006 09:20:08 -0800
Subject: [R] nonlinear model:  pseudo-design matrix
In-Reply-To: <43F579E3.6060408@stats.waikato.ac.nz>
References: <43F13B78.2050601@stats.waikato.ac.nz> <43F55054.30308@pdf.com>
	<43F579E3.6060408@stats.waikato.ac.nz>
Message-ID: <43F605C8.6080209@pdf.com>

Hi, Murray:

	  When I have problems with nonconvergence of nls, I often
move the problem to "optim(..., hessian=TRUE)".  Even if the larger 
model is overparameterized and the hessian is singular, I optim usually 
returns an answer from which I can then compute 2*log(likelihood ratio). 
  Moreover, the hessian will help me diagnose the problem.  If it were 
my problem today, I'd try the following:

	  (1) If there are substantial differences in the diagonal elements of 
the hessian, it suggests the scaling should be adjusted.  Not too long 
ago, someone else suggested that this could be done within optim via the 
argument control = list(parscale=...).  I have yet to try that, but I 
think it should work fine.

	  (2) If the diagonal elements of the hessian do not differ by more 
than a couple orders of magnitude, then I'd try eigen(fit$hessian, 
symmetric=TRUE).  The relative magnitudes of the eigenvalues will expose 
the effective numer of paramaters that can be estimated, and the 
eigenvectors associated with the smallest eigenvalues can help one 
diagnose the problem.

	  hope this helps.
	  spencer graves

Murray Jorgensen wrote:

> Hi Spencer,
> 
> you were the only one to reply. Yes I am aware of the intrinsic / 
> parameter effects distinction and the advantages of LR tests and 
> profiling over Wald tests based on the local curvature of the 
> loglikelihood surface at the larger of two models being compared. My 
> situation is that I am comparing two nested models both of which have 
> uncomfortably many parameters for the amount of data available. I am 
> able to fit the smaller of the two models but not the larger. In this 
> situation neither the the Wald nor the LR test is available to me but 
> the score test (a.k.a. the Lagrange Multiplier test) is available to me 
> because it is based on the loglikelihood gradient at the smaller model.
> 
> I have been able to carry out the test by extracting
> 
> X <- smaller.nls$m$gradient()
> 
> and obtaining the extra columns of X for the parameters in larger but 
> not in smaller by numerical differentiation. It seems that there should 
> be some way of obtaining the extra columns without recourse to numerical 
> differentiation, though.
> 
> Cheers,  Murray Jorgensen
> 
> Spencer Graves wrote:
> 
>>       There doubtless is a way to extract the gradient information you 
>> desire, but have you considered profiling instead?  Are you familiar 
>> with the distinction between intrinsic and parameter effects 
>> curvature?  In brief, part of the nonlinearities involved in nonlinear 
>> least squares are intrinsic to the problem, and part are due to the 
>> how the problem is parameterized.  If you change the parameterization, 
>> you change the parameter effects curvature, but the intrinsic 
>> curvature remains unchanged.  Roughly 30 years ago, Doug Bates and Don 
>> Watts reanalized a few dozen published nonlinear regression fits, and 
>> found that in all but perhaps one or two, the parameter effects were 
>> dominant and the intrinsic curvature was negligible.  See Bates and 
>> Watts (1988) Nonlinear Regression Analysis and Its Applications 
>> (Wiley) or Seber and Wild (1989) Nonlinear Regression (Wiley).
>>
>>       Bottom line:
>>
>>       1.  You will always get more accurate answers from profiling 
>> than from the Wald "pseudodesign matrix" approach.  Moreover, often 
>> the differences are dramatic.
>>
>>       2.  I just did RSiteSearch("profiling with nls").  The first hit 
>> was 
>> "http://finzi.psych.upenn.edu/R/library/stats/html/profile.nls.html". 
>> If this is not satisfactory, please explain why.
>>
>>       hope this helps.
>>       spencer graves
>>
>> Murray Jorgensen wrote:
>>
>>> Given a nonlinear model formula and a set of values for all the
>>> parameters defining a point in parameter space, is there a neat way to
>>> extract the pseudodesign matrix of the model at the point? That is the
>>> matrix of partial derivatives of the fitted values w.r.t. the parameters
>>> evaluated at the point.
>>>
>>> (I have figured out how to extract the gradient information from an 
>>> nls fitted model using the nlsModel part, but I wish to implement a 
>>> score test, so I need to be able to extract the information at points 
>>> other than the mle.)
>>>
>>> Thanks, Murray Jorgensen
> 
>



From spencer.graves at pdf.com  Fri Feb 17 18:23:24 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 17 Feb 2006 09:23:24 -0800
Subject: [R] lme, nlsList, nlsList.selfStart
In-Reply-To: <43F5AE78.7000908@univ-fcomte.fr>
References: <43EEE758.2050408@univ-fcomte.fr> <43F522FF.9060402@pdf.com>
	<43F59BA9.1010106@univ-fcomte.fr>
	<Pine.LNX.4.64.0602171040190.13399@gannet.stats.ox.ac.uk>
	<43F5AE78.7000908@univ-fcomte.fr>
Message-ID: <43F6068C.1030900@pdf.com>

	  Have you tried making mydata2$Dose the same length as everything else?

	  spencer graves

Patrick Giraudoux wrote:

> Well, right, Dose was indeed in the global environment and not in the 
> data.frame. Changing it with
> 
> mydata2$Dose<-100 # the real dose at the beginning of the experiment
> 
> improves the thing in a sense... but I face a new error:
> 
> mymod3<-nlsList(Conc+1 ~ Dose * exp(lKe+lKa-lCl) * 
> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)) | Organ,
> data=mydata2,
> start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
> )
> 
> Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
>        Non-numeric argument to mathematical function
> Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
>        Non-numeric argument to mathematical function
> Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
>        Non-numeric argument to mathematical function
> 
> I have checked the variables in the data.frame with:
> 
>  > sapply(mydata2,is.factor)
>  Tps  Conc Organ  Dose
> FALSE FALSE  TRUE FALSE
>  > sapply(mydata2,is.character)
>  Tps  Conc Organ  Dose
> FALSE FALSE FALSE FALSE
> 
> So everything looks OK on this side...
> 
> Furthermore, I have still this "old" error intact:
> 
>  > mymod4<-nlsList(SSfol,data=mydata2)
> Error in eval(expr, envir, enclos) : object "input" not found
> Error in eval(expr, envir, enclos) : object "input" not found
> Error in eval(expr, envir, enclos) : object "input" not found
> 
> 
> I am really sorry for calling help and boring everybody on this likely 
> trivial issue (this looks like asking a community to participate to 
> debogging line by line, a shame!!!), but I must admit that I am really 
> lost...
> 
> Thanks for your concern,
> 
> Kind regards,
> 
> Patrick
> 
> 
> Prof Brian Ripley a ??crit :
> 
>> We don't have Dose, and I think that is where the error lies.  If Dose 
>> were part of mydata2, this is likely to work, but otherwise it is Dose 
>> which has the wrong length.
>>
>> ?nlsList says
>>
>>     data: a data frame in which to interpret the variables named in
>>           'model'.
>>
>> and it means it: you must get all the variables from there.
>>
>>
>> On Fri, 17 Feb 2006, Patrick Giraudoux wrote:
>>
>>> Spencer,
>>>
>>> Thanks for the hint. I did not dare to bore people with the full data
>>> set and though that this kind of error may have been trivial and often
>>> encountered (so leading to a short answer), even though I did not see
>>> related messages on the r-help list. I already did the checks suggested
>>> before posting, and was aware of the possible confusion between 1 and l
>>> (actually the variable names were not given by myself).
>>>
>>> It seems that the trouble comes when the grouping variable "Organ" is
>>> used. The best (?) I can do  is to dump the data.frame here below.
>>>
>>> With this example, one can get exactly the same errors:
>>>
>>> mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) *
>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>    data=mydata2,
>>>    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>    )
>>>
>>> ... works well!!!
>>>
>>> but we get then:
>>>
>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)) | Organ,
>>>    data=mydata2,
>>>    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>    )
>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>> extranames,  :
>>>        variable lengths differ
>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>> extranames,  :
>>>        variable lengths differ
>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>> extranames,  :
>>>        variable lengths differ
>>>
>>>
>>> > mymod4<-nlsList(SSfol,data=mydata2)
>>> Error in eval(expr, envir, enclos) : object "input" not found
>>> Error in eval(expr, envir, enclos) : object "input" not found
>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>
>>>
>>> Sorry and apologise for the inconvenience met,
>>>
>>> Kind regards,
>>>
>>> Patrick
>>>
>>>
>>>
>>> # data.frame just to copy and past into R
>>>
>>> "mydata2" <-
>>> structure(list(Tps = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3,
>>> 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,
>>> 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9,
>>> 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 14,
>>> 14, 14, 14, 14, 17, 17, 17, 17, 17, 20, 20, 20, 20, 25, 28, 29,
>>> 50, 50, 50, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
>>> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4,
>>> 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,
>>> 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10,
>>> 10, 10, 11, 11, 11, 11, 11, 11, 14, 14, 14, 14, 14, 17, 17, 17,
>>> 17, 17, 20, 20, 20, 20, 25, 28, 29, 50, 50, 50, 136, 136, 136,
>>> 136, 136, 136, 136, 136, 136, 136, 1, 1, 1, 1, 1, 1, 2, 2, 2,
>>> 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,
>>> 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8,
>>> 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,
>>> 11, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 20, 20, 20, 20,
>>> 25, 28, 29, 50, 50, 50, 136, 136, 136, 136, 136, 136, 136, 136,
>>> 136, 136), Conc = c(0, 0, 0, 0, 0, 0, 0, 0.807852503274902,
>>> 0.204371494701886,
>>> 0.579222129993907, 0.989062273721619, 0, 1.11728297897571,
>>> 1.41057428121324,
>>> 0.888883702851307, 1.259907624008, 1.45753269675829, 1.07077516747401,
>>> 0.843279379, 0, 0.763110069196737, 1.11297791434297, 1.10087763997637,
>>> 0.946929594501016, 1.33112168, 0.654041755, 0.694167499, 1.289548703,
>>> 1.117139864, 0.807196192, 0.720221376552025, 0.560082823, 0.476583438,
>>> 2.590855204, 0.51510972, 1.072946887, 0.537999938614396, 
>>> 0.886684225905255,
>>> 0.630178116793598, 1.31534758842196, 1.33333958571746, 
>>> 0.922032210748255,
>>> 0.429930193046174, 1.35881467717335, 0.790045927902363, 
>>> 1.22484702570724,
>>> 0.808104508207897, 1.31185966817903, 1.51837686425553, 1.74105163638734,
>>> 1.80365598487402, 1.13240352674377, 1.50086243061644, 2.06355364280445,
>>> 0.439350890906039, 1.54692793444949, 1.78758216051046, 1.09043400023239,
>>> 0.811328376840514, 0.459192443530981, 0.695333473157298, 
>>> 0.387995007681174,
>>> 0.784627063444921, 1.02282256375842, 0.382687104107726, 
>>> 0.554290634950242,
>>> 0.130420456296453, 0.324194753224919, 0.31106140274139, 
>>> 0.513473505828888,
>>> 0.878620320248701, 1.18404358659996, 0.136926837896477, 0, 0,
>>> 0.835588760032974, 0.558617235576616, 1.21002805866839, 
>>> 0.769381068031404,
>>> 1.04514254228094, 0.373251847173678, 0.389005898972802, 
>>> 0.183141006154896,
>>> 0.223596336820146, 0.315526423315647, 0.0930349732768131,
>>> 0.169959185212759,
>>> 0.161878841748425, 0, 0.0483041009105874, 0, 0, 0, 0.0777005553478052,
>>> 0, 0.153175826795441, 0.0428171049833677, 0, 0, 0, 0, 0, 0, 0,
>>> 0, 0, 0, 26.564295705327, 5.5893744508169, 7.22612934071834,
>>> 36.6563989567777, 0, 28.8967184437329, 28.4030370337251, 
>>> 28.0886043901352,
>>> 26.1230935842208, 28.8895673910072, 42.6814210131968, 32.3555695551062,
>>> 0.76883326657205, 34.6159136622156, 38.329242204291, 56.4476583636484,
>>> 26.6249506083603, 31.3001451026823, 23.7339071829084, 23.3702284599355,
>>> 36.669903715038, 44.7377244306005, 31.2079335923023, 32.8613384312272,
>>> 29.4259634309146, 45.6112405959009, 48.1231689836687, 55.0037961570027,
>>> 32.9822316456421, 20.0382768189682, 26.0986380308655, 28.8915584506145,
>>> 28.7949023823068, 30.0278417498425, 58.8089779973569, 20.3602570111197,
>>> 29.6269605259023, 28.4404986724604, 30.2165182590977, 19.9204461889074,
>>> 31.1019196559556, 30.3847467747055, 36.8726911479995, 51.0618036275519,
>>> 23.5408013442579, 36.6948355347593, 27.4753860809429, 24.1341667099646,
>>> 27.5411488989643, 35.9021799354022, 19.7417897046158, 31.1403887303244,
>>> 46.1743622734049, 34.8235854891765, 22.1714704189293, 33.6805966894274,
>>> 35.2814908686112, 42.9767437212852, 38.1264997164547, 5.3651357974451,
>>> 42.8990434918385, 25.4908883698364, 25.99649502, 36.4958105490917,
>>> 40.8004126550705, 5.36867162116895, 0.00898476265269363, 0,
>>> 27.6810997945798,
>>> 28.7918300045713, 45.7577183830352, 35.9276318604787, 34.9717618087238,
>>> 29.620354272564, 24.6537513599869, 13.5363982464958, 25.8289073574818,
>>> 12.0090406245759, 4.753436805, 11.849214652228, 8.41410147611612,
>>> 0, 1.80855352862552, 1.1987530031681, 1.01148025243171, 
>>> 0.495675369574172,
>>> 1.62701127228732, 0, 16.6288242287241, 1.23656061354912, 
>>> 0.323708776035328,
>>> 0, 0.566916625204436, 0, 0, 0, 0, 0, 0, 0, 2.53578781871283,
>>> 3.50083667130797, 0, 0.98049572179098, 0, 3.57129673217304,
>>> 2.77298867949388,
>>> 2.12302645642669, 4.11923869203499, 4.69069462193674, 2.8698666062651,
>>> 2.05079837323067, 0.0602771574448942, 5.96454350250626, 
>>> 2.26267114439802,
>>> 3.06911285674854, 2.04233129537404, 2.62181873844029, 1.51813653072598,
>>> 1.46193772981073, 2.69864635755833, 3.44016493913122, 2.50834832469627,
>>> 3.48170744166168, 1.00637581555435, 1.67065398473081, 4.18855363095027,
>>> 3.39649762611015, 1.72804613460423, 1.40053679329531, 2.37032387724109,
>>> 3.19332545080983, 2.49474373894248, 2.17800931288708, 2.7601484443213,
>>> 0.91266104095844, 1.93485048639199, 1.19692593420788, 1.79537330666258,
>>> 2.14020930767983, 3.0122526724942, 2.81112226980754, 3.54890724398174,
>>> 3.01022926452999, 2.38263226710738, 3.53569238341869, 3.47869329713911,
>>> 0.679333339820719, 2.4764260756438, 3.82615100065366, 2.20449890383871,
>>> 1.371303113329, 1.2427787019995, 1.73319133880954, 0.391268883238408,
>>> 1.73610193837913, 2.68494324646718, 1.77065393606844, 1.45079980147062,
>>> 0.763775702906329, 0.98566725668627, 0.37838763208699, 
>>> 0.841811919286804,
>>> 1.46436462204795, 1.98409602726, 0.507005887891038, 0.465515668274195,
>>> 0, 1.873365675227, 1.69023864630648, 2.65530855919137, 2.34392199908302,
>>> 1.61917643594837, 1.05165934333345, 0.564642823436471, 
>>> 0.121621029620328,
>>> 0.515007625737071, 0.524345809084086, 0.130898614090571, 
>>> 0.332427740242623,
>>> 0.110214989555118, 0, 0.128642193589, 0.119407067173878, 
>>> 0.128926224027295,
>>> 0.0622331866694357, 0.215645168287442, 0, 0.859343941945178,
>>> 0.0500810300696456, 0, 0, 0.0628746592609754), Organ =
>>> structure(as.integer(c(1,
>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3,
>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>> 2, 2, 2, 2, 2)), .Label = c("Carc", "TD", "Foie"), class = c("ordered",
>>> "factor"))), .Names = c("Tps", "Conc", "Organ"), row.names = c("1",
>>> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
>>> "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24",
>>> "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35",
>>> "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46",
>>> "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57",
>>> "58", "59", "60", "61", "62", "63", "64", "65", "66", "67", "68",
>>> "69", "70", "71", "72", "73", "74", "75", "76", "77", "78", "79",
>>> "80", "81", "82", "83", "84", "85", "86", "87", "88", "89", "90",
>>> "91", "92", "93", "94", "95", "96", "97", "98", "99", "100",
>>> "101", "102", "103", "104", "105", "106", "107", "108", "109",
>>> "110", "111", "112", "113", "114", "115", "116", "117", "118",
>>> "119", "120", "121", "122", "123", "124", "125", "126", "127",
>>> "128", "129", "130", "131", "132", "133", "134", "135", "136",
>>> "137", "138", "139", "140", "141", "142", "143", "144", "145",
>>> "146", "147", "148", "149", "150", "151", "152", "153", "154",
>>> "155", "156", "157", "158", "159", "160", "161", "162", "163",
>>> "164", "165", "166", "167", "168", "169", "170", "171", "172",
>>> "173", "174", "175", "176", "177", "178", "179", "180", "181",
>>> "182", "183", "184", "185", "186", "187", "188", "189", "190",
>>> "191", "192", "193", "194", "195", "196", "197", "198", "199",
>>> "200", "201", "202", "203", "204", "205", "206", "207", "208",
>>> "209", "210", "211", "212", "213", "214", "215", "216", "217",
>>> "218", "219", "220", "221", "222", "223", "224", "225", "226",
>>> "227", "228", "229", "230", "231", "232", "233", "234", "235",
>>> "236", "237", "238", "239", "240", "241", "242", "243", "244",
>>> "245", "246", "247", "248", "249", "250", "251", "252", "253",
>>> "254", "255", "256", "257", "258", "259", "260", "261", "262",
>>> "263", "264", "265", "266", "267", "268", "269", "270", "271",
>>> "272", "273", "274", "275", "276", "277", "278", "279", "280",
>>> "281", "282", "283", "284", "285", "286", "287", "288", "289",
>>> "290", "291", "292", "293", "294", "295", "296", "297", "298",
>>> "299", "300"), class = c("nfnGroupedData", "nfGroupedData", 
>>> "groupedData",
>>> "data.frame"), formula = quote(Conc ~ Tps | Organ), FUN = function (x)
>>> max(x, na.rm = TRUE), order.groups = TRUE)
>>>
>>>
>>>
>>>
>>> Spencer Graves a ??crit :
>>>
>>>>       Regarding the following:
>>>>
>>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>>      data=mydata,
>>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>         variable lengths differ
>>>>
>>>>
>>>>       This example is NOT self contained and is entirely too
>>>> complicated for me to try to replicate it myself in a reasonable
>>>> period of time.  I will therefore ask one short question:  Are all the
>>>> variable names in the "nlsList" call either columns of "mydata" or
>>>> parameters to be estimated and therefore spelled out in "start"?  If I
>>>> were you, I'd check this all very carefully, being especially careful
>>>> about the distinction between "lCl" and "lC1", in particular.
>>>>
>>>>       If you'd like further help with this, I suggest you try to find
>>>> the simplest possible example that generates problem you don't
>>>> understand, then try to recast that example into one that is
>>>> completely self contained, either a data set in the standard R or nlme
>>>> distribution  or numbers that one can generate with a very few lines
>>>> of code.  If you use random numbers, please "set.seed", to increase
>>>> your confidence that someone else will see what you see.  (And please
>>>> review the posting guide! "www.R-project.org/posting-guide.html".
>>>> Doing so may increase your chances of getting more useful information
>>>> more quickly.)
>>>>
>>>>       spencer graves
>>>>
>>>> Patrick Giraudoux wrote:
>>>>
>>>>> Dear listers,
>>>>>
>>>>> I am trying to fit a model using nlsList() using alternately a
>>>>> SSfol() selfstart function or its developped equivalent formulae.
>>>>>
>>>>> This preliminary trial works well
>>>>>
>>>>> mydata<-groupedData(Conc~Tps|Organ,data=mydata)
>>>>> mymod1<-nls(Conc~SSfol(Dose,Tps,lKe,lKa,lCl),data=mydata)
>>>>>
>>>>> as well as a developped form:
>>>>>
>>>>> mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>>     data=mydata,
>>>>>     start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>     )
>>>>>
>>>>> However when trying to fit the model with nlsList, I get:
>>>>>
>>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>>      data=mydata,
>>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>      )
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>         variable lengths differ
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>         variable lengths differ
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>         variable lengths differ
>>>>>
>>>>> Or specifying  the grouping factor explicitely:
>>>>>
>>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe))|Organ,
>>>>>      data=mydata,
>>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>      )
>>>>>
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>         variable lengths differ
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>         variable lengths differ
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>         variable lengths differ
>>>>>
>>>>>
>>>>> I cannot find out why the grouping factor cannot be used (it has the
>>>>> same length as the other variables...)
>>>>>
>>>>> Another strange thing occurs: in the example given in the help of
>>>>> nlsList.selfstart, the following command works  well:
>>>>>
>>>>>  fm1 <- nlsList(SSasympOff, CO2)
>>>>>
>>>>> However its seemingly equivalent applied to the case above fails:
>>>>>
>>>>> mymod4<-nlsList(SSfol,data=mydata)
>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>>
>>>>>
>>>>> Any hint/suggestion appreciated.
>>>>>
>>>>> Kind regards,
>>>>>
>>>>> Patrick Giraudoux
>>>>>
>>>>> ______________________________________________
>>>>> R-help at stat.math.ethz.ch mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide!
>>>>> http://www.R-project.org/posting-guide.html
>>>>
>>>>
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>>
>>
>



From ripley at stats.ox.ac.uk  Fri Feb 17 18:25:42 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 17 Feb 2006 17:25:42 +0000 (GMT)
Subject: [R] lme, nlsList, nlsList.selfStart
In-Reply-To: <43F6068C.1030900@pdf.com>
References: <43EEE758.2050408@univ-fcomte.fr> <43F522FF.9060402@pdf.com>
	<43F59BA9.1010106@univ-fcomte.fr>
	<Pine.LNX.4.64.0602171040190.13399@gannet.stats.ox.ac.uk>
	<43F5AE78.7000908@univ-fcomte.fr> <43F6068C.1030900@pdf.com>
Message-ID: <Pine.LNX.4.64.0602171724510.31301@gannet.stats.ox.ac.uk>

On Fri, 17 Feb 2006, Spencer Graves wrote:

> 	  Have you tried making mydata2$Dose the same length as everything 
> else?

[<- does that for you: all columns in a data frame must be the same 
length.  Read on in your inbox for the solution.

>
> 	  spencer graves
>
> Patrick Giraudoux wrote:
>
>> Well, right, Dose was indeed in the global environment and not in the 
>> data.frame. Changing it with
>> 
>> mydata2$Dose<-100 # the real dose at the beginning of the experiment
>> 
>> improves the thing in a sense... but I face a new error:
>> 
>> mymod3<-nlsList(Conc+1 ~ Dose * exp(lKe+lKa-lCl) * 
>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)) | Organ,
>> data=mydata2,
>> start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>> )
>> 
>> Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
>>        Non-numeric argument to mathematical function
>> Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
>>        Non-numeric argument to mathematical function
>> Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
>>        Non-numeric argument to mathematical function
>> 
>> I have checked the variables in the data.frame with:
>>
>>  > sapply(mydata2,is.factor)
>>  Tps  Conc Organ  Dose
>> FALSE FALSE  TRUE FALSE
>>  > sapply(mydata2,is.character)
>>  Tps  Conc Organ  Dose
>> FALSE FALSE FALSE FALSE
>> 
>> So everything looks OK on this side...
>> 
>> Furthermore, I have still this "old" error intact:
>>
>>  > mymod4<-nlsList(SSfol,data=mydata2)
>> Error in eval(expr, envir, enclos) : object "input" not found
>> Error in eval(expr, envir, enclos) : object "input" not found
>> Error in eval(expr, envir, enclos) : object "input" not found
>> 
>> 
>> I am really sorry for calling help and boring everybody on this likely 
>> trivial issue (this looks like asking a community to participate to 
>> debogging line by line, a shame!!!), but I must admit that I am really 
>> lost...
>> 
>> Thanks for your concern,
>> 
>> Kind regards,
>> 
>> Patrick
>> 
>> 
>> Prof Brian Ripley a ??crit :
>> 
>>> We don't have Dose, and I think that is where the error lies.  If Dose 
>>> were part of mydata2, this is likely to work, but otherwise it is Dose 
>>> which has the wrong length.
>>> 
>>> ?nlsList says
>>>
>>>     data: a data frame in which to interpret the variables named in
>>>           'model'.
>>> 
>>> and it means it: you must get all the variables from there.
>>> 
>>> 
>>> On Fri, 17 Feb 2006, Patrick Giraudoux wrote:
>>> 
>>>> Spencer,
>>>> 
>>>> Thanks for the hint. I did not dare to bore people with the full data
>>>> set and though that this kind of error may have been trivial and often
>>>> encountered (so leading to a short answer), even though I did not see
>>>> related messages on the r-help list. I already did the checks suggested
>>>> before posting, and was aware of the possible confusion between 1 and l
>>>> (actually the variable names were not given by myself).
>>>> 
>>>> It seems that the trouble comes when the grouping variable "Organ" is
>>>> used. The best (?) I can do  is to dump the data.frame here below.
>>>> 
>>>> With this example, one can get exactly the same errors:
>>>> 
>>>> mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) *
>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>    data=mydata2,
>>>>    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>    )
>>>> 
>>>> ... works well!!!
>>>> 
>>>> but we get then:
>>>> 
>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)) | Organ,
>>>>    data=mydata2,
>>>>    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>    )
>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>> extranames,  :
>>>>        variable lengths differ
>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>> extranames,  :
>>>>        variable lengths differ
>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>> extranames,  :
>>>>        variable lengths differ
>>>> 
>>>> 
>>>> > mymod4<-nlsList(SSfol,data=mydata2)
>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>> 
>>>> 
>>>> Sorry and apologise for the inconvenience met,
>>>> 
>>>> Kind regards,
>>>> 
>>>> Patrick
>>>> 
>>>> 
>>>> 
>>>> # data.frame just to copy and past into R
>>>> 
>>>> "mydata2" <-
>>>> structure(list(Tps = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3,
>>>> 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,
>>>> 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9,
>>>> 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 14,
>>>> 14, 14, 14, 14, 17, 17, 17, 17, 17, 20, 20, 20, 20, 25, 28, 29,
>>>> 50, 50, 50, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
>>>> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4,
>>>> 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,
>>>> 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10,
>>>> 10, 10, 11, 11, 11, 11, 11, 11, 14, 14, 14, 14, 14, 17, 17, 17,
>>>> 17, 17, 20, 20, 20, 20, 25, 28, 29, 50, 50, 50, 136, 136, 136,
>>>> 136, 136, 136, 136, 136, 136, 136, 1, 1, 1, 1, 1, 1, 2, 2, 2,
>>>> 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,
>>>> 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8,
>>>> 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,
>>>> 11, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 20, 20, 20, 20,
>>>> 25, 28, 29, 50, 50, 50, 136, 136, 136, 136, 136, 136, 136, 136,
>>>> 136, 136), Conc = c(0, 0, 0, 0, 0, 0, 0, 0.807852503274902,
>>>> 0.204371494701886,
>>>> 0.579222129993907, 0.989062273721619, 0, 1.11728297897571,
>>>> 1.41057428121324,
>>>> 0.888883702851307, 1.259907624008, 1.45753269675829, 1.07077516747401,
>>>> 0.843279379, 0, 0.763110069196737, 1.11297791434297, 1.10087763997637,
>>>> 0.946929594501016, 1.33112168, 0.654041755, 0.694167499, 1.289548703,
>>>> 1.117139864, 0.807196192, 0.720221376552025, 0.560082823, 0.476583438,
>>>> 2.590855204, 0.51510972, 1.072946887, 0.537999938614396, 
>>>> 0.886684225905255,
>>>> 0.630178116793598, 1.31534758842196, 1.33333958571746, 0.922032210748255,
>>>> 0.429930193046174, 1.35881467717335, 0.790045927902363, 1.22484702570724,
>>>> 0.808104508207897, 1.31185966817903, 1.51837686425553, 1.74105163638734,
>>>> 1.80365598487402, 1.13240352674377, 1.50086243061644, 2.06355364280445,
>>>> 0.439350890906039, 1.54692793444949, 1.78758216051046, 1.09043400023239,
>>>> 0.811328376840514, 0.459192443530981, 0.695333473157298, 
>>>> 0.387995007681174,
>>>> 0.784627063444921, 1.02282256375842, 0.382687104107726, 
>>>> 0.554290634950242,
>>>> 0.130420456296453, 0.324194753224919, 0.31106140274139, 
>>>> 0.513473505828888,
>>>> 0.878620320248701, 1.18404358659996, 0.136926837896477, 0, 0,
>>>> 0.835588760032974, 0.558617235576616, 1.21002805866839, 
>>>> 0.769381068031404,
>>>> 1.04514254228094, 0.373251847173678, 0.389005898972802, 
>>>> 0.183141006154896,
>>>> 0.223596336820146, 0.315526423315647, 0.0930349732768131,
>>>> 0.169959185212759,
>>>> 0.161878841748425, 0, 0.0483041009105874, 0, 0, 0, 0.0777005553478052,
>>>> 0, 0.153175826795441, 0.0428171049833677, 0, 0, 0, 0, 0, 0, 0,
>>>> 0, 0, 0, 26.564295705327, 5.5893744508169, 7.22612934071834,
>>>> 36.6563989567777, 0, 28.8967184437329, 28.4030370337251, 
>>>> 28.0886043901352,
>>>> 26.1230935842208, 28.8895673910072, 42.6814210131968, 32.3555695551062,
>>>> 0.76883326657205, 34.6159136622156, 38.329242204291, 56.4476583636484,
>>>> 26.6249506083603, 31.3001451026823, 23.7339071829084, 23.3702284599355,
>>>> 36.669903715038, 44.7377244306005, 31.2079335923023, 32.8613384312272,
>>>> 29.4259634309146, 45.6112405959009, 48.1231689836687, 55.0037961570027,
>>>> 32.9822316456421, 20.0382768189682, 26.0986380308655, 28.8915584506145,
>>>> 28.7949023823068, 30.0278417498425, 58.8089779973569, 20.3602570111197,
>>>> 29.6269605259023, 28.4404986724604, 30.2165182590977, 19.9204461889074,
>>>> 31.1019196559556, 30.3847467747055, 36.8726911479995, 51.0618036275519,
>>>> 23.5408013442579, 36.6948355347593, 27.4753860809429, 24.1341667099646,
>>>> 27.5411488989643, 35.9021799354022, 19.7417897046158, 31.1403887303244,
>>>> 46.1743622734049, 34.8235854891765, 22.1714704189293, 33.6805966894274,
>>>> 35.2814908686112, 42.9767437212852, 38.1264997164547, 5.3651357974451,
>>>> 42.8990434918385, 25.4908883698364, 25.99649502, 36.4958105490917,
>>>> 40.8004126550705, 5.36867162116895, 0.00898476265269363, 0,
>>>> 27.6810997945798,
>>>> 28.7918300045713, 45.7577183830352, 35.9276318604787, 34.9717618087238,
>>>> 29.620354272564, 24.6537513599869, 13.5363982464958, 25.8289073574818,
>>>> 12.0090406245759, 4.753436805, 11.849214652228, 8.41410147611612,
>>>> 0, 1.80855352862552, 1.1987530031681, 1.01148025243171, 
>>>> 0.495675369574172,
>>>> 1.62701127228732, 0, 16.6288242287241, 1.23656061354912, 
>>>> 0.323708776035328,
>>>> 0, 0.566916625204436, 0, 0, 0, 0, 0, 0, 0, 2.53578781871283,
>>>> 3.50083667130797, 0, 0.98049572179098, 0, 3.57129673217304,
>>>> 2.77298867949388,
>>>> 2.12302645642669, 4.11923869203499, 4.69069462193674, 2.8698666062651,
>>>> 2.05079837323067, 0.0602771574448942, 5.96454350250626, 2.26267114439802,
>>>> 3.06911285674854, 2.04233129537404, 2.62181873844029, 1.51813653072598,
>>>> 1.46193772981073, 2.69864635755833, 3.44016493913122, 2.50834832469627,
>>>> 3.48170744166168, 1.00637581555435, 1.67065398473081, 4.18855363095027,
>>>> 3.39649762611015, 1.72804613460423, 1.40053679329531, 2.37032387724109,
>>>> 3.19332545080983, 2.49474373894248, 2.17800931288708, 2.7601484443213,
>>>> 0.91266104095844, 1.93485048639199, 1.19692593420788, 1.79537330666258,
>>>> 2.14020930767983, 3.0122526724942, 2.81112226980754, 3.54890724398174,
>>>> 3.01022926452999, 2.38263226710738, 3.53569238341869, 3.47869329713911,
>>>> 0.679333339820719, 2.4764260756438, 3.82615100065366, 2.20449890383871,
>>>> 1.371303113329, 1.2427787019995, 1.73319133880954, 0.391268883238408,
>>>> 1.73610193837913, 2.68494324646718, 1.77065393606844, 1.45079980147062,
>>>> 0.763775702906329, 0.98566725668627, 0.37838763208699, 0.841811919286804,
>>>> 1.46436462204795, 1.98409602726, 0.507005887891038, 0.465515668274195,
>>>> 0, 1.873365675227, 1.69023864630648, 2.65530855919137, 2.34392199908302,
>>>> 1.61917643594837, 1.05165934333345, 0.564642823436471, 0.121621029620328,
>>>> 0.515007625737071, 0.524345809084086, 0.130898614090571, 
>>>> 0.332427740242623,
>>>> 0.110214989555118, 0, 0.128642193589, 0.119407067173878, 
>>>> 0.128926224027295,
>>>> 0.0622331866694357, 0.215645168287442, 0, 0.859343941945178,
>>>> 0.0500810300696456, 0, 0, 0.0628746592609754), Organ =
>>>> structure(as.integer(c(1,
>>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3,
>>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>>> 2, 2, 2, 2, 2)), .Label = c("Carc", "TD", "Foie"), class = c("ordered",
>>>> "factor"))), .Names = c("Tps", "Conc", "Organ"), row.names = c("1",
>>>> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
>>>> "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24",
>>>> "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35",
>>>> "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46",
>>>> "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57",
>>>> "58", "59", "60", "61", "62", "63", "64", "65", "66", "67", "68",
>>>> "69", "70", "71", "72", "73", "74", "75", "76", "77", "78", "79",
>>>> "80", "81", "82", "83", "84", "85", "86", "87", "88", "89", "90",
>>>> "91", "92", "93", "94", "95", "96", "97", "98", "99", "100",
>>>> "101", "102", "103", "104", "105", "106", "107", "108", "109",
>>>> "110", "111", "112", "113", "114", "115", "116", "117", "118",
>>>> "119", "120", "121", "122", "123", "124", "125", "126", "127",
>>>> "128", "129", "130", "131", "132", "133", "134", "135", "136",
>>>> "137", "138", "139", "140", "141", "142", "143", "144", "145",
>>>> "146", "147", "148", "149", "150", "151", "152", "153", "154",
>>>> "155", "156", "157", "158", "159", "160", "161", "162", "163",
>>>> "164", "165", "166", "167", "168", "169", "170", "171", "172",
>>>> "173", "174", "175", "176", "177", "178", "179", "180", "181",
>>>> "182", "183", "184", "185", "186", "187", "188", "189", "190",
>>>> "191", "192", "193", "194", "195", "196", "197", "198", "199",
>>>> "200", "201", "202", "203", "204", "205", "206", "207", "208",
>>>> "209", "210", "211", "212", "213", "214", "215", "216", "217",
>>>> "218", "219", "220", "221", "222", "223", "224", "225", "226",
>>>> "227", "228", "229", "230", "231", "232", "233", "234", "235",
>>>> "236", "237", "238", "239", "240", "241", "242", "243", "244",
>>>> "245", "246", "247", "248", "249", "250", "251", "252", "253",
>>>> "254", "255", "256", "257", "258", "259", "260", "261", "262",
>>>> "263", "264", "265", "266", "267", "268", "269", "270", "271",
>>>> "272", "273", "274", "275", "276", "277", "278", "279", "280",
>>>> "281", "282", "283", "284", "285", "286", "287", "288", "289",
>>>> "290", "291", "292", "293", "294", "295", "296", "297", "298",
>>>> "299", "300"), class = c("nfnGroupedData", "nfGroupedData", 
>>>> "groupedData",
>>>> "data.frame"), formula = quote(Conc ~ Tps | Organ), FUN = function (x)
>>>> max(x, na.rm = TRUE), order.groups = TRUE)
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Spencer Graves a ??crit :
>>>>
>>>>>       Regarding the following:
>>>>> 
>>>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>>>      data=mydata,
>>>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>>> extranames,  :
>>>>>>         variable lengths differ
>>>>> 
>>>>>
>>>>>       This example is NOT self contained and is entirely too
>>>>> complicated for me to try to replicate it myself in a reasonable
>>>>> period of time.  I will therefore ask one short question:  Are all the
>>>>> variable names in the "nlsList" call either columns of "mydata" or
>>>>> parameters to be estimated and therefore spelled out in "start"?  If I
>>>>> were you, I'd check this all very carefully, being especially careful
>>>>> about the distinction between "lCl" and "lC1", in particular.
>>>>>
>>>>>       If you'd like further help with this, I suggest you try to find
>>>>> the simplest possible example that generates problem you don't
>>>>> understand, then try to recast that example into one that is
>>>>> completely self contained, either a data set in the standard R or nlme
>>>>> distribution  or numbers that one can generate with a very few lines
>>>>> of code.  If you use random numbers, please "set.seed", to increase
>>>>> your confidence that someone else will see what you see.  (And please
>>>>> review the posting guide! "www.R-project.org/posting-guide.html".
>>>>> Doing so may increase your chances of getting more useful information
>>>>> more quickly.)
>>>>>
>>>>>       spencer graves
>>>>> 
>>>>> Patrick Giraudoux wrote:
>>>>> 
>>>>>> Dear listers,
>>>>>> 
>>>>>> I am trying to fit a model using nlsList() using alternately a
>>>>>> SSfol() selfstart function or its developped equivalent formulae.
>>>>>> 
>>>>>> This preliminary trial works well
>>>>>> 
>>>>>> mydata<-groupedData(Conc~Tps|Organ,data=mydata)
>>>>>> mymod1<-nls(Conc~SSfol(Dose,Tps,lKe,lKa,lCl),data=mydata)
>>>>>> 
>>>>>> as well as a developped form:
>>>>>> 
>>>>>> mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>>>     data=mydata,
>>>>>>     start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>>     )
>>>>>> 
>>>>>> However when trying to fit the model with nlsList, I get:
>>>>>> 
>>>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>>>      data=mydata,
>>>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>>      )
>>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>>> extranames,  :
>>>>>>         variable lengths differ
>>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>>> extranames,  :
>>>>>>         variable lengths differ
>>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>>> extranames,  :
>>>>>>         variable lengths differ
>>>>>> 
>>>>>> Or specifying  the grouping factor explicitely:
>>>>>> 
>>>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe))|Organ,
>>>>>>      data=mydata,
>>>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>>      )
>>>>>> 
>>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>>> extranames,  :
>>>>>>         variable lengths differ
>>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>>> extranames,  :
>>>>>>         variable lengths differ
>>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>>> extranames,  :
>>>>>>         variable lengths differ
>>>>>> 
>>>>>> 
>>>>>> I cannot find out why the grouping factor cannot be used (it has the
>>>>>> same length as the other variables...)
>>>>>> 
>>>>>> Another strange thing occurs: in the example given in the help of
>>>>>> nlsList.selfstart, the following command works  well:
>>>>>>
>>>>>>  fm1 <- nlsList(SSasympOff, CO2)
>>>>>> 
>>>>>> However its seemingly equivalent applied to the case above fails:
>>>>>> 
>>>>>> mymod4<-nlsList(SSfol,data=mydata)
>>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>>> 
>>>>>> 
>>>>>> Any hint/suggestion appreciated.
>>>>>> 
>>>>>> Kind regards,
>>>>>> 
>>>>>> Patrick Giraudoux
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at stat.math.ethz.ch mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide!
>>>>>> http://www.R-project.org/posting-guide.html
>>>>> 
>>>>> 
>>>> 
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide! 
>>>> http://www.R-project.org/posting-guide.html
>>>> 
>>> 
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ml-r-help at epigenomics.com  Fri Feb 17 18:25:58 2006
From: ml-r-help at epigenomics.com (ml-r-help@epigenomics.com)
Date: 17 Feb 2006 18:25:58 +0100
Subject: [R] Please ignore (Re: EpiR.base - namespace changes)
In-Reply-To: <dt50g0$8da$1@perl.epigenomics.epi>
References: <dt50g0$8da$1@perl.epigenomics.epi>
Message-ID: <dt50v6$8rc$1@perl.epigenomics.epi>


Please ignore my posting, was not meant to be sent to this list.

Appologies for the distraction.

Regards,

  Matthias

-- 
Matthias Burger                     Project Manager/ Biostatistician
Epigenomics AG    Kleine Praesidentenstr. 1    10178 Berlin, Germany
phone:+49-30-24345-371                          fax:+49-30-24345-555
http://www.epigenomics.com           matthias.burger at epigenomics.com



From ggrothendieck at gmail.com  Fri Feb 17 18:36:51 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 17 Feb 2006 12:36:51 -0500
Subject: [R] how to clear screen in R-console?
In-Reply-To: <971536df0602170841o204a86e5rc775bc74fc378e83@mail.gmail.com>
References: <059DE74C2765E04284021ACFDB7A22DD8765D8@s6.neuro.mpg.de>
	<971536df0602170841o204a86e5rc775bc74fc378e83@mail.gmail.com>
Message-ID: <971536df0602170936j4922f9fcw60ac35133a7ca621@mail.gmail.com>

Here is a version that uses rcom instead of RDCOMClient.
This has the advantage that rcom is on CRAN.

cls <- function() {
	require(rcom)
	wsh <- comCreateObject("Wscript.Shell")
	comInvoke(wsh, "SendKeys", "\014")
	invisible(wsh)
}
cls() # test

On 2/17/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Here is a translation of Norm Olsen's vbscript code into pure R.
> This is intended for use with the Windows Rgui interface.
>
> cls <- function() {
>        require(RDCOMClient)
>        wsh <- COMCreate("Wscript.Shell")
>        wsh$SendKeys("\014")
>        invisible(wsh)
> }
> cls()  # invoke
>
>
>
> On 2/17/06, Marcus Leinweber <leinweber at neuro.mpg.de> wrote:
> > have already tried this?
> >
> > http://finzi.psych.upenn.edu/R/Rhelp02a/archive/55752.html
> >
> > m.
> >
> >
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Michael
> > > Sent: Thursday, February 16, 2006 9:23 PM
> > > To: Henrik Bengtsson
> > > Cc: R-help at stat.math.ethz.ch
> > > Subject: Re: [R] how to clear screen in R-console?
> > >
> > > I am actually using Rgui on Windows...
> > >
> > > What can I do?
> > >
> > > There is no way to programmatically clear screen?
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>



From roebuck at mdanderson.org  Fri Feb 17 19:14:57 2006
From: roebuck at mdanderson.org (Paul Roebuck)
Date: Fri, 17 Feb 2006 12:14:57 -0600 (CST)
Subject: [R] how to clear screen in R-console?
In-Reply-To: <59d7961d0602160459t493de978na04494e207460e55@mail.gmail.com>
References: <b1f16d9d0602160233r1a95ba81qd81583b047b7f2af@mail.gmail.com>
	<43F45928.8010902@web.de>
	<b1f16d9d0602160322m6cb6a484mfd6aee2bbf2b758b@mail.gmail.com>
	<59d7961d0602160459t493de978na04494e207460e55@mail.gmail.com>
Message-ID: <Pine.OSF.4.58.0602171202040.110191@wotan.mdacc.tmc.edu>

On Thu, 16 Feb 2006, Henrik Bengtsson wrote:

> On 2/16/06, Michael <comtech.usa at gmail.com> wrote:
>
> > On 2/16/06, Christian Schulz <ozric at web.de> wrote:
> > >
> > > >How to clear the screen in R-console?
> > >
> > > ctrl - e & l
> >
> > Any funcation that is callable from my program, instead of
> > pressing keys?
>
> depends on what type of terminal you are running.  For example, if you
> run R in a VT100 terminal, you can try
>
> cat("The following VT100 escape sequence will clear the screen on a
> VT100 terminal\n")
> cat("\033[2J")  # <ESC>[2J  == Clear Screen
> cat("If the screen was cleared you should only see this sentence.\n")
>
> i.e.
>
> vt100ClearScreen <- function(...) cat("\033[2J")
>

On my terminal, this required the addition of cursor homing
to replicate the effects of using the OS to clear the screen.

system_cls <- function() system("clear")
vt100_cls  <- function() cat("\033[2J\033[H")

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From spencer.graves at pdf.com  Fri Feb 17 19:19:34 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 17 Feb 2006 10:19:34 -0800
Subject: [R] lme, nlsList, nlsList.selfStart
In-Reply-To: <Pine.LNX.4.64.0602171724510.31301@gannet.stats.ox.ac.uk>
References: <43EEE758.2050408@univ-fcomte.fr> <43F522FF.9060402@pdf.com>
	<43F59BA9.1010106@univ-fcomte.fr>
	<Pine.LNX.4.64.0602171040190.13399@gannet.stats.ox.ac.uk>
	<43F5AE78.7000908@univ-fcomte.fr> <43F6068C.1030900@pdf.com>
	<Pine.LNX.4.64.0602171724510.31301@gannet.stats.ox.ac.uk>
Message-ID: <43F613B6.8070404@pdf.com>

Dear Prof. Ripley:

	  1.  That's great.  I seem to recall having problems with something 
like that when using a commercial *-Plus product not unlike R.  Version 
6.2 of this other software just produced the following for me:

 > tstDF <- data.frame(a = 1:3)
 > tstDF$b <- 2
 > sapply(tstDF, length)
  a b
  3 1

	  From R2.2.1, I get "3 3" for this example, as you noted.  Once more, 
I am doubly in your debt, sir, both for helping to make R what it is 
today AND for helping to educate me on its capabilities.

	  2.  Alas, my cerebral cortex produced "Nil pointer reference" in 
trying to parse your other comment, "Read on in your inbox for the 
solution."  Perhaps in the fullness of time, I shall be enlightened.

	  Thanks again,
	  spencer graves

Prof Brian Ripley wrote:

> On Fri, 17 Feb 2006, Spencer Graves wrote:
> 
>>       Have you tried making mydata2$Dose the same length as everything 
>> else?
> 
> 
> [<- does that for you: all columns in a data frame must be the same 
> length.  Read on in your inbox for the solution.
> 
>>
>>       spencer graves
>>
>> Patrick Giraudoux wrote:
>>
>>> Well, right, Dose was indeed in the global environment and not in the 
>>> data.frame. Changing it with
>>>
>>> mydata2$Dose<-100 # the real dose at the beginning of the experiment
>>>
>>> improves the thing in a sense... but I face a new error:
>>>
>>> mymod3<-nlsList(Conc+1 ~ Dose * exp(lKe+lKa-lCl) * 
>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)) | Organ,
>>> data=mydata2,
>>> start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>> )
>>>
>>> Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
>>>        Non-numeric argument to mathematical function
>>> Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
>>>        Non-numeric argument to mathematical function
>>> Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
>>>        Non-numeric argument to mathematical function
>>>
>>> I have checked the variables in the data.frame with:
>>>
>>>  > sapply(mydata2,is.factor)
>>>  Tps  Conc Organ  Dose
>>> FALSE FALSE  TRUE FALSE
>>>  > sapply(mydata2,is.character)
>>>  Tps  Conc Organ  Dose
>>> FALSE FALSE FALSE FALSE
>>>
>>> So everything looks OK on this side...
>>>
>>> Furthermore, I have still this "old" error intact:
>>>
>>>  > mymod4<-nlsList(SSfol,data=mydata2)
>>> Error in eval(expr, envir, enclos) : object "input" not found
>>> Error in eval(expr, envir, enclos) : object "input" not found
>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>
>>>
>>> I am really sorry for calling help and boring everybody on this 
>>> likely trivial issue (this looks like asking a community to 
>>> participate to debogging line by line, a shame!!!), but I must admit 
>>> that I am really lost...
>>>
>>> Thanks for your concern,
>>>
>>> Kind regards,
>>>
>>> Patrick
>>>
>>>
>>> Prof Brian Ripley a ??crit :
>>>
>>>> We don't have Dose, and I think that is where the error lies.  If 
>>>> Dose were part of mydata2, this is likely to work, but otherwise it 
>>>> is Dose which has the wrong length.
>>>>
>>>> ?nlsList says
>>>>
>>>>     data: a data frame in which to interpret the variables named in
>>>>           'model'.
>>>>
>>>> and it means it: you must get all the variables from there.
>>>>
>>>>
>>>> On Fri, 17 Feb 2006, Patrick Giraudoux wrote:
>>>>
>>>>> Spencer,
>>>>>
>>>>> Thanks for the hint. I did not dare to bore people with the full data
>>>>> set and though that this kind of error may have been trivial and often
>>>>> encountered (so leading to a short answer), even though I did not see
>>>>> related messages on the r-help list. I already did the checks 
>>>>> suggested
>>>>> before posting, and was aware of the possible confusion between 1 
>>>>> and l
>>>>> (actually the variable names were not given by myself).
>>>>>
>>>>> It seems that the trouble comes when the grouping variable "Organ" is
>>>>> used. The best (?) I can do  is to dump the data.frame here below.
>>>>>
>>>>> With this example, one can get exactly the same errors:
>>>>>
>>>>> mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>>    data=mydata2,
>>>>>    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>    )
>>>>>
>>>>> ... works well!!!
>>>>>
>>>>> but we get then:
>>>>>
>>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)) | Organ,
>>>>>    data=mydata2,
>>>>>    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>    )
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>        variable lengths differ
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>        variable lengths differ
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>        variable lengths differ
>>>>>
>>>>>
>>>>> > mymod4<-nlsList(SSfol,data=mydata2)
>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>>
>>>>>
>>>>> Sorry and apologise for the inconvenience met,
>>>>>
>>>>> Kind regards,
>>>>>
>>>>> Patrick
>>>>>
>>>>>
>>>>>
>>>>> # data.frame just to copy and past into R
>>>>>
>>>>> "mydata2" <-
>>>>> structure(list(Tps = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3,
>>>>> 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,
>>>>> 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9,
>>>>> 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 14,
>>>>> 14, 14, 14, 14, 17, 17, 17, 17, 17, 20, 20, 20, 20, 25, 28, 29,
>>>>> 50, 50, 50, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
>>>>> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4,
>>>>> 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,
>>>>> 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10,
>>>>> 10, 10, 11, 11, 11, 11, 11, 11, 14, 14, 14, 14, 14, 17, 17, 17,
>>>>> 17, 17, 20, 20, 20, 20, 25, 28, 29, 50, 50, 50, 136, 136, 136,
>>>>> 136, 136, 136, 136, 136, 136, 136, 1, 1, 1, 1, 1, 1, 2, 2, 2,
>>>>> 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,
>>>>> 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8,
>>>>> 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,
>>>>> 11, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 20, 20, 20, 20,
>>>>> 25, 28, 29, 50, 50, 50, 136, 136, 136, 136, 136, 136, 136, 136,
>>>>> 136, 136), Conc = c(0, 0, 0, 0, 0, 0, 0, 0.807852503274902,
>>>>> 0.204371494701886,
>>>>> 0.579222129993907, 0.989062273721619, 0, 1.11728297897571,
>>>>> 1.41057428121324,
>>>>> 0.888883702851307, 1.259907624008, 1.45753269675829, 1.07077516747401,
>>>>> 0.843279379, 0, 0.763110069196737, 1.11297791434297, 1.10087763997637,
>>>>> 0.946929594501016, 1.33112168, 0.654041755, 0.694167499, 1.289548703,
>>>>> 1.117139864, 0.807196192, 0.720221376552025, 0.560082823, 0.476583438,
>>>>> 2.590855204, 0.51510972, 1.072946887, 0.537999938614396, 
>>>>> 0.886684225905255,
>>>>> 0.630178116793598, 1.31534758842196, 1.33333958571746, 
>>>>> 0.922032210748255,
>>>>> 0.429930193046174, 1.35881467717335, 0.790045927902363, 
>>>>> 1.22484702570724,
>>>>> 0.808104508207897, 1.31185966817903, 1.51837686425553, 
>>>>> 1.74105163638734,
>>>>> 1.80365598487402, 1.13240352674377, 1.50086243061644, 
>>>>> 2.06355364280445,
>>>>> 0.439350890906039, 1.54692793444949, 1.78758216051046, 
>>>>> 1.09043400023239,
>>>>> 0.811328376840514, 0.459192443530981, 0.695333473157298, 
>>>>> 0.387995007681174,
>>>>> 0.784627063444921, 1.02282256375842, 0.382687104107726, 
>>>>> 0.554290634950242,
>>>>> 0.130420456296453, 0.324194753224919, 0.31106140274139, 
>>>>> 0.513473505828888,
>>>>> 0.878620320248701, 1.18404358659996, 0.136926837896477, 0, 0,
>>>>> 0.835588760032974, 0.558617235576616, 1.21002805866839, 
>>>>> 0.769381068031404,
>>>>> 1.04514254228094, 0.373251847173678, 0.389005898972802, 
>>>>> 0.183141006154896,
>>>>> 0.223596336820146, 0.315526423315647, 0.0930349732768131,
>>>>> 0.169959185212759,
>>>>> 0.161878841748425, 0, 0.0483041009105874, 0, 0, 0, 0.0777005553478052,
>>>>> 0, 0.153175826795441, 0.0428171049833677, 0, 0, 0, 0, 0, 0, 0,
>>>>> 0, 0, 0, 26.564295705327, 5.5893744508169, 7.22612934071834,
>>>>> 36.6563989567777, 0, 28.8967184437329, 28.4030370337251, 
>>>>> 28.0886043901352,
>>>>> 26.1230935842208, 28.8895673910072, 42.6814210131968, 
>>>>> 32.3555695551062,
>>>>> 0.76883326657205, 34.6159136622156, 38.329242204291, 56.4476583636484,
>>>>> 26.6249506083603, 31.3001451026823, 23.7339071829084, 
>>>>> 23.3702284599355,
>>>>> 36.669903715038, 44.7377244306005, 31.2079335923023, 32.8613384312272,
>>>>> 29.4259634309146, 45.6112405959009, 48.1231689836687, 
>>>>> 55.0037961570027,
>>>>> 32.9822316456421, 20.0382768189682, 26.0986380308655, 
>>>>> 28.8915584506145,
>>>>> 28.7949023823068, 30.0278417498425, 58.8089779973569, 
>>>>> 20.3602570111197,
>>>>> 29.6269605259023, 28.4404986724604, 30.2165182590977, 
>>>>> 19.9204461889074,
>>>>> 31.1019196559556, 30.3847467747055, 36.8726911479995, 
>>>>> 51.0618036275519,
>>>>> 23.5408013442579, 36.6948355347593, 27.4753860809429, 
>>>>> 24.1341667099646,
>>>>> 27.5411488989643, 35.9021799354022, 19.7417897046158, 
>>>>> 31.1403887303244,
>>>>> 46.1743622734049, 34.8235854891765, 22.1714704189293, 
>>>>> 33.6805966894274,
>>>>> 35.2814908686112, 42.9767437212852, 38.1264997164547, 5.3651357974451,
>>>>> 42.8990434918385, 25.4908883698364, 25.99649502, 36.4958105490917,
>>>>> 40.8004126550705, 5.36867162116895, 0.00898476265269363, 0,
>>>>> 27.6810997945798,
>>>>> 28.7918300045713, 45.7577183830352, 35.9276318604787, 
>>>>> 34.9717618087238,
>>>>> 29.620354272564, 24.6537513599869, 13.5363982464958, 25.8289073574818,
>>>>> 12.0090406245759, 4.753436805, 11.849214652228, 8.41410147611612,
>>>>> 0, 1.80855352862552, 1.1987530031681, 1.01148025243171, 
>>>>> 0.495675369574172,
>>>>> 1.62701127228732, 0, 16.6288242287241, 1.23656061354912, 
>>>>> 0.323708776035328,
>>>>> 0, 0.566916625204436, 0, 0, 0, 0, 0, 0, 0, 2.53578781871283,
>>>>> 3.50083667130797, 0, 0.98049572179098, 0, 3.57129673217304,
>>>>> 2.77298867949388,
>>>>> 2.12302645642669, 4.11923869203499, 4.69069462193674, 2.8698666062651,
>>>>> 2.05079837323067, 0.0602771574448942, 5.96454350250626, 
>>>>> 2.26267114439802,
>>>>> 3.06911285674854, 2.04233129537404, 2.62181873844029, 
>>>>> 1.51813653072598,
>>>>> 1.46193772981073, 2.69864635755833, 3.44016493913122, 
>>>>> 2.50834832469627,
>>>>> 3.48170744166168, 1.00637581555435, 1.67065398473081, 
>>>>> 4.18855363095027,
>>>>> 3.39649762611015, 1.72804613460423, 1.40053679329531, 
>>>>> 2.37032387724109,
>>>>> 3.19332545080983, 2.49474373894248, 2.17800931288708, 2.7601484443213,
>>>>> 0.91266104095844, 1.93485048639199, 1.19692593420788, 
>>>>> 1.79537330666258,
>>>>> 2.14020930767983, 3.0122526724942, 2.81112226980754, 3.54890724398174,
>>>>> 3.01022926452999, 2.38263226710738, 3.53569238341869, 
>>>>> 3.47869329713911,
>>>>> 0.679333339820719, 2.4764260756438, 3.82615100065366, 
>>>>> 2.20449890383871,
>>>>> 1.371303113329, 1.2427787019995, 1.73319133880954, 0.391268883238408,
>>>>> 1.73610193837913, 2.68494324646718, 1.77065393606844, 
>>>>> 1.45079980147062,
>>>>> 0.763775702906329, 0.98566725668627, 0.37838763208699, 
>>>>> 0.841811919286804,
>>>>> 1.46436462204795, 1.98409602726, 0.507005887891038, 0.465515668274195,
>>>>> 0, 1.873365675227, 1.69023864630648, 2.65530855919137, 
>>>>> 2.34392199908302,
>>>>> 1.61917643594837, 1.05165934333345, 0.564642823436471, 
>>>>> 0.121621029620328,
>>>>> 0.515007625737071, 0.524345809084086, 0.130898614090571, 
>>>>> 0.332427740242623,
>>>>> 0.110214989555118, 0, 0.128642193589, 0.119407067173878, 
>>>>> 0.128926224027295,
>>>>> 0.0622331866694357, 0.215645168287442, 0, 0.859343941945178,
>>>>> 0.0500810300696456, 0, 0, 0.0628746592609754), Organ =
>>>>> structure(as.integer(c(1,
>>>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3,
>>>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>>>> 2, 2, 2, 2, 2)), .Label = c("Carc", "TD", "Foie"), class = 
>>>>> c("ordered",
>>>>> "factor"))), .Names = c("Tps", "Conc", "Organ"), row.names = c("1",
>>>>> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
>>>>> "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24",
>>>>> "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35",
>>>>> "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46",
>>>>> "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57",
>>>>> "58", "59", "60", "61", "62", "63", "64", "65", "66", "67", "68",
>>>>> "69", "70", "71", "72", "73", "74", "75", "76", "77", "78", "79",
>>>>> "80", "81", "82", "83", "84", "85", "86", "87", "88", "89", "90",
>>>>> "91", "92", "93", "94", "95", "96", "97", "98", "99", "100",
>>>>> "101", "102", "103", "104", "105", "106", "107", "108", "109",
>>>>> "110", "111", "112", "113", "114", "115", "116", "117", "118",
>>>>> "119", "120", "121", "122", "123", "124", "125", "126", "127",
>>>>> "128", "129", "130", "131", "132", "133", "134", "135", "136",
>>>>> "137", "138", "139", "140", "141", "142", "143", "144", "145",
>>>>> "146", "147", "148", "149", "150", "151", "152", "153", "154",
>>>>> "155", "156", "157", "158", "159", "160", "161", "162", "163",
>>>>> "164", "165", "166", "167", "168", "169", "170", "171", "172",
>>>>> "173", "174", "175", "176", "177", "178", "179", "180", "181",
>>>>> "182", "183", "184", "185", "186", "187", "188", "189", "190",
>>>>> "191", "192", "193", "194", "195", "196", "197", "198", "199",
>>>>> "200", "201", "202", "203", "204", "205", "206", "207", "208",
>>>>> "209", "210", "211", "212", "213", "214", "215", "216", "217",
>>>>> "218", "219", "220", "221", "222", "223", "224", "225", "226",
>>>>> "227", "228", "229", "230", "231", "232", "233", "234", "235",
>>>>> "236", "237", "238", "239", "240", "241", "242", "243", "244",
>>>>> "245", "246", "247", "248", "249", "250", "251", "252", "253",
>>>>> "254", "255", "256", "257", "258", "259", "260", "261", "262",
>>>>> "263", "264", "265", "266", "267", "268", "269", "270", "271",
>>>>> "272", "273", "274", "275", "276", "277", "278", "279", "280",
>>>>> "281", "282", "283", "284", "285", "286", "287", "288", "289",
>>>>> "290", "291", "292", "293", "294", "295", "296", "297", "298",
>>>>> "299", "300"), class = c("nfnGroupedData", "nfGroupedData", 
>>>>> "groupedData",
>>>>> "data.frame"), formula = quote(Conc ~ Tps | Organ), FUN = function (x)
>>>>> max(x, na.rm = TRUE), order.groups = TRUE)
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> Spencer Graves a ??crit :
>>>>>
>>>>>>       Regarding the following:
>>>>>>
>>>>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>>>>      data=mydata,
>>>>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>>>> extranames,  :
>>>>>>>         variable lengths differ
>>>>>>
>>>>>>
>>>>>>
>>>>>>       This example is NOT self contained and is entirely too
>>>>>> complicated for me to try to replicate it myself in a reasonable
>>>>>> period of time.  I will therefore ask one short question:  Are all 
>>>>>> the
>>>>>> variable names in the "nlsList" call either columns of "mydata" or
>>>>>> parameters to be estimated and therefore spelled out in "start"?  
>>>>>> If I
>>>>>> were you, I'd check this all very carefully, being especially careful
>>>>>> about the distinction between "lCl" and "lC1", in particular.
>>>>>>
>>>>>>       If you'd like further help with this, I suggest you try to find
>>>>>> the simplest possible example that generates problem you don't
>>>>>> understand, then try to recast that example into one that is
>>>>>> completely self contained, either a data set in the standard R or 
>>>>>> nlme
>>>>>> distribution  or numbers that one can generate with a very few lines
>>>>>> of code.  If you use random numbers, please "set.seed", to increase
>>>>>> your confidence that someone else will see what you see.  (And please
>>>>>> review the posting guide! "www.R-project.org/posting-guide.html".
>>>>>> Doing so may increase your chances of getting more useful information
>>>>>> more quickly.)
>>>>>>
>>>>>>       spencer graves
>>>>>>
>>>>>> Patrick Giraudoux wrote:
>>>>>>
>>>>>>> Dear listers,
>>>>>>>
>>>>>>> I am trying to fit a model using nlsList() using alternately a
>>>>>>> SSfol() selfstart function or its developped equivalent formulae.
>>>>>>>
>>>>>>> This preliminary trial works well
>>>>>>>
>>>>>>> mydata<-groupedData(Conc~Tps|Organ,data=mydata)
>>>>>>> mymod1<-nls(Conc~SSfol(Dose,Tps,lKe,lKa,lCl),data=mydata)
>>>>>>>
>>>>>>> as well as a developped form:
>>>>>>>
>>>>>>> mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>>>>     data=mydata,
>>>>>>>     start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>>>     )
>>>>>>>
>>>>>>> However when trying to fit the model with nlsList, I get:
>>>>>>>
>>>>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>>>>      data=mydata,
>>>>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>>>      )
>>>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>>>> extranames,  :
>>>>>>>         variable lengths differ
>>>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>>>> extranames,  :
>>>>>>>         variable lengths differ
>>>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>>>> extranames,  :
>>>>>>>         variable lengths differ
>>>>>>>
>>>>>>> Or specifying  the grouping factor explicitely:
>>>>>>>
>>>>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe))|Organ,
>>>>>>>      data=mydata,
>>>>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>>>      )
>>>>>>>
>>>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>>>> extranames,  :
>>>>>>>         variable lengths differ
>>>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>>>> extranames,  :
>>>>>>>         variable lengths differ
>>>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>>>> extranames,  :
>>>>>>>         variable lengths differ
>>>>>>>
>>>>>>>
>>>>>>> I cannot find out why the grouping factor cannot be used (it has the
>>>>>>> same length as the other variables...)
>>>>>>>
>>>>>>> Another strange thing occurs: in the example given in the help of
>>>>>>> nlsList.selfstart, the following command works  well:
>>>>>>>
>>>>>>>  fm1 <- nlsList(SSasympOff, CO2)
>>>>>>>
>>>>>>> However its seemingly equivalent applied to the case above fails:
>>>>>>>
>>>>>>> mymod4<-nlsList(SSfol,data=mydata)
>>>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>>>>
>>>>>>>
>>>>>>> Any hint/suggestion appreciated.
>>>>>>>
>>>>>>> Kind regards,
>>>>>>>
>>>>>>> Patrick Giraudoux
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at stat.math.ethz.ch mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide!
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-help at stat.math.ethz.ch mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide! 
>>>>> http://www.R-project.org/posting-guide.html
>>>>>
>>>>
>>>
>>
>>
>



From bzajdlik at sentex.net  Fri Feb 17 19:17:58 2006
From: bzajdlik at sentex.net (Barry Zajdlik)
Date: Fri, 17 Feb 2006 13:17:58 -0500
Subject: [R] Variance for Vector of Constants is STILL Not Zero
In-Reply-To: <43F4E0CC.4000501@pdf.com>
Message-ID: <000001c633ee$7be4e7f0$0a00a8c0@Dell2003desktop>

Hello all,

Thanks for the responses but I am still annoyed by this seemingly simple
problem; I recorded sessionInfo() as below.

x<-rep(0.02,10)
> var(x)
[1] 1.337451e-35
>  sessionInfo()
R version 2.1.0, 2005-04-18, i386-pc-mingw32 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"
"datasets" 
[7] "base"     
>


I then decided to download the latest version today but obtained the
same result.

> x<-rep(0.02,10)
> var(x)
[1] 1.337451e-35

> sessionInfo()
R version 2.2.1, 2005-12-20, i386-pc-mingw32 

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"
"datasets" 
[7] "base"    


I Changed .Machine$double.eps to make the calculations LESS accurate.
My thought was that if I reduced the precision, 1-eps would return 1
instead of some number less than 1.  My thought was that if eps were
sufficiently large my sample problem would return a zero.  This didn't
happen though.

Again, any thoughts would be appreciated.

Regards,
Barry Zajdlik



From ripley at stats.ox.ac.uk  Fri Feb 17 19:25:59 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 17 Feb 2006 18:25:59 +0000 (GMT)
Subject: [R] lme, nlsList, nlsList.selfStart
In-Reply-To: <43F5AE78.7000908@univ-fcomte.fr>
References: <43EEE758.2050408@univ-fcomte.fr> <43F522FF.9060402@pdf.com>
	<43F59BA9.1010106@univ-fcomte.fr>
	<Pine.LNX.4.64.0602171040190.13399@gannet.stats.ox.ac.uk>
	<43F5AE78.7000908@univ-fcomte.fr>
Message-ID: <Pine.LNX.4.64.0602171144430.649@gannet.stats.ox.ac.uk>

This is a bug in nlsList.formula, where the author forgot that deparsing 
can spread over multiple lines.  Here is a patch:

--- nlsList.R   (revision 2298)
+++ nlsList.R   (working copy)
@@ -60,8 +60,9 @@
      } else if (length(level) > 1) {
        stop("Multiple levels not allowed")
      }
-    model <- eval(parse(text = paste(deparse(model[[2]]),
-                        deparse(getCovariateFormula(model)[[2]]), sep = "~")))
+    model <- eval(parse(text = paste(paste(deparse(model[[2]]), collapse=" "),
+                        paste(deparse(getCovariateFormula(model)[[2]]), collapse=" "),
+                       sep = "~")))
      groups <- getGroups(data, form = grpForm, level = level)[drop = TRUE]
    }
    if (is.null(start) && is.null(attr(data, "parameters"))) {

which will probably not survive emailing but should show you what the 
change is.

On Fri, 17 Feb 2006, Patrick Giraudoux wrote:

> Well, right, Dose was indeed in the global environment and not in the 
> data.frame. Changing it with
>
> mydata2$Dose<-100 # the real dose at the beginning of the experiment
>
> improves the thing in a sense... but I face a new error:
>
> mymod3<-nlsList(Conc+1 ~ Dose * exp(lKe+lKa-lCl) * 
> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)) | Organ,
> data=mydata2,
> start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
> )
>
> Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
>       Non-numeric argument to mathematical function
> Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
>       Non-numeric argument to mathematical function
> Error in exp(-exp(lKa) * Conc + 1 ~ Tps) :
>       Non-numeric argument to mathematical function
>
> I have checked the variables in the data.frame with:
>
>> sapply(mydata2,is.factor)
> Tps  Conc Organ  Dose
> FALSE FALSE  TRUE FALSE
>> sapply(mydata2,is.character)
> Tps  Conc Organ  Dose
> FALSE FALSE FALSE FALSE
>
> So everything looks OK on this side...
>
> Furthermore, I have still this "old" error intact:
>
>> mymod4<-nlsList(SSfol,data=mydata2)
> Error in eval(expr, envir, enclos) : object "input" not found
> Error in eval(expr, envir, enclos) : object "input" not found
> Error in eval(expr, envir, enclos) : object "input" not found
>
>
> I am really sorry for calling help and boring everybody on this likely 
> trivial issue (this looks like asking a community to participate to debogging 
> line by line, a shame!!!), but I must admit that I am really lost...
>
> Thanks for your concern,
>
> Kind regards,
>
> Patrick
>
>
> Prof Brian Ripley a ??crit :
>> We don't have Dose, and I think that is where the error lies.  If Dose were 
>> part of mydata2, this is likely to work, but otherwise it is Dose which has 
>> the wrong length.
>> 
>> ?nlsList says
>>
>>     data: a data frame in which to interpret the variables named in
>>           'model'.
>> 
>> and it means it: you must get all the variables from there.
>> 
>> 
>> On Fri, 17 Feb 2006, Patrick Giraudoux wrote:
>> 
>>> Spencer,
>>> 
>>> Thanks for the hint. I did not dare to bore people with the full data
>>> set and though that this kind of error may have been trivial and often
>>> encountered (so leading to a short answer), even though I did not see
>>> related messages on the r-help list. I already did the checks suggested
>>> before posting, and was aware of the possible confusion between 1 and l
>>> (actually the variable names were not given by myself).
>>> 
>>> It seems that the trouble comes when the grouping variable "Organ" is
>>> used. The best (?) I can do  is to dump the data.frame here below.
>>> 
>>> With this example, one can get exactly the same errors:
>>> 
>>> mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) *
>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>    data=mydata2,
>>>    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>    )
>>> 
>>> ... works well!!!
>>> 
>>> but we get then:
>>> 
>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)) | Organ,
>>>    data=mydata2,
>>>    start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>    )
>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>> extranames,  :
>>>        variable lengths differ
>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>> extranames,  :
>>>        variable lengths differ
>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>> extranames,  :
>>>        variable lengths differ
>>> 
>>> 
>>> > mymod4<-nlsList(SSfol,data=mydata2)
>>> Error in eval(expr, envir, enclos) : object "input" not found
>>> Error in eval(expr, envir, enclos) : object "input" not found
>>> Error in eval(expr, envir, enclos) : object "input" not found
>>> 
>>> 
>>> Sorry and apologise for the inconvenience met,
>>> 
>>> Kind regards,
>>> 
>>> Patrick
>>> 
>>> 
>>> 
>>> # data.frame just to copy and past into R
>>> 
>>> "mydata2" <-
>>> structure(list(Tps = c(1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3,
>>> 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6,
>>> 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9,
>>> 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 14,
>>> 14, 14, 14, 14, 17, 17, 17, 17, 17, 20, 20, 20, 20, 25, 28, 29,
>>> 50, 50, 50, 136, 136, 136, 136, 136, 136, 136, 136, 136, 136,
>>> 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4,
>>> 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,
>>> 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10,
>>> 10, 10, 11, 11, 11, 11, 11, 11, 14, 14, 14, 14, 14, 17, 17, 17,
>>> 17, 17, 20, 20, 20, 20, 25, 28, 29, 50, 50, 50, 136, 136, 136,
>>> 136, 136, 136, 136, 136, 136, 136, 1, 1, 1, 1, 1, 1, 2, 2, 2,
>>> 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5,
>>> 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8,
>>> 8, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11,
>>> 11, 11, 14, 14, 14, 14, 14, 17, 17, 17, 17, 17, 20, 20, 20, 20,
>>> 25, 28, 29, 50, 50, 50, 136, 136, 136, 136, 136, 136, 136, 136,
>>> 136, 136), Conc = c(0, 0, 0, 0, 0, 0, 0, 0.807852503274902,
>>> 0.204371494701886,
>>> 0.579222129993907, 0.989062273721619, 0, 1.11728297897571,
>>> 1.41057428121324,
>>> 0.888883702851307, 1.259907624008, 1.45753269675829, 1.07077516747401,
>>> 0.843279379, 0, 0.763110069196737, 1.11297791434297, 1.10087763997637,
>>> 0.946929594501016, 1.33112168, 0.654041755, 0.694167499, 1.289548703,
>>> 1.117139864, 0.807196192, 0.720221376552025, 0.560082823, 0.476583438,
>>> 2.590855204, 0.51510972, 1.072946887, 0.537999938614396, 
>>> 0.886684225905255,
>>> 0.630178116793598, 1.31534758842196, 1.33333958571746, 0.922032210748255,
>>> 0.429930193046174, 1.35881467717335, 0.790045927902363, 1.22484702570724,
>>> 0.808104508207897, 1.31185966817903, 1.51837686425553, 1.74105163638734,
>>> 1.80365598487402, 1.13240352674377, 1.50086243061644, 2.06355364280445,
>>> 0.439350890906039, 1.54692793444949, 1.78758216051046, 1.09043400023239,
>>> 0.811328376840514, 0.459192443530981, 0.695333473157298, 
>>> 0.387995007681174,
>>> 0.784627063444921, 1.02282256375842, 0.382687104107726, 0.554290634950242,
>>> 0.130420456296453, 0.324194753224919, 0.31106140274139, 0.513473505828888,
>>> 0.878620320248701, 1.18404358659996, 0.136926837896477, 0, 0,
>>> 0.835588760032974, 0.558617235576616, 1.21002805866839, 0.769381068031404,
>>> 1.04514254228094, 0.373251847173678, 0.389005898972802, 0.183141006154896,
>>> 0.223596336820146, 0.315526423315647, 0.0930349732768131,
>>> 0.169959185212759,
>>> 0.161878841748425, 0, 0.0483041009105874, 0, 0, 0, 0.0777005553478052,
>>> 0, 0.153175826795441, 0.0428171049833677, 0, 0, 0, 0, 0, 0, 0,
>>> 0, 0, 0, 26.564295705327, 5.5893744508169, 7.22612934071834,
>>> 36.6563989567777, 0, 28.8967184437329, 28.4030370337251, 28.0886043901352,
>>> 26.1230935842208, 28.8895673910072, 42.6814210131968, 32.3555695551062,
>>> 0.76883326657205, 34.6159136622156, 38.329242204291, 56.4476583636484,
>>> 26.6249506083603, 31.3001451026823, 23.7339071829084, 23.3702284599355,
>>> 36.669903715038, 44.7377244306005, 31.2079335923023, 32.8613384312272,
>>> 29.4259634309146, 45.6112405959009, 48.1231689836687, 55.0037961570027,
>>> 32.9822316456421, 20.0382768189682, 26.0986380308655, 28.8915584506145,
>>> 28.7949023823068, 30.0278417498425, 58.8089779973569, 20.3602570111197,
>>> 29.6269605259023, 28.4404986724604, 30.2165182590977, 19.9204461889074,
>>> 31.1019196559556, 30.3847467747055, 36.8726911479995, 51.0618036275519,
>>> 23.5408013442579, 36.6948355347593, 27.4753860809429, 24.1341667099646,
>>> 27.5411488989643, 35.9021799354022, 19.7417897046158, 31.1403887303244,
>>> 46.1743622734049, 34.8235854891765, 22.1714704189293, 33.6805966894274,
>>> 35.2814908686112, 42.9767437212852, 38.1264997164547, 5.3651357974451,
>>> 42.8990434918385, 25.4908883698364, 25.99649502, 36.4958105490917,
>>> 40.8004126550705, 5.36867162116895, 0.00898476265269363, 0,
>>> 27.6810997945798,
>>> 28.7918300045713, 45.7577183830352, 35.9276318604787, 34.9717618087238,
>>> 29.620354272564, 24.6537513599869, 13.5363982464958, 25.8289073574818,
>>> 12.0090406245759, 4.753436805, 11.849214652228, 8.41410147611612,
>>> 0, 1.80855352862552, 1.1987530031681, 1.01148025243171, 0.495675369574172,
>>> 1.62701127228732, 0, 16.6288242287241, 1.23656061354912, 
>>> 0.323708776035328,
>>> 0, 0.566916625204436, 0, 0, 0, 0, 0, 0, 0, 2.53578781871283,
>>> 3.50083667130797, 0, 0.98049572179098, 0, 3.57129673217304,
>>> 2.77298867949388,
>>> 2.12302645642669, 4.11923869203499, 4.69069462193674, 2.8698666062651,
>>> 2.05079837323067, 0.0602771574448942, 5.96454350250626, 2.26267114439802,
>>> 3.06911285674854, 2.04233129537404, 2.62181873844029, 1.51813653072598,
>>> 1.46193772981073, 2.69864635755833, 3.44016493913122, 2.50834832469627,
>>> 3.48170744166168, 1.00637581555435, 1.67065398473081, 4.18855363095027,
>>> 3.39649762611015, 1.72804613460423, 1.40053679329531, 2.37032387724109,
>>> 3.19332545080983, 2.49474373894248, 2.17800931288708, 2.7601484443213,
>>> 0.91266104095844, 1.93485048639199, 1.19692593420788, 1.79537330666258,
>>> 2.14020930767983, 3.0122526724942, 2.81112226980754, 3.54890724398174,
>>> 3.01022926452999, 2.38263226710738, 3.53569238341869, 3.47869329713911,
>>> 0.679333339820719, 2.4764260756438, 3.82615100065366, 2.20449890383871,
>>> 1.371303113329, 1.2427787019995, 1.73319133880954, 0.391268883238408,
>>> 1.73610193837913, 2.68494324646718, 1.77065393606844, 1.45079980147062,
>>> 0.763775702906329, 0.98566725668627, 0.37838763208699, 0.841811919286804,
>>> 1.46436462204795, 1.98409602726, 0.507005887891038, 0.465515668274195,
>>> 0, 1.873365675227, 1.69023864630648, 2.65530855919137, 2.34392199908302,
>>> 1.61917643594837, 1.05165934333345, 0.564642823436471, 0.121621029620328,
>>> 0.515007625737071, 0.524345809084086, 0.130898614090571, 
>>> 0.332427740242623,
>>> 0.110214989555118, 0, 0.128642193589, 0.119407067173878, 
>>> 0.128926224027295,
>>> 0.0622331866694357, 0.215645168287442, 0, 0.859343941945178,
>>> 0.0500810300696456, 0, 0, 0.0628746592609754), Organ =
>>> structure(as.integer(c(1,
>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
>>> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3,
>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,
>>> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
>>> 2, 2, 2, 2, 2)), .Label = c("Carc", "TD", "Foie"), class = c("ordered",
>>> "factor"))), .Names = c("Tps", "Conc", "Organ"), row.names = c("1",
>>> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13",
>>> "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24",
>>> "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35",
>>> "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46",
>>> "47", "48", "49", "50", "51", "52", "53", "54", "55", "56", "57",
>>> "58", "59", "60", "61", "62", "63", "64", "65", "66", "67", "68",
>>> "69", "70", "71", "72", "73", "74", "75", "76", "77", "78", "79",
>>> "80", "81", "82", "83", "84", "85", "86", "87", "88", "89", "90",
>>> "91", "92", "93", "94", "95", "96", "97", "98", "99", "100",
>>> "101", "102", "103", "104", "105", "106", "107", "108", "109",
>>> "110", "111", "112", "113", "114", "115", "116", "117", "118",
>>> "119", "120", "121", "122", "123", "124", "125", "126", "127",
>>> "128", "129", "130", "131", "132", "133", "134", "135", "136",
>>> "137", "138", "139", "140", "141", "142", "143", "144", "145",
>>> "146", "147", "148", "149", "150", "151", "152", "153", "154",
>>> "155", "156", "157", "158", "159", "160", "161", "162", "163",
>>> "164", "165", "166", "167", "168", "169", "170", "171", "172",
>>> "173", "174", "175", "176", "177", "178", "179", "180", "181",
>>> "182", "183", "184", "185", "186", "187", "188", "189", "190",
>>> "191", "192", "193", "194", "195", "196", "197", "198", "199",
>>> "200", "201", "202", "203", "204", "205", "206", "207", "208",
>>> "209", "210", "211", "212", "213", "214", "215", "216", "217",
>>> "218", "219", "220", "221", "222", "223", "224", "225", "226",
>>> "227", "228", "229", "230", "231", "232", "233", "234", "235",
>>> "236", "237", "238", "239", "240", "241", "242", "243", "244",
>>> "245", "246", "247", "248", "249", "250", "251", "252", "253",
>>> "254", "255", "256", "257", "258", "259", "260", "261", "262",
>>> "263", "264", "265", "266", "267", "268", "269", "270", "271",
>>> "272", "273", "274", "275", "276", "277", "278", "279", "280",
>>> "281", "282", "283", "284", "285", "286", "287", "288", "289",
>>> "290", "291", "292", "293", "294", "295", "296", "297", "298",
>>> "299", "300"), class = c("nfnGroupedData", "nfGroupedData", "groupedData",
>>> "data.frame"), formula = quote(Conc ~ Tps | Organ), FUN = function (x)
>>> max(x, na.rm = TRUE), order.groups = TRUE)
>>> 
>>> 
>>> 
>>> 
>>> Spencer Graves a ??crit :
>>>>       Regarding the following:
>>>> 
>>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>>      data=mydata,
>>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>         variable lengths differ
>>>>
>>>>       This example is NOT self contained and is entirely too
>>>> complicated for me to try to replicate it myself in a reasonable
>>>> period of time.  I will therefore ask one short question:  Are all the
>>>> variable names in the "nlsList" call either columns of "mydata" or
>>>> parameters to be estimated and therefore spelled out in "start"?  If I
>>>> were you, I'd check this all very carefully, being especially careful
>>>> about the distinction between "lCl" and "lC1", in particular.
>>>>
>>>>       If you'd like further help with this, I suggest you try to find
>>>> the simplest possible example that generates problem you don't
>>>> understand, then try to recast that example into one that is
>>>> completely self contained, either a data set in the standard R or nlme
>>>> distribution  or numbers that one can generate with a very few lines
>>>> of code.  If you use random numbers, please "set.seed", to increase
>>>> your confidence that someone else will see what you see.  (And please
>>>> review the posting guide! "www.R-project.org/posting-guide.html".
>>>> Doing so may increase your chances of getting more useful information
>>>> more quickly.)
>>>>
>>>>       spencer graves
>>>> 
>>>> Patrick Giraudoux wrote:
>>>> 
>>>>> Dear listers,
>>>>> 
>>>>> I am trying to fit a model using nlsList() using alternately a
>>>>> SSfol() selfstart function or its developped equivalent formulae.
>>>>> 
>>>>> This preliminary trial works well
>>>>> 
>>>>> mydata<-groupedData(Conc~Tps|Organ,data=mydata)
>>>>> mymod1<-nls(Conc~SSfol(Dose,Tps,lKe,lKa,lCl),data=mydata)
>>>>> 
>>>>> as well as a developped form:
>>>>> 
>>>>> mymod2<-nls(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>>     data=mydata,
>>>>>     start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>     )
>>>>> 
>>>>> However when trying to fit the model with nlsList, I get:
>>>>> 
>>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe)),
>>>>>      data=mydata,
>>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>      )
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>         variable lengths differ
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>         variable lengths differ
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>         variable lengths differ
>>>>> 
>>>>> Or specifying  the grouping factor explicitely:
>>>>> 
>>>>> mymod3<-nlsList(Conc~Dose * exp(lKe+lKa-lCl) *
>>>>> (exp(-exp(lKe)*Tps)-exp(-exp(lKa)*Tps)) /(exp(lKa)-exp(lKe))|Organ,
>>>>>      data=mydata,
>>>>>      start= c(lKe=-2.77, lKa=-1.41, lCl=-1.13)
>>>>>      )
>>>>> 
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>         variable lengths differ
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>         variable lengths differ
>>>>> Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>> extranames,  :
>>>>>         variable lengths differ
>>>>> 
>>>>> 
>>>>> I cannot find out why the grouping factor cannot be used (it has the
>>>>> same length as the other variables...)
>>>>> 
>>>>> Another strange thing occurs: in the example given in the help of
>>>>> nlsList.selfstart, the following command works  well:
>>>>>
>>>>>  fm1 <- nlsList(SSasympOff, CO2)
>>>>> 
>>>>> However its seemingly equivalent applied to the case above fails:
>>>>> 
>>>>> mymod4<-nlsList(SSfol,data=mydata)
>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>> Error in eval(expr, envir, enclos) : object "input" not found
>>>>> 
>>>>> 
>>>>> Any hint/suggestion appreciated.
>>>>> 
>>>>> Kind regards,
>>>>> 
>>>>> Patrick Giraudoux
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at stat.math.ethz.ch mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide!
>>>>> http://www.R-project.org/posting-guide.html
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>> 
>> 
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jeff.breiwick at noaa.gov  Fri Feb 17 21:01:56 2006
From: jeff.breiwick at noaa.gov (J.M. Breiwick)
Date: Fri, 17 Feb 2006 12:01:56 -0800
Subject: [R] sprintf
References: <dt50g0$8da$1@perl.epigenomics.epi>
Message-ID: <dt5a3q$8vd$1@sea.gmane.org>

Hi,

I want to use sprintf with vectors whose lengths vary.
As an example: x = c(2,4,6,10)
sprintf("%i%5f%5f%5f",x[1],x[2],x[3],x[4]) works. But if I have to compute 
the length of x within a function then I cannot list all for format codes 
and sprintf apparently will not accept just "x" - it wants one value for 
each format code as in the above example. Does anyone know a way to handle 
this? And is there a way to repeat the format code like in Fortran (e.g. 
5F4.1)? Thanks.

Jeff B.



From vivek.satsangi at gmail.com  Fri Feb 17 21:23:41 2006
From: vivek.satsangi at gmail.com (Vivek Satsangi)
Date: Fri, 17 Feb 2006 15:23:41 -0500
Subject: [R] (Newbie) Functions on vectors
Message-ID: <bcb171920602171223u46591f8eyba27ad1e070d51ac@mail.gmail.com>

Folks,

I want to make the following function more efficient, by vectorizing it:

getCriterionDecisionDate <- function (quarter , year)
{
  if (length(quarter) != length(year)) stop ("Quarter and year vectors
of unequal length!");
  ret <- character(0);

  for (i in 1:length(quarter)) {
    currQuarter <- quarter[i];
    currYear <- year[i];

    if ((currQuarter < 1) | (currQuarter > 4)) stop ("Invalid quarter!");
    if ((currYear < 1986) | (currYear > 2004)) stop ("Invalid year!");

    # If the criterion date is 1Q2004, then the reports were for periods
    # ending in Feb, March and April 2004 and the decision date is July 1, 2004.
    if (currQuarter == 1) {
      ret <- c(ret,paste("06/30/",currYear,sep=""));
    } else if (currQuarter == 2) {
      ret <- c(ret,paste("09/30/",currYear,sep=""));
    } else if (currQuarter == 3) {
      ret <- c(ret,paste("12/31/",currYear,sep=""));
    } else if (currQuarter == 4) {
      ret <- c(ret,paste("3/31/",currYear+1,sep=""));
    }
  }

  ret;
}


How can I make the 'if' statements work on vectors rather than using
one value at a time? (sorry, my copy of MASS is at home).

--
-- Vivek Satsangi
Student, Rochester, NY USA



From mschwartz at mn.rr.com  Fri Feb 17 21:27:41 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Fri, 17 Feb 2006 14:27:41 -0600
Subject: [R] sprintf
In-Reply-To: <dt5a3q$8vd$1@sea.gmane.org>
References: <dt50g0$8da$1@perl.epigenomics.epi> <dt5a3q$8vd$1@sea.gmane.org>
Message-ID: <1140208061.4543.69.camel@localhost.localdomain>

On Fri, 2006-02-17 at 12:01 -0800, J.M. Breiwick wrote:
> Hi,
> 
> I want to use sprintf with vectors whose lengths vary.
> As an example: x = c(2,4,6,10)
> sprintf("%i%5f%5f%5f",x[1],x[2],x[3],x[4]) works. But if I have to compute 
> the length of x within a function then I cannot list all for format codes 
> and sprintf apparently will not accept just "x" - it wants one value for 
> each format code as in the above example. Does anyone know a way to handle 
> this? And is there a way to repeat the format code like in Fortran (e.g. 
> 5F4.1)? Thanks.
> 
> Jeff B.

Is the format of the vector 'x' predictable?  In other words, will the
first element always be printed as an integer with the rest (of unknown
length) printed as floats?

Keep in mind that sprintf() is vectorized.

So:

x <- c(2, 4, 6, 10)

> c(sprintf("%i", x[1]), sprintf("%5f", x[-1]))
[1] "2"         "4.000000"  "6.000000"  "10.000000"


> x <- seq(2, 20, 2)
> x
 [1]  2  4  6  8 10 12 14 16 18 20

# Same code here
> c(sprintf("%i", x[1]), sprintf("%5f", x[-1]))
 [1] "2"         "4.000000"  "6.000000"  "8.000000"  "10.000000"
 [6] "12.000000" "14.000000" "16.000000" "18.000000" "20.000000"


Does that get what you want?

BTW, please do not create a new post by responding to a different
thread. It plays havoc with the list archive making it difficult to
search for your post and any replies.

HTH,

Marc Schwartz



From ggrothendieck at gmail.com  Fri Feb 17 21:37:08 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 17 Feb 2006 15:37:08 -0500
Subject: [R] (Newbie) Functions on vectors
In-Reply-To: <bcb171920602171223u46591f8eyba27ad1e070d51ac@mail.gmail.com>
References: <bcb171920602171223u46591f8eyba27ad1e070d51ac@mail.gmail.com>
Message-ID: <971536df0602171237j59740f99vb630188f77ecb312@mail.gmail.com>

You can use ifelse but even better note that
the zoo package has the yearqtr class which represents years
and quarters internally as years + (qtr-1)/4 where qtr is 0,1,2,3
so as to be consistent with ts class.   It also
has an as.Date.yearqtr method which will convert them
to class Date.  Using these the code is really just one line:


# test data
year <- 2001:2004
qtr  <- 1:4

library(zoo)
as.Date(as.yearqtr(year + qtr/4), frac = 1)


On 2/17/06, Vivek Satsangi <vivek.satsangi at gmail.com> wrote:
> Folks,
>
> I want to make the following function more efficient, by vectorizing it:
>
> getCriterionDecisionDate <- function (quarter , year)
> {
>  if (length(quarter) != length(year)) stop ("Quarter and year vectors
> of unequal length!");
>  ret <- character(0);
>
>  for (i in 1:length(quarter)) {
>    currQuarter <- quarter[i];
>    currYear <- year[i];
>
>    if ((currQuarter < 1) | (currQuarter > 4)) stop ("Invalid quarter!");
>    if ((currYear < 1986) | (currYear > 2004)) stop ("Invalid year!");
>
>    # If the criterion date is 1Q2004, then the reports were for periods
>    # ending in Feb, March and April 2004 and the decision date is July 1, 2004.
>    if (currQuarter == 1) {
>      ret <- c(ret,paste("06/30/",currYear,sep=""));
>    } else if (currQuarter == 2) {
>      ret <- c(ret,paste("09/30/",currYear,sep=""));
>    } else if (currQuarter == 3) {
>      ret <- c(ret,paste("12/31/",currYear,sep=""));
>    } else if (currQuarter == 4) {
>      ret <- c(ret,paste("3/31/",currYear+1,sep=""));
>    }
>  }
>
>  ret;
> }
>
>
> How can I make the 'if' statements work on vectors rather than using
> one value at a time? (sorry, my copy of MASS is at home).
>
> --
> -- Vivek Satsangi
> Student, Rochester, NY USA
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Fri Feb 17 21:39:26 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 17 Feb 2006 20:39:26 +0000 (GMT)
Subject: [R] (Newbie) Functions on vectors
In-Reply-To: <bcb171920602171223u46591f8eyba27ad1e070d51ac@mail.gmail.com>
References: <bcb171920602171223u46591f8eyba27ad1e070d51ac@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602172035060.23525@gannet.stats.ox.ac.uk>

Something like

Qs <- c("30/6", "30/9", "31/12", "31/3")
paste(Qs[quarter], year + (quarter==4), sep="")

(no trailing semicolons are necessary)

On Fri, 17 Feb 2006, Vivek Satsangi wrote:

> Folks,
>
> I want to make the following function more efficient, by vectorizing it:
>
> getCriterionDecisionDate <- function (quarter , year)
> {
>  if (length(quarter) != length(year)) stop ("Quarter and year vectors
> of unequal length!");
>  ret <- character(0);
>
>  for (i in 1:length(quarter)) {
>    currQuarter <- quarter[i];
>    currYear <- year[i];
>
>    if ((currQuarter < 1) | (currQuarter > 4)) stop ("Invalid quarter!");
>    if ((currYear < 1986) | (currYear > 2004)) stop ("Invalid year!");
>
>    # If the criterion date is 1Q2004, then the reports were for periods
>    # ending in Feb, March and April 2004 and the decision date is July 1, 2004.
>    if (currQuarter == 1) {
>      ret <- c(ret,paste("06/30/",currYear,sep=""));
>    } else if (currQuarter == 2) {
>      ret <- c(ret,paste("09/30/",currYear,sep=""));
>    } else if (currQuarter == 3) {
>      ret <- c(ret,paste("12/31/",currYear,sep=""));
>    } else if (currQuarter == 4) {
>      ret <- c(ret,paste("3/31/",currYear+1,sep=""));
>    }
>  }
>
>  ret;
> }
>
>
> How can I make the 'if' statements work on vectors rather than using
> one value at a time? (sorry, my copy of MASS is at home).
>
> --
> -- Vivek Satsangi
> Student, Rochester, NY USA
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ehlers at math.ucalgary.ca  Fri Feb 17 21:55:56 2006
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Fri, 17 Feb 2006 13:55:56 -0700
Subject: [R] Variance for Vector of Constants is STILL Not Zero
In-Reply-To: <000001c633ee$7be4e7f0$0a00a8c0@Dell2003desktop>
References: <000001c633ee$7be4e7f0$0a00a8c0@Dell2003desktop>
Message-ID: <43F6385C.50707@math.ucalgary.ca>

Barry,
Try the latest _patched_ version. I'm on 2006-02-12, but that may
already be superseded. I get var(x) = 0.

Peter Ehlers

Barry Zajdlik wrote:
> Hello all,
> 
> Thanks for the responses but I am still annoyed by this seemingly simple
> problem; I recorded sessionInfo() as below.
> 
> x<-rep(0.02,10)
> 
>>var(x)
> 
> [1] 1.337451e-35
> 
>> sessionInfo()
> 
> R version 2.1.0, 2005-04-18, i386-pc-mingw32 
> 
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"
> "datasets" 
> [7] "base"     
> 
> 
> 
> I then decided to download the latest version today but obtained the
> same result.
> 
> 
>>x<-rep(0.02,10)
>>var(x)
> 
> [1] 1.337451e-35
> 
> 
>>sessionInfo()
> 
> R version 2.2.1, 2005-12-20, i386-pc-mingw32 
> 
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"
> "datasets" 
> [7] "base"    
> 
> 
> I Changed .Machine$double.eps to make the calculations LESS accurate.
> My thought was that if I reduced the precision, 1-eps would return 1
> instead of some number less than 1.  My thought was that if eps were
> sufficiently large my sample problem would return a zero.  This didn't
> happen though.
> 
> Again, any thoughts would be appreciated.
> 
> Regards,
> Barry Zajdlik
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From pburns at pburns.seanet.com  Fri Feb 17 21:59:19 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Fri, 17 Feb 2006 20:59:19 +0000
Subject: [R] (Newbie) Functions on vectors
In-Reply-To: <bcb171920602171223u46591f8eyba27ad1e070d51ac@mail.gmail.com>
References: <bcb171920602171223u46591f8eyba27ad1e070d51ac@mail.gmail.com>
Message-ID: <43F63927.6060802@pburns.seanet.com>

Vivek,

For the tests you can do, for example:

if(any(quarter < 1 | quarter > 4)) stop('invalid quarter(s)')

For the dates you can do:

ret <- paste(c('6/30', '9/30', '12/31', '3/31')[quarter],
    year + quarter == 4, sep='/')

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Vivek Satsangi wrote:

>Folks,
>
>I want to make the following function more efficient, by vectorizing it:
>
>getCriterionDecisionDate <- function (quarter , year)
>{
>  if (length(quarter) != length(year)) stop ("Quarter and year vectors
>of unequal length!");
>  ret <- character(0);
>
>  for (i in 1:length(quarter)) {
>    currQuarter <- quarter[i];
>    currYear <- year[i];
>
>    if ((currQuarter < 1) | (currQuarter > 4)) stop ("Invalid quarter!");
>    if ((currYear < 1986) | (currYear > 2004)) stop ("Invalid year!");
>
>    # If the criterion date is 1Q2004, then the reports were for periods
>    # ending in Feb, March and April 2004 and the decision date is July 1, 2004.
>    if (currQuarter == 1) {
>      ret <- c(ret,paste("06/30/",currYear,sep=""));
>    } else if (currQuarter == 2) {
>      ret <- c(ret,paste("09/30/",currYear,sep=""));
>    } else if (currQuarter == 3) {
>      ret <- c(ret,paste("12/31/",currYear,sep=""));
>    } else if (currQuarter == 4) {
>      ret <- c(ret,paste("3/31/",currYear+1,sep=""));
>    }
>  }
>
>  ret;
>}
>
>
>How can I make the 'if' statements work on vectors rather than using
>one value at a time? (sorry, my copy of MASS is at home).
>
>--
>-- Vivek Satsangi
>Student, Rochester, NY USA
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From sell_mirage_ne at hotmail.com  Fri Feb 17 22:23:41 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Fri, 17 Feb 2006 15:23:41 -0600
Subject: [R] extracting a element with a name attribute from a list
Message-ID: <BAY110-F3423C71E2C3400DCFA7BBAC7F80@phx.gbl>

Hi R users

I like to extract (or collect) a numeric element with a name  from a list.

Is there any way to extract just a numeric element without the name attached 
to the element.

For example,

>mylist

        Mantel-Haenszel chi-squared test with continuity correction

data:  table(mydata[, x])
Mantel-Haenszel X-squared = 8.3832, df = 1, p-value = 0.003787
alternative hypothesis: true common odds ratio is not equal to 1
95 percent confidence interval:
0.2596963 0.7647255
sample estimates:
common odds ratio
        0.4456415

>is.list(mylist)
[1] TRUE
>names(mylist)
[1] "statistic"   "parameter"   "p.value"     "conf.int"    "estimate"    
"null.value"  "alternative"
[8] "method"      "data.name"
>mylist$estimate
common odds ratio
        0.4456415

I like to extract only a numeric element ( 0.4456415 ) without the name 
(common odds ratio).

How can I do that ?

Thanks

_________________________________________________________________
Dont just search. Find. Check out the new MSN Search!



From beperron at wustl.edu  Fri Feb 17 22:30:49 2006
From: beperron at wustl.edu (Brian Perron)
Date: Fri, 17 Feb 2006 15:30:49 -0600
Subject: [R] Heckman regression / adjustment for standard errors?
Message-ID: <84C59624B1B0204BBCB3B7DDF981AE63010AD19D@GWB-PO.gwb.wustl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060217/53caba6b/attachment.pl

From Jason.Mills at afhe.ualberta.ca  Fri Feb 17 22:35:47 2006
From: Jason.Mills at afhe.ualberta.ca (Mills, Jason)
Date: Fri, 17 Feb 2006 14:35:47 -0700
Subject: [R] Matrix indexing in a loop
Message-ID: <DAA63BFCC1431A47B75B73476BD237FC361D6A@afhe-ex.afhe.ualberta.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060217/011db6a4/attachment.pl

From rand at amgen.com  Fri Feb 17 22:44:41 2006
From: rand at amgen.com (Rand, Hugh)
Date: Fri, 17 Feb 2006 13:44:41 -0800
Subject: [R] trouble with extraction/interpretation of variance
	struct	ure para	meters from a model built using gnls and
	varConstPower
Message-ID: <567ACB2E39C83543B746F1AD7F5E5E04062E5450@wa-mb2-sea.amgen.com>

Works perfectly. Thank you.
-Hugh Rand

-----Original Message-----
From: Spencer Graves [mailto:spencer.graves at pdf.com]
Sent: Sunday, January 15, 2006 6:41 PM
To: Rand, Hugh
Cc: 'r-help at lists.R-project.org'
Subject: Re: [R] trouble with extraction/interpretation of variance
structure para meters from a model built using gnls and varConstPower


	  How about this:

 > exp(coef(model3$modelStruct$varStruct)["const"])
     const
0.6551298

	  Does that answer the question about not understanding the
connection 
between summary(model3) and coef(model3$modelStruct$varStruct)["const"]?

	  Regarding the question about R not being able to find
'coef.varFunc', 
I tried the following:
 > methods("coef")
<snip>
  coef.varFunc*
[37] coef.varIdent*        coef.varPower*

    Non-visible functions are asterisked	

	  Since "coef.varFunc" is "asterisked", I tried 
'getAnywhere(coef.varFunc)'.  I walked through this code line by line, 
until I found the following:

 > (val <- as.vector(model3$modelStruct$varStruct))
Variance function structure of class varConstPower representing
     const     power
0.6551298 0.8913665

	  Answer the questions?
	  spencer graves

Rand, Hugh wrote:

> I have been using gnls with the weights argument (and varConstPower) to
> specify a variance structure for curve fits. In attempting to extract the
> parameters for the variance model I am seeing results I don't understand.
> When I simply display the model (or use "summary" on the model), I get
what
> seem like reasonable values for both "power" and "const". When I actually
> try to extract the values, I get the same number for the "power", but a
> different (and less sensible) value for "const".
> 
> The simplest example I can come up with that shows the problem is as
> follows: 
> 
> 
> #Set up data
> 
> x    = c(0,0,0,1,1,1,2,2,2,3,3,3,4,4,4,5,5,5,6,6,6,7,7,7);
> y0   = c(.1,.1,.1, .5,.5,.5, 1,1,1, 2,2,2, 4,4,4, 7,7,7, 9,9,9, 10,10,10);
> yp   = c(0,.03,.05, 0,.05,.01, 0,.07,.03, .1,0,.2, .2,.1,0, .3,0,.1,
> 0,.3,.4, .3,.5,0);
> y    = y0 + 4*yp;
> data = data.frame(x=x,y=y);
> 
> #Run model
> 
> library(nlme)
> model3 = try(gnls(y ~
>
SSfpl(x,A,B,xmid,scal),data=data,weights=varConstPower(const=1,power=0,form=
> ~fitted(.))));
> 
> #Examine results
> 
> model3;                                         #const = .6551298,   power
=
> .8913665
> summary(model3);                                #const = .6551298,   power
=
> .8913665               
> 
> coef(model3$modelStruct$varStruct)["power"];    #                    power
=
> .8913665
> coef(model3$modelStruct$varStruct)["const"];    #const = -0.4229219 
> coef.varFunc(model3$modelStruct$varStruct);     #R can't seem to find this
> function, Splus can
> 
> 
> Any advice on what I am doing wrong would be appreciated.
> 
> Hugh Rand
> Senior Scientist
> Amgen
> rand at amgen.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Fri Feb 17 23:01:28 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 Feb 2006 23:01:28 +0100
Subject: [R] extracting a element with a name attribute from a list
In-Reply-To: <BAY110-F3423C71E2C3400DCFA7BBAC7F80@phx.gbl>
References: <BAY110-F3423C71E2C3400DCFA7BBAC7F80@phx.gbl>
Message-ID: <x2lkw9hcg7.fsf@turmalin.kubism.ku.dk>

"Taka Matzmoto" <sell_mirage_ne at hotmail.com> writes:

> Hi R users
> 
> I like to extract (or collect) a numeric element with a name  from a list.
> 
> Is there any way to extract just a numeric element without the name
> attached to the element.
> 
> For example,
> 
> >mylist
> 
>         Mantel-Haenszel chi-squared test with continuity correction
> 
> data:  table(mydata[, x])
> Mantel-Haenszel X-squared = 8.3832, df = 1, p-value = 0.003787
> alternative hypothesis: true common odds ratio is not equal to 1
> 95 percent confidence interval:
> 0.2596963 0.7647255
> sample estimates:
> common odds ratio
>         0.4456415
> 
> >is.list(mylist)
> [1] TRUE
> >names(mylist)
> [1] "statistic"   "parameter"   "p.value"     "conf.int"    "estimate"
> "null.value"  "alternative"
> [8] "method"      "data.name"
> >mylist$estimate
> common odds ratio
>         0.4456415
> 
> I like to extract only a numeric element ( 0.4456415 ) without the
> name (common odds ratio).
> 
> How can I do that ?

x <- mylist$estimate
names(x) <- NULL

or

x <- as.vector(mylist$estimate)

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From tlumley at u.washington.edu  Fri Feb 17 23:02:57 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 17 Feb 2006 14:02:57 -0800 (PST)
Subject: [R] Variance for Vector of Constants is STILL Not Zero
In-Reply-To: <000001c633ee$7be4e7f0$0a00a8c0@Dell2003desktop>
References: <000001c633ee$7be4e7f0$0a00a8c0@Dell2003desktop>
Message-ID: <Pine.LNX.4.64.0602171355270.29349@homer21.u.washington.edu>

On Fri, 17 Feb 2006, Barry Zajdlik wrote:
> Hello all,
>
> Thanks for the responses but I am still annoyed by this seemingly simple
> problem; I recorded sessionInfo() as below.
>
> x<-rep(0.02,10)
>> var(x)
> [1] 1.337451e-35

Well, yes, it is accurate only to 35 digits and this is a bit unfortunate 
since it could be more accurate in this case. The exact result is probably 
system-dependent, but there has been a bug report for a long time 
(PR#1228) that var() is not as accurate as it could possibly be, and 
patches would be welcome.  They obviously aren't a very high priority for 
anyone.

> I Changed .Machine$double.eps to make the calculations LESS accurate.
> My thought was that if I reduced the precision, 1-eps would return 1
> instead of some number less than 1.  My thought was that if eps were
> sufficiently large my sample problem would return a zero.  This didn't
> happen though.
>

.Machine is a set of constants that describe your hardware and C 
implementation.  They are right when you start. If you change them all 
that happens is that they become wrong -- R doesn't go in and re-engineer 
the floating point hardware.

 	-thomas



From spencer.graves at pdf.com  Fri Feb 17 23:32:19 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 17 Feb 2006 14:32:19 -0800
Subject: [R] nonlinear model:  pseudo-design matrix
In-Reply-To: <43F605C8.6080209@pdf.com>
References: <43F13B78.2050601@stats.waikato.ac.nz> <43F55054.30308@pdf.com>
	<43F579E3.6060408@stats.waikato.ac.nz> <43F605C8.6080209@pdf.com>
Message-ID: <43F64EF3.6070108@pdf.com>

Hi, Murray:

	  I just got 54 hits from RSiteSearch("numerical differentiation"), the 
first of which mentioned a function "numericDeriv" WITH a warning 
(http://finzi.psych.upenn.edu/R/Rhelp02a/archive/55462.html).

	  hope this helps.
	  spencer graves
###################
Hi Spencer,

I will try some of the ways you suggest and thank you for the 
suggestions. I still think that performing a score test is a sensible 
thing to do in my situation, though.

Murray

Spencer Graves wrote:

> Hi, Murray:
> 
>       When I have problems with nonconvergence of nls, I often
> move the problem to "optim(..., hessian=TRUE)".  Even if the larger 
> model is overparameterized and the hessian is singular, I optim usually 
> returns an answer from which I can then compute 2*log(likelihood ratio). 
>  Moreover, the hessian will help me diagnose the problem.  If it were my 
> problem today, I'd try the following:
> 
>       (1) If there are substantial differences in the diagonal elements 
> of the hessian, it suggests the scaling should be adjusted.  Not too 
> long ago, someone else suggested that this could be done within optim 
> via the argument control = list(parscale=...).  I have yet to try that, 
> but I think it should work fine.
> 
>       (2) If the diagonal elements of the hessian do not differ by more 
> than a couple orders of magnitude, then I'd try eigen(fit$hessian, 
> symmetric=TRUE).  The relative magnitudes of the eigenvalues will expose 
> the effective numer of paramaters that can be estimated, and the 
> eigenvectors associated with the smallest eigenvalues can help one 
> diagnose the problem.
> 
>       hope this helps.
>       spencer graves
> 
> Murray Jorgensen wrote:
> 
>> Hi Spencer,
>>
>> you were the only one to reply. Yes I am aware of the intrinsic / 
>> parameter effects distinction and the advantages of LR tests and 
>> profiling over Wald tests based on the local curvature of the 
>> loglikelihood surface at the larger of two models being compared. My 
>> situation is that I am comparing two nested models both of which have 
>> uncomfortably many parameters for the amount of data available. I am 
>> able to fit the smaller of the two models but not the larger. In this 
>> situation neither the the Wald nor the LR test is available to me but 
>> the score test (a.k.a. the Lagrange Multiplier test) is available to 
>> me because it is based on the loglikelihood gradient at the smaller 
>> model.
>>
>> I have been able to carry out the test by extracting
>>
>> X <- smaller.nls$m$gradient()
>>
>> and obtaining the extra columns of X for the parameters in larger but 
>> not in smaller by numerical differentiation. It seems that there 
>> should be some way of obtaining the extra columns without recourse to 
>> numerical differentiation, though.
>>
>> Cheers,  Murray Jorgensen
>>
>> Spencer Graves wrote:
>>
>>>       There doubtless is a way to extract the gradient information 
>>> you desire, but have you considered profiling instead?  Are you 
>>> familiar with the distinction between intrinsic and parameter effects 
>>> curvature?  In brief, part of the nonlinearities involved in 
>>> nonlinear least squares are intrinsic to the problem, and part are 
>>> due to the how the problem is parameterized.  If you change the 
>>> parameterization, you change the parameter effects curvature, but the 
>>> intrinsic curvature remains unchanged.  Roughly 30 years ago, Doug 
>>> Bates and Don Watts reanalized a few dozen published nonlinear 
>>> regression fits, and found that in all but perhaps one or two, the 
>>> parameter effects were dominant and the intrinsic curvature was 
>>> negligible.  See Bates and Watts (1988) Nonlinear Regression Analysis 
>>> and Its Applications (Wiley) or Seber and Wild (1989) Nonlinear 
>>> Regression (Wiley).
>>>
>>>       Bottom line:
>>>
>>>       1.  You will always get more accurate answers from profiling 
>>> than from the Wald "pseudodesign matrix" approach.  Moreover, often 
>>> the differences are dramatic.
>>>
>>>       2.  I just did RSiteSearch("profiling with nls").  The first 
>>> hit was 
>>> "http://finzi.psych.upenn.edu/R/library/stats/html/profile.nls.html". 
>>> If this is not satisfactory, please explain why.
>>>
>>>       hope this helps.
>>>       spencer graves
>>>
>>> Murray Jorgensen wrote:
>>>
>>>> Given a nonlinear model formula and a set of values for all the
>>>> parameters defining a point in parameter space, is there a neat way to
>>>> extract the pseudodesign matrix of the model at the point? That is the
>>>> matrix of partial derivatives of the fitted values w.r.t. the 
>>>> parameters
>>>> evaluated at the point.
>>>>
>>>> (I have figured out how to extract the gradient information from an 
>>>> nls fitted model using the nlsModel part, but I wish to implement a 
>>>> score test, so I need to be able to extract the information at 
>>>> points other than the mle.)
>>>>
>>>> Thanks, Murray Jorgensen
>>
>>
>>
>



From bpontar at amazon.com  Sat Feb 18 00:04:18 2006
From: bpontar at amazon.com (Pontarelli, Brett)
Date: Fri, 17 Feb 2006 15:04:18 -0800
Subject: [R] Matrix indexing in a loop
Message-ID: <2047FEBD93E8744D8A82C2510BB823C4014B03FD@exchg-sea3-02.ant.amazon.com>

Do you have to use a loop?  The following function should do what you want for the 1st order:

rook = function(Y) {
	rsub = function(Z) {
		X = matrix(0,nrow(Z),ncol(Z));
		X[1:(N-1),1:M] = X[1:(N-1),1:M] + Z[2:N,1:M];
		X[2:N,1:M] = X[2:N,1:M] + Z[1:(N-1),1:M];
		X[1:N,1:(M-1)] = X[1:N,1:(M-1)] + Z[1:N,2:M];
		X[1:N,2:M] = X[1:N,2:M] + Z[1:N,1:(M-1)];
		return(X);
	}
	return(rsub(Y)/rsub(matrix(1,nrow(Y),ncol(Y))));
}

I'm not sure I understand how the higher orders work.  For example, an interior element for the 1st order is always divided by 4.  Is an interior element for a 3rd order divided by 4 or 8 or something else?  Also, how are you implementing your 3D matrices?

--Brett


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mills, Jason
Sent: Friday, February 17, 2006 1:36 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Matrix indexing in a loop


How do you specify matrix location a[i,j] (or a[i-1,j], etc.) in a "for"
loop?  

I am looking for a flexible method of indexing neighbors over a series of lags (1,2,3...) and I may wish to extend this method to 3D arrays.


Example:

Data matrix
> fun
     [,1] [,2] [,3]
[1,]    1    5    9
[2,]    2    6   10
[3,]    3    7   11
[4,]    4    8   12


For each element a[i,j] in "fun", sum the 1st order (Rook's) neighbors:

a[i-1,j]

a[i+1,j]

a[i,j-1]

a[i,j+1]

Then divide by the number of elements included as neighbors-- this number depends on the location of a[i,j] in the matrix.


Insert the product of the neighbor calculation for each a[i,j] into the corresponding position b[i,j] in an empty matrix with the same dimensions as "fun".


For example, element [2,2] in "fun" should yield element [2,2] in a new matrix equal to 24/4=6.  Of course, element [1,1] in the new matrix should be the product of only two numbers.


Thanks

J. Mills

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From priggs at warnercnr.colostate.edu  Sat Feb 18 00:40:58 2006
From: priggs at warnercnr.colostate.edu (Philip Riggs)
Date: Fri, 17 Feb 2006 16:40:58 -0700
Subject: [R] Something changed and glm(..., family=binomial) doesn't work now
Message-ID: <1D6DE5F6-1107-4F29-9913-D2407B35B543@cnr.colostate.edu>

I ran logistic regression models last week using glm 
(...,family=binomial) and got a set of results. Since then I have  
loaded the Epi package for ROC analysis. Now when I run those same  
models I get completely different results, with most being:

Warning message:
fitted probabilities numerically 0 or 1 occurred in: glm.fit(x = X, y  
= Y, weights = weights, start = start, etastart = etastart,

I didn't get this result last week. Also, the ROC function in Epi is  
no longer working (giving a ROC of 1.000). What would have changed to  
cause this and how can I fix it?

p.s. To check I ran the same model in S and have the same result as  
last week.

Philip



From H.Y.Wong at leeds.ac.uk  Sat Feb 18 00:48:30 2006
From: H.Y.Wong at leeds.ac.uk (Yan Wong)
Date: Fri, 17 Feb 2006 23:48:30 +0000
Subject: [R] iPlots and mouse clicks
Message-ID: <5F156AEB-649E-4C5A-82B0-489FDF2C98FF@leeds.ac.uk>

Hi,

I'm investigating the iPlots package as a teaching aid, and I'd like  
to be able to detect mouse clicks (with x-y position) in the plotting  
window. I can't see how to do this - the only event loop that is  
illustrated in the examples uses iset.sel.changed(). Is there anyone  
out there who has made use of the iPlots event loop functionality and  
might be able to give me some tips?

Thanks, and apologies if this is not the correct list,

Yan Wong
Leeds



From obrienc at email.arizona.edu  Sat Feb 18 01:12:49 2006
From: obrienc at email.arizona.edu (Chris O'Brien)
Date: Fri, 17 Feb 2006 17:12:49 -0700
Subject: [R] truncated negative binomial using rnegbin
Message-ID: <6.2.1.2.2.20060202152956.01f47570@inbox.email.arizona.edu>

Dear R users,
I'm wanting to sample from the negative binomial distribution using the 
rnegbin function from the MASS library to create artificial samples for the 
purpose of doing some power calculations.  However, I would like to work 
with samples that come from a negative binomial distribution that includes 
only values greater than or equal to 1 (a truncated negative binomial), and 
I can't think of a straightforward way to accomplish this using rnegbin.

One suggestion I've received is that I use an iterative process to select 
numbers from the negative binomial, throw out the zeros, test the 
distribution for the desired parameters, and then repeat until the 
parameters are in an acceptable range.  I could then sample this 
'population' using the sample function, and go from there.  One major 
problem with this approach is that it is very time consuming on a desktop 
machine.

Here's a piece of code (from a friend, and untested)  that will do such a 
thing:

#
#  Function to generate a vector containing values from a truncated
#  negative binomial distribution (i.e., no zeros).  Select desired
#  mean and variance, sample size, initial values for mean and theta,
#  and a threshold value for tests.
#
#  format:  out<-nbin(desired_mean, desired_variance, n, initial_mean,
#                     theta, threshold_level)
#
#  example:  out<-nbin(2, 1, 100, 2, 2, 0.1)
#
#
nbin<-function(mu.s,var.s,n,mu.i,theta,test)
{
   library(MASS)

   mu<-0
   var<-0
   rand<-rep(0,n)
   while(abs(mu.s-mu)>=test & abs(var.s-var)>=test)
   {
     for(i in 1:n)
     {
      rnb<-0
      while(rnb==0)
       rnb<-rnegbin(1,mu.i,theta)
      rand[i]<-rnb
     }
     mu<-mean(rand)
     var<-var(rand)
   }
   return(rand)
}



As I am wanting to use these samples to compute power for a bootstrap 
procedure, the time demands will become prohibitive very quickly, 
especially for large sample sizes.
I'm thinking that there must be a more efficient, elegant, and quicker 
solution to the problem, but am having problems coming up with the answer.
I'd greatly welcome any insight into a more efficient method.

thanks in advance for any insight,
Chris O'Brien



From bpontar at amazon.com  Sat Feb 18 01:34:03 2006
From: bpontar at amazon.com (Pontarelli, Brett)
Date: Fri, 17 Feb 2006 16:34:03 -0800
Subject: [R] Matrix indexing in a loop
Message-ID: <2047FEBD93E8744D8A82C2510BB823C4014B04D9@exchg-sea3-02.ant.amazon.com>

You're right I had N and M defined outside of the function and rook and rsub were picking up on that.  The following is a bit better and more cleaned up version with i-th order option:

rook = function(Y,i) {
	N = nrow(Y);
	M = ncol(Y);
	rsub = function(Z,i) {
		X = matrix(0,N,M);
		X[1:(N-i),] = X[1:(N-i),] + Z[(1+i):N,];
		X[(1+i):N,] = X[(1+i):N,] + Z[1:(N-i),];
		X[,1:(M-i)] = X[,1:(M-i)] + Z[,(1+i):M];
		X[,(1+i):M] = X[,(1+i):M] + Z[,1:(M-i)];
		return(X);
	}
	return(rsub(Y,i)/rsub(matrix(1,N,M),i));
}

Notice that the variable "i" can be passed any value even one that causes an error.

--Brett


-----Original Message-----
From: Mills, Jason [mailto:Jason.Mills at afhe.ualberta.ca] 
Sent: Friday, February 17, 2006 4:11 PM
To: Pontarelli, Brett
Subject: RE: [R] Matrix indexing in a loop

Hi Brett, thanks for the tip.

I tried this function on my sample matrix and got the error message "Error in rsub(fun) : object "N" not found".  Your code looks like it should work, so I must be doing some wrong.  I will continue to experiment.

As for the neighbor pattern, the convention follows the rules of chess.
I would consider a 2nd order rook case to include only 4 elements:

a[i-2,j]
a[i+2,j]
a[i,j-2]
a[i,j+2]

Even 3rd order Rook would still only include 4 elements.  As another example, a Queen neighborhood includes 8 elements, independent of the lag order.


I haven't started using 3D arrays yet.  I am attempting spatio-temporal analysis and I have thought about representing my landscape (two
dimensions) over time (the third dimension).  For now, I'm trying to get a handle on working in two dimensions.

Thanks.  

Jason






-----Original Message-----
From: Pontarelli, Brett [mailto:bpontar at amazon.com]
Sent: Friday, February 17, 2006 4:04 PM
To: Mills, Jason; r-help at stat.math.ethz.ch
Subject: RE: [R] Matrix indexing in a loop

Do you have to use a loop?  The following function should do what you want for the 1st order:

rook = function(Y) {
	rsub = function(Z) {
		X = matrix(0,nrow(Z),ncol(Z));
		X[1:(N-1),1:M] = X[1:(N-1),1:M] + Z[2:N,1:M];
		X[2:N,1:M] = X[2:N,1:M] + Z[1:(N-1),1:M];
		X[1:N,1:(M-1)] = X[1:N,1:(M-1)] + Z[1:N,2:M];
		X[1:N,2:M] = X[1:N,2:M] + Z[1:N,1:(M-1)];
		return(X);
	}
	return(rsub(Y)/rsub(matrix(1,nrow(Y),ncol(Y))));
}

I'm not sure I understand how the higher orders work.  For example, an interior element for the 1st order is always divided by 4.  Is an interior element for a 3rd order divided by 4 or 8 or something else?
Also, how are you implementing your 3D matrices?

--Brett


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mills, Jason
Sent: Friday, February 17, 2006 1:36 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Matrix indexing in a loop


How do you specify matrix location a[i,j] (or a[i-1,j], etc.) in a "for"
loop?  

I am looking for a flexible method of indexing neighbors over a series of lags (1,2,3...) and I may wish to extend this method to 3D arrays.


Example:

Data matrix
> fun
     [,1] [,2] [,3]
[1,]    1    5    9
[2,]    2    6   10
[3,]    3    7   11
[4,]    4    8   12


For each element a[i,j] in "fun", sum the 1st order (Rook's) neighbors:

a[i-1,j]

a[i+1,j]

a[i,j-1]

a[i,j+1]

Then divide by the number of elements included as neighbors-- this number depends on the location of a[i,j] in the matrix.


Insert the product of the neighbor calculation for each a[i,j] into the corresponding position b[i,j] in an empty matrix with the same dimensions as "fun".


For example, element [2,2] in "fun" should yield element [2,2] in a new matrix equal to 24/4=6.  Of course, element [1,1] in the new matrix should be the product of only two numbers.


Thanks

J. Mills

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From kevin.thorpe at utoronto.ca  Sat Feb 18 02:44:37 2006
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 17 Feb 2006 20:44:37 -0500
Subject: [R] OT Futility Analysis
Message-ID: <43F67C05.5040909@utoronto.ca>

I beg your pardon if this is too off topic.  I am posting here
since I hope to find an R solution to my problem.  Please indulge
me while I give a little background about what I'm trying to do.

I'm on a DSMB for a clinical trial.  The Steering Committee for the
trial has asked us to perform a futility analysis on their primary
outcome which is a time-to-event endpoint.  The trial was not designed
with group sequential methods, nor was any futility analysis spelled
out in the protocol.  Another thing which may be relevant is that
due to circumstances beyond the investigators' control, the trial
will stop recruitment prematurely unless there is some compelling
reason for them to find a way to continue the trial.  Lastly, the
trial has accrued not quite half of the planned sample size.

Admittedly, I don't have a vast amount of experience implementing
stopping rules.  In other protocols I have seen where futility
analyses have been planned but a group sequential design has not
otherwise been employed, conditional power has been used for the
futility rule.  So naturally, that was my first thought (although
I may well be wrong) in this case.  I have done RSiteSearch() with
the following terms (three different searches):

	futility analysis
	conditional power
	stochastic curtailment

Nothing that looked relevant to my problem jumped out at me.

I have read, somewhat recently, that there are problems with conditional
power, although I don't remember the details at the moment.  This
has prompted me to consider other approaches to the problem.

One simple thing that has occurred to me, although I don't know
what the implications are is to simply look at a confidence
interval around the hazard ratio for the treatment effect.  In
the event that the CI includes 1 and excludes any clinically
important difference, I would take that as an indication of
futility.

I would appreciate your comments on this and to learn of any more
formal methods, particularly of implementations in R.

Thank you for reading.

Kevin

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.946.8081  Fax: 416.946.3297



From ggrothendieck at gmail.com  Sat Feb 18 03:09:15 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 17 Feb 2006 21:09:15 -0500
Subject: [R] Matrix indexing in a loop
In-Reply-To: <DAA63BFCC1431A47B75B73476BD237FC361D6A@afhe-ex.afhe.ualberta.ca>
References: <DAA63BFCC1431A47B75B73476BD237FC361D6A@afhe-ex.afhe.ualberta.ca>
Message-ID: <971536df0602171809s30593cb3m8d3a50de484a1651@mail.gmail.com>

For 2d here is a solution based on zoo.  It turns the matrix into
a time series and lags it forwards and backwards and does the
same for its transpose in order to avoid index machinations.
The function is called rook2 and it first defines three local
functions, one that converts NAs to zero, one that does
a lag using na.pad = TRUE and one to invoke Lag and
add up the lags:

library(zoo)
rook2 <- function(x, i = 1) {
   na2zero <- function(x) ifelse(is.na(x), 0, x)
   Lag <- function(x, i) na2zero(lag(zoo(x), i, na.pad = TRUE))
   Rook <- function(x, i) Lag(x, i) + Lag(x, -i) + t(Lag(t(x), i) +
Lag(t(x), -i))
   Rook(x, i) / Rook(1+0*x, i)
}

# test
m <- matrix(1:24, 6)
rook2(m)


On 2/17/06, Mills, Jason <Jason.Mills at afhe.ualberta.ca> wrote:
>
> How do you specify matrix location a[i,j] (or a[i-1,j], etc.) in a "for"
> loop?
>
> I am looking for a flexible method of indexing neighbors over a series
> of lags (1,2,3...) and I may wish to extend this method to 3D arrays.
>
>
> Example:
>
> Data matrix
> > fun
>     [,1] [,2] [,3]
> [1,]    1    5    9
> [2,]    2    6   10
> [3,]    3    7   11
> [4,]    4    8   12
>
>
> For each element a[i,j] in "fun", sum the 1st order (Rook's) neighbors:
>
> a[i-1,j]
>
> a[i+1,j]
>
> a[i,j-1]
>
> a[i,j+1]
>
> Then divide by the number of elements included as neighbors-- this
> number depends on the location of a[i,j] in the matrix.
>
>
> Insert the product of the neighbor calculation for each a[i,j] into the
> corresponding position b[i,j] in an empty matrix with the same
> dimensions as "fun".
>
>
> For example, element [2,2] in "fun" should yield element [2,2] in a new
> matrix equal to 24/4=6.  Of course, element [1,1] in the new matrix
> should be the product of only two numbers.
>
>
> Thanks
>
> J. Mills
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Sat Feb 18 04:07:00 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 17 Feb 2006 19:07:00 -0800
Subject: [R] Multiple comparison for circular data
In-Reply-To: <15f8e67d0602150059q44f74b79m91a9e4f83959ddfa@mail.gmail.com>
References: <15f8e67d0602150059q44f74b79m91a9e4f83959ddfa@mail.gmail.com>
Message-ID: <43F68F54.2010009@pdf.com>

	  I just got 141 hits from 'RSiteSearch("circular data")'.  From this, 
I quickly learned of two contributed packages for circular data: 
"circular" and "CircStats".  Both seem to be current, and both are 
maintained by the same person.

	  If you can compute a likelihood for a particular model, then you can 
test for equality of parameters between two data sets as follows:

	  logLik1 = log(likelihood for data set 1 fit by itself.
	  logLik2 = log(likelihood for data set 2 fit by itself.
	  logLik12= log(likelihood for data sets 1 and 2 fit as one.

	  log(likelihood ratio) = (logLik1+logLik2-logLik12).

	  If k parameters are fit for each model, then 2*log(likelihood ratio) 
should be approximately chi-square(k).  From this you can get a p-value 
to compare any pair of data sets.  Then use Bonferroni, multiplying each 
p-value by, say, (k-1).  Any p-value(s) below your Bonferroni-adjusted 
threshold could be claimed to be significantly different.

	  If this is not adequate, I suggest you download both packages (if you 
have not already), try them, and then send a question to the maintainer. 
  If you would like more help from the listserve, I suggest you PLEASE 
do read the posting guide! "www.R-project.org/posting-guide.html". 
Also, please install the "fortunes" package and read especially 
fortune('posting').

	  hope this helps.
	  spencer graves

ecoinfo wrote:

> Hi All,
> 
> Does anyone know how to compare the means of several circular-data
> samplings? Any related websites, references and softwares?
> 
> Thanks
> Xiaohua
> 
> --
> Xiaohua Dai, Dr.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at gmail.com  Sat Feb 18 05:02:46 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 17 Feb 2006 23:02:46 -0500
Subject: [R] Matrix indexing in a loop
In-Reply-To: <971536df0602171809s30593cb3m8d3a50de484a1651@mail.gmail.com>
References: <DAA63BFCC1431A47B75B73476BD237FC361D6A@afhe-ex.afhe.ualberta.ca>
	<971536df0602171809s30593cb3m8d3a50de484a1651@mail.gmail.com>
Message-ID: <971536df0602172002j6ec09435s11c9c70b1f052255@mail.gmail.com>

Thought about this some more and here is a solution that
works with 2d and 3d (and higher dimensions).

inner is a generalized inner product similar to a function
I have posted previously and f(x,y) is an inner product such
that f(x,y) is TRUE if abs(x - y) == order (after converting
both x and y to numeric) and FALSE otherwise.  Root then
uses as.data.frame.table to turn the array into data frames
with the last column having
the data and the other columns representing the indexes.
We then perform the inner product and use the resulting
matrix to multiply c(x) which is the input strung out
into a vector reshaping it back into the same shape as x.
Finally we divide each cell by the number of surrounding
cells.

root3 <- function(x, order = 1) {
	f <- function(x,y) sum(abs(as.numeric(x) - as.numeric(y))) == order
	inner <- function(a,b,f)
			apply(b,1,function(x)apply(a,1,function(y)f(x,y)))

	Root <- function(x) {
		n <- length(dim(x))
		dd <- sapply(as.data.frame.table(x)[,-n-1], as.numeric)
		structure(inner(dd, dd, f) %*% c(x), .Dim = dim(x))
	}
	Root(x) / Root(1+0*x)
}

# tests
m <- matrix(1:24, 6) # 2d
root3(m)
mm <- array(1:24, 2:4)  # 3d
root3(mm)


On 2/17/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> For 2d here is a solution based on zoo.  It turns the matrix into
> a time series and lags it forwards and backwards and does the
> same for its transpose in order to avoid index machinations.
> The function is called rook2 and it first defines three local
> functions, one that converts NAs to zero, one that does
> a lag using na.pad = TRUE and one to invoke Lag and
> add up the lags:
>
> library(zoo)
> rook2 <- function(x, i = 1) {
>   na2zero <- function(x) ifelse(is.na(x), 0, x)
>   Lag <- function(x, i) na2zero(lag(zoo(x), i, na.pad = TRUE))
>   Rook <- function(x, i) Lag(x, i) + Lag(x, -i) + t(Lag(t(x), i) +
> Lag(t(x), -i))
>   Rook(x, i) / Rook(1+0*x, i)
> }
>
> # test
> m <- matrix(1:24, 6)
> rook2(m)
>
>
> On 2/17/06, Mills, Jason <Jason.Mills at afhe.ualberta.ca> wrote:
> >
> > How do you specify matrix location a[i,j] (or a[i-1,j], etc.) in a "for"
> > loop?
> >
> > I am looking for a flexible method of indexing neighbors over a series
> > of lags (1,2,3...) and I may wish to extend this method to 3D arrays.
> >
> >
> > Example:
> >
> > Data matrix
> > > fun
> >     [,1] [,2] [,3]
> > [1,]    1    5    9
> > [2,]    2    6   10
> > [3,]    3    7   11
> > [4,]    4    8   12
> >
> >
> > For each element a[i,j] in "fun", sum the 1st order (Rook's) neighbors:
> >
> > a[i-1,j]
> >
> > a[i+1,j]
> >
> > a[i,j-1]
> >
> > a[i,j+1]
> >
> > Then divide by the number of elements included as neighbors-- this
> > number depends on the location of a[i,j] in the matrix.
> >
> >
> > Insert the product of the neighbor calculation for each a[i,j] into the
> > corresponding position b[i,j] in an empty matrix with the same
> > dimensions as "fun".
> >
> >
> > For example, element [2,2] in "fun" should yield element [2,2] in a new
> > matrix equal to 24/4=6.  Of course, element [1,1] in the new matrix
> > should be the product of only two numbers.
> >
> >
> > Thanks
> >
> > J. Mills
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>



From murdoch at stats.uwo.ca  Sat Feb 18 05:05:50 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 17 Feb 2006 23:05:50 -0500
Subject: [R] Variance for Vector of Constants is STILL Not Zero
In-Reply-To: <000001c633ee$7be4e7f0$0a00a8c0@Dell2003desktop>
References: <000001c633ee$7be4e7f0$0a00a8c0@Dell2003desktop>
Message-ID: <43F69D1E.6070107@stats.uwo.ca>

On 2/17/2006 1:17 PM, Barry Zajdlik wrote:
> Hello all,
> 
> Thanks for the responses but I am still annoyed by this seemingly simple
> problem; I recorded sessionInfo() as below.
> 
> x<-rep(0.02,10)
>> var(x)
> [1] 1.337451e-35
>>  sessionInfo()
> R version 2.1.0, 2005-04-18, i386-pc-mingw32 
> 
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"
> "datasets" 
> [7] "base"     
> 
> 
> I then decided to download the latest version today but obtained the
> same result.
> 
>> x<-rep(0.02,10)
>> var(x)
> [1] 1.337451e-35

My guess is that you've got a video driver or some other software that's 
messing with your floating point processor, reducing the precision from 
64 bit to 53 or less.  I can reproduce the error after running 
RSiteSearch, which messes with my fpu in that way:

 > var(rep(0.2, 100))
[1] 0
 > RSiteSearch('fpu')
A search query has been submitted to http://search.r-project.org
The results page should open in your browser shortly
 > var(rep(0.2, 100))
[1] 1.525181e-31

(I'm not blaming RSiteSearch for doing something bad, it's the system 
DLLs that it calls that are at fault.)

I think this is something we should address, but it's not easy.

Duncan Murdoch

> 
>> sessionInfo()
> R version 2.2.1, 2005-12-20, i386-pc-mingw32 
> 
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"
> "datasets" 
> [7] "base"    
> 
> 
> I Changed .Machine$double.eps to make the calculations LESS accurate.
> My thought was that if I reduced the precision, 1-eps would return 1
> instead of some number less than 1.  My thought was that if eps were
> sufficiently large my sample problem would return a zero.  This didn't
> happen though.
> 
> Again, any thoughts would be appreciated.
> 
> Regards,
> Barry Zajdlik
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sell_mirage_ne at hotmail.com  Sat Feb 18 06:20:44 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Fri, 17 Feb 2006 23:20:44 -0600
Subject: [R] figure out whether 1 is between two numbers
Message-ID: <BAY110-F25DDF9F317CD63C7F190C2C7F90@phx.gbl>

Hi R users

I have two variables (X and Y)

X <-  rnorm(100,.7,.5)
Y <-  rnorm (100,.3,.1)

I like to know whether 1 is between each pair of X and Y or not.

Thanks

TM



From jholtman at gmail.com  Sat Feb 18 06:48:05 2006
From: jholtman at gmail.com (jim holtman)
Date: Sat, 18 Feb 2006 00:48:05 -0500
Subject: [R] figure out whether 1 is between two numbers
In-Reply-To: <BAY110-F25DDF9F317CD63C7F190C2C7F90@phx.gbl>
References: <BAY110-F25DDF9F317CD63C7F190C2C7F90@phx.gbl>
Message-ID: <644e1f320602172148u6bdfacb3ib4f016ce9698c7ec@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060218/e59499f5/attachment.pl

From rbaer at atsu.edu  Sat Feb 18 07:13:39 2006
From: rbaer at atsu.edu (Robert W. Baer, Ph.D.)
Date: Sat, 18 Feb 2006 00:13:39 -0600
Subject: [R] figure out whether 1 is between two numbers
References: <BAY110-F25DDF9F317CD63C7F190C2C7F90@phx.gbl>
Message-ID: <003a01c63452$76612b40$6601a8c0@ALKAID>

Try:
(X>1 & Y<1) | (X<1 & Y>1)

Rob
----- Original Message ----- 
From: "Taka Matzmoto" <sell_mirage_ne at hotmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, February 17, 2006 11:20 PM
Subject: [R] figure out whether 1 is between two numbers


> Hi R users
>
> I have two variables (X and Y)
>
> X <-  rnorm(100,.7,.5)
> Y <-  rnorm (100,.3,.1)
>
> I like to know whether 1 is between each pair of X and Y or not.
>
> Thanks
>
> TM
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From sell_mirage_ne at hotmail.com  Sat Feb 18 08:08:10 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Sat, 18 Feb 2006 01:08:10 -0600
Subject: [R] looking for a graph command
Message-ID: <BAY110-F283D47DBE0FBA93110EB0EC7F90@phx.gbl>

Hi R users

I am looking for a command or function that draws a graph based on a 
correlation matrix or any lower or upper diagonal matrix.

If I have 5 variables (X1, X2, X3, X4, and X5) there are 10 unique 
correlation values

I like to draw some kind of a gird graph based on these values, using (1,2) 
(1,3), (1,4), (1,5), ...., (4,5) as positions on the graph. If a correlation 
value  is closer to 1 then the color for the value is getting black.  If a 
correlation value  is closer to zero then the color for the value is getting 
white.

Is there any graphic package allowing for doing that ?

TM.

_________________________________________________________________
Dont just search. Find. Check out the new MSN Search!



From ripley at stats.ox.ac.uk  Sat Feb 18 08:17:23 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 18 Feb 2006 07:17:23 +0000 (GMT)
Subject: [R] truncated negative binomial using rnegbin
In-Reply-To: <6.2.1.2.2.20060202152956.01f47570@inbox.email.arizona.edu>
References: <6.2.1.2.2.20060202152956.01f47570@inbox.email.arizona.edu>
Message-ID: <Pine.LNX.4.64.0602180714180.3188@gannet.stats.ox.ac.uk>

This code does not do what you describe: it samples one at a time.
It would be much better to take a larger sample (and you can use the 
theory to work out how much bigger) and just use x[x > 0] on that.  If 
that is not big enough, add some more, and if it is too big, keep the 
first n.

On Fri, 17 Feb 2006, Chris O'Brien wrote:

> Dear R users,
> I'm wanting to sample from the negative binomial distribution using the
> rnegbin function from the MASS library to create artificial samples for the
> purpose of doing some power calculations.  However, I would like to work
> with samples that come from a negative binomial distribution that includes
> only values greater than or equal to 1 (a truncated negative binomial), and
> I can't think of a straightforward way to accomplish this using rnegbin.
>
> One suggestion I've received is that I use an iterative process to select
> numbers from the negative binomial, throw out the zeros, test the
> distribution for the desired parameters, and then repeat until the
> parameters are in an acceptable range.  I could then sample this
> 'population' using the sample function, and go from there.  One major
> problem with this approach is that it is very time consuming on a desktop
> machine.
>
> Here's a piece of code (from a friend, and untested)  that will do such a
> thing:
>
> #
> #  Function to generate a vector containing values from a truncated
> #  negative binomial distribution (i.e., no zeros).  Select desired
> #  mean and variance, sample size, initial values for mean and theta,
> #  and a threshold value for tests.
> #
> #  format:  out<-nbin(desired_mean, desired_variance, n, initial_mean,
> #                     theta, threshold_level)
> #
> #  example:  out<-nbin(2, 1, 100, 2, 2, 0.1)
> #
> #
> nbin<-function(mu.s,var.s,n,mu.i,theta,test)
> {
>   library(MASS)
>
>   mu<-0
>   var<-0
>   rand<-rep(0,n)
>   while(abs(mu.s-mu)>=test & abs(var.s-var)>=test)
>   {
>     for(i in 1:n)
>     {
>      rnb<-0
>      while(rnb==0)
>       rnb<-rnegbin(1,mu.i,theta)
>      rand[i]<-rnb
>     }
>     mu<-mean(rand)
>     var<-var(rand)
>   }
>   return(rand)
> }
>
>
>
> As I am wanting to use these samples to compute power for a bootstrap
> procedure, the time demands will become prohibitive very quickly,
> especially for large sample sizes.
> I'm thinking that there must be a more efficient, elegant, and quicker
> solution to the problem, but am having problems coming up with the answer.
> I'd greatly welcome any insight into a more efficient method.
>
> thanks in advance for any insight,
> Chris O'Brien
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ms at mcdev.com.au  Sat Feb 18 10:31:21 2006
From: ms at mcdev.com.au (Martin Sandiford)
Date: Sat, 18 Feb 2006 20:01:21 +1030
Subject: [R] looking for a graph command
In-Reply-To: <BAY110-F283D47DBE0FBA93110EB0EC7F90@phx.gbl>
References: <BAY110-F283D47DBE0FBA93110EB0EC7F90@phx.gbl>
Message-ID: <4e142e890d10a2e886cf118f0bde3ba2@mcdev.com.au>

Maybe something like this will do what you want:

 > x <- matrix(NA, 5, 5)
 > x[upper.tri(x)] <- runif(10)
 > image(1-t(x)[,ncol(x):1], col=gray.colors(100), axes=FALSE)

Martin

On 18/02/2006, at 5:38 PM, Taka Matzmoto wrote:

> Hi R users
>
> I am looking for a command or function that draws a graph based on a 
> correlation matrix or any lower or upper diagonal matrix.
>
> If I have 5 variables (X1, X2, X3, X4, and X5) there are 10 unique 
> correlation values
>
> I like to draw some kind of a gird graph based on these values, using 
> (1,2) (1,3), (1,4), (1,5), ...., (4,5) as positions on the graph. If a 
> correlation value  is closer to 1 then the color for the value is 
> getting black.  If a correlation value  is closer to zero then the 
> color for the value is getting white.
>
> Is there any graphic package allowing for doing that ?
>
> TM.
>
> _________________________________________________________________
> Don?t just search. Find. Check out the new MSN Search!
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Sat Feb 18 11:19:20 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Feb 2006 11:19:20 +0100
Subject: [R] Something changed and glm(...,
	family=binomial) doesn't work now
In-Reply-To: <1D6DE5F6-1107-4F29-9913-D2407B35B543@cnr.colostate.edu>
References: <1D6DE5F6-1107-4F29-9913-D2407B35B543@cnr.colostate.edu>
Message-ID: <x28xs9rmtz.fsf@turmalin.kubism.ku.dk>

Philip Riggs <priggs at warnercnr.colostate.edu> writes:

> I ran logistic regression models last week using glm 
> (...,family=binomial) and got a set of results. Since then I have  
> loaded the Epi package for ROC analysis. Now when I run those same  
> models I get completely different results, with most being:
> 
> Warning message:
> fitted probabilities numerically 0 or 1 occurred in: glm.fit(x = X, y  
> = Y, weights = weights, start = start, etastart = etastart,
> 
> I didn't get this result last week. Also, the ROC function in Epi is  
> no longer working (giving a ROC of 1.000). What would have changed to  
> cause this and how can I fix it?
> 
> p.s. To check I ran the same model in S and have the same result as  
> last week.

Do you mean "load" or "install" Epi?? If the latter, does it matter
whether you use library(Epi) or not?

However: This sort of trouble usually means that you are not really
fitting the same models to the same data. The warning and the ROC
suggests that you have something in your model that gives perfect
separation between successes and failures. 

Are you using data=myframe in the glm call? Otherwise, you're open to
masking by variables in your workspace.


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From admin at biostatistic.de  Sat Feb 18 11:32:14 2006
From: admin at biostatistic.de (Knut Krueger)
Date: Sat, 18 Feb 2006 11:32:14 +0100
Subject: [R] showing the integrated number by point size
In-Reply-To: <1140195141.4543.12.camel@localhost.localdomain>
References: <43F5FACC.1080804@biostatistic.de>
	<1140195141.4543.12.camel@localhost.localdomain>
Message-ID: <43F6F7AE.8040102@biostatistic.de>



Marc Schwartz (via MN) schrieb:

>On Fri, 2006-02-17 at 17:33 +0100, Knut Krueger wrote:
>  
>
>>Is there any function to show the points like this example of SPSS?
>>
>>http://biostatistic.de/temp/reg.jpg
>>
>>The point size should represent the number of data at this point.
>>
>>with regards
>>Knut Krueger
>>    
>>
>
>There are a couple of functions in CRAN packages I believe that will do
>bubble plots.
>
To know the name of the function is always the problem before i am albe 
to seachr for :-(

>
>You might want to do:
>
>  RSiteSearch("Bubble Plot")
>
found the solution , thx

>
>which should help.
>
>A better option from a visualization perspective would be 
>
>  ?sunflowerplot
>  
>
Maybe, but I was told to search for bubbles. I will suggest the sunflowerplots.


Thank you very much
Knut Krueger



From isaac.martin at uc3m.es  Sat Feb 18 12:19:00 2006
From: isaac.martin at uc3m.es (isaac.martin@uc3m.es)
Date: Sat, 18 Feb 2006 12:19:00 +0100 (CET)
Subject: [R] R-help Digest, Vol 36, Issue 18
Message-ID: <20060218111900.C47E9E9C3@shem.uc3m.es>

Mi nueva direcci??n de correo es: isaac.martin at urjc.es

New e-mail address: isaac.martin at urjc.es



From charles.edwin.white at us.army.mil  Sat Feb 18 14:52:52 2006
From: charles.edwin.white at us.army.mil (White, Charles E WRAIR-Wash DC)
Date: Sat, 18 Feb 2006 08:52:52 -0500
Subject: [R] Something changed and glm(...,
	family=binomial) doesn't work now
Message-ID: <8BAEC5E546879B4FAA536200A292C614010A3916@AMEDMLNARMC135.amed.ds.army.mil>

"Are you using data=myframe in the glm call? Otherwise, you're open to
masking by variables in your workspace."

FYI, the data statement doesn't seem to be the shortcut it is elsewhere when the form of the argument is glm(cbind(success,failure)~predictor, family=binomial, data=myframe). The data statement doesn't seem to put 'myframe' in the environment where cbind operates. Choices for the user are to fully quality names inside of cbind [i.e., cbind(myframe$success,myframe$failure)] or to attach 'myframe' to the working environment. The same thing happens in lmer.

Chuck

Charles E. White, Senior Biostatistician, MS
Walter Reed Army Institute of Research
503 Robert Grant Ave., Room 1w102
Silver Spring, MD 20910-1557
301 319-9781
Personal/Professional Site:??http://users.starpower.net/cwhite571/professional/



From murdoch at stats.uwo.ca  Sat Feb 18 15:00:36 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 18 Feb 2006 09:00:36 -0500
Subject: [R] figure out whether 1 is between two numbers
In-Reply-To: <003a01c63452$76612b40$6601a8c0@ALKAID>
References: <BAY110-F25DDF9F317CD63C7F190C2C7F90@phx.gbl>
	<003a01c63452$76612b40$6601a8c0@ALKAID>
Message-ID: <43F72884.7050807@stats.uwo.ca>

On 2/18/2006 1:13 AM, Robert W. Baer, Ph.D. wrote:
> Try:
> (X>1 & Y<1) | (X<1 & Y>1)

This is a minor stylistic suggestion: when translating the mathematical 
expression (a < b < c), write it as (a < b) & (b < c).  It has no effect 
on the outcome, but keeping the inequalities in the same direction makes 
the meaning more obvious.

If you do this, your expression becomes

(Y<1 & 1<X) | (X<1 & 1<Y)

and it's clear at a glance what's going on.

I think I originally read this suggestion in something written by 
Kernighan and/or Plauger, I can't claim credit for it.

Duncan Murdoch

> 
> Rob
> ----- Original Message ----- 
> From: "Taka Matzmoto" <sell_mirage_ne at hotmail.com>
> To: <r-help at stat.math.ethz.ch>
> Sent: Friday, February 17, 2006 11:20 PM
> Subject: [R] figure out whether 1 is between two numbers
> 
> 
>> Hi R users
>>
>> I have two variables (X and Y)
>>
>> X <-  rnorm(100,.7,.5)
>> Y <-  rnorm (100,.3,.1)
>>
>> I like to know whether 1 is between each pair of X and Y or not.
>>
>> Thanks
>>
>> TM
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at gmail.com  Sat Feb 18 15:08:36 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 18 Feb 2006 09:08:36 -0500
Subject: [R] Matrix indexing in a loop
In-Reply-To: <971536df0602172002j6ec09435s11c9c70b1f052255@mail.gmail.com>
References: <DAA63BFCC1431A47B75B73476BD237FC361D6A@afhe-ex.afhe.ualberta.ca>
	<971536df0602171809s30593cb3m8d3a50de484a1651@mail.gmail.com>
	<971536df0602172002j6ec09435s11c9c70b1f052255@mail.gmail.com>
Message-ID: <971536df0602180608y293e749eya6970bb620d2f00f@mail.gmail.com>

There was an error in the function f -- it only worked correctly if
order was 1.  Here it is with that fixed.  The function f is the
only thing changed from my last post.  It makes use of the
fact that sum(x) == n and sum(x*x) == n*n  only occur when
one element of x is n and the rest are 0.

root3 <- function(x, order = 1) {
	f <- function(x,y) {
		z <- abs(as.numeric(x) - as.numeric(y))
		(sum(z) == order) & (sum(z*z) == order * order)
	}
	inner <- function(a,b,f)
			apply(b,1,function(x)apply(a,1,function(y)f(x,y)))

	Root <- function(x) {
		n <- length(dim(x))
		dd <- sapply(as.data.frame.table(x)[,-n-1], as.numeric)
		structure(inner(dd, dd, f) %*% c(x), .Dim = dim(x))
	}
	Root(x) / Root(1+0*x)
}

# tests
m <- matrix(1:24, 6) # 2d
root3(m)
mm <- array(1:24, 2:4)  # 3d
root3(mm)


On 2/17/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Thought about this some more and here is a solution that
> works with 2d and 3d (and higher dimensions).
>
> inner is a generalized inner product similar to a function
> I have posted previously and f(x,y) is an inner product such
> that f(x,y) is TRUE if abs(x - y) == order (after converting
> both x and y to numeric) and FALSE otherwise.  Root then
> uses as.data.frame.table to turn the array into data frames
> with the last column having
> the data and the other columns representing the indexes.
> We then perform the inner product and use the resulting
> matrix to multiply c(x) which is the input strung out
> into a vector reshaping it back into the same shape as x.
> Finally we divide each cell by the number of surrounding
> cells.
>
> root3 <- function(x, order = 1) {
>        f <- function(x,y) sum(abs(as.numeric(x) - as.numeric(y))) == order
>        inner <- function(a,b,f)
>                        apply(b,1,function(x)apply(a,1,function(y)f(x,y)))
>
>        Root <- function(x) {
>                n <- length(dim(x))
>                dd <- sapply(as.data.frame.table(x)[,-n-1], as.numeric)
>                structure(inner(dd, dd, f) %*% c(x), .Dim = dim(x))
>        }
>        Root(x) / Root(1+0*x)
> }
>
> # tests
> m <- matrix(1:24, 6) # 2d
> root3(m)
> mm <- array(1:24, 2:4)  # 3d
> root3(mm)
>
>
> On 2/17/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> > For 2d here is a solution based on zoo.  It turns the matrix into
> > a time series and lags it forwards and backwards and does the
> > same for its transpose in order to avoid index machinations.
> > The function is called rook2 and it first defines three local
> > functions, one that converts NAs to zero, one that does
> > a lag using na.pad = TRUE and one to invoke Lag and
> > add up the lags:
> >
> > library(zoo)
> > rook2 <- function(x, i = 1) {
> >   na2zero <- function(x) ifelse(is.na(x), 0, x)
> >   Lag <- function(x, i) na2zero(lag(zoo(x), i, na.pad = TRUE))
> >   Rook <- function(x, i) Lag(x, i) + Lag(x, -i) + t(Lag(t(x), i) +
> > Lag(t(x), -i))
> >   Rook(x, i) / Rook(1+0*x, i)
> > }
> >
> > # test
> > m <- matrix(1:24, 6)
> > rook2(m)
> >
> >
> > On 2/17/06, Mills, Jason <Jason.Mills at afhe.ualberta.ca> wrote:
> > >
> > > How do you specify matrix location a[i,j] (or a[i-1,j], etc.) in a "for"
> > > loop?
> > >
> > > I am looking for a flexible method of indexing neighbors over a series
> > > of lags (1,2,3...) and I may wish to extend this method to 3D arrays.
> > >
> > >
> > > Example:
> > >
> > > Data matrix
> > > > fun
> > >     [,1] [,2] [,3]
> > > [1,]    1    5    9
> > > [2,]    2    6   10
> > > [3,]    3    7   11
> > > [4,]    4    8   12
> > >
> > >
> > > For each element a[i,j] in "fun", sum the 1st order (Rook's) neighbors:
> > >
> > > a[i-1,j]
> > >
> > > a[i+1,j]
> > >
> > > a[i,j-1]
> > >
> > > a[i,j+1]
> > >
> > > Then divide by the number of elements included as neighbors-- this
> > > number depends on the location of a[i,j] in the matrix.
> > >
> > >
> > > Insert the product of the neighbor calculation for each a[i,j] into the
> > > corresponding position b[i,j] in an empty matrix with the same
> > > dimensions as "fun".
> > >
> > >
> > > For example, element [2,2] in "fun" should yield element [2,2] in a new
> > > matrix equal to 24/4=6.  Of course, element [1,1] in the new matrix
> > > should be the product of only two numbers.
> > >
> > >
> > > Thanks
> > >
> > > J. Mills
> > >
> > >        [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > >
> >
>



From murdoch at stats.uwo.ca  Sat Feb 18 15:09:03 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 18 Feb 2006 09:09:03 -0500
Subject: [R] looking for a graph command
In-Reply-To: <BAY110-F283D47DBE0FBA93110EB0EC7F90@phx.gbl>
References: <BAY110-F283D47DBE0FBA93110EB0EC7F90@phx.gbl>
Message-ID: <43F72A7F.2040108@stats.uwo.ca>

On 2/18/2006 2:08 AM, Taka Matzmoto wrote:
> Hi R users
> 
> I am looking for a command or function that draws a graph based on a 
> correlation matrix or any lower or upper diagonal matrix.
> 
> If I have 5 variables (X1, X2, X3, X4, and X5) there are 10 unique 
> correlation values
> 
> I like to draw some kind of a gird graph based on these values, using (1,2) 
> (1,3), (1,4), (1,5), ...., (4,5) as positions on the graph. If a correlation 
> value  is closer to 1 then the color for the value is getting black.  If a 
> correlation value  is closer to zero then the color for the value is getting 
> white.
> 
> Is there any graphic package allowing for doing that ?

library(ellipse)
plotcorr(cor(cbind(X1,X2,X3,X4,X5)))

You can set the colours of the individual entries using the col argument.

Duncan Murdoch



From murdoch at stats.uwo.ca  Sat Feb 18 15:14:09 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 18 Feb 2006 09:14:09 -0500
Subject: [R] RCMD SHILB uses g++ instead of gcc
In-Reply-To: <BAY110-F38DC661ADC68C9E1FD8024A3F80@phx.gbl>
References: <BAY110-F38DC661ADC68C9E1FD8024A3F80@phx.gbl>
Message-ID: <43F72BB1.7060808@stats.uwo.ca>

On 2/17/2006 6:02 AM, Vumani Dlamini wrote:
> I am using RCMD SHLIB to make a dll from the convolve2.c code presented with 
> R-exts. After an e-mail from Prof Ripley, I noticed that SHLIB is using a 
> C++ compiler instead of a C compiler for the code.

I think you're not using convolve2.c, you're using something with a .C 
extension.  To the makefiles, .c implies C, .C implies C++.

Duncan Murdoch

> 
> Have searched the R-site and the internet for answers and noticed that it is 
> possible to change the "makeconf" and "makefile" files to correct this. But 
> these files are not present in my system. I downloaded 
> "R-2.2.1pat-win32.exe" and installed the traditional windows way.
> 
> Thanks for your responses.
> 
> Full_Name: Vumani Dlamini
> Version: 2.2.1 Patched
> OS: Microsoft Windows XP Professional
> 
> 
> 
> 
> 
>> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>> To: Vumani Dlamini <dvumani at hotmail.com>
>> CC: r-help at stat.math.ethz.ch
>> Subject: Re: [R] symbol decoration and .Call
>> Date: Thu, 16 Feb 2006 13:12:25 +0000 (GMT)
>>
>> 1) Please read the posting guide and use the appropriate list, not R-help.
>>
>> 2) Please tell us exactly what you did, including your OS, R version and so 
>> on as the guide asks.  Looks to me like you used a C++ compiler to compile 
>> C.
>>
>> On Thu, 16 Feb 2006, Vumani Dlamini wrote:
>>
>>> Dear R-users,
>>> I am a novice user of .Call and am trying to use the C code in R-Ext to
>>> kickstart my learning process. All the code compiles but when I try to use
>>> .Call it gives the error (using "out.c" as an example),
>>>
>>> Error in .Call("out", x, y) : C entry point "out" not in load table
>>>
>>> when i use PEDUMP to check whether the symbol is loaded I find that it is
>>> loaded as "_Z3outP7SEXPRECS0_" and when I use this instead of "out" the
>>> program work.
>>>
>>> How can I remove the decoration so that only "out" is loaded?
>>>
>>> Thanks, Vumani
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Ted.Harding at nessie.mcc.ac.uk  Sat Feb 18 15:39:52 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sat, 18 Feb 2006 14:39:52 -0000 (GMT)
Subject: [R] figure out whether 1 is between two numbers
In-Reply-To: <43F72884.7050807@stats.uwo.ca>
Message-ID: <XFMail.060218143952.Ted.Harding@nessie.mcc.ac.uk>

On 18-Feb-06 Duncan Murdoch wrote:
> On 2/18/2006 1:13 AM, Robert W. Baer, Ph.D. wrote:
>> Try:
>> (X>1 & Y<1) | (X<1 & Y>1)
> 
> This is a minor stylistic suggestion: when translating the mathematical
> expression (a < b < c), write it as (a < b) & (b < c).  It has no
> effect 
> on the outcome, but keeping the inequalities in the same direction
> makes 
> the meaning more obvious.
> 
> If you do this, your expression becomes
> 
> (Y<1 & 1<X) | (X<1 & 1<Y)
> 
> and it's clear at a glance what's going on.
> 
> I think I originally read this suggestion in something written by 
> Kernighan and/or Plauger, I can't claim credit for it.
> 
> Duncan Murdoch

Mention of "Kernighan and/or Plauger" got me digging out K & P
"The Elements of Programming Style" (from 1974/78). The suggestion
is indeed in there, on pp 20-21, leading up to the rule "Use
the 'telephone test' for readability" ("If someone could
understand your code when read aloud over the telephone, it's
clear enough. If not, then it needs rewriting.")

The example is:

  Consider the sequence

    6 IF(X1.GE.ARRAY(I)) GO TO 2
      IF(ARRAY(I).LT.X2) ICOUNT=ICOUNT+1
    2 ...

  It takes a while to realize that IVOUNT is incremented only
  if ARRAY(I) lies between X1 and X2. .... Rewriting gives:

    6 IF(ARRAY(I).GT.X1 .AND. ARRAY(I).LT.X2) ICOUNT = ICOUNT + 1

(Though I think it could be improved still further by the slight
change to "X1.LT.ARRAY(I)" to bring it into line with Duncan's
example).

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 18-Feb-06                                       Time: 14:39:50
------------------------------ XFMail ------------------------------



From chelellis82 at hotmail.com  Sat Feb 18 16:08:06 2006
From: chelellis82 at hotmail.com (Chelsea Ellis)
Date: Sat, 18 Feb 2006 15:08:06 +0000
Subject: [R] Running AffylmGUI
Message-ID: <BAY15-F3393676C55582383B2DB6B8F90@phx.gbl>

I'm trying to run AffylmGUI in Bioconductor (for Windows), and I can't get 
my computer to recognize the tcl/tk files I downloaded from ActiveTCL.  I 
followed the directions for downloading and installing explicitly, but when 
I try to run AffylmGUI, R tells me that it can't find the files.  I've tried 
uninstalling and reinstalling both R and the ActiveTCL files, and that was 
no help.  Anyone have any troubleshooting  advice?

Thanks in advance,
Chelsea



From ccleland at optonline.net  Sat Feb 18 16:25:20 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Sat, 18 Feb 2006 10:25:20 -0500
Subject: [R] Conversion to Adjacency Matrix
Message-ID: <43F73C60.4090502@optonline.net>

   I have data in the following form:

ID COUPON0 COUPON1 COUPON2 COUPON3
  1       1    1000    1001    1002
  2       2      NA      NA      NA
  3    1000    1003      NA    1004
  4    1001      NA    1005      NA
  5    1002      NA      NA      NA
12    1003      NA      NA    1006
  7    1005      NA      NA      NA
  8    1004    1007      NA      NA
  9    1006      NA      NA      NA
26    1007      NA      NA      NA

   I would like to convert this into an adjacency matrix like the following:

     1  2  3  4  5 12  7  8  9 26
  1  0  0  1  1  1  0  0  0  0  0
  2  0  0  0  0  0  0  0  0  0  0
  3  0  0  0  0  0  1  0  1  0  0
  4  0  0  0  0  0  0  1  0  0  0
  5  0  0  0  0  0  0  0  0  0  0
12  0  0  0  0  0  0  0  0  1  0
  7  0  0  0  0  0  0  0  0  0  0
  8  0  0  0  0  0  0  0  0  0  1
  9  0  0  0  0  0  0  0  0  0  0
26  0  0  0  0  0  0  0  0  0  0

   The actual data contains about 570 rows and 7 "coupon" columns. 
COUPON0 is a unique coupon number submitted by each participant. 
COUPON1-COUPON7 are unique coupon numbers distributed to other 
participants.  About 15 participants were "seeds" who distributed coupon 
numbers but did not receive a coupon from another participant.  Many 
participants (including some seeds) did not distribute any coupons.
   Any ideas about how to make this conversion would be greatly appreciated.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ggrothendieck at gmail.com  Sat Feb 18 16:44:11 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 18 Feb 2006 10:44:11 -0500
Subject: [R] Conversion to Adjacency Matrix
In-Reply-To: <43F73C60.4090502@optonline.net>
References: <43F73C60.4090502@optonline.net>
Message-ID: <971536df0602180744l21bdd048te9319659ec0a4ad3@mail.gmail.com>

The generalized inner product function which I posted in response to
another query earlier today:

  https://www.stat.math.ethz.ch/pipermail/r-help/2006-February/087120.html

can also solve this problem:

   f <- function(x, y) length(na.omit(unlist(intersect(x,y)))) > 0
   inner(dd[,-1], dd[,-1], f) - diag(nrow(dd)) # inner from cited post


On 2/18/06, Chuck Cleland <ccleland at optonline.net> wrote:
>   I have data in the following form:
>
> ID COUPON0 COUPON1 COUPON2 COUPON3
>  1       1    1000    1001    1002
>  2       2      NA      NA      NA
>  3    1000    1003      NA    1004
>  4    1001      NA    1005      NA
>  5    1002      NA      NA      NA
> 12    1003      NA      NA    1006
>  7    1005      NA      NA      NA
>  8    1004    1007      NA      NA
>  9    1006      NA      NA      NA
> 26    1007      NA      NA      NA
>
>   I would like to convert this into an adjacency matrix like the following:
>
>     1  2  3  4  5 12  7  8  9 26
>  1  0  0  1  1  1  0  0  0  0  0
>  2  0  0  0  0  0  0  0  0  0  0
>  3  0  0  0  0  0  1  0  1  0  0
>  4  0  0  0  0  0  0  1  0  0  0
>  5  0  0  0  0  0  0  0  0  0  0
> 12  0  0  0  0  0  0  0  0  1  0
>  7  0  0  0  0  0  0  0  0  0  0
>  8  0  0  0  0  0  0  0  0  0  1
>  9  0  0  0  0  0  0  0  0  0  0
> 26  0  0  0  0  0  0  0  0  0  0
>
>   The actual data contains about 570 rows and 7 "coupon" columns.
> COUPON0 is a unique coupon number submitted by each participant.
> COUPON1-COUPON7 are unique coupon numbers distributed to other
> participants.  About 15 participants were "seeds" who distributed coupon
> numbers but did not receive a coupon from another participant.  Many
> participants (including some seeds) did not distribute any coupons.
>   Any ideas about how to make this conversion would be greatly appreciated.
>
> --
> Chuck Cleland, Ph.D.
> NDRI, Inc.
> 71 West 23rd Street, 8th floor
> New York, NY 10010
> tel: (212) 845-4495 (Tu, Th)
> tel: (732) 452-1424 (M, W, F)
> fax: (917) 438-0894
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From islandboy1982 at yahoo.com  Sat Feb 18 16:52:48 2006
From: islandboy1982 at yahoo.com (oliver wee)
Date: Sat, 18 Feb 2006 07:52:48 -0800 (PST)
Subject: [R] question about GARCH - newbie question
Message-ID: <20060218155248.2054.qmail@web33202.mail.mud.yahoo.com>

hello, 
I have been looking at multiple websites on GARCH and
have looked at some books and I am getting
contradictory models given for GARCH.

If I use the GARCH function to fit my model, I am
confused as to what the coefficents given refer to.

For example if I fit a GARCH(1,1) model, GARCH will
give me three coefficients Ao, Ai, and Bi

I know Ao refers to the constant of the model.
But what about Ai and Bi?

One website I looked at says the model for GARCH is:
1) S^2t = Ao + Ai S^2 t-1 + Bi E^2 t-1 + Et
(sigma squared sub t = a sub 0 + a sub 1 sigma squared
sub t-1 + b sub 1 epsilon squared sub t-1 + epsilon
sub t)
while a book I was reading says the general model is
2) S^2t = Ao + Ai Y^2 t-1 + Bi S^2 t-1
(sigma squared sub t = a sub 0 + a sub 1 Y squared sub
t-1 + b sub 1 sigma squared sub t-1).

where Y refers to the data points of th time series
S refers to the variance and E refers to the white
noise component.

I am very confused by this.

Also, two other questions regarding GARCH,
1) How exactly do I forecast future values of my
fitted GARCH model using R and how do I graph them? 
predict() won't work since it won't accept the n.ahead
argument. (Assuming I already have fitted my original
data set to an ARIMA model and have predicted future
values using the predict() command).  

2) This is not about R, but about GARCH in general. I
just want to check if I understood GARCH correctly. 
For example, I have already found an ARIMA model to
fit my original data set. In order for me to find the
appropriate GARCH model to fit my data set, I have to
get the acf of the squared values of my original data
set (assuming the data set is stationary, that is, its
acf show no significant correlations at all lags, but
the acf of its squared values is not stationary). Once
I get the acf of the squared values, I just compare
this to the acf of arma(p,q) models- similar to how I
was able to find my fitted ARIMA model? Is this
correct? Also, once I have found the appropriate GARCH
model, I can use this model to predict BOTH the future
values of the data set and its variance? and these 
future values will be far different than the one given
my my fitted ARIMA model?

I am sorry for the abundance of questions and I am
pretty sure some of these questions sound pretty dumb.
Its that I'm doing my study of time series mostly
through self-study and I got really confused about
GARCH.

Thank you very much for your help.



From h.wickham at gmail.com  Sat Feb 18 17:02:47 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Sat, 18 Feb 2006 10:02:47 -0600
Subject: [R] Conversion to Adjacency Matrix
In-Reply-To: <43F73C60.4090502@optonline.net>
References: <43F73C60.4090502@optonline.net>
Message-ID: <f8e6ff050602180802j17bd8b17ndc85662e60d284d0@mail.gmail.com>

>    I have data in the following form:
>
> ID COUPON0 COUPON1 COUPON2 COUPON3
>   1       1    1000    1001    1002
>   2       2      NA      NA      NA
>   3    1000    1003      NA    1004
>   4    1001      NA    1005      NA
>   5    1002      NA      NA      NA
> 12    1003      NA      NA    1006
>   7    1005      NA      NA      NA
>   8    1004    1007      NA      NA
>   9    1006      NA      NA      NA
> 26    1007      NA      NA      NA
>
>    I would like to convert this into an adjacency matrix like the following:

Here's one solution:

a <- data.frame(
 ID = c(1, 2, 3, 4, 5, 12, 7, 8, 9, 26),
 COUPON0 = c(1, 2, 1000, 1001, 1002, 1003, 1005, 1004, 1006, 1007),
 COUPON1 = c(1000, NA, 1003, NA, NA, NA, NA, 1007, NA, NA),
 COUPON2 = c(1001, NA, NA, 1005, NA, NA, NA, NA, NA, NA),
 COUPON3 = c(1002, NA, 1004, NA, NA, 1006, NA, NA, NA, NA)
)
names(a) <- tolower(names(a))

# Make a look up table from coupon to id
coupontoid <- a$id
names(coupontoid) <- a$coupon0

# Convert a to a more normal (in the sense of
# database normalisation) form
# (many other ways to do this)
library(reshape)
am <- melt(a, id=c("id", "coupon0"))
# Remap coupon number to id
map <- data.frame(src=am$id, dest=coupontoid[as.character(am$value)])
# Convert to adjacency matrix
xtabs(~ src + dest, map)

# Force all levels to display
map$src <- factor(map$src, levels=unique(a$id))
map$dest <- factor(map$dest, levels=unique(a$id))
xtabs(~ src + dest, map)

Regards,

Hadley



From liuwensui at gmail.com  Sat Feb 18 17:06:36 2006
From: liuwensui at gmail.com (Wensui Liu)
Date: Sat, 18 Feb 2006 11:06:36 -0500
Subject: [R] Question about variable selection
Message-ID: <1115a2b00602180806k16ab18ffi8a7217a778d64f2d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060218/c2121f7a/attachment.pl

From spencer.graves at pdf.com  Sat Feb 18 17:12:16 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 18 Feb 2006 08:12:16 -0800
Subject: [R] Variance for Vector of Constants is STILL Not Zero
In-Reply-To: <43F69D1E.6070107@stats.uwo.ca>
References: <000001c633ee$7be4e7f0$0a00a8c0@Dell2003desktop>
	<43F69D1E.6070107@stats.uwo.ca>
Message-ID: <43F74760.6090101@pdf.com>

	  I got the same thing as Duncan:

 > var(rep(0.2, 100))
[1] 0
 > RSiteSearch('fpu')
A search query has been submitted to http://search.r-project.org
The results page should open in your browser shortly
 > var(rep(0.2, 100))
[1] 1.525181e-31
 > sessionInfo()
R version 2.2.1, 2005-12-20, i386-pc-mingw32

attached base packages:
[1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
[7] "base"

	  spencer graves

Duncan Murdoch wrote:

> On 2/17/2006 1:17 PM, Barry Zajdlik wrote:
> 
>>Hello all,
>>
>>Thanks for the responses but I am still annoyed by this seemingly simple
>>problem; I recorded sessionInfo() as below.
>>
>>x<-rep(0.02,10)
>>
>>>var(x)
>>
>>[1] 1.337451e-35
>>
>>> sessionInfo()
>>
>>R version 2.1.0, 2005-04-18, i386-pc-mingw32 
>>
>>attached base packages:
>>[1] "methods"   "stats"     "graphics"  "grDevices" "utils"
>>"datasets" 
>>[7] "base"     
>>
>>
>>I then decided to download the latest version today but obtained the
>>same result.
>>
>>
>>>x<-rep(0.02,10)
>>>var(x)
>>
>>[1] 1.337451e-35
> 
> 
> My guess is that you've got a video driver or some other software that's 
> messing with your floating point processor, reducing the precision from 
> 64 bit to 53 or less.  I can reproduce the error after running 
> RSiteSearch, which messes with my fpu in that way:
> 
>  > var(rep(0.2, 100))
> [1] 0
>  > RSiteSearch('fpu')
> A search query has been submitted to http://search.r-project.org
> The results page should open in your browser shortly
>  > var(rep(0.2, 100))
> [1] 1.525181e-31
> 
> (I'm not blaming RSiteSearch for doing something bad, it's the system 
> DLLs that it calls that are at fault.)
> 
> I think this is something we should address, but it's not easy.
> 
> Duncan Murdoch
> 
> 
>>>sessionInfo()
>>
>>R version 2.2.1, 2005-12-20, i386-pc-mingw32 
>>
>>attached base packages:
>>[1] "methods"   "stats"     "graphics"  "grDevices" "utils"
>>"datasets" 
>>[7] "base"    
>>
>>
>>I Changed .Machine$double.eps to make the calculations LESS accurate.
>>My thought was that if I reduced the precision, 1-eps would return 1
>>instead of some number less than 1.  My thought was that if eps were
>>sufficiently large my sample problem would return a zero.  This didn't
>>happen though.
>>
>>Again, any thoughts would be appreciated.
>>
>>Regards,
>>Barry Zajdlik
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Sat Feb 18 17:54:33 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 18 Feb 2006 16:54:33 +0000 (GMT)
Subject: [R] Variance for Vector of Constants is STILL Not Zero
In-Reply-To: <43F74760.6090101@pdf.com>
References: <000001c633ee$7be4e7f0$0a00a8c0@Dell2003desktop>
	<43F69D1E.6070107@stats.uwo.ca> <43F74760.6090101@pdf.com>
Message-ID: <Pine.LNX.4.64.0602181647170.5032@gannet.stats.ox.ac.uk>

Note though that this is already giving 0 in both cases in R-devel on 
Windows (the only platform on which this difference occurs).


On Sat, 18 Feb 2006, Spencer Graves wrote:

> 	  I got the same thing as Duncan:
>
> > var(rep(0.2, 100))
> [1] 0
> > RSiteSearch('fpu')
> A search query has been submitted to http://search.r-project.org
> The results page should open in your browser shortly
> > var(rep(0.2, 100))
> [1] 1.525181e-31
> > sessionInfo()
> R version 2.2.1, 2005-12-20, i386-pc-mingw32
>
> attached base packages:
> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"     "datasets"
> [7] "base"
>
> 	  spencer graves
>
> Duncan Murdoch wrote:
>
>> On 2/17/2006 1:17 PM, Barry Zajdlik wrote:
>>
>>> Hello all,
>>>
>>> Thanks for the responses but I am still annoyed by this seemingly simple
>>> problem; I recorded sessionInfo() as below.
>>>
>>> x<-rep(0.02,10)
>>>
>>>> var(x)
>>>
>>> [1] 1.337451e-35
>>>
>>>> sessionInfo()
>>>
>>> R version 2.1.0, 2005-04-18, i386-pc-mingw32
>>>
>>> attached base packages:
>>> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"
>>> "datasets"
>>> [7] "base"
>>>
>>>
>>> I then decided to download the latest version today but obtained the
>>> same result.
>>>
>>>
>>>> x<-rep(0.02,10)
>>>> var(x)
>>>
>>> [1] 1.337451e-35
>>
>>
>> My guess is that you've got a video driver or some other software that's
>> messing with your floating point processor, reducing the precision from
>> 64 bit to 53 or less.  I can reproduce the error after running
>> RSiteSearch, which messes with my fpu in that way:
>>
>> > var(rep(0.2, 100))
>> [1] 0
>> > RSiteSearch('fpu')
>> A search query has been submitted to http://search.r-project.org
>> The results page should open in your browser shortly
>> > var(rep(0.2, 100))
>> [1] 1.525181e-31
>>
>> (I'm not blaming RSiteSearch for doing something bad, it's the system
>> DLLs that it calls that are at fault.)
>>
>> I think this is something we should address, but it's not easy.
>>
>> Duncan Murdoch
>>
>>
>>>> sessionInfo()
>>>
>>> R version 2.2.1, 2005-12-20, i386-pc-mingw32
>>>
>>> attached base packages:
>>> [1] "methods"   "stats"     "graphics"  "grDevices" "utils"
>>> "datasets"
>>> [7] "base"
>>>
>>>
>>> I Changed .Machine$double.eps to make the calculations LESS accurate.
>>> My thought was that if I reduced the precision, 1-eps would return 1
>>> instead of some number less than 1.  My thought was that if eps were
>>> sufficiently large my sample problem would return a zero.  This didn't
>>> happen though.
>>>
>>> Again, any thoughts would be appreciated.
>>>
>>> Regards,
>>> Barry Zajdlik
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Sat Feb 18 19:40:31 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Sat, 18 Feb 2006 13:40:31 -0500
Subject: [R] Question about variable selection
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED829@usctmx1106.merck.com>

That depends on whether the IV could have some significant interactions with
other Ivs not considered in the bivariate analysis.  E.g.,

> iv <- expand.grid(-2:2, -2:2)
> y <- 3 + iv[,1] * iv[,2] + rnorm(nrow(iv), sd=0.1)
> summary(lm(y ~ iv[,1]))

Call:
lm(formula = y ~ iv[, 1])

Residuals:
     Min       1Q   Median       3Q      Max 
-4.06259 -1.06048 -0.02377  1.05901  4.04315 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  3.01908    0.41482   7.278 2.09e-07 ***
iv[, 1]      0.01417    0.29332   0.048    0.962    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Residual standard error: 2.074 on 23 degrees of freedom
Multiple R-Squared: 0.0001014,  Adjusted R-squared: -0.04337 
F-statistic: 0.002333 on 1 and 23 DF,  p-value: 0.9619 

> summary(lm(y ~ iv[,1] * iv[,2]))

Call:
lm(formula = y ~ iv[, 1] * iv[, 2])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.22390 -0.08894 -0.01279  0.13525  0.17608 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)      3.019083   0.026330 114.665   <2e-16 ***
iv[, 1]          0.014167   0.018618   0.761    0.455    
iv[, 2]         -0.005486   0.018618  -0.295    0.771    
iv[, 1]:iv[, 2]  0.992865   0.013165  75.418   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

Residual standard error: 0.1316 on 21 degrees of freedom
Multiple R-Squared: 0.9963,     Adjusted R-squared: 0.9958 
F-statistic:  1896 on 3 and 21 DF,  p-value: < 2.2e-16 




Andy

From: Wensui Liu
> 
> Dear Lister,
> 
> I have a question about variable selection for regression.
> 
> if the IV is not significantly related to DV in the bivariate 
> analysis, does
> it make sense to include this IV into the full model with 
> multiple IVs?
> 
> Thank you so much!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From antonio.fabio at gmail.com  Sat Feb 18 19:57:17 2006
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Sat, 18 Feb 2006 19:57:17 +0100
Subject: [R] lag.plot messy labels default
Message-ID: <b0808fdc0602181057y316fab35na153d95247a15a8c@mail.gmail.com>

Hi all.
Using R 2.2.1 I have encountered the following trivial problem with lag.plot.

lag.plot(1:3)

produces a labelled, directed lines "lag plot". But labels are taken to be
as.character(1:3)
so x-y coordinates for the last label have to be recycled, and one
actually sees on the screen labels "1" and "3" overlapping. Typing:

lag.plot(1:3, labels=as.character(1:2))

solves the problem. Of course, the problem is there for univariate
time series of any length (just tried some values:D ).

Have a nice week end,
Antonio, Fabio Di Narzo.



From liuwensui at gmail.com  Sat Feb 18 20:02:36 2006
From: liuwensui at gmail.com (Wensui Liu)
Date: Sat, 18 Feb 2006 14:02:36 -0500
Subject: [R] Question about variable selection
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED829@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED829@usctmx1106.merck.com>
Message-ID: <1115a2b00602181102k714d90d9s8b9e31297b7bfd71@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060218/b47c71e1/attachment.pl

From jfox at mcmaster.ca  Sat Feb 18 20:35:05 2006
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 18 Feb 2006 14:35:05 -0500
Subject: [R] Question about variable selection
In-Reply-To: <1115a2b00602181102k714d90d9s8b9e31297b7bfd71@mail.gmail.com>
Message-ID: <20060218193508.RFRB20622.tomts10-srv.bellnexxia.net@JohnDesktop8300>

Dear Wensui and Andy,

When the explanatory variables are correlated it's perfectly possible for
the marginal relationship between and X and Y to be zero and a partial
relationship nonzero (even in the absence of interactions) -- this is simply
a reflection of the more general point that partial and marginal
relationships can differ.

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wensui Liu
> Sent: Saturday, February 18, 2006 2:03 PM
> To: Liaw, Andy
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Question about variable selection
> 
> Thank you so much for your reply, Andy.
> 
> But what if I am only interesed in main effects instead of 
> interactions?
> 
> 
> 
> On 2/18/06, Liaw, Andy <andy_liaw at merck.com> wrote:
> >
> > That depends on whether the IV could have some significant 
> > interactions with other Ivs not considered in the bivariate 
> analysis.  
> > E.g.,
> >
> > > iv <- expand.grid(-2:2, -2:2)
> > > y <- 3 + iv[,1] * iv[,2] + rnorm(nrow(iv), sd=0.1) summary(lm(y ~ 
> > > iv[,1]))
> >
> > Call:
> > lm(formula = y ~ iv[, 1])
> >
> > Residuals:
> >      Min       1Q   Median       3Q      Max
> > -4.06259 -1.06048 -0.02377  1.05901  4.04315
> >
> > Coefficients:
> >             Estimate Std. Error t value Pr(>|t|)
> > (Intercept)  3.01908    0.41482   7.278 2.09e-07 ***
> > iv[, 1]      0.01417    0.29332   0.048    0.962
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> > Residual standard error: 2.074 on 23 degrees of freedom Multiple 
> > R-Squared: 0.0001014,  Adjusted R-squared: -0.04337
> > F-statistic: 0.002333 on 1 and 23 DF,  p-value: 0.9619
> >
> > > summary(lm(y ~ iv[,1] * iv[,2]))
> >
> > Call:
> > lm(formula = y ~ iv[, 1] * iv[, 2])
> >
> > Residuals:
> >      Min       1Q   Median       3Q      Max
> > -0.22390 -0.08894 -0.01279  0.13525  0.17608
> >
> > Coefficients:
> >                  Estimate Std. Error t value Pr(>|t|)
> > (Intercept)      3.019083   0.026330 114.665   <2e-16 ***
> > iv[, 1]          0.014167   0.018618   0.761    0.455
> > iv[, 2]         -0.005486   0.018618  -0.295    0.771
> > iv[, 1]:iv[, 2]  0.992865   0.013165  75.418   <2e-16 ***
> > ---
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> > Residual standard error: 0.1316 on 21 degrees of freedom
> > Multiple R-Squared: 0.9963,     Adjusted R-squared: 0.9958
> > F-statistic:  1896 on 3 and 21 DF,  p-value: < 2.2e-16
> >
> >
> >
> >
> > Andy
> >
> > From: Wensui Liu
> > >
> > > Dear Lister,
> > >
> > > I have a question about variable selection for regression.
> > >
> > > if the IV is not significantly related to DV in the bivariate 
> > > analysis, does it make sense to include this IV into the 
> full model 
> > > with multiple IVs?
> > >
> > > Thank you so much!
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list 
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> > >
> >
> >
> >
> > 
> ----------------------------------------------------------------------
> > --------
> > Notice:  This e-mail message, together with any 
> > attachment...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From liuwensui at gmail.com  Sat Feb 18 21:03:01 2006
From: liuwensui at gmail.com (Wensui Liu)
Date: Sat, 18 Feb 2006 15:03:01 -0500
Subject: [R] Question about variable selection
In-Reply-To: <20060218193508.RFRB20622.tomts10-srv.bellnexxia.net@JohnDesktop8300>
References: <1115a2b00602181102k714d90d9s8b9e31297b7bfd71@mail.gmail.com>
	<20060218193508.RFRB20622.tomts10-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <1115a2b00602181203p19339c75rdbdbd28c0d03d7d1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060218/8173d1d7/attachment.pl

From jfox at mcmaster.ca  Sat Feb 18 21:22:57 2006
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 18 Feb 2006 15:22:57 -0500
Subject: [R] Question about variable selection
In-Reply-To: <1115a2b00602181203p19339c75rdbdbd28c0d03d7d1@mail.gmail.com>
Message-ID: <20060218202258.DRL27612.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear Wensui,

I don't think that it's possible to answer these questions mechanically,
especially if you're interested in the "true" relationship between the
response and a set of explanatory variables. If, however, you have a pure
prediction problem, then variable selection is a more reasonable approach,
as long as it's done carefully (in my opinion). 

I don't see how resampling and repeatedly examining the marginal
relationship between Y and an X is relevant to the question of whether there
is a partial relationship in the absence of a marginal relationship. (This
is close to what Wittgenstein once called buying two copies of the same
newspaper to see whether what was said in the first one is true.) After all,
as I said (and as you understand), the partial and marginal relationship can
differ -- so evidence about the marginal relationship is not necessarily
relevant to inference about the partial relationship. (As well,
bootstrapping a linear least-squares regression likely isn't going to give
you much additional information anyway.)

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wensui Liu
> Sent: Saturday, February 18, 2006 3:03 PM
> To: John Fox
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Question about variable selection
> 
> Dear John,
> 
> I fully understand your point that a IV might not be 
> significantly correlated with DV in bivariate situation but 
> might be significantly correlated with DV with the presense 
> of other IVs. But does this significant partial relationship 
> reflect the true relation between IV and DV and really help 
> to predict DV?
> 
> >From here, let's go one step further. If I do multiple 
> resampling from
> original dataset, build bivariate LM between IV and DV with 
> different samples, and still can't get significant result, do 
> you think I should give a chance to this IV by looking at its 
> partial relationship with DV?
> 
> Thank you so much!
> 
> On 2/18/06, John Fox <jfox at mcmaster.ca> wrote:
> >
> > Dear Wensui and Andy,
> >
> > When the explanatory variables are correlated it's 
> perfectly possible 
> > for the marginal relationship between and X and Y to be zero and a 
> > partial relationship nonzero (even in the absence of 
> interactions) -- 
> > this is simply a reflection of the more general point that 
> partial and 
> > marginal relationships can differ.
> >
> > Regards,
> > John
> >
> > --------------------------------
> > John Fox
> > Department of Sociology
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > 905-525-9140x23604
> > http://socserv.mcmaster.ca/jfox
> > --------------------------------
> >
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch 
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Wensui Liu
> > > Sent: Saturday, February 18, 2006 2:03 PM
> > > To: Liaw, Andy
> > > Cc: r-help at stat.math.ethz.ch
> > > Subject: Re: [R] Question about variable selection
> > >
> > > Thank you so much for your reply, Andy.
> > >
> > > But what if I am only interesed in main effects instead of 
> > > interactions?
> > >
> > >
> > >
> > > On 2/18/06, Liaw, Andy <andy_liaw at merck.com> wrote:
> > > >
> > > > That depends on whether the IV could have some significant 
> > > > interactions with other Ivs not considered in the bivariate
> > > analysis.
> > > > E.g.,
> > > >
> > > > > iv <- expand.grid(-2:2, -2:2)
> > > > > y <- 3 + iv[,1] * iv[,2] + rnorm(nrow(iv), sd=0.1) 
> summary(lm(y 
> > > > > ~
> > > > > iv[,1]))
> > > >
> > > > Call:
> > > > lm(formula = y ~ iv[, 1])
> > > >
> > > > Residuals:
> > > >      Min       1Q   Median       3Q      Max
> > > > -4.06259 -1.06048 -0.02377  1.05901  4.04315
> > > >
> > > > Coefficients:
> > > >             Estimate Std. Error t value Pr(>|t|)
> > > > (Intercept)  3.01908    0.41482   7.278 2.09e-07 ***
> > > > iv[, 1]      0.01417    0.29332   0.048    0.962
> > > > ---
> > > > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> > > >
> > > > Residual standard error: 2.074 on 23 degrees of freedom Multiple
> > > > R-Squared: 0.0001014,  Adjusted R-squared: -0.04337
> > > > F-statistic: 0.002333 on 1 and 23 DF,  p-value: 0.9619
> > > >
> > > > > summary(lm(y ~ iv[,1] * iv[,2]))
> > > >
> > > > Call:
> > > > lm(formula = y ~ iv[, 1] * iv[, 2])
> > > >
> > > > Residuals:
> > > >      Min       1Q   Median       3Q      Max
> > > > -0.22390 -0.08894 -0.01279  0.13525  0.17608
> > > >
> > > > Coefficients:
> > > >                  Estimate Std. Error t value Pr(>|t|)
> > > > (Intercept)      3.019083   0.026330 114.665   <2e-16 ***
> > > > iv[, 1]          0.014167   0.018618   0.761    0.455
> > > > iv[, 2]         -0.005486   0.018618  -0.295    0.771
> > > > iv[, 1]:iv[, 2]  0.992865   0.013165  75.418   <2e-16 ***
> > > > ---
> > > > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> > > >
> > > > Residual standard error: 0.1316 on 21 degrees of freedom
> > > > Multiple R-Squared: 0.9963,     Adjusted R-squared: 0.9958
> > > > F-statistic:  1896 on 3 and 21 DF,  p-value: < 2.2e-16
> > > >
> > > >
> > > >
> > > >
> > > > Andy
> > > >
> > > > From: Wensui Liu
> > > > >
> > > > > Dear Lister,
> > > > >
> > > > > I have a question about variable selection for regression.
> > > > >
> > > > > if the IV is not significantly related to DV in the bivariate 
> > > > > analysis, does it make sense to include this IV into the
> > > full model
> > > > > with multiple IVs?
> > > > >
> > > > > Thank you so much!
> > > > >
> > > > >       [[alternative HTML version deleted]]
> > > > >
> > > > > ______________________________________________
> > > > > R-help at stat.math.ethz.ch mailing list 
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide!
> > > > > http://www.R-project.org/posting-guide.html
> > > > >
> > > > >
> > > >
> > > >
> > > >
> > > >
> > > 
> --------------------------------------------------------------------
> > > --
> > > > --------
> > > > Notice:  This e-mail message, together with any 
> > > > attachment...{{dropped}}
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list 
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> >
> >
> 
> 
> --
> WenSui Liu
> (http://statcompute.blogspot.com)
> Senior Decision Support Analyst
> Health Policy and Clinical Effectiveness Cincinnati Children 
> Hospital Medical Center
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From spluque at gmail.com  Sat Feb 18 23:07:42 2006
From: spluque at gmail.com (Sebastian Luque)
Date: Sat, 18 Feb 2006 16:07:42 -0600
Subject: [R] reshaping result of by()
Message-ID: <87wtfspbgx.fsf@arctocephalus.homelinux.org>

Hello,

I'm trying to build a frequency table for a vector, broken down by the
combination of factors.  For further analyses, I need to have the result
arranged in a new data frame, with the upper limit of the histogram's
breaks, the per bin count, and the factors identifying each record.  My
problem is including the latter:

---<---------------cut here---------------start-------------->---

toydf <- expand.grid(sample(0:50, 50, TRUE), c("A", "B"),
                     c("pop1", "pop2", "pop3", "pop4", "pop5"))

"getFreq" <- function(x, bks)
{
  fhist <- hist(x, breaks = bks, plot = FALSE,
                include.lowest = TRUE)
  matrix(c(fhist$breaks[-1], fhist$counts),
           nrow = length(fhist$breaks[-1]), ncol = 2)
}

freqs <- by(toydf[[1]], list(toydf[[2]], toydf[[3]]), getFreq, bks = 0:50)

---<---------------cut here---------------end---------------->---

so I'd need to do some manipulation with dimnames(freqs), which contains
the levels of the factors supplied to 'getFreq', to assign the factors to
each element of the matrix value of 'by'.  I could then do:

do.call(rbind, freqs)

to obtain the final data frame, which would then have all the necessary
information.

Any help with manipulation of the dimnames(freqs) (or something even
better) would be very appreciated!

Cheers,

-- 
Sebastian P. Luque



From lists at revelle.net  Sat Feb 18 23:22:13 2006
From: lists at revelle.net (William Revelle)
Date: Sat, 18 Feb 2006 16:22:13 -0600
Subject: [R] Question about variable selection
In-Reply-To: <20060218202258.DRL27612.tomts16-srv.bellnexxia.net@JohnDesktop8300>
References: <20060218202258.DRL27612.tomts16-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <p06230900c01d4bbd4d62@[165.124.166.122]>

Dear Wensui,

What you are asking about is called in psychology a "suppressor" 
variable: a predictor variable unrelated to the criterion but 
correlated with the other predictors. (X1 in the following example) 
Although it has a zero relationship with the DV, it does "really" 
help to predict the DV by removing extraneous variance from the other 
IVs.  (I am not going to touch the Wittgenstein issue of truth here). 
Should it be included in the predictor set? Yes.  Is there any easy 
way to find all possible suppressors? No.


Consider the following:

#demonstration of "suppressor effects"
library(mvtnorm)
sigma <- matrix(c(1,.5,0,.5,1,.5,0,.5,1),ncol=3)
my.data <- data.frame(rmvnorm(1000,sigma=sigma))
names(my.data) <- c("X1", "X2", "Y")
round(cor(my.data),2)
summary(lm(Y~ X1 + X2,data= my.data))

which produces
       X1   X2     Y
X1  1.00 0.45 -0.04
X2  0.45 1.00  0.51
Y  -0.04 0.51  1.00
>  summary(lm(Y~ X1 + X2,data= my.data))

Call:
lm(formula = Y ~ X1 + X2, data = my.data)

Residuals:
      Min       1Q   Median       3Q      Max
-2.09350 -0.58069  0.02280  0.53436  3.02017

Coefficients:
             Estimate Std. Error t value Pr(>|t|)   
(Intercept)  0.02807    0.02557   1.098    0.273   
X1          -0.32849    0.02813 -11.680   <2e-16 ***
X2           0.65666    0.02861  22.951   <2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.8081 on 997 degrees of freedom
Multiple R-Squared: 0.3465,	Adjusted R-squared: 0.3452
F-statistic: 264.4 on 2 and 997 DF,  p-value: < 2.2e-16



At 3:22 PM -0500 2/18/06, John Fox wrote:
>Dear Wensui,
>
>I don't think that it's possible to answer these questions mechanically,
>especially if you're interested in the "true" relationship between the
>response and a set of explanatory variables. If, however, you have a pure
>prediction problem, then variable selection is a more reasonable approach,
>as long as it's done carefully (in my opinion).
>
>I don't see how resampling and repeatedly examining the marginal
>relationship between Y and an X is relevant to the question of whether there
>is a partial relationship in the absence of a marginal relationship. (This
>is close to what Wittgenstein once called buying two copies of the same
>newspaper to see whether what was said in the first one is true.) After all,
>as I said (and as you understand), the partial and marginal relationship can
>differ -- so evidence about the marginal relationship is not necessarily
>relevant to inference about the partial relationship. (As well,
>bootstrapping a linear least-squares regression likely isn't going to give
>you much additional information anyway.)
>
>Regards,
>  John
>
>--------------------------------
>John Fox
>Department of Sociology


.... (discussion of interaction from Andy Liaw)


>  > > > From: Wensui Liu
>  > > > >
>  > > > > Dear Lister,
>  > > > >
>  > > > > I have a question about variable selection for regression.
>  > > > >
>  > > > > if the IV is not significantly related to DV in the bivariate
>  > > > > analysis, does it make sense to include this IV into the
>  > > full model
>  > > > > with multiple IVs?
>  > > > >
>  > > > > Thank you so much!


-- 
William Revelle		http://pmc.psych.northwestern.edu/revelle.html   
Professor			http://personality-project.org/personality.html
Department of Psychology       http://www.wcas.northwestern.edu/psych/
Northwestern University	http://www.northwestern.edu/



From Ted.Harding at nessie.mcc.ac.uk  Sun Feb 19 11:16:58 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sun, 19 Feb 2006 10:16:58 -0000 (GMT)
Subject: [R] figure out whether 1 is between two numbers
In-Reply-To: <43F72884.7050807@stats.uwo.ca>
Message-ID: <XFMail.060219101658.Ted.Harding@nessie.mcc.ac.uk>

On 18-Feb-06 Duncan Murdoch wrote:
> On 2/18/2006 1:13 AM, Robert W. Baer, Ph.D. wrote:
>> Try:
>> (X>1 & Y<1) | (X<1 & Y>1)
> 
> This is a minor stylistic suggestion: when translating the
> mathematical expression (a < b < c), write it as
> (a < b) & (b < c). It has no effect on the outcome, but
> keeping the inequalities in the same direction makes 
> the meaning more obvious.
> 
> If you do this, your expression becomes
> 
> (Y<1 & 1<X) | (X<1 & 1<Y)
> 
> and it's clear at a glance what's going on.

And, as a follow-up, can I suggest for ultimate clarity [ :) ]

  (X<1 | Y<1) & (1<X | 1<Y)

Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 19-Feb-06                                       Time: 10:16:55
------------------------------ XFMail ------------------------------



From jholtman at gmail.com  Sun Feb 19 01:30:22 2006
From: jholtman at gmail.com (jim holtman)
Date: Sat, 18 Feb 2006 19:30:22 -0500
Subject: [R] reshaping result of by()
In-Reply-To: <87wtfspbgx.fsf@arctocephalus.homelinux.org>
References: <87wtfspbgx.fsf@arctocephalus.homelinux.org>
Message-ID: <644e1f320602181630u3f6c9ebdlbaa88b0a5b5ae352@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060218/a367c5ef/attachment.pl

From A.Robinson at ms.unimelb.edu.au  Sun Feb 19 01:43:09 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 19 Feb 2006 11:43:09 +1100 (EST)
Subject: [R] Changing predictor order in lm()
Message-ID: <50496.63.125.5.171.1140309789.squirrel@webmail.ms.unimelb.edu.au>

Dear community,

can anyone provide a snippet of code to force the lm() to fit a model with
terms in the formula in an arbitrary order?  I am interested in something
like:

lm(y ~ A * B + C, data=data)

where the interaction of A and B should be in the formula before C.  My
goal is to simplify my presentation of models using the anova() statement.
 I have found that this should be possible using the terms.formula()
function, but if anyone has an example that would be much appreciated.

Cheers

Andrew


Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344 4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au



From islandboy1982 at yahoo.com  Sun Feb 19 12:42:19 2006
From: islandboy1982 at yahoo.com (oliver wee)
Date: Sun, 19 Feb 2006 03:42:19 -0800 (PST)
Subject: [R] getting the conditional standard deviation of the residuals of
	a fitted GARCH model
Message-ID: <20060219114219.11846.qmail@web33203.mail.mud.yahoo.com>

hello,

what is the command used to get the conditional
standard deviation of the residuals of a fitted GARCH
model in R?

thanks again for the help.



From sell_mirage_ne at hotmail.com  Sun Feb 19 02:29:51 2006
From: sell_mirage_ne at hotmail.com (Taka Matzmoto)
Date: Sat, 18 Feb 2006 19:29:51 -0600
Subject: [R] (no subject)
Message-ID: <BAY110-F2F614FAB7BC45497364B4C7FE0@phx.gbl>

Thanks to Martin Sandiford,
I can draw a graph using lower diagonal type of data.
One problem I can't solve is to put appropriate tick marks on the graph

##############################################
x<- matrix(NA,50,50)
x[lower.tri(x)] <- runif(choose(50,2),0,1)
plot(1,2,xlim=c(1,50),ylim=c(49,2),xlab="",ylab="",type="n")
par(new=T)
image(1-t(x)[,ncol(x):1], col=gray.colors(100), axes=FALSE)
##############################################

I like ticks on both x-axis and y-axis to be located in the middle of each 
cell.
X-axis needs to start with 1 and end with 50.
Y-axis needs to start with 2 and end with 49.

I looked at the help file for "par" and changed some settings but I couldn't 
succeed.

Any advice on this issue would be greatly appreciated !!

TM

_________________________________________________________________
Dont just search. Find. Check out the new MSN Search!



From ka4alin at yandex.ru  Sun Feb 19 13:49:20 2006
From: ka4alin at yandex.ru (Evgeniy Kachalin)
Date: Sun, 19 Feb 2006 15:49:20 +0300
Subject: [R] Two factors -> nurical data dependency analyzing
In-Reply-To: <mailman.7.1140346801.11657.r-help@stat.math.ethz.ch>
References: <mailman.7.1140346801.11657.r-help@stat.math.ethz.ch>
Message-ID: <43F86950.3090008@yandex.ru>

Hello, dear R users.

What is the easiest and the most visualli understandable way to analize 
dependency of numerical variable on two factors?
Is the
boxplot(y~f1+f2) the good way? It seems that this formula does not work.

-- 
Evgeniy



From ripley at stats.ox.ac.uk  Sun Feb 19 13:43:41 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 19 Feb 2006 12:43:41 +0000 (GMT)
Subject: [R] Changing predictor order in lm()
In-Reply-To: <50496.63.125.5.171.1140309789.squirrel@webmail.ms.unimelb.edu.au>
References: <50496.63.125.5.171.1140309789.squirrel@webmail.ms.unimelb.edu.au>
Message-ID: <Pine.LNX.4.64.0602191240490.15946@gannet.stats.ox.ac.uk>

RSiteSearch("keep.order") gave me

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/14240.html

which has such an example, and points out another example is in 
demo(glm.vr).

On Sun, 19 Feb 2006, Andrew Robinson wrote:

> Dear community,
>
> can anyone provide a snippet of code to force the lm() to fit a model with
> terms in the formula in an arbitrary order?  I am interested in something
> like:
>
> lm(y ~ A * B + C, data=data)
>
> where the interaction of A and B should be in the formula before C.  My
> goal is to simplify my presentation of models using the anova() statement.
> I have found that this should be possible using the terms.formula()
> function, but if anyone has an example that would be much appreciated.
>
> Cheers
>
> Andrew
>
>
> Andrew Robinson
> Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
> Department of Mathematics and Statistics            Fax: +61-3-8344 4599
> University of Melbourne, VIC 3010 Australia
> Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Feb 19 15:49:21 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 19 Feb 2006 14:49:21 +0000 (GMT)
Subject: [R] Two factors -> nurical data dependency analyzing
In-Reply-To: <43F86950.3090008@yandex.ru>
References: <mailman.7.1140346801.11657.r-help@stat.math.ethz.ch>
	<43F86950.3090008@yandex.ru>
Message-ID: <Pine.LNX.4.64.0602191356450.20648@gannet.stats.ox.ac.uk>

On Sun, 19 Feb 2006, Evgeniy Kachalin wrote:

> Hello, dear R users.
>
> What is the easiest and the most visualli understandable way to analize
> dependency of numerical variable on two factors?

interaction.plot() is a good start.

> Is the
> boxplot(y~f1+f2) the good way? It seems that this formula does not work.

No, nor is it documented to: the help page is there to help you.  You need 
a single factor as the grouping, so make one via an interaction.
boxplot(y ~ f1:f2) should work.  E.g.

library(MASS)
boxplot(FL ~ sex:sp, data=crabs)

Another idea is to use lattice's bwplot.  E.g.

library(lattice)
bwplot(FL ~ sex | sp, data=crabs)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ka4alin at yandex.ru  Sun Feb 19 16:14:59 2006
From: ka4alin at yandex.ru (Evgeniy Kachalin)
Date: Sun, 19 Feb 2006 18:14:59 +0300
Subject: [R] Two factors -> nurical data dependency analyzing
In-Reply-To: <Pine.LNX.4.64.0602191356450.20648@gannet.stats.ox.ac.uk>
References: <mailman.7.1140346801.11657.r-help@stat.math.ethz.ch>
	<43F86950.3090008@yandex.ru>
	<Pine.LNX.4.64.0602191356450.20648@gannet.stats.ox.ac.uk>
Message-ID: <43F88B73.4000704@yandex.ru>

Prof Brian Ripley ?????:
> On Sun, 19 Feb 2006, Evgeniy Kachalin wrote:
>
>> Hello, dear R users.
>>
>> What is the easiest and the most visualli understandable way to analize
>> dependency of numerical variable on two factors?
>
> interaction.plot() is a good start.
>
>> Is the
>> boxplot(y~f1+f2) the good way? It seems that this formula does not work.
>
> No, nor is it documented to: the help page is there to help you. You 
> need a single factor as the grouping, so make one via an interaction.
> boxplot(y ~ f1:f2) should work. E.g.
>
> library(MASS)
> boxplot(FL ~ sex:sp, data=crabs)
Does not work:
???????????? ?? if (any(out[nna])) stats[c(1, 5)] <- range(x[!out], na.rm = 
TRUE) :
?????????????????????? ????????????????, ?? ?????????? TRUE/FALSE
????????????????: Warning messages:
1: + not meaningful for factors in: Ops.factor(x[floor(d)], x[ceiling(d)])
2: < not meaningful for factors in: Ops.factor(x, (stats[2] - coef * iqr))
3: > not meaningful for factors in: Ops.factor(x, (stats[4] + coef * iqr))

Hm...

> Another idea is to use lattice's bwplot. E.g.
>
> library(lattice)
> bwplot(FL ~ sex | sp, data=crabs)
>
>
That's not the point. The scales may differ significantly, also this is 
not conviniet for many factors.



From myotisone at gmail.com  Sun Feb 19 16:59:10 2006
From: myotisone at gmail.com (Graham Smith)
Date: Sun, 19 Feb 2006 15:59:10 +0000
Subject: [R] Linux Distribution Choice
Message-ID: <2c75873c0602190759m3518e5b5p@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060219/6c5c5880/attachment.pl

From charshaw at presby.edu  Sun Feb 19 17:00:44 2006
From: charshaw at presby.edu (Clint Harshaw)
Date: Sun, 19 Feb 2006 11:00:44 -0500
Subject: [R] changing names of vectors in list or data.frame
Message-ID: <43F8962C.2090206@presby.edu>

When I combine separate vectors into one list, there are new names 
created. I'd like to change them to something more meaningful.

Here are two examples using data(zelazo) from library(ISwR):

 > library(ISwR)
 > data(zelazo)
 > attach(zelazo)
 > zelazo
$active
[1]  9.00  9.50  9.75 10.00 13.00  9.50

$passive
[1] 11.00 10.00 10.00 11.75 10.50 15.00

$none
[1] 11.50 12.00  9.00 11.50 13.25 13.00

$ctr.8w
[1] 13.25 11.50 12.00 13.50 11.50
 > walk <- stack(list("active"=active, "passive"=passive, "none"=none, 
"ctr.8w"=ctr.8w))
 > walk
    values     ind
1    9.00  active
[...rows deleted...]
23  11.50  ctr.8w

I want to name the first column "walking" and the second column 
"training". How do I do this?

Here is a second example:

 > walk2 <- data.frame(c(active, passive, none, ctr.8w), c(rep(1:4, 
c(length(active), length(passive), length(none), length(ctr.8w)))))
 > walk2
    c.active..passive..none..ctr.8w.
1                              9.00
[...rows deleted...]
23                            11.50
 
c.rep.1.4..c.length.active...length.passive...length.none...length.ctr.8w....
1 
        [...rows deleted...]
4
 >

The created names are very long. Again, I want the name of the first 
column to be "walking" and the second column to be "training".

Thanks,
Clint



From charles.edwin.white at us.army.mil  Sun Feb 19 17:05:33 2006
From: charles.edwin.white at us.army.mil (White, Charles E WRAIR-Wash DC)
Date: Sun, 19 Feb 2006 11:05:33 -0500
Subject: [R] [Rd] Citation for R
Message-ID: <8BAEC5E546879B4FAA536200A292C614010A3925@AMEDMLNARMC135.amed.ds.army.mil>

My subject line refers to a thread from June 2005 where I found
explanations from Uwe Ligges and Friedrich Leisch as to what is intended
by the R citation recommended within the software. Forgive me if I
missed some points within the thread but when I found myself circling
through messages I had already read, I stopped trying to follow it. I
understand and mostly agree with how the R citation is currently
suggested, though I would like to make two recommendations:

(1) Include the version number in the citation.

When editors realize I'm citing software, they want to know which
version I am citing. Since the document we are citing (called the
'Reference Index' under the 'Manuals' link) actually includes the
version number anyway, I recommend that the R Development Core Team
expand the reference to include that information. A suggested format
follows:

R Development Core Team (2005). R: A language and environment for
statistical computing, reference index version 2.2.1. R Foundation for
Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0, URL
http://www.R-project.org.

(2) Help editors find the cited document by (a) explicitly providing a
citation link on the main web page for the R-project and (b) referencing
the cited document on the web site by the name under which it is cited.

Imagine the hapless editor following the R-project link expecting to
find a document called "R: A language and environment for statistical
computing." They then Google the ISBN number and find it referring to
multiple versions of the software. <grin> With regard to the citation
link, I recommend that it be called 'Citing R' and that it be placed on
the left side of the web page under the header called 'About R.' With
regard to the text on the page linked to 'Citing R,' I suggest something
like the following:

The R Development Core Team recommends the following citation for the
current major release of R:

R Development Core Team (2005). R: A language and environment for
statistical computing, reference index version 2.x.x. R Foundation for
Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0, URL
http://www.R-project.org.

With regard to the version number, 2 is the major release, the first x
is the minor release, and the last x is the patch level. The ISBN number
covers both the software and the tightly bundled reference index. This
number changes with each major release of R.
...

Thanks for your time.

Chuck

Charles E. White, Senior Biostatistician, MS
Walter Reed Army Institute of Research
503 Robert Grant Ave., Room 1w102
Silver Spring, MD 20910-1557
301 319-9781
Personal/Professional Site:
http://users.starpower.net/cwhite571/professional/



From ripley at stats.ox.ac.uk  Sun Feb 19 17:26:40 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 19 Feb 2006 16:26:40 +0000 (GMT)
Subject: [R] Two factors -> nurical data dependency analyzing
In-Reply-To: <43F88B73.4000704@yandex.ru>
References: <mailman.7.1140346801.11657.r-help@stat.math.ethz.ch>
	<43F86950.3090008@yandex.ru>
	<Pine.LNX.4.64.0602191356450.20648@gannet.stats.ox.ac.uk>
	<43F88B73.4000704@yandex.ru>
Message-ID: <Pine.LNX.4.64.0602191621540.22454@gannet.stats.ox.ac.uk>

I carefully tested my suggestions in the current version of R, 2.2.1, 
before posting.  They DO work, and as you have not even told us your 
version of R, we have no idea what you have broken on your R installation.


On Sun, 19 Feb 2006, Evgeniy Kachalin wrote:

> Prof Brian Ripley ?????:
>> On Sun, 19 Feb 2006, Evgeniy Kachalin wrote:
>> 
>>> Hello, dear R users.
>>> 
>>> What is the easiest and the most visualli understandable way to analize
>>> dependency of numerical variable on two factors?
>> 
>> interaction.plot() is a good start.
>> 
>>> Is the
>>> boxplot(y~f1+f2) the good way? It seems that this formula does not work.
>> 
>> No, nor is it documented to: the help page is there to help you. You need a 
>> single factor as the grouping, so make one via an interaction.
>> boxplot(y ~ f1:f2) should work. E.g.
>> 
>> library(MASS)
>> boxplot(FL ~ sex:sp, data=crabs)
> Does not work:
> ???????????? ?? if (any(out[nna])) stats[c(1, 5)] <- range(x[!out], na.rm = TRUE) :
> ?????????????????????? ????????????????, ?? ?????????? TRUE/FALSE
> ????????????????: Warning messages:
> 1: + not meaningful for factors in: Ops.factor(x[floor(d)], x[ceiling(d)])
> 2: < not meaningful for factors in: Ops.factor(x, (stats[2] - coef * iqr))
> 3: > not meaningful for factors in: Ops.factor(x, (stats[4] + coef * iqr))
>
> Hm...
>
>> Another idea is to use lattice's bwplot. E.g.
>> 
>> library(lattice)
>> bwplot(FL ~ sex | sp, data=crabs)
>> 
>> 
> That's not the point. The scales may differ significantly, also this is not 
> conviniet for many factors.
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Sun Feb 19 17:30:11 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 19 Feb 2006 16:30:11 +0000 (GMT)
Subject: [R] changing names of vectors in list or data.frame
In-Reply-To: <43F8962C.2090206@presby.edu>
References: <43F8962C.2090206@presby.edu>
Message-ID: <Pine.LNX.4.64.0602191628060.22454@gannet.stats.ox.ac.uk>

1) use names() on the resulting data frame: stack() always uses those two 
names.  As in

names(walk) <- c("walking", "training")

2) data.frame is more useful when the arguments are named, and you can 
just name them: see the help.

On Sun, 19 Feb 2006, Clint Harshaw wrote:

> When I combine separate vectors into one list, there are new names
> created. I'd like to change them to something more meaningful.
>
> Here are two examples using data(zelazo) from library(ISwR):
>
> > library(ISwR)
> > data(zelazo)
> > attach(zelazo)
> > zelazo
> $active
> [1]  9.00  9.50  9.75 10.00 13.00  9.50
>
> $passive
> [1] 11.00 10.00 10.00 11.75 10.50 15.00
>
> $none
> [1] 11.50 12.00  9.00 11.50 13.25 13.00
>
> $ctr.8w
> [1] 13.25 11.50 12.00 13.50 11.50
> > walk <- stack(list("active"=active, "passive"=passive, "none"=none,
> "ctr.8w"=ctr.8w))
> > walk
>    values     ind
> 1    9.00  active
> [...rows deleted...]
> 23  11.50  ctr.8w
>
> I want to name the first column "walking" and the second column
> "training". How do I do this?
>
> Here is a second example:
>
> > walk2 <- data.frame(c(active, passive, none, ctr.8w), c(rep(1:4,
> c(length(active), length(passive), length(none), length(ctr.8w)))))
> > walk2
>    c.active..passive..none..ctr.8w.
> 1                              9.00
> [...rows deleted...]
> 23                            11.50
>
> c.rep.1.4..c.length.active...length.passive...length.none...length.ctr.8w....
> 1
>        [...rows deleted...]
> 4
> >
>
> The created names are very long. Again, I want the name of the first
> column to be "walking" and the second column to be "training".
>
> Thanks,
> Clint
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ka4alin at yandex.ru  Sun Feb 19 17:33:59 2006
From: ka4alin at yandex.ru (Evgeniy Kachalin)
Date: Sun, 19 Feb 2006 19:33:59 +0300
Subject: [R] Two factors -> nurical data dependency analyzing
In-Reply-To: <Pine.LNX.4.64.0602191621540.22454@gannet.stats.ox.ac.uk>
References: <mailman.7.1140346801.11657.r-help@stat.math.ethz.ch>
	<43F86950.3090008@yandex.ru>
	<Pine.LNX.4.64.0602191356450.20648@gannet.stats.ox.ac.uk>
	<43F88B73.4000704@yandex.ru>
	<Pine.LNX.4.64.0602191621540.22454@gannet.stats.ox.ac.uk>
Message-ID: <43F89DF7.6010701@yandex.ru>

Prof Brian Ripley ?????:
> I carefully tested my suggestions in the current version of R, 2.2.1, 
> before posting. They DO work, and as you have not even told us your 
> version of R, we have no idea what you have broken on your R 
> installation.
I'm sorry. This works. Thank you.
Are there any other visualisation ways in R? I'm sorry if this question 
is not good enough for this mailing list.

-- 
Evgeniy



From p.dalgaard at biostat.ku.dk  Sun Feb 19 17:36:59 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Feb 2006 17:36:59 +0100
Subject: [R] changing names of vectors in list or data.frame
In-Reply-To: <43F8962C.2090206@presby.edu>
References: <43F8962C.2090206@presby.edu>
Message-ID: <x2zmknpaok.fsf@turmalin.kubism.ku.dk>

Clint Harshaw <charshaw at presby.edu> writes:

> When I combine separate vectors into one list, there are new names 
> created. I'd like to change them to something more meaningful.
> 
> Here are two examples using data(zelazo) from library(ISwR):
> 
>  > library(ISwR)
>  > data(zelazo)
>  > attach(zelazo)
>  > zelazo
> $active
> [1]  9.00  9.50  9.75 10.00 13.00  9.50
> 
> $passive
> [1] 11.00 10.00 10.00 11.75 10.50 15.00
> 
> $none
> [1] 11.50 12.00  9.00 11.50 13.25 13.00
> 
> $ctr.8w
> [1] 13.25 11.50 12.00 13.50 11.50
>  > walk <- stack(list("active"=active, "passive"=passive, "none"=none, 
> "ctr.8w"=ctr.8w))
>  > walk
>     values     ind
> 1    9.00  active
> [...rows deleted...]
> 23  11.50  ctr.8w
> 
> I want to name the first column "walking" and the second column 
> "training". How do I do this?

The obvious way would seem to be

names(walk) <- c("walking","training")
 
> Here is a second example:
> 
>  > walk2 <- data.frame(c(active, passive, none, ctr.8w), c(rep(1:4, 
> c(length(active), length(passive), length(none), length(ctr.8w)))))
>  > walk2
>     c.active..passive..none..ctr.8w.
> 1                              9.00
> [...rows deleted...]
> 23                            11.50
>  
> c.rep.1.4..c.length.active...length.passive...length.none...length.ctr.8w....
> 1 
>         [...rows deleted...]
> 4
>  >
> 
> The created names are very long. Again, I want the name of the first 
> column to be "walking" and the second column to be "training".

walk2 <- data.frame(walking=c(active, passive, none, ctr.8w),
   training=c(rep(1:4, c(length(active), length(passive),
   length(none), length(ctr.8w)))))


[or 
 walk2 <- data.frame(walking=unlist(zelazo),
                     training=factor(rep(1:4, sapply(zelazo,length)),
                                     labels=names(zelazo) ))
]
-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ka4alin at yandex.ru  Sun Feb 19 17:52:48 2006
From: ka4alin at yandex.ru (Evgeniy Kachalin)
Date: Sun, 19 Feb 2006 19:52:48 +0300
Subject: [R] Two factors -> nurical data dependency analyzing
In-Reply-To: <Pine.LNX.4.64.0602191356450.20648@gannet.stats.ox.ac.uk>
References: <mailman.7.1140346801.11657.r-help@stat.math.ethz.ch>
	<43F86950.3090008@yandex.ru>
	<Pine.LNX.4.64.0602191356450.20648@gannet.stats.ox.ac.uk>
Message-ID: <43F8A260.7060109@yandex.ru>

Prof Brian Ripley ?????:
> On Sun, 19 Feb 2006, Evgeniy Kachalin wrote:
>
>> Hello, dear R users.
>>
>> What is the easiest and the most visualli understandable way to analize
>> dependency of numerical variable on two factors?
>
> interaction.plot() is a good start.
>
>> Is the
>> boxplot(y~f1+f2) the good way? It seems that this formula does not work.
>
> No, nor is it documented to: the help page is there to help you. You 
> need a single factor as the grouping, so make one via an interaction.
> boxplot(y ~ f1:f2) should work. E.g.
>
> library(MASS)
> boxplot(FL ~ sex:sp, data=crabs)
>
> Another idea is to use lattice's bwplot. E.g.
>
> library(lattice)
> bwplot(FL ~ sex | sp, data=crabs)

Ideally it would be a tree of factors with mean as leaves. May be you 
could hint me direction to search for a graph.



From Roger.Bivand at nhh.no  Sun Feb 19 18:06:48 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 19 Feb 2006 18:06:48 +0100 (CET)
Subject: [R] Linux Distribution Choice
In-Reply-To: <2c75873c0602190759m3518e5b5p@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0602191744570.21407-100000@reclus.nhh.no>

On Sun, 19 Feb 2006, Graham Smith wrote:

> I am making some tentative steps into using Linux (Mandriva at the moment)
> and notice that not all the Linux binaries on CRAN are the latest release.
> 
> As R (plus Grass) will be key programs for me on Linux, is there a preferred
> Linux distribution that people in the R communiuty use?

There are a fair number of distributions out there, and often users find
that even though they have installed an R binary, they cannot successfully
install R contributed packages because their build train is incomplete,
and/or they lack development components. Building R from source on modern
Linux distributions is not difficult, and will let you check whether you
can install R contributed packages with C, C++, or Fortran source code.  
Essentially the same concerns apply to GRASS, and particularly to the
software GRASS depends on, crucially GDAL/OGR. 

While learning to install from source may seem challenging, it is worth
doing especially when you would like to work using several linked
applications. The R-GRASS interface is developed on RHEL4, I believe a
lead GRASS developer also uses RHEL, but others use Mandriva and many more
Debian, Ubuntu, and so on. If you'd like a taster, Quantian (0.7.9.1) has
GRASS 6.0.1, GDAL 1.2.6, and r-base 2.2.0 (none the latest releases, but
perhaps enough to try out).

If in doubt about a distribution, consider what support resources are 
close to you. "gmail.com" isn't very informative, but many organisationa 
and universities do have Linux policies, and choosing a distribution that 
maximises the chances to being able to talk to someone using the same 
distribution is sensible, even if it isn't the one you though of first. 
Chapter 2 of http://cran.r-project.org/doc/manuals/R-admin.html is helpful 
reading if you decide to install from source.

> 
> Many thanks,
> 
> Graham
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From phgrosjean at sciviews.org  Sun Feb 19 19:38:41 2006
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Sun, 19 Feb 2006 19:38:41 +0100
Subject: [R] how to clear screen in R-console?
In-Reply-To: <971536df0602170936j4922f9fcw60ac35133a7ca621@mail.gmail.com>
References: <059DE74C2765E04284021ACFDB7A22DD8765D8@s6.neuro.mpg.de>	<971536df0602170841o204a86e5rc775bc74fc378e83@mail.gmail.com>
	<971536df0602170936j4922f9fcw60ac35133a7ca621@mail.gmail.com>
Message-ID: <43F8BB31.5000302@sciviews.org>

And here is a reworked version that checks if it is RGui, if WSH is 
started, etc. and that returns invisibly TRUE/FALSE:

# An R function to clear the screen on RGui:
cls <- function() {
	if (.Platform$GUI[1] != "Rgui")
		return(invisible(FALSE))
	if (!require(rcom, quietly = TRUE)) # Not shown any way!
		stop("Package rcom is required for 'cls()'")
	wsh <- comCreateObject("Wscript.Shell")
	if (is.null(wsh)) {
		return(invisible(FALSE))
	} else {
		comInvoke(wsh, "SendKeys", "\014")
		return(invisible(TRUE))
	}
}
#cls() # test
# If you want to make sure that it worked (well, not 100% sure, but...)
res <- cls()
if (res) cat("Console should be cleared now!\n")

Best,

Philippe Grosjean

P.S.: Gabor, I would like to include this function in the SciViews 
bundle. Would it be a problem for you?

..............................................<??}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
( ( ( ( (
  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
  ) ) ) ) )
( ( ( ( (    web:   http://www.umh.ac.be/~econum
  ) ) ) ) )          http://www.sciviews.org
( ( ( ( (
..............................................................

Gabor Grothendieck wrote:
> Here is a version that uses rcom instead of RDCOMClient.
> This has the advantage that rcom is on CRAN.
> 
> cls <- function() {
> 	require(rcom)
> 	wsh <- comCreateObject("Wscript.Shell")
> 	comInvoke(wsh, "SendKeys", "\014")
> 	invisible(wsh)
> }
> cls() # test
> 
> On 2/17/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> 
>>Here is a translation of Norm Olsen's vbscript code into pure R.
>>This is intended for use with the Windows Rgui interface.
>>
>>cls <- function() {
>>       require(RDCOMClient)
>>       wsh <- COMCreate("Wscript.Shell")
>>       wsh$SendKeys("\014")
>>       invisible(wsh)
>>}
>>cls()  # invoke
>>
>>
>>
>>On 2/17/06, Marcus Leinweber <leinweber at neuro.mpg.de> wrote:
>>
>>>have already tried this?
>>>
>>>http://finzi.psych.upenn.edu/R/Rhelp02a/archive/55752.html
>>>
>>>m.
>>>
>>>
>>>
>>>>-----Original Message-----
>>>>From: r-help-bounces at stat.math.ethz.ch
>>>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Michael
>>>>Sent: Thursday, February 16, 2006 9:23 PM
>>>>To: Henrik Bengtsson
>>>>Cc: R-help at stat.math.ethz.ch
>>>>Subject: Re: [R] how to clear screen in R-console?
>>>>
>>>>I am actually using Rgui on Windows...
>>>>
>>>>What can I do?
>>>>
>>>>There is no way to programmatically clear screen?
>>>>
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From pauljohn32 at gmail.com  Sun Feb 19 20:53:47 2006
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sun, 19 Feb 2006 13:53:47 -0600
Subject: [R] segmentation fault with Hmisc areg.boot()
In-Reply-To: <43F4D72E.2000209@vanderbilt.edu>
References: <BC8A77DD-B116-41E0-A14F-5E0AD78B5087@muohio.edu>
	<43F4D72E.2000209@vanderbilt.edu>
Message-ID: <13e802630602191153s7390dbddmd6602d7b2d8c9686@mail.gmail.com>

On 2/16/06, Frank E Harrell Jr <f.harrell at vanderbilt.edu> wrote:
> >
> > Hank Stevens
> >
> > The following is taken from the example in the areg.boot
> > documentation, run inside Aquamacs Emacs:
> >
> >  > set.seed(171)  # to be able to reproduce example
> >  > x1 <- rnorm(200)
> >  > x2 <- runif(200)  # a variable that is really unrelated to y]
> >  > x3 <- factor(sample(c('cat','dog','cow'), 200,TRUE))  # also
> > unrelated to y
> >  > y  <- exp(x1 + rnorm(200)/3)
> >  > f  <- areg.boot(y ~ x1 + x2 + x3, B=40)
>
> Works fine on debian linux with same versions
>
> Frank


Works fine in Fedora Core 4 with R -2.2

in case more tests help to point finger at problematic OS

Paul Johnson


--
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From spencer.graves at pdf.com  Sun Feb 19 21:07:59 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 19 Feb 2006 12:07:59 -0800
Subject: [R] MANOVA: how do I read off within and between Sum-of-Squares
 info from the manova result?
In-Reply-To: <b1f16d9d0602160138q1bb2a477t4c53c35cf518cf3e@mail.gmail.com>
References: <b1f16d9d0602160138q1bb2a477t4c53c35cf518cf3e@mail.gmail.com>
Message-ID: <43F8D01F.30901@pdf.com>

	  1.  You did NOT provide an example, so I don't know if the following 
example will help.  I got it by following ?manova to "?summary.manova".

      tear <- c(6.5, 6.2, 5.8, 6.5, 6.5, 6.9, 7.2, 6.9, 6.1, 6.3,
                6.7, 6.6, 7.2, 7.1, 6.8, 7.1, 7.0, 7.2, 7.5, 7.6)
      gloss <- c(9.5, 9.9, 9.6, 9.6, 9.2, 9.1, 10.0, 9.9, 9.5, 9.4,
                 9.1, 9.3, 8.3, 8.4, 8.5, 9.2, 8.8, 9.7, 10.1, 9.2)
      opacity <- c(4.4, 6.4, 3.0, 4.1, 0.8, 5.7, 2.0, 3.9, 1.9, 5.7,
                   2.8, 4.1, 3.8, 1.6, 3.4, 8.4, 5.2, 6.9, 2.7, 1.9)
      Y <- cbind(tear, gloss, opacity)
      rate <- factor(gl(2,10), labels=c("Low", "High"))
      additive <- factor(gl(2, 5, len=20), labels=c("Low", "High"))

      fit <- manova(Y ~ rate * additive)
      summary.aov(fit)           # univariate ANOVA tables
      summary(fit, test="Wilks") # ANOVA table of Wilks' lambda

	  2.  To proceed further, I tried the following:

 > class(fit)
[1] "manova" "maov"   "aov"    "mlm"    "lm"

	  Inspired by this, I then tried the following:

 > ?methods
 > methods(class="manova")
[1] summary.manova
 > methods(class="maov")
no methods were found
 > methods(class="mlm")
  [1] add1.mlm*         anova.mlm         deviance.mlm*     drop1.mlm* 

  [5] estVar.mlm*       mauchly.test.mlm* plot.mlm          predict.mlm 

  [9] SSD.mlm*          summary.mlm       vcov.mlm*

    Non-visible functions are asterisked

	  This led me further:

 > fit
Call:
    manova(Y ~ rate * additive)

Terms:
                    rate additive rate:additive Residuals
tear             1.7405   0.7605        0.0005    1.7640
gloss            1.3005   0.6125        0.5445    2.6280
opacity          0.4205   4.9005        3.9605   64.9240
Deg. of Freedom       1        1             1        16

Residual standard error: 0.3320392 0.4052777 2.014386
Estimated effects may be unbalanced
 > estVar(fit)
              tear    gloss   opacity
tear     0.110250  0.00125 -0.191875
gloss    0.001250  0.16425 -0.034500
opacity -0.191875 -0.03450  4.057750
 > SSD(fit)
$SSD
           tear  gloss opacity
tear     1.764  0.020  -3.070
gloss    0.020  2.628  -0.552
opacity -3.070 -0.552  64.924

$call
manova(Y ~ rate * additive)

$df
[1] 16

	  If this does NOT answer your question, PLEASE do read the posting 
guide! (www.R-project.org/posting-guide.html) and send us another post. 
  Realize, however, that in r-help as in just about any other aspect of 
human existence, people who are more clear about what they want are 
generally more successful.

	  3.  I used MANOVA on a project 30 years ago.  From that and 
subsequent experience, it seem to me that MANOVA is a highly specialized 
tool for which the required assumptions are rarely met.  Most people are 
much better off making lots of plots to possible models and then 
residuals from model fits, etc.  In rare cases, MANOVA doubtless can 
find effects that can not be seen in the component univariate analyses. 
  However, I have yet to encounter such a case.  If I had time to pursue 
a modeling effort beyond simple univeriate analyses, I thing I would 
move to "structural equation modeling" (package sem) or "partial least 
squares".  "RSiteSearch" can lead you to R capabilities for these.  (See 
also "http://finzi.psych.upenn.edu/R/Rhelp02a/archive/29119.html").

	  hope this helps.
	  spencer graves	

Michael wrote:

> Hi all,
> 
> I am experimenting the function "manova" in R.
> 
> I tried it on a few data sets, but I did not understand the result:
> 
> I used "summary(manova_result)"
> 
> and "summary(manova_result, test='Wilks')"
> 
> and they gave a bunch of numbers...
> 
> But I need the Sum-of-Squares of BETWEEN and WITHIN matrices...
> 
> How do I read off from the R's manova results?
> 
> Any good example code and results?
> 
> Also, I am looking for tutorials/notes on how to compute those BETWEEN and
> WITHIN Sum-of-Squares myself...
> 
> I did not find any good discussion about MANOVA on the quite a few books I
> have on my hand currently...
> 
> Any books/referecnes/notes/tutorials give clear formulas on how to compute
> the MANOVAs?
> 
> Thanks a lot!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From pauljohn32 at gmail.com  Sun Feb 19 21:16:53 2006
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sun, 19 Feb 2006 14:16:53 -0600
Subject: [R] Converting factors back to numbers. Trouble with SPSS import
	data
Message-ID: <13e802630602191216w1d3d927cg23eee88ec690836c@mail.gmail.com>

I'm using Fedora Core 4, R-2.2.

The basic question is: can one recover the numerical values used in
SPSS after importing data into R with read.spss from the foreign
library?  Here's why I ask.

My colleague sent an SPSS data set. I must replicate some results she
calculated in SPSS and one problem is that the numbers used in SPSS
for variable values are not easily recovered in R.

I'm comparing 2 imported datasets, "eldat" (read.spss with No
convert-to-factors) and
"eldatfac" (read.spss with convert-to-factors)

If I bring in the data without conversion to factors:

library(foreign)
eldat <- read.spss("18CitySCBSsorted.sav", use.value.labels=F,
                        to.data.frame=T)

I can see the variable HAPPY is coded 0, 1, 2, 3.  Those are the
numbers that SPSS
uses as contrast values when it runs a regression with HAPPY.

In contrast,  allow R to translate the variables with a few value
labels into factors.

library(foreign)
eldatfac <- read.spss("18CitySCBSsorted.sav",
max.value.labels=7,to.data.frame=T)

Consider the first 50 observations on the variable HAPPY

> f<- eldatfac$HAPPY[1:50]
> f
 [1] Happy          Happy          Very happy     Happy          Very happy
 [6] Very happy     Happy          Very happy     Happy          Very happy
[11] Happy          Happy          Not very happy Very happy     Very happy
[16] Happy          Happy          Very happy     Happy          Happy
[21] Not very happy Happy          Happy          Very happy     Happy
[26] Happy          Happy          Happy          Happy          Happy
[31] Happy          Happy          Happy          Happy          Happy
[36] Happy          Very happy     Very happy     Happy          Very happy
[41] Very happy     Very happy     Happy          Very happy     Very happy
[46] Happy          Happy          Happy          Very happy     Very happy
6 Levels: Not happy at all Not very happy Happy Very happy ... Refused

> levels(f)
[1] "Not happy at all" "Not very happy"   "Happy"            "Very happy"
[5] "Don't know"       "Refused"


I need the numerical values back in order to have a regression like
SPSS.  Isn't this what ?factor says one ought to do? Why are these all
missing?

> as.numeric(levels(f))[f]
 [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA


> as.numeric(f)
 [1] 3 3 4 3 4 4 3 4 3 4 3 3 2 4 4 3 3 4 3 3 2 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 4 4
[39] 3 4 4 4 3 4 4 3 3 3 4 4

Comparing against the "as.numeric" output from the unconverted factor,
I can see the levels are just one digit different.

> g <- eldat$HAPPY[1:50]
> as.numeric(g)
 [1] 2 2 3 2 3 3 2 3 2 3 2 2 1 3 3 2 2 3 2 2 1 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 3 3
[39] 2 3 3 3 2 3 3 2 2 2 3 3

I'm more worried about the kinds of variables that are coded
irregularly 1, 3, 7, 11 in the SPSS scheme.

--
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From will at hss.caltech.edu  Sun Feb 19 23:32:58 2006
From: will at hss.caltech.edu (Will Terry)
Date: Sun, 19 Feb 2006 14:32:58 -0800
Subject: [R] Importing data
Message-ID: <DA6DD4A1-2BEB-4DDB-A99F-F434B46345D0@hss.caltech.edu>

Hi all,

I'm a new R user trying to import some tab delimited data. It's not  
clear to me why the following code won't work on my Mac:

 > read.delim("asphodel:Users:will:Desktop:Math_282:hw2:hw2- 
data1.txt",header=TRUE)
Error in file(file, "r") : unable to open connection
In addition: Warning message:
cannot open file `asphodel:Users:will:Desktop:Math_282:hw2:hw1- 
data1.txt'

Is this the correct syntax for specifying the path? Thanks!

-Will



From h.wickham at gmail.com  Sun Feb 19 23:34:17 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Sun, 19 Feb 2006 16:34:17 -0600
Subject: [R] MANOVA: how do I read off within and between Sum-of-Squares
	info from the manova result?
In-Reply-To: <43F8D01F.30901@pdf.com>
References: <b1f16d9d0602160138q1bb2a477t4c53c35cf518cf3e@mail.gmail.com>
	<43F8D01F.30901@pdf.com>
Message-ID: <f8e6ff050602191434m2b13763dw7db212aa05ee1a3d@mail.gmail.com>

>   However, I have yet to encounter such a case.  If I had time to pursue
> a modeling effort beyond simple univeriate analyses, I thing I would
> move to "structural equation modeling" (package sem) or "partial least
> squares".  "RSiteSearch" can lead you to R capabilities for these.  (See
> also "http://finzi.psych.upenn.edu/R/Rhelp02a/archive/29119.html").

Another option is to look at your data in their original high
dimensional space, eg., with the grand tour in GGobi
(http://www.ggobi.org, http://ggobi.org/demos/tour.html).  MANOVA
tests the hypothesis that the means are different (assuming
multivariate normality and a common variance-covariance matrix).  By
looking at your data you can investigate more interesting hypotheses -
are the groups overlapping? is there a linear or non-linear separation
between the groups? are the responses highly correlated?

Hadley



From p.dalgaard at biostat.ku.dk  Sun Feb 19 23:41:54 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Feb 2006 23:41:54 +0100
Subject: [R] Importing data
In-Reply-To: <DA6DD4A1-2BEB-4DDB-A99F-F434B46345D0@hss.caltech.edu>
References: <DA6DD4A1-2BEB-4DDB-A99F-F434B46345D0@hss.caltech.edu>
Message-ID: <x2vevbotsd.fsf@turmalin.kubism.ku.dk>

Will Terry <will at hss.caltech.edu> writes:

> Hi all,
> 
> I'm a new R user trying to import some tab delimited data. It's not  
> clear to me why the following code won't work on my Mac:
> 
>  > read.delim("asphodel:Users:will:Desktop:Math_282:hw2:hw2- 
> data1.txt",header=TRUE)
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file `asphodel:Users:will:Desktop:Math_282:hw2:hw1- 
> data1.txt'
> 
> Is this the correct syntax for specifying the path? Thanks!

Hmm, wouldn't know, but it the most common problem with file paths are
misspellings, and you have it spelled in two different ways there...

Does file.choose do something useful on the Mac?

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From rbaer at atsu.edu  Sun Feb 19 23:44:24 2006
From: rbaer at atsu.edu (Robert W. Baer, Ph.D.)
Date: Sun, 19 Feb 2006 16:44:24 -0600
Subject: [R] Converting factors back to numbers. Trouble with SPSS
	importdata
References: <13e802630602191216w1d3d927cg23eee88ec690836c@mail.gmail.com>
Message-ID: <002f01c635a6$08cd3fb0$6601a8c0@ALKAID>

Quoted directly from the FAQ (although granted I need to look this up over 
and over, myself.  Would that it had a easily remembered wrapper function):
7.10 How do I convert factors to numeric?
It may happen that when reading numeric data into R (usually, when reading 
in a file), they come in as factors. If f is such a factor object, you can 
use

     as.numeric(as.character(f))
to get the numbers back. More efficient, but harder to remember, is

     as.numeric(levels(f))[as.integer(f)]
In any case, do not call as.numeric() or their likes directly for the task 
at hand (as as.numeric() or unclass() give the internal codes).

----- Original Message ----- 
From: "Paul Johnson" <pauljohn32 at gmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Sunday, February 19, 2006 2:16 PM
Subject: [R] Converting factors back to numbers. Trouble with SPSS 
importdata


> I'm using Fedora Core 4, R-2.2.
>
> The basic question is: can one recover the numerical values used in
> SPSS after importing data into R with read.spss from the foreign
> library?  Here's why I ask.
>
> My colleague sent an SPSS data set. I must replicate some results she
> calculated in SPSS and one problem is that the numbers used in SPSS
> for variable values are not easily recovered in R.
>
> I'm comparing 2 imported datasets, "eldat" (read.spss with No
> convert-to-factors) and
> "eldatfac" (read.spss with convert-to-factors)
>
> If I bring in the data without conversion to factors:
>
> library(foreign)
> eldat <- read.spss("18CitySCBSsorted.sav", use.value.labels=F,
>                        to.data.frame=T)
>
> I can see the variable HAPPY is coded 0, 1, 2, 3.  Those are the
> numbers that SPSS
> uses as contrast values when it runs a regression with HAPPY.
>
> In contrast,  allow R to translate the variables with a few value
> labels into factors.
>
> library(foreign)
> eldatfac <- read.spss("18CitySCBSsorted.sav",
> max.value.labels=7,to.data.frame=T)
>
> Consider the first 50 observations on the variable HAPPY
>
>> f<- eldatfac$HAPPY[1:50]
>> f
> [1] Happy          Happy          Very happy     Happy          Very happy
> [6] Very happy     Happy          Very happy     Happy          Very happy
> [11] Happy          Happy          Not very happy Very happy     Very 
> happy
> [16] Happy          Happy          Very happy     Happy          Happy
> [21] Not very happy Happy          Happy          Very happy     Happy
> [26] Happy          Happy          Happy          Happy          Happy
> [31] Happy          Happy          Happy          Happy          Happy
> [36] Happy          Very happy     Very happy     Happy          Very 
> happy
> [41] Very happy     Very happy     Happy          Very happy     Very 
> happy
> [46] Happy          Happy          Happy          Very happy     Very 
> happy
> 6 Levels: Not happy at all Not very happy Happy Very happy ... Refused
>
>> levels(f)
> [1] "Not happy at all" "Not very happy"   "Happy"            "Very happy"
> [5] "Don't know"       "Refused"
>
>
> I need the numerical values back in order to have a regression like
> SPSS.  Isn't this what ?factor says one ought to do? Why are these all
> missing?
>
>> as.numeric(levels(f))[f]
> [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA 
> NA NA
> [26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA 
> NA NA
>
>
>> as.numeric(f)
> [1] 3 3 4 3 4 4 3 4 3 4 3 3 2 4 4 3 3 4 3 3 2 3 3 4 3 3 3 3 3 3 3 3 3 3 3 
> 3 4 4
> [39] 3 4 4 4 3 4 4 3 3 3 4 4
>
> Comparing against the "as.numeric" output from the unconverted factor,
> I can see the levels are just one digit different.
>
>> g <- eldat$HAPPY[1:50]
>> as.numeric(g)
> [1] 2 2 3 2 3 3 2 3 2 3 2 2 1 3 3 2 2 3 2 2 1 2 2 3 2 2 2 2 2 2 2 2 2 2 2 
> 2 3 3
> [39] 2 3 3 3 2 3 3 2 2 2 3 3
>
> I'm more worried about the kinds of variables that are coded
> irregularly 1, 3, 7, 11 in the SPSS scheme.
>
> --
> Paul E. Johnson
> Professor, Political Science
> 1541 Lilac Lane, Room 504
> University of Kansas
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From edd at debian.org  Mon Feb 20 00:49:42 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 19 Feb 2006 17:49:42 -0600
Subject: [R] Linux Distribution Choice
In-Reply-To: <2c75873c0602190759m3518e5b5p@mail.gmail.com>
References: <2c75873c0602190759m3518e5b5p@mail.gmail.com>
Message-ID: <17401.1046.491879.11700@basebud.nulle.part>


Graham,

On 19 February 2006 at 15:59, Graham Smith wrote:
| I am making some tentative steps into using Linux (Mandriva at the moment)
| and notice that not all the Linux binaries on CRAN are the latest release.
| 
| As R (plus Grass) will be key programs for me on Linux, is there a preferred
| Linux distribution that people in the R communiuty use?

Picking your preferred distribution is a fairly complex undertaking that will
invariably reflect a lot of your personal preferences.  Just like we may all
pick a different desk, chair or desk lamp for our work environment, we also
often end up with different computing choices. [1]

That said, if you are looking for R and Grass pre-built you could consider
either Debian, or the Ubuntu/Kubuntu derivatives.  We work fairly hard at
keeping the packages in Debian timely, and you'd get R and some 50 or so CRAN
packages already prebuilt and ready to use, as well as goodies like ESS,
Ggobi and more.  Likewise, my personal Quantian project may well be unique in
containing all that plus essentially all of CRAN and BioConductor (and lots
more) in a single DVD.

But at the end of the day you need to decide what you are comfortable with
installing and administrating. If you have friends or colleagues that use a
particular flavour then that may be reason enough to go with that flavour.
Finally, R and Grass don't care and you can always carry your scripts over to
another variant.

Hth, Dirk


[1] Provided they all run an Emacs flavour and ESS. Just kidding.

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison



From asaguiar at spsconsultoria.com  Mon Feb 20 01:30:00 2006
From: asaguiar at spsconsultoria.com (Alexandre Santos Aguiar)
Date: Sun, 19 Feb 2006 21:30:00 -0300
Subject: [R] Linux Distribution Choice
In-Reply-To: <17401.1046.491879.11700@basebud.nulle.part>
References: <2c75873c0602190759m3518e5b5p@mail.gmail.com>
	<17401.1046.491879.11700@basebud.nulle.part>
Message-ID: <200602192130.03649.asaguiar@spsconsultoria.com>

Em Dom 19 Fev 2006 20:49, Dirk Eddelbuettel escreveu:
> Likewise, my personal Quantian project may well be
> unique in containing all that plus essentially all of CRAN and BioConductor
> (and lots more) in a single DVD.

Quantian is a great job. I have appreciated it a lot.

However, Linux is far more flexible than the large number of distributions. 
They are good starting points. The real power is that you can become (at 
least partially) independent of distributions by compiling software by your 
own, extending and upgrading far beyond the support teams go.

For instance, I am using rigth now an old Conectiva 10 in which packaged R was 
version 1.9 and no upgrades were published by support. My current R 
installation is version 2.2.1. It compiled and runs smoothly. :-)
Not to mention some other 50+ pieces of software that did not exist in the 
original distribution.

Regards,

-- 

          Alexandre Santos Aguiar, MD



From pauljohn32 at gmail.com  Mon Feb 20 01:53:42 2006
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sun, 19 Feb 2006 18:53:42 -0600
Subject: [R] Converting factors back to numbers. Trouble with SPSS
	importdata
In-Reply-To: <002f01c635a6$08cd3fb0$6601a8c0@ALKAID>
References: <13e802630602191216w1d3d927cg23eee88ec690836c@mail.gmail.com>
	<002f01c635a6$08cd3fb0$6601a8c0@ALKAID>
Message-ID: <13e802630602191653l51ac5a93p473f818c16037e8c@mail.gmail.com>

On 2/19/06, Robert W. Baer, Ph.D. <rbaer at atsu.edu> wrote:
> Quoted directly from the FAQ (although granted I need to look this up over
> and over, myself.  Would that it had a easily remembered wrapper function):
> 7.10 How do I convert factors to numeric?
> It may happen that when reading numeric data into R (usually, when reading
> in a file), they come in as factors. If f is such a factor object, you can
> use
>
>      as.numeric(as.character(f))
> to get the numbers back. More efficient, but harder to remember, is
>
>      as.numeric(levels(f))[as.integer(f)]

I don't think I have that problem described in the FAQ.  I've had that
before, though.

Observe. Here's the original thing:

> eldatfac$HAPPY[1:10]
 [1] Happy      Happy      Very happy Happy      Very happy Very happy
 [7] Happy      Very happy Happy      Very happy
6 Levels: Not happy at all Not very happy Happy Very happy ... Refused

Here's the result of the first thing you cite from the FAQ

> as.numeric(as.character(eldatfac$HAPPY))[1:10]
 [1] NA NA NA NA NA NA NA NA NA NA
Warning message:
NAs introduced by coercion

Here's the second thing from the FAQ

> as.numeric(levels(eldatfac$HAPPY))[as.integer(eldatfac$HAPPY)]
 [1] NA NA NA NA NA NA NA NA NA NA
Warning message:
NAs introduced by coercion

What am I missing here?

--
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From pauljohn32 at gmail.com  Mon Feb 20 02:09:09 2006
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sun, 19 Feb 2006 19:09:09 -0600
Subject: [R] Linux Distribution Choice
In-Reply-To: <200602192130.03649.asaguiar@spsconsultoria.com>
References: <2c75873c0602190759m3518e5b5p@mail.gmail.com>
	<17401.1046.491879.11700@basebud.nulle.part>
	<200602192130.03649.asaguiar@spsconsultoria.com>
Message-ID: <13e802630602191709y4c749fc7g34cca9daa7eefff3@mail.gmail.com>

Fedora Core Linux is our preference here. The Fedora Extras system
keeps R (and just about everything else we need) up to date.  Much of
the Linux kernel and gcc development that goes on in the RedHat
company makes its way to Fedora more quickly than it does to other
distributions.

But the Debian-based distributions are nice too, don't take this as an
insult to them.

--
Paul E. Johnson
Professor, Political Science
1541 Lilac Lane, Room 504
University of Kansas



From murdoch at stats.uwo.ca  Mon Feb 20 02:12:25 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 19 Feb 2006 20:12:25 -0500
Subject: [R] Converting factors back to numbers. Trouble with
	SPSS	importdata
In-Reply-To: <13e802630602191653l51ac5a93p473f818c16037e8c@mail.gmail.com>
References: <13e802630602191216w1d3d927cg23eee88ec690836c@mail.gmail.com>	<002f01c635a6$08cd3fb0$6601a8c0@ALKAID>
	<13e802630602191653l51ac5a93p473f818c16037e8c@mail.gmail.com>
Message-ID: <43F91779.9000405@stats.uwo.ca>

On 2/19/2006 7:53 PM, Paul Johnson wrote:
> On 2/19/06, Robert W. Baer, Ph.D. <rbaer at atsu.edu> wrote:
>> Quoted directly from the FAQ (although granted I need to look this up over
>> and over, myself.  Would that it had a easily remembered wrapper function):
>> 7.10 How do I convert factors to numeric?
>> It may happen that when reading numeric data into R (usually, when reading
>> in a file), they come in as factors. If f is such a factor object, you can
>> use
>>
>>      as.numeric(as.character(f))
>> to get the numbers back. More efficient, but harder to remember, is
>>
>>      as.numeric(levels(f))[as.integer(f)]
> 
> I don't think I have that problem described in the FAQ.  I've had that
> before, though.
> 
> Observe. Here's the original thing:
> 
>> eldatfac$HAPPY[1:10]
>  [1] Happy      Happy      Very happy Happy      Very happy Very happy
>  [7] Happy      Very happy Happy      Very happy
> 6 Levels: Not happy at all Not very happy Happy Very happy ... Refused
> 
> Here's the result of the first thing you cite from the FAQ
> 
>> as.numeric(as.character(eldatfac$HAPPY))[1:10]
>  [1] NA NA NA NA NA NA NA NA NA NA
> Warning message:
> NAs introduced by coercion
> 
> Here's the second thing from the FAQ
> 
>> as.numeric(levels(eldatfac$HAPPY))[as.integer(eldatfac$HAPPY)]
>  [1] NA NA NA NA NA NA NA NA NA NA
> Warning message:
> NAs introduced by coercion
> 
> What am I missing here?

You're right, you have a different problem.  The FAQ is talking about 
the situation where the data in a file is numeric but is read as a 
factor, perhaps because of typos in one or two values.

In your case, levels(eldatfac$HAPPY) will tell you the correspondence 
between R's internal numbers and labels.  It's not the same as SPSS 
uses; as far as I know that coding is lost at this point.  You'll need 
to work out the coding you want to use and do it yourself.  For example, 
if the 1st 4 codes should be 0:3 and the others NA, you could use

encoding <- c(0:3, NA, NA)
encoding[as.integer(eldatfac$HAPPY)]

Duncan Murdoch



From tlumley at u.washington.edu  Mon Feb 20 02:16:20 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 19 Feb 2006 17:16:20 -0800 (PST)
Subject: [R] Converting factors back to numbers. Trouble with SPSS
 import data
In-Reply-To: <13e802630602191216w1d3d927cg23eee88ec690836c@mail.gmail.com>
Message-ID: <Pine.LNX.4.43.0602191716200.24876@hymn07.u.washington.edu>

On Sun, 19 Feb 2006, Paul Johnson wrote:

> I'm using Fedora Core 4, R-2.2.
>
> The basic question is: can one recover the numerical values used in
> SPSS after importing data into R with read.spss from the foreign
> library?  Here's why I ask.
>
> My colleague sent an SPSS data set. I must replicate some results she
> calculated in SPSS and one problem is that the numbers used in SPSS
> for variable values are not easily recovered in R.
>
> I'm comparing 2 imported datasets, "eldat" (read.spss with No
> convert-to-factors) and
> "eldatfac" (read.spss with convert-to-factors)
>
> If I bring in the data without conversion to factors:
>
> library(foreign)
> eldat <- read.spss("18CitySCBSsorted.sav", use.value.labels=F,
>                        to.data.frame=T)
>
> I can see the variable HAPPY is coded 0, 1, 2, 3.  Those are the
> numbers that SPSS
> uses as contrast values when it runs a regression with HAPPY.

So, bring in the data without conversion to factors.

Factors in R are not just labels for arbitrary numeric variables. They are a special type of variable for categorical data that happen to be implemented with the numbers 1,2,3,...

If that isn't what you want, don't use factors. read.spss will still return all the labels as attributes of the returned data frame.



> In contrast,  allow R to translate the variables with a few value
> labels into factors.
>
> library(foreign)
> eldatfac <- read.spss("18CitySCBSsorted.sav",
> max.value.labels=7,to.data.frame=T)
>
> Consider the first 50 observations on the variable HAPPY
>
>> f<- eldatfac$HAPPY[1:50]
>> f
> [1] Happy          Happy          Very happy     Happy          Very happy
> [6] Very happy     Happy          Very happy     Happy          Very happy
> [11] Happy          Happy          Not very happy Very happy     Very happy
> [16] Happy          Happy          Very happy     Happy          Happy
> [21] Not very happy Happy          Happy          Very happy     Happy
> [26] Happy          Happy          Happy          Happy          Happy
> [31] Happy          Happy          Happy          Happy          Happy
> [36] Happy          Very happy     Very happy     Happy          Very happy
> [41] Very happy     Very happy     Happy          Very happy     Very happy
> [46] Happy          Happy          Happy          Very happy     Very happy
> 6 Levels: Not happy at all Not very happy Happy Very happy ... Refused
>
>> levels(f)
> [1] "Not happy at all" "Not very happy"   "Happy"            "Very happy"
> [5] "Don't know"       "Refused"
>
>
> I need the numerical values back in order to have a regression like
> SPSS.  Isn't this what ?factor says one ought to do? Why are these all
> missing?
>
>> as.numeric(levels(f))[f]
> [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
> [26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NANA

No, this is not what ?factor says you should do.  This is what you do if your levels are numbers (in character form) and you want those numbers. "Happy" is not a number.


>> as.numeric(f)
> [1] 3 3 4 3 4 4 3 4 3 4 3 3 2 4 4 3 3 4 3 3 2 3 3 4 3 3 3 3 3 3 3 3 3 3 3 3 4 4
> [39] 3 4 4 4 3 4 4 3 3 3 4 4
>
> Comparing against the "as.numeric" output from the unconverted factor,
> I can see the levels are just one digit different.

Yes, because SPSS used the codes 0,1,2,3 and R uses 1,2,3,4.  You could just subtract 1 if you want the numbers to be smaller by 1.


>> g <- eldat$HAPPY[1:50]
>> as.numeric(g)
> [1] 2 2 3 2 3 3 2 3 2 3 2 2 1 3 3 2 2 3 2 2 1 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 3 3
> [39] 2 3 3 3 2 3 3 2 2 2 3 3
>
> I'm more worried about the kinds of variables that are coded
> irregularly 1, 3, 7, 11 in the SPSS scheme.
>

If you want to keep the numeric values, don't change them to factors. That's why there is an option.


     -thomas

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From butchar.2 at osu.edu  Mon Feb 20 02:56:22 2006
From: butchar.2 at osu.edu (jon butchar)
Date: Sun, 19 Feb 2006 20:56:22 -0500
Subject: [R] Linux Distribution Choice
In-Reply-To: <2c75873c0602190759m3518e5b5p@mail.gmail.com>
References: <2c75873c0602190759m3518e5b5p@mail.gmail.com>
Message-ID: <200602192056.23203.butchar.2@osu.edu>

On Sunday 19 February 2006 10:59, Graham Smith wrote:
> I am making some tentative steps into using Linux (Mandriva at the moment)
> and notice that not all the Linux binaries on CRAN are the latest release.
>
> As R (plus Grass) will be key programs for me on Linux, is there a
> preferred Linux distribution that people in the R communiuty use?
>
> Many thanks,
>
> Graham
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

As others stated, much depends on what you're comfortable using on a long-term 
basis and that can depend on several things.

With Linux, I gravitated towards Gentoo simply because the "portage" system 
made updating very easy.

You could also look into FreeBSD (http://www.freebsd.org).  It's a mature, 
very well put together operating system (also my personal choice), and the R 
port is usually kept up to date.

Best of luck,

jon



From yixiong_us at yahoo.com  Mon Feb 20 03:05:10 2006
From: yixiong_us at yahoo.com (Yi-Xiong Zhou)
Date: Sun, 19 Feb 2006 18:05:10 -0800 (PST)
Subject: [R] sqlSave
Message-ID: <20060220020510.91865.qmail@web31105.mail.mud.yahoo.com>

Hi, 

I am having trouble to write/create a table, which has
a date field. I want to create a stock price table,
which has fields of ticker, date, price. First, I
created such a table in Microsoft Access with a few
rows inputs. Using sqlQuery, I found that the date
field was retrieved as POSIXct value. Then I made a
data.frame with POSIXct as the data type for dates.
However, I received the following errors when I was
executing the sqlSave:

> price = data.frame(ticker=rep("FMDEX",5))
> price$date=c(as.POSIXct("2003-1-1"),
as.POSIXct("2003-1-2"), as.POSIXct("2003-1-3"),
as.POSIXct("2003-1-4"), as.POSIXct("2003-1-5"))
> price$price=1:5
> price
  ticker       date price
1  FMDEX 2003-01-01     1
2  FMDEX 2003-01-02     2
3  FMDEX 2003-01-03     3
4  FMDEX 2003-01-04     4
5  FMDEX 2003-01-05     5
> sqlSave(h, price, rownames=F)
Error in sqlSave(h, price, rownames = F) : 
        [RODBC] ERROR: Could not SQLExecDirect
37000 -3553 [Microsoft][ODBC Microsoft Access Driver]
Syntax error in field definition.


I am using R2.2.1 with RODBC library, on a Dell P5
computer with winXP Pro and office 2003. 

Thanks for your helps. 

Sean



From jhorn at bu.edu  Mon Feb 20 03:56:15 2006
From: jhorn at bu.edu (Jason Horn)
Date: Sun, 19 Feb 2006 21:56:15 -0500
Subject: [R] RMySQL Error Messages, crashing R
Message-ID: <E586A268-8D74-46C2-9169-171171D4F9A5@bu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060219/40c4bf8f/attachment.pl

From mingyufeng at gmail.com  Mon Feb 20 04:24:35 2006
From: mingyufeng at gmail.com (Mingyu Feng)
Date: Sun, 19 Feb 2006 22:24:35 -0500
Subject: [R] need help on nlme()
Message-ID: <9caad71a0602191924p7e10768ev4b4313d06ec3ba87@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060219/447e6be2/attachment.pl

From krcabrer at epm.net.co  Mon Feb 20 05:03:52 2006
From: krcabrer at epm.net.co (Kenneth Cabrera)
Date: Sun, 19 Feb 2006 23:03:52 -0500
Subject: [R] Linux Distribution Choice
In-Reply-To: <2c75873c0602190759m3518e5b5p@mail.gmail.com>
References: <2c75873c0602190759m3518e5b5p@mail.gmail.com>
Message-ID: <43F93FA8.7080000@epm.net.co>

Here we use Scientific Linux Distribution 4.2 
(https://www.scientificlinux.org/ ), that is based on RHEL4.
In this platform we both have R(2.2.1.) and GRASS(6.0.2) working.

Graham Smith wrote:

>I am making some tentative steps into using Linux (Mandriva at the moment)
>and notice that not all the Linux binaries on CRAN are the latest release.
>
>As R (plus Grass) will be key programs for me on Linux, is there a preferred
>Linux distribution that people in the R communiuty use?
>
>Many thanks,
>
>Graham
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>

From matgopa1 at umbc.edu  Mon Feb 20 06:29:51 2006
From: matgopa1 at umbc.edu (matgopa1@umbc.edu)
Date: Mon, 20 Feb 2006 00:29:51 -0500 (EST)
Subject: [R] formatting results from a function argument
Message-ID: <2149.71.248.16.181.1140413391.squirrel@71.248.16.181>

Hello all,

I have a simple function which calculates summary statistics of a dataset
in terms of a factor (say area).

> x = data.frame(Area = c(rep("cleanup", 5), rep("ref", 5)), TcCB =
c(rnorm(5)+2, rnorm(5)));x
      Area       TcCB
1  cleanup  2.5829747
2  cleanup  2.6796868
3  cleanup  2.5437094
4  cleanup  2.8453616
5  cleanup  1.1789683
6      ref  1.0140391
7      ref -0.8433729
8      ref  0.6512422
9      ref  0.2341083
10     ref -0.2688026
>
> summarystat<-function(x)
+ {
+ no.samples<-by(x,x$Area,function(x) length(x$TcCB))
+ mean<-by(x,x$Area,function(x) mean(x$TcCB))
+ quantile<-by(x,x$Area,function(x) summary(x$TcCB))
+ stdev<-by(x,x$Area,function(x) sd(x$TcCB))
+ final<-do.call("cbind",c(quantile,mean,stdev,no.samples))
+ return(final)
+ }
>
> test<-summarystat(x);test

        cleanup     ref cleanup       ref   cleanup      ref cleanup ref
Min.      1.179 -0.8434 2.36614 0.1574428 0.6737748 0.736001       5   5
1st Qu.   2.544 -0.2688 2.36614 0.1574428 0.6737748 0.736001       5   5
Median    2.583  0.2341 2.36614 0.1574428 0.6737748 0.736001       5   5
Mean      2.366  0.1574 2.36614 0.1574428 0.6737748 0.736001       5   5
3rd Qu.   2.680  0.6512 2.36614 0.1574428 0.6737748 0.736001       5   5
Max.      2.845  1.0140 2.36614 0.1574428 0.6737748 0.736001       5   5
>

Now the results are arranged as per quantile function.

When the results are printed, I would like to have the results for mean,
stdev, no.samples, quantiles one after the other with the function names
for the two factors namely cleanup and reference.  Can somebody help in
doing so? I did refer to a previous thread on formatting results from
function.  But my case is little different.

Moreover, i would like to know, if there is any R command which produces
this general summary statistics as above?

Thanks for your time.
Mathangi



From jholtman at gmail.com  Mon Feb 20 06:41:27 2006
From: jholtman at gmail.com (jim holtman)
Date: Mon, 20 Feb 2006 00:41:27 -0500
Subject: [R] formatting results from a function argument
In-Reply-To: <2149.71.248.16.181.1140413391.squirrel@71.248.16.181>
References: <2149.71.248.16.181.1140413391.squirrel@71.248.16.181>
Message-ID: <644e1f320602192141n24607cd7m272fdcfde9349d9c@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060220/fc0bd5b3/attachment.pl

From typhoon_zy at hotmail.com  Mon Feb 20 07:38:19 2006
From: typhoon_zy at hotmail.com (Feng Tai)
Date: Mon, 20 Feb 2006 00:38:19 -0600
Subject: [R] help on dyn.load()
Message-ID: <BAY111-F1EA21A0418E07139FFA0FE8FF0@phx.gbl>

Hi,

I used .C to call the C functions inside R. Everything works fine on the 
linux sever.

I installed cygwin on my windows xp x64 platform and used rcmd shlib xxx.c 
to compile. Everything works fine till now and xxx.dll is generated. But 
when I use dyn.load("xxx.dll") in R, it will open another R window and the 
original R window becomes "Not responding", nothing loaded in both R window. 
Anyone has similar experiences before. Thanks a lot.

BTW: I tried some other .dll files from the existed library. everything 
works ok. so I think maybe something wrong with my C code. But why it works 
fine on the linux server? Any guess or suggestion for this?

Feng



From Roger.Bivand at nhh.no  Mon Feb 20 08:13:49 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 20 Feb 2006 08:13:49 +0100 (CET)
Subject: [R] help on dyn.load()
In-Reply-To: <BAY111-F1EA21A0418E07139FFA0FE8FF0@phx.gbl>
Message-ID: <Pine.LNX.4.44.0602200806300.22406-100000@reclus.nhh.no>

On Mon, 20 Feb 2006, Feng Tai wrote:

> Hi,
> 
> I used .C to call the C functions inside R. Everything works fine on the 
> linux sever.
> 
> I installed cygwin on my windows xp x64 platform and used rcmd shlib xxx.c 
> to compile. Everything works fine till now and xxx.dll is generated. But 
> when I use dyn.load("xxx.dll") in R, it will open another R window and the 
> original R window becomes "Not responding", nothing loaded in both R window. 
> Anyone has similar experiences before. Thanks a lot.

It has been the case that you are recommended not to build shared library 
objects under Cygwin, but rather to follow the instructions in:

http://www.murdoch-sutherland.com/Rtools/

carefully - that is build under Windows using the chosen tools. The other 
.dll files you report functioning correctly were built in this way, so the 
easiest thing to do is to build in the same way. 

> 
> BTW: I tried some other .dll files from the existed library. everything 
> works ok. so I think maybe something wrong with my C code. But why it works 
> fine on the linux server? Any guess or suggestion for this?
> 
> Feng
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From detlef.steuer at hsu-hamburg.de  Mon Feb 20 08:44:46 2006
From: detlef.steuer at hsu-hamburg.de (Detlef Steuer)
Date: Mon, 20 Feb 2006 08:44:46 +0100
Subject: [R] Linux Distribution Choice
In-Reply-To: <17401.1046.491879.11700@basebud.nulle.part>
References: <2c75873c0602190759m3518e5b5p@mail.gmail.com>
	<17401.1046.491879.11700@basebud.nulle.part>
Message-ID: <20060220084446.063099fb.detlef.steuer@hsu-hamburg.de>

On Sun, 19 Feb 2006 17:49:42 -0600
Dirk Eddelbuettel <edd at debian.org> wrote:

> 
> Graham,
> 
> On 19 February 2006 at 15:59, Graham Smith wrote:
> | I am making some tentative steps into using Linux (Mandriva at the moment)
> | and notice that not all the Linux binaries on CRAN are the latest release.
> | 
> | As R (plus Grass) will be key programs for me on Linux, is there a preferred
> | Linux distribution that people in the R communiuty use?
> 
> Picking your preferred distribution is a fairly complex undertaking that will
> invariably reflect a lot of your personal preferences.  Just like we may all
> pick a different desk, chair or desk lamp for our work environment, we also
> often end up with different computing choices. [1]
> 
> That said, if you are looking for R and Grass pre-built you could consider
> either Debian, or the Ubuntu/Kubuntu derivatives.  We work fairly hard at
> keeping the packages in Debian timely, and you'd get R and some 50 or so CRAN
> packages already prebuilt and ready to use, as well as goodies like ESS,
> Ggobi and more.  Likewise, my personal Quantian project may well be unique in
> containing all that plus essentially all of CRAN and BioConductor (and lots
> more) in a single DVD.
> 
> But at the end of the day you need to decide what you are comfortable with
> installing and administrating. If you have friends or colleagues that use a
> particular flavour then that may be reason enough to go with that flavour.
> Finally, R and Grass don't care and you can always carry your scripts over to
> another variant.

I can only second Dirk's advise: his Quantian project is just great. But if you have coworkers around who already are specialized in one of the distros you can more than probably use their experience to get a quick start. 
Shameless self plug: From version 10.0 on there is even a yast repository for the SuSe an OpenSuse kind of linux :-)
(http://fawn.unibw-hamburg.de/~steuer/SL-10.0-OSS, soon on CRAN)

Have fun (and get the work done),
Detlef



> 
> Hth, Dirk
> 
> 
> [1] Provided they all run an Emacs flavour and ESS. Just kidding.
> 
> -- 
> Hell, there are no rules here - we're trying to accomplish something. 
>                                                   -- Thomas A. Edison
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Mon Feb 20 08:49:44 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 20 Feb 2006 07:49:44 +0000 (GMT)
Subject: [R] sqlSave [in RODBC]
In-Reply-To: <20060220020510.91865.qmail@web31105.mail.mud.yahoo.com>
References: <20060220020510.91865.qmail@web31105.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0602200739300.3917@gannet.stats.ox.ac.uk>

You can make use of the 'varTypes' argument of sqlSave() to specify the 
field types to be used.  You will have to do so if you are creating a 
table, as RODBC does not know what Access uses for dates (and POSIXct is 
appropriate for timestamps, not dates).

It is often easier to create the table in the DBMS (here Access) and then 
save to it, and you just haven't told us enough to know if that is what 
you are doing.

On Sun, 19 Feb 2006, Yi-Xiong Zhou wrote:

> Hi,
>
> I am having trouble to write/create a table, which has
> a date field. I want to create a stock price table,
> which has fields of ticker, date, price. First, I
> created such a table in Microsoft Access with a few
> rows inputs. Using sqlQuery, I found that the date
> field was retrieved as POSIXct value. Then I made a
> data.frame with POSIXct as the data type for dates.
> However, I received the following errors when I was
> executing the sqlSave:
>
>> price = data.frame(ticker=rep("FMDEX",5))
>> price$date=c(as.POSIXct("2003-1-1"),
> as.POSIXct("2003-1-2"), as.POSIXct("2003-1-3"),
> as.POSIXct("2003-1-4"), as.POSIXct("2003-1-5"))
>> price$price=1:5
>> price
>  ticker       date price
> 1  FMDEX 2003-01-01     1
> 2  FMDEX 2003-01-02     2
> 3  FMDEX 2003-01-03     3
> 4  FMDEX 2003-01-04     4
> 5  FMDEX 2003-01-05     5
>> sqlSave(h, price, rownames=F)
> Error in sqlSave(h, price, rownames = F) :
>        [RODBC] ERROR: Could not SQLExecDirect
> 37000 -3553 [Microsoft][ODBC Microsoft Access Driver]
> Syntax error in field definition.
>
>
> I am using R2.2.1 with RODBC library, on a Dell P5
> computer with winXP Pro and office 2003.
>
> Thanks for your helps.
>
> Sean
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Friedrich.Leisch at tuwien.ac.at  Mon Feb 20 09:42:38 2006
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Mon, 20 Feb 2006 09:42:38 +0100
Subject: [R] [Rd] Citation for R
In-Reply-To: <8BAEC5E546879B4FAA536200A292C614010A3925@AMEDMLNARMC135.amed.ds.army.mil>
References: <8BAEC5E546879B4FAA536200A292C614010A3925@AMEDMLNARMC135.amed.ds.army.mil>
Message-ID: <17401.33022.593889.783424@galadriel.ci.tuwien.ac.at>


That sound all very reasonable, so unless there are any protests I
will make the suggested changes on one of the next days.

Thanks a lot,
Fritz

>>>>> On Sun, 19 Feb 2006 11:05:33 -0500,
>>>>> White, Charles E WRAIR-Wash DC (WCEWD) wrote:

  > My subject line refers to a thread from June 2005 where I found
  > explanations from Uwe Ligges and Friedrich Leisch as to what is intended
  > by the R citation recommended within the software. Forgive me if I
  > missed some points within the thread but when I found myself circling
  > through messages I had already read, I stopped trying to follow it. I
  > understand and mostly agree with how the R citation is currently
  > suggested, though I would like to make two recommendations:

  > (1) Include the version number in the citation.

  > When editors realize I'm citing software, they want to know which
  > version I am citing. Since the document we are citing (called the
  > 'Reference Index' under the 'Manuals' link) actually includes the
  > version number anyway, I recommend that the R Development Core Team
  > expand the reference to include that information. A suggested format
  > follows:

  > R Development Core Team (2005). R: A language and environment for
  > statistical computing, reference index version 2.2.1. R Foundation for
  > Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0, URL
  > http://www.R-project.org.

  > (2) Help editors find the cited document by (a) explicitly providing a
  > citation link on the main web page for the R-project and (b) referencing
  > the cited document on the web site by the name under which it is cited.

  > Imagine the hapless editor following the R-project link expecting to
  > find a document called "R: A language and environment for statistical
  > computing." They then Google the ISBN number and find it referring to
  > multiple versions of the software. <grin> With regard to the citation
  > link, I recommend that it be called 'Citing R' and that it be placed on
  > the left side of the web page under the header called 'About R.' With
  > regard to the text on the page linked to 'Citing R,' I suggest something
  > like the following:

  > The R Development Core Team recommends the following citation for the
  > current major release of R:

  > R Development Core Team (2005). R: A language and environment for
  > statistical computing, reference index version 2.x.x. R Foundation for
  > Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0, URL
  > http://www.R-project.org.

  > With regard to the version number, 2 is the major release, the first x
  > is the minor release, and the last x is the patch level. The ISBN number
  > covers both the software and the tightly bundled reference index. This
  > number changes with each major release of R.
  > ...

  > Thanks for your time.

  > Chuck

  > Charles E. White, Senior Biostatistician, MS
  > Walter Reed Army Institute of Research
  > 503 Robert Grant Ave., Room 1w102
  > Silver Spring, MD 20910-1557
  > 301 319-9781
  > Personal/Professional Site:
  > http://users.starpower.net/cwhite571/professional/



From tastard at cict.fr  Mon Feb 20 09:52:06 2006
From: tastard at cict.fr (Emmanuelle TASTARD)
Date: Mon, 20 Feb 2006 09:52:06 +0100
Subject: [R] glmmPQL model selection
Message-ID: <003001c635fa$ed20e550$e2697882@st226edb>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060220/bb63b9bd/attachment.pl

From ronggui.huang at gmail.com  Mon Feb 20 10:53:53 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Mon, 20 Feb 2006 17:53:53 +0800
Subject: [R] need help on nlme()
In-Reply-To: <9caad71a0602191924p7e10768ev4b4313d06ec3ba87@mail.gmail.com>
References: <9caad71a0602191924p7e10768ev4b4313d06ec3ba87@mail.gmail.com>
Message-ID: <38b9f0350602200153m18da2f89m@mail.gmail.com>

I think nlme is not for logistic mixed effect model.
you should use glmmPQL in MASS or lmer in Matrix

2006/2/20, Mingyu Feng <mingyufeng at gmail.com>:
> Hello there,
>
> I am using nlme() to fit a logistic mixed effect model on our data.
> The outcome variable is binary.
> I got the error when I wanted to add a group factor to my model.
>
> My initial model is as below:
>
> model.a <- nlme(response~ 1/(1 + exp( -intercept- u0 - slope*TIME -
> u1*TIME)),
>                            + fixed=intercept+slope~1, random= u0+u1~1
> |studentID,
>                            + start=c(slope=.01, intercept=-1), data=log.data,
> method='ML')
>
> This works fine on my data. But when i update it by adding a group factor
> SKILLS,
> I got the error message:
> "Error in nlme.formula(response ~  1/(1 + exp( -intercept- u0 - slope*TIME
> :
>         starting values for the fixed component are not the correct length"
>
> The model is as below:
> model.a <- nlme(response~ 1/(1 + exp( -intercept- u0 - slope*TIME -
> u1*TIME)),
>                            + fixed=intercept+slope ~ SKILLS, random= u0+u1~1
> |studentID,
>                            + start=c(slope=.01, intercept=-1), data=log.data,
> method='ML')
>
> Does anybody see anything wrong with the "start" part of this model?
>
> Thanks a lot!!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--

Deparment of Sociology
Fudan University



From ripley at stats.ox.ac.uk  Mon Feb 20 10:57:09 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 20 Feb 2006 09:57:09 +0000 (GMT)
Subject: [R] sqlSave [in RODBC]
In-Reply-To: <Pine.LNX.4.64.0602200739300.3917@gannet.stats.ox.ac.uk>
References: <20060220020510.91865.qmail@web31105.mail.mud.yahoo.com>
	<Pine.LNX.4.64.0602200739300.3917@gannet.stats.ox.ac.uk>
Message-ID: <Pine.LNX.4.64.0602200951001.28038@gannet.stats.ox.ac.uk>

If you look in the file RODBC/tests.R you will see an example of using 
dates with Access.  As you will see from that file the incantations 
required are highly DBMS-dependent.

On Mon, 20 Feb 2006, Prof Brian Ripley wrote:

> You can make use of the 'varTypes' argument of sqlSave() to specify the
> field types to be used.  You will have to do so if you are creating a
> table, as RODBC does not know what Access uses for dates (and POSIXct is
> appropriate for timestamps, not dates).
>
> It is often easier to create the table in the DBMS (here Access) and then
> save to it, and you just haven't told us enough to know if that is what
> you are doing.
>
> On Sun, 19 Feb 2006, Yi-Xiong Zhou wrote:
>
>> Hi,
>>
>> I am having trouble to write/create a table, which has
>> a date field. I want to create a stock price table,
>> which has fields of ticker, date, price. First, I
>> created such a table in Microsoft Access with a few
>> rows inputs. Using sqlQuery, I found that the date
>> field was retrieved as POSIXct value. Then I made a
>> data.frame with POSIXct as the data type for dates.
>> However, I received the following errors when I was
>> executing the sqlSave:
>>
>>> price = data.frame(ticker=rep("FMDEX",5))
>>> price$date=c(as.POSIXct("2003-1-1"),
>> as.POSIXct("2003-1-2"), as.POSIXct("2003-1-3"),
>> as.POSIXct("2003-1-4"), as.POSIXct("2003-1-5"))
>>> price$price=1:5
>>> price
>>  ticker       date price
>> 1  FMDEX 2003-01-01     1
>> 2  FMDEX 2003-01-02     2
>> 3  FMDEX 2003-01-03     3
>> 4  FMDEX 2003-01-04     4
>> 5  FMDEX 2003-01-05     5
>>> sqlSave(h, price, rownames=F)
>> Error in sqlSave(h, price, rownames = F) :
>>        [RODBC] ERROR: Could not SQLExecDirect
>> 37000 -3553 [Microsoft][ODBC Microsoft Access Driver]
>> Syntax error in field definition.
>>
>>
>> I am using R2.2.1 with RODBC library, on a Dell P5
>> computer with winXP Pro and office 2003.
>>
>> Thanks for your helps.
>>
>> Sean
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From laura at env.leeds.ac.uk  Mon Feb 20 11:43:32 2006
From: laura at env.leeds.ac.uk (Laura Quinn)
Date: Mon, 20 Feb 2006 10:43:32 +0000 (GMT)
Subject: [R] Further rgl()/spheres3d() query
Message-ID: <Pine.LNX.4.44.0602201038110.17741-100000@gw.env.leeds.ac.uk>

Hi,

I am applying the following code to map pca loadings onto a 3d grid, my
problem is this - the output only plots the spheres in the requested color
(in this case "red") for the first argument. The sphere from the second
argument appear as flat dark circles. Also the text3d() command only seems
to work for a couple of the positions, with no text added in most cases.
Could anyone offer any suggestions?

 g.pca <- prcomp(RtG , retx = TRUE)
 scale <- 0.4
 bg3d("black")
 amp <- 6
 zlim <- amp*range(z)
 zlen <- (zlim[2] - zlim[1])*100
 colorlut <- terrain.colors(zlen) # height color lookup table
 col <- colorlut[ ((z*amp)-zlim[1])*100+1 ] # assign colors to heights
 surface3d(x,y,z*amp,color=col)
 for (i in 1:30) {
 for (i in 1) {
 pc <- g.pca$rotation[,i]
 pc.pos <- (pc > 0)
 if (any(pc.pos)) {
  spheres3d(xval[pc.pos],yval[pc.pos],6*zsamp[pc.pos],
     radius=scale*pc[pc.pos],color="red")
 }
 if (any(!pc.pos))  {
  spheres3d(xval[!pc.pos],yval[!pc.pos],6*zsamp[!pc.pos],
     radius=scale*pc[!pc.pos],color="blue")
 }
 points3d(sample[i,1],sample[i,2],sample[i,3],color="white",size=3.5,
          lit=TRUE)
 text3d(sample[i,1],sample[i,2],sample[i,3],i,adj=0)
 }}

Thanks in advance,
Laura

Laura Quinn
Institute of Atmospheric Science
School of Earth and Environment
University of Leeds
Leeds
LS2 9JT

tel: +44 113 343 1596
fax: +44 113 343 6716
mail: laura at env.leeds.ac.uk



From ripley at stats.ox.ac.uk  Mon Feb 20 11:52:10 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 20 Feb 2006 10:52:10 +0000 (GMT)
Subject: [R] need help on nlme()
In-Reply-To: <38b9f0350602200153m18da2f89m@mail.gmail.com>
References: <9caad71a0602191924p7e10768ev4b4313d06ec3ba87@mail.gmail.com>
	<38b9f0350602200153m18da2f89m@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602201047090.26027@gannet.stats.ox.ac.uk>

On Mon, 20 Feb 2006, ronggui wrote:

> I think nlme is not for logistic mixed effect model.
> you should use glmmPQL in MASS or lmer in Matrix

There are two senses of 'logistic mixed effect model'.  One is for a 
continuous response as given by SSlogis, and nlme is appropriate.  The 
other is a glm with a binomial (or binary) response, and nlme is 
inappropriate.

The issue here is that when the fixed includes an rhs, there are 
parameters for intercept and slope for each level of SKILLS, although they 
will be coded using contrasts.  So 2 starting values are not enough.

>
> 2006/2/20, Mingyu Feng <mingyufeng at gmail.com>:
>> Hello there,
>>
>> I am using nlme() to fit a logistic mixed effect model on our data.
>> The outcome variable is binary.
>> I got the error when I wanted to add a group factor to my model.
>>
>> My initial model is as below:
>>
>> model.a <- nlme(response~ 1/(1 + exp( -intercept- u0 - slope*TIME -
>> u1*TIME)),
>>                            + fixed=intercept+slope~1, random= u0+u1~1
>> |studentID,
>>                            + start=c(slope=.01, intercept=-1), data=log.data,
>> method='ML')
>>
>> This works fine on my data. But when i update it by adding a group factor
>> SKILLS,
>> I got the error message:
>> "Error in nlme.formula(response ~  1/(1 + exp( -intercept- u0 - slope*TIME
>> :
>>         starting values for the fixed component are not the correct length"
>>
>> The model is as below:
>> model.a <- nlme(response~ 1/(1 + exp( -intercept- u0 - slope*TIME -
>> u1*TIME)),
>>                            + fixed=intercept+slope ~ SKILLS, random= u0+u1~1
>> |studentID,
>>                            + start=c(slope=.01, intercept=-1), data=log.data,
>> method='ML')
>>
>> Does anybody see anything wrong with the "start" part of this model?
>>
>> Thanks a lot!!
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>
>
> --
> ????????????
> Deparment of Sociology
> Fudan University
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From gkkarthikeyann at gmail.com  Mon Feb 20 12:49:41 2006
From: gkkarthikeyann at gmail.com (karthi keyan)
Date: Mon, 20 Feb 2006 17:19:41 +0530
Subject: [R] how to get ROC for SVM
Message-ID: <8e3e33900602200349h31d7132aqdd94a907acc5d859@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060220/c5991e9d/attachment.pl

From murdoch at stats.uwo.ca  Mon Feb 20 13:01:22 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 20 Feb 2006 07:01:22 -0500
Subject: [R] Further rgl()/spheres3d() query
In-Reply-To: <Pine.LNX.4.44.0602201038110.17741-100000@gw.env.leeds.ac.uk>
References: <Pine.LNX.4.44.0602201038110.17741-100000@gw.env.leeds.ac.uk>
Message-ID: <43F9AF92.9000804@stats.uwo.ca>

On 2/20/2006 5:43 AM, Laura Quinn wrote:
> Hi,
> 
> I am applying the following code to map pca loadings onto a 3d grid, my
> problem is this - the output only plots the spheres in the requested color
> (in this case "red") for the first argument. The sphere from the second
> argument appear as flat dark circles. Also the text3d() command only seems
> to work for a couple of the positions, with no text added in most cases.
> Could anyone offer any suggestions?

A couple below, but you'll need to simplify your examples to get direct 
answers to your questions.
> 
>  g.pca <- prcomp(RtG , retx = TRUE)
>  scale <- 0.4
>  bg3d("black")
>  amp <- 6
>  zlim <- amp*range(z)

We can't execute this code, because we don't have z.

>  zlen <- (zlim[2] - zlim[1])*100
>  colorlut <- terrain.colors(zlen) # height color lookup table
>  col <- colorlut[ ((z*amp)-zlim[1])*100+1 ] # assign colors to heights
>  surface3d(x,y,z*amp,color=col)
>  for (i in 1:30) {
>  for (i in 1) {

This doesn't look right.  You're using i for two different purposes here.

Duncan Murdoch

>  pc <- g.pca$rotation[,i]
>  pc.pos <- (pc > 0)
>  if (any(pc.pos)) {
>   spheres3d(xval[pc.pos],yval[pc.pos],6*zsamp[pc.pos],
>      radius=scale*pc[pc.pos],color="red")
>  }
>  if (any(!pc.pos))  {
>   spheres3d(xval[!pc.pos],yval[!pc.pos],6*zsamp[!pc.pos],
>      radius=scale*pc[!pc.pos],color="blue")
>  }
>  points3d(sample[i,1],sample[i,2],sample[i,3],color="white",size=3.5,
>           lit=TRUE)
>  text3d(sample[i,1],sample[i,2],sample[i,3],i,adj=0)
>  }}
> 
> Thanks in advance,
> Laura
> 
> Laura Quinn
> Institute of Atmospheric Science
> School of Earth and Environment
> University of Leeds
> Leeds
> LS2 9JT
> 
> tel: +44 113 343 1596
> fax: +44 113 343 6716
> mail: laura at env.leeds.ac.uk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From r.hankin at noc.soton.ac.uk  Mon Feb 20 13:16:44 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Mon, 20 Feb 2006 12:16:44 +0000
Subject: [R] S4 classes in existing packages
In-Reply-To: <25D1C2585277D311B9A20000F6CCC71B0735BB07@DEFRAEX02>
References: <25D1C2585277D311B9A20000F6CCC71B0735BB07@DEFRAEX02>
Message-ID: <5D143AE3-E31C-4974-ACE0-DEA501EE4FC1@soc.soton.ac.uk>

Hi

Last year, there was a thread discussing S4 classes in existing  
packages.

I'm thinking of converting one of my packages from S3 to S4
and am having difficulty getting started.

I have "Programming with data" right here, and "S4 classes in 15  
pages, more
or less". I have also been looking at  the packages that are listed  
below...

...but what I really really want is a "hello, world!" package that
implements the track example in the Green Book and
illustrates best practice for S4 methods.

Has anyone coded up such a thing?





On 1 Nov 2005, at 08:33, Pfaff, Bernhard Dr. wrote:

>> Jeff Enos schrieb:
>>
>>> R-devel,
>>>
>>> I'm interested in looking at some examples of existing R packages  
>>> that
>>> rely heavily on S4 classes to get a feel for varying styles and
>>> package organization techniques.  Could you recommend any packages
>>> that might serve as a good starting point?
>>>
>>> Thanks in advance,
>>>
>>> Jeff
>>>
>>>
>> our packages distr, distrEx, distrSim, distrTEst and RandVar are  
>> based
>> on S4 classes and methods.
>
> As do many others, providing the variety of styles that the questioner
> asked for.  Those that are documented to do so include
>
> CoCo DBI IDPmisc Matrix RMySQL ROracle RSQLite RUnit SparseM aod  
> arules
> boolean coin colorspace copula deal dynamicGraph fBasics(etc)  
> flexclust
> flexmix giRaph gpclib its kappalab kernalb limma lme4 matlab monoProc
> orientlib partsm pixmap tuneR
>
> on CRAM, stats4 in the R sources and most (all?) of BioC.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>
> Hello Jeff,
>
> to amend the list: in the package "urca" S4-classes are implemented  
> too.
>
> Best,
> Bernhard
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r- 
> devel*****************************************************************
> Confidentiality Note: The information contained in this message,
> and any attachments, may contain confidential and/or privileged
> material. It is intended solely for the person(s) or entity to
> which it is addressed. Any review, retransmission, dissemination,
> or taking of any action in reliance upon this information by
> persons or entities other than the intended recipient(s) is
> prohibited. If you received this in error, please contact the
> sender and delete the material from any computer.
> *****************************************************************
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From ggrothendieck at gmail.com  Mon Feb 20 13:35:02 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 20 Feb 2006 07:35:02 -0500
Subject: [R] S4 classes in existing packages
In-Reply-To: <5D143AE3-E31C-4974-ACE0-DEA501EE4FC1@soc.soton.ac.uk>
References: <25D1C2585277D311B9A20000F6CCC71B0735BB07@DEFRAEX02>
	<5D143AE3-E31C-4974-ACE0-DEA501EE4FC1@soc.soton.ac.uk>
Message-ID: <971536df0602200435k70497c93ge48108fe17adf89a@mail.gmail.com>

There are some mentioned here:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/67430.html

On 2/20/06, Robin Hankin <r.hankin at noc.soton.ac.uk> wrote:
> Hi
>
> Last year, there was a thread discussing S4 classes in existing
> packages.
>
> I'm thinking of converting one of my packages from S3 to S4
> and am having difficulty getting started.
>
> I have "Programming with data" right here, and "S4 classes in 15
> pages, more
> or less". I have also been looking at  the packages that are listed
> below...
>
> ...but what I really really want is a "hello, world!" package that
> implements the track example in the Green Book and
> illustrates best practice for S4 methods.
>
> Has anyone coded up such a thing?
>
>
>
>
>
> On 1 Nov 2005, at 08:33, Pfaff, Bernhard Dr. wrote:
>
> >> Jeff Enos schrieb:
> >>
> >>> R-devel,
> >>>
> >>> I'm interested in looking at some examples of existing R packages
> >>> that
> >>> rely heavily on S4 classes to get a feel for varying styles and
> >>> package organization techniques.  Could you recommend any packages
> >>> that might serve as a good starting point?
> >>>
> >>> Thanks in advance,
> >>>
> >>> Jeff
> >>>
> >>>
> >> our packages distr, distrEx, distrSim, distrTEst and RandVar are
> >> based
> >> on S4 classes and methods.
> >
> > As do many others, providing the variety of styles that the questioner
> > asked for.  Those that are documented to do so include
> >
> > CoCo DBI IDPmisc Matrix RMySQL ROracle RSQLite RUnit SparseM aod
> > arules
> > boolean coin colorspace copula deal dynamicGraph fBasics(etc)
> > flexclust
> > flexmix giRaph gpclib its kappalab kernalb limma lme4 matlab monoProc
> > orientlib partsm pixmap tuneR
> >
> > on CRAM, stats4 in the R sources and most (all?) of BioC.
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> >
> > Hello Jeff,
> >
> > to amend the list: in the package "urca" S4-classes are implemented
> > too.
> >
> > Best,
> > Bernhard
> >
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-
> > devel*****************************************************************
> > Confidentiality Note: The information contained in this message,
> > and any attachments, may contain confidential and/or privileged
> > material. It is intended solely for the person(s) or entity to
> > which it is addressed. Any review, retransmission, dissemination,
> > or taking of any action in reliance upon this information by
> > persons or entities other than the intended recipient(s) is
> > prohibited. If you received this in error, please contact the
> > sender and delete the material from any computer.
> > *****************************************************************
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>  tel  023-8059-7743
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From myotisone at gmail.com  Mon Feb 20 13:36:44 2006
From: myotisone at gmail.com (Graham Smith)
Date: Mon, 20 Feb 2006 12:36:44 +0000
Subject: [R] Linux Distribution Choice
In-Reply-To: <2c75873c0602190759m3518e5b5p@mail.gmail.com>
References: <2c75873c0602190759m3518e5b5p@mail.gmail.com>
Message-ID: <2c75873c0602200436n3fbebcb6w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060220/9999c659/attachment.pl

From ggrothendieck at gmail.com  Mon Feb 20 13:42:08 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 20 Feb 2006 07:42:08 -0500
Subject: [R] formatting results from a function argument
In-Reply-To: <2149.71.248.16.181.1140413391.squirrel@71.248.16.181>
References: <2149.71.248.16.181.1140413391.squirrel@71.248.16.181>
Message-ID: <971536df0602200442u30977d21ob8d53f8965cb2ba4@mail.gmail.com>

Not sure I followed what it is you want but perhaps this will
help:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/67519.html

On 2/20/06, matgopa1 at umbc.edu <matgopa1 at umbc.edu> wrote:
> Hello all,
>
> I have a simple function which calculates summary statistics of a dataset
> in terms of a factor (say area).
>
> > x = data.frame(Area = c(rep("cleanup", 5), rep("ref", 5)), TcCB =
> c(rnorm(5)+2, rnorm(5)));x
>      Area       TcCB
> 1  cleanup  2.5829747
> 2  cleanup  2.6796868
> 3  cleanup  2.5437094
> 4  cleanup  2.8453616
> 5  cleanup  1.1789683
> 6      ref  1.0140391
> 7      ref -0.8433729
> 8      ref  0.6512422
> 9      ref  0.2341083
> 10     ref -0.2688026
> >
> > summarystat<-function(x)
> + {
> + no.samples<-by(x,x$Area,function(x) length(x$TcCB))
> + mean<-by(x,x$Area,function(x) mean(x$TcCB))
> + quantile<-by(x,x$Area,function(x) summary(x$TcCB))
> + stdev<-by(x,x$Area,function(x) sd(x$TcCB))
> + final<-do.call("cbind",c(quantile,mean,stdev,no.samples))
> + return(final)
> + }
> >
> > test<-summarystat(x);test
>
>        cleanup     ref cleanup       ref   cleanup      ref cleanup ref
> Min.      1.179 -0.8434 2.36614 0.1574428 0.6737748 0.736001       5   5
> 1st Qu.   2.544 -0.2688 2.36614 0.1574428 0.6737748 0.736001       5   5
> Median    2.583  0.2341 2.36614 0.1574428 0.6737748 0.736001       5   5
> Mean      2.366  0.1574 2.36614 0.1574428 0.6737748 0.736001       5   5
> 3rd Qu.   2.680  0.6512 2.36614 0.1574428 0.6737748 0.736001       5   5
> Max.      2.845  1.0140 2.36614 0.1574428 0.6737748 0.736001       5   5
> >
>
> Now the results are arranged as per quantile function.
>
> When the results are printed, I would like to have the results for mean,
> stdev, no.samples, quantiles one after the other with the function names
> for the two factors namely cleanup and reference.  Can somebody help in
> doing so? I did refer to a previous thread on formatting results from
> function.  But my case is little different.
>
> Moreover, i would like to know, if there is any R command which produces
> this general summary statistics as above?
>
> Thanks for your time.
> Mathangi
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From robin.smit at tno.nl  Mon Feb 20 14:05:14 2006
From: robin.smit at tno.nl (Smit, R. (Robin))
Date: Mon, 20 Feb 2006 14:05:14 +0100
Subject: [R] Matrix with p-values with reference to a correlation matrix
Message-ID: <2395774549BBDA40AC83BC9E6223FBFF99D057@MS-DT01VS01.tsn.tno.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060220/2e93d93b/attachment.pl

From jhorn at bu.edu  Mon Feb 20 14:09:49 2006
From: jhorn at bu.edu (Jason Horn)
Date: Mon, 20 Feb 2006 08:09:49 -0500
Subject: [R] RMySQL Error Messages, crashing R
In-Reply-To: <Pine.LNX.4.64.0602192017580.12132@springer.berkeley.edu>
References: <E586A268-8D74-46C2-9169-171171D4F9A5@bu.edu>
	<Pine.LNX.4.64.0602192017580.12132@springer.berkeley.edu>
Message-ID: <0E366731-895B-42DD-8E70-A9C7D0E66B05@bu.edu>

Phil,

Thanks for the tip.  I have tried rebuilding the RMySQL library, but  
it always fails.  When I run:

R CMD INSTALL --configure-args='--with-mysql-inc=/usr/local/mysql/ 
include --with-mysql-lib=/usr/local/mysql/lib' /Users/jason/Desktop/ 
RMySQL_0.5-7.tar.gz.tar

I get ...

gcc-3.3 -bundle -flat_namespace -undefined suppress -L/usr/local/lib - 
o RMySQL.so RS-DBI.o RS-MySQL.o -L/usr/local/mysql/lib -lmysqlclient - 
lz -lcc_dynamic -F/Library/Frameworks/R.framework/.. -framework R
ld: can't locate file for: -lcc_dynamic
make: *** [RMySQL.so] Error 1
ERROR: compilation failed for package 'RMySQL'

The MySQL that I have is 5.0.18 that I downloaded as a binary  
directly from mysql.com.  Is your mySQL installation from elsewhere?   
What do you mean "...that I installed through port."

It sounds like you have everything working.  What commands did you  
use to get mySQL 5 installed?  To get  RMySQL compiled?  Any help  
here is appreciated. I am heavily dependent on R working with mySQL  
for my project.

Thanks,

- Jason

On Feb 19, 2006, at 11:21 PM, Phil Spector wrote:

> Jason -
>     In order to get mysql5 to work with R.2.2 on Tiger, I had to  
> rebuild
> the RMySQL library against the mysql libraries that I installed  
> through port.
> (You didn't mention where you got your mysql from).  The problem I saw
> was that I kept seeing the warning message, and R wouldn't connect  
> to the database, but I'm pretty sure what you need to do is rebuild  
> the R library
> against the system libraries that you've currently got installed.
>
>                                        - Phil Spector
> 					 Statistical Computing Facility
> 					 Department of Statistics
> 					 UC Berkeley
> 					 spector at stat.berkeley.edu
>
>
> On Sun, 19 Feb 2006, Jason Horn wrote:
>
>> I am having trouble getting RMySQL working with R.  It did at one
>> point, work with an older 1.x version of R, but now with R2.2.1, I am
>> getting the following messages on my OS X 10.4.5 system:
>>
>> RS-DBI driver warning: (MySQL mismatch between compiled version
>> 4.0.24 and runtime version 4.1.14)
>>
>> if I then try to run any further db commands such as dbConnect, R
>> crashes with a bus error.  When I started getting this error, I was
>> using MySQL 5.  I have since removed that installation and instead
>> installed the older 4.0.24.  I still get the error message.  I have
>> also tried other versions of MySQL, but the error persists.  I have
>> also tried installing RMySQL from sources, but it makes no  
>> difference.
>>
>> Does anyone know what this error message means.  Are there any OS X
>> users that have with R 2.x working with RMySQL?
>>
>> Please help!
>>
>> - Jason
>>
>>
>> Jason Horn
>> Boston University Department of Biology
>> 5 Cumington Street  Boston, MA 02215
>>
>> jhorn at bu.edu
>> office: 617 353 6987
>> cell: 401 588 2766
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting- 
>> guide.html
>>
>



From christian.hoffmann at wsl.ch  Mon Feb 20 14:19:52 2006
From: christian.hoffmann at wsl.ch (Christian Hoffmann)
Date: Mon, 20 Feb 2006 14:19:52 +0100
Subject: [R] linear lists, insertion, deletion, traversal
Message-ID: <43F9C1F8.8010704@wsl.ch>

Hi,

Linear lists, as described e.g. by N.Wirth in "Algorithms and Data 
Structures", seem not to be implemented in S/R, and this with some good 
reason, I think.

Nevertheless I want to implement an algorithm using such linear lists. 
Does anybody have experience in this? I could not find any reference in 
R resources, also the Blue Book is mute here.

Thank you
Christian
-- 
Dr. Christian W. Hoffmann,
Swiss Federal Research Institute WSL
Mathematics + Statistical Computing
Zuercherstrasse 111
CH-8903 Birmensdorf, Switzerland

Tel +41-44-7392-277  (office)   -111(exchange)
Fax +41-44-7392-215  (fax)
christian.hoffmann at wsl.ch
http://www.wsl.ch/staff/christian.hoffmann

International Conference 5.-7.6.2006 Ekaterinburg Russia
"Climate changes and their impact on boreal and temperate forests"
http://ecoinf.uran.ru/conference/



From f.harrell at vanderbilt.edu  Mon Feb 20 14:19:45 2006
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Mon, 20 Feb 2006 07:19:45 -0600
Subject: [R] Matrix with p-values with reference to a correlation matrix
In-Reply-To: <2395774549BBDA40AC83BC9E6223FBFF99D057@MS-DT01VS01.tsn.tno.nl>
References: <2395774549BBDA40AC83BC9E6223FBFF99D057@MS-DT01VS01.tsn.tno.nl>
Message-ID: <43F9C1F1.2030108@vanderbilt.edu>

Smit, R. (Robin) wrote:
> Dear mailing list member
> 
>  
> 
> I have got the following question:
> 
> The function "cor.test(x1, x2)$p.value" computes the statistical
> significance of the correlation between vectors x1 and x2. 
> 
> However, I have got a data matrix with many variables. 
> 
> Instead of typing in all possible combinations, I was wondering if there
> is perhaps an R-function that produces a matrix showing the statistical
> significance (p-value) of each correlation (with a similar format as the
> correlation matrix).
> 
>  
> 
> Kind regards,
> Robin Smit

This was answered just a few days ago in r-help.  One way is

library(Hmisc)
rcorr(data matrix)

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From deshon at msu.edu  Mon Feb 20 15:57:02 2006
From: deshon at msu.edu (Rick DeShon)
Date: Mon, 20 Feb 2006 09:57:02 -0500
Subject: [R] Extracting variance components from lmer
Message-ID: <c3cb73d50602200657x591409e9x4f04cbdedfcdaff8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060220/b0ef55d3/attachment.pl

From dmedri at gmail.com  Mon Feb 20 16:26:53 2006
From: dmedri at gmail.com (Daniele Medri)
Date: Mon, 20 Feb 2006 16:26:53 +0100
Subject: [R] Group a dinamic number of vectors in a data.frame
Message-ID: <1140449213.24883.17.camel@localhost.localdomain>

Hi all,

I need to create a data.frame from a variable number of vectors.
The number of these vectors could change so I need a dinamic way to
group all in a data.frame. The number is length(abc).

e.g. vectors in my workspace

N1 <-c(1,2,3,4)
N2 <-c(1,2,3,4)
N3 <-c(1,2,3,4)
abc <-c(1,2,3)

the data.frame I want to create:

tcm <-data.frame(OneVector, TwoVector,  paste("N",1:length(abc)))

Obviously :) if I am here this approach doesn't work, so any kind of tip
is welcome.

Cheers
-- 
Daniele Medri



From dimitris.rizopoulos at med.kuleuven.be  Mon Feb 20 16:40:16 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Mon, 20 Feb 2006 16:40:16 +0100
Subject: [R] Group a dinamic number of vectors in a data.frame
References: <1140449213.24883.17.camel@localhost.localdomain>
Message-ID: <00c601c63633$f242e4a0$0540210a@www.domain>

one way is:

N1 <- rnorm(4)
N2 <- rnorm(4)
N3 <- rnorm(4)
N4 <- rnorm(4)
X1 <- LETTERS[1:4]
###################
nams <- c(paste("N", 1:4, sep = ""), "X1")
dat <- data.frame(lapply(nams, get))
names(dat) <- nams
dat

# check also
sapply(dat, data.class)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Daniele Medri" <dmedri at gmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, February 20, 2006 4:26 PM
Subject: [R] Group a dinamic number of vectors in a data.frame


> Hi all,
>
> I need to create a data.frame from a variable number of vectors.
> The number of these vectors could change so I need a dinamic way to
> group all in a data.frame. The number is length(abc).
>
> e.g. vectors in my workspace
>
> N1 <-c(1,2,3,4)
> N2 <-c(1,2,3,4)
> N3 <-c(1,2,3,4)
> abc <-c(1,2,3)
>
> the data.frame I want to create:
>
> tcm <-data.frame(OneVector, TwoVector,  paste("N",1:length(abc)))
>
> Obviously :) if I am here this approach doesn't work, so any kind of 
> tip
> is welcome.
>
> Cheers
> -- 
> Daniele Medri
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From bolker at ufl.edu  Mon Feb 20 16:38:42 2006
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 20 Feb 2006 15:38:42 +0000 (UTC)
Subject: [R] glmmPQL model selection
References: <003001c635fa$ed20e550$e2697882@st226edb>
Message-ID: <loom.20060220T162946-369@post.gmane.org>

Emmanuelle TASTARD <tastard <at> cict.fr> writes:

> 
> Hi,
> Im sorry, I know that it is a recurrent question but I have not been
> able to find the response in the Rhelp archives.
> I think my data require the use of the glmmPQL function but I do not
> know how to make the model selection. Since the AIC and log-likelihood
> are apparently meaningless, how can we select the parameters for a model
> and compare the models to find which one fits best the data?  

  I think your choices are (1) use the estimated standard errors/p-values
of the fixed effects to decide whether to include them in the model
or (2) if you really need likelihood-based tests, use lmer.  
(Model selection for variance parameters is a can of worms, see
Pinheiro and Bates.)  Also remember that *all* methods for this kind
of model are approximations, it's just a question of which ones are
more accurate (generally and in particular situations).

That's just my best guess, someone else may have better advice ...

   cheers
     Ben Bolker



From ggrothendieck at gmail.com  Mon Feb 20 16:46:17 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 20 Feb 2006 10:46:17 -0500
Subject: [R] Group a dinamic number of vectors in a data.frame
In-Reply-To: <1140449213.24883.17.camel@localhost.localdomain>
References: <1140449213.24883.17.camel@localhost.localdomain>
Message-ID: <971536df0602200746u3a6688fcoa81df12ca374ddc3@mail.gmail.com>

data.frame(OneVector, TwoVector,
  sapply(apropos("^N[0-9]*$"), get, simplify = FALSE))


On 2/20/06, Daniele Medri <dmedri at gmail.com> wrote:
> Hi all,
>
> I need to create a data.frame from a variable number of vectors.
> The number of these vectors could change so I need a dinamic way to
> group all in a data.frame. The number is length(abc).
>
> e.g. vectors in my workspace
>
> N1 <-c(1,2,3,4)
> N2 <-c(1,2,3,4)
> N3 <-c(1,2,3,4)
> abc <-c(1,2,3)
>
> the data.frame I want to create:
>
> tcm <-data.frame(OneVector, TwoVector,  paste("N",1:length(abc)))
>
> Obviously :) if I am here this approach doesn't work, so any kind of tip
> is welcome.
>
> Cheers
> --
> Daniele Medri
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From edgar.merkle at wichita.edu  Mon Feb 20 17:11:46 2006
From: edgar.merkle at wichita.edu (Ed Merkle)
Date: Mon, 20 Feb 2006 10:11:46 -0600
Subject: [R] Plots: displaying mathematical symbols in specific fonts
Message-ID: <6.2.3.4.2.20060220100146.021f3530@pop.service.ohio-state.edu>

Dear SavioRs,

I am doing some research where characters in different microsoft 
fonts serve as experimental stimuli.  Hence, in plot labels, I would 
like to display the characters in specific microsoft fonts.  I have 
figured out how to display letters and numbers, but I am having 
trouble with symbols such as capital delta.  Before I go further, I 
am using R 2.2.1 on Windows XP with everything in English.  I am 
trying to save my plot as a windows metafile.

To display different characters in verdana, for example, I first edit 
the Rdevga file so that it contains verdana.  I can then get verdana 
letters and numbers on the plot using a text() command.  Things 
within an expression() command, however, are not displayed in the 
desired font.  For example,

windows()
plot(rnorm(15),rnorm(15))
text(0,0,expression(Delta),font=10)

displays a capital delta, but it is not in font #10 within Rdevga.  I 
can get characters that have one of the first 255 ascii codes using 
chars8bit() in the sfsmisc package.  One example is the division sign:

text(0,0.2,chars8bit(247),font=10)

I have not been able to display other symbols in microsoft fonts, 
however.  Is this possible to do in R?  All replies are appreciated.

--
Ed Merkle, PhD
Department of Psychology
Wichita State University
Wichita, KS



From sangi at itc.utk.edu  Mon Feb 20 17:39:42 2006
From: sangi at itc.utk.edu (Sangeetha Swaminathan)
Date: Mon, 20 Feb 2006 11:39:42 -0500
Subject: [R] Time on x-axis
Message-ID: <44085AA7@webmail.utk.edu>

Hello,

   I just started using the GNU R. I am having trouble plotting my data. I am 
tryin to plot the following data:

TIMESTAMP    LOGIN-TIME 
(hh:mm:ss)          (s)

23:55:03       0.990972 
23:55:03       0.990972 
23:50:04       0.878968 
23:45:04       0.969271 
23:40:03       0.868848 
23:35:03        0.88141 
23:30:03       0.679571 
23:25:03       0.599834 
23:20:03       0.663436 
23:15:03       0.567414 
23:10:02       0.738379 
23:05:02       0.575764

with TIMESTAMP on the x-axis. The plot() function assumes the x-axis as the 
total number of events, and plots the desired graph. But I want the TIMESTAMP 
on the x-axis. If I try to change the x-axis, the y-axis gets modified too, 
and all I get is just a "dot" as a plot. 
Can someone tell me how I can make R plot my graph, with TIMESTAMP as my 
x-axis and LOGIN_TIME as my y-axis?

Thank you.

Sangeetha

-- Sangeetha Swaminathan
Graduate Assistant
Innovative Technology Center (ITC)
2444 Dunford Hall
The University of Tennessee
Knoxville, TN 37996
Phone [O]:(865) 974-9672
      [R]:(865) 946-4340



From ggrothendieck at gmail.com  Mon Feb 20 17:59:17 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 20 Feb 2006 11:59:17 -0500
Subject: [R] Time on x-axis
In-Reply-To: <44085AA7@webmail.utk.edu>
References: <44085AA7@webmail.utk.edu>
Message-ID: <971536df0602200859k7f515ff7n998db91e7d4fd3bd@mail.gmail.com>

Try this:

# test data
tt <- c("23:05:02", "23:10:02", "23:15:03", "23:20:03", "23:25:03",
"23:30:03", "23:35:03", "23:40:03", "23:45:04", "23:50:04", "23:55:03",
"23:55:03")
x <- c(0.575764, 0.738379, 0.567414, 0.663436, 0.599834, 0.679571,
0.88141, 0.868848, 0.969271, 0.878968, 0.990972, 0.990972)

library(zoo)
library(chron)
z <- zoo(x, times(tt))
plot(z)

Read the R Help Desk article in R News 4/1 about dates and times
and also read the chron article in its references.

Also read the zoo vignette which you can access like this:

library(zoo)
vignette("zoo")

and also read ?axis in case you want to customize the axes.


On 2/20/06, Sangeetha Swaminathan <sangi at itc.utk.edu> wrote:
> Hello,
>
>   I just started using the GNU R. I am having trouble plotting my data. I am
> tryin to plot the following data:
>
> TIMESTAMP    LOGIN-TIME
> (hh:mm:ss)          (s)
>
> 23:55:03       0.990972
> 23:55:03       0.990972
> 23:50:04       0.878968
> 23:45:04       0.969271
> 23:40:03       0.868848
> 23:35:03        0.88141
> 23:30:03       0.679571
> 23:25:03       0.599834
> 23:20:03       0.663436
> 23:15:03       0.567414
> 23:10:02       0.738379
> 23:05:02       0.575764
>
> with TIMESTAMP on the x-axis. The plot() function assumes the x-axis as the
> total number of events, and plots the desired graph. But I want the TIMESTAMP
> on the x-axis. If I try to change the x-axis, the y-axis gets modified too,
> and all I get is just a "dot" as a plot.
> Can someone tell me how I can make R plot my graph, with TIMESTAMP as my
> x-axis and LOGIN_TIME as my y-axis?
>
> Thank you.
>
> Sangeetha
>
> -- Sangeetha Swaminathan
> Graduate Assistant
> Innovative Technology Center (ITC)
> 2444 Dunford Hall
> The University of Tennessee
> Knoxville, TN 37996
> Phone [O]:(865) 974-9672
>      [R]:(865) 946-4340
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From pradeep.gunda at gmail.com  Mon Feb 20 18:15:55 2006
From: pradeep.gunda at gmail.com (Pradeep Gunda)
Date: Mon, 20 Feb 2006 12:15:55 -0500
Subject: [R] doubt on periodogram
Message-ID: <25ef638b0602200915j5d7a72favbc34a9cd4f21323b@mail.gmail.com>

hi all,

I am using the periodogram function provided by the "GeneTS" library
in R. The periodogram function takes a time-series as input and
returns a  spec(a vector of values) and their frequencies. My
requirement is, I have to loop through the values in this spec and
then remove some of these, depending on whether they exceed some
cutoff. I could not find any function to loop through the elements of
spec in periodogram. Could you inform how I can do this.


Example:


-------------------------------------------------------------------------------------------

> myts <- ts(c(1,2,3,40,3,2,5,40,2,3,1,40), frequency=1);
> myper <- periodogram(myts);
> myper

$spec
             [,1]
[1,] 1.900321e+00
[2,] 8.333333e-02
[3,] 1.064833e+03
[4,] 5.833333e-01
[5,] 2.766346e+00
[6,] 1.045333e+03

$freq
[1] 0.08333333 0.16666667 0.25000000 0.33333333 0.41666667 0.50000000

----------------------------------------------------------------------------------------------



my cutoff is 4.00 and I wasnt to discard all the values in the above
spec vector which are less than 4. Could you help me how could I do
that. I did not find any attributes or functions in periodogram
through which I can do this.

Thanks and Regards,
Pradeep Kumar Gunda



From M.A.MacNeil at ncl.ac.uk  Mon Feb 20 18:16:55 2006
From: M.A.MacNeil at ncl.ac.uk (Aaron MacNeil)
Date: Mon, 20 Feb 2006 17:16:55 +0000
Subject: [R] Nested AIC
Message-ID: <04234404-65A3-459D-952B-D13A2EE184E3@ncl.ac.uk>

Greetings,
I have recently come into some confusion over weather or not AIC  
results for comparing among models requires that they be nested.   
Reading Burnham & Anderson (2002) they are explicit that nested  
models are not required, but other respected statisticians have  
suggested that nesting is a pre-requisite for comparison.  Could  
anyone who feels strongly regarding either position post their  
arguments for or against nested models and AIC? This would assist me  
greatly in some analysis I am currently conducting.
Many thanks,

Aaron

<<
m aaron macneil

school of marine science
     and technology
university of newcastle
newcastle upon tyne, uk
ne1 7ru

m.a.macneil at ncl.ac.uk
 >>



From rva_ec at yahoo.com  Mon Feb 20 18:38:06 2006
From: rva_ec at yahoo.com (Vijay A Raghavan)
Date: Mon, 20 Feb 2006 09:38:06 -0800 (PST)
Subject: [R] mva.pairs
Message-ID: <20060220173806.97465.qmail@web53503.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060220/caeb557e/attachment.pl

From umalvarez at fata.unam.mx  Mon Feb 20 18:40:55 2006
From: umalvarez at fata.unam.mx (Ulises M. Alvarez)
Date: Mon, 20 Feb 2006 11:40:55 -0600
Subject: [R] Linux Distribution Choice
In-Reply-To: <2c75873c0602200436n3fbebcb6w@mail.gmail.com>
References: <2c75873c0602190759m3518e5b5p@mail.gmail.com>
	<2c75873c0602200436n3fbebcb6w@mail.gmail.com>
Message-ID: <43F9FF27.7080808@fata.unam.mx>

Ubuntu is a good choice : )

First, I will recommend you to take a look at:
http://ubuntuguide.org/

Specially...
http://ubuntuguide.org/#extrarepositories

It is slightly out of date, but still is useful.

Once you are done with that, installing R is quit simple. From a
terminal -available from the menus in your panel-, type:

$ sudo aptitude install r-base r-base-core r-base-html r-recommended
r-doc-pdf

And that's it!


On the other hand, if you want to install from the source, you may try
from a terminal the following:

$ sudo apt-get build-dep r-base
(A lot of *.deb's here)

$ sudo aptitude install checkinstall

Once you are done with that, get and unpack the R-source (once again on
a terminal):

$ wget -c http://cran.us.r-project.org/src/base/R-2/R-2.2.1.tar.gz
$ tar -xzf R-2.2.1.tar.gz
$ cd R-2.2.1
$ ./configure && make && make check
(You may like to see the results of 'make check' to asses that
everything went fine)

Finally:

$ sudo checkinstall
(You may enter some info here or leave the defaults)

And that's it!

Whatever you choose, I strongly recommend to run:
$ sudo apt-get build-dep r-base

So you can install, and build, additional packages from CRAN. You may
cut and paste the terminal commands, just be sure to omit the '$' symbol.

Graham Smith wrote:
> Thanks to everyone on this. Iyt ha sgiven me some useful insights into the
> 
>>different options. I am going to try Ubuntu for the time being and see how I
>>get on. Probably revewing the situatin once I understand a bit more about
>>how Linux works.
> 
> 
> 
> 
> Graham
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
U.M.A.
http://sophie.fata.unam.mx/



From mtb954 at gmail.com  Mon Feb 20 18:45:59 2006
From: mtb954 at gmail.com (mtb954@gmail.com)
Date: Mon, 20 Feb 2006 11:45:59 -0600
Subject: [R] glob2rx function not working
Message-ID: <e40d78ce0602200945q4ec35e1btdaa2269ade6c084b@mail.gmail.com>

Dear R users,

Inspired by previous list discussion of the glob2rxc function, I am
attempting to create a new vector called TOTAL by summing all vectors
whose names begin with ABC:

TOTAL = sum(list = ls(pattern = glob2rx("ABC*")))

I'm running R 2.2.1 on Windows XP. Can anyone say what I'm missing?

Thank you, Mark



From ripley at stats.ox.ac.uk  Mon Feb 20 18:53:23 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 20 Feb 2006 17:53:23 +0000 (GMT)
Subject: [R] Plots: displaying mathematical symbols in specific fonts
In-Reply-To: <6.2.3.4.2.20060220100146.021f3530@pop.service.ohio-state.edu>
References: <6.2.3.4.2.20060220100146.021f3530@pop.service.ohio-state.edu>
Message-ID: <Pine.LNX.4.64.0602201721390.15309@gannet.stats.ox.ac.uk>

On Mon, 20 Feb 2006, Ed Merkle wrote:

> Dear SavioRs,
>
> I am doing some research where characters in different microsoft
> fonts serve as experimental stimuli.  Hence, in plot labels, I would
> like to display the characters in specific microsoft fonts.  I have
> figured out how to display letters and numbers, but I am having
> trouble with symbols such as capital delta.  Before I go further, I
> am using R 2.2.1 on Windows XP with everything in English.  I am
> trying to save my plot as a windows metafile.
>
> To display different characters in verdana, for example, I first edit
> the Rdevga file so that it contains verdana.  I can then get verdana
> letters and numbers on the plot using a text() command.  Things
> within an expression() command, however, are not displayed in the
> desired font.  For example,

No, they are *always* displayed in font 5, as the Rdevga file actually 
says.  Verdana is not a mathematical font, and what you are looking for is 
the Greek letter Delta, not the mathematical symbol.

> windows()
> plot(rnorm(15),rnorm(15))
> text(0,0,expression(Delta),font=10)
>
> displays a capital delta, but it is not in font #10 within Rdevga.  I
> can get characters that have one of the first 255 ascii codes

Hmm, there are only 128 ASCII codes.  I guess you mean you are in CP1252 
aka WinAnsi, the Windows approximation to ISO Latin-1, and so can only 
access the (somewhat less than) 256 glyphs of that charset.

> using
> chars8bit() in the sfsmisc package.  One example is the division sign:
>
> text(0,0.2,chars8bit(247),font=10)

You don't need that: the standard octal and hex escapes work.  But if you 
want to draw symbols you should probably be using points() and pch=.
E.g.

points(0, 0.2, font=10, pch=247)

> I have not been able to display other symbols in microsoft fonts,
> however.  Is this possible to do in R?  All replies are appreciated.

Yes, but only by switching to a Greek locale.  For example

Sys.setlocale("LC_CTYPE", "greek")
plot(1:10)
text(8,2, "\xC4", font=10)

and that only on an NT-based version of Windows and the R-devel version of 
R.

It's easier on Unix-alikes in a UTF-8 locale, as then you can use Unicode 
escapes like \u0394.  But Windows does not have UTF-8 locales (although 
one day R may fake them -- actually internally it already can but there is 
no I/O support).  There you could also do

text(8, 2, "\u0394")
points(5, 7, font=4, pch=0x0394)

at least if you have fonts which support Greek.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at gmail.com  Mon Feb 20 19:10:25 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 20 Feb 2006 13:10:25 -0500
Subject: [R] glob2rx function not working
In-Reply-To: <e40d78ce0602200945q4ec35e1btdaa2269ade6c084b@mail.gmail.com>
References: <e40d78ce0602200945q4ec35e1btdaa2269ade6c084b@mail.gmail.com>
Message-ID: <971536df0602201010u4761a5celc5a0a4a254911895@mail.gmail.com>

Your expression is trying to sum a character vector
containing the names of the variables that begin with ABC.
Try this and try executing each portion of it to understand
it better:

ABC1 <- ABC2 <- 1
do.call("sum", lapply(apropos(glob2rx("ABC*")), get)) # 2

On 2/20/06, mtb954 at gmail.com <mtb954 at gmail.com> wrote:
> Dear R users,
>
> Inspired by previous list discussion of the glob2rxc function, I am
> attempting to create a new vector called TOTAL by summing all vectors
> whose names begin with ABC:
>
> TOTAL = sum(list = ls(pattern = glob2rx("ABC*")))
>
> I'm running R 2.2.1 on Windows XP. Can anyone say what I'm missing?
>
> Thank you, Mark
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From typhoon_zy at hotmail.com  Mon Feb 20 19:11:19 2006
From: typhoon_zy at hotmail.com (Feng Tai)
Date: Mon, 20 Feb 2006 12:11:19 -0600
Subject: [R] help on dyn.load()
In-Reply-To: <Pine.LNX.4.44.0602200806300.22406-100000@reclus.nhh.no>
Message-ID: <BAY111-F9852E14994490EBB6110DE8FF0@phx.gbl>

Thanks a lot!  It works now.

Feng


>From: Roger Bivand <Roger.Bivand at nhh.no>
>Reply-To: Roger.Bivand at nhh.no
>To: Feng Tai <typhoon_zy at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] help on dyn.load()
>Date: Mon, 20 Feb 2006 08:13:49 +0100 (CET)
>
>On Mon, 20 Feb 2006, Feng Tai wrote:
>
> > Hi,
> >
> > I used .C to call the C functions inside R. Everything works fine on the
> > linux sever.
> >
> > I installed cygwin on my windows xp x64 platform and used rcmd shlib 
>xxx.c
> > to compile. Everything works fine till now and xxx.dll is generated. But
> > when I use dyn.load("xxx.dll") in R, it will open another R window and 
>the
> > original R window becomes "Not responding", nothing loaded in both R 
>window.
> > Anyone has similar experiences before. Thanks a lot.
>
>It has been the case that you are recommended not to build shared library
>objects under Cygwin, but rather to follow the instructions in:
>
>http://www.murdoch-sutherland.com/Rtools/
>
>carefully - that is build under Windows using the chosen tools. The other
>.dll files you report functioning correctly were built in this way, so the
>easiest thing to do is to build in the same way.
>
> >
> > BTW: I tried some other .dll files from the existed library. everything
> > works ok. so I think maybe something wrong with my C code. But why it 
>works
> > fine on the linux server? Any guess or suggestion for this?
> >
> > Feng
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
> >
>
>--
>Roger Bivand
>Economic Geography Section, Department of Economics, Norwegian School of
>Economics and Business Administration, Helleveien 30, N-5045 Bergen,
>Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
>e-mail: Roger.Bivand at nhh.no
>



From p.dalgaard at biostat.ku.dk  Mon Feb 20 19:19:09 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Feb 2006 19:19:09 +0100
Subject: [R] glob2rx function not working
In-Reply-To: <e40d78ce0602200945q4ec35e1btdaa2269ade6c084b@mail.gmail.com>
References: <e40d78ce0602200945q4ec35e1btdaa2269ade6c084b@mail.gmail.com>
Message-ID: <x264n9rizm.fsf@turmalin.kubism.ku.dk>

mtb954 at gmail.com writes:

> Dear R users,
> 
> Inspired by previous list discussion of the glob2rxc function, I am
> attempting to create a new vector called TOTAL by summing all vectors
> whose names begin with ABC:
> 
> TOTAL = sum(list = ls(pattern = glob2rx("ABC*")))
> 
> I'm running R 2.2.1 on Windows XP. Can anyone say what I'm missing?

Probably, but I'll save the sarcasm...

Consider this:

> ls()
[1] "as.alist.call" "f"             "fire"
[4] "Hgb"           "perulung"      "walk2"
[7] "x"             "y"             "zelazo"
> ls(pattern=glob2rx("f*"))
[1] "f"    "fire"
> sum(list=ls(pattern=glob2rx("f*")))
Error in sum(..., na.rm = na.rm) : invalid 'mode' of argument

which is because

> sum(c("f","fire"))
Error in sum(..., na.rm = na.rm) : invalid 'mode' of argument

and has nothing to do with glob2rx, which is working fine.

You may be looking for constructions like

 do.call("sum",lapply(ls(pattern=glob2rx("ABC*")), get)))

or

 sum(unlist(lapply(ls(pattern=glob2rx("ABC*")), get)))


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From edd at debian.org  Mon Feb 20 20:01:26 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 20 Feb 2006 13:01:26 -0600
Subject: [R] Linux Distribution Choice
In-Reply-To: <43F9FF27.7080808@fata.unam.mx>
References: <2c75873c0602190759m3518e5b5p@mail.gmail.com>
	<2c75873c0602200436n3fbebcb6w@mail.gmail.com>
	<43F9FF27.7080808@fata.unam.mx>
Message-ID: <17402.4614.16822.956436@basebud.nulle.part>


Ulises,

Thanks for the helpful post but allow me to add one or two corrections:

On 20 February 2006 at 11:40, Ulises M. Alvarez wrote:
| Ubuntu is a good choice : )
| 
| First, I will recommend you to take a look at:
| http://ubuntuguide.org/
| 
| Specially...
| http://ubuntuguide.org/#extrarepositories
| 
| It is slightly out of date, but still is useful.
| 
| Once you are done with that, installing R is quit simple. From a
| terminal -available from the menus in your panel-, type:
| 
| $ sudo aptitude install r-base r-base-core r-base-html r-recommended
| r-doc-pdf
| 
| And that's it!

The key here is the archive you point to. 

Ubuntu freezes every six months, so 5.10 does "by design" not have R 2.2.0
and 2.2.1 which were released after 5.10.  See the R FAQ for the address of
the Debian stable backport (and our thanks to Chris Steigies for building
them); once you add the line to /etc/apt/sources.list you even get current
packages so that

	$ apt-get install r-base

can do its work. aptitude, wajig, ... and dozen other frontends then will as
well, of course. The r-base meta package should imply all the one you listed
above.  This ought to work on Ubutu as well as was discussed on r-help last
week.  It may fail if and when Debian's and Ubuntu's libraries diverge.

| On the other hand, if you want to install from the source, you may try
| from a terminal the following:
| 
| $ sudo apt-get build-dep r-base
| (A lot of *.deb's here)

Actually, 'apt-get install r-base-dev' should do the trick and was designed
by Doug for just that.

| $ sudo aptitude install checkinstall
| 
| Once you are done with that, get and unpack the R-source (once again on
| a terminal):
| 
| $ wget -c http://cran.us.r-project.org/src/base/R-2/R-2.2.1.tar.gz
| $ tar -xzf R-2.2.1.tar.gz
| $ cd R-2.2.1
| $ ./configure && make && make check
| (You may like to see the results of 'make check' to asses that
| everything went fine)

Configuring that way omits a lot of little goodies we have in the Debian
package. I'd go with the prebuild ones, or locally rebuild from Debian
sources. 

| Finally:
| 
| $ sudo checkinstall
| (You may enter some info here or leave the defaults)
| 
| And that's it!
| 
| Whatever you choose, I strongly recommend to run:
| $ sudo apt-get build-dep r-base

Again, 'r-base-dev' should cover that.

| So you can install, and build, additional packages from CRAN. You may

Or just use the 50-some existing ones in Debian and (K)Ubuntu. Do a

	$ apt-cache rdepends r-base-core

to see all the packages depending on r-base-core, which includes all CRAN,
Omegahat, ... packages we currently have.  

Dirk

| cut and paste the terminal commands, just be sure to omit the '$' symbol.
| 
| Graham Smith wrote:
| > Thanks to everyone on this. Iyt ha sgiven me some useful insights into the
| > 
| >>different options. I am going to try Ubuntu for the time being and see how I
| >>get on. Probably revewing the situatin once I understand a bit more about
| >>how Linux works.
| > 
| > 
| > 
| > 
| > Graham
| > 
| > 	[[alternative HTML version deleted]]
| > 
| > ______________________________________________
| > R-help at stat.math.ethz.ch mailing list
| > https://stat.ethz.ch/mailman/listinfo/r-help
| > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
| > 
| 
| -- 
| U.M.A.
| http://sophie.fata.unam.mx/
| 
| ______________________________________________
| R-help at stat.math.ethz.ch mailing list
| https://stat.ethz.ch/mailman/listinfo/r-help
| PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison



From bolker at ufl.edu  Mon Feb 20 20:13:43 2006
From: bolker at ufl.edu (Ben Bolker)
Date: Mon, 20 Feb 2006 19:13:43 +0000 (UTC)
Subject: [R] doubt on periodogram
References: <25ef638b0602200915j5d7a72favbc34a9cd4f21323b@mail.gmail.com>
Message-ID: <loom.20060220T200741-839@post.gmane.org>

Pradeep Gunda <pradeep.gunda <at> gmail.com> writes:

> 
> hi all,
> 
> I am using the periodogram function provided by the "GeneTS" library
> in R. 
> > myts <- ts(c(1,2,3,40,3,2,5,40,2,3,1,40), frequency=1);
> > myper <- periodogram(myts);
> > myper
> 
>
   
something like   

myper$spec <- myper$spec[myper$spec<4]

  Please take some time to sit down and read "An Introduction to R",
which came with your copy of R -- pages 11 and 12 will be especially
helpful.  If you find it too technical, try one of the many books
or contributed pieces of documentation listed on the main R web
site.

   cheers
    Ben Bolker



From mingyufeng at gmail.com  Mon Feb 20 20:45:09 2006
From: mingyufeng at gmail.com (Mingyu Feng)
Date: Mon, 20 Feb 2006 14:45:09 -0500
Subject: [R] get predicted values of models fit by lmer()?
Message-ID: <9caad71a0602201145x10019f7aje3ade7a4f16152a8@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060220/9a47a1d5/attachment.pl

From alex.park1 at ntlworld.com  Mon Feb 20 21:27:35 2006
From: alex.park1 at ntlworld.com (Alex Park)
Date: Mon, 20 Feb 2006 20:27:35 -0000
Subject: [R] Boxplot Help for Neophyte
Message-ID: <002d01c6365c$16f7d670$9a876ad5@JimPark>

R helpers

I am getting to grips with R but came across a small problem today that I 
could not fix by myself.

I have 3 text files, each with a single column of data. I read them in 
using:

myData1<-scan("C:/Program Files/R/myData1.txt")
myData2<-scan("C:/Program Files/R/myData2.txt")
myData3<-scan("C:/Program Files/R/myData3.txt")

I wanted to produce a chart with 3 boxplots of the data and used:

boxplot(myData1, myData2, myData3)

This worked fine so I consulted R [help(bxp)] to add some format and labels 
e.g. title= , xlab =, ylab= , notch=TRUE etc. I managed to figure that ok.

However, I could not figure out how to get the labels myData1, myData2, and 
myData3 on the boxplot x-axis to denote which box was which (though I knew 
by looking). Can anybody help with this?

I trawled through my downloaded R pdfs but could not find a way.

Regards


Alex Park



From nlemeur at fhcrc.org  Mon Feb 20 21:43:54 2006
From: nlemeur at fhcrc.org (Nolwenn LeMeur)
Date: Mon, 20 Feb 2006 12:43:54 -0800 (PST)
Subject: [R] Boxplot Help for Neophyte
In-Reply-To: <002d01c6365c$16f7d670$9a876ad5@JimPark>
References: <002d01c6365c$16f7d670$9a876ad5@JimPark>
Message-ID: <Pine.LNX.4.61.0602201242080.25338@vole.fhcrc.org>

Hi Alex,
how about,

myData<-data.frame("myData1"=myData1,"myData2"=myData2,"myData3"=myData3)
boxplot(myData)

Nolwenn

**************************************
Nolwenn Le Meur, PhD
Fred Hutchinson Cancer Research Center
Computational Biology
1100 Fairview Ave. N., M2-B876
P.O. Box 19024
Seattle, WA 98109-1024

On Mon, 20 Feb 2006, Alex Park wrote:

> R helpers
> 
> I am getting to grips with R but came across a small problem today that I 
> could not fix by myself.
> 
> I have 3 text files, each with a single column of data. I read them in 
> using:
> 
> myData1<-scan("C:/Program Files/R/myData1.txt")
> myData2<-scan("C:/Program Files/R/myData2.txt")
> myData3<-scan("C:/Program Files/R/myData3.txt")
> 
> I wanted to produce a chart with 3 boxplots of the data and used:
> 
> boxplot(myData1, myData2, myData3)
> 
> This worked fine so I consulted R [help(bxp)] to add some format and labels 
> e.g. title= , xlab =, ylab= , notch=TRUE etc. I managed to figure that ok.
> 
> However, I could not figure out how to get the labels myData1, myData2, and 
> myData3 on the boxplot x-axis to denote which box was which (though I knew 
> by looking). Can anybody help with this?
> 
> I trawled through my downloaded R pdfs but could not find a way.
> 
> Regards
> 
> 
> Alex Park
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From mschwartz at mn.rr.com  Mon Feb 20 21:58:35 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 20 Feb 2006 14:58:35 -0600
Subject: [R] Boxplot Help for Neophyte
In-Reply-To: <002d01c6365c$16f7d670$9a876ad5@JimPark>
References: <002d01c6365c$16f7d670$9a876ad5@JimPark>
Message-ID: <1140469115.4553.16.camel@localhost.localdomain>

On Mon, 2006-02-20 at 20:27 +0000, Alex Park wrote:
> R helpers
> 
> I am getting to grips with R but came across a small problem today that I 
> could not fix by myself.
> 
> I have 3 text files, each with a single column of data. I read them in 
> using:
> 
> myData1<-scan("C:/Program Files/R/myData1.txt")
> myData2<-scan("C:/Program Files/R/myData2.txt")
> myData3<-scan("C:/Program Files/R/myData3.txt")
> 
> I wanted to produce a chart with 3 boxplots of the data and used:
> 
> boxplot(myData1, myData2, myData3)
> 
> This worked fine so I consulted R [help(bxp)] to add some format and labels 
> e.g. title= , xlab =, ylab= , notch=TRUE etc. I managed to figure that ok.
> 
> However, I could not figure out how to get the labels myData1, myData2, and 
> myData3 on the boxplot x-axis to denote which box was which (though I knew 
> by looking). Can anybody help with this?
> 
> I trawled through my downloaded R pdfs but could not find a way.
> 
> Regards
> 
> 
> Alex Park


Alex,

You can use the 'names' argument to boxplot():

  boxplot(myData1, myData2, myData3, 
          names = c("myData1", "myData2", "myData"))

If you want additional flexibility, note that by default (unless you
change the 'at' argument), the group plots are drawn at integer axis
values of 1:n, where 'n' is the number of groups. See the 'at' argument
in ?boxplot.  You can then use mtext() to draw further text if desired.

HTH,

Marc Schwartz



From jholtman at gmail.com  Mon Feb 20 22:28:57 2006
From: jholtman at gmail.com (jim holtman)
Date: Mon, 20 Feb 2006 16:28:57 -0500
Subject: [R] Boxplot Help for Neophyte
In-Reply-To: <002d01c6365c$16f7d670$9a876ad5@JimPark>
References: <002d01c6365c$16f7d670$9a876ad5@JimPark>
Message-ID: <644e1f320602201328g6edd505dvf96474791adfd666@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060220/6aa2b050/attachment.pl

From comtech.usa at gmail.com  Wed Feb 15 07:05:14 2006
From: comtech.usa at gmail.com (Michael)
Date: Tue, 14 Feb 2006 22:05:14 -0800
Subject: [R] need a R-code formatter?
Message-ID: <b1f16d9d0602142205w75274a27kb877c3b4107777ac@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060214/8f52d559/attachment.pl

From bitwrit at ozemail.com.au  Sun Feb 12 04:12:10 2006
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Sat, 11 Feb 2006 22:12:10 -0500
Subject: [R] Need frequency distribution for x,y coordinates
Message-ID: <43EEA78A.5020203@ozemail.com.au>

mark shanks wrote:
 >
 > Hi,
 >
 > I have a set of data in x,y coordinates across the range of -5 to 5 
in each
 > dimension. I would like to obtain the frequency distribution of the
 > different points, and then graph them so you can see which of the 
points are
 > the most frequently occurring.
 >
 > This would seem to be easy in Matlab, which has the hist3 command for 
doing
 > frequency distributions/histograms in 3 dimensions. However, as far 
as I can
 > tell, R does not have a hist3 command.

If a 2D display is okay, you can use the color2D.matplot function in the 
plotrix package to plot the output of something like kde2d in MASS:

x<-seq(-5,5,by=0.1)
xdens<-kde2d(sample(x,500,TRUE),sample(x,500,TRUE),n=11)
color2D.matplot(xdens$z,c(1,0),c(0,1),c(0,0),
show.legend=TRUE,xlab="Columns",ylab="Rows")

Jim



From bitwrit at ozemail.com.au  Tue Feb 14 04:14:35 2006
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Mon, 13 Feb 2006 22:14:35 -0500
Subject: [R] Tobit Regression (residual Assumption)
In-Reply-To: <830480cb0602121524qb527534g8dd43ab16c99cd22@mail.gmail.com>
References: <830480cb0602121524qb527534g8dd43ab16c99cd22@mail.gmail.com>
Message-ID: <43F14B1B.1040207@ozemail.com.au>

Hi folks,

I exchanged a couple of emails privately about tobit regression and 
advised that he (bambang pramono) ask the list for pointers to a basic, 
widely available, introductory reference. I think it would be a great 
help if someone would kindly suggest such a reference.

Thanks,
Jim



From deepayan.sarkar at gmail.com  Tue Feb 14 17:59:11 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 14 Feb 2006 10:59:11 -0600
Subject: [R] lattice: calling functions
In-Reply-To: <43F1EE3F.1020107@stats.uwo.ca>
References: <20060214135606.GA3185@s1x.local> <43F1E6A4.5050304@stats.uwo.ca>
	<971536df0602140638t502239bdo949e6d0d20638ba@mail.gmail.com>
	<43F1EE3F.1020107@stats.uwo.ca>
Message-ID: <eb555e660602140859m501cbb05w6b60c055547a8aed@mail.gmail.com>

On 2/14/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> On 2/14/2006 9:38 AM, Gabor Grothendieck wrote:
> > On 2/14/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
> >> On 2/14/2006 8:56 AM, Wolfram Fischer wrote:
> >> > I defined three functions:
> >> >
> >> >> fun0 <- function( x=1:5, y=1:5, ... ) xyplot( y ~ x, ... )
> >> >
> >> >> fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, ... )
> >> >> fun2 <- function( ... ) xyplot( ... )
> >> >
> >> > The call of fun0() works as expected.
> >> >
> >> > The call of fun1() causes the following error:
> >> >     'Error in eval(expr, envir, enclos) : object "y" not found'
> >> >
> >> > How should I define fun2 to avoid the error?
> >>
> >> fun2 is fine, it's fun1 that has problems.  It is passing a formula
> >> through fun2 to xyplot without telling xyplot where to evaluate the
> >> arguments.  If you change it to
> >>
> >> fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, data=enviroment(), ...
> )

data=NULL works too, which is apparently what lm has.  The point being
that the environment of the formula is looked at, but the default
data=parent.frame() subverts that because of the way eval works (using
enclos only when envir is a list or data frame. What's wrong with
environments?). Even the following works:

fun1 <- function( x=1:5, y=1:5, ... )
    fun2( y ~ x, data = data.frame(x = x), ... )

I don't understand non-standard evaluation all that well, so I'll
happily consider any suggestions. I'll try changing the defaults to
NULL and see if there are any obvious problems.

Deepayan

> >> it will tell xyplot to look in the current environment at the time of
> >> the call, i.e. the fun1 evaluation environment where x and y live.
> >>
> >
> > Although this does seem to be how xyplot works, I think it indicates
> > there is a problem with it.
> >
> > The help file for xyplot indicates that for the xyplot formula method
> > the default
> > environment is the caller environment whereas it ought to be the
> environment
> > of the formula:
> >
> >     data: For the 'formula' method, a data frame containing values for
> >           any variables in the formula, as well as 'groups' and
> >           'subset' if applicable.  By default the environment where the
> >           function was called from is used.
> >
> > For example, if we replace xyplot with lm it does work as expected:
> >
> >    fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, ... )
> >    fun2 <- function( ... ) lm( ... )
> >    fun1()
>
> You're right, I forgot formulas have associated environments.  I've
> added the lattice maintainer to the cc list.
>
> Duncan Murdoch



From Galina_Glazko at URMC.Rochester.edu  Wed Feb 15 14:07:50 2006
From: Galina_Glazko at URMC.Rochester.edu (Glazko, Galina)
Date: Wed, 15 Feb 2006 08:07:50 -0500
Subject: [R] power law
Message-ID: <1AFEC6AD98A0AA4D948216A768A1578C480CD2@e2k3ms3.urmc-sh.rochester.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060215/381208c7/attachment.pl

From comtech.usa at gmail.com  Thu Feb 16 12:07:53 2006
From: comtech.usa at gmail.com (Michael)
Date: Thu, 16 Feb 2006 03:07:53 -0800
Subject: [R] how to close all windows?
Message-ID: <b1f16d9d0602160307p3215b733qc34f206b25098b29@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/fd61c010/attachment.pl

From alexandrarma at yahoo.com.br  Thu Feb 16 18:39:49 2006
From: alexandrarma at yahoo.com.br (Alexandra R. M. de Almeida)
Date: Thu, 16 Feb 2006 14:39:49 -0300 (ART)
Subject: [R] Reanding a windows file
Message-ID: <20060216173949.98281.qmail@web33305.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060216/6088d1bb/attachment.pl

From ccatj at web.de  Sun Feb 19 22:05:27 2006
From: ccatj at web.de (Christian Jones)
Date: Sun, 19 Feb 2006 22:05:27 +0100
Subject: [R] standardizing data
Message-ID: <496174581@web.de>

Hello R team,
I??m looking for a way to standardize (z transformation= standard deviation 1 and mean 0) a row of x y coordinates in order to conduct  a trend analysis. Does anyone know the command in R?
many thanks for help in advance
Christian



From daniele at medri.org  Mon Feb 20 16:22:06 2006
From: daniele at medri.org (Daniele Medri)
Date: Mon, 20 Feb 2006 16:22:06 +0100
Subject: [R] Group a dinamic number of vectors in a data.frame
Message-ID: <1140448926.24883.16.camel@localhost.localdomain>

Hi all,

I need to create a data.frame from a variable number of vectors.
The number of these vectors could change so I need a dinamic way to
group all in a data.frame. The number is length(abc).

e.g. vectors in my workspace

N1 <-c(1,2,3,4)
N2 <-c(1,2,3,4)
N3 <-c(1,2,3,4)
abc <-c(1,2,3)

the data.frame I want to create:

tcm <-data.frame(OneVector, TwoVector,  paste("N",1:length(abc)))

Obviously :) if I am here this approach doesn't work, so any kind of tip
is welcome.

Cheers
-- 
Daniele Medri



From hgn01 at aub.edu.lb  Fri Feb 17 17:29:10 2006
From: hgn01 at aub.edu.lb (Houssam Nassif)
Date: Fri, 17 Feb 2006 18:29:10 +0200
Subject: [R] SVM weights
Message-ID: <1140193750.43f5f9d62dd7c@imail.aub.edu.lb>

Hello
I am using e1071, svm.
After tuning the parameters, I would like to get the weights assigned to the
different features of my feature vector.
This is to perform a feature reduction step by eliminating features with low
discrimination values.

How can i get the weight vector?

best



From tang5 at purdue.edu  Sat Feb 11 21:50:57 2006
From: tang5 at purdue.edu (tang5@purdue.edu)
Date: Sat, 11 Feb 2006 15:50:57 -0500
Subject: [R] panel-VAR
Message-ID: <1139691057.43ee4e313fa68@webmail.purdue.edu>



Hi,
Anybody knows if there is a package for panel VAR ?
thanks



From attenka at utu.fi  Mon Feb 20 22:40:17 2006
From: attenka at utu.fi (Atte Tenkanen)
Date: Mon, 20 Feb 2006 23:40:17 +0200 (EET)
Subject: [R] How to read more than 1 table?
Message-ID: <57116.130.232.44.35.1140471617.squirrel@webmail2.utu.fi>

Question 1) I want to read many csv-tables and run the same commands for
all of them. Is there some simpler solution than this below to solve this
problem?


for (g in 1:6)
{

if (g==1){k="kt1_0057"}
if (g==2){k="kt1_0101"}
if (g==3){k="kt1_0613"}
if (g==4){k="staten"}
if (g==5){k="tenpenny"}
if (g==6){k="fiddrunk"}

TABLE=read.table(paste("/home/user/",k,".csv",sep=""),sep = ",",
na.strings=".",header=F,fill=TRUE);

print(TABLE)

}

Question 2) Is it possible to create new variables for example with the
assistance of for-loop without initialising them beforehand?



From Soren.Hojsgaard at agrsci.dk  Mon Feb 20 22:59:45 2006
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Mon, 20 Feb 2006 22:59:45 +0100
Subject: [R] Using LAPACK in C-code to be loaded in R - getting-started-help
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC038781E0@DJFPOST01.djf.agrsci.dk>

I want to speed up computations (involving matrices) by writing some C-code to be loaded. In the C-code, I need to invert matrices etc. As I've understood the "writing R extensions" doc, I can use use #include <R_ext/Linpack.h> in my .c-file and get access to linpack's facilities within my C-code. 
 
Is that correct?
 
If so, can anyone point me to examples on how this is actually done in practice?
 
Best regards
S??ren



From rwheeler at echip.com  Sun Feb 19 21:34:47 2006
From: rwheeler at echip.com (Bob Wheeler)
Date: Sun, 19 Feb 2006 15:34:47 -0500
Subject: [R] [R-pkgs] Zigurrat updated
Message-ID: <43F8D667.10309@echip.com>

I've updated the Ziggurat normal and exponential
generator in SuppDists in accordance with
Leong, et.al (2005). A comment on the implementation
of the Ziggurat Method. Jour. Stat. Sci. 12-7, 1-4.

The fix takes care of problems for very large sets
of random values. I tested it a bit on small samples
and it seems ok. It will be on CRAN shortly.
-- 
Bob Wheeler --- http://www.bobwheeler.com/
    ECHIP, Inc. --- Randomness comes in bunches.

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From p.dalgaard at biostat.ku.dk  Mon Feb 20 23:33:49 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Feb 2006 23:33:49 +0100
Subject: [R] Reanding a windows file
In-Reply-To: <20060216173949.98281.qmail@web33305.mail.mud.yahoo.com>
References: <20060216173949.98281.qmail@web33305.mail.mud.yahoo.com>
Message-ID: <x2slqdlkxe.fsf@turmalin.kubism.ku.dk>

"Alexandra R. M. de Almeida" <alexandrarma at yahoo.com.br> writes:

> Dear R users
>  
>  Some one knows how to read a windows file with the adress like 
"D:\CSV\Work\test.csv" without change the "\" by "/" by myself?!
>  There is some function or parameter that read like the adress windows form.
>  I tried to search somethig to substitute the "\" by "/", but I don't find...

Well, there's no problem with the backslashed form except if you try
copying it literally into R source code. If you do, you run into
problems with R interpreting the backslash as an escape character,
which itself needs to be escaped ("doubling the backslashes"). You
might for instance proceed as follows:

> x <- readLines(,1) # input data on next line
D:\CSV\Work\test.csv
> x
[1] "D:\\CSV\\Work\\test.csv"
> mydata <- read.csv(x)

Notice that x as such has only single backslashes, it is just the
print routine that inserts escape characters:

> cat(x,"\n")
D:\CSV\Work\test.csv
> nchar(x)
[1] 20

123456789*123456789*




-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Mon Feb 20 23:37:53 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 20 Feb 2006 23:37:53 +0100
Subject: [R] standardizing data
In-Reply-To: <496174581@web.de>
References: <496174581@web.de>
Message-ID: <x2oe11lkqm.fsf@turmalin.kubism.ku.dk>

Christian Jones <ccatj at web.de> writes:

> Hello R team,
> I??m looking for a way to standardize (z transformation= standard deviation 1 and mean 0) a row of x y coordinates in order to conduct  a trend analysis. Does anyone know the command in R?
> many thanks for help in advance
> Christian

What do you mean be "a row of x y coordinates"?? An N x 2 matrix?

scale() could well be the answer.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From will at hss.caltech.edu  Mon Feb 20 23:38:08 2006
From: will at hss.caltech.edu (Will Terry)
Date: Mon, 20 Feb 2006 14:38:08 -0800
Subject: [R] standardizing data
In-Reply-To: <496174581@web.de>
References: <496174581@web.de>
Message-ID: <0DFCF888-2435-4AC2-BAEE-D3F255BAFFED@hss.caltech.edu>

Hey there,
Did you try "scale(x)"?
This centers and scales the data in a matrix x.

Will

On Feb 19, 2006, at 1:05 PM, Christian Jones wrote:

> Hello R team,
> I?m looking for a way to standardize (z transformation= standard  
> deviation 1 and mean 0) a row of x y coordinates in order to  
> conduct  a trend analysis. Does anyone know the command in R?
> many thanks for help in advance
> Christian
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html
>



From aldi at wustl.edu  Mon Feb 20 23:43:55 2006
From: aldi at wustl.edu (Aldi Kraja)
Date: Mon, 20 Feb 2006 16:43:55 -0600
Subject: [R] var-covar matrices comparison:
Message-ID: <43FA462B.9020304@wustl.edu>

Hi,
Using package gclus in R, I have created some graphs that show the 
trends within subgroups of data and correlations among 9 variables (v1-v9).
Being interested for more details on these data I have produced also the 
var-covar matrices.
Question: From a pair of two subsets of data (with 9 variables each, I 
have two var-covar matrices for each subgroup, that differ for a 
treatment on one group (treatment A) vs (non-Treatment A).

Is there a software that can compare if two var-covar matrices are 
statistically the same?

Below are a pair of two matrices, from several others.
Thank you in advance for any input.
Aldi

 First group var-covar matrix (the data were under treatment a)

v1        v2                 v3          v4               v5       
v6       v7            v8             v9

 

v1         730.87       3.406      -283.41        -74.68       
107.57      -1355.13      -112.46      14.000       5.776

v2             3.41      24.950       105.45       -121.31      
-307.68       -285.40        29.65      -2.500      -7.796

v3          -283.41     105.451      6292.19      -2676.46      
-970.80      29296.23     10715.29       3.156     -66.313

v4           -74.68    -121.307     -2676.46     124492.30     
-2289.47     -20377.34      -409.71     183.500     563.102

v5           107.57    -307.681      -970.80      -2289.47      
7045.62      12118.09       954.51      38.258      96.355

v6         -1355.13    -285.404     29296.23     -20377.34     
12118.09     218555.93     70126.71     137.000    -130.667

v7          -112.46      29.645     10715.29       -409.71       
954.51      70126.71     28239.57      67.989     -26.370

v8            14.00      -2.500         3.16        183.50        
38.26        137.00        67.99      24.500       9.000

v9             5.78      -7.796       -66.31        563.10        
96.35       -130.67       -26.37       9.000      22.776

 

 

 Second group var-covar matrix (the data were NOT under treatment a)

v1        v2                 v3          v4               v5       
v6       v7            v8             v9

 

v1          2696.25       27.05       201.06       2745.54      
-344.39        540.48        654.20      34.363       7.623

v2            27.05       86.37       -96.89       -497.28     
-1185.10      -3108.71       -910.38      -4.254      -9.115

v3           201.06      -96.89     10647.26       8378.07      
 595.81      66122.43      26237.21     -65.093     -51.998

v4          2745.54     -497.28      8378.07     408391.25     
-3887.28      40477.40      30652.01     450.539      50.311

v5          -344.39    -1185.10       595.81      -3887.28     
29204.00      65320.00      15238.41     -98.237     102.975

v6           540.48    -3108.71     66122.43      40477.40     
65320.00     549955.14     194691.90    -555.552     -95.210

v7           654.20     -910.38     26237.21      30652.01     
15238.41     194691.90      82698.88     -70.417     -75.585

v8            34.36       -4.25       -65.09        450.54       
-98.24       -555.55        -70.42      79.689       8.164

v9             7.62       -9.11       -52.00         50.31       
102.97        -95.21        -75.58       8.164      30.492



From murdoch at stats.uwo.ca  Mon Feb 20 23:43:19 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 20 Feb 2006 17:43:19 -0500
Subject: [R] Reanding a windows file
In-Reply-To: <20060216173949.98281.qmail@web33305.mail.mud.yahoo.com>
References: <20060216173949.98281.qmail@web33305.mail.mud.yahoo.com>
Message-ID: <43FA4607.2010303@stats.uwo.ca>

On 2/16/2006 12:39 PM, Alexandra R. M. de Almeida wrote:
> Dear R users
>  
>  Some one knows how to read a windows file with the adress like "D:\CSV\Work\test.csv" without change the "\" by "/" by myself?!
>  There is some function or parameter that read like the adress windows form.
>  I tried to search somethig to substitute the "\" by "/", but I don't find...

Use file.choose(), and don't type anything at all.

Duncan Murdoch



From kjetilbrinchmannhalvorsen at gmail.com  Mon Feb 20 23:50:19 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Mon, 20 Feb 2006 18:50:19 -0400
Subject: [R] How to read more than 1 table?
In-Reply-To: <57116.130.232.44.35.1140471617.squirrel@webmail2.utu.fi>
References: <57116.130.232.44.35.1140471617.squirrel@webmail2.utu.fi>
Message-ID: <43FA47AB.6000003@gmail.com>

Atte Tenkanen wrote:
> Question 1) I want to read many csv-tables and run the same commands for
> all of them. Is there some simpler solution than this below to solve this
> problem?
> 
> 
> for (g in 1:6)
> {
> 
> if (g==1){k="kt1_0057"}
> if (g==2){k="kt1_0101"}
> if (g==3){k="kt1_0613"}
> if (g==4){k="staten"}
> if (g==5){k="tenpenny"}
> if (g==6){k="fiddrunk"}
> 
> TABLE=read.table(paste("/home/user/",k,".csv",sep=""),sep = ",",
> na.strings=".",header=F,fill=TRUE);

put your filenames in a character vector filenames:
filenames <- paste( c("kt1_0057", ...), ".csv", sep="")
tables  <- lapply( filenames, function(x) read.table(file=x, na.strings= 
..., ...) )

and if you want to repeat the same task for your six tables do it with 
lapply()  or  sapply()

> 
> print(TABLE)
> 
> }
> 
> Question 2) Is it possible to create new variables for example with the
> assistance of for-loop without initialising them beforehand?

This way:
    sapply(1:10, function(i) your.task(i) )

sapply() will do the initialization for you!

Kjetil

> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Soren.Hojsgaard at agrsci.dk  Tue Feb 21 00:03:12 2006
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Tue, 21 Feb 2006 00:03:12 +0100
Subject: [R] need a R-code formatter?
References: <b1f16d9d0602142205w75274a27kb877c3b4107777ac@mail.gmail.com>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC038781E4@DJFPOST01.djf.agrsci.dk>

You can use emacs with ESS - and/or try to encourage (kindly) the creator of Tinn-R to create such a code-formatter...
Best
S??ren

________________________________

Fra: r-help-bounces at stat.math.ethz.ch p?? vegne af Michael
Sendt: on 15-02-2006 07:05
Til: R-help at stat.math.ethz.ch
Emne: [R] need a R-code formatter?



Hi all,

I am using Tin-R as my editor; I use it because it allows me to send several
selected lines to R-console and execute them...

In some sense, this is my line-by-line debugger.

But it doesn't have a code formatter, I have to layout the indention myself
-- when there are many { } blocks with different layers, this editor does
not help me beautify the code...

I am looking for some editor with better debugging support and with a R-code
formatter?

Thanks a lot!

Michael.

        [[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Soren.Hojsgaard at agrsci.dk  Tue Feb 21 00:01:08 2006
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Tue, 21 Feb 2006 00:01:08 +0100
Subject: [R] How to read more than 1 table?
References: <57116.130.232.44.35.1140471617.squirrel@webmail2.utu.fi>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC038781E2@DJFPOST01.djf.agrsci.dk>

for (k in list.files()){
...
}
best
S??ren

________________________________

Fra: r-help-bounces at stat.math.ethz.ch p?? vegne af Atte Tenkanen
Sendt: ma 20-02-2006 22:40
Til: r-help at stat.math.ethz.ch
Emne: [R] How to read more than 1 table?



Question 1) I want to read many csv-tables and run the same commands for
all of them. Is there some simpler solution than this below to solve this
problem?


for (g in 1:6)
{

if (g==1){k="kt1_0057"}
if (g==2){k="kt1_0101"}
if (g==3){k="kt1_0613"}
if (g==4){k="staten"}
if (g==5){k="tenpenny"}
if (g==6){k="fiddrunk"}

TABLE=read.table(paste("/home/user/",k,".csv",sep=""),sep = ",",
na.strings=".",header=F,fill=TRUE);

print(TABLE)

}

Question 2) Is it possible to create new variables for example with the
assistance of for-loop without initialising them beforehand?

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Tue Feb 21 00:12:23 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 20 Feb 2006 23:12:23 +0000 (GMT)
Subject: [R] Using LAPACK in C-code to be loaded in R -
	getting-started-help
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC038781E0@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC038781E0@DJFPOST01.djf.agrsci.dk>
Message-ID: <Pine.LNX.4.64.0602202307510.15360@gannet.stats.ox.ac.uk>

Are you talking about LAPACK (title) or LINPACK (body)?

On Mon, 20 Feb 2006, S??ren H??jsgaard wrote:

> I want to speed up computations (involving matrices) by writing some 
> C-code to be loaded. In the C-code, I need to invert matrices etc. As 
> I've understood the "writing R extensions" doc, I can use use #include 
> <R_ext/Linpack.h> in my .c-file and get access to linpack's facilities 
> within my C-code.
>
> Is that correct?

Only for some of the functions listed in that file: please consult it.

> If so, can anyone point me to examples on how this is actually done in 
> practice?

On CRAN,

Linpack: RandomFields fracdiff glmmML mgcv
LAPACK: lots, e.g, MNP kernlab knncat rmetasim supclust

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From aorchid at mac.com  Tue Feb 21 00:21:47 2006
From: aorchid at mac.com (Aric Gregson)
Date: Mon, 20 Feb 2006 15:21:47 -0800
Subject: [R] Unable to configure R 2.2.1 on Solaris 5.10 x86_64
Message-ID: <1140477707.3808.2.camel@unknown>

Hello,

Apologies for the post here. I have read the R-Admin (learned
a lot!) and searched the web for days, but still fail at compiling R on
my Ultra 20 running solaris 10 x86 1/06. 

This is the tail of './configure' output:
.....
checking for dlopen in -ldl... yes
checking readline/history.h usability... no
checking readline/history.h presence... no
checking for readline/history.h... no
checking readline/readline.h usability... no
checking readline/readline.h presence... no
checking for readline/readline.h... no
checking for rl_callback_read_char in -lreadline... no
checking for main in -lncurses... no
checking for main in -ltermcap... yes
checking for rl_callback_read_char in -lreadline... no
checking for history_truncate_file... no
configure: error: --with-readline=yes (default) and headers/libs are
not available 

My R-2.2.1/config.site has the following changes from default:

CC="cc -xtarget=opteron -xarch=amd64"
CFLAGS="-xO5 -xlibmil -dalign"
CPPFLAGS=-I/opt/sfw/include -I/opt/sfw/include/readline \
-I/opt/csw/include -I/opt/SUNWspro/include -I/opt/csw/include/readline
F77="f95 -xarch=amd64 -xtarget=opteron"
FFLAGS="-xO5 -xlibmil -dalign"
LDFLAGS=-L/opt/SUNWspro/lib/amd64/ -L/opt/sfw/lib -L/opt/csw/lib
CXX="CC -xarch=amd64 -xtarget=opteron"
CXXFLAGS="-xO5 -xlibmil -dalign"
R_BROWSER=mozilla
MAKE=gmake

My .zshrc file has the following (as I saw that some of the LDFLAGS
should match my LD_LIBRARY_PATH and CONFIG_SHELL=/bin/ksh):

LD_LIBRARY_PATH=/opt/sfw/include:/opt/sfw/include/readline:/usr/local/lib:/usr/X/lib:/usr/lib:/usr/ucblib:/lib:/usr/ccs/lib:/etc/lib:/usr/dt/lib:/opt/SUNWspro/lib/amd64/:/opt/sfw/lib:/opt/csw/lib

Readline (version 4.2 from the Sun Companion CD) is located
in /opt/sfw/include/readline. Both the readline.h and history.h files
are there. Version 5.0 is located in /opt/csw/include/readline (from
Blastwave). As you can see, I am new at compiling in general and
Solaris specifically. Any help would be greatly appreciated.

System information:

System = SunOS
Release = 5.10
KernelID = Generic_118844-26
Machine = i86pc
OEM# = 0
Origin# = 1
NumCPU = 1

thanks,

aric



From alain.paquette at umontreal.ca  Tue Feb 21 00:21:56 2006
From: alain.paquette at umontreal.ca (Alain Paquette)
Date: Mon, 20 Feb 2006 18:21:56 -0500
Subject: [R] linear discriminant analysis in MASS
Message-ID: <43FA4F14.1050607@umontreal.ca>

Hello R people

I now know how to run my discriminant analysis with the lda function in 
MASS:
lda.alain=lda(Groupes ~ Ht.D0 + Lc.Dc + Ram + IDF, gr, CV = FALSE)
and it works fine.

But I am missing a test and cannot find any help on how to get it, if it 
exist.

The "S" equivalent:
discrim(structure(.Data = Groupes ~ Ht.D0 + Lc.Dc + Ram + IDF, class = 
"formula"), data = gr, family = Canonical(cov.structure = 
"homoscedastic"), na.action = na.omit, prior = "proportional")
outputs a nice matrix of Mahalanobis distances between groups and even 
tests (Hotelling's T Squared) for significant distances.

Why don't I just take the "S" output you say?  Because like you, I'd 
rather put in my paper that I did it using R of course!
Does anyone know of a way to get this test out of lda?  Or of another R 
package that does it?

Thanks
Alain
(on peut me r??pondre en fran??ais aussi, ??videmment!)

-- 
Alain Paquette
Laboratoire d'??cologie v??g??tale
Institut de recherche en biologie v??g??tale
Universit?? de Montr??al
4101 rue Sherbrooke Est
Montr??al (Qu??bec) H1X 2B2
 
alain.paquette at umontreal.ca
labo (514) 872-8488
fax (514) 872-9406
http://www.irbv.umontreal.ca/francais/personnel/cogliastro-paquette.htm



From uhkeller at web.de  Tue Feb 21 01:04:02 2006
From: uhkeller at web.de (Ulrich Keller)
Date: Tue, 21 Feb 2006 01:04:02 +0100
Subject: [R] bVar slot of lmer objects and standard errors
In-Reply-To: <40e66e0b0512301305n2106e765t65bf944de45a681b@mail.gmail.com>
References: <F5ED48890E2ACB468D0F3A64989D335A0139629C@dc1ex3.air.org>
	<40e66e0b0512301305n2106e765t65bf944de45a681b@mail.gmail.com>
Message-ID: <43FA58F2.7090906@web.de>

Hello,

I'm sorry to resurrect this thread that I started almost two months ago. 
I've been pretty busy since I posted my question and the issue is not 
that high on my priority list. Thanks to all those who replied, and I 
hope I can tickle your interest again.

As a reminder, my question was how one can extract the conditional 
posterior variance of a random effect from the bVar slot of an lmer 
model. Thanks to your answers, I now understand that I have to use the 
diagonal elements of the conditional matrices. However, I am not quite 
sure what this means:

Douglas Bates wrote:
> I'd have to go back and check but I think that these are the upper
> triangles of the symmetric matrix (as Spencer suggested) that are the
> conditional variance-covariance matrices of the two-dimensional 
> random effects for each school up to a scale factor.  That is, I think
> each face needs to be multiplied by s^2 to get the actual
> variance-covariance matrix.

What is s^2? Where can I find it in the lmer object? I tried reading the 
source, but gave up fairly quickly. Thanks in advance for your replies, 
and this time I promise I'll be more responsive.


Uli

My original post:
> Hello,
>
> I am looking for a way to obtain standard errors for emprirical Bayes estimates of a model fitted with lmer (like the ones plotted on page 14 of the document available at http://www.eric.ed.gov/ERICDocs/data/ericdocs2/content_storage_01/0000000b/80/2b/b3/94.pdf). Harold Doran mentioned (http://tolstoy.newcastle.edu.au/~rking/R/help/05/08/10638.html) that  the posterior modes' variances can be found in the bVar slot of lmer objects. However, when I fit e.g. this model:
>
> lmertest1<-lmer(mathtot~1+(m_escs_c|schoolid),hlmframe)
>
> then lmertest1 at bVar$schoolid is a three-dimensional array with dimensions (2,2,28). The factor schoolid has 28 levels, and there are random effects for the intercept and m_escs_c, but what does the third dimension correspond to? In other words, what are the contents of bVar, and how can I use them to get standard errors?
>
> Thanks in advance for your answers and Merry Christmas,
>
> Uli Keller



From nshephard at gmail.com  Tue Feb 21 01:35:25 2006
From: nshephard at gmail.com (Neil Shephard)
Date: Tue, 21 Feb 2006 08:35:25 +0800
Subject: [R] Linux Distribution Choice
Message-ID: <31b34fca0602201635l28b2103blc747e1e0d320f5ae@mail.gmail.com>

I thought I'd add my vote for Gentoo, which has been my distro of
choice for some time (although Slackware is very good as well, and
teaches you a lot about *NIX in general).

The main advantage of gentoo is that updating is very easy using the
portage system (as pointed out by jon  butchar), but unlike other
distributions which have packages which are compiled for generic x86
architechtures, you get one that is custom compiled to your
architechture and with the options you want compiled in (throught the
USE flags).  This is the point that Alexandre Santos Aguiar was
making.

Its a little more complicated to install the say Ubuntu where you just
drop the disc in the CD-ROM and point and click you way through, but
the documentation is second to none, and is extremly detailed.  In
addition the forums are really useful as well (although you may want
to use Google to search them as the default search engine isn't that
brilliant).

If you were to go with this option then I would recommend writing your
own script for installing packages (again from source).  An example of
one that I have written can be found at
http://slack.ser.man.ac.uk/progs/R/scripts/install.genetics.R

This way all the packages are installed from source and custom compiled as well.

HTH's

Neil
--
"Religion is the work of the Devil" - Anon

Email - nshephard at gmail.com / neilshep at cyllene.uwa.edu.au

Website - http://slack.ser.man.ac.uk/
Blog - http://slack---line.blogspot.com/
Flickr - http://www.flickr.com/photos/slackline/



From mtb954 at gmail.com  Tue Feb 21 01:41:45 2006
From: mtb954 at gmail.com (mtb954@gmail.com)
Date: Mon, 20 Feb 2006 18:41:45 -0600
Subject: [R] How to sum values across multiple variables using a wildcard?
Message-ID: <e40d78ce0602201641t2c9aac89w4a2be86ebed2983b@mail.gmail.com>

I have a dataframe called "data" with 5 records (in rows) each of
which has been scored on each of many variables (in columns).

Five of the variables are named var1, var2, var3, var4, var5 using
headers. The other variables are named using other conventions.

I can create a new variable called var6 with the value 15 for each
record with this code:

> var6=var1+var2+var3+var4+var5

but this is tedious for my real dataset with dozens of variables. I
would rather use a wildcard to add up all the variables that begin
with "Var" like this pseudocode:

> Var6=sum(var*)

Any suggestions for implementing this in R? Thanks! Mark



From h.wickham at gmail.com  Tue Feb 21 01:49:25 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 20 Feb 2006 18:49:25 -0600
Subject: [R] do.call, browser and traceback
Message-ID: <f8e6ff050602201649h40e47c64u43307ae3cab716a9@mail.gmail.com>

A problem that I've encountered when using do.call a lot is very large
stack traces, eg:

f <- function(x) stop()
do.call(error, mtcars)
traceback()
f <- function(x) browser()
do.call(f, mtcars)

I have hacked together my own version of traceback to fix this by
limiting the length of each line to 80 characters, but I can't see any
way to do something similar for browser.  Any suggestions?

Thanks,

Hadley



From gray.calhoun at gmail.com  Tue Feb 21 01:52:51 2006
From: gray.calhoun at gmail.com (Gray Calhoun)
Date: Mon, 20 Feb 2006 16:52:51 -0800
Subject: [R] Tobit Regression (residual Assumption)
In-Reply-To: <43F14B1B.1040207@ozemail.com.au>
References: <830480cb0602121524qb527534g8dd43ab16c99cd22@mail.gmail.com>
	<43F14B1B.1040207@ozemail.com.au>
Message-ID: <ff1904540602201652u2f2c9f3fhe5009a8201097ac0@mail.gmail.com>

The second edition of Jeff Wooldridge's "Introductory Econometrics, a
modern approach" has a subsection on tobit regression and should be
widely available.  It was written for undergraduate economics majors.

--Gray

On 2/13/06, Jim Lemon <bitwrit at ozemail.com.au> wrote:
> Hi folks,
>
> I exchanged a couple of emails privately about tobit regression and
> advised that he (bambang pramono) ask the list for pointers to a basic,
> widely available, introductory reference. I think it would be a great
> help if someone would kindly suggest such a reference.
>
> Thanks,
> Jim
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>


--
Gray Calhoun

Economics Department
UC San Diego



From ggrothendieck at gmail.com  Tue Feb 21 01:58:54 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 20 Feb 2006 19:58:54 -0500
Subject: [R] do.call, browser and traceback
In-Reply-To: <f8e6ff050602201649h40e47c64u43307ae3cab716a9@mail.gmail.com>
References: <f8e6ff050602201649h40e47c64u43307ae3cab716a9@mail.gmail.com>
Message-ID: <971536df0602201658p5348089lb4afb0697c04f6de@mail.gmail.com>

If f is long then you can get some savings like this:

  do.call("f", mtcars)  # note: used "f" rather than f

This does not solve the whole problem but its a step.

On 2/20/06, hadley wickham <h.wickham at gmail.com> wrote:
> A problem that I've encountered when using do.call a lot is very large
> stack traces, eg:
>
> f <- function(x) stop()
> do.call(error, mtcars)
> traceback()
> f <- function(x) browser()
> do.call(f, mtcars)
>
> I have hacked together my own version of traceback to fix this by
> limiting the length of each line to 80 characters, but I can't see any
> way to do something similar for browser.  Any suggestions?
>
> Thanks,
>
> Hadley
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Tue Feb 21 02:01:24 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 20 Feb 2006 20:01:24 -0500
Subject: [R] How to sum values across multiple variables using a
	wildcard?
In-Reply-To: <e40d78ce0602201641t2c9aac89w4a2be86ebed2983b@mail.gmail.com>
References: <e40d78ce0602201641t2c9aac89w4a2be86ebed2983b@mail.gmail.com>
Message-ID: <971536df0602201701n5f15eb9cjc98608c983ce41a9@mail.gmail.com>

See:

?rowSums



On 2/20/06, mtb954 at gmail.com <mtb954 at gmail.com> wrote:
> I have a dataframe called "data" with 5 records (in rows) each of
> which has been scored on each of many variables (in columns).
>
> Five of the variables are named var1, var2, var3, var4, var5 using
> headers. The other variables are named using other conventions.
>
> I can create a new variable called var6 with the value 15 for each
> record with this code:
>
> > var6=var1+var2+var3+var4+var5
>
> but this is tedious for my real dataset with dozens of variables. I
> would rather use a wildcard to add up all the variables that begin
> with "Var" like this pseudocode:
>
> > Var6=sum(var*)
>
> Any suggestions for implementing this in R? Thanks! Mark
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From hodgess at gator.dt.uh.edu  Tue Feb 21 02:07:58 2006
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Mon, 20 Feb 2006 19:07:58 -0600
Subject: [R]  R and packages
Message-ID: <200602210107.k1L17wlS011803@gator.dt.uh.edu>

Dear R People:

Here is yet another strange problem.  

I'm using R in one of my classes.  However, the computer lab has something
called "Deep Freeze" and the students cannot save anything to the hard drive.

I had R installed and things were working well.  They would save their 
.Rdata files to disks.

Now, we need to add more packages.  We can't download and we can't
bring them in via zip files (already tried both!)  When the zip files
are expanded, of course they build new directories......

I'm completely annoyed because learning to download packages
and installing them from local zips are actually important tasks!
We're also losing good teaching/learning time!

Anyhow, what I would like to do is produce a sort of combination R 
installation exe with our extra libraries as part of the package.

Does anyone have any suggestions on how this could be done, please?

This is R for Windows, Version 2.2.1

Thanks for any help!  Sorry about the totally weird problem!

Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu



From blomsp at ozemail.com.au  Tue Feb 21 02:09:47 2006
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Tue, 21 Feb 2006 12:09:47 +1100
Subject: [R] How to sum values across multiple variables using a
	wildcard?
In-Reply-To: <e40d78ce0602201641t2c9aac89w4a2be86ebed2983b@mail.gmail.com>
References: <e40d78ce0602201641t2c9aac89w4a2be86ebed2983b@mail.gmail.com>
Message-ID: <43FA685B.4060701@ozemail.com.au>

data <- data.frame(var1=c(1,2,3), var2=c(3,4,5), var3=c(4,5,6), foo = 
c(100,200,300))
# sum rows with "var" in their name
rowSums(data[, grep("var", names(data))])

 1  2  3
 8 11 14



mtb954 at gmail.com wrote:
> I have a dataframe called "data" with 5 records (in rows) each of
> which has been scored on each of many variables (in columns).
>
> Five of the variables are named var1, var2, var3, var4, var5 using
> headers. The other variables are named using other conventions.
>
> I can create a new variable called var6 with the value 15 for each
> record with this code:
>
>   
>> var6=var1+var2+var3+var4+var5
>>     
>
> but this is tedious for my real dataset with dozens of variables. I
> would rather use a wildcard to add up all the variables that begin
> with "Var" like this pseudocode:
>
>   
>> Var6=sum(var*)
>>     
>
> Any suggestions for implementing this in R? Thanks! Mark
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>   


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Centre for Resource and Environmental Studies
The Australian National University
Canberra ACT 0200
Australia
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C



From MSchwartz at mn.rr.com  Tue Feb 21 02:18:47 2006
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Mon, 20 Feb 2006 19:18:47 -0600
Subject: [R] How to sum values across multiple variables using
	a	wildcard?
In-Reply-To: <e40d78ce0602201641t2c9aac89w4a2be86ebed2983b@mail.gmail.com>
References: <e40d78ce0602201641t2c9aac89w4a2be86ebed2983b@mail.gmail.com>
Message-ID: <1140484727.4518.13.camel@localhost.localdomain>

On Mon, 2006-02-20 at 18:41 -0600, mtb954 at gmail.com wrote:
> I have a dataframe called "data" with 5 records (in rows) each of
> which has been scored on each of many variables (in columns).
> 
> Five of the variables are named var1, var2, var3, var4, var5 using
> headers. The other variables are named using other conventions.
> 
> I can create a new variable called var6 with the value 15 for each
> record with this code:
> 
> > var6=var1+var2+var3+var4+var5
> 
> but this is tedious for my real dataset with dozens of variables. I
> would rather use a wildcard to add up all the variables that begin
> with "Var" like this pseudocode:
> 
> > Var6=sum(var*)
> 
> Any suggestions for implementing this in R? Thanks! Mark

Here is one approach using grep().

Given a data frame called MyDF with the following structure:

> str(MyDF)
`data.frame':	10 obs. of  20 variables:
 $ other4 : num  -0.869  0.376 -2.022  0.619 -0.129 ...
 $ var8   : num  -0.380  1.428 -1.075 -0.796 -0.588 ...
 $ var4   : num  -0.0850 -0.7335 -0.5019 -1.1633 -0.0197 ...
 $ other9 : num   0.0210 -0.6455  0.0289  1.2405 -1.3359 ...
 $ var10  : num   0.647 -0.798  0.180  1.135 -0.258 ...
 $ other2 : num   0.1332 -0.2227  0.0423  0.6881  2.0304 ...
 $ other10: num  0.811 2.166 0.569 0.302 0.669 ...
 $ var1   : num  -0.774 -1.812 -1.230 -0.969  0.245 ...
 $ var2   : num  -0.0538  0.3712  0.8222 -0.8025 -0.6914 ...
 $ other6 : num  0.871 0.291 2.079 1.098 1.025 ...
 $ other1 : num  -0.5130  0.1358  0.8744  0.0997  1.7458 ...
 $ var9   : num   0.664 -0.456  0.415  2.090 -0.283 ...
 $ other3 : num  -0.425 -0.283  0.706 -1.879 -0.828 ...
 $ other7 : num   0.100  0.177  0.570 -0.631 -1.009 ...
 $ var3   : num   1.446 -0.862  0.184  1.077  0.146 ...
 $ var5   : num   0.402 -0.498 -0.906  0.641  1.690 ...
 $ var6   : num   0.892 -0.242  0.561  0.530 -0.291 ...
 $ other5 : num  -1.210  0.815 -1.284 -0.152  0.329 ...
 $ other8 : num  -0.265 -1.278  1.152  0.232 -1.189 ...
 $ var7   : num  -0.616 -0.994 -0.263  1.626 -1.372 ...


Note that the column names are either var* or other*.

Using grep() we get the indices of the column names that contain "other"
plus one or more following characters, where the "other" begins the
word:

> grep("\\bother.", names(MyDF))
 [1]  1  4  6  7 10 11 13 14 18 19

See ?regexp for more information. Note that I use "\\b" to being the
search at the starting word boundary and then "." to require that there
be following characters. Thus, this would not match " other1" or
" other".

You can then use the following to subset the data frame MyDF and sum the
rows for the requested columns:

> rowSums(MyDF[, grep("\\bother.", names(MyDF))])
        1         2         3         4         5         6         7 
-1.344893  1.531417  2.715234  1.616971  1.307379  4.655568  4.638446 
        8         9        10 
-2.640485 -2.226270 -2.158248 


You could use grep("other", names(MyDF)), but this would also get
"other" if it appears anywhere in the name. For example:

> grep("other", "Thisotherone")
[1] 1

It just depends upon your naming schema and how strict you need to be in
the search.

HTH,

Marc Schwartz



From mtb954 at gmail.com  Tue Feb 21 02:32:07 2006
From: mtb954 at gmail.com (mtb954@gmail.com)
Date: Mon, 20 Feb 2006 19:32:07 -0600
Subject: [R] How to sum values across multiple variables using a
	wildcard?
In-Reply-To: <1140484727.4518.13.camel@localhost.localdomain>
References: <e40d78ce0602201641t2c9aac89w4a2be86ebed2983b@mail.gmail.com>
	<1140484727.4518.13.camel@localhost.localdomain>
Message-ID: <e40d78ce0602201732p66bfe7f5y69e14fc4cca4fd74@mail.gmail.com>

Thanks Gabor, Simon and Marc...I got this to work with the grep() and
rowSums examples  you provided.

Mark


On 2/20/06, Marc Schwartz <MSchwartz at mn.rr.com> wrote:
> On Mon, 2006-02-20 at 18:41 -0600, mtb954 at gmail.com wrote:
> > I have a dataframe called "data" with 5 records (in rows) each of
> > which has been scored on each of many variables (in columns).
> >
> > Five of the variables are named var1, var2, var3, var4, var5 using
> > headers. The other variables are named using other conventions.
> >
> > I can create a new variable called var6 with the value 15 for each
> > record with this code:
> >
> > > var6=var1+var2+var3+var4+var5
> >
> > but this is tedious for my real dataset with dozens of variables. I
> > would rather use a wildcard to add up all the variables that begin
> > with "Var" like this pseudocode:
> >
> > > Var6=sum(var*)
> >
> > Any suggestions for implementing this in R? Thanks! Mark
>
> Here is one approach using grep().
>
> Given a data frame called MyDF with the following structure:
>
> > str(MyDF)
> `data.frame':   10 obs. of  20 variables:
>  $ other4 : num  -0.869  0.376 -2.022  0.619 -0.129 ...
>  $ var8   : num  -0.380  1.428 -1.075 -0.796 -0.588 ...
>  $ var4   : num  -0.0850 -0.7335 -0.5019 -1.1633 -0.0197 ...
>  $ other9 : num   0.0210 -0.6455  0.0289  1.2405 -1.3359 ...
>  $ var10  : num   0.647 -0.798  0.180  1.135 -0.258 ...
>  $ other2 : num   0.1332 -0.2227  0.0423  0.6881  2.0304 ...
>  $ other10: num  0.811 2.166 0.569 0.302 0.669 ...
>  $ var1   : num  -0.774 -1.812 -1.230 -0.969  0.245 ...
>  $ var2   : num  -0.0538  0.3712  0.8222 -0.8025 -0.6914 ...
>  $ other6 : num  0.871 0.291 2.079 1.098 1.025 ...
>  $ other1 : num  -0.5130  0.1358  0.8744  0.0997  1.7458 ...
>  $ var9   : num   0.664 -0.456  0.415  2.090 -0.283 ...
>  $ other3 : num  -0.425 -0.283  0.706 -1.879 -0.828 ...
>  $ other7 : num   0.100  0.177  0.570 -0.631 -1.009 ...
>  $ var3   : num   1.446 -0.862  0.184  1.077  0.146 ...
>  $ var5   : num   0.402 -0.498 -0.906  0.641  1.690 ...
>  $ var6   : num   0.892 -0.242  0.561  0.530 -0.291 ...
>  $ other5 : num  -1.210  0.815 -1.284 -0.152  0.329 ...
>  $ other8 : num  -0.265 -1.278  1.152  0.232 -1.189 ...
>  $ var7   : num  -0.616 -0.994 -0.263  1.626 -1.372 ...
>
>
> Note that the column names are either var* or other*.
>
> Using grep() we get the indices of the column names that contain "other"
> plus one or more following characters, where the "other" begins the
> word:
>
> > grep("\\bother.", names(MyDF))
>  [1]  1  4  6  7 10 11 13 14 18 19
>
> See ?regexp for more information. Note that I use "\\b" to being the
> search at the starting word boundary and then "." to require that there
> be following characters. Thus, this would not match " other1" or
> " other".
>
> You can then use the following to subset the data frame MyDF and sum the
> rows for the requested columns:
>
> > rowSums(MyDF[, grep("\\bother.", names(MyDF))])
>         1         2         3         4         5         6         7
> -1.344893  1.531417  2.715234  1.616971  1.307379  4.655568  4.638446
>         8         9        10
> -2.640485 -2.226270 -2.158248
>
>
> You could use grep("other", names(MyDF)), but this would also get
> "other" if it appears anywhere in the name. For example:
>
> > grep("other", "Thisotherone")
> [1] 1
>
> It just depends upon your naming schema and how strict you need to be in
> the search.
>
> HTH,
>
> Marc Schwartz
>
>
>



From murdoch at stats.uwo.ca  Tue Feb 21 02:45:41 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 20 Feb 2006 20:45:41 -0500
Subject: [R] R and packages
In-Reply-To: <200602210107.k1L17wlS011803@gator.dt.uh.edu>
References: <200602210107.k1L17wlS011803@gator.dt.uh.edu>
Message-ID: <43FA70C5.3070506@stats.uwo.ca>

On 2/20/2006 8:07 PM, Erin Hodgess wrote:
> Dear R People:
> 
> Here is yet another strange problem.  
> 
> I'm using R in one of my classes.  However, the computer lab has something
> called "Deep Freeze" and the students cannot save anything to the hard drive.
> 
> I had R installed and things were working well.  They would save their 
> .Rdata files to disks.
> 
> Now, we need to add more packages.  We can't download and we can't
> bring them in via zip files (already tried both!)  When the zip files
> are expanded, of course they build new directories......

You can probably use .libPaths() to add a new install location that is 
writeable.  You'll likely get a few error messages because R can't 
update the help indices, but the packages should be available.
> 
> I'm completely annoyed because learning to download packages
> and installing them from local zips are actually important tasks!
> We're also losing good teaching/learning time!
> 
> Anyhow, what I would like to do is produce a sort of combination R 
> installation exe with our extra libraries as part of the package.

You could also do this, if you have the tools installed to do a build. 
See the R Installation and Administration manual, Installing R Under 
Windows, Building from Source, Building the Installer (section 3.1.9 in 
the PDF version).  You can either build with extra packages from source, 
or make an image from an installed copy.  In either case you'll need to 
install a lot of build tools, but fewer for the second option.

Duncan Murdoch

> 
> Does anyone have any suggestions on how this could be done, please?
> 
> This is R for Windows, Version 2.2.1
> 
> Thanks for any help!  Sorry about the totally weird problem!
> 
> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From murdoch at stats.uwo.ca  Tue Feb 21 02:46:55 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 20 Feb 2006 20:46:55 -0500
Subject: [R] R and packages
In-Reply-To: <200602210107.k1L17wlS011803@gator.dt.uh.edu>
References: <200602210107.k1L17wlS011803@gator.dt.uh.edu>
Message-ID: <43FA710F.3010601@stats.uwo.ca>

On 2/20/2006 8:07 PM, Erin Hodgess wrote:
 > Dear R People:
 >
 > Here is yet another strange problem.
 >
 > I'm using R in one of my classes.  However, the computer lab has 
something
 > called "Deep Freeze" and the students cannot save anything to the 
hard drive.
 >
 > I had R installed and things were working well.  They would save their
 > .Rdata files to disks.
 >
 > Now, we need to add more packages.  We can't download and we can't
 > bring them in via zip files (already tried both!)  When the zip files
 > are expanded, of course they build new directories......

You can probably use .libPaths() to add a new install location that is 
writeable.  You'll likely get a few error messages because R can't 
update the help indices, but the packages should be available.
 >
 > I'm completely annoyed because learning to download packages
 > and installing them from local zips are actually important tasks!
 > We're also losing good teaching/learning time!
 >
 > Anyhow, what I would like to do is produce a sort of combination R
 > installation exe with our extra libraries as part of the package.

You could also do this, if you have the tools installed to do a build. 
See the R Installation and Administration manual, Installing R Under 
Windows, Building from Source, Building the Installer (section 3.1.9 in 
the PDF version).  You can either build with extra packages from source, 
or make an image from an installed copy.  In either case you'll need to 
install a lot of build tools, but fewer for the second option.

Duncan Murdoch

 >
 > Does anyone have any suggestions on how this could be done, please?
 >
 > This is R for Windows, Version 2.2.1
 >
 > Thanks for any help!  Sorry about the totally weird problem!
 >
 > Sincerely,
 > Erin Hodgess
 > Associate Professor
 > Department of Computer and Mathematical Sciences
 > University of Houston - Downtown
 > mailto: hodgess at gator.uhd.edu
 >
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help



From ligges at statistik.uni-dortmund.de  Tue Feb 21 08:00:37 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 21 Feb 2006 08:00:37 +0100
Subject: [R] need a R-code formatter?
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC038781E4@DJFPOST01.djf.agrsci.dk>
References: <b1f16d9d0602142205w75274a27kb877c3b4107777ac@mail.gmail.com>
	<C83C5E3DEEE97E498B74729A33F6EAEC038781E4@DJFPOST01.djf.agrsci.dk>
Message-ID: <43FABA95.8090401@statistik.uni-dortmund.de>

S??ren H??jsgaard wrote:
> You can use emacs with ESS - and/or try to encourage (kindly) the creator of Tinn-R to create such a code-formatter...

... or contribute the code formatter to the Tinn-R project which is one 
of the great ideas of Open Source software. The Tinn-R developers will 
be happy, certainly.

Uwe Ligges



> Best
> S??ren
> 
> ________________________________
> 
> Fra: r-help-bounces at stat.math.ethz.ch p?? vegne af Michael
> Sendt: on 15-02-2006 07:05
> Til: R-help at stat.math.ethz.ch
> Emne: [R] need a R-code formatter?
> 
> 
> 
> Hi all,
> 
> I am using Tin-R as my editor; I use it because it allows me to send several
> selected lines to R-console and execute them...
> 
> In some sense, this is my line-by-line debugger.
> 
> But it doesn't have a code formatter, I have to layout the indention myself
> -- when there are many { } blocks with different layers, this editor does
> not help me beautify the code...
> 
> I am looking for some editor with better debugging support and with a R-code
> formatter?
> 
> Thanks a lot!
> 
> Michael.
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Tue Feb 21 08:04:06 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 21 Feb 2006 08:04:06 +0100
Subject: [R] how to close all windows?
In-Reply-To: <b1f16d9d0602160307p3215b733qc34f206b25098b29@mail.gmail.com>
References: <b1f16d9d0602160307p3215b733qc34f206b25098b29@mail.gmail.com>
Message-ID: <43FABB66.3070006@statistik.uni-dortmund.de>

Michael wrote:
> Hi all,
> 
> I have 10+ graphic windows and 10+ R help window opening now...
> 
> How do I close them all at once?
> 
> Thanks a lot!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


See ?graphics.off

Uwe Ligges



From spluque at gmail.com  Tue Feb 21 08:20:25 2006
From: spluque at gmail.com (Sebastian Luque)
Date: Tue, 21 Feb 2006 01:20:25 -0600
Subject: [R] indexing within panels in xyplot
Message-ID: <87mzglgoue.fsf@arctocephalus.homelinux.org>

Dear R-helpers,

I need to show a linear fit through a subset of the data within each
combination of levels of two factors.  So I prepared an xyplot with
different panels for each level of one of the factors, and different
symbols within each panel for the levels of the second factor.  My problem
is selecting the subset of each combination through which the line should
be fit for subsequent plotting.  This hopefully shows the idea:


---<---------------cut here---------------start-------------->---
toydf <- expand.grid(1:100, c("A", "B"),
                     c("pop1", "pop2", "pop3", "pop4", "pop5"))
toydf <- data.frame(facA = toydf[[3]], facB = toydf[[2]],
                    x = toydf[[1]], y = rnorm(1000))

xyplot(y ~ x | facA, groups = facB, data = toydf,
       panel.groups = function(x, y, subscripts, ...) {
         panel.xyplot(x, y, ...)
         lindx <- which(y[subscripts] == max(y[subscripts], na.rm = TRUE))
         xleft <- mean(x[lindx], na.rm = TRUE)
         fit <- lm(y[x >= xleft] ~ x[x >= xleft])
         panel.abline(fit)
       })
---<---------------cut here---------------end---------------->---

i.e. the left limit for fitting the line is defined by the mean of x
values where y is equal to the maximum y values, *within* each combination
of levels of both factors.  The above is giving me:

Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
	0 (non-NA) cases
In addition: Warning message:
no finite arguments to max; returning -Inf 

which shows I'm not understanding how the 'subscripts' argument works.
I'd appreciate some pointers on what I'm doing wrong, as I haven't been
able to find help in the help pages and List archives.

Thanks,

-- 
Sebastian P. Luque



From ligges at statistik.uni-dortmund.de  Tue Feb 21 08:25:37 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 21 Feb 2006 08:25:37 +0100
Subject: [R] Group a dinamic number of vectors in a data.frame
In-Reply-To: <1140448926.24883.16.camel@localhost.localdomain>
References: <1140448926.24883.16.camel@localhost.localdomain>
Message-ID: <43FAC071.4030107@statistik.uni-dortmund.de>

Daniele Medri wrote:

> Hi all,
> 
> I need to create a data.frame from a variable number of vectors.
> The number of these vectors could change so I need a dinamic way to
> group all in a data.frame. The number is length(abc).
> 
> e.g. vectors in my workspace
> 
> N1 <-c(1,2,3,4)
> N2 <-c(1,2,3,4)
> N3 <-c(1,2,3,4)
> abc <-c(1,2,3)
> 
> the data.frame I want to create:
> 
> tcm <-data.frame(OneVector, TwoVector,  paste("N",1:length(abc)))
> 
> Obviously :) if I am here this approach doesn't work, so any kind of tip
> is welcome.

For example:

   lab <- paste("N", seq(along=abc), sep="")
   D <- data.frame(lapply(lab, get))
   names(D) <- lab

Uwe Ligges



> Cheers



From jwd at surewest.net  Tue Feb 21 08:40:49 2006
From: jwd at surewest.net (J Dougherty)
Date: Mon, 20 Feb 2006 23:40:49 -0800
Subject: [R] R and packages
In-Reply-To: <200602210107.k1L17wlS011803@gator.dt.uh.edu>
References: <200602210107.k1L17wlS011803@gator.dt.uh.edu>
Message-ID: <200602202340.49869.jwd@surewest.net>

You want to take the sysad by the hairy of his chinny-chin-chin and explain 
the issue in short sentences.  He or she ought to be able produce a solution 
without difficulty, and should not have any problems about doing so.  It IS 
their job.  

JD  

On Monday 20 February 2006 17:07, Erin Hodgess wrote:
> Dear R People:
>
> Here is yet another strange problem.
>
> I'm using R in one of my classes.  However, the computer lab has something
> called "Deep Freeze" and the students cannot save anything to the hard
> drive.
>
> I had R installed and things were working well.  They would save their
> .Rdata files to disks.
>
> Now, we need to add more packages.  We can't download and we can't
> bring them in via zip files (already tried both!)  When the zip files
> are expanded, of course they build new directories......
>
> I'm completely annoyed because learning to download packages
> and installing them from local zips are actually important tasks!
> We're also losing good teaching/learning time!
>
> Anyhow, what I would like to do is produce a sort of combination R
> installation exe with our extra libraries as part of the package.
>
> Does anyone have any suggestions on how this could be done, please?
>
> This is R for Windows, Version 2.2.1
>
> Thanks for any help!  Sorry about the totally weird problem!
>
> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From ahenningsen at email.uni-kiel.de  Tue Feb 21 08:42:44 2006
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Tue, 21 Feb 2006 08:42:44 +0100
Subject: [R] Heckman regression / adjustment for standard errors?
In-Reply-To: <84C59624B1B0204BBCB3B7DDF981AE63010AD19D@GWB-PO.gwb.wustl.edu>
References: <84C59624B1B0204BBCB3B7DDF981AE63010AD19D@GWB-PO.gwb.wustl.edu>
Message-ID: <200602210842.44704.ahenningsen@email.uni-kiel.de>

Hi Brian,

On Friday 17 February 2006 22:30, Brian Perron wrote:
> Hello folks,
>
> I am trying to estimate the two-step Heckman regression model.  I would
> like to make an adjustment for intragroup correlations.  Stata can
> implement this with the "cluster" option, but I am really hoping to stick
> with R.  It seems that the micEcon package is the primary source for this
> two-step regression model (i.e., heckit), but I can't find a way to make
> the adjustment.  Am I overlooking something with this package or other
> packages?

The heckit() function in the micEcon package definitively has no "cluster" 
option. Unfortunately, I don't know anything about adjustment for intragroup 
correlations in heckman type estimations. Is this difficult to implement? Do 
you know a description of this procedure? (Maybe we can do this together.)

Arne


> Brian
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From FredeA.Togersen at agrsci.dk  Tue Feb 21 08:57:11 2006
From: FredeA.Togersen at agrsci.dk (=?iso-8859-1?Q?Frede_Aakmann_T=F8gersen?=)
Date: Tue, 21 Feb 2006 08:57:11 +0100
Subject: [R] indexing within panels in xyplot
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC04244549@DJFPOST01.djf.agrsci.dk>


Based on your two first sentences I think the solution is to use

xyplot(y ~ x | facA, groups = facB, data = toydf,type=c("p","r"))

Try it and see if this is what you want.


Best regards

Frede Aakmann T??gersen
Scientist


Danish Institute of Agricultural Sciences
Research Centre Foulum
Dept. of Genetics and Biotechnology
Blichers All?? 20, P.O. BOX 50
DK-8830 Tjele

Phone:   +45 8999 1900
Direct:  +45 8999 1878

E-mail:  FredeA.Togersen at agrsci.dk
Web:	   http://www.agrsci.org				

This email may contain information that is confidential.
Any use or publication of this email without written permission from DIAS is not allowed.
If you are not the intended recipient, please notify DIAS immediately and delete this email.



 

> -----Oprindelig meddelelse-----
> Fra: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] P?? vegne af Sebastian Luque
> Sendt: 21. februar 2006 08:20
> Til: r-help at stat.math.ethz.ch
> Emne: [R] indexing within panels in xyplot
> 
> Dear R-helpers,
> 
> I need to show a linear fit through a subset of the data 
> within each combination of levels of two factors.  So I 
> prepared an xyplot with different panels for each level of 
> one of the factors, and different symbols within each panel 
> for the levels of the second factor.  My problem is selecting 
> the subset of each combination through which the line should 
> be fit for subsequent plotting.  This hopefully shows the idea:
> 
> 
> ---<---------------cut here---------------start-------------->---
> toydf <- expand.grid(1:100, c("A", "B"),
>                      c("pop1", "pop2", "pop3", "pop4", 
> "pop5")) toydf <- data.frame(facA = toydf[[3]], facB = toydf[[2]],
>                     x = toydf[[1]], y = rnorm(1000))
> 
> xyplot(y ~ x | facA, groups = facB, data = toydf,
>        panel.groups = function(x, y, subscripts, ...) {
>          panel.xyplot(x, y, ...)
>          lindx <- which(y[subscripts] == max(y[subscripts], 
> na.rm = TRUE))
>          xleft <- mean(x[lindx], na.rm = TRUE)
>          fit <- lm(y[x >= xleft] ~ x[x >= xleft])
>          panel.abline(fit)
>        })
> ---<---------------cut here---------------end---------------->---
> 
> i.e. the left limit for fitting the line is defined by the 
> mean of x values where y is equal to the maximum y values, 
> *within* each combination of levels of both factors.  The 
> above is giving me:
> 
> Error in lm.fit(x, y, offset = offset, singular.ok = 
> singular.ok, ...) : 
> 	0 (non-NA) cases
> In addition: Warning message:
> no finite arguments to max; returning -Inf 
> 
> which shows I'm not understanding how the 'subscripts' argument works.
> I'd appreciate some pointers on what I'm doing wrong, as I 
> haven't been able to find help in the help pages and List archives.
> 
> Thanks,
> 
> --
> Sebastian P. Luque
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ripley at stats.ox.ac.uk  Tue Feb 21 09:01:15 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Feb 2006 08:01:15 +0000 (GMT)
Subject: [R] linear discriminant analysis in MASS
In-Reply-To: <43FA4F14.1050607@umontreal.ca>
References: <43FA4F14.1050607@umontreal.ca>
Message-ID: <Pine.LNX.4.64.0602210741531.30785@gannet.stats.ox.ac.uk>

On Mon, 20 Feb 2006, Alain Paquette wrote:

> Hello R people
>
> I now know how to run my discriminant analysis with the lda function in
> MASS:
> lda.alain=lda(Groupes ~ Ht.D0 + Lc.Dc + Ram + IDF, gr, CV = FALSE)
> and it works fine.

CV=FALSE is the default and so not needed.

> But I am missing a test and cannot find any help on how to get it, if it
> exist.
>
> The "S" equivalent:

There is no such function in S, and I rather object as the S equivalent is 
lda() (and as the author of both I should know).  Credit where credit is 
due: discrim() is an S-PLUS function, indebted to lda().

> discrim(structure(.Data = Groupes ~ Ht.D0 + Lc.Dc + Ram + IDF, class =
> "formula"), data = gr, family = Canonical(cov.structure =
> "homoscedastic"), na.action = na.omit, prior = "proportional")
> outputs a nice matrix of Mahalanobis distances between groups and even
> tests (Hotelling's T Squared) for significant distances.

Well, it seems not to.  That is part of the output of the summary() 
method, which itself calls the multicomp() method.

> Why don't I just take the "S" output you say?  Because like you, I'd
> rather put in my paper that I did it using R of course!

No `of course' applies. If you learnt of this output from S-PLUS, I urge 
you to credit it honestly and accurately.  (If you refer to lda, you 
should credit that, not just R.)

> Does anyone know of a way to get this test out of lda?  Or of another R
> package that does it?

Mahalanobis distance between groups is easy, as this is just Euclidean 
distance between group centres in the scaled space.  The test statistics 
can be produced, but

- they are critically dependent on the unrealistic assumptions of 
multivariate normality and variance homogeneity and

- there needs to be an adjustment for multiple comparisons.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Erlend.Nilsen at sue.hihm.no  Tue Feb 21 09:50:15 2006
From: Erlend.Nilsen at sue.hihm.no (Erlend Birkeland Nilsen)
Date: Tue, 21 Feb 2006 09:50:15 +0100
Subject: [R] Extracting error terms from an lme object
In-Reply-To: <mailman.0.1140470724.22925.r-help@stat.math.ethz.ch>
Message-ID: <000001c636c3$d5cd6c10$6215249e@bio90231>

Hi all,

I have a problem with extracting the right error terms from an lme-object.
The fixed part of the model is quite simple (y~x1*x2, where x1 and x2 are
factor variables with two levels), with random intercepts (random=~1|group).
As I work with factor variables here, I would like to display this with a
barplot (or something like that), with error bars representing the sem or sd
of the mean values for each group (i.e. four bars). However, I have not
figured out how to extract sem (sd) values for these means, or actually what
would be the appropriate error terms to use here. The summary.lme function
only provides me with the se for the parameter estimates (intercept and
slopes) while I want to display error terms for the different levels. Could
this be achieved by setting up an appropriate contrast matrix (or would any
of the established contrasts methods work), or is there another way of
getting error estimates that I could use in such a figure?

All the best, 

Erlend Nilsen



From phgrosjean at sciviews.org  Tue Feb 21 09:58:24 2006
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue, 21 Feb 2006 09:58:24 +0100
Subject: [R] how to close all windows?
In-Reply-To: <43FABB66.3070006@statistik.uni-dortmund.de>
References: <b1f16d9d0602160307p3215b733qc34f206b25098b29@mail.gmail.com>
	<43FABB66.3070006@statistik.uni-dortmund.de>
Message-ID: <43FAD630.3000205@sciviews.org>

?graphics.off is for graphic windows only. You don't tell us, but I 
assume you are working with RGui under Windows. If you don't want many 
help windows, you can still change it in Edit -> GUI preferences -> 
Pager style -> single window.
Best,

Philippe Grosjean



Uwe Ligges wrote:
> Michael wrote:
> 
>>Hi all,
>>
>>I have 10+ graphic windows and 10+ R help window opening now...
>>
>>How do I close them all at once?
>>
>>Thanks a lot!
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> 
> See ?graphics.off
> 
> Uwe Ligges
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From katrin at hunt.ch  Tue Feb 21 10:03:22 2006
From: katrin at hunt.ch (katrin@hunt.ch)
Date: Tue, 21 Feb 2006 10:03:22 +0100
Subject: [R] Calculate R-Square for existing predictors
Message-ID: <1140512602.43fad75a55697@www.mail2web.ch>

Hello everybody,

in the past months I have developed a model to predict the mortality rate of
Acute Myocardial Infarction Patients. My evaluation was mainly based on ROC
Curves etc. 
I have now been asked to calculate the R-Square of my model, another existing
model in regards to the actual mortality rate. So far I have only found a
function calculating a regression, and then the R-Square of the calculated
Regression.
Is there a function to calculate the R-Square for existing models?

Thanks for your help

Katrin



From petr.pikal at precheza.cz  Tue Feb 21 10:36:28 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 21 Feb 2006 10:36:28 +0100
Subject: [R] how to close all windows?
In-Reply-To: <43FAD630.3000205@sciviews.org>
References: <43FABB66.3070006@statistik.uni-dortmund.de>
Message-ID: <43FAED2C.31116.A0887F@localhost>

Or you can modify Rprofile.site with

options(htmlhelp=TRUE)

and get your help in HTML browser, which can be sometimes more 
convenient due to hyperlinks.

Best regards
Petr


On 21 Feb 2006 at 9:58, Philippe Grosjean wrote:

Date sent:      	Tue, 21 Feb 2006 09:58:24 +0100
From:           	Philippe Grosjean <phgrosjean at sciviews.org>
Organization:   	SciViews & UMH - EcoNum
To:             	Uwe Ligges <ligges at statistik.uni-dortmund.de>
Copies to:      	R-help at stat.math.ethz.ch
Subject:        	Re: [R] how to close all windows?

> ?graphics.off is for graphic windows only. You don't tell us, but I
> assume you are working with RGui under Windows. If you don't want many
> help windows, you can still change it in Edit -> GUI preferences ->
> Pager style -> single window. Best,
> 
> Philippe Grosjean
> 
> 
> 
> Uwe Ligges wrote:
> > Michael wrote:
> > 
> >>Hi all,
> >>
> >>I have 10+ graphic windows and 10+ R help window opening now...
> >>
> >>How do I close them all at once?
> >>
> >>Thanks a lot!
> >>
> >>	[[alternative HTML version deleted]]
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide!
> >>http://www.R-project.org/posting-guide.html
> > 
> > 
> > 
> > See ?graphics.off
> > 
> > Uwe Ligges
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From csardi at rmki.kfki.hu  Tue Feb 21 10:59:22 2006
From: csardi at rmki.kfki.hu (Gabor Csardi)
Date: Tue, 21 Feb 2006 10:59:22 +0100
Subject: [R] power law
In-Reply-To: <1AFEC6AD98A0AA4D948216A768A1578C480CD2@e2k3ms3.urmc-sh.rochester.edu>
References: <1AFEC6AD98A0AA4D948216A768A1578C480CD2@e2k3ms3.urmc-sh.rochester.edu>
Message-ID: <20060221095921.GA7965@szaffi.rmki.kfki.hu>

See the methods here:
http://arxiv.org/abs/cond-mat/0412004
You can simply use the formula given here for continuous data. 

Discrete data is a bit more tricky, this is the function I'm using:

# -------------------------------------------------
power.law.fit <- function(x, xmin=NULL, start=2, ...) {

  if (length(x) == 0) {
    error("zero length vector")
  }
  if (length(x) == 1) {
    error("vector should be at least of length two")
  }  

  require(stats4)
		    
  if (is.null(xmin)) { xmin <- min(x) }
		        
  n <- length(x)
  x <- x[ x >= xmin]
  if (length(x) != n) {
    warning("too small values eliminated from vector")
    n <- length(x)
  }
					  
  mlogl <- function(alpha) {
     C <- 1/sum( (xmin:10000)^-alpha )
     -n*log(C)+alpha*sum(log(x))
  }
	      
  alpha <- mle(mlogl, start=list(alpha=start), ...)
		
  alpha
}
# -------------------------------------------------

The function (with is manual page) is also included in the igraph package,
see http://cneurocvs.rmki.kfki.hu/igraph

Hope this helps,
Gabor

On Wed, Feb 15, 2006 at 08:07:50AM -0500, Glazko, Galina wrote:
> Dear list,
> 
>  
> 
> Does anyone know how to fit the power law distribution?
> 
> I have the empirical distribution and would like to check whether it fits
> 
> power law (with the power estimated from the data).
> 
>  
> 
> Any hints are appreciated
> 
>  
> 
> Best regards
> 
> Galina
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Csardi Gabor <csardi at rmki.kfki.hu>    MTA RMKI, ELTE TTK



From pburns at pburns.seanet.com  Tue Feb 21 11:26:44 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 21 Feb 2006 10:26:44 +0000
Subject: [R] var-covar matrices comparison:
In-Reply-To: <43FA462B.9020304@wustl.edu>
References: <43FA462B.9020304@wustl.edu>
Message-ID: <43FAEAE4.6020402@pburns.seanet.com>

My first thought is to use a random permutation test.
In this setting the main question you need to ask is
what distance measure do you want to use between
variance matrices -- there are lots of choices.  One
that I've found useful is the absolute value of the
maximum eigenvalue of the difference of the matrices.

If you have a hypothesis about how the variances may
differ, then you should be able to come up with a more
powerful statistic.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Aldi Kraja wrote:

>Hi,
>Using package gclus in R, I have created some graphs that show the 
>trends within subgroups of data and correlations among 9 variables (v1-v9).
>Being interested for more details on these data I have produced also the 
>var-covar matrices.
>Question: From a pair of two subsets of data (with 9 variables each, I 
>have two var-covar matrices for each subgroup, that differ for a 
>treatment on one group (treatment A) vs (non-Treatment A).
>
>Is there a software that can compare if two var-covar matrices are 
>statistically the same?
>
>Below are a pair of two matrices, from several others.
>Thank you in advance for any input.
>Aldi
>
> First group var-covar matrix (the data were under treatment a)
>
>v1        v2                 v3          v4               v5       
>v6       v7            v8             v9
>
> 
>
>v1         730.87       3.406      -283.41        -74.68       
>107.57      -1355.13      -112.46      14.000       5.776
>
>v2             3.41      24.950       105.45       -121.31      
>-307.68       -285.40        29.65      -2.500      -7.796
>
>v3          -283.41     105.451      6292.19      -2676.46      
>-970.80      29296.23     10715.29       3.156     -66.313
>
>v4           -74.68    -121.307     -2676.46     124492.30     
>-2289.47     -20377.34      -409.71     183.500     563.102
>
>v5           107.57    -307.681      -970.80      -2289.47      
>7045.62      12118.09       954.51      38.258      96.355
>
>v6         -1355.13    -285.404     29296.23     -20377.34     
>12118.09     218555.93     70126.71     137.000    -130.667
>
>v7          -112.46      29.645     10715.29       -409.71       
>954.51      70126.71     28239.57      67.989     -26.370
>
>v8            14.00      -2.500         3.16        183.50        
>38.26        137.00        67.99      24.500       9.000
>
>v9             5.78      -7.796       -66.31        563.10        
>96.35       -130.67       -26.37       9.000      22.776
>
> 
>
> 
>
> Second group var-covar matrix (the data were NOT under treatment a)
>
>v1        v2                 v3          v4               v5       
>v6       v7            v8             v9
>
> 
>
>v1          2696.25       27.05       201.06       2745.54      
>-344.39        540.48        654.20      34.363       7.623
>
>v2            27.05       86.37       -96.89       -497.28     
>-1185.10      -3108.71       -910.38      -4.254      -9.115
>
>v3           201.06      -96.89     10647.26       8378.07      
> 595.81      66122.43      26237.21     -65.093     -51.998
>
>v4          2745.54     -497.28      8378.07     408391.25     
>-3887.28      40477.40      30652.01     450.539      50.311
>
>v5          -344.39    -1185.10       595.81      -3887.28     
>29204.00      65320.00      15238.41     -98.237     102.975
>
>v6           540.48    -3108.71     66122.43      40477.40     
>65320.00     549955.14     194691.90    -555.552     -95.210
>
>v7           654.20     -910.38     26237.21      30652.01     
>15238.41     194691.90      82698.88     -70.417     -75.585
>
>v8            34.36       -4.25       -65.09        450.54       
>-98.24       -555.55        -70.42      79.689       8.164
>
>v9             7.62       -9.11       -52.00         50.31       
>102.97        -95.21        -75.58       8.164      30.492
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From dingjia at gmail.com  Tue Feb 21 11:56:53 2006
From: dingjia at gmail.com (jia ding)
Date: Tue, 21 Feb 2006 11:56:53 +0100
Subject: [R] help-ERROR: unknown GUI none from Statistics::R
Message-ID: <91ae6e350602210256y6449a28k605bb57e84b51121@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060221/128afb3f/attachment.pl

From ana.quiterio at ine.pt  Tue Feb 21 12:56:22 2006
From: ana.quiterio at ine.pt (=?iso-8859-1?Q?Ana_Quit=E9rio?=)
Date: Tue, 21 Feb 2006 11:56:22 -0000
Subject: [R] call row names
Message-ID: <E97312684A84D511BDD40002A50968D607353357@lxpobw01.ine.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060221/bfffec69/attachment.pl

From ramasamy at cancer.org.uk  Tue Feb 21 13:10:19 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 21 Feb 2006 12:10:19 +0000
Subject: [R] call row names
In-Reply-To: <E97312684A84D511BDD40002A50968D607353357@lxpobw01.ine.pt>
References: <E97312684A84D511BDD40002A50968D607353357@lxpobw01.ine.pt>
Message-ID: <1140523819.3491.178.camel@dhcp-82.wolf.ox.ac.uk>

1) It is not good practice to call your objects after existing R
functions (e.g. table)

2) I think you are getting rows and columns confused. If you want to
extract the rows/column of a matrix or dataframe, then try subsetting it
by mat["A1", ] or mat[ , "v4"]. See help(subset) for more information.

3) It looks to me that your object is a list. Try doing class(table).

Regards, Adai


On Tue, 2006-02-21 at 11:56 +0000, Ana Quitrio wrote:
> Hi R users.
> 
>  
> 
> I have a table like that:
> 
>  
> 
> table
> 
> 
>  
> 
> var
> 
> A1
> 
> A2
> 
> A3
> 
> 
> v1
> 
> 41203
> 
> 3.69
> 
> 2.31
> 
> 
> v2
> 
> 20577
> 
> 4.51
> 
> 8.60
> 
> 
> v3
> 
> 20625
> 
> 2.87
> 
> 3.50
> 
> 
> v4
> 
> 6115
> 
> 8.92
> 
> 2.97
> 
> 
> v5
> 
> 3160
> 
> 1.49
> 
> 2.21
> 
> 
> v6
> 
> 2954
> 
> 2.62
> 
> 5.98
> 
> 
> v7
> 
> 4731
> 
> 1.83
> 
> 7.53
> 
> 
> v8
> 
> 2435
> 
> 7.68
> 
> 3.50
> 
> 
> v9
> 
> 2296
> 
> 3.03
> 
> 4.84
> 
> 
> v10
> 
> 6153
> 
> 1.06
> 
> 4.28
> 
> 
> v11
> 
> 3157
> 
> 1.07
> 
> 1.15
> 
> 
> v12
> 
> 2996
> 
> 1.06
> 
> 1.01
> 
> 
> v13
> 
> 6084
> 
> 2.65
> 
> 2.63
> 
> 
> v14
> 
> 3115
> 
> 2.42
> 
> 5.70
> 
> 
> v15
> 
> 2969
> 
> 2.92
> 
> 7.53
> 
>  
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> *	If  I want column A1 I do this: table$A1
> *	And if I want row v4 how can I do? (probably the problem happens
> because the column var is not considered as row names, but in the reality
> was with this purpose that was created by me)
> 
>  
> 
> Thanks in advance
> 
>  
> 
> Ana Quiterio
> 
>  
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ka4alin at yandex.ru  Tue Feb 21 13:12:28 2006
From: ka4alin at yandex.ru (Evgeniy Kachalin)
Date: Tue, 21 Feb 2006 15:12:28 +0300
Subject: [R] R-help Digest, Vol 36, Issue 21
In-Reply-To: <mailman.11.1140519602.6083.r-help@stat.math.ethz.ch>
References: <mailman.11.1140519602.6083.r-help@stat.math.ethz.ch>
Message-ID: <43FB03AC.9070009@yandex.ru>

Hello, dear R users.

I've already sent a question here, but I'm not sure that it had been read.

I need to visualize classification of my numerical data based on 2-3 
factors. As I suppose, the best way is a tree.
With an orbitrary function at the ends (leaves), or at least with means 
of my data at the ends.

What is the way to do it? As I found, ctree offers binary 
classification, but it that the only way? Of course, tree is not only 
way, may be you could offer other ways.

Thank you.



From stevenmh at muohio.edu  Tue Feb 21 13:14:19 2006
From: stevenmh at muohio.edu (Martin Henry H. Stevens)
Date: Tue, 21 Feb 2006 07:14:19 -0500
Subject: [R] R and packages
In-Reply-To: <200602202340.49869.jwd@surewest.net>
References: <200602210107.k1L17wlS011803@gator.dt.uh.edu>
	<200602202340.49869.jwd@surewest.net>
Message-ID: <111BCFA4-79CA-441E-8CC4-FD5200D9B3A0@muohio.edu>

Agreed.
Hank
On Feb 21, 2006, at 2:40 AM, J Dougherty wrote:

> You want to take the sysad by the hairy of his chinny-chin-chin and  
> explain
> the issue in short sentences.  He or she ought to be able produce a  
> solution
> without difficulty, and should not have any problems about doing  
> so.  It IS
> their job.
>
> JD
>
> On Monday 20 February 2006 17:07, Erin Hodgess wrote:
>> Dear R People:
>>
>> Here is yet another strange problem.
>>
>> I'm using R in one of my classes.  However, the computer lab has  
>> something
>> called "Deep Freeze" and the students cannot save anything to the  
>> hard
>> drive.
>>
>> I had R installed and things were working well.  They would save  
>> their
>> .Rdata files to disks.
>>
>> Now, we need to add more packages.  We can't download and we can't
>> bring them in via zip files (already tried both!)  When the zip files
>> are expanded, of course they build new directories......
>>
>> I'm completely annoyed because learning to download packages
>> and installing them from local zips are actually important tasks!
>> We're also losing good teaching/learning time!
>>
>> Anyhow, what I would like to do is produce a sort of combination R
>> installation exe with our extra libraries as part of the package.
>>
>> Does anyone have any suggestions on how this could be done, please?
>>
>> This is R for Windows, Version 2.2.1
>>
>> Thanks for any help!  Sorry about the totally weird problem!
>>
>> Sincerely,
>> Erin Hodgess
>> Associate Professor
>> Department of Computer and Mathematical Sciences
>> University of Houston - Downtown
>> mailto: hodgess at gator.uhd.edu
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html



From ka4alin at yandex.ru  Tue Feb 21 13:17:25 2006
From: ka4alin at yandex.ru (Evgeniy Kachalin)
Date: Tue, 21 Feb 2006 15:17:25 +0300
Subject: [R] R-help Digest, Vol 36, Issue 21
In-Reply-To: <43FB03AC.9070009@yandex.ru>
References: <mailman.11.1140519602.6083.r-help@stat.math.ethz.ch>
	<43FB03AC.9070009@yandex.ru>
Message-ID: <43FB04D5.20102@yandex.ru>

Evgeniy Kachalin wrote:
> Hello, dear R users.
> 
> I've already sent a question here, but I'm not sure that it had been read.
> 
> I need to visualize classification of my numerical data based on 2-3 
> factors. As I suppose, the best way is a tree.
> With an orbitrary function at the ends (leaves), or at least with means 
> of my data at the ends.
> 
> What is the way to do it? As I found, ctree offers binary 
> classification, but it that the only way? Of course, tree is not only 
> way, may be you could offer other ways.
> 
Or the best way of it is to do it with replacement, like a 'heatmap', 
but with means in the cells instead of colors, if it is possible.

Sorry for the second letter.



From RRoa at fisheries.gov.fk  Tue Feb 21 12:26:15 2006
From: RRoa at fisheries.gov.fk (Ruben Roa)
Date: Tue, 21 Feb 2006 09:26:15 -0200
Subject: [R] Nested AIC
Message-ID: <03DCBBA079F2324786E8715BE538968AA5AD64@FIGMAIL-CLUS01.FIG.FK>

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Aaron MacNeil
Sent: 20 February 2006 15:17
To: r-help at stat.math.ethz.ch
Subject: [R] Nested AIC

Greetings,
I have recently come into some confusion over weather or not AIC  
results for comparing among models requires that they be nested.   
Reading Burnham & Anderson (2002) they are explicit that nested models are not required, but other respected statisticians have suggested that nesting is a pre-requisite for comparison.  Could anyone who feels strongly regarding either position post their arguments for or against nested models and AIC? This would assist me greatly in some analysis I am currently conducting.
Many thanks,

Aaron

----
Hi, Aaron, Burnham & Anderson are explicit but they do not go into any depth regarding this issue. Akaike's colleagues Sakamoto, Ishiguro, and Kitagawa (Akaike Information Criterion Statistics, 1986, KTK Scientific Publishers) do no either, deal with it directly, and the examples they present that I have examined (not even half of the total in the book), are all of nested models. However, by reading some of Akaike's papers and the book quoted above it does not appear to me that there is any restriction on the use of the AIC related to nestedness. In fact, the theory does not preclude the comparison of models with different *probability densities (or mass)* as long as you keep all constants (like 1/sqrt(2pi) in the normal) in the calculation. 
Akaike (1973) wrote in the first sentence of his paper his general principle, which he called an extension of the maximum likelihood principle: 
"Given a set of estimates theta_hat's of the vector of parameters theta of a probability distribution with density f(x|theta) we adopt as our final estimate the one which will give the maximum of the expected log-likelihood, which is by definition
E(log f(X|theta_hat))=E(INTEGRAL f(x|theta)log f(x|theta_hat)dx)
Where X is a random variable following the distribution with the density function f(x|theta) and is independent of theta_hat".
All subsequent derivations in the paper, like the choice of distance measure, class of estimates, and elimination of the true parameter value, revolve around this principle. Now, nestedness is a mathematical property of what Burnham & Anderson call "the structural model", whereas Akaike's principle only concerns the probabilistic model f(x|theta) where the structural model is embedded.
I reply to you even though I do not feel strongly about this issue and you asked for replies from people who feel strongly about this issue.
Ruben



From ripley at stats.ox.ac.uk  Tue Feb 21 13:31:05 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Feb 2006 12:31:05 +0000 (GMT)
Subject: [R] help-ERROR: unknown GUI none from Statistics::R
In-Reply-To: <91ae6e350602210256y6449a28k605bb57e84b51121@mail.gmail.com>
References: <91ae6e350602210256y6449a28k605bb57e84b51121@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602211225280.6205@gannet.stats.ox.ac.uk>

On Tue, 21 Feb 2006, jia ding wrote:

> Hi,
>
> I download Statistics::R from
> http://search.cpan.org/~gmpassos/Statistics-R-0.02/
> I am going to combine R with perl.
>
> but it keeps give the error msg: ERROR: unknown GUI none & stop running
> script. I feel very strange, because previously it works.
>
> my perl version is 5.8.6
> my R version is Version 2.2.1
>
> Is there anybody know about it?

Yes.  R --gui=none has not been needed for a long time, and it no longer 
works (i.e. has been removed).  You need to remove it in 
lib/Statistics/R/Bridge/Linux.pm.

> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Hans.Skaug at mi.uib.no  Tue Feb 21 13:31:50 2006
From: Hans.Skaug at mi.uib.no (Hans Skaug)
Date: Tue, 21 Feb 2006 13:31:50 +0100
Subject: [R] glmm.admb - bug and possible solution??
Message-ID: <5BCBA62ECB426A47AE66567CDF930F98829C82@HUGIN.uib.no>

Dear R list,

A problem with the package glmmADMB was pointed out by R. Bagchi some time ago.
We have now fixed the problem and a new version of the package can be downloaded
from the usual place:

http://otter-rsch.com/admbre/examples/glmmadmb/glmmADMB.html

The likelihood values that previously were off by a constant have now been corrected.

Please let me know if there are other problems.

hans


>Dear Dr Skaug  and R users,
>
>just discovered glmm.admb in R, and it seems a very useful tool. 
>However, I ran into a problem when I compare two models:
>
>m1<-glmm.admb(survival~light*species*damage, random=~1, group="table", 
>data=bm, family="binomial", link="logit")
>
>m1.1<-glmm.admb(survival~(light+species+damage)^2, random=~1, 
>group="table", data=bm, family="binomial", link="logit")
>
>anova(m1, m1.1)
>
>I get the following output with the warning
>
>Analysis of Variance Table
>
>Model 1: survival ~ light * species * damage
>Model 2: survival ~ (light + damage + species)^2
>NoPar LogLik Df -2logQ P.value
>1 9.000 -103.307
>2 9.000 -103.781 0 -0.948
>Warning message:
>NaNs produced in: pchisq(q, df, lower.tail, log.p)

_____________________________
Hans Julius Skaug

Department of Mathematics
University of Bergen
Johannes Brunsgate 12
5008 Bergen
Norway
ph. (+47) 55 58 48 61



From portnoy at supereva.it  Tue Feb 21 13:49:53 2006
From: portnoy at supereva.it (portnoy@supereva.it)
Date: Tue, 21 Feb 2006 13:49:53 +0100
Subject: [R] how to get ROC for SVM
Message-ID: <43FB0C71.1080700@supereva.it>

> Message: 1
> Date: Mon, 20 Feb 2006 17:19:41 +0530
> From: "karthi keyan" <gkkarthikeyann at gmail.com>
> Subject: [R] how to get ROC for SVM
> To: r-help at stat.math.ethz.ch
> Message-ID:
> <8e3e33900602200349h31d7132aqdd94a907acc5d859 at mail.gmail.com>
> Content-Type: text/plain
>
> Hi
> How can i get ROC for svm during modelling in SVM. how to plot the
> values
>
> thanks
>
> karthik 
Probably this will help:
http://rocr.bioinf.mpi-sb.mpg.de/

Paolo



From karin.lagesen at medisin.uio.no  Tue Feb 21 14:07:35 2006
From: karin.lagesen at medisin.uio.no (Karin Lagesen)
Date: Tue, 21 Feb 2006 14:07:35 +0100
Subject: [R] rotated labels in barplot with beside=T and multiple groups
Message-ID: <ypx68xs45088.fsf@uracil.uio.no>


I have a data set that I display using barplot. I don't know what you
call it, but when I look at it, it looks like this:


> lsu
   
    (0,0.1]     (0.1,0.2]   (0.2,0.3]   (0.3,0.4]   (0.4,0.5]   (0.5,0.6]  
  A 0.052631579 0.000000000 0.000000000 0.000000000 0.000000000 0.000000000
  B 0.000000000 0.000000000 0.001007049 0.003021148 0.000000000 0.000000000
  E 0.200000000 0.000000000 0.000000000 0.000000000 0.100000000 0.000000000
   
    (0.6,0.7]   (0.7,0.8]   (0.8,0.9]   (0.9,1]    
  A 0.000000000 0.000000000 0.000000000 0.947368421
  B 0.000000000 0.004028197 0.005035247 0.986908359
  E 0.100000000 0.000000000 0.100000000 0.500000000
> 

Now, trying the examples shown via the r-help mailing list I am trying
to make a plot where each of the groups gets displayed in a
histogram-like fashion upwards with the number 0.1, 0.2 and so forth
underneath the group. What I do is the following:



> par(mar = c(6, 4, 4, 2) + 0.1)
> bplot = barplot(lsu, beside=TRUE, col=colors[1:length(lsu[,1])], ylim = c(0,1.0), xaxt = "n", xlab = "")
> axis(side=1,at=bplot, labels=FALSE, tick=TRUE)
NULL
> nam=rep("a",10)
> text(bplot, par("usr")[3] - 1.5, srt = 45, adj = 1, labels = nam, xpd = TRUE)
NULL
>

The result is the bars pointing upwards, like I want, but I get one
tickmark per bar, and no labels underneath. I want no tickmark, and
one label per group.

Any ideas as to what I am doing wrong?

TIA,

Karin
-- 
Karin Lagesen, PhD student
karin.lagesen at medisin.uio.no
http://www.cmbn.no/rognes/



From jacques.veslot at cirad.fr  Tue Feb 21 14:38:24 2006
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Tue, 21 Feb 2006 17:38:24 +0400
Subject: [R] rotated labels in barplot with beside=T and multiple groups
In-Reply-To: <ypx68xs45088.fsf@uracil.uio.no>
References: <ypx68xs45088.fsf@uracil.uio.no>
Message-ID: <43FB17D0.7040500@cirad.fr>

why not:

colnames(lsu) <- seq(0.1,1,by=0.1)
barplot(lsu, bes=T)



Karin Lagesen a ??crit :

>I have a data set that I display using barplot. I don't know what you
>call it, but when I look at it, it looks like this:
>
>
>  
>
>>lsu
>>    
>>
>   
>    (0,0.1]     (0.1,0.2]   (0.2,0.3]   (0.3,0.4]   (0.4,0.5]   (0.5,0.6]  
>  A 0.052631579 0.000000000 0.000000000 0.000000000 0.000000000 0.000000000
>  B 0.000000000 0.000000000 0.001007049 0.003021148 0.000000000 0.000000000
>  E 0.200000000 0.000000000 0.000000000 0.000000000 0.100000000 0.000000000
>   
>    (0.6,0.7]   (0.7,0.8]   (0.8,0.9]   (0.9,1]    
>  A 0.000000000 0.000000000 0.000000000 0.947368421
>  B 0.000000000 0.004028197 0.005035247 0.986908359
>  E 0.100000000 0.000000000 0.100000000 0.500000000
>  
>
>
>Now, trying the examples shown via the r-help mailing list I am trying
>to make a plot where each of the groups gets displayed in a
>histogram-like fashion upwards with the number 0.1, 0.2 and so forth
>underneath the group. What I do is the following:
>
>
>
>  
>
>>par(mar = c(6, 4, 4, 2) + 0.1)
>>bplot = barplot(lsu, beside=TRUE, col=colors[1:length(lsu[,1])], ylim = c(0,1.0), xaxt = "n", xlab = "")
>>axis(side=1,at=bplot, labels=FALSE, tick=TRUE)
>>    
>>
>NULL
>  
>
>>nam=rep("a",10)
>>text(bplot, par("usr")[3] - 1.5, srt = 45, adj = 1, labels = nam, xpd = TRUE)
>>    
>>
>NULL
>  
>
>
>The result is the bars pointing upwards, like I want, but I get one
>tickmark per bar, and no labels underneath. I want no tickmark, and
>one label per group.
>
>Any ideas as to what I am doing wrong?
>
>TIA,
>
>Karin
>  
>



From cklarner at isugw.indstate.edu  Tue Feb 21 14:52:04 2006
From: cklarner at isugw.indstate.edu (Carl Klarner)
Date: Tue, 21 Feb 2006 08:52:04 -0500
Subject: [R] How to Import Data
Message-ID: <s3fad4d1.087@isugw.indstate.edu>

Hello,
I am a very new user of R.  I've spent several hours trying to import
data, so I feel okay asking the list for help.  I had an Excel file,
then I turned it into a "csv" file, as instructed by directions.  My
filename is "x111.csv."  I then used the following commands to read this
(fairly small) dataset in.  

x111 <-read.table(file='x111.csv',
sep="",header=T,
quote="",comment.char="",as.is=T)

I then get the following error message.

Error in file(file, "r") : unable to open connection
In addition: Warning message:
cannot open file 'x111.csv', reason 'No such file or directory'

I would imagine I'm not putting my csv file in the right location for R
to be able to read it.  If that's the case, where should I put it?  Or
is there something else I need to do to it first?
Thanks for your help,
Carl



From MSchwartz at mn.rr.com  Tue Feb 21 14:58:23 2006
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Tue, 21 Feb 2006 07:58:23 -0600
Subject: [R] rotated labels in barplot with beside=T and multiple groups
In-Reply-To: <ypx68xs45088.fsf@uracil.uio.no>
References: <ypx68xs45088.fsf@uracil.uio.no>
Message-ID: <1140530303.4518.57.camel@localhost.localdomain>

On Tue, 2006-02-21 at 14:07 +0100, Karin Lagesen wrote:
> I have a data set that I display using barplot. I don't know what you
> call it, but when I look at it, it looks like this:
> 
> 
> > lsu
>    
>     (0,0.1]     (0.1,0.2]   (0.2,0.3]   (0.3,0.4]   (0.4,0.5]   (0.5,0.6]  
>   A 0.052631579 0.000000000 0.000000000 0.000000000 0.000000000 0.000000000
>   B 0.000000000 0.000000000 0.001007049 0.003021148 0.000000000 0.000000000
>   E 0.200000000 0.000000000 0.000000000 0.000000000 0.100000000 0.000000000
>    
>     (0.6,0.7]   (0.7,0.8]   (0.8,0.9]   (0.9,1]    
>   A 0.000000000 0.000000000 0.000000000 0.947368421
>   B 0.000000000 0.004028197 0.005035247 0.986908359
>   E 0.100000000 0.000000000 0.100000000 0.500000000


It appears to be a matrix, comprised of the results of using cut() along
with perhaps tapply() or similar on one or more continuous variables
using a grouping variable. See ?cut and ?tapply.


> Now, trying the examples shown via the r-help mailing list I am trying
> to make a plot where each of the groups gets displayed in a
> histogram-like fashion upwards with the number 0.1, 0.2 and so forth
> underneath the group. What I do is the following:
> 
> 
> 
> > par(mar = c(6, 4, 4, 2) + 0.1)
> > bplot = barplot(lsu, beside=TRUE, col=colors[1:length(lsu[,1])], ylim = c(0,1.0), xaxt = "n", xlab = "")
> > axis(side=1,at=bplot, labels=FALSE, tick=TRUE)
> NULL
> > nam=rep("a",10)
> > text(bplot, par("usr")[3] - 1.5, srt = 45, adj = 1, labels = nam, xpd = TRUE)
> NULL
> >
> 
> The result is the bars pointing upwards, like I want, but I get one
> tickmark per bar, and no labels underneath. I want no tickmark, and
> one label per group.
> 
> Any ideas as to what I am doing wrong?
> 
> TIA,
> 
> Karin


First, your code above has some errors.

The use of "col=colors[1:length(lsu[,1])]" does not work. It can either
be:

  col=colors()[1:length(lsu[,1])]

or easier to read:

  colors()[1:nrow(lsu)]


Second, the offset (-1.5) you have in the call to text():

  par("usr")[3] - 1.5

puts the text labels well below the bottom of the plot, which is why
they are not seen.  You need to change it to:

  par("usr")[3] - .05

or a similarly reduced offset figure.

Thus, you can now use:

  par(mar = c(6, 4, 4, 2) + 0.1)

  bplot <- barplot(lsu, beside = TRUE, 
                   col = colors()[1:nrow(lsu)], 
                   ylim = c(0, 1.0), xaxt = "n", xlab = "")

  axis(side = 1, at = bplot, labels = FALSE, tick = TRUE)

  nam <- rep("a", 10)

  text(bplot, par("usr")[3] - .05, srt = 45, adj = 1, 
       labels = nam, xpd = TRUE)


In order to get group labels for each of the three bars, you need to pay
attention to the "Value" section of ?barplot, which says:

     If 'beside' is true, use 'colMeans(mp)' for the midpoints of each
     _group_ of bars, see example.
  
Thus, if you want to place group labels on the plot use:

par(mar = c(6, 4, 4, 2) + 0.1)

bplot <- barplot(lsu, beside = TRUE, 
                 col = colors()[1:nrow(lsu)], 
                 ylim = c(0, 1.0), xaxt = "n", xlab = "")

nam <- rep("a", 10)

# Here is the change. Use colMeans(bplot)
text(colMeans(bplot), par("usr")[3] - .05, srt = 45, adj = 1, 
     labels = nam, xpd = TRUE)


Do not use the call to axis() if you don't want the tick marks, since
there is no other need for that function here.

If you do want to put tick marks at the midpoint of each group, you
could use:

  axis(1, at = colMeans(bplot), labels = FALSE)

HTH,

Marc Schwartz



From ramasamy at cancer.org.uk  Tue Feb 21 15:03:18 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 21 Feb 2006 14:03:18 +0000
Subject: [R] visualise classification by factors (was Re:  R-help Digest,
	Vol 36, Issue 21)
In-Reply-To: <43FB03AC.9070009@yandex.ru>
References: <mailman.11.1140519602.6083.r-help@stat.math.ethz.ch>
	<43FB03AC.9070009@yandex.ru>
Message-ID: <1140530599.3491.191.camel@dhcp-82.wolf.ox.ac.uk>

1) Please use a meaning subject line. Start a new thread instead of
replying to another thread. 

2) Please give a simple example (if possible reproducible) to help
explain the problem.

3) Please read the posting guide.



On Tue, 2006-02-21 at 15:12 +0300, Evgeniy Kachalin wrote:
> Hello, dear R users.
> 
> I've already sent a question here, but I'm not sure that it had been read.
> 
> I need to visualize classification of my numerical data based on 2-3 
> factors. As I suppose, the best way is a tree.
> With an orbitrary function at the ends (leaves), or at least with means 
> of my data at the ends.
> 
> What is the way to do it? As I found, ctree offers binary 
> classification, but it that the only way? Of course, tree is not only 
> way, may be you could offer other ways.
> 
> Thank you.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From johann.jacoby at uni-jena.de  Tue Feb 21 15:02:53 2006
From: johann.jacoby at uni-jena.de (Johann Jacoby)
Date: Tue, 21 Feb 2006 15:02:53 +0100
Subject: [R] How to Import Data
In-Reply-To: <s3fad4d1.087@isugw.indstate.edu>
References: <s3fad4d1.087@isugw.indstate.edu>
Message-ID: <43FB1D8D.2070103@uni-jena.de>

carl,

you wrote:

> I would imagine I'm not putting my csv file in the right location for R
> to be able to read it.  If that's the case, where should I put it?  Or
> is there something else I need to do to it first?

getwd() gives you the working directory in which the datafile has to
reside.

johann



From rapela at usc.edu  Tue Feb 21 15:05:21 2006
From: rapela at usc.edu (Joaquin Rapela)
Date: Tue, 21 Feb 2006 06:05:21 -0800
Subject: [R] wireframe, axis label-axis separation, xlab rotation
Message-ID: <20060221140521.GA5522@plato.usc.edu>

Greetings,

A couple of questions:

1. 
I am using wireframe. It prints 3d plots nicely on screen, but when I use a
postscript device the z-axis label merges with the z-axis. Is there any option
to control their separation?

2. 
Again, using wireframe, I rotate the whole plot using the screen parameter.
However, the x- and y-axis labels (xlab and ylab) remain horizontal. How could 
I rotate them? 

Thanks in advance, Joaquin

PS: my apologizes if these questions are too basic. I am new to R and to Trellis.
-- 
Joaquin Rapela
PhD Student, Electrical Engineering
University of Southern California
Hedco Neuroscience Building
3641 Watt Way
Los Angeles, CA 90089-2520
tel/fax: (213) 821-2070
http://www-scf.usc.edu/~rapela
----------------------------------

"This is the origin of their (the Aborigines') belief in the omnipotence of
thoughts, their unshakable confidence in the possibility of controlling the 
world and their inaccessibility to other experiences, so easily obtainable, 
which could teach them man's true position in the universe."
                                                                   Sigmund Freud
                                                                 Totem and Taboo



From jacques.veslot at cirad.fr  Tue Feb 21 15:05:39 2006
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Tue, 21 Feb 2006 18:05:39 +0400
Subject: [R] How to Import Data
In-Reply-To: <s3fad4d1.087@isugw.indstate.edu>
References: <s3fad4d1.087@isugw.indstate.edu>
Message-ID: <43FB1E33.4050003@cirad.fr>

select the directory with setwd() and then import data:

setwd("d:/.../yourdirectory")
x111 <- read.table("x111.csv",...)

or indicate path behind filename:
x111 <- read.table("d:/.../yourdirectory/x111.csv",...)

besides, there are other functions to import data.
see ?read.table




Carl Klarner a ??crit :

>Hello,
>I am a very new user of R.  I've spent several hours trying to import
>data, so I feel okay asking the list for help.  I had an Excel file,
>then I turned it into a "csv" file, as instructed by directions.  My
>filename is "x111.csv."  I then used the following commands to read this
>(fairly small) dataset in.  
>
>x111 <-read.table(file='x111.csv',
>sep="",header=T,
>quote="",comment.char="",as.is=T)
>
>I then get the following error message.
>
>Error in file(file, "r") : unable to open connection
>In addition: Warning message:
>cannot open file 'x111.csv', reason 'No such file or directory'
>
>I would imagine I'm not putting my csv file in the right location for R
>to be able to read it.  If that's the case, where should I put it?  Or
>is there something else I need to do to it first?
>Thanks for your help,
>Carl
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From bolker at ufl.edu  Tue Feb 21 15:08:58 2006
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 21 Feb 2006 14:08:58 +0000 (UTC)
Subject: [R] How to Import Data
References: <s3fad4d1.087@isugw.indstate.edu>
Message-ID: <loom.20060221T150226-343@post.gmane.org>

Carl Klarner <cklarner <at> isugw.indstate.edu> writes:

> 
> I would imagine I'm not putting my csv file in the right location for R
> to be able to read it.  If that's the case, where should I put it?  Or
> is there something else I need to do to it first?
> Thanks for your help,
> Carl

  You're probably right.  R opens by default in its installation
directory (usually somewhere in Program Files\R\... on Windows)
The easiest thing is to change the working directory to wherever
you have the files using setwd() or (in a GUI) some menu option
("Change dir" in the File menu under Windows).

   Useful functions for working directory, file selection etc.:
list.files() [list files in current directory], file.choose() [interactive
file chooser], file.exists() [whether or not a file exists], getwd() [print
current working directory], setwd() [set current working directory].

  The other common problem, which you probably *aren't* having, is
hidden file extensions under Windows.

   good luck
     Ben Bolker



From marcusgb at kth.se  Tue Feb 21 15:09:57 2006
From: marcusgb at kth.se (=?iso-8859-1?Q?Marcus_Gry_Bj=F6rklund?=)
Date: Tue, 21 Feb 2006 15:09:57 +0100
Subject: [R] Resolution of plots?
Message-ID: <20060221141034.274F3140C7C@mx1.kth.se>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060221/da9700a3/attachment.pl

From ramasamy at cancer.org.uk  Tue Feb 21 15:13:02 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 21 Feb 2006 14:13:02 +0000
Subject: [R] How to Import Data
In-Reply-To: <s3fad4d1.087@isugw.indstate.edu>
References: <s3fad4d1.087@isugw.indstate.edu>
Message-ID: <1140531183.3491.199.camel@dhcp-82.wolf.ox.ac.uk>

1) You need to use sep="," which is appropriate for a CSV file.

2) You need to specify the FULL path to the file. See 
http://cran.r-project.org/bin/windows/base/rw-FAQ.html#R-can_0027t-find-my-file

3) You can use read.csv which is the read.table variant for CSV files.


For example

  a <- read.csv( file="c:/Progra~1/Docume~1/ramasamy/x111.csv" )

might work if you replace it with your full path. If you have the
_unique_ rownames in the first column, you can add the argument
"row.names=1" in the call.

Regards, Adai



On Tue, 2006-02-21 at 08:52 -0500, Carl Klarner wrote:
> Hello,
> I am a very new user of R.  I've spent several hours trying to import
> data, so I feel okay asking the list for help.  I had an Excel file,
> then I turned it into a "csv" file, as instructed by directions.  My
> filename is "x111.csv."  I then used the following commands to read this
> (fairly small) dataset in.  
> 
> x111 <-read.table(file='x111.csv',
> sep="",header=T,
> quote="",comment.char="",as.is=T)
> 
> I then get the following error message.
> 
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file 'x111.csv', reason 'No such file or directory'
> 
> I would imagine I'm not putting my csv file in the right location for R
> to be able to read it.  If that's the case, where should I put it?  Or
> is there something else I need to do to it first?
> Thanks for your help,
> Carl
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ales.ziberna at gmail.com  Tue Feb 21 15:25:45 2006
From: ales.ziberna at gmail.com (=?windows-1252?Q?Ale=9A_=8Eiberna?=)
Date: Tue, 21 Feb 2006 15:25:45 +0100
Subject: [R] How to Import Data
In-Reply-To: <43FB1D8D.2070103@uni-jena.de>
References: <s3fad4d1.087@isugw.indstate.edu> <43FB1D8D.2070103@uni-jena.de>
Message-ID: <43FB22E9.3040405@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060221/31e06c44/attachment.pl

From philipp.pagel.lists at t-online.de  Tue Feb 21 15:27:43 2006
From: philipp.pagel.lists at t-online.de (Philipp Pagel)
Date: Tue, 21 Feb 2006 15:27:43 +0100
Subject: [R] How to Import Data
In-Reply-To: <s3fad4d1.087@isugw.indstate.edu>
References: <s3fad4d1.087@isugw.indstate.edu>
Message-ID: <20060221142743.GA32320@gsf.de>

On Tue, Feb 21, 2006 at 08:52:04AM -0500, Carl Klarner wrote:

> x111 <-read.table(file='x111.csv',
> sep="",header=T,
> quote="",comment.char="",as.is=T)

to make things easier for you you could do

x111 <-read.table( file.choose(), ... )

Also: Why are you setting sep="" ? Your filename suggests that you have
some kind of separator in your file...

cu
	Philipp

-- 
Dr. Philipp Pagel                            Tel.  +49-8161-71 2131
Dept. of Genome Oriented Bioinformatics      Fax.  +49-8161-71 2186
Technical University of Munich
Science Center Weihenstephan
85350 Freising, Germany

 and

Institute for Bioinformatics / MIPS          Tel.  +49-89-3187 3675
GSF - National Research Center               Fax.  +49-89-3187 3585
      for Environment and Health
Ingolst??dter Landstrasse 1
85764 Neuherberg, Germany
http://mips.gsf.de/staff/pagel



From murdoch at stats.uwo.ca  Tue Feb 21 15:32:57 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 21 Feb 2006 09:32:57 -0500
Subject: [R] How to Import Data
In-Reply-To: <1140531183.3491.199.camel@dhcp-82.wolf.ox.ac.uk>
References: <s3fad4d1.087@isugw.indstate.edu>
	<1140531183.3491.199.camel@dhcp-82.wolf.ox.ac.uk>
Message-ID: <43FB2499.1040808@stats.uwo.ca>

On 2/21/2006 9:13 AM, Adaikalavan Ramasamy wrote:
> 1) You need to use sep="," which is appropriate for a CSV file.
> 
> 2) You need to specify the FULL path to the file. See 
> http://cran.r-project.org/bin/windows/base/rw-FAQ.html#R-can_0027t-find-my-file

The advice to look at the FAQ is good, but it's not true that you need 
the full path.  Like other programs, R maintains a current working 
directory, and paths can be specified relative to that.  I usually put a 
line like

setwd('c:/my/working/dir')

at the start of scripts, so that the current directory is changed from 
the beginning.  Then I can use simple filenames to read files.

The other advice I usually give is to specify "file.choose()" instead of 
an explicit filename; this will open a file selection dialog.  (In my 
opinion, this should be the default, but some people disagree quite 
strongly.)

Duncan Murdoch

> 
> 3) You can use read.csv which is the read.table variant for CSV files.
> 
> 
> For example
> 
>   a <- read.csv( file="c:/Progra~1/Docume~1/ramasamy/x111.csv" )
> 
> might work if you replace it with your full path. If you have the
> _unique_ rownames in the first column, you can add the argument
> "row.names=1" in the call.
> 
> Regards, Adai
> 
> 
> 
> On Tue, 2006-02-21 at 08:52 -0500, Carl Klarner wrote:
>> Hello,
>> I am a very new user of R.  I've spent several hours trying to import
>> data, so I feel okay asking the list for help.  I had an Excel file,
>> then I turned it into a "csv" file, as instructed by directions.  My
>> filename is "x111.csv."  I then used the following commands to read this
>> (fairly small) dataset in.  
>> 
>> x111 <-read.table(file='x111.csv',
>> sep="",header=T,
>> quote="",comment.char="",as.is=T)
>> 
>> I then get the following error message.
>> 
>> Error in file(file, "r") : unable to open connection
>> In addition: Warning message:
>> cannot open file 'x111.csv', reason 'No such file or directory'
>> 
>> I would imagine I'm not putting my csv file in the right location for R
>> to be able to read it.  If that's the case, where should I put it?  Or
>> is there something else I need to do to it first?
>> Thanks for your help,
>> Carl
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Tue Feb 21 15:41:56 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Feb 2006 14:41:56 +0000 (GMT)
Subject: [R] Resolution of plots?
In-Reply-To: <20060221141034.274F3140C7C@mx1.kth.se>
References: <20060221141034.274F3140C7C@mx1.kth.se>
Message-ID: <Pine.LNX.4.64.0602211439130.7717@gannet.stats.ox.ac.uk>

On Tue, 21 Feb 2006, Marcus Gry Bj??rklund wrote:

> I have a problem regarding the output from the R plot window.

It seems you are using Windows, but you didn't say so!  I will assume that 
from here on down.

> I have a quite dense dendrogram that I wish to visualize using a suitable
> software (like Illustrator), and to accomplish that I right click on the
> image from the plotting device and I save as metafile. The problem is when I
> scale up the image, some of the vectors in the dendrogram image are
> inseparable.
>
> My question is if there is any way of increasing the resolution of the
> meta-file that I get from the plotting device?

No, as it is done to full metafile resolution (1/1200").  Why not plot on 
a larger size directly to a metafile using win.metafile?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From aldi at wustl.edu  Tue Feb 21 16:19:03 2006
From: aldi at wustl.edu (Aldi Kraja)
Date: Tue, 21 Feb 2006 09:19:03 -0600
Subject: [R] var-covar matrices comparison:
In-Reply-To: <43FAEAE4.6020402@pburns.seanet.com>
References: <43FA462B.9020304@wustl.edu> <43FAEAE4.6020402@pburns.seanet.com>
Message-ID: <43FB2F67.6040500@wustl.edu>

Thank you Patrick for your thoughts.

I was expecting someone had written a function that does maybe a 
hierarchical comparison of var-covar matrices using the flury hierarchy 
as proposed by
Philips and Arnold in Evolution 53(5), 1999;1506-1515. But your email 
has an interesting idea, so I will try to test it.
Thank you,

Aldi

Patrick Burns wrote:

> My first thought is to use a random permutation test.
> In this setting the main question you need to ask is
> what distance measure do you want to use between
> variance matrices -- there are lots of choices.  One
> that I've found useful is the absolute value of the
> maximum eigenvalue of the difference of the matrices.
>
> If you have a hypothesis about how the variances may
> differ, then you should be able to come up with a more
> powerful statistic.
>
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
>



From deepayan.sarkar at gmail.com  Tue Feb 21 16:20:13 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 21 Feb 2006 09:20:13 -0600
Subject: [R] wireframe, axis label-axis separation, xlab rotation
In-Reply-To: <20060221140521.GA5522@plato.usc.edu>
References: <20060221140521.GA5522@plato.usc.edu>
Message-ID: <eb555e660602210720q1e6a2ce1i892838a6f017d5af@mail.gmail.com>

On 2/21/06, Joaquin Rapela <rapela at usc.edu> wrote:
> Greetings,
>
> A couple of questions:
>
> 1.
> I am using wireframe. It prints 3d plots nicely on screen, but when I use a
> postscript device the z-axis label merges with the z-axis. Is there any
> option
> to control their separation?
>
> 2.
> Again, using wireframe, I rotate the whole plot using the screen parameter.
> However, the x- and y-axis labels (xlab and ylab) remain horizontal. How
> could
> I rotate them?

Both are possible, e.g.

wireframe(volcano,
          scales = list(z = list(distance = 3)),
          zlab = list("volcano", rot = 90),
          zoom = 0.4)

(The documentation is a bit lacking of these details.)

Deepayan



From gerald.herbert at hubbardbreeders.com  Tue Feb 21 16:48:28 2006
From: gerald.herbert at hubbardbreeders.com (gerald.herbert@hubbardbreeders.com)
Date: Tue, 21 Feb 2006 10:48:28 -0500
Subject: [R] Number of Days Between Dates: Incorrect Results For Date
	Calucations.
Message-ID: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAUmL1BciWlkSJzbtE4pRe0sKAAAAQAAAA7YffOmYFSU645jkej1wJmwEAAAAA@hubbardbreeders.com>

In some cases, incorrect results are produced by the code below intended to
calculate the number of days between 2 dates.  The year in question was a
leap year.

Note the results for 2004-04-04 and 2004-04-05 are the same! They should be
37 and 38 respectively.

> as.integer(as.POSIXct("2004-04-02") - as.POSIXct("2004-02-27"))
[1] 35
> as.integer(as.POSIXct("2004-04-03") - as.POSIXct("2004-02-27"))
[1] 36
> as.integer(as.POSIXct("2004-04-04") - as.POSIXct("2004-02-27"))
[1] 37
> as.integer(as.POSIXct("2004-04-05") - as.POSIXct("2004-02-27"))
[1] 37
> as.integer(as.POSIXct("2004-04-06") - as.POSIXct("2004-02-27"))
[1] 38



> as.integer(difftime(as.POSIXct("2004-04-06"),
as.POSIXct("2004-02-27"),units="days"))
[1] 38
> as.integer(difftime(as.POSIXct("2004-04-04"),
as.POSIXct("2004-02-27"),units="days"))
[1] 37
> as.integer(difftime(as.POSIXct("2004-04-05"),
as.POSIXct("2004-02-27"),units="days"))
[1] 37

It appears that difftime() and "-" are producing invalid results.


Regards,

Gerald Herbert



From jmacdon at med.umich.edu  Tue Feb 21 16:54:54 2006
From: jmacdon at med.umich.edu (James W. MacDonald)
Date: Tue, 21 Feb 2006 10:54:54 -0500
Subject: [R] mva.pairs
In-Reply-To: <20060220173806.97465.qmail@web53503.mail.yahoo.com>
References: <20060220173806.97465.qmail@web53503.mail.yahoo.com>
Message-ID: <43FB37CE.9000205@med.umich.edu>

Hi Vijay,

Vijay A Raghavan wrote:
> Hello,
>  
>  I am using the following code to plot an MVA plot.
>  
>  library(affy)
>  library(Biobase)
>  library(limma)
>  library(gcrma)
>  
>      pd<-read.phenoData("Clk.targets.2.txt",header=TRUE,
>      row.names=1,as.is=TRUE,sep="\t")
>      Data <- ReadAffy(filenames=pData(pd)$FileName,phenoData=pd) 
>      Print(Data)
>      
>      eset <- gcrma(Data) 
>      write.exprs(eset, file="clk.6-23-05.txt")
>        
>          
>      bitmap("clk-1.mva.jpg",width=15, height=12)
>      mva.pairs(exprs(eset)[,c(19,20,21,22,23,24)],log.it=FALSE)
>      dev.off()
>  
>  but I am getting an subscript out of bound error.
>  
>  Any Idea ?

The only reason I know for getting a subscript out of bound error is 
actually trying to subset an object using dimensions larger than the 
object itself. In other words, do you really have 24 columns (e.g., 24 
chips) in your exprSet?

>  
>  Thanks,
>  
>  Vijay
>  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
James W. MacDonald, M.S.
Biostatistician
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623



From tlumley at u.washington.edu  Tue Feb 21 17:01:30 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 21 Feb 2006 08:01:30 -0800 (PST)
Subject: [R] R and packages
In-Reply-To: <200602210107.k1L17wlS011803@gator.dt.uh.edu>
References: <200602210107.k1L17wlS011803@gator.dt.uh.edu>
Message-ID: <Pine.LNX.4.64.0602210756160.1702@homer24.u.washington.edu>

On Mon, 20 Feb 2006, Erin Hodgess wrote:

> Dear R People:
>
> Here is yet another strange problem.
>
> I'm using R in one of my classes.  However, the computer lab has something
> called "Deep Freeze" and the students cannot save anything to the hard drive.
>
> I had R installed and things were working well.  They would save their
> .Rdata files to disks.
>
> Now, we need to add more packages.  We can't download and we can't
> bring them in via zip files (already tried both!)  When the zip files
> are expanded, of course they build new directories......

I would suggest making this the system administrator's problem.  Either 
your site really has a policy that would prohibit R packages (in which 
case trying to subvert it may not be a good idea) or it is exactly the 
sort of problem that system administrators are supposed to solve.

Distrust for R binary (and even source) packages is not a completely 
unreasonable attitude. They can execute arbitrary code on your computer 
and, in contrast to R itself, you usually have no real knowledge of who 
wrote them.

 	-thomas



> I'm completely annoyed because learning to download packages
> and installing them from local zips are actually important tasks!
> We're also losing good teaching/learning time!
>
> Anyhow, what I would like to do is produce a sort of combination R
> installation exe with our extra libraries as part of the package.
>
> Does anyone have any suggestions on how this could be done, please?
>
> This is R for Windows, Version 2.2.1
>
> Thanks for any help!  Sorry about the totally weird problem!
>
> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From deepayan.sarkar at gmail.com  Tue Feb 21 17:06:46 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 21 Feb 2006 10:06:46 -0600
Subject: [R] indexing within panels in xyplot
In-Reply-To: <87mzglgoue.fsf@arctocephalus.homelinux.org>
References: <87mzglgoue.fsf@arctocephalus.homelinux.org>
Message-ID: <eb555e660602210806q89e6cdcjcc28849da5fbb9ae@mail.gmail.com>

On 2/21/06, Sebastian Luque <spluque at gmail.com> wrote:
> Dear R-helpers,
>
> I need to show a linear fit through a subset of the data within each
> combination of levels of two factors.  So I prepared an xyplot with
> different panels for each level of one of the factors, and different
> symbols within each panel for the levels of the second factor.  My problem
> is selecting the subset of each combination through which the line should
> be fit for subsequent plotting.  This hopefully shows the idea:
>
>
> ---<---------------cut here---------------start-------------->---
> toydf <- expand.grid(1:100, c("A", "B"),
>                      c("pop1", "pop2", "pop3", "pop4", "pop5"))
> toydf <- data.frame(facA = toydf[[3]], facB = toydf[[2]],
>                     x = toydf[[1]], y = rnorm(1000))
>
> xyplot(y ~ x | facA, groups = facB, data = toydf,
>        panel.groups = function(x, y, subscripts, ...) {
>          panel.xyplot(x, y, ...)
>          lindx <- which(y[subscripts] == max(y[subscripts], na.rm = TRUE))
>          xleft <- mean(x[lindx], na.rm = TRUE)
>          fit <- lm(y[x >= xleft] ~ x[x >= xleft])
>          panel.abline(fit)
>        })
> ---<---------------cut here---------------end---------------->---
>
> i.e. the left limit for fitting the line is defined by the mean of x
> values where y is equal to the maximum y values, *within* each combination
> of levels of both factors.  The above is giving me:
>
> Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :
> 	0 (non-NA) cases
> In addition: Warning message:
> no finite arguments to max; returning -Inf
>
> which shows I'm not understanding how the 'subscripts' argument works.
> I'd appreciate some pointers on what I'm doing wrong, as I haven't been
> able to find help in the help pages and List archives.

Well, there are exceptions to this rule, but generally x and y, when
they are passed on to the panel function, are _already_ subsetted, so
x[subscripts] makes absolutely no sense. Note how your panel function
calls

panel.xyplot(x, y, ...)

without referring to subscripts at all. The subscripts argument is
there for other variables (e.g. if you were drawing confidence
intervals, and had a separate vector in your data specifying the
interval lengths). In your case, there are no other variables
involved, so just get rid of the subscripts.

Deepayan



From ggrothendieck at gmail.com  Tue Feb 21 17:08:08 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 21 Feb 2006 11:08:08 -0500
Subject: [R] Number of Days Between Dates: Incorrect Results For Date
	Calucations.
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAUmL1BciWlkSJzbtE4pRe0sKAAAAQAAAA7YffOmYFSU645jkej1wJmwEAAAAA@hubbardbreeders.com>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAUmL1BciWlkSJzbtE4pRe0sKAAAAQAAAA7YffOmYFSU645jkej1wJmwEAAAAA@hubbardbreeders.com>
Message-ID: <971536df0602210808r333a89f0g1e27e99a30b8ce7e@mail.gmail.com>

The results are actually correct if you consider daylight savings time.

For example, try this and note that the difference is 23 hours, not 24 hours:

   as.POSIXct("2004-04-05") - as.POSIXct("2004-04-04")

You can address this by either using Date or chron classes or adding
the tz = "GMT" argument on your as.POSIXct calls as GMT does not
have daylight savings time.

See the Help Desk article in R News 4/1 for more on this.


On 2/21/06, gerald.herbert at hubbardbreeders.com
<gerald.herbert at hubbardbreeders.com> wrote:
> In some cases, incorrect results are produced by the code below intended to
> calculate the number of days between 2 dates.  The year in question was a
> leap year.
>
> Note the results for 2004-04-04 and 2004-04-05 are the same! They should be
> 37 and 38 respectively.
>
> > as.integer(as.POSIXct("2004-04-02") - as.POSIXct("2004-02-27"))
> [1] 35
> > as.integer(as.POSIXct("2004-04-03") - as.POSIXct("2004-02-27"))
> [1] 36
> > as.integer(as.POSIXct("2004-04-04") - as.POSIXct("2004-02-27"))
> [1] 37
> > as.integer(as.POSIXct("2004-04-05") - as.POSIXct("2004-02-27"))
> [1] 37
> > as.integer(as.POSIXct("2004-04-06") - as.POSIXct("2004-02-27"))
> [1] 38
>
>
>
> > as.integer(difftime(as.POSIXct("2004-04-06"),
> as.POSIXct("2004-02-27"),units="days"))
> [1] 38
> > as.integer(difftime(as.POSIXct("2004-04-04"),
> as.POSIXct("2004-02-27"),units="days"))
> [1] 37
> > as.integer(difftime(as.POSIXct("2004-04-05"),
> as.POSIXct("2004-02-27"),units="days"))
> [1] 37
>
> It appears that difftime() and "-" are producing invalid results.
>
>
> Regards,
>
> Gerald Herbert
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dimitris.rizopoulos at med.kuleuven.be  Tue Feb 21 17:11:49 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 21 Feb 2006 17:11:49 +0100
Subject: [R] Number of Days Between Dates: Incorrect Results For
	DateCalucations.
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAUmL1BciWlkSJzbtE4pRe0sKAAAAQAAAA7YffOmYFSU645jkej1wJmwEAAAAA@hubbardbreeders.com>
Message-ID: <01ab01c63701$851308f0$0540210a@www.domain>

check again your results with as.integer() replaced by round(); check 
also ?as.integer for its usage.

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: <gerald.herbert at hubbardbreeders.com>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, February 21, 2006 4:48 PM
Subject: [R] Number of Days Between Dates: Incorrect Results For 
DateCalucations.


> In some cases, incorrect results are produced by the code below 
> intended to
> calculate the number of days between 2 dates.  The year in question 
> was a
> leap year.
>
> Note the results for 2004-04-04 and 2004-04-05 are the same! They 
> should be
> 37 and 38 respectively.
>
>> as.integer(as.POSIXct("2004-04-02") - as.POSIXct("2004-02-27"))
> [1] 35
>> as.integer(as.POSIXct("2004-04-03") - as.POSIXct("2004-02-27"))
> [1] 36
>> as.integer(as.POSIXct("2004-04-04") - as.POSIXct("2004-02-27"))
> [1] 37
>> as.integer(as.POSIXct("2004-04-05") - as.POSIXct("2004-02-27"))
> [1] 37
>> as.integer(as.POSIXct("2004-04-06") - as.POSIXct("2004-02-27"))
> [1] 38
>
>
>
>> as.integer(difftime(as.POSIXct("2004-04-06"),
> as.POSIXct("2004-02-27"),units="days"))
> [1] 38
>> as.integer(difftime(as.POSIXct("2004-04-04"),
> as.POSIXct("2004-02-27"),units="days"))
> [1] 37
>> as.integer(difftime(as.POSIXct("2004-04-05"),
> as.POSIXct("2004-02-27"),units="days"))
> [1] 37
>
> It appears that difftime() and "-" are producing invalid results.
>
>
> Regards,
>
> Gerald Herbert
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From tlumley at u.washington.edu  Tue Feb 21 17:29:05 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 21 Feb 2006 08:29:05 -0800 (PST)
Subject: [R] Nested AIC
In-Reply-To: <03DCBBA079F2324786E8715BE538968AA5AD64@FIGMAIL-CLUS01.FIG.FK>
References: <03DCBBA079F2324786E8715BE538968AA5AD64@FIGMAIL-CLUS01.FIG.FK>
Message-ID: <Pine.LNX.4.64.0602210809450.1702@homer24.u.washington.edu>


This might be a more suitable message for eg the stats-discuss mailing 
list or one of the sci.stat.* newsgroups.

It is more complicated that it looks, partly because of the Anna Karenina 
problem: all nested models are the same, but non-nested models can be 
non-nested in different ways

Some notes:

1) Sometimes the AIC is clearly inappropriate: eg comparing the fit of a 
Poisson regression to a least-squares linear regression for count data. 
Here the likelihoods are not densities with respect to the same 
measure, so the likelihood ratio is meaningless.  You could also argue 
that the linear model isn't really being fitted by maximum likelihood.

2) You need to be careful when fitting models with different R functions, 
since they may omit different constants in the likelihood.

3) Transformations of the outcome are a problem. You can frame this as a 
mathematical problem or just note the difficulty of saying what you mean 
when you decide that the multiplicative error in one model is smaller than 
the additive error in another model.

4) If you have two least-squares linear regression models with the same 
outcome variable and different predictors then the AIC is choosing based 
on a consistent estimate of the mean squared prediction error, and in that 
sense it is a valid way to choose the model that predicts best.  This may 
or may not be the criterion you want, but if it isn't what you want then 
AIC isn't going to help.

5) If you have a large number of models then (nested or not) there is no 
guarantee that the estimate of prediction error is *uniformly* consistent, 
so the arguments behind AIC do not necessarily work.

        -thomas


On Tue, 21 Feb 2006, Ruben Roa wrote:

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Aaron MacNeil
> Sent: 20 February 2006 15:17
> To: r-help at stat.math.ethz.ch
> Subject: [R] Nested AIC
>
> Greetings,
> I have recently come into some confusion over weather or not AIC
> results for comparing among models requires that they be nested.
> Reading Burnham & Anderson (2002) they are explicit that nested models are not required, but other respected statisticians have suggested that nesting is a pre-requisite for comparison.  Could anyone who feels strongly regarding either position post their arguments for or against nested models and AIC? This would assist me greatly in some analysis I am currently conducting.
> Many thanks,
>
> Aaron
>
> ----
> Hi, Aaron, Burnham & Anderson are explicit but they do not go into any depth regarding this issue. Akaike's colleagues Sakamoto, Ishiguro, and Kitagawa (Akaike Information Criterion Statistics, 1986, KTK Scientific Publishers) do no either, deal with it directly, and the examples they present that I have examined (not even half of the total in the book), are all of nested models. However, by reading some of Akaike's papers and the book quoted above it does not appear to me that there is any restriction on the use of the AIC related to nestedness. In fact, the theory does not preclude the comparison of models with different *probability densities (or mass)* as long as you keep all constants (like 1/sqrt(2pi) in the normal) in the calculation.
> Akaike (1973) wrote in the first sentence of his paper his general principle, which he called an extension of the maximum likelihood principle:
> "Given a set of estimates theta_hat's of the vector of parameters theta of a probability distribution with density f(x|theta) we adopt as our final estimate the one which will give the maximum of the expected log-likelihood, which is by definition
> E(log f(X|theta_hat))=E(INTEGRAL f(x|theta)log f(x|theta_hat)dx)
> Where X is a random variable following the distribution with the density function f(x|theta) and is independent of theta_hat".
> All subsequent derivations in the paper, like the choice of distance measure, class of estimates, and elimination of the true parameter value, revolve around this principle. Now, nestedness is a mathematical property of what Burnham & Anderson call "the structural model", whereas Akaike's principle only concerns the probabilistic model f(x|theta) where the structural model is embedded.
> I reply to you even though I do not feel strongly about this issue and you asked for replies from people who feel strongly about this issue.
> Ruben
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From p.dalgaard at biostat.ku.dk  Tue Feb 21 17:36:21 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Feb 2006 17:36:21 +0100
Subject: [R] Number of Days Between Dates: Incorrect Results For Date
	Calucations.
In-Reply-To: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAUmL1BciWlkSJzbtE4pRe0sKAAAAQAAAA7YffOmYFSU645jkej1wJmwEAAAAA@hubbardbreeders.com>
References: <!~!UENERkVCMDkAAQACAAAAAAAAAAAAAAAAABgAAAAAAAAAUmL1BciWlkSJzbtE4pRe0sKAAAAQAAAA7YffOmYFSU645jkej1wJmwEAAAAA@hubbardbreeders.com>
Message-ID: <x2acckfz3u.fsf@turmalin.kubism.ku.dk>

<gerald.herbert at hubbardbreeders.com> writes:

> In some cases, incorrect results are produced by the code below intended to
> calculate the number of days between 2 dates.  The year in question was a
> leap year.
 
> Note the results for 2004-04-04 and 2004-04-05 are the same! They should be
> 37 and 38 respectively.

Nope. First, it depends on your timezone. Over here, they do actually
differ. However, a few weeks earlier, we have the similar phenomenon

> as.POSIXct("2004-03-29") - as.POSIXct("2004-02-27")
Time difference of 30.95833 days
> as.POSIXct("2004-03-28") - as.POSIXct("2004-02-27")
Time difference of 30 days

which is of course because March 28 was only 23 hours long which is in
turn because

> as.POSIXct("2004-03-28")
[1] "2004-03-28 CET"
> as.POSIXct("2004-03-29")
[1] "2004-03-29 CEST"
 
Get it?



> > as.integer(as.POSIXct("2004-04-02") - as.POSIXct("2004-02-27"))
> [1] 35
> > as.integer(as.POSIXct("2004-04-03") - as.POSIXct("2004-02-27"))
> [1] 36
> > as.integer(as.POSIXct("2004-04-04") - as.POSIXct("2004-02-27"))
> [1] 37
> > as.integer(as.POSIXct("2004-04-05") - as.POSIXct("2004-02-27"))
> [1] 37
> > as.integer(as.POSIXct("2004-04-06") - as.POSIXct("2004-02-27"))
> [1] 38
> 
> 
> 
> > as.integer(difftime(as.POSIXct("2004-04-06"),
> as.POSIXct("2004-02-27"),units="days"))
> [1] 38
> > as.integer(difftime(as.POSIXct("2004-04-04"),
> as.POSIXct("2004-02-27"),units="days"))
> [1] 37
> > as.integer(difftime(as.POSIXct("2004-04-05"),
> as.POSIXct("2004-02-27"),units="days"))
> [1] 37
> 
> It appears that difftime() and "-" are producing invalid results.
> 
> 
> Regards,
> 
> Gerald Herbert
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From buser at stat.math.ethz.ch  Tue Feb 21 17:46:00 2006
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Tue, 21 Feb 2006 17:46:00 +0100
Subject: [R] Extracting variance components from lmer
In-Reply-To: <c3cb73d50602200657x591409e9x4f04cbdedfcdaff8@mail.gmail.com>
References: <c3cb73d50602200657x591409e9x4f04cbdedfcdaff8@mail.gmail.com>
Message-ID: <17403.17352.580263.116693@stat.math.ethz.ch>

Hi Rick 

There may be a better way, but the following should work: 
 
attributes(vc.fit)$sc

Regards,

Christoph Buser

--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C13
ETH (Federal Inst. Technology)	8092 Zurich	 SWITZERLAND
phone: x-41-44-632-4673		fax: 632-1228
http://stat.ethz.ch/~buser/
--------------------------------------------------------------


Rick DeShon writes:
 > Hi All.
 > 
 > I need a bit of help extracting the residual error variance from the VarCorr
 > structure from lmer.
 > 
 > #Here's a 2-way random effects model
 > lmer.1    <- lmer(rating ~ (1|person)+(1|rater), data = dat)
 > 
 > #Get the structure
 > vc.fit <- VarCorr(lmer.1)
 > 
 > #results in.....
 > $person
 > 1 x 1 Matrix of class "dpoMatrix"
 >             (Intercept)
 > (Intercept)   0.7755392
 > 
 > $rater
 > 1 x 1 Matrix of class "dpoMatrix"
 >             (Intercept)
 > (Intercept)   0.2054469
 > 
 > attr(,"sc")
 > [1] 0.5051518
 > 
 > #I can pull out the person and rater variance components easy enough. For
 > example...
 > vc.person <- vc.fit$person at x
 > 
 > I'm sure it's simple but I have not been able to grab the residual variance
 > in the last matrix.  I simply wish to asign the residual to a scalar
 > variable.  Any suggestions would be appreciated!
 > 
 > Thanks!
 > 
 > Rick DeShon
 > 
 > 
 > --
 > Rick DeShon
 > 306 Psychology Building
 > Department of Psychology
 > Michigan State University
 > East Lansing, MI 48824-1116
 > 
 > 	[[alternative HTML version deleted]]
 > 
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From spluque at gmail.com  Tue Feb 21 17:48:05 2006
From: spluque at gmail.com (Sebastian Luque)
Date: Tue, 21 Feb 2006 10:48:05 -0600
Subject: [R] indexing within panels in xyplot
References: <87mzglgoue.fsf@arctocephalus.homelinux.org>
	<eb555e660602210806q89e6cdcjcc28849da5fbb9ae@mail.gmail.com>
Message-ID: <87r75wzmii.fsf@arctocephalus.homelinux.org>

"Deepayan Sarkar" <deepayan.sarkar at gmail.com> wrote:

[...]

> Well, there are exceptions to this rule, but generally x and y, when
> they are passed on to the panel function, are _already_ subsetted, so
> x[subscripts] makes absolutely no sense. Note how your panel function
> calls

> panel.xyplot(x, y, ...)

> without referring to subscripts at all. The subscripts argument is
> there for other variables (e.g. if you were drawing confidence
> intervals, and had a separate vector in your data specifying the
> interval lengths). In your case, there are no other variables
> involved, so just get rid of the subscripts.

Thanks Deepayan, I was indeed quite confused about this.

I realized I needed to limit the fitted line to the range of x values the
line is fit to, so I changed to panel.curve:

---<---------------cut here---------------start-------------->---
xyplot(y ~ x | facA, groups = facB, data = toydf,
       panel.groups = function(x, y, ...) {
         panel.xyplot(x, y, ...)
         lindx <- which(y == max(y, na.rm = TRUE))
         xleft <- mean(x[lindx], na.rm = TRUE)
         fit <- lm(y[x >= xleft] ~ x[x >= xleft])
         panel.curve(coef(fit)[1] + (coef(fit)[2] * x),
                     xleft, max(x, na.rm = TRUE))
       })

---<---------------cut here---------------end---------------->---

but can't find a way to color the line for each group differently.  I
tried passing a length-2 vector as a 'col' argument to panel.curve.
Unfortunately it's only picking the first, so that both lines get colored
the same.  I'm not sure, but it seems as if I need to use
'panel.superpose' directly to do this, as the help page suggests the above
would work?

Cheers,

-- 
Sebastian P. Luque



From drf5n at maplepark.com  Tue Feb 21 18:08:38 2006
From: drf5n at maplepark.com (David Forrest)
Date: Tue, 21 Feb 2006 11:08:38 -0600 (CST)
Subject: [R] color quantization / binning a variable into levels
Message-ID: <Pine.LNX.4.58.0602211020160.16984@maplepark.com>

Hi all,

I'd like to quantize a variable to map it into a limited set of integers
for use with a colormap.  "image" and filled.contour"  do this mapping
inside somewhere, but I'd like to choose the colors for plotting a set of
polygons.  Is there a pre-existing function that does something like this
well?  i.e., is capable of using 'breaks'?

quantize<-function(x,n=10, breaks=NULL){
# bin the variable x into n levels
  xmin<-min(x)
  xmax<-max(x)
  1+floor(n*(x-xmin)/(xmax-xmin)*.999)
}

x<- -10:10
cbind(x,quantize(x,2),quantize(x),quantize(x,21))

quantize(x,breaks=c(5,7))   #

Thanks for your time,

Dave
-- 
 Dr. David Forrest
 drf at vims.edu                                    (804)684-7900w
 drf5n at maplepark.com                             (804)642-0662h
                                   http://maplepark.com/~drf5n/



From bernarduse1 at yahoo.fr  Tue Feb 21 18:15:58 2006
From: bernarduse1 at yahoo.fr (Marc Bernard)
Date: Tue, 21 Feb 2006 18:15:58 +0100 (CET)
Subject: [R] Compute a correlation matrix from an existing covariance matrix
Message-ID: <20060221171558.89597.qmail@web25815.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060221/aae85938/attachment.pl

From andy_liaw at merck.com  Tue Feb 21 18:25:33 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 21 Feb 2006 12:25:33 -0500
Subject: [R] R and packages
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED82E@usctmx1106.merck.com>

From: Thomas Lumley
> 
> On Mon, 20 Feb 2006, Erin Hodgess wrote:
> 
> > Dear R People:
> >
> > Here is yet another strange problem.
> >
> > I'm using R in one of my classes.  However, the computer 
> lab has something
> > called "Deep Freeze" and the students cannot save anything 
> to the hard drive.
> >
> > I had R installed and things were working well.  They would 
> save their
> > .Rdata files to disks.
> >
> > Now, we need to add more packages.  We can't download and we can't
> > bring them in via zip files (already tried both!)  When the 
> zip files
> > are expanded, of course they build new directories......
> 
> I would suggest making this the system administrator's 
> problem.  Either 
> your site really has a policy that would prohibit R packages 
> (in which 
> case trying to subvert it may not be a good idea) or it is 
> exactly the 
> sort of problem that system administrators are supposed to solve.
> 
> Distrust for R binary (and even source) packages is not a completely 
> unreasonable attitude. They can execute arbitrary code on 
> your computer 
> and, in contrast to R itself, you usually have no real 
> knowledge of who 
> wrote them.
> 
>  	-thomas
> 
> 
> 
> > I'm completely annoyed because learning to download packages
> > and installing them from local zips are actually important tasks!
> > We're also losing good teaching/learning time!
> >
> > Anyhow, what I would like to do is produce a sort of combination R
> > installation exe with our extra libraries as part of the package.
> >
> > Does anyone have any suggestions on how this could be done, please?
> >
> > This is R for Windows, Version 2.2.1

In case the sysadmin refuses to make it his/her problem, this would be a
good alternative.  It's not hard to build a custom R installer that includes
packages of your choice.  It's all documented.  Look in the R-admin manual
(e.g., http://cran.r-project.org/doc/manuals/R-admin.html) and search for
EXTRA_PKGS.

Andy



> > Thanks for any help!  Sorry about the totally weird problem!
> >
> > Sincerely,
> > Erin Hodgess
> > Associate Professor
> > Department of Computer and Mathematical Sciences
> > University of Houston - Downtown
> > mailto: hodgess at gator.uhd.edu
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> 
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From andy_liaw at merck.com  Tue Feb 21 18:27:49 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 21 Feb 2006 12:27:49 -0500
Subject: [R] Compute a correlation matrix from an existing covariance
 matrix
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED82F@usctmx1106.merck.com>

See ?cov2cor.

Andy

From: Marc Bernard
> 
> Dear All,
>    
>   I am wondering if there is an R function to convert a 
> covariance matrix to a correlation matrix. I have a 
> covariance matrix sigma and I want to compute the 
> corresponding correlation matrix R from sigma.
>    
>   Thank you very much,
>    
>   Bernard
> 
> 		
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From p.dalgaard at biostat.ku.dk  Tue Feb 21 18:34:23 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Feb 2006 18:34:23 +0100
Subject: [R] Compute a correlation matrix from an existing covariance
	matrix
In-Reply-To: <20060221171558.89597.qmail@web25815.mail.ukl.yahoo.com>
References: <20060221171558.89597.qmail@web25815.mail.ukl.yahoo.com>
Message-ID: <x264n8fwf4.fsf@turmalin.kubism.ku.dk>

Marc Bernard <bernarduse1 at yahoo.fr> writes:

> Dear All,
>    
>   I am wondering if there is an R function to convert a covariance matrix to a correlation matrix. I have a covariance matrix sigma and I want to compute the corresponding correlation matrix R from sigma.

You mean something like cov2cor()?

(BTW, why doesn't the page for cor/var/cov/cov2cor show up on
help.search("covariance") or help.search("correlation") for me??)

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From kjetilbrinchmannhalvorsen at gmail.com  Tue Feb 21 18:35:32 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Tue, 21 Feb 2006 13:35:32 -0400
Subject: [R] Compute a correlation matrix from an existing covariance
 matrix
In-Reply-To: <20060221171558.89597.qmail@web25815.mail.ukl.yahoo.com>
References: <20060221171558.89597.qmail@web25815.mail.ukl.yahoo.com>
Message-ID: <43FB4F64.4070305@gmail.com>

Marc Bernard wrote:
> Dear All,
>    
>   I am wondering if there is an R function to convert a covariance matrix to a correlation matrix. I have a covariance matrix sigma and I want to compute the corresponding correlation matrix R from sigma.
>    

Does cov2cor  do what you want?

Kjetil

>   Thank you very much,
>    
>   Bernard
> 
> 		
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Tue Feb 21 18:36:15 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Feb 2006 17:36:15 +0000 (GMT)
Subject: [R] Nested AIC
In-Reply-To: <Pine.LNX.4.64.0602210809450.1702@homer24.u.washington.edu>
References: <03DCBBA079F2324786E8715BE538968AA5AD64@FIGMAIL-CLUS01.FIG.FK>
	<Pine.LNX.4.64.0602210809450.1702@homer24.u.washington.edu>
Message-ID: <Pine.LNX.4.64.0602211706500.11480@gannet.stats.ox.ac.uk>

On Tue, 21 Feb 2006, Thomas Lumley wrote:

>
> This might be a more suitable message for eg the stats-discuss mailing
> list or one of the sci.stat.* newsgroups.
>
> It is more complicated that it looks, partly because of the Anna Karenina
> problem: all nested models are the same, but non-nested models can be
> non-nested in different ways

And I am sure Akaike appreciated that, which may be why he only (AFAIK) 
derived a theoretical basis for AIC under strictly limited conditions 
including nesting.

> Some notes:
>
> 1) Sometimes the AIC is clearly inappropriate: eg comparing the fit of a
> Poisson regression to a least-squares linear regression for count data.
> Here the likelihoods are not densities with respect to the same
> measure, so the likelihood ratio is meaningless.  You could also argue
> that the linear model isn't really being fitted by maximum likelihood.
>
> 2) You need to be careful when fitting models with different R functions,
> since they may omit different constants in the likelihood.
>
> 3) Transformations of the outcome are a problem. You can frame this as a
> mathematical problem or just note the difficulty of saying what you mean
> when you decide that the multiplicative error in one model is smaller than
> the additive error in another model.
>
> 4) If you have two least-squares linear regression models with the same
> outcome variable and different predictors then the AIC is choosing based
> on a consistent estimate of the mean squared prediction error, and in that
> sense it is a valid way to choose the model that predicts best.  This may
> or may not be the criterion you want, but if it isn't what you want then
> AIC isn't going to help.
>
> 5) If you have a large number of models then (nested or not) there is no
> guarantee that the estimate of prediction error is *uniformly* consistent,
> so the arguments behind AIC do not necessarily work.

(That only makes sense if the model class changes with 'n', suitably 
defined.  You do get uniform consistency over a finite class of models, 
one of Akaike (1973)'s conditions.  However, to use AIC you don't just 
need a consistent estimator, but to worry about the consistency of 
the O(1/n) term in the mean since AIC/n is effectively s^2 + 2p/n.)

One other note.

AIC/n is a consistent estimator but only if the model is true, and one 
with a lot of sampling error.  Differences in AIC are much more precisely 
estimated for a pair of nested models than for some non-nested pairs.  So 
sampling error can make comparisons of AIC meaningless unless the 
differences are large (and 'large' grows with 'n' for some appropriate 
'n').

A recent talk of mine

 	http://www.stats.ox.ac.uk/~ripley/Nelder80.pdf

may be illuminating.  There is a published paper version.

>
> On Tue, 21 Feb 2006, Ruben Roa wrote:
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Aaron MacNeil
>> Sent: 20 February 2006 15:17
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] Nested AIC
>>
>> Greetings,
>> I have recently come into some confusion over weather or not AIC
>> results for comparing among models requires that they be nested.
>> Reading Burnham & Anderson (2002) they are explicit that nested models are not required, but other respected statisticians have suggested that nesting is a pre-requisite for comparison.  Could anyone who feels strongly regarding either position post their arguments for or against nested models and AIC? This would assist me greatly in some analysis I am currently conducting.
>> Many thanks,
>>
>> Aaron
>>
>> ----
>> Hi, Aaron, Burnham & Anderson are explicit but they do not go into any depth regarding this issue. Akaike's colleagues Sakamoto, Ishiguro, and Kitagawa (Akaike Information Criterion Statistics, 1986, KTK Scientific Publishers) do no either, deal with it directly, and the examples they present that I have examined (not even half of the total in the book), are all of nested models. However, by reading some of Akaike's papers and the book quoted above it does not appear to me that there is any restriction on the use of the AIC related to nestedness. In fact, the theory does not preclude the comparison of models with different *probability densities (or mass)* as long as you keep all constants (like 1/sqrt(2pi) in the normal) in the calculation.
>> Akaike (1973) wrote in the first sentence of his paper his general principle, which he called an extension of the maximum likelihood principle:
>> "Given a set of estimates theta_hat's of the vector of parameters theta of a probability distribution with density f(x|theta) we adopt as our final estimate the one which will give the maximum of the expected log-likelihood, which is by definition
>> E(log f(X|theta_hat))=E(INTEGRAL f(x|theta)log f(x|theta_hat)dx)
>> Where X is a random variable following the distribution with the density function f(x|theta) and is independent of theta_hat".
>> All subsequent derivations in the paper, like the choice of distance measure, class of estimates, and elimination of the true parameter value, revolve around this principle. Now, nestedness is a mathematical property of what Burnham & Anderson call "the structural model", whereas Akaike's principle only concerns the probabilistic model f(x|theta) where the structural model is embedded.
>> I reply to you even though I do not feel strongly about this issue and you asked for replies from people who feel strongly about this issue.
>> Ruben
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington, Seattle
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Mon Feb 20 23:43:30 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 20 Feb 2006 14:43:30 -0800 (PST)
Subject: [R] lattice: calling functions
In-Reply-To: <eb555e660602140859m501cbb05w6b60c055547a8aed@mail.gmail.com>
Message-ID: <Pine.LNX.4.43.0602201443300.15505@hymn09.u.washington.edu>

On Tue, 14 Feb 2006, Deepayan Sarkar wrote:

> On 2/14/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>> On 2/14/2006 9:38 AM, Gabor Grothendieck wrote:
>>> On 2/14/06, Duncan Murdoch <murdoch at stats.uwo.ca> wrote:
>>>> On 2/14/2006 8:56 AM, Wolfram Fischer wrote:
>>>> > I defined three functions:
>>>> >
>>>> >> fun0 <- function( x=1:5, y=1:5, ... ) xyplot( y ~ x, ... )
>>>> >
>>>> >> fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, ... )
>>>> >> fun2 <- function( ... ) xyplot( ... )
>>>> >
>>>> > The call of fun0() works as expected.
>>>> >
>>>> > The call of fun1() causes the following error:
>>>> >     'Error in eval(expr, envir, enclos) : object "y" not found'
>>>> >
>>>> > How should I define fun2 to avoid the error?
>>>>
>>>> fun2 is fine, it's fun1 that has problems.  It is passing a formula
>>>> through fun2 to xyplot without telling xyplot where to evaluate the
>>>> arguments.  If you change it to
>>>>
>>>> fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, data=enviroment(), ...
>> )
>
> data=NULL works too, which is apparently what lm has.  The point being
> that the environment of the formula is looked at, but the default
> data=parent.frame() subverts that because of the way eval works (using
> enclos only when envir is a list or data frame. What's wrong with
> environments?).

The reason for not using enclos= when envir= is an environment is that an environment already consists of a frame plus enclosing environment.  The point of enclos= is to supply the enclosing environment when envir= doesn't have one built in.

        -thomas



>                                      Even the following works:
>
> fun1 <- function( x=1:5, y=1:5, ... )
>    fun2( y ~ x, data = data.frame(x = x), ... )
>
> I don't understand non-standard evaluation all that well, so I'll
> happily consider any suggestions. I'll try changing the defaults to
> NULL and see if there are any obvious problems.
>
> Deepayan
>
>>>> it will tell xyplot to look in the current environment at the time of
>>>> the call, i.e. the fun1 evaluation environment where x and y live.
>>>>
>>>
>>> Although this does seem to be how xyplot works, I think it indicates
>>> there is a problem with it.
>>>
>>> The help file for xyplot indicates that for the xyplot formula method
>>> the default
>>> environment is the caller environment whereas it ought to be the
>> environment
>>> of the formula:
>>>
>>>     data: For the 'formula' method, a data frame containing values for
>>>           any variables in the formula, as well as 'groups' and
>>>           'subset' if applicable.  By default the environment where the
>>>           function was called from is used.
>>>
>>> For example, if we replace xyplot with lm it does work as expected:
>>>
>>>    fun1 <- function( x=1:5, y=1:5, ... ) fun2( y ~ x, ... )
>>>    fun2 <- function( ... ) lm( ... )
>>>    fun1()
>>
>> You're right, I forgot formulas have associated environments.  I've
>> added the lattice maintainer to the cc list.
>>
>> Duncan Murdoch
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From mtb954 at gmail.com  Tue Feb 21 18:53:49 2006
From: mtb954 at gmail.com (mtb954@gmail.com)
Date: Tue, 21 Feb 2006 11:53:49 -0600
Subject: [R] How to select only certain rows when making a new dataframe?
Message-ID: <e40d78ce0602210953x7668a272r3e50c8d4ec0c3240@mail.gmail.com>

Dear R-users,

I have two data frames. The "FIRST" data frame has 100 rows, the
"SECOND" data frame has only 50 rows.

The data frames have different variables in columns ("VAR1," "VAR2,"
etc) but they share a column called "ID" that contains a unique
identifer linking the two data frames.

I would like to make a "THIRD" data frame containing just the rows of
the "FIRST" data frame that match the rows (on "ID") in the "SECOND"
data frame.

>THIRD=data.frame(FIRST$ID,FIRST$VAR1,FIRST$VAR2)

How can I modify this line to include in "THIRD" just the rows in
"FIRST" that match the rows in "SECOND"? (i.e., contain the same value
in the shared "ID" column).

Thanks! Mark



From ccleland at optonline.net  Tue Feb 21 19:06:20 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Tue, 21 Feb 2006 13:06:20 -0500
Subject: [R] How to select only certain rows when making a new dataframe?
In-Reply-To: <e40d78ce0602210953x7668a272r3e50c8d4ec0c3240@mail.gmail.com>
References: <e40d78ce0602210953x7668a272r3e50c8d4ec0c3240@mail.gmail.com>
Message-ID: <43FB569C.3000501@optonline.net>

THIRD <- merge(FIRST, SECOND, by="ID", all.x=FALSE, all.y=TRUE)

mtb954 at gmail.com wrote:
> Dear R-users,
> 
> I have two data frames. The "FIRST" data frame has 100 rows, the
> "SECOND" data frame has only 50 rows.
> 
> The data frames have different variables in columns ("VAR1," "VAR2,"
> etc) but they share a column called "ID" that contains a unique
> identifer linking the two data frames.
> 
> I would like to make a "THIRD" data frame containing just the rows of
> the "FIRST" data frame that match the rows (on "ID") in the "SECOND"
> data frame.
> 
>> THIRD=data.frame(FIRST$ID,FIRST$VAR1,FIRST$VAR2)
> 
> How can I modify this line to include in "THIRD" just the rows in
> "FIRST" that match the rows in "SECOND"? (i.e., contain the same value
> in the shared "ID" column).
> 
> Thanks! Mark
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ales.ziberna at gmail.com  Tue Feb 21 19:08:19 2006
From: ales.ziberna at gmail.com (=?ISO-8859-2?Q?Ale=B9_=AEiberna?=)
Date: Tue, 21 Feb 2006 19:08:19 +0100
Subject: [R] Convertin rows of a matrix to a list
Message-ID: <43FB5713.40808@gmail.com>

Hello!

I would like to convert rows of a matrix to a elements of a list.

#For example, if I have
mat<-matrix(1:100,ncol=5, nrow=20)

#I can do:
list<-apply(mat,1,list)
list
#however this is not quite what I want. To get what I want, I have to do:
list<-lapply(list,function(x)x[[1]])
list

Is there a faster way?

Best regards,
Ales Ziberna



From abunn at whrc.org  Tue Feb 21 19:09:33 2006
From: abunn at whrc.org (Andy Bunn)
Date: Tue, 21 Feb 2006 13:09:33 -0500
Subject: [R] How to select only certain rows when making a new dataframe?
In-Reply-To: <e40d78ce0602210953x7668a272r3e50c8d4ec0c3240@mail.gmail.com>
Message-ID: <NEBBIPHDAMMOKDKPOFFIGECAEAAA.abunn@whrc.org>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of mtb954 at gmail.com
> Sent: Tuesday, February 21, 2006 12:54 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] How to select only certain rows when making a new
> dataframe?
> 
> 
> Dear R-users,
> 
> I have two data frames. The "FIRST" data frame has 100 rows, the
> "SECOND" data frame has only 50 rows.
> 
> The data frames have different variables in columns ("VAR1," "VAR2,"
> etc) but they share a column called "ID" that contains a unique
> identifer linking the two data frames.
> 
> I would like to make a "THIRD" data frame containing just the rows of
> the "FIRST" data frame that match the rows (on "ID") in the "SECOND"
> data frame.
> 
> >THIRD=data.frame(FIRST$ID,FIRST$VAR1,FIRST$VAR2)
> 
> How can I modify this line to include in "THIRD" just the rows in
> "FIRST" that match the rows in "SECOND"? (i.e., contain the same value
> in the shared "ID" column).

List this?

one <- data.frame(ID = 1:100, Var1 = runif(100), Var2 = runif(100))
two <- data.frame(ID = 26:50, VarA = runif(50), VarB = runif(50))
three <- one[one$ID == two$ID,]



From ripley at stats.ox.ac.uk  Tue Feb 21 19:13:01 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Feb 2006 18:13:01 +0000 (GMT)
Subject: [R] Unable to configure R 2.2.1 on Solaris 5.10 x86_64
In-Reply-To: <1140477707.3808.2.camel@unknown>
References: <1140477707.3808.2.camel@unknown>
Message-ID: <Pine.LNX.4.64.0602210726530.30785@gannet.stats.ox.ac.uk>

Have we not seen such posts before from you?  Perhaps you need to seek or 
employ a local Solaris guru (if they exist at `mac.com', or whatever your 
real but unstated affiliation is).

The information about what is going wrong is in the file config.log, so 
please study it.

But as it is not finding your readline headers, they appear not to be 
where you are saying to look. You certainly should not be having 
/foo/include/readline in your cpp path, just /foo/include since the 
headers looked for are of the form <readline/history.h>.

On Mon, 20 Feb 2006, Aric Gregson wrote:

> Hello,
>
> Apologies for the post here. I have read the R-Admin (learned
> a lot!) and searched the web for days, but still fail at compiling R on
> my Ultra 20 running solaris 10 x86 1/06.
>
> This is the tail of './configure' output:
> .....
> checking for dlopen in -ldl... yes
> checking readline/history.h usability... no
> checking readline/history.h presence... no
> checking for readline/history.h... no
> checking readline/readline.h usability... no
> checking readline/readline.h presence... no
> checking for readline/readline.h... no
> checking for rl_callback_read_char in -lreadline... no
> checking for main in -lncurses... no
> checking for main in -ltermcap... yes
> checking for rl_callback_read_char in -lreadline... no
> checking for history_truncate_file... no
> configure: error: --with-readline=yes (default) and headers/libs are
> not available
>
> My R-2.2.1/config.site has the following changes from default:
>
> CC="cc -xtarget=opteron -xarch=amd64"
> CFLAGS="-xO5 -xlibmil -dalign"
> CPPFLAGS=-I/opt/sfw/include -I/opt/sfw/include/readline \
> -I/opt/csw/include -I/opt/SUNWspro/include -I/opt/csw/include/readline
> F77="f95 -xarch=amd64 -xtarget=opteron"
> FFLAGS="-xO5 -xlibmil -dalign"
> LDFLAGS=-L/opt/SUNWspro/lib/amd64/ -L/opt/sfw/lib -L/opt/csw/lib
> CXX="CC -xarch=amd64 -xtarget=opteron"
> CXXFLAGS="-xO5 -xlibmil -dalign"
> R_BROWSER=mozilla
> MAKE=gmake
>
> My .zshrc file has the following (as I saw that some of the LDFLAGS
> should match my LD_LIBRARY_PATH and CONFIG_SHELL=/bin/ksh):
>
> LD_LIBRARY_PATH=/opt/sfw/include:/opt/sfw/include/readline:/usr/local/lib:/usr/X/lib:/usr/lib:/usr/ucblib:/lib:/usr/ccs/lib:/etc/lib:/usr/dt/lib:/opt/SUNWspro/lib/amd64/:/opt/sfw/lib:/opt/csw/lib

You do not want include paths in the library path.

>
> Readline (version 4.2 from the Sun Companion CD) is located
> in /opt/sfw/include/readline. Both the readline.h and history.h files
> are there. Version 5.0 is located in /opt/csw/include/readline (from
> Blastwave). As you can see, I am new at compiling in general and
> Solaris specifically. Any help would be greatly appreciated.
>
> System information:
>
> System = SunOS
> Release = 5.10
> KernelID = Generic_118844-26
> Machine = i86pc
> OEM# = 0
> Origin# = 1
> NumCPU = 1
>
> thanks,
>
> aric


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From quin.wills at googlemail.com  Tue Feb 21 19:20:09 2006
From: quin.wills at googlemail.com (Quin Wills)
Date: Tue, 21 Feb 2006 18:20:09 -0000
Subject: [R] How to get around heteroscedasticity with non-linear least
	squares in R?
Message-ID: <001601c63713$73e59590$b86b01a3@notebookquin>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060221/2bc5cf93/attachment.pl

From andy_liaw at merck.com  Tue Feb 21 19:20:44 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 21 Feb 2006 13:20:44 -0500
Subject: [R] Convertin rows of a matrix to a list
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED831@usctmx1106.merck.com>

Perhaps something like:

    as.list(as.data.frame(t(mat)))

Andy

From: Ale?? ??iberna
> 
> Hello!
> 
> I would like to convert rows of a matrix to a elements of a list.
> 
> #For example, if I have
> mat<-matrix(1:100,ncol=5, nrow=20)
> 
> #I can do:
> list<-apply(mat,1,list)
> list
> #however this is not quite what I want. To get what I want, I 
> have to do:
> list<-lapply(list,function(x)x[[1]])
> list
> 
> Is there a faster way?
> 
> Best regards,
> Ales Ziberna
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From lassana.koita at aviation-civile.gouv.fr  Tue Feb 21 19:23:05 2006
From: lassana.koita at aviation-civile.gouv.fr (KOITA Lassana - STAC/ACE)
Date: Tue, 21 Feb 2006 19:23:05 +0100
Subject: [R] I need your help
Message-ID: <OFDBDB1F8A.0DD8DFC9-ONC125711C.0063F275@aviation-civile.gouv.fr>





Hi,
Dear R users
I have problem with the following code. The matrix result must be a matrix
(3x3). But I have obtained a matrix(3x1) and I don't know why.
So, I need your help

Best regards

#####################################################################

taille <- function (delta, t, prob = 0.2)

{

niv.conf <- c(0.90, 0.95, 0.99)
if(niv.conf <- 0.90) {
   t <- 1.645
}

 else {

 if(niv.conf <- 0.95) {
   t <- 1.96
}

t <- 2.575
}

n <- length(delta)

m <- length(t)

result <- matrix(nrow = n, ncol = m);

for (i in 1:n)
   {
     for(j in 1:m)

      {

       result[i,j]<- prob*(1-prob)*((t[i])^2)/(delta[j])^2 ;

      }
   }

rownames(result) <- delta
colnames(result) <- niv.conf
round(result,2)

}

taille (delta <- c( 0.01, 0.02, 0.03), niv.conf <-  c(0.90, 0.95, 0.99))

####################################################################"



Lassana KOITA
Etudes de S??curit?? et d'Exploitation a??roportuaires / Aerodrome Safety &
Statistical analysis
Service Technique de l'Aviation Civile (STAC) / Civil Aviation Technical
Department
Direction G??n??rale de l'Aviation Civile (DGAC) / French Civil Aviation
Authority
Tel: 01 49 56 80 60
Fax: 01 49 56 82 14
E-mail: Lassana.Koita at aviation-civile.gouv.fr
http://www.stac.aviation-civile.gouv.fr/



From deepayan.sarkar at gmail.com  Tue Feb 21 19:32:09 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 21 Feb 2006 12:32:09 -0600
Subject: [R] indexing within panels in xyplot
In-Reply-To: <87r75wzmii.fsf@arctocephalus.homelinux.org>
References: <87mzglgoue.fsf@arctocephalus.homelinux.org>
	<eb555e660602210806q89e6cdcjcc28849da5fbb9ae@mail.gmail.com>
	<87r75wzmii.fsf@arctocephalus.homelinux.org>
Message-ID: <eb555e660602211032g1b2aedf8xdc8197d15a7e6d9c@mail.gmail.com>

On 2/21/06, Sebastian Luque <spluque at gmail.com> wrote:
> "Deepayan Sarkar" <deepayan.sarkar at gmail.com> wrote:
>
> [...]
>
> > Well, there are exceptions to this rule, but generally x and y, when
> > they are passed on to the panel function, are _already_ subsetted, so
> > x[subscripts] makes absolutely no sense. Note how your panel function
> > calls
>
> > panel.xyplot(x, y, ...)
>
> > without referring to subscripts at all. The subscripts argument is
> > there for other variables (e.g. if you were drawing confidence
> > intervals, and had a separate vector in your data specifying the
> > interval lengths). In your case, there are no other variables
> > involved, so just get rid of the subscripts.
>
> Thanks Deepayan, I was indeed quite confused about this.
>
> I realized I needed to limit the fitted line to the range of x values the
> line is fit to, so I changed to panel.curve:
>
> ---<---------------cut here---------------start-------------->---
> xyplot(y ~ x | facA, groups = facB, data = toydf,
>        panel.groups = function(x, y, ...) {
>          panel.xyplot(x, y, ...)
>          lindx <- which(y == max(y, na.rm = TRUE))
>          xleft <- mean(x[lindx], na.rm = TRUE)
>          fit <- lm(y[x >= xleft] ~ x[x >= xleft])
>          panel.curve(coef(fit)[1] + (coef(fit)[2] * x),
>                      xleft, max(x, na.rm = TRUE))
>        })
>
> ---<---------------cut here---------------end---------------->---
>
> but can't find a way to color the line for each group differently.  I
> tried passing a length-2 vector as a 'col' argument to panel.curve.
> Unfortunately it's only picking the first, so that both lines get colored
> the same.  I'm not sure, but it seems as if I need to use
> 'panel.superpose' directly to do this, as the help page suggests the above
> would work?

The (somewhat mysterious) solution is the following:


xyplot(y ~ x | facA, groups = facB, data = toydf,
       panel = panel.superpose,
       panel.groups = function(x, y, col.line, ...) {
           panel.xyplot(x, y, ...)
           lindx <- which(y == max(y, na.rm = TRUE))
           xleft <- mean(x[lindx], na.rm = TRUE)
           fit <- lm(y[x >= xleft] ~ x[x >= xleft])
           panel.curve(coef(fit)[1] + (coef(fit)[2] * x),
                       col = col.line,
                       xleft, max(x, na.rm = TRUE))
       })

This uses the fact that panel.groups is always supplied a 'col.line'
argument (along with many others) which has been suitably calculated
for each group (see panel.superpose for how this works).

You are in fact using 'panel.superpose' directly, as that's what the
panel function defaults to when there is a 'groups' argument. However,
this will change in R-2.3.0, and to use a panel.groups argument, you
will need to explicitly specify panel=panel.superpose. Sorry for the
confusion, but I believe this to be more sensible in the bigger scheme
of things.

If you now want a different set of line colors, you can

(1) either modify the "superpose.line" parameter, or
(2) specify col.line = c('red', 'blue') etc in the xyplot call.

Hope that makes things a bit clearer.

Deepayan
--
http://www.stat.wisc.edu/~deepayan/



From andy_liaw at merck.com  Tue Feb 21 19:56:39 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 21 Feb 2006 13:56:39 -0500
Subject: [R] How to get around heteroscedasticity with non-linear leas t
 squares in R?
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED833@usctmx1106.merck.com>

Your understanding isn't similar to mine.  Mine says robust/resistant
methods are for data with heavy tails, not heteroscedasticity.  The common
ways to approach heteroscedasticity are transformation and weighting.  The
first is easy and usually quite effective for dose-response data.  The
second is not much harder.  Both can be done in R with nls().

Andy

From: Quin Wills
> 
> I am using "nls" to fit dose-response curves but am not sure 
> how to approach
> more robust regression in R to get around the problem of the my error
> showing increased variance with increasing dose.  
> 
>  
> 
> My understanding is that "rlm" or "lqs" would not be a good idea here.
> 'Fairly new to regression work, so apologies if I'm missing something
> obvious.
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From pcampbell at econ.bbk.ac.uk  Tue Feb 21 20:32:27 2006
From: pcampbell at econ.bbk.ac.uk (Phineas Campbell)
Date: Tue, 21 Feb 2006 19:32:27 -0000
Subject: [R] Unable to configure R 2.2.1 on Solaris 5.10 x86_64
In-Reply-To: <1140477707.3808.2.camel@unknown>
Message-ID: <NGECIFANPOJAGABBAEAPEENIFJAA.pcampbell@econ.bbk.ac.uk>

Which compiler are you using?

I successfully built R for Solaris on SPARC using GCC, but it took a while
to get it working the first time.

The first step would be to see if you can build simple "Hello World" apps
for C, C++ and Fortran in the directory in which you are going to install R.

If you are unable to do this I would suggest that you build GCC from
sources, and rather than use the Sun Software companion disk download the
most recent versions of the various libraries and utilities from
www.sunfreeware.com.

HTH

Phineas Campbell
Birkbeck College
University of London





-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Aric Gregson
Sent: Monday, February 20, 2006 11:22 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Unable to configure R 2.2.1 on Solaris 5.10 x86_64


Hello,

Apologies for the post here. I have read the R-Admin (learned
a lot!) and searched the web for days, but still fail at compiling R on
my Ultra 20 running solaris 10 x86 1/06.

This is the tail of './configure' output:
.....
checking for dlopen in -ldl... yes
checking readline/history.h usability... no
checking readline/history.h presence... no
checking for readline/history.h... no
checking readline/readline.h usability... no
checking readline/readline.h presence... no
checking for readline/readline.h... no
checking for rl_callback_read_char in -lreadline... no
checking for main in -lncurses... no
checking for main in -ltermcap... yes
checking for rl_callback_read_char in -lreadline... no
checking for history_truncate_file... no
configure: error: --with-readline=yes (default) and headers/libs are
not available

My R-2.2.1/config.site has the following changes from default:

CC="cc -xtarget=opteron -xarch=amd64"
CFLAGS="-xO5 -xlibmil -dalign"
CPPFLAGS=-I/opt/sfw/include -I/opt/sfw/include/readline \
-I/opt/csw/include -I/opt/SUNWspro/include -I/opt/csw/include/readline
F77="f95 -xarch=amd64 -xtarget=opteron"
FFLAGS="-xO5 -xlibmil -dalign"
LDFLAGS=-L/opt/SUNWspro/lib/amd64/ -L/opt/sfw/lib -L/opt/csw/lib
CXX="CC -xarch=amd64 -xtarget=opteron"
CXXFLAGS="-xO5 -xlibmil -dalign"
R_BROWSER=mozilla
MAKE=gmake

My .zshrc file has the following (as I saw that some of the LDFLAGS
should match my LD_LIBRARY_PATH and CONFIG_SHELL=/bin/ksh):

LD_LIBRARY_PATH=/opt/sfw/include:/opt/sfw/include/readline:/usr/local/lib:/u
sr/X/lib:/usr/lib:/usr/ucblib:/lib:/usr/ccs/lib:/etc/lib:/usr/dt/lib:/opt/SU
NWspro/lib/amd64/:/opt/sfw/lib:/opt/csw/lib

Readline (version 4.2 from the Sun Companion CD) is located
in /opt/sfw/include/readline. Both the readline.h and history.h files
are there. Version 5.0 is located in /opt/csw/include/readline (from
Blastwave). As you can see, I am new at compiling in general and
Solaris specifically. Any help would be greatly appreciated.

System information:

System = SunOS
Release = 5.10
KernelID = Generic_118844-26
Machine = i86pc
OEM# = 0
Origin# = 1
NumCPU = 1

thanks,

aric

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From mail at bymouth.com  Tue Feb 21 20:50:12 2006
From: mail at bymouth.com (Stephen Choularton)
Date: Wed, 22 Feb 2006 06:50:12 +1100
Subject: [R] feature not available
Message-ID: <000001c63720$0b1f7550$9701a8c0@Tablet>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060222/2100b135/attachment.pl

From andy_liaw at merck.com  Tue Feb 21 21:03:39 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 21 Feb 2006 15:03:39 -0500
Subject: [R] feature not available
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED835@usctmx1106.merck.com>

From: Stephen Choularton
> 
> Hi
>  
> I am working with this data:
>  
>  
> my data summary is:
>  
>  
> > summary(spi)
>       open           high           low           close       
>    volume
> 
>  Min.   :4315   Min.   :4365   Min.   :4301   Min.   :4352   Min.   :
> 0  
>  1st Qu.:4480   1st Qu.:4497   1st Qu.:4458   1st Qu.:4475   1st
> Qu.:11135  
>  Median :4609   Median :4631   Median :4594   Median :4614   Median
> :14439  
>  Mean   :4620   Mean   :4640   Mean   :4599   Mean   :4620   Mean
> :16590  
>  3rd Qu.:4773   3rd Qu.:4796   3rd Qu.:4753   3rd Qu.:4766   3rd
> Qu.:18294  
>  Max.   :4944   Max.   :4954   Max.   :4912   Max.   :4937   Max.
> :73559  
>   openInterest      direction           volatility    
> volumeXdirection  
>  Min.   :     0   Min.   :-62.00000   Min.   : 0.00   Min.   
> :-2795242  
>  1st Qu.:184685   1st Qu.:-19.25000   1st Qu.:30.00   1st 
> Qu.: -248740  
>  Median :193233   Median : -1.50000   Median :38.50   Median 
> :  -15905  
>  Mean   :188825   Mean   :  0.01563   Mean   :41.58   Mean   
> :    6275  
>  3rd Qu.:199800   3rd Qu.: 17.00000   3rd Qu.:50.00   3rd 
> Qu.:  206325  
>  Max.   :236759   Max.   : 74.00000   Max.   :94.00   Max.   
> : 2024470  
>  volatilityXdirection     upDown          nextDay      
>  Min.   :      0      Min.   :0.0000   Min.   :0.0000  
>  1st Qu.: 362816      1st Qu.:0.0000   1st Qu.:0.0000  
>  Median : 540187      Median :0.0000   Median :0.0000  
>  Mean   : 731595      Mean   :0.4844   Mean   :0.4844  
>  3rd Qu.: 996650      3rd Qu.:1.0000   3rd Qu.:1.0000  
>  Max.   :3604391      Max.   :1.0000   Max.   :1.0000  
> >
>  
> and trying to do a glm like this:
>  
>  
> > logistic.model = glm(formula = as.factor(nextDay) ~ .,
> family=binomial, data=spi[1:50,])
> > summary(logistic.model)
>  
> Call:
> glm(formula = as.factor(nextDay) ~ ., family = binomial, data =
> spi[1:50, 
>     ])
>  
> Deviance Residuals: 
>     Min       1Q   Median       3Q      Max  
> -1.9994  -0.8575  -0.0330   0.7961   1.8376  
>  
> Coefficients: (2 not defined because of singularities)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The answer is most likely here:  You have multicollinearity.

Andy



>                        Estimate Std. Error z value Pr(>|z|)  
> (Intercept)          -3.016e+01  2.934e+01  -1.028   0.3040  
> open                 -2.514e-02  8.939e-02  -0.281   0.7785  
> high                  7.598e-02  1.295e-01   0.587   0.5575  
> low                  -1.065e-01  1.176e-01  -0.905   0.3656  
> close                 5.943e-02  7.995e-02   0.743   0.4573  
> volume                1.960e-04  1.977e-04   0.991   0.3215  
> openInterest          5.728e-05  5.266e-05   1.088   0.2767  
> direction                    NA         NA      NA       NA  
> volatility                   NA         NA      NA       NA  
> volumeXdirection      3.605e-06  3.765e-06   0.958   0.3383  
> volatilityXdirection -5.815e-06  5.708e-06  -1.019   0.3082  
> upDown               -2.561e+00  1.259e+00  -2.034   0.0419 *
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1 
>  
> (Dispersion parameter for binomial family taken to be 1)
>  
>     Null deviance: 69.235  on 49  degrees of freedom
> Residual deviance: 55.000  on 40  degrees of freedom
> AIC: 75
>  
> Number of Fisher Scoring iterations: 7
>  
> >
>  
> I am getting NA for direction and volatility.  I got it both 
> before and
> after casting them as.numeric.
>  
> Can anyone tell me what I am doing wrong?
>  
> Thanks
>  
> Stephen
> 
> -- 
> 
> 
> 
> 20/02/2006
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From p.dalgaard at biostat.ku.dk  Tue Feb 21 21:25:24 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Feb 2006 21:25:24 +0100
Subject: [R] Compute a correlation matrix from an existing covariance
	matrix
In-Reply-To: <x264n8fwf4.fsf@turmalin.kubism.ku.dk>
References: <20060221171558.89597.qmail@web25815.mail.ukl.yahoo.com>
	<x264n8fwf4.fsf@turmalin.kubism.ku.dk>
Message-ID: <x2oe10h32j.fsf@turmalin.kubism.ku.dk>

Peter Dalgaard <p.dalgaard at biostat.ku.dk> writes:

> (BTW, why doesn't the page for cor/var/cov/cov2cor show up on
> help.search("covariance") or help.search("correlation") for me??)

It's there now. Must have been a temporary condition, possibly in the
user... 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Tue Feb 21 21:28:14 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 21 Feb 2006 21:28:14 +0100
Subject: [R] How to get around heteroscedasticity with non-linear leas t
	squares in R?
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED833@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED833@usctmx1106.merck.com>
Message-ID: <x2k6boh2xt.fsf@turmalin.kubism.ku.dk>

"Liaw, Andy" <andy_liaw at merck.com> writes:

> Your understanding isn't similar to mine.  Mine says robust/resistant
> methods are for data with heavy tails, not heteroscedasticity.  The common
> ways to approach heteroscedasticity are transformation and weighting.  The
> first is easy and usually quite effective for dose-response data.  The
> second is not much harder.  Both can be done in R with nls().

And there is gnls() which allows direct modelling of the variance.

        -p
 
> Andy
> 
> From: Quin Wills
> > 
> > I am using "nls" to fit dose-response curves but am not sure 
> > how to approach
> > more robust regression in R to get around the problem of the my error
> > showing increased variance with increasing dose.  
> > 
> >  
> > 
> > My understanding is that "rlm" or "lqs" would not be a good idea here.
> > 'Fairly new to regression work, so apologies if I'm missing something
> > obvious.
> > 
> >  
> > 
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From bates at stat.wisc.edu  Tue Feb 21 22:10:23 2006
From: bates at stat.wisc.edu (Douglas Bates)
Date: Tue, 21 Feb 2006 15:10:23 -0600
Subject: [R] [OT] New book on software patents, etc.
Message-ID: <40e66e0b0602211310u419ebe76p32bdac1ba1b26c3e@mail.gmail.com>

I just saw a review of a book about software patents called "Math you
can't use" http://www.brookings.edu/press/books/mathyoucantuse.htm
which looks very interesting. The whole subject of software patents
and licenses on code is important in the R Project.



From ripley at stats.ox.ac.uk  Tue Feb 21 22:16:01 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Feb 2006 21:16:01 +0000 (GMT)
Subject: [R] How to get around heteroscedasticity with non-linear leas t
 squares in R?
In-Reply-To: <x2k6boh2xt.fsf@turmalin.kubism.ku.dk>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED833@usctmx1106.merck.com>
	<x2k6boh2xt.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.LNX.4.64.0602212114580.26743@gannet.stats.ox.ac.uk>

On Tue, 21 Feb 2006, Peter Dalgaard wrote:

> "Liaw, Andy" <andy_liaw at merck.com> writes:
>
>> Your understanding isn't similar to mine.  Mine says robust/resistant
>> methods are for data with heavy tails, not heteroscedasticity.  The common
>> ways to approach heteroscedasticity are transformation and weighting.  The
>> first is easy and usually quite effective for dose-response data.  The
>> second is not much harder.  Both can be done in R with nls().
>
> And there is gnls() which allows direct modelling of the variance.

in package nlme, BTW.

R-devel allows weights in nls, which makes it easier for those most 
familiar with that function.

>
>        -p
>
>> Andy
>>
>> From: Quin Wills
>>>
>>> I am using "nls" to fit dose-response curves but am not sure
>>> how to approach
>>> more robust regression in R to get around the problem of the my error
>>> showing increased variance with increasing dose.
>>>
>>>
>>>
>>> My understanding is that "rlm" or "lqs" would not be a good idea here.
>>> 'Fairly new to regression work, so apologies if I'm missing something
>>> obvious.
>>>
>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>>
>>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From marcodoc75 at yahoo.com  Tue Feb 21 22:28:20 2006
From: marcodoc75 at yahoo.com (Marco Geraci)
Date: Tue, 21 Feb 2006 13:28:20 -0800 (PST)
Subject: [R] I need your help
In-Reply-To: <OFDBDB1F8A.0DD8DFC9-ONC125711C.0063F275@aviation-civile.gouv.fr>
Message-ID: <20060221212820.1813.qmail@web31302.mail.mud.yahoo.com>

Hello,
I made some adjustments to your code.

1) You used 't' twice in your code. When you assign t
<- 1.645, the length m of 't' becomes 1 (that's why
your matrix was 3 x 1)

2) I assumed that the 'critical value' t is the
quantile of a Normal (0,1). By using 't <-
qnorm(0.5*level + 0.5)' allows you to consider any
value between 0 and 1 for level. Otherwise, you must
write a 'neverending' list  of 'if else'. If I assumed
wrong, put back in the code the 'if else' statement.

3) The 'kronecker' function avoids the loops for 'i'
and 'j'

I hope this is what you want.

Marco Geraci


######################

taille <- function (delta, level, prob = 0.2) {

t <- qnorm(0.5*level + 0.5)

n <- length(delta)
m <- length(level)

result <-
prob*(1-prob)*matrix(kronecker(t^2,delta^2,FUN="/"),
n, m, byrow=T)

rownames(result) <- delta
colnames(result) <- level
round(result,2)

}

taille (delta = c(0.01, 0.02, 0.03), level = c(0.90,
0.95, 0.99))

#############################



--- KOITA Lassana - STAC/ACE
<lassana.koita at aviation-civile.gouv.fr> wrote:

> 
> 
> 
> 
> Hi,
> Dear R users
> I have problem with the following code. The matrix
> result must be a matrix
> (3x3). But I have obtained a matrix(3x1) and I don't
> know why.
> So, I need your help
> 
> Best regards
> 
>
#####################################################################
> 
> taille <- function (delta, t, prob = 0.2)
> 
> {
> 
> niv.conf <- c(0.90, 0.95, 0.99)
> if(niv.conf <- 0.90) {
>    t <- 1.645
> }
> 
>  else {
> 
>  if(niv.conf <- 0.95) {
>    t <- 1.96
> }
> 
> t <- 2.575
> }
> 
> n <- length(delta)
> 
> m <- length(t)
> 
> result <- matrix(nrow = n, ncol = m);
> 
> for (i in 1:n)
>    {
>      for(j in 1:m)
> 
>       {
> 
>        result[i,j]<-
> prob*(1-prob)*((t[i])^2)/(delta[j])^2 ;
> 
>       }
>    }
> 
> rownames(result) <- delta
> colnames(result) <- niv.conf
> round(result,2)
> 
> }
> 
> taille (delta <- c( 0.01, 0.02, 0.03), niv.conf <- 
> c(0.90, 0.95, 0.99))
> 
>
####################################################################"
> 
> 
> 
> Lassana KOITA
> Etudes de S??curit?? et d'Exploitation a??roportuaires
> / Aerodrome Safety &
> Statistical analysis
> Service Technique de l'Aviation Civile (STAC) /
> Civil Aviation Technical
> Department
> Direction G??n??rale de l'Aviation Civile (DGAC) /
> French Civil Aviation
> Authority
> Tel: 01 49 56 80 60
> Fax: 01 49 56 82 14
> E-mail: Lassana.Koita at aviation-civile.gouv.fr
> http://www.stac.aviation-civile.gouv.fr/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From marcodoc75 at yahoo.com  Tue Feb 21 22:47:14 2006
From: marcodoc75 at yahoo.com (Marco Geraci)
Date: Tue, 21 Feb 2006 13:47:14 -0800 (PST)
Subject: [R] How to select only certain rows when making a new dataframe?
In-Reply-To: <e40d78ce0602210953x7668a272r3e50c8d4ec0c3240@mail.gmail.com>
Message-ID: <20060221214714.35887.qmail@web31301.mail.mud.yahoo.com>

I think ?merge is what you need. The help page of this
function is very....helpful

Marco

--- mtb954 at gmail.com wrote:

> Dear R-users,
> 
> I have two data frames. The "FIRST" data frame has
> 100 rows, the
> "SECOND" data frame has only 50 rows.
> 
> The data frames have different variables in columns
> ("VAR1," "VAR2,"
> etc) but they share a column called "ID" that
> contains a unique
> identifer linking the two data frames.
> 
> I would like to make a "THIRD" data frame containing
> just the rows of
> the "FIRST" data frame that match the rows (on "ID")
> in the "SECOND"
> data frame.
> 
> >THIRD=data.frame(FIRST$ID,FIRST$VAR1,FIRST$VAR2)
> 
> How can I modify this line to include in "THIRD"
> just the rows in
> "FIRST" that match the rows in "SECOND"? (i.e.,
> contain the same value
> in the shared "ID" column).
> 
> Thanks! Mark
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From kjetilbrinchmannhalvorsen at gmail.com  Tue Feb 21 23:31:10 2006
From: kjetilbrinchmannhalvorsen at gmail.com (Kjetil Brinchmann Halvorsen)
Date: Tue, 21 Feb 2006 18:31:10 -0400
Subject: [R] How to get around heteroscedasticity with non-linear least
 squares in R?
In-Reply-To: <001601c63713$73e59590$b86b01a3@notebookquin>
References: <001601c63713$73e59590$b86b01a3@notebookquin>
Message-ID: <43FB94AE.503@gmail.com>

Quin Wills wrote:
> I am using "nls" to fit dose-response curves but am not sure how to approach
> more robust regression in R to get around the problem of the my error
> showing increased variance with increasing dose.  
> 

package "sfsmisc"  has rnls (robust nls)
which might be of use.

Kjetil

>  
> 
> My understanding is that "rlm" or "lqs" would not be a good idea here.
> 'Fairly new to regression work, so apologies if I'm missing something
> obvious.
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From goujat at gmail.com  Tue Feb 21 23:35:38 2006
From: goujat at gmail.com (Lavrentiy)
Date: Wed, 22 Feb 2006 01:35:38 +0300
Subject: [R] Composing a matrix for 'heatmap' from original dataset and
 genetic data analysis.
Message-ID: <43FB95B9.1050909@gmail.com>

Hello.

I have following data:
doze	g1	g2	g3	g4	etc...
1200	a	d
1100	b	e
1158	c	f
1500	a	e
1403	c	f
...
etc.

Doze - numeric, levels(g1)=c('a','b','c'), levels(g2)=c('d','e','f').

This is the data of genetic analysis, where the factors are genes and 
the numerical is some numerical value.

I want to build up a function, which will do a preliminary data 
visualization based on factor levels combination and mean doze for that 
combination.

The best way to do it, as I think, is to build a tree which divides at 
the "stage 1" into the levels of factor 1, then on the "stage 2" into 
the levels of factor two etc. And in the end it will be mean doze for 
this branch. What I found was only 'ctree', this can only bifurcate, I'm 
not sure it fits much. What's the convenient way to visualize such kind 
of data in R?

I think 'heatmap' for any two factors I give to it with text mean labels 
(how to add them?) would be nice solution. So that's the way I wrote 
(ughly):

zar <- function(g1,g2,param='doz') {

levels(g1)->lg1
levels(g2)->lg2
table(lg1,lg2)->f
#to make a matrix for 'heatmap', is it necessary?
#data labels are not preserved in this expression, badly!

for (i in lg1) {
	for (j in lg2) {
	 
f[i,j]<-mean(subset(mydata,as.factor(g1)==i&as.factor(g2)==j)[[param]], 
na.rm=T)
			}
		}
heatmap(-f, Rowv=NA, Colv=NA, margins=c(10,10),main=param)
}

Please, make a hint to me for how to do this task easier and more 
convenient,
how to add text labels to 'heatmap'
and is this way right?

-- 
Evgeniy



From yen.lin.chia at intel.com  Wed Feb 22 00:14:30 2006
From: yen.lin.chia at intel.com (Chia, Yen Lin)
Date: Tue, 21 Feb 2006 15:14:30 -0800
Subject: [R] Limit of matrix + naming
Message-ID: <E305A4AFB7947540BC487567B5449BA8098FD339@scsmsx402.amr.corp.intel.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060221/3f569dda/attachment.pl

From A.Robinson at ms.unimelb.edu.au  Wed Feb 22 00:14:41 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Wed, 22 Feb 2006 10:14:41 +1100
Subject: [R]  Selecting amongst large classes of models (Was: Nested AIC)
In-Reply-To: <Pine.LNX.4.64.0602211706500.11480@gannet.stats.ox.ac.uk>
References: <03DCBBA079F2324786E8715BE538968AA5AD64@FIGMAIL-CLUS01.FIG.FK>
	<Pine.LNX.4.64.0602210809450.1702@homer24.u.washington.edu>
	<Pine.LNX.4.64.0602211706500.11480@gannet.stats.ox.ac.uk>
Message-ID: <20060221231441.GH39857@ms.unimelb.edu.au>

Professor Ripley,

On Tue, Feb 21, 2006 at 05:36:15PM +0000, Prof Brian Ripley wrote:
>
> A recent talk of mine
> 
>  	http://www.stats.ox.ac.uk/~ripley/Nelder80.pdf
> 
> may be illuminating.  There is a published paper version.
> 

Would you mind providing a citation for that published paper version?
I do not find details on your website, and Current Contents does not
provide any clues.

Cheers,

Andrew
-- 
Andrew Robinson  
Department of Mathematics and Statistics            Tel: +61-3-8344-9763
University of Melbourne, VIC 3010 Australia         Fax: +61-3-8344-4599
Email: a.robinson at ms.unimelb.edu.au         http://www.ms.unimelb.edu.au



From brian_cade at usgs.gov  Wed Feb 22 00:34:34 2006
From: brian_cade at usgs.gov (Brian S Cade)
Date: Tue, 21 Feb 2006 16:34:34 -0700
Subject: [R] How to get around heteroscedasticity with non-linear least
 squares in R?
In-Reply-To: <43FB94AE.503@gmail.com>
Message-ID: <OF6779F84B.DA065D84-ON8725711C.0080E4C4-8725711C.0081B852@usgs.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060221/551e332a/attachment.pl

From srini_iyyer_bio at yahoo.com  Wed Feb 22 02:24:52 2006
From: srini_iyyer_bio at yahoo.com (Srinivas Iyyer)
Date: Tue, 21 Feb 2006 17:24:52 -0800 (PST)
Subject: [R] R[1304] general protection rip - Error running R file in Batch
	mode
In-Reply-To: <E305A4AFB7947540BC487567B5449BA8098FD339@scsmsx402.amr.corp.intel.com>
Message-ID: <20060222012452.2894.qmail@web34504.mail.mud.yahoo.com>

hi group, 
 I have a list of 100 elements (genes), that are to be
queried in postgres.  The out of the file is processed
for fisher test and written back as a file with
pvalues.
For one such operation there are 54 lines of code. 

I replicated the same code changing the query element
and file name to write back. 

I created a jumbo 100*54 = 5400 lines of code by
replication. 

I saved this file as .R and ran it as:
R CMD BATCH myfile.R..

The program ran for ~40 mins. ( each operation takes 5
mins). after going home, I checked the stats and saw
that the program got aborted leaving 8 output files in
directory. 

I checked /var/log/messages and found :

localhost kernel: R[1304] general protection
rip:2a988c919e rsp:7fbfff87f0 error:0


postgres did not log any error message. 

This is my first time I am running my R code in BATCH
mode. I am a new to programming in R and I have been
working directly with R interface. 

Could any one guess what could have been the problem. 

Thanks
Sri



From andy_liaw at merck.com  Wed Feb 22 02:32:32 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 21 Feb 2006 20:32:32 -0500
Subject: [R] Limit of matrix + naming
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED83A@usctmx1106.merck.com>

Looking at length(list(2:305)) and str(list(2:305)) can be instructive.  You
don't need the list(), and you probably want to use `legal' names for
variables.

Andy

From: Chia, Yen Lin
> 
> Hi all,
> 
>  
> 
> I have read a data matrix of 304 x 404 using read.table.  When I am
> trying to name the colnames, with first try colnames(L5)<-list(2:305),
> 
> I keep getting error message such as 
> 
>  
> 
> Error in "colnames<-"(`*tmp*`, value = list(c(2, 3, 4, 5, 6, 
> 7, 8, 9,  :
> 
> 
>         length of 'dimnames' [2] not equal to array extent
> 
>  
> 
> and I don't know why.  But, if I look at the original names 
> in terms of
> V1, V2, the rownames are repeated again after V256.  Is there a
> limitation?  
> 
>  
> 
> Thanks.
> 
>  
> 
> Yen Lin
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From srini_iyyer_bio at yahoo.com  Wed Feb 22 02:49:57 2006
From: srini_iyyer_bio at yahoo.com (Srinivas Iyyer)
Date: Tue, 21 Feb 2006 17:49:57 -0800 (PST)
Subject: [R] R[1304] general protection rip - Error running R file in
	Batch mode
In-Reply-To: <20060222012452.2894.qmail@web34504.mail.mud.yahoo.com>
Message-ID: <20060222014957.99595.qmail@web34505.mail.mud.yahoo.com>

Hi group, 
I ran the file again and after 10 min. of run, the
process got interrupted.  

Here is the output of the file

$bash: R CMD BATCH grand.R > grand.log


 R CMD BATCH grand.R


/usr/local/lib64/R/bin/BATCH: line 55:  1758 Broken
pipe             ( echo "invisible(options(echo =
TRUE))"; cat ${in}; echo ''; echo "proc.time()" )
      1760 Segmentation fault      | ${R_HOME}/bin/R
${opts} >${out} 2>&1


Is this because of the excess query code in one .R
file?

Any suggestions, will help me .

thanks
Sri



> 
> I created a jumbo 100*54 = 5400 lines of code by
> replication. 
> 
> I saved this file as .R and ran it as:
> R CMD BATCH myfile.R..
> 
> The program ran for ~40 mins. ( each operation takes
> 5
> mins). after going home, I checked the stats and saw
> that the program got aborted leaving 8 output files
> in
> directory. 
> 
> I checked /var/log/messages and found :
> 
> localhost kernel: R[1304] general protection
> rip:2a988c919e rsp:7fbfff87f0 error:0
> 
> 
> postgres did not log any error message. 
> 
> This is my first time I am running my R code in
> BATCH
> mode. I am a new to programming in R and I have been
> working directly with R interface. 
> 
> Could any one guess what could have been the
> problem. 
> 
> Thanks
> Sri
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From David.Duffy at qimr.edu.au  Wed Feb 22 03:41:57 2006
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 22 Feb 2006 12:41:57 +1000 (EST)
Subject: [R] var-covar matrices comparison
In-Reply-To: <mailman.11.1140519602.6083.r-help@stat.math.ethz.ch>
References: <mailman.11.1140519602.6083.r-help@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0602221204520.14076@orpheus.qimr.edu.au>

> Date: Mon, 20 Feb 2006 16:43:55 -0600
> From: Aldi Kraja <aldi at wustl.edu>
>
> Hi,
> Using package gclus in R, I have created some graphs that show the
> trends within subgroups of data and correlations among 9 variables (v1-v9).
> Being interested for more details on these data I have produced also the
> var-covar matrices.
> Question: From a pair of two subsets of data (with 9 variables each, I
> have two var-covar matrices for each subgroup, that differ for a
> treatment on one group (treatment A) vs (non-Treatment A).
>
> Is there a software that can compare if two var-covar matrices are
> statistically the same?
>

This can be done in various structural equation modelling packages.  I don't
think it can be done automatically using the sem package, as that does not allow
multiple groups.  You can roll your own LR test (assuming MVN):

  f <- (N-1) * (log(det(E)) - log(det(O)) + sum(diag((O %*% solve(E))))-p)

  N=size of group
  p=number of variables
  E=expected covariance matrix
  O=observed covariance matrix

  where in your example, E will be the observed covariance matrix for
  the pooled groups.  There are GLS etc alternatives - see eg Bollen's book on
  SEM.

| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From dmaneesh at hotmail.com  Wed Feb 22 03:44:47 2006
From: dmaneesh at hotmail.com (maneesh deshpande)
Date: Tue, 21 Feb 2006 21:44:47 -0500
Subject: [R]  Ranking within factor subgroups
In-Reply-To: <43FA685B.4060701@ozemail.com.au>
Message-ID: <BAY107-F292721D1A3592D1E748CC5D2FD0@phx.gbl>


Hi,

I have a dataframe, x of the following form:

Date            Symbol   A    B  C
20041201     ABC      10  12 15
20041201     DEF       9    5   4
...
20050101     ABC         5  3   1
20050101     GHM       12 4    2
....

here A, B,C are properties of a set symbols recorded for a given date.
I wante to decile the symbols For each date and property and
create another set of columns "bucketA","bucketB", "bucketC" containing the 
decile rank
for each symbol. The following non-vectorized code does what I want,

bucket <- function(data,nBuckets) {
     q <- quantile(data,seq(0,1,len=nBuckets+1),na.rm=T)
     q[1] <- q[1] - 0.1 # need to do this to ensure there are no extra NAs
     cut(data,q,include.lowest=T,labels=F)
}

calcDeciles <- function(x,colNames) {
nBuckets <- 10
dates <- unique(x$Date)
for ( date in dates) {
  iVec <- x$Date == date
  xx <- x[iVec,]
  for (colName in colNames) {
     data <- xx[,colName]
     bColName <- paste("bucket",colName,sep="")
     x[iVec,bColName] <- bucket(data,nBuckets)
  }
}
x
}

x <- calcDeciles(x,c("A","B","C"))


I was wondering if it is possible to vectorize the above function to make it 
more efficient.
I tried,
rlist <- tapply(x$A,x$Date,bucket)
but I am not sure how to assign the contents of "rlist" to their appropriate 
slots in the original
dataframe.

Thanks,

Maneesh



From murdoch at stats.uwo.ca  Wed Feb 22 04:05:44 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 21 Feb 2006 22:05:44 -0500
Subject: [R] R[1304] general protection rip - Error running R file in
 Batch	mode
In-Reply-To: <20060222012452.2894.qmail@web34504.mail.mud.yahoo.com>
References: <20060222012452.2894.qmail@web34504.mail.mud.yahoo.com>
Message-ID: <43FBD508.30407@stats.uwo.ca>

On 2/21/2006 8:24 PM, Srinivas Iyyer wrote:
> hi group, 
>  I have a list of 100 elements (genes), that are to be
> queried in postgres.  The out of the file is processed
> for fisher test and written back as a file with
> pvalues.
> For one such operation there are 54 lines of code. 
> 
> I replicated the same code changing the query element
> and file name to write back. 
> 
> I created a jumbo 100*54 = 5400 lines of code by
> replication. 

That's a fairly strange way to write such a thing.  Why not write a 
single function, and run it in a loop?

> 
> I saved this file as .R and ran it as:
> R CMD BATCH myfile.R..
> 
> The program ran for ~40 mins. ( each operation takes 5
> mins). after going home, I checked the stats and saw
> that the program got aborted leaving 8 output files in
> directory. 
> 
> I checked /var/log/messages and found :
> 
> localhost kernel: R[1304] general protection
> rip:2a988c919e rsp:7fbfff87f0 error:0
> 
> 
> postgres did not log any error message. 
> 
> This is my first time I am running my R code in BATCH
> mode. I am a new to programming in R and I have been
> working directly with R interface. 
> 
> Could any one guess what could have been the problem. 

You haven't really given us much to go on.  You haven't stated the 
version, or what packages and functions you are using.

I'd guess this is a bug with one of the packages you're using, but it
could be a bug in R.  Can you determine which line causes the error? 
Does it happen if you extract just that line, and enough previous ones 
to set things up for it?

Duncan Murdoch



From quin.wills at googlemail.com  Wed Feb 22 04:19:06 2006
From: quin.wills at googlemail.com (Quin Wills)
Date: Wed, 22 Feb 2006 03:19:06 -0000
Subject: [R] How to get around heteroscedasticity with non-linear leas t
	squares in R?
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED839@usctmx1106.merck.com>
Message-ID: <000701c6375e$be5cbcc0$14ae01a3@notebookquin>

Thank you all, this has been a great help (including the methodological
advice). Very interesting - I'll be sure to read the lecture.

Quin

-----Original Message-----
From: Liaw, Andy [mailto:andy_liaw at merck.com] 
Sent: 22 February 2006 01:18
To: 'Brian S Cade'; KjetilBrinchmannHalvorsen at gmail.com
Cc: Quin Wills; r-help at stat.math.ethz.ch; r-help-bounces at stat.math.ethz.ch
Subject: RE: [R] How to get around heteroscedasticity with non-linear leas t
squares in R?

From: Brian S Cade
> 
> Instead of thinking that the heteroscedasticity is a nuisance and 
> something to "get around", i.e, just wanting weighted 
> estimates of the 
> mean function, you might want to think about what 
> heteroscedasticity is 
> telling you and estimate some other quantities.  

Indeed!  See Prof. Carroll's 2002 Fisher Lecture:
http://www.stat.tamu.edu/ftp/pub/rjcarroll/2003.papers.directory/published_F
isher_Lecture.pdf
(There's Powerpoint file on his web page, too.)

Andy

> Heteroscedasticity is 
> telling you that the conditional distributions don't change 
> at a constant 
> rate across all portions of the distribution (think 
> percentiles or more 
> generally quantiles) and, therefore, a function for the mean 
> (no matter 
> how precisely estimated) cannot tell you all there is to know 
> about your 
> dose-response relation.  Why not go after estimating the conditional 
> quantile functions directly with nonlinear quantile 
> regression, function 
> nlrq() in the quantreg package? 
> 
> Brian
> 
> Brian S. Cade
> 
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
> 
> email:  brian_cade at usgs.gov
> tel:  970 226-9326
> 
> 
> 
> Kjetil Brinchmann Halvorsen <kjetilbrinchmannhalvorsen at gmail.com> 
> Sent by: r-help-bounces at stat.math.ethz.ch
> 02/21/2006 03:31 PM
> Please respond to
> KjetilBrinchmannHalvorsen at gmail.com
> 
> 
> To
> Quin Wills <quin.wills at googlemail.com>
> cc
> r-help at stat.math.ethz.ch
> Subject
> Re: [R] How to get around heteroscedasticity with non-linear 
> least squares 
> in R?
> 
> 
> 
> 
> 
> 
> Quin Wills wrote:
> > I am using "nls" to fit dose-response curves but am not sure how to 
> approach
> > more robust regression in R to get around the problem of 
> the my error
> > showing increased variance with increasing dose. 
> > 
> 
> package "sfsmisc"  has rnls (robust nls)
> which might be of use.
> 
> Kjetil
> 
> > 
> > 
> > My understanding is that "rlm" or "lqs" would not be a good 
> idea here.
> > 'Fairly new to regression work, so apologies if I'm missing 
> something
> > obvious.
> > 
> > 
> > 
> > 
> >                [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


----------------------------------------------------------------------------
--
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From spencer.graves at pdf.com  Wed Feb 22 04:24:43 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 21 Feb 2006 19:24:43 -0800
Subject: [R] panel-VAR
In-Reply-To: <1139691057.43ee4e313fa68@webmail.purdue.edu>
References: <1139691057.43ee4e313fa68@webmail.purdue.edu>
Message-ID: <43FBD97B.6010109@pdf.com>

	  Have you looked at the nlme package?  If you provide more detail 
about your application (as suggested in the posting guide! 
"www.R-project.org/posting-guide.html"), you might receive more useful 
replies more quickly.

	  hope this helps,
	  spencer graves

tang5 at purdue.edu wrote:

> 
> Hi,
> Anybody knows if there is a package for panel VAR ?
> thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Wed Feb 22 04:44:39 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 21 Feb 2006 19:44:39 -0800
Subject: [R] OT Futility Analysis
In-Reply-To: <43F67C05.5040909@utoronto.ca>
References: <43F67C05.5040909@utoronto.ca>
Message-ID: <43FBDE27.7040209@pdf.com>

	  What does this particular Steering Committee think a "futility 
analysis" is?  Do they have any particular reference(s)?  What do you 
find in your own literature review?

	  If it were my problem, I think I'd start with questions like that. 
Your comments suggested to me a confounding of technical and political 
problems.  The politics suggests the language you need to use in your 
response.  Beyond that, I've never heard before of a "futility 
analysis", but I think I could do one by just trying to be clear about 
the options the Steering Committee might consider plausible and then 
comparing them with appropriate simulations -- summarized as confidence 
intervals, as you suggest.

	  And I hope that someone else will enlighten us both if there are 
better options available.

	  Best Wishes,
	  spencer graves
p.s.  For any attorneys who may read these comments, the suggestions are 
obviously warranteed up to the amount you paid for it, which is nothing. 
  If you follow them and they turn out to be inappropriate, you will pay 
the price.  I encourage you to share the problems with me, so I can 
learn from the experience.  However, the limits of my liability are as 
already stated.

Kevin E. Thorpe wrote:

> I beg your pardon if this is too off topic.  I am posting here
> since I hope to find an R solution to my problem.  Please indulge
> me while I give a little background about what I'm trying to do.
> 
> I'm on a DSMB for a clinical trial.  The Steering Committee for the
> trial has asked us to perform a futility analysis on their primary
> outcome which is a time-to-event endpoint.  The trial was not designed
> with group sequential methods, nor was any futility analysis spelled
> out in the protocol.  Another thing which may be relevant is that
> due to circumstances beyond the investigators' control, the trial
> will stop recruitment prematurely unless there is some compelling
> reason for them to find a way to continue the trial.  Lastly, the
> trial has accrued not quite half of the planned sample size.
> 
> Admittedly, I don't have a vast amount of experience implementing
> stopping rules.  In other protocols I have seen where futility
> analyses have been planned but a group sequential design has not
> otherwise been employed, conditional power has been used for the
> futility rule.  So naturally, that was my first thought (although
> I may well be wrong) in this case.  I have done RSiteSearch() with
> the following terms (three different searches):
> 
> 	futility analysis
> 	conditional power
> 	stochastic curtailment
> 
> Nothing that looked relevant to my problem jumped out at me.
> 
> I have read, somewhat recently, that there are problems with conditional
> power, although I don't remember the details at the moment.  This
> has prompted me to consider other approaches to the problem.
> 
> One simple thing that has occurred to me, although I don't know
> what the implications are is to simply look at a confidence
> interval around the hazard ratio for the treatment effect.  In
> the event that the CI includes 1 and excludes any clinically
> important difference, I would take that as an indication of
> futility.
> 
> I would appreciate your comments on this and to learn of any more
> formal methods, particularly of implementations in R.
> 
> Thank you for reading.
> 
> Kevin
>



From ramasamy at cancer.org.uk  Wed Feb 22 04:44:45 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 22 Feb 2006 03:44:45 +0000
Subject: [R] Ranking within factor subgroups
In-Reply-To: <BAY107-F292721D1A3592D1E748CC5D2FD0@phx.gbl>
References: <BAY107-F292721D1A3592D1E748CC5D2FD0@phx.gbl>
Message-ID: <1140579886.3452.3.camel@dhcp-82.wolf.ox.ac.uk>

It might help to give a simple reproducible example in the future. For
example

 df <- cbind.data.frame( date=rep( 1:5, each=100 ), A=rpois(500, 100),
                         B=rpois(500, 50), C=rpois(500, 30) )

might generate something like

	    date   A  B  C
	  1    1  93 51 32
	  2    1  95 51 30
	  3    1 102 59 28
	  4    1 105 52 32
	  5    1 105 53 26
	  6    1  99 59 37
	...    . ... .. ..
	495    5 100 57 19
	496    5  96 47 44
	497    5 111 56 35
	498    5 105 49 23
	499    5 105 61 30
	500    5  92 53 32

Here is my proposed solution. Can you double check with your existing
functions to see if they are correct.

   decile.fn <- function(x, nbreaks=10){
     br     <- quantile( x, seq(0, 1, len=nbreaks+1), na.rm=T )
     br[1]  <- -Inf
     return( cut(x, br, labels=F) )
   }

   out <- apply( df[ ,c("A", "B", "C")], 2,
                 function(v) unlist( tapply( v, df$date, decile.fn ) ) )

   rownames(out) <- rownames(df)
   out <- cbind(df$date, out)

Regards, Adai



On Tue, 2006-02-21 at 21:44 -0500, maneesh deshpande wrote:
> Hi,
> 
> I have a dataframe, x of the following form:
> 
> Date            Symbol   A    B  C
> 20041201     ABC      10  12 15
> 20041201     DEF       9    5   4
> ...
> 20050101     ABC         5  3   1
> 20050101     GHM       12 4    2
> ....
> 
> here A, B,C are properties of a set symbols recorded for a given date.
> I wante to decile the symbols For each date and property and
> create another set of columns "bucketA","bucketB", "bucketC" containing the 
> decile rank
> for each symbol. The following non-vectorized code does what I want,
> 
> bucket <- function(data,nBuckets) {
>      q <- quantile(data,seq(0,1,len=nBuckets+1),na.rm=T)
>      q[1] <- q[1] - 0.1 # need to do this to ensure there are no extra NAs
>      cut(data,q,include.lowest=T,labels=F)
> }
> 
> calcDeciles <- function(x,colNames) {
> nBuckets <- 10
> dates <- unique(x$Date)
> for ( date in dates) {
>   iVec <- x$Date == date
>   xx <- x[iVec,]
>   for (colName in colNames) {
>      data <- xx[,colName]
>      bColName <- paste("bucket",colName,sep="")
>      x[iVec,bColName] <- bucket(data,nBuckets)
>   }
> }
> x
> }
> 
> x <- calcDeciles(x,c("A","B","C"))
> 
> 
> I was wondering if it is possible to vectorize the above function to make it 
> more efficient.
> I tried,
> rlist <- tapply(x$A,x$Date,bucket)
> but I am not sure how to assign the contents of "rlist" to their appropriate 
> slots in the original
> dataframe.
> 
> Thanks,
> 
> Maneesh
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From DrJones at alum.MIT.edu  Wed Feb 22 06:31:13 2006
From: DrJones at alum.MIT.edu (Thomas L Jones)
Date: Wed, 22 Feb 2006 00:31:13 -0500
Subject: [R] How do I tell it which directory to use?
Message-ID: <000301c63771$32b654c0$2f01a8c0@DrJones>

>From Tom:

In R 2.2.0 under Windows, I want to be able to give it a filename such 
as "myFile.txt" without the quotes. But actually I mean:

C:\Documents and Settings\Tom\My Documents\qpaper7\R Project Started 
19 Dec 05\myFile.txt

If I were to repeat this each time, my computer would get all bored 
and cranky and start to drop bits (only a joke, of course). I think I 
want to set the Home directory or the working directory or some 
directory or other to the above directory. I may or may not want to 
set some environmental variables.

R 2.2.0; working directly from the console and copying and pasting 
code which I want to test into the console. Windows XP Home Edition. 
Administrator privileges are enabled. A curve ball: There are two 
accounts, "Tom" and "Jones;" the data are stored under "Tom," whereas 
the computation is being done under the "Jones" account. I won't bore 
you with the details of why I am doing this.

I was able to call Sys.getenv ("R_USER") and get the home directory.

I am a newbie to R and not familiar with the terminology.

Tom
Thomas L. Jones, Ph.D., Computer Science



From matgopa1 at umbc.edu  Wed Feb 22 06:46:21 2006
From: matgopa1 at umbc.edu (matgopa1@umbc.edu)
Date: Wed, 22 Feb 2006 00:46:21 -0500 (EST)
Subject: [R] stripchart-y axis labels
Message-ID: <3178.70.22.95.132.1140587181.squirrel@70.22.95.132>

Hello,

I am trying to create a stripchart for my data, where y axis labels are
characters (ie,names of cities).  I would like to change the orientation
of the y - axis labels, ie perpendicular to y axis.
Below is the code i am using:

par(srt=90)
with(ozone.ne.trim,
	stripchart(Median~City,main = "stripchart(ozone)"))

The par option doesn't seem to working.

Kindly help.

Thanks
mathangi.



From blomsp at ozemail.com.au  Wed Feb 22 06:52:22 2006
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Wed, 22 Feb 2006 16:52:22 +1100
Subject: [R] How do I tell it which directory to use?
In-Reply-To: <000301c63771$32b654c0$2f01a8c0@DrJones>
References: <000301c63771$32b654c0$2f01a8c0@DrJones>
Message-ID: <43FBFC16.2010508@ozemail.com.au>

I think you want getwd() and setwd().

HTH,

Simon.

Thomas L Jones wrote:
> >From Tom:
>
> In R 2.2.0 under Windows, I want to be able to give it a filename such 
> as "myFile.txt" without the quotes. But actually I mean:
>
> C:\Documents and Settings\Tom\My Documents\qpaper7\R Project Started 
> 19 Dec 05\myFile.txt
>
> If I were to repeat this each time, my computer would get all bored 
> and cranky and start to drop bits (only a joke, of course). I think I 
> want to set the Home directory or the working directory or some 
> directory or other to the above directory. I may or may not want to 
> set some environmental variables.
>
> R 2.2.0; working directly from the console and copying and pasting 
> code which I want to test into the console. Windows XP Home Edition. 
> Administrator privileges are enabled. A curve ball: There are two 
> accounts, "Tom" and "Jones;" the data are stored under "Tom," whereas 
> the computation is being done under the "Jones" account. I won't bore 
> you with the details of why I am doing this.
>
> I was able to call Sys.getenv ("R_USER") and get the home directory.
>
> I am a newbie to R and not familiar with the terminology.
>
> Tom
> Thomas L. Jones, Ph.D., Computer Science
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>   


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Centre for Resource and Environmental Studies
The Australian National University
Canberra ACT 0200
Australia
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C



From Augusto.Sanabria at ga.gov.au  Wed Feb 22 06:54:39 2006
From: Augusto.Sanabria at ga.gov.au (Augusto.Sanabria@ga.gov.au)
Date: Wed, 22 Feb 2006 16:54:39 +1100
Subject: [R] How do I tell it which directory to use?
Message-ID: <9707EBA615A57747A0668CECD4638A30016802A9@mail.agso.gov.au>


Tom,

You can define your working directory by using:

setwd("C:\Documents and Settings\Tom\My Documents\qpaper7\R Project Started 
19 Dec 05")

check that your file is there:
list.files()

and then use:

source("myFile.txt") 

the machine should load "myFile"

You can go to another directory:
setwd("anotherdir")

and repeat the procedure.

Or even better if you define a number of directories in an external file:

dir1 <- c(C:\Documents and Settings\Tom\My Documents\qpaper7\")
dir2 <- c(C:\Documents and Settings\Tom\My Documents\")

and after loading the file at the beginning of the sesion you can use:

setwd("dir1")  etc.

Is it of any help to you?

Cheers,

Augusto


--------------------------------------------
Augusto Sanabria. MSc, PhD.
Mathematical Modeller
Risk Research Group
Geospatial & Earth Monitoring Division
Geoscience Australia (www.ga.gov.au)
Cnr. Jerrabomberra Av. & Hindmarsh Dr.
Symonston ACT 2609
Ph. (02) 6249-9155
 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Thomas L Jones
Sent: Wednesday, 22 February 2006 4:31 PM
To: R-project help
Subject: [R] How do I tell it which directory to use?


>From Tom:

In R 2.2.0 under Windows, I want to be able to give it a filename such 
as "myFile.txt" without the quotes. But actually I mean:

C:\Documents and Settings\Tom\My Documents\qpaper7\R Project Started 
19 Dec 05\myFile.txt

If I were to repeat this each time, my computer would get all bored 
and cranky and start to drop bits (only a joke, of course). I think I 
want to set the Home directory or the working directory or some 
directory or other to the above directory. I may or may not want to 
set some environmental variables.

R 2.2.0; working directly from the console and copying and pasting 
code which I want to test into the console. Windows XP Home Edition. 
Administrator privileges are enabled. A curve ball: There are two 
accounts, "Tom" and "Jones;" the data are stored under "Tom," whereas 
the computation is being done under the "Jones" account. I won't bore 
you with the details of why I am doing this.

I was able to call Sys.getenv ("R_USER") and get the home directory.

I am a newbie to R and not familiar with the terminology.

Tom
Thomas L. Jones, Ph.D., Computer Science

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From blomsp at ozemail.com.au  Wed Feb 22 06:57:39 2006
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Wed, 22 Feb 2006 16:57:39 +1100
Subject: [R] stripchart-y axis labels
In-Reply-To: <3178.70.22.95.132.1140587181.squirrel@70.22.95.132>
References: <3178.70.22.95.132.1140587181.squirrel@70.22.95.132>
Message-ID: <43FBFD53.4060101@ozemail.com.au>

Try  par(las=2)

Cheers,

Simon.

matgopa1 at umbc.edu wrote:
> Hello,
>
> I am trying to create a stripchart for my data, where y axis labels are
> characters (ie,names of cities).  I would like to change the orientation
> of the y - axis labels, ie perpendicular to y axis.
> Below is the code i am using:
>
> par(srt=90)
> with(ozone.ne.trim,
> 	stripchart(Median~City,main = "stripchart(ozone)"))
>
> The par option doesn't seem to working.
>
> Kindly help.
>
> Thanks
> mathangi.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>   


-- 
Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Centre for Resource and Environmental Studies
The Australian National University
Canberra ACT 0200
Australia
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C



From Augusto.Sanabria at ga.gov.au  Wed Feb 22 07:13:17 2006
From: Augusto.Sanabria at ga.gov.au (Augusto.Sanabria@ga.gov.au)
Date: Wed, 22 Feb 2006 17:13:17 +1100
Subject: [R] Gram-Charlier series
Message-ID: <9707EBA615A57747A0668CECD4638A3081E3C2@mail.agso.gov.au>


 Good day everyone,

 I want to use the Gram-Charlier series expansion to model
 some data. To do that, I need functions to:

 1) Calculate 'n' moments from given data
 2) Transform 'n' moments to 'n' central moments, or
 3) Transform 'n' moments to 'n' cumulants
 4) Calculate a number of Hermite polynomials

 Are there R-functions to do any of the above?
 (mean, sd and cum3 are very limited)

 Thank you for your help,

 Augusto

--------------------------------------------
Augusto Sanabria. MSc, PhD.
Mathematical Modeller
Risk Research Group
Geospatial & Earth Monitoring Division
Geoscience Australia (www.ga.gov.au)
Cnr. Jerrabomberra Av. & Hindmarsh Dr.
Symonston ACT 2609
Ph. (02) 6249-9155



From ligges at statistik.uni-dortmund.de  Wed Feb 22 08:09:39 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 22 Feb 2006 08:09:39 +0100
Subject: [R] How do I tell it which directory to use?
In-Reply-To: <9707EBA615A57747A0668CECD4638A30016802A9@mail.agso.gov.au>
References: <9707EBA615A57747A0668CECD4638A30016802A9@mail.agso.gov.au>
Message-ID: <43FC0E33.8070502@statistik.uni-dortmund.de>

Augusto.Sanabria at ga.gov.au wrote:
> Tom,
> 
> You can define your working directory by using:
> 
> setwd("C:\Documents and Settings\Tom\My Documents\qpaper7\R Project Started 
> 19 Dec 05")

Thanks for your contribution to R-help, but:

No, see the R for Windows FAQs which tell you to use "\\" or "/" rather 
than "\"!


> 
> check that your file is there:
> list.files()
> 
> and then use:
> 
> source("myFile.txt") 
> 
> the machine should load "myFile"
> 
> You can go to another directory:
> setwd("anotherdir")
> 
> and repeat the procedure.
> 
> Or even better if you define a number of directories in an external file:
> 
> dir1 <- c(C:\Documents and Settings\Tom\My Documents\qpaper7\")
> dir2 <- c(C:\Documents and Settings\Tom\My Documents\")

See above + don't forget the quotes!


> and after loading the file at the beginning of the sesion you can use:
> 
> setwd("dir1")  etc.

In this case without quotes!

  setwd(dir1)

Please don't confuse other R-help readers and try to be more precise in 
your answers.

Uwe Ligges


> Is it of any help to you?
> Cheers,
> 
> Augusto
> 
> 
> --------------------------------------------
> Augusto Sanabria. MSc, PhD.
> Mathematical Modeller
> Risk Research Group
> Geospatial & Earth Monitoring Division
> Geoscience Australia (www.ga.gov.au)
> Cnr. Jerrabomberra Av. & Hindmarsh Dr.
> Symonston ACT 2609
> Ph. (02) 6249-9155
>  
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Thomas L Jones
> Sent: Wednesday, 22 February 2006 4:31 PM
> To: R-project help
> Subject: [R] How do I tell it which directory to use?
> 
> 
>>From Tom:
> 
> In R 2.2.0 under Windows, I want to be able to give it a filename such 
> as "myFile.txt" without the quotes. But actually I mean:
> 
> C:\Documents and Settings\Tom\My Documents\qpaper7\R Project Started 
> 19 Dec 05\myFile.txt
> 
> If I were to repeat this each time, my computer would get all bored 
> and cranky and start to drop bits (only a joke, of course). I think I 
> want to set the Home directory or the working directory or some 
> directory or other to the above directory. I may or may not want to 
> set some environmental variables.
> 
> R 2.2.0; working directly from the console and copying and pasting 
> code which I want to test into the console. Windows XP Home Edition. 
> Administrator privileges are enabled. A curve ball: There are two 
> accounts, "Tom" and "Jones;" the data are stored under "Tom," whereas 
> the computation is being done under the "Jones" account. I won't bore 
> you with the details of why I am doing this.
> 
> I was able to call Sys.getenv ("R_USER") and get the home directory.
> 
> I am a newbie to R and not familiar with the terminology.
> 
> Tom
> Thomas L. Jones, Ph.D., Computer Science
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Wed Feb 22 08:04:15 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Feb 2006 07:04:15 +0000 (GMT)
Subject: [R] Selecting amongst large classes of models (Was: Nested AIC)
In-Reply-To: <20060221231441.GH39857@ms.unimelb.edu.au>
References: <03DCBBA079F2324786E8715BE538968AA5AD64@FIGMAIL-CLUS01.FIG.FK>
	<Pine.LNX.4.64.0602210809450.1702@homer24.u.washington.edu>
	<Pine.LNX.4.64.0602211706500.11480@gannet.stats.ox.ac.uk>
	<20060221231441.GH39857@ms.unimelb.edu.au>
Message-ID: <Pine.LNX.4.64.0602220703230.16149@gannet.stats.ox.ac.uk>

On Wed, 22 Feb 2006, Andrew Robinson wrote:

> Professor Ripley,
>
> On Tue, Feb 21, 2006 at 05:36:15PM +0000, Prof Brian Ripley wrote:
>>
>> A recent talk of mine
>>
>>  	http://www.stats.ox.ac.uk/~ripley/Nelder80.pdf
>>
>> may be illuminating.  There is a published paper version.
>>
>
> Would you mind providing a citation for that published paper version?
> I do not find details on your website, and Current Contents does not
> provide any clues.

Ripley, B.D. (2004)
`Selecting amongst large classes of models'
In `Methods and Models in Statistics'
eds Adams, N., Crowder, M., Hand, D.J. and  Stephens, D. Imperial College
Press, pp. 155-170.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From blsykes at yahoo.com  Tue Feb 21 21:49:27 2006
From: blsykes at yahoo.com (Bryan Sykes)
Date: Tue, 21 Feb 2006 12:49:27 -0800 (PST)
Subject: [R] R xyplot and background color
Message-ID: <20060221204927.99555.qmail@web33802.mail.mud.yahoo.com>

Hi:

I have tried (unsuccessfully) to change the default
background color for my xyplot.  I have used
trellis.device(bg = "white", new = F) and
par(bg="white") before my xyplot command.  Yet the
color of the background has not changed.  Is there
something else I need to do?  I am using a windows
based machine to do this.


Thanks,

BLS



From andy_liaw at merck.com  Wed Feb 22 02:17:44 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 21 Feb 2006 20:17:44 -0500
Subject: [R] How to get around heteroscedasticity with non-linear leas t
 squares in R?
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED839@usctmx1106.merck.com>

From: Brian S Cade
> 
> Instead of thinking that the heteroscedasticity is a nuisance and 
> something to "get around", i.e, just wanting weighted 
> estimates of the 
> mean function, you might want to think about what 
> heteroscedasticity is 
> telling you and estimate some other quantities.  

Indeed!  See Prof. Carroll's 2002 Fisher Lecture:
http://www.stat.tamu.edu/ftp/pub/rjcarroll/2003.papers.directory/published_F
isher_Lecture.pdf
(There's Powerpoint file on his web page, too.)

Andy

> Heteroscedasticity is 
> telling you that the conditional distributions don't change 
> at a constant 
> rate across all portions of the distribution (think 
> percentiles or more 
> generally quantiles) and, therefore, a function for the mean 
> (no matter 
> how precisely estimated) cannot tell you all there is to know 
> about your 
> dose-response relation.  Why not go after estimating the conditional 
> quantile functions directly with nonlinear quantile 
> regression, function 
> nlrq() in the quantreg package? 
> 
> Brian
> 
> Brian S. Cade
> 
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
> 
> email:  brian_cade at usgs.gov
> tel:  970 226-9326
> 
> 
> 
> Kjetil Brinchmann Halvorsen <kjetilbrinchmannhalvorsen at gmail.com> 
> Sent by: r-help-bounces at stat.math.ethz.ch
> 02/21/2006 03:31 PM
> Please respond to
> KjetilBrinchmannHalvorsen at gmail.com
> 
> 
> To
> Quin Wills <quin.wills at googlemail.com>
> cc
> r-help at stat.math.ethz.ch
> Subject
> Re: [R] How to get around heteroscedasticity with non-linear 
> least squares 
> in R?
> 
> 
> 
> 
> 
> 
> Quin Wills wrote:
> > I am using "nls" to fit dose-response curves but am not sure how to 
> approach
> > more robust regression in R to get around the problem of 
> the my error
> > showing increased variance with increasing dose. 
> > 
> 
> package "sfsmisc"  has rnls (robust nls)
> which might be of use.
> 
> Kjetil
> 
> > 
> > 
> > My understanding is that "rlm" or "lqs" would not be a good 
> idea here.
> > 'Fairly new to regression work, so apologies if I'm missing 
> something
> > obvious.
> > 
> > 
> > 
> > 
> >                [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From maechler at stat.math.ethz.ch  Wed Feb 22 09:46:32 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 22 Feb 2006 09:46:32 +0100
Subject: [R] Gram-Charlier series
In-Reply-To: <9707EBA615A57747A0668CECD4638A3081E3C2@mail.agso.gov.au>
References: <9707EBA615A57747A0668CECD4638A3081E3C2@mail.agso.gov.au>
Message-ID: <17404.9448.424635.905639@stat.math.ethz.ch>

>>>>> "AugS" ==   <Augusto.Sanabria at ga.gov.au>
>>>>>     on Wed, 22 Feb 2006 17:13:17 +1100 writes:

    AugS> Good day everyone,

    AugS> I want to use the Gram-Charlier series expansion to model
    AugS> some data. To do that, I need functions to:

    AugS> 1) Calculate 'n' moments from given data
    AugS> 2) Transform 'n' moments to 'n' central moments, or
    AugS> 3) Transform 'n' moments to 'n' cumulants
    AugS> 4) Calculate a number of Hermite polynomials

    AugS> Are there R-functions to do any of the above?

I have functions to do "4)".
The nicer ones are built on package 'polynom' (which you should
definitely install and make use of for the above problems):

---------------------------------------------------------------------

#### Hermite Polynomials --- An extension to the "polynom" package
#### -------------------

## used e.g. from ../Pkg-ex/ctest/spearmanRho/prho-true-edgew.R
## for Edgeworth expansion

library(polynom)

hermitePolS <- function(n)
{
  ## Purpose: n-th Hermite polynomial  He(n) -- as "polynom" object
  ## --------------------------------------------------------------
  ## Arguments: n >= 0: integer
  ## ----------------------------------------------------------------------
  ## Author: Martin Maechler, Date: 26 Apr 2003, 20:33
    n <- as.integer(n)[1]
    if(n == 0) return(polynomial(1))
    x <- polynomial(0:1)
    if(n == 1) return(x)
    ## else
    ## Recursion : He_n(x) =  x He_{n-1}(x) - (n-1) He_{n-2}(x)
    ## The following is *definitely* not efficient
    return(x* hermitePolS(n-1) - (n-1) * hermitePolS(n-2))
}

system.time(He.9 <- hermitePolS(9)); He.9

## Much more efficient: without the *double* recursion :

hermitePol <- function(n)
{
  ## Purpose: n-th Hermite polynomial  He(n) -- as "polynom" object
  ## --------------------------------------------------------------
  ## Arguments: n >= 0: integer
  ## ----------------------------------------------------------------------
  ## Author: Martin Maechler, Date: 26 Apr 2003, 21:02
    n <- as.integer(n)[1]
    if(n == 0) return(polynomial(1))
    x <- polynomial(0:1)
    if(n == 1) return(x)
    ## else "Recursion" but the fast way:
    He.n1 <- polynomial(1)
    He <- x
    for(nn in 2:n) {
        He.n2 <- He.n1
        He.n1 <- He
        ## Recursion : He_n(x) =  x He_{n-1}(x) - (n-1) He_{n-2}(x)
        He <- x * He.n1 - (nn - 1) * He.n2
    }
    class(He) <- c("HermitePol", class(He))
    return(He)
}

system.time(He9 <- hermitePol(9)); He9 # 9 x faster

(fH9 <- as.function(He9))## note that 'polynom' needs a fix
## i.e.  polynom:::as.function.polynomial:
environment(fH9) <- .GlobalEnv
fH7 <- as.function(He7 <- hermitePol(7))
fH8 <- as.function(He8 <- hermitePol(8))
## Orthogonality and "Scale"
## These give 0 :
integrate(function(x)fH8(x)*fH9(x) * dnorm(x), -Inf,Inf, rel.tol=1e-10)
integrate(function(x)fH7(x)*fH9(x) * dnorm(x), -Inf,Inf, rel.tol=1e-8)
integrate(function(x)fH7(x)*fH8(x) * dnorm(x), -Inf,Inf, rel.tol=1e-10)
## Scale: Inf{ He_n(x) ^ 2  phi(x) dx } = n!  :
str(I9 <- integrate(function(x)fH9(x)^2 * dnorm(x), -Inf,Inf, rel.tol=1e-10, abs.tol = 0.01))



if(FALSE) {

## This is not quite it, but ok for small poly :
str.polynomial <- function(x, ...)
    cat("polynomial", noquote(as.character(x)),"\n")

## to improve, I would want an option `highOrder' to
##   as.character.polynomial(p,  highOrder = FALSE)
## and then improve the following (use "..." when it's too long:

##- str.polynomial <- function(x, ...)
##-     cat("polynomial", noquote(as.character(x, highOrder=TRUE)),"\n")

str(lapply(1:8, hermitePol))
## or even nicer:
}

for(n in 0:11)
    cat("He(",formatC(n,wid=2),") = ", noquote(as.character(hermitePol(n))),
        "\n", sep="")

###---------------------------------------------------------------------


    AugS> (mean, sd and cum3 are very limited)

    AugS> Thank you for your help,

    AugS> Augusto

    AugS> --------------------------------------------
    AugS> Augusto Sanabria. MSc, PhD.
		  .....................
		  (signature too long, core dumped)

Martin Maechler, ETH Zurich



From azzalini at stat.unipd.it  Wed Feb 22 10:09:46 2006
From: azzalini at stat.unipd.it (Adelchi Azzalini)
Date: Wed, 22 Feb 2006 10:09:46 +0100
Subject: [R] color quantization / binning a variable into levels
In-Reply-To: <Pine.LNX.4.58.0602211020160.16984@maplepark.com>
References: <Pine.LNX.4.58.0602211020160.16984@maplepark.com>
Message-ID: <20060222100946.2d55a8ab.azzalini@stat.unipd.it>

On Tue, 21 Feb 2006 11:08:38 -0600 (CST), David Forrest wrote:

perhaps "binning" of package "sm" is what you want

best wishes,
Adelchi Azzalini

DF> Hi all,
DF> 
DF> I'd like to quantize a variable to map it into a limited set of
DF> integers for use with a colormap.  "image" and filled.contour"  do
DF> this mapping inside somewhere, but I'd like to choose the colors
DF> for plotting a set of polygons.  Is there a pre-existing function
DF> that does something like this well?  i.e., is capable of using
DF> 'breaks'?
DF> 
DF> quantize<-function(x,n=10, breaks=NULL){
DF> # bin the variable x into n levels
DF>   xmin<-min(x)
DF>   xmax<-max(x)
DF>   1+floor(n*(x-xmin)/(xmax-xmin)*.999)
DF> }
DF> 
DF> x<- -10:10
DF> cbind(x,quantize(x,2),quantize(x),quantize(x,21))
DF> 
DF> quantize(x,breaks=c(5,7))   #
DF> 
DF> Thanks for your time,
DF> 
DF> Dave

-- 
Adelchi Azzalini  <azzalini at stat.unipd.it>
Dipart.Scienze Statistiche, Universit?? di Padova, Italia
tel. +39 049 8274147,  http://azzalini.stat.unipd.it/



From r.hankin at noc.soton.ac.uk  Wed Feb 22 10:11:51 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Wed, 22 Feb 2006 09:11:51 +0000
Subject: [R] elements that appear only once
Message-ID: <634A4100-08CD-4704-9995-DD07AC4BB078@soc.soton.ac.uk>

Hi.

I have a factor and I want to extract just those elements that appear  
exactly once.
How to do this?

Toy example follows.

 > a <- as.factor(c(rep("oak",5) ,rep("ash",1),rep("elm",1),rep 
("beech",4)))
 > a
[1] oak   oak   oak   oak   oak   ash   elm   beech beech beech beech
Levels: ash beech elm oak
 > table(a)
a
   ash beech   elm   oak
     1     4     1     5
 >

So I would want "ash" and "elm", because there is only one ash and
only one elm in my wood.

My Best Effort:


 > names(table(a)[table(a)==1])
[1] "ash" "elm"
 >

This doesn't seem particularly elegant to me; there must be a better  
way!

anyone?




--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From erhansen at math.ku.dk  Wed Feb 22 10:17:14 2006
From: erhansen at math.ku.dk (Ernst Hansen)
Date: Wed, 22 Feb 2006 10:17:14 +0100
Subject: [R] Gram-Charlier series
In-Reply-To: <17404.9448.424635.905639@stat.math.ethz.ch>
References: <9707EBA615A57747A0668CECD4638A3081E3C2@mail.agso.gov.au>
	<17404.9448.424635.905639@stat.math.ethz.ch>
Message-ID: <17404.11290.125526.561904@pc12.math.ku.dk>

Martin Maechler writes:
 > >>>>> "AugS" ==   <Augusto.Sanabria at ga.gov.au>
 > >>>>>     on Wed, 22 Feb 2006 17:13:17 +1100 writes:
 > 
 >     AugS> Good day everyone,
 > 
 >     AugS> I want to use the Gram-Charlier series expansion to model
 >     AugS> some data. To do that, I need functions to:
 > 
 >     AugS> 1) Calculate 'n' moments from given data
 >     AugS> 2) Transform 'n' moments to 'n' central moments, or
 >     AugS> 3) Transform 'n' moments to 'n' cumulants
 >     AugS> 4) Calculate a number of Hermite polynomials
 > 
 >     AugS> Are there R-functions to do any of the above?
 > 
 > I have functions to do "4)".

For a direct way to translate raw moments into cumulants, you may want
to look at the methods from the book 'Symbolic Computation for
Statistical Inference' by D. F. Andrews and J. E. Stafford.  There is
in fact an R-implementation of the methods available at

  http://fisher.utstat.toronto.edu/david/SCSI/RSCSI.html


Hope this helps,

Ernst Hansen
Department of Statistics
University of Copenhagen



From dimitris.rizopoulos at med.kuleuven.be  Wed Feb 22 10:24:33 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 22 Feb 2006 10:24:33 +0100
Subject: [R] elements that appear only once
References: <634A4100-08CD-4704-9995-DD07AC4BB078@soc.soton.ac.uk>
Message-ID: <00a001c63791$cab12370$0540210a@www.domain>

another approach is:

names(which(table(a) == 1))

but I don't know if you find this more elegant :)


Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Robin Hankin" <r.hankin at noc.soton.ac.uk>
To: "RHelp" <r-help at stat.math.ethz.ch>
Sent: Wednesday, February 22, 2006 10:11 AM
Subject: [R] elements that appear only once


> Hi.
>
> I have a factor and I want to extract just those elements that 
> appear
> exactly once.
> How to do this?
>
> Toy example follows.
>
> > a <- as.factor(c(rep("oak",5) ,rep("ash",1),rep("elm",1),rep
> ("beech",4)))
> > a
> [1] oak   oak   oak   oak   oak   ash   elm   beech beech beech 
> beech
> Levels: ash beech elm oak
> > table(a)
> a
>   ash beech   elm   oak
>     1     4     1     5
> >
>
> So I would want "ash" and "elm", because there is only one ash and
> only one elm in my wood.
>
> My Best Effort:
>
>
> > names(table(a)[table(a)==1])
> [1] "ash" "elm"
> >
>
> This doesn't seem particularly elegant to me; there must be a better
> way!
>
> anyone?
>
>
>
>
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>  tel  023-8059-7743
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From ritz at kvl.dk  Wed Feb 22 10:22:20 2006
From: ritz at kvl.dk (Christian Ritz)
Date: Wed, 22 Feb 2006 10:22:20 +0100
Subject: [R] How to get around heteroscedasticity with non-linear	least
	squares in R?
Message-ID: <43FC3BC802000006002A3384@gwia.kvl.dk>

Hi Quin,

the package 'drc' on CRAN deals with modelling dose-response curves.

Moreover it allows adjustment for heterogeneity by means of 


  transformation (Box-Cox transformation)

  modelling the variance as a power of the mean.


See the package documentation for more features.


Christian



From Steve.Roberts at manchester.ac.uk  Wed Feb 22 10:47:41 2006
From: Steve.Roberts at manchester.ac.uk (Stephen A Roberts)
Date: Wed, 22 Feb 2006 09:47:41 +0000
Subject: [R] OT Futility Analysis
In-Reply-To: <43FBDE27.7040209@pdf.com>
Message-ID: <20060222094741625.00000002680@K01391008F6W51J>


I would take the line that if they hadn't pre-specified any stopping rules, the only reason to stop is safety or new external data. I would be very suspicious of requests from the steering committee to stop for futility - they should be blinded so why are they thinking futility unless results have leaked? I would argue that they are obliged to finish the trial once they start.

This is an example of the need to sort out these things in advance - look up the stuff from the UK DAMOCLES project. The recent book edited by DeMets et al (Data Monitoring in Clinical Trials: A Case Studies Approach) is a good read on these sorts of issues and I think there is a more statistical book from the same group of authors.

 As far as software is concerned, futility analysis and conditional power are simply standard analyses with made up data and more-or-less justifiable assumptions.

Steve.


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-
> bounces at stat.math.ethz.ch] On Behalf Of Spencer Graves
> Sent: 22 February 2006 03:45
> To: Kevin E. Thorpe
> Cc: R Help Mailing List
> Subject: Re: [R] OT Futility Analysis
> 
> 	  What does this particular Steering Committee think a "futility
> analysis" is?  Do they have any particular reference(s)?  What do you
> find in your own literature review?
> 
> 	  If it were my problem, I think I'd start with questions like that.
> Your comments suggested to me a confounding of technical and political
> problems.  The politics suggests the language you need to use in your
> response.  Beyond that, I've never heard before of a "futility
> analysis", but I think I could do one by just trying to be clear about
> the options the Steering Committee might consider plausible and then
> comparing them with appropriate simulations -- summarized as confidence
> intervals, as you suggest.
> 
> 	  And I hope that someone else will enlighten us both if there are
> better options available.
> 
> 	  Best Wishes,
> 	  spencer graves
> p.s.  For any attorneys who may read these comments, the suggestions are
> obviously warranteed up to the amount you paid for it, which is nothing.
>   If you follow them and they turn out to be inappropriate, you will pay
> the price.  I encourage you to share the problems with me, so I can
> learn from the experience.  However, the limits of my liability are as
> already stated.
> 
> Kevin E. Thorpe wrote:
> 
> > I beg your pardon if this is too off topic.  I am posting here
> > since I hope to find an R solution to my problem.  Please indulge
> > me while I give a little background about what I'm trying to do.
> >
> > I'm on a DSMB for a clinical trial.  The Steering Committee for the
> > trial has asked us to perform a futility analysis on their primary
> > outcome which is a time-to-event endpoint.  The trial was not designed
> > with group sequential methods, nor was any futility analysis spelled
> > out in the protocol.  Another thing which may be relevant is that
> > due to circumstances beyond the investigators' control, the trial
> > will stop recruitment prematurely unless there is some compelling
> > reason for them to find a way to continue the trial.  Lastly, the
> > trial has accrued not quite half of the planned sample size.
> >
> > Admittedly, I don't have a vast amount of experience implementing
> > stopping rules.  In other protocols I have seen where futility
> > analyses have been planned but a group sequential design has not
> > otherwise been employed, conditional power has been used for the
> > futility rule.  So naturally, that was my first thought (although
> > I may well be wrong) in this case.  I have done RSiteSearch() with
> > the following terms (three different searches):
> >
> > 	futility analysis
> > 	conditional power
> > 	stochastic curtailment
> >
> > Nothing that looked relevant to my problem jumped out at me.
> >
> > I have read, somewhat recently, that there are problems with conditional
> > power, although I don't remember the details at the moment.  This
> > has prompted me to consider other approaches to the problem.
> >
> > One simple thing that has occurred to me, although I don't know
> > what the implications are is to simply look at a confidence
> > interval around the hazard ratio for the treatment effect.  In
> > the event that the CI includes 1 and excludes any clinically
> > important difference, I would take that as an indication of
> > futility.
> >
> > I would appreciate your comments on this and to learn of any more
> > formal methods, particularly of implementations in R.
> >
> > Thank you for reading.
> >
> > Kevin
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From jkawczak at uncc.edu  Wed Feb 22 10:55:15 2006
From: jkawczak at uncc.edu (Janusz Kawczak)
Date: Wed, 22 Feb 2006 04:55:15 -0500 (EST)
Subject: [R] Gram-Charlier series
In-Reply-To: <17404.11290.125526.561904@pc12.math.ku.dk>
References: <9707EBA615A57747A0668CECD4638A3081E3C2@mail.agso.gov.au>
	<17404.9448.424635.905639@stat.math.ethz.ch>
	<17404.11290.125526.561904@pc12.math.ku.dk>
Message-ID: <Pine.GSO.4.55.0602220453120.7304@is-sm1.uncc.edu>

I believe this page includes more up to date version:
http://fisher.utstat.toronto.edu/david/Sym2004/Sym2004.html

Janusz.

On Wed, 22 Feb 2006, Ernst Hansen wrote:

> Martin Maechler writes:
>  > >>>>> "AugS" ==   <Augusto.Sanabria at ga.gov.au>
>  > >>>>>     on Wed, 22 Feb 2006 17:13:17 +1100 writes:
>  >
>  >     AugS> Good day everyone,
>  >
>  >     AugS> I want to use the Gram-Charlier series expansion to model
>  >     AugS> some data. To do that, I need functions to:
>  >
>  >     AugS> 1) Calculate 'n' moments from given data
>  >     AugS> 2) Transform 'n' moments to 'n' central moments, or
>  >     AugS> 3) Transform 'n' moments to 'n' cumulants
>  >     AugS> 4) Calculate a number of Hermite polynomials
>  >
>  >     AugS> Are there R-functions to do any of the above?
>  >
>  > I have functions to do "4)".
>
> For a direct way to translate raw moments into cumulants, you may want
> to look at the methods from the book 'Symbolic Computation for
> Statistical Inference' by D. F. Andrews and J. E. Stafford.  There is
> in fact an R-implementation of the methods available at
>
>   http://fisher.utstat.toronto.edu/david/SCSI/RSCSI.html
>
>
> Hope this helps,
>
> Ernst Hansen
> Department of Statistics
> University of Copenhagen
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From r.hankin at noc.soton.ac.uk  Wed Feb 22 12:14:44 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Wed, 22 Feb 2006 11:14:44 +0000
Subject: [R] elements that appear only once
In-Reply-To: <00a001c63791$cab12370$0540210a@www.domain>
References: <634A4100-08CD-4704-9995-DD07AC4BB078@soc.soton.ac.uk>
	<00a001c63791$cab12370$0540210a@www.domain>
Message-ID: <12088627-6235-4E95-9420-FC381369D1ED@soc.soton.ac.uk>

Hi Dmitris, and list



On 22 Feb 2006, at 09:24, Dimitris Rizopoulos wrote:

> another approach is:
>
> names(which(table(a) == 1))
>
> but I don't know if you find this more elegant :)
>



well, thank you for this (which() is good here!) but this is still  
"inelegant" IMHO
because it uses the names() of a table.

If I had

 > a <- as.factor(c(1,1,1,2,3,4,4,4,4,5))
 > names(which(table(a)==1))
[1] "2" "3" "5"
 >

this gives a character vector.

I could coerce using  as.integer() here, but this seems so....inelegant.

best wishes


Robin



>
> Best,
> Dimitris
>



>
>
>> Hi.
>>
>> I have a factor and I want to extract just those elements that
>> appear
>> exactly once.
>> How to do this?
>>
>> Toy example follows.
>>
>>> a <- as.factor(c(rep("oak",5) ,rep("ash",1),rep("elm",1),rep
>> ("beech",4)))
>>> a
>> [1] oak   oak   oak   oak   oak   ash   elm   beech beech beech
>> beech
>> Levels: ash beech elm oak
>>> table(a)
>> a
>>   ash beech   elm   oak
>>     1     4     1     5
>>>
>>
>> So I would want "ash" and "elm", because there is only one ash and
>> only one elm in my wood.
>>
>> My Best Effort:
>>
>>
>>> names(table(a)[table(a)==1])
>> [1] "ash" "elm"
>>>
>>
>> This doesn't seem particularly elegant to me; there must be a better
>> way!
>>
>> anyone?
>>
>>

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From ramasamy at cancer.org.uk  Wed Feb 22 13:23:42 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 22 Feb 2006 12:23:42 +0000
Subject: [R] How do I tell it which directory to use?
In-Reply-To: <9707EBA615A57747A0668CECD4638A30016802A9@mail.agso.gov.au>
References: <9707EBA615A57747A0668CECD4638A30016802A9@mail.agso.gov.au>
Message-ID: <1140611023.3485.6.camel@dhcp-82.wolf.ox.ac.uk>

I think the idea of defining dir1 and dir2 is a good one. If you want to
simplify life even further, you can put these into files that get
initialised when R starts. See help(Startup) for details.

Regards, Adai


On Wed, 2006-02-22 at 16:54 +1100, Augusto.Sanabria at ga.gov.au wrote:
> Tom,
> 
> You can define your working directory by using:
> 
> setwd("C:\Documents and Settings\Tom\My Documents\qpaper7\R Project Started 
> 19 Dec 05")
> 
> check that your file is there:
> list.files()
> 
> and then use:
> 
> source("myFile.txt") 
> 
> the machine should load "myFile"
> 
> You can go to another directory:
> setwd("anotherdir")
> 
> and repeat the procedure.
> 
> Or even better if you define a number of directories in an external file:
> 
> dir1 <- c(C:\Documents and Settings\Tom\My Documents\qpaper7\")
> dir2 <- c(C:\Documents and Settings\Tom\My Documents\")
> 
> and after loading the file at the beginning of the sesion you can use:
> 
> setwd("dir1")  etc.
> 
> Is it of any help to you?
> 
> Cheers,
> 
> Augusto
> 
> 
> --------------------------------------------
> Augusto Sanabria. MSc, PhD.
> Mathematical Modeller
> Risk Research Group
> Geospatial & Earth Monitoring Division
> Geoscience Australia (www.ga.gov.au)
> Cnr. Jerrabomberra Av. & Hindmarsh Dr.
> Symonston ACT 2609
> Ph. (02) 6249-9155
>  
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Thomas L Jones
> Sent: Wednesday, 22 February 2006 4:31 PM
> To: R-project help
> Subject: [R] How do I tell it which directory to use?
> 
> 
> >From Tom:
> 
> In R 2.2.0 under Windows, I want to be able to give it a filename such 
> as "myFile.txt" without the quotes. But actually I mean:
> 
> C:\Documents and Settings\Tom\My Documents\qpaper7\R Project Started 
> 19 Dec 05\myFile.txt
> 
> If I were to repeat this each time, my computer would get all bored 
> and cranky and start to drop bits (only a joke, of course). I think I 
> want to set the Home directory or the working directory or some 
> directory or other to the above directory. I may or may not want to 
> set some environmental variables.
> 
> R 2.2.0; working directly from the console and copying and pasting 
> code which I want to test into the console. Windows XP Home Edition. 
> Administrator privileges are enabled. A curve ball: There are two 
> accounts, "Tom" and "Jones;" the data are stored under "Tom," whereas 
> the computation is being done under the "Jones" account. I won't bore 
> you with the details of why I am doing this.
> 
> I was able to call Sys.getenv ("R_USER") and get the home directory.
> 
> I am a newbie to R and not familiar with the terminology.
> 
> Tom
> Thomas L. Jones, Ph.D., Computer Science
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From moritz.marienfeld at arcor.de  Wed Feb 22 13:25:18 2006
From: moritz.marienfeld at arcor.de (moritz.marienfeld@arcor.de)
Date: Wed, 22 Feb 2006 13:25:18 +0100 (CET)
Subject: [R] How can one use R-code and R-functions within C-Code?
Message-ID: <6511510.1140611118249.JavaMail.ngmail@webmail-08.arcor-online.net>

Dear everyone,

the following problem: Our group has written a lengthy program in c++, to which we would like to add some additional features. Because we are not sure if those features are actually useful, we would prefer to take a "quick and dirty" approach just to try them out. The additional feature is that in every iteration of the algorithm membership-probabilities should by calculated by a multinomial logit or probit model. We have tried to get C/C++ code for this, but sadly neither me nor my collegue succeded in obtaining C-code for something, which has certainly already be programmed in C several times. 

But we know, that R functions like "multinom" exist, which could do the job. This is why we would like to use R-Code and R-functions within or C++ program if this is possible. So I have actually two questions: Is it feasible to use R-code and R-functions like "multinom" within a c++ program? And if so, what is the best way to implement this (how to get data from C into the R functions, how to execute the R functions within C++, how to transfer the results back to c++)?

Moritz    

Moritz Marienfeld

Viel oder wenig? Schnell oder langsam? Unbegrenzt surfen + telefonieren
ohne Zeit- und Volumenbegrenzung? DAS TOP ANGEBOT JETZT bei Arcor: g??nstig
und schnell mit DSL - das All-Inclusive-Paket f??r clevere Doppel-Sparer,
nur  44,85 ?  inkl. DSL- und ISDN-Grundgeb??hr!



From ramasamy at cancer.org.uk  Wed Feb 22 13:27:19 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 22 Feb 2006 12:27:19 +0000
Subject: [R] elements that appear only once
In-Reply-To: <634A4100-08CD-4704-9995-DD07AC4BB078@soc.soton.ac.uk>
References: <634A4100-08CD-4704-9995-DD07AC4BB078@soc.soton.ac.uk>
Message-ID: <1140611239.3485.8.camel@dhcp-82.wolf.ox.ac.uk>

A slight variation on your solution but hopefully more readable:

	names( which( table(a) == 1 ) )

Regards, Adai



On Wed, 2006-02-22 at 09:11 +0000, Robin Hankin wrote:
> Hi.
> 
> I have a factor and I want to extract just those elements that appear  
> exactly once.
> How to do this?
> 
> Toy example follows.
> 
>  > a <- as.factor(c(rep("oak",5) ,rep("ash",1),rep("elm",1),rep 
> ("beech",4)))
>  > a
> [1] oak   oak   oak   oak   oak   ash   elm   beech beech beech beech
> Levels: ash beech elm oak
>  > table(a)
> a
>    ash beech   elm   oak
>      1     4     1     5
>  >
> 
> So I would want "ash" and "elm", because there is only one ash and
> only one elm in my wood.
> 
> My Best Effort:
> 
> 
>  > names(table(a)[table(a)==1])
> [1] "ash" "elm"
>  >
> 
> This doesn't seem particularly elegant to me; there must be a better  
> way!
> 
> anyone?
> 
> 
> 
> 
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>   tel  023-8059-7743
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ronggui.huang at gmail.com  Wed Feb 22 13:36:28 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Wed, 22 Feb 2006 20:36:28 +0800
Subject: [R] does multinomial logistic model from multinom (nnet) has logLik?
Message-ID: <38b9f0350602220436v514bc933i@mail.gmail.com>

I want to get the logLik to calculate McFadden.R2 ,ML.R2 and
Cragg.Uhler.R2, but the value from multinom does not have logLik.So my
quetion is : is logLik meaningful to multinomial logistic model from
multinom?If it does, how can I get it?

Thank you!

ps: I konw  VGAM has function to get the multinomial logistic model
with  logLik,  but I prefer use the function from "official" R
packages .

--
ronggui
Deparment of Sociology
Fudan University



From ripley at stats.ox.ac.uk  Wed Feb 22 13:39:23 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Feb 2006 12:39:23 +0000 (GMT)
Subject: [R] elements that appear only once
In-Reply-To: <12088627-6235-4E95-9420-FC381369D1ED@soc.soton.ac.uk>
References: <634A4100-08CD-4704-9995-DD07AC4BB078@soc.soton.ac.uk>
	<00a001c63791$cab12370$0540210a@www.domain>
	<12088627-6235-4E95-9420-FC381369D1ED@soc.soton.ac.uk>
Message-ID: <Pine.LNX.4.64.0602221230510.30614@gannet.stats.ox.ac.uk>

On Wed, 22 Feb 2006, Robin Hankin wrote:

> Hi Dmitris, and list
>
> On 22 Feb 2006, at 09:24, Dimitris Rizopoulos wrote:
>
>> another approach is:
>>
>> names(which(table(a) == 1))
>>
>> but I don't know if you find this more elegant :)

Since the names of the table are the levels of the factor, I would use

levels(a)[table(a) %in% 1]

Well, almost.  If you have NA or NaN as a factor level then all these 
solutions need to be more complicated.

> well, thank you for this (which() is good here!) but this is still
> "inelegant" IMHO
> because it uses the names() of a table.
>
> If I had
>
> > a <- as.factor(c(1,1,1,2,3,4,4,4,4,5))
> > names(which(table(a)==1))
> [1] "2" "3" "5"
> >
>
> this gives a character vector.
>
> I could coerce using  as.integer() here, but this seems so....inelegant.

But a has a character vector of levels, and there is nothing there to tell 
R that you wanted integers and not decimal-digit character strings.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From I.Szentirmai at rug.nl  Wed Feb 22 13:40:35 2006
From: I.Szentirmai at rug.nl (I.Szentirmai)
Date: Wed, 22 Feb 2006 13:40:35 +0100
Subject: [R] read.table missing values
In-Reply-To: <1140611023.3485.6.camel@dhcp-82.wolf.ox.ac.uk>
References: <9707EBA615A57747A0668CECD4638A30016802A9@mail.agso.gov.au>
	<1140611023.3485.6.camel@dhcp-82.wolf.ox.ac.uk>
Message-ID: <web-16585564@mail3.rug.nl>

Dear R users,

I'm trying to read data from a tab-delimited text file to 
R, but I have problems with missing values. R gives this 
kind of error messages: "line 1 did not have 9 elements".

Could someone tell me how I can deal with missing values 
in this case?

Thanks a lot in advance,
Istvan



From p.dalgaard at biostat.ku.dk  Wed Feb 22 13:41:43 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 Feb 2006 13:41:43 +0100
Subject: [R] var-covar matrices comparison
In-Reply-To: <Pine.LNX.4.58.0602221204520.14076@orpheus.qimr.edu.au>
References: <mailman.11.1140519602.6083.r-help@stat.math.ethz.ch>
	<Pine.LNX.4.58.0602221204520.14076@orpheus.qimr.edu.au>
Message-ID: <x28xs336rc.fsf@viggo.kubism.ku.dk>

David Duffy <David.Duffy at qimr.edu.au> writes:

> > Date: Mon, 20 Feb 2006 16:43:55 -0600
> > From: Aldi Kraja <aldi at wustl.edu>
> >
> > Hi,
> > Using package gclus in R, I have created some graphs that show the
> > trends within subgroups of data and correlations among 9 variables (v1-v9).
> > Being interested for more details on these data I have produced also the
> > var-covar matrices.
> > Question: From a pair of two subsets of data (with 9 variables each, I
> > have two var-covar matrices for each subgroup, that differ for a
> > treatment on one group (treatment A) vs (non-Treatment A).
> >
> > Is there a software that can compare if two var-covar matrices are
> > statistically the same?
> >
> 
> This can be done in various structural equation modelling packages.  I don't
> think it can be done automatically using the sem package, as that does not allow
> multiple groups.  You can roll your own LR test (assuming MVN):
> 
>   f <- (N-1) * (log(det(E)) - log(det(O)) + sum(diag((O %*% solve(E))))-p)
> 
>   N=size of group
>   p=number of variables
>   E=expected covariance matrix
>   O=observed covariance matrix

..and an asymptotic approximation to order n^-3 is found in TW
Anderson: An Introduction to Multivariate Statistical Analysis
(formula (7) section 10.5 in my 1958, 1st ed. reprint).

 
>   where in your example, E will be the observed covariance matrix for
>   the pooled groups.  There are GLS etc alternatives - see eg Bollen's book on
>   SEM.
> 
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Wed Feb 22 13:42:29 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Feb 2006 12:42:29 +0000 (GMT)
Subject: [R] How can one use R-code and R-functions within C-Code?
In-Reply-To: <6511510.1140611118249.JavaMail.ngmail@webmail-08.arcor-online.net>
References: <6511510.1140611118249.JavaMail.ngmail@webmail-08.arcor-online.net>
Message-ID: <Pine.LNX.4.64.0602221240090.30614@gannet.stats.ox.ac.uk>

This is discussed in the `Writing R Extensions' manual which ships with 
every copy of R.

Yes, it is possible and widely used.  For example, this is how optim() and 
nls() work.

See the posting guide, which clearly indicates this is a topic for 
the R-devel list.

On Wed, 22 Feb 2006, moritz.marienfeld at arcor.de wrote:

> Dear everyone,
>
> the following problem: Our group has written a lengthy program in c++, 
> to which we would like to add some additional features. Because we are 
> not sure if those features are actually useful, we would prefer to take 
> a "quick and dirty" approach just to try them out. The additional 
> feature is that in every iteration of the algorithm 
> membership-probabilities should by calculated by a multinomial logit or 
> probit model. We have tried to get C/C++ code for this, but sadly 
> neither me nor my collegue succeded in obtaining C-code for something, 
> which has certainly already be programmed in C several times.
>
> But we know, that R functions like "multinom" exist, which could do the 
> job. This is why we would like to use R-Code and R-functions within or 
> C++ program if this is possible. So I have actually two questions: Is it 
> feasible to use R-code and R-functions like "multinom" within a c++ 
> program? And if so, what is the best way to implement this (how to get 
> data from C into the R functions, how to execute the R functions within 
> C++, how to transfer the results back to c++)?


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From francoisromain at free.fr  Wed Feb 22 13:50:28 2006
From: francoisromain at free.fr (Romain Francois)
Date: Wed, 22 Feb 2006 13:50:28 +0100
Subject: [R] How can one use R-code and R-functions within C-Code?
In-Reply-To: <6511510.1140611118249.JavaMail.ngmail@webmail-08.arcor-online.net>
References: <6511510.1140611118249.JavaMail.ngmail@webmail-08.arcor-online.net>
Message-ID: <43FC5E14.804@free.fr>

Le 22.02.2006 13:25, moritz.marienfeld at arcor.de a ??crit :
> Dear everyone,
>
> the following problem: Our group has written a lengthy program in c++, to which we would like to add some additional features. Because we are not sure if those features are actually useful, we would prefer to take a "quick and dirty" approach just to try them out. The additional feature is that in every iteration of the algorithm membership-probabilities should by calculated by a multinomial logit or probit model. We have tried to get C/C++ code for this, but sadly neither me nor my collegue succeded in obtaining C-code for something, which has certainly already be programmed in C several times. 
>
> But we know, that R functions like "multinom" exist, which could do the job. This is why we would like to use R-Code and R-functions within or C++ program if this is possible. So I have actually two questions: Is it feasible to use R-code and R-functions like "multinom" within a c++ program? And if so, what is the best way to implement this (how to get data from C into the R functions, how to execute the R functions within C++, how to transfer the results back to c++)?
>
> Moritz    
>
> Moritz Marienfeld
>   

Hi,

For a quick (and pretty not dirty) approach, try Rserve : 
http://rosuda.org/Rserve/

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
Discover the R Movies Gallery : http://addictedtor.free.fr/movies
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From sumantab at ambaresearch.com  Wed Feb 22 13:51:03 2006
From: sumantab at ambaresearch.com (Sumanta Basak)
Date: Wed, 22 Feb 2006 18:21:03 +0530
Subject: [R] Error in RBloomberg
Message-ID: <14850601FF012647A90A5DB31F96DB374A30CB@INBLRDC01.BANG.irpvl.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060222/3fefc3c6/attachment.pl

From sdavis2 at mail.nih.gov  Wed Feb 22 13:54:49 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 22 Feb 2006 07:54:49 -0500
Subject: [R] read.table missing values
In-Reply-To: <web-16585564@mail3.rug.nl>
Message-ID: <C021C949.6262%sdavis2@mail.nih.gov>

Does using read.delim instead of read.table fix your problem?

Sean


On 2/22/06 7:40 AM, "I.Szentirmai" <I.Szentirmai at rug.nl> wrote:

> Dear R users,
> 
> I'm trying to read data from a tab-delimited text file to
> R, but I have problems with missing values. R gives this
> kind of error messages: "line 1 did not have 9 elements".
> 
> Could someone tell me how I can deal with missing values
> in this case?
> 
> Thanks a lot in advance,
> Istvan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at gmail.com  Wed Feb 22 13:57:05 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 22 Feb 2006 07:57:05 -0500
Subject: [R] elements that appear only once
In-Reply-To: <634A4100-08CD-4704-9995-DD07AC4BB078@soc.soton.ac.uk>
References: <634A4100-08CD-4704-9995-DD07AC4BB078@soc.soton.ac.uk>
Message-ID: <971536df0602220457o495c3170hab4f75dfacbf11c8@mail.gmail.com>

I am not sure whether this is desirable but here is another way just
in case:

   paste(setdiff(a, a[duplicated(a)]))

You could replace paste with as.character if you prefer or
could remove it entirely if you want the result as a factor.

On 2/22/06, Robin Hankin <r.hankin at noc.soton.ac.uk> wrote:
> Hi.
>
> I have a factor and I want to extract just those elements that appear
> exactly once.
> How to do this?
>
> Toy example follows.
>
>  > a <- as.factor(c(rep("oak",5) ,rep("ash",1),rep("elm",1),rep
> ("beech",4)))
>  > a
> [1] oak   oak   oak   oak   oak   ash   elm   beech beech beech beech
> Levels: ash beech elm oak
>  > table(a)
> a
>   ash beech   elm   oak
>     1     4     1     5
>  >
>
> So I would want "ash" and "elm", because there is only one ash and
> only one elm in my wood.
>
> My Best Effort:
>
>
>  > names(table(a)[table(a)==1])
> [1] "ash" "elm"
>  >
>
> This doesn't seem particularly elegant to me; there must be a better
> way!
>
> anyone?
>
>
>
>
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>  tel  023-8059-7743
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Wed Feb 22 13:57:23 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 Feb 2006 13:57:23 +0100
Subject: [R] elements that appear only once
In-Reply-To: <12088627-6235-4E95-9420-FC381369D1ED@soc.soton.ac.uk>
References: <634A4100-08CD-4704-9995-DD07AC4BB078@soc.soton.ac.uk>
	<00a001c63791$cab12370$0540210a@www.domain>
	<12088627-6235-4E95-9420-FC381369D1ED@soc.soton.ac.uk>
Message-ID: <x24q2r3618.fsf@viggo.kubism.ku.dk>

Robin Hankin <r.hankin at noc.soton.ac.uk> writes:

> Hi Dmitris, and list
> 
> 
> 
> On 22 Feb 2006, at 09:24, Dimitris Rizopoulos wrote:
> 
> > another approach is:
> >
> > names(which(table(a) == 1))
> >
> > but I don't know if you find this more elegant :)
> >
> 
> 
> 
> well, thank you for this (which() is good here!) but this is still  
> "inelegant" IMHO
> because it uses the names() of a table.
> 
> If I had
> 
>  > a <- as.factor(c(1,1,1,2,3,4,4,4,4,5))
>  > names(which(table(a)==1))
> [1] "2" "3" "5"
>  >
> 
> this gives a character vector.
> 
> I could coerce using  as.integer() here, but this seems so....inelegant.

You could go 

sort(unique(a))[table(a)==1]

(without the sort(), things go pearshaped, try setting

a <- factor(c(1,1,1,2,3,4,4,4,4,5),levels=5:1)

wnd you'll see).

If we assume that a is a factor, another option is

levels(a))[table(a)==1]

but that also has the problem of returning a character vector.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From I.Szentirmai at rug.nl  Wed Feb 22 14:03:41 2006
From: I.Szentirmai at rug.nl (I.Szentirmai)
Date: Wed, 22 Feb 2006 14:03:41 +0100
Subject: [R] read.table missing values
In-Reply-To: <C021C949.6262%sdavis2@mail.nih.gov>
References: <C021C949.6262%sdavis2@mail.nih.gov>
Message-ID: <web-16587354@mail3.rug.nl>

might be, but I have already found another solution: 
reat.table(file,sep="\t")

Thanks,
Istvan



On Wed, 22 Feb 2006 07:54:49 -0500
  Sean Davis <sdavis2 at mail.nih.gov> wrote:
> Does using read.delim instead of read.table fix your 
>problem?
> 
> Sean
> 
> 
> On 2/22/06 7:40 AM, "I.Szentirmai" <I.Szentirmai at rug.nl> 
>wrote:
> 
>> Dear R users,
>> 
>> I'm trying to read data from a tab-delimited text file 
>>to
>> R, but I have problems with missing values. R gives this
>> kind of error messages: "line 1 did not have 9 
>>elements".
>> 
>> Could someone tell me how I can deal with missing values
>> in this case?
>> 
>> Thanks a lot in advance,
>> Istvan
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
> 
>



From gasper.cankar at ric.si  Wed Feb 22 14:12:04 2006
From: gasper.cankar at ric.si (Gasper Cankar)
Date: Wed, 22 Feb 2006 14:12:04 +0100
Subject: [R] issue with plot (type="h")
Message-ID: <C437AF9075F4E84E86D34CDA5252B8EB0B9A64@intra2003.ric.si>

Hello everyone.

For reasons too long to explain I wanted to do plots similar to histograms with plot(type="h"). 
I ran into a problem - if I set line width too high, histogram isn't accurate anymore.

For example:

par(lend=2)
plot(c(2,4,3,2),ylim=c(0,5), type="h")
abline(h=3)

Column 3 appears just as high as it should. But if I do

par(lend=2)
plot(c(2,4,3,2),ylim=c(0,5), type="h",lwd=100)
abline(h=3)

then columns become too high. Can I correct the problem or is there another way to display my data correctly?

Thanks for help,



Ga??per Cankar 
National Examinations Centre, 
Slovenia



From dingjia at gmail.com  Wed Feb 22 14:31:08 2006
From: dingjia at gmail.com (jia ding)
Date: Wed, 22 Feb 2006 14:31:08 +0100
Subject: [R] 2 barplots in the same graph
Message-ID: <91ae6e350602220531g7b562a30q7b382a23debc28f1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060222/894d0ea4/attachment.pl

From I.Szentirmai at rug.nl  Wed Feb 22 14:32:48 2006
From: I.Szentirmai at rug.nl (I.Szentirmai)
Date: Wed, 22 Feb 2006 14:32:48 +0100
Subject: [R] testing factor effects in glm
In-Reply-To: <14850601FF012647A90A5DB31F96DB374A30CB@INBLRDC01.BANG.irpvl.com>
References: <14850601FF012647A90A5DB31F96DB374A30CB@INBLRDC01.BANG.irpvl.com>
Message-ID: <web-16589601@mail3.rug.nl>

Dear All,

I'm using a glm to analyse the effect of year on a 
variable with poisson distribution. Using the summary() I 
can test whether years are different from each other, but 
how can I test whether year has an overall effect on my 
respons variable? My guess is that by a Wald-test, but I 
don't know how exactly.

Could someone give me advice?

Many thanks,
Istvan



From ripley at stats.ox.ac.uk  Wed Feb 22 14:53:53 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Feb 2006 13:53:53 +0000 (GMT)
Subject: [R] does multinomial logistic model from multinom (nnet) has
 logLik?
In-Reply-To: <38b9f0350602220436v514bc933i@mail.gmail.com>
References: <38b9f0350602220436v514bc933i@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602221351390.1081@gannet.stats.ox.ac.uk>

On Wed, 22 Feb 2006, ronggui wrote:

> I want to get the logLik to calculate McFadden.R2 ,ML.R2 and
> Cragg.Uhler.R2, but the value from multinom does not have logLik.So my
> quetion is : is logLik meaningful to multinomial logistic model from
> multinom?If it does, how can I get it?

>From the help page:

Value:

      A 'nnet' object with additional components:

deviance: the residual deviance.

So it has a residual deviance.  That is -2 log Lik in many cases (but not 
if the argument 'summ' is used)

> Thank you!
>
> ps: I konw  VGAM has function to get the multinomial logistic model
> with  logLik,  but I prefer use the function from "official" R
> packages .
>
> --
> ronggui
> Deparment of Sociology
> Fudan University

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sundar.dorai-raj at pdf.com  Wed Feb 22 15:11:41 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 22 Feb 2006 06:11:41 -0800
Subject: [R] issue with plot (type="h")
In-Reply-To: <C437AF9075F4E84E86D34CDA5252B8EB0B9A64@intra2003.ric.si>
References: <C437AF9075F4E84E86D34CDA5252B8EB0B9A64@intra2003.ric.si>
Message-ID: <43FC711D.2090202@pdf.com>



Gasper Cankar wrote:
> Hello everyone.
> 
> For reasons too long to explain I wanted to do plots similar to histograms with plot(type="h"). 
> I ran into a problem - if I set line width too high, histogram isn't accurate anymore.
> 
> For example:
> 
> par(lend=2)
> plot(c(2,4,3,2),ylim=c(0,5), type="h")
> abline(h=3)
> 
> Column 3 appears just as high as it should. But if I do
> 
> par(lend=2)
> plot(c(2,4,3,2),ylim=c(0,5), type="h",lwd=100)
> abline(h=3)
> 
> then columns become too high. Can I correct the problem or is there another way to display my data correctly?
> 

Try ?barplot instead:

bp <- barplot(c(2, 4, 3, 2), ylim = c(0, 5))
axis(side = 1, at = bp, labels = 1:4)
abline(h = 3)
box()

--sundar



From ronggui.huang at gmail.com  Wed Feb 22 15:12:37 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Wed, 22 Feb 2006 22:12:37 +0800
Subject: [R] does multinomial logistic model from multinom (nnet) has
	logLik?
In-Reply-To: <Pine.LNX.4.64.0602221351390.1081@gannet.stats.ox.ac.uk>
References: <38b9f0350602220436v514bc933i@mail.gmail.com>
	<Pine.LNX.4.64.0602221351390.1081@gannet.stats.ox.ac.uk>
Message-ID: <38b9f0350602220612u337f29d8k@mail.gmail.com>

So it's valid to get logLik (deviance/-2) when the summ argument is unused?

Thank you.

2006/2/22, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> On Wed, 22 Feb 2006, ronggui wrote:
>
> > I want to get the logLik to calculate McFadden.R2 ,ML.R2 and
> > Cragg.Uhler.R2, but the value from multinom does not have logLik.So my
> > quetion is : is logLik meaningful to multinomial logistic model from
> > multinom?If it does, how can I get it?
>
> From the help page:
>
> Value:
>
>       A 'nnet' object with additional components:
>
> deviance: the residual deviance.
>
> So it has a residual deviance.  That is -2 log Lik in many cases (but not
> if the argument 'summ' is used)
>
> > Thank you!
> >
> > ps: I konw  VGAM has function to get the multinomial logistic model
> > with  logLik,  but I prefer use the function from "official" R
> > packages .
> >
> > --
> > ronggui
> > Deparment of Sociology
> > Fudan University
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


--

Deparment of Sociology
Fudan University



From p.dalgaard at biostat.ku.dk  Wed Feb 22 15:14:50 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 22 Feb 2006 15:14:50 +0100
Subject: [R] issue with plot (type="h")
In-Reply-To: <C437AF9075F4E84E86D34CDA5252B8EB0B9A64@intra2003.ric.si>
References: <C437AF9075F4E84E86D34CDA5252B8EB0B9A64@intra2003.ric.si>
Message-ID: <x2u0ar1nvp.fsf@viggo.kubism.ku.dk>

"Gasper Cankar" <gasper.cankar at ric.si> writes:

> Hello everyone.
> 
> For reasons too long to explain I wanted to do plots similar to histograms with plot(type="h"). 
> I ran into a problem - if I set line width too high, histogram isn't accurate anymore.
> 
> For example:
> 
> par(lend=2)
> plot(c(2,4,3,2),ylim=c(0,5), type="h")
> abline(h=3)
> 
> Column 3 appears just as high as it should. But if I do
> 
> par(lend=2)
> plot(c(2,4,3,2),ylim=c(0,5), type="h",lwd=100)
> abline(h=3)
> 
> then columns become too high. Can I correct the problem or is there another way to display my data correctly?
> 
> Thanks for help,

lend=1 seems to cure it.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From bolker at zoo.ufl.edu  Wed Feb 22 15:20:00 2006
From: bolker at zoo.ufl.edu (Ben Bolker)
Date: Wed, 22 Feb 2006 14:20:00 +0000 (UTC)
Subject: [R] issue with plot (type="h")
References: <C437AF9075F4E84E86D34CDA5252B8EB0B9A64@intra2003.ric.si>
Message-ID: <loom.20060222T151633-5@post.gmane.org>

Gasper Cankar <gasper.cankar <at> ric.si> writes:

> 
> Hello everyone.
> 
> For reasons too long to explain I wanted to do plots similar to histograms
with plot(type="h"). 
> I ran into a problem - if I set line width too high, histogram isn't accurate
anymore.

 try par(lend=1) instead.  Far from obvious, but see
Paul Murrell's article in R News #2 of 2004

  cheers
     Ben



From alain.paquette at umontreal.ca  Wed Feb 22 15:23:00 2006
From: alain.paquette at umontreal.ca (Alain Paquette)
Date: Wed, 22 Feb 2006 09:23:00 -0500
Subject: [R] linear discriminant analysis in MASS
In-Reply-To: <Pine.LNX.4.64.0602210741531.30785@gannet.stats.ox.ac.uk>
References: <43FA4F14.1050607@umontreal.ca>
	<Pine.LNX.4.64.0602210741531.30785@gannet.stats.ox.ac.uk>
Message-ID: <43FC73C4.9050505@umontreal.ca>

Dear Prof. Ripley
I'm sorry about the confusion; this reply will simply avoid any humor 
attempts (good or bad).

About "S"
I'm sorry, as a "user" I was not aware of any "S" still existing outside 
of s-plus or R.  So your right, the procedure I was referring to was 
conducted on s-plus.  I used the GUI to construct the analysis, so I 
really don't know if the discrim() procedure I copied from the "command" 
window is accurate.  But when I re-run the analysis with that as the 
command line, I get the same results.  And it does provide a matrix of 
Mahalanobis distances between groups and a test of their significance 
(Hotelling's T Squared for Differences in Means Between Each Group).

About the credits
My data set is on JMP (SAS).  It's great at manipulating and exploring 
data sets.  The software does allow for many analysis types too, so my 
very first discriminant analysis was actually on JMP.  But like many GUI 
softwares, it lacks options.  JMP approaches the distance problem by 
drawing 95% confidence interval spheres around group means.  Thats very 
nice (although it doesn't account for multiple comparisons) for LDA 
problems with few groups, but I have 12 so it became messy 
(graphically).  Besides, I have the - I think very healthy - problem of 
never trusting just one software, especially the black box type, for my 
analysis.

I was also accumulating literature on the subject (ecophysiology of 
trees, not statistics!) and I came across this paper

Delagrange, S., Messier, C., Lechowicz, M.J. and Dizengremel, P. 2004. 
Physiological, morphological and allocational plasticity in understory 
deciduous trees: importance of plant size and light availability. Tree 
Physiol. 24(7): 775-784.

which presented a test on Mahalanobis distances from LDA analysis.  Now 
they used SAS (CAN-DISC with the ANOVA option) for their analysis.  I 
tried it on R (lda in MASS and discrimin in ade4), without success (I 
get the discriminant analysis, but not the test).  So I tried it on 
S-PLUS, and voil??!  You could say that actually my first encounter with 
the procedure was with SAS, then on R, and only then on S-PLUS.

I use the "vegan" package a lot for permutational statistics, as well as 
code developed at Pierre Legendre's lab, and I cite them accordingly, 
just like I believe I did with lda in MASS in the present e-mail.  
Thanks for your advice on multiple comparisons and normality.  By the 
way, the s-plus procedure also outputs normality and co-variance tests.  
I do have multiple normality, but for now (!), I have covariance 
heterogeneity.   I was of course planning on a Dunn-Sidak correction for 
multiple comparisons.

Thank you for the quick reply,
Alain


Prof Brian Ripley a ??crit :
> On Mon, 20 Feb 2006, Alain Paquette wrote:
>
>> Hello R people
>>
>> I now know how to run my discriminant analysis with the lda function in
>> MASS:
>> lda.alain=lda(Groupes ~ Ht.D0 + Lc.Dc + Ram + IDF, gr, CV = FALSE)
>> and it works fine.
>
> CV=FALSE is the default and so not needed.
>
>> But I am missing a test and cannot find any help on how to get it, if it
>> exist.
>>
>> The "S" equivalent:
>
> There is no such function in S, and I rather object as the S 
> equivalent is lda() (and as the author of both I should know).  Credit 
> where credit is due: discrim() is an S-PLUS function, indebted to lda().
>
>> discrim(structure(.Data = Groupes ~ Ht.D0 + Lc.Dc + Ram + IDF, class =
>> "formula"), data = gr, family = Canonical(cov.structure =
>> "homoscedastic"), na.action = na.omit, prior = "proportional")
>> outputs a nice matrix of Mahalanobis distances between groups and even
>> tests (Hotelling's T Squared) for significant distances.
>
> Well, it seems not to.  That is part of the output of the summary() 
> method, which itself calls the multicomp() method.
>
>> Why don't I just take the "S" output you say?  Because like you, I'd
>> rather put in my paper that I did it using R of course!
>
> No `of course' applies. If you learnt of this output from S-PLUS, I 
> urge you to credit it honestly and accurately.  (If you refer to lda, 
> you should credit that, not just R.)
>
>> Does anyone know of a way to get this test out of lda?  Or of another R
>> package that does it?
>
> Mahalanobis distance between groups is easy, as this is just Euclidean 
> distance between group centres in the scaled space.  The test 
> statistics can be produced, but
>
> - they are critically dependent on the unrealistic assumptions of 
> multivariate normality and variance homogeneity and
>
> - there needs to be an adjustment for multiple comparisons.
>

-- 
Alain Paquette
Laboratoire d'??cologie v??g??tale
Institut de recherche en biologie v??g??tale
Universit?? de Montr??al
4101 rue Sherbrooke Est
Montr??al (Qu??bec) H1X 2B2
 
alain.paquette at umontreal.ca
labo (514) 872-8488
fax (514) 872-9406
http://www.irbv.umontreal.ca/francais/personnel/cogliastro-paquette.htm



From Manuel.A.Morales at williams.edu  Wed Feb 22 15:31:21 2006
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Wed, 22 Feb 2006 09:31:21 -0500
Subject: [R] issue with plot (type="h")
In-Reply-To: <C437AF9075F4E84E86D34CDA5252B8EB0B9A64@intra2003.ric.si>
References: <C437AF9075F4E84E86D34CDA5252B8EB0B9A64@intra2003.ric.si>
Message-ID: <1140618681.3020.4.camel@localhost.localdomain>

Hi Gaper

On Wed, 2006-02-22 at 14:12 +0100, Gasper Cankar wrote:
> Hello everyone.
> 
> For reasons too long to explain I wanted to do plots similar to histograms with plot(type="h"). 
> I ran into a problem - if I set line width too high, histogram isn't accurate anymore.
> 
> For example:
> 
> par(lend=2)
> plot(c(2,4,3,2),ylim=c(0,5), type="h")
> abline(h=3)
> 
> Column 3 appears just as high as it should. But if I do
> 
> par(lend=2)
> plot(c(2,4,3,2),ylim=c(0,5), type="h",lwd=100)
> abline(h=3)
> 
> then columns become too high. Can I correct the problem or is there another way to display my data correctly?

You need to use lend=1 or lend="butt" in your par() statement.

In my view, it would be nice to change the default to use lend=1 for
plot type = h, or at least to include a warning when square is used,
since the effect of increasing the lwd may not always be obvious.



From Manuel.A.Morales at williams.edu  Wed Feb 22 15:33:30 2006
From: Manuel.A.Morales at williams.edu (Manuel Morales)
Date: Wed, 22 Feb 2006 09:33:30 -0500
Subject: [R] R xyplot and background color
In-Reply-To: <20060221204927.99555.qmail@web33802.mail.mud.yahoo.com>
References: <20060221204927.99555.qmail@web33802.mail.mud.yahoo.com>
Message-ID: <1140618811.3020.6.camel@localhost.localdomain>

On Tue, 2006-02-21 at 12:49 -0800, Bryan Sykes wrote:
> Hi:
> 
> I have tried (unsuccessfully) to change the default
> background color for my xyplot.  I have used
> trellis.device(bg = "white", new = F) and
> par(bg="white") before my xyplot command.  Yet the
> color of the background has not changed.  Is there
> something else I need to do?  I am using a windows
> based machine to do this.

Try xyplot(..., par.settings=list(background="white"))

HTH,

Manuel



From bates at stat.wisc.edu  Wed Feb 22 15:35:11 2006
From: bates at stat.wisc.edu (Douglas Bates)
Date: Wed, 22 Feb 2006 08:35:11 -0600
Subject: [R] Extracting variance components from lmer
In-Reply-To: <17403.17352.580263.116693@stat.math.ethz.ch>
References: <c3cb73d50602200657x591409e9x4f04cbdedfcdaff8@mail.gmail.com>
	<17403.17352.580263.116693@stat.math.ethz.ch>
Message-ID: <40e66e0b0602220635h504bffabxd7da758caac82c55@mail.gmail.com>

On 2/21/06, Christoph Buser <buser at stat.math.ethz.ch> wrote:
> Hi Rick
>
> There may be a better way, but the following should work:
>
> attributes(vc.fit)$sc

That works but a more direct way would be

attr(vc.fit, "sc")

By the way,  that value is the estimated standard deviation not the
estimated variance.

>
> Regards,
>
> Christoph Buser
>
> --------------------------------------------------------------
> Christoph Buser <buser at stat.math.ethz.ch>
> Seminar fuer Statistik, LEO C13
> ETH (Federal Inst. Technology)  8092 Zurich      SWITZERLAND
> phone: x-41-44-632-4673         fax: 632-1228
> http://stat.ethz.ch/~buser/
> --------------------------------------------------------------
>
>
> Rick DeShon writes:
>  > Hi All.
>  >
>  > I need a bit of help extracting the residual error variance from the VarCorr
>  > structure from lmer.
>  >
>  > #Here's a 2-way random effects model
>  > lmer.1    <- lmer(rating ~ (1|person)+(1|rater), data = dat)
>  >
>  > #Get the structure
>  > vc.fit <- VarCorr(lmer.1)
>  >
>  > #results in.....
>  > $person
>  > 1 x 1 Matrix of class "dpoMatrix"
>  >             (Intercept)
>  > (Intercept)   0.7755392
>  >
>  > $rater
>  > 1 x 1 Matrix of class "dpoMatrix"
>  >             (Intercept)
>  > (Intercept)   0.2054469
>  >
>  > attr(,"sc")
>  > [1] 0.5051518
>  >
>  > #I can pull out the person and rater variance components easy enough. For
>  > example...
>  > vc.person <- vc.fit$person at x
>  >
>  > I'm sure it's simple but I have not been able to grab the residual variance
>  > in the last matrix.  I simply wish to asign the residual to a scalar
>  > variable.  Any suggestions would be appreciated!
>  >
>  > Thanks!
>  >
>  > Rick DeShon
>  >
>  >
>  > --
>  > Rick DeShon
>  > 306 Psychology Building
>  > Department of Psychology
>  > Michigan State University
>  > East Lansing, MI 48824-1116
>  >
>  >      [[alternative HTML version deleted]]
>  >
>  > ______________________________________________
>  > R-help at stat.math.ethz.ch mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From rbaer at atsu.edu  Wed Feb 22 15:38:42 2006
From: rbaer at atsu.edu (Robert Baer)
Date: Wed, 22 Feb 2006 08:38:42 -0600
Subject: [R] 2 barplots in the same graph
References: <91ae6e350602220531g7b562a30q7b382a23debc28f1@mail.gmail.com>
Message-ID: <00cd01c637bd$adf32ea0$a00c010a@BigBaer>

See ?barplot

If I understand what you want, try:

barplot(x1,border="red",density=0)
par(new=TRUE)
barplot(x2,border="green",density=0)

Rob
____________________________
Robert W. Baer, Ph.D.
Associate Professor
Department of Physiology
A. T. Still University of Health Science
800 W. Jefferson St.
Kirksville, MO 63501-1497 USA
----- Original Message ----- 
From: "jia ding" <dingjia at gmail.com>
To: "R-help" <r-help at stat.math.ethz.ch>
Sent: Wednesday, February 22, 2006 7:31 AM
Subject: [R] 2 barplots in the same graph


> Hello,
>
> I have a very simple question about "2 barplots in the same graph".
>
> It seems quite easy, but I searched google for long time, haven't find
> solution.
>
> For example, I want one graph like:
> x1=seq(0,2,by=0.3)
> x2=seq(3,0,by=-0.1)
> barplot(x1,col="red")
> barplot(x2,col="green")
>
> It means if it's on the same graph, some bars are overlaped.
> So if the bars are hollow, instead of filled with color, it will be
better.
>
> Actually, I think it's something similar with matlab's "hold on" command.
>
> Thanks!
>
> Nina
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>



From jfox at mcmaster.ca  Wed Feb 22 15:45:41 2006
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 22 Feb 2006 09:45:41 -0500
Subject: [R] does multinomial logistic model from multinom (nnet) has
	logLik?
In-Reply-To: <38b9f0350602220436v514bc933i@mail.gmail.com>
Message-ID: <20060222144540.XSNR28670.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear ronggui,

You could use deviance().

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of ronggui
> Sent: Wednesday, February 22, 2006 7:36 AM
> To: r-help help
> Subject: [R] does multinomial logistic model from multinom 
> (nnet) has logLik?
> 
> I want to get the logLik to calculate McFadden.R2 ,ML.R2 and 
> Cragg.Uhler.R2, but the value from multinom does not have 
> logLik.So my quetion is : is logLik meaningful to multinomial 
> logistic model from multinom?If it does, how can I get it?
> 
> Thank you!
> 
> ps: I konw  VGAM has function to get the multinomial logistic 
> model with  logLik,  but I prefer use the function from 
> "official" R packages .
> 
> --
> ronggui
> Deparment of Sociology
> Fudan University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From MMcIntosh at kvpharmaceutical.com  Wed Feb 22 15:40:04 2006
From: MMcIntosh at kvpharmaceutical.com (MMcIntosh@kvpharmaceutical.com)
Date: Wed, 22 Feb 2006 08:40:04 -0600
Subject: [R] read.table missing values
Message-ID: <03C1DDD7C6E26C4EBB28BF16DEE302BC040F3297@kvmail1.kv.kvph.dom>

I have experienced a similar problem when saving Excel data in this
format.  When any of the variables, except the last, contained missing
values, there was not a problem.  However, the problem occurred when the
last variable contained missing values.  My guess is that the last
delimiter was left off?  The "fill" option worked in my case.  Use the
option with care and double check the dataset.

HTH
Matthew McIntosh



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of I.Szentirmai
Sent: Wednesday, February 22, 2006 7:04 AM
To: r-help
Subject: Re: [R] read.table missing values

might be, but I have already found another solution: 
reat.table(file,sep="\t")

Thanks,
Istvan



On Wed, 22 Feb 2006 07:54:49 -0500
  Sean Davis <sdavis2 at mail.nih.gov> wrote:
> Does using read.delim instead of read.table fix your 
>problem?
> 
> Sean
> 
> 
> On 2/22/06 7:40 AM, "I.Szentirmai" <I.Szentirmai at rug.nl> 
>wrote:
> 
>> Dear R users,
>> 
>> I'm trying to read data from a tab-delimited text file 
>>to
>> R, but I have problems with missing values. R gives this
>> kind of error messages: "line 1 did not have 9 
>>elements".
>> 
>> Could someone tell me how I can deal with missing values
>> in this case?
>> 
>> Thanks a lot in advance,
>> Istvan
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
> 
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ronggui.huang at gmail.com  Wed Feb 22 15:50:51 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Wed, 22 Feb 2006 22:50:51 +0800
Subject: [R] does multinomial logistic model from multinom (nnet) has
	logLik?
In-Reply-To: <38b9f0350602220612u337f29d8k@mail.gmail.com>
References: <38b9f0350602220436v514bc933i@mail.gmail.com>
	<Pine.LNX.4.64.0602221351390.1081@gannet.stats.ox.ac.uk>
	<38b9f0350602220612u337f29d8k@mail.gmail.com>
Message-ID: <38b9f0350602220650g5765ca1dq@mail.gmail.com>

Here is a function for calculating  the measures of fit for
multinomial logistic model (using nnet::multinom).If anything wrong ,I
hope  experts point it out.Thank you.

fitstat <- function(object) {
#thanks Ripley, B. D. for telling how to get the LogLik and when is invalid.
{if (!is.null(object$call$summ) && !identical(object$call$summ,0))
   stop("when 'summ' argument is not zero,can NOT get Loglik") }
object.base <- update(object,.~1,trace=FALSE)
dev.base <- deviance(object.base) ; L.base <- - dev.base/2
dev.full <- deviance(object) ; L.full <- - dev.full/2
G2 <- dev.base - dev.full
df <- object$edf - object.base$edf
LR.test.p <- pchisq(G2,df,lower=F)

aic <- object$AIC

n<-dim(object$residuals)[1]

#get the predict value to cal count R2
pre <- predict(object,type="class")
y <- eval.parent(object$call$data)[,as.character(object$call$formula[[2]])]
if (!identical(length(y),length(pre))) stop("Length not matched.")
tab <- table(y,pre)
if (!identical(dim(tab)[1],dim(tab)[2])) stop("pred and y have diff nlevels")
ad <- max(rowSums(tab))#max of row sum

#cal R2
ML.R2 <- 1-exp(-G2/n)
McFadden.R2 <- 1-(L.full/L.base)
McFadden.Adj.R2 <- 1-((L.full-mod$edf)/L.base)
Cragg.Uhler.R2 <- ML.R2/(1-exp(2*L.base/n))
Count.R2 <- sum(diag(tab))/sum(tab)
Count.adj.R2 <- (sum(diag(tab))-ad)/(sum(tab)-ad)

#get the result
res<-list(LR=G2,df=df,LR.test.p =LR.test.p
,aic=aic,ML.R2=ML.R2,Cragg.Uhler.R2=Cragg.Uhler.R2,McFadden.R2
=McFadden.R2 ,McFadden.Adj.R2=McFadden.Adj.R2,Count.R2=Count.R2,Count.adj.R2=Count.adj.R2)

#print the result
cat("\n",
    paste(rep("-",21)),
    "\n The Fitstats are : \n",
    sprintf("G2(%d) = %f",df,G2),
    " ,Prob ",format.pval(LR.test.p),
    "\n",sprintf("AIC   = %f",aic),
    sprintf(",ML.R2 = %f \n",ML.R2),
    paste(rep("-",21)),"\n",
    sprintf("Cragg.Uhler.R2  = %f \n",Cragg.Uhler.R2),
    sprintf("McFadden.R2     = %f \n",McFadden.R2),
    sprintf("McFadden.Adj.R2 = %f \n",McFadden.Adj.R2),
    sprintf("Count.R2        = %f \n",Count.R2),
    sprintf("Count.adj.R2    = %f \n",Count.adj.R2),
    "\n Note:The maxinum of ML R2 is less than 1 \n",
    paste(rep("-",21)),"\n")
invisible(res)
}

#example
require(nnet)
data(mexico,package="Zelig")
mod <- multinom(vote88 ~ pristr + othcok + othsocok,mexico)
summary(mod,cor=F)
fitstat(mod)

#reference:
#J. SCOTT LONG and JEREMY FREESE,REGRESSION MODELS FOR CATEGORICAL
DEPENDENT VARIABLES USING STATA.

> fitstat(mod)

 - - - - - - - - - - - - - - - - - - - - -
 The Fitstats are :
 G2(6) = 381.351620  ,Prob  < 2.22e-16
 AIC   = 2376.571142 ,ML.R2 = 0.244679
 - - - - - - - - - - - - - - - - - - - - -
 Cragg.Uhler.R2  = 0.282204
 McFadden.R2     = 0.139082
 McFadden.Adj.R2 = 0.133247
 Count.R2        = 0.596026
 Count.adj.R2    = 0.123003

 Note:The maxinum of ML R2 is less than 1
 - - - - - - - - - - - - - - - - - - - - -

 06-2-22ronggui<ronggui.huang at gmail.com> 
> So it's valid to get logLik (deviance/-2) when the summ argument is unused?
>
> Thank you.
>
> 2006/2/22, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> > On Wed, 22 Feb 2006, ronggui wrote:
> >
> > > I want to get the logLik to calculate McFadden.R2 ,ML.R2 and
> > > Cragg.Uhler.R2, but the value from multinom does not have logLik.So my
> > > quetion is : is logLik meaningful to multinomial logistic model from
> > > multinom?If it does, how can I get it?
> >
> > From the help page:
> >
> > Value:
> >
> >       A 'nnet' object with additional components:
> >
> > deviance: the residual deviance.
> >
> > So it has a residual deviance.  That is -2 log Lik in many cases (but not
> > if the argument 'summ' is used)
> >
> > > Thank you!
> > >
> > > ps: I konw  VGAM has function to get the multinomial logistic model
> > > with  logLik,  but I prefer use the function from "official" R
> > > packages .
> > >
> > > --
> > > ronggui
> > > Deparment of Sociology
> > > Fudan University
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
>
>
> --
> 
> Deparment of Sociology
> Fudan University
>


--
ronggui
Deparment of Sociology
Fudan University



From tom at maladmin.com  Wed Feb 22 11:14:25 2006
From: tom at maladmin.com (tom wright)
Date: Wed, 22 Feb 2006 05:14:25 -0500
Subject: [R] exponent confusion
Message-ID: <1140603265.25774.27.camel@localhost.localdomain>

please excuse me if this ones a basic error

> y<-c(-0.7,-0.6,-0.5)
> -0.7^1.22
[1] -0.6471718

> y^1.22
[1] NaN NaN NaN

am I missing something important in my basic math?



From petr.pikal at precheza.cz  Wed Feb 22 16:24:04 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 22 Feb 2006 16:24:04 +0100
Subject: [R] How to Import Data
In-Reply-To: <s3fad4d1.087@isugw.indstate.edu>
Message-ID: <43FC9024.4630.2202DB1@localhost>

If you do not want to use csv file transfer you can:

Open Excel
select data
Ctrl-C
Open R
your.data <- read.delim("clipboard")

will transfer clipboard contents of clipboard into your.data.

HTH
Petr



On 21 Feb 2006 at 8:52, Carl Klarner wrote:

Date sent:      	Tue, 21 Feb 2006 08:52:04 -0500
From:           	"Carl Klarner" <cklarner at isugw.indstate.edu>
To:             	<r-help at stat.math.ethz.ch>
Subject:        	[R] How to Import Data

> Hello,
> I am a very new user of R.  I've spent several hours trying to import
> data, so I feel okay asking the list for help.  I had an Excel file,
> then I turned it into a "csv" file, as instructed by directions.  My
> filename is "x111.csv."  I then used the following commands to read
> this (fairly small) dataset in.  
> 
> x111 <-read.table(file='x111.csv',
> sep="",header=T,
> quote="",comment.char="",as.is=T)
> 
> I then get the following error message.
> 
> Error in file(file, "r") : unable to open connection
> In addition: Warning message:
> cannot open file 'x111.csv', reason 'No such file or directory'
> 
> I would imagine I'm not putting my csv file in the right location for
> R to be able to read it.  If that's the case, where should I put it? 
> Or is there something else I need to do to it first? Thanks for your
> help, Carl
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From blatny at biomed.cas.cz  Wed Feb 22 16:30:41 2006
From: blatny at biomed.cas.cz (Radek Blatny)
Date: Wed, 22 Feb 2006 16:30:41 +0100
Subject: [R] warning when installing package
Message-ID: <F30531BE-6F08-49CF-8CF1-2E6DFED22B91@biomed.cas.cz>

Hello,
I have R for Mac OS X Aqua GUI Version 1.14 with R 2.2.0 Framework. I  
got following warnings when installing "qtl" package 1.01-9 from CRAN 
(sources) on the austrian mirror:

warning 1:

ld: warning multiple definitions of symbol _signgam
/Library/Frameworks/R.framework/../R.framework/R(lgamma.lo)  
definition of _signgam
/usr/lib/libSystem.dylib(gamma9.o) definition of _signgam

warning 2:

perl: warning: Setting locale failed.
perl: warning: Please check that your locale settings:
	LC_ALL = (unset),
	LANG = "en_CZ.UTF-8"
     are supported and installed on your system.
perl: warning: Falling back to the standard locale ("C").

warning 3:

chmod: /Library/Frameworks/R.framework/Versions/2.2/Resources/library/ 
R.css: Operation not permitted

Two of them - warnings 2 and 3 - I get quite often, also with other  
packages, they seem to be a systemic problem. Any suggestions? Thank  
you much.

Regards, Radek

Radek Blatny, MSc.
Institute of Molecular Genetics
Department of Mouse Molecular Genetics (Jiri Forejt unit)
Czech Academy of Sciences
Videnska 1083
142 20, Prague
Czech Republic
Tel. (+420) 241 062 256
Fax (+420) 241 062 154
http://www.img.cas.cz/mmg
email: blatny at biomed.cas.cz
Skype name: blatny



From farewelld at Cardiff.ac.uk  Wed Feb 22 16:35:03 2006
From: farewelld at Cardiff.ac.uk (Daniel Farewell)
Date: Wed, 22 Feb 2006 15:35:03 +0000
Subject: [R] unused factor levels in reshape
Message-ID: <s3fc84c0.018@ZGRW21.uwcm.ac.uk>

When reshaping a dataframe in which there are unused factor levels in the id variable, I get the following error:

Error in if (!all(really.constant)) warning(gettextf("some constant variables (%s) are really varying",  : 
        missing value where TRUE/FALSE needed

For example,

> df <- data.frame(i = factor(rep(1:5, each = 2)), t = factor(rep(1:2, 5)), x = rep(rbinom(5, 1, 0.5), each = 2), y = rpois(10, 10))

> subdf <- subset(df, i %in% 1:3)

defines a dataframe, and a subframe with some unused factor levels (i = 4, 5). Then

> reshape(df, v.names = "y", timevar = "t", idvar = "i", direction = "wide")
  i x y.1 y.2
1 1 0  13   6
3 2 0  12   5
5 3 0  10   9
7 4 1   9  11
9 5 1  12   8

works fine but

> reshape(subdf, v.names = "y", timevar = "t", idvar = "i", direction = "wide")
Error in if (!all(really.constant)) warning(gettextf("some constant variables (%s) are really varying",  : 
        missing value where TRUE/FALSE needed

produces the error, which happens during the check to see if the variables assumed constant are constant. The problem is that reshape searches over all the levels of the id variable (i in this case) to see if the other variables (here x) are constant. But there is no x associated with i = 4, 5 in the smaller dataframe, so

> tapply(subdf$x, subdf$i, function(x) length(unique(x)) == 1)
   1    2    3    4    5 
TRUE TRUE TRUE   NA   NA

produces some NAs. A slight change to the reshape code to work around this problem would be to use (the equivalent of)

> tapply(subdf$x, subdf$i[, drop = TRUE], function(x) length(unique(x)) == 1)
   1    2    3 
TRUE TRUE TRUE

in the reshapeWide function within reshape, but perhaps there is a good reason not to do this?

Daniel



From tlumley at u.washington.edu  Wed Feb 22 16:48:09 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 22 Feb 2006 07:48:09 -0800 (PST)
Subject: [R] testing factor effects in glm
In-Reply-To: <web-16589601@mail3.rug.nl>
References: <14850601FF012647A90A5DB31F96DB374A30CB@INBLRDC01.BANG.irpvl.com>
	<web-16589601@mail3.rug.nl>
Message-ID: <Pine.LNX.4.64.0602220747020.12487@homer23.u.washington.edu>

On Wed, 22 Feb 2006, I.Szentirmai wrote:

> Dear All,
>
> I'm using a glm to analyse the effect of year on a
> variable with poisson distribution. Using the summary() I
> can test whether years are different from each other, but
> how can I test whether year has an overall effect on my
> respons variable? My guess is that by a Wald-test, but I
> don't know how exactly.
>

You can get a likelihood ratio test by also fitting a model without year 
and using anova() to compare the two models.

I think multiple people have written wald test functions. Mine is 
regTermTest in the "survey" package.

 	-thomas



From mschwartz at mn.rr.com  Wed Feb 22 16:57:01 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Wed, 22 Feb 2006 09:57:01 -0600
Subject: [R] 2 barplots in the same graph
In-Reply-To: <91ae6e350602220531g7b562a30q7b382a23debc28f1@mail.gmail.com>
References: <91ae6e350602220531g7b562a30q7b382a23debc28f1@mail.gmail.com>
Message-ID: <1140623821.4483.6.camel@localhost.localdomain>

On Wed, 2006-02-22 at 14:31 +0100, jia ding wrote:
> Hello,
> 
> I have a very simple question about "2 barplots in the same graph".
> 
> It seems quite easy, but I searched google for long time, haven't find
> solution.
> 
> For example, I want one graph like:
> x1=seq(0,2,by=0.3)
> x2=seq(3,0,by=-0.1)
> barplot(x1,col="red")
> barplot(x2,col="green")
> 
> It means if it's on the same graph, some bars are overlaped.
> So if the bars are hollow, instead of filled with color, it will be better.
> 
> Actually, I think it's something similar with matlab's "hold on" command.
> 
> Thanks!
> 
> Nina


I may be misinterpreting your question, but do you want something like
this?

 x1 <- seq(0, 2, by = 0.3)
 x2 <- seq(3, 0, by = -0.1)

 # Set bar fill to white, border to green
 barplot(x2, col = "white", border ="green")

 # Set bar fill to white, border to red and add to prior plot
 barplot(x1, col = "white", border = "red", add = TRUE)


See the 'add' and 'border' arguments in ?barplot.


HTH,

Marc Schwartz



From elsawy at ysbl.york.ac.uk  Wed Feb 22 17:14:29 2006
From: elsawy at ysbl.york.ac.uk (Karim Elsawy)
Date: Wed, 22 Feb 2006 16:14:29 +0000
Subject: [R] ylim in dendrogram plot ... error
Message-ID: <43FC8DE5.9070108@ysbl.york.ac.uk>

I'm trying to plot a dendrogram object which is created using 
"as.dendogram" function. It works fine however I can not change the 
yaxis limits of the plot.


   tree<-as.dendrogram(hclust(as.dist(dissim),method="single"))
   plot(tree,ylim=range(0,20))
   Error in plot.default(0, xlim = xlim, ylim = ylim, type = "n", xlab =
   xlab,  :
         formal argument "ylim" matched by multiple actual arguments


This is imporatant for getting a consistant scale for different trees 
plotted side by side

your help is very much appreciated
Karim



From gunter.berton at gene.com  Wed Feb 22 17:23:26 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 22 Feb 2006 08:23:26 -0800
Subject: [R] How to get around heteroscedasticity with
	non-linear	leastsquares in R?
In-Reply-To: <43FC3BC802000006002A3384@gwia.kvl.dk>
Message-ID: <001e01c637cc$4fb33b00$711f210a@gne.windows.gene.com>

And an added US$.02 is that the raw response (optical density, counts (large
numbers) of radio decay, fluorescence units, etc.) in dose response curves
often varies over several orders of magnitude, so that, in conformance to
John Tukey's "First Aid" suggestions, a log transformation or something
similar is often a standard prescription for fitting dose/response curves
(with the usual handwringing about whether the error is additive or
multiplicative; there is typically  some of both, as David Rocke's papers of
a decade or more ago argue).

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Christian Ritz
> Sent: Wednesday, February 22, 2006 1:22 AM
> To: quin.wills at googlemail.com
> Cc: r-help at stat.math.ethz.ch; p.dalgaard at biostat.ku.dk
> Subject: Re: [R] How to get around heteroscedasticity with 
> non-linear leastsquares in R?
> 
> Hi Quin,
> 
> the package 'drc' on CRAN deals with modelling dose-response curves.
> 
> Moreover it allows adjustment for heterogeneity by means of 
> 
> 
>   transformation (Box-Cox transformation)
> 
>   modelling the variance as a power of the mean.
> 
> 
> See the package documentation for more features.
> 
> 
> Christian
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Wed Feb 22 17:24:10 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 22 Feb 2006 11:24:10 -0500
Subject: [R] 2 barplots in the same graph
In-Reply-To: <91ae6e350602220531g7b562a30q7b382a23debc28f1@mail.gmail.com>
References: <91ae6e350602220531g7b562a30q7b382a23debc28f1@mail.gmail.com>
Message-ID: <971536df0602220824y6f3e1a8eo6b5cc041250cf097@mail.gmail.com>

The barplot solution already presented is probably what you want
but just in case here is a zoo solution:

library(zoo)
z <- merge(zoo(x2), zoo(x1, seq(x1)+.5))
plot(z, type = "h", plot.type = "single", col = 1:2, lwd = 5)

Or a similar solution without zoo:
 plot(c(x1, x2) ~ c(seq(x1)+.5, seq(x2)),
  col = c(1+0*x1, 2+0*x2), type = "h", lwd = 5)


On 2/22/06, jia ding <dingjia at gmail.com> wrote:
> Hello,
>
> I have a very simple question about "2 barplots in the same graph".
>
> It seems quite easy, but I searched google for long time, haven't find
> solution.
>
> For example, I want one graph like:
> x1=seq(0,2,by=0.3)
> x2=seq(3,0,by=-0.1)
> barplot(x1,col="red")
> barplot(x2,col="green")
>
> It means if it's on the same graph, some bars are overlaped.
> So if the bars are hollow, instead of filled with color, it will be better.
>
> Actually, I think it's something similar with matlab's "hold on" command.
>
> Thanks!
>
> Nina
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Wed Feb 22 17:51:54 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Feb 2006 16:51:54 +0000 (GMT)
Subject: [R] exponent confusion
In-Reply-To: <1140603265.25774.27.camel@localhost.localdomain>
References: <1140603265.25774.27.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.64.0602221650140.5943@gannet.stats.ox.ac.uk>

On Wed, 22 Feb 2006, tom wright wrote:

> please excuse me if this ones a basic error
>
>> y<-c(-0.7,-0.6,-0.5)
>> -0.7^1.22
> [1] -0.6471718

?Syntax shows ^ has a higher precedance than -, so that is

-(0.7^1.22)

>
>> y^1.22
> [1] NaN NaN NaN
>
> am I missing something important in my basic math?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Ted.Harding at nessie.mcc.ac.uk  Wed Feb 22 17:59:19 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 22 Feb 2006 16:59:19 -0000 (GMT)
Subject: [R] exponent confusion
In-Reply-To: <1140603265.25774.27.camel@localhost.localdomain>
Message-ID: <XFMail.060222165919.Ted.Harding@nessie.mcc.ac.uk>

On 22-Feb-06 tom wright wrote:
> please excuse me if this ones a basic error
> 
>> y<-c(-0.7,-0.6,-0.5)
>> -0.7^1.22
> [1] -0.6471718
> 
>> y^1.22
> [1] NaN NaN NaN
> 
> am I missing something important in my basic math?

Ummm, not sure ... it depends where the explanation fits in.
It's certainly important, but whether it's "basic math" is
another question. And you're certainly missing it!

See

?Syntax

which outputs (initally)

 The following unary and binary operators are defined.  They are
     listed in precedence groups, from highest to lowest.

       '[ [['             indexing
       '::'               name space/variable name separator
       '$ @'              component / slot extraction
       '^'                exponentiation (right to left)
       '- +'              unary minus and plus
       ':'                sequence operator
       '%any%'            special operators
       '* /'              multiply, divide
       '+ -'              (binary) add, subtract
       '< > <= >= == !='  ordering and comparison
       '!'                negation
       '&  &&'            and
       '| ||'             or
       '~'                as in formulae
       '-> ->>'           rightwards assignment
       '='                assignment (right to left)
       '<- <<-'           assignment (right to left)
       '?'                help (unary and binary)

     Within an expression operators of equal precedence are evaluated
     from left to right except where indicated.

Therefore the binary unary operator "^" has precedence over the
unary (sign) operator "-" .

Hence your expression

  -0.7^1.22

is evaluated as

  -(0.7^1.22)

i.e. first do 0.7^1.22, then apply "-".

On the other hand, once you have created

  y<-c(-0.7,-0.6,-0.5)

then each element is already a negative number before you do
anything with it. Hence

  y^1.22 = c( (-0.7)^1.22, (-0.6)^1.22, (-0.5)^1.22 )
         = c(NaN, NaN, NaN)

As an alternative example, unary "-" has precedence over
binary "+" or "-", so that -2+3 is not -(2+3) = 5 but
(-2) + 3 (first apply unary "-", then do binary "+").

Computer languages always embody precedence rules such
as the above to resolve ambiguites in expressions such
as "-a^b" written without parenetheses; but then, in order
to get what you want you need to know the rules in order
to write such expressions correctly.

When in doubt use paraentheses!

A case which has often trapped  people in R (see many
places in the r-help archive) is a sequence expression
such as

  a<-1
  b<-10
  (a:b-1)

which for many is an optical illusion tempting them to
think it is a:(b-1) whereas is is in fact (a:b)-1, i.e.

  0, 1, 2, 3, 4, 5, 6, 7, 8, 9

and not

  1, 2, 3, 4, 5, 6, 7, 8, 9

(see the precedences of binary "-" and the sequence
operator ":" above -- i.e. first do ":" and then the
binary "-").

In cases like this it really is worth while writing
the parantheses:

  (a:b)-1   or   a:(b-1)

according to which you mean, since (a:b-1) really is
visually deceptive.

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 22-Feb-06                                       Time: 16:59:17
------------------------------ XFMail ------------------------------



From kevin.thorpe at utoronto.ca  Wed Feb 22 17:57:16 2006
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Wed, 22 Feb 2006 11:57:16 -0500
Subject: [R] OT Futility Analysis
In-Reply-To: <20060222094741625.00000002680@K01391008F6W51J>
References: <20060222094741625.00000002680@K01391008F6W51J>
Message-ID: <43FC97EC.3030803@utoronto.ca>

Thank you Spencer and Steve for your helpful comments.  If I may, I
would like to elaborate on some of the points you raise.

Stephen A Roberts wrote:
> I would take the line that if they hadn't pre-specified any stopping
> rules, the only reason to stop is safety or new external data. I
> would be very suspicious of requests from the steering committee to
> stop for futility - they should be blinded so why are they thinking
> futility unless results have leaked? I would argue that they are
> obliged to finish the trial once they start.

In general I agree with this.  In this case the request for a futility
analysis came from the sponsor (a drug company).  It is a classic case
of company B buys company A and wnats to stop R&D on company A's drugs.
Therefore the company was looking for a reason to stop.  Now that they
will stop producing the drug used in the trial, recruitment will end
before reaching its target.  Now the Steering Committee's point of
view is that if there is any reasonable hope, they would find some
other way to continue recruitment.  I am confident that results have
not leaked.  I am well aquainted with the data management and blinding
procedures in place for the trial.

> This is an example of the need to sort out these things in advance -
> look up the stuff from the UK DAMOCLES project. The recent book
> edited by DeMets et al (Data Monitoring in Clinical Trials: A Case
> Studies Approach) is a good read on these sorts of issues and I think
> there is a more statistical book from the same group of authors.

Thanks for the reference.  My library has it, so will give it a look.

> As far as software is concerned, futility analysis and conditional
> power are simply standard analyses with made up data and more-or-less
> justifiable assumptions.

I am also interested if there are good alternatives to conditional
power for this type of scenario.

> Steve.
> 
> 
> 
>> 
>> What does this particular Steering Committee think a "futility 
>> analysis" is?  Do they have any particular reference(s)?  What do
>> you find in your own literature review?
>> 
>> If it were my problem, I think I'd start with questions like that. 
>> Your comments suggested to me a confounding of technical and
>> political problems.  The politics suggests the language you need to
>> use in your response.  Beyond that, I've never heard before of a
>> "futility analysis", but I think I could do one by just trying to
>> be clear about the options the Steering Committee might consider
>> plausible and then comparing them with appropriate simulations --
>> summarized as confidence intervals, as you suggest.

I did ask REPEATEDLY for guidelines from the steering committee, but
none came or are likely to come.  In fact, they wanted me to come up
with the recommendation, which I find entirely inappropriate, but here
I am.  So, I don't think I'm confounded between techincal and political.

Basically, they want to stop if there is a low chance of rejecting the
null hypothesis.  This is often referred to as conditional power or
stochastic curtailment.  I recently saw a paper by Scott Emerson
pointing out some problems (interpretation, relation to unconditional
power).

As far as references, I have used a book by Jennisen and Turnbull in
the past, but, as I recall, with the exception of stochastic
curtailment, it assumes the trial was designed with group sequential
methods.  I have also just found a 1988 Biometrics paper by Lan and
Wittes on the B-value which I will read.

>> And I hope that someone else will enlighten us both if there are 
>> better options available.
>> 
>> Best Wishes, spencer graves p.s.  For any attorneys who may read
>> these comments, the suggestions are obviously warranteed up to the
>> amount you paid for it, which is nothing. If you follow them and
>> they turn out to be inappropriate, you will pay the price.  I
>> encourage you to share the problems with me, so I can learn from
>> the experience.  However, the limits of my liability are as already
>> stated.
>> 
>> Kevin E. Thorpe wrote:
>> 
>> 
>>> I beg your pardon if this is too off topic.  I am posting here 
>>> since I hope to find an R solution to my problem.  Please indulge
>>>  me while I give a little background about what I'm trying to do.
>>> 
>>> 
>>> I'm on a DSMB for a clinical trial.  The Steering Committee for
>>> the trial has asked us to perform a futility analysis on their
>>> primary outcome which is a time-to-event endpoint.  The trial was
>>> not designed with group sequential methods, nor was any futility
>>> analysis spelled out in the protocol.  Another thing which may be
>>> relevant is that due to circumstances beyond the investigators'
>>> control, the trial will stop recruitment prematurely unless there
>>> is some compelling reason for them to find a way to continue the
>>> trial.  Lastly, the trial has accrued not quite half of the
>>> planned sample size.
>>> 
>>> Admittedly, I don't have a vast amount of experience implementing
>>>  stopping rules.  In other protocols I have seen where futility 
>>> analyses have been planned but a group sequential design has not 
>>> otherwise been employed, conditional power has been used for the 
>>> futility rule.  So naturally, that was my first thought (although
>>>  I may well be wrong) in this case.  I have done RSiteSearch()
>>> with the following terms (three different searches):
>>> 
>>> futility analysis conditional power stochastic curtailment
>>> 
>>> Nothing that looked relevant to my problem jumped out at me.
>>> 
>>> I have read, somewhat recently, that there are problems with
>>> conditional power, although I don't remember the details at the
>>> moment.  This has prompted me to consider other approaches to the
>>> problem.
>>> 
>>> One simple thing that has occurred to me, although I don't know 
>>> what the implications are is to simply look at a confidence 
>>> interval around the hazard ratio for the treatment effect.  In 
>>> the event that the CI includes 1 and excludes any clinically 
>>> important difference, I would take that as an indication of 
>>> futility.
>>> 
>>> I would appreciate your comments on this and to learn of any more
>>>  formal methods, particularly of implementations in R.
>>> 
>>> Thank you for reading.
>>> 
>>> Kevin


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.946.8081  Fax: 416.946.3297



From tlumley at u.washington.edu  Wed Feb 22 18:00:25 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 22 Feb 2006 09:00:25 -0800 (PST)
Subject: [R] exponent confusion
In-Reply-To: <1140603265.25774.27.camel@localhost.localdomain>
References: <1140603265.25774.27.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.64.0602220856550.7152@homer24.u.washington.edu>

On Wed, 22 Feb 2006, tom wright wrote:

> please excuse me if this ones a basic error
>
>> y<-c(-0.7,-0.6,-0.5)
>> -0.7^1.22
> [1] -0.6471718
>
>> y^1.22
> [1] NaN NaN NaN
>
> am I missing something important in my basic math?
>

Yes.

Non-integer powers of negative numbers don't work (well, they are complex 
numbers)

The first example appears to work but only because -0.7^1.22 is 
-(0.7^1.22) not (-0.7)^1.22. See help(Syntax) for operator precedence in 
R.  This does keep confusing people, and perhaps should be a FAQ, but it 
is fairly standard in programming languages.


 	-thomas



From vasu.akkineni at louisville.edu  Wed Feb 22 18:09:11 2006
From: vasu.akkineni at louisville.edu (Akkineni,Vasundhara)
Date: Wed, 22 Feb 2006 12:09:11 -0500
Subject: [R] heatmap.2 in gplots package
Message-ID: <1140628151.9539654svakki01@netmail.louisville.edu>

Hello all,

I am using the heatmap.2 function in the gplots package. I want to supress the reordering of the columns of the data matrix i pass to the function. I used the statement,

heatmap.2(z,Colv=FALSE,dendrogram="row",col=redgreen(75))

where z, is the matrix of data. The output i want should have the rows reordered along with the dendrogram and the columns should be in the original order without any dendrogram. For the above statement i am getting an error:

Error in image.default(1:nc, 1:nr, x, xlim = 0.5 + c(0, nc), ylim = 0.5 +  : 
        dimensions of z are not length(x)(+1) times length(y)(+1)

I also tried using ,
heatmap.2(z,Colv=NULL,dendrogram="row",col=redgreen(75))
for which i am getting the output, but the columns are reordered. How can this be done for the way in which i want the map to appear?

Thanks,
svakki.



From tlumley at u.washington.edu  Wed Feb 22 18:09:28 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 22 Feb 2006 09:09:28 -0800 (PST)
Subject: [R] unused factor levels in reshape
In-Reply-To: <s3fc84c0.018@ZGRW21.uwcm.ac.uk>
References: <s3fc84c0.018@ZGRW21.uwcm.ac.uk>
Message-ID: <Pine.LNX.4.64.0602220907530.7152@homer24.u.washington.edu>

On Wed, 22 Feb 2006, Daniel Farewell wrote:

> When reshaping a dataframe in which there are unused factor levels in 
> the id variable, I get the following error:
>
> Error in if (!all(really.constant)) warning(gettextf("some constant variables (%s) are really varying",  :
>        missing value where TRUE/FALSE needed

Yes, I think it's a bug. Thanks for pointing it out.

 	-thomas

>
> For example,
>
>> df <- data.frame(i = factor(rep(1:5, each = 2)), t = factor(rep(1:2, 5)), x = rep(rbinom(5, 1, 0.5), each = 2), y = rpois(10, 10))
>
>> subdf <- subset(df, i %in% 1:3)
>
> defines a dataframe, and a subframe with some unused factor levels (i = 4, 5). Then
>
>> reshape(df, v.names = "y", timevar = "t", idvar = "i", direction = "wide")
>  i x y.1 y.2
> 1 1 0  13   6
> 3 2 0  12   5
> 5 3 0  10   9
> 7 4 1   9  11
> 9 5 1  12   8
>
> works fine but
>
>> reshape(subdf, v.names = "y", timevar = "t", idvar = "i", direction = "wide")
> Error in if (!all(really.constant)) warning(gettextf("some constant variables (%s) are really varying",  :
>        missing value where TRUE/FALSE needed
>
> produces the error, which happens during the check to see if the variables assumed constant are constant. The problem is that reshape searches over all the levels of the id variable (i in this case) to see if the other variables (here x) are constant. But there is no x associated with i = 4, 5 in the smaller dataframe, so
>
>> tapply(subdf$x, subdf$i, function(x) length(unique(x)) == 1)
>   1    2    3    4    5
> TRUE TRUE TRUE   NA   NA
>
> produces some NAs. A slight change to the reshape code to work around this problem would be to use (the equivalent of)
>
>> tapply(subdf$x, subdf$i[, drop = TRUE], function(x) length(unique(x)) == 1)
>   1    2    3
> TRUE TRUE TRUE
>
> in the reshapeWide function within reshape, but perhaps there is a good reason not to do this?
>
> Daniel
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From I.Szentirmai at rug.nl  Wed Feb 22 18:23:38 2006
From: I.Szentirmai at rug.nl (I.Szentirmai)
Date: Wed, 22 Feb 2006 18:23:38 +0100
Subject: [R] subset problem
Message-ID: <web-16603890@mail3.rug.nl>

Dear All,

I'm trying to run a model on a subset of my data 
identified by year = 2002. Does anyone know whats wrong 
with the syntax below:

glmmPQL(desm~desdat,random=~1|male,family=quasibinomial,
data=mcare,subset=year=2002)

I get an error message all the time, but it worked with 
string variables (like: subset=sex=="M").

Thanks,
Istvan



From pcampbell at econ.bbk.ac.uk  Wed Feb 22 18:41:56 2006
From: pcampbell at econ.bbk.ac.uk (Phineas Campbell)
Date: Wed, 22 Feb 2006 17:41:56 -0000
Subject: [R] exponent confusion
In-Reply-To: <1140603265.25774.27.camel@localhost.localdomain>
Message-ID: <NGECIFANPOJAGABBAEAPOEOHFJAA.pcampbell@econ.bbk.ac.uk>

> -0.7^1.22
[1] -0.6471718

(-0.7)^1.22
>NaN

Arithmetically this makes perfect sense, syntactically I'm not sure it does.

>z<-c(-0.7)
> z == -0.7
[1] TRUE
> z^1.22
[1] NaN


I remember a programming homily: if you are unsure of the operator
precedence then you shouldn't assume the person who has to maintain your
code has any better knowledge so you should make the order in which you want
expressions to be evaluated explicit.

Phineas



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of tom wright
Sent: Wednesday, February 22, 2006 10:14 AM
To: R-Stat Help
Subject: [R] exponent confusion


please excuse me if this ones a basic error

> y<-c(-0.7,-0.6,-0.5)
> -0.7^1.22
[1] -0.6471718

> y^1.22
[1] NaN NaN NaN

am I missing something important in my basic math?

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From gregory.r.warnes at pfizer.com  Wed Feb 22 18:54:37 2006
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Wed, 22 Feb 2006 12:54:37 -0500
Subject: [R] heatmap.2 in gplots package
Message-ID: <915D2D65A9986440A277AC5C98AA466F01863968@groamrexm02.amer.pfizer.com>

Hello Akkineni,

This bug has already been reported and we have a tentative solution that we are testing.  I'll send you a copy of the modified code once we finish testing.

-G

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of
> Akkineni,Vasundhara
> Sent: Wednesday, February 22, 2006 12:09 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] heatmap.2 in gplots package
> 
> 
> Hello all,
> 
> I am using the heatmap.2 function in the gplots package. I 
> want to supress the reordering of the columns of the data 
> matrix i pass to the function. I used the statement,
> 
> heatmap.2(z,Colv=FALSE,dendrogram="row",col=redgreen(75))
> 
> where z, is the matrix of data. The output i want should have 
> the rows reordered along with the dendrogram and the columns 
> should be in the original order without any dendrogram. For 
> the above statement i am getting an error:
> 
> Error in image.default(1:nc, 1:nr, x, xlim = 0.5 + c(0, nc), 
> ylim = 0.5 +  : 
>         dimensions of z are not length(x)(+1) times length(y)(+1)
> 
> I also tried using ,
> heatmap.2(z,Colv=NULL,dendrogram="row",col=redgreen(75))
> for which i am getting the output, but the columns are 
> reordered. How can this be done for the way in which i want 
> the map to appear?
> 
> Thanks,
> svakki.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html
----------------------------------------------------------------------
LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From sdavis2 at mail.nih.gov  Wed Feb 22 18:55:25 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 22 Feb 2006 12:55:25 -0500
Subject: [R] heatmap.2 in gplots package
In-Reply-To: <1140628151.9539654svakki01@netmail.louisville.edu>
Message-ID: <C0220FBD.6634%sdavis2@mail.nih.gov>




On 2/22/06 12:09 PM, "Akkineni,Vasundhara" <vasu.akkineni at louisville.edu>
wrote:

> Hello all,
> 
> I am using the heatmap.2 function in the gplots package. I want to supress the
> reordering of the columns of the data matrix i pass to the function. I used
> the statement,
> 
> heatmap.2(z,Colv=FALSE,dendrogram="row",col=redgreen(75))
> 
> where z, is the matrix of data. The output i want should have the rows
> reordered along with the dendrogram and the columns should be in the original
> order without any dendrogram. For the above statement i am getting an error:
> 
> Error in image.default(1:nc, 1:nr, x, xlim = 0.5 + c(0, nc), ylim = 0.5 +  :
>         dimensions of z are not length(x)(+1) times length(y)(+1)
> 
> I also tried using ,
> heatmap.2(z,Colv=NULL,dendrogram="row",col=redgreen(75))
> for which i am getting the output, but the columns are reordered. How can this
> be done for the way in which i want the map to appear?

Use Colv=1:ncol(z), I think.

Sean



From mtb954 at gmail.com  Wed Feb 22 19:05:37 2006
From: mtb954 at gmail.com (mtb954@gmail.com)
Date: Wed, 22 Feb 2006 12:05:37 -0600
Subject: [R] Merge dataframes with no shared rows,
	some shared and some unshared columns
Message-ID: <e40d78ce0602221005h169040f6sfe2cd5f44c1883e5@mail.gmail.com>

Dear R-users,

I have two dataframes FIRST and SECOND that do not share any rows
(i.e., there is no unique identifier linking the rows in the two
dataframes, the rows are independent).

The dataframes have three variables (in columns) in common, but each
dataframe also has some variables not shared by the other.

I wish to merge FIRST and SECOND into a THIRD dataframe, stacking the
shared columns and including the unshared columns from FIRST and
SECOND as columns in THIRD. Also, I wish rows in THIRD that do not
have a value in a particular column (because they came from a
dataframe without that column) to acquire the value "0" (zero).

Finally, it it possible to merge >2 dataframes using the merge function?

Any ideas? Thanks, Mark



From beperron at wustl.edu  Wed Feb 22 19:05:51 2006
From: beperron at wustl.edu (Brian Perron)
Date: Wed, 22 Feb 2006 12:05:51 -0600
Subject: [R] Merging data
Message-ID: <84C59624B1B0204BBCB3B7DDF981AE63010AD1CC@GWB-PO.gwb.wustl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060222/58294d22/attachment.pl

From andy_liaw at merck.com  Wed Feb 22 19:14:51 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 22 Feb 2006 13:14:51 -0500
Subject: [R] subset problem
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED840@usctmx1106.merck.com>

You need year == 2002.

Andy

From:  I.Szentirmai
> 
> Dear All,
> 
> I'm trying to run a model on a subset of my data 
> identified by year = 2002. Does anyone know whats wrong 
> with the syntax below:
> 
> glmmPQL(desm~desdat,random=~1|male,family=quasibinomial,
> data=mcare,subset=year=2002)
> 
> I get an error message all the time, but it worked with 
> string variables (like: subset=sex=="M").
> 
> Thanks,
> Istvan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ccleland at optonline.net  Wed Feb 22 19:21:20 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 22 Feb 2006 13:21:20 -0500
Subject: [R] Merging data
In-Reply-To: <84C59624B1B0204BBCB3B7DDF981AE63010AD1CC@GWB-PO.gwb.wustl.edu>
References: <84C59624B1B0204BBCB3B7DDF981AE63010AD1CC@GWB-PO.gwb.wustl.edu>
Message-ID: <43FCABA0.4030102@optonline.net>

Brian Perron wrote:
> Hello all,
> 
> I am fairly new to R and am trying to bring together data from multiple sources.  Here is one problem that I cannot seem to crack ? I hope somebody can help.  Let me simplify the problem:  Let?s say I have two datasets:  DATA1 and DATA2.  I would like to work with all the cases in DATA2.  I have additional variables on these cases in DATA1, which is a larger data set with many additional cases.  I know how to merge data sets if the datasets contain the same cases.  However, I want to eliminate all the cases from DATA1 that are not present in DATA2 and then merge.  The CASEID is my matching variable, and there are no duplicate variable names. 
> Any guidance would be greatly appreciated. 

Take closer look at the all.x and all.y arguments in ?merge.  Does this 
give what you want?

merge(DATA1, DATA2, by="CASEID", all.x=FALSE, all.y=TRUE)

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From andy_liaw at merck.com  Wed Feb 22 19:23:58 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 22 Feb 2006 13:23:58 -0500
Subject: [R] Merge dataframes with no shared rows,
 some shared and som e unshared columns
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED841@usctmx1106.merck.com>

> first <- data.frame(a=1:3, b=4:6)
> second <- data.frame(b=7:9, c=10:12)
> third <- merge(first, second, by="b", all=TRUE)
> third
  b  a  c
1 4  1 NA
2 5  2 NA
3 6  3 NA
4 7 NA 10
5 8 NA 11
6 9 NA 12

It's easy to replace the Nas with whatever value you want.

No, merge() does not work with more than two data sets at a time.

Andy

From: mtb954 at gmail.com
> 
> Dear R-users,
> 
> I have two dataframes FIRST and SECOND that do not share any rows
> (i.e., there is no unique identifier linking the rows in the two
> dataframes, the rows are independent).
> 
> The dataframes have three variables (in columns) in common, but each
> dataframe also has some variables not shared by the other.
> 
> I wish to merge FIRST and SECOND into a THIRD dataframe, stacking the
> shared columns and including the unshared columns from FIRST and
> SECOND as columns in THIRD. Also, I wish rows in THIRD that do not
> have a value in a particular column (because they came from a
> dataframe without that column) to acquire the value "0" (zero).
> 
> Finally, it it possible to merge >2 dataframes using the 
> merge function?
> 
> Any ideas? Thanks, Mark
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From andy_liaw at merck.com  Wed Feb 22 19:27:13 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 22 Feb 2006 13:27:13 -0500
Subject: [R] Merging data
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED842@usctmx1106.merck.com>

Something like this?

> data1 <- data.frame(id=c(1, 3, 5), x=runif(3))
> data2 <- data.frame(id=1:10, y=runif(10))
> data3 <- merge(data1, data2, by="id", all.x=TRUE, all.y=FALSE)
> data3
  id         x         y
1  1 0.9533341 0.1803271
2  3 0.9143624 0.5033228
3  5 0.2866931 0.4233733

Andy

From: Brian Perron
> 
> Hello all,
> 
> I am fairly new to R and am trying to bring together data 
> from multiple sources.  Here is one problem that I cannot 
> seem to crack - I hope somebody can help.  Let me simplify 
> the problem:  Let's say I have two datasets:  DATA1 and 
> DATA2.  I would like to work with all the cases in DATA2.  I 
> have additional variables on these cases in DATA1, which is a 
> larger data set with many additional cases.  I know how to 
> merge data sets if the datasets contain the same cases.  
> However, I want to eliminate all the cases from DATA1 that 
> are not present in DATA2 and then merge.  The CASEID is my 
> matching variable, and there are no duplicate variable names. 
> Any guidance would be greatly appreciated. 
> 
> Thanks in advance,
> Brian  
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
>



From jfox at mcmaster.ca  Wed Feb 22 19:29:12 2006
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 22 Feb 2006 13:29:12 -0500
Subject: [R] testing factor effects in glm
In-Reply-To: <Pine.LNX.4.64.0602220747020.12487@homer23.u.washington.edu>
Message-ID: <20060222182911.UEIR18394.tomts5-srv.bellnexxia.net@JohnDesktop8300>

Dear Istvan,

You might want to take a look at the Anova() and linear.hypothesis()
functions in the car package.

Regards,
 John

 
 On Wed, 22 Feb 2006, I.Szentirmai wrote:
 
> Dear All,
> 
> I'm using a glm to analyse the effect of year on a 
> variable with poisson distribution. Using the summary() I 
> can test whether years are different from each other, but 
> how can I test whether year has an overall effect on my 
> respons variable? My guess is that by a Wald-test, but I 
> don't know how exactly.



From lizzylaws at yahoo.com  Wed Feb 22 19:57:08 2006
From: lizzylaws at yahoo.com (Elizabeth Lawson)
Date: Wed, 22 Feb 2006 10:57:08 -0800 (PST)
Subject: [R] nlin equivalent
Message-ID: <20060222185708.83632.qmail@web32101.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060222/61cd1d37/attachment.pl

From mschwartz at mn.rr.com  Wed Feb 22 20:10:36 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Wed, 22 Feb 2006 13:10:36 -0600
Subject: [R] OT Futility Analysis
In-Reply-To: <43FC97EC.3030803@utoronto.ca>
References: <20060222094741625.00000002680@K01391008F6W51J>
	<43FC97EC.3030803@utoronto.ca>
Message-ID: <1140635436.4483.72.camel@localhost.localdomain>

On Wed, 2006-02-22 at 11:57 -0500, Kevin E. Thorpe wrote:
> Thank you Spencer and Steve for your helpful comments.  If I may, I
> would like to elaborate on some of the points you raise.

Kevin,

I am not sure if you received any offlist replies to your post. Given
the subject matter, I had considered that you might have.

You might find the following thread over in the MedStats group to be of
interest:

http://groups.google.com/group/MedStats/browse_frm/thread/144c97dc5cfc4f00?tvc=1

It discusses some of the issues of early stopping, in this particular
case due to "running out of funds". Some of the points raised below are
addressed in that thread.

MedStats, BTW, would be a good forum to consider for your query.

> Stephen A Roberts wrote:
> > I would take the line that if they hadn't pre-specified any stopping
> > rules, the only reason to stop is safety or new external data. I
> > would be very suspicious of requests from the steering committee to
> > stop for futility - they should be blinded so why are they thinking
> > futility unless results have leaked? I would argue that they are
> > obliged to finish the trial once they start.
> 
> In general I agree with this.  In this case the request for a futility
> analysis came from the sponsor (a drug company).  It is a classic case
> of company B buys company A and wnats to stop R&D on company A's drugs.
> Therefore the company was looking for a reason to stop.  Now that they
> will stop producing the drug used in the trial, recruitment will end
> before reaching its target.  Now the Steering Committee's point of
> view is that if there is any reasonable hope, they would find some
> other way to continue recruitment.  I am confident that results have
> not leaked.  I am well aquainted with the data management and blinding
> procedures in place for the trial.

Has the decision to cease production already been made or is the sponsor
still open to being "sold" on the idea of keeping the study going,
pending the outcome of your further work?

If production of the study treatment has already ceased, the ability of
the SC to make a business case to the sponsor may be a forgone
conclusion if there is insufficient product available to continue.

> > This is an example of the need to sort out these things in advance -
> > look up the stuff from the UK DAMOCLES project. The recent book
> > edited by DeMets et al (Data Monitoring in Clinical Trials: A Case
> > Studies Approach) is a good read on these sorts of issues and I think
> > there is a more statistical book from the same group of authors.
> 
> Thanks for the reference.  My library has it, so will give it a look.
> 
> > As far as software is concerned, futility analysis and conditional
> > power are simply standard analyses with made up data and more-or-less
> > justifiable assumptions.
> 
> I am also interested if there are good alternatives to conditional
> power for this type of scenario.
> 
> > Steve.
> > 
> > 
> > 
> >> 
> >> What does this particular Steering Committee think a "futility 
> >> analysis" is?  Do they have any particular reference(s)?  What do
> >> you find in your own literature review?
> >> 
> >> If it were my problem, I think I'd start with questions like that. 
> >> Your comments suggested to me a confounding of technical and
> >> political problems.  The politics suggests the language you need to
> >> use in your response.  Beyond that, I've never heard before of a
> >> "futility analysis", but I think I could do one by just trying to
> >> be clear about the options the Steering Committee might consider
> >> plausible and then comparing them with appropriate simulations --
> >> summarized as confidence intervals, as you suggest.
> 
> I did ask REPEATEDLY for guidelines from the steering committee, but
> none came or are likely to come.  In fact, they wanted me to come up
> with the recommendation, which I find entirely inappropriate, but here
> I am.  So, I don't think I'm confounded between techincal and political.

>From what I have seen of the regulatory guidance documents, the SC
should not provide you with any guidelines and the analysis should be
done independent of their input, since their input may be biased in
favor of the new drug. As I note below, the mere fact that the SC is
arguing in favor of continuing the study would suggest the possibility
of a priori bias. This is critical to consider, since there are no
pre-specified stopping rules.

In addition, these should not be done by you in isolation either and the
other clinical members of the DMC/DSMB should materially contribute to
the process. They should be just as clinically competent as any members
of the SC relative to putting forth reasonable assumptions upon which to
base any analyses.

> Basically, they want to stop if there is a low chance of rejecting the
> null hypothesis.  This is often referred to as conditional power or
> stochastic curtailment.  I recently saw a paper by Scott Emerson
> pointing out some problems (interpretation, relation to unconditional
> power).
> 
> As far as references, I have used a book by Jennisen and Turnbull in
> the past, but, as I recall, with the exception of stochastic
> curtailment, it assumes the trial was designed with group sequential
> methods.  I have also just found a 1988 Biometrics paper by Lan and
> Wittes on the B-value which I will read.

J&T has a case study with survival analysis as I recall. I don't have it
at hand at the moment.

Another paper that you might find helpful is:

Modifying The Design of Ongoing Trials Without Unblinding
Gould and Shih
Statist. Med., 17, 89 ? 100 (1998)

I happened to locate a copy here during a Google search:

http://www2.umdnj.edu/~shihwj/papers/Gould%20and%20Shih%2098.pdf


There is also a Powerpoint presentation by Hung et al that you might
find of interest here:

http://www.fda.gov/cder/Offices/Biostatistics/Hung_etal_6/Hung_etal_6.PPT


BTW, though timing does not help you, there is a new book in process by
Proschan, Lan and Wittes due in June here:

http://www.springer.com/sgw/cda/frontpage/0,11855,4-10134-22-96964889-0,00.html


Two other documents that would be of value here, in a general guideline
sense, are the FDA's draft guidance on DMC's for sponsors (yes, I noted
you are "north of the border"):

http://www.fda.gov/cber/gdlns/clindatmon.htm

and of course ICH E9:

http://www.ich.org/cache/compo/475-272-1.html#E9

Both of which touch on the areas of interim analyses and early stopping.


It seems to me there there is a tension between the sponsor and the SC. 

In the former case, the sponsor is looking to make a business decision,
based upon what will clearly be less than perfect data, where
"scientific integrity" is or may be compromised. 

On the other hand, the SC is looking to argue for keeping the study
going and that presumably is based upon some a priori insight into the
likelihood of a favorable outcome for the new drug.

If there is to be a mid-course correction in the study (even though
there were no pre-specified stopping rules), there is a risk that the
mere decision to continue the study will somehow bias the future conduct
of it, given the present dynamics and "who knows what" about the
decision making process.

Some of the questions to be considered are what assumptions do you make
in the course of your assessment relative to future data and the need
for adjustments, if any, to the primary hypotheses of the study
(including alpha levels) given the knowledge that becomes available
during the un-planned interim analysis.

At the end of the day, you will need to consider the requirement to make
adjustments in the current study protocol, requiring re-submission and
re-approval by the requisite regulatory authority. It therefore would be
worthwhile to consider proactive communications with the regulatory
contacts for the study and discuss this situation with them to get their
"buy in" on any proposed approaches before taking any further steps.

<snip other content>

HTH,

Marc Schwartz



From thomas.hoffmann at uni-bonn.de  Wed Feb 22 20:16:45 2006
From: thomas.hoffmann at uni-bonn.de (Thomas Hoffmann)
Date: Wed, 22 Feb 2006 20:16:45 +0100
Subject: [R] shaded timeseries plot
Message-ID: <43FCB89D.50908@uni-bonn.de>

Dear list members,

I would like to plot a time series, with grayshaded background in time 
phases were the value of the timeseries exceeds the mean value. For 
example, if the temperature from 1995-1998 exeeds the mean value between 
1980 and 2005, the background in the plot from 1995-1998 shall be shaded.

Can anybody help me?
Thanks
Thomas H.



From abunn at whrc.org  Wed Feb 22 20:24:28 2006
From: abunn at whrc.org (Andy Bunn)
Date: Wed, 22 Feb 2006 14:24:28 -0500
Subject: [R] shaded timeseries plot
In-Reply-To: <43FCB89D.50908@uni-bonn.de>
Message-ID: <NEBBIPHDAMMOKDKPOFFIEEEEEAAA.abunn@whrc.org>

Does this thread help?
https://stat.ethz.ch/pipermail/r-help/2006-February/086874.html


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Thomas Hoffmann
> Sent: Wednesday, February 22, 2006 2:17 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] shaded timeseries plot
> 
> 
> Dear list members,
> 
> I would like to plot a time series, with grayshaded background in time 
> phases were the value of the timeseries exceeds the mean value. For 
> example, if the temperature from 1995-1998 exeeds the mean value between 
> 1980 and 2005, the background in the plot from 1995-1998 shall be shaded.
> 
> Can anybody help me?
> Thanks
> Thomas H.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From jfox at mcmaster.ca  Wed Feb 22 20:33:16 2006
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 22 Feb 2006 14:33:16 -0500
Subject: [R] nlin equivalent
In-Reply-To: <20060222185708.83632.qmail@web32101.mail.mud.yahoo.com>
Message-ID: <20060222193315.DIDB10262.tomts22-srv.bellnexxia.net@JohnDesktop8300>

Dear Elizabeth,

See ?nls. [You could have found this via help.search("nonlinear least
squares").]

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Elizabeth Lawson
> Sent: Wednesday, February 22, 2006 1:57 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] nlin equivalent
> 
> Does R have any equivalent for proc nlin?
>    
>   Thanks,
>    
>   Elizabeth Lawson
>



From vasu.akkineni at louisville.edu  Wed Feb 22 21:15:31 2006
From: vasu.akkineni at louisville.edu (Akkineni,Vasundhara)
Date: Wed, 22 Feb 2006 15:15:31 -0500
Subject: [R] heatmap.2 in gplots package
Message-ID: <1140639331.48fd5564svakki01@netmail.louisville.edu>

I used Colv=1:ncol(z), and i got the display the way i need it. Thanks.

One more question, is there a way to increase the size of the color key in heatmap.2 so that all the tick values(for Eg.,in my case, values range between 10,000-50,000) can be seen clearly. In the normal case i am just able to see the initial tick value which is 10,000. Please suggest a better way to do this.

Thanks for the help.

svakki.

-----Original Message-----
From: Sean Davis <sdavis2 at mail.nih.gov>
To: "Akkineni,Vasundhara" <svakki01 at netmail.louisville.edu>, r-help <r-help at stat.math.ethz.ch>
Date: Wed, 22 Feb 2006 12:55:25 -0500
Subject: Re: [R] heatmap.2 in gplots package




On 2/22/06 12:09 PM, "Akkineni,Vasundhara" <vasu.akkineni at louisville.edu>
wrote:

> Hello all,
> 
> I am using the heatmap.2 function in the gplots package. I want to supress the
> reordering of the columns of the data matrix i pass to the function. I used
> the statement,
> 
> heatmap.2(z,Colv=FALSE,dendrogram="row",col=redgreen(75))
> 
> where z, is the matrix of data. The output i want should have the rows
> reordered along with the dendrogram and the columns should be in the original
> order without any dendrogram. For the above statement i am getting an error:
> 
> Error in image.default(1:nc, 1:nr, x, xlim = 0.5 + c(0, nc), ylim = 0.5 +  :
>         dimensions of z are not length(x)(+1) times length(y)(+1)
> 
> I also tried using ,
> heatmap.2(z,Colv=NULL,dendrogram="row",col=redgreen(75))
> for which i am getting the output, but the columns are reordered. How can this
> be done for the way in which i want the map to appear?

Use Colv=1:ncol(z), I think.

Sean



From sdavis2 at mail.nih.gov  Wed Feb 22 21:19:31 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 22 Feb 2006 15:19:31 -0500
Subject: [R] heatmap.2 in gplots package
In-Reply-To: <1140639331.48fd5564svakki01@netmail.louisville.edu>
Message-ID: <C0223183.6678%sdavis2@mail.nih.gov>




On 2/22/06 3:15 PM, "Akkineni,Vasundhara" <vasu.akkineni at louisville.edu>
wrote:

> I used Colv=1:ncol(z), and i got the display the way i need it. Thanks.
> 
> One more question, is there a way to increase the size of the color key in
> heatmap.2 so that all the tick values(for Eg.,in my case, values range between
> 10,000-50,000) can be seen clearly. In the normal case i am just able to see
> the initial tick value which is 10,000. Please suggest a better way to do
> this.

As far as I know there is not an easy way to do this without hacking the
heatmap.2 code, but I could be wrong.  For the purposes of making final
plots, I typically find that the best thing to do is to make a PDF of the
plot and then edit using Adobe or some such thing.

Sean



From Soren.Hojsgaard at agrsci.dk  Wed Feb 22 21:32:55 2006
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Wed, 22 Feb 2006 21:32:55 +0100
Subject: [R] How can I see how %*% is implemented?
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC038781F3@DJFPOST01.djf.agrsci.dk>

I would like to see how the matrix multiplication operator %*% is implemented (because I want to see which external Fortran/C routines are used). How can I do so?
Best
S??ren



From ripley at stats.ox.ac.uk  Wed Feb 22 22:00:41 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 22 Feb 2006 21:00:41 +0000 (GMT)
Subject: [R] How can I see how %*% is implemented?
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC038781F3@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC038781F3@DJFPOST01.djf.agrsci.dk>
Message-ID: <Pine.LNX.4.64.0602222053240.7961@gannet.stats.ox.ac.uk>

On Wed, 22 Feb 2006, S??ren H??jsgaard wrote:

> I would like to see how the matrix multiplication operator %*% is 
> implemented (because I want to see which external Fortran/C routines are 
> used). How can I do so? Best S??ren

[This is probably a R-devel question: please study the posting guide.]

> get("%*%")
.Primitive("%*%")

so get your R sources out (I'll use current R-devel), go to 
src/main/names.c and search.  You find

{"%*%",         do_matprod,     0,      1,      2,      {PP_BINARY, 
PREC_PERCENT,0}},

So this is OP 0 of do_matprod.  Search for that in src/main/*.c: it is is 
array.c. Find

     if (PRIMVAL(op) == 0) {			/* op == 0 : matprod() */

and the meat is

 	if (mode == CPLXSXP)
 	    cmatprod(COMPLEX(CAR(args)), nrx, ncx,
 		     COMPLEX(CADR(args)), nry, ncy, COMPLEX(ans));
 	else
 	    matprod(REAL(CAR(args)), nrx, ncx,
 		    REAL(CADR(args)), nry, ncy, REAL(ans));

Now look for matprod and cmatprod.  The answer is that if there are no 
IEEE754 specials, dgemm or zgemm are used.  Those are level-3 BLAS 
routines.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From mtmorgan at fhcrc.org  Wed Feb 22 22:03:19 2006
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 22 Feb 2006 13:03:19 -0800
Subject: [R] How can I see how %*% is implemented?
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC038781F3@DJFPOST01.djf.agrsci.dk>
	=?iso-8859-1?q?=28S=F8ren_H=F8jsgaard's?= message of "Wed,
	22 Feb 2006 21:32:55 +0100")
References: <C83C5E3DEEE97E498B74729A33F6EAEC038781F3@DJFPOST01.djf.agrsci.dk>
Message-ID: <6phu0arp0mg.fsf@gopher3.fhcrc.org>

get("%*%")

tells you that it is a primitive (i.e., implemented in C). The file
<R_HOME>/src/main/names.c directs you to do_matprod, in file
<R_HOME/src/main/array.c.

Martin

S??ren H??jsgaard <Soren.Hojsgaard at agrsci.dk> writes:

> I would like to see how the matrix multiplication operator %*% is implemented (because I want to see which external Fortran/C routines are used). How can I do so?
> Best
> S??ren
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From S.Nakagawa at sheffield.ac.uk  Wed Feb 22 23:37:40 2006
From: S.Nakagawa at sheffield.ac.uk (S Nakagawa)
Date: Wed, 22 Feb 2006 22:37:40 +0000
Subject: [R] Degree of freedom for contrast t-tests in lme
Message-ID: <1140647860.43fce7b42ec27@webmail.shef.ac.uk>

Dear all

Somebody may have asked this before but I could not find any answers in the web
so let me ask a question on lme.

When I have a fixed factor of, say, three levels (A, B, C), in which each level
has different size (i.e. no. of observations; e.g. A>B>C). When I run an lme
model, I get the same degree of freedom for all the contrast t-tests (e.g. AvsB
or BvsC). I have tried this to several data sets but the same thing happened.
Whatever sample size I have in different levels (in a fixed factor), I get the
same degree of freedom for t-tests. 

Why is this? Is this how mixed-effects model work? Does this mean that if I have
unbalanced design, results from lme are likely to be wrong?

Thank you for your help

Shinichi

-- 
Shinichi Nakagawa
Department of Animal & Plant Sciences,
University of Sheffield,	
Sheffield S10 2TN, UK
Tel: +44-114-222-0064  
Fax: +44-114-222-0002



From Qinghong.Li at rdmo.nestle.com  Wed Feb 22 23:43:04 2006
From: Qinghong.Li at rdmo.nestle.com (Li,Qinghong,ST.LOUIS,Molecular Biology)
Date: Wed, 22 Feb 2006 16:43:04 -0600
Subject: [R] multinomial test
Message-ID: <2BA2B7291D5DC6409FD53CB7C01F0D990183B768@usslre00.nestle.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060222/fc0f133d/attachment.pl

From jholtman at gmail.com  Thu Feb 23 00:32:56 2006
From: jholtman at gmail.com (jim holtman)
Date: Wed, 22 Feb 2006 18:32:56 -0500
Subject: [R] multinomial test
In-Reply-To: <2BA2B7291D5DC6409FD53CB7C01F0D990183B768@usslre00.nestle.com>
References: <2BA2B7291D5DC6409FD53CB7C01F0D990183B768@usslre00.nestle.com>
Message-ID: <644e1f320602221532w439f8995w156d26ae95a0f52e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060222/70c4c642/attachment.pl

From gunter.berton at gene.com  Thu Feb 23 00:43:54 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 22 Feb 2006 15:43:54 -0800
Subject: [R] multinomial test
In-Reply-To: <644e1f320602221532w439f8995w156d26ae95a0f52e@mail.gmail.com>
Message-ID: <005801c63809$d7c32770$711f210a@gne.windows.gene.com>

Qinghong:

R Has an extensive Help system which you should learn to use.

help.search('multinomial') 
?Multinomial

Jim: sample() is wrong -- it gives random samples, not probabilities.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of jim holtman
> Sent: Wednesday, February 22, 2006 3:33 PM
> To: Li,Qinghong,ST.LOUIS,Molecular Biology
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] multinomial test
> 
> ?sample
> 
> sample(1:3, 6, TRUE, prob=c(2/9, 1/6, 11/18))
> 
> 
> 
> On 2/22/06, Li,Qinghong,ST.LOUIS,Molecular Biology <
> Qinghong.Li at rdmo.nestle.com> wrote:
> >
> > Hi All,
> >
> > What is the R function for computing multinomial distribution, e.g.
> > f(2,1,3; 2/9, 1/6, 11/18, 6)?
> >
> > That is, a total of 6 trials, event 1's p1=2/9, x1=2, event 
> 2's p2=1/6,
> > x2=1, and event 3's p3=11/18, x3=3.
> >
> > thanks,
> > Johnny
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> 
> 
> 
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 646 9390
> 
> What the problem you are trying to solve?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Qinghong.Li at rdmo.nestle.com  Thu Feb 23 00:46:39 2006
From: Qinghong.Li at rdmo.nestle.com (Li,Qinghong,ST.LOUIS,Molecular Biology)
Date: Wed, 22 Feb 2006 17:46:39 -0600
Subject: [R] multinomial test
Message-ID: <2BA2B7291D5DC6409FD53CB7C01F0D990183B76A@usslre00.nestle.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060222/b7f43720/attachment.pl

From Qinghong.Li at rdmo.nestle.com  Thu Feb 23 00:53:27 2006
From: Qinghong.Li at rdmo.nestle.com (Li,Qinghong,ST.LOUIS,Molecular Biology)
Date: Wed, 22 Feb 2006 17:53:27 -0600
Subject: [R] multinomial test
Message-ID: <2BA2B7291D5DC6409FD53CB7C01F0D990183B76B@usslre00.nestle.com>

Thanks. That is what I try to find. You know what, I have tried ?multinomial, but it didn't recognize. It is case sensitive I guess.

Johnny

-----Original Message-----
From: Berton Gunter [mailto:gunter.berton at gene.com]
Sent: Wednesday, February 22, 2006 5:44 PM
To: 'jim holtman'; Li,Qinghong,ST.LOUIS,Molecular Biology
Cc: r-help at stat.math.ethz.ch
Subject: RE: [R] multinomial test


Qinghong:

R Has an extensive Help system which you should learn to use.

help.search('multinomial') 
?Multinomial

Jim: sample() is wrong -- it gives random samples, not probabilities.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of jim holtman
> Sent: Wednesday, February 22, 2006 3:33 PM
> To: Li,Qinghong,ST.LOUIS,Molecular Biology
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] multinomial test
> 
> ?sample
> 
> sample(1:3, 6, TRUE, prob=c(2/9, 1/6, 11/18))
> 
> 
> 
> On 2/22/06, Li,Qinghong,ST.LOUIS,Molecular Biology <
> Qinghong.Li at rdmo.nestle.com> wrote:
> >
> > Hi All,
> >
> > What is the R function for computing multinomial distribution, e.g.
> > f(2,1,3; 2/9, 1/6, 11/18, 6)?
> >
> > That is, a total of 6 trials, event 1's p1=2/9, x1=2, event 
> 2's p2=1/6,
> > x2=1, and event 3's p3=11/18, x3=3.
> >
> > thanks,
> > Johnny
> >
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> 
> 
> 
> --
> Jim Holtman
> Cincinnati, OH
> +1 513 646 9390
> 
> What the problem you are trying to solve?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From sundar.dorai-raj at pdf.com  Thu Feb 23 01:14:20 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 22 Feb 2006 16:14:20 -0800
Subject: [R] multinomial test
In-Reply-To: <2BA2B7291D5DC6409FD53CB7C01F0D990183B76B@usslre00.nestle.com>
References: <2BA2B7291D5DC6409FD53CB7C01F0D990183B76B@usslre00.nestle.com>
Message-ID: <43FCFE5C.9070804@pdf.com>

This is what I get when I try ?multinomial:

 > ?multinomial
No documentation for 'multinomial' in specified packages and libraries:
you could try 'help.search("multinomial")'
                ^^^^^^^^^^^^^^^^^^^^^^^^^^

Which leads to ?Multinomial and Bert's advice below.

--sundar


Li,Qinghong,ST.LOUIS,Molecular Biology wrote:
> Thanks. That is what I try to find. You know what, I have tried ?multinomial, but it didn't recognize. It is case sensitive I guess.
> 
> Johnny
> 
> -----Original Message-----
> From: Berton Gunter [mailto:gunter.berton at gene.com]
> Sent: Wednesday, February 22, 2006 5:44 PM
> To: 'jim holtman'; Li,Qinghong,ST.LOUIS,Molecular Biology
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] multinomial test
> 
> 
> Qinghong:
> 
> R Has an extensive Help system which you should learn to use.
> 
> help.search('multinomial') 
> ?Multinomial
> 
> Jim: sample() is wrong -- it gives random samples, not probabilities.
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
> 
> 
> 
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch 
>>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of jim holtman
>>Sent: Wednesday, February 22, 2006 3:33 PM
>>To: Li,Qinghong,ST.LOUIS,Molecular Biology
>>Cc: r-help at stat.math.ethz.ch
>>Subject: Re: [R] multinomial test
>>
>>?sample
>>
>>sample(1:3, 6, TRUE, prob=c(2/9, 1/6, 11/18))
>>
>>
>>
>>On 2/22/06, Li,Qinghong,ST.LOUIS,Molecular Biology <
>>Qinghong.Li at rdmo.nestle.com> wrote:
>>
>>>Hi All,
>>>
>>>What is the R function for computing multinomial distribution, e.g.
>>>f(2,1,3; 2/9, 1/6, 11/18, 6)?
>>>
>>>That is, a total of 6 trials, event 1's p1=2/9, x1=2, event 
>>
>>2's p2=1/6,
>>
>>>x2=1, and event 3's p3=11/18, x3=3.
>>>
>>>thanks,
>>>Johnny
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>>http://www.R-project.org/posting-guide.html
>>>
>>
>>
>>
>>--
>>Jim Holtman
>>Cincinnati, OH
>>+1 513 646 9390
>>
>>What the problem you are trying to solve?
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Soren.Hojsgaard at agrsci.dk  Thu Feb 23 01:56:42 2006
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Thu, 23 Feb 2006 01:56:42 +0100
Subject: [R] Degree of freedom for contrast t-tests in lme
References: <1140647860.43fce7b42ec27@webmail.shef.ac.uk>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC038781F5@DJFPOST01.djf.agrsci.dk>

I think this happens because degrees of freedom in lme are calculated using the "containment" method (see documentation to proc mixed in SAS if you don't know the method). 
 
Formally this means that the t-tests are "wrong" for (most) unbalanced designs. 
 
However, if the sample sizes are not too small this should not be to much of a problem because the t-distribution quickly comes to resemble the normal, and if sample sizes are small one may wonder whether it makes sense to make the t-tests anyway. (The validity of a t-test on, say, 4 dfs relies heavily on data being normal whereas a t-test on 14 dfs does not - because of central limit theorems).
 
As I've understood Douglas Bates (who made lme), he finds that those df-issues are not the most important issues in statistics, so lme might not change drastically in that respect... 
 
It would, however, be nice to have methods in lme which could deal with this problem. One option would be that *somebody* implement Kenward/Rogers and/or Satterthwaites and/or related methods for estimating the degrees of freedom. Another possibility is to base the tests on Monte Carlo p-values...
 
Best regards
S??ren

________________________________

Fra: r-help-bounces at stat.math.ethz.ch p?? vegne af S Nakagawa
Sendt: on 22-02-2006 23:37
Til: r-help at stat.math.ethz.ch
Emne: [R] Degree of freedom for contrast t-tests in lme



Dear all

Somebody may have asked this before but I could not find any answers in the web
so let me ask a question on lme.

When I have a fixed factor of, say, three levels (A, B, C), in which each level
has different size (i.e. no. of observations; e.g. A>B>C). When I run an lme
model, I get the same degree of freedom for all the contrast t-tests (e.g. AvsB
or BvsC). I have tried this to several data sets but the same thing happened.
Whatever sample size I have in different levels (in a fixed factor), I get the
same degree of freedom for t-tests.

Why is this? Is this how mixed-effects model work? Does this mean that if I have
unbalanced design, results from lme are likely to be wrong?

Thank you for your help

Shinichi

--
Shinichi Nakagawa
Department of Animal & Plant Sciences,
University of Sheffield,       
Sheffield S10 2TN, UK
Tel: +44-114-222-0064 
Fax: +44-114-222-0002

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dmaneesh at hotmail.com  Thu Feb 23 04:45:37 2006
From: dmaneesh at hotmail.com (maneesh deshpande)
Date: Wed, 22 Feb 2006 22:45:37 -0500
Subject: [R] Ranking within factor subgroups
In-Reply-To: <1140579886.3452.3.camel@dhcp-82.wolf.ox.ac.uk>
Message-ID: <BAY107-F3592EDACEA8D92D1128BBCD2F20@phx.gbl>

Hi Adai,

I think your solution only works if the rows of the data frame are ordered 
by "date" and
the ordering function is the same used to order the levels of 
factor(df$date) ?
It turns out (as I implied in my question) my data is indeed organized in 
this manner, so my
current problem is solved.
In the general case, I suppose, one could always order the data frame by 
date before proceeding ?

Thanks,

Maneesh


>From: Adaikalavan Ramasamy <ramasamy at cancer.org.uk>
>Reply-To: ramasamy at cancer.org.uk
>To: maneesh deshpande <dmaneesh at hotmail.com>
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R]  Ranking within factor subgroups
>Date: Wed, 22 Feb 2006 03:44:45 +0000
>
>It might help to give a simple reproducible example in the future. For
>example
>
>  df <- cbind.data.frame( date=rep( 1:5, each=100 ), A=rpois(500, 100),
>                          B=rpois(500, 50), C=rpois(500, 30) )
>
>might generate something like
>
>	    date   A  B  C
>	  1    1  93 51 32
>	  2    1  95 51 30
>	  3    1 102 59 28
>	  4    1 105 52 32
>	  5    1 105 53 26
>	  6    1  99 59 37
>	...    . ... .. ..
>	495    5 100 57 19
>	496    5  96 47 44
>	497    5 111 56 35
>	498    5 105 49 23
>	499    5 105 61 30
>	500    5  92 53 32
>
>Here is my proposed solution. Can you double check with your existing
>functions to see if they are correct.
>
>    decile.fn <- function(x, nbreaks=10){
>      br     <- quantile( x, seq(0, 1, len=nbreaks+1), na.rm=T )
>      br[1]  <- -Inf
>      return( cut(x, br, labels=F) )
>    }
>
>    out <- apply( df[ ,c("A", "B", "C")], 2,
>                  function(v) unlist( tapply( v, df$date, decile.fn ) ) )
>
>    rownames(out) <- rownames(df)
>    out <- cbind(df$date, out)
>
>Regards, Adai
>
>
>
>On Tue, 2006-02-21 at 21:44 -0500, maneesh deshpande wrote:
> > Hi,
> >
> > I have a dataframe, x of the following form:
> >
> > Date            Symbol   A    B  C
> > 20041201     ABC      10  12 15
> > 20041201     DEF       9    5   4
> > ...
> > 20050101     ABC         5  3   1
> > 20050101     GHM       12 4    2
> > ....
> >
> > here A, B,C are properties of a set symbols recorded for a given date.
> > I wante to decile the symbols For each date and property and
> > create another set of columns "bucketA","bucketB", "bucketC" containing 
>the
> > decile rank
> > for each symbol. The following non-vectorized code does what I want,
> >
> > bucket <- function(data,nBuckets) {
> >      q <- quantile(data,seq(0,1,len=nBuckets+1),na.rm=T)
> >      q[1] <- q[1] - 0.1 # need to do this to ensure there are no extra 
>NAs
> >      cut(data,q,include.lowest=T,labels=F)
> > }
> >
> > calcDeciles <- function(x,colNames) {
> > nBuckets <- 10
> > dates <- unique(x$Date)
> > for ( date in dates) {
> >   iVec <- x$Date == date
> >   xx <- x[iVec,]
> >   for (colName in colNames) {
> >      data <- xx[,colName]
> >      bColName <- paste("bucket",colName,sep="")
> >      x[iVec,bColName] <- bucket(data,nBuckets)
> >   }
> > }
> > x
> > }
> >
> > x <- calcDeciles(x,c("A","B","C"))
> >
> >
> > I was wondering if it is possible to vectorize the above function to 
>make it
> > more efficient.
> > I tried,
> > rlist <- tapply(x$A,x$Date,bucket)
> > but I am not sure how to assign the contents of "rlist" to their 
>appropriate
> > slots in the original
> > dataframe.
> >
> > Thanks,
> >
> > Maneesh
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
> >
>



From p.dalgaard at biostat.ku.dk  Thu Feb 23 07:28:13 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 23 Feb 2006 07:28:13 +0100
Subject: [R] Ranking within factor subgroups
In-Reply-To: <BAY107-F3592EDACEA8D92D1128BBCD2F20@phx.gbl>
References: <BAY107-F3592EDACEA8D92D1128BBCD2F20@phx.gbl>
Message-ID: <x2hd6qy4g2.fsf@turmalin.kubism.ku.dk>

"maneesh deshpande" <dmaneesh at hotmail.com> writes:

> Hi Adai,
> 
> I think your solution only works if the rows of the data frame are ordered 
> by "date" and
> the ordering function is the same used to order the levels of 
> factor(df$date) ?
> It turns out (as I implied in my question) my data is indeed organized in 
> this manner, so my
> current problem is solved.
> In the general case, I suppose, one could always order the data frame by 
> date before proceeding ?
> 
> Thanks,
> 
> Maneesh

You might prefer to look at split/unsplit/split<-, i.e. the z-scores
by group line:

     z <- unsplit(lapply(split(x, g), scale), g)

with "scale" suitably replaced. Presumably (meaning: I didn't quite
read your code closely enough)

    z <- unsplit(lapply(split(x, g), bucket, 10), g)

could do it.
 
> 
> >From: Adaikalavan Ramasamy <ramasamy at cancer.org.uk>
> >Reply-To: ramasamy at cancer.org.uk
> >To: maneesh deshpande <dmaneesh at hotmail.com>
> >CC: r-help at stat.math.ethz.ch
> >Subject: Re: [R]  Ranking within factor subgroups
> >Date: Wed, 22 Feb 2006 03:44:45 +0000
> >
> >It might help to give a simple reproducible example in the future. For
> >example
> >
> >  df <- cbind.data.frame( date=rep( 1:5, each=100 ), A=rpois(500, 100),
> >                          B=rpois(500, 50), C=rpois(500, 30) )
> >
> >might generate something like
> >
> >	    date   A  B  C
> >	  1    1  93 51 32
> >	  2    1  95 51 30
> >	  3    1 102 59 28
> >	  4    1 105 52 32
> >	  5    1 105 53 26
> >	  6    1  99 59 37
> >	...    . ... .. ..
> >	495    5 100 57 19
> >	496    5  96 47 44
> >	497    5 111 56 35
> >	498    5 105 49 23
> >	499    5 105 61 30
> >	500    5  92 53 32
> >
> >Here is my proposed solution. Can you double check with your existing
> >functions to see if they are correct.
> >
> >    decile.fn <- function(x, nbreaks=10){
> >      br     <- quantile( x, seq(0, 1, len=nbreaks+1), na.rm=T )
> >      br[1]  <- -Inf
> >      return( cut(x, br, labels=F) )
> >    }
> >
> >    out <- apply( df[ ,c("A", "B", "C")], 2,
> >                  function(v) unlist( tapply( v, df$date, decile.fn ) ) )
> >
> >    rownames(out) <- rownames(df)
> >    out <- cbind(df$date, out)
> >
> >Regards, Adai
> >
> >
> >
> >On Tue, 2006-02-21 at 21:44 -0500, maneesh deshpande wrote:
> > > Hi,
> > >
> > > I have a dataframe, x of the following form:
> > >
> > > Date            Symbol   A    B  C
> > > 20041201     ABC      10  12 15
> > > 20041201     DEF       9    5   4
> > > ...
> > > 20050101     ABC         5  3   1
> > > 20050101     GHM       12 4    2
> > > ....
> > >
> > > here A, B,C are properties of a set symbols recorded for a given date.
> > > I wante to decile the symbols For each date and property and
> > > create another set of columns "bucketA","bucketB", "bucketC" containing 
> >the
> > > decile rank
> > > for each symbol. The following non-vectorized code does what I want,
> > >
> > > bucket <- function(data,nBuckets) {
> > >      q <- quantile(data,seq(0,1,len=nBuckets+1),na.rm=T)
> > >      q[1] <- q[1] - 0.1 # need to do this to ensure there are no extra 
> >NAs
> > >      cut(data,q,include.lowest=T,labels=F)
> > > }
> > >
> > > calcDeciles <- function(x,colNames) {
> > > nBuckets <- 10
> > > dates <- unique(x$Date)
> > > for ( date in dates) {
> > >   iVec <- x$Date == date
> > >   xx <- x[iVec,]
> > >   for (colName in colNames) {
> > >      data <- xx[,colName]
> > >      bColName <- paste("bucket",colName,sep="")
> > >      x[iVec,bColName] <- bucket(data,nBuckets)
> > >   }
> > > }
> > > x
> > > }
> > >
> > > x <- calcDeciles(x,c("A","B","C"))
> > >
> > >
> > > I was wondering if it is possible to vectorize the above function to 
> >make it
> > > more efficient.
> > > I tried,
> > > rlist <- tapply(x$A,x$Date,bucket)
> > > but I am not sure how to assign the contents of "rlist" to their 
> >appropriate
> > > slots in the original
> > > dataframe.
> > >
> > > Thanks,
> > >
> > > Maneesh
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> >http://www.R-project.org/posting-guide.html
> > >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From iadzhubey at rics.bwh.harvard.edu  Thu Feb 23 08:50:40 2006
From: iadzhubey at rics.bwh.harvard.edu (Ivan Adzhubey)
Date: Thu, 23 Feb 2006 02:50:40 -0500
Subject: [R] Problems building R 2.2.1 with libgoto and SSE2 enabled
Message-ID: <200602230250.40687.iadzhubey@rics.bwh.harvard.edu>

Hi,

I am trying to build R 2.2.1 with Kazushige Goto's BLAS library (libgoto) and 
encountered a problem: I have two computers with the almost identical 
hardware (P4 Northwood CPU, i875 chipset, 2GB DDR400 RAM) and identical Linux 
OS. I have the latest version of libgoto for this CPU installed on both boxes 
(libgoto_northwood32p-r1.00.so) and I am using gcc compiler flags "-O2 
-march=pentium4 -mfpmath=sse -msse2" to enable use of SSE2 extensions. With 
one computer that works perfectly, while on the other one "make check" 
constantly fails on lm-test. If I remove "-mfpmath=sse -msse2" part from the 
gcc flags then all checks pass on the second computer too. Any hints on what 
may cause the error? Anyone willing to share his/her experience on building 
and using R with SSE2 and on libgoto performance in particular? I was 
planning to give ATLAS a try but pre-built binaries are not available for my 
distro and on my AMD Opteron cluster it took almost 48 hours to build. I am 
not sure my home computer (the one that gives me errors with libgoto/SSE2) 
would survive this.

TIA,
Ivan



From r.hankin at noc.soton.ac.uk  Thu Feb 23 09:09:55 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Thu, 23 Feb 2006 08:09:55 +0000
Subject: [R] discrete probability distribution
Message-ID: <1BDB3E41-0FC6-4B26-A610-080CCB8E0E5F@soc.soton.ac.uk>

Hi

I want to sample from a discrete random variable X,  defined on
the  non-negative integers, with

prob(X=0) = (1-p)
prob(X=1) = (1-p)*p
...
prob(X=i)=(1-p)*p^i
...



Before reinventing the wheel,
is there a ready-made R function to give me such a thing?


--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From calenge at biomserv.univ-lyon1.fr  Thu Feb 23 09:25:26 2006
From: calenge at biomserv.univ-lyon1.fr (=?ISO-8859-1?Q?Cl=E9ment_Calenge?=)
Date: Thu, 23 Feb 2006 09:25:26 +0100
Subject: [R] [R-pkgs] adehabitat version 1.4
Message-ID: <43FD7176.8040403@biomserv.univ-lyon1.fr>

Dear all,

I have just uploaded to CRAN the version 1.4 of the
package 'adehabitat'. Significant changes are
listed below:

- The eigenanalysis of selection ratios (Calenge and Dufour, 2006, Ecology)
  can now be performed using the function eisera(). It can be used for 
the analysis of
  habitat selection when habitat can be considered to consist of several 
habitat types
  (e.g. vegetation types).

- A new class, the class "ltraj", is now available for the analysis of 
trajectories of animals
  (e.g. for the analysis of data collected using GPS collars). This 
class automatically
  computes the turning angles between successive moves, the absolute 
angles for each move,
  the speeds and the net squared displacement for each relocation. This 
class is to be
  prefered to the class "traj". The class "traj" is now deprecated.
  Note that the data set "puechcirc" is now of the class ltraj.

- The functions making the interface with the package "sp" have been 
updated: 'area2spol'
   converts an object of class 'area' into an object of class 
'SpatialPolygons'. 'spol2area' converts
   an object of class 'SpatialPolygons' or 'SpatialPolygonsDataFrame' 
into an object of class 'area'.
   'attpol2area' gets the data attribute of an object of class 
'SpatialPolygonsDataFrame'
   and stores is into a data frame. 'traj2spdf' converts an object of 
class 'traj' into an object of
   class 'SpatialPointsDataFrame'. 'traj2sldf' converts an object of 
class 'traj' into an object of
   class 'SpatialLinesDataFrame'.

- The function enfa() has been modified:
   The old components "co" and "l1" have been removed from objects of 
class "enfa", as they did not rely
   on solid mathematical theory. The old component "c1" is now named 
"co", and corresponds to
   the scores of habitat variables in the enfa (the squared norm of this 
vector is equal to 1 for
   the identity metric). As previously, the component "li" stores the 
scores of the resource units
   in the ENFA.

- The function df2kasc now accept objects of class "kasc" with one column.

- That's all, thanks for reading !

Questions, comments and suggestions are greatly appreciated.
Happy testing,


Cl??ment Calenge

-- 
Cl??ment CALENGE
LBBE - UMR CNRS 5558 - Universit?? 
Claude Bernard Lyon 1 - FRANCE
tel. (+33) 04.72.43.27.57
fax. (+33) 04.72.43.13.88

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From Matthias.Kohl at stamats.de  Thu Feb 23 09:41:34 2006
From: Matthias.Kohl at stamats.de (Matthias Kohl)
Date: Thu, 23 Feb 2006 09:41:34 +0100
Subject: [R] discrete probability distribution
In-Reply-To: <1BDB3E41-0FC6-4B26-A610-080CCB8E0E5F@soc.soton.ac.uk>
References: <1BDB3E41-0FC6-4B26-A610-080CCB8E0E5F@soc.soton.ac.uk>
Message-ID: <43FD753E.1020200@stamats.de>

Hi,

have a look at
http://mathworld.wolfram.com/GeometricDistribution.html
respectively
http://mathworld.wolfram.com/NegativeBinomialDistribution.html
with r = 1.

In R have a look at
?rnbinom
with n = 1 and in your case: prob = 1-p

hth
Matthias

>Hi
>
>I want to sample from a discrete random variable X,  defined on
>the  non-negative integers, with
>
>prob(X=0) = (1-p)
>prob(X=1) = (1-p)*p
>...
>prob(X=i)=(1-p)*p^i
>...
>
>
>
>Before reinventing the wheel,
>is there a ready-made R function to give me such a thing?
>
>
>--
>Robin Hankin
>Uncertainty Analyst
>National Oceanography Centre, Southampton
>European Way, Southampton SO14 3ZH, UK
>  tel  023-8059-7743
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>


-- 
StaMatS - Statistik + Mathematik Service
Dr. rer. nat. Matthias Kohl
Gottlieb-Keim-Stra??e 60
95448 Bayreuth
Phone: +49 921 50736457
E-Mail: matthias.kohl at stamats.de
Home: www.stamats.de



From sfelten at uwinst.unizh.ch  Thu Feb 23 10:06:37 2006
From: sfelten at uwinst.unizh.ch (Stefanie von Felten, IPW&IfU)
Date: Thu, 23 Feb 2006 10:06:37 +0100
Subject: [R] Questions for manipulating datasets in R e.g. sorting and
	matching
Message-ID: <43FD7B1D.2000602@uwinst.unizh.ch>

Hello everyone,

I want to sort a dataset in R, using multiple columns as sorting 
criteria. I know I can sort a dataset "Data" with 14 columns using one 
column (the fifth), by typing:

DataSort<-Data[order(Data[,5]),1:14]

But how can the dataset be sorted by column 5, then by 6, then by 8?

Another question is, how two datasets can be matched by a column present 
in both of them?

Steffi
-- 
---------------------------------
Stefanie von Felten
Doktorandin

ETH Z??rich
Institut f??r Pflanzenwissenschaften
ETH Zentrum, LFW A 2

Telefon: 044 632 85 97
Telefax: 044 632 11 53
e-mail:  stefanie.vonfelten at ipw.agrl.ethz.ch
http://www.ipw.agrl.ethz.ch/~svfelten/

und:

Universit??t Z??rich
Institut f??r Umweltwissenschaften
Winterthurerstrasse 190
8057 Z??rich

Telefon: 044 635 61 23
Telefax: 044 635 57 11
e-mail:  sfelten at uwinst.unizh.ch
http://www.unizh.ch/uwinst/homepages/steffi.html



From dimitris.rizopoulos at med.kuleuven.be  Thu Feb 23 10:17:38 2006
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Thu, 23 Feb 2006 10:17:38 +0100
Subject: [R] Questions for manipulating datasets in R e.g. sorting
	andmatching
References: <43FD7B1D.2000602@uwinst.unizh.ch>
Message-ID: <00a301c63859$fdec3b80$0540210a@www.domain>

regarding your 1st question you can still use order(), i.e., 
order(Data[,5], Data[,6], Data[,8]); regarding you 2nd question look 
at ?merge.

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/(0)16/336899
Fax: +32/(0)16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Stefanie von Felten, IPW&IfU" <sfelten at uwinst.unizh.ch>
To: <r-help at stat.math.ethz.ch>
Sent: Thursday, February 23, 2006 10:06 AM
Subject: [R] Questions for manipulating datasets in R e.g. sorting 
andmatching


Hello everyone,

I want to sort a dataset in R, using multiple columns as sorting
criteria. I know I can sort a dataset "Data" with 14 columns using one
column (the fifth), by typing:

DataSort<-Data[order(Data[,5]),1:14]

But how can the dataset be sorted by column 5, then by 6, then by 8?

Another question is, how two datasets can be matched by a column 
present
in both of them?

Steffi
-- 
---------------------------------
Stefanie von Felten
Doktorandin

ETH Z??rich
Institut f??r Pflanzenwissenschaften
ETH Zentrum, LFW A 2

Telefon: 044 632 85 97
Telefax: 044 632 11 53
e-mail:  stefanie.vonfelten at ipw.agrl.ethz.ch
http://www.ipw.agrl.ethz.ch/~svfelten/

und:

Universit??t Z??rich
Institut f??r Umweltwissenschaften
Winterthurerstrasse 190
8057 Z??rich

Telefon: 044 635 61 23
Telefax: 044 635 57 11
e-mail:  sfelten at uwinst.unizh.ch
http://www.unizh.ch/uwinst/homepages/steffi.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html


Disclaimer: http://www.kuleuven.be/cwis/email_disclaimer.htm



From Ted.Harding at nessie.mcc.ac.uk  Thu Feb 23 10:18:55 2006
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Thu, 23 Feb 2006 09:18:55 -0000 (GMT)
Subject: [R] discrete probability distribution
In-Reply-To: <1BDB3E41-0FC6-4B26-A610-080CCB8E0E5F@soc.soton.ac.uk>
Message-ID: <XFMail.060223091855.Ted.Harding@nessie.mcc.ac.uk>

On 23-Feb-06 Robin Hankin wrote:
> Hi
> 
> I want to sample from a discrete random variable X,  defined on
> the  non-negative integers, with
> 
> prob(X=0) = (1-p)
> prob(X=1) = (1-p)*p
> ...
> prob(X=i)=(1-p)*p^i
> ...
> 
> 
> 
> Before reinventing the wheel,
> is there a ready-made R function to give me such a thing?

Use rgeom(n,(1-p))

Note (from ?rgeom) that these functions use the definition

  P(n) = p*(1-p)^n

i.e. the complementary value of p to the one in your description.

Best wishes,
Ted.

--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 23-Feb-06                                       Time: 09:18:50
------------------------------ XFMail ------------------------------



From christian.montel at eligo.de  Thu Feb 23 10:29:05 2006
From: christian.montel at eligo.de (Christian Montel)
Date: Thu, 23 Feb 2006 10:29:05 +0100
Subject: [R] Questions for manipulating datasets in R e.g. sorting and
 matching
In-Reply-To: <43FD7B1D.2000602@uwinst.unizh.ch>
References: <43FD7B1D.2000602@uwinst.unizh.ch>
Message-ID: <43FD8061.3000001@eligo.de>

hi steffi,

try
DataSort<-Data[order(Data[,5],Data[,6],Data[,8]),1:14]

and for further details ?order. For matching try ?merge.

Best Regards,

Christian

Stefanie von Felten, IPW&IfU schrieb:
> Hello everyone,
> 
> I want to sort a dataset in R, using multiple columns as sorting 
> criteria. I know I can sort a dataset "Data" with 14 columns using one 
> column (the fifth), by typing:
> 
> DataSort<-Data[order(Data[,5]),1:14]
> 
> But how can the dataset be sorted by column 5, then by 6, then by 8?
> 
> Another question is, how two datasets can be matched by a column present 
> in both of them?
> 
> Steffi

-- 
Dr. Christian Montel
Eligo GmbH - B??ro Berlin
Friedrichstr. 90
10 117 Berlin
Fon (030) -- 20 25 31 94
Fax (030) -- 20 25 33 33
e-mail: christian.montel at eligo.de
http://www.eligo.de/



From ripley at stats.ox.ac.uk  Thu Feb 23 10:27:00 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 09:27:00 +0000 (GMT)
Subject: [R] Problems building R 2.2.1 with libgoto and SSE2 enabled
In-Reply-To: <200602230250.40687.iadzhubey@rics.bwh.harvard.edu>
References: <200602230250.40687.iadzhubey@rics.bwh.harvard.edu>
Message-ID: <Pine.LNX.4.64.0602230903070.29720@gannet.stats.ox.ac.uk>

[This sort of highly technical non-R issue would be better discussed on 
the R-devel list.  See the R posting guide.]

Do note the comments in the R-admin manual.  R requires proper results 
with IEEE754 specials (Infs and NaNs) and switching on fast arithmetic 
options often calls failures because of this.  It is not clear from your 
description what compiler you are using (presumably some version of gcc), 
and how it handles this.  Since gcc's AMD64 code makes use of such 
extensions it may be safe, but we don't know about your compiler/CPU 
combination.   Generally the advice is that it takes more time to 
investigate wrong results from over-optimization (as now, and it is not 
just your time in this case) than to make use of safer options.

However, without knowing what the failure is (look in the 
tests/foo.Rout.fail file) we can only speculate.

Building ATLAS should take only a couple of hours at most for platforms 
where there are good defaults, and that includes P4 on Linux.  I had a lot 
of problems on Opteron, basically because my machine was too fast for the 
timing loops (and you also need to ensure that PIC code is used).


On Thu, 23 Feb 2006, Ivan Adzhubey wrote:

> Hi,
>
> I am trying to build R 2.2.1 with Kazushige Goto's BLAS library (libgoto) and
> encountered a problem: I have two computers with the almost identical
> hardware (P4 Northwood CPU, i875 chipset, 2GB DDR400 RAM) and identical Linux
> OS. I have the latest version of libgoto for this CPU installed on both boxes
> (libgoto_northwood32p-r1.00.so) and I am using gcc compiler flags "-O2
> -march=pentium4 -mfpmath=sse -msse2" to enable use of SSE2 extensions. With
> one computer that works perfectly, while on the other one "make check"
> constantly fails on lm-test. If I remove "-mfpmath=sse -msse2" part from the
> gcc flags then all checks pass on the second computer too. Any hints on what
> may cause the error? Anyone willing to share his/her experience on building
> and using R with SSE2 and on libgoto performance in particular? I was
> planning to give ATLAS a try but pre-built binaries are not available for my
> distro and on my AMD Opteron cluster it took almost 48 hours to build. I am
> not sure my home computer (the one that gives me errors with libgoto/SSE2)
> would survive this.
>
> TIA,
> Ivan
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From b.otto at uke.uni-hamburg.de  Thu Feb 23 11:10:43 2006
From: b.otto at uke.uni-hamburg.de (Benjamin Otto)
Date: Thu, 23 Feb 2006 11:10:43 +0100
Subject: [R] automatic generation of variable names
Message-ID: <NOEOKKCPBGIAIPPDONMGMEOFCBAA.b.otto@uke.uni-hamburg.de>

Hi,

is there some way to generate a varaible name automatically?

What I would like to do is:

Instead
-------

table1 <- orderbysomecolumn
table2 <- orderbysomecolumn
table3 <- orderbysomecolumn
...

automate
--------
for (i in 1:numoftables) {
   table%someconcatenation%i <- orderbysomecolumn
}

regards,
Benjamin



From p.dalgaard at biostat.ku.dk  Thu Feb 23 11:26:03 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 23 Feb 2006 11:26:03 +0100
Subject: [R] Problems building R 2.2.1 with libgoto and SSE2 enabled
In-Reply-To: <200602230250.40687.iadzhubey@rics.bwh.harvard.edu>
References: <200602230250.40687.iadzhubey@rics.bwh.harvard.edu>
Message-ID: <x2u0aqmkw4.fsf@viggo.kubism.ku.dk>

Ivan Adzhubey <iadzhubey at rics.bwh.harvard.edu> writes:

> Hi,
> 
> I am trying to build R 2.2.1 with Kazushige Goto's BLAS library (libgoto) and 
> encountered a problem: I have two computers with the almost identical 
> hardware (P4 Northwood CPU, i875 chipset, 2GB DDR400 RAM) and identical Linux 
> OS. I have the latest version of libgoto for this CPU installed on both boxes 
> (libgoto_northwood32p-r1.00.so) and I am using gcc compiler flags "-O2 
> -march=pentium4 -mfpmath=sse -msse2" to enable use of SSE2 extensions. With 
> one computer that works perfectly, while on the other one "make check" 
> constantly fails on lm-test. If I remove "-mfpmath=sse -msse2" part from the 
> gcc flags then all checks pass on the second computer too. Any hints on what 
> may cause the error? 

Some hints, nothing conclusive:

Different gcc versions? glibc? (perhaps only one machine was updated).

Does libgoto factor into this at all? Will things still (not) work if
you omit it? If so, are you sure that both machines are picking it up
correctly?

Which test is failing?

> Anyone willing to share his/her experience on building 
> and using R with SSE2 and on libgoto performance in particular? I was 
> planning to give ATLAS a try but pre-built binaries are not available for my 
> distro and on my AMD Opteron cluster it took almost 48 hours to build. I am 
> not sure my home computer (the one that gives me errors with libgoto/SSE2) 
> would survive this.

Build times for ATLAS are highly dependent on platform. On P4, it is
usually quite fast (since most choices are known in advance). 11
*minutes* on the one I'm using to type this. 

(Why are you keeping your Linux distro a secret, BTW?)

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ligges at statistik.uni-dortmund.de  Thu Feb 23 11:32:12 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 23 Feb 2006 11:32:12 +0100
Subject: [R] automatic generation of variable names
In-Reply-To: <NOEOKKCPBGIAIPPDONMGMEOFCBAA.b.otto@uke.uni-hamburg.de>
References: <NOEOKKCPBGIAIPPDONMGMEOFCBAA.b.otto@uke.uni-hamburg.de>
Message-ID: <43FD8F2C.10502@statistik.uni-dortmund.de>

Benjamin Otto wrote:

> Hi,
> 
> is there some way to generate a varaible name automatically?


See the R FAQs: "How can I turn a string into a variable?"

Uwe Ligges




> What I would like to do is:
> 
> Instead
> -------
> 
> table1 <- orderbysomecolumn
> table2 <- orderbysomecolumn
> table3 <- orderbysomecolumn
> ...
> 
> automate
> --------
> for (i in 1:numoftables) {
>    table%someconcatenation%i <- orderbysomecolumn
> }
> 
> regards,
> Benjamin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From lescroel_cebc at no-log.org  Thu Feb 23 11:36:47 2006
From: lescroel_cebc at no-log.org (lescroel_cebc@no-log.org)
Date: Thu, 23 Feb 2006 11:36:47 +0100 (CET)
Subject: [R] Need confirmation of my lme() structure
Message-ID: <1393.lescroel_cebc.1140691007.squirrel@webmail.no-log.org>

Hello,

I'm a new user of R and I would need somebody to confirm (or not!) that
I'm doing right. I'm analyzing diving characteristics (maximal depth,
etc...) of birds breeding in 2 sites, during 2 stages (see data
structiring below).

   FILE        SITE      STAGE
M04    :402   C: 471   Guard:1557
M13    :344   M:2143   Incub:1057                                     M10 
  :252                                  M14    :209                       
          M15    :190                                  (Other):955

I want to analyse the effects of site and stage using REML analyses with
site and stage as fixed factors and file (i.e. individual bird) as a
random factor.
In R, I would write the following command:

> reml_depthmax <- lme(DEPTHMAX~SITE*STAGE, random=~1|FILE,
na.action=na.omit)

Am I right???

Many thanks for your help,

Am??lie


-- 
Am??lie Lescro??l, Ph.D.
Centre d'Etudes Biologiques de Chiz?? - CNRS, UPR 1934
79360 Villiers en Bois
France
http://www.cebc.cnrs.fr/Uk_taaf/equip_AL.html



From pmilin at ff.ns.ac.yu  Thu Feb 23 11:54:04 2006
From: pmilin at ff.ns.ac.yu (Petar Milin)
Date: Thu, 23 Feb 2006 11:54:04 +0100
Subject: [R] Strange p-level for the fixed effect with lme function
Message-ID: <1140692044.9023.16.camel@localhost.localdomain>

Hello,
I ran two lme analyses and got expected results. However, I saw
something suspicious regarding p-level for fixed effect. Models are the
same, only experimental designs differ and, of course, subjects. I am
aware that I could done nesting Subjects within Experiments, but it is
expected to have much slower RT (reaction time) in the second
experiment, since the task is more complex, so it would not make much
sense. That is why I kept analyses separated:

(A) lme(RT ~ F2 + MI, random =~ 1 | Subject, data = exp1)

ANOVA:
            numDF denDF   F-value p-value
(Intercept)     1  1379 243012.61  <.0001
F2              1  1379     47.55  <.0001
MI              1  1379      4.69  0.0305

Fixed effects: RT ~ F2 + MI
                Value  Std.Error   DF   t-value p-value
(Intercept)  6.430962 0.03843484 1379 167.32118  0.0000
F2          -0.028028 0.00445667 1379  -6.28896  0.0000
MI          -0.004058 0.00187358 1379  -2.16612  0.0305

===========================================================

(B) lme(RT ~ F2 + MI, random =~ 1 | Subject, data = exp2)

ANOVA:
            numDF denDF   F-value p-value
(Intercept)     1   659 150170.71  <.0001
F2              1   659     17.28  <.0001
MI              1   659     13.43   3e-04

Fixed effects: RT ~ F2 + MI
                Value  Std.Error  DF   t-value p-value
(Intercept)  6.608252 0.05100954 659 129.54935  0.0000
F2          -0.008679 0.00616191 659  -1.40855  0.1594
MI           0.009476 0.00258605 659   3.66420  0.0003

As you can see, in exp1 p-levels for the model and for the fixed effects
are the same, as thay should be, as far as I know. Yet, in exp2 there is
significant p for F2 in the model, but insignificant regarding F2 as
fixed factor. How is it possible? I have ran many linear models and
those two values correspond (or are the same). Anyway, how can it be to
have insignificant effect that is significant in the model? Some strange
property of that factor, like distribution? Multicolinearity? Please,
help me on that.

Sincerely,
Petar



From akayser at envico.ch  Thu Feb 23 12:01:48 2006
From: akayser at envico.ch (Achim Kayser)
Date: Thu, 23 Feb 2006 12:01:48 +0100
Subject: [R] tcl/tk - Problem unter MacOS X / X11
Message-ID: <43FD961C.4070609@envico.ch>

Hallo !

Ich habe versucht Rcmdr unter MacOSX 10.4.5 zu installieren. RGui zeigt 
an, dass tcl/tk laufen. Bei Aufruf von Rcmdr friert R jedoch komplett ein.
JGR zeigt im Paketmanager dagegen an, dass tcl/tk nicht gestartet werden 
konnte und spuckt folgende Meldung aus:


 > library(tcltk)
Loading Tcl/Tk interface ... Error in fun(...) : no display name and no 
$DISPLAY environment variable
Error: .onLoad failed in 'loadNamespace' for 'tcltk'
Error: package/namespace load failed for 'tcltk'
 >

Ideen ?

Achim



From p.dalgaard at biostat.ku.dk  Thu Feb 23 12:09:54 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 23 Feb 2006 12:09:54 +0100
Subject: [R] Strange p-level for the fixed effect with lme function
In-Reply-To: <1140692044.9023.16.camel@localhost.localdomain>
References: <1140692044.9023.16.camel@localhost.localdomain>
Message-ID: <x2lkw2miv1.fsf@viggo.kubism.ku.dk>

Petar Milin <pmilin at ff.ns.ac.yu> writes:

> Hello,
> I ran two lme analyses and got expected results. However, I saw
> something suspicious regarding p-level for fixed effect. Models are the
> same, only experimental designs differ and, of course, subjects. I am
> aware that I could done nesting Subjects within Experiments, but it is
> expected to have much slower RT (reaction time) in the second
> experiment, since the task is more complex, so it would not make much
> sense. That is why I kept analyses separated:
> 
> (A) lme(RT ~ F2 + MI, random =~ 1 | Subject, data = exp1)
> 
> ANOVA:
>             numDF denDF   F-value p-value
> (Intercept)     1  1379 243012.61  <.0001
> F2              1  1379     47.55  <.0001
> MI              1  1379      4.69  0.0305
> 
> Fixed effects: RT ~ F2 + MI
>                 Value  Std.Error   DF   t-value p-value
> (Intercept)  6.430962 0.03843484 1379 167.32118  0.0000
> F2          -0.028028 0.00445667 1379  -6.28896  0.0000
> MI          -0.004058 0.00187358 1379  -2.16612  0.0305
> 
> ===========================================================
> 
> (B) lme(RT ~ F2 + MI, random =~ 1 | Subject, data = exp2)
> 
> ANOVA:
>             numDF denDF   F-value p-value
> (Intercept)     1   659 150170.71  <.0001
> F2              1   659     17.28  <.0001
> MI              1   659     13.43   3e-04
> 
> Fixed effects: RT ~ F2 + MI
>                 Value  Std.Error  DF   t-value p-value
> (Intercept)  6.608252 0.05100954 659 129.54935  0.0000
> F2          -0.008679 0.00616191 659  -1.40855  0.1594
> MI           0.009476 0.00258605 659   3.66420  0.0003
> 
> As you can see, in exp1 p-levels for the model and for the fixed effects
> are the same, as thay should be, as far as I know. Yet, in exp2 there is
> significant p for F2 in the model, but insignificant regarding F2 as
> fixed factor. How is it possible? I have ran many linear models and
> those two values correspond (or are the same). Anyway, how can it be to
> have insignificant effect that is significant in the model? Some strange
> property of that factor, like distribution? Multicolinearity? Please,
> help me on that.

"Type I"... 

The  ANOVA is progressive, so refers to the situation *after* removing
MI from the model.  Try anova(lmefit, Terms="F2")

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From kubovy at virginia.edu  Thu Feb 23 12:21:11 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Thu, 23 Feb 2006 06:21:11 -0500
Subject: [R] JGR problem with installPackages()?
Message-ID: <B123CB05-277B-4E85-AA28-A05B6787FEDC@virginia.edu>

Dear r-helpers,

When I pull down the Packages:Package Installer menu, I get:
==================================
 > installPackages()
stack imbalance in .External, 22 then 66
stack imbalance in <-, 20 then 64
stack imbalance in <-, 117 then 118
stack imbalance in {, 115 then 116
stack imbalance in if, 113 then 114
stack imbalance in {, 111 then 112
stack imbalance in <-, 105 then 106
stack imbalance in {, 103 then 104
stack imbalance in for, 96 then 97
stack imbalance in {, 94 then 95
stack imbalance in if, 92 then 93
stack imbalance in {, 90 then 91
stack imbalance in if, 88 then 89
stack imbalance in {, 86 then 85
stack imbalance in standardGeneric, 78 then 77
stack imbalance in <-, 76 then 75
stack imbalance in {, 74 then 73
stack imbalance in {, 68 then 67
stack imbalance in {, 18 then 61
stack imbalance in <-, 12 then 55
stack imbalance in internal ls, 66 then 87stack imbalance  
in .Internal, 65 then 67
stack imbalance in <-, 63 then 65
stack imbalance in {, 61 then 63
stack imbalance in c, 53 then 55
stack imbalance in <-, 51 then 53
stack imbalance in {, 49 then 51
stack imbalance in for, 42 then 44
stack imbalance in {, 40 then 42
stack imbalance in {, 33 then 35
stack imbalance in if, 31 then 33
stack imbalance in {, 29 then 31
stack imbalance in .External, 67 then 24
stack imbalance in <-, 65 then 22
stack imbalance in if, 63 then 20
stack imbalance in {, 61 then 18
stack imbalance in invisible, 55 then 12
Warning message:
'CRAN.packages' is deprecated.
Use 'available.packages' instead.
See help("Deprecated")
====================================
running
----------
R version 2.2.1, 2005-12-20, powerpc-apple-darwin7.9.0

attached base packages:
[1] "datasets"  "methods"   "stats"     "utils"     "graphics"   
"grid"      "grDevices"
[8] "base"

other attached packages:
         nlme   simpleboot         boot     gridBase        Hmisc  
latticeExtra          car
   "3.1-68.1"      "1.1-1"     "1.2-24"      "0.4-2"      
"3.0-10"      "0.1-4"     "1.0-18"
         MASS       Matrix          JGR       JavaGD        rJava      
multcomp      mvtnorm
     "7.2-24"    "0.995-4"     "0.1-10"      "0.2-1"       
"0.3-6"      "0.4-8"      "0.7-2"
        abind      lattice
      "1.1-0"    "0.12-11"

Package:       JGR
Version:       0.1-10
Date:          2005-05-27
Title:         JGR - Java Gui for R
Built:         R 2.2.0; ; 2005-10-12 16:22:13; unix
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From murdoch at stats.uwo.ca  Thu Feb 23 12:54:03 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 23 Feb 2006 06:54:03 -0500
Subject: [R] automatic generation of variable names
In-Reply-To: <43FD8F2C.10502@statistik.uni-dortmund.de>
References: <NOEOKKCPBGIAIPPDONMGMEOFCBAA.b.otto@uke.uni-hamburg.de>
	<43FD8F2C.10502@statistik.uni-dortmund.de>
Message-ID: <43FDA25B.6090803@stats.uwo.ca>

On 2/23/2006 5:32 AM, Uwe Ligges wrote:
> Benjamin Otto wrote:
> 
>> Hi,
>>
>> is there some way to generate a varaible name automatically?
> 
> 
> See the R FAQs: "How can I turn a string into a variable?"

Especially the last bit of advice there, which suggests using a list 
instead.

Duncan Murdoch

> 
> Uwe Ligges
> 
> 
> 
> 
>> What I would like to do is:
>>
>> Instead
>> -------
>>
>> table1 <- orderbysomecolumn
>> table2 <- orderbysomecolumn
>> table3 <- orderbysomecolumn
>> ...
>>
>> automate
>> --------
>> for (i in 1:numoftables) {
>>    table%someconcatenation%i <- orderbysomecolumn
>> }
>>
>> regards,
>> Benjamin
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From amsa36060 at yahoo.com  Thu Feb 23 13:26:54 2006
From: amsa36060 at yahoo.com (Amir Safari)
Date: Thu, 23 Feb 2006 04:26:54 -0800 (PST)
Subject: [R] calculation problem
Message-ID: <20060223122654.78449.qmail@web60414.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060223/abba1b17/attachment.pl

From b.otto at uke.uni-hamburg.de  Thu Feb 23 13:45:15 2006
From: b.otto at uke.uni-hamburg.de (Benjamin Otto)
Date: Thu, 23 Feb 2006 13:45:15 +0100
Subject: [R] automatic generation of variable names
In-Reply-To: <43FDA25B.6090803@stats.uwo.ca>
Message-ID: <NOEOKKCPBGIAIPPDONMGMEOICBAA.b.otto@uke.uni-hamburg.de>

Thanks for the quick help! 

regards,
Benjamin



From pls at mevik.net  Thu Feb 23 09:18:29 2006
From: pls at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik_and_Ron_Wehrens?=)
Date: Thu, 23 Feb 2006 09:18:29 +0100
Subject: [R] [R-pkgs] pls version 1.2-0
Message-ID: <m0mzgi8p4a.fsf@bar.nemo-project.org>

Version 1.2-0 of the pls package is now available on CRAN.

The pls package implements partial least squares regression (PLSR) and
principal component regression (PCR).  Features of the package include

- Several plsr algorithms: orthogonal scores, kernel pls and simpls
- Flexible cross-validation
- A formula interface, with traditional methods like predict, coef,
  plot and summary
- Functions for extraction of scores and loadings, and calculation of
  (R)MSEP and R2
- A simple multiplicative scatter correction (msc) implementation
- Functions for plotting predictions, validation statistics,
  coefficients, scores, loadings, biplots and correlation loadings.

The main changes since 1.1-0 are

- predict() now handles missing data like the `lm' method does (the
  default is to predict `NA').
- fitted() and residuals() now return NA for observations with missing
  values, if na.action is na.exclude.
- `ncomp' is now reduced when it is too large for the requested 
  cross-validation.
- Line plot parameter arguments have been added to predplotXy(), so
  one can control the properties of the target line in predplot().
- MSEP(), RMSEP(), loadings(), loadingplot() and scoreplot() are now
  generic.


See the file CHANGES in the sources for all changes.

-- 
Ron Wehrens and Bj??rn-Helge Mevik

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From ripley at stats.ox.ac.uk  Thu Feb 23 14:04:49 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 13:04:49 +0000 (GMT)
Subject: [R] Strange p-level for the fixed effect with lme function
In-Reply-To: <1140692044.9023.16.camel@localhost.localdomain>
References: <1140692044.9023.16.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.64.0602231300240.3267@gannet.stats.ox.ac.uk>

What code did you actually run to get what you labelled as 'ANOVA'?

If this was anova[.lme], the default type is "sequential", whereas the 
t-values (from summary[.lme], I presume) are from marginal tests.

Whether sequential and marginal tests are similar or even the same is a 
question of balance in the design (for linear models as well).

On Thu, 23 Feb 2006, Petar Milin wrote:

> Hello,
> I ran two lme analyses and got expected results. However, I saw
> something suspicious regarding p-level for fixed effect. Models are the
> same, only experimental designs differ and, of course, subjects. I am
> aware that I could done nesting Subjects within Experiments, but it is
> expected to have much slower RT (reaction time) in the second
> experiment, since the task is more complex, so it would not make much
> sense. That is why I kept analyses separated:
>
> (A) lme(RT ~ F2 + MI, random =~ 1 | Subject, data = exp1)
>
> ANOVA:
>            numDF denDF   F-value p-value
> (Intercept)     1  1379 243012.61  <.0001
> F2              1  1379     47.55  <.0001
> MI              1  1379      4.69  0.0305
>
> Fixed effects: RT ~ F2 + MI
>                Value  Std.Error   DF   t-value p-value
> (Intercept)  6.430962 0.03843484 1379 167.32118  0.0000
> F2          -0.028028 0.00445667 1379  -6.28896  0.0000
> MI          -0.004058 0.00187358 1379  -2.16612  0.0305
>
> ===========================================================
>
> (B) lme(RT ~ F2 + MI, random =~ 1 | Subject, data = exp2)
>
> ANOVA:
>            numDF denDF   F-value p-value
> (Intercept)     1   659 150170.71  <.0001
> F2              1   659     17.28  <.0001
> MI              1   659     13.43   3e-04
>
> Fixed effects: RT ~ F2 + MI
>                Value  Std.Error  DF   t-value p-value
> (Intercept)  6.608252 0.05100954 659 129.54935  0.0000
> F2          -0.008679 0.00616191 659  -1.40855  0.1594
> MI           0.009476 0.00258605 659   3.66420  0.0003
>
> As you can see, in exp1 p-levels for the model and for the fixed effects
> are the same, as thay should be, as far as I know. Yet, in exp2 there is
> significant p for F2 in the model, but insignificant regarding F2 as
> fixed factor. How is it possible? I have ran many linear models and
> those two values correspond (or are the same). Anyway, how can it be to
> have insignificant effect that is significant in the model? Some strange
> property of that factor, like distribution? Multicolinearity? Please,
> help me on that.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From xmeng at capitalbio.com  Thu Feb 23 14:49:43 2006
From: xmeng at capitalbio.com (XinMeng)
Date: Thu, 23 Feb 2006 21:49:43 +0800
Subject: [R] read file of EXCEL format
Message-ID: <340702583.27265@capitalbio.com>


Hello sir:

How can I read data file of EXCEL format from disk("d:\\data.XLS" for example)?

I can only read data file of .txt format
read.delim("d:\\data.txt",header=T,as.is=T),but only EXCEL format is available at present.


Thanks a lot



From michael.watson at bbsrc.ac.uk  Thu Feb 23 14:33:08 2006
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Thu, 23 Feb 2006 13:33:08 -0000
Subject: [R] Bug in setting GUI to SDI mode?
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9503008357@iahce2ksrv1.iah.bbsrc.ac.uk>

Hi

I did a google search on this and came up with nothing.

OK, in the latest release of R for windows, I want to change the gui to
SDI mode.  

Edit -> GUI preferences
Choose SDI
Apply

I get the message about properties not being able to be changed on a
running console, and that I need to save.

So I click Save, and am met with a "Save As" dialogue box with the
default file called Rconsole, the file type as "All files".  I have no
idea where I actually have to save this.

I saved it in C:\Program File\R\2.2.1 anyway, restarted the console, and
SDI mode was not set.

I realiuse I can use the --sdi option on the command line, but I want to
know how to make this work through the GUI

Any help?

Thanks
Mick



From akayser at envico.ch  Thu Feb 23 14:37:34 2006
From: akayser at envico.ch (Achim Kayser)
Date: Thu, 23 Feb 2006 14:37:34 +0100
Subject: [R] tcl/tk - Install problem using MacOS X / X11
Message-ID: <43FDBA9E.2080805@envico.ch>

Hi

Sorry, my first post was in German.

I tried to get Rcmdr running under MacOS X 10.4.5. While RGui pretends 
that tcltk is running, starting Rcmdr freezes R completely.
Instead, JGR which gave me the following results:

 > library(tcltk)
Loading Tcl/Tk interface ... Error in fun(...) : no display name and no
$DISPLAY environment variable
Error: .onLoad failed in 'loadNamespace' for 'tcltk'
Error: package/namespace load failed for 'tcltk'
 >
I tried

Sys.putenv("DISPLAY"=":0")

which indeed resulted in a line in Rprofile:

## non standard settings for the R.app GUI of the Mac OS X port
if(.Platform$GUI == "AQUA") {
     ## this is set to let RAqua use both X11 device and
     ## X11/TclTk
     if (Sys.getenv("DISPLAY") == "")
	Sys.putenv("DISPLAY" = ":0")

     ## this is to allow g77 compiler to work
     Sys.putenv("PATH" = paste(Sys.getenv("PATH"),":/usr/local/bin",sep 
= ""))
}## end "Aqua"

Anay ideas what`s wrong ?

Regards

Achim



Hallo !

Ich habe versucht Rcmdr unter MacOSX 10.4.5 zu installieren. RGui zeigt
an, dass tcl/tk laufen. Bei Aufruf von Rcmdr friert R jedoch komplett ein.
JGR zeigt im Paketmanager dagegen an, dass tcl/tk nicht gestartet werden
konnte und spuckt folgende Meldung aus:


> library(tcltk)
Loading Tcl/Tk interface ... Error in fun(...) : no display name and no
$DISPLAY environment variable
Error: .onLoad failed in 'loadNamespace' for 'tcltk'
Error: package/namespace load failed for 'tcltk'
>

Ideen ?

Achim



From ccleland at optonline.net  Thu Feb 23 14:37:42 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 23 Feb 2006 08:37:42 -0500
Subject: [R] read file of EXCEL format
In-Reply-To: <340702583.27265@capitalbio.com>
References: <340702583.27265@capitalbio.com>
Message-ID: <43FDBAA6.2020302@optonline.net>

XinMeng wrote:
> Hello sir:
> 
> How can I read data file of EXCEL format from disk("d:\\data.XLS" for example)?
> 
> I can only read data file of .txt format
> read.delim("d:\\data.txt",header=T,as.is=T),but only EXCEL format is available at present.

Here is one way to read it directly:

library(RODBC)

z <- odbcConnectExcel("d:/data.xls")
       mydata <- sqlFetch(z, "Sheet1")
       close(z)

# Replace Sheet1 with the name of the worksheet to be read.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From sdavis2 at mail.nih.gov  Thu Feb 23 14:39:50 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 23 Feb 2006 08:39:50 -0500
Subject: [R] read file of EXCEL format
In-Reply-To: <340702583.27265@capitalbio.com>
Message-ID: <C0232556.66EF%sdavis2@mail.nih.gov>

http://cran.r-project.org/doc/manuals/R-data.html#Reading-Excel-spreadsheets


On 2/23/06 8:49 AM, "XinMeng" <xmeng at capitalbio.com> wrote:

> 
> Hello sir:
> 
> How can I read data file of EXCEL format from disk("d:\\data.XLS" for
> example)?
> 
> I can only read data file of .txt format
> read.delim("d:\\data.txt",header=T,as.is=T),but only EXCEL format is available
> at present.

Reading the manual is quite helpful for such things:

http://cran.r-project.org/doc/manuals/R-data.html#Reading-Excel-spreadsheets

Sean



From ripley at stats.ox.ac.uk  Thu Feb 23 14:39:58 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 13:39:58 +0000 (GMT)
Subject: [R] read file of EXCEL format
In-Reply-To: <340702583.27265@capitalbio.com>
References: <340702583.27265@capitalbio.com>
Message-ID: <Pine.LNX.4.64.0602231337340.4468@gannet.stats.ox.ac.uk>

Please see the 'R Data Import/Export Manual' which ships with every copy 
of R.

On Thu, 23 Feb 2006, XinMeng wrote:

> Hello sir:
>
> How can I read data file of EXCEL format from disk("d:\\data.XLS" for example)?
>
> I can only read data file of .txt format
> read.delim("d:\\data.txt",header=T,as.is=T),but only EXCEL format is available at present.

> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

PLEASE do!


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From aleszib2 at gmail.com  Thu Feb 23 14:50:13 2006
From: aleszib2 at gmail.com (Ales Ziberna)
Date: Thu, 23 Feb 2006 14:50:13 +0100
Subject: [R] Bug in setting GUI to SDI mode?
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9503008357@iahce2ksrv1.iah.bbsrc.ac.uk>
References: <8975119BCD0AC5419D61A9CF1A923E9503008357@iahce2ksrv1.iah.bbsrc.ac.uk>
Message-ID: <43FDBD94.3060500@gmail.com>

You should save it to

C:\Program File\R\2.2.1\etc

Best,
Ales Ziberna


michael watson (IAH-C) pravi:
> Hi
>
> I did a google search on this and came up with nothing.
>
> OK, in the latest release of R for windows, I want to change the gui to
> SDI mode.  
>
> Edit -> GUI preferences
> Choose SDI
> Apply
>
> I get the message about properties not being able to be changed on a
> running console, and that I need to save.
>
> So I click Save, and am met with a "Save As" dialogue box with the
> default file called Rconsole, the file type as "All files".  I have no
> idea where I actually have to save this.
>
> I saved it in C:\Program File\R\2.2.1 anyway, restarted the console, and
> SDI mode was not set.
>
> I realiuse I can use the --sdi option on the command line, but I want to
> know how to make this work through the GUI
>
> Any help?
>
> Thanks
> Mick
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From murdoch at stats.uwo.ca  Thu Feb 23 14:51:23 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 23 Feb 2006 08:51:23 -0500
Subject: [R] Bug in setting GUI to SDI mode?
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9503008357@iahce2ksrv1.iah.bbsrc.ac.uk>
References: <8975119BCD0AC5419D61A9CF1A923E9503008357@iahce2ksrv1.iah.bbsrc.ac.uk>
Message-ID: <43FDBDDB.1030505@stats.uwo.ca>

On 2/23/2006 8:33 AM, michael watson (IAH-C) wrote:
> Hi
> 
> I did a google search on this and came up with nothing.
> 
> OK, in the latest release of R for windows, I want to change the gui to
> SDI mode.  
> 
> Edit -> GUI preferences
> Choose SDI
> Apply
> 
> I get the message about properties not being able to be changed on a
> running console, and that I need to save.
> 
> So I click Save, and am met with a "Save As" dialogue box with the
> default file called Rconsole, the file type as "All files".  I have no
> idea where I actually have to save this.
> 
> I saved it in C:\Program File\R\2.2.1 anyway, restarted the console, and
> SDI mode was not set.
> 
> I realiuse I can use the --sdi option on the command line, but I want to
> know how to make this work through the GUI
> 
> Any help?

See the ?Rconsole man page.  The search is somewhat complicated; it's up 
to you to decide whether you want the setting to apply just to your user 
(it should be in the R_USER directory), or be the default for all users 
(it should be in the R_HOME/etc directory).  For me, the default 
location for saving is the R_USER directory; I suspect it's the same 
default for you, but I haven't actually checked the code.

Duncan Murdoch



From ligges at statistik.uni-dortmund.de  Thu Feb 23 14:55:04 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 23 Feb 2006 14:55:04 +0100
Subject: [R] Bug in setting GUI to SDI mode?
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9503008357@iahce2ksrv1.iah.bbsrc.ac.uk>
References: <8975119BCD0AC5419D61A9CF1A923E9503008357@iahce2ksrv1.iah.bbsrc.ac.uk>
Message-ID: <43FDBEB8.4060702@statistik.uni-dortmund.de>

michael watson (IAH-C) wrote:

> Hi
> 
> I did a google search on this and came up with nothing.
> 
> OK, in the latest release of R for windows, I want to change the gui to
> SDI mode.  
> 
> Edit -> GUI preferences
> Choose SDI
> Apply
> 
> I get the message about properties not being able to be changed on a
> running console, and that I need to save.
> 
> So I click Save, and am met with a "Save As" dialogue box with the
> default file called Rconsole, the file type as "All files".  I have no
> idea where I actually have to save this.

See ?Rconsole and the R for Windows FAQs

Uwe Ligges


> I saved it in C:\Program File\R\2.2.1 anyway, restarted the console, and
> SDI mode was not set.
> 
> I realiuse I can use the --sdi option on the command line, but I want to
> know how to make this work through the GUI
> 
> Any help?
>
> Thanks
> Mick
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sundar.dorai-raj at pdf.com  Thu Feb 23 14:56:11 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 23 Feb 2006 05:56:11 -0800
Subject: [R] Bug in setting GUI to SDI mode?
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9503008357@iahce2ksrv1.iah.bbsrc.ac.uk>
References: <8975119BCD0AC5419D61A9CF1A923E9503008357@iahce2ksrv1.iah.bbsrc.ac.uk>
Message-ID: <43FDBEFB.3000406@pdf.com>



michael watson (IAH-C) wrote:
> Hi
> 
> I did a google search on this and came up with nothing.
> 
> OK, in the latest release of R for windows, I want to change the gui to
> SDI mode.  
> 
> Edit -> GUI preferences
> Choose SDI
> Apply
> 
> I get the message about properties not being able to be changed on a
> running console, and that I need to save.
> 
> So I click Save, and am met with a "Save As" dialogue box with the
> default file called Rconsole, the file type as "All files".  I have no
> idea where I actually have to save this.
> 
> I saved it in C:\Program File\R\2.2.1 anyway, restarted the console, and
> SDI mode was not set.
> 
> I realiuse I can use the --sdi option on the command line, but I want to
> know how to make this work through the GUI
> 
> Any help?
> 
> Thanks
> Mick
> 

So, what's the "bug"? You need to save in

$R_HOME\etc

where $R_HOME is the directory where you have R installed. (Your example 
directory above seems odd - is it a typo?).

BTW, this is in the rw-FAQ 5.2. Or you can read ?Rconsole.

HTH,

--sundar



From andy_liaw at merck.com  Thu Feb 23 14:56:36 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 23 Feb 2006 08:56:36 -0500
Subject: [R] Bug in setting GUI to SDI mode?
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED84B@usctmx1106.merck.com>

The file needs to be in R_HOME\etc.  See ?Rconsole.

Andy

From: michael watson (IAH-C)
> 
> Hi
> 
> I did a google search on this and came up with nothing.
> 
> OK, in the latest release of R for windows, I want to change 
> the gui to
> SDI mode.  
> 
> Edit -> GUI preferences
> Choose SDI
> Apply
> 
> I get the message about properties not being able to be changed on a
> running console, and that I need to save.
> 
> So I click Save, and am met with a "Save As" dialogue box with the
> default file called Rconsole, the file type as "All files".  I have no
> idea where I actually have to save this.
> 
> I saved it in C:\Program File\R\2.2.1 anyway, restarted the 
> console, and
> SDI mode was not set.
> 
> I realiuse I can use the --sdi option on the command line, 
> but I want to
> know how to make this work through the GUI
> 
> Any help?
> 
> Thanks
> Mick
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From michael.watson at bbsrc.ac.uk  Thu Feb 23 14:58:55 2006
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Thu, 23 Feb 2006 13:58:55 -0000
Subject: [R] Bug in setting GUI to SDI mode?
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9503008363@iahce2ksrv1.iah.bbsrc.ac.uk>

Woops!

RTFM for me :(

Thanks everyone for your help.

Mick 

-----Original Message-----
From: Liaw, Andy [mailto:andy_liaw at merck.com] 
Sent: 23 February 2006 13:57
To: michael watson (IAH-C); r-help at stat.math.ethz.ch
Subject: RE: [R] Bug in setting GUI to SDI mode?

The file needs to be in R_HOME\etc.  See ?Rconsole.

Andy

From: michael watson (IAH-C)
> 
> Hi
> 
> I did a google search on this and came up with nothing.
> 
> OK, in the latest release of R for windows, I want to change the gui 
> to SDI mode.
> 
> Edit -> GUI preferences
> Choose SDI
> Apply
> 
> I get the message about properties not being able to be changed on a 
> running console, and that I need to save.
> 
> So I click Save, and am met with a "Save As" dialogue box with the 
> default file called Rconsole, the file type as "All files".  I have no

> idea where I actually have to save this.
> 
> I saved it in C:\Program File\R\2.2.1 anyway, restarted the console, 
> and SDI mode was not set.
> 
> I realiuse I can use the --sdi option on the command line, but I want 
> to know how to make this work through the GUI
> 
> Any help?
> 
> Thanks
> Mick
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


------------------------------------------------------------------------
------
Notice:  This e-mail message, together with any attachments,...{{dropped}}



From bady at univ-lyon1.fr  Thu Feb 23 15:07:38 2006
From: bady at univ-lyon1.fr (bady@univ-lyon1.fr)
Date: Thu, 23 Feb 2006 15:07:38 +0100
Subject: [R] read file of EXCEL format
In-Reply-To: <340702583.27265@capitalbio.com>
References: <340702583.27265@capitalbio.com>
Message-ID: <1140703658.43fdc1aa9b615@webmail.univ-lyon1.fr>

hi, hi all,

there are several possibilities to import data in Excel format.
you can use the fonctions "odbcConnectExcel","read.xls", ...
(see http://cran.r-project.org/doc/manuals/R-data.html)

require(RODBC)
?odbcConnect

library(gdata)
?read.xls


regards,


P.BADY



Selon XinMeng <xmeng at capitalbio.com>:

>
> Hello sir:
>
> How can I read data file of EXCEL format from disk("d:\\data.XLS" for
> example)?
>
> I can only read data file of .txt format
> read.delim("d:\\data.txt",header=T,as.is=T),but only EXCEL format is
> available at present.
>
>
> Thanks a lot
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>




--------------------------------------------------------------------------
Ce message a ??t?? envoy?? depuis le webmail IMP (Internet Messaging Program)



From ripley at stats.ox.ac.uk  Thu Feb 23 15:14:52 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 14:14:52 +0000 (GMT)
Subject: [R] User Bug in setting GUI to SDI mode?
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E9503008357@iahce2ksrv1.iah.bbsrc.ac.uk>
References: <8975119BCD0AC5419D61A9CF1A923E9503008357@iahce2ksrv1.iah.bbsrc.ac.uk>
Message-ID: <Pine.LNX.4.64.0602231409570.15257@gannet.stats.ox.ac.uk>

On Thu, 23 Feb 2006, michael watson (IAH-C) wrote:

> I did a google search on this and came up with nothing.

You were asked (in the posting guide) to read the R documentation, and 
this _is_ in the rw-FAQ and also in ?Rconsole.

> OK, in the latest release of R for windows, I want to change the gui to
> SDI mode.
>
> Edit -> GUI preferences
> Choose SDI
> Apply
>
> I get the message about properties not being able to be changed on a
> running console, and that I need to save.
>
> So I click Save, and am met with a "Save As" dialogue box with the
> default file called Rconsole, the file type as "All files".  I have no
> idea where I actually have to save this.
>
> I saved it in C:\Program File\R\2.2.1 anyway, restarted the console, and
> SDI mode was not set.

As documented.

> I realiuse I can use the --sdi option on the command line, but I want to
> know how to make this work through the GUI

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From alexa at cenpat.edu.ar  Thu Feb 23 15:27:55 2006
From: alexa at cenpat.edu.ar (alexa@cenpat.edu.ar)
Date: Thu, 23 Feb 2006 11:27:55 -0300
Subject: [R] partial mantel test
Message-ID: <43FD9C3B.29602.6FC390@localhost>

I would like to know how to run  a partial mantel test controlling for spatial 
autocorrelation and correlation with other environmental variables. It seems that 
with function included in vegan for partial mantel test I can only test for the 
relationship between two variables controlling for the effect of a third one.
Thanks a lot
Alexandra
---
Lic. Alexandra Sapoznikow
Centro Nacional Patagonico - CENPAT - CONICET
Bvd. Brown S/N
Puerto Madryn, Chubut, Argentina
Tel: 54-2965/451024/450401/451301/451375
Fax: 54-2965/45154
E-mail: alexa at cenpat.edu.ar



From amsa36060 at yahoo.com  Thu Feb 23 15:31:42 2006
From: amsa36060 at yahoo.com (Amir Safari)
Date: Thu, 23 Feb 2006 06:31:42 -0800 (PST)
Subject: [R] Cross-validation in SVM
Message-ID: <20060223143142.93005.qmail@web60413.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060223/a2b11a00/attachment.pl

From amsa36060 at yahoo.com  Thu Feb 23 15:56:12 2006
From: amsa36060 at yahoo.com (Amir Safari)
Date: Thu, 23 Feb 2006 06:56:12 -0800 (PST)
Subject: [R] locpoly
Message-ID: <20060223145612.26895.qmail@web60417.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060223/edb31b9c/attachment.pl

From jfox at mcmaster.ca  Thu Feb 23 16:04:59 2006
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 23 Feb 2006 10:04:59 -0500
Subject: [R] tcl/tk - Install problem using MacOS X / X11
In-Reply-To: <43FDBA9E.2080805@envico.ch>
Message-ID: <20060223150459.ZITE27612.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear Achim,

I'm not a Mac user, so can only offer limited help, but I wonder whether
you've looked at the Rcmdr installation notes at
<http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>?
There are instructions there for getting the Rcmdr package working on Macs.

I hope that this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Achim Kayser
> Sent: Thursday, February 23, 2006 8:38 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] tcl/tk - Install problem using MacOS X / X11
> 
> Hi
> 
> Sorry, my first post was in German.
> 
> I tried to get Rcmdr running under MacOS X 10.4.5. While RGui 
> pretends that tcltk is running, starting Rcmdr freezes R completely.
> Instead, JGR which gave me the following results:
> 
>  > library(tcltk)
> Loading Tcl/Tk interface ... Error in fun(...) : no display 
> name and no $DISPLAY environment variable
> Error: .onLoad failed in 'loadNamespace' for 'tcltk'
> Error: package/namespace load failed for 'tcltk'
>  >
> I tried
> 
> Sys.putenv("DISPLAY"=":0")
> 
> which indeed resulted in a line in Rprofile:
> 
> ## non standard settings for the R.app GUI of the Mac OS X 
> port if(.Platform$GUI == "AQUA") {
>      ## this is set to let RAqua use both X11 device and
>      ## X11/TclTk
>      if (Sys.getenv("DISPLAY") == "")
> 	Sys.putenv("DISPLAY" = ":0")
> 
>      ## this is to allow g77 compiler to work
>      Sys.putenv("PATH" = 
> paste(Sys.getenv("PATH"),":/usr/local/bin",sep
> = ""))
> }## end "Aqua"
> 
> Anay ideas what`s wrong ?
> 
> Regards
> 
> Achim
> 
> 
> 
> Hallo !
> 
> Ich habe versucht Rcmdr unter MacOSX 10.4.5 zu installieren. 
> RGui zeigt an, dass tcl/tk laufen. Bei Aufruf von Rcmdr 
> friert R jedoch komplett ein.
> JGR zeigt im Paketmanager dagegen an, dass tcl/tk nicht 
> gestartet werden konnte und spuckt folgende Meldung aus:
> 
> 
> > library(tcltk)
> Loading Tcl/Tk interface ... Error in fun(...) : no display 
> name and no $DISPLAY environment variable
> Error: .onLoad failed in 'loadNamespace' for 'tcltk'
> Error: package/namespace load failed for 'tcltk'
> >
> 
> Ideen ?
> 
> Achim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From peterdlauren at yahoo.com  Thu Feb 23 16:32:13 2006
From: peterdlauren at yahoo.com (Peter Lauren)
Date: Thu, 23 Feb 2006 07:32:13 -0800 (PST)
Subject: [R] Problem with List() Inside Function
Message-ID: <20060223153213.8000.qmail@web30302.mail.mud.yahoo.com>

I have a function declared thus.
FirstEigenvectorBoundary.Training <-
function(InputFileName='C:/Samples2/PT_Amp.txt',
Header=TRUE, Colour="red")

Inside the function, I have the following call

out<-list(x=Eigenvectors[2:(NumMetricsSelected+1),1],
y=-0.8, z=NumMetricsSelected);

NumMetricsSelected has the value 2 and Eigenvectors
has the following form
           [,1]       [,2]       [,3]
[1,]  0.6404630 -0.2153989  0.7371638
[2,] -0.6081319  0.4439621  0.6580830
[3,]  0.4690231  0.8697706 -0.1533503

When I do it manually at the console, I get the
correct result.  I.e.
> out
$x
[1] -0.6081319  0.4690231

$y
[1] -0.8

$z
[1] 2

However, when I call the function like this
> Training<-FirstEigenvectorBoundary.Training()

I get
>Training
$x
[1] 0.658083

$y
[1] -0.8

$z
[1] 2

That is, the $x element has only one value (instead of
2) and it is from the wrong part of the matrix.

Can anyone see what I am doing wrong?

Thanks very much,
Peter.



From michael.watson at bbsrc.ac.uk  Thu Feb 23 16:35:22 2006
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Thu, 23 Feb 2006 15:35:22 -0000
Subject: [R] Changing the x-axis labels in plot()
Message-ID: <8975119BCD0AC5419D61A9CF1A923E950300838F@iahce2ksrv1.iah.bbsrc.ac.uk>

Hi

Hopefully this one isn't in the manual or I am about to get shot :-S

One of my colleagues wants a slightly strange graph.  We basically have
a data matrix, and she wants to plot, for each row, the values in the
row as points on the graph.  The following code draws the graph just
fine:

plot(row(d)[,3:9],d[,3:9])

So as there are 12 rows in my matrix, there are 12 columns of points,
which is what she wants.

However, she wants the x-axis labelled with the row names, not with
1,2,3,4,5 etc

I can figure out from reading par() how to turn off the default drawing
of the numerical labels, but how do I use the row names instead?

Thanks
Mick



From sarah.goslee at gmail.com  Thu Feb 23 16:48:25 2006
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 23 Feb 2006 10:48:25 -0500
Subject: [R] partial mantel test
In-Reply-To: <43FD9C3B.29602.6FC390@localhost>
References: <43FD9C3B.29602.6FC390@localhost>
Message-ID: <efb536d50602230748s4bec65d4y71fb6a732046acd3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060223/d08d2416/attachment.pl

From goedman at mac.com  Thu Feb 23 17:01:11 2006
From: goedman at mac.com (Rob J Goedman)
Date: Thu, 23 Feb 2006 08:01:11 -0800
Subject: [R] tcl/tk - Problem unter MacOS X / X11
In-Reply-To: <43FD961C.4070609@envico.ch>
References: <43FD961C.4070609@envico.ch>
Message-ID: <7299CA20-C1BB-4D67-AF7D-FEB6C7C1A84B@mac.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060223/db090d7f/attachment.pl

From Achim.Zeileis at wu-wien.ac.at  Thu Feb 23 17:19:25 2006
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 23 Feb 2006 17:19:25 +0100 (CET)
Subject: [R] Cross-validation in SVM
In-Reply-To: <20060223143142.93005.qmail@web60413.mail.yahoo.com>
References: <20060223143142.93005.qmail@web60413.mail.yahoo.com>
Message-ID: <Pine.LNX.4.58.0602231717050.17370@thorin.ci.tuwien.ac.at>

On Thu, 23 Feb 2006, Amir Safari wrote:

> Calculation of Cross-Validation for SVM, with thoese time series which
> include negative and positive values ( for example return of a stock
> exchange index) must be different from a calculation of Cross-Validation
> with time series which includes just absolute values( for example a
> stock exchange index).

Not necessarily, depends on the type of data.

> How is it calculated for a return time series?

>From the man page of svm():

   cross: if a integer value k>0 is specified, a k-fold cross
          validation on the training data is performed to assess the
          quality of the model: the accuracy rate for classification
          and the Mean Squared Error for regression

i.e., MSE will be used.
Z



From ales.ziberna at gmail.com  Thu Feb 23 17:21:44 2006
From: ales.ziberna at gmail.com (=?windows-1252?Q?Ale=9A_=8Eiberna?=)
Date: Thu, 23 Feb 2006 17:21:44 +0100
Subject: [R] Convertin rows of a matrix to a list
In-Reply-To: <43FB5D69.8020409@pburns.seanet.com>
References: <43FB5713.40808@gmail.com> <43FB5D69.8020409@pburns.seanet.com>
Message-ID: <43FDE118.3010506@gmail.com>

Thanks to all,
especially to Patrick Burns, who's solution is the fastest!

Best regards,
Ales

Patrick Burns pravi:
> Untried, but does this work for you:
>
> split(mat, row(mat))
>
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
>
> Ale? ?iberna wrote:
>
>> Hello!
>>
>> I would like to convert rows of a matrix to a elements of a list.
>>
>> #For example, if I have
>> mat<-matrix(1:100,ncol=5, nrow=20)
>>
>> #I can do:
>> list<-apply(mat,1,list)
>> list
>> #however this is not quite what I want. To get what I want, I have to 
>> do:
>> list<-lapply(list,function(x)x[[1]])
>> list
>>
>> Is there a faster way?
>>
>> Best regards,
>> Ales Ziberna
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>>
>>
>>  
>>
>
>



From akayser at envico.ch  Thu Feb 23 17:24:39 2006
From: akayser at envico.ch (Achim Kayser)
Date: Thu, 23 Feb 2006 17:24:39 +0100
Subject: [R] tcl/tk - Problem unter MacOS X / X11
In-Reply-To: <7299CA20-C1BB-4D67-AF7D-FEB6C7C1A84B@mac.com>
References: <43FD961C.4070609@envico.ch>
	<7299CA20-C1BB-4D67-AF7D-FEB6C7C1A84B@mac.com>
Message-ID: <43FDE1C7.20904@envico.ch>

Thanks Rob !

That was it ! I had forgotten two of them. Now the GUI comes up nicely.
I' ll test it out an keep you posted.

Regards

Achim


Rob J Goedman schrieb:
> Achim,
>
> For the RGUI part:
>
> Have you installed the required packages for Rcmdr (e.g. abind, car, 
> effects, lmtest, multcomp, mvtnorm, relimp, sandwich, strucchange, and 
> zoo)?
>
> Rob
>
> On Feb 23, 2006, at 3:01 AM, Achim Kayser wrote:
>
>> Hallo !
>>
>> Ich habe versucht Rcmdr unter MacOSX 10.4.5 zu installieren. RGui zeigt 
>> an, dass tcl/tk laufen. Bei Aufruf von Rcmdr friert R jedoch komplett 
>> ein.
>> JGR zeigt im Paketmanager dagegen an, dass tcl/tk nicht gestartet werden 
>> konnte und spuckt folgende Meldung aus:
>>
>>
>>> library(tcltk)
>> Loading Tcl/Tk interface ... Error in fun(...) : no display name and no 
>> $DISPLAY environment variable
>> Error: .onLoad failed in 'loadNamespace' for 'tcltk'
>> Error: package/namespace load failed for 'tcltk'
>>>
>>
>> Ideen ?
>>
>> Achim
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch <mailto:R-help at stat.math.ethz.ch> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>



From pzs6 at CDC.GOV  Thu Feb 23 17:24:51 2006
From: pzs6 at CDC.GOV (Smith, Phil)
Date: Thu, 23 Feb 2006 11:24:51 -0500
Subject: [R] svyby and svyratio in the Thomas Lumley's  survey package
References: <2554377D323C9A40BD69956059FD05490ED452F1@mnip1>
Message-ID: <2554377D323C9A40BD69956059FD05490ED452FC@mnip1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060223/a411810c/attachment.pl

From gunter.berton at gene.com  Thu Feb 23 17:34:15 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 23 Feb 2006 08:34:15 -0800
Subject: [R] Changing the x-axis labels in plot()
Message-ID: <002a01c63896$fc662400$711f210a@gne.windows.gene.com>

 

Please learn how to use R's extensive Help capabilities -- It **is** in the
"manual" -- and also in the R-help archives.

help.search('axis')  (obvious keyword, no?) will get you what you want.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> michael watson (IAH-C)
> Sent: Thursday, February 23, 2006 7:35 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Changing the x-axis labels in plot()
> 
> Hi
> 
> Hopefully this one isn't in the manual or I am about to get shot :-S
> 
> One of my colleagues wants a slightly strange graph.  We 
> basically have
> a data matrix, and she wants to plot, for each row, the values in the
> row as points on the graph.  The following code draws the graph just
> fine:
> 
> plot(row(d)[,3:9],d[,3:9])
> 
> So as there are 12 rows in my matrix, there are 12 columns of points,
> which is what she wants.
> 
> However, she wants the x-axis labelled with the row names, not with
> 1,2,3,4,5 etc
> 
> I can figure out from reading par() how to turn off the 
> default drawing
> of the numerical labels, but how do I use the row names instead?
> 
> Thanks
> Mick
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From henrik.parn at bio.ntnu.no  Thu Feb 23 17:40:19 2006
From: henrik.parn at bio.ntnu.no (Henrik Parn)
Date: Thu, 23 Feb 2006 17:40:19 +0100
Subject: [R] dist() between groups of data
Message-ID: <43FDE573.7070603@bio.ntnu.no>

Dear all,

I have a data set with x and y positions of nests. Each nest can be 
grouped according to a factor z. I have made a small dummy data set, 
where the grouping variable z is 0 or 1:

x <- runif(6)
y <- runif(6)
z <- rep(c(0,1), each=3)
xyz <- cbind(x,y,z)
xyz
             x           y z
[1,] 0.7176801 0.760944688 0
[2,] 0.2377928 0.080622524 0
[3,] 0.9450770 0.022039470 0
[4,] 0.8725492 0.971996677 1
[5,] 0.6356198 0.001569859 1
[6,] 0.8949670 0.066044377 1


First of all, I suppose that this is the correct way to calculate the 
Euclidean distance between /all/ nests:

xy <- cbind(x,y)
d.all <- dist(xy)


However, I would like to obtain a distance matrix for distances between 
nests belonging to certain groups. For example "calculate all distances 
from nests where z equals something, to nests where z equals something 
else".

Is it best to split the data in two matrices according to the value of z 
in the two groups to be compared, and then try to follow the suggestions 
by Gabor Grothendieck* Date:* Wed 07 Jan 2004 - 15:16:37 EST , or are 
there other ways that can be applied straight to one matrix?


Thanks in advance!

Henrik











-- 
************************
Henrik P??rn
Department of Biology
NTNU
7491 Trondheim
Norway

+47 735 96282 (office)
+47 909 89 255 (mobile)
+47 735 96100 (fax)



From edd at debian.org  Thu Feb 23 17:54:39 2006
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 23 Feb 2006 10:54:39 -0600
Subject: [R]  Feature request in setting GUI to SDI mode?
In-Reply-To: <Pine.LNX.4.64.0602231409570.15257@gannet.stats.ox.ac.uk>
References: <8975119BCD0AC5419D61A9CF1A923E9503008357@iahce2ksrv1.iah.bbsrc.ac.uk>
	<Pine.LNX.4.64.0602231409570.15257@gannet.stats.ox.ac.uk>
Message-ID: <17405.59599.227408.573739@basebud.nulle.part>


R looks for Rconsole in $HOME as well. I don't like to cluster $HOME with
visible files, so I was wondering if R could also look for

	$HOME/.Rconsole

to hide Rconsole in $HOME. That would be the best of both worlds.

Thanks, Dirk

-- 
Hell, there are no rules here - we're trying to accomplish something. 
                                                  -- Thomas A. Edison



From mschwartz at mn.rr.com  Thu Feb 23 17:55:59 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 23 Feb 2006 10:55:59 -0600
Subject: [R] Changing the x-axis labels in plot()
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E950300838F@iahce2ksrv1.iah.bbsrc.ac.uk>
References: <8975119BCD0AC5419D61A9CF1A923E950300838F@iahce2ksrv1.iah.bbsrc.ac.uk>
Message-ID: <1140713759.4533.14.camel@localhost.localdomain>

On Thu, 2006-02-23 at 15:35 +0000, michael watson (IAH-C) wrote:
> Hi
> 
> Hopefully this one isn't in the manual or I am about to get shot :-S

Bang  ;-)

> One of my colleagues wants a slightly strange graph.  We basically have
> a data matrix, and she wants to plot, for each row, the values in the
> row as points on the graph.  The following code draws the graph just
> fine:
> 
> plot(row(d)[,3:9],d[,3:9])


If I am understanding correctly what you want, you could alternatively
use:

  boxplot(as.data.frame(t(d[, 3:9])))

which provides a somewhat different approach to visualizing the data.
There are other methods as well of course.

> So as there are 12 rows in my matrix, there are 12 columns of points,
> which is what she wants.
> 
> However, she wants the x-axis labelled with the row names, not with
> 1,2,3,4,5 etc
> 
> I can figure out from reading par() how to turn off the default drawing
> of the numerical labels, but how do I use the row names instead?
> 
> Thanks
> Mick


Try:

  plot(row(d)[,3:9], d[,3:9], xaxt = "n")


You can then use the axis() function to specify the labels and tick mark
positions that you want. See ?axis for more information.

In ?par, see 'xaxt' and 'yaxt', which are also referred to in the
description of the 'axes' argument in ?plot.default.

HTH,

Marc Schwartz



From h.wickham at gmail.com  Thu Feb 23 17:56:21 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 23 Feb 2006 10:56:21 -0600
Subject: [R] do.call, browser and traceback
In-Reply-To: <971536df0602201658p5348089lb4afb0697c04f6de@mail.gmail.com>
References: <f8e6ff050602201649h40e47c64u43307ae3cab716a9@mail.gmail.com>
	<971536df0602201658p5348089lb4afb0697c04f6de@mail.gmail.com>
Message-ID: <f8e6ff050602230856w296f729bp1eaaaddbe71a3b78@mail.gmail.com>

> If f is long then you can get some savings like this:
>
>   do.call("f", mtcars)  # note: used "f" rather than f
>

Unfortunately, my f is a character vector containing the function I
want to call.  Thanks for the idea though.

Hadley



From murdoch at stats.uwo.ca  Thu Feb 23 18:13:43 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 23 Feb 2006 12:13:43 -0500
Subject: [R] locpoly
In-Reply-To: <20060223145612.26895.qmail@web60417.mail.yahoo.com>
References: <20060223145612.26895.qmail@web60417.mail.yahoo.com>
Message-ID: <43FDED47.5060707@stats.uwo.ca>

On 2/23/2006 9:56 AM, Amir Safari wrote:
>  
>    
>    Dear R Users,
>   When using locpoly function, number of output values is smaller than the number of input values. How is it possible to get number of output component $y equal to the number of inputs.

You could use linear interpolation on its outputs, e.g.

x <- runif(20)
y <- x^2 + rnorm(20)

fit <- locpoly(x, y, bandwidth=0.3)
fitfn <- approxfun(fit$x, fit$y)
yhat <- fitfn(x)

Duncan Murdoch



From murdoch at stats.uwo.ca  Thu Feb 23 18:15:39 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 23 Feb 2006 12:15:39 -0500
Subject: [R] Changing the x-axis labels in plot()
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E950300838F@iahce2ksrv1.iah.bbsrc.ac.uk>
References: <8975119BCD0AC5419D61A9CF1A923E950300838F@iahce2ksrv1.iah.bbsrc.ac.uk>
Message-ID: <43FDEDBB.1050406@stats.uwo.ca>

On 2/23/2006 10:35 AM, michael watson (IAH-C) wrote:
> Hi
> 
> Hopefully this one isn't in the manual or I am about to get shot :-S
> 
> One of my colleagues wants a slightly strange graph.  We basically have
> a data matrix, and she wants to plot, for each row, the values in the
> row as points on the graph.  The following code draws the graph just
> fine:
> 
> plot(row(d)[,3:9],d[,3:9])
> 
> So as there are 12 rows in my matrix, there are 12 columns of points,
> which is what she wants.
> 
> However, she wants the x-axis labelled with the row names, not with
> 1,2,3,4,5 etc
> 
> I can figure out from reading par() how to turn off the default drawing
> of the numerical labels, but how do I use the row names instead?

Use the axis() function.  The x-axis is side=1; labels can be a 
character vector containing anything you like.

Duncan Murdoch



From I.Szentirmai at rug.nl  Thu Feb 23 18:24:09 2006
From: I.Szentirmai at rug.nl (I.Szentirmai)
Date: Thu, 23 Feb 2006 18:24:09 +0100
Subject: [R] binomial models with too many 1s???
In-Reply-To: <Pine.LNX.4.58.0602231717050.17370@thorin.ci.tuwien.ac.at>
References: <20060223143142.93005.qmail@web60413.mail.yahoo.com>
	<Pine.LNX.4.58.0602231717050.17370@thorin.ci.tuwien.ac.at>
Message-ID: <web-16656881@mail3.rug.nl>

Dear R users,

Does anyone know a solution for the problem when there are 
too many ones or zeros in the respons of a binomial model? 
I think this means that the data are over/under despersed 
and the result is very bad model fit.

I'm using glmmPQL(family=quasibinomial) to fit a model to 
my data, but the model estimates are not in the range they 
should be due to overdispersion (or under?) What shall I 
do? Is there a model type for this kind of data? I would 
prefer to keep all may data, otherwise I could also select 
some of the ones so that their number will be equal to the 
number of zeros. But I don't thik this is the right way...

Any help would be appreciated.

Thanks,
Istvan



From dvumani at hotmail.com  Thu Feb 23 18:28:34 2006
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Thu, 23 Feb 2006 17:28:34 +0000
Subject: [R] R function use in C returning a list
Message-ID: <BAY110-F1115F9524FD402BF797C8CA3F20@phx.gbl>

Dear R users,
Is it possible to use an R function accepting several arguments and 
returning a list in C code. I notice that in all examples only one variable 
is returned.
Here is the C part I feel is giving the problems,

	SEXP R_fcall, ans;
	PROTECT(R_fcall = lang2(likelihood, R_NilValue));
	++nProtected;
	defineVar(install("PAR"), PAR, env);
	defineVar(install("DATA"), oldData, env);
	defineVar(install("N"), N, env);
	PROTECT(ans =  eval(R_fcall, env));

oldData is a matrix which i set using

	SEXP dim;
	PROTECT(dim = NEW_INTEGER(2));
	++nProtected;
	INTEGER_DATA(dim)[0] = n;
	INTEGER_DATA(dim)[1] = 2;
	setAttrib(oldData, R_DimSymbol, dim);

if i return both function and data they are ok, but its evaluating the 
function and returning the list or even a single number which is a problem.
Thanks again, Vumani



From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Feb 23 16:53:44 2006
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu, 23 Feb 2006 16:53:44 +0100 (CET)
Subject: [R] useR! 2006 - 2006-02-28 Submission Deadline
Message-ID: <Pine.LNX.4.64.0602231652490.26868@artemis.imbe.med.uni-erlangen.de>


Dear useRs,

The submission deadline for `useR! 2006', the second R user conference to 
be held in Vienna June 15-17 2006, is only five days ahead. So this 
weekend is the perfect time to submit abstracts for user-contributed 
sessions!

The sessions will be a platform to bring together R users, contributers,
package maintainers and developers in the S spirit that `users are 
developers'.

We invite all R users to submit abstracts on topics presenting innovations 
or exciting applications of R. A web page offering more information on the 
`useR!' conference, abstract submission, registration and Vienna is 
available at

   http://www.R-project.org/useR-2006/

We look forward to receiving your abstract!


The organizing committee:
Torsten Hothorn, Achim Zeileis, David Meyer, Bettina Gruen,
Kurt Hornik and Friedrich Leisch

_______________________________________________
R-announce at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce



From ruser2006 at yahoo.com  Thu Feb 23 18:47:06 2006
From: ruser2006 at yahoo.com (r user)
Date: Thu, 23 Feb 2006 09:47:06 -0800 (PST)
Subject: [R] memory managment under Windows XP
Message-ID: <20060223174706.41777.qmail@web37010.mail.mud.yahoo.com>

I am using R 2.2.1 in a Windowes XP environment.

I work with very large datasets, and occassionally run
out of memory.

I have modified my boot.ini file to use the "/3gb
switch".

I also run the following line after I launch R ( I am
unsure if it is helpful).

"memory.limit(size = 4095)"

Please point me to useful references on how to better
manage memory, or suggestother actions.



From p.dalgaard at biostat.ku.dk  Thu Feb 23 19:22:30 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 23 Feb 2006 19:22:30 +0100
Subject: [R] Changing the x-axis labels in plot()
In-Reply-To: <8975119BCD0AC5419D61A9CF1A923E950300838F@iahce2ksrv1.iah.bbsrc.ac.uk>
References: <8975119BCD0AC5419D61A9CF1A923E950300838F@iahce2ksrv1.iah.bbsrc.ac.uk>
Message-ID: <x2ek1uyly1.fsf@turmalin.kubism.ku.dk>

"michael watson (IAH-C)" <michael.watson at bbsrc.ac.uk> writes:

> Hi
> 
> Hopefully this one isn't in the manual or I am about to get shot :-S

*Kapow*... [1]
 
> One of my colleagues wants a slightly strange graph.  We basically have
> a data matrix, and she wants to plot, for each row, the values in the
> row as points on the graph.  The following code draws the graph just
> fine:
>  
> plot(row(d)[,3:9],d[,3:9])
> 
> So as there are 12 rows in my matrix, there are 12 columns of points,
> which is what she wants.
> 
> However, she wants the x-axis labelled with the row names, not with
> 1,2,3,4,5 etc
> 
> I can figure out from reading par() how to turn off the default drawing
> of the numeri cal labels, but how do I use the row names instead?

axis(1, at=1:12, labels=rownames(d))


[1] Look e.g. at the examples section in plot.default.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Thu Feb 23 20:04:07 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 19:04:07 +0000 (GMT)
Subject: [R] do.call, browser and traceback
In-Reply-To: <f8e6ff050602201649h40e47c64u43307ae3cab716a9@mail.gmail.com>
References: <f8e6ff050602201649h40e47c64u43307ae3cab716a9@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602231857360.10209@gannet.stats.ox.ac.uk>

On Mon, 20 Feb 2006, hadley wickham wrote:

> A problem that I've encountered when using do.call a lot is very large
> stack traces, eg:
>
> f <- function(x) stop()
> do.call(error, mtcars)
> traceback()
> f <- function(x) browser()
> do.call(f, mtcars)

Did you mean that?  Both are errors.  Perhaps

f <- function(...) browser()
do.call(f, mtcars)

is an actual example of the idea.

What is being used is

 	Rprintf("Called from: ");
 	PrintValueRec(cptr->call,rho);

in src/main/main.c.  We could certainly allow an option to limit the 
deparse length, but I have to say that quite often the useful information 
is well down the list of arguments.  There is currently no user control.

>
> I have hacked together my own version of traceback to fix this by
> limiting the length of each line to 80 characters, but I can't see any
> way to do something similar for browser.  Any suggestions?
>
> Thanks,
>
> Hadley
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dr.mike at ntlworld.com  Thu Feb 23 20:34:52 2006
From: dr.mike at ntlworld.com (mike waters)
Date: Thu, 23 Feb 2006 19:34:52 -0000
Subject: [R] binomial models with too many 1s???
In-Reply-To: <web-16656881@mail3.rug.nl>
Message-ID: <005201c638b0$39120680$0400a8c0@C400XP>

 I take it that a zero inflated negative binomial (i.e. Poisson) regression
model is what you are trying to fit, aka ZIP? If so try looking at the
documentation for the zicounts package for R, for one. Of course, you can
also search on these keywords yourself, to find exactly what you want....

Regards,

Mike

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of I.Szentirmai
Sent: 23 February 2006 17:24
To: R-help at stat.math.ethz.ch
Subject: [R] binomial models with too many 1s???

Dear R users,

Does anyone know a solution for the problem when there are too many ones or
zeros in the respons of a binomial model? 
I think this means that the data are over/under despersed and the result is
very bad model fit.

I'm using glmmPQL(family=quasibinomial) to fit a model to my data, but the
model estimates are not in the range they should be due to overdispersion
(or under?) What shall I do? Is there a model type for this kind of data? I
would prefer to keep all may data, otherwise I could also select some of the
ones so that their number will be equal to the number of zeros. But I don't
thik this is the right way...

Any help would be appreciated.

Thanks,
Istvan

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From h.wickham at gmail.com  Thu Feb 23 20:39:38 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Thu, 23 Feb 2006 13:39:38 -0600
Subject: [R] do.call, browser and traceback
In-Reply-To: <Pine.LNX.4.64.0602231857360.10209@gannet.stats.ox.ac.uk>
References: <f8e6ff050602201649h40e47c64u43307ae3cab716a9@mail.gmail.com>
	<Pine.LNX.4.64.0602231857360.10209@gannet.stats.ox.ac.uk>
Message-ID: <f8e6ff050602231139l5fece06bmcf40d7887b9df207@mail.gmail.com>

> Did you mean that?  Both are errors.  Perhaps
>
> f <- function(...) browser()
> do.call(f, mtcars)

Sorry, yes, that is what I meant.

> What is being used is
>
>         Rprintf("Called from: ");
>         PrintValueRec(cptr->call,rho);
>
> in src/main/main.c.  We could certainly allow an option to limit the
> deparse length, but I have to say that quite often the useful information
> is well down the list of arguments.  There is currently no user control.

It would be nice to have some user control - I find the first 100
characters or so is usually sufficient, especially when the real
problem is further down the stack.  It is a real pain when you have
used do.call with a 10,000 row dataframe - and then it is basically
impossible to find the problem by manual inspection anyway.  Even
limiting to 1000 characters would be a big improvement.

Hadley



From andy_liaw at merck.com  Thu Feb 23 21:23:19 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 23 Feb 2006 15:23:19 -0500
Subject: [R] locpoly
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED857@usctmx1106.merck.com>

From: Duncan Murdoch
> 
> On 2/23/2006 9:56 AM, Amir Safari wrote:
> >  
> >    
> >    Dear R Users,
> >   When using locpoly function, number of output values is 
> smaller than the number of input values. How is it possible 
> to get number of output component $y equal to the number of inputs.
> 
> You could use linear interpolation on its outputs, e.g.
> 
> x <- runif(20)
> y <- x^2 + rnorm(20)
> 
> fit <- locpoly(x, y, bandwidth=0.3)
> fitfn <- approxfun(fit$x, fit$y)
> yhat <- fitfn(x)

... Or use something that has a predict() method; e.g., locfit() in the
`locfit' package.

Andy

 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From andy_liaw at merck.com  Thu Feb 23 21:27:06 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 23 Feb 2006 15:27:06 -0500
Subject: [R] memory managment under Windows XP
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED858@usctmx1106.merck.com>

There are plenty in the the list archive, one of which is to switch to a run
64-bit R on a 64-bit platform with lots of physical RAM.  Such hardware is
quite affordable these days (certainly cheaper than most commercial software
that you'd have to buy if you didn't have R).

Andy

From: r user
> 
> I am using R 2.2.1 in a Windowes XP environment.
> 
> I work with very large datasets, and occassionally run
> out of memory.
> 
> I have modified my boot.ini file to use the "/3gb
> switch".
> 
> I also run the following line after I launch R ( I am
> unsure if it is helpful).
> 
> "memory.limit(size = 4095)"
> 
> Please point me to useful references on how to better
> manage memory, or suggestother actions.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From tlumley at u.washington.edu  Thu Feb 23 21:43:07 2006
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 23 Feb 2006 12:43:07 -0800 (PST)
Subject: [R] svyby and svyratio in the Thomas Lumley's  survey package
In-Reply-To: <2554377D323C9A40BD69956059FD05490ED452FC@mnip1>
References: <2554377D323C9A40BD69956059FD05490ED452F1@mnip1>
	<2554377D323C9A40BD69956059FD05490ED452FC@mnip1>
Message-ID: <Pine.LNX.4.64.0602231118380.23263@homer21.u.washington.edu>

On Thu, 23 Feb 2006, Smith, Phil wrote:

> Dear R-ers:
>
> I'm using Thomas Lumley's "survey" package.
>
> I'd like to compute survey ratio estimates (numerator=~utd , 
> denominator=~one) for each of serval domains using by=~factor(domain).
>
> I can't quite work out the syntax for the call to the "svyby" function. I try:
>
> svyby( numerator=~ utd, denominator=~one , by=~ factor(domain) , 
> design=nis , svyratio )
>
> and I get an error that says that "domain" is not found. (nis is the 
> design object)
>

Hmm. I don't get the same error message (perhaps a question of versions?), 
but there is a problem. svyby is not really set up to work with svyratio. 
I will try to fix this, but there are simple workarounds.

If you do
  data(api)
  dstrat<-svydesign(id=~1,strata=~stype, weights=~pw,
        data=apistrat, fpc=~fpc)

  result <- svyby(~api.stu,by=~factor(stype), denominator=~enroll,
        design=dstrat,svyratio)

(ie, don't name the numerator argument) then the computations are done as 
you want.  The result does not print correctly, because svyby() returns 
some extra attributes that print() doesn't know how to handle.

You can extract the results you need with coef() or just remove the 
extraneous attributes
> result
Error in unlist(x, recursive, use.names) :
         argument not a list
> coef(result)
   statistic.ratio statistic.var
E       0.8518163  4.945408e-05
H       0.8105702  0.0004193180
M       0.8356958  0.0003307829
> result$statistic.call<-NULL
> result
   factor(stype) statistic.ratio statistic.var         SE
E             E       0.8518163  4.945408e-05 0.00703236
H             H       0.8105702  0.0004193180 0.02047726
M             M       0.8356958  0.0003307829 0.01818744



Finally, the name of the denominator variable looks suspicious. If `one' 
is a variable whose values are all 1 and you just want domain means you 
can do the equivalent of
   svyby(~api00,~stype,design=dstrat,svymean)
to get the mean of api00 within each value of stype.  You don't need 
svyratio(). In fact, part of the test suite for the survey package is to 
check that svyratio, svymean, and svyglm give the same answers for domain 
means.

 	-thomas



From roger.bos at gmail.com  Thu Feb 23 21:54:53 2006
From: roger.bos at gmail.com (roger bos)
Date: Thu, 23 Feb 2006 15:54:53 -0500
Subject: [R] memory managment under Windows XP
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED858@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED858@usctmx1106.merck.com>
Message-ID: <1db726800602231254s2d5e32e4gcaefa449276098fe@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060223/072e2859/attachment.pl

From pburns at pburns.seanet.com  Thu Feb 23 21:59:55 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu, 23 Feb 2006 20:59:55 +0000
Subject: [R] Problem with List() Inside Function
In-Reply-To: <20060223153213.8000.qmail@web30302.mail.mud.yahoo.com>
References: <20060223153213.8000.qmail@web30302.mail.mud.yahoo.com>
Message-ID: <43FE224B.5010202@pburns.seanet.com>

My solution when I run into mysteries like this
is to put

browser()

in the function just before or after the line of interest.
The magnitude and direction of my stupidity usually
become clear quickly.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Peter Lauren wrote:

>I have a function declared thus.
>FirstEigenvectorBoundary.Training <-
>function(InputFileName='C:/Samples2/PT_Amp.txt',
>Header=TRUE, Colour="red")
>
>Inside the function, I have the following call
>
>out<-list(x=Eigenvectors[2:(NumMetricsSelected+1),1],
>y=-0.8, z=NumMetricsSelected);
>
>NumMetricsSelected has the value 2 and Eigenvectors
>has the following form
>           [,1]       [,2]       [,3]
>[1,]  0.6404630 -0.2153989  0.7371638
>[2,] -0.6081319  0.4439621  0.6580830
>[3,]  0.4690231  0.8697706 -0.1533503
>
>When I do it manually at the console, I get the
>correct result.  I.e.
>  
>
>>out
>>    
>>
>$x
>[1] -0.6081319  0.4690231
>
>$y
>[1] -0.8
>
>$z
>[1] 2
>
>However, when I call the function like this
>  
>
>>Training<-FirstEigenvectorBoundary.Training()
>>    
>>
>
>I get
>  
>
>>Training
>>    
>>
>$x
>[1] 0.658083
>
>$y
>[1] -0.8
>
>$z
>[1] 2
>
>That is, the $x element has only one value (instead of
>2) and it is from the wrong part of the matrix.
>
>Can anyone see what I am doing wrong?
>
>Thanks very much,
>Peter.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From CPartridge at hec.ohio-state.edu  Thu Feb 23 22:15:46 2006
From: CPartridge at hec.ohio-state.edu (Charles Partridge)
Date: Thu, 23 Feb 2006 16:15:46 -0500
Subject: [R] Consultants Needed
Message-ID: <C3AE68CDBFAEB34DBCF9F41A8A0136CE3BE8A4@maverick.hec.ohio-state.edu>

Group,

My colleagues and I are considering compiling a network of Ohio users of
[R], who would are interested in consulting with local agencies
throughout Ohio who are interested in learning the software.  

If you are interested in being a consultant, please contact me off-list.
In addition, if you happen to know of another [R] user that could
provide consulting services, could you please forward this message to
him/her? 

Thank you for your time.

Regards,

Charles R. Partridge
Evaluation Specialist
Center for Learning Excellence
The John Glenn Institute for Public Service & Public Policy
807 Kinnear Road, Room 214
Columbus, Ohio 43212-1421
Phone: 614.292.2419
FAX: 614.247.6447
Email: cpartridge at hec.ohio-state.edu
http://cle.osu.edu

CONFIDENTIALITY NOTICE: This message is intended only for th...{{dropped}}



From gunter.berton at gene.com  Thu Feb 23 22:38:13 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 23 Feb 2006 13:38:13 -0800
Subject: [R] Problem with List() Inside Function
In-Reply-To: <43FE224B.5010202@pburns.seanet.com>
Message-ID: <006101c638c1$73362650$711f210a@gne.windows.gene.com>

 
Is the following from Patrick Burns another pearl for the fortunes package?

-- Bert Gunter


*****************************

 My solution when I run into mysteries like this
 is to put
 
 browser()
 
 in the function just before or after the line of interest.
 The magnitude and direction of my stupidity usually
 become clear quickly.
 
 Patrick Burns
 patrick at burns-stat.com
 +44 (0)20 8525 0696
 http://www.burns-stat.com
 (home of S Poetry and "A Guide for the Unwilling S User")



From ericpante at earthlink.net  Thu Feb 23 22:50:23 2006
From: ericpante at earthlink.net (Eric Pante)
Date: Thu, 23 Feb 2006 16:50:23 -0500
Subject: [R] R and marine protected areas: algorithms for site selection
Message-ID: <8dfaa97594953aee0361e33bf833d777@earthlink.net>

Dear listers,

a central problem in conservation biology is the selection of sites in 
reserve network design.
many algorithms have been published, and I was wondering any have been 
implemented in R.
I did not seen anything on CRAN or R-help, or on the web in general.

Best regards, Eric

Eric Pante
----------------------------------------------------------------
College of Charleston, Grice Marine Laboratory
205 Fort Johnson Road, Charleston SC 29412
Phone: 843-953-9190 (lab)  -9200 (main office)
----------------------------------------------------------------

	"On ne force pas la curiosite, on l'eveille ..."
	Daniel Pennac



From ripley at stats.ox.ac.uk  Thu Feb 23 23:01:14 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 23 Feb 2006 22:01:14 +0000 (GMT)
Subject: [R] memory managment under Windows XP
In-Reply-To: <1db726800602231254s2d5e32e4gcaefa449276098fe@mail.gmail.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED858@usctmx1106.merck.com>
	<1db726800602231254s2d5e32e4gcaefa449276098fe@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602232144030.26536@gannet.stats.ox.ac.uk>

On Thu, 23 Feb 2006, roger bos wrote:

> And of course using rm(...) to clean up objects you no longer need.  No
> amount of physical memory can save you from grossly inefficient code and
> large memory leaks.  For example, lets say I have a large testMat object
> that I use time period.  I loop though each month using for loops.  Even
> though the object has the same name each month, and thus gets overwritten,
> the memory management seems to go better by manually removing the object at
> the end of each loop.  Also, I sometimes call gc() at the end of each loop,
> but I don't know if that actually helps or not.  I figure it can't hurt.

It does help to rm() and then gc() at a point when you know that the 
number of objects in use is minimal.  R will gc() repeatedly when it 
starts to run out of address space, but this does not help if the address 
space is already fragmented.

The main problem on 32-bit OSes is (virtual) memory fragmentation, and 3Gb 
is not really much address space for objects in 100s of Mb.

I've now only got a 64-bit desktop and servers (plus a 32-bit Windows 
laptop).  It is a shame for Windows users that a 64-bit Open Source 
toolchain* is nowhere in sight, but I suspect a sufficiently determined 
user of Win64 could build a 64-bit port of R with commercial compilers.

*You need a compiler, assembler, linker and runtime, and the latter may 
well be the most problematic.

> On 2/23/06, Liaw, Andy <andy_liaw at merck.com> wrote:
>>
>> There are plenty in the the list archive, one of which is to switch to a
>> run
>> 64-bit R on a 64-bit platform with lots of physical RAM.  Such hardware is
>> quite affordable these days (certainly cheaper than most commercial
>> software
>> that you'd have to buy if you didn't have R).
>>
>> Andy
>>
>> From: r user
>>>
>>> I am using R 2.2.1 in a Windowes XP environment.
>>>
>>> I work with very large datasets, and occassionally run
>>> out of memory.
>>>
>>> I have modified my boot.ini file to use the "/3gb
>>> switch".
>>>
>>> I also run the following line after I launch R ( I am
>>> unsure if it is helpful).
>>>
>>> "memory.limit(size = 4095)"
>>>
>>> Please point me to useful references on how to better
>>> manage memory, or suggestother actions.
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>>
>>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mike_saunders at umenfa.maine.edu  Thu Feb 23 23:01:50 2006
From: mike_saunders at umenfa.maine.edu (Mike Saunders)
Date: Thu, 23 Feb 2006 17:01:50 -0500
Subject: [R] Need a hint
Message-ID: <000b01c638c4$bfd10590$b5a76f82@CFRU0204>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060223/6de94b89/attachment.pl

From Greg.Snow at intermountainmail.org  Thu Feb 23 23:22:20 2006
From: Greg.Snow at intermountainmail.org (Gregory Snow)
Date: Thu, 23 Feb 2006 15:22:20 -0700
Subject: [R] Need a hint
Message-ID: <07E228A5BE53C24CAD490193A7381BBB2668C6@LP-EXCHVS07.CO.IHC.COM>

Here are a couple of quick thoughts on your problem.

1. Use alpha channels (may require you to produce all your graphs as pdf
files).

Fill each of your criteria categories with a mostly transparent color,
e.g. the full contour of z[1] between 20 and 30 is 20% opaque and the
full contour(s) of z[2] < 40 is 20% opaque.  Then where they overlap
will be 40% opaque and stand out (and if you have 5 critera then where
they all overlap  will be 100% opaque.


2. create a dataframe with all your z's predicted over a regular grid of
x and y values (possibly the same set as used for the contours), then
create a logical variable that ands together all your critera, e.g.:

New <- transform(old, z.combined = 20 < z1 & z1 < 30 & z2 < 40)

Then do a levelplot with the new logical variable as the response (maybe
do as.numeric on it first), then overlay your contours on top of the
levelplot.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Mike Saunders
> Sent: Thursday, February 23, 2006 3:02 PM
> To: R Help
> Subject: [R] Need a hint
> 
> R community:
> 
> I have been creating code for plotting nomographs, or 
> multiple, overlain contour plots of z-variables on a common 
> x- and y- variable.  My input has been a matrix with observed 
> x, y, and multiple z variables; I then create a trend surface 
> using trmat for each z-variable.  So far so good.
> 
> One application I have for these, requires shading a portion 
> of the nomogram that meets criteria for some of the 
> z-variables (i.e., z[1] must be between 20 and 30, z[2] must 
> be less than 40, etc.).  My solution was to use a logical 
> comparison on each contour surface provided by trmat, sum the 
> "logical surfaces" up and see if they were less than the 
> total number of criteria.  It works, but it is quite 
> inefficient even if I vectorize the code somewhat; for 
> example if I specify a gridsize of 200 in trmat, have 5 z 
> variables, and 1 criteria for each, I will have well over 
> 200,000 comparisons to make!  So I am looking for hints or 
> maybe an entirely different approach to speed this up.
> 
> I attached the crit.region function below along with my write 
> up on how it works.  Can somebody give me some ideas on how 
> to proceed?
> 
> Thanks,
> Mike
> 
> Mike R. Saunders
> Forest Biometrician
> Cooperative Forest Research Unit
> University of Maine
> 5755 Nutting Hall
> Orono, ME  04469-5755
> 
> 207-581-2763 (O)
> 207-581-2833 (F)
> 
> 
> # The following function selects a region that meets a set of 
> # criteria defined in terms of z-variables in a list from 
> nomogram # or a similarly formatted list.  This function 
> basically is a set # of logical comparisons on z-values at 
> each xy-coordinate.  As such, # the function is rasterized 
> and can take considerable time when # each z-variable matrix 
> is quite large.  Parameters for the # function are:
> # 
> #   1) x        (Required)  Either a list consisting of a vector
> #                           of gridded x-coordinates, a vector of 
> #                           gridded y-coordinates and matrices of
> #                           each z-variable, or a vector of just 
> #                           the gridded x-coordinates.
> #   2) y        (Optional)  A vector of gridded y-coordinates.
> #   3) z        (Optional)  A matrix or data.frame of z-variates
> #                           that correspond to the gridded 
> #                           xy-coordinates.
> #   4) critmat  (Required)  A matrix or data.frame with rows equal
> #                           to the number of z-variables and 2 
> #                           columns.  The first column corresponds
> #                           to the minimum value allowed for each
> #                           z-variable, the second to the maximum
> #                           value.  If there is no minimum or
> #                           maximum for a variable, NA should be 
> #                           used in the appropriate row and column.
> #
> # This function returns the critical area as a matrix of NA 
> and 1 # with dimension equal to a z-variable matrix.  The 
> function also # returns a message if there is no critical 
> area solution.
> #
> # [Future versions of this function will try to improve its # 
>  computational speed.] #
> crit.region<-function(x,y=NULL,z=NULL,critmat) {
>     if(all(missing(y),missing(z))) {
>         
> stopifnot(class(x)=="list",sum(lapply(x,class)[1:2]!="numeric"
)==0,sum(sapply(x,class)[3:length(x)]!="matrix")==>
0,length(x[[1]])==dim(x[[3]])[1],length(x[[2]])==dim(x[[3]])[2
> ],length(x)>4)
>         y<-x[[2]]
>         z<-x[c(3:length(x))]
>         x<-x[[1]]
>     } else if(any(missing(y),missing(z))) {
>         stop("y and z are both required unless x is properly 
> formatted list")
>     } else 
> stopifnot(class(y)=="numeric",class(z)=="list",length(x)==dim(
> z[[1]])[1],length(y)==dim(z[[1]])[2],sum(sapply(z,class)!="mat
rix")==0)
>     w<-length(z)
>     zrange<-sapply(z,range,na.rm=T)
>     
> stopifnot(class(critmat)%in%c("matrix","data.frame"),dim(critm
at)==c(w,2))
>     critarea<-matrix(data=0,nrow=dim(z[[1]])[1],ncol=dim(z[[1]])[2])
>     for(i in 1:w) {
>         minz<-ifelse(is.na(critmat[i,1]),zrange[1,i],critmat[i,1])
>         maxz<-ifelse(is.na(critmat[i,2]),zrange[2,i],critmat[i,2])
>         critarea<-critarea+apply(z[[i]],c(1,2), function(x) 
> ifelse(x>minz & x<maxz,1,0))
>         }     
>     critarea<-apply(critarea,c(1,2), function(x) ifelse(x==w,1,NA))
>     if(sum(critarea,na.rm=T)==0) message("Critical region is 
> empty set!")
>     return(critarea)
> }
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From cliard at hotmail.com  Fri Feb 24 00:08:29 2006
From: cliard at hotmail.com (charles liard)
Date: Thu, 23 Feb 2006 23:08:29 +0000
Subject: [R] siegel-tukey test
Message-ID: <BAY107-F30F6DF97A943E9DF0321ACDEF20@phx.gbl>

Hi,

I'm a frequent R user and ran into a message from 2004 in which someone 
wants to use R for a Siegel-Tukey test.  To the best of my knowledge (and 
I've checked a lot), there is no way to do this in R.  However, I've set up 
some R code that requires the sue of an executable program made with a 
general-purpose language (turing).   Ultimately, the test is performed 
correctly a la Conover and/or Sprent.  I will happily make the whole thing 
available to anyone who wants it.

I have a question.  Suppose the two data sets have different means and the 
difference is unknown a priori.  Can the difference be estimated from the 
data when using the Siegel-Tukey test?  Reputable sources disagree on this.  
What do you think?  I say yes.  It isn't as if we never use sample standard 
deviations ...

Thanks!

Charles Liard



From cswingle at iarc.uaf.edu  Fri Feb 24 00:10:29 2006
From: cswingle at iarc.uaf.edu (Christopher Swingley)
Date: Thu, 23 Feb 2006 14:10:29 -0900
Subject: [R] Working with lists with numerical names
Message-ID: <20060223231029.GJ7550@iarc.uaf.edu>

Greetings!

I'm have a hard time working with some data I imported from a baseball
database.  Several of the database columns have numbers in them (2B,
3B), and when I try to use these vectors from the data frame, I get
syntax errors, probably because it's interpreting the name as a number:

 > show(batting2005)
   playerID yearID stint teamID lgID   G  AB   R   H 2B 3B HR RBI SB CS  BB
   1   robleos01   2005     1    LAN   NL 110 364  44  99 18  1  5 34  0  8  31
   2   iguchta01   2005     1    CHA   AL 135 511  74 142 25  6 15 71 15  5  47
   3   molinya01   2005     1    SLN   NL 114 385  36  97 15  1  8 49  2  3  23
   . . .
 > print(batting2005$HR)
   [1]  5 15  8  3 14  3  6 21  8  7  9 27 12  5 14  8 28  9 22 15  5
   22  9 10  1
   . . .
 > print(batting2005$2B)
 Error: syntax error in "print(batting2005$2"

 > SLG<-(H + 2B + 3B * 2 + HR * 3) / AB;
 Error: syntax error in "SLG<-(H + 2B"      # batting2005 is attached

 > SLG<-(H + "2B" + "3B" * 2 + HR * 3) / AB;
 Error in H + "2B" : non-numeric argument to binary operator

Is there a way to "escape" the '2B' somehow or encapsulate it so that R
knows I'm talking about that particular numeric vector?

Thanks,

Chris
-- 
Christopher S. Swingley          email: cswingle at iarc.uaf.edu
Intl. Arctic Research Center
University of Alaska Fairbanks   www.frontier.iarc.uaf.edu/~cswingle/



From sundar.dorai-raj at pdf.com  Fri Feb 24 00:23:32 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 23 Feb 2006 15:23:32 -0800
Subject: [R] Working with lists with numerical names
In-Reply-To: <20060223231029.GJ7550@iarc.uaf.edu>
References: <20060223231029.GJ7550@iarc.uaf.edu>
Message-ID: <43FE43F4.9070302@pdf.com>



Christopher Swingley wrote:
> Greetings!
> 
> I'm have a hard time working with some data I imported from a baseball
> database.  Several of the database columns have numbers in them (2B,
> 3B), and when I try to use these vectors from the data frame, I get
> syntax errors, probably because it's interpreting the name as a number:
> 
>  > show(batting2005)
>    playerID yearID stint teamID lgID   G  AB   R   H 2B 3B HR RBI SB CS  BB
>    1   robleos01   2005     1    LAN   NL 110 364  44  99 18  1  5 34  0  8  31
>    2   iguchta01   2005     1    CHA   AL 135 511  74 142 25  6 15 71 15  5  47
>    3   molinya01   2005     1    SLN   NL 114 385  36  97 15  1  8 49  2  3  23
>    . . .
>  > print(batting2005$HR)
>    [1]  5 15  8  3 14  3  6 21  8  7  9 27 12  5 14  8 28  9 22 15  5
>    22  9 10  1
>    . . .
>  > print(batting2005$2B)
>  Error: syntax error in "print(batting2005$2"
> 
>  > SLG<-(H + 2B + 3B * 2 + HR * 3) / AB;
>  Error: syntax error in "SLG<-(H + 2B"      # batting2005 is attached
> 
>  > SLG<-(H + "2B" + "3B" * 2 + HR * 3) / AB;
>  Error in H + "2B" : non-numeric argument to binary operator
> 
> Is there a way to "escape" the '2B' somehow or encapsulate it so that R
> knows I'm talking about that particular numeric vector?
> 
> Thanks,
> 
> Chris

Hi, Chris,

 > x <- data.frame(1:5, 6:10)
 > names(x) <- c("R", "2B")
 > x
   R 2B
1 1  6
2 2  7
3 3  8
4 4  9
5 5 10
 > x$"2B"
[1]  6  7  8  9 10
 > with(x, R + `2B`)
[1]  7  9 11 13 15

HTH,

--sundar



From jholtman at gmail.com  Fri Feb 24 00:22:36 2006
From: jholtman at gmail.com (jim holtman)
Date: Thu, 23 Feb 2006 18:22:36 -0500
Subject: [R] Working with lists with numerical names
In-Reply-To: <20060223231029.GJ7550@iarc.uaf.edu>
References: <20060223231029.GJ7550@iarc.uaf.edu>
Message-ID: <644e1f320602231522u6f26fad0nef40991601fd26e6@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060223/84b96480/attachment.pl

From cswingle at iarc.uaf.edu  Fri Feb 24 00:24:42 2006
From: cswingle at iarc.uaf.edu (Christopher Swingley)
Date: Thu, 23 Feb 2006 14:24:42 -0900
Subject: [R] Working with lists with numerical names
In-Reply-To: <43FE43F4.9070302@pdf.com>
References: <20060223231029.GJ7550@iarc.uaf.edu> <43FE43F4.9070302@pdf.com>
Message-ID: <20060223232441.GN7550@iarc.uaf.edu>

Sundar,

* Sundar Dorai-Raj <sundar.dorai-raj at pdf.com> [2006-Feb-23 14:23 AKST]:
> Hi, Chris,
> 
> > x <- data.frame(1:5, 6:10)
> > names(x) <- c("R", "2B")
> > x
>   R 2B
> 1 1  6
> 2 2  7
> 3 3  8
> 4 4  9
> 5 5 10
> > x$"2B"

Thanks.  I swear I tried just about every other combination of possible
escape character.  But I didn't try:

    frame$"vector"

or

    `vector`

My bad.

I *knew* it was something simple!

Cheers,

Chris
-- 
Christopher S. Swingley          email: cswingle at iarc.uaf.edu
Intl. Arctic Research Center
University of Alaska Fairbanks   www.frontier.iarc.uaf.edu/~cswingle/



From dmaneesh at hotmail.com  Fri Feb 24 01:46:00 2006
From: dmaneesh at hotmail.com (maneesh deshpande)
Date: Thu, 23 Feb 2006 19:46:00 -0500
Subject: [R] Ranking within factor subgroups
In-Reply-To: <x2hd6qy4g2.fsf@turmalin.kubism.ku.dk>
Message-ID: <BAY107-F182EA3C257F09FE5110800D2F30@phx.gbl>

Hi Peter,

That did the trick. Thank you very much.

Regards,

Maneesh


>From: Peter Dalgaard <p.dalgaard at biostat.ku.dk>
>To: "maneesh deshpande" <dmaneesh at hotmail.com>
>CC: ramasamy at cancer.org.uk, r-help at stat.math.ethz.ch
>Subject: Re: [R] Ranking within factor subgroups
>Date: 23 Feb 2006 07:28:13 +0100
>
>"maneesh deshpande" <dmaneesh at hotmail.com> writes:
>
> > Hi Adai,
> >
> > I think your solution only works if the rows of the data frame are 
>ordered
> > by "date" and
> > the ordering function is the same used to order the levels of
> > factor(df$date) ?
> > It turns out (as I implied in my question) my data is indeed organized 
>in
> > this manner, so my
> > current problem is solved.
> > In the general case, I suppose, one could always order the data frame by
> > date before proceeding ?
> >
> > Thanks,
> >
> > Maneesh
>
>You might prefer to look at split/unsplit/split<-, i.e. the z-scores
>by group line:
>
>      z <- unsplit(lapply(split(x, g), scale), g)
>
>with "scale" suitably replaced. Presumably (meaning: I didn't quite
>read your code closely enough)
>
>     z <- unsplit(lapply(split(x, g), bucket, 10), g)
>
>could do it.
>
> >
> > >From: Adaikalavan Ramasamy <ramasamy at cancer.org.uk>
> > >Reply-To: ramasamy at cancer.org.uk
> > >To: maneesh deshpande <dmaneesh at hotmail.com>
> > >CC: r-help at stat.math.ethz.ch
> > >Subject: Re: [R]  Ranking within factor subgroups
> > >Date: Wed, 22 Feb 2006 03:44:45 +0000
> > >
> > >It might help to give a simple reproducible example in the future. For
> > >example
> > >
> > >  df <- cbind.data.frame( date=rep( 1:5, each=100 ), A=rpois(500, 100),
> > >                          B=rpois(500, 50), C=rpois(500, 30) )
> > >
> > >might generate something like
> > >
> > >	    date   A  B  C
> > >	  1    1  93 51 32
> > >	  2    1  95 51 30
> > >	  3    1 102 59 28
> > >	  4    1 105 52 32
> > >	  5    1 105 53 26
> > >	  6    1  99 59 37
> > >	...    . ... .. ..
> > >	495    5 100 57 19
> > >	496    5  96 47 44
> > >	497    5 111 56 35
> > >	498    5 105 49 23
> > >	499    5 105 61 30
> > >	500    5  92 53 32
> > >
> > >Here is my proposed solution. Can you double check with your existing
> > >functions to see if they are correct.
> > >
> > >    decile.fn <- function(x, nbreaks=10){
> > >      br     <- quantile( x, seq(0, 1, len=nbreaks+1), na.rm=T )
> > >      br[1]  <- -Inf
> > >      return( cut(x, br, labels=F) )
> > >    }
> > >
> > >    out <- apply( df[ ,c("A", "B", "C")], 2,
> > >                  function(v) unlist( tapply( v, df$date, decile.fn ) ) 
>)
> > >
> > >    rownames(out) <- rownames(df)
> > >    out <- cbind(df$date, out)
> > >
> > >Regards, Adai
> > >
> > >
> > >
> > >On Tue, 2006-02-21 at 21:44 -0500, maneesh deshpande wrote:
> > > > Hi,
> > > >
> > > > I have a dataframe, x of the following form:
> > > >
> > > > Date            Symbol   A    B  C
> > > > 20041201     ABC      10  12 15
> > > > 20041201     DEF       9    5   4
> > > > ...
> > > > 20050101     ABC         5  3   1
> > > > 20050101     GHM       12 4    2
> > > > ....
> > > >
> > > > here A, B,C are properties of a set symbols recorded for a given 
>date.
> > > > I wante to decile the symbols For each date and property and
> > > > create another set of columns "bucketA","bucketB", "bucketC" 
>containing
> > >the
> > > > decile rank
> > > > for each symbol. The following non-vectorized code does what I want,
> > > >
> > > > bucket <- function(data,nBuckets) {
> > > >      q <- quantile(data,seq(0,1,len=nBuckets+1),na.rm=T)
> > > >      q[1] <- q[1] - 0.1 # need to do this to ensure there are no 
>extra
> > >NAs
> > > >      cut(data,q,include.lowest=T,labels=F)
> > > > }
> > > >
> > > > calcDeciles <- function(x,colNames) {
> > > > nBuckets <- 10
> > > > dates <- unique(x$Date)
> > > > for ( date in dates) {
> > > >   iVec <- x$Date == date
> > > >   xx <- x[iVec,]
> > > >   for (colName in colNames) {
> > > >      data <- xx[,colName]
> > > >      bColName <- paste("bucket",colName,sep="")
> > > >      x[iVec,bColName] <- bucket(data,nBuckets)
> > > >   }
> > > > }
> > > > x
> > > > }
> > > >
> > > > x <- calcDeciles(x,c("A","B","C"))
> > > >
> > > >
> > > > I was wondering if it is possible to vectorize the above function to
> > >make it
> > > > more efficient.
> > > > I tried,
> > > > rlist <- tapply(x$A,x$Date,bucket)
> > > > but I am not sure how to assign the contents of "rlist" to their
> > >appropriate
> > > > slots in the original
> > > > dataframe.
> > > >
> > > > Thanks,
> > > >
> > > > Maneesh
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide!
> > >http://www.R-project.org/posting-guide.html
> > > >
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
> >
>
>--
>    O__  ---- Peter Dalgaard             ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 
>35327918
>~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 
>35327907



From jmiyamot at u.washington.edu  Fri Feb 24 02:16:37 2006
From: jmiyamot at u.washington.edu (John M. Miyamoto)
Date: Thu, 23 Feb 2006 17:16:37 -0800 (Pacific Standard Time)
Subject: [R] converting character matrix to a dataframe
Message-ID: <Pine.WNT.4.64.0602231712430.600@johnmiyamoto.psych.washington.edu>

Dear R-Help,
    Suppose I have a character matrix, e.g.,

(ch.mat <- matrix(c('a','s','*','f','w','*','k','*','*','f','i','o'), 
ncol=3))

When I convert 'ch.mat' to a dataframe, the columns are converted to 
factors:

(d1 <- data.frame(ch.mat))
mode(d1[,1])
is.factor(d1[,1])

To prevent this, I can use 'I' to protect the column vectors:

(d2 <- data.frame(x1 = I(ch.mat[,1]), x2 = I(ch.mat[,2]), x3 = 
I(ch.mat[,3])))
mode(d2[,1])
is.factor(d2[,2])

but this method is cumbersome if the matrix has many columns.
The following code is reasonably efficient even if the matrix has 
arbitrarily many columns.

(d3 <- data.frame(apply(ch.mat,2,function(x) data.frame(I(x)))))
mode(d3[,1])
is.factor(d3[,1])

Question:  Is there a more efficient method than the last one for 
converting a character matrix to a dataframe while preventing the 
automatic conversion of the column vectors to factors?

John

--------------------------------------------------------------------
John Miyamoto, Dept. of Psychology, Box 351525
University of Washington, Seattle, WA 98195-1525
Phone 206-543-0805, Fax 206-685-3157
Homepage http://faculty.washington.edu/jmiyamot/



From ggrothendieck at gmail.com  Fri Feb 24 02:51:40 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 23 Feb 2006 20:51:40 -0500
Subject: [R] converting character matrix to a dataframe
In-Reply-To: <Pine.WNT.4.64.0602231712430.600@johnmiyamoto.psych.washington.edu>
References: <Pine.WNT.4.64.0602231712430.600@johnmiyamoto.psych.washington.edu>
Message-ID: <971536df0602231751q7ef4e59n4f21fc35a7d74e28@mail.gmail.com>

You could do it directly like this:

structure(split(ch.mat, col(ch.mat)),
       row.names = 1:nrow(ch.mat), .Names = 1:ncol(ch.mat),
       class = "data.frame")


On 2/23/06, John M. Miyamoto <jmiyamot at u.washington.edu> wrote:
> Dear R-Help,
>    Suppose I have a character matrix, e.g.,
>
> (ch.mat <- matrix(c('a','s','*','f','w','*','k','*','*','f','i','o'),
> ncol=3))
>
> When I convert 'ch.mat' to a dataframe, the columns are converted to
> factors:
>
> (d1 <- data.frame(ch.mat))
> mode(d1[,1])
> is.factor(d1[,1])
>
> To prevent this, I can use 'I' to protect the column vectors:
>
> (d2 <- data.frame(x1 = I(ch.mat[,1]), x2 = I(ch.mat[,2]), x3 =
> I(ch.mat[,3])))
> mode(d2[,1])
> is.factor(d2[,2])
>
> but this method is cumbersome if the matrix has many columns.
> The following code is reasonably efficient even if the matrix has
> arbitrarily many columns.
>
> (d3 <- data.frame(apply(ch.mat,2,function(x) data.frame(I(x)))))
> mode(d3[,1])
> is.factor(d3[,1])
>
> Question:  Is there a more efficient method than the last one for
> converting a character matrix to a dataframe while preventing the
> automatic conversion of the column vectors to factors?
>
> John
>
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157
> Homepage http://faculty.washington.edu/jmiyamot/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From joe at confucius.gnacademy.org  Fri Feb 24 03:36:28 2006
From: joe at confucius.gnacademy.org (Joseph Wang)
Date: Thu, 23 Feb 2006 20:36:28 -0600
Subject: [R] setMethod and contains not saving
Message-ID: <200602232036.29085.joe@confucius.gnacademy.org>

Sorry if this is a duplicate....

I'm having the following problem saving methods which are subclasses of other
objects.  Is there a workaround.  The problem is that the R file that
triggers this bug is several meg, and I'd like to load from a RData file.

This works

> setClass('foo')

[1] "foo"

> setMethod('$', 'foo', function(x,name) x)

[1] "$"

> showMethods('$')

Function "$":
x = "ANY"
x = "foo"

> q()

Save workspace image? [y/n/c]: y
(restart)

> showMethods('$')

Function "$":
x = "ANY"
x = "foo"

This doesn't ....

> setClass('bar', contains='foo')

[1] "bar"

> setMethod('$', 'bar', function(x,name)x)

[1] "$"

> showMethods('$')

Function "$":
x = "ANY"
x = "foo"
x = "bar"

> q()

Save workspace image? [y/n/c]: y
(restart)

> showMethods('$')

Function "$":
x = "ANY"



From jemoore at duke.edu  Fri Feb 24 04:41:45 2006
From: jemoore at duke.edu (Jeffrey Moore)
Date: Thu, 23 Feb 2006 22:41:45 -0500
Subject: [R] importing data from BUGS format to R?
Message-ID: <200602240343.k1O3hRsE014730@gallun.acpub.duke.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060223/76e075c5/attachment.pl

From ggrothendieck at gmail.com  Fri Feb 24 04:46:34 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 23 Feb 2006 22:46:34 -0500
Subject: [R] importing data from BUGS format to R?
In-Reply-To: <200602240343.k1O3hRsE014730@gallun.acpub.duke.edu>
References: <200602240343.k1O3hRsE014730@gallun.acpub.duke.edu>
Message-ID: <971536df0602231946y821ee4ejf40569a1c525152b@mail.gmail.com>

Just source the file:

source("mywinbugsfile.R")
head(y)


On 2/23/06, Jeffrey Moore <jemoore at duke.edu> wrote:
> For those who use WinBUGS (or for those who are just familar with this
> format), I have a text file that looks like this (which is how R would
> export data if you used the "structure" function):
>
> y= structure(.Data= c(-6.93310E+01, 4.32870E+01, -6.96600E+01, 4.35730E+01,
> -6.90150E+01, 4.35870E+01, -5.81060E+01, 4.52890E+01, -6.65590E+01,
> 4.34600E+01, -6.61850E+01, 4.35000E+01, -6.54130E+01, 4.31940E+01,
> -6.42790E+01, 4.34780E+01, -6.35520E+01, 4.38070E+01, -6.32980E+01,
> 4.39520E+01, -6.25690E+01, 4.41760E+01, -6.20810E+01, 4.40800E+01,
> -6.14280E+01, 4.46210E+01, -6.10530E+01, 4.48050E+01, -6.00300E+01,
> 4.50480E+01, -5.88110E+01, 4.50280E+01, -5.83660E+01, 4.50400E+01,
> -5.83140E+01, 4.48780E+01, -5.87330E+01, 4.50340E+01, -5.87430E+01,
> 4.51630E+01, -5.88170E+01, 4.54030E+01, -5.89380E+01, 4.53260E+01,
> -5.89110E+01, 4.55260E+01,     NA,     NA, -5.91250E+01, 4.56070E+01,
> -5.90140E+01, 4.59690E+01, -5.89830E+01, 4.64640E+01, -5.89240E+01,
> 4.66300E+01, -5.93770E+01, 4.66810E+01, -5.90010E+01, 4.65640E+01,
> -5.91230E+01, 4.67780E+01, -5.92350E+01, 4.70000E+01, -5.92310E+01,
> 4.68350E+01,     NA,     NA, -5.88530E+01, 4.68560E+01,     NA,     NA,
> NA,     NA,     NA,     NA, -5.83550E+01, 4.65300E+01, -5.83270E+01,
> 4.64970E+01, -5.86210E+01, 4.65320E+01,     NA,     NA, -5.82720E+01,
> 4.65060E+01, -5.81480E+01, 4.64490E+01, -5.83350E+01, 4.63650E+01,     NA,
> NA, -5.84800E+01, 4.63340E+01, -5.83980E+01, 4.63040E+01, -5.83390E+01,
> 4.62030E+01, -5.82170E+01, 4.62620E+01,     NA,     NA, -5.80420E+01,
> 4.61940E+01, -5.80360E+01, 4.57280E+01, -5.80590E+01, 4.55420E+01,
> -5.83010E+01, 4.54730E+01, -5.83710E+01, 4.55010E+01, -5.86540E+01,
> 4.52870E+01, -5.87020E+01, 4.51740E+01, -5.87400E+01, 4.52620E+01,
> -5.88330E+01, 4.53190E+01, -5.89740E+01, 4.53410E+01,     NA,     NA,
> -5.85240E+01, 4.54970E+01, -5.81710E+01, 4.56200E+01, -5.79070E+01,
> 4.58370E+01,     NA,     NA, -5.73610E+01, 4.62660E+01, -5.71820E+01,
> 4.60770E+01, -5.70540E+01, 4.59920E+01,     NA,     NA,     NA,     NA,
> -5.58460E+01, 4.51830E+01, -5.53690E+01, 4.52890E+01, -5.49260E+01,
> 4.53340E+01, -5.40070E+01, 4.53670E+01, -5.35510E+01, 4.54510E+01,     NA,
> NA, -5.15130E+01, 4.63060E+01, -5.15000E+01, 4.63280E+01, -5.08410E+01,
> 4.67780E+01, -4.99400E+01, 4.69670E+01, -4.88440E+01, 4.72810E+01,
> -4.87250E+01, 4.76880E+01, -4.70460E+01, 4.87420E+01, -5.17870E+01,
> 4.83990E+01, -4.68830E+01, 4.97030E+01, -4.73700E+01, 5.03350E+01,
> -4.75990E+01, 5.10690E+01, -5.15050E+01, 5.05110E+01, -4.80640E+01,
> 5.19200E+01, -4.83890E+01, 5.27580E+01,     NA,     NA, -4.85200E+01,
> 5.41250E+01, -4.87630E+01, 5.53650E+01,     NA,     NA, -4.84790E+01,
> 5.70560E+01, -4.82690E+01, 5.77990E+01, -4.77870E+01, 5.87570E+01,
> -4.74070E+01, 5.96700E+01, -4.76990E+01, 6.02020E+01, -4.82110E+01,
> 6.03410E+01, -4.90240E+01, 6.05510E+01, -4.89050E+01, 6.06780E+01,
> -4.80660E+01, 6.05380E+01, -4.61030E+01, 6.01290E+01,     NA,     NA,
> -4.59880E+01, 6.02070E+01, -4.55240E+01, 5.99680E+01, -4.59540E+01,
> 5.97650E+01, -4.58830E+01, 5.98200E+01, -4.64730E+01, 6.00690E+01,
> -4.64660E+01, 6.00730E+01, -4.59630E+01, 5.99330E+01, -4.63940E+01,
> 6.01380E+01, -4.64370E+01, 6.02270E+01, -4.67750E+01, 6.04410E+01,
> -4.68020E+01, 6.04700E+01, -4.57440E+01, 5.97720E+01, -4.48480E+01,
> 5.96590E+01, -4.50540E+01, 5.97830E+01), .Dim=c(120, 2))
>
> I would like to read this into R as an 120x2 array (matrix or data frame).
> How would I do so?
>
> I know I can just copy/paste all the values bound by c( ), and then just do
> something like this:
>
> y <- matrix(c(pasted values), nrow=120, ncol = 2)
>
> But, I get errors messages when I try to copy/paste the whole dataset
> because I reach line limits in the R console, such that certain values get
> split, and then R doesn't know what to do with something like "0E+01, -".
> So, I can instead try to copy/paste in a piecemeal fashion (which I've done,
> and it works fine), but I'm sure there's a better way.
>
> Thanks
> Jeff
>
> ******************************************
> Jeffrey Moore, Ph.D.
> Postdoctoral Research Scientist
> Duke Center for Marine Conservation
> Duke University Marine Laboratory
> 135 Duke Marine Lab Road
> Beaufort, NC 28516
> Phone: (252) 504-7653
> Fax: (252) 504-7689
> Email: jemoore at duke.edu
> *****************************************
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From will at hss.caltech.edu  Fri Feb 24 05:57:32 2006
From: will at hss.caltech.edu (Will Terry)
Date: Thu, 23 Feb 2006 20:57:32 -0800
Subject: [R] Graybill-Bowden confidence band
Message-ID: <597B8636-B6AC-4CDE-812A-935E6742ED4C@hss.caltech.edu>

Hi R folks,

Anyone know how I can compute the alpha significance point for a  
distribution described as "the maximum absolute value of k Student t- 
variables, each based on v degrees of freedom and having a common  
pairwise correlation coefficient rho"? In my case rho is known to be 0.

Or, more to the point, anyone know how to compute a Graybill-Bowden  
confidence band around my OLS regression line?

Thanks a bunch!
Will Terry



From samiks at ambaresearch.com  Fri Feb 24 06:04:44 2006
From: samiks at ambaresearch.com (Samik Sen)
Date: Fri, 24 Feb 2006 10:34:44 +0530
Subject: [R] Error In RBloomberg
Message-ID: <14850601FF012647A90A5DB31F96DB374A34D0@INBLRDC01.BANG.irpvl.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060224/e9e6451b/attachment.pl

From matgopa1 at umbc.edu  Fri Feb 24 07:36:29 2006
From: matgopa1 at umbc.edu (matgopa1@umbc.edu)
Date: Fri, 24 Feb 2006 01:36:29 -0500 (EST)
Subject: [R] Help with barplot
Message-ID: <1244.70.17.17.138.1140762989.squirrel@70.17.17.138>

Hello all,

I need to create a horizontal barplot with the following data:

City          Median

Springfield     34
Worcester     66
Fitchburg     65
Lowell       63
Quincy       62
Boston       36
Cambridge    54
Waltham      42
Medford      52
Pittsfield     65
Rensselaer     60
Schenectady     56
Glens Falls     64

The code below produces the bars for the Median, but how or where do I
specify the corresponding city name on the y-axis for the bars.

x<-data.frame(City=ozone.ne.trim$City,Median=ozone.ne.trim$Median)
with (x,
      barplot(Median,horiz=TRUE))

Please help.
Mathangi



From jacques.veslot at cirad.fr  Fri Feb 24 07:50:16 2006
From: jacques.veslot at cirad.fr (Jacques VESLOT)
Date: Fri, 24 Feb 2006 10:50:16 +0400
Subject: [R] Help with barplot
In-Reply-To: <1244.70.17.17.138.1140762989.squirrel@70.17.17.138>
References: <1244.70.17.17.138.1140762989.squirrel@70.17.17.138>
Message-ID: <43FEACA8.8030709@cirad.fr>

par(mar=par()$mar+c(0,3,0,0))
with(x, barplot(structure(Median, names=as.character(City)),horiz=T,las=2))


matgopa1 at umbc.edu a ??crit :

>Hello all,
>
>I need to create a horizontal barplot with the following data:
>
>City          Median
>
>Springfield     34
>Worcester     66
>Fitchburg     65
>Lowell       63
>Quincy       62
>Boston       36
>Cambridge    54
>Waltham      42
>Medford      52
>Pittsfield     65
>Rensselaer     60
>Schenectady     56
>Glens Falls     64
>
>The code below produces the bars for the Median, but how or where do I
>specify the corresponding city name on the y-axis for the bars.
>
>x<-data.frame(City=ozone.ne.trim$City,Median=ozone.ne.trim$Median)
>with (x,
>      barplot(Median,horiz=TRUE))
>
>Please help.
>Mathangi
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From chua.tock.hing at artsci.monash.edu.my  Fri Feb 24 08:19:22 2006
From: chua.tock.hing at artsci.monash.edu.my (Chua Tock Hing)
Date: Fri, 24 Feb 2006 15:19:22 +0800
Subject: [R] read table problem
Message-ID: <200602240719.k1O7JmCK002179@ms.monash.edu.my>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060224/f1fce589/attachment.pl

From ripley at stats.ox.ac.uk  Fri Feb 24 08:25:07 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 Feb 2006 07:25:07 +0000 (GMT)
Subject: [R] does multinomial logistic model from multinom (nnet) has
 logLik?
In-Reply-To: <38b9f0350602220650g5765ca1dq@mail.gmail.com>
References: <38b9f0350602220436v514bc933i@mail.gmail.com>
	<Pine.LNX.4.64.0602221351390.1081@gannet.stats.ox.ac.uk>
	<38b9f0350602220612u337f29d8k@mail.gmail.com>
	<38b9f0350602220650g5765ca1dq@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602240721220.2717@gannet.stats.ox.ac.uk>

Please note, I told you that the deviance was minus twice log-likelihood 
unless summ > 0.  I had not checked the latter case, where it is not 
obvious, but I did not say it was invalid.

In fact the answer is to be found on p.203 of MASS4 (we do ask people to 
read the supporting documentation), and this is valid also for summ > 0.
I will add a comment to the help file.

On Wed, 22 Feb 2006, ronggui wrote:

> Here is a function for calculating  the measures of fit for
> multinomial logistic model (using nnet::multinom).If anything wrong ,I
> hope  experts point it out.Thank you.
>
> fitstat <- function(object) {
> #thanks Ripley, B. D. for telling how to get the LogLik and when is invalid.
> {if (!is.null(object$call$summ) && !identical(object$call$summ,0))
>   stop("when 'summ' argument is not zero,can NOT get Loglik") }
> object.base <- update(object,.~1,trace=FALSE)
> dev.base <- deviance(object.base) ; L.base <- - dev.base/2
> dev.full <- deviance(object) ; L.full <- - dev.full/2
> G2 <- dev.base - dev.full
> df <- object$edf - object.base$edf
> LR.test.p <- pchisq(G2,df,lower=F)
>
> aic <- object$AIC
>
> n<-dim(object$residuals)[1]
>
> #get the predict value to cal count R2
> pre <- predict(object,type="class")
> y <- eval.parent(object$call$data)[,as.character(object$call$formula[[2]])]
> if (!identical(length(y),length(pre))) stop("Length not matched.")
> tab <- table(y,pre)
> if (!identical(dim(tab)[1],dim(tab)[2])) stop("pred and y have diff nlevels")
> ad <- max(rowSums(tab))#max of row sum
>
> #cal R2
> ML.R2 <- 1-exp(-G2/n)
> McFadden.R2 <- 1-(L.full/L.base)
> McFadden.Adj.R2 <- 1-((L.full-mod$edf)/L.base)
> Cragg.Uhler.R2 <- ML.R2/(1-exp(2*L.base/n))
> Count.R2 <- sum(diag(tab))/sum(tab)
> Count.adj.R2 <- (sum(diag(tab))-ad)/(sum(tab)-ad)
>
> #get the result
> res<-list(LR=G2,df=df,LR.test.p =LR.test.p
> ,aic=aic,ML.R2=ML.R2,Cragg.Uhler.R2=Cragg.Uhler.R2,McFadden.R2
> =McFadden.R2 ,McFadden.Adj.R2=McFadden.Adj.R2,Count.R2=Count.R2,Count.adj.R2=Count.adj.R2)
>
> #print the result
> cat("\n",
>    paste(rep("-",21)),
>    "\n The Fitstats are : \n",
>    sprintf("G2(%d) = %f",df,G2),
>    " ,Prob ",format.pval(LR.test.p),
>    "\n",sprintf("AIC   = %f",aic),
>    sprintf(",ML.R2 = %f \n",ML.R2),
>    paste(rep("-",21)),"\n",
>    sprintf("Cragg.Uhler.R2  = %f \n",Cragg.Uhler.R2),
>    sprintf("McFadden.R2     = %f \n",McFadden.R2),
>    sprintf("McFadden.Adj.R2 = %f \n",McFadden.Adj.R2),
>    sprintf("Count.R2        = %f \n",Count.R2),
>    sprintf("Count.adj.R2    = %f \n",Count.adj.R2),
>    "\n Note:The maxinum of ML R2 is less than 1 \n",
>    paste(rep("-",21)),"\n")
> invisible(res)
> }
>
> #example
> require(nnet)
> data(mexico,package="Zelig")
> mod <- multinom(vote88 ~ pristr + othcok + othsocok,mexico)
> summary(mod,cor=F)
> fitstat(mod)
>
> #reference:
> #J. SCOTT LONG and JEREMY FREESE,REGRESSION MODELS FOR CATEGORICAL
> DEPENDENT VARIABLES USING STATA.
>
>> fitstat(mod)
>
> - - - - - - - - - - - - - - - - - - - - -
> The Fitstats are :
> G2(6) = 381.351620  ,Prob  < 2.22e-16
> AIC   = 2376.571142 ,ML.R2 = 0.244679
> - - - - - - - - - - - - - - - - - - - - -
> Cragg.Uhler.R2  = 0.282204
> McFadden.R2     = 0.139082
> McFadden.Adj.R2 = 0.133247
> Count.R2        = 0.596026
> Count.adj.R2    = 0.123003
>
> Note:The maxinum of ML R2 is less than 1
> - - - - - - - - - - - - - - - - - - - - -
>
> ???? 06-2-22????ronggui<ronggui.huang at gmail.com> ????????????
>> So it's valid to get logLik (deviance/-2) when the summ argument is unused?
>>
>> Thank you.
>>
>> 2006/2/22, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
>>> On Wed, 22 Feb 2006, ronggui wrote:
>>>
>>>> I want to get the logLik to calculate McFadden.R2 ,ML.R2 and
>>>> Cragg.Uhler.R2, but the value from multinom does not have logLik.So my
>>>> quetion is : is logLik meaningful to multinomial logistic model from
>>>> multinom?If it does, how can I get it?
>>>
>>> From the help page:
>>>
>>> Value:
>>>
>>>       A 'nnet' object with additional components:
>>>
>>> deviance: the residual deviance.
>>>
>>> So it has a residual deviance.  That is -2 log Lik in many cases (but not
>>> if the argument 'summ' is used)
>>>
>>>> Thank you!
>>>>
>>>> ps: I konw  VGAM has function to get the multinomial logistic model
>>>> with  logLik,  but I prefer use the function from "official" R
>>>> packages .
>>>>
>>>> --
>>>> ronggui
>>>> Deparment of Sociology
>>>> Fudan University
>>>
>>> --
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>
>>
>>
>> --
>> ????????????
>> Deparment of Sociology
>> Fudan University
>>
>
>
> --
> ronggui
> Deparment of Sociology
> Fudan University
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Fri Feb 24 08:31:14 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 Feb 2006 07:31:14 +0000 (GMT)
Subject: [R] converting character matrix to a dataframe
In-Reply-To: <Pine.WNT.4.64.0602231712430.600@johnmiyamoto.psych.washington.edu>
References: <Pine.WNT.4.64.0602231712430.600@johnmiyamoto.psych.washington.edu>
Message-ID: <Pine.LNX.4.64.0602240727450.2717@gannet.stats.ox.ac.uk>

It is a bit more efficient to use as.data.frame in your apply.

You could make a copy of as.data.frame.matrix (under another name) and 
remove the special-casing of character matrices.  This would efficiently 
give you a data frame with character columns, but they would then not be 
treated 'AsIs' in subsequent manipulations.  So this is only desirable if 
efficiency is really important (and it seems unlikely to me that it is).

On Thu, 23 Feb 2006, John M. Miyamoto wrote:

> Dear R-Help,
>    Suppose I have a character matrix, e.g.,
>
> (ch.mat <- matrix(c('a','s','*','f','w','*','k','*','*','f','i','o'),
> ncol=3))
>
> When I convert 'ch.mat' to a dataframe, the columns are converted to
> factors:
>
> (d1 <- data.frame(ch.mat))
> mode(d1[,1])
> is.factor(d1[,1])
>
> To prevent this, I can use 'I' to protect the column vectors:
>
> (d2 <- data.frame(x1 = I(ch.mat[,1]), x2 = I(ch.mat[,2]), x3 =
> I(ch.mat[,3])))
> mode(d2[,1])
> is.factor(d2[,2])
>
> but this method is cumbersome if the matrix has many columns.
> The following code is reasonably efficient even if the matrix has
> arbitrarily many columns.
>
> (d3 <- data.frame(apply(ch.mat,2,function(x) data.frame(I(x)))))
> mode(d3[,1])
> is.factor(d3[,1])
>
> Question:  Is there a more efficient method than the last one for
> converting a character matrix to a dataframe while preventing the
> automatic conversion of the column vectors to factors?
>
> John
>
> --------------------------------------------------------------------
> John Miyamoto, Dept. of Psychology, Box 351525
> University of Washington, Seattle, WA 98195-1525
> Phone 206-543-0805, Fax 206-685-3157
> Homepage http://faculty.washington.edu/jmiyamot/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Fri Feb 24 08:48:17 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 24 Feb 2006 08:48:17 +0100
Subject: [R] importing data from BUGS format to R?
In-Reply-To: <971536df0602231946y821ee4ejf40569a1c525152b@mail.gmail.com>
References: <200602240343.k1O3hRsE014730@gallun.acpub.duke.edu>
	<971536df0602231946y821ee4ejf40569a1c525152b@mail.gmail.com>
Message-ID: <43FEBA41.1060405@statistik.uni-dortmund.de>

Gabor Grothendieck wrote:
> Just source the file:
> 
> source("mywinbugsfile.R")
> head(y)


... and don't forget to transpose the matrix afterwards, if this was 
BUGS code.

Uwe Ligges



> 
> On 2/23/06, Jeffrey Moore <jemoore at duke.edu> wrote:
> 
>>For those who use WinBUGS (or for those who are just familar with this
>>format), I have a text file that looks like this (which is how R would
>>export data if you used the "structure" function):
>>
>>y= structure(.Data= c(-6.93310E+01, 4.32870E+01, -6.96600E+01, 4.35730E+01,
>>-6.90150E+01, 4.35870E+01, -5.81060E+01, 4.52890E+01, -6.65590E+01,
>>4.34600E+01, -6.61850E+01, 4.35000E+01, -6.54130E+01, 4.31940E+01,
>>-6.42790E+01, 4.34780E+01, -6.35520E+01, 4.38070E+01, -6.32980E+01,
>>4.39520E+01, -6.25690E+01, 4.41760E+01, -6.20810E+01, 4.40800E+01,
>>-6.14280E+01, 4.46210E+01, -6.10530E+01, 4.48050E+01, -6.00300E+01,
>>4.50480E+01, -5.88110E+01, 4.50280E+01, -5.83660E+01, 4.50400E+01,
>>-5.83140E+01, 4.48780E+01, -5.87330E+01, 4.50340E+01, -5.87430E+01,
>>4.51630E+01, -5.88170E+01, 4.54030E+01, -5.89380E+01, 4.53260E+01,
>>-5.89110E+01, 4.55260E+01,     NA,     NA, -5.91250E+01, 4.56070E+01,
>>-5.90140E+01, 4.59690E+01, -5.89830E+01, 4.64640E+01, -5.89240E+01,
>>4.66300E+01, -5.93770E+01, 4.66810E+01, -5.90010E+01, 4.65640E+01,
>>-5.91230E+01, 4.67780E+01, -5.92350E+01, 4.70000E+01, -5.92310E+01,
>>4.68350E+01,     NA,     NA, -5.88530E+01, 4.68560E+01,     NA,     NA,
>>NA,     NA,     NA,     NA, -5.83550E+01, 4.65300E+01, -5.83270E+01,
>>4.64970E+01, -5.86210E+01, 4.65320E+01,     NA,     NA, -5.82720E+01,
>>4.65060E+01, -5.81480E+01, 4.64490E+01, -5.83350E+01, 4.63650E+01,     NA,
>>NA, -5.84800E+01, 4.63340E+01, -5.83980E+01, 4.63040E+01, -5.83390E+01,
>>4.62030E+01, -5.82170E+01, 4.62620E+01,     NA,     NA, -5.80420E+01,
>>4.61940E+01, -5.80360E+01, 4.57280E+01, -5.80590E+01, 4.55420E+01,
>>-5.83010E+01, 4.54730E+01, -5.83710E+01, 4.55010E+01, -5.86540E+01,
>>4.52870E+01, -5.87020E+01, 4.51740E+01, -5.87400E+01, 4.52620E+01,
>>-5.88330E+01, 4.53190E+01, -5.89740E+01, 4.53410E+01,     NA,     NA,
>>-5.85240E+01, 4.54970E+01, -5.81710E+01, 4.56200E+01, -5.79070E+01,
>>4.58370E+01,     NA,     NA, -5.73610E+01, 4.62660E+01, -5.71820E+01,
>>4.60770E+01, -5.70540E+01, 4.59920E+01,     NA,     NA,     NA,     NA,
>>-5.58460E+01, 4.51830E+01, -5.53690E+01, 4.52890E+01, -5.49260E+01,
>>4.53340E+01, -5.40070E+01, 4.53670E+01, -5.35510E+01, 4.54510E+01,     NA,
>>NA, -5.15130E+01, 4.63060E+01, -5.15000E+01, 4.63280E+01, -5.08410E+01,
>>4.67780E+01, -4.99400E+01, 4.69670E+01, -4.88440E+01, 4.72810E+01,
>>-4.87250E+01, 4.76880E+01, -4.70460E+01, 4.87420E+01, -5.17870E+01,
>>4.83990E+01, -4.68830E+01, 4.97030E+01, -4.73700E+01, 5.03350E+01,
>>-4.75990E+01, 5.10690E+01, -5.15050E+01, 5.05110E+01, -4.80640E+01,
>>5.19200E+01, -4.83890E+01, 5.27580E+01,     NA,     NA, -4.85200E+01,
>>5.41250E+01, -4.87630E+01, 5.53650E+01,     NA,     NA, -4.84790E+01,
>>5.70560E+01, -4.82690E+01, 5.77990E+01, -4.77870E+01, 5.87570E+01,
>>-4.74070E+01, 5.96700E+01, -4.76990E+01, 6.02020E+01, -4.82110E+01,
>>6.03410E+01, -4.90240E+01, 6.05510E+01, -4.89050E+01, 6.06780E+01,
>>-4.80660E+01, 6.05380E+01, -4.61030E+01, 6.01290E+01,     NA,     NA,
>>-4.59880E+01, 6.02070E+01, -4.55240E+01, 5.99680E+01, -4.59540E+01,
>>5.97650E+01, -4.58830E+01, 5.98200E+01, -4.64730E+01, 6.00690E+01,
>>-4.64660E+01, 6.00730E+01, -4.59630E+01, 5.99330E+01, -4.63940E+01,
>>6.01380E+01, -4.64370E+01, 6.02270E+01, -4.67750E+01, 6.04410E+01,
>>-4.68020E+01, 6.04700E+01, -4.57440E+01, 5.97720E+01, -4.48480E+01,
>>5.96590E+01, -4.50540E+01, 5.97830E+01), .Dim=c(120, 2))
>>
>>I would like to read this into R as an 120x2 array (matrix or data frame).
>>How would I do so?
>>
>>I know I can just copy/paste all the values bound by c( ), and then just do
>>something like this:
>>
>>y <- matrix(c(pasted values), nrow=120, ncol = 2)
>>
>>But, I get errors messages when I try to copy/paste the whole dataset
>>because I reach line limits in the R console, such that certain values get
>>split, and then R doesn't know what to do with something like "0E+01, -".
>>So, I can instead try to copy/paste in a piecemeal fashion (which I've done,
>>and it works fine), but I'm sure there's a better way.
>>
>>Thanks
>>Jeff
>>
>>******************************************
>>Jeffrey Moore, Ph.D.
>>Postdoctoral Research Scientist
>>Duke Center for Marine Conservation
>>Duke University Marine Laboratory
>>135 Duke Marine Lab Road
>>Beaufort, NC 28516
>>Phone: (252) 504-7653
>>Fax: (252) 504-7689
>>Email: jemoore at duke.edu
>>*****************************************
>>
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Fri Feb 24 08:50:52 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 Feb 2006 07:50:52 +0000 (GMT)
Subject: [R] Error In RBloomberg
In-Reply-To: <14850601FF012647A90A5DB31F96DB374A34D0@INBLRDC01.BANG.irpvl.com>
References: <14850601FF012647A90A5DB31F96DB374A34D0@INBLRDC01.BANG.irpvl.com>
Message-ID: <Pine.LNX.4.64.0602240734580.2717@gannet.stats.ox.ac.uk>

Someone else at the same domain sent this earlier this week, so please do
check before posting.  See

https://stat.ethz.ch/pipermail/r-help/2006-February/087382.html
(which is not complete in the archive, but arrived here).

Problems in packages should be reported to the maintainer.  In this case 
my guess is that the package needs updating as origin() is an unexported 
function from package chron.  Using another package with an unrelated 
function origin() just causes errors, and is what namespaces are designed 
to avoid.

Note that packages which are Windows-only (and in this case depend on a 
non-CRAN package) do not get tested in the daily testing.

On Fri, 24 Feb 2006, Samik Sen wrote:

> Hello R-Expert,
>
>
> Recently I was using "RBloomberg" package in R-2.2.0 in Windows (XP)
> machine installing the required packages. I checked one example using
> blpGetData guided in corresponding help file:
>
>
> conn <- blpConnect()
>
> edb <- blpGetData(conn, "ED1 Comdty", "PX_LAST", start=chron("1/1/06"),
> end=chron("1/31/06"))
>
>
>
> I got error message as following:
>
> The error message: Error in any (origin (chronDate)! = orig): couldn't
> find function "origin".
>
>
>
> Then I installed package "calibrate". I tried the same example ignoring
> "start=chron("1/1/01")" and end=chron("1/31/06").The result was:
>
>
>
> ED1 Comdty   PX_LAST
>
> 95.1125
>
> But when I tried the same with "start=chron("1/1/01")" installing the
> package "calibrate". I got followings catching edb:
>
>
>
>
>
> ED1                             Comdty           PX_LAST
>
> (02/23/06 17:53:57)                            NA
>
>
>
>
>
>
> I want to get all values of PX_LAST within 1/1/01 and 1/31/06 instead of
> getting NA on the date I am working.Any help regarding this is
> appreciated in advance.
>
>
>
> Thanks,
>
>
> Samik Sen
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Feb 24 08:52:50 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 Feb 2006 07:52:50 +0000 (GMT)
Subject: [R] read table problem
In-Reply-To: <200602240719.k1O7JmCK002179@ms.monash.edu.my>
References: <200602240719.k1O7JmCK002179@ms.monash.edu.my>
Message-ID: <Pine.LNX.4.64.0602240751370.2995@gannet.stats.ox.ac.uk>

Files save()d in R should be read back with load().
.RData or .rda are common extensions for such files.

On Fri, 24 Feb 2006, Chua Tock Hing wrote:

> Hi
>
>
>
> I have a file saved in R, named agrexp.Rdata, shown below
>
>
>
>> agrdata
>
>  fert yield
>
> 1   25    84
>
> 2   50    80
>
> 3   75    90
>
> 4  100   154
>
> 5  125   148
>
>
>
> If I double clicked on this file, the data is displayed without problem.
>
> However if I tried to import using:
>
>> agrdata<-read.table("agrexp.Rdata")   or
>
>> agrdata<-read.table("agrexp.Rdata",header=TRUE)  or
>
>> agrdata<-read.table("agrexp.Rdata",header=TRUE,row.names=1)  or
>
>> agrdata<-read.table("agrexp.Rdata",sep="")
>
>
>
> I get an error message
>
> "Warning message:
>
> incomplete final line found by readTableHeader on 'agrexp.Rdata'"
>
>
>
> or if I used:
>
>> data(agrexp)
>
> I get Warning message:
>
> data set 'agrexp' not found in: data(agrexp)
>
>
>
> Can anybody please help? I am a new user!
>
>
>
> Thank you
>
>
>
> CHUA TH
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jmiyamot at u.washington.edu  Fri Feb 24 09:58:35 2006
From: jmiyamot at u.washington.edu (John M. Miyamoto)
Date: Fri, 24 Feb 2006 00:58:35 -0800 (Pacific Standard Time)
Subject: [R] converting character matrix to a dataframe
In-Reply-To: <Pine.LNX.4.64.0602240727450.2717@gannet.stats.ox.ac.uk>
References: <Pine.WNT.4.64.0602231712430.600@johnmiyamoto.psych.washington.edu>
	<Pine.LNX.4.64.0602240727450.2717@gannet.stats.ox.ac.uk>
Message-ID: <Pine.WNT.4.63.0602240052150.1436@miyamoto.psych.washington.edu>

On Fri, 24 Feb 2006, Prof Brian Ripley wrote:

> It is a bit more efficient to use as.data.frame in your apply.
>
> You could make a copy of as.data.frame.matrix (under another name) and remove 
> the special-casing of character matrices.  This would efficiently give you a 
> data frame with character columns, but they would then not be treated 'AsIs' 
> in subsequent manipulations.  So this is only desirable if efficiency is 
> really important (and it seems unlikely to me that it is).
>
> On Thu, 23 Feb 2006, John M. Miyamoto wrote:
>
>> Dear R-Help,
>>    Suppose I have a character matrix, e.g.,
>> 
>> (ch.mat <- matrix(c('a','s','*','f','w','*','k','*','*','f','i','o'),
>> ncol=3))
>> 
>> When I convert 'ch.mat' to a dataframe, the columns are converted to
>> factors:
[SNIP]
>> The following code is reasonably efficient even if the matrix has
>> arbitrarily many columns.
>> 
>> (d3 <- data.frame(apply(ch.mat,2,function(x) data.frame(I(x)))))
>> mode(d3[,1])
>> is.factor(d3[,1])
>> 
>> Question:  Is there a more efficient method than the last one for
>> converting a character matrix to a dataframe while preventing the
>> automatic conversion of the column vectors to factors?

So I take it that this last solution would be:

(ch.mat <- matrix(c('a','s','*','f','w','*','k','*','*','f','i','o'), 
ncol=3))

(d4 <- data.frame(apply(ch.mat, 2, function(x) as.data.frame(I(x)))))
mode(d4[,1])
is.factor(d4[,1])

You're right that I'm not really concerned with computational efficiency, 
but only minimizing the amount of code that I have to write and remember. 
The solution seems to be that I should write a function that accomplishes 
this task, which I have done.  Thank you.

John



From plummer at iarc.fr  Fri Feb 24 10:27:21 2006
From: plummer at iarc.fr (Martyn Plummer)
Date: Fri, 24 Feb 2006 10:27:21 +0100
Subject: [R] importing data from BUGS format to R?
In-Reply-To: <43FEBA41.1060405@statistik.uni-dortmund.de>
References: <200602240343.k1O3hRsE014730@gallun.acpub.duke.edu>
	<971536df0602231946y821ee4ejf40569a1c525152b@mail.gmail.com>
	<43FEBA41.1060405@statistik.uni-dortmund.de>
Message-ID: <1140773241.3012.15.camel@seurat.iarc.fr>

On Fri, 2006-02-24 at 08:48 +0100, Uwe Ligges wrote:
> Gabor Grothendieck wrote:
> > Just source the file:
> > 
> > source("mywinbugsfile.R")
> > head(y)
> 
> 
> ... and don't forget to transpose the matrix afterwards, if this was 
> BUGS code.
> 
> Uwe Ligges

If this were a WinBUGS data file (or initial values file), the whole
expression would be wrapped in a call to list(). In this case, you would
need to assign the output from source(), or use the dget() function,
e.g. for the EPILEPSY example:

> mydata <- dget("epildata.txt")
> names(mydata)
[1] "N"    "T"    "y"    "Trt"  "Base" "Age"  "V4"
> mydata$T
[1] 4

But, as Uwe points out, arrays will need to be reorganized, as WinBUGS
fills matrices by row rather than column.

> head(mydata$y) #wrong!
     [,1] [,2] [,3] [,4]
[1,]    5    9    9    7
[2,]    3   11    4    6
[3,]    3    0    0    7
[4,]    3    0    4    1
[5,]    3    5    3    1
[6,]    5    0    0    2

I wrote a function called "bugs2jags", which you will find in the coda
package, for converting WinBUGS data files into the data format used by
JAGS which is, by no coincidence, the format used by the R function
dump().

> library(coda)
Loading required package: lattice
> bugs2jags("epildata.txt","epildata.R") #Creates file "epildata.R"
> source("epildata.R")
> ls()
[1] "Age"  "Base" "N"    "T"    "Trt"  "V4"   "y"

This creates objects in your work space, and sorts out the arrays

> head(y) #right
     [,1] [,2] [,3] [,4]
[1,]    5    3    3    3
[2,]    3    5    3    3
[3,]    2    4    0    5
[4,]    4    4    1    4
[5,]    7   18    9   21
[6,]    5    2    8    7

Martyn

> 
> > 
> > On 2/23/06, Jeffrey Moore <jemoore at duke.edu> wrote:
> > 
> >>For those who use WinBUGS (or for those who are just familar with this
> >>format), I have a text file that looks like this (which is how R would
> >>export data if you used the "structure" function):
> >>
> >>y= structure(.Data= c(-6.93310E+01, 4.32870E+01, -6.96600E+01, 4.35730E+01,
> >>-6.90150E+01, 4.35870E+01, -5.81060E+01, 4.52890E+01, -6.65590E+01,
> >>4.34600E+01, -6.61850E+01, 4.35000E+01, -6.54130E+01, 4.31940E+01,
> >>-6.42790E+01, 4.34780E+01, -6.35520E+01, 4.38070E+01, -6.32980E+01,
> >>4.39520E+01, -6.25690E+01, 4.41760E+01, -6.20810E+01, 4.40800E+01,
> >>-6.14280E+01, 4.46210E+01, -6.10530E+01, 4.48050E+01, -6.00300E+01,
> >>4.50480E+01, -5.88110E+01, 4.50280E+01, -5.83660E+01, 4.50400E+01,
> >>-5.83140E+01, 4.48780E+01, -5.87330E+01, 4.50340E+01, -5.87430E+01,
> >>4.51630E+01, -5.88170E+01, 4.54030E+01, -5.89380E+01, 4.53260E+01,
> >>-5.89110E+01, 4.55260E+01,     NA,     NA, -5.91250E+01, 4.56070E+01,
> >>-5.90140E+01, 4.59690E+01, -5.89830E+01, 4.64640E+01, -5.89240E+01,
> >>4.66300E+01, -5.93770E+01, 4.66810E+01, -5.90010E+01, 4.65640E+01,
> >>-5.91230E+01, 4.67780E+01, -5.92350E+01, 4.70000E+01, -5.92310E+01,
> >>4.68350E+01,     NA,     NA, -5.88530E+01, 4.68560E+01,     NA,     NA,
> >>NA,     NA,     NA,     NA, -5.83550E+01, 4.65300E+01, -5.83270E+01,
> >>4.64970E+01, -5.86210E+01, 4.65320E+01,     NA,     NA, -5.82720E+01,
> >>4.65060E+01, -5.81480E+01, 4.64490E+01, -5.83350E+01, 4.63650E+01,     NA,
> >>NA, -5.84800E+01, 4.63340E+01, -5.83980E+01, 4.63040E+01, -5.83390E+01,
> >>4.62030E+01, -5.82170E+01, 4.62620E+01,     NA,     NA, -5.80420E+01,
> >>4.61940E+01, -5.80360E+01, 4.57280E+01, -5.80590E+01, 4.55420E+01,
> >>-5.83010E+01, 4.54730E+01, -5.83710E+01, 4.55010E+01, -5.86540E+01,
> >>4.52870E+01, -5.87020E+01, 4.51740E+01, -5.87400E+01, 4.52620E+01,
> >>-5.88330E+01, 4.53190E+01, -5.89740E+01, 4.53410E+01,     NA,     NA,
> >>-5.85240E+01, 4.54970E+01, -5.81710E+01, 4.56200E+01, -5.79070E+01,
> >>4.58370E+01,     NA,     NA, -5.73610E+01, 4.62660E+01, -5.71820E+01,
> >>4.60770E+01, -5.70540E+01, 4.59920E+01,     NA,     NA,     NA,     NA,
> >>-5.58460E+01, 4.51830E+01, -5.53690E+01, 4.52890E+01, -5.49260E+01,
> >>4.53340E+01, -5.40070E+01, 4.53670E+01, -5.35510E+01, 4.54510E+01,     NA,
> >>NA, -5.15130E+01, 4.63060E+01, -5.15000E+01, 4.63280E+01, -5.08410E+01,
> >>4.67780E+01, -4.99400E+01, 4.69670E+01, -4.88440E+01, 4.72810E+01,
> >>-4.87250E+01, 4.76880E+01, -4.70460E+01, 4.87420E+01, -5.17870E+01,
> >>4.83990E+01, -4.68830E+01, 4.97030E+01, -4.73700E+01, 5.03350E+01,
> >>-4.75990E+01, 5.10690E+01, -5.15050E+01, 5.05110E+01, -4.80640E+01,
> >>5.19200E+01, -4.83890E+01, 5.27580E+01,     NA,     NA, -4.85200E+01,
> >>5.41250E+01, -4.87630E+01, 5.53650E+01,     NA,     NA, -4.84790E+01,
> >>5.70560E+01, -4.82690E+01, 5.77990E+01, -4.77870E+01, 5.87570E+01,
> >>-4.74070E+01, 5.96700E+01, -4.76990E+01, 6.02020E+01, -4.82110E+01,
> >>6.03410E+01, -4.90240E+01, 6.05510E+01, -4.89050E+01, 6.06780E+01,
> >>-4.80660E+01, 6.05380E+01, -4.61030E+01, 6.01290E+01,     NA,     NA,
> >>-4.59880E+01, 6.02070E+01, -4.55240E+01, 5.99680E+01, -4.59540E+01,
> >>5.97650E+01, -4.58830E+01, 5.98200E+01, -4.64730E+01, 6.00690E+01,
> >>-4.64660E+01, 6.00730E+01, -4.59630E+01, 5.99330E+01, -4.63940E+01,
> >>6.01380E+01, -4.64370E+01, 6.02270E+01, -4.67750E+01, 6.04410E+01,
> >>-4.68020E+01, 6.04700E+01, -4.57440E+01, 5.97720E+01, -4.48480E+01,
> >>5.96590E+01, -4.50540E+01, 5.97830E+01), .Dim=c(120, 2))
> >>
> >>I would like to read this into R as an 120x2 array (matrix or data frame).
> >>How would I do so?
> >>
> >>I know I can just copy/paste all the values bound by c( ), and then just do
> >>something like this:
> >>
> >>y <- matrix(c(pasted values), nrow=120, ncol = 2)
> >>
> >>But, I get errors messages when I try to copy/paste the whole dataset
> >>because I reach line limits in the R console, such that certain values get
> >>split, and then R doesn't know what to do with something like "0E+01, -".
> >>So, I can instead try to copy/paste in a piecemeal fashion (which I've done,
> >>and it works fine), but I'm sure there's a better way.
> >>
> >>Thanks
> >>Jeff
> >>
> >>******************************************
> >>Jeffrey Moore, Ph.D.
> >>Postdoctoral Research Scientist
> >>Duke Center for Marine Conservation
> >>Duke University Marine Laboratory
> >>135 Duke Marine Lab Road
> >>Beaufort, NC 28516
> >>Phone: (252) 504-7653
> >>Fax: (252) 504-7689
> >>Email: jemoore at duke.edu
> >>*****************************************
> >>
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >>
> > 
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-----------------------------------------------------------------------
This message and its attachments are strictly confidential. ...{{dropped}}



From jgarcia at ija.csic.es  Fri Feb 24 11:00:46 2006
From: jgarcia at ija.csic.es (Javier Garcia-Pintado)
Date: Fri, 24 Feb 2006 11:00:46 +0100
Subject: [R] R script autoload at startup
Message-ID: <7.0.0.16.0.20060224105224.01f27a90@ija.csic.es>

Hello;
I'm now using mainly R for windows, mainly because I'm writing a 
tcl/Tk interface for some people, and I've got two questions. I'm an 
absolute beginner with tctk or tcktk use under the R GUI.

1) Is it posible to create a shorcut that launchs the R GUI and 
automatically reads the "source code" of the tcl/tk script to also 
launch the tcltk interface?

2) Is the RGUI programmed with tcltk? In this case, is it possible 
for an user like me to create a menu entry at the R GUI to call the 
source code in this R/tcl/Tk script?

Any of the two options would be very good for us.

Thanks and best regards,

Javier



From robin.smit at tno.nl  Fri Feb 24 11:04:03 2006
From: robin.smit at tno.nl (Smit, R. (Robin))
Date: Fri, 24 Feb 2006 11:04:03 +0100
Subject: [R] Extracting information from factanal()
Message-ID: <2395774549BBDA40AC83BC9E6223FBFF99D06B@MS-DT01VS01.tsn.tno.nl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060224/e8ea35b3/attachment.pl

From dingjia at gmail.com  Fri Feb 24 11:17:55 2006
From: dingjia at gmail.com (jia ding)
Date: Fri, 24 Feb 2006 11:17:55 +0100
Subject: [R] 2 barplots in the same graph
In-Reply-To: <971536df0602220824y6f3e1a8eo6b5cc041250cf097@mail.gmail.com>
References: <91ae6e350602220531g7b562a30q7b382a23debc28f1@mail.gmail.com>
	<971536df0602220824y6f3e1a8eo6b5cc041250cf097@mail.gmail.com>
Message-ID: <91ae6e350602240217l14b6cd31ke0ef89ec0089d9c2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060224/b95f3d5a/attachment.pl

From ronggui.huang at gmail.com  Fri Feb 24 11:29:17 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Fri, 24 Feb 2006 18:29:17 +0800
Subject: [R] does multinomial logistic model from multinom (nnet) has
	logLik?
In-Reply-To: <Pine.LNX.4.64.0602240721220.2717@gannet.stats.ox.ac.uk>
References: <38b9f0350602220436v514bc933i@mail.gmail.com>
	<Pine.LNX.4.64.0602221351390.1081@gannet.stats.ox.ac.uk>
	<38b9f0350602220612u337f29d8k@mail.gmail.com>
	<38b9f0350602220650g5765ca1dq@mail.gmail.com>
	<Pine.LNX.4.64.0602240721220.2717@gannet.stats.ox.ac.uk>
Message-ID: <38b9f0350602240229m426e7463y@mail.gmail.com>

I should ues "Not obvious " instead of "invalid", this is my mistake.

2006/2/24, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> Please note, I told you that the deviance was minus twice log-likelihood
> unless summ > 0.  I had not checked the latter case, where it is not
> obvious, but I did not say it was invalid.
>
> In fact the answer is to be found on p.203 of MASS4 (we do ask people to
> read the supporting documentation), and this is valid also for summ > 0.

I did read the help page in nnet.And MASS4 is not avaivable  just now :(

I will check that when I can.

> I will add a comment to the help file.

appreciate!


> On Wed, 22 Feb 2006, ronggui wrote:
>
> > Here is a function for calculating  the measures of fit for
> > multinomial logistic model (using nnet::multinom).If anything wrong ,I
> > hope  experts point it out.Thank you.
> >
> > fitstat <- function(object) {
> > #thanks Ripley, B. D. for telling how to get the LogLik and when is not obvious.
> > {if (!is.null(object$call$summ) && !identical(object$call$summ,0))
> >   stop("when 'summ' argument is not zero,can NOT get Loglik") }
> > object.base <- update(object,.~1,trace=FALSE)
> > dev.base <- deviance(object.base) ; L.base <- - dev.base/2
> > dev.full <- deviance(object) ; L.full <- - dev.full/2
> > G2 <- dev.base - dev.full
> > df <- object$edf - object.base$edf
> > LR.test.p <- pchisq(G2,df,lower=F)
> >
> > aic <- object$AIC
> >
> > n<-dim(object$residuals)[1]
> >
> > #get the predict value to cal count R2
> > pre <- predict(object,type="class")
> > y <- eval.parent(object$call$data)[,as.character(object$call$formula[[2]])]
> > if (!identical(length(y),length(pre))) stop("Length not matched.")
> > tab <- table(y,pre)
> > if (!identical(dim(tab)[1],dim(tab)[2])) stop("pred and y have diff nlevels")
> > ad <- max(rowSums(tab))#max of row sum
> >
> > #cal R2
> > ML.R2 <- 1-exp(-G2/n)
> > McFadden.R2 <- 1-(L.full/L.base)
> > McFadden.Adj.R2 <- 1-((L.full-mod$edf)/L.base)
> > Cragg.Uhler.R2 <- ML.R2/(1-exp(2*L.base/n))
> > Count.R2 <- sum(diag(tab))/sum(tab)
> > Count.adj.R2 <- (sum(diag(tab))-ad)/(sum(tab)-ad)
> >
> > #get the result
> > res<-list(LR=G2,df=df,LR.test.p =LR.test.p
> > ,aic=aic,ML.R2=ML.R2,Cragg.Uhler.R2=Cragg.Uhler.R2,McFadden.R2
> > =McFadden.R2 ,McFadden.Adj.R2=McFadden.Adj.R2,Count.R2=Count.R2,Count.adj.R2=Count.adj.R2)
> >
> > #print the result
> > cat("\n",
> >    paste(rep("-",21)),
> >    "\n The Fitstats are : \n",
> >    sprintf("G2(%d) = %f",df,G2),
> >    " ,Prob ",format.pval(LR.test.p),
> >    "\n",sprintf("AIC   = %f",aic),
> >    sprintf(",ML.R2 = %f \n",ML.R2),
> >    paste(rep("-",21)),"\n",
> >    sprintf("Cragg.Uhler.R2  = %f \n",Cragg.Uhler.R2),
> >    sprintf("McFadden.R2     = %f \n",McFadden.R2),
> >    sprintf("McFadden.Adj.R2 = %f \n",McFadden.Adj.R2),
> >    sprintf("Count.R2        = %f \n",Count.R2),
> >    sprintf("Count.adj.R2    = %f \n",Count.adj.R2),
> >    "\n Note:The maxinum of ML R2 is less than 1 \n",
> >    paste(rep("-",21)),"\n")
> > invisible(res)
> > }
> >
> > #example
> > require(nnet)
> > data(mexico,package="Zelig")
> > mod <- multinom(vote88 ~ pristr + othcok + othsocok,mexico)
> > summary(mod,cor=F)
> > fitstat(mod)
> >
> > #reference:
> > #J. SCOTT LONG and JEREMY FREESE,REGRESSION MODELS FOR CATEGORICAL
> > DEPENDENT VARIABLES USING STATA.
> >
> >> fitstat(mod)
> >
> > - - - - - - - - - - - - - - - - - - - - -
> > The Fitstats are :
> > G2(6) = 381.351620  ,Prob  < 2.22e-16
> > AIC   = 2376.571142 ,ML.R2 = 0.244679
> > - - - - - - - - - - - - - - - - - - - - -
> > Cragg.Uhler.R2  = 0.282204
> > McFadden.R2     = 0.139082
> > McFadden.Adj.R2 = 0.133247
> > Count.R2        = 0.596026
> > Count.adj.R2    = 0.123003
> >
> > Note:The maxinum of ML R2 is less than 1
> > - - - - - - - - - - - - - - - - - - - - -
> >
> >  06-2-22ronggui<ronggui.huang at gmail.com> 
> >> So it's valid to get logLik (deviance/-2) when the summ argument is unused?
> >>
> >> Thank you.
> >>
> >> 2006/2/22, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> >>> On Wed, 22 Feb 2006, ronggui wrote:
> >>>
> >>>> I want to get the logLik to calculate McFadden.R2 ,ML.R2 and
> >>>> Cragg.Uhler.R2, but the value from multinom does not have logLik.So my
> >>>> quetion is : is logLik meaningful to multinomial logistic model from
> >>>> multinom?If it does, how can I get it?
> >>>
> >>> From the help page:
> >>>
> >>> Value:
> >>>
> >>>       A 'nnet' object with additional components:
> >>>
> >>> deviance: the residual deviance.
> >>>
> >>> So it has a residual deviance.  That is -2 log Lik in many cases (but not
> >>> if the argument 'summ' is used)
> >>>
> >>>> Thank you!
> >>>>
> >>>> ps: I konw  VGAM has function to get the multinomial logistic model
> >>>> with  logLik,  but I prefer use the function from "official" R
> >>>> packages .
> >>>>
> >>>> --
> >>>> ronggui
> >>>> Deparment of Sociology
> >>>> Fudan University
> >>>
> >>> --
> >>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >>> University of Oxford,             Tel:  +44 1865 272861 (self)
> >>> 1 South Parks Road,                     +44 1865 272866 (PA)
> >>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>>
> >>
> >>
> >> --
> >> 
> >> Deparment of Sociology
> >> Fudan University
> >>
> >
> >
> > --
> > ronggui
> > Deparment of Sociology
> > Fudan University
> >
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


--

Deparment of Sociology
Fudan University



From francoisromain at free.fr  Fri Feb 24 11:31:26 2006
From: francoisromain at free.fr (Romain Francois)
Date: Fri, 24 Feb 2006 11:31:26 +0100
Subject: [R] 2 barplots in the same graph
In-Reply-To: <91ae6e350602240217l14b6cd31ke0ef89ec0089d9c2@mail.gmail.com>
References: <91ae6e350602220531g7b562a30q7b382a23debc28f1@mail.gmail.com>	<971536df0602220824y6f3e1a8eo6b5cc041250cf097@mail.gmail.com>
	<91ae6e350602240217l14b6cd31ke0ef89ec0089d9c2@mail.gmail.com>
Message-ID: <43FEE07E.6060605@free.fr>

Le 24.02.2006 11:17, jia ding a ??crit :
> Thanks All!
>
> I combine your answers and post the code here again, if later somebody need
> it.
>
> Actually, what I want is:
>   
>> x1
>>     
> [1]  1  2 10
>   
>> x2
>>     
> [1] -3  5 -8
>   
>> barplot(x1,col="white",border="red")
>> barplot(x2,col="white",border="green",add=T)
>>     
> So that, the two plots even share the same x-axis.
>
> But, It comes another question: >
> barplot(x2,col="white",border="green",add=T), because there are 2 numbers
> are negative, some part of the bar is missing. Is there any automatic
> function to make the axes fit very well for both bars?
>
>   
R> barplot(x1,col="white",border="red", ylim=range(c(x1,x2)))
> And, suppose I want to add another command: axis(1, 0:20) to draw x-axis. I
> notice it  increase like: 0,1,2,3,...20; how can I make it 0,5,15,20?
>
>   
before doing axis(1, 0:20) have you tried to do
R> 0:20

So,

R> axis(1, (0:4)*5)
or
R> axis(1, c(0,5, 10, 15, 20))
or
R> axis(1, seq(0,20, by=5))

it's up to you. There are probably other solutions as well
> Thanks!
>
>   
You're welcome

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
Discover the R Movies Gallery : http://addictedtor.free.fr/movies
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From Torsten.Hothorn at rzmail.uni-erlangen.de  Fri Feb 24 11:39:44 2006
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Fri, 24 Feb 2006 11:39:44 +0100 (CET)
Subject: [R] [R-pkgs] New `party' tools
Message-ID: <Pine.LNX.4.64.0602241135480.4699@artemis.imbe.med.uni-erlangen.de>


Dear useRs,

Version 0.8-1 of the `party' package will appear on CRAN and its mirrors
in due course. This version implements two new tools:

   o  `mob', an object-oriented implementation of a recently suggested
       algorithm for model-based recursive partitioning (Zeileis, Hothorn,
       Hornik, 2005) has been added. It works out of the box for partitioning
       (generalized) linear regression models, others can be easily plugged
       in. A new vignette "MOB" describes the implementation ideas and
       provides a few examples with nice plots.

   o  `cforest', an implementation of Breiman's random forest ensemble
       algorithm based on conditional inference trees (`ctree') has been
       added and can be used to analyse censored data and weighted
       problems.

Moreover, some minor issues have been addressed and are documented in the 
CHANGES file.

Best wishes,

Torsten, Kurt and Achim.

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From dingjia at gmail.com  Fri Feb 24 11:58:58 2006
From: dingjia at gmail.com (jia ding)
Date: Fri, 24 Feb 2006 11:58:58 +0100
Subject: [R] 2 barplots in the same graph
In-Reply-To: <43FEE07E.6060605@free.fr>
References: <91ae6e350602220531g7b562a30q7b382a23debc28f1@mail.gmail.com>
	<971536df0602220824y6f3e1a8eo6b5cc041250cf097@mail.gmail.com>
	<91ae6e350602240217l14b6cd31ke0ef89ec0089d9c2@mail.gmail.com>
	<43FEE07E.6060605@free.fr>
Message-ID: <91ae6e350602240258x7a0a772cw45869eb1c0be88e3@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060224/003b6c1a/attachment.pl

From francoisromain at free.fr  Fri Feb 24 12:58:53 2006
From: francoisromain at free.fr (Romain Francois)
Date: Fri, 24 Feb 2006 12:58:53 +0100
Subject: [R] 2 barplots in the same graph
In-Reply-To: <91ae6e350602240258x7a0a772cw45869eb1c0be88e3@mail.gmail.com>
References: <91ae6e350602220531g7b562a30q7b382a23debc28f1@mail.gmail.com>	
	<971536df0602220824y6f3e1a8eo6b5cc041250cf097@mail.gmail.com>	
	<91ae6e350602240217l14b6cd31ke0ef89ec0089d9c2@mail.gmail.com>	
	<43FEE07E.6060605@free.fr>
	<91ae6e350602240258x7a0a772cw45869eb1c0be88e3@mail.gmail.com>
Message-ID: <43FEF4FD.40405@free.fr>

Le 24.02.2006 11:58, jia ding a ??crit :
> Hi,
> Would you pls try  these?
>
>  x1<-c(1,2,10)
>  x2<-c(-3,5,-8)
>  barplot(x1,col="white",border="red",ylim=range(c(x1,x2)))
>  barplot(x2,col="white",border="green",ylim=range(c(x1,x2)),add=T)
>  axis(1, 0:3)
>  box()
>
ylim is not needed on the second call.

>
> Q1, on x-axis "1,2,3" is not shown at the middle position of the bars. 
> e.g for first bar, "1" is tend to right ; while third bar, "3" is tend 
> to left.

Use the outputs from barplot :

out <- barplot(x1,col="white",border="red",ylim=extendrange(c(x1,x2)))
out
axis(1, out[,1], sprintf('bar %d', 1:3))

> Q2, once >box(), then bars are cut again.

You can use extendrange instead of range, ie :

barplot(x1,col="white",border="red",ylim=extendrange(c(x1,x2)))

> Q3, when y-axis is "0", I want to draw a parallel line to  x-axis:
>       I tried >lines(c(0,5),c(0,0)) ; is there any other way to do it?

abline(h=0)

> Thanks.
>
> Nina
Also, try :
?barplot
http://addictedtor.free.fr/graphiques/search.php?q=barplot

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
Discover the R Movies Gallery : http://addictedtor.free.fr/movies
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From ripley at stats.ox.ac.uk  Fri Feb 24 13:00:56 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 Feb 2006 12:00:56 +0000 (GMT)
Subject: [R] Extracting information from factanal()
In-Reply-To: <2395774549BBDA40AC83BC9E6223FBFF99D06B@MS-DT01VS01.tsn.tno.nl>
References: <2395774549BBDA40AC83BC9E6223FBFF99D06B@MS-DT01VS01.tsn.tno.nl>
Message-ID: <Pine.LNX.4.64.0602241153470.6480@gannet.stats.ox.ac.uk>

For the loadings, please use the loadings() accessor function.  It is 
"loadings" print method that is giving you the "proportion var", not 
factanal().  So to use a reproducible example

> example(factanal)
> fit <- factanal(m1, factors = 3)
> (ld <- loadings(fit))

Loadings:
    Factor1 Factor2 Factor3
v1 0.944   0.182   0.267
v2 0.905   0.235   0.159
v3 0.236   0.210   0.946
v4 0.180   0.242   0.828
v5 0.242   0.881   0.286
v6 0.193   0.959   0.196

                Factor1 Factor2 Factor3
SS loadings      1.893   1.886   1.797
Proportion Var   0.316   0.314   0.300
Cumulative Var   0.316   0.630   0.929

and look at S3method("print", "loadings") to see how it does that.  (It 
calculates the summary table, not extracts the values.)


On Fri, 24 Feb 2006, Smit, R. (Robin) wrote:

> Dear list members,
>
>
>
> I apologize for putting this (probably) very basic question on the
> mailing list. I have scanned through the R website (using search) but
> did not found an answer.
>
>
>
> (code included below)
>
>
>
> A factor matrix is simply extracted (which can then subsequently be
> exported using write.table) by FACT$loadings[1:6,].
>
> I would also like to specifically extract and export "proportion var",
> but unfortunately are not succesful after attempting different ways
> (str(FACT) did not help me).
>
> Any suggestions/comments are appreciated.
>
>
>
> Kind regards,
> Robin Smit
>
>
>
>
>
>> FACT <- factanal(HATCO, 2, rotation = "none")
>> FACT
>
> Call:
> factanal(x = HATCO, factors = 2, rotation = "none")
>
> Uniquenesses:
>   x1    x2    x3    x4    x6    x7
> 0.498 0.568 0.477 0.111 0.298 0.526
>
> Loadings:
>   Factor1 Factor2
> x1          0.709
> x2  0.326  -0.570
> x3 -0.166   0.704
> x4  0.941
> x6  0.829   0.118
> x7  0.267  -0.634
>
>               Factor1 Factor2
> SS loadings      1.778   1.743
> Proportion Var   0.296   0.291
> Cumulative Var   0.296   0.587
>
> Test of the hypothesis that 2 factors are sufficient.
> The chi square statistic is 3.98 on 4 degrees of freedom.
> The p-value is 0.409
>
>
>
> This e-mail and its contents are subject to the DISCLAIMER at http://www.tno.nl/disclaimer/email.html
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From zh107 at york.ac.uk  Fri Feb 24 13:31:49 2006
From: zh107 at york.ac.uk (Zhesi He)
Date: Fri, 24 Feb 2006 12:31:49 +0000
Subject: [R] RGtk2 install in Mac
Message-ID: <29f7c6ea58e192edc966de523151a46b@york.ac.uk>

Dear R-list,

I'm struggling installing RGtk2 on my Mac. Has anybody succeeded in  
doing so?

I've got Gtk2.8 (finally)
and I have R2.0.1

I'm using ibook G4 and Mac 10.3.9

and here is the error I got from installing
 > R CMD INSTALL ~/Desktop/install/RGtk2_2.8.0-0.tar.gz

* Installing *source* package 'RGtk2' ...
checking for pkg-config... /sw/bin/pkg-config
checking pkg-config is at least version 0.9.0... yes
checking for GTK... yes
checking for LIBGLADE... yes
checking for GTKMOZEMBED... configure: WARNING: firefox-gtkmozembed not  
found
configure: creating ./config.status
config.status: creating src/Makevars
** libs
gcc -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include  
  -I/usr/local/include  -g -D_R_=1 -DUSE_R=1  
-I/usr/local/include/gtk-2.0 -I/usr/local/lib/gtk-2.0/include  
-I/usr/local/include/atk-1.0 -I/usr/local/include/cairo  
-I/usr/local/include/pango-1.0 -I/usr/local/include/glib-2.0  
-I/usr/local/lib/glib-2.0/include   -I/usr/local/include/libglade-2.0  
-I/usr/local/include/gtk-2.0 -I/usr/local/include/libxml2  
-I/usr/local/lib/gtk-2.0/include -I/usr/local/include/atk-1.0  
-I/usr/local/include/cairo -I/usr/local/include/pango-1.0  
-I/usr/local/include/glib-2.0 -I/usr/local/lib/glib-2.0/include     
-I/Library/Frameworks/R.framework/Resources/include  -DHAVE_LIBGLADE  
-fno-common  -g -O2 -c RGtkDataFrame.c -o RGtkDataFrame.o

......

gcc -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/include  
  -I/usr/local/include  -g -D_R_=1 -DUSE_R=1  
-I/usr/local/include/gtk-2.0 -I/usr/local/lib/gtk-2.0/include  
-I/usr/local/include/atk-1.0 -I/usr/local/include/cairo  
-I/usr/local/include/pango-1.0 -I/usr/local/include/glib-2.0  
-I/usr/local/lib/glib-2.0/include   -I/usr/local/include/libglade-2.0  
-I/usr/local/include/gtk-2.0 -I/usr/local/include/libxml2  
-I/usr/local/lib/gtk-2.0/include -I/usr/local/include/atk-1.0  
-I/usr/local/include/cairo -I/usr/local/include/pango-1.0  
-I/usr/local/include/glib-2.0 -I/usr/local/lib/glib-2.0/include     
-I/Library/Frameworks/R.framework/Resources/include  -DHAVE_LIBGLADE  
-fno-common  -g -O2 -c conversion.c -o conversion.o
conversion.c: In function `asCRaw':
conversion.c:49: error: subscripted value is neither array nor pointer
conversion.c: In function `asRRaw':
conversion.c:87: warning: assignment makes pointer from integer without  
a cast
conversion.c:88: error: subscripted value is neither array nor pointer
make: *** [conversion.o] Error 1
ERROR: compilation failed for package 'RGtk2'
** Removing  
'/Library/Frameworks/R.framework/Versions/2.0.1/Resources/library/ 
RGtk2'
** Restoring previous  
'/Library/Frameworks/R.framework/Versions/2.0.1/Resources/library/ 
RGtk2'


Any suggestions would be helpful.
Thanks

___________________________________________________

Zhesi He
S-Block Biology, YCCSA, University of York
York YO10 5YW, U.K.
Phone:  +44-(0)1904-328554
Email:  zh107 at york.ac.uk



From ramasamy at cancer.org.uk  Fri Feb 24 14:51:31 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 24 Feb 2006 13:51:31 +0000
Subject: [R] Ranking within factor subgroups
In-Reply-To: <x2hd6qy4g2.fsf@turmalin.kubism.ku.dk>
References: <BAY107-F3592EDACEA8D92D1128BBCD2F20@phx.gbl>
	<x2hd6qy4g2.fsf@turmalin.kubism.ku.dk>
Message-ID: <1140789091.11525.43.camel@dhcp-82.wolf.ox.ac.uk>

Thank you! I did not know about the split and unsplit functions. It
looks like a very powerful and useful combination to master.

Regards, Adai



On Thu, 2006-02-23 at 07:28 +0100, Peter Dalgaard wrote:
> "maneesh deshpande" <dmaneesh at hotmail.com> writes:
> 
> > Hi Adai,
> > 
> > I think your solution only works if the rows of the data frame are ordered 
> > by "date" and
> > the ordering function is the same used to order the levels of 
> > factor(df$date) ?
> > It turns out (as I implied in my question) my data is indeed organized in 
> > this manner, so my
> > current problem is solved.
> > In the general case, I suppose, one could always order the data frame by 
> > date before proceeding ?
> > 
> > Thanks,
> > 
> > Maneesh
> 
> You might prefer to look at split/unsplit/split<-, i.e. the z-scores
> by group line:
> 
>      z <- unsplit(lapply(split(x, g), scale), g)
> 
> with "scale" suitably replaced. Presumably (meaning: I didn't quite
> read your code closely enough)
> 
>     z <- unsplit(lapply(split(x, g), bucket, 10), g)
> 
> could do it.
>  
> > 
> > >From: Adaikalavan Ramasamy <ramasamy at cancer.org.uk>
> > >Reply-To: ramasamy at cancer.org.uk
> > >To: maneesh deshpande <dmaneesh at hotmail.com>
> > >CC: r-help at stat.math.ethz.ch
> > >Subject: Re: [R]  Ranking within factor subgroups
> > >Date: Wed, 22 Feb 2006 03:44:45 +0000
> > >
> > >It might help to give a simple reproducible example in the future. For
> > >example
> > >
> > >  df <- cbind.data.frame( date=rep( 1:5, each=100 ), A=rpois(500, 100),
> > >                          B=rpois(500, 50), C=rpois(500, 30) )
> > >
> > >might generate something like
> > >
> > >	    date   A  B  C
> > >	  1    1  93 51 32
> > >	  2    1  95 51 30
> > >	  3    1 102 59 28
> > >	  4    1 105 52 32
> > >	  5    1 105 53 26
> > >	  6    1  99 59 37
> > >	...    . ... .. ..
> > >	495    5 100 57 19
> > >	496    5  96 47 44
> > >	497    5 111 56 35
> > >	498    5 105 49 23
> > >	499    5 105 61 30
> > >	500    5  92 53 32
> > >
> > >Here is my proposed solution. Can you double check with your existing
> > >functions to see if they are correct.
> > >
> > >    decile.fn <- function(x, nbreaks=10){
> > >      br     <- quantile( x, seq(0, 1, len=nbreaks+1), na.rm=T )
> > >      br[1]  <- -Inf
> > >      return( cut(x, br, labels=F) )
> > >    }
> > >
> > >    out <- apply( df[ ,c("A", "B", "C")], 2,
> > >                  function(v) unlist( tapply( v, df$date, decile.fn ) ) )
> > >
> > >    rownames(out) <- rownames(df)
> > >    out <- cbind(df$date, out)
> > >
> > >Regards, Adai
> > >
> > >
> > >
> > >On Tue, 2006-02-21 at 21:44 -0500, maneesh deshpande wrote:
> > > > Hi,
> > > >
> > > > I have a dataframe, x of the following form:
> > > >
> > > > Date            Symbol   A    B  C
> > > > 20041201     ABC      10  12 15
> > > > 20041201     DEF       9    5   4
> > > > ...
> > > > 20050101     ABC         5  3   1
> > > > 20050101     GHM       12 4    2
> > > > ....
> > > >
> > > > here A, B,C are properties of a set symbols recorded for a given date.
> > > > I wante to decile the symbols For each date and property and
> > > > create another set of columns "bucketA","bucketB", "bucketC" containing 
> > >the
> > > > decile rank
> > > > for each symbol. The following non-vectorized code does what I want,
> > > >
> > > > bucket <- function(data,nBuckets) {
> > > >      q <- quantile(data,seq(0,1,len=nBuckets+1),na.rm=T)
> > > >      q[1] <- q[1] - 0.1 # need to do this to ensure there are no extra 
> > >NAs
> > > >      cut(data,q,include.lowest=T,labels=F)
> > > > }
> > > >
> > > > calcDeciles <- function(x,colNames) {
> > > > nBuckets <- 10
> > > > dates <- unique(x$Date)
> > > > for ( date in dates) {
> > > >   iVec <- x$Date == date
> > > >   xx <- x[iVec,]
> > > >   for (colName in colNames) {
> > > >      data <- xx[,colName]
> > > >      bColName <- paste("bucket",colName,sep="")
> > > >      x[iVec,bColName] <- bucket(data,nBuckets)
> > > >   }
> > > > }
> > > > x
> > > > }
> > > >
> > > > x <- calcDeciles(x,c("A","B","C"))
> > > >
> > > >
> > > > I was wondering if it is possible to vectorize the above function to 
> > >make it
> > > > more efficient.
> > > > I tried,
> > > > rlist <- tapply(x$A,x$Date,bucket)
> > > > but I am not sure how to assign the contents of "rlist" to their 
> > >appropriate
> > > > slots in the original
> > > > dataframe.
> > > >
> > > > Thanks,
> > > >
> > > > Maneesh
> > > >
> > > > ______________________________________________
> > > > R-help at stat.math.ethz.ch mailing list
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide! 
> > >http://www.R-project.org/posting-guide.html
> > > >
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > 
>



From mtb954 at gmail.com  Fri Feb 24 14:54:31 2006
From: mtb954 at gmail.com (mtb954 mtb954)
Date: Fri, 24 Feb 2006 07:54:31 -0600
Subject: [R] Sorting a dataframe by one column?
Message-ID: <e40d78ce0602240554x322a356era72fa63923e32961@mail.gmail.com>

Given the following dataframe:

A=1:10
B=(a-5)^2
DATAFRAME=data.frame(A,B)

How can I sort DATAFRAME increasing (or decreasing, for that matter)
by B without making reference to A, or any other column?

I've read ?order and ?sort but cannot seem to figure this out.

Thank you.

Mark



From I.Szentirmai at rug.nl  Fri Feb 24 14:55:34 2006
From: I.Szentirmai at rug.nl (I.Szentirmai)
Date: Fri, 24 Feb 2006 14:55:34 +0100
Subject: [R] SE of parameter estimates in glmm.admb
Message-ID: <web-16695899@mail3.rug.nl>

Dear R users,

Does anyone know how to get standard errors of the 
parameter estimates in glmm.admb?

Thanks,
Istvan



From michael.watson at bbsrc.ac.uk  Fri Feb 24 15:07:19 2006
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Fri, 24 Feb 2006 14:07:19 -0000
Subject: [R] Sorting a dataframe by one column?
Message-ID: <8975119BCD0AC5419D61A9CF1A923E95030083E9@iahce2ksrv1.iah.bbsrc.ac.uk>

You mean like this?

a<-1:10
b<-(a-5)^2
d<-data.frame(a,b)
d[order(d$b),]

?? 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of mtb954 mtb954
Sent: 24 February 2006 13:55
To: r-help at stat.math.ethz.ch
Subject: [R] Sorting a dataframe by one column?

Given the following dataframe:

A=1:10
B=(a-5)^2
DATAFRAME=data.frame(A,B)

How can I sort DATAFRAME increasing (or decreasing, for that matter) by
B without making reference to A, or any other column?

I've read ?order and ?sort but cannot seem to figure this out.

Thank you.

Mark

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From ccleland at optonline.net  Fri Feb 24 15:14:44 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 24 Feb 2006 09:14:44 -0500
Subject: [R] Sorting a dataframe by one column?
In-Reply-To: <e40d78ce0602240554x322a356era72fa63923e32961@mail.gmail.com>
References: <e40d78ce0602240554x322a356era72fa63923e32961@mail.gmail.com>
Message-ID: <43FF14D4.5030101@optonline.net>

mtb954 mtb954 wrote:
> Given the following dataframe:
> 
> A=1:10
> B=(a-5)^2
> DATAFRAME=data.frame(A,B)
> 
> How can I sort DATAFRAME increasing (or decreasing, for that matter)
> by B without making reference to A, or any other column?
> 
> I've read ?order and ?sort but cannot seem to figure this out.

You should have tried RSiteSearch("sort dataframe") also, since there 
are many examples in the archives of R-help.

  A=1:10
  B=(A-5)^2
  mydata=data.frame(A,B)
  mydata[order(mydata$B),]
  mydata[rev(order(mydata$B)),]

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From h.wickham at gmail.com  Fri Feb 24 15:21:31 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Fri, 24 Feb 2006 08:21:31 -0600
Subject: [R] RGtk2 install in Mac
In-Reply-To: <29f7c6ea58e192edc966de523151a46b@york.ac.uk>
References: <29f7c6ea58e192edc966de523151a46b@york.ac.uk>
Message-ID: <f8e6ff050602240621s6984132am7fc1ac0527c8800f@mail.gmail.com>

> I'm struggling installing RGtk2 on my Mac. Has anybody succeeded in
> doing so?

This isn't probably the right place to talk about RGtk2, given that
the web page suggests you should email the creator (Michael Lawrence)
if you have any problems.

I suspect your problem is the rather old version of R.  Update to the
latest version and try again.  The other possible problem is that it
looks like you are using fink, while we have only been testing using
darwinports.

Hadley



From ccatj at web.de  Fri Feb 24 15:33:13 2006
From: ccatj at web.de (Christian Jones)
Date: Fri, 24 Feb 2006 15:33:13 +0100
Subject: [R] predicting glm on a new dataset
Message-ID: <501227032@web.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060224/a9e98a05/attachment.pl

From vivek.satsangi at gmail.com  Fri Feb 24 15:44:45 2006
From: vivek.satsangi at gmail.com (Vivek Satsangi)
Date: Fri, 24 Feb 2006 09:44:45 -0500
Subject: [R] Minor documentation improvement
Message-ID: <bcb171920602240644w2d79bd47q32125ea661848c9@mail.gmail.com>

Gentlemen,

In the documentation for reshape, in the function signature, the
argument "direction" is not listed. However, it is explained in the
explanation of parameters below.

I am using R 2.2.1.


Out of curiosity: Is the R core team still an all-male affair? I don't
think I have seen a single lady's name.
--
-- Vivek Satsangi
Student, Rochester, NY USA



From Hans.Skaug at mi.uib.no  Fri Feb 24 15:51:43 2006
From: Hans.Skaug at mi.uib.no (Hans Skaug)
Date: Fri, 24 Feb 2006 15:51:43 +0100
Subject: [R] SE of parameter estimates in glmm.admb
Message-ID: <5BCBA62ECB426A47AE66567CDF930F98829E39@HUGIN.uib.no>

Dear Istvan,

An example

  library(glmmADMB)

  tt = glmm.admb(y ~ Base * trt + Age, random = ~Visit,group = "subject", data = epil2, family = "nbinom")

To print the covariance matrix of the random effects vector (and the std of those estimates, see bottom) :

  print.glmm.admb(tt,sd_S_print=TRUE)

Have a look at ?print.glmm.admb.

To get the std's of the beta's (fixed effects) you type:

  tt$stdbeta

I will try to find a better way to get access to the latter.

Use "names(tt)" to see what objects there are. 

hans

>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of I.Szentirmai
>Sent: Friday, February 24, 2006 2:56 PM
>To: R mailing list
>Subject: [R] SE of parameter estimates in glmm.admb
>
>Dear R users,
>
>Does anyone know how to get standard errors of the 
>parameter estimates in glmm.admb?
>
>Thanks,
>Istvan
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
>



From assampryseley at yahoo.com  Fri Feb 24 15:55:05 2006
From: assampryseley at yahoo.com (Pryseley Assam)
Date: Fri, 24 Feb 2006 06:55:05 -0800 (PST)
Subject: [R] Help with classes and generic function
In-Reply-To: <mailman.13.1140692402.29662.r-help@stat.math.ethz.ch>
Message-ID: <20060224145505.76422.qmail@web37112.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060224/62eb6a6e/attachment.pl

From ccleland at optonline.net  Fri Feb 24 16:03:55 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 24 Feb 2006 10:03:55 -0500
Subject: [R] predicting glm on a new dataset
In-Reply-To: <501227032@web.de>
References: <501227032@web.de>
Message-ID: <43FF205B.5090402@optonline.net>

Christian Jones wrote:
> 
> Hello together,
> 
> I would like to predict my fitted values on a new dataset. The original dataset consists of the variable a and b (data.frame(a,b)). The dataset for prediction consists of the same variables, but variable b has a constant value (x) added towards it (data.frame (a,b+x).
> 
> The prediction command returns the identical set of predicted values as for the original dataset yet I would have expected them to change due to b+x.
> 
> Were have I gone wrong?
> 
> Heres my code:
> 
> orig.frame<-data.frame(y,a,b)
> 
> pred.frame<-data.frame(a,b+x)
> 
> attach(orig.frame)
> 
> modela<-glm(y~a+b,binomial)
> 
> pr<-predict(modela,newdata=pred.frame,type="response")

Does this work for you?

orig.frame <- data.frame(y, a, b)
pred.frame <- data.frame(a, b = b + x)
modela <- glm(y ~ a + b, family = binomial, data = orig.frame)
pr <- predict(modela, newdata = pred.frame, type = "response")

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From vivek.satsangi at gmail.com  Fri Feb 24 16:16:29 2006
From: vivek.satsangi at gmail.com (Vivek Satsangi)
Date: Fri, 24 Feb 2006 10:16:29 -0500
Subject: [R] (Newbie) Aggregate for NA values
Message-ID: <bcb171920602240716v3d556779o83d172aa9049c117@mail.gmail.com>

Folks,

Sorry if this question has been answered before or is obvious (or
worse, statistically "bad"). I don't understand what was said in one
of the search results that seems somewhat related.

I use aggregate to get a quick summary of the data. Part of what I am
looking for in the summary is, how much influence might the NA's have
had, if they were included, and is excluding them from the means
causing some sort of bias. So I want the summary stat for the NA's
also.

Here is a simple example session (edited to remove the typos I made,
comments added later):

> tmp_a <- 1:10
> tmp_b <- rep(1:5,2)
> tmp_c <- rep(1:2,5)
> tmp_d <- c(1,1,1,2,2,2,3,3,3,4)
> tmp_df <- data.frame(tmp_a,tmp_b,tmp_c,tmp_d);
> tmp_df$tmp_c[9:10] <- NA ;
> tmp_df
   tmp_a tmp_b tmp_c tmp_d
1      1     1     1     1
2      2     2     2     1
3      3     3     1     1
4      4     4     2     2
5      5     5     1     2
6      6     1     2     2
7      7     2     1     3
8      8     3     2     3
9      9     4    NA     3
10    10     5    NA     4
> aggregate(tmp_df$tmp_d,by=list(tmp_df$tmp_b,tmp_df$tmp_c),mean);
  Group.1 Group.2 x
1       1       1 1
2       2       1 3
3       3       1 1
4       5       1 2
5       1       2 2
6       2       2 1
7       3       2 3
8       4       2 2
# Only one row for each (tmp_b, tmp_c) combination, NA's getting dropped.

> aggregate(tmp_df$tmp_d,by=list(tmp_df$tmp_c),mean);
  Group.1    x
1       1 1.75
2       2 2.00

What I want in this last aggregate is, a mean for the values in tmp_d
that correspond to the tmp_c values of NA. Similarly, perhaps there is
a way to make the second last call to aggregate return the values of
tmp_d for the NA values of tmp_c also.

How can I achieve this?

--
-- Vivek Satsangi
Student, Rochester, NY USA



From vivek.satsangi at gmail.com  Fri Feb 24 16:31:06 2006
From: vivek.satsangi at gmail.com (Vivek Satsangi)
Date: Fri, 24 Feb 2006 10:31:06 -0500
Subject: [R] Minor documentation improvement
In-Reply-To: <bcb171920602240644w2d79bd47q32125ea661848c9@mail.gmail.com>
References: <bcb171920602240644w2d79bd47q32125ea661848c9@mail.gmail.com>
Message-ID: <bcb171920602240731p11f7ee1em537c0a70e5736e99@mail.gmail.com>

Please ignore this message. I was not reading carefully enough, the
parameter is in there.

Vivek

On 2/24/06, Vivek Satsangi <vivek.satsangi at gmail.com> wrote:
> Gentlemen,
>
> In the documentation for reshape, in the function signature, the
> argument "direction" is not listed. However, it is explained in the
> explanation of parameters below.
>
> I am using R 2.2.1.
>
>
> Out of curiosity: Is the R core team still an all-male affair? I don't
> think I have seen a single lady's name.
> --
> -- Vivek Satsangi
> Student, Rochester, NY USA
>


--
-- Vivek Satsangi
Student, Rochester, NY USA



From ramasamy at cancer.org.uk  Fri Feb 24 17:05:07 2006
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 24 Feb 2006 16:05:07 +0000
Subject: [R] (Newbie) Aggregate for NA values
In-Reply-To: <bcb171920602240716v3d556779o83d172aa9049c117@mail.gmail.com>
References: <bcb171920602240716v3d556779o83d172aa9049c117@mail.gmail.com>
Message-ID: <1140797107.11525.90.camel@dhcp-82.wolf.ox.ac.uk>

I think it makes perfect sense for R to drop it since 'NA' represents
uninformative information. I do not know if there is a elegant solution
but I would suggest that you make these 'NA' into an informative value.

Here is one possibility:

 df <- data.frame( AA=1:10, BB=rep(1:5,2), CC=rep(1:2,5), DD=rnorm(10) )
 df[ 9:10, "CC" ] <- NA

 df[is.na(df)] <- "lala"   ## change NA's into informative category ##


 aggregate( df$DD, by=list( df$CC ), mean  )
     Group.1          x
   1       1  1.1533763
   2       2  0.6427338
   3    lala -0.2745249

 aggregate( df$DD, by=list( df$BB, df$CC ), mean  )
      Group.1 Group.2           x
   1        1       1  0.47264081
   2        2       1  0.63795211
   3        3       1  1.66756015
   4        5       1  1.83535232
   5        1       2  0.89914287
   6        2       2  1.11102134
   7        3       2  0.22268699
   8        4       2  0.33808394
   9        4    lala -0.60154608
   10       5    lala  0.05249622

Regards, Adai



On Fri, 2006-02-24 at 10:16 -0500, Vivek Satsangi wrote:
> Folks,
> 
> Sorry if this question has been answered before or is obvious (or
> worse, statistically "bad"). I don't understand what was said in one
> of the search results that seems somewhat related.
> 
> I use aggregate to get a quick summary of the data. Part of what I am
> looking for in the summary is, how much influence might the NA's have
> had, if they were included, and is excluding them from the means
> causing some sort of bias. So I want the summary stat for the NA's
> also.
> 
> Here is a simple example session (edited to remove the typos I made,
> comments added later):
> 
> > tmp_a <- 1:10
> > tmp_b <- rep(1:5,2)
> > tmp_c <- rep(1:2,5)
> > tmp_d <- c(1,1,1,2,2,2,3,3,3,4)
> > tmp_df <- data.frame(tmp_a,tmp_b,tmp_c,tmp_d);
> > tmp_df$tmp_c[9:10] <- NA ;
> > tmp_df
>    tmp_a tmp_b tmp_c tmp_d
> 1      1     1     1     1
> 2      2     2     2     1
> 3      3     3     1     1
> 4      4     4     2     2
> 5      5     5     1     2
> 6      6     1     2     2
> 7      7     2     1     3
> 8      8     3     2     3
> 9      9     4    NA     3
> 10    10     5    NA     4
> > aggregate(tmp_df$tmp_d,by=list(tmp_df$tmp_b,tmp_df$tmp_c),mean);
>   Group.1 Group.2 x
> 1       1       1 1
> 2       2       1 3
> 3       3       1 1
> 4       5       1 2
> 5       1       2 2
> 6       2       2 1
> 7       3       2 3
> 8       4       2 2
> # Only one row for each (tmp_b, tmp_c) combination, NA's getting dropped.
> 
> > aggregate(tmp_df$tmp_d,by=list(tmp_df$tmp_c),mean);
>   Group.1    x
> 1       1 1.75
> 2       2 2.00
> 
> What I want in this last aggregate is, a mean for the values in tmp_d
> that correspond to the tmp_c values of NA. Similarly, perhaps there is
> a way to make the second last call to aggregate return the values of
> tmp_d for the NA values of tmp_c also.
> 
> How can I achieve this?
> 
> --
> -- Vivek Satsangi
> Student, Rochester, NY USA
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From mcrawford at gmail.com  Fri Feb 24 17:18:36 2006
From: mcrawford at gmail.com (Matt Crawford)
Date: Fri, 24 Feb 2006 08:18:36 -0800
Subject: [R] Summarize by two-column factor, retaining original factors
Message-ID: <77b4b03e0602240818s2af3a7e6sa5b3606727b9a14b@mail.gmail.com>

I am having trouble doing the following.  I have a data.frame like
this, where x and y are a variable that I want to do calculations on:

Name Year x y
ab   2001  15 3
ab   2001  10 2
ab   2002  12 8
ab   2003  7 10
dv   2002  10 15
dv   2002  3 2
dv   2003  1 15

Before I do all the other things I need to do with this data, I need
to summarize or collapse the data by name and year.  I've found that I
can do things like
nameyear<-interaction(name,year)
dataframe$nameyear<-nameyear
tapply(dataframe$x,dataframe$nameyear,sum)
tapply(dataframe$y,dataframe$nameyear,sum)
and then bind those together.

But my problem is that I need to somehow retain the original Names in
my collapsed dataset, so that later I can do analyses with the Name
factors.  All I can think of is something like
tapply(dataframe$Name,dataframe$nameyear, somefunction?)
but nothing seems to work.

I'm actually trying to convert a SAS program, and I can't get out of
that mindset.  There, it's a simple Proc Means, By Name Year.

Thanks for any help or suggestions on the right way to go about this.

Matt Crawford



From mschwartz at mn.rr.com  Fri Feb 24 17:29:11 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Fri, 24 Feb 2006 10:29:11 -0600
Subject: [R] Summarize by two-column factor, retaining original factors
In-Reply-To: <77b4b03e0602240818s2af3a7e6sa5b3606727b9a14b@mail.gmail.com>
References: <77b4b03e0602240818s2af3a7e6sa5b3606727b9a14b@mail.gmail.com>
Message-ID: <1140798551.4492.2.camel@localhost.localdomain>

On Fri, 2006-02-24 at 08:18 -0800, Matt Crawford wrote:
> I am having trouble doing the following.  I have a data.frame like
> this, where x and y are a variable that I want to do calculations on:
> 
> Name Year x y
> ab   2001  15 3
> ab   2001  10 2
> ab   2002  12 8
> ab   2003  7 10
> dv   2002  10 15
> dv   2002  3 2
> dv   2003  1 15
> 
> Before I do all the other things I need to do with this data, I need
> to summarize or collapse the data by name and year.  I've found that I
> can do things like
> nameyear<-interaction(name,year)
> dataframe$nameyear<-nameyear
> tapply(dataframe$x,dataframe$nameyear,sum)
> tapply(dataframe$y,dataframe$nameyear,sum)
> and then bind those together.
> 
> But my problem is that I need to somehow retain the original Names in
> my collapsed dataset, so that later I can do analyses with the Name
> factors.  All I can think of is something like
> tapply(dataframe$Name,dataframe$nameyear, somefunction?)
> but nothing seems to work.
> 
> I'm actually trying to convert a SAS program, and I can't get out of
> that mindset.  There, it's a simple Proc Means, By Name Year.
> 
> Thanks for any help or suggestions on the right way to go about this.
> 
> Matt Crawford

Matt,

Just use aggregate():

> aggregate(MyDF[, 3:4], list(Name = MyDF$Name, Year = MyDF$Year), sum)
  Name Year  x  y
1   ab 2001 25  5
2   ab 2002 12  8
3   dv 2002 13 17
4   ab 2003  7 10
5   dv 2003  1 15


See ?aggregate for more information.

HTH,

Marc Schwartz



From ggrothendieck at gmail.com  Fri Feb 24 17:34:03 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 24 Feb 2006 11:34:03 -0500
Subject: [R] Summarize by two-column factor, retaining original factors
In-Reply-To: <1140798551.4492.2.camel@localhost.localdomain>
References: <77b4b03e0602240818s2af3a7e6sa5b3606727b9a14b@mail.gmail.com>
	<1140798551.4492.2.camel@localhost.localdomain>
Message-ID: <971536df0602240834g287edcaegb61f73d9c4fc3732@mail.gmail.com>

Or even

aggregate(DF[3:4], DF[1:2], sum)



On 2/24/06, Marc Schwartz (via MN) <mschwartz at mn.rr.com> wrote:
> On Fri, 2006-02-24 at 08:18 -0800, Matt Crawford wrote:
> > I am having trouble doing the following.  I have a data.frame like
> > this, where x and y are a variable that I want to do calculations on:
> >
> > Name Year x y
> > ab   2001  15 3
> > ab   2001  10 2
> > ab   2002  12 8
> > ab   2003  7 10
> > dv   2002  10 15
> > dv   2002  3 2
> > dv   2003  1 15
> >
> > Before I do all the other things I need to do with this data, I need
> > to summarize or collapse the data by name and year.  I've found that I
> > can do things like
> > nameyear<-interaction(name,year)
> > dataframe$nameyear<-nameyear
> > tapply(dataframe$x,dataframe$nameyear,sum)
> > tapply(dataframe$y,dataframe$nameyear,sum)
> > and then bind those together.
> >
> > But my problem is that I need to somehow retain the original Names in
> > my collapsed dataset, so that later I can do analyses with the Name
> > factors.  All I can think of is something like
> > tapply(dataframe$Name,dataframe$nameyear, somefunction?)
> > but nothing seems to work.
> >
> > I'm actually trying to convert a SAS program, and I can't get out of
> > that mindset.  There, it's a simple Proc Means, By Name Year.
> >
> > Thanks for any help or suggestions on the right way to go about this.
> >
> > Matt Crawford
>
> Matt,
>
> Just use aggregate():
>
> > aggregate(MyDF[, 3:4], list(Name = MyDF$Name, Year = MyDF$Year), sum)
>  Name Year  x  y
> 1   ab 2001 25  5
> 2   ab 2002 12  8
> 3   dv 2002 13 17
> 4   ab 2003  7 10
> 5   dv 2003  1 15
>
>
> See ?aggregate for more information.
>
> HTH,
>
> Marc Schwartz
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ccleland at optonline.net  Fri Feb 24 17:41:55 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 24 Feb 2006 11:41:55 -0500
Subject: [R] Summarize by two-column factor, retaining original factors
In-Reply-To: <77b4b03e0602240818s2af3a7e6sa5b3606727b9a14b@mail.gmail.com>
References: <77b4b03e0602240818s2af3a7e6sa5b3606727b9a14b@mail.gmail.com>
Message-ID: <43FF3753.90605@optonline.net>

Matt Crawford wrote:
> I am having trouble doing the following.  I have a data.frame like
> this, where x and y are a variable that I want to do calculations on:
> 
> Name Year x y
> ab   2001  15 3
> ab   2001  10 2
> ab   2002  12 8
> ab   2003  7 10
> dv   2002  10 15
> dv   2002  3 2
> dv   2003  1 15
> 
> Before I do all the other things I need to do with this data, I need
> to summarize or collapse the data by name and year.  I've found that I
> can do things like
> nameyear<-interaction(name,year)
> dataframe$nameyear<-nameyear
> tapply(dataframe$x,dataframe$nameyear,sum)
> tapply(dataframe$y,dataframe$nameyear,sum)
> and then bind those together.
> 
> But my problem is that I need to somehow retain the original Names in
> my collapsed dataset, so that later I can do analyses with the Name
> factors.  All I can think of is something like
> tapply(dataframe$Name,dataframe$nameyear, somefunction?)
> but nothing seems to work.
> 
> I'm actually trying to convert a SAS program, and I can't get out of
> that mindset.  There, it's a simple Proc Means, By Name Year.
> 
> Thanks for any help or suggestions on the right way to go about this.

mydata <- data.frame(
            Name = c("ab","ab","ab","ab","dv","dv","dv"),
            Year = c(2001,2001,2002,2003,2002,2002,2003),
               x = c(15,10,12,7,10,3,1),
               y = c(3,2,8,10,15,2,15))

aggregate(mydata[,c("x", "y")],
           list(Name = mydata$Name, Year = mydata$Year), sum)

   Name Year  x  y
1   ab 2001 25  5
2   ab 2002 12  8
3   dv 2002 13 17
4   ab 2003  7 10
5   dv 2003  1 15

?aggregate

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From marcv at water.ca.gov  Fri Feb 24 18:23:36 2006
From: marcv at water.ca.gov (=?iso-8859-1?Q?Vayssi=E8res=2C_Marc?=)
Date: Fri, 24 Feb 2006 09:23:36 -0800
Subject: [R] dist() between groups of data
Message-ID: <30CA44F956F0E545825A119B6FE2DD0C01759E77@sacex3.ad.water.ca.gov>

Henrik,

If I understand your question, what you want is:

x <- runif(9)
y <- runif(9)
z <- rep(c(0,1,2), each=3)
xyz <- cbind(x,y,z)
xyz
d.all <- dist(xyz[,c("x","y")])
d.all
xyz.02 <- subset(xyz, z == 0 | z == 2)
xyz.02
d.02 <- dist(xyz.02[,c("x","y")])
d.02

Marc  

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Henrik Parn
Sent: Thursday, February 23, 2006 8:40 AM
To: r-help at stat.math.ethz.ch
Subject: [R] dist() between groups of data

Dear all,

I have a data set with x and y positions of nests. Each nest can be grouped according to a factor z. I have made a small dummy data set, where the grouping variable z is 0 or 1:

x <- runif(6)
y <- runif(6)
z <- rep(c(0,1), each=3)
xyz <- cbind(x,y,z)
xyz
             x           y z
[1,] 0.7176801 0.760944688 0
[2,] 0.2377928 0.080622524 0
[3,] 0.9450770 0.022039470 0
[4,] 0.8725492 0.971996677 1
[5,] 0.6356198 0.001569859 1
[6,] 0.8949670 0.066044377 1


First of all, I suppose that this is the correct way to calculate the Euclidean distance between /all/ nests:

xy <- cbind(x,y)
d.all <- dist(xy)


However, I would like to obtain a distance matrix for distances between nests belonging to certain groups. For example "calculate all distances from nests where z equals something, to nests where z equals something else".

Is it best to split the data in two matrices according to the value of z in the two groups to be compared, and then try to follow the suggestions by Gabor Grothendieck* Date:* Wed 07 Jan 2004 - 15:16:37 EST , or are there other ways that can be applied straight to one matrix?


Thanks in advance!

Henrik











--
************************
Henrik P??rn
Department of Biology
NTNU
7491 Trondheim
Norway

+47 735 96282 (office)
+47 909 89 255 (mobile)
+47 735 96100 (fax)

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Soren.Hojsgaard at agrsci.dk  Fri Feb 24 19:26:03 2006
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Fri, 24 Feb 2006 19:26:03 +0100
Subject: [R] Summarize by two-column factor, retaining original factors
References: <77b4b03e0602240818s2af3a7e6sa5b3606727b9a14b@mail.gmail.com>
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC038781FD@DJFPOST01.djf.agrsci.dk>

The summaryBy function in the doBy package might help you:
summaryBy(x+y~Year, data=..., FUN=c(mean,var))
Best regards
S??ren

________________________________

Fra: r-help-bounces at stat.math.ethz.ch p?? vegne af Matt Crawford
Sendt: fr 24-02-2006 17:18
Til: r-help at stat.math.ethz.ch
Emne: [R] Summarize by two-column factor, retaining original factors



I am having trouble doing the following.  I have a data.frame like
this, where x and y are a variable that I want to do calculations on:

Name Year x y
ab   2001  15 3
ab   2001  10 2
ab   2002  12 8
ab   2003  7 10
dv   2002  10 15
dv   2002  3 2
dv   2003  1 15

Before I do all the other things I need to do with this data, I need
to summarize or collapse the data by name and year.  I've found that I
can do things like
nameyear<-interaction(name,year)
dataframe$nameyear<-nameyear
tapply(dataframe$x,dataframe$nameyear,sum)
tapply(dataframe$y,dataframe$nameyear,sum)
and then bind those together.

But my problem is that I need to somehow retain the original Names in
my collapsed dataset, so that later I can do analyses with the Name
factors.  All I can think of is something like
tapply(dataframe$Name,dataframe$nameyear, somefunction?)
but nothing seems to work.

I'm actually trying to convert a SAS program, and I can't get out of
that mindset.  There, it's a simple Proc Means, By Name Year.

Thanks for any help or suggestions on the right way to go about this.

Matt Crawford

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From murdoch at stats.uwo.ca  Fri Feb 24 19:28:35 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 24 Feb 2006 13:28:35 -0500
Subject: [R] Minor documentation improvement
In-Reply-To: <bcb171920602240644w2d79bd47q32125ea661848c9@mail.gmail.com>
References: <bcb171920602240644w2d79bd47q32125ea661848c9@mail.gmail.com>
Message-ID: <43FF5053.20208@stats.uwo.ca>

On 2/24/2006 9:44 AM, Vivek Satsangi wrote:
> Gentlemen,
> 
> In the documentation for reshape, in the function signature, the
> argument "direction" is not listed. However, it is explained in the
> explanation of parameters below.

I see it between drop and new.row.names:

>  reshape(data, varying = NULL, v.names = NULL, timevar = "time",
>              idvar = "id", ids = 1:NROW(data),
>              times = seq(length = length(varying[[1]])),
>              drop = NULL, direction, new.row.names = NULL,
>              split = list(regexp="\.", include=FALSE))

in the reshape man page.  Did you overlook it, or are you looking 
somewhere else?

> I am using R 2.2.1.
> 
> 
> Out of curiosity: Is the R core team still an all-male affair? I don't
> think I have seen a single lady's name.

It's been several years since I've seen some of them, but as far as I've 
heard, they're all still male.

Duncan Murdoch



From tom at maladmin.com  Fri Feb 24 14:43:07 2006
From: tom at maladmin.com (tom wright)
Date: Fri, 24 Feb 2006 08:43:07 -0500
Subject: [R] help with optimize statement
Message-ID: <1140788587.25774.42.camel@localhost.localdomain>

Can some help me spot what I'm doing wrong here.
I have two equations, one a michalis-menton eqn and one a straight line.
I need to work out where they cross.

I created the function:
solveEqn<-function(x,vals){
Vmax<-vals[1]
Ks<-vals[2]
m<-vals[3]
c<-vals[4]
    diff<-0
    mmVal<-exp(Vmax+x/(Ks+x))
    slVal<-x*m+c

    diff<-mmVal-slVal
    return(diff)
}
> optim(c(200,500),solveEqn,vals=c(2.4591201,-0.4015233,5.924e-5,3.437))
Error in optim(c(200, 500), solveEqn, vals = c(2.4591201, -0.4015233,  :
        objective function in optim evaluates to length 2 not 1


If i replace return(diff) with sum(diff) then the optim function runs
but returns the wrong value (which should be about 290).

Many thanks 
Tom



From mtb954 at gmail.com  Fri Feb 24 19:54:40 2006
From: mtb954 at gmail.com (mtb954 mtb954)
Date: Fri, 24 Feb 2006 12:54:40 -0600
Subject: [R] Sorting alphanumerically
Message-ID: <e40d78ce0602241054g1c0b0c5bi839987c42aaaab02@mail.gmail.com>

I'm trying to sort a DATAFRAME by a column "ID" that contains
alphanumeric data. Specifically,"ID" contains integers all preceeded
by the character "g" as in:

g1, g6, g3, g19, g100, g2, g39

I am using the following code:

DATAFRAME=DATAFRAME[order(DATAFRAME1$ID),]

and was hoping it would sort the dataframe by ID in the following manner

g1, g2, g3, g6, g19, g39, g100

but it doesn't sort at all. Could anyone point out my mistake?

Thank you.

Mark



From ggrothendieck at gmail.com  Fri Feb 24 20:06:37 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 24 Feb 2006 14:06:37 -0500
Subject: [R] Sorting alphanumerically
In-Reply-To: <e40d78ce0602241054g1c0b0c5bi839987c42aaaab02@mail.gmail.com>
References: <e40d78ce0602241054g1c0b0c5bi839987c42aaaab02@mail.gmail.com>
Message-ID: <971536df0602241106u71e89ca6s7c64fcae474bb2d4@mail.gmail.com>

This was just discussed recently.  Try:

library(gtools)
?mixedorder

On 2/24/06, mtb954 mtb954 <mtb954 at gmail.com> wrote:
> I'm trying to sort a DATAFRAME by a column "ID" that contains
> alphanumeric data. Specifically,"ID" contains integers all preceeded
> by the character "g" as in:
>
> g1, g6, g3, g19, g100, g2, g39
>
> I am using the following code:
>
> DATAFRAME=DATAFRAME[order(DATAFRAME1$ID),]
>
> and was hoping it would sort the dataframe by ID in the following manner
>
> g1, g2, g3, g6, g19, g39, g100
>
> but it doesn't sort at all. Could anyone point out my mistake?
>
> Thank you.
>
> Mark
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From mschwartz at mn.rr.com  Fri Feb 24 20:10:17 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Fri, 24 Feb 2006 13:10:17 -0600
Subject: [R] Sorting alphanumerically
In-Reply-To: <e40d78ce0602241054g1c0b0c5bi839987c42aaaab02@mail.gmail.com>
References: <e40d78ce0602241054g1c0b0c5bi839987c42aaaab02@mail.gmail.com>
Message-ID: <1140808217.4492.17.camel@localhost.localdomain>

On Fri, 2006-02-24 at 12:54 -0600, mtb954 mtb954 wrote:
> I'm trying to sort a DATAFRAME by a column "ID" that contains
> alphanumeric data. Specifically,"ID" contains integers all preceeded
> by the character "g" as in:
> 
> g1, g6, g3, g19, g100, g2, g39
> 
> I am using the following code:
> 
> DATAFRAME=DATAFRAME[order(DATAFRAME1$ID),]
> 
> and was hoping it would sort the dataframe by ID in the following manner
> 
> g1, g2, g3, g6, g19, g39, g100
> 
> but it doesn't sort at all. Could anyone point out my mistake?
> 
> Thank you.
> 
> Mark

The values are being sorted by character based ordering, which may be
impacted upon by your locale.

Thus, on my system, you end up with something like the following:

> ID[order(ID)]
[1] "g1"   "g100" "g19"  "g2"   "g3"   "g39"  "g6"


What you can do, based upon the presumption that the prefix of 'g' is
present as you describe above, is:

> ID[order(as.numeric((gsub("g", "", ID))))]
[1] "g1"   "g2"   "g3"   "g6"   "g19"  "g39"  "g100"


What this does is to use gsub() to strip the 'g' and then order by
numeric value.


HTH,

Marc Schwartz



From ccleland at optonline.net  Fri Feb 24 20:12:56 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Fri, 24 Feb 2006 14:12:56 -0500
Subject: [R] Sorting alphanumerically
In-Reply-To: <e40d78ce0602241054g1c0b0c5bi839987c42aaaab02@mail.gmail.com>
References: <e40d78ce0602241054g1c0b0c5bi839987c42aaaab02@mail.gmail.com>
Message-ID: <43FF5AB8.3070002@optonline.net>

Does this help?

ID <- paste("g", sample(1:100, 100, replace=FALSE), sep="")

ID
   [1] "g88"  "g5"   "g79"  "g67"  "g43"  "g21"  "g66"
   [8] "g9"   "g38"  "g86"  "g12"  "g85"  "g74"  "g34"
  [15] "g52"  "g95"  "g6"   "g22"  "g70"  "g87"  "g7"
  [22] "g83"  "g63"  "g42"  "g26"  "g65"  "g16"  "g97"
  [29] "g76"  "g2"   "g90"  "g23"  "g15"  "g82"  "g75"
  [36] "g58"  "g17"  "g20"  "g96"  "g91"  "g31"  "g33"
  [43] "g48"  "g32"  "g93"  "g54"  "g49"  "g36"  "g81"
  [50] "g57"  "g27"  "g14"  "g62"  "g10"  "g80"  "g71"
  [57] "g28"  "g37"  "g89"  "g8"   "g94"  "g68"  "g56"
  [64] "g92"  "g41"  "g11"  "g4"   "g99"  "g55"  "g60"
  [71] "g18"  "g69"  "g19"  "g64"  "g39"  "g1"   "g53"
  [78] "g44"  "g24"  "g100" "g35"  "g3"   "g40"  "g47"
  [85] "g51"  "g46"  "g61"  "g45"  "g50"  "g25"  "g13"
  [92] "g73"  "g77"  "g30"  "g84"  "g78"  "g29"  "g59"
  [99] "g72"  "g98"

ID[order(as.numeric(substr(ID, start=2, stop=nchar(ID))))]
   [1] "g1"   "g2"   "g3"   "g4"   "g5"   "g6"   "g7"
   [8] "g8"   "g9"   "g10"  "g11"  "g12"  "g13"  "g14"
  [15] "g15"  "g16"  "g17"  "g18"  "g19"  "g20"  "g21"
  [22] "g22"  "g23"  "g24"  "g25"  "g26"  "g27"  "g28"
  [29] "g29"  "g30"  "g31"  "g32"  "g33"  "g34"  "g35"
  [36] "g36"  "g37"  "g38"  "g39"  "g40"  "g41"  "g42"
  [43] "g43"  "g44"  "g45"  "g46"  "g47"  "g48"  "g49"
  [50] "g50"  "g51"  "g52"  "g53"  "g54"  "g55"  "g56"
  [57] "g57"  "g58"  "g59"  "g60"  "g61"  "g62"  "g63"
  [64] "g64"  "g65"  "g66"  "g67"  "g68"  "g69"  "g70"
  [71] "g71"  "g72"  "g73"  "g74"  "g75"  "g76"  "g77"
  [78] "g78"  "g79"  "g80"  "g81"  "g82"  "g83"  "g84"
  [85] "g85"  "g86"  "g87"  "g88"  "g89"  "g90"  "g91"
  [92] "g92"  "g93"  "g94"  "g95"  "g96"  "g97"  "g98"
  [99] "g99"  "g100"

The idea is to drop the leading "g", convert to numeric, and then order.

mtb954 mtb954 wrote:
> I'm trying to sort a DATAFRAME by a column "ID" that contains
> alphanumeric data. Specifically,"ID" contains integers all preceeded
> by the character "g" as in:
> 
> g1, g6, g3, g19, g100, g2, g39
> 
> I am using the following code:
> 
> DATAFRAME=DATAFRAME[order(DATAFRAME1$ID),]
> 
> and was hoping it would sort the dataframe by ID in the following manner
> 
> g1, g2, g3, g6, g19, g39, g100
> 
> but it doesn't sort at all. Could anyone point out my mistake?
> 
> Thank you.
> 
> Mark
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From lewinger at usc.edu  Fri Feb 24 20:16:55 2006
From: lewinger at usc.edu (Juan Lewinger)
Date: Fri, 24 Feb 2006 11:16:55 -0800
Subject: [R] Multiple plots on the same pdf file
Message-ID: <de69ed165b4d.43feeb27@usc.edu>

Is there a way to output multiple plots generated with a high level plot function such as "plot()" to the same pdf file? The following does not work (in windows XP):

pdf(filename)
plot(...)                         # first plot
plot(...)                         # second plot
.....
plot(...)                         # n-th plot
dev.off()

Thanks for your help!



From jgarcia at ija.csic.es  Fri Feb 24 20:18:43 2006
From: jgarcia at ija.csic.es (javier garcia-pintado)
Date: Fri, 24 Feb 2006 20:18:43 +0100
Subject: [R] R script autoload at startup
In-Reply-To: <43FF28BB.8030207@neverbox.com>
References: <7.0.0.16.0.20060224105224.01f27a90@ija.csic.es>
	<43FF28BB.8030207@neverbox.com>
Message-ID: <200602242018.43971.jgarcia@ija.csic.es>

Yes.

It would be nice and useful to save the users the task of loading the source 
R-TcltK code everytime they start up R. Because, in principle they are going 
to use R just for this. But the R GUI must remains open

Javier
-----------------------
El Viernes, 24 de Febrero de 2006 16:39, Frank Samuelson escribi??:
> Do you need the user to interact with the Rgui after the code has run?
>
> -Frank
>
> Javier Garcia-Pintado wrote:
> > Hello;
> > I'm now using mainly R for windows, mainly because I'm writing a
> > tcl/Tk interface for some people, and I've got two questions. I'm an
> > absolute beginner with tctk or tcktk use under the R GUI.
> >
> > 1) Is it posible to create a shorcut that launchs the R GUI and
> > automatically reads the "source code" of the tcl/tk script to also
> > launch the tcltk interface?
> >
> > 2) Is the RGUI programmed with tcltk? In this case, is it possible
> > for an user like me to create a menu entry at the R GUI to call the
> > source code in this R/tcl/Tk script?
> >
> > Any of the two options would be very good for us.
> >
> > Thanks and best regards,
> >
> > Javier

-- 
javier garc??a-pintado



From andy_liaw at merck.com  Fri Feb 24 20:41:06 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 24 Feb 2006 14:41:06 -0500
Subject: [R] Multiple plots on the same pdf file
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED866@usctmx1106.merck.com>

You need to say more explicitly what `does not work' means (as the Posting
Guide asks).  What you've stated will generate plots in separate pages in
the PDF file.  If that's not what you want, then tell us exactly what you
are looking for.

Andy

From: Juan Lewinger
> 
> Is there a way to output multiple plots generated with a high 
> level plot function such as "plot()" to the same pdf file? 
> The following does not work (in windows XP):
> 
> pdf(filename)
> plot(...)                         # first plot
> plot(...)                         # second plot
> .....
> plot(...)                         # n-th plot
> dev.off()
> 
> Thanks for your help!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From lewinger at usc.edu  Fri Feb 24 21:06:36 2006
From: lewinger at usc.edu (Juan Lewinger)
Date: Fri, 24 Feb 2006 12:06:36 -0800
Subject: [R] Multiple plots on the same pdf file (clarification)
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED866@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED866@usctmx1106.merck.com>
Message-ID: <de189a3c31aa.43fef6cc@usc.edu>

I wanted to output each plot to a separate page on the same pdf file. Contrary to what I stated in my original question, the code below does do the job. I now identified my problem as Acrobat's (my installation), not R.
 Thanks for the help 

----- Original Message -----
From: "Liaw, Andy" <andy_liaw at merck.com>
Date: Friday, February 24, 2006 11:41 am
Subject: RE: [R] Multiple plots on the same pdf file
To: 'Juan Lewinger' <lewinger at usc.edu>, r-help at stat.math.ethz.ch

> You need to say more explicitly what `does not work' means (as the 
> PostingGuide asks).  What you've stated will generate plots in 
> separate pages in
> the PDF file.  If that's not what you want, then tell us exactly 
> what you
> are looking for.
> 
> Andy
> 
> From: Juan Lewinger
> > 
> > Is there a way to output multiple plots generated with a high 
> > level plot function such as "plot()" to the same pdf file? 
> > The following does not work (in windows XP):
> > 
> > pdf(filename)
> > plot(...)                         # first plot
> > plot(...)                         # second plot
> > .....
> > plot(...)                         # n-th plot
> > dev.off()
> > 
> > Thanks for your help!
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> 
> -------------------------------------------------------------------
> -----------
> Notice:  This e-mail message, together with any attachments, 
> contains information of Merck & Co., Inc. (One Merck Drive, 
> Whitehouse Station, New Jersey, USA 08889), and/or its affiliates 
> (which may be known outside the United States as Merck Frosst, 
> Merck Sharp & Dohme or MSD and in Japan, as Banyu) that may be 
> confidential, proprietary copyrighted and/or legally privileged. 
> It is intended solely for the use of the individual or entity 
> named on this message.  If you are not the intended recipient, and 
> have received this message in error, please notify us immediately 
> by reply e-mail and then delete it from your system.
> -------------------------------------------------------------------
> -----------
>



From ripley at stats.ox.ac.uk  Fri Feb 24 21:12:12 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 Feb 2006 20:12:12 +0000 (GMT)
Subject: [R] R script autoload at startup
In-Reply-To: <200602242018.43971.jgarcia@ija.csic.es>
References: <7.0.0.16.0.20060224105224.01f27a90@ija.csic.es>
	<43FF28BB.8030207@neverbox.com>
	<200602242018.43971.jgarcia@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0602242008050.26876@gannet.stats.ox.ac.uk>

See ?Startup for how to do this via .Rprofile or etc/Rprofile.site.

The answer to your second question is that RGui is not written in tcltk 
(can't you tell from the speed with which it works?), but there are 
documented R functions for you to add menu items, such as winMenuAdd.

(I do wonder how you missed these in the searches for help, as all the 
terms I tried found the answers.)

On Fri, 24 Feb 2006, javier garcia-pintado wrote:

> Yes.
>
> It would be nice and useful to save the users the task of loading the source
> R-TcltK code everytime they start up R. Because, in principle they are going
> to use R just for this. But the R GUI must remains open
>
> Javier
> -----------------------
> El Viernes, 24 de Febrero de 2006 16:39, Frank Samuelson escribi??:
>> Do you need the user to interact with the Rgui after the code has run?
>>
>> -Frank
>>
>> Javier Garcia-Pintado wrote:
>>> Hello;
>>> I'm now using mainly R for windows, mainly because I'm writing a
>>> tcl/Tk interface for some people, and I've got two questions. I'm an
>>> absolute beginner with tctk or tcktk use under the R GUI.
>>>
>>> 1) Is it posible to create a shorcut that launchs the R GUI and
>>> automatically reads the "source code" of the tcl/tk script to also
>>> launch the tcltk interface?
>>>
>>> 2) Is the RGUI programmed with tcltk? In this case, is it possible
>>> for an user like me to create a menu entry at the R GUI to call the
>>> source code in this R/tcl/Tk script?
>>>
>>> Any of the two options would be very good for us.
>>>
>>> Thanks and best regards,
>>>
>>> Javier
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From jost.burkardt at web.de  Fri Feb 24 21:17:11 2006
From: jost.burkardt at web.de (Jost Burkardt)
Date: Fri, 24 Feb 2006 21:17:11 +0100
Subject: [R] help with optimize statement
In-Reply-To: <1140788587.25774.42.camel@localhost.localdomain>
References: <1140788587.25774.42.camel@localhost.localdomain>
Message-ID: <43FF69C7.8080003@web.de>

Hi Tom,

first I can't see, why you think the crossing-point should be 290, look
at the plot

x <- seq(200, 500, 10)
plot( exp(2.4591201+x/(-0.4015233+x)) ~ x, ylim=c(0,40), type="l")
lines(5.924e-5*x+3.437 ~x)

Maybe your vals are wrong?

2) For optimizing a function of 1 parameter, you should use optimize
instead of optim

3) As your Function return the difference of the michaelis-menton eqn
and the line, optimize will maximize the difference, you could use the
sum of squares:

solveEqn<-function(x,vals){
Vmax<-vals[1]
Ks<-vals[2]
m<-vals[3]
c<-vals[4]
    diff<-0
    mmVal<-exp(Vmax+x/(Ks+x))
    slVal<-x*m+c

    diff<-mmVal-slVal
    return((mmVal-slVal)^2)
}

optimize(solveEqn,c(0,1e6),vals=c(2.4591201,-0.4015233,5.924e-5,3.437))

x <- seq(0, 1e6, len=100)
plot( exp(2.4591201+x/(-0.4015233+x)) ~ x, ylim=c(0,40), type="l")
lines(5.924e-5*x+3.437 ~x)

Jost Burkardt

tom wright wrote:
> Can some help me spot what I'm doing wrong here.
> I have two equations, one a michalis-menton eqn and one a straight line.
> I need to work out where they cross.
> 
> I created the function:
> solveEqn<-function(x,vals){
> Vmax<-vals[1]
> Ks<-vals[2]
> m<-vals[3]
> c<-vals[4]
>     diff<-0
>     mmVal<-exp(Vmax+x/(Ks+x))
>     slVal<-x*m+c
> 
>     diff<-mmVal-slVal
>     return(diff)
> }
> 
>>optim(c(200,500),solveEqn,vals=c(2.4591201,-0.4015233,5.924e-5,3.437))
> 
> Error in optim(c(200, 500), solveEqn, vals = c(2.4591201, -0.4015233,  :
>         objective function in optim evaluates to length 2 not 1
> 
> 
> If i replace return(diff) with sum(diff) then the optim function runs
> but returns the wrong value (which should be about 290).
> 
> Many thanks 
> Tom
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From grenyer at virginia.edu  Fri Feb 24 21:46:53 2006
From: grenyer at virginia.edu (Rich Grenyer)
Date: Fri, 24 Feb 2006 15:46:53 -0500
Subject: [R] R and marine protected areas: algorithms for site selection
Message-ID: <a02f04f198170999e2c193464e189384@virginia.edu>

Hi - I looked briefly a little while ago for R interaction with linear 
programming tools. There is limited support for the lp_solve solver 
(http://sourceforge.net/projects/lpsolve) in the package lpSolve, but 
it doesn't give full access to the external solver's capabilities. 
Other than that, you may want to look at the Gnu Linear Programming Kit 
(http://www.gnu.org/software/glpk/glpk.html) and MathProg or Zimpl 
(http://www.zib.de/koch/zimpl/), and be prepared to get R to write text 
files that can then be run externally. Ugly, but you may get somewhere.

If you find anything better that integrates R and linear programming, 
I'd be interested to hear about it.

Regards,

Rich



> Dear listers,
>
> a central problem in conservation biology is the selection of sites in
> reserve network design.
> many algorithms have been published, and I was wondering any have been
> implemented in R.
> I did not seen anything on CRAN or R-help, or on the web in general.
>
> Best regards, Eric
>
> Eric Pante

--------------------
Rich Grenyer, Ph.D.
Biology Department - University of Virginia
Gilmer Hall
Charlottesville, Virginia
VA 22904
United States of America

tel: (+1) 434 982 5629
fax: (+1) 434 982 5626
http://faculty.virginia.edu/gittleman/rich



From sangi at itc.utk.edu  Fri Feb 24 21:49:01 2006
From: sangi at itc.utk.edu (Sangeetha Swaminathan)
Date: Fri, 24 Feb 2006 15:49:01 -0500
Subject: [R] Time on x-axis
Message-ID: <441B876B@webmail.utk.edu>

Hello,

   Thank you! It worked!! Now I have another query; I have about 300 data 
entries, and I dont think it would be possible to quote everything under 
tt<-c("") or x<-c(). Is there any way to plot the graph, without having to 
manually quote all the data items in the array?

Thank you.

Sangeetha

>===== Original Message From "Gabor Grothendieck" <ggrothendieck at gmail.com> 
=====
>Try this:
>
># test data
>tt <- c("23:05:02", "23:10:02", "23:15:03", "23:20:03", "23:25:03",
>"23:30:03", "23:35:03", "23:40:03", "23:45:04", "23:50:04", "23:55:03",
>"23:55:03")
>x <- c(0.575764, 0.738379, 0.567414, 0.663436, 0.599834, 0.679571,
>0.88141, 0.868848, 0.969271, 0.878968, 0.990972, 0.990972)
>
>library(zoo)
>library(chron)
>z <- zoo(x, times(tt))
>plot(z)
>
>Read the R Help Desk article in R News 4/1 about dates and times
>and also read the chron article in its references.
>
>Also read the zoo vignette which you can access like this:
>
>library(zoo)
>vignette("zoo")
>
>and also read ?axis in case you want to customize the axes.
>
>
>On 2/20/06, Sangeetha Swaminathan <sangi at itc.utk.edu> wrote:
>> Hello,
>>
>>   I just started using the GNU R. I am having trouble plotting my data. I 
am
>> tryin to plot the following data:
>>
>> TIMESTAMP    LOGIN-TIME
>> (hh:mm:ss)          (s)
>>
>> 23:55:03       0.990972
>> 23:55:03       0.990972
>> 23:50:04       0.878968
>> 23:45:04       0.969271
>> 23:40:03       0.868848
>> 23:35:03        0.88141
>> 23:30:03       0.679571
>> 23:25:03       0.599834
>> 23:20:03       0.663436
>> 23:15:03       0.567414
>> 23:10:02       0.738379
>> 23:05:02       0.575764
>>
>> with TIMESTAMP on the x-axis. The plot() function assumes the x-axis as the
>> total number of events, and plots the desired graph. But I want the 
TIMESTAMP
>> on the x-axis. If I try to change the x-axis, the y-axis gets modified too,
>> and all I get is just a "dot" as a plot.
>> Can someone tell me how I can make R plot my graph, with TIMESTAMP as my
>> x-axis and LOGIN_TIME as my y-axis?
>>
>> Thank you.
>>
>> Sangeetha
>>
>> -- Sangeetha Swaminathan
>> Graduate Assistant
>> Innovative Technology Center (ITC)
>> 2444 Dunford Hall
>> The University of Tennessee
>> Knoxville, TN 37996
>> Phone [O]:(865) 974-9672
>>      [R]:(865) 946-4340
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html
>>

-- Sangeetha Swaminathan
Graduate Assistant
Innovative Technology Center (ITC)
2444 Dunford Hall
The University of Tennessee
Knoxville, TN 37996
Phone [O]:(865) 974-9672
      [R]:(865) 946-4340



From mtb954 at gmail.com  Fri Feb 24 22:52:18 2006
From: mtb954 at gmail.com (mtb954 mtb954)
Date: Fri, 24 Feb 2006 15:52:18 -0600
Subject: [R] Read SAS .sd2 file into R?
Message-ID: <e40d78ce0602241352n113eda71l64d90f0c952efeb0@mail.gmail.com>

Does anyone know how to import a SAS .sd2 file into R? I can't see
anything in library(foreign).

Thank you. Mark



From p.dalgaard at biostat.ku.dk  Fri Feb 24 23:19:38 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 24 Feb 2006 23:19:38 +0100
Subject: [R] Read SAS .sd2 file into R?
In-Reply-To: <e40d78ce0602241352n113eda71l64d90f0c952efeb0@mail.gmail.com>
References: <e40d78ce0602241352n113eda71l64d90f0c952efeb0@mail.gmail.com>
Message-ID: <x21wxso0w5.fsf@turmalin.kubism.ku.dk>

"mtb954 mtb954" <mtb954 at gmail.com> writes:

> Does anyone know how to import a SAS .sd2 file into R? I can't see
> anything in library(foreign).

The SAS dataset file formats are not publicly available. You need
either SAS itself (on a Windows machine) or a specialized tool like
DBMS/Copy to converti it.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ggrothendieck at gmail.com  Sat Feb 25 00:05:33 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 24 Feb 2006 18:05:33 -0500
Subject: [R] Time on x-axis
In-Reply-To: <441B876B@webmail.utk.edu>
References: <441B876B@webmail.utk.edu>
Message-ID: <971536df0602241505k4d040b46h75624ebb1c7919@mail.gmail.com>

See:

library(zoo)
?read.zoo


On 2/24/06, Sangeetha Swaminathan <sangi at itc.utk.edu> wrote:
> Hello,
>
>   Thank you! It worked!! Now I have another query; I have about 300 data
> entries, and I dont think it would be possible to quote everything under
> tt<-c("") or x<-c(). Is there any way to plot the graph, without having to
> manually quote all the data items in the array?
>
> Thank you.
>
> Sangeetha
>
> >===== Original Message From "Gabor Grothendieck" <ggrothendieck at gmail.com>
> =====
> >Try this:
> >
> ># test data
> >tt <- c("23:05:02", "23:10:02", "23:15:03", "23:20:03", "23:25:03",
> >"23:30:03", "23:35:03", "23:40:03", "23:45:04", "23:50:04", "23:55:03",
> >"23:55:03")
> >x <- c(0.575764, 0.738379, 0.567414, 0.663436, 0.599834, 0.679571,
> >0.88141, 0.868848, 0.969271, 0.878968, 0.990972, 0.990972)
> >
> >library(zoo)
> >library(chron)
> >z <- zoo(x, times(tt))
> >plot(z)
> >
> >Read the R Help Desk article in R News 4/1 about dates and times
> >and also read the chron article in its references.
> >
> >Also read the zoo vignette which you can access like this:
> >
> >library(zoo)
> >vignette("zoo")
> >
> >and also read ?axis in case you want to customize the axes.
> >
> >
> >On 2/20/06, Sangeetha Swaminathan <sangi at itc.utk.edu> wrote:
> >> Hello,
> >>
> >>   I just started using the GNU R. I am having trouble plotting my data. I
> am
> >> tryin to plot the following data:
> >>
> >> TIMESTAMP    LOGIN-TIME
> >> (hh:mm:ss)          (s)
> >>
> >> 23:55:03       0.990972
> >> 23:55:03       0.990972
> >> 23:50:04       0.878968
> >> 23:45:04       0.969271
> >> 23:40:03       0.868848
> >> 23:35:03        0.88141
> >> 23:30:03       0.679571
> >> 23:25:03       0.599834
> >> 23:20:03       0.663436
> >> 23:15:03       0.567414
> >> 23:10:02       0.738379
> >> 23:05:02       0.575764
> >>
> >> with TIMESTAMP on the x-axis. The plot() function assumes the x-axis as the
> >> total number of events, and plots the desired graph. But I want the
> TIMESTAMP
> >> on the x-axis. If I try to change the x-axis, the y-axis gets modified too,
> >> and all I get is just a "dot" as a plot.
> >> Can someone tell me how I can make R plot my graph, with TIMESTAMP as my
> >> x-axis and LOGIN_TIME as my y-axis?
> >>
> >> Thank you.
> >>
> >> Sangeetha
> >>
> >> -- Sangeetha Swaminathan
> >> Graduate Assistant
> >> Innovative Technology Center (ITC)
> >> 2444 Dunford Hall
> >> The University of Tennessee
> >> Knoxville, TN 37996
> >> Phone [O]:(865) 974-9672
> >>      [R]:(865) 946-4340
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >>
>
> -- Sangeetha Swaminathan
> Graduate Assistant
> Innovative Technology Center (ITC)
> 2444 Dunford Hall
> The University of Tennessee
> Knoxville, TN 37996
> Phone [O]:(865) 974-9672
>      [R]:(865) 946-4340
>
>



From ggrothendieck at gmail.com  Sat Feb 25 00:57:19 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 24 Feb 2006 18:57:19 -0500
Subject: [R] Time on x-axis
In-Reply-To: <971536df0602241505k4d040b46h75624ebb1c7919@mail.gmail.com>
References: <441B876B@webmail.utk.edu>
	<971536df0602241505k4d040b46h75624ebb1c7919@mail.gmail.com>
Message-ID: <971536df0602241557m6696b824y27ed68a2133a36c3@mail.gmail.com>

And also, read 1. R News 4/1 help desk article on dates and times,
2. the zoo vignette:

library(zoo)
vignette("zoo")

and 3. re-read the Introduction to R manual:
   http://cran.r-project.org/doc/manuals/R-intro.pdf


On 2/24/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> See:
>
> library(zoo)
> ?read.zoo
>
>
> On 2/24/06, Sangeetha Swaminathan <sangi at itc.utk.edu> wrote:
> > Hello,
> >
> >   Thank you! It worked!! Now I have another query; I have about 300 data
> > entries, and I dont think it would be possible to quote everything under
> > tt<-c("") or x<-c(). Is there any way to plot the graph, without having to
> > manually quote all the data items in the array?
> >
> > Thank you.
> >
> > Sangeetha
> >
> > >===== Original Message From "Gabor Grothendieck" <ggrothendieck at gmail.com>
> > =====
> > >Try this:
> > >
> > ># test data
> > >tt <- c("23:05:02", "23:10:02", "23:15:03", "23:20:03", "23:25:03",
> > >"23:30:03", "23:35:03", "23:40:03", "23:45:04", "23:50:04", "23:55:03",
> > >"23:55:03")
> > >x <- c(0.575764, 0.738379, 0.567414, 0.663436, 0.599834, 0.679571,
> > >0.88141, 0.868848, 0.969271, 0.878968, 0.990972, 0.990972)
> > >
> > >library(zoo)
> > >library(chron)
> > >z <- zoo(x, times(tt))
> > >plot(z)
> > >
> > >Read the R Help Desk article in R News 4/1 about dates and times
> > >and also read the chron article in its references.
> > >
> > >Also read the zoo vignette which you can access like this:
> > >
> > >library(zoo)
> > >vignette("zoo")
> > >
> > >and also read ?axis in case you want to customize the axes.
> > >
> > >
> > >On 2/20/06, Sangeetha Swaminathan <sangi at itc.utk.edu> wrote:
> > >> Hello,
> > >>
> > >>   I just started using the GNU R. I am having trouble plotting my data. I
> > am
> > >> tryin to plot the following data:
> > >>
> > >> TIMESTAMP    LOGIN-TIME
> > >> (hh:mm:ss)          (s)
> > >>
> > >> 23:55:03       0.990972
> > >> 23:55:03       0.990972
> > >> 23:50:04       0.878968
> > >> 23:45:04       0.969271
> > >> 23:40:03       0.868848
> > >> 23:35:03        0.88141
> > >> 23:30:03       0.679571
> > >> 23:25:03       0.599834
> > >> 23:20:03       0.663436
> > >> 23:15:03       0.567414
> > >> 23:10:02       0.738379
> > >> 23:05:02       0.575764
> > >>
> > >> with TIMESTAMP on the x-axis. The plot() function assumes the x-axis as the
> > >> total number of events, and plots the desired graph. But I want the
> > TIMESTAMP
> > >> on the x-axis. If I try to change the x-axis, the y-axis gets modified too,
> > >> and all I get is just a "dot" as a plot.
> > >> Can someone tell me how I can make R plot my graph, with TIMESTAMP as my
> > >> x-axis and LOGIN_TIME as my y-axis?
> > >>
> > >> Thank you.
> > >>
> > >> Sangeetha
> > >>
> > >> -- Sangeetha Swaminathan
> > >> Graduate Assistant
> > >> Innovative Technology Center (ITC)
> > >> 2444 Dunford Hall
> > >> The University of Tennessee
> > >> Knoxville, TN 37996
> > >> Phone [O]:(865) 974-9672
> > >>      [R]:(865) 946-4340
> > >>
> > >> ______________________________________________
> > >> R-help at stat.math.ethz.ch mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >>
> >
> > -- Sangeetha Swaminathan
> > Graduate Assistant
> > Innovative Technology Center (ITC)
> > 2444 Dunford Hall
> > The University of Tennessee
> > Knoxville, TN 37996
> > Phone [O]:(865) 974-9672
> >      [R]:(865) 946-4340
> >
> >
>



From sledepi at operamail.com  Sat Feb 25 03:06:50 2006
From: sledepi at operamail.com (sloan jones)
Date: Sat, 25 Feb 2006 03:06:50 +0100
Subject: [R] graphing dilemna
Message-ID: <20060225020653.71BB17B527@ws5-10.us4.outblaze.com>

I want to create a graph that combines both stacked and side-by-side bars, is this possible? 

If more information is need:  I have five age categories which are further divided by gender (the male and female bars lie side by side and then all the age groups are side by side). I want to further divide just the youngest category into two smaller age groups and retain the sex division -- stack the ages but have the sexes side by side. 

Help!
Sloan




-- 
_______________________________________________
Surf the Web in a faster, safer and easier way:
Download Opera 8 at http://www.opera.com



From mtb954 at gmail.com  Sat Feb 25 05:21:58 2006
From: mtb954 at gmail.com (Mark)
Date: Fri, 24 Feb 2006 22:21:58 -0600
Subject: [R] Sorting alphanumerically
In-Reply-To: <43FF5AB8.3070002@optonline.net>
References: <e40d78ce0602241054g1c0b0c5bi839987c42aaaab02@mail.gmail.com>
	<43FF5AB8.3070002@optonline.net>
Message-ID: <e40d78ce0602242021w328c4e65ue2f8192c6904e87f@mail.gmail.com>

Thank you all, for your help.
Mark

On 2/24/06, Chuck Cleland <ccleland at optonline.net> wrote:
> Does this help?
>
> ID <- paste("g", sample(1:100, 100, replace=FALSE), sep="")
>
> ID
>    [1] "g88"  "g5"   "g79"  "g67"  "g43"  "g21"  "g66"
>    [8] "g9"   "g38"  "g86"  "g12"  "g85"  "g74"  "g34"
>   [15] "g52"  "g95"  "g6"   "g22"  "g70"  "g87"  "g7"
>   [22] "g83"  "g63"  "g42"  "g26"  "g65"  "g16"  "g97"
>   [29] "g76"  "g2"   "g90"  "g23"  "g15"  "g82"  "g75"
>   [36] "g58"  "g17"  "g20"  "g96"  "g91"  "g31"  "g33"
>   [43] "g48"  "g32"  "g93"  "g54"  "g49"  "g36"  "g81"
>   [50] "g57"  "g27"  "g14"  "g62"  "g10"  "g80"  "g71"
>   [57] "g28"  "g37"  "g89"  "g8"   "g94"  "g68"  "g56"
>   [64] "g92"  "g41"  "g11"  "g4"   "g99"  "g55"  "g60"
>   [71] "g18"  "g69"  "g19"  "g64"  "g39"  "g1"   "g53"
>   [78] "g44"  "g24"  "g100" "g35"  "g3"   "g40"  "g47"
>   [85] "g51"  "g46"  "g61"  "g45"  "g50"  "g25"  "g13"
>   [92] "g73"  "g77"  "g30"  "g84"  "g78"  "g29"  "g59"
>   [99] "g72"  "g98"
>
> ID[order(as.numeric(substr(ID, start=2, stop=nchar(ID))))]
>    [1] "g1"   "g2"   "g3"   "g4"   "g5"   "g6"   "g7"
>    [8] "g8"   "g9"   "g10"  "g11"  "g12"  "g13"  "g14"
>   [15] "g15"  "g16"  "g17"  "g18"  "g19"  "g20"  "g21"
>   [22] "g22"  "g23"  "g24"  "g25"  "g26"  "g27"  "g28"
>   [29] "g29"  "g30"  "g31"  "g32"  "g33"  "g34"  "g35"
>   [36] "g36"  "g37"  "g38"  "g39"  "g40"  "g41"  "g42"
>   [43] "g43"  "g44"  "g45"  "g46"  "g47"  "g48"  "g49"
>   [50] "g50"  "g51"  "g52"  "g53"  "g54"  "g55"  "g56"
>   [57] "g57"  "g58"  "g59"  "g60"  "g61"  "g62"  "g63"
>   [64] "g64"  "g65"  "g66"  "g67"  "g68"  "g69"  "g70"
>   [71] "g71"  "g72"  "g73"  "g74"  "g75"  "g76"  "g77"
>   [78] "g78"  "g79"  "g80"  "g81"  "g82"  "g83"  "g84"
>   [85] "g85"  "g86"  "g87"  "g88"  "g89"  "g90"  "g91"
>   [92] "g92"  "g93"  "g94"  "g95"  "g96"  "g97"  "g98"
>   [99] "g99"  "g100"
>
> The idea is to drop the leading "g", convert to numeric, and then order.
>
> mtb954 mtb954 wrote:
> > I'm trying to sort a DATAFRAME by a column "ID" that contains
> > alphanumeric data. Specifically,"ID" contains integers all preceeded
> > by the character "g" as in:
> >
> > g1, g6, g3, g19, g100, g2, g39
> >
> > I am using the following code:
> >
> > DATAFRAME=DATAFRAME[order(DATAFRAME1$ID),]
> >
> > and was hoping it would sort the dataframe by ID in the following manner
> >
> > g1, g2, g3, g6, g19, g39, g100
> >
> > but it doesn't sort at all. Could anyone point out my mistake?
> >
> > Thank you.
> >
> > Mark
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>
> --
> Chuck Cleland, Ph.D.
> NDRI, Inc.
> 71 West 23rd Street, 8th floor
> New York, NY 10010
> tel: (212) 845-4495 (Tu, Th)
> tel: (732) 452-1424 (M, W, F)
> fax: (917) 438-0894
>



From peterdlauren at yahoo.com  Sat Feb 25 13:36:15 2006
From: peterdlauren at yahoo.com (Peter Lauren)
Date: Sat, 25 Feb 2006 04:36:15 -0800 (PST)
Subject: [R] Problem with List() Inside Function
In-Reply-To: <43FE224B.5010202@pburns.seanet.com>
Message-ID: <20060225123615.34898.qmail@web30307.mail.mud.yahoo.com>

Dear Dr. Burns,

Many thanks for your reply.  I figured out what the
problem was.  I had neglected to put the line
out;
at the end of the function.  Once I did that,
everything was fine.  

Thanks again,
Peter.

--- Patrick Burns <pburns at pburns.seanet.com> wrote:

> My solution when I run into mysteries like this
> is to put
> 
> browser()
> 
> in the function just before or after the line of
> interest.
> The magnitude and direction of my stupidity usually
> become clear quickly.
> 
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S
> User")
> 
> Peter Lauren wrote:
> 
> >I have a function declared thus.
> >FirstEigenvectorBoundary.Training <-
> >function(InputFileName='C:/Samples2/PT_Amp.txt',
> >Header=TRUE, Colour="red")
> >
> >Inside the function, I have the following call
> >
>
>out<-list(x=Eigenvectors[2:(NumMetricsSelected+1),1],
> >y=-0.8, z=NumMetricsSelected);
> >
> >NumMetricsSelected has the value 2 and Eigenvectors
> >has the following form
> >           [,1]       [,2]       [,3]
> >[1,]  0.6404630 -0.2153989  0.7371638
> >[2,] -0.6081319  0.4439621  0.6580830
> >[3,]  0.4690231  0.8697706 -0.1533503
> >
> >When I do it manually at the console, I get the
> >correct result.  I.e.
> >  
> >
> >>out
> >>    
> >>
> >$x
> >[1] -0.6081319  0.4690231
> >
> >$y
> >[1] -0.8
> >
> >$z
> >[1] 2
> >
> >However, when I call the function like this
> >  
> >
> >>Training<-FirstEigenvectorBoundary.Training()
> >>    
> >>
> >
> >I get
> >  
> >
> >>Training
> >>    
> >>
> >$x
> >[1] 0.658083
> >
> >$y
> >[1] -0.8
> >
> >$z
> >[1] 2
> >
> >That is, the $x element has only one value (instead
> of
> >2) and it is from the wrong part of the matrix.
> >
> >Can anyone see what I am doing wrong?
> >
> >Thanks very much,
> >Peter.
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> >
> >
> >  
> >
> 
>



From cgb at datanalytics.com  Sat Feb 25 16:45:38 2006
From: cgb at datanalytics.com (Carlos J. Gil Bellosta)
Date: Sat, 25 Feb 2006 16:45:38 +0100
Subject: [R] Patient Rule Induction Method implemented in R?
In-Reply-To: <971536df0602241505k4d040b46h75624ebb1c7919@mail.gmail.com>
References: <441B876B@webmail.utk.edu>
	<971536df0602241505k4d040b46h75624ebb1c7919@mail.gmail.com>
Message-ID: <1140882339.3163.9.camel@lenin>

Dear R users,

I have not been able to find any implementation of Friedman's Patient
Rule Induction Method, PRIM, available on R. Is there any?

In any case, is there any reasonable alternative? So far, I have been
using trees and just keeping the extreme leaves. But a project of mine
requires a method that would just "hunt the bumps" in a high dimensional
data set and that would produce a relatively understandable/graphical
set of rules.

Sincerely,

Carlos J. Gil Bellosta
http://www.datanalytics.com



From mtb954 at gmail.com  Sat Feb 25 19:20:55 2006
From: mtb954 at gmail.com (Mark)
Date: Sat, 25 Feb 2006 12:20:55 -0600
Subject: [R] Adding header lines to a dataframe that is exported using
	write.csv
Message-ID: <e40d78ce0602251020p32698ae4r8c1b0e5736a07c64@mail.gmail.com>

I would like to export a dataframe to a .csv using:

>write.csv(dataframe,"dataframe.csv")

but I need to add four "header" lines to the csv that are not part of
the dataframe (which itself has a line of column headers).

The difficulty (for me, at least!) lies in the requirement that
certain elements of the header (X, Y and the number of "Q"s - please
see example below) must be defined based on the number of rows and
columns in the dataframe, which vary depending on the input file.

Here's what the 3 .csv header lines should look like, followed by a
number of dataframe rows (i.e., these lines are not R code, but are
what R will produce).

X, plots ,,,, #where X=number of rows in the dataframe
Y, species,,,, #where Y=number of columns in the dataframe
,Q,Q,Q,Q,Q #where the number of Qs=the number of columns in the dataframe

Those 3 .csv header lines would be followed by dataframe, which
consists of one row containing column headers and X "data" rows:

,spec1,spec2,spec3,sp3c4,spec5 #these are the dataframe's column headers
plot1,15.84,0,0,792,7 #this is an example "data" row

In case the above is unclear, I have also attached a small .csv as an
example of what the output should look like.

Thank you. Mark

From murdoch at stats.uwo.ca  Sat Feb 25 19:32:20 2006
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 25 Feb 2006 13:32:20 -0500
Subject: [R] Adding header lines to a dataframe that is exported using
 write.csv
In-Reply-To: <e40d78ce0602251020p32698ae4r8c1b0e5736a07c64@mail.gmail.com>
References: <e40d78ce0602251020p32698ae4r8c1b0e5736a07c64@mail.gmail.com>
Message-ID: <4400A2B4.6090601@stats.uwo.ca>

On 2/25/2006 1:20 PM, Mark wrote:
> I would like to export a dataframe to a .csv using:
> 
>> write.csv(dataframe,"dataframe.csv")
> 
> but I need to add four "header" lines to the csv that are not part of
> the dataframe (which itself has a line of column headers).

Open a connection and write the header to it first, then write the
dataframe.  For example,

df <- data.frame(a=1:5,b=6:10)

f <- file("dataframe.csv", "w")

writeLines(paste(c(nrow(df), ncol(df)), c("plots", "species"), ",,,", 
sep=","),f)
writeLines(paste(rep(",Q", ncol(df)), collapse=""),f)
write.csv(df, f)

close(f)

Duncan Murdoch
> 
> The difficulty (for me, at least!) lies in the requirement that
> certain elements of the header (X, Y and the number of "Q"s - please
> see example below) must be defined based on the number of rows and
> columns in the dataframe, which vary depending on the input file.
> 
> Here's what the 3 .csv header lines should look like, followed by a
> number of dataframe rows (i.e., these lines are not R code, but are
> what R will produce).
> 
> X, plots ,,,, #where X=number of rows in the dataframe
> Y, species,,,, #where Y=number of columns in the dataframe
> ,Q,Q,Q,Q,Q #where the number of Qs=the number of columns in the dataframe
> 
> Those 3 .csv header lines would be followed by dataframe, which
> consists of one row containing column headers and X "data" rows:
> 
> ,spec1,spec2,spec3,sp3c4,spec5 #these are the dataframe's column headers
> plot1,15.84,0,0,792,7 #this is an example "data" row
> 
> In case the above is unclear, I have also attached a small .csv as an
> example of what the output should look like.
> 
> Thank you. Mark
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From A.Robinson at ms.unimelb.edu.au  Sat Feb 25 22:42:45 2006
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Sun, 26 Feb 2006 08:42:45 +1100 (EST)
Subject: [R] Changing predictor order in lm()
In-Reply-To: <Pine.LNX.4.64.0602191240490.15946@gannet.stats.ox.ac.uk>
References: <50496.63.125.5.171.1140309789.squirrel@webmail.ms.unimelb.edu.au>
	<Pine.LNX.4.64.0602191240490.15946@gannet.stats.ox.ac.uk>
Message-ID: <62483.220.237.183.166.1140903765.squirrel@webmail.ms.unimelb.edu.au>

Thanks to Brian Ripley and Ernst Hansen for their kindly replies to my
question.

Cheers

Andrew


On Sun, February 19, 2006 11:43 pm, Prof Brian Ripley said:
> RSiteSearch("keep.order") gave me
>
> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/14240.html
>
> which has such an example, and points out another example is in
> demo(glm.vr).
>
> On Sun, 19 Feb 2006, Andrew Robinson wrote:
>
>> Dear community,
>>
>> can anyone provide a snippet of code to force the lm() to fit a model
>> with
>> terms in the formula in an arbitrary order?  I am interested in
>> something
>> like:
>>
>> lm(y ~ A * B + C, data=data)
>>
>> where the interaction of A and B should be in the formula before C.  My
>> goal is to simplify my presentation of models using the anova()
>> statement.
>> I have found that this should be possible using the terms.formula()
>> function, but if anyone has an example that would be much appreciated.
>>
>> Cheers
>>
>> Andrew
>>
>>
>> Andrew Robinson
>> Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
>> Department of Mathematics and Statistics            Fax: +61-3-8344 4599
>> University of Melbourne, VIC 3010 Australia
>> Email: a.robinson at ms.unimelb.edu.au    Website:
>> http://www.ms.unimelb.edu.au
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>


Andrew Robinson
Senior Lecturer in Statistics                       Tel: +61-3-8344-9763
Department of Mathematics and Statistics            Fax: +61-3-8344 4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au



From ccatj at web.de  Sun Feb 26 00:18:02 2006
From: ccatj at web.de (Christian Jones)
Date: Sun, 26 Feb 2006 00:18:02 +0100
Subject: [R] problems with bootstrapping (Divergence or singularity ???)
Message-ID: <502403363@web.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060226/dc1be04f/attachment.pl

From spencer.graves at pdf.com  Sun Feb 26 01:27:46 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 25 Feb 2006 16:27:46 -0800
Subject: [R] bVar slot of lmer objects and standard errors
In-Reply-To: <43FA58F2.7090906@web.de>
References: <F5ED48890E2ACB468D0F3A64989D335A0139629C@dc1ex3.air.org>	<40e66e0b0512301305n2106e765t65bf944de45a681b@mail.gmail.com>
	<43FA58F2.7090906@web.de>
Message-ID: <4400F602.5010004@pdf.com>

	  I shall provide herewith an example of what I believe is "the 
conditional posterior variance of a random effect".  I hope someone more 
knowledgeable will check this and provide a correction if it's not 
correct.  I say this in part because my simple rationality check (below) 
didn't match as closely as I had hoped.

	  I don't have easy access to the "hlmframe" of your example, so I used 
the example in the "lmer" documentation:

library(lme4)
(fm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy))
Formula: Reaction ~ Days + (Days | Subject)
    Data: sleepstudy
       AIC      BIC    logLik MLdeviance REMLdeviance
  1753.628 1769.593 -871.8141   1751.986     1743.628
Random effects:
  Groups   Name        Variance Std.Dev. Corr
  Subject  (Intercept) 612.090  24.7405
           Days         35.072   5.9221  0.066
  Residual             654.941  25.5918
# of obs: 180, groups: Subject, 18
<snip>

	  I think we want the "Residual Variance" of 654.941 (Std.Dev. of 
25.5918).  To get this, let's try "VarCorr":

(vC.fm1 <- VarCorr(fm1))
$Subject
2 x 2 Matrix of class "dpoMatrix"
             (Intercept)     Days
(Intercept)   612.09032  9.60428
Days            9.60428 35.07165

attr(,"sc")
[1] 25.59182

	  Our desired 25.5918 is 'attr(,"sc")' here.  We get that as follows:

(s. <- attr(vC.fm1, "sc"))
[1] 25.59182

	  Next, by studying 'str(fm1)' and earlier emails you cite, we get the 
desired conditional posterior covariance matrix as follows:

 > (condPostCov <- (s.^2)*fm1 at bVar$Subject)
, , 1
          [,1]       [,2]
[1,] 145.7051 -21.444432
[2,]   0.0000   5.312275
<snip>
, , 18
          [,1]       [,2]
[1,] 145.7051 -21.444432
[2,]   0.0000   5.312275

	  This actually gives us only the upper triangular portion of the 
desired covariance matrices.  The following will make them all symmetric:

condPostCov[2,1,] <- condPostCov[1,2,]

	  As a check, I computed the covariance matrix of the estimated random 
effects. To get this, I reviewed str(ranef(fm1)), which led me to the 
following:

  var(ranef.fm1 at .Data[[1]])
             (Intercept)     Days
(Intercept)   466.38503 31.04874
Days           31.04874 29.75939

	  These numbers are all much larger than "condPostCov".  However, I 
believe this must be a random bounce -- unless it's a deficiency in my 
understanding (in which case, I hope someone will provide a correction).

	  Ulrich:  Would you mind checking this either with a published example 
or a Monte Carlo and reporting the results to us?

	  Viel Gl??ck,
	  spencer graves
	  	
Ulrich Keller wrote:

> Hello,
> 
> I'm sorry to resurrect this thread that I started almost two months ago. 
> I've been pretty busy since I posted my question and the issue is not 
> that high on my priority list. Thanks to all those who replied, and I 
> hope I can tickle your interest again.
> 
> As a reminder, my question was how one can extract the conditional 
> posterior variance of a random effect from the bVar slot of an lmer 
> model. Thanks to your answers, I now understand that I have to use the 
> diagonal elements of the conditional matrices. However, I am not quite 
> sure what this means:
> 
> Douglas Bates wrote:
> 
>>I'd have to go back and check but I think that these are the upper
>>triangles of the symmetric matrix (as Spencer suggested) that are the
>>conditional variance-covariance matrices of the two-dimensional 
>>random effects for each school up to a scale factor.  That is, I think
>>each face needs to be multiplied by s^2 to get the actual
>>variance-covariance matrix.
> 
> 
> What is s^2? Where can I find it in the lmer object? I tried reading the 
> source, but gave up fairly quickly. Thanks in advance for your replies, 
> and this time I promise I'll be more responsive.
> 
> 
> Uli
> 
> My original post:
> 
>>Hello,
>>
>>I am looking for a way to obtain standard errors for 
emprirical Bayes estimates of a model fitted with lmer
(like the ones plotted on page 14 of the document
available at
http://www.eric.ed.gov/ERICDocs/data/ericdocs2/content_storage_01/0000000b/80/2b/b3/94.pdf). 

Harold Doran mentioned 
(http://tolstoy.newcastle.edu.au/~rking/R/help/05/08/10638.html)
that  the posterior modes' variances can be found in the bVar
slot of lmer objects. However, when I fit e.g. this model:
>>
>>lmertest1<-lmer(mathtot~1+(m_escs_c|schoolid),hlmframe)
>>
>>then lmertest1 at bVar$schoolid is a three-dimensional 
array with dimensions (2,2,28). The factor schoolid

has 28 levels, and there are random effects for the
intercept and m_escs_c, but what does the third
dimension correspond to? In other words, what are
the contents of bVar, and how can I use them to
get standard errors?
>>
>>Thanks in advance for your answers and Merry Christmas,
>>
>>Uli Keller
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Scott.Williams at petermac.org  Sun Feb 26 04:02:32 2006
From: Scott.Williams at petermac.org (Williams Scott)
Date: Sun, 26 Feb 2006 14:02:32 +1100
Subject: [R] frailty in coxph or repeated measures in cph (Design)
Message-ID: <46B75B4A4A45914ABB0901364EFF4A200319C6@PMC-EMAIL.petermac.org.au>

I am trying to build a model to aid a clinical decision. Certain patients have a blood marker measured at each visit - a rise of this may indicate recurrence of the cancer after treatment (endpoint is "clinical recurrence", censored). In a proportion (up to 30%), this rise is a false positive - hence I wish to correlate factors at the time of the rising test to clinical recurrence, preferably expressed using nomogram (Design library). Many patients have more than one rise and sometimes even 5 rises doesn't mean inevitable failure. The aim is to identify the true positives early, to offer further therapy. 

 

The data form presently disregards the potential multiplicity of measurements per individual, treating each as independent. For example:

 

id <- c(a,a,a,b,b,b) # patient id

risenumber <- c(1,2,3,1,2,3) # number of each rise per patient

clinfail <- c(1,1,1,0,0,0) # censored indicator of clinical failure status (the endpoint) 

clinfailtime <- c(5,4,3,10,9,8) # time from rise to clinical failure endpoint

riseval <- c(10,20,30,1,2,3) # value of test at the time of rise

timesinceRx <- c(1,2,3,1,2,3) # years since treatment

Rxtype <- c(c,c,c,d,d,d) # type of treatment

...plus other variables at time of rise plus pre-treatment variables

 

In generic terms, analysis would be:

fit <- cph(Surv(clinfailtime, clinfail) ~ riseval +Rxtype...)

nomogram(fit)

 

I could easily convert these data to counting process notation and use time-dependent covariates aligned to treatment date. I do think the question is different however - not "what predicts clinical failure from the time of treatment" - rather, "what predicts the risk of clinical failure beyond the time of rise". To complicate things, the different treatments will be likely to have non-proportional hazards, with Rxtype=='d' likely to have large numbers of false positive rises at 1-2 years due to differing biology.

 

The obvious lack of independence between the successive rises in an individual is the problem - my feeling is to use the current data format with:

fit <- coxph(Surv(clinfailtime, clinfail) ~ riseval +Rxtype +frailty(id) 

 

The frailty option is not available in cph (Design), meaning an illustrative nomogram would be more difficult to produce. Any thoughts on what might be the best solution to this would be most welcome.

 

Scott Williams MD

Radiation Oncology

Peter MacCallum Cancer Centre

Melbourne, Australia



From matheric at u.washington.edu  Sun Feb 26 05:47:13 2006
From: matheric at u.washington.edu (Eric C. Jennings)
Date: Sat, 25 Feb 2006 20:47:13 -0800
Subject: [R] how to get f(x)=___ from a piecwise function
Message-ID: <000b01c63a8f$bafbb430$733dd080@Victor1>

>From actual real-world readings, I have two vectors:

x<- c(-100.4, 32.0, 99.8, 200.2, 300.6, 399.8, 500.0, 600.0, 699.6, 799.6, 
899.8)
y<- c(0.4, 0.0, 0.2, -0.2, -0.6, 0.2, 0.0, 0.0, 0.4, 0.4, 0.2)

which, in the usual way constitute a  continuous piecewise function.

What I want to do is find an easy method to get at f(x) for some x I have 
NOT specified in the above vector.  For example I want f(356).

I have already put the time and effort in to write a program to compute this 
by breaking the function into the various pieces and computing the slopes of 
the individual lines etc. etc.

I am just looking to find an easier method.

Thank you for your help.
Eric



From jholtman at gmail.com  Sun Feb 26 06:27:48 2006
From: jholtman at gmail.com (jim holtman)
Date: Sun, 26 Feb 2006 00:27:48 -0500
Subject: [R] how to get f(x)=___ from a piecwise function
In-Reply-To: <000b01c63a8f$bafbb430$733dd080@Victor1>
References: <000b01c63a8f$bafbb430$733dd080@Victor1>
Message-ID: <644e1f320602252127s5693d4b6xb8442d168e898724@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060226/dc3265e3/attachment.pl

From alexnerdy at hotmail.com  Sun Feb 26 09:14:15 2006
From: alexnerdy at hotmail.com (Alexander Nervedi)
Date: Sun, 26 Feb 2006 08:14:15 +0000
Subject: [R] collocation methods
Message-ID: <BAY106-F85D56D5AAED88FA9F702BBBF10@phx.gbl>

Hi R Users,

I have been trying to google (in general and specifically r-project) to see 
if I can find listing that may point me to understand the state of the art 
in R for functional approximation. Unfortunately, I have been unable to find 
anything concrete.

I hope I am missing something, and hence this message. Are there packages 
out there that may implement collocation. Specifically I am trying to 
implement Chebychev polynomial approximations.

Much more generally, has the R-management thought of some kind of 
encycopaedia that will allow developers/users to figure out what kinds of 
different routines are implemented and packaged under different packages?

thanks,
currently,

R Neeu B.



From patrick.giraudoux at univ-fcomte.fr  Sun Feb 26 14:24:19 2006
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 26 Feb 2006 14:24:19 +0100
Subject: [R] subtotal, submean, aggregate
Message-ID: <4401AC03.6050301@univ-fcomte.fr>

Dear All,

I would like to make partial sums (or means or any other function) of 
the values in intervals along a sequence (spatial transect) where groups 
are defined.

For instance:

habitats<-rep(c("meadow","forest","meadow","pasture"),c(10,5,12,6))
observations<-rpois(length(habitats),2)
transect<-data.frame(observations=observations,habitats=habitats)

aggregate() is not suitable for my purpose because I want a result 
respecting the order of the habitats encountered although they may have 
the same name (and not pooling each group on each level of the factor 
created). For instance, the output of the ideal function 
mynicefunction() would be something as:

mynicefunction(transect$observations, by=list(transect$habitats),sum)
meadow     16
forest      9
meadow     21
pasture    17

and not

aggregate(transect$observations,by=list(transect$habitats),sum)
  Group.1  x
1  forest  9
2  meadow 37
3 pasture 17

Did anybody hear about such a function already written in R? If no, any 
idea to make it simple and elegant to write?

Cheers,

Patrick Giraudoux



From ggrothendieck at gmail.com  Sun Feb 26 15:08:31 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 26 Feb 2006 09:08:31 -0500
Subject: [R] subtotal, submean, aggregate
In-Reply-To: <4401AC03.6050301@univ-fcomte.fr>
References: <4401AC03.6050301@univ-fcomte.fr>
Message-ID: <971536df0602260608g64da87f0i49ee4a9e5867f81c@mail.gmail.com>

Create another variable that gives the run number and aggregate on
both the habitat and run number removing the run number after
aggregating:

runno <- cumsum(c(TRUE, diff(as.numeric(transect[,2])) !=0))
aggregate(transect[,1], list(obs = transect[,2], runno = runno), sum)[,-2]

This does not give the same as your example but I think there are some
errors in your example output.

On 2/26/06, Patrick Giraudoux <patrick.giraudoux at univ-fcomte.fr> wrote:
> Dear All,
>
> I would like to make partial sums (or means or any other function) of
> the values in intervals along a sequence (spatial transect) where groups
> are defined.
>
> For instance:
>
> habitats<-rep(c("meadow","forest","meadow","pasture"),c(10,5,12,6))
> observations<-rpois(length(habitats),2)
> transect<-data.frame(observations=observations,habitats=habitats)
>
> aggregate() is not suitable for my purpose because I want a result
> respecting the order of the habitats encountered although they may have
> the same name (and not pooling each group on each level of the factor
> created). For instance, the output of the ideal function
> mynicefunction() would be something as:
>
> mynicefunction(transect$observations, by=list(transect$habitats),sum)
> meadow     16
> forest      9
> meadow     21
> pasture    17
>
> and not
>
> aggregate(transect$observations,by=list(transect$habitats),sum)
>  Group.1  x
> 1  forest  9
> 2  meadow 37
> 3 pasture 17
>
> Did anybody hear about such a function already written in R? If no, any
> idea to make it simple and elegant to write?
>
> Cheers,
>
> Patrick Giraudoux
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Roger.Bivand at nhh.no  Sun Feb 26 15:18:14 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Sun, 26 Feb 2006 15:18:14 +0100 (CET)
Subject: [R] subtotal, submean, aggregate
In-Reply-To: <4401AC03.6050301@univ-fcomte.fr>
Message-ID: <Pine.LNX.4.44.0602261512170.32524-100000@reclus.nhh.no>

On Sun, 26 Feb 2006, Patrick Giraudoux wrote:

> Dear All,
> 
> I would like to make partial sums (or means or any other function) of 
> the values in intervals along a sequence (spatial transect) where groups 
> are defined.
> 
> For instance:
> 
> habitats<-rep(c("meadow","forest","meadow","pasture"),c(10,5,12,6))
> observations<-rpois(length(habitats),2)
> transect<-data.frame(observations=observations,habitats=habitats)
> 
> aggregate() is not suitable for my purpose because I want a result 
> respecting the order of the habitats encountered although they may have 
> the same name (and not pooling each group on each level of the factor 
> created). For instance, the output of the ideal function 
> mynicefunction() would be something as:
> 
> mynicefunction(transect$observations, by=list(transect$habitats),sum)
> meadow     16
> forest      9
> meadow     21
> pasture    17
> 
> and not
> 
> aggregate(transect$observations,by=list(transect$habitats),sum)
>   Group.1  x
> 1  forest  9
> 2  meadow 37
> 3 pasture 17
> 
> Did anybody hear about such a function already written in R? If no, any 
> idea to make it simple and elegant to write?

I got as far as:

rle.habs <- rle(habitats)
habitats1 <- rep(make.names(rle.habs$values, unique=TRUE), rle.habs$lengths)
aggregate(observations,by=list(habitats1),sum)

making an extra habitats vector with a unique label for each run. 

Since I don't know your seed, the results are not the same, but rle() is 
quite good for runs.

Roger

> 
> Cheers,
> 
> Patrick Giraudoux
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From patrick.giraudoux at univ-fcomte.fr  Sun Feb 26 15:34:27 2006
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 26 Feb 2006 15:34:27 +0100
Subject: [R] subtotal, submean, aggregate
In-Reply-To: <971536df0602260608g64da87f0i49ee4a9e5867f81c@mail.gmail.com>
References: <4401AC03.6050301@univ-fcomte.fr>
	<971536df0602260608g64da87f0i49ee4a9e5867f81c@mail.gmail.com>
Message-ID: <4401BC73.401@univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060226/d6131b04/attachment.pl

From patrick.giraudoux at univ-fcomte.fr  Sun Feb 26 15:40:48 2006
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 26 Feb 2006 15:40:48 +0100
Subject: [R] subtotal, submean, aggregate
In-Reply-To: <Pine.LNX.4.44.0602261512170.32524-100000@reclus.nhh.no>
References: <Pine.LNX.4.44.0602261512170.32524-100000@reclus.nhh.no>
Message-ID: <4401BDF0.9060903@univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060226/d1b6f88d/attachment.pl

From ggrothendieck at gmail.com  Sun Feb 26 15:42:47 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 26 Feb 2006 09:42:47 -0500
Subject: [R] subtotal, submean, aggregate
In-Reply-To: <4401BC73.401@univ-fcomte.fr>
References: <4401AC03.6050301@univ-fcomte.fr>
	<971536df0602260608g64da87f0i49ee4a9e5867f81c@mail.gmail.com>
	<4401BC73.401@univ-fcomte.fr>
Message-ID: <971536df0602260642l4d7ca708t47d640cc7fb8cf4d@mail.gmail.com>

We are just comparing the difference to 0 so it does not matter if its positive
or negative.  All that matters is whether its 0 or not.

In fact, the runno you calculate with the abs is identical to the one
I posted without the abs:

runno <- cumsum(c(TRUE, abs(diff(as.numeric(transect[,2])))!=0))
runno2 <- cumsum(c(TRUE, diff(as.numeric(transect[,2])))!=0)
identical(runno, runno2)  # TRUE


On 2/26/06, Patrick Giraudoux <patrick.giraudoux at univ-fcomte.fr> wrote:
> Excellent! I was messing with this problem since the early afternoon.
> Actually the discrepancy you noticed remaining comes from negative
> difference in
> diff(as.numeric(transect[,2]))
> One can work it around using  abs(diff(as.numeric(transect[,2]))). This
> makes:
>
> runno <- cumsum(c(TRUE, abs(diff(as.numeric(transect[,2])))!=0))
> aggregate(transect[,1], list(obs = transect[,2], runno = runno), sum)
>
> I did not know about this use of diff, which was the key point... and then
> cumsum for polishing. Really great and also elegant (concise). I like it!
>
> Thanks a lot!!!
>
> Cheers,
>
> Patrick
>
>
> Gabor Grothendieck a ??crit :
> Create another variable that gives the run number and aggregate on
both the
> habitat and run number removing the run number after
aggregating:

runno <-
> cumsum(c(TRUE, diff(as.numeric(transect[,2])) !=0))
aggregate(transect[,1],
> list(obs = transect[,2], runno = runno), sum)[,-2]

This does not give the
> same as your example but I think there are some
errors in your example
> output.

On 2/26/06, Patrick Giraudoux
> <patrick.giraudoux at univ-fcomte.fr> wrote:

> Dear All,

I would like to make partial sums (or means or any other
> function) of
the values in intervals along a sequence (spatial transect)
> where groups
are defined.

For
> instance:

habitats<-rep(c("meadow","forest","meadow","pasture"),c(10,5,12,6))
observations<-rpois(length(habitats),2)
transect<-data.frame(observations=observations,habitats=habitats)

aggregate()
> is not suitable for my purpose because I want a result
respecting the order
> of the habitats encountered although they may have
the same name (and not
> pooling each group on each level of the factor
created). For instance, the
> output of the ideal function
mynicefunction() would be something
> as:

mynicefunction(transect$observations,
> by=list(transect$habitats),sum)
meadow 16
forest 9
meadow 21
pasture 17

and
> not

aggregate(transect$observations,by=list(transect$habitats),sum)
> Group.1 x
1 forest 9
2 meadow 37
3 pasture 17

Did anybody hear about such a
> function already written in R? If no, any
idea to make it simple and elegant
> to write?

Cheers,

Patrick
> Giraudoux

______________________________________________
R-help at stat.math.ethz.ch
> mailing
> list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do
> read the posting guide!
> http://www.R-project.org/posting-guide.html


>
>



From patrick.giraudoux at univ-fcomte.fr  Sun Feb 26 15:52:30 2006
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Sun, 26 Feb 2006 15:52:30 +0100
Subject: [R] subtotal, submean, aggregate
In-Reply-To: <971536df0602260642l4d7ca708t47d640cc7fb8cf4d@mail.gmail.com>
References: <4401AC03.6050301@univ-fcomte.fr>	
	<971536df0602260608g64da87f0i49ee4a9e5867f81c@mail.gmail.com>	
	<4401BC73.401@univ-fcomte.fr>
	<971536df0602260642l4d7ca708t47d640cc7fb8cf4d@mail.gmail.com>
Message-ID: <4401C0AE.3060701@univ-fcomte.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060226/fc7dcd81/attachment.pl

From zh107 at york.ac.uk  Sun Feb 26 15:58:10 2006
From: zh107 at york.ac.uk (Zhesi He)
Date: Sun, 26 Feb 2006 14:58:10 +0000
Subject: [R] R2.2.1 source compile problem in MacOS10.3
Message-ID: <a773ed73c60f70ff272ef9ae25cf27c0@york.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060226/b1993bbe/attachment.pl

From ggrothendieck at gmail.com  Sun Feb 26 16:04:49 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 26 Feb 2006 10:04:49 -0500
Subject: [R] subtotal, submean, aggregate
In-Reply-To: <4401C0AE.3060701@univ-fcomte.fr>
References: <4401AC03.6050301@univ-fcomte.fr>
	<971536df0602260608g64da87f0i49ee4a9e5867f81c@mail.gmail.com>
	<4401BC73.401@univ-fcomte.fr>
	<971536df0602260642l4d7ca708t47d640cc7fb8cf4d@mail.gmail.com>
	<4401C0AE.3060701@univ-fcomte.fr>
Message-ID: <971536df0602260704m214807d4j3a2a6382a02c4ba3@mail.gmail.com>

Yes, that must be it.  Probably best to issue a:

set.seed(1)

as part of the code when posting examples with random numbers.

Also here is a variation that uses rle that Roger used together with
some elements of the solution I posted:

runno <- with(rle(as.numeric(transect[,2])), rep(seq(along = lengths), lengths))
aggregate(transect[,1], list(obs = transect[,2], runno), sum)[,-2]


On 2/26/06, Patrick Giraudoux <patrick.giraudoux at univ-fcomte.fr> wrote:
> Yes right. Checking some examples, all come out OK.
>
>
> same as your example but I think there are some errors in your example
> output.
> Simply the 'errors' observed come simply from the seed in
> rpois(length(habitats),2)
> It is unlikely it is the same on your and my computer...
>
> Cheers,
>
> Patrick
>
>
> Gabor Grothendieck a ??crit :
> We are just comparing the difference to 0 so it does not matter if its
> positive
or negative. All that matters is whether its 0 or not.

In fact,
> the runno you calculate with the abs is identical to the one
I posted
> without the abs:

runno <- cumsum(c(TRUE,
> abs(diff(as.numeric(transect[,2])))!=0))
runno2 <- cumsum(c(TRUE,
> diff(as.numeric(transect[,2])))!=0)
identical(runno, runno2) # TRUE


On
> 2/26/06, Patrick Giraudoux
> <patrick.giraudoux at univ-fcomte.fr> wrote:

> Excellent! I was messing with this problem since the early
> afternoon.
Actually the discrepancy you noticed remaining comes from
> negative
difference in
diff(as.numeric(transect[,2]))
One can work it around
> using abs(diff(as.numeric(transect[,2]))). This
makes:

runno <-
> cumsum(c(TRUE,
> abs(diff(as.numeric(transect[,2])))!=0))
aggregate(transect[,1], list(obs =
> transect[,2], runno = runno), sum)

I did not know about this use of diff,
> which was the key point... and then
cumsum for polishing. Really great and
> also elegant (concise). I like it!

Thanks a
> lot!!!

Cheers,

Patrick


Gabor Grothendieck a ??crit :
Create another
> variable that gives the run number and aggregate on

> both the

> habitat and run number removing the run number after

> aggregating:

runno <-

> cumsum(c(TRUE, diff(as.numeric(transect[,2])) !=0))

> aggregate(transect[,1],

> list(obs = transect[,2], runno = runno), sum)[,-2]

> This does not give the

> same as your example but I think there are some

> errors in your example

> output.

> On 2/26/06, Patrick Giraudoux

> <patrick.giraudoux at univ-fcomte.fr> wrote:

>
> Dear All,

> I would like to make partial sums (or means or any other

> function) of

> the values in intervals along a sequence (spatial transect)

> where groups

> are defined.

For

> instance:

> habitats<-rep(c("meadow","forest","meadow","pasture"),c(10,5,12,6))
observations<-rpois(length(habitats),2)
transect<-data.frame(observations=observations,habitats=habitats)

aggregate()
> is not suitable for my purpose because I want a result

> respecting the order

> of the habitats encountered although they may have

> the same name (and not

> pooling each group on each level of the factor

> created). For instance, the

> output of the ideal function

> mynicefunction() would be something

> as:

> mynicefunction(transect$observations,

> by=list(transect$habitats),sum)

> meadow 16
forest 9
meadow 21
pasture 17

and

> not

> aggregate(transect$observations,by=list(transect$habitats),sum)
> Group.1 x

> 1 forest 9
2 meadow 37
3 pasture 17

Did anybody hear about such a

> function already written in R? If no, any

> idea to make it simple and elegant

> to write?

> Cheers,

Patrick

> Giraudoux

> ______________________________________________
R-help at stat.math.ethz.ch
> mailing
list

> https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do

> read the posting
> guide!
http://www.R-project.org/posting-guide.html

>

>
>
>



From steury at biology2.wustl.edu  Sun Feb 26 17:56:18 2006
From: steury at biology2.wustl.edu (Todd Steury)
Date: Sun, 26 Feb 2006 10:56:18 -0600
Subject: [R] How to fit all possible sub-models in glm
Message-ID: <002601c63af5$90123a30$6400a8c0@Laptop>

Greetings fellow R-users,

Does anyone know of a way to fit all possible subsets of a global model
under glm? I'm looking for something similar to "regsubsets" (from package
leaps), but that can handle logistic (binomial) regression. I've searched
the archives, books, etc., but have as of yet been unsuccessful. Thanks in
advance for any help/advice.

P.s., I'm fairly new to R, so my apologies if this problem is a simple one
to answer.  
 
Todd D. Steury
Dept. of Biology
Campus Box 1229, 1 Brookings Dr.
Washington University
St. Louis, MO  63130



From spencer.graves at pdf.com  Sun Feb 26 18:09:47 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 26 Feb 2006 09:09:47 -0800
Subject: [R] Extracting error terms from an lme object
In-Reply-To: <000001c636c3$d5cd6c10$6215249e@bio90231>
References: <000001c636c3$d5cd6c10$6215249e@bio90231>
Message-ID: <4401E0DB.8090500@pdf.com>

	  Are you familiar with Pinheiro and Bates (2000) Mixed-Effects Models 
in S and S-Plus (Springer)?  This book contains detailed answers to many 
questions of this nature.

	  If this is not adequate, please submit another question after first 
reading the posting guide! "www.R-project.org/posting-guide.html". 
People who try to answer questions on this list seem more likely to 
respond to questions that are simple and understandable, and questions 
more consistent with this guide seem more likely to be simple, self 
contained, etc.

	  hope this helps.
	  spencer graves

Erlend Birkeland Nilsen wrote:

> Hi all,
> 
> I have a problem with extracting the right error terms from an lme-object.
> The fixed part of the model is quite simple (y~x1*x2, where x1 and x2 are
> factor variables with two levels), with random intercepts (random=~1|group).
> As I work with factor variables here, I would like to display this with a
> barplot (or something like that), with error bars representing the sem or sd
> of the mean values for each group (i.e. four bars). However, I have not
> figured out how to extract sem (sd) values for these means, or actually what
> would be the appropriate error terms to use here. The summary.lme function
> only provides me with the se for the parameter estimates (intercept and
> slopes) while I want to display error terms for the different levels. Could
> this be achieved by setting up an appropriate contrast matrix (or would any
> of the established contrasts methods work), or is there another way of
> getting error estimates that I could use in such a figure?
> 
> All the best, 
> 
> Erlend Nilsen
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jzhang1982 at gmail.com  Sun Feb 26 18:08:06 2006
From: jzhang1982 at gmail.com (zhang jian)
Date: Sun, 26 Feb 2006 12:08:06 -0500
Subject: [R] how to change my data to "point data set" in package "SPLANCE"?
In-Reply-To: <3f2938d50602251619v511cedd4vfe79474000cdc7bf@mail.gmail.com>
References: <3f2938d50602251619v511cedd4vfe79474000cdc7bf@mail.gmail.com>
Message-ID: <3f2938d50602260908h7281ec38o39eb87ab9d3c8cd1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060226/eb02d893/attachment.pl

From kubovy at virginia.edu  Sun Feb 26 18:35:21 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Sun, 26 Feb 2006 12:35:21 -0500
Subject: [R] How to produce notches in bwplot?
Message-ID: <9AEE0B71-CEF3-472F-B9D6-03E27D5E6158@virginia.edu>

Dear r-helpers,

tst <- data.frame(as.numeric(x <- 1:20), f <- rep(c('hi','lo'), times  
= 10))
with(tst, bwplot(f ~ x, panel = function(x, y){panel.bwplot(x, y, pch  
= '|', stats = boxplot.stats, fill = 8, varwidth = T)}))

I can't figure out from the documentation how to tell stats that I  
would like to see notches or (even bands).

Here is what I've done. (By the way, there is something about the  
style of R documentation that has --- more than once --- led me to  
these kinds of problems.)
RSiteSearch('bwplot notch') gives me nothing (as well as other  
similar queries).
xyplot {lattice} tells me about panel.bwplot, but does not illustrate  
its use.
panel.bwplot {lattice} tells me about the fact that the default  
setting of stats to boxplot.stats, but doesn't give an example.
boxplot.stats {grDevices}  tells me that the default setting is  
do.conf = TRUE, which I gathered meant that notches would be computed  
and hence plotted.

Does anyone have advice about how I could have gone about finding out  
how to do this (preferably from documentation rather than reading code)?
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From abitbol at sent.com  Sun Feb 26 21:47:55 2006
From: abitbol at sent.com (Jean-Louis Abitbol)
Date: Sun, 26 Feb 2006 21:47:55 +0100
Subject: [R] assigning differences in a loop
Message-ID: <1140986875.2492.255306013@webmail.messagingengine.com>

Dear All

I would need to generate differences between variates such as
nam1<-nam2-nam3 in the following loop:

for(i in c("13","26","38")) { 
    for (j in c("HR","PQ","QRS","QT")){
       nam1<-paste("d",j,i,sep="")
       nam2<-paste(j,i,sep=".")
       nam3<-paste(j,"0",sep=".")
       cat(nam1,"\n")
       cat(nam2,"\n")
       cat(nam3,"\n") 
      }}

for example the first difference would be dHR13<-HR.13-HR.0

I have tried

get(paste("d",j,i,sep=""))<-get(paste(j,i,sep="."))-get(paste(j,"0",sep="."))

which result in an error message such as "target of the assign does not
belong to the language" (translation from French).

I have looked in the FAQ but do not understand how to use assign in this
context.

Thanks for any help,

Kind regards, Jean-Louis
Dr. Jean-Louis Abitbol
Directeur Recherche Clinique
Trophos SA, Parc scientifique de Luminy, Case 931
Luminy Biotech Entreprises
13288 Marseille Cedex 9
Tel 04 91 82 82 73, Fax 04 91 82 82 89
Portable 06 24 47 59 34



From deepayan.sarkar at gmail.com  Sun Feb 26 22:04:00 2006
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Sun, 26 Feb 2006 15:04:00 -0600
Subject: [R] How to produce notches in bwplot?
In-Reply-To: <9AEE0B71-CEF3-472F-B9D6-03E27D5E6158@virginia.edu>
References: <9AEE0B71-CEF3-472F-B9D6-03E27D5E6158@virginia.edu>
Message-ID: <eb555e660602261304t4ef3054cv663fb0e41554075e@mail.gmail.com>

On 2/26/06, Michael Kubovy <kubovy at virginia.edu> wrote:
> Dear r-helpers,
>
> tst <- data.frame(as.numeric(x <- 1:20), f <- rep(c('hi','lo'), times
> = 10))
> with(tst, bwplot(f ~ x, panel = function(x, y){panel.bwplot(x, y, pch
> = '|', stats = boxplot.stats, fill = 8, varwidth = T)}))
>
> I can't figure out from the documentation how to tell stats that I
> would like to see notches or (even bands).
>
> Here is what I've done. (By the way, there is something about the
> style of R documentation that has --- more than once --- led me to
> these kinds of problems.)
> RSiteSearch('bwplot notch') gives me nothing (as well as other
> similar queries).
> xyplot {lattice} tells me about panel.bwplot, but does not illustrate
> its use.

Well, ?xyplot, which is the same as ?bwplot, does give you examples of
calls to bwplot. If you want, you can imagine adding
'panel=panel.bwplot' to that call (which is redundant because that's
the default). I'm not sure what other ``illustrative use'' you were
hoping for.

> panel.bwplot {lattice} tells me about the fact that the default
> setting of stats to boxplot.stats, but doesn't give an example.
> boxplot.stats {grDevices}  tells me that the default setting is
> do.conf = TRUE, which I gathered meant that notches would be computed
> and hence plotted.
>
> Does anyone have advice about how I could have gone about finding out
> how to do this (preferably from documentation rather than reading code)?

You cannot add notches using the default panel function for bwplot,
i.e. panel.bwplot. Since you found no indication in the documentation
that you could, I would say that the documentation was successful :-).

It's hard enough documenting features that are available, so you can't
really expect a list of features that are not implemented. This case
is somewhat unusual, since this is a feature available in boxplot but
missing in panel.bwplot, so I'll add a note.

Of course, you can always write your own panel function that implements notches.

Deepayan
--
http://www.stat.wisc.edu/~deepayan/



From jfontain at free.fr  Sun Feb 26 22:36:32 2006
From: jfontain at free.fr (Jean-Luc Fontaine)
Date: Sun, 26 Feb 2006 22:36:32 +0100
Subject: [R] time series prediction with genetic algorithms
Message-ID: <44021F60.6080301@free.fr>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I am just curious about this...
Would you have any experience or recommendation on a suitable R
package to start with?

Many thanks in advance,

- --
Jean-Luc Fontaine  http://jfontain.free.fr/
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.2.1 (GNU/Linux)
Comment: Using GnuPG with Fedora - http://enigmail.mozdev.org

iD8DBQFEAh9fkG/MMvcT1qQRAhBPAJ9n3NquwwKjMyJqIeYw9cWip3HpCwCgjgna
flqZZf9FpTF4sqwqh0N80S4=
=vLNA
-----END PGP SIGNATURE-----



From MSchwartz at mn.rr.com  Sun Feb 26 23:04:08 2006
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sun, 26 Feb 2006 16:04:08 -0600
Subject: [R] assigning differences in a loop
In-Reply-To: <1140986875.2492.255306013@webmail.messagingengine.com>
References: <1140986875.2492.255306013@webmail.messagingengine.com>
Message-ID: <1140991448.4506.19.camel@localhost.localdomain>

On Sun, 2006-02-26 at 21:47 +0100, Jean-Louis Abitbol wrote:
> Dear All
> 
> I would need to generate differences between variates such as
> nam1<-nam2-nam3 in the following loop:
> 
> for(i in c("13","26","38")) { 
>     for (j in c("HR","PQ","QRS","QT")){
>        nam1<-paste("d",j,i,sep="")
>        nam2<-paste(j,i,sep=".")
>        nam3<-paste(j,"0",sep=".")
>        cat(nam1,"\n")
>        cat(nam2,"\n")
>        cat(nam3,"\n") 
>       }}
> 
> for example the first difference would be dHR13<-HR.13-HR.0
> 
> I have tried
> 
> get(paste("d",j,i,sep=""))<-get(paste(j,i,sep="."))-get(paste(j,"0",sep="."))
> 
> which result in an error message such as "target of the assign does not
> belong to the language" (translation from French).
> 
> I have looked in the FAQ but do not understand how to use assign in this
> context.
> 
> Thanks for any help,

Presumably, the error is referring to the fact that the target of the
subtraction operation does not yet exist. Thus, get() is returning an
error.

Lacking your data, which I presume is ECG measurement information from
the acronyms in use, you could do something like this:

for(i in c("13","26","38")) { 
    for (j in c("HR","PQ","QRS","QT")){
       nam1<-paste("d",j,i,sep="")
       nam2<-paste(j,i,sep=".")
       nam3<-paste(j,"0",sep=".")
       eval(parse(text = paste(nam1, " <- ", nam2, " - ", nam3,  "\n")))
      }}

Note that the result of the last line in the loop is a series of
expressions, which are then evaluated:

  expression(dHR13 <- HR.13 - HR.0)
  expression(dPQ13 <- PQ.13 - PQ.0)
  expression(dQRS13 <- QRS.13 - QRS.0)
  expression(dQT13 <- QT.13 - QT.0)
  expression(dHR26 <- HR.26 - HR.0)
  expression(dPQ26 <- PQ.26 - PQ.0)
  expression(dQRS26 <- QRS.26 - QRS.0)
  expression(dQT26 <- QT.26 - QT.0)
  expression(dHR38 <- HR.38 - HR.0)
  expression(dPQ38 <- PQ.38 - PQ.0)
  expression(dQRS38 <- QRS.38 - QRS.0)
  expression(dQT38 <- QT.38 - QT.0)

You can see this if you replace that last line with:

  print(parse(text = paste(nam1, " <- ", nam2, " - ", nam3,  "\n")))


However, I can't help but think that there is an easier way here. If
your data might be in a matrix 'mat' (or could be put into this format),
with the following example structure:

set.seed(1)
mat <- matrix(sample(16), 4, 4)
colnames(mat) <- c("0", "13","26","38")
rownames(mat) <- c("HR","PQ","QRS","QT")

> mat
     0 13 26 38
HR   5  3 14 13
PQ   6 10  1  8
QRS  9 11  2  4
QT  12 15  7 16


You can then use:

> mat[, 2:4] - mat[, 1]
    13 26 38
HR  -2  9  8
PQ   4 -5  2
QRS  2 -7 -5
QT   3 -5  4


which creates a matrix with the results of subtracting cols 2:4 from col
1.

HTH,

Marc Schwartz



From MSchwartz at mn.rr.com  Sun Feb 26 23:20:40 2006
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sun, 26 Feb 2006 16:20:40 -0600
Subject: [R] assigning differences in a loop
In-Reply-To: <1140991448.4506.19.camel@localhost.localdomain>
References: <1140986875.2492.255306013@webmail.messagingengine.com>
	<1140991448.4506.19.camel@localhost.localdomain>
Message-ID: <1140992440.4506.23.camel@localhost.localdomain>

On Sun, 2006-02-26 at 16:04 -0600, Marc Schwartz wrote:

> Lacking your data, which I presume is ECG measurement information from
> the acronyms in use, you could do something like this:
> 
> for(i in c("13","26","38")) { 
>     for (j in c("HR","PQ","QRS","QT")){
>        nam1<-paste("d",j,i,sep="")
>        nam2<-paste(j,i,sep=".")
>        nam3<-paste(j,"0",sep=".")
>        eval(parse(text = paste(nam1, " <- ", nam2, " - ", nam3,  "\n")))
>       }}

Quick correction here. I accidentally left in the 'newline' in the last
line above. This is a remnant of testing with print(). It should be:

for(i in c("13","26","38")) { 
    for (j in c("HR","PQ","QRS","QT")){
       nam1<-paste("d",j,i,sep="")
       nam2<-paste(j,i,sep=".")
       nam3<-paste(j,"0",sep=".")
       eval(parse(text = paste(nam1, " <- ", nam2, " - ", nam3)))
      }}


Marc



From kubovy at virginia.edu  Mon Feb 27 01:47:08 2006
From: kubovy at virginia.edu (Michael Kubovy)
Date: Sun, 26 Feb 2006 19:47:08 -0500
Subject: [R] How to produce notches in bwplot?
In-Reply-To: <eb555e660602261304t4ef3054cv663fb0e41554075e@mail.gmail.com>
References: <9AEE0B71-CEF3-472F-B9D6-03E27D5E6158@virginia.edu>
	<eb555e660602261304t4ef3054cv663fb0e41554075e@mail.gmail.com>
Message-ID: <5DEBA34D-B05F-44C8-892F-C61C90BF2A3A@virginia.edu>

Deepayan,

Thanks so much for the clarification(i.e., that one cannot produce  
notches in boxplots using bwplot). I hope that I did not come across  
as being critical of the superb and selfless work that you have done.
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From pradeep.gunda at gmail.com  Mon Feb 27 02:39:32 2006
From: pradeep.gunda at gmail.com (Pradeep Gunda)
Date: Sun, 26 Feb 2006 20:39:32 -0500
Subject: [R] Query on multivariate time series
Message-ID: <25ef638b0602261739n64d39ad8p3d2a15d1cb14977e@mail.gmail.com>

Hi,

Could anyone inform how to perform multi-variate auto regression using
the past 't' values for regression in R. I have looked at ARMA
provided by DES library and mvr provided by PLS library but could not
match them to my requirements.

Specifically, I want the following

Say I have attributes a1-a4. and the regression equation is as follows:

a4(t) = alpha1*a1(t-X)+alpha2*a2(t-X)+alpha3*a3(t-X)+alpha4*a1(t-X-1)+alpha5*a2(t-X-1)...
             alphan*a3(t-2X)

where X is the window length of the time series.

Thanks,
Pradeep



From lebouton at msu.edu  Sun Feb 26 18:57:16 2006
From: lebouton at msu.edu (Joseph LeBouton)
Date: Sun, 26 Feb 2006 11:57:16 -0600
Subject: [R] changing degrees of freedom in summary.lm()
Message-ID: <4401EBFC.9020102@msu.edu>

Hello all,

I'm trying to do a nested linear model with a dataset that incorporates 
an observation for each of several classes within each of several plots. 
  I have 219 plots, and 17 classes within each plot.

data.frame has columns "plot","class","age","dep.var"

With lm(dep.var~class*age),

The summary(lm) function returns t-test and F-test values evaluated as 
though I were working with 219*17-17=3706 degrees of freedom, when in 
fact I have but 219-17=202 df.  I'm probably being dense on this one, 
but is there a way I can set df to the proper number so that summary.lm 
does the correct significance test?  Or should I be doing an entirely 
different anlaysis?

Thanks,

-jlb
-- 
************************************
Joseph P. LeBouton
Forest Ecology PhD Candidate
Department of Forestry
Michigan State University
East Lansing, Michigan 48824

Office phone: 517-355-7744
email: lebouton at msu.edu



From hodgess at gator.dt.uh.edu  Mon Feb 27 07:02:11 2006
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Mon, 27 Feb 2006 00:02:11 -0600
Subject: [R]  install RPM file on Redhat
Message-ID: <200602270602.k1R62Buc006400@gator.dt.uh.edu>

Dear R People:

I downloaded the RPM for Red Hat Linux.

How do I install this, please?  When I looked 
at the R Intallation manual, it seemed to be
referring to installing from source.

Thanks in advance!

Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu



From ligges at statistik.uni-dortmund.de  Mon Feb 27 08:38:28 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 27 Feb 2006 08:38:28 +0100
Subject: [R] install RPM file on Redhat
In-Reply-To: <200602270602.k1R62Buc006400@gator.dt.uh.edu>
References: <200602270602.k1R62Buc006400@gator.dt.uh.edu>
Message-ID: <4402AC74.9040601@statistik.uni-dortmund.de>

Erin Hodgess wrote:
> Dear R People:
> 
> I downloaded the RPM for Red Hat Linux.
> 
> How do I install this, please?  When I looked 
> at the R Intallation manual, it seemed to be
> referring to installing from source.
> 
> Thanks in advance!

rpm installation is an OS issue:

1. Open http://www.google.com
2. Type "RedHat rpm install"
3. Click "I'm Feeling Lucky"

Uwe Ligges



> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jzhang1982 at gmail.com  Sun Feb 26 01:19:37 2006
From: jzhang1982 at gmail.com (zhang jian)
Date: Sat, 25 Feb 2006 19:19:37 -0500
Subject: [R] how to change my data to "point data set" in package "SPLANCE"?
Message-ID: <3f2938d50602251619v511cedd4vfe79474000cdc7bf@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060225/9ed70e81/attachment.pl

From backer at psych.uib.no  Mon Feb 27 09:08:41 2006
From: backer at psych.uib.no (Tom Backer Johnsen)
Date: Mon, 27 Feb 2006 09:08:41 +0100
Subject: [R] Standardized regression weights with lm()
Message-ID: <5.2.0.8.2.20060227085914.0203c450@alf.uib.no>

Being a newbie in respect to the use of R (but more experienced in respect 
to SPSS and Statistica), I am somewhat surprised at one thing.  When using 
summary() to output the results from lm() you get what I would expect, with 
one exception, I am missing the standardized regression weights (beta's).

Of course, it is possible to standardize all variables involved to get this 
information, but that is a rather brute approach.

Is there a simpler approach I can show my students?

Tom

+----------------------------------------------------------------+
| Tom Backer Johnsen, Psychometrics Unit,  Faculty of Psychology |
| University of Bergen, Christies gt. 12, N-5015 Bergen,  NORWAY |
| Tel : +47-5558-9185                        Fax : +47-5558-9879 |
| Email : backer at psych.uib.no    URL : http://www.galton.uib.no/ |
+----------------------------------------------------------------+



From andza at osi.lv  Mon Feb 27 09:28:27 2006
From: andza at osi.lv (Andris Jankevics)
Date: Mon, 27 Feb 2006 10:28:27 +0200
Subject: [R] install RPM file on Redhat
In-Reply-To: <200602270602.k1R62Buc006400@gator.dt.uh.edu>
References: <200602270602.k1R62Buc006400@gator.dt.uh.edu>
Message-ID: <200602271028.27173.andza@osi.lv>

Hello, 
As a root users type a command like this:
rpm -iU R-2.2.1-1.rh4AS.i686.rpm

On Pirmdiena, 27. Februris 2006 08:02, Erin Hodgess wrote:
> Dear R People:
>
> I downloaded the RPM for Red Hat Linux.
>
> How do I install this, please?  When I looked
> at the R Intallation manual, it seemed to be
> referring to installing from source.
>
> Thanks in advance!
>
> Sincerely,
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: hodgess at gator.uhd.edu
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From comtech.usa at gmail.com  Mon Feb 27 10:00:06 2006
From: comtech.usa at gmail.com (Michael)
Date: Mon, 27 Feb 2006 01:00:06 -0800
Subject: [R] question about Principal Component Analysis in R?
Message-ID: <b1f16d9d0602270100m59f2b925s39715e0022a231de@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/1156970d/attachment.pl

From Roger.Bivand at nhh.no  Mon Feb 27 10:18:27 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 27 Feb 2006 10:18:27 +0100 (CET)
Subject: [R] how to change my data to "point data set" in package
	"SPLANCE"?
In-Reply-To: <3f2938d50602251619v511cedd4vfe79474000cdc7bf@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0602271003070.699-100000@reclus.nhh.no>

On Sat, 25 Feb 2006, zhang jian wrote:

> Hi!
> I want to use the package "SPLANCE" to do Ripley's K analysis
> I have a basic question about the package.
> I try to find how to do it, but I cannot.

You asked the same question with reference to the spatial package 
associated with MASS last week, and have now asked this one twice. I 
replied to your question about spatial, but have not seen any comment 
from you on that solution. Perhaps your best choice is to study the 
literature of the subject more closely, next to try to learn something of 
how data are represented in R, and when you have done that, and if you 
still have difficulties, ask again. 

Note that the help pages do explain carefully how the functions should be
used, with examples that are documented in the cited references. Please do
try to use the documentation provided with these packages.

Hint: it appears that qumo is a data frame. You can extract the 
coordinates in many ways. Data frames are also seen as lists, and since 
your data frame has coordinates named "x" and "y", the splancs function 
as.points() will work:

library(splancs)
xy <- data.frame(x=rnorm(50), y=rnorm(50))
pxy <- as.points(xy)
plot(pxy)
plot(khat(pxy, sbox(pxy), s=seq(0,2,0.1)), type="l")


> I hope you can help me.
> I donot know how to change my data form to "point data set".
> my data form is:
> > qumo[1:5,]
>      code species  dbh     x      y   tag status branch
> 223 10312    QUMO 54.5  7.83  44.80 10306  alive      0
> 252 10331    QUMO 48.8 11.44  51.05 10333  alive      0
> 346 10424    QUMO 67.0 14.30  69.68 10443  alive      0
> 395 10511    QUMO  7.8  3.10  83.83 10503  alive      0
> 491 10613    QUMO 57.1  9.12 107.00 10607  alive      0
> "x""y" is the coordinate.
> 
> And I think "xl   xu   yl   yu" equl to  "0  500  0  500"
> it is a square.
> 
> Can you help me?
> Thank you very much.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From jgarcia at ija.csic.es  Mon Feb 27 11:10:54 2006
From: jgarcia at ija.csic.es (javier garcia-pintado)
Date: Mon, 27 Feb 2006 11:10:54 +0100
Subject: [R] R script autoload at startup
In-Reply-To: <Pine.LNX.4.64.0602242008050.26876@gannet.stats.ox.ac.uk>
References: <7.0.0.16.0.20060224105224.01f27a90@ija.csic.es>
	<200602242018.43971.jgarcia@ija.csic.es>
	<Pine.LNX.4.64.0602242008050.26876@gannet.stats.ox.ac.uk>
Message-ID: <200602271110.54532.jgarcia@ija.csic.es>

Thank you very much Prof Brian R,

I also wonder how I missed that.

Anyway, In my .Rprofile file:

>.First <- function() cat ("\n Welcome to R!\n")

works perfectly, while:

>.First <- function() winMenuAdd("Newmenu")

give me the answer:

"Error in .First(): couldn't find function "winMenuAdd"

I just can add the new menu, and create the menu entries later, calling a 
source() that adds the menus.

Perhaps the functions to add menus to the RGUI are called after the .RProfile 
is red?

To add it via the .Rprofile would be perfect, but anywat, to be able to create 
the menu calling manually a source after the GUI is completely started is 
good enough for me.

Best regards,

Javier

El Viernes, 24 de Febrero de 2006 21:12, escribi:
> See ?Startup for how to do this via .Rprofile or etc/Rprofile.site.
>
> The answer to your second question is that RGui is not written in tcltk
> (can't you tell from the speed with which it works?), but there are
> documented R functions for you to add menu items, such as winMenuAdd.
>
> (I do wonder how you missed these in the searches for help, as all the
> terms I tried found the answers.)
>
> On Fri, 24 Feb 2006, javier garcia-pintado wrote:
> > Yes.
> >
> > It would be nice and useful to save the users the task of loading the
> > source R-TcltK code everytime they start up R. Because, in principle they
> > are going to use R just for this. But the R GUI must remains open
> >
> > Javier
> > -----------------------
> >
> > El Viernes, 24 de Febrero de 2006 16:39, Frank Samuelson escribi:
> >> Do you need the user to interact with the Rgui after the code has run?
> >>
> >> -Frank
> >>
> >> Javier Garcia-Pintado wrote:
> >>> Hello;
> >>> I'm now using mainly R for windows, mainly because I'm writing a
> >>> tcl/Tk interface for some people, and I've got two questions. I'm an
> >>> absolute beginner with tctk or tcktk use under the R GUI.
> >>>
> >>> 1) Is it posible to create a shorcut that launchs the R GUI and
> >>> automatically reads the "source code" of the tcl/tk script to also
> >>> launch the tcltk interface?
> >>>
> >>> 2) Is the RGUI programmed with tcltk? In this case, is it possible
> >>> for an user like me to create a menu entry at the R GUI to call the
> >>> source code in this R/tcl/Tk script?
> >>>
> >>> Any of the two options would be very good for us.
> >>>
> >>> Thanks and best regards,
> >>>
> >>> Javier

-- 
javier garca-pintado



From comtech.usa at gmail.com  Mon Feb 27 11:32:54 2006
From: comtech.usa at gmail.com (Michael)
Date: Mon, 27 Feb 2006 02:32:54 -0800
Subject: [R] how to use the basis matrix of "ns" in R? really confused by
	multi-dim spline filtering?
Message-ID: <b1f16d9d0602270232ye0d8538rabed2c61f8f3e3a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/dbfe7957/attachment.pl

From m.blizinski at wit.edu.pl  Mon Feb 27 11:50:12 2006
From: m.blizinski at wit.edu.pl (Maciej =?iso-8859-2?Q?Blizi=F1ski?=)
Date: Mon, 27 Feb 2006 11:50:12 +0100
Subject: [R] Fuzzy version of prop.test
Message-ID: <1141037412.15649.23.camel@localhost.localnet>

Is there such thing as a fuzzy version of prop.test?

Let's say I have the output from cmeans, i.e. set of clusters. Every
object belongs to each cluster "in a fuzzy way".

object cluster1 group dependentvar
obj1       0.21     A            1
obj2       0.84     A            0
obj3       0.90     B            1
obj4       0.02     B            0

Having data in above form, is it possible to perform (something like) a
prop.test against groups A and B, inside cluster1? Since every object
belongs to cluster1 "to some degree", every observation should apply to
the test "to some degree". Is there already a test in R that does that?
Can you recommend a relevant reading?

-- 
Maciej Blizi??ski <m.blizinski at wit.edu.pl>
http://automaciej.blogspot.com/



From hb at maths.lth.se  Mon Feb 27 12:03:00 2006
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Mon, 27 Feb 2006 12:03:00 +0100
Subject: [R] Adding header lines to a dataframe that is exported using
	write.csv
In-Reply-To: <e40d78ce0602251020p32698ae4r8c1b0e5736a07c64@mail.gmail.com>
References: <e40d78ce0602251020p32698ae4r8c1b0e5736a07c64@mail.gmail.com>
Message-ID: <59d7961d0602270303w663d4bcdgba060f0fd8e66b97@mail.gmail.com>

Just a tips: When you add headers to tabulate files like yours, it is
convenient to start each header line with a '#' (like an R comment),
because then read.table() will not complain about the header lines. 
It is easy to strip the '#' off the header lines, i.e. grep("^#", "",
hlines) before further parsing.

/Henrik

On 2/25/06, Mark <mtb954 at gmail.com> wrote:
> I would like to export a dataframe to a .csv using:
>
> >write.csv(dataframe,"dataframe.csv")
>
> but I need to add four "header" lines to the csv that are not part of
> the dataframe (which itself has a line of column headers).
>
> The difficulty (for me, at least!) lies in the requirement that
> certain elements of the header (X, Y and the number of "Q"s - please
> see example below) must be defined based on the number of rows and
> columns in the dataframe, which vary depending on the input file.
>
> Here's what the 3 .csv header lines should look like, followed by a
> number of dataframe rows (i.e., these lines are not R code, but are
> what R will produce).
>
> X, plots ,,,, #where X=number of rows in the dataframe
> Y, species,,,, #where Y=number of columns in the dataframe
> ,Q,Q,Q,Q,Q #where the number of Qs=the number of columns in the dataframe
>
> Those 3 .csv header lines would be followed by dataframe, which
> consists of one row containing column headers and X "data" rows:
>
> ,spec1,spec2,spec3,sp3c4,spec5 #these are the dataframe's column headers
> plot1,15.84,0,0,792,7 #this is an example "data" row
>
> In case the above is unclear, I have also attached a small .csv as an
> example of what the output should look like.
>
> Thank you. Mark
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>


--
Henrik Bengtsson
Mobile: +46 708 909208 (+1h UTC)



From sdavis2 at mail.nih.gov  Mon Feb 27 12:32:20 2006
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 27 Feb 2006 06:32:20 -0500
Subject: [R] Adding header lines to a dataframe that is exported using
 write.csv
In-Reply-To: <59d7961d0602270303w663d4bcdgba060f0fd8e66b97@mail.gmail.com>
Message-ID: <C0284D74.6930%sdavis2@mail.nih.gov>




On 2/27/06 6:03 AM, "Henrik Bengtsson" <hb at maths.lth.se> wrote:

> Just a tips: When you add headers to tabulate files like yours, it is
> convenient to start each header line with a '#' (like an R comment),
> because then read.table() will not complain about the header lines.
> It is easy to strip the '#' off the header lines, i.e. grep("^#", "",
> hlines) before further parsing.

You can also use the skip argument to read.table() to skip an arbitrary
number of lines of header information.

Sean



From vmuggeo at dssm.unipa.it  Mon Feb 27 13:17:59 2006
From: vmuggeo at dssm.unipa.it (vito muggeo)
Date: Mon, 27 Feb 2006 13:17:59 +0100
Subject: [R] how to use the basis matrix of "ns" in R? really confused
 by	multi-dim spline filtering?
In-Reply-To: <b1f16d9d0602270232ye0d8538rabed2c61f8f3e3a@mail.gmail.com>
References: <b1f16d9d0602270232ye0d8538rabed2c61f8f3e3a@mail.gmail.com>
Message-ID: <4402EDF7.6000302@dssm.unipa.it>

Dear Micheal,

 > the output of the "ns" function in R is "basis matrix", but then
Yes you are right, the output of the ns(x, df) is the basis matrix of a 
natural cubic spline with df degrees of freedom. See ?ns (in package 
splines) on how to specify df or knots or ..

Fitting y~ns(x,df) yields a smooth curve given by a linear combination 
of the basis functions (the single colums of the basis matrix) by the 
estimated coefficients (returned by the fitted model).

As far as I know, a tensor product is usually employed to 
multidimensional smoothing and the multidimensional basis is formed via 
the kronecker product of the marginal bases.

Finally, last but not least: Probably you need some statistical 
backaground on spline fitting..
Please, read some statistical papers/books on such topic (for instance 
see references in packages splines, mgcv)

best,
vito

Michael wrote:
> Hi all,
> 
> Could anybody recommend some easy-to-understand and example based
> notes/tutorials on how to use cubic splines to do filtering on
> multi-dimension data?
> 
> I am confused by the 1-dimensional case, and more confused by
> multi-dimensional case.
> 
> I found all the books suddenly become very abstract when it comes to this
> subject.
> 
> They don't provide examples in R or Splus at all.
> 
> Specifically, I don't know how to provide data "x" to the "ns" function in
> R,
> 
> and I don't understand what should be the output matrix, and how to use the
> output matrix to "filter" data?
> 
> Books mention about basis matrix, design matrix, model matrix, data matrix,
> etc. I got lost.
> 
> I presume the output of the "ns" function in R is "basis matrix", but then
> how do I use it?  How to form tensor-product?
> 
> I don't understand it at all.
> 
> Please help me!
> 
> Thank you very much!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
====================================
Vito M.R. Muggeo
Dip.to Sc Statist e Matem `Vianelli'
Universit?? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 6626240
fax: 091 485726/485612



From jmb56 at leicester.ac.uk  Mon Feb 27 13:49:14 2006
From: jmb56 at leicester.ac.uk (Bowden, J.M.)
Date: Mon, 27 Feb 2006 12:49:14 -0000
Subject: [R] gauss.hermite function
Message-ID: <286C9166197E0C44B94FF9762B27DAC70771E70B@sumac.cfs.le.ac.uk>

Hi,

I am trying to find a function that returns simply the weights and
points of an n point gauss hermite integeration, so that I can use them
to fit a non-standard likelihood.

I have found some documentation for the function 'gauss.hermite' written
by jim lindley, but can't find the actual binary on CRAN


I'm aware there are lots of functions like glmm, glmmML etc to fit mixed
models, that use gh integration but all I require is the points and
weights.


Does anyone know if there is a function that is downloadable from CRAN
that will do this


Thanks in advance


Jack Bowden

PhD student, Leicester



From ripley at stats.ox.ac.uk  Mon Feb 27 15:31:59 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 27 Feb 2006 14:31:59 +0000 (GMT)
Subject: [R] R script autoload at startup
In-Reply-To: <200602271110.54532.jgarcia@ija.csic.es>
References: <7.0.0.16.0.20060224105224.01f27a90@ija.csic.es>
	<200602242018.43971.jgarcia@ija.csic.es>
	<Pine.LNX.4.64.0602242008050.26876@gannet.stats.ox.ac.uk>
	<200602271110.54532.jgarcia@ija.csic.es>
Message-ID: <Pine.LNX.4.64.0602271429480.12121@gannet.stats.ox.ac.uk>

On Mon, 27 Feb 2006, javier garcia-pintado wrote:

> Thank you very much Prof Brian R,
> I also wonder how I missed that.
> Anyway, In my .Rprofile file:
>> .First <- function() cat ("\n Welcome to R!\n")
> works perfectly, while:
>> .First <- function() winMenuAdd("Newmenu")
> give me the answer:
> "Error in .First(): couldn't find function "winMenuAdd"
> I just can add the new menu, and create the menu entries later, calling a source() that adds the menus.
> Perhaps the functions to add menus to the RGUI are called after the .RProfile is red?

> To add it via the .Rprofile would be perfect, but anywat, to be able to 
> create the menu calling manually a source after the GUI is completely 
> started is good enough for me.

You need to specify the package at that point, as when .First is run the 
default packages are not yet loaded (see ?Startup for the precise 
description).  E.g. (untested, as I am using Linux)

.First <- function() utils::winMenuAdd("Newmenu")


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Feb 27 15:35:09 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 27 Feb 2006 14:35:09 +0000 (GMT)
Subject: [R] gauss.hermite function
In-Reply-To: <286C9166197E0C44B94FF9762B27DAC70771E70B@sumac.cfs.le.ac.uk>
References: <286C9166197E0C44B94FF9762B27DAC70771E70B@sumac.cfs.le.ac.uk>
Message-ID: <Pine.LNX.4.64.0602271433020.12121@gannet.stats.ox.ac.uk>

On Mon, 27 Feb 2006, Bowden, J.M. wrote:

> I am trying to find a function that returns simply the weights and
> points of an n point gauss hermite integeration, so that I can use them
> to fit a non-standard likelihood.
>
> I have found some documentation for the function 'gauss.hermite' written
> by jim lindley, but can't find the actual binary on CRAN
>
>
> I'm aware there are lots of functions like glmm, glmmML etc to fit mixed
> models, that use gh integration but all I require is the points and
> weights.
>
>
> Does anyone know if there is a function that is downloadable from CRAN
> that will do this

I think you mean Jim Lindsey, whose packages are not on CRAN but at an
address given in the R FAQ (and has changed from time to time).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From lgautier at gmail.com  Mon Feb 27 15:38:12 2006
From: lgautier at gmail.com (Laurent Gautier)
Date: Mon, 27 Feb 2006 22:38:12 +0800
Subject: [R] prepared query with RODBC ?
Message-ID: <27d1e6020602270638u55cf0687na67c76a78b6cdf66@mail.gmail.com>

Dear List,

Would anyone know how to perform prepared queries with ROBC ?
I had a shot with some of the internal (non-exported) functions of the package
but ended up with a segfault, so I prefer asking around before
experimenting further...

Thanks,



Laurent



From tsfeldman at noble.org  Mon Feb 27 15:52:47 2006
From: tsfeldman at noble.org (Feldman, Tracy)
Date: Mon, 27 Feb 2006 08:52:47 -0600
Subject: [R] question about lmer--different answers from different versions
	of R?
Message-ID: <497D588A106806408FB0792E4E9A16588369D3@mail2.noble.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/a15a3901/attachment.pl

From c.gold at magnet.at  Mon Feb 27 16:15:04 2006
From: c.gold at magnet.at (Christian Gold)
Date: Mon, 27 Feb 2006 16:15:04 +0100
Subject: [R] repeated measures ANOVA
Message-ID: <44031778.CF736D1A@magnet.at>

Dear list members:

I have the following data:
group <- rep(rep(1:2, c(5,5)), 3)
time <- rep(1:3, rep(10,3))
subject <- rep(1:10, 3)
p.pa <- c(92, 44, 49, 52, 41, 34, 32, 65, 47, 58, 94, 82, 48, 60, 47,
46, 41, 73, 60, 69, 95, 53, 44, 66, 62, 46, 53, 73, 84, 79)
P.PA <- data.frame(subject, group, time, p.pa)

The ten subjects were randomly assigned to one of two groups and
measured three times. (The treatment changes after the second time
point.)

Now I am trying to find out the most adequate way for an analysis of
main effects and interaction. Most social scientists would call this
analysis a repeated measures ANOVA, but I understand that mixed-effects
model is a more generic term for the same analysis. I did the analysis
in four ways (one in SPSS, three in R):

1. In SPSS I used "general linear model, repeated measures", defining a
"within-subject factor" for the three different time points. (The data
frame is structured differently in SPSS so that there is one line for
each subject, and each time point is a separate variable.)
Time was significant.

2. Analogous to what is recommended in the first chapter of Pinheiro &
Bates' "Mixed-Effects Models" book, I used
library(nlme)
summary(lme ( p.pa ~ time * group, random = ~ 1 | subject))
Here, time was NOT significant. This was surprising not only in
comparison with the result in SPSS, but also when looking at the graph:
interaction.plot(time, group, p.pa)

3. I then tried a code for the lme4 package, as described by Douglas
Bates in RNews 5(1), 2005 (p. 27-30). The result was the same as in 2.
library(lme4)
summary(lmer ( p.pa ~ time * group + (time*group | subject), P.PA ))

4. The I also tried what Jonathan Baron suggests in his "Notes on the
use of R for psychology experiments and questionnaires" (on CRAN):
summary( aov ( p.pa ~ time * group + Error(subject/(time * group)) ) ) 
This gives me yet another result.

So I am confused. Which one should I use?

Thanks

Christian




--
____________________________
Dr. Christian Gold, PhD
http://www.hisf.no/~chrisgol



From kviel at darwin.sfbr.org  Mon Feb 27 17:27:15 2006
From: kviel at darwin.sfbr.org (Kevin Viel)
Date: Mon, 27 Feb 2006 10:27:15 -0600
Subject: [R] Read SAS .sd2 file into R?
References: <e40d78ce0602241352n113eda71l64d90f0c952efeb0@mail.gmail.com>
	<x21wxso0w5.fsf@turmalin.kubism.ku.dk>
Message-ID: <44032863.6000403@darwin.sfbr.org>



Peter Dalgaard wrote:
> "mtb954 mtb954" <mtb954 at gmail.com> writes:
> 
> 
>>Does anyone know how to import a SAS .sd2 file into R? I can't see
>>anything in library(foreign).
> 
> 
> The SAS dataset file formats are not publicly available. You need
> either SAS itself (on a Windows machine) or a specialized tool like
> DBMS/Copy to converti it.


Peter,

   There may be another way, though I have yet to explore it.

The SAS System Viewer is free and you may distribute it royalty free:

http://www.sas.com/apps/demosdownloads/sassysview_PROD_8.2_sysdep.jsp?packageID=000176


"Files Supported by the SAS System Viewer
The SAS System Viewer lets you view the following types of SAS files:
Read Only
* 7.00 Data Sets created under the windows environment (sas7bdat, sd7, 
sd2, ssd,
ssd0x, saseb$data)
* 6.06 - 6.12 Catalogs - Directory Information Only (sc2, sct, sct0x,
saseb$catalog)
* 3.2.2 JMP(r) Data Sets - Macintosh and Windows (jmp)
* 6.12 MDDB - Multi-dimensional Data Base Files (sm2)
* SAS Transport Files (stx, xpt)
* SAS Log Files (log)
* SAS List Files (lst)

Read and Write Enabled
* Comma Delimited Files (csv)
* Space Delimited Files (prn)
* Text Based Files (sas, dat, cfg, html)"

Whether you can copy and paste will be key.

Regards,

Kevin

----------------------------------------------------------------------
Kevin Viel
Department of Genetics                  e-mail: kviel at darwin.sfbr.org
Southwest Foundation                    phone:  (210)258-9884
P.O. Box 760549                         fax:    (210)258-9444
San Antonio, TX 78245-0549

Kevin Viel
PhD Candidate
Department of Epidemiology
Rollins School of Public Health
Emory University
Atlanta, GA 30322



From jgarcia at ija.csic.es  Mon Feb 27 17:35:08 2006
From: jgarcia at ija.csic.es (javier garcia-pintado)
Date: Mon, 27 Feb 2006 17:35:08 +0100
Subject: [R] TclTk library loading (whole version) Linux
Message-ID: <44032A3C.8040709@ija.csic.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/88f3c6f8/attachment.pl

From spencer.graves at pdf.com  Mon Feb 27 17:59:09 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 27 Feb 2006 08:59:09 -0800
Subject: [R] changing degrees of freedom in summary.lm()
In-Reply-To: <4401EBFC.9020102@msu.edu>
References: <4401EBFC.9020102@msu.edu>
Message-ID: <44032FDD.2090909@pdf.com>

	  I believe your difficulties will be greatly enlightened by using 
either lme in library(nlme) or lmer associated with the lme4 package. 
Essential documentation is Pinheiro and Bates (2000) Mixed-Effects 
Models in S and S-Plus (Springer).

	  hope this helps.
	  spencer graves

Joseph LeBouton wrote:
> Hello all,
> 
> I'm trying to do a nested linear model with a dataset that incorporates 
> an observation for each of several classes within each of several plots. 
>   I have 219 plots, and 17 classes within each plot.
> 
> data.frame has columns "plot","class","age","dep.var"
> 
> With lm(dep.var~class*age),
> 
> The summary(lm) function returns t-test and F-test values evaluated as 
> though I were working with 219*17-17=3706 degrees of freedom, when in 
> fact I have but 219-17=202 df.  I'm probably being dense on this one, 
> but is there a way I can set df to the proper number so that summary.lm 
> does the correct significance test?  Or should I be doing an entirely 
> different anlaysis?
> 
> Thanks,
> 
> -jlb



From spencer.graves at pdf.com  Mon Feb 27 18:00:14 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 27 Feb 2006 09:00:14 -0800
Subject: [R] gauss.hermite function
In-Reply-To: <Pine.LNX.4.64.0602271433020.12121@gannet.stats.ox.ac.uk>
References: <286C9166197E0C44B94FF9762B27DAC70771E70B@sumac.cfs.le.ac.uk>
	<Pine.LNX.4.64.0602271433020.12121@gannet.stats.ox.ac.uk>
Message-ID: <4403301E.1030400@pdf.com>

	  Have you also considered "gauss.quad" or "gauss.quad.prob" in the 
"statmod" package?

	  spencer graves

Prof Brian Ripley wrote:
> On Mon, 27 Feb 2006, Bowden, J.M. wrote:
> 
> 
>>I am trying to find a function that returns simply the weights and
>>points of an n point gauss hermite integeration, so that I can use them
>>to fit a non-standard likelihood.
>>
>>I have found some documentation for the function 'gauss.hermite' written
>>by jim lindley, but can't find the actual binary on CRAN
>>
>>
>>I'm aware there are lots of functions like glmm, glmmML etc to fit mixed
>>models, that use gh integration but all I require is the points and
>>weights.
>>
>>
>>Does anyone know if there is a function that is downloadable from CRAN
>>that will do this
> 
> 
> I think you mean Jim Lindsey, whose packages are not on CRAN but at an
> address given in the R FAQ (and has changed from time to time).
>



From pzs6 at CDC.GOV  Mon Feb 27 18:02:31 2006
From: pzs6 at CDC.GOV (Smith, Phil)
Date: Mon, 27 Feb 2006 12:02:31 -0500
Subject: [R] help with step()
Message-ID: <2554377D323C9A40BD69956059FD05491136B101@mnip1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/2d6be4b4/attachment.pl

From p.dalgaard at biostat.ku.dk  Mon Feb 27 18:24:52 2006
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Feb 2006 18:24:52 +0100
Subject: [R] TclTk library loading (whole version) Linux
In-Reply-To: <44032A3C.8040709@ija.csic.es>
References: <44032A3C.8040709@ija.csic.es>
Message-ID: <x23bi4k93v.fsf@turmalin.kubism.ku.dk>

javier garcia-pintado <jgarcia at ija.csic.es> writes:

> Hello;
> 
> Well, I'm afraid this is the second related problem I report in two days
> (I'm sorry for this)
> 
> I've programmed a tcltk interface for a model and it includes a
> comboBox. The comboBox widget comes with the "BWidgets" library of Tcl/Tk.
> 
>  It works all perfectly with the windows R GUI (with the help of Prof.
> B. Ripley), following the advices in ?Startup, but I would like that it
> also could work under Linux. I've got a complete TclTk8.4 installed and
> also BWidgets, and I could swear that the complete Tcl libraries could
> be loaded at least once, because I saw a message like "Tcl 1.7" or
> similar under R.
> 
> Now I don't receive the message anymore and it cannot find BWidgets
> under R. So I'm not even sure that I'm loading the whole tclTk Library
> anymore(instead of the subset that comes along with R)
> 
> I've got libtcl8.4.so and libtk8.4.so in /usr/lib
> My .Renviron file contains:
> 
> MY_TCLTK=yes
> TCL_LIBRARY=/usr/lib/tcl8.4
> 
> an in my R session:
> ------------------------------
> > Sys.getenv("MY_TCLTK")
> MY_TCLTK
>    "yes"
> > Sys.getenv("TCL_LIBRARY")
>       TCL_LIBRARY
> "/usr/lib/tcl8.4"
> > tclRequire("BWidgets")
> [1] FALSE
> Warning message:
> Tcl package 'BWidgets' not found in: tclRequire("BWidgets")
> ---------------------------------
> 
> Please, some how uses BWidgets could tell if I'm doing something wrong
> in these steps? I've just installed ESS (Emacs Speaks Statistics), could
> this be a source of problem?
> 
> Thanks to all, and best regards
> 
> Javier

Another Javier (pez-de-Lacalle) has been messing with similar issues
for the "uroot" package it seems. There is some stuff in the README file
that might be useful. He has  tclRequire("BWidget") (no "s")...

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From sundar.dorai-raj at pdf.com  Mon Feb 27 18:33:54 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 27 Feb 2006 09:33:54 -0800
Subject: [R] help with step()
In-Reply-To: <2554377D323C9A40BD69956059FD05491136B101@mnip1>
References: <2554377D323C9A40BD69956059FD05491136B101@mnip1>
Message-ID: <44033802.1010003@pdf.com>


Smith, Phil wrote:
> Folks:
>  
> I'm having trouble doing a forward variable selection using step()
>  
> First, I fit an initial model:
>  
> fit0  <-  glm ( est~1 , data=all, subset=c(n>=25) )
>  
> then I invoke step():
>  
> fit1 <- step( fit0 , scope=list(upper=est~ pcped + pchosp + pfarm
> ,lower=est~1))
>  
>  
> I get the error message:  Error in eval(expr, envir, enclos) : invalid
> 'envir' argument
>  
> I looked at the documention on step(). There is no 'envir' arguement.
>  
> Can anyone shed light on what I'm doing wrong? 
>  
> Thanks,
> Phil Smith
> CDC
> 
>  
> 

Could be your "data" argument. ?all is a base function. Try re-naming to 
something else. Here's an example:

set.seed(1)
z <- all <- data.frame(x = rnorm(10), y = rnorm(10))

glm.all <- glm(y ~ 1, data = all)
step(glm.all, list(upper = y ~ x, lower = y ~ 1))

# Start:  AIC= 32.67
# y ~ 1
#
# Error in eval(expr, envir, enclos) : invalid 'envir' argument

glm.z <- glm(y ~ 1, data = z)
step(glm.z, list(upper = y ~ x, lower = y ~ 1))

# Start:  AIC= 32.67
#  y ~ 1
#
#        Df Deviance    AIC
# <none>      10.295 32.669
# + x     1    8.834 33.139
#
# Call:  glm(formula = y ~ 1, data = z)
#
# Coefficients:
# (Intercept)
#      0.2488
#
# Degrees of Freedom: 9 Total (i.e. Null);  9 Residual
# Null Deviance:      10.29
# Residual Deviance: 10.29        AIC: 32.67



From waeltlmi at fh-albsig.de  Mon Feb 27 18:56:21 2006
From: waeltlmi at fh-albsig.de (waeltlmi@fh-albsig.de)
Date: Mon, 27 Feb 2006 18:56:21 +0100
Subject: [R] 4D stacked column chart, Excel -> R
Message-ID: <20060227175502.M18749@fh-albsig.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/7a8b0cb1/attachment.pl

From Greg.Snow at intermountainmail.org  Mon Feb 27 19:03:17 2006
From: Greg.Snow at intermountainmail.org (Gregory Snow)
Date: Mon, 27 Feb 2006 11:03:17 -0700
Subject: [R] graphing dilemna
Message-ID: <07E228A5BE53C24CAD490193A7381BBB266A47@LP-EXCHVS07.CO.IHC.COM>

When barplots start getting complicated (and sometimes before that) you
may want to start considering dotplots (package lattice) instead.

For your specific problem you could possibly do the side-by-side plot,
then using the output from barplot and the rect function you could plot
a rectangle over the top of part of the on bar (or set of bars) to do
the stacked portion.

-- 
Gregory (Greg) L. Snow Ph.D.
Statistical Data Center
Intermountain Healthcare
greg.snow at intermountainmail.org
(801) 408-8111
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of sloan jones
> Sent: Friday, February 24, 2006 7:07 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] graphing dilemna
> 
> I want to create a graph that combines both stacked and 
> side-by-side bars, is this possible? 
> 
> If more information is need:  I have five age categories 
> which are further divided by gender (the male and female bars 
> lie side by side and then all the age groups are side by 
> side). I want to further divide just the youngest category 
> into two smaller age groups and retain the sex division -- 
> stack the ages but have the sexes side by side. 
> 
> Help!
> Sloan
> 
> 
> 
> 
> --
> _______________________________________________
> Surf the Web in a faster, safer and easier way:
> Download Opera 8 at http://www.opera.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From jzhang1982 at gmail.com  Mon Feb 27 19:12:59 2006
From: jzhang1982 at gmail.com (zhang jian)
Date: Mon, 27 Feb 2006 13:12:59 -0500
Subject: [R] about"Riply's K function"and "envelope"
Message-ID: <3f2938d50602271012n7db99b77q4615afb1d7a5ca4a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/a9951644/attachment.pl

From inchausti at cebc.cnrs.fr  Mon Feb 27 19:13:24 2006
From: inchausti at cebc.cnrs.fr (Pablo Inchausti)
Date: Mon, 27 Feb 2006 19:13:24 +0100
Subject: [R] obtaining means/SD after fitting a mixed model
Message-ID: <5.0.2.1.2.20060227190806.00a76450@194.254.155.1>

Hello,
I am running (non-balanced) mixed models (using library lme4) such as :
model1<-glmmPQL(Y~grouping variable+ covariate, random=~1|yr/month, 
data=dat, family= gaussian or poisson)
and besides the usual output in terms of the statistical significance of 
the fitted coefficients, I'd like to obtain the adjusted means and standard 
deviations (as one obtains after fitting a lm model). My problem is that I 
cannot find a command equivalent to "model.table (model, grouping variable, 
mean/sd)" that would apply to mixed models. Any suggestion would be 
appreciated.
Thanks in advance

Pablo



From h.wickham at gmail.com  Mon Feb 27 19:18:00 2006
From: h.wickham at gmail.com (hadley wickham)
Date: Mon, 27 Feb 2006 12:18:00 -0600
Subject: [R] 4D stacked column chart, Excel -> R
In-Reply-To: <20060227175502.M18749@fh-albsig.de>
References: <20060227175502.M18749@fh-albsig.de>
Message-ID: <f8e6ff050602271018t4c2282av999674ad99064959@mail.gmail.com>

A stacked barchart is a bad idea.  A 3d barchart is a very bad idea. 
A stacked 3d barchart is a very very bad idea.

Why?  Because it is very difficult to compare numbers.  In a stacked
bar chart you can only really compare the total, and the number in the
lowest bar.  In a 3d barchart you can only compare values in the same
row (distorting perspective + occlusion).

If you want to display you data in a interpretible way, I would
suggest a dotchart, carefully broken down to emphasise the comparisons
you want.

Hadley

On 2/27/06, waeltlmi at fh-albsig.de <waeltlmi at fh-albsig.de> wrote:
> Hi All.
>
> I'd like to programm a 4 dimensional chart in R.
> Acctually I wanted to solve that problem in Excel cause I had the data there.
> Here is a link of my actual problem description (there are some chart pictures as well)....
> http://www.mrexcel.com/board2/viewtopic.php?t=187336&highlight=stacked+column
> because I still couldn't solve that problem I came to R.
>
> The chart should be actually a 3D chart of the type 3D Column Chart with following achsis:
> X Achsis: driven kilometre in 10000 blocks
> Y Achsis: Production month
> Z Achsis: number
> I need to show another month in that chart, the repair month.
> Each column should be a stacked column with more colors, so that every color shows one repair month.
>
> I tried to do it with the scatterplot3d function after I saw this example (it is from uwe ligges book):
> install.packages("scatterplot3d")
> library("scatterplot3d")
> data(trees)
> s3d <- scatterplot3d(trees, type = "h", angle = 55, scale.y = 0.7, pch = 16, main = "trees")
> my.lm <- with(trees, lm(Volume ~ Girth + Height) )
> s3d$plane3d(my.lm, lty.box = "solid" )
>
> Normally I just have to group the ranges which show the km in 10000 blocks and group the points as well,
> but I didn't come that far. even the scatterplot3d funtion didn't work for my data (gwx and x is my data table).
> x <- gw.faelle(gwx)
> k3d <- scatterplot3d(x, type = "h", angle = 55, scale.y = 0.7, pch = 16, main = "GWK" )
> Error in segments(x, z, x, z2, col = col, cex = cex.symbols, ...) :
>  invalid color specification
>
> Do you have an idea how I can accomplish this task? Is it at allpossible to do that with scatterplot and some low level functions orshall I look at other packages and functions?
>
> Thanks in advance for any help and ideas!
>
> Best regards,
> Michael
>
>
> --
> HS Albstadt-Sigmaringen WebMail (http://webmail.hs-albsig.de)
>
> --
> HS Albstadt-Sigmaringen WebMail (http://webmail.hs-albsig.de)
>
>
>
>         [[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From jtw2 at CDC.GOV  Mon Feb 27 19:30:52 2006
From: jtw2 at CDC.GOV (Wassell, James T., Ph.D.)
Date: Mon, 27 Feb 2006 13:30:52 -0500
Subject: [R] power and sample size for a GLM with Poisson response variable
Message-ID: <AF2DCD619279544BA454141F4A45B9E3F5E1F5@m-niosh-3.niosh.cdc.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/45d7495b/attachment.pl

From peter.austin at ices.on.ca  Mon Feb 27 19:46:26 2006
From: peter.austin at ices.on.ca (Austin, Peter)
Date: Mon, 27 Feb 2006 13:46:26 -0500
Subject: [R] singular convergence in glmmPQL
Message-ID: <69E8946004ED8243A9E1554F7401424F7780C4@ices10.ices.on.ca>


I am using the 'glmmPQL function in the 'MASS' library to fit a mixed effects logistic regression model to simulated data.  I am conducting a series of simulations, and with certain simulated datasets, estimation of the random effects logistic regression model unexpectedly terminates.  I receive the following error message from R:

Error in lme.formula(fixed=zz + arm.long,random=~1 | id.long, 
method="ML", : singular convergence (7)

I would like to modify my code so that the resultant model is assigned a null value, rather than having estimation terminate.

My R code for this example is contained below.

# Data are read in for the two sets of clusters.  There are 100 clusters
# in each of the two groups.

y.1j <-c(3,2,3,1,3,3,2,2,3,1,1,3,2,2,3,3,3,1,5,2,4,4,1,3,3,4,5,3,3,0,2,2,0,2,2,2,1,3,2,3,1,0,4,4,4,2,1,2,4,1,0,1,0,1,2,4,2,1,1,2,3,3,1,3,0,2,3,4,2,2,4,2,1,3,1,4,3,0,3,4,3,0,1,3,1,0,2,2,6,2,2,1,1,1,2,1,0,2,2,2)

y.2j <- c(3,4,3,3,3,4,1,8,2,3,3,1,3,2,1,2,4,6,1,3,6,3,4,3,5,5,4,6,3,3,4,0,4,2,2,4,1,0,5,2,7,4,4,3,3,4,4,6,1,1,2,2,2,4,0,2,1,5,5,2,3,4,1,3,1,1,1,4,3,3,3,2,1,3,1,3,2,3,2,3,4,2,3,2,7,2,2,2,3,2,6,2,2,3,3,3,2,3,1,4)
# Number of positive responses in each cluster in each group.

n.clusters.1 <- length(y.1j)
n.clusters.2 <- length(y.2j)
# Number of clusters in each group.

m.1j <- rep(20,n.clusters.1)
m.2j <- rep(20,n.clusters.2)
# 20 subjects in each cluster in each group.

M.1 <- sum(m.1j)
M.2 <- sum(m.2j)
# Number of subjects in each of the two groups.

K <- n.clusters.1 + n.clusters.2
# Total number of clusters in the two groups combined.

############################################################################
# Use a random effects logistic regression model with cluster-specific
# random intercepts. 
############################################################################

library("MASS")
# import MASS library for using function 'glmmPQL'

# create subject-specific responses from cluster-aggregate responses.
y.j <- c(y.1j,y.2j)
m.j <- c(m.1j,m.2j)
x.j <- m.j - y.j
resp.mat <- cbind(y.j,x.j)
# First column is number of successes, second column is number of failures.
# One row per cluster.

y <- rep(c(1,0),K)
pat.mat <- matrix(t(resp.mat),ncol=1,byrow=T)
y.long <- rep(y,pat.mat)
# Create vector of 1/0 outcomes with 1 observation per subject.

id.long <- rep(1:K,c(m.1j,m.2j))

arm.0 <- rep(1,M.1)
arm.1 <- rep(0,M.2)
arm.long <- c(arm.0,arm.1)
# Indicator variable for which group the cluster belongs to.

re.1 <- glmmPQL(y.long ~ arm.long,random = ~1|id.long,family=binomial)


My question is this:
Is it possible for the vector "re.1" to be returned with a null value if there is a singular convergence in the underlying call to 'lme'? Rather than having the execution terminate, can a null value be assigned to "re.1"?  As it stands, "re.1" is undefined when estimation terminates.

Thanks very much,

Peter

Peter Austin, PhD
Senior Scientist, Institute for Clinical Evaluative Sciences.
Associate Professor, Departments of Public Health Sciences and Health Policy, Management and Evaluation, University of Toronto.
??
Institute for Clinical Evaluative Sciences 
G106 - 2075 Bayview Avenue 
Toronto, Ontario, M4N 3M5 
Tel:?? (416) 480-6131
Fax: (416) 480-6048??
ICES Web Site: www.ices.on.ca


___________________________________________________________________________ 
This email may contain confidential and/or privileged inform...{{dropped}}



From gunter.berton at gene.com  Mon Feb 27 20:01:58 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 27 Feb 2006 11:01:58 -0800
Subject: [R] singular convergence in glmmPQL
In-Reply-To: <69E8946004ED8243A9E1554F7401424F7780C4@ices10.ices.on.ca>
Message-ID: <005401c63bd0$49384a60$1a83fea9@gne.windows.gene.com>

If I understand you correctly (your post was, ummm... a bit long),

?try

should help. Condition on the class of the return inheriting from
'try-error' . i.e.

result<-try(glimmPQL(...))
if(inherits(result,'try-error'))...

As the try man page says, fancier things can be done via tryCatch()

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Austin, Peter
> Sent: Monday, February 27, 2006 10:46 AM
> To: r-help at stat.math.ethz.ch
> Cc: Austin, Peter
> Subject: [R] singular convergence in glmmPQL
> 
> 
> I am using the 'glmmPQL function in the 'MASS' library to fit 
> a mixed effects logistic regression model to simulated data.  
> I am conducting a series of simulations, and with certain 
> simulated datasets, estimation of the random effects logistic 
> regression model unexpectedly terminates.  I receive the 
> following error message from R:
> 
> Error in lme.formula(fixed=zz + arm.long,random=~1 | id.long, 
> method="ML", : singular convergence (7)
> 
> I would like to modify my code so that the resultant model is 
> assigned a null value, rather than having estimation terminate.
> 
> My R code for this example is contained below.
> 
> # Data are read in for the two sets of clusters.  There are 
> 100 clusters
> # in each of the two groups.
> 
> y.1j 
> <-c(3,2,3,1,3,3,2,2,3,1,1,3,2,2,3,3,3,1,5,2,4,4,1,3,3,4,5,3,3,
> 0,2,2,0,2,2,2,1,3,2,3,1,0,4,4,4,2,1,2,4,1,0,1,0,1,2,4,2,1,1,2,
> 3,3,1,3,0,2,3,4,2,2,4,2,1,3,1,4,3,0,3,4,3,0,1,3,1,0,2,2,6,2,2,
> 1,1,1,2,1,0,2,2,2)
> 
> y.2j <- 
> c(3,4,3,3,3,4,1,8,2,3,3,1,3,2,1,2,4,6,1,3,6,3,4,3,5,5,4,6,3,3,
> 4,0,4,2,2,4,1,0,5,2,7,4,4,3,3,4,4,6,1,1,2,2,2,4,0,2,1,5,5,2,3,
> 4,1,3,1,1,1,4,3,3,3,2,1,3,1,3,2,3,2,3,4,2,3,2,7,2,2,2,3,2,6,2,
> 2,3,3,3,2,3,1,4)
> # Number of positive responses in each cluster in each group.
> 
> n.clusters.1 <- length(y.1j)
> n.clusters.2 <- length(y.2j)
> # Number of clusters in each group.
> 
> m.1j <- rep(20,n.clusters.1)
> m.2j <- rep(20,n.clusters.2)
> # 20 subjects in each cluster in each group.
> 
> M.1 <- sum(m.1j)
> M.2 <- sum(m.2j)
> # Number of subjects in each of the two groups.
> 
> K <- n.clusters.1 + n.clusters.2
> # Total number of clusters in the two groups combined.
> 
> ##############################################################
> ##############
> # Use a random effects logistic regression model with cluster-specific
> # random intercepts. 
> ##############################################################
> ##############
> 
> library("MASS")
> # import MASS library for using function 'glmmPQL'
> 
> # create subject-specific responses from cluster-aggregate responses.
> y.j <- c(y.1j,y.2j)
> m.j <- c(m.1j,m.2j)
> x.j <- m.j - y.j
> resp.mat <- cbind(y.j,x.j)
> # First column is number of successes, second column is 
> number of failures.
> # One row per cluster.
> 
> y <- rep(c(1,0),K)
> pat.mat <- matrix(t(resp.mat),ncol=1,byrow=T)
> y.long <- rep(y,pat.mat)
> # Create vector of 1/0 outcomes with 1 observation per subject.
> 
> id.long <- rep(1:K,c(m.1j,m.2j))
> 
> arm.0 <- rep(1,M.1)
> arm.1 <- rep(0,M.2)
> arm.long <- c(arm.0,arm.1)
> # Indicator variable for which group the cluster belongs to.
> 
> re.1 <- glmmPQL(y.long ~ arm.long,random = ~1|id.long,family=binomial)
> 
> 
> My question is this:
> Is it possible for the vector "re.1" to be returned with a 
> null value if there is a singular convergence in the 
> underlying call to 'lme'? Rather than having the execution 
> terminate, can a null value be assigned to "re.1"?  As it 
> stands, "re.1" is undefined when estimation terminates.
> 
> Thanks very much,
> 
> Peter
> 
> Peter Austin, PhD
> Senior Scientist, Institute for Clinical Evaluative Sciences.
> Associate Professor, Departments of Public Health Sciences 
> and Health Policy, Management and Evaluation, University of Toronto.
> ??
> Institute for Clinical Evaluative Sciences 
> G106 - 2075 Bayview Avenue 
> Toronto, Ontario, M4N 3M5 
> Tel:?? (416) 480-6131
> Fax: (416) 480-6048??
> ICES Web Site: www.ices.on.ca
> 
> 
> ______________________________________________________________
> _____________ 
> This email may contain confidential and/or privileged 
> inform...{{dropped}}
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From llei at bccrc.ca  Mon Feb 27 20:09:24 2006
From: llei at bccrc.ca (Linda Lei)
Date: Mon, 27 Feb 2006 11:09:24 -0800
Subject: [R] about clustering method
Message-ID: <90B06673D826C64E8ED8EEA6B6FDF8CAE72AF7@crcmail1.BCCRC.CA>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/d1215c14/attachment.pl

From epurdom at stanford.edu  Mon Feb 27 20:34:00 2006
From: epurdom at stanford.edu (Elizabeth Purdom)
Date: Mon, 27 Feb 2006 11:34:00 -0800
Subject: [R] Question about Sweave
Message-ID: <6.1.2.0.2.20060227110614.04580030@epurdom.pobox.stanford.edu>

Hi,

I'm not sure if Sweave questions should go to the general list, but it 
seems to be part of the core R package without a separate maintainer.

I am writing a tutorial for R in a latex file. I'd like to use Sweave, 
since this seems its ideal usage. The problem is that I want to 
purposefully put errors in and then the output that comes with it in the 
text of my tutorial. However the errors kill the function Sweave() in R 
when what I would like is for Sweave to just run it and include the error 
message as part of the output.

I have set options(error=NULL). It doesn't seem that the error options 
would affect Sweave in the right way, since an error in my .Rnw file causes 
an error in Sweave() itself, not just in the processing of the code, but 
maybe there's an error-handling system I don't know about that would do it. 
(I tried error=expression(NULL) but Sweave couldn't finish regardless). I 
don't see any options in the documentation of Sweave that allow this 
behavior, either.

Thanks,
Elizabeth



From john.gavin at ubs.com  Mon Feb 27 20:33:54 2006
From: john.gavin at ubs.com (john.gavin@ubs.com)
Date: Mon, 27 Feb 2006 19:33:54 -0000
Subject: [R] elements in each row of a matrix to the left.
Message-ID: <182544D7A3144B42994EEA5662C54E0101A3BA75@NLDNC105PEX1.ubsw.net>

Hi,

Given a matrix like

(z <- matrix(c(
1, 1, NA, NA, NA, NA,
1,  NA, 1,  NA, 1, NA,
NA, 1, 1,  1,  NA, NA), ncol = 3))

     [,1] [,2] [,3]
[1,]    1    1   NA
[2,]    1   NA    1
[3,]   NA    1    1
[4,]   NA   NA    1
[5,]   NA    1   NA
[6,]   NA   NA   NA

is there a vectorised way to produce the output like

     [,1] [,2] [,3]
[1,]    1    1   NA
[2,]    1   NA    1
[3,]    1    1   NA
[4,]    1   NA   NA
[5,]    1   NA   NA
[6,]   NA   NA   NA

That is, given an n by m matrix, and going row by row, 
if the first non-NA element is in column k
I want to move elements in columns from k to m
to columns 1 to m-k+1 with NAs filling in from 
m-k+2 to m.

> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    2.1            
year     2005           
month    12             
day      20             
svn rev  36812          
language R        

Regards,

John.

John Gavin <john.gavin at ubs.com>,
Quantitative Risk Control,
UBS Investment Bank, 6th floor, 
100 Liverpool St., London EC2M 2RH, UK.
Phone +44 (0) 207 567 4289
Fax   +44 (0) 207 568 5352

Visit our website at http://www.ubs.com

This message contains confidential information and is intend...{{dropped}}



From davidhughjones at gmail.com  Mon Feb 27 20:43:43 2006
From: davidhughjones at gmail.com (David Hugh-Jones)
Date: Mon, 27 Feb 2006 19:43:43 +0000
Subject: [R] heckit with a probit
Message-ID: <f5d848060602271143k3016dbdcm@mail.gmail.com>

Hi

I have data for voting behaviour on two (related) binary votes. I want
to examine the second vote, running separate regressions for groups
who voted different ways on the first vote. As the votes are not
independent, I guess that there is an issue with selection bias.

So, I think I would like to fit a heckit style model but with a binary
dependent variable - so, in effect, two successive probits. Is there a
way to do it in R? (Alternatively: am I thinking about this the right
way?)

Cheers
David



From pburns at pburns.seanet.com  Mon Feb 27 20:55:00 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 27 Feb 2006 19:55:00 +0000
Subject: [R] elements in each row of a matrix to the left.
In-Reply-To: <182544D7A3144B42994EEA5662C54E0101A3BA75@NLDNC105PEX1.ubsw.net>
References: <182544D7A3144B42994EEA5662C54E0101A3BA75@NLDNC105PEX1.ubsw.net>
Message-ID: <44035914.4050507@pburns.seanet.com>

John,

Does

t(apply(z, 1, sort, na.last=TRUE))

do what you want?


Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

john.gavin at ubs.com wrote:

>Hi,
>
>Given a matrix like
>
>(z <- matrix(c(
>1, 1, NA, NA, NA, NA,
>1,  NA, 1,  NA, 1, NA,
>NA, 1, 1,  1,  NA, NA), ncol = 3))
>
>     [,1] [,2] [,3]
>[1,]    1    1   NA
>[2,]    1   NA    1
>[3,]   NA    1    1
>[4,]   NA   NA    1
>[5,]   NA    1   NA
>[6,]   NA   NA   NA
>
>is there a vectorised way to produce the output like
>
>     [,1] [,2] [,3]
>[1,]    1    1   NA
>[2,]    1   NA    1
>[3,]    1    1   NA
>[4,]    1   NA   NA
>[5,]    1   NA   NA
>[6,]   NA   NA   NA
>
>That is, given an n by m matrix, and going row by row, 
>if the first non-NA element is in column k
>I want to move elements in columns from k to m
>to columns 1 to m-k+1 with NAs filling in from 
>m-k+2 to m.
>
>  
>
>>version
>>    
>>
>         _              
>platform i386-pc-mingw32
>arch     i386           
>os       mingw32        
>system   i386, mingw32  
>status                  
>major    2              
>minor    2.1            
>year     2005           
>month    12             
>day      20             
>svn rev  36812          
>language R        
>
>Regards,
>
>John.
>
>John Gavin <john.gavin at ubs.com>,
>Quantitative Risk Control,
>UBS Investment Bank, 6th floor, 
>100 Liverpool St., London EC2M 2RH, UK.
>Phone +44 (0) 207 567 4289
>Fax   +44 (0) 207 568 5352
>
>Visit our website at http://www.ubs.com
>
>This message contains confidential information and is intend...{{dropped}}
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From sundar.dorai-raj at pdf.com  Mon Feb 27 20:58:00 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 27 Feb 2006 11:58:00 -0800
Subject: [R] about"Riply's K function"and "envelope"
In-Reply-To: <3f2938d50602271012n7db99b77q4615afb1d7a5ca4a@mail.gmail.com>
References: <3f2938d50602271012n7db99b77q4615afb1d7a5ca4a@mail.gmail.com>
Message-ID: <440359C8.8030400@pdf.com>



zhang jian wrote:
> hi!
> I did Riply's K function and envelope in the package "SPATSTAT". When the
> species number is less, it can work well and it is quickly. But when the
> species number is more(example:2000), it told me"memory limit". So I change
> "memory limit". But the speed is very slow. I took 13 hours to run the
> programe.
> Perhaps there are other methods that can do it. Or just change some
> parsmeters.
> who can help me?
> Thank you!
>                                                                Jian Zhang
> 

I don't have an example, but have you looked at ?Kenvl in the spatial 
package?

HTH,

--sundar



From sasprog474474 at yahoo.com  Mon Feb 27 21:12:01 2006
From: sasprog474474 at yahoo.com (Greg Tarpinian)
Date: Mon, 27 Feb 2006 12:12:01 -0800 (PST)
Subject: [R] relative referencing for filenames &etc
Message-ID: <20060227201201.51950.qmail@web37107.mail.mud.yahoo.com>

BACKGROUND:
I use SAS on a daily basis and one of its most powerful features in a
production environment is the use of LIBNAME and FILEREF statements, e.g.:


PROC PRINTTO LOG = "&LOGDIR.\data processing.log" NEW;
RUN;
PROC IMPORT 
	DATAFILE= "&DATADIR.\blah.xls"
	OUT = TEMP
	DBMS = EXCEL REPLACE;
    SHEET = "Sheet1"; 
    GETNAMES = YES;
RUN;


Properly setting up SAS Shortcuts in the WinXP environment, or (say)
the UNIX equivalent of batch files in the UNIX environment will cause
SAS to autoexecute (say) an INIT.SAS file that automatically assigns
the LOGDIR and DATADIR macro variables used above.  This is extremely
convenient because it makes the SAS code more portable from project to
project.


MY QUESTION:
Is it possible to use this kind of relative file and directory referencing
from within R?


Kind regards,


      Greg



From Camarda at demogr.mpg.de  Mon Feb 27 21:23:04 2006
From: Camarda at demogr.mpg.de (Camarda, Carlo Giovanni)
Date: Mon, 27 Feb 2006 21:23:04 +0100
Subject: [R] Different deviance residuals in a (similar?!?) glm example
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E6C0C560@HERMES.demogr.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/3ec608da/attachment.pl

From jzhang1982 at gmail.com  Mon Feb 27 21:26:16 2006
From: jzhang1982 at gmail.com (zhang jian)
Date: Mon, 27 Feb 2006 15:26:16 -0500
Subject: [R] about"Riply's K function"and "envelope"
In-Reply-To: <440359C8.8030400@pdf.com>
References: <3f2938d50602271012n7db99b77q4615afb1d7a5ca4a@mail.gmail.com>
	<440359C8.8030400@pdf.com>
Message-ID: <3f2938d50602271226r27e8cbeax564c3eeff3d4f536@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/64e0698b/attachment.pl

From Roger.Bivand at nhh.no  Mon Feb 27 21:46:19 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 27 Feb 2006 21:46:19 +0100 (CET)
Subject: [R] Question about Sweave
In-Reply-To: <6.1.2.0.2.20060227110614.04580030@epurdom.pobox.stanford.edu>
Message-ID: <Pine.LNX.4.44.0602272140070.699-100000@reclus.nhh.no>

On Mon, 27 Feb 2006, Elizabeth Purdom wrote:

> Hi,
> 
> I'm not sure if Sweave questions should go to the general list, but it 
> seems to be part of the core R package without a separate maintainer.
> 
> I am writing a tutorial for R in a latex file. I'd like to use Sweave, 
> since this seems its ideal usage. The problem is that I want to 
> purposefully put errors in and then the output that comes with it in the 
> text of my tutorial. However the errors kill the function Sweave() in R 
> when what I would like is for Sweave to just run it and include the error 
> message as part of the output.
> 
> I have set options(error=NULL). It doesn't seem that the error options 
> would affect Sweave in the right way, since an error in my .Rnw file causes 
> an error in Sweave() itself, not just in the processing of the code, but 
> maybe there's an error-handling system I don't know about that would do it. 
> (I tried error=expression(NULL) but Sweave couldn't finish regardless). I 
> don't see any options in the documentation of Sweave that allow this 
> behavior, either.

The usual way is to put the erroneous command inside try(), and mix blocks 
with echo=FALSE or TRUE and cat() of the object returned by try() of your 
command. See:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/60984.html

for an example.

> 
> Thanks,
> Elizabeth
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From sundar.dorai-raj at pdf.com  Mon Feb 27 21:59:57 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 27 Feb 2006 12:59:57 -0800
Subject: [R] about"Riply's K function"and "envelope"
In-Reply-To: <3f2938d50602271226r27e8cbeax564c3eeff3d4f536@mail.gmail.com>
References: <3f2938d50602271012n7db99b77q4615afb1d7a5ca4a@mail.gmail.com>	<440359C8.8030400@pdf.com>
	<3f2938d50602271226r27e8cbeax564c3eeff3d4f536@mail.gmail.com>
Message-ID: <4403684D.8090309@pdf.com>

So as not to offend the authors of spatial and splancs, please describe 
what "not good" means in this context? What is it about 
spatstat::envelope that cannot be achieved by spatial::Kenvl? Besides, 
the author of the K-function (Ripley himself) wrote the latter package. 
Here's an example:

library(spatial)
set.seed(24)
X <- list(x = runif(100), y = runif(100),
           area = c(xl = 0, xu = 1, yl = 0, xu = 1))
ppregion(X)
plot(Kfn(X, 0.5), type = "b", xlab = "distance", ylab = "L(t)")
set.seed(42)
lims <- Kenvl(0.5, 100, Psim(69))
lines(lims$x, lims$l, lty = 2, col = "darkred")
lines(lims$x, lims$u, lty = 2, col = "darkred")

library(spatstat)
Y <- ppp(X$x, X$y, X$area[1:2], X$area[3:4])
set.seed(42)
Yenv <- envelope(Y, nsim = 100)

Of course, these will look different because Kenvl and Kfn actually 
compute the L-function (which is a better visual tool), but otherwise 
they should be very similar.

(I must admit I haven't read all the documentation for spatstat so I may 
be off base as to what ?envelope is actually doing.)

--sundar


zhang jian wrote:
> I have tried the package"spatial" and "splance".But it is not good.
> I think there are some questions when I run the programs.
> I attach a part of data. can you help me try to do it? And attach a simple
> program to me.
> my plot is square, 500m*500m.
> 
>>PIKO[1:10,]
> 
>      code species  dbh     x     y   tag status branch
> 92  10142    PIKO 38.9  6.05 12.81 10165  alive      0
> 109 10213    PIKO 41.0  6.71 26.21 10202  alive      0
> 135 10222    PIKO 48.3 18.98 21.28 10214  alive      0
> 146 10223    PIKO 47.0 19.45 22.83 10224  alive      0
> 147 10223    PIKO 20.0 19.74 28.65 10225  alive      0
> 151 10223    PIKO 23.3 17.03 28.88 10229  alive      0
> 152 10223    PIKO 33.5 16.94 27.25 10230  alive      0
> 176 10232    PIKO 43.5 19.20 30.88 10248  alive      0
> 181 10233    PIKO 39.0 18.10 35.60 10252  alive      0
> 212 10243    PIKO 71.2  6.94 37.27 10281  alive      0
> 
> "x,y" are coordinations. I want to use them to do Ripley's K analysis.
> thank you very much!
> Help me!
>                                           jian zhang
> 
> On 2/27/06, Sundar Dorai-Raj <sundar.dorai-raj at pdf.com> wrote:
> 
>>
>>
>>zhang jian wrote:
>>
>>>hi!
>>>I did Riply's K function and envelope in the package "SPATSTAT". When
>>
>>the
>>
>>>species number is less, it can work well and it is quickly. But when the
>>>species number is more(example:2000), it told me"memory limit". So I
>>
>>change
>>
>>>"memory limit". But the speed is very slow. I took 13 hours to run the
>>>programe.
>>>Perhaps there are other methods that can do it. Or just change some
>>>parsmeters.
>>>who can help me?
>>>Thank you!
>>>                                                               Jian
>>
>>Zhang
>>
>>I don't have an example, but have you looked at ?Kenvl in the spatial
>>package?
>>
>>HTH,
>>
>>--sundar
>>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From comtech.usa at gmail.com  Mon Feb 27 21:58:06 2006
From: comtech.usa at gmail.com (Michael)
Date: Mon, 27 Feb 2006 12:58:06 -0800
Subject: [R] how to use the basis matrix of "ns" in R? really confused
	by multi-dim spline filtering?
In-Reply-To: <4402EDF7.6000302@dssm.unipa.it>
References: <b1f16d9d0602270232ye0d8538rabed2c61f8f3e3a@mail.gmail.com>
	<4402EDF7.6000302@dssm.unipa.it>
Message-ID: <b1f16d9d0602271258g3cdd29bcr6627b4db2e1ad14@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/256d2575/attachment.pl

From Roger.Bivand at nhh.no  Mon Feb 27 22:16:23 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Mon, 27 Feb 2006 22:16:23 +0100 (CET)
Subject: [R] about"Riply's K function"and "envelope"
In-Reply-To: <3f2938d50602271226r27e8cbeax564c3eeff3d4f536@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0602272207070.699-100000@reclus.nhh.no>

On Mon, 27 Feb 2006, zhang jian wrote:

> I have tried the package"spatial" and "splance".But it is not good.

You are not correct. All three packages, spatial, splancs, and spatstat
can be used, and, for the same bounding window, will give the same
results. Your complain that spatstat has difficulties computing simulation
envelopes for 2000 points (in your fourth appeal for help) also seems
unlikely. My impression is that you are not following advice given, and
are trying to simulate with an unnecessarily large number of replications,
and very likely for far too many distance bins.

Please simplify your task to something that you can make work. In each of
the three packages, calculating khat and computing simulation envelopes is
just a couple of lines, so try to get them right on a small data set that
you understand. Following the examples in the package will be a good 
start.

Once you have made it work on a small subset of your data following the 
examples in the packages, you can scale up to your full data sets.

> I think there are some questions when I run the programs.
> I attach a part of data. can you help me try to do it? And attach a simple
> program to me.
> my plot is square, 500m*500m.
> > PIKO[1:10,]
>      code species  dbh     x     y   tag status branch
> 92  10142    PIKO 38.9  6.05 12.81 10165  alive      0
> 109 10213    PIKO 41.0  6.71 26.21 10202  alive      0
> 135 10222    PIKO 48.3 18.98 21.28 10214  alive      0
> 146 10223    PIKO 47.0 19.45 22.83 10224  alive      0
> 147 10223    PIKO 20.0 19.74 28.65 10225  alive      0
> 151 10223    PIKO 23.3 17.03 28.88 10229  alive      0
> 152 10223    PIKO 33.5 16.94 27.25 10230  alive      0
> 176 10232    PIKO 43.5 19.20 30.88 10248  alive      0
> 181 10233    PIKO 39.0 18.10 35.60 10252  alive      0
> 212 10243    PIKO 71.2  6.94 37.27 10281  alive      0
> 
> "x,y" are coordinations. I want to use them to do Ripley's K analysis.
> thank you very much!
> Help me!
>                                           jian zhang
> 
> On 2/27/06, Sundar Dorai-Raj <sundar.dorai-raj at pdf.com> wrote:
> >
> >
> >
> > zhang jian wrote:
> > > hi!
> > > I did Riply's K function and envelope in the package "SPATSTAT". When
> > the
> > > species number is less, it can work well and it is quickly. But when the
> > > species number is more(example:2000), it told me"memory limit". So I
> > change
> > > "memory limit". But the speed is very slow. I took 13 hours to run the
> > > programe.
> > > Perhaps there are other methods that can do it. Or just change some
> > > parsmeters.
> > > who can help me?
> > > Thank you!
> > >                                                                Jian
> > Zhang
> > >
> >
> > I don't have an example, but have you looked at ?Kenvl in the spatial
> > package?
> >
> > HTH,
> >
> > --sundar
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From otter at otter-rsch.com  Mon Feb 27 22:38:40 2006
From: otter at otter-rsch.com (dave fournier)
Date: Mon, 27 Feb 2006 13:38:40 -0800
Subject: [R]  singular convergence in glmmPQL
Message-ID: <44037160.3000001@otter-rsch.com>


Hi,

If you are having trouble with convergence in glmmPQL
you might want to try our glmmADMB package for R at

http://otter-rsch.com/admbre/examples/glmmadmb/glmmADMB.html

It is more stable according to some users.

I believe the corresponding commands for
your model are

# paste this after your other commands
  df<-data.frame(y.long,arm.long,id.long)
# load glmmADMB package
 library("glmmADMB")
# invoke glmmADMB routine
 re.1 <- glmm.admb(y.long ~ arm.long,
random=~1,group='id.long',family='binomial',link='logit',data=df)

and that should do it.

   Cheers,

   Dave



-- 
David A. Fournier
P.O. Box 2040,
Sidney, B.C. V8l 3s3
Canada
http://otter-rsch.com



From llei at bccrc.ca  Mon Feb 27 22:30:01 2006
From: llei at bccrc.ca (Linda Lei)
Date: Mon, 27 Feb 2006 13:30:01 -0800
Subject: [R] clustering
Message-ID: <90B06673D826C64E8ED8EEA6B6FDF8CAE72AF9@crcmail1.BCCRC.CA>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/6142117b/attachment.pl

From idimakos at upatras.gr  Mon Feb 27 22:41:55 2006
From: idimakos at upatras.gr (Ioannis Dimakos)
Date: Mon, 27 Feb 2006 23:41:55 +0200 (EET)
Subject: [R] repeated measures ANOVA
In-Reply-To: <44031778.CF736D1A@magnet.at>
References: <44031778.CF736D1A@magnet.at>
Message-ID: <55658.84.254.13.123.1141076515.squirrel@mail.upatras.gr>

Christian,

One thing that may help with the data you provide is to make sure that
group, time, and subject are indeed factors.
group <- factor(group)
time <- factor(time)
subject <- factor(subject)

Running your analyses in both SPSS 13.0 and R.2.2.1 (the R sessions were
ran in win xp and ubuntu/linux), gave the following results:

1) SPSS
time: F(2,16) = 7.623,p <.005.

2) When I ran your code, the aov piece gave a singularity warning, while the
lmer bit gave a false convergence message.

I believe that in your case, the code should be:

aov(p.pa~time*group + Error(subject))
or
aov(p.pa~time*group + Error(subject + subject:time)

They both give identical results

When following the "nlme way", your code is correct and should give the
same results as in spss, or aov.

I was also stuck in the "lmer way", even when I changed the code to:
lmer(p.pa~time*group + (time|subject).


Perhaps, another list member, or Prof. Bates could provide more info on
this one?

IKD

On Mon, February 27, 2006 17:15, Christian Gold wrote:
> Dear list members:
>
> I have the following data:
> group <- rep(rep(1:2, c(5,5)), 3)
> time <- rep(1:3, rep(10,3))
> subject <- rep(1:10, 3)
> p.pa <- c(92, 44, 49, 52, 41, 34, 32, 65, 47, 58, 94, 82, 48, 60, 47,
> 46, 41, 73, 60, 69, 95, 53, 44, 66, 62, 46, 53, 73, 84, 79)
> P.PA <- data.frame(subject, group, time, p.pa)
>
> The ten subjects were randomly assigned to one of two groups and
> measured three times. (The treatment changes after the second time
> point.)
>
> Now I am trying to find out the most adequate way for an analysis of
> main effects and interaction. Most social scientists would call this
> analysis a repeated measures ANOVA, but I understand that mixed-effects
> model is a more generic term for the same analysis. I did the analysis
> in four ways (one in SPSS, three in R):
>
> 1. In SPSS I used "general linear model, repeated measures", defining a
> "within-subject factor" for the three different time points. (The data
> frame is structured differently in SPSS so that there is one line for
> each subject, and each time point is a separate variable.)
> Time was significant.
>
> 2. Analogous to what is recommended in the first chapter of Pinheiro &
> Bates' "Mixed-Effects Models" book, I used
> library(nlme)
> summary(lme ( p.pa ~ time * group, random = ~ 1 | subject))
> Here, time was NOT significant. This was surprising not only in
> comparison with the result in SPSS, but also when looking at the graph:
> interaction.plot(time, group, p.pa)
>
> 3. I then tried a code for the lme4 package, as described by Douglas
> Bates in RNews 5(1), 2005 (p. 27-30). The result was the same as in 2.
> library(lme4)
> summary(lmer ( p.pa ~ time * group + (time*group | subject), P.PA ))
>
> 4. The I also tried what Jonathan Baron suggests in his "Notes on the
> use of R for psychology experiments and questionnaires" (on CRAN):
> summary( aov ( p.pa ~ time * group + Error(subject/(time * group)) ) )
> This gives me yet another result.
>
> So I am confused. Which one should I use?
>
> Thanks
>
> Christian
>
>
>
>
> --
> ____________________________
> Dr. Christian Gold, PhD
> http://www.hisf.no/~chrisgol
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>


-- 
Ioannis C. Dimakos, Ph.D.
University of Patras
Department of Elementary Education
Patras, GR-26500 GREECE
http://www.elemedu.upatras.gr/dimakos/
http://yannishome.port5.com/

-- 
Ioannis C. Dimakos, Ph.D.
University of Patras
Department of Elementary Education
Patras, GR-26500 GREECE
http://www.elemedu.upatras.gr/dimakos/
http://yannishome.port5.com/



From andy_liaw at merck.com  Mon Feb 27 22:47:58 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 27 Feb 2006 16:47:58 -0500
Subject: [R] how to use the basis matrix of "ns" in R? really confused
 by multi-dim spline filtering?
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED886@usctmx1106.merck.com>

If you do not understand what ns() outputs, nor descriptions of splines in
books, perhaps it's not an appropriate tool for you.  Look for something
that you understand (or can understand after some reading).  No one is
pointing a gun to your head and tell you to use splines, I hope.

If you have a hard time understanding what you read in books, it's
unrealistic to expect a mailing list about a software to teach you.

Andy

From: Michael
> 
> Have you seen an example on how to do it in R? I found no practical
> examples...
> 
> On 2/27/06, vito muggeo <vmuggeo at dssm.unipa.it> wrote:
> >
> > Dear Micheal,
> >
> > > the output of the "ns" function in R is "basis matrix", but then
> > Yes you are right, the output of the ns(x, df) is the basis 
> matrix of a
> > natural cubic spline with df degrees of freedom. See ?ns (in package
> > splines) on how to specify df or knots or ..
> >
> > Fitting y~ns(x,df) yields a smooth curve given by a linear 
> combination
> > of the basis functions (the single colums of the basis 
> matrix) by the
> > estimated coefficients (returned by the fitted model).
> >
> > As far as I know, a tensor product is usually employed to
> > multidimensional smoothing and the multidimensional basis 
> is formed via
> > the kronecker product of the marginal bases.
> >
> > Finally, last but not least: Probably you need some statistical
> > backaground on spline fitting..
> > Please, read some statistical papers/books on such topic 
> (for instance
> > see references in packages splines, mgcv)
> >
> > best,
> > vito
> >
> > Michael wrote:
> > > Hi all,
> > >
> > > Could anybody recommend some easy-to-understand and example based
> > > notes/tutorials on how to use cubic splines to do filtering on
> > > multi-dimension data?
> > >
> > > I am confused by the 1-dimensional case, and more confused by
> > > multi-dimensional case.
> > >
> > > I found all the books suddenly become very abstract when 
> it comes to
> > this
> > > subject.
> > >
> > > They don't provide examples in R or Splus at all.
> > >
> > > Specifically, I don't know how to provide data "x" to the 
> "ns" function
> > in
> > > R,
> > >
> > > and I don't understand what should be the output matrix, 
> and how to use
> > the
> > > output matrix to "filter" data?
> > >
> > > Books mention about basis matrix, design matrix, model 
> matrix, data
> > matrix,
> > > etc. I got lost.
> > >
> > > I presume the output of the "ns" function in R is "basis 
> matrix", but
> > then
> > > how do I use it?  How to form tensor-product?
> > >
> > > I don't understand it at all.
> > >
> > > Please help me!
> > >
> > > Thank you very much!
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> >
> > --
> > ====================================
> > Vito M.R. Muggeo
> > Dip.to Sc Statist e Matem `Vianelli'
> > Universit?? di Palermo
> > viale delle Scienze, edificio 13
> > 90128 Palermo - ITALY
> > tel: 091 6626240
> > fax: 091 485726/485612
> > ====================================
> >
> 
> 	[[alternative HTML version deleted]]
> 
>



From thomas.hoffmann at uni-bonn.de  Mon Feb 27 23:08:10 2006
From: thomas.hoffmann at uni-bonn.de (Thomas Hoffmann)
Date: Mon, 27 Feb 2006 23:08:10 +0100
Subject: [R] log scale y axis ticks control on boxplots
Message-ID: <4403784A.10800@uni-bonn.de>

Hey R Users

I like to control the ticks and labels in a boxplot as described for a 
xyplot below (thread in maillinglist in may 2003). Does anybody knows 
how it works?

Thanks in advance
Thomas

Thread from May 2003
(http://tolstoy.newcastle.edu.au/R/help/03a/5604.html)

Hello R Users!

I'm using lattice to produce some graphs with logaritmic y-scales. I use
the command

xyplot(hits ~ c(1:1024), data=eichData, type="S", scales=list(y =
list(log=10)))

to create the plot. This is fine, except for the automatically choosen
tick marks. I'd like to have a major tick at the 10^n location and minor
ticks in between which correspond with the native variable. To get this
working I have to use at and label like

labl <- rep("", 30)
labl[1] <- "1"; labl[10] <- "10"; labl[19] <- "100"; labl[28] <- "1000";
nums <- c(1:10, seq(20,100, 10), seq(200, 1000, 100))
xyplot(hits ~ c(1:1024), data=eichData, type="S", scales=list(y =
list(log=10, at=nums, labels=labl)))



From comtech.usa at gmail.com  Mon Feb 27 23:31:23 2006
From: comtech.usa at gmail.com (Michael)
Date: Mon, 27 Feb 2006 14:31:23 -0800
Subject: [R] how to use the basis matrix of "ns" in R? really confused
	by multi-dim spline filtering?
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED886@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED886@usctmx1106.merck.com>
Message-ID: <b1f16d9d0602271431pd5bc9f5raf61eabf0a752dac@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/30c2d525/attachment.pl

From rduval at gmail.com  Tue Feb 28 00:06:55 2006
From: rduval at gmail.com (Robert Duval)
Date: Mon, 27 Feb 2006 18:06:55 -0500
Subject: [R] heckit with a probit
In-Reply-To: <f5d848060602271143k3016dbdcm@mail.gmail.com>
References: <f5d848060602271143k3016dbdcm@mail.gmail.com>
Message-ID: <2b6e342f0602271506t53e60475j7cefb638fb111103@mail.gmail.com>

I don't know if I understand your problem very well but the first
reference that comes to mind is

James Heckman, "Dummy Endogenous Variables in a Simultaneous Equation
System," Econometrica, (July 1978).

also you might find a good survey of the literature on

Francis Vella "Estimating models with sample selection bias: A
survey," Journal of Human Resources, 1998, Vol 33 pp 127-169.

I don't know how many of the methods here proposed are already
implemented in R, but in principle many of them are Likelihood models
that you could program.


best
robert


On 2/27/06, David Hugh-Jones <davidhughjones at gmail.com> wrote:
> Hi
>
> I have data for voting behaviour on two (related) binary votes. I want
> to examine the second vote, running separate regressions for groups
> who voted different ways on the first vote. As the votes are not
> independent, I guess that there is an issue with selection bias.
>
> So, I think I would like to fit a heckit style model but with a binary
> dependent variable - so, in effect, two successive probits. Is there a
> way to do it in R? (Alternatively: am I thinking about this the right
> way?)
>
> Cheers
> David
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From gunter.berton at gene.com  Tue Feb 28 00:10:17 2006
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 27 Feb 2006 15:10:17 -0800
Subject: [R] how to use the basis matrix of "ns" in R? really confusedby
	multi-dim spline filtering?
In-Reply-To: <b1f16d9d0602271431pd5bc9f5raf61eabf0a752dac@mail.gmail.com>
Message-ID: <007a01c63bf2$f9dc8120$1a83fea9@gne.windows.gene.com>

Michael:

I do not think Andy mischaracterized, for you initially said:

" Books mention about basis matrix, design matrix, model
 matrix, data matrix, etc. I got lost. "

This also seems to me a statement that you do not understand the basic
principles and concepts -- hence Vito's and Andy's advice.  The
documentation does require that you understand the underlying mathematical
ideas for splines and merely explains how R inmplements them -- R's syntax.
If you need help translating the mathematical ideas into practice, which
**is** an issue of basic understanding in my opinion, than perhaps you need
a more extensive tutorial, which the spline man page certainly does not
provide. I would suggest that you search around the web until you find one.
(I think Friedman/Hastie/Tibshirani's "STATISTICAL LEARNING THEORY" contains
a nice overview, but you may disagree). After such homework and if you still
wish to use splines, R's man page should be fully comprehensible, I believe.
If not, I think you should consider following Andy's advice.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Michael
> Sent: Monday, February 27, 2006 2:31 PM
> To: Liaw, Andy
> Cc: R-help at stat.math.ethz.ch
> Subject: Re: [R] how to use the basis matrix of "ns" in R? 
> really confusedby multi-dim spline filtering?
> 
> I think you mis-understood. And perhaps you read in a haste, 
> or you were
> just in a bad mood today.
> 
> I think on this mailing-list, many people come for help on a R related
> issue, they know something theoretically, but since they are 
> new to R, they
> want to use R, they want to use R to help do applied things.
> 
> For me, there is a missing link between my understanding of 
> splines from the
> books(which are abstract) and a usage example in R. That's 
> something I am
> looking for. I believe it is very appropriate.
> 
> If you don't know, or don't want to say anything helpful, 
> please just don't
> say anything. It is not about a gun pointing, it is about a 
> learning process
> which is very specific to R.
> 
> Please kindly try not to say negative things, and try to 
> discourage people
> from learning new things.
> 
> On 2/27/06, Liaw, Andy <andy_liaw at merck.com> wrote:
> >
> > If you do not understand what ns() outputs, nor 
> descriptions of splines in
> > books, perhaps it's not an appropriate tool for you.  Look 
> for something
> > that you understand (or can understand after some reading). 
>  No one is
> > pointing a gun to your head and tell you to use splines, I hope.
> >
> > If you have a hard time understanding what you read in books, it's
> > unrealistic to expect a mailing list about a software to teach you.
> >
> > Andy
> >
> > From: Michael
> > >
> > > Have you seen an example on how to do it in R? I found no 
> practical
> > > examples...
> > >
> > > On 2/27/06, vito muggeo <vmuggeo at dssm.unipa.it> wrote:
> > > >
> > > > Dear Micheal,
> > > >
> > > > > the output of the "ns" function in R is "basis 
> matrix", but then
> > > > Yes you are right, the output of the ns(x, df) is the basis
> > > matrix of a
> > > > natural cubic spline with df degrees of freedom. See 
> ?ns (in package
> > > > splines) on how to specify df or knots or ..
> > > >
> > > > Fitting y~ns(x,df) yields a smooth curve given by a linear
> > > combination
> > > > of the basis functions (the single colums of the basis
> > > matrix) by the
> > > > estimated coefficients (returned by the fitted model).
> > > >
> > > > As far as I know, a tensor product is usually employed to
> > > > multidimensional smoothing and the multidimensional basis
> > > is formed via
> > > > the kronecker product of the marginal bases.
> > > >
> > > > Finally, last but not least: Probably you need some statistical
> > > > backaground on spline fitting..
> > > > Please, read some statistical papers/books on such topic
> > > (for instance
> > > > see references in packages splines, mgcv)
> > > >
> > > > best,
> > > > vito
> > > >
> > > > Michael wrote:
> > > > > Hi all,
> > > > >
> > > > > Could anybody recommend some easy-to-understand and 
> example based
> > > > > notes/tutorials on how to use cubic splines to do filtering on
> > > > > multi-dimension data?
> > > > >
> > > > > I am confused by the 1-dimensional case, and more confused by
> > > > > multi-dimensional case.
> > > > >
> > > > > I found all the books suddenly become very abstract when
> > > it comes to
> > > > this
> > > > > subject.
> > > > >
> > > > > They don't provide examples in R or Splus at all.
> > > > >
> > > > > Specifically, I don't know how to provide data "x" to the
> > > "ns" function
> > > > in
> > > > > R,
> > > > >
> > > > > and I don't understand what should be the output matrix,
> > > and how to use
> > > > the
> > > > > output matrix to "filter" data?
> > > > >
> > > > > Books mention about basis matrix, design matrix, model
> > > matrix, data
> > > > matrix,
> > > > > etc. I got lost.
> > > > >
> > > > > I presume the output of the "ns" function in R is "basis
> > > matrix", but
> > > > then
> > > > > how do I use it?  How to form tensor-product?
> > > > >
> > > > > I don't understand it at all.
> > > > >
> > > > > Please help me!
> > > > >
> > > > > Thank you very much!
> > > > >
> > > > >       [[alternative HTML version deleted]]
> > > > >
> > > > > ______________________________________________
> > > > > R-help at stat.math.ethz.ch mailing list
> > > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > > PLEASE do read the posting guide!
> > > > http://www.R-project.org/posting-guide.html
> > > > >
> > > >
> > > > --
> > > > ====================================
> > > > Vito M.R. Muggeo
> > > > Dip.to Sc Statist e Matem `Vianelli'
> > > > Universit` di Palermo
> > > > viale delle Scienze, edificio 13
> > > > 90128 Palermo - ITALY
> > > > tel: 091 6626240
> > > > fax: 091 485726/485612
> > > > ====================================
> > > >
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >
> >
> >
> >
> > 
> --------------------------------------------------------------
> ----------------
> > Notice:  This e-mail message, together with any 
> attachment...{{dropped}}
> 
>



From johanfaux at yahoo.com  Tue Feb 28 01:07:00 2006
From: johanfaux at yahoo.com (johan Faux)
Date: Mon, 27 Feb 2006 16:07:00 -0800 (PST)
Subject: [R] how to automatically install old versions of packages ..
Message-ID: <20060228000700.4651.qmail@web31409.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/d475ab96/attachment.pl

From sdfrost at ucsd.edu  Tue Feb 28 01:34:19 2006
From: sdfrost at ucsd.edu (Simon Frost)
Date: Mon, 27 Feb 2006 16:34:19 -0800
Subject: [R] Collinearity in nls problem
Message-ID: <1141086859.12112.2961.camel@penguin.local>

Dear R-Help list,

I have a nonlinear least squares problem, which involves a changepoint;
at the beginning, the outcome y is constant, and after a delay, t0, y
follows a biexponential decay. I log-transform the data, to stabilize
the error variance. At time t < t0, my model is

log(y_i)=log(exp(a0)+exp(b0))

at time t >= t0, the model is

log(y_i)=log(exp(a0-a1*(t_i - t0))+exp(b0=b1*(t_i - t0)))

I thought that I would have identifiability issues, but this model seems
to work fine except that the parameters t0 (the delay) is highly
correlated with the initial decay slope a0 (which makes sense, as the
longer the delay, the more rapid the drop has to be, conditional on the
data).

To get over this problem, I could reparameterize the problem, but it
isn't clear to me how to do this for the above model. I also thought
about using a penalized least square approach, to shrink t0 and a1
towards 0. I haven't seen much on penalized least squares in a nonlinear
least squares setting; is this a good way to go? Can I justifiably
penalize only a0 and a1, or should I also penalize the other parameters?

Thanks for any help!
Simon
-- 
Simon D.W. Frost, D.Phil.
Assistant Adjunct Professor of Pathology
University of California, San Diego
Mailcode 8208
UCSD Antiviral Research Center
150 W. Washington St.
San Diego, CA 92103
Tel: +1 619 543 8898
Fax: +1 619 543 5094
Email: sdfrost at ucsd.edu



From caf at gis.usu.edu  Tue Feb 28 02:38:35 2006
From: caf at gis.usu.edu (Craig A Faulhaber)
Date: Mon, 27 Feb 2006 18:38:35 -0700
Subject: [R] power and sample size for a GLM with Poisson response
	variable
In-Reply-To: <AF2DCD619279544BA454141F4A45B9E3F5E1F5@m-niosh-3.niosh.cdc.gov>
References: <AF2DCD619279544BA454141F4A45B9E3F5E1F5@m-niosh-3.niosh.cdc.gov>
Message-ID: <4403A99B.9040700@gis.usu.edu>

Thanks for the functions, James.  I, too, did not understand the 
"constraints" vector in asypow.  Can anyone on the listserve explain this?

Craig

Wassell, James T., Ph.D. wrote:

> Craig,   I found the package asypow difficult to use and it did not 
> yield results in the ballpark of other approaches.   (could not figure 
> out the "constraints" vector).  
>
> I wrote some simple functions, one asy.pwr uses the non-central 
> chi-square distn.
>
>
-- 
Craig A. Faulhaber
Department of Forest, Range, and Wildlife Sciences
Utah State University
5230 Old Main Hill
Logan, UT 84322
(435)797-3892



From john_d_mchenry at yahoo.com  Tue Feb 28 02:46:58 2006
From: john_d_mchenry at yahoo.com (John McHenry)
Date: Mon, 27 Feb 2006 17:46:58 -0800 (PST)
Subject: [R] Elegant way to express residual calculation in R?
Message-ID: <20060228014658.35964.qmail@web35410.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/0c98e271/attachment.pl

From andy_liaw at merck.com  Tue Feb 28 04:46:38 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 27 Feb 2006 22:46:38 -0500
Subject: [R] how to use the basis matrix of "ns" in R? really confused
 by multi-dim spline filtering?
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED88C@usctmx1106.merck.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060227/a921e173/attachment.pl

From mikael.anderson at gmail.com  Tue Feb 28 04:51:42 2006
From: mikael.anderson at gmail.com (Mikael Anderson)
Date: Tue, 28 Feb 2006 14:51:42 +1100
Subject: [R] Bounding Box in pdf files
Message-ID: <bdc992b40602271951y19f54a55w6ebf8e7314b3727e@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060228/23fbf640/attachment.pl

From andy_liaw at merck.com  Tue Feb 28 05:02:37 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 27 Feb 2006 23:02:37 -0500
Subject: [R] Elegant way to express residual calculation in R?
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED88D@usctmx1106.merck.com>

Not sure if the following would qualify as elegant...  It's easier to work
with a matrix instead of data frame:

x.mat <- data.matrix(X)
xmean <- mean(x.mat)
operator.eff <- ave(x.mat, row(x.mat)) - xmean
machine.eff <- ave(x.mat, col(x.mat)) - xmean
(predicted.x <- xmean + operator.eff + machine.eff)
resid.x <- x.mat - predicted.x
sum(resid.x^2)

You can also use aov(), but you already know that...

Andy

From: John McHenry
> 
>     Hi All,
> 
>     I am illustrating a simple, two-way ANOVA using the 
> following data and I'm 
>     having difficulty in expressing the predicted values 
> succinctly in R.
> 
>     X<- data.frame(read.table(textConnection("
>         Machine.1    Machine.2    Machine.3
>         53           61           51
>         47           55           51
>         46           52           49
>         50           58           54
>         49           54           50"
>     ), header=TRUE))
>     rownames(X)<- paste("Operator.", 1:nrow(X), sep="")
>     print(X)
> 
>     # I'd like to know if there is a more elegant way to 
> calculate the residuals
>     # than the following, which seems to be rather a kludge. 
> If you care to read
>     # the code you'll see what I mean. 
> 
>     machine.adjustment<-  colMeans(X) - mean(mean(X))    # 
> length(machine.adjustment)==3
>     operator.adjustment<- rowMeans(X) - mean(mean(X))    # 
> length(operator.adjustment)==5
>     X.predicted<- numeric(0)
>     for (j in 1:ncol(X))
>     {
>         new.col<- mean(mean(X)) + operator.adjustment + 
> machine.adjustment[j]
>         X.predicted<- cbind(X.predicted, new.col)
>     }
>     print(X.predicted)
>     X.residual<- X - X.predicted
>     SS.E<- sum( X.residual^2 )
> 
> It seems like there ought to be some way of doing that a 
> little bit cleaner ...
> 
> Thanks,
> 
> Jack.
> 
> 		
> ---------------------------------
> 
> Bring photos to life! New PhotoMail  makes sharing a breeze. 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ggrothendieck at gmail.com  Tue Feb 28 05:19:30 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 27 Feb 2006 23:19:30 -0500
Subject: [R] Elegant way to express residual calculation in R?
In-Reply-To: <20060228014658.35964.qmail@web35410.mail.mud.yahoo.com>
References: <20060228014658.35964.qmail@web35410.mail.mud.yahoo.com>
Message-ID: <971536df0602272019t31ae7f23i75337e567c5ab088@mail.gmail.com>

Try this:

Xm <- as.matrix(X)
X.lm <- lm(c(Xm) ~ factor(col(Xm)) + factor(row(Xm)))
sum(resid(X.lm)^2)

or if the idea was to do it without using lm try replacing
your calculation of X.predicted with this:

X.predicted <-
  outer(operator.adjustment, machine.adjustment, "+") + mean(mean(X))


On 2/27/06, John McHenry <john_d_mchenry at yahoo.com> wrote:
>    Hi All,
>
>    I am illustrating a simple, two-way ANOVA using the following data and I'm
>    having difficulty in expressing the predicted values succinctly in R.
>
>    X<- data.frame(read.table(textConnection("
>        Machine.1    Machine.2    Machine.3
>        53           61           51
>        47           55           51
>        46           52           49
>        50           58           54
>        49           54           50"
>    ), header=TRUE))
>    rownames(X)<- paste("Operator.", 1:nrow(X), sep="")
>    print(X)
>
>    # I'd like to know if there is a more elegant way to calculate the residuals
>    # than the following, which seems to be rather a kludge. If you care to read
>    # the code you'll see what I mean.
>
>    machine.adjustment<-  colMeans(X) - mean(mean(X))    # length(machine.adjustment)==3
>    operator.adjustment<- rowMeans(X) - mean(mean(X))    # length(operator.adjustment)==5
>    X.predicted<- numeric(0)
>    for (j in 1:ncol(X))
>    {
>        new.col<- mean(mean(X)) + operator.adjustment + machine.adjustment[j]
>        X.predicted<- cbind(X.predicted, new.col)
>    }
>    print(X.predicted)
>    X.residual<- X - X.predicted
>    SS.E<- sum( X.residual^2 )
>
> It seems like there ought to be some way of doing that a little bit cleaner ...
>
> Thanks,
>
> Jack.
>
>
> ---------------------------------
>
> Bring photos to life! New PhotoMail  makes sharing a breeze.
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Tue Feb 28 05:43:04 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 27 Feb 2006 23:43:04 -0500
Subject: [R] Elegant way to express residual calculation in R?
In-Reply-To: <971536df0602272019t31ae7f23i75337e567c5ab088@mail.gmail.com>
References: <20060228014658.35964.qmail@web35410.mail.mud.yahoo.com>
	<971536df0602272019t31ae7f23i75337e567c5ab088@mail.gmail.com>
Message-ID: <971536df0602272043t153f888s717e812600045e90@mail.gmail.com>

Here is one further idea:

Xm <- as.matrix(X)
Xm. <- scale(Xm, scale = FALSE)
Xm.. <- t(scale(t(tmp), scale = FALSE))
sum(Xm..^2)


On 2/27/06, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Try this:
>
> Xm <- as.matrix(X)
> X.lm <- lm(c(Xm) ~ factor(col(Xm)) + factor(row(Xm)))
> sum(resid(X.lm)^2)
>
> or if the idea was to do it without using lm try replacing
> your calculation of X.predicted with this:
>
> X.predicted <-
>  outer(operator.adjustment, machine.adjustment, "+") + mean(mean(X))
>
>
> On 2/27/06, John McHenry <john_d_mchenry at yahoo.com> wrote:
> >    Hi All,
> >
> >    I am illustrating a simple, two-way ANOVA using the following data and I'm
> >    having difficulty in expressing the predicted values succinctly in R.
> >
> >    X<- data.frame(read.table(textConnection("
> >        Machine.1    Machine.2    Machine.3
> >        53           61           51
> >        47           55           51
> >        46           52           49
> >        50           58           54
> >        49           54           50"
> >    ), header=TRUE))
> >    rownames(X)<- paste("Operator.", 1:nrow(X), sep="")
> >    print(X)
> >
> >    # I'd like to know if there is a more elegant way to calculate the residuals
> >    # than the following, which seems to be rather a kludge. If you care to read
> >    # the code you'll see what I mean.
> >
> >    machine.adjustment<-  colMeans(X) - mean(mean(X))    # length(machine.adjustment)==3
> >    operator.adjustment<- rowMeans(X) - mean(mean(X))    # length(operator.adjustment)==5
> >    X.predicted<- numeric(0)
> >    for (j in 1:ncol(X))
> >    {
> >        new.col<- mean(mean(X)) + operator.adjustment + machine.adjustment[j]
> >        X.predicted<- cbind(X.predicted, new.col)
> >    }
> >    print(X.predicted)
> >    X.residual<- X - X.predicted
> >    SS.E<- sum( X.residual^2 )
> >
> > It seems like there ought to be some way of doing that a little bit cleaner ...
> >
> > Thanks,
> >
> > Jack.
> >
> >
> > ---------------------------------
> >
> > Bring photos to life! New PhotoMail  makes sharing a breeze.
> >        [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>



From MSchwartz at mn.rr.com  Tue Feb 28 06:08:01 2006
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Mon, 27 Feb 2006 23:08:01 -0600
Subject: [R] Bounding Box in pdf files
In-Reply-To: <bdc992b40602271951y19f54a55w6ebf8e7314b3727e@mail.gmail.com>
References: <bdc992b40602271951y19f54a55w6ebf8e7314b3727e@mail.gmail.com>
Message-ID: <1141103281.4539.40.camel@localhost.localdomain>

On Tue, 2006-02-28 at 14:51 +1100, Mikael Anderson wrote:
> This is probably  a faq but I have not been able to find a solution.
> 
> I create a pdf file in R but latex complains that it can't find the bounding
> box. Here is an example:
> 
> > pdf(file="test.pdf", onefile=FALSE,  width=8,height=8)
> > plot(1:10)
> > dev.off()
> X11
>   2
> > sessionInfo()
> R version 2.2.1, 2005-12-20, sparc-sun-solaris2.9
> 
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
> 
> other attached packages:
>   mapdata   mapproj      maps
>  "2.0-17" "1.1-7.1"  "2.0-30"
> 
> This is the error from latex:
> 
> ! LaTeX Error: Cannot determine size of graphic in test.pdf  (no Bound
> ingBox).
> 
> Any thoughts about what the problem might be?
> 
> /Miakel


Are you using 'latex' or 'pdflatex' from the command line?

I am guessing the former given the error.

The former requires EPS (Encapsulated Postscript) files, whereas the
latter uses PDF files.

If you want (or need to) to stay with 'latex', you can generate EPS
files in R using a modification of your example above:

 postscript(file="test.pdf", onefile = FALSE, horizontal = FALSE,
            paper = "special", width = 8, height = 8)

 plot(1:10)
 dev.off()

See the Details section in ?postscript for more information.

The simplified advantage seen with using pdflatex and pdf graphics is
that it is a single step to go from TeX to PDF. In the case of using EPS
files with latex, it takes three steps, going from TeX to DVI to PS to
PDF. Of course shell scripts help with that process.

The advantage of using EPS files with latex is that there are certain
packages for TeX that do not work with pdflatex. So it depends upon what
you need to do.

HTH,

Marc Schwartz



From t.lim at auckland.ac.nz  Tue Feb 28 06:10:03 2006
From: t.lim at auckland.ac.nz (Tiong Lim)
Date: Tue, 28 Feb 2006 18:10:03 +1300
Subject: [R] Compiling R on aix getting error
Message-ID: <4403DB2B.50709@auckland.ac.nz>

I am trying to compile R 2.2.1 on aix 5.3 with xlc/xlC 7.0 , but i am 
getting the error below. I did a search on the archive and someone had a 
similar error as me but I can't seem to find a fix for the error below.

Target "R" is up to date.
Target "R" is up to date.
Target "R" is up to date.
Target "R" is up to date.
Target "Makedeps" is up to date.
Target "libbz2.a" is up to date.
Target "Makedeps" is up to date.
Target "libpcre.a" is up to date.
Target "Makedeps" is up to date.
Target "libz.a" is up to date.
../../../src/include/libintl.h is unchanged
../../../include/libintl.h is unchanged
Target "localecharset.h" is up to date.
Target "Makedeps" is up to date.
Target "libintl.a" is up to date.
Target "R" is up to date.
Target "Makedeps" is up to date.
Target "libappl.a" is up to date.
Target "Makedeps" is up to date.
Target "libnmath.a" is up to date.
Target "Makedeps" is up to date.
Target "libunix.a" is up to date.
Target "Makedeps" is up to date.
        xlc  -I../../src/extra/zlib -I../../src/extra/bzip2 
-I../../src/extra/pcre   -I. -I../../src/include -I../../src/include  
-DHAVE_CONFIG_H   -O -qstrict  -c platform.c -o platform.o
"/usr/include/netinet/in.h", line 793.1: 1506-166 (S) Definition of 
function socklen_t requires parentheses.
"/usr/include/netinet/in.h", line 793.17: 1506-276 (S) Syntax error: 
possible missing '{'?
"/usr/include/sys/socket.h", line 374.9: 1506-046 (S) Syntax error.
"/usr/include/sys/socket.h", line 378.9: 1506-046 (S) Syntax error.
"/usr/include/sys/socket.h", line 404.9: 1506-046 (S) Syntax error.
"/usr/include/sys/socket.h", line 475.52: 1506-046 (S) Syntax error.
"/usr/include/sys/socket.h", line 476.57: 1506-046 (S) Syntax error.
"/usr/include/sys/socket.h", line 477.57: 1506-046 (S) Syntax error.
"/usr/include/sys/socket.h", line 478.87: 1506-046 (S) Syntax error.
"/usr/include/sys/socket.h", line 484.44: 1506-275 (S) Unexpected text 
socklen_t encountered.
"/usr/include/sys/socket.h", line 485.47: 1506-275 (S) Unexpected text 
socklen_t encountered.
"/usr/include/sys/socket.h", line 486.55: 1506-046 (S) Syntax error.
"/usr/include/sys/socket.h", line 490.73: 1506-275 (S) Unexpected text 
socklen_t encountered.
"/usr/include/sys/socket.h", line 491.49: 1506-275 (S) Unexpected text 
socklen_t encountered.
"platform.c", line 1386.13: 1506-285 (S) The indirection operator cannot 
be applied to a pointer to an incomplete struct or union.
"platform.c", line 1388.34: 1506-285 (S) The indirection operator cannot 
be applied to a pointer to an incomplete struct or union.
make: The error code from the last command is 1.


Stop.
make: The error code from the last command is 2.


Stop.
make: The error code from the last command is 1.


Stop.
make: The error code from the last command is 1.


Stop.

thanks
Tiong



From ripley at stats.ox.ac.uk  Tue Feb 28 06:16:53 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Feb 2006 05:16:53 +0000 (GMT)
Subject: [R] Bounding Box in pdf files
In-Reply-To: <bdc992b40602271951y19f54a55w6ebf8e7314b3727e@mail.gmail.com>
References: <bdc992b40602271951y19f54a55w6ebf8e7314b3727e@mail.gmail.com>
Message-ID: <Pine.LNX.4.64.0602280503320.21783@gannet.stats.ox.ac.uk>

Simple: PDF files do not have a BoundingBox so there is none to find 
(BoundingBox is associated with postscript files).  (The equivalent in a 
PDF file is the MediaBox or CropBox.)

You have not shown us the LaTeX, but the problem lies there.  I would 
expect you to need to use pdflatex if you want to include PDF graphics.

Please seem further help on a latex list.

On Tue, 28 Feb 2006, Mikael Anderson wrote:

> This is probably  a faq but I have not been able to find a solution.

Googling for 'Bounding Box PDF' led me lots of useful information.

> I create a pdf file in R but latex complains that it can't find the bounding
> box. Here is an example:
>
>> pdf(file="test.pdf", onefile=FALSE,  width=8,height=8)
>> plot(1:10)
>> dev.off()
> X11
>  2
>> sessionInfo()
> R version 2.2.1, 2005-12-20, sparc-sun-solaris2.9
>
> attached base packages:
> [1] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"
> [7] "base"
>
> other attached packages:
>  mapdata   mapproj      maps
> "2.0-17" "1.1-7.1"  "2.0-30"
>
> This is the error from latex:
>
> ! LaTeX Error: Cannot determine size of graphic in test.pdf  (no Bound
> ingBox).
>
> Any thoughts about what the problem might be?
>
> /Miakel
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From MSchwartz at mn.rr.com  Tue Feb 28 06:21:13 2006
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Mon, 27 Feb 2006 23:21:13 -0600
Subject: [R] log scale y axis ticks control on boxplots
In-Reply-To: <4403784A.10800@uni-bonn.de>
References: <4403784A.10800@uni-bonn.de>
Message-ID: <1141104073.4539.45.camel@localhost.localdomain>

On Mon, 2006-02-27 at 23:08 +0100, Thomas Hoffmann wrote:
> Hey R Users
> 
> I like to control the ticks and labels in a boxplot as described for a 
> xyplot below (thread in maillinglist in may 2003). Does anybody knows 
> how it works?
> 
> Thanks in advance
> Thomas
> 
> Thread from May 2003
> (http://tolstoy.newcastle.edu.au/R/help/03a/5604.html)
> 
> Hello R Users!
> 
> I'm using lattice to produce some graphs with logaritmic y-scales. I use
> the command
> 
> xyplot(hits ~ c(1:1024), data=eichData, type="S", scales=list(y =
> list(log=10)))
> 
> to create the plot. This is fine, except for the automatically choosen
> tick marks. I'd like to have a major tick at the 10^n location and minor
> ticks in between which correspond with the native variable. To get this
> working I have to use at and label like
> 
> labl <- rep("", 30)
> labl[1] <- "1"; labl[10] <- "10"; labl[19] <- "100"; labl[28] <- "1000";
> nums <- c(1:10, seq(20,100, 10), seq(200, 1000, 100))
> xyplot(hits ~ c(1:1024), data=eichData, type="S", scales=list(y =
> list(log=10, at=nums, labels=labl)))


It's not entirely clear whether you want this using bwplot() or
boxplot(). So...here are examples using both:

  library(lattice)
  x <- 1:1000
  labl <- rep("", 28)
  labl[1] <- "1"
  labl[10] <- "10"
  labl[19] <- "100"
  labl[28] <- "1000"
  nums <- c(1:10, seq(20, 100, 10), seq(200, 1000, 100))
  bwplot(x, log = "x", 
         scales = list(x = list(log = 10, at = nums, labels = labl)))



  x <- 1:1000
  boxplot(x, log = "y", yaxt = "n")
  labl <- rep("", 28)
  labl[1] <- "1"
  labl[10] <- "10"
  labl[19] <- "100"
  labl[28] <- "1000"
  nums <- c(1:10, seq(20, 100, 10), seq(200, 1000, 100))
  axis(2, at = nums, label = labl, las = 2)


Is either one of those what you are looking for?

HTH,

Marc Schwartz



From ripley at stats.ox.ac.uk  Tue Feb 28 06:31:04 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Feb 2006 05:31:04 +0000 (GMT)
Subject: [R] Compiling R on aix getting error
In-Reply-To: <4403DB2B.50709@auckland.ac.nz>
References: <4403DB2B.50709@auckland.ac.nz>
Message-ID: <Pine.LNX.4.64.0602280518330.22167@gannet.stats.ox.ac.uk>

On Tue, 28 Feb 2006, Tiong Lim wrote:

> I am trying to compile R 2.2.1 on aix 5.3 with xlc/xlC 7.0 , but i am
> getting the error below. I did a search on the archive and someone had a
> similar error as me but I can't seem to find a fix for the error below.

Are you referrring to

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/66941.html

?  Unfortunately I never received a reply to those questions.

This appeared to be something new in AIX 5.3's headers, most likely that 
they have apparently started defining SOCKLEN_T.  For the R-devel version 
on R we changed to R_SOCKLEN_T.

So please try the R-devel version of R, or change all occurrences of
SOCKLEN_T to R_SOCKLEN_T.

Googling showed that several other projects had been affected by this. 
E.g.  http://www.zsh.org/mla/workers/2004/msg01205.html
And socklen_t on AIX has been an age-old problem.

...
>        xlc  -I../../src/extra/zlib -I../../src/extra/bzip2
> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
> -DHAVE_CONFIG_H   -O -qstrict  -c platform.c -o platform.o
> "/usr/include/netinet/in.h", line 793.1: 1506-166 (S) Definition of
> function socklen_t requires parentheses.
> "/usr/include/netinet/in.h", line 793.17: 1506-276 (S) Syntax error:
> possible missing '{'?
> "/usr/include/sys/socket.h", line 374.9: 1506-046 (S) Syntax error.
> "/usr/include/sys/socket.h", line 378.9: 1506-046 (S) Syntax error.
> "/usr/include/sys/socket.h", line 404.9: 1506-046 (S) Syntax error.
> "/usr/include/sys/socket.h", line 475.52: 1506-046 (S) Syntax error.
> "/usr/include/sys/socket.h", line 476.57: 1506-046 (S) Syntax error.
> "/usr/include/sys/socket.h", line 477.57: 1506-046 (S) Syntax error.
> "/usr/include/sys/socket.h", line 478.87: 1506-046 (S) Syntax error.
> "/usr/include/sys/socket.h", line 484.44: 1506-275 (S) Unexpected text
> socklen_t encountered.
> "/usr/include/sys/socket.h", line 485.47: 1506-275 (S) Unexpected text
> socklen_t encountered.
> "/usr/include/sys/socket.h", line 486.55: 1506-046 (S) Syntax error.
> "/usr/include/sys/socket.h", line 490.73: 1506-275 (S) Unexpected text
> socklen_t encountered.
> "/usr/include/sys/socket.h", line 491.49: 1506-275 (S) Unexpected text
> socklen_t encountered.
> "platform.c", line 1386.13: 1506-285 (S) The indirection operator cannot
> be applied to a pointer to an incomplete struct or union.
> "platform.c", line 1388.34: 1506-285 (S) The indirection operator cannot
> be applied to a pointer to an incomplete struct or union.
> make: The error code from the last command is 1.
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kar at itga.com.au  Tue Feb 28 06:31:34 2006
From: kar at itga.com.au (Kylie-anne Richards)
Date: Tue, 28 Feb 2006 16:31:34 +1100
Subject: [R] Capturing warning messages within R
Message-ID: <20060228053349.6FB3E44D03@melmail.itga.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060228/ee73b346/attachment.pl

From ripley at stats.ox.ac.uk  Tue Feb 28 06:44:35 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Feb 2006 05:44:35 +0000 (GMT)
Subject: [R] Capturing warning messages within R
In-Reply-To: <20060228053349.6FB3E44D03@melmail.itga.com.au>
References: <20060228053349.6FB3E44D03@melmail.itga.com.au>
Message-ID: <Pine.LNX.4.64.0602280542060.22167@gannet.stats.ox.ac.uk>

They are written to stderr, so you can capture stderr (which is only used 
by R itself for messages).

Beyond that, I suggest you need to ask on an Rpy list about Rpy, rather 
than on R-help.

On Tue, 28 Feb 2006, Kylie-anne Richards wrote:

> Just wondering, how do you capture "warning messege"s from R? I'm using Rpy
> (the python plug-in for R). I guess those
> are not python exception so I couldn't use the "try" block.
>
> For example:
>
> Ran out of iterations and did not converge in: fitter(X, Y, strats, offset,
> init, control, weights = weights, MPR
>
> Regards,
>
> Kylie-Anne Richards
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

PLEASE do, including not sending HTML mail.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From petr.pikal at precheza.cz  Tue Feb 28 09:01:19 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 28 Feb 2006 09:01:19 +0100
Subject: [R] clustering
In-Reply-To: <90B06673D826C64E8ED8EEA6B6FDF8CAE72AF9@crcmail1.BCCRC.CA>
Message-ID: <4404115F.29580.3E4CBB@localhost>

Did you try to use help.search() on your topics?

Help files with alias or concept or title matching 'SOM' using 
regular expression matching:



any(base)                               Are Some Values True?
SOM(class)                              Self-Organizing Maps: Online 
Algorithm
batchSOM(class)                         Self-Organizing Maps: Batch 
Algorithm
somgrid(class)                          Plot SOM Fits
somers2(Hmisc)                          Somers' Dxy Rank Correlation
isoMDS(MASS)                            Kruskal's Non-metric 
Multidimensional Scaling
gam.check(mgcv)                         Some diagnostics for a fitted 
gam model


Help files with alias or concept or title matching 'partitioning' 
using fuzzy matching:



clusplot.partition(cluster)             Bivariate Clusplot of a 
Partitioning Object
pam(cluster)                            Partitioning Around Medoids
pam.object(cluster)                     Partitioning Around Medoids 
(PAM) Object
partition(cluster)                      Partitioning Object
mvpart(mvpart)                          Recursive Partitioning and 
Regression Trees
rpart(mvpart)                           Recursive Partitioning and 
Regression Trees
rpart.object(mvpart)                    Recursive Partitioning and 
Regression Trees Object
rpart(rpart)                            Recursive Partitioning and 
Regression Trees
rpart.object(rpart)                     Recursive Partitioning and 
Regression Trees Object

Help files with alias or concept or title matching 'neural network' 
using fuzzy matching:



nnetHess(nnet)                          Evaluates Hessian for a 
Neural Network
nnet(nnet)                              Fit Neural Networks

HTH
Petr



On 27 Feb 2006 at 13:30, Linda Lei wrote:

Date sent:      	Mon, 27 Feb 2006 13:30:01 -0800
From:           	"Linda Lei" <llei at bccrc.ca>
To:             	<r-help at stat.math.ethz.ch>
Subject:        	[R] clustering

> Hi there,
> 
> 
> 
> Sorry for the double email. Does R have the packages for the following
> clustering methods? And if it does,  what the commands for them? 
> 
> 
> 
> 1. SOM (Self-organization map)
> 
> 
> 
> 2. Graph partitioning:
> 
> 
> 
> 3. Neural network
> 
> 
> 
> 4. Probability Binning
> 
> 
> 
> 
> 
> Thank you very much!
> 
> Linda
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
>  [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From Friedrich.Leisch at tuwien.ac.at  Tue Feb 28 08:50:04 2006
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Tue, 28 Feb 2006 08:50:04 +0100
Subject: [R] about clustering method
In-Reply-To: <90B06673D826C64E8ED8EEA6B6FDF8CAE72AF7@crcmail1.BCCRC.CA>
References: <90B06673D826C64E8ED8EEA6B6FDF8CAE72AF7@crcmail1.BCCRC.CA>
Message-ID: <17412.172.883717.150859@celebrian.ci.tuwien.ac.at>

>>>>> On Mon, 27 Feb 2006 11:09:24 -0800,
>>>>> Linda Lei (LL) wrote:

  > Hi there,
  > I'm doing some clustering analysis and try to find all the algorithms
  > related to clustering in R. Here is the list of the algorithms I found.
  > But I'm not sure if 

  > It's the complete list.  Could you please check it and see if there're
  > other ones? 

You may want to have a look at the CTAN Task View about Clustering at

	http://cran.r-project.org/src/contrib/Views/

HTH,
Fritz Leisch

-- 
-------------------------------------------------------------------
Friedrich Leisch 

Institut f??r Statistik                        Tel: +49 89 2180 3165
Ludwig-Maximilians-Universit??t                Fax: +49 89 2180 5308
Akademiestra??e 1
D-80799 M??nchen                  http://www.ci.tuwien.ac.at/~leisch



From Friedrich.Leisch at tuwien.ac.at  Tue Feb 28 09:03:45 2006
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Tue, 28 Feb 2006 09:03:45 +0100
Subject: [R] Question about Sweave
In-Reply-To: <6.1.2.0.2.20060227110614.04580030@epurdom.pobox.stanford.edu>
References: <6.1.2.0.2.20060227110614.04580030@epurdom.pobox.stanford.edu>
Message-ID: <17412.993.931983.71207@celebrian.ci.tuwien.ac.at>

>>>>> On Mon, 27 Feb 2006 11:34:00 -0800,
>>>>> Elizabeth Purdom (EP) wrote:

  > Hi,
  > I'm not sure if Sweave questions should go to the general list, but it 
  > seems to be part of the core R package without a separate maintainer.

  > I am writing a tutorial for R in a latex file. I'd like to use Sweave, 
  > since this seems its ideal usage. The problem is that I want to 
  > purposefully put errors in and then the output that comes with it in the 
  > text of my tutorial. However the errors kill the function Sweave() in R 
  > when what I would like is for Sweave to just run it and include the error 
  > message as part of the output.

  > I have set options(error=NULL). It doesn't seem that the error options 
  > would affect Sweave in the right way, since an error in my .Rnw file causes 
  > an error in Sweave() itself, not just in the processing of the code, but 
  > maybe there's an error-handling system I don't know about that would do it. 
  > (I tried error=expression(NULL) but Sweave couldn't finish regardless). I 
  > don't see any options in the documentation of Sweave that allow this 
  > behavior, either.

There is no direct support, but fortunately R is a full-featured
programming language ;-)

I usually do something along the lines of

**********************************************************

\documentclass[a4paper]{article}

\begin{document}

<<errchunk,eval=false>>=
x=sin("a")
<<echo=false>>=
cat(try({
<<errchunk>>
}))
@ 

\end{document}

**********************************************************

which of course only helps if you know where the error will happen,
but in your application this seems to be the case.

Best,
Fritz Leisch

-- 
-----------------------------------------------------------------------
Friedrich Leisch 

Institut f??r Statistik                          Tel: (+49 89) 2180 3165
Ludwig-Maximilians-Universit??t                  Fax: (+49 89) 2180 5308
Akademiestra??e 1
D-80799 M??nchen                      http://www.ci.tuwien.ac.at/~leisch



From bhs2 at mevik.net  Tue Feb 28 09:52:53 2006
From: bhs2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Tue, 28 Feb 2006 09:52:53 +0100
Subject: [R] question about Principal Component Analysis in R?
In-Reply-To: <b1f16d9d0602270100m59f2b925s39715e0022a231de@mail.gmail.com>
	(comtech.usa@gmail.com's
	message of "Mon, 27 Feb 2006 01:00:06 -0800")
References: <b1f16d9d0602270100m59f2b925s39715e0022a231de@mail.gmail.com>
Message-ID: <m0bqwr6f16.fsf@bar.nemo-project.org>

Michael wrote:

>> pca=prcomp(training_data, center=TRUE, scale=FALSE, retx=TRUE);
>
> Then I want to rotate the test data set using the
>
>> d1=scale(test_data, center=TRUE, scale=FALSE) %*% pca$rotation;
>> d2=predict(pca, test_data, center=TRUE, scale=FALSE);
>
> these two values are different
>
>> min(d2-d1)
> [1] -1.976152
>> max(d2-d1)
> [1] 1.535222

This is because you have subtracted a different means vector.  You
should use the coloumn means of the training data (as predict does;
see the last line of stats:::predict.prcomp):

d1=scale(test_data, center=pca$center, scale=FALSE) %*% pca$rotation;


-- 
Bj??rn-Helge Mevik



From comtech.usa at gmail.com  Tue Feb 28 10:14:21 2006
From: comtech.usa at gmail.com (Michael)
Date: Tue, 28 Feb 2006 01:14:21 -0800
Subject: [R] does svm have a CV to obtain the best "cost" parameter?
Message-ID: <b1f16d9d0602280114q789a8722ne82d445507c8ac70@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060228/21c5a2b6/attachment.pl

From comtech.usa at gmail.com  Tue Feb 28 10:19:55 2006
From: comtech.usa at gmail.com (Michael)
Date: Tue, 28 Feb 2006 01:19:55 -0800
Subject: [R] how to use the basis matrix of "ns" in R? really confused
	by multi-dim spline filtering?
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED88C@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED88C@usctmx1106.merck.com>
Message-ID: <b1f16d9d0602280119g1c0f7535ja22ed9c34e36d7f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060228/7a1a8386/attachment.pl

From depire at inrets.fr  Tue Feb 28 10:27:25 2006
From: depire at inrets.fr (depire@inrets.fr)
Date: Tue, 28 Feb 2006 10:27:25 +0100
Subject: [R] LaTeX in R graph
Message-ID: <1141118845.4404177d8b2cc@webmail.inrets.fr>


Hello,
I would like to know if it is possible to insert LaTeX typesetting in R output.
I want to obtain a graph with LaTeX label in order to incorporate it as
postscript or pdf,

x<-seq(0,1,length=100)
y<-x*x
plot(x,y,xlab="$X$",ylab="$X^2$")



From r.hankin at noc.soton.ac.uk  Tue Feb 28 10:31:29 2006
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Tue, 28 Feb 2006 09:31:29 +0000
Subject: [R] lines() and recycled colours
Message-ID: <2CBD2498-21C6-4262-9940-A52E8129E605@soc.soton.ac.uk>

Hi

?lines says


      For 'type = "h"', 'col' can be a vector and will be recycled as
      needed.


Why doesn't  lines() recycle colours for other types?

If I type


 > plot(0:1,0:1,type="n")
 > lines(runif(11),runif(11),col=c("red","green"))
 >


then all ten lines are red, with no warning given.  Is there a reason  
why
colour recycling would be a bad idea in this case?
  Also, it would be nice if arguments such as lwd
were recycled if needed too.




--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From john.gavin at ubs.com  Tue Feb 28 10:31:51 2006
From: john.gavin at ubs.com (john.gavin@ubs.com)
Date: Tue, 28 Feb 2006 09:31:51 -0000
Subject: [R] elements in each row of a matrix to the left.
In-Reply-To: <44035914.4050507@pburns.seanet.com>
Message-ID: <182544D7A3144B42994EEA5662C54E0101A3BA7B@NLDNC105PEX1.ubsw.net>

Hi Patrick/Jeff,

> Does
> 
> t(apply(z, 1, sort, na.last=TRUE))
> 
> do what you want?

Not quite.

t(apply(z, 1, sort, na.last=TRUE))

     [,1] [,2] [,3]
[1,]    1    1   NA
[2,]    1    1   NA
[3,]    1    1   NA
[4,]    1   NA   NA
[5,]    1   NA   NA
[6,]   NA   NA   NA

Row 2 is the problem.

I dont want to move all NAs to the end of each row.
I just want to move all of the NAs before the first non-NA element,
if any, to the end of each row.
So in my example, rows 1 and 2 should remain unchanged.

What I have got at the moment is ugly

shiftLeft <- function(z)
{ x <- as.data.frame(t(z)) # work with cols not rows.
  ans <- lapply(x, function(xx) 
  { # get indices of first and last non-NA element
    ind <- which(!is.na(xx))
    ind <- ind[c(1, length(ind))]
    # if all NAs or if first element is non-NA do no work
    if (any(is.na(ind)) || ind[1] == 1) xx else
    { temp <- numeric(length(xx)) ; temp[] <- NA
      # move elements in posns ind[1] to ind[2] to the start
      temp[1:(ind[2]-ind[1]+1)] <- xx[ind[1]:ind[2]]
      temp
    } # if
  }) # lapply
  ans <- as.matrix(data.frame(ans))
  dimnames(ans) <- dimnames(z)
  t(ans)
}

> z ; shiftLeft(z)
     [,1] [,2] [,3]
[1,]    1    1   NA
[2,]    1   NA    1
[3,]   NA    1    1
[4,]   NA   NA    1
[5,]   NA    1   NA
[6,]   NA   NA   NA
     [,1] [,2] [,3]
[1,]    1    1   NA
[2,]    1   NA    1
[3,]    1    1   NA
[4,]    1   NA   NA
[5,]    1   NA   NA
[6,]   NA   NA   NA

I feel that there is probably a shorter vectorised way to do this.
In general, I have matrices (z) with several thousand rows and 
and few hundred columns so vectorisation would help.

Regards,

John.


> -----Original Message-----
> From: Patrick Burns [mailto:pburns at pburns.seanet.com]
> Sent: 27 February 2006 19:55
> To: Gavin, John
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] elements in each row of a matrix to the left.
> 
> John,
> 
> Does
> 
> t(apply(z, 1, sort, na.last=TRUE))
> 
> do what you want?
> 
> 
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
> 
> john.gavin at ubs.com wrote:
> 
> >Hi,
> >
> >Given a matrix like
> >
> >(z <- matrix(c(
> >1, 1, NA, NA, NA, NA,
> >1,  NA, 1,  NA, 1, NA,
> >NA, 1, 1,  1,  NA, NA), ncol = 3))
> >
> >     [,1] [,2] [,3]
> >[1,]    1    1   NA
> >[2,]    1   NA    1
> >[3,]   NA    1    1
> >[4,]   NA   NA    1
> >[5,]   NA    1   NA
> >[6,]   NA   NA   NA
> >
> >is there a vectorised way to produce the output like
> >
> >     [,1] [,2] [,3]
> >[1,]    1    1   NA
> >[2,]    1   NA    1
> >[3,]    1    1   NA
> >[4,]    1   NA   NA
> >[5,]    1   NA   NA
> >[6,]   NA   NA   NA
> >
> >That is, given an n by m matrix, and going row by row, 
> >if the first non-NA element is in column k
> >I want to move elements in columns from k to m
> >to columns 1 to m-k+1 with NAs filling in from 
> >m-k+2 to m.
> >
> >  
> >
> >>version
> >>    
> >>
> >         _              
> >platform i386-pc-mingw32
> >arch     i386           
> >os       mingw32        
> >system   i386, mingw32  
> >status                  
> >major    2              
> >minor    2.1            
> >year     2005           
> >month    12             
> >day      20             
> >svn rev  36812          
> >language R        
> >
> >Regards,
> >
> >John.
> >
> >John Gavin <john.gavin at ubs.com>,
> >Quantitative Risk Control,
> >UBS Investment Bank, 6th floor, 
> >100 Liverpool St., London EC2M 2RH, UK.
> >Phone +44 (0) 207 567 4289
> >Fax   +44 (0) 207 568 5352
> >
> >Visit our website at http://www.ubs.com
> >
> >This message contains confidential information and is 
> intend...{{dropped}}
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html
>
>
>
>  
>


Visit our website at http://www.ubs.com

This message contains confidential information and is intend...{{dropped}}



From Dietrich.Trenkler at uni-osnabrueck.de  Tue Feb 28 10:33:08 2006
From: Dietrich.Trenkler at uni-osnabrueck.de (Dietrich Trenkler)
Date: Tue, 28 Feb 2006 10:33:08 +0100
Subject: [R] LaTeX in R graph
In-Reply-To: <1141118845.4404177d8b2cc@webmail.inrets.fr>
References: <1141118845.4404177d8b2cc@webmail.inrets.fr>
Message-ID: <440418D4.6030704@uni-osnabrueck.de>

depire at inrets.fr schrieb:

>Hello,
>I would like to know if it is possible to insert LaTeX typesetting in R output.
>I want to obtain a graph with LaTeX label in order to incorporate it as
>postscript or pdf,
>
>x<-seq(0,1,length=100)
>y<-x*x
>plot(x,y,xlab="$X$",ylab="$X^2$")
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>
Hi,

have a look at the psfrag package.

D. Trenkler

-- 
Dietrich Trenkler c/o Universitaet Osnabrueck 
Rolandstr. 8; D-49069 Osnabrueck, Germany    
email: Dietrich.Trenkler at Uni-Osnabrueck.de



From michael.watson at bbsrc.ac.uk  Tue Feb 28 10:37:46 2006
From: michael.watson at bbsrc.ac.uk (michael watson (IAH-C))
Date: Tue, 28 Feb 2006 09:37:46 -0000
Subject: [R] lines() and recycled colours
Message-ID: <8975119BCD0AC5419D61A9CF1A923E9503008448@iahce2ksrv1.iah.bbsrc.ac.uk>

Hi

Lines behaves as the help() says it does:

plot(0:1,0:1,type="n")
lines(runif(11),runif(11),col=c("red","green"), type="h")

Mick

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Robin Hankin
Sent: 28 February 2006 09:31
To: RHelp
Subject: [R] lines() and recycled colours

Hi

?lines says


      For 'type = "h"', 'col' can be a vector and will be recycled as
      needed.


Why doesn't  lines() recycle colours for other types?

If I type


 > plot(0:1,0:1,type="n")
 > lines(runif(11),runif(11),col=c("red","green"))
 >


then all ten lines are red, with no warning given.  Is there a reason
why colour recycling would be a bad idea in this case?
  Also, it would be nice if arguments such as lwd were recycled if
needed too.




--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton European Way, Southampton SO14
3ZH, UK
  tel  023-8059-7743

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From francoisromain at free.fr  Tue Feb 28 10:50:43 2006
From: francoisromain at free.fr (Romain Francois)
Date: Tue, 28 Feb 2006 10:50:43 +0100
Subject: [R] LaTeX in R graph
In-Reply-To: <1141118845.4404177d8b2cc@webmail.inrets.fr>
References: <1141118845.4404177d8b2cc@webmail.inrets.fr>
Message-ID: <44041CF3.4000907@free.fr>

Le 28.02.2006 10:27, depire at inrets.fr a ??crit :
> Hello,
> I would like to know if it is possible to insert LaTeX typesetting in R output.
> I want to obtain a graph with LaTeX label in order to incorporate it as
> postscript or pdf,
>
> x<-seq(0,1,length=100)
> y<-x*x
> plot(x,y,xlab="$X$",ylab="$X^2$")
>   
Bonjour Alexandre,

There is already a mechanism in R to insert mathematical annotations in 
graphics, see
?plotmath

x<-seq(0,1,length=100)
y<-x*x
plot(x,y,xlab=expression(X),ylab=expression(X^2))


But this is not really LaTeX.

What about creating you graphic with no labels, and then use the LaTeX 
package eso-pic to put your labels where you like with the command 
\AddToShipoutPicture*
Maybe somebody has done something to wrap it all.

Romain


-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
Discover the R Movies Gallery : http://addictedtor.free.fr/movies
+---------------------------------------------------------------+
| Romain FRANCOIS - http://francoisromain.free.fr               |
| Doctorant INRIA Futurs / EDF                                  |
+---------------------------------------------------------------+



From petr.pikal at precheza.cz  Tue Feb 28 10:55:12 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 28 Feb 2006 10:55:12 +0100
Subject: [R] lines() and recycled colours
In-Reply-To: <2CBD2498-21C6-4262-9940-A52E8129E605@soc.soton.ac.uk>
Message-ID: <44042C10.11417.A69AB2@localhost>

Hi

not sure as I do not know actual syntax, but seems to me that in 
type=h there segments are drawn from x axis to x,y values, hence the 
recycling behaviour has some sense.

In other types I wonder if it was really useful to have each segment 
of a line painted by different colour. If this is a case why not use 
segments() directly?

And probably the same applies to lwd, where it would be also strange 
if each segment was different line width?

HTH
Petr


On 28 Feb 2006 at 9:31, Robin Hankin wrote:

To:             	RHelp <r-help at stat.math.ethz.ch>
From:           	Robin Hankin <r.hankin at noc.soton.ac.uk>
Date sent:      	Tue, 28 Feb 2006 09:31:29 +0000
Subject:        	[R] lines() and recycled colours

> Hi
> 
> ?lines says
> 
> 
>       For 'type = "h"', 'col' can be a vector and will be recycled as
>       needed.
> 
> 
> Why doesn't  lines() recycle colours for other types?
> 
> If I type
> 
> 
>  > plot(0:1,0:1,type="n")
>  > lines(runif(11),runif(11),col=c("red","green"))
>  >
> 
> 
> then all ten lines are red, with no warning given.  Is there a reason 
> why colour recycling would be a bad idea in this case?
>   Also, it would be nice if arguments such as lwd
> were recycled if needed too.
> 
> 
> 
> 
> --
> Robin Hankin
> Uncertainty Analyst
> National Oceanography Centre, Southampton
> European Way, Southampton SO14 3ZH, UK
>   tel  023-8059-7743
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From timo.becker at oeaw.ac.at  Tue Feb 28 11:01:26 2006
From: timo.becker at oeaw.ac.at (Timo Becker)
Date: Tue, 28 Feb 2006 11:01:26 +0100
Subject: [R] creating dendrogram from cluster hierarchy
In-Reply-To: <mailman.10.1140001208.21738.r-help@stat.math.ethz.ch>
References: <mailman.10.1140001208.21738.r-help@stat.math.ethz.ch>
Message-ID: <44041F76.90403@oeaw.ac.at>

Dear R users,

I have created data for hierarchical agglomerative cluster analysis 
which consist of the merging pairs and the agglomeration heights, e.g. 
something like

my.merge <- matrix(c(-1,-2,-3,1), ncol=2, byrow=TRUE)
my.height <- c(0.5, 1)

I'd like to plot a corresponding dendrogram but I don't know how to 
convert my data to achieve this.
Is it possible to create a dendrogram object from a cluster hierarchy?

Thanks in advance,
Cheers,
Timo

-- 
Timo Becker
Phonetics
Austrian Academy of Sciences
Acoustics Research Institute



From waeltlmi at fh-albsig.de  Tue Feb 28 11:07:54 2006
From: waeltlmi at fh-albsig.de (waeltlmi@fh-albsig.de)
Date: Tue, 28 Feb 2006 11:07:54 +0100
Subject: [R] 4D stacked column chart, Excel -> R
In-Reply-To: <f8e6ff050602271018t4c2282av999674ad99064959@mail.gmail.com>
References: <20060227175502.M18749@fh-albsig.de>
	<f8e6ff050602271018t4c2282av999674ad99064959@mail.gmail.com>
Message-ID: <20060228100221.M68232@fh-albsig.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060228/9a77b317/attachment.pl

From jonathan.williams at pharmacology.oxford.ac.uk  Tue Feb 28 11:08:45 2006
From: jonathan.williams at pharmacology.oxford.ac.uk (Jonathan Williams)
Date: Tue, 28 Feb 2006 10:08:45 -0000
Subject: [R] ex-Gaussian survival distribution
Message-ID: <NGBBKJEMOMLJFCOIEGCEKEINJPAA.jonathan.williams@pharm.ox.ac.uk>

Dear R-Helpers,

I am hoping to perform survival analyses using the "ex-Gaussian"
distribution.
I understand that the ex-Gaussian is a convolution of exponential and
Gaussian
distributions for survival data.

I checked the "survreg.distributions" help and saw that it is possible to
mix
pre-defined distributions. Am I correct to think that the following code
makes
the ex-Gaussian:-

exGauss=survreg.distributions$exponential
exGauss$name='exGaussian'
exGauss$dist=survreg.distributions$gaussian

Am I further correct to think that I can compare the fits of the ex-Gaussian
and Weibull distributions to the data via:-

fit1=survreg(Surv(response)~1+frailty(unit), data=dat, dist=exGauss)
fit2=survreg(Surv(response)~1+frailty(unit), data=dat, dist='weibull')
anova(fit1, fit2)

Finally, am I further correct to think that the output from this anova means
that
the Weibull distribution fits the data worse than the exGauss distribution
that I
made?

              Terms Resid. Df    -2*LL Test       Df Deviance P(>|Chi|)
1 1 + frailty(unit)  4229.778 63129.46            NA       NA        NA
2 1 + frailty(unit)  4228.020 58426.27    = 1.757815 4703.190         0

Many thanks for your help with these questions. I have a feeling they are
trivial,
but I am a psychiatrist so I need to check that I am not barking up the
wrong tree
(or simply barking...)!

Jonathan Williams

PS why does "weibull" need quotes in the survreg procedure, while exGauss
does not?



From maechler at stat.math.ethz.ch  Tue Feb 28 11:19:47 2006
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Feb 2006 11:19:47 +0100
Subject: [R] creating dendrogram from cluster hierarchy
In-Reply-To: <44041F76.90403@oeaw.ac.at>
References: <mailman.10.1140001208.21738.r-help@stat.math.ethz.ch>
	<44041F76.90403@oeaw.ac.at>
Message-ID: <17412.9155.863739.45920@stat.math.ethz.ch>

>>>>> "Timo" == Timo Becker <timo.becker at oeaw.ac.at>
>>>>>     on Tue, 28 Feb 2006 11:01:26 +0100 writes:

    Timo> Dear R users, I have created data for hierarchical
    Timo> agglomerative cluster analysis which consist of the
    Timo> merging pairs and the agglomeration heights, e.g.
    Timo> something like

    Timo> my.merge <- matrix(c(-1,-2,-3,1), ncol=2, byrow=TRUE)
    Timo> my.height <- c(0.5, 1)

    Timo> I'd like to plot a corresponding dendrogram but I
    Timo> don't know how to convert my data to achieve this.  Is
    Timo> it possible to create a dendrogram object from a
    Timo> cluster hierarchy?

Yes, it is possible.   R does it already with the
as.dendrogram() method for objects of class "hclust".

But I assume you'd also like to know *how* you can do it... ;-)

I'd strongly recommend to take the example of hclust() and have
your function return an object ``like'' the one hclust()
returns.  Then, as.dendrogram( <your object> ) will work.

You have to decide for yourself if your function should return
an object of class "hclust" (which is partly described by
?hclust ), and you use as.dendrogram[.hclust]() directly, 
or rather your function returns a class "hclustTimo" and you
write your own  as.dendrogram.hclustTimo() method.

I'd recommend looking at and using the R's source code, e.g., from 
https://svn.R-project.org/R/trunk/src/library/stats/R/hclust.R and
https://svn.R-project.org/R/trunk/src/library/stats/R/dendrogram.R

Regards,
Martin Maechler, ETH Zurich



From petr.pikal at precheza.cz  Tue Feb 28 11:24:40 2006
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 28 Feb 2006 11:24:40 +0100
Subject: [R] elements in each row of a matrix to the left.
In-Reply-To: <182544D7A3144B42994EEA5662C54E0101A3BA7B@NLDNC105PEX1.ubsw.net>
References: <44035914.4050507@pburns.seanet.com>
Message-ID: <440432F8.25415.C195FB@localhost>

Hi

not a complete solution but

z.f<-matrix(z%in%1, ncol=3)

gives you a matrix of logicals

and

apply(apply(z.f*1, 1,cumsum),2,function(x) sum(x==0))
[1] 0 0 1 2 1 3

shall give you number of values to drop from each row.

Then you maybe could use it to manipulate your z matrix.

HTH
Petr




On 28 Feb 2006 at 9:31, john.gavin at ubs.com wrote:

Date sent:      	Tue, 28 Feb 2006 09:31:51 -0000
From:           	<john.gavin at ubs.com>
To:             	<pburns at pburns.seanet.com>, <Jeff.Laake at noaa.gov>
Copies to:      	r-help at stat.math.ethz.ch
Subject:        	Re: [R] elements in each row of a matrix to the left.

> Hi Patrick/Jeff,
> 
> > Does
> > 
> > t(apply(z, 1, sort, na.last=TRUE))
> > 
> > do what you want?
> 
> Not quite.
> 
> t(apply(z, 1, sort, na.last=TRUE))
> 
>      [,1] [,2] [,3]
> [1,]    1    1   NA
> [2,]    1    1   NA
> [3,]    1    1   NA
> [4,]    1   NA   NA
> [5,]    1   NA   NA
> [6,]   NA   NA   NA
> 
> Row 2 is the problem.
> 
> I dont want to move all NAs to the end of each row.
> I just want to move all of the NAs before the first non-NA element, if
> any, to the end of each row. So in my example, rows 1 and 2 should
> remain unchanged.
> 
> What I have got at the moment is ugly
> 
> shiftLeft <- function(z)
> { x <- as.data.frame(t(z)) # work with cols not rows.
>   ans <- lapply(x, function(xx) 
>   { # get indices of first and last non-NA element
>     ind <- which(!is.na(xx))
>     ind <- ind[c(1, length(ind))]
>     # if all NAs or if first element is non-NA do no work
>     if (any(is.na(ind)) || ind[1] == 1) xx else
>     { temp <- numeric(length(xx)) ; temp[] <- NA
>       # move elements in posns ind[1] to ind[2] to the start
>       temp[1:(ind[2]-ind[1]+1)] <- xx[ind[1]:ind[2]]
>       temp
>     } # if
>   }) # lapply
>   ans <- as.matrix(data.frame(ans))
>   dimnames(ans) <- dimnames(z)
>   t(ans)
> }
> 
> > z ; shiftLeft(z)
>      [,1] [,2] [,3]
> [1,]    1    1   NA
> [2,]    1   NA    1
> [3,]   NA    1    1
> [4,]   NA   NA    1
> [5,]   NA    1   NA
> [6,]   NA   NA   NA
>      [,1] [,2] [,3]
> [1,]    1    1   NA
> [2,]    1   NA    1
> [3,]    1    1   NA
> [4,]    1   NA   NA
> [5,]    1   NA   NA
> [6,]   NA   NA   NA
> 
> I feel that there is probably a shorter vectorised way to do this. In
> general, I have matrices (z) with several thousand rows and and few
> hundred columns so vectorisation would help.
> 
> Regards,
> 
> John.
> 
> 
> > -----Original Message-----
> > From: Patrick Burns [mailto:pburns at pburns.seanet.com]
> > Sent: 27 February 2006 19:55
> > To: Gavin, John
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] elements in each row of a matrix to the left.
> > 
> > John,
> > 
> > Does
> > 
> > t(apply(z, 1, sort, na.last=TRUE))
> > 
> > do what you want?
> > 
> > 
> > Patrick Burns
> > patrick at burns-stat.com
> > +44 (0)20 8525 0696
> > http://www.burns-stat.com
> > (home of S Poetry and "A Guide for the Unwilling S User")
> > 
> > john.gavin at ubs.com wrote:
> > 
> > >Hi,
> > >
> > >Given a matrix like
> > >
> > >(z <- matrix(c(
> > >1, 1, NA, NA, NA, NA,
> > >1,  NA, 1,  NA, 1, NA,
> > >NA, 1, 1,  1,  NA, NA), ncol = 3))
> > >
> > >     [,1] [,2] [,3]
> > >[1,]    1    1   NA
> > >[2,]    1   NA    1
> > >[3,]   NA    1    1
> > >[4,]   NA   NA    1
> > >[5,]   NA    1   NA
> > >[6,]   NA   NA   NA
> > >
> > >is there a vectorised way to produce the output like
> > >
> > >     [,1] [,2] [,3]
> > >[1,]    1    1   NA
> > >[2,]    1   NA    1
> > >[3,]    1    1   NA
> > >[4,]    1   NA   NA
> > >[5,]    1   NA   NA
> > >[6,]   NA   NA   NA
> > >
> > >That is, given an n by m matrix, and going row by row, 
> > >if the first non-NA element is in column k
> > >I want to move elements in columns from k to m
> > >to columns 1 to m-k+1 with NAs filling in from 
> > >m-k+2 to m.
> > >
> > >  
> > >
> > >>version
> > >>    
> > >>
> > >         _              
> > >platform i386-pc-mingw32
> > >arch     i386           
> > >os       mingw32        
> > >system   i386, mingw32  
> > >status                  
> > >major    2              
> > >minor    2.1            
> > >year     2005           
> > >month    12             
> > >day      20             
> > >svn rev  36812          
> > >language R        
> > >
> > >Regards,
> > >
> > >John.
> > >
> > >John Gavin <john.gavin at ubs.com>,
> > >Quantitative Risk Control,
> > >UBS Investment Bank, 6th floor, 
> > >100 Liverpool St., London EC2M 2RH, UK.
> > >Phone +44 (0) 207 567 4289
> > >Fax   +44 (0) 207 568 5352
> > >
> > >Visit our website at http://www.ubs.com
> > >
> > >This message contains confidential information and is 
> > intend...{{dropped}}
> > >
> > >______________________________________________
> > >R-help at stat.math.ethz.ch mailing list
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> >
> >
> >  
> >
> 
> 
> Visit our website at http://www.ubs.com
> 
> This message contains confidential information and is\ > i...{{dropped}}



From pburns at pburns.seanet.com  Tue Feb 28 11:27:45 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 28 Feb 2006 10:27:45 +0000
Subject: [R] elements in each row of a matrix to the left.
In-Reply-To: <182544D7A3144B42994EEA5662C54E0101A3BA7B@NLDNC105PEX1.ubsw.net>
References: <182544D7A3144B42994EEA5662C54E0101A3BA7B@NLDNC105PEX1.ubsw.net>
Message-ID: <440425A1.5000104@pburns.seanet.com>

Okay, I think this does the requested operation:

 > single.shift
function (x)
{
        r <- rle(is.na(x))
        if(!r$values[1]) return(x)
        num <- r$length[1]
        c(x[-1:-num], rep(NA, num))
}
 > t(apply(z, 1, single.shift))


john.gavin at ubs.com wrote:

>Hi Patrick/Jeff,
>
>  
>
>>Does
>>
>>t(apply(z, 1, sort, na.last=TRUE))
>>
>>do what you want?
>>    
>>
>
>Not quite.
>
>t(apply(z, 1, sort, na.last=TRUE))
>
>     [,1] [,2] [,3]
>[1,]    1    1   NA
>[2,]    1    1   NA
>[3,]    1    1   NA
>[4,]    1   NA   NA
>[5,]    1   NA   NA
>[6,]   NA   NA   NA
>
>Row 2 is the problem.
>
>I dont want to move all NAs to the end of each row.
>I just want to move all of the NAs before the first non-NA element,
>if any, to the end of each row.
>So in my example, rows 1 and 2 should remain unchanged.
>
>What I have got at the moment is ugly
>
>shiftLeft <- function(z)
>{ x <- as.data.frame(t(z)) # work with cols not rows.
>  ans <- lapply(x, function(xx) 
>  { # get indices of first and last non-NA element
>    ind <- which(!is.na(xx))
>    ind <- ind[c(1, length(ind))]
>    # if all NAs or if first element is non-NA do no work
>    if (any(is.na(ind)) || ind[1] == 1) xx else
>    { temp <- numeric(length(xx)) ; temp[] <- NA
>      # move elements in posns ind[1] to ind[2] to the start
>      temp[1:(ind[2]-ind[1]+1)] <- xx[ind[1]:ind[2]]
>      temp
>    } # if
>  }) # lapply
>  ans <- as.matrix(data.frame(ans))
>  dimnames(ans) <- dimnames(z)
>  t(ans)
>}
>
>  
>
>>z ; shiftLeft(z)
>>    
>>
>     [,1] [,2] [,3]
>[1,]    1    1   NA
>[2,]    1   NA    1
>[3,]   NA    1    1
>[4,]   NA   NA    1
>[5,]   NA    1   NA
>[6,]   NA   NA   NA
>     [,1] [,2] [,3]
>[1,]    1    1   NA
>[2,]    1   NA    1
>[3,]    1    1   NA
>[4,]    1   NA   NA
>[5,]    1   NA   NA
>[6,]   NA   NA   NA
>
>I feel that there is probably a shorter vectorised way to do this.
>In general, I have matrices (z) with several thousand rows and 
>and few hundred columns so vectorisation would help.
>
>Regards,
>
>John.
>
>
>  
>
>>-----Original Message-----
>>From: Patrick Burns [mailto:pburns at pburns.seanet.com]
>>Sent: 27 February 2006 19:55
>>To: Gavin, John
>>Cc: r-help at stat.math.ethz.ch
>>Subject: Re: [R] elements in each row of a matrix to the left.
>>
>>John,
>>
>>Does
>>
>>t(apply(z, 1, sort, na.last=TRUE))
>>
>>do what you want?
>>
>>
>>Patrick Burns
>>patrick at burns-stat.com
>>+44 (0)20 8525 0696
>>http://www.burns-stat.com
>>(home of S Poetry and "A Guide for the Unwilling S User")
>>
>>john.gavin at ubs.com wrote:
>>
>>    
>>
>>>Hi,
>>>
>>>Given a matrix like
>>>
>>>(z <- matrix(c(
>>>1, 1, NA, NA, NA, NA,
>>>1,  NA, 1,  NA, 1, NA,
>>>NA, 1, 1,  1,  NA, NA), ncol = 3))
>>>
>>>    [,1] [,2] [,3]
>>>[1,]    1    1   NA
>>>[2,]    1   NA    1
>>>[3,]   NA    1    1
>>>[4,]   NA   NA    1
>>>[5,]   NA    1   NA
>>>[6,]   NA   NA   NA
>>>
>>>is there a vectorised way to produce the output like
>>>
>>>    [,1] [,2] [,3]
>>>[1,]    1    1   NA
>>>[2,]    1   NA    1
>>>[3,]    1    1   NA
>>>[4,]    1   NA   NA
>>>[5,]    1   NA   NA
>>>[6,]   NA   NA   NA
>>>
>>>That is, given an n by m matrix, and going row by row, 
>>>if the first non-NA element is in column k
>>>I want to move elements in columns from k to m
>>>to columns 1 to m-k+1 with NAs filling in from 
>>>m-k+2 to m.
>>>
>>> 
>>>
>>>      
>>>
>>>>version
>>>>   
>>>>
>>>>        
>>>>
>>>        _              
>>>platform i386-pc-mingw32
>>>arch     i386           
>>>os       mingw32        
>>>system   i386, mingw32  
>>>status                  
>>>major    2              
>>>minor    2.1            
>>>year     2005           
>>>month    12             
>>>day      20             
>>>svn rev  36812          
>>>language R        
>>>
>>>Regards,
>>>
>>>John.
>>>
>>>John Gavin <john.gavin at ubs.com>,
>>>Quantitative Risk Control,
>>>UBS Investment Bank, 6th floor, 
>>>100 Liverpool St., London EC2M 2RH, UK.
>>>Phone +44 (0) 207 567 4289
>>>Fax   +44 (0) 207 568 5352
>>>
>>>Visit our website at http://www.ubs.com
>>>
>>>This message contains confidential information and is 
>>>      
>>>
>>intend...{{dropped}}
>>    
>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! 
>>>      
>>>
>http://www.R-project.org/posting-guide.html
>  
>
>>
>> 
>>
>>    
>>
>
>
>Visit our website at http://www.ubs.com
>
>This message contains confidential information and is intended only 
>for the individual named.  If you are not the named addressee you 
>should not disseminate, distribute or copy this e-mail.  Please 
>notify the sender immediately by e-mail if you have received this 
>e-mail by mistake and delete this e-mail from your system.
>
>E-mail transmission cannot be guaranteed to be secure or error-free 
>as information could be intercepted, corrupted, lost, destroyed, 
>arrive late or incomplete, or contain viruses.  The sender therefore 
>does not accept liability for any errors or omissions in the contents 
>of this message which arise as a result of e-mail transmission.  If 
>verification is required please request a hard-copy version.  This 
>message is provided for informational purposes and should not be 
>construed as a solicitation or offer to buy or sell any securities or 
>related financial instruments.
>
>
>
>
>  
>



From d_pleydell at yahoo.com  Tue Feb 28 11:47:13 2006
From: d_pleydell at yahoo.com (David Pleydell)
Date: Tue, 28 Feb 2006 10:47:13 +0000 (GMT)
Subject: [R] Illegal Instruction
Message-ID: <20060228104713.81009.qmail@web52807.mail.yahoo.com>

I am running Debian Etch on a dual Xeon 64 bit Dell
Precision with the latest versions of R and
RandomFields.

I am unable to run the first example in ?GaussRF (in
RandomFields).

The bug occurs when GaussRF runs the line 

error <- InitSimulateRF(x = x, y = y, z = z, T = T,
grid = grid, model = model, param = param, trend =
trend, method = method, register = register,
gridtriple = gridtriple, distribution = "Gauss")

This line crashes down the R session with the message
"Illegal Instruction".

I re-started R using R -d gdb and retried the example,
the crash message was now

Program received signal SIGILL, Illegal instruction.
0x00002aaaab31d6af in ATL_dJIK56x56x56TN56x56x0_a1_b0
()
   from /usr/lib/atlas/libblas.so.3

I then reinstalled atlas3-base, refblas3, and lapack3
from the sid repository. But this failled to improve
matters.

What should I try next?

David



From d_pleydell at yahoo.com  Tue Feb 28 11:59:07 2006
From: d_pleydell at yahoo.com (David Pleydell)
Date: Tue, 28 Feb 2006 10:59:07 +0000 (GMT)
Subject: [R] Re> Illegal Instrunction
Message-ID: <20060228105907.36782.qmail@web52815.mail.yahoo.com>

OK I found the problem.

locate libblas.so.3 showed there were two such files,
one in /usr/lib/, the other in /usr/lib/atlas/

removing the atlas installation cured the bug.

Not sure what I should do if I later find that I need
atlas for some reason. 

cheers
David



From inchausti at cebc.cnrs.fr  Tue Feb 28 12:03:47 2006
From: inchausti at cebc.cnrs.fr (Pablo Inchausti)
Date: Tue, 28 Feb 2006 12:03:47 +0100
Subject: [R] obtaining means/SD after fitting a mixed model
Message-ID: <5.0.2.1.2.20060228120233.00a90be0@194.254.155.1>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060228/596e29a1/attachment.pl

From john.gavin at ubs.com  Tue Feb 28 12:10:33 2006
From: john.gavin at ubs.com (john.gavin@ubs.com)
Date: Tue, 28 Feb 2006 11:10:33 -0000
Subject: [R] elements in each row of a matrix to the left.
In-Reply-To: <440425A1.5000104@pburns.seanet.com>
Message-ID: <182544D7A3144B42994EEA5662C54E0101A3BA80@NLDNC105PEX1.ubsw.net>

Hi Patrick,

Yes, that works. Thanks for your time.

Regards,

John.

> -----Original Message-----
> From: Patrick Burns [mailto:pburns at pburns.seanet.com]
> Sent: 28 February 2006 10:28
> To: Gavin, John
> Cc: Jeff.Laake at noaa.gov; r-help at stat.math.ethz.ch
> Subject: Re: [R] elements in each row of a matrix to the left.
> 
> 
> Okay, I think this does the requested operation:
> 
>  > single.shift
> function (x)
> {
>         r <- rle(is.na(x))
>         if(!r$values[1]) return(x)
>         num <- r$length[1]
>         c(x[-1:-num], rep(NA, num))
> }
>  > t(apply(z, 1, single.shift))
> 
> 
> john.gavin at ubs.com wrote:
> 
> >Hi Patrick/Jeff,
> >
> >  
> >
> >>Does
> >>
> >>t(apply(z, 1, sort, na.last=TRUE))
> >>
> >>do what you want?
> >>    
> >>
> >
> >Not quite.
> >
> >t(apply(z, 1, sort, na.last=TRUE))
> >
> >     [,1] [,2] [,3]
> >[1,]    1    1   NA
> >[2,]    1    1   NA
> >[3,]    1    1   NA
> >[4,]    1   NA   NA
> >[5,]    1   NA   NA
> >[6,]   NA   NA   NA
> >
> >Row 2 is the problem.
> >
> >I dont want to move all NAs to the end of each row.
> >I just want to move all of the NAs before the first non-NA element,
> >if any, to the end of each row.
> >So in my example, rows 1 and 2 should remain unchanged.
> >
> >What I have got at the moment is ugly
> >
> >shiftLeft <- function(z)
> >{ x <- as.data.frame(t(z)) # work with cols not rows.
> >  ans <- lapply(x, function(xx) 
> >  { # get indices of first and last non-NA element
> >    ind <- which(!is.na(xx))
> >    ind <- ind[c(1, length(ind))]
> >    # if all NAs or if first element is non-NA do no work
> >    if (any(is.na(ind)) || ind[1] == 1) xx else
> >    { temp <- numeric(length(xx)) ; temp[] <- NA
> >      # move elements in posns ind[1] to ind[2] to the start
> >      temp[1:(ind[2]-ind[1]+1)] <- xx[ind[1]:ind[2]]
> >      temp
> >    } # if
> >  }) # lapply
> >  ans <- as.matrix(data.frame(ans))
> >  dimnames(ans) <- dimnames(z)
> >  t(ans)
> >}
> >
> >  
> >
> >>z ; shiftLeft(z)
> >>    
> >>
> >     [,1] [,2] [,3]
> >[1,]    1    1   NA
> >[2,]    1   NA    1
> >[3,]   NA    1    1
> >[4,]   NA   NA    1
> >[5,]   NA    1   NA
> >[6,]   NA   NA   NA
> >     [,1] [,2] [,3]
> >[1,]    1    1   NA
> >[2,]    1   NA    1
> >[3,]    1    1   NA
> >[4,]    1   NA   NA
> >[5,]    1   NA   NA
> >[6,]   NA   NA   NA
> >
> >I feel that there is probably a shorter vectorised way to do this.
> >In general, I have matrices (z) with several thousand rows and 
> >and few hundred columns so vectorisation would help.
> >
> >Regards,
> >
> >John.
> >
> >
> >  
> >
> >>-----Original Message-----
> >>From: Patrick Burns [mailto:pburns at pburns.seanet.com]
> >>Sent: 27 February 2006 19:55
> >>To: Gavin, John
> >>Cc: r-help at stat.math.ethz.ch
> >>Subject: Re: [R] elements in each row of a matrix to the left.
> >>
> >>John,
> >>
> >>Does
> >>
> >>t(apply(z, 1, sort, na.last=TRUE))
> >>
> >>do what you want?
> >>
> >>
> >>Patrick Burns
> >>patrick at burns-stat.com
> >>+44 (0)20 8525 0696
> >>http://www.burns-stat.com
> >>(home of S Poetry and "A Guide for the Unwilling S User")
> >>
> >>john.gavin at ubs.com wrote:
> >>
> >>    
> >>
> >>>Hi,
> >>>
> >>>Given a matrix like
> >>>
> >>>(z <- matrix(c(
> >>>1, 1, NA, NA, NA, NA,
> >>>1,  NA, 1,  NA, 1, NA,
> >>>NA, 1, 1,  1,  NA, NA), ncol = 3))
> >>>
> >>>    [,1] [,2] [,3]
> >>>[1,]    1    1   NA
> >>>[2,]    1   NA    1
> >>>[3,]   NA    1    1
> >>>[4,]   NA   NA    1
> >>>[5,]   NA    1   NA
> >>>[6,]   NA   NA   NA
> >>>
> >>>is there a vectorised way to produce the output like
> >>>
> >>>    [,1] [,2] [,3]
> >>>[1,]    1    1   NA
> >>>[2,]    1   NA    1
> >>>[3,]    1    1   NA
> >>>[4,]    1   NA   NA
> >>>[5,]    1   NA   NA
> >>>[6,]   NA   NA   NA
> >>>
> >>>That is, given an n by m matrix, and going row by row, 
> >>>if the first non-NA element is in column k
> >>>I want to move elements in columns from k to m
> >>>to columns 1 to m-k+1 with NAs filling in from 
> >>>m-k+2 to m.
> >>>
> >>> 
> >>>
> >>>      
> >>>
> >>>>version
> >>>>   
> >>>>
> >>>>        
> >>>>
> >>>        _              
> >>>platform i386-pc-mingw32
> >>>arch     i386           
> >>>os       mingw32        
> >>>system   i386, mingw32  
> >>>status                  
> >>>major    2              
> >>>minor    2.1            
> >>>year     2005           
> >>>month    12             
> >>>day      20             
> >>>svn rev  36812          
> >>>language R        
> >>>
> >>>Regards,
> >>>
> >>>John.
> >>>
> >>>John Gavin <john.gavin at ubs.com>,
> >>>Quantitative Risk Control,
> >>>UBS Investment Bank, 6th floor, 
> >>>100 Liverpool St., London EC2M 2RH, UK.
> >>>Phone +44 (0) 207 567 4289
> >>>Fax   +44 (0) 207 568 5352
> >>>
> >>>Visit our website at http://www.ubs.com
> >>>
> >>>This message contains confidential information and is 
> >>>      
> >>>
> >>intend...{{dropped}}
> >>    
> >>
> >>>______________________________________________
> >>>R-help at stat.math.ethz.ch mailing list
> >>>https://stat.ethz.ch/mailman/listinfo/r-help
> >>>PLEASE do read the posting guide! 
> >>>      
> >>>
> >http://www.R-project.org/posting-guide.html
> >  
> >
> >>
> >> 
> >>
> >>    
> >>
> >
> >
> >Visit our website at http://www.ubs.com
> >
> >This message contains confidential information and is intended only 
> >for the individual named.  If you are not the named addressee you 
> >should not disseminate, distribute or copy this e-mail.  Please 
> >notify the sender immediately by e-mail if you have received this 
> >e-mail by mistake and delete this e-mail from your system.
> >
> >E-mail transmission cannot be guaranteed to be secure or error-free 
> >as information could be intercepted, corrupted, lost, destroyed, 
> >arrive late or incomplete, or contain viruses.  The sender therefore 
> >does not accept liability for any errors or omissions in the 
> contents 
> >of this message which arise as a result of e-mail transmission.  If 
> >verification is required please request a hard-copy version.  This 
> >message is provided for informational purposes and should not be 
> >construed as a solicitation or offer to buy or sell any 
> securities or 
> >related financial instruments.
> >
> >
> >
> >
> >  
> >
> 
> 

Visit our website at http://www.ubs.com

This message contains confidential information and is intend...{{dropped}}



From andy_liaw at merck.com  Tue Feb 28 13:14:29 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 28 Feb 2006 07:14:29 -0500
Subject: [R] does svm have a CV to obtain the best "cost" parameter?
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED88E@usctmx1106.merck.com>

From: Michael
> 
> Hi all,
> 
> I am using the "svm" command in the e1071 package.
> 
> Does it have an automatic way of setting the "cost" parameter?

See ?best.svm in that package.
 
> I changed a few values for the "cost" parameter but I hope there is a
> systematic way of obtaining the best "cost" value.
> 
> I noticed that there is a "cross" (Cross validation) 
> parameter in the "svm"
> function.
> 
> But I did not see how it can be used to optimize the "cost" parameter.
> 
> By the way, what does a 0 training error and a high testing 
> error mean?
> Varying "cross=5", or "cross=10", etc. does not change the 
> training error
> and testing error at all. How to improve?

Overfitting, which varying different validation method will not solve.

Andy
 
> Thanks a lot!
> 
> M.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>



From ligges at statistik.uni-dortmund.de  Tue Feb 28 13:59:52 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 28 Feb 2006 13:59:52 +0100 (CET)
Subject: [R] prepared query with RODBC ?
In-Reply-To: <27d1e6020602270638u55cf0687na67c76a78b6cdf66@mail.gmail.com>
References: <27d1e6020602270638u55cf0687na67c76a78b6cdf66@mail.gmail.com>
Message-ID: <Pine.LNX.4.58.0602281359170.24524@amadeus.statistik.uni-dortmund.de>



On Mon, 27 Feb 2006, Laurent Gautier wrote:

> Dear List,
> 
> Would anyone know how to perform prepared queries with ROBC ?
> I had a shot with some of the internal (non-exported) functions of the package
> but ended up with a segfault, so I prefer asking around before
> experimenting further...


People might be able to help if you are more specific. See the posting 
guide.

Uwe Ligges
 
> Thanks,
> 
> 
> 
> Laurent
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Tue Feb 28 14:01:43 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 28 Feb 2006 14:01:43 +0100 (CET)
Subject: [R] relative referencing for filenames &etc
In-Reply-To: <20060227201201.51950.qmail@web37107.mail.mud.yahoo.com>
References: <20060227201201.51950.qmail@web37107.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.58.0602281401110.24524@amadeus.statistik.uni-dortmund.de>



On Mon, 27 Feb 2006, Greg Tarpinian wrote:

> BACKGROUND:
> I use SAS on a daily basis and one of its most powerful features in a
> production environment is the use of LIBNAME and FILEREF statements, e.g.:
> 
> 
> PROC PRINTTO LOG = "&LOGDIR.\data processing.log" NEW;
> RUN;
> PROC IMPORT 
> 	DATAFILE= "&DATADIR.\blah.xls"
> 	OUT = TEMP
> 	DBMS = EXCEL REPLACE;
>     SHEET = "Sheet1"; 
>     GETNAMES = YES;
> RUN;
> 
> 
> Properly setting up SAS Shortcuts in the WinXP environment, or (say)
> the UNIX equivalent of batch files in the UNIX environment will cause
> SAS to autoexecute (say) an INIT.SAS file that automatically assigns
> the LOGDIR and DATADIR macro variables used above.  This is extremely
> convenient because it makes the SAS code more portable from project to
> project.
> 
> 
> MY QUESTION:
> Is it possible to use this kind of relative file and directory referencing
> from within R?

Perhaps you are looking for ?setwd

Uwe ligges
 
> 
> Kind regards,
> 
> 
>       Greg
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From timo.becker at oeaw.ac.at  Tue Feb 28 14:15:32 2006
From: timo.becker at oeaw.ac.at (Timo Becker)
Date: Tue, 28 Feb 2006 14:15:32 +0100
Subject: [R] creating dendrogram from cluster hierarchy
In-Reply-To: <17412.9155.863739.45920@stat.math.ethz.ch>
References: <mailman.10.1140001208.21738.r-help@stat.math.ethz.ch>	<44041F76.90403@oeaw.ac.at>
	<17412.9155.863739.45920@stat.math.ethz.ch>
Message-ID: <44044CF4.1070605@oeaw.ac.at>

Martin Maechler schrieb:

>>>>>>"Timo" == Timo Becker <timo.becker at oeaw.ac.at>
>>>>>>    on Tue, 28 Feb 2006 11:01:26 +0100 writes:
>>>>>>            
>>>>>>
>
>    Timo> Dear R users, I have created data for hierarchical
>    Timo> agglomerative cluster analysis which consist of the
>    Timo> merging pairs and the agglomeration heights, e.g.
>    Timo> something like
>
>    Timo> my.merge <- matrix(c(-1,-2,-3,1), ncol=2, byrow=TRUE)
>    Timo> my.height <- c(0.5, 1)
>
>    Timo> I'd like to plot a corresponding dendrogram but I
>    Timo> don't know how to convert my data to achieve this.  Is
>    Timo> it possible to create a dendrogram object from a
>    Timo> cluster hierarchy?
>
>Yes, it is possible.   R does it already with the
>as.dendrogram() method for objects of class "hclust".
>  
>
Unfortunately the hierarchy is created by another program than R. This 
is the reason why the only available data for the hclust or dendrogram 
object creation are the merge-matrix and the agglomeration heights. So 
as.dendrogram() does not work here.

>But I assume you'd also like to know *how* you can do it... ;-)
>
>I'd strongly recommend to take the example of hclust() and have
>your function return an object ``like'' the one hclust()
>returns.  Then, as.dendrogram( <your object> ) will work.
>
>You have to decide for yourself if your function should return
>an object of class "hclust" (which is partly described by
>?hclust ), and you use as.dendrogram[.hclust]() directly, 
>or rather your function returns a class "hclustTimo" and you
>write your own  as.dendrogram.hclustTimo() method.
>
>I'd recommend looking at and using the R's source code, e.g., from 
>https://svn.R-project.org/R/trunk/src/library/stats/R/hclust.R and
>https://svn.R-project.org/R/trunk/src/library/stats/R/dendrogram.R
>
>Regards,
>Martin Maechler, ETH Zurich
>
>  
>
I adapted the source code of hclust.R and a quick (and VERY dirty) 
solution is as follows:

hierarchy2dendrogram <- function(hierarchy) {
 tree <- list(merge = hierarchy[,1:2],
             height= hierarchy[,3],
             order = seq(1:(dim(hierarchy)[1]+1)),
         method=NULL,
         call = match.call(),
         dist.method = "whatever")
  class(tree) <- "hclust"
  return(tree)
}
my.merge <- matrix(c(-1,-2,-3,1), ncol=2, byrow=TRUE)
my.height <- c(0.5, 1)
my.hierarchy <- cbind(my.merge, my.height)
my.hclust.object <- hierarchy2dendrogram(my.hierarchy)
plot(my.hclust.object)

Perhaps there exists a "cleaner" solution which also returns the optimal 
order (if I am right the ordering is accomplished by the Fortran 
function "hcass2") but the above works fine for me.

Thanks a lot and best regards,
Timo

-- 
Timo Becker
Phonetics
Austrian Academy of Sciences
Acoustics Research Institute



From ronggui.huang at gmail.com  Tue Feb 28 14:18:07 2006
From: ronggui.huang at gmail.com (ronggui)
Date: Tue, 28 Feb 2006 21:18:07 +0800
Subject: [R] How to do it without for loops?
Message-ID: <38b9f0350602280518t777fa395o@mail.gmail.com>

This is the code:

x<-matrix(rnorm(20),5)
y<-list()
for (i in seq(nrow(x))) y[[i]]<-t(x[i,,drop=F])%*%x[i,,drop=F]
y[[1]]+y[[2]]+y[[3]]+y[[4]]+y[[5]]

How can I do it without using for loops?
Thank you in advance!
--
ronggui
Deparment of Sociology
Fudan University



From ripley at stats.ox.ac.uk  Tue Feb 28 14:21:04 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Feb 2006 13:21:04 +0000 (GMT)
Subject: [R] Re> Illegal Instrunction
In-Reply-To: <20060228105907.36782.qmail@web52815.mail.yahoo.com>
References: <20060228105907.36782.qmail@web52815.mail.yahoo.com>
Message-ID: <Pine.LNX.4.64.0602281316340.2300@gannet.stats.ox.ac.uk>

This is a Debian issue, not an R issue.

Almost certainly you are running an ATLAS tuned on a machine other than 
your own.

ATLAS is designed to be tuned on the target machine, which is easy to do 
if you install it from the sources.  Debian provides pre-built versions, 
but these need to be matched to the actual CPU and it seems the matching 
has gone wrong for you.

(On RedHat systems I have seen precisely this when R built with an ATLAS 
on a P4 was run on a PIII, by someone who mounted the wrong file system.)

On Tue, 28 Feb 2006, David Pleydell wrote:

> OK I found the problem.
>
> locate libblas.so.3 showed there were two such files,
> one in /usr/lib/, the other in /usr/lib/atlas/
>
> removing the atlas installation cured the bug.
>
> Not sure what I should do if I later find that I need
> atlas for some reason.
>
> cheers
> David
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Feb 28 14:25:49 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Feb 2006 13:25:49 +0000 (GMT)
Subject: [R] relative referencing for filenames &etc
In-Reply-To: <Pine.LNX.4.58.0602281401110.24524@amadeus.statistik.uni-dortmund.de>
References: <20060227201201.51950.qmail@web37107.mail.mud.yahoo.com>
	<Pine.LNX.4.58.0602281401110.24524@amadeus.statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.64.0602281322090.2300@gannet.stats.ox.ac.uk>

On Tue, 28 Feb 2006, Uwe Ligges wrote:

>
>
> On Mon, 27 Feb 2006, Greg Tarpinian wrote:
>
>> BACKGROUND:
>> I use SAS on a daily basis and one of its most powerful features in a
>> production environment is the use of LIBNAME and FILEREF statements, e.g.:
>>
>>
>> PROC PRINTTO LOG = "&LOGDIR.\data processing.log" NEW;
>> RUN;
>> PROC IMPORT
>> 	DATAFILE= "&DATADIR.\blah.xls"
>> 	OUT = TEMP
>> 	DBMS = EXCEL REPLACE;
>>     SHEET = "Sheet1";
>>     GETNAMES = YES;
>> RUN;
>>
>>
>> Properly setting up SAS Shortcuts in the WinXP environment, or (say)
>> the UNIX equivalent of batch files in the UNIX environment will cause
>> SAS to autoexecute (say) an INIT.SAS file that automatically assigns
>> the LOGDIR and DATADIR macro variables used above.  This is extremely
>> convenient because it makes the SAS code more portable from project to
>> project.
>>
>>
>> MY QUESTION:
>> Is it possible to use this kind of relative file and directory referencing
>> from within R?
>
> Perhaps you are looking for ?setwd

Another idea is to use environment variables.  So if in an R function I 
have

     xls_file <- file.path(Sys.getenv("DATADIR"), "blah.xls")

I can R run from a shortcut, appending DATADIR=J:/foo/bar to the command 
line.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Matthias.Templ at statistik.gv.at  Tue Feb 28 14:36:19 2006
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Tue, 28 Feb 2006 14:36:19 +0100
Subject: [R] How to do it without for loops?
Message-ID: <83536658864BC243BE3C06D7E936ABD5027BAE8E@xchg1.statistik.local>

Hello,

One solution is:

lapply(1:nrow(x), function(i){ t(x[i,,drop=FALSE]) %*% x[i,,drop=FALSE]
})

Best,
Matthias

> 
> This is the code:
> 
> x<-matrix(rnorm(20),5)
> y<-list()
> for (i in seq(nrow(x))) y[[i]]<-t(x[i,,drop=F])%*%x[i,,drop=F]
> y[[1]]+y[[2]]+y[[3]]+y[[4]]+y[[5]]
> 
> How can I do it without using for loops?
> Thank you in advance!
> --
> ronggui
> Deparment of Sociology
> Fudan University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read 
> the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Tue Feb 28 14:39:51 2006
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 28 Feb 2006 14:39:51 +0100 (CET)
Subject: [R] How to do it without for loops?
In-Reply-To: <38b9f0350602280518t777fa395o@mail.gmail.com>
References: <38b9f0350602280518t777fa395o@mail.gmail.com>
Message-ID: <Pine.LNX.4.58.0602281439420.26154@amadeus.statistik.uni-dortmund.de>



On Tue, 28 Feb 2006, ronggui wrote:

> This is the code:
> 
> x<-matrix(rnorm(20),5)
> y<-list()
> for (i in seq(nrow(x))) y[[i]]<-t(x[i,,drop=F])%*%x[i,,drop=F]
> y[[1]]+y[[2]]+y[[3]]+y[[4]]+y[[5]]
> 
> How can I do it without using for loops?

 crossprod(x)

Uwe Ligges

> Thank you in advance!
> --
> ronggui
> Deparment of Sociology
> Fudan University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Tue Feb 28 14:41:36 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Feb 2006 13:41:36 +0000 (GMT)
Subject: [R] Different deviance residuals in a (similar?!?) glm example
In-Reply-To: <8B08A3A1EA7AAC41BE24C750338754E6C0C560@HERMES.demogr.mpg.de>
References: <8B08A3A1EA7AAC41BE24C750338754E6C0C560@HERMES.demogr.mpg.de>
Message-ID: <Pine.LNX.4.64.0602281330560.2300@gannet.stats.ox.ac.uk>

This is a Poisson regression.  You cannot just multiply counts by 10 and 
have a valid sample from a Poisson distribution with 10x the mean.  So the 
example (and the calculations below) make zero statistical sense.

For a poisson() family,

$dev.resids
function (y, mu, wt)
2 * wt * (y * log(ifelse(y == 0, 1, y/mu)) - (y - mu))

So if you multiply the counts by 10 and change the offset to multiply the 
mu by 10, (y - log(y/mu) - (y - mu)) is multiplied by 10.  Hence the 
deviance residuals are scaled by sqrt(10), and res1/res is sqrt(10).

> plot(const.a, const.b, pch=16)
> lines(const.a, 1/sqrt(const.a))

indicates a perfect fit.

On Mon, 27 Feb 2006, Camarda, Carlo Giovanni wrote:

> Dear R-users,
> I would like to show you a simple example that gives an overview of one
> of my current issue.
> Although my working setting implies a different parametric model (which
> cannot be framed in the glm), I guess that what I'll get from the
> following example it would help for the next steps.
> Anyway here it is.
> Firstly I simulated from a series of exposures, a series of deaths
> (given a model, Gompertz, and a probability distribution, Poisson). Then
> a multiply both deaths and exposures by a constant. Finally I fitted
> with glm the simulated data sets and I compared the deviance residuals.
> They're different by a certain constant, but I could not get a
> meaningful relationship between the used constants (a scatter plot of
> them is given at the end).
> The following example tried to be as completed as possible and I hope
> that it will be clearer than my previous words.
> Thanks,
> Carlo Giovanni Camarda
>
> #### simulation procedure
> age <- 50:100 # time range
> # parameters
> alpha.sim <- 0.00005
> beta.sim <- 0.1
> # simulated hazard from a Gompertz
> hazard.sim <- alpha.sim*(exp(beta.sim*age))
> # first dataset
> exposures <- c(4748, 4461, 4473, 4326, 4259, 4219, 4049, 3965, 3801,
> 3818, 3670, 3521, 3537,
>               3482, 3347, 3180, 3100, 2890, 2755, 2622, 2530, 2502,
> 2293, 2216, 1986, 1875,
>               1693, 1550, 1395, 1295, 1104, 952, 792, 755, 726, 608,
> 523, 419, 338,
>               246, 205, 148, 112, 75, 52, 32, 23, 15, 7, 6, 3) # just
> as example
> deaths.sim <- rpois(length(age), exposures*hazard.sim) # simulating
> deaths from a poisson distribution (Brillinger, 1986)
> my.offset  <- log(exposures) # offset for the poisson regression
> # new dataset: decupleing the sample size
> deaths.sim1 <- deaths.sim * 10
> exposures1  <- exposures  * 10
> my.offset1  <- log(exposures1)
> # fitting the first dataset
> fit <- glm(formula = deaths.sim ~ age + offset(my.offset),
>           family = poisson(link = "log"))
> res <- residuals(fit, type="deviance")
> # fitting the new dataset
> fit1 <- glm(formula = deaths.sim1 ~ age + offset(my.offset1),
>            family = poisson(link = "log"))
> res1 <- residuals(fit1, type="deviance")
> # estimating hazard
> hazard.act <- deaths.sim/exposures # == deaths.sim1/exposures1
> hazard.fit <- predict(fit, type="response") / exposures
> hazard.fit1 <- predict(fit1, type="response") / exposures1
> # plotting log-hazard
> plot(age, log(hazard.sim), cex=1.2)
> lines(age, log(hazard.act), col="red", lwd=2)
> lines(age, log(hazard.fit), col="blue", lwd=2, lty=2)
> lines(age, log(hazard.fit1), col="green", lwd=2, lty=3)
> all(round(hazard.fit,5)==round(hazard.fit1,5)) ## TRUE
> # plotting residuals
> plot(age, res, cex=1.2, lwd=2, ylim=range(res, res1))
> points(age, res1, col="red", cex=1.2, lwd=2, pch=2)
> all(round(res,5)==round(res1,5)) ## FALSE
> # looking at the ratio
> ratio <- (res/res1)[1]
> ratio
> all(round(res,10)==round(res1*ratio,10))
> # here the scatterplot resid-ratios vs multiplier-constant
> const.a <- c(1:16) # constants which I tried to multiply by
> const.b <-
> c(1,0.7071068,0.5773503,0.5,0.4472136,0.4082483,0.3779645,0.3535534, #
> ratio between the deviance residuals
>
> 0.3333333,0.3162278,0.3015113,0.2886751,0.2773501,0.2672612,0.2581989,0.
> 25)
> plot(const.a, const.b, pch=16)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at gmail.com  Tue Feb 28 14:43:15 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 28 Feb 2006 08:43:15 -0500
Subject: [R] How to do it without for loops?
In-Reply-To: <38b9f0350602280518t777fa395o@mail.gmail.com>
References: <38b9f0350602280518t777fa395o@mail.gmail.com>
Message-ID: <971536df0602280543i4c848426v249bd9c74c1897be@mail.gmail.com>

Try:

crossprod(x)

or

t(x) %*% x

On 2/28/06, ronggui <ronggui.huang at gmail.com> wrote:
> This is the code:
>
> x<-matrix(rnorm(20),5)
> y<-list()
> for (i in seq(nrow(x))) y[[i]]<-t(x[i,,drop=F])%*%x[i,,drop=F]
> y[[1]]+y[[2]]+y[[3]]+y[[4]]+y[[5]]
>
> How can I do it without using for loops?
> Thank you in advance!
> --
> ronggui
> Deparment of Sociology
> Fudan University
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From hansruedi.baetschmann at fgcz.unizh.ch  Tue Feb 28 14:58:38 2006
From: hansruedi.baetschmann at fgcz.unizh.ch (Hansruedi Baetschmann)
Date: Tue, 28 Feb 2006 14:58:38 +0100
Subject: [R] Binary Package RMySQL Windows available ?
Message-ID: <4404570E.3020105@fgcz.unizh.ch>

Is there a precompiled version of the package RMySQL for Windows 
available anywhere ?

Best thanks for help !

Hansruedi
_________________________________

Hansruedi Baetschmann
dipl.math.ETH et lic.oec.HSG
Functional Genomics Center Zurich
Winterthurerstrasse 190 / Y32H06
CH-8057 Z??rich
Tel   : +41 44 635 39 02
Natel : +41 79 235 46 49



From ripley at stats.ox.ac.uk  Tue Feb 28 15:44:35 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Feb 2006 14:44:35 +0000 (GMT)
Subject: [R] Binary Package RMySQL Windows available ?
In-Reply-To: <4404570E.3020105@fgcz.unizh.ch>
References: <4404570E.3020105@fgcz.unizh.ch>
Message-ID: <Pine.LNX.4.64.0602281439140.6556@gannet.stats.ox.ac.uk>

Yes.  See

http://cran.r-project.org/bin/windows/contrib/2.2/ReadMe

However, we have found that it is often necessary to have almost exactly 
the same version of MySQL as used to build the binary, so you may e.g. 
only be able to use the binary there with R 2.2.1 and MySQL 5.0.x and not 
e.g. 4.1.y.

On Tue, 28 Feb 2006, Hansruedi Baetschmann wrote:

> Is there a precompiled version of the package RMySQL for Windows
> available anywhere ?
>
> Best thanks for help !
>
> Hansruedi

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Robert.McGehee at geodecapital.com  Tue Feb 28 16:01:51 2006
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Tue, 28 Feb 2006 10:01:51 -0500
Subject: [R] Spearman correlation confidence interval
Message-ID: <67DCA285A2D7754280D3B8E88EB548020C94677F@MSGBOSCLB2WIN.DMN1.FMR.COM>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060228/14928b49/attachment.pl

From ggrothendieck at gmail.com  Tue Feb 28 16:14:58 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 28 Feb 2006 10:14:58 -0500
Subject: [R] Spearman correlation confidence interval
In-Reply-To: <67DCA285A2D7754280D3B8E88EB548020C94677F@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB548020C94677F@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <971536df0602280714i66e1d216rf5595268f353ba43@mail.gmail.com>

You could use a bootstrapped confidence interval.  You can find
R code examples of using bootstrapped confidence intervals
for correlation coefficients (and also an example of the
alternative Fisher Transform) in the proto vignette:

library(proto)
vignette("proto")  # see 3.2


On 2/28/06, McGehee, Robert <Robert.McGehee at geodecapital.com> wrote:
> R-help(ers),
>
> Does anyone know of an R function available for calculating a confidence
> interval for a Spearman correlation? If no such resource is available,
> is using the confidence interval from a Pearson correlation a reasonable
> proxy if the vectors come from normal distributions (i.e. likely
> indistinguishable from the true confidence interval in error bars of an
> autocorrelogram or correlation plot)?
>
> Thanks in advance,
> Robert
>
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From flavio.zanini at epfl.ch  Tue Feb 28 16:22:24 2006
From: flavio.zanini at epfl.ch (flavio.zanini@epfl.ch)
Date: Tue, 28 Feb 2006 16:22:24 +0100
Subject: [R] Stepwise with AICc
Message-ID: <1141140144.44046ab03af64@imapwww.epfl.ch>

Hi,

I would like to uses AIC.c criterion in stepwise selection. I found some
comments about this issue in R help archives, and it seems that no standard
scripts are available. Except from www.prodsyse.com (stepAIC.c), but,
unfortunately, demanding adaptations for R.

Suggestions on this will be very much appreciated

regards
Flavio Zanini


-- 
Flavio Zanini
Geographical Information Systems Lab (LaSIG)
Swiss Federal Institute of Technology Lausanne (EPFL)
CH-1015 Lausanne
Tel: 021 693 27 14



From ruser2006 at yahoo.com  Tue Feb 28 16:27:23 2006
From: ruser2006 at yahoo.com (r user)
Date: Tue, 28 Feb 2006 07:27:23 -0800 (PST)
Subject: [R] vector math: calculating a rolling 12 row product?
Message-ID: <20060228152723.4557.qmail@web37009.mail.mud.yahoo.com>

I have a dataframe of numeric values with 30 ?rows?
and 7 ?columns?.

For each column, beginning at ?row? 12 and down to
?row? 30, I wish to calculate the ?rolling 12 row
product?.  I.e., within each column, I wish to
multiply all the values in row 1:12, 2:13,
19:30.

I wish to save the results as a new dataframe, which
will have 19 rows and 7 columns.



From ccleland at optonline.net  Tue Feb 28 16:36:45 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Tue, 28 Feb 2006 10:36:45 -0500
Subject: [R] vector math: calculating a rolling 12 row product?
In-Reply-To: <20060228152723.4557.qmail@web37009.mail.mud.yahoo.com>
References: <20060228152723.4557.qmail@web37009.mail.mud.yahoo.com>
Message-ID: <44046E0D.3000903@optonline.net>

How about applying cumprod to the columns and then subsetting the result?

apply(mydata, 2, cumprod)[12:30,]

?cumprod

r user wrote:
> I have a dataframe of numeric values with 30 ?rows?
> and 7 ?columns?.
> 
> For each column, beginning at ?row? 12 and down to
> ?row? 30, I wish to calculate the ?rolling 12 row
> product?.  I.e., within each column, I wish to
> multiply all the values in row 1:12, 2:13,?19:30.
> 
> I wish to save the results as a new dataframe, which
> will have 19 rows and 7 columns.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ggrothendieck at gmail.com  Tue Feb 28 16:41:16 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 28 Feb 2006 10:41:16 -0500
Subject: [R] vector math: calculating a rolling 12 row product?
In-Reply-To: <20060228152723.4557.qmail@web37009.mail.mud.yahoo.com>
References: <20060228152723.4557.qmail@web37009.mail.mud.yahoo.com>
Message-ID: <971536df0602280741p3fcdd977ved64fc2267791a23@mail.gmail.com>

Use as.matrix to convert your data frame to a matrix
and suppose we have this test data as a matrix:

  mat <- matrix(seq(30*7), 30, 7)

Then try this:

  library(zoo)
  mat2 <- coredata(rapply(zoo(mat), 12, prod))

See:

   library(zoo)
   vignette("zoo")

and the various zoo help files for more info.


On 2/28/06, r user <ruser2006 at yahoo.com> wrote:
> I have a dataframe of numeric values with 30 "rows"
> and 7 "columns".
>
> For each column, beginning at "row" 12 and down to
> "row" 30, I wish to calculate the "rolling 12 row
> product".  I.e., within each column, I wish to
> multiply all the values in row 1:12, 2:13,?19:30.
>
> I wish to save the results as a new dataframe, which
> will have 19 rows and 7 columns.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ccleland at optonline.net  Tue Feb 28 16:41:20 2006
From: ccleland at optonline.net (Chuck Cleland)
Date: Tue, 28 Feb 2006 10:41:20 -0500
Subject: [R] vector math: calculating a rolling 12 row product?
In-Reply-To: <44046E0D.3000903@optonline.net>
References: <20060228152723.4557.qmail@web37009.mail.mud.yahoo.com>
	<44046E0D.3000903@optonline.net>
Message-ID: <44046F20.70106@optonline.net>

Sorry, I don't think I gave what you asked for, but cumprod() may still 
help.

Chuck Cleland wrote:
> How about applying cumprod to the columns and then subsetting the result?
> 
> apply(mydata, 2, cumprod)[12:30,]
> 
> ?cumprod
> 
> r user wrote:
>> I have a dataframe of numeric values with 30 ?rows?
>> and 7 ?columns?.
>>
>> For each column, beginning at ?row? 12 and down to
>> ?row? 30, I wish to calculate the ?rolling 12 row
>> product?.  I.e., within each column, I wish to
>> multiply all the values in row 1:12, 2:13,?19:30.
>>
>> I wish to save the results as a new dataframe, which
>> will have 19 rows and 7 columns.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From ripley at stats.ox.ac.uk  Tue Feb 28 16:45:57 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Feb 2006 15:45:57 +0000 (GMT)
Subject: [R] Stepwise with AICc
In-Reply-To: <1141140144.44046ab03af64@imapwww.epfl.ch>
References: <1141140144.44046ab03af64@imapwww.epfl.ch>
Message-ID: <Pine.LNX.4.64.0602281544300.15960@gannet.stats.ox.ac.uk>

stepAIC uses extractAIC to calculate AIC.  So all that is in principle 
necessary is to modify extractAIC to return AICc.

On Tue, 28 Feb 2006, flavio.zanini at epfl.ch wrote:

> Hi,
>
> I would like to uses AIC.c criterion in stepwise selection. I found some
> comments about this issue in R help archives, and it seems that no standard
> scripts are available. Except from www.prodsyse.com (stepAIC.c), but,
> unfortunately, demanding adaptations for R.
>
> Suggestions on this will be very much appreciated
>
> regards
> Flavio Zanini
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From timo.becker at oeaw.ac.at  Tue Feb 28 17:26:11 2006
From: timo.becker at oeaw.ac.at (Timo Becker)
Date: Tue, 28 Feb 2006 17:26:11 +0100
Subject: [R] creating dendrogram from cluster hierarchy
In-Reply-To: <44044CF4.1070605@oeaw.ac.at>
References: <mailman.10.1140001208.21738.r-help@stat.math.ethz.ch>	<44041F76.90403@oeaw.ac.at>
	<17412.9155.863739.45920@stat.math.ethz.ch>
	<44044CF4.1070605@oeaw.ac.at>
Message-ID: <440479A3.4040701@oeaw.ac.at>

Timo Becker schrieb:

> Martin Maechler schrieb:
>
>>>>>>> "Timo" == Timo Becker <timo.becker at oeaw.ac.at>
>>>>>>>    on Tue, 28 Feb 2006 11:01:26 +0100 writes:
>>>>>>>           
>>>>>>
>>
>>    Timo> Dear R users, I have created data for hierarchical
>>    Timo> agglomerative cluster analysis which consist of the
>>    Timo> merging pairs and the agglomeration heights, e.g.
>>    Timo> something like
>>
>>    Timo> my.merge <- matrix(c(-1,-2,-3,1), ncol=2, byrow=TRUE)
>>    Timo> my.height <- c(0.5, 1)
>>
>>    Timo> I'd like to plot a corresponding dendrogram but I
>>    Timo> don't know how to convert my data to achieve this.  Is
>>    Timo> it possible to create a dendrogram object from a
>>    Timo> cluster hierarchy?
>>
>> Yes, it is possible.   R does it already with the
>> as.dendrogram() method for objects of class "hclust".
>>  
>>
> Unfortunately the hierarchy is created by another program than R. This 
> is the reason why the only available data for the hclust or dendrogram 
> object creation are the merge-matrix and the agglomeration heights. So 
> as.dendrogram() does not work here.
>
>> But I assume you'd also like to know *how* you can do it... ;-)
>>
>> I'd strongly recommend to take the example of hclust() and have
>> your function return an object ``like'' the one hclust()
>> returns.  Then, as.dendrogram( <your object> ) will work.
>>
>> You have to decide for yourself if your function should return
>> an object of class "hclust" (which is partly described by
>> ?hclust ), and you use as.dendrogram[.hclust]() directly, or rather 
>> your function returns a class "hclustTimo" and you
>> write your own  as.dendrogram.hclustTimo() method.
>>
>> I'd recommend looking at and using the R's source code, e.g., from 
>> https://svn.R-project.org/R/trunk/src/library/stats/R/hclust.R and
>> https://svn.R-project.org/R/trunk/src/library/stats/R/dendrogram.R
>>
>> Regards,
>> Martin Maechler, ETH Zurich
>>
>>  
>>
> I adapted the source code of hclust.R and a quick (and VERY dirty) 
> solution is as follows:
>
> hierarchy2dendrogram <- function(hierarchy) {
> tree <- list(merge = hierarchy[,1:2],
>             height= hierarchy[,3],
>             order = seq(1:(dim(hierarchy)[1]+1)),
>         method=NULL,
>         call = match.call(),
>         dist.method = "whatever")
>  class(tree) <- "hclust"
>  return(tree)
> }
> my.merge <- matrix(c(-1,-2,-3,1), ncol=2, byrow=TRUE)
> my.height <- c(0.5, 1)
> my.hierarchy <- cbind(my.merge, my.height)
> my.hclust.object <- hierarchy2dendrogram(my.hierarchy)
> plot(my.hclust.object)
>
> Perhaps there exists a "cleaner" solution which also returns the 
> optimal order (if I am right the ordering is accomplished by the 
> Fortran function "hcass2") but the above works fine for me.
>
> Thanks a lot and best regards,
> Timo
>
The above is not recommended, since

hierarchy <- matrix(c(-1,2,-2,-3,0.5,1), ncol=3)
hc <- hierarchy2dendrogram(hierarchy)
plot(hc)

causes R 2.2.1 (WinXP) to crash.
I am aware that I am using objects in an unusual way they were not meant to.
I still do not understand what went wrong though (I suppose the merge 
matrix has to follow several restrictions).

Regards,
Timo

-- 
Timo Becker
Phonetics
Austrian Academy of Sciences
Acoustics Research Institute



From osgis.lists at gmail.com  Tue Feb 28 17:40:41 2006
From: osgis.lists at gmail.com (David Bitner)
Date: Tue, 28 Feb 2006 10:40:41 -0600
Subject: [R] kmeans
Message-ID: <71c3c6c50602280840h68c748a6wcd0f7175b16c3ad2@mail.gmail.com>

Is there any way that I can assure that kmeans always returns the same
result for the same data by locking down the random number generator
or anything else?

David



From sundar.dorai-raj at pdf.com  Tue Feb 28 17:50:35 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 28 Feb 2006 10:50:35 -0600
Subject: [R] kmeans
In-Reply-To: <71c3c6c50602280840h68c748a6wcd0f7175b16c3ad2@mail.gmail.com>
References: <71c3c6c50602280840h68c748a6wcd0f7175b16c3ad2@mail.gmail.com>
Message-ID: <44047F5B.3050107@pdf.com>



David Bitner wrote:
> Is there any way that I can assure that kmeans always returns the same
> result for the same data by locking down the random number generator
> or anything else?
> 
> David
> 

Try ?set.seed before your call to kmeans:

# from ?kmeans
# a 2-dimensional example
x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2),
            matrix(rnorm(100, mean = 1, sd = 0.3), ncol = 2))
colnames(x) <- c("x", "y")

# set seed for random number generator
set.seed(42)
cl.1 <- kmeans(x, 5, nstart = 25)
set.seed(42)
cl.2 <- kmeans(x, 5, nstart = 25)

# check whether objects are identical
all.equal(cl.1, cl.2)

HTH,
--sundar



From wcai11 at hotmail.com  Tue Feb 28 17:48:32 2006
From: wcai11 at hotmail.com (Weijie Cai)
Date: Tue, 28 Feb 2006 11:48:32 -0500
Subject: [R] any more direct-search optimization method in R
Message-ID: <BAY103-F415C4215CBD566D4A4E7AD3F70@phx.gbl>

Hello list,

I am dealing with a noisy function (gradient,hessian not available) with 
simple boundary constraints (x_i>0). I've tried constrOptim() using nelder 
mead to minimize it but it is way too slow and the returned results are not 
satisfying. simulated annealing is so hard to tune and it always crashes R 
program in my case. I wonder if there are any packages or functions can do 
direct search optimization?

A rough search in literature shows multidirectional search and DIRECT 
algorithm may help. Is there any other satisfying algorithm?

Thanks,
WC



From I.Visser at uva.nl  Tue Feb 28 17:59:25 2006
From: I.Visser at uva.nl (Ingmar Visser)
Date: Tue, 28 Feb 2006 17:59:25 +0100
Subject: [R] any more direct-search optimization method in R
In-Reply-To: <BAY103-F415C4215CBD566D4A4E7AD3F70@phx.gbl>
Message-ID: <C02A3FFD.3108%I.Visser@uva.nl>

If you have only boundary constraints on parameters you can use method
L-BFGS in optim.
Hth, ingmar


> From: Weijie Cai <wcai11 at hotmail.com>
> Date: Tue, 28 Feb 2006 11:48:32 -0500
> To: <r-help at stat.math.ethz.ch>
> Subject: [R] any more direct-search optimization method in R
> 
> Hello list,
> 
> I am dealing with a noisy function (gradient,hessian not available) with
> simple boundary constraints (x_i>0). I've tried constrOptim() using nelder
> mead to minimize it but it is way too slow and the returned results are not
> satisfying. simulated annealing is so hard to tune and it always crashes R
> program in my case. I wonder if there are any packages or functions can do
> direct search optimization?
> 
> A rough search in literature shows multidirectional search and DIRECT
> algorithm may help. Is there any other satisfying algorithm?
> 
> Thanks,
> WC
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Roger.Bivand at nhh.no  Tue Feb 28 18:02:16 2006
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Tue, 28 Feb 2006 18:02:16 +0100 (CET)
Subject: [R] kmeans
In-Reply-To: <71c3c6c50602280840h68c748a6wcd0f7175b16c3ad2@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0602281801510.1827-100000@reclus.nhh.no>

On Tue, 28 Feb 2006, David Bitner wrote:

> Is there any way that I can assure that kmeans always returns the same
> result for the same data by locking down the random number generator
> or anything else?

?set.seed

> 
> David
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From vokey at uleth.ca  Tue Feb 28 18:03:08 2006
From: vokey at uleth.ca (John Vokey)
Date: Tue, 28 Feb 2006 10:03:08 -0700
Subject: [R] repeated measures ANOVA
In-Reply-To: <mailman.9.1141124402.25605.r-help@stat.math.ethz.ch>
References: <mailman.9.1141124402.25605.r-help@stat.math.ethz.ch>
Message-ID: <7FE902BF-99C3-4B38-BA14-F7ED7731E9A7@uleth.ca>

Christian,
   You need, first to factor() your factors in the data frame P.PA,  
and then denote the error-terms in aov correctly, as follows:

 > group <- rep(rep(1:2, c(5,5)), 3)
 > time <- rep(1:3, rep(10,3))
 > subject <- rep(1:10, 3)
 > p.pa <- c(92, 44, 49, 52, 41, 34, 32, 65, 47, 58, 94, 82, 48, 60, 47,
+ 46, 41, 73, 60, 69, 95, 53, 44, 66, 62, 46, 53, 73, 84, 79)
 > P.PA <- data.frame(subject, group, time, p.pa)

 > # added code:
 > P.PA$group=factor(P.PA$group)
 > P.PA$time=factor(P.PA$time)
 > P.PA$subject=factor(P.PA$subject)

 > summary(aov(p.pa~group*time+Error(subject/time),data=P.PA))

Error: subject
           Df Sum Sq Mean Sq F value Pr(>F)
group      1  158.7   158.7  0.1931  0.672
Residuals  8 6576.3   822.0

Error: subject:time
            Df  Sum Sq Mean Sq F value   Pr(>F)
time        2 1078.07  539.03  7.6233 0.004726 **
group:time  2  216.60  108.30  1.5316 0.246251
Residuals  16 1131.33   70.71
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

On 28-Feb-06, at 4:00 AM, r-help-request at stat.math.ethz.ch wrote:

> Dear list members:
>
> I have the following data:
> group <- rep(rep(1:2, c(5,5)), 3)
> time <- rep(1:3, rep(10,3))
> subject <- rep(1:10, 3)
> p.pa <- c(92, 44, 49, 52, 41, 34, 32, 65, 47, 58, 94, 82, 48, 60, 47,
> 46, 41, 73, 60, 69, 95, 53, 44, 66, 62, 46, 53, 73, 84, 79)
> P.PA <- data.frame(subject, group, time, p.pa)
>
> The ten subjects were randomly assigned to one of two groups and
> measured three times. (The treatment changes after the second time
> point.)
>
> Now I am trying to find out the most adequate way for an analysis of
> main effects and interaction. Most social scientists would call this
> analysis a repeated measures ANOVA, but I understand that mixed- 
> effects
> model is a more generic term for the same analysis. I did the analysis
> in four ways (one in SPSS, three in R):
>
> 1. In SPSS I used "general linear model, repeated measures",  
> defining a
> "within-subject factor" for the three different time points. (The data
> frame is structured differently in SPSS so that there is one line for
> each subject, and each time point is a separate variable.)
> Time was significant.
>
> 2. Analogous to what is recommended in the first chapter of Pinheiro &
> Bates' "Mixed-Effects Models" book, I used
> library(nlme)
> summary(lme ( p.pa ~ time * group, random = ~ 1 | subject))
> Here, time was NOT significant. This was surprising not only in
> comparison with the result in SPSS, but also when looking at the  
> graph:
> interaction.plot(time, group, p.pa)
>
> 3. I then tried a code for the lme4 package, as described by Douglas
> Bates in RNews 5(1), 2005 (p. 27-30). The result was the same as in 2.
> library(lme4)
> summary(lmer ( p.pa ~ time * group + (time*group | subject), P.PA ))
>
> 4. The I also tried what Jonathan Baron suggests in his "Notes on the
> use of R for psychology experiments and questionnaires" (on CRAN):
> summary( aov ( p.pa ~ time * group + Error(subject/(time * group)) ) )
> This gives me yet another result.
>
> So I am confused. Which one should I use?
>
> Thanks
>
> Christian

--
Please avoid sending me Word or PowerPoint attachments.
See <http://www.gnu.org/philosophy/no-word-attachments.html>

-Dr. John R. Vokey



From f.calboli at imperial.ac.uk  Tue Feb 28 18:14:39 2006
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Tue, 28 Feb 2006 17:14:39 +0000
Subject: [R] subsetting a list of matrices
Message-ID: <1141146879.4893.19.camel@localhost.localdomain>

Hi All,

I have a list of matrices:

> x
     [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    3    6
> y
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]   18   21   24   27   30   33
[2,]   19   22   25   28   31   34
[3,]   20   23   26   29   32   35
> z =list(x,y)

I want to create a second list that is has a subset each matrix in the
list subsetting so I get the 2nd and 3rd row of each (and all columns).

How could I do that (apart from looping)?

Regards,

Federico Calboli

-- 
Federico C. F. Calboli
Department of Epidemiology and Public Health
Imperial College, St Mary's Campus
Norfolk Place, London W2 1PG

Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193

f.calboli [.a.t] imperial.ac.uk
f.calboli [.a.t] gmail.com



From Robert.McGehee at geodecapital.com  Tue Feb 28 18:17:58 2006
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Tue, 28 Feb 2006 12:17:58 -0500
Subject: [R] prepared query with RODBC ?
Message-ID: <67DCA285A2D7754280D3B8E88EB548020C946781@MSGBOSCLB2WIN.DMN1.FMR.COM>

I may be misunderstanding you, but why can't you execute a prepared
query the same in RODBC as you would directly on your SQL server? In
Microsoft SQL server, for instance, I would just set up an ADO
application and set the Prepared and CommandText properties before
running the query.

Here is an example from the Microsoft SQL help page. In this example, I
would try storing all of the below as a string in R, and simply pass
this into the odbcQuery or sqlQuery.  However, see the help for your
specific SQL application. Note that (for at least SQL server) one can
disable the prepare/execute model, so you might have to check your ODBC
settings before running.

--Robert

Dim cn As New ADODB.Connection
Dim cmdPrep1 As New ADODB.Command
Dim prm1 As New ADODB.Parameter
Dim prm2 As New ADODB.Parameter
Dim strCn As String

strCn = "Server=MyServerName;Database=pubs;Trusted_Connection=yes"
cn.Provider = "sqloledb"
cn.Open strCn
Set cmdPrep1.ActiveConnection = cn
cmdPrep1.CommandText = "UPDATE titles SET type=? WHERE title_id =?"
cmdPrep1.CommandType = adCmdText
cmdPrep1.Prepared = True
  
Set prm1 = cmdPrep1.CreateParameter("Type", adChar, adParamInput, 12,
"New Bus")
cmdPrep1.Parameters.Append prm1
  
Set prm2 = cmdPrep1.CreateParameter("ProductID", adInteger,
adParamInput, 4, 3)
cmdPrep1.Parameters.Append prm2

cmdPrep1.Execute

cmdPrep1("Type") = "New Cook"
cmdPrep1("title_id") = "TC7777"
cmdPrep1.Execute

cn.Close


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Laurent Gautier
Sent: Monday, February 27, 2006 9:38 AM
To: r-help at stat.math.ethz.ch
Subject: [R] prepared query with RODBC ?

Dear List,

Would anyone know how to perform prepared queries with ROBC ?
I had a shot with some of the internal (non-exported) functions of the
package
but ended up with a segfault, so I prefer asking around before
experimenting further...

Thanks,



Laurent

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From bolker at ufl.edu  Tue Feb 28 18:27:56 2006
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 28 Feb 2006 17:27:56 +0000 (UTC)
Subject: [R] any more direct-search optimization method in R
References: <BAY103-F415C4215CBD566D4A4E7AD3F70@phx.gbl>
	<C02A3FFD.3108%I.Visser@uva.nl>
Message-ID: <loom.20060228T181610-781@post.gmane.org>

Ingmar Visser <I.Visser <at> uva.nl> writes:

> 
> If you have only boundary constraints on parameters you can use method
> L-BFGS in optim.
> Hth, ingmar
> 
> > From: Weijie Cai <wcai11 <at> hotmail.com>

> > 
> > I am dealing with a noisy function (gradient,hessian not available) with
> > simple boundary constraints (x_i>0). I've tried constrOptim() using nelder
> > mead to minimize it but it is way too slow and the returned results are not
> > satisfying. simulated annealing is so hard to tune and it always crashes R
> > program in my case. I wonder if there are any packages or functions can do
> > direct search optimization?
> > 

   Noisy functions are really challenging to optimize; (1) there is no
"best" method (despite all the papers doing comparisons of stochastic
global optimizers on various sets of test functions); (2) the fancier
methods are hard to program [and existing implementations tend have more
restricted licenses]; (3) they tend to be slow (thousands of function
evaluations).   Packages on CRAN that *might* be helpful are
genalg, DEoptim.
   A typical "poor man's" approach to boundary constraints is to
add a quadratic penalty (perhaps not even trying to evaluate the
objective function -- e.g. substituting the value at the closest
boundary point) for parameters outside the constraints into
the objective function.
   With more information (number of parameters, time to compute a
single function evaluation, kind of noise) we might be able to help
more.
  
  Ben Bolker



From ylee1011 at MIT.EDU  Tue Feb 28 18:28:32 2006
From: ylee1011 at MIT.EDU (Young-Jin Lee)
Date: Tue, 28 Feb 2006 12:28:32 -0500
Subject: [R] [Q] specifying weights for robust regression with rlm
Message-ID: <44048840.7040602@mit.edu>

Hello, R-listers

I am relatively new to R and looking for some help on the "rlm" command.

Instead of using provided weight functions such as huber or hampel, I 
want to specify weights to be applied to each data point. After reading 
rlm help files, I found a "weight" option. According to the help 
document, the "weight" option allows me to specify prior weights for 
each case. However, the help documents do not give me enough information 
and I have the following two questions:
1. Does it mean that rlm command will be using only these prior weights 
in doing a robust regression task when they are supplied? Please correct 
me if I misunderstand anything.

2. How can I specify prior weights? I guess I should provide a vector of 
weights. Can someone show me how to do it?

Any help would be appreciated. Thanks in advance.

Young-Jin



From ggrothendieck at gmail.com  Tue Feb 28 18:29:55 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 28 Feb 2006 12:29:55 -0500
Subject: [R] subsetting a list of matrices
In-Reply-To: <1141146879.4893.19.camel@localhost.localdomain>
References: <1141146879.4893.19.camel@localhost.localdomain>
Message-ID: <971536df0602280929i5fe0f832leb70fe56609deac@mail.gmail.com>

Try this:

lapply(z, "[", 2:3, TRUE)

On 2/28/06, Federico Calboli <f.calboli at imperial.ac.uk> wrote:
> Hi All,
>
> I have a list of matrices:
>
> > x
>     [,1] [,2]
> [1,]    1    4
> [2,]    2    5
> [3,]    3    6
> > y
>     [,1] [,2] [,3] [,4] [,5] [,6]
> [1,]   18   21   24   27   30   33
> [2,]   19   22   25   28   31   34
> [3,]   20   23   26   29   32   35
> > z =list(x,y)
>
> I want to create a second list that is has a subset each matrix in the
> list subsetting so I get the 2nd and 3rd row of each (and all columns).
>
> How could I do that (apart from looping)?
>
> Regards,
>
> Federico Calboli
>
> --
> Federico C. F. Calboli
> Department of Epidemiology and Public Health
> Imperial College, St Mary's Campus
> Norfolk Place, London W2 1PG
>
> Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193
>
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From sundar.dorai-raj at pdf.com  Tue Feb 28 18:37:09 2006
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 28 Feb 2006 11:37:09 -0600
Subject: [R] subsetting a list of matrices
In-Reply-To: <1141146879.4893.19.camel@localhost.localdomain>
References: <1141146879.4893.19.camel@localhost.localdomain>
Message-ID: <44048A45.9030404@pdf.com>



Federico Calboli wrote:
> Hi All,
> 
> I have a list of matrices:
> 
> 
>>x
> 
>      [,1] [,2]
> [1,]    1    4
> [2,]    2    5
> [3,]    3    6
> 
>>y
> 
>      [,1] [,2] [,3] [,4] [,5] [,6]
> [1,]   18   21   24   27   30   33
> [2,]   19   22   25   28   31   34
> [3,]   20   23   26   29   32   35
> 
>>z =list(x,y)
> 
> 
> I want to create a second list that is has a subset each matrix in the
> list subsetting so I get the 2nd and 3rd row of each (and all columns).
> 
> How could I do that (apart from looping)?
> 
> Regards,
> 
> Federico Calboli
> 

Try:

x <- matrix(1:6, 3, 2)
y <- matrix(18:35, 3, 6)
z <- list(x = x, y = y)
lapply(z, "[", 2:3, TRUE)

or

lapply(z, "[", 2:3, TRUE, drop = FALSE)

to prevent "[" from dropping the dim attribute. The latter is only 
required if

x <- matrix(1:2, 2, 1)

for example.


HTH,

--sundar



From spencer.graves at pdf.com  Tue Feb 28 18:33:35 2006
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 28 Feb 2006 09:33:35 -0800
Subject: [R] any more direct-search optimization method in R
In-Reply-To: <C02A3FFD.3108%I.Visser@uva.nl>
References: <C02A3FFD.3108%I.Visser@uva.nl>
Message-ID: <4404896F.8090306@pdf.com>

WC:

	  What do you mean by "noisy" in this context?

	  1.  You say, "gradient, hessian not available".  Is it continuous 
with perhaps discontinuities in the first derivative?

	  2.  Or is it something you can compute only to, say, 5 significant 
digits, and some numerical optimizers get lost trying to estimate 
derivatives from so fine a grid that the gradient and hessian are mostly 
noise?

	  3.  Also, why do you think "constrOptim" is too slow?  Does it call 
your function too many times or does your function take too long to 
compute each time it's called?

	  4.  What's not satisfactory about the results of "constrOptim"?

	  5.  Do you know if only one it has only one local minimum in the 
region, or might it have more?

	  6.  Regardless of the answers to the above, have you considered using 
"expand.grid" to get starting values and narrow the search (with 
possibly system.time or proc.time to find out how much time is required 
for each function evaluation)?  I haven't tried this, but I would think 
it would be possible to fit a spline (either exactly or a smoothing 
spline) to a set of points, then optimize the spline.

	  hope this helps.
	  spencer graves

Ingmar Visser wrote:

> If you have only boundary constraints on parameters you can use method
> L-BFGS in optim.
> Hth, ingmar
> 
> 
> 
>>From: Weijie Cai <wcai11 at hotmail.com>
>>Date: Tue, 28 Feb 2006 11:48:32 -0500
>>To: <r-help at stat.math.ethz.ch>
>>Subject: [R] any more direct-search optimization method in R
>>
>>Hello list,
>>
>>I am dealing with a noisy function (gradient,hessian not available) with
>>simple boundary constraints (x_i>0). I've tried constrOptim() using nelder
>>mead to minimize it but it is way too slow and the returned results are not
>>satisfying. simulated annealing is so hard to tune and it always crashes R
>>program in my case. I wonder if there are any packages or functions can do
>>direct search optimization?
>>
>>A rough search in literature shows multidirectional search and DIRECT
>>algorithm may help. Is there any other satisfying algorithm?
>>
>>Thanks,
>>WC
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From mschwartz at mn.rr.com  Tue Feb 28 18:41:17 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 28 Feb 2006 11:41:17 -0600
Subject: [R] subsetting a list of matrices
In-Reply-To: <1141146879.4893.19.camel@localhost.localdomain>
References: <1141146879.4893.19.camel@localhost.localdomain>
Message-ID: <1141148478.4565.27.camel@localhost.localdomain>

On Tue, 2006-02-28 at 17:14 +0000, Federico Calboli wrote:
> Hi All,
> 
> I have a list of matrices:
> 
> > x
>      [,1] [,2]
> [1,]    1    4
> [2,]    2    5
> [3,]    3    6
> > y
>      [,1] [,2] [,3] [,4] [,5] [,6]
> [1,]   18   21   24   27   30   33
> [2,]   19   22   25   28   31   34
> [3,]   20   23   26   29   32   35
> > z =list(x,y)
> 
> I want to create a second list that is has a subset each matrix in the
> list subsetting so I get the 2nd and 3rd row of each (and all columns).
> 
> How could I do that (apart from looping)?
> 
> Regards,
> 
> Federico Calboli


Here is one approach:

> lapply(z, function(x) x[2:3, ])
[[1]]
     [,1] [,2]
[1,]    2    5
[2,]    3    6

[[2]]
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]   19   22   25   28   31   34
[2,]   20   23   26   29   32   35


HTH,

Marc Schwartz



From sasprog474474 at yahoo.com  Tue Feb 28 18:52:11 2006
From: sasprog474474 at yahoo.com (Greg Tarpinian)
Date: Tue, 28 Feb 2006 09:52:11 -0800 (PST)
Subject: [R] relative referencing for filenames &etc
In-Reply-To: <Pine.LNX.4.64.0602281322090.2300@gannet.stats.ox.ac.uk>
Message-ID: <20060228175211.91163.qmail@web37114.mail.mud.yahoo.com>

Thank you both for your helpful suggestions.  My ignorance of R prevents me
from understanding exactly how to

   "...run from a shortcut, appending DATADIR=J:/foo/bar to the 
    command line"

but I assume that Appendix C of "S Programming" will help me there -- I was
unaware of this material when I posted my question.  I was able to success-
fully use the following:

   > Sys.putenv("R_DATADIR"="Z:/.../raw")
   > Sys.getenv("R_DATADIR")
      R_DATADIR 
   "Z:/.../raw" 
   > file.path(Sys.getenv("R_DATADIR"), "RAWDATA.xls")
   [1] "Z:/.../raw/RAWDATA.xls"

Using this type of code, I should be able to "point" R at data and output
directories.  In my industry, programmers are required to save their SAS
log files for auditing purposes, and knowing that R has similar capabilities
is very helpful.

Again, thanks for your help.  Kind regards,


     Greg




--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On Tue, 28 Feb 2006, Uwe Ligges wrote:
> 
> >
> >
> > On Mon, 27 Feb 2006, Greg Tarpinian wrote:
> >
> >> BACKGROUND:
> >> I use SAS on a daily basis and one of its most powerful features in a
> >> production environment is the use of LIBNAME and FILEREF statements, e.g.:
> >>
> >>
> >> PROC PRINTTO LOG = "&LOGDIR.\data processing.log" NEW;
> >> RUN;
> >> PROC IMPORT
> >> 	DATAFILE= "&DATADIR.\blah.xls"
> >> 	OUT = TEMP
> >> 	DBMS = EXCEL REPLACE;
> >>     SHEET = "Sheet1";
> >>     GETNAMES = YES;
> >> RUN;
> >>
> >>
> >> Properly setting up SAS Shortcuts in the WinXP environment, or (say)
> >> the UNIX equivalent of batch files in the UNIX environment will cause
> >> SAS to autoexecute (say) an INIT.SAS file that automatically assigns
> >> the LOGDIR and DATADIR macro variables used above.  This is extremely
> >> convenient because it makes the SAS code more portable from project to
> >> project.
> >>
> >>
> >> MY QUESTION:
> >> Is it possible to use this kind of relative file and directory referencing
> >> from within R?
> >
> > Perhaps you are looking for ?setwd
> 
> Another idea is to use environment variables.  So if in an R function I 
> have
> 
>      xls_file <- file.path(Sys.getenv("DATADIR"), "blah.xls")
> 
> I can R run from a shortcut, appending DATADIR=J:/foo/bar to the command 
> line.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From ripley at stats.ox.ac.uk  Tue Feb 28 19:06:36 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Feb 2006 18:06:36 +0000 (GMT)
Subject: [R] relative referencing for filenames &etc
In-Reply-To: <20060228175211.91163.qmail@web37114.mail.mud.yahoo.com>
References: <20060228175211.91163.qmail@web37114.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.64.0602281806050.20429@gannet.stats.ox.ac.uk>

On Tue, 28 Feb 2006, Greg Tarpinian wrote:

> Thank you both for your helpful suggestions.  My ignorance of R prevents me
> from understanding exactly how to
>
>   "...run from a shortcut, appending DATADIR=J:/foo/bar to the
>    command line"

See the rw-FAQ for more details.

> but I assume that Appendix C of "S Programming" will help me there -- I was
> unaware of this material when I posted my question.  I was able to success-
> fully use the following:
>
>   > Sys.putenv("R_DATADIR"="Z:/.../raw")
>   > Sys.getenv("R_DATADIR")
>      R_DATADIR
>   "Z:/.../raw"
>   > file.path(Sys.getenv("R_DATADIR"), "RAWDATA.xls")
>   [1] "Z:/.../raw/RAWDATA.xls"
>
> Using this type of code, I should be able to "point" R at data and output
> directories.  In my industry, programmers are required to save their SAS
> log files for auditing purposes, and knowing that R has similar capabilities
> is very helpful.
>
> Again, thanks for your help.  Kind regards,
>
>
>     Greg
>
>
>
>
> --- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
>> On Tue, 28 Feb 2006, Uwe Ligges wrote:
>>
>>>
>>>
>>> On Mon, 27 Feb 2006, Greg Tarpinian wrote:
>>>
>>>> BACKGROUND:
>>>> I use SAS on a daily basis and one of its most powerful features in a
>>>> production environment is the use of LIBNAME and FILEREF statements, e.g.:
>>>>
>>>>
>>>> PROC PRINTTO LOG = "&LOGDIR.\data processing.log" NEW;
>>>> RUN;
>>>> PROC IMPORT
>>>> 	DATAFILE= "&DATADIR.\blah.xls"
>>>> 	OUT = TEMP
>>>> 	DBMS = EXCEL REPLACE;
>>>>     SHEET = "Sheet1";
>>>>     GETNAMES = YES;
>>>> RUN;
>>>>
>>>>
>>>> Properly setting up SAS Shortcuts in the WinXP environment, or (say)
>>>> the UNIX equivalent of batch files in the UNIX environment will cause
>>>> SAS to autoexecute (say) an INIT.SAS file that automatically assigns
>>>> the LOGDIR and DATADIR macro variables used above.  This is extremely
>>>> convenient because it makes the SAS code more portable from project to
>>>> project.
>>>>
>>>>
>>>> MY QUESTION:
>>>> Is it possible to use this kind of relative file and directory referencing
>>>> from within R?
>>>
>>> Perhaps you are looking for ?setwd
>>
>> Another idea is to use environment variables.  So if in an R function I
>> have
>>
>>      xls_file <- file.path(Sys.getenv("DATADIR"), "blah.xls")
>>
>> I can R run from a shortcut, appending DATADIR=J:/foo/bar to the command
>> line.
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>
>
> __________________________________________________
> Do You Yahoo!?
> Tired of spam?  Yahoo! Mail has the best spam protection around
> http://mail.yahoo.com
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Feb 28 19:14:34 2006
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Feb 2006 18:14:34 +0000 (GMT)
Subject: [R] [Q] specifying weights for robust regression with rlm
In-Reply-To: <44048840.7040602@mit.edu>
References: <44048840.7040602@mit.edu>
Message-ID: <Pine.LNX.4.64.0602281810090.20429@gannet.stats.ox.ac.uk>

On Tue, 28 Feb 2006, Young-Jin Lee wrote:

> Hello, R-listers
>
> I am relatively new to R and looking for some help on the "rlm" command.
>
> Instead of using provided weight functions such as huber or hampel, I
> want to specify weights to be applied to each data point. After reading
> rlm help files, I found a "weight" option. According to the help
> document, the "weight" option

It is an argument, not an option: it is listed under arguments!

> allows me to specify prior weights for
> each case. However, the help documents do not give me enough information
> and I have the following two questions:
> 1. Does it mean that rlm command will be using only these prior weights
> in doing a robust regression task when they are supplied? Please correct
> me if I misunderstand anything.
> 2. How can I specify prior weights? I guess I should provide a vector of
> weights. Can someone show me how to do it?

rlm is part of the support software for a book.  The book has worked
examples of supplying weights.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From bolker at ufl.edu  Tue Feb 28 19:32:47 2006
From: bolker at ufl.edu (Ben Bolker)
Date: Tue, 28 Feb 2006 13:32:47 -0500
Subject: [R] any more direct-search optimization method in R
Message-ID: <4404974F.9080902@ufl.edu>


    Mathematica may well have good optimization routines; I know MATLAB
does (e.g. the optimization toolbox, 
http://www.mathworks.com/products/optimization/?BB=1 , has a 
general-constraints nonlinear optimizer) -- I also think
more people develop optimization code in MATLAB because of its use in
engineering circles.  (The DIRECT algorithm is implemented in
TOMLAB, a MATLAB add-on package from a third party.)
(S+NuOPT is also available from Insightful,
although it doesn't look like it does global stochastic stuff;
our friends at Otter Research have ADMB, although I don't
know how well it handles noisy objective functions.)

    Drawbacks: (1) switching platforms is a pain, (2) most of
these alternatives are
expensive [although if you have the money it may well be
worth it], (3) Mathematica is notoriously bad about documenting
its methods and giving references to the peer-reviewed literature.
If I were regularly doing really difficult optimization
problems I might switch to MATLAB+add-ons.

   I would like to see more optimization choices implemented in
R, but haven't gotten around to doing so myself yet.  For hard
optimization problems, however, it is nearly always true that
you have to know something about your problem and tune methods
accordingly (see Spencer Graves' message in this thread).

   Ben

-------- Original Message --------
Subject: Re: [R] any more direct-search optimization method in R
Date: Tue, 28 Feb 2006 09:55:15 -0800 (PST)
From: Greg Tarpinian <sasprog474474 at yahoo.com>
To: Ben Bolker <bolker at ufl.edu>

This may not be the most helpful advice, but Mathematica is a wonderful
platform having many more built-in optimization routines than R.  I have
found the simulated annealing facility to be robust and much easier to
use than R's own facility.  This may be a case where switching to another
platform would be the easiest solution.

Kind regards,

     Greg



--- Ben Bolker <bolker at ufl.edu> wrote:

> Ingmar Visser <I.Visser <at> uva.nl> writes:
> 
> > 
> > If you have only boundary constraints on parameters you can use method
> > L-BFGS in optim.
> > Hth, ingmar
> > 
> > > From: Weijie Cai <wcai11 <at> hotmail.com>
> 
> > > 
> > > I am dealing with a noisy function (gradient,hessian not available) with
> > > simple boundary constraints (x_i>0). I've tried constrOptim() using
> nelder
> > > mead to minimize it but it is way too slow and the returned results are
> not
> > > satisfying. simulated annealing is so hard to tune and it always crashes
> R
> > > program in my case. I wonder if there are any packages or functions can
> do
> > > direct search optimization?
> > > 
> 
>    Noisy functions are really challenging to optimize; (1) there is no
> "best" method (despite all the papers doing comparisons of stochastic
> global optimizers on various sets of test functions); (2) the fancier
> methods are hard to program [and existing implementations tend have more
> restricted licenses]; (3) they tend to be slow (thousands of function
> evaluations).   Packages on CRAN that *might* be helpful are
> genalg, DEoptim.
>    A typical "poor man's" approach to boundary constraints is to
> add a quadratic penalty (perhaps not even trying to evaluate the
> objective function -- e.g. substituting the value at the closest
> boundary point) for parameters outside the constraints into
> the objective function.
>    With more information (number of parameters, time to compute a
> single function evaluation, kind of noise) we might be able to help
> more.
>   
>   Ben Bolker
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


__________________________________________________




-- 
620B Bartram Hall                            bolker at zoo.ufl.edu
Zoology Department, University of Florida    http://www.zoo.ufl.edu/bolker
Box 118525                                   (ph)  352-392-5697
Gainesville, FL 32611-8525                   (fax) 352-392-3704



From ggrothendieck at gmail.com  Tue Feb 28 19:36:46 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 28 Feb 2006 13:36:46 -0500
Subject: [R] relative referencing for filenames &etc
In-Reply-To: <20060228175211.91163.qmail@web37114.mail.mud.yahoo.com>
References: <Pine.LNX.4.64.0602281322090.2300@gannet.stats.ox.ac.uk>
	<20060228175211.91163.qmail@web37114.mail.mud.yahoo.com>
Message-ID: <971536df0602281036o4e3db0d0t5e3a1384f1af9a95@mail.gmail.com>

I think the idea of the prior respondents was that R_DATADIR
would be set outside R and the application and just fetched from
an environment variable inside the application so that the application
is independent of it.

If, in fact, your R code knows the data directory anyways, you could
just do

  datadir <- "J:/foo/bar"
  file.path(datadir, "rawdata.xls")



On 2/28/06, Greg Tarpinian <sasprog474474 at yahoo.com> wrote:
> Thank you both for your helpful suggestions.  My ignorance of R prevents me
> from understanding exactly how to
>
>   "...run from a shortcut, appending DATADIR=J:/foo/bar to the
>    command line"
>
> but I assume that Appendix C of "S Programming" will help me there -- I was
> unaware of this material when I posted my question.  I was able to success-
> fully use the following:
>
>   > Sys.putenv("R_DATADIR"="Z:/.../raw")
>   > Sys.getenv("R_DATADIR")
>      R_DATADIR
>   "Z:/.../raw"
>   > file.path(Sys.getenv("R_DATADIR"), "RAWDATA.xls")
>   [1] "Z:/.../raw/RAWDATA.xls"
>
> Using this type of code, I should be able to "point" R at data and output
> directories.  In my industry, programmers are required to save their SAS
> log files for auditing purposes, and knowing that R has similar capabilities
> is very helpful.
>
> Again, thanks for your help.  Kind regards,
>
>
>     Greg
>
>
>
>
> --- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
> > On Tue, 28 Feb 2006, Uwe Ligges wrote:
> >
> > >
> > >
> > > On Mon, 27 Feb 2006, Greg Tarpinian wrote:
> > >
> > >> BACKGROUND:
> > >> I use SAS on a daily basis and one of its most powerful features in a
> > >> production environment is the use of LIBNAME and FILEREF statements, e.g.:
> > >>
> > >>
> > >> PROC PRINTTO LOG = "&LOGDIR.\data processing.log" NEW;
> > >> RUN;
> > >> PROC IMPORT
> > >>    DATAFILE= "&DATADIR.\blah.xls"
> > >>    OUT = TEMP
> > >>    DBMS = EXCEL REPLACE;
> > >>     SHEET = "Sheet1";
> > >>     GETNAMES = YES;
> > >> RUN;
> > >>
> > >>
> > >> Properly setting up SAS Shortcuts in the WinXP environment, or (say)
> > >> the UNIX equivalent of batch files in the UNIX environment will cause
> > >> SAS to autoexecute (say) an INIT.SAS file that automatically assigns
> > >> the LOGDIR and DATADIR macro variables used above.  This is extremely
> > >> convenient because it makes the SAS code more portable from project to
> > >> project.
> > >>
> > >>
> > >> MY QUESTION:
> > >> Is it possible to use this kind of relative file and directory referencing
> > >> from within R?
> > >
> > > Perhaps you are looking for ?setwd
> >
> > Another idea is to use environment variables.  So if in an R function I
> > have
> >
> >      xls_file <- file.path(Sys.getenv("DATADIR"), "blah.xls")
> >
> > I can R run from a shortcut, appending DATADIR=J:/foo/bar to the command
> > line.
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From marcodoc75 at yahoo.com  Tue Feb 28 19:43:35 2006
From: marcodoc75 at yahoo.com (Marco Geraci)
Date: Tue, 28 Feb 2006 10:43:35 -0800 (PST)
Subject: [R] subsetting a list of matrices
In-Reply-To: <1141146879.4893.19.camel@localhost.localdomain>
Message-ID: <20060228184335.71140.qmail@web31306.mail.mud.yahoo.com>

Hi. Have you tried 'help.search('list')' ?
See ?lapply

> lapply(z, function(s) s[2:3,,drop=F])
[[1]]
     [,1] [,2]
[1,]    2    5
[2,]    3    6

[[2]]
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]   19   22   25   28   31   34
[2,]   20   23   26   29   32   35


Marco Geraci

--- Federico Calboli <f.calboli at imperial.ac.uk> wrote:

> Hi All,
> 
> I have a list of matrices:
> 
> > x
>      [,1] [,2]
> [1,]    1    4
> [2,]    2    5
> [3,]    3    6
> > y
>      [,1] [,2] [,3] [,4] [,5] [,6]
> [1,]   18   21   24   27   30   33
> [2,]   19   22   25   28   31   34
> [3,]   20   23   26   29   32   35
> > z =list(x,y)
> 
> I want to create a second list that is has a subset
> each matrix in the
> list subsetting so I get the 2nd and 3rd row of each
> (and all columns).
> 
> How could I do that (apart from looping)?
> 
> Regards,
> 
> Federico Calboli
> 
> -- 
> Federico C. F. Calboli
> Department of Epidemiology and Public Health
> Imperial College, St Mary's Campus
> Norfolk Place, London W2 1PG
> 
> Tel  +44 (0)20 7594 1602     Fax (+44) 020 7594 3193
> 
> f.calboli [.a.t] imperial.ac.uk
> f.calboli [.a.t] gmail.com
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From jebyrnes at ucdavis.edu  Tue Feb 28 20:18:40 2006
From: jebyrnes at ucdavis.edu (Jarrett Byrnes)
Date: Tue, 28 Feb 2006 11:18:40 -0800
Subject: [R] Canonical Values and Centroids for MANOVA plots
Message-ID: <7d176c673120e450d2cb05b7371f343f@ucdavis.edu>

Hey, all, I'm trying to construct a centroid plot using canonical 
values from a MANOVA.  I know that from the summary.manova object you 
can get Eigenvalues, and the H and E matrices (from SS$Treatment and 
SS$Residuals), but I am at a loss to get the loadings for the canonical 
values, nor values for the centroid centers and radii.  Is there a 
package that does this that I am just missing, or any helpful code out 
there that I have been unable to locate?

Thanks so much!

-Jarrett

p.s. There are a bunch of ecologists and evolutionary biologists here 
at Davis who, as a group, have just taken it upon themselves to learn 
R, and it's going swimmingly so far!


----------------------------------------
Jarrett Byrnes
Population Biology Graduate Group, UC Davis
Bodega Marine Lab
707-875-1969
http://www-eve.ucdavis.edu/stachowicz/byrnes.shtml



From tinatinaleonard at gmail.com  Tue Feb 28 20:43:54 2006
From: tinatinaleonard at gmail.com (tina leonard)
Date: Tue, 28 Feb 2006 15:43:54 -0400
Subject: [R] burst argument in as.ltraj()
Message-ID: <66a26a9c0602281143w58fb2124sc9f1d20cd88b1d52@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060228/1fae64f0/attachment.pl

From ggrothendieck at gmail.com  Tue Feb 28 21:26:26 2006
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 28 Feb 2006 15:26:26 -0500
Subject: [R] repeated measures ANOVA
In-Reply-To: <7FE902BF-99C3-4B38-BA14-F7ED7731E9A7@uleth.ca>
References: <mailman.9.1141124402.25605.r-help@stat.math.ethz.ch>
	<7FE902BF-99C3-4B38-BA14-F7ED7731E9A7@uleth.ca>
Message-ID: <971536df0602281226g60ae47cfr8efca6578dce6490@mail.gmail.com>

Or use gl which directly forms a factor:

group <- gl(2, 5, 30)
time <- gl(3, 10)
subject <- gl(10, 1, 30)


On 2/28/06, John Vokey <vokey at uleth.ca> wrote:
> Christian,
>   You need, first to factor() your factors in the data frame P.PA,
> and then denote the error-terms in aov correctly, as follows:
>
>  > group <- rep(rep(1:2, c(5,5)), 3)
>  > time <- rep(1:3, rep(10,3))
>  > subject <- rep(1:10, 3)
>  > p.pa <- c(92, 44, 49, 52, 41, 34, 32, 65, 47, 58, 94, 82, 48, 60, 47,
> + 46, 41, 73, 60, 69, 95, 53, 44, 66, 62, 46, 53, 73, 84, 79)
>  > P.PA <- data.frame(subject, group, time, p.pa)
>
>  > # added code:
>  > P.PA$group=factor(P.PA$group)
>  > P.PA$time=factor(P.PA$time)
>  > P.PA$subject=factor(P.PA$subject)
>
>  > summary(aov(p.pa~group*time+Error(subject/time),data=P.PA))
>
> Error: subject
>           Df Sum Sq Mean Sq F value Pr(>F)
> group      1  158.7   158.7  0.1931  0.672
> Residuals  8 6576.3   822.0
>
> Error: subject:time
>            Df  Sum Sq Mean Sq F value   Pr(>F)
> time        2 1078.07  539.03  7.6233 0.004726 **
> group:time  2  216.60  108.30  1.5316 0.246251
> Residuals  16 1131.33   70.71
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> On 28-Feb-06, at 4:00 AM, r-help-request at stat.math.ethz.ch wrote:
>
> > Dear list members:
> >
> > I have the following data:
> > group <- rep(rep(1:2, c(5,5)), 3)
> > time <- rep(1:3, rep(10,3))
> > subject <- rep(1:10, 3)
> > p.pa <- c(92, 44, 49, 52, 41, 34, 32, 65, 47, 58, 94, 82, 48, 60, 47,
> > 46, 41, 73, 60, 69, 95, 53, 44, 66, 62, 46, 53, 73, 84, 79)
> > P.PA <- data.frame(subject, group, time, p.pa)
> >
> > The ten subjects were randomly assigned to one of two groups and
> > measured three times. (The treatment changes after the second time
> > point.)
> >
> > Now I am trying to find out the most adequate way for an analysis of
> > main effects and interaction. Most social scientists would call this
> > analysis a repeated measures ANOVA, but I understand that mixed-
> > effects
> > model is a more generic term for the same analysis. I did the analysis
> > in four ways (one in SPSS, three in R):
> >
> > 1. In SPSS I used "general linear model, repeated measures",
> > defining a
> > "within-subject factor" for the three different time points. (The data
> > frame is structured differently in SPSS so that there is one line for
> > each subject, and each time point is a separate variable.)
> > Time was significant.
> >
> > 2. Analogous to what is recommended in the first chapter of Pinheiro &
> > Bates' "Mixed-Effects Models" book, I used
> > library(nlme)
> > summary(lme ( p.pa ~ time * group, random = ~ 1 | subject))
> > Here, time was NOT significant. This was surprising not only in
> > comparison with the result in SPSS, but also when looking at the
> > graph:
> > interaction.plot(time, group, p.pa)
> >
> > 3. I then tried a code for the lme4 package, as described by Douglas
> > Bates in RNews 5(1), 2005 (p. 27-30). The result was the same as in 2.
> > library(lme4)
> > summary(lmer ( p.pa ~ time * group + (time*group | subject), P.PA ))
> >
> > 4. The I also tried what Jonathan Baron suggests in his "Notes on the
> > use of R for psychology experiments and questionnaires" (on CRAN):
> > summary( aov ( p.pa ~ time * group + Error(subject/(time * group)) ) )
> > This gives me yet another result.
> >
> > So I am confused. Which one should I use?
> >
> > Thanks
> >
> > Christian
>
> --
> Please avoid sending me Word or PowerPoint attachments.
> See <http://www.gnu.org/philosophy/no-word-attachments.html>
>
> -Dr. John R. Vokey
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From comtech.usa at gmail.com  Tue Feb 28 21:30:09 2006
From: comtech.usa at gmail.com (Michael)
Date: Tue, 28 Feb 2006 12:30:09 -0800
Subject: [R] does svm have a CV to obtain the best "cost" parameter?
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED88E@usctmx1106.merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED88E@usctmx1106.merck.com>
Message-ID: <b1f16d9d0602281230n36e1c2f0n4670b1124c9c1ff1@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060228/fc69b80c/attachment.pl

From wcai11 at hotmail.com  Tue Feb 28 21:37:33 2006
From: wcai11 at hotmail.com (Weijie Cai)
Date: Tue, 28 Feb 2006 15:37:33 -0500
Subject: [R] any more direct-search optimization method in R
In-Reply-To: <4404896F.8090306@pdf.com>
Message-ID: <BAY103-F314DD4DFCC05B31F96AEFD3F70@phx.gbl>

Hi All,
Thanks for all your replies especially for Graves suggestions. You are right 
I should give more information about my function. So my responds to your 
questions are:
1. 2. the function itself is not continuous/smooth. The evaluation at each 
point is a random number with a non-constant variance. When it approaches 
the global minimum, the variance is very small. There is some kind of 
structure from the surface plot of my function but its form is intractable, 
unfortunately.

3. 4. each evaluation of my function is not slow. The returned results by 
constrOptim() are just not quite close to true global minimum (error can be 
as large as 0.2). Of course I can ignore the message of nonconvergence, the 
precision is really not satisfying. Every time nelder-mead will use up 300 
default iterations when doing optimization. I guess the essential reason is 
the randomness of function surface.

5. Yes I am sure there is a global minimum. I did a lengthy computation at 
rough grids and global minimum is very close to true minimum.

6. Do you mean I start from a "minimum" found by grid searching? That's what 
I did. I never tried using smooth functions to approximate my function 
though.

WC


>From: Spencer Graves <spencer.graves at pdf.com>
>To: Ingmar Visser <I.Visser at uva.nl>
>CC: Weijie Cai <wcai11 at hotmail.com>, r-help at stat.math.ethz.ch
>Subject: Re: [R] any more direct-search optimization method in R
>Date: Tue, 28 Feb 2006 09:33:35 -0800
>
>WC:
>
>	  What do you mean by "noisy" in this context?
>
>	  1.  You say, "gradient, hessian not available".  Is it continuous with 
>perhaps discontinuities in the first derivative?
>
>	  2.  Or is it something you can compute only to, say, 5 significant 
>digits, and some numerical optimizers get lost trying to estimate 
>derivatives from so fine a grid that the gradient and hessian are mostly 
>noise?
>
>	  3.  Also, why do you think "constrOptim" is too slow?  Does it call your 
>function too many times or does your function take too long to compute each 
>time it's called?
>
>	  4.  What's not satisfactory about the results of "constrOptim"?
>
>	  5.  Do you know if only one it has only one local minimum in the region, 
>or might it have more?
>
>	  6.  Regardless of the answers to the above, have you considered using 
>"expand.grid" to get starting values and narrow the search (with possibly 
>system.time or proc.time to find out how much time is required for each 
>function evaluation)?  I haven't tried this, but I would think it would be 
>possible to fit a spline (either exactly or a smoothing spline) to a set of 
>points, then optimize the spline.
>
>	  hope this helps.
>	  spencer graves
>
>Ingmar Visser wrote:
>
>>If you have only boundary constraints on parameters you can use method
>>L-BFGS in optim.
>>Hth, ingmar
>>
>>
>>
>>>From: Weijie Cai <wcai11 at hotmail.com>
>>>Date: Tue, 28 Feb 2006 11:48:32 -0500
>>>To: <r-help at stat.math.ethz.ch>
>>>Subject: [R] any more direct-search optimization method in R
>>>
>>>Hello list,
>>>
>>>I am dealing with a noisy function (gradient,hessian not available) with
>>>simple boundary constraints (x_i>0). I've tried constrOptim() using 
>>>nelder
>>>mead to minimize it but it is way too slow and the returned results are 
>>>not
>>>satisfying. simulated annealing is so hard to tune and it always crashes 
>>>R
>>>program in my case. I wonder if there are any packages or functions can 
>>>do
>>>direct search optimization?
>>>
>>>A rough search in literature shows multidirectional search and DIRECT
>>>algorithm may help. Is there any other satisfying algorithm?
>>>
>>>Thanks,
>>>WC
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! 
>>>http://www.R-project.org/posting-guide.html
>>
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html



From pburns at pburns.seanet.com  Tue Feb 28 22:14:06 2006
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 28 Feb 2006 21:14:06 +0000
Subject: [R] any more direct-search optimization method in R
In-Reply-To: <BAY103-F314DD4DFCC05B31F96AEFD3F70@phx.gbl>
References: <BAY103-F314DD4DFCC05B31F96AEFD3F70@phx.gbl>
Message-ID: <4404BD1E.4030202@pburns.seanet.com>

Given that information, I think a genetic algorithm
should probably do well with your problem.  Standard
derivative-based optimizers are going to get frustrated
and give up.  I can believe that Nelder-Mead could
get confused as well, though I'm not sure that it will.

'genopt' from S Poetry does have box constraints for
the parameters.  I'm not sure what other genetic algorithms
that are in R are like.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Weijie Cai wrote:

>Hi All,
>Thanks for all your replies especially for Graves suggestions. You are right 
>I should give more information about my function. So my responds to your 
>questions are:
>1. 2. the function itself is not continuous/smooth. The evaluation at each 
>point is a random number with a non-constant variance. When it approaches 
>the global minimum, the variance is very small. There is some kind of 
>structure from the surface plot of my function but its form is intractable, 
>unfortunately.
>
>3. 4. each evaluation of my function is not slow. The returned results by 
>constrOptim() are just not quite close to true global minimum (error can be 
>as large as 0.2). Of course I can ignore the message of nonconvergence, the 
>precision is really not satisfying. Every time nelder-mead will use up 300 
>default iterations when doing optimization. I guess the essential reason is 
>the randomness of function surface.
>
>5. Yes I am sure there is a global minimum. I did a lengthy computation at 
>rough grids and global minimum is very close to true minimum.
>
>6. Do you mean I start from a "minimum" found by grid searching? That's what 
>I did. I never tried using smooth functions to approximate my function 
>though.
>
>WC
>
>
>  
>
>>From: Spencer Graves <spencer.graves at pdf.com>
>>To: Ingmar Visser <I.Visser at uva.nl>
>>CC: Weijie Cai <wcai11 at hotmail.com>, r-help at stat.math.ethz.ch
>>Subject: Re: [R] any more direct-search optimization method in R
>>Date: Tue, 28 Feb 2006 09:33:35 -0800
>>
>>WC:
>>
>>	  What do you mean by "noisy" in this context?
>>
>>	  1.  You say, "gradient, hessian not available".  Is it continuous with 
>>perhaps discontinuities in the first derivative?
>>
>>	  2.  Or is it something you can compute only to, say, 5 significant 
>>digits, and some numerical optimizers get lost trying to estimate 
>>derivatives from so fine a grid that the gradient and hessian are mostly 
>>noise?
>>
>>	  3.  Also, why do you think "constrOptim" is too slow?  Does it call your 
>>function too many times or does your function take too long to compute each 
>>time it's called?
>>
>>	  4.  What's not satisfactory about the results of "constrOptim"?
>>
>>	  5.  Do you know if only one it has only one local minimum in the region, 
>>or might it have more?
>>
>>	  6.  Regardless of the answers to the above, have you considered using 
>>"expand.grid" to get starting values and narrow the search (with possibly 
>>system.time or proc.time to find out how much time is required for each 
>>function evaluation)?  I haven't tried this, but I would think it would be 
>>possible to fit a spline (either exactly or a smoothing spline) to a set of 
>>points, then optimize the spline.
>>
>>	  hope this helps.
>>	  spencer graves
>>
>>Ingmar Visser wrote:
>>
>>    
>>
>>>If you have only boundary constraints on parameters you can use method
>>>L-BFGS in optim.
>>>Hth, ingmar
>>>
>>>
>>>
>>>      
>>>
>>>>From: Weijie Cai <wcai11 at hotmail.com>
>>>>Date: Tue, 28 Feb 2006 11:48:32 -0500
>>>>To: <r-help at stat.math.ethz.ch>
>>>>Subject: [R] any more direct-search optimization method in R
>>>>
>>>>Hello list,
>>>>
>>>>I am dealing with a noisy function (gradient,hessian not available) with
>>>>simple boundary constraints (x_i>0). I've tried constrOptim() using 
>>>>nelder
>>>>mead to minimize it but it is way too slow and the returned results are 
>>>>not
>>>>satisfying. simulated annealing is so hard to tune and it always crashes 
>>>>R
>>>>program in my case. I wonder if there are any packages or functions can 
>>>>do
>>>>direct search optimization?
>>>>
>>>>A rough search in literature shows multidirectional search and DIRECT
>>>>algorithm may help. Is there any other satisfying algorithm?
>>>>
>>>>Thanks,
>>>>WC
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! 
>>>>http://www.R-project.org/posting-guide.html
>>>>        
>>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! 
>>>http://www.R-project.org/posting-guide.html
>>>      
>>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From d.scott at auckland.ac.nz  Tue Feb 28 22:25:20 2006
From: d.scott at auckland.ac.nz (David Scott)
Date: Wed, 1 Mar 2006 10:25:20 +1300 (NZDT)
Subject: [R] LaTeX in R graph
In-Reply-To: <440418D4.6030704@uni-osnabrueck.de>
References: <1141118845.4404177d8b2cc@webmail.inrets.fr>
	<440418D4.6030704@uni-osnabrueck.de>
Message-ID: <Pine.LNX.4.61.0603011024090.9516@stat12.stat.auckland.ac.nz>

On Tue, 28 Feb 2006, Dietrich Trenkler wrote:

> depire at inrets.fr schrieb:
>
>> Hello,
>> I would like to know if it is possible to insert LaTeX typesetting in R output.
>> I want to obtain a graph with LaTeX label in order to incorporate it as
>> postscript or pdf,
>>
>> x<-seq(0,1,length=100)
>> y<-x*x
>> plot(x,y,xlab="$X$",ylab="$X^2$")
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>
>>
> Hi,
>
> have a look at the psfrag package.
>
I have an example of the use of psfrag in the file "Lecture Slides on TeX" 
which is on the page:

http://www.stat.auckland.ac.nz/~dscott/782/index.php

David Scott
_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
 		The University of Auckland, PB 92019
 		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz


Graduate Officer, Department of Statistics



From andy_liaw at merck.com  Tue Feb 28 22:47:12 2006
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 28 Feb 2006 16:47:12 -0500
Subject: [R] does svm have a CV to obtain the best "cost" parameter?
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED894@usctmx1106.merck.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20060228/85eccbd7/attachment.pl

From hodgess at gator.dt.uh.edu  Tue Feb 28 23:10:38 2006
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Tue, 28 Feb 2006 16:10:38 -0600
Subject: [R]  jpeg and pixels
Message-ID: <200602282210.k1SMAcFO018142@gator.dt.uh.edu>

Dear R People:

When using the jpeg function for plotting,
is there a way to set the size in inches, please?

There is an option for width and height in pixels, but
not inches.


Any suggestions would be welcome!!!!!

R Version 2.2.1 Windows

Thanks in advance!
Sincerely,
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: hodgess at gator.uhd.edu



From mschwartz at mn.rr.com  Tue Feb 28 23:46:08 2006
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 28 Feb 2006 16:46:08 -0600
Subject: [R] jpeg and pixels
In-Reply-To: <200602282210.k1SMAcFO018142@gator.dt.uh.edu>
References: <200602282210.k1SMAcFO018142@gator.dt.uh.edu>
Message-ID: <1141166769.5301.13.camel@localhost.localdomain>

On Tue, 2006-02-28 at 16:10 -0600, Erin Hodgess wrote:
> Dear R People:
> 
> When using the jpeg function for plotting,
> is there a way to set the size in inches, please?
> 
> There is an option for width and height in pixels, but
> not inches.
> 
> 
> Any suggestions would be welcome!!!!!

The problem is that the size of the resultant image when using bitmaps
is entirely dependent upon the resolution (in pixels per inch) of the
device upon which it is displayed. This is also referred to as dpi or
dots per inch.

Thus, for example, on my system I have a dual display configuration. 

The laptop internal LCD (15 inch diag.) is running at 1600x1200 with a
dpi of 133.

My external LCD display is a 20.1 inch diag., also at 1600x1200, with a
dpi of 98.

Thus, a JPEG image that is 400 pixels x 400 pixels will be roughly 3
inches square on my laptop, but roughly 4 inches square on the external
display.

You need to know the target dpi of the display device and then calculate
the required pixels from there.

An alternative is to use the bitmap() function, where you can specify
height and width arguments, but also need to define the 'res' setting,
which is the dpi desired. Even here, the basic calculation process is
the same:

  Inches = Pixels / DPI


HTH.

Marc Schwartz



From t.lim at auckland.ac.nz  Tue Feb 28 23:59:27 2006
From: t.lim at auckland.ac.nz (Tiong Lim)
Date: Wed, 01 Mar 2006 11:59:27 +1300
Subject: [R] Compiling R on aix getting error
In-Reply-To: <Pine.LNX.4.64.0602280518330.22167@gannet.stats.ox.ac.uk>
References: <4403DB2B.50709@auckland.ac.nz>
	<Pine.LNX.4.64.0602280518330.22167@gannet.stats.ox.ac.uk>
Message-ID: <4404D5CF.6030100@auckland.ac.nz>

Prof Brian Ripley wrote:

> On Tue, 28 Feb 2006, Tiong Lim wrote:
>
>> I am trying to compile R 2.2.1 on aix 5.3 with xlc/xlC 7.0 , but i am
>> getting the error below. I did a search on the archive and someone had a
>> similar error as me but I can't seem to find a fix for the error below.
>
>
> Are you referrring to
>
> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/66941.html
>
> ?  Unfortunately I never received a reply to those questions.
>
> This appeared to be something new in AIX 5.3's headers, most likely 
> that they have apparently started defining SOCKLEN_T.  For the R-devel 
> version on R we changed to R_SOCKLEN_T.
>
> So please try the R-devel version of R, or change all occurrences of
> SOCKLEN_T to R_SOCKLEN_T.
>
> Googling showed that several other projects had been affected by this. 
> E.g.  http://www.zsh.org/mla/workers/2004/msg01205.html
> And socklen_t on AIX has been an age-old problem.
>
> ...
>
>>        xlc  -I../../src/extra/zlib -I../../src/extra/bzip2
>> -I../../src/extra/pcre   -I. -I../../src/include -I../../src/include
>> -DHAVE_CONFIG_H   -O -qstrict  -c platform.c -o platform.o
>> "/usr/include/netinet/in.h", line 793.1: 1506-166 (S) Definition of
>> function socklen_t requires parentheses.
>> "/usr/include/netinet/in.h", line 793.17: 1506-276 (S) Syntax error:
>> possible missing '{'?
>> "/usr/include/sys/socket.h", line 374.9: 1506-046 (S) Syntax error.
>> "/usr/include/sys/socket.h", line 378.9: 1506-046 (S) Syntax error.
>> "/usr/include/sys/socket.h", line 404.9: 1506-046 (S) Syntax error.
>> "/usr/include/sys/socket.h", line 475.52: 1506-046 (S) Syntax error.
>> "/usr/include/sys/socket.h", line 476.57: 1506-046 (S) Syntax error.
>> "/usr/include/sys/socket.h", line 477.57: 1506-046 (S) Syntax error.
>> "/usr/include/sys/socket.h", line 478.87: 1506-046 (S) Syntax error.
>> "/usr/include/sys/socket.h", line 484.44: 1506-275 (S) Unexpected text
>> socklen_t encountered.
>> "/usr/include/sys/socket.h", line 485.47: 1506-275 (S) Unexpected text
>> socklen_t encountered.
>> "/usr/include/sys/socket.h", line 486.55: 1506-046 (S) Syntax error.
>> "/usr/include/sys/socket.h", line 490.73: 1506-275 (S) Unexpected text
>> socklen_t encountered.
>> "/usr/include/sys/socket.h", line 491.49: 1506-275 (S) Unexpected text
>> socklen_t encountered.
>> "platform.c", line 1386.13: 1506-285 (S) The indirection operator cannot
>> be applied to a pointer to an incomplete struct or union.
>> "platform.c", line 1388.34: 1506-285 (S) The indirection operator cannot
>> be applied to a pointer to an incomplete struct or union.
>> make: The error code from the last command is 1.
>>
>
Thanks Brian for the explanation . Compiling the development version get 
me pass the SOCKET error . But now i get Undefined symbols errors .
Googling I find reference 
https://stat.ethz.ch/pipermail/r-help/2004-March/046128.html which also 
report similar error but  no answer .

Tiong


Target "R" is up to date.
Target "R" is up to date.
Target "R" is up to date.
Target "R" is up to date.
Target "Makedeps" is up to date.
Target "libbz2.a" is up to date.
Target "Makedeps" is up to date.
Target "libpcre.a" is up to date.
Target "Makedeps" is up to date.
Target "libz.a" is up to date.
../../../src/include/libintl.h is unchanged
../../../include/libintl.h is unchanged
Target "localecharset.h" is up to date.
Target "Makedeps" is up to date.
Target "libintl.a" is up to date.
Target "R" is up to date.
Target "Makedeps" is up to date.
Target "libappl.a" is up to date.
Target "Makedeps" is up to date.
Target "libnmath.a" is up to date.
Target "Makedeps" is up to date.
Target "libunix.a" is up to date.
Target "Makedeps" is up to date.
/people/lim/R-devel/bin/exec/R is unchanged
Target "Makedeps" is up to date.
        xlc -q64  -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry 
-Wl,-bexpall -Wl,-bI:../../../etc/R.exp -L/usr/local/lib -o R_X11.so 
dataentry.o devX11.o rotated.o rbitmap.o -lSM -lICE -lX11 -lXt  -ljpeg 
-lpng -lz
ld: 0711-317 ERROR: Undefined symbol: .Rf_error
ld: 0711-317 ERROR: Undefined symbol: .Rf_warning
ld: 0711-317 ERROR: Undefined symbol: .Rf_lengthgets
ld: 0711-317 ERROR: Undefined symbol: .R_Reprotect
ld: 0711-317 ERROR: Undefined symbol: .Rf_mkChar
ld: 0711-317 ERROR: Undefined symbol: .SET_STRING_ELT
ld: 0711-317 ERROR: Undefined symbol: .Rf_isNull
ld: 0711-317 ERROR: Undefined symbol: .SET_VECTOR_ELT
ld: 0711-317 ERROR: Undefined symbol: .Rf_isVector
ld: 0711-317 ERROR: Undefined symbol: .Rf_allocVector
ld: 0711-317 ERROR: Undefined symbol: R_NaString
ld: 0711-317 ERROR: Undefined symbol: R_NilValue
ld: 0711-317 ERROR: Undefined symbol: .Rf_PrintDefaults
ld: 0711-317 ERROR: Undefined symbol: .Rf_EncodeElement
ld: 0711-317 ERROR: Undefined symbol: .Rf_length
ld: 0711-317 ERROR: Undefined symbol: .Rf_coerceVector
ld: 0711-317 ERROR: Undefined symbol: .Rf_install
ld: 0711-317 ERROR: Undefined symbol: R_GlobalEnv
ld: 0711-317 ERROR: Undefined symbol: .Rf_GetOption
ld: 0711-317 ERROR: Undefined symbol: .Rf_asInteger
ld: 0711-317 ERROR: Undefined symbol: R_NaInt
ld: 0711-317 ERROR: Undefined symbol: .log10
ld: 0711-317 ERROR: Undefined symbol: .floor
ld: 0711-317 ERROR: Undefined symbol: .R_strtod
ld: 0711-317 ERROR: Undefined symbol: .Rf_isBlankString
ld: 0711-317 ERROR: Undefined symbol: R_NaReal
ld: 0711-317 ERROR: Undefined symbol: .UNIMPLEMENTED
ld: 0711-317 ERROR: Undefined symbol: .Rf_duplicate
ld: 0711-317 ERROR: Undefined symbol: .R_ProtectWithIndex
ld: 0711-317 ERROR: Undefined symbol: R_NamesSymbol
ld: 0711-317 ERROR: Undefined symbol: .Rf_getAttrib
ld: 0711-317 ERROR: Undefined symbol: .Rf_errorcall
ld: 0711-317 ERROR: Undefined symbol: .Rf_protect
ld: 0711-317 ERROR: Undefined symbol: .Rf_str2type
ld: 0711-317 ERROR: Undefined symbol: R_BaseEnv
ld: 0711-317 ERROR: Undefined symbol: .Rf_begincontext
ld: 0711-317 ERROR: Undefined symbol: .Rf_endcontext
ld: 0711-317 ERROR: Undefined symbol: .Rf_setAttrib
ld: 0711-317 ERROR: Undefined symbol: .Rf_unprotect
ld: 0711-317 ERROR: Undefined symbol: .libintl_gettext
ld: 0711-317 ERROR: Undefined symbol: .R_setX11Routines
ld: 0711-317 ERROR: Undefined symbol: .Rf_checkArity
ld: 0711-317 ERROR: Undefined symbol: .vmaxget
ld: 0711-317 ERROR: Undefined symbol: .Rf_asReal
ld: 0711-317 ERROR: Undefined symbol: .Rf_isValidString
ld: 0711-317 ERROR: Undefined symbol: .Rf_warningcall
ld: 0711-317 ERROR: Undefined symbol: .Rf_isString
ld: 0711-317 ERROR: Undefined symbol: .Rf_isInteger
ld: 0711-317 ERROR: Undefined symbol: .Rf_isLogical
ld: 0711-317 ERROR: Undefined symbol: .Rf_isReal
ld: 0711-317 ERROR: Undefined symbol: .Rf_RGBpar
ld: 0711-317 ERROR: Undefined symbol: .vmaxset
ld: 0711-317 ERROR: Undefined symbol: .R_CheckDeviceAvailable
ld: 0711-317 ERROR: Undefined symbol: R_interrupts_suspended
ld: 0711-317 ERROR: Undefined symbol: .Rf_mkString
ld: 0711-317 ERROR: Undefined symbol: .Rf_gsetVar
ld: 0711-317 ERROR: Undefined symbol: .GEcreateDevDesc
ld: 0711-317 ERROR: Undefined symbol: .Rf_addDevice
ld: 0711-317 ERROR: Undefined symbol: .GEinitDisplayList
ld: 0711-317 ERROR: Undefined symbol: R_interrupts_pending
ld: 0711-317 ERROR: Undefined symbol: .Rf_onintr
ld: 0711-317 ERROR: Undefined symbol: .R_alloc
ld: 0711-317 ERROR: Undefined symbol: .Rf_findVar
ld: 0711-317 ERROR: Undefined symbol: .Rf_elt
ld: 0711-317 ERROR: Undefined symbol: .Rf_GetDevice
ld: 0711-317 ERROR: Undefined symbol: .Rf_ScalarString
ld: 0711-317 ERROR: Undefined symbol: .R_FindNamespace
ld: 0711-317 ERROR: Undefined symbol: .Rf_eval
ld: 0711-317 ERROR: Undefined symbol: R_InputHandlers
ld: 0711-317 ERROR: Undefined symbol: .getInputHandler
ld: 0711-317 ERROR: Undefined symbol: .removeInputHandler
ld: 0711-317 ERROR: Undefined symbol: .Rf_devNumber
ld: 0711-317 ERROR: Undefined symbol: .Rf_KillDevice
ld: 0711-317 ERROR: Undefined symbol: .GEplayDisplayList
ld: 0711-317 ERROR: Undefined symbol: .pow
ld: 0711-317 ERROR: Undefined symbol: .R_ShowMessage
ld: 0711-317 ERROR: Undefined symbol: mbcslocale
ld: 0711-317 ERROR: Undefined symbol: .sin
ld: 0711-317 ERROR: Undefined symbol: .cos
ld: 0711-317 ERROR: Undefined symbol: .tan
ld: 0711-317 ERROR: Undefined symbol: .R_ExpandFileName
ld: 0711-317 ERROR: Undefined symbol: .R_fopen
ld: 0711-317 ERROR: Undefined symbol: .Rf_asLogical
ld: 0711-317 ERROR: Undefined symbol: .addInputHandler
ld: 0711-317 ERROR: Undefined symbol: .Rprintf
ld: 0711-317 ERROR: Undefined symbol: .R_IsNA
ld: 0711-345 Use the -bloadmap or -bnoquiet option to obtain more 
information.
make: The error code from the last command is 8.


Stop.
make: The error code from the last command is 2.


Stop.
make: The error code from the last command is 1.


Stop.
make: The error code from the last command is 1.


Stop.
make: The error code from the last command is 1.


Stop.



