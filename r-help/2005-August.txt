From wuertz at itp.phys.ethz.ch  Mon Aug  1 00:07:10 2005
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Sun, 31 Jul 2005 22:07:10 +0000
Subject: [R] farimaSim
In-Reply-To: <1122392445.42e6597dcfeed@web-mail1.uibk.ac.at>
References: <mailman.13.1122372001.29817.r-help@stat.math.ethz.ch>
	<1122392445.42e6597dcfeed@web-mail1.uibk.ac.at>
Message-ID: <42ED4B8E.1090504@itp.phys.ethz.ch>

Hansi Weissensteiner wrote:

>Hello!
>
>I installed the fSeries package to get some farima time-series which i tried
>with farimaSim, but unfortunately i got always an error. I tried it this way:
>
>  
>
>>farimaSim(n = 1000, model = list(ar = 0.5,  d = 0.3, ma = 0.1), method="freq")
>>    
>>
>
>Error in farimaSim(n = 1000, model = list(ar = 0.5, d = 0.3, ma = 0.1),  :
> ... used in an incorrect context
>  
>
In the function definition of farimaSim the dots argument is missing.
Replace or overwrite  farimaSim by the following function.
I have to aplogize for any inconveniances caused by this bug.
The bug will be fixed in the next version of Rmetrics.

Diethelm Wuertz



farimaSim =
function(n = 1000, model = list(ar = c(0.5, -0.5), d = 0.3, ma = 0.1),
method = c("freq", "time"), ...)
############  ^^^^^^^^^^   #### Insert the dots!!!!
{   # A function implemented by Diethelm Wuertz

    # Description:
    #   Simulates a FARMA Time Series Process
   
    # Note:
    #   Splus-Like argument list
   
    # Example:
    #   armaSim(model = list(ar = c(0.5, -0.5), d = 0.2, ma = 0.1))
    #   armaSim(model = list(d = 0.2, ma = 0))
    #   armaSim(model = list(d = 0.2))
   
    # FUNCTION:
   
    # Settings:
    innov = NULL
    n.start = 100
    start.innov = NULL
    rand.gen = rnorm
   
    # Simulate:
    if (!is.list(model))
        stop("model must be list")
    if (is.null(innov))
        innov = rand.gen(n, ...)
    n = length(innov)
    if (is.null(start.innov))
        start.innov = rand.gen(n, ...)
    n.start = length(start.innov)

    # AR PART:
    p = length(model$ar)
    if (p == 1 && model$ar == 0)
        p = 0
    if (p) {
        minroots = min(Mod(polyroot(c(1, -model$ar))))
        if (minroots <= 1) stop("ar part of model is not stationary")
    }
   
    # MA PART:
    q = length(model$ma)
    if (q == 1 && model$ma == 0)
        q = 0
    if (n.start < p + q)
        stop("burn-in must be as long as ar + ma")
   
    # DIFFERENCING:
    ## if (model$d < 0) stop("d must be positive ")
    dd = length(model$d)   
    if (dd) {
        # FRACDIFF if "dd" is a non-integer value:
        d = model$d
        if (d != round(d) ) {
            TSMODEL = "FRACDIFF"
        } else {
            TSMODEL = "ARIMA" }
    } else {
        d = 0
        TSMODEL = "ARIMA"
    }
   
    # ARMA:
    if (TSMODEL == "ARIMA") {
        stop("d is a short range model")
    }
       
    if (TSMODEL == "FRACDIFF") {
        if (p == 0) model$ar = 0
        if (q == 0) model$ma = 0
        mu = 0
        # Use Fortran Routine from R's contributed fracdiff package:
        # This is a BUILTIN function ...
        x = .Fortran("fdsim", as.integer(n), as.integer(p), as.integer(q),
            as.double(model$ar), as.double(model$ma), as.double(model$d),
            as.double(mu), as.double(rnorm(n + q)), x = double(n + q),
            as.double(.Machine$double.xmin), 
as.double(.Machine$double.xmax),
            as.double(.Machine$double.neg.eps), 
as.double(.Machine$double.eps),
            PACKAGE = "fSeries")$x[1:n]
    }
              
    # Return Value:
    ans = as.ts(x)
    attr(ans, "model") = model
    ans
}



The result will be:

farimaSim(n = 1000, model = list(ar = 0.5,  d = 0.3, ma = 0.1), 
method="freq")
Time Series:
Start = 1
End = 1000
Frequency = 1
   [1]  3.2301357515  2.7050870252  3.4878581467  4.1825601460  5.1286599175
   [6]  5.5220029973  5.1488261085  5.9423142081  3.5078481961  2.1189096844
  [11]  2.5885700846  2.2224732255  3.0389690791  2.8123050401  2.6096020908
  [16]  2.3095398924  1.4900953088  2.6017795027  3.5148157279  3.4317135045
...
 [991] -0.5745174996  0.9022402358 -0.5675451281  1.4723458150  2.2187064082
 [996]  1.6818662030  0.3170217298  0.9290833661  0.5800528928 -1.6796471062
attr(,"model")
attr(,"model")$ar
[1] 0.5

attr(,"model")$d
[1] 0.3

attr(,"model")$ma
[1] 0.1




>Some ideas?
>
>Regards,
>
>    ___
> _ /_|_|   Hansi Weissensteiner
>/o\__/O\=  csae1552 at uibk.ac.at
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From ggrothendieck at gmail.com  Mon Aug  1 00:19:57 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 31 Jul 2005 18:19:57 -0400
Subject: [R] farimaSim
In-Reply-To: <42ED4B8E.1090504@itp.phys.ethz.ch>
References: <mailman.13.1122372001.29817.r-help@stat.math.ethz.ch>
	<1122392445.42e6597dcfeed@web-mail1.uibk.ac.at>
	<42ED4B8E.1090504@itp.phys.ethz.ch>
Message-ID: <971536df05073115196d38a6fe@mail.gmail.com>

Note that if the only difference is the addition of ... to the formal arguments
then you can just do this once in your session before using farimaSim:

  formals(farimaSim) <- c(formals(farimaSim), alist(... = ))

Now farimaSim will have ... as an argument. e.g.

> formals(farimaSim) <- c(formals(farimaSim), alist(... = ))
> args(farimaSim)
function (n = 1000, model = list(ar = c(0.5, -0.5), d = 0.3, 
    ma = 0.1), method = c("freq", "time"), ...) 



On 7/31/05, Diethelm Wuertz <wuertz at itp.phys.ethz.ch> wrote:
> Hansi Weissensteiner wrote:
> 
> >Hello!
> >
> >I installed the fSeries package to get some farima time-series which i tried
> >with farimaSim, but unfortunately i got always an error. I tried it this way:
> >
> >
> >
> >>farimaSim(n = 1000, model = list(ar = 0.5,  d = 0.3, ma = 0.1), method="freq")
> >>
> >>
> >
> >Error in farimaSim(n = 1000, model = list(ar = 0.5, d = 0.3, ma = 0.1),  :
> > ... used in an incorrect context
> >
> >
> In the function definition of farimaSim the dots argument is missing.
> Replace or overwrite  farimaSim by the following function.
> I have to aplogize for any inconveniances caused by this bug.
> The bug will be fixed in the next version of Rmetrics.
> 
> Diethelm Wuertz
> 
> 
> 
> farimaSim =
> function(n = 1000, model = list(ar = c(0.5, -0.5), d = 0.3, ma = 0.1),
> method = c("freq", "time"), ...)
> ############  ^^^^^^^^^^   #### Insert the dots!!!!
> {   # A function implemented by Diethelm Wuertz
> 
>    # Description:
>    #   Simulates a FARMA Time Series Process
> 
>    # Note:
>    #   Splus-Like argument list
> 
>    # Example:
>    #   armaSim(model = list(ar = c(0.5, -0.5), d = 0.2, ma = 0.1))
>    #   armaSim(model = list(d = 0.2, ma = 0))
>    #   armaSim(model = list(d = 0.2))
> 
>    # FUNCTION:
> 
>    # Settings:
>    innov = NULL
>    n.start = 100
>    start.innov = NULL
>    rand.gen = rnorm
> 
>    # Simulate:
>    if (!is.list(model))
>        stop("model must be list")
>    if (is.null(innov))
>        innov = rand.gen(n, ...)
>    n = length(innov)
>    if (is.null(start.innov))
>        start.innov = rand.gen(n, ...)
>    n.start = length(start.innov)
> 
>    # AR PART:
>    p = length(model$ar)
>    if (p == 1 && model$ar == 0)
>        p = 0
>    if (p) {
>        minroots = min(Mod(polyroot(c(1, -model$ar))))
>        if (minroots <= 1) stop("ar part of model is not stationary")
>    }
> 
>    # MA PART:
>    q = length(model$ma)
>    if (q == 1 && model$ma == 0)
>        q = 0
>    if (n.start < p + q)
>        stop("burn-in must be as long as ar + ma")
> 
>    # DIFFERENCING:
>    ## if (model$d < 0) stop("d must be positive ")
>    dd = length(model$d)
>    if (dd) {
>        # FRACDIFF if "dd" is a non-integer value:
>        d = model$d
>        if (d != round(d) ) {
>            TSMODEL = "FRACDIFF"
>        } else {
>            TSMODEL = "ARIMA" }
>    } else {
>        d = 0
>        TSMODEL = "ARIMA"
>    }
> 
>    # ARMA:
>    if (TSMODEL == "ARIMA") {
>        stop("d is a short range model")
>    }
> 
>    if (TSMODEL == "FRACDIFF") {
>        if (p == 0) model$ar = 0
>        if (q == 0) model$ma = 0
>        mu = 0
>        # Use Fortran Routine from R's contributed fracdiff package:
>        # This is a BUILTIN function ...
>        x = .Fortran("fdsim", as.integer(n), as.integer(p), as.integer(q),
>            as.double(model$ar), as.double(model$ma), as.double(model$d),
>            as.double(mu), as.double(rnorm(n + q)), x = double(n + q),
>            as.double(.Machine$double.xmin),
> as.double(.Machine$double.xmax),
>            as.double(.Machine$double.neg.eps),
> as.double(.Machine$double.eps),
>            PACKAGE = "fSeries")$x[1:n]
>    }
> 
>    # Return Value:
>    ans = as.ts(x)
>    attr(ans, "model") = model
>    ans
> }
> 
> 
> 
> The result will be:
> 
> farimaSim(n = 1000, model = list(ar = 0.5,  d = 0.3, ma = 0.1),
> method="freq")
> Time Series:
> Start = 1
> End = 1000
> Frequency = 1
>   [1]  3.2301357515  2.7050870252  3.4878581467  4.1825601460  5.1286599175
>   [6]  5.5220029973  5.1488261085  5.9423142081  3.5078481961  2.1189096844
>  [11]  2.5885700846  2.2224732255  3.0389690791  2.8123050401  2.6096020908
>  [16]  2.3095398924  1.4900953088  2.6017795027  3.5148157279  3.4317135045
> ...
>  [991] -0.5745174996  0.9022402358 -0.5675451281  1.4723458150  2.2187064082
>  [996]  1.6818662030  0.3170217298  0.9290833661  0.5800528928 -1.6796471062
> attr(,"model")
> attr(,"model")$ar
> [1] 0.5
> 
> attr(,"model")$d
> [1] 0.3
> 
> attr(,"model")$ma
> [1] 0.1
> 
> 
> 
> 
> >Some ideas?
> >
> >Regards,
> >
> >    ___
> > _ /_|_|   Hansi Weissensteiner
> >/o\__/O\=  csae1552 at uibk.ac.at
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jfox at mcmaster.ca  Mon Aug  1 02:08:00 2005
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 31 Jul 2005 20:08:00 -0400
Subject: [R] partial SS for anova
In-Reply-To: <200507302325.TAA04781@webmail5.cac.psu.edu>
Message-ID: <20050801000759.MSPH25800.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Natalia,

See the Anova() function in the car package. Also see the warning in ?Anova
about "Type III" sums of squares.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> NATALIA F TCHETCHERINA
> Sent: Saturday, July 30, 2005 6:25 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] partial SS for anova
> 
> Hello,
> I use  lme4 package.
> library(lme4)
> fit=lmer(y ~ time+dye+trt+trt:time + (1|rep), data=dataset, 
> na.action='na.omit')
> anova(fit)
> 
> The anova gives sequential F-tests and sequential SS.
> 
> My question is: how I can get partial F-tests and partial SS?
>  For lm (not lmer)
> anova(lm(y~x+z))
> we can use
> anova(fit, ssType=3)
> but it is not work for lmer.
> 
> Natalia.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From deepayan.sarkar at gmail.com  Mon Aug  1 03:11:20 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Sun, 31 Jul 2005 20:11:20 -0500
Subject: [R] lattice/ grid.layout/ multiple graphs per page
In-Reply-To: <BEA6A7E18959A04385DC14D24619F89F01D73BAA@sagemsg0008.sagemsmrd01.sa.gov.au>
References: <BEA6A7E18959A04385DC14D24619F89F01D73BAA@sagemsg0008.sagemsmrd01.sa.gov.au>
Message-ID: <eb555e66050731181158135876@mail.gmail.com>

On 7/28/05, McClatchie, Sam (PIRSA-SARDI)
<mcclatchie.sam at saugov.sa.gov.au> wrote:
> Background:
> OS: Linux Mandrake 10.1
> release: R 2.0.0
> editor: GNU Emacs 21.3.2
> front-end: ESS 5.2.3
> ---------------------------------
> 
> >-----Original Message-----
> >From: Deepayan Sarkar [mailto:deepayan.sarkar at gmail.com]
> >Sent: Friday, 29 July 2005 3:44 AM
> >To: McClatchie, Sam (PIRSA-SARDI)
> >Cc: R-Help-Request (E-mail)
> >Subject: Re: [R] lattice/ grid.layout/ multiple graphs per page
> 
> >Depends on the details of your 'working trellis code'. Are you using
> >print() explicitly with 'newpage=FALSE'? See ?print.trellis for
> >details.
> >
> >Deepayan
> 
> -------------------------
> Sorry Deepayan, I should have included the full code originally.
> Here it is, with your suggestion for using the newpage=FALSE option to
> print(). I still have not got it right.


Your code is not reproducible (but full of irrelevant details).
All the grid layout stuff is commented out, so I am not sure what
you expect this code to do.

Anyway, you are probably missing some upViewport / popViewport
calls, since the following does what I would expect:



library(lattice)
library(grid)

p <- xyplot(1 ~ 1)

grid.newpage()
pushViewport(viewport(layout = grid.layout(2, 2)))

pushViewport(viewport(layout.pos.col=1, layout.pos.row=1))
print(p, newpage = FALSE)
popViewport(1)

pushViewport(viewport(layout.pos.col=2, layout.pos.row=2))
print(p, newpage = FALSE)
popViewport()



From Meredith.Briggs at team.telstra.com  Mon Aug  1 04:47:15 2005
From: Meredith.Briggs at team.telstra.com (Briggs, Meredith M)
Date: Mon, 1 Aug 2005 12:47:15 +1000
Subject: [R] How do you increase memeory?
Message-ID: <3B5823541A25D311B3B90008C7F905641B1152E3@ntmsg0092.corpmail.telstra.com.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050801/37f53a31/attachment.pl

From Mike.Lawrence at Dal.Ca  Mon Aug  1 05:19:06 2005
From: Mike.Lawrence at Dal.Ca (Mike Lawrence)
Date: Mon,  1 Aug 2005 00:19:06 -0300
Subject: [R] How do you increase memeory?
In-Reply-To: <3B5823541A25D311B3B90008C7F905641B1152E3@ntmsg0092.corpmail.telstra.com.au>
References: <3B5823541A25D311B3B90008C7F905641B1152E3@ntmsg0092.corpmail.telstra.com.au>
Message-ID: <20050801001906.ltovvbjad3scokss@my1.dal.ca>

memory.limit(size = x)

where x is the desired memory limit in MB.



Quoting "Briggs, Meredith M" <Meredith.Briggs at team.telstra.com>:

> Hello
>
>
> Function memory.size() =435109888. How do I increase it by, say 30%?
>
> Thanks
> Meredith
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



-- 

Mike Lawrence, BA(Hons)
Research Assistant to Dr. Gail Eskes
Dalhousie University & QEII Health Sciences Centre (Psychiatry)

Mike.Lawrence at Dal.Ca

"The road to Wisdom? Well, it's plain and simple to express:
Err and err and err again, but less and less and less."
- Piet Hein



From ripley at stats.ox.ac.uk  Mon Aug  1 08:48:18 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 1 Aug 2005 07:48:18 +0100 (BST)
Subject: [R] Updating to nlme 3.1-62 failing from source (OS X)
In-Reply-To: <3155B34E-506F-4C64-AC0C-88A79368A539@virginia.edu>
References: <3155B34E-506F-4C64-AC0C-88A79368A539@virginia.edu>
Message-ID: <Pine.LNX.4.61.0508010739220.4671@gannet.stats>

This is an internal compiler/assembler error - please check that your 
tools are consistent and if so report this as a MacOS X error.

(It is the sort of thing which happens if gcc targetted for one assembler 
is used with another, for example on Solaris with GNU vs Sun assemblers.)

Given that the C code being compiled is unchanged since 3.1-60 which was 
successfully compiled by the maintainers, this does point to a problem 
local to you.

On Sun, 31 Jul 2005, Michael Kubovy wrote:

> R Version 2.1.1  (2005-06-20); R Cocoa GUI 1.12 (1622);  Mac OS X
> 10.4.2 (8C46)
>
> For nlme, the R package installer for CRAN (binaries) gives 3.1-60 as
> Repository Version as well as Installed Version.

The CRAN repository for MacOS X has not be updated for a couple of weeks.

> For CRAN (sources) it gives 3.1-62 as Repository Version and 3.1-60
> as Installed Version.
>
> When I try to update nlme, I get
>
> * Installing *source* package 'nlme' ...
> ** libs
> gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/
> include  -I/usr/local/include   -fno-common  -g -O2 -c corStruct.c -o
> corStruct.o
> /var/tmp//ccOTBSDa.s:6088:** Removing '/Library/Frameworks/
> R.framework/Versions/2.1.1/Resources/library/nlme'
> ** Restoring previous '/Library/Frameworks/R.framework/Versions/2.1.1/
> Resources/library/nlme'
>
> The downloaded packages are in
>     /private/tmp/RtmpL1j8Sa/downloaded_packages
> Unknown pseudo-op: .p2align
> /var/tmp//ccOTBSDa.s:6088:Rest of line ignored. 1st junk character
> valued 50 (2).
> /var/tmp//ccOTBSDa.s:6414:Unknown pseudo-op: .p2align
> /var/tmp//ccOTBSDa.s:6414:Rest of line ignored. 1st junk character
> valued 50 (2).
> /var/tmp//ccOTBSDa.s:6608:Unknown pseudo-op: .p2align
> /var/tmp//ccOTBSDa.s:6608:Rest of line ignored. 1st junk character
> valued 50 (2).
> /var/tmp//ccOTBSDa.s:7111:Unknown pseudo-op: .subsections_via_symbols
> make: *** [corStruct.o] Error 1
> ERROR: compilation failed for package 'nlme'

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From poohdov at yahoo.com  Mon Aug  1 10:17:18 2005
From: poohdov at yahoo.com (Arie)
Date: Mon, 1 Aug 2005 01:17:18 -0700 (PDT)
Subject: [R] Conditional piece-wise dependent regression
Message-ID: <20050801081719.52138.qmail@web40602.mail.yahoo.com>

Hi, after reading some R docs, I couldn?t figure out how can I find the solution for the following
problem, therefore I would ask this friendly list for an advice.

We?re making a least square approximation for an experiment described by the following model:

T is the time,
Y is some measured value.

>From time=0 till time=U:
Y = b + p*T
>From time=U and on (some effect added):
Y = b + p*T + q*(T-U)
>From time=V and on (some additional effect added):
Y = b + p*T + q*(T-U) + r*(T-V)

Measured: Yi, Ti pairs.
Wanted: b, p, q, r.
b and p are the same for all time ranges;
q is the same for time=U and on.

Thanks,
Arie.



From dimitris.rizopoulos at med.kuleuven.be  Mon Aug  1 10:39:48 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Mon, 1 Aug 2005 10:39:48 +0200
Subject: [R] Conditional piece-wise dependent regression
References: <20050801081719.52138.qmail@web40602.mail.yahoo.com>
Message-ID: <006a01c59674$93a4a1e0$0540210a@www.domain>

Since you want least squares, I think you could use lm() here, i.e.,

U <- 50
V <- 100
Time <- 1:150
dat <- data.frame(y = rnorm(150), Time, f1 = as.numeric(Time > U), f2 
= as.numeric(Time > V))
###############
m <- lm(y ~ Time + I(Time - U):f1 + I(Time - V):f2, data = dat)

# check also the design matrix
model.matrix(m)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm



----- Original Message ----- 
From: "Arie" <poohdov at yahoo.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, August 01, 2005 10:17 AM
Subject: [R] Conditional piece-wise dependent regression


Hi, after reading some R docs, I couldn't figure out how can I find 
the solution for the following
problem, therefore I would ask this friendly list for an advice.

We're making a least square approximation for an experiment described 
by the following model:

T is the time,
Y is some measured value.

>From time=0 till time=U:
Y = b + p*T
>From time=U and on (some effect added):
Y = b + p*T + q*(T-U)
>From time=V and on (some additional effect added):
Y = b + p*T + q*(T-U) + r*(T-V)

Measured: Yi, Ti pairs.
Wanted: b, p, q, r.
b and p are the same for all time ranges;
q is the same for time=U and on.

Thanks,
Arie.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From javad_ashjari at yahoo.com  Mon Aug  1 12:21:51 2005
From: javad_ashjari at yahoo.com (javad Ashjari)
Date: Mon, 1 Aug 2005 03:21:51 -0700 (PDT)
Subject: [R] fortran
Message-ID: <20050801102151.52039.qmail@web52613.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050801/73f6852b/attachment.pl

From aleszib at gmail.com  Mon Aug  1 13:24:51 2005
From: aleszib at gmail.com (Ales Ziberna)
Date: Mon, 1 Aug 2005 13:24:51 +0200
Subject: [R] fortran
References: <20050801102151.52039.qmail@web52613.mail.yahoo.com>
Message-ID: <007c01c5968b$a3687680$598debd4@ales>

See
?dyn.load
?.Fortran

and manual "Writing R Extensions"!

Then ask again if you have additional questions!

Hope this helps,
Ales Ziberna

----- Original Message ----- 
From: "javad Ashjari" <javad_ashjari at yahoo.com>
To: <R-help at stat.math.ethz.ch>
Sent: Monday, August 01, 2005 12:21 PM
Subject: [R] fortran


> Dear Friends
> I am trying to call a fortran subroutine in R, but i can not. How can i 
> use the subroutines in R?
> Regrads
> Javad
>
> __________________________________________________
>
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From JAROSLAW.W.TUSZYNSKI at saic.com  Mon Aug  1 16:20:18 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Mon, 1 Aug 2005 10:20:18 -0400 
Subject: [R] How to hiding code for a package
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD57F4105@us-arlington-0668.mail.saic.com>

I always thought that ability to see and study the code of every package,
was a great thing about R and other "open source" environments. So I hope
there are no good ways of hiding the code of packages. 

Jarek
====================================================\=======

 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">   \
 Jaroslaw.W.Tuszynski at saic.com                     `    \



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Gary Wong
Sent: Saturday, July 30, 2005 4:21 AM
To: r-help at stat.math.ethz.ch
Subject: [R] How to hiding code for a package

Hey everyone,

I have made a package and wish to release it but before then I have a
problem. I have a few functions in this package written in R that I wish to
hide such that after installation, someone can use say the function
>foo(parameters = "") but cannot do >foo.
Typing foo should not show the source code or at least not all of it. Is
there a way to do this ? I have searched the mailing list and used google,
and have found something like "[R] Hiding internal package functions for the
doc. pkg-internal.Rd" but this seems different since it seems that the
keyword internal just hides the function from showing in the index and hides
documentation, not the function itself. Can someone help? Thanks

Gary

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From c.wallace at qmul.ac.uk  Mon Aug  1 16:24:27 2005
From: c.wallace at qmul.ac.uk (Chris Wallace)
Date: Mon, 01 Aug 2005 15:24:27 +0100
Subject: [R] converting stata's by syntax to R
Message-ID: <m3ek9dag6c.fsf@qmul.ac.uk>

I am struggling with migrating some stata code to R.  I have a data
frame containing, sometimes, repeat observations (rows) of the same
family.  I want to keep only one observation per family, selecting
that observation according to some other variable.  An example data
frame is:

# construct example data
fam <- c(1,2,3,3,4,4,4)
wt <- c(1,1,0.6,0.4,0.4,0.4,0.2)
keep <- c(1,1,1,0,1,0,0)
dat <- as.data.frame(cbind(fam,wt,keep))
dat

I want to keep the observation for which wt is a maximum, and where
this doesn't identify a unique observation, to keep just one anyway,
not caring which.  Those observations are indicated above by keep==1.
(Note, keep <- c(1,1,1,0,0,1,0) would be fine too, but not
c(1,1,1,0,0,0,1)).

The stata code I would use is
bys fam (wt): keep if _n==_N

This is my (long-winded) attempt in R:

# first keep those rows where wt=max_fam(wt)
maxwt <- by(dat,dat$fam,function(x) max(x[,2]))
maxwt <- sapply(maxwt,"[[",1)
maxwt.dat <- data.frame("maxwt"=maxwt,"fam"=as.integer(names(maxwt)))
dat <- merge(dat,maxwt.dat)
dat <- dat[dat$wt==dat$maxwt,]
dat

Now I am stuck - I want to keep either row with fam==4, and have tried
playing around with combinations of sample and apply or by, but with
no success.  I can only find an inefficient for-loop solution:
      
# identify those rows with >1 observation
more <- by(dat,dat$fam,function(x) dim(x)[1])
more <- sapply(more,"[[",1)
more.dat <- data.frame("more"=more,"fam"=as.integer(names(more)))
dat <- merge(dat,more.dat)

# sample from those for whom more>1
result<-dat[dat$more==1,]
for(f in unique(dat$fam[dat$more>1])) {
  rows <- rownames(dat[dat$fam==f,])
  result <- rbind(result,dat[sample(rows,1),])
}
result

I am sure that for something so simple in stata to be so complicated
in R must indicate ignorance of R on my part, but searches of help
files and RSiteSearch hasn't led to any better solution.

Any suggestions would be most helpful! Thanks, C.



From faceasec at uapar.edu  Mon Aug  1 16:57:44 2005
From: faceasec at uapar.edu (secretario academico FACEA)
Date: Mon, 01 Aug 2005 11:57:44 -0300
Subject: [R] reading from posgresql
Message-ID: <42EE3868.2080900@uapar.edu>

Dear all
I don't know how to read data from posgresql to R.
Does anybody can help me?
Thanks a lot
Adri??n

From jgentry at jimmy.harvard.edu  Mon Aug  1 17:05:10 2005
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Mon, 1 Aug 2005 11:05:10 -0400 (EDT)
Subject: [R] reading from posgresql
In-Reply-To: <42EE3868.2080900@uapar.edu>
Message-ID: <Pine.SOL.4.20.0508011104330.24662-100000@santiam.dfci.harvard.edu>

> I don't know how to read data from posgresql to R.

The RdbiPgSQL package will read from Postgres.  Its current incarnation is
available via Bioconductor (www.bioconductor.org).



From 0034058 at fudan.edu.cn  Mon Aug  1 17:02:56 2005
From: 0034058 at fudan.edu.cn (ronggui)
Date: Mon, 01 Aug 2005 23:02:56 +0800
Subject: [R] converting stata's by syntax to R
Message-ID: <0IKJ00IMLTCDN5@mail.fudan.edu.cn>

try
> attach(dat)
> dat<-dat[order(fam,wt),]
#sort the data ,as the stata's byable command does
> lis<-by(dat,fam,function(x) x[length(x$fam),])
#equall your stata command ,but return a list.
> do.call(rbind,lis)
#to make the list to be a matrix-like result.
  fam  wt keep
1   1 1.0    1
2   2 1.0    1
3   3 0.4    0
4   4 0.4    0

	

======= 2005-08-01 22:24:27 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>I am struggling with migrating some stata code to R.  I have a data
>frame containing, sometimes, repeat observations (rows) of the same
>family.  I want to keep only one observation per family, selecting
>that observation according to some other variable.  An example data
>frame is:
>
># construct example data
>fam <- c(1,2,3,3,4,4,4)
>wt <- c(1,1,0.6,0.4,0.4,0.4,0.2)
>keep <- c(1,1,1,0,1,0,0)
>dat <- as.data.frame(cbind(fam,wt,keep))
>dat
>
>I want to keep the observation for which wt is a maximum, and where
>this doesn't identify a unique observation, to keep just one anyway,
>not caring which.  Those observations are indicated above by keep==1.
>(Note, keep <- c(1,1,1,0,0,1,0) would be fine too, but not
>c(1,1,1,0,0,0,1)).
>
>The stata code I would use is
>bys fam (wt): keep if _n==_N
>
>This is my (long-winded) attempt in R:
>
># first keep those rows where wt=max_fam(wt)
>maxwt <- by(dat,dat$fam,function(x) max(x[,2]))
>maxwt <- sapply(maxwt,"[[",1)
>maxwt.dat <- data.frame("maxwt"=maxwt,"fam"=as.integer(names(maxwt)))
>dat <- merge(dat,maxwt.dat)
>dat <- dat[dat$wt==dat$maxwt,]
>dat
>
>Now I am stuck - I want to keep either row with fam==4, and have tried
>playing around with combinations of sample and apply or by, but with
>no success.  I can only find an inefficient for-loop solution:
>      
># identify those rows with >1 observation
>more <- by(dat,dat$fam,function(x) dim(x)[1])
>more <- sapply(more,"[[",1)
>more.dat <- data.frame("more"=more,"fam"=as.integer(names(more)))
>dat <- merge(dat,more.dat)
>
># sample from those for whom more>1
>result<-dat[dat$more==1,]
>for(f in unique(dat$fam[dat$more>1])) {
>  rows <- rownames(dat[dat$fam==f,])
>  result <- rbind(result,dat[sample(rows,1),])
>}
>result
>
>I am sure that for something so simple in stata to be so complicated
>in R must indicate ignorance of R on my part, but searches of help
>files and RSiteSearch hasn't led to any better solution.
>
>Any suggestions would be most helpful! Thanks, C.
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-08-01

------
Deparment of Sociology
Fudan University

Blog:http://sociology.yculblog.com



From p.dalgaard at biostat.ku.dk  Mon Aug  1 17:08:03 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 01 Aug 2005 17:08:03 +0200
Subject: [R] converting stata's by syntax to R
In-Reply-To: <m3ek9dag6c.fsf@qmul.ac.uk>
References: <m3ek9dag6c.fsf@qmul.ac.uk>
Message-ID: <x2r7ddg0fg.fsf@turmalin.kubism.ku.dk>

Chris Wallace <c.wallace at qmul.ac.uk> writes:

> I am struggling with migrating some stata code to R.  I have a data
> frame containing, sometimes, repeat observations (rows) of the same
> family.  I want to keep only one observation per family, selecting
> that observation according to some other variable.  An example data
> frame is:
> 
> # construct example data
> fam <- c(1,2,3,3,4,4,4)
> wt <- c(1,1,0.6,0.4,0.4,0.4,0.2)
> keep <- c(1,1,1,0,1,0,0)
> dat <- as.data.frame(cbind(fam,wt,keep))
> dat
> 
> I want to keep the observation for which wt is a maximum, and where
> this doesn't identify a unique observation, to keep just one anyway,
> not caring which.  Those observations are indicated above by keep==1.
> (Note, keep <- c(1,1,1,0,0,1,0) would be fine too, but not
> c(1,1,1,0,0,0,1)).
> 
> The stata code I would use is
> bys fam (wt): keep if _n==_N
> 
> This is my (long-winded) attempt in R:
> 
> # first keep those rows where wt=max_fam(wt)
> maxwt <- by(dat,dat$fam,function(x) max(x[,2]))
> maxwt <- sapply(maxwt,"[[",1)
> maxwt.dat <- data.frame("maxwt"=maxwt,"fam"=as.integer(names(maxwt)))
> dat <- merge(dat,maxwt.dat)
> dat <- dat[dat$wt==dat$maxwt,]
> dat
> 
> Now I am stuck - I want to keep either row with fam==4, and have tried
> playing around with combinations of sample and apply or by, but with
> no success.  I can only find an inefficient for-loop solution:
>       
> # identify those rows with >1 observation
> more <- by(dat,dat$fam,function(x) dim(x)[1])
> more <- sapply(more,"[[",1)
> more.dat <- data.frame("more"=more,"fam"=as.integer(names(more)))
> dat <- merge(dat,more.dat)
> 
> # sample from those for whom more>1
> result<-dat[dat$more==1,]
> for(f in unique(dat$fam[dat$more>1])) {
>   rows <- rownames(dat[dat$fam==f,])
>   result <- rbind(result,dat[sample(rows,1),])
> }
> result
> 
> I am sure that for something so simple in stata to be so complicated
> in R must indicate ignorance of R on my part, but searches of help
> files and RSiteSearch hasn't led to any better solution.
> 
> Any suggestions would be most helpful! Thanks, C.

How about

unsplit(lapply(split(dat,dat$fam), 
               function(x) seq(length=nrow(x)) == which.max(x$wt)),
        dat$fam)

or 

do.call("rbind", lapply(split(dat,dat$fam),
                        function(x) x[which.max(x$wt),]))

or (same thing, basically)

do.call("rbind", by(dat,dat$fam,function(x) x[which.max(x$wt),]))

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From jeaneid at chass.utoronto.ca  Mon Aug  1 17:23:01 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Mon, 1 Aug 2005 11:23:01 -0400
Subject: [R] converting stata's by syntax to R
In-Reply-To: <m3ek9dag6c.fsf@qmul.ac.uk>
Message-ID: <Pine.SGI.4.40.0508011122250.10151985-100000@origin.chass.utoronto.ca>

Here is one way this can be done
 do.call("rbind", by(dat, list(dat$fam) ,function(x) {
+ if(NROW(x)>1) return(x[which.max(x$wt),])
+ else return(x)}
+ ))


and it returns
  fam  wt keep
1   1 1.0    1
2   2 1.0    1
3   3 0.6    1
4   4 0.4    1



hth,


On Mon, 1 Aug 2005, Chris Wallace wrote:

> I am struggling with migrating some stata code to R.  I have a data
> frame containing, sometimes, repeat observations (rows) of the same
> family.  I want to keep only one observation per family, selecting
> that observation according to some other variable.  An example data
> frame is:
>
> # construct example data
> fam <- c(1,2,3,3,4,4,4)
> wt <- c(1,1,0.6,0.4,0.4,0.4,0.2)
> keep <- c(1,1,1,0,1,0,0)
> dat <- as.data.frame(cbind(fam,wt,keep))
> dat
>
> I want to keep the observation for which wt is a maximum, and where
> this doesn't identify a unique observation, to keep just one anyway,
> not caring which.  Those observations are indicated above by keep==1.
> (Note, keep <- c(1,1,1,0,0,1,0) would be fine too, but not
> c(1,1,1,0,0,0,1)).
>
> The stata code I would use is
> bys fam (wt): keep if _n==_N
>
> This is my (long-winded) attempt in R:
>
> # first keep those rows where wt=max_fam(wt)
> maxwt <- by(dat,dat$fam,function(x) max(x[,2]))
> maxwt <- sapply(maxwt,"[[",1)
> maxwt.dat <- data.frame("maxwt"=maxwt,"fam"=as.integer(names(maxwt)))
> dat <- merge(dat,maxwt.dat)
> dat <- dat[dat$wt==dat$maxwt,]
> dat
>
> Now I am stuck - I want to keep either row with fam==4, and have tried
> playing around with combinations of sample and apply or by, but with
> no success.  I can only find an inefficient for-loop solution:
>
> # identify those rows with >1 observation
> more <- by(dat,dat$fam,function(x) dim(x)[1])
> more <- sapply(more,"[[",1)
> more.dat <- data.frame("more"=more,"fam"=as.integer(names(more)))
> dat <- merge(dat,more.dat)
>
> # sample from those for whom more>1
> result<-dat[dat$more==1,]
> for(f in unique(dat$fam[dat$more>1])) {
>   rows <- rownames(dat[dat$fam==f,])
>   result <- rbind(result,dat[sample(rows,1),])
> }
> result
>
> I am sure that for something so simple in stata to be so complicated
> in R must indicate ignorance of R on my part, but searches of help
> files and RSiteSearch hasn't led to any better solution.
>
> Any suggestions would be most helpful! Thanks, C.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From pohl at marge.statistik.uni-koeln.de  Mon Aug  1 17:15:08 2005
From: pohl at marge.statistik.uni-koeln.de (S. Pohl)
Date: Mon, 1 Aug 2005 17:15:08 +0200
Subject: [R] Clayton-Oakes failure time model
Message-ID: <045701c596ab$d0c7b490$1b9e5f86@simurechner>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050801/f1a43ced/attachment.pl

From dimitris.rizopoulos at med.kuleuven.be  Mon Aug  1 17:28:35 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Mon, 1 Aug 2005 17:28:35 +0200
Subject: [R] converting stata's by syntax to R
References: <m3ek9dag6c.fsf@qmul.ac.uk>
Message-ID: <003a01c596ad$aeadc6e0$0540210a@www.domain>

if you also need to create the `keep' vector, then you could try this 
approach:

fam <- c(1,2,3,3,4,4,4)
wt <- c(1,1,0.6,0.4,0.4,0.4,0.2)
dat <- data.frame(fam, wt)
###########
keep <- unlist( lapply(split(wt, fam), function(x){
        ind <- rep(FALSE, length(x))
        ind[which.max(x)] <- TRUE
        ind
    }) )
as.numeric(keep)
dat[keep, ]


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Chris Wallace" <c.wallace at qmul.ac.uk>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, August 01, 2005 4:24 PM
Subject: [R] converting stata's by syntax to R


>I am struggling with migrating some stata code to R.  I have a data
> frame containing, sometimes, repeat observations (rows) of the same
> family.  I want to keep only one observation per family, selecting
> that observation according to some other variable.  An example data
> frame is:
>
> # construct example data
> fam <- c(1,2,3,3,4,4,4)
> wt <- c(1,1,0.6,0.4,0.4,0.4,0.2)
> keep <- c(1,1,1,0,1,0,0)
> dat <- as.data.frame(cbind(fam,wt,keep))
> dat
>
> I want to keep the observation for which wt is a maximum, and where
> this doesn't identify a unique observation, to keep just one anyway,
> not caring which.  Those observations are indicated above by 
> keep==1.
> (Note, keep <- c(1,1,1,0,0,1,0) would be fine too, but not
> c(1,1,1,0,0,0,1)).
>
> The stata code I would use is
> bys fam (wt): keep if _n==_N
>
> This is my (long-winded) attempt in R:
>
> # first keep those rows where wt=max_fam(wt)
> maxwt <- by(dat,dat$fam,function(x) max(x[,2]))
> maxwt <- sapply(maxwt,"[[",1)
> maxwt.dat <- 
> data.frame("maxwt"=maxwt,"fam"=as.integer(names(maxwt)))
> dat <- merge(dat,maxwt.dat)
> dat <- dat[dat$wt==dat$maxwt,]
> dat
>
> Now I am stuck - I want to keep either row with fam==4, and have 
> tried
> playing around with combinations of sample and apply or by, but with
> no success.  I can only find an inefficient for-loop solution:
>
> # identify those rows with >1 observation
> more <- by(dat,dat$fam,function(x) dim(x)[1])
> more <- sapply(more,"[[",1)
> more.dat <- data.frame("more"=more,"fam"=as.integer(names(more)))
> dat <- merge(dat,more.dat)
>
> # sample from those for whom more>1
> result<-dat[dat$more==1,]
> for(f in unique(dat$fam[dat$more>1])) {
>  rows <- rownames(dat[dat$fam==f,])
>  result <- rbind(result,dat[sample(rows,1),])
> }
> result
>
> I am sure that for something so simple in stata to be so complicated
> in R must indicate ignorance of R on my part, but searches of help
> files and RSiteSearch hasn't led to any better solution.
>
> Any suggestions would be most helpful! Thanks, C.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From reid_huntsinger at merck.com  Mon Aug  1 17:49:03 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Mon, 1 Aug 2005 11:49:03 -0400
Subject: [R] Conditional piece-wise dependent regression
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A9563@uswpmx00.merck.com>

In case you want to estimate U and V as well, there's a segmented regression
package (called "segmented") on http://cran.r-project.org for this.

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Dimitris Rizopoulos
Sent: Monday, August 01, 2005 4:40 AM
To: Arie
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Conditional piece-wise dependent regression


Since you want least squares, I think you could use lm() here, i.e.,

U <- 50
V <- 100
Time <- 1:150
dat <- data.frame(y = rnorm(150), Time, f1 = as.numeric(Time > U), f2 
= as.numeric(Time > V))
###############
m <- lm(y ~ Time + I(Time - U):f1 + I(Time - V):f2, data = dat)

# check also the design matrix
model.matrix(m)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm



----- Original Message ----- 
From: "Arie" <poohdov at yahoo.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, August 01, 2005 10:17 AM
Subject: [R] Conditional piece-wise dependent regression


Hi, after reading some R docs, I couldn't figure out how can I find 
the solution for the following
problem, therefore I would ask this friendly list for an advice.

We're making a least square approximation for an experiment described 
by the following model:

T is the time,
Y is some measured value.

>From time=0 till time=U:
Y = b + p*T
>From time=U and on (some effect added):
Y = b + p*T + q*(T-U)
>From time=V and on (some additional effect added):
Y = b + p*T + q*(T-U) + r*(T-V)

Measured: Yi, Ti pairs.
Wanted: b, p, q, r.
b and p are the same for all time ranges;
q is the same for time=U and on.

Thanks,
Arie.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From br44114 at gmail.com  Mon Aug  1 17:55:29 2005
From: br44114 at gmail.com (bogdan romocea)
Date: Mon, 1 Aug 2005 11:55:29 -0400
Subject: [R] How to hiding code for a package
Message-ID: <8d5a3635050801085546c8b5ad@mail.gmail.com>

There's something else you could try - since you can't hide the code,
obfuscate it. Hide the real thing in a large pile of useless,
complicated, awfully formatted code that would stop anyone except the
most desperate (including yourself, after a couple of weeks/months)
from trying to understand it. The best solution would be to compile
the code, but R is not there yet.


> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
> Sent: Saturday, July 30, 2005 5:35 AM
> To: Gary Wong
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] How to hiding code for a package
> 
> 
> What you ask is impossible.  For a function to be callable it 
> has to be 
> locatable and hence can be printed.
> 
> One possibility is to have a namespace, and something like
> 
> foo <- function(...) foo_internal(...)
> 
> where foo is exported but foo_internal is not.  Then foo_internal is 
> hidden from casual inspection, but it can be listed by cognescenti.
> 
> Why do you want to do this?  Anyhone can read the source code of your 
> package, and any function which can be called can be 
> deparsed, possibly 
> after jumping through a few hoops.
> 
> On Sat, 30 Jul 2005, Gary Wong wrote:
> 
> > Hey everyone,
> >
> > I have made a package and wish to release it but
> > before then I have a problem. I have a few functions
> > in this package written in R that I wish to hide such
> > that after installation, someone can use say the
> > function >foo(parameters = "") but cannot do >foo.
> > Typing foo should not show the source code or at least
> > not all of it. Is there a way to do this ? I have
> > searched the mailing list and used google, and have
> > found something like "[R] Hiding internal package
> > functions for the doc. pkg-internal.Rd" but this seems
> > different since it seems that the keyword internal
> > just hides the function from showing in the index and
> > hides documentation, not the function itself. Can
> > someone help? Thanks
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Mon Aug  1 18:02:26 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 01 Aug 2005 09:02:26 -0700
Subject: [R] How to hiding code for a package
In-Reply-To: <8d5a3635050801085546c8b5ad@mail.gmail.com>
References: <8d5a3635050801085546c8b5ad@mail.gmail.com>
Message-ID: <42EE4792.5070904@pdf.com>

Dear Gary Wong:

	  Are you trying to defeat the GNU License?  If so, why not make it 
available as an S-Plus library?  There, you don't have to provide the 
source;  binary files will suffice.

	  spencer graves

bogdan romocea wrote:

> There's something else you could try - since you can't hide the code,
> obfuscate it. Hide the real thing in a large pile of useless,
> complicated, awfully formatted code that would stop anyone except the
> most desperate (including yourself, after a couple of weeks/months)
> from trying to understand it. The best solution would be to compile
> the code, but R is not there yet.
> 
> 
> 
>>-----Original Message-----
>>From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
>>Sent: Saturday, July 30, 2005 5:35 AM
>>To: Gary Wong
>>Cc: r-help at stat.math.ethz.ch
>>Subject: Re: [R] How to hiding code for a package
>>
>>
>>What you ask is impossible.  For a function to be callable it 
>>has to be 
>>locatable and hence can be printed.
>>
>>One possibility is to have a namespace, and something like
>>
>>foo <- function(...) foo_internal(...)
>>
>>where foo is exported but foo_internal is not.  Then foo_internal is 
>>hidden from casual inspection, but it can be listed by cognescenti.
>>
>>Why do you want to do this?  Anyhone can read the source code of your 
>>package, and any function which can be called can be 
>>deparsed, possibly 
>>after jumping through a few hoops.
>>
>>On Sat, 30 Jul 2005, Gary Wong wrote:
>>
>>
>>>Hey everyone,
>>>
>>>I have made a package and wish to release it but
>>>before then I have a problem. I have a few functions
>>>in this package written in R that I wish to hide such
>>>that after installation, someone can use say the
>>>function >foo(parameters = "") but cannot do >foo.
>>>Typing foo should not show the source code or at least
>>>not all of it. Is there a way to do this ? I have
>>>searched the mailing list and used google, and have
>>>found something like "[R] Hiding internal package
>>>functions for the doc. pkg-internal.Rd" but this seems
>>>different since it seems that the keyword internal
>>>just hides the function from showing in the index and
>>>hides documentation, not the function itself. Can
>>>someone help? Thanks
>>
>>-- 
>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>University of Oxford,             Tel:  +44 1865 272861 (self)
>>1 South Parks Road,                     +44 1865 272866 (PA)
>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From tlumley at u.washington.edu  Mon Aug  1 18:43:03 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 1 Aug 2005 09:43:03 -0700 (PDT)
Subject: [R] converting stata's by syntax to R
In-Reply-To: <m3ek9dag6c.fsf@qmul.ac.uk>
References: <m3ek9dag6c.fsf@qmul.ac.uk>
Message-ID: <Pine.A41.4.61b.0508010937110.226770@homer10.u.washington.edu>

On Mon, 1 Aug 2005, Chris Wallace wrote:

> I am struggling with migrating some stata code to R.  I have a data
> frame containing, sometimes, repeat observations (rows) of the same
> family.  I want to keep only one observation per family, selecting
> that observation according to some other variable.  An example data
> frame is:
>
> # construct example data
> fam <- c(1,2,3,3,4,4,4)
> wt <- c(1,1,0.6,0.4,0.4,0.4,0.2)
> keep <- c(1,1,1,0,1,0,0)
> dat <- as.data.frame(cbind(fam,wt,keep))
> dat
>
> I want to keep the observation for which wt is a maximum, and where
> this doesn't identify a unique observation, to keep just one anyway,
> not caring which.  Those observations are indicated above by keep==1.
> (Note, keep <- c(1,1,1,0,0,1,0) would be fine too, but not
> c(1,1,1,0,0,0,1)).
>
> The stata code I would use is
> bys fam (wt): keep if _n==_N

A reasonably direct translation of the Stata code is

   index <- order(fam, -wt)
   keep <- !duplicated(fam[index])
   dat <- data.frame(fam=fam[index], wt=wt[index], keep=keep)

which sorts wt into decreasing order within family, then keeps the first 
observation in each family.

This is less general than solutions other people have given, but I'd 
expect it to be faster for large data sets. 'keep' ends up TRUE/FALSE 
rather than 1/0; if this is a problem use as.numeric() on it.

 	-thomas



From kubovy at virginia.edu  Mon Aug  1 19:26:19 2005
From: kubovy at virginia.edu (Michael Kubovy)
Date: Mon, 1 Aug 2005 13:26:19 -0400
Subject: [R] Compiling nlme 3.1-62 succeeds if OS X Developer Tools
	updated; however, compiling mgcv_1.3-4 fails
In-Reply-To: <Pine.LNX.4.61.0508010739220.4671@gannet.stats>
References: <3155B34E-506F-4C64-AC0C-88A79368A539@virginia.edu>
	<Pine.LNX.4.61.0508010739220.4671@gannet.stats>
Message-ID: <4494D992-0C51-4EDE-B32D-CDC52417C2ED@virginia.edu>

Prof. Ripley was right. The problem went away when I updated the  
Developer Tools.

On Aug 1, 2005, at 2:48 AM, Prof Brian Ripley wrote:

> This is an internal compiler/assembler error - please check that  
> your tools are consistent and if so report this as a MacOS X error.

> On Sun, 31 Jul 2005, Michael Kubovy wrote:

>> When I try to update nlme, I get
>>
>> * Installing *source* package 'nlme' ...
>> ** libs
>> gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/
>> include  -I/usr/local/include   -fno-common  -g -O2 -c corStruct.c -o
>> corStruct.o
>> /var/tmp//ccOTBSDa.s:6088:** Removing '/Library/Frameworks/
>> R.framework/Versions/2.1.1/Resources/library/nlme'
>> ** Restoring previous '/Library/Frameworks/R.framework/Versions/ 
>> 2.1.1/
>> Resources/library/nlme'
>>
>> The downloaded packages are in
>>     /private/tmp/RtmpL1j8Sa/downloaded_packages
>> Unknown pseudo-op: .p2align
>> /var/tmp//ccOTBSDa.s:6088:Rest of line ignored. 1st junk character
>> valued 50 (2).
>> /var/tmp//ccOTBSDa.s:6414:Unknown pseudo-op: .p2align
>> /var/tmp//ccOTBSDa.s:6414:Rest of line ignored. 1st junk character
>> valued 50 (2).
>> /var/tmp//ccOTBSDa.s:6608:Unknown pseudo-op: .p2align
>> /var/tmp//ccOTBSDa.s:6608:Rest of line ignored. 1st junk character
>> valued 50 (2).
>> /var/tmp//ccOTBSDa.s:7111:Unknown pseudo-op: .subsections_via_symbols
>> make: *** [corStruct.o] Error 1
>> ERROR: compilation failed for package 'nlme'

However, the following problem occurred when I tried to compile mgcv:

* Installing *source* package 'mgcv' ...
** libs
gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/ 
include  -I/usr/local/include   -fno-common  -g -O2 -c gcv.c -o gcv.o
gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/ 
include  -I/usr/local/include   -fno-common  -g -O2 -c magic.c -o  
magic.o
gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/ 
include  -I/usr/local/include   -fno-common  -g -O2 -c mat.c -o mat.o
gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/ 
include  -I/usr/local/include   -fno-common  -g -O2 -c matrix.c -o  
matrix.o
gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/ 
include  -I/usr/local/include   -fno-common  -g -O2 -c mgcv.c -o mgcv.o
gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/ 
include  -I/usr/local/include   -fno-common  -g -O2 -c qp.c -o qp.o
gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/ 
include  -I/usr/local/include   -fno-common  -g -O2 -c tprs.c -o tprs.o
gcc-3.3 -bundle -flat_namespace -undefined suppress -L/usr/local/lib - 
o mgcv.so gcv.o magic.o mat.o matrix.o mgcv.o qp.o tprs.o  -framework  
vecLib -L/usr/local/lib/gcc/powerpc-apple-darwin6.8/3.4.2 -lg2c - 
lSystem  -framework R
ld: warning ** Removing '/Library/Frameworks/R.framework/Versions/ 
2.1.1/Resources/library/mgcv'
** Restoring previous '/Library/Frameworks/R.framework/Versions/2.1.1/ 
Resources/library/mgcv'
multiple definitions of symbol _xerbla_
/Library/Frameworks/R.framework/R(print.lo) definition of _xerbla_
/System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/ 
vecLib.framework/Versions/A/libBLAS.dylib(single module) definition  
of _xerbla_
ld: warning multiple definitions of symbol _signgam
/Library/Frameworks/R.framework/R(lgamma.lo) definition of _signgam
/usr/lib/libSystem.dylib(gamma9.o) definition of _signgam
ld: gcv.o has external relocation entries in non-writable section  
(__TEXT,__text) for symbols:
restFP
saveFP
make: *** [mgcv.so] Error 1
ERROR: compilation failed for package 'mgcv'

_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From wongg62 at yahoo.com  Mon Aug  1 21:15:37 2005
From: wongg62 at yahoo.com (Gary Wong)
Date: Mon, 1 Aug 2005 12:15:37 -0700 (PDT)
Subject: [R] How to hiding code for a package
In-Reply-To: <42EE4792.5070904@pdf.com>
Message-ID: <20050801191537.55131.qmail@web80314.mail.yahoo.com>



--- Spencer Graves <spencer.graves at pdf.com> wrote:

> Dear Gary Wong:
> 
> 	  Are you trying to defeat the GNU License?  If so,
> why not make it 
> available as an S-Plus library?  There, you don't
> have to provide the 
> source;  binary files will suffice.
> 
> 	  spencer graves
> 
> bogdan romocea wrote:
> 
> > There's something else you could try - since you
> can't hide the code,
> > obfuscate it. Hide the real thing in a large pile
> of useless,
> > complicated, awfully formatted code that would
> stop anyone except the
> > most desperate (including yourself, after a couple
> of weeks/months)
> > from trying to understand it. The best solution
> would be to compile
> > the code, but R is not there yet.
> > 
> > 
> > 
> >>-----Original Message-----
> >>From: Prof Brian Ripley
> [mailto:ripley at stats.ox.ac.uk] 
> >>Sent: Saturday, July 30, 2005 5:35 AM
> >>To: Gary Wong
> >>Cc: r-help at stat.math.ethz.ch
> >>Subject: Re: [R] How to hiding code for a package
> >>
> >>
> >>What you ask is impossible.  For a function to be
> callable it 
> >>has to be 
> >>locatable and hence can be printed.
> >>
> >>One possibility is to have a namespace, and
> something like
> >>
> >>foo <- function(...) foo_internal(...)
> >>
> >>where foo is exported but foo_internal is not. 
> Then foo_internal is 
> >>hidden from casual inspection, but it can be
> listed by cognescenti.
> >>
> >>Why do you want to do this?  Anyhone can read the
> source code of your 
> >>package, and any function which can be called can
> be 
> >>deparsed, possibly 
> >>after jumping through a few hoops.
> >>
> >>On Sat, 30 Jul 2005, Gary Wong wrote:
> >>
> >>
> >>>Hey everyone,
> >>>
> >>>I have made a package and wish to release it but
> >>>before then I have a problem. I have a few
> functions
> >>>in this package written in R that I wish to hide
> such
> >>>that after installation, someone can use say the
> >>>function >foo(parameters = "") but cannot do
> >foo.
> >>>Typing foo should not show the source code or at
> least
> >>>not all of it. Is there a way to do this ? I have
> >>>searched the mailing list and used google, and
> have
> >>>found something like "[R] Hiding internal package
> >>>functions for the doc. pkg-internal.Rd" but this
> seems
> >>>different since it seems that the keyword
> internal
> >>>just hides the function from showing in the index
> and
> >>>hides documentation, not the function itself. Can
> >>>someone help? Thanks
> >>
> >>-- 
> >>Brian D. Ripley,                 
> ripley at stats.ox.ac.uk
> >>Professor of Applied Statistics, 
> http://www.stats.ox.ac.uk/~ripley/
> >>University of Oxford,             Tel:  +44 1865
> 272861 (self)
> >>1 South Parks Road,                     +44 1865
> 272866 (PA)
> >>Oxford OX1 3TG, UK                Fax:  +44 1865
> 272595
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide! 
> >>http://www.R-project.org/posting-guide.html
> >>
> > 
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> -- 
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
> 
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From JAROSLAW.W.TUSZYNSKI at saic.com  Mon Aug  1 22:03:39 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Mon, 1 Aug 2005 16:03:39 -0400 
Subject: [R] New functions supporting GIF file format in R
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD57F4108@us-arlington-0668.mail.saic.com>

Sorry about late response but I was traveling and did not follow R-Help for
2 weeks.

I think, I prefer to leave read/write.GIF functions in my package where I
have a full control of IO formats. I like to store images as integer or real
matrices, and movies as 3D arrays. I believe that 'pixmap' package (as well
as 'rimage' package and possibly others) use specialized classes for images
, and do not handle movies at all (correct me if I am wrong).  

If you would like to add capability reading and writing GIF files (or ENVI
files - another multi-frame file format - see read/write.ENVI) to the
'pixmap' class, feel free to write a shell around my function. With input in
correct range (0:255) and option "scale='never'", no processing will be done
to your data on the way in or out. Also, I am not planning on making any
changes to that function, unless bugs are found. 

Regards,

Jarek
====================================================\=======

 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">   \
 Jaroslaw.W.Tuszynski at saic.com                     `    \



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Martin Maechler
Sent: Tuesday, July 19, 2005 2:53 AM
To: Tuszynski, Jaroslaw W.
Cc: (r-help at stat.math.ethz.ch.)
Subject: Re: [R] New functions supporting GIF file format in R

>>>>> "JarekT" == Tuszynski, Jaroslaw W <JAROSLAW.W.TUSZYNSKI at saic.com>
>>>>>     on Mon, 18 Jul 2005 16:00:43 -0400 writes:

    JarekT> Hi, A minor announcement. I just added two functions
    JarekT> for reading and writing GIF files to my caTools
    JarekT> package. Input and output is in the form of standard
    JarekT> R matrices or arrays, and standard R color-maps
    JarekT> (palettes). The functions can read and write both
    JarekT> regular GIF images, as well as, multi-frame animated
    JarekT> GIFs. Most of the work is done in C level code
    JarekT> (included), so functions do not use any external
    JarekT> libraries.

 

    JarekT> For more info and examples go to
    JarekT> http://cran.r-project.org/doc/packages/caTools.pdf
    JarekT> <http://cran.r-project.org/doc/packages/caTools.pdf>
    JarekT> and click GIF.

Wouldn't it make sense to donate these to the 'pixmap' package which is
dedicated to such objects and has been in place for a very long time?

Regards,
Martin

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From edhuang00 at yahoo.com  Mon Aug  1 23:54:44 2005
From: edhuang00 at yahoo.com (Haibo Huang)
Date: Mon, 1 Aug 2005 14:54:44 -0700 (PDT)
Subject: [R] NA when using read.csv
Message-ID: <20050801215445.64238.qmail@web31005.mail.mud.yahoo.com>

Hi, when I used:

Dist=read.csv("test.csv",header=TRUE)

to read data from CSV file. For some cells, R
mistakenly put in as NA, while most of the cells still
appears to be right, and there is no error message in
R. I am pretty sure the csv file is all right, but
just can't figure out what went wrong. Can someone
share your thoughts with me? Thanks!

Ed



From ggrothendieck at gmail.com  Tue Aug  2 00:05:11 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 1 Aug 2005 18:05:11 -0400
Subject: [R] NA when using read.csv
In-Reply-To: <20050801215445.64238.qmail@web31005.mail.mud.yahoo.com>
References: <20050801215445.64238.qmail@web31005.mail.mud.yahoo.com>
Message-ID: <971536df050801150578e7a877@mail.gmail.com>

On 8/1/05, Haibo Huang <edhuang00 at yahoo.com> wrote:
> Hi, when I used:
> 
> Dist=read.csv("test.csv",header=TRUE)
> 
> to read data from CSV file. For some cells, R
> mistakenly put in as NA, while most of the cells still

Its not likely that there are errors in this software so
its probably not a mistake but some other cause.

> appears to be right, and there is no error message in
> R. I am pretty sure the csv file is all right, but
> just can't figure out what went wrong. Can someone
> share your thoughts with me? Thanks!

Read the posting guide at  the bottom of each post.
In particular, cut down the input file to a few lines that
still exhibit the problem in order to provide a reproducible 
example. 

As an aside note that 'header = TRUE' is the default in read.csv
(but not on read.table) so you don't need to specify it.



From tsjerkw at gmail.com  Tue Aug  2 00:16:47 2005
From: tsjerkw at gmail.com (Tsjerk Wassenaar)
Date: Mon, 1 Aug 2005 23:16:47 +0100
Subject: [R] canonical correlations on multiple sets
Message-ID: <8ff898150508011516192128da@mail.gmail.com>

Hi!

I was wondering whether anybody could help me with canonical
correlation on multiple sets (3 or 4) of variates, e.g. using one of
the methods suggested by Kettenring (Biometrika 58(3):433, 1971),
starting from covariance or correlation matrices.

If someone could point me to an efficient way to achieve this or maybe
share a method, I would be forever grateful.

Some additional information on the data:

Submatrices of covariance matrix S: S11, S12, S13, (S14, ) S22, S23,
(S24, ) S33 (, S34, S44), with dim(S) = p + q + q or p + p + q + q

I would like to retrieve the canonical correlates and the canonical
variates for all sets.

Thanks in advance,

Tsjerk



From t.gill1 at uq.edu.au  Tue Aug  2 01:53:17 2005
From: t.gill1 at uq.edu.au (Tony Gill)
Date: Tue, 2 Aug 2005 09:53:17 +1000
Subject: [R] Rgdal windows binary warning message
Message-ID: <200508012353.j71NrHpW066385@smtp1.uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050802/1aef7f8c/attachment.pl

From zhilinliu_email at yahoo.com  Tue Aug  2 02:27:51 2005
From: zhilinliu_email at yahoo.com (Zhilin Liu)
Date: Mon, 1 Aug 2005 17:27:51 -0700 (PDT)
Subject: [R] can we manage memory usage to increase speed?
Message-ID: <20050802002752.73239.qmail@web50301.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050801/1952f38d/attachment.pl

From lschwei at mac.com  Tue Aug  2 02:32:18 2005
From: lschwei at mac.com (Lisa Schweitzer)
Date: Mon, 1 Aug 2005 20:32:18 -0400
Subject: [R] nnet package for OS X
In-Reply-To: <200508012353.j71NrHpW066385@smtp1.uq.edu.au>
References: <200508012353.j71NrHpW066385@smtp1.uq.edu.au>
Message-ID: <20EAC8E4-ECF1-49E7-8F60-BC5EC15D0D25@mac.com>

Hello every one--

My sincere apologies if I have missed something obvious, but I need  
to construct some multinomial logit models.  I remember using nnet  
for this in the past, but I am having trouble locating a OS X version  
of this (it's been a year or so since I had to use it). I found a   
Windows version, but when I try to install across platforms, it  
crashes R immediately--no error messages or anything helpful.  Can  
any one direct me to a repository, or alternatively, to another  
package readily available Mac side that can do simple multinomial  
logit models? This is basic survey data--nothing fancy needed.

All best,

Lisa



From sean.oriordain at gmail.com  Tue Aug  2 02:53:35 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Tue, 2 Aug 2005 01:53:35 +0100
Subject: [R] nnet package for OS X
In-Reply-To: <20EAC8E4-ECF1-49E7-8F60-BC5EC15D0D25@mac.com>
References: <200508012353.j71NrHpW066385@smtp1.uq.edu.au>
	<20EAC8E4-ECF1-49E7-8F60-BC5EC15D0D25@mac.com>
Message-ID: <8ed68eed050801175321f87b37@mail.gmail.com>

Hi Lisa,
as far as I know, nnet is part of the VR bundle which is a recommended
package...
refer http://www.stats.bris.ac.uk/R/src/contrib/Descriptions/VR.html

so just try library(nnet) and see what happens!

cheers!
Sean


On 02/08/05, Lisa Schweitzer <lschwei at mac.com> wrote:
> Hello every one--
> 
> My sincere apologies if I have missed something obvious, but I need
> to construct some multinomial logit models.  I remember using nnet
> for this in the past, but I am having trouble locating a OS X version
> of this (it's been a year or so since I had to use it). I found a
> Windows version, but when I try to install across platforms, it
> crashes R immediately--no error messages or anything helpful.  Can
> any one direct me to a repository, or alternatively, to another
> package readily available Mac side that can do simple multinomial
> logit models? This is basic survey data--nothing fancy needed.
> 
> All best,
> 
> Lisa
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From wuming.gong at gmail.com  Tue Aug  2 03:39:13 2005
From: wuming.gong at gmail.com (Wuming Gong)
Date: Tue, 2 Aug 2005 09:39:13 +0800
Subject: [R] NA when using read.csv
In-Reply-To: <971536df050801150578e7a877@mail.gmail.com>
References: <20050801215445.64238.qmail@web31005.mail.mud.yahoo.com>
	<971536df050801150578e7a877@mail.gmail.com>
Message-ID: <b428d06d05080118395319ee4c@mail.gmail.com>

Hi Haibo,

Are there any character "#" in the cells? By default, the things at
the right side of the character "#" will be masked as comments.

Wuming

On 8/2/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> On 8/1/05, Haibo Huang <edhuang00 at yahoo.com> wrote:
> > Hi, when I used:
> >
> > Dist=read.csv("test.csv",header=TRUE)
> >
> > to read data from CSV file. For some cells, R
> > mistakenly put in as NA, while most of the cells still
> 
> Its not likely that there are errors in this software so
> its probably not a mistake but some other cause.
> 
> > appears to be right, and there is no error message in
> > R. I am pretty sure the csv file is all right, but
> > just can't figure out what went wrong. Can someone
> > share your thoughts with me? Thanks!
> 
> Read the posting guide at  the bottom of each post.
> In particular, cut down the input file to a few lines that
> still exhibit the problem in order to provide a reproducible
> example.
> 
> As an aside note that 'header = TRUE' is the default in read.csv
> (but not on read.table) so you don't need to specify it.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Chunyu.Yang at phd.mccombs.utexas.edu  Tue Aug  2 04:31:05 2005
From: Chunyu.Yang at phd.mccombs.utexas.edu (Chunyu Yang {msbbb062})
Date: Mon, 1 Aug 2005 21:31:05 -0500
Subject: [R] Can R do regression with absolute error loss?
Message-ID: <D0FDBB819E2E9D44BDC404AD94B0D36F0228225A@E2K3BE.mccombs.utexas.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050801/24dd861e/attachment.pl

From ggrothendieck at gmail.com  Tue Aug  2 04:46:09 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 1 Aug 2005 22:46:09 -0400
Subject: [R] Can R do regression with absolute error loss?
In-Reply-To: <D0FDBB819E2E9D44BDC404AD94B0D36F0228225A@E2K3BE.mccombs.utexas.edu>
References: <D0FDBB819E2E9D44BDC404AD94B0D36F0228225A@E2K3BE.mccombs.utexas.edu>
Message-ID: <971536df050801194638ade65d@mail.gmail.com>

Check out the quantreg package.

On 8/1/05, Chunyu Yang {msbbb062} <Chunyu.Yang at phd.mccombs.utexas.edu> wrote:
> Dear R users,
> 
> 
> 
> I wonder if there are some functions or packages in R that can perform
> regression under absolute error loss. I have searched the full manual of
> R, but can not find it. I really appreciate your help.
> 
> 
> 
> Best regards,
> 
> 
> 
> Ben Yang
> 
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jjmichael at comcast.net  Tue Aug  2 04:51:58 2005
From: jjmichael at comcast.net (Jacob Michaelson)
Date: Mon, 1 Aug 2005 20:51:58 -0600
Subject: [R] (no subject)
Message-ID: <22761BFE-8A79-4A81-966F-6E863E556A83@comcast.net>

I've been using R for a while under Mac OS X, which thanks to the R  
on OS X developers, is probably the best platform for learning R.  I  
recently built a Linux box with a Pentium D processor, and am running  
an AMD64 port of Ubuntu with the SMP kernel.

After setting up the basics on the box, I thought I'd install R as  
well. I've had a very hard time finding good documentation on some  
configure flags/options for compiling a 64-bit version of R on  
Linux.  I thought this was very strange, considering Linux is  
apparently the R developer's platform of choice.

Can anyone point me to some good build instructions for 64-bit R  
under Linux?  Should I compile it against any additional libraries  
for better performance?

Thanks in advance for any pointers.

--Jake



From jjmichael at comcast.net  Tue Aug  2 04:53:09 2005
From: jjmichael at comcast.net (Jacob Michaelson)
Date: Mon, 1 Aug 2005 20:53:09 -0600
Subject: [R] linux compile options (64-bit)
References: <22761BFE-8A79-4A81-966F-6E863E556A83@comcast.net>
Message-ID: <5FD5AD51-2B4A-4669-AC0F-DBD1541B10E8@comcast.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050801/85fd2340/attachment.pl

From edhuang00 at yahoo.com  Tue Aug  2 04:59:46 2005
From: edhuang00 at yahoo.com (Haibo Huang)
Date: Mon, 1 Aug 2005 19:59:46 -0700 (PDT)
Subject: [R] can we manage memory usage to increase speed?
In-Reply-To: <20050802002752.73239.qmail@web50301.mail.yahoo.com>
Message-ID: <20050802025946.37215.qmail@web31006.mail.mud.yahoo.com>

Please refer to the following post.

Ed

--- Mike Lawrence <Mike.Lawrence at dal.ca> wrote:

> Date: Mon,  1 Aug 2005 00:19:06 -0300
> From: Mike Lawrence <Mike.Lawrence at dal.ca>
> To: "Briggs, Meredith M"
> <Meredith.Briggs at team.telstra.com>
> CC: r-help at stat.math.ethz.ch
> Subject: Re: [R] How do you increase memeory?
> 
> memory.limit(size = x)
> 
> where x is the desired memory limit in MB.
> 
> 
> 
> Quoting "Briggs, Meredith M"
> <Meredith.Briggs at team.telstra.com>:
> 
> > Hello
> >
> >
> > Function memory.size() =435109888. How do I
> increase it by, say 30%?
> >
> > Thanks
> > Meredith
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> 
> 
> -- 
> 
> Mike Lawrence, BA(Hons)
> Research Assistant to Dr. Gail Eskes
> Dalhousie University & QEII Health Sciences Centre
> (Psychiatry)
> 
> Mike.Lawrence at Dal.Ca
> 
> "The road to Wisdom? Well, it's plain and simple to
> express:
> Err and err and err again, but less and less and
> less."
> - Piet Hein
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 


--- Zhilin Liu <zhilinliu_email at yahoo.com> wrote:

> Hi,
>  
> Thanks for reading.
>  
> I am running  a process in R for microarray data
> analysis. RedHat Enterprise Linux 4, dual AMD CPU,
> 6G memory. However, the R process use only a total
> of <200M memory. And the CPU usage is total to ~110%
> for two. The program takes at least 2 weeks to run
> at the current speed. Is there some way we can
> increase the usage of CPUs and memories and speed
> up? Any suggestion is appreciated.
>  
> Thanks again.
>  
> Zhilin 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Tue Aug  2 08:34:39 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 Aug 2005 07:34:39 +0100 (BST)
Subject: [R] linux compile options (64-bit)
In-Reply-To: <5FD5AD51-2B4A-4669-AC0F-DBD1541B10E8@comcast.net>
References: <22761BFE-8A79-4A81-966F-6E863E556A83@comcast.net>
	<5FD5AD51-2B4A-4669-AC0F-DBD1541B10E8@comcast.net>
Message-ID: <Pine.LNX.4.61.0508020729350.19394@gannet.stats>

We find it equally strange that you posted this!

The advice _is_ in the R-admin manual which the INSTALL file asks you to 
read if you have any questions.  It covers using enhanced BLAS libraries.

R builds out of the box on FC3, FC4 and Suse on AMD64.  I use Goto's BLAS, 
but ATLAS can be used (except that building a shared version is tricky).

Quite a few packages have been written in ways that stop them building on 
64-bit platforms (and the maintainers have been informed but not fixed 
them).

On Mon, 1 Aug 2005, Jacob Michaelson wrote:

> Sorry--sent this before I added a subject line...
>
> Begin forwarded message:
>
>> From: Jacob Michaelson <jjmichael at comcast.net>
>> Date: August 1, 2005 8:51:58 PM MDT
>> To: r-help at stat.math.ethz.ch
>>
>>
>> I've been using R for a while under Mac OS X, which thanks to the R
>> on OS X developers, is probably the best platform for learning R.
>> I recently built a Linux box with a Pentium D processor, and am
>> running an AMD64 port of Ubuntu with the SMP kernel.
>>
>> After setting up the basics on the box, I thought I'd install R as
>> well. I've had a very hard time finding good documentation on some
>> configure flags/options for compiling a 64-bit version of R on
>> Linux.  I thought this was very strange, considering Linux is
>> apparently the R developer's platform of choice.
>>
>> Can anyone point me to some good build instructions for 64-bit R
>> under Linux?  Should I compile it against any additional libraries
>> for better performance?

> 	[[alternative HTML version deleted]]

> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Aug  2 08:38:54 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 Aug 2005 07:38:54 +0100 (BST)
Subject: [R] Rgdal windows binary warning message
In-Reply-To: <200508012353.j71NrHpW066385@smtp1.uq.edu.au>
References: <200508012353.j71NrHpW066385@smtp1.uq.edu.au>
Message-ID: <Pine.LNX.4.61.0508020736370.19394@gannet.stats>

This is a consequence of how VC++ compiled gdal.  R is protecting 
itself against that.  Since R did not crash, there is nothing to worry 
about.

On Tue, 2 Aug 2005, Tony Gill wrote:

> Hi all,
>
> I just downloaded windows binaries of RGDAL (from
> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.1/) and installed.
>
> I ran the example R_HOME\library\rgdal\R-ex\getPixmapGDAL.R and everything
> seemed to work as expected. However I got the following warning message:
>
> DLL attempted to change FPU control word from 8001f to 9001f
>
> The R-help (?dyn.load) describes the problem as:
>
> ************************************
> External code must not change the floating point control word, but
>     many DLLs do so.  Common changes are to set it to use 53 bit
>     precision instead of R's default 64 bit precision, or to unmask
>     some exceptions.  'dyn.load' detects such changes,  and restores
>     R's control word to its default value of hex 8001F.   This may
>     cause the DLL to malfunction; if so, it should be rewritten to
>     save and restore the control word itself.  If 'warn.FPU' is set to
>     'TRUE' using the 'options' function,  a warning will be printed.
>     (If the warning says that the control word was changed from some
>     other value than 8001F,  please report the circumstances to the
>     Windows maintainers:   that probably indicates an internal bug.)
>
> ************************************
>
> Does anyone know if this is a major problem for reading and manipulating
> image files using RDAL? And if so are there windows binaries which have
> patched it up?
>
> Thanks in advance
>
> Tony
>
> ******************************************
> Tony Gill - PhD Candidate
> Centre for Remote Sensing & Spatial Information Science
> School of Geography, Planning & Architecture
> University of Queensland
> Brisbane, Queensland, AUSTRALIA, 4072
> Ph: 61-7-3365-7027
> email: t.gill1 at uq.edu.au
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Aug  2 08:42:07 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 Aug 2005 07:42:07 +0100 (BST)
Subject: [R] can we manage memory usage to increase speed?
In-Reply-To: <20050802025946.37215.qmail@web31006.mail.mud.yahoo.com>
References: <20050802025946.37215.qmail@web31006.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.61.0508020739180.19394@gannet.stats>

On Mon, 1 Aug 2005, Haibo Huang wrote:

> Please refer to the following post.

Which is about Windows only, not Linux.  (And on Windows, the answer given 
is on the help page for memory.size. together with a better one.)

>
> Ed
>
> --- Mike Lawrence <Mike.Lawrence at dal.ca> wrote:
>
>> Date: Mon,  1 Aug 2005 00:19:06 -0300
>> From: Mike Lawrence <Mike.Lawrence at dal.ca>
>> To: "Briggs, Meredith M"
>> <Meredith.Briggs at team.telstra.com>
>> CC: r-help at stat.math.ethz.ch
>> Subject: Re: [R] How do you increase memeory?
>>
>> memory.limit(size = x)
>>
>> where x is the desired memory limit in MB.
>>
>>
>>
>> Quoting "Briggs, Meredith M"
>> <Meredith.Briggs at team.telstra.com>:
>>
>>> Hello
>>>
>>>
>>> Function memory.size() =435109888. How do I
>> increase it by, say 30%?
>>>
>>> Thanks
>>> Meredith

> --- Zhilin Liu <zhilinliu_email at yahoo.com> wrote:
>
>> Hi,
>>
>> Thanks for reading.
>>
>> I am running  a process in R for microarray data
>> analysis. RedHat Enterprise Linux 4, dual AMD CPU,
>> 6G memory. However, the R process use only a total
>> of <200M memory. And the CPU usage is total to ~110%
>> for two. The program takes at least 2 weeks to run
>> at the current speed. Is there some way we can
>> increase the usage of CPUs and memories and speed
>> up? Any suggestion is appreciated.
>>
>> Thanks again.
>>
>> Zhilin
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gb at stat.umu.se  Tue Aug  2 10:10:40 2005
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 2 Aug 2005 10:10:40 +0200
Subject: [R] linux compile options (64-bit)
In-Reply-To: <Pine.LNX.4.61.0508020729350.19394@gannet.stats>
References: <22761BFE-8A79-4A81-966F-6E863E556A83@comcast.net>
	<5FD5AD51-2B4A-4669-AC0F-DBD1541B10E8@comcast.net>
	<Pine.LNX.4.61.0508020729350.19394@gannet.stats>
Message-ID: <20050802081040.GA28478@stat.umu.se>

On Tue, Aug 02, 2005 at 07:34:39AM +0100, Prof Brian Ripley wrote:
> We find it equally strange that you posted this!
> 
> The advice _is_ in the R-admin manual which the INSTALL file asks you to 
> read if you have any questions.  It covers using enhanced BLAS libraries.
> 
> R builds out of the box on FC3, FC4 and Suse on AMD64.  I use Goto's BLAS, 
> but ATLAS can be used (except that building a shared version is tricky).

Incidentally, I have just tried building R on a Fujitsu Amilo amd64 with
debian-amd64 (unstable) and ATLAS. Both 'make' and 'make check' worked
without complaints with gcc-3.4.5, but when I tried gcc-4.0.1, 'make check' 
failed with a segmentation error after
-----------------------------------------------------------------------------
R is now configured for x86_64-unknown-linux-gnu

  Source directory:          .
  Installation directory:    /usr/local

  C compiler:                /usr/bin/gcc-4.0  -g -O2
  C++ compiler:              /usr/bin/g++-4.0  -g -O2
  Fortran compiler:          /usr/bin/gfortran-4.0  -g -O2

  Interfaces supported:      X11, tcltk
  External libraries:        readline, BLAS(ATLAS)
  Additional capabilities:   PNG, JPEG, iconv, MBCS, NLS
  Options enabled:           R profiling

  Recommended packages:      yes
-------------------------------------------------------------------
amilo:/usr/local/src/R/R-2.1.1# make check
make[1]: Entering directory `/usr/local/src/R/R-2.1.1/tests'
make[2]: Entering directory `/usr/local/src/R/R-2.1.1/tests'
make[3]: Enteri|ng directory `/usr/local/src/R/R-2.1.1/tests/Examples'
make[4]: Entering directory `/usr/local/src/R/R-2.1.1/tests/Examples'
make[4]: Leaving directory `/usr/local/src/R/R-2.1.1/tests/Examples'
make[4]: Entering directory `/usr/local/src/R/R-2.1.1/tests/Examples'
collecting examples for package 'base' ...
make[5]: Entering directory `/usr/local/src/R/R-2.1.1/src/library'
 >>> Building/Updating help pages for package 'base'
     Formats: text html latex example
make[5]: Leaving directory `/usr/local/src/R/R-2.1.1/src/library'
running code in 'base-Ex.R' .../bin/sh: line 1:  9010 Segmentation fault      ../../bin/R --vanilla <base-Ex.R >base-Ex.Rout 2>&1
make[4]: *** [base-Ex.Rout] Error 1
make[4]: Leaving directory `/usr/local/src/R/R-2.1.1/tests/Examples'
make[3]: *** [test-Examples-Base] Error 2
make[3]: Leaving directory `/usr/local/src/R/R-2.1.1/tests/Examples'
make[2]: *** [test-Examples] Error 2
make[2]: Leaving directory `/usr/local/src/R/R-2.1.1/tests'
make[1]: *** [test-all-basics] Error 1
make[1]: Leaving directory `/usr/local/src/R/R-2.1.1/tests'
make: *** [check] Error 2


> eigen(print(cbind(c(0,1i), c(-1i,0))))# Hermite ==> real Eigen values
     [,1] [,2]
[1,] 0+0i 0-1i
[2,] 0+1i 0+0i

Running it under 'R -d gdb': R "hangs"; after C-c:

Program received signal SIGINT, Interrupt.
zhetd2_ (uplo=@0x7fffff92ebbe, n=@0x7fffff92e9f4, a=0x10900f0,
    lda=@0x7fffff92ebb8, d=0x13b06e8, e=0xb6add8, tau=0x1bb6448,
    info=@0x7fffff92ea04, _uplo=1) at cmplx.f:8330
8330                   CALL ZAXPY( N-I, ALPHA, A( I+1, I ), 1, TAU( I ), 1 )
Current language:  auto; currently fortran
-----------------------------------------------------------------------

[...]

G??ran
-- 
G??ran Brostr??m                    tel: +46 90 786 5223
Department of Statistics          fax: +46 90 786 6614
Ume?? University                   http://www.stat.umu.se/~goran.brostrom/
SE-90187 Ume??, Sweden             e-mail: gb at stat.umu.se



From ales.ziberna at guest.arnes.si  Tue Aug  2 10:12:10 2005
From: ales.ziberna at guest.arnes.si (=?iso-8859-2?Q?Ale=B9_=AEiberna?=)
Date: Tue, 2 Aug 2005 10:12:10 +0200
Subject: [R] Putting all elementes of the list in an enviorment of a function
Message-ID: <020501c59739$e2138fb0$598debd4@ales>

Hello!

I have two functions.

The first one prepares the arguments for the second one. What is the best 
way to put all resoults of the first one into the second one? I tried 
attach, however the object in the "main" enviorment have a priority over the 
ones in list. An example is at the end.

Thanks in advance for any suggestions!
Ales Ziberna

For example - I would like to use just "a" instead of "list$a" in fuction 
"second"

first<-function(a,b){
    if(length(a)!=1) a <- a[1]
    if(length(b)!=1) b <- b[1]
    list(a=a,b=b)
}

second<-function(list,c){
    list$a + list$b + c
}

a<-c(2,3)
b<-4:64
c<-5

res<-first(a,b)
second(res,c)



From ripley at stats.ox.ac.uk  Tue Aug  2 10:33:45 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 Aug 2005 09:33:45 +0100 (BST)
Subject: [R] linux compile options (64-bit)
In-Reply-To: <20050802081040.GA28478@stat.umu.se>
References: <22761BFE-8A79-4A81-966F-6E863E556A83@comcast.net>
	<5FD5AD51-2B4A-4669-AC0F-DBD1541B10E8@comcast.net>
	<Pine.LNX.4.61.0508020729350.19394@gannet.stats>
	<20050802081040.GA28478@stat.umu.se>
Message-ID: <Pine.LNX.4.61.0508020914500.21072@gannet.stats>

On Tue, 2 Aug 2005, G?ran Brostr?m wrote:

> On Tue, Aug 02, 2005 at 07:34:39AM +0100, Prof Brian Ripley wrote:
>> We find it equally strange that you posted this!
>>
>> The advice _is_ in the R-admin manual which the INSTALL file asks you to
>> read if you have any questions.  It covers using enhanced BLAS libraries.
>>
>> R builds out of the box on FC3, FC4 and Suse on AMD64.  I use Goto's BLAS,
>> but ATLAS can be used (except that building a shared version is tricky).
>
> Incidentally, I have just tried building R on a Fujitsu Amilo amd64 with
> debian-amd64 (unstable) and ATLAS. Both 'make' and 'make check' worked
> without complaints with gcc-3.4.5,

There is no gcc 3.4.5!  There are versions 3.3.5 and 3.4.4.

> but when I tried gcc-4.0.1, 'make check' failed with a segmentation 
> error after

I have seen this on FC3.  Note that ZAXPY is a BLAS routine, and you are 
using ATLAS: was that also built with gcc-4.0.1?  On FC3 I get the failure 
if I use its BLAS, and not if I configure R with --without-blas.  (I did 
not see the problem using the gcc4 RPM from FC3 update, and I gather 
others have managed to use gcc4 from FC4.)

We do not recommend gcc-4.0.x as yet: we have yet to see any performance 
gains (only losses) from it, and this is one of a number of known 
nuisances.  More serious are places where it apparently generates 
incorrect code and so gives incorrect answers.

...

>> eigen(print(cbind(c(0,1i), c(-1i,0))))# Hermite ==> real Eigen values
>     [,1] [,2]
> [1,] 0+0i 0-1i
> [2,] 0+1i 0+0i
>
> Running it under 'R -d gdb': R "hangs"; after C-c:
>
> Program received signal SIGINT, Interrupt.
> zhetd2_ (uplo=@0x7fffff92ebbe, n=@0x7fffff92e9f4, a=0x10900f0,
>    lda=@0x7fffff92ebb8, d=0x13b06e8, e=0xb6add8, tau=0x1bb6448,
>    info=@0x7fffff92ea04, _uplo=1) at cmplx.f:8330
> 8330                   CALL ZAXPY( N-I, ALPHA, A( I+1, I ), 1, TAU( I ), 1 )
> Current language:  auto; currently fortran

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Tue Aug  2 10:35:35 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 Aug 2005 09:35:35 +0100 (BST)
Subject: [R] Putting all elementes of the list in an enviorment of a
 function
In-Reply-To: <020501c59739$e2138fb0$598debd4@ales>
References: <020501c59739$e2138fb0$598debd4@ales>
Message-ID: <Pine.LNX.4.61.0508020934420.21072@gannet.stats>

?with will help you.

I would avoid using 'list' as a function name, as it will confuse people 
and might confuse R too.

On Tue, 2 Aug 2005, [iso-8859-2] Alea }iberna wrote:

> Hello!
>
> I have two functions.
>
> The first one prepares the arguments for the second one. What is the best
> way to put all resoults of the first one into the second one? I tried
> attach, however the object in the "main" enviorment have a priority over the
> ones in list. An example is at the end.
>
> Thanks in advance for any suggestions!
> Ales Ziberna
>
> For example - I would like to use just "a" instead of "list$a" in fuction
> "second"
>
> first<-function(a,b){
>    if(length(a)!=1) a <- a[1]
>    if(length(b)!=1) b <- b[1]
>    list(a=a,b=b)
> }
>
> second<-function(list,c){
>    list$a + list$b + c
> }
>
> a<-c(2,3)
> b<-4:64
> c<-5
>
> res<-first(a,b)
> second(res,c)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From aleszib at gmail.com  Tue Aug  2 11:01:01 2005
From: aleszib at gmail.com (Ales Ziberna)
Date: Tue, 2 Aug 2005 11:01:01 +0200
Subject: [R] Putting all elementes of the list in an enviorment of a
	function
References: <020501c59739$e2138fb0$598debd4@ales>
	<Pine.LNX.4.61.0508020934420.21072@gannet.stats>
Message-ID: <029401c59741$4eab3a40$598debd4@ales>

Thank you!

However, this does not do exacty what I want. I would like somehow to modify 
only the function second.

BTW, I used "list" only to create a "list", it is not one of my functions.

Thanks again,
Ales Ziberna

----- Original Message ----- 
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "Ales Ziberna" <ales.ziberna at guest.arnes.si>
Cc: "R-help" <r-help at stat.math.ethz.ch>
Sent: Tuesday, August 02, 2005 10:35 AM
Subject: Re: [R] Putting all elementes of the list in an enviorment of a 
function


> ?with will help you.
>
> I would avoid using 'list' as a function name, as it will confuse people
> and might confuse R too.
>
> On Tue, 2 Aug 2005, [iso-8859-2] Alea }iberna wrote:
>
>> Hello!
>>
>> I have two functions.
>>
>> The first one prepares the arguments for the second one. What is the best
>> way to put all resoults of the first one into the second one? I tried
>> attach, however the object in the "main" enviorment have a priority over 
>> the
>> ones in list. An example is at the end.
>>
>> Thanks in advance for any suggestions!
>> Ales Ziberna
>>
>> For example - I would like to use just "a" instead of "list$a" in fuction
>> "second"
>>
>> first<-function(a,b){
>>    if(length(a)!=1) a <- a[1]
>>    if(length(b)!=1) b <- b[1]
>>    list(a=a,b=b)
>> }
>>
>> second<-function(list,c){
>>    list$a + list$b + c
>> }
>>
>> a<-c(2,3)
>> b<-4:64
>> c<-5
>>
>> res<-first(a,b)
>> second(res,c)
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From gb at stat.umu.se  Tue Aug  2 11:23:51 2005
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 2 Aug 2005 11:23:51 +0200
Subject: [R] linux compile options (64-bit)
In-Reply-To: <Pine.LNX.4.61.0508020914500.21072@gannet.stats>
References: <22761BFE-8A79-4A81-966F-6E863E556A83@comcast.net>
	<5FD5AD51-2B4A-4669-AC0F-DBD1541B10E8@comcast.net>
	<Pine.LNX.4.61.0508020729350.19394@gannet.stats>
	<20050802081040.GA28478@stat.umu.se>
	<Pine.LNX.4.61.0508020914500.21072@gannet.stats>
Message-ID: <20050802092351.GA30688@stat.umu.se>

On Tue, Aug 02, 2005 at 09:33:45AM +0100, Prof Brian Ripley wrote:
> On Tue, 2 Aug 2005, G??ran Brostr??m wrote:
[...]

> >Incidentally, I have just tried building R on a Fujitsu Amilo amd64 with
> >debian-amd64 (unstable) and ATLAS. Both 'make' and 'make check' worked
> >without complaints with gcc-3.4.5,
> 
> There is no gcc 3.4.5!  There are versions 3.3.5 and 3.4.4.

I apologize for the incomplete description; gcc -v gives:

gcc version 3.4.5 20050706 (prerelease) (Debian 3.4.4-5)

> >but when I tried gcc-4.0.1, 'make check' failed with a segmentation 
> >error after
> 
> I have seen this on FC3.  Note that ZAXPY is a BLAS routine, and you are 
> using ATLAS: was that also built with gcc-4.0.1?  

Probably not; I just 'apt-get install'ed atlas3-base etc. I'll build atlas
from source and try again. 

> On FC3 I get the failure 
> if I use its BLAS, and not if I configure R with --without-blas.  (I did 
> not see the problem using the gcc4 RPM from FC3 update, and I gather 
> others have managed to use gcc4 from FC4.)
> 
> We do not recommend gcc-4.0.x as yet: we have yet to see any performance 
> gains (only losses) from it, and this is one of a number of known 
> nuisances.  More serious are places where it apparently generates 
> incorrect code and so gives incorrect answers.

OK. An additional advantage with gfortran(-4.x) will be the possibility to
use fortan95 code, n'est ce pas?

G??ran



From ripley at stats.ox.ac.uk  Tue Aug  2 11:25:21 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 Aug 2005 10:25:21 +0100 (BST)
Subject: [R] Putting all elementes of the list in an enviorment of a
 function
In-Reply-To: <029401c59741$4eab3a40$598debd4@ales>
References: <020501c59739$e2138fb0$598debd4@ales>
	<Pine.LNX.4.61.0508020934420.21072@gannet.stats>
	<029401c59741$4eab3a40$598debd4@ales>
Message-ID: <Pine.LNX.4.61.0508021020350.25607@gannet.stats>

On Tue, 2 Aug 2005, Ales Ziberna wrote:

> Thank you!
>
> However, this does not do exacty what I want. I would like somehow to modify 
> only the function second.

What happened when you tried my suggestion as

second <- function(l, c) with(l, a + b + c)

?  It does work for me.

> BTW, I used "list" only to create a "list", it is not one of my functions.

You used it as a variable within second()!


> Thanks again,
> Ales Ziberna
>
> ----- Original Message ----- From: "Prof Brian Ripley" 
> <ripley at stats.ox.ac.uk>
> To: "Ales Ziberna" <ales.ziberna at guest.arnes.si>
> Cc: "R-help" <r-help at stat.math.ethz.ch>
> Sent: Tuesday, August 02, 2005 10:35 AM
> Subject: Re: [R] Putting all elementes of the list in an enviorment of a 
> function
>
>
>> ?with will help you.
>> 
>> I would avoid using 'list' as a function name, as it will confuse people
>> and might confuse R too.
>> 
>> On Tue, 2 Aug 2005, [iso-8859-2] Alea }iberna wrote:
>> 
>>> Hello!
>>> 
>>> I have two functions.
>>> 
>>> The first one prepares the arguments for the second one. What is the best
>>> way to put all resoults of the first one into the second one? I tried
>>> attach, however the object in the "main" enviorment have a priority over 
>>> the
>>> ones in list. An example is at the end.
>>> 
>>> Thanks in advance for any suggestions!
>>> Ales Ziberna
>>> 
>>> For example - I would like to use just "a" instead of "list$a" in fuction
>>> "second"
>>> 
>>> first<-function(a,b){
>>>    if(length(a)!=1) a <- a[1]
>>>    if(length(b)!=1) b <- b[1]
>>>    list(a=a,b=b)
>>> }
>>> 
>>> second<-function(list,c){
>>>    list$a + list$b + c
>>> }
>>> 
>>> a<-c(2,3)
>>> b<-4:64
>>> c<-5
>>> 
>>> res<-first(a,b)
>>> second(res,c)
>> 
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Aug  2 11:58:31 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 Aug 2005 10:58:31 +0100 (BST)
Subject: [R] linux compile options (64-bit)
In-Reply-To: <20050802092351.GA30688@stat.umu.se>
References: <22761BFE-8A79-4A81-966F-6E863E556A83@comcast.net>
	<5FD5AD51-2B4A-4669-AC0F-DBD1541B10E8@comcast.net>
	<Pine.LNX.4.61.0508020729350.19394@gannet.stats>
	<20050802081040.GA28478@stat.umu.se>
	<Pine.LNX.4.61.0508020914500.21072@gannet.stats>
	<20050802092351.GA30688@stat.umu.se>
Message-ID: <Pine.LNX.4.61.0508021052020.25929@gannet.stats>

On Tue, 2 Aug 2005, G?ran Brostr?m wrote:

> On Tue, Aug 02, 2005 at 09:33:45AM +0100, Prof Brian Ripley wrote:
>> On Tue, 2 Aug 2005, G?ran Brostr?m wrote:
> [...]
>
>>> Incidentally, I have just tried building R on a Fujitsu Amilo amd64 with
>>> debian-amd64 (unstable) and ATLAS. Both 'make' and 'make check' worked
>>> without complaints with gcc-3.4.5,
>>
>> There is no gcc 3.4.5!  There are versions 3.3.5 and 3.4.4.
>
> I apologize for the incomplete description; gcc -v gives:
>
> gcc version 3.4.5 20050706 (prerelease) (Debian 3.4.4-5)
>
>>> but when I tried gcc-4.0.1, 'make check' failed with a segmentation
>>> error after
>>
>> I have seen this on FC3.  Note that ZAXPY is a BLAS routine, and you are
>> using ATLAS: was that also built with gcc-4.0.1?
>
> Probably not; I just 'apt-get install'ed atlas3-base etc. I'll build atlas
> from source and try again.
>
>> On FC3 I get the failure
>> if I use its BLAS, and not if I configure R with --without-blas.  (I did
>> not see the problem using the gcc4 RPM from FC3 update, and I gather
>> others have managed to use gcc4 from FC4.)
>>
>> We do not recommend gcc-4.0.x as yet: we have yet to see any performance
>> gains (only losses) from it, and this is one of a number of known
>> nuisances.  More serious are places where it apparently generates
>> incorrect code and so gives incorrect answers.
>
> OK. An additional advantage with gfortran(-4.x) will be the possibility to
> use fortan95 code, n'est ce pas?

Some Fortran95 code, anyway.  (It is not yet a complete implementation.)

The problems we are seeing with gcc4 are mainly (but not 
entirely) with gfortran: it seems not quite ready for production use.
-4.0.1 is already a considerable improvement over -4.0.0.

There is another project (www.g95.org) that is using a slightly different 
version of these sources, and either g95 or gfortran can be used with 
gcc3 if you want to use F95 sources.  However, F95 is unlikely to be 
suitable for use in distributed R packages for a long time to come.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From aleszib at gmail.com  Tue Aug  2 11:57:27 2005
From: aleszib at gmail.com (Ales Ziberna)
Date: Tue, 2 Aug 2005 11:57:27 +0200
Subject: [R] Putting all elementes of the list in an enviorment of a
	function
References: <020501c59739$e2138fb0$598debd4@ales>
	<Pine.LNX.4.61.0508020934420.21072@gannet.stats>
	<029401c59741$4eab3a40$598debd4@ales>
	<Pine.LNX.4.61.0508021020350.25607@gannet.stats>
Message-ID: <02ad01c59748$b7e38d30$598debd4@ales>

I apologize, it seams did not interpret your first mail corectly!
Everything works now!

Thank you again!
Ales Ziberna
----- Original Message ----- 
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "Ales Ziberna" <aleszib at gmail.com>
Cc: "R-help" <r-help at stat.math.ethz.ch>
Sent: Tuesday, August 02, 2005 11:25 AM
Subject: Re: [R] Putting all elementes of the list in an enviorment of a 
function


> On Tue, 2 Aug 2005, Ales Ziberna wrote:
>
>> Thank you!
>>
>> However, this does not do exacty what I want. I would like somehow to 
>> modify only the function second.
>
> What happened when you tried my suggestion as
>
> second <- function(l, c) with(l, a + b + c)
>
> ?  It does work for me.
>
>> BTW, I used "list" only to create a "list", it is not one of my 
>> functions.
>
> You used it as a variable within second()!
>
>
>> Thanks again,
>> Ales Ziberna
>>
>> ----- Original Message ----- From: "Prof Brian Ripley" 
>> <ripley at stats.ox.ac.uk>
>> To: "Ales Ziberna" <ales.ziberna at guest.arnes.si>
>> Cc: "R-help" <r-help at stat.math.ethz.ch>
>> Sent: Tuesday, August 02, 2005 10:35 AM
>> Subject: Re: [R] Putting all elementes of the list in an enviorment of a 
>> function
>>
>>
>>> ?with will help you.
>>>
>>> I would avoid using 'list' as a function name, as it will confuse people
>>> and might confuse R too.
>>>
>>> On Tue, 2 Aug 2005, [iso-8859-2] Alea }iberna wrote:
>>>
>>>> Hello!
>>>>
>>>> I have two functions.
>>>>
>>>> The first one prepares the arguments for the second one. What is the 
>>>> best
>>>> way to put all resoults of the first one into the second one? I tried
>>>> attach, however the object in the "main" enviorment have a priority 
>>>> over the
>>>> ones in list. An example is at the end.
>>>>
>>>> Thanks in advance for any suggestions!
>>>> Ales Ziberna
>>>>
>>>> For example - I would like to use just "a" instead of "list$a" in 
>>>> fuction
>>>> "second"
>>>>
>>>> first<-function(a,b){
>>>>    if(length(a)!=1) a <- a[1]
>>>>    if(length(b)!=1) b <- b[1]
>>>>    list(a=a,b=b)
>>>> }
>>>>
>>>> second<-function(list,c){
>>>>    list$a + list$b + c
>>>> }
>>>>
>>>> a<-c(2,3)
>>>> b<-4:64
>>>> c<-5
>>>>
>>>> res<-first(a,b)
>>>> second(res,c)
>>>
>>> -- 
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From c.wallace at qmul.ac.uk  Tue Aug  2 11:58:19 2005
From: c.wallace at qmul.ac.uk (Chris Wallace)
Date: Tue, 02 Aug 2005 10:58:19 +0100
Subject: [R] converting stata's by syntax to R
In-Reply-To: <m3ek9dag6c.fsf@qmul.ac.uk> (Chris Wallace's message of "Mon, 01
	Aug 2005 15:24:27 +0100")
References: <m3ek9dag6c.fsf@qmul.ac.uk>
Message-ID: <m31x5c8xtw.fsf@qmul.ac.uk>

Chris Wallace <c.wallace at qmul.ac.uk> writes:

> I am struggling with migrating some stata code to R....

Thanks to all who replied.  It was very helpful to see a combination
of more direct stata->R translations and more R-ish code.  which.max()
solves my problem this time, but learning about split(), unsplit() and
duplicated() should make such problems fewer in the long run.

C.



From Allan at STATS.uct.ac.za  Tue Aug  2 12:06:13 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Tue, 02 Aug 2005 12:06:13 +0200
Subject: [R] R: regression data set
Message-ID: <42EF4595.40C9BC8C@STATS.uct.ac.za>

hi all

i am busy teaching a regression analysis course to second year science
students. the course is fairly theoretical with all of the standard
theorems and proofs...

i would like to give the class a practical assignment as well. could you
suggest a good problem and the location of the data set/s?

it would be good if the data set has been analysed by a number of other
people so that students can see the different ways of tackling a
regression problem. 

some of the issues to be covered:

estimation
is there really a model
variable selection ...
outliers and influential observations
interpreting the regression model


/
allan

From gb at stat.umu.se  Tue Aug  2 12:12:08 2005
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 2 Aug 2005 12:12:08 +0200
Subject: [R] linux compile options (64-bit)
In-Reply-To: <Pine.LNX.4.61.0508021052020.25929@gannet.stats>
References: <22761BFE-8A79-4A81-966F-6E863E556A83@comcast.net>
	<5FD5AD51-2B4A-4669-AC0F-DBD1541B10E8@comcast.net>
	<Pine.LNX.4.61.0508020729350.19394@gannet.stats>
	<20050802081040.GA28478@stat.umu.se>
	<Pine.LNX.4.61.0508020914500.21072@gannet.stats>
	<20050802092351.GA30688@stat.umu.se>
	<Pine.LNX.4.61.0508021052020.25929@gannet.stats>
Message-ID: <20050802101208.GA32181@stat.umu.se>

On Tue, Aug 02, 2005 at 10:58:31AM +0100, Prof Brian Ripley wrote:

> The problems we are seeing with gcc4 are mainly (but not 
> entirely) with gfortran: it seems not quite ready for production use.
> -4.0.1 is already a considerable improvement over -4.0.0.
> 
> There is another project (www.g95.org) that is using a slightly different 
> version of these sources, and either g95 or gfortran can be used with 
> gcc3 if you want to use F95 sources.  However, F95 is unlikely to be 
> suitable for use in distributed R packages for a long time to come.

Thanks; I'll stick to 3.4.4(!) and f77 for the time being.

G??ran



From jochen.einbeck at nuigalway.ie  Tue Aug  2 12:57:49 2005
From: jochen.einbeck at nuigalway.ie (Jochen Einbeck)
Date: Tue, 02 Aug 2005 11:57:49 +0100
Subject: [R] Read from data frame, and not from global environment
Message-ID: <42EF51AD.3060800@nuigalway.ie>

Dear members,

assume given  a function of type

test<-function(formula,  data , w){
  ......
  glm1<-glm(formula,  family=poisson, data=data, weights=w)
  ......
}

and a simple example data frame as

test.frame<-data.frame(x=1:10,y=(1:10)*2,a=(1:10)^3).

Let us now execute

test(y ~ x, test.frame, a )

My question is: What do I have to insert at the first occurance of ..... 
in the test function to ensure that

1) 'a'  is read from the data frame (and is only read from the global 
environment if  and only if  'a' is not found in the data frame)
2) glm finds w in in the local environment of the function 'test'

The question is obviously related to  Fernando's problem with   
'Defining a "local" function'  some months ago, though the discussion 
there does not solve the questions above.

Cheers,

Jochen Einbeck
NUI Galway, Ireland



From Kevin.Wang at maths.anu.edu.au  Tue Aug  2 13:29:27 2005
From: Kevin.Wang at maths.anu.edu.au (Kevin Wang)
Date: Tue, 02 Aug 2005 21:29:27 +1000
Subject: [R] R: regression data set
In-Reply-To: <42EF4595.40C9BC8C@STATS.uct.ac.za>
References: <42EF4595.40C9BC8C@STATS.uct.ac.za>
Message-ID: <42EF5917.4000907@maths.anu.edu.au>

Clark Allan wrote:

> i would like to give the class a practical assignment as well. could you
> suggest a good problem and the location of the data set/s?
> 
> it would be good if the data set has been analysed by a number of other
> people so that students can see the different ways of tackling a
> regression problem. 

If you want some "textbook" examples I'd recommend
Ripley and Venables's  Modern Applied Statistics With S (VR bundle);

Maindonald and Braun's Data Analysis and Graphics using R (DAAG package)

Cheers,

Kev

-- 
Ko-Kang Kevin Wang
PhD Student
Centre for Bioinformation Science
Building 27, Room 1004
Mathematical Sciences Institute (MSI)
Australian National University
Canberra, ACT 2601
Australia

Homepage: http://wwwmaths.anu.edu.au/~wangk/
Ph (W): +61-2-6125-2431
Ph (H): +61-2-6125-7407
Ph (M): +61-40-451-8301



From ripley at stats.ox.ac.uk  Tue Aug  2 13:32:35 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 Aug 2005 12:32:35 +0100 (BST)
Subject: [R] Read from data frame, and not from global environment
In-Reply-To: <42EF51AD.3060800@nuigalway.ie>
References: <42EF51AD.3060800@nuigalway.ie>
Message-ID: <Pine.LNX.4.61.0508021217570.31221@gannet.stats>

I don't think that is the best way to do what I guess you intended. Try 
something like

test <- function(formula,  data , weights)
{
     Call <- match.call()
     Call[[1]] <- as.name("glm")
     Call$family <- quote(poisson)
     glm1 <- eval.parent(Call)
     ....
}

which is probably giving the scoping that you want.

You could do what you ask for at 1) by something like

     wname <- deparse(substitute(w))
     w <- if(wname %in% names(data)) data[[wname]] else get(wname, .GlobalEnv)

and for 2) by replacing .GlobalEnv by an expression constructed by calls 
to environment() (I don't know exactly what you intended here).

On Tue, 2 Aug 2005, Jochen Einbeck wrote:

> Dear members,
>
> assume given  a function of type
>
> test<-function(formula,  data , w){
>  ......
>  glm1<-glm(formula,  family=poisson, data=data, weights=w)
>  ......
> }
>
> and a simple example data frame as
>
> test.frame<-data.frame(x=1:10,y=(1:10)*2,a=(1:10)^3).
>
> Let us now execute
>
> test(y ~ x, test.frame, a )
>
> My question is: What do I have to insert at the first occurance of .....
> in the test function to ensure that
>
> 1) 'a'  is read from the data frame (and is only read from the global
> environment if  and only if  'a' is not found in the data frame)
> 2) glm finds w in in the local environment of the function 'test'

That contradicts 1)!

> The question is obviously related to  Fernando's problem with
> 'Defining a "local" function'  some months ago, though the discussion
> there does not solve the questions above.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From murdoch at stats.uwo.ca  Tue Aug  2 13:59:21 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 02 Aug 2005 07:59:21 -0400
Subject: [R] Rgdal windows binary warning message
In-Reply-To: <Pine.LNX.4.61.0508020736370.19394@gannet.stats>
References: <200508012353.j71NrHpW066385@smtp1.uq.edu.au>
	<Pine.LNX.4.61.0508020736370.19394@gannet.stats>
Message-ID: <42EF6019.8030604@stats.uwo.ca>

Prof Brian Ripley wrote:
> This is a consequence of how VC++ compiled gdal.  R is protecting 
> itself against that.  Since R did not crash, there is nothing to worry 
> about.

To add to that:  the RGDAL maintainer could work around this bug in 
VC++.  I haven't used that compiler, but with others it is sufficient to 
ask R to set the FPU control word.  Instructions are here: 
<http://www.stats.uwo.ca/faculty/murdoch/software/compilingDLLs/index.html#fpu>

Duncan Murdoch
> 
> On Tue, 2 Aug 2005, Tony Gill wrote:
> 
> 
>>Hi all,
>>
>>I just downloaded windows binaries of RGDAL (from
>>http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.1/) and installed.
>>
>>I ran the example R_HOME\library\rgdal\R-ex\getPixmapGDAL.R and everything
>>seemed to work as expected. However I got the following warning message:
>>
>>DLL attempted to change FPU control word from 8001f to 9001f
>>
>>The R-help (?dyn.load) describes the problem as:
>>
>>************************************
>>External code must not change the floating point control word, but
>>    many DLLs do so.  Common changes are to set it to use 53 bit
>>    precision instead of R's default 64 bit precision, or to unmask
>>    some exceptions.  'dyn.load' detects such changes,  and restores
>>    R's control word to its default value of hex 8001F.   This may
>>    cause the DLL to malfunction; if so, it should be rewritten to
>>    save and restore the control word itself.  If 'warn.FPU' is set to
>>    'TRUE' using the 'options' function,  a warning will be printed.
>>    (If the warning says that the control word was changed from some
>>    other value than 8001F,  please report the circumstances to the
>>    Windows maintainers:   that probably indicates an internal bug.)
>>
>>************************************
>>
>>Does anyone know if this is a major problem for reading and manipulating
>>image files using RDAL? And if so are there windows binaries which have
>>patched it up?
>>
>>Thanks in advance
>>
>>Tony
>>
>>******************************************
>>Tony Gill - PhD Candidate
>>Centre for Remote Sensing & Spatial Information Science
>>School of Geography, Planning & Architecture
>>University of Queensland
>>Brisbane, Queensland, AUSTRALIA, 4072
>>Ph: 61-7-3365-7027
>>email: t.gill1 at uq.edu.au
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
>



From renukas at gmail.com  Tue Aug  2 14:50:44 2005
From: renukas at gmail.com (Renuka Sane)
Date: Tue, 2 Aug 2005 18:20:44 +0530
Subject: [R] question on graphs and finding area under a curve
Message-ID: <f7dc8e94050802055030cb409@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050802/1bb5fc9a/attachment.pl

From poohdov at yahoo.com  Tue Aug  2 15:09:37 2005
From: poohdov at yahoo.com (Arie)
Date: Tue, 2 Aug 2005 06:09:37 -0700 (PDT)
Subject: [R] Conditional piece-wise dependent regression
Message-ID: <20050802130937.32515.qmail@web40607.mail.yahoo.com>

Thank you Dimitris & Reid, you were very helpful.

Best wishes,
Arie.



From JAROSLAW.W.TUSZYNSKI at saic.com  Tue Aug  2 15:16:14 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Tue, 2 Aug 2005 09:16:14 -0400 
Subject: [R] can we manage memory usage to increase speed?
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD57F410B@us-arlington-0668.mail.saic.com>

 
If you have a code that takes 2 weeks to run, than it might be a case of
inefficient algorithm design. I was able to go from overnight runs (SELDI
data analysis) to 20 minute runs by identifying single inefficient function
that took most of the time, and writing it in C.

Jarek
====================================================\=======

 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">   \
 Jaroslaw.W.Tuszynski at saic.com                     `    \


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Zhilin Liu
Sent: Monday, August 01, 2005 8:28 PM
To: r-help at stat.math.ethz.ch
Subject: [R] can we manage memory usage to increase speed?

Hi,
 
Thanks for reading.
 
I am running  a process in R for microarray data analysis. RedHat Enterprise
Linux 4, dual AMD CPU, 6G memory. However, the R process use only a total of
<200M memory. And the CPU usage is total to ~110% for two. The program takes
at least 2 weeks to run at the current speed. Is there some way we can
increase the usage of CPUs and memories and speed up? Any suggestion is
appreciated.
 
Thanks again.
 
Zhilin 

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From MSchwartz at mn.rr.com  Tue Aug  2 15:18:52 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Tue, 02 Aug 2005 08:18:52 -0500
Subject: [R] question on graphs and finding area under a curve
In-Reply-To: <f7dc8e94050802055030cb409@mail.gmail.com>
References: <f7dc8e94050802055030cb409@mail.gmail.com>
Message-ID: <1122988732.4074.15.camel@localhost.localdomain>

On Tue, 2005-08-02 at 18:20 +0530, Renuka Sane wrote:
> Question on graphs:
> 
> The default case for drawing a graph in R, is where a little space is left 
> on the x and y axis before the first tick i.e. even if I say xlim=c(0,1) -- 
> there will be some space between the edge of the x-axis and where 0 is 
> placed. If I want 0 on the edge, how do I do it in R?

See ?par and take note of the 'xaxs' and 'yaxs' parameters. By default,
these are set to 'r', where the axes are extended by 4% in each
direction. Thus, set one or both parameters to 'i' to set the axes to
exactly the ranges of xlim and/or ylim as you require.

> Area under the curve:
> 
> I have a 45 degree line and a curve above or below it. Is there a way in R 
> to find the area between the two?

See Frank Harrell's somers2() function in the Hmisc package on CRAN.
Among other things, it outputs a value "C", which is the AUC.

HTH,

Marc Schwartz



From francoisromain at free.fr  Tue Aug  2 15:22:11 2005
From: francoisromain at free.fr (Romain Francois)
Date: Tue, 02 Aug 2005 15:22:11 +0200
Subject: [R] question on graphs and finding area under a curve
In-Reply-To: <f7dc8e94050802055030cb409@mail.gmail.com>
References: <f7dc8e94050802055030cb409@mail.gmail.com>
Message-ID: <42EF7383.2090109@free.fr>

Le 02.08.2005 14:50, Renuka Sane a ??crit :

>Question on graphs:
>
>The default case for drawing a graph in R, is where a little space is left 
>on the x and y axis before the first tick i.e. even if I say xlim=c(0,1) -- 
>there will be some space between the edge of the x-axis and where 0 is 
>placed. If I want 0 on the edge, how do I do it in R?
>
>Area under the curve:
>
>I have a 45 degree line and a curve above or below it. Is there a way in R 
>to find the area between the two?
>
>  
>
Hi,

integrate.xy in sfsmisc package might help you.

Romain

>Thanks,
>Renuka
>
- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From JAROSLAW.W.TUSZYNSKI at saic.com  Tue Aug  2 15:22:57 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Tue, 2 Aug 2005 09:22:57 -0400 
Subject: [R] question on graphs and finding area under a curve
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD57F410C@us-arlington-0668.mail.saic.com>

How about:

trapz = function(x, y) 
{ # computes the integral of y with respect to x using trapezoidal
integration. 
  idx = 2:length(x)
  return (as.double( (x[idx] - x[idx-1]) %*% (y[idx] + y[idx-1])) / 2)
} 

Jarek
====================================================\=======

 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">   \
 Jaroslaw.W.Tuszynski at saic.com                     `    \


-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Renuka Sane
Sent: Tuesday, August 02, 2005 8:51 AM
To: r-help at stat.math.ethz.ch
Subject: [R] question on graphs and finding area under a curve

Question on graphs:

The default case for drawing a graph in R, is where a little space is left
on the x and y axis before the first tick i.e. even if I say xlim=c(0,1) --
there will be some space between the edge of the x-axis and where 0 is
placed. If I want 0 on the edge, how do I do it in R?

Area under the curve:

I have a 45 degree line and a curve above or below it. Is there a way in R
to find the area between the two?

Thanks,
Renuka

--
Renuka Sane
http://www.nyx.net/~rsane

	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From rvaradha at jhsph.edu  Tue Aug  2 15:24:05 2005
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Tue, 2 Aug 2005 09:24:05 -0400
Subject: [R] question on graphs and finding area under a curve
In-Reply-To: <f7dc8e94050802055030cb409@mail.gmail.com>
Message-ID: <OWA-1pA0hZaPHrKwT7N0002bcc2@owa-1.sph.ad.jhsph.edu>

Hi,

To find the area lying between the curve y = y(x) and 45 degree line (which,
assuming it goes through the origin, is y = x), you can use the following
function based on trapezoidal rule:

trap.rule <- function(x,f) {sum(diff(x)*(f[-1]+f[-length(f)]))/2}

trap.rule(x,f=y-x)

This area will be negative if y(x) is below the 45 degree line.

However, your question is not complete, I think.  You need to specify the
interval of integration. For this you may need to determine the points of
intersection of the two curves, which involves the solution of a fixed point
problem.

Hope this helps,
Ravi.

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-
> bounces at stat.math.ethz.ch] On Behalf Of Renuka Sane
> Sent: Tuesday, August 02, 2005 8:51 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] question on graphs and finding area under a curve
> 
> Question on graphs:
> 
> The default case for drawing a graph in R, is where a little space is left
> on the x and y axis before the first tick i.e. even if I say xlim=c(0,1) -
> -
> there will be some space between the edge of the x-axis and where 0 is
> placed. If I want 0 on the edge, how do I do it in R?
> 
> Area under the curve:
> 
> I have a 45 degree line and a curve above or below it. Is there a way in R
> to find the area between the two?
> 
> Thanks,
> Renuka
> 
> --
> Renuka Sane
> http://www.nyx.net/~rsane
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From kubovy at virginia.edu  Tue Aug  2 15:33:52 2005
From: kubovy at virginia.edu (Michael Kubovy)
Date: Tue, 2 Aug 2005 09:33:52 -0400
Subject: [R] Contour plot crest line
Message-ID: <5402C8EC-C5EE-4FA9-BFDC-6BD66A775605@virginia.edu>

Any suggestions about drawing the ridge line on a response surface  
represented as a contour plot?

_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From tuechler at gmx.at  Tue Aug  2 15:45:14 2005
From: tuechler at gmx.at (Heinz Tuechler)
Date: Tue, 02 Aug 2005 15:45:14 +0200
Subject: [R] how to print a data.frame without row.names
Message-ID: <3.0.6.32.20050802154514.007b39c0@pop.gmx.net>

Dear All,
is there a simple way to print a data.frame without its row.names?

example:
datum <- as.Date(c("2004-01-01", "2004-01-06", "2004-04-12"))
content <- c('Neujahr', 'Hl 3 K.', 'Ostern')
df1 <- data.frame(datum, content)
print(df1)

       datum content
1 2004-01-01 Neujahr
2 2004-01-06 Hl 3 K.
3 2004-04-12  Ostern

Can I get this "table" without 1, 2, 3 ?

Thanks in advance

Heinz Tuechler



From herodote at oreka.com  Tue Aug  2 15:56:32 2005
From: herodote at oreka.com (=?iso-8859-1?Q?herodote@oreka.com?=)
Date: Tue,  2 Aug 2005 14:56:32 +0100
Subject: [R] (no subject)
Message-ID: <IKLLE8$41AAC3803431D01EC771CD67227D50A1@oreka.com>

hi all,

I wish to draw on the same graphic device 3 functions.

But i don't want them to be on different graph, i want to compare them on the same

I don't need mfrow or mfcol, I need something else... 

1 graph on 1 device inside this graph 3 ploted function.

I saw something unsing data.frame, but i think it's overkill, and something less complicated must exist, if not why?

why not plot(func1,func2,func3) ??

thks.

////////////////////////////////////////////////////////////
// Webmail Oreka : http://www.oreka.com
////////////////////////////////////////////////////////////



From herodote at oreka.com  Tue Aug  2 15:57:34 2005
From: herodote at oreka.com (=?iso-8859-1?Q?herodote@oreka.com?=)
Date: Tue,  2 Aug 2005 14:57:34 +0100
Subject: [R] =?iso-8859-1?q?plotting_3_functions_on_same_graph?=
Message-ID: <IKLLFY$5CCF65F0F9543A42D7E8C97B1656BC43@oreka.com>

hi all,

I wish to draw on the same graphic device 3 functions.

But i don't want them to be on different graph, i want to compare them on the same

I don't need mfrow or mfcol, I need something else... 

1 graph on 1 device inside this graph 3 ploted function.

I saw something unsing data.frame, but i think it's overkill, and something less complicated must exist, if not why?

why not plot(func1,func2,func3) ??

thks.


////////////////////////////////////////////////////////////
// Webmail Oreka : http://www.oreka.com
////////////////////////////////////////////////////////////



From francoisromain at free.fr  Tue Aug  2 16:05:19 2005
From: francoisromain at free.fr (Romain Francois)
Date: Tue, 02 Aug 2005 16:05:19 +0200
Subject: [R] how to print a data.frame without row.names
In-Reply-To: <3.0.6.32.20050802154514.007b39c0@pop.gmx.net>
References: <3.0.6.32.20050802154514.007b39c0@pop.gmx.net>
Message-ID: <42EF7D9F.9050705@free.fr>

Le 02.08.2005 15:45, Heinz Tuechler a ??crit :

>Dear All,
>is there a simple way to print a data.frame without its row.names?
>
>example:
>datum <- as.Date(c("2004-01-01", "2004-01-06", "2004-04-12"))
>content <- c('Neujahr', 'Hl 3 K.', 'Ostern')
>df1 <- data.frame(datum, content)
>print(df1)
>
>       datum content
>1 2004-01-01 Neujahr
>2 2004-01-06 Hl 3 K.
>3 2004-04-12  Ostern
>
>Can I get this "table" without 1, 2, 3 ?
>  
>
See write.table and its row.names argument

R> write.table(df1, row.names=FALSE)

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From buser at stat.math.ethz.ch  Tue Aug  2 16:04:36 2005
From: buser at stat.math.ethz.ch (Christoph Buser)
Date: Tue, 2 Aug 2005 16:04:36 +0200
Subject: [R] =?iso-8859-1?q?plotting_3_functions_on_same_graph?=
In-Reply-To: <IKLLFY$5CCF65F0F9543A42D7E8C97B1656BC43@oreka.com>
References: <IKLLFY$5CCF65F0F9543A42D7E8C97B1656BC43@oreka.com>
Message-ID: <17135.32116.294308.107065@stat.math.ethz.ch>

Hi 

Maybe matplot (see ?matplot) can help you.

Regards,

Christoph Buser

--------------------------------------------------------------
Christoph Buser <buser at stat.math.ethz.ch>
Seminar fuer Statistik, LEO C13
ETH (Federal Inst. Technology)	8092 Zurich	 SWITZERLAND
phone: x-41-44-632-4673		fax: 632-1228
http://stat.ethz.ch/~buser/
--------------------------------------------------------------


herodote at oreka.com writes:
 > hi all,
 > 
 > I wish to draw on the same graphic device 3 functions.
 > 
 > But i don't want them to be on different graph, i want to compare them on the same
 > 
 > I don't need mfrow or mfcol, I need something else... 
 > 
 > 1 graph on 1 device inside this graph 3 ploted function.
 > 
 > I saw something unsing data.frame, but i think it's overkill, and something less complicated must exist, if not why?
 > 
 > why not plot(func1,func2,func3) ??
 > 
 > thks.
 > 
 > 
 > ////////////////////////////////////////////////////////////
 > // Webmail Oreka : http://www.oreka.com
 > ////////////////////////////////////////////////////////////
 > 
 > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jeff.horner at vanderbilt.edu  Tue Aug  2 09:54:21 2005
From: jeff.horner at vanderbilt.edu (Jeffrey Horner)
Date: Tue, 02 Aug 2005 02:54:21 -0500
Subject: [R] [R-pkgs] [ANNOUNCE] mod_R: The R/Apache Integration Project
Message-ID: <42EF26AD.2050208@vanderbilt.edu>


   What is it?
   -----------
   mod_R is a project dedicated to embedding the R interpreter inside
   the Apache 2.0 (and beyond) web server for the purpose of writing web
   applications in R. It's composed of three parts:

   mod_R: the Apache 2.0 module that implements the glue to load the
   R interpreter.

   RApache: the R package that provides the API for programming web
   applications in R.

   libapreq 2.0.4: an Apache sponsored project for parsing request input.
   If you don't want to compile and install this version, then you can
   specify which libapreq2 library to use during configuration.

   The Latest Version
   ------------------

   Details of the latest version can be found at the mod_R
   project page:

http://biostat.mc.vanderbilt.edu/twiki/bin/view/Main/ApacheRproject

   (mind the wrap)


   Prerequisites
   -------------
   This release has been tested under Debian Linux with Apache 2.0.54,
   R 2.1.1, and libapreq 2.0.4.  Apache2 _MUST_ be compiled with the
   prefork MPM to compile mod_R. Also, R must have been compiled with
   the --enable-R-shlib configure flag.

   Installation
   ------------
   The following is the preferred way to compile and install mod_R:

     $ ./configure --with-apache2-apxs=/path/to/apxs --with-R=/path/to/R
     $ make
     $ make install

   Both --with-apache2-apxs and --with-R _MUST_ be specified.  Otherwise,
   trying to figure out the dependencies between the sources and headers
   and library paths becomes quite complex.

   If you don't want to compile and install the bundled libapreq2 version,
   then add --with-apreq2-config=/path/to/apreq2-config. The version _MUST_
   be equal to or greater than 2.0.4.

   Configuration
   -------------
   In order to use mod_R and RApache, you must configure apache to find
   it. Type help("directives",package="RApache") once mod_R is installed
   for a little more detail. Add something similar to this to the apache
   config file:

     LoadModule R_Module /path/to/mod_R.so

     <Location /URL>
        SetHandler r-handler
        Rsource /path/to/R/code.R
        RreqHandler function-name
        Rlibrary library-name
     </Location>

   Also, libR.so _MUST_ be found in the shared library path as it is
   linked to by mod_R, RApache and the rest of the packages containing
   shared libraries. You can either set LD_LIBRARY_PATH like this:

      $ export LD_LIBRARY_PATH=`/path/to/R RHOME`/lib

   or add that path to /etc/ld.so.conf and then run ldconfig.

   NOTE: the latest apache2 debian packages cause the web server to run
   in a very reduced environment, thus one is unable to set LD_LIBRARY_PATH
   before calling /etc/init.d/apache2. One option is to actually edit that
   file and add the LD_LIBRARY_PATH explicitly. Another is to use the 
apache2ctl
   scripts which are also bundled with the debian packages. Or you can 
add it
   to /etc/ld.so.conf.

   Documentation
   -------------
   All of the documentation is currently in the RApache package. Once
   you install mod_R, start R and load the RApache package. You'll get
   a warning that you're currently not running the R interpreter within
   Apache; just don't try to run any of the code. Sample session:
    > library(RApache)
    Warning message:

    RApache is only useful within the Apache web server.
    It is loaded now for informational purposes only

     in: firstlib(which.lib.loc, package)
    > help(package="RApache")

                    Information on package 'RApache'

    Description:

    Package:       RApache
    Version:       0.1-0
    Date:          2005-08-02
    Title:         An R interface to the Apache 2.0 web server
    Author:        Jeffrey Horner
    Maintainer:    Jeffrey Horner <jeff.horner at vanderbilt.edu>
    License:       Apache License, Version 2.0
    Description:   RApache allows web applications to be written in R and
    executed within the Apache 2.0 web server.
    Built:         R 2.1.0; i386-pc-linux-gnu; 2005-08-02 01:06:26; unix

    Index:

    IO                      IO in RApache
    apache.add_cookie       Adding Cookies to Outgoing Headers
    apache.add_header       Adding HTTP headers
    apache.allow_methods    RApache Methods
    apache.log_error        Logging Errors to the Apache error log
    apache.set_content_type
    Setting the Content Type header
    apr_table               Structure of the apr_table type in RApache
    as.html                 Converting RApache objects to HTML
    directives              RApache directives used in Apace config file
    intro                   Introduction to RApache
    request_rec             Structure of the RApache request record
    return_codes            RApache handler return codes


   Licensing
   ---------

   Please see the file called LICENSE.

-- 
Jeffrey Horner       Computer Systems Analyst         School of Medicine
615-322-8606         Department of Biostatistics   Vanderbilt University

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From francoisromain at free.fr  Tue Aug  2 16:12:12 2005
From: francoisromain at free.fr (Romain Francois)
Date: Tue, 02 Aug 2005 16:12:12 +0200
Subject: [R] plotting 3 functions on same graph
In-Reply-To: <IKLLE8$41AAC3803431D01EC771CD67227D50A1@oreka.com>
References: <IKLLE8$41AAC3803431D01EC771CD67227D50A1@oreka.com>
Message-ID: <42EF7F3C.609@free.fr>

Le 02.08.2005 15:56, herodote at oreka.com a ??crit :

>hi all,
>
>I wish to draw on the same graphic device 3 functions.
>
>But i don't want them to be on different graph, i want to compare them on the same
>
>I don't need mfrow or mfcol, I need something else... 
>
>1 graph on 1 device inside this graph 3 ploted function.
>
>I saw something unsing data.frame, but i think it's overkill, and something less complicated must exist, if not why?
>
>why not plot(func1,func2,func3) ??
>
>thks.
>  
>
Take a look at :
?points
?lines
?curve
par(new=TRUE)

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From p.dalgaard at biostat.ku.dk  Tue Aug  2 16:32:47 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Aug 2005 16:32:47 +0200
Subject: [R] plotting 3 functions on same graph
In-Reply-To: <42EF7F3C.609@free.fr>
References: <IKLLE8$41AAC3803431D01EC771CD67227D50A1@oreka.com>
	<42EF7F3C.609@free.fr>
Message-ID: <x24qa81ka8.fsf@turmalin.kubism.ku.dk>

Romain Francois <francoisromain at free.fr> writes:

> Le 02.08.2005 15:56, herodote at oreka.com a ??crit :
> 
> >hi all,
> >
> >I wish to draw on the same graphic device 3 functions.
> >
> >But i don't want them to be on different graph, i want to compare them on the same
> >
> >I don't need mfrow or mfcol, I need something else... 
> >
> >1 graph on 1 device inside this graph 3 ploted function.
> >
> >I saw something unsing data.frame, but i think it's overkill, and something less complicated must exist, if not why?
> >
> >why not plot(func1,func2,func3) ??
> >
> >thks.
> >  
> >
> Take a look at :
> ?points
> ?lines
> ?curve
> par(new=TRUE)

...and curve(...., add=TRUE). The minor gotcha is that you need to
adjust the ylim setting to make sure that all curves fit.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From shellyzhang77 at gmail.com  Tue Aug  2 17:01:45 2005
From: shellyzhang77 at gmail.com (qi zhang)
Date: Tue, 2 Aug 2005 11:01:45 -0400
Subject: [R] a question about data manipulation
Message-ID: <d9f121940508020801457d4c1b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050802/508de53d/attachment.pl

From tuechler at gmx.at  Tue Aug  2 17:46:07 2005
From: tuechler at gmx.at (Heinz Tuechler)
Date: Tue, 02 Aug 2005 17:46:07 +0200
Subject: [R] how to print a data.frame without row.names
In-Reply-To: <42EF7D9F.9050705@free.fr>
References: <3.0.6.32.20050802154514.007b39c0@pop.gmx.net>
	<3.0.6.32.20050802154514.007b39c0@pop.gmx.net>
Message-ID: <3.0.6.32.20050802174607.007ae100@pop.gmx.net>

At 16:05 02.08.2005 +0200, Romain Francois wrote:
>Le 02.08.2005 15:45, Heinz Tuechler a ??crit :
>
>>Dear All,
>>is there a simple way to print a data.frame without its row.names?
>>
>>example:
>>datum <- as.Date(c("2004-01-01", "2004-01-06", "2004-04-12"))
>>content <- c('Neujahr', 'Hl 3 K.', 'Ostern')
>>df1 <- data.frame(datum, content)
>>print(df1)
>>
>>       datum content
>>1 2004-01-01 Neujahr
>>2 2004-01-06 Hl 3 K.
>>3 2004-04-12  Ostern
>>
>>Can I get this "table" without 1, 2, 3 ?
>>  
>>
>See write.table and its row.names argument
>
>R> write.table(df1, row.names=FALSE)
>
>Romain
>

write.table(df1, row.names=FALSE, quote=FALSE)
datum content
2004-01-01 Neujahr
2004-01-06 Hl 3 K.
2004-04-12 Ostern

I tried this, but then the column headers and column contents are not aligned.

If you expand the example, you see clearly the difference.

datum <- as.Date(c("2004-01-01", "2004-01-06", "2004-04-12"))
content <- c('Neujahr', 'Hl 3 K.', 'Ostern')
number <- c(1, 6, 110)
string <- c('a', 'bbbb', 'c')
df1 <- data.frame(datum, content, number, string)
print(df1)
       datum content number string
1 2004-01-01 Neujahr      1      a
2 2004-01-06 Hl 3 K.      6   bbbb
3 2004-04-12  Ostern    110      c

write.table(df1, row.names=FALSE, quote=FALSE)
datum content number string
2004-01-01 Neujahr 1 a
2004-01-06 Hl 3 K. 6 bbbb
2004-04-12 Ostern 110 c

Maybe I missed a function like print.xtable with type="ascii". It seems
that it has to be done with cat.

Thank you

Heinz

>-- 
>visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
>~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
>~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
>~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
>~~                http://www.isup.cicrp.jussieu.fr/                  ~~
>~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
>~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
>~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
>
>



From spencer.graves at pdf.com  Tue Aug  2 17:51:39 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 02 Aug 2005 08:51:39 -0700
Subject: [R] can we manage memory usage to increase speed?
In-Reply-To: <CA0BCF3BED56294AB91E3AD74B849FD57F410B@us-arlington-0668.mail.saic.com>
References: <CA0BCF3BED56294AB91E3AD74B849FD57F410B@us-arlington-0668.mail.saic.com>
Message-ID: <42EF968B.7080009@pdf.com>

	  And you can identify inefficient code fairly easily taking snapshots 
from "proc.time" and computing elapsed time for sections of your code.

	  spencer graves

Tuszynski, Jaroslaw W. wrote:

>  
> If you have a code that takes 2 weeks to run, than it might be a case of
> inefficient algorithm design. I was able to go from overnight runs (SELDI
> data analysis) to 20 minute runs by identifying single inefficient function
> that took most of the time, and writing it in C.
> 
> Jarek
> ====================================================\=======
> 
>  Jarek Tuszynski, PhD.                           o / \ 
>  Science Applications International Corporation  <\__,|  
>  (703) 676-4192                                   ">   \
>  Jaroslaw.W.Tuszynski at saic.com                     `    \
> 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Zhilin Liu
> Sent: Monday, August 01, 2005 8:28 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] can we manage memory usage to increase speed?
> 
> Hi,
>  
> Thanks for reading.
>  
> I am running  a process in R for microarray data analysis. RedHat Enterprise
> Linux 4, dual AMD CPU, 6G memory. However, the R process use only a total of
> <200M memory. And the CPU usage is total to ~110% for two. The program takes
> at least 2 weeks to run at the current speed. Is there some way we can
> increase the usage of CPUs and memories and speed up? Any suggestion is
> appreciated.
>  
> Thanks again.
>  
> Zhilin 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From jholtman at gmail.com  Tue Aug  2 17:56:18 2005
From: jholtman at gmail.com (jim holtman)
Date: Tue, 2 Aug 2005 11:56:18 -0400
Subject: [R] a question about data manipulation
In-Reply-To: <d9f121940508020801457d4c1b@mail.gmail.com>
References: <d9f121940508020801457d4c1b@mail.gmail.com>
Message-ID: <644e1f3205080208561233d9aa@mail.gmail.com>

use 'split'

> x.1 <- data.frame(COL1=1:50, COL2=50:1, id=sample(1:4,50,T))
> x.2 <- split(x.1, x.1$id)
> str(x.2)
List of 4
 $ 1:`data.frame':      10 obs. of  3 variables:
  ..$ COL1: int [1:10] 5 10 11 12 22 24 27 34 38 47
  ..$ COL2: int [1:10] 46 41 40 39 29 27 24 17 13 4
  ..$ id  : int [1:10] 1 1 1 1 1 1 1 1 1 1
 $ 2:`data.frame':      13 obs. of  3 variables:
  ..$ COL1: int [1:13] 1 2 14 16 19 25 26 28 30 31 ...
  ..$ COL2: int [1:13] 50 49 37 35 32 26 25 23 21 20 ...
  ..$ id  : int [1:13] 2 2 2 2 2 2 2 2 2 2 ...
 $ 3:`data.frame':      14 obs. of  3 variables:
  ..$ COL1: int [1:14] 3 8 9 13 17 23 32 36 39 42 ...
  ..$ COL2: int [1:14] 48 43 42 38 34 28 19 15 12 9 ...
  ..$ id  : int [1:14] 3 3 3 3 3 3 3 3 3 3 ...
 $ 4:`data.frame':      13 obs. of  3 variables:
  ..$ COL1: int [1:13] 4 6 7 15 18 20 21 29 35 37 ...
  ..$ COL2: int [1:13] 47 45 44 36 33 31 30 22 16 14 ...
  ..$ id  : int [1:13] 4 4 4 4 4 4 4 4 4 4 ...
> names(x.2)
[1] "1" "2" "3" "4"
> x.2[['1']]
   COL1 COL2 id
5     5   46  1
10   10   41  1
11   11   40  1
12   12   39  1
22   22   29  1
24   24   27  1
27   27   24  1
34   34   17  1
38   38   13  1
47   47    4  1
> x.2[['3']]
   COL1 COL2 id
3     3   48  3
8     8   43  3
9     9   42  3
13   13   38  3
17   17   34  3
23   23   28  3
32   32   19  3
36   36   15  3
39   39   12  3
42   42    9  3
44   44    7  3
45   45    6  3
49   49    2  3
50   50    1  3
> 


On 8/2/05, qi zhang <shellyzhang77 at gmail.com> wrote:
> Dear R-user,
>  I have a simple question, I just can't figure out a easy way to handle it.
>  My importing data x is like this:
>  COL1 COL2 id
> 1 12 49 1
> 2 70 120 1
> 3 58 124 1
> 51 14 13 2
> 52 88 100 2
> 53 90 134 2
>  I want to change the format of the data, i want to group data into
> differenct part according id,so that when i use x[1], which will refer me to
> the information about first id.I use the command:
> 
> list(list(N=2,n=c(100,150),matrix(c(x[x$id==1,][,1],x[x$id==1,][,2]),nr=2,nc=3)),list(N=2,n=c(100,150),matrix(c(x[x$id==2,][,1],x[x$id==2,][,2]),nr=2,nc=3)))
> 
> so the data becomes :
> 
> [[1]]
> [[1]]$N
> [1] 2
> 
> [[1]]$n
> [1] 100 150
> 
> [[1]][[3]]
> [,1] [,2] [,3]
> [1,] 12 58 120
> [2,] 70 49 124
> 
> 
> [[2]]
> [[2]]$N
> [1] 2
> 
> [[2]]$n
> [1] 100 150
> 
> [[2]][[3]]
> [,1] [,2] [,3]
> [1,] 14 90 100
> [2,] 88 13 134
> 
> This is the format I want, but problem is that for my data, id is not only 1
> to 2,but 1 to 100, so my code is not efficient. Could you help me find a
> efficient way? Thanks.
> 
>  Qi Zhang
> 
> PhD student,
> 
> University of Cincinnati
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Jim Holtman
Convergys
+1 513 723 2929

What the problem you are trying to solve?



From spencer.graves at pdf.com  Tue Aug  2 17:59:24 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 02 Aug 2005 08:59:24 -0700
Subject: [R] How to hiding code for a package
In-Reply-To: <8d5a3635050801085546c8b5ad@mail.gmail.com>
References: <8d5a3635050801085546c8b5ad@mail.gmail.com>
Message-ID: <42EF985C.6090800@pdf.com>

	  The problem with this is that if someone thinks it's useful, they 
will likely slog through the obfuscation, then offer something much 
simpler to do the same thing -- and then be shocked and confused if the 
originator doesn't thank them for their efort!  I've heard that S-Plus 
allows you to encrypt your code.  Talk with Insightful if you want to 
protect your intellectual property.

	  spencer graves

bogdan romocea wrote:

> There's something else you could try - since you can't hide the code,
> obfuscate it. Hide the real thing in a large pile of useless,
> complicated, awfully formatted code that would stop anyone except the
> most desperate (including yourself, after a couple of weeks/months)
> from trying to understand it. The best solution would be to compile
> the code, but R is not there yet.
> 
> 
> 
>>-----Original Message-----
>>From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
>>Sent: Saturday, July 30, 2005 5:35 AM
>>To: Gary Wong
>>Cc: r-help at stat.math.ethz.ch
>>Subject: Re: [R] How to hiding code for a package
>>
>>
>>What you ask is impossible.  For a function to be callable it 
>>has to be 
>>locatable and hence can be printed.
>>
>>One possibility is to have a namespace, and something like
>>
>>foo <- function(...) foo_internal(...)
>>
>>where foo is exported but foo_internal is not.  Then foo_internal is 
>>hidden from casual inspection, but it can be listed by cognescenti.
>>
>>Why do you want to do this?  Anyhone can read the source code of your 
>>package, and any function which can be called can be 
>>deparsed, possibly 
>>after jumping through a few hoops.
>>
>>On Sat, 30 Jul 2005, Gary Wong wrote:
>>
>>
>>>Hey everyone,
>>>
>>>I have made a package and wish to release it but
>>>before then I have a problem. I have a few functions
>>>in this package written in R that I wish to hide such
>>>that after installation, someone can use say the
>>>function >foo(parameters = "") but cannot do >foo.
>>>Typing foo should not show the source code or at least
>>>not all of it. Is there a way to do this ? I have
>>>searched the mailing list and used google, and have
>>>found something like "[R] Hiding internal package
>>>functions for the doc. pkg-internal.Rd" but this seems
>>>different since it seems that the keyword internal
>>>just hides the function from showing in the index and
>>>hides documentation, not the function itself. Can
>>>someone help? Thanks
>>
>>-- 
>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>University of Oxford,             Tel:  +44 1865 272861 (self)
>>1 South Parks Road,                     +44 1865 272866 (PA)
>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From herodote at oreka.com  Tue Aug  2 18:18:15 2005
From: herodote at oreka.com (=?iso-8859-1?Q?herodote@oreka.com?=)
Date: Tue,  2 Aug 2005 17:18:15 +0100
Subject: [R] =?iso-8859-1?q?multiple_scale?=
Message-ID: <IKLRYF$AE909B3EF9675DAB592A01412777EB5F@oreka.com>

Hi all

i need to put on one graph 2 functions who's x axis is the same and y not.

I mean on horizontal the time, and on vertical left: pressure, on vertical right: rpm of a motor, is R able to do that?

i've found this that i could adapt maybe (i don't need time series really?) :/ :

(http://tolstoy.newcastle.edu.au/R/help/04/03/1456.html)
## 
## Description: A simple function which plots two time series on one plot where 
## the series can have different value intervals over the same time interval. 
## Usage: ts.plot.2Axis(xleft, xright) 
## Arguments: xleft is the time series for the left vertical axis and xright 
## is for the right axis. xleft and xright are defined as time series with 
## the 'ts' function in package ts. 
## ts.plot function must be available, do library(ts) to ensure this if 
## necessary. 
## In addition the usual 'ts.plot' and 'plot' parameters can be set 
## directly (mar, main, xlab, ylab, lwd) or through gpars as in ts.plot. 
## Also parameter digits is the preferred number of decimal digits on right 
## axis and ticks is the preferred number of tick marks on right axis. 
## Details: The time series for the right vertical axis is scaled with a simple 
## rule of thumb scaling. 
## The ts.plot function is used to plot the series. 
## Value: None. 
## Note: When scaling is not acceptable try switching the series parameters. 
## If a ylabel is to be set it is here only possible for the left axis. 
## See also: 'ts.plot', 'ts', 'legend'. 
## Author and date: Hauksson, Bjorn Arnar. March 2004. 
## Example: 
## First paste this function into the R console or use 'source'. 
#library(ts) 
#data(UKLungDeaths) 
#x <- ldeaths 
#y <- fdeaths/mdeaths 
#ts.plot.2Axis(x, y) 
#legTxt <- c("UK lung deaths", "UK female/male deaths (rhs)") 
#legend(1976.5, 3950, legTxt, lty=c(1:2), col=c(1:2), lwd=2, bty="n") 
## 


ts.plot.2Axis <- function(xleft, xright, digits=1, ticks=5, 
                          mar=(c(4,4,4,4)+0.1), main="", 
                          xlab="", ylab="", lwd=2, gpars=list()) { 
        # Settings for other parameters than those in the function parameter list 
        par(mar=mar) # Margins 
      k <- ncol(as.matrix(xleft)) # Number of time series on left vertical scale 
        lty <- c(1:(k+1)) # Line types 
        col <- c(1:(k+1)) # Line colors 


        # Scale time series on right vertical axis 
        scale <- (max(xleft)-min(xleft))/(max(xright)-min(xright)) 
      xright2 <- xright*scale 
      meanScale <- mean(xleft) - mean(xright2) 
        xright2 <- xright2 + meanScale 


        # Plot the series 
        ts.plot(xleft, xright2, lty=lty, col=col, main=main, ylab=ylab, xlab=xlab, 
        lwd=lwd, gpars=gpars) 


        # Add the right vertical axis labels 
        lab <- seq(round(min(xright), digits), round(max(xright), digits), 
        length=ticks) 
        labAt <- seq(min(xright2), max(xright2), length=ticks) 
        axis(side=4, labels=lab, at=labAt) 
} 

are there a better way to plot what i want?

thks.
guillaume.

////////////////////////////////////////////////////////////
// Webmail Oreka : http://www.oreka.com
////////////////////////////////////////////////////////////



From maechler at stat.math.ethz.ch  Tue Aug  2 18:40:47 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 2 Aug 2005 18:40:47 +0200
Subject: [R] how to print a data.frame without row.names
In-Reply-To: <3.0.6.32.20050802174607.007ae100@pop.gmx.net>
References: <3.0.6.32.20050802154514.007b39c0@pop.gmx.net>
	<3.0.6.32.20050802174607.007ae100@pop.gmx.net>
Message-ID: <17135.41487.149836.798318@stat.math.ethz.ch>


>>>>> "Heinz" == Heinz Tuechler <tuechler at gmx.at>
>>>>>     on Tue, 02 Aug 2005 17:46:07 +0200 writes:

  .......................

    Heinz> I tried this, but then the column headers and column
    Heinz> contents are not aligned.

  ........................

Use the tabulator if you need them aligned :

write.table(USArrests, row.names = FALSE, sep = "\t")



From dmbates at gmail.com  Tue Aug  2 18:57:59 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Tue, 2 Aug 2005 11:57:59 -0500
Subject: [R] can we manage memory usage to increase speed?
In-Reply-To: <42EF968B.7080009@pdf.com>
References: <CA0BCF3BED56294AB91E3AD74B849FD57F410B@us-arlington-0668.mail.saic.com>
	<42EF968B.7080009@pdf.com>
Message-ID: <40e66e0b0508020957ea37522@mail.gmail.com>

On 8/2/05, Spencer Graves <spencer.graves at pdf.com> wrote:
>           And you can identify inefficient code fairly easily taking snapshots
> from "proc.time" and computing elapsed time for sections of your code.
> 
>           spencer graves

Using Rprof may be a better choice.  See

?Rprof

> 
> Tuszynski, Jaroslaw W. wrote:
> 
> >
> > If you have a code that takes 2 weeks to run, than it might be a case of
> > inefficient algorithm design. I was able to go from overnight runs (SELDI
> > data analysis) to 20 minute runs by identifying single inefficient function
> > that took most of the time, and writing it in C.
> >
> > Jarek
> > ====================================================\=======
> >
> >  Jarek Tuszynski, PhD.                           o / \
> >  Science Applications International Corporation  <\__,|
> >  (703) 676-4192                                   ">   \
> >  Jaroslaw.W.Tuszynski at saic.com                     `    \
> >
> >
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Zhilin Liu
> > Sent: Monday, August 01, 2005 8:28 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] can we manage memory usage to increase speed?
> >
> > Hi,
> >
> > Thanks for reading.
> >
> > I am running  a process in R for microarray data analysis. RedHat Enterprise
> > Linux 4, dual AMD CPU, 6G memory. However, the R process use only a total of
> > <200M memory. And the CPU usage is total to ~110% for two. The program takes
> > at least 2 weeks to run at the current speed. Is there some way we can
> > increase the usage of CPUs and memories and speed up? Any suggestion is
> > appreciated.
> >
> > Thanks again.
> >
> > Zhilin
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> --
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
> 
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From naj at ccf.org  Tue Aug  2 19:10:04 2005
From: naj at ccf.org (Jeanie (Jie) Na)
Date: Tue, 02 Aug 2005 13:10:04 -0400
Subject: [R] multiple scale
In-Reply-To: <IKLRYF$AE909B3EF9675DAB592A01412777EB5F@oreka.com>
References: <IKLRYF$AE909B3EF9675DAB592A01412777EB5F@oreka.com>
Message-ID: <1123002604.29051.1.camel@wb4-c29-lin>

Hi, 
Search the list, you might be able to find the message but here it is.

Copied From Dr. Brian Ripley's post
> x <- 1:10
> y <- rnorm(10)
> z <- runif(10, 1000, 10000)
> par(mar=c(5,4,4,4) + 0.1)  # Leave space for z axis
> plot(x, y)
> par(new=T)
> plot(x, z, type="l", axes=F, bty="n", xlab="", ylab="")
> axis(4, at=pretty(range(z)))
> mtext(z, 4, 3)
change last line to mtext("z", 4, 3).

J.
On Tue, 2005-08-02 at 17:18 +0100, herodote at oreka.com wrote:
> Hi all
> 
> i need to put on one graph 2 functions who's x axis is the same and y not.
> 
> I mean on horizontal the time, and on vertical left: pressure, on vertical right: rpm of a motor, is R able to do that?
> 
> i've found this that i could adapt maybe (i don't need time series really?) :/ :
> 
> (http://tolstoy.newcastle.edu.au/R/help/04/03/1456.html)
> ## 
> ## Description: A simple function which plots two time series on one plot where 
> ## the series can have different value intervals over the same time interval. 
> ## Usage: ts.plot.2Axis(xleft, xright) 
> ## Arguments: xleft is the time series for the left vertical axis and xright 
> ## is for the right axis. xleft and xright are defined as time series with 
> ## the 'ts' function in package ts. 
> ## ts.plot function must be available, do library(ts) to ensure this if 
> ## necessary. 
> ## In addition the usual 'ts.plot' and 'plot' parameters can be set 
> ## directly (mar, main, xlab, ylab, lwd) or through gpars as in ts.plot. 
> ## Also parameter digits is the preferred number of decimal digits on right 
> ## axis and ticks is the preferred number of tick marks on right axis. 
> ## Details: The time series for the right vertical axis is scaled with a simple 
> ## rule of thumb scaling. 
> ## The ts.plot function is used to plot the series. 
> ## Value: None. 
> ## Note: When scaling is not acceptable try switching the series parameters. 
> ## If a ylabel is to be set it is here only possible for the left axis. 
> ## See also: 'ts.plot', 'ts', 'legend'. 
> ## Author and date: Hauksson, Bjorn Arnar. March 2004. 
> ## Example: 
> ## First paste this function into the R console or use 'source'. 
> #library(ts) 
> #data(UKLungDeaths) 
> #x <- ldeaths 
> #y <- fdeaths/mdeaths 
> #ts.plot.2Axis(x, y) 
> #legTxt <- c("UK lung deaths", "UK female/male deaths (rhs)") 
> #legend(1976.5, 3950, legTxt, lty=c(1:2), col=c(1:2), lwd=2, bty="n") 
> ## 
> 
> 
> ts.plot.2Axis <- function(xleft, xright, digits=1, ticks=5, 
>                           mar=(c(4,4,4,4)+0.1), main="", 
>                           xlab="", ylab="", lwd=2, gpars=list()) { 
>         # Settings for other parameters than those in the function parameter list 
>         par(mar=mar) # Margins 
>       k <- ncol(as.matrix(xleft)) # Number of time series on left vertical scale 
>         lty <- c(1:(k+1)) # Line types 
>         col <- c(1:(k+1)) # Line colors 
> 
> 
>         # Scale time series on right vertical axis 
>         scale <- (max(xleft)-min(xleft))/(max(xright)-min(xright)) 
>       xright2 <- xright*scale 
>       meanScale <- mean(xleft) - mean(xright2) 
>         xright2 <- xright2 + meanScale 
> 
> 
>         # Plot the series 
>         ts.plot(xleft, xright2, lty=lty, col=col, main=main, ylab=ylab, xlab=xlab, 
>         lwd=lwd, gpars=gpars) 
> 
> 
>         # Add the right vertical axis labels 
>         lab <- seq(round(min(xright), digits), round(max(xright), digits), 
>         length=ticks) 
>         labAt <- seq(min(xright2), max(xright2), length=ticks) 
>         axis(side=4, labels=lab, at=labAt) 
> } 
> 
> are there a better way to plot what i want?
> 
> thks.
> guillaume.
> 
> ////////////////////////////////////////////////////////////
> // Webmail Oreka : http://www.oreka.com
> ////////////////////////////////////////////////////////////
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
-- 
Jeanie (Jie) Na

Programmer Analyst II                       _   _    ___    _   _    ____
Department of Quantitative Health Sciences [_]-[_]  / - \  | |_| |  (_(_
Cleveland Clinic Foundation                 |   |  ( |_| ) )  _  (   _| )
Tel: (216)4451369                          [_]-[_]  \_\_\  |_| |_|  (___/



From p.dalgaard at biostat.ku.dk  Tue Aug  2 19:19:53 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Aug 2005 19:19:53 +0200
Subject: [R] how to print a data.frame without row.names
In-Reply-To: <17135.41487.149836.798318@stat.math.ethz.ch>
References: <3.0.6.32.20050802154514.007b39c0@pop.gmx.net>
	<3.0.6.32.20050802174607.007ae100@pop.gmx.net>
	<17135.41487.149836.798318@stat.math.ethz.ch>
Message-ID: <x2ek9cl0hy.fsf@turmalin.kubism.ku.dk>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

> >>>>> "Heinz" == Heinz Tuechler <tuechler at gmx.at>
> >>>>>     on Tue, 02 Aug 2005 17:46:07 +0200 writes:
> 
>   .......................
> 
>     Heinz> I tried this, but then the column headers and column
>     Heinz> contents are not aligned.
> 
>   ........................
> 
> Use the tabulator if you need them aligned :
> 
> write.table(USArrests, row.names = FALSE, sep = "\t")

Unless a column or a header is 8 chars or wider (and UrbanPop is!).

This seems to do it:

  x <- as.matrix(format(USArrests))
  rownames(x) <- rep("", nrow(x))
  print(x, quote=FALSE, right=TRUE)

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From gavin.simpson at ucl.ac.uk  Tue Aug  2 19:27:33 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 02 Aug 2005 18:27:33 +0100
Subject: [R] problem using evaluating a formula
Message-ID: <1123003653.26101.26.camel@gsimpson.geog.ucl.ac.uk>

##data
y1 <- matrix(c(3,1,0,1,0,1,1,0,0,0,1,0,0,0,1,1,0,1,1,1),
             nrow = 5, byrow = TRUE)
y2 <- matrix(c
(3,0,10,3,3,0,0,1,1,0,0,0,0,0,1,0,1,0,0,2,1,0,1,1,0,2,1,1,4,1),
             nrow = 5, byrow = TRUE)
y1 <- as.data.frame(y1)
y2 <- as.data.frame(y2)
rownames(y1) <- rownames(y2) <- paste("site", 1:5, sep = "")
colnames(y1) <- paste("spp", 1:4, sep = "")
colnames(y2) <- paste("spp", 1:6, sep = "")

##code
coca.formula <- function(formula, data, ...)
  {
    ##cat("\nusing formula method\n")
    ##browser()
    if (missing(data)) {
        data <- parent.frame()
    }
    m <- match.call(expand.dots = FALSE)
    m$... <- NULL
    m[[1]] <- as.name("model.frame")
## the next line fails
    m <- eval(m, sys.parent())
    Terms <- attr(m, "terms")
    Response <- model.extract(m, "response")
    attr(Terms, "intercept") <- 0
    Predictor <- model.matrix(Terms, m)
    retval <- list(m = m, Terms = Terms, Response = Response,
                   Predictor = Predictor)
    return(retval)
  }

coca(y1 ~ y2, method = "symmetric", symmetric= TRUE)

gives:

Error in model.frame(formula, rownames, variables, varnames, extras,
extranames,  : 
	invalid variable type

when executing the indicated line

now both y1 and y2 are data.frames - this is the natural way of
specifying the model I have in mind - and I think this is the problem as
it seems to be the rhs of the formula that is causing the error.

Is there an alternative way of handling and evaling formulae if the rhs
is a data.frame (if my assumption is correct of course)? I would like,
eventually, to have the option of specifying the predictors as either a
data.frame or via named variables found in the variable passed to data.

A simple alternative would be to do the following:

predictor <- get(as.character(formula[[3]]))
response <- get(as.character(formula[[2]]))

Would I be missing something vital that I'm not appreciating if I used
this simple method?

Any other suggestions gratefully received.

Many thanks in advance,

Gav
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From S.Pickett at exeter.ac.uk  Tue Aug  2 19:26:29 2005
From: S.Pickett at exeter.ac.uk (sp219)
Date: Tue, 2 Aug 2005 18:26:29 +0100
Subject: [R] simplifying a lmer model
Message-ID: <42F281BA@minerva2.ex.ac.uk>

I have been using lmer in lme4() to analyse the effect of dropping a term from 
the model as below 
anova.name<-anova(m1,m2)
Where m1 is an original model and m2 has one term removed. I can then create 
my own type III tables for each variable in the model. However with many 
variables this becomes exceedingly time consuming! 
anova.lme in nlme() and Anova() in car dont seem to work for lme objects 
created with lmer? Is there any other way to create type III tables?
Any help much appreciated.
Simon P

Simon Pickett
Centre for Ecology and Conservation Biology
University of Exeter in Cornwall
Tremough Campus
Penryn 
Cornwall
TR10 9EZ UK
Tel: 01326371852



From gavin.simpson at ucl.ac.uk  Tue Aug  2 19:31:52 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 02 Aug 2005 18:31:52 +0100
Subject: [R] problem using evaluating a formula
In-Reply-To: <1123003653.26101.26.camel@gsimpson.geog.ucl.ac.uk>
References: <1123003653.26101.26.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <1123003912.26995.1.camel@gsimpson.geog.ucl.ac.uk>

On Tue, 2005-08-02 at 18:27 +0100, Gavin Simpson wrote:
> ##data
<snip>
> 
> coca(y1 ~ y2, method = "symmetric", symmetric= TRUE)

sorry, this should have been:

coca.formula(y1 ~ y2, method = "symmetric", symmetric= TRUE)

> gives:
> 
> Error in model.frame(formula, rownames, variables, varnames, extras,
> extranames,  : 
> 	invalid variable type
<snip>

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From p.dalgaard at biostat.ku.dk  Tue Aug  2 19:36:35 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 02 Aug 2005 19:36:35 +0200
Subject: [R] simplifying a lmer model
In-Reply-To: <42F281BA@minerva2.ex.ac.uk>
References: <42F281BA@minerva2.ex.ac.uk>
Message-ID: <x2ack0kzq4.fsf@turmalin.kubism.ku.dk>

sp219 <S.Pickett at exeter.ac.uk> writes:

> I have been using lmer in lme4() to analyse the effect of dropping a term from 
> the model as below 
> anova.name<-anova(m1,m2)
> Where m1 is an original model and m2 has one term removed. I can then create 
> my own type III tables for each variable in the model. However with many 
> variables this becomes exceedingly time consuming! 
> anova.lme in nlme() and Anova() in car dont seem to work for lme objects 
> created with lmer? Is there any other way to create type III tables?
> Any help much appreciated.
> Simon P

I haven't played nearly as much with lme4 as I perhaps should have,
but my first try would be to see whether drop1 works on lmer models.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From JSirgo at navigantconsulting.com  Tue Aug  2 19:42:25 2005
From: JSirgo at navigantconsulting.com (Jorge Sirgo)
Date: Tue, 2 Aug 2005 13:42:25 -0400
Subject: [R] Help with sas.get
Message-ID: <OF45AA0D64.326E3EE2-ON85257051.0060F7D6-85257051.0061440B@insidenci.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050802/6e8e85a1/attachment.pl

From tlumley at u.washington.edu  Tue Aug  2 20:08:29 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 2 Aug 2005 11:08:29 -0700 (PDT)
Subject: [R] can we manage memory usage to increase speed?
In-Reply-To: <42EF968B.7080009@pdf.com>
References: <CA0BCF3BED56294AB91E3AD74B849FD57F410B@us-arlington-0668.mail.saic.com>
	<42EF968B.7080009@pdf.com>
Message-ID: <Pine.A41.4.61b.0508021107240.307516@homer04.u.washington.edu>

On Tue, 2 Aug 2005, Spencer Graves wrote:

> 	  And you can identify inefficient code fairly easily taking snapshots
> from "proc.time" and computing elapsed time for sections of your code.

Or use the profiler, which makes it much easier. There was a Programmers' 
Niche article about it in one of the first R Newsletters.

 	-thomas


> 	  spencer graves
>
> Tuszynski, Jaroslaw W. wrote:
>
>>
>> If you have a code that takes 2 weeks to run, than it might be a case of
>> inefficient algorithm design. I was able to go from overnight runs (SELDI
>> data analysis) to 20 minute runs by identifying single inefficient function
>> that took most of the time, and writing it in C.
>>
>> Jarek
>> ====================================================\=======
>>
>>  Jarek Tuszynski, PhD.                           o / \
>>  Science Applications International Corporation  <\__,|
>>  (703) 676-4192                                   ">   \
>>  Jaroslaw.W.Tuszynski at saic.com                     `    \
>>
>>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Zhilin Liu
>> Sent: Monday, August 01, 2005 8:28 PM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] can we manage memory usage to increase speed?
>>
>> Hi,
>>
>> Thanks for reading.
>>
>> I am running  a process in R for microarray data analysis. RedHat Enterprise
>> Linux 4, dual AMD CPU, 6G memory. However, the R process use only a total of
>> <200M memory. And the CPU usage is total to ~110% for two. The program takes
>> at least 2 weeks to run at the current speed. Is there some way we can
>> increase the usage of CPUs and memories and speed up? Any suggestion is
>> appreciated.
>>
>> Thanks again.
>>
>> Zhilin
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> -- 
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
>
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From dhiren22 at hotmail.com  Tue Aug  2 20:54:15 2005
From: dhiren22 at hotmail.com (Dhiren DSouza)
Date: Tue, 02 Aug 2005 14:54:15 -0400
Subject: [R]  reading in and mps file
Message-ID: <BAY102-F1985A717D9AC6A85A853BCD3C20@phx.gbl>

Hi all:

How does one read in an mps file and store it in a matrix as is.  I have 
pasted the format of the file.  I have implemented an mps writer but would 
like to have the capability to read in an mps file as well and store it in a 
matrix with out using the 'linprog' routines in R.  Is there are way to use 
read.table or scan on the file below.  Your help will be greatly 
appreciated.

-Dhiren

NAME test.2005-08-02.Tue
ROWS
N obj
L CPA
E ass1
E ass2
E ass3
COLUMNS
982323.1 obj 7.12279694339023 CPA -0.300433084368706 ass1 1
982323.2 obj -8.41320485916529 CPA 0.603671897647387 ass1 1
982323.41 obj 0 CPA 0 ass1 1
982351.1 obj -21.4471176117659 CPA 1.80909823649563 ass2 1
982351.22 obj -32.9606785054072 CPA 3.23030611400710 ass2 1
982351.41 obj 0 CPA 0 ass2 1
982554.1 obj 1.66536080466821 CPA -0.107303781434894 ass3 1
982554.23 obj -1.07268986390231 CPA 0.100720627703143 ass3 1
982554.41 obj 0 CPA 0 ass3 1
RHS
rhs ass1 1
rhs ass2 1
rhs ass3 1
ENDATA



From sasprog474 at yahoo.com  Tue Aug  2 21:13:13 2005
From: sasprog474 at yahoo.com (Greg Tarpinian)
Date: Tue, 2 Aug 2005 12:13:13 -0700 (PDT)
Subject: [R] Hmisc / Design question
Message-ID: <20050802191313.2176.qmail@web32805.mail.mud.yahoo.com>

All,

I have been reading Dr. Harrell's excellent 
"Regression Modeling Strategies" book and trying out
the exercises.  I understand that contrast( ) is used
to obtain contrasts between two variables for given 
levels of other nuisance variables; is there a way
to use contrast( ) to obtain, for example, Scheffe
confidence intervals / hypothesis tests for many
post hoc contrasts at once?

Any help would be much appreciated,

    Greg



From Hathaikan.Chootrakool at newcastle.ac.uk  Tue Aug  2 21:36:23 2005
From: Hathaikan.Chootrakool at newcastle.ac.uk (Hathaikan Chootrakool)
Date: Tue, 2 Aug 2005 20:36:23 +0100 (BST)
Subject: [R] Loop problem
Message-ID: <2411.128.240.6.80.1123011383.squirrel@128.240.6.80>

Dear everyone

     I am a new user,would like to combine these code together by using a
loop,each function has three value as Tr = 1 - 3,how can i combine
together?


logitTr1 <-logit[logit[,"Study"]&logit[,"Tr"]==1,]
(number of row in each group (1-3) is difference but equal in colume)

fnTr1 <- function (p) sum(
n/2*log(2*pi)+log(1/logitTr1$sd)+1/2*(logitTr1$logitp*logitTr1$logitp-2*logitTr1$logitp*p+p^2)
                    *1/logitTr1$sd*logitTr1$sd )
(maximum likelyhood function)

outTr1<- nlm (fnTr1,p=c(10),hessian=TRUE)
minimumTr1 <- outTr1$minimum
valueTr1 <- outTr1$estimate
(estimate the value)

The problem is the program couldn't work by using logitTr[i],fnTr[i]
outTr[i],minimumTr[i],value[i] in a loop. The function logitTr[i] is the
data matrix which is not equal each group, fnTr[i] is the
maximumlikelyhood function for estimation in next step;
outTr[i],minimumTr[i],valueTr[i].



Has anyone got any idea to help me?,thank you very much.

Hathaikan



From arrayprofile at yahoo.com  Tue Aug  2 21:45:18 2005
From: arrayprofile at yahoo.com (array chip)
Date: Tue, 2 Aug 2005 12:45:18 -0700 (PDT)
Subject: [R] memory limit
Message-ID: <20050802194518.33524.qmail@web40810.mail.yahoo.com>

Hi, is it possible to increase the memory limit to
infinite so that I don't need to worry about whether
it is enough or not? In S-plus, you can do this by
setting:

options( memory = as.integer( Inf ) )

is it possible to do this in R?



From steve_adams_sd at yahoo.com  Tue Aug  2 21:51:14 2005
From: steve_adams_sd at yahoo.com (Steve Adams)
Date: Tue, 2 Aug 2005 12:51:14 -0700 (PDT)
Subject: [R] parallel computing in R
Message-ID: <20050802195114.66092.qmail@web33313.mail.mud.yahoo.com>

Hi, is there an excellent source of documentation for
installation, configuration of R packages
(Rmpi,snow,rsprng etc.) for parallel computing on
linus system?

Thanks



From f.harrell at vanderbilt.edu  Tue Aug  2 22:16:50 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 02 Aug 2005 15:16:50 -0500
Subject: [R] Hmisc / Design question
In-Reply-To: <20050802191313.2176.qmail@web32805.mail.mud.yahoo.com>
References: <20050802191313.2176.qmail@web32805.mail.mud.yahoo.com>
Message-ID: <42EFD4B2.90302@vanderbilt.edu>

Greg Tarpinian wrote:
> All,
> 
> I have been reading Dr. Harrell's excellent 
> "Regression Modeling Strategies" book and trying out
> the exercises.  I understand that contrast( ) is used
> to obtain contrasts between two variables for given 
> levels of other nuisance variables; is there a way
> to use contrast( ) to obtain, for example, Scheffe
> confidence intervals / hypothesis tests for many
> post hoc contrasts at once?
> 
> Any help would be much appreciated,
> 
>     Greg

Steven Novick (cc'd) has written some nice code that I regret I haven't 
had time to add into contrast.Design for doing simulation-based 
adjustment for multiple comparisons.  Below is the code he sent me.

## Program:     multiple.adjustment.R
## Version:     1
## Author:      Steven Novick
## Date:        May 21, 2004
## Purpose:     Compute the exact T-critical value for multiple 
comparisons based on the paper
##              Don Edwards and Jack Berry (1987). "The Efficiency of 
Simulation-Based Multiple Comparison".
##              Biometrics 43, pp913-928.
multiple.adjustment = function(fit, cont1, cont2, alpha=.05, m=79999)
{
     ## fit = object of class "ols" from library Design
     ## cont1, cont2 = data.frame with elements to be contrasted.  See 
function "contrast" in Design.
     ## alpha = test significance level
     ## m = number of monte-carlo runs
     V=fit$var/fit$stats["Sigma"]^2  ## Var( coef(fit) ) = sigma^2 * V
     C=contrast(fit, cont1, cont2)$X ## Contrast matrix
     df = fit$df    ## Error degrees of freedom


     r = (m+1)*(1-alpha) # P( W < w[r] ) = alpha
     if ( floor(r) != ceiling(r) )
         stop("(m+1)*(1-alpha) must be an integer.")


     ## Create random numbers
     n.contrast=nrow(C)
     n.coef=length(coef(fit))
     G=chol(V)
     U=apply(C, 1, function(ctr){( G%*%ctr 
)/as.vector(sqrt(t(ctr)%*%V%*%ctr)) })
     W = sort(sapply(1:m, function(i){ z=rnorm(n.coef); y=sqrt(rchisq(1, 
df)/df); w=abs(t(U)%*%z)/y; return(max(w)) }))

     w.alpha = W[r]  ## Cut-off value for testing; 95% CI = beta.hat + 
c(-1, 1)*w.alpha* SE(beta.hat)
     alpha.star = 2*(1-pt(w.alpha, df))      ## What is alpha if using 
T-statistic ?

     return(list(w.alpha=w.alpha, alpha.star=alpha.star))
}
-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From ligges at statistik.uni-dortmund.de  Tue Aug  2 22:24:40 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 02 Aug 2005 22:24:40 +0200
Subject: [R] memory limit
In-Reply-To: <20050802194518.33524.qmail@web40810.mail.yahoo.com>
References: <20050802194518.33524.qmail@web40810.mail.yahoo.com>
Message-ID: <42EFD688.1030808@statistik.uni-dortmund.de>

array chip wrote:

> Hi, is it possible to increase the memory limit to
> infinite so that I don't need to worry about whether
> it is enough or not? In S-plus, you can do this by
> setting:
> 
> options( memory = as.integer( Inf ) )
 >
> is it possible to do this in R?

You are on Windows, right?

See ?memory.limit

You cannot say "Inf", but memory.limit(4000) sets it to 4Gb which you 
won't reach with a 32bit machine anyway.

Say you are on a 32bit machine with 512Mb of RAM, you certainly do not 
want that R accesses much more than 512Mb for itself, in order to 
prevent too much swapping. And that's what R chooses for you.

Uwe Ligges



> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From spluque at gmail.com  Tue Aug  2 22:17:50 2005
From: spluque at gmail.com (Sebastian Luque)
Date: Tue, 02 Aug 2005 15:17:50 -0500
Subject: [R] cut.Date functionality for chron date/time objects
Message-ID: <87u0i8ks9d.fsf@gmail.com>

Hello,

I've encountered the need to cut some chron objects of the form:

R> mychron <- chron(sort(runif(10, 0, 10)))
R> mychron
 [1] (01/01/70 16:36:20) (01/02/70 00:08:46) (01/03/70 16:54:49)
 [4] (01/04/70 06:45:00) (01/07/70 06:21:24) (01/07/70 18:28:44)
 [7] (01/08/70 00:47:05) (01/08/70 05:11:44) (01/10/70 01:07:53)
[10] (01/10/70 17:46:53)

into arbitrary (e.g. a given number of minutes, seconds, etc.) units.
Basically, I'm searching for the functionality of cut.Date, which has a
nice 'breaks' argument:


,-----[ *help[R](cut.Date)* (lines: 23 - 30) ]
|   breaks: a vector of cut points _or_ number giving the number of
|           intervals which 'x' is to be cut into _or_ an interval
|           specification, one of '"sec"', '"min"', '"hour"', '"day"',
|           '"DSTday"', '"week"', '"month"' or '"year"', optionally
|           preceded by an integer and a space, or followed by '"s"'. 
|           For '"Date"' objects only '"day"', '"week"', '"month"' and
|           '"year"' are allowed. 
`-----

'cut.dates' (from chron itself) allows for cut'ing into months, years,
etc., but not any fractions or multiples of these.

Converting the chron objects to POSIXct (via 'as.POSIXct') and then using
cut.Date works, but is inconvenient, as it introduces time zone
information. Is there a better way to deal with this?

Thanks in advance,
-- 
Sebastian P. Luque



From liuwensui at gmail.com  Tue Aug  2 22:32:24 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Tue, 2 Aug 2005 16:32:24 -0400
Subject: [R] Help with sas.get
In-Reply-To: <OF45AA0D64.326E3EE2-ON85257051.0060F7D6-85257051.0061440B@insidenci.com>
References: <OF45AA0D64.326E3EE2-ON85257051.0060F7D6-85257051.0061440B@insidenci.com>
Message-ID: <1115a2b0050802133258d0e707@mail.gmail.com>

Jorge,

My understanding about sas.get is that it actually runs SAS in the
backend, output the SAS data, and then import it into R again.

It might be better to convert SAS to csv format and read it into R.

On 8/2/05, Jorge Sirgo <JSirgo at navigantconsulting.com> wrote:
> I am running R 2.0.1 on Windows trying to import a SAS dataset into R
> using sas.get.
> 
> It is a small SAS dataset, but when I write the command, the SAS window
> opens but never appears to complete.  Am I doing something wrong?
> 
> Here is an example of my command:
> 
> temp <- sas.get("J:/blah","name")
> 
> Jorge
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
WenSui Liu, MS MA
Senior Decision Support Analyst
Division of Health Policy and Clinical Effectiveness
Cincinnati Children Hospital Medical Center



From mdsohn at yahoo.com  Tue Aug  2 22:34:09 2005
From: mdsohn at yahoo.com (Michael Sohn)
Date: Tue, 2 Aug 2005 13:34:09 -0700 (PDT)
Subject: [R] breaking command in command line in R for Mac Aqua
Message-ID: <20050802203409.21315.qmail@web50904.mail.yahoo.com>

I'm using R for Mac Aqua version 2.1.1

If at the command line, I type:
ls(
and then a return, the command line prompt changes to
a plus sign indicating that the command has not been
completed.  How do I break, or kill, the partial
command?  Sometimes, I type a long command but miss a
bracket or parenthesis.  On a unix or linux version of
R, I can type ctrl-c.  On the Mac, ctrl-c,
command-(dot), and escape do not work.

Any solutions?
Mike



From f.harrell at vanderbilt.edu  Tue Aug  2 23:00:13 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 02 Aug 2005 16:00:13 -0500
Subject: [R] Help with sas.get
In-Reply-To: <1115a2b0050802133258d0e707@mail.gmail.com>
References: <OF45AA0D64.326E3EE2-ON85257051.0060F7D6-85257051.0061440B@insidenci.com>
	<1115a2b0050802133258d0e707@mail.gmail.com>
Message-ID: <42EFDEDD.2030905@vanderbilt.edu>

Wensui Liu wrote:
> Jorge,
> 
> My understanding about sas.get is that it actually runs SAS in the
> backend, output the SAS data, and then import it into R again.

He has SAS running locally.
> 
> It might be better to convert SAS to csv format and read it into R.

For that, the Hmisc package's sasxport.get(..., method='csv'...) can help.

Frank

> 
> On 8/2/05, Jorge Sirgo <JSirgo at navigantconsulting.com> wrote:
> 
>>I am running R 2.0.1 on Windows trying to import a SAS dataset into R
>>using sas.get.
>>
>>It is a small SAS dataset, but when I write the command, the SAS window
>>opens but never appears to complete.  Am I doing something wrong?
>>
>>Here is an example of my command:
>>
>>temp <- sas.get("J:/blah","name")
>>
>>Jorge
>>        [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From edd at debian.org  Tue Aug  2 23:32:05 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 2 Aug 2005 21:32:05 +0000 (UTC)
Subject: [R] parallel computing in R
References: <20050802195114.66092.qmail@web33313.mail.mud.yahoo.com>
Message-ID: <loom.20050802T232424-281@post.gmane.org>

Steve Adams <steve_adams_sd <at> yahoo.com> writes:
> Hi, is there an excellent source of documentation for
> installation, configuration of R packages
> (Rmpi,snow,rsprng etc.) for parallel computing on
> linus system?

In case you want it ready-to-run, Rmpi, SNOW, Rsprng, ... work out 
of the box under Quantian, which would give you openMosix to boot
which can make scheduling MPI/PVM easier. For more about Quantian,
see the pages at http://dirk.eddelbuettel.com/quantian 

All three are also part of Debian so you could add them (pre-built, 
no less) to a regular Debian system, and possibly a derived system 
such as Ubuntu. Sprng was a bit tricky to build, the others are 
pretty standard.

I talked about it a little at Usenix last year and intend to revisit 
this for DSC 2005 in a couple of days. 

Hope this helps, Dirk



From zhilinliu_email at yahoo.com  Tue Aug  2 23:35:12 2005
From: zhilinliu_email at yahoo.com (Zhilin Liu)
Date: Tue, 2 Aug 2005 14:35:12 -0700 (PDT)
Subject: [R] can we manage memory usage to increase speed?
In-Reply-To: <40e66e0b0508020957ea37522@mail.gmail.com>
Message-ID: <20050802213512.7540.qmail@web50305.mail.yahoo.com>

Hi, 
Thank you all for the kind reply.

I recompiled R as the previous one turned profiling
off. 

I am using package MAANOVA, running the matest
function which is a permutation test. The author did
warn that it takes a long time to run.

Here is one of the test results:
[ Rdata]# ./R CMD Rprof maanovatest.out

Each sample represents 0.02 seconds.
Total run time: 905.959999999466 seconds.

Total seconds: time spent in function and callees.
Self seconds: time spent in function alone.

   %       total       %       self
 total    seconds     self    seconds    name
100.00    905.94      0.00      0.00     "matest"
 80.18    726.40      0.25      2.30     "fitmaanova"
 79.37    719.04      0.19      1.72     "mixed"
 68.34    619.16      1.05      9.50     "pinv"
 64.33    582.78      0.88      7.96     "La.svd"
 55.51    502.90     55.51    502.90     ".Call"
 38.47    348.54      1.58     14.28     "makeHq"
 34.50    312.60      0.13      1.18     "solveMME"
 19.80    179.42      0.18      1.60    
"matest.engine"
 10.19     92.30     10.19     92.30     "%*%"
......

The other part are not pasted as they are almost the
same everytime we check the profiling. Only the parts
above changes. For example, here is another output:
100.00   1411.02      0.00      0.02     "matest"
 82.88   1169.40      0.24      3.40     "fitmaanova"
 82.22   1160.18      0.19      2.74     "mixed"
 68.82    971.02      1.06     14.90     "pinv"
 64.84    914.94      0.85     11.98     "La.svd"
 56.10    791.64     56.10    791.64     ".Call"
 39.13    552.10      1.55     21.84     "makeHq"
 36.77    518.82      0.13      1.88     "solveMME"
 31.40    443.04      0.00      0.00     "matest.perm"
 17.10    241.32      0.16      2.28    
"matest.engine"
 10.15    143.24     10.15    143.24     "%*%"

I run this with a permutation of 2 times and it is
still running. So it is not possible to run 1000
permutations with this kind of speed.

And here is the output of TOP for R:
  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM   
TIME+  COMMAND
15250 liuz       0 -20  218m 136m 2556 R 72.3  2.5 
29:05.20 R

Any suggestion to improve the performance is highly
appreciated.

Thanks a lot.

Zhilin



--- Douglas Bates <dmbates at gmail.com> wrote:

> On 8/2/05, Spencer Graves <spencer.graves at pdf.com>
> wrote:
> >           And you can identify inefficient code
> fairly easily taking snapshots
> > from "proc.time" and computing elapsed time for
> sections of your code.
> > 
> >           spencer graves
> 
> Using Rprof may be a better choice.  See
> 
> ?Rprof
> 
> > 
> > Tuszynski, Jaroslaw W. wrote:
> > 
> > >
> > > If you have a code that takes 2 weeks to run,
> than it might be a case of
> > > inefficient algorithm design. I was able to go
> from overnight runs (SELDI
> > > data analysis) to 20 minute runs by identifying
> single inefficient function
> > > that took most of the time, and writing it in C.
> > >
> > > Jarek
> > >
>
====================================================\=======
> > >
> > >  Jarek Tuszynski, PhD.                          
> o / \
> > >  Science Applications International Corporation 
> <\__,|
> > >  (703) 676-4192                                 
>  ">   \
> > >  Jaroslaw.W.Tuszynski at saic.com                  
>   `    \
> > >
> > >
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On
> Behalf Of Zhilin Liu
> > > Sent: Monday, August 01, 2005 8:28 PM
> > > To: r-help at stat.math.ethz.ch
> > > Subject: [R] can we manage memory usage to
> increase speed?
> > >
> > > Hi,
> > >
> > > Thanks for reading.
> > >
> > > I am running  a process in R for microarray data
> analysis. RedHat Enterprise
> > > Linux 4, dual AMD CPU, 6G memory. However, the R
> process use only a total of
> > > <200M memory. And the CPU usage is total to
> ~110% for two. The program takes
> > > at least 2 weeks to run at the current speed. Is
> there some way we can
> > > increase the usage of CPUs and memories and
> speed up? Any suggestion is
> > > appreciated.
> > >
> > > Thanks again.
> > >
> > > Zhilin
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> > 
> > --
> > Spencer Graves, PhD
> > Senior Development Engineer
> > PDF Solutions, Inc.
> > 333 West San Carlos Street Suite 700
> > San Jose, CA 95110, USA
> > 
> > spencer.graves at pdf.com
> > www.pdf.com <http://www.pdf.com>
> > Tel:  408-938-4420
> > Fax: 408-280-7915
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From tuechler at gmx.at  Tue Aug  2 23:59:32 2005
From: tuechler at gmx.at (Heinz Tuechler)
Date: Tue, 02 Aug 2005 23:59:32 +0200
Subject: [R] how to print a data.frame without row.names
In-Reply-To: <x2ek9cl0hy.fsf@turmalin.kubism.ku.dk>
References: <17135.41487.149836.798318@stat.math.ethz.ch>
	<3.0.6.32.20050802154514.007b39c0@pop.gmx.net>
	<3.0.6.32.20050802174607.007ae100@pop.gmx.net>
	<17135.41487.149836.798318@stat.math.ethz.ch>
Message-ID: <3.0.6.32.20050802235932.007b35b0@pop.gmx.net>

Thanks to all of you for your help.

As far as I see, the solution of Peter Dalgaard works exactly as I want.
All other solutions have limitations.

Heinz

At 19:19 02.08.2005 +0200, Peter Dalgaard wrote:
>Martin Maechler <maechler at stat.math.ethz.ch> writes:
>
>> >>>>> "Heinz" == Heinz Tuechler <tuechler at gmx.at>
>> >>>>>     on Tue, 02 Aug 2005 17:46:07 +0200 writes:
>> 
>>   .......................
>> 
>>     Heinz> I tried this, but then the column headers and column
>>     Heinz> contents are not aligned.
>> 
>>   ........................
>> 
>> Use the tabulator if you need them aligned :
>> 
>> write.table(USArrests, row.names = FALSE, sep = "\t")
>
>Unless a column or a header is 8 chars or wider (and UrbanPop is!).
>
>This seems to do it:
>
>  x <- as.matrix(format(USArrests))
>  rownames(x) <- rep("", nrow(x))
>  print(x, quote=FALSE, right=TRUE)
>
>-- 
>   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
>  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
>~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>
>



From ggrothendieck at gmail.com  Wed Aug  3 01:21:48 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 2 Aug 2005 19:21:48 -0400
Subject: [R] cut.Date functionality for chron date/time objects
In-Reply-To: <87u0i8ks9d.fsf@gmail.com>
References: <87u0i8ks9d.fsf@gmail.com>
Message-ID: <971536df05080216212b1a6b49@mail.gmail.com>

Assuming, as in your post:

set.seed(123)
mychron <- chron(sort(runif(10, 0, 10)))
breaks <- quantile(mychron)

# is one of these adequate?

cut(mychron, breaks)

cut(unclass(mychron), unclass(breaks), lab = FALSE)



On 8/2/05, Sebastian Luque <spluque at gmail.com> wrote:
> Hello,
> 
> I've encountered the need to cut some chron objects of the form:
> 
> R> mychron <- chron(sort(runif(10, 0, 10)))
> R> mychron
>  [1] (01/01/70 16:36:20) (01/02/70 00:08:46) (01/03/70 16:54:49)
>  [4] (01/04/70 06:45:00) (01/07/70 06:21:24) (01/07/70 18:28:44)
>  [7] (01/08/70 00:47:05) (01/08/70 05:11:44) (01/10/70 01:07:53)
> [10] (01/10/70 17:46:53)
> 
> into arbitrary (e.g. a given number of minutes, seconds, etc.) units.
> Basically, I'm searching for the functionality of cut.Date, which has a
> nice 'breaks' argument:
> 
> 
> ,-----[ *help[R](cut.Date)* (lines: 23 - 30) ]
> |   breaks: a vector of cut points _or_ number giving the number of
> |           intervals which 'x' is to be cut into _or_ an interval
> |           specification, one of '"sec"', '"min"', '"hour"', '"day"',
> |           '"DSTday"', '"week"', '"month"' or '"year"', optionally
> |           preceded by an integer and a space, or followed by '"s"'.
> |           For '"Date"' objects only '"day"', '"week"', '"month"' and
> |           '"year"' are allowed.
> `-----
> 
> 'cut.dates' (from chron itself) allows for cut'ing into months, years,
> etc., but not any fractions or multiples of these.
> 
> Converting the chron objects to POSIXct (via 'as.POSIXct') and then using
> cut.Date works, but is inconvenient, as it introduces time zone
> information. Is there a better way to deal with this?
> 
> Thanks in advance,
> --
> Sebastian P. Luque
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From 2bingho at stanford.edu  Wed Aug  3 02:42:14 2005
From: 2bingho at stanford.edu (Bing Ho)
Date: Tue,  2 Aug 2005 17:42:14 -0700
Subject: [R] Trouble with SciViews-R 0.7-3, SciViews R 0.8-7,
	and Tinn-R 1.16.1.5
Message-ID: <1123029734.42f012e61d024@webmail.stanford.edu>

Hello everybody,

I am new to using Windows and R, and have been experimenting with various
packages.

I recently installed R 2.1.1 under Windows XP SP2, and tried installing the
latest versions of SciViews (0.7-6, and R package 0.8-7 found on the
sciviews.org website), and also Tinn-R 1.16.1.5 stable. I have also been
experimenting with R Commander 0.9-14 stable, 1.0-2 stable, and also tried
1.1 unstable (along with dependent packages).

Oddly, although the installer for SciViews says version 0.7-3, the About
dialog box says 0.7.6. I am not certain which is the correct version.

I have confirmed incompatibility with the latest stable and unstable R
Commander and SciViews (recently noted by Grosjean in R-help). R Commander
0.9-14 does work with SciViews 0.7.6 (.3?), but also produces the
previously reported error that R Commander is not installed (answering "No"
to installing, will allow the correct dialog box to open).

I have noticed the following additional two behaviours which have
consistently been produced.

1. After installing SciViews 0.8-7 package from the SciViews website, the
call-tip functionality is broken in Tinn-R 1.16.1.5 stable. Downgrading, or
installing, the SciViews 0.8-6 from CRAN restores, or enables, this
functionality.

2. The Packages menu in SciViews-R 0.7.3 is hopelessly broken for me (at
least under R 2.1.1). The only menu option that works sometimes, for
reasons I am unable to elucidate, is Load packages (the first option);
however, many times Rconsole crashes altogether. The other menu choices
result in nothing happening. I am able to replicate this behaviour with
multiple fresh installs of R 2.1.1, SciViews 0.7-6 (3?) (and SciViews 0.8.7
package), and tcltk2 0.7-4.

I am not sure that these reports matter since it appears that SciViews will
shortly be updated, but since I found no mention of these issues, I am
hopeful that the next version may fix them.



From spluque at gmail.com  Wed Aug  3 02:55:34 2005
From: spluque at gmail.com (Sebastian Luque)
Date: Tue, 02 Aug 2005 19:55:34 -0500
Subject: [R] cut.Date functionality for chron date/time objects
References: <87u0i8ks9d.fsf@gmail.com>
	<971536df05080216212b1a6b49@mail.gmail.com>
Message-ID: <87r7db7sah.fsf@gmail.com>

Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> Assuming, as in your post:
>
> set.seed(123)
> mychron <- chron(sort(runif(10, 0, 10)))
> breaks <- quantile(mychron)
>
> # is one of these adequate?
>
> cut(mychron, breaks)
>
> cut(unclass(mychron), unclass(breaks), lab = FALSE)

Thank you Gabor, that showed me I really needed to be more creative with
the 'breaks' argument. So what I needed was (with mychron as above):

breaks <- seq(min(mychron, na.rm = TRUE),
              ceiling(max(mychron, na.rm = TRUE)), by = 1/2)

cut(unclass(mychron), unclass(breaks),
    include.lowest = TRUE, labels = FALSE)


in order to cut the chron object into 1/2 day units.


Thanks so much,
-- 
Sebastian P. Luque



From spencer.graves at pdf.com  Wed Aug  3 03:45:15 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 02 Aug 2005 18:45:15 -0700
Subject: [R] cut.Date functionality for chron date/time objects
In-Reply-To: <87r7db7sah.fsf@gmail.com>
References: <87u0i8ks9d.fsf@gmail.com>	<971536df05080216212b1a6b49@mail.gmail.com>
	<87r7db7sah.fsf@gmail.com>
Message-ID: <42F021AB.6040306@pdf.com>

How about the following:

 > set.seed(123)
 > mychron <- chron(sort(runif(10, 0, 10)))
 > (breaks <- chron(pretty(quantile(mychron))))
[1] 01/01/70 01/03/70 01/05/70 01/07/70 01/09/70 01/11/70
 >
spencer graves

Sebastian Luque wrote:

> Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> 
>>Assuming, as in your post:
>>
>>set.seed(123)
>>mychron <- chron(sort(runif(10, 0, 10)))
>>breaks <- quantile(mychron)
>>
>># is one of these adequate?
>>
>>cut(mychron, breaks)
>>
>>cut(unclass(mychron), unclass(breaks), lab = FALSE)
> 
> 
> Thank you Gabor, that showed me I really needed to be more creative with
> the 'breaks' argument. So what I needed was (with mychron as above):
> 
> breaks <- seq(min(mychron, na.rm = TRUE),
>               ceiling(max(mychron, na.rm = TRUE)), by = 1/2)
> 
> cut(unclass(mychron), unclass(breaks),
>     include.lowest = TRUE, labels = FALSE)
> 
> 
> in order to cut the chron object into 1/2 day units.
> 
> 
> Thanks so much,

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From rlyoung at email.arizona.edu  Wed Aug  3 04:06:56 2005
From: rlyoung at email.arizona.edu (Rebecca Young)
Date: Tue,  2 Aug 2005 19:06:56 -0700
Subject: [R] prcomp eigenvalues
Message-ID: <20050802190656.32ds8k84ogk48koo@www.email.arizona.edu>

Hello,

Can you get eigenvalues in addition to eigevectors using prcomp?  If so how?
I am unable to use princomp due to small sample sizes.
Thank you in advance for your help!
Rebecca Young

--
Rebecca Young
Graduate Student
Ecology & Evolutionary Biology, Badyaev Lab
University of Arizona
1041 E Lowell
Tucson, AZ 85721-0088
Office: 425BSW
rlyoung at email.arizona.edu
(520) 621-4005



From 0034058 at fudan.edu.cn  Wed Aug  3 04:38:31 2005
From: 0034058 at fudan.edu.cn (ronggui)
Date: Wed, 03 Aug 2005 10:38:31 +0800
Subject: [R] prcomp eigenvalues
Message-ID: <0IKM001GZK7GPA@mail.fudan.edu.cn>

I donn't think you can get it directly from prcomp ,but you can get it though svd.In fact,the prcomp use the svd to do the principal components analysis .
	

======= 2005-08-03 10:06:56 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>Hello,
>
>Can you get eigenvalues in addition to eigevectors using prcomp?  If so how?
>I am unable to use princomp due to small sample sizes.
>Thank you in advance for your help!
>Rebecca Young
>
>--
>Rebecca Young
>Graduate Student
>Ecology & Evolutionary Biology, Badyaev Lab
>University of Arizona
>1041 E Lowell
>Tucson, AZ 85721-0088
>Office: 425BSW
>rlyoung at email.arizona.edu
>(520) 621-4005
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-08-03

------
Deparment of Sociology
Fudan University

Blog:http://sociology.yculblog.com



From sundar.dorai-raj at pdf.com  Wed Aug  3 04:56:52 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 02 Aug 2005 21:56:52 -0500
Subject: [R] prcomp eigenvalues
In-Reply-To: <20050802190656.32ds8k84ogk48koo@www.email.arizona.edu>
References: <20050802190656.32ds8k84ogk48koo@www.email.arizona.edu>
Message-ID: <42F03274.5010103@pdf.com>



Rebecca Young wrote:
> Hello,
> 
> Can you get eigenvalues in addition to eigevectors using prcomp?  If so how?
> I am unable to use princomp due to small sample sizes.
> Thank you in advance for your help!
> Rebecca Young
> 


Hi, Rebecca,

 From ?prcomp:

      The calculation is done by a singular value decomposition of the
      (centered and possibly scaled) data matrix, not by using 'eigen'
      on the covariance matrix.  This is generally the preferred method
      for numerical accuracy. ...

So you can get the singular values, but not the eigenvalues. You could 
use ?princomp if you really want the eigenvalues. In either case, you 
read the code to see how this is done.

x <- matrix(rnorm(1000), 100, 10)

# eigenvalues
v <- cov.wt(x)
ev <- eigen(v$cov * (1 - 1/v$n.obs), symmetric = TRUE)$values
ev[ev < 0] <- 0
princomp(x)$sdev
sqrt(ev)

# singular values
sv <- svd(scale(x, center = TRUE, scale = FALSE), nu = 0)
prcomp(x)$sdev
sv$d/sqrt(max(1, nrow(x) - 1))

HTH,

--sundar



From spluque at gmail.com  Wed Aug  3 05:00:11 2005
From: spluque at gmail.com (Sebastian Luque)
Date: Tue, 02 Aug 2005 22:00:11 -0500
Subject: [R] cut.Date functionality for chron date/time objects
References: <87u0i8ks9d.fsf@gmail.com>
	<971536df05080216212b1a6b49@mail.gmail.com> <87r7db7sah.fsf@gmail.com>
	<42F021AB.6040306@pdf.com>
Message-ID: <87k6j37mis.fsf@gmail.com>

Spencer Graves <spencer.graves at pdf.com> wrote:
> How about the following:
>
>> set.seed(123)
>> mychron <- chron(sort(runif(10, 0, 10)))
>> (breaks <- chron(pretty(quantile(mychron))))
> [1] 01/01/70 01/03/70 01/05/70 01/07/70 01/09/70 01/11/70

I was looking for a way to cut it into specified units of time, rather
than quantiles. Anyway, both your suggestions show one can go very far
with the breaks arg.

Thank you!
-- 
Sebastian P. Luque



From adrian at maths.uwa.edu.au  Wed Aug  3 06:05:42 2005
From: adrian at maths.uwa.edu.au (Adrian Baddeley)
Date: Wed, 3 Aug 2005 12:05:42 +0800
Subject: [R] hash code for arbitrary object
Message-ID: <17136.17046.279126.350254@maths.uwa.edu.au>

Can anyone suggest a simple way to calculate a 'hash code'
from an arbitrary R object?

hash(x) should return an integer or string 
with the property that 
     if hash(x) != hash(y) then x and y are not identical
and the time to compute hash(x) should be quite short.

Any suggestions welcome
thanks
Adrian Baddeley



From MSchwartz at mn.rr.com  Wed Aug  3 06:26:34 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Tue, 02 Aug 2005 23:26:34 -0500
Subject: [R] hash code for arbitrary object
In-Reply-To: <17136.17046.279126.350254@maths.uwa.edu.au>
References: <17136.17046.279126.350254@maths.uwa.edu.au>
Message-ID: <1123043194.4100.7.camel@localhost.localdomain>

On Wed, 2005-08-03 at 12:05 +0800, Adrian Baddeley wrote:
> Can anyone suggest a simple way to calculate a 'hash code'
> from an arbitrary R object?
> 
> hash(x) should return an integer or string 
> with the property that 
>      if hash(x) != hash(y) then x and y are not identical
> and the time to compute hash(x) should be quite short.
> 
> Any suggestions welcome
> thanks
> Adrian Baddeley


Take a look at Dirk Eddelbuettel's digest() function in the package of
the same name on CRAN. Be sure to read the details section for caveats
regarding collisions.

HTH,

Marc Schwartz



From mblanche at uclink.berkeley.edu  Wed Aug  3 07:26:30 2005
From: mblanche at uclink.berkeley.edu (Marco Blanchette)
Date: Tue, 02 Aug 2005 22:26:30 -0700
Subject: [R]  regexpr and portability issue
Message-ID: <BF15A396.3B20%mblanche@uclink.berkeley.edu>

Dear all--

I am still forging my first arms with R and I am fighting with regexpr() as
well as portability between unix and windoz. I need to extract barcodes from
filenames (which are located between a double and single underscore) as well
as the directory where the filename is residing. Here is the solution I came
to:

aFileName <- 
"/Users/marco/Desktop/diagnosticAnalysis/test/MA__251329410021_S01_A01.txt"
t <- regexpr("__\\d*_",aFileName, perl=T)
t.dir <- regexpr("^.*/", aFileName, perl=T)
base.name <- substr(aFileName, t+2, t-2 + attr(t,"match.length"))
base.dir <- substr(aFileName, t.dir, attr(t.dir,"match.length"))

My questions are:
1) Is there a more elegant way to deal with regular expressions (read here:
more easier, more like perl style).
2) I have a portability problem when I extract the base.dir Windoz is using
'\' instead of '/' to separate directories.

Any suggestions/comments

Many Tx

Marco Blanchette, Ph.D.

mblanche at uclink.berkeley.edu

Donald C. Rio's lab
Department of Molecular and Cell Biology
16 Barker Hall
University of California
Berkeley, CA 94720-3204

Tel: (510) 642-1084
Cell: (510) 847-0996
Fax: (510) 642-6062



From Jin.Li at csiro.au  Wed Aug  3 07:44:19 2005
From: Jin.Li at csiro.au (Jin.Li@csiro.au)
Date: Wed, 3 Aug 2005 15:44:19 +1000
Subject: [R] how to test this
Message-ID: <2BEE99D7F6F1484EBDD1D22167385E7515223B@exqld1-ath.nexus.csiro.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050803/e0196f0d/attachment.pl

From ggrothendieck at gmail.com  Wed Aug  3 07:47:33 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 3 Aug 2005 01:47:33 -0400
Subject: [R] regexpr and portability issue
In-Reply-To: <BF15A396.3B20%mblanche@uclink.berkeley.edu>
References: <BF15A396.3B20%mblanche@uclink.berkeley.edu>
Message-ID: <971536df050802224720d0b200@mail.gmail.com>

Try this.  The regular expression says to match 
- anything 
- followed by a double underscore 
- followed by one or more digits
- followed by an underscore 
- followed by anything.  
The digits have been parenthesized so that they can be referred to in
the backreference "\\1".    Also use the R function dirname
rather than regular expressions.

base.name <- sub(".*__([[:digit:]]+)_.*", "\\1", aFileName, ext = TRUE)
base.dir <- dirname(aFileName)


On 8/3/05, Marco Blanchette <mblanche at uclink.berkeley.edu> wrote:
> Dear all--
> 
> I am still forging my first arms with R and I am fighting with regexpr() as
> well as portability between unix and windoz. I need to extract barcodes from
> filenames (which are located between a double and single underscore) as well
> as the directory where the filename is residing. Here is the solution I came
> to:
> 
> aFileName <-
> "/Users/marco/Desktop/diagnosticAnalysis/test/MA__251329410021_S01_A01.txt"
> t <- regexpr("__\\d*_",aFileName, perl=T)
> t.dir <- regexpr("^.*/", aFileName, perl=T)
> base.name <- substr(aFileName, t+2, t-2 + attr(t,"match.length"))
> base.dir <- substr(aFileName, t.dir, attr(t.dir,"match.length"))
> 
> My questions are:
> 1) Is there a more elegant way to deal with regular expressions (read here:
> more easier, more like perl style).
> 2) I have a portability problem when I extract the base.dir Windoz is using
> '\' instead of '/' to separate directories.
> 
> Any suggestions/comments
> 
> Many Tx
> 
> Marco Blanchette, Ph.D.
> 
> mblanche at uclink.berkeley.edu
> 
> Donald C. Rio's lab
> Department of Molecular and Cell Biology
> 16 Barker Hall
> University of California
> Berkeley, CA 94720-3204
> 
> Tel: (510) 642-1084
> Cell: (510) 847-0996
> Fax: (510) 642-6062
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From bernd.weiss at uni-koeln.de  Wed Aug  3 07:52:40 2005
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Wed, 03 Aug 2005 07:52:40 +0200
Subject: [R] Multilevel logistic regression using lmer vs glmmPQL vs. gllamm
	in Stata
Message-ID: <42F077C8.25154.B07C1D@localhost>

Dear all,

I am trying to replicate some multilevel models with binary outcomes 
using R's "lmer" and "glmmPQL" and Stata's gllmm, respectively. 

The data can be found at <http://www.uni-koeln.de/~ahf34/xerop.dta>. 

The relevant Stata output can be found at  <http://www.uni-
koeln.de/~ahf34/stataoutput.txt>. First, you will find the 
unconditional model, i.e. no level1- or 2-predictor variables. The 
second model contains some level 1-predictor variables

My R file can be found at <http://www.uni-koeln.de/~ahf34/xerop.R>.

Beside the fact that there is a difference between the estimates of 
the intercept (unconditional model: R: -2.76459 and Stata: -2.698923) 
I am especially interested in the level 2 variance. 

In Stata the level 2 variance is about 1.03, while in R it is  4.68. 

Using glmmPQL from package MASS again gives different results for the 
level 2 variance component. What is meant by "Residual"? I thought 
the level 1 variance is fixed to (pi^2)/3.  

I am a beginner in multilevel modeling so I assume I made some 
mistake either in interpreting the output or specifying the models. 

I would appreciate any help.

Bernd



From blomsp at ozemail.com.au  Wed Aug  3 08:23:06 2005
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Wed, 03 Aug 2005 16:23:06 +1000
Subject: [R] how to test this
In-Reply-To: <2BEE99D7F6F1484EBDD1D22167385E7515223B@exqld1-ath.nexus.cs
	iro.au>
References: <2BEE99D7F6F1484EBDD1D22167385E7515223B@exqld1-ath.nexus.csiro.au>
Message-ID: <6.2.1.2.0.20050803161641.01dca268@mail.ozemail.com.au>

This is two tests: Whether the slope != 1 and whether the intercept != 0.

To do this, include an offset in your model:

fit  <- lm(y ~ x + offset(x), data=dat)

HTH,

Simon.


At 03:44 PM 3/08/2005, Jin.Li at csiro.au wrote:
>Dear there,
>
>I am wondering how to test whether a simple linear regression model
>(e.g. y=1.05x) is significantly different from a 1 to 1 line (i.e. y=x).
>Thanks.
>
>Regards,
>
>Jin
>
>
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Centre for Resource and Environmental Studies
The Australian National University
Canberra ACT 0200
Australia
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C



From bernd.weiss at uni-koeln.de  Wed Aug  3 08:24:36 2005
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Wed, 03 Aug 2005 08:24:36 +0200
Subject: [R] Multilevel logistic regression using lmer vs glmmPQL vs.
	gllamm	in Stata
In-Reply-To: <42F077C8.25154.B07C1D@localhost>
Message-ID: <42F07F44.30468.CDB9E4@localhost>

Am 3 Aug 2005 um 7:52 hat Bernd Weiss geschrieben:

[..]

Sorry, I forgot to mention which R version I am using:

> version
         _                           
platform i386-pc-mingw32             
arch     i386                        
os       mingw32                     
system   i386, mingw32               
status   Under development (unstable)
major    2                           
minor    2.0                         
year     2005                        
month    07                          
day      25                          
svn rev  35036                       
language R            


Bernd



From ripley at stats.ox.ac.uk  Wed Aug  3 09:01:48 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 3 Aug 2005 08:01:48 +0100 (BST)
Subject: [R] prcomp eigenvalues
In-Reply-To: <42F03274.5010103@pdf.com>
References: <20050802190656.32ds8k84ogk48koo@www.email.arizona.edu>
	<42F03274.5010103@pdf.com>
Message-ID: <Pine.LNX.4.61.0508030755250.5034@gannet.stats>

The eigenvalues are the squares of the singular values (although you need 
to watch the scalings used, in particular n vs n-1).  (This is standard 
theory.)

Since both are non-negative, given one you can get the other.

On Tue, 2 Aug 2005, Sundar Dorai-Raj wrote:

>
>
> Rebecca Young wrote:
>> Hello,
>>
>> Can you get eigenvalues in addition to eigevectors using prcomp?  If so how?
>> I am unable to use princomp due to small sample sizes.
>> Thank you in advance for your help!
>> Rebecca Young
>>
>
>
> Hi, Rebecca,
>
> From ?prcomp:
>
>      The calculation is done by a singular value decomposition of the
>      (centered and possibly scaled) data matrix, not by using 'eigen'
>      on the covariance matrix.  This is generally the preferred method
>      for numerical accuracy. ...
>
> So you can get the singular values, but not the eigenvalues. You could
> use ?princomp if you really want the eigenvalues. In either case, you
> read the code to see how this is done.
>
> x <- matrix(rnorm(1000), 100, 10)
>
> # eigenvalues
> v <- cov.wt(x)
> ev <- eigen(v$cov * (1 - 1/v$n.obs), symmetric = TRUE)$values
> ev[ev < 0] <- 0
> princomp(x)$sdev
> sqrt(ev)
>
> # singular values
> sv <- svd(scale(x, center = TRUE, scale = FALSE), nu = 0)
> prcomp(x)$sdev
> sv$d/sqrt(max(1, nrow(x) - 1))
>
> HTH,
>
> --sundar
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jarioksa at sun3.oulu.fi  Wed Aug  3 09:09:07 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Wed, 03 Aug 2005 10:09:07 +0300
Subject: [R] prcomp eigenvalues
In-Reply-To: <20050802190656.32ds8k84ogk48koo@www.email.arizona.edu>
References: <20050802190656.32ds8k84ogk48koo@www.email.arizona.edu>
Message-ID: <1123052947.5385.19.camel@localhost.localdomain>

On Tue, 2005-08-02 at 19:06 -0700, Rebecca Young wrote:
> Hello,
> 
> Can you get eigenvalues in addition to eigevectors using prcomp?  If so how?
> I am unable to use princomp due to small sample sizes.
> Thank you in advance for your help!
> Rebecca Young
> 
Rebecca, 

This answer is similar as some others, but this is simpler.

You have two separate problems: running PCA and getting eigenvalues. The
first is easy to solve: use prcomp instead of princomp (which only
exists for  historic reasons).  Function prcomp can handle cases with
more columns than rows. 

pc <- prcomp(x)

Above I assumed that your data are called x (or you can first make x,
say: x <- rcauchy(200); dim(x) <- c(20,10) -- which puts a funny twist
to comments on variances and standard deviations below).

This saves something that are called 'sdev' or standard deviations, and
you can get values that are (proportional to) eigenvalues simply by
taking their squares:

ev <- pc$sdev^2

These may be good enough for you (they would be good enough for me).
However, if you want to exactly replicate the numbers in some other
piece of software, you may need to multiply these by some constant. If
you don't need this, you may stop reading here.

The eigenvalues above are related to usual 'unbiased' variance so that
the following results are approximately equal:

sum(ev)
sum(apply(x, 2, var))

If you want to get eigenvalues related to biased estimate of variance,
you can do

eb <- (1-1/nrow(x))*ev

Function princomp uses these, as do some other software, but prcomp
works hard and carefully to get the eigenvalues it uses instead of
biased values (that would come naturally and directly in the algorithm
it uses). 

Some programs relate their eigenvalues to the sum of squares, and you
can get these by

es <- (nrow(x) - 1) * ev

Finally, some popular programs in ecology (your affiliation) use
proportional eigenvalues which you can get with:

ev/sum(ev)

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/



From ripley at stats.ox.ac.uk  Wed Aug  3 09:19:33 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 3 Aug 2005 08:19:33 +0100 (BST)
Subject: [R] how to test this
In-Reply-To: <6.2.1.2.0.20050803161641.01dca268@mail.ozemail.com.au>
References: <2BEE99D7F6F1484EBDD1D22167385E7515223B@exqld1-ath.nexus.csiro.au>
	<6.2.1.2.0.20050803161641.01dca268@mail.ozemail.com.au>
Message-ID: <Pine.LNX.4.61.0508030815060.5034@gannet.stats>

On Wed, 3 Aug 2005, Simon Blomberg wrote:

> This is two tests: Whether the slope != 1 and whether the intercept != 0.

Neither model given has an intercept ....

> To do this, include an offset in your model:
>
> fit  <- lm(y ~ x + offset(x), data=dat)

but no intercept, so use

summary(lm(y ~ 0 + x + offset(1.05*x), data=dat))

and look if the coefficient of x is significantly different from zero.

E.g.

x <- 1:10
set.seed(1)
y <- 1.05*x + rnorm(10)
summary(lm(y ~ 0 + x + offset(1.05*x)))

Coefficients:
   Estimate Std. Error t value Pr(>|t|)
x  0.03061    0.03910   0.783    0.454

is not.


>
> HTH,
>
> Simon.
>
>
> At 03:44 PM 3/08/2005, Jin.Li at csiro.au wrote:
>>
>> I am wondering how to test whether a simple linear regression model
>> (e.g. y=1.05x) is significantly different from a 1 to 1 line (i.e. y=x).


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From vito_ricci at yahoo.com  Wed Aug  3 09:21:09 2005
From: vito_ricci at yahoo.com (Vito Ricci)
Date: Wed, 3 Aug 2005 09:21:09 +0200 (CEST)
Subject: [R] regression data set
Message-ID: <20050803072109.92071.qmail@web41206.mail.yahoo.com>

Hi,

I suggest to give a look to:

?Practical Regression and Anova using R? by Julian
Faraway

http://cran.r-project.org/doc/contrib/Faraway-PRA.pdf
http://www.stat.lsa.umich.edu/~faraway/book/

see also package faraway for datasets:

http://cbio.uct.ac.za/CRAN/src/contrib/Descriptions/faraway.html

for some econometric data sets:

http://www.oswego.edu/~kane/econometrics/data.htm

for data sets:

http://lib.stat.cmu.edu/

Regards,

Vito

Clark Allan wrote:

> i would like to give the class a practical
assignment as well. could you
> suggest a good problem and the location of the data
set/s?
> 
> it would be good if the data set has been analysed
by a number of other
> people so that students can see the different ways
of tackling a
> regression problem.

Diventare costruttori di soluzioni
Became solutions' constructors

"The business of the statistician is to catalyze 
the scientific learning process."  
George E. P. Box

"Statistical thinking will one day be as necessary for efficient citizenship as the ability to read and write"
H. G. Wells

Top 10 reasons to become a Statistician

     1. Deviation is considered normal
     2. We feel complete and sufficient
     3. We are 'mean' lovers
     4. Statisticians do it discretely and continuously
     5. We are right 95% of the time
     6. We can legally comment on someone's posterior distribution
     7. We may not be normal, but we are transformable
     8. We never have to say we are certain
     9. We are honestly significantly different
    10. No one wants our jobs


Visitate il portale http://www.modugno.it/
e in particolare la sezione su Palese  http://www.modugno.it/archivio/palesesanto_spirito/



From ripley at stats.ox.ac.uk  Wed Aug  3 09:22:13 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 3 Aug 2005 08:22:13 +0100 (BST)
Subject: [R] Multilevel logistic regression using lmer vs glmmPQL vs.
 gllamm in Stata
In-Reply-To: <42F077C8.25154.B07C1D@localhost>
References: <42F077C8.25154.B07C1D@localhost>
Message-ID: <Pine.LNX.4.61.0508030819500.5034@gannet.stats>

On Wed, 3 Aug 2005, Bernd Weiss wrote:

> I am trying to replicate some multilevel models with binary outcomes
> using R's "lmer" and "glmmPQL" and Stata's gllmm, respectively.

That's not going to happen as they are not using the same criteria.

> The data can be found at <http://www.uni-koeln.de/~ahf34/xerop.dta>.
>
> The relevant Stata output can be found at  <http://www.uni-
> koeln.de/~ahf34/stataoutput.txt>. First, you will find the
> unconditional model, i.e. no level1- or 2-predictor variables. The
> second model contains some level 1-predictor variables
>
> My R file can be found at <http://www.uni-koeln.de/~ahf34/xerop.R>.
>
> Beside the fact that there is a difference between the estimates of
> the intercept (unconditional model: R: -2.76459 and Stata: -2.698923)
> I am especially interested in the level 2 variance.
>
> In Stata the level 2 variance is about 1.03, while in R it is  4.68.
>
> Using glmmPQL from package MASS again gives different results for the
> level 2 variance component. What is meant by "Residual"? I thought
> the level 1 variance is fixed to (pi^2)/3.

Please read the book for which this is support software, as it definitely 
does not say that, and it does explain how such differences can occur.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Aug  3 09:30:28 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 3 Aug 2005 08:30:28 +0100 (BST)
Subject: [R] regexpr and portability issue
In-Reply-To: <BF15A396.3B20%mblanche@uclink.berkeley.edu>
References: <BF15A396.3B20%mblanche@uclink.berkeley.edu>
Message-ID: <Pine.LNX.4.61.0508030808290.5034@gannet.stats>

On Tue, 2 Aug 2005, Marco Blanchette wrote:

> I am still forging my first arms with R and I am fighting with regexpr() as
> well as portability between unix and windoz. I need to extract barcodes from
> filenames (which are located between a double and single underscore) as well
> as the directory where the filename is residing. Here is the solution I came
> to:
>
> aFileName <-
> "/Users/marco/Desktop/diagnosticAnalysis/test/MA__251329410021_S01_A01.txt"
> t <- regexpr("__\\d*_",aFileName, perl=T)
> t.dir <- regexpr("^.*/", aFileName, perl=T)
> base.name <- substr(aFileName, t+2, t-2 + attr(t,"match.length"))
> base.dir <- substr(aFileName, t.dir, attr(t.dir,"match.length"))
>
> My questions are:
> 1) Is there a more elegant way to deal with regular expressions (read here:
> more easier, more like perl style).

Yes, use sub and backreferences.  An example from the R sources doing 
something similar:

             wfile <- sub("/chm/([^/]*)$", "", file)
             thispkg <- sub(".*/([^/]*)/chm/([^/]*)$", "\\1", file)

However, R does have functions basename() and dirname() to do this!

> 2) I have a portability problem when I extract the base.dir Windoz is using
> '\' instead of '/' to separate directories.

That is misinformation: Windows (sic) accepts either / or \ (see the 
rw-FAQ and the R FAQ).  Use chartr("\\", "/", path) to map \ to /.

The `portability problem' appears to be of your own making -- take heart 
that R itself manages to manipulate filepaths portably.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Allan at STATS.uct.ac.za  Wed Aug  3 09:53:24 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Wed, 03 Aug 2005 09:53:24 +0200
Subject: [R] R: histograms and ylim
Message-ID: <42F077F4.2C39D65E@STATS.uct.ac.za>

hi all

a very simple question once again!!!

can we change the "y" range in a histogram?


e.g.
x=rnorm(1000)
hist(x,ylim=0.5,prob=T)	#this does not work


any suggestions???

From francoisromain at free.fr  Wed Aug  3 10:08:31 2005
From: francoisromain at free.fr (Romain Francois)
Date: Wed, 03 Aug 2005 10:08:31 +0200
Subject: [R] R: histograms and ylim
In-Reply-To: <42F077F4.2C39D65E@STATS.uct.ac.za>
References: <42F077F4.2C39D65E@STATS.uct.ac.za>
Message-ID: <42F07B7F.5060401@free.fr>

Le 03.08.2005 09:53, Clark Allan a ??crit :

>hi all
>
>a very simple question once again!!!
>
>can we change the "y" range in a histogram?
>
>
>e.g.
>x=rnorm(1000)
>hist(x,ylim=0.5,prob=T)	#this does not work
>
>
>any suggestions???
>
That does work :

R> hist(x,ylim=c(0,0.5),prob=T) # that does work

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From petr.pikal at precheza.cz  Wed Aug  3 10:08:55 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 03 Aug 2005 10:08:55 +0200
Subject: [R] R: histograms and ylim
In-Reply-To: <42F077F4.2C39D65E@STATS.uct.ac.za>
Message-ID: <42F097B7.19681.88489C@localhost>

Hallo


a very simple answer as well

hist(x,ylim=c(0,0.5),prob=T)   #this does work

Cheers

Petr

from help page:

xlim, ylim: the range of x and y values with sensible defaults. Note
		^^^^^^

          that 'xlim' is _not_ used to define the histogram (breaks),
          but only for plotting (when 'plot = TRUE').



On 3 Aug 2005 at 9:53, Clark Allan wrote:

> hi all
> 
> a very simple question once again!!!
> 
> can we change the "y" range in a histogram?
> 
> 
> e.g.
> x=rnorm(1000)
> hist(x,ylim=0.5,prob=T)	#this does not work
> 
> 
> any suggestions???

Petr Pikal
petr.pikal at precheza.cz



From anders.bjorgesater at bio.uio.no  Wed Aug  3 10:20:32 2005
From: anders.bjorgesater at bio.uio.no (Anders =?iso-8859-1?Q?Bj=F8rges=E6ter?=)
Date: Wed, 03 Aug 2005 10:20:32 +0200
Subject: [R] filtering a dataset, loop,unique duplicate?
Message-ID: <6.2.0.14.2.20050803100703.01de2ac0@pop.uio.no>



From anders.bjorgesater at bio.uio.no  Wed Aug  3 10:40:23 2005
From: anders.bjorgesater at bio.uio.no (Anders =?iso-8859-1?Q?Bj=F8rges=E6ter?=)
Date: Wed, 03 Aug 2005 10:40:23 +0200
Subject: [R] filter data set unique, duplicate..
Message-ID: <6.2.0.14.2.20050803103952.01dac9e8@pop.uio.no>

Hello

First, thanks for the help for an earlier question about error handling!

I have problem filtering a dataset.
I'm trying to filter the data in the y columns based on the values in the x 
column, e.g.:

x          y1        y2                    yn
1.0       1          NA                  3
2.0       1          NA                  11
2.0       2          NA                  NA
3.0       1          5                      16
3.0       7          5                      2
4.0       8          4                      1

and want to keep the highest y if x is identical, like this:

x          y1        y2                    yn
1.0       1          NA                  3
2.0       2          NA                  11
3.0       7          5                      16
4.0       8          4                      1

or just as good:

x          y1        y2                    yn
1.0	   1          NA                  3
2.0       NA*    NA                  NA
2.0       2          NA                  11
3.0       NA*    5                      16
3.0       7          NA*                NA*
4.0       8          4                      1

If any has any suggestions or pointers how to do this I would really 
appreciate it.

/Anders



From dimitris.rizopoulos at med.kuleuven.be  Wed Aug  3 11:21:32 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 3 Aug 2005 11:21:32 +0200
Subject: [R] filter data set unique, duplicate..
References: <6.2.0.14.2.20050803103952.01dac9e8@pop.uio.no>
Message-ID: <003901c5980c$bd1274a0$0540210a@www.domain>

maybe you could consider something like this:

dat <- data.frame(x = c(1, 2, 2, 3, 3, 4),
                  y1 = c(1, 1, 2, 1, 7, 8),
                  y2 = c(NA, NA, NA, 5, 5, 4),
                  y3 = c(3, 11, NA, 16, 2, 1))
#############
out <- as.data.frame(lapply(dat[-1], function(y, x) tapply(y, x, max, 
na.rm = TRUE), x = dat["x"]))
out[out == -Inf] <- NA
out$x <- unique(dat["x"])
out


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Anders Bj??rges??ter" <anders.bjorgesater at bio.uio.no>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, August 03, 2005 10:40 AM
Subject: [R] filter data set unique, duplicate..


> Hello
>
> First, thanks for the help for an earlier question about error 
> handling!
>
> I have problem filtering a dataset.
> I'm trying to filter the data in the y columns based on the values 
> in the x
> column, e.g.:
>
> x          y1        y2                    yn
> 1.0       1          NA                  3
> 2.0       1          NA                  11
> 2.0       2          NA                  NA
> 3.0       1          5                      16
> 3.0       7          5                      2
> 4.0       8          4                      1
>
> and want to keep the highest y if x is identical, like this:
>
> x          y1        y2                    yn
> 1.0       1          NA                  3
> 2.0       2          NA                  11
> 3.0       7          5                      16
> 4.0       8          4                      1
>
> or just as good:
>
> x          y1        y2                    yn
> 1.0    1          NA                  3
> 2.0       NA*    NA                  NA
> 2.0       2          NA                  11
> 3.0       NA*    5                      16
> 3.0       7          NA*                NA*
> 4.0       8          4                      1
>
> If any has any suggestions or pointers how to do this I would really
> appreciate it.
>
> /Anders
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From 0034058 at fudan.edu.cn  Wed Aug  3 12:02:14 2005
From: 0034058 at fudan.edu.cn (ronggui)
Date: Wed, 03 Aug 2005 18:02:14 +0800
Subject: [R] Multilevel logistic regression using lmer vs glmmPQL
 vs.gllamm in Stata
Message-ID: <0IKN007Y34QX8U@mail.fudan.edu.cn>

>On Wed, 3 Aug 2005, Bernd Weiss wrote:
>
>> I am trying to replicate some multilevel models with binary outcomes
>> using R's "lmer" and "glmmPQL" and Stata's gllmm, respectively.
>
>That's not going to happen as they are not using the same criteria.

the glmmPQL and lmer both use the PQL method to do it ,so can we get the same result by setting some options to the command?


>> The data can be found at <http://www.uni-koeln.de/~ahf34/xerop.dta>.
>>
>> The relevant Stata output can be found at  <http://www.uni-
>> koeln.de/~ahf34/stataoutput.txt>. First, you will find the
>> unconditional model, i.e. no level1- or 2-predictor variables. The
>> second model contains some level 1-predictor variables
>>
>> My R file can be found at <http://www.uni-koeln.de/~ahf34/xerop.R>.
>>
>> Beside the fact that there is a difference between the estimates of
>> the intercept (unconditional model: R: -2.76459 and Stata: -2.698923)
>> I am especially interested in the level 2 variance.
>>
>> In Stata the level 2 variance is about 1.03, while in R it is  4.68.
>>
>> Using glmmPQL from package MASS again gives different results for the
>> level 2 variance component. What is meant by "Residual"? I thought
>> the level 1 variance is fixed to (pi^2)/3.
>
>Please read the book for which this is support software, as it definitely 
>does not say that, and it does explain how such differences can occur.
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-08-03

------
Deparment of Sociology
Fudan University

Blog:http://sociology.yculblog.com



From ramasamy at cancer.org.uk  Wed Aug  3 12:13:29 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 03 Aug 2005 11:13:29 +0100
Subject: [R] question on graphs and finding area under a curve
In-Reply-To: <OWA-1pA0hZaPHrKwT7N0002bcc2@owa-1.sph.ad.jhsph.edu>
References: <OWA-1pA0hZaPHrKwT7N0002bcc2@owa-1.sph.ad.jhsph.edu>
Message-ID: <1123064009.6002.4.camel@ipc143004.lif.icnet.uk>

Also see function rocdemo.sca in the ROC package.

The area under the 45 degree line in an ROC curve has an area of 0.5.

Regards, Adai



On Tue, 2005-08-02 at 09:24 -0400, Ravi Varadhan wrote:
> Hi,
> 
> To find the area lying between the curve y = y(x) and 45 degree line (which,
> assuming it goes through the origin, is y = x), you can use the following
> function based on trapezoidal rule:
> 
> trap.rule <- function(x,f) {sum(diff(x)*(f[-1]+f[-length(f)]))/2}
> 
> trap.rule(x,f=y-x)
> 
> This area will be negative if y(x) is below the 45 degree line.
> 
> However, your question is not complete, I think.  You need to specify the
> interval of integration. For this you may need to determine the points of
> intersection of the two curves, which involves the solution of a fixed point
> problem.
> 
> Hope this helps,
> Ravi.
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-
> > bounces at stat.math.ethz.ch] On Behalf Of Renuka Sane
> > Sent: Tuesday, August 02, 2005 8:51 AM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] question on graphs and finding area under a curve
> > 
> > Question on graphs:
> > 
> > The default case for drawing a graph in R, is where a little space is left
> > on the x and y axis before the first tick i.e. even if I say xlim=c(0,1) -
> > -
> > there will be some space between the edge of the x-axis and where 0 is
> > placed. If I want 0 on the edge, how do I do it in R?
> > 
> > Area under the curve:
> > 
> > I have a 45 degree line and a curve above or below it. Is there a way in R
> > to find the area between the two?
> > 
> > Thanks,
> > Renuka
> > 
> > --
> > Renuka Sane
> > http://www.nyx.net/~rsane
> > 
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-
> > guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ramasamy at cancer.org.uk  Wed Aug  3 12:45:52 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 03 Aug 2005 11:45:52 +0100
Subject: [R] Loop problem
In-Reply-To: <2411.128.240.6.80.1123011383.squirrel@128.240.6.80>
References: <2411.128.240.6.80.1123011383.squirrel@128.240.6.80>
Message-ID: <1123065953.6002.29.camel@ipc143004.lif.icnet.uk>

1) You need to simplify your codes a bit and show people how the input
might look like if you want useful responses. Perhaps a small
reproducible example or brief description of what you are trying to do
might help. See the posting guide for more details.


2) I am guessing here but are you interested in multinomial logistic
regression ? If so, searching the R-help suggests glm with
family="binomial", multinom in nnet package and
http://www.stat.auckland.ac.nz/~yee/VGAM/ . Remember that you may need
'Tr' to be a factor.


3) You should avoid writing functions that depend on global variables as
they may change. If you really need your MLE function, here is an
(untested) way to rewrite it such that it requires explicit inputs. 

  my.MLE <- function (x, mu, v){

    n <- length( x )
    tmp <- n*log(2*pi) + n*log(v) + sum( ( x - mu )^2 ) / v
    return( 0.5*tmp )

  }

and you call it with

   my.MLE( x=logitTr1$logitp, mu=p, v=logitTr1$sd^2 )


Regards, Adai



On Tue, 2005-08-02 at 20:36 +0100, Hathaikan Chootrakool wrote:
> Dear everyone
> 
>      I am a new user,would like to combine these code together by using a
> loop,each function has three value as Tr = 1 - 3,how can i combine
> together?
> 
> 
> logitTr1 <-logit[logit[,"Study"]&logit[,"Tr"]==1,]
> (number of row in each group (1-3) is difference but equal in colume)
> 
> fnTr1 <- function (p) sum(
> n/2*log(2*pi)+log(1/logitTr1$sd)+1/2*(logitTr1$logitp*logitTr1$logitp-2*logitTr1$logitp*p+p^2)
>                     *1/logitTr1$sd*logitTr1$sd )
> (maximum likelyhood function)
> 
> outTr1<- nlm (fnTr1,p=c(10),hessian=TRUE)
> minimumTr1 <- outTr1$minimum
> valueTr1 <- outTr1$estimate
> (estimate the value)
> 
> The problem is the program couldn't work by using logitTr[i],fnTr[i]
> outTr[i],minimumTr[i],value[i] in a loop. The function logitTr[i] is the
> data matrix which is not equal each group, fnTr[i] is the
> maximumlikelyhood function for estimation in next step;
> outTr[i],minimumTr[i],valueTr[i].
> 
> 
> 
> Has anyone got any idea to help me?,thank you very much.
> 
> Hathaikan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ramasamy at cancer.org.uk  Wed Aug  3 13:03:11 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Wed, 03 Aug 2005 12:03:11 +0100
Subject: [R] breaking command in command line in R for Mac Aqua
In-Reply-To: <20050802203409.21315.qmail@web50904.mail.yahoo.com>
References: <20050802203409.21315.qmail@web50904.mail.yahoo.com>
Message-ID: <1123066992.6002.42.camel@ipc143004.lif.icnet.uk>

Why not use an editor ? 

I would highly recommend Emacs in combination with Emacs Speaks
Statistics (ESS). Section 2.1 of [1] might help with the installation.

Otherwise you can try JGR [2] or others [3]. There is a R special
interest group for MAC users [4] that you can try.

[1] http://www.xemacs.org/Documentation/packages/html/ess_2.html
[2] http://stats.math.uni-augsburg.de/JGR/index.shtml
[3] http://www.sciviews.org/_rgui/projects/Editors.html
[4] https://stat.ethz.ch/mailman/listinfo/r-sig-mac

Regards, Adai



On Tue, 2005-08-02 at 13:34 -0700, Michael Sohn wrote:
> I'm using R for Mac Aqua version 2.1.1
> 
> If at the command line, I type:
> ls(
> and then a return, the command line prompt changes to
> a plus sign indicating that the command has not been
> completed.  How do I break, or kill, the partial
> command?  Sometimes, I type a long command but miss a
> bracket or parenthesis.  On a unix or linux version of
> R, I can type ctrl-c.  On the Mac, ctrl-c,
> command-(dot), and escape do not work.
> 
> Any solutions?
> Mike
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Wed Aug  3 13:41:19 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 Aug 2005 13:41:19 +0200
Subject: [R] breaking command in command line in R for Mac Aqua
In-Reply-To: <1123066992.6002.42.camel@ipc143004.lif.icnet.uk>
References: <20050802203409.21315.qmail@web50904.mail.yahoo.com>
	<1123066992.6002.42.camel@ipc143004.lif.icnet.uk>
Message-ID: <x2acjzp7s0.fsf@turmalin.kubism.ku.dk>

Adaikalavan Ramasamy <ramasamy at cancer.org.uk> writes:

> Why not use an editor ? 
> 
> I would highly recommend Emacs in combination with Emacs Speaks
> Statistics (ESS). Section 2.1 of [1] might help with the installation.
> 
> Otherwise you can try JGR [2] or others [3]. There is a R special
> interest group for MAC users [4] that you can try.
> 
> [1] http://www.xemacs.org/Documentation/packages/html/ess_2.html
> [2] http://stats.math.uni-augsburg.de/JGR/index.shtml
> [3] http://www.sciviews.org/_rgui/projects/Editors.html
> [4] https://stat.ethz.ch/mailman/listinfo/r-sig-mac
> 
> Regards, Adai

Neither of those prevent you from sending incomplete lines do they?

In a tight spot, you can alway just generate a syntax error. The thing
is that you will typically have forgotten how to do that reliably.
Entering 

 $$ 

or 

 a b

is a good guess. The main exception is that you could be in the middle
of a text string, in which case you need a terminating quote first.

        -p

> On Tue, 2005-08-02 at 13:34 -0700, Michael Sohn wrote:
> > I'm using R for Mac Aqua version 2.1.1
> > 
> > If at the command line, I type:
> > ls(
> > and then a return, the command line prompt changes to
> > a plus sign indicating that the command has not been
> > completed.  How do I break, or kill, the partial
> > command?  Sometimes, I type a long command but miss a
> > bracket or parenthesis.  On a unix or linux version of
> > R, I can type ctrl-c.  On the Mac, ctrl-c,
> > command-(dot), and escape do not work.
> > 
> > Any solutions?
> > Mike


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From rpeng at jhsph.edu  Wed Aug  3 13:52:27 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 03 Aug 2005 07:52:27 -0400
Subject: [R] hash code for arbitrary object
In-Reply-To: <17136.17046.279126.350254@maths.uwa.edu.au>
References: <17136.17046.279126.350254@maths.uwa.edu.au>
Message-ID: <42F0AFFB.3060003@jhsph.edu>

You can compute MD5 and SHA1 digests with the 'digest' package.

-roger

Adrian Baddeley wrote:
> Can anyone suggest a simple way to calculate a 'hash code'
> from an arbitrary R object?
> 
> hash(x) should return an integer or string 
> with the property that 
>      if hash(x) != hash(y) then x and y are not identical
> and the time to compute hash(x) should be quite short.
> 
> Any suggestions welcome
> thanks
> Adrian Baddeley
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From msvika at mscc.huji.ac.il  Wed Aug  3 15:53:59 2005
From: msvika at mscc.huji.ac.il (Vicky Landsman)
Date: Wed, 3 Aug 2005 15:53:59 +0200
Subject: [R] Converting a list from R to Stata
Message-ID: <003001c59832$cc5868e0$a200a8c0@HOME2>


Dear all,
I have a list containing 150 simulated datasets in R. Is there a way to 
convert it to the Stata format such that I will be able to apply some Stata 
functions on each dataset in the list?
Thank you in advance,
Vicky Landsman.



From Kechi.Nzerem at rms.com  Wed Aug  3 15:12:03 2005
From: Kechi.Nzerem at rms.com (Kechi Nzerem)
Date: Wed, 3 Aug 2005 14:12:03 +0100
Subject: [R] glmmPQL error in logLik.reStruct
Message-ID: <D71DD12EF4EDE740A09A929F6D2C509920AFBB@mailuk1.rms.com>

Dear R users,

I'm attempting to fit a GLM with random effects using the tweedie family
for the error structure.  I'm getting the error:

iteration 1 
Error in logLik.reStruct(object, conLin) : 
        NA/NaN/Inf in foreign function call (arg 3)

I'm running V2.1.0
I notice from searching the lists that the same error was reported in
May 2004 by Spencer Graves, but no-one was able to offer any
suggestions.  Running the sample code that he provided also still
produces the same error:

set.seed(8) 
N. <- 1000 
z <- rnorm(N.) 
pr.good <- exp(-1e-4*exp(2+2*z)) 
quantile(pr.good) 
DF. <- data.frame(yield=rbinom(N., N., pr.good)/N., 
       Offset=rep(-10, N.), nest=1:N.) 
fit <- glmmPQL(fixed=1-yield~offset(Offset), random=~1|nest, 
       family=binomial(link="cloglog"), 
       data=DF., weights=rep(N., N.)) 

A year on can anyone suggest what the problem might be?  Or in
particular, Spencer - did you come up with a solution?

Thanks in advance, 

Kechi Nzerem



From gratified at hadden.com  Wed Aug  3 15:15:26 2005
From: gratified at hadden.com (Kathleen)
Date: Wed, 3 Aug 2005 16:15:26 +0300
Subject: [R] Will Shares of This Company be Moving Higher?
Message-ID: <506911325.6015081451@212.174.123.56>

Investment Times Alert Issues: (STRONG BUY)
 
We Told last week at 1.20 to WATCH and now its $2.35 and 
we think it goes to $4.00 on expected news this week...
 
Harbin Pingchuan Pharmaceutical: (PGCN)
Current Price: $2.35
Shares Outstanding: 20 Million
Market Capitalization: $6 Million
Short Term Target: $5.75
12month Target: $10.00 (!!!)
 
***We told you there was going to be a BIG move on THURSDAY, FRIDAY, MONDAY, AND TUESDAY 
and we think WEDNESDAY COULD BE HUGH !!!!!!

NEWS RELEASE:
PGCN MAKES HUGH MOVE, UP A AMAZING  $1.15 - IN 5 DAYS OF TRADING !!! 

***WE URGE YOU TO PUT PGCN ON YOUR RADAR FOR WEDNESDAY AUGUST 3, 2005***
 
HARBIN, China, July  /Xinhua-PRNewswire-FirstCall/ -- 
Harbin Pingchuan Pharmaceutical Holding Co. Ltd. 
(OTC Bulletin Board: PGCN - News; "PINGCHUAN") announced today that PINGCHUAN 
signed a Purchase Agreement with the Guangdong Medicine Group Co. Ltd. ("GDMG").
Under the terms of the agreement, PINGCHUAN will authorize GDMG as its franchisee 
in five southern provinces of China. With respect to the authorization, GDMG intends 
to purchase approximately US$2.00million worth of PINGCHUAN's pharmaceutical products 
in 2005. By cooperating with GDMG, PINGCHUAN will greatly enhance the marketing network 
and sales channels in Southern China.
 
"We are delighted to reach this agreement with the leading medical enterprise 
in Southern China. This purchase agreement not only increases our sales revenue 
in these five provinces, but also substantially improves our brand awareness 
in Southern China. While maintaining the existing marketing network, we are developing 
and setting up new marketing network and sales channel actively." Said Hu ZhanWu, 
Chairman and President of Pingchuan Pharmaceutical Co. Ltd., "One of our marketing 
strategies is to establish a connection with medical enterprises such as 
Guangdong Medicine Group, for the promotion of our products into their commercial networks 
throughout the entire country."



****REASON TO WATCH PGCN****
Make no mistake: Our mission at SmallCap-Investors is to claw our way through the 
thousands of underperforming companies out there to find the golden needle in the 
haystack the micro-cap DIAMOND that can make you rich. More often than not, the stocks 
we profile show a significant increase in stock price and sometimes in days, 
not months or years.
 
Do this often enough, and your portfolio can double, even TRIPLE in value.
 









 

Disclaimer:
Information within this email contains "forwardlooking statements" within
the meaning of Section 27Aof the Securities Act of 1933 and Section 21B of
the Securities Exchange Act of 1934. Any statements that express or involve
discussions with respect to predictions, expectations, beliefs,
plans, projections, objectives, goals, assumptions or future events or
performance are not statements of historical fact and may be "forward
looking statements". "Forward looking statements" are based on
expectations, estimates and projections at the time the statements are made
that involve a number of risks and uncertainties which could cause actual
results or events to differ materially from those presently anticipated.
Forward looking statements in this action may be identified through the use
of words such as "projects", "foresee", "expects", "will", "anticipates",
"estimates", "believes", "understands" or that by statements indicating
certain actions "may", "could", or "might" occur. Risk factors include
general economic and business conditions, the ability to acquire and develop
specific projects, the ability to fund operations and changes in consumer
and business consumption habits and other factors overwhich the company has
little or no control. The publisher of this newsletter does not represent
that the information contained in this message states all material facts or
does not omit a material fact necessary to make the statements therein not
misleading. All information provided within this email pertaining to
investing, ST0CKs, securities must be understood as information provided and
not investment advice. The publisher of this newsletter advises all readers
and subscribers to seek advice from a registered professional securities
representative before deciding to trade in ST0CKs featured within this
email. None of the material within this report shall be construed as any
kind of investment advice or solicitation. Many of these companies are on
the verge of bankruptcy. You can lose all your money by investing in this
ST0CK. We urge you to read the company's SEC filings now, before you invest.
The publisher of this newsletter is not a registered invstment advisor.
Subscribers should not view information herein as legal, tax, accounting or
investment advice. In compliance with the SecuritiesAct of 1933, Section
17(b), The publisher of this newsletter is contracted to receive six hundred
thousand free trading shares from a third party, not an officer, director or
affiliate shareholder for the circulation of this report. Be aware of an
inherent conflict of interest resulting from such compensation due to the
fact that this is a paid advertisement and is not without bias. The party
that paid us has a position in the ST0CK they will sell at anytime without
notice. This could have a negative impact on the price of the ST0CK, causing
you to lose money. All factual information in this report was gathered from
public sources, including but not limited to SEC filings, Company Websites
and Company Press Releases. The publisher of this newsletter believes this
information to be reliable but can make no guarantee as to its accuracy or
completeness. Use of the material within this email constitutes your
acceptance of these terms.



From GBLEVINS at marketsolutionsgroup.com  Wed Aug  3 16:09:31 2005
From: GBLEVINS at marketsolutionsgroup.com (Greg Blevins)
Date: Wed, 03 Aug 2005 09:09:31 -0500
Subject: [R] Seeking help with a loop
Message-ID: <s2f089e2.023@mail.marketsolutionsgroup.com>

Hello R Helpers,

After spending considerable time attempting to write a loop (and searching the help archives) I have decided to post my problem.  

In a dataframe I have columns labeled:

q33a q33b q33c...q33r    q35a q35b q35c...q35r

What I want to do is create new variables based on the following logic:
newfielda <- ifelse(q35a==1, q33a, NA)
newfieldb <- ifelse(q35b==1, q33b, NA)
...
newfieldr

What I did was create two new dataframes, one containing q33a-r the other q35a-r and tried to loop over both, but I could not get any of the loop syntax I tried to give me the result I was seeking.

Any help would be much appreciated.

Greg Blevins
Partner
The Market Solutions Group, Inc.
Minneapolis, MN

Windows XP, R 2.1.1



From jabezwuk at yahoo.co.uk  Wed Aug  3 16:23:57 2005
From: jabezwuk at yahoo.co.uk (Jabez Wilson)
Date: Wed, 3 Aug 2005 15:23:57 +0100 (BST)
Subject: [R] abline and linearity over groups
Message-ID: <20050803142357.86383.qmail@web25406.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050803/8c141ab2/attachment.pl

From jochen.einbeck at nuigalway.ie  Wed Aug  3 16:33:14 2005
From: jochen.einbeck at nuigalway.ie (Jochen Einbeck)
Date: Wed, 03 Aug 2005 15:33:14 +0100
Subject: [R] Read from data frame, and not from global environment
References: <42EF51AD.3060800@nuigalway.ie>
	<Pine.LNX.4.61.0508021217570.31221@gannet.stats>
Message-ID: <42F0D5AA.60805@nuigalway.ie>

Thanks. It is now working as I wanted, if I use (simplified)

test<-function(formula, data, w){
  wname <- deparse(substitute(w))
  w <- if(wname %in% names(data)) data[[wname]] else get(wname, .GlobalEnv)
  data$w<-w
  glm1<-glm(formula=formula,data=data, weights=w)
  .....
}


What I was looking for in  2) was a more elegant way  (than setting 
data$w<-w)  to make  w  available to the glm function.



Prof Brian Ripley wrote:

> I don't think that is the best way to do what I guess you intended. 
> Try something like
> 
> test <- function(formula,  data , weights)
> {
>     Call <- match.call()
>     Call[[1]] <- as.name("glm")
>     Call$family <- quote(poisson)
>     glm1 <- eval.parent(Call)
>     ....
> }
> 
> which is probably giving the scoping that you want.
> 
> You could do what you ask for at 1) by something like
> 
>     wname <- deparse(substitute(w))
>     w <- if(wname %in% names(data)) data[[wname]] else get(wname, 
> .GlobalEnv)
> 
> and for 2) by replacing .GlobalEnv by an expression constructed by 
> calls to environment() (I don't know exactly what you intended here).
> 
> On Tue, 2 Aug 2005, Jochen Einbeck wrote:
> 
>> Dear members,
>> 
>> assume given  a function of type
>> 
>> test<-function(formula,  data , w){
>>  ......
>>  glm1<-glm(formula,  family=poisson, data=data, weights=w)
>>  ......
>> }
>> 
>> and a simple example data frame as
>> 
>> test.frame<-data.frame(x=1:10,y=(1:10)*2,a=(1:10)^3).
>> 
>> Let us now execute
>> 
>> test(y ~ x, test.frame, a )
>> 
>> My question is: What do I have to insert at the first occurance of .....
>> in the test function to ensure that
>> 
>> 1) 'a'  is read from the data frame (and is only read from the global
>> environment if  and only if  'a' is not found in the data frame)
>> 2) glm finds w in in the local environment of the function 'test'
> 
> 
> That contradicts 1)!
> 
>> The question is obviously related to  Fernando's problem with
>> 'Defining a "local" function'  some months ago, though the discussion
>> there does not solve the questions above.
> 
>



From 0034058 at fudan.edu.cn  Wed Aug  3 16:39:34 2005
From: 0034058 at fudan.edu.cn (ronggui)
Date: Wed, 03 Aug 2005 22:39:34 +0800
Subject: [R] abline and linearity over groups
Message-ID: <0IKN006LWHL4YK@mail.fudan.edu.cn>

>?abline
 and you can see
...
'reg' is a regression object which contains 'reg$coef'.  If it is
     of length 1 then the value is taken to be the slope of a line
     through the origin, otherwise, the first 2 values are taken to be
     the intercept and slope.
...

and
> plot(test$l~test$t)
> abline(lm(test$l~test$t))
> (lm(test$l~test$t))

Call:
lm(formula = test$l ~ test$t)

Coefficients:
(Intercept)       test$t  
     0.4432     104.1688  

> test$tF=factor(test$t)
> plot(test$l~test$tF)
> abline(lm(test$l~test$tF))
> (lm(test$l~test$tF))

Call:
lm(formula = test$l ~ test$tF)

Coefficients:
(Intercept)     test$tF1     test$tF2  
    -0.8776     108.1313     208.3376  

when test$tF is factor,these are 3 coef and the first two are used to drow the line,with  Intercept =   -0.8776 and slope= 108.1313   ,and     abline(lm(test$l~test$tF)) is abline(-0.8776,108.1313)


======= 2005-08-03 22:23:57 ÄúÔÚÀ´ÐÅÖÐÐ´µÀ£º=======

>
>
>Dear R users, please can you help me understand the behaviour of abline using function lm.
>
>I'm trying to learn linearity over groups. So I make three groups with 10 values each:
>
>test=data.frame(cbind(
>l=c(rnorm(10,0,30),rnorm(10,100,30),rnorm(10,200,30)),
>t = c(rep(0,10), rep(1,10), rep(2,10))
>))
>
>when I do: 
>
>plot(test$l~test$t)
>abline(lm(test$l~test$t))
>
>
>the abline is a straight line through the centre of the points of each of the groups.
>
>If, however, I factorise the groups (in order to do e.g. anova analysis) and then plot the data
>
>test$tF=factor(test$t)
>plot(test$l~test$tF)
>abline(lm(test$l~test$tF))
>
>
>the abline is now shifted up and to the left of where I would expect the line to go (through the centre of the points of each of the groups).
>
>If there is a simple explanation, could someone tell me it?
>
> 
>
>		
>---------------------------------
>To help you stay safe and secure online, we've developed the all new Yahoo! Security Centre.
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

= = = = = = = = = = = = = = = = = = = =
			


 

2005-08-03

------
Deparment of Sociology
Fudan University

Blog:http://sociology.yculblog.com



From lami at faunalia.it  Wed Aug  3 16:49:35 2005
From: lami at faunalia.it (Leonardo Lami)
Date: Wed, 3 Aug 2005 16:49:35 +0200
Subject: [R] lda function
Message-ID: <200508031649.35392.lami@faunalia.it>

Hello,
I'm tring to make a linear discriminant analysis eith lda (MASS).
In the value of the resulting object is there information about the value of 
the centroids of the discriminated group for the discriminant functions?

Thank you in advance for your help!
Leonardo
-- 
Leonardo Lami
lami at faunalia.it            www.faunalia.it
Via Colombo 3 - 51010 Massa e Cozzile (PT), Italy   Tel: (+39)349-1310164
GPG key @: hkp://wwwkeys.pgp.net http://www.pgp.net/wwwkeys.html
https://www.biglumber.com



From Kechi.Nzerem at rms.com  Wed Aug  3 17:00:50 2005
From: Kechi.Nzerem at rms.com (Kechi Nzerem)
Date: Wed, 3 Aug 2005 16:00:50 +0100
Subject: [R] glmmPQL error in logLik.reStruct
Message-ID: <D71DD12EF4EDE740A09A929F6D2C509920AFDD@mailuk1.rms.com>

Dear all,

As an update to my previous post, for anyone who is interested: Someone
has kindly told me that this error does not occur in the 2.2 pre-release
version.  I've run my particular model with my data and this problem is
solved in the 2.2 pre-release.

Cheers,

Kechi Nzerem

>-----Original Message-----
>From: Kechi Nzerem
>Sent: 03 August 2005 14:12
>To: 'r-help at lists.R-project.org'
>Subject: glmmPQL error in logLik.reStruct
>
>Dear R users,
>
>I'm attempting to fit a GLM with random effects using the tweedie
family
>for the error structure.  I'm getting the error:
>
>iteration 1
>Error in logLik.reStruct(object, conLin) :
>        NA/NaN/Inf in foreign function call (arg 3)
>
>I'm running V2.1.0
>I notice from searching the lists that the same error was reported in
May
>2004 by Spencer Graves, but no-one was able to offer any suggestions.
>Running the sample code that he provided also still produces the same
>error:
>
>set.seed(8)
>N. <- 1000
>z <- rnorm(N.)
>pr.good <- exp(-1e-4*exp(2+2*z))
>quantile(pr.good)
>DF. <- data.frame(yield=rbinom(N., N., pr.good)/N.,
>       Offset=rep(-10, N.), nest=1:N.)
>fit <- glmmPQL(fixed=1-yield~offset(Offset), random=~1|nest,
>       family=binomial(link="cloglog"),
>       data=DF., weights=rep(N., N.))
>
>A year on can anyone suggest what the problem might be?  Or in
particular,
>Spencer - did you come up with a solution?
>
>Thanks in advance,
>
>Kechi Nzerem



From ciblab1 at usu.edu  Wed Aug  3 17:02:20 2005
From: ciblab1 at usu.edu (Jake Michaelson)
Date: Wed, 03 Aug 2005 09:02:20 -0600
Subject: [R] make error: X11/Intrinsic.h: No such,,,
Message-ID: <1123081340.2221.4.camel@localhost.localdomain>

Hi all,

I'm trying to build R 2.1.1 on Ubuntu 5.04 i686-SMP. Configure goes well
with:

./configure --with-BLAS --with-readline=no 

but once I run 'make', I get the following error:

In file included from devX11.c:64:
devX11.h:57:74: X11/Intrinsic.h: No such file or directory


Any ideas?

Thanks in advance,

Jake



From jjmichael at comcast.net  Wed Aug  3 17:04:58 2005
From: jjmichael at comcast.net (Jake Michaelson)
Date: Wed, 03 Aug 2005 09:04:58 -0600
Subject: [R] make error: X11/Intrinsic.h: No such,,,
Message-ID: <1123081498.11958.0.camel@localhost.localdomain>

Hi all,

I'm trying to build R 2.1.1 on Ubuntu 5.04 i686-SMP. Configure goes well
with:

./configure --with-BLAS --with-readline=no 

but once I run 'make', I get the following error:

In file included from devX11.c:64:
devX11.h:57:74: X11/Intrinsic.h: No such file or directory


Any ideas?

Thanks in advance,

Jake



From spencer.graves at pdf.com  Wed Aug  3 17:20:53 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 03 Aug 2005 08:20:53 -0700
Subject: [R] breaking command in command line in R for Mac Aqua
In-Reply-To: <x2acjzp7s0.fsf@turmalin.kubism.ku.dk>
References: <20050802203409.21315.qmail@web50904.mail.yahoo.com>	<1123066992.6002.42.camel@ipc143004.lif.icnet.uk>
	<x2acjzp7s0.fsf@turmalin.kubism.ku.dk>
Message-ID: <42F0E0D5.3000008@pdf.com>

	  My favorite syntax error for such situations is "[}", but as Peter 
said, that won't work if you are in the middle of a quote.  Then one 
might try '"[}'.  If that failed, "'[}" should work.

	  Thanks, Peter.  	
	  spencer graves

Peter Dalgaard wrote:

> Adaikalavan Ramasamy <ramasamy at cancer.org.uk> writes:
> 
> 
>>Why not use an editor ? 
>>
>>I would highly recommend Emacs in combination with Emacs Speaks
>>Statistics (ESS). Section 2.1 of [1] might help with the installation.
>>
>>Otherwise you can try JGR [2] or others [3]. There is a R special
>>interest group for MAC users [4] that you can try.
>>
>>[1] http://www.xemacs.org/Documentation/packages/html/ess_2.html
>>[2] http://stats.math.uni-augsburg.de/JGR/index.shtml
>>[3] http://www.sciviews.org/_rgui/projects/Editors.html
>>[4] https://stat.ethz.ch/mailman/listinfo/r-sig-mac
>>
>>Regards, Adai
> 
> 
> Neither of those prevent you from sending incomplete lines do they?
> 
> In a tight spot, you can alway just generate a syntax error. The thing
> is that you will typically have forgotten how to do that reliably.
> Entering 
> 
>  $$ 
> 
> or 
> 
>  a b
> 
> is a good guess. The main exception is that you could be in the middle
> of a text string, in which case you need a terminating quote first.
> 
>         -p
> 
> 
>>On Tue, 2005-08-02 at 13:34 -0700, Michael Sohn wrote:
>>
>>>I'm using R for Mac Aqua version 2.1.1
>>>
>>>If at the command line, I type:
>>>ls(
>>>and then a return, the command line prompt changes to
>>>a plus sign indicating that the command has not been
>>>completed.  How do I break, or kill, the partial
>>>command?  Sometimes, I type a long command but miss a
>>>bracket or parenthesis.  On a unix or linux version of
>>>R, I can type ctrl-c.  On the Mac, ctrl-c,
>>>command-(dot), and escape do not work.
>>>
>>>Any solutions?
>>>Mike
> 
> 
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From jabezwuk at yahoo.co.uk  Wed Aug  3 17:33:30 2005
From: jabezwuk at yahoo.co.uk (Jabez Wilson)
Date: Wed, 3 Aug 2005 16:33:30 +0100 (BST)
Subject: [R] abline and linearity over groups
In-Reply-To: <0IKN006LWHL4YK@mail.fudan.edu.cn>
Message-ID: <20050803153330.3828.qmail@web25405.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050803/ef99049d/attachment.pl

From tlumley at u.washington.edu  Wed Aug  3 17:38:44 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 3 Aug 2005 08:38:44 -0700 (PDT)
Subject: [R] Converting a list from R to Stata
In-Reply-To: <003001c59832$cc5868e0$a200a8c0@HOME2>
References: <003001c59832$cc5868e0$a200a8c0@HOME2>
Message-ID: <Pine.A41.4.61b.0508030836221.210186@homer09.u.washington.edu>

On Wed, 3 Aug 2005, Vicky Landsman wrote:

>
> Dear all,
> I have a list containing 150 simulated datasets in R. Is there a way to
> convert it to the Stata format such that I will be able to apply some Stata
> functions on each dataset in the list?

For Stata your best best is probably to stack all 150 datasets into one 
long data frame and add an id variable, so you can then -by id:- your 
analysis.
   big.data.frame <- do.call("rbind", the.list.of.datasets)
will stack them for you and
   big.data.frame$id <- rep(1:150, sapply(the.list.of.data.sets, nrow))
will make the id variable.

 	-thomas



From tplate at acm.org  Wed Aug  3 18:00:52 2005
From: tplate at acm.org (Tony Plate)
Date: Wed, 03 Aug 2005 10:00:52 -0600
Subject: [R] Seeking help with a loop
In-Reply-To: <s2f089e2.023@mail.marketsolutionsgroup.com>
References: <s2f089e2.023@mail.marketsolutionsgroup.com>
Message-ID: <42F0EA34.2020602@acm.org>

 > x <- data.frame(q33a=3:4,q33b=5:6,q35a=1:2,q35b=2:1)
 > y <- list()
 > for (i in grep("q33", colnames(x), value=TRUE))
+    y[[sub("q33","",i)]] <- ifelse(x[[sub("q33","q35",i)]]==1, x[[i]], NA)
 > as.data.frame(y)
    a  b
1  3 NA
2 NA  6
 > # if you really want to create new variables rather
 > # than have them in a data frame:
 > # (use paste() or sub() to modify the names if you
 > #  want something like "newfielda")
 > for (i in names(y)) assign(i, y[[i]])
 > a
[1]  3 NA
 > b
[1] NA  6
 >

hope this helps,

Tony Plate

Greg Blevins wrote:
> Hello R Helpers,
> 
> After spending considerable time attempting to write a loop (and searching the help archives) I have decided to post my problem.  
> 
> In a dataframe I have columns labeled:
> 
> q33a q33b q33c...q33r    q35a q35b q35c...q35r
> 
> What I want to do is create new variables based on the following logic:
> newfielda <- ifelse(q35a==1, q33a, NA)
> newfieldb <- ifelse(q35b==1, q33b, NA)
> ...
> newfieldr
> 
> What I did was create two new dataframes, one containing q33a-r the other q35a-r and tried to loop over both, but I could not get any of the loop syntax I tried to give me the result I was seeking.
> 
> Any help would be much appreciated.
> 
> Greg Blevins
> Partner
> The Market Solutions Group, Inc.
> Minneapolis, MN
> 
> Windows XP, R 2.1.1
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From phgrosjean at sciviews.org  Wed Aug  3 18:01:15 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed, 03 Aug 2005 18:01:15 +0200
Subject: [R] Trouble with SciViews-R 0.7-3, SciViews R 0.8-7,
 and Tinn-R 1.16.1.5
In-Reply-To: <1123029734.42f012e61d024@webmail.stanford.edu>
References: <1123029734.42f012e61d024@webmail.stanford.edu>
Message-ID: <42F0EA4B.3070107@sciviews.org>

Hello Bing Ho,

This is a shame to me: I have not fixed yet all incompatiblities between 
R 2.1.X, Rcmdr 1.X and SciViews-R. I know all these bugs and I am 
working on them. I just add today to the 
http://www.sciviews.org/SciViews-R page that the current version of 
SciViews-R is only compatible with R 2.0.X and with Rcmdr 0.9-X to avoid 
further confusion.

Concerning the broken call-tip functionnality in Tinn-R with SciViews 
0.8-7, it is by purpose. The call-tip server is not started by default 
anymore, starting from version 0.8-7 (on CRAN, I currently leave version 
0.8-6). This is for better compatibility with Rpad that I made this 
change. For version 0.8-7, the way to start the DDE server is explained 
in the man pade of guiDDEInstall(). Before version 0.8-7, you started 
the call-tip server automatically at the loading of the package, thus with:
 > library(svIDE)

Starting from version 0.8-7, you can do either:
 > option(use.DEE = TRUE) # Force starting the DDE server when svIDE loads
 > library(svIDE)

or:
 > library(svIDE)
 > guiDDEInstall() # Start the server manually

Best,

Philippe

..............................................<??}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
( ( ( ( (
  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
  ) ) ) ) )
( ( ( ( (    web:   http://www.umh.ac.be/~econum
  ) ) ) ) )          http://www.sciviews.org
( ( ( ( (
..............................................................

Bing Ho wrote:
> Hello everybody,
> 
> I am new to using Windows and R, and have been experimenting with various
> packages.
> 
> I recently installed R 2.1.1 under Windows XP SP2, and tried installing the
> latest versions of SciViews (0.7-6, and R package 0.8-7 found on the
> sciviews.org website), and also Tinn-R 1.16.1.5 stable. I have also been
> experimenting with R Commander 0.9-14 stable, 1.0-2 stable, and also tried
> 1.1 unstable (along with dependent packages).
> 
> Oddly, although the installer for SciViews says version 0.7-3, the About
> dialog box says 0.7.6. I am not certain which is the correct version.
> 
> I have confirmed incompatibility with the latest stable and unstable R
> Commander and SciViews (recently noted by Grosjean in R-help). R Commander
> 0.9-14 does work with SciViews 0.7.6 (.3?), but also produces the
> previously reported error that R Commander is not installed (answering "No"
> to installing, will allow the correct dialog box to open).
> 
> I have noticed the following additional two behaviours which have
> consistently been produced.
> 
> 1. After installing SciViews 0.8-7 package from the SciViews website, the
> call-tip functionality is broken in Tinn-R 1.16.1.5 stable. Downgrading, or
> installing, the SciViews 0.8-6 from CRAN restores, or enables, this
> functionality.
> 
> 2. The Packages menu in SciViews-R 0.7.3 is hopelessly broken for me (at
> least under R 2.1.1). The only menu option that works sometimes, for
> reasons I am unable to elucidate, is Load packages (the first option);
> however, many times Rconsole crashes altogether. The other menu choices
> result in nothing happening. I am able to replicate this behaviour with
> multiple fresh installs of R 2.1.1, SciViews 0.7-6 (3?) (and SciViews 0.8.7
> package), and tcltk2 0.7-4.
> 
> I am not sure that these reports matter since it appears that SciViews will
> shortly be updated, but since I found no mention of these issues, I am
> hopeful that the next version may fix them.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From jjmichael at comcast.net  Wed Aug  3 18:23:20 2005
From: jjmichael at comcast.net (Jake Michaelson)
Date: Wed, 3 Aug 2005 10:23:20 -0600
Subject: [R] red-black-green color palette?
Message-ID: <cbc7a1be7e3c68c0ccac507be8d3e7d8@comcast.net>

I'm working on some heatmaps, and the person I'm working with would 
prefer a red-black-green color palette (red denoting gene induction and 
green denoting gene repression).  Does such a palette exist already?  
If not, is there an easy way to create one?

Thanks,

Jake



From nestor.fernandez at ufz.de  Wed Aug  3 18:44:38 2005
From: nestor.fernandez at ufz.de (Nestor Fernandez)
Date: Wed, 03 Aug 2005 18:44:38 +0200
Subject: [R] clara - memory limit
Message-ID: <1123087478.42f0f47610447@webmail.ufz.de>

Dear all,

I'm trying to estimate clusters from a very large dataset using clara but the
program stops with a memory error. The (very simple) code and the error:

mydata<-read.dbf(file="fnorsel_4px.dbf")
my.clara.7k<-clara(mydata,k=7)

>Error: cannot allocate vector of size 465108 Kb

The dataset contains >3,000,000 rows and 15 columns. I'm using a windows
computer with 1.5G RAM; I also tried changing the memory limit to the maximum
possible (4000M)
Is there a way to calculate clara clusters from such large datasets?

Thanks a lot.

Nestor.-



From francoisromain at free.fr  Wed Aug  3 18:54:22 2005
From: francoisromain at free.fr (Romain Francois)
Date: Wed, 03 Aug 2005 18:54:22 +0200
Subject: [R] red-black-green color palette?
In-Reply-To: <cbc7a1be7e3c68c0ccac507be8d3e7d8@comcast.net>
References: <cbc7a1be7e3c68c0ccac507be8d3e7d8@comcast.net>
Message-ID: <42F0F6BE.3010206@free.fr>

Le 03.08.2005 18:23, Jake Michaelson a ??crit :

>I'm working on some heatmaps, and the person I'm working with would 
>prefer a red-black-green color palette (red denoting gene induction and 
>green denoting gene repression).  Does such a palette exist already?  
>If not, is there an easy way to create one?
>
>Thanks,
>
>Jake
>  
>
greenred in gplots is what you are looking for.

Cheers,

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From ripley at stats.ox.ac.uk  Wed Aug  3 19:08:14 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 3 Aug 2005 18:08:14 +0100 (BST)
Subject: [R] make error: X11/Intrinsic.h: No such,,,
In-Reply-To: <1123081340.2221.4.camel@localhost.localdomain>
References: <1123081340.2221.4.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.61.0508031806170.20604@gannet.stats>

On Wed, 3 Aug 2005, Jake Michaelson wrote:

> Hi all,
>
> I'm trying to build R 2.1.1 on Ubuntu 5.04 i686-SMP. Configure goes well
> with:
>
> ./configure --with-BLAS --with-readline=no
>
> but once I run 'make', I get the following error:
>
> In file included from devX11.c:64:
> devX11.h:57:74: X11/Intrinsic.h: No such file or directory
>
>
> Any ideas?

Yes, please discuss this on an Ubuntu list.  There is a problem with your 
X11 installation, and it not something ever reported from any other OS 
that I can recall.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Aug  3 19:10:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 3 Aug 2005 18:10:50 +0100 (BST)
Subject: [R] lda function
In-Reply-To: <200508031649.35392.lami@faunalia.it>
References: <200508031649.35392.lami@faunalia.it>
Message-ID: <Pine.LNX.4.61.0508031808300.20604@gannet.stats>

On Wed, 3 Aug 2005, Leonardo Lami wrote:

> I'm tring to make a linear discriminant analysis eith lda (MASS).
> In the value of the resulting object is there information about the value of
> the centroids of the discriminated group for the discriminant functions?

Yes.  See the help page, which tells you what _is_ there.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Aug  3 19:18:27 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 3 Aug 2005 18:18:27 +0100 (BST)
Subject: [R] clara - memory limit
In-Reply-To: <1123087478.42f0f47610447@webmail.ufz.de>
References: <1123087478.42f0f47610447@webmail.ufz.de>
Message-ID: <Pine.LNX.4.61.0508031813040.20604@gannet.stats>

>From the help page:

      'clara' is fully described in chapter 3 of Kaufman and Rousseeuw
      (1990). Compared to other partitioning methods such as 'pam', it
      can deal with much larger datasets.  Internally, this is achieved
      by considering sub-datasets of fixed size ('sampsize') such that
      the time and storage requirements become linear in n rather than
      quadratic.

and the default for 'sampsize' is apparently at least nrow(x).

So you need to set 'sampsize' (and perhaps 'samples') appropriately,


On Wed, 3 Aug 2005, Nestor Fernandez wrote:

> Dear all,
>
> I'm trying to estimate clusters from a very large dataset using clara but the
> program stops with a memory error. The (very simple) code and the error:
>
> mydata<-read.dbf(file="fnorsel_4px.dbf")
> my.clara.7k<-clara(mydata,k=7)
>
>> Error: cannot allocate vector of size 465108 Kb
>
> The dataset contains >3,000,000 rows and 15 columns. I'm using a windows
> computer with 1.5G RAM; I also tried changing the memory limit to the maximum
> possible (4000M)

Actually, the limit is probably 2048M: see the rw-FAQ Q on memory limits.

> Is there a way to calculate clara clusters from such large datasets?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From reid_huntsinger at merck.com  Wed Aug  3 19:21:45 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Wed, 3 Aug 2005 13:21:45 -0400
Subject: [R] clara - memory limit
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A9569@uswpmx00.merck.com>

I thought setting keep.data=FALSE might help, but running this on a 32-bit
Linux machine, the R process seems to use 1.2 GB until just before clara
returns, when it increases to 1.9 GB, regardless of whether keep.data=FALSE
or TRUE. Possibly it's the overhead of the .C() interface, but that's mostly
an uninformed guess. 

You could sample your data (say half), remove the original, run clara, keep
the mediods, then read your data again and assign each observation to the
nearest mediod. This is what clara does anyway, with much smaller samples by
default.

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Nestor Fernandez
Sent: Wednesday, August 03, 2005 12:45 PM
To: r-help at stat.math.ethz.ch
Subject: [R] clara - memory limit


Dear all,

I'm trying to estimate clusters from a very large dataset using clara but
the
program stops with a memory error. The (very simple) code and the error:

mydata<-read.dbf(file="fnorsel_4px.dbf")
my.clara.7k<-clara(mydata,k=7)

>Error: cannot allocate vector of size 465108 Kb

The dataset contains >3,000,000 rows and 15 columns. I'm using a windows
computer with 1.5G RAM; I also tried changing the memory limit to the
maximum
possible (4000M)
Is there a way to calculate clara clusters from such large datasets?

Thanks a lot.

Nestor.-

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Wed Aug  3 19:23:45 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 3 Aug 2005 19:23:45 +0200
Subject: [R] clara - memory limit
In-Reply-To: <1123087478.42f0f47610447@webmail.ufz.de>
References: <1123087478.42f0f47610447@webmail.ufz.de>
Message-ID: <17136.64929.258892.514091@stat.math.ethz.ch>

>>>>> "Nestor" == Nestor Fernandez <nestor.fernandez at ufz.de>
>>>>>     on Wed, 03 Aug 2005 18:44:38 +0200 writes:

    Nestor> I'm trying to estimate clusters from a
    Nestor> very large dataset using clara but the program stops
    Nestor> with a memory error. The (very simple) code and the
    Nestor> error:

    Nestor> mydata<-read.dbf(file="fnorsel_4px.dbf")
    Nestor> my.clara.7k<-clara(mydata,k=7)

    >> Error: cannot allocate vector of size 465108 Kb

    Nestor> The dataset contains >3,000,000 rows and 15
    Nestor> columns. I'm using a windows computer with 1.5G RAM;
    Nestor> I also tried changing the memory limit to the
    Nestor> maximum possible (4000M) Is there a way to calculate
    Nestor> clara clusters from such large datasets?

One way to start is reading the help   ?clara  more carefully
and hence use

    clara(mydata, k=7, keep.data = FALSE)
		     ^^^^^^^^^^^^^^^^^^^

But that might not be enough:
You may need 64-bit CPU and an operating system (with system
libraries and an R version) that uses 64-bit addressing, i.e.,
not any current version of M$ Windows.

   Nestor> Thanks a lot.

you're welcome.

Martin Maechler, ETH Zurich



From ripley at stats.ox.ac.uk  Wed Aug  3 19:26:54 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 3 Aug 2005 18:26:54 +0100 (BST)
Subject: [R] clara - memory limit
In-Reply-To: <Pine.LNX.4.61.0508031813040.20604@gannet.stats>
References: <1123087478.42f0f47610447@webmail.ufz.de>
	<Pine.LNX.4.61.0508031813040.20604@gannet.stats>
Message-ID: <Pine.LNX.4.61.0508031822240.20604@gannet.stats>

On Wed, 3 Aug 2005, Prof Brian Ripley wrote:

>> From the help page:
>
>     'clara' is fully described in chapter 3 of Kaufman and Rousseeuw
>     (1990). Compared to other partitioning methods such as 'pam', it
>     can deal with much larger datasets.  Internally, this is achieved
>     by considering sub-datasets of fixed size ('sampsize') such that
>     the time and storage requirements become linear in n rather than
>     quadratic.
>
> and the default for 'sampsize' is apparently at least nrow(x).

Correction, sorry, in your case 40 + 2*k = 54.

> So you need to set 'sampsize' (and perhaps 'samples') appropriately,

That might be it, but a traceback() showing where the error is occurring 
would help.  Another possible place is in the initial manipulations 
scaling the data matrix.

Since sub-sampling is used, you can start with a much smaller subset of 
the data.

>
>
> On Wed, 3 Aug 2005, Nestor Fernandez wrote:
>
>> Dear all,
>> 
>> I'm trying to estimate clusters from a very large dataset using clara but 
>> the
>> program stops with a memory error. The (very simple) code and the error:
>> 
>> mydata<-read.dbf(file="fnorsel_4px.dbf")
>> my.clara.7k<-clara(mydata,k=7)
>> 
>>> Error: cannot allocate vector of size 465108 Kb
>> 
>> The dataset contains >3,000,000 rows and 15 columns. I'm using a windows
>> computer with 1.5G RAM; I also tried changing the memory limit to the 
>> maximum
>> possible (4000M)
>
> Actually, the limit is probably 2048M: see the rw-FAQ Q on memory limits.
>
>> Is there a way to calculate clara clusters from such large datasets?
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From uofiowa at gmail.com  Wed Aug  3 19:29:38 2005
From: uofiowa at gmail.com (Omar Lakkis)
Date: Wed, 3 Aug 2005 13:29:38 -0400
Subject: [R] File size limit exceeded
Message-ID: <3f87cc6d050803102929c041c1@mail.gmail.com>

R quits with the message above?
What is the cause of the message and how can I avoid this?
I am using R.2.1.0 on a debian box.



From martac21 at libero.it  Wed Aug  3 19:38:28 2005
From: martac21 at libero.it (Marta Colombo)
Date: Wed,  3 Aug 2005 19:38:28 +0200
Subject: [R] R-squared
Message-ID: <IKNQC4$D7F9AA625249B6ABADE9753EB19A394C@libero.it>

Good evening, I am Marta Colombo, student of the "Politecnico" in Milan and I'm looking for some help.I'd like to know how I can see R-Squared using loess because in the output there are only:
number of observations
equivalent number of parameters 
residual standard error
and even looking at the summary I wasn't able to find it.
Thank you very much for the attention,
Marta Colombo



____________________________________________________________
Libero Flat, sempre a 4 Mega a 19,95 euro al mese!



From Eric.Archer at noaa.gov  Wed Aug  3 20:43:05 2005
From: Eric.Archer at noaa.gov (Eric Archer)
Date: Wed, 03 Aug 2005 11:43:05 -0700
Subject: [R] passing variable to formula environment
Message-ID: <42F11039.4000108@noaa.gov>

List gurus,

I'm trying to code a Gompertz growth curve function as part of a larger 
project and have run across a problem due to my ignorance of 
environments. Some sample data and the function are as follows:

growth <- data.frame(age = c(1.92, 3, 5.83, 3.17, 15.5, 1.17, 5.58, 
13.33, 14.29, 5.83, 13.79, 6.33, 13.75, 16.83, 13, 11.67, 0.25, 1.73, 
9.46, 5.67), length = c(157, 165, 179, 171, 195, 135, 179, 193, 194, 
186, 196, 186, 210, 200, 189, 194, 106, 161, 188, 159))

# return gompertz fit
Gompertz <- function(data,Xintercept,Lzero,start) {
  gomp <- formula(length ~ Lzero * exp(k * (1 - exp(-g * (age - 
Xintercept)))))
  nls(formula=gomp,data=data,start=start)
}

When I run the function, I get the following error:

 > Gompertz(growth,0,87,list(k=0.5,g=0.5))
Error in eval(expr, envir, enclos) : Object "Lzero" not found

After reading through the help files on 'nls', 'formula', 'model.frame', 
and 'environment', I understand that the formula gets evaluated in the 
environment in which it is created, and in my case, "Lzero" is not 
defined in that environment, but I'm still shaky on the environment 
concept and can't figure out how to pass or include "Lzero" in the 
environment that nls is evaluating gomp and data in.

I have tried redefining "gomp" in the function as:

gomp <- as.formula("length ~ Lzero * exp(k * (1 - exp(-g * (age - 
Xintercept))))",environment()) 
# thinking that 'environment()' refers to environment of Gompertz 
function where Lzero exists

gomp <- as.formula("length ~ Lzero * exp(k * (1 - exp(-g * (age - 
Xintercept))))",environment(Gompertz))
# trying to explicitly force it

gomp <- as.formula("length ~ Lzero * exp(k * (1 - exp(-g * (age - 
Xintercept))))",new.env())
# my guess at what formula(x,...) does

...but I get the same error. Since I'm still trying to wrap my head 
around environments and evaluation in R, the solution to this will be 
very educational.  Thanks in advance.

Cheers,
e.

-- 

Eric Archer, Ph.D.
NOAA-SWFSC
8604 La Jolla Shores Dr.
La Jolla, CA 92037
858-546-7121,7003(FAX)
eric.archer at noaa.gov


"Lighthouses are more helpful than churches."
    - Benjamin Franklin

"Cogita tute" - Think for yourself



From jmacdon at med.umich.edu  Wed Aug  3 20:44:48 2005
From: jmacdon at med.umich.edu (James W. MacDonald)
Date: Wed, 03 Aug 2005 14:44:48 -0400
Subject: [R] red-black-green color palette?
In-Reply-To: <cbc7a1be7e3c68c0ccac507be8d3e7d8@comcast.net>
References: <cbc7a1be7e3c68c0ccac507be8d3e7d8@comcast.net>
Message-ID: <42F110A0.108@med.umich.edu>

Jake Michaelson wrote:
> I'm working on some heatmaps, and the person I'm working with would 
> prefer a red-black-green color palette (red denoting gene induction and 
> green denoting gene repression).  Does such a palette exist already?  
> If not, is there an easy way to create one?

See ?maPalette in the marray package of Bioconductor.

HTH,

Jim


> 
> Thanks,
> 
> Jake
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
James W. MacDonald
Affymetrix and cDNA Microarray Core
University of Michigan Cancer Center
1500 E. Medical Center Drive
7410 CCGC
Ann Arbor MI 48109
734-647-5623



From sundar.dorai-raj at pdf.com  Wed Aug  3 20:58:24 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 03 Aug 2005 13:58:24 -0500
Subject: [R] filter data set unique, duplicate..
In-Reply-To: <003901c5980c$bd1274a0$0540210a@www.domain>
References: <6.2.0.14.2.20050803103952.01dac9e8@pop.uio.no>
	<003901c5980c$bd1274a0$0540210a@www.domain>
Message-ID: <42F113D0.6010909@pdf.com>

Hi, Anders/Dimitris,

Dimitris Rizopoulos wrote:
> maybe you could consider something like this:
> 
> dat <- data.frame(x = c(1, 2, 2, 3, 3, 4),
>                   y1 = c(1, 1, 2, 1, 7, 8),
>                   y2 = c(NA, NA, NA, 5, 5, 4),
>                   y3 = c(3, 11, NA, 16, 2, 1))
> #############
> out <- as.data.frame(lapply(dat[-1], function(y, x) tapply(y, x, max, 
> na.rm = TRUE), x = dat["x"]))
> out[out == -Inf] <- NA
> out$x <- unique(dat["x"])

Beware this line. If "x" is not sorted as it is in "dat" then your rows 
will be misaligned.

Here's another solution using "by" though it's no more efficient than 
what Dimitris has given.

out <- by(dat[-1], dat[1], function(y) {
   max.na <- function(x)
     if(all(is.na(x))) NA else max(x, na.rm = TRUE)
   apply(y, 2, max.na)
})
out <- as.data.frame(do.call("rbind", out))
out <- cbind(x = as.numeric(row.names(out)), out)
out

HTH,

--sundar

> out
> 
> 
> I hope it helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/336899
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.be/biostat/
>      http://www.student.kuleuven.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message ----- 
> From: "Anders Bj??rges??ter" <anders.bjorgesater at bio.uio.no>
> To: <r-help at stat.math.ethz.ch>
> Sent: Wednesday, August 03, 2005 10:40 AM
> Subject: [R] filter data set unique, duplicate..
> 
> 
> 
>>Hello
>>
>>First, thanks for the help for an earlier question about error 
>>handling!
>>
>>I have problem filtering a dataset.
>>I'm trying to filter the data in the y columns based on the values 
>>in the x
>>column, e.g.:
>>
>>x          y1        y2                    yn
>>1.0       1          NA                  3
>>2.0       1          NA                  11
>>2.0       2          NA                  NA
>>3.0       1          5                      16
>>3.0       7          5                      2
>>4.0       8          4                      1
>>
>>and want to keep the highest y if x is identical, like this:
>>
>>x          y1        y2                    yn
>>1.0       1          NA                  3
>>2.0       2          NA                  11
>>3.0       7          5                      16
>>4.0       8          4                      1
>>
>>or just as good:
>>
>>x          y1        y2                    yn
>>1.0    1          NA                  3
>>2.0       NA*    NA                  NA
>>2.0       2          NA                  11
>>3.0       NA*    5                      16
>>3.0       7          NA*                NA*
>>4.0       8          4                      1
>>
>>If any has any suggestions or pointers how to do this I would really
>>appreciate it.
>>
>>/Anders
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sundar.dorai-raj at pdf.com  Wed Aug  3 21:11:08 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 03 Aug 2005 14:11:08 -0500
Subject: [R] passing variable to formula environment
In-Reply-To: <42F11039.4000108@noaa.gov>
References: <42F11039.4000108@noaa.gov>
Message-ID: <42F116CC.40504@pdf.com>



Eric Archer wrote:
> List gurus,
> 
> I'm trying to code a Gompertz growth curve function as part of a larger 
> project and have run across a problem due to my ignorance of 
> environments. Some sample data and the function are as follows:
> 
> growth <- data.frame(age = c(1.92, 3, 5.83, 3.17, 15.5, 1.17, 5.58, 
> 13.33, 14.29, 5.83, 13.79, 6.33, 13.75, 16.83, 13, 11.67, 0.25, 1.73, 
> 9.46, 5.67), length = c(157, 165, 179, 171, 195, 135, 179, 193, 194, 
> 186, 196, 186, 210, 200, 189, 194, 106, 161, 188, 159))
> 
> # return gompertz fit
> Gompertz <- function(data,Xintercept,Lzero,start) {
>   gomp <- formula(length ~ Lzero * exp(k * (1 - exp(-g * (age - 
> Xintercept)))))
>   nls(formula=gomp,data=data,start=start)
> }
> 
> When I run the function, I get the following error:
> 
>  > Gompertz(growth,0,87,list(k=0.5,g=0.5))
> Error in eval(expr, envir, enclos) : Object "Lzero" not found
> 
> After reading through the help files on 'nls', 'formula', 'model.frame', 
> and 'environment', I understand that the formula gets evaluated in the 
> environment in which it is created, and in my case, "Lzero" is not 
> defined in that environment, but I'm still shaky on the environment 
> concept and can't figure out how to pass or include "Lzero" in the 
> environment that nls is evaluating gomp and data in.
> 
> I have tried redefining "gomp" in the function as:
> 
> gomp <- as.formula("length ~ Lzero * exp(k * (1 - exp(-g * (age - 
> Xintercept))))",environment()) 
> # thinking that 'environment()' refers to environment of Gompertz 
> function where Lzero exists
> 
> gomp <- as.formula("length ~ Lzero * exp(k * (1 - exp(-g * (age - 
> Xintercept))))",environment(Gompertz))
> # trying to explicitly force it
> 
> gomp <- as.formula("length ~ Lzero * exp(k * (1 - exp(-g * (age - 
> Xintercept))))",new.env())
> # my guess at what formula(x,...) does
> 
> ...but I get the same error. Since I'm still trying to wrap my head 
> around environments and evaluation in R, the solution to this will be 
> very educational.  Thanks in advance.
> 
> Cheers,
> e.
> 

Hi, Eric,

I think the easiest way to do this is to use substitute:

# return gompertz fit
Gompertz <- function(data, Xintercept, Lzero, start) {
   gomp <- substitute(length ~ Lzero * exp(k * (1 - exp(-g * (age - 
Xintercept)))),
                      list(Xintercept = Xintercept, Lzero = Lzero))
   nls(gomp, data, start)
}

Gompertz(growth, 0, 87, list(k = 0.5, g = 0.5))

HTH,

--sundar



From Eric.Archer at noaa.gov  Wed Aug  3 21:13:15 2005
From: Eric.Archer at noaa.gov (Eric Archer)
Date: Wed, 03 Aug 2005 12:13:15 -0700
Subject: [R] passing variable to formula environment
In-Reply-To: <42F116CC.40504@pdf.com>
References: <42F11039.4000108@noaa.gov> <42F116CC.40504@pdf.com>
Message-ID: <42F1174B.1030107@noaa.gov>

Most excellent Sundar!  Thanks so much!

Cheers,
e.

Sundar Dorai-Raj wrote:

>
>
> Eric Archer wrote:
>
>> List gurus,
>>
>> I'm trying to code a Gompertz growth curve function as part of a 
>> larger project and have run across a problem due to my ignorance of 
>> environments. Some sample data and the function are as follows:
>>
>> growth <- data.frame(age = c(1.92, 3, 5.83, 3.17, 15.5, 1.17, 5.58, 
>> 13.33, 14.29, 5.83, 13.79, 6.33, 13.75, 16.83, 13, 11.67, 0.25, 1.73, 
>> 9.46, 5.67), length = c(157, 165, 179, 171, 195, 135, 179, 193, 194, 
>> 186, 196, 186, 210, 200, 189, 194, 106, 161, 188, 159))
>>
>> # return gompertz fit
>> Gompertz <- function(data,Xintercept,Lzero,start) {
>>   gomp <- formula(length ~ Lzero * exp(k * (1 - exp(-g * (age - 
>> Xintercept)))))
>>   nls(formula=gomp,data=data,start=start)
>> }
>>
>> When I run the function, I get the following error:
>>
>>  > Gompertz(growth,0,87,list(k=0.5,g=0.5))
>> Error in eval(expr, envir, enclos) : Object "Lzero" not found
>>
>> After reading through the help files on 'nls', 'formula', 
>> 'model.frame', and 'environment', I understand that the formula gets 
>> evaluated in the environment in which it is created, and in my case, 
>> "Lzero" is not defined in that environment, but I'm still shaky on 
>> the environment concept and can't figure out how to pass or include 
>> "Lzero" in the environment that nls is evaluating gomp and data in.
>>
>> I have tried redefining "gomp" in the function as:
>>
>> gomp <- as.formula("length ~ Lzero * exp(k * (1 - exp(-g * (age - 
>> Xintercept))))",environment()) # thinking that 'environment()' refers 
>> to environment of Gompertz function where Lzero exists
>>
>> gomp <- as.formula("length ~ Lzero * exp(k * (1 - exp(-g * (age - 
>> Xintercept))))",environment(Gompertz))
>> # trying to explicitly force it
>>
>> gomp <- as.formula("length ~ Lzero * exp(k * (1 - exp(-g * (age - 
>> Xintercept))))",new.env())
>> # my guess at what formula(x,...) does
>>
>> ...but I get the same error. Since I'm still trying to wrap my head 
>> around environments and evaluation in R, the solution to this will be 
>> very educational.  Thanks in advance.
>>
>> Cheers,
>> e.
>>
>
> Hi, Eric,
>
> I think the easiest way to do this is to use substitute:
>
> # return gompertz fit
> Gompertz <- function(data, Xintercept, Lzero, start) {
>   gomp <- substitute(length ~ Lzero * exp(k * (1 - exp(-g * (age - 
> Xintercept)))),
>                      list(Xintercept = Xintercept, Lzero = Lzero))
>   nls(gomp, data, start)
> }
>
> Gompertz(growth, 0, 87, list(k = 0.5, g = 0.5))
>
> HTH,
>
> --sundar



-- 

Eric Archer, Ph.D.
NOAA-SWFSC
8604 La Jolla Shores Dr.
La Jolla, CA 92037
858-546-7121,7003(FAX)
eric.archer at noaa.gov


"Lighthouses are more helpful than churches."
    - Benjamin Franklin

"Cogita tute" - Think for yourself



From ecoinformatics at gmail.com  Wed Aug  3 21:38:12 2005
From: ecoinformatics at gmail.com (ecoinfo)
Date: Wed, 3 Aug 2005 21:38:12 +0200
Subject: [R] help for cell2nb and queencell in spdep package
Message-ID: <15f8e67d0508031238629887e4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050803/61bd0708/attachment.pl

From chrish at stats.ucl.ac.uk  Wed Aug  3 21:51:15 2005
From: chrish at stats.ucl.ac.uk (Christian Hennig)
Date: Wed, 3 Aug 2005 20:51:15 +0100 (BST)
Subject: [R] R CMD build error
Message-ID: <Pine.LNX.4.58.0508032046360.18848@egon.stats.ucl.ac.uk>

Dear list,

I try to update the prabclus package.
R CMD check works nicely, no warnings, good results in all tests.
However, building the package fails:

ginkgo:/disk5/home/chrish/RAusw/libsrc R CMD build prabclus
* checking for file 'prabclus/DESCRIPTION' ... OK
* preparing 'prabclus':
* checking whether 'INDEX' is up-to-date ... OK
* removing junk files
* building 'prabclus_2.0-1.tar.gz'
tar: prabclus/man/.#prabinit.Rd: Cannot stat: No such file or directory
tar: Error exit delayed from previous errors

Does anybody have an idea why tar is looking for
prabclus/man/.#prabinit.Rd (which indeed doesn't exist, but why should
it?)

Thank you,
Christian

*** NEW ADDRESS! ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche



From rangeshk at gmail.com  Wed Aug  3 22:10:44 2005
From: rangeshk at gmail.com (Rangesh Kunnavakkam)
Date: Wed, 3 Aug 2005 15:10:44 -0500
Subject: [R] help regarding loops in R
In-Reply-To: <Pine.LNX.4.58.0508032046360.18848@egon.stats.ucl.ac.uk>
References: <Pine.LNX.4.58.0508032046360.18848@egon.stats.ucl.ac.uk>
Message-ID: <839df10a050803131082dd7c@mail.gmail.com>

I  have a large vector of around 12597 elements and I wish to calculate
p-value for each element using a formula of something like:
                        p-value= 1- exp^(kexp^(-labda))
I was wondering someone could give some ideas how to implement for each element.
thankyou very much
Rangesh.K



From jeaneid at chass.utoronto.ca  Wed Aug  3 22:30:13 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Wed, 3 Aug 2005 16:30:13 -0400
Subject: [R] Seeking help with a loop
In-Reply-To: <s2f089e2.023@mail.marketsolutionsgroup.com>
Message-ID: <Pine.SGI.4.40.0508031628580.10177797-100000@origin.chass.utoronto.ca>

You can do the following without resorting to a "hard coded" loop
sapply( paste("q35", letters[1:grep("r", letters)], sep=""), function(x)
ifelse(temp[, x]%in%1,temp[, sub("5", "3", x)],NA)


as the following example shows
temp <- matrix(sample(c(0,1), 360, replace=T), nrow=10)
 colnames(temp) <- c(paste("q33", letters[1:grep("r", letters)], sep=""), paste("q35", letters[1:grep("r", letters)], sep=""))
 sapply( paste("q35", letters[1:grep("r", letters)], sep=""), function(x)  ifelse(temp[, x]%in%1,temp[, sub("5", "3", x)],NA))


HTH

Jean
On Wed, 3 Aug 2005, Greg Blevins wrote:

> Hello R Helpers,
>
> After spending considerable time attempting to write a loop (and searching the help archives) I have decided to post my problem.
>
> In a dataframe I have columns labeled:
>
> q33a q33b q33c...q33r    q35a q35b q35c...q35r
>
> What I want to do is create new variables based on the following logic:
> newfielda <- ifelse(q35a==1, q33a, NA)
> newfieldb <- ifelse(q35b==1, q33b, NA)
> ...
> newfieldr
>
> What I did was create two new dataframes, one containing q33a-r the other q35a-r and tried to loop over both, but I could not get any of the loop syntax I tried to give me the result I was seeking.
>
> Any help would be much appreciated.
>
> Greg Blevins
> Partner
> The Market Solutions Group, Inc.
> Minneapolis, MN
>
> Windows XP, R 2.1.1
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jeaneid at chass.utoronto.ca  Wed Aug  3 22:38:54 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Wed, 3 Aug 2005 16:38:54 -0400
Subject: [R] help regarding loops in R
In-Reply-To: <839df10a050803131082dd7c@mail.gmail.com>
Message-ID: <Pine.SGI.4.40.0508031633350.10177797-100000@origin.chass.utoronto.ca>


if labda is the elements of the vector and you know what kexp is , you can
use apply

apply(your_vector, 1, function(x) 1- exp^(kexp^(-x)))


HTH

Jean
On Wed, 3 Aug 2005, Rangesh Kunnavakkam wrote:

> I  have a large vector of around 12597 elements and I wish to calculate
> p-value for each element using a formula of something like:
>                         p-value= 1- exp^(kexp^(-labda))
> I was wondering someone could give some ideas how to implement for each element.
> thankyou very much
> Rangesh.K
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Wed Aug  3 22:34:18 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 3 Aug 2005 21:34:18 +0100 (BST)
Subject: [R] File size limit exceeded
In-Reply-To: <3f87cc6d050803102929c041c1@mail.gmail.com>
References: <3f87cc6d050803102929c041c1@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0508032110220.30763@gannet.stats>

On Wed, 3 Aug 2005, Omar Lakkis wrote:

> R quits with the message above?

'R quits'?  What exactly happens? -- please see the posting guide.

> What is the cause of the message and how can I avoid this?
> I am using R.2.1.0 on a debian box.

Which platform (please see the posting guide)?

I guess it means you have exceeded the 2Gb file size limit of a 32-bit OS, 
but it is possible that you have a file size limit set in your shell.

If the former, you need the configure option --enable-linux-lfs, and you 
need a very recent R-patched as that option got inadvertently broken in 
2.1.0.  (I've spent a couple of hours this afternoon checking that it 
works again on i686 linux -- another alternative is to use a 64-bit 
platform which is what most people needing large files do.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rwcitek at alum.calberkeley.org  Wed Aug  3 22:35:50 2005
From: rwcitek at alum.calberkeley.org (Robert Citek)
Date: Wed, 3 Aug 2005 15:35:50 -0500
Subject: [R] Eclipse, R, plug-in?
Message-ID: <245E2ABB-D80B-4527-ACF7-BAC37D2B011A@alum.calberkeley.org>


Has any developed or is anyone developing a plug-in[1] for using R  
with Eclipse[2]?

Eclipse is an Integrated Development Environment (IDE) written in  
Java.  While originally used as an IDE for Java, it has become an  
nice environment for developing and testing in other languages, too,  
including perl, C#, PHP, python, PL/SQL, among many others.

[1] http://www.eclipse.org/community/osplugins.html
[2] http://www.eclipse.org/

Regards,
- Robert
http://www.cwelug.org/downloads
Help others get OpenSource software.  Distribute FLOSS
for Windows, Linux, *BSD, and MacOS X with BitTorrent



From sundar.dorai-raj at pdf.com  Wed Aug  3 22:46:54 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 03 Aug 2005 15:46:54 -0500
Subject: [R] help regarding loops in R
In-Reply-To: <839df10a050803131082dd7c@mail.gmail.com>
References: <Pine.LNX.4.58.0508032046360.18848@egon.stats.ucl.ac.uk>
	<839df10a050803131082dd7c@mail.gmail.com>
Message-ID: <42F12D3E.4010601@pdf.com>



Rangesh Kunnavakkam wrote:
> I  have a large vector of around 12597 elements and I wish to calculate
> p-value for each element using a formula of something like:
>                         p-value= 1- exp^(kexp^(-labda))
> I was wondering someone could give some ideas how to implement for each element.
> thankyou very much
> Rangesh.K
> 

Each element of what? lambda (sic), k? What are these? vectors, scalars? 
R is vectorised, so you should be able to do following, assuming lambda 
is a vector and k is a scalar, for example:

p <- 1 - exp(k * exp(-lambda))

(I am assuming I parsed your formula correctly. If not, please do clarify.)

If both k and lambda are both vectors then the above still applies as 
long as they are the same length (including length 1). If they differ in 
length, beware of R's recycling rules.

HTH,

--sundar

P.S. Have you read the posting guide and subsequent literature, 
especially, an Introduction to R? Because you used "exp^(...)" and 
"kexp" suggests, no.



From helprhelp at gmail.com  Wed Aug  3 22:46:59 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Wed, 3 Aug 2005 15:46:59 -0500
Subject: [R] outlier detection
Message-ID: <cdf8178305080313466bdb611f@mail.gmail.com>

Hi, there:
I am wondering what packages are available in R which can do "outlier
detection" in large-scale dataset.

Thanks for sharing info,

weiwei

-- 
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From sfalcon at fhcrc.org  Wed Aug  3 22:48:20 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 03 Aug 2005 13:48:20 -0700
Subject: [R] Job: Computational Biology at FHCRC is hiring
Message-ID: <m2pssuiw6j.fsf@fhcrc.org>

Greetings all,

Our group[1] is seeking to hire three programmers to work on various
aspects of Bioconductor as well as other projects within the
Computational Biology group at the Fred Hutchinson Cancer Research
Center.

Here is a brief description of each position with a link for more
info.  Feel free to pass this along to folks you think would be
interested.  

Send resume/cv to Seth Falcon <sfalcon at fhcrc.org>.  PDF or plain-text
preferred.


Best Wishes,

+ seth

[1] Program in Computational Biology at the Fred Hutchinson Cancer
Research Center, Seattle, WA, USA.


R Programmer
------------

This position will improve the object-oriented infrastructure of core
Bioconductor packages and develop new packages for analyzing
biological data. The programmer will have the opportunity to develop
exciting new skills that will contribute to his/her growth in the
computational field.

URL:
http://jobs.nwsource.com/texis/jobsearch/details.html?id=42e768446d61c0&q=R%20programmer&pp=25&qComp=Fred%20Hutchinson%20Cancer%20Research%20Center&view=1&page=1


Grid Computing and Parallel Programming Specialist
--------------------------------------------------

The programmer in this position will design and implement a grid
computing structure that will make use of available computing
resources at the center. S/he will write programs in R (and C) that
use the grid system. In addition, the programmer will serve as an
advocate for the new computing environment, by explaining its use to
non-technical audiences and serving as a resource for scientists
wanting to make use of the grid.

URL:
http://jobs.nwsource.com/texis/jobsearch/details.html?id=42e50a616d6670&q=R%20programmer&pp=25&qComp=Fred%20Hutchinson%20Cancer%20Research%20Center&view=1&page=1


Webservices Specialist
----------------------

The Webservices Programming Specialist will create webservices for
existing functionality in Bioconductor packages and design tools to
automate the process of webservice creation.

URL:
http://jobs.nwsource.com/texis/jobsearch/details.html?id=42e768416d6230&q=R%20programmer&pp=25&qComp=Fred%20Hutchinson%20Cancer%20Research%20Center&view=1&page=1



From edhuang00 at yahoo.com  Wed Aug  3 22:52:13 2005
From: edhuang00 at yahoo.com (Haibo Huang)
Date: Wed, 3 Aug 2005 13:52:13 -0700 (PDT)
Subject: [R] Convert numeric to factor
In-Reply-To: <Pine.SGI.4.40.0508031633350.10177797-100000@origin.chass.utoronto.ca>
Message-ID: <20050803205213.54862.qmail@web31010.mail.mud.yahoo.com>

Hi,

I tried to do a logistic regression with polr(MASS). I
thought I already converted the response to factor,
but obvious I was wrong. Could anyone tell me what I
did wrong and how to correct it? Thank you very much!

> Lease=read.csv("LeaseDummy.csv", header=TRUE)
> Lease$ID <-
as.integer(factor(Lease$EarlyTermination)) 
> 
>
RegA=polr(ID~1+MSA+SIC.Code+TenantOption+LLOption+TOExercised,

+  data=Lease, method=c("logistic"))
Error in polr(ID ~ 1 + MSA + SIC.Code + TenantOption +
LLOption + TOExercised,  : 
        response must be a factor
> summary(RegA)


Best,
Ed.




--- Jean Eid <jeaneid at chass.utoronto.ca> wrote:

> 
> if labda is the elements of the vector and you know
> what kexp is , you can
> use apply
> 
> apply(your_vector, 1, function(x) 1-
> exp^(kexp^(-x)))
> 
> 
> HTH
> 
> Jean
> On Wed, 3 Aug 2005, Rangesh Kunnavakkam wrote:
> 
> > I  have a large vector of around 12597 elements
> and I wish to calculate
> > p-value for each element using a formula of
> something like:
> >                         p-value= 1-
> exp^(kexp^(-labda))
> > I was wondering someone could give some ideas how
> to implement for each element.
> > thankyou very much
> > Rangesh.K
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From roger.bos at gmail.com  Wed Aug  3 23:00:40 2005
From: roger.bos at gmail.com (roger bos)
Date: Wed, 3 Aug 2005 17:00:40 -0400
Subject: [R] using weighted.mean with tapply()
Message-ID: <1db7268005080314007e1fdb1b@mail.gmail.com>

I am trying to calculate the weighted mean for a of 10 deciles and I
get an error:
> decile <- tapply(X=mat$trt1m, INDEX=mat$Rank, FUN=weighted.mean, w=mat$mcap)
Error in FUN(X[[1]], ...) : 'x' and 'w' must have the same length

All three of my inputs have the same length, as shown below, and the
weighted.mean calculation works by itself, just not in tapply()

> length(mat$Rank)
[1] 1853
> length(mat$mcap)
[1] 1853
> length(mat$trt1m)
[1] 1853
> mean(mat$trt1m)
[1] -0.04475397
weighted.mean(mat$trt1m, w=mat$mcap)
[1] -0.04819243
> mat$mcap[is.na(mat$mcap)] <- min(mat$mcap, na.rm=TRUE)

I am probably making a simple error in how I pass the optional
parameter w.  Any help would be greatly appreciated.



From ogabbrie at tin.it  Wed Aug  3 23:24:21 2005
From: ogabbrie at tin.it (Simone Gabbriellini)
Date: Wed, 3 Aug 2005 23:24:21 +0200
Subject: [R] problem with for()
Message-ID: <5860A155-CE7B-4BDF-A184-282E5D23F9F4@tin.it>

Dear list,
can someone tell me why this two pieces of code give me the same  
results?

 > for(i in 0:5){ sum[i] = i }
 > sum
[1] 1 2 3 4 5

 > for(i in 1:5){ sum[i] = i }
 > sum
[1] 1 2 3 4 5

shouldn't the first one be

0 1 2 3 4 5

thank you,
simone



From p.dalgaard at biostat.ku.dk  Wed Aug  3 23:34:10 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 03 Aug 2005 23:34:10 +0200
Subject: [R] problem with for()
In-Reply-To: <5860A155-CE7B-4BDF-A184-282E5D23F9F4@tin.it>
References: <5860A155-CE7B-4BDF-A184-282E5D23F9F4@tin.it>
Message-ID: <x2irymu2lp.fsf@turmalin.kubism.ku.dk>

Simone Gabbriellini <ogabbrie at tin.it> writes:

> Dear list,
> can someone tell me why this two pieces of code give me the same  
> results?
> 
>  > for(i in 0:5){ sum[i] = i }
>  > sum
> [1] 1 2 3 4 5
> 
>  > for(i in 1:5){ sum[i] = i }
>  > sum
> [1] 1 2 3 4 5
> 
> shouldn't the first one be
> 
> 0 1 2 3 4 5

No. Indexing starts at 1 in R.

Next, figure out this:

> sum=0
> for(i in 5:-5){ sum[i] = i }
> sum
[1] -5 -5 -5 -5 -4


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From MSchwartz at mn.rr.com  Wed Aug  3 23:37:30 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Wed, 03 Aug 2005 16:37:30 -0500
Subject: [R] problem with for()
In-Reply-To: <5860A155-CE7B-4BDF-A184-282E5D23F9F4@tin.it>
References: <5860A155-CE7B-4BDF-A184-282E5D23F9F4@tin.it>
Message-ID: <1123105050.4100.13.camel@localhost.localdomain>

On Wed, 2005-08-03 at 23:24 +0200, Simone Gabbriellini wrote:
> Dear list,
> can someone tell me why this two pieces of code give me the same  
> results?
> 
>  > for(i in 0:5){ sum[i] = i }
>  > sum
> [1] 1 2 3 4 5
> 
>  > for(i in 1:5){ sum[i] = i }
>  > sum
> [1] 1 2 3 4 5
> 
> shouldn't the first one be
> 
> 0 1 2 3 4 5
> 
> thank you,
> simone

No....the indexing of R objects is 1 based. Thus your first loop tried
to set i[0], which is a non-existent entry.

> i <- 0:5

> i
[1] 0 1 2 3 4 5

> i[0]
numeric(0)

> i[1]
[1] 0

HTH,

Marc Schwartz



From spencer.graves at pdf.com  Wed Aug  3 23:43:22 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 03 Aug 2005 14:43:22 -0700
Subject: [R] problem with for()
In-Reply-To: <x2irymu2lp.fsf@turmalin.kubism.ku.dk>
References: <5860A155-CE7B-4BDF-A184-282E5D23F9F4@tin.it>
	<x2irymu2lp.fsf@turmalin.kubism.ku.dk>
Message-ID: <42F13A7A.3040301@pdf.com>

Hint:  help.search() -> "An Introduction to R" -> "Simple manipulations 
numbers and vectors" -> ...

spencer graves

Peter Dalgaard wrote:

> Simone Gabbriellini <ogabbrie at tin.it> writes:
> 
> 
>>Dear list,
>>can someone tell me why this two pieces of code give me the same  
>>results?
>>
>> > for(i in 0:5){ sum[i] = i }
>> > sum
>>[1] 1 2 3 4 5
>>
>> > for(i in 1:5){ sum[i] = i }
>> > sum
>>[1] 1 2 3 4 5
>>
>>shouldn't the first one be
>>
>>0 1 2 3 4 5
> 
> 
> No. Indexing starts at 1 in R.
> 
> Next, figure out this:
> 
> 
>>sum=0
>>for(i in 5:-5){ sum[i] = i }
>>sum
> 
> [1] -5 -5 -5 -5 -4
> 
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From markus.jantti at iki.fi  Wed Aug  3 23:48:23 2005
From: markus.jantti at iki.fi (=?ISO-8859-1?Q?Markus_J=E4ntti?=)
Date: Thu, 04 Aug 2005 00:48:23 +0300
Subject: [R] using weighted.mean with tapply()
In-Reply-To: <1db7268005080314007e1fdb1b@mail.gmail.com>
References: <1db7268005080314007e1fdb1b@mail.gmail.com>
Message-ID: <42F13BA7.2030403@iki.fi>

roger bos wrote:
> I am trying to calculate the weighted mean for a of 10 deciles and I
> get an error:
> 
>>decile <- tapply(X=mat$trt1m, INDEX=mat$Rank, FUN=weighted.mean, w=mat$mcap)
> 
> Error in FUN(X[[1]], ...) : 'x' and 'w' must have the same length
> 
> All three of my inputs have the same length, as shown below, and the
> weighted.mean calculation works by itself, just not in tapply()
> 

Hi -- I asked pretty much this same question some years ago:

http://www.r-project.org/nocvs/mail/r-help/1999/2160.html

The answer turns out to be that you should pass the index to tapply
rather than the data. In your case this would, I think, translate to

decile <- tapply(seq(along=mat$trlm, mat$Rank,
function(i, x=mat$trlm[i], w=mat$mcap[i])
weighted.mean(x[i], w[i]))

hope this helps.

regards,

Markus

> 
>>length(mat$Rank)
> 
> [1] 1853
> 
>>length(mat$mcap)
> 
> [1] 1853
> 
>>length(mat$trt1m)
> 
> [1] 1853
> 
>>mean(mat$trt1m)
> 
> [1] -0.04475397
> weighted.mean(mat$trt1m, w=mat$mcap)
> [1] -0.04819243
> 
>>mat$mcap[is.na(mat$mcap)] <- min(mat$mcap, na.rm=TRUE)
> 
> 
> I am probably making a simple error in how I pass the optional
> parameter w.  Any help would be greatly appreciated.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Markus Jantti
Abo Akademi University
markus.jantti at iki.fi
http://www.iki.fi/~mjantti



From ogabbrie at tin.it  Thu Aug  4 00:25:15 2005
From: ogabbrie at tin.it (Simone Gabbriellini)
Date: Thu, 4 Aug 2005 00:25:15 +0200
Subject: [R] problem with for()
In-Reply-To: <1123105050.4100.13.camel@localhost.localdomain>
References: <5860A155-CE7B-4BDF-A184-282E5D23F9F4@tin.it>
	<1123105050.4100.13.camel@localhost.localdomain>
Message-ID: <FA0F39D3-A8EE-47A9-80D6-C1EA49BD9C36@tin.it>

how can I have a 0 evaluated in my loop then?
it is important for my algorithm

do you have any hints?

simone

Il giorno 03/ago/05, alle ore 23:37, Marc Schwartz ha scritto:

> On Wed, 2005-08-03 at 23:24 +0200, Simone Gabbriellini wrote:
>
>> Dear list,
>> can someone tell me why this two pieces of code give me the same
>> results?
>>
>>
>>> for(i in 0:5){ sum[i] = i }
>>> sum
>>>
>> [1] 1 2 3 4 5
>>
>>
>>> for(i in 1:5){ sum[i] = i }
>>> sum
>>>
>> [1] 1 2 3 4 5
>>
>> shouldn't the first one be
>>
>> 0 1 2 3 4 5
>>
>> thank you,
>> simone
>>
>
> No....the indexing of R objects is 1 based. Thus your first loop tried
> to set i[0], which is a non-existent entry.
>
>
>> i <- 0:5
>>
>
>
>> i
>>
> [1] 0 1 2 3 4 5
>
>
>> i[0]
>>
> numeric(0)
>
>
>> i[1]
>>
> [1] 0
>
> HTH,
>
> Marc Schwartz
>
>
>
>



From MSchwartz at mn.rr.com  Thu Aug  4 00:39:55 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Wed, 03 Aug 2005 17:39:55 -0500
Subject: [R] problem with for()
In-Reply-To: <FA0F39D3-A8EE-47A9-80D6-C1EA49BD9C36@tin.it>
References: <5860A155-CE7B-4BDF-A184-282E5D23F9F4@tin.it>
	<1123105050.4100.13.camel@localhost.localdomain>
	<FA0F39D3-A8EE-47A9-80D6-C1EA49BD9C36@tin.it>
Message-ID: <1123108795.4100.19.camel@localhost.localdomain>

It would help to have an example of what it is you are trying to do.

Importantly, keep separate the need to have zero be a value in a vector
as opposed to using zero to index a vector.

As I note below in my reply, you can have:

> x <- 0:5

> x
[1] 0 1 2 3 4 5

> x ^ 2
[1]  0  1  4  9 16 25

Marc

On Thu, 2005-08-04 at 00:25 +0200, Simone Gabbriellini wrote:
> how can I have a 0 evaluated in my loop then?
> it is important for my algorithm
> 
> do you have any hints?
> 
> simone
> 
> Il giorno 03/ago/05, alle ore 23:37, Marc Schwartz ha scritto:
> 
> > On Wed, 2005-08-03 at 23:24 +0200, Simone Gabbriellini wrote:
> >
> >> Dear list,
> >> can someone tell me why this two pieces of code give me the same
> >> results?
> >>
> >>
> >>> for(i in 0:5){ sum[i] = i }
> >>> sum
> >>>
> >> [1] 1 2 3 4 5
> >>
> >>
> >>> for(i in 1:5){ sum[i] = i }
> >>> sum
> >>>
> >> [1] 1 2 3 4 5
> >>
> >> shouldn't the first one be
> >>
> >> 0 1 2 3 4 5
> >>
> >> thank you,
> >> simone
> >>
> >
> > No....the indexing of R objects is 1 based. Thus your first loop tried
> > to set i[0], which is a non-existent entry.
> >
> >
> >> i <- 0:5
> >>
> >
> >
> >> i
> >>
> > [1] 0 1 2 3 4 5
> >
> >
> >> i[0]
> >>
> > numeric(0)
> >
> >
> >> i[1]
> >>
> > [1] 0
> >
> > HTH,
> >
> > Marc Schwartz
> >
> >
> >
> >



From liuwensui at gmail.com  Thu Aug  4 00:41:09 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Wed, 3 Aug 2005 18:41:09 -0400
Subject: [R] outlier detection
In-Reply-To: <cdf8178305080313466bdb611f@mail.gmail.com>
References: <cdf8178305080313466bdb611f@mail.gmail.com>
Message-ID: <1115a2b0050803154126fb030d@mail.gmail.com>

Random forest can do the job.

HTH.

On 8/3/05, Weiwei Shi <helprhelp at gmail.com> wrote:
> Hi, there:
> I am wondering what packages are available in R which can do "outlier
> detection" in large-scale dataset.
> 
> Thanks for sharing info,
> 
> weiwei
> 
> --
> Weiwei Shi, Ph.D
> 
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
WenSui Liu, MS MA
Senior Decision Support Analyst
Division of Health Policy and Clinical Effectiveness
Cincinnati Children Hospital Medical Center



From gunter.berton at gene.com  Thu Aug  4 01:18:48 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 3 Aug 2005 16:18:48 -0700
Subject: [R] A question on validity checking for S4 classes
Message-ID: <200508032318.j73NInRx009993@meitner.gene.com>

Folks:

(This is a question on the formal S4 class system). R 2.1.1 on Windows.

I'm pretty sure the following is a failure of my understanding, rather than
a bug, so may I ask for some clarification?

The Green book states that (p. 295) "Objects are checked for validity when
permanently assigned, or explicitly by the function validObject()." The Help
for setValidity() seems silent on the details, however, and this does not
appear to be the R implementation. Here's an example to show why I think
not:

> setClass('posNumber','numeric')
[1] "posNumber"

> setValidity('posNumber',function(object)
+ if(any(object at .Data<=0))'Must be positive numbers'
+ else TRUE)

Slots:
              
Name:    .Data
Class: numeric

Extends: 
Class "numeric", from data part
Class "vector", by class "numeric"

> z<-new('posNumber',1:3)
> z
An object of class "posNumber"
[1] 1 2 3

#### BUT ....
> z<-z-5
> z
An object of class "posNumber"
[1] -4 -3 -2
##### Isn't this where the Green book says validity should be checked?
#####  Further, note that when one does the explicit check:

> validObject(z)
Error in validObject(z) : invalid class "posNumber" object: Must be positive
numbers 

## or when one tries to instantiate 'posNumber' incorrectly:
> z<-new('posNumber',-(1:3))
Error in validObject(.Object) : invalid class "posNumber" object: Must be
positive numbers

So when does R do validity checking? And, in particular, how should I
arrange the classes/validity checking or other methods so that I can assure
that an object of class 'posNumber' consists of positive numbers without
doing an explicit validObject() check? Many thanks and my apologies if I
have misunderstood or overlooked something obvious.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box



From aoganyan at niss.org  Thu Aug  4 01:52:00 2005
From: aoganyan at niss.org (Anna Oganyan)
Date: Wed, 03 Aug 2005 19:52:00 -0400
Subject: [R] multivariate F distribution
Message-ID: <42F158A0.70603@niss.org>

Dear List,

Is there any function in R to generate multivariate F distribution with 
given correlation/covariance matrix?

Actually, I just want to generate some 2-dimentional non-normal data 
sets (skewed) for low (may be around 0.3 cor coeff.) negatively and also 
positively correlated variables ?

Thanks in advance.

Anna



From ggrothendieck at gmail.com  Thu Aug  4 01:57:01 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 3 Aug 2005 19:57:01 -0400
Subject: [R] passing variable to formula environment
In-Reply-To: <42F116CC.40504@pdf.com>
References: <42F11039.4000108@noaa.gov> <42F116CC.40504@pdf.com>
Message-ID: <971536df05080316571f99f8b2@mail.gmail.com>

Note that we can omit the second argument to substitute as
in this case since they will be given by the default.

On 8/3/05, Sundar Dorai-Raj <sundar.dorai-raj at pdf.com> wrote:
> 
> 
> Eric Archer wrote:
> > List gurus,
> >
> > I'm trying to code a Gompertz growth curve function as part of a larger
> > project and have run across a problem due to my ignorance of
> > environments. Some sample data and the function are as follows:
> >
> > growth <- data.frame(age = c(1.92, 3, 5.83, 3.17, 15.5, 1.17, 5.58,
> > 13.33, 14.29, 5.83, 13.79, 6.33, 13.75, 16.83, 13, 11.67, 0.25, 1.73,
> > 9.46, 5.67), length = c(157, 165, 179, 171, 195, 135, 179, 193, 194,
> > 186, 196, 186, 210, 200, 189, 194, 106, 161, 188, 159))
> >
> > # return gompertz fit
> > Gompertz <- function(data,Xintercept,Lzero,start) {
> >   gomp <- formula(length ~ Lzero * exp(k * (1 - exp(-g * (age -
> > Xintercept)))))
> >   nls(formula=gomp,data=data,start=start)
> > }
> >
> > When I run the function, I get the following error:
> >
> >  > Gompertz(growth,0,87,list(k=0.5,g=0.5))
> > Error in eval(expr, envir, enclos) : Object "Lzero" not found
> >
> > After reading through the help files on 'nls', 'formula', 'model.frame',
> > and 'environment', I understand that the formula gets evaluated in the
> > environment in which it is created, and in my case, "Lzero" is not
> > defined in that environment, but I'm still shaky on the environment
> > concept and can't figure out how to pass or include "Lzero" in the
> > environment that nls is evaluating gomp and data in.
> >
> > I have tried redefining "gomp" in the function as:
> >
> > gomp <- as.formula("length ~ Lzero * exp(k * (1 - exp(-g * (age -
> > Xintercept))))",environment())
> > # thinking that 'environment()' refers to environment of Gompertz
> > function where Lzero exists
> >
> > gomp <- as.formula("length ~ Lzero * exp(k * (1 - exp(-g * (age -
> > Xintercept))))",environment(Gompertz))
> > # trying to explicitly force it
> >
> > gomp <- as.formula("length ~ Lzero * exp(k * (1 - exp(-g * (age -
> > Xintercept))))",new.env())
> > # my guess at what formula(x,...) does
> >
> > ...but I get the same error. Since I'm still trying to wrap my head
> > around environments and evaluation in R, the solution to this will be
> > very educational.  Thanks in advance.
> >
> > Cheers,
> > e.
> >
> 
> Hi, Eric,
> 
> I think the easiest way to do this is to use substitute:
> 
> # return gompertz fit
> Gompertz <- function(data, Xintercept, Lzero, start) {
>   gomp <- substitute(length ~ Lzero * exp(k * (1 - exp(-g * (age -
> Xintercept)))),
>                      list(Xintercept = Xintercept, Lzero = Lzero))
>   nls(gomp, data, start)
> }
> 
> Gompertz(growth, 0, 87, list(k = 0.5, g = 0.5))
> 
> HTH,
> 
> --sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From gerifalte28 at hotmail.com  Thu Aug  4 01:58:38 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Wed, 03 Aug 2005 23:58:38 +0000
Subject: [R] Convert numeric to factor
In-Reply-To: <20050803205213.54862.qmail@web31010.mail.mud.yahoo.com>
Message-ID: <BAY103-F32722196E7390BD7AAA8E4A6C50@phx.gbl>

Why are you adding as.integer before the factor statement?  You are forcing 
the variable to be an integer even tough you are passing factor within the 
statement.  Try

Lease$ID <-factor(Lease$EarlyTermination)

Cheers

Francisco


>From: Haibo Huang <edhuang00 at yahoo.com>
>To: r-help at r-project.org
>Subject: [R] Convert numeric to factor
>Date: Wed, 3 Aug 2005 13:52:13 -0700 (PDT)
>
>Hi,
>
>I tried to do a logistic regression with polr(MASS). I
>thought I already converted the response to factor,
>but obvious I was wrong. Could anyone tell me what I
>did wrong and how to correct it? Thank you very much!
>
> > Lease=read.csv("LeaseDummy.csv", header=TRUE)
> > Lease$ID <-
>as.integer(factor(Lease$EarlyTermination))
> >
> >
>RegA=polr(ID~1+MSA+SIC.Code+TenantOption+LLOption+TOExercised,
>
>+  data=Lease, method=c("logistic"))
>Error in polr(ID ~ 1 + MSA + SIC.Code + TenantOption +
>LLOption + TOExercised,  :
>         response must be a factor
> > summary(RegA)
>
>
>Best,
>Ed.
>
>
>
>
>--- Jean Eid <jeaneid at chass.utoronto.ca> wrote:
>
> >
> > if labda is the elements of the vector and you know
> > what kexp is , you can
> > use apply
> >
> > apply(your_vector, 1, function(x) 1-
> > exp^(kexp^(-x)))
> >
> >
> > HTH
> >
> > Jean
> > On Wed, 3 Aug 2005, Rangesh Kunnavakkam wrote:
> >
> > > I  have a large vector of around 12597 elements
> > and I wish to calculate
> > > p-value for each element using a formula of
> > something like:
> > >                         p-value= 1-
> > exp^(kexp^(-labda))
> > > I was wondering someone could give some ideas how
> > to implement for each element.
> > > thankyou very much
> > > Rangesh.K
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From arrayprofile at yahoo.com  Thu Aug  4 02:03:05 2005
From: arrayprofile at yahoo.com (array chip)
Date: Wed, 3 Aug 2005 17:03:05 -0700 (PDT)
Subject: [R] color palette
Message-ID: <20050804000305.6364.qmail@web40825.mail.yahoo.com>

Hi, I have a matrix with both positive and negative
numbers, I would like to use image() to draw a
heatmap. How can I can design a palette (or is there a
function already available) that treat negative
numbers in a blue gradient and positive numbers in a
red gradient and treat 0 as white?

Thanks



From tlumley at u.washington.edu  Thu Aug  4 02:12:27 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 3 Aug 2005 17:12:27 -0700 (PDT)
Subject: [R] color palette
In-Reply-To: <20050804000305.6364.qmail@web40825.mail.yahoo.com>
References: <20050804000305.6364.qmail@web40825.mail.yahoo.com>
Message-ID: <Pine.A41.4.61b.0508031711220.210186@homer09.u.washington.edu>

On Wed, 3 Aug 2005, array chip wrote:

> Hi, I have a matrix with both positive and negative
> numbers, I would like to use image() to draw a
> heatmap. How can I can design a palette (or is there a
> function already available) that treat negative
> numbers in a blue gradient and positive numbers in a
> red gradient and treat 0 as white?
>

?colorRampPalette

 	-thomas



From ramasamy at cancer.org.uk  Thu Aug  4 03:05:15 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Thu, 04 Aug 2005 02:05:15 +0100
Subject: [R] abline and linearity over groups
In-Reply-To: <20050803153330.3828.qmail@web25405.mail.ukl.yahoo.com>
References: <20050803153330.3828.qmail@web25405.mail.ukl.yahoo.com>
Message-ID: <1123117515.5864.79.camel@dhcppc3>

I think ronggui is right and your example is just a coincidence. Here is
my example in which case the intercept is hugely different 
(with slightly different style of coding).


  set.seed(1)  # for reproducibility 
  y  <- c( rnorm(10, 0, 30), rnorm(10, 100, 30), rnorm(10, 200, 30) )
  x  <- rep( 1:3, each=10 )

  df <- cbind.data.frame( y=y, x1=x, x2=factor(x) )
  plot(df$x2, df$y)
  points(df$x1, df$y, col=2, pch=2)

  ( fit1 <- lm( y ~ x1, data=df ) )
      (Intercept)           x1
           -89.55        96.01


  ( fit2 <- lm( y ~ x2, data=df ) )
      (Intercept)          x22          x23
            3.966      103.499      192.024

  abline(fit1)
  abline(fit2, col="red")  # wrong

The line above is wrong because it is fitting 

   abline(3.966, 103.499, col="green", lty=3)

as documented in help(abline) and pointed out by ronggui.


Note that 'fit1' is a linear model for regression while 
'fit2' is a linear model for ANOVA and that the documentation
of help(abline) uses the word "regression". Perhaps

It is more reliable to plot the fitted or predicted values via

   points( df$x2, fit2$fitted, col=4, pch=20 ) 

and this works regardless whether the linear model if for regression
or ANOVA.

You could replace plot() with lines() but this is perhaps not
appropriate with an ANOVA fit which may not have numerical values for x.


Regards, Adai



On Wed, 2005-08-03 at 16:33 +0100, Jabez Wilson wrote:
> But those two lines are almose identical The difference between i=0.4432, s=104.1688 and i=0.8776,s=108.1313 is almost negligible.
> 
> What I see is that abline draws a line with a v.similar slope but intercept is about 90 instead of 0.8776. Try running the example to see what I mean.
> 
> ronggui <0034058 at fudan.edu.cn> wrote:>?abline
> and you can see
> ...
> 'reg' is a regression object which contains 'reg$coef'. If it is
> of length 1 then the value is taken to be the slope of a line
> through the origin, otherwise, the first 2 values are taken to be
> the intercept and slope.
> ...
> 
> and
> > plot(test$l~test$t)
> > abline(lm(test$l~test$t))
> > (lm(test$l~test$t))
> 
> Call:
> lm(formula = test$l ~ test$t)
> 
> Coefficients:
> (Intercept) test$t 
> 0.4432 104.1688 
> 
> > test$tF=factor(test$t)
> > plot(test$l~test$tF)
> > abline(lm(test$l~test$tF))
> > (lm(test$l~test$tF))
> 
> Call:
> lm(formula = test$l ~ test$tF)
> 
> Coefficients:
> (Intercept) test$tF1 test$tF2 
> -0.8776 108.1313 208.3376 
> 
> when test$tF is factor,these are 3 coef and the first two are used to drow the line,with Intercept = -0.8776 and slope= 108.1313 ,and abline(lm(test$l~test$tF)) is abline(-0.8776,108.1313)
> 
> 
> ======= 2005-08-03 22:23:57 Ð´=======
> 
> >
> >
> >Dear R users, please can you help me understand the behaviour of abline using function lm.
> >
> >I'm trying to learn linearity over groups. So I make three groups with 10 values each:
> >
> >test=data.frame(cbind(
> >l=c(rnorm(10,0,30),rnorm(10,100,30),rnorm(10,200,30)),
> >t = c(rep(0,10), rep(1,10), rep(2,10))
> >))
> >
> >when I do: 
> >
> >plot(test$l~test$t)
> >abline(lm(test$l~test$t))
> >
> >
> >the abline is a straight line through the centre of the points of each of the groups.
> >
> >If, however, I factorise the groups (in order to do e.g. anova analysis) and then plot the data
> >
> >test$tF=factor(test$t)
> >plot(test$l~test$tF)
> >abline(lm(test$l~test$tF))
> >
> >
> >the abline is now shifted up and to the left of where I would expect the line to go (through the centre of the points of each of the groups).
> >
> >If there is a simple explanation, could someone tell me it?
> >
> > 
> >
> > 
> >---------------------------------
> >To help you stay safe and secure online, we've developed the all new Yahoo! Security Centre.
> > [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> = = = = = = = = = = = = = = = = = = = =
> 
> 
> 
> 
> 
> 2005-08-03
> 
> ------
> Deparment of Sociology
> Fudan University
> 
> Blog:http://sociology.yculblog.com
> 
> 
> 		
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From wl at eimb.ru  Thu Aug  4 03:37:52 2005
From: wl at eimb.ru (Wladimir Eremeev)
Date: Wed, 3 Aug 2005 17:37:52 -0800
Subject: [R] one more minor and small bug in lattice in R
In-Reply-To: <200507251353.07608.deepayan@stat.wisc.edu>
References: <1803865630.20050520160521@eimb.ru>
	<200505200955.37557.deepayan@stat.wisc.edu>
	<1906380434.20050723200741@eimb.ru>
	<200507251353.07608.deepayan@stat.wisc.edu>
Message-ID: <1262806553.20050803173752@eimb.ru>

Dear all.

 I have found one more minor bug in the Lattice package.

 When xyplot plots several curves on each panel with the default panel
 function panel.xyplot, and when it is called with "g" %in% type
(that is,
xyplot(y1+y2+y3~x|cond,allow.multiple=TRUE,type=c("o","g"),<other params>)
 ), it draws grid lines several times (for each curve), and it appears,
 that they overlay all curves plotted, except the last one.

 I think there is a need to establish some kind of flag, showing, that
 the grid is already drawn, and other runs of the panel.xyplot for the
 same panel must not draw it again.
 I was looking to the source of the xyplot, but haven't found any place to put the flag.

 Another solution could be to establish separate types for each curve
 on the plot... However, AFAIK, they are not all intercompatible.

 There is also need to do something with custom panel functions...

 Hmm... The task looks complex to me now. :)

 Any suggestions?
 
---
Best regards,
Wladimir



From helprhelp at gmail.com  Thu Aug  4 05:12:40 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Wed, 3 Aug 2005 22:12:40 -0500
Subject: [R] outlier detection
In-Reply-To: <1115a2b0050803154126fb030d@mail.gmail.com>
References: <cdf8178305080313466bdb611f@mail.gmail.com>
	<1115a2b0050803154126fb030d@mail.gmail.com>
Message-ID: <cdf817830508032012736cf29a@mail.gmail.com>

Thanks. 
I knew rf based on proximity can detect the outlier but when the data
size goes to 1 million and the features go around 200, I guess I
probably do not have enough memory to proceed. Do u have some
experience of outlier detection in this kind of data size?

regards,

weiwei

On 8/3/05, Wensui Liu <liuwensui at gmail.com> wrote:
> Random forest can do the job.
> 
> HTH.
> 
> On 8/3/05, Weiwei Shi <helprhelp at gmail.com> wrote:
> > Hi, there:
> > I am wondering what packages are available in R which can do "outlier
> > detection" in large-scale dataset.
> >
> > Thanks for sharing info,
> >
> > weiwei
> >
> > --
> > Weiwei Shi, Ph.D
> >
> > "Did you always know?"
> > "No, I did not. But I believed..."
> > ---Matrix III
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> 
> --
> WenSui Liu, MS MA
> Senior Decision Support Analyst
> Division of Health Policy and Clinical Effectiveness
> Cincinnati Children Hospital Medical Center
> 


-- 
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From Glenn.Stone at csiro.au  Thu Aug  4 05:36:20 2005
From: Glenn.Stone at csiro.au (Glenn Stone)
Date: Thu, 04 Aug 2005 13:36:20 +1000
Subject: [R] Odd timing behaviour in reading a file
Message-ID: <42F18D34.9000007@csiro.au>

Hi all,  please don't ask me why I tried this but.......

I have observed some odd behaviour in the time taken to read a file. I 
tried searching the archives without much success, but that could be me.

The first time I read a (60Mb) CSV file, takes a certain amount of time. 
The second time takes appreciably longer and the third and subsequent 
times very much shorter times. See below,

$ R2.1.1

R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

 > system.time(temp <- 
read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
[1] 32.55  0.30 33.46  0.00  0.00
 > system.time(temp <- 
read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
[1] 45.32  0.24 45.72  0.00  0.00
 > system.time(temp <- 
read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
[1] 11.73  0.17 11.94  0.00  0.00
 > system.time(temp <- 
read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
[1] 8.58 0.28 8.96 0.00 0.00
 > system.time(temp <- 
read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
[1] 8.80 0.16 9.02 0.00 0.00


This is a relatively quiet opteron running redhat linux and using R2.1.1
The same pattern is repeatable, and occurs in R2.0.1 and on a Dell 
laptop running Windows XP.

I guess it is probably something to do with the garbage collector? Can 
anyone explain further? Particularly the first increase.

Thanks....

-- 
Glenn Stone
CSIRO Bioinformatics
http://www.bioinformatics.csiro.au



From ajayshah at mayin.org  Thu Aug  4 03:03:21 2005
From: ajayshah at mayin.org (Ajay Narottam Shah)
Date: Thu, 4 Aug 2005 06:33:21 +0530
Subject: [R] Puzzled at rpart prediction
Message-ID: <20050804010321.GA17700@lubyanka.local>

I'm in a situation where I say:

> predict(m.rpart, newdata=D[N1+t,])
      0   1
173 0.8 0.2

which I interpret as meaning: an 80% chance of "0" and a 20% chance of
"1". Okay. This is consistent with:

> predict(m.rpart, newdata=D[N1+t,], type="class")
[1] 0
Levels: 0 1

But I'm puzzled at the following. If I say:

> predict(m.rpart, newdata=D[N1+t,], type="vector")
173 
  1 

What gives?

I will be happy to packup a runnable demonstration for any of you, but
I wondered if it was just my lack of knowledge about "type" in
predict.rpart; wondered if there was a simple and logical explanation.

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From bernd.weiss at uni-koeln.de  Thu Aug  4 08:11:37 2005
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Thu, 04 Aug 2005 08:11:37 +0200
Subject: [R] Multilevel logistic regression using lmer vs glmmPQL
	vs.gllamm in Stata
In-Reply-To: <0IKN007Y34QX8U@mail.fudan.edu.cn>
Message-ID: <42F1CDB9.21518.DAA94B@localhost>

Am 3 Aug 2005 um 18:02 hat ronggui geschrieben:

> >On Wed, 3 Aug 2005, Bernd Weiss wrote:
> >
> >> I am trying to replicate some multilevel models with binary
> >> outcomes using R's "lmer" and "glmmPQL" and Stata's gllmm,
> >> respectively.

[...]

> the glmmPQL and lmer both use the PQL method to do it ,so can we get
> the same result by setting some options to the command?
> 

Thanks to Prof. Ripley and ronggui for their answers. 

To verify my findings I tried other datasets and simulated some data 
and compared the results between R and Stata. Everything works fine, 
no differences -- except for the xerop-dataset. 

Having a closer look to the R output I found some unusual values for 
AIC, BIC and deviance, see below:

           AIC           BIC         logLik      deviance
 1.797693e+308 1.797693e+308 -8.988466e+307 1.797693e+308    

I assume I have to change some of the lmer-parameters but have 
absolutely no idea which one. 

Again, I would appreciate any help.

Bernd



From Jin.Li at csiro.au  Thu Aug  4 08:15:51 2005
From: Jin.Li at csiro.au (Jin.Li@csiro.au)
Date: Thu, 4 Aug 2005 16:15:51 +1000
Subject: [R] how to test this
Message-ID: <2BEE99D7F6F1484EBDD1D22167385E7514DC97@exqld1-ath.nexus.csiro.au>

Thank you all for the reply.
Regards,
Jin

-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Wednesday, 3 August 2005 5:20 P
To: Simon Blomberg
Cc: Li, Jin (CSE, Atherton); r-help at stat.math.ethz.ch
Subject: Re: [R] how to test this

On Wed, 3 Aug 2005, Simon Blomberg wrote:

> This is two tests: Whether the slope != 1 and whether the intercept !=
0.

Neither model given has an intercept ....

> To do this, include an offset in your model:
>
> fit  <- lm(y ~ x + offset(x), data=dat)

but no intercept, so use

summary(lm(y ~ 0 + x + offset(1.05*x), data=dat))

and look if the coefficient of x is significantly different from zero.

E.g.

x <- 1:10
set.seed(1)
y <- 1.05*x + rnorm(10)
summary(lm(y ~ 0 + x + offset(1.05*x)))

Coefficients:
   Estimate Std. Error t value Pr(>|t|)
x  0.03061    0.03910   0.783    0.454

is not.


>
> HTH,
>
> Simon.
>
>
> At 03:44 PM 3/08/2005, Jin.Li at csiro.au wrote:
>>
>> I am wondering how to test whether a simple linear regression model
>> (e.g. y=1.05x) is significantly different from a 1 to 1 line (i.e.
y=x).


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Aug  4 08:15:41 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 4 Aug 2005 07:15:41 +0100 (BST)
Subject: [R] Odd timing behaviour in reading a file
In-Reply-To: <42F18D34.9000007@csiro.au>
References: <42F18D34.9000007@csiro.au>
Message-ID: <Pine.LNX.4.61.0508040711200.4397@gannet.stats>

Please see the gcFirst argument to system.time, which you should set to 
TRUE for such timings.  Your second run is paying to GC the results of the 
first, most likely.

Beyond that, R adjusts its GC triggers based on usage, and when you first 
start using large objects the trigger levels will grow and generally 
things will speed up.  Set gcinfo(TRUE) to watch what is happening.

On Thu, 4 Aug 2005, Glenn Stone wrote:

> Hi all,  please don't ask me why I tried this but.......
>
> I have observed some odd behaviour in the time taken to read a file. I
> tried searching the archives without much success, but that could be me.
>
> The first time I read a (60Mb) CSV file, takes a certain amount of time.
> The second time takes appreciably longer and the third and subsequent
> times very much shorter times. See below,
>
> $ R2.1.1
>
> R : Copyright 2005, The R Foundation for Statistical Computing
> Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>  Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
>
> > system.time(temp <-
> read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
> [1] 32.55  0.30 33.46  0.00  0.00
> > system.time(temp <-
> read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
> [1] 45.32  0.24 45.72  0.00  0.00
> > system.time(temp <-
> read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
> [1] 11.73  0.17 11.94  0.00  0.00
> > system.time(temp <-
> read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
> [1] 8.58 0.28 8.96 0.00 0.00
> > system.time(temp <-
> read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
> [1] 8.80 0.16 9.02 0.00 0.00
>
>
> This is a relatively quiet opteron running redhat linux and using R2.1.1
> The same pattern is repeatable, and occurs in R2.0.1 and on a Dell
> laptop running Windows XP.
>
> I guess it is probably something to do with the garbage collector? Can
> anyone explain further? Particularly the first increase.
>
> Thanks....
>
> -- 
> Glenn Stone
> CSIRO Bioinformatics
> http://www.bioinformatics.csiro.au
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Thu Aug  4 09:35:40 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 04 Aug 2005 09:35:40 +0200
Subject: [R] Eclipse, R, plug-in?
In-Reply-To: <245E2ABB-D80B-4527-ACF7-BAC37D2B011A@alum.calberkeley.org>
References: <245E2ABB-D80B-4527-ACF7-BAC37D2B011A@alum.calberkeley.org>
Message-ID: <42F1C54C.1070201@statistik.uni-dortmund.de>

Robert Citek wrote:

> Has any developed or is anyone developing a plug-in[1] for using R  
> with Eclipse[2]?

Stephan Wahlbrink made a Plug-In available at
http://www.walware.de/goto/statet

Uwe Ligges


> Eclipse is an Integrated Development Environment (IDE) written in  
> Java.  While originally used as an IDE for Java, it has become an  
> nice environment for developing and testing in other languages, too,  
> including perl, C#, PHP, python, PL/SQL, among many others.
> 
> [1] http://www.eclipse.org/community/osplugins.html
> [2] http://www.eclipse.org/
> 
> Regards,
> - Robert
> http://www.cwelug.org/downloads
> Help others get OpenSource software.  Distribute FLOSS
> for Windows, Linux, *BSD, and MacOS X with BitTorrent
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Thu Aug  4 09:44:59 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 04 Aug 2005 09:44:59 +0200
Subject: [R] Puzzled at rpart prediction
In-Reply-To: <20050804010321.GA17700@lubyanka.local>
References: <20050804010321.GA17700@lubyanka.local>
Message-ID: <42F1C77B.5000002@statistik.uni-dortmund.de>

Ajay Narottam Shah wrote:

> I'm in a situation where I say:
> 
> 
>>predict(m.rpart, newdata=D[N1+t,])
> 
>       0   1
> 173 0.8 0.2
> 
> which I interpret as meaning: an 80% chance of "0" and a 20% chance of
> "1". Okay. This is consistent with:
> 
> 
>>predict(m.rpart, newdata=D[N1+t,], type="class")
> 
> [1] 0
> Levels: 0 1
> 
> But I'm puzzled at the following. If I say:
> 
> 
>>predict(m.rpart, newdata=D[N1+t,], type="vector")
> 
> 173 
>   1 
> 
> What gives?

This means that the class of the first level is chosen, and the first 
level is "0".

Uwe Ligges


> I will be happy to packup a runnable demonstration for any of you, but
> I wondered if it was just my lack of knowledge about "type" in
> predict.rpart; wondered if there was a simple and logical explanation.
>



From t.gill1 at uq.edu.au  Thu Aug  4 10:02:55 2005
From: t.gill1 at uq.edu.au (Tony Gill)
Date: Thu, 4 Aug 2005 18:02:55 +1000
Subject: [R] how to read individual values from a pixmap object
Message-ID: <200508040803.j7482uWZ096963@smtp1.uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050804/26481fff/attachment.pl

From p.dalgaard at biostat.ku.dk  Thu Aug  4 10:05:27 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 04 Aug 2005 10:05:27 +0200
Subject: [R] multivariate F distribution
In-Reply-To: <42F158A0.70603@niss.org>
References: <42F158A0.70603@niss.org>
Message-ID: <x2wtn2xh2w.fsf@turmalin.kubism.ku.dk>

Anna Oganyan <aoganyan at niss.org> writes:

> Dear List,
> 
> Is there any function in R to generate multivariate F distribution with 
> given correlation/covariance matrix?
> 
> Actually, I just want to generate some 2-dimentional non-normal data 
> sets (skewed) for low (may be around 0.3 cor coeff.) negatively and also 
> positively correlated variables 

> 
> Thanks in advance.
> 
> Anna

Er, what is "multivariate F"? I have a guess (solve(A,B) where A and B
have independent Wishart distributions with the same covariance matrix
-- the matrix that gets summarized into Wilk's Lambda, Pillai's trace,
etc.) but Googling also pops up something about "inverted Dirichlet"
which may or may not be equivalent.

Wishart variates can be generate from (multivariate) normals in a
brute-force way using crossprod(). Some may have thought up a more
efficient way.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ogabbrie at tin.it  Thu Aug  4 10:18:49 2005
From: ogabbrie at tin.it (Simone Gabbriellini)
Date: Thu, 4 Aug 2005 10:18:49 +0200
Subject: [R] problem with for()
In-Reply-To: <1123108795.4100.19.camel@localhost.localdomain>
References: <5860A155-CE7B-4BDF-A184-282E5D23F9F4@tin.it>
	<1123105050.4100.13.camel@localhost.localdomain>
	<FA0F39D3-A8EE-47A9-80D6-C1EA49BD9C36@tin.it>
	<1123108795.4100.19.camel@localhost.localdomain>
Message-ID: <6BA257B4-0F4A-4C65-968E-E85F0D0F6410@tin.it>

Marc,
I did it with the simple trick of keepin separate vector values and  
index values, as you suggested in your mail

it was simple, but you know, it's always simple when you've done it :)

thank you very much,
simone

Il giorno 04/ago/05, alle ore 00:39, Marc Schwartz ha scritto:

> It would help to have an example of what it is you are trying to do.
>
> Importantly, keep separate the need to have zero be a value in a  
> vector
> as opposed to using zero to index a vector.
>
> As I note below in my reply, you can have:
>
>
>> x <- 0:5
>>
>
>
>> x
>>
> [1] 0 1 2 3 4 5
>
>
>> x ^ 2
>>
> [1]  0  1  4  9 16 25
>
> Marc
>
> On Thu, 2005-08-04 at 00:25 +0200, Simone Gabbriellini wrote:
>
>> how can I have a 0 evaluated in my loop then?
>> it is important for my algorithm
>>
>> do you have any hints?
>>
>> simone
>>
>> Il giorno 03/ago/05, alle ore 23:37, Marc Schwartz ha scritto:
>>
>>
>>> On Wed, 2005-08-03 at 23:24 +0200, Simone Gabbriellini wrote:
>>>
>>>
>>>> Dear list,
>>>> can someone tell me why this two pieces of code give me the same
>>>> results?
>>>>
>>>>
>>>>
>>>>> for(i in 0:5){ sum[i] = i }
>>>>> sum
>>>>>
>>>>>
>>>> [1] 1 2 3 4 5
>>>>
>>>>
>>>>
>>>>> for(i in 1:5){ sum[i] = i }
>>>>> sum
>>>>>
>>>>>
>>>> [1] 1 2 3 4 5
>>>>
>>>> shouldn't the first one be
>>>>
>>>> 0 1 2 3 4 5
>>>>
>>>> thank you,
>>>> simone
>>>>
>>>>
>>>
>>> No....the indexing of R objects is 1 based. Thus your first loop  
>>> tried
>>> to set i[0], which is a non-existent entry.
>>>
>>>
>>>
>>>> i <- 0:5
>>>>
>>>>
>>>
>>>
>>>
>>>> i
>>>>
>>>>
>>> [1] 0 1 2 3 4 5
>>>
>>>
>>>
>>>> i[0]
>>>>
>>>>
>>> numeric(0)
>>>
>>>
>>>
>>>> i[1]
>>>>
>>>>
>>> [1] 0
>>>
>>> HTH,
>>>
>>> Marc Schwartz
>>>
>>>
>>>
>>>
>>>
>
>



From p.dalgaard at biostat.ku.dk  Thu Aug  4 10:26:40 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 04 Aug 2005 10:26:40 +0200
Subject: [R] Eclipse, R, plug-in?
In-Reply-To: <42F1C54C.1070201@statistik.uni-dortmund.de>
References: <245E2ABB-D80B-4527-ACF7-BAC37D2B011A@alum.calberkeley.org>
	<42F1C54C.1070201@statistik.uni-dortmund.de>
Message-ID: <x2slxqxg3j.fsf@turmalin.kubism.ku.dk>

Uwe Ligges <ligges at statistik.uni-dortmund.de> writes:

> Robert Citek wrote:
> 
> > Has any developed or is anyone developing a plug-in[1] for using R  
> > with Eclipse[2]?
> 
> Stephan Wahlbrink made a Plug-In available at
> http://www.walware.de/goto/statet
> 
> Uwe Ligges

Cool. Especially now that Eclipse exists in an entirely Free Software
variant (GNU classpath) that ships with FC4. Judging from Stephan's
comments there is still work to be done, though.

I seem to recall that there is an S-PLUS plugin in the latest version,
but we haven't received it yet.

        -p

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From plummer at iarc.fr  Thu Aug  4 10:30:07 2005
From: plummer at iarc.fr (Martyn Plummer)
Date: Thu, 04 Aug 2005 10:30:07 +0200
Subject: [R] using weighted.mean with tapply()
In-Reply-To: <1db7268005080314007e1fdb1b@mail.gmail.com>
References: <1db7268005080314007e1fdb1b@mail.gmail.com>
Message-ID: <1123144207.3557.28.camel@seurat>

On Wed, 2005-08-03 at 17:00 -0400, roger bos wrote:
> I am trying to calculate the weighted mean for a of 10 deciles and I
> get an error:
> > decile <- tapply(X=mat$trt1m, INDEX=mat$Rank, FUN=weighted.mean, w=mat$mcap)
> Error in FUN(X[[1]], ...) : 'x' and 'w' must have the same length
> 
> All three of my inputs have the same length, as shown below, and the
> weighted.mean calculation works by itself, just not in tapply()
> 
> > length(mat$Rank)
> [1] 1853
> > length(mat$mcap)
> [1] 1853
> > length(mat$trt1m)
> [1] 1853
> > mean(mat$trt1m)
> [1] -0.04475397
> weighted.mean(mat$trt1m, w=mat$mcap)
> [1] -0.04819243
> > mat$mcap[is.na(mat$mcap)] <- min(mat$mcap, na.rm=TRUE)
> 
> I am probably making a simple error in how I pass the optional
> parameter w.  Any help would be greatly appreciated.

When you use tapply, only the first argument of the function you supply
is split by the index variable.  There is no way for tapply to know if
further arguments should be split or not, so it doesn't split them.  
People are regularly caught out by this.  If you look carefully at the
documentation for split, there is a warning about it.

Here is a very dense solution (due to Peter Dalgaard):

by(mat, mat$Rank, with, weighted.mean(trt1m,  mcap))

Alternatively you can split up the data frame using split, write your
own custom wrapper function for doing the weighted mean, and use lapply
or sapply:

sapply(split(mat,mat$Rank), function(x) {weighted.mean(x$trt1m,x$mcap)})

Martyn



-----------------------------------------------------------------------
This message and its attachments are strictly confidential. ...{{dropped}}



From dimitris.rizopoulos at med.kuleuven.be  Thu Aug  4 10:43:15 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Thu, 4 Aug 2005 10:43:15 +0200
Subject: [R] multivariate F distribution
References: <42F158A0.70603@niss.org> <x2wtn2xh2w.fsf@turmalin.kubism.ku.dk>
Message-ID: <016801c598d0$8e5b6120$0540210a@www.domain>

Well, there is a way for constructing a "multivariate F" (i.e., a 
multivariate distribution with F marginals), using copulas, thanks to 
Jun Yan's copula package. For instance, in for the bivariate case

library(copula)
x <- mvdc(claytonCopula(2), c("f", "f"),
          list(list(df1 = 8, df2 = 9), list(df1 = 8, df2 = 9)))
x
contour(x, dmvdc, xis = seq(1e-04, 2, len = 51), yis = seq(1e-04, 2, 
len = 51))

x.samp <- rmvdc(x, 1000)
hist(x.samp[, 1])
hist(x.samp[, 2])


Regarding the "correlation", the Clayton copula for theta = 2 gives 
Kendall's tau = 0.5, e.g.,

cor(x.samp, method = "kendall")


Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Peter Dalgaard" <p.dalgaard at biostat.ku.dk>
To: "Anna Oganyan" <aoganyan at niss.org>
Cc: <r-help at stat.math.ethz.ch>
Sent: Thursday, August 04, 2005 10:05 AM
Subject: Re: [R] multivariate F distribution


Anna Oganyan <aoganyan at niss.org> writes:

> Dear List,
>
> Is there any function in R to generate multivariate F distribution 
> with
> given correlation/covariance matrix?
>
> Actually, I just want to generate some 2-dimentional non-normal data
> sets (skewed) for low (may be around 0.3 cor coeff.) negatively and 
> also
> positively correlated variables .
>
> Thanks in advance.
>
> Anna

Er, what is "multivariate F"? I have a guess (solve(A,B) where A and B
have independent Wishart distributions with the same covariance matrix
-- the matrix that gets summarized into Wilk's Lambda, Pillai's trace,
etc.) but Googling also pops up something about "inverted Dirichlet"
which may or may not be equivalent.

Wishart variates can be generate from (multivariate) normals in a
brute-force way using crossprod(). Some may have thought up a more
efficient way.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 
35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 
35327907

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From nbrailo at cca.edu  Thu Aug  4 11:27:13 2005
From: nbrailo at cca.edu (Nensi Brailo)
Date: Thu, 04 Aug 2005 02:27:13 -0700
Subject: [R] nbrailo@ccac-art.edu
In-Reply-To: <1089005388-444877482@mail2.cca.edu>
Message-ID: <react-8845419@cca.edu>

I will be on vacation until August 11, 2005.  
I will respond to your message when I return.  Thank you.  

If you need immediate assistance please call or e-mail the following:

for circulation related questions please call Meyer Library Circulation 
at 510-594-3658
for reference assistance please call Simpson Library at 415-703-9574
for reference and ARTstore related questions please call Jon Worona at 
415-551-9252 or e-mail jworona at cca.edu 

--Nensi Brailo, Librarian
Meyer Library, California College of the Arts 

P.S. For more information please visit the CCA Libraries website at http://library.cca.edu



From GDiTanna at Regione.Emilia-Romagna.it  Thu Aug  4 11:52:05 2005
From: GDiTanna at Regione.Emilia-Romagna.it (Di Tanna Gian Luca)
Date: Thu, 4 Aug 2005 11:52:05 +0200
Subject: [R] fit non linear model using weighted least squares
Message-ID: <B08D5829F162FE4BBA1AE4F3CEBB45A7937EAD@asr02srv.ente.regione.emr.it>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050804/fe068960/attachment.pl

From W.E.Wolski at newcastle.ac.uk  Thu Aug  4 11:57:43 2005
From: W.E.Wolski at newcastle.ac.uk (nwew)
Date: Thu, 4 Aug 2005 10:57:43 +0100
Subject: [R] optim
Message-ID: <42F05039@webmail.ncl.ac.uk>

Dear R-helpers,

The function optim implements algorithms that I would like to use.


I have function implemented in R, which given the parameters of which 
minimization is to take place returns a scalar as well as the gradient.

Unfortunately optim requires two function _fn_ and _gr_ where fn returns the 
function value and gr the gradient. Splitting my function in two functions 
would be easy, however I am wondering if evaluating both is not doubling the 
the very high computational costs. Most of the computational intensive 
operations are identical if computing the function value and gradient.

Question: is there a way to tweek optim that only one function evaluation is 
necessary? Are ther other implementations of the algorithm, which do assume 
that the function to be minimized returns the function value and the gradient 
as well?

Thanks
Eryk.



From Roger.Bivand at nhh.no  Thu Aug  4 11:59:37 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 4 Aug 2005 11:59:37 +0200 (CEST)
Subject: [R] help for cell2nb and queencell in spdep package
In-Reply-To: <15f8e67d0508031238629887e4@mail.gmail.com>
Message-ID: <Pine.LNX.4.44.0508041142370.32407-100000@reclus.nhh.no>

On Wed, 3 Aug 2005, ecoinfo wrote:

> Dear Dr. Bivand and R-users,
>  I have a 5 by 5 grid, say, location[1:5,1:5], and I want to know the 
> indices of 8 neighbours of each cell. For example, for location[2,2], its 
> neighbour coordinates are [1,1:3], [2,1], [2,3] and [3,1:3]. Sometimes I 
> also need to remove edge effects (torus = TRUE).
>  I have tried "cell2nb" function in your spdep package. Here's my example:
>  > neigh <- cell2nb(5,5,type="queen",torus=T)
> > neigh
> Neighbour list object:
> Number of regions: 25 
> Number of nonzero links: 200 
> Percentage nonzero weights: 32 
> Average number of links: 8 
> > neigh[1]
> [[1]]
> [1] 2 5 6 7 10 21 22 25
>  Is there way to index each element of neigh[1], i.e., the first is 2, the 
> second is 5, ... ? 

neigh is a list of integer vectors, so you can use standard indexing:

> neigh[[1]][1]
[1] 2

using double square brackets for accessing the list components, and single 
for the vector elements. I think this is what you are asking for, if not, 
please clarify. To find out which (row, column) address this corresponds 
to, look it up in the "region.id" attribute:

> attr(neigh, "region.id")[neigh[[1]][1]]
[1] "2:1"

>  Could you also give me an example of the function "queencell(rowcol, nrow, 
> ncol, torus=FALSE, rmin=1, cmin=1)"? What's a rowcol? 

>From the help page: 

	"rowcol: matrix with two columns of row, column indices"

The queencell function is used internally, but takes a single row matrix 
of (row, column) indices, and returns a matrix of (row, column) indices 
for the contiguous neighbours of that cell:

> queencell(matrix(c(1,1),1,2), 8, 8, TRUE)
     row col
[1,]   2   8
[2,]   1   8
[3,]   8   8
[4,]   2   1
[5,]   8   1
[6,]   2   2
[7,]   1   2
[8,]   8   2
attr(,"coords")
[1] 1 1

for your case on a torus.

Hope this helps,

Roger

>  Thanks,
> Xiaohua
> 
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From murdoch at stats.uwo.ca  Thu Aug  4 12:22:46 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 04 Aug 2005 06:22:46 -0400
Subject: [R] optim
In-Reply-To: <42F05039@webmail.ncl.ac.uk>
References: <42F05039@webmail.ncl.ac.uk>
Message-ID: <42F1EC76.2050807@stats.uwo.ca>

nwew wrote:
> Dear R-helpers,
> 
> The function optim implements algorithms that I would like to use.
> 
> 
> I have function implemented in R, which given the parameters of which 
> minimization is to take place returns a scalar as well as the gradient.
> 
> Unfortunately optim requires two function _fn_ and _gr_ where fn returns the 
> function value and gr the gradient. Splitting my function in two functions 
> would be easy, however I am wondering if evaluating both is not doubling the 
> the very high computational costs. Most of the computational intensive 
> operations are identical if computing the function value and gradient.
> 
> Question: is there a way to tweek optim that only one function evaluation is 
> necessary? Are ther other implementations of the algorithm, which do assume 
> that the function to be minimized returns the function value and the gradient 
> as well?

I don't know the answer to your question, but here's a different 
approach.  Write a function that effectively splits your single function 
into two:

splitfn <- function(f) {
   lastx <- NA
   lastfn <- NA
   lastgr <- NA

   doeval <- function(x) {
     if (identical(all.equal(x, lastx), TRUE)) return(lastfn)
     lastx <<- x
     both <- f(x)
     lastfn <<- both$fnval
     lastgr <<- both$grval
     return(lastfn)
   }

   fn <- function(x) doeval(x)

   gr <- function(x) {
     doeval()
     lastgr
   }

   list(fn=fn, gr=gr)
}

I haven't tested this, but the idea is that it sets up a local 
environment where the last x value and last function and gradient values 
are stored.  If the next call asks for the same x, then the cached 
values are returned.  I don't know if it will actually improve 
efficiency:  that depends on whether optim evaluates the gradient and 
function values at the same points or at different points.

You would use this as follows, assuming your function is called f:

  f2 <- splitfn(f)

  optim(par, f2$fn, f2$gr, ...)

Duncan Murdoch



From ripley at stats.ox.ac.uk  Thu Aug  4 12:23:08 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 4 Aug 2005 11:23:08 +0100 (BST)
Subject: [R] optim
In-Reply-To: <42F05039@webmail.ncl.ac.uk>
References: <42F05039@webmail.ncl.ac.uk>
Message-ID: <Pine.LNX.4.61.0508041117540.25798@gannet.stats>

On Thu, 4 Aug 2005, nwew wrote:

> Dear R-helpers,
>
> The function optim implements algorithms that I would like to use.

They are available to you as part of the R API at C level.

> I have function implemented in R, which given the parameters of which
> minimization is to take place returns a scalar as well as the gradient.
>
> Unfortunately optim requires two function _fn_ and _gr_ where fn returns the
> function value and gr the gradient. Splitting my function in two functions
> would be easy, however I am wondering if evaluating both is not doubling the
> the very high computational costs. Most of the computational intensive
> operations are identical if computing the function value and gradient.

That is an unusual situation.

> Question: is there a way to tweek optim that only one function evaluation is
> necessary? Are ther other implementations of the algorithm, which do assume
> that the function to be minimized returns the function value and the gradient
> as well?

You can of course write your function to cache the work and check if the
parameter value is unchanged from the last call.  Then if the optimizer 
calls for the gradient after the function value in the same place (and 
most methods will) you can just do the additional work for the gradient.

That is what nnet does, at C level.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From a.ali at agrhymet.ne  Thu Aug  4 11:23:01 2005
From: a.ali at agrhymet.ne (Abdou ALI)
Date: Thu, 4 Aug 2005 11:23:01 +0200
Subject: [R] additional graphical parameters in contour function
Message-ID: <000601c598d6$1c785a80$7201a8c0@Portableabdou>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050804/6214a193/attachment.pl

From sundar.dorai-raj at pdf.com  Thu Aug  4 12:24:41 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 04 Aug 2005 05:24:41 -0500
Subject: [R] optim
In-Reply-To: <42F05039@webmail.ncl.ac.uk>
References: <42F05039@webmail.ncl.ac.uk>
Message-ID: <42F1ECE9.2060305@pdf.com>



nwew wrote:
> Dear R-helpers,
> 
> The function optim implements algorithms that I would like to use.
> 
> 
> I have function implemented in R, which given the parameters of which 
> minimization is to take place returns a scalar as well as the gradient.
> 
> Unfortunately optim requires two function _fn_ and _gr_ where fn returns the 
> function value and gr the gradient. Splitting my function in two functions 
> would be easy, however I am wondering if evaluating both is not doubling the 
> the very high computational costs. Most of the computational intensive 
> operations are identical if computing the function value and gradient.
> 
> Question: is there a way to tweek optim that only one function evaluation is 
> necessary? Are ther other implementations of the algorithm, which do assume 
> that the function to be minimized returns the function value and the gradient 
> as well?
> 
> Thanks
> Eryk.
> 

Hi, Eryk,

?optim does not *require* the "gr" argument. If one is not supplied, 
numerical gradients are used for which optim evaluates "fn" twice. 
However, in many cases analytical gradients can both improve numerical 
accuracy and computational speed.

Trivial example:

fn <- function(beta) {
   sum((y - x %*% beta)^2)
}

gr <- function(beta) {
   colSums(-2 * x * drop((y - x %*% beta)))
}

set.seed(1)
n <- 10000
p <- 5
g <- factor(rep(LETTERS[1:p], each = n/p))
x <- model.matrix(~g)
beta <- rnorm(p)
y <- drop(x %*% beta + rnorm(n))
start <- rep(0, p)

system.time(f1 <- optim(start, fn, gr, hessian = TRUE))
# [1] 0.47 0.00 0.48   NA   NA

system.time(f2 <- optim(start, fn, hessian = TRUE))
# [1] 0.54 0.00 0.53   NA   NA

f1$par
#[1] -0.6408643  0.2128109 -0.8378791  1.5983054  0.3366216

f2$par
#[1] -0.6408643  0.2128109 -0.8378791  1.5983054  0.3366216

f1$hessian
#      [,1] [,2] [,3] [,4] [,5]
#[1,] 20000 4000 4000 4000 4000
#[2,]  4000 4000    0    0    0
#[3,]  4000    0 4000    0    0
#[4,]  4000    0    0 4000    0
#[5,]  4000    0    0    0 4000

f2$hessian
#      [,1]         [,2] [,3]         [,4] [,5]
#[1,] 20000 4.000000e+03 4000 4.000000e+03 4000
#[2,]  4000 4.000000e+03    0 2.273737e-07    0
#[3,]  4000 0.000000e+00 4000 0.000000e+00    0
#[4,]  4000 2.273737e-07    0 4.000000e+03    0
#[5,]  4000 0.000000e+00    0 0.000000e+00 4000
#

Does this answer your question? Furthermore, have you read the chapter 
in MASS that discusses optim?

HTH,

--sundar



From Roger.Bivand at nhh.no  Thu Aug  4 12:25:24 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 4 Aug 2005 12:25:24 +0200 (CEST)
Subject: [R] how to read individual values from a pixmap object
In-Reply-To: <200508040803.j7482uWZ096963@smtp1.uq.edu.au>
Message-ID: <Pine.LNX.4.44.0508041207140.32407-100000@reclus.nhh.no>

On Thu, 4 Aug 2005, Tony Gill wrote:

> Hi All,
>  
> I have a greyscale image that I am reading in through RGDAL and placing in a
> pixmap object.
>  
> As an example use the logo.jpg file that comes with the RGDAL package:
>  
> #Read the file
> logo <- system.file("pictures/logo.jpg", package="rgdal")[1]
> x <- new("GDALReadOnlyDataset", logo)
>  
> #Create the pixmap object
> xGrey <- getPixmapGDAL(x)
>  
> Now I would like to read individual pixel values and store them in a
> separate vector. However I have not found a straight-forward way to do this.
>  
> I thought that something like:
>  
> x <- xGrey[1,1]
>  
> would return the pixel value, but it seems to return a pixmap object with
> dimension 1x1 (i.e. only one pixel in size)
>  
> xGrey[1,1]
> Pixmap image
>   Type          : pixmapGrey 
>   Size          : 1x1 
>   Resolution    : 1x1 
>   Bounding box  : 1 0 2 1
>  
> Any ideas on how to get the actual pixel value from a pixmap? (Note I could
> output to an ascii file and then read the file back in as text - but not
> nice!)
>  

There are lots of ideas in the S4 Classes and Methods useR! 04 keynote
talk given by pixmap maintainer Friedrich Leisch at:  

http://www.ci.tuwien.ac.at/Conferences/useR-2004/Keynotes/Leisch.pdf

but the easiest one is:

> setAs("pixmapGrey", "matrix", function(from, to) {from at grey})
> x
Pixmap image
  Type          : pixmapGrey 
  Size          : 1x1 
  Resolution    : 1x1 
  Bounding box  : 0 0 1 1 

> as(x, "matrix")
     [,1]
[1,]    1

unless you use a hammer and chisel:

> str(x)
Formal class 'pixmapGrey' [package "pixmap"] with 6 slots
  ..@ grey    : num [1, 1] 1
  ..@ channels: chr "grey"
  ..@ size    : int [1:2] 1 1
  ..@ cellres : num [1:2] 1 1
  ..@ bbox    : num [1:4] 0 0 1 1
  ..@ bbcent  : logi FALSE
> x at grey
     [,1]
[1,]    1



> Thanks in advance
>  
> Tony
>  
> ******************************************
> Tony Gill - PhD Candidate
> Centre for Remote Sensing & Spatial Information Science
> School of Geography, Planning & Architecture
> University of Queensland
> Brisbane, Queensland, AUSTRALIA, 4072
> Ph: 61-7-3365-7027
> email: t.gill1 at uq.edu.au
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From blindglobe at gmail.com  Thu Aug  4 12:48:58 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Thu, 4 Aug 2005 12:48:58 +0200
Subject: [R] Eclipse, R, plug-in?
In-Reply-To: <x2slxqxg3j.fsf@turmalin.kubism.ku.dk>
References: <245E2ABB-D80B-4527-ACF7-BAC37D2B011A@alum.calberkeley.org>
	<42F1C54C.1070201@statistik.uni-dortmund.de>
	<x2slxqxg3j.fsf@turmalin.kubism.ku.dk>
Message-ID: <1abe3fa9050804034846eb789a@mail.gmail.com>

On 04 Aug 2005 10:26:40 +0200, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:

> I seem to recall that there is an S-PLUS plugin in the latest version,
> but we haven't received it yet.

I believe it's in the "enterprise edition" (which is the version with
"large datasets", etc), not the more common and less expensive
professional version.

best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe at gmail.com



From mmiller at nassp.uct.ac.za  Thu Aug  4 12:57:20 2005
From: mmiller at nassp.uct.ac.za (Mark Miller)
Date: Thu, 4 Aug 2005 12:57:20 +0200
Subject: [R] Using nonlinear regression
Message-ID: <200508041257.21030.mmiller@nassp.uct.ac.za>

Hi, I have been trying to figure out how to use the nonlinear regression to 
fit the cumulative lognormal distribution to a number of data points I have 
but I am a new R user and I cant quite decipher the notes on nonlinear 
regression.  Any help in this regard will be greatly appreciated, my email 
address is mmiller at nassp.uct.ac.za



From ligges at statistik.uni-dortmund.de  Thu Aug  4 12:58:58 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 04 Aug 2005 12:58:58 +0200
Subject: [R] additional graphical parameters in contour function
In-Reply-To: <000601c598d6$1c785a80$7201a8c0@Portableabdou>
References: <000601c598d6$1c785a80$7201a8c0@Portableabdou>
Message-ID: <42F1F4F2.8090809@statistik.uni-dortmund.de>

Abdou ALI wrote:

> Hello,
> Do you know why additional graphical parameters (like "type","pch", ...) do not work in the R contour fonction. For example the command 'contour(..., type="o",pch=16)' gives nothing, just simple contour lines.

Please, can you explain why you think it does make sense here?

Uwe Ligges


> Thank you for your response.
> 
> Abdou. 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at gmail.com  Thu Aug  4 13:02:26 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 4 Aug 2005 07:02:26 -0400
Subject: [R] optim
In-Reply-To: <42F05039@webmail.ncl.ac.uk>
References: <42F05039@webmail.ncl.ac.uk>
Message-ID: <971536df0508040402671011ea@mail.gmail.com>

Check out:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/18289.html

On 8/4/05, nwew <W.E.Wolski at newcastle.ac.uk> wrote:
> Dear R-helpers,
> 
> The function optim implements algorithms that I would like to use.
> 
> 
> I have function implemented in R, which given the parameters of which
> minimization is to take place returns a scalar as well as the gradient.
> 
> Unfortunately optim requires two function _fn_ and _gr_ where fn returns the
> function value and gr the gradient. Splitting my function in two functions
> would be easy, however I am wondering if evaluating both is not doubling the
> the very high computational costs. Most of the computational intensive
> operations are identical if computing the function value and gradient.
> 
> Question: is there a way to tweek optim that only one function evaluation is
> necessary? Are ther other implementations of the algorithm, which do assume
> that the function to be minimized returns the function value and the gradient
> as well?
> 
> Thanks
> Eryk.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From a.ali at agrhymet.ne  Thu Aug  4 12:26:53 2005
From: a.ali at agrhymet.ne (Abdou ALI)
Date: Thu, 4 Aug 2005 12:26:53 +0200
Subject: [R] additional graphical parameters in contour function
References: <000601c598d6$1c785a80$7201a8c0@Portableabdou>
	<42F1F4F2.8090809@statistik.uni-dortmund.de>
Message-ID: <002d01c598df$086e4320$7201a8c0@Portableabdou>


>> Do you know why additional graphical parameters (like "type","pch", ...) 
>> do not work in the R contour fonction. For example the command 
>> 'contour(..., type="o",pch=16)' gives nothing, just simple contour lines.
>
> Please, can you explain why you think it does make sense here?
>
The reason is that I want to add on a same graphic several contour plot, and 
I want to give different line types for each contour. I thus thought that 
these options of the contour function made it possible to do it.

Thank.


>
> Uwe Ligges
>
>
>> Thank you for your response.
>>
>> Abdou. [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>



From JAROSLAW.W.TUSZYNSKI at saic.com  Thu Aug  4 13:33:01 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Thu, 4 Aug 2005 07:33:01 -0400 
Subject: [R] color palette
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD57F4111@us-arlington-0668.mail.saic.com>

'Tim.colors' in 'fields' package goes from blue to red, and passes through
the colors cyan, yellow, and orange. Also known as Jet color-map in Matlab.
You can also easily design your own color map using 'rgb' function from
'gdDevices'.

Jarek
====================================================\=======

 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">   \
 Jaroslaw.W.Tuszynski at saic.com                     `    \



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of array chip
Sent: Wednesday, August 03, 2005 8:03 PM
To: r-help at stat.math.ethz.ch
Subject: [R] color palette

Hi, I have a matrix with both positive and negative numbers, I would like to
use image() to draw a heatmap. How can I can design a palette (or is there a
function already available) that treat negative numbers in a blue gradient
and positive numbers in a red gradient and treat 0 as white?

Thanks

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From hsantin-janin at gct.org.uk  Thu Aug  4 13:32:47 2005
From: hsantin-janin at gct.org.uk (Hugues Santin-Janin)
Date: Thu, 4 Aug 2005 12:32:47 +0100
Subject: [R] prediction from glm
Message-ID: <051EED336DB7264EA57EBB75CB87168C9CA29A@GCTHQ1.gct.org.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050804/22a64faa/attachment.pl

From sundar.dorai-raj at pdf.com  Thu Aug  4 13:34:27 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 04 Aug 2005 06:34:27 -0500
Subject: [R] additional graphical parameters in contour function
In-Reply-To: <002d01c598df$086e4320$7201a8c0@Portableabdou>
References: <000601c598d6$1c785a80$7201a8c0@Portableabdou>	<42F1F4F2.8090809@statistik.uni-dortmund.de>
	<002d01c598df$086e4320$7201a8c0@Portableabdou>
Message-ID: <42F1FD43.7060706@pdf.com>



Abdou ALI wrote:
>>>Do you know why additional graphical parameters (like "type","pch", ...) 
>>>do not work in the R contour fonction. For example the command 
>>>'contour(..., type="o",pch=16)' gives nothing, just simple contour lines.
>>
>>Please, can you explain why you think it does make sense here?
>>
> 
> The reason is that I want to add on a same graphic several contour plot, and 
> I want to give different line types for each contour. I thus thought that 
> these options of the contour function made it possible to do it.
> 
> Thank.
> 
> 
Hi, Abdou,

Then use "lty", not "type", as is shown in ?contour.

--sundar



From ligges at statistik.uni-dortmund.de  Thu Aug  4 13:36:45 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 04 Aug 2005 13:36:45 +0200
Subject: [R] additional graphical parameters in contour function
In-Reply-To: <002d01c598df$086e4320$7201a8c0@Portableabdou>
References: <000601c598d6$1c785a80$7201a8c0@Portableabdou>
	<42F1F4F2.8090809@statistik.uni-dortmund.de>
	<002d01c598df$086e4320$7201a8c0@Portableabdou>
Message-ID: <42F1FDCD.4020403@statistik.uni-dortmund.de>

Abdou ALI wrote:

> 
>>> Do you know why additional graphical parameters (like "type","pch", 
>>> ...) do not work in the R contour fonction. For example the command 
>>> 'contour(..., type="o",pch=16)' gives nothing, just simple contour 
>>> lines.
>>
>>
>> Please, can you explain why you think it does make sense here?
>>
> The reason is that I want to add on a same graphic several contour plot, 
> and I want to give different line types for each contour. I thus thought 
> that these options of the contour function made it possible to do it.

But these arguments do not refer to line types at all!

Use "lty" instead as in:

  x <- -6:16
  op <- par(mfrow = c(2, 1))
  contour(outer(x, x), method = "edge", lty=1)
  contour(outer(x, x), method = "edge", lty=2)

Uwe Ligges




> Thank.
> 
> 
>>
>> Uwe Ligges
>>
>>
>>> Thank you for your response.
>>>
>>> Abdou. [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>
>>



From bitwrit at ozemail.com.au  Fri Aug  5 00:01:59 2005
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Thu, 04 Aug 2005 22:01:59 +0000
Subject: [R] problem with for()
Message-ID: <42F29057.5080708@ozemail.com.au>

Simone Gabbriellini wrote:

 > it was simple, but you know, it's always simple when you've done it :)

Surely this homage to experience deserves nomination for the fortunes 
package.

Jim



From weismann_d at klinik.uni-wuerzburg.de  Thu Aug  4 14:03:09 2005
From: weismann_d at klinik.uni-wuerzburg.de (Weismann_D)
Date: Thu, 04 Aug 2005 14:03:09 +0200
Subject: [R] Graphics on MacOSX
Message-ID: <BF17D09D.E26%weismann_d@klinik.uni-wuerzburg.de>

Ist there a possibility on MacOSX to import Graphics into MSOffice
Applications and resize them there without decreased quality? When I import
via copy&paste I get low quality bitmaps and via import pictures (pdf) it is
all the same. In the Windows versions of R there is the convienient way to
use metafile format which can easily be resized in ppt and word. What is the
equivalent way on MacOSX?
Thanks, Dirk.



From Friedrich.Leisch at tuwien.ac.at  Thu Aug  4 14:06:30 2005
From: Friedrich.Leisch at tuwien.ac.at (Friedrich.Leisch@tuwien.ac.at)
Date: Thu, 4 Aug 2005 14:06:30 +0200
Subject: [R] how to read individual values from a pixmap object
In-Reply-To: <200508040803.j7482uWZ096963@smtp1.uq.edu.au>
References: <200508040803.j7482uWZ096963@smtp1.uq.edu.au>
Message-ID: <17138.1222.269324.360745@celebrian.ci.tuwien.ac.at>

>>>>> On Thu, 4 Aug 2005 18:02:55 +1000,
>>>>> Tony Gill (TG) wrote:

[...]

  > Now I would like to read individual pixel values and store them in a
  > separate vector. However I have not found a straight-forward way to do this.
 
  > I thought that something like:
 
  > x <- xGrey[1,1]
 
  > would return the pixel value, but it seems to return a pixmap object with
  > dimension 1x1 (i.e. only one pixel in size)
 
  > xGrey[1,1]
  > Pixmap image
  >   Type          : pixmapGrey 
  >   Size          : 1x1 
  >   Resolution    : 1x1 
  >   Bounding box  : 1 0 2 1
 
  > Any ideas on how to get the actual pixel value from a pixmap? (Note I could
  > output to an ascii file and then read the file back in as text - but not
  > nice!)


getChannels(xGrey) will get you the matrix of pixel values.

HTH,

-- 
-------------------------------------------------------------------
                        Friedrich Leisch 
Institut f??r Statistik                     Tel: (+43 1) 58801 10715
Technische Universit??t Wien                Fax: (+43 1) 58801 10798
Wiedner Hauptstra??e 8-10/1071
A-1040 Wien, Austria             http://www.ci.tuwien.ac.at/~leisch



From Achim.Zeileis at wu-wien.ac.at  Thu Aug  4 14:17:26 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 4 Aug 2005 14:17:26 +0200
Subject: [R] problem with for()
In-Reply-To: <42F29057.5080708@ozemail.com.au>
References: <42F29057.5080708@ozemail.com.au>
Message-ID: <20050804141726.53725523.Achim.Zeileis@wu-wien.ac.at>

On Thu, 04 Aug 2005 22:01:59 +0000 Jim Lemon wrote:

> Simone Gabbriellini wrote:
> 
>  > it was simple, but you know, it's always simple when you've done it
>  > :)
> 
> Surely this homage to experience deserves nomination for the fortunes 
> package.

Thanks for the pointer, included in the package now. I've also
just submitted a new version (1.1-2) to CRAN, binary versions should be
available from the mirrors in the next days.
Z

> Jim
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From dvumani at hotmail.com  Thu Aug  4 14:33:57 2005
From: dvumani at hotmail.com (Vumani Dlamini)
Date: Thu, 04 Aug 2005 12:33:57 +0000
Subject: [R] drawing a network digraph
Message-ID: <BAY16-F27E3068B2DF60D79CFCDE6A3C40@phx.gbl>

Dear R users,
I have a matrix with 2 columns with the variables: "daughter index", "mother 
index". I would like to draw a network digraph using this data, where each 
daughter is connected to a mother and between the connections inlcude a 
circle with the information on the indices ("daughter index", "mother 
index"): i.e. something similar to graphs produced by graphviz.
I am clueless. I have looked at the libraries SEM and SNA but it looks like 
they can't help my cause.
Hope you help.
Vumani



From pberming at research.ryerson.ca  Thu Aug  4 14:42:47 2005
From: pberming at research.ryerson.ca (Philip Bermingham)
Date: Thu, 4 Aug 2005 08:42:47 -0400
Subject: [R] Modifying the parameters for a function
Message-ID: <91EDF384F07C0441BB0EEC1142618052147E81@mail3.arts.ryerson.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050804/3142a801/attachment.pl

From ligges at statistik.uni-dortmund.de  Thu Aug  4 14:49:48 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 04 Aug 2005 14:49:48 +0200
Subject: [R] Modifying the parameters for a function
In-Reply-To: <91EDF384F07C0441BB0EEC1142618052147E81@mail3.arts.ryerson.ca>
References: <91EDF384F07C0441BB0EEC1142618052147E81@mail3.arts.ryerson.ca>
Message-ID: <42F20EEC.3060007@statistik.uni-dortmund.de>

Philip Bermingham wrote:

> I have modified the parameters for a function (for my own use) in the
> stats package, but I assume I need to update the parameter set in
> another file as I'm getting the following error when I  run R:
> 
>  
> 
> The compile works fine so I assume there is a configuration file in the
> base package of R that needs modification.
> 
>  
> 
> Error in parse(file, n, text, prompt) : syntax error on line 11102

No, you have introduced an error, obviously.

Uwe Ligges

> Error: unable to load R code in package 'stats'
> 
> During startup - Warning message:
> 
> package stats in options("defaultPackages") was not found
> 
>  
> 
> Philip.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rpeng at jhsph.edu  Thu Aug  4 15:00:13 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 04 Aug 2005 09:00:13 -0400
Subject: [R] Modifying the parameters for a function
In-Reply-To: <91EDF384F07C0441BB0EEC1142618052147E81@mail3.arts.ryerson.ca>
References: <91EDF384F07C0441BB0EEC1142618052147E81@mail3.arts.ryerson.ca>
Message-ID: <42F2115D.1020103@jhsph.edu>

What exactly do you mean by "compile"?  What compile works fine?

-roger

Philip Bermingham wrote:
> I have modified the parameters for a function (for my own use) in the
> stats package, but I assume I need to update the parameter set in
> another file as I'm getting the following error when I  run R:
> 
>  
> 
> The compile works fine so I assume there is a configuration file in the
> base package of R that needs modification.
> 
>  
> 
> Error in parse(file, n, text, prompt) : syntax error on line 11102
> 
> Error: unable to load R code in package 'stats'
> 
> During startup - Warning message:
> 
> package stats in options("defaultPackages") was not found
> 
>  
> 
> Philip.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From sdavis2 at mail.nih.gov  Thu Aug  4 15:24:08 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Thu, 04 Aug 2005 09:24:08 -0400
Subject: [R] drawing a network digraph
In-Reply-To: <BAY16-F27E3068B2DF60D79CFCDE6A3C40@phx.gbl>
Message-ID: <BF178F38.B176%sdavis2@mail.nih.gov>

On 8/4/05 8:33 AM, "Vumani Dlamini" <dvumani at hotmail.com> wrote:

> Dear R users,
> I have a matrix with 2 columns with the variables: "daughter index", "mother
> index". I would like to draw a network digraph using this data, where each
> daughter is connected to a mother and between the connections inlcude a
> circle with the information on the indices ("daughter index", "mother
> index"): i.e. something similar to graphs produced by graphviz.
> I am clueless. I have looked at the libraries SEM and SNA but it looks like
> they can't help my cause.

Since you mention graphviz, why not use Rgraphviz available from
BioConductor?  There are other packages available for doing graphing.  A
search of the r-help archives will turn up some discussion in the past 1-2
weeks.

Sean



From sfalcon at fhcrc.org  Thu Aug  4 15:39:38 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 04 Aug 2005 06:39:38 -0700
Subject: [R] drawing a network digraph
In-Reply-To: <BAY16-F27E3068B2DF60D79CFCDE6A3C40@phx.gbl> (Vumani Dlamini's
	message of "Thu, 04 Aug 2005 12:33:57 +0000")
References: <BAY16-F27E3068B2DF60D79CFCDE6A3C40@phx.gbl>
Message-ID: <m2k6j195yd.fsf@fhcrc.org>

On  4 Aug 2005, dvumani at hotmail.com wrote:

> Dear R users, I have a matrix with 2 columns with the variables:
> "daughter index", "mother index". I would like to draw a network
> digraph using this data, where each daughter is connected to a
> mother and between the connections inlcude a circle with the
> information on the indices ("daughter index", "mother index"):
> i.e. something similar to graphs produced by graphviz.  I am
> clueless. I have looked at the libraries SEM and SNA but it looks
> like they can't help my cause.  Hope you help.  Vumani

You want the Rgraphviz package from Bioconductor.  To use Rgraphviz,
you will need to first install graphviz.  

To install Rgraphviz:

  If you are on a Linux type system with R-2.1.x:
      source("http://bioconductor.org/biocLite.R")
      biocLite("Rgraphviz")

  If you use Windows, you need to use an R-devel snapshot in order to
  (easily) access Bioconductor development packages (Rgraphviz was
  only recently ported to Windows).  But the commands to install are
  the same as above.

HTH,

+ seth



From pberming at research.ryerson.ca  Thu Aug  4 15:48:42 2005
From: pberming at research.ryerson.ca (Philip Bermingham)
Date: Thu, 4 Aug 2005 09:48:42 -0400
Subject: [R] Modifying the parameters for a function
Message-ID: <91EDF384F07C0441BB0EEC1142618052147EA7@mail3.arts.ryerson.ca>

When I compile the package I modified.

-----Original Message-----
From: Roger D. Peng [mailto:rpeng at jhsph.edu] 
Sent: Thursday, August 04, 2005 9:00 AM
To: Philip Bermingham
Cc: R-help at stat.math.ethz.ch
Subject: Re: [R] Modifying the parameters for a function

What exactly do you mean by "compile"?  What compile works fine?

-roger

Philip Bermingham wrote:
> I have modified the parameters for a function (for my own use) in the
> stats package, but I assume I need to update the parameter set in
> another file as I'm getting the following error when I  run R:
> 
>  
> 
> The compile works fine so I assume there is a configuration file in
the
> base package of R that needs modification.
> 
>  
> 
> Error in parse(file, n, text, prompt) : syntax error on line 11102
> 
> Error: unable to load R code in package 'stats'
> 
> During startup - Warning message:
> 
> package stats in options("defaultPackages") was not found
> 
>  
> 
> Philip.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From hugues_sj at yahoo.fr  Thu Aug  4 15:58:35 2005
From: hugues_sj at yahoo.fr (hugues santin janin)
Date: Thu, 4 Aug 2005 15:58:35 +0200 (CEST)
Subject: [R] prediction from glm
Message-ID: <20050804135835.30007.qmail@web25103.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050804/d8ad7fb4/attachment.pl

From HStevens at MUOhio.edu  Thu Aug  4 16:13:54 2005
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Thu, 4 Aug 2005 10:13:54 -0400
Subject: [R] Graphics on MacOSX
In-Reply-To: <BF17D09D.E26%weismann_d@klinik.uni-wuerzburg.de>
References: <BF17D09D.E26%weismann_d@klinik.uni-wuerzburg.de>
Message-ID: <9bf12bd680088cb944d1b84f7dc54267@MUOhio.edu>

This is a big issue for me, causing many days of angst. I finally 
stumbled on the following solution. I create a device save an image 
with postscript(). I then open it in Adobe Acrobat, select the area I 
want, enlarge to at least 400%, then copy, then paste into PowerPoint 
or Word. Alternatively, you can simply save a graphics image through 
the gui and it saves it as pdf. Then go through the steps of selecting, 
enlarging and copying in Acrobat. I am guessing real graphics programs 
would work as well (Photoshop or Illustrator), but I don't have those.

Hank Stevens


On Aug 4, 2005, at 8:03 AM, Weismann_D wrote:

> Ist there a possibility on MacOSX to import Graphics into MSOffice
> Applications and resize them there without decreased quality? When I 
> import
> via copy&paste I get low quality bitmaps and via import pictures (pdf) 
> it is
> all the same. In the Windows versions of R there is the convienient 
> way to
> use metafile format which can easily be resized in ppt and word. What 
> is the
> equivalent way on MacOSX?
> Thanks, Dirk.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>
Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From r.shengzhe at gmail.com  Thu Aug  4 16:18:43 2005
From: r.shengzhe at gmail.com (Shengzhe Wu)
Date: Thu, 4 Aug 2005 16:18:43 +0200
Subject: [R] Help: how to stop the process when there is a mishandling
Message-ID: <ea57975b05080407187acc3399@mail.gmail.com>

Hello,

How to stop the process when there is a mishandling making R system
frozen? If there is a way other than quitting the system when frozen
occurs?

Thank you,
Shengzhe



From murdoch at stats.uwo.ca  Thu Aug  4 16:33:22 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 04 Aug 2005 10:33:22 -0400
Subject: [R] Modifying the parameters for a function
In-Reply-To: <91EDF384F07C0441BB0EEC1142618052147E81@mail3.arts.ryerson.ca>
References: <91EDF384F07C0441BB0EEC1142618052147E81@mail3.arts.ryerson.ca>
Message-ID: <42F22732.3090706@stats.uwo.ca>

Philip Bermingham wrote:
> I have modified the parameters for a function (for my own use) in the
> stats package, but I assume I need to update the parameter set in
> another file as I'm getting the following error when I  run R:
> 
>  
> 
> The compile works fine so I assume there is a configuration file in the
> base package of R that needs modification.
> 
>  
> 
> Error in parse(file, n, text, prompt) : syntax error on line 11102
> 
> Error: unable to load R code in package 'stats'

This means that you've introduced a syntax error when you did your 
edits.  The line number information is fairly useless:  R has 
concatenated all of the files together, you don't see the original line 
number.  Your best strategy is to look at where you made changes.

I'm hoping to improve the error reporting on parse errors in R 2.2, but 
time is flying by...

Duncan Murdoch
> 
> During startup - Warning message:
> 
> package stats in options("defaultPackages") was not found
> 
>  
> 
> Philip.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rpeng at jhsph.edu  Thu Aug  4 16:39:45 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 04 Aug 2005 10:39:45 -0400
Subject: [R] Help: how to stop the process when there is a mishandling
In-Reply-To: <ea57975b05080407187acc3399@mail.gmail.com>
References: <ea57975b05080407187acc3399@mail.gmail.com>
Message-ID: <42F228B1.3000602@jhsph.edu>

On Unix you can send one of the 'USR' signals to 'kill'.  See 
?Signals.

-roger

Shengzhe Wu wrote:
> Hello,
> 
> How to stop the process when there is a mishandling making R system
> frozen? If there is a way other than quitting the system when frozen
> occurs?
> 
> Thank you,
> Shengzhe
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From efg at stowers-institute.org  Thu Aug  4 17:21:06 2005
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Thu, 4 Aug 2005 10:21:06 -0500
Subject: [R] red-black-green color palette?
References: <cbc7a1be7e3c68c0ccac507be8d3e7d8@comcast.net>
Message-ID: <dctbp3$85c$1@sea.gmane.org>

"Jake Michaelson" <jjmichael at comcast.net> wrote in message
news:cbc7a1be7e3c68c0ccac507be8d3e7d8 at comcast.net...
> I'm working on some heatmaps, and the person I'm working with would
> prefer a red-black-green color palette (red denoting gene induction and
> green denoting gene repression).  Does such a palette exist already?
> If not, is there an easy way to create one?

Here are four ways:

showpanel <- function(Colors)
{
  image(matrix(1:length(Colors), ncol=1), col=Colors, xaxt="n", yaxt="n" )
}

oldpar <- par(mfrow=c(4,2))

# Method 1 (colorRampPalette was new in R 2.1.0) in grDevices
# Same as function with same name in dichromat package?
showpanel(colorRampPalette( c("green", "black", "red"), space="rgb")(32))
showpanel(colorRampPalette( c("green", "black", "red"), space="rgb")(64))

# Method 2
library(gplots)
showpanel(greenred(32))
showpanel(redgreen(64))

# Method 3
library(geneplotter)
showpanel(greenred.colors(32))
showpanel(greenred.colors(64))

# Method 4
library("marray")
pal <- maPalette(low="green", high="red",mid="black")
maColorBar(seq(-2,2, 0.2), col=pal, horizontal=TRUE, k=0)
maColorBar(seq(-2,2, 0.1), col=pal, horizontal=TRUE, k=0)


efg
--
Earl F. Glynn
Scientific Programmer
Stowers Institute for Medical Research



From r.shengzhe at gmail.com  Thu Aug  4 17:39:01 2005
From: r.shengzhe at gmail.com (Shengzhe Wu)
Date: Thu, 4 Aug 2005 17:39:01 +0200
Subject: [R] Help: how to stop the process when there is a mishandling
In-Reply-To: <42F228B1.3000602@jhsph.edu>
References: <ea57975b05080407187acc3399@mail.gmail.com>
	<42F228B1.3000602@jhsph.edu>
Message-ID: <ea57975b05080408392a190483@mail.gmail.com>

and how about R on windows system? since I am currently using R of
windows version.

Thank you,
Shengzhe

On 8/4/05, Roger D. Peng <rpeng at jhsph.edu> wrote:
> On Unix you can send one of the 'USR' signals to 'kill'.  See
> ?Signals.
> 
> -roger
> 
> Shengzhe Wu wrote:
> > Hello,
> >
> > How to stop the process when there is a mishandling making R system
> > frozen? If there is a way other than quitting the system when frozen
> > occurs?
> >
> > Thank you,
> > Shengzhe
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> --
> Roger D. Peng
> http://www.biostat.jhsph.edu/~rpeng/
>



From jean.vidal at freesurf.fr  Thu Aug  4 17:55:49 2005
From: jean.vidal at freesurf.fr (jean.vidal@freesurf.fr)
Date: Thu, 4 Aug 2005 17:55:49 +0200 (CEST)
Subject: [R] Problem when pasting from Winedit into Rgui
Message-ID: <39757.192.54.193.35.1123170949.squirrel@jose.freesurf.fr>

After upgrading to R 2.1.1, the usual paste-and-go from Winedit seems to
not work anymore.
I try installing the last 'RWinEdt_1.7-3' edition, but with no more result.
After selecting the program lines to submit, I  click on the 'paste' icon
and nothing happens in the R gui (a subliminal, flashing move in the
edition menu...). Idem for 'source' and 'R-history'.
Downgrading to 2.0.1 solves the trouble.

Do I forget something ?
Thanks for any help.

I am working with :
> version
         _
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    1.1
year     2005
month    06
day      20
language R



From ligges at statistik.uni-dortmund.de  Thu Aug  4 18:10:22 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 04 Aug 2005 18:10:22 +0200
Subject: [R] Problem when pasting from Winedit into Rgui
In-Reply-To: <39757.192.54.193.35.1123170949.squirrel@jose.freesurf.fr>
References: <39757.192.54.193.35.1123170949.squirrel@jose.freesurf.fr>
Message-ID: <42F23DEE.20805@statistik.uni-dortmund.de>

jean.vidal at freesurf.fr wrote:

> After upgrading to R 2.1.1, the usual paste-and-go from Winedit seems to
> not work anymore.
> I try installing the last 'RWinEdt_1.7-3' edition, but with no more result.
> After selecting the program lines to submit, I  click on the 'paste' icon
> and nothing happens in the R gui (a subliminal, flashing move in the
> edition menu...). Idem for 'source' and 'R-history'.
> Downgrading to 2.0.1 solves the trouble.
> 
> Do I forget something ?
> Thanks for any help.

You might want to conatct the RWinEdt maintainer. He would tell you that 
you should read the output of RWinEdt appearaing when you say
   library(RWinEdt)

I guess you have a french localized version of RGui running in mdi mode? 
In this case, switch to sdi mode and adjust the RWinEdt setting.
It's all explained in much more detail in the ReadMe of RWinEdt.

Uwe Ligges


> I am working with :
> 
>>version
> 
>          _
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    1.1
> year     2005
> month    06
> day      20
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Thu Aug  4 18:16:06 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 04 Aug 2005 09:16:06 -0700
Subject: [R] Counterintuitive Simulation Results
Message-ID: <42F23F46.1080104@pdf.com>

	  I wonder if someone can help me understand some counterintuitive 
simulation results.  Below please find 12 lines of R code that 
theoretically, to the best of my understanding, should produce 
essentially a flat line with no discernable pattern.  Instead, I see an 
initial dramatic drop followed by a slow rise to an asymptote.

	  The simulation computes the mean of 20,000 simulated trajectories of 
400 observations each of a one-sided Cusum of independent normal 
increments with mean EZ[t] = (-0.1) and unit variance.  Started with any 
initial value, the mean of the Cusum should approach an asymptote as the 
number of observations increases;  when started at that asymptote, it 
should theoretically stay flat, unlike what we see here.

	  I would think this could be an artifact of the simulation 
methodology, but I've gotten essentially this image with several 
independently programmed simulations in S-Plus 6.1, with all six 
different random number generators in R 1.9.1 and 2.1.1 and with MS 
Excel.  For modest changes in EZ[t] < 0, I get a different asymptote but 
pretty much the same image.

#################################################
simCus5 <- function(mu=-0.1, Qp0=4.5, maxTime=400, nSims=20000){
   Qp.mean <- rep(NA, maxTime)
   Qp.t <- rep(Qp0, nSims)
   for(i in 1:maxTime){
     z.t <- (mu + rnorm(nSims))
     Qp.t <- pmax(0, Qp.t+z.t)
     Qp.mean[i] <- mean(Qp.t)
   }
   Qp.mean
}
set.seed(1)
plot(simCus5(Qp0=4.5))
#################################################

	  Thanks for your time in reading this.
	  Best Wishes,
	  Spencer Graves

Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From arrayprofile at yahoo.com  Thu Aug  4 18:31:03 2005
From: arrayprofile at yahoo.com (array chip)
Date: Thu, 4 Aug 2005 09:31:03 -0700 (PDT)
Subject: [R] color palette
In-Reply-To: <Pine.A41.4.61b.0508031711220.210186@homer09.u.washington.edu>
Message-ID: <20050804163103.25314.qmail@web40810.mail.yahoo.com>

Thanks for the suggestion. I still could not figure
out how to use the function to do my job. What's
important in my job is that I have to map white color
to value 0, and then form a bue gradient for negative
values, and red gradient for positive values. The data
matrix I have is not symmetric aound 0, say 0 is at
the 18 percentile, and values range from -10 to 30.
How exactly I could do my job? Bear with me, I am new
to color, I don't quite understand how the image
function map the number is the data matrix to the
colors defined in the col argument.

Thanks


--- Thomas Lumley <tlumley at u.washington.edu> wrote:

> On Wed, 3 Aug 2005, array chip wrote:
> 
> > Hi, I have a matrix with both positive and
> negative
> > numbers, I would like to use image() to draw a
> > heatmap. How can I can design a palette (or is
> there a
> > function already available) that treat negative
> > numbers in a blue gradient and positive numbers in
> a
> > red gradient and treat 0 as white?
> >
> 
> ?colorRampPalette
> 
>  	-thomas
>



From elvis at xlsolutions-corp.com  Thu Aug  4 18:36:49 2005
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Thu,  4 Aug 2005 09:36:49 -0700
Subject: [R] Course *** R/Splus Advanced Programming *** September 2005 @ 2
	locations
Message-ID: <20050804093649.a108dc04937c07ba67766dad37185406.1d8a4304b8.wbe@email.email.secureserver.net>

XSolutions Corp (www.xlsolutions-corp.com) is proud to announce
our  September 2005 "Advanced R/Splus programming" course taught by R
Development
Core Team Guru!

www.xlsolutions-corp.com/Radv.htm

*********Atlanta --------------- September 1-2
*********New York ----------- September 1-2
*********Boston --------------- TBD
*********Washington, DC ---TBD, please email if interested.

Ask for group discount and reserve your seat Now  (payment due after
the class)

Email Sue Turner:  sue at xlsolutions-corp.com

Course Outline:

- Overview of R/S fundamentals: Syntax and Semantics
- Class and Inheritance in R/S-Plus
- Concepts, Construction and good use of language objects
- Coercion and efficiency
- Object-oriented programming in R and S-Plus
- Advanced manipulation tools: Parse, Deparse, Substitute, etc.
- How to fully take advantage of Vectorization
- Generic and Method Functions; S4 (S-Plus 6)
- Search path, databases and frames Visibility
- Working with large objects
- Handling Properly Recursion and iterative calculations
- Managing loops; For (S-Plus) and for() loops
- Consequences of Lazy Evaluation
- Efficient Code practices for large computations
- Memory management and Resource monitoring
- Writing R/S-Plus functions to call compiled code
- Writing and debugging compiled code for R/S-Plus system
- Connecting R/S-Plus to External Data Sources
- Understanding the structure of model fitting functions in R/S-Plus
- Designing and Packaging efficiently a new model function

It'll also deal with lots of S-Plus efficiency issues and any special
topics
from participants is welcome.

Please let us know if you and your colleagues are interested in this
class
to take advantage of group discount. Over half of the seats in this
class
are currently reserved.  Register now to secure your seat in this
course!

Cheers,

Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com



From deepayan.sarkar at gmail.com  Thu Aug  4 18:37:55 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 4 Aug 2005 11:37:55 -0500
Subject: [R] one more minor and small bug in lattice in R
In-Reply-To: <1262806553.20050803173752@eimb.ru>
References: <1803865630.20050520160521@eimb.ru>
	<200505200955.37557.deepayan@stat.wisc.edu>
	<1906380434.20050723200741@eimb.ru>
	<200507251353.07608.deepayan@stat.wisc.edu>
	<1262806553.20050803173752@eimb.ru>
Message-ID: <eb555e6605080409373244757@mail.gmail.com>

On 8/3/05, Wladimir Eremeev <wl at eimb.ru> wrote:
> Dear all.
> 
>  I have found one more minor bug in the Lattice package.
> 
>  When xyplot plots several curves on each panel with the default panel
>  function panel.xyplot, and when it is called with "g" %in% type
> (that is,
> xyplot(y1+y2+y3~x|cond,allow.multiple=TRUE,type=c("o","g"),<other params>)
>  ), it draws grid lines several times (for each curve), and it appears,
>  that they overlay all curves plotted, except the last one.
> 
>  I think there is a need to establish some kind of flag, showing, that
>  the grid is already drawn, and other runs of the panel.xyplot for the
>  same panel must not draw it again.

This has been fixed in the latest version (which has been uploaded,
but not on CRAN yet), by making panel.superpose handle 'g' in type.

Deepayan



From friendly at yorku.ca  Thu Aug  4 18:52:49 2005
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 04 Aug 2005 12:52:49 -0400
Subject: [R] visualizing/summarizing a large, sparse logistic regression
Message-ID: <42F247E1.8030509@yorku.ca>

I have data on ~340000 cases where it is desired to predict
binary outcome, Withdrawn, using up to 8, A:H, predictors in
a 3 x 2^7 design, but where the frequencies in these 168
cells vary enormously (1--108000).  As well, there are
two additional variables, Agency and Office, and it is
desired, among other things, to determine if the rates
vary with Agency and Office controlling for A - H.

I fit an initial model
   Withdrawn ~ A + B + C + D + E + F + G + H

giving all main effects significant, and am trying to find
a compact way to summarize and visualize the fitted rates
under this model, or a more complex model involving
Agency and Office plus potential interactions among A-H.

Can someone point me in some useful directions or to some
similar examples?

thanks,
-Michael

-- 
Michael Friendly     Email: friendly at yorku.ca
Professor, Psychology Dept.
York University      Voice: 416 736-5115 x66249 Fax: 416 736-5814
4700 Keele Street    http://www.math.yorku.ca/SCS/friendly.html
Toronto, ONT  M3J 1P3 CANADA



From r.shengzhe at gmail.com  Thu Aug  4 19:03:21 2005
From: r.shengzhe at gmail.com (Shengzhe Wu)
Date: Thu, 4 Aug 2005 19:03:21 +0200
Subject: [R] Help: how to hide the buttons of a new opening device
Message-ID: <ea57975b0508041003b36962@mail.gmail.com>

Hello,

When I open a new device by "windows()", how to hide the 3 buttons on
the top-right corner of this window, since I want to make these
buttons not work, and the window can be closed only by "dev.off()" or
"graphics.off()".

Thank you,
Shengzhe



From Robert.McGehee at geodecapital.com  Thu Aug  4 19:06:40 2005
From: Robert.McGehee at geodecapital.com (McGehee, Robert)
Date: Thu, 4 Aug 2005 13:06:40 -0400
Subject: [R] Counterintuitive Simulation Results
Message-ID: <67DCA285A2D7754280D3B8E88EB548020C946651@MSGBOSCLB2WIN.DMN1.FMR.COM>

Spencer,
On the first iteration of your simulation, all of the Qp.t + z.t < 0, so
you're adding a vector of rep(4.5, 20000) to a random distribution with
mean -0.1. So one would expect on iteration 2, your mean would have
dropped by about 0.1 (which it does). This process continues until about
the 20th iteration when we start seeing that a large number of our
initial starting points are floored at zero (because of the pmax). For
points greater than zero, we continue to subtract an average of 0.1
(actually less than this), but for those points already at zero, we're
actually adding a mean of 0.348 (since we can never subtract from a zero
number in this case), which starts the trajectory moving upward towards
its asymptote.

#That is, for those paths far above 0.1, we are subtracting
> mean(rnorm(10000, mean = -0.1))
[1] -0.1059246

#And for those paths already at zero, we are adding
> mean(pmax(0, rnorm(10000, mean = -0.1)))
[1] 0.3482376

To see a simulation a bit closer to what you were expecting, replace the
starting values with a random distribution with mean Qp0.

i.e. replace
> Qp.t <- rep(Qp0, nSims)
with
> Qp.t <- rnorm(nSims, Qp0, sd = 3.7)

Robert


-----Original Message-----
From: Spencer Graves [mailto:spencer.graves at pdf.com] 
Sent: Thursday, August 04, 2005 12:16 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Counterintuitive Simulation Results


	  I wonder if someone can help me understand some
counterintuitive 
simulation results.  Below please find 12 lines of R code that 
theoretically, to the best of my understanding, should produce 
essentially a flat line with no discernable pattern.  Instead, I see an 
initial dramatic drop followed by a slow rise to an asymptote.

	  The simulation computes the mean of 20,000 simulated
trajectories of 
400 observations each of a one-sided Cusum of independent normal 
increments with mean EZ[t] = (-0.1) and unit variance.  Started with any

initial value, the mean of the Cusum should approach an asymptote as the

number of observations increases;  when started at that asymptote, it 
should theoretically stay flat, unlike what we see here.

	  I would think this could be an artifact of the simulation 
methodology, but I've gotten essentially this image with several 
independently programmed simulations in S-Plus 6.1, with all six 
different random number generators in R 1.9.1 and 2.1.1 and with MS 
Excel.  For modest changes in EZ[t] < 0, I get a different asymptote but

pretty much the same image.

#################################################
simCus5 <- function(mu=-0.1, Qp0=4.5, maxTime=400, nSims=20000){
   Qp.mean <- rep(NA, maxTime)
   Qp.t <- rep(Qp0, nSims)
   for(i in 1:maxTime){
     z.t <- (mu + rnorm(nSims))
     Qp.t <- pmax(0, Qp.t+z.t)
     Qp.mean[i] <- mean(Qp.t)
   }
   Qp.mean
}
set.seed(1)
plot(simCus5(Qp0=4.5))
#################################################

	  Thanks for your time in reading this.
	  Best Wishes,
	  Spencer Graves

Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From fennellw at gmail.com  Thu Aug  4 19:35:27 2005
From: fennellw at gmail.com (William Fennell)
Date: Thu, 4 Aug 2005 13:35:27 -0400
Subject: [R] R config question
Message-ID: <985880620508041035539fd9ac@mail.gmail.com>

Hi FOlks,

I tried to configure  R 2.1.1 prior to making R on Solaris 8 and get this error.
configure: error: --with-readline=yes (default) and headers/libs are
not available

Any ideas what this means?

Thanks,

Bill



From cristian at biometria.univr.it  Thu Aug  4 19:36:35 2005
From: cristian at biometria.univr.it (Cristian)
Date: Thu,  4 Aug 2005 19:36:35 +0200
Subject: [R] linkage disequilibrium
Message-ID: <1123176995.42f252238a47a@biometria.univr.it>

Dear all, 

I'm using the package "Genetics", and I'm interested in the computation of D'
statistics for Linkage Disequilibrium, for which the LD() command has been
realised. Unfortunately I don't find any reference on "how" the D' is computed
by the LD() function. In the package documentation it is generally referred as
"MLE" estimation, but references are not provided. Does anybody knows how it is
obtained or, at least, some references?

Are there any other R package performing the D' computation both for phased and
unphased genotype?

Thanks!
Cristian



================================================
Cristian Pattaro
Unit of Epidemiology & Medical Statistics
Department of Medicine and Public Health
University of Verona, Italy
================================================

-------------------------------------------------
Biometria - biometria.univr.it



From martin at metahuman.org  Thu Aug  4 19:37:23 2005
From: martin at metahuman.org (Martin C. Martin)
Date: Thu, 04 Aug 2005 13:37:23 -0400
Subject: [R] Adding "sum" to derivatives table
Message-ID: <42F25253.90707@metahuman.org>

Hi,

Trying this:

deriv(expression(sum(x)), "x")

Gives the error message:

        Function 'sum' is not in the derivatives table

I'd like to add it, is this difficult?  If not, where is the derivatives 
table?

However, give how basic "sum" is, I suspect it would have been added if 
it were straightforward.  Do functions in the derivatives table need to 
be vectorized?  i.e. given a vector of length n, they need to produce a 
vector of length n?  Or is there some other restriction?

Thanks,
Martin



From ligges at statistik.uni-dortmund.de  Thu Aug  4 19:40:19 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 04 Aug 2005 19:40:19 +0200
Subject: [R] Help: how to hide the buttons of a new opening device
In-Reply-To: <ea57975b0508041003b36962@mail.gmail.com>
References: <ea57975b0508041003b36962@mail.gmail.com>
Message-ID: <42F25303.40309@statistik.uni-dortmund.de>

Shengzhe Wu wrote:

> Hello,
> 
> When I open a new device by "windows()", how to hide the 3 buttons on
> the top-right corner of this window, since I want to make these
> buttons not work, and the window can be closed only by "dev.off()" or
> "graphics.off()".

You cannot.

Uwe Ligges

> 
> Thank you,
> Shengzhe
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Thu Aug  4 19:44:54 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 04 Aug 2005 19:44:54 +0200
Subject: [R] R config question
In-Reply-To: <985880620508041035539fd9ac@mail.gmail.com>
References: <985880620508041035539fd9ac@mail.gmail.com>
Message-ID: <42F25416.9090005@statistik.uni-dortmund.de>

William Fennell wrote:

> Hi FOlks,
> 
> I tried to configure  R 2.1.1 prior to making R on Solaris 8 and get this error.
> configure: error: --with-readline=yes (default) and headers/libs are
> not available
> 
> Any ideas what this means?

... maybe that configure cannot find the readline headers/libs?
Either install them (highly recommended) or configure without readline 
support.

Uwe Ligges


> Thanks,
> 
> Bill
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rolf at math.unb.ca  Thu Aug  4 19:50:58 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 4 Aug 2005 14:50:58 -0300 (ADT)
Subject: [R] Adding "sum" to derivatives table
Message-ID: <200508041750.j74HowfO007023@erdos.math.unb.ca>

>  deriv(expression(sum(x)), "x")

	does not make any sense.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From weigand.stephen at gmail.com  Thu Aug  4 19:58:53 2005
From: weigand.stephen at gmail.com (Stephen D. Weigand)
Date: Thu, 4 Aug 2005 12:58:53 -0500
Subject: [R] Graphics on MacOSX
In-Reply-To: <9bf12bd680088cb944d1b84f7dc54267@MUOhio.edu>
References: <BF17D09D.E26%weismann_d@klinik.uni-wuerzburg.de>
	<9bf12bd680088cb944d1b84f7dc54267@MUOhio.edu>
Message-ID: <5665f4c99c9947423a5e1c2b74bcef84@gmail.com>

Dear Dirk and Hank,

On Aug 4, 2005, at 9:13 AM, Martin Henry H. Stevens wrote:

> This is a big issue for me, causing many days of angst. I finally
> stumbled on the following solution. I create a device save an image
> with postscript(). I then open it in Adobe Acrobat, select the area I
> want, enlarge to at least 400%, then copy, then paste into PowerPoint
> or Word. Alternatively, you can simply save a graphics image through
> the gui and it saves it as pdf. Then go through the steps of selecting,
> enlarging and copying in Acrobat. I am guessing real graphics programs
> would work as well (Photoshop or Illustrator), but I don't have those.
>
> Hank Stevens
>
>
> On Aug 4, 2005, at 8:03 AM, Weismann_D wrote:
>
>> Ist there a possibility on MacOSX to import Graphics into MSOffice
>> Applications and resize them there without decreased quality? When I
>> import
>> via copy&paste I get low quality bitmaps and via import pictures (pdf)
>> it is
>> all the same. In the Windows versions of R there is the convienient
>> way to
>> use metafile format which can easily be resized in ppt and word. What
>> is the
>> equivalent way on MacOSX?
>> Thanks, Dirk.

You could try creating a PNG with bitmap() using a high resolution, 
e.g.,

bitmap("test.png", type = "png256", res = 1200)
plot(1:10, rnorm(10))
dev.off()

Preview can read the resulting PNG file just fine and the Windows 
version of Office can insert PNGs, displays them well, and allows 
resizing. (I don't have an OS X version of Office so can't test that 
the OS X version would handle the PNGs equally well but I would have to 
assume it does.)

bitmap() requires Ghostscript which I have installed on my system in 
/usr/local/bin. I'm not sure whether Ghostscript came with OS X or if I 
installed it myself but it's freely available.

Hope this helps,

Stephen

PS I am using the out-of-the-box R.app:

platform powerpc-apple-darwin7.9.0
arch     powerpc
os       darwin7.9.0
system   powerpc, darwin7.9.0
status   Patched
major    2
minor    1.0
year     2005
month    05
day      12

and Ghostscript 8.13 (2003-12-31)



From murdoch at stats.uwo.ca  Thu Aug  4 20:16:45 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 04 Aug 2005 14:16:45 -0400
Subject: [R] Help: how to stop the process when there is a mishandling
In-Reply-To: <ea57975b05080408392a190483@mail.gmail.com>
References: <ea57975b05080407187acc3399@mail.gmail.com>	<42F228B1.3000602@jhsph.edu>
	<ea57975b05080408392a190483@mail.gmail.com>
Message-ID: <42F25B8D.8090100@stats.uwo.ca>

On 8/4/2005 11:39 AM, Shengzhe Wu wrote:
> and how about R on windows system? since I am currently using R of
> windows version.

Hit "ESC" in the console.  If that doesn't work, there's a bug.  Report 
it to the package maintainer if you're running package code, or here if 
it's base code.  Be sure to give enough details that others can see 
things freeze.

And if it really is frozen, you can use Ctrl-Alt-Del to open the Windows 
  Task Manager, select the Rgui application, and "End task".  Assuming 
you have permission, etc.

Duncan Murdoch
> 
> Thank you,
> Shengzhe
> 
> On 8/4/05, Roger D. Peng <rpeng at jhsph.edu> wrote:
>> On Unix you can send one of the 'USR' signals to 'kill'.  See
>> ?Signals.
>> 
>> -roger
>> 
>> Shengzhe Wu wrote:
>> > Hello,
>> >
>> > How to stop the process when there is a mishandling making R system
>> > frozen? If there is a way other than quitting the system when frozen
>> > occurs?
>> >
>> > Thank you,
>> > Shengzhe
>> >
>> > ______________________________________________
>> > R-help at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>> >
>> 
>> --
>> Roger D. Peng
>> http://www.biostat.jhsph.edu/~rpeng/
>>
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Thu Aug  4 20:20:08 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 04 Aug 2005 11:20:08 -0700
Subject: [R] Counterintuitive Simulation Results
In-Reply-To: <67DCA285A2D7754280D3B8E88EB548020C946651@MSGBOSCLB2WIN.DMN1.FMR.COM>
References: <67DCA285A2D7754280D3B8E88EB548020C946651@MSGBOSCLB2WIN.DMN1.FMR.COM>
Message-ID: <42F25C58.5020703@pdf.com>

Hi, Robert:

	  Yes, I understand now.  Thanks very much for your insight.

	  Best Wishes,
	  Spencer Graves

McGehee, Robert wrote:

> Spencer,
> On the first iteration of your simulation, all of the Qp.t + z.t < 0, so
> you're adding a vector of rep(4.5, 20000) to a random distribution with
> mean -0.1. So one would expect on iteration 2, your mean would have
> dropped by about 0.1 (which it does). This process continues until about
> the 20th iteration when we start seeing that a large number of our
> initial starting points are floored at zero (because of the pmax). For
> points greater than zero, we continue to subtract an average of 0.1
> (actually less than this), but for those points already at zero, we're
> actually adding a mean of 0.348 (since we can never subtract from a zero
> number in this case), which starts the trajectory moving upward towards
> its asymptote.
> 
> #That is, for those paths far above 0.1, we are subtracting
> 
>>mean(rnorm(10000, mean = -0.1))
> 
> [1] -0.1059246
> 
> #And for those paths already at zero, we are adding
> 
>>mean(pmax(0, rnorm(10000, mean = -0.1)))
> 
> [1] 0.3482376
> 
> To see a simulation a bit closer to what you were expecting, replace the
> starting values with a random distribution with mean Qp0.
> 
> i.e. replace
> 
>>Qp.t <- rep(Qp0, nSims)
> 
> with
> 
>>Qp.t <- rnorm(nSims, Qp0, sd = 3.7)
> 
> 
> Robert
> 
> 
> -----Original Message-----
> From: Spencer Graves [mailto:spencer.graves at pdf.com] 
> Sent: Thursday, August 04, 2005 12:16 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Counterintuitive Simulation Results
> 
> 
> 	  I wonder if someone can help me understand some
> counterintuitive 
> simulation results.  Below please find 12 lines of R code that 
> theoretically, to the best of my understanding, should produce 
> essentially a flat line with no discernable pattern.  Instead, I see an 
> initial dramatic drop followed by a slow rise to an asymptote.
> 
> 	  The simulation computes the mean of 20,000 simulated
> trajectories of 
> 400 observations each of a one-sided Cusum of independent normal 
> increments with mean EZ[t] = (-0.1) and unit variance.  Started with any
> 
> initial value, the mean of the Cusum should approach an asymptote as the
> 
> number of observations increases;  when started at that asymptote, it 
> should theoretically stay flat, unlike what we see here.
> 
> 	  I would think this could be an artifact of the simulation 
> methodology, but I've gotten essentially this image with several 
> independently programmed simulations in S-Plus 6.1, with all six 
> different random number generators in R 1.9.1 and 2.1.1 and with MS 
> Excel.  For modest changes in EZ[t] < 0, I get a different asymptote but
> 
> pretty much the same image.
> 
> #################################################
> simCus5 <- function(mu=-0.1, Qp0=4.5, maxTime=400, nSims=20000){
>    Qp.mean <- rep(NA, maxTime)
>    Qp.t <- rep(Qp0, nSims)
>    for(i in 1:maxTime){
>      z.t <- (mu + rnorm(nSims))
>      Qp.t <- pmax(0, Qp.t+z.t)
>      Qp.mean[i] <- mean(Qp.t)
>    }
>    Qp.mean
> }
> set.seed(1)
> plot(simCus5(Qp0=4.5))
> #################################################
> 
> 	  Thanks for your time in reading this.
> 	  Best Wishes,
> 	  Spencer Graves
> 
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
> 
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From murdoch at stats.uwo.ca  Thu Aug  4 20:18:34 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 04 Aug 2005 14:18:34 -0400
Subject: [R] Help: how to hide the buttons of a new opening device
In-Reply-To: <ea57975b0508041003b36962@mail.gmail.com>
References: <ea57975b0508041003b36962@mail.gmail.com>
Message-ID: <42F25BFA.6000007@stats.uwo.ca>

On 8/4/2005 1:03 PM, Shengzhe Wu wrote:
> Hello,
> 
> When I open a new device by "windows()", how to hide the 3 buttons on
> the top-right corner of this window, since I want to make these
> buttons not work, and the window can be closed only by "dev.off()" or
> "graphics.off()".

There are no exposed functions to do that.  You're going to have to look 
at the R source code, and add something.

Duncan Murdoch



From martin at metahuman.org  Thu Aug  4 20:23:26 2005
From: martin at metahuman.org (Martin C. Martin)
Date: Thu, 04 Aug 2005 14:23:26 -0400
Subject: [R] Adding "sum" to derivatives table
In-Reply-To: <200508041750.j74HowfO007023@erdos.math.unb.ca>
References: <200508041750.j74HowfO007023@erdos.math.unb.ca>
Message-ID: <42F25D1E.9010204@metahuman.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050804/969cf0d4/attachment.pl

From spencer.graves at pdf.com  Thu Aug  4 20:25:35 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 04 Aug 2005 11:25:35 -0700
Subject: [R] Help: how to stop the process when there is a mishandling
In-Reply-To: <42F25B8D.8090100@stats.uwo.ca>
References: <ea57975b05080407187acc3399@mail.gmail.com>	<42F228B1.3000602@jhsph.edu>	<ea57975b05080408392a190483@mail.gmail.com>
	<42F25B8D.8090100@stats.uwo.ca>
Message-ID: <42F25D9F.7040408@pdf.com>

	  If you are using XEmacs, it's not that easy.  I'm not completely 
clear on the protocol in that case, but I think you have to first click 
in the R window, then <ctrl-G> + <ctrl-C> + <ctrl-C>.  Perhaps an Emacs 
wizard will enlighten us.

	  spencer graves

Duncan Murdoch wrote:

> On 8/4/2005 11:39 AM, Shengzhe Wu wrote:
> 
>>and how about R on windows system? since I am currently using R of
>>windows version.
> 
> 
> Hit "ESC" in the console.  If that doesn't work, there's a bug.  Report 
> it to the package maintainer if you're running package code, or here if 
> it's base code.  Be sure to give enough details that others can see 
> things freeze.
> 
> And if it really is frozen, you can use Ctrl-Alt-Del to open the Windows 
>   Task Manager, select the Rgui application, and "End task".  Assuming 
> you have permission, etc.
> 
> Duncan Murdoch
> 
>>Thank you,
>>Shengzhe
>>
>>On 8/4/05, Roger D. Peng <rpeng at jhsph.edu> wrote:
>>
>>>On Unix you can send one of the 'USR' signals to 'kill'.  See
>>>?Signals.
>>>
>>>-roger
>>>
>>>Shengzhe Wu wrote:
>>>
>>>>Hello,
>>>>
>>>>How to stop the process when there is a mishandling making R system
>>>>frozen? If there is a way other than quitting the system when frozen
>>>>occurs?
>>>>
>>>>Thank you,
>>>>Shengzhe
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>>
>>>
>>>--
>>>Roger D. Peng
>>>http://www.biostat.jhsph.edu/~rpeng/
>>>
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From martin at metahuman.org  Thu Aug  4 20:27:36 2005
From: martin at metahuman.org (Martin C. Martin)
Date: Thu, 04 Aug 2005 14:27:36 -0400
Subject: [R] Help: how to stop the process when there is a mishandling
In-Reply-To: <42F25B8D.8090100@stats.uwo.ca>
References: <ea57975b05080407187acc3399@mail.gmail.com>	<42F228B1.3000602@jhsph.edu>	<ea57975b05080408392a190483@mail.gmail.com>
	<42F25B8D.8090100@stats.uwo.ca>
Message-ID: <42F25E18.8020009@metahuman.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050804/f8cb69f9/attachment.pl

From murdoch at stats.uwo.ca  Thu Aug  4 20:30:36 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 04 Aug 2005 14:30:36 -0400
Subject: [R] Help: how to stop the process when there is a mishandling
In-Reply-To: <42F25D9F.7040408@pdf.com>
References: <ea57975b05080407187acc3399@mail.gmail.com>	<42F228B1.3000602@jhsph.edu>	<ea57975b05080408392a190483@mail.gmail.com>
	<42F25B8D.8090100@stats.uwo.ca> <42F25D9F.7040408@pdf.com>
Message-ID: <42F25ECC.1090209@stats.uwo.ca>

On 8/4/2005 2:25 PM, Spencer Graves wrote:
> 	  If you are using XEmacs, it's not that easy.  I'm not completely 
> clear on the protocol in that case, but I think you have to first click 
> in the R window, then <ctrl-G> + <ctrl-C> + <ctrl-C>.  Perhaps an Emacs 
> wizard will enlighten us.
> 
> 	  spencer graves

Yes, I was talking about Rgui.exe.  ESC doesn't stop Rterm.exe, which is 
what XEmacs is running.

Duncan Murdoch

> 
> Duncan Murdoch wrote:
> 
>> On 8/4/2005 11:39 AM, Shengzhe Wu wrote:
>> 
>>>and how about R on windows system? since I am currently using R of
>>>windows version.
>> 
>> 
>> Hit "ESC" in the console.  If that doesn't work, there's a bug.  Report 
>> it to the package maintainer if you're running package code, or here if 
>> it's base code.  Be sure to give enough details that others can see 
>> things freeze.
>> 
>> And if it really is frozen, you can use Ctrl-Alt-Del to open the Windows 
>>   Task Manager, select the Rgui application, and "End task".  Assuming 
>> you have permission, etc.
>> 
>> Duncan Murdoch
>> 
>>>Thank you,
>>>Shengzhe
>>>
>>>On 8/4/05, Roger D. Peng <rpeng at jhsph.edu> wrote:
>>>
>>>>On Unix you can send one of the 'USR' signals to 'kill'.  See
>>>>?Signals.
>>>>
>>>>-roger
>>>>
>>>>Shengzhe Wu wrote:
>>>>
>>>>>Hello,
>>>>>
>>>>>How to stop the process when there is a mishandling making R system
>>>>>frozen? If there is a way other than quitting the system when frozen
>>>>>occurs?
>>>>>
>>>>>Thank you,
>>>>>Shengzhe
>>>>>
>>>>>______________________________________________
>>>>>R-help at stat.math.ethz.ch mailing list
>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>>>
>>>>
>>>>--
>>>>Roger D. Peng
>>>>http://www.biostat.jhsph.edu/~rpeng/
>>>>
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>> 
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From kevin.thorpe at utoronto.ca  Thu Aug  4 20:57:28 2005
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Thu, 04 Aug 2005 14:57:28 -0400
Subject: [R] Problem configuring R-patched
Message-ID: <42F26518.30708@utoronto.ca>

I downloaded R-patched (2005-08-04) from CRAN today.
I ran ./configure --enable-R-shlib

I received the error message:

checking for recommended packages... no
configure: error: Some of the recommended packages are missing
   Use --without-recommended-packages if this was intentional

I built a previous version of R-patched successfully on my system
which is running the SuSE 9,2 Pro Linux distribution.  I untarred the
tar ball into the same directory I did my last build on in case that's
important.

The only other differences between this attempt and my successful build
are:

1. I did not use --enable-R-shlib last time.
2. I found and installed the blas libraries for this build.

Have I messed up or made an erroneous assumption along the way?

Thanks

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.946.8081  Fax: 416.971.2462



From rwcitek at alum.calberkeley.org  Thu Aug  4 21:02:01 2005
From: rwcitek at alum.calberkeley.org (Robert Citek)
Date: Thu, 4 Aug 2005 14:02:01 -0500
Subject: [R] Eclipse, R, plug-in?
In-Reply-To: <42F1C54C.1070201@statistik.uni-dortmund.de>
References: <245E2ABB-D80B-4527-ACF7-BAC37D2B011A@alum.calberkeley.org>
	<42F1C54C.1070201@statistik.uni-dortmund.de>
Message-ID: <CB3F34CB-8A08-44B5-B1F6-496930C512F9@alum.calberkeley.org>


On Aug 4, 2005, at 2:35 AM, Uwe Ligges wrote:
> Robert Citek wrote:
>> Has any developed or is anyone developing a plug-in[1] for using R
>> with Eclipse[2]?
>
> Stephan Wahlbrink made a Plug-In available at
> http://www.walware.de/goto/statet

Fantastic.  I started dabbling in R a few months ago and then got  
pulled into other projects.  Hopefully, I'll be able to devote a bit  
more time to R, again.

Regards,
- Robert
http://www.cwelug.org/downloads
Help others get OpenSource software.  Distribute FLOSS
for Windows, Linux, *BSD, and MacOS X with BitTorrent



From rolf at math.unb.ca  Thu Aug  4 21:13:53 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 4 Aug 2005 16:13:53 -0300 (ADT)
Subject: [R] Adding "sum" to derivatives table
Message-ID: <200508041913.j74JDrbB010823@erdos.math.unb.ca>

Martin C. Martin wrote:

> Rolf Turner wrote:
> 
> >> deriv(expression(sum(x)), "x")
> >>    
> >>
> >
> >	does not make any sense.
> >  
> >
> Good point.  But this does:
> 
> deriv(expression(sum(log(a*x))), "a")
> 
> where a is a scalar.

	Okay --- I see what you're getting at now.

	But I think that to get deriv() to handle expressions
	of that sort, i.e for

		 deriv(expression(sum(log(a*x))), "a")

	not to fall over, requires more than ``putting sum in the
	derivatives table''.  The problem is that ``sum'' is not the
	``right sort of function''.  Functions that appear in the
	derivatives table are (I think --- I am not knowledgable
	about this) functions of a single variable, like sin and cos
	and log, u.s.w.  Whereas sum is a function of arbitrarily
	many variables.

	What is needed is for deriv() to know the rule that ``the
	derivative of a sum is the sum of the derivatives''.  This
	would require rewriting the code of deriv().  Whether the
	required rule could be built into deriv() safely and sensibly
	is not clear to me.  It might be do-able; I wouldn't want to
	try it, but!

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From helprhelp at gmail.com  Thu Aug  4 21:13:14 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Thu, 4 Aug 2005 14:13:14 -0500
Subject: [R] some thoughts on outlier detection, need help!
Message-ID: <cdf8178305080412137c567835@mail.gmail.com>

Dear listers:
I have an idea to do the outlier detection and I need to use R to
implement it first. Here I hope I can get some input from all the
guru's here.

I select distance-based approach---
step 1:
calculate the distance of any two rows for a dataframe. considering
the scaling among different variables, I choose mahalanobis, using
variance as scaler.

step 2:
Let k be the number of points in one "cluster". K is decided by
answering the following question: how many neighbors a point needs for
not being an outlier.

for each point, get the smallest (k-1) distances from step1.  Among
the (k-1) distances of each point, get the max for the point.

step 3:
get the distribution of those max for all the points. Thus, the
multivariate problem becomes a univariate one. Then the outlier in
those max's will define the outlier of the point.

My question is:
1. I don't know if using mahalanobis is proper or not since most
clustering algorithms implemented in R (like pam or clara) use
euclidean or mahattan.
2. Is there a way to get the mahalanobis distance matrix for any two
rows of a dataframe or matrix?
3. My approach does allow a point belonging to more than one
k-cluster. Is there similar algorithm in R or published?

Thanks for any suggestions,

weiwei
-- 
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From jonathenwu at hotmail.com  Wed Aug  3 16:28:25 2005
From: jonathenwu at hotmail.com (=?gb2312?B?zuIg6rs=?=)
Date: Wed, 03 Aug 2005 14:28:25 +0000
Subject: [R] interpolation function in R
Message-ID: <BAY105-F572F7EC793B83E40C9E0FD0C50@phx.gbl>

Hi
does R provide some interpolation fucntions?
thank



From JAROSLAW.W.TUSZYNSKI at saic.com  Thu Aug  4 21:36:45 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Thu, 4 Aug 2005 15:36:45 -0400 
Subject: [R] FW:  color palette
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD57F4115@us-arlington-0668.mail.saic.com>


Try:

n   = 100;
x   = matrix(seq(-10, 30, length.out=500), ncol=1)
col = colorRampPalette( c("green", "white", "red"), space="rgb")(n) breaks =
c(seq(-10, 0, length.out=n/2)-0.5, 0, seq(0, 30, length.out=n/2)+0.5)
image(x, col=col, breaks=breaks)

See also today's discussion on R-Help about "red-black-green color palette",
since most of the code above came from Earl Glyn post.

Jarek
====================================================\=======

 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">   \
 Jaroslaw.W.Tuszynski at saic.com                     `    \



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of array chip
Sent: Thursday, August 04, 2005 12:31 PM
To: Thomas Lumley
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] color palette

Thanks for the suggestion. I still could not figure out how to use the
function to do my job. What's important in my job is that I have to map
white color to value 0, and then form a bue gradient for negative values,
and red gradient for positive values. The data matrix I have is not
symmetric aound 0, say 0 is at the 18 percentile, and values range from -10
to 30.
How exactly I could do my job? Bear with me, I am new to color, I don't
quite understand how the image function map the number is the data matrix to
the colors defined in the col argument.

Thanks


--- Thomas Lumley <tlumley at u.washington.edu> wrote:

> On Wed, 3 Aug 2005, array chip wrote:
> 
> > Hi, I have a matrix with both positive and
> negative
> > numbers, I would like to use image() to draw a heatmap. How can I 
> > can design a palette (or is
> there a
> > function already available) that treat negative numbers in a blue 
> > gradient and positive numbers in
> a
> > red gradient and treat 0 as white?
> >
> 
> ?colorRampPalette
> 
>  	-thomas
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From rolf at math.unb.ca  Thu Aug  4 21:37:41 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Thu, 4 Aug 2005 16:37:41 -0300 (ADT)
Subject: [R] interpolation function in R
Message-ID: <200508041937.j74JbfZf012079@erdos.math.unb.ca>


?approx

?splinefun



From sundar.dorai-raj at pdf.com  Thu Aug  4 21:37:49 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 04 Aug 2005 14:37:49 -0500
Subject: [R] interpolation function in R
In-Reply-To: <BAY105-F572F7EC793B83E40C9E0FD0C50@phx.gbl>
References: <BAY105-F572F7EC793B83E40C9E0FD0C50@phx.gbl>
Message-ID: <42F26E8D.2030803@pdf.com>



Îâ ê» wrote:
> Hi
> does R provide some interpolation fucntions?
> thank
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

PLEASE do read the posting guide!

help.search("interpolation")

returns

interpSpline(splines)   Create an Interpolation Spline
periodicSpline(splines)
                        Create a Periodic Interpolation Spline
NLSstClosestX(stats)    Inverse Interpolation
approx(stats)           Interpolation Functions
spline(stats)           Interpolating Splines

for example. There may be others in packages I don't have installed as well.

HTH,

--sundar



From bolker at ufl.edu  Thu Aug  4 22:24:56 2005
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 4 Aug 2005 20:24:56 +0000 (UTC)
Subject: [R] how to read individual values from a pixmap object
References: <200508040803.j7482uWZ096963@smtp1.uq.edu.au>
Message-ID: <loom.20050804T222406-603@post.gmane.org>

Tony Gill <t.gill1 <at> uq.edu.au> writes:

> 
> Hi All,
> 
> I have a greyscale image that I am reading in through RGDAL and placing in a
> pixmap object.
> 

> 

library(pixmap)
x <- read.pnm("graypic.pnm")
str(x)
x at grey[1,1]



From bolker at ufl.edu  Thu Aug  4 22:40:08 2005
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 4 Aug 2005 20:40:08 +0000 (UTC)
Subject: [R] how to read individual values from a pixmap object
References: <200508040803.j7482uWZ096963@smtp1.uq.edu.au>
	<loom.20050804T222406-603@post.gmane.org>
Message-ID: <loom.20050804T223901-305@post.gmane.org>

Ben Bolker <bolker <at> ufl.edu> writes:

> 
> Tony Gill <t.gill1 <at> uq.edu.au> writes:
> 
> > 
> > Hi All,
> > 
> > I have a greyscale image ...
> library(pixmap)

> x <- read.pnm("graypic.pnm")
> str(x)
> x <at> grey[1,1]
> 

  just in case there's any confusion ... that <at> should
be an at-symbol!



From caitlin1 at u.washington.edu  Thu Aug  4 22:45:11 2005
From: caitlin1 at u.washington.edu (Caitlin Burgess)
Date: Thu, 4 Aug 2005 13:45:11 -0700 (PDT)
Subject: [R] alaska map? - answers
In-Reply-To: <Pine.LNX.4.44.0507252226040.4996-100000@reclus.nhh.no>
Message-ID: <Pine.LNX.4.43.0508041345110.12009@hymn10.u.washington.edu>


Thanks very much to Roger Bivand and Greg Snow who wrote, respectively:

>map("world2", "USA:alaska")
>
>
>gives the low resolution, using the "world" database is split on the date
>line. The mapdata package has better resolution.


and


>Look at:
>
>http://www.census.gov/geo/www/cob/bdy_files.html
>
>There are shapefiles of the 50 states there, outlines, counties, and
>others.






> On Mon, 25 Jul 2005, Caitlin Burgess wrote:
>
>> Hello,
>>
>> I've installed the Becker and Wilks maps, mapdata, and mapproj packages
>> so I can begin
>> to try these out for some work I need to do on a map of
>> Alaska but I don't know where to find a map of Alaska. Has anyone solved
>> this already and could help?
>>
>> Thanks very much in advance,
>>
>> Caitlin
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>



From gavin.simpson at ucl.ac.uk  Thu Aug  4 23:16:52 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 04 Aug 2005 22:16:52 +0100
Subject: [R] Problem configuring R-patched
In-Reply-To: <42F26518.30708@utoronto.ca>
References: <42F26518.30708@utoronto.ca>
Message-ID: <1123190212.7455.5.camel@gsimpson.geog.ucl.ac.uk>

On Thu, 2005-08-04 at 14:57 -0400, Kevin E. Thorpe wrote:
> I downloaded R-patched (2005-08-04) from CRAN today.
> I ran ./configure --enable-R-shlib
> 
> I received the error message:
> 
> checking for recommended packages... no
> configure: error: Some of the recommended packages are missing
>    Use --without-recommended-packages if this was intentional
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
So was this intentional?

> I built a previous version of R-patched successfully on my system
> which is running the SuSE 9,2 Pro Linux distribution.  I untarred the
> tar ball into the same directory I did my last build on in case that's
> important.
> 
> The only other differences between this attempt and my successful build
> are:
> 
> 1. I did not use --enable-R-shlib last time.
> 2. I found and installed the blas libraries for this build.
> 
> Have I messed up or made an erroneous assumption along the way?

Yes and No. You obviously haven't compiled R recently. If you haven't
got the recommended packages in the source you are compiling, configure
now gives an error, which quite clearly states (and you've quoted it in
your email!) that it cannot find (some of) the recommended packages.

A solution - again given by the error message you quote! - is:

./configure --enable-R-shlib --without-recommended-packages
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

That should clear things up.

Other wise you need to cd to the R directory (where you have the source
code), and then execute ./tools/rsync-recommended and then run your
configure command.

HTH

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From christine.adrion at web.de  Thu Aug  4 23:26:10 2005
From: christine.adrion at web.de (Christine Adrion)
Date: Thu, 4 Aug 2005 23:26:10 +0200
Subject: [R] exact goodness-of-fit test
Message-ID: <006601c5993b$230864c0$4c3cb850@v3x0q0>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050804/486324f6/attachment.pl

From peter at fe.up.pt  Fri Aug  5 00:02:25 2005
From: peter at fe.up.pt (Peter Ho)
Date: Thu, 04 Aug 2005 23:02:25 +0100
Subject: [R] p-values
Message-ID: <42F29071.1000107@fe.up.pt>

HI R-users,

I am trying to repeat an example from Rayner and Best "A contingency 
table approach to nonparametric testing (Chapter 7, Ice cream example).

In their book they calculate Durbin's statistic, D1, a dispersion 
statistics, D2, and a residual. P-values for each statistic is 
calculated from a chi-square distribution and also Monte Carlo p-values.

I have found similar p-values based on the chi-square distribution by 
using:

 > pchisq(12, df= 6, lower.tail=F)
[1] 0.0619688
 > pchisq(5.1, df= 6, lower.tail=F)
[1] 0.5310529

Is there a way to calculate the equivalent Monte Carlo p-values?

The values were 0.02 and 0.138 respectively.

The use of the approximate chi-square probabilities for Durbin's test 
are considered not good enough according to Van der Laan (The American 
Statistician 1988,42,165-166).


Peter
--------------------------------
ESTG-IPVC



From joseclaudio.faria at terra.com.br  Fri Aug  5 00:00:37 2005
From: joseclaudio.faria at terra.com.br (Jose Claudio Faria)
Date: Thu, 04 Aug 2005 19:00:37 -0300
Subject: [R] An small suggestion for the R team
Message-ID: <42F29005.1060609@terra.com.br>

Hi all,

I would like to suggest that all R functions/etc like:
   codes-deprecated
   grid-internal
   ns-alt
   ns-dblcolon
   ns-hooks
   ns-internals
   ns-lowlev
   ns-reflect.Rd
   tools-internal
   ts-defunct
   utils-deprecated
   utils-internal
   ... and another

i.e, function/word separate for '-'

were all substituted by
   codes_deprecated
   grid_internal
   ns_alt
   ns_dblcolon
   ns_hooks
   ns_internals
   ns_lowlev
   ns_reflect.Rd
   tools_internal
   ts_defunct
   utils_deprecated
   utils_internal
   ... and another

i.e, by '_'

Because it is impossible to make a good highlighter with the first one.

How to differentiating myValue:

varOne = 100
varTwo = 50
myValue = varOne-varTwo

from codes-deprecated, or ns-alt, for example.

TIA,
-- 
Jose Claudio Faria
Brasil/Bahia/UESC/DCET
Estatistica Experimental/Prof. Adjunto
mails:
  joseclaudio.faria at terra.com.br
  jc_faria at uesc.br
  jc_faria at uol.com.br
tel: 73-3634.2779



From kevin.thorpe at utoronto.ca  Fri Aug  5 00:05:19 2005
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Thu, 04 Aug 2005 18:05:19 -0400
Subject: [R] Problem configuring R-patched
In-Reply-To: <1123190212.7455.5.camel@gsimpson.geog.ucl.ac.uk>
References: <42F26518.30708@utoronto.ca>
	<1123190212.7455.5.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <42F2911F.3010203@utoronto.ca>

Gavin Simpson wrote:
> On Thu, 2005-08-04 at 14:57 -0400, Kevin E. Thorpe wrote:
> 
>>I downloaded R-patched (2005-08-04) from CRAN today.
>>I ran ./configure --enable-R-shlib
>>
>>I received the error message:
>>
>>checking for recommended packages... no
>>configure: error: Some of the recommended packages are missing
>>   Use --without-recommended-packages if this was intentional
> 
>          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> So was this intentional?

No, it wasn't.

> 
>>I built a previous version of R-patched successfully on my system
>>which is running the SuSE 9,2 Pro Linux distribution.  I untarred the
>>tar ball into the same directory I did my last build on in case that's
>>important.
>>
>>The only other differences between this attempt and my successful build
>>are:
>>
>>1. I did not use --enable-R-shlib last time.
>>2. I found and installed the blas libraries for this build.
>>
>>Have I messed up or made an erroneous assumption along the way?
> 
> 
> Yes and No. You obviously haven't compiled R recently. If you haven't
> got the recommended packages in the source you are compiling, configure
> now gives an error, which quite clearly states (and you've quoted it in
> your email!) that it cannot find (some of) the recommended packages.

Actually, I compiled it about a week ago.  Here is my current version.

 > version
          _
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status   Patched
major    2
minor    1.1
year     2005
month    07
day      28
language R

When I compiled that version, I did my "tar xzf" to a clean directory
and did not receive that error.

> A solution - again given by the error message you quote! - is:
> 
> ./configure --enable-R-shlib --without-recommended-packages
>                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> 
> That should clear things up.

I realise that would clear it up.  I was puzzled why I got this message
in the first place, given I didn't get it last week.

> Other wise you need to cd to the R directory (where you have the source
> code), and then execute ./tools/rsync-recommended and then run your
> configure command.
> 
> HTH
> 
> G

Thanks for the rsync tip.

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.946.8081  Fax: 416.971.2462



From ggrothendieck at gmail.com  Fri Aug  5 00:26:01 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 4 Aug 2005 18:26:01 -0400
Subject: [R] An small suggestion for the R team
In-Reply-To: <42F29005.1060609@terra.com.br>
References: <42F29005.1060609@terra.com.br>
Message-ID: <971536df05080415267e363b79@mail.gmail.com>

On 8/4/05, Jose Claudio Faria <joseclaudio.faria at terra.com.br> wrote:
> Hi all,
> 
> I would like to suggest that all R functions/etc like:
>   codes-deprecated
>   grid-internal
>   ns-alt
>   ns-dblcolon
>   ns-hooks
>   ns-internals
>   ns-lowlev
>   ns-reflect.Rd
>   tools-internal
>   ts-defunct
>   utils-deprecated
>   utils-internal
>   ... and another
> 
> i.e, function/word separate for '-'
> 
> were all substituted by
>   codes_deprecated
>   grid_internal
>   ns_alt
>   ns_dblcolon
>   ns_hooks
>   ns_internals
>   ns_lowlev
>   ns_reflect.Rd
>   tools_internal
>   ts_defunct
>   utils_deprecated
>   utils_internal
>   ... and another
> 
> i.e, by '_'
> 
> Because it is impossible to make a good highlighter with the first one.
> 
> How to differentiating myValue:
> 
> varOne = 100
> varTwo = 50
> myValue = varOne-varTwo
> 
> from codes-deprecated, or ns-alt, for example.

One can create a variable with a minus in it by using
backquotes:

> `a-b` <- 3
> a <- 10
> b <- 4
> `a-b` + a-b
[1] 9  # 3 + 10 - 4



From ggrothendieck at gmail.com  Fri Aug  5 00:31:53 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 4 Aug 2005 18:31:53 -0400
Subject: [R] An small suggestion for the R team
In-Reply-To: <971536df05080415267e363b79@mail.gmail.com>
References: <42F29005.1060609@terra.com.br>
	<971536df05080415267e363b79@mail.gmail.com>
Message-ID: <971536df0508041531701e20fb@mail.gmail.com>

On 8/4/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> On 8/4/05, Jose Claudio Faria <joseclaudio.faria at terra.com.br> wrote:
> > Hi all,
> >
> > I would like to suggest that all R functions/etc like:
> >   codes-deprecated
> >   grid-internal
> >   ns-alt
> >   ns-dblcolon
> >   ns-hooks
> >   ns-internals
> >   ns-lowlev
> >   ns-reflect.Rd
> >   tools-internal
> >   ts-defunct
> >   utils-deprecated
> >   utils-internal
> >   ... and another
> >
> > i.e, function/word separate for '-'
> >
> > were all substituted by
> >   codes_deprecated
> >   grid_internal
> >   ns_alt
> >   ns_dblcolon
> >   ns_hooks
> >   ns_internals
> >   ns_lowlev
> >   ns_reflect.Rd
> >   tools_internal
> >   ts_defunct
> >   utils_deprecated
> >   utils_internal
> >   ... and another
> >
> > i.e, by '_'
> >
> > Because it is impossible to make a good highlighter with the first one.
> >
> > How to differentiating myValue:
> >
> > varOne = 100
> > varTwo = 50
> > myValue = varOne-varTwo
> >
> > from codes-deprecated, or ns-alt, for example.
> 
> One can create a variable with a minus in it by using
> backquotes:
> 
> > `a-b` <- 3
> > a <- 10
> > b <- 4
> > `a-b` + a-b
> [1] 9  # 3 + 10 - 4
> 

One other point.  The help system, i.e. ?, accommodates minus
signs like this where the last two statements below give
the same result:

library(survival)
?"survival-internal"
internal?survival

Another example is,

library(dyn)
package?dyn



From joseclaudio.faria at terra.com.br  Fri Aug  5 00:51:59 2005
From: joseclaudio.faria at terra.com.br (Jose Claudio Faria)
Date: Thu, 04 Aug 2005 19:51:59 -0300
Subject: [R] An small suggestion for the R team
In-Reply-To: <971536df0508041531701e20fb@mail.gmail.com>
References: <42F29005.1060609@terra.com.br>	
	<971536df05080415267e363b79@mail.gmail.com>
	<971536df0508041531701e20fb@mail.gmail.com>
Message-ID: <42F29C0F.4010904@terra.com.br>

Gabor Grothendieck wrote:
> On 8/4/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> 
>>On 8/4/05, Jose Claudio Faria <joseclaudio.faria at terra.com.br> wrote:
>>
>>>Hi all,
>>>
>>>I would like to suggest that all R functions/etc like:
>>>  codes-deprecated
>>>  grid-internal
>>>  ns-alt
>>>  ns-dblcolon
>>>  ns-hooks
>>>  ns-internals
>>>  ns-lowlev
>>>  ns-reflect.Rd
>>>  tools-internal
>>>  ts-defunct
>>>  utils-deprecated
>>>  utils-internal
>>>  ... and another
>>>
>>>i.e, function/word separate for '-'
>>>
>>>were all substituted by
>>>  codes_deprecated
>>>  grid_internal
>>>  ns_alt
>>>  ns_dblcolon
>>>  ns_hooks
>>>  ns_internals
>>>  ns_lowlev
>>>  ns_reflect.Rd
>>>  tools_internal
>>>  ts_defunct
>>>  utils_deprecated
>>>  utils_internal
>>>  ... and another
>>>
>>>i.e, by '_'
>>>
>>>Because it is impossible to make a good highlighter with the first one.
>>>
>>>How to differentiating myValue:
>>>
>>>varOne = 100
>>>varTwo = 50
>>>myValue = varOne-varTwo
>>>
>>>from codes-deprecated, or ns-alt, for example.
>>
>>One can create a variable with a minus in it by using
>>backquotes:
>>
>>
>>>`a-b` <- 3
>>>a <- 10
>>>b <- 4
>>>`a-b` + a-b
>>
>>[1] 9  # 3 + 10 - 4
>>
> 
> 
> One other point.  The help system, i.e. ?, accommodates minus
> signs like this where the last two statements below give
> the same result:
> 
> library(survival)
> ?"survival-internal"
> internal?survival
> 
> Another example is,
> 
> library(dyn)
> package?dyn

Indeed, the above are very good examples of how to contour the original problem Gabor!
But the central problem is to make Good R highlighter, as I'm trying to do
for the programs Tinn-R and jEdit with this functions.

Is not possible differentiate the signal minus as a simple character (word-word) from
the mathematical operator minus (object-object).

I think that is more easy to remove all this functions/reserved words.

TIA,
-- 
Jose Claudio Faria
Brasil/Bahia/UESC/DCET
Estatistica Experimental/Prof. Adjunto
mails:
  joseclaudio.faria at terra.com.br
  jc_faria at uesc.br
  jc_faria at uol.com.br
tel: 73-3634.2779



From mchaudha at jhsph.edu  Fri Aug  5 01:13:27 2005
From: mchaudha at jhsph.edu (Mohammad A. Chaudhary)
Date: Thu, 4 Aug 2005 19:13:27 -0400
Subject: [R] Where the error message comes from?
Message-ID: <7B4C4F3BD3C32243B0FC170251843990016FD864@XCH-VN02.sph.ad.jhsph.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050804/5af51a4f/attachment.pl

From mcrawford at gmail.com  Fri Aug  5 01:25:40 2005
From: mcrawford at gmail.com (Matt Crawford)
Date: Thu, 4 Aug 2005 16:25:40 -0700
Subject: [R] Avoiding for loop
Message-ID: <77b4b03e05080416253115fbd0@mail.gmail.com>

I understand that in R, for loops are not used as often as other
languages, and am trying to learn how to avoid them.  I am wondering
if there is a more efficient way to write a certain piece of code,
which right now I can only envision as a for loop.  I have a data file
that basically looks like:
1,55
1,23
2,12
...
that defines a matrix.  Each row of the data file corresponds to a row
of the matrix, where each number in the row tells me what column a "1"
or "-1" should go into.  So the first row in the data snippet above
means that the first row of my matrix needs to have a 1 in the 1st
column, and a -1 in the 55nd column.  (And 0 elsewhere, which is
already there as I've created the matrix filled with 0s beforehand.)

So my current code looks like:
        if(nrow(rawdata) >= 1) for(i in 1:nrow(rawdata)) {
                        X[i, rawdata[i, 1]] <- 1
                        X[i, rawdata[i, 2]] <- -1
                } 

where rawdata is the original data file.
This sort of assignment happens many times in my program so any
improvement would be much appreciated.  Thanks.



From tlumley at u.washington.edu  Fri Aug  5 01:27:59 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 4 Aug 2005 16:27:59 -0700 (PDT)
Subject: [R] An small suggestion for the R team
In-Reply-To: <42F29C0F.4010904@terra.com.br>
References: <42F29005.1060609@terra.com.br>
	<971536df05080415267e363b79@mail.gmail.com>
	<971536df0508041531701e20fb@mail.gmail.com>
	<42F29C0F.4010904@terra.com.br>
Message-ID: <Pine.A41.4.61b.0508041626510.405936@homer10.u.washington.edu>

On Thu, 4 Aug 2005, Jose Claudio Faria wrote:
>>>> I would like to suggest that all R functions/etc like:
>>>>  codes-deprecated
>>>>  grid-internal
>>>>  ns-alt
>>>>  ns-dblcolon
>>>>  ns-hooks
>>>>  ns-internals
>>>>  ns-lowlev
>>>>  ns-reflect.Rd
>>>>  tools-internal
>>>>  ts-defunct
>>>>  utils-deprecated
>>>>  utils-internal
>>>>  ... and another
>>>>

These are not R functions or reserved works. They are just the names of 
help pages.  They should not occur in code (except in double-quoted 
strings).

 	-thomas



From tlumley at u.washington.edu  Fri Aug  5 01:31:17 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 4 Aug 2005 16:31:17 -0700 (PDT)
Subject: [R] Avoiding for loop
In-Reply-To: <77b4b03e05080416253115fbd0@mail.gmail.com>
References: <77b4b03e05080416253115fbd0@mail.gmail.com>
Message-ID: <Pine.A41.4.61b.0508041628520.405936@homer10.u.washington.edu>

On Thu, 4 Aug 2005, Matt Crawford wrote:

> I understand that in R, for loops are not used as often as other
> languages, and am trying to learn how to avoid them.  I am wondering
> if there is a more efficient way to write a certain piece of code,
> which right now I can only envision as a for loop.  I have a data file
> that basically looks like:
> 1,55
> 1,23
> 2,12
> ...
> that defines a matrix.  Each row of the data file corresponds to a row
> of the matrix, where each number in the row tells me what column a "1"
> or "-1" should go into.  So the first row in the data snippet above
> means that the first row of my matrix needs to have a 1 in the 1st
> column, and a -1 in the 55nd column.  (And 0 elsewhere, which is
> already there as I've created the matrix filled with 0s beforehand.)
>

This may be a job for matrix indexes

    ii<-1:nrow(rawdata)
    X[cbind(ii,rawdata[,1])] <- 1
    X[cbind(ii,rawdata[,2])] <- -1


 	-thomas



From murdoch at stats.uwo.ca  Fri Aug  5 01:38:14 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 04 Aug 2005 19:38:14 -0400
Subject: [R] An small suggestion for the R team
In-Reply-To: <42F29005.1060609@terra.com.br>
References: <42F29005.1060609@terra.com.br>
Message-ID: <42F2A6E6.5080707@stats.uwo.ca>

Jose Claudio Faria wrote:
> Hi all,
> 
> I would like to suggest that all R functions/etc like:
>    codes-deprecated
>    grid-internal
>    ns-alt
>    ns-dblcolon
>    ns-hooks
>    ns-internals
>    ns-lowlev
>    ns-reflect.Rd
>    tools-internal
>    ts-defunct
>    utils-deprecated
>    utils-internal
>    ... and another
> 
> i.e, function/word separate for '-'
> 
> were all substituted by
>    codes_deprecated
>    grid_internal
>    ns_alt
>    ns_dblcolon
>    ns_hooks
>    ns_internals
>    ns_lowlev
>    ns_reflect.Rd
>    tools_internal
>    ts_defunct
>    utils_deprecated
>    utils_internal
>    ... and another
> 
> i.e, by '_'
> 
> Because it is impossible to make a good highlighter with the first one.

Your suggested names are all valid identifiers.  The "-" gives strings 
that are not.  That's intentional; the help system relies on it.  You 
find "utils-deprecated" using deprecated?utils.

If your highlighter has problems with the "-", then don't bother 
highlighting.  Those names aren't very common.  Or...
> 
> How to differentiating myValue:
> 
> varOne = 100
> varTwo = 50
> myValue = varOne-varTwo
> 
> from codes-deprecated, or ns-alt, for example.

...you could do it by context.  codes-deprecated will only show up in 
*.Rd files as a possible search term:  an alias, or a name.

Duncan Murdoch



From joseclaudio.faria at terra.com.br  Fri Aug  5 01:42:01 2005
From: joseclaudio.faria at terra.com.br (Jose Claudio Faria)
Date: Thu, 04 Aug 2005 20:42:01 -0300
Subject: [R] An small suggestion for the R team
In-Reply-To: <Pine.A41.4.61b.0508041626510.405936@homer10.u.washington.edu>
References: <42F29005.1060609@terra.com.br>
	<971536df05080415267e363b79@mail.gmail.com>	<971536df0508041531701e20fb@mail.gmail.com>
	<42F29C0F.4010904@terra.com.br>
	<Pine.A41.4.61b.0508041626510.405936@homer10.u.washington.edu>
Message-ID: <42F2A7C9.3010705@terra.com.br>

Hi THomas,

This is very a good information: thanks very much!
So, I will just now to remove all from the highlighters.
BTW, do you know if the signal minus is used in some function or reserved word?

TIA,

Jose Claudio Faria

Thomas Lumley wrote:
> On Thu, 4 Aug 2005, Jose Claudio Faria wrote:
> 
>>>>> I would like to suggest that all R functions/etc like:
>>>>>  codes-deprecated
>>>>>  grid-internal
>>>>>  ns-alt
>>>>>  ns-dblcolon
>>>>>  ns-hooks
>>>>>  ns-internals
>>>>>  ns-lowlev
>>>>>  ns-reflect.Rd
>>>>>  tools-internal
>>>>>  ts-defunct
>>>>>  utils-deprecated
>>>>>  utils-internal
>>>>>  ... and another
>>>>>
> 
> These are not R functions or reserved works. They are just the names of 
> help pages.  They should not occur in code (except in double-quoted 
> strings).
> 
>     -thomas



From murdoch at stats.uwo.ca  Fri Aug  5 01:51:18 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 04 Aug 2005 19:51:18 -0400
Subject: [R] Problem configuring R-patched
In-Reply-To: <42F2911F.3010203@utoronto.ca>
References: <42F26518.30708@utoronto.ca>	<1123190212.7455.5.camel@gsimpson.geog.ucl.ac.uk>
	<42F2911F.3010203@utoronto.ca>
Message-ID: <42F2A9F6.5030506@stats.uwo.ca>

Kevin E. Thorpe wrote:
> Gavin Simpson wrote:
> 
>>On Thu, 2005-08-04 at 14:57 -0400, Kevin E. Thorpe wrote:
>>
>>
>>>I downloaded R-patched (2005-08-04) from CRAN today.
>>>I ran ./configure --enable-R-shlib
>>>
>>>I received the error message:
>>>
>>>checking for recommended packages... no
>>>configure: error: Some of the recommended packages are missing
>>>  Use --without-recommended-packages if this was intentional
>>
>>         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>>So was this intentional?
> 
> 
> No, it wasn't.
> 
> 
>>>I built a previous version of R-patched successfully on my system
>>>which is running the SuSE 9,2 Pro Linux distribution.  I untarred the
>>>tar ball into the same directory I did my last build on in case that's
>>>important.
>>>
>>>The only other differences between this attempt and my successful build
>>>are:
>>>
>>>1. I did not use --enable-R-shlib last time.
>>>2. I found and installed the blas libraries for this build.
>>>
>>>Have I messed up or made an erroneous assumption along the way?
>>
>>
>>Yes and No. You obviously haven't compiled R recently. If you haven't
>>got the recommended packages in the source you are compiling, configure
>>now gives an error, which quite clearly states (and you've quoted it in
>>your email!) that it cannot find (some of) the recommended packages.
> 
> 
> Actually, I compiled it about a week ago.  Here is my current version.
> 
>  > version
>           _
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status   Patched
> major    2
> minor    1.1
> year     2005
> month    07
> day      28
> language R
> 
> When I compiled that version, I did my "tar xzf" to a clean directory
> and did not receive that error.
> 
> 
>>A solution - again given by the error message you quote! - is:
>>
>>./configure --enable-R-shlib --without-recommended-packages
>>                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>>
>>That should clear things up.
> 
> 
> I realise that would clear it up.  I was puzzled why I got this message
> in the first place, given I didn't get it last week.

I believe there are two kinds of tar files.  The daily snapshots don't 
include the recommended packages, the releases do.

Or perhaps the test is a recent addition.

Duncan Murdoch

> 
> 
>>Other wise you need to cd to the R directory (where you have the source
>>code), and then execute ./tools/rsync-recommended and then run your
>>configure command.
>>
>>HTH
>>
>>G
> 
> 
> Thanks for the rsync tip.
>



From joseclaudio.faria at terra.com.br  Fri Aug  5 01:52:51 2005
From: joseclaudio.faria at terra.com.br (Jose Claudio Faria)
Date: Thu, 04 Aug 2005 20:52:51 -0300
Subject: [R] An small suggestion for the R team
In-Reply-To: <42F2A6E6.5080707@stats.uwo.ca>
References: <42F29005.1060609@terra.com.br> <42F2A6E6.5080707@stats.uwo.ca>
Message-ID: <42F2AA53.40905@terra.com.br>

Ok Duncan,

Thank you very much for the tip!
I will to remove all these identifiers.

Regards,
--
Jose Claudio Faria

Duncan Murdoch wrote:
> Jose Claudio Faria wrote:
> 
>> Hi all,
>>
>> I would like to suggest that all R functions/etc like:
>>    codes-deprecated
>>    grid-internal
>>    ns-alt
>>    ns-dblcolon
>>    ns-hooks
>>    ns-internals
>>    ns-lowlev
>>    ns-reflect.Rd
>>    tools-internal
>>    ts-defunct
>>    utils-deprecated
>>    utils-internal
>>    ... and another
>>
>> i.e, function/word separate for '-'
>>
>> were all substituted by
>>    codes_deprecated
>>    grid_internal
>>    ns_alt
>>    ns_dblcolon
>>    ns_hooks
>>    ns_internals
>>    ns_lowlev
>>    ns_reflect.Rd
>>    tools_internal
>>    ts_defunct
>>    utils_deprecated
>>    utils_internal
>>    ... and another
>>
>> i.e, by '_'
>>
>> Because it is impossible to make a good highlighter with the first one.
> 
> 
> Your suggested names are all valid identifiers.  The "-" gives strings 
> that are not.  That's intentional; the help system relies on it.  You 
> find "utils-deprecated" using deprecated?utils.
> 
> If your highlighter has problems with the "-", then don't bother 
> highlighting.  Those names aren't very common.  Or...
> 
>>
>> How to differentiating myValue:
>>
>> varOne = 100
>> varTwo = 50
>> myValue = varOne-varTwo
>>
>> from codes-deprecated, or ns-alt, for example.
> 
> 
> ...you could do it by context.  codes-deprecated will only show up in 
> *.Rd files as a possible search term:  an alias, or a name.
> 
> Duncan Murdoch
>



From ggrothendieck at gmail.com  Fri Aug  5 03:35:02 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 4 Aug 2005 21:35:02 -0400
Subject: [R] Avoiding for loop
In-Reply-To: <77b4b03e05080416253115fbd0@mail.gmail.com>
References: <77b4b03e05080416253115fbd0@mail.gmail.com>
Message-ID: <971536df050804183521058064@mail.gmail.com>

On 8/4/05, Matt Crawford <mcrawford at gmail.com> wrote:
> I understand that in R, for loops are not used as often as other
> languages, and am trying to learn how to avoid them.  I am wondering
> if there is a more efficient way to write a certain piece of code,
> which right now I can only envision as a for loop.  I have a data file
> that basically looks like:
> 1,55
> 1,23
> 2,12
> ...
> that defines a matrix.  Each row of the data file corresponds to a row
> of the matrix, where each number in the row tells me what column a "1"
> or "-1" should go into.  So the first row in the data snippet above
> means that the first row of my matrix needs to have a 1 in the 1st
> column, and a -1 in the 55nd column.  (And 0 elsewhere, which is
> already there as I've created the matrix filled with 0s beforehand.)
> 
> So my current code looks like:
>        if(nrow(rawdata) >= 1) for(i in 1:nrow(rawdata)) {
>                        X[i, rawdata[i, 1]] <- 1
>                        X[i, rawdata[i, 2]] <- -1
>                }
> 
> where rawdata is the original data file.
> This sort of assignment happens many times in my program so any
> improvement would be much appreciated.  Thanks.


idx <- seq(length = max(rawdata, 0))
X <- outer(rawdata[,1], idx, "==") - outer(rawdata[,2], idx, "==")

Note that we did not have to predefine X and it also works if rawdata
has zero rows:

   rawdata <- matrix(0, nr = 0, nc = 2) 

in which case it gives a 0 by 0 matrix.



From kevin.thorpe at utoronto.ca  Fri Aug  5 04:13:05 2005
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Thu, 04 Aug 2005 22:13:05 -0400
Subject: [R] Problem configuring R-patched
In-Reply-To: <42F2A9F6.5030506@stats.uwo.ca>
References: <42F26518.30708@utoronto.ca>	<1123190212.7455.5.camel@gsimpson.geog.ucl.ac.uk>
	<42F2911F.3010203@utoronto.ca> <42F2A9F6.5030506@stats.uwo.ca>
Message-ID: <42F2CB31.6010906@utoronto.ca>

Duncan Murdoch wrote:
> Kevin E. Thorpe wrote:
> 
>> Gavin Simpson wrote:
>>
>>> On Thu, 2005-08-04 at 14:57 -0400, Kevin E. Thorpe wrote:
>>>
>>>
>>>> I downloaded R-patched (2005-08-04) from CRAN today.
>>>> I ran ./configure --enable-R-shlib
>>>>
>>>> I received the error message:
>>>>
>>>> checking for recommended packages... no
>>>> configure: error: Some of the recommended packages are missing
>>>>  Use --without-recommended-packages if this was intentional
>>>
>>>
>>>         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>>> So was this intentional?
>>
>>
>>
>> No, it wasn't.
>>
>>
>>>> I built a previous version of R-patched successfully on my system
>>>> which is running the SuSE 9,2 Pro Linux distribution.  I untarred the
>>>> tar ball into the same directory I did my last build on in case that's
>>>> important.
>>>>
>>>> The only other differences between this attempt and my successful build
>>>> are:
>>>>
>>>> 1. I did not use --enable-R-shlib last time.
>>>> 2. I found and installed the blas libraries for this build.
>>>>
>>>> Have I messed up or made an erroneous assumption along the way?
>>>
>>>
>>>
>>> Yes and No. You obviously haven't compiled R recently. If you haven't
>>> got the recommended packages in the source you are compiling, configure
>>> now gives an error, which quite clearly states (and you've quoted it in
>>> your email!) that it cannot find (some of) the recommended packages.
>>
>>
>>
>> Actually, I compiled it about a week ago.  Here is my current version.
>>
>>  > version
>>           _
>> platform i686-pc-linux-gnu
>> arch     i686
>> os       linux-gnu
>> system   i686, linux-gnu
>> status   Patched
>> major    2
>> minor    1.1
>> year     2005
>> month    07
>> day      28
>> language R
>>
>> When I compiled that version, I did my "tar xzf" to a clean directory
>> and did not receive that error.
>>
>>
>>> A solution - again given by the error message you quote! - is:
>>>
>>> ./configure --enable-R-shlib --without-recommended-packages
>>>                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>>>
>>> That should clear things up.
>>
>>
>>
>> I realise that would clear it up.  I was puzzled why I got this message
>> in the first place, given I didn't get it last week.
> 
> 
> I believe there are two kinds of tar files.  The daily snapshots don't 
> include the recommended packages, the releases do.
> 
> Or perhaps the test is a recent addition.

Both versions were R-patched.tar.gz as opposed to the devel sets which
looks like it's actually a link to the most recent.  Maybe I incorrectly
assumed that the patched tarballs contained the recommended packages.

> Duncan Murdoch
> 
>>
>>
>>> Other wise you need to cd to the R directory (where you have the source
>>> code), and then execute ./tools/rsync-recommended and then run your
>>> configure command.
>>>
>>> HTH
>>>
>>> G
>>
>>
>>
>> Thanks for the rsync tip.

Anyway, running rsync-recommended did the trick.

Thanks

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.946.8081  Fax: 416.971.2462



From spencer.graves at pdf.com  Fri Aug  5 04:50:39 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 04 Aug 2005 19:50:39 -0700
Subject: [R] Contour plot crest line
In-Reply-To: <5402C8EC-C5EE-4FA9-BFDC-6BD66A775605@virginia.edu>
References: <5402C8EC-C5EE-4FA9-BFDC-6BD66A775605@virginia.edu>
Message-ID: <42F2D3FF.7050701@pdf.com>

	  Have you studied the examples on the help pages for "contour" and 
"persp"?  Also, if my memory is correct, there is some useful 
information this on Venables and Ripley, Modern Applied Statistics with 
S, 4th ed. (Springer).

	  spencer graves

Michael Kubovy wrote:

> Any suggestions about drawing the ridge line on a response surface  
> represented as a contour plot?
> 
> _____________________________
> Professor Michael Kubovy
> University of Virginia
> Department of Psychology
> USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
> Parcels:    Room 102        Gilmer Hall
>          McCormick Road    Charlottesville, VA 22903
> Office:    B011    +1-434-982-4729
> Lab:        B019    +1-434-982-4751
> Fax:        +1-434-982-4766
> WWW:    http://www.people.virginia.edu/~mk9y/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From stat_ramesh at rediffmail.com  Fri Aug  5 08:44:13 2005
From: stat_ramesh at rediffmail.com (Ramesh Kolluru)
Date: 5 Aug 2005 06:44:13 -0000
Subject: [R] Problem
Message-ID: <20050805064413.12482.qmail@webmail52.rediffmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050805/c9ff1134/attachment.pl

From cniharral_rhelp at yahoo.es  Fri Aug  5 08:59:07 2005
From: cniharral_rhelp at yahoo.es (C NL)
Date: Fri, 5 Aug 2005 08:59:07 +0200 (CEST)
Subject: [R] Discriminant analysis
Message-ID: <20050805065907.48646.qmail@web25405.mail.ukl.yahoo.com>

Hi,

  I'm a newbie in R and don't much aobut all the
modules and their capabilities, but I'm interested in
solving a problem about a discriminant analysis done
with SPSS tool. The thing is that I would like to make
a discrimant analysis similar to the one done with
SPSS, but I can't find the way to solve it.

  I've been playing with R and I can handle more or
less my data, the point is that I need to know what
kind of discriminant analysis should I use to obtain
the same results as I obtain with SPSS. Should I use
"qda" or "lda"?? If not, what else could I use??

  Can anybody help me to find out a light in my way?
I've been searching all over the web to fetch any help
or example but I couldn't get anything.

  I would apreciate any help greatly.

Thanks

  Carlos Niharra L??pez
  Software Engineer
  Madrid (Spain)


		
______________________________________________ 

Nuevos servicios, m??s seguridad



From ligges at statistik.uni-dortmund.de  Fri Aug  5 10:16:43 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 05 Aug 2005 10:16:43 +0200
Subject: [R] Discriminant analysis
In-Reply-To: <20050805065907.48646.qmail@web25405.mail.ukl.yahoo.com>
References: <20050805065907.48646.qmail@web25405.mail.ukl.yahoo.com>
Message-ID: <42F3206B.1000301@statistik.uni-dortmund.de>

C NL wrote:

> Hi,
> 
>   I'm a newbie in R and don't much aobut all the
> modules and their capabilities, but I'm interested in
> solving a problem about a discriminant analysis done
> with SPSS tool. The thing is that I would like to make
> a discrimant analysis similar to the one done with
> SPSS, but I can't find the way to solve it.
> 
>   I've been playing with R and I can handle more or
> less my data, the point is that I need to know what
> kind of discriminant analysis should I use to obtain
> the same results as I obtain with SPSS. Should I use
> "qda" or "lda"?? If not, what else could I use??


Well, what about asking SPSS what it does, at first? What assumptions 
have you had re. the covariance matrix?
I guess the default will be a linear discriminant analysis, but I do not 
know SPSS. And *you* should know whether the analysis you did with SPSS 
made sense or not for your data (hence also which models/methods you 
applied).

Uwe Ligges


>   Can anybody help me to find out a light in my way?
> I've been searching all over the web to fetch any help
> or example but I couldn't get anything.
> 
>   I would apreciate any help greatly.
> 
> Thanks
> 
>   Carlos Niharra L??pez
>   Software Engineer
>   Madrid (Spain)
> 
> 
> 		
> ______________________________________________ 
> 
> Nuevos servicios, m??s seguridad
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Fri Aug  5 10:24:27 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 05 Aug 2005 10:24:27 +0200
Subject: [R] Where the error message comes from?
In-Reply-To: <7B4C4F3BD3C32243B0FC170251843990016FD864@XCH-VN02.sph.ad.jhsph.edu>
References: <7B4C4F3BD3C32243B0FC170251843990016FD864@XCH-VN02.sph.ad.jhsph.edu>
Message-ID: <42F3223B.7080204@statistik.uni-dortmund.de>

Mohammad A. Chaudhary wrote:

> Hi all:
> 
> I get the following error message that I am not able to resolve.
> 
>  
> 
> Error in if (const(t, min(1e-08, mean(t)/1e+06))) { : 
>
>         missing value where TRUE/FALSE needed


That means that for some value of "t",
   const(t, min(1e-08, mean(t)/1e+06))
gives NA or NaN rather than something that could be interpreted as TRUE 
or FALSE.

What is const, BTW?



>  
> 
> It appears right before the last data.frame statement. 
> 
>  
> 
> Below is the program that simulates data from one way random effects
> model and then computes normality and bootstrap confidence interval for
> Cost-Effectiveness Ratio. 
> 
>  
> 
> I have pasted the message in blue.

No, we do not want html mail (and the html version got deleted, see 
below), hence nothing is blue (although we statisticians do like sort of 
BLUEs, of course).

Uwe Ligges


>  
> 
> I appreciate any guidance in figuring it out.
> 
> Ashraf
> 
>  
> 
> #### SIMULATING DATA #####
> 
> SimClust <- function(k,m,mu,sb2,sw2,r,z)  {
> 
> #set.seed(1234)
> 
>  
> 
> # k   = Number of groups
> 
> # m   = Group size
> 
> # mu  = Group mean, same for all groups
> 
> # sb2 = Between group variance
> 
> # sw2 = Within group variance 
> 
> # r   = Corelation coefficient
> 
> # z   = standard normal variate cutoff value for binomial rv
> 
>       
> 
> # Simulate the random effects
> 
>    A = rnorm(n=k, mean=0, sd=sqrt(sb2))
> 
>  
> 
> # Work out the mean of each group of data
> 
>    means = matrix(mu, nrow=k,ncol=1)
> 
>    for(row in 1:k){        
> 
>      means[row] = means[row,1] + A[row]}
> 
>  
> 
> # Initializing the data vectors
> 
>   g=c=c1=mu1=numeric(k*m)
> 
>  
> 
> # Now generate the data one group at a time.
> 
> ind=0   
> 
> for(u in 1:k){
> 
>    for(replicate in 1:m){
> 
>          ind = ind + 1
> 
>        x=rnorm(1);y=rnorm(1)
> 
>        c[ind] = sqrt(sw2)*x+means[u]
> 
>        c1[ind] <- sqrt(sw2)*(x*r+y*sqrt(1-r**2))+means[u] 
> 
>        g[ind] = u
> 
>        mu1[ind] =means[u]
> 
>      }}  
> 
>  
> 
> data.frame(g=factor(g),c,e=(c1 > mean(c1)+z*sd(c1))+0)
> 
> }
> 
>  
> 
> #################################################################
> 
> sk1=sk2=sk11=sk21=skR=k1=m1=R2=R1=n10=f10=nb10=b10=s10=p10=bca10=NULL
> 
> n.cp=f.cp=nb.cp=b.cp=s.cp=p.cp=bca.cp=NULL
> 
>    
> 
> for (k in c(12,24,48)) {
> 
> for (m in c(25,50,100)) {
> 
> for (j in 1:1000) {
> 
>  
> 
> #### PREPARING CLUSTER LEVEL DATA ######
> 
>  d1=SimClust(k,m,mu=30,sb2=25,sw2=75,r=0.5,z=0.841621)  # for p=0.2
> 
>  d2=SimClust(k,m,mu=20,sb2=25,sw2=75,r=0.5,z=1.281552)  # for p=0.1
> 
>  
> 
> ## TREATMENT ##
> 
> r1 <- cor(d1[,2:3])[1,2]
> 
> # COST #
> 
>   ac1 <- anova(lm(c~g,d1))
> 
>   rc1 <- (ac1[1,3]-ac1[2,3])/(ac1[1,3]+(m-1)*ac1[2,3])
> 
>     if (rc1 < 0) rc1 <- 0 
> 
>   vc1 <- var(d1[,2])
> 
>   mc1 <- as.vector(by(d1[,2],as.numeric(d1[,1]),mean))
> 
>   vc1m <- vc1*(1+(m-1)*rc1)/(k*m)
> 
> # EFFECT #
> 
>   ae1 <- anova(lm(e~g,d1))
> 
>   re1 <- (ae1[1,3]-ae1[2,3])/(ae1[1,3]+(m-1)*ae1[2,3])
> 
>     if (re1 < 0) re1 <- 0 
> 
>   ve1 <- var(d1[,3])
> 
>   me1 <- as.vector(by(d1[,3],as.numeric(d1[,1]),mean))
> 
>   re1p <- 1- m*sum(me1*(1-me1))/(k*(m-1)*mean(me1)*(1-mean(me1)))
> 
>   ve1m <- ve1*(1+(m-1)*re1)/(k*m)
> 
> ## CONTROL ##
> 
> r2 <- cor(d2[,2:3])[1,2]
> 
> # COST #
> 
>   ac2 <- anova(lm(c~g,d2))
> 
>   rc2 <- (ac2[1,3]-ac2[2,3])/(ac2[1,3]+(m-1)*ac2[2,3])
> 
>     if (rc2 < 0) rc2 <- 0 
> 
>   vc2 <- var(d2[,2])
> 
>   mc2 <- as.vector(by(d2[,2],as.numeric(d2[,1]),mean))
> 
>   vc2m <- vc2*(1+(m-1)*rc2)/(k*m)
> 
> #  EFECT #
> 
>   ae2 <- anova(lm(e~g,d2))
> 
>   re2 <- (ae2[1,3]-ae2[2,3])/(ae2[1,3]+(m-1)*ae2[2,3])
> 
>     if (re2 < 0) re2 <- 0 
> 
>   ve2 <- var(d2[,3])
> 
>   me2 <- as.vector(by(d2[,3],as.numeric(d2[,1]),mean))
> 
>   re2p <- 1- m*sum(me2*(1-me2))/(k*(m-1)*mean(me2)*(1-mean(me2)))
> 
>   ve2m <- ve2*(1+(m-1)*re2)/(k*m)
> 
>  
> 
> ## Combining and Computing ICER ##
> 
> d <- data.frame(s = c(rep(1,k),rep(2,k)),
> 
>                 i = c(1:k,1:k),  n =rep(m,2*k),
> mc=c(mc1,mc2),me=c(me1,me2)) 
> 
>  
> 
>  mmc1   <- mean(d[1:k,4])
> 
>  mmc2   <- mean(d[(k+1):(2*k),4])
> 
>  mme1   <- mean(d[1:k,5])
> 
>  mme2   <- mean(d[(k+1):(2*k),5])
> 
>  
> 
>  cnn <- (vc1m+vc2m)/(mmc1-mmc2)^2
> 
>  cdd <- (ve1m+ve2m)/(mme1-mme2)^2
> 
>  cnd <-
> (r1*(vc1m*ve1m)^0.5+r2*(vc2m*ve2m)^0.5)/((mmc1-mmc2)*(mme1-mme2))
> 
>  
> 
>  R  <- (mmc1-mmc2)/(mme1-mme2)
> 
>  seR  <- R*(cnn+cdd-2*cnd)^0.5
> 
> f1 <-
> R*((1-3.8416*cnd)-1.96*((cnn+cdd-2*cnd)-3.8416*(cnn*cdd-cnd^2))^0.5)/(1-
> 3.8416*cdd)
> 
> f2 <-
> R*((1-3.8416*cnd)+1.96*((cnn+cdd-2*cnd)-3.8416*(cnn*cdd-cnd^2))^0.5)/(1-
> 3.8416*cdd)
> 
>  
> 
> ######## BOOTSTRAPPING AND PRINTING ##########   
> 
> icer<-function(d0,f)  {
> 
>  
> 
>  mmc1 <- mean(d0[1:k,4]*f[1:k])
> 
>  mmc2 <- mean(d0[(k+1):(2*k),4]*f[(k+1):(2*k)])
> 
>  mme1 <- mean(d0[1:k,5]*f[1:k])
> 
>  mme2 <- mean(d0[(k+1):(2*k),5]*f[(k+1):(2*k)])
> 
>  
> 
>  c((mmc1-mmc2)/(mme1-mme2),seR^2)
> 
> }
> 
>  
> 
> bout <- boot(d,icer, R=999, stype="f", strata=d[,1])
> 
> bci <- boot.ci(bout, conf = 0.95,  type =
> c("norm","basic","stud","perc","bca")) 
> 
>  
> 
> sk1[j] <- 3*(mean(d1[,2])-median(d1[,2]))/sd(d1[,2])
> 
> sk2[j] <- 3*(mean(d2[,2])-median(d2[,2]))/sd(d2[,2])
> 
>  
> 
>  
> 
>     R2[j]  <- R
> 
>    n10[j]  <- (100 < R-1.96*seR    || R+1.96*seR > 100)+0
> 
>    f10[j]  <- (100 < f1 || f2 > 100)+0
> 
>   nb10[j]  <- (100 < bci$norm[,2]  || bci$norm[,3]  > 100)+0
> 
>    b10[j]  <- (100 < bci$basic[,4] || bci$basic[,5] > 100)+0
> 
>    s10[j]  <- (100 < bci$stud[,4]  || bci$stud[,5]  > 100)+0
> 
>    p10[j]  <- (100 < bci$perc[,4]  || bci$perc[,5]  > 100)+0
> 
>  bca10[j]  <- (100 < bci$bca[,4]   || bci$bca[,5]   > 100)+0
> 
> }
> 
>  
> 
> k1=c(k1,k); m1=c(m1,m); R1=c(R1,mean(R2)); sk11=c(sk11,mean(sk1));
> sk21=c(sk21,mean(sk2));skR=c(skR,3*(mean(R2)-median(R2))/sd(R2));
> 
> n.cp=c(n.cp,mean(n10)); f.cp=c(f.cp,mean(f10));
> nb.cp=c(nb.cp,mean(nb10)); b.cp=c(b.cp,mean(b10)); 
> 
> s.cp=c(s.cp,mean(s10)); p.cp=c(p.cp,mean(p10));
> bca.cp=c(bca.cp,mean(bca10)); 
> 
>  
> 
> }}
> 
>  
> 
> Error in if (const(t, min(1e-08, mean(t)/1e+06))) { : 
> 
>         missing value where TRUE/FALSE needed
> 
>  
> 
> data.frame(k1,m1,sk11,sk21,skR,R1,n.cp,f.cp,nb.cp,b.cp,s.cp,p.cp,bca.cp)
> 
>  
> 
> NULL data frame with 0 rows
> 
>  
> 
> _________________________________
> 
> M. Ashraf Chaudhary, Ph.D.
> 
> Assisociate Scientist/Biostatistician
> 
> Department of International Health
> 
> Johns Hopkins Bloomberg School of Public Health
> 
> 615 N. Wolfe St.  Room W5506
> 
> Baltimore MD 21205-2179
> 
>  
> 
> (410) 502-0741/fax: (410) 502-6733
> 
> mchaudha at jhsph.edu
> 
> Web:http://faculty.jhsph.edu/?F=Mohammad&L=Chaudhary
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From maechler at stat.math.ethz.ch  Fri Aug  5 10:31:38 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 5 Aug 2005 10:31:38 +0200
Subject: [R] clara - memory limit
In-Reply-To: <D9A95B4B7B20354992E165EEADA31999056A9569@uswpmx00.merck.com>
References: <D9A95B4B7B20354992E165EEADA31999056A9569@uswpmx00.merck.com>
Message-ID: <17139.9194.573844.972908@stat.math.ethz.ch>


>>>>> "ReidH" == Huntsinger, Reid <reid_huntsinger at merck.com>
>>>>>     on Wed, 3 Aug 2005 13:21:45 -0400 writes:

    ReidH> I thought setting keep.data=FALSE might help, but
    ReidH> running this on a 32-bit Linux machine, the R process
    ReidH> seems to use 1.2 GB until just before clara returns,
    ReidH> when it increases to 1.9 GB, regardless of whether
    ReidH> keep.data=FALSE or TRUE. Possibly it's the overhead
    ReidH> of the .C() interface, but that's mostly an
    ReidH> uninformed guess.

not only;  I've found at least one place to save more memory for 
'keep.data = FALSE',
thanks to your careful observation, Reid!

This, together, with another small change, will lead to a new
release of the cluster package, soon.

Martin Maechler, ETH Zurich



From fdu.xiaojf at gamil.com  Fri Aug  5 10:34:49 2005
From: fdu.xiaojf at gamil.com (fdu.xiaojf@gamil.com)
Date: Fri, 05 Aug 2005 16:34:49 +0800
Subject: [R] Installation problem on SGI IRIX6.5
Message-ID: <42F324A9.6070907@gamil.com>

Hi, all,

I'm a newbie to R. I came across a problem when I tried to install R on
an SGI machine which is running IRIX64 6.5.

I have successfully run configure, but when I tried to run "make"(or
"gmake"), errors came out. Following is the error message.

Does someone has experiences in the R's installation on IRIX ? Any hints
will be greatly appreciated !

Thanks in advance!


Error Message:
------------------------------------------------------------------------

cc -I../../src/extra/zlib -I../../src/extra/bzip2 -I../../src/extra/pcre
  -I. -I../../src/include -I../../src/include
-I/user_data2/jfxiao/local/include -DHAVE_CONFIG_H -OPT:IEEE_NaN_inf=ON
  -g -c character.c -o character.o
cc-1185 cc: WARNING File = character.c, Line = 714
   An enumerated type is mixed with another type.

             warn = warn | !utf8strIsASCII(CHAR(STRING_ELT(CAR(args), i)));
                  ^

cc-1552 cc: WARNING File = character.c, Line = 698
   The variable "uclass" is set but never used.

       int i, len, minlen, uclass;
                           ^

cc-1020 cc: ERROR File = character.c, Line = 1300
   The identifier "wctrans_t" is undefined.

         wctrans_t tr = wctrans(ul ? "toupper" : "tolower");
         ^

cc-1185 cc: WARNING File = character.c, Line = 1733
   An enumerated type is mixed with another type.

         Rboolean warn = !utf8strIsASCII(CHAR(STRING_ELT(pat, 0)));
                         ^

cc-1185 cc: WARNING File = character.c, Line = 1926
   An enumerated type is mixed with another type.

       useRaw = strcmp(CHAR(STRING_ELT(stype, 0)), "integer");
              ^

1 error detected in the compilation of "character.c".
gmake[3]: *** [character.o] Error 2
gmake[3]: Leaving directory
`/user_data2/jfxiao/local/source/R/R-2.1.1/src/main'
gmake[2]: *** [R] Error 2
gmake[2]: Leaving directory
`/user_data2/jfxiao/local/source/R/R-2.1.1/src/main'
gmake[1]: *** [R] Error 1
gmake[1]: Leaving directory `/user_data2/jfxiao/local/source/R/R-2.1.1/src'
gmake: *** [R] Error 1



From rnitze at wiwi.uni-bielefeld.de  Fri Aug  5 10:37:46 2005
From: rnitze at wiwi.uni-bielefeld.de (Roy Nitze)
Date: Fri, 05 Aug 2005 10:37:46 +0200
Subject: [R] How to set the floating point precision beyond e-22?
Message-ID: <000001c59998$f4ddc320$8b554681@uwiwoeko152>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050805/f16c188f/attachment.pl

From rnitze at wiwi.uni-bielefeld.de  Fri Aug  5 10:44:18 2005
From: rnitze at wiwi.uni-bielefeld.de (Roy Nitze)
Date: Fri, 05 Aug 2005 10:44:18 +0200
Subject: [R] How to set the floating point precision beyond e-22?
Message-ID: <000501c59999$de3330f0$8b554681@uwiwoeko152>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050805/029ff2d7/attachment.pl

From alxmilton at yahoo.it  Fri Aug  5 10:58:08 2005
From: alxmilton at yahoo.it (alessandro carletti)
Date: Fri, 5 Aug 2005 01:58:08 -0700 (PDT)
Subject: [R] using "for" loop
Message-ID: <20050805085808.87956.qmail@web26606.mail.ukl.yahoo.com>

Hi everybody,
how can I create a loop for plotting parameters for
each level of a variable, for example:

NAME   temperature  depth
aaa      23           -1
aaa      22           -2
aaa      24           -1
bbb      23           -4
bbb      23           -1 
aaa      22           -1
bbb      22            0

I mean, I would like R to plot temperature vs depth
for aaa, then another plot for bbb, and so on.

Is it for loop ok?
Thanks



From renaud.lancelot at cirad.fr  Fri Aug  5 11:12:48 2005
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Fri, 05 Aug 2005 11:12:48 +0200
Subject: [R] using "for" loop
In-Reply-To: <20050805085808.87956.qmail@web26606.mail.ukl.yahoo.com>
References: <20050805085808.87956.qmail@web26606.mail.ukl.yahoo.com>
Message-ID: <42F32D90.1030803@cirad.fr>

alessandro carletti a ??crit :
> Hi everybody,
> how can I create a loop for plotting parameters for
> each level of a variable, for example:
> 
> NAME   temperature  depth
> aaa      23           -1
> aaa      22           -2
> aaa      24           -1
> bbb      23           -4
> bbb      23           -1 
> aaa      22           -1
> bbb      22            0
> 
> I mean, I would like R to plot temperature vs depth
> for aaa, then another plot for bbb, and so on.
> 
> Is it for loop ok?
> Thanks

Package lattice is your friend. Using your example:

Data <- read.table(file = "clipboard", header = TRUE)
library(lattice)
xyplot(temperature ~ depth | NAME, data = Data)

Best,

Renaud

-- 
Dr Renaud Lancelot, v??t??rinaire
Projet FSP r??gional ??pid??miologie v??t??rinaire
C/0 Ambassade de France - SCAC
BP 834 Antananarivo 101 - Madagascar

e-mail: renaud.lancelot at cirad.fr
tel.:   +261 32 40 165 53 (cell)
         +261 20 22 665 36 ext. 225 (work)
         +261 20 22 494 37 (home)



From markus.schwarz at wsl.ch  Fri Aug  5 11:24:54 2005
From: markus.schwarz at wsl.ch (Markus Schwarz)
Date: Fri, 05 Aug 2005 11:24:54 +0200
Subject: [R] kappa-accuracy and test for signifcance
Message-ID: <5.2.1.1.1.20050805112406.040f9dd8@mail.wsl.ch>

Dear list,

I calculated the kappa-accuracy for two differnt classifications.
How can I test now the two kappa-value for significance?

thanks, Mark
.....................................................................
Markus Schwarz
Wissenschaftliche Mitarbeiterin
Eidg. Forschungsanstalt WSL
Forschungsprogramm Musterland
Z??rcherstrasse 111
CH-8903 Birmensdorf

Telefon +41-44-739 22 87
Fax +41-44-739 22 15
markus.schwarz at wsl.ch
http://www.wsl.ch/staff/markus.schwarz/    	
.....................................................................



From baron at psych.upenn.edu  Fri Aug  5 12:09:30 2005
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Fri, 5 Aug 2005 06:09:30 -0400
Subject: [R] kappa-accuracy and test for signifcance
In-Reply-To: <5.2.1.1.1.20050805112406.040f9dd8@mail.wsl.ch>
References: <5.2.1.1.1.20050805112406.040f9dd8@mail.wsl.ch>
Message-ID: <20050805100930.GA729@psych>

On 08/05/05 11:24, Markus Schwarz wrote:
> Dear list,
> 
> I calculated the kappa-accuracy for two differnt classifications.
> How can I test now the two kappa-value for significance?

If you search the functions in 
http://finzi.psych.upenn.edu/nmz.html
or just use
RSiteSearch("kappa",restrict="functions")
then you will find several ways to compute kappa (assuming that
it is the same kappa we're talking about).
The first one I looked at (kappa2 in irr) yields a p value.

I'm not sure that this is what you are asking, though.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron



From murdoch at stats.uwo.ca  Fri Aug  5 12:45:38 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 05 Aug 2005 06:45:38 -0400
Subject: [R] How to set the floating point precision beyond e-22?
In-Reply-To: <000001c59998$f4ddc320$8b554681@uwiwoeko152>
References: <000001c59998$f4ddc320$8b554681@uwiwoeko152>
Message-ID: <42F34352.6070504@stats.uwo.ca>

Roy Nitze wrote:
> We have a problem inverting a matrix which has the following eigenvalues:
>  
> 
>>eigen(tcross, only.values=TRUE)
> 
> $values
>  [1]  7.917775e+20  2.130980e+16  7.961620e+13  8.241041e+12  2.258325e+12
>  [6]  3.869428e+11  6.791041e+10  2.485352e+09  9.863098e+08  9.819373e+05
> [11]  3.263408e+05  2.929853e+05  2.920419e+05  2.714355e+05  8.733435e+04
> [16]  8.127136e+04  6.543883e+04  5.335074e+04  3.773311e+04  2.904373e+04
> [21]  2.418297e+04  1.387422e+04  8.925090e+03  5.538344e+03  4.831908e+03
> [26]  1.133571e+03  9.882477e+02  7.725812e+02  5.081682e+02  3.010545e+02
> [31]  1.801611e+02  1.319787e+02  1.050521e+02  7.096471e+01  5.576549e+01
> [36]  4.192645e+01  3.549810e+01  2.638731e+01  2.444429e+01  1.735139e+01
> [41]  1.058796e+01  7.425778e+00  7.209576e+00  4.689665e+00  3.181650e+00
> [46]  3.002956e+00  1.959247e+00  1.551665e+00  1.079589e+00  1.064981e+00
> [51]  5.409617e-01  4.076501e-01  2.010129e-01  1.302394e-01  4.029787e-02
> [56]  2.599448e-02  1.061294e-02  1.634286e-03  4.095303e-09  1.021885e-10
> [61]  2.124763e-11  6.906665e-12  2.850103e-12  9.440867e-13  6.269723e-13
> [66]  1.043794e-13 -1.300171e-13 -7.220665e-13 -4.166945e-12 -6.145350e-12
> [71] -2.776804e-11 -5.269669e-11 -7.154246e-10 -1.490515e-09 -1.294256e-08
> [76] -1.224821e-02 -3.278657e+00 -4.620100e+01 -9.781843e+02 -1.303929e+04
> [81] -5.545949e+04 -8.077540e+04 -8.577861e+04 -1.329961e+05 -1.450908e+05
> [86] -3.022353e+05 -4.015776e+05
> 
> As yout can see, the eigenvalues spread very much (between e+20 and e-13).
> We presume, that it has something to do with R's floating point precision,
> which I read is about 22-digits in mantissa as default.

Less than that.  It depends a bit on the platform and the exact 
calculation, but you can't count on more than 15-16 decimal digits 
precision.

> Can this precision
> be set to values above 22? 

No.  R generally uses the floating point hardware type "double 
precision", and it's a fixed size.

The problem occurs especially when trying to
> perform 2SLS with the 'systemfit' package. There appears always an error
> message like the following from the inverting routine:
>  
> solve(tcross)
> Error in solve.default(tcross) : Lapack routine dgesv: system is exactly
> singular

You will have to find a different solution to the problem.  To machine 
precision, that matrix looks singular.  This usually indicates that it's 
not the right matrix to try to invert.

Duncan Murdoch



From p.dalgaard at biostat.ku.dk  Fri Aug  5 13:47:25 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Aug 2005 13:47:25 +0200
Subject: [R] How to set the floating point precision beyond e-22?
In-Reply-To: <42F34352.6070504@stats.uwo.ca>
References: <000001c59998$f4ddc320$8b554681@uwiwoeko152>
	<42F34352.6070504@stats.uwo.ca>
Message-ID: <x23bpoip0y.fsf@turmalin.kubism.ku.dk>

Duncan Murdoch <murdoch at stats.uwo.ca> writes:

> 
> You will have to find a different solution to the problem.  To machine 
> precision, that matrix looks singular.  This usually indicates that it's 
> not the right matrix to try to invert.

It might be a scaling issue though: If you're measuring age in days
and hormone concentrations in Molar, then you'll get that sort of
eigenvalue ratios in a fairly benign way.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ahenningsen at email.uni-kiel.de  Fri Aug  5 14:03:05 2005
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Fri, 5 Aug 2005 14:03:05 +0200
Subject: [R] Documenting data sets with many variables
Message-ID: <200508051403.05220.ahenningsen@email.uni-kiel.de>

Hi,

I extended the data set "Blanciforti86" that is included in my R package 
"micEcon". For instance, I added consumer prices, annual consumption 
expenditures and expenditure shares of eleven aggregate commodity groups. 
The corresponding variables in the data frame are called "pAgg1", 
"pAgg2", ..., "pAgg11", "xAgg1", "xAgg2", ..., "xAgg11", "wAgg1", 
"wAgg2", ..., "wAgg11". To avoid to describe all 33 items in the "\format" 
section of the documentation (.Rd file) I wrote something like

\format{
   This data frame contains the following columns:
   \describe{
      [ . . . ]
      \item{xAggX}{Expenditure on the aggregate commodity group X
         (in Millions of US-Dollars).}
      \item{pAggX}{Price index for the aggregate commodity group X 
         (1972 = 100).}
      \item{wAggX}{Expenditure share of the aggregate commodity group X.}
      [ . . . ]
   }
}

and explained the 11 aggregate commodity groups only once in a different 
section (1=food, 2=clothing, ... ). However, "R CMD check" now complains 
about "data codoc mismatches", e.g. 
  Code: [...] pAgg1pAgg2 pAgg3  [...] 
  Docs: [...] pAggX [...] 

Is there a way to avoid the description of all 33 items without getting a 
complaint from "R CMD check"?

Thanks,
Arne

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From dominik.grathwohl at rdls.nestle.com  Fri Aug  5 14:08:32 2005
From: dominik.grathwohl at rdls.nestle.com (Grathwohl, Dominik, LAUSANNE,
	NRC-BAS)
Date: Fri, 5 Aug 2005 14:08:32 +0200
Subject: [R] Help, my RGui is speaking French!
Message-ID: <63E04C5ADEDACB4989972239CDABF057046AE7@chlsne01.nestle.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050805/fc87585b/attachment.pl

From rnitze at wiwi.uni-bielefeld.de  Fri Aug  5 14:11:17 2005
From: rnitze at wiwi.uni-bielefeld.de (Roy Nitze)
Date: Fri, 05 Aug 2005 14:11:17 +0200
Subject: [R] How to set the floating point precision beyond e-22?
In-Reply-To: <mailman.0.1123227176.30323.r-help@stat.math.ethz.ch>
Message-ID: <000001c599b6$c9296cc0$8b554681@uwiwoeko152>

>> 
>> You will have to find a different solution to the problem.  To machine 
>> precision, that matrix looks singular.  This usually indicates that it's 
>> not the right matrix to try to invert.

> It might be a scaling issue though: If you're measuring age in days
> and hormone concentrations in Molar, then you'll get that sort of
> eigenvalue ratios in a fairly benign way.

I'm quite aware of that problem, but we have to deal with certain economic
variables which are usually given in a certain dimension. So it is difficult
to force all values to a certain order.

The other thing is, that i.e. EViews is able to perform 2SLS in the same
regression setup. Don't they have to invert the same matrices? If so, how do
they do it and how can we mimic their proceeding in R? Scaling and
Rescaling? What about the interpretation of the coefficients computed on a
scaled basis and given in the context of re-/unscaled data?

I'm not quite clear about it.

Thanks to all of you.



From jonathenwu at hotmail.com  Fri Aug  5 14:12:02 2005
From: jonathenwu at hotmail.com (=?gb2312?B?zuIg6rs=?=)
Date: Fri, 05 Aug 2005 12:12:02 +0000
Subject: [R] interpolation function
Message-ID: <BAY105-F266B2ACC8BE026E011E774D0C70@phx.gbl>

Hi,
I have a sparse matrix.I want to fill values into the entries whose value 
is 0.The new generated values should come from the interpolation of the 
values have existed.Does R provide such interpolation functions which 
operate on Matrix, for example ,such a matrix below
 0  0  0  0  2.3  0 0  0  0 
 0  0 3.1 0   0   0 0 1.4 0
 0  0  0  0   0   0 0  0  0
1.1 0  0  0   0   0 0  0  0
 0  0  0  4   0   0 0  0  6
 0  0  0  0   0   0 0  0  0
 0  0  0  0   0   7 0  0  0
 0  3  0  0   0   0 6  0  0
 0  0  0  0   9   0 0  0  0
thanks a lot
hao wu



From murdoch at stats.uwo.ca  Fri Aug  5 14:15:59 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 05 Aug 2005 08:15:59 -0400
Subject: [R] How to set the floating point precision beyond e-22?
In-Reply-To: <x23bpoip0y.fsf@turmalin.kubism.ku.dk>
References: <000001c59998$f4ddc320$8b554681@uwiwoeko152>	<42F34352.6070504@stats.uwo.ca>
	<x23bpoip0y.fsf@turmalin.kubism.ku.dk>
Message-ID: <42F3587F.5050803@stats.uwo.ca>

Peter Dalgaard wrote:
> Duncan Murdoch <murdoch at stats.uwo.ca> writes:
> 
> 
>>You will have to find a different solution to the problem.  To machine 
>>precision, that matrix looks singular.  This usually indicates that it's 
>>not the right matrix to try to invert.
> 
> 
> It might be a scaling issue though: If you're measuring age in days
> and hormone concentrations in Molar, then you'll get that sort of
> eigenvalue ratios in a fairly benign way.

Remember the old joke.

The patient to his doctor:  "It hurts when I do this."

The doctor:  "So don't do that."

Duncan Murdoch



From ligges at statistik.uni-dortmund.de  Fri Aug  5 14:18:20 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 05 Aug 2005 14:18:20 +0200
Subject: [R] Help, my RGui is speaking French!
In-Reply-To: <63E04C5ADEDACB4989972239CDABF057046AE7@chlsne01.nestle.com>
References: <63E04C5ADEDACB4989972239CDABF057046AE7@chlsne01.nestle.com>
Message-ID: <42F3590C.1060905@statistik.uni-dortmund.de>

Grathwohl, Dominik, LAUSANNE, NRC-BAS wrote:
> Dear R-helpers,
> 
> First of all I have nothing against the French language!
> But now my problem, yesterday I installed R 2.1.1
> and I had to experience that my RGui is speaking French.
> My windows locals is French (Switzerland).
> I'm used to English and I want to reset my RGui to English.
> I was seeking for the solution in the archives,
> however not successfully.
> By the way the searchable archives via:
> http://www.r-project.org/, Mailing Lists, R-help, web-interface, searchable achieves,
> did not work: http://maths.newcastle.edu.au/~rking/R/
> Also I was seeking in the FAQ's 
> http://cran.r-project.org/doc/FAQ/R-FAQ.html
> and
> http://www.stats.ox.ac.uk/pub/R/rw-FAQ.html
> and could not find the solution.
> I'm sure that lots of people have queried already 
> and that the solution is already written down somewhere.
> However I cant find it.
> Could somebody give me a hint?


For example, read the most recent R Newsletter on localization of R.
As one solution, set the environment variable
  LANGUAGE=en

Uwe Ligges



> Kind regards,
> 
> Dominik
> 
> 
> 
> My system:
> 
> platform i386-pc-mingw32
> arch     i386           
> os       mingw32        
> system   i386, mingw32  
> status                  
> major    2              
> minor    1.1            
> year     2005           
> month    06             
> day      20             
> language R          
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From rolf at math.unb.ca  Fri Aug  5 14:25:05 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Fri, 5 Aug 2005 09:25:05 -0300 (ADT)
Subject: [R] interpolation function
Message-ID: <200508051225.j75CP5Sj003718@erdos.math.unb.ca>


What you intend strikes me as being pretty silly.  Do not expect R to
work magic for you.  Even if there were such a function as you desire
in R, the results it would give would be effectively meaningless for
data such as you exhibited.

			cheers,

				Rolf Turner
				rolf at math.unb.ca



From rnitze at wiwi.uni-bielefeld.de  Fri Aug  5 14:26:35 2005
From: rnitze at wiwi.uni-bielefeld.de (Roy Nitze)
Date: Fri, 05 Aug 2005 14:26:35 +0200
Subject: [R]  How to set the floating point precision beyond e-22?
Message-ID: <000001c599b8$eb8ce9c0$8b554681@uwiwoeko152>

>> 
>> You will have to find a different solution to the problem.  To machine 
>> precision, that matrix looks singular.  This usually indicates that it's 
>> not the right matrix to try to invert.

> It might be a scaling issue though: If you're measuring age in days
> and hormone concentrations in Molar, then you'll get that sort of
> eigenvalue ratios in a fairly benign way.

I'm quite aware of that problem, but we have to deal with certain economic
variables which are usually given in a certain dimension. So it is difficult
to force all values to a certain order.

The other thing is, that i.e. EViews is able to perform 2SLS in the same
regression setup. Don't they have to invert the same matrices? If so, how do
they do it and how can we mimic their proceeding in R? Scaling and
Rescaling? What about the interpretation of the coefficients computed on a
scaled basis and given in the context of re-/unscaled data?

I'm not quite clear about it.

Thanks to all of you.



From p.dalgaard at biostat.ku.dk  Fri Aug  5 14:26:39 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 05 Aug 2005 14:26:39 +0200
Subject: [R] Help, my RGui is speaking French!
In-Reply-To: <63E04C5ADEDACB4989972239CDABF057046AE7@chlsne01.nestle.com>
References: <63E04C5ADEDACB4989972239CDABF057046AE7@chlsne01.nestle.com>
Message-ID: <x2y87gh8n4.fsf@turmalin.kubism.ku.dk>

"Grathwohl, Dominik, LAUSANNE,  NRC-BAS" <dominik.grathwohl at rdls.nestle.com> writes:

> Dear R-helpers,
> 
> First of all I have nothing against the French language!
> But now my problem, yesterday I installed R 2.1.1
> and I had to experience that my RGui is speaking French.
> My windows locals is French (Switzerland).
> I'm used to English and I want to reset my RGui to English.
> I was seeking for the solution in the archives,
> however not successfully.
> By the way the searchable archives via:
> http://www.r-project.org/, Mailing Lists, R-help, web-interface, searchable achieves,
> did not work: http://maths.newcastle.edu.au/~rking/R/
> Also I was seeking in the FAQ's 
> http://cran.r-project.org/doc/FAQ/R-FAQ.html
> and
> http://www.stats.ox.ac.uk/pub/R/rw-FAQ.html
> and could not find the solution.
> I'm sure that lots of people have queried already 
> and that the solution is already written down somewhere.
> However I cant find it.
> Could somebody give me a hint?

Make sure that the environment variable LANGUAGE is set to "en". I
think the consensus is that putting it into HOME/.Renviron is the most
practical way. 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ramasamy at cancer.org.uk  Fri Aug  5 14:53:25 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 05 Aug 2005 13:53:25 +0100
Subject: [R] interpolation function
In-Reply-To: <BAY105-F266B2ACC8BE026E011E774D0C70@phx.gbl>
References: <BAY105-F266B2ACC8BE026E011E774D0C70@phx.gbl>
Message-ID: <1123246405.6226.76.camel@ipc143004.lif.icnet.uk>

I do not understand your question. If this was not a sparse matrix, then
I would have asked you refer into the missing value literature. Even
there, people generally remove any columns/rows that have too many
missing values to avoid unreliable results. 

And since this is a sparse matrix, you are going to have too many
missing values on all rows and columns. I could be wrong but if I am,
someone will tell me that soon enough.

Regards, Adai



On Fri, 2005-08-05 at 12:12 +0000, å´ æ˜Š wrote:
> Hi,
> I have a sparse matrix.I want to fill values into the entries whose value 
> is 0.The new generated values should come from the interpolation of the 
> values have existed.Does R provide such interpolation functions which 
> operate on Matrix, for example ,such a matrix below
>  0  0  0  0  2.3  0 0  0  0 
>  0  0 3.1 0   0   0 0 1.4 0
>  0  0  0  0   0   0 0  0  0
> 1.1 0  0  0   0   0 0  0  0
>  0  0  0  4   0   0 0  0  6
>  0  0  0  0   0   0 0  0  0
>  0  0  0  0   0   7 0  0  0
>  0  3  0  0   0   0 6  0  0
>  0  0  0  0   9   0 0  0  0
> thanks a lot
> hao wu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From JAROSLAW.W.TUSZYNSKI at saic.com  Fri Aug  5 15:08:21 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Fri, 5 Aug 2005 09:08:21 -0400 
Subject: [R] An small suggestion for the R team
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD57F4118@us-arlington-0668.mail.saic.com>

Jose,

While writing highlighters for jEdit, I assume you are familiar with
existing R and Rd highlighters for jEdit. R mode was written by Tobias Elze,
based on a file from Zed A. Shaw, and I wrote Rd highlighter. 

If you (or anybody else needs them) I can send a copy.

Jarek
=====================================\====                 
 Jarek Tuszynski, PhD.                               o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                        ">  \
 Jaroslaw.W.Tuszynski at saic.com                   `    \



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jose Claudio Faria
Sent: Thursday, August 04, 2005 6:52 PM
To: Gabor Grothendieck
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] An small suggestion for the R team

Gabor Grothendieck wrote:
> On 8/4/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> 
>>On 8/4/05, Jose Claudio Faria <joseclaudio.faria at terra.com.br> wrote:
>>
>>>Hi all,
>>>
>>>I would like to suggest that all R functions/etc like:
>>>  codes-deprecated
>>>  grid-internal
>>>  ns-alt
>>>  ns-dblcolon
>>>  ns-hooks
>>>  ns-internals
>>>  ns-lowlev
>>>  ns-reflect.Rd
>>>  tools-internal
>>>  ts-defunct
>>>  utils-deprecated
>>>  utils-internal
>>>  ... and another
>>>
>>>i.e, function/word separate for '-'
>>>
>>>were all substituted by
>>>  codes_deprecated
>>>  grid_internal
>>>  ns_alt
>>>  ns_dblcolon
>>>  ns_hooks
>>>  ns_internals
>>>  ns_lowlev
>>>  ns_reflect.Rd
>>>  tools_internal
>>>  ts_defunct
>>>  utils_deprecated
>>>  utils_internal
>>>  ... and another
>>>
>>>i.e, by '_'
>>>
>>>Because it is impossible to make a good highlighter with the first one.
>>>
>>>How to differentiating myValue:
>>>
>>>varOne = 100
>>>varTwo = 50
>>>myValue = varOne-varTwo
>>>
>>>from codes-deprecated, or ns-alt, for example.
>>
>>One can create a variable with a minus in it by using
>>backquotes:
>>
>>
>>>`a-b` <- 3
>>>a <- 10
>>>b <- 4
>>>`a-b` + a-b
>>
>>[1] 9  # 3 + 10 - 4
>>
> 
> 
> One other point.  The help system, i.e. ?, accommodates minus signs 
> like this where the last two statements below give the same result:
> 
> library(survival)
> ?"survival-internal"
> internal?survival
> 
> Another example is,
> 
> library(dyn)
> package?dyn

Indeed, the above are very good examples of how to contour the original
problem Gabor!
But the central problem is to make Good R highlighter, as I'm trying to do
for the programs Tinn-R and jEdit with this functions.

Is not possible differentiate the signal minus as a simple character
(word-word) from the mathematical operator minus (object-object).

I think that is more easy to remove all this functions/reserved words.

TIA,
--
Jose Claudio Faria
Brasil/Bahia/UESC/DCET
Estatistica Experimental/Prof. Adjunto
mails:
  joseclaudio.faria at terra.com.br
  jc_faria at uesc.br
  jc_faria at uol.com.br
tel: 73-3634.2779

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From dmbates at gmail.com  Fri Aug  5 15:23:05 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Fri, 5 Aug 2005 08:23:05 -0500
Subject: [R] How to set the floating point precision beyond e-22?
In-Reply-To: <000001c59998$f4ddc320$8b554681@uwiwoeko152>
References: <000001c59998$f4ddc320$8b554681@uwiwoeko152>
Message-ID: <40e66e0b05080506236af3fa31@mail.gmail.com>

On 8/5/05, Roy Nitze <rnitze at wiwi.uni-bielefeld.de> wrote:
> We have a problem inverting a matrix which has the following eigenvalues:
> 
> > eigen(tcross, only.values=TRUE)
> $values
>  [1]  7.917775e+20  2.130980e+16  7.961620e+13  8.241041e+12  2.258325e+12
>  [6]  3.869428e+11  6.791041e+10  2.485352e+09  9.863098e+08  9.819373e+05
> [11]  3.263408e+05  2.929853e+05  2.920419e+05  2.714355e+05  8.733435e+04
> [16]  8.127136e+04  6.543883e+04  5.335074e+04  3.773311e+04  2.904373e+04
> [21]  2.418297e+04  1.387422e+04  8.925090e+03  5.538344e+03  4.831908e+03
> [26]  1.133571e+03  9.882477e+02  7.725812e+02  5.081682e+02  3.010545e+02
> [31]  1.801611e+02  1.319787e+02  1.050521e+02  7.096471e+01  5.576549e+01
> [36]  4.192645e+01  3.549810e+01  2.638731e+01  2.444429e+01  1.735139e+01
> [41]  1.058796e+01  7.425778e+00  7.209576e+00  4.689665e+00  3.181650e+00
> [46]  3.002956e+00  1.959247e+00  1.551665e+00  1.079589e+00  1.064981e+00
> [51]  5.409617e-01  4.076501e-01  2.010129e-01  1.302394e-01  4.029787e-02
> [56]  2.599448e-02  1.061294e-02  1.634286e-03  4.095303e-09  1.021885e-10
> [61]  2.124763e-11  6.906665e-12  2.850103e-12  9.440867e-13  6.269723e-13
> [66]  1.043794e-13 -1.300171e-13 -7.220665e-13 -4.166945e-12 -6.145350e-12
> [71] -2.776804e-11 -5.269669e-11 -7.154246e-10 -1.490515e-09 -1.294256e-08
> [76] -1.224821e-02 -3.278657e+00 -4.620100e+01 -9.781843e+02 -1.303929e+04
> [81] -5.545949e+04 -8.077540e+04 -8.577861e+04 -1.329961e+05 -1.450908e+05
> [86] -3.022353e+05 -4.015776e+05
> 
> As yout can see, the eigenvalues spread very much (between e+20 and e-13).
> We presume, that it has something to do with R's floating point precision,
> which I read is about 22-digits in mantissa as default. Can this precision
> be set to values above 22? The problem occurs especially when trying to
> perform 2SLS with the 'systemfit' package. There appears always an error
> message like the following from the inverting routine:
> 
> solve(tcross)
> Error in solve.default(tcross) : Lapack routine dgesv: system is exactly
> singular
> 
> Or is there another source of error? We would like to embed R-routines in a
> non-commercial web application for which we need to employ 'systemfit'
> together with individual, user-submitted data. So the problem needs a
> general solution and not a special one for this particular matrix.

It appears that you are using the crossproduct but not taking
advantage of the symmetry.

The condition number of the crossproduct is the square of the
condition number of the original matrix so you are making your
conditioning problems much worse by taking the crossproduct.  I
suggest that you use a QR or SVD decomposition of the original model
matrix instead.  You will still end up with a very ill-conditioned
problem but now quite as bad as the one you have now.



From maechler at stat.math.ethz.ch  Fri Aug  5 15:54:02 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 5 Aug 2005 15:54:02 +0200
Subject: [R] Problem configuring R-patched
In-Reply-To: <42F2CB31.6010906@utoronto.ca>
References: <42F26518.30708@utoronto.ca>
	<1123190212.7455.5.camel@gsimpson.geog.ucl.ac.uk>
	<42F2911F.3010203@utoronto.ca> <42F2A9F6.5030506@stats.uwo.ca>
	<42F2CB31.6010906@utoronto.ca>
Message-ID: <17139.28538.177227.719096@stat.math.ethz.ch>

Sorry to chime in a bit late here..

>>>>> "Kevin" == Kevin E Thorpe <kevin.thorpe at utoronto.ca>
>>>>>     on Thu, 04 Aug 2005 22:13:05 -0400 writes:

    Kevin> Duncan Murdoch wrote:
    >> Kevin E. Thorpe wrote:
    >> 
    >>> Gavin Simpson wrote:
    >>> 
    >>>> On Thu, 2005-08-04 at 14:57 -0400, Kevin E. Thorpe
    >>>> wrote:
    >>>> 
    >>>> 
    >>>>> I downloaded R-patched (2005-08-04) from CRAN today.
    >>>>> I ran ./configure --enable-R-shlib
    >>>>> 
    >>>>> I received the error message:
    >>>>> 
    >>>>> checking for recommended packages... no configure:
    >>>>> error: Some of the recommended packages are missing
    >>>>> Use --without-recommended-packages if this was
    >>>>> intentional
    >>>> 
    >>>> 
    >>>> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ So was this intentional?
    >>> 
    >>> 
    >>> 
    >>> No, it wasn't.
    >>> 
    >>> 
    >>>>> I built a previous version of R-patched successfully
    >>>>> on my system which is running the SuSE 9,2 Pro Linux
    >>>>> distribution.  I untarred the tar ball into the same
    >>>>> directory I did my last build on in case that's
    >>>>> important.
    >>>>> 
    >>>>> The only other differences between this attempt and my
    >>>>> successful build are:
    >>>>> 
    >>>>> 1. I did not use --enable-R-shlib last time.  2. I
    >>>>> found and installed the blas libraries for this build.
    >>>>> 
    >>>>> Have I messed up or made an erroneous assumption along
    >>>>> the way?
    >>>> 
    >>>> 
    >>>> 
    >>>> Yes and No. You obviously haven't compiled R
    >>>> recently. If you haven't got the recommended packages
    >>>> in the source you are compiling, configure now gives an
    >>>> error, which quite clearly states (and you've quoted it
    >>>> in your email!) that it cannot find (some of) the
    >>>> recommended packages.
    >>> 
    >>> 
    >>> 
    >>> Actually, I compiled it about a week ago.  Here is my
    >>> current version.
    >>> 
    >>> > version _ platform i686-pc-linux-gnu arch i686 os
    >>> linux-gnu system i686, linux-gnu status Patched major 2
    >>> minor 1.1 year 2005 month 07 day 28 language R
    >>> 
    >>> When I compiled that version, I did my "tar xzf" to a
    >>> clean directory and did not receive that error.
    >>> 
    >>> 
    >>>> A solution - again given by the error message you
    >>>> quote! - is:
    >>>> 
    >>>> ./configure --enable-R-shlib
    >>>> --without-recommended-packages
    >>>> ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    >>>> 
    >>>> That should clear things up.
    >>> 
    >>> 
    >>> 
    >>> I realise that would clear it up.  I was puzzled why I
    >>> got this message in the first place, given I didn't get
    >>> it last week.
    >> 
    >> 
    >> I believe there are two kinds of tar files.  The daily
    >> snapshots don't include the recommended packages, the
    >> releases do.

eeehm, no: The daily snapshots do contain the recommended packages,
and have for quite a while now.

    >> Or perhaps the test is a recent addition.

only for a pretty generous definition of "recent".

To be honest, I don't know what Kevin's problem could be.

The daily snapshots are really produced here at ETH Zurich and
daily mirrored from here to CRAN. I can see that the 
	 R-patched_2005-08-04.tar.gz
does contain the recommended packages.

Maybe your download wasn't completed; your disk full; or you
have a gnome in your computer who occasionally deletes some of
your files?  I've had similar feelings a few times in the
past...

    Kevin> Both versions were R-patched.tar.gz as opposed to the
    Kevin> devel sets which looks like it's actually a link to
    Kevin> the most recent.  Maybe I incorrectly assumed that

    Kevin> Maybe I incorrectly assumed that the patched tarballs
    Kevin> contained the recommended packages.

actually that was a correct assumption.

Martin Maechler, ETH Zurich



From admin at biostatistic.de  Fri Aug  5 16:12:39 2005
From: admin at biostatistic.de (Knut Krueger)
Date: Fri, 05 Aug 2005 16:12:39 +0200
Subject: [R] High resolution plots
In-Reply-To: <971536df0507131406564f7700@mail.gmail.com>
References: <42D53844.4040802@ebi-wasser.uni-karlsruhe.de>
	<971536df0507131406564f7700@mail.gmail.com>
Message-ID: <42F373D7.8080606@biostatistic.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050805/347731f7/attachment.pl

From spencer.graves at pdf.com  Fri Aug  5 16:23:03 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 05 Aug 2005 07:23:03 -0700
Subject: [R] How to set the floating point precision beyond e-22?
In-Reply-To: <40e66e0b05080506236af3fa31@mail.gmail.com>
References: <000001c59998$f4ddc320$8b554681@uwiwoeko152>
	<40e66e0b05080506236af3fa31@mail.gmail.com>
Message-ID: <42F37647.6030706@pdf.com>

	  And don't forget to rescale first, as Peter Dalgaard suggested.

	  I've been giving this lecture for over 20 years, and I got caught by 
it myself a few years ago.  I computed the crossproduct matrix, as Doug 
said, and had no end of trouble because it was numerically singular.  I 
rescaled each column by subtracting some number roughly close to the 
mean or median and dividing by something close to the standard 
deviation, and the problem went away.

	  spencer graves

Douglas Bates wrote:

> On 8/5/05, Roy Nitze <rnitze at wiwi.uni-bielefeld.de> wrote:
> 
>>We have a problem inverting a matrix which has the following eigenvalues:
>>
>>
>>>eigen(tcross, only.values=TRUE)
>>
>>$values
>> [1]  7.917775e+20  2.130980e+16  7.961620e+13  8.241041e+12  2.258325e+12
>> [6]  3.869428e+11  6.791041e+10  2.485352e+09  9.863098e+08  9.819373e+05
>>[11]  3.263408e+05  2.929853e+05  2.920419e+05  2.714355e+05  8.733435e+04
>>[16]  8.127136e+04  6.543883e+04  5.335074e+04  3.773311e+04  2.904373e+04
>>[21]  2.418297e+04  1.387422e+04  8.925090e+03  5.538344e+03  4.831908e+03
>>[26]  1.133571e+03  9.882477e+02  7.725812e+02  5.081682e+02  3.010545e+02
>>[31]  1.801611e+02  1.319787e+02  1.050521e+02  7.096471e+01  5.576549e+01
>>[36]  4.192645e+01  3.549810e+01  2.638731e+01  2.444429e+01  1.735139e+01
>>[41]  1.058796e+01  7.425778e+00  7.209576e+00  4.689665e+00  3.181650e+00
>>[46]  3.002956e+00  1.959247e+00  1.551665e+00  1.079589e+00  1.064981e+00
>>[51]  5.409617e-01  4.076501e-01  2.010129e-01  1.302394e-01  4.029787e-02
>>[56]  2.599448e-02  1.061294e-02  1.634286e-03  4.095303e-09  1.021885e-10
>>[61]  2.124763e-11  6.906665e-12  2.850103e-12  9.440867e-13  6.269723e-13
>>[66]  1.043794e-13 -1.300171e-13 -7.220665e-13 -4.166945e-12 -6.145350e-12
>>[71] -2.776804e-11 -5.269669e-11 -7.154246e-10 -1.490515e-09 -1.294256e-08
>>[76] -1.224821e-02 -3.278657e+00 -4.620100e+01 -9.781843e+02 -1.303929e+04
>>[81] -5.545949e+04 -8.077540e+04 -8.577861e+04 -1.329961e+05 -1.450908e+05
>>[86] -3.022353e+05 -4.015776e+05
>>
>>As yout can see, the eigenvalues spread very much (between e+20 and e-13).
>>We presume, that it has something to do with R's floating point precision,
>>which I read is about 22-digits in mantissa as default. Can this precision
>>be set to values above 22? The problem occurs especially when trying to
>>perform 2SLS with the 'systemfit' package. There appears always an error
>>message like the following from the inverting routine:
>>
>>solve(tcross)
>>Error in solve.default(tcross) : Lapack routine dgesv: system is exactly
>>singular
>>
>>Or is there another source of error? We would like to embed R-routines in a
>>non-commercial web application for which we need to employ 'systemfit'
>>together with individual, user-submitted data. So the problem needs a
>>general solution and not a special one for this particular matrix.
> 
> 
> It appears that you are using the crossproduct but not taking
> advantage of the symmetry.
> 
> The condition number of the crossproduct is the square of the
> condition number of the original matrix so you are making your
> conditioning problems much worse by taking the crossproduct.  I
> suggest that you use a QR or SVD decomposition of the original model
> matrix instead.  You will still end up with a very ill-conditioned
> problem but now quite as bad as the one you have now.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From ligges at statistik.uni-dortmund.de  Fri Aug  5 16:24:40 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 05 Aug 2005 16:24:40 +0200
Subject: [R] High resolution plots
In-Reply-To: <42F373D7.8080606@biostatistic.de>
References: <42D53844.4040802@ebi-wasser.uni-karlsruhe.de>	<971536df0507131406564f7700@mail.gmail.com>
	<42F373D7.8080606@biostatistic.de>
Message-ID: <42F376A8.6040309@statistik.uni-dortmund.de>

Knut Krueger wrote:

> 
> Gabor Grothendieck schrieb:
> 
> 
>>On 7/13/05, Luis Tercero <luis.tercero at ebi-wasser.uni-karlsruhe.de> wrote: 
>> 
>>
>>
>>>Dear R-help community,
>>>
>>>would any of you have a (preferably simple) example of a
>>>presentation-quality .png plot, i.e. one that looks like the .eps plots
>>>generated by R? I am working with R 2.0.1 in WindowsXP and am having
>>>similar problems as Knut Krueger in printing high-quality plots. I have
>>>looked at the help file and examples therein as well as others I have
>>>been able to find online but to no avail. After many many tries I have
>>>to concede I cannot figure it out.
>>>
>>>I would be very grateful for your help.
>>>   
>>>
>>
>>  If you want the highest resolution use a vector format,
>>not a bitmapped format such as png. See:
>>
>>http://maths.newcastle.edu.au/~rking/R/help/04/02/1168.html
>>
> 
> The link is now broken, and I did not copy the hints.
> Does anybody knows if it its available at any other location?
> 
> And I tried to find
> 
> 
>>Thanks for the pointer!  .wmf is far superior, I was just in the dark 
>>about the format and R's ability to produce it (An Introduction to R 
>>"Device drivers" does not mention it and I had obviously missed the 
>>deciding last two words in "?device" 'windows')
>>
> 
> the wmf command but there is nothing to find with help.search("wmf")


See ?win.metafile

Uwe Ligges


> with regards
> Knut Krueger
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Fri Aug  5 16:28:22 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 05 Aug 2005 07:28:22 -0700
Subject: [R] interpolation function
In-Reply-To: <200508051225.j75CP5Sj003718@erdos.math.unb.ca>
References: <200508051225.j75CP5Sj003718@erdos.math.unb.ca>
Message-ID: <42F37786.1040008@pdf.com>

	  I hope you don't take offense at anything said on this list.  My 
philosophy about this is summarized in something I wrote last December 
that has since been immoratlized in the "fortunes" package:

 > library(fortunes)
 > fortune("Spencer Graves")

Our great-great grandchilren as yet unborn may read some of the stupid
questions and/or answers that I and perhaps others give from time to 
time. I'd
rather get flamed for saying something stupid in public on this list than to
continue to provide substandard service to the people with whom I work 
because
I perpetrated the same mistake in an environment in which no one 
questioned so
effectively my errors.
    -- Spencer Graves (in a discussion on whether answers on R-help 
should be
       more polite)
       R-help (December 2004)

	  Best Wishes,
	  spencer graves

Rolf Turner wrote:

> What you intend strikes me as being pretty silly.  Do not expect R to
> work magic for you.  Even if there were such a function as you desire
> in R, the results it would give would be effectively meaningless for
> data such as you exhibited.
> 
> 			cheers,
> 
> 				Rolf Turner
> 				rolf at math.unb.ca
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From ripley at stats.ox.ac.uk  Fri Aug  5 16:33:05 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 5 Aug 2005 15:33:05 +0100 (BST)
Subject: [R] Help, my RGui is speaking French!
In-Reply-To: <x2y87gh8n4.fsf@turmalin.kubism.ku.dk>
References: <63E04C5ADEDACB4989972239CDABF057046AE7@chlsne01.nestle.com>
	<x2y87gh8n4.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0508051527290.30020@gannet.stats>

On Fri, 5 Aug 2005, Peter Dalgaard wrote:

> "Grathwohl, Dominik, LAUSANNE,  NRC-BAS" <dominik.grathwohl at rdls.nestle.com> writes:
>
>> Dear R-helpers,
>>
>> First of all I have nothing against the French language!
>> But now my problem, yesterday I installed R 2.1.1
>> and I had to experience that my RGui is speaking French.
>> My windows locals is French (Switzerland).
>> I'm used to English and I want to reset my RGui to English.
>> I was seeking for the solution in the archives,
>> however not successfully.

Well, did you try the `R Installation and Administration Manual'?  That 
does sound appropriate and it is covered there.

>> By the way the searchable archives via:
>> http://www.r-project.org/, Mailing Lists, R-help, web-interface, searchable achieves,
>> did not work: http://maths.newcastle.edu.au/~rking/R/
>> Also I was seeking in the FAQ's
>> http://cran.r-project.org/doc/FAQ/R-FAQ.html
>> and
>> http://www.stats.ox.ac.uk/pub/R/rw-FAQ.html
>> and could not find the solution.
>> I'm sure that lots of people have queried already
>> and that the solution is already written down somewhere.
>> However I cant find it.
>> Could somebody give me a hint?
>
> Make sure that the environment variable LANGUAGE is set to "en". I
> think the consensus is that putting it into HOME/.Renviron is the most
> practical way.

The rw-FAQ recommends a different way, though.

This is a new topic in the next release of the rw-FAQ (to go with the next 
release of R) since it has recently been fairly frequently asked.  To wit

   I selected English for Installation but R runs in Chinese!

   Precisely, you selected English @strong{for installation}!  The language
   of the installer has nothing to do with the language used to run R: this
   is completely standard Windows practice (and necessary as different
   users of the computer may use different languages).

   The language R uses for menus and messages is determined by the
   @emph{locale}: please read the appropriate manual (the @emph{R
   Installation and Administration Manual}) for the details.  You can
   ensure that R uses English messages by appending @code{LANGUAGE=en} to
   the shortcut you use to start R.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fdu.xiaojf at gamil.com  Fri Aug  5 16:33:13 2005
From: fdu.xiaojf at gamil.com (Xiao Jianfeng)
Date: Fri, 05 Aug 2005 22:33:13 +0800
Subject: [R] Installation problem on SGI IRIX6.5
In-Reply-To: <42F324A9.6070907@gamil.com>
References: <42F324A9.6070907@gamil.com>
Message-ID: <42F378A9.9070600@gamil.com>

fdu.xiaojf at gamil.com wrote:

> Hi, all,
>
> I'm a newbie to R. I came across a problem when I tried to install R on
> an SGI machine which is running IRIX64 6.5.
>
> I have successfully run configure, but when I tried to run "make"(or
> "gmake"), errors came out. Following is the error message.
>
> Does someone has experiences in the R's installation on IRIX ? Any hints
> will be greatly appreciated !
>
> Thanks in advance!
>
>
> Error Message:
> ------------------------------------------------------------------------
>
> cc -I../../src/extra/zlib -I../../src/extra/bzip2 -I../../src/extra/pcre
>  -I. -I../../src/include -I../../src/include
> -I/user_data2/jfxiao/local/include -DHAVE_CONFIG_H -OPT:IEEE_NaN_inf=ON
>  -g -c character.c -o character.o
> cc-1185 cc: WARNING File = character.c, Line = 714
>   An enumerated type is mixed with another type.
>
>             warn = warn | !utf8strIsASCII(CHAR(STRING_ELT(CAR(args), 
> i)));
>                  ^
>
> cc-1552 cc: WARNING File = character.c, Line = 698
>   The variable "uclass" is set but never used.
>
>       int i, len, minlen, uclass;
>                           ^
>
> cc-1020 cc: ERROR File = character.c, Line = 1300
>   The identifier "wctrans_t" is undefined.
>
>         wctrans_t tr = wctrans(ul ? "toupper" : "tolower");
>         ^

    I think the problem is here.

    In the GNU C Library, "wctrans_t" is defined in "wctype.h", but on
my system,
    "wctrans_t" is not defined in /usr/include/wctype.h

    Does anybody has successfully installed R 2.1.1 on IRIX 6.5 ? I have
spent all
    day surfing on the net but find no helpful information.

    Thanks again !

>
>
>
> 1 error detected in the compilation of "character.c".
> gmake[3]: *** [character.o] Error 2
> gmake[3]: Leaving directory
> `/user_data2/jfxiao/local/source/R/R-2.1.1/src/main'
> gmake[2]: *** [R] Error 2
> gmake[2]: Leaving directory
> `/user_data2/jfxiao/local/source/R/R-2.1.1/src/main'
> gmake[1]: *** [R] Error 1
> gmake[1]: Leaving directory 
> `/user_data2/jfxiao/local/source/R/R-2.1.1/src'
> gmake: *** [R] Error 1
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Fri Aug  5 16:38:40 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 5 Aug 2005 15:38:40 +0100 (BST)
Subject: [R] High resolution plots
In-Reply-To: <42F373D7.8080606@biostatistic.de>
References: <42D53844.4040802@ebi-wasser.uni-karlsruhe.de>
	<971536df0507131406564f7700@mail.gmail.com>
	<42F373D7.8080606@biostatistic.de>
Message-ID: <Pine.LNX.4.61.0508051535480.30020@gannet.stats>

On Fri, 5 Aug 2005, Knut Krueger wrote:

>
>
> Gabor Grothendieck schrieb:
>
>> On 7/13/05, Luis Tercero <luis.tercero at ebi-wasser.uni-karlsruhe.de> wrote:
>>
>>
>>> Dear R-help community,
>>>
>>> would any of you have a (preferably simple) example of a
>>> presentation-quality .png plot, i.e. one that looks like the .eps plots
>>> generated by R? I am working with R 2.0.1 in WindowsXP and am having
>>> similar problems as Knut Krueger in printing high-quality plots. I have
>>> looked at the help file and examples therein as well as others I have
>>> been able to find online but to no avail. After many many tries I have
>>> to concede I cannot figure it out.
>>>
>>> I would be very grateful for your help.
>>>
>>>
>>
>>   If you want the highest resolution use a vector format,
>> not a bitmapped format such as png. See:
>>
>> http://maths.newcastle.edu.au/~rking/R/help/04/02/1168.html
>>
> The link is now broken, and I did not copy the hints.
> Does anybody knows if it its available at any other location?
>
> And I tried to find
>
>> Thanks for the pointer!  .wmf is far superior, I was just in the dark
>> about the format and R's ability to produce it (An Introduction to R
>> "Device drivers" does not mention it and I had obviously missed the
>> deciding last two words in "?device" 'windows')
>>
> the wmf command but there is nothing to find with help.search("wmf")

Searching for acronyms is not usually a good idea.  Searching for 
`metafile' should work (on Windows).

Note that R can produce Windows metafiles only on Windows, which is why it 
is not in `An Introduction to R'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From feldesmanm at pdx.edu  Fri Aug  5 17:06:52 2005
From: feldesmanm at pdx.edu (Marc R. Feldesman)
Date: Fri, 05 Aug 2005 08:06:52 -0700
Subject: [R] Discriminant analysis
In-Reply-To: <20050805065907.48646.qmail@web25405.mail.ukl.yahoo.com>
References: <20050805065907.48646.qmail@web25405.mail.ukl.yahoo.com>
Message-ID: <6.2.1.2.2.20050805080058.02761e68@pop.mail.yahoo.com>

At 11:59 PM 8/4/2005, C NL wrote:
 >Hi,
 >
 >  I'm a newbie in R and don't much aobut all the
 >modules and their capabilities, but I'm interested in
 >solving a problem about a discriminant analysis done
 >with SPSS tool. The thing is that I would like to make
 >a discrimant analysis similar to the one done with
 >SPSS, but I can't find the way to solve it.
 >
 >  I've been playing with R and I can handle more or
 >less my data, the point is that I need to know what
 >kind of discriminant analysis should I use to obtain
 >the same results as I obtain with SPSS. Should I use
 >"qda" or "lda"?? If not, what else could I use??
 >
 >  Can anybody help me to find out a light in my way?
 >I've been searching all over the web to fetch any help
 >or example but I couldn't get anything.
 >
 >  I would apreciate any help greatly.


If you're using R, you are not going to get "SPSS results" using lda or 
qda.  You will get results comparable to SPSS, but not all the extra 
output.  Virtually all the extra output can be obtained by taking advantage 
of the programming tools available to you in R.  What you should do is to 
learn what lda is capable of doing -- read the help files in particular, 
read the book(s) on which lda is based (MASS - "Modern Applied Statistics 
with S" by Venables and Ripley, as well as Ripley's "Pattern Recognition 
and Neural Networks". )  Both books - coupled with the help files and the 
examples - give you a pretty good sense of what you can do with lda.  Study 
the output of an lda object to see what is in there.  If you understand 
discriminant analysis and the computations involved, R provides all the 
tools to go from the lda object to most of the information that you 
want.  However, if you are looking for statistics at the push of a button, 
then I suggest you stick with SPSS or SAS (or as an alternative, the 
commercial version of S - SPlus, which does have a very powerful 
discriminant routine built on the top of lda).

Hope this helps.



From tom at maladmin.com  Fri Aug  5 13:10:59 2005
From: tom at maladmin.com (tom wright)
Date: Fri, 05 Aug 2005 07:10:59 -0400
Subject: [R] interpolation function
In-Reply-To: <BAY105-F266B2ACC8BE026E011E774D0C70@phx.gbl>
References: <BAY105-F266B2ACC8BE026E011E774D0C70@phx.gbl>
Message-ID: <1123240259.3951.1.camel@localhost.localdomain>

On Fri, 2005-05-08 at 12:12 +0000, å´ æ˜Š wrote:
> Hi,
> I have a sparse matrix.I want to fill values into the entries whose value 
> is 0.The new generated values should come from the interpolation of the 
> values have existed.Does R provide such interpolation functions which 
> operate on Matrix, for example ,such a matrix below
>  0  0  0  0  2.3  0 0  0  0 
>  0  0 3.1 0   0   0 0 1.4 0
>  0  0  0  0   0   0 0  0  0
> 1.1 0  0  0   0   0 0  0  0
>  0  0  0  4   0   0 0  0  6
>  0  0  0  0   0   0 0  0  0
>  0  0  0  0   0   7 0  0  0
>  0  3  0  0   0   0 6  0  0
>  0  0  0  0   9   0 0  0  0
> thanks a lot
> hao wu

Does this look like an answer? If anyone knows a better way please tell
me.

> d<-c(0,2,3,2,0,3,4,0,0,0,0,0)
> d.mat<-matrix(data=d,nrow=4,ncol=3,byrow=TRUE)
> for(i in 1:length(d.mat[1,])){
+ d.mat[,i][d.mat[,i]==0]<-mean(d.mat[,i][d.mat[,i]>0])
+ }

Thanks
Tom



From ggrothendieck at gmail.com  Fri Aug  5 17:13:20 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 5 Aug 2005 11:13:20 -0400
Subject: [R] High resolution plots
In-Reply-To: <42F373D7.8080606@biostatistic.de>
References: <42D53844.4040802@ebi-wasser.uni-karlsruhe.de>
	<971536df0507131406564f7700@mail.gmail.com>
	<42F373D7.8080606@biostatistic.de>
Message-ID: <971536df050805081311dbeef5@mail.gmail.com>

On 8/5/05, Knut Krueger <admin at biostatistic.de> wrote:
> 
> 
> Gabor Grothendieck schrieb:
> 
> >On 7/13/05, Luis Tercero <luis.tercero at ebi-wasser.uni-karlsruhe.de> wrote:
> >
> >
> >>Dear R-help community,
> >>
> >>would any of you have a (preferably simple) example of a
> >>presentation-quality .png plot, i.e. one that looks like the .eps plots
> >>generated by R? I am working with R 2.0.1 in WindowsXP and am having
> >>similar problems as Knut Krueger in printing high-quality plots. I have
> >>looked at the help file and examples therein as well as others I have
> >>been able to find online but to no avail. After many many tries I have
> >>to concede I cannot figure it out.
> >>
> >>I would be very grateful for your help.
> >>
> >>
> >
> >   If you want the highest resolution use a vector format,
> >not a bitmapped format such as png. See:
> >
> >http://maths.newcastle.edu.au/~rking/R/help/04/02/1168.html
> >
> The link is now broken, and I did not copy the hints.
> Does anybody knows if it its available at any other location?
> 
> And I tried to find
> 
> >Thanks for the pointer!  .wmf is far superior, I was just in the dark
> >about the format and R's ability to produce it (An Introduction to R
> >"Device drivers" does not mention it and I had obviously missed the
> >deciding last two words in "?device" 'windows')
> >
> the wmf command but there is nothing to find with help.search("wmf")


It seems that the links have changed so that the part of the
url that reads:

	http:maths.newcastle.edu.au/~rking

needs to be replaced with:

	http://tolstoy.newcastle.edu.au

That is, the link has changed from:

	http://maths.newcastle.edu.au/~rking/R/help/04/02/1168.html
to:
	http://tolstoy.newcastle.edu.au/R/help/04/02/1168.html

Alternately google for the message id, which is:

	<20040221000411.C14FC397E at mprdmxin.myway.com>



From dhiren22 at hotmail.com  Fri Aug  5 17:21:26 2005
From: dhiren22 at hotmail.com (Dhiren DSouza)
Date: Fri, 05 Aug 2005 11:21:26 -0400
Subject: [R]  SJava linux installation problems
Message-ID: <BAY102-F3635D982F2B43BFAE22371D3C70@phx.gbl>

Hi:

I am extremely new to linux so bare with the questions.  I am trying to 
install the SJava package for R on linux (debian).

I issue the R CMD INSTALL SJava_0.68-0.tar.gz and get the following error

Cannot find Java.
Please set your path to include the directory in which the java executable 
resides,
or set the environment variable JAVA_HOME before this configure script is 
run.

I have j2sdk1.4.2_08 installed and I am assuming that the I need to set the 
environment variable JAVA_HOME to its path, so I did the following

export JAVA_HOME=/usr/local/j2sdk1.4.2/j2sdk1.4.2_08/bin/

I get the same error as before.

Can someone please help me if I am missing something?  Your help will be 
greatly appreciated.

-Dhiren



From andy_liaw at merck.com  Fri Aug  5 17:26:46 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 5 Aug 2005 11:26:46 -0400
Subject: [R] interpolation function
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EB63@usctmx1106.Merck.com>

I don't know if what Hao wanted to do is to hang himself, but if so, perhaps
here is one possible rope:

> idx <- which(m > 0, arr.ind=TRUE)
> m.nz <- m[idx]
> library(akima)
> (m.int <- interp.new(idx[,1], idx[,2], m.nz, xo=1:9, yo=1:9, extrap=TRUE))
$x
[1] 1 2 3 4 5 6 7 8 9

$y
[1] 1 2 3 4 5 6 7 8 9

$z
              [,1]      [,2]      [,3]       [,4]       [,5]       [,6]
[,7]
 [1,]   57.1356740  55.18522 38.413800  18.086957   2.300000   0.737908  22.
544616
 [2,]   18.8241001  19.35348  3.100000 -20.355403 -41.610566 -51.308028 -40.
090327
 [3,]    3.2234619   8.63630 -5.312670 -29.221287 -53.732091 -69.487619 -67.
130408
 [4,]    1.1000000  13.75521  4.290890 -17.935507 -43.566514 -63.244671 -67.
612515
 [5,]    3.2013295  25.25298 22.408739   4.000000 -20.615776 -42.081126 -51.
038588
 [6,]    0.2005624  33.62766 39.538938  27.083292   5.618185 -15.498922 -26.
910566
 [7,]  -17.2478151  29.37731 46.179546  41.812431  25.633428   7.000000  -4.
730390
 [8,]  -58.4893169   3.00000 32.828625  38.685475  29.928013  15.913700   6.
000000
 [9,] -130.5161684 -53.43667 -9.550716   8.258617   9.000000   1.817369  -3.
604296
             [,8]       [,9]
 [1,]  76.7287988 170.407375
 [2,]   1.4000000  80.913745
 [3,] -37.3029968  28.876027
 [4,] -47.3125835   6.953079
 [5,] -38.1307000   6.000000
 [6,] -19.2592860  16.750369
 [7,]  -0.2080329  29.451691
 [8,]   9.3350825  34.229953
 [9,]   0.8303142  21.211142

Note how wild the interpolated/extrapolated values can be...

Andy


> From: Adaikalavan Ramasamy
> 
> I do not understand your question. If this was not a sparse 
> matrix, then
> I would have asked you refer into the missing value literature. Even
> there, people generally remove any columns/rows that have too many
> missing values to avoid unreliable results. 
> 
> And since this is a sparse matrix, you are going to have too many
> missing values on all rows and columns. I could be wrong but if I am,
> someone will tell me that soon enough.
> 
> Regards, Adai
> 
> 
> 
> On Fri, 2005-08-05 at 12:12 +0000, Îâ ê» wrote:
> > Hi,
> > I have a sparse matrix.I want to fill values into the 
> entries whose value 
> > is 0.The new generated values should come from the 
> interpolation of the 
> > values have existed.Does R provide such interpolation 
> functions which 
> > operate on Matrix, for example ,such a matrix below
> >  0  0  0  0  2.3  0 0  0  0 
> >  0  0 3.1 0   0   0 0 1.4 0
> >  0  0  0  0   0   0 0  0  0
> > 1.1 0  0  0   0   0 0  0  0
> >  0  0  0  4   0   0 0  0  6
> >  0  0  0  0   0   0 0  0  0
> >  0  0  0  0   0   7 0  0  0
> >  0  3  0  0   0   0 6  0  0
> >  0  0  0  0   9   0 0  0  0
> > thanks a lot
> > hao wu
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From tom at maladmin.com  Fri Aug  5 13:30:57 2005
From: tom at maladmin.com (tom wright)
Date: Fri, 05 Aug 2005 07:30:57 -0400
Subject: [R] use of NA's
In-Reply-To: <1123240259.3951.1.camel@localhost.localdomain>
References: <BAY105-F266B2ACC8BE026E011E774D0C70@phx.gbl>
	<1123240259.3951.1.camel@localhost.localdomain>
Message-ID: <1123241457.3951.6.camel@localhost.localdomain>

Can someone please explain why this works: 

> > d<-c(0,2,3,2,0,3,4,0,0,0,0,0)
> > d.mat<-matrix(data=d,nrow=4,ncol=3,byrow=TRUE)
> > for(i in 1:length(d.mat[1,])){
> + d.mat[,i][d.mat[,i]==0]<-mean(d.mat[,i][d.mat[,i]>0])
> + }

Whereas: 

> d<-c(0,2,3,2,0,3,4,0,0,0,0,0)
> d.mat<-matrix(data=d,nrow=4,ncol=3,byrow=TRUE)
> d.mat[d.mat==0]<-NA
> for(i in 1:length(d.mat[1,])){
+ d.mat[,i][d.mat[,i]==NA]<-mean(d.mat[,i],na.rm=TRUE)
+ }
dosnt

Thanks
Tom



From KINLEY_ROBERT at Lilly.com  Fri Aug  5 17:36:04 2005
From: KINLEY_ROBERT at Lilly.com (Robert Kinley)
Date: Fri, 05 Aug 2005 16:36:04 +0100
Subject: [R] use of NA's
In-Reply-To: <1123241457.3951.6.camel@localhost.localdomain>
Message-ID: <OFB59FA4C8.A0D65A6C-ON80257054.00558EC1-80257054.0055B289@EliLilly.lilly.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050805/bcedcd39/attachment.pl

From rpeng at jhsph.edu  Fri Aug  5 17:37:09 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Fri, 05 Aug 2005 11:37:09 -0400
Subject: [R] use of NA's
In-Reply-To: <1123241457.3951.6.camel@localhost.localdomain>
References: <BAY105-F266B2ACC8BE026E011E774D0C70@phx.gbl>	<1123240259.3951.1.camel@localhost.localdomain>
	<1123241457.3951.6.camel@localhost.localdomain>
Message-ID: <42F387A5.8070508@jhsph.edu>

To test for 'NA' you shouldn't use '=='.  Use 'is.na()' instead.

-roger

tom wright wrote:
> Can someone please explain why this works: 
> 
> 
>>>d<-c(0,2,3,2,0,3,4,0,0,0,0,0)
>>>d.mat<-matrix(data=d,nrow=4,ncol=3,byrow=TRUE)
>>>for(i in 1:length(d.mat[1,])){
>>
>>+ d.mat[,i][d.mat[,i]==0]<-mean(d.mat[,i][d.mat[,i]>0])
>>+ }
> 
> 
> Whereas: 
> 
> 
>>d<-c(0,2,3,2,0,3,4,0,0,0,0,0)
>>d.mat<-matrix(data=d,nrow=4,ncol=3,byrow=TRUE)
>>d.mat[d.mat==0]<-NA
>>for(i in 1:length(d.mat[1,])){
> 
> + d.mat[,i][d.mat[,i]==NA]<-mean(d.mat[,i],na.rm=TRUE)
> + }
> dosnt
> 
> Thanks
> Tom
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From sundar.dorai-raj at pdf.com  Fri Aug  5 17:38:45 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Fri, 05 Aug 2005 10:38:45 -0500
Subject: [R] use of NA's
In-Reply-To: <1123241457.3951.6.camel@localhost.localdomain>
References: <BAY105-F266B2ACC8BE026E011E774D0C70@phx.gbl>	<1123240259.3951.1.camel@localhost.localdomain>
	<1123241457.3951.6.camel@localhost.localdomain>
Message-ID: <42F38805.3090303@pdf.com>



tom wright wrote:
> Can someone please explain why this works: 
> 
> 
>>>d<-c(0,2,3,2,0,3,4,0,0,0,0,0)
>>>d.mat<-matrix(data=d,nrow=4,ncol=3,byrow=TRUE)
>>>for(i in 1:length(d.mat[1,])){
>>
>>+ d.mat[,i][d.mat[,i]==0]<-mean(d.mat[,i][d.mat[,i]>0])
>>+ }
> 
> 
> Whereas: 
> 
> 
>>d<-c(0,2,3,2,0,3,4,0,0,0,0,0)
>>d.mat<-matrix(data=d,nrow=4,ncol=3,byrow=TRUE)
>>d.mat[d.mat==0]<-NA
>>for(i in 1:length(d.mat[1,])){
> 
> + d.mat[,i][d.mat[,i]==NA]<-mean(d.mat[,i],na.rm=TRUE)
> + }
> dosnt
> 
> Thanks
> Tom
> 

d.mat[,i] == NA returns NA. You want ?is.na to test for missing values.

--sundar



From dominik.grathwohl at rdls.nestle.com  Fri Aug  5 17:41:59 2005
From: dominik.grathwohl at rdls.nestle.com (Grathwohl, Dominik, LAUSANNE,
	NRC-BAS)
Date: Fri, 5 Aug 2005 17:41:59 +0200
Subject: [R]  Help, my RGui is speaking French!
Message-ID: <63E04C5ADEDACB4989972239CDABF057046AF0@chlsne01.nestle.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050805/4c7f7c89/attachment.pl

From robut at iinet.net.au  Fri Aug  5 17:43:53 2005
From: robut at iinet.net.au (Robert Cunningham)
Date: Fri, 5 Aug 2005 23:43:53 +0800
Subject: [R] High resolution plots
In-Reply-To: <Pine.LNX.4.61.0508051535480.30020@gannet.stats>
References: <42D53844.4040802@ebi-wasser.uni-karlsruhe.de>
	<42F373D7.8080606@biostatistic.de>
	<Pine.LNX.4.61.0508051535480.30020@gannet.stats>
Message-ID: <200508052343.54630.robut@iinet.net.au>

On Fri, 5 Aug 2005 22:38, Prof Brian Ripley wrote:
> On Fri, 5 Aug 2005, Knut Krueger wrote:
> > Gabor Grothendieck schrieb:
> >> On 7/13/05, Luis Tercero <luis.tercero at ebi-wasser.uni-karlsruhe.de> 
wrote:
> >>> Dear R-help community,
> >>>
> >>> would any of you have a (preferably simple) example of a
> >>> presentation-quality .png plot, i.e. one that looks like the .eps plots
> >>> generated by R? I am working with R 2.0.1 in WindowsXP and am having
> >>> similar problems as Knut Krueger in printing high-quality plots. I have
> >>> looked at the help file and examples therein as well as others I have
> >>> been able to find online but to no avail. After many many tries I have
> >>> to concede I cannot figure it out.
> >>>
> >>> I would be very grateful for your help.
> >>
> >>   If you want the highest resolution use a vector format,
> >> not a bitmapped format such as png. See:
> >>
> >> http://maths.newcastle.edu.au/~rking/R/help/04/02/1168.html
> >
> > The link is now broken, and I did not copy the hints.
> > Does anybody knows if it its available at any other location?
> >
> > And I tried to find
> >
> >> Thanks for the pointer!  .wmf is far superior, I was just in the dark
> >> about the format and R's ability to produce it (An Introduction to R
> >> "Device drivers" does not mention it and I had obviously missed the
> >> deciding last two words in "?device" 'windows')
> >
> > the wmf command but there is nothing to find with help.search("wmf")
>
> Searching for acronyms is not usually a good idea.  Searching for
> `metafile' should work (on Windows).
>
> Note that R can produce Windows metafiles only on Windows, which is why it
> is not in `An Introduction to R'.

As I mentioned last month 
(https://stat.ethz.ch/pipermail/r-help/2005-July/074591.html) 
I've been able to run R under Wine and use it to produce windows metafiles.




-- 
Cheers,

RJ Cunningham



From dieter.menne at menne-biomed.de  Fri Aug  5 17:56:43 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 5 Aug 2005 15:56:43 +0000 (UTC)
Subject: [R] prediction from glm
References: <051EED336DB7264EA57EBB75CB87168C9CA29A@GCTHQ1.gct.org.uk>
Message-ID: <loom.20050805T175241-499@post.gmane.org>

Hugues Santin-Janin <hsantin-janin <at> gct.org.uk> writes:

> I try to fit birds counts over years using glm. I have done (with Estate
> and year as factors):
> 
> Model1 <- glm(Females~Estate+Year+offset = log(area)), family =
> quasipoisson(link = log), na.action = "na.exclude") 
.. 
> Pred1 <- predict(Model1, type = "response", na.action = "na.exclude")
> 
> My question is: How can I obtain predictions for Females in each year
> that are standardized by averaging over the levels of Estate?

You should use the newdata argument in predict.glm to construct the "should-be" 
data set. The example on the page ?predict.glm creates budworm-data on the fly, 
but it's probably easier to understand if you create a separate data frame 
myfemales first, the do predict(Model1, newdata=myfemales,..) in a separate 
step.

Dieter Menne



From lami at faunalia.it  Fri Aug  5 18:00:44 2005
From: lami at faunalia.it (Leonardo Lami)
Date: Fri, 5 Aug 2005 18:00:44 +0200
Subject: [R] lda discriminant functions
Message-ID: <200508051800.44815.lami@faunalia.it>

Hi list,
I'm looking about lda function.
I'd like to know how calcolate the value of the discriminant functions for the 
original datas.
I see that in the result object "lda" there is $scaling a matrix which 
transforms observations to discriminant functions, normalized so that within 
groups covariance matrix is spherical.

I'd like to have the value of the discriminant function not normalized.

Best regards
Leonardo

-- 
Leonardo Lami
lami at faunalia.it            www.faunalia.it
Via Colombo 3 - 51010 Massa e Cozzile (PT), Italy   Tel: (+39)349-1310164
GPG key @: hkp://wwwkeys.pgp.net http://www.pgp.net/wwwkeys.html
https://www.biglumber.com



From ripley at stats.ox.ac.uk  Fri Aug  5 18:08:41 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 5 Aug 2005 17:08:41 +0100 (BST)
Subject: [R] Installation problem on SGI IRIX6.5
In-Reply-To: <42F378A9.9070600@gamil.com>
References: <42F324A9.6070907@gamil.com> <42F378A9.9070600@gamil.com>
Message-ID: <Pine.LNX.4.61.0508051653330.5979@gannet.stats>

Please do try reading the R-admin manual (as the INSTALL file asks you to: 
it does not ask you to `surf on the net').

The following section may help you:

   To enable UTF-8 support, configure with default @option{--enable-mbcs}.
   This will check for a large number of features, notably support for the
   C99/UNIX98 wide character functions and for UTF-8 or MBCS support in
   X11.  If enough of these are found, @code{MBCS} will be listed as one
   of the ``Additional capabilities''

so try --disable-mbcs if your OS has broken header files.  (It apparently 
does have wctrans, but not the type it returns.)

Now we know of the existence of such an OS, we can add a check.  Are 
wctrans and wctrans_t defined anywhere else?


On Fri, 5 Aug 2005, Xiao Jianfeng wrote:

> fdu.xiaojf at gamil.com wrote:
>
>> Hi, all,
>> 
>> I'm a newbie to R. I came across a problem when I tried to install R on
>> an SGI machine which is running IRIX64 6.5.
>> 
>> I have successfully run configure, but when I tried to run "make"(or
>> "gmake"), errors came out. Following is the error message.
>> 
>> Does someone has experiences in the R's installation on IRIX ? Any hints
>> will be greatly appreciated !
>> 
>> Thanks in advance!
>> 
>> 
>> Error Message:
>> ------------------------------------------------------------------------
>> 
>> cc -I../../src/extra/zlib -I../../src/extra/bzip2 -I../../src/extra/pcre
>>  -I. -I../../src/include -I../../src/include
>> -I/user_data2/jfxiao/local/include -DHAVE_CONFIG_H -OPT:IEEE_NaN_inf=ON
>>  -g -c character.c -o character.o
>> cc-1185 cc: WARNING File = character.c, Line = 714
>>   An enumerated type is mixed with another type.
>> 
>>             warn = warn | !utf8strIsASCII(CHAR(STRING_ELT(CAR(args), i)));
>>                  ^
>> 
>> cc-1552 cc: WARNING File = character.c, Line = 698
>>   The variable "uclass" is set but never used.
>> 
>>       int i, len, minlen, uclass;
>>                           ^
>> 
>> cc-1020 cc: ERROR File = character.c, Line = 1300
>>   The identifier "wctrans_t" is undefined.
>> 
>>         wctrans_t tr = wctrans(ul ? "toupper" : "tolower");
>>         ^
>
>   I think the problem is here.
>
>   In the GNU C Library, "wctrans_t" is defined in "wctype.h", but on
> my system,
>   "wctrans_t" is not defined in /usr/include/wctype.h
>
>   Does anybody has successfully installed R 2.1.1 on IRIX 6.5 ? I have
> spent all
>   day surfing on the net but find no helpful information.
>
>   Thanks again !
>
>> 
>> 
>> 
>> 1 error detected in the compilation of "character.c".
>> gmake[3]: *** [character.o] Error 2
>> gmake[3]: Leaving directory
>> `/user_data2/jfxiao/local/source/R/R-2.1.1/src/main'
>> gmake[2]: *** [R] Error 2
>> gmake[2]: Leaving directory
>> `/user_data2/jfxiao/local/source/R/R-2.1.1/src/main'
>> gmake[1]: *** [R] Error 1
>> gmake[1]: Leaving directory `/user_data2/jfxiao/local/source/R/R-2.1.1/src'
>> gmake: *** [R] Error 1
>> 
>> ------------------------------------------------------------------------
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>> 
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mrfearless47 at yahoo.com  Fri Aug  5 18:09:40 2005
From: mrfearless47 at yahoo.com (Marc Feldesman)
Date: Fri, 5 Aug 2005 09:09:40 -0700 (PDT)
Subject: [R] lda discriminant functions
In-Reply-To: <200508051800.44815.lami@faunalia.it>
Message-ID: <20050805160940.38016.qmail@web32612.mail.mud.yahoo.com>



--- Leonardo Lami <lami at faunalia.it> wrote:

> Hi list,
> I'm looking about lda function.
> I'd like to know how calcolate the value of the discriminant
> functions for the 
> original datas.
> I see that in the result object "lda" there is $scaling a matrix
> which 
> transforms observations to discriminant functions, normalized so that
> within 
> groups covariance matrix is spherical.
> 
> I'd like to have the value of the discriminant function not
> normalized.
> 

The information you need to do this is already there, but you need to
understand how to manipulate your raw data in conjunction with the lda
object to calculate the result you want.  If you don't understand the
matrix math involved and the statistics necessary, you probably won't
be successful.  Suggest you read ?lda, followed by MASS, followed by
Professor Ripley's Pattern Recognition and Neural Networks, followed by
a any good book that shows you the matrix algebra for doing the
discriminant calculations.  It isn't hard to do.  If you understand the
math to get the individual scores, normalized or unnormalized, but just
do not understand the "R-way" of doing things, check back again.  

Dr. Marc R Feldesman
Professor & Chair Emeritus
Department of Anthropology
Portland State University
Portland, OR 97207

Please respond to all emails at:  feldesmanm at pdx.edu

"Some people live and die by actuarial tables"  Groundhog Day



From martin at metahuman.org  Fri Aug  5 18:16:41 2005
From: martin at metahuman.org (Martin C. Martin)
Date: Fri, 05 Aug 2005 12:16:41 -0400
Subject: [R] Computing sums of the columns of an array
Message-ID: <42F390E9.3010301@metahuman.org>

Hi,

I have a 5x731 array A, and I want to compute the sums of the columns.  
Currently I do:

apply(A, 2, sum)

But it turns out, this is slow: 70% of my CPU time is spent here, even 
though there are many complicated steps in my computation.

Is there a faster way?

Thanks,
Martin



From andy_liaw at merck.com  Fri Aug  5 18:22:29 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 5 Aug 2005 12:22:29 -0400
Subject: [R] Computing sums of the columns of an array
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EB64@usctmx1106.Merck.com>

See ?colSums.

Andy

> From: Martin C. Martin
> 
> Hi,
> 
> I have a 5x731 array A, and I want to compute the sums of the 
> columns.  
> Currently I do:
> 
> apply(A, 2, sum)
> 
> But it turns out, this is slow: 70% of my CPU time is spent 
> here, even 
> though there are many complicated steps in my computation.
> 
> Is there a faster way?
> 
> Thanks,
> Martin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From reid_huntsinger at merck.com  Fri Aug  5 18:23:14 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Fri, 5 Aug 2005 12:23:14 -0400
Subject: [R] Computing sums of the columns of an array
Message-ID: <D9A95B4B7B20354992E165EEADA31999056A956F@uswpmx00.merck.com>

colSums() is a lot faster. 

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Martin C. Martin
Sent: Friday, August 05, 2005 12:17 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Computing sums of the columns of an array


Hi,

I have a 5x731 array A, and I want to compute the sums of the columns.  
Currently I do:

apply(A, 2, sum)

But it turns out, this is slow: 70% of my CPU time is spent here, even 
though there are many complicated steps in my computation.

Is there a faster way?

Thanks,
Martin

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From dieter.menne at menne-biomed.de  Fri Aug  5 18:20:12 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 5 Aug 2005 16:20:12 +0000 (UTC)
Subject: [R] fit non linear model using weighted least squares
References: <B08D5829F162FE4BBA1AE4F3CEBB45A7937EAD@asr02srv.ente.regione.emr.it>
Message-ID: <loom.20050805T181841-874@post.gmane.org>

Di Tanna Gian Luca <GDiTanna <at> Regione.Emilia-Romagna.it> writes:

> I'd like to fit a non linear model using weighted least squares.
> I am using the gnls function but I don't know how to perform a weighted
> least squares (my weights are a "simple" colum of data).

In your case it probably would be easier to use nls (in stats) instead of gnls. 
There is an example using weighting on the help-page.

Dieter Menne



From ligges at statistik.uni-dortmund.de  Fri Aug  5 18:24:09 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 05 Aug 2005 18:24:09 +0200
Subject: [R] Computing sums of the columns of an array
In-Reply-To: <42F390E9.3010301@metahuman.org>
References: <42F390E9.3010301@metahuman.org>
Message-ID: <42F392A9.5050700@statistik.uni-dortmund.de>

Martin C. Martin wrote:

> Hi,
> 
> I have a 5x731 array A, and I want to compute the sums of the columns.  
> Currently I do:
> 
> apply(A, 2, sum)


colSums(A)

Uwe Ligges


> But it turns out, this is slow: 70% of my CPU time is spent here, even 
> though there are many complicated steps in my computation.
> 
> Is there a faster way?
> 
> Thanks,
> Martin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From murdoch at stats.uwo.ca  Fri Aug  5 18:24:08 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 05 Aug 2005 12:24:08 -0400
Subject: [R] Computing sums of the columns of an array
In-Reply-To: <42F390E9.3010301@metahuman.org>
References: <42F390E9.3010301@metahuman.org>
Message-ID: <42F392A8.2040900@stats.uwo.ca>

On 8/5/2005 12:16 PM, Martin C. Martin wrote:
> Hi,
> 
> I have a 5x731 array A, and I want to compute the sums of the columns.  
> Currently I do:
> 
> apply(A, 2, sum)
> 
> But it turns out, this is slow: 70% of my CPU time is spent here, even 
> though there are many complicated steps in my computation.
> 
> Is there a faster way?

You'd probably do better with matrix multiplication:

rep(1, nrow(A)) %*% A

Duncan Murdoch



From roebuck at odin.mdacc.tmc.edu  Fri Aug  5 18:26:27 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Fri, 5 Aug 2005 11:26:27 -0500 (CDT)
Subject: [R] SJava linux installation problems
In-Reply-To: <BAY102-F3635D982F2B43BFAE22371D3C70@phx.gbl>
References: <BAY102-F3635D982F2B43BFAE22371D3C70@phx.gbl>
Message-ID: <Pine.OSF.4.58.0508051118180.304121@odin.mdacc.tmc.edu>

On Fri, 5 Aug 2005, Dhiren DSouza wrote:

> I am extremely new to linux so bare with the questions.  I am
> trying to install the SJava package for R on linux (debian).
>
> I issue the R CMD INSTALL SJava_0.68-0.tar.gz and get the
> following error
>
> Cannot find Java.
> Please set your path to include the directory in which the
> java executable resides, or set the environment variable
> JAVA_HOME before this configure script is run.
>
> I have j2sdk1.4.2_08 installed and I am assuming that the I
> need to set the environment variable JAVA_HOME to its path,
> so I did the following
>
> export JAVA_HOME=/usr/local/j2sdk1.4.2/j2sdk1.4.2_08/bin/

Remove '/bin/' from the environment variable path as
JAVA_HOME should point to the directory containing the
'bin' subdirectory. Best practice is NOT to include the
trailing slash of directory name in the value for an
environment variable.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From petr.mandys at matfyz.cz  Fri Aug  5 18:34:56 2005
From: petr.mandys at matfyz.cz (Petr Mandys)
Date: Fri, 5 Aug 2005 18:34:56 +0200 (CEST)
Subject: [R] log-logistic distribution
Message-ID: <Pine.LNX.4.62.0508051833090.9640@artax.karlin.mff.cuni.cz>

Hi,

I need to get quantile function for log-logistic distribution. How can I 
do it?

Thanks a lot

Pete



From gavin.simpson at ucl.ac.uk  Fri Aug  5 18:39:03 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 05 Aug 2005 17:39:03 +0100
Subject: [R] Computing sums of the columns of an array
In-Reply-To: <42F390E9.3010301@metahuman.org>
References: <42F390E9.3010301@metahuman.org>
Message-ID: <1123259944.9235.18.camel@gsimpson.geog.ucl.ac.uk>

On Fri, 2005-08-05 at 12:16 -0400, Martin C. Martin wrote:
> Hi,
> 
> I have a 5x731 array A, and I want to compute the sums of the columns.  
> Currently I do:
> 
> apply(A, 2, sum)
> 
> But it turns out, this is slow: 70% of my CPU time is spent here, even 
> though there are many complicated steps in my computation.
> 
> Is there a faster way?

Yes, colSums()

e.g.:

> set.seed(1234)
> dat <- matrix(runif(5*731), ncol = 731)
> system.time(for(i in 1:1000) apply(dat, 2, sum), gcFirst = TRUE)
[1] 8.05 0.00 9.89 0.00 0.00
> system.time(for(i in 1:1000) colSums(dat), gcFirst = TRUE)
[1] 0.09 0.01 0.09 0.00 0.00

But neither is that slow on my system. What is A?

HTH

Gav
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From kevin.thorpe at utoronto.ca  Fri Aug  5 18:41:09 2005
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Fri, 05 Aug 2005 12:41:09 -0400
Subject: [R] Problem configuring R-patched
In-Reply-To: <17139.28538.177227.719096@stat.math.ethz.ch>
References: <42F26518.30708@utoronto.ca>	<1123190212.7455.5.camel@gsimpson.geog.ucl.ac.uk>	<42F2911F.3010203@utoronto.ca>	<42F2A9F6.5030506@stats.uwo.ca>	<42F2CB31.6010906@utoronto.ca>
	<17139.28538.177227.719096@stat.math.ethz.ch>
Message-ID: <42F396A5.9070501@utoronto.ca>

Martin Maechler wrote:
>     Duncan> I believe there are two kinds of tar files.  The daily
>     Duncan> snapshots don't include the recommended packages, the
>     Duncan> releases do.
> 
> eeehm, no: The daily snapshots do contain the recommended packages,
> and have for quite a while now.
> 
>     Duncan> Or perhaps the test is a recent addition.
> 
> only for a pretty generous definition of "recent".
> 
> To be honest, I don't know what Kevin's problem could be.
> 
> The daily snapshots are really produced here at ETH Zurich and
> daily mirrored from here to CRAN. I can see that the 
> 	 R-patched_2005-08-04.tar.gz
> does contain the recommended packages.
> 
> Maybe your download wasn't completed; your disk full; or you
> have a gnome in your computer who occasionally deletes some of
> your files?  I've had similar feelings a few times in the
> past...
> 
>     Kevin> Both versions were R-patched.tar.gz as opposed to the
>     Kevin> devel sets which looks like it's actually a link to
>     Kevin> the most recent.  Maybe I incorrectly assumed that
> 
>     Kevin> Maybe I incorrectly assumed that the patched tarballs
>     Kevin> contained the recommended packages.
> 
> actually that was a correct assumption.
> 
> Martin Maechler, ETH Zurich

I still don't know why it didn't work observe (sorry for the wrapping):

kevin at rho:/home/src> tar tvzf R-patched.tar.gz | grep Recommended
drwxr-xr-x local/local       0 2005-08-03 20:45:50 
R-patched/src/library/Recommended/
-rw-r--r-- local/local    2394 2005-04-18 08:51:32 
R-patched/src/library/Recommended/Makefile.in
-rw-r--r-- local/local      20 2005-04-18 08:51:32 
R-patched/src/library/Recommended/.cvsignore
-rw-r--r-- local/local   25656 2005-04-18 08:58:17 
R-patched/src/library/Recommended/KernSmooth_2.22-15.tar.gz
-rw-r--r-- local/local  465529 2005-07-28 11:45:14 
R-patched/src/library/Recommended/VR_7.2-17.tar.gz
-rw-r--r-- local/local  179895 2005-07-28 11:45:14 
R-patched/src/library/Recommended/boot_1.2-23.tar.gz
-rw-r--r-- local/local  190975 2005-07-03 11:45:11 
R-patched/src/library/Recommended/cluster_1.10.1.tar.gz
-rw-r--r-- local/local  273520 2005-07-14 11:45:08 
R-patched/src/library/Recommended/foreign_0.8-9.tar.gz
-rw-r--r-- local/local  205131 2005-07-27 11:45:14 
R-patched/src/library/Recommended/lattice_0.12-1.tar.gz
-rw-r--r-- local/local  240276 2005-07-12 11:46:13 
R-patched/src/library/Recommended/mgcv_1.3-4.tar.gz
-rw-r--r-- local/local  662143 2005-07-26 11:45:13 
R-patched/src/library/Recommended/nlme_3.1-62.tar.gz
-rw-r--r-- local/local  110072 2005-04-19 11:45:20 
R-patched/src/library/Recommended/rpart_3.1-23.tar.gz
-rw-r--r-- local/local  846737 2005-06-10 11:45:23 
R-patched/src/library/Recommended/survival_2.18.tar.gz
lrwxrwxrwx local/local       0 2005-08-03 20:45:50 
R-patched/src/library/Recommended/VR.tgz -> VR_7.2-17.tar.gz
lrwxrwxrwx local/local       0 2005-08-03 20:45:50 
R-patched/src/library/Recommended/boot.tgz -> boot_1.2-23.tar.gz
lrwxrwxrwx local/local       0 2005-08-03 20:45:50 
R-patched/src/library/Recommended/cluster.tgz -> cluster_1.10.1.tar.gz
lrwxrwxrwx local/local       0 2005-08-03 20:45:50 
R-patched/src/library/Recommended/foreign.tgz -> foreign_0.8-9.tar.gz
lrwxrwxrwx local/local       0 2005-08-03 20:45:50 
R-patched/src/library/Recommended/KernSmooth.tgz -> 
KernSmooth_2.22-15.tar.gz
lrwxrwxrwx local/local       0 2005-08-03 20:45:50 
R-patched/src/library/Recommended/lattice.tgz -> lattice_0.12-1.tar.gz
lrwxrwxrwx local/local       0 2005-08-03 20:45:50 
R-patched/src/library/Recommended/nlme.tgz -> nlme_3.1-62.tar.gz
lrwxrwxrwx local/local       0 2005-08-03 20:45:50 
R-patched/src/library/Recommended/mgcv.tgz -> mgcv_1.3-4.tar.gz
lrwxrwxrwx local/local       0 2005-08-03 20:45:50 
R-patched/src/library/Recommended/rpart.tgz -> rpart_3.1-23.tar.gz
lrwxrwxrwx local/local       0 2005-08-03 20:45:50 
R-patched/src/library/Recommended/survival.tgz -> survival_2.18.tar.gz


It appears to me that the recommended packages were in the tarball.

I suppose it is largely immaterial now given I have successfully
re-built R.

Thanks your help.

-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.946.8081  Fax: 416.971.2462



From ligges at statistik.uni-dortmund.de  Fri Aug  5 18:43:43 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 05 Aug 2005 18:43:43 +0200
Subject: [R] Computing sums of the columns of an array
In-Reply-To: <42F392A8.2040900@stats.uwo.ca>
References: <42F390E9.3010301@metahuman.org> <42F392A8.2040900@stats.uwo.ca>
Message-ID: <42F3973F.4020904@statistik.uni-dortmund.de>

Duncan Murdoch wrote:

> On 8/5/2005 12:16 PM, Martin C. Martin wrote:
> 
>>Hi,
>>
>>I have a 5x731 array A, and I want to compute the sums of the columns.  
>>Currently I do:
>>
>>apply(A, 2, sum)
>>
>>But it turns out, this is slow: 70% of my CPU time is spent here, even 
>>though there are many complicated steps in my computation.
>>
>>Is there a faster way?
> 
> 
> You'd probably do better with matrix multiplication:
> 
> rep(1, nrow(A)) %*% A


No, better use colSums(), which has been optimized for this purpose:

  A <- matrix(seq(1, 10000000), ncol=10000)
  system.time(colSums(A))
  # ~ 0.1 sec.
  system.time(rep(1, nrow(A)) %*% A)
  # ~ 0.5 sec.


Uwe Ligges



> Duncan Murdoch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Fri Aug  5 18:50:55 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 5 Aug 2005 17:50:55 +0100 (BST)
Subject: [R] log-logistic distribution
In-Reply-To: <Pine.LNX.4.62.0508051833090.9640@artax.karlin.mff.cuni.cz>
References: <Pine.LNX.4.62.0508051833090.9640@artax.karlin.mff.cuni.cz>
Message-ID: <Pine.LNX.4.61.0508051749220.20790@gannet.stats>

On Fri, 5 Aug 2005, Petr Mandys wrote:

> I need to get quantile function for log-logistic distribution. How can I
> do it?

>From the quantile function qlogis for the logistic:
X is log-logistic iff log(X) is logistic.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ciblab1 at usu.edu  Fri Aug  5 18:51:07 2005
From: ciblab1 at usu.edu (Jake Michaelson)
Date: Fri, 05 Aug 2005 10:51:07 -0600
Subject: [R] heatmap row names as char vector?
Message-ID: <1123260667.16070.7.camel@localhost.localdomain>

Hi All,

Could anyone help me on how to output the row names of a heatmap as a
character vector?  I'm looking for a way to have the names in a list (or
similar) in the same order as they appear in the clustering of the
heatmap.

Thanks in advance,

Jake



From sasprog474 at yahoo.com  Fri Aug  5 18:52:48 2005
From: sasprog474 at yahoo.com (Greg Tarpinian)
Date: Fri, 5 Aug 2005 09:52:48 -0700 (PDT)
Subject: [R] contrast {Design} question
Message-ID: <20050805165248.81133.qmail@web32814.mail.mud.yahoo.com>

All,

I have been trying to get the following code to work:

A.quantiles <- quantile(foo.frame$A, 
probs = seq(from = 0.05, to = 0.95, by = 0.05))
base.quantiles <- quantile(Efficacy205$BASELINE_RANK,
probs = seq(from = 0.05, to = 0.95, by = 0.05))
gender <- levels(Efficacy205$GENDER)
contrast.1 
 <- contrast(Model.1, 
             list(TPCODE= 'A', 
                  AGE = age.quantiles, 
		  BASELINE_RANK = base.quantiles,
                  GENDER = gender),
	     list(TPCODE = 'D', 
                  AGE = age.quantiles, 
		  BASELINE_RANK = base.quantiles,
                  GENDER = gender),
	     type = 'average', 
             weights = table(gender))



From andy_liaw at merck.com  Fri Aug  5 18:52:39 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 5 Aug 2005 12:52:39 -0400
Subject: [R] Computing sums of the columns of an array
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EB65@usctmx1106.Merck.com>



> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Uwe Ligges
> Sent: Friday, August 05, 2005 12:44 PM
> To: Duncan Murdoch
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Computing sums of the columns of an array
> 
> 
> Duncan Murdoch wrote:
> 
> > On 8/5/2005 12:16 PM, Martin C. Martin wrote:
> > 
> >>Hi,
> >>
> >>I have a 5x731 array A, and I want to compute the sums of 
> the columns.  
> >>Currently I do:
> >>
> >>apply(A, 2, sum)
> >>
> >>But it turns out, this is slow: 70% of my CPU time is spent 
> here, even 
> >>though there are many complicated steps in my computation.
> >>
> >>Is there a faster way?
> > 
> > 
> > You'd probably do better with matrix multiplication:
> > 
> > rep(1, nrow(A)) %*% A
> 
> 
> No, better use colSums(), which has been optimized for this purpose:
> 
>   A <- matrix(seq(1, 10000000), ncol=10000)
>   system.time(colSums(A))
>   # ~ 0.1 sec.
>   system.time(rep(1, nrow(A)) %*% A)
>   # ~ 0.5 sec.

With the dimension that Martin stated, I don't see much difference:

> A <- matrix(runif(5 * 731), 5)
> system.time(replicate(1e4, rep(1, nrow(A)) %*% A), gcFirst=TRUE)
[1] 5.28 0.13 5.46   NA   NA
> system.time(replicate(1e4, rep(1, nrow(A)) %*% A), gcFirst=TRUE)
[1] 1.99 0.20 2.22   NA   NA
> system.time(replicate(1e4, rep(1, nrow(A)) %*% A), gcFirst=TRUE)
[1] 1.97 0.25 2.28   NA   NA
> system.time(replicate(1e4, rep(1, nrow(A)) %*% A), gcFirst=TRUE)
[1] 1.90 0.20 2.16   NA   NA
> system.time(replicate(1e4, colSums(A)), gcFirst=TRUE)
[1] 1.53 0.22 1.75   NA   NA
> system.time(replicate(1e4, colSums(A)), gcFirst=TRUE)
[1] 1.53 0.19 1.72   NA   NA
> system.time(replicate(1e4, colSums(A)), gcFirst=TRUE)
[1] 1.51 0.19 1.70   NA   NA
> system.time(replicate(1e4, colSums(A)), gcFirst=TRUE)
[1] 1.49 0.25 1.79   NA   NA

However, I don't understand why the first try took so much longer.

Andy 

 
> Uwe Ligges
> 
> 
> 
> > Duncan Murdoch
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From murdoch at stats.uwo.ca  Fri Aug  5 18:55:06 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 05 Aug 2005 12:55:06 -0400
Subject: [R] Computing sums of the columns of an array
In-Reply-To: <42F3973F.4020904@statistik.uni-dortmund.de>
References: <42F390E9.3010301@metahuman.org> <42F392A8.2040900@stats.uwo.ca>
	<42F3973F.4020904@statistik.uni-dortmund.de>
Message-ID: <42F399EA.307@stats.uwo.ca>

On 8/5/2005 12:43 PM, Uwe Ligges wrote:
> Duncan Murdoch wrote:
> 
>> On 8/5/2005 12:16 PM, Martin C. Martin wrote:
>> 
>>>Hi,
>>>
>>>I have a 5x731 array A, and I want to compute the sums of the columns.  
>>>Currently I do:
>>>
>>>apply(A, 2, sum)
>>>
>>>But it turns out, this is slow: 70% of my CPU time is spent here, even 
>>>though there are many complicated steps in my computation.
>>>
>>>Is there a faster way?
>> 
>> 
>> You'd probably do better with matrix multiplication:
>> 
>> rep(1, nrow(A)) %*% A
> 
> 
> No, better use colSums(), which has been optimized for this purpose:
> 
>   A <- matrix(seq(1, 10000000), ncol=10000)
>   system.time(colSums(A))
>   # ~ 0.1 sec.
>   system.time(rep(1, nrow(A)) %*% A)
>   # ~ 0.5 sec.

I didn't claim my solution was the best, only better. :-)

One point of interest:  I think your example exaggerates the difference 
by using a matrix of integers.  On my machine I get a ratio something 
like yours with the same example

 > A <- matrix(seq(1, 10000000), ncol=10000)
 >   system.time(colSums(A))
[1] 0.08 0.00 0.08   NA   NA
 >   system.time(rep(1, nrow(A)) %*% A)
[1] 0.25 0.01 0.23   NA   NA

but if I make A floating point, there's much less difference:

 > A <- matrix(as.numeric(seq(1, 10000000)), ncol=10000)
 >   system.time(colSums(A))
[1] 0.09 0.00 0.09   NA   NA
 >   system.time(rep(1, nrow(A)) %*% A)
[1] 0.11 0.00 0.12   NA   NA

Still, colSums is the winner in both cases.

Duncan Murdoch



From sasprog474 at yahoo.com  Fri Aug  5 19:00:39 2005
From: sasprog474 at yahoo.com (Greg Tarpinian)
Date: Fri, 5 Aug 2005 10:00:39 -0700 (PDT)
Subject: [R] contrast {Design} question
Message-ID: <20050805170040.83007.qmail@web32814.mail.mud.yahoo.com>

Sorry about the previous email, hadn't finished
editing yet....

Here is some code that I have been trying to get
to work:

A.quant <- 
quantile(foo.frame$A, 
         probs=seq(from=0.05, to=0.95, by=0.05))
B.quant <- 
quantile(foo.frame$B, 
         probs=seq(from=0.05, to=0.95, by=0.05))
gender <- levels(foo.frame$GENDER)

contrast.1 <- 
contrast(Model.1,
         list(TREAT= 'A', A= A.quant, 
	      B = B.quant, 
              GENDER = gender),
         list(TREAT= 'D', A= A.quant, 
              B = B.quant, 
              GENDER = gender),
	 type = 'average', weights = table(gender))

My goal is to obtain a set of "average" Type II
contrasts over the levels of GENDER, but not over the
levels of A and B.  R keeps telling me that 
"weights" needs to be 722 elements, but this is the
total number of contrasts over all levels of A,
B, and GENDER....

Any suggestions would be greatly appreciated,

      Greg



From edhuang00 at yahoo.com  Fri Aug  5 19:05:22 2005
From: edhuang00 at yahoo.com (Haibo Huang)
Date: Fri, 5 Aug 2005 10:05:22 -0700 (PDT)
Subject: [R] calculate likelihood based on logit regression
Message-ID: <20050805170522.28198.qmail@web31015.mail.mud.yahoo.com>

Hi,

I just ran the following logit regression. But can
anyone tell me how to calculate how much more likely
males (Male=1) could show such symptom than
females(Male=0)? I know it must be simple to get once
I have the coefficients, but I just don't recall.
Thank you very much!

Call:
glm(formula = Symptoms ~ 1 + Male, family =
binomial(link = logit), 
    data = HA)
Deviance Residuals: 
       Min          1Q      Median          3Q        
Max  
-6.038e+03  -2.067e-06   0.000e+00   0.000e+00  
6.720e+03  
Coefficients:
                      Estimate Std. Error    z value
Pr(>|z|)    
(Intercept)          5.711e+00  8.466e-02  6.746e+01  
<2e-16 ***
Male        -6.493e+00  8.540e-02 -7.603e+01   <2e-16
***


Best,
Ed



From martin at metahuman.org  Fri Aug  5 19:05:26 2005
From: martin at metahuman.org (Martin C. Martin)
Date: Fri, 05 Aug 2005 13:05:26 -0400
Subject: [R] Computing sums of the columns of an array
In-Reply-To: <1123259944.9235.18.camel@gsimpson.geog.ucl.ac.uk>
References: <42F390E9.3010301@metahuman.org>
	<1123259944.9235.18.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <42F39C56.40802@metahuman.org>

Thanks everyone.

Gavin Simpson wrote:

>But neither is that slow on my system. What is A?
>
It's in the middle of a loop.  I'm doing some maximum likelihood 
estimation, and having to evaluate my model over and over again for 
different parameter values.

Thanks,
Martin



From leonardosepulveda at gmail.com  Fri Aug  5 19:09:54 2005
From: leonardosepulveda at gmail.com (=?ISO-8859-1?Q?Leonardo_Sepulveda_Dur=E1n?=)
Date: Fri, 5 Aug 2005 13:09:54 -0400
Subject: [R] Cluster analysis of protein time series
Message-ID: <78a5a6fe0508051009635d4a03@mail.gmail.com>

Hello!!!

I have a question about clustering. I'll present my problem first.

I have a simulation of a protein trayectory (a file with a time series
of protein 3D-coordinates), from it I can calculate the Root Mean
Square desviation (RMSD) beetween any pair of  structures in the
trayectory, which is a rough idea of 3D similarity beetween them. If
for every conformation (trayectory frame) I calculate the RMSD with
all other frames in the trayectory, I get a RMSD matrix, which is the
data i  have now.

In some published works a conformational analysis is performed with
this. They represent every frame of the trayectory as a point in the
space (or plane); and having N(N-1)/2 independent distances (RMSD
matrix, D[i, j]) they arrange them in space in a way that the real
distance d[i, j] in the plot would be very close to the Matrix
distance, so the residual 'e'
is minimized 
                              N
                      e = SUM( | D[i, j] - d[i, j] |  )
                            i, j; i<j

I have attached a .jpg  file with an example taken from a paper. It
would be also usefull for me to link points beetwen them acording with
time, to have an idea of the temporal changue in conformation.

I read the class and cluster package, and i did not find any function
able to do this, and I cannot imagine how to use existent funtions to
obtain results i want. I would like to ask, according to what i expose
above, whether is posible to obtain a graph like that in R. I Know
from manuals that in R is not posible to interact with graphs, So if
it would be posible to obtain that graph, there would be difficult to
zoom on it, or to know  the identity of a particular point by
clicking. Nevertheless i read that there is other programs that can be
used to obtain movies of R data, or interact with graphs ?Someone
knows their(s) name(s)?

Any help or comment would be very useful

Leonardo

From ligges at statistik.uni-dortmund.de  Fri Aug  5 19:19:55 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 05 Aug 2005 19:19:55 +0200
Subject: [R] Computing sums of the columns of an array
In-Reply-To: <42F399EA.307@stats.uwo.ca>
References: <42F390E9.3010301@metahuman.org> <42F392A8.2040900@stats.uwo.ca>
	<42F3973F.4020904@statistik.uni-dortmund.de>
	<42F399EA.307@stats.uwo.ca>
Message-ID: <42F39FBB.9010504@statistik.uni-dortmund.de>

Duncan Murdoch wrote:

> On 8/5/2005 12:43 PM, Uwe Ligges wrote:
> 
>> Duncan Murdoch wrote:
>>
>>> On 8/5/2005 12:16 PM, Martin C. Martin wrote:
>>>
>>>> Hi,
>>>>
>>>> I have a 5x731 array A, and I want to compute the sums of the 
>>>> columns.  Currently I do:
>>>>
>>>> apply(A, 2, sum)
>>>>
>>>> But it turns out, this is slow: 70% of my CPU time is spent here, 
>>>> even though there are many complicated steps in my computation.
>>>>
>>>> Is there a faster way?
>>>
>>>
>>>
>>> You'd probably do better with matrix multiplication:
>>>
>>> rep(1, nrow(A)) %*% A
>>
>>
>>
>> No, better use colSums(), which has been optimized for this purpose:
>>
>>   A <- matrix(seq(1, 10000000), ncol=10000)
>>   system.time(colSums(A))
>>   # ~ 0.1 sec.
>>   system.time(rep(1, nrow(A)) %*% A)
>>   # ~ 0.5 sec.
> 
> 
> I didn't claim my solution was the best, only better. :-)
 >
> One point of interest:  I think your example exaggerates the difference 
> by using a matrix of integers.  On my machine I get a ratio something 
> like yours with the same example
> 
>  > A <- matrix(seq(1, 10000000), ncol=10000)
>  >   system.time(colSums(A))
> [1] 0.08 0.00 0.08   NA   NA
>  >   system.time(rep(1, nrow(A)) %*% A)
> [1] 0.25 0.01 0.23   NA   NA
> 
> but if I make A floating point, there's much less difference:
> 
>  > A <- matrix(as.numeric(seq(1, 10000000)), ncol=10000)
>  >   system.time(colSums(A))
> [1] 0.09 0.00 0.09   NA   NA

On my machine:
[1] 0.12 0.00 0.12   NA   NA

>  >   system.time(rep(1, nrow(A)) %*% A)
> [1] 0.11 0.00 0.12   NA   NA

On my machine:
[1] 0.32 0.00 0.32   NA   NA


Hence still a bigger factor both with R-2.1.1 release (standard BLAS; 
gcc-3.4.2, WinNT4.0, Athlon XP with real freq. of 1667MHz, 1Gb).
And still a bigger factor (0.09 vs. 0.21) on a Xeon 3.06Ghz with 2Gb.

Are you using Goto's BLAS (for me, your performance is still not 
achievable with ATLAS)?

Best,
Uwe


> Still, colSums is the winner in both cases.
> 
> Duncan Murdoch



From ripley at stats.ox.ac.uk  Fri Aug  5 19:46:54 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 5 Aug 2005 18:46:54 +0100 (BST)
Subject: [R] Explaining timings (was Computing sums of the columns of an
 array)
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EB65@usctmx1106.Merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EB65@usctmx1106.Merck.com>
Message-ID: <Pine.LNX.4.61.0508051842170.22354@gannet.stats>

On Fri, 5 Aug 2005, Liaw, Andy wrote:

>> A <- matrix(runif(5 * 731), 5)
>> system.time(replicate(1e4, rep(1, nrow(A)) %*% A), gcFirst=TRUE)
> [1] 5.28 0.13 5.46   NA   NA
>> system.time(replicate(1e4, rep(1, nrow(A)) %*% A), gcFirst=TRUE)
> [1] 1.99 0.20 2.22   NA   NA
>> system.time(replicate(1e4, rep(1, nrow(A)) %*% A), gcFirst=TRUE)
> [1] 1.97 0.25 2.28   NA   NA
>> system.time(replicate(1e4, rep(1, nrow(A)) %*% A), gcFirst=TRUE)
> [1] 1.90 0.20 2.16   NA   NA
>> system.time(replicate(1e4, colSums(A)), gcFirst=TRUE)
> [1] 1.53 0.22 1.75   NA   NA
>> system.time(replicate(1e4, colSums(A)), gcFirst=TRUE)
> [1] 1.53 0.19 1.72   NA   NA
>> system.time(replicate(1e4, colSums(A)), gcFirst=TRUE)
> [1] 1.51 0.19 1.70   NA   NA
>> system.time(replicate(1e4, colSums(A)), gcFirst=TRUE)
> [1] 1.49 0.25 1.79   NA   NA
>
> However, I don't understand why the first try took so much longer.

I've explained that to someone else earlier in the week.  You need to get 
R's internal gc limits tuned up to match the task in hand, and on the 
first run it will often gc frequently.  I got 90 GCs the first time, 9 
the second and eventually about 7.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From edhuang00 at yahoo.com  Fri Aug  5 21:25:02 2005
From: edhuang00 at yahoo.com (Haibo Huang)
Date: Fri, 5 Aug 2005 12:25:02 -0700 (PDT)
Subject: [R] calculate likelihood based on logit regression
In-Reply-To: <20050805170522.28198.qmail@web31015.mail.mud.yahoo.com>
Message-ID: <20050805192502.51638.qmail@web31010.mail.mud.yahoo.com>

I think males are z times more likely to show such
symptom, where:

z=(1+exp(6.493-5.711))/(1+exp(-5.711))

Is this right? Thanks!
Ed.

--- Haibo Huang <edhuang00 at yahoo.com> wrote:

> Hi,
> 
> I just ran the following logit regression. But can
> anyone tell me how to calculate how much more likely
> males (Male=1) could show such symptom than
> females(Male=0)? I know it must be simple to get
> once
> I have the coefficients, but I just don't recall.
> Thank you very much!
> 
> Call:
> glm(formula = Symptoms ~ 1 + Male, family =
> binomial(link = logit), 
>     data = HA)
> Deviance Residuals: 
>        Min          1Q      Median          3Q      
>  
> Max  
> -6.038e+03  -2.067e-06   0.000e+00   0.000e+00  
> 6.720e+03  
> Coefficients:
>                       Estimate Std. Error    z value
> Pr(>|z|)    
> (Intercept)          5.711e+00  8.466e-02  6.746e+01
>  
> <2e-16 ***
> Male        -6.493e+00  8.540e-02 -7.603e+01  
> <2e-16
> ***
> 
> 
> Best,
> Ed
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From jen at xlsolutions-corp.com  Fri Aug  5 21:27:39 2005
From: jen at xlsolutions-corp.com (Jen McDonald)
Date: Fri,  5 Aug 2005 12:27:39 -0700
Subject: [R] Technical Support Engineer for R/S and Bioconductor
Message-ID: <20050805122739.61cf36fc0b73de5f0c7f07b3effe7558.fd4f63f25a.wbe@email.email.secureserver.net>



From jen at xlsolutions-corp.com  Fri Aug  5 21:42:45 2005
From: jen at xlsolutions-corp.com (Jen McDonald)
Date: Fri,  5 Aug 2005 12:42:45 -0700
Subject: [R] Technical Support Engineer for R/S and Bioconductor
Message-ID: <20050805124245.61cf36fc0b73de5f0c7f07b3effe7558.8619810051.wbe@email.email.secureserver.net>



From martin at metahuman.org  Fri Aug  5 21:58:39 2005
From: martin at metahuman.org (Martin C. Martin)
Date: Fri, 05 Aug 2005 15:58:39 -0400
Subject: [R] Statistical significance of a classifier
Message-ID: <42F3C4EF.3070202@metahuman.org>

Hi,

I have a bunch of data points x from two classes A & B, and I'm creating 
a classifier.  So I have a function f(x) which estimates the probability 
that x is in class A.  (I have an equal number of examples of each, so 
p(class) = 0.5.)

One way of seeing how well this does is to compute the error rate on the 
test set, i.e. if f(x)>0.5 call it A, and see how many times I 
misclassify an item.  That's what MASS does.  But we should be able to 
do better: misclassifying should be more of a problem if the regression 
is confident then if it isn't.

How can I show that my f(x) = P(x is in class A) does better than chance?

Thanks,
Martin



From sue at xlsolutions-corp.com  Fri Aug  5 22:06:21 2005
From: sue at xlsolutions-corp.com (Sue Turner)
Date: Fri,  5 Aug 2005 13:06:21 -0700
Subject: [R] Technical Support Engineer for R/S and Bioconductor
Message-ID: <20050805130621.9f08cc34deb45d78e54b3b5664e21546.3d3b28a512.wbe@email.email.secureserver.net>



From andy_liaw at merck.com  Fri Aug  5 22:06:05 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 5 Aug 2005 16:06:05 -0400
Subject: [R] Statistical significance of a classifier
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EB79@usctmx1106.Merck.com>

> From: Martin C. Martin
> 
> Hi,
> 
> I have a bunch of data points x from two classes A & B, and 
> I'm creating 
> a classifier.  So I have a function f(x) which estimates the 
> probability 
> that x is in class A.  (I have an equal number of examples of 
> each, so 
> p(class) = 0.5.)
> 
> One way of seeing how well this does is to compute the error 
> rate on the 
> test set, i.e. if f(x)>0.5 call it A, and see how many times I 
> misclassify an item.  That's what MASS does.  But we should 

Surely you mean `99% of dataminers/machine learners' rather than `MASS'?

> be able to 
> do better: misclassifying should be more of a problem if the 
> regression 
> is confident then if it isn't.
> 
> How can I show that my f(x) = P(x is in class A) does better 
> than chance?

It depends on what you mean by `better'.  For some problem, people are
perfectly happy with misclassifcation rate.  For others, the estimated
probabilities count a lot more.  One possibility is to look at the ROC
curve.  Another possibility is to look at the calibration curve (see MASS
the book).

Andy

 
> Thanks,
> Martin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From edhuang00 at yahoo.com  Fri Aug  5 22:17:21 2005
From: edhuang00 at yahoo.com (Haibo Huang)
Date: Fri, 5 Aug 2005 13:17:21 -0700 (PDT)
Subject: [R] question regarding logit regression using glm
Message-ID: <20050805201721.30350.qmail@web31014.mail.mud.yahoo.com>

I got the following warning messages when I did a
binomial logit regression using glm():

Warning messages: 
1: Algorithm did not converge in: glm.fit(x = X, y =
Y, weights = weights, start = start, etastart =
etastart,  
2: fitted probabilities numerically 0 or 1 occurred
in: glm.fit(x = X, y = Y, weights = weights, start =
start, etastart = etastart,  

Can some one share your thoughts on how to solve this
problem? Please read the following for details. Thank
you very much!

Best,
Ed


> Lease=read.csv("lease.csv", header=TRUE)
> Lease$ET = factor(Lease$EarlyTermination)
> SICCode=factor(Lease$SIC.Code)
> TO=factor(Lease$TenantHasOption)
> LO=factor(Lease$LandlordHasOption)
> TEO=factor(Lease$TenantExercisedOption)
> 
> RegA=glm(ET~1+MSA, 
+ family=binomial(link=logit), data=Lease,
weights=Origil.SQFT)
Warning messages: 
1: Algorithm did not converge in: glm.fit(x = X, y =
Y, weights = weights, start = start, etastart =
etastart,  
2: fitted probabilities numerically 0 or 1 occurred
in: glm.fit(x = X, y = Y, weights = weights, start =
start, etastart = etastart,  
> summary(RegA)

Call:
glm(formula = ET ~ 1 + MSA, family = binomial(link =
logit), 
    data = Lease, weights = Origil.SQFT)

Deviance Residuals: 
       Min          1Q      Median          3Q        
Max  
-6.038e+03  -2.066e-06   0.000e+00   0.000e+00  
6.720e+03  

Coefficients:
                      Estimate Std. Error    z value
Pr(>|z|)    
(Intercept)          5.711e+00  8.466e-02  6.745e+01  
<2e-16 ***
MSAAnchorage        -6.493e+00  8.541e-02 -7.602e+01  
<2e-16 ***
MSAAtlanta           6.894e+14  2.310e+04  2.985e+10  
<2e-16 ***
MSAAustin           -9.362e+14  4.954e+04 -1.890e+10  
<2e-16 ***
MSABoston           -2.474e+15  2.151e+04 -1.150e+11  
<2e-16 ***
MSACharlotte        -2.150e+15  7.265e+04 -2.960e+10  
<2e-16 ***
MSAChicago          -1.174e+15  2.057e+04 -5.707e+10  
<2e-16 ***
MSACleveland        -7.607e+14  7.046e+04 -1.080e+10  
<2e-16 ***
MSAColumbus         -2.768e+15  1.685e+05 -1.642e+10  
<2e-16 ***
MSADallas            2.061e+14  3.261e+04  6.321e+09  
<2e-16 ***
MSADenver            5.470e+14  3.366e+04  1.625e+10  
<2e-16 ***
MSAEast Bay         -6.191e+01  1.344e+05  -4.61e-04  
     1    
MSAFt. Worth        -6.565e+00  8.483e-02 -7.739e+01  
<2e-16 ***
MSAHouston          -2.735e+15  3.576e+04 -7.648e+10  
<2e-16 ***
MSAIndianapolis     -7.483e+14  6.588e+04 -1.136e+10  
<2e-16 ***
MSALos Angeles      -1.388e+15  2.887e+04 -4.809e+10  
<2e-16 ***
MSAMinneapolis      -1.011e+15  2.731e+04 -3.702e+10  
<2e-16 ***
MSANashville         2.143e+01  9.395e+04   2.28e-04  
     1    
MSANew Orleans      -3.370e+15  5.038e+04 -6.689e+10  
<2e-16 ***
MSANew York         -2.526e+15  2.969e+04 -8.507e+10  
<2e-16 ***
MSANorfolk          -5.614e+01  2.020e+06  -2.78e-05  
     1    
MSAOakland-East Bay -2.272e+15  3.642e+04 -6.239e+10  
<2e-16 ***
MSAOrange County    -5.165e+14  2.428e+04 -2.128e+10  
<2e-16 ***
MSAOrlando          -3.215e+15  1.096e+05 -2.933e+10  
<2e-16 ***
MSAPhiladelphia     -8.871e+14  4.948e+04 -1.793e+10  
<2e-16 ***
MSAPhoenix          -1.156e+01  8.807e-02 -1.313e+02  
<2e-16 ***
MSAPortland          7.604e+14  3.841e+04  1.980e+10  
<2e-16 ***
MSARaleigh-Durham   -4.312e+01  1.294e+05  -3.33e-04  
     1    
MSARiverside         1.626e+15  4.645e+05  3.500e+09  
<2e-16 ***
MSASacramento       -9.873e+14  5.345e+04 -1.847e+10  
<2e-16 ***
MSASalt Lake City    1.793e+15  2.029e+05  8.839e+09  
<2e-16 ***
MSASan Antonio       9.451e+14  9.473e+04  9.977e+09  
<2e-16 ***
MSASan Diego        -3.740e+15  6.651e+04 -5.623e+10  
<2e-16 ***
MSASan Francisco     3.109e+14  2.394e+04  1.299e+10  
<2e-16 ***
MSASan Jose          7.392e+14  2.961e+04  2.497e+10  
<2e-16 ***
MSASeattle          -2.250e+15  1.581e+04 -1.423e+11  
<2e-16 ***
MSASt. Louis        -2.606e+15  1.801e+05 -1.447e+10  
<2e-16 ***
MSAStamford         -6.592e+00  8.469e-02 -7.784e+01  
<2e-16 ***
MSAWashington DC     8.460e+13  3.319e+04  2.549e+09  
<2e-16 ***
MSAWest Palm Beach  -3.924e+01  2.308e+05  -1.70e-04  
     1    
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.'
0.1 ` ' 1 

(Dispersion parameter for binomial family taken to be
1)

    Null deviance:  123111026  on 9302  degrees of
freedom
Residual deviance: 3028559052  on 9263  degrees of
freedom
AIC: 3028559132

Number of Fisher Scoring iterations: 25

> anova(RegA)
Analysis of Deviance Table

Model: binomial, link: logit

Response: ET

Terms added sequentially (first to last)


       Df   Deviance Resid. Df Resid. Dev
NULL                      9302  123111026
MSA    39          0      9263 3028559052
>



From tak at usjp.org  Fri Aug  5 22:17:20 2005
From: tak at usjp.org (Tak Ishikida)
Date: Fri, 05 Aug 2005 13:17:20 -0700
Subject: [R]  make error: X11/Intrinsic.h: No such,,,
Message-ID: <1123273040.29703.27.camel@localhost.localdomain>

I had the same problem with my ubuntu machine.  A search for a Debian
package that includes the header file Intrinsic.h at
http://www.debian.org/distrib/packages (with stable distribution and
Intel x86 architecture) turned up libdevel/libxt-dev package.  I
installed libxt-dev package (with the synaptic package manager) and was
able to compile.  

Hope this helps.

tak



From itsme_410 at yahoo.com  Fri Aug  5 22:37:17 2005
From: itsme_410 at yahoo.com (Globe Trotter)
Date: Fri, 5 Aug 2005 13:37:17 -0700 (PDT)
Subject: [R] code for gap statistic
Message-ID: <20050805203717.79915.qmail@web54505.mail.yahoo.com>

Hi,

Can anyone point me to code for the gap statistic?

Many thanks and best wishes!



From jjmichael at comcast.net  Fri Aug  5 22:39:49 2005
From: jjmichael at comcast.net (Jake Michaelson)
Date: Fri, 05 Aug 2005 14:39:49 -0600
Subject: [R] make error: X11/Intrinsic.h: No such,,,
In-Reply-To: <1123273040.29703.27.camel@localhost.localdomain>
References: <1123273040.29703.27.camel@localhost.localdomain>
Message-ID: <1123274389.7234.3.camel@localhost.localdomain>

Thanks for the help -- this morning someone (on the Ubuntu boards) was
kind enough to point this out to me. Now if there were only a decent
Linux front end/gui for R...

Thanks,

Jake
 
On Fri, 2005-08-05 at 13:17 -0700, Tak Ishikida wrote:
> I had the same problem with my ubuntu machine.  A search for a Debian
> package that includes the header file Intrinsic.h at
> http://www.debian.org/distrib/packages (with stable distribution and
> Intel x86 architecture) turned up libdevel/libxt-dev package.  I
> installed libxt-dev package (with the synaptic package manager) and was
> able to compile.  
> 
> Hope this helps.
> 
> tak
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From itsme_410 at yahoo.com  Fri Aug  5 22:41:52 2005
From: itsme_410 at yahoo.com (Globe Trotter)
Date: Fri, 5 Aug 2005 13:41:52 -0700 (PDT)
Subject: [R] use of color for hclust
Message-ID: <20050805204152.80806.qmail@web54505.mail.yahoo.com>

Hi,

I have a grouping of some observations. I want to cluster them using
hierarchical clustering and compare how the hierarchical clustering shows up
vis-a-vis the groupings. Is it possible to do this in color? I guess what I am
looking for is a way to color the labels of a hierarchical clustering plot
using different colors according to the original grouping. Any suggestions?

Many thanks and best wishes!



From martin at metahuman.org  Fri Aug  5 23:15:21 2005
From: martin at metahuman.org (Martin C. Martin)
Date: Fri, 05 Aug 2005 17:15:21 -0400
Subject: [R] Statistical significance of a classifier
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EB79@usctmx1106.Merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EB79@usctmx1106.Merck.com>
Message-ID: <42F3D6E9.1090806@metahuman.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050805/b10fae67/attachment.pl

From jreid at myriad.com  Sat Aug  6 00:51:29 2005
From: jreid at myriad.com (Julia Reid)
Date: Fri, 05 Aug 2005 16:51:29 -0600
Subject: [R] GAP pointer
Message-ID: <42F3ED71.4080105@myriad.com>

I am trying to do a simple segregation analysis using the GAP package. I 
have the documentation for pointer but I desperately need an example so 
that I can see how to format the datfile and the jobfile. For each 
individual, I have FamilyId, SubjectId, FatherId, MotherId, and 
AffectedStatus (0/1). I would like to obtain the likelihood ratio 
statistic for transmission.
I would greatly appreciate any help on this subject.
Best to all,
Julia Reid



From sourceforge at metrak.com  Sat Aug  6 01:40:26 2005
From: sourceforge at metrak.com (sosman)
Date: Sat, 06 Aug 2005 09:40:26 +1000
Subject: [R] Latex error with Sweave example
Message-ID: <42F3F8EA.6020100@metrak.com>

I created a tex file following the example in the Sweave help which 
produced the following files in my working directory.

Sweave-test-1-006.eps
Sweave-test-1-006.pdf
Sweave-test-1-007.eps
Sweave-test-1-007.pdf
Sweave-test-1.tex

When I run latex on this, I get a latex error, log file below.  I am 
running R 2.1.1 on Windows XP.  I have installed "small MiKTeX" and I 
have added "C:\Program Files\R\rw2011\share\texmf" to the roots of 
MiKTex.  The MiKTeX test ran fine after I installed it.

Any tips would be most appreciated.

This is e-TeX, Version 3.141592-2.2 (MiKTeX 2.4) (preloaded format=latex 
2005.8.5)  6 AUG 2005 09:28
entering extended mode
**Sweave-test-1
(Sweave-test-1.tex
LaTeX2e <2003/12/01>
Babel <v3.8a> and hyphenation patterns for english, french, german, 
ngerman, du
mylang, nohyphenation, loaded.
(C:\usr\texmf\tex\latex\base\article.cls
Document Class: article 2004/02/16 v1.4f Standard LaTeX document class
(C:\usr\texmf\tex\latex\base\size10.clo
File: size10.clo 2004/02/16 v1.4f Standard LaTeX file (size option)
)
\c at part=\count79
\c at section=\count80
\c at subsection=\count81
\c at subsubsection=\count82
\c at paragraph=\count83
\c at subparagraph=\count84
\c at figure=\count85
\c at table=\count86
\abovecaptionskip=\skip41
\belowcaptionskip=\skip42
\bibindent=\dimen102
)
(C:\usr\texmf\tex\latex\ltxmisc\a4wide.sty
Package: a4wide 1994/08/30

(C:\usr\texmf\tex\latex\ntgclass\a4.sty
Package: a4 1999/03/03 v1.2f A4 based page layout
))
! Missing \endcsname inserted.
<to be read again>
                    \protect
l.11 \begin
            {document}
?
! Emergency stop.
<to be read again>
                    \protect
l.11 \begin
            {document}
End of file on the terminal!


Here is how much of TeX's memory you used:
  223 strings out of 95898
  2212 string characters out of 1195177
  46816 words of memory out of 1050593
  3336 multiletter control sequences out of 35000
  3640 words of font info for 14 fonts, out of 500000 for 1000
  14 hyphenation exceptions out of 607
  23i,0n,17p,117b,36s stack positions out of 1500i,500n,5000p,200000b,32768s
No pages of output.



-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Sweave-test-1.tex
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050806/3f35b51d/Sweave-test-1.pl

From deleeuw at frazmtn.com  Sat Aug  6 01:44:42 2005
From: deleeuw at frazmtn.com (Jan de Leeuw)
Date: Fri, 5 Aug 2005 16:44:42 -0700
Subject: [R] code for metric / nonmetric MDS
Message-ID: <1BCCFCAE-99AE-4C4E-B191-2174115A50AD@frazmtn.com>

This does metric/nonmetric weighted least squares multidimensional  
scaling
using the smacof algorithm (deleeuw, 1977, in barra et al (eds),  
recent developments
in statistics; or deleeuw and heiser, 1980, in krishnaiah (ed),  
multivariate
analysis V). Uses a dist object for both dissimilarities and weights,
which should both be non-negative for convergence. Fits euclidean
distances only.

Monotone regression is done by pool-adjacent-violators, implemented
in pava.R. The pava function can actually do monotone regression
using weighted means, medians, or p-fractiles -- although for mds
only means are used.

Somebody asked for this and it may be useful to others. It is not  
written
for efficiency, but the flexibility of allowing weights can be handy. By
using relaxed smacof updates (see deleeuw and heiser or the book
by borg and groenen) we can make this about twice as fast -- but that
will come later. Feel free to tinker away.

-------------- next part --------------


==========================================================
Jan de Leeuw, 11667 Steinhoff Rd, Frazier Park, CA 93225, 661-245-1725
==========================================================
                                      Und die Einen sind im Dunkeln
                                      Und die Andern sind im Licht
                                      Und man siehe die im Lichte
                                      Die im Dunklen sieht man nicht
                                                                         
                                  Brecht




From deleeuw at stat.ucla.edu  Sat Aug  6 01:51:56 2005
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Fri, 5 Aug 2005 16:51:56 -0700
Subject: [R] (no subject)
Message-ID: <FF1C3156-DB08-4A7A-86FD-F06123B0BBF3@stat.ucla.edu>

This does metric/nonmetric weighted least squares multidimensional  
scaling
using the smacof algorithm (deleeuw, 1977, in barra et al (eds),  
recent developments
in statistics; or deleeuw and heiser, 1980, in krishnaiah (ed),  
multivariate
analysis V). Uses a dist object for both dissimilarities and weights,
which should both be non-negative for convergence. Fits euclidean
distances only.

Monotone regression is done by pool-adjacent-violators, implemented
in pava.R. The pava function can actually do monotone regression
using weighted means, medians, or p-fractiles -- although for mds
only means are used.

Somebody asked for this and it may be useful to others. It is not  
written
for efficiency, but the flexibility of allowing weights can be handy. By
using relaxed smacof updates (see deleeuw and heiser or the book
by borg and groenen) we can make this about twice as fast -- but that
will come later. Feel free to tinker away.


-------------- next part --------------


===
Jan de Leeuw; Distinguished Professor and Chair, UCLA Department of  
Statistics;
Editor: Journal of Multivariate Analysis, Journal of Statistical  
Software
US mail: 8130 Math Sciences Bldg, Box 951554, Los Angeles, CA 90095-1554
phone (310)-825-9550;  fax (310)-206-5658;  email: deleeuw at stat.ucla.edu
.mac: jdeleeuw ++++++  aim: deleeuwjan ++++++ skype: j_deleeuw
homepages: http://gifi.stat.ucla.edu ++++++ http://www.cuddyvalley.org
   
------------------------------------------------------------------------ 
-------------------------
           No matter where you go, there you are. --- Buckaroo Banzai
                    http://gifi.stat.ucla.edu/sounds/nomatter.au
   
------------------------------------------------------------------------ 
-------------------------



From murdoch at stats.uwo.ca  Sat Aug  6 01:54:47 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 05 Aug 2005 19:54:47 -0400
Subject: [R] Latex error with Sweave example
In-Reply-To: <42F3F8EA.6020100@metrak.com>
References: <42F3F8EA.6020100@metrak.com>
Message-ID: <42F3FC47.4030105@stats.uwo.ca>

sosman wrote:
> I created a tex file following the example in the Sweave help which 
> produced the following files in my working directory.
> 
> Sweave-test-1-006.eps
> Sweave-test-1-006.pdf
> Sweave-test-1-007.eps
> Sweave-test-1-007.pdf
> Sweave-test-1.tex
> 
> When I run latex on this, I get a latex error, log file below.  I am 
> running R 2.1.1 on Windows XP.  I have installed "small MiKTeX" and I 
> have added "C:\Program Files\R\rw2011\share\texmf" to the roots of 
> MiKTex.  The MiKTeX test ran fine after I installed it.
> 
> Any tips would be most appreciated.

I think you need to ask on one of the Miktex lists.  My guess would be 
that your problem is caused by using e-TeX, but I couldn't say for sure. 
  Certainly the error is occurring entirely within MikTeX packages; you 
haven't got to the R stuff yet.

My web page

http://www.murdoch-sutherland.com/Rtools/miktex.html

is getting kind of old, but it does tell you how to avoid using e-TeX.

Duncan Murdoch

> 
> This is e-TeX, Version 3.141592-2.2 (MiKTeX 2.4) (preloaded format=latex 
> 2005.8.5)  6 AUG 2005 09:28
> entering extended mode
> **Sweave-test-1
> (Sweave-test-1.tex
> LaTeX2e <2003/12/01>
> Babel <v3.8a> and hyphenation patterns for english, french, german, 
> ngerman, du
> mylang, nohyphenation, loaded.
> (C:\usr\texmf\tex\latex\base\article.cls
> Document Class: article 2004/02/16 v1.4f Standard LaTeX document class
> (C:\usr\texmf\tex\latex\base\size10.clo
> File: size10.clo 2004/02/16 v1.4f Standard LaTeX file (size option)
> )
> \c at part=\count79
> \c at section=\count80
> \c at subsection=\count81
> \c at subsubsection=\count82
> \c at paragraph=\count83
> \c at subparagraph=\count84
> \c at figure=\count85
> \c at table=\count86
> \abovecaptionskip=\skip41
> \belowcaptionskip=\skip42
> \bibindent=\dimen102
> )
> (C:\usr\texmf\tex\latex\ltxmisc\a4wide.sty
> Package: a4wide 1994/08/30
> 
> (C:\usr\texmf\tex\latex\ntgclass\a4.sty
> Package: a4 1999/03/03 v1.2f A4 based page layout
> ))
> ! Missing \endcsname inserted.
> <to be read again>
>                     \protect
> l.11 \begin
>             {document}
> ?
> ! Emergency stop.
> <to be read again>
>                     \protect
> l.11 \begin
>             {document}
> End of file on the terminal!
> 
> 
> Here is how much of TeX's memory you used:
>   223 strings out of 95898
>   2212 string characters out of 1195177
>   46816 words of memory out of 1050593
>   3336 multiletter control sequences out of 35000
>   3640 words of font info for 14 fonts, out of 500000 for 1000
>   14 hyphenation exceptions out of 607
>   23i,0n,17p,117b,36s stack positions out of 1500i,500n,5000p,200000b,32768s
> No pages of output.
> 
> 
> 
> 
> 
> ------------------------------------------------------------------------
> 
> \documentclass[a4paper]{article}
> 
> \title{A Test File}
> \author{Friedrich Leisch}
> 
> 
> \usepackage{a4wide}
> 
> \usepackage{C:/PROGRA~1/R/rw2011/share/texmf/Sweave}
> \begin{document}
> 
> \maketitle
> 
> A simple example that will run in any S engine: The integers from 1 to
> 10 are
> \begin{Schunk}
> \begin{Soutput}
>  [1]  1  2  3  4  5  6  7  8  9 10
> \end{Soutput}
> \end{Schunk}
> 
> We can also emulate a simple calculator:
> \begin{Schunk}
> \begin{Sinput}
> 
>>1 + 1
> 
> \end{Sinput}
> \begin{Soutput}
> [1] 2
> \end{Soutput}
> \begin{Sinput}
> 
>>1 + pi
> 
> \end{Sinput}
> \begin{Soutput}
> [1] 4.141593
> \end{Soutput}
> \begin{Sinput}
> 
>>sin(pi/2)
> 
> \end{Sinput}
> \begin{Soutput}
> [1] 1
> \end{Soutput}
> \end{Schunk}
> 
> Now we look at Gaussian data:
> 
> \begin{Schunk}
> \begin{Soutput}
>  [1]  1.0549825921  1.0338743287  1.3960748544  0.8442504660 -1.3844903806
>  [6] -0.1132289262  0.0340332855  0.0002775862 -1.0397650922  0.4255640780
> [11] -0.0101131650 -0.9338368343 -0.8404841222  0.1815343256 -0.0655929025
> [16] -0.6401327742  0.2787653149 -0.0940385332 -0.6531716561 -0.8501837369
> \end{Soutput}
> \begin{Soutput}
> 	One Sample t-test
> 
> data:  x 
> t = -0.4006, df = 19, p-value = 0.6932
> alternative hypothesis: true mean is not equal to 0 
> 95 percent confidence interval:
>  -0.4281708  0.2906027 
> sample estimates:
>   mean of x 
> -0.06878406 
> \end{Soutput}
> \end{Schunk}
> Note that we can easily integrate some numbers into standard text: The
> third element of vector \texttt{x} is 1.39607485443702, the
> $p$-value of the test is 0.69319. % $
> 
> Now we look at a summary of the famous iris data set, and we want to
> see the commands in the code chunks.  Note that the summary needs to
> be \texttt{print()}ed explicitly, because eval would discard it otherwise. I
> consider this a feature, because it allows for much finer control on
> what gets into the final report.
> 
> 
> 
> % the following code is R-specific, as data(iris) will not run in Splus.
> % Hence, we mark it as R code.
> \begin{Schunk}
> \begin{Sinput}
> 
>>data(iris)
>>print(summary(iris))
> 
> \end{Sinput}
> \begin{Soutput}
>   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
>  Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
>  1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
>  Median :5.800   Median :3.000   Median :4.350   Median :1.300  
>  Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  
>  3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
>  Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  
>        Species  
>  setosa    :50  
>  versicolor:50  
>  virginica :50  
> \end{Soutput}
> \end{Schunk}
> 
> 
> \begin{figure}[htbp]
>   \begin{center}
> \begin{Schunk}
> \begin{Sinput}
> 
>>library(graphics)
>>pairs(iris)
> 
> \end{Sinput}
> \end{Schunk}
> \includegraphics{Sweave-test-1-006}
>     \caption{Pairs plot of the iris data.}
>   \end{center}
> \end{figure}
> 
> \begin{figure}[htbp]
>   \begin{center}
> \begin{Schunk}
> \begin{Sinput}
> 
>>boxplot(Sepal.Length ~ Species, data = iris)
> 
> \end{Sinput}
> \end{Schunk}
> \includegraphics{Sweave-test-1-007}
>     \caption{Boxplot of sepal length grouped by species.}
>   \end{center}
> \end{figure}
> 
> 
> % R is not S-PLUS, hence this chunk will be ignored:
> 
> \end{document}
> 
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From deepayan at stat.wisc.edu  Sat Aug  6 03:23:31 2005
From: deepayan at stat.wisc.edu (Deepayan Sarkar)
Date: Fri, 5 Aug 2005 20:23:31 -0500
Subject: [R] [R-pkgs] new version of lattice
Message-ID: <200508052023.31632.deepayan@stat.wisc.edu>


[This is more a warning than an announcement]

A new version of lattice should be soon on CRAN. From this version onwards, 
all high-level lattice functions are (S3) generic. All of them have formula 
methods, some have other methods as well, formalizing the various non-formula 
uses which used to be handled by clumsy hacks in the past. There's also a new 
table method for barchart.

Ideally, this change should be completely transparent to the user and no 
existing code should break (except undocumented and inappropriate examples 
like 

dotplot( x  | a )

which used to work like dotplot(~x | a) before). However, Murphy's law usually 
prevails, so...

Deepayan

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From 0034058 at fudan.edu.cn  Sat Aug  6 05:55:15 2005
From: 0034058 at fudan.edu.cn (ronggui)
Date: Sat, 06 Aug 2005 11:55:15 +0800
Subject: [R] oldClass vs. class
Message-ID: <0IKS00K3G7S19D@mail.fudan.edu.cn>

Hi,When I read the source of str,i find  these code
-----
  ## Show further classes // Assume that they do NOT have an own Method --
    ## not quite perfect ! (.Class = 'remaining classes', starting with current)
    cl <- oldClass(object); cl <- cl[cl != "data.frame"]  #- not THIS class
-----
so I use ?oldClass to try to learn more about oldClass.But after I have reading all the help page ,I still have no idea the diiference between oldClass and class.

Anynone can help me ?


2005-08-06

------
Deparment of Sociology
Fudan University

Blog:http://sociology.yculblog.com



From ggrothendieck at gmail.com  Sat Aug  6 06:20:12 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 6 Aug 2005 00:20:12 -0400
Subject: [R] High resolution plots
In-Reply-To: <971536df050805081311dbeef5@mail.gmail.com>
References: <42D53844.4040802@ebi-wasser.uni-karlsruhe.de>
	<971536df0507131406564f7700@mail.gmail.com>
	<42F373D7.8080606@biostatistic.de>
	<971536df050805081311dbeef5@mail.gmail.com>
Message-ID: <971536df050805212053ae7894@mail.gmail.com>

On 8/5/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> On 8/5/05, Knut Krueger <admin at biostatistic.de> wrote:
> >
> >
> > Gabor Grothendieck schrieb:
> >
> > >On 7/13/05, Luis Tercero <luis.tercero at ebi-wasser.uni-karlsruhe.de> wrote:
> > >
> > >
> > >>Dear R-help community,
> > >>
> > >>would any of you have a (preferably simple) example of a
> > >>presentation-quality .png plot, i.e. one that looks like the .eps plots
> > >>generated by R? I am working with R 2.0.1 in WindowsXP and am having
> > >>similar problems as Knut Krueger in printing high-quality plots. I have
> > >>looked at the help file and examples therein as well as others I have
> > >>been able to find online but to no avail. After many many tries I have
> > >>to concede I cannot figure it out.
> > >>
> > >>I would be very grateful for your help.
> > >>
> > >>
> > >
> > >   If you want the highest resolution use a vector format,
> > >not a bitmapped format such as png. See:
> > >
> > >http://maths.newcastle.edu.au/~rking/R/help/04/02/1168.html
> > >
> > The link is now broken, and I did not copy the hints.
> > Does anybody knows if it its available at any other location?
> >
> > And I tried to find
> >
> > >Thanks for the pointer!  .wmf is far superior, I was just in the dark
> > >about the format and R's ability to produce it (An Introduction to R
> > >"Device drivers" does not mention it and I had obviously missed the
> > >deciding last two words in "?device" 'windows')
> > >
> > the wmf command but there is nothing to find with help.search("wmf")
> 
> 
> It seems that the links have changed so that the part of the
> url that reads:
> 
>        http:maths.newcastle.edu.au/~rking
> 
> needs to be replaced with:
> 
>        http://tolstoy.newcastle.edu.au
> 
> That is, the link has changed from:
> 
>        http://maths.newcastle.edu.au/~rking/R/help/04/02/1168.html
> to:
>        http://tolstoy.newcastle.edu.au/R/help/04/02/1168.html
> 
> Alternately google for the message id, which is:
> 
>        <20040221000411.C14FC397E at mprdmxin.myway.com>
> 

There is a useful summary of differences between bitmapped and
vector graphics at:

http://www.stc-saz.org/resources/0203_graphics.pdf



From ripley at stats.ox.ac.uk  Sat Aug  6 08:50:02 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 6 Aug 2005 07:50:02 +0100 (BST)
Subject: [R] oldClass vs. class
In-Reply-To: <0IKS00K3G7S19D@mail.fudan.edu.cn>
References: <0IKS00K3G7S19D@mail.fudan.edu.cn>
Message-ID: <Pine.LNX.4.61.0508060746280.14918@gannet.stats>

On Sat, 6 Aug 2005, ronggui wrote:

> Hi,When I read the source of str,i find  these code
> -----
>  ## Show further classes // Assume that they do NOT have an own Method --
>    ## not quite perfect ! (.Class = 'remaining classes', starting with current)
>    cl <- oldClass(object); cl <- cl[cl != "data.frame"] #- not THIS 
> class -----

> so I use ?oldClass to try to learn more about oldClass.But 
> after I have reading all the help page ,I still have no idea the 
> diiference between oldClass and class.

>From the help page

      Many R objects have a 'class' attribute, a character vector giving
      the names of the classes which the object "inherits" from.  If the
      object does not have a class attribute, it has an implicit class,
      '"matrix"', '"array"' or the result of 'mode(x)'.  (Functions
      'oldClass' and 'oldClass<-' get and set the attribute, which can
      also be done directly.)

so class returns the implicit class, and oldClass does not.

> A <- matrix(1:6, 2,3)
> class(A)
[1] "matrix"
> oldClass(A)
NULL

just as it says.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From joerg-burmester at gmx.net  Sat Aug  6 10:43:53 2005
From: joerg-burmester at gmx.net (Joerg Burmester)
Date: Sat, 6 Aug 2005 10:43:53 +0200
Subject: [R] problems with function-formating, please help
Message-ID: <000201c59a63$078abda0$0500a8c0@acjoergws>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050806/6b3f21dd/attachment.pl

From petr.mandys at matfyz.cz  Sat Aug  6 11:10:45 2005
From: petr.mandys at matfyz.cz (Petr Mandys)
Date: Sat, 6 Aug 2005 11:10:45 +0200 (CEST)
Subject: [R] qq.loglogistic
Message-ID: <Pine.LNX.4.62.0508061108450.31539@artax.karlin.mff.cuni.cz>

Hi,

is there any similar function in R to S function qq.loglogistic, which 
produces a Q-Q plot?

Thanks a lot

Pete



From murdoch at stats.uwo.ca  Sat Aug  6 12:13:38 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sat, 06 Aug 2005 06:13:38 -0400
Subject: [R] problems with function-formating, please help
In-Reply-To: <000201c59a63$078abda0$0500a8c0@acjoergws>
References: <000201c59a63$078abda0$0500a8c0@acjoergws>
Message-ID: <42F48D52.7030901@stats.uwo.ca>

Joerg Burmester wrote:
> please help me.
> 
> since 2 days i have tried desperately to find desperately a solution for the following problem:
> 
> i have an array of 3 different vectors like:
> 
> 
>>clustertransformationstabelle[,15:17]
> 
>           x1            x2                x3
> 1  0.6270023 0.2464946 0.5074781
> 2  0.5629291 0.1783861 0.4398626
> 3  0.6773455 0.3107641 0.5637289
> 4  0.0000000 0.0000000 0.0000000
> 
> i want to calculate a corresponding result-vector with a formula resp function eg:
> 
> 
>>result <- - 1.60638946783994e-05 + 384.649339378693 * x1 - 168.920548209815 * x2 - 693.51261768584 * x3 + 479.305764753298 * x1 * x3
> 
> 
> after formating the result would look like
> 
>>dim(result) <- c(4,1)
>>result
> 
>                [,1]
>  [1,]  1.057852e-01
>  [2,]  2.854227e-02
>  [3,]  1.107150e-01
>  [4,] -1.606389e-05
> 
> fine....
> but due to mass routines, i have to create the result-function automatically, 
> unfortunately it can only be generated via a paste-command as a character-string in quotes like:
> 
> functionterm <- "- 1.60638946783994e-05 + 384.649339378693 * x1 - 168.920548209815 * x2 - 693.51261768584 * x3 + 479.305764753298 * x1 * x3"

You should almost never write text and reparse it -- it almost always 
indicates  a poor solution to whatever problem you're trying to solve.

I can't tell from your message what you want your function to do, but if 
you want a function that takes args x1, x2, x3 and returns the value 
1.60638946783994e-05 + 384.649339378693 * x1 - 168.920548209815 * x2 - 
693.51261768584 * x3 + 479.305764753298 * x1 * x3, where those 
coefficients come from some other calculation, just do it like this:

makefn <- function(coeffs) {
   function(x1, x2, x3) coeffs[1] +
                        coeffs[2]*x1 +
                        coeffs[3]*x2 +
                        coeffs[4]*x1*x3
}

Then use it like this:

f <- makefn(c(-1.606, 384.64, etc.))

and f is the function you want.

Duncan Murdoch

> 
> how on earth can i use that automatically generated functionterm (see line above), 
> unfortunately inclusive their quotes, in order to get a correct fomated function?
> 
> if i try to convert it into a function like:
> 
>>result <- as.function(alist(x1=,x2=,x3=, functionterm))
> 
> 
> and give some example input-data eg.:
> 
>>result(0.6270023, 0.2464946, 0.5074781)
> 
> 
> i always get that stupid functionterm in quotes returned
> [1] "- 1.60638946783994e-05 + 384.649339378693 * x1 - 168.920548209815 * x2 - 693.51261768584 * x3 + 479.305764753298 * x1 * x3"
> 
> instead of the correct values (like 1.057852e-01, see result-array[1,1] some lines above)
> please help me, i am blocked since 2 days already by that stupid problem
> 
> joerg burmester
> 
> Phone: +49-(0)4131-40898-5
> Mobile Phone: +49-(0)177-4812371
> Fax: +49-(0)4131-40898-7
> Email: joerg-burmester at gmx.net
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Knut-Krueger at einthal.de  Sat Aug  6 12:27:00 2005
From: Knut-Krueger at einthal.de (Knut Krueger)
Date: Sat, 06 Aug 2005 12:27:00 +0200
Subject: [R] High resolution plots
In-Reply-To: <42D363D9.2080703@biostatistic.de>
References: <42D363D9.2080703@biostatistic.de>
Message-ID: <42F49074.9080503@einthal.de>



Knut Krueger schrieb:

>Is there any possibility to get high resolution plots in a windows xp 
>system?
>I tried it with the device function png(filename = 
>"c:/r/highresplot%d.png",pointsize=12, res=900)
>but when I try to set: width = 480, height = 480 or   pointsize = 12, 
>the text is not scaled in the same way as the plots.
>

There are three bmp based functions available;:
bmp, jpeg, png

bmp is without compression so I decided not to use it 
jpeg is no loss less compression so I decided not to use it 
the third was png

Now I tried the other one and I think that there is a bug in the png code or I do not understand the reason:

jpeg(filename = "c:/r/Rplot%03d.jpg", width = 960, height = 960, pointsize = 24, quality = 100, bg = "white", res = 2400)
witdh/heigth  = 960  <> 10.16 mm
ppi=2400
Results as expected


jpeg(filename = "c:/r/Rplot%03d.jpg", width = 1920, height = 1920,
          pointsize = 48, quality = 100, bg = "white", res = 2400)

witdh/heigth  = 1920  <> 20.32 mm
ppi=2400
Results as expected


bmp(filename = "c:/r/Rplot%03d.bmp", width = 1920, height = 1920, pointsize = 48, bg = "white", res = 2400)
witdh/heigth  = 1920  <> 20.32 mm
ppi=2400
Results as expected


png(filename = "c:/r/Rplot%03d.png", width = 1920, height = 1920, pointsize = 48, bg = "white", res = 2400)

witdh/heigth  = 1920  <> 20.32 mm
ppi=150
Result not as expected.

Ok I am able to use the jpeg or bmp format, but does anybody know why the png function does not work in the same way as the jpeg and bmp function?

Regards Knut



From forum at biostatistic.de  Sat Aug  6 12:56:20 2005
From: forum at biostatistic.de (Forum Replies)
Date: Sat, 06 Aug 2005 12:56:20 +0200
Subject: [R] High resolution plots
In-Reply-To: <Pine.LNX.4.61.0508051535480.30020@gannet.stats>
References: <42D53844.4040802@ebi-wasser.uni-karlsruhe.de>	<971536df0507131406564f7700@mail.gmail.com>	<42F373D7.8080606@biostatistic.de>
	<Pine.LNX.4.61.0508051535480.30020@gannet.stats>
Message-ID: <42F49754.2090506@biostatistic.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050806/46270889/attachment.pl

From admin at biostatistic.de  Sat Aug  6 13:12:50 2005
From: admin at biostatistic.de (Knut Krueger)
Date: Sat, 06 Aug 2005 13:12:50 +0200
Subject: [R] High resolution plots
In-Reply-To: <Pine.LNX.4.61.0508051535480.30020@gannet.stats>
References: <42D53844.4040802@ebi-wasser.uni-karlsruhe.de>	<971536df0507131406564f7700@mail.gmail.com>	<42F373D7.8080606@biostatistic.de>
	<Pine.LNX.4.61.0508051535480.30020@gannet.stats>
Message-ID: <42F49B32.6040900@biostatistic.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050806/86304b08/attachment.pl

From ligges at statistik.uni-dortmund.de  Sat Aug  6 14:24:20 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sat, 06 Aug 2005 14:24:20 +0200
Subject: [R] Latex error with Sweave example
In-Reply-To: <42F3F8EA.6020100@metrak.com>
References: <42F3F8EA.6020100@metrak.com>
Message-ID: <42F4ABF4.1030503@statistik.uni-dortmund.de>




I do not think that the file specification in

\usepackage{C:/PROGRA~1/R/rw2011/share/texmf/Sweave}

is supported....

Rather use \usepackage{Sweave} and put Sweave.sty somewhere in the 
search path of LaTeX (either in some of its directories - do not forget 
to 'texhash' - or in the local directory).

Uwe Ligges


sosman wrote:
> I created a tex file following the example in the Sweave help which 
> produced the following files in my working directory.
> 
> Sweave-test-1-006.eps
> Sweave-test-1-006.pdf
> Sweave-test-1-007.eps
> Sweave-test-1-007.pdf
> Sweave-test-1.tex
> 
> When I run latex on this, I get a latex error, log file below.  I am 
> running R 2.1.1 on Windows XP.  I have installed "small MiKTeX" and I 
> have added "C:\Program Files\R\rw2011\share\texmf" to the roots of 
> MiKTex.  The MiKTeX test ran fine after I installed it.
> 
> Any tips would be most appreciated.
> 
> This is e-TeX, Version 3.141592-2.2 (MiKTeX 2.4) (preloaded format=latex 
> 2005.8.5)  6 AUG 2005 09:28
> entering extended mode
> **Sweave-test-1
> (Sweave-test-1.tex
> LaTeX2e <2003/12/01>
> Babel <v3.8a> and hyphenation patterns for english, french, german, 
> ngerman, du
> mylang, nohyphenation, loaded.
> (C:\usr\texmf\tex\latex\base\article.cls
> Document Class: article 2004/02/16 v1.4f Standard LaTeX document class
> (C:\usr\texmf\tex\latex\base\size10.clo
> File: size10.clo 2004/02/16 v1.4f Standard LaTeX file (size option)
> )
> \c at part=\count79
> \c at section=\count80
> \c at subsection=\count81
> \c at subsubsection=\count82
> \c at paragraph=\count83
> \c at subparagraph=\count84
> \c at figure=\count85
> \c at table=\count86
> \abovecaptionskip=\skip41
> \belowcaptionskip=\skip42
> \bibindent=\dimen102
> )
> (C:\usr\texmf\tex\latex\ltxmisc\a4wide.sty
> Package: a4wide 1994/08/30
> 
> (C:\usr\texmf\tex\latex\ntgclass\a4.sty
> Package: a4 1999/03/03 v1.2f A4 based page layout
> ))
> ! Missing \endcsname inserted.
> <to be read again>
>                    \protect
> l.11 \begin
>            {document}
> ?
> ! Emergency stop.
> <to be read again>
>                    \protect
> l.11 \begin
>            {document}
> End of file on the terminal!
> 
> 
> Here is how much of TeX's memory you used:
>  223 strings out of 95898
>  2212 string characters out of 1195177
>  46816 words of memory out of 1050593
>  3336 multiletter control sequences out of 35000
>  3640 words of font info for 14 fonts, out of 500000 for 1000
>  14 hyphenation exceptions out of 607
>  23i,0n,17p,117b,36s stack positions out of 1500i,500n,5000p,200000b,32768s
> No pages of output.
> 
> 
> 
> 
> ------------------------------------------------------------------------
> 
> \documentclass[a4paper]{article}
> 
> \title{A Test File}
> \author{Friedrich Leisch}
> 
> 
> \usepackage{a4wide}
> 
> \usepackage{C:/PROGRA~1/R/rw2011/share/texmf/Sweave}
> \begin{document}
> 
> \maketitle
> 
> A simple example that will run in any S engine: The integers from 1 to
> 10 are
> \begin{Schunk}
> \begin{Soutput}
>  [1]  1  2  3  4  5  6  7  8  9 10
> \end{Soutput}
> \end{Schunk}
> 
> We can also emulate a simple calculator:
> \begin{Schunk}
> \begin{Sinput}
> 
>>1 + 1
> 
> \end{Sinput}
> \begin{Soutput}
> [1] 2
> \end{Soutput}
> \begin{Sinput}
> 
>>1 + pi
> 
> \end{Sinput}
> \begin{Soutput}
> [1] 4.141593
> \end{Soutput}
> \begin{Sinput}
> 
>>sin(pi/2)
> 
> \end{Sinput}
> \begin{Soutput}
> [1] 1
> \end{Soutput}
> \end{Schunk}
> 
> Now we look at Gaussian data:
> 
> \begin{Schunk}
> \begin{Soutput}
>  [1]  1.0549825921  1.0338743287  1.3960748544  0.8442504660 -1.3844903806
>  [6] -0.1132289262  0.0340332855  0.0002775862 -1.0397650922  0.4255640780
> [11] -0.0101131650 -0.9338368343 -0.8404841222  0.1815343256 -0.0655929025
> [16] -0.6401327742  0.2787653149 -0.0940385332 -0.6531716561 -0.8501837369
> \end{Soutput}
> \begin{Soutput}
> 	One Sample t-test
> 
> data:  x 
> t = -0.4006, df = 19, p-value = 0.6932
> alternative hypothesis: true mean is not equal to 0 
> 95 percent confidence interval:
>  -0.4281708  0.2906027 
> sample estimates:
>   mean of x 
> -0.06878406 
> \end{Soutput}
> \end{Schunk}
> Note that we can easily integrate some numbers into standard text: The
> third element of vector \texttt{x} is 1.39607485443702, the
> $p$-value of the test is 0.69319. % $
> 
> Now we look at a summary of the famous iris data set, and we want to
> see the commands in the code chunks.  Note that the summary needs to
> be \texttt{print()}ed explicitly, because eval would discard it otherwise. I
> consider this a feature, because it allows for much finer control on
> what gets into the final report.
> 
> 
> 
> % the following code is R-specific, as data(iris) will not run in Splus.
> % Hence, we mark it as R code.
> \begin{Schunk}
> \begin{Sinput}
> 
>>data(iris)
>>print(summary(iris))
> 
> \end{Sinput}
> \begin{Soutput}
>   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
>  Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
>  1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
>  Median :5.800   Median :3.000   Median :4.350   Median :1.300  
>  Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  
>  3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
>  Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  
>        Species  
>  setosa    :50  
>  versicolor:50  
>  virginica :50  
> \end{Soutput}
> \end{Schunk}
> 
> 
> \begin{figure}[htbp]
>   \begin{center}
> \begin{Schunk}
> \begin{Sinput}
> 
>>library(graphics)
>>pairs(iris)
> 
> \end{Sinput}
> \end{Schunk}
> \includegraphics{Sweave-test-1-006}
>     \caption{Pairs plot of the iris data.}
>   \end{center}
> \end{figure}
> 
> \begin{figure}[htbp]
>   \begin{center}
> \begin{Schunk}
> \begin{Sinput}
> 
>>boxplot(Sepal.Length ~ Species, data = iris)
> 
> \end{Sinput}
> \end{Schunk}
> \includegraphics{Sweave-test-1-007}
>     \caption{Boxplot of sepal length grouped by species.}
>   \end{center}
> \end{figure}
> 
> 
> % R is not S-PLUS, hence this chunk will be ignored:
> 
> \end{document}
> 
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From kjetil at acelerate.com  Sat Aug  6 01:26:30 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Fri, 05 Aug 2005 19:26:30 -0400
Subject: [R] use of NA's
In-Reply-To: <OFB59FA4C8.A0D65A6C-ON80257054.00558EC1-80257054.0055B289@EliLilly.lilly.com>
References: <OFB59FA4C8.A0D65A6C-ON80257054.00558EC1-80257054.0055B289@EliLilly.lilly.com>
Message-ID: <42F3F5A6.7060705@acelerate.com>

Robert Kinley wrote:

>with NAs it's always safest to use the construction 
>
>if(is.na(foo))
>
>rather than
>
>if(foo==NA)
>
>cheers          Bob Kinley
>
>
>  
>
And if it is not clear why, try:

 > NA == NA
[1] NA
 >
 Kjetil


>tom wright <tom at maladmin.com> 
>Sent by: r-help-bounces at stat.math.ethz.ch
>05/08/2005 12:30
>
>To
>r-help at stat.math.ethz.ch
>cc
>
>Subject
>[R] use of NA's
>
>
>
>
>
>
>Can someone please explain why this works: 
>
>  
>
>>>d<-c(0,2,3,2,0,3,4,0,0,0,0,0)
>>>d.mat<-matrix(data=d,nrow=4,ncol=3,byrow=TRUE)
>>>for(i in 1:length(d.mat[1,])){
>>>      
>>>
>>+ d.mat[,i][d.mat[,i]==0]<-mean(d.mat[,i][d.mat[,i]>0])
>>+ }
>>    
>>
>
>Whereas: 
>
>  
>
>>d<-c(0,2,3,2,0,3,4,0,0,0,0,0)
>>d.mat<-matrix(data=d,nrow=4,ncol=3,byrow=TRUE)
>>d.mat[d.mat==0]<-NA
>>for(i in 1:length(d.mat[1,])){
>>    
>>
>+ d.mat[,i][d.mat[,i]==NA]<-mean(d.mat[,i],na.rm=TRUE)
>+ }
>dosnt
>
>Thanks
>Tom
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
Internal Virus Database is out-of-date.
Checked by AVG Anti-Virus.



From charles.edwin.white at us.army.mil  Sat Aug  6 17:20:53 2005
From: charles.edwin.white at us.army.mil (White, Charles E WRAIR-Wash DC)
Date: Sat, 6 Aug 2005 11:20:53 -0400
Subject: [R] Archive Search on R Help Mailing List Help
Message-ID: <8BAEC5E546879B4FAA536200A292C6140DD125@AMEDMLNARMC135.amed.ds.army.mil>

The link to the search engine at the University of Newcastle, Australia doesn't seem to be working. Is there someone who can either update the link or indicate when the service may be back? 

Thanks.

Chuck



From charles.edwin.white at us.army.mil  Sat Aug  6 17:38:56 2005
From: charles.edwin.white at us.army.mil (White, Charles E WRAIR-Wash DC)
Date: Sat, 6 Aug 2005 11:38:56 -0400
Subject: [R] gnomeGUI on FC4
Message-ID: <8BAEC5E546879B4FAA536200A292C6140DD126@AMEDMLNARMC135.amed.ds.army.mil>

It seems nice that R is part of the 'walled garden' of applications specifically configured to run under Fedora Core 4 (Linux). The gnomeGUI has a separate installation routine under FC4 and yum tells me it's installed. I've even found an executable for it in /usr/lib/R/bin/exec. However, as far as I can tell, it doesn't do anything. Since the documentation is rather... sparse... I'm not exactly sure what it's supposed to do anyway. As an experiment, I removed the RPM and downloaded the library using R. The list of errors generated by trying to install the library was rather spectacular, so I won't waste bandwidth printing it at the moment. Is there a simple way to get this library/program running or should I just wait for further development?

Thanks.

Chuck



From ripley at stats.ox.ac.uk  Sat Aug  6 19:51:13 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 6 Aug 2005 18:51:13 +0100 (BST)
Subject: [R] gnomeGUI on FC4
In-Reply-To: <8BAEC5E546879B4FAA536200A292C6140DD126@AMEDMLNARMC135.amed.ds.army.mil>
References: <8BAEC5E546879B4FAA536200A292C6140DD126@AMEDMLNARMC135.amed.ds.army.mil>
Message-ID: <Pine.LNX.4.61.0508061840020.26041@gannet.stats>

On Sat, 6 Aug 2005, White, Charles E WRAIR-Wash DC wrote:

> It seems nice that R is part of the 'walled garden' of applications 
> specifically configured to run under Fedora Core 4 (Linux). The gnomeGUI 
> has a separate installation routine under FC4 and yum tells me it's 
> installed. I've even found an executable for it in /usr/lib/R/bin/exec. 
> However, as far as I can tell, it doesn't do anything. Since the 
> documentation is rather... sparse... I'm not exactly sure what it's 
> supposed to do anyway. As an experiment, I removed the RPM and 
> downloaded the library using R. The list of errors generated by trying 
> to install the library was rather spectacular, so I won't waste 
> bandwidth printing it at the moment. Is there a simple way to get this 
> library/program running or should I just wait for further development?

R --gui=gnome is how to run it.

That is described in `An Introduction to R' (the manual we ask all users 
to read) and the main documentation (as documented in the packages's 
README) is in the R Installation and Administration Manual.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gerifalte28 at hotmail.com  Sat Aug  6 20:50:12 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Sat, 06 Aug 2005 18:50:12 +0000
Subject: [R] Archive Search on R Help Mailing List Help
In-Reply-To: <8BAEC5E546879B4FAA536200A292C6140DD125@AMEDMLNARMC135.amed.ds.army.mil>
Message-ID: <BAY103-F15620FE1109B694FDFAB18A6C60@phx.gbl>

Try accesing http://search.r-project.org/ directly or within R using 
RSiteSearch(utils).  It is not the same site that you are asking for but you 
will find very useful information there (including a link to Robert King's 
archives).

Francisco



>From: "White, Charles E WRAIR-Wash DC" <charles.edwin.white at us.army.mil>
>To: <r-help at stat.math.ethz.ch>
>Subject: [R] Archive Search on R Help Mailing List Help
>Date: Sat, 6 Aug 2005 11:20:53 -0400
>
>The link to the search engine at the University of Newcastle, Australia 
>doesn't seem to be working. Is there someone who can either update the link 
>or indicate when the service may be back?
>
>Thanks.
>
>Chuck
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From rangeshk at gmail.com  Sat Aug  6 21:48:16 2005
From: rangeshk at gmail.com (Rangesh Kunnavakkam)
Date: Sat, 6 Aug 2005 14:48:16 -0500
Subject: [R] help regarding functions & loops
Message-ID: <839df10a05080612484a170a7e@mail.gmail.com>

I am new to R,so excuse me if its too basic. I have a vector of scores
        S= {s1,s2,s3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sn}
n could be very large.
I want to find p-value for each score and I have the formula
         pvalue= 1-exp(-exp(S))
so any ideas how to get this new vector P={p1,p2,p3,p4,p5....pn}
thankyou in advance
Rangesh



From j_brindle at hotmail.com  Sat Aug  6 22:39:22 2005
From: j_brindle at hotmail.com (Jim Brindle)
Date: Sat, 6 Aug 2005 16:39:22 -0400
Subject: [R] Bold-face axes with Boxplot
Message-ID: <BAY20-DAV4D71BC7EBC1D9B3945A2E80C60@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050806/d70da9d4/attachment.pl

From spencer.graves at pdf.com  Sun Aug  7 01:42:40 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 06 Aug 2005 16:42:40 -0700
Subject: [R] Using nonlinear regression
In-Reply-To: <200508041257.21030.mmiller@nassp.uct.ac.za>
References: <200508041257.21030.mmiller@nassp.uct.ac.za>
Message-ID: <42F54AF0.7060808@pdf.com>

	  Is there some reason you don't want to use maximum likelihood?  With 
the 2-parameter lognormal and no censored observations, the maximum 
likelihood estimates (MLEs) are just the mean and standard deviation of 
the logs.  See ?fitdistr in library(MASS).

	  If you really want nonlinear least squares, have you considered "nls"?

	  In the likely event that this response does not meet your needs, I 
suggest you consider preparing another question using the posting guide! 
http://www.R-project.org/posting-guide.html, as it can increase the 
chances of getting a more helpful reply -- if you don't find an answer 
in the course of preparing a question following the guide.

	  spencer graves

Mark Miller wrote:

> Hi, I have been trying to figure out how to use the nonlinear regression to 
> fit the cumulative lognormal distribution to a number of data points I have 
> but I am a new R user and I cant quite decipher the notes on nonlinear 
> regression.  Any help in this regard will be greatly appreciated, my email 
> address is mmiller at nassp.uct.ac.za
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From Glenn.Stone at csiro.au  Sun Aug  7 02:03:48 2005
From: Glenn.Stone at csiro.au (Glenn.Stone@csiro.au)
Date: Sun, 7 Aug 2005 10:03:48 +1000
Subject: [R] Odd timing behaviour in reading a file
Message-ID: <23BA2D8C2BB69047969C28B19807FCA6066B41@exnswn2-syd.nexus.csiro.au>


Thanks, very helpful.

Is there some way to adjust those GC triggers in advance?

-----Original Message-----
From:	Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
Sent:	Thu 8/4/2005 4:15 PM
To:	Stone, Glenn (CMIS, North Ryde)
Cc:	r-help at stat.math.ethz.ch
Subject:	Re: [R] Odd timing behaviour in reading a file
Please see the gcFirst argument to system.time, which you should set to 
TRUE for such timings.  Your second run is paying to GC the results of the 
first, most likely.

Beyond that, R adjusts its GC triggers based on usage, and when you first 
start using large objects the trigger levels will grow and generally 
things will speed up.  Set gcinfo(TRUE) to watch what is happening.

On Thu, 4 Aug 2005, Glenn Stone wrote:

> Hi all,  please don't ask me why I tried this but.......
>
> I have observed some odd behaviour in the time taken to read a file. I
> tried searching the archives without much success, but that could be me.
>
> The first time I read a (60Mb) CSV file, takes a certain amount of time.
> The second time takes appreciably longer and the third and subsequent
> times very much shorter times. See below,
>
> $ R2.1.1
>
> R : Copyright 2005, The R Foundation for Statistical Computing
> Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>  Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
>
> > system.time(temp <-
> read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
> [1] 32.55  0.30 33.46  0.00  0.00
> > system.time(temp <-
> read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
> [1] 45.32  0.24 45.72  0.00  0.00
> > system.time(temp <-
> read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
> [1] 11.73  0.17 11.94  0.00  0.00
> > system.time(temp <-
> read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
> [1] 8.58 0.28 8.96 0.00 0.00
> > system.time(temp <-
> read.csv("Mapping50K_Xba240_annot.csv",header=TRUE, as.is=TRUE))
> [1] 8.80 0.16 9.02 0.00 0.00
>
>
> This is a relatively quiet opteron running redhat linux and using R2.1.1
> The same pattern is repeatable, and occurs in R2.0.1 and on a Dell
> laptop running Windows XP.
>
> I guess it is probably something to do with the garbage collector? Can
> anyone explain further? Particularly the first increase.
>
> Thanks....
>
> -- 
> Glenn Stone
> CSIRO Bioinformatics
> http://www.bioinformatics.csiro.au
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sean.oriordain at gmail.com  Sun Aug  7 02:07:08 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Sun, 7 Aug 2005 01:07:08 +0100
Subject: [R] help regarding functions & loops
In-Reply-To: <839df10a05080612484a170a7e@mail.gmail.com>
References: <839df10a05080612484a170a7e@mail.gmail.com>
Message-ID: <8ed68eed05080617077c2cb580@mail.gmail.com>

Hi Rangesh,

Perhaps I mis-understand your question, but it could be as simple as...

p <- 1-exp(-exp(s))

In R, this is vectorized such that a new vector is calculated - one
value for each value of s, so p will have the same length as s.

In the "Introduction to R" read up on vectors and how to avoid loops.

cheers!
Sean

On 06/08/05, Rangesh Kunnavakkam <rangeshk at gmail.com> wrote:
> I am new to R,so excuse me if its too basic. I have a vector of scores
>         S= {s1,s2,s3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,sn}
> n could be very large.
> I want to find p-value for each score and I have the formula
>          pvalue= 1-exp(-exp(S))
> so any ideas how to get this new vector P={p1,p2,p3,p4,p5....pn}
> thankyou in advance
> Rangesh
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Sun Aug  7 04:10:31 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 06 Aug 2005 19:10:31 -0700
Subject: [R] some thoughts on outlier detection, need help!
In-Reply-To: <cdf8178305080412137c567835@mail.gmail.com>
References: <cdf8178305080412137c567835@mail.gmail.com>
Message-ID: <42F56D97.70402@pdf.com>

	  I'm not certain what you are asking.  PLEASE do read the posting 
guide! "http://www.R-project.org/posting-guide.html".  If you formulate 
your question in terms of a simple example, showing where you got stuck 
as suggested in the posting guide, it might help others understand your 
question and inspire suggestions.

	  TINSTAFL = There is no such thing as a free lunch (Heinlein, The Moon 
is a Harsh Mistress)

	  spencer graves

Weiwei Shi wrote:

> Dear listers:
> I have an idea to do the outlier detection and I need to use R to
> implement it first. Here I hope I can get some input from all the
> guru's here.
> 
> I select distance-based approach---
> step 1:
> calculate the distance of any two rows for a dataframe. considering
> the scaling among different variables, I choose mahalanobis, using
> variance as scaler.
> 
> step 2:
> Let k be the number of points in one "cluster". K is decided by
> answering the following question: how many neighbors a point needs for
> not being an outlier.
> 
> for each point, get the smallest (k-1) distances from step1.  Among
> the (k-1) distances of each point, get the max for the point.
> 
> step 3:
> get the distribution of those max for all the points. Thus, the
> multivariate problem becomes a univariate one. Then the outlier in
> those max's will define the outlier of the point.
> 
> My question is:
> 1. I don't know if using mahalanobis is proper or not since most
> clustering algorithms implemented in R (like pam or clara) use
> euclidean or mahattan.
> 2. Is there a way to get the mahalanobis distance matrix for any two
> rows of a dataframe or matrix?
> 3. My approach does allow a point belonging to more than one
> k-cluster. Is there similar algorithm in R or published?
> 
> Thanks for any suggestions,
> 
> weiwei

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From spencer.graves at pdf.com  Sun Aug  7 04:31:41 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 06 Aug 2005 19:31:41 -0700
Subject: [R] exact goodness-of-fit test
In-Reply-To: <006601c5993b$230864c0$4c3cb850@v3x0q0>
References: <006601c5993b$230864c0$4c3cb850@v3x0q0>
Message-ID: <42F5728D.5090003@pdf.com>

	  I don't know of an existing R function to do this.  However, it 
should not be too hard, especially if I had only one with the numbers 
you gave.  I'd compute the observed chi-square, then construct a series 
of 4 nested "for" loops to generate all 5969040 = 22!/(15! 0! 3! 4!) 
possible outcomes that sum to 22, compute the chi-square for each, and 
count how many have a chi-square at least as extreme as what you 
observed.  If I wanted a general algorithm, that would take more work.

	  If you'd like more help than this, PLEASE do read the posting guide! 
"http://www.R-project.org/posting-guide.html", show us your code and 
where you got stuck.

	  spencer graves

Christine Adrion wrote:

> Hello,
> 
> I have a question concerning the R-function chisq.test. 
> 
> For example, I have some count data which can be categorized as follows
> class1: 15 observations
> class2:  0 observations
> class3:  3 observations
> class4:  4 observations
> 
> I would like to test the hypothesis whether the population probabilities are all equal (=> Test for discrete uniform distribution)
> If you have a small sample size and therefore a sparse (1xr)-table, then assumptions for chisquare-goodness-of-fit test are violated (the numbers expected are less than 5 in more than 75% of the entries.)
> 
> #######  R-Program: Chisquare-Test :#########
> 
> mydata <- c(15,0,3,4)
> chisq.test(mydata, correct=TRUE, rescale.p = TRUE, simulate.p.value = TRUE, B = 2000)
> 
> 
> As you cannot ignore the small sample size, I use 'simulate.p.value' is 'TRUE'  and therefore the p-value is computed by Monte Carlo simulation with 'B' replicates.
> But is it also the possible to use an EXACT version of a chisquare goodness-of-fit test without a Monte-Carlo-simulation? How can I calculate this in R?
> 
> 
> 
> Any hint would be appreciated,
> Regards,
> Christine Adrion
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From spencer.graves at pdf.com  Sun Aug  7 04:34:59 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 06 Aug 2005 19:34:59 -0700
Subject: [R] p-values
In-Reply-To: <42F29071.1000107@fe.up.pt>
References: <42F29071.1000107@fe.up.pt>
Message-ID: <42F57353.9040304@pdf.com>

Hi, Peter:

	  Please see my reply of a few minutes ago subject:  exact 
goodness-of-fit test.  I don't know Rayner and Best, but the same 
method, I think, should apply.  spencer graves

Peter Ho wrote:

> HI R-users,
> 
> I am trying to repeat an example from Rayner and Best "A contingency 
> table approach to nonparametric testing (Chapter 7, Ice cream example).
> 
> In their book they calculate Durbin's statistic, D1, a dispersion 
> statistics, D2, and a residual. P-values for each statistic is 
> calculated from a chi-square distribution and also Monte Carlo p-values.
> 
> I have found similar p-values based on the chi-square distribution by 
> using:
> 
>  > pchisq(12, df= 6, lower.tail=F)
> [1] 0.0619688
>  > pchisq(5.1, df= 6, lower.tail=F)
> [1] 0.5310529
> 
> Is there a way to calculate the equivalent Monte Carlo p-values?
> 
> The values were 0.02 and 0.138 respectively.
> 
> The use of the approximate chi-square probabilities for Durbin's test 
> are considered not good enough according to Van der Laan (The American 
> Statistician 1988,42,165-166).
> 
> 
> Peter
> --------------------------------
> ESTG-IPVC
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From sourceforge at metrak.com  Sun Aug  7 04:38:19 2005
From: sourceforge at metrak.com (sosman)
Date: Sun, 07 Aug 2005 12:38:19 +1000
Subject: [R] Latex error with Sweave example
In-Reply-To: <42F3F8EA.6020100@metrak.com>
References: <42F3F8EA.6020100@metrak.com>
Message-ID: <42F5741B.8040106@metrak.com>

sosman wrote:
> I created a tex file following the example in the Sweave help which 
> produced the following files in my working directory.
[snip]

Thanks for the replies - I have worked around the problem by running 
latex on my Fedora machine.  I will leave getting MiKTeX running to a 
rainy day.

Actually after some further digging - I ended up using latex2html, I am 
using this for daily metrics and the main requirement is for presenting 
and annotating plots.

cheers



From ripley at stats.ox.ac.uk  Sun Aug  7 07:20:04 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 7 Aug 2005 06:20:04 +0100 (BST)
Subject: [R] Odd timing behaviour in reading a file
In-Reply-To: <23BA2D8C2BB69047969C28B19807FCA6066B41@exnswn2-syd.nexus.csiro.au>
References: <23BA2D8C2BB69047969C28B19807FCA6066B41@exnswn2-syd.nexus.csiro.au>
Message-ID: <Pine.LNX.4.61.0508070617390.17626@gannet.stats>

On Sun, 7 Aug 2005 Glenn.Stone at csiro.au wrote:

> Thanks, very helpful.
>
> Is there some way to adjust those GC triggers in advance?

Almost: that is what the statrtup flags such as --min-vsize help do.

> -----Original Message-----
> From:	Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent:	Thu 8/4/2005 4:15 PM
> To:	Stone, Glenn (CMIS, North Ryde)
> Cc:	r-help at stat.math.ethz.ch
> Subject:	Re: [R] Odd timing behaviour in reading a file
> Please see the gcFirst argument to system.time, which you should set to
> TRUE for such timings.  Your second run is paying to GC the results of the
> first, most likely.
>
> Beyond that, R adjusts its GC triggers based on usage, and when you first
> start using large objects the trigger levels will grow and generally
> things will speed up.  Set gcinfo(TRUE) to watch what is happening.

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From fdu.xiaojf at gamil.com  Sun Aug  7 12:38:25 2005
From: fdu.xiaojf at gamil.com (Xiao Jianfeng)
Date: Sun, 07 Aug 2005 18:38:25 +0800
Subject: [R] Installation problem on SGI IRIX6.5
In-Reply-To: <Pine.LNX.4.61.0508051653330.5979@gannet.stats>
References: <42F324A9.6070907@gamil.com> <42F378A9.9070600@gamil.com>
	<Pine.LNX.4.61.0508051653330.5979@gannet.stats>
Message-ID: <42F5E4A1.8040408@gamil.com>

Prof Brian Ripley wrote:

>Please do try reading the R-admin manual (as the INSTALL file asks you to: 
>it does not ask you to `surf on the net').
>
>  
>
Thanks a lot !

I have read the R-admin manual before turn to the internet,
but I didn't read it carefully. Sorry about that.


>The following section may help you:
>
>   To enable UTF-8 support, configure with default @option{--enable-mbcs}.
>   This will check for a large number of features, notably support for the
>   C99/UNIX98 wide character functions and for UTF-8 or MBCS support in
>   X11.  If enough of these are found, @code{MBCS} will be listed as one
>   of the ``Additional capabilities''
>
>so try --disable-mbcs if your OS has broken header files.  (It apparently 
>does have wctrans, but not the type it returns.)
>
>  
>
Yes, it does help.

Now I used the following command to configure according page 28(*B.7.5 
IRIX*):

"
env CC=cc F77=f77 CXX=CC CPPFLAGS="-I/user_data2/jfxiao/local/include 
-I/usr/freeware/include" LDFLAGS="-L/user_data2/jfxiao/local/lib 
-L/usr/freeware/lib32" CFLAGS="-O2" FFLAGS="-O2" CXXFLAGS="-O2" 
./configure --prefix=/user_data2/jfxiao/local --disable-mbcs 
--disable-nls MAKE=gmake
"

This command ran successfully, and get the following output:

"
R is now configured for mips-sgi-irix6.5

Source directory: .
Installation directory: /user_data2/jfxiao/local

C compiler: cc -OPT:IEEE_NaN_inf=ON -O2
C++ compiler: CC -OPT:IEEE_NaN_inf=ON -O2
Fortran compiler: f77 -OPT:IEEE_NaN_inf=ON -O2

Interfaces supported: X11
External libraries: readline, BLAS(generic)
Additional capabilities:
Options enabled: R profiling

Recommended packages: yes

configure: WARNING: you cannot build DVI versions of the R manuals
configure: WARNING: you cannot build info or html versions of the R manuals
configure: WARNING: you cannot build PDF versions of the R manuals
"

Then I ran `gmake` to make, but it fails.
I got the following error message:
"
cc -I../../src/extra/zlib -I../../src/extra/bzip2 -I../../src/extra/pcre 
-I. -I../../src/include -I../../src/include 
-I/user_data2/jfxiao/local/include -I/usr/freeware/include 
-DHAVE_CONFIG_H -OPT:IEEE_NaN_inf=ON -O2 -c errors.c -o errors.o
cc-1185 cc: WARNING File = errors.c, Line = 266
An enumerated type is mixed with another type.

dcall = CHAR(STRING_ELT(deparse1(call, 0, SIMPLEDEPARSE), 0));
^

*cc-1515 cc: ERROR File = errors.c, Line = 357
A value of type "int" cannot be assigned to an entity of type "char *".

header = ngettext("Warning message:\n", "Warning messages:\n",
^*

......
......
......

1 error detected in the compilation of "errors.c".
gmake[3]: *** [errors.o] Error 2
gmake[3]: Leaving directory 
`/user_data2/jfxiao/local/source/R/R-2.1.1/src/main'
gmake[2]: *** [R] Error 2
gmake[2]: Leaving directory 
`/user_data2/jfxiao/local/source/R/R-2.1.1/src/main'
gmake[1]: *** [R] Error 1
gmake[1]: Leaving directory `/user_data2/jfxiao/local/source/R/R-2.1.1/src'
gmake: *** [R] Error 1
"

It's strange since the return value of ngettext() do have a value type 
of "char *".

Can somebody tell me why ?


>Now we know of the existence of such an OS, we can add a check.  Are 
>wctrans and wctrans_t defined anywhere else?
>  
>
I've run `grep "wctrans_t" */* ` in "/usr/include? but get nothing.



I've also tried to complie with gcc.

Acoording the instruction on page 28(*B.7.5 IRIX*), I used the following
command to configure:
"
env F77=f77 FFLAGS="-O2" CPPFLAGS="-I/user_data2/jfxiao/local/include 
-I/usr/freeware/include" LDFLAGS="-L/user_data2/jfxiao/local/lib 
-L/usr/freeware/lib32" ./configure --prefix=/user_data2/jfxiao/local 
--disable-mbcs --disable-nls MAKE=gmake
"
(Note that I have to specify F77=f77 or the configure step will fail.)

The command run without problem and gave out the success message:
"

R is now configured for mips-sgi-irix6.5

Source directory: .
Installation directory: /user_data2/jfxiao/local

C compiler: gcc -g -O2
C++ compiler: g++ -g -O2
Fortran compiler: f77 -OPT:IEEE_NaN_inf=ON -O2

Interfaces supported: X11
External libraries: readline, BLAS(generic)
Additional capabilities:
Options enabled: R profiling

Recommended packages: yes

configure: WARNING: you cannot build DVI versions of the R manuals
configure: WARNING: you cannot build info or html versions of the R manuals
configure: WARNING: you cannot build PDF versions of the R manuals

"

Then I ran `gmake` to compile, but it failed again.
Next is the last part of the output:

"
....

f77 -OPT:IEEE_NaN_inf=ON -O2 -c xxxpr.f -o xxxpr.o
gcc -L/user_data2/jfxiao/local/lib -L/usr/freeware/lib32 -o R.bin 
Rmain.o CConverters.o CommandLineArgs.o Rdynload.o Renviron.o RNG.o 
apply.o arithmetic.o apse.o array.o attrib.o base.o bind.o builtin.o 
character.o coerce.o colors.o complex.o connections.o context.o cov.o 
cum.o dcf.o datetime.o debug.o deparse.o deriv.o dotcode.o dounzip.o 
dstruct.o duplicate.o engine.o envir.o errors.o eval.o format.o 
fourier.o gevents.o gram.o gram-ex.o graphics.o identical.o internet.o 
iosupport.o lapack.o list.o logic.o main.o mapply.o match.o memory.o 
model.o names.o objects.o optim.o optimize.o options.o par.o paste.o 
pcre.o platform.o plot.o plot3d.o plotmath.o print.o printarray.o 
printvector.o printutils.o qsort.o random.o regex.o registration.o 
relop.o saveload.o scan.o seq.o serialize.o size.o sort.o source.o 
split.o sprintf.o startup.o subassign.o subscript.o subset.o summary.o 
sysutils.o unique.o util.o version.o vfonts.o xxxpr.o ../unix/libunix.a 
../appl/libappl.a ../nmath/libnmath.a -lblas -L/usr/lib32/mips4/r10000 
-L/usr/lib32/mips4 -lftn -lm ../extra/zlib/libz.a 
../extra/bzip2/libbz2.a ../extra/pcre/libpcre.a -lreadline -ldl -lm
ld32: WARNING 84 : /usr/lib32/libdl.so is not used for resolving any symbol.
ld32: ERROR 33 : Unresolved text symbol "ngettext" -- 1st referenced by 
errors.o.
Use linker option -v to see when and which objects, archives and dsos 
are loaded.
ld32: INFO 152: Output file removed because of error.
collect2: ld returned 2 exit status
gmake[3]: *** [R.bin] Error 1
gmake[3]: Leaving directory 
`/user_data2/jfxiao/local/source/R/R-2.1.1/src/main'
gmake[2]: *** [R] Error 2
gmake[2]: Leaving directory 
`/user_data2/jfxiao/local/source/R/R-2.1.1/src/main'
gmake[1]: *** [R] Error 1
gmake[1]: Leaving directory `/user_data2/jfxiao/local/source/R/R-2.1.1/src'
gmake: *** [R] Error 1
"

I have read the manual again and ased some people in our lab, but get no 
helpful information.

I'm not familiar about compilation in Unix, so I come here to bother again.

Thanks again for any help !



From hugues_sj at yahoo.fr  Sun Aug  7 16:11:37 2005
From: hugues_sj at yahoo.fr (hugues santin janin)
Date: Sun, 7 Aug 2005 16:11:37 +0200 (CEST)
Subject: [R] prediction from glm...
Message-ID: <20050807141137.30900.qmail@web25110.mail.ukl.yahoo.com>

Hello r-help, 

I'm trying to fit birds counts over years using glm. In fact I'm trying to reproduce an analysis already perform with genstat (attach document). I have done (with Estate
and year as factors):

Model1 <- glm(Females~Estate+Year+offset = log(area)), family =
quasipoisson(link = log), na.action = "na.exclude") 

After I have calculated the prediction using:

Pred1 <- predict(Model1, type = "response", na.action = "na.exclude")

Pred1 given to me the prediction using Model1 e.g. Females~Estate+Year. But I search to reproduce the original data whitout the sEstate effect. That permit me to interprete only the variation in number of bird due to theYear. The argument new.data seems  useful to specify which data we want to predict but not to specify how to predict these data.
 
predict.glm is the good functoin to do that? How can I specify to predict.glm() to remove the sEstate effect of the Females prediction?
 
I have not found answer in the archives of R-help.
I thank you for your time and your help in regards to this problem,

Hugues SANTIN-JANIN

hugues_sj at yahoo.fr

"Game Conservancy Trust"






		
---------------------------------


From ripley at stats.ox.ac.uk  Sun Aug  7 18:47:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 7 Aug 2005 17:47:46 +0100 (BST)
Subject: [R] prediction from glm...
In-Reply-To: <20050807141137.30900.qmail@web25110.mail.ukl.yahoo.com>
References: <20050807141137.30900.qmail@web25110.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.61.0508071740470.8094@gannet.stats>

On Sun, 7 Aug 2005, hugues santin janin wrote:

> Hello r-help,
>
> I'm trying to fit birds counts over years using glm. In fact I'm trying to reproduce an analysis already perform with genstat (attach document). I have done (with Estate
> and year as factors):
>
> Model1 <- glm(Females~Estate+Year+offset = log(area)), family =
> quasipoisson(link = log), na.action = "na.exclude")

That is not valid R. 
Did you actually use  Females~Estate+Year+offset(log(area)) ?

> After I have calculated the prediction using:
>
> Pred1 <- predict(Model1, type = "response", na.action = "na.exclude")
>
> Pred1 given to me the prediction using Model1 e.g. Females~Estate+Year.

That is not what I read Model1 to be.

> But I search to reproduce the original data whitout the sEstate effect.

Did you mean the 'Estate' term?  Otherwise, what is `sEstate'?

> That permit me to interprete only the variation in number of bird due to 
> theYear. The argument new.data seems useful to specify which data we 
> want to predict but not to specify how to predict these data.

Did you mean `newdata'?

> predict.glm is the good functoin to do that? How can I specify to 
> predict.glm() to remove the sEstate effect of the Females prediction?

You fit a model without the term if you want to predict from a different 
model.

> I have not found answer in the archives of R-help.
> I thank you for your time and your help in regards to this problem,

I am sorry, but you will need to be *accurate* in what you write, as you 
have made too many errors for me (at least) to guess what you mean.

This sort of thing is covered in all good texts on R, of which there are 
several in the FAQ.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sun Aug  7 19:23:14 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 7 Aug 2005 18:23:14 +0100 (BST)
Subject: [R] Installation problem on SGI IRIX6.5
In-Reply-To: <42F5E4A1.8040408@gamil.com>
References: <42F324A9.6070907@gamil.com> <42F378A9.9070600@gamil.com>
	<Pine.LNX.4.61.0508051653330.5979@gannet.stats>
	<42F5E4A1.8040408@gamil.com>
Message-ID: <Pine.LNX.4.61.0508071817440.10036@gannet.stats>

You have a large number of non-IRIX paths in your configure. That is 
almost certainly your problem: other people _have_ successfully built R 
2.1.x on IRIX 6.5.  In particular, you seem to have a broken version of 
gettext in your non-IRIX directories which is not declaring ngettext.

If you cannot use a less eclectic collection of software, run
configure --help and see how to use the provided gettext (probably via
--with-included-gettext).  Or use --disable-nls.

On Sun, 7 Aug 2005, Xiao Jianfeng wrote:

> Prof Brian Ripley wrote:
>
>> Please do try reading the R-admin manual (as the INSTALL file asks you to: 
>> it does not ask you to `surf on the net').
>> 
>> 
> Thanks a lot !
>
> I have read the R-admin manual before turn to the internet,
> but I didn't read it carefully. Sorry about that.
>
>
>> The following section may help you:
>> 
>>   To enable UTF-8 support, configure with default @option{--enable-mbcs}.
>>   This will check for a large number of features, notably support for the
>>   C99/UNIX98 wide character functions and for UTF-8 or MBCS support in
>>   X11.  If enough of these are found, @code{MBCS} will be listed as one
>>   of the ``Additional capabilities''
>> 
>> so try --disable-mbcs if your OS has broken header files.  (It apparently 
>> does have wctrans, but not the type it returns.)
>> 
>> 
> Yes, it does help.
>
> Now I used the following command to configure according page 28(*B.7.5 
> IRIX*):
>
> "
> env CC=cc F77=f77 CXX=CC CPPFLAGS="-I/user_data2/jfxiao/local/include 
> -I/usr/freeware/include" LDFLAGS="-L/user_data2/jfxiao/local/lib 
> -L/usr/freeware/lib32" CFLAGS="-O2" FFLAGS="-O2" CXXFLAGS="-O2" ./configure 
> --prefix=/user_data2/jfxiao/local --disable-mbcs --disable-nls MAKE=gmake
> "
>
> This command ran successfully, and get the following output:
>
> "
> R is now configured for mips-sgi-irix6.5
>
> Source directory: .
> Installation directory: /user_data2/jfxiao/local
>
> C compiler: cc -OPT:IEEE_NaN_inf=ON -O2
> C++ compiler: CC -OPT:IEEE_NaN_inf=ON -O2
> Fortran compiler: f77 -OPT:IEEE_NaN_inf=ON -O2
>
> Interfaces supported: X11
> External libraries: readline, BLAS(generic)
> Additional capabilities:
> Options enabled: R profiling
>
> Recommended packages: yes
>
> configure: WARNING: you cannot build DVI versions of the R manuals
> configure: WARNING: you cannot build info or html versions of the R manuals
> configure: WARNING: you cannot build PDF versions of the R manuals
> "
>
> Then I ran `gmake` to make, but it fails.
> I got the following error message:
> "
> cc -I../../src/extra/zlib -I../../src/extra/bzip2 -I../../src/extra/pcre -I. 
> -I../../src/include -I../../src/include -I/user_data2/jfxiao/local/include 
> -I/usr/freeware/include -DHAVE_CONFIG_H -OPT:IEEE_NaN_inf=ON -O2 -c errors.c 
> -o errors.o
> cc-1185 cc: WARNING File = errors.c, Line = 266
> An enumerated type is mixed with another type.
>
> dcall = CHAR(STRING_ELT(deparse1(call, 0, SIMPLEDEPARSE), 0));
> ^
>
> *cc-1515 cc: ERROR File = errors.c, Line = 357
> A value of type "int" cannot be assigned to an entity of type "char *".
>
> header = ngettext("Warning message:\n", "Warning messages:\n",
> ^*
>
> ......
> ......
> ......
>
> 1 error detected in the compilation of "errors.c".
> gmake[3]: *** [errors.o] Error 2
> gmake[3]: Leaving directory 
> `/user_data2/jfxiao/local/source/R/R-2.1.1/src/main'
> gmake[2]: *** [R] Error 2
> gmake[2]: Leaving directory 
> `/user_data2/jfxiao/local/source/R/R-2.1.1/src/main'
> gmake[1]: *** [R] Error 1
> gmake[1]: Leaving directory `/user_data2/jfxiao/local/source/R/R-2.1.1/src'
> gmake: *** [R] Error 1
> "
>
> It's strange since the return value of ngettext() do have a value type of 
> "char *".
>
> Can somebody tell me why ?
>
>
>> Now we know of the existence of such an OS, we can add a check.  Are 
>> wctrans and wctrans_t defined anywhere else?
>> 
> I've run `grep "wctrans_t" */* ` in "/usr/include but get nothing.
>
>
>
> I've also tried to complie with gcc.
>
> Acoording the instruction on page 28(*B.7.5 IRIX*), I used the following
> command to configure:
> "
> env F77=f77 FFLAGS="-O2" CPPFLAGS="-I/user_data2/jfxiao/local/include 
> -I/usr/freeware/include" LDFLAGS="-L/user_data2/jfxiao/local/lib 
> -L/usr/freeware/lib32" ./configure --prefix=/user_data2/jfxiao/local 
> --disable-mbcs --disable-nls MAKE=gmake
> "
> (Note that I have to specify F77=f77 or the configure step will fail.)
>
> The command run without problem and gave out the success message:
> "
>
> R is now configured for mips-sgi-irix6.5
>
> Source directory: .
> Installation directory: /user_data2/jfxiao/local
>
> C compiler: gcc -g -O2
> C++ compiler: g++ -g -O2
> Fortran compiler: f77 -OPT:IEEE_NaN_inf=ON -O2
>
> Interfaces supported: X11
> External libraries: readline, BLAS(generic)
> Additional capabilities:
> Options enabled: R profiling
>
> Recommended packages: yes
>
> configure: WARNING: you cannot build DVI versions of the R manuals
> configure: WARNING: you cannot build info or html versions of the R manuals
> configure: WARNING: you cannot build PDF versions of the R manuals
>
> "
>
> Then I ran `gmake` to compile, but it failed again.
> Next is the last part of the output:
>
> "
> ....
>
> f77 -OPT:IEEE_NaN_inf=ON -O2 -c xxxpr.f -o xxxpr.o
> gcc -L/user_data2/jfxiao/local/lib -L/usr/freeware/lib32 -o R.bin Rmain.o 
> CConverters.o CommandLineArgs.o Rdynload.o Renviron.o RNG.o apply.o 
> arithmetic.o apse.o array.o attrib.o base.o bind.o builtin.o character.o 
> coerce.o colors.o complex.o connections.o context.o cov.o cum.o dcf.o 
> datetime.o debug.o deparse.o deriv.o dotcode.o dounzip.o dstruct.o 
> duplicate.o engine.o envir.o errors.o eval.o format.o fourier.o gevents.o 
> gram.o gram-ex.o graphics.o identical.o internet.o iosupport.o lapack.o 
> list.o logic.o main.o mapply.o match.o memory.o model.o names.o objects.o 
> optim.o optimize.o options.o par.o paste.o pcre.o platform.o plot.o plot3d.o 
> plotmath.o print.o printarray.o printvector.o printutils.o qsort.o random.o 
> regex.o registration.o relop.o saveload.o scan.o seq.o serialize.o size.o 
> sort.o source.o split.o sprintf.o startup.o subassign.o subscript.o subset.o 
> summary.o sysutils.o unique.o util.o version.o vfonts.o xxxpr.o 
> ../unix/libunix.a ../appl/libappl.a ../nmath/libnmath.a -lblas 
> -L/usr/lib32/mips4/r10000 -L/usr/lib32/mips4 -lftn -lm ../extra/zlib/libz.a 
> ../extra/bzip2/libbz2.a ../extra/pcre/libpcre.a -lreadline -ldl -lm
> ld32: WARNING 84 : /usr/lib32/libdl.so is not used for resolving any symbol.
> ld32: ERROR 33 : Unresolved text symbol "ngettext" -- 1st referenced by 
> errors.o.
> Use linker option -v to see when and which objects, archives and dsos are 
> loaded.
> ld32: INFO 152: Output file removed because of error.
> collect2: ld returned 2 exit status
> gmake[3]: *** [R.bin] Error 1
> gmake[3]: Leaving directory 
> `/user_data2/jfxiao/local/source/R/R-2.1.1/src/main'
> gmake[2]: *** [R] Error 2
> gmake[2]: Leaving directory 
> `/user_data2/jfxiao/local/source/R/R-2.1.1/src/main'
> gmake[1]: *** [R] Error 1
> gmake[1]: Leaving directory `/user_data2/jfxiao/local/source/R/R-2.1.1/src'
> gmake: *** [R] Error 1
> "
>
> I have read the manual again and ased some people in our lab, but get no 
> helpful information.
>
> I'm not familiar about compilation in Unix, so I come here to bother again.
>
> Thanks again for any help !
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From spencer.graves at pdf.com  Sun Aug  7 21:58:11 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 07 Aug 2005 12:58:11 -0700
Subject: [R] qq.loglogistic
In-Reply-To: <Pine.LNX.4.62.0508061108450.31539@artax.karlin.mff.cuni.cz>
References: <Pine.LNX.4.62.0508061108450.31539@artax.karlin.mff.cuni.cz>
Message-ID: <42F667D3.3000906@pdf.com>

	  I know of no such function.  Some authors have described PP and QQ 
plots for a arbitrary distributions.  I've experimented with PP plots 
and QQ plots for uniform, Student's t, chi-square and F distributions, 
but have not gotten much out of them.  The uniform plots failed to show 
adequate detail close to 0 or 1.  With the Student's t, chi-square, and 
F plots, the points in the tail were too far apart for me to easily 
judge what was happening.

	  However, I regularly use normal probability plots.  If I wanted to 
test a logistic fit, I might esimate the parameters, e.g. using 
"fitdistr" in library(MASS), then transform the data to probabilities 
using plogis, then further tranform the probabilities to normal scores 
using qnorm.  The I would make a normal probability plot.

	  If anyone else has relevant experience, whether consistent or 
conflicting with mine, I'd be pleased to hear about it.

	  spencer graves

Petr Mandys wrote:

> Hi,
> 
> is there any similar function in R to S function qq.loglogistic, which 
> produces a Q-Q plot?
> 
> Thanks a lot
> 
> Pete
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From spencer.graves at pdf.com  Mon Aug  8 00:54:20 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 07 Aug 2005 15:54:20 -0700
Subject: [R] question regarding logit regression using glm
In-Reply-To: <20050805201721.30350.qmail@web31014.mail.mud.yahoo.com>
References: <20050805201721.30350.qmail@web31014.mail.mud.yahoo.com>
Message-ID: <42F6911C.2020102@pdf.com>

	  The "problem" is that with 40 parameters, you are able to get a 
perfect fit for at least some of the observations.  To achieve this, it 
sends selected parameters to +/-Inf.  Of course, it quits before it gets 
to Inf, but most of your parameter estimates exceeded 1e13 in absolute 
value.

	  What do you want?  Do you really need MSA to be a factor, requiring 
you to estimate 39 parameters for MSA?  Does it make sense to 
parameterize it some other way, like latitude and longitude?  You could 
fit a polynomial in lat + lon and gain substantial insight, I suspect, 
that you can't get from the factor coefficients.

	  spencer graves

Haibo Huang wrote:

> I got the following warning messages when I did a
> binomial logit regression using glm():
> 
> Warning messages: 
> 1: Algorithm did not converge in: glm.fit(x = X, y =
> Y, weights = weights, start = start, etastart =
> etastart,  
> 2: fitted probabilities numerically 0 or 1 occurred
> in: glm.fit(x = X, y = Y, weights = weights, start =
> start, etastart = etastart,  
> 
> Can some one share your thoughts on how to solve this
> problem? Please read the following for details. Thank
> you very much!
> 
> Best,
> Ed
> 
> 
> 
>>Lease=read.csv("lease.csv", header=TRUE)
>>Lease$ET = factor(Lease$EarlyTermination)
>>SICCode=factor(Lease$SIC.Code)
>>TO=factor(Lease$TenantHasOption)
>>LO=factor(Lease$LandlordHasOption)
>>TEO=factor(Lease$TenantExercisedOption)
>>
>>RegA=glm(ET~1+MSA, 
> 
> + family=binomial(link=logit), data=Lease,
> weights=Origil.SQFT)
> Warning messages: 
> 1: Algorithm did not converge in: glm.fit(x = X, y =
> Y, weights = weights, start = start, etastart =
> etastart,  
> 2: fitted probabilities numerically 0 or 1 occurred
> in: glm.fit(x = X, y = Y, weights = weights, start =
> start, etastart = etastart,  
> 
>>summary(RegA)
> 
> 
> Call:
> glm(formula = ET ~ 1 + MSA, family = binomial(link =
> logit), 
>     data = Lease, weights = Origil.SQFT)
> 
> Deviance Residuals: 
>        Min          1Q      Median          3Q        
> Max  
> -6.038e+03  -2.066e-06   0.000e+00   0.000e+00  
> 6.720e+03  
> 
> Coefficients:
>                       Estimate Std. Error    z value
> Pr(>|z|)    
> (Intercept)          5.711e+00  8.466e-02  6.745e+01  
> <2e-16 ***
> MSAAnchorage        -6.493e+00  8.541e-02 -7.602e+01  
> <2e-16 ***
> MSAAtlanta           6.894e+14  2.310e+04  2.985e+10  
> <2e-16 ***
> MSAAustin           -9.362e+14  4.954e+04 -1.890e+10  
> <2e-16 ***
> MSABoston           -2.474e+15  2.151e+04 -1.150e+11  
> <2e-16 ***
> MSACharlotte        -2.150e+15  7.265e+04 -2.960e+10  
> <2e-16 ***
> MSAChicago          -1.174e+15  2.057e+04 -5.707e+10  
> <2e-16 ***
> MSACleveland        -7.607e+14  7.046e+04 -1.080e+10  
> <2e-16 ***
> MSAColumbus         -2.768e+15  1.685e+05 -1.642e+10  
> <2e-16 ***
> MSADallas            2.061e+14  3.261e+04  6.321e+09  
> <2e-16 ***
> MSADenver            5.470e+14  3.366e+04  1.625e+10  
> <2e-16 ***
> MSAEast Bay         -6.191e+01  1.344e+05  -4.61e-04  
>      1    
> MSAFt. Worth        -6.565e+00  8.483e-02 -7.739e+01  
> <2e-16 ***
> MSAHouston          -2.735e+15  3.576e+04 -7.648e+10  
> <2e-16 ***
> MSAIndianapolis     -7.483e+14  6.588e+04 -1.136e+10  
> <2e-16 ***
> MSALos Angeles      -1.388e+15  2.887e+04 -4.809e+10  
> <2e-16 ***
> MSAMinneapolis      -1.011e+15  2.731e+04 -3.702e+10  
> <2e-16 ***
> MSANashville         2.143e+01  9.395e+04   2.28e-04  
>      1    
> MSANew Orleans      -3.370e+15  5.038e+04 -6.689e+10  
> <2e-16 ***
> MSANew York         -2.526e+15  2.969e+04 -8.507e+10  
> <2e-16 ***
> MSANorfolk          -5.614e+01  2.020e+06  -2.78e-05  
>      1    
> MSAOakland-East Bay -2.272e+15  3.642e+04 -6.239e+10  
> <2e-16 ***
> MSAOrange County    -5.165e+14  2.428e+04 -2.128e+10  
> <2e-16 ***
> MSAOrlando          -3.215e+15  1.096e+05 -2.933e+10  
> <2e-16 ***
> MSAPhiladelphia     -8.871e+14  4.948e+04 -1.793e+10  
> <2e-16 ***
> MSAPhoenix          -1.156e+01  8.807e-02 -1.313e+02  
> <2e-16 ***
> MSAPortland          7.604e+14  3.841e+04  1.980e+10  
> <2e-16 ***
> MSARaleigh-Durham   -4.312e+01  1.294e+05  -3.33e-04  
>      1    
> MSARiverside         1.626e+15  4.645e+05  3.500e+09  
> <2e-16 ***
> MSASacramento       -9.873e+14  5.345e+04 -1.847e+10  
> <2e-16 ***
> MSASalt Lake City    1.793e+15  2.029e+05  8.839e+09  
> <2e-16 ***
> MSASan Antonio       9.451e+14  9.473e+04  9.977e+09  
> <2e-16 ***
> MSASan Diego        -3.740e+15  6.651e+04 -5.623e+10  
> <2e-16 ***
> MSASan Francisco     3.109e+14  2.394e+04  1.299e+10  
> <2e-16 ***
> MSASan Jose          7.392e+14  2.961e+04  2.497e+10  
> <2e-16 ***
> MSASeattle          -2.250e+15  1.581e+04 -1.423e+11  
> <2e-16 ***
> MSASt. Louis        -2.606e+15  1.801e+05 -1.447e+10  
> <2e-16 ***
> MSAStamford         -6.592e+00  8.469e-02 -7.784e+01  
> <2e-16 ***
> MSAWashington DC     8.460e+13  3.319e+04  2.549e+09  
> <2e-16 ***
> MSAWest Palm Beach  -3.924e+01  2.308e+05  -1.70e-04  
>      1    
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.'
> 0.1 ` ' 1 
> 
> (Dispersion parameter for binomial family taken to be
> 1)
> 
>     Null deviance:  123111026  on 9302  degrees of
> freedom
> Residual deviance: 3028559052  on 9263  degrees of
> freedom
> AIC: 3028559132
> 
> Number of Fisher Scoring iterations: 25
> 
> 
>>anova(RegA)
> 
> Analysis of Deviance Table
> 
> Model: binomial, link: logit
> 
> Response: ET
> 
> Terms added sequentially (first to last)
> 
> 
>        Df   Deviance Resid. Df Resid. Dev
> NULL                      9302  123111026
> MSA    39          0      9263 3028559052
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From ckjmaner at carolina.rr.com  Mon Aug  8 05:22:45 2005
From: ckjmaner at carolina.rr.com (Charles and Kimberly Maner)
Date: Sun, 7 Aug 2005 23:22:45 -0400
Subject: [R] Graphics on MacOSX
Message-ID: <200508080322.j783M1L6028086@ms-smtp-04-eri0.southeast.rr.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050807/1e9c494b/attachment.pl

From guido.parravergara at jcu.edu.au  Mon Aug  8 08:26:43 2005
From: guido.parravergara at jcu.edu.au (Guido Parra Vergara)
Date: Mon, 08 Aug 2005 16:26:43 +1000
Subject: [R] extract t-values from pairwise.t.test
Message-ID: <6.2.3.4.0.20050808162248.01d22890@pop.jcu.edu.au>

Hi,

how can I extract the t-values after running a pairwise.t.test? The 
output just list the p-values.
Many thanks for your help.

Cheers
Guido



____________________________________

Guido J. Parra
School of Tropical Environment Studies and Geography
James Cook University
Townsville
Queensland 4811

Phone:  61 7 47815824
Fax:            61 7 47814020
Mobile: 0437630843
e-mail:         guido.parravergara at jcu.edu.au



From David.Duffy at qimr.edu.au  Mon Aug  8 08:22:40 2005
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 8 Aug 2005 16:22:40 +1000 (EST)
Subject: [R] R-help Digest, Vol 30, Issue 6
In-Reply-To: <mailman.9.1123322401.19861.r-help@stat.math.ethz.ch>
References: <mailman.9.1123322401.19861.r-help@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0508081613200.16880@orpheus.qimr.edu.au>

On Fri, 5 Aug 2005 Julia Reid  wrote:

> Subject: [R] GAP pointer
>
> I am trying to do a simple segregation analysis using the GAP package. I
> have the documentation for pointer but I desperately need an example so
> that I can see how to format the datfile and the jobfile. For each
> individual, I have FamilyId, SubjectId, FatherId, MotherId, and
> AffectedStatus (0/1). I would like to obtain the likelihood ratio
> statistic for transmission.
> I would greatly appreciate any help on this subject.
> Best to all,
> Julia Reid
>
I wouldn't use Pointer myself (there are lots of more recent packages*),
but look at the examples in
http://cedar.genetics.soton.ac.uk/pub/PROGRAMS/pointer/pointer.tar.Z
and the manual, which is in the book:

Morton N.E., Rao D.C & Lalouel J-M (1983).
Methods in Genetic Epidemiology. Karger
PO Box, CH-4009 Basel (Switzerland).
ISBN 3-8055-3668-2

which you will find in many academic libraries.

David Duffy.


* Don't you use Pap or JPap at Myriad?



From mail at bymouth.com  Mon Aug  8 08:37:35 2005
From: mail at bymouth.com (Stephen Choularton)
Date: Mon, 8 Aug 2005 16:37:35 +1000
Subject: [R] chisq.test
Message-ID: <027701c59be3$abec78d0$45576f89@Tablet>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050808/263140da/attachment.pl

From avscan at jeunesse-sports.gouv.fr  Mon Aug  8 08:45:58 2005
From: avscan at jeunesse-sports.gouv.fr (avscan@jeunesse-sports.gouv.fr)
Date: Mon,  8 Aug 2005 08:45:58 +0200 (CEST)
Subject: [R] Alerte Virus
Message-ID: <20050808064558.EBBDE2D5E5A@smtp.mjs.priv.atos.fr>

Le mail envoye a  20stephane.dumas at jeunesse-sports.gouv.fr le lundi 08 ao??t contient un virus



From petr.pikal at precheza.cz  Mon Aug  8 08:46:17 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 08 Aug 2005 08:46:17 +0200
Subject: [R] extract t-values from pairwise.t.test
In-Reply-To: <6.2.3.4.0.20050808162248.01d22890@pop.jcu.edu.au>
Message-ID: <42F71BD9.18456.2F7A1D@localhost>

Hallo

My output lists more than p-values

> ttt<-t.test(rnorm(10), rnorm(10), paired=T)
> ttt

        Paired t-test

data:  rnorm(10) and rnorm(10) 
t = 1.7508, df = 9, p-value = 0.1139
alternative hypothesis: true difference in means is not equal to 0 
95 percent confidence interval:
 -0.1750263  1.3735176 
sample estimates:
mean of the differences 
              0.5992456 

> str(ttt)
List of 9
 $ statistic  : Named num 1.75
  ..- attr(*, "names")= chr "t"
 $ parameter  : Named num 9
  ..- attr(*, "names")= chr "df"
 $ p.value    : num 0.114
 $ conf.int   : atomic [1:2] -0.175  1.374
  ..- attr(*, "conf.level")= num 0.95
 $ estimate   : Named num 0.599
  ..- attr(*, "names")= chr "mean of the differences"
 $ null.value : Named num 0
  ..- attr(*, "names")= chr "difference in means"
 $ alternative: chr "two.sided"
 $ method     : chr "Paired t-test"
 $ data.name  : chr "rnorm(10) and rnorm(10)"
 - attr(*, "class")= chr "htest"
> ttt$statistic
       t 
1.750790 
>

The output is list and you can call any part of it by its name or by [] 
braces.

HTH
Petr




On 8 Aug 2005 at 16:26, Guido Parra Vergara wrote:

> Hi,
> 
> how can I extract the t-values after running a pairwise.t.test? The
> output just list the p-values. Many thanks for your help.
> 
> Cheers
> Guido
> 
> 
> 
> ____________________________________
> 
> Guido J. Parra
> School of Tropical Environment Studies and Geography
> James Cook University
> Townsville
> Queensland 4811
> 
> Phone:  61 7 47815824
> Fax:            61 7 47814020
> Mobile: 0437630843
> e-mail:         guido.parravergara at jcu.edu.au
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From blomsp at ozemail.com.au  Mon Aug  8 09:12:27 2005
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Mon, 08 Aug 2005 17:12:27 +1000
Subject: [R] extract t-values from pairwise.t.test
In-Reply-To: <42F71BD9.18456.2F7A1D@localhost>
References: <6.2.3.4.0.20050808162248.01d22890@pop.jcu.edu.au>
	<42F71BD9.18456.2F7A1D@localhost>
Message-ID: <6.2.1.2.0.20050808170432.01d9b500@mail.ozemail.com.au>

I think the questioner was interested in pairwise.t.test. See 
?pairwise.t.test. From looking at the source, pairwise.t.test calls t.test 
if sd's are not pooled, or calculates its own t.val if sds are pooled. It 
looks very easy to hack to return the t values instead of the p values.

Simon.


At 04:46 PM 8/08/2005, Petr Pikal wrote:
>Hallo
>
>My output lists more than p-values
>
> > ttt<-t.test(rnorm(10), rnorm(10), paired=T)
> > ttt
>
>         Paired t-test
>
>data:  rnorm(10) and rnorm(10)
>t = 1.7508, df = 9, p-value = 0.1139
>alternative hypothesis: true difference in means is not equal to 0
>95 percent confidence interval:
>  -0.1750263  1.3735176
>sample estimates:
>mean of the differences
>               0.5992456
>
> > str(ttt)
>List of 9
>  $ statistic  : Named num 1.75
>   ..- attr(*, "names")= chr "t"
>  $ parameter  : Named num 9
>   ..- attr(*, "names")= chr "df"
>  $ p.value    : num 0.114
>  $ conf.int   : atomic [1:2] -0.175  1.374
>   ..- attr(*, "conf.level")= num 0.95
>  $ estimate   : Named num 0.599
>   ..- attr(*, "names")= chr "mean of the differences"
>  $ null.value : Named num 0
>   ..- attr(*, "names")= chr "difference in means"
>  $ alternative: chr "two.sided"
>  $ method     : chr "Paired t-test"
>  $ data.name  : chr "rnorm(10) and rnorm(10)"
>  - attr(*, "class")= chr "htest"
> > ttt$statistic
>        t
>1.750790
> >
>
>The output is list and you can call any part of it by its name or by []
>braces.
>
>HTH
>Petr
>
>
>
>
>On 8 Aug 2005 at 16:26, Guido Parra Vergara wrote:
>
> > Hi,
> >
> > how can I extract the t-values after running a pairwise.t.test? The
> > output just list the p-values. Many thanks for your help.
> >
> > Cheers
> > Guido
> >
> >
> >
> > ____________________________________
> >
> > Guido J. Parra
> > School of Tropical Environment Studies and Geography
> > James Cook University
> > Townsville
> > Queensland 4811
> >
> > Phone:  61 7 47815824
> > Fax:            61 7 47814020
> > Mobile: 0437630843
> > e-mail:         guido.parravergara at jcu.edu.au
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
>
>Petr Pikal
>petr.pikal at precheza.cz
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From p.dalgaard at biostat.ku.dk  Mon Aug  8 09:20:13 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 Aug 2005 09:20:13 +0200
Subject: [R] extract t-values from pairwise.t.test
In-Reply-To: <6.2.3.4.0.20050808162248.01d22890@pop.jcu.edu.au>
References: <6.2.3.4.0.20050808162248.01d22890@pop.jcu.edu.au>
Message-ID: <x2oe88q4ia.fsf@turmalin.kubism.ku.dk>

Guido Parra Vergara <guido.parravergara at jcu.edu.au> writes:

> Hi,
> 
> how can I extract the t-values after running a pairwise.t.test? The 
> output just list the p-values.
> Many thanks for your help.

It's not a very complicated function. Why not just modify it to your
needs? 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Mon Aug  8 09:27:51 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 Aug 2005 09:27:51 +0200
Subject: [R] chisq.test
In-Reply-To: <027701c59be3$abec78d0$45576f89@Tablet>
References: <027701c59be3$abec78d0$45576f89@Tablet>
Message-ID: <x2k6iwq45k.fsf@turmalin.kubism.ku.dk>

"Stephen Choularton" <mail at bymouth.com> writes:

> Hi
>  
> I am trying to use this function.  Can anyone show me how I would input
> the following example?
>  
> Chi-Squared = (40-30)^2 + (20-30)^2 + (30-30)^2
>                            30           30             30
>  
> = 3.333 + 3.333 + 0 = 6.666 (p value = 0.036)

> chisq.test(c(40,30,20))

        Chi-squared test for given probabilities

data:  c(40, 30, 20)
X-squared = 6.6667, df = 2, p-value = 0.03567

>  
> I want to be able to use different denominators so can you show me how I
> can do it to accommodate these rather than assuming they are all the
> same.

 No. You want to test different *hypotheses* about the distribution on
 the three groups. E.g. for 2:1:1 split:

> chisq.test(c(40,30,20),p=c(.5,.25,.25))

        Chi-squared test for given probabilities

data:  c(40, 30, 20)
X-squared = 3.3333, df = 2, p-value = 0.1889
 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From tamir at imp.univie.ac.at  Mon Aug  8 10:11:21 2005
From: tamir at imp.univie.ac.at (Ido M. Tamir)
Date: Mon, 8 Aug 2005 10:11:21 +0200
Subject: [R] Searchable Mailing List Archives Down
Message-ID: <200508081011.21637.tamir@imp.univie.ac.at>

Hi,
I was a user of the searchable Mail Archives which you have
linked from somewhere on your homepage.

http://maths.newcastle.edu.au/~rking/R/

This link is out of order. I know there is a search at GMANE
and MARC, but the results were not that nice.

Is it possible to recreate this searchable archive somewhere?
I think it used google.

Thank you very much
Ido Tamir



From guido.parravergara at jcu.edu.au  Mon Aug  8 10:28:34 2005
From: guido.parravergara at jcu.edu.au (Guido Parra Vergara)
Date: Mon, 08 Aug 2005 18:28:34 +1000
Subject: [R] extract t-values from pairwise.t.test
In-Reply-To: <x2oe88q4ia.fsf@turmalin.kubism.ku.dk>
References: <6.2.3.4.0.20050808162248.01d22890@pop.jcu.edu.au>
	<x2oe88q4ia.fsf@turmalin.kubism.ku.dk>
Message-ID: <6.2.3.4.0.20050808181336.01cff528@pop.jcu.edu.au>

Hi,

I am not familiar with changing R functions. I 
can see in the code that t-values get calculated 
as t. val, however when I modified the code to 
include t.val under ans and then run the modified 
function I get  Object "t.val" not found. How do 
I properly modify the function to list t. val in the output?

Thanks
Guido



At 05:20 PM 8/08/2005, Peter Dalgaard wrote:
>Guido Parra Vergara <guido.parravergara at jcu.edu.au> writes:
>
> > Hi,
> >
> > how can I extract the t-values after running a pairwise.t.test? The
> > output just list the p-values.
> > Many thanks for your help.
>
>It's not a very complicated function. Why not just modify it to your
>needs?
>
>--
>    O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
>~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907

____________________________________

Guido J. Parra
School of Tropical Environment Studies and Geography
James Cook University
Townsville
Queensland 4811

Phone:  61 7 47815824
Fax:            61 7 47814020
Mobile: 0437630843
e-mail:         guido.parravergara at jcu.edu.au



From prokopow at wiwi.uni-frankfurt.de  Mon Aug  8 10:33:39 2005
From: prokopow at wiwi.uni-frankfurt.de (Agnieszka Prokopowicz)
Date: Mon, 8 Aug 2005 10:33:39 +0200
Subject: [R] nested logit with latent classes
Message-ID: <001301c59bf3$e09cae50$204b028d@aga>

Hi Everybody, 

I am interested in estimating nested logit with latent classes at the
lower level. 

I have seen the codes for conditional logit and latent class analysis
but I haven?t found anything about nested logit all the more nested
logit with latent classes. 

Could you help me with appropriate coding?

Thanks for your help

Best regards, 

Agnieszka Prokopowicz


********************************************
M.Sc.??Agnieszka Prokopowicz
Department of Electronic Commerce
Goethe-University
Mertonstrasse 17
60054 Frankfurt/Main
Germany 
Phone:?????? ++49 69 798 28862
Fax:???????????? ++49 69 798 28973
Email:???????? prokopow at wiwi.uni-frankfurt.de
********************************************
??



From fdu.xiaojf at gamil.com  Mon Aug  8 10:56:59 2005
From: fdu.xiaojf at gamil.com (Xiao Jianfeng)
Date: Mon, 08 Aug 2005 16:56:59 +0800
Subject: [R] installing problems about randomForest
Message-ID: <42F71E5B.7080307@gamil.com>

Hi all,

When I tried to install package randomForest, it gave out the following 
error message:
"
 > install.packages("randomForest", dependencies = TRUE)
trying URL 
'http://www.lmbe.seu.edu.cn/CRAN/src/contrib/randomForest_4.5-12.tar.gz'
Content type 'application/x-gzip' length 82217 bytes
opened URL
==================================================
downloaded 80Kb

Cannot create directory "": No such file or directory
* Installing *source* package 'randomForest' ...
** libs
gcc -I/user_data2/jfxiao/local/lib/R/include  
-I/usr/freeware/include     -g -O2 -c classTree.c -o classTree.o
gcc -I/user_data2/jfxiao/local/lib/R/include  
-I/usr/freeware/include     -g -O2 -c regTree.c -o regTree.o
gcc -I/user_data2/jfxiao/local/lib/R/include  
-I/usr/freeware/include     -g -O2 -c regrf.c -o regrf.o
gcc -I/user_data2/jfxiao/local/lib/R/include  
-I/usr/freeware/include     -g -O2 -c rf.c -o rf.o
f77 -OPT:IEEE_NaN_inf=ON    -O2 -c rfsub.f -o rfsub.o
"rfsub.f", line 90: error(2346): expression must have logical or integer 
type
              if (decsplit < 0.0) decsplit = 0.0                         
                  ^

"rfsub.f", line 90: error(2051): expected a ")"
              if (decsplit < 0.0) decsplit = 0.0                         
                           ^

2 errors detected in the compilation of "rfsub.f".
gmake: *** [rfsub.o] Error 2
ERROR: compilation failed for package 'randomForest'
"
Can somebody help me ?

Thanks in advance.

Xiao Jianfeng



From ligges at statistik.uni-dortmund.de  Mon Aug  8 11:06:23 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 08 Aug 2005 11:06:23 +0200
Subject: [R] installing problems about randomForest
In-Reply-To: <42F71E5B.7080307@gamil.com>
References: <42F71E5B.7080307@gamil.com>
Message-ID: <42F7208F.5010204@statistik.uni-dortmund.de>

Xiao Jianfeng wrote:

> Hi all,
> 
> When I tried to install package randomForest, it gave out the following 
> error message:
> "
>  > install.packages("randomForest", dependencies = TRUE)
> trying URL 
> 'http://www.lmbe.seu.edu.cn/CRAN/src/contrib/randomForest_4.5-12.tar.gz'
> Content type 'application/x-gzip' length 82217 bytes
> opened URL
> ==================================================
> downloaded 80Kb
> 
> Cannot create directory "": No such file or directory
> * Installing *source* package 'randomForest' ...
> ** libs
> gcc -I/user_data2/jfxiao/local/lib/R/include  
> -I/usr/freeware/include     -g -O2 -c classTree.c -o classTree.o
> gcc -I/user_data2/jfxiao/local/lib/R/include  
> -I/usr/freeware/include     -g -O2 -c regTree.c -o regTree.o
> gcc -I/user_data2/jfxiao/local/lib/R/include  
> -I/usr/freeware/include     -g -O2 -c regrf.c -o regrf.o
> gcc -I/user_data2/jfxiao/local/lib/R/include  
> -I/usr/freeware/include     -g -O2 -c rf.c -o rf.o
> f77 -OPT:IEEE_NaN_inf=ON    -O2 -c rfsub.f -o rfsub.o
> "rfsub.f", line 90: error(2346): expression must have logical or integer 
> type
>              if (decsplit < 0.0) decsplit = 0.0                         
>                  ^
> 
> "rfsub.f", line 90: error(2051): expected a ")"
>              if (decsplit < 0.0) decsplit = 0.0                         
>                           ^
> 
> 2 errors detected in the compilation of "rfsub.f".
> gmake: *** [rfsub.o] Error 2
> ERROR: compilation failed for package 'randomForest'
> "
> Can somebody help me ?


Which OS/platform and compiler are we talking about?

Uwe Ligges



> Thanks in advance.
> 
> Xiao Jianfeng
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From petr.pikal at precheza.cz  Mon Aug  8 12:00:25 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 08 Aug 2005 12:00:25 +0200
Subject: [R] extract t-values from pairwise.t.test
In-Reply-To: <6.2.3.4.0.20050808181336.01cff528@pop.jcu.edu.au>
References: <x2oe88q4ia.fsf@turmalin.kubism.ku.dk>
Message-ID: <42F74959.20102.E14187@localhost>

Hallo

I am not sure but this could be what you want. You has to change 
function compare.levels not only add t.val in ans. If you want t-
values AND p-values together in one table it probably is not so 
simple.

my.pairded.t.test <- function (x, g, p.adjust.method = 
p.adjust.methods, pool.sd = TRUE,
    ...)
{
    DNAME <- paste(deparse(substitute(x)), "and", 
deparse(substitute(g)))
    g <- factor(g)
    p.adjust.method <- match.arg(p.adjust.method)
    if (pool.sd) {
        METHOD <- "t tests with pooled SD"
        xbar <- tapply(x, g, mean, na.rm = TRUE)
        s <- tapply(x, g, sd, na.rm = TRUE)
        n <- tapply(!is.na(x), g, sum)
        degf <- n - 1
        total.degf <- sum(degf)
        pooled.sd <- sqrt(sum(s^2 * degf)/total.degf)
        compare.levels <- function(i, j) {
            dif <- xbar[i] - xbar[j]
            se.dif <- pooled.sd * sqrt(1/n[i] + 1/n[j])
            t.val <- dif/se.dif
            #  2 * pt(-abs(t.val), total.degf) 	this is commented out
            t.val    # this is added
        }
    }
    else {
        METHOD <- "t tests with non-pooled SD"
        compare.levels <- function(i, j) {
            xi <- x[as.integer(g) == i]
            xj <- x[as.integer(g) == j]
            t.test(xi, xj, ...)$statistic     	# this is changed in case 
					          	# pool.sd=F
        }
    }
    PVAL <- pairwise.table(compare.levels, levels(g), 
p.adjust.method)
    ans <- list(method = METHOD, data.name = DNAME, p.value 
= PVAL,
        p.adjust.method = p.adjust.method)
    class(ans) <- "pairwise.htest"
    ans
}

HTH
Petr




On 8 Aug 2005 at 18:28, Guido Parra Vergara wrote:

> Hi,
> 
> I am not familiar with changing R functions. I 
> can see in the code that t-values get calculated 
> as t. val, however when I modified the code to 
> include t.val under ans and then run the modified 
> function I get  Object "t.val" not found. How do 
> I properly modify the function to list t. val in the output?
> 
> Thanks
> Guido
> 
> 
> 
> At 05:20 PM 8/08/2005, Peter Dalgaard wrote:
> >Guido Parra Vergara <guido.parravergara at jcu.edu.au> writes:
> >
> > > Hi,
> > >
> > > how can I extract the t-values after running a pairwise.t.test?
> > > The output just list the p-values. Many thanks for your help.
> >
> >It's not a very complicated function. Why not just modify it to your
> >needs?
> >
> >--
> >    O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
> >   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
> >  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45)
> >  35327918
> >~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45)
> >35327907
> 
> ____________________________________
> 
> Guido J. Parra
> School of Tropical Environment Studies and Geography
> James Cook University
> Townsville
> Queensland 4811
> 
> Phone:  61 7 47815824
> Fax:            61 7 47814020
> Mobile: 0437630843
> e-mail:         guido.parravergara at jcu.edu.au
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From ramasamy at cancer.org.uk  Mon Aug  8 12:08:15 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 08 Aug 2005 11:08:15 +0100
Subject: [R] Searchable Mailing List Archives Down
In-Reply-To: <200508081011.21637.tamir@imp.univie.ac.at>
References: <200508081011.21637.tamir@imp.univie.ac.at>
Message-ID: <1123495695.6009.9.camel@ipc143004.lif.icnet.uk>

The site by Robert King is now working again. I admit that I had
problems accessing it too few times last week. By adding the phrase
"site:https://stat.ethz.ch/pipermail/r-help/" in my google search, I got
something that resembled that output but it did specify from which
archive and month the results came from.

You might also find the search engine by Jonathan Baron 
(http://finzi.psych.upenn.edu/nmz.html) useful and it searched the
documentations and functions as well as mail archives.

Regards, Adai



On Mon, 2005-08-08 at 10:11 +0200, Ido M. Tamir wrote:
> Hi,
> I was a user of the searchable Mail Archives which you have
> linked from somewhere on your homepage.
> 
> http://maths.newcastle.edu.au/~rking/R/
> 
> This link is out of order. I know there is a search at GMANE
> and MARC, but the results were not that nice.
> 
> Is it possible to recreate this searchable archive somewhere?
> I think it used google.
> 
> Thank you very much
> Ido Tamir
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Mon Aug  8 12:10:49 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 8 Aug 2005 11:10:49 +0100 (BST)
Subject: [R] installing problems about randomForest
In-Reply-To: <42F7208F.5010204@statistik.uni-dortmund.de>
References: <42F71E5B.7080307@gamil.com>
	<42F7208F.5010204@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.61.0508081106440.23840@gannet.stats>

On Mon, 8 Aug 2005, Uwe Ligges wrote:

> Xiao Jianfeng wrote:
>
>> Hi all,
>>
>> When I tried to install package randomForest, it gave out the following
>> error message:
>> "
>> > install.packages("randomForest", dependencies = TRUE)
>> trying URL
>> 'http://www.lmbe.seu.edu.cn/CRAN/src/contrib/randomForest_4.5-12.tar.gz'
>> Content type 'application/x-gzip' length 82217 bytes
>> opened URL
>> ==================================================
>> downloaded 80Kb
>>
>> Cannot create directory "": No such file or directory

I have no idea what that is about.

>> * Installing *source* package 'randomForest' ...
>> ** libs
>> gcc -I/user_data2/jfxiao/local/lib/R/include
>> -I/usr/freeware/include     -g -O2 -c classTree.c -o classTree.o
>> gcc -I/user_data2/jfxiao/local/lib/R/include
>> -I/usr/freeware/include     -g -O2 -c regTree.c -o regTree.o
>> gcc -I/user_data2/jfxiao/local/lib/R/include
>> -I/usr/freeware/include     -g -O2 -c regrf.c -o regrf.o
>> gcc -I/user_data2/jfxiao/local/lib/R/include
>> -I/usr/freeware/include     -g -O2 -c rf.c -o rf.o
>> f77 -OPT:IEEE_NaN_inf=ON    -O2 -c rfsub.f -o rfsub.o
>> "rfsub.f", line 90: error(2346): expression must have logical or integer
>> type
>>              if (decsplit < 0.0) decsplit = 0.0
>>                  ^
>>
>> "rfsub.f", line 90: error(2051): expected a ")"
>>              if (decsplit < 0.0) decsplit = 0.0
>>                           ^
>>
>> 2 errors detected in the compilation of "rfsub.f".
>> gmake: *** [rfsub.o] Error 2
>> ERROR: compilation failed for package 'randomForest'
>> "
>> Can somebody help me ?
>
>
> Which OS/platform and compiler are we talking about?

>From his multitudinous recent postings, a peculiar IRIX setup.

However, that line is not valid Fortran: replace < by .LT.
Please note the posting guide asks you to discuss problems in packages 
with the maintainer (and to state your platform and R version).


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From snvk4u at gmail.com  Mon Aug  8 12:20:30 2005
From: snvk4u at gmail.com (Krishna)
Date: Mon, 8 Aug 2005 15:50:30 +0530
Subject: [R] help on regression by subsets in dataset
Message-ID: <139ef1c205080803201bc2f96f@mail.gmail.com>

Hi Everyone

May I request for a small help while performing the regression analysis.

I would like to know is there any possibility of conducting the
regression for different data subsets (in the same data file),
classified on the basis of "grouping variable". The alternative for
this is running the regression for n number of times which you all
know is quite cumbersome.

Thank you for your kind attention and help

rgds

krishna



From Allan at STATS.uct.ac.za  Mon Aug  8 12:30:44 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Mon, 08 Aug 2005 12:30:44 +0200
Subject: [R] R: cbind
Message-ID: <42F73454.49841D8A@STATS.uct.ac.za>

hi all


are we able to combine column vectors of different lengths such that the
result appears in matrix form?

e.g.

a=1
b=1:3
d=1:4

then

z=CBIND(a,b,d)


1 1 1
  2 2
  3 3
    4

i stil want the following!
z[,1]=1
z[,2]=1:3
z[,3]=1:5

i made up the name of this function. we could use "cbind" but it does
not seem to allows this!

thanking you in advance.

/
allan

From Allan at STATS.uct.ac.za  Mon Aug  8 12:34:10 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Mon, 08 Aug 2005 12:34:10 +0200
Subject: [R] R: matrix sizes
Message-ID: <42F73522.586A8883@STATS.uct.ac.za>

hi all

assume that one is doing a simulation. in each iteration one produces a
vector of results. this vectors length might change for each different
iteration. how can one construct a matrix that contains all of the
interation results in a matrix where each of the columns are the outputs
from the different interations.

how would have to define the output matrix initally?

/
thanking you in advance

From ligges at statistik.uni-dortmund.de  Mon Aug  8 12:51:18 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 08 Aug 2005 12:51:18 +0200
Subject: [R] R: matrix sizes
In-Reply-To: <42F73522.586A8883@STATS.uct.ac.za>
References: <42F73522.586A8883@STATS.uct.ac.za>
Message-ID: <42F73926.800@statistik.uni-dortmund.de>

Clark Allan wrote:

> hi all
> 
> assume that one is doing a simulation. in each iteration one produces a
> vector of results. this vectors length might change for each different
> iteration. how can one construct a matrix that contains all of the
> interation results in a matrix where each of the columns are the outputs
> from the different interations.
> 
> how would have to define the output matrix initally?

Of course, you define it to the maximal_length x number_iterations, but 
in fact you probably want a list rather than a matrix.

Uwe Ligges



> /
> thanking you in advance
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ligges at statistik.uni-dortmund.de  Mon Aug  8 12:55:19 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 08 Aug 2005 12:55:19 +0200
Subject: [R] R: cbind
In-Reply-To: <42F73454.49841D8A@STATS.uct.ac.za>
References: <42F73454.49841D8A@STATS.uct.ac.za>
Message-ID: <42F73A17.3040704@statistik.uni-dortmund.de>

Clark Allan wrote:

> hi all
> 
> 
> are we able to combine column vectors of different lengths such that the
> result appears in matrix form?
> 
> e.g.
> 
> a=1
> b=1:3
> d=1:4
> 
> then
> 
> z=CBIND(a,b,d)
> 
> 
> 1 1 1
>   2 2
>   3 3
>     4
> 
> i stil want the following!
> z[,1]=1
> z[,2]=1:3
> z[,3]=1:5
> 
> i made up the name of this function. we could use "cbind" but it does
> not seem to allows this!

See my other message: You probably want a list.

If not, the sparce matrix classes provided by package Matrix might be 
worth considering.

Uwe Ligges



> thanking you in advance.
> 
> /
> allan
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sundar.dorai-raj at pdf.com  Mon Aug  8 13:13:16 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 08 Aug 2005 06:13:16 -0500
Subject: [R] R: cbind
In-Reply-To: <42F73454.49841D8A@STATS.uct.ac.za>
References: <42F73454.49841D8A@STATS.uct.ac.za>
Message-ID: <42F73E4C.5010805@pdf.com>



Clark Allan wrote:
> hi all
> 
> 
> are we able to combine column vectors of different lengths such that the
> result appears in matrix form?
> 
> e.g.
> 
> a=1
> b=1:3
> d=1:4
> 
> then
> 
> z=CBIND(a,b,d)
> 
> 
> 1 1 1
>   2 2
>   3 3
>     4
> 
> i stil want the following!
> z[,1]=1
> z[,2]=1:3
> z[,3]=1:5
> 
> i made up the name of this function. we could use "cbind" but it does
> not seem to allows this!
> 
> thanking you in advance.
> 
> /
> allan

Hi, Allan,

How about the following:

cbind.all <- function(..., fill.with = NA) {
   args <- list(...)
   len <- sapply(args, NROW)
   if(diff(rng <- range(len)) > 0) {
     maxlen <- rng[2]
     pad <- function(x, n) c(x, rep(fill.with, n))
     for(j in seq(along = args)) {
       if(maxlen == len[j]) next
       if(is.data.frame(args[[j]])) {
         args[[j]] <- lapply(args[[j]], pad, maxlen - len[j])
         args[[j]] <- as.data.frame(args[[j]])
       } else if(is.matrix(args[[j]])) {
         args[[j]] <- apply(args[[j]], 2, pad, maxlen - len[j])
       } else if(is.vector(args[[j]])) {
         args[[j]] <- pad(args[[j]], maxlen - len[j])
       } else {
         stop("... must only contain data.frames or arrays.")
       }
     }
   }
   do.call("cbind", args)
}

cbind.all(data.frame(a=1),
           data.frame(a=c(2,1)),
           x = 1, y = matrix(1:4,2,2))

cbind.all(a = 1, b = 1:3, d = 1:4)

HTH,

--sundar



From dargosch at gmail.com  Mon Aug  8 13:26:38 2005
From: dargosch at gmail.com (Fredrik Karlsson)
Date: Mon, 8 Aug 2005 13:26:38 +0200
Subject: [R] Groups in histograms?
Message-ID: <376e97ec05080804263ea2b05d@mail.gmail.com>

Dear list,

I would like to create histograms for up to three groups, with
distincive colour/pattern, in a trellis panel. However, I have not
been able to find a way to do this. histogram does not seem to have a
group argument.

Please help.

/Fredrik



From ggrothendieck at gmail.com  Mon Aug  8 13:36:33 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 8 Aug 2005 07:36:33 -0400
Subject: [R] R: cbind
In-Reply-To: <42F73454.49841D8A@STATS.uct.ac.za>
References: <42F73454.49841D8A@STATS.uct.ac.za>
Message-ID: <971536df05080804361ad255c6@mail.gmail.com>

On 8/8/05, Clark Allan <Allan at stats.uct.ac.za> wrote:
> hi all
> 
> 
> are we able to combine column vectors of different lengths such that the
> result appears in matrix form?
> 
> e.g.
> 
> a=1
> b=1:3
> d=1:4
> 
> then
> 
> z=CBIND(a,b,d)
> 
> 
> 1 1 1
>  2 2
>  3 3
>    4
> 
> i stil want the following!
> z[,1]=1
> z[,2]=1:3
> z[,3]=1:5
> 
> i made up the name of this function. we could use "cbind" but it does
> not seem to allows this!

There are a number of alternatives:

# 1. just create a list

x1 <- list(a = 1, b = 1:3, c = 1:4)

# 2. create a ts object:

x2 <- do.call("cbind", lapply(x1, ts))

# 3. create a matrix from the ts object 

x3 <-  unclass(do.call("cbind", lapply(d, ts)))
tsp(x3) <- NULL



From ggrothendieck at gmail.com  Mon Aug  8 13:41:53 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 8 Aug 2005 07:41:53 -0400
Subject: [R] R: cbind
In-Reply-To: <971536df05080804361ad255c6@mail.gmail.com>
References: <42F73454.49841D8A@STATS.uct.ac.za>
	<971536df05080804361ad255c6@mail.gmail.com>
Message-ID: <971536df050808044175bc38cc@mail.gmail.com>

On 8/8/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> On 8/8/05, Clark Allan <Allan at stats.uct.ac.za> wrote:
> > hi all
> >
> >
> > are we able to combine column vectors of different lengths such that the
> > result appears in matrix form?
> >
> > e.g.
> >
> > a=1
> > b=1:3
> > d=1:4
> >
> > then
> >
> > z=CBIND(a,b,d)
> >
> >
> > 1 1 1
> >  2 2
> >  3 3
> >    4
> >
> > i stil want the following!
> > z[,1]=1
> > z[,2]=1:3
> > z[,3]=1:5
> >
> > i made up the name of this function. we could use "cbind" but it does
> > not seem to allows this!
> 
> There are a number of alternatives:
> 
> # 1. just create a list
> 
> x1 <- list(a = 1, b = 1:3, c = 1:4)
> 
> # 2. create a ts object:
> 
> x2 <- do.call("cbind", lapply(x1, ts))
> 
> # 3. create a matrix from the ts object
> 
> x3 <-  unclass(do.call("cbind", lapply(d, ts)))
> tsp(x3) <- NULL
> 

That last one should have been:

x3 <- unclass(x2)
tsp(x3) <- NULL



From dimitris.rizopoulos at med.kuleuven.be  Mon Aug  8 13:51:43 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Mon, 8 Aug 2005 13:51:43 +0200
Subject: [R] help on regression by subsets in dataset
References: <139ef1c205080803201bc2f96f@mail.gmail.com>
Message-ID: <008c01c59c0f$8c1efa10$0540210a@www.domain>

you could use function lmList() from the nlme package, i.e.,

dat <- data.frame(y = rnorm(120), x = runif(120, -3, 3), g = rep(1:3, 
each = 40))
############
library(nlme)
m <- lmList(y ~ x | g, data = dat)
m
summary(m)

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Krishna" <snvk4u at gmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, August 08, 2005 12:20 PM
Subject: [R] help on regression by subsets in dataset


> Hi Everyone
>
> May I request for a small help while performing the regression 
> analysis.
>
> I would like to know is there any possibility of conducting the
> regression for different data subsets (in the same data file),
> classified on the basis of "grouping variable". The alternative for
> this is running the regression for n number of times which you all
> know is quite cumbersome.
>
> Thank you for your kind attention and help
>
> rgds
>
> krishna
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Mon Aug  8 14:05:08 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 8 Aug 2005 08:05:08 -0400
Subject: [R] help on regression by subsets in dataset
In-Reply-To: <139ef1c205080803201bc2f96f@mail.gmail.com>
References: <139ef1c205080803201bc2f96f@mail.gmail.com>
Message-ID: <971536df05080805057802131f@mail.gmail.com>

On 8/8/05, Krishna <snvk4u at gmail.com> wrote:
> Hi Everyone
> 
> May I request for a small help while performing the regression analysis.
> 
> I would like to know is there any possibility of conducting the
> regression for different data subsets (in the same data file),
> classified on the basis of "grouping variable". The alternative for
> this is running the regression for n number of times which you all
> know is quite cumbersome.


This defines a model which has a separate intercept and slope for
each value of the grouping variable g:

> # sample data
> x <- 1:12
> g <- gl(4,3)
> g
 [1] 1 1 1 2 2 2 3 3 3 4 4 4
Levels: 1 2 3 4
> set.seed(1)
> y <- rnorm(12)

> # now define the model and run the regression
> lm(y ~ g/x - 1)

Call:
lm(formula = y ~ g/x - 1)

Coefficients:
      g1        g2        g3        g4      g1:x      g2:x      g3:x      g4:x  
-0.21697   6.40748   0.24710  -3.29170  -0.10459  -1.20787   0.04418   0.34762



From dargosch at gmail.com  Mon Aug  8 14:06:15 2005
From: dargosch at gmail.com (Fredrik Karlsson)
Date: Mon, 8 Aug 2005 14:06:15 +0200
Subject: [R] Groups in histograms?
In-Reply-To: <dd6040c905080804377c7da379@mail.gmail.com>
References: <376e97ec05080804263ea2b05d@mail.gmail.com>
	<dd6040c905080804377c7da379@mail.gmail.com>
Message-ID: <376e97ec05080805066022332f@mail.gmail.com>

Hi Gary,

I have found this, but it is not exactly what I am looking for. 
What I need is the groups to be inside of a single panel, not in
different panels.
Kind of like an histogram version of the xyplot(Y ~ X1,
groups=X2,panel=panel.superpose) command. (I hope this is correct).

/Fredrik

On 8/8/05, Gary Collins <collins.gs at gmail.com> wrote:
> Have a look at the "histogram" function in the Lattice package.
> 
> if x are your data to be displayed and y is your grouping variable you
> can just do
> 
> > histogram(~x|y)
> 
> HTH
> Gary
> 
> On 08/08/05, Fredrik Karlsson <dargosch at gmail.com> wrote:
> > Dear list,
> >
> > I would like to create histograms for up to three groups, with
> > distincive colour/pattern, in a trellis panel. However, I have not
> > been able to find a way to do this. histogram does not seem to have a
> > group argument.
> >
> > Please help.
> >
> > /Fredrik
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 


-- 
My Gentoo + PVR-350 + IVTV + MythTV blog is on  
http://gentoomythtv.blogspot.com/



From fdu.xiaojf at gamil.com  Mon Aug  8 14:09:22 2005
From: fdu.xiaojf at gamil.com (Xiao Jianfeng)
Date: Mon, 08 Aug 2005 20:09:22 +0800
Subject: [R] installing problems about randomForest
In-Reply-To: <Pine.LNX.4.61.0508081106440.23840@gannet.stats>
References: <42F71E5B.7080307@gamil.com>	<42F7208F.5010204@statistik.uni-dortmund.de>
	<Pine.LNX.4.61.0508081106440.23840@gannet.stats>
Message-ID: <42F74B72.7030208@gamil.com>

Prof Brian Ripley wrote:

>On Mon, 8 Aug 2005, Uwe Ligges wrote:
>
>  
>
>>Xiao Jianfeng wrote:
>>
>>    
>>
>>>Hi all,
>>>
>>>When I tried to install package randomForest, it gave out the following
>>>error message:
>>>"
>>>      
>>>
>>>>install.packages("randomForest", dependencies = TRUE)
>>>>        
>>>>
>>>trying URL
>>>'http://www.lmbe.seu.edu.cn/CRAN/src/contrib/randomForest_4.5-12.tar.gz'
>>>Content type 'application/x-gzip' length 82217 bytes
>>>opened URL
>>>==================================================
>>>downloaded 80Kb
>>>
>>>Cannot create directory "": No such file or directory
>>>      
>>>
>
>I have no idea what that is about.
>  
>
  In my .cshrc, I set "R_LIBS" like this:
  ' setenv R_LIBS="$HOME/local/lib/R/library" ', is it OK?

>  
>
>>>* Installing *source* package 'randomForest' ...
>>>** libs
>>>gcc -I/user_data2/jfxiao/local/lib/R/include
>>>-I/usr/freeware/include     -g -O2 -c classTree.c -o classTree.o
>>>gcc -I/user_data2/jfxiao/local/lib/R/include
>>>-I/usr/freeware/include     -g -O2 -c regTree.c -o regTree.o
>>>gcc -I/user_data2/jfxiao/local/lib/R/include
>>>-I/usr/freeware/include     -g -O2 -c regrf.c -o regrf.o
>>>gcc -I/user_data2/jfxiao/local/lib/R/include
>>>-I/usr/freeware/include     -g -O2 -c rf.c -o rf.o
>>>f77 -OPT:IEEE_NaN_inf=ON    -O2 -c rfsub.f -o rfsub.o
>>>"rfsub.f", line 90: error(2346): expression must have logical or integer
>>>type
>>>             if (decsplit < 0.0) decsplit = 0.0
>>>                 ^
>>>
>>>"rfsub.f", line 90: error(2051): expected a ")"
>>>             if (decsplit < 0.0) decsplit = 0.0
>>>                          ^
>>>
>>>2 errors detected in the compilation of "rfsub.f".
>>>gmake: *** [rfsub.o] Error 2
>>>ERROR: compilation failed for package 'randomForest'
>>>"
>>>Can somebody help me ?
>>>      
>>>
>>Which OS/platform and compiler are we talking about?
>>    
>>
   SGI IRIX 6.5, gcc 3.3, and f77 shiped with IRIX

>
>>From his multitudinous recent postings, a peculiar IRIX setup.
>
>However, that line is not valid Fortran: replace < by .LT.
>Please note the posting guide asks you to discuss problems in packages 
>with the maintainer (and to state your platform and R version).
>  
>
  Thanks, I will try to contact the maintainer.



From alxmilton at yahoo.it  Mon Aug  8 14:34:52 2005
From: alxmilton at yahoo.it (alessandro carletti)
Date: Mon, 8 Aug 2005 05:34:52 -0700 (PDT)
Subject: [R] selecting outliers
Message-ID: <20050808123452.14782.qmail@web26610.mail.ukl.yahoo.com>

Hi everybody,
I'd like to know if there's an easy way for extracting
outliers record from a dataset, in order to perform
further analysis on them.
Thanks

Alessandro



From David.Duffy at qimr.edu.au  Mon Aug  8 14:30:55 2005
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Mon, 8 Aug 2005 22:30:55 +1000 (EST)
Subject: [R] linkage disequilibrium
In-Reply-To: <mailman.9.1123236007.13094.r-help@stat.math.ethz.ch>
References: <mailman.9.1123236007.13094.r-help@stat.math.ethz.ch>
Message-ID: <Pine.LNX.4.58.0508081631570.16880@orpheus.qimr.edu.au>

> Date: Thu,  4 Aug 2005 19:36:35 +0200
> From: Cristian <cristian at biometria.univr.it>
> Subject: [R] linkage disequilibrium
> To: r-help at stat.math.ethz.ch
> Message-ID: <1123176995.42f252238a47a at biometria.univr.it>
> Content-Type: text/plain; charset=ISO-8859-1
>
> I'm using the package "Genetics", and I'm interested in the computation of D'
> statistics for Linkage Disequilibrium, for which the LD() command has been
> realised. Unfortunately I don't find any reference on "how" the D' is computed
> by the LD() function. In the package documentation it is generally referred as
> "MLE" estimation, but references are not provided. Does anybody knows how it is
> obtained or, at least, some references?
>
> Are there any other R package performing the D' computation both for phased and
> unphased genotype?
>
> Thanks!  Cristian
>

You need to look at the code:
getAnywhere("LD.genotype")

See any standard reference such as Bruce Weir's _Genetic Data Analysis_
(Sinauer Associates) or Pak Sham's book on statistical genetics for the
background to the algorithm.

The chi-square testing D=0 from LD() is twice what it should be, and you
may be confused (I know I was) by the fact that the marginal allele
frequencies are estimated using non-missing data for each locus in turn.
This means the bounds (pmin and pmax) for the AB haplotype frequency are
different from that in the actual table used to maximize the likelihood.
So, you will get different answers from programs using jointly
complete observations only.

Several other packages for haplotype analysis are on CRAN.  Package
haplo.stats has the haplo.em() function to give the MLEs for the haplotype
frequencies.  From these you can easily calculate D etc.  Package hwde
estimates nonstandard disequilibrium coefficients in a loglinear
framework, and can be used to compare different sample disequilibria.
Note that haplo.stats and hapassoc are aimed specifically at comparing
groups or testing for association to other traits. My package
gllm is not as easy to use but can combine phased and unphased data in
loglinear models -- you could probably use cat in the same way.

David Duffy.

| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v



From chrish at stats.ucl.ac.uk  Mon Aug  8 14:45:25 2005
From: chrish at stats.ucl.ac.uk (Christian Hennig)
Date: Mon, 8 Aug 2005 13:45:25 +0100 (BST)
Subject: [R] selecting outliers
In-Reply-To: <20050808123452.14782.qmail@web26610.mail.ukl.yahoo.com>
References: <20050808123452.14782.qmail@web26610.mail.ukl.yahoo.com>
Message-ID: <Pine.LNX.4.58.0508081340080.14535@egon.stats.ucl.ac.uk>

Hi Alessandro,

On Mon, 8 Aug 2005, alessandro carletti wrote:

> Hi everybody,
> I'd like to know if there's an easy way for extracting
> outliers record from a dataset, in order to perform
> further analysis on them.

The answer is "no". The reasons are not technical. There are some quite
easy outlier detection approaches around (e.g., compute robust Mahalanobis
distances with cov.mcd/mahalanobis and call the points with too large
distances "outliers").
But the main problem is that the term outlier has no objective, unique
meaning. It depends crucially on your aims and on the assumptions you want
to make about the non-outliers in the dataset (which should be
elliptically distributed and homogeneously close to a multivariate
normal distribution for the Mahalanobis approach).

Best,
Christian

*** NEW ADDRESS! ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche



From Soren.Hojsgaard at agrsci.dk  Mon Aug  8 14:59:35 2005
From: Soren.Hojsgaard at agrsci.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Mon, 8 Aug 2005 14:59:35 +0200
Subject: [R] selecting outliers
Message-ID: <C83C5E3DEEE97E498B74729A33F6EAEC0308412C@DJFPOST01.djf.agrsci.dk>

Perhaps what Alessandro is after is simpler than that: Making a plot of data in a data frame, being able to click on 'suspicious points', getting the corresponding rows of a data out in a new data frame (for further inspection) while keeping the 'good points' in the plot (and perhaps redoing some calculations on the basis of the good points only....). This could then go on in an iterative way. That would be a perfectly sensible thing to do. How difficult it is technically I don't know, but it seems that it would require a call-back mechanism from a plot window to R (and a more 'advanced' one than provided by 'locator()').

Best regards
S??ren

-----Oprindelig meddelelse-----
Fra: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] P?? vegne af Christian Hennig
Sendt: 8. august 2005 14:45
Til: alessandro carletti
Cc: rHELP
Emne: Re: [R] selecting outliers

Hi Alessandro,

On Mon, 8 Aug 2005, alessandro carletti wrote:

> Hi everybody,
> I'd like to know if there's an easy way for extracting outliers record 
> from a dataset, in order to perform further analysis on them.

The answer is "no". The reasons are not technical. There are some quite easy outlier detection approaches around (e.g., compute robust Mahalanobis distances with cov.mcd/mahalanobis and call the points with too large distances "outliers").
But the main problem is that the term outlier has no objective, unique meaning. It depends crucially on your aims and on the assumptions you want to make about the non-outliers in the dataset (which should be elliptically distributed and homogeneously close to a multivariate normal distribution for the Mahalanobis approach).

Best,
Christian

*** NEW ADDRESS! ***
Christian Hennig
University College London, Department of Statistical Science Gower St., London WC1E 6BT, phone +44 207 679 1698 chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From chrish at stats.ucl.ac.uk  Mon Aug  8 15:11:19 2005
From: chrish at stats.ucl.ac.uk (Christian Hennig)
Date: Mon, 8 Aug 2005 14:11:19 +0100 (BST)
Subject: [R] selecting outliers
In-Reply-To: <C83C5E3DEEE97E498B74729A33F6EAEC0308412C@DJFPOST01.djf.agrsci.dk>
References: <C83C5E3DEEE97E498B74729A33F6EAEC0308412C@DJFPOST01.djf.agrsci.dk>
Message-ID: <Pine.LNX.4.58.0508081409081.14535@egon.stats.ucl.ac.uk>

Hi,

if Soren is right, why not take a look on the identify help page?

Christian

On Mon, 8 Aug 2005, S??ren H??jsgaard wrote:

> Perhaps what Alessandro is after is simpler than that: Making a plot of data in a data frame, being able to click on 'suspicious points', getting the corresponding rows of a data out in a new data frame (for further inspection) while keeping the 'good points' in the plot (and perhaps redoing some calculations on the basis of the good points only....). This could then go on in an iterative way. That would be a perfectly sensible thing to do. How difficult it is technically I don't know, but it seems that it would require a call-back mechanism from a plot window to R (and a more 'advanced' one than provided by 'locator()').
>
> Best regards
> S??ren
>
> -----Oprindelig meddelelse-----
> Fra: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] P?? vegne af Christian Hennig
> Sendt: 8. august 2005 14:45
> Til: alessandro carletti
> Cc: rHELP
> Emne: Re: [R] selecting outliers
>
> Hi Alessandro,
>
> On Mon, 8 Aug 2005, alessandro carletti wrote:
>
> > Hi everybody,
> > I'd like to know if there's an easy way for extracting outliers record
> > from a dataset, in order to perform further analysis on them.
>
> The answer is "no". The reasons are not technical. There are some quite easy outlier detection approaches around (e.g., compute robust Mahalanobis distances with cov.mcd/mahalanobis and call the points with too large distances "outliers").
> But the main problem is that the term outlier has no objective, unique meaning. It depends crucially on your aims and on the assumptions you want to make about the non-outliers in the dataset (which should be elliptically distributed and homogeneously close to a multivariate normal distribution for the Mahalanobis approach).
>
> Best,
> Christian
>
> *** NEW ADDRESS! ***
> Christian Hennig
> University College London, Department of Statistical Science Gower St., London WC1E 6BT, phone +44 207 679 1698 chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

*** NEW ADDRESS! ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche



From peterwyang at gmail.com  Mon Aug  8 15:11:47 2005
From: peterwyang at gmail.com (Peter Yang)
Date: Mon, 8 Aug 2005 09:11:47 -0400
Subject: [R] coefficient of polynomial expansion
Message-ID: <a922041d05080806111ac4e7f7@mail.gmail.com>

Hi,

I would like to get the coefficient of polynomial expansion. For example,

(1+ x)^2 = 1 + 2x + x^2, and the coefficients are 1, 2 and 1.
(1 + x + x^2)^3 = 1 + 3*x + 6*x^2 + 7*x^3 + 6*x^4 + 3*x^5 + x^6, and
the coefficients are 1, 3, 6, 7, 6, 3, and 1.

I know that we can use polynom library. Is there any other way to do
it without loading a library.

Thanks a lot for your help.


Peter



From andy_liaw at merck.com  Mon Aug  8 15:11:14 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 8 Aug 2005 09:11:14 -0400
Subject: [R] installing problems about randomForest
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EB80@usctmx1106.Merck.com>

> From: Prof Brian Ripley
> 
> On Mon, 8 Aug 2005, Uwe Ligges wrote:
> 
> > Xiao Jianfeng wrote:
> >
> >> Hi all,
> >>
> >> When I tried to install package randomForest, it gave out 
> the following
> >> error message:
> >> "
> >> > install.packages("randomForest", dependencies = TRUE)
> >> trying URL
> >> 
> 'http://www.lmbe.seu.edu.cn/CRAN/src/contrib/randomForest_4.5-
> 12.tar.gz'
> >> Content type 'application/x-gzip' length 82217 bytes
> >> opened URL
> >> ==================================================
> >> downloaded 80Kb
> >>
> >> Cannot create directory "": No such file or directory
> 
> I have no idea what that is about.
> 
> >> * Installing *source* package 'randomForest' ...
> >> ** libs
> >> gcc -I/user_data2/jfxiao/local/lib/R/include
> >> -I/usr/freeware/include     -g -O2 -c classTree.c -o classTree.o
> >> gcc -I/user_data2/jfxiao/local/lib/R/include
> >> -I/usr/freeware/include     -g -O2 -c regTree.c -o regTree.o
> >> gcc -I/user_data2/jfxiao/local/lib/R/include
> >> -I/usr/freeware/include     -g -O2 -c regrf.c -o regrf.o
> >> gcc -I/user_data2/jfxiao/local/lib/R/include
> >> -I/usr/freeware/include     -g -O2 -c rf.c -o rf.o
> >> f77 -OPT:IEEE_NaN_inf=ON    -O2 -c rfsub.f -o rfsub.o
> >> "rfsub.f", line 90: error(2346): expression must have 
> logical or integer
> >> type
> >>              if (decsplit < 0.0) decsplit = 0.0
> >>                  ^
> >>
> >> "rfsub.f", line 90: error(2051): expected a ")"
> >>              if (decsplit < 0.0) decsplit = 0.0
> >>                           ^
> >>
> >> 2 errors detected in the compilation of "rfsub.f".
> >> gmake: *** [rfsub.o] Error 2
> >> ERROR: compilation failed for package 'randomForest'
> >> "
> >> Can somebody help me ?
> >
> >
> > Which OS/platform and compiler are we talking about?
> 
> >From his multitudinous recent postings, a peculiar IRIX setup.
> 
> However, that line is not valid Fortran: replace < by .LT.
> Please note the posting guide asks you to discuss problems in 
> packages 
> with the maintainer (and to state your platform and R version).

Thanks for catching that!  It must have slipped when I was going back and
forth between C and Fortran...

Update should appear on CRAN this week, I hope.

Best,
Andy

 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From Nathan.Weisz at uni-konstanz.de  Mon Aug  8 15:45:06 2005
From: Nathan.Weisz at uni-konstanz.de (Nathan Weisz)
Date: Mon, 8 Aug 2005 15:45:06 +0200
Subject: [R] xyplot with 2 y-axes
Message-ID: <C99212E6-D5D6-431A-B698-C7F71AD979F3@uni-konstanz.de>

Dear R-helpers,

I'm trying to get xyplot to plot 2 y-axes. I looked at the examples  
and googled around. This is how far I got so far.

test<-data.frame(a=rnorm(100),b=rnorm(100)*10,ind=rep(1:10,10),con=rep 
(1:10,rep(10,10)))
xyplot(a+b~con|ind,data=test,allow.multiple=T)

This however puts a+b on one axis. I'd need e.g. a as left and b as  
right axis.

Best wishes,
Nathan
------------------------------
$platform
[1] "powerpc-apple-darwin7.9.0"
$arch
[1] "powerpc"
$os
[1] "darwin7.9.0"
$system
[1] "powerpc, darwin7.9.0"
$status
[1] ""
$major
[1] "2"
$minor
[1] "1.1"
$year
[1] "2005"
$month
[1] "06"
$day
[1] "20"
$language
[1] "R"



From fdu.xiaojf at gmail.com  Mon Aug  8 15:41:24 2005
From: fdu.xiaojf at gmail.com (Xiao Jianfeng)
Date: Mon, 08 Aug 2005 21:41:24 +0800
Subject: [R] installing problems about randomForest
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EB80@usctmx1106.Merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EB80@usctmx1106.Merck.com>
Message-ID: <42F76104.3050605@gmail.com>

Liaw, Andy wrote:

>Thanks for catching that!  It must have slipped when I was going back and
>forth between C and Fortran...
>
>Update should appear on CRAN this week, I hope.
>
>Best,
>Andy
>  
>
 Thanks for your quick replay.

 I just want you to know that I have tried R 2.1.0 on my pc running
 Debian etch. I used 'apt-get r-base' to install R, and 
'install("randomForest",
 dependencies = TRUE)' from within R to install randomForest, but it failed
 again.

 Regards,

 Xiao Jianfeng



From jjmichael at comcast.net  Mon Aug  8 15:45:22 2005
From: jjmichael at comcast.net (Jacob Michaelson)
Date: Mon, 8 Aug 2005 07:45:22 -0600
Subject: [R] heatmap -- invisible list?
Message-ID: <E0A87CEE-3A7D-4AD9-8D77-9A401219BF06@comcast.net>

Hi all,

In heatmap's documentation, it mentions that the output value is  
actually an invisible list...how would one access this list?

Thanks,

Jake



From ggrothendieck at gmail.com  Mon Aug  8 15:51:45 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 8 Aug 2005 09:51:45 -0400
Subject: [R] coefficient of polynomial expansion
In-Reply-To: <a922041d05080806111ac4e7f7@mail.gmail.com>
References: <a922041d05080806111ac4e7f7@mail.gmail.com>
Message-ID: <971536df0508080651639e4dff@mail.gmail.com>

On 8/8/05, Peter Yang <peterwyang at gmail.com> wrote:
> Hi,
> 
> I would like to get the coefficient of polynomial expansion. For example,
> 
> (1+ x)^2 = 1 + 2x + x^2, and the coefficients are 1, 2 and 1.
> (1 + x + x^2)^3 = 1 + 3*x + 6*x^2 + 7*x^3 + 6*x^4 + 3*x^5 + x^6, and
> the coefficients are 1, 3, 6, 7, 6, 3, and 1.
> 

Use symbolic differentiation as in:

https://stat.ethz.ch/pipermail/r-help/2004-December/060797.html



From ramasamy at cancer.org.uk  Mon Aug  8 15:50:07 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 08 Aug 2005 14:50:07 +0100
Subject: [R] R: matrix sizes
In-Reply-To: <42F73522.586A8883@STATS.uct.ac.za>
References: <42F73522.586A8883@STATS.uct.ac.za>
Message-ID: <1123509007.30584.8.camel@ipc143004.lif.icnet.uk>

1) If the output at each iteration gives a fixed number of elements,
then you can pre-define the matrix. For example

   mat <- matrix( NA, nr=6, nc=500 )
   for(i in 1:500 ){ 
      x <- rnorm(13)
      mat[ , i] <- summary(x)
   }

2) If the length of the output varies at each iteration, then it is
probably best to use a list.

   mylist <- list(NULL)
   for(i in 1:500){
       x <- rpois(1, lambda=10) + 1
       y <- rnorm(x)
       my.list[[ i ]] <- y
   }

Regards, Adai



On Mon, 2005-08-08 at 12:34 +0200, Clark Allan wrote:
> hi all
> 
> assume that one is doing a simulation. in each iteration one produces a
> vector of results. this vectors length might change for each different
> iteration. how can one construct a matrix that contains all of the
> interation results in a matrix where each of the columns are the outputs
> from the different interations.
> 
> how would have to define the output matrix initally?
> 
> /
> thanking you in advance
> ______________________________________________ R-help at stat.math.ethz.ch mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From sdavis2 at mail.nih.gov  Mon Aug  8 15:54:29 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 08 Aug 2005 09:54:29 -0400
Subject: [R] heatmap -- invisible list?
In-Reply-To: <E0A87CEE-3A7D-4AD9-8D77-9A401219BF06@comcast.net>
Message-ID: <BF1CDC55.B459%sdavis2@mail.nih.gov>

On 8/8/05 9:45 AM, "Jacob Michaelson" <jjmichael at comcast.net> wrote:

> Hi all,
> 
> In heatmap's documentation, it mentions that the output value is
> actually an invisible list...how would one access this list?


Mylist <- heatmap(....)



From astrzelczak at ps.pl  Mon Aug  8 16:02:58 2005
From: astrzelczak at ps.pl (astrzelczak@ps.pl)
Date: Mon,  8 Aug 2005 16:02:58 +0200
Subject: [R] INDVAL and mvpart
Message-ID: <1123509778.42f76612311cd@www.ps.pl>


Hi,

I'd like to perform Dufrene-Legendre Indicator Species Analysis for
a multivariate regression tree. However I have problems with arguments
of duleg(veg,class,numitr=1000)function. How to obtain  a vector of
numeric class memberships for samples, or a classification object
returned from mvpart?

thanks in advance

--
Best regards,

Agnieszka Strzelczak                          mailto:astrzelczak at ps.pl



From tpapp at Princeton.EDU  Mon Aug  8 16:26:48 2005
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Mon, 8 Aug 2005 16:26:48 +0200
Subject: [R] using <<- with a changing variable name (substitute?)
Message-ID: <20050808142648.GA27795@tpapp.student.princeton.edu>

I have a matrix r and a scalar d, and I would like to apply the
following functions to each of its elements:

1. if r < 0, no change
2. if 0 <= r < d, replace element by zero
3. if d <= r, replace element by r-d

I wrote a small function for this

  m <- function(b) {sapply(b, function(bb) {
    if (bb < 0) {bb} else {if (bb>d) {bb-d} else 0}
  })}
 
so I can simply say r <- m(r).  The problem is that the matrix r is
huge and only one of them fits in the memory, and I don't need the
original r, so I would like to do this memory-efficiently.  Moreover,
there are matrices with various names (not only r) so I need a generic
function (they don't fit in memory at the same time, I load, save and
rm them).

I tried various combinations of <<-, assign, substitute etc. but could
not get it working.  Could somebody please help me?

Tamas



From maechler at stat.math.ethz.ch  Mon Aug  8 16:46:44 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 8 Aug 2005 16:46:44 +0200
Subject: [R] coefficient of polynomial expansion
In-Reply-To: <a922041d05080806111ac4e7f7@mail.gmail.com>
References: <a922041d05080806111ac4e7f7@mail.gmail.com>
Message-ID: <17143.28756.171183.453758@stat.math.ethz.ch>

>>>>> "Peter" == Peter Yang <peterwyang at gmail.com>
>>>>>     on Mon, 8 Aug 2005 09:11:47 -0400 writes:

    Peter> Hi, I would like to get the coefficient of polynomial
    Peter> expansion. For example,

    Peter> (1+ x)^2 = 1 + 2x + x^2, and the coefficients are 1,
    Peter> 2 and 1.  (1 + x + x^2)^3 = 1 + 3*x + 6*x^2 + 7*x^3 +
    Peter> 6*x^4 + 3*x^5 + x^6, and the coefficients are 1, 3,
    Peter> 6, 7, 6, 3, and 1.

    Peter> I know that we can use polynom library. Is there any
    Peter> other way to do it without loading a library.

yes, load the polynom *package*  (from the library where the
		      ---------   *package* is installed)

What's bad about using polynom?  IMO it is very nice, very useful
package for the purpose it was written.

Using packages for tasks they were written is one of the
strengths of the R project, 
so why are you reluctant?

Martin



From ripley at stats.ox.ac.uk  Mon Aug  8 17:07:10 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 8 Aug 2005 16:07:10 +0100 (BST)
Subject: [R] using <<- with a changing variable name (substitute?)
In-Reply-To: <20050808142648.GA27795@tpapp.student.princeton.edu>
References: <20050808142648.GA27795@tpapp.student.princeton.edu>
Message-ID: <Pine.LNX.4.61.0508081556230.11413@gannet.stats>

On Mon, 8 Aug 2005, Tamas K Papp wrote:

> I have a matrix r and a scalar d, and I would like to apply the
> following functions to each of its elements:
>
> 1. if r < 0, no change
> 2. if 0 <= r < d, replace element by zero
> 3. if d <= r, replace element by r-d
>
> I wrote a small function for this
>
>  m <- function(b) {sapply(b, function(bb) {
>    if (bb < 0) {bb} else {if (bb>d) {bb-d} else 0}
>  })}

Why use sapply?

r[] <- ifelse(r >= d, r-d, ifelse(r >= 0, 0, r))

is one more efficient way.

>
> so I can simply say r <- m(r).  The problem is that the matrix r is
> huge and only one of them fits in the memory,

If that is literally true, you cannot do this at R level AFAICS.  The only 
way I can see that you can do this with standard semantics is

m(r) <- d

with a replacement function m<-() written using .Call.  Using

"m<-" <- function(r, d) ifelse(r >= d, r-d, ifelse(r >= 0, 0, r))

is going to make several copies.

> and I don't need the
> original r, so I would like to do this memory-efficiently.  Moreover,
> there are matrices with various names (not only r) so I need a generic
> function (they don't fit in memory at the same time, I load, save and
> rm them).
>
> I tried various combinations of <<-, assign, substitute etc. but could
> not get it working.  Could somebody please help me?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Mon Aug  8 17:17:54 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 8 Aug 2005 17:17:54 +0200
Subject: [R] make error: X11/Intrinsic.h: No such,,,
In-Reply-To: <1123274389.7234.3.camel@localhost.localdomain>
References: <1123273040.29703.27.camel@localhost.localdomain>
	<1123274389.7234.3.camel@localhost.localdomain>
Message-ID: <17143.30626.849917.821534@stat.math.ethz.ch>

>>>>> "Jake" == Jake Michaelson <jjmichael at comcast.net>
>>>>>     on Fri, 05 Aug 2005 14:39:49 -0600 writes:

    Jake> Thanks for the help -- this morning someone (on the
    Jake> Ubuntu boards) was kind enough to point this out to
    Jake> me. Now if there were only a decent Linux front
    Jake> end/gui for R...

is ESS (http://ESS.r-project.org/) indecent to you ?

Martin Maechler, ETH Zurich



From peter at estg.ipvc.pt  Mon Aug  8 17:26:55 2005
From: peter at estg.ipvc.pt (Peter Ho)
Date: Mon, 08 Aug 2005 16:26:55 +0100
Subject: [R] p-values
In-Reply-To: <42F57353.9040304@pdf.com>
References: <42F29071.1000107@fe.up.pt> <42F57353.9040304@pdf.com>
Message-ID: <42F779BF.6090803@estg.ipvc.pt>

Spencer,


Thank you for referring me to your other email on Exact goodness-of-fit 
test. However, I'm not entirely sure if what you mentioned is the same 
for my case. I'm not a statistician and it would help me if you could 
explain what you meant in a little more detail. Perhaps I need to 
explain the problem in more detail.

I am looking for a way to calculate exaxt p-values by Monte Carlo 
Simulation for Durbin's test. Durbin's test statistic is similar to 
Friedman's statistic, but considers the case of Balanced Incomplete 
block designs. I have found a function written by Felipe de Mendiburu 
for calculating Durbin's statistic, which gives the chi-squared p-value. 
I have also been read an article by Torsten Hothorn "On exact rank Tests 
in R" (R News 1(1), 11?12.) and he has shown how to calculate Monte 
Carlo p-values using pperm. In the article by Torsten Hothorn he gives:

R> pperm(W, ranks, length(x))

He compares his method to that of StatXact, which is the program Rayner 
and Best suggested using. Is there a way to do this for example for the 
friedman test.

A paper by Joachim Rohmel discusses "The permutation distribution for 
the friendman test" (Computational Statistics & Data Analysis 1997, 26: 
83-99). This seems to be on the lines of what I need, although I am not 
quite sure. Has anyone tried to recode his APL program for R?

I have tried a number of things, all unsucessful. Searching through 
previous postings have not been very successful either. It seems that 
pperm is the way to go, but I would need help from someone on this.

Any hints on how to continue would be much appreciated.


Peter


Spencer Graves wrote:

>Hi, Peter:
>
>	  Please see my reply of a few minutes ago subject:  exact 
>goodness-of-fit test.  I don't know Rayner and Best, but the same 
>method, I think, should apply.  spencer graves
>
>Peter Ho wrote:
>
>  
>
>>HI R-users,
>>
>>I am trying to repeat an example from Rayner and Best "A contingency 
>>table approach to nonparametric testing (Chapter 7, Ice cream example).
>>
>>In their book they calculate Durbin's statistic, D1, a dispersion 
>>statistics, D2, and a residual. P-values for each statistic is 
>>calculated from a chi-square distribution and also Monte Carlo p-values.
>>
>>I have found similar p-values based on the chi-square distribution by 
>>using:
>>
>> > pchisq(12, df= 6, lower.tail=F)
>>[1] 0.0619688
>> > pchisq(5.1, df= 6, lower.tail=F)
>>[1] 0.5310529
>>
>>Is there a way to calculate the equivalent Monte Carlo p-values?
>>
>>The values were 0.02 and 0.138 respectively.
>>
>>The use of the approximate chi-square probabilities for Durbin's test 
>>are considered not good enough according to Van der Laan (The American 
>>Statistician 1988,42,165-166).
>>
>>
>>Peter
>>--------------------------------
>>ESTG-IPVC
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>    
>>
>
>  
>



From tpapp at Princeton.EDU  Mon Aug  8 17:22:20 2005
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Mon, 8 Aug 2005 17:22:20 +0200
Subject: [R] using <<- with a changing variable name (substitute?)
In-Reply-To: <Pine.LNX.4.61.0508081556230.11413@gannet.stats>
References: <20050808142648.GA27795@tpapp.student.princeton.edu>
	<Pine.LNX.4.61.0508081556230.11413@gannet.stats>
Message-ID: <20050808152220.GA29170@tpapp.student.princeton.edu>

On Mon, Aug 08, 2005 at 04:07:10PM +0100, Prof Brian Ripley wrote:
> On Mon, 8 Aug 2005, Tamas K Papp wrote:
>
> > m <- function(b) {sapply(b, function(bb) {
> >   if (bb < 0) {bb} else {if (bb>d) {bb-d} else 0}
> > })}
> 
> Why use sapply?
> 
> r[] <- ifelse(r >= d, r-d, ifelse(r >= 0, 0, r))
> 
> is one more efficient way.

Thank you very much, this speeded up things considerably.  I need this
operation to ignore the first column of the matrix, is there a more
efficient way than

r[,-1] <- ifelse(r[,-1] >= d, r[,-1]-d, ifelse(r[,-1] >= 0, 0, r[,-1]))

?

Tamas



From alxmilton at yahoo.it  Mon Aug  8 17:34:54 2005
From: alxmilton at yahoo.it (alessandro carletti)
Date: Mon, 8 Aug 2005 08:34:54 -0700 (PDT)
Subject: [R] vector vs array
Message-ID: <20050808153455.22758.qmail@web26601.mail.ukl.yahoo.com>

Hi!
OK, I'm trying to select some "useful outliers" from
my dataset: I defined 11 "treshold" values (1 for each
level of a variable (sampling site) as follows:


tresholds<-function(x)
{
tapply(x,mm$NAME,FUN=mean ,simplify = T, na.rm=T)->med


tapply(x,mm$NAME,FUN=sd ,simplify = T,
na.rm=T)->standev 

standev+med

}
tresholds(mm$chl)


Now I'd like to select those values from vector mm$chl
that are higher than each "treshold value", but how
can I compare a vector with 1885 elements with the one
with 11?
Sorry for this (probably) stupid question...
and thanks in advance.
Alessandro



From jjmichael at comcast.net  Mon Aug  8 17:48:46 2005
From: jjmichael at comcast.net (Jake Michaelson)
Date: Mon, 08 Aug 2005 09:48:46 -0600
Subject: [R] make error: X11/Intrinsic.h: No such,,,
In-Reply-To: <17143.30626.849917.821534@stat.math.ethz.ch>
References: <1123273040.29703.27.camel@localhost.localdomain>
	<1123274389.7234.3.camel@localhost.localdomain>
	<17143.30626.849917.821534@stat.math.ethz.ch>
Message-ID: <1123516126.7520.5.camel@localhost.localdomain>

I use Mac OS X at home and Linux at work, so the R Aqua GUI has spoiled
me.  I have not seen its equal so far (on Windows or Linux).  The most
important thing to me is how easily accessible the help and
documentation is.  I like how when I begin typing a function, the form
and arguments to the function automatically appear at the bottom bar,
refreshing my memory.  I like that all plots are output to on-screen
PDF.  I could go on and on, but I hope that someday we'll see something
on Linux with the same polish and ease-of-use.  Maybe when Cairo is
integrated into Gnome it might make PDF plot display more feasible...

 
On Mon, 2005-08-08 at 17:17 +0200, Martin Maechler wrote:
> >>>>> "Jake" == Jake Michaelson <jjmichael at comcast.net>
> >>>>>     on Fri, 05 Aug 2005 14:39:49 -0600 writes:
> 
>     Jake> Thanks for the help -- this morning someone (on the
>     Jake> Ubuntu boards) was kind enough to point this out to
>     Jake> me. Now if there were only a decent Linux front
>     Jake> end/gui for R...
> 
> is ESS (http://ESS.r-project.org/) indecent to you ?
> 
> Martin Maechler, ETH Zurich



From mzp3769 at yahoo.com  Mon Aug  8 18:06:00 2005
From: mzp3769 at yahoo.com (m p)
Date: Mon, 8 Aug 2005 09:06:00 -0700 (PDT)
Subject: [R] filled.contour help
Message-ID: <20050808160600.47553.qmail@web51003.mail.yahoo.com>

Hello,
I plot with filled.contour and have this problem.
There is an area that I want to cover with angled
shading lines to represent NA in my data. 
Very much appreciate help. 
Thanks,
Mark


pal <- palette(gray(seq(1.,0.,len=8)))
filled.contour(fvec,qvec,etsarray,
     
levels=c(-.6,-.4,-.2,,0.,.2,.4,,.6,.8,,1.),zlim=c(-.6,1),
               xlab=xstring,ylab=ystring,
              
col=pal,key.axes=axis(4,c(-.6,-.4,-.2,0.,.2,.4,.6,.8,1.)))



From severine.erhel at free.fr  Mon Aug  8 18:15:27 2005
From: severine.erhel at free.fr (severine.erhel@free.fr)
Date: Mon, 08 Aug 2005 18:15:27 +0200
Subject: [R]  get the wald chi square in binary logistic regression
Message-ID: <1123517727.42f7851f8ab53@imp2-q.free.fr>

hello,

I work since a few time on R and i wanted to know how to obtain the Wald chi
square value when you make a binary logistic regression. In fact, i have the z
value and the signification but is there a script to see what is the value of
Wald chi square. You can see my model below,
Best regards,

S??verine Erhel





[Previously saved workspace restored]


> m3 = glm(reponse2 ~ form + factor(critere2) ,family=binomial,data=mes.donnees)
>  summary (m3)

Call:
glm(formula = reponse2 ~ form + factor(critere2), family = binomial,
    data = mes.donnees)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-2.5402   0.2064   0.3354   0.4833   1.4177

Coefficients:
                         Estimate Std. Error z value Pr(>|z|)
(Intercept)                0.5482     0.3930   1.395   0.1631
form   Illustration        3.2904     0.6478   5.080 3.78e-07 ***
form  Texte+illustration   2.6375     0.4746   5.557 2.74e-08 ***
factor(critere2)2         -1.0973     0.5103  -2.150   0.0315 *
factor(critere2)3         -0.9891     0.5107  -1.937   0.0528 .
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 227.76  on 218  degrees of freedom
Residual deviance: 162.11  on 214  degrees of freedom
AIC: 172.11

Number of Fisher Scoring iterations: 5



From Paul.Boutros at utoronto.ca  Mon Aug  8 18:31:11 2005
From: Paul.Boutros at utoronto.ca (Paul Boutros)
Date: Mon, 8 Aug 2005 12:31:11 -0400
Subject: [R] Building R 2.1.0 on AIX 5.2.0.0
In-Reply-To: <1109650742.4223ed36b9939@webmail.utoronto.ca>
Message-ID: <CPEAKHBKLBNIKJDIELLCCEDNDEAA.Paul.Boutros@utoronto.ca>

Hello,

The set of messages below reports a successful build of 2.0.0 on AIX 5.2
using GCC 3.3.2

I've been trying for a while now to build 2.1.0 and 2.1.1 and have been
unsuccessful.  I've tried:
- GCC 3.3.2 and 4.0.1
- default AIX make and GNU make
- 32-bit and 64-bit builds

A typical configure output is:
==============================================
R is now configured for powerpc-ibm-aix5.2.0.0

  Source directory:          .
  Installation directory:    /db2blast/R/2.1.0

  C compiler:                gcc -mno-fp-in-toc -maix32 -g -O2
  C++ compiler:              g++  -g -O2
  Fortran compiler:          g77  -maix32 -O2

  Interfaces supported:      X11
  External libraries:
  Additional capabilities:   PNG, JPEG, MBCS, NLS
  Options enabled:           R profiling

  Recommended packages:      yes
==============================================

In all cases make crashes with:

==============================================
make[5]: Leaving directory `/db2blast/R/R-2.1.0/src/library/tools/src'
make[4]: Leaving directory `/db2blast/R/R-2.1.0/src/library/tools/src'
Error in dyn.load(x, as.logical(local), as.logical(now)) :
        unable to load shared library
'/db2blast/R/R-2.1.0/library/tools/libs/tools.so':

Execution halted
make[3]: *** [all] Error 1
make[3]: Leaving directory `/db2blast/R/R-2.1.0/src/library/tools'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/db2blast/R/R-2.1.0/src/library'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/db2blast/R/R-2.1.0/src'
make: *** [R] Error 1
==============================================

Any ideas on what might have changed between 2.0.1 and 2.1.0 to cause this,
or maybe any suggestions on what I could try next?
Paul


> -----Original Message-----
> From: paul.boutros at utoronto.ca [mailto:paul.boutros at utoronto.ca]
> Sent: Monday, February 28, 2005 11:19 PM
> To: R-help at stat.math.ethz.ch
> Subject: Problems Building Ron AIX 5.2.0.0 (Solved)
>
>
> Happily I got this to work, largely by trial-and-error.  In hopes
> that this will
> help somebody else, my config.site ended up being:
> OBJECT_MODE=64
> R_PAPERSIZE=letter
> CC=/usr/local/bin/gcc
> MAIN_LDFLAGS=-Wl,-brtl
> SHLIB_LDFLAGS=-Wl,-G
>
> Which is virtually identical to that recommended in R-admin: one
> of my problems
> was using "-W1,brtl" rather than "-W1,-brtl".  This was R 2.0.1
> on AIX 5.2.0.0 with GCC 3.3.2
>
> The previous messages I'd posted on this issue are included below.
>
> Paul
>
> ============================================================
> My apologies -- I had believed that by linking the source message I
> had made the detailed context available.  I will be more careful in
> the future to correctly give full context.
>
> Paul
>
> > -----Original Message-----
> > From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> > Sent: Saturday, February 26, 2005 5:23 AM
> > To: paul.boutros at utoronto.ca
> > Cc: r-help at stat.math.ethz.ch
> > Subject: Re: [R] Problems Building R on AIX 5.2.0.0 (Update)
> >
> >
> > Quotes from messages about Solaris 9 are not necessarily applicable to
> > AIX, and in omitting the context you have misrepresented me.
> >
> > Please do bear in mind the `moral rights' on quoting given at
> >
> > http://www.jiscmail.ac.uk/help/policy/copyright.htm
> >
> > (Perhaps such a reference is needed in the posting guide?)
> >
> >
> > On Fri, 25 Feb 2005 paul.boutros at utoronto.ca wrote:
> >
> > > Hi,
> > >
> > > My previous message is appended: I'm still struggling with
> > building on AIX.  I
> > > updated my config.site to follow the suggestions from R-admin:
> > > MAIN_LDFLAGS=-Wl,brtl
> > > SHLIB_LDFLAGS=-Wl,-G
> > >
> > > This led to an error during configure:
> > > checking whether mixed C/Fortran code can be run... configure:
> > WARNING: cannot
> > > run mixed C/Fortan code
> > > configure: error: Maybe check LDFLAGS for paths to Fortran libraries?
> > >
> > > This confused me a bit, because before adding the MAIN_LDFLAGS
> > and SHLIB_LDFLAGS
> > > to config.site this step of configure did not show an error.
> > When I googled this
> > > I found a previous message from last year:
> > > http://tolstoy.newcastle.edu.au/R/help/04/04/1622.html
> > >
> > > At the end of this message Professor Ripley says:
> > > "You need wherever libg2c.so is installed in your LD_LIBRARY_PATH."
> > >
> > > So... I went looking for this file and could not find it!  In
> > /usr/local/lib I
> > > have:
> > > $ ls -al libg2c*
> > > -rw-r--r--   1 freeware staff       7751224 Jan 09 2004  libg2c.a
> > > -rwxr-xr-x   1 freeware staff           714 Jan 09 2004  libg2c.la
> > >
> > > But no libg2c.so appears to be on my system.  Does this
> > indicate a bad install
> > > of gcc, or could anybody offer any suggestions on where to go
> from here?
> > >
> > > Paul
> > >
> > > ---------------------------------------------------
> > > From: Paul Boutros <Paul.Boutros_at_utoronto.ca>
> > > Date: Thu 24 Feb 2005 - 02:43:52 EST
> > >
> > > Hello,
> > >
> > > I am trying to build R 2.0.1 on an AIX 5.2.0.0 machine using
> gcc 3.3.2:
> > > $ oslevel
> > >
> > > 5.2.0.0
> > > $ gcc -v
> > >
> > > Reading specs from
> > /usr/local/lib/gcc-lib/powerpc-ibm-aix5.2.0.0/3.3.2/specs
> > > Configured with: ../gcc-3.3.2/configure : (reconfigured)
> > ../gcc-3.3.2/configure
> > > --disable-nls : (reconfigured) ../gcc-3.3.2/configure
> > --disable-nls Thread
> > > model: aix
> > > gcc version 3.3.2
> > >
> > > Configure goes okay, but I get an error that I don't quite know
> > how to interpret
> > > during make. I've included the summary output from the end of
> > configure as well
> > > as the error that I get during make below. Any
> > suggestions/recommendations are
> > > very much appreciate: I'm stuck on ideas for what could be
> going wrong.
> > >
> > > Paul
> > >
> > > $ ./configure --prefix=/db2blaste/R
> > >
> > >
> > > <snip>
> > >
> > > R is now configured for powerpc-ibm-aix5.2.0.0
> > >
> > >  Source directory: .
> > >  Installation directory: /db2blast/R
> > >
> > >  C compiler:                gcc -mno-fp-in-toc -g -O2
> > >  C++ compiler:              g++  -g -O2
> > >  Fortran compiler:          g77  -g -O2
> > >
> > >  Interfaces supported:      X11
> > >
> > >  External libraries:
> > >  Additional capabilities: PNG, JPEG
> > >  Options enabled: R profiling
> > >
> > >  Recommended packages: yes
> > >
> > > configure: WARNING: you cannot build DVI versions of the R manuals
> > > configure: WARNING: you cannot build info or html versions of
> > the R manuals
> > > configure: WARNING: you cannot build PDF versions of the R manuals
> > > configure: WARNING: I could not determine a browser
> > > configure: WARNING: I could not determine a PDF viewer
> > >
> > >
> > > $ make
> > >
> > >
> > > <snip>
> > >
> > >        gcc -Wl,-bM:SRE -Wl,-H512 -Wl,-T512 -Wl,-bnoentry
> > -Wl,-bexpall -Wl,- bI:
> > > .
> > >
> > > ./../../etc/R.exp -L/usr/local/lib -o
> > > lapack.so -Wl,-bI:../../../etc/Rlapack.exp
> > > Lapack.lo rgeev.lo
> > >
> > > rsyev.lo -L../../../lib -lRlapack -L/usr/local/lib -L/usr/
> > local/lib/gcc-lib/
> > > powerpc-ibm-aix5.2.0.0/3.3.2 -L/usr/local/lib/gcc-lib/powe rpc-
> > > ibm-aix5.2.0.0/3.3.2/../../.. -lfrtbegin -lg2c -lm -lgcc_s
> > /usr/local/lib/gcclib
> > > /powerpc-ibm-aix5.2.0.0/3.3.2/libgcc.a -lg -ldl -ltermcap -lm
> > -lc ld: 0706-006
> > > Cannot find or open library file: -l Rlapack
> > >
> > >        ld:open(): A file or directory in the path name does not exist.
> > > collect2: ld returned 255 exit status
> > > make: 1254-004 The error code from the last command is 1.
> > >
> > > Stop.
> > > make: 1254-004 The error code from the last command is 2.
> > >
> > > Stop.
> > > make: 1254-004 The error code from the last command is 1.
> > >
> > > Stop.
> > > make: 1254-004 The error code from the last command is 1.
> > >
> > > Stop.
> > > make: 1254-004 The error code from the last command is 1.
> > >
> > > Stop.
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From helprhelp at gmail.com  Mon Aug  8 18:53:19 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Mon, 8 Aug 2005 11:53:19 -0500
Subject: [R] computationally singular
Message-ID: <cdf8178305080809536f18e4ac@mail.gmail.com>

Hi,
I have a dataset which has around 138 variables and 30,000 cases. I am
trying to calculate a mahalanobis distance matrix for them and my
procedure is like this:

Suppose my data is stored in mymatrix
> S<-cov(mymatrix) # this is fine
> D<-sapply(1:nrow(mymatrix), function(i) mahalanobis(mymatrix, mymatrix[i,], S))
Error in solve.default(cov, ...) : system is computationally singular:
reciprocal condition number = 1.09501e-25

I understand the error message but I don't know how to trace down
which variables caused this so that I can "sacrifice" them if there
are not a lot. Again, not sure if it is due to some variables and not
sure if dropping variables is a good idea either.

Thanks for help,

weiwei


-- 
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From cobleigh at gmail.com  Mon Aug  8 19:03:09 2005
From: cobleigh at gmail.com (Jamieson Cobleigh)
Date: Mon, 8 Aug 2005 13:03:09 -0400
Subject: [R] Help with doing overlays plots...
Message-ID: <7f50836c0508081003904d002@mail.gmail.com>

I have a data frame with three columns, type (a factor with two
values:  "Monolithic" and "Compositional"), size (numeric), and states
(numeric).  I want to create a plot where size goes on the x-axis and
states goes on the y-axis.  In this plot, I want two lines, one where
the type is "Monolithic" and one where the type is "Compositional".

I think this can be done by using the plot command to plot the line
for one of the two types (setting the xlim and ylim parameters to
ensure the plot area is large enough to hold all of the points). 
Then, I can use the lines and points commands to add the second line
onto the plot.

However, I don't want to have to specify the legend manually.  I want
something in R that does what can be done in SAS by using "plot
states*size=type" in "proc gplot".

Here is a dump of my data set:

tmp <-
structure(list(type = structure(as.integer(c(2, 2, 2, 1, 1, 1, 
1, 1)), .Label = c("Compositional", "Monolithic"), class = "factor"), 
    size = as.integer(c(2, 3, 4, 2, 3, 4, 5, 6)), states = as.integer(c(4910, 
    336026, 37526650, 4016, 44941, 310553, 8260254, 144145585
    ))), .Names = c("type", "size", "states"), row.names = c("1", 
"2", "3", "4", "5", "6", "7", "8"), class = "data.frame")



From renaud.lancelot at cirad.fr  Mon Aug  8 19:03:38 2005
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Mon, 08 Aug 2005 20:03:38 +0300
Subject: [R] get the wald chi square in binary logistic regression
In-Reply-To: <1123517727.42f7851f8ab53@imp2-q.free.fr>
References: <1123517727.42f7851f8ab53@imp2-q.free.fr>
Message-ID: <42F7906A.3010603@cirad.fr>

severine.erhel at free.fr a ??crit :
> hello,
> 
> I work since a few time on R and i wanted to know how to obtain the Wald chi
> square value when you make a binary logistic regression. In fact, i have the z
> value and the signification but is there a script to see what is the value of
> Wald chi square. You can see my model below,
> Best regards,
> 
> S??verine Erhel
> 
If you want a global test for several coeff associated with the same 
variable (e.g., form or criter2 in your example), you can fit the model 
without the variable and compare the 2 models with a likelihood ratio 
test (function anova): it is safer than the Wald test.

If you really want the Wald test, it is available in different packages: 
see for example the function wald.test in package aod.

Best,

Renaud


> 
> 
> 
> 
> [Previously saved workspace restored]
> 
> 
> 
>>m3 = glm(reponse2 ~ form + factor(critere2) ,family=binomial,data=mes.donnees)
>> summary (m3)
> 
> 
> Call:
> glm(formula = reponse2 ~ form + factor(critere2), family = binomial,
>     data = mes.donnees)
> 
> Deviance Residuals:
>     Min       1Q   Median       3Q      Max
> -2.5402   0.2064   0.3354   0.4833   1.4177
> 
> Coefficients:
>                          Estimate Std. Error z value Pr(>|z|)
> (Intercept)                0.5482     0.3930   1.395   0.1631
> form   Illustration        3.2904     0.6478   5.080 3.78e-07 ***
> form  Texte+illustration   2.6375     0.4746   5.557 2.74e-08 ***
> factor(critere2)2         -1.0973     0.5103  -2.150   0.0315 *
> factor(critere2)3         -0.9891     0.5107  -1.937   0.0528 .
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> 
> (Dispersion parameter for binomial family taken to be 1)
> 
>     Null deviance: 227.76  on 218  degrees of freedom
> Residual deviance: 162.11  on 214  degrees of freedom
> AIC: 172.11
> 
> Number of Fisher Scoring iterations: 5
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Dr Renaud Lancelot, v??t??rinaire
Projet FSP r??gional ??pid??miologie v??t??rinaire
C/0 Ambassade de France - SCAC
BP 834 Antananarivo 101 - Madagascar

e-mail: renaud.lancelot at cirad.fr
tel.:   +261 32 40 165 53 (cell)
         +261 20 22 665 36 ext. 225 (work)
         +261 20 22 494 37 (home)



From chrish at stats.ucl.ac.uk  Mon Aug  8 19:05:55 2005
From: chrish at stats.ucl.ac.uk (Christian Hennig)
Date: Mon, 8 Aug 2005 18:05:55 +0100 (BST)
Subject: [R] computationally singular
In-Reply-To: <cdf8178305080809536f18e4ac@mail.gmail.com>
References: <cdf8178305080809536f18e4ac@mail.gmail.com>
Message-ID: <Pine.LNX.4.58.0508081801570.14535@egon.stats.ucl.ac.uk>

Once I had a situation where the reason was that the variables were
scaled to extremely different magnitudes. 1e-25 is a *very* small number
but still there is some probability that it may help to look up standard
deviations and to multiply the
variable with the smallest st.dev. with 1e20 or something.

Best,
Christian

On Mon, 8 Aug 2005, Weiwei Shi wrote:

> Hi,
> I have a dataset which has around 138 variables and 30,000 cases. I am
> trying to calculate a mahalanobis distance matrix for them and my
> procedure is like this:
>
> Suppose my data is stored in mymatrix
> > S<-cov(mymatrix) # this is fine
> > D<-sapply(1:nrow(mymatrix), function(i) mahalanobis(mymatrix, mymatrix[i,], S))
> Error in solve.default(cov, ...) : system is computationally singular:
> reciprocal condition number = 1.09501e-25
>
> I understand the error message but I don't know how to trace down
> which variables caused this so that I can "sacrifice" them if there
> are not a lot. Again, not sure if it is due to some variables and not
> sure if dropping variables is a good idea either.
>
> Thanks for help,
>
> weiwei
>
>
> --
> Weiwei Shi, Ph.D
>
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

*** NEW ADDRESS! ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche



From severine.erhel at free.fr  Mon Aug  8 19:12:47 2005
From: severine.erhel at free.fr (severine.erhel@free.fr)
Date: Mon, 08 Aug 2005 19:12:47 +0200
Subject: [R] get the wald chi square in binary logistic regression
In-Reply-To: <42F7906A.3010603@cirad.fr>
References: <1123517727.42f7851f8ab53@imp2-q.free.fr>
	<42F7906A.3010603@cirad.fr>
Message-ID: <1123521167.42f7928f5a357@imp1-q.free.fr>

th,ks for your help,

i don't have this package on my R, do you know an other package that have this
test...thanks




Selon Renaud Lancelot <renaud.lancelot at cirad.fr>:

> severine.erhel at free.fr a ??crit :
> > hello,
> >
> > I work since a few time on R and i wanted to know how to obtain the Wald
> chi
> > square value when you make a binary logistic regression. In fact, i have
> the z
> > value and the signification but is there a script to see what is the value
> of
> > Wald chi square. You can see my model below,
> > Best regards,
> >
> > S??verine Erhel
> >
> If you want a global test for several coeff associated with the same
> variable (e.g., form or criter2 in your example), you can fit the model
> without the variable and compare the 2 models with a likelihood ratio
> test (function anova): it is safer than the Wald test.
>
> If you really want the Wald test, it is available in different packages:
> see for example the function wald.test in package aod.
>
> Best,
>
> Renaud
>
>
> >
> >
> >
> >
> > [Previously saved workspace restored]
> >
> >
> >
> >>m3 = glm(reponse2 ~ form + factor(critere2)
> ,family=binomial,data=mes.donnees)
> >> summary (m3)
> >
> >
> > Call:
> > glm(formula = reponse2 ~ form + factor(critere2), family = binomial,
> >     data = mes.donnees)
> >
> > Deviance Residuals:
> >     Min       1Q   Median       3Q      Max
> > -2.5402   0.2064   0.3354   0.4833   1.4177
> >
> > Coefficients:
> >                          Estimate Std. Error z value Pr(>|z|)
> > (Intercept)                0.5482     0.3930   1.395   0.1631
> > form   Illustration        3.2904     0.6478   5.080 3.78e-07 ***
> > form  Texte+illustration   2.6375     0.4746   5.557 2.74e-08 ***
> > factor(critere2)2         -1.0973     0.5103  -2.150   0.0315 *
> > factor(critere2)3         -0.9891     0.5107  -1.937   0.0528 .
> > ---
> > Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
> >
> > (Dispersion parameter for binomial family taken to be 1)
> >
> >     Null deviance: 227.76  on 218  degrees of freedom
> > Residual deviance: 162.11  on 214  degrees of freedom
> > AIC: 172.11
> >
> > Number of Fisher Scoring iterations: 5
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
>
>
> --
> Dr Renaud Lancelot, v??t??rinaire
> Projet FSP r??gional ??pid??miologie v??t??rinaire
> C/0 Ambassade de France - SCAC
> BP 834 Antananarivo 101 - Madagascar
>
> e-mail: renaud.lancelot at cirad.fr
> tel.:   +261 32 40 165 53 (cell)
>          +261 20 22 665 36 ext. 225 (work)
>          +261 20 22 494 37 (home)
>



From amsa36060 at yahoo.com  Mon Aug  8 19:18:51 2005
From: amsa36060 at yahoo.com (Amir Safari)
Date: Mon, 8 Aug 2005 10:18:51 -0700 (PDT)
Subject: [R] How to insert a certain model in SVM regarding to fixed kernels
	?
Message-ID: <20050808171851.24629.qmail@web60415.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050808/17d9901f/attachment.pl

From ccleland at optonline.net  Mon Aug  8 19:19:27 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Mon, 08 Aug 2005 13:19:27 -0400
Subject: [R] Help with doing overlays plots...
In-Reply-To: <7f50836c0508081003904d002@mail.gmail.com>
References: <7f50836c0508081003904d002@mail.gmail.com>
Message-ID: <42F7941F.9000006@optonline.net>

trellis.device()

xyplot(states ~ size, groups=type, data=tmp,
                 panel = "panel.superpose",
                 panel.groups ="panel.linejoin", auto.key=TRUE)

Jamieson Cobleigh wrote:
> I have a data frame with three columns, type (a factor with two
> values:  "Monolithic" and "Compositional"), size (numeric), and states
> (numeric).  I want to create a plot where size goes on the x-axis and
> states goes on the y-axis.  In this plot, I want two lines, one where
> the type is "Monolithic" and one where the type is "Compositional".
> 
> I think this can be done by using the plot command to plot the line
> for one of the two types (setting the xlim and ylim parameters to
> ensure the plot area is large enough to hold all of the points). 
> Then, I can use the lines and points commands to add the second line
> onto the plot.
> 
> However, I don't want to have to specify the legend manually.  I want
> something in R that does what can be done in SAS by using "plot
> states*size=type" in "proc gplot".
> 
> Here is a dump of my data set:
> 
> tmp <-
> structure(list(type = structure(as.integer(c(2, 2, 2, 1, 1, 1, 
> 1, 1)), .Label = c("Compositional", "Monolithic"), class = "factor"), 
>     size = as.integer(c(2, 3, 4, 2, 3, 4, 5, 6)), states = as.integer(c(4910, 
>     336026, 37526650, 4016, 44941, 310553, 8260254, 144145585
>     ))), .Names = c("type", "size", "states"), row.names = c("1", 
> "2", "3", "4", "5", "6", "7", "8"), class = "data.frame")
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From helprhelp at gmail.com  Mon Aug  8 19:22:51 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Mon, 8 Aug 2005 12:22:51 -0500
Subject: [R] computationally singular
In-Reply-To: <Pine.LNX.4.58.0508081801570.14535@egon.stats.ucl.ac.uk>
References: <cdf8178305080809536f18e4ac@mail.gmail.com>
	<Pine.LNX.4.58.0508081801570.14535@egon.stats.ucl.ac.uk>
Message-ID: <cdf81783050808102211b60eb8@mail.gmail.com>

I think the problem might be caused two variables are very correlated.
Should I check the cov matrix and try to delete some?
But i am just not quite sure of your reply. Could you detail it with some steps?

thanks,

weiwei

On 8/8/05, Christian Hennig <chrish at stats.ucl.ac.uk> wrote:
> Once I had a situation where the reason was that the variables were
> scaled to extremely different magnitudes. 1e-25 is a *very* small number
> but still there is some probability that it may help to look up standard
> deviations and to multiply the
> variable with the smallest st.dev. with 1e20 or something.
> 
> Best,
> Christian
> 
> On Mon, 8 Aug 2005, Weiwei Shi wrote:
> 
> > Hi,
> > I have a dataset which has around 138 variables and 30,000 cases. I am
> > trying to calculate a mahalanobis distance matrix for them and my
> > procedure is like this:
> >
> > Suppose my data is stored in mymatrix
> > > S<-cov(mymatrix) # this is fine
> > > D<-sapply(1:nrow(mymatrix), function(i) mahalanobis(mymatrix, mymatrix[i,], S))
> > Error in solve.default(cov, ...) : system is computationally singular:
> > reciprocal condition number = 1.09501e-25
> >
> > I understand the error message but I don't know how to trace down
> > which variables caused this so that I can "sacrifice" them if there
> > are not a lot. Again, not sure if it is due to some variables and not
> > sure if dropping variables is a good idea either.
> >
> > Thanks for help,
> >
> > weiwei
> >
> >
> > --
> > Weiwei Shi, Ph.D
> >
> > "Did you always know?"
> > "No, I did not. But I believed..."
> > ---Matrix III
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> *** NEW ADDRESS! ***
> Christian Hennig
> University College London, Department of Statistical Science
> Gower St., London WC1E 6BT, phone +44 207 679 1698
> chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche
> 


-- 
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From chrish at stats.ucl.ac.uk  Mon Aug  8 19:23:43 2005
From: chrish at stats.ucl.ac.uk (Christian Hennig)
Date: Mon, 8 Aug 2005 18:23:43 +0100 (BST)
Subject: [R] (more) computationally singular
In-Reply-To: <cdf8178305080809536f18e4ac@mail.gmail.com>
References: <cdf8178305080809536f18e4ac@mail.gmail.com>
Message-ID: <Pine.LNX.4.58.0508081813120.14535@egon.stats.ucl.ac.uk>

More ideas:

You can also perform an Eigenvalue decomposition of the covariance
matrix and see along which
directions the singularity occurs and how strong it is.
Consequences could be: rescaling (or omission) of variables that are
strong in these
directions, taking principal components, or linear transformation of the
whole data in order to attain less extreme ratios between cov eigenvalues.

Generally I would say that information reduction (principal components or
leaving out variables) should only be done if "small variance along a
direction" means that "this direction is not important" in terms of the
subject matter problem. Otherwise transformation could help. (Perhaps my
guess was wrong in the first mail, you don't have to multiply something
by 1e20 to repair a 1e-25 condition number and a more moderate
transformation suffices.)

Best,
Christian


On Mon, 8 Aug 2005, Weiwei Shi wrote:

> Hi,
> I have a dataset which has around 138 variables and 30,000 cases. I am
> trying to calculate a mahalanobis distance matrix for them and my
> procedure is like this:
>
> Suppose my data is stored in mymatrix
> > S<-cov(mymatrix) # this is fine
> > D<-sapply(1:nrow(mymatrix), function(i) mahalanobis(mymatrix, mymatrix[i,], S))
> Error in solve.default(cov, ...) : system is computationally singular:
> reciprocal condition number = 1.09501e-25
>
> I understand the error message but I don't know how to trace down
> which variables caused this so that I can "sacrifice" them if there
> are not a lot. Again, not sure if it is due to some variables and not
> sure if dropping variables is a good idea either.
>
> Thanks for help,
>
> weiwei
>
>
> --
> Weiwei Shi, Ph.D
>
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

*** NEW ADDRESS! ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche



From chrish at stats.ucl.ac.uk  Mon Aug  8 19:31:56 2005
From: chrish at stats.ucl.ac.uk (Christian Hennig)
Date: Mon, 8 Aug 2005 18:31:56 +0100 (BST)
Subject: [R] (part III) computationally singular
In-Reply-To: <cdf81783050808102211b60eb8@mail.gmail.com>
References: <cdf8178305080809536f18e4ac@mail.gmail.com> 
	<Pine.LNX.4.58.0508081801570.14535@egon.stats.ucl.ac.uk>
	<cdf81783050808102211b60eb8@mail.gmail.com>
Message-ID: <Pine.LNX.4.58.0508081824230.14535@egon.stats.ucl.ac.uk>

Sorry, our emails crossed...

On Mon, 8 Aug 2005, Weiwei Shi wrote:

> I think the problem might be caused two variables are very correlated.
> Should I check the cov matrix and try to delete some?

In this case, taking principal components should do the job.
Variable deletion may help as well - I am not extremely against it, it
depends on your whole project and aim, but I would not start with that
before I found out if there are more "proper" possibilities.

> But i am just not quite sure of your reply. Could you detail it with some
steps?

Look up all std.devs of the variables.
If the ratio between the largest one and the smallest one is more than,
let's say, 1e5, consider that as "not healthy". Multiply the variables
with the smallest std.devs with constants so that the ratio between
largest and smallest std.dev is not more than 1e3, say (I am not sure
about the exact size of these numbers... try something...). Look if the
problem vanishes after such rescaling.

Don't ask me the same about the second email - I don't have the time to
explain that in detail.

Sorry,
Christian

>
> thanks,
>
> weiwei
>
> On 8/8/05, Christian Hennig <chrish at stats.ucl.ac.uk> wrote:
> > Once I had a situation where the reason was that the variables were
> > scaled to extremely different magnitudes. 1e-25 is a *very* small number
> > but still there is some probability that it may help to look up standard
> > deviations and to multiply the
> > variable with the smallest st.dev. with 1e20 or something.
> >
> > Best,
> > Christian
> >
> > On Mon, 8 Aug 2005, Weiwei Shi wrote:
> >
> > > Hi,
> > > I have a dataset which has around 138 variables and 30,000 cases. I am
> > > trying to calculate a mahalanobis distance matrix for them and my
> > > procedure is like this:
> > >
> > > Suppose my data is stored in mymatrix
> > > > S<-cov(mymatrix) # this is fine
> > > > D<-sapply(1:nrow(mymatrix), function(i) mahalanobis(mymatrix, mymatrix[i,], S))
> > > Error in solve.default(cov, ...) : system is computationally singular:
> > > reciprocal condition number = 1.09501e-25
> > >
> > > I understand the error message but I don't know how to trace down
> > > which variables caused this so that I can "sacrifice" them if there
> > > are not a lot. Again, not sure if it is due to some variables and not
> > > sure if dropping variables is a good idea either.
> > >
> > > Thanks for help,
> > >
> > > weiwei
> > >
> > >
> > > --
> > > Weiwei Shi, Ph.D
> > >
> > > "Did you always know?"
> > > "No, I did not. But I believed..."
> > > ---Matrix III
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > >
> >
> > *** NEW ADDRESS! ***
> > Christian Hennig
> > University College London, Department of Statistical Science
> > Gower St., London WC1E 6BT, phone +44 207 679 1698
> > chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche
> >
>
>
> --
> Weiwei Shi, Ph.D
>
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
>

*** NEW ADDRESS! ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche



From tpapp at Princeton.EDU  Mon Aug  8 19:41:02 2005
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Mon, 8 Aug 2005 19:41:02 +0200
Subject: [R] modifying argument of a .C call (DUP=FALSE)
Message-ID: <20050808174058.GA31325@tpapp.student.princeton.edu>

I have a huge matrix on which I need to do a simple (elementwise)
transformation.  Two of these matrices cannot fit in the memory, so I cannot
do this in R.

I thought of writing some C code to do this and calling it using .C with
DUP=FALSE.  All I need is a simple for loop that replaces elements with
their new value, something like

void transform(double *a, int *lengtha)  {
  int i;
  for (i=0; i < *lengtha; i++) {
    *(a+i) = calculatenewvaluesomehow(*(a+i))
  }
}

trans <- function(a) .C("transform",as.double(a), as.integer(length(a))

is it possible to do this?  The manuals say that it is dangerous, is it
possible to avoid the dangers somehow?

Tamas



From giacomo.finocchiaro at ifom-ieo-campus.it  Mon Aug  8 19:42:21 2005
From: giacomo.finocchiaro at ifom-ieo-campus.it (Finocchiaro Giacomo)
Date: Mon, 08 Aug 2005 19:42:21 +0200
Subject: [R] Square matrix plot
In-Reply-To: <mailman.9.1123408801.21605.r-help@stat.math.ethz.ch>
References: <mailman.9.1123408801.21605.r-help@stat.math.ethz.ch>
Message-ID: <6.0.3.0.0.20050808184029.01c3fc48@pop.ifom-firc.it>

Hi,

having a matrix where rows=n and cols=m, I calculated the spearman 
correlation values of the matrix, this generated a square matrix m x m.
Dose anyone knows how can I create a plot similar to this

http://bio.ifom-firc.it/User/finoc/ask.png ( produced with hierarchical 
cluster explorer)

using R? I would like to have a range of colors from green(-1) to 
red(+1)  proportional to the correlation value calculated. Thanks a lot. 
Regards

				Giacomo Finocchiaro



From tlumley at u.washington.edu  Mon Aug  8 19:47:27 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 8 Aug 2005 10:47:27 -0700 (PDT)
Subject: [R] GUIs (was Re:  make error: X11/Intrinsic.h: No such,,,)
In-Reply-To: <1123516126.7520.5.camel@localhost.localdomain>
References: <1123273040.29703.27.camel@localhost.localdomain>
	<1123274389.7234.3.camel@localhost.localdomain>
	<17143.30626.849917.821534@stat.math.ethz.ch>
	<1123516126.7520.5.camel@localhost.localdomain>
Message-ID: <Pine.A41.4.61b.0508081046420.50600@homer06.u.washington.edu>

On Mon, 8 Aug 2005, Jake Michaelson wrote:

> I use Mac OS X at home and Linux at work, so the R Aqua GUI has spoiled
> me.  I have not seen its equal so far (on Windows or Linux).  The most
> important thing to me is how easily accessible the help and
> documentation is.  I like how when I begin typing a function, the form
> and arguments to the function automatically appear at the bottom bar,
> refreshing my memory.

You could use the JGR gui.

 	-thomas



From spencer.graves at pdf.com  Mon Aug  8 19:52:51 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 08 Aug 2005 10:52:51 -0700
Subject: [R] get the wald chi square in binary logistic regression
In-Reply-To: <1123521167.42f7928f5a357@imp1-q.free.fr>
References: <1123517727.42f7851f8ab53@imp2-q.free.fr>	<42F7906A.3010603@cirad.fr>
	<1123521167.42f7928f5a357@imp1-q.free.fr>
Message-ID: <42F79BF3.60407@pdf.com>

	  Is this a research question?  If not, I'd like to know why you think 
the Wald test is better.

	  Are you famililiar with Bates and Watts (1988) Nonlinear Regression 
Analysis and Its Applications (Wiley), and with the concepts of 
"intrinsic" and "parameter effects" nonlinearity?  In brief, nonlinear 
regression and maximum likelihood estimation more generally involve 
projection onto a nonlinear manifold, which is subject to intrinsic 
nonlinearity as well as parameter effects nonlinearity.  The Wald test 
suffers from both types of nonlinearity, while the 2*log(likelihood 
ratio) procedure suffers from only the intrinsic nonlinearity. 
Moreover, one of the later chapters in Bates and Watts include a 
comparison intrinsic and parameter effects nonlinearity in several 
published nonlinear regression examples.  I don't remember the details 
now, but in all but a few cases, the parameter effects were at least an 
order of magnitude greater than the intrinsic nonlinearity.

	  If you are not familiar with Bates and Watts, I highly recommend it. 
  If you are, I could see comparing Wald and 2*log(likelihood ratio) to 
decide if I want to use Wald in certain applications where 
2*log(likelihood ratio) may not be feasible.

	  If you have evidence raising questions about the above, I'd like to 
know.

	  spencer graves

severine.erhel at free.fr wrote:

> th,ks for your help,
> 
> i don't have this package on my R, do you know an other package that have this
> test...thanks
> 
> 
> 
> 
> Selon Renaud Lancelot <renaud.lancelot at cirad.fr>:
> 
> 
>>severine.erhel at free.fr a ??crit :
>>
>>>hello,
>>>
>>>I work since a few time on R and i wanted to know how to obtain the Wald
>>
>>chi
>>
>>>square value when you make a binary logistic regression. In fact, i have
>>
>>the z
>>
>>>value and the signification but is there a script to see what is the value
>>
>>of
>>
>>>Wald chi square. You can see my model below,
>>>Best regards,
>>>
>>>S??verine Erhel
>>>
>>
>>If you want a global test for several coeff associated with the same
>>variable (e.g., form or criter2 in your example), you can fit the model
>>without the variable and compare the 2 models with a likelihood ratio
>>test (function anova): it is safer than the Wald test.
>>
>>If you really want the Wald test, it is available in different packages:
>>see for example the function wald.test in package aod.
>>
>>Best,
>>
>>Renaud
>>
>>
>>
>>>
>>>
>>>
>>>[Previously saved workspace restored]
>>>
>>>
>>>
>>>
>>>>m3 = glm(reponse2 ~ form + factor(critere2)
>>
>>,family=binomial,data=mes.donnees)
>>
>>>>summary (m3)
>>>
>>>
>>>Call:
>>>glm(formula = reponse2 ~ form + factor(critere2), family = binomial,
>>>    data = mes.donnees)
>>>
>>>Deviance Residuals:
>>>    Min       1Q   Median       3Q      Max
>>>-2.5402   0.2064   0.3354   0.4833   1.4177
>>>
>>>Coefficients:
>>>                         Estimate Std. Error z value Pr(>|z|)
>>>(Intercept)                0.5482     0.3930   1.395   0.1631
>>>form   Illustration        3.2904     0.6478   5.080 3.78e-07 ***
>>>form  Texte+illustration   2.6375     0.4746   5.557 2.74e-08 ***
>>>factor(critere2)2         -1.0973     0.5103  -2.150   0.0315 *
>>>factor(critere2)3         -0.9891     0.5107  -1.937   0.0528 .
>>>---
>>>Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.' 0.1 ` ' 1
>>>
>>>(Dispersion parameter for binomial family taken to be 1)
>>>
>>>    Null deviance: 227.76  on 218  degrees of freedom
>>>Residual deviance: 162.11  on 214  degrees of freedom
>>>AIC: 172.11
>>>
>>>Number of Fisher Scoring iterations: 5
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>
>>http://www.R-project.org/posting-guide.html
>>
>>
>>--
>>Dr Renaud Lancelot, v??t??rinaire
>>Projet FSP r??gional ??pid??miologie v??t??rinaire
>>C/0 Ambassade de France - SCAC
>>BP 834 Antananarivo 101 - Madagascar
>>
>>e-mail: renaud.lancelot at cirad.fr
>>tel.:   +261 32 40 165 53 (cell)
>>         +261 20 22 665 36 ext. 225 (work)
>>         +261 20 22 494 37 (home)
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From ramasamy at cancer.org.uk  Mon Aug  8 19:57:51 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 08 Aug 2005 18:57:51 +0100
Subject: [R] vector vs array
In-Reply-To: <20050808153455.22758.qmail@web26601.mail.ukl.yahoo.com>
References: <20050808153455.22758.qmail@web26601.mail.ukl.yahoo.com>
Message-ID: <1123523872.30584.72.camel@ipc143004.lif.icnet.uk>

General Notes :
a) Please try to give a simple example
b) Please avoid the rightwards assignment (i.e. "->"). Eventhough it is
perfectly legal to use it, it is confusing especially when you are
posting to a mailing list.


1) Here is a reproducible example

 set.seed(1)                         # for reproducibility
 v   <- abs( rnorm(1000) )
 thr <- c( 0.5, 1.0, 2.0, 3.0 )


2) If you simply want to count the number of points above a threshold

 sapply( thr, function(x) sum(v > x) )
 [1] 620 326  60   3


3) Or you can cut the data by threshold limits (be careful at the edges
if you have discrete data) followed by breaks

 table( cut( v, breaks=c( -Inf, thr, Inf ) ) ) )

 (-Inf,0.5]    (0.5,1]      (1,2]      (2,3]    (3,Inf]
        380        294        266         57          3

 
4) If you want to turn the problem on its head and ask for which
threshold point would you get 99%, 99.9% and 99.99% of the data below
it, you can use use quantiles

 quantile( v, c(0.99, 0.999, 0.9999) )
      99%    99.9%   99.99%
 2.529139 3.056497 3.734899


Regards, Adai



On Mon, 2005-08-08 at 08:34 -0700, alessandro carletti wrote:
> Hi!
> OK, I'm trying to select some "useful outliers" from
> my dataset: I defined 11 "treshold" values (1 for each
> level of a variable (sampling site) as follows:
> 
> 
> tresholds<-function(x)
> {
> tapply(x,mm$NAME,FUN=mean ,simplify = T, na.rm=T)->med
> 
> 
> tapply(x,mm$NAME,FUN=sd ,simplify = T,
> na.rm=T)->standev 
> 
> standev+med
> 
> }
> tresholds(mm$chl)
> 
> 
> Now I'd like to select those values from vector mm$chl
> that are higher than each "treshold value", but how
> can I compare a vector with 1885 elements with the one
> with 11?
> Sorry for this (probably) stupid question...
> and thanks in advance.
> Alessandro
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From mdowle at concordiafunds.com  Mon Aug  8 20:15:19 2005
From: mdowle at concordiafunds.com (Matthew Dowle)
Date: Mon, 8 Aug 2005 19:15:19 +0100 
Subject: [R] tapply huge speed difference if X has names
Message-ID: <78166BFC5165D811AA0400065BF0324BF07641@WISCONSIN>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050808/8a5bfe58/attachment.pl

From Song.Li at usask.ca  Mon Aug  8 20:14:54 2005
From: Song.Li at usask.ca (Song)
Date: Mon, 08 Aug 2005 12:14:54 -0600
Subject: [R] Difference amongst spline smoothers
Message-ID: <004201c59c45$13ce70a0$0501000a@DELL8600>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050808/d76ae032/attachment.pl

From dlalountas at yahoo.com  Mon Aug  8 20:20:33 2005
From: dlalountas at yahoo.com (denis lalountas)
Date: Mon, 8 Aug 2005 11:20:33 -0700 (PDT)
Subject: [R] parametric survival plot
Message-ID: <20050808182033.17125.qmail@web54605.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050808/70d25eba/attachment.pl

From gattuso at obs-vlfr.fr  Mon Aug  8 20:50:32 2005
From: gattuso at obs-vlfr.fr (Jean-Pierre Gattuso)
Date: Mon, 8 Aug 2005 12:50:32 -0600
Subject: [R] Reading large files in R
Message-ID: <6905383A-CBD2-42AC-9691-488B3BF3BDE1@obs-vlfr.fr>

Dear R-listers:

I am trying to work with a big (262 Mb) file but apparently reach a  
memory limit using R on a MacOSX as well as on a unix machine.

This is the script:

 > type=list(a=0,b=0,c=0)
 > tmp <- scan(file="coastal_gebco_sandS_blend.txt", what=type,  
sep="\t", quote="\"", dec=".", skip=1, na.strings="-99", nmax=13669628)
Read 13669627 records
 > gebco <- data.frame(tmp)
Error: cannot allocate vector of size 106793 Kb


Even tmp does not seem right:

 > summary(tmp)
Error: recursive default argument reference


Do you have any suggestion?

Thanks,
Jean-Pierre Gattuso



From ramasamy at cancer.org.uk  Mon Aug  8 20:55:37 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 08 Aug 2005 19:55:37 +0100
Subject: [R] Square matrix plot
In-Reply-To: <6.0.3.0.0.20050808184029.01c3fc48@pop.ifom-firc.it>
References: <mailman.9.1123408801.21605.r-help@stat.math.ethz.ch>
	<6.0.3.0.0.20050808184029.01c3fc48@pop.ifom-firc.it>
Message-ID: <1123527337.31411.3.camel@ipc143004.lif.icnet.uk>

The URL that you sent is not working. Can you please check ?

If you mean 2 dimensional hierarchical clustering as often used in
microarrays, then see help("heatmap"). There was a discussion last week
about using red-green for heatmap. See
http://tolstoy.newcastle.edu.au/R/help/05/08/9714.html

Or if you want to want to plot one column against another, then see
help("pairs").

Regards, Adai



On Mon, 2005-08-08 at 19:42 +0200, Finocchiaro Giacomo wrote:
> Hi,
> 
> having a matrix where rows=n and cols=m, I calculated the spearman 
> correlation values of the matrix, this generated a square matrix m x m.
> Dose anyone knows how can I create a plot similar to this
> 
> http://bio.ifom-firc.it/User/finoc/ask.png ( produced with hierarchical 
> cluster explorer)
> 
> using R? I would like to have a range of colors from green(-1) to 
> red(+1)  proportional to the correlation value calculated. Thanks a lot. 
> Regards
> 
> 				Giacomo Finocchiaro
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From kerryrekky at yahoo.com  Mon Aug  8 20:57:44 2005
From: kerryrekky at yahoo.com (Kerry Bush)
Date: Mon, 8 Aug 2005 11:57:44 -0700 (PDT)
Subject: [R] use different symbols for frequency in a plot
Message-ID: <20050808185744.71396.qmail@web51803.mail.yahoo.com>

suppose I have the following data

x<-c(rep(.1,5),rep(.2,6),rep(.4,10),rep(.5,20))
y<-c(rep(.5,3),rep(.6,8),rep(1.2,8),rep(2.5,18),rep(3,4))

If I plot(x,y) in R, I will only get seven distinct
points. What I want to do is to use different symbols
to show the frequency at each point.

e.g. if the frequncey is between 1 and 5, then I plot
the point as a circle; if the frequency is between 6
and 10, then I plot the point as a square; if the
frequency is above 10, then I plot the point as a
triangle.

I am not sure how to do this in R. Can anybody help me?



From ramasamy at cancer.org.uk  Mon Aug  8 21:02:12 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 08 Aug 2005 20:02:12 +0100
Subject: [R] Reading large files in R
In-Reply-To: <6905383A-CBD2-42AC-9691-488B3BF3BDE1@obs-vlfr.fr>
References: <6905383A-CBD2-42AC-9691-488B3BF3BDE1@obs-vlfr.fr>
Message-ID: <1123527732.31411.10.camel@ipc143004.lif.icnet.uk>

>From Note section of help("read.delim") :

     'read.table' is not the right tool for reading large matrices,
     especially those with many columns: it is designed to read _data
     frames_ which may have columns of very different classes. Use
     'scan' instead.

So I am not sure why you used 'scan', then converted it to a data frame.

1) Can provide an sample of the data that you are trying to read in.
2) How much memory does your machine has ?
3) Try reading in the first few lines using the nmax argument in scan.

Regards, Adai



On Mon, 2005-08-08 at 12:50 -0600, Jean-Pierre Gattuso wrote:
> Dear R-listers:
> 
> I am trying to work with a big (262 Mb) file but apparently reach a  
> memory limit using R on a MacOSX as well as on a unix machine.
> 
> This is the script:
> 
>  > type=list(a=0,b=0,c=0)
>  > tmp <- scan(file="coastal_gebco_sandS_blend.txt", what=type,  
> sep="\t", quote="\"", dec=".", skip=1, na.strings="-99", nmax=13669628)
> Read 13669627 records
>  > gebco <- data.frame(tmp)
> Error: cannot allocate vector of size 106793 Kb
> 
> 
> Even tmp does not seem right:
> 
>  > summary(tmp)
> Error: recursive default argument reference
> 
> 
> Do you have any suggestion?
> 
> Thanks,
> Jean-Pierre Gattuso
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ccleland at optonline.net  Mon Aug  8 21:17:44 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Mon, 08 Aug 2005 15:17:44 -0400
Subject: [R] use different symbols for frequency in a plot
In-Reply-To: <20050808185744.71396.qmail@web51803.mail.yahoo.com>
References: <20050808185744.71396.qmail@web51803.mail.yahoo.com>
Message-ID: <42F7AFD8.5070807@optonline.net>

You might consider one of these approaches instead:

plot(jitter(x), jitter(y))

or

pdf(file="c:/AlphaExample.pdf", version = "1.4")

plot(x, y, col = rgb(1, 0, 0, .2), pch = 16)

dev.off()

Kerry Bush wrote:
> suppose I have the following data
> 
> x<-c(rep(.1,5),rep(.2,6),rep(.4,10),rep(.5,20))
> y<-c(rep(.5,3),rep(.6,8),rep(1.2,8),rep(2.5,18),rep(3,4))
> 
> If I plot(x,y) in R, I will only get seven distinct
> points. What I want to do is to use different symbols
> to show the frequency at each point.
> 
> e.g. if the frequncey is between 1 and 5, then I plot
> the point as a circle; if the frequency is between 6
> and 10, then I plot the point as a square; if the
> frequency is above 10, then I plot the point as a
> triangle.
> 
> I am not sure how to do this in R. Can anybody help me?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From p.dalgaard at biostat.ku.dk  Mon Aug  8 21:28:44 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 08 Aug 2005 21:28:44 +0200
Subject: [R] modifying argument of a .C call (DUP=FALSE)
In-Reply-To: <20050808174058.GA31325@tpapp.student.princeton.edu>
References: <20050808174058.GA31325@tpapp.student.princeton.edu>
Message-ID: <x27jew449f.fsf@turmalin.kubism.ku.dk>

Tamas K Papp <tpapp at princeton.edu> writes:

> I have a huge matrix on which I need to do a simple (elementwise)
> transformation.  Two of these matrices cannot fit in the memory, so I cannot
> do this in R.
> 
> I thought of writing some C code to do this and calling it using .C with
> DUP=FALSE.  All I need is a simple for loop that replaces elements with
> their new value, something like
> 
> void transform(double *a, int *lengtha)  {
>   int i;
>   for (i=0; i < *lengtha; i++) {
>     *(a+i) = calculatenewvaluesomehow(*(a+i))
>   }
> }
> 
> trans <- function(a) .C("transform",as.double(a), as.integer(length(a))
> 
> is it possible to do this?  The manuals say that it is dangerous, is it
> possible to avoid the dangers somehow?

It's more a question of whether the dangers affect you. In general,
the issue is that you risk modifying a second (virtual) copy of the
data along with the one you intend to modify. If you're sure that you
don't have any, the point is moot. It is fairly difficult to be sure
of that in the general case, which is why we generally discourage
DUP=FALSE, especially for package writers, but for personal use you
might just get away with it.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ripley at stats.ox.ac.uk  Mon Aug  8 21:36:17 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 8 Aug 2005 20:36:17 +0100 (BST)
Subject: [R] tapply huge speed difference if X has names
In-Reply-To: <78166BFC5165D811AA0400065BF0324BF07641@WISCONSIN>
References: <78166BFC5165D811AA0400065BF0324BF07641@WISCONSIN>
Message-ID: <Pine.LNX.4.61.0508082034060.22175@gannet.stats>

Please use a current version of R!

This was fixed long ago, and you will find it in the NEWS file:

         split() now handles vectors with names internally and so is
         almost as fast as on vectors without names (and maybe 100x
         faster than before).


On Mon, 8 Aug 2005, Matthew Dowle wrote:

>
> Hi all,
>
> Apologies if this has been raised before ... R's tapply is very fast, but if
> X has names in this example, there seems to be a huge slow down: under 1
> second compared to 151 seconds.  The following timings are repeatable and
> are timed properly on a single user machine :
>
>> X = 1:100000
>> names(X) = X
>> system.time(fast<<-tapply(as.vector(X), rep(1:10000,each=10), mean))	#
> as.vector() to drop the names
> [1] 0.36 0.00 0.35 0.00 0.00
>> system.time(slow<<-tapply(X, rep(1:10000,each=10), mean))
> [1] 149.95   1.83 151.79   0.00   0.00
>> head(fast)
>   1    2    3    4    5    6
> 5.5 15.5 25.5 35.5 45.5 55.5
>> head(slow)
>   1    2    3    4    5    6
> 5.5 15.5 25.5 35.5 45.5 55.5
>> identical(fast,slow)
> [1] TRUE
>>
>
> Looking inside tapply, which then calls split, it seems there is an
> is.null(names(x)) which prevents R's internal fast version from being
> called. Why is that there? Could it be removed?  I often do something like
> tapply(mat[,"colname"],...) where mat has rownames. Therefore the rownames
> of mat become the names of the vector mat[,"colname"], and this seems to
> slow down tapply a lot. Perhaps other functions which call split also suffer
> this problem?
>
>> split.default
> function (x, f)
> {
>    if (is.list(f))
>        f <- interaction(f)
>    f <- factor(f)
>    if (is.null(attr(x, "class")) && is.null(names(x)))
>        return(.Internal(split(x, f)))
>    lf <- levels(f)
>    y <- vector("list", length(lf))
>    names(y) <- lf
>    for (k in lf) y[[k]] <- x[f %in% k]
>    y
> }
> <environment: namespace:base>
>>
>
>> version
>         _
> platform x86_64-redhat-linux-gnu
> arch     x86_64
> os       linux-gnu
> system   x86_64, linux-gnu
> status
> major    2
> minor    0.1
> year     2004
> month    11
> day      15
> language R
>>
>
>
> Thanks and regards,
> Matthew
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gunter.berton at gene.com  Mon Aug  8 21:35:52 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 8 Aug 2005 12:35:52 -0700
Subject: [R] Reading large files in R
In-Reply-To: <1123527732.31411.10.camel@ipc143004.lif.icnet.uk>
Message-ID: <200508081935.j78JZq1M017285@hertz.gene.com>

... and it is likely that even if you did have enough memory (several times
the size of the data are generally needed) it would take a very long time.

If you do have enough memory and the data are all of one type -- numeric
here -- you're better off treating it as a matrix rather than converting it
to a data frame.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Adaikalavan Ramasamy
> Sent: Monday, August 08, 2005 12:02 PM
> To: Jean-Pierre Gattuso
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Reading large files in R
> 
> >From Note section of help("read.delim") :
> 
>      'read.table' is not the right tool for reading large matrices,
>      especially those with many columns: it is designed to read _data
>      frames_ which may have columns of very different classes. Use
>      'scan' instead.
> 
> So I am not sure why you used 'scan', then converted it to a 
> data frame.
> 
> 1) Can provide an sample of the data that you are trying to read in.
> 2) How much memory does your machine has ?
> 3) Try reading in the first few lines using the nmax argument in scan.
> 
> Regards, Adai
> 
> 
> 
> On Mon, 2005-08-08 at 12:50 -0600, Jean-Pierre Gattuso wrote:
> > Dear R-listers:
> > 
> > I am trying to work with a big (262 Mb) file but apparently 
> reach a  
> > memory limit using R on a MacOSX as well as on a unix machine.
> > 
> > This is the script:
> > 
> >  > type=list(a=0,b=0,c=0)
> >  > tmp <- scan(file="coastal_gebco_sandS_blend.txt", what=type,  
> > sep="\t", quote="\"", dec=".", skip=1, na.strings="-99", 
> nmax=13669628)
> > Read 13669627 records
> >  > gebco <- data.frame(tmp)
> > Error: cannot allocate vector of size 106793 Kb
> > 
> > 
> > Even tmp does not seem right:
> > 
> >  > summary(tmp)
> > Error: recursive default argument reference
> > 
> > 
> > Do you have any suggestion?
> > 
> > Thanks,
> > Jean-Pierre Gattuso
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Mon Aug  8 21:41:26 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 8 Aug 2005 20:41:26 +0100 (BST)
Subject: [R] modifying argument of a .C call (DUP=FALSE)
In-Reply-To: <x27jew449f.fsf@turmalin.kubism.ku.dk>
References: <20050808174058.GA31325@tpapp.student.princeton.edu>
	<x27jew449f.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.LNX.4.61.0508082039070.22175@gannet.stats>

On Mon, 8 Aug 2005, Peter Dalgaard wrote:

> Tamas K Papp <tpapp at princeton.edu> writes:
>
>> I have a huge matrix on which I need to do a simple (elementwise)
>> transformation.  Two of these matrices cannot fit in the memory, so I cannot
>> do this in R.
>>
>> I thought of writing some C code to do this and calling it using .C with
>> DUP=FALSE.  All I need is a simple for loop that replaces elements with
>> their new value, something like
>>
>> void transform(double *a, int *lengtha)  {
>>   int i;
>>   for (i=0; i < *lengtha; i++) {
>>     *(a+i) = calculatenewvaluesomehow(*(a+i))
>>   }
>> }
>>
>> trans <- function(a) .C("transform",as.double(a), as.integer(length(a))
>>
>> is it possible to do this?  The manuals say that it is dangerous, is it
>> possible to avoid the dangers somehow?
>
> It's more a question of whether the dangers affect you. In general,
> the issue is that you risk modifying a second (virtual) copy of the
> data along with the one you intend to modify. If you're sure that you
> don't have any, the point is moot. It is fairly difficult to be sure
> of that in the general case, which is why we generally discourage
> DUP=FALSE, especially for package writers, but for personal use you
> might just get away with it.

I did specifically suggest .Call in an earlier reply to the same person on 
the same problem, because there you can do this via a replacement function 
with standard semantics.  See the discussion of SET_NAMED in `Writing R 
Extensions'.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ramasamy at cancer.org.uk  Mon Aug  8 22:04:23 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 08 Aug 2005 21:04:23 +0100
Subject: [R] use different symbols for frequency in a plot
In-Reply-To: <20050808185744.71396.qmail@web51803.mail.yahoo.com>
References: <20050808185744.71396.qmail@web51803.mail.yahoo.com>
Message-ID: <1123531464.31411.54.camel@ipc143004.lif.icnet.uk>

Group by which variable ? If you mean the joint distribution of 'x' and
'y' then something along the following lines

 x <- rep( c(0.1, 0.2, 0.4, 0.5),      c(5, 6, 10, 20) )
 y <- rep( c(0.5, 0.6, 1.2, 2.5, 3.0), c(3, 8, 8, 18, 4) )

 new     <- factor( paste(x, y, sep="_") )
 tb      <- table(new)

 pchcode <- cut(tb , c(-Inf, 1, 5, 6, 10, Inf), labels=F)

 tmp     <- t( sapply( strsplit( names(tb), split="_") , c ) )
 df      <- data.frame( x=tmp[ ,1], y=tmp[ ,2], 
                        freq=as.vector(tb), pchcode = pchcode -1 )

     x   y freq pchcode
 1 0.1 0.5    3       1
 2 0.1 0.6    2       1
 3 0.2 0.6    6       2
 4 0.4 1.2    8       3
 5 0.4 2.5    2       1
 6 0.5 2.5   16       4
 7 0.5   3    4       1

And now to plot it, we use points() repeatedly.

 plot( as.numeric(df$x), as.numeric(df$y), type="n" )

 for( i in unique( df$pchcode ) ){
    w <- which( df$pchcode == i )
    points( df$x[w], df$y[w], pch=as.numeric(i) )
 }

I am sure someone else will come up with a neater solution.


Can I also suggest that you try the following

  plot( jitter(x), jitter(y) )

or better still the following

  library(hexbin)
  plot( hexbin(x, y) )


Regards, Adai

On Mon, 2005-08-08 at 11:57 -0700, Kerry Bush wrote:
> suppose I have the following data
> 
> x<-c(rep(.1,5),rep(.2,6),rep(.4,10),rep(.5,20))
> y<-c(rep(.5,3),rep(.6,8),rep(1.2,8),rep(2.5,18),rep(3,4))
> 
> If I plot(x,y) in R, I will only get seven distinct
> points. What I want to do is to use different symbols
> to show the frequency at each point.
> 
> e.g. if the frequncey is between 1 and 5, then I plot
> the point as a circle; if the frequency is between 6
> and 10, then I plot the point as a square; if the
> frequency is above 10, then I plot the point as a
> triangle.
> 
> I am not sure how to do this in R. Can anybody help me?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From kerryrekky at yahoo.com  Mon Aug  8 22:42:08 2005
From: kerryrekky at yahoo.com (Kerry Bush)
Date: Mon, 8 Aug 2005 13:42:08 -0700 (PDT)
Subject: [R] use different symbols for frequency in a plot
In-Reply-To: <1123531464.31411.54.camel@ipc143004.lif.icnet.uk>
Message-ID: <20050808204208.71510.qmail@web51804.mail.yahoo.com>

Thank you.

But I only need three classes of freqnencies (in
another words, only three kinds of symbols) for 1-5,
5-10 and above 10, not to use different symbols for
different frequencies. Otherwise, clearly R will run
out of available symbols and the plot is also hard to
view.

Thank you anyway.

--- Adaikalavan Ramasamy <ramasamy at cancer.org.uk>
wrote:

> Group by which variable ? If you mean the joint
> distribution of 'x' and
> 'y' then something along the following lines
> 
>  x <- rep( c(0.1, 0.2, 0.4, 0.5),      c(5, 6, 10,
> 20) )
>  y <- rep( c(0.5, 0.6, 1.2, 2.5, 3.0), c(3, 8, 8,
> 18, 4) )
> 
>  new     <- factor( paste(x, y, sep="_") )
>  tb      <- table(new)
> 
>  pchcode <- cut(tb , c(-Inf, 1, 5, 6, 10, Inf),
> labels=F)
> 
>  tmp     <- t( sapply( strsplit( names(tb),
> split="_") , c ) )
>  df      <- data.frame( x=tmp[ ,1], y=tmp[ ,2], 
>                         freq=as.vector(tb), pchcode
> = pchcode -1 )
> 
>      x   y freq pchcode
>  1 0.1 0.5    3       1
>  2 0.1 0.6    2       1
>  3 0.2 0.6    6       2
>  4 0.4 1.2    8       3
>  5 0.4 2.5    2       1
>  6 0.5 2.5   16       4
>  7 0.5   3    4       1
> 
> And now to plot it, we use points() repeatedly.
> 
>  plot( as.numeric(df$x), as.numeric(df$y), type="n"
> )
> 
>  for( i in unique( df$pchcode ) ){
>     w <- which( df$pchcode == i )
>     points( df$x[w], df$y[w], pch=as.numeric(i) )
>  }
> 
> I am sure someone else will come up with a neater
> solution.
> 
> 
> Can I also suggest that you try the following
> 
>   plot( jitter(x), jitter(y) )
> 
> or better still the following
> 
>   library(hexbin)
>   plot( hexbin(x, y) )
> 
> 
> Regards, Adai
> 
> On Mon, 2005-08-08 at 11:57 -0700, Kerry Bush wrote:
> > suppose I have the following data
> > 
> > x<-c(rep(.1,5),rep(.2,6),rep(.4,10),rep(.5,20))
> >
>
y<-c(rep(.5,3),rep(.6,8),rep(1.2,8),rep(2.5,18),rep(3,4))
> > 
> > If I plot(x,y) in R, I will only get seven
> distinct
> > points. What I want to do is to use different
> symbols
> > to show the frequency at each point.
> > 
> > e.g. if the frequncey is between 1 and 5, then I
> plot
> > the point as a circle; if the frequency is between
> 6
> > and 10, then I plot the point as a square; if the
> > frequency is above 10, then I plot the point as a
> > triangle.
> > 
> > I am not sure how to do this in R. Can anybody
> help me?
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> > 
> 
>



From mschwartz at mn.rr.com  Mon Aug  8 22:44:10 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 08 Aug 2005 15:44:10 -0500
Subject: [R] use different symbols for frequency in a plot
In-Reply-To: <20050808185744.71396.qmail@web51803.mail.yahoo.com>
References: <20050808185744.71396.qmail@web51803.mail.yahoo.com>
Message-ID: <1123533851.5588.45.camel@localhost.localdomain>

On Mon, 2005-08-08 at 11:57 -0700, Kerry Bush wrote:
> suppose I have the following data
> 
> x<-c(rep(.1,5),rep(.2,6),rep(.4,10),rep(.5,20))
> y<-c(rep(.5,3),rep(.6,8),rep(1.2,8),rep(2.5,18),rep(3,4))
> 
> If I plot(x,y) in R, I will only get seven distinct
> points. What I want to do is to use different symbols
> to show the frequency at each point.
> 
> e.g. if the frequncey is between 1 and 5, then I plot
> the point as a circle; if the frequency is between 6
> and 10, then I plot the point as a square; if the
> frequency is above 10, then I plot the point as a
> triangle.
> 
> I am not sure how to do this in R. Can anybody help me?

You might want to review this recent post by Deepayan Sarkar:

https://stat.ethz.ch/pipermail/r-help/2005-July/074042.html

with modest modification you can replace his example, which plots the
frequencies with:

x <- c(rep(.1,5),rep(.2,6),rep(.4,10),rep(.5,20))
y <- c(rep(.5,3),rep(.6,8),rep(1.2,8),rep(2.5,18),rep(3,4))

temp <- data.frame(x, y)

foo <- subset(as.data.frame(table(temp)), Freq > 0)

> foo
     x   y Freq
1  0.1 0.5    3
5  0.1 0.6    2
6  0.2 0.6    6
11 0.4 1.2    8
15 0.4 2.5    2
16 0.5 2.5   16
20 0.5   3    4

# Use cut() to create the bins and specify the plotting symbols
# for each bin, which are the 'label' values
foo$sym <- with(foo, cut(Freq, c(0, 5, 10, Inf), 
                         labels = c(21, 22, 24))) 


# convert 'foo' to all numeric from factors above for plotting
foo <- apply(foo, 2, function(x) as.numeric(as.character(x)))


> foo
     x   y Freq sym
1  0.1 0.5    3  21
5  0.1 0.6    2  21
6  0.2 0.6    6  22
11 0.4 1.2    8  22
15 0.4 2.5    2  21
16 0.5 2.5   16  24
20 0.5   3    4  21


# Now do the plot. Keep in mind that 'foo' is now
# a matrix, rather than a data frame
plot(foo[, "x"], foo[, "y"], pch = foo[, "sym"])


HTH,

Marc Schwartz



From edhuang00 at yahoo.com  Mon Aug  8 23:06:48 2005
From: edhuang00 at yahoo.com (Haibo Huang)
Date: Mon, 8 Aug 2005 14:06:48 -0700 (PDT)
Subject: [R] Help with "non-integer #successes in a binomial glm"
Message-ID: <20050808210649.13589.qmail@web31009.mail.mud.yahoo.com>

Hi,

I had a logit regression, but don't really know how to
handle the "Warning message: non-integer #successes in
a binomial glm! in: eval(expr, envir, enclos)"
problem. I had the same logit regression without
weights and it worked out without the warning, but I
figured it makes more sense to add the weights. The
weights sum up to one. 

Could anyone give me some hint? Thanks a lot!

FYI, I have posted both regressions (with and without
weights) below.

Ed


> setwd("P:/Work in Progress/Haibo/Hans")
> 
> Lease=read.csv("lease.csv", header=TRUE)
> Lease$ET <- factor(Lease$EarlyTermination)
> SICCode=factor(Lease$SIC.Code)
> Lease$TO=factor(Lease$TenantHasOption)
> Lease$LO=factor(Lease$LandlordHasOption)
> Lease$TEO=factor(Lease$TenantExercisedOption)
> 
> RegA=glm(ET~1+TO, 
+ family=binomial(link=logit), data=Lease)
> summary(RegA)

Call:
glm(formula = ET ~ 1 + TO, family = binomial(link =
logit), data = Lease)

Deviance Residuals: 
    Min       1Q   Median       3Q      Max  
-0.5839  -0.5839  -0.5839  -0.3585   2.3565  

Coefficients:
            Estimate Std. Error z value Pr(>|z|)    
(Intercept) -1.68271    0.02363  -71.20   <2e-16 ***
TO1         -1.02959    0.09012  -11.43   <2e-16 ***
---
Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.'
0.1 ` ' 1 

(Dispersion parameter for binomial family taken to be
1)

    Null deviance: 12987  on 15809  degrees of freedom
Residual deviance: 12819  on 15808  degrees of freedom
AIC: 12823

Number of Fisher Scoring iterations: 5

> setwd("P:/Work in Progress/Haibo/Hans")
> 
> Lease=read.csv("lease.csv", header=TRUE)
> Lease$ET <- factor(Lease$EarlyTermination)
> SICCode=factor(Lease$SIC.Code)
> Lease$TO=factor(Lease$TenantHasOption)
> Lease$LO=factor(Lease$LandlordHasOption)
> Lease$TEO=factor(Lease$TenantExercisedOption)
> 
> RegA=glm(ET~1+TO, 
+ family=binomial(link=logit), data=Lease,
weights=PortionSF)
Warning message: 
non-integer #successes in a binomial glm! in:
eval(expr, envir, enclos) 
> summary(RegA)

Call:
glm(formula = ET ~ 1 + TO, family = binomial(link =
logit), data = Lease, 
    weights = PortionSF)

Deviance Residuals: 
      Min         1Q     Median         3Q        Max 

-0.055002  -0.003434   0.000000   0.000000   0.120656 


Coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)   -1.120      2.618  -0.428    0.669
TO1           -1.570      9.251  -0.170    0.865

(Dispersion parameter for binomial family taken to be
1)

    Null deviance: 1.0201  on 9302  degrees of freedom
Residual deviance: 0.9787  on 9301  degrees of freedom
AIC: 4

Number of Fisher Scoring iterations: 5



From jjmichael at cc.usu.edu  Mon Aug  8 23:58:00 2005
From: jjmichael at cc.usu.edu (Jake)
Date: Mon, 8 Aug 2005 15:58:00 -0600
Subject: [R] reverse order of matrix rows
Message-ID: <e8a97510991c685e34f9d76811c6b0bb@cc.usu.edu>

Quick question:  how can I reverse the order of the rows in a matrix?  
i.e. make the last row first and the first row last, etc.?



From deming.mi at vanderbilt.edu  Tue Aug  9 00:19:59 2005
From: deming.mi at vanderbilt.edu (Deming Mi)
Date: Mon, 8 Aug 2005 17:19:59 -0500
Subject: [R] two term exponential model
Message-ID: <003f01c59c67$6023a340$1b0bc80a@msrc.mc.vanderbilt.edu>

Dear R users,
Does anybody know if there is an R function (package) to fit a two-terms 
exponential model like y = a*exp(bx) + c*exp(dx) where y is dependent 
variable and x is independent variable.  MATLAB has a Curve Fitting Toolbox 
to implement this fitting, but I don't know if there is an R package for 
this fitting.  Thank you!

Deming Mi



From marteye29 at hotmail.com  Tue Aug  9 00:39:58 2005
From: marteye29 at hotmail.com (Martin Kardos)
Date: Mon, 08 Aug 2005 16:39:58 -0600
Subject: [R] AIC model selection
Message-ID: <BAY108-F298843DDD3853F58952D88B7B80@phx.gbl>

Hello All;

I need to run a multiple regression analysis and use Akaike's Information 
Criterion for model selection.  I understand that this command will give the 
AIC value for specified models:

AIC(object, ..., k = 2)

with "..." meaning any other optional models for which I would like AIC 
values.  But, how can I specify (in the place of "...") that I want R to 
perform an model selection prodecure based on Akaike's Information Criterion 
on a set of potential independent variables in a model such as:

model.lm=lm(A~B+C+D+E+F+G)

?

Thanks a million;

Marty



From jeaneid at chass.utoronto.ca  Tue Aug  9 01:44:12 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Mon, 8 Aug 2005 19:44:12 -0400
Subject: [R] reverse order of matrix rows
In-Reply-To: <e8a97510991c685e34f9d76811c6b0bb@cc.usu.edu>
Message-ID: <Pine.SGI.4.40.0508081943280.10828189-100000@origin.chass.utoronto.ca>

sapply(nrow(matrix):1, function(x) matrix[x,])



On Mon, 8 Aug 2005, Jake wrote:

> Quick question:  how can I reverse the order of the rows in a matrix?
> i.e. make the last row first and the first row last, etc.?
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jjmichael at cc.usu.edu  Tue Aug  9 01:54:05 2005
From: jjmichael at cc.usu.edu (Jacob Michaelson)
Date: Mon, 8 Aug 2005 17:54:05 -0600
Subject: [R] reverse order of matrix rows
In-Reply-To: <200508082335.j78NZSp4019389@hertz.gene.com>
References: <200508082335.j78NZSp4019389@hertz.gene.com>
Message-ID: <F1B39E58-9CD9-414C-9902-26E395B5CBCA@cc.usu.edu>

Thanks to those who provided the one-liner answers!  They worked  
quite well.

I'm quite sure that 95% of the questions posted on this mailing list  
could be answered with a quick..."read the manual, stupid...", but  
I'm very grateful to those who take the time to write one-liners.   I  
know that I have been greatly helped by searching through archived  
questions from other people, which I'm sure to some R gurus must have  
seemed like stupid questions.  But in reality the Mailing List  
archives are an invaluable source of documentation, one that wouldn't  
exist if every question were met with a "go read the manual..."  
response.

--Jake

On Aug 8, 2005, at 5:35 PM, Berton Gunter wrote:


> Quick answer: Read "An Introduction to R" and learn about indexing.
>
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>
> "The business of the statistician is to catalyze the scientific  
> learning
> process."  - George E. P. Box
>
>
>
>
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Jake
>> Sent: Monday, August 08, 2005 2:58 PM
>> To: R-help at stat.math.ethz.ch
>> Subject: [R] reverse order of matrix rows
>>
>> Quick question:  how can I reverse the order of the rows in a
>> matrix?
>> i.e. make the last row first and the first row last, etc.?
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>>
>>
>
>
>
>



From ramasamy at cancer.org.uk  Tue Aug  9 02:01:40 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 09 Aug 2005 01:01:40 +0100
Subject: [R] use different symbols for frequency in a plot
In-Reply-To: <20050808204208.71510.qmail@web51804.mail.yahoo.com>
References: <20050808204208.71510.qmail@web51804.mail.yahoo.com>
Message-ID: <1123545700.31784.49.camel@ipc143004.lif.icnet.uk>

Remove the '6' from the code that contains 'cut'. I am not sure how it
crept into my code. Then you should have the following mapping

	Freq	pch code
	1-5	1
	6-10	2
	11-	3

I am more concerned about viewers getting confused with many symbols
than running out of symbols in R. Looking at the last example in
help("points"), I would say that there are 20-30 usable symbols.
Remember that you can also use text() to put multi-character text.

Regards, Adai



On Mon, 2005-08-08 at 13:42 -0700, Kerry Bush wrote:
> Thank you.
> 
> But I only need three classes of freqnencies (in
> another words, only three kinds of symbols) for 1-5,
> 5-10 and above 10, not to use different symbols for
> different frequencies. Otherwise, clearly R will run
> out of available symbols and the plot is also hard to
> view.
> 
> Thank you anyway.
> 
> --- Adaikalavan Ramasamy <ramasamy at cancer.org.uk>
> wrote:
> 
> > Group by which variable ? If you mean the joint
> > distribution of 'x' and
> > 'y' then something along the following lines
> > 
> >  x <- rep( c(0.1, 0.2, 0.4, 0.5),      c(5, 6, 10,
> > 20) )
> >  y <- rep( c(0.5, 0.6, 1.2, 2.5, 3.0), c(3, 8, 8,
> > 18, 4) )
> > 
> >  new     <- factor( paste(x, y, sep="_") )
> >  tb      <- table(new)
> > 
> >  pchcode <- cut(tb , c(-Inf, 1, 5, 6, 10, Inf),
> > labels=F)
> > 
> >  tmp     <- t( sapply( strsplit( names(tb),
> > split="_") , c ) )
> >  df      <- data.frame( x=tmp[ ,1], y=tmp[ ,2], 
> >                         freq=as.vector(tb), pchcode
> > = pchcode -1 )
> > 
> >      x   y freq pchcode
> >  1 0.1 0.5    3       1
> >  2 0.1 0.6    2       1
> >  3 0.2 0.6    6       2
> >  4 0.4 1.2    8       3
> >  5 0.4 2.5    2       1
> >  6 0.5 2.5   16       4
> >  7 0.5   3    4       1
> > 
> > And now to plot it, we use points() repeatedly.
> > 
> >  plot( as.numeric(df$x), as.numeric(df$y), type="n"
> > )
> > 
> >  for( i in unique( df$pchcode ) ){
> >     w <- which( df$pchcode == i )
> >     points( df$x[w], df$y[w], pch=as.numeric(i) )
> >  }
> > 
> > I am sure someone else will come up with a neater
> > solution.
> > 
> > 
> > Can I also suggest that you try the following
> > 
> >   plot( jitter(x), jitter(y) )
> > 
> > or better still the following
> > 
> >   library(hexbin)
> >   plot( hexbin(x, y) )
> > 
> > 
> > Regards, Adai
> > 
> > On Mon, 2005-08-08 at 11:57 -0700, Kerry Bush wrote:
> > > suppose I have the following data
> > > 
> > > x<-c(rep(.1,5),rep(.2,6),rep(.4,10),rep(.5,20))
> > >
> >
> y<-c(rep(.5,3),rep(.6,8),rep(1.2,8),rep(2.5,18),rep(3,4))
> > > 
> > > If I plot(x,y) in R, I will only get seven
> > distinct
> > > points. What I want to do is to use different
> > symbols
> > > to show the frequency at each point.
> > > 
> > > e.g. if the frequncey is between 1 and 5, then I
> > plot
> > > the point as a circle; if the frequency is between
> > 6
> > > and 10, then I plot the point as a square; if the
> > > frequency is above 10, then I plot the point as a
> > > triangle.
> > > 
> > > I am not sure how to do this in R. Can anybody
> > help me?
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > > 
> > 
> > 
> 
> 
> __________________________________________________
> Do You Yahoo!?
> Tired of spam?  Yahoo! Mail has the best spam protection around 
> http://mail.yahoo.com 
>



From ramasamy at cancer.org.uk  Tue Aug  9 02:04:59 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 09 Aug 2005 01:04:59 +0100
Subject: [R] reverse order of matrix rows
In-Reply-To: <Pine.SGI.4.40.0508081943280.10828189-100000@origin.chass.utoronto.ca>
References: <Pine.SGI.4.40.0508081943280.10828189-100000@origin.chass.utoronto.ca>
Message-ID: <1123545900.31784.52.camel@ipc143004.lif.icnet.uk>

How about simply 

	mat <- mat[ nrow(mat):1, ]

Regards, Adai



On Mon, 2005-08-08 at 19:44 -0400, Jean Eid wrote:
> sapply(nrow(matrix):1, function(x) matrix[x,])
> 
> 
> 
> On Mon, 8 Aug 2005, Jake wrote:
> 
> > Quick question:  how can I reverse the order of the rows in a matrix?
> > i.e. make the last row first and the first row last, etc.?
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ramasamy at cancer.org.uk  Tue Aug  9 02:07:34 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 09 Aug 2005 01:07:34 +0100
Subject: [R] AIC model selection
In-Reply-To: <BAY108-F298843DDD3853F58952D88B7B80@phx.gbl>
References: <BAY108-F298843DDD3853F58952D88B7B80@phx.gbl>
Message-ID: <1123546054.31784.56.camel@ipc143004.lif.icnet.uk>

Are you looking for possibly stepAIC from the package MASS ?

Regards, Adai



On Mon, 2005-08-08 at 16:39 -0600, Martin Kardos wrote:
> Hello All;
> 
> I need to run a multiple regression analysis and use Akaike's Information 
> Criterion for model selection.  I understand that this command will give the 
> AIC value for specified models:
> 
> AIC(object, ..., k = 2)
> 
> with "..." meaning any other optional models for which I would like AIC 
> values.  But, how can I specify (in the place of "...") that I want R to 
> perform an model selection prodecure based on Akaike's Information Criterion 
> on a set of potential independent variables in a model such as:
> 
> model.lm=lm(A~B+C+D+E+F+G)
> 
> ?
> 
> Thanks a million;
> 
> Marty
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From kerryrekky at yahoo.com  Tue Aug  9 02:16:28 2005
From: kerryrekky at yahoo.com (Kerry Bush)
Date: Mon, 8 Aug 2005 17:16:28 -0700 (PDT)
Subject: [R] AIC model selection
In-Reply-To: <1123546054.31784.56.camel@ipc143004.lif.icnet.uk>
Message-ID: <20050809001628.45195.qmail@web51806.mail.yahoo.com>

The last time I used it, the function step() was using
AIC as model selection criteria as the default. It is
in the base package so you don't have to refer to
other fancy functions.

--- Adaikalavan Ramasamy <ramasamy at cancer.org.uk>
wrote:

> Are you looking for possibly stepAIC from the
> package MASS ?
> 
> Regards, Adai
> 
> 
> 
> On Mon, 2005-08-08 at 16:39 -0600, Martin Kardos
> wrote:
> > Hello All;
> > 
> > I need to run a multiple regression analysis and
> use Akaike's Information 
> > Criterion for model selection.  I understand that
> this command will give the 
> > AIC value for specified models:
> > 
> > AIC(object, ..., k = 2)
> > 
> > with "..." meaning any other optional models for
> which I would like AIC 
> > values.  But, how can I specify (in the place of
> "...") that I want R to 
> > perform an model selection prodecure based on
> Akaike's Information Criterion 
> > on a set of potential independent variables in a
> model such as:
> > 
> > model.lm=lm(A~B+C+D+E+F+G)
> > 
> > ?
> > 
> > Thanks a million;
> > 
> > Marty
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From tpapp at Princeton.EDU  Tue Aug  9 07:42:12 2005
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Tue, 9 Aug 2005 07:42:12 +0200
Subject: [R] use different symbols for frequency in a plot
In-Reply-To: <42F7AFD8.5070807@optonline.net>
References: <20050808185744.71396.qmail@web51803.mail.yahoo.com>
	<42F7AFD8.5070807@optonline.net>
Message-ID: <20050809054212.GA32339@tpapp.student.princeton.edu>

On Mon, Aug 08, 2005 at 03:17:44PM -0400, Chuck Cleland wrote:
> You might consider one of these approaches instead:
> 
> plot(jitter(x), jitter(y))
> 
> or
> 
> pdf(file="c:/AlphaExample.pdf", version = "1.4")
> 
> plot(x, y, col = rgb(1, 0, 0, .2), pch = 16)
> 
> dev.off()

sunflowerplot() is also useful for this (although it won't be as elegant as
the pdf with alpha on screen, it looks better on paper).

Tamas



From ripley at stats.ox.ac.uk  Tue Aug  9 08:24:02 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 9 Aug 2005 07:24:02 +0100 (BST)
Subject: [R] Help with "non-integer #successes in a binomial glm"
In-Reply-To: <20050808210649.13589.qmail@web31009.mail.mud.yahoo.com>
References: <20050808210649.13589.qmail@web31009.mail.mud.yahoo.com>
Message-ID: <Pine.LNX.4.61.0508090720020.6010@gannet.stats>

On Mon, 8 Aug 2005, Haibo Huang wrote:

> I had a logit regression, but don't really know how to
> handle the "Warning message: non-integer #successes in
> a binomial glm! in: eval(expr, envir, enclos)"
> problem. I had the same logit regression without
> weights and it worked out without the warning, but I
> figured it makes more sense to add the weights. The
> weights sum up to one.

Weights are case weights in a binomial GLM, that is w_i means `I have w_i 
of these'.  Do check out the theory in MASS (the book) or Nelder & 
McCullagh.  There are some circumstances when fractional weights make 
sense (when this doing something other than fitting a glm, e.g. part of a 
`mixture of experts' model) but they are unusual, hence the warning.

>
> Could anyone give me some hint? Thanks a lot!
>
> FYI, I have posted both regressions (with and without
> weights) below.
>
> Ed
>
>
>> setwd("P:/Work in Progress/Haibo/Hans")
>>
>> Lease=read.csv("lease.csv", header=TRUE)
>> Lease$ET <- factor(Lease$EarlyTermination)
>> SICCode=factor(Lease$SIC.Code)
>> Lease$TO=factor(Lease$TenantHasOption)
>> Lease$LO=factor(Lease$LandlordHasOption)
>> Lease$TEO=factor(Lease$TenantExercisedOption)
>>
>> RegA=glm(ET~1+TO,
> + family=binomial(link=logit), data=Lease)
>> summary(RegA)
>
> Call:
> glm(formula = ET ~ 1 + TO, family = binomial(link =
> logit), data = Lease)
>
> Deviance Residuals:
>    Min       1Q   Median       3Q      Max
> -0.5839  -0.5839  -0.5839  -0.3585   2.3565
>
> Coefficients:
>            Estimate Std. Error z value Pr(>|z|)
> (Intercept) -1.68271    0.02363  -71.20   <2e-16 ***
> TO1         -1.02959    0.09012  -11.43   <2e-16 ***
> ---
> Signif. codes:  0 `***' 0.001 `**' 0.01 `*' 0.05 `.'
> 0.1 ` ' 1
>
> (Dispersion parameter for binomial family taken to be
> 1)
>
>    Null deviance: 12987  on 15809  degrees of freedom
> Residual deviance: 12819  on 15808  degrees of freedom
> AIC: 12823
>
> Number of Fisher Scoring iterations: 5
>
>> setwd("P:/Work in Progress/Haibo/Hans")
>>
>> Lease=read.csv("lease.csv", header=TRUE)
>> Lease$ET <- factor(Lease$EarlyTermination)
>> SICCode=factor(Lease$SIC.Code)
>> Lease$TO=factor(Lease$TenantHasOption)
>> Lease$LO=factor(Lease$LandlordHasOption)
>> Lease$TEO=factor(Lease$TenantExercisedOption)
>>
>> RegA=glm(ET~1+TO,
> + family=binomial(link=logit), data=Lease,
> weights=PortionSF)
> Warning message:
> non-integer #successes in a binomial glm! in:
> eval(expr, envir, enclos)
>> summary(RegA)
>
> Call:
> glm(formula = ET ~ 1 + TO, family = binomial(link =
> logit), data = Lease,
>    weights = PortionSF)
>
> Deviance Residuals:
>      Min         1Q     Median         3Q        Max
>
> -0.055002  -0.003434   0.000000   0.000000   0.120656
>
>
> Coefficients:
>            Estimate Std. Error z value Pr(>|z|)
> (Intercept)   -1.120      2.618  -0.428    0.669
> TO1           -1.570      9.251  -0.170    0.865
>
> (Dispersion parameter for binomial family taken to be
> 1)
>
>    Null deviance: 1.0201  on 9302  degrees of freedom
> Residual deviance: 0.9787  on 9301  degrees of freedom
> AIC: 4
>
> Number of Fisher Scoring iterations: 5

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Aug  9 08:27:56 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 9 Aug 2005 07:27:56 +0100 (BST)
Subject: [R] AIC model selection
In-Reply-To: <BAY108-F298843DDD3853F58952D88B7B80@phx.gbl>
References: <BAY108-F298843DDD3853F58952D88B7B80@phx.gbl>
Message-ID: <Pine.LNX.4.61.0508090724400.6010@gannet.stats>

First, AIC is `An Information Criterion' according to Akaike.

Second, help.search("AIC") turns up

stepAIC(MASS)           Choose a model by AIC in a Stepwise Algorithm
multinom(nnet)          Fit Multinomial Log-linear Models
mosaicplot(graphics)    Mosaic Plots
AIC(stats)              Akaike's An Information Criterion
extractAIC(stats)       Extract AIC from a Fitted Model
step(stats)             Choose a model by AIC in a Stepwise Algorithm
AIC-methods(stats4)     Methods for Function 'AIC' in Package 'stats4'
frailty(survival)       (Approximate) Frailty models

Did you not notice that two of those are answers to your question?


On Mon, 8 Aug 2005, Martin Kardos wrote:

> Hello All;
>
> I need to run a multiple regression analysis and use Akaike's Information
> Criterion for model selection.  I understand that this command will give the
> AIC value for specified models:
>
> AIC(object, ..., k = 2)
>
> with "..." meaning any other optional models for which I would like AIC
> values.  But, how can I specify (in the place of "...") that I want R to
> perform an model selection prodecure based on Akaike's Information Criterion
> on a set of potential independent variables in a model such as:
>
> model.lm=lm(A~B+C+D+E+F+G)
>
> ?
>
> Thanks a million;
>
> Marty
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Aug  9 08:30:24 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 9 Aug 2005 07:30:24 +0100 (BST)
Subject: [R] two term exponential model
In-Reply-To: <003f01c59c67$6023a340$1b0bc80a@msrc.mc.vanderbilt.edu>
References: <003f01c59c67$6023a340$1b0bc80a@msrc.mc.vanderbilt.edu>
Message-ID: <Pine.LNX.4.61.0508090728200.6010@gannet.stats>

On Mon, 8 Aug 2005, Deming Mi wrote:

> Does anybody know if there is an R function (package) to fit a two-terms
> exponential model like y = a*exp(bx) + c*exp(dx) where y is dependent
> variable and x is independent variable.  MATLAB has a Curve Fitting Toolbox
> to implement this fitting, but I don't know if there is an R package for
> this fitting.  Thank you!

See ?nls

>From my experience with such models the coefficients are often not 
well-determined and so you need a good starting point.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jarioksa at sun3.oulu.fi  Tue Aug  9 09:22:36 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Tue, 09 Aug 2005 10:22:36 +0300
Subject: [R] INDVAL and mvpart
In-Reply-To: <1123509778.42f76612311cd@www.ps.pl>
References: <1123509778.42f76612311cd@www.ps.pl>
Message-ID: <1123572156.16069.5.camel@biol102145.oulu.fi>

Agnieszka,

Package 'mvpart' is documented. In this case, ?rpart.object explains
*where* in the rpart object is the membership vector.

cheers, jari oksanen

On Mon, 2005-08-08 at 16:02 +0200, astrzelczak at ps.pl wrote:
> Hi,
> 
> I'd like to perform Dufrene-Legendre Indicator Species Analysis for
> a multivariate regression tree. However I have problems with arguments
> of duleg(veg,class,numitr=1000)function. How to obtain  a vector of
> numeric class memberships for samples, or a classification object
> returned from mvpart?

-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/



From alxmilton at yahoo.it  Tue Aug  9 09:58:25 2005
From: alxmilton at yahoo.it (alessandro carletti)
Date: Tue, 9 Aug 2005 00:58:25 -0700 (PDT)
Subject: [R] more on vector vs array
In-Reply-To: <1123523872.30584.72.camel@ipc143004.lif.icnet.uk>
Message-ID: <20050809075825.51170.qmail@web26607.mail.ukl.yahoo.com>


Ok, thanks,
I'll try with a simplier example:

I have a vector with 4 levels

dataframe 1
station   temp
aaa        12
aaa        13
bbb        12
bbb        20
aaa        23
bbb        21
ccc        30
ccc        18
ddd        15
aaa        11
ddd        15
ddd        10


and a thresholds vector

station    thr  
aaa         20
bbb         18
ccc         25
ddd         10


I vant to select from dataframe 1 each value (level by
level) > its own threshold value.
How to do it automatically? (vector temp and vector
thr have different length)

Thanks



From u08adh at hotmail.com  Mon Aug  8 23:49:09 2005
From: u08adh at hotmail.com (Andreas Hary)
Date: Mon, 8 Aug 2005 22:49:09 +0100
Subject: [R] Reading large files in R
References: <200508081935.j78JZq1M017285@hertz.gene.com>
Message-ID: <BAY103-DAV14B1D66C6BA53CD2FBEFEEDFB80@phx.gbl>

You can also use the RODBC package to hold the data in a database, say MySQL 
and only import it when you do the modelling, e.g.

> library(RODBC)
> library(sspir)
> con <- odbcConnect("MySQL Test")
> data(vandrivers)
> sqlSave(con,dat=vandrivers,append=FALSE)
> rm(vandrivers)
> gc()
> van.call <- sqlQuery(con,'select * from vandrivers;')
> vd <- ssm( y ~ tvar(1) + seatbelt + sumseason(time,12),
>           time=time, family=poisson(link="log"),
>           data=eval(van.call))
> vd$ss$phi["(Intercept)"] <- exp(- 2*3.703307 )
> vd$ss$C0 <- diag(13)*1000
> vd.res <- kfs(vd)
> gc()

In this case I have first saved the vandriver data in 'MySQL Test', but one 
can obviously write the data directly to the database. Since the data is not 
held in memory I find that I can do much larger computations than is 
otherwise possible. The downside is of course that computations take a bit 
longer.
Best wishes,

Andreas

=====================
Andreas D Hary
Email:    u08adh at hotmail.com
Mobile:   07906860987
Phone:   02076554940




----- Original Message ----- 
From: "Berton Gunter" <gunter.berton at gene.com>
To: <ramasamy at cancer.org.uk>; "'Jean-Pierre Gattuso'" <gattuso at obs-vlfr.fr>
Cc: <r-help at stat.math.ethz.ch>
Sent: Monday, August 08, 2005 8:35 PM
Subject: Re: [R] Reading large files in R


> ... and it is likely that even if you did have enough memory (several 
> times
> the size of the data are generally needed) it would take a very long time.
>
> If you do have enough memory and the data are all of one type -- numeric
> here -- you're better off treating it as a matrix rather than converting 
> it
> to a data frame.
>
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
>
>
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
>> Adaikalavan Ramasamy
>> Sent: Monday, August 08, 2005 12:02 PM
>> To: Jean-Pierre Gattuso
>> Cc: r-help at stat.math.ethz.ch
>> Subject: Re: [R] Reading large files in R
>>
>> >From Note section of help("read.delim") :
>>
>>      'read.table' is not the right tool for reading large matrices,
>>      especially those with many columns: it is designed to read _data
>>      frames_ which may have columns of very different classes. Use
>>      'scan' instead.
>>
>> So I am not sure why you used 'scan', then converted it to a
>> data frame.
>>
>> 1) Can provide an sample of the data that you are trying to read in.
>> 2) How much memory does your machine has ?
>> 3) Try reading in the first few lines using the nmax argument in scan.
>>
>> Regards, Adai
>>
>>
>>
>> On Mon, 2005-08-08 at 12:50 -0600, Jean-Pierre Gattuso wrote:
>> > Dear R-listers:
>> >
>> > I am trying to work with a big (262 Mb) file but apparently
>> reach a
>> > memory limit using R on a MacOSX as well as on a unix machine.
>> >
>> > This is the script:
>> >
>> >  > type=list(a=0,b=0,c=0)
>> >  > tmp <- scan(file="coastal_gebco_sandS_blend.txt", what=type,
>> > sep="\t", quote="\"", dec=".", skip=1, na.strings="-99",
>> nmax=13669628)
>> > Read 13669627 records
>> >  > gebco <- data.frame(tmp)
>> > Error: cannot allocate vector of size 106793 Kb
>> >
>> >
>> > Even tmp does not seem right:
>> >
>> >  > summary(tmp)
>> > Error: recursive default argument reference
>> >
>> >
>> > Do you have any suggestion?
>> >
>> > Thanks,
>> > Jean-Pierre Gattuso
>> >
>> > ______________________________________________
>> > R-help at stat.math.ethz.ch mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>> >
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From dimitris.rizopoulos at med.kuleuven.be  Tue Aug  9 10:19:37 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 9 Aug 2005 10:19:37 +0200
Subject: [R] more on vector vs array
References: <20050809075825.51170.qmail@web26607.mail.ukl.yahoo.com>
Message-ID: <002d01c59cbb$15787380$0540210a@www.domain>

you could use something like this:

dat1 <- data.frame(station = rep(letters[1:5], 4), temp = 
round(rnorm(20, 15, 3)))
dat2 <- data.frame(station = letters[1:5], temp = round(rnorm(5, 15, 
4)))
################
dat <- merge(dat1, dat2, by = "station")
do.call("rbind", lapply(split(dat, dat$station), function(x){
        out <- x[x$temp.x > x$temp.y, ]
        if(nrow(out)) out else rep(NA, length(x))
    }))


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "alessandro carletti" <alxmilton at yahoo.it>
To: "rHELP" <R-help at stat.math.ethz.ch>
Sent: Tuesday, August 09, 2005 9:58 AM
Subject: [R] more on vector vs array


>
> Ok, thanks,
> I'll try with a simplier example:
>
> I have a vector with 4 levels
>
> dataframe 1
> station   temp
> aaa        12
> aaa        13
> bbb        12
> bbb        20
> aaa        23
> bbb        21
> ccc        30
> ccc        18
> ddd        15
> aaa        11
> ddd        15
> ddd        10
>
>
> and a thresholds vector
>
> station    thr
> aaa         20
> bbb         18
> ccc         25
> ddd         10
>
>
> I vant to select from dataframe 1 each value (level by
> level) > its own threshold value.
> How to do it automatically? (vector temp and vector
> thr have different length)
>
> Thanks
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Ted.Harding at nessie.mcc.ac.uk  Tue Aug  9 09:42:04 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 09 Aug 2005 08:42:04 +0100 (BST)
Subject: [R] two term exponential model
In-Reply-To: <Pine.LNX.4.61.0508090728200.6010@gannet.stats>
Message-ID: <XFMail.050809084204.Ted.Harding@nessie.mcc.ac.uk>

On 09-Aug-05 Prof Brian Ripley wrote:
> On Mon, 8 Aug 2005, Deming Mi wrote:
> 
>> Does anybody know if there is an R function (package) to fit a
>> two-terms exponential model like y = a*exp(bx) + c*exp(dx)
>> where y is dependent variable and x is independent variable.
>> MATLAB has a Curve Fitting Toolbox to implement this fitting,
>> but I don't know if there is an R package for this fitting.
>> Thank you!
> 
> See ?nls
> 
>>From my experience with such models the coefficients are often not 
> well-determined and so you need a good starting point.

I concur with this remark. While the determination does depend on
the anmount of random error around the curve, the plain fact is
that often this error is such that there is little difference
in fit between the two-term exponential and a single-term exponential,
or between different 2-term models with substantially different
exponential terms (and it can get worse with more terms).

I would strongly recommend creating profile-likelihood plots
for say (with your parametrisation above) "a" vs "c", "b" vs "d",
etc., using the log-likelihood for the MLE as reference, and drawing
contours at levels corresponding to P-values (e.g. 75%, 50%, 25%,
10%, 5%) of the chisquare on 2 d.f. for (e.g.) the function of (b,d)

  -2*log(L(b,d,ahat(b,d),chat(b,d))) + 2*log(L(aHat,cHat,bHat,dHat))

where ahat(b,d) and chat(b,d) are the MLEs of a and c at fixed
b and d, and aHat, cHat, bHat, dHat are the unrestricted MLEs,
and similar for (a,c).

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 09-Aug-05                                       Time: 08:34:06
------------------------------ XFMail ------------------------------



From dargosch at gmail.com  Tue Aug  9 10:29:36 2005
From: dargosch at gmail.com (Fredrik Karlsson)
Date: Tue, 9 Aug 2005 10:29:36 +0200
Subject: [R] Groups in histograms?
In-Reply-To: <376e97ec05080805066022332f@mail.gmail.com>
References: <376e97ec05080804263ea2b05d@mail.gmail.com>
	<dd6040c905080804377c7da379@mail.gmail.com>
	<376e97ec05080805066022332f@mail.gmail.com>
Message-ID: <376e97ec05080901291dd5b00@mail.gmail.com>

Dear list,

Sorry for answering my own post, but I have had partial sucess in
this. With the panel function below, I get separate histograms in each
panel using the group argument.

histogram(~vot | agem, nint=50,data=work,groups=Type, subset=agem > 24
& agem < 30, panel=panel.grouphist,type="count",ylim=c(0,20),auto.key=T)

panel.grouphist <- function(x,groups,...){
  add <- T
  grouplevels <- unique(groups)
  ngroups <- length(grouplevels)
  
  for(i in 1:ngroups){
    gcol <- trellis.par.get("superpose.fill")$col[i]
    gx <- x[groups == grouplevels[i]]
    panel.histogram(gx,col=gcol,...)
  }

}

However, the color I get in the key using simpleKey is not the same as
the one in the the plot.
How do I get the two functions to use the same color scale?

/Fredrik

On 8/8/05, Fredrik Karlsson <dargosch at gmail.com> wrote:
> Hi Gary,
> 
> I have found this, but it is not exactly what I am looking for.
> What I need is the groups to be inside of a single panel, not in
> different panels.
> Kind of like an histogram version of the xyplot(Y ~ X1,
> groups=X2,panel=panel.superpose) command. (I hope this is correct).
> 
> /Fredrik
> 
> On 8/8/05, Gary Collins <collins.gs at gmail.com> wrote:
> > Have a look at the "histogram" function in the Lattice package.
> >
> > if x are your data to be displayed and y is your grouping variable you
> > can just do
> >
> > > histogram(~x|y)
> >
> > HTH
> > Gary
> >
> > On 08/08/05, Fredrik Karlsson <dargosch at gmail.com> wrote:
> > > Dear list,
> > >
> > > I would like to create histograms for up to three groups, with
> > > distincive colour/pattern, in a trellis panel. However, I have not
> > > been able to find a way to do this. histogram does not seem to have a
> > > group argument.
> > >
> > > Please help.
> > >
> > > /Fredrik
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > >
> >



From shv736 at yahoo.com  Tue Aug  9 10:55:18 2005
From: shv736 at yahoo.com (Vassily Shvets)
Date: Tue, 9 Aug 2005 01:55:18 -0700 (PDT)
Subject: [R] archive of models
Message-ID: <20050809085518.6400.qmail@web52307.mail.yahoo.com>

I'm wondering if there's a possibility of having a
bunch of models that have already been assembled and
run using R, that might be available to users? My own
interest is in AR and msm models, but examples  would
seem to be of great use to all kinds of statistical
analyses with R-- surely "a picture is worth a
thousand words"?

thanks,
russell
(I've noticed that someone is asking about the archive
in Australia, but this seems to be a little complex
and perhaps not dependable. I'm thinking of something
like the PDF "Introduction to R", but with worked
examples. Or maybe someone has some worked examples
they wouldn't mind publishing on the list...?)



From pburns at pburns.seanet.com  Tue Aug  9 11:16:15 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 09 Aug 2005 10:16:15 +0100
Subject: [R] more on vector vs array
In-Reply-To: <20050809075825.51170.qmail@web26607.mail.ukl.yahoo.com>
References: <20050809075825.51170.qmail@web26607.mail.ukl.yahoo.com>
Message-ID: <42F8745F.1090905@pburns.seanet.com>

If 'thr' were a vector with the stations as names,
then you could do (untested):

above <- dataframe1[, 'temp'] > thr[as.character(dataframe1[, 'station'])]

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

alessandro carletti wrote:

>Ok, thanks,
>I'll try with a simplier example:
>
>I have a vector with 4 levels
>
>dataframe 1
>station   temp
>aaa        12
>aaa        13
>bbb        12
>bbb        20
>aaa        23
>bbb        21
>ccc        30
>ccc        18
>ddd        15
>aaa        11
>ddd        15
>ddd        10
>
>
>and a thresholds vector
>
>station    thr  
>aaa         20
>bbb         18
>ccc         25
>ddd         10
>
>
>I vant to select from dataframe 1 each value (level by
>level) > its own threshold value.
>How to do it automatically? (vector temp and vector
>thr have different length)
>
>Thanks
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From astrzelczak at ps.pl  Tue Aug  9 11:34:52 2005
From: astrzelczak at ps.pl (astrzelczak@ps.pl)
Date: Tue,  9 Aug 2005 11:34:52 +0200
Subject: [R] INDVAL and mvpart
Message-ID: <1123580092.42f878bc92a3a@www.ps.pl>


Hello Jari,

I've tried to do the analysis this way:

> duleg(data.matrix(dane[,9:28]),predict(fit,type="vector"),numitr=1000)
Error in "row.names<-.data.frame"(`*tmp*`, value = NULL) :
        invalid 'row.names' length

I haven o idea what's going on with the row names....

cheers  :)
Agnieszka


Tuesday, August 9, 2005, 9:22:36 AM, you wrote:

>> Hi,
>>
>> I'd like to perform Dufrene-Legendre Indicator Species Analysis for
>> a multivariate regression tree. However I have problems with arguments
>> of duleg(veg,class,numitr=1000)function. How to obtain  a vector of
>> numeric class memberships for samples, or a classification object
>> returned from mvpart?


--
Best regards,

 Agnieszka Strzelczak                         mailto:astrzelczak at ps.pl



From ramasamy at cancer.org.uk  Tue Aug  9 11:52:00 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 09 Aug 2005 10:52:00 +0100
Subject: [R] AIC model selection
In-Reply-To: <20050809001628.45195.qmail@web51806.mail.yahoo.com>
References: <20050809001628.45195.qmail@web51806.mail.yahoo.com>
Message-ID: <1123581121.32762.9.camel@ipc143004.lif.icnet.uk>

True. But from the "Note" section of help(step) :

     This is a minimal implementation. Use 'stepAIC' in package 'MASS'
     for a wider range of object classes.


And from author(s) section :

     B. D. Ripley: 'step' is a slightly simplified version of 'stepAIC'
     in package 'MASS' (Venables & Ripley, 2002 and earlier editions).


I am not sure why the simplification was necessary but I would prefer
the slightly more comprehensive version. Besides I like the word AIC
reflected in the function of the name as it is using AIC criterion to do
stepwise selection.

Regards, Adai



On Mon, 2005-08-08 at 17:16 -0700, Kerry Bush wrote:
> The last time I used it, the function step() was using
> AIC as model selection criteria as the default. It is
> in the base package so you don't have to refer to
> other fancy functions.
> 
> --- Adaikalavan Ramasamy <ramasamy at cancer.org.uk>
> wrote:
> 
> > Are you looking for possibly stepAIC from the
> > package MASS ?
> > 
> > Regards, Adai
> > 
> > 
> > 
> > On Mon, 2005-08-08 at 16:39 -0600, Martin Kardos
> > wrote:
> > > Hello All;
> > > 
> > > I need to run a multiple regression analysis and
> > use Akaike's Information 
> > > Criterion for model selection.  I understand that
> > this command will give the 
> > > AIC value for specified models:
> > > 
> > > AIC(object, ..., k = 2)
> > > 
> > > with "..." meaning any other optional models for
> > which I would like AIC 
> > > values.  But, how can I specify (in the place of
> > "...") that I want R to 
> > > perform an model selection prodecure based on
> > Akaike's Information Criterion 
> > > on a set of potential independent variables in a
> > model such as:
> > > 
> > > model.lm=lm(A~B+C+D+E+F+G)
> > > 
> > > ?
> > > 
> > > Thanks a million;
> > > 
> > > Marty
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > 
> 
> 
> 
> 		
> ____________________________________________________
> Start your day with Yahoo! - make it your home page 
> http://www.yahoo.com/r/hs 
> 
>



From ramasamy at cancer.org.uk  Tue Aug  9 12:05:28 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 09 Aug 2005 11:05:28 +0100
Subject: [R] more on vector vs array
In-Reply-To: <002d01c59cbb$15787380$0540210a@www.domain>
References: <20050809075825.51170.qmail@web26607.mail.ukl.yahoo.com>
	<002d01c59cbb$15787380$0540210a@www.domain>
Message-ID: <1123581929.32762.14.camel@ipc143004.lif.icnet.uk>

Nice one. But I think you could replace the last line (the one with
do.call) with the simpler

 w <- which( dat[ ,2] > dat[ ,3] )
 w
 [1]  6 11 13 14 16 18 20

 dat[ w, ]
    station temp.x temp.y
 6        b     18     16
 11       c     17     15
 13       d     16     14
 14       d     17     14
 16       d     17     14
 18       e     16     15
 20       e     19     15

Thank you.

Regards, Adai



On Tue, 2005-08-09 at 10:19 +0200, Dimitris Rizopoulos wrote:
> you could use something like this:
> 
> dat1 <- data.frame(station = rep(letters[1:5], 4), temp = 
> round(rnorm(20, 15, 3)))
> dat2 <- data.frame(station = letters[1:5], temp = round(rnorm(5, 15, 
> 4)))
> ################
> dat <- merge(dat1, dat2, by = "station")
> do.call("rbind", lapply(split(dat, dat$station), function(x){
>         out <- x[x$temp.x > x$temp.y, ]
>         if(nrow(out)) out else rep(NA, length(x))
>     }))
> 
> 
> I hope it helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/336899
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.be/biostat/
>      http://www.student.kuleuven.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message ----- 
> From: "alessandro carletti" <alxmilton at yahoo.it>
> To: "rHELP" <R-help at stat.math.ethz.ch>
> Sent: Tuesday, August 09, 2005 9:58 AM
> Subject: [R] more on vector vs array
> 
> 
> >
> > Ok, thanks,
> > I'll try with a simplier example:
> >
> > I have a vector with 4 levels
> >
> > dataframe 1
> > station   temp
> > aaa        12
> > aaa        13
> > bbb        12
> > bbb        20
> > aaa        23
> > bbb        21
> > ccc        30
> > ccc        18
> > ddd        15
> > aaa        11
> > ddd        15
> > ddd        10
> >
> >
> > and a thresholds vector
> >
> > station    thr
> > aaa         20
> > bbb         18
> > ccc         25
> > ddd         10
> >
> >
> > I vant to select from dataframe 1 each value (level by
> > level) > its own threshold value.
> > How to do it automatically? (vector temp and vector
> > thr have different length)
> >
> > Thanks
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Torsten.Schindler at chello.at  Tue Aug  9 12:22:24 2005
From: Torsten.Schindler at chello.at (Torsten Schindler)
Date: Tue, 9 Aug 2005 12:22:24 +0200
Subject: [R] How to pre-filter large amounts of data effectively
Message-ID: <FF4B73D7-2D7E-4D25-A2CD-FD14014701CB@chello.at>

Hi,

I'm a R newbie and want to accelerate the following pre-filtering  
step of a data set with more than 115,000 rows :

#-----------------
# Function to filter out constant data columns
filter.const<-function(X, vectors=c('column', 'row'), tol=0){
   realdata=c()
   filteredX<-matrix()
   if( vectors[1] == 'row' ){
     for( row in (1:nrow(X)) ){
       if( length(which(X[row,]!=median(X[row,])))>tol ){
         realdata[length(realdata)+1]=row
       }
     }
     filteredX=X[realdata,]
   } else if( vectors[1] == 'column' ){
     for( col in (1:ncol(X)) ){
       if( length(which(X[,col]!=median(X[,col])))>tol ){
         realdata[length(realdata)+1]=col
       }
     }
     filteredX=X[,realdata]
   }
   return(list(x=filteredX, ix=realdata))
}

#-----------------
# Filter out all all-constant columns in my training data set
#
# Read training data set with class information in the first column
training <- read.csv('training_data.txt')
dim(training) # => 49 rows and 525 columns

# Prepare column names by stripping the underline and the number at  
the end
colnames(training) <- sub('_\\d+$', '', colnames(training), perl=TRUE)

# Filter out the all-constant columns, exclude column 1, the class  
column called myclass
training.filter <- filter.const(training[,-1])

# The filtered data frame is
training.filtered <- cbind(myclass=training[,1], training.filter$x)
dim(training.filtered) # => 49 rows and 250 columns

# Save the filtered training set for later use in classification
filtered.data <- 'training_set_filtered.Rdata'
save(training.filtered, file=filtered.data)

#-----------------
# THE FOLLOWING FILTERING STEP TAKES 3 HOUR ON MY PowerBook
# AND CONSUMES ABOUT 600 Mb MEMORY.
#
# I WOULD BE HAPPY ABOUT ANY HINT HOW TO IMPROVE THIS.

# Pre-filter the big data set (more than 115,000 rows and 524  
columns) for later class predictions.
# The big data set contains the same column names as the training  
set, but in a different order.

input.file <- 'big_data_set.txt'
filtered.file <- 'big_data_set_filtered.txt'

# Read header with first row
prediction.set <- read.csv(input.file, header=TRUE, skip=0, nrow=1)

# Prepare column names by stripping the underline and the number at  
the end
colnames(prediction.set) <- sub('_\\d+$', '', colnames 
(prediction.set), perl=TRUE)
prediction.set.header <- colnames(prediction.set)

# Get descriptor columns of the training data set without the  
Activity_Class column
training.filtered.property.colnames <- colnames(training.filtered)[-1]

# Filter out the all-constant columns from the training set
prediction.set.filtered <- prediction.set 
[training.filtered.property.colnames]
dim(prediction.set.filtered) # => 1 row and 249 columns

# Write header and the first filtered row
write.csv(prediction.set.filtered, file=filtered.file,
             append=FALSE,  
col.names=training.filtered.property.colnames)

blocksize <- 1000
for (lineid in (0:120)*blocksize) {
   cat('lineid: ', lineid, '\n')

   # Read block of data
   # We have to add an dummy colname "x" in the col.names, when the  
header is not read!
   prediction.set <- try(read.csv(input.file, header=FALSE,
                         col.names=c('x',prediction.set.header),  
row.names=1,
                         skip=lineid+2, nrow=blocksize))
   if (class(prediction.set) == "try-error") break

   # Filter out all-constant training set columns from the block
   prediction.set.filtered <- prediction.set 
[training.filtered.property.colnames]

   # Append the data
   # (I know this function is slow, but I couldn't figure out how to  
do it faster, so far.)
   write.table(prediction.set.filtered, file=filtered.file,
                         append=TRUE, col.names=FALSE, sep=",")
}

#-------------
# Now read in the filtered data set and save it for later use in  
classification
prediction.set.filtered <- read.csv(filtered.file, header=TRUE,  
row.names=1)
filtered.data <- 'prediction_set_filtered.Rdata'
save(prediction.set.filtered, file=filtered.data)



I would be very happy about any hints how to improve the code above!!!

Best regards,

Torsten



From francoisromain at free.fr  Tue Aug  9 12:48:43 2005
From: francoisromain at free.fr (Romain Francois)
Date: Tue, 09 Aug 2005 12:48:43 +0200
Subject: [R] use of color for hclust
In-Reply-To: <20050805204152.80806.qmail@web54505.mail.yahoo.com>
References: <20050805204152.80806.qmail@web54505.mail.yahoo.com>
Message-ID: <42F88A0B.5060603@free.fr>

Le 05.08.2005 22:41, Globe Trotter a ??crit :

>Hi,
>
>I have a grouping of some observations. I want to cluster them using
>hierarchical clustering and compare how the hierarchical clustering shows up
>vis-a-vis the groupings. Is it possible to do this in color? I guess what I am
>looking for is a way to color the labels of a hierarchical clustering plot
>using different colors according to the original grouping. Any suggestions?
>
>Many thanks and best wishes!
>  
>
Hello,

Sorry I'm late on that thread. I just started to make fun with package 
creation. Here you can find the A2R package (really a first draft 
actually) that may answer your neads: http://addictedtor.free.fr/packages/
Comments and feedback are allways welcome.

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From Torsten.Schindler at chello.at  Tue Aug  9 12:53:50 2005
From: Torsten.Schindler at chello.at (Torsten Schindler)
Date: Tue, 9 Aug 2005 12:53:50 +0200
Subject: [R] How to pre-filter large amounts of data effectively
In-Reply-To: <42F8875F.3010708@pburns.seanet.com>
References: <FF4B73D7-2D7E-4D25-A2CD-FD14014701CB@chello.at>
	<42F8875F.3010708@pburns.seanet.com>
Message-ID: <FE0601B3-424D-42CA-AC10-1348BFB27C65@chello.at>

You are right, but unfortunately this is not the limiting step or  
bottleneck in the code below.
The filter.const() function is only used to get the non-constant  
columns in the
training data set, which is initially small (49 rows and 525 columns).
And this function is only applied for filtering the training set and  
takes about 2 seconds on my PowerBook.
After filtering the training data set, just the list of column names  
is used to filter the huge "prediction.set".
I think, the really time and memory consuming part is the for-loop  
below, but I don't know how to improve this part.

Anyway, thanks for the hint!!!

Best,
Torsten

On Aug 9, 2005, at 12:37 PM, Patrick Burns wrote:

> Building up an object like you do with 'realdata' is very
> wasteful (S Poetry says why).  I think you want something
> along the lines of:
>
> if(vectors[1] == 'column') {
>    realdata <- apply(X, 2, function(x) diff(range(x))) > tol
>    filteredX <- X[, realdata]
> } else {
>    realdata <- apply(X, 1, function(x) diff(range(x))) > tol
>    filteredX <- X[realdata, ]
> }
>
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
>
> Torsten Schindler wrote:
>
>
>> Hi,
>>
>> I'm a R newbie and want to accelerate the following pre-filtering   
>> step of a data set with more than 115,000 rows :
>>
>> #-----------------
>> # Function to filter out constant data columns
>> filter.const<-function(X, vectors=c('column', 'row'), tol=0){
>>   realdata=c()
>>   filteredX<-matrix()
>>   if( vectors[1] == 'row' ){
>>     for( row in (1:nrow(X)) ){
>>       if( length(which(X[row,]!=median(X[row,])))>tol ){
>>         realdata[length(realdata)+1]=row
>>       }
>>     }
>>     filteredX=X[realdata,]
>>   } else if( vectors[1] == 'column' ){
>>     for( col in (1:ncol(X)) ){
>>       if( length(which(X[,col]!=median(X[,col])))>tol ){
>>         realdata[length(realdata)+1]=col
>>       }
>>     }
>>     filteredX=X[,realdata]
>>   }
>>   return(list(x=filteredX, ix=realdata))
>> }
>>
>> #-----------------
>> # Filter out all all-constant columns in my training data set
>> #
>> # Read training data set with class information in the first column
>> training <- read.csv('training_data.txt')
>> dim(training) # => 49 rows and 525 columns
>>
>> # Prepare column names by stripping the underline and the number  
>> at  the end
>> colnames(training) <- sub('_\\d+$', '', colnames(training),  
>> perl=TRUE)
>>
>> # Filter out the all-constant columns, exclude column 1, the  
>> class  column called myclass
>> training.filter <- filter.const(training[,-1])
>>
>> # The filtered data frame is
>> training.filtered <- cbind(myclass=training[,1], training.filter$x)
>> dim(training.filtered) # => 49 rows and 250 columns
>>
>> # Save the filtered training set for later use in classification
>> filtered.data <- 'training_set_filtered.Rdata'
>> save(training.filtered, file=filtered.data)
>>
>> #-----------------
>> # THE FOLLOWING FILTERING STEP TAKES 3 HOUR ON MY PowerBook
>> # AND CONSUMES ABOUT 600 Mb MEMORY.
>> #
>> # I WOULD BE HAPPY ABOUT ANY HINT HOW TO IMPROVE THIS.
>>
>> # Pre-filter the big data set (more than 115,000 rows and 524   
>> columns) for later class predictions.
>> # The big data set contains the same column names as the training   
>> set, but in a different order.
>>
>> input.file <- 'big_data_set.txt'
>> filtered.file <- 'big_data_set_filtered.txt'
>>
>> # Read header with first row
>> prediction.set <- read.csv(input.file, header=TRUE, skip=0, nrow=1)
>>
>> # Prepare column names by stripping the underline and the number  
>> at  the end
>> colnames(prediction.set) <- sub('_\\d+$', '', colnames  
>> (prediction.set), perl=TRUE)
>> prediction.set.header <- colnames(prediction.set)
>>
>> # Get descriptor columns of the training data set without the   
>> Activity_Class column
>> training.filtered.property.colnames <- colnames(training.filtered) 
>> [-1]
>>
>> # Filter out the all-constant columns from the training set
>> prediction.set.filtered <- prediction.set  
>> [training.filtered.property.colnames]
>> dim(prediction.set.filtered) # => 1 row and 249 columns
>>
>> # Write header and the first filtered row
>> write.csv(prediction.set.filtered, file=filtered.file,
>>             append=FALSE,   
>> col.names=training.filtered.property.colnames)
>>
>> blocksize <- 1000
>> for (lineid in (0:120)*blocksize) {
>>   cat('lineid: ', lineid, '\n')
>>
>>   # Read block of data
>>   # We have to add an dummy colname "x" in the col.names, when  
>> the  header is not read!
>>   prediction.set <- try(read.csv(input.file, header=FALSE,
>>                         col.names=c('x',prediction.set.header),   
>> row.names=1,
>>                         skip=lineid+2, nrow=blocksize))
>>   if (class(prediction.set) == "try-error") break
>>
>>   # Filter out all-constant training set columns from the block
>>   prediction.set.filtered <- prediction.set  
>> [training.filtered.property.colnames]
>>
>>   # Append the data
>>   # (I know this function is slow, but I couldn't figure out how  
>> to  do it faster, so far.)
>>   write.table(prediction.set.filtered, file=filtered.file,
>>                         append=TRUE, col.names=FALSE, sep=",")
>> }
>>
>> #-------------
>> # Now read in the filtered data set and save it for later use in   
>> classification
>> prediction.set.filtered <- read.csv(filtered.file, header=TRUE,   
>> row.names=1)
>> filtered.data <- 'prediction_set_filtered.Rdata'
>> save(prediction.set.filtered, file=filtered.data)
>>
>>
>>
>> I would be very happy about any hints how to improve the code  
>> above!!!
>>
>> Best regards,
>>
>> Torsten
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting- 
>> guide.html
>>
>>
>>
>>
>>
>
>



From ramasamy at cancer.org.uk  Tue Aug  9 13:10:07 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 09 Aug 2005 12:10:07 +0100
Subject: [R] How to pre-filter large amounts of data effectively
In-Reply-To: <FF4B73D7-2D7E-4D25-A2CD-FD14014701CB@chello.at>
References: <FF4B73D7-2D7E-4D25-A2CD-FD14014701CB@chello.at>
Message-ID: <1123585807.32762.50.camel@ipc143004.lif.icnet.uk>

I do not fully comprehend the codes below. But if I usually want to
check if all the elements in a row/column are the same, then I would
check the variance or range and see if they are nearly zero.

 v.row <- apply( mat, 1, var )
 v.col <- apply( mat, 2, var )

 tol      <- 0
 good.row <- which( v.row > tol )
 good.col <- which( v.col > tol )


Regards, Adai



On Tue, 2005-08-09 at 12:22 +0200, Torsten Schindler wrote:
> Hi,
> 
> I'm a R newbie and want to accelerate the following pre-filtering  
> step of a data set with more than 115,000 rows :
> 
> #-----------------
> # Function to filter out constant data columns
> filter.const<-function(X, vectors=c('column', 'row'), tol=0){
>    realdata=c()
>    filteredX<-matrix()
>    if( vectors[1] == 'row' ){
>      for( row in (1:nrow(X)) ){
>        if( length(which(X[row,]!=median(X[row,])))>tol ){
>          realdata[length(realdata)+1]=row
>        }
>      }
>      filteredX=X[realdata,]
>    } else if( vectors[1] == 'column' ){
>      for( col in (1:ncol(X)) ){
>        if( length(which(X[,col]!=median(X[,col])))>tol ){
>          realdata[length(realdata)+1]=col
>        }
>      }
>      filteredX=X[,realdata]
>    }
>    return(list(x=filteredX, ix=realdata))
> }
> 
> #-----------------
> # Filter out all all-constant columns in my training data set
> #
> # Read training data set with class information in the first column
> training <- read.csv('training_data.txt')
> dim(training) # => 49 rows and 525 columns
> 
> # Prepare column names by stripping the underline and the number at  
> the end
> colnames(training) <- sub('_\\d+$', '', colnames(training), perl=TRUE)
> 
> # Filter out the all-constant columns, exclude column 1, the class  
> column called myclass
> training.filter <- filter.const(training[,-1])
> 
> # The filtered data frame is
> training.filtered <- cbind(myclass=training[,1], training.filter$x)
> dim(training.filtered) # => 49 rows and 250 columns
> 
> # Save the filtered training set for later use in classification
> filtered.data <- 'training_set_filtered.Rdata'
> save(training.filtered, file=filtered.data)
> 
> #-----------------
> # THE FOLLOWING FILTERING STEP TAKES 3 HOUR ON MY PowerBook
> # AND CONSUMES ABOUT 600 Mb MEMORY.
> #
> # I WOULD BE HAPPY ABOUT ANY HINT HOW TO IMPROVE THIS.
> 
> # Pre-filter the big data set (more than 115,000 rows and 524  
> columns) for later class predictions.
> # The big data set contains the same column names as the training  
> set, but in a different order.
> 
> input.file <- 'big_data_set.txt'
> filtered.file <- 'big_data_set_filtered.txt'
> 
> # Read header with first row
> prediction.set <- read.csv(input.file, header=TRUE, skip=0, nrow=1)
> 
> # Prepare column names by stripping the underline and the number at  
> the end
> colnames(prediction.set) <- sub('_\\d+$', '', colnames 
> (prediction.set), perl=TRUE)
> prediction.set.header <- colnames(prediction.set)
> 
> # Get descriptor columns of the training data set without the  
> Activity_Class column
> training.filtered.property.colnames <- colnames(training.filtered)[-1]
> 
> # Filter out the all-constant columns from the training set
> prediction.set.filtered <- prediction.set 
> [training.filtered.property.colnames]
> dim(prediction.set.filtered) # => 1 row and 249 columns
> 
> # Write header and the first filtered row
> write.csv(prediction.set.filtered, file=filtered.file,
>              append=FALSE,  
> col.names=training.filtered.property.colnames)
> 
> blocksize <- 1000
> for (lineid in (0:120)*blocksize) {
>    cat('lineid: ', lineid, '\n')
> 
>    # Read block of data
>    # We have to add an dummy colname "x" in the col.names, when the  
> header is not read!
>    prediction.set <- try(read.csv(input.file, header=FALSE,
>                          col.names=c('x',prediction.set.header),  
> row.names=1,
>                          skip=lineid+2, nrow=blocksize))
>    if (class(prediction.set) == "try-error") break
> 
>    # Filter out all-constant training set columns from the block
>    prediction.set.filtered <- prediction.set 
> [training.filtered.property.colnames]
> 
>    # Append the data
>    # (I know this function is slow, but I couldn't figure out how to  
> do it faster, so far.)
>    write.table(prediction.set.filtered, file=filtered.file,
>                          append=TRUE, col.names=FALSE, sep=",")
> }
> 
> #-------------
> # Now read in the filtered data set and save it for later use in  
> classification
> prediction.set.filtered <- read.csv(filtered.file, header=TRUE,  
> row.names=1)
> filtered.data <- 'prediction_set_filtered.Rdata'
> save(prediction.set.filtered, file=filtered.data)
> 
> 
> 
> I would be very happy about any hints how to improve the code above!!!
> 
> Best regards,
> 
> Torsten
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From simon.woodhead at bristol.ac.uk  Tue Aug  9 13:42:16 2005
From: simon.woodhead at bristol.ac.uk (Simon Woodhead)
Date: Tue, 09 Aug 2005 12:42:16 +0100
Subject: [R] floor() rounding problem?
Message-ID: <42F89698.3090809@bristol.ac.uk>

Dear all,

Could someone please explain the following perculiarity?

 > 2 == 0.2/0.1
[1] TRUE
 > 3 == 0.3/0.1
[1] FALSE

Similarly,

floor(0.2/0.1) = 2
floor(0.3/0.1) = 2

Thank you,
Simon



From sdavis2 at mail.nih.gov  Tue Aug  9 13:49:55 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 09 Aug 2005 07:49:55 -0400
Subject: [R] floor() rounding problem?
In-Reply-To: <42F89698.3090809@bristol.ac.uk>
Message-ID: <BF1E10A3.BFF5%sdavis2@mail.nih.gov>

On 8/9/05 7:42 AM, "Simon Woodhead" <simon.woodhead at bristol.ac.uk> wrote:

> Dear all,
> 
> Could someone please explain the following perculiarity?
> 
>> 2 == 0.2/0.1
> [1] TRUE
>> 3 == 0.3/0.1
> [1] FALSE
> 
> Similarly,
> 
> floor(0.2/0.1) = 2
> floor(0.3/0.1) = 2


This is a FAQ 
(http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-
numbers-are-equal_003f)

Hope this helps.
Sean



From ligges at statistik.uni-dortmund.de  Tue Aug  9 13:51:00 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 09 Aug 2005 13:51:00 +0200
Subject: [R] floor() rounding problem?
In-Reply-To: <42F89698.3090809@bristol.ac.uk>
References: <42F89698.3090809@bristol.ac.uk>
Message-ID: <42F898A4.5060806@statistik.uni-dortmund.de>

Simon Woodhead wrote:

> Dear all,
> 
> Could someone please explain the following perculiarity?


Please read the FAQ "Why doesn't R think these numbers are equal" (as 
the posting gude asks you to do).

Uwe Ligges


>  > 2 == 0.2/0.1
> [1] TRUE
>  > 3 == 0.3/0.1
> [1] FALSE
> 
> Similarly,
> 
> floor(0.2/0.1) = 2
> floor(0.3/0.1) = 2
> 
> Thank you,
> Simon
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dimitris.rizopoulos at med.kuleuven.be  Tue Aug  9 13:54:19 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 9 Aug 2005 13:54:19 +0200
Subject: [R] floor() rounding problem?
References: <42F89698.3090809@bristol.ac.uk>
Message-ID: <001201c59cd9$13847010$0540210a@www.domain>

Look at ?Comparison, especially in the "Note" section, i.e.,

3 == 0.3/0.1
identical(all.equal(3, 0.3/0.1), TRUE)


Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Simon Woodhead" <simon.woodhead at bristol.ac.uk>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, August 09, 2005 1:42 PM
Subject: [R] floor() rounding problem?


> Dear all,
>
> Could someone please explain the following perculiarity?
>
> > 2 == 0.2/0.1
> [1] TRUE
> > 3 == 0.3/0.1
> [1] FALSE
>
> Similarly,
>
> floor(0.2/0.1) = 2
> floor(0.3/0.1) = 2
>
> Thank you,
> Simon
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From sean.oriordain at gmail.com  Tue Aug  9 15:26:40 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Tue, 9 Aug 2005 13:26:40 +0000
Subject: [R] solution: package install probs. win-xp. file move
Message-ID: <8ed68eed050809062626902c35@mail.gmail.com>

Hi,

This is just an FYI documenting a conflict between R and
Google-Desktop.  The solution was to click on the Google-Desktop icon
in the systray and click on "Pause Indexing".  I also temporarily
suspended anti-virus scanning before successfully
install.packages("VR") many times without getting an error message.

I was getting an intermittant failure when I tried to install a
package or update a package under Win-XP-Pro-sp2.

There is 5gb of free space on the drive and I'm an admistrator on this
machine and most times (but not every time) I tried to
upgrade.packages() or install.packages() I got the following error
message "unable to move temporary installation" message.

It appears to be a file-locking issue with the Google-Desktop search -
ie. during the few seconds that install.packages() creates a fileNNNN
directory tree, google-desktop starts reading these files and then
prevents this tree from being moved to its correct place under
\library

cheers,
Sean

==========================

Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0

I installed todays 2.2.0-pre and I get exactly the same thing. The
first time I did it, no problem; I exit out of R-2.2.0-pre (and 2.1.1)
and go back into 2.2.0-pre and type 'install.packages("VR")' and I get
the "unable to move temporary installation".

I've searched the archives and the web for the phrase "unable to move
temporary installation"; I've looked for similar bugs at r-bugs and I
found nothing.

Clearly something to do with file locking on windows - possibly anti-virus?

cheers,
Sean

==========================

e.g.
> install.packages("VR")
--- Please select a CRAN mirror for use in this session ---
trying URL 'http://cran.uk.r-project.org/bin/windows/contrib/2.1/VR_7.2-17.zip'
Content type 'application/zip' length 1570833 bytes
opened URL
downloaded 1534Kb

bundle 'VR' successfully unpacked and MD5 sums checked

The downloaded packages are in
        C:\Documents and Settings\soriorda\Local
Settings\Temp\Rtmp9355\downloaded_packages
updating HTML package descriptions
Warning message:
unable to move temporary installation 'C:\Program
Files\R\rw2011\library\file11565\MASS' to
'C:\PROGRA~1\R\rw2011\library\MASS'
 
=============================
R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.2.0 Under development (unstable) (2005-08-04 r35153M)

> install.packages("VR")
--- Please select a CRAN mirror for use in this session ---
trying URL 'http://cran.uk.r-project.org/bin/windows/contrib/2.2/VR_7.2-17.zip'
Content type 'application/zip' length 1570833 bytes
opened URL
downloaded 1534Kb

bundle 'VR' successfully unpacked and MD5 sums checked

The downloaded packages are in
        C:\Documents and Settings\soriorda\Local
Settings\Temp\Rtmp10612\downloaded_packages
updating HTML package descriptions
Warning message:
unable to move temporary installation 'C:\Program
Files\R\R-2.2.0dev\library\file17748\MASS' to
'C:\PROGRA~1\R\R-22~1.0DE\library\MASS'



From anne.piotet at ge.ocai.ch  Tue Aug  9 16:59:25 2005
From: anne.piotet at ge.ocai.ch (anne.piotet@ge.ocai.ch)
Date: Tue, 9 Aug 2005 15:59:25 +0100
Subject: [R] connexion problem getHdata (HMisc)
Message-ID: <OFE4CC88F7.25C0E88C-ON41257058.0051E1F2-41257058.00524249@ocai.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050809/ef04f141/attachment.pl

From ivo_welch-rstat8303 at mailblocks.com  Tue Aug  9 16:20:59 2005
From: ivo_welch-rstat8303 at mailblocks.com (ivo_welch-rstat8303@mailblocks.com)
Date: Tue, 09 Aug 2005 07:20:59 -0700
Subject: [R] clip to keep coordinate system?
Message-ID: <200508091421.j79EL2U9007005@hypatia.math.ethz.ch>


dear R wizards:

plot( 1, 1, ylim=(2,10), xlim=(2,10), type="n");
rect( -1, -1, 12, 12, col=gray(0.99) );

unfortunately wipes out the border axes around the plot.  how do I keep 
this?

regards,

/ivo



From yang_eric9 at yahoo.com  Tue Aug  9 16:40:21 2005
From: yang_eric9 at yahoo.com (Eric yang)
Date: Tue, 9 Aug 2005 07:40:21 -0700 (PDT)
Subject: [R] spline curves in R
Message-ID: <20050809144021.57190.qmail@web33912.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050809/6c2ba336/attachment.pl

From tlumley at u.washington.edu  Tue Aug  9 16:49:36 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Tue, 9 Aug 2005 07:49:36 -0700 (PDT)
Subject: [R] clip to keep coordinate system?
In-Reply-To: <200508091421.j79EL2U9007005@hypatia.math.ethz.ch>
References: <200508091421.j79EL2U9007005@hypatia.math.ethz.ch>
Message-ID: <Pine.A41.4.61b.0508090747060.113222@homer09.u.washington.edu>

On Tue, 9 Aug 2005 ivo_welch-rstat8303 at mailblocks.com wrote:

>
> dear R wizards:
>
> plot( 1, 1, ylim=(2,10), xlim=(2,10), type="n");
> rect( -1, -1, 12, 12, col=gray(0.99) );
>
> unfortunately wipes out the border axes around the plot.  how do I keep
> this?

I think you meant
   plot( 1, 1, ylim=c(2,10), xlim=c(2,10), type="n")
   rect( -1, -1, 12, 12, col=gray(0.99) )
Your code has two syntax errors and two spurious semicolons.

The border axes are gone because you have drawn on top of them.

On the quartz() and pdf() devices you could draw the rectangle in a 
partially transparent color rather than solid light grey.

More generally, you can redraw the border axes with box()

 	-thomas



From admin at biostatistic.de  Tue Aug  9 17:09:08 2005
From: admin at biostatistic.de (Knut Krueger)
Date: Tue, 09 Aug 2005 17:09:08 +0200
Subject: [R] RGUI crash when opening script in XP Home enviroment
Message-ID: <42F8C714.1030801@biostatistic.de>

If  there is a helpfile open (f.e ?glm) and it is the top window, then 
an exception error occurs (closing RGUI)
when I hit the open file button.
If the helpfile is not the top window (of the RGUI) I am able to open a 
new script without any error.
The RGUI is not closing complete there is a blank screen left which I 
have to close with the X Button or Taskmanager

Windows XP Home - German Version updates installed.

R-Version 2.1.0

If there you need any further details please ass for.

with regards
Knut Krueger
http://www.biostatistic.de



From admin at biostatistic.de  Tue Aug  9 17:15:53 2005
From: admin at biostatistic.de (Knut Krueger)
Date: Tue, 09 Aug 2005 17:15:53 +0200
Subject: [R] RGUI crash when opening script in XP Home enviroment
In-Reply-To: <42F8C714.1030801@biostatistic.de>
References: <42F8C714.1030801@biostatistic.de>
Message-ID: <42F8C8A9.4020900@biostatistic.de>



Knut Krueger schrieb:

>If there you need any further details please ass for.
>  
>
.... ask for .... :-(


AppName: rgui.exe	 AppVer: 2.10.50418.0	 ModName: r.dll
ModVer: 2.10.50418.0	 Offset: 000077cc

with regards
Knut Krueger
http://www.biostatistic.de



From petr.pikal at precheza.cz  Tue Aug  9 17:30:48 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 09 Aug 2005 17:30:48 +0200
Subject: [R] rpart plot question
Message-ID: <42F8E848.31315.20FB40A@localhost>

Dear all

I am quite confused by rpart plotting. Here is example.

set.seed(1)
y <- (c(rnorm(10), rnorm(10)+2, rnorm(10)+5))
x <- c(rep(c(1,2,5), c(10,10,10))
fit <- rpart(x~y)
plot(fit)
text(fit)

Text on first split says x < 3.5 and on the second split x < 1.5 what 
I understand:

If x < 3.5 so y is lower and y values go to the left split. OK. But, 
sometimes there is

whatever >= nnn and it seems to me that if this condition is true 
response variable follow to right split.

try:

y1<-(c(rnorm(10)+5,rnorm(10)+2, rnorm(10)))
fit<-rpart(y1~x)
plot(fit)
text(fit)

Well, I am not sure I express myself clearly. Am I correct that 
when there is < sign I shall follow left node but when there is >= 
sign I shall follow the right one?

Best regards
Petr Pikal
Petr Pikal
petr.pikal at precheza.cz



From Jordi.Molins at drkw.com  Tue Aug  9 17:52:31 2005
From: Jordi.Molins at drkw.com (Molins, Jordi)
Date: Tue, 9 Aug 2005 17:52:31 +0200
Subject: [R] mars of degree 3?
Message-ID: <C5A76BA0CA4D734CA725124C4D6397AC8BFE5F@ibfftce502.de.ad.drkw.net>

Dear list,

when I execute

library(mda)

x1 <- rnorm(100000,mean=1,sd=.12)
x2 <- rnorm(100000,mean=.6,sd=.12)
y <- pp(x1,1)+pp(x1,1)*pp(x2,.6)+.12*rnorm(length(x1))
mymars <- mars(cbind(x1,x2),y,degree=2)

mymars$cuts
mymars$factor

I get what I expected. Instead, when I execute

x1 <- rnorm(100000,mean=1,sd=.12)
x2 <- rnorm(100000,mean=.6,sd=.12)
x3 <- rnorm(100000,mean=.2,sd=.12)
y <-
pp(x1,1)+pp(x2,.6)+pp(x3,.2)+pp(x1,1)*pp(x2,.6)+pp(x1,1)*pp(x3,.2)+pp(x2,.6)
*pp(x3,.2)+pp(x1,1)*pp(x2,.6)*pp(x3,.2)+.12*rnorm(length(x1))
mymars <- mars(cbind(x1,x2,x3),y,degree=3,prune=FALSE)

mymars$cuts
mymars$factor

or

x1 <- rnorm(100000,mean=1,sd=.12)
x2 <- rnorm(100000,mean=.6,sd=.12)
x3 <- rnorm(100000,mean=.2,sd=.12)
y <- pp(x1,1)*pp(x2,.6)*pp(x3,.2)+.12*rnorm(length(x1))
mymars <- mars(cbind(x1,x2,x3),y,degree=3,prune=FALSE)

mymars$cuts
mymars$factor

I do not get the term of interaction degree 3.

What am I thinking wrong?

Thank you

Jordi



--------------------------------------------------------------------------------
The information contained herein is confidential and is inte...{{dropped}}



From astrzelczak at ps.pl  Tue Aug  9 17:54:31 2005
From: astrzelczak at ps.pl (astrzelczak@ps.pl)
Date: Tue,  9 Aug 2005 17:54:31 +0200
Subject: [R] xvmult and green lines
Message-ID: <1123602871.42f8d1b76d2ff@www.ps.pl>



Hello,

I'm performing mvpart analysis, I've chosen to interactively pick the tree
(xv="pick")  and to do multiple cross-validation (xvmult=10). On the plot x-val
relative error=f(cp/size of the tree) there are some green lines, which didn't
appear during normal cross-validation. What do they depict?

thanks in advance for help
Agnieszka



From Jordi.Molins at drkw.com  Tue Aug  9 17:57:23 2005
From: Jordi.Molins at drkw.com (Molins, Jordi)
Date: Tue, 9 Aug 2005 17:57:23 +0200
Subject: [R] mars of degree 3?
Message-ID: <C5A76BA0CA4D734CA725124C4D6397AC8BFE60@ibfftce502.de.ad.drkw.net>

I have forgotten to list the definition of pp. Here it is:

pp <- function(x,a) {ifelse(x>a, x-a, 0)}
______________________________________

Dear list,

when I execute

library(mda)

x1 <- rnorm(100000,mean=1,sd=.12)
x2 <- rnorm(100000,mean=.6,sd=.12)
y <- pp(x1,1)+pp(x1,1)*pp(x2,.6)+.12*rnorm(length(x1))
mymars <- mars(cbind(x1,x2),y,degree=2)

mymars$cuts
mymars$factor

I get what I expected. Instead, when I execute

x1 <- rnorm(100000,mean=1,sd=.12)
x2 <- rnorm(100000,mean=.6,sd=.12)
x3 <- rnorm(100000,mean=.2,sd=.12)
y <-
pp(x1,1)+pp(x2,.6)+pp(x3,.2)+pp(x1,1)*pp(x2,.6)+pp(x1,1)*pp(x3,.2)+pp(x2,.6)
*pp(x3,.2)+pp(x1,1)*pp(x2,.6)*pp(x3,.2)+.12*rnorm(length(x1))
mymars <- mars(cbind(x1,x2,x3),y,degree=3,prune=FALSE)

mymars$cuts
mymars$factor

or

x1 <- rnorm(100000,mean=1,sd=.12)
x2 <- rnorm(100000,mean=.6,sd=.12)
x3 <- rnorm(100000,mean=.2,sd=.12)
y <- pp(x1,1)*pp(x2,.6)*pp(x3,.2)+.12*rnorm(length(x1))
mymars <- mars(cbind(x1,x2,x3),y,degree=3,prune=FALSE)

mymars$cuts
mymars$factor

I do not get the term of interaction degree 3.

What am I thinking wrong?

Thank you

Jordi



--------------------------------------------------------------------------------
The information contained herein is confidential and is inte...{{dropped}}



From cobleigh at gmail.com  Tue Aug  9 17:57:33 2005
From: cobleigh at gmail.com (Jamieson Cobleigh)
Date: Tue, 9 Aug 2005 11:57:33 -0400
Subject: [R] Saving trellis output to files in scripts...
Message-ID: <7f50836c05080908571a796fb9@mail.gmail.com>

With much help from Chuck Cleland, I was able to get xyplot to
generate the plot I wanted.  I'm trying to write a script (that can be
read using source("file")) to create the plots I want and save them to
files.

If I type the following lines into the R (in interactive mode), the
correct plot gets saved into the file myfile.ps with a size of 4,096
bytes:

----------------------------
require(lattice)

trellis.device("postscript", file="myfile.ps", color=FALSE,
paper="letter", horizontal=TRUE, onefile=TRUE)

xyplot(y ~ x, type="b", data.frame(x=1:5, y=5:1))

dev.off()
----------------------------

However, if I put the same lines into a file, "temp.txt", and type
source("temp.txt") into R, then myfile.ps ends up with a size of 2,332
bytes and shows a blank page when loaded into ghostscript.

When run using source, it looks like the device is not getting closed
correctly since if I type source("temp.txt") and then dev.list() R
responds:  "postscript 2"

If I type dev.off(), the file size then increases to 4,277 bytes, but
then the ps file is malformed.

Anyone know how to make this work?

Jamie



From tpapp at Princeton.EDU  Tue Aug  9 18:13:52 2005
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Tue, 9 Aug 2005 18:13:52 +0200
Subject: [R] managing large datasets with RMySQL
Message-ID: <20050809161352.GA9847@tpapp.student.princeton.edu>

I have a large dataset (about 1 million data points from a
68-dimensional state space, result of an MCMC simulation) which won't
fit in memory.  I think that the only solution for analyzing this is
saving it in relational database (when generated) and then reading
back only portions of this data.

I have installed & initialized MySQL and the RMySQL package (I know
nothing about SQL, unfortunately, but I will try to learn).  The code
from section 4.3.1 of the R Data Import/Export manual runs
successfully.

Questions:

1. should I use dbWriteTable(..., overwrite=FALSE, append=TRUE) for
repeatedly saving the chunks of data?

2. is it OK to make row.names=FALSE when writing?

3. how do I  retrieve only parts of the  data? dbReadTable returns the
whole thing if I understand correctly.

If somebody has written code for analyzing data in parts before, I
would appreciate if he could send it.

Thanks,

Tamas



From afshart at exchange.sba.miami.edu  Tue Aug  9 18:21:19 2005
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Tue, 9 Aug 2005 12:21:19 -0400
Subject: [R] numeric operations w/ lists
Message-ID: <6BCB4D493A447546A8126F24332056E8F289B8@school1.business.edu>


Hello all,

X is a list of 20 lists, and each individual list has 65 elements.

Y is a list of 65 elements.

WANT:  subtract Y from each of the 20 lists in X.

Here's what I tried and the error messages:

> X - rep(Y, 20)
Error in X - rep(Y 20) : non-numeric argument to binary operator

I tried several methods w/o success.  Any suggestions kindly
appreciated.

Thanks,
Dave

ps - please copy afshar at miami.edu in the reply, as I've had 
problems receiving the daily digest.



From andy_liaw at merck.com  Tue Aug  9 18:34:12 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 9 Aug 2005 12:34:12 -0400
Subject: [R] Saving trellis output to files in scripts...
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EB89@usctmx1106.Merck.com>

This is in the FAQ:  You need to wrap any trellis calls in functions or
scripts in print().

Andy

> From: Jamieson Cobleigh
> 
> With much help from Chuck Cleland, I was able to get xyplot to
> generate the plot I wanted.  I'm trying to write a script (that can be
> read using source("file")) to create the plots I want and save them to
> files.
> 
> If I type the following lines into the R (in interactive mode), the
> correct plot gets saved into the file myfile.ps with a size of 4,096
> bytes:
> 
> ----------------------------
> require(lattice)
> 
> trellis.device("postscript", file="myfile.ps", color=FALSE,
> paper="letter", horizontal=TRUE, onefile=TRUE)
> 
> xyplot(y ~ x, type="b", data.frame(x=1:5, y=5:1))
> 
> dev.off()
> ----------------------------
> 
> However, if I put the same lines into a file, "temp.txt", and type
> source("temp.txt") into R, then myfile.ps ends up with a size of 2,332
> bytes and shows a blank page when loaded into ghostscript.
> 
> When run using source, it looks like the device is not getting closed
> correctly since if I type source("temp.txt") and then dev.list() R
> responds:  "postscript 2"
> 
> If I type dev.off(), the file size then increases to 4,277 bytes, but
> then the ps file is malformed.
> 
> Anyone know how to make this work?
> 
> Jamie
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From sdavis2 at mail.nih.gov  Tue Aug  9 19:01:27 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 09 Aug 2005 13:01:27 -0400
Subject: [R] numeric operations w/ lists
In-Reply-To: <6BCB4D493A447546A8126F24332056E8F289B8@school1.business.edu>
Message-ID: <BF1E59A7.C0C0%sdavis2@mail.nih.gov>

On 8/9/05 12:21 PM, "Afshartous, David" <afshart at exchange.sba.miami.edu>
wrote:

> 
> Hello all,
> 
> X is a list of 20 lists, and each individual list has 65 elements.
> 
> Y is a list of 65 elements.
> 
> WANT:  subtract Y from each of the 20 lists in X.
> 
> Here's what I tried and the error messages:
> 
>> X - rep(Y, 20)

See ?lapply.  Something like:


NewX <- lapply(X,function(tmp) {tmp-Y})

Hope this helps.

Sean



From gunter.berton at gene.com  Tue Aug  9 19:09:27 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 9 Aug 2005 10:09:27 -0700
Subject: [R] numeric operations w/ lists
In-Reply-To: <6BCB4D493A447546A8126F24332056E8F289B8@school1.business.edu>
Message-ID: <200508091709.j79H9RRl002791@faraday.gene.com>

Suggestions:

1. Read the relevant sections of "An Introduction to R" and the R language
definition to learn how to work with lists. 
3. ?lapply to learn how to use the apply family on lists

Hint: sapply(X,"-",y=Y)

The above references will tell you what these hieroglyphics mean and what
you get. Also why
matrix(unlist(X)-Y,nr=65) 

gives you the same result.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Afshartous, David
> Sent: Tuesday, August 09, 2005 9:21 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] numeric operations w/ lists
> 
> 
> Hello all,
> 
> X is a list of 20 lists, and each individual list has 65 elements.
> 
> Y is a list of 65 elements.
> 
> WANT:  subtract Y from each of the 20 lists in X.
> 
> Here's what I tried and the error messages:
> 
> > X - rep(Y, 20)
> Error in X - rep(Y 20) : non-numeric argument to binary operator
> 
> I tried several methods w/o success.  Any suggestions kindly
> appreciated.
> 
> Thanks,
> Dave
> 
> ps - please copy afshar at miami.edu in the reply, as I've had 
> problems receiving the daily digest.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From rab45+ at pitt.edu  Tue Aug  9 19:16:02 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Tue, 09 Aug 2005 13:16:02 -0400 (EDT)
Subject: [R] Adding Functionality to stat.table in Epi
Message-ID: <14779.128.147.28.3.1123607762.squirrel@webmail.pitt.edu>

The stat.table function in the Epi package won't do standard deviations.
It didn't seem that it would be difficult to add an "sd" function to the
stat.table function. Following the example for the mean, I set up a
similar function for the sd (and included it as an options) but it just
won't work. (I tried sending messages to the Epi mailing list after
subscribing but my mail is always returned. I don't have the exact error
messages at the moment or I would post them.)

Even if I just copy stat.table to stat.table2 and try to run stat.table2,
I get:

> stat.table2(index=list(race,gender),list(count(),percent(race)),margins=TRUE)
Error: couldn't find function "array.subset"

I can't find any "array.subset" function, yet the original stat.table
works just fine.

I've copied other functions and made changes to them and they would work
just fine. I must be missing something here.

Any insights would be appreciated.

Rick B.



From greg.snow at ihc.com  Tue Aug  9 19:20:51 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Tue, 09 Aug 2005 11:20:51 -0600
Subject: [R] Adding Functionality to stat.table in Epi
Message-ID: <s2f891a9.025@lp-msg1.co.ihc.com>

After you copy stat.table to stat.table2 and modify stat.table2
try:

> environment(stat.table2) <- environment(stat.table)

(you should only need to do that 1 time after creating/editing
stat.table2).

hope this helps,

Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111

>>> <rab45+ at pitt.edu> 08/09/05 11:16AM >>>
The stat.table function in the Epi package won't do standard
deviations.
It didn't seem that it would be difficult to add an "sd" function to
the
stat.table function. Following the example for the mean, I set up a
similar function for the sd (and included it as an options) but it
just
won't work. (I tried sending messages to the Epi mailing list after
subscribing but my mail is always returned. I don't have the exact
error
messages at the moment or I would post them.)

Even if I just copy stat.table to stat.table2 and try to run
stat.table2,
I get:

>
stat.table2(index=list(race,gender),list(count(),percent(race)),margins=TRUE)
Error: couldn't find function "array.subset"

I can't find any "array.subset" function, yet the original stat.table
works just fine.

I've copied other functions and made changes to them and they would
work
just fine. I must be missing something here.

Any insights would be appreciated.

Rick B.

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From hastie at stanford.edu  Tue Aug  9 19:27:32 2005
From: hastie at stanford.edu (Trevor Hastie)
Date: Tue, 9 Aug 2005 10:27:32 -0700
Subject: [R] Digest reading is tedious
Message-ID: <03091f4b0b5415eeb2d9be3e5e070ceb@stanford.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050809/c658f061/attachment.pl

From cobleigh at gmail.com  Tue Aug  9 19:30:05 2005
From: cobleigh at gmail.com (Jamieson Cobleigh)
Date: Tue, 9 Aug 2005 13:30:05 -0400
Subject: [R] Saving trellis output to files in scripts...
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EB89@usctmx1106.Merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EB89@usctmx1106.Merck.com>
Message-ID: <7f50836c0508091030163cfd97@mail.gmail.com>

Thanks, that worked.  I see now where it says that in the help for
xyplot, however, it wasn't obvious to me before.

Jamie

On 8/9/05, Liaw, Andy <andy_liaw at merck.com> wrote:
> This is in the FAQ:  You need to wrap any trellis calls in functions or
> scripts in print().
> 
> Andy
> 
> > From: Jamieson Cobleigh
> >
> > With much help from Chuck Cleland, I was able to get xyplot to
> > generate the plot I wanted.  I'm trying to write a script (that can be
> > read using source("file")) to create the plots I want and save them to
> > files.
> >
> > If I type the following lines into the R (in interactive mode), the
> > correct plot gets saved into the file myfile.ps with a size of 4,096
> > bytes:
> >
> > ----------------------------
> > require(lattice)
> >
> > trellis.device("postscript", file="myfile.ps", color=FALSE,
> > paper="letter", horizontal=TRUE, onefile=TRUE)
> >
> > xyplot(y ~ x, type="b", data.frame(x=1:5, y=5:1))
> >
> > dev.off()
> > ----------------------------
> >
> > However, if I put the same lines into a file, "temp.txt", and type
> > source("temp.txt") into R, then myfile.ps ends up with a size of 2,332
> > bytes and shows a blank page when loaded into ghostscript.
> >
> > When run using source, it looks like the device is not getting closed
> > correctly since if I type source("temp.txt") and then dev.list() R
> > responds:  "postscript 2"
> >
> > If I type dev.off(), the file size then increases to 4,277 bytes, but
> > then the ps file is malformed.
> >
> > Anyone know how to make this work?
> >
> > Jamie
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >
> >
> 
> 
> 
> ------------------------------------------------------------------------------
> Notice:  This e-mail message, together with any attachment...{{dropped}}



From jgentry at jimmy.harvard.edu  Tue Aug  9 19:55:10 2005
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Tue, 9 Aug 2005 13:55:10 -0400 (EDT)
Subject: [R] Digest reading is tedious
Message-ID: <Pine.SOL.4.20.0508091354400.5724-100000@santiam.dfci.harvard.edu>

> Like many, I am sure, I get R-Help in digest form. Its easy enough to
> browse the
> subject lines, but then if an entry interests you, you have to embark
> on this tedious search or scroll to find it.
> It would be great to have a "clickable" digest, where the topics list
> is a set of pointers, and clicking on a topic
> takes you to that entry. I can think of at least one way to do this via
> web pages, but I bet those with
> more web skills than me can come up with an elegant solution.
                                                                                
I sincerely hope you don't mean that you wish HTML enabled content in the
actual emails coming through the mailing list.  People who send HTML in
email text should be taken out back and shot :)
                                                                                
You could always look through the archives at:
https://stat.ethz.ch/pipermail/r-help/
                                                                                
And simply sort by date or whatever else suits your fancy.



From peterwyang at gmail.com  Tue Aug  9 19:56:02 2005
From: peterwyang at gmail.com (Peter Yang)
Date: Tue, 9 Aug 2005 13:56:02 -0400
Subject: [R] how to use the function from another package
Message-ID: <a922041d05080910561a53e859@mail.gmail.com>

Hi, I am trying to write a package(A) for myself and need to use a
function from another package(B) which is in R already(need to install
it before use). Could anyone tell me how to implement that? Also I
hope that my package gives an ERROR message(something like "STOP,
please install package B first") if the package B is not installed
yet.  It is my first time to write a package. Thanks very much for
your help.

Peter



From blindglobe at gmail.com  Tue Aug  9 20:03:04 2005
From: blindglobe at gmail.com (A.J. Rossini)
Date: Tue, 9 Aug 2005 20:03:04 +0200
Subject: [R] Digest reading is tedious
In-Reply-To: <03091f4b0b5415eeb2d9be3e5e070ceb@stanford.edu>
References: <03091f4b0b5415eeb2d9be3e5e070ceb@stanford.edu>
Message-ID: <1abe3fa9050809110375ae145e@mail.gmail.com>

Trevor -

There's a wonderful feature in gnus (the emacs information (including
mail) reader), that "bursts" digests into subparts for reading (and
hence, easy access). I think there are other similar tools as well for
other mail readers.

best,
-tony


On 8/9/05, Trevor Hastie <hastie at stanford.edu> wrote:
> Like many, I am sure, I get R-Help in digest form. Its easy enough to
> browse the
> subject lines, but then if an entry interests you, you have to embark
> on this tedious search or scroll to find it.
> It would be great to have a "clickable" digest, where the topics list
> is a set of pointers, and clicking on a topic
> takes you to that entry. I can think of at least one way to do this via
> web pages, but I bet those with
> more web skills than me can come up with an elegant solution.
> -------------------------------------------------------------------
>  Trevor Hastie  hastie at stanford.edu
>  Professor, Department of Statistics, Stanford University
>  Phone: (650) 725-2231 (Statistics) Fax: (650) 725-8977
>  (650) 498-5233 (Biostatistics) Fax: (650) 725-6951
>  URL: http://www-stat.stanford.edu/~hastie
>    address: room 104, Department of Statistics, Sequoia Hall
>  390 Serra Mall, Stanford University, CA 94305-4065
>   --------------------------------------------------------------------
> 
>         [[alternative text/enriched version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 


-- 
best,
-tony

"Commit early,commit often, and commit in a repository from which we can easily
roll-back your mistakes" (AJR, 4Jan05).

A.J. Rossini
blindglobe at gmail.com



From rab45+ at pitt.edu  Tue Aug  9 20:04:55 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Tue, 09 Aug 2005 14:04:55 -0400 (EDT)
Subject: [R] Adding Functionality to stat.table in Epi
In-Reply-To: <s2f891a9.025@lp-msg1.co.ihc.com>
References: <s2f891a9.025@lp-msg1.co.ihc.com>
Message-ID: <18768.128.147.28.3.1123610695.squirrel@webmail.pitt.edu>

> After you copy stat.table to stat.table2 and modify stat.table2
> try:
>
>> environment(stat.table2) <- environment(stat.table)
>
> (you should only need to do that 1 time after creating/editing
> stat.table2).
>
> hope this helps,
>
> Greg Snow, Ph.D.
> Statistical Data Center, LDS Hospital
> Intermountain Health Care
> greg.snow at ihc.com
> (801) 408-8111
>
>>>> <rab45+ at pitt.edu> 08/09/05 11:16AM >>>
> The stat.table function in the Epi package won't do standard
> deviations.
> It didn't seem that it would be difficult to add an "sd" function to
> the
> stat.table function. Following the example for the mean, I set up a
> similar function for the sd (and included it as an options) but it
> just
> won't work. (I tried sending messages to the Epi mailing list after
> subscribing but my mail is always returned. I don't have the exact
> error
> messages at the moment or I would post them.)
>
> Even if I just copy stat.table to stat.table2 and try to run
> stat.table2,
> I get:
>
>>
> stat.table2(index=list(race,gender),list(count(),percent(race)),margins=TRUE)
> Error: couldn't find function "array.subset"
>
> I can't find any "array.subset" function, yet the original stat.table
> works just fine.
>
> I've copied other functions and made changes to them and they would
> work
> just fine. I must be missing something here.
>
> Any insights would be appreciated.
>
> Rick B.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>

Thanks Greg. That helps but I still get the following error message:

> stat.table2(index=list(race),list(count(),sd(age.at.scanning)),margins=TRUE)
Error in if (digits < 0) digits <- 6 : missing value where TRUE/FALSE needed

Rick

Below is the code (sorry it's kind of long). The mean function works but
the sd function produces the error message:

stat.table2 <- function (index, contents = count(), data, margins = FALSE)
{
    index.sub <- substitute(index)
    index <- if (missing(data))
        eval(index)
    else eval(index.sub, data)
    deparse.name <- function(x) if (is.symbol(x))
        as.character(x)
    else ""
    if (is.list(index)) {
        if (is.call(index.sub)) {
            index.names <- names(index.sub)
            fixup <- if (is.null(index.names))
                seq(along = index.sub)
            else index.names == ""
            dep <- sapply(index.sub[fixup], deparse.name)
            if (is.null(index.names))
                index.labels <- dep
            else {
                index.labels <- index.names
                index.labels[fixup] <- dep
            }
            index.labels <- index.labels[-1]
        }
        else {
            index.labels <- if (!is.null(names(index))) {
                names(index)
            }
            else {
                rep("", length(index))
            }
        }
    }
    else {
        index.labels <- deparse.name(index.sub)
    }
    if (!is.list(index))
        index <- list(index)
    index <- lapply(index, as.factor)
    contents <- substitute(contents)
    if (!identical(deparse(contents[[1]]), "list")) {
        contents <- call("list", contents)
    }
    valid.functions <- c("count", "mean", "sd","weighted.mean", "sum",
        "quantile", "median", "IQR", "max", "min", "ratio", "percent")
    table.fun <- character(length(contents) - 1)
    for (i in 2:length(contents)) {
        if (!is.call(contents[[i]]))
            stop("contents must be a list of function calls")
        FUN <- deparse(contents[[i]][[1]])
        if (!FUN %in% valid.functions)
            stop(paste("Function", FUN, "not permitted in stat.table"))
        else table.fun[i - 1] <- FUN
    }
    stat.labels <- sapply(contents, deparse)[-1]
    content.names <- names(contents)
    if (!is.null(content.names)) {
        for (i in 2:length(content.names)) {
            if (nchar(content.names[i]) > 0)
                stat.labels[i - 1] <- content.names[i]
        }
    }
    count <- function(id) {
        if (missing(id)) {
            id <- seq(along = index[[1]])
        }
        y <- tapply(id, INDEX = subindex, FUN = function(x)
length(unique(x)))
        y[is.na(y)] <- 0
        return(y)
    }
    mean <- function(x, trim = 0, na.rm = TRUE) {
        tapply(x, INDEX = subindex, FUN = base::mean, trim = trim,
            na.rm = na.rm)
    }
    sd <- function(x, na.rm = TRUE) {
        tapply(x, INDEX = subindex, FUN = stats::sd,
            na.rm = na.rm)
    }

    weighted.mean <- function(x, w, na.rm = TRUE) {
        tapply(x, INDEX = subindex, FUN = stats::weighted.mean,
            w = w, na.rm = na.rm)
    }
    sum <- function(..., na.rm = TRUE) {
        tapply(..., INDEX = subindex, FUN = base::sum, na.rm = na.rm)
    }
    quantile <- function(x, probs, na.rm = TRUE, names = TRUE,
        type = 7, ...) {
        if (length(probs > 1))
            stop("The quantile function only accepts scalar prob values
within stat.table")
        tapply(x, INDEX = subindex, FUN = stats::quantile, probs = prob,
            na.rm = na.rm, names = names, type = type, ...)
    }
    median <- function(x, na.rm = TRUE) {
        tapply(x, INDEX = subindex, FUN = stats::median, na.rm = na.rm)
    }
    IQR <- function(x, na.rm = TRUE) {
        tapply(x, INDEX = subindex, FUN = stats::IQR, na.rm = na.rm)
    }
    max <- function(..., na.rm = TRUE) {
        tapply(..., INDEX = subindex, FUN = base::max, na.rm = na.rm)
    }
    min <- function(..., na.rm = TRUE) {
        tapply(..., INDEX = subindex, FUN = base::min, na.rm = na.rm)
    }
    ratio <- function(d, y, scale = 1, na.rm = TRUE) {
        if (length(scale) != 1)
            stop("Scale parameter must be a scalar")
        if (na.rm) {
            w <- (!is.na(d) & !is.na(y))
            tab1 <- tapply(d * w, INDEX = subindex, FUN = base::sum,
                na.rm = TRUE)
            tab2 <- tapply(y * w, INDEX = subindex, FUN = base::sum,
                na.rm = TRUE)
        }
        else {
            tab1 <- tapply(d, INDEX = subindex, FUN = base::sum,
                na.rm = FALSE)
            tab2 <- tapply(y, INDEX = subindex, FUN = base::sum,
                na.rm = FALSE)
        }
        return(scale * tab1/tab2)
    }
    percent <- function(...) {
        x <- list(...)
        if (length(x) == 0)
            stop("No variables to calculate percent")
        n <- count()
        sweep.index <- logical(length(subindex))
        for (i in seq(along = subindex)) {
            sweep.index[i] <- !any(sapply(x, identical, subindex[[i]]))
        }
        if (!any(sweep.index)) {
            return(100 * n/base::sum(n, na.rm = TRUE))
        }
        else {
            margin <- apply(n, which(sweep.index), base::sum,
                na.rm = TRUE)
            margin[margin == 0] <- NA
            return(100 * sweep(n, which(sweep.index), margin,
                "/"))
        }
    }
    n.dim <- length(index)
    tab.dim <- sapply(index, nlevels)
    if (length(margins) == 1)
        margins <- rep(margins, n.dim)
    else if (length(margins) != n.dim)
        stop("Incorrect length for margins argument")
    fac.list <- vector("list", n.dim)
    for (i in 1:n.dim) {
        fac.list[[i]] <- if (margins[i])
            c(0, 1)
        else 1
    }
    subtable.grid <- as.matrix(expand.grid(fac.list))
    ans.dim <- c(length(contents) - 1, tab.dim + margins)
    ans <- numeric(prod(ans.dim))
    for (i in 1:nrow(subtable.grid)) {
        in.subtable <- as.logical(subtable.grid[i, ])
        llim <- rep(1, n.dim) + ifelse(in.subtable, rep(0, n.dim),
            tab.dim)
        ulim <- tab.dim + ifelse(in.subtable, rep(0, n.dim),
            rep(1, n.dim))
        subindex <- index[in.subtable]
        subtable.list <- if (missing(data))
            eval(contents)
        else eval(as.expression(contents), data)
        for (j in 1:length(subtable.list)) {
            ans[array.subset(ans.dim, c(j, llim), c(j, ulim))] <-
subtable.list[[j]]
        }
    }
    ans <- array(ans, dim = ans.dim)
    ans.dimnames <- lapply(index, levels)
    names(ans.dimnames) <- index.labels
    for (i in 1:length(index)) {
        if (margins[i])
            ans.dimnames[[i]] <- c(ans.dimnames[[i]], "Total")
    }
    dimnames(ans) <- c(list(contents = stat.labels), ans.dimnames)
    attr(ans, "table.fun") <- table.fun
    class(ans) <- c("stat.table", class(ans))
    return(ans)
}
environment(stat.table2) <- environment(stat.table)

stat.table2(index=list(race),list(count(),mean(age.at.scanning)),margins=TRUE)

stat.table2(index=list(race),list(count(),sd(age.at.scanning)),margins=TRUE)



From JAROSLAW.W.TUSZYNSKI at saic.com  Tue Aug  9 20:08:08 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Tue, 9 Aug 2005 14:08:08 -0400 
Subject: [R] how to use the function from another package
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD57F412C@us-arlington-0668.mail.saic.com>

See "Writing R Extensions" / Creating R package / Description file /
"depends" field (section 1.1.1).

Jarek
====================================================\=======

 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">   \
 Jaroslaw.W.Tuszynski at saic.com                     `    \



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Peter Yang
Sent: Tuesday, August 09, 2005 1:56 PM
To: R-help at stat.math.ethz.ch
Subject: [R] how to use the function from another package

Hi, I am trying to write a package(A) for myself and need to use a function
from another package(B) which is in R already(need to install it before
use). Could anyone tell me how to implement that? Also I hope that my
package gives an ERROR message(something like "STOP, please install package
B first") if the package B is not installed yet.  It is my first time to
write a package. Thanks very much for your help.

Peter

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From roebuck at odin.mdacc.tmc.edu  Tue Aug  9 20:22:39 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Tue, 9 Aug 2005 13:22:39 -0500 (CDT)
Subject: [R] how to use the function from another package
In-Reply-To: <a922041d05080910561a53e859@mail.gmail.com>
References: <a922041d05080910561a53e859@mail.gmail.com>
Message-ID: <Pine.OSF.4.58.0508091316100.75925@odin.mdacc.tmc.edu>

On Tue, 9 Aug 2005, Peter Yang wrote:

> I am trying to write a package(A) for myself and need to use a
> function from another package(B) which is in R already(need to install
> it before use). Could anyone tell me how to implement that? Also I
> hope that my package gives an ERROR message(something like "STOP,
> please install package B first") if the package B is not installed
> yet.  It is my first time to write a package. Thanks very much for
> your help.

In your package's DESCRIPTION file, you should have an entry
that lists your package dependencies. Simply add the other
package there as well.

For example, to support the current version of R and a
package named foo, the entry would look like this:

    Depends: R (>= 2.1.1), foo

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From Ted.Harding at nessie.mcc.ac.uk  Tue Aug  9 19:48:49 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 09 Aug 2005 18:48:49 +0100 (BST)
Subject: [R] Digest reading is tedious
In-Reply-To: <03091f4b0b5415eeb2d9be3e5e070ceb@stanford.edu>
Message-ID: <XFMail.050809184849.Ted.Harding@nessie.mcc.ac.uk>

On 09-Aug-05 Trevor Hastie wrote:
> Like many, I am sure, I get R-Help in digest form. Its easy enough
> to browse the subject lines, but then if an entry interests you,
> you have to embark on this tedious search or scroll to find it.
> It would be great to have a "clickable" digest, where the topics list 
> is a set of pointers, and clicking on a topic takes you to that entry.
> I can think of at least one way to do this via web pages, but I bet
> those with more web skills than me can come up with an elegant
> solution.

If that were implemented, I would suggest that it should be a third
category of format, "html-digest", say.

Otherwise, people (though I'm not one of them) who choose to receive
R-help in digest form but use text-based mail software will find
their screens cluttered with HTML tags.

It's a good idea, but I think the existing digest format should
also be kept as it is.

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 09-Aug-05                                       Time: 18:48:42
------------------------------ XFMail ------------------------------



From david.whiting at ncl.ac.uk  Tue Aug  9 20:30:23 2005
From: david.whiting at ncl.ac.uk (David Whiting)
Date: Tue, 09 Aug 2005 19:30:23 +0100
Subject: [R] Digest reading is tedious
In-Reply-To: <1abe3fa9050809110375ae145e@mail.gmail.com>
References: <03091f4b0b5415eeb2d9be3e5e070ceb@stanford.edu>
	<1abe3fa9050809110375ae145e@mail.gmail.com>
Message-ID: <42F8F63F.70605@ncl.ac.uk>

A.J. Rossini wrote:
> Trevor -
> 
> There's a wonderful feature in gnus (the emacs information (including
> mail) reader), that "bursts" digests into subparts for reading (and
> hence, easy access). I think there are other similar tools as well for
> other mail readers.

If you are using linux you can use procmail with formail. I used to do
this a long time ago. See, for example:

http://polydistortion.net/doc/procmail-monash.html#digests

It's been a while since I used it so I'm not sure how much tweaking you
would need to do to get the recipe right for you. But once you have it
done you can then use any email client.


-- 
David Whiting
School of Clinical Medical Sciences, The Medical School
University of Newcastle upon Tyne, NE2 4HH, UK.

"I love deadlines. I love the whooshing noise they make as they go by"
(Douglas Adams)



From JAROSLAW.W.TUSZYNSKI at saic.com  Tue Aug  9 21:13:54 2005
From: JAROSLAW.W.TUSZYNSKI at saic.com (Tuszynski, Jaroslaw W.)
Date: Tue, 9 Aug 2005 15:13:54 -0400 
Subject: [R] how to use the function from another package
Message-ID: <CA0BCF3BED56294AB91E3AD74B849FD57F412E@us-arlington-0668.mail.saic.com>

> Thanks very much for your help. Do I still have to write library( ) to
load the library in my code after I add a "depends" field in the DESCRIPTION
file? 

No, 

First when user of your package downloads it (at least on Windows machines)
all required packages are also downloaded (this mechanism sometimes needs
manual help, but that is another story). Then when he loads your package (by
calling library(YourPackage)) all required packages are loaded into R.

One good way to research this kind of questions (other than documentation
and R-Help) is to study source code of other people packages.
   
Jarek
====================================================\=======

 Jarek Tuszynski, PhD.                           o / \ 
 Science Applications International Corporation  <\__,|  
 (703) 676-4192                                   ">   \
 Jaroslaw.W.Tuszynski at saic.com                     `    \


-----Original Message-----
From: peterwyang at gmail.com [mailto:peterwyang at gmail.com] 
Sent: Tuesday, August 09, 2005 2:57 PM
To: Tuszynski, Jaroslaw W.
Subject: Re: [R] how to use the function from another package

Thanks very much for your help. Do I still have to write library( ) to load
the library in my code after I add a "depends" field in the DESCRIPTION
file? Thanks.

Peter


On 8/9/05, Tuszynski, Jaroslaw W. <JAROSLAW.W.TUSZYNSKI at saic.com> wrote:
> See "Writing R Extensions" / Creating R package / Description file / 
> "depends" field (section 1.1.1).
> 
> Jarek
> ====================================================\=======
> 
>  Jarek Tuszynski, PhD.                           o / \
>  Science Applications International Corporation  <\__,|
>  (703) 676-4192                                   ">   \
>  Jaroslaw.W.Tuszynski at saic.com                     `    \
> 
> 
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Peter Yang
> Sent: Tuesday, August 09, 2005 1:56 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] how to use the function from another package
> 
> Hi, I am trying to write a package(A) for myself and need to use a 
> function from another package(B) which is in R already(need to install 
> it before use). Could anyone tell me how to implement that? Also I 
> hope that my package gives an ERROR message(something like "STOP, 
> please install package B first") if the package B is not installed 
> yet.  It is my first time to write a package. Thanks very much for your
help.
> 
> Peter
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Tue Aug  9 22:14:30 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 09 Aug 2005 22:14:30 +0200
Subject: [R] Digest reading is tedious
In-Reply-To: <Pine.SOL.4.20.0508091354400.5724-100000@santiam.dfci.harvard.edu>
References: <Pine.SOL.4.20.0508091354400.5724-100000@santiam.dfci.harvard.edu>
Message-ID: <x2hddysw9l.fsf@turmalin.kubism.ku.dk>

Jeff Gentry <jgentry at jimmy.harvard.edu> writes:

> > Like many, I am sure, I get R-Help in digest form. Its easy enough to
> > browse the
> > subject lines, but then if an entry interests you, you have to embark
> > on this tedious search or scroll to find it.
> > It would be great to have a "clickable" digest, where the topics list
> > is a set of pointers, and clicking on a topic
> > takes you to that entry. I can think of at least one way to do this via
> > web pages, but I bet those with
> > more web skills than me can come up with an elegant solution.
>                                                                                 
> I sincerely hope you don't mean that you wish HTML enabled content in the
> actual emails coming through the mailing list.  People who send HTML in
> email text should be taken out back and shot :)

Pretty much what my spam filter does... Well, it kills the message,
not the sender, although the latter would be a more permanent
solution.

> You could always look through the archives at:
> https://stat.ethz.ch/pipermail/r-help/
> And simply sort by date or whatever else suits your fancy.

Exactly what I was going to say. In fact, the archives have been
updating considerably faster than my inbox at times when there has
been a "Stau" on the Information Superhighway.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From maechler at stat.math.ethz.ch  Tue Aug  9 22:47:35 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 9 Aug 2005 22:47:35 +0200
Subject: [R] Digest reading is tedious
In-Reply-To: <03091f4b0b5415eeb2d9be3e5e070ceb@stanford.edu>
References: <03091f4b0b5415eeb2d9be3e5e070ceb@stanford.edu>
Message-ID: <17145.5735.426400.446812@stat.math.ethz.ch>

>>>>> "Trevor" == Trevor Hastie <hastie at stanford.edu>
>>>>>     on Tue, 9 Aug 2005 10:27:32 -0700 writes:

    Trevor> Like many, I am sure, I get R-Help in digest
    Trevor> form. Its easy enough to browse the subject lines,
    Trevor> but then if an entry interests you, you have to
    Trevor> embark on this tedious search or scroll to find it.
    Trevor> It would be great to have a "clickable" digest,
    Trevor> where the topics list is a set of pointers, and
    Trevor> clicking on a topic takes you to that entry. I can
    Trevor> think of at least one way to do this via web pages,
    Trevor> but I bet those with more web skills than me can
    Trevor> come up with an elegant solution.

But that has been an option in mailman, the software behind our
mailing lists  --- for ages ---

I'm astonished none of the funny responses would mention this,
and I'm further astonished I have to explain such simple things
to such smart people ;-)

Please open the URL at the end of every message
   https://stat.ethz.ch/mailman/listinfo/r-help
go to the bottom  and "log in"  -- clicking the [Unsubscribe or Edit Options] 
field.  You need your mailing list password sooner or later.
The one you get sent every 1st of the month; or you can have it
sent to you again.

Then you are in a page entitled
     "R-help Membership Configuration for  <foo>@<bar"
Scroll down to the section 
       "Your R-help Subscription"
where the 3rd entry is entitled
      Get MIME or Plain Text Digests?
and now you want MIME.


I hope this helps,
Martin



From f.harrell at vanderbilt.edu  Tue Aug  9 23:19:31 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 09 Aug 2005 17:19:31 -0400
Subject: [R] connexion problem getHdata (HMisc)
In-Reply-To: <OFE4CC88F7.25C0E88C-ON41257058.0051E1F2-41257058.00524249@ocai.ch>
References: <OFE4CC88F7.25C0E88C-ON41257058.0051E1F2-41257058.00524249@ocai.ch>
Message-ID: <42F91DE3.30004@vanderbilt.edu>

anne.piotet at ge.ocai.ch wrote:
> **********************************************************************
>  This email and any files transmitted with it are confidential and
> intended solely for the use of the individual or entity to whom they
> are addressed. If you have received this email in error please notify
> the system manager.
> 
> **********************************************************************
> 
> Hi
> 
> Just installing R and some packages in my new job; trying to download 
> dataset directly from 
> biostatistics dptm of Vanderbilt University using getHdata from Hmisc I 
> get the following:
> 
> Error in file (file, "r") : connexion openinig not possible
> Furthermore : 
> connexion to 'biostat.mc.vanderbilt.edu' impossible on port 80 
>  
> Can one get around this problem?
> 
> NOTE: I am not an administrator on the system....
> 
> 
> Anne Piotet  

It is hard for me to help when you provided no code and no output from 
typing

  version

at the command prompt.  You also did not include the version of Hmisc. 
I tried a small test:

library(Hmisc)
getHdata(titanic3)

and it worked fine, using the most recent Hmisc.

Frank

>   
>  t??l: 022 809 54 36  
> e-mail: anne.piotet at ge.ocai.ch  
>   
> Office cantonal de l'assurance-invalidit?? (OCAI)  
> rue de Lyon 97  
> 1203 Gen??ve GE  
>  
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From u08adh at hotmail.com  Tue Aug  9 23:40:24 2005
From: u08adh at hotmail.com (Andreas Hary)
Date: Tue, 9 Aug 2005 22:40:24 +0100
Subject: [R] Reading large files in R
References: <200508081935.j78JZq1M017285@hertz.gene.com>
	<BAY103-DAV14B1D66C6BA53CD2FBEFEEDFB80@phx.gbl>
Message-ID: <BAY103-DAV3757A3767817BFEFE7D59DFBB0@phx.gbl>

Brief correction: it should read

>> van.call <- call('sqlQuery',con,query='select * from vandrivers;')

rather than

>> van.call <- sqlQuery(con,'select * from vandrivers;')

The latter statement would load the data into memory as usual.
Best wishes,

Andreas




----- Original Message ----- 
From: "Andreas Hary" <u08adh at hotmail.com>
To: "Berton Gunter" <gunter.berton at gene.com>; <ramasamy at cancer.org.uk>; 
"'Jean-Pierre Gattuso'" <gattuso at obs-vlfr.fr>
Cc: <r-help at stat.math.ethz.ch>
Sent: Monday, August 08, 2005 10:49 PM
Subject: Re: [R] Reading large files in R


> You can also use the RODBC package to hold the data in a database, say 
> MySQL
> and only import it when you do the modelling, e.g.
>
>> library(RODBC)
>> library(sspir)
>> con <- odbcConnect("MySQL Test")
>> data(vandrivers)
>> sqlSave(con,dat=vandrivers,append=FALSE)
>> rm(vandrivers)
>> gc()
>> van.call <- sqlQuery(con,'select * from vandrivers;')
>> vd <- ssm( y ~ tvar(1) + seatbelt + sumseason(time,12),
>>           time=time, family=poisson(link="log"),
>>           data=eval(van.call))
>> vd$ss$phi["(Intercept)"] <- exp(- 2*3.703307 )
>> vd$ss$C0 <- diag(13)*1000
>> vd.res <- kfs(vd)
>> gc()
>
> In this case I have first saved the vandriver data in 'MySQL Test', but 
> one
> can obviously write the data directly to the database. Since the data is 
> not
> held in memory I find that I can do much larger computations than is
> otherwise possible. The downside is of course that computations take a bit
> longer.
> Best wishes,
>
> Andreas
>
> =====================
> Andreas D Hary
> Email:    u08adh at hotmail.com
> Mobile:   07906860987
> Phone:   02076554940
>
>
>
>
> ----- Original Message ----- 
> From: "Berton Gunter" <gunter.berton at gene.com>
> To: <ramasamy at cancer.org.uk>; "'Jean-Pierre Gattuso'" 
> <gattuso at obs-vlfr.fr>
> Cc: <r-help at stat.math.ethz.ch>
> Sent: Monday, August 08, 2005 8:35 PM
> Subject: Re: [R] Reading large files in R
>
>
>> ... and it is likely that even if you did have enough memory (several
>> times
>> the size of the data are generally needed) it would take a very long 
>> time.
>>
>> If you do have enough memory and the data are all of one type -- numeric
>> here -- you're better off treating it as a matrix rather than converting
>> it
>> to a data frame.
>>
>> -- Bert Gunter
>> Genentech Non-Clinical Statistics
>> South San Francisco, CA
>>
>> "The business of the statistician is to catalyze the scientific learning
>> process."  - George E. P. Box
>>
>>
>>
>>> -----Original Message-----
>>> From: r-help-bounces at stat.math.ethz.ch
>>> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
>>> Adaikalavan Ramasamy
>>> Sent: Monday, August 08, 2005 12:02 PM
>>> To: Jean-Pierre Gattuso
>>> Cc: r-help at stat.math.ethz.ch
>>> Subject: Re: [R] Reading large files in R
>>>
>>> >From Note section of help("read.delim") :
>>>
>>>      'read.table' is not the right tool for reading large matrices,
>>>      especially those with many columns: it is designed to read _data
>>>      frames_ which may have columns of very different classes. Use
>>>      'scan' instead.
>>>
>>> So I am not sure why you used 'scan', then converted it to a
>>> data frame.
>>>
>>> 1) Can provide an sample of the data that you are trying to read in.
>>> 2) How much memory does your machine has ?
>>> 3) Try reading in the first few lines using the nmax argument in scan.
>>>
>>> Regards, Adai
>>>
>>>
>>>
>>> On Mon, 2005-08-08 at 12:50 -0600, Jean-Pierre Gattuso wrote:
>>> > Dear R-listers:
>>> >
>>> > I am trying to work with a big (262 Mb) file but apparently
>>> reach a
>>> > memory limit using R on a MacOSX as well as on a unix machine.
>>> >
>>> > This is the script:
>>> >
>>> >  > type=list(a=0,b=0,c=0)
>>> >  > tmp <- scan(file="coastal_gebco_sandS_blend.txt", what=type,
>>> > sep="\t", quote="\"", dec=".", skip=1, na.strings="-99",
>>> nmax=13669628)
>>> > Read 13669627 records
>>> >  > gebco <- data.frame(tmp)
>>> > Error: cannot allocate vector of size 106793 Kb
>>> >
>>> >
>>> > Even tmp does not seem right:
>>> >
>>> >  > summary(tmp)
>>> > Error: recursive default argument reference
>>> >
>>> >
>>> > Do you have any suggestion?
>>> >
>>> > Thanks,
>>> > Jean-Pierre Gattuso
>>> >
>>> > ______________________________________________
>>> > R-help at stat.math.ethz.ch mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>> >
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide!
>>> http://www.R-project.org/posting-guide.html
>>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From gerw at chevron.com  Wed Aug 10 00:47:35 2005
From: gerw at chevron.com (Williams, George  (gerw))
Date: Tue, 9 Aug 2005 17:47:35 -0500
Subject: [R] Password prompt for download.file from linux
Message-ID: <0F1D6BCE86683745AA3542A44973560A0B2982@HOU150NTXC1MA.hou150.chevrontexaco.net>

Is there any way to be prompted for a password when using a proxy server
to down load files to linux.  The only approach I have seen in the
documentation involves putting a clear text password into an environment
variable, which would get me into trouble.
Thanks for the help,
George Williams



From Duncan.Mackay at flinders.edu.au  Wed Aug 10 03:40:15 2005
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Wed, 10 Aug 2005 11:10:15 +0930
Subject: [R] RGUI crash when opening script in XP Home enviroment
Message-ID: <20050810014016.4F9DA4A684@mamba.cc.flinders.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050810/4b752968/attachment.pl

From Duncan.Mackay at flinders.edu.au  Wed Aug 10 03:44:00 2005
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Wed, 10 Aug 2005 11:14:00 +0930
Subject: [R] Digest reading is tedious
Message-ID: <20050810014401.0C9824A686@mamba.cc.flinders.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050810/5881d723/attachment.pl

From Duncan.Mackay at flinders.edu.au  Wed Aug 10 04:15:07 2005
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Wed, 10 Aug 2005 11:45:07 +0930
Subject: [R] RGUI crash when opening script in XP Home enviroment
Message-ID: <20050810021507.D6B2A4A642@mamba.cc.flinders.edu.au>



From Duncan.Mackay at flinders.edu.au  Wed Aug 10 04:15:29 2005
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Wed, 10 Aug 2005 11:45:29 +0930
Subject: [R] Digest reading is tedious
Message-ID: <20050810021530.2EA8C4A642@mamba.cc.flinders.edu.au>



From Duncan.Mackay at flinders.edu.au  Wed Aug 10 04:18:56 2005
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Wed, 10 Aug 2005 11:48:56 +0930
Subject: [R] RGUI crash when opening script in XP Home enviroment
Message-ID: <20050810021857.52BBF4A642@mamba.cc.flinders.edu.au>

I can duplicate this problem under WinXP Professional 5.1.2600 Service Pack
2 Build 2600 on a Toshiba Satellite A10. Thanks to Knut for identifying just
what was causing this problem - I was having this error repeatedly but
couldn't track down the cause.
Duncan


> version
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    1.1            
year     2005           
month    06             
day      20             
language R      


*****************************************
Dr. Duncan Mackay
School of Biological Sciences
Flinders University
GPO Box 2100
Adelaide
S.A.    5001
AUSTRALIA

Ph (08) 8201 2627    FAX (08) 8201 3015

http://www.scieng.flinders.edu.au/biology/people/mackay_d/index.html



From Duncan.Mackay at flinders.edu.au  Wed Aug 10 04:19:15 2005
From: Duncan.Mackay at flinders.edu.au (Duncan Mackay)
Date: Wed, 10 Aug 2005 11:49:15 +0930
Subject: [R] Digest reading is tedious
Message-ID: <20050810021916.0700C4A642@mamba.cc.flinders.edu.au>

Any prospects of getting R-news delivered as an RSS feed???
Duncan


*****************************************
Dr. Duncan Mackay
School of Biological Sciences
Flinders University
GPO Box 2100
Adelaide
S.A.    5001
AUSTRALIA

Ph (08) 8201 2627    FAX (08) 8201 3015

http://www.scieng.flinders.edu.au/biology/people/mackay_d/index.html



From edd at debian.org  Wed Aug 10 04:10:22 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 9 Aug 2005 21:10:22 -0500
Subject: [R] Digest reading is tedious
In-Reply-To: <20050810014401.0C9824A686@mamba.cc.flinders.edu.au>
References: <20050810014401.0C9824A686@mamba.cc.flinders.edu.au>
Message-ID: <17145.25102.267486.179160@basebud.nulle.part>


On 10 August 2005 at 11:14, Duncan Mackay wrote:
| Any prospects of getting R-news delivered as an RSS feed???

The R-help (!!) list is available via Gmane.org, a fabulous service that
archives, redirects, displays, ... a gazillion mailing lists. Among them are
are r-help, r-devel, and several r-sig-* lists.  See the top of 

	http://dir.gmane.org/index.php?prefix=gmane.comp.lang.r

for the current list. By Gmane's convention, -help or -user lists often end
up as '*.general'. So r-help is at 

	http://dir.gmane.org/gmane.comp.lang.r.general

from where you get the different web interfaces as well as four different rss
feeds.  My favourite web form is 

	http://news.gmane.org/gmane.comp.lang.r.general

but that one has also been 'frozen' for maybe half a day.

Lastly, the page

	http://www.gmane.org/rss.php

has info on RSS at Gmane.

(CC'ed to Kurt as a suggestion for the FAQ ?)

Hth, Dirk

-- 
Statistics: The (futile) attempt to offer certainty about uncertainty.
         -- Roger Koenker, 'Dictionary of Received Ideas of Statistics'



From snvk4u at gmail.com  Wed Aug 10 07:12:58 2005
From: snvk4u at gmail.com (Krishna)
Date: Wed, 10 Aug 2005 10:42:58 +0530
Subject: [R] error loading nlme package
Message-ID: <139ef1c20508092212d52370@mail.gmail.com>

Hi everyone

The suggestion I received from Mr. Dimitris Rizopoulos and Mr. Gabor
Grothendieck seems to work well. But unfortunately when I am trying to
load nlme package, the following error message is generated. Please
help me on this, at the earliest.

> library(nlme)
Error in loadNamespace(i, c(lib.loc, .libPaths()), keep.source) : 
        There is no package called 'lattice'
In addition: Warning message: 
package 'nlme' was built under R version 2.0.1 
Error in library(nlme) : package/namespace load failed for 'nlme'

Though i am using the version R 2.0.0. A couple of hours back it was
loaded, in the new session this problem is generated.

regards
Krishna



From sean.oriordain at gmail.com  Wed Aug 10 08:23:59 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Wed, 10 Aug 2005 07:23:59 +0100
Subject: [R] connexion problem getHdata (HMisc)
In-Reply-To: <42F91DE3.30004@vanderbilt.edu>
References: <OFE4CC88F7.25C0E88C-ON41257058.0051E1F2-41257058.00524249@ocai.ch>
	<42F91DE3.30004@vanderbilt.edu>
Message-ID: <8ed68eed050809232345bd2f2a@mail.gmail.com>

Could this be a web-proxy problem?

http://cran.r-project.org/bin/windows/base/rw-FAQ.html#The-internet-download-functions-fail_002e

Have you tried doing update.packages() ? does this work?

I presume you're on some sort of Windows?

Sean


On 09/08/05, Frank E Harrell Jr <f.harrell at vanderbilt.edu> wrote:
> anne.piotet at ge.ocai.ch wrote:
> > **********************************************************************
> >  This email and any files transmitted with it are confidential and
> > intended solely for the use of the individual or entity to whom they
> > are addressed. If you have received this email in error please notify
> > the system manager.
> >
> > **********************************************************************
> >
> > Hi
> >
> > Just installing R and some packages in my new job; trying to download
> > dataset directly from
> > biostatistics dptm of Vanderbilt University using getHdata from Hmisc I
> > get the following:
> >
> > Error in file (file, "r") : connexion openinig not possible
> > Furthermore :
> > connexion to 'biostat.mc.vanderbilt.edu' impossible on port 80
> >
> > Can one get around this problem?
> >
> > NOTE: I am not an administrator on the system....
> >
> >
> > Anne Piotet
> 
> It is hard for me to help when you provided no code and no output from
> typing
> 
>   version
> 
> at the command prompt.  You also did not include the version of Hmisc.
> I tried a small test:
> 
> library(Hmisc)
> getHdata(titanic3)
> 
> and it worked fine, using the most recent Hmisc.
> 
> Frank
> 
> >
> >  t??l: 022 809 54 36
> > e-mail: anne.piotet at ge.ocai.ch
> >
> > Office cantonal de l'assurance-invalidit?? (OCAI)
> > rue de Lyon 97
> > 1203 Gen??ve GE
> >
> >       [[alternative HTML version deleted]]
> >
> >
> >
> > ------------------------------------------------------------------------
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> --
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                       Department of Biostatistics   Vanderbilt University
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From admin at biostatistic.de  Wed Aug 10 09:01:04 2005
From: admin at biostatistic.de (Knut Krueger)
Date: Wed, 10 Aug 2005 09:01:04 +0200
Subject: [R] RGUI crash when opening script in XP Home enviroment
In-Reply-To: <42F8C714.1030801@biostatistic.de>
References: <42F8C714.1030801@biostatistic.de>
Message-ID: <42F9A630.9030909@biostatistic.de>



Knut Krueger schrieb:

>If  there is a helpfile open (f.e ?glm) and it is the top window, then 
>an exception error occurs (closing RGUI)
>when I hit the open file button.
>If the helpfile is not the top window (of the RGUI) I am able to open a 
>new script without any error.
>The RGUI is not closing complete there is a blank screen left which I 
>have to close with the X Button or Taskmanager
>
>Windows XP Home - German Version updates installed.
>
>R-Version 2.1.0
>
>I
>
And it is the same problem with the 2.1.1 patched version 
http://www.cran.r-project.org/bin/windows/base/rpatched.html

with regards
Knut Krueger
http://www.biostatistic.de



From z319112 at hotmail.com  Wed Aug 10 09:09:35 2005
From: z319112 at hotmail.com (Felix Royo)
Date: Wed, 10 Aug 2005 07:09:35 +0000
Subject: [R] Treatment-response analysis along time
Message-ID: <BAY104-F19933BC5CAAC3C49745392BCBA0@phx.gbl>

Dear R people,
I wonder if you could give me a hand with some of my data. I have a very 
typical analysis in biology, however it is difficult for me to find the 
right way to analyse. I had a group of animals, I gave them a treatment, and 
I measure a variable along time -one??s per day- along 5 days,for 
example(fake data):
Animals Time1 Time2 Time3 Time4
1            1         5        3        1
2            2         7        4        1
3            5         5        3        1
4            1         3        7        2
5            2         7        7        1
Please, notice that all the animals get the same treatment, and there are no 
  control -animals which has no received any treatment.
Normally I handle this kind of data with SPSS and Repeated Measurement 
analysis. That tell me if there is a change along the time, but no 
information about when the treatment start to be effective, when the effect 
has pass. Besides, i would like to be able to handle this data with R.
I have been looking at Crawley's S-plus book, and I cannot find similar 
example as I have, not either in the Dalgaard??s introduction to R, because 
he uses an example where different animals are measured as each time -using 
time as a factor in a one way anova (I am hope I am right).
Thanks for your help and time.
Best regards
Felix



From pantd at unlv.nevada.edu  Wed Aug 10 09:10:11 2005
From: pantd at unlv.nevada.edu (pantd@unlv.nevada.edu)
Date: Wed, 10 Aug 2005 00:10:11 -0700
Subject: [R] HPD credible sets
Message-ID: <1123657811.42f9a85361f6c@webmail.scsv.nevada.edu>

Hi R users
Is there a function in R that gives HPD credible sets.  i googled it but was in
vain!

- dev



From dimitris.rizopoulos at med.kuleuven.be  Wed Aug 10 09:21:25 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 10 Aug 2005 09:21:25 +0200
Subject: [R] Treatment-response analysis along time
References: <BAY104-F19933BC5CAAC3C49745392BCBA0@phx.gbl>
Message-ID: <009201c59d7c$1e193080$0540210a@www.domain>

you haven't told us what kind of variable you measure, but either way 
look at lmer() function in lme4 package which fits both linear and 
generalized linear mixed-effects models.

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Felix Royo" <z319112 at hotmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, August 10, 2005 9:09 AM
Subject: [R] Treatment-response analysis along time


Dear R people,
I wonder if you could give me a hand with some of my data. I have a 
very
typical analysis in biology, however it is difficult for me to find 
the
right way to analyse. I had a group of animals, I gave them a 
treatment, and
I measure a variable along time -one??s per day- along 5 days,for
example(fake data):
Animals Time1 Time2 Time3 Time4
1            1         5        3        1
2            2         7        4        1
3            5         5        3        1
4            1         3        7        2
5            2         7        7        1
Please, notice that all the animals get the same treatment, and there 
are no
  control -animals which has no received any treatment.
Normally I handle this kind of data with SPSS and Repeated Measurement
analysis. That tell me if there is a change along the time, but no
information about when the treatment start to be effective, when the 
effect
has pass. Besides, i would like to be able to handle this data with R.
I have been looking at Crawley's S-plus book, and I cannot find 
similar
example as I have, not either in the Dalgaard??s introduction to R, 
because
he uses an example where different animals are measured as each 
time -using
time as a factor in a one way anova (I am hope I am right).
Thanks for your help and time.
Best regards
Felix

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Wed Aug 10 09:28:54 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 10 Aug 2005 08:28:54 +0100 (BST)
Subject: [R] RGUI crash when opening script in XP Home enviroment
In-Reply-To: <42F9A630.9030909@biostatistic.de>
References: <42F8C714.1030801@biostatistic.de>
	<42F9A630.9030909@biostatistic.de>
Message-ID: <Pine.LNX.4.61.0508100824410.20599@gannet.stats>

This is not the place to report reproducible faults: please see the
posting guide and send a complete bug report to the appropriate place.
(Let alone three followups from Duncan Mackay!)

However, as I don't know what the `open file button' is, I cannot
reproduce it.  Is this MDI or SDI mode, and if the former is this using
the icon on the toolbar, whose tooltip says it is `open script'?
                                                         ^^^^^^
What did you expect that to do?

Please make clear in your report if this one or two problems, i.e. is the 
`not closing completely' only after the error?

This looks like yet another problem caused by adding the script editor, 
since prior to that there was pager toolbar.


On Wed, 10 Aug 2005, Knut Krueger wrote:

>
>
> Knut Krueger schrieb:
>
>> If  there is a helpfile open (f.e ?glm) and it is the top window, then
>> an exception error occurs (closing RGUI)
>> when I hit the open file button.
>> If the helpfile is not the top window (of the RGUI) I am able to open a
>> new script without any error.
>> The RGUI is not closing complete there is a blank screen left which I
>> have to close with the X Button or Taskmanager
>>
>> Windows XP Home - German Version updates installed.
>>
>> R-Version 2.1.0
>>
>> I
>>
> And it is the same problem with the 2.1.1 patched version
> http://www.cran.r-project.org/bin/windows/base/rpatched.html
>
> with regards
> Knut Krueger
> http://www.biostatistic.de
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Wed Aug 10 09:40:34 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 10 Aug 2005 09:40:34 +0200
Subject: [R] error loading nlme package
In-Reply-To: <139ef1c20508092212d52370@mail.gmail.com>
References: <139ef1c20508092212d52370@mail.gmail.com>
Message-ID: <42F9AF72.20302@statistik.uni-dortmund.de>

Krishna wrote:

> Hi everyone
> 
> The suggestion I received from Mr. Dimitris Rizopoulos and Mr. Gabor
> Grothendieck seems to work well. But unfortunately when I am trying to
> load nlme package, the following error message is generated. Please
> help me on this, at the earliest.
> 
> 
>>library(nlme)
> 
> Error in loadNamespace(i, c(lib.loc, .libPaths()), keep.source) : 
>         There is no package called 'lattice'
> In addition: Warning message: 
> package 'nlme' was built under R version 2.0.1 
> Error in library(nlme) : package/namespace load failed for 'nlme'


Your whole setup seems to be seriously broken.
Please reinstall R (and that's the best time to upgrade to R-2.1.1).

Uwe Ligges

> Though i am using the version R 2.0.0. A couple of hours back it was
> loaded, in the new session this problem is generated.
> 
> regards
> Krishna
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From wfl1 at cornell.edu  Mon Aug 15 15:50:09 2005
From: wfl1 at cornell.edu (Warren Lamboy)
Date: Mon, 15 Aug 2005 09:50:09 -0400
Subject: [R] R equivalent to Fortran, GAUSS, or Perl's "goto"
Message-ID: <000201c5a1a0$4378b2b0$1502ec84@NA08WLAMBOY>

Does R have something equivalent to the "goto" in Perl?
If so, can you please tell me what it is?  I cannot find
it in the Ref Manual or the Language Manual.

Thanks.  

-  Warren



Warren Lamboy
USDA-ARS Plant Genetic Resources Unit
Geneva, NY, USA  14456



From p.dalgaard at biostat.ku.dk  Wed Aug 10 11:15:58 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Aug 2005 11:15:58 +0200
Subject: [R] Treatment-response analysis along time
In-Reply-To: <BAY104-F19933BC5CAAC3C49745392BCBA0@phx.gbl>
References: <BAY104-F19933BC5CAAC3C49745392BCBA0@phx.gbl>
Message-ID: <x2fytikv8x.fsf@turmalin.kubism.ku.dk>

"Felix Royo" <z319112 at hotmail.com> writes:

> Dear R people,
> I wonder if you could give me a hand with some of my data. I have a very 
> typical analysis in biology, however it is difficult for me to find the 
> right way to analyse. I had a group of animals, I gave them a treatment, and 
> I measure a variable along time -one??s per day- along 5 days,for 
> example(fake data):
> Animals Time1 Time2 Time3 Time4
> 1            1         5        3        1
> 2            2         7        4        1
> 3            5         5        3        1
> 4            1         3        7        2
> 5            2         7        7        1
> Please, notice that all the animals get the same treatment, and there are no 
>   control -animals which has no received any treatment.
> Normally I handle this kind of data with SPSS and Repeated Measurement 
> analysis. That tell me if there is a change along the time, but no 
> information about when the treatment start to be effective, when the effect 
> has pass. Besides, i would like to be able to handle this data with R.
> I have been looking at Crawley's S-plus book, and I cannot find similar 
> example as I have, not either in the Dalgaard??s introduction to R, because 
> he uses an example where different animals are measured as each time -using 
> time as a factor in a one way anova (I am hope I am right).
> Thanks for your help and time.
> Best regards
> Felix

ISwR is hardly an extensive treatise on repeated measurements, but
two-way ANOVA *is* in there (Section 6.3 and 10.6 for the replicated
case). Notice that you need a different data layout for that,
basically the result of a reshape(...direction="long"). 

Also, the capabilities of the newer mlm methods are relevant for this
kind of data (see ?anova.mlm, and the examples).

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From B.Rowlingson at lancaster.ac.uk  Wed Aug 10 11:23:17 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 10 Aug 2005 10:23:17 +0100
Subject: [R] R equivalent to Fortran, GAUSS, or Perl's "goto"
In-Reply-To: <000201c5a1a0$4378b2b0$1502ec84@NA08WLAMBOY>
References: <000201c5a1a0$4378b2b0$1502ec84@NA08WLAMBOY>
Message-ID: <42F9C785.9090900@lancaster.ac.uk>

Warren Lamboy wrote:
> Does R have something equivalent to the "goto" in Perl?
> If so, can you please tell me what it is?  I cannot find
> it in the Ref Manual or the Language Manual.

What was true in 1968 is still true now:

http://www.acm.org/classics/oct95/

Of course Perl has one, but then in Perl there's always more than one 
way to shoot yourself in the foot.

Baz



From dmb at mrc-dunn.cam.ac.uk  Wed Aug 10 11:41:49 2005
From: dmb at mrc-dunn.cam.ac.uk (Dan Bolser)
Date: Wed, 10 Aug 2005 10:41:49 +0100 (BST)
Subject: [R] Question about curve fitting...
Message-ID: <Pine.LNX.4.21.0508101034530.16024-100000@mail.mrc-dunn.cam.ac.uk>


Meta:
This question is somewhat long and has two parts, I would be very happy
for someone just to nudge me in the right direction with the manual /
tutorial, as I am somewhat lost...


1) How do I fit a curve of the form "y = k1 * x^k2" ?

I want to estimate values of k1 and k2 given the x/y data I have, and I
can't work out how to get R to calculate and return their estimates.


2) Given the value of k1 and k2 for population A, how can I test if
population B has significantly different values of k1 and k2?

Sorry for the basic question. I think I just need to read up on a few
functions.


I have about 50 xy pairs in total if that makes a difference.

Dan.



From S.O.Nyangoma at amc.uva.nl  Wed Aug 10 12:21:33 2005
From: S.O.Nyangoma at amc.uva.nl (S.O. Nyangoma)
Date: Wed, 10 Aug 2005 12:21:33 +0200
Subject: [R] Question about curve fitting...
Message-ID: <1df0ab1dd53c.1dd53c1df0ab@amc.uva.nl>

I see that 
log(y)=log(k1)+k2*log(x)
use lm?

----- Original Message -----
From: Dan Bolser <dmb at mrc-dunn.cam.ac.uk>
Date: Wednesday, August 10, 2005 11:41 am
Subject: [R] Question about curve fitting...

> 
> Meta:
> This question is somewhat long and has two parts, I would be very 
> happyfor someone just to nudge me in the right direction with the 
> manual /
> tutorial, as I am somewhat lost...
> 
> 
> 1) How do I fit a curve of the form "y = k1 * x^k2" ?
> 
> I want to estimate values of k1 and k2 given the x/y data I have, 
> and I
> can't work out how to get R to calculate and return their estimates.
> 
> 
> 2) Given the value of k1 and k2 for population A, how can I test if
> population B has significantly different values of k1 and k2?
> 
> Sorry for the basic question. I think I just need to read up on a few
> functions.
> 
> 
> I have about 50 xy pairs in total if that makes a difference.
> 
> Dan.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From admin at biostatistic.de  Wed Aug 10 12:38:04 2005
From: admin at biostatistic.de (Knut Krueger)
Date: Wed, 10 Aug 2005 12:38:04 +0200
Subject: [R] RGUI crash when opening script in XP Home enviroment
In-Reply-To: <Pine.LNX.4.61.0508100824410.20599@gannet.stats>
References: <42F8C714.1030801@biostatistic.de>	<42F9A630.9030909@biostatistic.de>
	<Pine.LNX.4.61.0508100824410.20599@gannet.stats>
Message-ID: <42F9D90C.3010808@biostatistic.de>



Prof Brian Ripley schrieb:

>This is not the place to report reproducible faults: please see the
>posting guide and send a complete bug report to the appropriate place.
>(Let alone three followups from Duncan Mackay!)
>  
>
Thank??s for the hint I sent the error (including the following url) to 
the Bug tracing system, but I also thought that the user here should 
know how to prevent the error.
I lost a lot of time with rewriting scripts which were not saved before 
I opened a new one until I realized the reason of this.

>However, as I don't know what the `open file button' is, I cannot
>reproduce it.  Is this MDI or SDI mode, 
>
Sorry about this, but I don not know the difference and I do not know 
what the shortcuts are standing for
   

>and if the former is this using
>the icon on the toolbar, whose tooltip says it is `open script'?
>
Yes this one but not the 'file -> open script' 
line

>
>Please make clear in your report if this one or two problems, i.e. is the 
>`not closing completely' only after the error?
>  
>
The report with screen prints is available (I'm sorry that it is a 
German operating system):
http://www.biostatistic.de/forum/messages/2291/2350.html

I hope this is clarifying the open questions

with regards
Knut Krueger
http://www.biostatistic.de



From dargosch at gmail.com  Wed Aug 10 13:15:56 2005
From: dargosch at gmail.com (Fredrik Karlsson)
Date: Wed, 10 Aug 2005 13:15:56 +0200
Subject: [R] Not loading libraries
Message-ID: <376e97ec050810041561b1caf5@mail.gmail.com>

Dear list,

I have a bunch of libraries that are automatically loaded when I start
the R environment. How do I remove them?

Output:
fredrik at theodor:~/dokument/Thesis/Book$ make
Making file voicing.tex from voicing.Rnw
Loading Tcl/Tk interface ... done
Loading required package: tcltk
Loading required package: rgl
Loading required package: zoo
Loading required package: strucchange
Loading required package: sandwich
Loading required package: relimp
Loading required package: nnet
Loading required package: graphics
Loading required package: grDevices
Loading required package: stats
Loading required package: nlme
Loading required package: mvtnorm
Loading required package: multcomp
Loading required package: mgcv
This is mgcv 1.3-1
Loading required package: MASS
Loading required package: lmtest
Loading required package: lattice
Loading required package: grid
Loading required package: foreign
Loading required package: effects
Loading required package: car
Loading required package: abind
> library(tools); Sweave("voicing.Rnw")
....

/Fredrik



From Gregor.Gorjanc at bfro.uni-lj.si  Wed Aug 10 13:42:12 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Wed, 10 Aug 2005 13:42:12 +0200
Subject: [R] Exponential, Weibull and log-logistic distributions in glm()
Message-ID: <7FFEE688B57D7346BC6241C55900E730F319BD@pollux.bfro.uni-lj.si>

Dear R-users!

I would like to fit exponential, Weibull and log-logistic via glm() like
functions. Does anyone know a way to do this? Bellow is a bit longer 
description of my problem.

Hm, could family() be adjusted/improved/added to allow for these distributions?
SAS procedure GENMOD alows to specify deviance and variance functions to
help in such cases. I have not tried that option and I do not know how
does it work. I do not expect that others will do the job, although it 
would not harm ;)

Thanks in advance!

I fully understand that all mentioned distributiones are available through
"survival" functions in various packages but I don't have data that 
correspond fully to survival data. I have data on some cell parameters,
which show cell vitality. These data are highly skewed and I have
therefore modeled them via log-normal and gamma in glm(). Based
on deviance residuals, gamma seems to fit better. By the way, are there any
other means of chosing the right disribution for GLM?

However, some references from field of this data suggested that Weibull might
be better and I would like to try this, as well as with exponential and 
log-logistic. Of course, author in that paper did not say how they performed
the analyses, but I guess they took each group (several group were compared) 
separately and estimated parameters for distribution, say Weibull, via maximum 
likelhood. I do not like this approach, since not all data are used in one run, 
and would like to use model to get parameter estimates and perform inference.
With Weibull I am aware that it does not fit in exponential family, unless one
is read to specify a value/estimate for one parameter.

Any comment are welcome!

Lep pozdrav / With regards,
    Gregor Gorjanc

----------------------------------------------------------------------
University of Ljubljana
Biotechnical Faculty        URI: http://www.bfro.uni-lj.si/MR/ggorjan
Zootechnical Department     mail: gregor.gorjanc <at> bfro.uni-lj.si
Groblje 3                   tel: +386 (0)1 72 17 861
SI-1230 Domzale             fax: +386 (0)1 72 17 888
Slovenia, Europe
----------------------------------------------------------------------
"One must learn by doing the thing; for though you think you know it,
 you have no certainty until you try." Sophocles ~ 450 B.C.



From ripley at stats.ox.ac.uk  Wed Aug 10 13:54:19 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 10 Aug 2005 12:54:19 +0100 (BST)
Subject: [R] Not loading libraries
In-Reply-To: <376e97ec050810041561b1caf5@mail.gmail.com>
References: <376e97ec050810041561b1caf5@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0508101250170.12833@gannet.stats>

On Wed, 10 Aug 2005, Fredrik Karlsson wrote:

> I have a bunch of libraries that are automatically loaded when I start
> the R environment. How do I remove them?

By undoing what you did to get them there.

`make' is not the usual way to start R: try R --vanilla and see what 
happens (probably none of this).  Then read ?Startup and try just 'R'.

My guess is that has something to do loading Rcmdr afer having set R to 
run with no default packages, but we have no evidence of how you ran R.

> Output:
> fredrik at theodor:~/dokument/Thesis/Book$ make
> Making file voicing.tex from voicing.Rnw
> Loading Tcl/Tk interface ... done
> Loading required package: tcltk
> Loading required package: rgl
> Loading required package: zoo
> Loading required package: strucchange
> Loading required package: sandwich
> Loading required package: relimp
> Loading required package: nnet
> Loading required package: graphics
> Loading required package: grDevices
> Loading required package: stats
> Loading required package: nlme
> Loading required package: mvtnorm
> Loading required package: multcomp
> Loading required package: mgcv
> This is mgcv 1.3-1
> Loading required package: MASS
> Loading required package: lmtest
> Loading required package: lattice
> Loading required package: grid
> Loading required package: foreign
> Loading required package: effects
> Loading required package: car
> Loading required package: abind
>> library(tools); Sweave("voicing.Rnw")
> ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kangs at ornl.gov  Wed Aug 10 14:13:28 2005
From: kangs at ornl.gov (Kang, Sang-Hoon)
Date: Wed, 10 Aug 2005 08:13:28 -0400
Subject: [R] invalid 'mode' of argument?
Message-ID: <74700A2004B18A459CDA46BF6BDEDEF501A77C33@ORNLEXCHANGE.ornl.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050810/c8c1f160/attachment.pl

From tuechler at gmx.at  Wed Aug 10 14:24:47 2005
From: tuechler at gmx.at (Heinz Tuechler)
Date: Wed, 10 Aug 2005 14:24:47 +0200
Subject: [R] how to write assignment form of function
Message-ID: <3.0.6.32.20050810142447.007b0410@pop.gmx.net>

Dear All,

where can I find information about how to write an assigment form of a
function?
For curiosity I tried to write a different form of the levels()-function,
since the original method for factor deletes all other attributes of a factor.
Of course, the simple method would be to use instead of levels(x) <-
newlevels, attr(x, 'levels') <- newlevels.

I tried the following:
## example
x <- factor(c(1,1,NA,2,3,4,4,4,1,2)); y <- x
attr(x, 'levels') <- c('a', 'b', 'c', 'd')     # does what I want
x
 [1] a    a    <NA> b    c    d    d    d    a    b   
Levels: a b c d
 
'levels.simple<-' <- function (x, value) 
 {
      attr(x, 'levels') <- value
 }
 
levels.simple(y) <- c('a', 'b', 'c', 'd')     # does not what I want
y
[1] "a" "b" "c" "d"
 
Thanks,
Heinz T??chler



From roger.bos at gmail.com  Wed Aug 10 14:23:00 2005
From: roger.bos at gmail.com (roger bos)
Date: Wed, 10 Aug 2005 08:23:00 -0400
Subject: [R] R equivalent to Fortran, GAUSS, or Perl's "goto"
In-Reply-To: <000201c5a1a0$4378b2b0$1502ec84@NA08WLAMBOY>
References: <000201c5a1a0$4378b2b0$1502ec84@NA08WLAMBOY>
Message-ID: <1db726800508100523294dbc49@mail.gmail.com>

The best thing to do would be to provide an example of how you want to
use the goto, then someone can probably suggest a work around or an
alternative way of doing the same thing, once we have something
concrete to go on.

Thanks,
Roger

On 8/15/05, Warren Lamboy <wfl1 at cornell.edu> wrote:
> Does R have something equivalent to the "goto" in Perl?
> If so, can you please tell me what it is?  I cannot find
> it in the Ref Manual or the Language Manual.
> 
> Thanks.
> 
> -  Warren
> 
> 
> 
> Warren Lamboy
> USDA-ARS Plant Genetic Resources Unit
> Geneva, NY, USA  14456
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From jarioksa at sun3.oulu.fi  Wed Aug 10 14:28:24 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Wed, 10 Aug 2005 15:28:24 +0300
Subject: [R] invalid 'mode' of argument?
In-Reply-To: <74700A2004B18A459CDA46BF6BDEDEF501A77C33@ORNLEXCHANGE.ornl.gov>
References: <74700A2004B18A459CDA46BF6BDEDEF501A77C33@ORNLEXCHANGE.ornl.gov>
Message-ID: <1123676904.30602.35.camel@biol102145.oulu.fi>

On Wed, 2005-08-10 at 08:13 -0400, Kang, Sang-Hoon wrote:

> As a novice I was trying to calculate Shannon diversity index using
> diversity function in vegan package and kept having same error message.
> Error in sum(..., na.rm = na.rm) : invalid 'mode' of argument
> 
This error (which is from sum()) seems to come if you have non-numeric
data (factors, character variables etc.). Check that your data are
strictly numeric. Some of the most common cases I've seen are that row
or column names are not read as row and column names but as data rows or
columns. 
> 
> My dataset is from microarray and have abundant missing values, so I
> tried labeling them as NA and 0, but still same error message.

> Shannon index is negative sum of proportion times log of proportion, so
> I put 1 for missing values to avoid log 0, but still same error message.
> 
You shouldn't forge your data: the function handles zeros.

PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/



From wfl1 at cornell.edu  Tue Aug 16 14:36:49 2005
From: wfl1 at cornell.edu (Warren Lamboy)
Date: Tue, 16 Aug 2005 08:36:49 -0400
Subject: [R] R equivalent to Fortran, GAUSS, or Perl's "goto"
In-Reply-To: <42F9C785.9090900@lancaster.ac.uk>
Message-ID: <002801c5a25f$2c9dd060$1502ec84@NA08WLAMBOY>

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Barry Rowlingson
Sent: Wednesday, August 10, 2005 5:23 AM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] R equivalent to Fortran, GAUSS, or Perl's "goto"


Warren Lamboy wrote:
> Does R have something equivalent to the "goto" in Perl?
> If so, can you please tell me what it is?  I cannot find
> it in the Ref Manual or the Language Manual.

What was true in 1968 is still true now:

http://www.acm.org/classics/oct95/

Of course Perl has one, but then in Perl there's always more than one 
way to shoot yourself in the foot.

Baz



Does that mean the answer to my first question is "No"?

Warren



From dimitris.rizopoulos at med.kuleuven.be  Wed Aug 10 14:49:08 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 10 Aug 2005 14:49:08 +0200
Subject: [R] how to write assignment form of function
References: <3.0.6.32.20050810142447.007b0410@pop.gmx.net>
Message-ID: <003001c59da9$e6300df0$0540210a@www.domain>

take a look at e.g., get("levels<-.factor"); you should return "x" in 
your function, i.e.,

y <- x <- factor(c(1,1,NA,2,3,4,4,4,1,2))
############
'levels.simple<-' <- function(x, value){
      attr(x, 'levels') <- value
      x
 }

levels.simple(y) <- c('a', 'b', 'c', 'd')
y


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Heinz Tuechler" <tuechler at gmx.at>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, August 10, 2005 2:24 PM
Subject: [R] how to write assignment form of function


Dear All,

where can I find information about how to write an assigment form of a
function?
For curiosity I tried to write a different form of the 
levels()-function,
since the original method for factor deletes all other attributes of a 
factor.
Of course, the simple method would be to use instead of levels(x) <-
newlevels, attr(x, 'levels') <- newlevels.

I tried the following:
## example
x <- factor(c(1,1,NA,2,3,4,4,4,1,2)); y <- x
attr(x, 'levels') <- c('a', 'b', 'c', 'd')     # does what I want
x
 [1] a    a    <NA> b    c    d    d    d    a    b
Levels: a b c d

'levels.simple<-' <- function (x, value)
 {
      attr(x, 'levels') <- value
 }

levels.simple(y) <- c('a', 'b', 'c', 'd')     # does not what I want
y
[1] "a" "b" "c" "d"

Thanks,
Heinz T??chler

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From ivo_welch-rstat8303 at mailblocks.com  Wed Aug 10 15:18:49 2005
From: ivo_welch-rstat8303 at mailblocks.com (ivo_welch-rstat8303@mailblocks.com)
Date: Wed, 10 Aug 2005 06:18:49 -0700
Subject: [R] clip to keep coordinate system?
In-Reply-To: <Pine.A41.4.61b.0508090747060.113222@homer09.u.washington.edu>
References: <200508091421.j79EL2U9007005@hypatia.math.ethz.ch>
	<Pine.A41.4.61b.0508090747060.113222@homer09.u.washington.edu>
Message-ID: <200508101318.j7ADIqS7001169@hypatia.math.ethz.ch>


Dear wizards:

despite my omission of the c() on the limits, a kind soul sent me the 
answer: a par(new=T) will make the next plot() redraw nicely.

a help question for  R-2.1.0:  help.search("transparent")  gives
"No help files found with alias or concept or title matching 
'transparent' using fuzzy matching."
but "?par" has the word transparent in the color specification section 
(though an example of usage would make this one much clearer, too).  
shouldn't help.search() look through the build-in docs, too?

sincerely, /iaw

---
ivo welch



From dargosch at gmail.com  Wed Aug 10 15:19:59 2005
From: dargosch at gmail.com (Fredrik Karlsson)
Date: Wed, 10 Aug 2005 15:19:59 +0200
Subject: [R] Not loading libraries
In-Reply-To: <Pine.LNX.4.61.0508101250170.12833@gannet.stats>
References: <376e97ec050810041561b1caf5@mail.gmail.com>
	<Pine.LNX.4.61.0508101250170.12833@gannet.stats>
Message-ID: <376e97ec05081006191c2673c3@mail.gmail.com>

Dear list,

I'm sorry about not providing all the necessary details. The R call is: 

"library(tools); Sweave(\"$*.Rnw\")" | R --no-save -q

Using the --vanilla switch, I am able to keep the libraries  from
loading, but since I need some of the datasets in the .RData file, my
call to Sweave fails.
I have not been able to find loading of libraries in an ,Rprofile, and
my options contains this:

> options("defaultPackages")
$defaultPackages
[1] "datasets"  "utils"     "grDevices" "graphics"  "stats"     "methods"  

Prof. Ripley is right when assuming that the libraries are loaded
because of me trying out the Rcmdr GUI and then doing a save.image().
What I did not know was that I managed to  save the loading of
libraries at the same time. This is what I would like to undo.

/Fredrik




On 8/10/05, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Wed, 10 Aug 2005, Fredrik Karlsson wrote:
> 
> > I have a bunch of libraries that are automatically loaded when I start
> > the R environment. How do I remove them?
> 
> By undoing what you did to get them there.
> 
> `make' is not the usual way to start R: try R --vanilla and see what
> happens (probably none of this).  Then read ?Startup and try just 'R'.
> 
> My guess is that has something to do loading Rcmdr afer having set R to
> run with no default packages, but we have no evidence of how you ran R.
> 
> > Output:
> > fredrik at theodor:~/dokument/Thesis/Book$ make
> > Making file voicing.tex from voicing.Rnw
> > Loading Tcl/Tk interface ... done
> > Loading required package: tcltk
> > Loading required package: rgl
> > Loading required package: zoo
> > Loading required package: strucchange
> > Loading required package: sandwich
> > Loading required package: relimp
> > Loading required package: nnet
> > Loading required package: graphics
> > Loading required package: grDevices
> > Loading required package: stats
> > Loading required package: nlme
> > Loading required package: mvtnorm
> > Loading required package: multcomp
> > Loading required package: mgcv
> > This is mgcv 1.3-1
> > Loading required package: MASS
> > Loading required package: lmtest
> > Loading required package: lattice
> > Loading required package: grid
> > Loading required package: foreign
> > Loading required package: effects
> > Loading required package: car
> > Loading required package: abind
> >> library(tools); Sweave("voicing.Rnw")
> > ....
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From tuechler at gmx.at  Wed Aug 10 15:39:21 2005
From: tuechler at gmx.at (Heinz Tuechler)
Date: Wed, 10 Aug 2005 15:39:21 +0200
Subject: [R] how to write assignment form of function
In-Reply-To: <003001c59da9$e6300df0$0540210a@www.domain>
References: <3.0.6.32.20050810142447.007b0410@pop.gmx.net>
Message-ID: <3.0.6.32.20050810153921.00798100@pop.gmx.net>

At 14:49 10.08.2005 +0200, Dimitris Rizopoulos wrote:
>take a look at e.g., get("levels<-.factor"); you should return "x" in 
>your function, i.e.,
>
>y <- x <- factor(c(1,1,NA,2,3,4,4,4,1,2))
>############
>'levels.simple<-' <- function(x, value){
>      attr(x, 'levels') <- value
>      x
> }
>
>levels.simple(y) <- c('a', 'b', 'c', 'd')
>y
>
>
>I hope it helps.
>
>Best,
>Dimitris
>
Dear Dimitris,

Thank you a lot - it helped. Now it works.

Heinz



>----
>Dimitris Rizopoulos
>Ph.D. Student
>Biostatistical Centre
>School of Public Health
>Catholic University of Leuven
>
>Address: Kapucijnenvoer 35, Leuven, Belgium
>Tel: +32/16/336899
>Fax: +32/16/337015
>Web: http://www.med.kuleuven.be/biostat/
>     http://www.student.kuleuven.be/~m0390867/dimitris.htm
>
>
>----- Original Message ----- 
>From: "Heinz Tuechler" <tuechler at gmx.at>
>To: <r-help at stat.math.ethz.ch>
>Sent: Wednesday, August 10, 2005 2:24 PM
>Subject: [R] how to write assignment form of function
>
>
>Dear All,
>
>where can I find information about how to write an assigment form of a
>function?
>For curiosity I tried to write a different form of the 
>levels()-function,
>since the original method for factor deletes all other attributes of a 
>factor.
>Of course, the simple method would be to use instead of levels(x) <-
>newlevels, attr(x, 'levels') <- newlevels.
>
>I tried the following:
>## example
>x <- factor(c(1,1,NA,2,3,4,4,4,1,2)); y <- x
>attr(x, 'levels') <- c('a', 'b', 'c', 'd')     # does what I want
>x
> [1] a    a    <NA> b    c    d    d    d    a    b
>Levels: a b c d
>
>'levels.simple<-' <- function (x, value)
> {
>      attr(x, 'levels') <- value
> }
>
>levels.simple(y) <- c('a', 'b', 'c', 'd')     # does not what I want
>y
>[1] "a" "b" "c" "d"
>
>Thanks,
>Heinz T??chler
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
>
>



From alxmilton at yahoo.it  Wed Aug 10 15:37:04 2005
From: alxmilton at yahoo.it (alessandro carletti)
Date: Wed, 10 Aug 2005 06:37:04 -0700 (PDT)
Subject: [R] date format
Message-ID: <20050810133704.5601.qmail@web26609.mail.ukl.yahoo.com>

Hi,
I have a problem with a vector (x) containing dates in
format "yyyy-mm" (I'm working with monthly means): how
can I convert it in date format, so that I can plot it
recognising trends for my variables?
class(x) says: factor
Thanks
Alex



From christian.hoffmann at wsl.ch  Wed Aug 10 15:49:32 2005
From: christian.hoffmann at wsl.ch (Christian Hoffmann)
Date: Wed, 10 Aug 2005 15:49:32 +0200
Subject: [R] Plit result of pairs in an Sweave compatible manner
Message-ID: <42FA05EC.4090809@wsl.ch>

Hi,

I want to use "pairs" on a fairly big matrix, say more than 30 columns. 
R tries to fit this on one page, which results in tiny invidual 
rectangles, and dots are hard to see.

Is there a way to transform the output of pairs in a way that subplots 
of 10*10, say, rectangles are generated. These subplots should then go 
to Sweave which is accepting one figure at a time presently.

Thanks for help
Christian Hoffmann

PS: In the old S (The New S language, Becker, Chambers, Wilks) there was 
a parameter "max" to split the output.
-- 
Dr. Christian W. Hoffmann,
Swiss Federal Research Institute WSL
Mathematics + Statistical Computing
Zuercherstrasse 111
CH-8903 Birmensdorf, Switzerland

Tel +41-44-7392-277  (office)   -111(exchange)
Fax +41-44-7392-215  (fax)
christian.hoffmann at wsl.ch
http://www.wsl.ch/staff/christian.hoffmann



From ftorrei2 at uiuc.edu  Wed Aug 10 16:02:01 2005
From: ftorrei2 at uiuc.edu (ftorrei2@uiuc.edu)
Date: Wed, 10 Aug 2005 09:02:01 -0500
Subject: [R] Problems with numeric variable containing ? values
Message-ID: <a48b4dd7.29aaeb66.8242700@expms2.cites.uiuc.edu>

Hello,

I have a problem with the values for one column in a table.
The variable represented in this column is numeric (I get TRUE
when I ask is.numeric(x)). However, the values are listed
ordinally and with row numbers as values, not with the ones
that appear in the table. Some rows have an undefined value
for this column, which appears as ? in the table (this is not
an error). I wonder whether these undefined values are causing
the problem.
I need to extract a subset from this column with all rows not
having '?' and then use the subset for a number if analysis.
So far this is not possible since the subset does not have the
real values, but the row numbers mentioned above. Any help?

Thanks in advance,
Francisco Torreira     
Francisco Torreira
Spanish, Italian and Portuguese
Univ. of Illinois at Urbana-Champaign
707 South Mathews Aven.
4031 FLB
Urbana, IL, 61801



From ripley at stats.ox.ac.uk  Wed Aug 10 16:18:33 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 10 Aug 2005 15:18:33 +0100 (BST)
Subject: [R] how to write assignment form of function
In-Reply-To: <3.0.6.32.20050810142447.007b0410@pop.gmx.net>
References: <3.0.6.32.20050810142447.007b0410@pop.gmx.net>
Message-ID: <Pine.LNX.4.61.0508101513210.16636@gannet.stats>

On Wed, 10 Aug 2005, Heinz Tuechler wrote:

> where can I find information about how to write an assigment form of a
> function?

In all good books on S programming, or by studying examples.  But in this 
case the problem is actually about defining functions with the return 
value you expect.

> For curiosity I tried to write a different form of the levels()-function,
> since the original method for factor deletes all other attributes of a factor.
> Of course, the simple method would be to use instead of levels(x) <-
> newlevels, attr(x, 'levels') <- newlevels.

And that would not do what the current function does, which is to merge 
levels as required.

I suggest you look at levels<-.factor in R-devel, which does not drop 
attributes.


> I tried the following:
> ## example
> x <- factor(c(1,1,NA,2,3,4,4,4,1,2)); y <- x
> attr(x, 'levels') <- c('a', 'b', 'c', 'd')     # does what I want
> x
> [1] a    a    <NA> b    c    d    d    d    a    b
> Levels: a b c d
>
> 'levels.simple<-' <- function (x, value)
> {
>      attr(x, 'levels') <- value
> }

This did not return anything!  Try returning 'x'.

> levels.simple(y) <- c('a', 'b', 'c', 'd')     # does not what I want
> y
> [1] "a" "b" "c" "d"


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From br44114 at gmail.com  Wed Aug 10 16:20:56 2005
From: br44114 at gmail.com (bogdan romocea)
Date: Wed, 10 Aug 2005 10:20:56 -0400
Subject: [R] date format
Message-ID: <8d5a3635050810072050e5324e@mail.gmail.com>

You need the day to convert to a date format. Assuming day=15:
x.date <- as.Date(paste(as.character(x),"-15",sep=""),format="%Y-%m-%d")


> -----Original Message-----
> From: alessandro carletti [mailto:alxmilton at yahoo.it] 
> Sent: Wednesday, August 10, 2005 9:37 AM
> To: rHELP
> Subject: [R] date format
> 
> 
> Hi,
> I have a problem with a vector (x) containing dates in
> format "yyyy-mm" (I'm working with monthly means): how
> can I convert it in date format, so that I can plot it
> recognising trends for my variables?
> class(x) says: factor
> Thanks
> Alex
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From efg at stowers-institute.org  Wed Aug 10 16:26:00 2005
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Wed, 10 Aug 2005 09:26:00 -0500
Subject: [R] Digest reading is tedious
References: <20050810014401.0C9824A686@mamba.cc.flinders.edu.au>
	<17145.25102.267486.179160@basebud.nulle.part>
Message-ID: <ddd2pp$96a$1@sea.gmane.org>

"Dirk Eddelbuettel" <edd at debian.org> wrote in message
news:17145.25102.267486.179160 at basebud.nulle.part...
> The R-help (!!) list is available via Gmane.org, a fabulous service that
> archives, redirects, displays, ... a gazillion mailing lists. Among them
are
> are r-help, r-devel, and several r-sig-* lists.  See the top of
>
> http://dir.gmane.org/index.php?prefix=gmane.comp.lang.r
>
> for the current list. By Gmane's convention, -help or -user lists often
end
> up as '*.general'. So r-help is at

Reading these "newsgroups" is a great way to keep up with what's going on
with R without the daily digest tedium:
- gmane.comp.lang.r.general
- gmane.comp.lang.r.devel
- gmane.comp.lang.r.announce

The BioConductor mailing list is also there, but I find its name a bit odd:
- gmane.science.biology.informatics.conductor

The name makes some sense, but I missed it for months because it didn't have
"bioconductor" exactly in the name.

efg



From tlumley at u.washington.edu  Wed Aug 10 16:41:55 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Wed, 10 Aug 2005 07:41:55 -0700 (PDT)
Subject: [R] Exponential, Weibull and log-logistic distributions in glm()
In-Reply-To: <7FFEE688B57D7346BC6241C55900E730F319BD@pollux.bfro.uni-lj.si>
References: <7FFEE688B57D7346BC6241C55900E730F319BD@pollux.bfro.uni-lj.si>
Message-ID: <Pine.A41.4.61b.0508100735340.147026@homer07.u.washington.edu>

On Wed, 10 Aug 2005, Gorjanc Gregor wrote:

> Dear R-users!
>
> I would like to fit exponential, Weibull and log-logistic via glm() like
> functions. Does anyone know a way to do this? Bellow is a bit longer
> description of my problem.

I think you want to use survreg().  It will still work when there is no 
censoring.


Adding these families to glm() would be difficult. They are really not 
generalized linear models in any of the useful senses: not exponential 
families, don't have estimating functions linear in the response 
variable, not fitted by iteratively reweighted least squares.


 	-thomas



From dmb at mrc-dunn.cam.ac.uk  Wed Aug 10 16:53:39 2005
From: dmb at mrc-dunn.cam.ac.uk (Dan Bolser)
Date: Wed, 10 Aug 2005 15:53:39 +0100 (BST)
Subject: [R] Question about curve fitting...
In-Reply-To: <1df0ab1dd53c.1dd53c1df0ab@amc.uva.nl>
Message-ID: <Pine.LNX.4.21.0508101552530.19151-100000@mail.mrc-dunn.cam.ac.uk>

On Wed, 10 Aug 2005, S.O. Nyangoma wrote:

>I see that 
>log(y)=log(k1)+k2*log(x)
>use lm?

Thats a nice solution in this instance, but in general how do I get R to
fit a particular function (formula) and return the parameters?

Cheers,
Dan.

>
>----- Original Message -----
>From: Dan Bolser <dmb at mrc-dunn.cam.ac.uk>
>Date: Wednesday, August 10, 2005 11:41 am
>Subject: [R] Question about curve fitting...
>
>> 
>> Meta:
>> This question is somewhat long and has two parts, I would be very 
>> happyfor someone just to nudge me in the right direction with the 
>> manual /
>> tutorial, as I am somewhat lost...
>> 
>> 
>> 1) How do I fit a curve of the form "y = k1 * x^k2" ?
>> 
>> I want to estimate values of k1 and k2 given the x/y data I have, 
>> and I
>> can't work out how to get R to calculate and return their estimates.
>> 
>> 
>> 2) Given the value of k1 and k2 for population A, how can I test if
>> population B has significantly different values of k1 and k2?
>> 
>> Sorry for the basic question. I think I just need to read up on a few
>> functions.
>> 
>> 
>> I have about 50 xy pairs in total if that makes a difference.
>> 
>> Dan.
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-
>> guide.html
>



From p.dalgaard at biostat.ku.dk  Wed Aug 10 17:01:43 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Aug 2005 17:01:43 +0200
Subject: [R] Question about curve fitting...
In-Reply-To: <Pine.LNX.4.21.0508101552530.19151-100000@mail.mrc-dunn.cam.ac.uk>
References: <Pine.LNX.4.21.0508101552530.19151-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <x2psslkf8o.fsf@turmalin.kubism.ku.dk>

Dan Bolser <dmb at mrc-dunn.cam.ac.uk> writes:

> On Wed, 10 Aug 2005, S.O. Nyangoma wrote:
> 
> >I see that 
> >log(y)=log(k1)+k2*log(x)
> >use lm?
> 
> Thats a nice solution in this instance, but in general how do I get R to
> fit a particular function (formula) and return the parameters?

nls() is your friend.
 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From gunter.berton at gene.com  Wed Aug 10 17:01:24 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 10 Aug 2005 08:01:24 -0700
Subject: [R] Question about curve fitting...
In-Reply-To: <1df0ab1dd53c.1dd53c1df0ab@amc.uva.nl>
Message-ID: <200508101501.j7AF1ONG001169@meitner.gene.com>

As you appeared to have received no reply ...

1) Use nls() on the original equation

2) Transforming first and using linear fitting is **NOT** the same. The
error structures differ and therefore you get different results. The
greatest effect is on inferences -- i.e confidence intervals for the
parameters: the usual asymptotic intervals would be symmetric based on the
original scale, asymmetric based on the transformed. For reasonably
well-behaved data the point estimates shouldn't be too much different,
however. In any case, the linearization is a good way to find starting
values.


-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of S.O. Nyangoma
> Sent: Wednesday, August 10, 2005 3:22 AM
> To: Dan Bolser
> Cc: R mailing list
> Subject: Re: [R] Question about curve fitting...
> 
> I see that 
> log(y)=log(k1)+k2*log(x)
> use lm?
> 
> ----- Original Message -----
> From: Dan Bolser <dmb at mrc-dunn.cam.ac.uk>
> Date: Wednesday, August 10, 2005 11:41 am
> Subject: [R] Question about curve fitting...
> 
> > 
> > Meta:
> > This question is somewhat long and has two parts, I would be very 
> > happyfor someone just to nudge me in the right direction with the 
> > manual /
> > tutorial, as I am somewhat lost...
> > 
> > 
> > 1) How do I fit a curve of the form "y = k1 * x^k2" ?
> > 
> > I want to estimate values of k1 and k2 given the x/y data I have, 
> > and I
> > can't work out how to get R to calculate and return their estimates.
> > 
> > 
> > 2) Given the value of k1 and k2 for population A, how can I test if
> > population B has significantly different values of k1 and k2?
> > 
> > Sorry for the basic question. I think I just need to read 
> up on a few
> > functions.
> > 
> > 
> > I have about 50 xy pairs in total if that makes a difference.
> > 
> > Dan.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-
> > guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From dimitris.rizopoulos at med.kuleuven.be  Wed Aug 10 17:09:00 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 10 Aug 2005 17:09:00 +0200
Subject: [R] Question about curve fitting...
References: <Pine.LNX.4.21.0508101552530.19151-100000@mail.mrc-dunn.cam.ac.uk>
Message-ID: <009d01c59dbd$70201e20$0540210a@www.domain>

I think here it's important to consider how the errors term come into 
the model. If "y = k1 * x^k2 * e" then in the log-scale you have a 
linear model; however if you assume that "y = k1 * x^k2 + e", the you 
want a nonlinear model (i.e., nls()). For instance,

x <- runif(500, 1, 3)
y <- 1 * x^2 + rnorm(500)
m <- nls(y ~ exp(k1 + k2 * log(x)), start = c("k1" = 1, "k2" = 2))
c(exp(coef(m)[1]), coef(m)[2])


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Dan Bolser" <dmb at mrc-dunn.cam.ac.uk>
To: "S.O. Nyangoma" <S.O.Nyangoma at amc.uva.nl>
Cc: "R mailing list" <r-help at stat.math.ethz.ch>
Sent: Wednesday, August 10, 2005 4:53 PM
Subject: Re: [R] Question about curve fitting...


> On Wed, 10 Aug 2005, S.O. Nyangoma wrote:
>
>>I see that
>>log(y)=log(k1)+k2*log(x)
>>use lm?
>
> Thats a nice solution in this instance, but in general how do I get 
> R to
> fit a particular function (formula) and return the parameters?
>
> Cheers,
> Dan.
>
>>
>>----- Original Message -----
>>From: Dan Bolser <dmb at mrc-dunn.cam.ac.uk>
>>Date: Wednesday, August 10, 2005 11:41 am
>>Subject: [R] Question about curve fitting...
>>
>>>
>>> Meta:
>>> This question is somewhat long and has two parts, I would be very
>>> happyfor someone just to nudge me in the right direction with the
>>> manual /
>>> tutorial, as I am somewhat lost...
>>>
>>>
>>> 1) How do I fit a curve of the form "y = k1 * x^k2" ?
>>>
>>> I want to estimate values of k1 and k2 given the x/y data I have,
>>> and I
>>> can't work out how to get R to calculate and return their 
>>> estimates.
>>>
>>>
>>> 2) Given the value of k1 and k2 for population A, how can I test 
>>> if
>>> population B has significantly different values of k1 and k2?
>>>
>>> Sorry for the basic question. I think I just need to read up on a 
>>> few
>>> functions.
>>>
>>>
>>> I have about 50 xy pairs in total if that makes a difference.
>>>
>>> Dan.
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-
>>> guide.html
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From tuechler at gmx.at  Wed Aug 10 17:10:13 2005
From: tuechler at gmx.at (Heinz Tuechler)
Date: Wed, 10 Aug 2005 17:10:13 +0200
Subject: [R] how to write assignment form of function
In-Reply-To: <Pine.LNX.4.61.0508101513210.16636@gannet.stats>
References: <3.0.6.32.20050810142447.007b0410@pop.gmx.net>
	<3.0.6.32.20050810142447.007b0410@pop.gmx.net>
Message-ID: <3.0.6.32.20050810171013.007b35b0@pop.gmx.net>

Dear Professor Ripley,

thank you for your answer. Adding a return value, as also Dimitris
Rizopoulos suggested the function does what I need, that is to rename
factor levels.
I tried to look at levels<-.factor in R-devel but I have to admit that I do
not know exactly where to look and searching I did not find it. For the
moment my problem is solved and I interpret your hint that way that in the
future levels<-.factor will not more drop all other attributes.

Thanks again

Heinz T??chler

At 15:18 10.08.2005 +0100, Prof Brian Ripley wrote:
>On Wed, 10 Aug 2005, Heinz Tuechler wrote:
>
>> where can I find information about how to write an assigment form of a
>> function?
>
>In all good books on S programming, or by studying examples.  But in this 
>case the problem is actually about defining functions with the return 
>value you expect.
>
>> For curiosity I tried to write a different form of the levels()-function,
>> since the original method for factor deletes all other attributes of a
factor.
>> Of course, the simple method would be to use instead of levels(x) <-
>> newlevels, attr(x, 'levels') <- newlevels.
>
>And that would not do what the current function does, which is to merge 
>levels as required.
>
>I suggest you look at levels<-.factor in R-devel, which does not drop 
>attributes.
>
>
>> I tried the following:
>> ## example
>> x <- factor(c(1,1,NA,2,3,4,4,4,1,2)); y <- x
>> attr(x, 'levels') <- c('a', 'b', 'c', 'd')     # does what I want
>> x
>> [1] a    a    <NA> b    c    d    d    d    a    b
>> Levels: a b c d
>>
>> 'levels.simple<-' <- function (x, value)
>> {
>>      attr(x, 'levels') <- value
>> }
>
>This did not return anything!  Try returning 'x'.
>
>> levels.simple(y) <- c('a', 'b', 'c', 'd')     # does not what I want
>> y
>> [1] "a" "b" "c" "d"
>
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>



From ripley at stats.ox.ac.uk  Wed Aug 10 17:15:03 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 10 Aug 2005 16:15:03 +0100 (BST)
Subject: [R] how to write assignment form of function
In-Reply-To: <3.0.6.32.20050810171013.007b35b0@pop.gmx.net>
References: <3.0.6.32.20050810142447.007b0410@pop.gmx.net>
	<3.0.6.32.20050810142447.007b0410@pop.gmx.net>
	<3.0.6.32.20050810171013.007b35b0@pop.gmx.net>
Message-ID: <Pine.LNX.4.61.0508101614350.24505@gannet.stats>

On Wed, 10 Aug 2005, Heinz Tuechler wrote:

> Dear Professor Ripley,
>
> thank you for your answer. Adding a return value, as also Dimitris
> Rizopoulos suggested the function does what I need, that is to rename
> factor levels.
> I tried to look at levels<-.factor in R-devel but I have to admit that I do
> not know exactly where to look and searching I did not find it. For the

https://svn.r-project.org/R/trunk/src/library/base/R/factor.R

> moment my problem is solved and I interpret your hint that way that in the
> future levels<-.factor will not more drop all other attributes.

Yes, that's true.

>
> Thanks again
>
> Heinz T?chler
>
> At 15:18 10.08.2005 +0100, Prof Brian Ripley wrote:
>> On Wed, 10 Aug 2005, Heinz Tuechler wrote:
>>
>>> where can I find information about how to write an assigment form of a
>>> function?
>>
>> In all good books on S programming, or by studying examples.  But in this
>> case the problem is actually about defining functions with the return
>> value you expect.
>>
>>> For curiosity I tried to write a different form of the levels()-function,
>>> since the original method for factor deletes all other attributes of a
> factor.
>>> Of course, the simple method would be to use instead of levels(x) <-
>>> newlevels, attr(x, 'levels') <- newlevels.
>>
>> And that would not do what the current function does, which is to merge
>> levels as required.
>>
>> I suggest you look at levels<-.factor in R-devel, which does not drop
>> attributes.
>>
>>
>>> I tried the following:
>>> ## example
>>> x <- factor(c(1,1,NA,2,3,4,4,4,1,2)); y <- x
>>> attr(x, 'levels') <- c('a', 'b', 'c', 'd')     # does what I want
>>> x
>>> [1] a    a    <NA> b    c    d    d    d    a    b
>>> Levels: a b c d
>>>
>>> 'levels.simple<-' <- function (x, value)
>>> {
>>>      attr(x, 'levels') <- value
>>> }
>>
>> This did not return anything!  Try returning 'x'.
>>
>>> levels.simple(y) <- c('a', 'b', 'c', 'd')     # does not what I want
>>> y
>>> [1] "a" "b" "c" "d"
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From georg.otto at tuebingen.mpg.de  Wed Aug 10 17:16:31 2005
From: georg.otto at tuebingen.mpg.de (Georg Otto)
Date: Wed, 10 Aug 2005 17:16:31 +0200
Subject: [R] RMySQL not loading on Mac OS X
Message-ID: <37839347-B615-479A-9E24-D413EE5034BD@tuebingen.mpg.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050810/e022f779/attachment.pl

From efg at stowers-institute.org  Wed Aug 10 18:18:23 2005
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Wed, 10 Aug 2005 11:18:23 -0500
Subject: [R] Why only a "" string for heading for row.names with write.csv
	with a matrix?
Message-ID: <ddd9cg$14p$1@sea.gmane.org>

Consider:
> x <- matrix(1:6, 2,3)
> rownames(x) <- c("ID1", "ID2")
> colnames(x) <- c("Attr1", "Attr2", "Attr3")

> x
    Attr1 Attr2 Attr3
ID1     1     3     5
ID2     2     4     6

> write.csv(x,file="x.csv")
"","Attr1","Attr2","Attr3"
"ID1",1,3,5
"ID2",2,4,6

Have I missed an easy way to get the "" string to be something meaningful?

There is no information in the "" string.  This column heading for the row
names often could used as a database key, but the "" entry would need to be
manually edited first.  Why not provide a way to specify the string instead
of putting "" as the heading for the rownames?

>From http://finzi.psych.upenn.edu/R/doc/manual/R-data.html

  Header line
  R prefers the header line to have no entry for the row names,
  . . .
  Some other systems require a (possibly empty) entry for the row names,
which is what write.table will provide if argument col.names = NA  is
specified. Excel is one such system.

Why is an "empty" entry the only option here?

A quick solution that comes to mind seems a bit kludgy:

> y <- cbind(rownames(x), x)
> colnames(y)[1] <- "ID"
> y
    ID    Attr1 Attr2 Attr3
ID1 "ID1" "1"   "3"   "5"
ID2 "ID2" "2"   "4"   "6"

> write.table(y, row.names=F, col.names=T, sep=",", file="y.csv")
"ID","Attr1","Attr2","Attr3"
"ID1","1","3","5"
"ID2","2","4","6"

Now the rownames have an "ID" header, which could be used as a key in a
database if desired without editing (but all the "numbers" are now
characters strings, too).

It's also not clear why I had to use write.table above, instead of
write.csv:
> write.csv(y, row.names=F, col.names=T, file="y.csv")
Error in write.table(..., col.names = NA, sep = ",", qmethod = "double") :
        col.names = NA makes no sense when row.names = FALSE

Thanks for any insight about this.

efg
--
Earl F. Glynn
Bioinformatics
Stowers Institute



From tplate at acm.org  Wed Aug 10 19:42:08 2005
From: tplate at acm.org (Tony Plate)
Date: Wed, 10 Aug 2005 11:42:08 -0600
Subject: [R] Why only a "" string for heading for row.names with
 write.csv with a matrix?
In-Reply-To: <ddd9cg$14p$1@sea.gmane.org>
References: <ddd9cg$14p$1@sea.gmane.org>
Message-ID: <42FA3C70.9000805@acm.org>

Here's a relatively easy way to get what I think you want.  Note that 
converting x to a data frame before cbind'ing allows the type of the 
elements of x to be preserved:

 > x <- matrix(1:6, 2,3)
 > rownames(x) <- c("ID1", "ID2")
 > colnames(x) <- c("Attr1", "Attr2", "Attr3")
 > x
     Attr1 Attr2 Attr3
ID1     1     3     5
ID2     2     4     6
 > write.table(cbind(id=row.names(x), as.data.frame(x)), 
row.names=FALSE, sep=",")
"id","Attr1","Attr2","Attr3"
"ID1",1,3,5
"ID2",2,4,6
 >

As to why you can't get this via an argument to write.table (or 
write.csv), I suspect that part of the answer is a wish to avoid 
"creeping featuritis".  Transferring data between programs is 
notoriously infuriating.  There are more data formats than there are 
programs, but few programs use the same format as their default & 
preferred format.  So to accommodate everyone's preferred format would 
require an extremely large number of features in the data import/export 
functions.  Maintaining software that contains a large number of 
features is difficult -- it's easy for errors to creep in because there 
are so many combinations of how different features can be used on 
different functions.

The alternative to having lots of features on each function is to have a 
relatively small set of powerful functions that can be used to construct 
the behavior you want.  This type of software is thought by many to be 
easier to maintain and extend.  I think is is pretty much the preferred 
approach in R.  The above one-liner for writing the data in the form you 
want is really not much more complex than using an additional argument 
to write.table().  (And if you need to do this kind of thing frequently, 
then it's easy in R to create your own wrapper function for 'write.table'.)

One might object to this line of explanation by noting that many 
functions already have many arguments and lots of features.  I think the 
situation is that the original author of any particular function gets to 
decide what features the function will have, and after that there is 
considerable reluctance (justifiably) to add new features, especially in 
cases where there desired functionality can be easily achieved in other 
ways with existing functions.

-- Tony Plate

Earl F. Glynn wrote:
> Consider:
> 
>>x <- matrix(1:6, 2,3)
>>rownames(x) <- c("ID1", "ID2")
>>colnames(x) <- c("Attr1", "Attr2", "Attr3")
> 
> 
>>x
> 
>     Attr1 Attr2 Attr3
> ID1     1     3     5
> ID2     2     4     6
> 
> 
>>write.csv(x,file="x.csv")
> 
> "","Attr1","Attr2","Attr3"
> "ID1",1,3,5
> "ID2",2,4,6
> 
> Have I missed an easy way to get the "" string to be something meaningful?
> 
> There is no information in the "" string.  This column heading for the row
> names often could used as a database key, but the "" entry would need to be
> manually edited first.  Why not provide a way to specify the string instead
> of putting "" as the heading for the rownames?
> 
>>From http://finzi.psych.upenn.edu/R/doc/manual/R-data.html
> 
>   Header line
>   R prefers the header line to have no entry for the row names,
>   . . .
>   Some other systems require a (possibly empty) entry for the row names,
> which is what write.table will provide if argument col.names = NA  is
> specified. Excel is one such system.
> 
> Why is an "empty" entry the only option here?
> 
> A quick solution that comes to mind seems a bit kludgy:
> 
> 
>>y <- cbind(rownames(x), x)
>>colnames(y)[1] <- "ID"
>>y
> 
>     ID    Attr1 Attr2 Attr3
> ID1 "ID1" "1"   "3"   "5"
> ID2 "ID2" "2"   "4"   "6"
> 
> 
>>write.table(y, row.names=F, col.names=T, sep=",", file="y.csv")
> 
> "ID","Attr1","Attr2","Attr3"
> "ID1","1","3","5"
> "ID2","2","4","6"
> 
> Now the rownames have an "ID" header, which could be used as a key in a
> database if desired without editing (but all the "numbers" are now
> characters strings, too).
> 
> It's also not clear why I had to use write.table above, instead of
> write.csv:
> 
>>write.csv(y, row.names=F, col.names=T, file="y.csv")
> 
> Error in write.table(..., col.names = NA, sep = ",", qmethod = "double") :
>         col.names = NA makes no sense when row.names = FALSE
> 
> Thanks for any insight about this.
> 
> efg
> --
> Earl F. Glynn
> Bioinformatics
> Stowers Institute
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From arrayprofile at yahoo.com  Wed Aug 10 20:39:16 2005
From: arrayprofile at yahoo.com (array chip)
Date: Wed, 10 Aug 2005 11:39:16 -0700 (PDT)
Subject: [R] background colors in image()
Message-ID: <20050810183917.95610.qmail@web40808.mail.yahoo.com>

Hi, I am using image() function to plot a matrix which
has some missing valuies (NA). It looks like, by
default, missing values were drawn in white color, How
can I change that into a different color, say a gray
color? I tried to use bg='gray' argument with no luck.
Anyone has a suggestion?

Thanks



From ripley at stats.ox.ac.uk  Wed Aug 10 21:11:56 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 10 Aug 2005 20:11:56 +0100 (BST)
Subject: [R] background colors in image()
In-Reply-To: <20050810183917.95610.qmail@web40808.mail.yahoo.com>
References: <20050810183917.95610.qmail@web40808.mail.yahoo.com>
Message-ID: <Pine.LNX.4.61.0508102002290.31620@gannet.stats>

On Wed, 10 Aug 2005, someone needing to conceal his real name wrote:

> Hi, I am using image() function to plot a matrix which
> has some missing valuies (NA). It looks like, by
> default, missing values were drawn in white color, How
> can I change that into a different color, say a gray
> color? I tried to use bg='gray' argument with no luck.
> Anyone has a suggestion?

They are not drawn in white: in fact they are not drawn at all, so the 
current background (or if transparent, the canvas) is what you see.

> par(bg="yellow")
> image(matrix(c(1,2,NA, 1),2, 2))

works, for example.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rab45+ at pitt.edu  Wed Aug 10 21:14:44 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Wed, 10 Aug 2005 15:14:44 -0400 (EDT)
Subject: [R] repeated - R package
Message-ID: <53921.128.147.28.3.1123701284.squirrel@webmail.pitt.edu>

Thompson's Manual to Accompany Agresti's book refers to a package named
"repeated". It's not on CRAN from what I can see. I have seen rpm's for
it. Where is the best place to download this package?

Rick B.



From ripley at stats.ox.ac.uk  Wed Aug 10 21:25:02 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 10 Aug 2005 20:25:02 +0100 (BST)
Subject: [R] repeated - R package
In-Reply-To: <53921.128.147.28.3.1123701284.squirrel@webmail.pitt.edu>
References: <53921.128.147.28.3.1123701284.squirrel@webmail.pitt.edu>
Message-ID: <Pine.LNX.4.61.0508102021460.31951@gannet.stats>

On Wed, 10 Aug 2005 rab45+ at pitt.edu wrote:

> Thompson's Manual to Accompany Agresti's book refers to a package named
> "repeated". It's not on CRAN from what I can see. I have seen rpm's for
> it. Where is the best place to download this package?

See the FAQ, Q5.1.5.  As to the `best' place, it is hard to say as the URI 
keeps changing: currently it seems to be 
http://popgen.unimaas.nl/~jlindsey/rcode.html.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rchandler at forwild.umass.edu  Wed Aug 10 21:33:23 2005
From: rchandler at forwild.umass.edu (Richard Chandler)
Date: Wed, 10 Aug 2005 15:33:23 -0400
Subject: [R] coxph with cluster() model selection
Message-ID: <1123702403.42fa568379190@mail-www2.oit.umass.edu>

Hello,

Can someone suggest a strategy of selecting a parsimonious coxph model
when there is a cluster() term, a frailty() term and several
potentially important covariates? I have read in the R-help archives
that AIC can not be used when cluster() is.  

My full model looks something like:

fit <- coxph(Surv(start, stop, fate) ~ x1 + x2 + x3 + x4 +
cluster(site) + frailty(year), data)

Thank you.

Richard


-- 
Richard Chandler
Department of Natural Resources Conservation
UMass Amherst
(413)545-1237



From dlvanbrunt at gmail.com  Wed Aug 10 21:50:08 2005
From: dlvanbrunt at gmail.com (David L. Van Brunt, Ph.D.)
Date: Wed, 10 Aug 2005 14:50:08 -0500
Subject: [R] Creating new columns inside a loop
Message-ID: <d332d3e1050810125048ef939b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050810/9bfda744/attachment.pl

From p.dalgaard at biostat.ku.dk  Wed Aug 10 21:55:01 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 10 Aug 2005 21:55:01 +0200
Subject: [R] Creating new columns inside a loop
In-Reply-To: <d332d3e1050810125048ef939b@mail.gmail.com>
References: <d332d3e1050810125048ef939b@mail.gmail.com>
Message-ID: <x2d5olk1nu.fsf@turmalin.kubism.ku.dk>

"David L. Van Brunt, Ph.D." <dlvanbrunt at gmail.com> writes:

> Ok, I know R isn't an optimal environment for looping (or so I've heard) but 
> I have a need to loop through columns of data and create new columns of data 
> based on calculations within rows...
> 
> I'm sure there's a help file, but I'm not sure what search terms to use to 
> find it! The problem is that these new columns need to have names that I can 
> later access... Like NewVar1, NewVar2, etc.... 
> 
> In php I'd call this "indirection" but I'm not sure what to call it in R so 
> that I can find instructions on how to create, name, and address the values 
> stored this way...
> 
> any gentle nudges in the right direction would be greatly appreciated!

A little more information about what you're actually trying to do and
I'm sure someone will give you a nudge with a sledgehammer...

At present, your description is just that little bit too nebulous.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From tuechler at gmx.at  Wed Aug 10 23:25:16 2005
From: tuechler at gmx.at (Heinz Tuechler)
Date: Wed, 10 Aug 2005 23:25:16 +0200
Subject: [R] how to write assignment form of function
Message-ID: <3.0.6.32.20050810232516.007bc710@pop.gmx.net>

At 17:44 10.08.2005 +0100, Patrick Burns wrote:
>S Poetry may be of use to you in this.

Thank you for the hint and thank you for S Poetry. I like it, I read it,
maybe about a year ago, but I don't remember all of it and with all the
material I collected about R it's not always easy to remember where I read
what.

Heinz T??chler
>
>
>Patrick Burns
>patrick at burns-stat.com
>+44 (0)20 8525 0696
>http://www.burns-stat.com
>(home of S Poetry and "A Guide for the Unwilling S User")
>
>Heinz Tuechler wrote:
>
>>Dear All,
>>
>>where can I find information about how to write an assigment form of a
>>function?
>>For curiosity I tried to write a different form of the levels()-function,
>>since the original method for factor deletes all other attributes of a
factor.
>>Of course, the simple method would be to use instead of levels(x) <-
>>newlevels, attr(x, 'levels') <- newlevels.
>>
>>I tried the following:
>>## example
>>x <- factor(c(1,1,NA,2,3,4,4,4,1,2)); y <- x
>>attr(x, 'levels') <- c('a', 'b', 'c', 'd')     # does what I want
>>x
>> [1] a    a    <NA> b    c    d    d    d    a    b   
>>Levels: a b c d
>> 
>>'levels.simple<-' <- function (x, value) 
>> {
>>      attr(x, 'levels') <- value
>> }
>> 
>>levels.simple(y) <- c('a', 'b', 'c', 'd')     # does not what I want
>>y
>>[1] "a" "b" "c" "d"
>> 
>>Thanks,
>>Heinz T??chler
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>>
>>
>>
>>  
>>
>
>



From rab45+ at pitt.edu  Wed Aug 10 23:40:44 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Wed, 10 Aug 2005 17:40:44 -0400 (EDT)
Subject: [R] system is exactly singular
Message-ID: <58432.128.147.28.3.1123710044.squirrel@webmail.pitt.edu>

When trying to fit a generalized linear mixed model using glmmPQL:

> fit0 <- glmmPQL(ifelse(response=="A",1,0)~gender,data=set1,
    random=~1|subject,family=binomial)
iteration 1
Error in solve.default(pdMatrix(a, fact = TRUE)) :
        Lapack routine dgesv: system is exactly singular

Could this be occuring because the paired responses for each subject are
always the same? If this were the case, what would be the best way to
handle this situation?

I replaced the response variable with fake data that are not always the
same for each pair and then I don't get this (or any) error message.

Rick B.



From ripley at stats.ox.ac.uk  Wed Aug 10 23:42:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 10 Aug 2005 22:42:46 +0100 (BST)
Subject: [R] RGUI crash when opening script in XP Home enviroment
In-Reply-To: <Pine.LNX.4.61.0508100824410.20599@gannet.stats>
References: <42F8C714.1030801@biostatistic.de>
	<42F9A630.9030909@biostatistic.de>
	<Pine.LNX.4.61.0508100824410.20599@gannet.stats>
Message-ID: <Pine.LNX.4.61.0508102240100.4491@gannet.stats>

On Wed, 10 Aug 2005, Prof Brian Ripley wrote:

> This is not the place to report reproducible faults: please see the
> posting guide and send a complete bug report to the appropriate place.
> (Let alone three followups from Duncan Mackay!)
>
> However, as I don't know what the `open file button' is, I cannot
> reproduce it.  Is this MDI or SDI mode, and if the former is this using
> the icon on the toolbar, whose tooltip says it is `open script'?
>                                                         ^^^^^^
> What did you expect that to do?
>
> Please make clear in your report if this one or two problems, i.e. is the 
> `not closing completely' only after the error?
>
> This looks like yet another problem caused by adding the script editor, since 
> prior to that there was pager toolbar.

Yes, that was it (it had been told the pager was an editor).  Now fixed in 
R-patched and R-devel.

> On Wed, 10 Aug 2005, Knut Krueger wrote:
>
>> 
>> 
>> Knut Krueger schrieb:
>> 
>>> If  there is a helpfile open (f.e ?glm) and it is the top window, then
>>> an exception error occurs (closing RGUI)
>>> when I hit the open file button.
>>> If the helpfile is not the top window (of the RGUI) I am able to open a
>>> new script without any error.
>>> The RGUI is not closing complete there is a blank screen left which I
>>> have to close with the X Button or Taskmanager
>>> 
>>> Windows XP Home - German Version updates installed.
>>> 
>>> R-Version 2.1.0
>>> 
>>> I
>>> 
>> And it is the same problem with the 2.1.1 patched version
>> http://www.cran.r-project.org/bin/windows/base/rpatched.html
>> 
>> with regards
>> Knut Krueger
>> http://www.biostatistic.de
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>> 
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rab45+ at pitt.edu  Wed Aug 10 23:50:27 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Wed, 10 Aug 2005 17:50:27 -0400 (EDT)
Subject: [R] system is exactly singular
In-Reply-To: <58432.128.147.28.3.1123710044.squirrel@webmail.pitt.edu>
References: <58432.128.147.28.3.1123710044.squirrel@webmail.pitt.edu>
Message-ID: <58749.128.147.28.3.1123710627.squirrel@webmail.pitt.edu>

> When trying to fit a generalized linear mixed model using glmmPQL:
>
>> fit0 <- glmmPQL(ifelse(response=="A",1,0)~gender,data=set1,
>     random=~1|subject,family=binomial)
> iteration 1
> Error in solve.default(pdMatrix(a, fact = TRUE)) :
>         Lapack routine dgesv: system is exactly singular
>
> Could this be occuring because the paired responses for each subject are
> always the same? If this were the case, what would be the best way to
> handle this situation?
>
> I replaced the response variable with fake data that are not always the
> same for each pair and then I don't get this (or any) error message.
>
>

Sorry, I forgot that a variable like gender will be the same for both
responses.

Rick B.



From arrayprofile at yahoo.com  Thu Aug 11 00:59:43 2005
From: arrayprofile at yahoo.com (array chip)
Date: Wed, 10 Aug 2005 15:59:43 -0700 (PDT)
Subject: [R] background colors in image()
In-Reply-To: <Pine.LNX.4.61.0508102002290.31620@gannet.stats>
Message-ID: <20050810225943.37858.qmail@web40808.mail.yahoo.com>

Thanks for the suggestion! It works in a way that the
entire graph window is in the background color, is
there a way to only have the plotting area (i.e. the
area within the axis box in the background color, but
leave the area outside the axes to be unchanged
(white)?

Thanks!

--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On Wed, 10 Aug 2005, someone needing to conceal his
> real name wrote:
> 
> > Hi, I am using image() function to plot a matrix
> which
> > has some missing valuies (NA). It looks like, by
> > default, missing values were drawn in white color,
> How
> > can I change that into a different color, say a
> gray
> > color? I tried to use bg='gray' argument with no
> luck.
> > Anyone has a suggestion?
> 
> They are not drawn in white: in fact they are not
> drawn at all, so the 
> current background (or if transparent, the canvas)
> is what you see.
> 
> > par(bg="yellow")
> > image(matrix(c(1,2,NA, 1),2, 2))
> 
> works, for example.
> 
> -- 
> Brian D. Ripley,                 
> ripley at stats.ox.ac.uk
> Professor of Applied Statistics, 
> http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865
> 272861 (self)
> 1 South Parks Road,                     +44 1865
> 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865
> 272595
>



From aolinto_r at bignet.com.br  Thu Aug 11 01:28:01 2005
From: aolinto_r at bignet.com.br (Antonio Olinto)
Date: Wed, 10 Aug 2005 20:28:01 -0300
Subject: [R] cluster analysis question
Message-ID: <1123716481.42fa8d81cd11e@webmail2.bignet.com.br>

Hi,

I?m using hclust to make a cluster analysis in Q mode, but I have too many
objects (observations) and it?s difficult to identify them in the plot. I?d like
to get a list with the objects ordered in the same way they appear in the cluster.

I have already tried order, labels and merge but I couldn?t get the result I want.

Thanks for any help,

Antonio Olinto



-------------------------------------------------
WebMail Bignet - O seu provedor do litoral
www.bignet.com.br



From ggrothendieck at gmail.com  Thu Aug 11 02:36:28 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 10 Aug 2005 20:36:28 -0400
Subject: [R] date format
In-Reply-To: <8d5a3635050810072050e5324e@mail.gmail.com>
References: <8d5a3635050810072050e5324e@mail.gmail.com>
Message-ID: <971536df0508101736155fd096@mail.gmail.com>

Small point but since:

- the paste function will convert its arguments to character
- as.Date will give you the format requested anyways 
- minus is the logical separator here

we could modify that to:

	as.Date(paste(d, 15, sep = "-"))



On 8/10/05, bogdan romocea <br44114 at gmail.com> wrote:
> You need the day to convert to a date format. Assuming day=15:
> x.date <- as.Date(paste(as.character(x),"-15",sep=""),format="%Y-%m-%d")
> 
> 
> > -----Original Message-----
> > From: alessandro carletti [mailto:alxmilton at yahoo.it]
> > Sent: Wednesday, August 10, 2005 9:37 AM
> > To: rHELP
> > Subject: [R] date format
> >
> >
> > Hi,
> > I have a problem with a vector (x) containing dates in
> > format "yyyy-mm" (I'm working with monthly means): how
> > can I convert it in date format, so that I can plot it
> > recognising trends for my variables?
> > class(x) says: factor
> > Thanks
> > Alex
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Thu Aug 11 02:37:35 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 10 Aug 2005 20:37:35 -0400
Subject: [R] Question about curve fitting...
In-Reply-To: <009d01c59dbd$70201e20$0540210a@www.domain>
References: <Pine.LNX.4.21.0508101552530.19151-100000@mail.mrc-dunn.cam.ac.uk>
	<009d01c59dbd$70201e20$0540210a@www.domain>
Message-ID: <971536df0508101737231a0958@mail.gmail.com>

Note that even if you decide that this distinction is applicable,
you may still wish to run a linear model prior to
nls to get the starting values.  


On 8/10/05, Dimitris Rizopoulos <dimitris.rizopoulos at med.kuleuven.be> wrote:
> I think here it's important to consider how the errors term come into
> the model. If "y = k1 * x^k2 * e" then in the log-scale you have a
> linear model; however if you assume that "y = k1 * x^k2 + e", the you
> want a nonlinear model (i.e., nls()). For instance,
> 
> x <- runif(500, 1, 3)
> y <- 1 * x^2 + rnorm(500)
> m <- nls(y ~ exp(k1 + k2 * log(x)), start = c("k1" = 1, "k2" = 2))
> c(exp(coef(m)[1]), coef(m)[2])
> 
> 
> I hope it helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/336899
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.be/biostat/
>     http://www.student.kuleuven.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message -----
> From: "Dan Bolser" <dmb at mrc-dunn.cam.ac.uk>
> To: "S.O. Nyangoma" <S.O.Nyangoma at amc.uva.nl>
> Cc: "R mailing list" <r-help at stat.math.ethz.ch>
> Sent: Wednesday, August 10, 2005 4:53 PM
> Subject: Re: [R] Question about curve fitting...
> 
> 
> > On Wed, 10 Aug 2005, S.O. Nyangoma wrote:
> >
> >>I see that
> >>log(y)=log(k1)+k2*log(x)
> >>use lm?
> >
> > Thats a nice solution in this instance, but in general how do I get
> > R to
> > fit a particular function (formula) and return the parameters?
> >
> > Cheers,
> > Dan.
> >
> >>
> >>----- Original Message -----
> >>From: Dan Bolser <dmb at mrc-dunn.cam.ac.uk>
> >>Date: Wednesday, August 10, 2005 11:41 am
> >>Subject: [R] Question about curve fitting...
> >>
> >>>
> >>> Meta:
> >>> This question is somewhat long and has two parts, I would be very
> >>> happyfor someone just to nudge me in the right direction with the
> >>> manual /
> >>> tutorial, as I am somewhat lost...
> >>>
> >>>
> >>> 1) How do I fit a curve of the form "y = k1 * x^k2" ?
> >>>
> >>> I want to estimate values of k1 and k2 given the x/y data I have,
> >>> and I
> >>> can't work out how to get R to calculate and return their
> >>> estimates.
> >>>
> >>>
> >>> 2) Given the value of k1 and k2 for population A, how can I test
> >>> if
> >>> population B has significantly different values of k1 and k2?
> >>>
> >>> Sorry for the basic question. I think I just need to read up on a
> >>> few
> >>> functions.
> >>>
> >>>
> >>> I have about 50 xy pairs in total if that makes a difference.
> >>>
> >>> Dan.
> >>>
> >>> ______________________________________________
> >>> R-help at stat.math.ethz.ch mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide!
> >>> http://www.R-project.org/posting-
> >>> guide.html
> >>
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Thu Aug 11 03:58:49 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 10 Aug 2005 21:58:49 -0400
Subject: [R] repeated - R package
In-Reply-To: <Pine.LNX.4.61.0508102021460.31951@gannet.stats>
References: <53921.128.147.28.3.1123701284.squirrel@webmail.pitt.edu>
	<Pine.LNX.4.61.0508102021460.31951@gannet.stats>
Message-ID: <971536df0508101858786a7311@mail.gmail.com>

On 8/10/05, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Wed, 10 Aug 2005 rab45+ at pitt.edu wrote:
> 
> > Thompson's Manual to Accompany Agresti's book refers to a package named
> > "repeated". It's not on CRAN from what I can see. I have seen rpm's for
> > it. Where is the best place to download this package?
> 
> See the FAQ, Q5.1.5.  As to the `best' place, it is hard to say as the URI
> keeps changing: currently it seems to be
> http://popgen.unimaas.nl/~jlindsey/rcode.html.

I have found that one can generally find it from the Related
Projects page on the R site.

That is, from the R home page click on Related Projects (second last link
on the left) and from that page click on Jim Lindsey's R page.



From kjetil at acelerate.com  Thu Aug 11 03:06:28 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Wed, 10 Aug 2005 21:06:28 -0400
Subject: [R] computationally singular
In-Reply-To: <cdf81783050808102211b60eb8@mail.gmail.com>
References: <cdf8178305080809536f18e4ac@mail.gmail.com>	<Pine.LNX.4.58.0508081801570.14535@egon.stats.ucl.ac.uk>
	<cdf81783050808102211b60eb8@mail.gmail.com>
Message-ID: <42FAA494.8070604@acelerate.com>

Weiwei Shi wrote:

>I think the problem might be caused two variables are very correlated.
>Should I check the cov matrix and try to delete some?
>But i am just not quite sure of your reply. Could you detail it with some steps?
>
>thanks,
>  
>
Why not do principal component analysis? To identify the zero variance
linear combination(s) look at the nzero eigenvalues.  Also, it *might* 
make sense
to calculate a " mahalanobis" distance replacing the matrix inverse with a
pseudoinverse.

Kjetil


>weiwei
>
>On 8/8/05, Christian Hennig <chrish at stats.ucl.ac.uk> wrote:
>  
>
>>Once I had a situation where the reason was that the variables were
>>scaled to extremely different magnitudes. 1e-25 is a *very* small number
>>but still there is some probability that it may help to look up standard
>>deviations and to multiply the
>>variable with the smallest st.dev. with 1e20 or something.
>>
>>Best,
>>Christian
>>
>>On Mon, 8 Aug 2005, Weiwei Shi wrote:
>>
>>    
>>
>>>Hi,
>>>I have a dataset which has around 138 variables and 30,000 cases. I am
>>>trying to calculate a mahalanobis distance matrix for them and my
>>>procedure is like this:
>>>
>>>Suppose my data is stored in mymatrix
>>>      
>>>
>>>>S<-cov(mymatrix) # this is fine
>>>>D<-sapply(1:nrow(mymatrix), function(i) mahalanobis(mymatrix, mymatrix[i,], S))
>>>>        
>>>>
>>>Error in solve.default(cov, ...) : system is computationally singular:
>>>reciprocal condition number = 1.09501e-25
>>>
>>>I understand the error message but I don't know how to trace down
>>>which variables caused this so that I can "sacrifice" them if there
>>>are not a lot. Again, not sure if it is due to some variables and not
>>>sure if dropping variables is a good idea either.
>>>
>>>Thanks for help,
>>>
>>>weiwei
>>>
>>>
>>>--
>>>Weiwei Shi, Ph.D
>>>
>>>"Did you always know?"
>>>"No, I did not. But I believed..."
>>>---Matrix III
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>>      
>>>
>>*** NEW ADDRESS! ***
>>Christian Hennig
>>University College London, Department of Statistical Science
>>Gower St., London WC1E 6BT, phone +44 207 679 1698
>>chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche
>>
>>    
>>
>
>
>  
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
Internal Virus Database is out-of-date.
Checked by AVG Anti-Virus.



From helprhelp at gmail.com  Thu Aug 11 04:24:24 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Wed, 10 Aug 2005 21:24:24 -0500
Subject: [R] computationally singular
In-Reply-To: <42FAA494.8070604@acelerate.com>
References: <cdf8178305080809536f18e4ac@mail.gmail.com>
	<Pine.LNX.4.58.0508081801570.14535@egon.stats.ucl.ac.uk>
	<cdf81783050808102211b60eb8@mail.gmail.com>
	<42FAA494.8070604@acelerate.com>
Message-ID: <cdf817830508101924526aa4b9@mail.gmail.com>

PCA definately is worth of trying, which was my second thought. But
thanks for the help and also on the suggestion.

On 8/10/05, Kjetil Brinchmann Halvorsen <kjetil at acelerate.com> wrote:
> Weiwei Shi wrote:
> 
> >I think the problem might be caused two variables are very correlated.
> >Should I check the cov matrix and try to delete some?
> >But i am just not quite sure of your reply. Could you detail it with some steps?
> >
> >thanks,
> >
> >
> Why not do principal component analysis? To identify the zero variance
> linear combination(s) look at the nzero eigenvalues.  Also, it *might*
> make sense
> to calculate a " mahalanobis" distance replacing the matrix inverse with a
> pseudoinverse.
> 
> Kjetil
> 
> 
> >weiwei
> >
> >On 8/8/05, Christian Hennig <chrish at stats.ucl.ac.uk> wrote:
> >
> >
> >>Once I had a situation where the reason was that the variables were
> >>scaled to extremely different magnitudes. 1e-25 is a *very* small number
> >>but still there is some probability that it may help to look up standard
> >>deviations and to multiply the
> >>variable with the smallest st.dev. with 1e20 or something.
> >>
> >>Best,
> >>Christian
> >>
> >>On Mon, 8 Aug 2005, Weiwei Shi wrote:
> >>
> >>
> >>
> >>>Hi,
> >>>I have a dataset which has around 138 variables and 30,000 cases. I am
> >>>trying to calculate a mahalanobis distance matrix for them and my
> >>>procedure is like this:
> >>>
> >>>Suppose my data is stored in mymatrix
> >>>
> >>>
> >>>>S<-cov(mymatrix) # this is fine
> >>>>D<-sapply(1:nrow(mymatrix), function(i) mahalanobis(mymatrix, mymatrix[i,], S))
> >>>>
> >>>>
> >>>Error in solve.default(cov, ...) : system is computationally singular:
> >>>reciprocal condition number = 1.09501e-25
> >>>
> >>>I understand the error message but I don't know how to trace down
> >>>which variables caused this so that I can "sacrifice" them if there
> >>>are not a lot. Again, not sure if it is due to some variables and not
> >>>sure if dropping variables is a good idea either.
> >>>
> >>>Thanks for help,
> >>>
> >>>weiwei
> >>>
> >>>
> >>>--
> >>>Weiwei Shi, Ph.D
> >>>
> >>>"Did you always know?"
> >>>"No, I did not. But I believed..."
> >>>---Matrix III
> >>>
> >>>______________________________________________
> >>>R-help at stat.math.ethz.ch mailing list
> >>>https://stat.ethz.ch/mailman/listinfo/r-help
> >>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >>>
> >>>
> >>>
> >>*** NEW ADDRESS! ***
> >>Christian Hennig
> >>University College London, Department of Statistical Science
> >>Gower St., London WC1E 6BT, phone +44 207 679 1698
> >>chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche
> >>
> >>
> >>
> >
> >
> >
> >
> 
> 
> --
> 
> Kjetil Halvorsen.
> 
> Peace is the most effective weapon of mass construction.
>                --  Mahdi Elmandjra
> 
> 
> 
> 
> 
> --
> Internal Virus Database is out-of-date.
> Checked by AVG Anti-Virus.
> Version: 7.0.338 / Virus Database: 267.9.7/60 - Release Date: 28/07/2005
> 
> 


-- 
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From spencer.graves at pdf.com  Thu Aug 11 05:01:48 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 10 Aug 2005 20:01:48 -0700
Subject: [R] p-values
In-Reply-To: <42F779BF.6090803@estg.ipvc.pt>
References: <42F29071.1000107@fe.up.pt> <42F57353.9040304@pdf.com>
	<42F779BF.6090803@estg.ipvc.pt>
Message-ID: <42FABF9C.2000304@pdf.com>

	  pperm seems reasonable, though I have not looked at the details.

	  We should be careful about terminology, however.  So-called "exact 
p-values" are generally p-values computed assuming a distribution over a 
finite set of possible outcomes assuming some constraints to make the 
outcome space finite.  For example, Fisher's exact test for a 2x2 table 
assumes the marginals are fixed.

	  I don't remember the details now, but I believe there is literature 
claiming that this may not be the best thing to do when, for example, 
when it is reasonable to assume that the number in each cell is Poisson. 
  In such cases, you may lose statistical power by conditioning on the 
marginals.  I hope someone else will enlighten us both, because I'm not 
current on the literature in this area.

	  The situation with "exact tests" and "exact p-values" is not nearly 
as bad as with so-called ""exact confidence intervals", which promise to 
deliver at least the indicated coverage probability.  With discrete 
distributions, it is known that 'Approximate is better than "exact' for 
interval estimation of binomial proportions', as noted in an article of 
this title by A. Agresti and B. A. Coull (1998) American Statistician, 
52:  119-126.  (For more on this particular issue, see Brown, Cai and 
Dasgupta 2003 "Interval Estimation in Exponential Families", Statistica 
Sinica 13:  19-49).

	  If this does not answer your question adequately, may I suggest you 
try the posting guide.  People report having found answers to difficult 
questions in the process of preparing a question following that guide, 
and when they do post a question, they are much more likely to get a 
useful reply.

	  spencer graves

Peter Ho wrote:

> Spencer,
> 
> 
> Thank you for referring me to your other email on Exact goodness-of-fit 
> test. However, I'm not entirely sure if what you mentioned is the same 
> for my case. I'm not a statistician and it would help me if you could 
> explain what you meant in a little more detail. Perhaps I need to 
> explain the problem in more detail.
> 
> I am looking for a way to calculate exaxt p-values by Monte Carlo 
> Simulation for Durbin's test. Durbin's test statistic is similar to 
> Friedman's statistic, but considers the case of Balanced Incomplete 
> block designs. I have found a function written by Felipe de Mendiburu 
> for calculating Durbin's statistic, which gives the chi-squared p-value. 
> I have also been read an article by Torsten Hothorn "On exact rank Tests 
> in R" (R News 1(1), 11?12.) and he has shown how to calculate Monte 
> Carlo p-values using pperm. In the article by Torsten Hothorn he gives:
> 
> R> pperm(W, ranks, length(x))
> 
> He compares his method to that of StatXact, which is the program Rayner 
> and Best suggested using. Is there a way to do this for example for the 
> friedman test.
> 
> A paper by Joachim Rohmel discusses "The permutation distribution for 
> the friendman test" (Computational Statistics & Data Analysis 1997, 26: 
> 83-99). This seems to be on the lines of what I need, although I am not 
> quite sure. Has anyone tried to recode his APL program for R?
> 
> I have tried a number of things, all unsucessful. Searching through 
> previous postings have not been very successful either. It seems that 
> pperm is the way to go, but I would need help from someone on this.
> 
> Any hints on how to continue would be much appreciated.
> 
> 
> Peter
> 
> 
> Spencer Graves wrote:
> 
>> Hi, Peter:
>>
>>       Please see my reply of a few minutes ago subject:  exact 
>> goodness-of-fit test.  I don't know Rayner and Best, but the same 
>> method, I think, should apply.  spencer graves
>>
>> Peter Ho wrote:
>>
>>  
>>
>>> HI R-users,
>>>
>>> I am trying to repeat an example from Rayner and Best "A contingency 
>>> table approach to nonparametric testing (Chapter 7, Ice cream example).
>>>
>>> In their book they calculate Durbin's statistic, D1, a dispersion 
>>> statistics, D2, and a residual. P-values for each statistic is 
>>> calculated from a chi-square distribution and also Monte Carlo p-values.
>>>
>>> I have found similar p-values based on the chi-square distribution by 
>>> using:
>>>
>>> > pchisq(12, df= 6, lower.tail=F)
>>> [1] 0.0619688
>>> > pchisq(5.1, df= 6, lower.tail=F)
>>> [1] 0.5310529
>>>
>>> Is there a way to calculate the equivalent Monte Carlo p-values?
>>>
>>> The values were 0.02 and 0.138 respectively.
>>>
>>> The use of the approximate chi-square probabilities for Durbin's test 
>>> are considered not good enough according to Van der Laan (The 
>>> American Statistician 1988,42,165-166).
>>>
>>>
>>> Peter
>>> --------------------------------
>>> ESTG-IPVC
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>>   
>>
>>
>>  
>>
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From zhliur at yahoo.com  Thu Aug 11 08:10:16 2005
From: zhliur at yahoo.com (yyan liu)
Date: Wed, 10 Aug 2005 23:10:16 -0700 (PDT)
Subject: [R] include C functions from nmath in my own C functions
Message-ID: <20050811061016.84536.qmail@web53112.mail.yahoo.com>

Hi:
  I followed the README in src/nmath/standalone/
to make the use the command "make shared" to make the
libRmath.so file. I also add the directories containg
libRmath.so to  LD_LIBRARY_PATH by using command 
"export
LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$/home/zhliu/Backup/R-2.0.1/src/nmath/standalon
    e
"
However, when I try to run the following codes. 
/***********************************************/
#define MATHLIB_STANDALONE 1
#include <Rmath.h>

int
main()
{
/* something to force the library to be included */
    qnorm(0.7, 0.0, 1.0, 0, 0); 
    return 0;
}
/**************************************************/

It gives me the following error message. It seems
definitions of some R functions can not be found in
the libRmath.so file. Anyone has any idea about this
problem? Thank you very much!


/usr/local/lib/libRmath.so: undefined reference to
`expm1'
/usr/local/lib/libRmath.so: undefined reference to
`log'
/usr/local/lib/libRmath.so: undefined reference to
`sqrt'
/usr/local/lib/libRmath.so: undefined reference to
`rint'
/usr/local/lib/libRmath.so: undefined reference to
`cos'
/usr/local/lib/libRmath.so: undefined reference to
`sin'
/usr/local/lib/libRmath.so: undefined reference to
`pow'
/usr/local/lib/libRmath.so: undefined reference to
`sinh'
/usr/local/lib/libRmath.so: undefined reference to
`log10'
/usr/local/lib/libRmath.so: undefined reference to
`exp'
/usr/local/lib/libRmath.so: undefined reference to
`tan'
/usr/local/lib/libRmath.so: undefined reference to
`log1p'
/usr/local/lib/libRmath.so: undefined reference to
`hypot'
collect2: ld returned 1 exit status



From anne.piotet at ge.ocai.ch  Thu Aug 11 09:44:17 2005
From: anne.piotet at ge.ocai.ch (anne.piotet@ge.ocai.ch)
Date: Thu, 11 Aug 2005 08:44:17 +0100
Subject: [R] connexion problem getHdata (HMisc)
In-Reply-To: <42F91DE3.30004@vanderbilt.edu>
Message-ID: <OF766D8F8D.6180BEF6-ON4125705A.002A0B64-4125705A.002A6A92@ocai.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050811/b1a0d458/attachment.pl

From francoisromain at free.fr  Thu Aug 11 09:03:33 2005
From: francoisromain at free.fr (Romain Francois)
Date: Thu, 11 Aug 2005 09:03:33 +0200
Subject: [R] background colors in image()
In-Reply-To: <20050810225943.37858.qmail@web40808.mail.yahoo.com>
References: <20050810225943.37858.qmail@web40808.mail.yahoo.com>
Message-ID: <42FAF845.3010609@free.fr>

Le 11.08.2005 00:59, array chip a ??crit :

>Thanks for the suggestion! It works in a way that the
>entire graph window is in the background color, is
>there a way to only have the plotting area (i.e. the
>area within the axis box in the background color, but
>leave the area outside the axes to be unchanged
>(white)?
>
>Thanks!
>
>  
>
You need to learn how to use par('usr') and argument add in image.
demo('graphics') is one way to learn or look at graph 8 on r graph gallery

R> image(matrix(c(1,2,NA, 1),2, 2))
R> usr <- par('usr')
R> rect(usr[1], usr[3], usr[2], usr[4], col="cornsilk")
R> image(matrix(c(1,2,NA, 1),2, 2),add=TRUE)

Romain

>--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
>  
>
>>On Wed, 10 Aug 2005, someone needing to conceal his
>>real name wrote:
>>
>>    
>>
>>>Hi, I am using image() function to plot a matrix
>>>      
>>>
>>which
>>    
>>
>>>has some missing valuies (NA). It looks like, by
>>>default, missing values were drawn in white color,
>>>      
>>>
>>How
>>    
>>
>>>can I change that into a different color, say a
>>>      
>>>
>>gray
>>    
>>
>>>color? I tried to use bg='gray' argument with no
>>>      
>>>
>>luck.
>>    
>>
>>>Anyone has a suggestion?
>>>      
>>>
>>They are not drawn in white: in fact they are not
>>drawn at all, so the 
>>current background (or if transparent, the canvas)
>>is what you see.
>>
>>    
>>
>>>par(bg="yellow")
>>>image(matrix(c(1,2,NA, 1),2, 2))
>>>      
>>>
>>works, for example.
>>
>>-- 
>>Brian D. Ripley,                 
>>ripley at stats.ox.ac.uk
>>Professor of Applied Statistics, 
>>http://www.stats.ox.ac.uk/~ripley/
>>University of Oxford,             Tel:  +44 1865
>>272861 (self)
>>1 South Parks Road,                     +44 1865
>>272866 (PA)
>>Oxford OX1 3TG, UK                Fax:  +44 1865
>>272595
>>    
>>

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From sean.oriordain at gmail.com  Thu Aug 11 09:16:48 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Thu, 11 Aug 2005 07:16:48 +0000
Subject: [R] connexion problem getHdata (HMisc)
In-Reply-To: <OF766D8F8D.6180BEF6-ON4125705A.002A0B64-4125705A.002A6A92@ocai.ch>
References: <42F91DE3.30004@vanderbilt.edu>
	<OF766D8F8D.6180BEF6-ON4125705A.002A0B64-4125705A.002A6A92@ocai.ch>
Message-ID: <8ed68eed05081100165754ce4e@mail.gmail.com>

Hi Anne,

does update.packages() work, or does it just hang?

cheers!
Sean

On 11/08/05, anne.piotet at ge.ocai.ch <anne.piotet at ge.ocai.ch> wrote:
> Sorry about the missing info, I'm just trying to do too many things at the
> same time!
> I installed R on my Windows2000 computer (no choice there) .
> 
> > version
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    1.1
> year     2005
> month    06
> day      20
> language R
> 
> Hmisc version: 3.0-6  ;
> 
> On my home computer (LINUX and Windows XT) with the same (latest) R and
> Hmisc version installed, I had no problem with getHdata...
> 
> Thanks
> Anne
> 
> 
> 
> 
> 
> 
> 
> Frank E Harrell Jr <f.harrell at vanderbilt.edu>
> 09.08.2005 22:19
> 
> A
> anne.piotet at ge.ocai.ch
> cc
> r-help at stat.math.ethz.ch
> Objet
> Re: [R] connexion problem getHdata (HMisc)
> 
> 
> 
> 
> 
> 
> anne.piotet at ge.ocai.ch wrote:
> > **********************************************************************
> >  This email and any files transmitted with it are confidential and
> > intended solely for the use of the individual or entity to whom they
> > are addressed. If you have received this email in error please notify
> > the system manager.
> >
> > **********************************************************************
> >
> > Hi
> >
> > Just installing R and some packages in my new job; trying to download
> > dataset directly from
> > biostatistics dptm of Vanderbilt University using getHdata from Hmisc I
> > get the following:
> >
> > Error in file (file, "r") : connexion openinig not possible
> > Furthermore :
> > connexion to 'biostat.mc.vanderbilt.edu' impossible on port 80
> >
> > Can one get around this problem?
> >
> > NOTE: I am not an administrator on the system....
> >
> >
> > Anne Piotet
> 
> It is hard for me to help when you provided no code and no output from
> typing
> 
>   version
> 
> at the command prompt.  You also did not include the version of Hmisc.
> I tried a small test:
> 
> library(Hmisc)
> getHdata(titanic3)
> 
> and it worked fine, using the most recent Hmisc.
> 
> Frank
> 
> >
> >  t??l: 022 809 54 36
> > e-mail: anne.piotet at ge.ocai.ch
> >
> > Office cantonal de l'assurance-invalidit?? (OCAI)
> > rue de Lyon 97
> > 1203 Gen??ve GE
> >
> >                [[alternative HTML version deleted]]
> >
> >
> >
> > ------------------------------------------------------------------------
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> 
> --
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                       Department of Biostatistics   Vanderbilt University
> 
> 
>         [[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From ripley at stats.ox.ac.uk  Thu Aug 11 09:19:13 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Aug 2005 08:19:13 +0100 (BST)
Subject: [R] include C functions from nmath in my own C functions
In-Reply-To: <20050811061016.84536.qmail@web53112.mail.yahoo.com>
References: <20050811061016.84536.qmail@web53112.mail.yahoo.com>
Message-ID: <Pine.LNX.4.61.0508110810060.11057@gannet.stats>

First, please read the posting guide: it says C programming questions 
should go to R-devel so it seems you have not done so.

Second, you have not told us your OS nor what you did to run your code, so 
we have to guess. But sin etc are not 'R functions' but C mathematical 
functions, and the quess is that you failed to link against libm.  Most C 
compilers will do that for you automatically or do not even have a 
separate libm, so telling us your OS (as the posting guide does ask) was 
important.

Please seek local C programming help on how to do this on your OS.

On Wed, 10 Aug 2005, yyan liu wrote:

> Hi:
>  I followed the README in src/nmath/standalone/
> to make the use the command "make shared" to make the
> libRmath.so file. I also add the directories containg
> libRmath.so to  LD_LIBRARY_PATH by using command
> "export
> LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$/home/zhliu/Backup/R-2.0.1/src/nmath/standalon
>    e
> "
> However, when I try to run the following codes.
> /***********************************************/
> #define MATHLIB_STANDALONE 1
> #include <Rmath.h>
>
> int
> main()
> {
> /* something to force the library to be included */
>    qnorm(0.7, 0.0, 1.0, 0, 0);
>    return 0;
> }
> /**************************************************/
>
> It gives me the following error message. It seems
> definitions of some R functions can not be found in
> the libRmath.so file. Anyone has any idea about this
> problem? Thank you very much!
>
>
> /usr/local/lib/libRmath.so: undefined reference to
> `expm1'
> /usr/local/lib/libRmath.so: undefined reference to
> `log'
> /usr/local/lib/libRmath.so: undefined reference to
> `sqrt'
> /usr/local/lib/libRmath.so: undefined reference to
> `rint'
> /usr/local/lib/libRmath.so: undefined reference to
> `cos'
> /usr/local/lib/libRmath.so: undefined reference to
> `sin'
> /usr/local/lib/libRmath.so: undefined reference to
> `pow'
> /usr/local/lib/libRmath.so: undefined reference to
> `sinh'
> /usr/local/lib/libRmath.so: undefined reference to
> `log10'
> /usr/local/lib/libRmath.so: undefined reference to
> `exp'
> /usr/local/lib/libRmath.so: undefined reference to
> `tan'
> /usr/local/lib/libRmath.so: undefined reference to
> `log1p'
> /usr/local/lib/libRmath.so: undefined reference to
> `hypot'
> collect2: ld returned 1 exit status
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From anne.piotet at ge.ocai.ch  Thu Aug 11 10:25:24 2005
From: anne.piotet at ge.ocai.ch (anne.piotet@ge.ocai.ch)
Date: Thu, 11 Aug 2005 09:25:24 +0100
Subject: [R] connexion problem getHdata (HMisc)
In-Reply-To: <8ed68eed05081100165754ce4e@mail.gmail.com>
Message-ID: <OFEFD0EA0F.9D488A54-ON4125705A.002DC285-4125705A.002E2DD5@ocai.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050811/c580eb1d/attachment.pl

From tpapp at Princeton.EDU  Thu Aug 11 09:34:12 2005
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Thu, 11 Aug 2005 09:34:12 +0200
Subject: [R] how to disable RODBC log file
Message-ID: <20050811073412.GA7598@tpapp.student.princeton.edu>

I am using RODBC with Postgresql.  I have disabled the log file in
~/.odbc.ini, but nevertheless I still get a logfile in /tmp, which can
grow to gigabytes, so I would like to disable it.

It appears that the logfile is generated by R:

% lsof | grep /tmp/psqlodbc_tpapp7482.log
R         7482       tpapp    3w      REG        3,5     3127    1668135 /tmp/psqlodbc_tpapp7482.log

Could somebody please tell me how to disable this logfile?  I have
searched the list and help, but found nothing about this.

Thanks,

Tamas



From anne.piotet at ge.ocai.ch  Thu Aug 11 10:49:04 2005
From: anne.piotet at ge.ocai.ch (anne.piotet@ge.ocai.ch)
Date: Thu, 11 Aug 2005 09:49:04 +0100
Subject: [R] connexion problem getHdata (HMisc)
In-Reply-To: <8ed68eed05081100367146a7f8@mail.gmail.com>
Message-ID: <OF67C130F4.50D9B504-ON4125705A.00304C90-4125705A.0030588D@ocai.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050811/867f074e/attachment.pl

From ozric at web.de  Thu Aug 11 10:13:16 2005
From: ozric at web.de (christian schulz)
Date: Thu, 11 Aug 2005 10:13:16 +0200
Subject: [R] conjoint optim
Message-ID: <42FB089C.9050408@web.de>

Hi,

have anybody a starting point or experince  how i could optimize the 
results from a conjoint-ananlysis.
I have the idea to optimize this with 2 function , one for the 
parth-worth utilities which have to maximize and  a secondconcurrent
 for the cost's of  the parth-worth utilities ("product-parts") which 
should be minimize or smaller than value x?

My main problem how i have to construct the formula, beacuse i'm not 
operation research expert.

Easy Example:  
Parth-Worth Utilities
Attribute1: Color (red=0.1,blue=0.3)
Attribute2: Price (100$=0.4,200$=0.2)

So how i could  use it in a formular that only one color and one price 
is choosen from an optimizer to maximize it  (..dummy!?).
In real life it could be up to 20 Attributes and different count's of 
levels.

many thanks & regards,
Christian



From ripley at stats.ox.ac.uk  Thu Aug 11 10:26:24 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Aug 2005 09:26:24 +0100 (BST)
Subject: [R] off-topic ODBC Q (was how to disable RODBC log file)
In-Reply-To: <20050811073412.GA7598@tpapp.student.princeton.edu>
References: <20050811073412.GA7598@tpapp.student.princeton.edu>
Message-ID: <Pine.LNX.4.61.0508110924001.17392@gannet.stats>

RODBC does not have a log file, and this is nothing to do with RODBC or R.

What you are talking about here is an *ODBC* log file, and for that you
need to consult your (unstated) device manager documentation for your
(unstated) OS.

The name of the log file (psqlodbc_*) should have given you a clue: it
seems to be coming from the ODBC driver.

On Thu, 11 Aug 2005, Tamas K Papp wrote:

> I am using RODBC with Postgresql.  I have disabled the log file in
> ~/.odbc.ini, but nevertheless I still get a logfile in /tmp, which can
> grow to gigabytes, so I would like to disable it.
>
> It appears that the logfile is generated by R:
>
> % lsof | grep /tmp/psqlodbc_tpapp7482.log
> R         7482       tpapp    3w      REG        3,5     3127    1668135 /tmp/psqlodbc_tpapp7482.log
>
> Could somebody please tell me how to disable this logfile?  I have
> searched the list and help, but found nothing about this.

> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

PLEASE do as we ask!

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ales.ziberna at guest.arnes.si  Thu Aug 11 10:47:38 2005
From: ales.ziberna at guest.arnes.si (=?iso-8859-2?Q?Ale=B9_=AEiberna?=)
Date: Thu, 11 Aug 2005 10:47:38 +0200
Subject: [R] getting xpinch and ypinch
Message-ID: <00b401c59e51$5a12d390$598debd4@ales>

Hello!

I would like to know if it is possible (and how) to get xpinch and ypinch 
values that R gets (from the system) for drawing plots.

If I understand correctly; with this values I could save the same picture as 
I see on computer 1 on computer 2 as a let say wmf file.

Thank you in advance,
Ales Ziberna



From JohnField at ozemail.com.au  Thu Aug 11 11:41:53 2005
From: JohnField at ozemail.com.au (John Field)
Date: Thu, 11 Aug 2005 19:11:53 +0930
Subject: [R] rpart plot question
Message-ID: <6.2.0.14.2.20050811190215.03130390@pop.ozemail.com.au>

Petr Pikal wrote:

Dear all


I am quite confused by rpart plotting. Here is example.


set.seed(1)

y <- (c(rnorm(10), rnorm(10)+2, rnorm(10)+5))

x <- c(rep(c(1,2,5), c(10,10,10))

fit <- rpart(x~y)    ##  NB should be y~x

plot(fit)

text(fit)


Text on first split says x < 3.5 and on the second split x < 1.5 what

I understand:


If x < 3.5 so y is lower and y values go to the left split. OK. But,

sometimes there is


whatever >= nnn and it seems to me that if this condition is true

response variable follow to right split.


try:


y1<-(c(rnorm(10)+5,rnorm(10)+2, rnorm(10)))

fit<-rpart(y1~x)

plot(fit)

text(fit)


Well, I am not sure I express myself clearly. Am I correct that

when there is < sign I shall follow left node but when there is >=

sign I shall follow the right one?


Best regards

Petr Pikal

Petr Pikal

<https://stat.ethz.ch/mailman/listinfo/r-help>petr.pikal at precheza.cz
If instead of rpart you use mvpart, ie

library(mvpart)
fit <- mvpart(y~x, data=data.frame(cbind(x,y)))
plot(fit)
text.rpart(fit,which=4)

then the plot will be much clearer about the condition for splits.

summary(fit) will also help.

Regards,
John

=============================
John Field Consulting Pty Ltd
10 High St, Burnside SA 5066, Australia
ph: +61 8 8332 5294 or +61 409 097 586
fax: +61 8 8332 1229
email:  JohnField at ozemail.com.au 

From Allan at STATS.uct.ac.za  Thu Aug 11 13:15:48 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Thu, 11 Aug 2005 13:15:48 +0200
Subject: [R] sub set selection
Message-ID: <42FB3364.878FF151@STATS.uct.ac.za>

hi all

is there a package that undertakes subset selection but BASED ON AIC or
any other information criteria.

i've seen the "subselect" and the "leaps" package but i have not played
around with them yet.

thanx

From simone.gabbriellini at sp.unipi.it  Thu Aug 11 14:04:58 2005
From: simone.gabbriellini at sp.unipi.it (Simone Gabbriellini)
Date: Thu, 11 Aug 2005 14:04:58 +0200
Subject: [R] tcltk programming guide
Message-ID: <05BBF16F-8C4D-43AE-8411-A22757CF5145@sp.unipi.it>

Dear List,
I'm looking for some documentation about the R tcltk package
The one I found in the help doesn't look exaustive, I need  
information on the use of the single tk widget, maybe with some examples

thank you,
simone gabbriellini



From jzhang at jimmy.harvard.edu  Thu Aug 11 14:18:21 2005
From: jzhang at jimmy.harvard.edu (John Zhang)
Date: Thu, 11 Aug 2005 08:18:21 -0400 (EDT)
Subject: [R] tcltk programming guide
Message-ID: <20050811121645.663214CD23@pascal.dfci.harvard.edu>

Go to http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/. There are good 
examples.


>X-Original-To: jzhang at jimmy.harvard.edu
>Delivered-To: jzhang at jimmy.harvard.edu
>X-Virus-Scanned: by amavisd-new at stat.math.ethz.ch
>Mime-Version: 1.0 (Apple Message framework v733)
>To: R-help at stat.math.ethz.ch
>From: Simone Gabbriellini <simone.gabbriellini at sp.unipi.it>
>Date: Thu, 11 Aug 2005 14:04:58 +0200
>Subject: [R] tcltk programming guide
>X-BeenThere: r-help at stat.math.ethz.ch
>X-Mailman-Version: 2.1.6
>List-Id: "Main R Mailing List: Primary help" <r-help.stat.math.ethz.ch>
>List-Unsubscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
>List-Archive: <https://stat.ethz.ch/pipermail/r-help>
>List-Post: <mailto:r-help at stat.math.ethz.ch>
>List-Help: <mailto:r-help-request at stat.math.ethz.ch?subject=help>
>List-Subscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>, 
<mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>
>Content-Transfer-Encoding: 7bit
>X-Spam-Checker-Version: SpamAssassin 3.0.1 (2004-10-22) on  
pascal.dfci.harvard.edu
>X-Spam-Level: 
>X-Spam-Status: No, score=-2.6 required=3.0 tests=BAYES_00 autolearn=ham  
version=3.0.1
>
>Dear List,
>I'm looking for some documentation about the R tcltk package
>The one I found in the help doesn't look exaustive, I need  
>information on the use of the single tk widget, maybe with some examples
>
>thank you,
>simone gabbriellini
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Jianhua Zhang
Department of Medical Oncology
Dana-Farber Cancer Institute
44 Binney Street
Boston, MA 02115-6084



From peter at fe.up.pt  Thu Aug 11 14:37:55 2005
From: peter at fe.up.pt (Peter Ho)
Date: Thu, 11 Aug 2005 13:37:55 +0100
Subject: [R] Error in autoloader
Message-ID: <42FB46A3.1020506@fe.up.pt>

Hi,

After installing the latest versions of lme4, Matrix, VR on a Debian 
Box, I have run into a problem. When I use library(lme4) on R Version 
2.1.0  (2005-04-18) I get the following error message:

 > library(lme4)
Loading required package: Matrix
Error in autoloader(name = "confint", package = "MASS") :
        autoloader did not find 'confint' in 'MASS'

An example of the complete session is given at the end of this email. A 
search in the docs.
At present I have 3 directories where packages are kept, as I use 
apt-get install "r-cran-package_ name" when one is available in Debian 
and when it is not R, R CMD INSTALL package_name. This gives me the 
following directories when use help.start():

(1) Packages in /usr/local/lib/R/site-library  (packages installed by R 
CMD INSTALL)

(2) Packages in /usr/lib/R/site-library (packages installed with apt-get 
install)

(3) Packages in /usr/lib/R/library (base install with apt-get install)


Matrix, lme4 and other suggested packages were first installed with R 
CMD INSTALL.  and can be found in /usr/local/lib/R/site-library.  After 
the error occured, I updated VR with apt-get install (found in 
/usr/lib/R/library) and got the same error message.

Installing a second version of lme4 and matrix with apt-get install puts 
these packages in /usr/lib/R/site-library and gives the same error as 
before.

Looking at the MASS no function 'confint' exists, only confint.glm, 
confint.nls,confint.profile.glm and confint.profile.nls

Can anyone suggest a solution to the problem or why I am unable to 
access lme4 or as the error statement suggests, a problem with the 
Matrix package and Mass?



Thanks

Peter



#############################################
R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.1.0  (2005-04-18), ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

Loading Tcl/Tk interface ... done
Loading required package: tcltk
Loading required package: rgl
Loading required package: zoo
Loading required package: strucchange
Loading required package: sandwich
Loading required package: relimp
Loading required package: nnet
Loading required package: graphics
Loading required package: grDevices
Loading required package: stats
Loading required package: nlme

Attaching package: 'nlme'


        The following object(s) are masked from package:stats :

         contr.SAS

Loading required package: mvtnorm
Loading required package: multcomp
Loading required package: mgcv
This is mgcv 1.2-4
Loading required package: MASS
Loading required package: lmtest
Loading required package: lattice
Loading required package: grid
Loading required package: foreign
Loading required package: effects
Loading required package: car
Loading required package: abind
[Previously saved workspace restored]

 > library(lme4)
Loading required package: Matrix
Error in autoloader(name = "confint", package = "MASS") :
        autoloader did not find 'confint' in 'MASS'
 >



From liuwensui at gmail.com  Thu Aug 11 14:38:57 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Thu, 11 Aug 2005 08:38:57 -0400
Subject: [R] sub set selection
In-Reply-To: <42FB3364.878FF151@STATS.uct.ac.za>
References: <42FB3364.878FF151@STATS.uct.ac.za>
Message-ID: <1115a2b005081105388bde7e4@mail.gmail.com>

in what model, glm or gam? I believe you can use aic in both.

On 8/11/05, Clark Allan <Allan at stats.uct.ac.za> wrote:
> hi all
> 
> is there a package that undertakes subset selection but BASED ON AIC or
> any other information criteria.
> 
> i've seen the "subselect" and the "leaps" package but i have not played
> around with them yet.
> 
> thanx
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 


-- 
WenSui Liu, MS MA
Senior Decision Support Analyst
Division of Health Policy and Clinical Effectiveness
Cincinnati Children Hospital Medical Center



From anne.piotet at ge.ocai.ch  Thu Aug 11 15:48:18 2005
From: anne.piotet at ge.ocai.ch (anne.piotet@ge.ocai.ch)
Date: Thu, 11 Aug 2005 14:48:18 +0100
Subject: [R] translation Hmisc Design
Message-ID: <OF88B332C1.642F0BF5-ON4125705A.004A9AFF-4125705A.004BBDC1@ocai.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050811/55b07cb6/attachment.pl

From rab45+ at pitt.edu  Thu Aug 11 14:54:09 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Thu, 11 Aug 2005 08:54:09 -0400 (EDT)
Subject: [R] repeated - R package - Compilation Error
In-Reply-To: <14058.128.147.28.3.1123764485.squirrel@webmail.pitt.edu>
References: <53921.128.147.28.3.1123701284.squirrel@webmail.pitt.edu>
	<Pine.LNX.4.61.0508102021460.31951@gannet.stats>
	<14058.128.147.28.3.1123764485.squirrel@webmail.pitt.edu>
Message-ID: <14187.128.147.28.3.1123764849.squirrel@webmail.pitt.edu>

>> On Wed, 10 Aug 2005 rab45+ at pitt.edu wrote:
>>
>>> Thompson's Manual to Accompany Agresti's book refers to a package named
>>> "repeated". It's not on CRAN from what I can see. I have seen rpm's for
>>> it. Where is the best place to download this package?
>>
>> See the FAQ, Q5.1.5.  As to the `best' place, it is hard to say as the
>> URI
>> keeps changing: currently it seems to be
>> http://popgen.unimaas.nl/~jlindsey/rcode.html.
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>
> I downloaded from the site you suggested but I get an error when
> installing:
>
> drwxr-xr-x  5 root   root     4096 Apr 25  2003 repeated
> -rw-rw-r--  1 chippy chippy 176563 Aug 10 17:05 repeated.tgz
> [root at ophth-bilora R]# man R
> [root at ophth-bilora R]# R CMD INSTALL repeated
> * Installing *source* package 'repeated' ...
> ** libs
> gfortran   -fPIC  -O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32
> -march=i386 -mtune=pentium4 -fasynchronous-unwind-tables -c chidden.f -o
> chidden.o
> gfortran   -fPIC  -O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32
> -march=i386 -mtune=pentium4 -fasynchronous-unwind-tables -c cphidden.f -o
> cphidden.o
> gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC  -O2 -g -pipe
> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32 -march=i386 -mtune=pentium4
> -fasynchronous-unwind-tables -c cutil.c -o cutil.o
> gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC  -O2 -g -pipe
> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32 -march=i386 -mtune=pentium4
> -fasynchronous-unwind-tables -c dist.c -o dist.o
> gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC  -O2 -g -pipe
> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32 -march=i386 -mtune=pentium4
> -fasynchronous-unwind-tables -c gar.c -o gar.o
> gfortran   -fPIC  -O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32
> -march=i386 -mtune=pentium4 -fasynchronous-unwind-tables -c hidden.f -o
> hidden.o
> gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC  -O2 -g -pipe
> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32 -march=i386 -mtune=pentium4
> -fasynchronous-unwind-tables -c kcountb.c -o kcountb.o
> gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC  -O2 -g -pipe
> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32 -march=i386 -mtune=pentium4
> -fasynchronous-unwind-tables -c kserieb.c -o kserieb.o
> gfortran   -fPIC  -O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32
> -march=i386 -mtune=pentium4 -fasynchronous-unwind-tables -c logitord.f -o
> logitord.o
> gfortran   -fPIC  -O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32
> -march=i386 -mtune=pentium4 -fasynchronous-unwind-tables -c binnest.f -o
> binnest.o
>  In file binnest.f:638
>
>              Gradient(t1+t2+kk) = Gradient(t1+t2+kk) + (D1_Sig2(kk) / Li
>                                                                        1
> Error: Expected a right parenthesis in expression at (1)
> make: *** [binnest.o] Error 1
> ERROR: compilation failed for package 'repeated'
>
> I guess I can go in and fix this and try re-compiling.
>
> Rick B.
>
>

When I go into binnest.f, here is what I see:

C       Calculate First Derivative
	   Do kk = 1, t1
	      Gradient(kk) = Gradient(kk) + (D1_beta(kk) / Li)
	   End do
	   Do kk = 1, t2
	      Gradient(t1+kk) = Gradient(t1+kk) + (D1_Sig1(kk) / Li)
	   End do
	   Do kk = 1, t3
line 638 ->Gradient(t1+t2+kk) = Gradient(t1+t2+kk) + (D1_Sig2(kk) / Li)
	   End do

As you can see, line 638 looks just fine.

Why do I get a compilation error?

Rick B.



From rab45+ at pitt.edu  Thu Aug 11 14:48:05 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Thu, 11 Aug 2005 08:48:05 -0400 (EDT)
Subject: [R] repeated - R package - Compilation Error
In-Reply-To: <Pine.LNX.4.61.0508102021460.31951@gannet.stats>
References: <53921.128.147.28.3.1123701284.squirrel@webmail.pitt.edu>
	<Pine.LNX.4.61.0508102021460.31951@gannet.stats>
Message-ID: <14058.128.147.28.3.1123764485.squirrel@webmail.pitt.edu>

> On Wed, 10 Aug 2005 rab45+ at pitt.edu wrote:
>
>> Thompson's Manual to Accompany Agresti's book refers to a package named
>> "repeated". It's not on CRAN from what I can see. I have seen rpm's for
>> it. Where is the best place to download this package?
>
> See the FAQ, Q5.1.5.  As to the `best' place, it is hard to say as the URI
> keeps changing: currently it seems to be
> http://popgen.unimaas.nl/~jlindsey/rcode.html.
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>

I downloaded from the site you suggested but I get an error when installing:

drwxr-xr-x  5 root   root     4096 Apr 25  2003 repeated
-rw-rw-r--  1 chippy chippy 176563 Aug 10 17:05 repeated.tgz
[root at ophth-bilora R]# man R
[root at ophth-bilora R]# R CMD INSTALL repeated
* Installing *source* package 'repeated' ...
** libs
gfortran   -fPIC  -O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32
-march=i386 -mtune=pentium4 -fasynchronous-unwind-tables -c chidden.f -o
chidden.o
gfortran   -fPIC  -O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32
-march=i386 -mtune=pentium4 -fasynchronous-unwind-tables -c cphidden.f -o
cphidden.o
gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC  -O2 -g -pipe
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32 -march=i386 -mtune=pentium4
-fasynchronous-unwind-tables -c cutil.c -o cutil.o
gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC  -O2 -g -pipe
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32 -march=i386 -mtune=pentium4
-fasynchronous-unwind-tables -c dist.c -o dist.o
gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC  -O2 -g -pipe
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32 -march=i386 -mtune=pentium4
-fasynchronous-unwind-tables -c gar.c -o gar.o
gfortran   -fPIC  -O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32
-march=i386 -mtune=pentium4 -fasynchronous-unwind-tables -c hidden.f -o
hidden.o
gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC  -O2 -g -pipe
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32 -march=i386 -mtune=pentium4
-fasynchronous-unwind-tables -c kcountb.c -o kcountb.o
gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC  -O2 -g -pipe
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32 -march=i386 -mtune=pentium4
-fasynchronous-unwind-tables -c kserieb.c -o kserieb.o
gfortran   -fPIC  -O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32
-march=i386 -mtune=pentium4 -fasynchronous-unwind-tables -c logitord.f -o
logitord.o
gfortran   -fPIC  -O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32
-march=i386 -mtune=pentium4 -fasynchronous-unwind-tables -c binnest.f -o
binnest.o
 In file binnest.f:638

             Gradient(t1+t2+kk) = Gradient(t1+t2+kk) + (D1_Sig2(kk) / Li
                                                                       1
Error: Expected a right parenthesis in expression at (1)
make: *** [binnest.o] Error 1
ERROR: compilation failed for package 'repeated'

I guess I can go in and fix this and try re-compiling.

Rick B.



From Allan at STATS.uct.ac.za  Thu Aug 11 15:02:37 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Thu, 11 Aug 2005 15:02:37 +0200
Subject: [R] sub set selection
References: <42FB3364.878FF151@STATS.uct.ac.za>
	<1115a2b005081105388bde7e4@mail.gmail.com>
Message-ID: <42FB4C6D.AE74658A@STATS.uct.ac.za>

just normal linear model: multiple regression in particular

Wensui Liu wrote:
> 
> in what model, glm or gam? I believe you can use aic in both.
> 
> On 8/11/05, Clark Allan <Allan at stats.uct.ac.za> wrote:
> > hi all
> >
> > is there a package that undertakes subset selection but BASED ON AIC or
> > any other information criteria.
> >
> > i've seen the "subselect" and the "leaps" package but i have not played
> > around with them yet.
> >
> > thanx
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> >
> 
> --
> WenSui Liu, MS MA
> Senior Decision Support Analyst
> Division of Health Policy and Clinical Effectiveness
> Cincinnati Children Hospital Medical Center

From rab45+ at pitt.edu  Thu Aug 11 15:00:52 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Thu, 11 Aug 2005 09:00:52 -0400 (EDT)
Subject: [R] repeated - R package - Compilation Error
In-Reply-To: <14187.128.147.28.3.1123764849.squirrel@webmail.pitt.edu>
References: <53921.128.147.28.3.1123701284.squirrel@webmail.pitt.edu>
	<Pine.LNX.4.61.0508102021460.31951@gannet.stats>
	<14058.128.147.28.3.1123764485.squirrel@webmail.pitt.edu>
	<14187.128.147.28.3.1123764849.squirrel@webmail.pitt.edu>
Message-ID: <14433.128.147.28.3.1123765252.squirrel@webmail.pitt.edu>


>
> When I go into binnest.f, here is what I see:
>
> C       Calculate First Derivative
> 	   Do kk = 1, t1
> 	      Gradient(kk) = Gradient(kk) + (D1_beta(kk) / Li)
> 	   End do
> 	   Do kk = 1, t2
> 	      Gradient(t1+kk) = Gradient(t1+kk) + (D1_Sig1(kk) / Li)
> 	   End do
> 	   Do kk = 1, t3
> line 638 ->Gradient(t1+t2+kk) = Gradient(t1+t2+kk) + (D1_Sig2(kk) / Li)
> 	   End do
>
> As you can see, line 638 looks just fine.
>
> Why do I get a compilation error?
>
> Rick B.
>
>

I used a text editor to remove two blanks from the front of line 638 and
it compiled without errors. Now I have to find the "rmutil" package and
install it to get repeated working.

Rick B.



From rab45+ at pitt.edu  Thu Aug 11 15:12:47 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Thu, 11 Aug 2005 09:12:47 -0400 (EDT)
Subject: [R] repeated - R package - Now rmutil Compilation Errors
In-Reply-To: <14187.128.147.28.3.1123764849.squirrel@webmail.pitt.edu>
References: <53921.128.147.28.3.1123701284.squirrel@webmail.pitt.edu>
	<Pine.LNX.4.61.0508102021460.31951@gannet.stats>
	<14058.128.147.28.3.1123764485.squirrel@webmail.pitt.edu>
	<14187.128.147.28.3.1123764849.squirrel@webmail.pitt.edu>
Message-ID: <14818.128.147.28.3.1123765967.squirrel@webmail.pitt.edu>

In my quest to install the repeated package, I have also to install the
"rmutil" package. (BTW, I'm running Fedora Core 4 and R 2.1.1.) But I now
get several compilation errors for rmutil and I'm afraid to try to fix
them:

[root at ophth-bilora R]# R CMD INSTALL rmutil
* Installing *source* package 'rmutil' ...
** libs
gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC  -O2 -g -pipe
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32 -march=i386 -mtune=pentium4
-fasynchronous-unwind-tables -c cutil.c -o cutil.o
gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC  -O2 -g -pipe
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32 -march=i386 -mtune=pentium4
-fasynchronous-unwind-tables -c dist.c -o dist.o
gfortran   -fPIC  -O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32
-march=i386 -mtune=pentium4 -fasynchronous-unwind-tables -c gettvc.f -o
gettvc.o
 In file gettvc.f:55

            tvcov2(n,i)=-1e301
                             1
Error: Real constant overflows its kind at (1)
 In file gettvc.f:79

               recx=1e301
                        1
Error: Real constant overflows its kind at (1)
 In file gettvc.f:84

               reck=1e301
                        1
Error: Real constant overflows its kind at (1)
 In file gettvc.f:86

            if((recx.ge.1e300).and.(reck.ge.1e300)) ldone=.true.
                            1
Error: Real constant overflows its kind at (1)
make: *** [gettvc.o] Error 1
ERROR: compilation failed for package 'rmutil'

I downloaded both repeated and rmutil (for R > 2.0) from:

http://popgen.unimaas.nl/~jlindsey/rcode.html


Rick B.



From Roger.Bivand at nhh.no  Thu Aug 11 15:19:04 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 11 Aug 2005 15:19:04 +0200 (CEST)
Subject: [R] repeated - R package - Compilation Error
In-Reply-To: <14433.128.147.28.3.1123765252.squirrel@webmail.pitt.edu>
Message-ID: <Pine.LNX.4.44.0508111511160.14876-100000@reclus.nhh.no>

On Thu, 11 Aug 2005 rab45+ at pitt.edu wrote:

> 
> >
> > When I go into binnest.f, here is what I see:
> >
> > C       Calculate First Derivative
> > 	   Do kk = 1, t1
> > 	      Gradient(kk) = Gradient(kk) + (D1_beta(kk) / Li)
> > 	   End do
> > 	   Do kk = 1, t2
> > 	      Gradient(t1+kk) = Gradient(t1+kk) + (D1_Sig1(kk) / Li)
> > 	   End do
> > 	   Do kk = 1, t3
> > line 638 ->Gradient(t1+t2+kk) = Gradient(t1+t2+kk) + (D1_Sig2(kk) / Li)
> > 	   End do
> >
> > As you can see, line 638 looks just fine.
> >
> > Why do I get a compilation error?
> >
> > Rick B.
> >
> >
> 
> I used a text editor to remove two blanks from the front of line 638 and
> it compiled without errors. Now I have to find the "rmutil" package and
> install it to get repeated working.

Well spotted, almost certainly the closing bracket was not seen by the
compiler because it ran into the comment field of the line (columns beyond
72), and failed with unmatched brackets. Some compilers allow arbitrarily
long lines, but apparently not yours.

> 
> Rick B.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From liuwensui at gmail.com  Thu Aug 11 15:19:48 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Thu, 11 Aug 2005 09:19:48 -0400
Subject: [R] sub set selection
In-Reply-To: <42FB3364.878FF151@STATS.uct.ac.za>
References: <42FB3364.878FF151@STATS.uct.ac.za>
Message-ID: <1115a2b005081106193841d257@mail.gmail.com>

check stepAIC in MASS package. 



On 8/11/05, Clark Allan <Allan at stats.uct.ac.za> wrote:
> hi all
> 
> is there a package that undertakes subset selection but BASED ON AIC or
> any other information criteria.
> 
> i've seen the "subselect" and the "leaps" package but i have not played
> around with them yet.
> 
> thanx
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 


-- 
WenSui Liu, MS MA
Senior Decision Support Analyst
Division of Health Policy and Clinical Effectiveness
Cincinnati Children Hospital Medical Center



From peter at estg.ipvc.pt  Thu Aug 11 15:28:00 2005
From: peter at estg.ipvc.pt (Peter Ho)
Date: Thu, 11 Aug 2005 14:28:00 +0100
Subject: [R] p-values
In-Reply-To: <42FABF9C.2000304@pdf.com>
References: <42F29071.1000107@fe.up.pt> <42F57353.9040304@pdf.com>
	<42F779BF.6090803@estg.ipvc.pt> <42FABF9C.2000304@pdf.com>
Message-ID: <42FB5260.9050607@estg.ipvc.pt>

Spencer,

Here is an example from rayner and best 2001 and the script sent by 
Felipe.  This can be done as follows using the function durbin.grupos() 
in the attached file

 > ###Ice cream example from Rayner and Best 2001 . Chapter 7
 > judge <- rep(c(1:7),rep(3,7))
 > variety <- c(1,2,4,2,3,5,3,4,6,4,5,7,1,5,6,2,6,7,1,3,7)
 > cream <- c(2,3,1,3,1,2,2,1,3,1,2,3,3,1,2,3,1,2,3,1,2)
 > durbin.grupos(judge,variety,cream,k=3,r=3,alpha=0.01)

Prueba de Durbin
..............
Chi Cuadrado :  12
Gl.          :  6
P-valor      :  0.0619688
..............
Comparación de tratamientos

Alpha        :  0.01
Gl.          :  8
t-Student    :  3.355387
Diferencia minima
para la diferencia entre suma de rangos =  4.109493

Grupos, Tratamientos y la Suma de sus rangos
a        2       9
ab       1       8
abc      7       7
abc      6       6
abc      5       5
 bc      3       4
  c      4       3
  trat prom   M
1    2    9   a
2    1    8  ab
3    7    7 abc
4    6    6 abc
5    5    5 abc
6    3    4  bc
7    4    3   c
 >                              

You can see that the p-value is the same with

 > pchisq(12, df= 6, lower.tail=F)
[1] 0.0619688

I am hoping that someone, maybe Torsten, might be able to suggest how I 
can incorporate Monte-Carlo p-values using pperm().  The statistical 
issues are beyond my comprehension and I assume that Rayner and Best 
suggestion to use Monte-Carlo p-values instead of Chi-square p-values to 
be correct. In the above example the Monte-Carlo p-value is 0.02. This 
is a significant difference, resulting in the rejection of the null 
hypothesis when using Monte-Carlo p-values.

I hope this example might help. Thanks again for your answer and also to 
Felipe for sending the function for Durbin's test.



Peter



Spencer Graves wrote:

>       pperm seems reasonable, though I have not looked at the details.
>
>       We should be careful about terminology, however.  So-called 
> "exact p-values" are generally p-values computed assuming a 
> distribution over a finite set of possible outcomes assuming some 
> constraints to make the outcome space finite.  For example, Fisher's 
> exact test for a 2x2 table assumes the marginals are fixed.
>
>       I don't remember the details now, but I believe there is 
> literature claiming that this may not be the best thing to do when, 
> for example, when it is reasonable to assume that the number in each 
> cell is Poisson.  In such cases, you may lose statistical power by 
> conditioning on the marginals.  I hope someone else will enlighten us 
> both, because I'm not current on the literature in this area.
>
>       The situation with "exact tests" and "exact p-values" is not 
> nearly as bad as with so-called ""exact confidence intervals", which 
> promise to deliver at least the indicated coverage probability.  With 
> discrete distributions, it is known that 'Approximate is better than 
> "exact' for interval estimation of binomial proportions', as noted in 
> an article of this title by A. Agresti and B. A. Coull (1998) American 
> Statistician, 52:  119-126.  (For more on this particular issue, see 
> Brown, Cai and Dasgupta 2003 "Interval Estimation in Exponential 
> Families", Statistica Sinica 13:  19-49).
>
>       If this does not answer your question adequately, may I suggest 
> you try the posting guide.  People report having found answers to 
> difficult questions in the process of preparing a question following 
> that guide, and when they do post a question, they are much more 
> likely to get a useful reply.
>
>       spencer graves
>
> Peter Ho wrote:
>
>> Spencer,
>>
>>
>> Thank you for referring me to your other email on Exact 
>> goodness-of-fit test. However, I'm not entirely sure if what you 
>> mentioned is the same for my case. I'm not a statistician and it 
>> would help me if you could explain what you meant in a little more 
>> detail. Perhaps I need to explain the problem in more detail.
>>
>> I am looking for a way to calculate exaxt p-values by Monte Carlo 
>> Simulation for Durbin's test. Durbin's test statistic is similar to 
>> Friedman's statistic, but considers the case of Balanced Incomplete 
>> block designs. I have found a function written by Felipe de Mendiburu 
>> for calculating Durbin's statistic, which gives the chi-squared 
>> p-value. I have also been read an article by Torsten Hothorn "On 
>> exact rank Tests in R" (R News 1(1), 11–12.) and he has shown how to 
>> calculate Monte Carlo p-values using pperm. In the article by Torsten 
>> Hothorn he gives:
>>
>> R> pperm(W, ranks, length(x))
>>
>> He compares his method to that of StatXact, which is the program 
>> Rayner and Best suggested using. Is there a way to do this for 
>> example for the friedman test.
>>
>> A paper by Joachim Rohmel discusses "The permutation distribution for 
>> the friendman test" (Computational Statistics & Data Analysis 1997, 
>> 26: 83-99). This seems to be on the lines of what I need, although I 
>> am not quite sure. Has anyone tried to recode his APL program for R?
>>
>> I have tried a number of things, all unsucessful. Searching through 
>> previous postings have not been very successful either. It seems that 
>> pperm is the way to go, but I would need help from someone on this.
>>
>> Any hints on how to continue would be much appreciated.
>>
>>
>> Peter
>>
>>
>> Spencer Graves wrote:
>>
>>> Hi, Peter:
>>>
>>>       Please see my reply of a few minutes ago subject:  exact 
>>> goodness-of-fit test.  I don't know Rayner and Best, but the same 
>>> method, I think, should apply.  spencer graves
>>>
>>> Peter Ho wrote:
>>>
>>>  
>>>
>>>> HI R-users,
>>>>
>>>> I am trying to repeat an example from Rayner and Best "A 
>>>> contingency table approach to nonparametric testing (Chapter 7, Ice 
>>>> cream example).
>>>>
>>>> In their book they calculate Durbin's statistic, D1, a dispersion 
>>>> statistics, D2, and a residual. P-values for each statistic is 
>>>> calculated from a chi-square distribution and also Monte Carlo 
>>>> p-values.
>>>>
>>>> I have found similar p-values based on the chi-square distribution 
>>>> by using:
>>>>
>>>> > pchisq(12, df= 6, lower.tail=F)
>>>> [1] 0.0619688
>>>> > pchisq(5.1, df= 6, lower.tail=F)
>>>> [1] 0.5310529
>>>>
>>>> Is there a way to calculate the equivalent Monte Carlo p-values?
>>>>
>>>> The values were 0.02 and 0.138 respectively.
>>>>
>>>> The use of the approximate chi-square probabilities for Durbin's 
>>>> test are considered not good enough according to Van der Laan (The 
>>>> American Statistician 1988,42,165-166).
>>>>
>>>>
>>>> Peter
>>>> --------------------------------
>>>> ESTG-IPVC
>>>>
>>>> ______________________________________________
>>>> R-help at stat.math.ethz.ch mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide! 
>>>> http://www.R-project.org/posting-guide.html
>>>>   
>>>
>>>
>>>
>>>  
>>>
>>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Durbin.r
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050811/17206e5f/Durbin.pl

From rab45+ at pitt.edu  Thu Aug 11 15:25:14 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Thu, 11 Aug 2005 09:25:14 -0400 (EDT)
Subject: [R] repeated - R package - Compilation Error
In-Reply-To: <42FB4F56.8080501@gsf.de>
References: <53921.128.147.28.3.1123701284.squirrel@webmail.pitt.edu>
	<Pine.LNX.4.61.0508102021460.31951@gannet.stats>
	<14058.128.147.28.3.1123764485.squirrel@webmail.pitt.edu>
	<14187.128.147.28.3.1123764849.squirrel@webmail.pitt.edu>
	<14433.128.147.28.3.1123765252.squirrel@webmail.pitt.edu>
	<42FB4F56.8080501@gsf.de>
Message-ID: <15783.128.147.28.3.1123766714.squirrel@webmail.pitt.edu>

> You know what spams are?
> It is highly recommended to try such basic things and to get the
> depencies right _before_ posting to mailing lists.
>
> Regards
>
> Michael
>
> rab45+ at pitt.edu wrote:
>>>When I go into binnest.f, here is what I see:
>>>
>>>C       Calculate First Derivative
>>>	   Do kk = 1, t1
>>>	      Gradient(kk) = Gradient(kk) + (D1_beta(kk) / Li)
>>>	   End do
>>>	   Do kk = 1, t2
>>>	      Gradient(t1+kk) = Gradient(t1+kk) + (D1_Sig1(kk) / Li)
>>>	   End do
>>>	   Do kk = 1, t3
>>>line 638 ->Gradient(t1+t2+kk) = Gradient(t1+t2+kk) + (D1_Sig2(kk) / Li)
>>>	   End do
>>>
>>>As you can see, line 638 looks just fine.
>>>
>>>Why do I get a compilation error?
>>>
>>>Rick B.
>>>
>>>
>>
>>
>> I used a text editor to remove two blanks from the front of line 638 and
>> it compiled without errors. Now I have to find the "rmutil" package and
>> install it to get repeated working.
>>
>> Rick B.
>>


I'm not sure what your point is. I'm getting a compilation error for a
package that should compile without errors. The error message doesn't say
anything about needing anything - it doesn't complain about
"dependencies." Now once I got repeated to compile, it did give a
*warning" message about needing rmutils. But rmutils won't compile and
gives several error messages (in my other post). I've installed many R
packages and I've never seen problems like this before.

Rick B.



From Roger.Bivand at nhh.no  Thu Aug 11 15:39:38 2005
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 11 Aug 2005 15:39:38 +0200 (CEST)
Subject: [R] repeated - R package - Now rmutil Compilation Errors
In-Reply-To: <14818.128.147.28.3.1123765967.squirrel@webmail.pitt.edu>
Message-ID: <Pine.LNX.4.44.0508111525140.14876-100000@reclus.nhh.no>

On Thu, 11 Aug 2005 rab45+ at pitt.edu wrote:

> In my quest to install the repeated package, I have also to install the
> "rmutil" package. (BTW, I'm running Fedora Core 4 and R 2.1.1.) But I now
> get several compilation errors for rmutil and I'm afraid to try to fix
> them:
> 
> [root at ophth-bilora R]# R CMD INSTALL rmutil
> * Installing *source* package 'rmutil' ...
> ** libs
> gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC  -O2 -g -pipe
> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32 -march=i386 -mtune=pentium4
> -fasynchronous-unwind-tables -c cutil.c -o cutil.o
> gcc -I/usr/lib/R/include  -I/usr/local/include   -fPIC  -O2 -g -pipe
> -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32 -march=i386 -mtune=pentium4
> -fasynchronous-unwind-tables -c dist.c -o dist.o
> gfortran   -fPIC  -O2 -g -pipe -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -m32
> -march=i386 -mtune=pentium4 -fasynchronous-unwind-tables -c gettvc.f -o
> gettvc.o
>  In file gettvc.f:55
> 
>             tvcov2(n,i)=-1e301
>                              1
> Error: Real constant overflows its kind at (1)
>  In file gettvc.f:79
> 
>                recx=1e301
>                         1
> Error: Real constant overflows its kind at (1)
>  In file gettvc.f:84
> 
>                reck=1e301
>                         1
> Error: Real constant overflows its kind at (1)
>  In file gettvc.f:86
> 
>             if((recx.ge.1e300).and.(reck.ge.1e300)) ldone=.true.
>                             1
> Error: Real constant overflows its kind at (1)
> make: *** [gettvc.o] Error 1
> ERROR: compilation failed for package 'rmutil'
> 
> I downloaded both repeated and rmutil (for R > 2.0) from:
> 
> http://popgen.unimaas.nl/~jlindsey/rcode.html
> 

Please note that you are using gfortran rather than g77 - they are not the
same, and very possibly differ in how they react to code. The 1e301
constants do overflow the maximum real value (of the order of 3e+38), but
1d301 is less than the maximum double value of the order of 1.7e+308. So
the variable declarations in the code do not seem to match the constants
being used, which probably ought to have been written as "d" rather than
"e" anyway. It doesn't look as though you'll be able to compile this code
with your chosen compiler, could you rather try g77? There seems to be
useful advice on the Fedora lists.

> 
> Rick B.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger Bivand
Economic Geography Section, Department of Economics, Norwegian School of
Economics and Business Administration, Helleveien 30, N-5045 Bergen,
Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
e-mail: Roger.Bivand at nhh.no



From rab45+ at pitt.edu  Thu Aug 11 15:44:44 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Thu, 11 Aug 2005 09:44:44 -0400 (EDT)
Subject: [R] repeated - R package - Now rmutil Compilation Errors
In-Reply-To: <Pine.LNX.4.44.0508111525140.14876-100000@reclus.nhh.no>
References: <14818.128.147.28.3.1123765967.squirrel@webmail.pitt.edu>
	<Pine.LNX.4.44.0508111525140.14876-100000@reclus.nhh.no>
Message-ID: <16488.128.147.28.3.1123767884.squirrel@webmail.pitt.edu>


>
> Please note that you are using gfortran rather than g77 - they are not the
> same, and very possibly differ in how they react to code. The 1e301
> constants do overflow the maximum real value (of the order of 3e+38), but
> 1d301 is less than the maximum double value of the order of 1.7e+308. So
> the variable declarations in the code do not seem to match the constants
> being used, which probably ought to have been written as "d" rather than
> "e" anyway. It doesn't look as though you'll be able to compile this code
> with your chosen compiler, could you rather try g77? There seems to be
> useful advice on the Fedora lists.
>
>>
>> Rick B.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> --
> Roger Bivand
> Economic Geography Section, Department of Economics, Norwegian School of
> Economics and Business Administration, Helleveien 30, N-5045 Bergen,
> Norway. voice: +47 55 95 93 55; fax +47 55 95 95 43
> e-mail: Roger.Bivand at nhh.no
>
>
>
>

I think you are correct. Before I read your message I did a man page for
gfortran and it says that it is not complete. Why FC4 choose this
incomplete fortran compiler is beyond me. I have installed g77 and now
trying to remove gfortran.

Thanks.

Rick B.



From owzar001 at mc.duke.edu  Thu Aug 11 16:02:00 2005
From: owzar001 at mc.duke.edu (Kouros Owzar)
Date: Thu, 11 Aug 2005 10:02:00 -0400
Subject: [R] Kouros Owzar is out
Message-ID: <OF0A24D350.A4681856-ON8525705A.004D1670-8525705A.004D1670@notes.duke.edu>


I will be out of the office starting  08/10/2005 and will not return until
08/15/2005.



From tlumley at u.washington.edu  Thu Aug 11 16:33:23 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 11 Aug 2005 07:33:23 -0700 (PDT)
Subject: [R] sub set selection
In-Reply-To: <42FB3364.878FF151@STATS.uct.ac.za>
References: <42FB3364.878FF151@STATS.uct.ac.za>
Message-ID: <Pine.A41.4.61b.0508110732380.79090@homer07.u.washington.edu>

On Thu, 11 Aug 2005, Clark Allan wrote:

> hi all
>
> is there a package that undertakes subset selection but BASED ON AIC or
> any other information criteria.
>
> i've seen the "subselect" and the "leaps" package but i have not played
> around with them yet.

The leaps package finds a best model of each size, so all the standard 
criteria are equivalent. It can report AIC or BIC for each of these 
models.

 	-thomas



From amsa36060 at yahoo.com  Thu Aug 11 16:34:15 2005
From: amsa36060 at yahoo.com (Amir Safari)
Date: Thu, 11 Aug 2005 07:34:15 -0700 (PDT)
Subject: [R] How to insert a certain model in SVM regarding to fixed kernels
Message-ID: <20050811143415.28223.qmail@web60417.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050811/f6ff45b5/attachment.pl

From simone.gabbriellini at sp.unipi.it  Thu Aug 11 16:42:50 2005
From: simone.gabbriellini at sp.unipi.it (Simone Gabbriellini)
Date: Thu, 11 Aug 2005 16:42:50 +0200
Subject: [R] tcltk programming guide
In-Reply-To: <20050811121645.663214CD23@pascal.dfci.harvard.edu>
References: <20050811121645.663214CD23@pascal.dfci.harvard.edu>
Message-ID: <0E25C03D-83A6-4BD9-AA14-8B9861AD1498@sp.unipi.it>

thank you, I knew that link, but I need something more document- 
oriented, more specific, i.e. if I want to know how to use tkadd,  
where should I look? or tkinsert and so on...

thanx,
simone

Il giorno 11/ago/05, alle ore 14:18, John Zhang ha scritto:

> Go to http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/. There  
> are good
> examples.
>
>
>
>> X-Original-To: jzhang at jimmy.harvard.edu
>> Delivered-To: jzhang at jimmy.harvard.edu
>> X-Virus-Scanned: by amavisd-new at stat.math.ethz.ch
>> Mime-Version: 1.0 (Apple Message framework v733)
>> To: R-help at stat.math.ethz.ch
>> From: Simone Gabbriellini <simone.gabbriellini at sp.unipi.it>
>> Date: Thu, 11 Aug 2005 14:04:58 +0200
>> Subject: [R] tcltk programming guide
>> X-BeenThere: r-help at stat.math.ethz.ch
>> X-Mailman-Version: 2.1.6
>> List-Id: "Main R Mailing List: Primary help" <r- 
>> help.stat.math.ethz.ch>
>> List-Unsubscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>,
>>
> <mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
>
>> List-Archive: <https://stat.ethz.ch/pipermail/r-help>
>> List-Post: <mailto:r-help at stat.math.ethz.ch>
>> List-Help: <mailto:r-help-request at stat.math.ethz.ch?subject=help>
>> List-Subscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>,
>>
> <mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>
>
>> Content-Transfer-Encoding: 7bit
>> X-Spam-Checker-Version: SpamAssassin 3.0.1 (2004-10-22) on
>>
> pascal.dfci.harvard.edu
>
>> X-Spam-Level:
>> X-Spam-Status: No, score=-2.6 required=3.0 tests=BAYES_00  
>> autolearn=ham
>>
> version=3.0.1
>
>>
>> Dear List,
>> I'm looking for some documentation about the R tcltk package
>> The one I found in the help doesn't look exaustive, I need
>> information on the use of the single tk widget, maybe with some  
>> examples
>>
>> thank you,
>> simone gabbriellini
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting- 
>> guide.html
>>
>
> Jianhua Zhang
> Department of Medical Oncology
> Dana-Farber Cancer Institute
> 44 Binney Street
> Boston, MA 02115-6084
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html
>



From jfox at mcmaster.ca  Thu Aug 11 16:57:40 2005
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 11 Aug 2005 10:57:40 -0400
Subject: [R] tcltk programming guide
In-Reply-To: <0E25C03D-83A6-4BD9-AA14-8B9861AD1498@sp.unipi.it>
Message-ID: <20050811145741.CGRX2981.tomts43-srv.bellnexxia.net@JohnDesktop8300>

Dear Simone,

tcltk functions correspond closely to Tcl and Tk commands, so documentation
for the latter, available at <http://wiki.tcl.tk/3109>, is helpful. I also
found Welsch's Practical Programming in Tcl and Tk useful. I expect that
you've already seen Peter Dalgaard's two R News articles on the tcltk
package.

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Simone 
> Gabbriellini
> Sent: Thursday, August 11, 2005 9:43 AM
> To: John Zhang
> Cc: R-help at stat.math.ethz.ch
> Subject: Re: [R] tcltk programming guide
> 
> thank you, I knew that link, but I need something more 
> document- oriented, more specific, i.e. if I want to know how 
> to use tkadd, where should I look? or tkinsert and so on...
> 
> thanx,
> simone
> 
> Il giorno 11/ago/05, alle ore 14:18, John Zhang ha scritto:
> 
> > Go to 
> http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/. There are 
> > good examples.
> >
> >
> >
> >> X-Original-To: jzhang at jimmy.harvard.edu
> >> Delivered-To: jzhang at jimmy.harvard.edu
> >> X-Virus-Scanned: by amavisd-new at stat.math.ethz.ch
> >> Mime-Version: 1.0 (Apple Message framework v733)
> >> To: R-help at stat.math.ethz.ch
> >> From: Simone Gabbriellini <simone.gabbriellini at sp.unipi.it>
> >> Date: Thu, 11 Aug 2005 14:04:58 +0200
> >> Subject: [R] tcltk programming guide
> >> X-BeenThere: r-help at stat.math.ethz.ch
> >> X-Mailman-Version: 2.1.6
> >> List-Id: "Main R Mailing List: Primary help" <r- 
> >> help.stat.math.ethz.ch>
> >> List-Unsubscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>,
> >>
> > <mailto:r-help-request at stat.math.ethz.ch?subject=unsubscribe>
> >
> >> List-Archive: <https://stat.ethz.ch/pipermail/r-help>
> >> List-Post: <mailto:r-help at stat.math.ethz.ch>
> >> List-Help: <mailto:r-help-request at stat.math.ethz.ch?subject=help>
> >> List-Subscribe: <https://stat.ethz.ch/mailman/listinfo/r-help>,
> >>
> > <mailto:r-help-request at stat.math.ethz.ch?subject=subscribe>
> >
> >> Content-Transfer-Encoding: 7bit
> >> X-Spam-Checker-Version: SpamAssassin 3.0.1 (2004-10-22) on
> >>
> > pascal.dfci.harvard.edu
> >
> >> X-Spam-Level:
> >> X-Spam-Status: No, score=-2.6 required=3.0 tests=BAYES_00 
> >> autolearn=ham
> >>
> > version=3.0.1
> >
> >>
> >> Dear List,
> >> I'm looking for some documentation about the R tcltk 
> package The one 
> >> I found in the help doesn't look exaustive, I need 
> information on the 
> >> use of the single tk widget, maybe with some examples
> >>
> >> thank you,
> >> simone gabbriellini
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list 
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide! 
> http://www.R-project.org/posting- 
> >> guide.html
> >>
> >
> > Jianhua Zhang
> > Department of Medical Oncology
> > Dana-Farber Cancer Institute
> > 44 Binney Street
> > Boston, MA 02115-6084
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting- 
> > guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From w.vanijcken at erasmusmc.nl  Thu Aug 11 17:13:10 2005
From: w.vanijcken at erasmusmc.nl (WFJ van IJcken)
Date: Thu, 11 Aug 2005 17:13:10 +0200
Subject: [R] question
Message-ID: <42FB6B06.2080809@erasmusmc.nl>

Hi,

I have a problem with R, after an update:
 this piece of code:
cat("creating resolver data frame\n");
dfG<-cbind(dfG,2^(RGN$G))
dfR<-cbind(dfR,2^(RGN$R))

suddenly, creates values to inf.
Is the syntax changed for the ^ symbol in the latest R downloadable version?

Kind regards, wilfred
-- 


  Dr. Ir. Wilfred Van IJcken

Labmanager Genomics

Erasmus Center for Biomics, Erasmus MC

P.O. Box 1738, 3000 DR  Rotterdam

Dr. Molewaterplein 50, 3015 GE  Rotterdam

The Netherlands

Tel      +31 (0) 10 40 88 454

Fax     +31 (0) 10 40 89 468

www.erasmusmc.nl/biomics <http://www.erasmusmc.nl/biomics>



From dlvanbrunt at gmail.com  Thu Aug 11 17:38:16 2005
From: dlvanbrunt at gmail.com (David L. Van Brunt, Ph.D.)
Date: Thu, 11 Aug 2005 10:38:16 -0500
Subject: [R] Creating new columns inside a loop
In-Reply-To: <x2d5olk1nu.fsf@turmalin.kubism.ku.dk>
References: <d332d3e1050810125048ef939b@mail.gmail.com>
	<x2d5olk1nu.fsf@turmalin.kubism.ku.dk>
Message-ID: <d332d3e105081108386f81426f@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050811/25d676b3/attachment.pl

From renukas at gmail.com  Thu Aug 11 17:47:25 2005
From: renukas at gmail.com (Renuka Sane)
Date: Thu, 11 Aug 2005 21:17:25 +0530
Subject: [R] question on creating a new logical variable
Message-ID: <f7dc8e9405081108473ee11164@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050811/790f0221/attachment.pl

From renukas at gmail.com  Thu Aug 11 17:57:40 2005
From: renukas at gmail.com (Renuka Sane)
Date: Thu, 11 Aug 2005 21:27:40 +0530
Subject: [R] question on creating a new logical variable
Message-ID: <f7dc8e940508110857320c9b3d@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050811/62cc8a44/attachment.pl

From chrisp at uwinst.unizh.ch  Fri Aug 12 03:23:39 2005
From: chrisp at uwinst.unizh.ch (Christopher Philipson)
Date: Thu, 11 Aug 2005 18:23:39 -0700
Subject: [R] strips according to groups in xYplot or xyplot
Message-ID: <42FBFA1B.7050702@uwinst.unizh.ch>

Dear all,

using the follwing code, i have been trying group the individual plots 
from trellis graphics according to genus.  adding a groups=genus colours 
the lines on the individual plots accordingly.  However, i need the 
strips to be coloured according to genus with the lines in each plot 
remaining black.  using xyplot and conditioning to genus and species 
light|species+genus  draws an extra strip with the genus name, this 
almost there, but then i have lots of blanc plots for all the 
nonexistant genus species conbinations - and also i wish to retain my 
error bars from xYplot.

I understand that the solution is probably making my own strip function, 
but this is a little beyond my programming skills.  Does anyone have any 
similar examples?  an example dataframe is pasted below


Many thanks
Chris

xYplot(Cbind(rgr.biomass,rgr.biomass-se,rgr.biomass+se) ~ light|species, 
data=data2,   between=list(x=c(0.3,0.3,0.3,0.3,0.3),y=c(0.3,0.3,0.3)), 
type=c("l"), col.line="black",ylab= "rgr biomass (g-day-1)",
xlab="% light in nursery", main="Relative Growth rates of Diperocarps in 
three simulated light conditions", par.strip.text=list(cex=0.9, 
font=3),par.settings=list(axis.text=list(cex=0.7)),layout=c(6,4), grid=T)




genus light   rgr.biomass        species           se
conformis.0.3      Dipterocarpus   0.3  0.0071360017      conformis 
0.0005639106
conformis.3        Dipterocarpus   3.0  0.0114787998      conformis 
0.0005139212
conformis.18       Dipterocarpus  18.0  0.0128981690      conformis 
0.0007443577
beccarii.0.3        Dryobalanops   0.3  0.0043183235       beccarii 
0.0008404544
lanceolata.0.3      Dryobalanops   0.3  0.0037914641     lanceolata 
0.0012840799
beccarii.3          Dryobalanops   3.0  0.0086008217       beccarii 
0.0007029627
lanceolata.3        Dryobalanops   3.0  0.0066640135     lanceolata 
0.0010293987
beccarii.18         Dryobalanops  18.0  0.0113213323       beccarii 
0.0014422309
lanceolata.18       Dryobalanops  18.0  0.0107687387     lanceolata 
0.0014388931
nervosa.0.3                Hopea   0.3 -0.0009249978        nervosa 
0.0018732192
sangal.0.3                 Hopea   0.3  0.0019374847         sangal 
0.0007375358
spp.0.3                    Hopea   0.3  0.0086367776            spp 
0.0004649476
nervosa.3                  Hopea   3.0  0.0028767234        nervosa 
0.0006551664
sangal.3                   Hopea   3.0  0.0056669364         sangal 
0.0005872821
spp.3                      Hopea   3.0  0.0118224681            spp 
0.0005562180
nervosa.18                 Hopea  18.0  0.0016949373        nervosa 
0.0016615030
sangal.18                  Hopea  18.0  0.0041026605         sangal 
0.0018584946
spp.18                     Hopea  18.0  0.0114581095            spp 
0.0012815084
malaanonan.0.3        Parashorea   0.3  0.0055797534     malaanonan 
0.0007918039
tomentella.0.3        Parashorea   0.3  0.0123015741     tomentella 
0.0008293033
malaanonan.3          Parashorea   3.0  0.0099503268     malaanonan 
0.0006376027
tomentella.3          Parashorea   3.0  0.0155581595     tomentella 
0.0006379742
malaanonan.18         Parashorea  18.0  0.0092196940     malaanonan 
0.0017303947
tomentella.18         Parashorea  18.0  0.0163406724     tomentella 
0.0013648430
argentifolia.0.3          Shorea   0.3  0.0083378142   argentifolia 
0.0010850323
beccariana.0.3            Shorea   0.3  0.0070930251     beccariana 
0.0004610866
faguetiana.0.3            Shorea   0.3  0.0045384372     faguetiana 
0.0010002449
gibbosa.0.3               Shorea   0.3  0.0120252725        gibbosa 
0.0015315410
guiso.0.3                 Shorea   0.3  0.0016886809          guiso 
0.0004390734
johorensis.0.3            Shorea   0.3  0.0046130010     johorensis 
0.0013987125
leprosula.0.3             Shorea   0.3  0.0054931197      leprosula 
0.0007935381
macrophylla.0.3           Shorea   0.3  0.0071376385    macrophylla 
0.0006889700
macroptera.0.3            Shorea   0.3  0.0044181634     macroptera 
0.0005528986
oleosa.fallax.0.3         Shorea   0.3  0.0045416334  oleosa.fallax 
0.0004696663
ovalis.0.3                Shorea   0.3  0.0021653329         ovalis 
0.0014667085
parvifolia.0.3            Shorea   0.3  0.0031730144     parvifolia 
0.0002314153
parvistipulata.0.3        Shorea   0.3  0.0108939901 parvistipulata 
0.0007272541
superba.0.3               Shorea   0.3  0.0048611998        superba 
0.0005558181
argentifolia.3            Shorea   3.0  0.0130474184   argentifolia 
0.0005603928
beccariana.3              Shorea   3.0  0.0116513374     beccariana 
0.0006809518
faguetiana.3              Shorea   3.0  0.0056884859     faguetiana 
0.0024317150
gibbosa.3                 Shorea   3.0  0.0163350328        gibbosa 
0.0008753554
guiso.3                   Shorea   3.0  0.0039323112          guiso 
0.0008966266
johorensis.3              Shorea   3.0  0.0057245098     johorensis 
0.0012002584
leprosula.3               Shorea   3.0  0.0110078404      leprosula 
0.0006868679
macrophylla.3             Shorea   3.0  0.0115086497    macrophylla 
0.0006057665
macroptera.3              Shorea   3.0  0.0083571394     macroptera 
0.0004631552
oleosa.fallax.3           Shorea   3.0  0.0087806875  oleosa.fallax 
0.0006363115
ovalis.3                  Shorea   3.0  0.0048820034         ovalis 
0.0014104024
parvifolia.3              Shorea   3.0  0.0078921667     parvifolia 
0.0004507610
parvistipulata.3          Shorea   3.0  0.0148271032 parvistipulata 
0.0005077023
superba.3                 Shorea   3.0  0.0085652932        superba 
0.0010371722
argentifolia.18           Shorea  18.0  0.0132702301   argentifolia 
0.0016208120
beccariana.18             Shorea  18.0  0.0109954252     beccariana 
0.0006496374
faguetiana.18             Shorea  18.0  0.0049321550     faguetiana 
0.0008261597
gibbosa.18                Shorea  18.0  0.0188341938        gibbosa 
0.0008460866
guiso.18                  Shorea  18.0  0.0065560144          guiso 
0.0013176760
johorensis.18             Shorea  18.0  0.0057575280     johorensis 
0.0014724596
leprosula.18              Shorea  18.0  0.0156544894      leprosula 
0.0006584250
macrophylla.18            Shorea  18.0  0.0111129238    macrophylla 
0.0004117240
macroptera.18             Shorea  18.0  0.0097310849     macroptera 
0.0003881022
oleosa.fallax.18          Shorea  18.0  0.0089809752  oleosa.fallax 
0.0003670370
ovalis.18                 Shorea  18.0  0.0062264658         ovalis 
0.0009884059
parvifolia.18             Shorea  18.0  0.0078973351     parvifolia 
0.0011538826
parvistipulata.18         Shorea  18.0  0.0159302434 parvistipulata 
0.0004134491
superba.18                Shorea  18.0  0.0097285994        superba 
0.0007884945

-- 
========================================
Mr Christopher D. Philipson,
PhD Student,
University of Z??rich,
Institute for Environmental Sciences,
Winterthurstrasse 190
CH - 8057 Z??rich
 
Tel: +41 44 635 6129
Fax: +41 44 635 5711



From ripley at stats.ox.ac.uk  Thu Aug 11 18:26:47 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Aug 2005 17:26:47 +0100 (BST)
Subject: [R] Please don't blame your tools (was Error in autoloader)
In-Reply-To: <42FB46A3.1020506@fe.up.pt>
References: <42FB46A3.1020506@fe.up.pt>
Message-ID: <Pine.LNX.4.61.0508111340230.24357@gannet.stats>

The problem is **NOT** in MASS.  confint is in stats, not MASS, and has 
been (in base then stats) since R 1.7.0.  You could (and should) have 
checked that from the (O)NEWS files of R and MASS.

Nor is there an error in autoloader, as your title stated.

Some other piece of software on your system is seriously out of date.
Running traceback() might tell you what it is.  My suspicion is that
you have somewhere a long-outdated version of lme4.

Starting each R session with that long list of packages is surely not a 
good idea.  Part of the homework before posting should be to run R 
--vanilla and see what happens there.

If this were me I would scrap all of the outdated R installation you have 
and start again with R 2.1.1 (or R-patched).


On Thu, 11 Aug 2005, Peter Ho wrote:

> Hi,
>
> After installing the latest versions of lme4, Matrix, VR on a Debian
> Box, I have run into a problem. When I use library(lme4) on R Version
> 2.1.0  (2005-04-18) I get the following error message:
>
> > library(lme4)
> Loading required package: Matrix
> Error in autoloader(name = "confint", package = "MASS") :
>        autoloader did not find 'confint' in 'MASS'
>
> An example of the complete session is given at the end of this email. A
> search in the docs.
> At present I have 3 directories where packages are kept, as I use
> apt-get install "r-cran-package_ name" when one is available in Debian
> and when it is not R, R CMD INSTALL package_name. This gives me the
> following directories when use help.start():
>
> (1) Packages in /usr/local/lib/R/site-library  (packages installed by R
> CMD INSTALL)
>
> (2) Packages in /usr/lib/R/site-library (packages installed with apt-get
> install)
>
> (3) Packages in /usr/lib/R/library (base install with apt-get install)
>
>
> Matrix, lme4 and other suggested packages were first installed with R
> CMD INSTALL.  and can be found in /usr/local/lib/R/site-library.  After
> the error occured, I updated VR with apt-get install (found in
> /usr/lib/R/library) and got the same error message.
>
> Installing a second version of lme4 and matrix with apt-get install puts
> these packages in /usr/lib/R/site-library and gives the same error as
> before.
>
> Looking at the MASS no function 'confint' exists, only confint.glm,
> confint.nls,confint.profile.glm and confint.profile.nls
>
> Can anyone suggest a solution to the problem or why I am unable to
> access lme4 or as the error statement suggests, a problem with the
> Matrix package and Mass?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From liuwensui at gmail.com  Thu Aug 11 18:27:57 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Thu, 11 Aug 2005 12:27:57 -0400
Subject: [R] question on creating a new logical variable
In-Reply-To: <f7dc8e940508110857320c9b3d@mail.gmail.com>
References: <f7dc8e940508110857320c9b3d@mail.gmail.com>
Message-ID: <1115a2b0050811092723b52196@mail.gmail.com>

table(ifelse(A==2&B==3, TRUE, FALSE))


On 8/11/05, Renuka Sane <renukas at gmail.com> wrote:
> I think there was an incomplete mail that was accidently sent by me. I
> apologize for the inconvenience. Here is the full text.
> 
> I have two variables.
> A <- rep(c(1:9), 2)
> B <- rep(c(2:10),2)
> 
> I want to know the the value for
> A==1 and B==1
> 
> If I do A== 1 | B==1, I get
> FALSE TRUE
> 16 2
> This is incorrect.
> 
> Similarly table(A==1) +table(B==1) reports an error as the arrays are non
> conformable.
> 
> To solve the problem I therefore create a new variable
> C <- c(A, B)
> and then do table(C==1) which gives me
> FALSE TRUE
> 34 2
> 
> Is there a way to do this without making the new variable C?
> 
> Thanks,
> Renuka
> 
> --
> Renuka Sane
> http://www.nyx.net/~rsane
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
WenSui Liu
(http://statcompute.blogspot.com)
Senior Decision Support Analyst
Cincinnati Children Hospital Medical Center



From roebuck at odin.mdacc.tmc.edu  Thu Aug 11 18:42:57 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Thu, 11 Aug 2005 11:42:57 -0500 (CDT)
Subject: [R] question on creating a new logical variable
In-Reply-To: <f7dc8e940508110857320c9b3d@mail.gmail.com>
References: <f7dc8e940508110857320c9b3d@mail.gmail.com>
Message-ID: <Pine.OSF.4.58.0508111137250.191916@odin.mdacc.tmc.edu>

On Thu, 11 Aug 2005, Renuka Sane wrote:

> I have two variables.
> A <- rep(c(1:9), 2)
> B <- rep(c(2:10),2)
>
> I want to know the the value for
> A==1 and B==1
>
> [SNIP]
>
> To solve the problem I therefore create a new variable
> C <- c(A, B)
> and then do table(C==1) which gives me
> FALSE TRUE
> 34 2
>
> Is there a way to do this without making the new variable C?

You mean something besides not explicitly creating it?

table(c(A, B) == 1)

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From tlumley at u.washington.edu  Thu Aug 11 19:18:51 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 11 Aug 2005 10:18:51 -0700 (PDT)
Subject: [R] Creating new columns inside a loop
In-Reply-To: <d332d3e105081108386f81426f@mail.gmail.com>
References: <d332d3e1050810125048ef939b@mail.gmail.com>
	<x2d5olk1nu.fsf@turmalin.kubism.ku.dk>
	<d332d3e105081108386f81426f@mail.gmail.com>
Message-ID: <Pine.A41.4.61b.0508111012440.244658@homer06.u.washington.edu>

On Thu, 11 Aug 2005, David L. Van Brunt, Ph.D. wrote:

> Ok, here's an english pseudo coded version of what I'd like to do...
>
> 10 columns of (somedata)
> names(somedata): C1 C2 C3 C4 C5
> Loop through each column
> FOR ColName = C1 through C5
> Compute a new column, named "ColNameA" = some result for each row
> Compute another new Column named ColNameB" = some other result for each row
> NEXTColName

A direct translation is

for(name in names(somedata)){
    somedata[[paste(name,"A",sep="")]]<-some.result(somedata[[name]])
    somedata[[paste(name,"B",sep="")]]<-some.other.result(somedata[[name]])
}

Possibly more efficient is

some.more.data <- lapply(somedata, some.result)
names(some.more.data)<-paste(names(somedata),"A",sep="")

yet.more.data <- lapply(somedata, some.other.result)
names(yet.more.data)<-paste(names(somedata),"B",sep="")

somedata<-cbind(somedata, some.more.data, yet.more.data)

 	-thomas


> Desired Result:
> Names(somedata): C1 C1A C1B C2 C2A C2B C3 C3A C3B C4 C4A C4B C5 C5A C5B
>
> So, basically, my question is how to both address and assign the names of
> the variables rather than the values of the variables while coding my loop.
> I hope that's clearer... kind of hard to explain!
>
> On 10 Aug 2005 21:55:01 +0200, Peter Dalgaard <p.dalgaard at biostat.ku.dk>
> wrote:
>>
>> "David L. Van Brunt, Ph.D." <dlvanbrunt at gmail.com> writes:
>>
>>> Ok, I know R isn't an optimal environment for looping (or so I've heard)
>> but
>>> I have a need to loop through columns of data and create new columns of
>> data
>>> based on calculations within rows...
>>>
>>> I'm sure there's a help file, but I'm not sure what search terms to use
>> to
>>> find it! The problem is that these new columns need to have names that I
>> can
>>> later access... Like NewVar1, NewVar2, etc....
>>>
>>> In php I'd call this "indirection" but I'm not sure what to call it in R
>> so
>>> that I can find instructions on how to create, name, and address the
>> values
>>> stored this way...
>>>
>>> any gentle nudges in the right direction would be greatly appreciated!
>>
>> A little more information about what you're actually trying to do and
>> I'm sure someone will give you a nudge with a sledgehammer...
>>
>> At present, your description is just that little bit too nebulous.
>>
>> --
>> O__ ---- Peter Dalgaard Øster Farimagsgade 5, Entr.B
>> c/ /'_ --- Dept. of Biostatistics PO Box 2099, 1014 Cph. K
>> (*) \(*) -- University of Copenhagen Denmark Ph: (+45) 35327918
>> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk) FAX: (+45) 35327907
>>
>
>
>
> -- 
> ---------------------------------------
> David L. Van Brunt, Ph.D.
> mailto:dlvanbrunt at gmail.com
>
> 	[[alternative HTML version deleted]]
>
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From shelbaroo at yahoo.com  Thu Aug 11 19:31:12 2005
From: shelbaroo at yahoo.com (shelby berkowitz)
Date: Thu, 11 Aug 2005 10:31:12 -0700 (PDT)
Subject: [R] Converting strings with internal delimiters into lists
Message-ID: <20050811173112.10357.qmail@web30206.mail.mud.yahoo.com>

Hi UserRs,

I know that there has to be an easy way to do this in
R (probably easy enough that once someone clues me in
I'll smack myself on the forehead for not figuring it
out myself), but my searches on my own have not
yielded any hints.

I have many fields in my dataset that participants
entered as "free lists" - i.e., the field constitutes
a varying number of names each separated by a
delimiter.  The resulting data frame might look
something like:

 testtable<-
as.data.frame(cbind(c("Joe,Mary,Jane","Mary"),c("Fred,Joe","Pete,Joe,Mary,Fred")))

In actuality the names are typically multi-word
organization names, but you get the idea...

What I need to do is to convert these text strings
into lists comprised of the elements separated by the
commas so that I can work with these elements across
the dataset, manipulate them, etc.

Thanks in advance to any kind soul who can offer me a
tip to the appropriate functions or a line of code!

Best,

Shelby



From arrayprofile at yahoo.com  Thu Aug 11 19:31:24 2005
From: arrayprofile at yahoo.com (array chip)
Date: Thu, 11 Aug 2005 10:31:24 -0700 (PDT)
Subject: [R] background colors in image()
In-Reply-To: <42FAF845.3010609@free.fr>
Message-ID: <20050811173124.3925.qmail@web40812.mail.yahoo.com>

Romain,

Thanks for the code. It worked perfectly!



--- Romain Francois <francoisromain at free.fr> wrote:

> Le 11.08.2005 00:59, array chip a ??crit :
> 
> >Thanks for the suggestion! It works in a way that
> the
> >entire graph window is in the background color, is
> >there a way to only have the plotting area (i.e.
> the
> >area within the axis box in the background color,
> but
> >leave the area outside the axes to be unchanged
> >(white)?
> >
> >Thanks!
> >
> >  
> >
> You need to learn how to use par('usr') and argument
> add in image.
> demo('graphics') is one way to learn or look at
> graph 8 on r graph gallery
> 
> R> image(matrix(c(1,2,NA, 1),2, 2))
> R> usr <- par('usr')
> R> rect(usr[1], usr[3], usr[2], usr[4],
> col="cornsilk")
> R> image(matrix(c(1,2,NA, 1),2, 2),add=TRUE)
> 
> Romain
> 
> >--- Prof Brian Ripley <ripley at stats.ox.ac.uk>
> wrote:
> >
> >  
> >
> >>On Wed, 10 Aug 2005, someone needing to conceal
> his
> >>real name wrote:
> >>
> >>    
> >>
> >>>Hi, I am using image() function to plot a matrix
> >>>      
> >>>
> >>which
> >>    
> >>
> >>>has some missing valuies (NA). It looks like, by
> >>>default, missing values were drawn in white
> color,
> >>>      
> >>>
> >>How
> >>    
> >>
> >>>can I change that into a different color, say a
> >>>      
> >>>
> >>gray
> >>    
> >>
> >>>color? I tried to use bg='gray' argument with no
> >>>      
> >>>
> >>luck.
> >>    
> >>
> >>>Anyone has a suggestion?
> >>>      
> >>>
> >>They are not drawn in white: in fact they are not
> >>drawn at all, so the 
> >>current background (or if transparent, the canvas)
> >>is what you see.
> >>
> >>    
> >>
> >>>par(bg="yellow")
> >>>image(matrix(c(1,2,NA, 1),2, 2))
> >>>      
> >>>
> >>works, for example.
> >>
> >>-- 
> >>Brian D. Ripley,                 
> >>ripley at stats.ox.ac.uk
> >>Professor of Applied Statistics, 
> >>http://www.stats.ox.ac.uk/~ripley/
> >>University of Oxford,             Tel:  +44 1865
> >>272861 (self)
> >>1 South Parks Road,                     +44 1865
> >>272866 (PA)
> >>Oxford OX1 3TG, UK                Fax:  +44 1865
> >>272595
> >>    
> >>
> 
> -- 
> visit the R Graph Gallery :
> http://addictedtor.free.fr/graphiques
> ~~~~~~~~
>
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ~~~~~~~~
> ~~~~~~      Romain FRANCOIS -
> http://addictedtor.free.fr         ~~~~~~
> ~~~~        Etudiant  ISUP - CS3 - Industrie et
> Services           ~~~~
> ~~                http://www.isup.cicrp.jussieu.fr/ 
>                 ~~
> ~~~~           Stagiaire INRIA Futurs - Equipe
> SELECT              ~~~~
> ~~~~~~  
> http://www.inria.fr/recherche/equipes/select.fr.html
>    ~~~~~~
> ~~~~~~~~
>
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> ~~~~~~~~
> 
>



From jjmichael at comcast.net  Thu Aug 11 19:56:55 2005
From: jjmichael at comcast.net (Jake Michaelson)
Date: Thu, 11 Aug 2005 11:56:55 -0600
Subject: [R] easier way to print heatmap on multiple pages?
Message-ID: <f8338f835c4d44040353456d365c9347@comcast.net>

Hi All,

I've worked on some code to take a heatmap with 1000 row entries, and 
split this up into 20 pages, each with 50 rows from the original 
heatmap.  I want to preserve the row order such that all 20 pages, if 
put together, would comprise the original heatmap.

Here's what I've done:

##make the initial heatmap, with all 1000 rows and write it to an 
object 'heatAll'
heatAll = heatmap.2(combined.int.top, col = cm.colors(256), trace = 
"none")


  pdf(file="~/Desktop/Alfalfa-Ladak-StemV3.pdf", width=8, height=12, 
pointsize=4)
for(i in 1:20){
   selected = heatAll$rowInd[((i-1)*50):((i-1)*50+50)] ##get original 
row order in groups of 50

   heatmap.2(combined.int.top[selected,], Rowv = FALSE, ##prevent row 
re-ordering
   Colv=heatAll$colInd,
   col=cm.colors(256),
   trace="none", margins = c(9,8),
   main=paste("page", i, sep=" "))

  }
  dev.off()

I can't think of why this wouldn't work, but for some reason things are 
completely out of order.  For example, the first page of the PDF shows 
many genes found at the bottom of the original heatmap, but in a 
different order.  Strange.

So, have I made this insanely complicated?  Is there an easier, better 
way to print a large heatmap on multiple pages?

Thanks in advance for any help.

--Jake



From gunter.berton at gene.com  Thu Aug 11 19:58:42 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 11 Aug 2005 10:58:42 -0700
Subject: [R] Converting strings with internal delimiters into lists
In-Reply-To: <20050811173112.10357.qmail@web30206.mail.mud.yahoo.com>
Message-ID: <200508111758.j7BHwgxR016777@hertz.gene.com>

???  I guess I don't get it.

Note that

>  testtable<-
>
as.data.frame(cbind(c("Joe,Mary,Jane","Mary"),c("Fred,Joe","Pete,Joe,Mary,Fr
ed")))

is probably not what you want since cbind expects vectors of equal length.
By default, shorter vectors are recycled to the length of the longest one,
which I doubt is what you want.

Why isn't 

>
mylist<-list(c("Joe,Mary,Jane","Mary"),c("Fred,Joe","Pete,Joe,Mary,Fred"),..
.)

suitable? S lists are specifically designed to handle different objects with
different lengths (or totally different objects). lapply(), sapply() and
friends or for() loops can then work over such a list to do what you want.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box



From tlumley at u.washington.edu  Thu Aug 11 20:26:58 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Thu, 11 Aug 2005 11:26:58 -0700 (PDT)
Subject: [R] Converting strings with internal delimiters into lists
In-Reply-To: <20050811173112.10357.qmail@web30206.mail.mud.yahoo.com>
References: <20050811173112.10357.qmail@web30206.mail.mud.yahoo.com>
Message-ID: <Pine.A41.4.61b.0508111126440.244658@homer06.u.washington.edu>

On Thu, 11 Aug 2005, shelby berkowitz wrote:

> Hi UserRs,
>
> I know that there has to be an easy way to do this in
> R (probably easy enough that once someone clues me in
> I'll smack myself on the forehead for not figuring it
> out myself), but my searches on my own have not
> yielded any hints.

I think you are looking for strsplit()

 	-thomas


> I have many fields in my dataset that participants
> entered as "free lists" - i.e., the field constitutes
> a varying number of names each separated by a
> delimiter.  The resulting data frame might look
> something like:
>
> testtable<-
> as.data.frame(cbind(c("Joe,Mary,Jane","Mary"),c("Fred,Joe","Pete,Joe,Mary,Fred")))
>
> In actuality the names are typically multi-word
> organization names, but you get the idea...
>
> What I need to do is to convert these text strings
> into lists comprised of the elements separated by the
> commas so that I can work with these elements across
> the dataset, manipulate them, etc.
>
> Thanks in advance to any kind soul who can offer me a
> tip to the appropriate functions or a line of code!
>
> Best,
>
> Shelby
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle



From shelbaroo at yahoo.com  Thu Aug 11 21:22:30 2005
From: shelbaroo at yahoo.com (shelby berkowitz)
Date: Thu, 11 Aug 2005 12:22:30 -0700 (PDT)
Subject: [R] Converting strings with internal delimiters into lists
In-Reply-To: <Pine.A41.4.61b.0508111126440.244658@homer06.u.washington.edu>
Message-ID: <20050811192230.42047.qmail@web30206.mail.mud.yahoo.com>

yes, that does it.  thanks!

--- Thomas Lumley <tlumley at u.washington.edu> wrote:

> On Thu, 11 Aug 2005, shelby berkowitz wrote:
> 
> > Hi UserRs,
> >
> > I know that there has to be an easy way to do this
> in
> > R (probably easy enough that once someone clues me
> in
> > I'll smack myself on the forehead for not figuring
> it
> > out myself), but my searches on my own have not
> > yielded any hints.
> 
> I think you are looking for strsplit()
> 
>  	-thomas
> 
> 
> > I have many fields in my dataset that participants
> > entered as "free lists" - i.e., the field
> constitutes
> > a varying number of names each separated by a
> > delimiter.  The resulting data frame might look
> > something like:
> >
> > testtable<-
> >
>
as.data.frame(cbind(c("Joe,Mary,Jane","Mary"),c("Fred,Joe","Pete,Joe,Mary,Fred")))
> >
> > In actuality the names are typically multi-word
> > organization names, but you get the idea...
> >
> > What I need to do is to convert these text strings
> > into lists comprised of the elements separated by
> the
> > commas so that I can work with these elements
> across
> > the dataset, manipulate them, etc.
> >
> > Thanks in advance to any kind soul who can offer
> me a
> > tip to the appropriate functions or a line of
> code!
> >
> > Best,
> >
> > Shelby
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> Thomas Lumley			Assoc. Professor, Biostatistics
> tlumley at u.washington.edu	University of Washington,
> Seattle
>



From xprt.wannabe at gmail.com  Thu Aug 11 21:55:45 2005
From: xprt.wannabe at gmail.com (xpRt.wannabe)
Date: Thu, 11 Aug 2005 14:55:45 -0500
Subject: [R] A coding question involving variable assignments
Message-ID: <a4fecdd705081112552ce6b904@mail.gmail.com>

Dear List,

I have the following code that does what I want:

x <- replicate(5,replicate(10,sum(rnorm(rpois(1,10)))))

How might one change it such that the maximum value generated by
rnorm(rpois(1,10)) can be retrieved for later use?



From ales.ziberna at guest.arnes.si  Thu Aug 11 23:05:01 2005
From: ales.ziberna at guest.arnes.si (=?iso-8859-2?Q?Ale=B9_=AEiberna?=)
Date: Thu, 11 Aug 2005 23:05:01 +0200
Subject: [R] getting xpinch and ypinch
Message-ID: <019501c59eb8$5697b0c0$598debd4@ales>

Hello!

I would like to know if it is possible (and how) to get xpinch and ypinch
values that R gets (from the system) for drawing plots.

If I understand correctly; with this values I could save the same picture as
I see on computer 1 on computer 2 as a let say wmf file.

Thank you in advance,
Ales Ziberna



From uofiowa at gmail.com  Thu Aug 11 23:20:45 2005
From: uofiowa at gmail.com (Omar Lakkis)
Date: Thu, 11 Aug 2005 17:20:45 -0400
Subject: [R] signal handling
Message-ID: <3f87cc6d050811142082b87d6@mail.gmail.com>

Is ther a signal handling model in R? similar to Perl's %SIG hash.
I want to do fast clean up in my R code before exit when a kill signal
is issued.



From helprhelp at gmail.com  Thu Aug 11 23:36:11 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Thu, 11 Aug 2005 16:36:11 -0500
Subject: [R] clustering or homegenity approaches?
Message-ID: <cdf81783050811143638c0123a@mail.gmail.com>

Hi, there:
I have a question on the following dataset

> rbind(t2[which(t4>0.3),][1:3,], t2[1:3,]) # don't worry about what this line means
          [,1]      [,2]       [,3]       [,4]       [,5]
[1,] 34.216166 96.928587 330.125990 330.183222 330.201215
[2,]  2.819183  8.134491   8.275841   8.525256   8.828448
[3,]  2.819183  7.541680   7.550333   8.374636   8.690998
[4,]  4.672551  5.036353   5.072710   5.152218   5.223204
[5,]  5.470131  5.500513   5.674139   5.689151   5.770423
[6,]  4.480287  4.628300   4.797686   4.814106   4.823345

I want to filter out the first 3 cases from the rest and the criteria
is I am looking for a "gap".

My way is using std(eachrow)/median(each) and set up a threshold,
which is very naive, but fast and good enough. But I want it better
and more "academic". Please be advised. I think clustering might help,
but it needs to be quick since t2 has 30000 rows.

Thanks,

Weiwei
-- 
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From roebuck at odin.mdacc.tmc.edu  Fri Aug 12 00:04:15 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Thu, 11 Aug 2005 17:04:15 -0500 (CDT)
Subject: [R] signal handling
In-Reply-To: <3f87cc6d050811142082b87d6@mail.gmail.com>
References: <3f87cc6d050811142082b87d6@mail.gmail.com>
Message-ID: <Pine.OSF.4.58.0508111643050.218401@odin.mdacc.tmc.edu>

On Thu, 11 Aug 2005, Omar Lakkis wrote:

> Is ther[sic] a signal handling model in R? similar to
> Perl's %SIG hash. I want to do fast clean up in my R
> code before exit when a kill signal is issued.

You may find on.exit() somewhat useful for cleanup
but signals are not propogated to your code by the
R environment.

?Signals (on Unix-based platforms) mentions that SIGUSR2
will bypass the above; no idea about Windows.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From steve_adams_sd at yahoo.com  Fri Aug 12 00:34:18 2005
From: steve_adams_sd at yahoo.com (Steve Adams)
Date: Thu, 11 Aug 2005 15:34:18 -0700 (PDT)
Subject: [R] error tracing
Message-ID: <20050811223418.22598.qmail@web33315.mail.mud.yahoo.com>

Hi, I am running some Cox modeling on large number of
variables (thousands) using apply. For some reasons,
some of the variables have problems in Cox regression,
so the the run was stopped automatically. Is there a
way to keep the running for all the variables to
complete and let us, when done, to trace back which of
the variables cause the problem?

Thanks



From dsonneborn at ucdavis.edu  Fri Aug 12 00:40:17 2005
From: dsonneborn at ucdavis.edu (Dean Sonneborn)
Date: Thu, 11 Aug 2005 15:40:17 -0700
Subject: [R] scatter plot
Message-ID: <42FBD3D1.1050408@yellow.ucdavis.edu>

I'd like to do a simple scatter plot but instead of using the variable 
values on the X axis I would like to plot the percentiles. I searched in 
the manual for percentiles but did not find what I was looking for. I've 
been using SAS for several years but I new to R.

-- 
Dean Sonneborn
Programmer Analyst
Department of Public Health Sciences
University of California, Davis
(916) 734-6656



From ramasamy at cancer.org.uk  Fri Aug 12 13:04:05 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Fri, 12 Aug 2005 12:04:05 +0100
Subject: [R] scatter plot
In-Reply-To: <42FBD3D1.1050408@yellow.ucdavis.edu>
References: <42FBD3D1.1050408@yellow.ucdavis.edu>
Message-ID: <1123844646.5868.11.camel@dhcppc3>

Here is a hack

 par(mfrow=c(1,2))

 x  <- rnorm(1000)
 y  <- x + rnorm(1000)
 xp <- (rank(x)-1)/(length(x)-1)

 plot( x, y )
 plot( xp, y )

But do notice that by using percentiles, it spreads the 'x' values
evenly. This may be important for points at the extremes.

Regards, Adai



On Thu, 2005-08-11 at 15:40 -0700, Dean Sonneborn wrote:
> I'd like to do a simple scatter plot but instead of using the variable 
> values on the X axis I would like to plot the percentiles. I searched in 
> the manual for percentiles but did not find what I was looking for. I've 
> been using SAS for several years but I new to R.
>



From dsonneborn at ucdavis.edu  Fri Aug 12 01:05:01 2005
From: dsonneborn at ucdavis.edu (Dean Sonneborn)
Date: Thu, 11 Aug 2005 16:05:01 -0700
Subject: [R] scatter plot
Message-ID: <42FBD99D.5070901@yellow.ucdavis.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050811/ef96a3b3/attachment.pl

From murdoch at stats.uwo.ca  Fri Aug 12 02:10:05 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 11 Aug 2005 20:10:05 -0400
Subject: [R] signal handling
In-Reply-To: <3f87cc6d050811142082b87d6@mail.gmail.com>
References: <3f87cc6d050811142082b87d6@mail.gmail.com>
Message-ID: <42FBE8DD.4050905@stats.uwo.ca>

Omar Lakkis wrote:
> Is ther a signal handling model in R? similar to Perl's %SIG hash.
> I want to do fast clean up in my R code before exit when a kill signal
> is issued.

I don't know Perl's %SIG hash.  However, there are several things you 
can do:  the on.exit() function lets a function do cleanup, and there 
are various hooks available (see ?setHook), and finalizers (see 
?reg.finalizer) for some kinds of objects.

Duncan Murdoch



From e.catchpole at adfa.edu.au  Fri Aug 12 02:23:31 2005
From: e.catchpole at adfa.edu.au (ecatchpole)
Date: Fri, 12 Aug 2005 10:23:31 +1000
Subject: [R] A coding question involving variable assignments
In-Reply-To: <a4fecdd705081112552ce6b904@mail.gmail.com>
References: <a4fecdd705081112552ce6b904@mail.gmail.com>
Message-ID: <42FBEC03.1050103@adfa.edu.au>

On 12/08/05 05:55,  xpRt.wannabe wrote,:
> Dear List,
> 
> I have the following code that does what I want:
> 
> x <- replicate(5,replicate(10,sum(rnorm(rpois(1,10)))))
> 
> How might one change it such that the maximum value generated by
> rnorm(rpois(1,10)) can be retrieved for later use?

set.seed(99)
x <- replicate(5,replicate(10,sum(rnorm(rpois(1,10)))))
set.seed(99)
mx <- replicate(5,replicate(10,max(rnorm(rpois(1,10)))))

should work?

Ted.
-- 
Dr E.A. Catchpole
Visiting Fellow
Univ of New South Wales at ADFA, Canberra, Australia
and University of Kent, Canterbury, England
- www.ma.adfa.edu.au/~eac
- fax: +61 2 6268 8786		
- ph:  +61 2 6268 8895



From xprt.wannabe at gmail.com  Fri Aug 12 02:24:10 2005
From: xprt.wannabe at gmail.com (xpRt.wannabe)
Date: Thu, 11 Aug 2005 19:24:10 -0500
Subject: [R] A coding question involving variable assignments
In-Reply-To: <644e1f3205081113172ed45e4e@mail.gmail.com>
References: <a4fecdd705081112552ce6b904@mail.gmail.com>
	<644e1f3205081113172ed45e4e@mail.gmail.com>
Message-ID: <a4fecdd705081117245045248@mail.gmail.com>

Jim and List,

Thank you for the prompt reply.  Perhaps I should have been more
specific in the way I phrased the question.

The code you gave would return the max value just one time.  I was
interested in getting as many max values generated by
rnorm(rpois(1,10)) as specified by:

> replicate(5,replicate(10 ... )))))

In the end, I expect to get 10 x 5 max values.

In that context, how might the code be changed?

On 8/11/05, jim holtman <jholtman at gmail.com> wrote:
> temp <- rnorm(rpois(1,10))
> x <- replicate(5,replicate(10,sum(temp)))
> temp <- max(temp)
> 
> On 8/11/05, xpRt.wannabe <xprt.wannabe at gmail.com> wrote:
> > Dear List,
> >
> > I have the following code that does what I want:
> >
> > x <- replicate(5,replicate(10,sum(rnorm(rpois(1,10)))))
> >
> > How might one change it such that the maximum value generated by
> > rnorm(rpois(1,10)) can be retrieved for later use?
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> 
> --
> Jim Holtman
> Convergys
> +1 513 723 2929
> 
> What the problem you are trying to solve?
>



From xprt.wannabe at gmail.com  Fri Aug 12 04:17:00 2005
From: xprt.wannabe at gmail.com (xpRt.wannabe)
Date: Thu, 11 Aug 2005 21:17:00 -0500
Subject: [R] A coding question involving variable assignments
In-Reply-To: <42FBEC03.1050103@adfa.edu.au>
References: <a4fecdd705081112552ce6b904@mail.gmail.com>
	<42FBEC03.1050103@adfa.edu.au>
Message-ID: <a4fecdd705081119175e37f49@mail.gmail.com>

Ted and List,

In your code that produced 'mx', you dropped sum() from my original
code though.  As a result, the 10 x 5 max's are of the same value. 
Unfortunately, that's not what I need.


On 8/11/05, ecatchpole <e.catchpole at adfa.edu.au> wrote:
> On 12/08/05 05:55,  xpRt.wannabe wrote,:
> > Dear List,
> >
> > I have the following code that does what I want:
> >
> > x <- replicate(5,replicate(10,sum(rnorm(rpois(1,10)))))
> >
> > How might one change it such that the maximum value generated by
> > rnorm(rpois(1,10)) can be retrieved for later use?
> 
> set.seed(99)
> x <- replicate(5,replicate(10,sum(rnorm(rpois(1,10)))))
> set.seed(99)
> mx <- replicate(5,replicate(10,max(rnorm(rpois(1,10)))))
> 
> should work?
> 
> Ted.
> --
> Dr E.A. Catchpole
> Visiting Fellow
> Univ of New South Wales at ADFA, Canberra, Australia
> and University of Kent, Canterbury, England
> - www.ma.adfa.edu.au/~eac
> - fax: +61 2 6268 8786
> - ph:  +61 2 6268 8895
>



From e.catchpole at adfa.edu.au  Fri Aug 12 04:48:54 2005
From: e.catchpole at adfa.edu.au (ecatchpole)
Date: Fri, 12 Aug 2005 12:48:54 +1000
Subject: [R] A coding question involving variable assignments
In-Reply-To: <a4fecdd705081119175e37f49@mail.gmail.com>
References: <a4fecdd705081112552ce6b904@mail.gmail.com>
	<42FBEC03.1050103@adfa.edu.au>
	<a4fecdd705081119175e37f49@mail.gmail.com>
Message-ID: <42FC0E16.1080609@adfa.edu.au>

Sorry, I don't follow. What's wrong with this?

Ted.

 > set.seed(99)
 >  x <- replicate(5,replicate(10,sum(rnorm(rpois(1,10)))))
 > set.seed(99)
 > mx <- replicate(5,replicate(10,max(rnorm(rpois(1,10)))))
 > x
             [,1]        [,2]        [,3]       [,4]       [,5]
  [1,] -2.0071674  -7.0883335 -0.03766649  2.6859415 -5.4685172
  [2,] -4.7211799   2.4177121 -0.92575948 -7.2201952 -2.5969177
  [3,]  0.2325584  -0.1790635 -3.17988580 -2.0249829  1.6994276
  [4,] -1.7738725   1.5836438  5.06193854 -5.4798269 -2.4363479
  [5,] -3.0394562   2.8859440  2.67993750  5.0534413  0.6560877
  [6,]  6.2436591  -4.0226431  1.97545757 -1.5641548  4.0443831
  [7,]  0.4641453 -10.4417831  1.08048629  2.4675178 -5.5114109
  [8,]  1.1570728  -3.6081361  1.37858782  0.3534015  1.8282236
  [9,]  4.3988625   3.0692562 -0.69898483 -1.6882952 -1.1548913
[10,] -3.7288105  -1.4455309  5.80146323 -6.1962790 -1.3698381
 > mx
            [,1]      [,2]      [,3]      [,4]     [,5]
  [1,] 0.4896243 1.4110132 0.7329387 3.2700493 1.861891
  [2,] 1.0989215 1.6215407 1.5980779 2.2921963 1.417614
  [3,] 1.4000518 1.4867612 1.0130372 0.5686142 1.442630
  [4,] 0.5981696 2.0916016 2.0894395 0.9760749 1.419316
  [5,] 1.0066032 1.8084703 1.6556502 2.1431458 2.393037
  [6,] 2.7329641 1.8689793 1.1494738 1.2899945 1.702919
  [7,] 0.5851713 0.6224785 2.4466643 1.1955567 0.951106
  [8,] 1.3850466 0.9305735 1.4003689 1.5209779 1.864211
  [9,] 1.8645760 1.1958389 0.9270208 0.4971312 1.576020
[10,] 1.5889265 1.0253490 4.6865908 0.9852816 1.032410


On 12/08/05 12:17,  xpRt.wannabe wrote,:
> Ted and List,
> 
> In your code that produced 'mx', you dropped sum() from my original
> code though.  As a result, the 10 x 5 max's are of the same value. 
> Unfortunately, that's not what I need.
> 
> 
> On 8/11/05, ecatchpole <e.catchpole at adfa.edu.au> wrote:
>>On 12/08/05 05:55,  xpRt.wannabe wrote,:
>>>Dear List,
>>>
>>>I have the following code that does what I want:
>>>
>>>x <- replicate(5,replicate(10,sum(rnorm(rpois(1,10)))))
>>>
>>>How might one change it such that the maximum value generated by
>>>rnorm(rpois(1,10)) can be retrieved for later use?
>>set.seed(99)
>>x <- replicate(5,replicate(10,sum(rnorm(rpois(1,10)))))
>>set.seed(99)
>>mx <- replicate(5,replicate(10,max(rnorm(rpois(1,10)))))
>>
>>should work?
>>
>>Ted.
>>--
>>Dr E.A. Catchpole
>>Visiting Fellow
>>Univ of New South Wales at ADFA, Canberra, Australia
>>and University of Kent, Canterbury, England
>>- www.ma.adfa.edu.au/~eac
>>- fax: +61 2 6268 8786
>>- ph:  +61 2 6268 8895
>>


-- 
Dr E.A. Catchpole
Visiting Fellow
Univ of New South Wales at ADFA, Canberra, Australia
and University of Kent, Canterbury, England
- www.ma.adfa.edu.au/~eac
- fax: +61 2 6268 8786		
- ph:  +61 2 6268 8895



From wilmotb at ohsu.edu  Fri Aug 12 05:16:42 2005
From: wilmotb at ohsu.edu (Beth Wilmot)
Date: Thu, 11 Aug 2005 20:16:42 -0700
Subject: [R] access assigned objects
Message-ID: <s2fbb235.065@ohsu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050811/a72f2f50/attachment.pl

From xprt.wannabe at gmail.com  Fri Aug 12 05:27:09 2005
From: xprt.wannabe at gmail.com (xpRt.wannabe)
Date: Thu, 11 Aug 2005 22:27:09 -0500
Subject: [R] A coding question involving variable assignments
In-Reply-To: <42FC0E16.1080609@adfa.edu.au>
References: <a4fecdd705081112552ce6b904@mail.gmail.com>
	<42FBEC03.1050103@adfa.edu.au>
	<a4fecdd705081119175e37f49@mail.gmail.com>
	<42FC0E16.1080609@adfa.edu.au>
Message-ID: <a4fecdd70508112027325e5d48@mail.gmail.com>

Ted and List,

What I need is I need to know what max of rnorm(rpois(1,10)) is before
R does sum(), replicate(10, ...) and replicate(5, ...).

The fact that you have set.seed(99) twice, does that mean, say, entry
[1,1] 0.4896243 in 'mx' is one of the z number of values generated by
rnorm(rpois(1,10)) that add up to [1,1]  -2.0071674 in 'x'?  Another
way to ask the question, I guess, is, by doing set.seed(99) twice are
the values generated by rnorm(rpois(1,10)) for 'x' same as those for
'mx'?


On 8/11/05, ecatchpole <e.catchpole at adfa.edu.au> wrote:
> Sorry, I don't follow. What's wrong with this?
> 
> Ted.
> 
>  > set.seed(99)
>  >  x <- replicate(5,replicate(10,sum(rnorm(rpois(1,10)))))
>  > set.seed(99)
>  > mx <- replicate(5,replicate(10,max(rnorm(rpois(1,10)))))
>  > x
>             [,1]        [,2]        [,3]       [,4]       [,5]
>  [1,] -2.0071674  -7.0883335 -0.03766649  2.6859415 -5.4685172
>  [2,] -4.7211799   2.4177121 -0.92575948 -7.2201952 -2.5969177
>  [3,]  0.2325584  -0.1790635 -3.17988580 -2.0249829  1.6994276
>  [4,] -1.7738725   1.5836438  5.06193854 -5.4798269 -2.4363479
>  [5,] -3.0394562   2.8859440  2.67993750  5.0534413  0.6560877
>  [6,]  6.2436591  -4.0226431  1.97545757 -1.5641548  4.0443831
>  [7,]  0.4641453 -10.4417831  1.08048629  2.4675178 -5.5114109
>  [8,]  1.1570728  -3.6081361  1.37858782  0.3534015  1.8282236
>  [9,]  4.3988625   3.0692562 -0.69898483 -1.6882952 -1.1548913
> [10,] -3.7288105  -1.4455309  5.80146323 -6.1962790 -1.3698381
>  > mx
>            [,1]      [,2]      [,3]      [,4]     [,5]
>  [1,] 0.4896243 1.4110132 0.7329387 3.2700493 1.861891
>  [2,] 1.0989215 1.6215407 1.5980779 2.2921963 1.417614
>  [3,] 1.4000518 1.4867612 1.0130372 0.5686142 1.442630
>  [4,] 0.5981696 2.0916016 2.0894395 0.9760749 1.419316
>  [5,] 1.0066032 1.8084703 1.6556502 2.1431458 2.393037
>  [6,] 2.7329641 1.8689793 1.1494738 1.2899945 1.702919
>  [7,] 0.5851713 0.6224785 2.4466643 1.1955567 0.951106
>  [8,] 1.3850466 0.9305735 1.4003689 1.5209779 1.864211
>  [9,] 1.8645760 1.1958389 0.9270208 0.4971312 1.576020
> [10,] 1.5889265 1.0253490 4.6865908 0.9852816 1.032410
> 
> 
> On 12/08/05 12:17,  xpRt.wannabe wrote,:
> > Ted and List,
> >
> > In your code that produced 'mx', you dropped sum() from my original
> > code though.  As a result, the 10 x 5 max's are of the same value.
> > Unfortunately, that's not what I need.
> >
> >
> > On 8/11/05, ecatchpole <e.catchpole at adfa.edu.au> wrote:
> >>On 12/08/05 05:55,  xpRt.wannabe wrote,:
> >>>Dear List,
> >>>
> >>>I have the following code that does what I want:
> >>>
> >>>x <- replicate(5,replicate(10,sum(rnorm(rpois(1,10)))))
> >>>
> >>>How might one change it such that the maximum value generated by
> >>>rnorm(rpois(1,10)) can be retrieved for later use?
> >>set.seed(99)
> >>x <- replicate(5,replicate(10,sum(rnorm(rpois(1,10)))))
> >>set.seed(99)
> >>mx <- replicate(5,replicate(10,max(rnorm(rpois(1,10)))))
> >>
> >>should work?
> >>
> >>Ted.
> >>--
> >>Dr E.A. Catchpole
> >>Visiting Fellow
> >>Univ of New South Wales at ADFA, Canberra, Australia
> >>and University of Kent, Canterbury, England
> >>- www.ma.adfa.edu.au/~eac
> >>- fax: +61 2 6268 8786
> >>- ph:  +61 2 6268 8895
> >>
> 
> 
> --
> Dr E.A. Catchpole
> Visiting Fellow
> Univ of New South Wales at ADFA, Canberra, Australia
> and University of Kent, Canterbury, England
> - www.ma.adfa.edu.au/~eac
> - fax: +61 2 6268 8786
> - ph:  +61 2 6268 8895
>



From e.catchpole at adfa.edu.au  Fri Aug 12 05:55:42 2005
From: e.catchpole at adfa.edu.au (ecatchpole)
Date: Fri, 12 Aug 2005 13:55:42 +1000
Subject: [R] A coding question involving variable assignments
In-Reply-To: <a4fecdd70508112027325e5d48@mail.gmail.com>
References: <a4fecdd705081112552ce6b904@mail.gmail.com>
	<42FBEC03.1050103@adfa.edu.au>
	<a4fecdd705081119175e37f49@mail.gmail.com>
	<42FC0E16.1080609@adfa.edu.au>
	<a4fecdd70508112027325e5d48@mail.gmail.com>
Message-ID: <42FC1DBE.7010503@adfa.edu.au>

On 12/08/05 13:27,  xpRt.wannabe wrote,:
> Ted and List,
> 
> What I need is I need to know what max of rnorm(rpois(1,10)) is before
> R does sum(), replicate(10, ...) and replicate(5, ...).
> 
> The fact that you have set.seed(99) twice, does that mean, say, entry
> [1,1] 0.4896243 in 'mx' is one of the z number of values generated by
> rnorm(rpois(1,10)) that add up to [1,1]  -2.0071674 in 'x'?  Another
> way to ask the question, I guess, is, by doing set.seed(99) twice are
> the values generated by rnorm(rpois(1,10)) for 'x' same as those for
> 'mx'?

Yes, that's the reason for having a set.seed() function.

Ted.

-- 
Dr E.A. Catchpole
Visiting Fellow
Univ of New South Wales at ADFA, Canberra, Australia
and University of Kent, Canterbury, England
- www.ma.adfa.edu.au/~eac
- fax: +61 2 6268 8786		
- ph:  +61 2 6268 8895



From dunn at usq.edu.au  Fri Aug 12 06:14:09 2005
From: dunn at usq.edu.au (Peter Dunn)
Date: Fri, 12 Aug 2005 14:14:09 +1000
Subject: [R] Help converting a function from S-Plus to R:  family$weight
Message-ID: <42FC2211.5040702@usq.edu.au>

Hi all

I am converting an S-Plus function into R.  The S-Plus code
uses some of the glm families, and  family  objects.

The family objects in S-Plus and R have many different
features, for example:

In R:
 > names(Gamma())
  [1] "family"     "link"       "linkfun"    "linkinv"    "variance"
  [6] "dev.resids" "aic"        "mu.eta"     "initialize" "validmu"
[11] "valideta"

In S-Plus:
 > names(Gamma())
[1] "family"     "names"      "link"       "inverse"    "deriv"
[6] "initialize" "variance"   "deviance"   "weight"
 >


My question concerns the variable  weight  in the S-Plus function.
I'm not sure what it is.  (I have searched the S-Plus mailing list
archive, and my "S-Plus for linux 6.1" documentation.)  For almost all
family objects, the weight variable is the same as variance,
just weighted (and the former as a function; the later as an
expression):

 > Gamma()$variance
function(mu)
mu^2
 > Gamma()$weight
expression(w * mu^2.)
 >

The same applies for most families.  So I thought I could determine
what this weight variable was.

But alas--not the inverse,gaussian:

 > inverse.gaussian()$variance
function(mu)
mu^3
 > inverse.gaussian()$weight
expression(w/((sqrt(family$variance(mu)) * family$deriv(mu))^2.))


So:
- can anyone tell me what this expression weight represents?
- why is the inverse.gaussian family different than all others?

Thanks in advance.

P.

My S-Plus version:

 > version
Version 6.2.1  for Linux 2.4.18 : 2003

My R version:

 > version
          _
platform i386-pc-linux-gnu
arch     i386
os       linux-gnu
system   i386, linux-gnu
status
major    2
minor    1.0
year     2005
month    04
day      18
language R
 >


-- 
Dr Peter Dunn  |  Senior Lecturer in Statistics
Faculty of Sciences, University of Southern Queensland
   Web:    http://www.sci.usq.edu.au/staff/dunn
   Email:  dunn <at> usq.edu.au
CRICOS:  QLD 00244B |  NSW 02225M |  VIC 02387D |  WA 02521C



From xprt.wannabe at gmail.com  Fri Aug 12 06:47:51 2005
From: xprt.wannabe at gmail.com (xpRt.wannabe)
Date: Thu, 11 Aug 2005 23:47:51 -0500
Subject: [R] A coding question involving variable assignments
In-Reply-To: <42FC1DBE.7010503@adfa.edu.au>
References: <a4fecdd705081112552ce6b904@mail.gmail.com>
	<42FBEC03.1050103@adfa.edu.au>
	<a4fecdd705081119175e37f49@mail.gmail.com>
	<42FC0E16.1080609@adfa.edu.au>
	<a4fecdd70508112027325e5d48@mail.gmail.com>
	<42FC1DBE.7010503@adfa.edu.au>
Message-ID: <a4fecdd7050811214772a57575@mail.gmail.com>

Thank you!  That was helpful.

Another thing I learned was that I would need to do set.seed(99) not
once but twice in this context.

On 8/11/05, ecatchpole <e.catchpole at adfa.edu.au> wrote:
> On 12/08/05 13:27,  xpRt.wannabe wrote,:
> > Ted and List,
> >
> > What I need is I need to know what max of rnorm(rpois(1,10)) is before
> > R does sum(), replicate(10, ...) and replicate(5, ...).
> >
> > The fact that you have set.seed(99) twice, does that mean, say, entry
> > [1,1] 0.4896243 in 'mx' is one of the z number of values generated by
> > rnorm(rpois(1,10)) that add up to [1,1]  -2.0071674 in 'x'?  Another
> > way to ask the question, I guess, is, by doing set.seed(99) twice are
> > the values generated by rnorm(rpois(1,10)) for 'x' same as those for
> > 'mx'?
> 
> Yes, that's the reason for having a set.seed() function.
> 
> Ted.
> 
> --
> Dr E.A. Catchpole
> Visiting Fellow
> Univ of New South Wales at ADFA, Canberra, Australia
> and University of Kent, Canterbury, England
> - www.ma.adfa.edu.au/~eac
> - fax: +61 2 6268 8786
> - ph:  +61 2 6268 8895
>



From mail at bymouth.com  Fri Aug 12 06:54:35 2005
From: mail at bymouth.com (Stephen Choularton)
Date: Fri, 12 Aug 2005 14:54:35 +1000
Subject: [R] chisq warning
Message-ID: <000001c59efa$2344c810$9701a8c0@Tablet>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050812/5b17e552/attachment.pl

From ligges at statistik.uni-dortmund.de  Fri Aug 12 08:49:21 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 12 Aug 2005 08:49:21 +0200
Subject: [R] access assigned objects
In-Reply-To: <s2fbb235.065@ohsu.edu>
References: <s2fbb235.065@ohsu.edu>
Message-ID: <42FC4671.3080504@statistik.uni-dortmund.de>

Beth Wilmot wrote:
> Dear list,
> I am trying to write a function that will make a matrix of each row of a data frame (4 columns), calculate a fisher.test on each resulting matrix and assign a vector of the p-values.  I have gotten through making the matrices,  but cannot calculate the fisher.test.
>  
> fm<-function(x)
> {dfrow<-nrow(x)
>  
> mm <- vector("list", dfrow)
> for(i in 1:dfrow)
>    mm[[i]] <- matrix(x[i,],nr=2)


If x is a data.frame, x[1,] is also a data.frame.

Try unlist() at first:

     mm[[i]] <- matrix(unlist(x[i,]),nr=2)


Uwe Ligges



> 
> }
>  
> I don't know how to access each mm[[i]] as everything I've tried gives me the error that 
> "Error in fisher.test(mm[[i]]) : all entries of x must be nonnegative and finite"
>  
> All the numbers in the matrices are between 1 and 600.  
>  
>  
> Thanks,
> Beth
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From frt at Codan.dk  Fri Aug 12 10:52:05 2005
From: frt at Codan.dk (Fredrik Thuring)
Date: Fri, 12 Aug 2005 10:52:05 +0200
Subject: [R] Concerning reading of SAS-files
Message-ID: <OFB6EC6EDC.B08DF69D-ONC125705B.002F85F7-C125705B.0030B9B5@codan.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050812/ff48c78e/attachment.pl

From snvk4u at gmail.com  Fri Aug 12 11:07:38 2005
From: snvk4u at gmail.com (Krishna)
Date: Fri, 12 Aug 2005 14:37:38 +0530
Subject: [R] help on cross hedge optimal hedge variance ratio
Message-ID: <139ef1c205081202071d57b2d0@mail.gmail.com>

Hi everyone

I am trying to estimate the optimal hedge variance ratio for cross
hedging two commodities. the price levels are used (compared to price
change and % price change) and used the OLS with dummy variable for
estimating the co-efficients. the equation looks like this

Y = B + B1*D1 + B2*X + B3*(X*D1)

Where Y = Daily Cash market price
D1 = Dummy variable taking value 1 for period Oct-Mar and 0 for Apr-Sep
X = Daily futures market price on which cross hedging is done.
B,B1,B2,B3 are the slope co-efficients. 

The results look like this 
Regression Statistics
Multiple R		0.948702709
R Square		0.900036831
Adjusted R Square	0.89981135
Standard Error		25.52050965
Observations		1334


	Coefficients	Standard Error	t Stat	P-value
Intercept	53.817		4.375		12.300	0.000
X	0.986		0.012		80.283	0.000
D1	27.399		6.106		4.487	0.000
D1 * X	-0.100		0.017		-5.820	0.000
	
It is understood the slope co-efficients for different periods are
significant as indicated by t-table value. But I feel suspicious on
the reliability of this values.

I have used 5 years of daily price data for running the regression,
and I feel suscpicious becasue, the monthly correlations (pearson
correlation co-efficient) are highly varying between spot and futures
and some times even negative.

Can someone suggest me 
a) the tests to judge the reliability of hedge-variance values
b) Is there any other better method than described here for estimating
the hedge-variance values

Thank you for the attention and look forward for an early reply

rgds

snvk



From admin at biostatistic.de  Fri Aug 12 11:27:46 2005
From: admin at biostatistic.de (Knut Krueger)
Date: Fri, 12 Aug 2005 11:27:46 +0200
Subject: [R] RGUI crash when opening script in XP Home enviroment
In-Reply-To: <42F9D90C.3010808@biostatistic.de>
References: <42F8C714.1030801@biostatistic.de>	<42F9A630.9030909@biostatistic.de>	<Pine.LNX.4.61.0508100824410.20599@gannet.stats>
	<42F9D90C.3010808@biostatistic.de>
Message-ID: <42FC6B92.7090301@biostatistic.de>




>Prof Brian Ripley schrieb:
>
>  
>
>>However, as I don't know what the `open file button' is, I cannot
>>reproduce it.  Is this MDI or SDI mode, 
>>    
>>

found it : MDI Mode
Pager Style multiple windows

Knut Krueger



From n.shah at decisioncraft.com  Fri Aug 12 12:10:37 2005
From: n.shah at decisioncraft.com (Nikhil Shah)
Date: Fri, 12 Aug 2005 15:40:37 +0530
Subject: [R] R Help
Message-ID: <002801c59f26$17ae9c20$7900a8c0@dca.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050812/20211564/attachment.pl

From n.shah at decisioncraft.com  Fri Aug 12 12:23:16 2005
From: n.shah at decisioncraft.com (Nikhil Shah)
Date: Fri, 12 Aug 2005 15:53:16 +0530
Subject: [R] handling warning messages
Message-ID: <003201c59f27$dbc57920$7900a8c0@dca.com>

Hi,

I have query regarding R & Rserve. In Rserve, there is a way to capture
Errors by RSrvException class, but is there any way to capture warning
messages?

   I have found that there is "warnings()" command in R, which lists the
last warning message, but I am not able to get the warning message in java
program by executing the following line:

REXP rx = null;
rx = connection.eval("x<-sqrt(-9)"); // will generate warning message
connection.eval("warnings()").asString(); // this displays null instead of
warning message

Please reply me correct way, if any, to display warning message.

Regards,
Nikhil Shah



From david.meyer at wu-wien.ac.at  Fri Aug 12 14:28:35 2005
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Fri, 12 Aug 2005 14:28:35 +0200
Subject: [R] How to insert a certain model in SVM regarding to fixed
	kernels
In-Reply-To: <20050811143415.28223.qmail@web60417.mail.yahoo.com>
References: <20050811143415.28223.qmail@web60417.mail.yahoo.com>
Message-ID: <20050812142835.7c88d847.david.meyer@wu-wien.ac.at>

Amir,

>  
> Suppose that we want to regress for example a certain autoregressive
> model using SVM. We have our data and also some fixed kernels in
> libSVM behinde e1071 in front. The question: Where can we insert our
> certain autoregressive model ? During creating data frame ? 

Yes, I think.

> Or perhaps we can make a 
> relationship between our variables ended to desired autoregressive
> model ?

Gabor Grothendieck's `dyn` package provides support for the use of
general regression functions for time series analysis, and we are
currently struggling to integrate the e1071 interface into that
framework (but nothing is ready so far). Is it that kind of support you
have been looking for?

Cheers,
David

>  
> Thanks a lot for your help.
> Amir Safari
>  
>  
> 
> 
> __________________________________________________
> Do You Yahoo!?
> Tired of spam?  Yahoo! Mail has the best spam protection around 
> http://mail.yahoo.com 


-- 
Dr. David Meyer
Department of Information Systems and Operations

Vienna University of Economics and Business Administration
Augasse 2-6, A-1090 Wien, Austria, Europe
Fax: +43-1-313 36x746 
Tel: +43-1-313 36x4393
HP:  http://wi.wu-wien.ac.at/~meyer/



From adi at roda.ro  Fri Aug 12 12:34:45 2005
From: adi at roda.ro (Adrian Dusa)
Date: Fri, 12 Aug 2005 13:34:45 +0300
Subject: [R] Digest reading is tedious
In-Reply-To: <17145.5735.426400.446812@stat.math.ethz.ch>
References: <03091f4b0b5415eeb2d9be3e5e070ceb@stanford.edu>
	<17145.5735.426400.446812@stat.math.ethz.ch>
Message-ID: <200508121334.45856.adi@roda.ro>

On Tuesday 09 August 2005 23:47, Martin Maechler wrote:
> >>>>> "Trevor" == Trevor Hastie <hastie at stanford.edu>
> >>>>>     on Tue, 9 Aug 2005 10:27:32 -0700 writes:
>
>     Trevor> [...snip...]
>
> But that has been an option in mailman, the software behind our
> mailing lists  --- for ages ---
>
> [...snip...]
> I hope this helps,
> Martin

I use MIME for digest reading, with KMail under SuSE 9.2. The way I get the 
digest is a list of encapsulated messages. There is, however, a tedious 
things: the encapsulated messages are not numbered...
(so I still have to scroll down to find a particular message, guessing the 
right place where it might be; odd enough, there is no "Find text" inside a 
message in KMail).

If there's any option in KMail to split the digest into threaded messages, I 
couldn't find it. I tried to figure out how to use procmail and formail but 
is too complex for a regular user.

Is it possible to get numbered encapsulated messages?
TIA,
Adrian

-- 
Adrian Dusa
Arhiva Romana de Date Sociale
Bd. Schitu Magureanu nr.1
Tel./Fax: +40 21 3126618 \
              +40 21 3120210 / int.101


-- 
This message was scanned for spam and viruses by BitDefender.
For more information please visit http://linux.bitdefender.com/



From paterijk at hotmail.com  Fri Aug 12 12:50:46 2005
From: paterijk at hotmail.com (Pat Meyer)
Date: Fri, 12 Aug 2005 10:50:46 +0000
Subject: [R] R_X11 module cannot be loaded
Message-ID: <BAY14-F241846FDF9029E40A44084D5BC0@phx.gbl>

Hi,

I encountered a problem while working in R on our Server (4 Itanium 2 
processors). We have redhat for IA64 installed, and R version R-2.0.1 
(2004-11-15).

Here is my problem.

When I run R in a console, the png command works flawlessly and it outputs a 
png file.

Nevertheless, when I run R on a file containing a png command in BATCH mode, 
I get:

-------------
Error in png(file.path("/home/pat/Documents/Work/R2HTML", graph1)) :
        R_X11 module cannot be loaded
In addition: Warning message:
X11 module is not available under this GUI
Execution halted
-------------

Can anybody tell me what is going on?

I tried the same thing on other computers (normal i386 processors), and 
everything works fine there. Is it my R version which is out of date?

Thank you very much for your precious help

Patrick



From david.whiting at ncl.ac.uk  Fri Aug 12 12:55:02 2005
From: david.whiting at ncl.ac.uk (David Whiting)
Date: Fri, 12 Aug 2005 11:55:02 +0100
Subject: [R] Digest reading is tedious
In-Reply-To: <200508121334.45856.adi@roda.ro>
References: <03091f4b0b5415eeb2d9be3e5e070ceb@stanford.edu>	<17145.5735.426400.446812@stat.math.ethz.ch>
	<200508121334.45856.adi@roda.ro>
Message-ID: <42FC8006.50908@ncl.ac.uk>

Hi Adrian,

Here's what I used to use for a list I used to subscribe to (it is the
first example in the man page for formail, it worked for me and I never
went further playing with formail):

:0:
* !
* ^TO_expert at linux-mandrake\.com
| formail +1 -ds >>new/expert


Here is a rough summary of what it does:

:0:    (is something to do with file locking (I think))
* !    (I can't remember what this does)
* ^TO_expert at linux-mandrake\.com

^TO_ means the email address is in the To: *or* the CC: header. Note
that you have to escape the dot in the .com bit.

| formail +1 -ds >>new/expert

This pipes the digest to formail, splits the messages and puts them all
into a mailbox called new/expert (in this case).

For you, the recipe might be something like:


:0:
* !
* ^TO_r-help at stat\.math\.ethz\.ch
| formail +1 -ds >>R-undigested



HTH,

Dave

Adrian Dusa wrote:
> On Tuesday 09 August 2005 23:47, Martin Maechler wrote:
> 
>>>>>>>"Trevor" == Trevor Hastie <hastie at stanford.edu>
>>>>>>>    on Tue, 9 Aug 2005 10:27:32 -0700 writes:
>>
>>    Trevor> [...snip...]
>>
>>But that has been an option in mailman, the software behind our
>>mailing lists  --- for ages ---
>>
>>[...snip...]
>>I hope this helps,
>>Martin
> 
> 
> I use MIME for digest reading, with KMail under SuSE 9.2. The way I get the 
> digest is a list of encapsulated messages. There is, however, a tedious 
> things: the encapsulated messages are not numbered...
> (so I still have to scroll down to find a particular message, guessing the 
> right place where it might be; odd enough, there is no "Find text" inside a 
> message in KMail).
> 
> If there's any option in KMail to split the digest into threaded messages, I 
> couldn't find it. I tried to figure out how to use procmail and formail but 
> is too complex for a regular user.
> 
> Is it possible to get numbered encapsulated messages?
> TIA,
> Adrian
> 

-- 
David Whiting
School of Clinical Medical Sciences, The Medical School
University of Newcastle upon Tyne, NE2 4HH, UK.

"I love deadlines. I love the whooshing noise they make as they go by"
(Douglas Adams)



From sdavis2 at mail.nih.gov  Fri Aug 12 12:56:48 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 12 Aug 2005 06:56:48 -0400
Subject: [R] R_X11 module cannot be loaded
In-Reply-To: <BAY14-F241846FDF9029E40A44084D5BC0@phx.gbl>
Message-ID: <BF21F8B0.C421%sdavis2@mail.nih.gov>

On 8/12/05 6:50 AM, "Pat Meyer" <paterijk at hotmail.com> wrote:

> Hi,
> 
> I encountered a problem while working in R on our Server (4 Itanium 2
> processors). We have redhat for IA64 installed, and R version R-2.0.1
> (2004-11-15).
> 
> Here is my problem.
> 
> When I run R in a console, the png command works flawlessly and it outputs a
> png file.
> 
> Nevertheless, when I run R on a file containing a png command in BATCH mode,
> I get:
> 
> -------------
> Error in png(file.path("/home/pat/Documents/Work/R2HTML", graph1)) :
>       R_X11 module cannot be loaded
> In addition: Warning message:
> X11 module is not available under this GUI
> Execution halted
> -------------
> 
> Can anybody tell me what is going on?

This is a FAQ:

http://cran.r-project.org/doc/FAQ/R-FAQ.html#How-do-I-produce-PNG-graphics-i
n-batch-mode_003f

Sean



From peter at fe.up.pt  Fri Aug 12 13:29:51 2005
From: peter at fe.up.pt (Peter Ho)
Date: Fri, 12 Aug 2005 12:29:51 +0100
Subject: [R] Problem with lme4
Message-ID: <42FC882F.90101@fe.up.pt>

Hi,

I cannot seem to get lme4 to work. I have installed the lme4 and Matrix 
package with apt-get. and both can be found in /usr/lib/R/site-library.
When I tried an example for lmer, R could not find the function lmer(),

 > library(lme4)

Attaching package: 'lme4'


        The following object(s) are masked from package:nlme :

         getCovariateFormula getResponseFormula groupedData

Error in autoloader(name = "confint", package = "MASS") :
        autoloader did not find 'confint' in 'MASS'
 > (fm1 <- lmer(decrease ~ treatment + (1|rowpos) + (1|colpos),
+              OrchardSprays))
Error: couldn't find function "lmer"
 >               

Is this a bug with the lme4 package for Debian (r-cran-lme4)? 


Peter



#########################
R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

Loading Tcl/Tk interface ... done
Loading required package: tcltk
Loading required package: rgl
Loading required package: zoo
Loading required package: strucchange
Loading required package: sandwich
Loading required package: relimp
Loading required package: nnet
Loading required package: graphics
Loading required package: grDevices
Loading required package: stats
Loading required package: nlme

Attaching package: 'nlme'


        The following object(s) are masked from package:stats :

         contr.SAS

Loading required package: mvtnorm
Loading required package: multcomp
Loading required package: mgcv
This is mgcv 1.2-4
Loading required package: MASS
Loading required package: lmtest
Loading required package: lattice
Loading required package: grid
Loading required package: foreign
Loading required package: effects
Loading required package: car
Loading required package: abind
[Previously saved workspace restored]

 > library(Matrix)
 > library(lme4)

Attaching package: 'lme4'


        The following object(s) are masked from package:nlme :

         getCovariateFormula getResponseFormula groupedData

Error in autoloader(name = "confint", package = "MASS") :
        autoloader did not find 'confint' in 'MASS'
 > (fm1 <- lmer(decrease ~ treatment + (1|rowpos) + (1|colpos),
+              OrchardSprays))
Error: couldn't find function "lmer"
 >



From Gregor.Gorjanc at bfro.uni-lj.si  Fri Aug 12 13:34:07 2005
From: Gregor.Gorjanc at bfro.uni-lj.si (Gorjanc Gregor)
Date: Fri, 12 Aug 2005 13:34:07 +0200
Subject: [R] Exponential, Weibull and log-logistic distributions in glm()
Message-ID: <7FFEE688B57D7346BC6241C55900E730F319C4@pollux.bfro.uni-lj.si>

>> Dear R-users!
>>
>> I would like to fit exponential, Weibull and log-logistic via glm() like
>> functions. Does anyone know a way to do this? Bellow is a bit longer
>> description of my problem.
>
> I think you want to use survreg().  It will still work when there is no 
> censoring.
>
>
> Adding these families to glm() would be difficult. They are really not 
> generalized linear models in any of the useful senses: not exponential 
> families, don't have estimating functions linear in the response 
> variable, not fitted by iteratively reweighted least squares.

Thank you very much for the response. I didn't want to get into survival
since this is really not my field, but it seems that providing those 
distributions in glm() is not so easy as I thought. Based on your hint I 
tried with survreg and estimates seems reasonable.

best, Gregor



From ggrothendieck at gmail.com  Fri Aug 12 14:02:19 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 12 Aug 2005 08:02:19 -0400
Subject: [R] How to insert a certain model in SVM regarding to fixed
	kernels
In-Reply-To: <20050812142835.7c88d847.david.meyer@wu-wien.ac.at>
References: <20050811143415.28223.qmail@web60417.mail.yahoo.com>
	<20050812142835.7c88d847.david.meyer@wu-wien.ac.at>
Message-ID: <971536df0508120502251e1862@mail.gmail.com>

David, Please correct me if I am wrong but I think svm partially works
with dyn although I don't remember what the specific limitations were.
Its possible that what works already is enough for Amir. For example,

library(e1071)
library(dyn)
set.seed(1)
y <- ts(rnorm(100))
y.svm <- dyn$svm(y ~ lag(y))
yp <- predict(y.svm)
ts.plot(y, yp, col = 1:2)

On 8/12/05, David Meyer <david.meyer at wu-wien.ac.at> wrote:
> Amir,
> 
> >
> > Suppose that we want to regress for example a certain autoregressive
> > model using SVM. We have our data and also some fixed kernels in
> > libSVM behinde e1071 in front. The question: Where can we insert our
> > certain autoregressive model ? During creating data frame ?
> 
> Yes, I think.
> 
> > Or perhaps we can make a
> > relationship between our variables ended to desired autoregressive
> > model ?
> 
> Gabor Grothendieck's `dyn` package provides support for the use of
> general regression functions for time series analysis, and we are
> currently struggling to integrate the e1071 interface into that
> framework (but nothing is ready so far). Is it that kind of support you
> have been looking for?
> 
> Cheers,
> David
> 
> >
> > Thanks a lot for your help.
> > Amir Safari
> >
> >
> >
> >
> > __________________________________________________
> > Do You Yahoo!?
> > Tired of spam?  Yahoo! Mail has the best spam protection around
> > http://mail.yahoo.com
> 
> 
> --
> Dr. David Meyer
> Department of Information Systems and Operations
> 
> Vienna University of Economics and Business Administration
> Augasse 2-6, A-1090 Wien, Austria, Europe
> Fax: +43-1-313 36x746
> Tel: +43-1-313 36x4393
> HP:  http://wi.wu-wien.ac.at/~meyer/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ggrothendieck at gmail.com  Fri Aug 12 14:18:44 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 12 Aug 2005 08:18:44 -0400
Subject: [R] How to insert a certain model in SVM regarding to fixed
	kernels
In-Reply-To: <971536df0508120502251e1862@mail.gmail.com>
References: <20050811143415.28223.qmail@web60417.mail.yahoo.com>
	<20050812142835.7c88d847.david.meyer@wu-wien.ac.at>
	<971536df0508120502251e1862@mail.gmail.com>
Message-ID: <971536df050812051810a66bf3@mail.gmail.com>

On 8/12/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> David, Please correct me if I am wrong but I think svm partially works
> with dyn although I don't remember what the specific limitations were.
> Its possible that what works already is enough for Amir. For example,
> 
> library(e1071)
> library(dyn)
> set.seed(1)
> y <- ts(rnorm(100))
> y.svm <- dyn$svm(y ~ lag(y))

The above statement should have been y.svm <- dyn$svm(y ~ lag(y,-1))
since we want to bring the previous value of y forward so that it is being
used to predict y (rather than predicting y by bringing the future value of y
backward).  In R positive values for the lag move the series backward
and negative values move it forward.

> yp <- predict(y.svm)
> ts.plot(y, yp, col = 1:2)
> 
> On 8/12/05, David Meyer <david.meyer at wu-wien.ac.at> wrote:
> > Amir,
> >
> > >
> > > Suppose that we want to regress for example a certain autoregressive
> > > model using SVM. We have our data and also some fixed kernels in
> > > libSVM behinde e1071 in front. The question: Where can we insert our
> > > certain autoregressive model ? During creating data frame ?
> >
> > Yes, I think.
> >
> > > Or perhaps we can make a
> > > relationship between our variables ended to desired autoregressive
> > > model ?
> >
> > Gabor Grothendieck's `dyn` package provides support for the use of
> > general regression functions for time series analysis, and we are
> > currently struggling to integrate the e1071 interface into that
> > framework (but nothing is ready so far). Is it that kind of support you
> > have been looking for?
> >
> > Cheers,
> > David
> >
> > >
> > > Thanks a lot for your help.
> > > Amir Safari
> > >
> > >
> > >
> > >
> > > __________________________________________________
> > > Do You Yahoo!?
> > > Tired of spam?  Yahoo! Mail has the best spam protection around
> > > http://mail.yahoo.com
> >
> >
> > --
> > Dr. David Meyer
> > Department of Information Systems and Operations
> >
> > Vienna University of Economics and Business Administration
> > Augasse 2-6, A-1090 Wien, Austria, Europe
> > Fax: +43-1-313 36x746
> > Tel: +43-1-313 36x4393
> > HP:  http://wi.wu-wien.ac.at/~meyer/
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>



From jps at sanger.ac.uk  Fri Aug 12 14:27:51 2005
From: jps at sanger.ac.uk (Jason Skelton)
Date: Fri, 12 Aug 2005 13:27:51 +0100
Subject: [R] Dating Objects
Message-ID: <42FC95C7.8080106@sanger.ac.uk>

Hi

I know this subject has been mentioned before but from the mail archives 
I'm under the impression that this is not possible ?
I'm trying to carryout the equivalent of ls -l in R to give some 
date/time label to each of my objects

If the case is that there is no equivalent, is it possible to list all 
objects in an environment that share a common component ?
So that the common component is also displayed ?

I'm attempting to do the following

object$time <- Sys.time() for every object i've created
which although tedious appears to work

However I've no idea how if it is possible to list all the objects by $time
or extract the object name & $ time from all objects simultaneously so I 
can compare them.
Or am I just wasting my time ?

Apologies but my knowledge of R is limited at best ;-(
Any help would be fantastic and greatfully received

Cheers

Jason



-- 
--------------------------------
Jason Skelton
Pathogen Microarrays
Wellcome Trust Sanger Institute
Hinxton
Cambridge
CB10 1SA

Tel +44(0)1223 834244 Ext 7123
Fax +44(0)1223 494919



From dieter.menne at menne-biomed.de  Fri Aug 12 14:37:03 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 12 Aug 2005 12:37:03 +0000 (UTC)
Subject: [R] chisq warning
References: <000001c59efa$2344c810$9701a8c0@Tablet>
Message-ID: <loom.20050812T143258-488@post.gmane.org>

Stephen Choularton <mail <at> bymouth.com> writes:

> I am running chisq as below and getting a warning. Can anyone tell me
> the significance or the warning?
> 
> > chisq.test(c(10 ,4 ,2 ,6 ,5 ,3 ,4 ,4 ,6 ,3 ,2 ,2 ,2 ,4 ,7 ,10 ,0 ,6
> ,19 ,3 ,2 ,7 ,2 ,2 ,2 ,1 ,32 ,2 ,3 ,10 ,1 ,3 ,9 ,4 ,10 ,2 ,2 ,4 ,5 ,7 ,6

.....

> Warning message: 
> Chi-squared approximation may be incorrect in: chisq.test(c(10, 4, 2, 6,
> 5, 3, 4, 4, 6, 3, 2, 2, 2, 4, 7, 10,  

This warning means that the expected count in one group is < 5. Try 
simulate.p.value = TRUE if you want to be sure your result is meaningful. 
Looks like you should be cautios: p = 0.0004998 versus p< 2.2 E-16 with
simulate.p.value = FALSE.

Dieter



From S.Pickett at exeter.ac.uk  Fri Aug 12 14:41:54 2005
From: S.Pickett at exeter.ac.uk (sp219)
Date: Fri, 12 Aug 2005 13:41:54 +0100
Subject: [R] coercing created variables into a new data frame using na.omit()
Message-ID: <42FD2569@minerva2.ex.ac.uk>

Hi,
I am an R newbie and one thing I am having trouble with binding variables that 
I have created within one data frame into a new data frame when using 
na.omit(). To illustrate this problem I will give the example I am working on 
and the approah I have been using:-
data.frame1<-filepath....
attach(data.frame1)
#create a new variable using a function
new.variable<-rep(1,length(weight3))
for (x in 1:length(new.variable)) 
{f<-((((age1[x]-7)*(weight[x]-mw))+((age2[x]-7)*(weight2[x]-mw))+((age3[x]-7)*
(weight3[x]-mw)))/(((age1[x]-7)^2)+((age2[x]-7)^2)+((age3[x]-7)^2))); 
new.variable[x]<-f}
#then bind it into the existing old data frame
data.frame2<-cbind(data.frame1,newvariable)
rm(dat.frame1)
attach(data.frame2)
#everything o.k. so far but now the problem part... I basically want to remove 
all the rows with NA in the new data frame including corresponding rows in the 
new variable
data.frame3<-na.omit(data.frame2)
rm(data.frame2)
attach(data.frame3)
length of new.variable has not changed but the length of all the other 
variables in data.frame2 has?
Could someone please provide an explanation or an alternative route if 
possible?
Any suggestions much appreciated,
Thankyou, Simon Pickett

Simon Pickett
Centre for Ecology and Conservation Biology
University of Exeter in Cornwall
Tremough Campus
Penryn 
Cornwall
TR10 9EZ UK
Tel: 01326371852



From dieter.menne at menne-biomed.de  Fri Aug 12 14:43:46 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 12 Aug 2005 12:43:46 +0000 (UTC)
Subject: [R] error tracing
References: <20050811223418.22598.qmail@web33315.mail.mud.yahoo.com>
Message-ID: <loom.20050812T144138-228@post.gmane.org>

Steve Adams <steve_adams_sd <at> yahoo.com> writes:

 
> Hi, I am running some Cox modeling on large number of
> variables (thousands) using apply. For some reasons,
> some of the variables have problems in Cox regression,
> so the the run was stopped automatically. Is there a
> way to keep the running for all the variables to
> complete and let us, when done, to trace back which of
> the variables cause the problem?

Since each Cox model is a bit of work, you won't notice
the difference if you used a loop instead of apply. Within the for-loop, 
use try() to catch the bad guys.

Dieter



From S.Pickett at exeter.ac.uk  Fri Aug 12 14:42:43 2005
From: S.Pickett at exeter.ac.uk (sp219)
Date: Fri, 12 Aug 2005 13:42:43 +0100
Subject: [R] coercing created variables into a new data frame using na.omit()
Message-ID: <42FD2639@minerva2.ex.ac.uk>

Hi,
I am an R newbie and one thing I am having trouble with binding variables that 
I have created within one data frame into a new data frame when using 
na.omit(). To illustrate this problem I will give the example I am working on 
and the approah I have been using:-
data.frame1<-filepath....
attach(data.frame1)
#create a new variable using a function
new.variable<-rep(1,length(weight3))
for (x in 1:length(new.variable)) 
{f<-((((age1[x]-7)*(weight[x]-mw))+((age2[x]-7)*(weight2[x]-mw))+((age3[x]-7)*
(weight3[x]-mw)))/(((age1[x]-7)^2)+((age2[x]-7)^2)+((age3[x]-7)^2))); 
new.variable[x]<-f}
#then bind it into the existing old data frame
data.frame2<-cbind(data.frame1,newvariable)
rm(dat.frame1)
attach(data.frame2)
#everything o.k. so far but now the problem part... I basically want to remove 
all the rows with NA in the new data frame including corresponding rows in the 
new variable
data.frame3<-na.omit(data.frame2)
rm(data.frame2)
attach(data.frame3)
length of new.variable has not changed but the length of all the other 
variables in data.frame2 has?
Could someone please provide an explanation or an alternative route if 
possible?
Any suggestions much appreciated,
Thankyou, Simon Pickett

Simon Pickett
Centre for Ecology and Conservation Biology
University of Exeter in Cornwall
Tremough Campus
Penryn 
Cornwall
TR10 9EZ UK
Tel: 01326371852



From ripley at stats.ox.ac.uk  Fri Aug 12 14:59:31 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 Aug 2005 13:59:31 +0100 (BST)
Subject: [R] coercing created variables into a new data frame using
 na.omit()
In-Reply-To: <42FD2569@minerva2.ex.ac.uk>
References: <42FD2569@minerva2.ex.ac.uk>
Message-ID: <Pine.LNX.4.61.0508121348430.8827@gannet.stats>

I don't know if you can read your message, but I find it exceedingly 
difficult and there seem to be several typos.  Please use the space and 
return keys ... and only send a message once.

You problem is perhaps that you are not looking at the data frame, but at 
the variable in the workspace.  attach()ing data frames is convenient but 
error-prone (as you have found).  rm(new.variable) should solve this, but 
it is better to cultivate a different style.  For example

with(data.frame1, {
# commands to create value
data.frame1$new.variable <- value
})
data.frame3 <- na.omit(data.frame1)

I think too that the creation of the value can be vectorized simply, 
generalizing something like

value <- (age1 - 7)*(weight - mw)


On Fri, 12 Aug 2005, sp219 wrote:

> Hi,
> I am an R newbie and one thing I am having trouble with binding variables that
> I have created within one data frame into a new data frame when using
> na.omit(). To illustrate this problem I will give the example I am working on
> and the approah I have been using:-
> data.frame1<-filepath....
> attach(data.frame1)
> #create a new variable using a function
> new.variable<-rep(1,length(weight3))
> for (x in 1:length(new.variable))
> {f<-((((age1[x]-7)*(weight[x]-mw))+((age2[x]-7)*(weight2[x]-mw))+((age3[x]-7)*
> (weight3[x]-mw)))/(((age1[x]-7)^2)+((age2[x]-7)^2)+((age3[x]-7)^2)));
> new.variable[x]<-f}
> #then bind it into the existing old data frame
> data.frame2<-cbind(data.frame1,newvariable)
> rm(dat.frame1)
> attach(data.frame2)
> #everything o.k. so far but now the problem part... I basically want to remove
> all the rows with NA in the new data frame including corresponding rows in the
> new variable
> data.frame3<-na.omit(data.frame2)
> rm(data.frame2)
> attach(data.frame3)
> length of new.variable has not changed but the length of all the other
> variables in data.frame2 has?
> Could someone please provide an explanation or an alternative route if
> possible?
> Any suggestions much appreciated,
> Thankyou, Simon Pickett
>
> Simon Pickett
> Centre for Ecology and Conservation Biology
> University of Exeter in Cornwall
> Tremough Campus
> Penryn
> Cornwall
> TR10 9EZ UK
> Tel: 01326371852
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sdavis2 at mail.nih.gov  Fri Aug 12 15:07:15 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 12 Aug 2005 09:07:15 -0400
Subject: [R] Finding regions of overlap
Message-ID: <BF221743.C451%sdavis2@mail.nih.gov>

I have a number of regions consisting of (start,end) pairs.  I would like to
find regions of overlap among various sets of these regions.  In other
words, I would like to find unions/intersections of arbitrary sets of
regions.  Does this smell of anything anyone has already done?

Thanks,
Sean



From br44114 at gmail.com  Fri Aug 12 15:12:15 2005
From: br44114 at gmail.com (bogdan romocea)
Date: Fri, 12 Aug 2005 09:12:15 -0400
Subject: [R] Concerning reading of SAS-files
Message-ID: <8d5a363505081206121e70b522@mail.gmail.com>

The first one is an index, not a data set. Anyway, just use SAS to
export the data sets in text format (CSV, tab-delimited etc). You can
then easily read those in R. (By the way, the help for read.xport says
that 'The file must be in SAS XPORT format.' Is .sas7bdat an XPORT
file? Hint: no.)


> -----Original Message-----
> From: Fredrik Thuring [mailto:frt at Codan.dk] 
> Sent: Friday, August 12, 2005 4:52 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Concerning reading of SAS-files
> 
> 
> 
> Hi!
> 
> I'm trying to start a credibility estimation study with a 
> coule of data 
> sets that are created for SAS. The data sets are saved as 
> ".sas7bndx" and 
> ".sas7bdat".
> I've tried reading them to R with the function 'read.xport' but this 
> returns the error message 'Error in lookup.xport(file) : 
> unable to open 
> file'.
> Are there any other functions that one could use instead?
> 
> Thanks a lot to who ever can solve my problem!
> 
> Fredrik Thuring
> Codan Insurance, Copenhagen
> 
> Best regards
> Fredrik Thuring
> 
> 
> --------------------------------------------------------------
> ----------------
> This e-mail and any attachment may be confidential and may 
> also be privileged.
> If you are not the intended recipient, please notify us 
> immediately and then
> delete this e-mail and any attachment without retaining 
> copies or disclosing
> the contents thereof to any other person.
> Thank you.
> --------------------------------------------------------------
> ----------------
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From dmbates at gmail.com  Fri Aug 12 15:29:03 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Fri, 12 Aug 2005 08:29:03 -0500
Subject: [R] Problem with lme4
In-Reply-To: <42FC882F.90101@fe.up.pt>
References: <42FC882F.90101@fe.up.pt>
Message-ID: <40e66e0b050812062913d202ab@mail.gmail.com>

On 8/12/05, Peter Ho <peter at fe.up.pt> wrote:
> Hi,
> 
> I cannot seem to get lme4 to work. I have installed the lme4 and Matrix
> package with apt-get. and both can be found in /usr/lib/R/site-library.
> When I tried an example for lmer, R could not find the function lmer(),

Try using

install.packages("Matrix")
install.packages("lme4")

in R instead.  I have not created and uploaded new Debian packages of
the lme4 and Matrix R packages for several weeks.  The versions on
CRAN are more recent than the versions on the Debian archives.

> 
>  > library(lme4)
> 
> Attaching package: 'lme4'
> 
> 
>         The following object(s) are masked from package:nlme :
> 
>          getCovariateFormula getResponseFormula groupedData
> 
> Error in autoloader(name = "confint", package = "MASS") :
>         autoloader did not find 'confint' in 'MASS'

Try not to have the nlme and the lme4 packages loaded simultaneously. 
It appears that you may have had Rcmdr loaded causing many of the
other packages to be loaded.  It would be better to use --vanilla in
the call to R and keep the number of loaded packages to a minimum
until you can work out the problem of where lmer can be found.

It is a bit confusing.  The lmer function was in the lme4 package but
now is in the Matrix package.
>  > (fm1 <- lmer(decrease ~ treatment + (1|rowpos) + (1|colpos),
> +              OrchardSprays))
> Error: couldn't find function "lmer"
>  >
> 
> Is this a bug with the lme4 package for Debian (r-cran-lme4)?
> 
> 
> Peter
> 
> 
> 
> #########################
> R : Copyright 2005, The R Foundation for Statistical Computing
> Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>   Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
> 
> Loading Tcl/Tk interface ... done
> Loading required package: tcltk
> Loading required package: rgl
> Loading required package: zoo
> Loading required package: strucchange
> Loading required package: sandwich
> Loading required package: relimp
> Loading required package: nnet
> Loading required package: graphics
> Loading required package: grDevices
> Loading required package: stats
> Loading required package: nlme
> 
> Attaching package: 'nlme'
> 
> 
>         The following object(s) are masked from package:stats :
> 
>          contr.SAS
> 
> Loading required package: mvtnorm
> Loading required package: multcomp
> Loading required package: mgcv
> This is mgcv 1.2-4
> Loading required package: MASS
> Loading required package: lmtest
> Loading required package: lattice
> Loading required package: grid
> Loading required package: foreign
> Loading required package: effects
> Loading required package: car
> Loading required package: abind
> [Previously saved workspace restored]
> 
>  > library(Matrix)
>  > library(lme4)
> 
> Attaching package: 'lme4'
> 
> 
>         The following object(s) are masked from package:nlme :
> 
>          getCovariateFormula getResponseFormula groupedData
> 
> Error in autoloader(name = "confint", package = "MASS") :
>         autoloader did not find 'confint' in 'MASS'
>  > (fm1 <- lmer(decrease ~ treatment + (1|rowpos) + (1|colpos),
> +              OrchardSprays))
> Error: couldn't find function "lmer"
>  >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Fri Aug 12 15:30:50 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 12 Aug 2005 09:30:50 -0400
Subject: [R] Finding regions of overlap
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EBC0@usctmx1106.Merck.com>

Am I missing something?  It seems quite easy to me:

Suppose the intervals are (l1, u1), (l2, u2), ..., (ln, un).  The
intersection, if non-empty, would be (max(l1, ..., ln), min(u1, ..., un)),
and the union (min(l1, ..., ln), max(u1, ..., un)).

Andy

> From: Sean Davis
> 
> I have a number of regions consisting of (start,end) pairs.  
> I would like to
> find regions of overlap among various sets of these regions.  In other
> words, I would like to find unions/intersections of arbitrary sets of
> regions.  Does this smell of anything anyone has already done?
> 
> Thanks,
> Sean
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From sdavis2 at mail.nih.gov  Fri Aug 12 15:35:00 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 12 Aug 2005 09:35:00 -0400
Subject: [R] Finding regions of overlap
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EBC0@usctmx1106.Merck.com>
Message-ID: <BF221DC4.C45A%sdavis2@mail.nih.gov>

On 8/12/05 9:30 AM, "Liaw, Andy" <andy_liaw at merck.com> wrote:

> Am I missing something?  It seems quite easy to me:
> 
> Suppose the intervals are (l1, u1), (l2, u2), ..., (ln, un).  The
> intersection, if non-empty, would be (max(l1, ..., ln), min(u1, ..., un)),
> and the union (min(l1, ..., ln), max(u1, ..., un)).

Another coffee for me?

Thanks, Andy.

Sean



From Jan.Verbesselt at biw.kuleuven.be  Fri Aug 12 15:45:26 2005
From: Jan.Verbesselt at biw.kuleuven.be (Jan Verbesselt)
Date: Fri, 12 Aug 2005 15:45:26 +0200
Subject: [R] HowTo derive a correct likelihood-ratio chi-squared statistic
	from lrm() with a rsc() ?
Message-ID: <001c01c59f44$188eee60$1145210a@agr.ad10.intern.kuleuven.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050812/6592260d/attachment.pl

From bleongcw at gmail.com  Fri Aug 12 15:50:43 2005
From: bleongcw at gmail.com (Bernard Leong)
Date: Fri, 12 Aug 2005 14:50:43 +0100
Subject: [R] Issues with tcltk for Tiger Mac OSX
Message-ID: <296ecd1205081206507d983b1a@mail.gmail.com>

Dear R-helpers,

I have installed the latest version of R 2.1.1 in the Tiger OSX.
However, when I load up R and use the following command:

> library(tcltk)

I encounter the following error:

Loading Tcl/Tk interface ... Error in dyn.load(x, as.logical(local),
as.logical(now)) :
	unable to load shared library
'/Library/Frameworks/R.framework/Resources/library/tcltk/libs/tcltk.so':
  dlopen(/Library/Frameworks/R.framework/Resources/library/tcltk/libs/tcltk.so,
10): corrupt binary, library ordinal too big
Error: .onLoad failed in 'loadNamespace' for 'tcltk'
Error: package/namespace load failed for 'tcltk'

I have done a couple of remedies: 
1) Tried installing tcl and tk 8.4 from source
2) Tried to install the version of tcltk from the fink sourceforge net.
3) Tried to change the path

and it does not work.

Does anyone have a solution to this problem  as I need tcltk to run limmaGUI?

Best regards,
Bernard



From deepayan.sarkar at gmail.com  Fri Aug 12 15:55:46 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 12 Aug 2005 08:55:46 -0500
Subject: [R] Groups in histograms?
In-Reply-To: <376e97ec05080901291dd5b00@mail.gmail.com>
References: <376e97ec05080804263ea2b05d@mail.gmail.com>
	<dd6040c905080804377c7da379@mail.gmail.com>
	<376e97ec05080805066022332f@mail.gmail.com>
	<376e97ec05080901291dd5b00@mail.gmail.com>
Message-ID: <eb555e660508120655242ab8b8@mail.gmail.com>

On 8/9/05, Fredrik Karlsson <dargosch at gmail.com> wrote:
> Dear list,
> 
> Sorry for answering my own post, but I have had partial sucess in
> this. With the panel function below, I get separate histograms in each
> panel using the group argument.
> 
> histogram(~vot | agem, nint=50,data=work,groups=Type, subset=agem > 24
> & agem < 30, panel=panel.grouphist,type="count",ylim=c(0,20),auto.key=T)
> 
> panel.grouphist <- function(x,groups,...){
>   add <- T
>   grouplevels <- unique(groups)
>   ngroups <- length(grouplevels)
> 
>   for(i in 1:ngroups){
>     gcol <- trellis.par.get("superpose.fill")$col[i]
>     gx <- x[groups == grouplevels[i]]
>     panel.histogram(gx,col=gcol,...)
>   }
> 
> }
> 
> However, the color I get in the key using simpleKey is not the same as
> the one in the the plot.
> How do I get the two functions to use the same color scale?

How are you using simpleKey? I get the same colors by adding 

histogram(...
                 auto.key = list(points = FALSE, rectangles = TRUE))

By the way, have you considered using a grouped 'densityplot' instead?

Deepayan



From liuj24 at univmail.cis.mcmaster.ca  Fri Aug 12 15:59:57 2005
From: liuj24 at univmail.cis.mcmaster.ca (J. Liu)
Date: Fri, 12 Aug 2005 09:59:57 -0400
Subject: [R] General expression of a unitary matrix
Message-ID: <web-101063654@cgpsrv2.cis.mcmaster.ca>

Hi, all,

Does anybody got the most general expression of a unitary matrix?
I found one in the book, four entries of the matrix are:
 
(cos\theta) exp(j\alpha);     -(sin\theta)exp(j(\alpha-\Omega));
(sin\theta)exp(j(\beta+\Omega));   (cos\theta) exp(j\beta);
 
where "j" is for complex. 
However, since for any two unitary matrices, their product should also
be a unitary matrix. When I try to use the above expression to
calculate the product, I can not derive the product into the same form.
Therefore, I suspect that this may not be the most general expression. 

Could you help me out of this? Thanks...



From ecartis at lists.ems.ru  Fri Aug 12 16:19:09 2005
From: ecartis at lists.ems.ru (Ecartis)
Date: Fri, 12 Aug 2005 07:19:09 -0700 (PDT)
Subject: [R] Ecartis command results: -- Binary/unsupported file stripped by
	Ecartis --
Message-ID: <ecartis-08122005071909.3200.1@216-55-166-157.dedicated.abac.net>


>> The original message was received at Fri, 12 Aug 2005 09:18:43 -0500
Unknown command.

>> from 175.107.114.173
Unknown command.

>> ----- The following addresses had permanent fatal errors -----
Unknown command.

>> ecartis at ems.ems.ru
Unknown command.

>> ----- Transcript of the session follows -----
Unknown command.

>> ... while talking to mail server 123.68.71.251:
Unknown command.

>> 554 <ecartis at ems.ems.ru>... Mail quota exceeded
Unknown command.

>> 554 <ecartis at ems.ems.ru>... Service unavailable
Unknown command.

---
Ecartis v1.0.0 - job execution complete.



From dlvanbrunt at gmail.com  Fri Aug 12 16:20:50 2005
From: dlvanbrunt at gmail.com (David L. Van Brunt, Ph.D.)
Date: Fri, 12 Aug 2005 09:20:50 -0500
Subject: [R] Creating new columns inside a loop
In-Reply-To: <200508111656.j7BGudmU018861@faraday.gene.com>
References: <d332d3e105081108386f81426f@mail.gmail.com>
	<200508111656.j7BGudmU018861@faraday.gene.com>
Message-ID: <d332d3e105081207206b86180a@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050812/753b16ca/attachment.pl

From roebuck at odin.mdacc.tmc.edu  Fri Aug 12 16:24:31 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Fri, 12 Aug 2005 09:24:31 -0500 (CDT)
Subject: [R] Dating Objects
In-Reply-To: <42FC95C7.8080106@sanger.ac.uk>
References: <42FC95C7.8080106@sanger.ac.uk>
Message-ID: <Pine.OSF.4.58.0508120906190.268788@odin.mdacc.tmc.edu>

On Fri, 12 Aug 2005, Jason Skelton wrote:

> I'm trying to carryout the equivalent of ls -l in R
> to give some date/time label to each of my objects
>
> If the case is that there is no equivalent, is it
> possible to list all objects in an environment that
> share a common component so that the common component
> is also displayed?
>
> I'm attempting to do the following
>
> object$time <- Sys.time()
>
> for every object i've created which although tedious
> appears to work
>
> However I've no idea how if it is possible to list all
> the objects by $time or extract the object name & $time
> from all objects simultaneously so I can compare them.

Not really following why you want to do this so it's
hard to suggest something. Were you attempting to track
mtime or ctime?

Perhaps instead you could describe the larger problem
you're trying to solve so there's more context to work
with.

> Or am I just wasting my time?

Most of us probably are...

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From leonardosepulveda at gmail.com  Fri Aug 12 16:44:25 2005
From: leonardosepulveda at gmail.com (=?ISO-8859-1?Q?Leonardo_Sepulveda_Dur=E1n?=)
Date: Fri, 12 Aug 2005 10:44:25 -0400
Subject: [R] evaluating string variables
Message-ID: <78a5a6fe050812074455760f6c@mail.gmail.com>

Hello!!!

I have a folder (C:/R/) with matrix files, named by number, i.e.
0.mat, 1.mat,...,1250.mat. In this case, they are 5x5 simetric
matrices. I would like to compute a property for each matrix and put
calculated values into a data frame for posterior ploting and
printing. Below there is an example for 7 matrices (0.mat..6.mat)

#define data frame
L <- data.frame(frame=numeric(7), L=numeric(7))
f0<-1/(5*(5-1)) # first variable for computation

#loop over matrices, Open it , calculate property and put into data frame
for(i in 0:6){
	m<-matrix(scan('C:/R/i.mat', n=5*5),5,5, byrow=TRUE) # load matrix
	f1<-geodist(m)                                                           
	f2<-sum(colSums(f1$gdist))                                        
	l <-f0*f2                                                            
       # Calculate property
	L[i+1, ]<-c(i,l)                                                     
      # Fill data frame
}

but the matrix cannot be loaded, because it try to open a file named
"i.mat". I don`t know how to loop with a counter named 'i', and use it
to define the name of the file too. How can i do it? I have not found
the way.
 
Leonardo



From sean.oriordain at gmail.com  Fri Aug 12 16:49:36 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Fri, 12 Aug 2005 14:49:36 +0000
Subject: [R] evaluating string variables
In-Reply-To: <78a5a6fe050812074455760f6c@mail.gmail.com>
References: <78a5a6fe050812074455760f6c@mail.gmail.com>
Message-ID: <8ed68eed05081207496fd3220@mail.gmail.com>

use paste() to construct the file name 
e.g. fn <- paste(i,".mat",sep="")

Sean

On 12/08/05, Leonardo Sepulveda Dur??n <leonardosepulveda at gmail.com> wrote:
> Hello!!!
> 
> I have a folder (C:/R/) with matrix files, named by number, i.e.
> 0.mat, 1.mat,...,1250.mat. In this case, they are 5x5 simetric
> matrices. I would like to compute a property for each matrix and put
> calculated values into a data frame for posterior ploting and
> printing. Below there is an example for 7 matrices (0.mat..6.mat)
> 
> #define data frame
> L <- data.frame(frame=numeric(7), L=numeric(7))
> f0<-1/(5*(5-1)) # first variable for computation
> 
> #loop over matrices, Open it , calculate property and put into data frame
> for(i in 0:6){
>         m<-matrix(scan('C:/R/i.mat', n=5*5),5,5, byrow=TRUE) # load matrix
>         f1<-geodist(m)
>         f2<-sum(colSums(f1$gdist))
>         l <-f0*f2
>        # Calculate property
>         L[i+1, ]<-c(i,l)
>       # Fill data frame
> }
> 
> but the matrix cannot be loaded, because it try to open a file named
> "i.mat". I don`t know how to loop with a counter named 'i', and use it
> to define the name of the file too. How can i do it? I have not found
> the way.
> 
> Leonardo
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dimitris.rizopoulos at med.kuleuven.be  Fri Aug 12 16:52:08 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Fri, 12 Aug 2005 16:52:08 +0200
Subject: [R] evaluating string variables
References: <78a5a6fe050812074455760f6c@mail.gmail.com>
Message-ID: <00b301c59f4d$6982b8c0$0540210a@www.domain>

look at ?paste(), e.g.,

paste("C:/R/", i, "mat", sep = "")

I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Leonardo Sepulveda Dur??n" <leonardosepulveda at gmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Friday, August 12, 2005 4:44 PM
Subject: [R] evaluating string variables


> Hello!!!
>
> I have a folder (C:/R/) with matrix files, named by number, i.e.
> 0.mat, 1.mat,...,1250.mat. In this case, they are 5x5 simetric
> matrices. I would like to compute a property for each matrix and put
> calculated values into a data frame for posterior ploting and
> printing. Below there is an example for 7 matrices (0.mat..6.mat)
>
> #define data frame
> L <- data.frame(frame=numeric(7), L=numeric(7))
> f0<-1/(5*(5-1)) # first variable for computation
>
> #loop over matrices, Open it , calculate property and put into data 
> frame
> for(i in 0:6){
> m<-matrix(scan('C:/R/i.mat', n=5*5),5,5, byrow=TRUE) # load matrix
> f1<-geodist(m)
> f2<-sum(colSums(f1$gdist))
> l <-f0*f2
>       # Calculate property
> L[i+1, ]<-c(i,l)
>      # Fill data frame
> }
>
> but the matrix cannot be loaded, because it try to open a file named
> "i.mat". I don`t know how to loop with a counter named 'i', and use 
> it
> to define the name of the file too. How can i do it? I have not 
> found
> the way.
>
> Leonardo
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From francoisromain at free.fr  Fri Aug 12 17:01:40 2005
From: francoisromain at free.fr (Romain Francois)
Date: Fri, 12 Aug 2005 17:01:40 +0200
Subject: [R] evaluating string variables
In-Reply-To: <78a5a6fe050812074455760f6c@mail.gmail.com>
References: <78a5a6fe050812074455760f6c@mail.gmail.com>
Message-ID: <42FCB9D4.2000001@free.fr>

Le 12.08.2005 16:44, Leonardo Sepulveda Dur??n a ??crit :

>Hello!!!
>
>I have a folder (C:/R/) with matrix files, named by number, i.e.
>0.mat, 1.mat,...,1250.mat. In this case, they are 5x5 simetric
>matrices. I would like to compute a property for each matrix and put
>calculated values into a data frame for posterior ploting and
>printing. Below there is an example for 7 matrices (0.mat..6.mat)
>
>#define data frame
>L <- data.frame(frame=numeric(7), L=numeric(7))
>f0<-1/(5*(5-1)) # first variable for computation
>
>#loop over matrices, Open it , calculate property and put into data frame
>for(i in 0:6){
>	m<-matrix(scan('C:/R/i.mat', n=5*5),5,5, byrow=TRUE) # load matrix
>	f1<-geodist(m)                                                           
>	f2<-sum(colSums(f1$gdist))                                        
>	l <-f0*f2                                                            
>       # Calculate property
>	L[i+1, ]<-c(i,l)                                                     
>      # Fill data frame
>}
>
>but the matrix cannot be loaded, because it try to open a file named
>"i.mat". I don`t know how to loop with a counter named 'i', and use it
>to define the name of the file too. How can i do it? I have not found
>the way.
> 
>Leonardo
>  
>
Here are two ways :

paste('C:/R/',i,'.mat',sep="")
sprintf("C:/R/%d.mat",i)

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From leonardosepulveda at gmail.com  Fri Aug 12 16:59:33 2005
From: leonardosepulveda at gmail.com (=?ISO-8859-1?Q?Leonardo_Sepulveda_Dur=E1n?=)
Date: Fri, 12 Aug 2005 10:59:33 -0400
Subject: [R] evaluating string variables
In-Reply-To: <00b301c59f4d$6982b8c0$0540210a@www.domain>
References: <78a5a6fe050812074455760f6c@mail.gmail.com>
	<00b301c59f4d$6982b8c0$0540210a@www.domain>
Message-ID: <78a5a6fe050812075934f9c64a@mail.gmail.com>

Thanks a lot!!! 

using

m<-matrix(scan(paste("C:/R/",i,".mat",sep=""), n=5*5),5,5, byrow=TRUE)

worked very well!!!

Leonardo



From gunter.berton at gene.com  Fri Aug 12 17:03:29 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 12 Aug 2005 08:03:29 -0700
Subject: [R] evaluating string variables
In-Reply-To: <78a5a6fe050812074455760f6c@mail.gmail.com>
Message-ID: <200508121503.j7CF3TiS010415@compton.gene.com>


Given my own language inadequacies (I speak only one), I must, of necessity,
refrain from criticizing  the multilingual. However, in this one instance my
sensibilities have been overwhelmed: "symmetric" , please :-)   .

Incidentally, you may find that file.path() is also useful.

Cheers,
Bert

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Leonardo Sepulveda Dur??n
> Sent: Friday, August 12, 2005 7:44 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] evaluating string variables
> 
> Hello!!!
> 
> I have a folder (C:/R/) with matrix files, named by number, i.e.
> 0.mat, 1.mat,...,1250.mat. In this case, they are 5x5 simetric
> matrices. I would like to compute a property for each matrix and put
> calculated values into a data frame for posterior ploting and
> printing. Below there is an example for 7 matrices (0.mat..6.mat)
> 
> #define data frame
> L <- data.frame(frame=numeric(7), L=numeric(7))
> f0<-1/(5*(5-1)) # first variable for computation
> 
> #loop over matrices, Open it , calculate property and put 
> into data frame
> for(i in 0:6){
> 	m<-matrix(scan('C:/R/i.mat', n=5*5),5,5, byrow=TRUE) # 
> load matrix
> 	f1<-geodist(m)                                          
>                  
> 	f2<-sum(colSums(f1$gdist))                              
>           
> 	l <-f0*f2                                               
>              
>        # Calculate property
> 	L[i+1, ]<-c(i,l)                                        
>              
>       # Fill data frame
> }
> 
> but the matrix cannot be loaded, because it try to open a file named
> "i.mat". I don`t know how to loop with a counter named 'i', and use it
> to define the name of the file too. How can i do it? I have not found
> the way.
>  
> Leonardo
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From f.harrell at vanderbilt.edu  Fri Aug 12 17:26:39 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 12 Aug 2005 10:26:39 -0500
Subject: [R] Concerning reading of SAS-files
In-Reply-To: <8d5a363505081206121e70b522@mail.gmail.com>
References: <8d5a363505081206121e70b522@mail.gmail.com>
Message-ID: <42FCBFAF.3010807@vanderbilt.edu>

bogdan romocea wrote:
> The first one is an index, not a data set. Anyway, just use SAS to
> export the data sets in text format (CSV, tab-delimited etc). You can
> then easily read those in R. (By the way, the help for read.xport says
> that 'The file must be in SAS XPORT format.' Is .sas7bdat an XPORT
> file? Hint: no.)
> 
> 
> 
>>-----Original Message-----
>>From: Fredrik Thuring [mailto:frt at Codan.dk] 
>>Sent: Friday, August 12, 2005 4:52 AM
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] Concerning reading of SAS-files
>>
>>
>>
>>Hi!
>>
>>I'm trying to start a credibility estimation study with a 
>>coule of data 
>>sets that are created for SAS. The data sets are saved as 
>>".sas7bndx" and 
>>".sas7bdat".
>>I've tried reading them to R with the function 'read.xport' but this 
>>returns the error message 'Error in lookup.xport(file) : 
>>unable to open 
>>file'.
>>Are there any other functions that one could use instead?
>>
>>Thanks a lot to who ever can solve my problem!
>>
>>Fredrik Thuring
>>Codan Insurance, Copenhagen

If you want to go the CSV route, the sasxport.get function in Hmisc can 
help.  Its help function references a Howto on our web site.  Beware 
that SAS PROC EXPORT which it uses is not really a PROC but a stored 
macro (where do all the billions of $ SAS earns go?) that has a bug if 
you have an unmatched quote in a field.  sasxport.get will detect the 
problem because it compares the number of observations to that reported 
by PROC CONTENTS.

Frank Harrell



From david.whiting at ncl.ac.uk  Fri Aug 12 17:48:18 2005
From: david.whiting at ncl.ac.uk (David Whiting)
Date: Fri, 12 Aug 2005 16:48:18 +0100
Subject: [R] Dating Objects
In-Reply-To: <42FC95C7.8080106@sanger.ac.uk>
References: <42FC95C7.8080106@sanger.ac.uk>
Message-ID: <42FCC4C2.6000702@ncl.ac.uk>

Hi Jason,

Perhaps you get do what you want to do using attributes? Does this get
close to what you need?


> ## Create some objects
> xx <- "adsfasdf"
> zz <- 3027
> yy <- "abdsf"
>
> ## Assign a time attribute to them.
> attr(zz, "time") <- Sys.time()
> attr(yy, "time") <- Sys.time()
>
> ## To see the time attribute of, for example, zz:
> attributes(zz)$time
[1] "2005-08-12 16:46:47 BST"
>
> ## A crude function to show the time attributes
> ## of objects:
>
> time.attr <- function (x) {
+   x.attr <- attributes(get(x))
+   attr.names <- names(attributes(get(x)))
+   if (!is.null(attr.names) && attr.names %in% "time") {
+     x.time <- x.attr$time
+     names(x.time) <- x
+     x.time
+   }
+ }
>
> ## Apply the time.attr function to all objects listed by ls():
> lapply(ls(), time.attr)
[[1]]
NULL

[[2]]
NULL

[[3]]
                       yy
"2005-08-12 16:46:47 BST"

[[4]]
                       zz
"2005-08-12 16:46:47 BST"


Dave



Jason Skelton wrote:
> Hi
> 
> I know this subject has been mentioned before but from the mail archives 
> I'm under the impression that this is not possible ?
> I'm trying to carryout the equivalent of ls -l in R to give some 
> date/time label to each of my objects
> 
> If the case is that there is no equivalent, is it possible to list all 
> objects in an environment that share a common component ?
> So that the common component is also displayed ?
> 
> I'm attempting to do the following
> 
> object$time <- Sys.time() for every object i've created
> which although tedious appears to work
> 
> However I've no idea how if it is possible to list all the objects by $time
> or extract the object name & $ time from all objects simultaneously so I 
> can compare them.
> Or am I just wasting my time ?
> 
> Apologies but my knowledge of R is limited at best ;-(
> Any help would be fantastic and greatfully received
> 
> Cheers
> 
> Jason
> 
> 
> 

-- 
David Whiting
School of Clinical Medical Sciences, The Medical School
University of Newcastle upon Tyne, NE2 4HH, UK.

"I love deadlines. I love the whooshing noise they make as they go by"
(Douglas Adams)



From rolf at math.unb.ca  Fri Aug 12 17:56:14 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Fri, 12 Aug 2005 12:56:14 -0300 (ADT)
Subject: [R] Dating Objects
Message-ID: <200508121556.j7CFuEwg009104@erdos.math.unb.ca>

Paul Roebuck wrote:

On Fri, 12 Aug 2005, Jason Skelton wrote:

> > I'm trying to carryout the equivalent of ls -l in R
> > to give some date/time label to each of my objects
> >
> > If the case is that there is no equivalent, is it
> > possible to list all objects in an environment that
> > share a common component so that the common component
> > is also displayed?
> >
> > I'm attempting to do the following
> >
> > object$time <- Sys.time()
> >
> > for every object i've created which although tedious
> > appears to work
> >
> > However I've no idea how if it is possible to list all
> > the objects by $time or extract the object name & $time
> > from all objects simultaneously so I can compare them.
> 
> Not really following why you want to do this so it's
> hard to suggest something. Were you attempting to track
> mtime or ctime?
> 
> Perhaps instead you could describe the larger problem
> you're trying to solve so there's more context to work
> with.
> 
> > Or am I just wasting my time?
> 
> Most of us probably are...

	I don't follow what you aren't following ....  It seems to me
	to be an eminently reasonable thing to want to do.  Answers
	questions such as ``Was x modified since y was modified?''

	Presumably modification date is what's wanted; this is the
	crucial concept.  One could tack on a creation date as well ...

	I think I would make the modification data an ***attribute***
	of the object, rather than sticking it in as a component.
	(The latter might mess up some vital aspect of the nature
	of the object.)

	The problem is to remember to date stamp each object each
	time it is modified ....

	To do the analogue of ``ls -l'' one could create a function
	say ``lsl()'' along the following lines:

	lsl <- function() {
		xxx <- ls(envir=.GlobalEnv)
		yyy <- unlist(lapply(xxx,function(x){
					     a <- attr(get(x),'datestamp')
					     if(is.null(a)) NA else a
				  }
                              ))
		ooo <- order(yyy,na.last=FALSE)
		yyy[is.na(yyy)] <- "undated"
		rrr <- rep("",length(xxx))
		prmatrix(cbind(xxx[ooo],yyy[ooo]),rowlab=rrr,quote=FALSE)
		invisible()
	}
	
	The date stamping could be done by a function such as

		 stomp <- function(x){
				attr(x,'datestamp') <- paste(Sys.time())
				x
			  }

	This would work except there seems to be a bug in order()
	when na.last is set to FALSE.

	I tried

	> lsl <- stomp(lsl)
 > stomp <- stomp(stomp)
 > a <- stomp(42)
 > b <- stomp(runif(10))
 > lsl()

and got

 [,1]  [,2]               
 lsl   2005-08-12 12:38:12
 stomp 2005-08-12 12:38:27
 a     2005-08-12 12:38:35
 b     2005-08-12 12:38:46

Then I did

 > x <- 1:10 # No stomping.
 > lsl()

and got

[,1]  [,2]               
 lsl   2005-08-12 12:38:12
 stomp 2005-08-12 12:38:27
 x     undated            
 a     2005-08-12 12:38:35
 b     2005-08-12 12:38:46

so the undated x got put in the middle, rather than at the beginning
as it should've been.  Weird.  I'm going to send a separate email
about this.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From rolf at math.unb.ca  Fri Aug 12 18:18:21 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Fri, 12 Aug 2005 13:18:21 -0300 (ADT)
Subject: [R] Bug in order with na.last=FALSE?
Message-ID: <200508121618.j7CGILs7011874@erdos.math.unb.ca>

I scanned the archives a bit and found discussion of a bug in order
when na.last=NA, but nothing about when na.last=FALSE.

Assign a (character) vector x as follows:

	x <- c("2005-08-12 12:38:35","2005-08-12 12:38:46",NA,
               "2005-08-12 12:38:27",NA)

Then executing

	o <- order(x,na.last=FALSE)
	o
	x[o]

gives

	[1] 4 3 5 1 2

and

	[1] "2005-08-12 12:38:27" NA                    NA                   
	[4] "2005-08-12 12:38:35" "2005-08-12 12:38:46"

so that the NAs are neither first nor last.  The result of order(), ``o''
should be 3 5 4 1 2.

It seems to be the complicated strings which form the entries of x that
are messing things up;

	y <- c("b","c",NA,"a",NA)
	y[order(y,na.last=FALSE)]

gives

	[1] NA  NA  "a" "b" "c"

is it ought.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From B.Rowlingson at lancaster.ac.uk  Fri Aug 12 18:37:33 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 12 Aug 2005 17:37:33 +0100
Subject: [R] Dating Objects
In-Reply-To: <200508121556.j7CFuEwg009104@erdos.math.unb.ca>
References: <200508121556.j7CFuEwg009104@erdos.math.unb.ca>
Message-ID: <42FCD04D.6010404@lancaster.ac.uk>

Rolf Turner wrote:

> 	I don't follow what you aren't following ....  It seems to me
> 	to be an eminently reasonable thing to want to do.  Answers
> 	questions such as ``Was x modified since y was modified?''

  I wanted to have some sort of 'make'-like functionality in R. Suppose 
you have some complicated analysis that depends on several variables. If 
you change one of them, you might not want to redo all the parts of the 
analyses that dont depend on that change. Integrating this with Sweave 
would be another gem, since parts of your Sweave document that might 
take a long time to run might not need to run again if you've only 
changed something after that point. If it takes an hour to generate a 
dataset and two seconds to plot it, and you've made a change to the 
plot, you dont want to re-run the whole data generation again when you 
weave your document.

> 	I think I would make the modification data an ***attribute***
> 	of the object, rather than sticking it in as a component.
> 	(The latter might mess up some vital aspect of the nature
> 	of the object.)
> 
> 	The problem is to remember to date stamp each object each
> 	time it is modified ....

  A while ago I attacked this problem at the C-code level. I found out 
where R made assignments and tacked on a 'modified' attribute to the 
object at that point. However it was a quick hack and it broke R quite 
badly. One of the problems was that R objects were no longer identical 
to assigned versions of themselves, and lots of tests broke.

  I think to be done properly it needs to be done at a lower level.

Barry



From david.meyer at wu-wien.ac.at  Fri Aug 12 20:40:05 2005
From: david.meyer at wu-wien.ac.at (David Meyer)
Date: Fri, 12 Aug 2005 20:40:05 +0200
Subject: [R] How to insert a certain model in SVM regarding to fixed
 kernels
In-Reply-To: <971536df0508120502251e1862@mail.gmail.com>
References: <20050811143415.28223.qmail@web60417.mail.yahoo.com>
	<20050812142835.7c88d847.david.meyer@wu-wien.ac.at>
	<971536df0508120502251e1862@mail.gmail.com>
Message-ID: <20050812204005.49dd5f3b.david.meyer@wu-wien.ac.at>

> David, Please correct me if I am wrong but I think svm partially works
> with dyn although I don't remember what the specific limitations were.

Yes, the fitted values / residuals can be extracted from the trained
model. The 'newdata' argument of predict() is not functional yet for
time series.

Cheers,
David

> Its possible that what works already is enough for Amir. For example,
> 
> library(e1071)
> library(dyn)
> set.seed(1)
> y <- ts(rnorm(100))
> y.svm <- dyn$svm(y ~ lag(y))
> yp <- predict(y.svm)
> ts.plot(y, yp, col = 1:2)
> 
> On 8/12/05, David Meyer <david.meyer at wu-wien.ac.at> wrote:
> > Amir,
> > 
> > >
> > > Suppose that we want to regress for example a certain
> > > autoregressive model using SVM. We have our data and also some
> > > fixed kernels in libSVM behinde e1071 in front. The question:
> > > Where can we insert our certain autoregressive model ? During
> > > creating data frame ?
> > 
> > Yes, I think.
> > 
> > > Or perhaps we can make a
> > > relationship between our variables ended to desired autoregressive
> > > model ?
> > 
> > Gabor Grothendieck's `dyn` package provides support for the use of
> > general regression functions for time series analysis, and we are
> > currently struggling to integrate the e1071 interface into that
> > framework (but nothing is ready so far). Is it that kind of support
> > you have been looking for?
> > 
> > Cheers,
> > David
> > 
> > >
> > > Thanks a lot for your help.
> > > Amir Safari
> > >
> > >
> > >
> > >
> > > __________________________________________________
> > > Do You Yahoo!?
> > > Tired of spam?  Yahoo! Mail has the best spam protection around
> > > http://mail.yahoo.com
> > 
> > 
> > --
> > Dr. David Meyer
> > Department of Information Systems and Operations
> > 
> > Vienna University of Economics and Business Administration
> > Augasse 2-6, A-1090 Wien, Austria, Europe
> > Fax: +43-1-313 36x746
> > Tel: +43-1-313 36x4393
> > HP:  http://wi.wu-wien.ac.at/~meyer/
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> 
> 


-- 
Dr. David Meyer
Department of Information Systems and Operations

Vienna University of Economics and Business Administration
Augasse 2-6, A-1090 Wien, Austria, Europe
Fax: +43-1-313 36x746 
Tel: +43-1-313 36x4393
HP:  http://wi.wu-wien.ac.at/~meyer/



From jfox at mcmaster.ca  Fri Aug 12 19:17:41 2005
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 12 Aug 2005 13:17:41 -0400
Subject: [R] Issues with tcltk for Tiger Mac OSX
In-Reply-To: <296ecd1205081206507d983b1a@mail.gmail.com>
Message-ID: <20050812171741.LFWG26128.tomts5-srv.bellnexxia.net@JohnDesktop8300>

Dear Bernard,

The Rcmdr web site has some instructions prepared by Rob Goedman for Mac
users at
<http://socserv.socsci.mcmaster.ca/jfox/Misc/Rcmdr/installation-notes.html>
that might prove useful. (I'm not a Mac user myself so can't offer specific
advice.)

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Bernard Leong
> Sent: Friday, August 12, 2005 8:51 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Issues with tcltk for Tiger Mac OSX
> 
> Dear R-helpers,
> 
> I have installed the latest version of R 2.1.1 in the Tiger OSX.
> However, when I load up R and use the following command:
> 
> > library(tcltk)
> 
> I encounter the following error:
> 
> Loading Tcl/Tk interface ... Error in dyn.load(x, as.logical(local),
> as.logical(now)) :
> 	unable to load shared library
> '/Library/Frameworks/R.framework/Resources/library/tcltk/libs/
> tcltk.so':
>   
> dlopen(/Library/Frameworks/R.framework/Resources/library/tcltk
> /libs/tcltk.so,
> 10): corrupt binary, library ordinal too big
> Error: .onLoad failed in 'loadNamespace' for 'tcltk'
> Error: package/namespace load failed for 'tcltk'
> 
> I have done a couple of remedies: 
> 1) Tried installing tcl and tk 8.4 from source
> 2) Tried to install the version of tcltk from the fink 
> sourceforge net.
> 3) Tried to change the path
> 
> and it does not work.
> 
> Does anyone have a solution to this problem  as I need tcltk 
> to run limmaGUI?
> 
> Best regards,
> Bernard
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From kjetil at acelerate.com  Fri Aug 12 19:05:07 2005
From: kjetil at acelerate.com (Kjetil Brinchmann Halvorsen)
Date: Fri, 12 Aug 2005 13:05:07 -0400
Subject: [R] coercing created variables into a new data frame using
	na.omit()
In-Reply-To: <Pine.LNX.4.61.0508121348430.8827@gannet.stats>
References: <42FD2569@minerva2.ex.ac.uk>
	<Pine.LNX.4.61.0508121348430.8827@gannet.stats>
Message-ID: <42FCD6C3.6090607@acelerate.com>

Prof Brian Ripley wrote:

>I don't know if you can read your message, but I find it exceedingly 
>difficult and there seem to be several typos.  Please use the space and 
>return keys ... and only send a message once.
>
>You problem is perhaps that you are not looking at the data frame, but at 
>the variable in the workspace.  attach()ing data frames is convenient but 
>error-prone (as you have found).  rm(new.variable) should solve this, but 
>it is better to cultivate a different style.  For example
>
>with(data.frame1, {
># commands to create value
>data.frame1$new.variable <- value
>})
>data.frame3 <- na.omit(data.frame1)
>
>  
>
That cannot possible work, as assignment within with is local to
with's environment. I have used superassigmnent for this (<<-), but that 
cannot possible
be a good style?

Look at the following:

 > test <- data.frame( a=1:5, b=1:5)
 > test
  a b
1 1 1
2 2 2
3 3 3
4 4 4
5 5 5
 > with(test, test$c <- 1:5)
 > test
  a b
1 1 1
2 2 2
3 3 3
4 4 4
5 5 5
 > with(test, test$c <<- 1:5)
 > test
  a b c
1 1 1 1
2 2 2 2
3 3 3 3
4 4 4 4
5 5 5 5

So what is the best style her?

Kjetil

>I think too that the creation of the value can be vectorized simply, 
>generalizing something like
>
>value <- (age1 - 7)*(weight - mw)
>
>
>On Fri, 12 Aug 2005, sp219 wrote:
>
>  
>
>>Hi,
>>I am an R newbie and one thing I am having trouble with binding variables that
>>I have created within one data frame into a new data frame when using
>>na.omit(). To illustrate this problem I will give the example I am working on
>>and the approah I have been using:-
>>data.frame1<-filepath....
>>attach(data.frame1)
>>#create a new variable using a function
>>new.variable<-rep(1,length(weight3))
>>for (x in 1:length(new.variable))
>>{f<-((((age1[x]-7)*(weight[x]-mw))+((age2[x]-7)*(weight2[x]-mw))+((age3[x]-7)*
>>(weight3[x]-mw)))/(((age1[x]-7)^2)+((age2[x]-7)^2)+((age3[x]-7)^2)));
>>new.variable[x]<-f}
>>#then bind it into the existing old data frame
>>data.frame2<-cbind(data.frame1,newvariable)
>>rm(dat.frame1)
>>attach(data.frame2)
>>#everything o.k. so far but now the problem part... I basically want to remove
>>all the rows with NA in the new data frame including corresponding rows in the
>>new variable
>>data.frame3<-na.omit(data.frame2)
>>rm(data.frame2)
>>attach(data.frame3)
>>length of new.variable has not changed but the length of all the other
>>variables in data.frame2 has?
>>Could someone please provide an explanation or an alternative route if
>>possible?
>>Any suggestions much appreciated,
>>Thankyou, Simon Pickett
>>
>>Simon Pickett
>>Centre for Ecology and Conservation Biology
>>University of Exeter in Cornwall
>>Tremough Campus
>>Penryn
>>Cornwall
>>TR10 9EZ UK
>>Tel: 01326371852
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>    
>>
>
>  
>


-- 

Kjetil Halvorsen.

Peace is the most effective weapon of mass construction.
               --  Mahdi Elmandjra





-- 
Internal Virus Database is out-of-date.
Checked by AVG Anti-Virus.



From greg.snow at ihc.com  Fri Aug 12 19:37:26 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Fri, 12 Aug 2005 11:37:26 -0600
Subject: [R] HPD credible sets
Message-ID: <s2fc89ff.043@lp-msg1.co.ihc.com>

There are 2 very basic functions in the package TeachingDemos.  They
only work on univariate unimodal (single interval) situations.

There is also a function in the boa package, but I don't know anything
about that one.

Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111

>>> <pantd at unlv.nevada.edu> 08/10/05 01:10AM >>>
Hi R users
Is there a function in R that gives HPD credible sets.  i googled it
but was in
vain!

- dev

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From liusong at stat.umn.edu  Fri Aug 12 21:07:12 2005
From: liusong at stat.umn.edu (Liu Song)
Date: Fri, 12 Aug 2005 14:07:12 -0500 (CDT)
Subject: [R] as.formula and lme ( Fixed effects: Error in as.vector(x,
 "list") : cannot coerce to vector)
Message-ID: <Pine.LNX.4.61.0508121354310.5850@owasso.stat.umn.edu>

This is a continuing issue with the one on the list a long time ago (I 
couldn't find a solution to it from the web):
--------------------------------------------------------------------------
> Using a formula converted with as.formula with lme leads
> to an error message. Same works ok with lm, and with
> lme and a fixed formula.
> 
> # demonstrates problems with lme and as.formula
> demo<-data.frame(x=1:20,y=(1:20)+rnorm(20),subj=as.factor(rep(1:2,10)))
> demo.lm1<-lme(y~x,data=demo,random=~1|subj)
> print(summary(demo.lm1))
> newframe<-data.frame(x=1:5,subj=rep(1,5))
> predict(demo.lm1,newframe,level=0)
> 
> fma<-as.formula("y~x")
> demo.lm<-lm(fma,data=demo)        # ok
> predict(demo.lm,newframe,level=0) # ok
> demo.lm2<-lme(fma,data=demo,random=~1|subj) # looks ok, but isn't
> print(summary(demo.lm2))
> 
> #Fixed effects: Error in as.vector(x, "list") : cannot coerce to vector
> #predict(demo.lm2,newframe,level=0) # does not work

Thanks for the detailed report.  I can reproduce the problem.  It
appears that there needs to be an eval early in the lme function so it
stores the formula for the fixed effects, not the name of the formula.
------------------------------------------------------------------------
Now I follow the suggestion and use :
demo.lm2<-lme(eval(fma),data=demo,random=~1|subj) 
#works ok, even with summary(demo.lm2) 
#predict(demo.lm2,newframe,level=0) 
#Error in eval() : Argument "expr" is missing, with no default

How can I fix this problem and get the predict() function to work?
Thank you!

********************************************************************
Song Liu
School of Statistics
313 FordH
224 Church St. SE
Minneapolis,MN 55455



From ripley at stats.ox.ac.uk  Fri Aug 12 21:21:57 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 Aug 2005 20:21:57 +0100 (BST)
Subject: [R] coercing created variables into a new data frame using
 na.omit()
In-Reply-To: <42FCD6C3.6090607@acelerate.com>
References: <42FD2569@minerva2.ex.ac.uk>
	<Pine.LNX.4.61.0508121348430.8827@gannet.stats>
	<42FCD6C3.6090607@acelerate.com>
Message-ID: <Pine.LNX.4.61.0508122014010.13281@gannet.stats>

On Fri, 12 Aug 2005, Kjetil Brinchmann Halvorsen wrote:

> Prof Brian Ripley wrote:
>
>> I don't know if you can read your message, but I find it exceedingly 
>> difficult and there seem to be several typos.  Please use the space and 
>> return keys ... and only send a message once.
>> 
>> You problem is perhaps that you are not looking at the data frame, but at 
>> the variable in the workspace.  attach()ing data frames is convenient but 
>> error-prone (as you have found).  rm(new.variable) should solve this, but 
>> it is better to cultivate a different style.  For example
>> 
>> with(data.frame1, {
>> # commands to create value
>> data.frame1$new.variable <- value
>> })
>> data.frame3 <- na.omit(data.frame1)
>> 
>> 
> That cannot possible work,

No, it's just a sketch of a style.

> as assignment within with is local to with's environment. I have used 
> superassigmnent for this (<<-), but that cannot possible be a good 
> style?

I intended that the changed object be returned: so for example

test <- with(test, {test$c <- 1:5; test})

does work.  What I really meant to write (and had tested) could be 
sketched as

value <- with(data.frame1, {
# commands to create value
})
data.frame1$new.variable <- value
data.frame3 <- na.omit(data.frame1)

but cut-and-paste got two lines out of order.

> Look at the following:
>
>> test <- data.frame( a=1:5, b=1:5)
>> test
> a b
> 1 1 1
> 2 2 2
> 3 3 3
> 4 4 4
> 5 5 5
>> with(test, test$c <- 1:5)
>> test
> a b
> 1 1 1
> 2 2 2
> 3 3 3
> 4 4 4
> 5 5 5
>> with(test, test$c <<- 1:5)
>> test
> a b c
> 1 1 1 1
> 2 2 2 2
> 3 3 3 3
> 4 4 4 4
> 5 5 5 5
>
> So what is the best style her?
>
> Kjetil

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Aug 12 21:29:55 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 Aug 2005 20:29:55 +0100 (BST)
Subject: [R] as.formula and lme ( Fixed effects: Error in as.vector(x,
 "list") : cannot coerce to vector)
In-Reply-To: <Pine.LNX.4.61.0508121354310.5850@owasso.stat.umn.edu>
References: <Pine.LNX.4.61.0508121354310.5850@owasso.stat.umn.edu>
Message-ID: <Pine.LNX.4.61.0508122024110.13281@gannet.stats>

You can use substitute() to get the actual formula in your call.

demo.lm2 <- 
eval(substitute(lme(fma, data=demo, random=~1|subj), list(fma=fma)))

works for me in your example.

On Fri, 12 Aug 2005, Liu Song wrote:

> This is a continuing issue with the one on the list a long time ago (I
> couldn't find a solution to it from the web):
> --------------------------------------------------------------------------
>> Using a formula converted with as.formula with lme leads
>> to an error message. Same works ok with lm, and with
>> lme and a fixed formula.
>>
>> # demonstrates problems with lme and as.formula
>> demo<-data.frame(x=1:20,y=(1:20)+rnorm(20),subj=as.factor(rep(1:2,10)))
>> demo.lm1<-lme(y~x,data=demo,random=~1|subj)
>> print(summary(demo.lm1))
>> newframe<-data.frame(x=1:5,subj=rep(1,5))
>> predict(demo.lm1,newframe,level=0)
>>
>> fma<-as.formula("y~x")
>> demo.lm<-lm(fma,data=demo)        # ok
>> predict(demo.lm,newframe,level=0) # ok
>> demo.lm2<-lme(fma,data=demo,random=~1|subj) # looks ok, but isn't
>> print(summary(demo.lm2))
>>
>> #Fixed effects: Error in as.vector(x, "list") : cannot coerce to vector
>> #predict(demo.lm2,newframe,level=0) # does not work
>
> Thanks for the detailed report.  I can reproduce the problem.  It
> appears that there needs to be an eval early in the lme function so it
> stores the formula for the fixed effects, not the name of the formula.
> ------------------------------------------------------------------------
> Now I follow the suggestion and use :
> demo.lm2<-lme(eval(fma),data=demo,random=~1|subj)
> #works ok, even with summary(demo.lm2)
> #predict(demo.lm2,newframe,level=0)
> #Error in eval() : Argument "expr" is missing, with no default
>
> How can I fix this problem and get the predict() function to work?
> Thank you!
>
> ********************************************************************
> Song Liu
> School of Statistics
> 313 FordH
> 224 Church St. SE
> Minneapolis,MN 55455
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tate_sterling_avery at hotmail.com  Fri Aug 12 21:50:17 2005
From: tate_sterling_avery at hotmail.com (Tate Avery)
Date: Fri, 12 Aug 2005 15:50:17 -0400
Subject: [R] Manually Calculating Odds from POLR Model
Message-ID: <BAY103-F20AE1C5245A6F40951E570AEBC0@phx.gbl>

Hello,

I am using polr(...) to generate a model.  The summary shows the 
coefficients and the intercepts.

For example:

    coefficient for x1 = c1
    coefficient for x2 = c2

    intercept A|B = i1
    intercept B|C = i2

I can then run predict(..., type="p") with the model and see the odds for 
each factor.

For example:

      A        B        C
1    0.3     0.5      0.2
2    0.4     0.1      0.5

What I really want to be able to do is take the 2 coefficients, the 2 
intercepts, the x1 & x2 values and manually calculate the probabilities 
generated by predict().

I have been searching quite extensively for the underlying calculations that 
transform the polr output and the input variables into the final output 
odds.  I have tried a number of dead-end roads so far.

So, if anyone has any information on how to do this or where I can find out, 
I would be extremely grateful.

Thank you for your time,
Tate Avery



From sdavis2 at mail.nih.gov  Fri Aug 12 22:19:44 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 12 Aug 2005 16:19:44 -0400
Subject: [R] R-devel and bad magic number
Message-ID: <BF227CA0.C4D8%sdavis2@mail.nih.gov>

Is anyone else having issues like this (r-devel)?  The files look fine in an
editor....

> load('stuff1.R')
Error: bad restore file magic number (file may be corrupted) -- no data
loaded
> load('/Users/sdavis/Desktop/Downloads/biomaRt/R/biomaRt.R')
Error: bad restore file magic number (file may be corrupted) -- no data
loaded
> version
         _         
platform powerpc-apple-darwin7.9.0
arch     powerpc   
os       darwin7.9.0
system   powerpc, darwin7.9.0
status   Under development (unstable)
major    2         
minor    2.0       
year     2005      
month    08        
day      11        
svn rev  35256     
language R     

Thanks,
Sean



From shawp at mail.nih.gov  Fri Aug 12 22:49:55 2005
From: shawp at mail.nih.gov (Shaw, Philip (NIH/NIMH))
Date: Fri, 12 Aug 2005 16:49:55 -0400
Subject: [R] converting a t statistic to r2
Message-ID: <8DA2F8902C1FE648B7A6523320CBAFC8122232@NIHCESMLBX3.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050812/bdb712b6/attachment.pl

From helprhelp at gmail.com  Fri Aug 12 23:04:51 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Fri, 12 Aug 2005 16:04:51 -0500
Subject: [R] need help
Message-ID: <cdf817830508121404662e5cfc@mail.gmail.com>

Hi, there:
I think i need to re-phrase my question since last time I did not get
any reply but i think the question is not that hard, probably i did
not make the question clear:

I want to find cases like
35, 90, 330, 330, 335

from the rest which look like
3, 3, 3, 3.2, 3.3
4, 4.4, 4.5, 4.6, 4.7
....

basically there is one (or more) big 'gap' in the case i seek. 

thanks,

weiwei

-- 
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From gattuso at obs-vlfr.fr  Fri Aug 12 23:08:47 2005
From: gattuso at obs-vlfr.fr (Jean-Pierre Gattuso)
Date: Fri, 12 Aug 2005 15:08:47 -0600
Subject: [R] quotes
Message-ID: <74AC704F-42EA-4C98-B1A7-1A6B2510B8C1@obs-vlfr.fr>

Hi:

I have been struggling with gsub to no avail and am seeking help from  
the list.

I want to make a vector of the string "one, two, three" and have  
tried to:

     - replace each comma by ","
     - add " at the beginning of the string
     - add " at the end of the string

to issue the command:

     col.names <- c("one", "two", "three")

for use in a data frame.

I have tried gsub to get that but am unable to get the double quote  
and when I try to escape it (\"), I also get the backslash.


Thanks for your help,
jpg



From helprhelp at gmail.com  Fri Aug 12 23:09:29 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Fri, 12 Aug 2005 16:09:29 -0500
Subject: [R] multiple responses classification/regression problem
Message-ID: <cdf817830508121409523aebfe@mail.gmail.com>

Hi, there:
I am wondering if anyone knows about this? the response variable is a
vector. I knew mvpart might be able to do this. anyone would like to
share some examples?

of course, nnet can do that too, but what else?

Thanks,

you guys have a good weekend!

Weiwei
-- 
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From pgilbert at bank-banque-canada.ca  Fri Aug 12 23:20:02 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 12 Aug 2005 17:20:02 -0400
Subject: [R] signal handling
In-Reply-To: <3f87cc6d050811142082b87d6@mail.gmail.com>
References: <3f87cc6d050811142082b87d6@mail.gmail.com>
Message-ID: <42FD1282.2090307@bank-banque-canada.ca>

I'm not sure about perl's signals, but Unix signals can be passed with
     q("yes/no", status=whatever)
See ?q.  This is pretty useful for passing signal to make, for example.

Paul

Omar Lakkis wrote:

> Is ther a signal handling model in R? similar to Perl's %SIG hash.
> I want to do fast clean up in my R code before exit when a kill signal
> is issued.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From res90sx5 at verizon.net  Fri Aug 12 23:21:28 2005
From: res90sx5 at verizon.net (Daniel Nordlund)
Date: Fri, 12 Aug 2005 14:21:28 -0700
Subject: [R] need help
In-Reply-To: <cdf817830508121404662e5cfc@mail.gmail.com>
Message-ID: <0IL400DGGONXZ771@vms044.mailsrvcs.net>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch]
> On Behalf Of Weiwei Shi
> Sent: Friday, August 12, 2005 2:05 PM
> To: r-help
> Subject: [R] need help
> 
> Hi, there:
> I think i need to re-phrase my question since last time I did not get
> any reply but i think the question is not that hard, probably i did
> not make the question clear:
> 
> I want to find cases like
> 35, 90, 330, 330, 335
> 
> from the rest which look like
> 3, 3, 3, 3.2, 3.3
> 4, 4.4, 4.5, 4.6, 4.7
> ....
> 
> basically there is one (or more) big 'gap' in the case i seek.
> 
> thanks,
> 
> weiwei
> 
> --
> Weiwei Shi, Ph.D

Weiwei,

You will have to specify what you mean by a big gap before anyone can help.  And I still don't understand what your data look like.  Is

35, 90, 330, 330, 335

supposed to represent a sequence or a row of a matrix (or data frame)?

Dan Nordlund
Bothell, WA



From pgilbert at bank-banque-canada.ca  Fri Aug 12 23:27:31 2005
From: pgilbert at bank-banque-canada.ca (Paul Gilbert)
Date: Fri, 12 Aug 2005 17:27:31 -0400
Subject: [R] Dating Objects
In-Reply-To: <42FCD04D.6010404@lancaster.ac.uk>
References: <200508121556.j7CFuEwg009104@erdos.math.unb.ca>
	<42FCD04D.6010404@lancaster.ac.uk>
Message-ID: <42FD1443.3070400@bank-banque-canada.ca>



Barry Rowlingson wrote:

> Rolf Turner wrote:
> 
> 
>>	I don't follow what you aren't following ....  It seems to me
>>	to be an eminently reasonable thing to want to do.  Answers
>>	questions such as ``Was x modified since y was modified?''
> 
> 
>   I wanted to have some sort of 'make'-like functionality in R. 

Why not just use make and generate a sequence of targets that come from 
renaming the .RData file saved after each step.

Suppose
> you have some complicated analysis that depends on several variables. If 
> you change one of them, you might not want to redo all the parts of the 
> analyses that dont depend on that change. Integrating this with Sweave 
> would be another gem, since parts of your Sweave document that might 
> take a long time to run might not need to run again if you've only 
> changed something after that point. If it takes an hour to generate a 
> dataset and two seconds to plot it, and you've made a change to the 
> plot, you dont want to re-run the whole data generation again when you 
> weave your document.
> 
> 
>>	I think I would make the modification data an ***attribute***
>>	of the object, rather than sticking it in as a component.
>>	(The latter might mess up some vital aspect of the nature
>>	of the object.)
>>
>>	The problem is to remember to date stamp each object each
>>	time it is modified ....
> 
> 
>   A while ago I attacked this problem at the C-code level. I found out 
> where R made assignments and tacked on a 'modified' attribute to the 
> object at that point. However it was a quick hack and it broke R quite 
> badly. One of the problems was that R objects were no longer identical 
> to assigned versions of themselves, and lots of tests broke.
> 
>   I think to be done properly it needs to be done at a lower level.

Well, I guess what I'm suggesting is at a much higher level.

Paul
> 
> Barry
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From helprhelp at gmail.com  Fri Aug 12 23:33:40 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Fri, 12 Aug 2005 16:33:40 -0500
Subject: [R] need help
In-Reply-To: <0IL400DGGONXZ771@vms044.mailsrvcs.net>
References: <cdf817830508121404662e5cfc@mail.gmail.com>
	<0IL400DGGONXZ771@vms044.mailsrvcs.net>
Message-ID: <cdf8178305081214334812f2c6@mail.gmail.com>

Hi, there:
here is some part from my previous email:

          [,1]      [,2]       [,3]       [,4]       [,5]
[1,] 34.216166 96.928587 330.125990 330.183222 330.201215
[2,]  2.819183  8.134491   8.275841   8.525256   8.828448
[3,]  2.819183  7.541680   7.550333   8.374636   8.690998
[4,]  4.672551  5.036353   5.072710   5.152218   5.223204
[5,]  5.470131  5.500513   5.674139   5.689151   5.770423
[6,]  4.480287  4.628300   4.797686   4.814106   4.823345

I want to filter out the first 3 cases from the rest and the criteria
is I am looking for a "gap". 

My way is using std(eachrow)/median(each) and set up a threshold,
which is very naive, but fast and good enough. But I want it better
and more "academic". Please be advised. I think clustering might help,
but it needs to be quick since t2 has 30000 rows.

Thanks,


On 8/12/05, Daniel Nordlund <res90sx5 at verizon.net> wrote:
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch]
> > On Behalf Of Weiwei Shi
> > Sent: Friday, August 12, 2005 2:05 PM
> > To: r-help
> > Subject: [R] need help
> >
> > Hi, there:
> > I think i need to re-phrase my question since last time I did not get
> > any reply but i think the question is not that hard, probably i did
> > not make the question clear:
> >
> > I want to find cases like
> > 35, 90, 330, 330, 335
> >
> > from the rest which look like
> > 3, 3, 3, 3.2, 3.3
> > 4, 4.4, 4.5, 4.6, 4.7
> > ....
> >
> > basically there is one (or more) big 'gap' in the case i seek.
> >
> > thanks,
> >
> > weiwei
> >
> > --
> > Weiwei Shi, Ph.D
> 
> Weiwei,
> 
> You will have to specify what you mean by a big gap before anyone can help.  And I still don't understand what your data look like.  Is
> 
> 35, 90, 330, 330, 335
> 
> supposed to represent a sequence or a row of a matrix (or data frame)?
> 
> Dan Nordlund
> Bothell, WA
> 
> 
> 


-- 
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From liuwensui at gmail.com  Fri Aug 12 23:36:10 2005
From: liuwensui at gmail.com (Wensui Liu)
Date: Fri, 12 Aug 2005 17:36:10 -0400
Subject: [R] multiple responses classification/regression problem
In-Reply-To: <cdf817830508121409523aebfe@mail.gmail.com>
References: <cdf817830508121409523aebfe@mail.gmail.com>
Message-ID: <1115a2b00508121436224ffb09@mail.gmail.com>

polymars() in polspline pakage can do the work.

HTH.

On 8/12/05, Weiwei Shi <helprhelp at gmail.com> wrote:
> Hi, there:
> I am wondering if anyone knows about this? the response variable is a
> vector. I knew mvpart might be able to do this. anyone would like to
> share some examples?
> 
> of course, nnet can do that too, but what else?
> 
> Thanks,
> 
> you guys have a good weekend!
> 
> Weiwei
> --
> Weiwei Shi, Ph.D
> 
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
WenSui Liu
(http://statcompute.blogspot.com)
Senior Decision Support Analyst
Cincinnati Children Hospital Medical Center



From ripley at stats.ox.ac.uk  Fri Aug 12 23:39:00 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 Aug 2005 22:39:00 +0100 (BST)
Subject: [R] quotes
In-Reply-To: <74AC704F-42EA-4C98-B1A7-1A6B2510B8C1@obs-vlfr.fr>
References: <74AC704F-42EA-4C98-B1A7-1A6B2510B8C1@obs-vlfr.fr>
Message-ID: <Pine.LNX.4.61.0508122235070.3155@gannet.stats>

col.names <- strsplit("one, two, three", ", ")[[1]]

is an easy way to do this.  But you can do

paste('"', gsub(', ',  '","', "one, two, three"), '"', sep="")

R accepts either single or double quotes and it can make life easier to 
use both.

On Fri, 12 Aug 2005, Jean-Pierre Gattuso wrote:

> Hi:
>
> I have been struggling with gsub to no avail and am seeking help from
> the list.
>
> I want to make a vector of the string "one, two, three" and have
> tried to:
>
>     - replace each comma by ","
>     - add " at the beginning of the string
>     - add " at the end of the string
>
> to issue the command:
>
>     col.names <- c("one", "two", "three")
>
> for use in a data frame.
>
> I have tried gsub to get that but am unable to get the double quote
> and when I try to escape it (\"), I also get the backslash.
>
>
> Thanks for your help,
> jpg
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Sat Aug 13 01:22:23 2005
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 12 Aug 2005 19:22:23 -0400
Subject: [R] Manually Calculating Odds from POLR Model
In-Reply-To: <BAY103-F20AE1C5245A6F40951E570AEBC0@phx.gbl>
Message-ID: <20050812232223.TSDK1799.tomts40-srv.bellnexxia.net@JohnDesktop8300>

Dear Tate,

If I understand correctly what you're asking, the formulas are on p. 21 of
the paper at
<http://socserv.socsci.mcmaster.ca/jfox/Papers/logit-effect-displays.pdf>.
But why do you want to do this when you can get the fitted probabilities
from predict()?

I hope this helps.
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tate Avery
> Sent: Friday, August 12, 2005 2:50 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Manually Calculating Odds from POLR Model
> 
> Hello,
> 
> I am using polr(...) to generate a model.  The summary shows 
> the coefficients and the intercepts.
> 
> For example:
> 
>     coefficient for x1 = c1
>     coefficient for x2 = c2
> 
>     intercept A|B = i1
>     intercept B|C = i2
> 
> I can then run predict(..., type="p") with the model and see 
> the odds for each factor.
> 
> For example:
> 
>       A        B        C
> 1    0.3     0.5      0.2
> 2    0.4     0.1      0.5
> 
> What I really want to be able to do is take the 2 
> coefficients, the 2 intercepts, the x1 & x2 values and 
> manually calculate the probabilities generated by predict().
> 
> I have been searching quite extensively for the underlying 
> calculations that transform the polr output and the input 
> variables into the final output odds.  I have tried a number 
> of dead-end roads so far.
> 
> So, if anyone has any information on how to do this or where 
> I can find out, I would be extremely grateful.
> 
> Thank you for your time,
> Tate Avery
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From murdoch at stats.uwo.ca  Sat Aug 13 01:53:15 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Fri, 12 Aug 2005 19:53:15 -0400
Subject: [R] R-devel and bad magic number
In-Reply-To: <BF227CA0.C4D8%sdavis2@mail.nih.gov>
References: <BF227CA0.C4D8%sdavis2@mail.nih.gov>
Message-ID: <42FD366B.6090900@stats.uwo.ca>

Sean Davis wrote:
> Is anyone else having issues like this (r-devel)?  The files look fine in an
> editor....
> 
> 
>>load('stuff1.R')
> 
> Error: bad restore file magic number (file may be corrupted) -- no data
> loaded
> 
>>load('/Users/sdavis/Desktop/Downloads/biomaRt/R/biomaRt.R')
> 
> Error: bad restore file magic number (file may be corrupted) -- no data
> loaded

load() is for binary workspaces.  Use source() to read source code.

Duncan Murdoch



From fisher at plessthan.com  Sat Aug 13 02:11:45 2005
From: fisher at plessthan.com (Dennis Fisher)
Date: Fri, 12 Aug 2005 17:11:45 -0700
Subject: [R] R/S-Plus/SAS yield different results for Kendall-tau and
	Spearman nonparametric regression
Message-ID: <7FB06B66-58EB-4909-84F7-FE3F73B13B6A@plessthan.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050812/5edfc851/attachment.pl

From spencer.graves at pdf.com  Sat Aug 13 02:31:06 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 12 Aug 2005 17:31:06 -0700
Subject: [R] Problems with numeric variable containing ? values
In-Reply-To: <a48b4dd7.29aaeb66.8242700@expms2.cites.uiuc.edu>
References: <a48b4dd7.29aaeb66.8242700@expms2.cites.uiuc.edu>
Message-ID: <42FD3F4A.9050707@pdf.com>

	  I'm very sorry, but I do not understand your question.  If you are 
still waiting for an answer, may I suggest you PLEASE do read the 
posting guide! "http://www.R-project.org/posting-guide.html".  This may 
help you formulate your question so it will be easier for someone else 
to understand what you are asking and provide a useful reply.

	  spencer graves

ftorrei2 at uiuc.edu wrote:

> Hello,
> 
> I have a problem with the values for one column in a table.
> The variable represented in this column is numeric (I get TRUE
> when I ask is.numeric(x)). However, the values are listed
> ordinally and with row numbers as values, not with the ones
> that appear in the table. Some rows have an undefined value
> for this column, which appears as ? in the table (this is not
> an error). I wonder whether these undefined values are causing
> the problem.
> I need to extract a subset from this column with all rows not
> having '?' and then use the subset for a number if analysis.
> So far this is not possible since the subset does not have the
> real values, but the row numbers mentioned above. Any help?
> 
> Thanks in advance,
> Francisco Torreira     
> Francisco Torreira
> Spanish, Italian and Portuguese
> Univ. of Illinois at Urbana-Champaign
> 707 South Mathews Aven.
> 4031 FLB
> Urbana, IL, 61801
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From spencer.graves at pdf.com  Sat Aug 13 02:47:10 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 12 Aug 2005 17:47:10 -0700
Subject: [R] question
In-Reply-To: <42FB6B06.2080809@erasmusmc.nl>
References: <42FB6B06.2080809@erasmusmc.nl>
Message-ID: <42FD430E.5040501@pdf.com>

	  What are RGN$G and RGN$R?

	  Consider the following:

 > .Machine$double.xmax
[1] 1.797693e+308
 > log(.Machine$double.xmax, base=2)
[1] 1024
 > 2^(log(.Machine$double.xmax, base=2)-1)
[1] 8.988466e+307
 > 2^log(.Machine$double.xmax, base=2)
[1] Inf

	  If you want something different from this, PLEASE do read the
posting guide! "http://www.R-project.org/posting-guide.html".  It may
help you formulate your question to increase the chances of getting a 
more useful reply.

	  Best Wishes,
	  spencer graves

WFJ van IJcken wrote:

> Hi,
> 
> I have a problem with R, after an update:
>  this piece of code:
> cat("creating resolver data frame\n");
> dfG<-cbind(dfG,2^(RGN$G))
> dfR<-cbind(dfR,2^(RGN$R))
> 
> suddenly, creates values to inf.
> Is the syntax changed for the ^ symbol in the latest R downloadable version?
> 
> Kind regards, wilfred

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From mblanche at uclink.berkeley.edu  Sat Aug 13 02:53:50 2005
From: mblanche at uclink.berkeley.edu (Marco Blanchette)
Date: Fri, 12 Aug 2005 17:53:50 -0700
Subject: [R] Broken tkrplot on Mac OS X
In-Reply-To: <1123793945.42fbbc1935d1f@webmail.ifc.unam.mx>
Message-ID: <BF2292AE.3F5E%mblanche@uclink.berkeley.edu>

Dear all--

I have been trying to get the tkrplot package to work in order to use the
bioconductor package genArise.

I am trying to build it on a Mac running OS 10.4.1 with R 2.1.1. Following a
stanadard install from R here the error I get when I try to load tkrplot

> library(tkrplot)
 Loading required package: tcltk
 Loading Tcl/Tk interface ... done
 Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class =
 "tclObj") : 
         [tcl] no suitable image found.  Did find:
         
 /Library/Frameworks/R.framework/Versions/2.1.1/Resources/library/tkrplot/li
b
 s/tkrplot.so: not a dylib.
 Error in library(tkrplot) : .First.lib failed for 'tkrplot'

Gustavo Corral suggestion was to rebuild the tkrplot.so bundle as a library
by doing:

> It can be rather tricky to make it work. You have to download it, then
> install it with R CMD INSTALL, then you may need to edit the file Makeconf in
> the RHOME/etc directory (the command R RHOME says the path to RHOME
> directory).
> In this file you must change:
> 
> (line 41 in my case)
> SHLIB_CXXLDFLAGS = -bundle -flat_namespace -undefined suppress
> replaced by:
> SHLIB_CXXLDFLAGS = -dynamiclib -flat_namespace -undefined suppress
> 
> (line 45 ...)
> SHLIB_LDFLAGS = -bundle -flat_namespace -undefined suppress
> replaced by:
> SHLIB_LDFLAGS = -dynamiclib -flat_namespace -undefined suppress
> 
> then move to the src directory in the tkrplot you just download and link
> tkrplot
> with the statement: R CMD SHLIB -o tkrplot.so. Then move tkrplot.so by hand to
> 
> the libs directory of the tkrplot installation (RHOME/library/tkrplot/libs).

That what I did. Now I am having a different error when I try to load
tkrplot...

> library(tkrplot)
Loading required package: tcltk
Loading Tcl/Tk interface ... done
Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class =
"tclObj") : 
        [tcl] couldn't find procedure Rplot_Init.
Error in library(tkrplot) : .First.lib failed for 'tkrplot'

Any clue as how to fix tkrplot?

Why is this package so difficult to install???

Anyway, I would appreciate any help/suggestions.

Many tx

Marco

Marco Blanchette, Ph.D.

mblanche at uclink.berkeley.edu

Donald C. Rio's lab
Department of Molecular and Cell Biology
16 Barker Hall
University of California
Berkeley, CA 94720-3204

Tel: (510) 642-1084
Cell: (510) 847-0996
Fax: (510) 642-6062



From rab45+ at pitt.edu  Sat Aug 13 05:00:23 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Fri, 12 Aug 2005 23:00:23 -0400 (EDT)
Subject: [R] g77 and R
In-Reply-To: <42FD43FA.1080105@verizon.net>
References: <37348.209.195.160.60.1123889812.squirrel@webmail.pitt.edu>
	<42FD43FA.1080105@verizon.net>
Message-ID: <49796.209.195.160.60.1123902023.squirrel@webmail.pitt.edu>

> rab45+ at pitt.edu wrote:
>> Jerry,
>>
>> Here are the two R packages.
>>
>> Thanks.
>>
>> Rick
> All the fortran codes compile OK so the problem is invoking the compiler
> you
> want.  One approach which is a work around is to rename the gfortran
> executable
> to somthing else like gfortran-save and create a link called gfortran that
> points to g77.  That might work, but its a hack.
>
>  From looking at these it appears that they are intended to be built from
> the R
> environment.  Unfortunately I am not an R user and I am not familiar with
> it.
>
> What is the usual build process you go through?
>
> Jerry
>

Installing R packages (sets of statistical analysis functions for specific
types of problems) is usually very simple. If the R package is in a
repository, then something like:

> install.packages(c("foreign","chron"))

will automatically find, download, compile c and fortran code (if
necessary), and put the package functions from the foreign and chron
packages into the library. It's usually painless and simple - all the
details automatically handled. Since gfortran was installed, a number of
packages have failed to compile properly and weren't installed. I have
never had a problem installing R packages until very recently - I suspect
when gfortran was foisted on us unawares.

Before FC changed to gfortran, g77 was always used. All I want to do is to
make sure that if fortran code needs to be compiled, g77 will be used. I
don't think R knows anything about gfortran or g77 - it just uses what is
available on a given system - so this is something I need to change on FC4
- not R.

Rick



From jsorkin at grecc.umaryland.edu  Sat Aug 13 05:19:24 2005
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 12 Aug 2005 23:19:24 -0400
Subject: [R] boot error: Error in statistic(data, original,
	...) : unused	argument(s) ( ...)
Message-ID: <s2fd2e99.012@grecc.umaryland.edu>

I am having difficulty setting up a boot strap.
My code is listed below. I am getting the following
error message:
Error in statistic(data, original, ...) : unused argument(s) ( ...)

I neither understand the error I have made that leads to 
the error message, nor do I know how to fix my error.
Any help would be appreciated.
Thank you,
John

R2.1.1 patched
Win 2k.

> AdjForBase2<-
+ function (data) 
+ {
+ cat("******************\n")
+ 
+ x1<-data[,1]
+ x2<-x1+rnorm(100,0,2)
+ xdiff<-x2-x1
+ corx1x2minx1<-cor(x1,xdiff)
+ 
+ y1<-data[,2]
+ y2<-y1+rnorm(100,10,2)
+ ydiff<-y2-y1
+ cory1y2miny1<-cor(y1,ydiff)
+ 
+ return(c(mean(x1),mean(x2),corx1x2minx1,
+          mean(y1),mean(y2),cory1y2miny1))
+ }
>  boot(data=mommy,statistic=AdjForBase2,R=10)
Error in statistic(data, original, ...) : unused argument(s) ( ...)

John Sorkin M.D., Ph.D.
Chief, Biostatistics and Informatics
Baltimore VA Medical Center GRECC and
University of Maryland School of Medicine Claude Pepper OAIC

University of Maryland School of Medicine
Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524

410-605-7119 
- NOTE NEW EMAIL ADDRESS:
jsorkin at grecc.umaryland.edu



From jsorkin at grecc.umaryland.edu  Sat Aug 13 05:38:48 2005
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 12 Aug 2005 23:38:48 -0400
Subject: [R] boot error: Error in statistic(data, original,
	...) : unused	argument(s) ( ...)
Message-ID: <s2fd332f.016@grecc.umaryland.edu>

I have added on additional line to the code below, the line the
defines the matrix passed to AdjForBase2.

I am having difficulty setting up a boot strap.
My code is listed below. I am getting the following
error message:
Error in statistic(data, original, ...) : unused argument(s) ( ...)
I neither understand the error I have made that leads to 
the error message, nor do I know how to fix my error.
Any help would be appreciated.
Thank you,
John


> AdjForBase2<-
+ function (data) 
+ {
+ cat("******************\n")
+ #print(length(x))
+ 
+ x1<-data[,1]
+ x2<-x1+rnorm(100,0,2)
+ xdiff<-x2-x1
+ corx1x2minx1<-cor(x1,xdiff)
+ 
+ y1<-data[,2]
+ y2<-y1+rnorm(100,10,2)
+ ydiff<-y2-y1
+ cory1y2miny1<-cor(y1,ydiff)
+ 
+ return(c(mean(x1),mean(x2),corx1x2minx1,
+          mean(y1),mean(y2),cory1y2miny1))
+ }
> mommy<-as.matrix(cbind(runif(100,0,100),runif(100,5,100)))
>  boot(data=mommy,statistic=AdjForBase2,R=10)
Error in statistic(data, original, ...) : unused argument(s) ( ...)



From rab45+ at pitt.edu  Sat Aug 13 06:03:35 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Sat, 13 Aug 2005 00:03:35 -0400 (EDT)
Subject: [R] g77 and R
In-Reply-To: <42FD43FA.1080105@verizon.net>
References: <37348.209.195.160.60.1123889812.squirrel@webmail.pitt.edu>
	<42FD43FA.1080105@verizon.net>
Message-ID: <42150.209.195.160.60.1123905815.squirrel@webmail.pitt.edu>

> rab45+ at pitt.edu wrote:
>> Jerry,
>>
>> Here are the two R packages.
>>
>> Thanks.
>>
>> Rick
> All the fortran codes compile OK so the problem is invoking the compiler
> you
> want.  One approach which is a work around is to rename the gfortran
> executable
> to somthing else like gfortran-save and create a link called gfortran that
> points to g77.  That might work, but its a hack.
>
>  From looking at these it appears that they are intended to be built from
> the R
> environment.  Unfortunately I am not an R user and I am not familiar with
> it.
>
> What is the usual build process you go through?
>
> Jerry
>

I was able to install rmutil by using g77. During installation, R prints
out the gfortran command with parameters. I ran this part separately using
g77 in place of gfortran. I could have used a link to g77 (if I removed
gfortran) but when I did this, there was a problem with the
"mtune=pentium4" argument so I removed this argument. Then the various
fortran programs compiled. I then use R to install the package and
(miracuously) R installed the package. (It seems R skipped trying to
compile the fortan code once the executables were already created and
available - so R was able to put the created functions into the library
tree so they could be used in an R session.)

This is all very kludgy - I would prefer to go back to a few days ago
without gfortran and R packages installed without any problems.

Rick B.



From ripley at stats.ox.ac.uk  Sat Aug 13 07:13:30 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 13 Aug 2005 06:13:30 +0100 (BST)
Subject: [R] boot error: Error in statistic(data, original,
 ...) : unused argument(s) ( ...)
In-Reply-To: <s2fd332f.016@grecc.umaryland.edu>
References: <s2fd332f.016@grecc.umaryland.edu>
Message-ID: <Pine.LNX.4.61.0508130601040.7951@gannet.stats>

Please look at the examples and the book which package boot supports (see 
its DESCRIPTION file).  From ?boot

statistic: A function which when applied to data returns a vector
           containing the statistic(s) of interest.  When
           'sim="parametric"', the first argument to 'statistic' must be
           the data.  For each replicate a simulated dataset returned by
           'ran.gen' will be passed.  In all other cases 'statistic'
           must take at least two arguments.
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
and yours only takes one argument, hence the error message.

I suspect you want

AdjForBase2 <- function (data, inds)

and to refer to data[inds, 1] and data[inds, 2], but since your code is 
completely devoid of spaces and indentation, I have paid it little 
attention.


On Fri, 12 Aug 2005, John Sorkin wrote:

> I have added on additional line to the code below, the line the
> defines the matrix passed to AdjForBase2.
>
> I am having difficulty setting up a boot strap.
> My code is listed below. I am getting the following
> error message:
> Error in statistic(data, original, ...) : unused argument(s) ( ...)
> I neither understand the error I have made that leads to
> the error message, nor do I know how to fix my error.
> Any help would be appreciated.
> Thank you,
> John
>
>
>> AdjForBase2<-
> + function (data)
> + {
> + cat("******************\n")
> + #print(length(x))
> +
> + x1<-data[,1]
> + x2<-x1+rnorm(100,0,2)
> + xdiff<-x2-x1
> + corx1x2minx1<-cor(x1,xdiff)
> +
> + y1<-data[,2]
> + y2<-y1+rnorm(100,10,2)
> + ydiff<-y2-y1
> + cory1y2miny1<-cor(y1,ydiff)
> +
> + return(c(mean(x1),mean(x2),corx1x2minx1,
> +          mean(y1),mean(y2),cory1y2miny1))
> + }
>> mommy<-as.matrix(cbind(runif(100,0,100),runif(100,5,100)))
>>  boot(data=mommy,statistic=AdjForBase2,R=10)
> Error in statistic(data, original, ...) : unused argument(s) ( ...)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From roebuck at odin.mdacc.tmc.edu  Sat Aug 13 08:19:52 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Sat, 13 Aug 2005 01:19:52 -0500 (CDT)
Subject: [R] signal handling
In-Reply-To: <42FD1282.2090307@bank-banque-canada.ca>
References: <3f87cc6d050811142082b87d6@mail.gmail.com>
	<42FD1282.2090307@bank-banque-canada.ca>
Message-ID: <Pine.OSF.4.58.0508130117230.322846@odin.mdacc.tmc.edu>

On Fri, 12 Aug 2005, Paul Gilbert wrote:

> Omar Lakkis wrote:
>
> > Is ther a signal handling model in R? similar to Perl's
> > %SIG hash. I want to do fast clean up in my R code before
> > exit when a kill signal is issued.
>
> I'm not sure about perl's signals, but Unix signals can be
> passed with
>      q("yes/no", status=whatever)
> See ?q.  This is pretty useful for passing signal to make,
> for example.

That's a return code though, not a signal.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From tpapp at Princeton.EDU  Sat Aug 13 10:03:14 2005
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Sat, 13 Aug 2005 10:03:14 +0200
Subject: [R] retrieving large columns using RODBC
Message-ID: <20050813080313.GA7404@tpapp.student.princeton.edu>

Hi,

I have a large table in Postgresql (result of an MCMC simulation, with 1
million rows) and I would like to retrive colums (correspond to variables)
using RODBC.  I have a column called "index" which is used to order rows.

Unfortunately, sqlQuery can't return all the values from a column at once
(RODBC complains about lack of memory).  So I am using the following code:

getcolumns <- function(channel, tablename, colnames, totalrows,
                      ordered=TRUE,chunksize=1e5) {
  r <- matrix(double(0),totalrows,length(colnames))
  for (i in 1:ceiling(totalrows/chunksize)) {
    cat(".")
    r[((i-1)*chunksize+1):(i*chunksize)] <- as.matrix(
      sqlQuery(channel, paste("SELECT", paste(colnames,collapse=", "),
                              "FROM", tablename,
                              "WHERE index <=", i*chunksize,
                              "AND index >", (i-1)*chunksize,
                              if (ordered) "ORDER BY index;" else ";")))
  }
  cat("\n")
  drop(r)                               # convert to vector if needed
}

to retrieve it in chunks.  However, this is very slow -- takes about 15
minutes on my machine.  Is there a way to speed it up?

I am running Linux on a powerbook, RODBC version 1.1-4, R 2.1.1.  The
machine has only 512 Mb of RAM.

Thanks,

Tamas



From ripley at stats.ox.ac.uk  Sat Aug 13 11:07:53 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 13 Aug 2005 10:07:53 +0100 (BST)
Subject: [R] Help converting a function from S-Plus to R: family$weight
In-Reply-To: <42FC2211.5040702@usq.edu.au>
References: <42FC2211.5040702@usq.edu.au>
Message-ID: <Pine.LNX.4.61.0508130955490.18254@gannet.stats>

I think a question about the S family() functions is best determined by 
reading the S(-PLUS) documentation.  The weights component computes the 
working weights for the IWLS, unsurprisingly (and as stated by 
?family.object).  R has mu.eta to do that, the crucial line in R's glm.fit 
being

    w <- sqrt((weights[good] * mu.eta.val[good]^2)/variance(mu)[good])


But you don't need to port S-only features to R.  You do need to worry 
about R-only features.

On Fri, 12 Aug 2005, Peter Dunn wrote:

> Hi all
>
> I am converting an S-Plus function into R.  The S-Plus code
> uses some of the glm families, and  family  objects.
>
> The family objects in S-Plus and R have many different
> features, for example:
>
> In R:
> > names(Gamma())
>  [1] "family"     "link"       "linkfun"    "linkinv"    "variance"
>  [6] "dev.resids" "aic"        "mu.eta"     "initialize" "validmu"
> [11] "valideta"
>
> In S-Plus:
> > names(Gamma())
> [1] "family"     "names"      "link"       "inverse"    "deriv"
> [6] "initialize" "variance"   "deviance"   "weight"
> >
>
>
> My question concerns the variable  weight  in the S-Plus function.
> I'm not sure what it is.  (I have searched the S-Plus mailing list
> archive, and my "S-Plus for linux 6.1" documentation.)  For almost all
> family objects, the weight variable is the same as variance,
> just weighted (and the former as a function; the later as an
> expression):
>
> > Gamma()$variance
> function(mu)
> mu^2
> > Gamma()$weight
> expression(w * mu^2.)
> >
>
> The same applies for most families.  So I thought I could determine
> what this weight variable was.
>
> But alas--not the inverse,gaussian:
>
> > inverse.gaussian()$variance
> function(mu)
> mu^3
> > inverse.gaussian()$weight
> expression(w/((sqrt(family$variance(mu)) * family$deriv(mu))^2.))
>
>
> So:
> - can anyone tell me what this expression weight represents?
> - why is the inverse.gaussian family different than all others?
>
> Thanks in advance.
>
> P.
>
> My S-Plus version:
>
> > version
> Version 6.2.1  for Linux 2.4.18 : 2003
>
> My R version:
>
> > version
>          _
> platform i386-pc-linux-gnu
> arch     i386
> os       linux-gnu
> system   i386, linux-gnu
> status
> major    2
> minor    1.0
> year     2005
> month    04
> day      18
> language R
> >
>
>
> -- 
> Dr Peter Dunn  |  Senior Lecturer in Statistics
> Faculty of Sciences, University of Southern Queensland
>   Web:    http://www.sci.usq.edu.au/staff/dunn
>   Email:  dunn <at> usq.edu.au
> CRICOS:  QLD 00244B |  NSW 02225M |  VIC 02387D |  WA 02521C
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Jan.Verbesselt at biw.kuleuven.be  Sat Aug 13 11:09:38 2005
From: Jan.Verbesselt at biw.kuleuven.be (Jan Verbesselt)
Date: Sat, 13 Aug 2005 11:09:38 +0200
Subject: [R] Penalized likelihood-ratio chi-squared statistic: L.R. model
	for Goodness of fit?
Message-ID: <002401c59fe6$bba4c780$1145210a@agr.ad10.intern.kuleuven.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050813/da86cc43/attachment.pl

From ales.ziberna at guest.arnes.si  Sat Aug 13 12:09:01 2005
From: ales.ziberna at guest.arnes.si (=?iso-8859-2?Q?Ale=B9_=AEiberna?=)
Date: Sat, 13 Aug 2005 12:09:01 +0200
Subject: [R] Including Fortran subrutines in a package
Message-ID: <00d201c59fef$089638f0$0200a8c0@TAMARA>

Hello!

I am creating a packege and I would like to inclued some Fortrun subrutines. 
I have two questions.
1. Can I use "free form fortan" - compiles well usinf g77 -ffree-form.
2. Is it enough to place the ".for" files in scr folder?

Thank you in advance for any help!
Ales Ziberna

P.S.: I am runing R 2.1.1 on Win XP, SP2. I installed rtools, mingw, perl as 
suggested in the manuals. Here are some detailsabour R:
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    1.1
year     2005
month    06
day      20
language R



From ales.ziberna at guest.arnes.si  Sat Aug 13 12:09:06 2005
From: ales.ziberna at guest.arnes.si (=?iso-8859-2?Q?Ale=B9_=AEiberna?=)
Date: Sat, 13 Aug 2005 12:09:06 +0200
Subject: [R] Problems runing R CMD check
Message-ID: <00d301c59fef$0a5b4180$0200a8c0@TAMARA>

Hello!

I have a problem checking the package. Firstly, I do not know how to specify 
the package to check. I tied specify it by supplying the path and by runing 
the R CMD check in the directory of the package.

In addition to that, I get an error bellow. Any suggestions on how to set 
TMPDIR would be greatly appriciated!

C:\Ales\Statistika\Blocno modeliranje\dr\blockmodeling>R CMD check
* checking for working latex ...Error: environment variable TMPDIR not set 
(or s
et to unusable value) and no default available.
 at D:\PROGRA~1\R\rw2011\share\perl/R/Utils.pm line 72

Thank you in advance for any help!
Ales Ziberna

P.S.: I am runing R 2.1.1 on Win XP, SP2. I installed rtools, mingw, perl as 
suggested in the manuals.Here are some details about R:
platform i386-pc-mingw32
arch     i386
os       mingw32
system   i386, mingw32
status
major    2
minor    1.1
year     2005
month    06
day      20
language R



From sean.oriordain at gmail.com  Sat Aug 13 12:26:02 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Sat, 13 Aug 2005 10:26:02 +0000
Subject: [R] Problems runing R CMD check
In-Reply-To: <00d301c59fef$0a5b4180$0200a8c0@TAMARA>
References: <00d301c59fef$0a5b4180$0200a8c0@TAMARA>
Message-ID: <8ed68eed05081303265b845e95@mail.gmail.com>

hi!

start - control panel - system - advanced - environmental variables

probably better to be working in a directory with no spaces in the path...

s/

On 13/08/05, Ale? ?iberna <ales.ziberna at guest.arnes.si> wrote:
> Hello!
> 
> I have a problem checking the package. Firstly, I do not know how to specify
> the package to check. I tied specify it by supplying the path and by runing
> the R CMD check in the directory of the package.
> 
> In addition to that, I get an error bellow. Any suggestions on how to set
> TMPDIR would be greatly appriciated!
> 
> C:\Ales\Statistika\Blocno modeliranje\dr\blockmodeling>R CMD check
> * checking for working latex ...Error: environment variable TMPDIR not set
> (or s
> et to unusable value) and no default available.
>  at D:\PROGRA~1\R\rw2011\share\perl/R/Utils.pm line 72
> 
> Thank you in advance for any help!
> Ales Ziberna
> 
> P.S.: I am runing R 2.1.1 on Win XP, SP2. I installed rtools, mingw, perl as
> suggested in the manuals.Here are some details about R:
> platform i386-pc-mingw32
> arch     i386
> os       mingw32
> system   i386, mingw32
> status
> major    2
> minor    1.1
> year     2005
> month    06
> day      20
> language R
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From GVG at Stowers-Institute.org  Sat Aug 13 12:34:11 2005
From: GVG at Stowers-Institute.org (Glazko, Galina)
Date: Sat, 13 Aug 2005 05:34:11 -0500
Subject: [R] simulate the data set having the same  covariance matrix
Message-ID: <200508131034.j7DAYERh021056@hypatia.math.ethz.ch>


Dear list,

I have the set of multidimensional vectors X1,.,Xn and I need to simulate the data set having the same  covariance matrix, as for X1,.., Xn.

Do someone know how it can be done in R?
I appreciate your help.

Best regards
Galina



From bitwrit at ozemail.com.au  Sat Aug 13 23:28:29 2005
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Sat, 13 Aug 2005 21:28:29 +0000
Subject: [R] need help
In-Reply-To: <cdf817830508121404662e5cfc@mail.gmail.com>
References: <cdf817830508121404662e5cfc@mail.gmail.com>
Message-ID: <42FE65FD.5050802@ozemail.com.au>

Weiwei Shi wrote:
> Hi, there:
> I think i need to re-phrase my question since last time I did not get
> any reply but i think the question is not that hard, probably i did
> not make the question clear:
> 
> I want to find cases like
> 35, 90, 330, 330, 335
> 
> from the rest which look like
> 3, 3, 3, 3.2, 3.3
> 4, 4.4, 4.5, 4.6, 4.7
> ....
> 
> basically there is one (or more) big 'gap' in the case i seek. 
> 
Hi Weiwei,

I think your method of defining a central value for the large proportion 
of values and then setting a criterion for outliers is valid (or at 
least as valid as many other ways of defining outliers). However, here 
is a different method, sorting the vector of values and then looking for 
a "gap" with a specified multiple (gap.prop) of the mean differences 
between the smaller values. It returns the first value after the "gap" 
(easily changed to all the values after). To account for vectors that 
have negative values the minimum value is subtracted when calculating 
"newx" and then added to the result. For your data, a gap.prop of 20 
works, but the default value of 10 doesn't. It also won't work where 
large values are typical and small ones are the outliers (well, it will 
indicate where the "gap" is).

Jim
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: find.first.gap.R
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050813/99cdabfe/find.first.gap.pl

From ripley at stats.ox.ac.uk  Sat Aug 13 13:56:20 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 13 Aug 2005 12:56:20 +0100 (BST)
Subject: [R] Problems runing R CMD check
In-Reply-To: <00d301c59fef$0a5b4180$0200a8c0@TAMARA>
References: <00d301c59fef$0a5b4180$0200a8c0@TAMARA>
Message-ID: <Pine.LNX.4.61.0508131246120.25275@gannet.stats>

Please do read the manuals before posting, as we ask in the posting guide.

On Sat, 13 Aug 2005, [iso-8859-2] Alea }iberna wrote:

> I have a problem checking the package. Firstly, I do not know how to specify
> the package to check. I tied specify it by supplying the path and by runing
> the R CMD check in the directory of the package.

Both work.

> In addition to that, I get an error bellow. Any suggestions on how to set
> TMPDIR would be greatly appriciated!

This is answered in the R-admin manual, even giving an example!

Note also the comments in the R-exts manual about paths with spaces in.

> C:\Ales\Statistika\Blocno modeliranje\dr\blockmodeling>R CMD check
> * checking for working latex ...Error: environment variable TMPDIR not set
> (or s
> et to unusable value) and no default available.
> at D:\PROGRA~1\R\rw2011\share\perl/R/Utils.pm line 72


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Aug 13 13:57:56 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 13 Aug 2005 12:57:56 +0100 (BST)
Subject: [R] simulate the data set having the same  covariance matrix
In-Reply-To: <200508131034.j7DAYERh021056@hypatia.math.ethz.ch>
References: <200508131034.j7DAYERh021056@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.61.0508131256390.25275@gannet.stats>

library(MASS)
?mvrnorm
Note the 'empirical' argument.

On Sat, 13 Aug 2005, Glazko, Galina wrote:

> I have the set of multidimensional vectors X1,.,Xn and I need to 
> simulate the data set having the same covariance matrix, as for X1,.., 
> Xn.
>
> Do someone know how it can be done in R?
> I appreciate your help.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ila at mayin.org  Sat Aug 13 14:31:23 2005
From: ila at mayin.org (Ila Patnaik)
Date: Sat, 13 Aug 2005 18:01:23 +0530
Subject: [R] How to make a lagged variable in panel data?
Message-ID: <20050813123123.GX394@bindi.local>

Suppose we observe N individuals, for each of which we have a
time-series. How do we correctly create a lagged value of the
time-series variable?

As an example, suppose I create:

  A <- data.frame(year=rep(c(1980:1984),3),
                  person= factor(sort(rep(1:3,5))),
                  wage=c(rnorm(15)))

  > A
     year person        wage
  1  1980      1  0.17923212
  2  1981      1  0.25610292
  3  1982      1  0.50833655
  4  1983      1 -0.42448395
  5  1984      1  0.49233532
  6  1980      2 -0.49928025
  7  1981      2  0.06842660
  8  1982      2  0.65677575
  9  1983      2  0.15947390
  10 1984      2 -0.46585116
  11 1980      3 -0.29052635
  12 1981      3 -0.27109203
  13 1982      3 -0.76168164
  14 1983      3  0.02294361
  15 1984      3  2.22828032

What I'd like to do is to make a lagged wage for each person, i.e., I
should get an additional variable A$wage.lag1:

  > A
     year person        wage       wage.lag1
  1  1980      1  0.17923212             NA
  2  1981      1  0.25610292     0.17923212
  3  1982      1  0.50833655     0.25610292
  4  1983      1 -0.42448395     0.50833655
  5  1984      1  0.49233532    -0.42448395
  6  1980      2 -0.49928025             NA
  7  1981      2  0.06842660    -0.49928025
  8  1982      2  0.65677575     0.06842660
  9  1983      2  0.15947390     0.65677575
  10 1984      2 -0.46585116     0.15947390
  11 1980      3 -0.29052635             NA
  12 1981      3 -0.27109203    -0.29052635
  13 1982      3 -0.76168164    -0.27109203
  14 1983      3  0.02294361    -0.76168164
  15 1984      3  2.22828032     0.02294361

I could think of writing code which does this "by hand", but it struck
me as a fundamental requirement when dealing with panel data, so
perhaps there is high level support for such a task?

I have been trying to learn groupedData objects and the tools that go
with them, but I didn't get a hint about how I would address such a
task.

                -Ila



From attenka at utu.fi  Sat Aug 13 15:45:24 2005
From: attenka at utu.fi (Atte Tenkanen)
Date: Sat, 13 Aug 2005 16:45:24 +0300 (EEST)
Subject: [R] How to change the names in tone pitch column
Message-ID: <34163.130.232.15.71.1123940724.squirrel@webmail2.utu.fi>

Hi,

I have a column (V4) in a midi event list which includes tone pitch names,
i.e. "A4, E4, C#4, A3...":

> compo[1:10,]
   V1 V2 V3  V4 V5 V6  V7
1   1  1  0  A4 96  2   0
2   1  1  0  E4 96  2   0
3   1  1  0 C#4 96  2   0
4   1  1  0  A3 96  2   0
5   1  3  0  B4 96  1   0
6   1  3  0  E4 96  1   0
7   1  3  0  B3 96  1   0
8   1  3  0 G#3 96  1   0
9   1  4  0 C#5 96  1   0
10  1  4  0  D4 96  0 512

Now I'd like to change them to "pitch classes" (column "pc" here, which
has the values between 0-11, using modulo 12) and absolute midi numbers
(column pcAb, values 0->107), so as results A4 gives 9 and 57 (and for
example C0 gives 0 and O, C2-> 0 and 24 etc):

> compo[1:10,]
   V1 V2 V3  V4 V5 V6  V7 pc pcAb
1   1  1  0  A4 96  2   0  9   57
2   1  1  0  E4 96  2   0  4   52
3   1  1  0 C#4 96  2   0  1   49
4   1  1  0  A3 96  2   0  9   45
5   1  3  0  B4 96  1   0 11   59
6   1  3  0  E4 96  1   0  4   52
7   1  3  0  B3 96  1   0 11   47
8   1  3  0 G#3 96  1   0  8   44
9   1  4  0 C#5 96  1   0  1   61
10  1  4  0  D4 96  0 512  2   50

I have done it this way (see next under this comment), but there must be
some shorter way, using for-loop and paste-command with sep="" or some
other way?:

##*************************************************************************#
## Create pitch class vector (add column pc to compo file) from column V4:
##*************************************************************************#

pc=c();
pc[V4=="C0"|V4=="C1"|V4=="C2"|V4=="C3"|V4=="C4"|V4=="C5"|V4=="C6"|V4=="C7"|V4=="C8"]=0;
pc[V4=="C#0"|V4=="C#1"|V4=="C#2"|V4=="C#3"|V4=="C#4"|V4=="C#5"|V4=="C#6"|V4=="C#7"|V4=="C#8"]=1;
pc[V4=="D0"|V4=="D1"|V4=="D2"|V4=="D3"|V4=="D4"|V4=="D5"|V4=="D6"|V4=="D7"|V4=="D8"]=2;
pc[V4=="D#0"|V4=="D#1"|V4=="D#2"|V4=="D#3"|V4=="D#4"|V4=="D#5"|V4=="D#6"|V4=="D#7"|V4=="D#8"]=3;
pc[V4=="E0"|V4=="E1"|V4=="E2"|V4=="E3"|V4=="E4"|V4=="E5"|V4=="E6"|V4=="E7"|V4=="E8"]=4;
pc[V4=="F0"|V4=="F1"|V4=="F2"|V4=="F3"|V4=="F4"|V4=="F5"|V4=="F6"|V4=="F7"|V4=="F8"]=5;
pc[V4=="F#0"|V4=="F#1"|V4=="F#2"|V4=="F#3"|V4=="F#4"|V4=="F#5"|V4=="F#6"|V4=="F#7"|V4=="F#8"]=6;
pc[V4=="G0"|V4=="G1"|V4=="G2"|V4=="G3"|V4=="G4"|V4=="G5"|V4=="G6"|V4=="G7"|V4=="G8"]=7;
pc[V4=="G#0"|V4=="G#1"|V4=="G#2"|V4=="G#3"|V4=="G#4"|V4=="G#5"|V4=="G#6"|V4=="G#7"|V4=="G#8"]=8;
pc[V4=="A0"|V4=="A1"|V4=="A2"|V4=="A3"|V4=="A4"|V4=="A5"|V4=="A6"|V4=="A7"|V4=="A8"]=9;
pc[V4=="A#0"|V4=="A#1"|V4=="A#2"|V4=="A#3"|V4=="A#4"|V4=="A#5"|V4=="A#6"|V4=="A#7"|V4=="A#8"]=10;
pc[V4=="B0"|V4=="B1"|V4=="B2"|V4=="B3"|V4=="B4"|V4=="B5"|V4=="B6"|V4=="B7"|V4=="B8"]=11;

## ... and absolute pitches (0-107):

pcAb=c();
pcAb[V4=="C0"]=0;pcAb[V4=="C#0"]=1;pcAb[V4=="D0"]=2;pcAb[V4=="D#0"]=3;pcAb[V4=="E0"]=4;pcAb[V4=="F0"]=5;pcAb[V4=="F#0"]=6;pcAb[V4=="G0"]=7;pcAb[V4=="G#0"]=8;pcAb[V4=="A0"]=9;pcAb[V4=="A#0"]=10;pcAb[V4=="B0"]=11;
pcAb[V4=="C1"]=12;pcAb[V4=="C#1"]=13;pcAb[V4=="D1"]=14;pcAb[V4=="D#1"]=15;pcAb[V4=="E1"]=16;pcAb[V4=="F1"]=17;pcAb[V4=="F#1"]=18;pcAb[V4=="G1"]=19;pcAb[V4=="G#1"]=20;pcAb[V4=="A1"]=21;pcAb[V4=="A#1"]=22;pcAb[V4=="B1"]=23;
pcAb[V4=="C2"]=24;pcAb[V4=="C#2"]=25;pcAb[V4=="D2"]=26;pcAb[V4=="D#2"]=27;pcAb[V4=="E2"]=28;pcAb[V4=="F2"]=29;pcAb[V4=="F#2"]=30;pcAb[V4=="G2"]=31;pcAb[V4=="G#2"]=32;pcAb[V4=="A2"]=33;pcAb[V4=="A#2"]=34;pcAb[V4=="B2"]=35;
pcAb[V4=="C3"]=36;pcAb[V4=="C#3"]=37;pcAb[V4=="D3"]=38;pcAb[V4=="D#3"]=39;pcAb[V4=="E3"]=40;pcAb[V4=="F3"]=41;pcAb[V4=="F#3"]=42;pcAb[V4=="G3"]=43;pcAb[V4=="G#3"]=44;pcAb[V4=="A3"]=45;pcAb[V4=="A#3"]=46;pcAb[V4=="B3"]=47;
pcAb[V4=="C4"]=48;pcAb[V4=="C#4"]=49;pcAb[V4=="D4"]=50;pcAb[V4=="D#4"]=51;pcAb[V4=="E4"]=52;pcAb[V4=="F4"]=53;pcAb[V4=="F#4"]=54;pcAb[V4=="G4"]=55;pcAb[V4=="G#4"]=56;pcAb[V4=="A4"]=57;pcAb[V4=="A#4"]=58;pcAb[V4=="B4"]=59;
pcAb[V4=="C5"]=60;pcAb[V4=="C#5"]=61;pcAb[V4=="D5"]=62;pcAb[V4=="D#5"]=63;pcAb[V4=="E5"]=64;pcAb[V4=="F5"]=65;pcAb[V4=="F#5"]=66;pcAb[V4=="G5"]=67;pcAb[V4=="G#5"]=68;pcAb[V4=="A5"]=69;pcAb[V4=="A#5"]=70;pcAb[V4=="B5"]=71;
pcAb[V4=="C6"]=72;pcAb[V4=="C#6"]=73;pcAb[V4=="D6"]=74;pcAb[V4=="D#6"]=75;pcAb[V4=="E6"]=76;pcAb[V4=="F6"]=77;pcAb[V4=="F#6"]=78;pcAb[V4=="G6"]=79;pcAb[V4=="G#6"]=80;pcAb[V4=="A6"]=81;pcAb[V4=="A#6"]=82;pcAb[V4=="B6"]=83;
pcAb[V4=="C7"]=84;pcAb[V4=="C#7"]=85;pcAb[V4=="D7"]=86;pcAb[V4=="D#7"]=87;pcAb[V4=="E7"]=88;pcAb[V4=="F7"]=89;pcAb[V4=="F#7"]=90;pcAb[V4=="G7"]=91;pcAb[V4=="G#7"]=92;pcAb[V4=="A7"]=93;pcAb[V4=="A#7"]=94;pcAb[V4=="B7"]=95;
pcAb[V4=="C8"]=96;pcAb[V4=="C#8"]=97;pcAb[V4=="D8"]=98;pcAb[V4=="D#8"]=99;pcAb[V4=="E8"]=100;pcAb[V4=="F8"]=101;pcAb[V4=="F#8"]=102;pcAb[V4=="G8"]=103;pcAb[V4=="G#8"]=104;pcAb[V4=="A8"]=105;pcAb[V4=="A#8"]=106;pcAb[V4=="B8"]=107;

#*****************************************************************************

## Bind vectors pc and pcAb to original composition array:
compo=cbind(compo,pc,pcAb);

-Atte



From f.harrell at vanderbilt.edu  Sat Aug 13 15:57:10 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 13 Aug 2005 08:57:10 -0500
Subject: [R] Penalized likelihood-ratio chi-squared statistic: L.R.
 model for Goodness of fit?
In-Reply-To: <002401c59fe6$bba4c780$1145210a@agr.ad10.intern.kuleuven.ac.be>
References: <002401c59fe6$bba4c780$1145210a@agr.ad10.intern.kuleuven.ac.be>
Message-ID: <42FDFC36.4080002@vanderbilt.edu>

Jan Verbesselt wrote:
> Dear R list,
> 
>  
> 
> From the lrm() binary logistic model we derived the G2 value or the
> likelihood-ratio chi-squared statistic given as L.R. model, in the output of
> the lrm().

> How can this value be penalized for non-linearity (we used splines in the
> lrm function)?
> 

> lrm.iRVI <- lrm(arson ~ rcs(iRVI,5),
> penalty=list(simple=10,nonlinear=100,nonlinear.interaction=4)) 
> 
> This didn’t work properly.

Please following the posting guide.  What do you mean by 'work' and what 
is the output?

You are attempting to penalize for nonexistent interaction terms.

Differential penalization is only appropriate if there are many similar 
terms being penalized (e.g., you fit a multivariable model and want to 
penalize all nonlinear terms in all variables combined).

> The aim is to obtain a value that can be used to compare the goodness of fit
> of the different univariate binary logistic models. 

By univariate I assume you mean univariable.  Penalization is primarily 
used to fit multivariable models.  It allows you to fit "bigger" models.

But for your purpose comparing AIC of various models might be entertained.

Frank

> 
> (The lower the value, the better the fit)
> 
> Kind regards,
> 
> Jan
> 
> ____________________________________________________________________
> Ir. Jan Verbesselt
> Research Associate
> Group of Geomatics Engineering
> Department Biosystems ~ M³-BIORES
> Vital Decosterstraat 102, 3000 Leuven, Belgium
> Tel: +32-16-329750   Fax: +32-16-329760
> http://gloveg.kuleuven.ac.be/
> _______________________________________________________________________
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From spencer.graves at pdf.com  Sat Aug 13 18:06:23 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 13 Aug 2005 09:06:23 -0700
Subject: [R] General expression of a unitary matrix
In-Reply-To: <web-101063654@cgpsrv2.cis.mcmaster.ca>
References: <web-101063654@cgpsrv2.cis.mcmaster.ca>
Message-ID: <42FE1A7F.203@pdf.com>

	  Google led me to 
"http://mathworld.wolfram.com/SpecialUnitaryMatrix.html", where I 
learned that a "special unitary matrix" U has det(U) = 1 in addition to 
the "unitary matrix" requirement that

	  U %*% t(Conj(U)) == diag(dim(U)[1]).

	  Thus, if U is a k x k unitary matrix with det(U) = exp(th*1i), 
exp(-th*1i/k)*U is a special unitary matrix.  Moreover, the special 
unitary matrices are a group under multiplication.

	  Another Google query led me to  	 
"http://mathworld.wolfram.com/SpecialUnitaryGroup.html", which gives a 
general expression for a special unitary matrix, which seems to require 
three real numbers, not four;  with a fourth, you could get a general 
unitary matrix.

	  spencer graves

J. Liu wrote:

> Hi, all,
> 
> Does anybody got the most general expression of a unitary matrix?
> I found one in the book, four entries of the matrix are:
>  
> (cos\theta) exp(j\alpha);     -(sin\theta)exp(j(\alpha-\Omega));
> (sin\theta)exp(j(\beta+\Omega));   (cos\theta) exp(j\beta);
>  
> where "j" is for complex. 
> However, since for any two unitary matrices, their product should also
> be a unitary matrix. When I try to use the above expression to
> calculate the product, I can not derive the product into the same form.
> Therefore, I suspect that this may not be the most general expression. 
> 
> Could you help me out of this? Thanks...
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From simone.gabbriellini at sp.unipi.it  Sat Aug 13 18:09:27 2005
From: simone.gabbriellini at sp.unipi.it (Simone Gabbriellini)
Date: Sat, 13 Aug 2005 18:09:27 +0200
Subject: [R] tkinsert matrix - how to display a matrix with tcltk
Message-ID: <0FF8E409-B45C-4F0C-B6FA-BC8779BF75EB@sp.unipi.it>

dear list,
I have problems with tkinsert
I need to display a matrix as a result of my function, but when I use  
tkinsert(txt, "end", myMatrix, sep="\n") I simply obtain a string.

I do:

n<-tclVar()
tclObj(n)<-matrix(data, ncol=lenght)
tkinsert(txt, "end", tclvalue(n), sep="\n")

any hints?

thank you in advance,
simone gabbriellini



From spencer.graves at pdf.com  Sat Aug 13 19:39:01 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 13 Aug 2005 10:39:01 -0700
Subject: [R] help on cross hedge optimal hedge variance ratio
In-Reply-To: <139ef1c205081202071d57b2d0@mail.gmail.com>
References: <139ef1c205081202071d57b2d0@mail.gmail.com>
Message-ID: <42FE3035.7060308@pdf.com>

	  You have not told us what software you used to get the results you 
present.  My first question is whether you are working with prices or 
log(prices)?  If the former, I suggest you consider the latter;  price 
changes tend to be much better behaved, more nearly normal, etc., on the 
log scale than in dollars, Euros, Rupias, or whatever.

	  Secondly, have you made a normal probability plot of the residuals, 
preferably using "studres" in library(MASS)?  (If you don't have 
Venables and Ripley 2002 Modern Applied Statistis with S, Springer, I 
recommend you get it and spend some time with it.  In addition to 
"studres", it has an excellent chapter devoted to an introductory 
discussion of time series analysis.)  Outliers suggest you may need to 
be working with some of the more sophisticated Rmetrics tools, but I'm 
not sufficiently familiar with those to say much more about that at the 
present time.

	  If I had outliers, I might just delete them initially.  However, I 
would definitely want to come back to them later, because the outliers 
could provide more information than other observations to predict, for 
example, a structural change in the market.  Modeling and reacting 
properly to such signals could make the difference between stellar 
performance and disaster in managing a hedge fund.

	  Thirdly, have you made acf and pacf of the residuals?  Also, have you 
computed the Box-Ljung statistic (function Box.test)?  If no, I suggest 
you do that as a next step.  If they indicate some kind of 
autocorrelation structure, I might then try to model and estimate that 
along with your regression model using function "arima".

	  If you still have questions (which I suspect), then feel free to ask 
another question.  However, before you do that, PLEASE do read the 
posting guide prior! "http://www.R-project.org/posting-guide.html". 
Many people find answers to their own questions in the process of 
working through the posting guide.  Questions posted following that 
process tend to be clearer, easier for others to understand and respond 
to.  On average, this tends to increase the speed, volume and utility of 
replies.

	  spencer graves

Krishna wrote:

> Hi everyone
> 
> I am trying to estimate the optimal hedge variance ratio for cross
> hedging two commodities. the price levels are used (compared to price
> change and % price change) and used the OLS with dummy variable for
> estimating the co-efficients. the equation looks like this
> 
> Y = B + B1*D1 + B2*X + B3*(X*D1)
> 
> Where Y = Daily Cash market price
> D1 = Dummy variable taking value 1 for period Oct-Mar and 0 for Apr-Sep
> X = Daily futures market price on which cross hedging is done.
> B,B1,B2,B3 are the slope co-efficients. 
> 
> The results look like this 
> Regression Statistics
> Multiple R		0.948702709
> R Square		0.900036831
> Adjusted R Square	0.89981135
> Standard Error		25.52050965
> Observations		1334
> 
> 
> 	Coefficients	Standard Error	t Stat	P-value
> Intercept	53.817		4.375		12.300	0.000
> X	0.986		0.012		80.283	0.000
> D1	27.399		6.106		4.487	0.000
> D1 * X	-0.100		0.017		-5.820	0.000
> 	
> It is understood the slope co-efficients for different periods are
> significant as indicated by t-table value. But I feel suspicious on
> the reliability of this values.
> 
> I have used 5 years of daily price data for running the regression,
> and I feel suscpicious becasue, the monthly correlations (pearson
> correlation co-efficient) are highly varying between spot and futures
> and some times even negative.
> 
> Can someone suggest me 
> a) the tests to judge the reliability of hedge-variance values
> b) Is there any other better method than described here for estimating
> the hedge-variance values
> 
> Thank you for the attention and look forward for an early reply
> 
> rgds
> 
> snvk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From kubovy at virginia.edu  Sat Aug 13 19:57:41 2005
From: kubovy at virginia.edu (Michael Kubovy)
Date: Sat, 13 Aug 2005 13:57:41 -0400
Subject: [R] When I  install from source, chmod not permitted
Message-ID: <112B82A4-6ACD-4734-A673-770255D225EA@virginia.edu>

How to fix:
chmod: /Library/Frameworks/R.framework/Versions/2.1.1/Resources/ 
library/R.css: Operation not permitted

Kindly cc me when replying to list.
_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From kubovy at virginia.edu  Sat Aug 13 20:14:28 2005
From: kubovy at virginia.edu (Michael Kubovy)
Date: Sat, 13 Aug 2005 14:14:28 -0400
Subject: [R] Compilation failures: mgcv, spatstat, Matrix, cluster
Message-ID: <98CBCB22-9D53-4016-95E5-2496D7C204C9@virginia.edu>

Please cc me when replying to the list.

With Version 2.1.1  (2005-06-20) on Power Mac G5 running Mac OS X  
10.4.2 (8C46):

Some compilations work (e.g., MatchIt, RGraphics, Zelig), and some  
don't, e.g., mgcv, spatstat,  and the following (Matrix, cluster):

trying URL 'http://www.ibiblio.org/pub/languages/R/CRAN/src/contrib/ 
Matrix_0.98-3.tar.gz'
Content type 'application/x-tar' length 626712 bytes
opened URL
==================================================
downloaded 612Kb

* Installing *source* package 'Matrix' ...
** libs

The downloaded packages are in
     /private/tmp/RtmpPddsAE/downloaded_packages
gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/ 
include  -I/usr/local/include  -I./Metis -fno-common  -g -O2 -c  
HBMM.c -o HBMM.o
In file included from HBMM.c:2:
iohb.h:6:19: malloc.h: No such file or directory
make: *** [HBMM.o] Error 1
ERROR: compilation failed for package 'Matrix'

trying URL 'http://www.ibiblio.org/pub/languages/R/CRAN/src/contrib/ 
cluster_1.10.1.tar.gz'
Content type 'application/x-tar' length 190975 bytes
opened URL
==================================================
downloaded 186Kb

* Installing *source* package 'cluster' ...
** libs
gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/ 
include  -I/usr/local/include   -fno-common  -g -O2 -c clara.c -o  
clara.o
g77   -fno-common  -g -O2 -c daisy.f -o daisy.o
g77   -fno-common  -g -O2 -c dysta.f -o dysta.o
g77   -fno-common  -g -O2 -c fanny.f -o fanny.o
g77   -fno-common  -g -O2 -c meet.f -o meet.o
g77   -fno-common  -g -O2 -c mona.f -o mona.o
gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/ 
include  -I/usr/local/include   -fno-common  -g -O2 -c pam.c -o pam.o
gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/ 
include  -I/usr/local/include   -fno-common  -g -O2 -c spannel.c -o  
spannel.o
g77   -fno-common  -g -O2 -c twins.f -o twins.o

The downloaded packages are in
     /private/tmp/RtmpPddsAE/downloaded_packages
gcc-3.3 -bundle -flat_namespace -undefined suppress -L/usr/local/lib - 
o cluster.so clara.o daisy.o dysta.o fanny.o meet.o mona.o pam.o  
spannel.o twins.o  -L/usr/local/lib/gcc/powerpc-apple-darwin6.8/3.4.2  
-lg2c -lSystem -framework R
** Removing '/Library/Frameworks/R.framework/Versions/2.1.1/Resources/ 
library/cluster'
** Restoring previous '/Library/Frameworks/R.framework/Versions/2.1.1/ 
Resources/library/cluster'
ld: clara.o has external relocation entries in non-writable section  
(__TEXT,__text) for symbols:
restFP
saveFP
make: *** [cluster.so] Error 1
ERROR: compilation failed for package 'cluster'



_____________________________
Professor Michael Kubovy
University of Virginia
Department of Psychology
USPS:     P.O.Box 400400    Charlottesville, VA 22904-4400
Parcels:    Room 102        Gilmer Hall
         McCormick Road    Charlottesville, VA 22903
Office:    B011    +1-434-982-4729
Lab:        B019    +1-434-982-4751
Fax:        +1-434-982-4766
WWW:    http://www.people.virginia.edu/~mk9y/



From spencer.graves at pdf.com  Sat Aug 13 20:17:42 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 13 Aug 2005 11:17:42 -0700
Subject: [R] converting a t statistic to r2
In-Reply-To: <8DA2F8902C1FE648B7A6523320CBAFC8122232@NIHCESMLBX3.nih.gov>
References: <8DA2F8902C1FE648B7A6523320CBAFC8122232@NIHCESMLBX3.nih.gov>
Message-ID: <42FE3946.7010500@pdf.com>

	  The formula R2 = t2/(df+t2) applies only if a single intercept and a 
single slope are estimate with simple linear regression in something 
like B~A or B~age, but not with interaction nor quadratic term in age.

	  For further information, I just got 4 hits from 'RSiteSearch("R^2 in 
lme")', two of which seemed relevant to your question: 
"http://finzi.psych.upenn.edu/R/Rhelp02a/archive/17572.html", and 
"http://finzi.psych.upenn.edu/R/Rhelp02a/archive/34377.html".

	  If you still want more help after this, please submit another 
question -- after reading the posting guide! 
"http://www.R-project.org/posting-guide.html".  The Posting Guide serves 
two purposes:  (a) It helps people get better answers to their questions 
quicker.  (b) It makes it easier for people who try to answer such 
questions to understand what the questioner wants.  It seems to succeeds 
fairly well on both counts when it is used.  I think I can see in a 
question whether the submitter has paid adequate attention to the 
posting guide:  The questions tend to be better focused, more complete, 
and easier to understand and reply to.  If you want free consulting, you 
have to pay for it.

	  spencer graves
-- 

Shaw, Philip (NIH/NIMH) wrote:

> HI
>  
> I wonder if anyone can help.  I have a longitudinal sample of 100 subjects:
> 200 data points were acquired starting at different ages and at irregular
> intervals (subjects have different numbers of repeated data points, so some
> have only one data point).  I have been examining the relationship over time
> (it is quadratic) of continuous variables A on variable B.  To model this I
> have been using linear mixed models in R.  
>  
> B~A*age +A*I(age^2) + random term (for individual)
>  
> I get t values associated with A, age and A*age.
>  
> How (or can) the t value for A be converted to a correlation (r) or variance
> value?  
>  
> I recall that R2 = t2/(df+t2)
>  
> But can this be applied to linear mixed models and what are the degrees of
> freedom?
>  
> I hope this is reasonably clear,
>  
> Many thanks for any opinions
>  
> Philip
>  
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From 10133msb at comb.es  Sat Aug 13 21:02:20 2005
From: 10133msb at comb.es (SALAMERO BARO, MANUEL)
Date: Sat, 13 Aug 2005 21:02:20 +0200
Subject: [R] path analysis
Message-ID: <200508132102.AA132120860@comb.es>

Someone knows if it is possible to perform a path analysis with sem package (or any other) to explain a dependent *dichotomus* variable?

Thanks,

Manel Salamero



From ftorrei2 at uiuc.edu  Sat Aug 13 22:11:58 2005
From: ftorrei2 at uiuc.edu (ftorrei2@uiuc.edu)
Date: Sat, 13 Aug 2005 15:11:58 -0500
Subject: [R] Problem with numeric variable
Message-ID: <289b14c1.2b5848c8.81fca00@expms2.cites.uiuc.edu>

Hello all,

I posted a question some days ago without getting any answers,
perhaps, as one of you kindly pointed out, because the
question was not clearly stated. Let me reformulate it:
In a frame, a column named C2 represents a numeric variable
(checked with is.numeric(C2)). Some rows in the frame have an
undefined value for C2, represented in the table by a ? sign.
The remaining rows have numeric values with 2 decimals. For
example, row 10 has 43.70 for C2, while row 1 has ?. The
problem is that when I list C2 values (or when I try to plot
them, etc), these values are not the ones that appeared in the
table. Below are the first 3 lines of what I get when I list C2:
> C2
[1] 43 47 96 62 87 55 1 98 121 1 1 1 67 1 112 1 93 44
[19] 85 569 52 110 126 95 92 60 36 383 373 298 274 406 208 175
293 306
[37] 305 172 134 115 94 84 104 99 64 271 269 310 268 359 443
248 204 345

These are not the correct values for C2, and I guess that they
are just row numbers. How can I get the correct C2 values
ready for analysis? Is this problem related to the fact that
some rows have a ? value for C2?

Thanks in advance,
Francisco Torreira
Francisco Torreira
Spanish, Italian and Portuguese
Univ. of Illinois at Urbana-Champaign
707 South Mathews Aven.
4031 FLB
Urbana, IL, 61801



From attenka at utu.fi  Sat Aug 13 23:16:31 2005
From: attenka at utu.fi (Atte Tenkanen)
Date: Sun, 14 Aug 2005 00:16:31 +0300 (EEST)
Subject: [R] How to change the names in tone pitch column
In-Reply-To: <Pine.LNX.4.60.0508130815090.32284@springer.berkeley.edu>
References: <34163.130.232.15.71.1123940724.squirrel@webmail2.utu.fi>
	<Pine.LNX.4.60.0508130815090.32284@springer.berkeley.edu>
Message-ID: <43479.130.232.44.35.1123967791.squirrel@webmail2.utu.fi>

Thanks Phil!

This is much more beautiful and elegant. And I learned 2 new R-functions,
nchar and substr.

-Atte

> Atte -
>     Here's one way - there certainly are others:
>
> notes = 0:11
> names(notes) = c("C","C#","D","D#","E","F","F#","G","G#","A","A#","B")
> pc = notes[substr(V4,1,nchar(V4) - 1)]
> names(pc) = NULL
> pcAb = pc + 12 * as.numeric(substr(V4,nchar(V4),nchar(V4)))
> names(pcAb) = NULL
>
>                                         - Phil Spector
>  					 Statistical Computing Facility
>  					 Department of Statistics
>  					 UC Berkeley
>  					 spector at stat.berkeley.edu
>
>
> On Sat, 13 Aug 2005, Atte Tenkanen wrote:
>
>> Hi,
>>
>> I have a column (V4) in a midi event list which includes tone pitch
>> names,
>> i.e. "A4, E4, C#4, A3...":
>>
>>> compo[1:10,]
>>   V1 V2 V3  V4 V5 V6  V7
>> 1   1  1  0  A4 96  2   0
>> 2   1  1  0  E4 96  2   0
>> 3   1  1  0 C#4 96  2   0
>> 4   1  1  0  A3 96  2   0
>> 5   1  3  0  B4 96  1   0
>> 6   1  3  0  E4 96  1   0
>> 7   1  3  0  B3 96  1   0
>> 8   1  3  0 G#3 96  1   0
>> 9   1  4  0 C#5 96  1   0
>> 10  1  4  0  D4 96  0 512
>>
>> Now I'd like to change them to "pitch classes" (column "pc" here, which
>> has the values between 0-11, using modulo 12) and absolute midi numbers
>> (column pcAb, values 0->107), so as results A4 gives 9 and 57 (and for
>> example C0 gives 0 and O, C2-> 0 and 24 etc):
>>
>>> compo[1:10,]
>>   V1 V2 V3  V4 V5 V6  V7 pc pcAb
>> 1   1  1  0  A4 96  2   0  9   57
>> 2   1  1  0  E4 96  2   0  4   52
>> 3   1  1  0 C#4 96  2   0  1   49
>> 4   1  1  0  A3 96  2   0  9   45
>> 5   1  3  0  B4 96  1   0 11   59
>> 6   1  3  0  E4 96  1   0  4   52
>> 7   1  3  0  B3 96  1   0 11   47
>> 8   1  3  0 G#3 96  1   0  8   44
>> 9   1  4  0 C#5 96  1   0  1   61
>> 10  1  4  0  D4 96  0 512  2   50
>>
>> I have done it this way (see next under this comment), but there must be
>> some shorter way, using for-loop and paste-command with sep="" or some
>> other way?:
>>
>> ##*************************************************************************#
>> ## Create pitch class vector (add column pc to compo file) from column
>> V4:
>> ##*************************************************************************#
>>
>> pc=c();
>> pc[V4=="C0"|V4=="C1"|V4=="C2"|V4=="C3"|V4=="C4"|V4=="C5"|V4=="C6"|V4=="C7"|V4=="C8"]=0;
>> pc[V4=="C#0"|V4=="C#1"|V4=="C#2"|V4=="C#3"|V4=="C#4"|V4=="C#5"|V4=="C#6"|V4=="C#7"|V4=="C#8"]=1;
>> pc[V4=="D0"|V4=="D1"|V4=="D2"|V4=="D3"|V4=="D4"|V4=="D5"|V4=="D6"|V4=="D7"|V4=="D8"]=2;
>> pc[V4=="D#0"|V4=="D#1"|V4=="D#2"|V4=="D#3"|V4=="D#4"|V4=="D#5"|V4=="D#6"|V4=="D#7"|V4=="D#8"]=3;
>> pc[V4=="E0"|V4=="E1"|V4=="E2"|V4=="E3"|V4=="E4"|V4=="E5"|V4=="E6"|V4=="E7"|V4=="E8"]=4;
>> pc[V4=="F0"|V4=="F1"|V4=="F2"|V4=="F3"|V4=="F4"|V4=="F5"|V4=="F6"|V4=="F7"|V4=="F8"]=5;
>> pc[V4=="F#0"|V4=="F#1"|V4=="F#2"|V4=="F#3"|V4=="F#4"|V4=="F#5"|V4=="F#6"|V4=="F#7"|V4=="F#8"]=6;
>> pc[V4=="G0"|V4=="G1"|V4=="G2"|V4=="G3"|V4=="G4"|V4=="G5"|V4=="G6"|V4=="G7"|V4=="G8"]=7;
>> pc[V4=="G#0"|V4=="G#1"|V4=="G#2"|V4=="G#3"|V4=="G#4"|V4=="G#5"|V4=="G#6"|V4=="G#7"|V4=="G#8"]=8;
>> pc[V4=="A0"|V4=="A1"|V4=="A2"|V4=="A3"|V4=="A4"|V4=="A5"|V4=="A6"|V4=="A7"|V4=="A8"]=9;
>> pc[V4=="A#0"|V4=="A#1"|V4=="A#2"|V4=="A#3"|V4=="A#4"|V4=="A#5"|V4=="A#6"|V4=="A#7"|V4=="A#8"]=10;
>> pc[V4=="B0"|V4=="B1"|V4=="B2"|V4=="B3"|V4=="B4"|V4=="B5"|V4=="B6"|V4=="B7"|V4=="B8"]=11;
>>
>> ## ... and absolute pitches (0-107):
>>
>> pcAb=c();
>> pcAb[V4=="C0"]=0;pcAb[V4=="C#0"]=1;pcAb[V4=="D0"]=2;pcAb[V4=="D#0"]=3;pcAb[V4=="E0"]=4;pcAb[V4=="F0"]=5;pcAb[V4=="F#0"]=6;pcAb[V4=="G0"]=7;pcAb[V4=="G#0"]=8;pcAb[V4=="A0"]=9;pcAb[V4=="A#0"]=10;pcAb[V4=="B0"]=11;
>> pcAb[V4=="C1"]=12;pcAb[V4=="C#1"]=13;pcAb[V4=="D1"]=14;pcAb[V4=="D#1"]=15;pcAb[V4=="E1"]=16;pcAb[V4=="F1"]=17;pcAb[V4=="F#1"]=18;pcAb[V4=="G1"]=19;pcAb[V4=="G#1"]=20;pcAb[V4=="A1"]=21;pcAb[V4=="A#1"]=22;pcAb[V4=="B1"]=23;
>> pcAb[V4=="C2"]=24;pcAb[V4=="C#2"]=25;pcAb[V4=="D2"]=26;pcAb[V4=="D#2"]=27;pcAb[V4=="E2"]=28;pcAb[V4=="F2"]=29;pcAb[V4=="F#2"]=30;pcAb[V4=="G2"]=31;pcAb[V4=="G#2"]=32;pcAb[V4=="A2"]=33;pcAb[V4=="A#2"]=34;pcAb[V4=="B2"]=35;
>> pcAb[V4=="C3"]=36;pcAb[V4=="C#3"]=37;pcAb[V4=="D3"]=38;pcAb[V4=="D#3"]=39;pcAb[V4=="E3"]=40;pcAb[V4=="F3"]=41;pcAb[V4=="F#3"]=42;pcAb[V4=="G3"]=43;pcAb[V4=="G#3"]=44;pcAb[V4=="A3"]=45;pcAb[V4=="A#3"]=46;pcAb[V4=="B3"]=47;
>> pcAb[V4=="C4"]=48;pcAb[V4=="C#4"]=49;pcAb[V4=="D4"]=50;pcAb[V4=="D#4"]=51;pcAb[V4=="E4"]=52;pcAb[V4=="F4"]=53;pcAb[V4=="F#4"]=54;pcAb[V4=="G4"]=55;pcAb[V4=="G#4"]=56;pcAb[V4=="A4"]=57;pcAb[V4=="A#4"]=58;pcAb[V4=="B4"]=59;
>> pcAb[V4=="C5"]=60;pcAb[V4=="C#5"]=61;pcAb[V4=="D5"]=62;pcAb[V4=="D#5"]=63;pcAb[V4=="E5"]=64;pcAb[V4=="F5"]=65;pcAb[V4=="F#5"]=66;pcAb[V4=="G5"]=67;pcAb[V4=="G#5"]=68;pcAb[V4=="A5"]=69;pcAb[V4=="A#5"]=70;pcAb[V4=="B5"]=71;
>> pcAb[V4=="C6"]=72;pcAb[V4=="C#6"]=73;pcAb[V4=="D6"]=74;pcAb[V4=="D#6"]=75;pcAb[V4=="E6"]=76;pcAb[V4=="F6"]=77;pcAb[V4=="F#6"]=78;pcAb[V4=="G6"]=79;pcAb[V4=="G#6"]=80;pcAb[V4=="A6"]=81;pcAb[V4=="A#6"]=82;pcAb[V4=="B6"]=83;
>> pcAb[V4=="C7"]=84;pcAb[V4=="C#7"]=85;pcAb[V4=="D7"]=86;pcAb[V4=="D#7"]=87;pcAb[V4=="E7"]=88;pcAb[V4=="F7"]=89;pcAb[V4=="F#7"]=90;pcAb[V4=="G7"]=91;pcAb[V4=="G#7"]=92;pcAb[V4=="A7"]=93;pcAb[V4=="A#7"]=94;pcAb[V4=="B7"]=95;
>> pcAb[V4=="C8"]=96;pcAb[V4=="C#8"]=97;pcAb[V4=="D8"]=98;pcAb[V4=="D#8"]=99;pcAb[V4=="E8"]=100;pcAb[V4=="F8"]=101;pcAb[V4=="F#8"]=102;pcAb[V4=="G8"]=103;pcAb[V4=="G#8"]=104;pcAb[V4=="A8"]=105;pcAb[V4=="A#8"]=106;pcAb[V4=="B8"]=107;
>>
>> #*****************************************************************************
>>
>> ## Bind vectors pc and pcAb to original composition array:
>> compo=cbind(compo,pc,pcAb);
>>
>> -Atte
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>



From jconnor at stat.cmu.edu  Sun Aug 14 01:05:01 2005
From: jconnor at stat.cmu.edu (Jason Connor)
Date: Sat, 13 Aug 2005 19:05:01 -0400 (EDT)
Subject: [R] Lattice on Mac OS X & Strip Labels
Message-ID: <Pine.LNX.4.44.0508131859290.19254-100000@hydra7.stat.cmu.edu>


Hi,

I'm running R 1.9 on a Mac with OS X (v10.3.9).

When I use the lattice package I never see text in the strip labels.  The 
labels appear and I can change their color, size, etc., but no matter what 
I do, no text appears.

When I run the same code on my Unix R, the strip labels appear no problem.

Does anyone have any suggestions about how to reconfigure my lattice
window?

Thanks
Jason



From e.leoni at gmail.com  Sun Aug 14 01:26:05 2005
From: e.leoni at gmail.com (Eduardo Leoni)
Date: Sat, 13 Aug 2005 19:26:05 -0400
Subject: [R] monte carlo simulations/lmer
Message-ID: <e474b379050813162662727148@mail.gmail.com>

Hi - I am doing some monte carlo simulations comparing bayesian (using
Plummer's jags) and maximum likelihood (using lmer from package lme4
by Bates et al).

I would like to know if there is a way I can flag nonconvergence and
exceptions. Currently the simulations just stop and the output reads
things like:

Error in optim(.Call("lmer_coef", x, 2, PACKAGE = "Matrix"), fn, gr,
method = "L-BFGS-B",  :
    L-BFGS-B needs finite values of 'fn'
In addition: Warning message:
Leading minor of size 1 of downdated X'X is indefinite

Error in .local(object, ...) : Leading 2 minor of Omega[[1]] not
positive definite
In addition: Warning messages:
1: optim or nlminb returned message ERROR: ABNORMAL_TERMINATION_IN_LNSRCH
in: "LMEoptimize<-"(`*tmp*`, value = list(maxIter = 200, msMaxIter = 200, 
2: optim or nlminb returned message ERROR: ABNORMAL_TERMINATION_IN_LNSRCH
in: "LMEoptimize<-"(`*tmp*`, value = list(maxIter = 200, msMaxIter = 200, 


thanks for any help.

-eduardo



From jfox at mcmaster.ca  Sun Aug 14 01:35:24 2005
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 13 Aug 2005 19:35:24 -0400
Subject: [R] path analysis
In-Reply-To: <200508132102.AA132120860@comb.es>
Message-ID: <20050813233524.YOSJ27508.tomts16-srv.bellnexxia.net@JohnDesktop8300>

Dear Manel,

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> SALAMERO BARO, MANUEL
> Sent: Saturday, August 13, 2005 2:02 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] path analysis
> 
> Someone knows if it is possible to perform a path analysis 
> with sem package (or any other) to explain a dependent 
> *dichotomus* variable?
> 

Yes -- you can use the hetcor() function in the polycor package to generate
a correlation matrix and boot.sem() in the sem package to get standard
errors or confidence intervals. Make sure that the dichotomous variables are
represented as factors. See ?boot.sem for an example.

I hope this helps,
 John



From rolf at math.unb.ca  Sun Aug 14 02:17:46 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Sat, 13 Aug 2005 21:17:46 -0300 (ADT)
Subject: [R] monte carlo simulations/lmer
Message-ID: <200508140017.j7E0HkTC002573@erdos.math.unb.ca>


I think you want to use the function try(); see ?try.

				cheers,

					Rolf Turner
					rolf at math.unb.ca



From roebuck at odin.mdacc.tmc.edu  Sun Aug 14 02:25:24 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Sat, 13 Aug 2005 19:25:24 -0500 (CDT)
Subject: [R] Compilation failures: mgcv, spatstat, Matrix, cluster
In-Reply-To: <98CBCB22-9D53-4016-95E5-2496D7C204C9@virginia.edu>
References: <98CBCB22-9D53-4016-95E5-2496D7C204C9@virginia.edu>
Message-ID: <Pine.OSF.4.58.0508131828010.350399@odin.mdacc.tmc.edu>

On Sat, 13 Aug 2005, Michael Kubovy wrote:

> With Version 2.1.1  (2005-06-20) on Power Mac G5 running Mac OS X
> 10.4.2 (8C46):
>
> Some compilations work (e.g., MatchIt, RGraphics, Zelig), and some
> don't, e.g., mgcv, spatstat,  and the following (Matrix, cluster):
>
> trying URL 'http://www.ibiblio.org/pub/languages/R/CRAN/src/contrib/
> Matrix_0.98-3.tar.gz'
> Content type 'application/x-tar' length 626712 bytes
> opened URL
> ==================================================
> downloaded 612Kb
>
> * Installing *source* package 'Matrix' ...
> ** libs
>
> The downloaded packages are in
>      /private/tmp/RtmpPddsAE/downloaded_packages
> gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/
> include  -I/usr/local/include  -I./Metis -fno-common  -g -O2 -c
> HBMM.c -o HBMM.o
> In file included from HBMM.c:2:
> iohb.h:6:19: malloc.h: No such file or directory
> make: *** [HBMM.o] Error 1
> ERROR: compilation failed for package 'Matrix'

Didn't check package for actually functioning correctly,
but the following changes will allow compilation on OS X
10.3. In ANSI C, the standard memory allocation routines
are declared in <stdlib.h>; <malloc.h> is obsolete for that
purpose and isn't guaranteed to exist.


Matrix/src/mmio.c:
    Add #include <stdlib.h>
    Remove #include <malloc.h>

Matrix/src/iohb.h:
    Remove #include <malloc.h>

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From ggrothendieck at gmail.com  Sun Aug 14 03:26:50 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 13 Aug 2005 21:26:50 -0400
Subject: [R] How to make a lagged variable in panel data?
In-Reply-To: <20050813123123.GX394@bindi.local>
References: <20050813123123.GX394@bindi.local>
Message-ID: <971536df0508131826474643ce@mail.gmail.com>

On 8/13/05, Ila Patnaik <ila at mayin.org> wrote:
> Suppose we observe N individuals, for each of which we have a
> time-series. How do we correctly create a lagged value of the
> time-series variable?
> 
> As an example, suppose I create:
> 
>  A <- data.frame(year=rep(c(1980:1984),3),
>                  person= factor(sort(rep(1:3,5))),
>                  wage=c(rnorm(15)))
> 
>  > A
>     year person        wage
>  1  1980      1  0.17923212
>  2  1981      1  0.25610292
>  3  1982      1  0.50833655
>  4  1983      1 -0.42448395
>  5  1984      1  0.49233532
>  6  1980      2 -0.49928025
>  7  1981      2  0.06842660
>  8  1982      2  0.65677575
>  9  1983      2  0.15947390
>  10 1984      2 -0.46585116
>  11 1980      3 -0.29052635
>  12 1981      3 -0.27109203
>  13 1982      3 -0.76168164
>  14 1983      3  0.02294361
>  15 1984      3  2.22828032
> 
> What I'd like to do is to make a lagged wage for each person, i.e., I
> should get an additional variable A$wage.lag1:
> 
>  > A
>     year person        wage       wage.lag1
>  1  1980      1  0.17923212             NA
>  2  1981      1  0.25610292     0.17923212
>  3  1982      1  0.50833655     0.25610292
>  4  1983      1 -0.42448395     0.50833655
>  5  1984      1  0.49233532    -0.42448395
>  6  1980      2 -0.49928025             NA
>  7  1981      2  0.06842660    -0.49928025
>  8  1982      2  0.65677575     0.06842660
>  9  1983      2  0.15947390     0.65677575
>  10 1984      2 -0.46585116     0.15947390
>  11 1980      3 -0.29052635             NA
>  12 1981      3 -0.27109203    -0.29052635
>  13 1982      3 -0.76168164    -0.27109203
>  14 1983      3  0.02294361    -0.76168164
>  15 1984      3  2.22828032     0.02294361
> 


We can use 'by' to split data frame A by person and to
apply the function f to each such subset of rows. Function f
makes that portion of wage which corresponds to a single
person into a ts class time series so that we can use lag
with it and then we cbind wage together with its lag.  From
the cbind'ed result we extract out those times that
correspond to the original series since the example output
only includes those. Note that such extraction has a side
effect of turning wages into a matrix rather than a time
series.  We then put every together using cbind(...) once
again and once the 'by' is complete we rbind all rows together.

	f <- function(x) { 
		wage <- ts(x$wage, start = x$year[1])
		idx <- seq(length = length(wage))
		wages <- cbind(wage, lag(wage, -1))[idx,]
		cbind(x[,1:2], wages)
	}

	result <- do.call("rbind", by(A, A$person, f))
	result



From alanzhao at gmail.com  Sun Aug 14 07:09:39 2005
From: alanzhao at gmail.com (Alan Zhao)
Date: Sat, 13 Aug 2005 22:09:39 -0700
Subject: [R] PCA problem in R
Message-ID: <ddmjmp$j5j$1@sea.gmane.org>

Dear all:

When I have more variables than units, say a 195*10896 matrix which has 
10896 variables and 195 samples. prcomp will give only 195 principal 
components. I checked in the help, but there is no explanation that why 
this happen. Can we get more than 195 PCs for this case? Thank you very 
much.

Best!
Alan
Aug-12-2005



From shigesong at gmail.com  Sun Aug 14 07:48:46 2005
From: shigesong at gmail.com (Shige Song)
Date: Sun, 14 Aug 2005 13:48:46 +0800
Subject: [R] Documents for LME4
Message-ID: <5abc11d8050813224867ad690d@mail.gmail.com>

Dear All,

I want to fit a two-level cross-classified random effect poisson model
using LME4. However, the documentation for this pacakge seems really
thin. I have the NLME book, but there is not much about mixed
generalized linear models. Any suggestions about where I should begin?
Thanks!

Best,
Shige



From ripley at stats.ox.ac.uk  Sun Aug 14 08:25:36 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 14 Aug 2005 07:25:36 +0100 (BST)
Subject: [R] PCA problem in R
In-Reply-To: <ddmjmp$j5j$1@sea.gmane.org>
References: <ddmjmp$j5j$1@sea.gmane.org>
Message-ID: <Pine.LNX.4.61.0508140714210.22738@gannet.stats>

On Sat, 13 Aug 2005, Alan Zhao wrote:

> When I have more variables than units, say a 195*10896 matrix which has
> 10896 variables and 195 samples. prcomp will give only 195 principal
> components. I checked in the help, but there is no explanation that why
> this happen.

There is not even a definition of a PC in the help. Did you read the 
references?  This is what they are given for!

> Can we get more than 195 PCs for this case? Thank you very
> much.

Check out the theory in the references.  You can, but all the remaining 
ones are constant across samples and not uniquely defined.  You are likely 
to have trouble storing the coefficients (10701x10896 is 800Mb).
It would be better to do whatever you intend to do with them without 
explicitly computing them.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dieter.menne at menne-biomed.de  Sun Aug 14 10:22:52 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Sun, 14 Aug 2005 08:22:52 +0000 (UTC)
Subject: [R] Documents for LME4
References: <5abc11d8050813224867ad690d@mail.gmail.com>
Message-ID: <loom.20050814T102104-402@post.gmane.org>

Shige Song <shigesong <at> gmail.com> writes:

> I want to fit a two-level cross-classified random effect poisson model
> using LME4. However, the documentation for this pacakge seems really
> thin. I have the NLME book, but there is not much about mixed
> generalized linear models. Any suggestions about where I should begin?

lme4 is work in progress, so documentation is still a bit limited. You may try 
Douglas Bates' article 

http://cran.r-project.org/doc/Rnews/Rnews_2005-1.pdf

to give you a starter to understand the syntax.

Dieter



From fcsaszar at gmail.com  Sun Aug 14 10:40:02 2005
From: fcsaszar at gmail.com (Felipe Csaszar)
Date: Sun, 14 Aug 2005 04:40:02 -0400
Subject: [R] complex expression with plotmath
Message-ID: <f6eb7d54050814014050ee2302@mail.gmail.com>

Hello everyone,

I want to define a function that receives the name of two variables
(may include Greek letters and subscripts) and uses them into the
title of a plot.

My best attempt is the following:
myplot <- function(var1, var2) {
    v=paste(var1,"==1 & ",var2,"==2");
    plot(1:10, main=parse(,,v))
}

But when I call it with something like myplot("Q[i]", "Delta[j]") I
get "&(Q_i=1,Delta_j=2)" as title when I want to get "Q_i=1 &
Delta_j=2".

Is there any solution within R? (I don't want to use psfrag and Latex
to post-process the plot)

Why R does not have support for full Latex expressions? (as Matlab
f.ex.). IMHO plotmath is not good enough.

Thank you all.

Felipe



From ajayshah at mayin.org  Sun Aug 14 12:33:36 2005
From: ajayshah at mayin.org (Ajay Narottam Shah)
Date: Sun, 14 Aug 2005 16:03:36 +0530
Subject: [R] Panel data handling (lags, growth rates)
Message-ID: <20050814103336.GK458@lubyanka.local>

I have written two functions which do useful things with panel data
a.k.a. longitudinal data, where one unit of observation (a firm or a
person or an animal) is observed on a uniform time grid:
   - The first function makes lagged values of variables of your choice.
   - The second function makes growth rates w.r.t. q observations ago,
      for variables of your choice.

These strike me as bread-and-butter tasks in dealing with panel
data. I couldn't find these functions in the standard R
libraries. They are presented in this email for two reasons. First,
it'll be great if R gurus can look at the code and propose
improvements. Second, it'll be great if some package-owner can adopt
these orphans :-) and make them available to the R community.

The two functions follow:

library(Hmisc)                          # Am using Lag() in this.

# Task: For a supplied list of variables (the list `lagvars'),
#       make new columns in a dataset denoting lagged values.
#       You must supply `unitvar' which identifies the unit that's
#           repeatedly observed.
#       You must supply the name of the time variable `timevar'
#       and you must tell a list of the lags that interest you (`lags')
# Example:
#  paneldata.lags(A, "person", "year", c("v1","v2"), lags=1:4)
paneldata.lags <- function(X, unitvar, timevar, lagvars, lags=1) {
  stopifnot(length(lagvars)>=1)
  X <- X[order(X[,timevar]),]           # just in case it's not sorted.

  innertask <- function(Y, lagvars, lags) {
    E <- labels <- NULL
    for (v in lagvars) {
      for (i in lags) {
        E <- cbind(E, Lag(Y[,v], i))
      }
      labels <- c(labels, paste(v, ".l", lags, sep=""))
    }
    colnames(E) <- labels
    cbind(Y, E)
  }

  do.call("rbind", by(X, X[,unitvar], innertask, lagvars, lags))
}

# Task: For a supplied list of variables (the list `gvars'),
#       make new columns in a dataset denoting growth rates.
#       You must supply `unitvar' which identifies the unit that's
#           repeatedly observed.
#       You must supply the name of the time variable `timevar'
#       and you must tell the time periods Q (vector is ok) over which
#       the growth rates are computed.
paneldata.growthrates <- function(X, unitvar, timevar, gvars, Q=1) {
  stopifnot(length(gvars)>=1)
  X <- X[order(X[,timevar]),]

  makegrowths <- function(x, q) {
    new <- rep(NA, length(x))
    for (t in (1+q):length(x)) {
      new[t] <- 100*((x[t]/x[t-q])-1)
    }
    return(new)
  }

  innertask <- function(Y, gvars, Q) {
    E <- labels <- NULL
    for (v in gvars) {
      for (q in Q) {
        E <- cbind(E, makegrowths(Y[,v], q))
      }
      labels <- c(labels, paste(v, ".g", Q, sep=""))
    }
    colnames(E) <- labels
    cbind(Y, E)
  }

  do.call("rbind", by(X, X[,unitvar], innertask, gvars, Q))
}

Here's a demo of using them:

# A simple panel dataset
A <- data.frame(year=rep(1980:1982,4),
                person=factor(sort(rep(1:4,3))),
                v1=round(rnorm(12),digits=2), v2=round(rnorm(12),digits=2))

# Demo of creating lags for both variables v1 and v2 --
paneldata.lags(A, "person", "year", c("v1","v2"), lags=1:2)
# Demo of creating growth rates for v2 w.r.t. 1 & 2 years ago --
paneldata.growthrates(A, "person", "year", "v2", Q=1:2)




Finally, I have a question. In a previous posting on this subject,
Gabor showed me that my code:

# Blast this function for all the values that A$person takes --
new <- NULL
for (f in levels(A$person)) {
  new <- rbind(new,
               make.additional.variables(subset(A, A$person==f),
                                         nlags=2, Q=1))
}
A <- new; rm(new)

can be replaced by one do.call() (as used above). It's awesome, but I
don't understand it! :-) Could someone please explain how and why this
works? I know by() and I see that when I do by(A,A$x), it gives me a
list containing as many entries as are levels of A$x. I couldn't think
of a way to force all this into one data frame; the best I could do
was to do for (f in levels (A$person)) {} as shown here. The two
functions above are using do.call() as Gabor used them, and they're
awesome, but I don't understand why they work! The man page ?do.call
was a bit too cryptic and I couldn't comprehend it. Where can I learn
this stuff?

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From tmlammail at yahoo.com  Sun Aug 14 13:26:35 2005
From: tmlammail at yahoo.com (Martin Lam)
Date: Sun, 14 Aug 2005 04:26:35 -0700 (PDT)
Subject: [R] How to add decision trees into a list?
Message-ID: <20050814112635.75429.qmail@web40529.mail.yahoo.com>

Hi,

I am somewhat new to R so this question may be
foolish, but is it possible to add decision trees into
a list, array or vector in R?

I am trying to build a collection (ensemble) of
decision trees. Every time a new instance arrive I
need to get the prediction of each decision tree. I
have tried to add a decision tree into a variable but
without luck. Is a special package needed perhaps?

This is what I tried:

# load the rpart package
library("rpart")

# 6*3 (18) samples are left out for prediction
sub <- c(sample(1:50, 45), sample(51:100, 45),
sample(101:150, 45))

# train the tree with the subset
fit <- rpart(Species ~ ., data=iris, subset=sub)

# make a nice test table
table(predict(fit, iris[-sub,], type="class"),
iris[-sub, "Species"])

# add fit to the collection
collection <- fit

# for the illustrative purpose, I add fit again to the
# collection
collection <- c(collection, fit)

# get the first tree in the collection???
tree1 <- collection[1]

# test the tree
table(predict(tree1, iris[-sub,], type="class"),
iris[-sub, "Species"])

# error message from R
Error in predict(tree1, iris[-sub, ], type = "class")
: no applicable method for "predict"


The problem is that I am not able to add the decision
trees into a variable/list. Somehow the function 'c'
isn't 'copying' it right.

Any help is appreciated.

Thanks in advance,

M. Lam



From ftorrei2 at uiuc.edu  Sun Aug 14 14:16:50 2005
From: ftorrei2 at uiuc.edu (ftorrei2@uiuc.edu)
Date: Sun, 14 Aug 2005 07:16:50 -0500
Subject: [R] Problem with numeric variable
Message-ID: <a31d08fd.2bb09e07.81b4200@expms2.cites.uiuc.edu>

Well, you were right. When I check with str() or summary(),
the data frame appears as having a factor for that column.
However, if I ask is.factor(C2), I get FALSE, and if I ask
is.numeric(C2) I get TRUE. This seems strange.
So I decided to reimport the dataframe, this time with NA as
undefined values, and not ?. C2 was imported as a numeric
variable, as checked with str() and is.numeric(). But I still
get the indexes and not the values when I use C2 for any
purpose, just as happened before. How can this be possible?
All the other columns in the table behave properly. 
The only difference I see between this columns ans the others
is that it contains NA values.

Thanks again,
Francisco Torreira

 
  

---- Original message ----
>Date: Sun, 14 Aug 2005 10:11:15 +0100
>From: Patrick Burns <pburns at pburns.seanet.com>  
>Subject: Re: [R] Problem with numeric variable  
>To: ftorrei2 at uiuc.edu
>
>I think your problem is that you have a factor rather
>than a numeric vector (even though you say you checked
>with 'is.numeric').  Missing values should be represented
>by 'NA' and not by '?' which is what makes me think you
>have a factor.
>
>Patrick Burns
>patrick at burns-stat.com
>+44 (0)20 8525 0696
>http://www.burns-stat.com
>(home of S Poetry and "A Guide for the Unwilling S User")
>
>ftorrei2 at uiuc.edu wrote:
>
>>Hello all,
>>
>>I posted a question some days ago without getting any answers,
>>perhaps, as one of you kindly pointed out, because the
>>question was not clearly stated. Let me reformulate it:
>>In a frame, a column named C2 represents a numeric variable
>>(checked with is.numeric(C2)). Some rows in the frame have an
>>undefined value for C2, represented in the table by a ? sign.
>>The remaining rows have numeric values with 2 decimals. For
>>example, row 10 has 43.70 for C2, while row 1 has ?. The
>>problem is that when I list C2 values (or when I try to plot
>>them, etc), these values are not the ones that appeared in the
>>table. Below are the first 3 lines of what I get when I list C2:
>>  
>>
>>>C2
>>>    
>>>
>>[1] 43 47 96 62 87 55 1 98 121 1 1 1 67 1 112 1 93 44
>>[19] 85 569 52 110 126 95 92 60 36 383 373 298 274 406 208 175
>>293 306
>>[37] 305 172 134 115 94 84 104 99 64 271 269 310 268 359 443
>>248 204 345
>>
>>These are not the correct values for C2, and I guess that they
>>are just row numbers. How can I get the correct C2 values
>>ready for analysis? Is this problem related to the fact that
>>some rows have a ? value for C2?
>>
>>Thanks in advance,
>>Francisco Torreira
>>Francisco Torreira
>>Spanish, Italian and Portuguese
>>Univ. of Illinois at Urbana-Champaign
>>707 South Mathews Aven.
>>4031 FLB
>>Urbana, IL, 61801
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>>
>>
>>
>>  
>>
>
Francisco Torreira
Spanish, Italian and Portuguese
Univ. of Illinois at Urbana-Champaign
707 South Mathews Aven.
4031 FLB
Urbana, IL, 61801



From ripley at stats.ox.ac.uk  Sun Aug 14 14:23:42 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 14 Aug 2005 13:23:42 +0100 (BST)
Subject: [R] How to add decision trees into a list?
In-Reply-To: <20050814112635.75429.qmail@web40529.mail.yahoo.com>
References: <20050814112635.75429.qmail@web40529.mail.yahoo.com>
Message-ID: <Pine.LNX.4.61.0508141318140.32176@gannet.stats>

You have not created a list to add trees (not 'decision trees' from rpart, 
BTW) to.  You need something like

collection <- vector("list", 5)
collection[[1]] <- fit
...

Reading ?c should illuminate your mistake: note that 'fit' is a list (and 
so already a vector).

On Sun, 14 Aug 2005, Martin Lam wrote:

> Hi,
>
> I am somewhat new to R so this question may be
> foolish, but is it possible to add decision trees into
> a list, array or vector in R?
>
> I am trying to build a collection (ensemble) of
> decision trees. Every time a new instance arrive I
> need to get the prediction of each decision tree. I
> have tried to add a decision tree into a variable but
> without luck. Is a special package needed perhaps?

No, just reading the basic documentation.

> This is what I tried:
>
> # load the rpart package
> library("rpart")
>
> # 6*3 (18) samples are left out for prediction
> sub <- c(sample(1:50, 45), sample(51:100, 45),
> sample(101:150, 45))
>
> # train the tree with the subset
> fit <- rpart(Species ~ ., data=iris, subset=sub)
>
> # make a nice test table
> table(predict(fit, iris[-sub,], type="class"),
> iris[-sub, "Species"])
>
> # add fit to the collection
> collection <- fit
>
> # for the illustrative purpose, I add fit again to the
> # collection
> collection <- c(collection, fit)
>
> # get the first tree in the collection???
> tree1 <- collection[1]
>
> # test the tree
> table(predict(tree1, iris[-sub,], type="class"),
> iris[-sub, "Species"])
>
> # error message from R
> Error in predict(tree1, iris[-sub, ], type = "class")
> : no applicable method for "predict"
>
>
> The problem is that I am not able to add the decision
> trees into a variable/list. Somehow the function 'c'
> isn't 'copying' it right.
>
> Any help is appreciated.
>
> Thanks in advance,
>
> M. Lam
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmbates at gmail.com  Sun Aug 14 16:30:26 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Sun, 14 Aug 2005 09:30:26 -0500
Subject: [R] Documents for LME4
In-Reply-To: <loom.20050814T102104-402@post.gmane.org>
References: <5abc11d8050813224867ad690d@mail.gmail.com>
	<loom.20050814T102104-402@post.gmane.org>
Message-ID: <40e66e0b0508140730418e2b2f@mail.gmail.com>

On 8/14/05, Dieter Menne <dieter.menne at menne-biomed.de> wrote:
> Shige Song <shigesong <at> gmail.com> writes:
> 
> > I want to fit a two-level cross-classified random effect poisson model
> > using LME4. However, the documentation for this pacakge seems really
> > thin. I have the NLME book, but there is not much about mixed
> > generalized linear models. Any suggestions about where I should begin?
> 
> lme4 is work in progress, so documentation is still a bit limited. You may try
> Douglas Bates' article
> 
> http://cran.r-project.org/doc/Rnews/Rnews_2005-1.pdf
> 
> to give you a starter to understand the syntax.
> 
> Dieter
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

There are several worked examples (and will soon be more) of lmer
usage in the mlmRev package.  Also see the vignette in that package.

As Dieter kindly mentioned this is a work in progress.  The
documentation will ultimately be in the form of a book with the
working title "Multilevel Modeling in R".



From liuj24 at univmail.cis.mcmaster.ca  Sun Aug 14 16:36:16 2005
From: liuj24 at univmail.cis.mcmaster.ca (J. Liu)
Date: Sun, 14 Aug 2005 10:36:16 -0400
Subject: [R] General expression of a unitary matrix
In-Reply-To: <42FE1A7F.203@pdf.com>
Message-ID: <web-101162541@cgpsrv2.cis.mcmaster.ca>

Thank you, Spencer. I read through the websites you suggested. What I
need is how to parameterize a 2\times 2 unitary matrix. Generally,
since for a complex 2\times 2 matrix, there are 8 free variables, and
for it to be unitary, there are four constraints (unit norm and
orthogonality), hence I think there are four free variables left for a
2\times 2unitary matrix. The form I found can not decribe all the
unitary matrix, that is why I suspect that it is not the most general
one. The form in the second web you suggested is an interesting one,
however, since only 3 variables invovled, it may not be the most
general expression. 

Jing  


On Sat, 13 Aug 2005 09:06:23 -0700
 Spencer Graves <spencer.graves at pdf.com> wrote:
> 	  Google led me to 
> "http://mathworld.wolfram.com/SpecialUnitaryMatrix.html", where I 
> learned that a "special unitary matrix" U has det(U) = 1 in addition
> to 
> the "unitary matrix" requirement that
> 
> 	  U %*% t(Conj(U)) == diag(dim(U)[1]).
> 
> 	  Thus, if U is a k x k unitary matrix with det(U) = exp(th*1i), 
> exp(-th*1i/k)*U is a special unitary matrix.  Moreover, the special 
> unitary matrices are a group under multiplication.
> 
> 	  Another Google query led me to  	 
> "http://mathworld.wolfram.com/SpecialUnitaryGroup.html", which gives
> a 
> general expression for a special unitary matrix, which seems to
> require 
> three real numbers, not four;  with a fourth, you could get a general
> 
> unitary matrix.
> 
> 	  spencer graves
> 
> J. Liu wrote:
> 
> > Hi, all,
> > 
> > Does anybody got the most general expression of a unitary matrix?
> > I found one in the book, four entries of the matrix are:
> >  
> > (cos\theta) exp(j\alpha);     -(sin\theta)exp(j(\alpha-\Omega));
> > (sin\theta)exp(j(\beta+\Omega));   (cos\theta) exp(j\beta);
> >  
> > where "j" is for complex. 
> > However, since for any two unitary matrices, their product should
> also
> > be a unitary matrix. When I try to use the above expression to
> > calculate the product, I can not derive the product into the same
> form.
> > Therefore, I suspect that this may not be the most general
> expression. 
> > 
> > Could you help me out of this? Thanks...
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> -- 
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
> 
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From R.P.Clement at westminster.ac.uk  Sun Aug 14 16:46:12 2005
From: R.P.Clement at westminster.ac.uk (R.P.Clement@westminster.ac.uk)
Date: Sun, 14 Aug 2005 15:46:12 +0100
Subject: [R] PCA problem in R
In-Reply-To: <Pine.LNX.4.61.0508140714210.22738@gannet.stats>
References: <ddmjmp$j5j$1@sea.gmane.org>
	<Pine.LNX.4.61.0508140714210.22738@gannet.stats>
Message-ID: <1124030772.42ff59348c387@zeppo.wmin.ac.uk>

Hi. I have two comments on this.

Quoting Prof Brian Ripley <ripley at stats.ox.ac.uk>:

> On Sat, 13 Aug 2005, Alan Zhao wrote:
>
> > When I have more variables than units, say a 195*10896 matrix which has
> > 10896 variables and 195 samples. prcomp will give only 195 principal
> > components. I checked in the help, but there is no explanation that why
> > this happen.
>
> There is not even a definition of a PC in the help. Did you read the
> references?  This is what they are given for!

I don't know if it's too simple and introductory for the OP, but I quite like
Lindsay Smith's intro to PCA.

http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf

> > Can we get more than 195 PCs for this case? Thank you very
> > much.
>
> Check out the theory in the references.  You can, but all the remaining
> ones are constant across samples and not uniquely defined.  You are likely
> to have trouble storing the coefficients (10701x10896 is 800Mb).
> It would be better to do whatever you intend to do with them without
> explicitly computing them.

I've been using prcomp on data with 50 samples and 8000 variables. That
completes in acceptable time on a very modest (XP2000+/512M/rh9) machine.
Though, I note that I only have 1/4 of the samples of the OP.

Cheers,

Ross-c



From ggrothendieck at gmail.com  Sun Aug 14 17:11:44 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 14 Aug 2005 11:11:44 -0400
Subject: [R] Panel data handling (lags, growth rates)
In-Reply-To: <20050814103336.GK458@lubyanka.local>
References: <20050814103336.GK458@lubyanka.local>
Message-ID: <971536df0508140811e485730@mail.gmail.com>

On 8/14/05, Ajay Narottam Shah <ajayshah at mayin.org> wrote:
> I have written two functions which do useful things with panel data
> a.k.a. longitudinal data, where one unit of observation (a firm or a
> person or an animal) is observed on a uniform time grid:
>   - The first function makes lagged values of variables of your choice.
>   - The second function makes growth rates w.r.t. q observations ago,
>      for variables of your choice.
> 
> These strike me as bread-and-butter tasks in dealing with panel
> data. I couldn't find these functions in the standard R
> libraries. They are presented in this email for two reasons. First,
> it'll be great if R gurus can look at the code and propose
> improvements. Second, it'll be great if some package-owner can adopt
> these orphans :-) and make them available to the R community.
> 
> The two functions follow:
> 
> library(Hmisc)                          # Am using Lag() in this.
> 
> # Task: For a supplied list of variables (the list `lagvars'),
> #       make new columns in a dataset denoting lagged values.
> #       You must supply `unitvar' which identifies the unit that's
> #           repeatedly observed.
> #       You must supply the name of the time variable `timevar'
> #       and you must tell a list of the lags that interest you (`lags')
> # Example:
> #  paneldata.lags(A, "person", "year", c("v1","v2"), lags=1:4)
> paneldata.lags <- function(X, unitvar, timevar, lagvars, lags=1) {
>  stopifnot(length(lagvars)>=1)
>  X <- X[order(X[,timevar]),]           # just in case it's not sorted.
> 
>  innertask <- function(Y, lagvars, lags) {
>    E <- labels <- NULL
>    for (v in lagvars) {
>      for (i in lags) {
>        E <- cbind(E, Lag(Y[,v], i))
>      }
>      labels <- c(labels, paste(v, ".l", lags, sep=""))
>    }
>    colnames(E) <- labels
>    cbind(Y, E)
>  }
> 
>  do.call("rbind", by(X, X[,unitvar], innertask, lagvars, lags))
> }
> 
> # Task: For a supplied list of variables (the list `gvars'),
> #       make new columns in a dataset denoting growth rates.
> #       You must supply `unitvar' which identifies the unit that's
> #           repeatedly observed.
> #       You must supply the name of the time variable `timevar'
> #       and you must tell the time periods Q (vector is ok) over which
> #       the growth rates are computed.
> paneldata.growthrates <- function(X, unitvar, timevar, gvars, Q=1) {
>  stopifnot(length(gvars)>=1)
>  X <- X[order(X[,timevar]),]
> 
>  makegrowths <- function(x, q) {
>    new <- rep(NA, length(x))
>    for (t in (1+q):length(x)) {
>      new[t] <- 100*((x[t]/x[t-q])-1)
>    }
>    return(new)
>  }
> 
>  innertask <- function(Y, gvars, Q) {
>    E <- labels <- NULL
>    for (v in gvars) {
>      for (q in Q) {
>        E <- cbind(E, makegrowths(Y[,v], q))
>      }
>      labels <- c(labels, paste(v, ".g", Q, sep=""))
>    }
>    colnames(E) <- labels
>    cbind(Y, E)
>  }
> 
>  do.call("rbind", by(X, X[,unitvar], innertask, gvars, Q))
> }
> 
> Here's a demo of using them:
> 
> # A simple panel dataset
> A <- data.frame(year=rep(1980:1982,4),
>                person=factor(sort(rep(1:4,3))),
>                v1=round(rnorm(12),digits=2), v2=round(rnorm(12),digits=2))
> 
> # Demo of creating lags for both variables v1 and v2 --
> paneldata.lags(A, "person", "year", c("v1","v2"), lags=1:2)
> # Demo of creating growth rates for v2 w.r.t. 1 & 2 years ago --
> paneldata.growthrates(A, "person", "year", "v2", Q=1:2)
> 
> 
> 
> 
> Finally, I have a question. In a previous posting on this subject,
> Gabor showed me that my code:
> 
> # Blast this function for all the values that A$person takes --
> new <- NULL
> for (f in levels(A$person)) {
>  new <- rbind(new,
>               make.additional.variables(subset(A, A$person==f),
>                                         nlags=2, Q=1))
> }
> A <- new; rm(new)
> 
> can be replaced by one do.call() (as used above). It's awesome, but I
> don't understand it! :-) Could someone please explain how and why this
> works? I know by() and I see that when I do by(A,A$x), it gives me a
> list containing as many entries as are levels of A$x. I couldn't think
> of a way to force all this into one data frame; the best I could do
> was to do for (f in levels (A$person)) {} as shown here. The two
> functions above are using do.call() as Gabor used them, and they're
> awesome, but I don't understand why they work! The man page ?do.call
> was a bit too cryptic and I couldn't comprehend it. Where can I learn
> this stuff?
> 

Don't know of a source, I just study code, but 
conceptually by just splits up the rows by the grouping
argument giving a list of data frames and applies the
function to each element of the list giving the result.

For example, if we write:

f <- function(x) colSums(x[,-5])
iris.by <- by(iris, iris$Species, f)

is the same as:

f <- function(x) colSums(x[,-5])
iris.split <- split(iris, iris$Species)
iris.lapply <- lapply(iris.split, f)

except that in the by case the result gets a class of "by".

In either of the above cases the result is a list of these
three elements, i.e. these three data frames:

el1 <- iris.by[[1]]; el2 <- iris.by[[2]]; el3 <- iris.by[[3]]

Now, if g <- function(x,y)x+y then

	g(1,2)

is the same as

	do.call("g", list(1,2))

so going back the iris example, to rbind el1, el2 and el3 together we do this:

	rbind(el1, el2, el3)

which is the same as 

	do.call("rbind", list(e1, e2, e3))

which is the same as

	do.call("rbind", iris.by)



From ggrothendieck at gmail.com  Sun Aug 14 17:24:04 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 14 Aug 2005 11:24:04 -0400
Subject: [R] complex expression with plotmath
In-Reply-To: <f6eb7d54050814014050ee2302@mail.gmail.com>
References: <f6eb7d54050814014050ee2302@mail.gmail.com>
Message-ID: <971536df050814082473de6326@mail.gmail.com>

On 8/14/05, Felipe Csaszar <fcsaszar at gmail.com> wrote:
> Hello everyone,
> 
> I want to define a function that receives the name of two variables
> (may include Greek letters and subscripts) and uses them into the
> title of a plot.
> 
> My best attempt is the following:
> myplot <- function(var1, var2) {
>    v=paste(var1,"==1 & ",var2,"==2");
>    plot(1:10, main=parse(,,v))
> }
> 
> But when I call it with something like myplot("Q[i]", "Delta[j]") I
> get "&(Q_i=1,Delta_j=2)" as title when I want to get "Q_i=1 &
> Delta_j=2".
> 
> Is there any solution within R? (I don't want to use psfrag and Latex
> to post-process the plot)
> 
> Why R does not have support for full Latex expressions? (as Matlab
> f.ex.). IMHO plotmath is not good enough.
> 

Try this:


myplot <- function(var1, var2) 
	plot(1:10, main = bquote(.(var1) == 1 ~ "&" ~ .(var2) == 2))
myplot(quote(Q[i]), quote(Delta[j]))



From spencer.graves at pdf.com  Sun Aug 14 18:05:19 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 14 Aug 2005 09:05:19 -0700
Subject: [R] General expression of a unitary matrix
In-Reply-To: <web-101162541@cgpsrv2.cis.mcmaster.ca>
References: <web-101162541@cgpsrv2.cis.mcmaster.ca>
Message-ID: <42FF6BBF.5030701@pdf.com>

	  Could you provide an example that can NOT be expressed in that form?

	  spencer graves

J. Liu wrote:

> Thank you, Spencer. I read through the websites you suggested. What I
> need is how to parameterize a 2\times 2 unitary matrix. Generally,
> since for a complex 2\times 2 matrix, there are 8 free variables, and
> for it to be unitary, there are four constraints (unit norm and
> orthogonality), hence I think there are four free variables left for a
> 2\times 2unitary matrix. The form I found can not decribe all the
> unitary matrix, that is why I suspect that it is not the most general
> one. The form in the second web you suggested is an interesting one,
> however, since only 3 variables invovled, it may not be the most
> general expression. 
> 
> Jing  
> 
> 
> On Sat, 13 Aug 2005 09:06:23 -0700
>  Spencer Graves <spencer.graves at pdf.com> wrote:
> 
>>	  Google led me to 
>>"http://mathworld.wolfram.com/SpecialUnitaryMatrix.html", where I 
>>learned that a "special unitary matrix" U has det(U) = 1 in addition
>>to 
>>the "unitary matrix" requirement that
>>
>>	  U %*% t(Conj(U)) == diag(dim(U)[1]).
>>
>>	  Thus, if U is a k x k unitary matrix with det(U) = exp(th*1i), 
>>exp(-th*1i/k)*U is a special unitary matrix.  Moreover, the special 
>>unitary matrices are a group under multiplication.
>>
>>	  Another Google query led me to  	 
>>"http://mathworld.wolfram.com/SpecialUnitaryGroup.html", which gives
>>a 
>>general expression for a special unitary matrix, which seems to
>>require 
>>three real numbers, not four;  with a fourth, you could get a general
>>
>>unitary matrix.
>>
>>	  spencer graves
>>
>>J. Liu wrote:
>>
>>
>>>Hi, all,
>>>
>>>Does anybody got the most general expression of a unitary matrix?
>>>I found one in the book, four entries of the matrix are:
>>> 
>>>(cos\theta) exp(j\alpha);     -(sin\theta)exp(j(\alpha-\Omega));
>>>(sin\theta)exp(j(\beta+\Omega));   (cos\theta) exp(j\beta);
>>> 
>>>where "j" is for complex. 
>>>However, since for any two unitary matrices, their product should
>>
>>also
>>
>>>be a unitary matrix. When I try to use the above expression to
>>>calculate the product, I can not derive the product into the same
>>
>>form.
>>
>>>Therefore, I suspect that this may not be the most general
>>
>>expression. 
>>
>>>Could you help me out of this? Thanks...
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>
>>http://www.R-project.org/posting-guide.html
>>
>>-- 
>>Spencer Graves, PhD
>>Senior Development Engineer
>>PDF Solutions, Inc.
>>333 West San Carlos Street Suite 700
>>San Jose, CA 95110, USA
>>
>>spencer.graves at pdf.com
>>www.pdf.com <http://www.pdf.com>
>>Tel:  408-938-4420
>>Fax: 408-280-7915
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
> 
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From jeaneid at chass.utoronto.ca  Sun Aug 14 18:05:42 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Sun, 14 Aug 2005 12:05:42 -0400
Subject: [R] Problem with numeric variable
In-Reply-To: <a31d08fd.2bb09e07.81b4200@expms2.cites.uiuc.edu>
Message-ID: <Pine.SGI.4.40.0508141205210.86788-100000@origin.chass.utoronto.ca>

can you give the line you are using to import the data.

On Sun, 14 Aug 2005 ftorrei2 at uiuc.edu wrote:

> Well, you were right. When I check with str() or summary(),
> the data frame appears as having a factor for that column.
> However, if I ask is.factor(C2), I get FALSE, and if I ask
> is.numeric(C2) I get TRUE. This seems strange.
> So I decided to reimport the dataframe, this time with NA as
> undefined values, and not ?. C2 was imported as a numeric
> variable, as checked with str() and is.numeric(). But I still
> get the indexes and not the values when I use C2 for any
> purpose, just as happened before. How can this be possible?
> All the other columns in the table behave properly.
> The only difference I see between this columns ans the others
> is that it contains NA values.
>
> Thanks again,
> Francisco Torreira
>
>
>
>
> ---- Original message ----
> >Date: Sun, 14 Aug 2005 10:11:15 +0100
> >From: Patrick Burns <pburns at pburns.seanet.com>
> >Subject: Re: [R] Problem with numeric variable
> >To: ftorrei2 at uiuc.edu
> >
> >I think your problem is that you have a factor rather
> >than a numeric vector (even though you say you checked
> >with 'is.numeric').  Missing values should be represented
> >by 'NA' and not by '?' which is what makes me think you
> >have a factor.
> >
> >Patrick Burns
> >patrick at burns-stat.com
> >+44 (0)20 8525 0696
> >http://www.burns-stat.com
> >(home of S Poetry and "A Guide for the Unwilling S User")
> >
> >ftorrei2 at uiuc.edu wrote:
> >
> >>Hello all,
> >>
> >>I posted a question some days ago without getting any answers,
> >>perhaps, as one of you kindly pointed out, because the
> >>question was not clearly stated. Let me reformulate it:
> >>In a frame, a column named C2 represents a numeric variable
> >>(checked with is.numeric(C2)). Some rows in the frame have an
> >>undefined value for C2, represented in the table by a ? sign.
> >>The remaining rows have numeric values with 2 decimals. For
> >>example, row 10 has 43.70 for C2, while row 1 has ?. The
> >>problem is that when I list C2 values (or when I try to plot
> >>them, etc), these values are not the ones that appeared in the
> >>table. Below are the first 3 lines of what I get when I list C2:
> >>
> >>
> >>>C2
> >>>
> >>>
> >>[1] 43 47 96 62 87 55 1 98 121 1 1 1 67 1 112 1 93 44
> >>[19] 85 569 52 110 126 95 92 60 36 383 373 298 274 406 208 175
> >>293 306
> >>[37] 305 172 134 115 94 84 104 99 64 271 269 310 268 359 443
> >>248 204 345
> >>
> >>These are not the correct values for C2, and I guess that they
> >>are just row numbers. How can I get the correct C2 values
> >>ready for analysis? Is this problem related to the fact that
> >>some rows have a ? value for C2?
> >>
> >>Thanks in advance,
> >>Francisco Torreira
> >>Francisco Torreira
> >>Spanish, Italian and Portuguese
> >>Univ. of Illinois at Urbana-Champaign
> >>707 South Mathews Aven.
> >>4031 FLB
> >>Urbana, IL, 61801
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >>
> >>
> >>
> >>
> >>
> >
> Francisco Torreira
> Spanish, Italian and Portuguese
> Univ. of Illinois at Urbana-Champaign
> 707 South Mathews Aven.
> 4031 FLB
> Urbana, IL, 61801
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From 10133msb at comb.es  Sun Aug 14 19:34:27 2005
From: 10133msb at comb.es (Manel Salamero)
Date: Sun, 14 Aug 2005 19:34:27 +0200
Subject: [R] path analysis
Message-ID: <200508141934.AA471204134@comb.es>

This solves part of my problem with the independent ordinal variables, but my dependent variable is truly categorial (illness/no illness). Polychoric correlation implies that data are continuous, which in not the case. Is possible to implement logistic regression in the path model?

Thanks,

Manel Salamero

---------- Original Message ----------------------------------
De: "John Fox" <jfox at mcmaster.ca>
Data:  Sat, 13 Aug 2005 19:35:24 -0400

Dear Manel,

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> SALAMERO BARO, MANUEL
> Sent: Saturday, August 13, 2005 2:02 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] path analysis
> 
> Someone knows if it is possible to perform a path analysis 
> with sem package (or any other) to explain a dependent 
> *dichotomus* variable?
> 

Yes -- you can use the hetcor() function in the polycor package to generate
a correlation matrix and boot.sem() in the sem package to get standard
errors or confidence intervals. Make sure that the dichotomous variables are
represented as factors. See ?boot.sem for an example.

I hope this helps,
 John



From jfox at mcmaster.ca  Sun Aug 14 20:33:40 2005
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 14 Aug 2005 14:33:40 -0400
Subject: [R] path analysis
In-Reply-To: <200508141934.AA471204134@comb.es>
Message-ID: <20050814183340.LGAK26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>

Dear Manuel,

Polychoric correlations imply only that the *latent* variables are
continuous -- the observed variables are ordered categories. Tetrachoric and
point-biserial correlations are special cases respectively of polychoric and
polyserial correlations. As long as you're willing to think of the
dichotomous variable as the dissection into two categories of a latent
continuous variable (and assuming multinormality of the latent variables),
you can use the approach that I suggested. This isn't logistic regression,
but it's similar to a probit model.

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Manel Salamero
> Sent: Sunday, August 14, 2005 12:34 PM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] path analysis
> 
> This solves part of my problem with the independent ordinal 
> variables, but my dependent variable is truly categorial 
> (illness/no illness). Polychoric correlation implies that 
> data are continuous, which in not the case. Is possible to 
> implement logistic regression in the path model?
> 
> Thanks,
> 
> Manel Salamero
> 
> ---------- Original Message ----------------------------------
> De: "John Fox" <jfox at mcmaster.ca>
> Data:  Sat, 13 Aug 2005 19:35:24 -0400
> 
> Dear Manel,
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> SALAMERO BARO, 
> > MANUEL
> > Sent: Saturday, August 13, 2005 2:02 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] path analysis
> > 
> > Someone knows if it is possible to perform a path analysis with sem 
> > package (or any other) to explain a dependent
> > *dichotomus* variable?
> > 
> 
> Yes -- you can use the hetcor() function in the polycor 
> package to generate
> a correlation matrix and boot.sem() in the sem package to get standard
> errors or confidence intervals. Make sure that the 
> dichotomous variables are
> represented as factors. See ?boot.sem for an example.
> 
> I hope this helps,
>  John
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Sun Aug 14 20:51:39 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 14 Aug 2005 11:51:39 -0700
Subject: [R] General expression of a unitary matrix
In-Reply-To: <web-101162541@cgpsrv2.cis.mcmaster.ca>
References: <web-101162541@cgpsrv2.cis.mcmaster.ca>
Message-ID: <42FF92BB.2070906@pdf.com>

	  Below please find functions that attempt to test for whether a matrix 
is unitary and special unitary (SU) and generate an SU matrix from a 
3-vector and convert a 2x2 SU matrix to a 3-vector.  These are not 
extensively debugged, so they may not be correct.  However, they passed 
a few simple tests, including the following:

	  SU2.4 <- SU2(1:3)%*%SU2(2:4)
	  all.equal(SU2.4, SU2(Re(SU2.vec(SU2.4))))

	  An SU2 matrix has lots of structure.  I computed xi from the ratio of 
the diagonals and zeta from the ratio of the off-diagonals.  Then I used 
those to compute eta = atan(x[1,2]/exp(zeta*1i), x[1,1]/exp(xi*1i)).

	  If you find a counter example, please post it to the list;  maybe 
someone will fix it or explain why Wolfram was wrong.  If you clean up 
the functions I wrote, e.g, adding checks and returning only the real 
part of the 3-vector, etc., please post that to the list.

	  spencer graves
######################################
is.unitary <- function(x,
        eps=prod(dim(x))*.Machine$double.eps){
   x2 <- (x %*% t(Conj(x)))
   (abs(mean(x2-diag(dim(x)[1])))
       < eps)
}

is.unitary(diag(3)+1e-15)
is.unitary(diag(3)+1e-16)

is.SU <- function(x,
        eps=prod(dim(x))*.Machine$double.eps){
   if(is.unitary(x, eps)){
     eig.x <- eigen(x)
     det.x <- prod(eig.x$values)
     return(abs(det.x-1)<eps)
   }
   else FALSE
}

is.SU(diag(3)+1e-15)
is.SU(diag(3)+1e-16)

SU2 <- function(x){
# x = c(xi, eta, zeta)
   eix <- exp(1i*x[1])
   eiz <- exp(1i*x[3])
   su2 <- array(NA, dim=c(2,2))
   diag(su2) <- (c(eix, Conj(eix))*
             cos(x[2]))
   seta <- sin(x[2])
   su2[1,2] <- eiz*seta
   su2[2,1] <- (-Conj(eiz)*seta)
   su2
}

SU2(1:3)
is.SU(SU2(1:3))

is.SU(SU2(1:3)%*%SU2(2:4))

SU2.vec <- function(x,
        eps=prod(dim(x))*.Machine$double.eps){
   xi <- (log(x[1,1]/x[2,2])/(2i))
   zeta <- (log(-x[1,2]/x[2,1])/(2i))
#
   eixi <- exp(xi*1i)
   eizeta <- exp(zeta*1i)
   eta1 <- atan(x[1,2]/eizeta,
                x[1,1]/eixi )
#  eta2 <- atan(-x[2,1]/eizeta,
#               x[2,2]/eixi)
   vec <- c(xi, eta1, zeta)
   vec
}

x <- SU2(1:3)

SU2.4 <- SU2(1:3)%*%SU2(2:4)


SU2.vec(SU2.4)

SU2.4
all.equal(SU2.4,
SU2(SU2.vec(SU2.4)))

all.equal(SU2.4,
SU2(Re(SU2.vec(SU2.4))))

SU2.vec(SU2(1:3))

######################################
Yeah. Let U=U_1*U_2' where U_1 and U_2 are unitary in that form. My
objection is to write U in that form too. However, I can not find a way
to do it.

On Sun, 14 Aug 2005 09:05:19 -0700
#########################
	  Could you provide an example that can NOT be expressed in that form?

	  spencer graves

J. Liu wrote:

> Thank you, Spencer. I read through the websites you suggested. What I
> need is how to parameterize a 2\times 2 unitary matrix. Generally,
> since for a complex 2\times 2 matrix, there are 8 free variables, and
> for it to be unitary, there are four constraints (unit norm and
> orthogonality), hence I think there are four free variables left for a
> 2\times 2unitary matrix. The form I found can not decribe all the
> unitary matrix, that is why I suspect that it is not the most general
> one. The form in the second web you suggested is an interesting one,
> however, since only 3 variables invovled, it may not be the most
> general expression. 
> 
> Jing  
> 
> 
> On Sat, 13 Aug 2005 09:06:23 -0700
>  Spencer Graves <spencer.graves at pdf.com> wrote:
> 
>>	  Google led me to 
>>"http://mathworld.wolfram.com/SpecialUnitaryMatrix.html", where I 
>>learned that a "special unitary matrix" U has det(U) = 1 in addition
>>to 
>>the "unitary matrix" requirement that
>>
>>	  U %*% t(Conj(U)) == diag(dim(U)[1]).
>>
>>	  Thus, if U is a k x k unitary matrix with det(U) = exp(th*1i), 
>>exp(-th*1i/k)*U is a special unitary matrix.  Moreover, the special 
>>unitary matrices are a group under multiplication.
>>
>>	  Another Google query led me to  	 
>>"http://mathworld.wolfram.com/SpecialUnitaryGroup.html", which gives
>>a 
>>general expression for a special unitary matrix, which seems to
>>require 
>>three real numbers, not four;  with a fourth, you could get a general
>>
>>unitary matrix.
>>
>>	  spencer graves
>>
>>J. Liu wrote:
>>
>>
>>>Hi, all,
>>>
>>>Does anybody got the most general expression of a unitary matrix?
>>>I found one in the book, four entries of the matrix are:
>>> 
>>>(cos\theta) exp(j\alpha);     -(sin\theta)exp(j(\alpha-\Omega));
>>>(sin\theta)exp(j(\beta+\Omega));   (cos\theta) exp(j\beta);
>>> 
>>>where "j" is for complex. 
>>>However, since for any two unitary matrices, their product should
>>
>>also
>>
>>>be a unitary matrix. When I try to use the above expression to
>>>calculate the product, I can not derive the product into the same
>>
>>form.
>>
>>>Therefore, I suspect that this may not be the most general
>>
>>expression. 
>>
>>>Could you help me out of this? Thanks...
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>
>>http://www.R-project.org/posting-guide.html
>>
>>-- 
>>Spencer Graves, PhD
>>Senior Development Engineer
>>PDF Solutions, Inc.
>>333 West San Carlos Street Suite 700
>>San Jose, CA 95110, USA
>>
>>spencer.graves at pdf.com
>>www.pdf.com <http://www.pdf.com>
>>Tel:  408-938-4420
>>Fax: 408-280-7915
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
> 
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From fcsaszar at gmail.com  Sun Aug 14 21:06:45 2005
From: fcsaszar at gmail.com (Felipe Csaszar)
Date: Sun, 14 Aug 2005 15:06:45 -0400
Subject: [R] complex expression with plotmath
In-Reply-To: <971536df050814082473de6326@mail.gmail.com>
References: <f6eb7d54050814014050ee2302@mail.gmail.com>
	<971536df050814082473de6326@mail.gmail.com>
Message-ID: <f6eb7d5405081412061f047a1b@mail.gmail.com>

Thanks, it worked!

So the cute trick was the call to *quote* inside the function call.

Thanks again,

Felipe



On 8/14/05, Gabor Grothendieck <ggrothendieck at gmail.com> wrote:
> On 8/14/05, Felipe Csaszar <fcsaszar at gmail.com> wrote:
> > Hello everyone,
> >
> > I want to define a function that receives the name of two variables
> > (may include Greek letters and subscripts) and uses them into the
> > title of a plot.
> >
> > My best attempt is the following:
> > myplot <- function(var1, var2) {
> >    v=paste(var1,"==1 & ",var2,"==2");
> >    plot(1:10, main=parse(,,v))
> > }
> >
> > But when I call it with something like myplot("Q[i]", "Delta[j]") I
> > get "&(Q_i=1,Delta_j=2)" as title when I want to get "Q_i=1 &
> > Delta_j=2".
> >
> > Is there any solution within R? (I don't want to use psfrag and Latex
> > to post-process the plot)
> >
> > Why R does not have support for full Latex expressions? (as Matlab
> > f.ex.). IMHO plotmath is not good enough.
> >
> 
> Try this:
> 
> 
> myplot <- function(var1, var2)
>         plot(1:10, main = bquote(.(var1) == 1 ~ "&" ~ .(var2) == 2))
> myplot(quote(Q[i]), quote(Delta[j]))
>



From cobleigh at gmail.com  Sun Aug 14 21:47:04 2005
From: cobleigh at gmail.com (Jamieson Cobleigh)
Date: Sun, 14 Aug 2005 15:47:04 -0400
Subject: [R] Labels on axes with log scales with lattice
Message-ID: <7f50836c0508141247153bf360@mail.gmail.com>

I using lattice to make some plots and I want to make the y-axis on
some of these plots use a log scale.  In the following plot:

x <- 1:10
y <- 2^x
xyplot(log10(y) ~ x)

I get tick marks on the y-axis at 0.5, 1.0, 1.5, 2.0, 2.5, and 3.0.  I
would rather have just 3 tick marks at 1.0, 2.0, and 3.0 but labeled
10, 100, and 1000.

I know this can be done using the "at" and "labels" parameters to the
"x" parameter to the "scales" parameter to the "xyplot" command.

xyplot(log10(y) ~ x, scales=list(y=list(at=c(1, 2, 3), labels=c(10,
100, 1000))))

My problem is that I am making multiple plots and cannot set the
labels on each plot individually.  I need to automate the computation
of the "at" and "labels" parameters.  I think the "axTicks" command
can compute the information I need to set "at" and "labels" correctly,
but I am having trouble determining how to set its parameters to make
it compute the information I need.  Perhaps "pretty" might work to,
but "axTicks" seems better designed for handling logarithmic axes.

Does anyone have any suggestions?

Thanks in advance!

Jamie



From jfox at mcmaster.ca  Sun Aug 14 23:20:36 2005
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 14 Aug 2005 17:20:36 -0400
Subject: [R] path analysis
In-Reply-To: <20050814183340.LGAK26550.tomts20-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <20050814212036.VSWP16985.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Manuel and list,

I see that I wrote "point-biserial" when I meant "biserial."

Sorry,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of John Fox
> Sent: Sunday, August 14, 2005 1:34 PM
> To: 10133msb at comb.es
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] path analysis
> 
> Dear Manuel,
> 
> Polychoric correlations imply only that the *latent* 
> variables are continuous -- the observed variables are 
> ordered categories. Tetrachoric and point-biserial 
> correlations are special cases respectively of polychoric and 
> polyserial correlations. As long as you're willing to think 
> of the dichotomous variable as the dissection into two 
> categories of a latent continuous variable (and assuming 
> multinormality of the latent variables), you can use the 
> approach that I suggested. This isn't logistic regression, 
> but it's similar to a probit model.
> 
> Regards,
>  John
> 
> --------------------------------
> John Fox
> Department of Sociology
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> 905-525-9140x23604
> http://socserv.mcmaster.ca/jfox
> -------------------------------- 
> 
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch 
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Manel Salamero
> > Sent: Sunday, August 14, 2005 12:34 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: Re: [R] path analysis
> > 
> > This solves part of my problem with the independent ordinal 
> variables, 
> > but my dependent variable is truly categorial (illness/no illness). 
> > Polychoric correlation implies that data are continuous, 
> which in not 
> > the case. Is possible to implement logistic regression in the path 
> > model?
> > 
> > Thanks,
> > 
> > Manel Salamero
> > 
> > ---------- Original Message ----------------------------------
> > De: "John Fox" <jfox at mcmaster.ca>
> > Data:  Sat, 13 Aug 2005 19:35:24 -0400
> > 
> > Dear Manel,
> > 
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch 
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of
> > SALAMERO BARO,
> > > MANUEL
> > > Sent: Saturday, August 13, 2005 2:02 PM
> > > To: r-help at stat.math.ethz.ch
> > > Subject: [R] path analysis
> > > 
> > > Someone knows if it is possible to perform a path 
> analysis with sem 
> > > package (or any other) to explain a dependent
> > > *dichotomus* variable?
> > > 
> > 
> > Yes -- you can use the hetcor() function in the polycor package to 
> > generate a correlation matrix and boot.sem() in the sem 
> package to get 
> > standard errors or confidence intervals. Make sure that the 
> > dichotomous variables are represented as factors. See 
> ?boot.sem for an 
> > example.
> > 
> > I hope this helps,
> >  John
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From w.northcott at unsw.edu.au  Mon Aug 15 01:55:59 2005
From: w.northcott at unsw.edu.au (Bill Northcott)
Date: Mon, 15 Aug 2005 09:55:59 +1000
Subject: [R]  Including Fortran subrutines in a package
In-Reply-To: <mailman.9.1124013600.13283.r-help@stat.math.ethz.ch>
References: <mailman.9.1124013600.13283.r-help@stat.math.ethz.ch>
Message-ID: <142A1603-7E6F-4309-9ADA-377200D127BD@unsw.edu.au>

On 14/08/2005, at 8:00 PM, r-help-request at stat.math.ethz.ch wrote:
> I am creating a packege and I would like to inclued some Fortrun  
> subrutines.
> I have two questions.
> 1. Can I use "free form fortan" - compiles well usinf g77 -ffree-form.
> 2. Is it enough to place the ".for" files in scr folder?

gcc Fortran is in the process of moving from g77 which goes with  
gcc-3.x to gfortran which goes with gcc-4.x.

AFAIK -ffree-form is the default for g77 but not for gfortran if the  
source file has the .f .for extensions.  Free form is the default  
for .f90 .f95 extensions.  So maybe
1. include the -ffree-form option so that thing will not break with  
gfortran.
2. don't assume the gcc Fortran compiler is g77.

Bill Northcott



From alanzhao at gmail.com  Mon Aug 15 02:57:52 2005
From: alanzhao at gmail.com (Alan Zhao)
Date: Sun, 14 Aug 2005 17:57:52 -0700
Subject: [R] PCA problem in R
In-Reply-To: <1124030772.42ff59348c387@zeppo.wmin.ac.uk>
References: <ddmjmp$j5j$1@sea.gmane.org>	<Pine.LNX.4.61.0508140714210.22738@gannet.stats>
	<1124030772.42ff59348c387@zeppo.wmin.ac.uk>
Message-ID: <ddopak$jom$1@sea.gmane.org>

R.P.Clement at westminster.ac.uk wrote:
> Hi. I have two comments on this.
> 
> Quoting Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> 
> 
>>On Sat, 13 Aug 2005, Alan Zhao wrote:
>>
>>
>>>When I have more variables than units, say a 195*10896 matrix which has
>>>10896 variables and 195 samples. prcomp will give only 195 principal
>>>components. I checked in the help, but there is no explanation that why
>>>this happen.
>>
>>There is not even a definition of a PC in the help. Did you read the
>>references?  This is what they are given for!
> 
> 
> I don't know if it's too simple and introductory for the OP, but I quite like
> Lindsay Smith's intro to PCA.
> 
> http://www.cs.otago.ac.nz/cosc453/student_tutorials/principal_components.pdf
It is a very good tutorial. Thank you very much for your help.

Sincerely,
Zheng Zhao
Aug-14-2005



From hodgess at gator.dt.uh.edu  Mon Aug 15 03:29:24 2005
From: hodgess at gator.dt.uh.edu (Erin Hodgess)
Date: Sun, 14 Aug 2005 20:29:24 -0500
Subject: [R]  lme, fixed and random
Message-ID: <200508150129.j7F1TOvF022720@gator.dt.uh.edu>

Dear R People:

I need to set up an lme.  I have logratio as my response var,
range, and I(range^2) as the fixed variables.

The random effects vars are xa1 through xa24.

How do I set up the lme statement, please?

I tried with 
lme(logratio ~ range + I(range^2), random=fmla)

is an as.formula statement with the xa1 throught xa24 var with a leading

Any suggestions, please


Thanks,
Erin Hodgess
mailto: hodgess at gator.uhd.edu



From spencer.graves at pdf.com  Mon Aug 15 04:31:28 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 14 Aug 2005 19:31:28 -0700
Subject: [R] lme, fixed and random
In-Reply-To: <200508150129.j7F1TOvF022720@gator.dt.uh.edu>
References: <200508150129.j7F1TOvF022720@gator.dt.uh.edu>
Message-ID: <42FFFE80.2050905@pdf.com>

lme(logratio ~ range + I(range^2), random=~1|fmla, 
data=data.frame.contianing.range.and.fmla)

spencer graves
p.s.  I highly recommend Pinheiro and Bates (2000) Mixed-Effects Models 
in S and S-Plus (Springer).

Erin Hodgess wrote:

> Dear R People:
> 
> I need to set up an lme.  I have logratio as my response var,
> range, and I(range^2) as the fixed variables.
> 
> The random effects vars are xa1 through xa24.
> 
> How do I set up the lme statement, please?
> 
> I tried with 
> lme(logratio ~ range + I(range^2), random=fmla)
> 
> is an as.formula statement with the xa1 throught xa24 var with a leading
> 
> Any suggestions, please
> 
> 
> Thanks,
> Erin Hodgess
> mailto: hodgess at gator.uhd.edu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From p.dalgaard at biostat.ku.dk  Mon Aug 15 05:18:20 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 15 Aug 2005 05:18:20 +0200
Subject: [R] R/S-Plus/SAS yield different results for Kendall-tau and
	Spearman nonparametric regression
In-Reply-To: <7FB06B66-58EB-4909-84F7-FE3F73B13B6A@plessthan.com>
References: <7FB06B66-58EB-4909-84F7-FE3F73B13B6A@plessthan.com>
Message-ID: <x2wtmnubur.fsf@turmalin.kubism.ku.dk>

Dennis Fisher <fisher at plessthan.com> writes:

> Colleagues,
> I ran some nonparametric regressions in R (run in RedHat Linux), then  
> a colleague repeated the analyses in SAS.  When we obtained different  
> results, I tested S-Plus (same Linux box).  And, got yet different  
> results.  I replicated the results with a small dataset:
> 
> DATA:
 (They came across somewhat garbled, but we'll believe you...)

...

> Each of the programs yields some differences, possibly because of how  
> ties are handled (R warns about this).  Can anyone enlighten me?

Ties are certainly involved in the Spearman case. There are more
accurate expressions for the variance of the test statistic in the
tied case, than the formula that R is using. As you see, the
difference is not exactly huge (at least for a small number of ties),
but it is something that we should get around to fixing.

I assume that there is a similar issue with Kendall's tau. In
addition, S-PLUS appears to modify the actual definition of the test
statistic, which might be a matter of taste. (K's tau relies
on counting concordant and discordant pairs relative to the total
number of pairs, and with ties, some pairs will be undecided. You can
either discard such pairs or count them as zeros. S-PLUS appears to be
doing the latter. A quick test is to notice that  x <- y <- rep(0:1,4)
gives a tau that is less than 1 in S-PLUS but gives 1 in R.)

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From tkremund98 at hotmail.com  Mon Aug 15 07:12:42 2005
From: tkremund98 at hotmail.com (Todd Remund)
Date: Sun, 14 Aug 2005 23:12:42 -0600
Subject: [R] Vector comparison to matrix
Message-ID: <BAY18-F9E3F0B10E871F7FFD6674D4B10@phx.gbl>

I am looking for a fast way to count the number of rows in a matrix are 
identical to a pattern vector.  For example, if I am interested in counting 
the number of row vectors in a matrix that are identical to (1,2,3) what 
would I do?  I have tried the identical statement in a loop but this is far 
too slow.  I have a very large matrix and need to avoid loops at all costs.  
Thanks for any help.
Todd Remund



From jonathenwu at hotmail.com  Sat Aug 13 10:14:46 2005
From: jonathenwu at hotmail.com (=?gb2312?B?zuIg6rs=?=)
Date: Sat, 13 Aug 2005 08:14:46 +0000
Subject: [R] scratch a figure
Message-ID: <BAY105-F3234F0F691B65E511506B0D0BF0@phx.gbl>

Hi,
I have generated a figure using rgl.surface(),how can I scratch this 
figure? thanks a lot.
regards
Hao Wu



From pcovelli at alice.it  Mon Aug 15 00:17:40 2005
From: pcovelli at alice.it (Paolo Covelli)
Date: Mon, 15 Aug 2005 00:17:40 +0200
Subject: [R] R for symbian
Message-ID: <002a01c5a11d$fc156030$0201a8c0@DHN2FN1J>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050815/8b23c743/attachment.pl

From mmiller at nassp.uct.ac.za  Thu Aug 11 10:51:46 2005
From: mmiller at nassp.uct.ac.za (Mark Miller)
Date: Thu, 11 Aug 2005 10:51:46 +0200
Subject: [R] Using nonlinear regression
In-Reply-To: <5537091C-6831-4C7B-80EF-4EB34F78A1BC@wisc.edu>
References: <200508041257.21030.mmiller@nassp.uct.ac.za>
	<5537091C-6831-4C7B-80EF-4EB34F78A1BC@wisc.edu>
Message-ID: <200508111051.46559.mmiller@nassp.uct.ac.za>

Attached is a copy of my code, the data and the plots obtained by varying 
terms manually, I was told that nonlinear regression in R could find the 
values for me, but I am unable to figure how exactly I could implement this.  
Any help would be very greatly appreciated as I am completely stuck on this 
problem.


On Thursday 04 August 2005 13:40, you wrote:
> It might be good to have an example of your problem.
>
> On Aug 4, 2005, at 5:57 AM, Mark Miller wrote:
> > Hi, I have been trying to figure out how to use the nonlinear
> > regression to
> > fit the cumulative lognormal distribution to a number of data
> > points I have
> > but I am a new R user and I cant quite decipher the notes on nonlinear
> > regression.  Any help in this regard will be greatly appreciated,
> > my email
> > address is mmiller at nassp.uct.ac.za
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-
> > guide.html
-------------- next part --------------
A non-text attachment was scrubbed...
Name: cumIAT.ps
Type: application/postscript
Size: 47024 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20050811/3e2bdc83/cumIAT.ps
-------------- next part --------------
A non-text attachment was scrubbed...
Name: cumTFR.ps
Type: application/postscript
Size: 13981 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20050811/3e2bdc83/cumTFR.ps
-------------- next part --------------
A non-text attachment was scrubbed...
Name: cumTTR.ps
Type: application/postscript
Size: 35507 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20050811/3e2bdc83/cumTTR.ps
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Rstuff.R
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050811/3e2bdc83/Rstuff.pl

From ripley at stats.ox.ac.uk  Mon Aug 15 08:42:59 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Aug 2005 07:42:59 +0100 (BST)
Subject: [R] Vector comparison to matrix
In-Reply-To: <BAY18-F9E3F0B10E871F7FFD6674D4B10@phx.gbl>
References: <BAY18-F9E3F0B10E871F7FFD6674D4B10@phx.gbl>
Message-ID: <Pine.LNX.4.61.0508150739170.19359@gannet.stats>

Probably you use the idea from unique.matrix, that is

1) form a string from each row and
2) call match() to see which strings match your pattern row.

On Sun, 14 Aug 2005, Todd Remund wrote:

> I am looking for a fast way to count the number of rows in a matrix are
> identical to a pattern vector.  For example, if I am interested in counting
> the number of row vectors in a matrix that are identical to (1,2,3) what
> would I do?  I have tried the identical statement in a loop but this is far
> too slow.  I have a very large matrix and need to avoid loops at all costs.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dieter.menne at menne-biomed.de  Mon Aug 15 08:47:33 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Mon, 15 Aug 2005 06:47:33 +0000 (UTC)
Subject: [R] scratch a figure
References: <BAY105-F3234F0F691B65E511506B0D0BF0@phx.gbl>
Message-ID: <loom.20050815T084558-680@post.gmane.org>

<jonathenwu <at> hotmail.com> writes:

> I have generated a figure using rgl.surface(),how can I scratch this 
> figure? thanks a lot.

Assuming you mean "print": Try rgl.snapshot, which produces a png file that can 
be printed by any standard paint program.

Dieter



From mcclatchie.sam at saugov.sa.gov.au  Mon Aug 15 09:27:12 2005
From: mcclatchie.sam at saugov.sa.gov.au (McClatchie, Sam (PIRSA-SARDI))
Date: Mon, 15 Aug 2005 16:57:12 +0930
Subject: [R] return unique values from date/time class object
Message-ID: <BEA6A7E18959A04385DC14D24619F89F01D73C1D@sagemsg0008.sagemsmrd01.sa.gov.au>

Background:
OS: Linux Mandrake 10.1
release: R 2.0.0
editor: GNU Emacs 21.3.2
front-end: ESS 5.2.3
---------------------------------
Colleagues

I have a  wind speed time series with a normal frequency distribution and a
spike in the 5 metres/second bin. The most likely explanation is that the
instrument was returning duplicate values at this speed. To check  this, I
want to extract all the unique times from the series. However, unique()
works with vectors and the object is POSIXt class. I've looked for a similar
function to unique() that will work with this class, but have failed to find
one.

Any suggestions?

Thanks

Sam
----
Sam McClatchie,
Biological oceanography 
South Australian Aquatic Sciences Centre
PO Box 120, Henley Beach 5022
Adelaide, South Australia
email <mcclatchie.sam at saugov.sa.gov.au>
Cellular: 0431 304 497 
Telephone: (61-8) 8207 5448
FAX: (61-8) 8207 5481
Research home page <http://www.members.iinet.net.au/~s.mcclatchie/>
  
                   /\
      ...>><xX(??> 
                //// \\\\
                   <??)Xx><<
              /////  \\\\\\
                        ><(((??> 
  >><(((??>   ...>><xX(??>O<??)Xx><<



From ripley at stats.ox.ac.uk  Mon Aug 15 09:33:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Aug 2005 08:33:50 +0100 (BST)
Subject: [R] Vector comparison to matrix
In-Reply-To: <Pine.LNX.4.61.0508150739170.19359@gannet.stats>
References: <BAY18-F9E3F0B10E871F7FFD6674D4B10@phx.gbl>
	<Pine.LNX.4.61.0508150739170.19359@gannet.stats>
Message-ID: <Pine.LNX.4.61.0508150829020.22285@gannet.stats>

On Mon, 15 Aug 2005, Prof Brian Ripley wrote:

> Probably you use the idea from unique.matrix, that is
>
> 1) form a string from each row and
> 2) call match() to see which strings match your pattern row.

If your matrix A really does have short rows like c(1,2,3) and millions of 
them, another idea is to do

target <- rep(c(1,2,3), each= nrow(A))
rowSums(A != target) == 0

For wider rows my first suggestion is probably faster.

> On Sun, 14 Aug 2005, Todd Remund wrote:
>
>> I am looking for a fast way to count the number of rows in a matrix are
>> identical to a pattern vector.  For example, if I am interested in counting
>> the number of row vectors in a matrix that are identical to (1,2,3) what
>> would I do?  I have tried the identical statement in a loop but this is far
>> too slow.  I have a very large matrix and need to avoid loops at all costs.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From petr.pikal at precheza.cz  Mon Aug 15 10:10:29 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 15 Aug 2005 10:10:29 +0200
Subject: [R] return unique values from date/time class object
In-Reply-To: <BEA6A7E18959A04385DC14D24619F89F01D73C1D@sagemsg0008.sagemsmrd01.sa.gov.au>
Message-ID: <43006A15.8845.3104E3@localhost>

Hi Sam

It works for me:

ss<-Sys.time()
sss<-rep(ss,5)
ss<-Sys.time()
sss<-c(sss,ss)
> sss
[1] "2005-08-15 10:04:02 St??edn?? Evropa (letn?? ??as)" "2005-08-15 
10:04:02 St??edn?? Evropa (letn?? ??as)"
[3] "2005-08-15 10:04:02 St??edn?? Evropa (letn?? ??as)" "2005-08-15 
10:04:02 St??edn?? Evropa (letn?? ??as)"
[5] "2005-08-15 10:04:02 St??edn?? Evropa (letn?? ??as)" "2005-08-15 
10:04:35 St??edn?? Evropa (letn?? ??as)"

# six values but only 2 different

> unique(sss)
[1] "2005-08-15 10:04:02 St??edn?? Evropa (letn?? ??as)" "2005-08-15 
10:04:35 St??edn?? Evropa (letn?? ??as)"

# 2 values

> str(sss)
'POSIXct', format: chr [1:6] "2005-08-15 10:04:02" "2005-08-15 
10:04:02" "2005-08-15 10:04:02" "2005-08-15 10:04:02" "2005-
08-15 10:04:02" ...

# posix format as well

HTH
Petr





On 15 Aug 2005 at 16:57, McClatchie, Sam (PIRSA-SARDI) wrote:

> Background:
> OS: Linux Mandrake 10.1
> release: R 2.0.0
> editor: GNU Emacs 21.3.2
> front-end: ESS 5.2.3
> ---------------------------------
> Colleagues
> 
> I have a  wind speed time series with a normal frequency distribution
> and a spike in the 5 metres/second bin. The most likely explanation is
> that the instrument was returning duplicate values at this speed. To
> check  this, I want to extract all the unique times from the series.
> However, unique() works with vectors and the object is POSIXt class.
> I've looked for a similar function to unique() that will work with
> this class, but have failed to find one.
> 
> Any suggestions?
> 
> Thanks
> 
> Sam
> ----
> Sam McClatchie,
> Biological oceanography 
> South Australian Aquatic Sciences Centre
> PO Box 120, Henley Beach 5022
> Adelaide, South Australia
> email <mcclatchie.sam at saugov.sa.gov.au>
> Cellular: 0431 304 497 
> Telephone: (61-8) 8207 5448
> FAX: (61-8) 8207 5481
> Research home page <http://www.members.iinet.net.au/~s.mcclatchie/>
> 
>                    /\
>       ...>><xX(??> 
>                 //// \\\\
>                    <??)Xx><<
>               /////  \\\\\\
>                         ><(((??> 
>   >><(((??>   ...>><xX(??>O<??)Xx><<
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From ripley at stats.ox.ac.uk  Mon Aug 15 10:39:43 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Aug 2005 09:39:43 +0100 (BST)
Subject: [R] return unique values from date/time class object
In-Reply-To: <BEA6A7E18959A04385DC14D24619F89F01D73C1D@sagemsg0008.sagemsmrd01.sa.gov.au>
References: <BEA6A7E18959A04385DC14D24619F89F01D73C1D@sagemsg0008.sagemsmrd01.sa.gov.au>
Message-ID: <Pine.LNX.4.61.0508150936050.23063@gannet.stats>

On Mon, 15 Aug 2005, McClatchie, Sam (PIRSA-SARDI) wrote:

> Background:
> OS: Linux Mandrake 10.1
> release: R 2.0.0

Time for an update.

> editor: GNU Emacs 21.3.2
> front-end: ESS 5.2.3
> ---------------------------------
> Colleagues
>
> I have a  wind speed time series with a normal frequency distribution and a
> spike in the 5 metres/second bin. The most likely explanation is that the
> instrument was returning duplicate values at this speed. To check  this, I
> want to extract all the unique times from the series. However, unique()
> works with vectors and the object is POSIXt class. I've looked for a similar
> function to unique() that will work with this class, but have failed to find
> one.

foo[!duplicated(unclass(foo))]

works, for POSIXct (POSIXt is a virtual class covering that and POSIXlt: 
for the latter convert to POSIXct).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From peter at fe.up.pt  Mon Aug 15 12:55:51 2005
From: peter at fe.up.pt (Peter Ho)
Date: Mon, 15 Aug 2005 11:55:51 +0100
Subject: [R] Problem with lme4
In-Reply-To: <40e66e0b050812062913d202ab@mail.gmail.com>
References: <42FC882F.90101@fe.up.pt>
	<40e66e0b050812062913d202ab@mail.gmail.com>
Message-ID: <430074B7.4000303@fe.up.pt>

I did as you suggested by just running just R (--vanilla) and that 
seemed to work. Not sure what the problem was though.

Thanks

Peter

Douglas Bates wrote:

>On 8/12/05, Peter Ho <peter at fe.up.pt> wrote:
>  
>
>>Hi,
>>
>>I cannot seem to get lme4 to work. I have installed the lme4 and Matrix
>>package with apt-get. and both can be found in /usr/lib/R/site-library.
>>When I tried an example for lmer, R could not find the function lmer(),
>>    
>>
>
>Try using
>
>install.packages("Matrix")
>install.packages("lme4")
>
>in R instead.  I have not created and uploaded new Debian packages of
>the lme4 and Matrix R packages for several weeks.  The versions on
>CRAN are more recent than the versions on the Debian archives.
>
>  
>
>> > library(lme4)
>>
>>Attaching package: 'lme4'
>>
>>
>>        The following object(s) are masked from package:nlme :
>>
>>         getCovariateFormula getResponseFormula groupedData
>>
>>Error in autoloader(name = "confint", package = "MASS") :
>>        autoloader did not find 'confint' in 'MASS'
>>    
>>
>
>Try not to have the nlme and the lme4 packages loaded simultaneously. 
>It appears that you may have had Rcmdr loaded causing many of the
>other packages to be loaded.  It would be better to use --vanilla in
>the call to R and keep the number of loaded packages to a minimum
>until you can work out the problem of where lmer can be found.
>
>It is a bit confusing.  The lmer function was in the lme4 package but
>now is in the Matrix package.
>  
>
>> > (fm1 <- lmer(decrease ~ treatment + (1|rowpos) + (1|colpos),
>>+              OrchardSprays))
>>Error: couldn't find function "lmer"
>> >
>>
>>Is this a bug with the lme4 package for Debian (r-cran-lme4)?
>>
>>
>>Peter
>>
>>
>>
>>#########################
>>R : Copyright 2005, The R Foundation for Statistical Computing
>>Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0
>>
>>R is free software and comes with ABSOLUTELY NO WARRANTY.
>>You are welcome to redistribute it under certain conditions.
>>Type 'license()' or 'licence()' for distribution details.
>>
>>  Natural language support but running in an English locale
>>
>>R is a collaborative project with many contributors.
>>Type 'contributors()' for more information and
>>'citation()' on how to cite R or R packages in publications.
>>
>>Type 'demo()' for some demos, 'help()' for on-line help, or
>>'help.start()' for a HTML browser interface to help.
>>Type 'q()' to quit R.
>>
>>Loading Tcl/Tk interface ... done
>>Loading required package: tcltk
>>Loading required package: rgl
>>Loading required package: zoo
>>Loading required package: strucchange
>>Loading required package: sandwich
>>Loading required package: relimp
>>Loading required package: nnet
>>Loading required package: graphics
>>Loading required package: grDevices
>>Loading required package: stats
>>Loading required package: nlme
>>
>>Attaching package: 'nlme'
>>
>>
>>        The following object(s) are masked from package:stats :
>>
>>         contr.SAS
>>
>>Loading required package: mvtnorm
>>Loading required package: multcomp
>>Loading required package: mgcv
>>This is mgcv 1.2-4
>>Loading required package: MASS
>>Loading required package: lmtest
>>Loading required package: lattice
>>Loading required package: grid
>>Loading required package: foreign
>>Loading required package: effects
>>Loading required package: car
>>Loading required package: abind
>>[Previously saved workspace restored]
>>
>> > library(Matrix)
>> > library(lme4)
>>
>>Attaching package: 'lme4'
>>
>>
>>        The following object(s) are masked from package:nlme :
>>
>>         getCovariateFormula getResponseFormula groupedData
>>
>>Error in autoloader(name = "confint", package = "MASS") :
>>        autoloader did not find 'confint' in 'MASS'
>> > (fm1 <- lmer(decrease ~ treatment + (1|rowpos) + (1|colpos),
>>+              OrchardSprays))
>>Error: couldn't find function "lmer"
>> >
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>    
>>
>
>
>
>  
>



From jtk at cmp.uea.ac.uk  Mon Aug 15 13:17:18 2005
From: jtk at cmp.uea.ac.uk (Jan T. Kim)
Date: Mon, 15 Aug 2005 12:17:18 +0100
Subject: [R] Semicolons (was:  clip to keep coordinate system?)
In-Reply-To: <Pine.A41.4.61b.0508090747060.113222@homer09.u.washington.edu>
References: <200508091421.j79EL2U9007005@hypatia.math.ethz.ch>
	<Pine.A41.4.61b.0508090747060.113222@homer09.u.washington.edu>
Message-ID: <20050815111718.GB4783@jtkpc.cmp.uea.ac.uk>

On Tue, Aug 09, 2005 at 07:49:36AM -0700, Thomas Lumley wrote:
> On Tue, 9 Aug 2005 ivo_welch-rstat8303 at mailblocks.com wrote:
> 
> >
> > dear R wizards:
> >
> > plot( 1, 1, ylim=(2,10), xlim=(2,10), type="n");
> > rect( -1, -1, 12, 12, col=gray(0.99) );
> >
> > unfortunately wipes out the border axes around the plot.  how do I keep
> > this?
> 
> I think you meant
>    plot( 1, 1, ylim=c(2,10), xlim=c(2,10), type="n")
>    rect( -1, -1, 12, 12, col=gray(0.99) )
> Your code has two syntax errors and two spurious semicolons.

What's wrong with the semicolons? Technically, they're not necessary,
but they definitely improve readability without doing any harm.

Best regards, Jan
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |    *NEW*    email: jtk at cmp.uea.ac.uk                               |
 |    *NEW*    WWW:   http://www.cmp.uea.ac.uk/people/jtk             |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*



From ramasamy at cancer.org.uk  Mon Aug 15 02:37:37 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 15 Aug 2005 01:37:37 +0100
Subject: [R] stepAIC invalid scope argument
Message-ID: <1124066257.6000.29.camel@ipc143004.lif.icnet.uk>

I am trying to replicate the first example from stepAIC from the MASS
package with my own dataset but am running into error. If someone can
point where I have gone wrong, I would appreciate it very much. 

Here is an example :

 set.seed(1)
 df   <- data.frame( x1=rnorm(1000), x2=rnorm(1000), x3=rnorm(1000) )
 df$y <- 0.5*df$x1 + rnorm(1000, mean=8, sd=0.5)
 # pairs(df); head(df)

 lo  <- aov( y ~ 1, data=df )
 hi  <- aov( y ~ .^2, data=df )
 mid <- aov( y ~ x2 + x3, data=df )

Running any of the following commands

 stepAIC( mid, scope=list(upper = ~x1 + x2 + x3 , lower = ~1) )
 stepAIC( mid, scope=list(upper = hi , lower = lo) )
 addterm( mid, ~ x1 + x2 + x3 )
 addterm( lo, hi )

gives the same error message : 
  Error in eval(expr, envir, enclos) : invalid second argument

Here is a traceback of the first failed command :
 14: eval(predvars, data, env)
 13: model.frame.default(formula = y ~ x2 + x3 + x1, data = df, drop.unused.levels = TRUE)
 12: model.frame(formula = y ~ x2 + x3 + x1, data = df, drop.unused.levels = TRUE)
 11: eval(expr, envir, enclos)
 10: eval(mf, parent.frame())
 9: lm(formula = y ~ x2 + x3 + x1, data = df, method = "model.frame")
 8: eval(expr, envir, enclos)
 7: eval(fcall, env, parent.frame())
 6: model.frame.lm(fob, xlev = object$xlevels)
 5: model.frame(fob, xlev = object$xlevels)
 4: stats:::add1.lm(object, scope = scope, scale = scale)
 3: addterm.lm(fit, scope$add, scale = scale, trace = max(0, trace - 1), k = k, ...)
 2: addterm(fit, scope$add, scale = scale, trace = max(0, trace - 1), k = k, ...)
 1: stepAIC(mid, scope = list(upper = ~x1 + x2 + x3, lower = ~1))

Any pointers would be much appreciated. Thank you.

Regards, Adai



From Katharina.Steinmann at stud.unibas.ch  Mon Aug 15 15:39:54 2005
From: Katharina.Steinmann at stud.unibas.ch (K. Steinmann)
Date: Mon, 15 Aug 2005 15:39:54 +0200
Subject: [R] error in predict glm (new levels cause problems)
Message-ID: <1124113194.43009b2a2343d@webmail.unibas.ch>

Dear R-helpers,

I try to perform glm's with negative binomial distributed data.
So I use the MASS library and the commands:
model_1 = glm.nb(response ~ y1 + y2 + ...+ yi, data = data.frame)
and
predict(model_1, newdata = data.frame)


So far, I think everything should be ok.

But when I want to perform a glm with a subset of the data,
I run into an error message as soon as I want to predict values, based on the
new model. The problem seems to be the reduced number of levels of one of the
factors yi ( a categorical factor) in the subset of the original data set.

On cran search I found some related hint, that the line "mf$drop.unused.levels
<- TRUE " in the glm (or glm.nb) function could cause the problem.

Therefore I changed the line to "mf$drop.unused.levels <- FALSE ".
Indeed the error message disappears and when I compare the prediction of model_1
with the prediction of the model, carried out with the full data set but with
the changed glm.nb function, I get the same predicted numbers.

However, the change of glm.nb function was more of an intuitive action, and
since I still consider myself as a beginner of R, I don't feel comfortable.

So my questions:
1. Is there an easier way to solve my problem?
2. Do I affect the glm.nb function seriously, by changing the line mentioned
above?


Thank you for your help,
Katharina

PS: I am working with R 2.0.0
PPS: Concrete error message:
"Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
object$xlevels) :
        factor I(kanton) has new level(s) GE"




--
K. Steinmann
Botanisches Institut
Universit??t Basel
CH-4056 Basel
Switzerland
Tel  0041 61 267 35 02
E-mail: Katharina.Steinmann at stud.unibas.ch



From rvaradha at jhsph.edu  Mon Aug 15 15:49:09 2005
From: rvaradha at jhsph.edu (Ravi Varadhan)
Date: Mon, 15 Aug 2005 09:49:09 -0400
Subject: [R] Vector comparison to matrix
In-Reply-To: <BAY18-F9E3F0B10E871F7FFD6674D4B10@phx.gbl>
Message-ID: <OWA-1tMVhEUsebmspH2000307fe@owa-1.sph.ad.jhsph.edu>

Hi Todd,

Here is a function that was suggested to me by Gabor Grothendieck.  This
function counts the number of times each row of a matrix B occurs in another
matrix A.

rowmatch.count <- function(a,b) { 
    f <- function(...) paste(..., sep=":")
    a2 <- do.call("f", as.data.frame(a))
    b2 <- do.call("f", as.data.frame(b))
    c(table(c(a2,unique(b2)))[b2] - 1)
}

If you are interested in finding the number of occurrences of a vector "b"
instead, you can call this function as follows:

rowmatch.count(A,t(as.matrix(b))

Hope this is helps,
Ravi.


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-
> bounces at stat.math.ethz.ch] On Behalf Of Todd Remund
> Sent: Monday, August 15, 2005 1:13 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Vector comparison to matrix
> 
> I am looking for a fast way to count the number of rows in a matrix are
> identical to a pattern vector.  For example, if I am interested in
> counting
> the number of row vectors in a matrix that are identical to (1,2,3) what
> would I do?  I have tried the identical statement in a loop but this is
> far
> too slow.  I have a very large matrix and need to avoid loops at all
> costs.
> Thanks for any help.
> Todd Remund
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From ripley at stats.ox.ac.uk  Mon Aug 15 16:23:30 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Aug 2005 15:23:30 +0100 (BST)
Subject: [R] stepAIC invalid scope argument
In-Reply-To: <1124066257.6000.29.camel@ipc143004.lif.icnet.uk>
References: <1124066257.6000.29.camel@ipc143004.lif.icnet.uk>
Message-ID: <Pine.LNX.4.61.0508151521390.31534@gannet.stats>

Try not to use the name of an R object ... the error is caused by using 
'df' as the second argument to eval().

It works with DF in place of df.

I don;t understand your subject line: that is not the error message you 
received.

On Mon, 15 Aug 2005, Adaikalavan Ramasamy wrote:

> I am trying to replicate the first example from stepAIC from the MASS
> package with my own dataset but am running into error. If someone can
> point where I have gone wrong, I would appreciate it very much.
>
> Here is an example :
>
> set.seed(1)
> df   <- data.frame( x1=rnorm(1000), x2=rnorm(1000), x3=rnorm(1000) )
> df$y <- 0.5*df$x1 + rnorm(1000, mean=8, sd=0.5)
> # pairs(df); head(df)
>
> lo  <- aov( y ~ 1, data=df )
> hi  <- aov( y ~ .^2, data=df )
> mid <- aov( y ~ x2 + x3, data=df )
>
> Running any of the following commands
>
> stepAIC( mid, scope=list(upper = ~x1 + x2 + x3 , lower = ~1) )
> stepAIC( mid, scope=list(upper = hi , lower = lo) )
> addterm( mid, ~ x1 + x2 + x3 )
> addterm( lo, hi )
>
> gives the same error message :
>  Error in eval(expr, envir, enclos) : invalid second argument
>
> Here is a traceback of the first failed command :
> 14: eval(predvars, data, env)
> 13: model.frame.default(formula = y ~ x2 + x3 + x1, data = df, drop.unused.levels = TRUE)
> 12: model.frame(formula = y ~ x2 + x3 + x1, data = df, drop.unused.levels = TRUE)
> 11: eval(expr, envir, enclos)
> 10: eval(mf, parent.frame())
> 9: lm(formula = y ~ x2 + x3 + x1, data = df, method = "model.frame")
> 8: eval(expr, envir, enclos)
> 7: eval(fcall, env, parent.frame())
> 6: model.frame.lm(fob, xlev = object$xlevels)
> 5: model.frame(fob, xlev = object$xlevels)
> 4: stats:::add1.lm(object, scope = scope, scale = scale)
> 3: addterm.lm(fit, scope$add, scale = scale, trace = max(0, trace - 1), k = k, ...)
> 2: addterm(fit, scope$add, scale = scale, trace = max(0, trace - 1), k = k, ...)
> 1: stepAIC(mid, scope = list(upper = ~x1 + x2 + x3, lower = ~1))
>
> Any pointers would be much appreciated. Thank you.
>
> Regards, Adai
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Aug 15 16:57:21 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Aug 2005 15:57:21 +0100 (BST)
Subject: [R] stepAIC invalid scope argument
In-Reply-To: <Pine.LNX.4.61.0508151521390.31534@gannet.stats>
References: <1124066257.6000.29.camel@ipc143004.lif.icnet.uk>
	<Pine.LNX.4.61.0508151521390.31534@gannet.stats>
Message-ID: <Pine.LNX.4.61.0508151551510.5318@gannet.stats>

In case it is unclear why in this case there is a problem: you are running 
a function (here model.frame) in the stats namespace and so it looks in 
the stats namespace before the workspace when looking for 'df'.

On Mon, 15 Aug 2005, Prof Brian Ripley wrote:

> Try not to use the name of an R object ... the error is caused by using
> 'df' as the second argument to eval().
>
> It works with DF in place of df.
>
> I don't understand your subject line: that is not the error message you
> received.
>
> On Mon, 15 Aug 2005, Adaikalavan Ramasamy wrote:
>
>> I am trying to replicate the first example from stepAIC from the MASS
>> package with my own dataset but am running into error. If someone can
>> point where I have gone wrong, I would appreciate it very much.
>>
>> Here is an example :
>>
>> set.seed(1)
>> df   <- data.frame( x1=rnorm(1000), x2=rnorm(1000), x3=rnorm(1000) )
>> df$y <- 0.5*df$x1 + rnorm(1000, mean=8, sd=0.5)
>> # pairs(df); head(df)
>>
>> lo  <- aov( y ~ 1, data=df )
>> hi  <- aov( y ~ .^2, data=df )
>> mid <- aov( y ~ x2 + x3, data=df )
>>
>> Running any of the following commands
>>
>> stepAIC( mid, scope=list(upper = ~x1 + x2 + x3 , lower = ~1) )
>> stepAIC( mid, scope=list(upper = hi , lower = lo) )
>> addterm( mid, ~ x1 + x2 + x3 )
>> addterm( lo, hi )
>>
>> gives the same error message :
>>  Error in eval(expr, envir, enclos) : invalid second argument
>>
>> Here is a traceback of the first failed command :
>> 14: eval(predvars, data, env)
>> 13: model.frame.default(formula = y ~ x2 + x3 + x1, data = df, drop.unused.levels = TRUE)
>> 12: model.frame(formula = y ~ x2 + x3 + x1, data = df, drop.unused.levels = TRUE)
>> 11: eval(expr, envir, enclos)
>> 10: eval(mf, parent.frame())
>> 9: lm(formula = y ~ x2 + x3 + x1, data = df, method = "model.frame")
>> 8: eval(expr, envir, enclos)
>> 7: eval(fcall, env, parent.frame())
>> 6: model.frame.lm(fob, xlev = object$xlevels)
>> 5: model.frame(fob, xlev = object$xlevels)
>> 4: stats:::add1.lm(object, scope = scope, scale = scale)
>> 3: addterm.lm(fit, scope$add, scale = scale, trace = max(0, trace - 1), k = k, ...)
>> 2: addterm(fit, scope$add, scale = scale, trace = max(0, trace - 1), k = k, ...)
>> 1: stepAIC(mid, scope = list(upper = ~x1 + x2 + x3, lower = ~1))
>>
>> Any pointers would be much appreciated. Thank you.
>>
>> Regards, Adai
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ramasamy at cancer.org.uk  Mon Aug 15 05:04:26 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 15 Aug 2005 04:04:26 +0100
Subject: [R] stepAIC invalid scope argument
In-Reply-To: <Pine.LNX.4.61.0508151521390.31534@gannet.stats>
References: <1124066257.6000.29.camel@ipc143004.lif.icnet.uk>
	<Pine.LNX.4.61.0508151521390.31534@gannet.stats>
Message-ID: <1124075066.6000.35.camel@ipc143004.lif.icnet.uk>

You are right, it works fine with a different name. Its a bad habit that
I need to shake off.

The error message said that the second argument was invalid. The second
argument in stepAIC and addterm is 'scope' and thus the title.

Thank you again.

Regards, Adai



On Mon, 2005-08-15 at 15:23 +0100, Prof Brian Ripley wrote:
> Try not to use the name of an R object ... the error is caused by using 
> 'df' as the second argument to eval().
> 
> It works with DF in place of df.
> 
> I don;t understand your subject line: that is not the error message you 
> received.
> 
> On Mon, 15 Aug 2005, Adaikalavan Ramasamy wrote:
> 
> > I am trying to replicate the first example from stepAIC from the MASS
> > package with my own dataset but am running into error. If someone can
> > point where I have gone wrong, I would appreciate it very much.
> >
> > Here is an example :
> >
> > set.seed(1)
> > df   <- data.frame( x1=rnorm(1000), x2=rnorm(1000), x3=rnorm(1000) )
> > df$y <- 0.5*df$x1 + rnorm(1000, mean=8, sd=0.5)
> > # pairs(df); head(df)
> >
> > lo  <- aov( y ~ 1, data=df )
> > hi  <- aov( y ~ .^2, data=df )
> > mid <- aov( y ~ x2 + x3, data=df )
> >
> > Running any of the following commands
> >
> > stepAIC( mid, scope=list(upper = ~x1 + x2 + x3 , lower = ~1) )
> > stepAIC( mid, scope=list(upper = hi , lower = lo) )
> > addterm( mid, ~ x1 + x2 + x3 )
> > addterm( lo, hi )
> >
> > gives the same error message :
> >  Error in eval(expr, envir, enclos) : invalid second argument
> >
> > Here is a traceback of the first failed command :
> > 14: eval(predvars, data, env)
> > 13: model.frame.default(formula = y ~ x2 + x3 + x1, data = df, drop.unused.levels = TRUE)
> > 12: model.frame(formula = y ~ x2 + x3 + x1, data = df, drop.unused.levels = TRUE)
> > 11: eval(expr, envir, enclos)
> > 10: eval(mf, parent.frame())
> > 9: lm(formula = y ~ x2 + x3 + x1, data = df, method = "model.frame")
> > 8: eval(expr, envir, enclos)
> > 7: eval(fcall, env, parent.frame())
> > 6: model.frame.lm(fob, xlev = object$xlevels)
> > 5: model.frame(fob, xlev = object$xlevels)
> > 4: stats:::add1.lm(object, scope = scope, scale = scale)
> > 3: addterm.lm(fit, scope$add, scale = scale, trace = max(0, trace - 1), k = k, ...)
> > 2: addterm(fit, scope$add, scale = scale, trace = max(0, trace - 1), k = k, ...)
> > 1: stepAIC(mid, scope = list(upper = ~x1 + x2 + x3, lower = ~1))
> >
> > Any pointers would be much appreciated. Thank you.
> >
> > Regards, Adai
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>



From murdoch at stats.uwo.ca  Mon Aug 15 17:07:26 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 15 Aug 2005 11:07:26 -0400
Subject: [R] scratch a figure
In-Reply-To: <BAY105-F3234F0F691B65E511506B0D0BF0@phx.gbl>
References: <BAY105-F3234F0F691B65E511506B0D0BF0@phx.gbl>
Message-ID: <4300AFAE.2080203@stats.uwo.ca>

å´ æ˜Š wrote:
> Hi,
> I have generated a figure using rgl.surface(),how can I scratch this 
> figure? thanks a lot.

Which version of rgl are you using? Current is 0.65. What does "scratch" 
mean?  There are functions rgl.close(), rgl.clear(), rgl.pop().  You can 
also just close the window; a new one will be created the next time you 
draw something.

Duncan Murdoch



From Hummel at mpimp-golm.mpg.de  Mon Aug 15 17:10:44 2005
From: Hummel at mpimp-golm.mpg.de (Jan Hummel)
Date: Mon, 15 Aug 2005 17:10:44 +0200
Subject: [R] Re-sort list of vectors
Message-ID: <1F5B2A5E6712B94DA65EA9EBF0A1A38230E2B0@EMAIL.mpimp-golm.mpg.de>

Hi.
Can anyone suggest a simple way to re-sort in R a list of vectors of the
following form?

input
$"1"
	a	b	c
	1	2	3
$"2"
	a	b	c
	4	5	6

Output should be something like:
"a"
	"1" 1
	"2" 4
"b"
	"1" 2
	"2" 5
"c"
	"1" 3
	"2" 6

I've been futzing with mapply(), outer(), split(), rbind() and so on but
haven't found an elegant solution.

Thanks,
Jan.

P.S. E-mailed CCs of posted replies appreciated.



From andy_liaw at merck.com  Mon Aug 15 17:30:32 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 15 Aug 2005 11:30:32 -0400
Subject: [R] Re-sort list of vectors
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EBCB@usctmx1106.Merck.com>

If all vectors in the list have the same length, why not use a matrix?  Then
you'd just transpose the matrix if you need to.  If you really have to have
it as a list, here's one possibility:

> x <- list("1"=c(a=1, b=2, c=3), "2"=c(a=4, b=5, c=6))
> x
$"1"
a b c 
1 2 3 

$"2"
a b c 
4 5 6 
> as.list(as.data.frame(t(matrix(unlist(x), nrow=3))))
$V1
[1] 1 4

$V2
[1] 2 5

$V3
[1] 3 6

Andy


> From: Jan Hummel
> 
> Hi.
> Can anyone suggest a simple way to re-sort in R a list of 
> vectors of the
> following form?
> 
> input
> $"1"
> 	a	b	c
> 	1	2	3
> $"2"
> 	a	b	c
> 	4	5	6
> 
> Output should be something like:
> "a"
> 	"1" 1
> 	"2" 4
> "b"
> 	"1" 2
> 	"2" 5
> "c"
> 	"1" 3
> 	"2" 6
> 
> I've been futzing with mapply(), outer(), split(), rbind() 
> and so on but
> haven't found an elegant solution.
> 
> Thanks,
> Jan.
> 
> P.S. E-mailed CCs of posted replies appreciated.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From ripley at stats.ox.ac.uk  Mon Aug 15 17:33:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Aug 2005 16:33:22 +0100 (BST)
Subject: [R] stepAIC invalid scope argument
In-Reply-To: <1124075066.6000.35.camel@ipc143004.lif.icnet.uk>
References: <1124066257.6000.29.camel@ipc143004.lif.icnet.uk> 
	<Pine.LNX.4.61.0508151521390.31534@gannet.stats>
	<1124075066.6000.35.camel@ipc143004.lif.icnet.uk>
Message-ID: <Pine.LNX.4.61.0508151632510.8126@gannet.stats>

On Mon, 15 Aug 2005, Adaikalavan Ramasamy wrote:

> You are right, it works fine with a different name. Its a bad habit that
> I need to shake off.
>
> The error message said that the second argument was invalid. The second
> argument in stepAIC and addterm is 'scope' and thus the title.

OK, we'll improve the error message ....

>
> Thank you again.
>
> Regards, Adai
>
>
>
> On Mon, 2005-08-15 at 15:23 +0100, Prof Brian Ripley wrote:
>> Try not to use the name of an R object ... the error is caused by using
>> 'df' as the second argument to eval().
>>
>> It works with DF in place of df.
>>
>> I don;t understand your subject line: that is not the error message you
>> received.
>>
>> On Mon, 15 Aug 2005, Adaikalavan Ramasamy wrote:
>>
>>> I am trying to replicate the first example from stepAIC from the MASS
>>> package with my own dataset but am running into error. If someone can
>>> point where I have gone wrong, I would appreciate it very much.
>>>
>>> Here is an example :
>>>
>>> set.seed(1)
>>> df   <- data.frame( x1=rnorm(1000), x2=rnorm(1000), x3=rnorm(1000) )
>>> df$y <- 0.5*df$x1 + rnorm(1000, mean=8, sd=0.5)
>>> # pairs(df); head(df)
>>>
>>> lo  <- aov( y ~ 1, data=df )
>>> hi  <- aov( y ~ .^2, data=df )
>>> mid <- aov( y ~ x2 + x3, data=df )
>>>
>>> Running any of the following commands
>>>
>>> stepAIC( mid, scope=list(upper = ~x1 + x2 + x3 , lower = ~1) )
>>> stepAIC( mid, scope=list(upper = hi , lower = lo) )
>>> addterm( mid, ~ x1 + x2 + x3 )
>>> addterm( lo, hi )
>>>
>>> gives the same error message :
>>>  Error in eval(expr, envir, enclos) : invalid second argument
>>>
>>> Here is a traceback of the first failed command :
>>> 14: eval(predvars, data, env)
>>> 13: model.frame.default(formula = y ~ x2 + x3 + x1, data = df, drop.unused.levels = TRUE)
>>> 12: model.frame(formula = y ~ x2 + x3 + x1, data = df, drop.unused.levels = TRUE)
>>> 11: eval(expr, envir, enclos)
>>> 10: eval(mf, parent.frame())
>>> 9: lm(formula = y ~ x2 + x3 + x1, data = df, method = "model.frame")
>>> 8: eval(expr, envir, enclos)
>>> 7: eval(fcall, env, parent.frame())
>>> 6: model.frame.lm(fob, xlev = object$xlevels)
>>> 5: model.frame(fob, xlev = object$xlevels)
>>> 4: stats:::add1.lm(object, scope = scope, scale = scale)
>>> 3: addterm.lm(fit, scope$add, scale = scale, trace = max(0, trace - 1), k = k, ...)
>>> 2: addterm(fit, scope$add, scale = scale, trace = max(0, trace - 1), k = k, ...)
>>> 1: stepAIC(mid, scope = list(upper = ~x1 + x2 + x3, lower = ~1))
>>>
>>> Any pointers would be much appreciated. Thank you.
>>>
>>> Regards, Adai
>>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From macq at llnl.gov  Mon Aug 15 17:34:09 2005
From: macq at llnl.gov (Don MacQueen)
Date: Mon, 15 Aug 2005 08:34:09 -0700
Subject: [R] Way to make R idle for some time and try something again
 later
In-Reply-To: <Pine.LNX.4.61.0507300618320.19789@gannet.stats>
References: <BF0FCDDC.6C9B%thchung@tgen.org>
	<p06210209bf105ab36a33@[128.115.153.6]>
	<Pine.LNX.4.61.0507300618320.19789@gannet.stats>
Message-ID: <p0621020bbf26628f560a@[128.115.153.6]>


At 6:44 AM +0100 7/30/05, Prof Brian Ripley wrote:
>This depends on what else is going on.  My guess is that you are 
>running the Aqua GUI, and it is servicing the GUI which is taking 
>the time, not R itself.

Actually, no, I am not using the Aqua GUI. Not even a "framework" build:
    ../source/configure --enable-R-shlib --with-blas=-framework vecLib 
--with-lapack --enable-R-framework=no


>On all of Linux, Solaris and Windows (RGui or Rterm) Sys.sleep() 
>does use very close to zero resources at the beginning of a session, 
>but things may be different if e.g. tcltk widgets are in use.
>
>On Fri, 29 Jul 2005, Don MacQueen wrote:
>
>>I done something very similar -- have R watch a file, and whenever
>>new data is added to the file, read the new data from the file. In my
>>case, new data was arriving once per minute, so I needed to have R
>>wait about a minute before looking for new data.
>>
>>On my unix-based system, I found that if I usd
>
>I don't think your system IS `unix-based' (Unix is a trademark, and 
>MacOS X is based on a rather different kernel).  It is quite 
>possible that it is behaving differently from the POSIX description 
>of Unix system calls on which R is based for Unix-alikes.
>
>>       Sys.sleep( N )
>>then cpu usage immediately went up drastically. If the the system is
>>otherwise fairly idle, cpu usage goes up to nearly 100%. A cpu
>>monitor shows that R is using the cpu cycles.
>>
>>If I use instead
>>      system('sleep N')
>>cpu usage does not go up.
>
>Does that freeze the GUI?  It certainly freezes tcltk widgets on Unix.

I've never tried it while using tcltk widgets.

(and apologies for the delay; I've been away from the office for two weeks)

>
>>(where N is the number of seconds to sleep)
>>
>>>  version
>>          _
>>platform powerpc-apple-darwin7.9.0
>>arch     powerpc
>>os       darwin7.9.0
>>system   powerpc, darwin7.9.0
>>status
>>major    2
>>minor    1.1
>>year     2005
>>month    06
>>day      20
>>language R
>>
>>
>>At 12:13 PM -0700 7/29/05, Tae-Hoon Chung wrote:
>>>Hi, All;
>>>
>>>I have a question. In R, what is the best way to make R idle for a while and
>>>try something again later? For example, suppose there is an R job which
>>>accesses a file that may be shared with other active jobs. So when the file
>>>is being accessed by other job, your job will not be able to access the file
>>>and your job will crash because of that. To avoid this, you want your job to
>>>try to access the file repeatedly with some time interval, say every 10
>>>seconds or something like that. Which is the best way to do this in R?
>
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From spencer.graves at pdf.com  Mon Aug 15 17:37:52 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 15 Aug 2005 08:37:52 -0700
Subject: [R] Using nonlinear regression
In-Reply-To: <200508111051.46559.mmiller@nassp.uct.ac.za>
References: <200508041257.21030.mmiller@nassp.uct.ac.za>	<5537091C-6831-4C7B-80EF-4EB34F78A1BC@wisc.edu>
	<200508111051.46559.mmiller@nassp.uct.ac.za>
Message-ID: <4300B6D0.4090002@pdf.com>

	  Do you want to estimate the parameters of a lognormal distribution or 
learn how to do nonlinear regression in R?

	  If the former, as far as I know, the best known method is maximum 
likelihood, for which the answer is to compute mean and standard 
deviations of the logs.  This assumes you are talking about the 
2-parameter lognormal.  I don't know the best method for a 3-parameter 
lognormal.  If that's what you want, PLEASE do read the posting guide! 
"http://www.R-project.org/posting-guide.html".  Doing so can increase 
the chances of getting a useful reply.

	  If you want examples of nonlinear regression, have you considered 
"nls" and "optim"?

	  spencer graves

Mark Miller wrote:
> Attached is a copy of my code, the data and the plots obtained by varying 
> terms manually, I was told that nonlinear regression in R could find the 
> values for me, but I am unable to figure how exactly I could implement this.  
> Any help would be very greatly appreciated as I am completely stuck on this 
> problem.
> 
> 
> On Thursday 04 August 2005 13:40, you wrote:
> 
>>It might be good to have an example of your problem.
>>
>>On Aug 4, 2005, at 5:57 AM, Mark Miller wrote:
>>
>>>Hi, I have been trying to figure out how to use the nonlinear
>>>regression to
>>>fit the cumulative lognormal distribution to a number of data
>>>points I have
>>>but I am a new R user and I cant quite decipher the notes on nonlinear
>>>regression.  Any help in this regard will be greatly appreciated,
>>>my email
>>>address is mmiller at nassp.uct.ac.za
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-
>>>guide.html
>>>
>>>
>>>------------------------------------------------------------------------
>>>
>>>rm(list=ls())
>>>
>>>outPut = read.csv("dataOut2.csv")
>>>arrive = outPut[1]
>>>register = outPut[2]
>>>complete = outPut[3]
>>>
>>>
>>>IAT = 0
>>>TTR = 0
>>>TTC = 0
>>>TFR = 0
>>>cnt = 1
>>>
>>>for(i in array(2:dim(arrive)[1]))
>>>{
>>>	temp = outPut[i,3]-outPut[i,2]
>>>	if(temp > 0)
>>>	{
>>>		IAT[cnt] = outPut[i,1]-outPut[i-1,1]
>>>		TTR[cnt] = outPut[i,2]-outPut[i,1]
>>>		TFR[cnt] = outPut[i,3]-outPut[i,2]
>>>		cnt = cnt + 1
>>>	}
>>>}
>>>
>>>cumIAT = IAT/sum(IAT)
>>>for(i in array(2:length(IAT)))
>>>{
>>>	cumIAT[i] = cumIAT[i-1]+cumIAT[i]
>>>}
>>>cumIAT[1] = 0
>>>plot(cumIAT,do.point=F)
>>>
>>>
>>>TTR[cnt] = outPut[1,2]-outPut[1,1]
>>>TFR[cnt] = outPut[1,3]-outPut[1,2]
>>>
>>># Plot for inter-arrival times
>>>x = seq(0,30,0.01)
>>>#postscript("cumIAT.ps")
>>>plot(ecdf(IAT), do.point=FALSE)
>>>lines(x, pexp(x,0.4))
>>>dev.off()
>>># rexp(100,0.21)
>>>
>>>x = seq(0,20,0.01)
>>>postscript("cumTTR.ps")
>>>plot(ecdf(TTR), do.point=FALSE)
>>>lines(x, plnorm(x,1,0.7))
>>>dev.off()
>>># rlnorm(100,1,0.7)
>>>
>>># Plot for Time to complete from registered
>>>x = seq(0,30,0.01)
>>>postscript("cumTFR.ps")
>>>plot(ecdf(TFR), do.point=FALSE)
>>>lines(x*600, pbeta(x,1.4,4.3))
>>>dev.off()
>>># rbeta(100,1.6,5)*600
>>>
>>># Find the position with the leat time and hence the next avaliable ambulance
>>>minimum = function(toFind)
>>>{
>>>	min = 0;
>>>	pos = 0;
>>>	for(i in array(1:length(toFind)))
>>>	{
>>>		if(i == 1)
>>>		{
>>>			min = toFind[i]
>>>			pos = i
>>>		}
>>>		else
>>>		{
>>>			if(toFind[i] < min)
>>>			{
>>>				min = toFind[i]
>>>				pos = i
>>>			}
>>>		}
>>>	} 
>>>
>>>	pos
>>>}
>>>
>>>ambsReq = 0
>>>numAmbs = 0
>>>numberAmbs = 0
>>>avgWait = 1
>>>numberAmbs2 = 0
>>>avgWaitTime2 = 0
>>>avgWaitTime = 0
>>>counter = 0
>>>counter2 = 1
>>>cntO = 1
>>>
>>>for(i in array(1:50))
>>>{
>>>	while(avgWait > 0)
>>>	{
>>>		counter = counter + 1
>>>		numAmbs = numAmbs + 1
>>>		numberAmbs[counter] = numAmbs
>>>		numCalls = 1
>>>		ambs = array(c(array(0,numAmbs)), dim=c(numAmbs,numCalls))
>>>		waitTime = ambs
>>>		totalTime = ambs
>>>		currTime = 0
>>>		timeTS = 0
>>>		IotherAT = 0
>>>		TotherTR = 0
>>>	
>>>		for(i in array(1:500))
>>>		{
>>>			#interAT = IAT(ceil(rand()*length(IAT)));
>>>			interAT = rexp(1,0.21)
>>>			#timeTR = TTR(ceil(rand()*length(TTR)));
>>>			timeTR = rlnorm(1,1,0.7)
>>>			#timeFR = TFR(ceil(rand()*length(TFR)));
>>>			timeFR = rbeta(1,1.4,4.3)*600
>>>
>>>			IotherAT[i] = interAT
>>>			TotherTR[i] = timeTR
>>>	
>>>			currTime = currTime + interAT
>>>		
>>>			pos = minimum(totalTime)
>>>
>>>			if(ambs[pos,numCalls] != 0)
>>>			{
>>>				numCalls = numCalls + 1
>>>				ambs = array(c(ambs,array(0,numAmbs)), dim=c(numAmbs,numCalls))
>>>				waitTime = array(c(waitTime,array(0,numAmbs)), dim=c(numAmbs,numCalls))
>>>				if(totalTime[pos] > currTime)
>>>					waitTime[pos,numCalls] = totalTime[pos] - currTime
>>>				totalTime[pos] = totalTime[pos] + interAT + timeTR + timeFR
>>>				ambs[pos,numCalls] = interAT + timeTR + timeFR
>>>			}
>>>			else
>>>			{
>>>				for(i in array(1:numCalls))
>>>				{
>>>					if(ambs[pos,i] == 0)
>>>					{
>>>						if(totalTime[pos] > currTime)
>>>							waitTime[pos,i] = totalTime[pos] - currTime
>>>						totalTime[pos] = totalTime[pos] + interAT + timeTR + timeFR
>>>						ambs[pos,numCalls] = interAT + timeTR + timeFR
>>>						break
>>>					}
>>>				}
>>>			}
>>>		}
>>>
>>>		avgWait = sum(waitTime)/500
>>>		avgWaitTime[counter] = avgWait
>>>		if(numAmbs == 25)
>>>		{
>>>			avgWaitTime2[cntO] = avgWait
>>>			numberAmbs2[cntO] = numAmbs
>>>			cntO = cntO + 1
>>>		}
>>>	}
>>>
>>>	postscript("timeAmbs.ps")
>>>	plot(numberAmbs,avgWaitTime,'lines') 
>>>	dev.off()
>>>
>>>	postscript("timeAmbs2.ps")
>>>	plot(numberAmbs2,avgWaitTime2,'lines') 
>>>	dev.off()
>>>
>>>	ambsReq[counter2] = numAmbs
>>>	numAmbs = 0
>>>	numberAmbs = 0
>>>	avgWait = 1
>>>	avgWaitTime = 0
>>>	counter = 0
>>>	counter2 = counter2 +1
>>>	cntO = 1
>>>	numberAmbs2 = 0
>>>	avgWaitTime2 = 1
>>>}
>>>
>>>
>>>
>>>
>>>TotherFR = 0
>>>cnt = 1
>>>for(i in array(1:dim(ambs)[1]))
>>>{
>>>	for(j in array(1:dim(ambs)[2]))
>>>	{
>>>		if(ambs[i,j] != 0)
>>>		{
>>>			TotherFR[cnt] = ambs[i,j]
>>>			cnt = cnt +1
>>>		}
>>>	}
>>>}
>>>
>>>postscript("dataIAT.ps")
>>>hist(IAT,30)
>>>dev.off()
>>>
>>>postscript("simIAT.ps")
>>>hist(IotherAT,30)
>>>dev.off()
>>>
>>>postscript("dataTTR.ps")
>>>hist(TTR,30)
>>>dev.off()
>>>
>>>postscript("simTTR.ps")
>>>hist(TotherTR,30)
>>>dev.off()
>>>
>>>postscript("dataTFR.ps")
>>>hist(TFR,30)
>>>dev.off()
>>>
>>>postscript("simTFR.ps")
>>>hist(TotherFR,30)
>>>dev.off()
>>>
>>>
>>>------------------------------------------------------------------------
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From tlumley at u.washington.edu  Mon Aug 15 17:41:08 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 15 Aug 2005 08:41:08 -0700 (PDT)
Subject: [R] boot error: Error in statistic(data, original,
 ...) : unused argument(s) ( ...)
In-Reply-To: <Pine.LNX.4.61.0508130601040.7951@gannet.stats>
References: <s2fd332f.016@grecc.umaryland.edu>
	<Pine.LNX.4.61.0508130601040.7951@gannet.stats>
Message-ID: <Pine.A41.4.61b.0508150839260.279420@homer06.u.washington.edu>

On Sat, 13 Aug 2005, Prof Brian Ripley wrote:
> I suspect you want
>
> AdjForBase2 <- function (data, inds)
>
> and to refer to data[inds, 1] and data[inds, 2], but since your code is
> completely devoid of spaces and indentation, I have paid it little
> attention.

http://msr.uwaterloo.ca/msr2005/papers/27.pdf  describes a study of 
student computer science projects from CVS logs in which the only code 
feature correlated with the final grade was the number of times a space 
was used after a comma.  [I'm not sure I like their analysis, though].


 	-thomas



From br44114 at gmail.com  Mon Aug 15 18:33:41 2005
From: br44114 at gmail.com (bogdan romocea)
Date: Mon, 15 Aug 2005 12:33:41 -0400
Subject: [R] retrieving large columns using RODBC
Message-ID: <8d5a36350508150933590d3c71@mail.gmail.com>

This appears to be an SQL issue. Look for a way to speed up your
queries in Postgresql. I presume you haven't created an index on
'index', which means that every time you run your SELECT, Postgresql
is forced to do a full table scan (not good). If the index doesn't
solve the problem, look for some SQL help.


> -----Original Message-----
> From: Tamas K Papp [mailto:tpapp at princeton.edu] 
> Sent: Saturday, August 13, 2005 4:03 AM
> To: R-help mailing list
> Subject: [R] retrieving large columns using RODBC
> 
> 
> Hi,
> 
> I have a large table in Postgresql (result of an MCMC 
> simulation, with 1
> million rows) and I would like to retrive colums (correspond 
> to variables)
> using RODBC.  I have a column called "index" which is used to 
> order rows.
> 
> Unfortunately, sqlQuery can't return all the values from a 
> column at once
> (RODBC complains about lack of memory).  So I am using the 
> following code:
> 
> getcolumns <- function(channel, tablename, colnames, totalrows,
>                       ordered=TRUE,chunksize=1e5) {
>   r <- matrix(double(0),totalrows,length(colnames))
>   for (i in 1:ceiling(totalrows/chunksize)) {
>     cat(".")
>     r[((i-1)*chunksize+1):(i*chunksize)] <- as.matrix(
>       sqlQuery(channel, paste("SELECT", paste(colnames,collapse=", "),
>                               "FROM", tablename,
>                               "WHERE index <=", i*chunksize,
>                               "AND index >", (i-1)*chunksize,
>                               if (ordered) "ORDER BY index;" 
> else ";")))
>   }
>   cat("\n")
>   drop(r)                               # convert to vector if needed
> }
> 
> to retrieve it in chunks.  However, this is very slow -- 
> takes about 15
> minutes on my machine.  Is there a way to speed it up?
> 
> I am running Linux on a powerbook, RODBC version 1.1-4, R 2.1.1.  The
> machine has only 512 Mb of RAM.
> 
> Thanks,
> 
> Tamas
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From gunter.berton at gene.com  Mon Aug 15 18:48:06 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 15 Aug 2005 09:48:06 -0700
Subject: [R] PCA problem in R
In-Reply-To: <Pine.LNX.4.61.0508140714210.22738@gannet.stats>
Message-ID: <200508151648.j7FGm66i021103@volta.gene.com>

To add to Brian Ripley's note:

All but possibly the first few (1-3, say) PC's are very likely  random
numbers. You need to either consult references or get statistical help to
understand why. May I also suggest that you add Prof Ripley's book on
PATTERN RECOGNITION AND NEURAL NETWORKS to your reading list -- in
particular, Ch. 9.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Prof 
> Brian Ripley
> Sent: Saturday, August 13, 2005 11:26 PM
> To: Alan Zhao
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] PCA problem in R
> 
> On Sat, 13 Aug 2005, Alan Zhao wrote:
> 
> > When I have more variables than units, say a 195*10896 
> matrix which has
> > 10896 variables and 195 samples. prcomp will give only 195 principal
> > components. I checked in the help, but there is no 
> explanation that why
> > this happen.
> 
> There is not even a definition of a PC in the help. Did you read the 
> references?  This is what they are given for!
> 
> > Can we get more than 195 PCs for this case? Thank you very
> > much.
> 
> Check out the theory in the references.  You can, but all the 
> remaining 
> ones are constant across samples and not uniquely defined.  
> You are likely 
> to have trouble storing the coefficients (10701x10896 is 800Mb).
> It would be better to do whatever you intend to do with them without 
> explicitly computing them.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From admin at biostatistic.de  Mon Aug 15 18:50:48 2005
From: admin at biostatistic.de (Knut Krueger)
Date: Mon, 15 Aug 2005 18:50:48 +0200
Subject: [R] relation between cex.axis and pointsize in graphics device
Message-ID: <4300C7E8.5000903@biostatistic.de>

I am not able to see the relation between this parameters.
Will I get the same result with 

pointsize=24 and  cex.axis=1
and
pointsize=12 and  cex.axis=2

It seems that the fonts will be only scaled when I am changing the 
pointsize after printing
and it seem that they will be drawn in a better resoultion with the 
second way pointsize=12 and  cex.axis=2


 bmp(filename = "Rplot%03d.bmp", width = 480, height = 480,
         pointsize = 24, bg = "white", res = NA)

     axis(1, 1:7, LETTERS[1:7], cex.axis=1)   



 bmp(filename = "Rplot%03d.bmp", width = 480, height = 480,

         pointsize = 12, bg = "white", res = NA)



     axis(1, 1:7, LETTERS[1:7], cex.axis=2)     



 

with regards
Knut Krueger



From ripley at stats.ox.ac.uk  Mon Aug 15 18:51:45 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Aug 2005 17:51:45 +0100 (BST)
Subject: [R] retrieving large columns using RODBC
In-Reply-To: <8d5a36350508150933590d3c71@mail.gmail.com>
References: <8d5a36350508150933590d3c71@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0508151749240.31932@gannet.stats>

On Mon, 15 Aug 2005, bogdan romocea wrote:

> This appears to be an SQL issue. Look for a way to speed up your
> queries in Postgresql. I presume you haven't created an index on
> 'index', which means that every time you run your SELECT, Postgresql
> is forced to do a full table scan (not good). If the index doesn't
> solve the problem, look for some SQL help.

If that were the case the fact that sqlQuery is not being used properly 
(it can do the query and return the results in blocks) is likely to be 
the problem.  But then we do ask people to read the help page before 
posting.

>
>
>> -----Original Message-----
>> From: Tamas K Papp [mailto:tpapp at princeton.edu]
>> Sent: Saturday, August 13, 2005 4:03 AM
>> To: R-help mailing list
>> Subject: [R] retrieving large columns using RODBC
>>
>>
>> Hi,
>>
>> I have a large table in Postgresql (result of an MCMC
>> simulation, with 1
>> million rows) and I would like to retrive colums (correspond
>> to variables)
>> using RODBC.  I have a column called "index" which is used to
>> order rows.
>>
>> Unfortunately, sqlQuery can't return all the values from a
>> column at once
>> (RODBC complains about lack of memory).  So I am using the
>> following code:
>>
>> getcolumns <- function(channel, tablename, colnames, totalrows,
>>                       ordered=TRUE,chunksize=1e5) {
>>   r <- matrix(double(0),totalrows,length(colnames))
>>   for (i in 1:ceiling(totalrows/chunksize)) {
>>     cat(".")
>>     r[((i-1)*chunksize+1):(i*chunksize)] <- as.matrix(
>>       sqlQuery(channel, paste("SELECT", paste(colnames,collapse=", "),
>>                               "FROM", tablename,
>>                               "WHERE index <=", i*chunksize,
>>                               "AND index >", (i-1)*chunksize,
>>                               if (ordered) "ORDER BY index;"
>> else ";")))
>>   }
>>   cat("\n")
>>   drop(r)                               # convert to vector if needed
>> }
>>
>> to retrieve it in chunks.  However, this is very slow --
>> takes about 15
>> minutes on my machine.  Is there a way to speed it up?
>>
>> I am running Linux on a powerbook, RODBC version 1.1-4, R 2.1.1.  The
>> machine has only 512 Mb of RAM.
>>
>> Thanks,
>>
>> Tamas
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From shea at cgd.ucar.edu  Mon Aug 15 18:56:28 2005
From: shea at cgd.ucar.edu (Dennis Shea)
Date: Mon, 15 Aug 2005 10:56:28 -0600 (MDT)
Subject: [R] PCA problem in R
Message-ID: <200508151656.j7FGuSBT019203@upham.cgd.ucar.edu>

[SNIP]>> 
>>>On Sat, 13 Aug 2005, Alan Zhao wrote:
>>>
>>>>When I have more variables than units, say a 195*10896 matrix which has
>>>>10896 variables and 195 samples. prcomp will give only 195 principal
>>>>components. I checked in the help, but there is no explanation that why
>>>>this happen.

[SNIP]

>Sincerely,
>Zheng Zhao
>Aug-14-2005
>______________________________________________

Just yesterday I subscribed to r-help because I am planning
on learning the basics of R ... today.   :-)
Thus, I am not sure about the history of this question.

The above situation, more variables than samples, 
is commonly encounterd in the climate studies.
Consider annual mean temperatures for 195 years
on a coarse 72 [lat] x 144 [lon]  grid [72*144=10368 
spatial variables]. 

Let  S be the number of grid points and T be the number
of years. I think there is a theorem (?Eckart-Young?) 
which states that the maximum number of unique eigenvalues 
is min(S,T). In your case 195 eigenvalues is correct. 
I speculate that the underlying function transposes the 
input data matrix and computes the the TxT [rather than SxS]
covariance matrix and solves for the eigenvalues/vectors. 
It then uses a linear transformation to get the results
for the original input data matrix.

Computationally, the above is much faster and uses less memory.



From rolf at math.unb.ca  Mon Aug 15 19:01:42 2005
From: rolf at math.unb.ca (Rolf Turner)
Date: Mon, 15 Aug 2005 14:01:42 -0300 (ADT)
Subject: [R] Testing.
Message-ID: <200508151701.j7FH1gGM024121@erdos.math.unb.ca>


Please ignore this message; I apologise for the annoyance.

			cheers,

				Rolf



From Hummel at mpimp-golm.mpg.de  Mon Aug 15 19:09:57 2005
From: Hummel at mpimp-golm.mpg.de (Jan Hummel)
Date: Mon, 15 Aug 2005 19:09:57 +0200
Subject: [R] Re-sort list of vectors
Message-ID: <1F5B2A5E6712B94DA65EA9EBF0A1A38230E2B3@EMAIL.mpimp-golm.mpg.de>

 Thanks a lot! But unfortunately I will not know the dimensions of both lists. And further, the lists may be (partly) disjoint as: x <- list("1"=c(a=1, b=2, c=3), "2"=c(d=4, b=5, e=6)). And last but not least I'm really have to have access to the names of the named list items.

The problem I dealt with is in unlist() merging the names together, as you can see in your example given: "V1", "V2" and "V3". Because off interpreting the names later as identifiers in db queries I'm really interested in getting something like list("a"=c("1"=1), "b"=c("1"=2, "2"=5), "c"=c("1"=3), "d"=c("1"=4), "e"=c("1"=6)) for the above input. 
By giving the result this way I'm able to extract both names from two sets as well as the according value between both items.

One point could be to build a matrix but this matrix would have many NA's. So I prefer Lists of Lists.

Any ideas?

cheers
	Jan

-----Urspr??ngliche Nachricht-----
Von: Liaw, Andy [mailto:andy_liaw at merck.com] 
Gesendet: Montag, 15. August 2005 17:31
An: Jan Hummel; r-help at stat.math.ethz.ch
Betreff: RE: [R] Re-sort list of vectors

If all vectors in the list have the same length, why not use a matrix?  Then you'd just transpose the matrix if you need to.  If you really have to have it as a list, here's one possibility:

> x <- list("1"=c(a=1, b=2, c=3), "2"=c(a=4, b=5, c=6)) x
$"1"
a b c
1 2 3 

$"2"
a b c
4 5 6 
> as.list(as.data.frame(t(matrix(unlist(x), nrow=3))))
$V1
[1] 1 4

$V2
[1] 2 5

$V3
[1] 3 6

Andy


> From: Jan Hummel
> 
> Hi.
> Can anyone suggest a simple way to re-sort in R a list of vectors of 
> the following form?
> 
> input
> $"1"
> 	a	b	c
> 	1	2	3
> $"2"
> 	a	b	c
> 	4	5	6
> 
> Output should be something like:
> "a"
> 	"1" 1
> 	"2" 4
> "b"
> 	"1" 2
> 	"2" 5
> "c"
> 	"1" 3
> 	"2" 6
> 
> I've been futzing with mapply(), outer(), split(), rbind() and so on 
> but haven't found an elegant solution.
> 
> Thanks,
> Jan.
> 
> P.S. E-mailed CCs of posted replies appreciated.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From gunter.berton at gene.com  Mon Aug 15 19:11:50 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 15 Aug 2005 10:11:50 -0700
Subject: [R] PCA problem in R
In-Reply-To: <200508151656.j7FGuSBT019203@upham.cgd.ucar.edu>
Message-ID: <200508151711.j7FHBo8q001710@volta.gene.com>

You are wrong. No covariance matrix is computed. Please don't "speculate" --
read the Help file which clearly states:

"The calculation is done by a singular value decomposition of the (centered
and possibly scaled) data matrix, not by using eigen on the covariance
matrix. This is generally the preferred method for numerical accuracy. "

-- Bert Gunter

> I speculate that the underlying function transposes the 
> input data matrix and computes the the TxT [rather than SxS]
> covariance matrix and solves for the eigenvalues/vectors. 
> It then uses a linear transformation to get the results
> for the original input data matrix.
> 
> Computationally, the above is much faster and uses less memory.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From andy_liaw at merck.com  Mon Aug 15 19:14:07 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 15 Aug 2005 13:14:07 -0400
Subject: [R] PCA problem in R
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EBCD@usctmx1106.Merck.com>

> From: Dennis Shea
> 
> [SNIP]>> 
> >>>On Sat, 13 Aug 2005, Alan Zhao wrote:
> >>>
> >>>>When I have more variables than units, say a 195*10896 
> matrix which has
> >>>>10896 variables and 195 samples. prcomp will give only 
> 195 principal
> >>>>components. I checked in the help, but there is no 
> explanation that why
> >>>>this happen.
> 
> [SNIP]
> 
> >Sincerely,
> >Zheng Zhao
> >Aug-14-2005
> >______________________________________________
> 
> Just yesterday I subscribed to r-help because I am planning
> on learning the basics of R ... today.   :-)
> Thus, I am not sure about the history of this question.
> 
> The above situation, more variables than samples, 
> is commonly encounterd in the climate studies.
> Consider annual mean temperatures for 195 years
> on a coarse 72 [lat] x 144 [lon]  grid [72*144=10368 
> spatial variables]. 
> 
> Let  S be the number of grid points and T be the number
> of years. I think there is a theorem (?Eckart-Young?) 
> which states that the maximum number of unique eigenvalues 
> is min(S,T). In your case 195 eigenvalues is correct. 
> I speculate that the underlying function transposes the 
> input data matrix and computes the the TxT [rather than SxS]
> covariance matrix and solves for the eigenvalues/vectors. 
> It then uses a linear transformation to get the results
> for the original input data matrix.
> 
> Computationally, the above is much faster and uses less memory.

It is usually a good idea to consult the help page before speculating.
?prcomp has, in its `Detail' section:

The calculation is done by a singular value decomposition of the (centered
and possibly scaled) data matrix, not by using eigen on the covariance
matrix. This is generally the preferred method for numerical accuracy. 

Andy
 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From andy_liaw at merck.com  Mon Aug 15 19:18:05 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 15 Aug 2005 13:18:05 -0400
Subject: [R] Re-sort list of vectors
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EBCE@usctmx1106.Merck.com>

You could try using one of the sparse representations of matrices in the
SparseM or Matrix packages.  Both packages have vignettes.

Andy

> From: Jan Hummel
> 
>  Thanks a lot! But unfortunately I will not know the 
> dimensions of both lists. And further, the lists may be 
> (partly) disjoint as: x <- list("1"=c(a=1, b=2, c=3), 
> "2"=c(d=4, b=5, e=6)). And last but not least I'm really have 
> to have access to the names of the named list items.
> 
> The problem I dealt with is in unlist() merging the names 
> together, as you can see in your example given: "V1", "V2" 
> and "V3". Because off interpreting the names later as 
> identifiers in db queries I'm really interested in getting 
> something like list("a"=c("1"=1), "b"=c("1"=2, "2"=5), 
> "c"=c("1"=3), "d"=c("1"=4), "e"=c("1"=6)) for the above input. 
> By giving the result this way I'm able to extract both names 
> from two sets as well as the according value between both items.
> 
> One point could be to build a matrix but this matrix would 
> have many NA's. So I prefer Lists of Lists.
> 
> Any ideas?
> 
> cheers
> 	Jan
> 
> -----Urspr??ngliche Nachricht-----
> Von: Liaw, Andy [mailto:andy_liaw at merck.com] 
> Gesendet: Montag, 15. August 2005 17:31
> An: Jan Hummel; r-help at stat.math.ethz.ch
> Betreff: RE: [R] Re-sort list of vectors
> 
> If all vectors in the list have the same length, why not use 
> a matrix?  Then you'd just transpose the matrix if you need 
> to.  If you really have to have it as a list, here's one possibility:
> 
> > x <- list("1"=c(a=1, b=2, c=3), "2"=c(a=4, b=5, c=6)) x
> $"1"
> a b c
> 1 2 3 
> 
> $"2"
> a b c
> 4 5 6 
> > as.list(as.data.frame(t(matrix(unlist(x), nrow=3))))
> $V1
> [1] 1 4
> 
> $V2
> [1] 2 5
> 
> $V3
> [1] 3 6
> 
> Andy
> 
> 
> > From: Jan Hummel
> > 
> > Hi.
> > Can anyone suggest a simple way to re-sort in R a list of 
> vectors of 
> > the following form?
> > 
> > input
> > $"1"
> > 	a	b	c
> > 	1	2	3
> > $"2"
> > 	a	b	c
> > 	4	5	6
> > 
> > Output should be something like:
> > "a"
> > 	"1" 1
> > 	"2" 4
> > "b"
> > 	"1" 2
> > 	"2" 5
> > "c"
> > 	"1" 3
> > 	"2" 6
> > 
> > I've been futzing with mapply(), outer(), split(), rbind() 
> and so on 
> > but haven't found an elegant solution.
> > 
> > Thanks,
> > Jan.
> > 
> > P.S. E-mailed CCs of posted replies appreciated.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From ivo_welch-rstat8303 at mailblocks.com  Mon Aug 15 19:23:22 2005
From: ivo_welch-rstat8303 at mailblocks.com (ivo_welch-rstat8303@mailblocks.com)
Date: Mon, 15 Aug 2005 10:23:22 -0700
Subject: [R] paste / system mystery
Message-ID: <200508151723.j7FHNPY9009618@hypatia.math.ethz.ch>


Dear R wizards:

under R-2.1.0:

eargs <- 3:5;
line <- paste(c("echo A B", eargs));
cat("executing from R: '", line, "'\n");
system(line);

Oddly, only "A" and "B" are echoed, not the eargs.  I had hoped that 
line would be one string at this point, and for printing this seems to 
be true.  However, unlist(line) still gives me the 4 components.  It 
almost seems like the objects were not really pasted, but kept separate 
[perhaps to conserve memory]---which works internally, but not 
externally.

Is this my poor understanding of R, an R "feature," or an R bug?

help appreciated.

/iaw


---
ivo welch



From jholtman at gmail.com  Mon Aug 15 19:37:06 2005
From: jholtman at gmail.com (jim holtman)
Date: Mon, 15 Aug 2005 13:37:06 -0400
Subject: [R] Re-sort list of vectors
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EBCE@usctmx1106.Merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EBCE@usctmx1106.Merck.com>
Message-ID: <644e1f320508151037207527db@mail.gmail.com>

Not that I like loops, but here is a quick and dirty way of doing it:

Result <- list()
for (i in names(x)){
    for (j in names(x[[i]])){
        Result[[j]][[i]] <- x[[i]][[j]]
    }
}


On 8/15/05, Liaw, Andy <andy_liaw at merck.com> wrote:
> You could try using one of the sparse representations of matrices in the
> SparseM or Matrix packages.  Both packages have vignettes.
> 
> Andy
> 
> > From: Jan Hummel
> >
> >  Thanks a lot! But unfortunately I will not know the
> > dimensions of both lists. And further, the lists may be
> > (partly) disjoint as: x <- list("1"=c(a=1, b=2, c=3),
> > "2"=c(d=4, b=5, e=6)). And last but not least I'm really have
> > to have access to the names of the named list items.
> >
> > The problem I dealt with is in unlist() merging the names
> > together, as you can see in your example given: "V1", "V2"
> > and "V3". Because off interpreting the names later as
> > identifiers in db queries I'm really interested in getting
> > something like list("a"=c("1"=1), "b"=c("1"=2, "2"=5),
> > "c"=c("1"=3), "d"=c("1"=4), "e"=c("1"=6)) for the above input.
> > By giving the result this way I'm able to extract both names
> > from two sets as well as the according value between both items.
> >
> > One point could be to build a matrix but this matrix would
> > have many NA's. So I prefer Lists of Lists.
> >
> > Any ideas?
> >
> > cheers
> >       Jan
> >
> > -----Urspr??ngliche Nachricht-----
> > Von: Liaw, Andy [mailto:andy_liaw at merck.com]
> > Gesendet: Montag, 15. August 2005 17:31
> > An: Jan Hummel; r-help at stat.math.ethz.ch
> > Betreff: RE: [R] Re-sort list of vectors
> >
> > If all vectors in the list have the same length, why not use
> > a matrix?  Then you'd just transpose the matrix if you need
> > to.  If you really have to have it as a list, here's one possibility:
> >
> > > x <- list("1"=c(a=1, b=2, c=3), "2"=c(a=4, b=5, c=6)) x
> > $"1"
> > a b c
> > 1 2 3
> >
> > $"2"
> > a b c
> > 4 5 6
> > > as.list(as.data.frame(t(matrix(unlist(x), nrow=3))))
> > $V1
> > [1] 1 4
> >
> > $V2
> > [1] 2 5
> >
> > $V3
> > [1] 3 6
> >
> > Andy
> >
> >
> > > From: Jan Hummel
> > >
> > > Hi.
> > > Can anyone suggest a simple way to re-sort in R a list of
> > vectors of
> > > the following form?
> > >
> > > input
> > > $"1"
> > >     a       b       c
> > >     1       2       3
> > > $"2"
> > >     a       b       c
> > >     4       5       6
> > >
> > > Output should be something like:
> > > "a"
> > >     "1" 1
> > >     "2" 4
> > > "b"
> > >     "1" 2
> > >     "2" 5
> > > "c"
> > >     "1" 3
> > >     "2" 6
> > >
> > > I've been futzing with mapply(), outer(), split(), rbind()
> > and so on
> > > but haven't found an elegant solution.
> > >
> > > Thanks,
> > > Jan.
> > >
> > > P.S. E-mailed CCs of posted replies appreciated.
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> > >
> > >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Jim Holtman
Convergys
+1 513 723 2929

What the problem you are trying to solve?



From ripley at stats.ox.ac.uk  Mon Aug 15 19:42:32 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Aug 2005 18:42:32 +0100 (BST)
Subject: [R] PCA problem in R
In-Reply-To: <200508151656.j7FGuSBT019203@upham.cgd.ucar.edu>
References: <200508151656.j7FGuSBT019203@upham.cgd.ucar.edu>
Message-ID: <Pine.LNX.4.61.0508151820130.7406@gannet.stats>

On Mon, 15 Aug 2005, Dennis Shea wrote:

> [SNIP]>>
>>>> On Sat, 13 Aug 2005, Alan Zhao wrote:
>>>>
>>>>> When I have more variables than units, say a 195*10896 matrix which has
>>>>> 10896 variables and 195 samples. prcomp will give only 195 principal
>>>>> components. I checked in the help, but there is no explanation that why
>>>>> this happen.
>
> [SNIP]
>
>> Sincerely,
>> Zheng Zhao
>> Aug-14-2005
>> ______________________________________________
>
> Just yesterday I subscribed to r-help because I am planning
> on learning the basics of R ... today.   :-)
> Thus, I am not sure about the history of this question.

> The above situation, more variables than samples,
> is commonly encounterd in the climate studies.
> Consider annual mean temperatures for 195 years
> on a coarse 72 [lat] x 144 [lon]  grid [72*144=10368
> spatial variables].

Which are variables and which are samples here?  In standard statistical 
parlance you have 195 variables at 10368 samples. In some fields there are 
the concepts of R-mode and Q-mode PCA, and you seem to be in Q-mode, which 
is why you have a transpose.

> Let  S be the number of grid points and T be the number
> of years. I think there is a theorem (?Eckart-Young?)
> which states that the maximum number of unique eigenvalues
> is min(S,T). In your case 195 eigenvalues is correct.

Eigenvalues of what?  Eckart-Young is about the SVD, see e.g.

http://voteview.com/ideal_point_Eckart_Young_Theorem.htm

as Googling easily shows.  (It is used to prove some of the approximation 
properties of PCA, e.g. in

http://www.stats.ox.ac.uk/~ripley/MultAnal_MT2004/PCA.pdf)

> I speculate that the underlying function transposes the
> input data matrix and computes the the TxT [rather than SxS]
> covariance matrix and solves for the eigenvalues/vectors.
> It then uses a linear transformation to get the results
> for the original input data matrix.
>
> Computationally, the above is much faster and uses less memory.

You speculate incorrectly, even in your Q-mode view of the world.
The real point is that is solves a different problem, which is what my 
answer to the original post was about.

> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

It really would be a good idea to do the homework it suggests.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Mon Aug 15 19:43:44 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 15 Aug 2005 10:43:44 -0700 (PDT)
Subject: [R] paste / system mystery
In-Reply-To: <200508151723.j7FHNPY9009618@hypatia.math.ethz.ch>
References: <200508151723.j7FHNPY9009618@hypatia.math.ethz.ch>
Message-ID: <Pine.A41.4.61b.0508151043110.279420@homer06.u.washington.edu>

On Mon, 15 Aug 2005 ivo_welch-rstat8303 at mailblocks.com wrote:

>
> Dear R wizards:
>
> under R-2.1.0:
>
> eargs <- 3:5;
> line <- paste(c("echo A B", eargs));
> cat("executing from R: '", line, "'\n");
> system(line);
>
> Oddly, only "A" and "B" are echoed, not the eargs.  I had hoped that
> line would be one string at this point, and for printing this seems to
> be true.  However, unlist(line) still gives me the 4 components.  It
> almost seems like the objects were not really pasted, but kept separate
> [perhaps to conserve memory]---which works internally, but not
> externally.
>
> Is this my poor understanding of R, an R "feature," or an R bug?
>

It's your understanding.  Look at the `collapse' argument to paste().

 	-thomas



From dmbates at gmail.com  Mon Aug 15 19:48:27 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Mon, 15 Aug 2005 12:48:27 -0500
Subject: [R] paste / system mystery
In-Reply-To: <200508151723.j7FHNPY9009618@hypatia.math.ethz.ch>
References: <200508151723.j7FHNPY9009618@hypatia.math.ethz.ch>
Message-ID: <40e66e0b05081510487765317f@mail.gmail.com>

On 8/15/05, ivo_welch-rstat8303 at mailblocks.com
<ivo_welch-rstat8303 at mailblocks.com> wrote:
> 
> Dear R wizards:
> 
> under R-2.1.0:
> 
> eargs <- 3:5;
> line <- paste(c("echo A B", eargs));
> cat("executing from R: '", line, "'\n");
> system(line);
> 
> Oddly, only "A" and "B" are echoed, not the eargs.  I had hoped that
> line would be one string at this point, and for printing this seems to
> be true.  However, unlist(line) still gives me the 4 components.  It
> almost seems like the objects were not really pasted, but kept separate
> [perhaps to conserve memory]---which works internally, but not
> externally.
> 
> Is this my poor understanding of R, an R "feature," or an R bug?

Poor understanding but the mistake is a common one.  If you want to
form a character vector of length 1 you must use the "collapse"
argument to paste().  Try

> eargs <- 3:5
> paste("echo A B", paste(eargs, collapse = " "))
[1] "echo A B 3 4 5"
>



From ligges at statistik.uni-dortmund.de  Mon Aug 15 19:52:11 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 15 Aug 2005 19:52:11 +0200
Subject: [R] paste / system mystery
In-Reply-To: <200508151723.j7FHNPY9009618@hypatia.math.ethz.ch>
References: <200508151723.j7FHNPY9009618@hypatia.math.ethz.ch>
Message-ID: <4300D64B.8040504@statistik.uni-dortmund.de>

ivo_welch-rstat8303 at mailblocks.com wrote:

> Dear R wizards:
> 
> under R-2.1.0:
> 
> eargs <- 3:5;
> line <- paste(c("echo A B", eargs));
> cat("executing from R: '", line, "'\n");
> system(line);
> 
> Oddly, only "A" and "B" are echoed, not the eargs.  I had hoped that 
> line would be one string at this point, and for printing this seems to 
> be true.  However, unlist(line) still gives me the 4 components.  It 
> almost seems like the objects were not really pasted, but kept separate 
> [perhaps to conserve memory]---which works internally, but not 
> externally.
> 
> Is this my poor understanding of R, an R "feature," or an R bug?

Feature:
The arguments of paste() get pasted, and you have just specified one 
argument which is a character *vector*.
You want to say that the elements of the vector should be pasted as follows:

line <- paste(c("echo A B", eargs), collapse = " ")

Uwe Ligges




> help appreciated.
> 
> /iaw
> 
> 
> ---
> ivo welch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ramasamy at cancer.org.uk  Mon Aug 15 08:00:04 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Mon, 15 Aug 2005 07:00:04 +0100
Subject: [R] Re-sort list of vectors
In-Reply-To: <1F5B2A5E6712B94DA65EA9EBF0A1A38230E2B3@EMAIL.mpimp-golm.mpg.de>
References: <1F5B2A5E6712B94DA65EA9EBF0A1A38230E2B3@EMAIL.mpimp-golm.mpg.de>
Message-ID: <1124085604.6000.62.camel@ipc143004.lif.icnet.uk>

Here is one possible and ugly hack. 

 mylist  <- list("1"=c(a=1, b=2, c=3), "2"=c(d=4, b=5, e=6))

 myvec   <- unlist( mylist )
   1.a 1.b 1.c 2.d 2.b 2.e 
     1   2   3   4   5   6 
 
 mymat   <- sapply( strsplit( names(myvec) , split="\\." ) , c )
      [,1] [,2] [,3] [,4] [,5] [,6]
  [1,] "1"  "1"  "1"  "2"  "2"  "2" 
  [2,] "a"  "b"  "c"  "d"  "b"  "e" 


 tmp     <- data.frame( "main"=mymat[2,], 
                        "sub"=mymat[ 1,], "value"=myvec )
     main sub value
 1.a    a   1     1
 1.b    b   1     2
 1.c    c   1     3
 2.d    d   2     4
 2.b    b   2     5
 2.e    e   2     6

I would be quite happy with at this point to loop through the rows and
insert this element by element into MySQL. This may be inefficient for
large datasets. Otherwise I can create this into a matrix with NAs.


So here is my ugly hack to get the list format that you desire. 

 tmp2    <- data.frame( "main"=tmp$main, 
              "elements"=paste('"', tmp$sub, '"=', tmp$value, sep="") )

 newlist <- tapply( noquote(as.character(tmp2$elements)), tmp2$main, c )

 newlist
 $a
 [1] "1"=1

 $b
 [1] "1"=2 "2"=5

 $c
 [1] "1"=3

 $d
 [1] "2"=4

 $e
 [1] "2"=6

I am sure someone will come up with a shorter and neater solution.

Regards, Adai



On Mon, 2005-08-15 at 19:09 +0200, Jan Hummel wrote:
>  Thanks a lot! But unfortunately I will not know the dimensions of both lists. And further, the lists may be (partly) disjoint as: x <- list("1"=c(a=1, b=2, c=3), "2"=c(d=4, b=5, e=6)). And last but not least I'm really have to have access to the names of the named list items.
> 
> The problem I dealt with is in unlist() merging the names together, as you can see in your example given: "V1", "V2" and "V3". Because off interpreting the names later as identifiers in db queries I'm really interested in getting something like list("a"=c("1"=1), "b"=c("1"=2, "2"=5), "c"=c("1"=3), "d"=c("1"=4), "e"=c("1"=6)) for the above input. 
> By giving the result this way I'm able to extract both names from two sets as well as the according value between both items.
> 
> One point could be to build a matrix but this matrix would have many NA's. So I prefer Lists of Lists.
> 
> Any ideas?
> 
> cheers
> 	Jan
> 
> -----UrsprÃ¼ngliche Nachricht-----
> Von: Liaw, Andy [mailto:andy_liaw at merck.com] 
> Gesendet: Montag, 15. August 2005 17:31
> An: Jan Hummel; r-help at stat.math.ethz.ch
> Betreff: RE: [R] Re-sort list of vectors
> 
> If all vectors in the list have the same length, why not use a matrix?  Then you'd just transpose the matrix if you need to.  If you really have to have it as a list, here's one possibility:
> 
> > x <- list("1"=c(a=1, b=2, c=3), "2"=c(a=4, b=5, c=6)) x
> $"1"
> a b c
> 1 2 3 
> 
> $"2"
> a b c
> 4 5 6 
> > as.list(as.data.frame(t(matrix(unlist(x), nrow=3))))
> $V1
> [1] 1 4
> 
> $V2
> [1] 2 5
> 
> $V3
> [1] 3 6
> 
> Andy
> 
> 
> > From: Jan Hummel
> > 
> > Hi.
> > Can anyone suggest a simple way to re-sort in R a list of vectors of 
> > the following form?
> > 
> > input
> > $"1"
> > 	a	b	c
> > 	1	2	3
> > $"2"
> > 	a	b	c
> > 	4	5	6
> > 
> > Output should be something like:
> > "a"
> > 	"1" 1
> > 	"2" 4
> > "b"
> > 	"1" 2
> > 	"2" 5
> > "c"
> > 	"1" 3
> > 	"2" 6
> > 
> > I've been futzing with mapply(), outer(), split(), rbind() and so on 
> > but haven't found an elegant solution.
> > 
> > Thanks,
> > Jan.
> > 
> > P.S. E-mailed CCs of posted replies appreciated.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dmbates at gmail.com  Mon Aug 15 20:02:46 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Mon, 15 Aug 2005 13:02:46 -0500
Subject: [R] Compilation failures: mgcv, spatstat, Matrix, cluster
In-Reply-To: <Pine.OSF.4.58.0508131828010.350399@odin.mdacc.tmc.edu>
References: <98CBCB22-9D53-4016-95E5-2496D7C204C9@virginia.edu>
	<Pine.OSF.4.58.0508131828010.350399@odin.mdacc.tmc.edu>
Message-ID: <40e66e0b050815110269e4c0a3@mail.gmail.com>

On 8/13/05, Paul Roebuck <roebuck at odin.mdacc.tmc.edu> wrote:
> On Sat, 13 Aug 2005, Michael Kubovy wrote:
> 
> > With Version 2.1.1  (2005-06-20) on Power Mac G5 running Mac OS X
> > 10.4.2 (8C46):
> >
> > Some compilations work (e.g., MatchIt, RGraphics, Zelig), and some
> > don't, e.g., mgcv, spatstat,  and the following (Matrix, cluster):
> >
> > trying URL 'http://www.ibiblio.org/pub/languages/R/CRAN/src/contrib/
> > Matrix_0.98-3.tar.gz'
> > Content type 'application/x-tar' length 626712 bytes
> > opened URL
> > ==================================================
> > downloaded 612Kb
> >
> > * Installing *source* package 'Matrix' ...
> > ** libs
> >
> > The downloaded packages are in
> >      /private/tmp/RtmpPddsAE/downloaded_packages
> > gcc-3.3 -no-cpp-precomp -I/Library/Frameworks/R.framework/Resources/
> > include  -I/usr/local/include  -I./Metis -fno-common  -g -O2 -c
> > HBMM.c -o HBMM.o
> > In file included from HBMM.c:2:
> > iohb.h:6:19: malloc.h: No such file or directory
> > make: *** [HBMM.o] Error 1
> > ERROR: compilation failed for package 'Matrix'
> 
> Didn't check package for actually functioning correctly,
> but the following changes will allow compilation on OS X
> 10.3. In ANSI C, the standard memory allocation routines
> are declared in <stdlib.h>; <malloc.h> is obsolete for that
> purpose and isn't guaranteed to exist.
> 
> 
> Matrix/src/mmio.c:
>     Add #include <stdlib.h>
>     Remove #include <malloc.h>
> 
> Matrix/src/iohb.h:
>     Remove #include <malloc.h>

Thanks for the suggestion, Paul.  I wasn't quite as sloppy as it may
seem.  I recently introduced the iohb.[hc] and mmio.[hc] files from
NIST into the Matrix package but I didn't check them thoroughly before
doing so.  I should have.  Those are not the only antiquated C
constructs in those files.  The author of iohb.c also assumes that he
can pass a string constant to a function that modifies the contents of
that argument and, of course, gcc will produce code that segfaults at
that point if you do not use -fwriteable-strings and we don't want to
do that.



From amsa36060 at yahoo.com  Mon Aug 15 20:05:02 2005
From: amsa36060 at yahoo.com (Amir Safari)
Date: Mon, 15 Aug 2005 11:05:02 -0700 (PDT)
Subject: [R] How to insert a certain model in SVM regarding to fixed
	kernels
In-Reply-To: <971536df050812051810a66bf3@mail.gmail.com>
Message-ID: <20050815180502.99406.qmail@web60416.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050815/a78a2691/attachment.pl

From dmbates at gmail.com  Mon Aug 15 20:16:33 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Mon, 15 Aug 2005 13:16:33 -0500
Subject: [R] monte carlo simulations/lmer
In-Reply-To: <e474b379050813162662727148@mail.gmail.com>
References: <e474b379050813162662727148@mail.gmail.com>
Message-ID: <40e66e0b05081511166de21d74@mail.gmail.com>

On 8/13/05, Eduardo Leoni <e.leoni at gmail.com> wrote:
> Hi - I am doing some monte carlo simulations comparing bayesian (using
> Plummer's jags) and maximum likelihood (using lmer from package lme4
> by Bates et al).
> 
> I would like to know if there is a way I can flag nonconvergence and
> exceptions. Currently the simulations just stop and the output reads
> things like:
> 
> Error in optim(.Call("lmer_coef", x, 2, PACKAGE = "Matrix"), fn, gr,
> method = "L-BFGS-B",  :
>     L-BFGS-B needs finite values of 'fn'
> In addition: Warning message:
> Leading minor of size 1 of downdated X'X is indefinite
> 
> Error in .local(object, ...) : Leading 2 minor of Omega[[1]] not
> positive definite
> In addition: Warning messages:
> 1: optim or nlminb returned message ERROR: ABNORMAL_TERMINATION_IN_LNSRCH
> in: "LMEoptimize<-"(`*tmp*`, value = list(maxIter = 200, msMaxIter = 200,
> 2: optim or nlminb returned message ERROR: ABNORMAL_TERMINATION_IN_LNSRCH
> in: "LMEoptimize<-"(`*tmp*`, value = list(maxIter = 200, msMaxIter = 200,

As Rolf Turner indicated, you can wrap the call to lmer in try() to
prevent breaking the loop on convergence failure.  I'm not sure
exactly what Bayesian analysis you are doing but you may want to look
at the function mcmcsamp in versions 0.98-1and later of the Matrix
package.  It can take a fitted lmer object and create an MCMC sample
from the posterior distribution of the parameters assuming a locally
uniform prior on the fixed-effects parameters and the non-informative
prior described by Box and Tiao for the variance-covariance matrices.



From melanie.vida at gmail.com  Mon Aug 15 21:47:34 2005
From: melanie.vida at gmail.com (mmv)
Date: Mon, 15 Aug 2005 15:47:34 -0400
Subject: [R] randomForest Error passing string argument
Message-ID: <aaaf40920508151247543a645c@mail.gmail.com>

I'm attempting to pass a string argument into the function
randomForest but I get an error:

state <- paste(list("fruit ~", "apples+oranges+blueberries",
"data=fruits.data, mtry=2, do.trace=100, na.action=na.omit,
keep.forest=TRUE"), sep= " ", collapse="")

model.rf <- randomForest(state)

Error in if (n==0) stop ("data(x) has 0 rows") argument is of length zero.

-Thanks in advance,



From ligges at statistik.uni-dortmund.de  Mon Aug 15 22:12:42 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 15 Aug 2005 22:12:42 +0200
Subject: [R] randomForest Error passing string argument
In-Reply-To: <aaaf40920508151247543a645c@mail.gmail.com>
References: <aaaf40920508151247543a645c@mail.gmail.com>
Message-ID: <4300F73A.9020605@statistik.uni-dortmund.de>

mmv wrote:

> I'm attempting to pass a string argument into the function
> randomForest but I get an error:
> 
> state <- paste(list("fruit ~", "apples+oranges+blueberries",
> "data=fruits.data, mtry=2, do.trace=100, na.action=na.omit,
> keep.forest=TRUE"), sep= " ", collapse="")


I really don't understand why you want it as a character.
I think you probably want to generate arguments dynamically and specify 
them in form of a list, which leads to constructions using do.call() at 
the end.

Anyway, if you really want to call randomForest with the abouve text, I 
guess this is one of tzhe few circumstances where you can do 
eval(parse(.....)):

state <- paste("fruit ~", "apples+oranges+blueberries,",
   "data=fruits.data, mtry=2, do.trace=100, na.action=na.omit,
    keep.forest=TRUE")
the_call <- paste("randomForest(", state, ")")
eval(parse(text=the_call))

Uwe Ligges


> model.rf <- randomForest(state)
> 
> Error in if (n==0) stop ("data(x) has 0 rows") argument is of length zero.
> 
> -Thanks in advance,
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From xiyanlon at gmail.com  Mon Aug 15 22:38:50 2005
From: xiyanlon at gmail.com (Xiyan Lon)
Date: Mon, 15 Aug 2005 22:38:50 +0200
Subject: [R] How to get a list work in RData file
Message-ID: <4300FD5A.2020808@gmail.com>

Dear R-Helper,
I want to know how I get a list  work which I saved in RData file. For 
example,

 > test.xy <- function(x,y) {
+    xy <- x+y
+    xy
+ }
 >
 > xyadd <- test.xy(x=2, y=3)
 > xyadd
[1] 5
 > x1 <- c(2,43,60,8)
 > y1 <- c(91,7,5,30)
 >
 > xyadd1 <- test.xy(x=x1, y=y1)
 > xyadd1
[1] 93 50 65 38
 > save(list = ls(all=TRUE), file = "testxy.RData")
 > rm(list=ls(all=TRUE))
 > load("C:/R/useR/testxy.RData")
 > ls()
[1] "test.xy" "x1"      "xyadd"   "xyadd1"  "y1"    
 >
 > ls.str(pat="xyadd")
xyadd :  num 5
xyadd1 :  num [1:4] 93 50 65 38
 >

When I run, I know the result like above
 > xyadd
[1] 5
 > xyadd1
[1] 93 50 65 38
 >
what I want to know, is there any function to make the result like:

 > xyadd

         test.xy(x=2, y=3)

and

 > xyadd1

        test.xy(x=x1, y=y1)

Best,
Xiyan Lon



From slist at oomvanlieshout.net  Mon Aug 15 22:51:01 2005
From: slist at oomvanlieshout.net (Sander Oom)
Date: Mon, 15 Aug 2005 22:51:01 +0200
Subject: [R] How to repeat code snippet for several variables in a data
	frame?
Message-ID: <43010035.103@oomvanlieshout.net>

Dear all,

I have a data frame containing the results of an experiment. Like this:

a<-seq(1,4,by=1)
b<-seq(1,2,by=1)
test<-expand.grid(b,a,a)
colnames(test)<-c("replicates","bins", "groups")
test$abc <- rnorm(32)
test$def <- rnorm(32)
test$ghi <- rnorm(32)
test

The following code snippet aggregates the data for one variable and then 
draws a plot:

tmp <- aggregate(test$abc, list(
   test$bins, test$groups),
   mean)
colnames(tmp) <- c("bins", "groups", "abc")
tmp
#pltName <- paste("line_datGrassChem_", "abc", ".eps", sep="")
#postscript(pltName)
   labs <- c("-15/-9","-9/-6","-6/-3","-3/0")
   sps <- trellis.par.get("superpose.symbol")
   sps$pch <- 1:4
   trellis.par.set("superpose.symbol", sps)
   xyplot( abc ~ bins, data = tmp,
     groups = groups, type = list("p", "l"),
     scales = list(x = list(labels=labs)),
     layout = c(1,1),
     key = list(columns = 4,
       text = list(paste(unique(tmp$groups))),
       points = Rows(sps, 1:4)
       )
   )
#dev.off()

How can I wrap R code around this code snippet, such that I can repeat 
the same code snippet for all other variables in the data frame (i.e. 
def, ghi, etc.).

Thanks for your suggestions!

Sander.

-- 
--------------------------------------------
Dr Sander P. Oom
Animal, Plant and Environmental Sciences,
University of the Witwatersrand
Private Bag 3, Wits 2050, South Africa
Tel (work)      +27 (0)11 717 64 04
Tel (home)      +27 (0)18 297 44 51
Fax             +27 (0)18 299 24 64
Email   sander at oomvanlieshout.net
Web     www.oomvanlieshout.net/sander



From tate_sterling_avery at hotmail.com  Mon Aug 15 22:57:48 2005
From: tate_sterling_avery at hotmail.com (Tate Avery)
Date: Mon, 15 Aug 2005 16:57:48 -0400
Subject: [R] Manually Calculating Odds from POLR Model
In-Reply-To: <20050812232223.TSDK1799.tomts40-srv.bellnexxia.net@JohnDesktop8300>
Message-ID: <BAY103-F1285823B1FE6D8AF411D5AAEB10@phx.gbl>

John,

Thank you, the document was very helpful.  I can now calculate the same 
values generated by predict() when I am using purely numeric input data.

Another small question arises when I look at the example using 'housing' in 
the polr() documentation page:

Running the example produces the following coefficients...

Coefficients:
   InflMedium      InflHigh TypeApartment    TypeAtrium   TypeTerrace      
ContHigh
    0.5663924     1.2888218    -0.5723552    -0.3661912    -1.0910195     
0.3602834

Now, if I am trying to perform a prediction and the value for INFL comes in 
as 'Medium' what is done?  And, what is done for 'low'?

That seems to be the last missing piece in my understanding of how to 
convert the model values into predictions.

Thank you,
Tate

>From: "John Fox" <jfox at mcmaster.ca>
>To: "'Tate Avery'" <tate_sterling_avery at hotmail.com>
>CC: <r-help at stat.math.ethz.ch>
>Subject: RE: [R] Manually Calculating Odds from POLR Model
>Date: Fri, 12 Aug 2005 19:22:23 -0400
>
>Dear Tate,
>
>If I understand correctly what you're asking, the formulas are on p. 21 of
>the paper at
><http://socserv.socsci.mcmaster.ca/jfox/Papers/logit-effect-displays.pdf>.
>But why do you want to do this when you can get the fitted probabilities
>from predict()?
>
>I hope this helps.
>  John
>
>--------------------------------
>John Fox
>Department of Sociology
>McMaster University
>Hamilton, Ontario
>Canada L8S 4M4
>905-525-9140x23604
>http://socserv.mcmaster.ca/jfox
>--------------------------------
>
> > -----Original Message-----
> > From: r-help-bounces at stat.math.ethz.ch
> > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tate Avery
> > Sent: Friday, August 12, 2005 2:50 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Manually Calculating Odds from POLR Model
> >
> > Hello,
> >
> > I am using polr(...) to generate a model.  The summary shows
> > the coefficients and the intercepts.
> >
> > For example:
> >
> >     coefficient for x1 = c1
> >     coefficient for x2 = c2
> >
> >     intercept A|B = i1
> >     intercept B|C = i2
> >
> > I can then run predict(..., type="p") with the model and see
> > the odds for each factor.
> >
> > For example:
> >
> >       A        B        C
> > 1    0.3     0.5      0.2
> > 2    0.4     0.1      0.5
> >
> > What I really want to be able to do is take the 2
> > coefficients, the 2 intercepts, the x1 & x2 values and
> > manually calculate the probabilities generated by predict().
> >
> > I have been searching quite extensively for the underlying
> > calculations that transform the polr output and the input
> > variables into the final output odds.  I have tried a number
> > of dead-end roads so far.
> >
> > So, if anyone has any information on how to do this or where
> > I can find out, I would be extremely grateful.
> >
> > Thank you for your time,
> > Tate Avery
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
>



From sdavis2 at mail.nih.gov  Mon Aug 15 23:04:49 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Mon, 15 Aug 2005 17:04:49 -0400
Subject: [R] R CMD check  failure on minimal code
Message-ID: <BF267BB1.C726%sdavis2@mail.nih.gov>

I have a peculiar problem that I'm sure is a simple one, but I can't figure
out what my mistake is.  Can someone enlighten me?  I have a simple file,
class.R:

##
setClass("abc",representation(a = "character", b = "ANY"))

I have a package directory ExpressCGH1 made with package.skeleton.  The
package happily builds and installs, but R CMD check fails with (ignoring
the documenation warnings, etc.):

> version
         _         
platform powerpc-apple-darwin7.9.0
arch     powerpc   
os       darwin7.9.0
system   powerpc, darwin7.9.0
status   Patched   
major    2         
minor    1.1       
year     2005      
month    08        
day      12        
language R         



%%% R CMD check -l '/User
s/sdavis/Library/R/library' ExpressCGH1
* checking for working latex ... OK
* using log directory
'/Users/sdavis/Work/R-Programs/packages/devel/ExpressCGH/E
xpressCGH1.Rcheck'
* using R version 2.1.1, 2005-08-12
* checking for file 'ExpressCGH1/DESCRIPTION' ... OK
* checking extension type ... Package
* this is package 'ExpressCGH1' version '1.0'
* checking if this is a source package ... OK

* Installing *source* package 'ExpressCGH1' ...
** libs
WARNING: no source files found
chmod: /Users/sdavis/Library/R/library/ExpressCGH1/libs/*: No such file or
direc
tory
** R
** help
 >>> Building/Updating help pages for package 'ExpressCGH1'
     Formats: text html latex example
  convertDNAcopyOutput              text    html    latex   example
     missing link(s):  ~~fun~~
** building package indices ...
* DONE (ExpressCGH1)

* checking package directory ... OK
* checking for portable file names ... OK
* checking for sufficient/correct file permissions ... OK
* checking DESCRIPTION meta-information ... OK
* checking package dependencies ... OK
* checking index information ... OK
* checking package subdirectories ... WARNING
Subdirectory 'src' contains no source files.
* checking R files for syntax errors ... OK
* checking R files for library.dynam ... OK
* checking S3 generic/method consistency ... WARNING
Error: unable to load R code in package 'ExpressCGH1'
Call sequence:
2: stop(gettextf("unable to load R code in package '%s'",
libraryPkgName(package
)), 
       call. = FALSE, domain = NA)
1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose =
FALSE)
Execution halted
See section 'Generic functions and methods' of the 'Writing R Extensions'
manual.
* checking replacement functions ... WARNING
Error: unable to load R code in package 'ExpressCGH1'
Call sequence:
2: stop(gettextf("unable to load R code in package '%s'",
libraryPkgName(package
)), 
       call. = FALSE, domain = NA)
1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose =
FALSE)
Execution halted
In R, the argument of a replacement function which corresponds to the right
hand side must be named 'value'.
* checking foreign function calls ... WARNING
Error: unable to load R code in package 'ExpressCGH1'
Call sequence:
2: stop(gettextf("unable to load R code in package '%s'",
libraryPkgName(package
)), 
       call. = FALSE, domain = NA)
1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose =
FALSE)
Execution halted
See section 'System and foreign language interfaces' of the 'Writing R
Extensions' manual.
* checking Rd files ... WARNING
Rd files with likely Rd problems:
Unaccounted top-level text in file
'/Users/sdavis/Work/R-Programs/packages/devel
/ExpressCGH/ExpressCGH1/man/convertDNAcopyOutput.Rd':
Following section 'note':
"\n\n ~Make other sections like Warning with \\section{Warning }{....}
~\n\n"

Rd files with non-standard keywords:
  
/Users/sdavis/Work/R-Programs/packages/devel/ExpressCGH/ExpressCGH1/man/conv
er
tDNAcopyOutput.Rd:
    ~kwd1 ~kwd2
Each '\keyword' entry should specify one of the standard keywords (as
listed in file 'KEYWORDS.db' in the 'doc' subdirectory of the R home
directory).

See chapter 'Writing R documentation files' in manual 'Writing R
Extensions'.
* checking for missing documentation entries ... ERROR
Error: unable to load R code in package 'ExpressCGH1'



From ripley at stats.ox.ac.uk  Mon Aug 15 23:13:25 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Aug 2005 22:13:25 +0100 (BST)
Subject: [R] How to get a list work in RData file
In-Reply-To: <4300FD5A.2020808@gmail.com>
References: <4300FD5A.2020808@gmail.com>
Message-ID: <Pine.LNX.4.61.0508152209140.9609@gannet.stats>

On Mon, 15 Aug 2005, Xiyan Lon wrote:

> Dear R-Helper,
(There are quite a few of us.)

> I want to know how I get a list  work which I saved in RData file. For
> example,

I don't understand that at all, but it looks as if you want to save an 
unevaluated call, in which case see ?quote and use something like

xyadd <- quote(test.xy(x=2, y=3))

load and saving has nothing to do with this: it doesn't change the meaning 
of objects in the workspace.

> > test.xy <- function(x,y) {
> +    xy <- x+y
> +    xy
> + }
> >
> > xyadd <- test.xy(x=2, y=3)
> > xyadd
> [1] 5
> > x1 <- c(2,43,60,8)
> > y1 <- c(91,7,5,30)
> >
> > xyadd1 <- test.xy(x=x1, y=y1)
> > xyadd1
> [1] 93 50 65 38
> > save(list = ls(all=TRUE), file = "testxy.RData")
> > rm(list=ls(all=TRUE))
> > load("C:/R/useR/testxy.RData")
> > ls()
> [1] "test.xy" "x1"      "xyadd"   "xyadd1"  "y1"
> >
> > ls.str(pat="xyadd")
> xyadd :  num 5
> xyadd1 :  num [1:4] 93 50 65 38
> >
>
> When I run, I know the result like above
> > xyadd
> [1] 5
> > xyadd1
> [1] 93 50 65 38
> >
> what I want to know, is there any function to make the result like:
>
> > xyadd
>
>         test.xy(x=2, y=3)
>
> and
>
> > xyadd1
>
>        test.xy(x=x1, y=y1)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Mon Aug 15 23:19:07 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Aug 2005 22:19:07 +0100 (BST)
Subject: [R] R CMD check  failure on minimal code
In-Reply-To: <BF267BB1.C726%sdavis2@mail.nih.gov>
References: <BF267BB1.C726%sdavis2@mail.nih.gov>
Message-ID: <Pine.LNX.4.61.0508152215080.9609@gannet.stats>

Did you remember to declare a dependency on package 'methods'?  I suspect 
not.  Please see `Writing R Extensions'.

setClass is not part of base R, and those checks are being run with base 
R only.  I expect your package will not load when R is run with no default 
packages.  (Quite a few people run R without package 'methods' for 
speed, especially on startup -- it takes about half the startup time.)

On Mon, 15 Aug 2005, Sean Davis wrote:

> I have a peculiar problem that I'm sure is a simple one, but I can't figure
> out what my mistake is.  Can someone enlighten me?  I have a simple file,
> class.R:
>
> ##
> setClass("abc",representation(a = "character", b = "ANY"))
>
> I have a package directory ExpressCGH1 made with package.skeleton.  The
> package happily builds and installs, but R CMD check fails with (ignoring
> the documenation warnings, etc.):
>
>> version
>         _
> platform powerpc-apple-darwin7.9.0
> arch     powerpc
> os       darwin7.9.0
> system   powerpc, darwin7.9.0
> status   Patched
> major    2
> minor    1.1
> year     2005
> month    08
> day      12
> language R
>
>
>
> %%% R CMD check -l '/User
> s/sdavis/Library/R/library' ExpressCGH1
> * checking for working latex ... OK
> * using log directory
> '/Users/sdavis/Work/R-Programs/packages/devel/ExpressCGH/E
> xpressCGH1.Rcheck'
> * using R version 2.1.1, 2005-08-12
> * checking for file 'ExpressCGH1/DESCRIPTION' ... OK
> * checking extension type ... Package
> * this is package 'ExpressCGH1' version '1.0'
> * checking if this is a source package ... OK
>
> * Installing *source* package 'ExpressCGH1' ...
> ** libs
> WARNING: no source files found
> chmod: /Users/sdavis/Library/R/library/ExpressCGH1/libs/*: No such file or
> direc
> tory
> ** R
> ** help
> >>> Building/Updating help pages for package 'ExpressCGH1'
>     Formats: text html latex example
>  convertDNAcopyOutput              text    html    latex   example
>     missing link(s):  ~~fun~~
> ** building package indices ...
> * DONE (ExpressCGH1)
>
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking package dependencies ... OK
> * checking index information ... OK
> * checking package subdirectories ... WARNING
> Subdirectory 'src' contains no source files.
> * checking R files for syntax errors ... OK
> * checking R files for library.dynam ... OK
> * checking S3 generic/method consistency ... WARNING
> Error: unable to load R code in package 'ExpressCGH1'
> Call sequence:
> 2: stop(gettextf("unable to load R code in package '%s'",
> libraryPkgName(package
> )),
>       call. = FALSE, domain = NA)
> 1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose =
> FALSE)
> Execution halted
> See section 'Generic functions and methods' of the 'Writing R Extensions'
> manual.
> * checking replacement functions ... WARNING
> Error: unable to load R code in package 'ExpressCGH1'
> Call sequence:
> 2: stop(gettextf("unable to load R code in package '%s'",
> libraryPkgName(package
> )),
>       call. = FALSE, domain = NA)
> 1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose =
> FALSE)
> Execution halted
> In R, the argument of a replacement function which corresponds to the right
> hand side must be named 'value'.
> * checking foreign function calls ... WARNING
> Error: unable to load R code in package 'ExpressCGH1'
> Call sequence:
> 2: stop(gettextf("unable to load R code in package '%s'",
> libraryPkgName(package
> )),
>       call. = FALSE, domain = NA)
> 1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose =
> FALSE)
> Execution halted
> See section 'System and foreign language interfaces' of the 'Writing R
> Extensions' manual.
> * checking Rd files ... WARNING
> Rd files with likely Rd problems:
> Unaccounted top-level text in file
> '/Users/sdavis/Work/R-Programs/packages/devel
> /ExpressCGH/ExpressCGH1/man/convertDNAcopyOutput.Rd':
> Following section 'note':
> "\n\n ~Make other sections like Warning with \\section{Warning }{....}
> ~\n\n"
>
> Rd files with non-standard keywords:
>
> /Users/sdavis/Work/R-Programs/packages/devel/ExpressCGH/ExpressCGH1/man/conv
> er
> tDNAcopyOutput.Rd:
>    ~kwd1 ~kwd2
> Each '\keyword' entry should specify one of the standard keywords (as
> listed in file 'KEYWORDS.db' in the 'doc' subdirectory of the R home
> directory).
>
> See chapter 'Writing R documentation files' in manual 'Writing R
> Extensions'.
> * checking for missing documentation entries ... ERROR
> Error: unable to load R code in package 'ExpressCGH1'
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From dmbates at gmail.com  Mon Aug 15 23:27:12 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Mon, 15 Aug 2005 16:27:12 -0500
Subject: [R] R CMD check failure on minimal code
In-Reply-To: <BF267BB1.C726%sdavis2@mail.nih.gov>
References: <BF267BB1.C726%sdavis2@mail.nih.gov>
Message-ID: <40e66e0b050815142711799a08@mail.gmail.com>

On 8/15/05, Sean Davis <sdavis2 at mail.nih.gov> wrote:
> I have a peculiar problem that I'm sure is a simple one, but I can't figure
> out what my mistake is.  Can someone enlighten me?  I have a simple file,
> class.R:
> 
> ##
> setClass("abc",representation(a = "character", b = "ANY"))
> 
> I have a package directory ExpressCGH1 made with package.skeleton.  The
> package happily builds and installs, but R CMD check fails with (ignoring
> the documenation warnings, etc.):

Can you declare a slot to have class "ANY"?  You can use class "ANY"
in a method signature but I don't think you can use it for a slot.

Try to see if you can attach the package in R.  That may give more
informative errors.

> 
> > version
>          _
> platform powerpc-apple-darwin7.9.0
> arch     powerpc
> os       darwin7.9.0
> system   powerpc, darwin7.9.0
> status   Patched
> major    2
> minor    1.1
> year     2005
> month    08
> day      12
> language R
> 
> 
> 
> %%% R CMD check -l '/User
> s/sdavis/Library/R/library' ExpressCGH1
> * checking for working latex ... OK
> * using log directory
> '/Users/sdavis/Work/R-Programs/packages/devel/ExpressCGH/E
> xpressCGH1.Rcheck'
> * using R version 2.1.1, 2005-08-12
> * checking for file 'ExpressCGH1/DESCRIPTION' ... OK
> * checking extension type ... Package
> * this is package 'ExpressCGH1' version '1.0'
> * checking if this is a source package ... OK
> 
> * Installing *source* package 'ExpressCGH1' ...
> ** libs
> WARNING: no source files found
> chmod: /Users/sdavis/Library/R/library/ExpressCGH1/libs/*: No such file or
> direc
> tory
> ** R
> ** help
>  >>> Building/Updating help pages for package 'ExpressCGH1'
>      Formats: text html latex example
>   convertDNAcopyOutput              text    html    latex   example
>      missing link(s):  ~~fun~~
> ** building package indices ...
> * DONE (ExpressCGH1)
> 
> * checking package directory ... OK
> * checking for portable file names ... OK
> * checking for sufficient/correct file permissions ... OK
> * checking DESCRIPTION meta-information ... OK
> * checking package dependencies ... OK
> * checking index information ... OK
> * checking package subdirectories ... WARNING
> Subdirectory 'src' contains no source files.
> * checking R files for syntax errors ... OK
> * checking R files for library.dynam ... OK
> * checking S3 generic/method consistency ... WARNING
> Error: unable to load R code in package 'ExpressCGH1'
> Call sequence:
> 2: stop(gettextf("unable to load R code in package '%s'",
> libraryPkgName(package
> )),
>        call. = FALSE, domain = NA)
> 1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose =
> FALSE)
> Execution halted
> See section 'Generic functions and methods' of the 'Writing R Extensions'
> manual.
> * checking replacement functions ... WARNING
> Error: unable to load R code in package 'ExpressCGH1'
> Call sequence:
> 2: stop(gettextf("unable to load R code in package '%s'",
> libraryPkgName(package
> )),
>        call. = FALSE, domain = NA)
> 1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose =
> FALSE)
> Execution halted
> In R, the argument of a replacement function which corresponds to the right
> hand side must be named 'value'.
> * checking foreign function calls ... WARNING
> Error: unable to load R code in package 'ExpressCGH1'
> Call sequence:
> 2: stop(gettextf("unable to load R code in package '%s'",
> libraryPkgName(package
> )),
>        call. = FALSE, domain = NA)
> 1: library(package, lib.loc = lib.loc, character.only = TRUE, verbose =
> FALSE)
> Execution halted
> See section 'System and foreign language interfaces' of the 'Writing R
> Extensions' manual.
> * checking Rd files ... WARNING
> Rd files with likely Rd problems:
> Unaccounted top-level text in file
> '/Users/sdavis/Work/R-Programs/packages/devel
> /ExpressCGH/ExpressCGH1/man/convertDNAcopyOutput.Rd':
> Following section 'note':
> "\n\n ~Make other sections like Warning with \\section{Warning }{....}
> ~\n\n"
> 
> Rd files with non-standard keywords:
> 
> /Users/sdavis/Work/R-Programs/packages/devel/ExpressCGH/ExpressCGH1/man/conv
> er
> tDNAcopyOutput.Rd:
>     ~kwd1 ~kwd2
> Each '\keyword' entry should specify one of the standard keywords (as
> listed in file 'KEYWORDS.db' in the 'doc' subdirectory of the R home
> directory).
> 
> See chapter 'Writing R documentation files' in manual 'Writing R
> Extensions'.
> * checking for missing documentation entries ... ERROR
> Error: unable to load R code in package 'ExpressCGH1'
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From efg at stowers-institute.org  Mon Aug 15 23:28:10 2005
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Mon, 15 Aug 2005 16:28:10 -0500
Subject: [R] Anything like dir.choose (similar to file.choose) in R?
Message-ID: <ddr1db$uja$1@sea.gmane.org>

Does R have a dir.choose function?

I can use file.choose like this as a kludge to get something like a
dir.choose, but a real dir.choose would be better:

  cat("Select one of files in directory to process:\n")
  filename <- gsub("\\\\", "/", file.choose())
  basepath <- dirname(filename)

Windows provides a lower-level SHBrowseForFolder function to create such a
dialog (see links below).  Do other platforms have similar functionality at
a lower level?  (Hoping this would be an easy addition to R.)

SHBrowseForFolder Function
http://msdn.microsoft.com/library/default.asp?url=/library/en-us/shellcc/platform/shell/reference/functions/shbrowseforfolder.asp

Using the Shell API function SHBrowseForFolder()
http://community.borland.com/article/0,1410,17008,00.html

efg
--
Earl F. Glynn
Bioinformatics
Stowers Institute for Medical Research



From S.O.Nyangoma at amc.uva.nl  Tue Aug 16 00:19:31 2005
From: S.O.Nyangoma at amc.uva.nl (S.O. Nyangoma)
Date: Tue, 16 Aug 2005 00:19:31 +0200
Subject: [R] queer data set
Message-ID: <2c3de12c42f5.2c42f52c3de1@amc.uva.nl>

I have a dataset that is basically structureless. Its dimension varies 
from row to row and sep(s) are a mixture of tab and semi colon (;) and 
example is

HEADER1 HEADER2 HEADER3   HEADER3
A1       B1      C1       X11;X12;X13
A2       B2      C2       X21;X22;X23;X24;X25
A3       B3      C3       
A4       B4      C4       X41;X42;X43
A5       B5      C5       X51

etc., say. Note that a blank under HEADER3 corresponds to non 
occurance and all semi colon (;) delimited variables are under 
HEADER3. These values run into tens of thousands. I want to give some 
order to this queer matrix to something like:

HEADER1 HEADER2 HEADER3   HEADER3
A1       B1      C1       X11
A1       B1      C1       X12
A1       B1      C1       X13
A1       B1      C1       X14
A2       B2      C2       X21
A2       B2      C2       X22
A2       B2      C2       X23
A2       B2      C2       X24
A2       B2      C2       X25
A2       B2      C2       X26
A3       B3      C3       NA
A4       B4      C4       X41
A4       B4      C4       X42
A4       B4      C4       X43

Is there a brilliant R-way of doing such task?

Goodday. Stephen.








----- Original Message -----
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
Date: Monday, August 15, 2005 11:13 pm
Subject: Re: [R] How to get a list work in RData file

> On Mon, 15 Aug 2005, Xiyan Lon wrote:
> 
> > Dear R-Helper,
> (There are quite a few of us.)
> 
> > I want to know how I get a list  work which I saved in RData 
> file. For
> > example,
> 
> I don't understand that at all, but it looks as if you want to 
> save an 
> unevaluated call, in which case see ?quote and use something like
> 
> xyadd <- quote(test.xy(x=2, y=3))
> 
> load and saving has nothing to do with this: it doesn't change the 
> meaning 
> of objects in the workspace.
> 
> > > test.xy <- function(x,y) {
> > +    xy <- x+y
> > +    xy
> > + }
> > >
> > > xyadd <- test.xy(x=2, y=3)
> > > xyadd
> > [1] 5
> > > x1 <- c(2,43,60,8)
> > > y1 <- c(91,7,5,30)
> > >
> > > xyadd1 <- test.xy(x=x1, y=y1)
> > > xyadd1
> > [1] 93 50 65 38
> > > save(list = ls(all=TRUE), file = "testxy.RData")
> > > rm(list=ls(all=TRUE))
> > > load("C:/R/useR/testxy.RData")
> > > ls()
> > [1] "test.xy" "x1"      "xyadd"   "xyadd1"  "y1"
> > >
> > > ls.str(pat="xyadd")
> > xyadd :  num 5
> > xyadd1 :  num [1:4] 93 50 65 38
> > >
> >
> > When I run, I know the result like above
> > > xyadd
> > [1] 5
> > > xyadd1
> > [1] 93 50 65 38
> > >
> > what I want to know, is there any function to make the result like:
> >
> > > xyadd
> >
> >         test.xy(x=2, y=3)
> >
> > and
> >
> > > xyadd1
> >
> >        test.xy(x=x1, y=y1)
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html



From jfox at mcmaster.ca  Tue Aug 16 00:30:58 2005
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 15 Aug 2005 18:30:58 -0400
Subject: [R] Manually Calculating Odds from POLR Model
In-Reply-To: <BAY103-F1285823B1FE6D8AF411D5AAEB10@phx.gbl>
Message-ID: <20050815223058.CBZU25800.tomts13-srv.bellnexxia.net@JohnDesktop8300>

Dear Tate,

Your question pertains generally to the treatment of factors in model
formulas and is not particular to polr(). For a brief explanation, see
Section 11.1, "Defining statistical models; formulae," and in particular
Section 11.1.1 on "Contrasts" in the manual An Introduction to R, which is
distributed with R. More detailed explanations are in texts such as Venables
and Ripley, Modern Applied Statistics With S, and my own, An R and S-PLUS
Companion to Applied Regression. 

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: Tate Avery [mailto:tate_sterling_avery at hotmail.com] 
> Sent: Monday, August 15, 2005 3:58 PM
> To: jfox at mcmaster.ca
> Cc: r-help at stat.math.ethz.ch
> Subject: RE: [R] Manually Calculating Odds from POLR Model
> 
> John,
> 
> Thank you, the document was very helpful.  I can now 
> calculate the same values generated by predict() when I am 
> using purely numeric input data.
> 
> Another small question arises when I look at the example 
> using 'housing' in the polr() documentation page:
> 
> Running the example produces the following coefficients...
> 
> Coefficients:
>    InflMedium      InflHigh TypeApartment    TypeAtrium   
> TypeTerrace      
> ContHigh
>     0.5663924     1.2888218    -0.5723552    -0.3661912    
> -1.0910195     
> 0.3602834
> 
> Now, if I am trying to perform a prediction and the value for 
> INFL comes in as 'Medium' what is done?  And, what is done for 'low'?
> 
> That seems to be the last missing piece in my understanding 
> of how to convert the model values into predictions.
> 
> Thank you,
> Tate
> 
> >From: "John Fox" <jfox at mcmaster.ca>
> >To: "'Tate Avery'" <tate_sterling_avery at hotmail.com>
> >CC: <r-help at stat.math.ethz.ch>
> >Subject: RE: [R] Manually Calculating Odds from POLR Model
> >Date: Fri, 12 Aug 2005 19:22:23 -0400
> >
> >Dear Tate,
> >
> >If I understand correctly what you're asking, the formulas 
> are on p. 21 
> >of the paper at 
> ><http://socserv.socsci.mcmaster.ca/jfox/Papers/logit-effect-d
isplays.pdf>.
> >But why do you want to do this when you can get the fitted 
> >probabilities from predict()?
> >
> >I hope this helps.
> >  John
> >
> >--------------------------------
> >John Fox
> >Department of Sociology
> >McMaster University
> >Hamilton, Ontario
> >Canada L8S 4M4
> >905-525-9140x23604
> >http://socserv.mcmaster.ca/jfox
> >--------------------------------
> >
> > > -----Original Message-----
> > > From: r-help-bounces at stat.math.ethz.ch 
> > > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tate Avery
> > > Sent: Friday, August 12, 2005 2:50 PM
> > > To: r-help at stat.math.ethz.ch
> > > Subject: [R] Manually Calculating Odds from POLR Model
> > >
> > > Hello,
> > >
> > > I am using polr(...) to generate a model.  The summary shows the 
> > > coefficients and the intercepts.
> > >
> > > For example:
> > >
> > >     coefficient for x1 = c1
> > >     coefficient for x2 = c2
> > >
> > >     intercept A|B = i1
> > >     intercept B|C = i2
> > >
> > > I can then run predict(..., type="p") with the model and see the 
> > > odds for each factor.
> > >
> > > For example:
> > >
> > >       A        B        C
> > > 1    0.3     0.5      0.2
> > > 2    0.4     0.1      0.5
> > >
> > > What I really want to be able to do is take the 2 
> coefficients, the 
> > > 2 intercepts, the x1 & x2 values and manually calculate the 
> > > probabilities generated by predict().
> > >
> > > I have been searching quite extensively for the underlying 
> > > calculations that transform the polr output and the input 
> variables 
> > > into the final output odds.  I have tried a number of 
> dead-end roads 
> > > so far.
> > >
> > > So, if anyone has any information on how to do this or 
> where I can 
> > > find out, I would be extremely grateful.
> > >
> > > Thank you for your time,
> > > Tate Avery
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list 
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> >
> 
>



From tplate at acm.org  Tue Aug 16 00:40:05 2005
From: tplate at acm.org (Tony Plate)
Date: Mon, 15 Aug 2005 16:40:05 -0600
Subject: [R] queer data set
In-Reply-To: <2c3de12c42f5.2c42f52c3de1@amc.uva.nl>
References: <2c3de12c42f5.2c42f52c3de1@amc.uva.nl>
Message-ID: <430119C5.10100@acm.org>

Here's one way of working with the data you gave:

 > x <- read.table(file("clipboard"), fill=T, header=T)
 > x
   HEADER1 HEADER2 HEADER3           HEADER3.1
1      A1      B1      C1         X11;X12;X13
2      A2      B2      C2 X21;X22;X23;X24;X25
3      A3      B3      C3
4      A4      B4      C4         X41;X42;X43
5      A5      B5      C5                 X51
 > apply(x, 1, function(x) strsplit(x[4], ";")[[1]])
$"1"
[1] "X11" "X12" "X13"

$"2"
[1] "X21" "X22" "X23" "X24" "X25"

$"3"
character(0)

$"4"
[1] "X41" "X42" "X43"

$"5"
[1] "X51"

 > do.call("rbind", apply(x, 1, function(x) {
+    y <- strsplit(x[4], ";")[[1]]
+    x3 <- matrix(x[1:3], ncol=3, nrow=max(1,length(y)), byrow=T)
+    return(cbind(x3, if (length(y)) y else "NA"))
+ }))
       [,1] [,2] [,3] [,4]
  [1,] "A1" "B1" "C1" "X11"
  [2,] "A1" "B1" "C1" "X12"
  [3,] "A1" "B1" "C1" "X13"
  [4,] "A2" "B2" "C2" "X21"
  [5,] "A2" "B2" "C2" "X22"
  [6,] "A2" "B2" "C2" "X23"
  [7,] "A2" "B2" "C2" "X24"
  [8,] "A2" "B2" "C2" "X25"
  [9,] "A3" "B3" "C3" "NA"
[10,] "A4" "B4" "C4" "X41"
[11,] "A4" "B4" "C4" "X42"
[12,] "A4" "B4" "C4" "X43"
[13,] "A5" "B5" "C5" "X51"
 >

This of course is a matrix; you can convert it back to a dataframe using 
as.data.frame() if you desire.  Use either "NA" (with quotes) or NA 
(without quotes) to control whether you get just the string "NA" or an 
actual character NA value in column 4.  If you're processing a huge 
amount of data, you can probably do better by rewriting the above code 
to avoid implicit coercions of data types.

hope this helps,

Tony Plate

S.O. Nyangoma wrote:
> I have a dataset that is basically structureless. Its dimension varies 
> from row to row and sep(s) are a mixture of tab and semi colon (;) and 
> example is
> 
> HEADER1 HEADER2 HEADER3   HEADER3
> A1       B1      C1       X11;X12;X13
> A2       B2      C2       X21;X22;X23;X24;X25
> A3       B3      C3       
> A4       B4      C4       X41;X42;X43
> A5       B5      C5       X51
> 
> etc., say. Note that a blank under HEADER3 corresponds to non 
> occurance and all semi colon (;) delimited variables are under 
> HEADER3. These values run into tens of thousands. I want to give some 
> order to this queer matrix to something like:
> 
> HEADER1 HEADER2 HEADER3   HEADER3
> A1       B1      C1       X11
> A1       B1      C1       X12
> A1       B1      C1       X13
> A1       B1      C1       X14
> A2       B2      C2       X21
> A2       B2      C2       X22
> A2       B2      C2       X23
> A2       B2      C2       X24
> A2       B2      C2       X25
> A2       B2      C2       X26
> A3       B3      C3       NA
> A4       B4      C4       X41
> A4       B4      C4       X42
> A4       B4      C4       X43
> 
> Is there a brilliant R-way of doing such task?
> 
> Goodday. Stephen.
> 
> 
> 
> 
> 
> 
> 
> 
> ----- Original Message -----
> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> Date: Monday, August 15, 2005 11:13 pm
> Subject: Re: [R] How to get a list work in RData file
> 
> 
>>On Mon, 15 Aug 2005, Xiyan Lon wrote:
>>
>>
>>>Dear R-Helper,
>>
>>(There are quite a few of us.)
>>
>>
>>>I want to know how I get a list  work which I saved in RData 
>>
>>file. For
>>
>>>example,
>>
>>I don't understand that at all, but it looks as if you want to 
>>save an 
>>unevaluated call, in which case see ?quote and use something like
>>
>>xyadd <- quote(test.xy(x=2, y=3))
>>
>>load and saving has nothing to do with this: it doesn't change the 
>>meaning 
>>of objects in the workspace.
>>
>>
>>>>test.xy <- function(x,y) {
>>>
>>>+    xy <- x+y
>>>+    xy
>>>+ }
>>>
>>>>xyadd <- test.xy(x=2, y=3)
>>>>xyadd
>>>
>>>[1] 5
>>>
>>>>x1 <- c(2,43,60,8)
>>>>y1 <- c(91,7,5,30)
>>>>
>>>>xyadd1 <- test.xy(x=x1, y=y1)
>>>>xyadd1
>>>
>>>[1] 93 50 65 38
>>>
>>>>save(list = ls(all=TRUE), file = "testxy.RData")
>>>>rm(list=ls(all=TRUE))
>>>>load("C:/R/useR/testxy.RData")
>>>>ls()
>>>
>>>[1] "test.xy" "x1"      "xyadd"   "xyadd1"  "y1"
>>>
>>>>ls.str(pat="xyadd")
>>>
>>>xyadd :  num 5
>>>xyadd1 :  num [1:4] 93 50 65 38
>>>
>>>When I run, I know the result like above
>>>
>>>>xyadd
>>>
>>>[1] 5
>>>
>>>>xyadd1
>>>
>>>[1] 93 50 65 38
>>>
>>>what I want to know, is there any function to make the result like:
>>>
>>>
>>>>xyadd
>>>
>>>        test.xy(x=2, y=3)
>>>
>>>and
>>>
>>>
>>>>xyadd1
>>>
>>>       test.xy(x=x1, y=y1)
>>
>>-- 
>>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>University of Oxford,             Tel:  +44 1865 272861 (self)
>>1 South Parks Road,                     +44 1865 272866 (PA)
>>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-
>>guide.html
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From xiyanlon at gmail.com  Tue Aug 16 01:33:13 2005
From: xiyanlon at gmail.com (Xiyan Lon)
Date: Tue, 16 Aug 2005 01:33:13 +0200
Subject: [R] How to get a list work in RData file
In-Reply-To: <Pine.LNX.4.61.0508152209140.9609@gannet.stats>
References: <4300FD5A.2020808@gmail.com>
	<Pine.LNX.4.61.0508152209140.9609@gannet.stats>
Message-ID: <43012639.6060203@gmail.com>

Dear Prof. Brian,
Why I need to know, because I lost my work and code which I used in my 
project. Lucky I always save my work which RData file. But I forgot 
which list, function, initial, etc I used.

Xiyan Lon

Prof Brian Ripley wrote:

> On Mon, 15 Aug 2005, Xiyan Lon wrote:
>
>> Dear R-Helper,
>
> (There are quite a few of us.)
>
>> I want to know how I get a list  work which I saved in RData file. For
>> example,
>
>
> I don't understand that at all, but it looks as if you want to save an 
> unevaluated call, in which case see ?quote and use something like
>
> xyadd <- quote(test.xy(x=2, y=3))
>
> load and saving has nothing to do with this: it doesn't change the 
> meaning of objects in the workspace.
>
>> > test.xy <- function(x,y) {
>> +    xy <- x+y
>> +    xy
>> + }
>> >
>> > xyadd <- test.xy(x=2, y=3)
>> > xyadd
>> [1] 5
>> > x1 <- c(2,43,60,8)
>> > y1 <- c(91,7,5,30)
>> >
>> > xyadd1 <- test.xy(x=x1, y=y1)
>> > xyadd1
>> [1] 93 50 65 38
>> > save(list = ls(all=TRUE), file = "testxy.RData")
>> > rm(list=ls(all=TRUE))
>> > load("C:/R/useR/testxy.RData")
>> > ls()
>> [1] "test.xy" "x1"      "xyadd"   "xyadd1"  "y1"
>> >
>> > ls.str(pat="xyadd")
>> xyadd :  num 5
>> xyadd1 :  num [1:4] 93 50 65 38
>> >
>>
>> When I run, I know the result like above
>> > xyadd
>> [1] 5
>> > xyadd1
>> [1] 93 50 65 38
>> >
>> what I want to know, is there any function to make the result like:
>>
>> > xyadd
>>
>>         test.xy(x=2, y=3)
>>
>> and
>>
>> > xyadd1
>>
>>        test.xy(x=x1, y=y1)
>
>



From Ted.Harding at nessie.mcc.ac.uk  Tue Aug 16 01:45:53 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 16 Aug 2005 00:45:53 +0100 (BST)
Subject: [R] queer data set
In-Reply-To: <2c3de12c42f5.2c42f52c3de1@amc.uva.nl>
Message-ID: <XFMail.050816004553.Ted.Harding@nessie.mcc.ac.uk>

On 15-Aug-05 S.O. Nyangoma wrote:
> I have a dataset that is basically structureless. Its dimension
> varies from row to row and sep(s) are a mixture of tab and semi
> colon (;) an example is
> 
HEADER1 HEADER2 HEADER3   HEADER3
A1       B1      C1       X11;X12;X13
A2       B2      C2       X21;X22;X23;X24;X25
A3       B3      C3       
A4       B4      C4       X41;X42;X43
A5       B5      C5       X51
> 
> etc., say. Note that a blank under HEADER3 corresponds to non 
> occurance and all semi colon (;) delimited variables are under 
> HEADER3. These values run into tens of thousands. I want to give some 
> order to this queer matrix to something like:
> 
> HEADER1 HEADER2 HEADER3   HEADER3
> A1       B1      C1       X11
> A1       B1      C1       X12
> A1       B1      C1       X13
> A1       B1      C1       X14
> A2       B2      C2       X21
> A2       B2      C2       X22
> A2       B2      C2       X23
> A2       B2      C2       X24
> A2       B2      C2       X25
> A2       B2      C2       X26
> A3       B3      C3       NA
> A4       B4      C4       X41
> A4       B4      C4       X42
> A4       B4      C4       X43
> 
> Is there a brilliant R-way of doing such task?
> 
> Goodday. Stephen.

I don't know about a brilliant R trick (though I'm sure others do).

But (on my usual hobby-horse) if you have 'awk' available (and
don't mind using it) then it will do the job:

First create an 'awk' program file as follows:

  {for(i in A) delete A[i]}
  {if($4==""){A[1]="NA"}
    else {split($4,A,";")}}
  {B = $1 "\t" $2 "\t" $3}
  {for(i in A) print B "\t" A[i]}

and call this say split.awk

Then run

  awk -f split.awk

and feed it the lines of your primary dataset as above. Here's
a cut&paste from my Linux session, where the first block of
lines after "awk -f split.awk" are the lines being input to
the program, starting with the header, followed by the output
of the program starting with the header again:

awk -f split.awk
HEADER1 HEADER2 HEADER3   HEADER3
A1       B1      C1       X11;X12;X13
A2       B2      C2       X21;X22;X23;X24;X25
A3       B3      C3       
A4       B4      C4       X41;X42;X43
A5       B5      C5       X51
HEADER1 HEADER2 HEADER3 HEADER3
A1      B1      C1      X11
A1      B1      C1      X12
A1      B1      C1      X13
A2      B2      C2      X24
A2      B2      C2      X25
A2      B2      C2      X21
A2      B2      C2      X22
A2      B2      C2      X23
A3      B3      C3      NA
A4      B4      C4      X41
A4      B4      C4      X42
A4      B4      C4      X43
A5      B5      C5      X51

In unixoid systems, with a large file of such lines, the command
would be

  cat yourdatafile | awk -f split.awk

and then you would only see the output, not the input as shown
above, and you can of course redirect it into a new file with

  cat yourdatafile | awk -f split.awk > newdatafile

Note, however, that the order of the lines output for the third
line of input (the one with X21;X22;X23;X24;X25) is not the same
as the order of the X21;X22;X23;X24;X25 though they are all there.

This is a "feature" of the way 'awk' handles arrays (which are
"associative arrays" indexed by values, not by position).

This may not matter for your application; but if it does matter
then I'm not sure how to force the correct order.

Hoping this helps,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 16-Aug-05                                       Time: 00:45:49
------------------------------ XFMail ------------------------------



From andy_liaw at merck.com  Tue Aug 16 02:36:19 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 15 Aug 2005 20:36:19 -0400
Subject: [R] Anything like dir.choose (similar to file.choose) in R?
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EBD1@usctmx1106.Merck.com>

If you can use the `tcltk' package, Prof. John Fox had pointed this out to
me before:

dir <- tclvalue(tkchooseDirectory())

Andy

> From: Earl F. Glynn
> 
> Does R have a dir.choose function?
> 
> I can use file.choose like this as a kludge to get something like a
> dir.choose, but a real dir.choose would be better:
> 
>   cat("Select one of files in directory to process:\n")
>   filename <- gsub("\\\\", "/", file.choose())
>   basepath <- dirname(filename)
> 
> Windows provides a lower-level SHBrowseForFolder function to 
> create such a
> dialog (see links below).  Do other platforms have similar 
> functionality at
> a lower level?  (Hoping this would be an easy addition to R.)
> 
> SHBrowseForFolder Function
> http://msdn.microsoft.com/library/default.asp?url=/library/en-
> us/shellcc/platform/shell/reference/functions/shbrowseforfolder.asp
> 
> Using the Shell API function SHBrowseForFolder()
> http://community.borland.com/article/0,1410,17008,00.html
> 
> efg
> --
> Earl F. Glynn
> Bioinformatics
> Stowers Institute for Medical Research
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From siddique at ucla.edu  Tue Aug 16 02:47:32 2005
From: siddique at ucla.edu (Juned Siddique)
Date: Mon, 15 Aug 2005 17:47:32 -0700
Subject: [R] Overall Legend
Message-ID: <001301c5a1fc$1622b110$769b300a@hsrcenter.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050815/0f512d8f/attachment.pl

From andy_liaw at merck.com  Tue Aug 16 02:47:43 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 15 Aug 2005 20:47:43 -0400
Subject: [R] How to get a list work in RData file
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EBD2@usctmx1106.Merck.com>

If you want to keep track of the function call that produced an object,
usually you need to do that inside the function that's being called, e.g.,

> test.xy <- function(x,y) {
+     xy <- x+y
+     attr(xy, "Call") <- match.call()
+     xy
+ }
> xyadd <- test.xy(x=2, y=3)
> xyadd
[1] 5
attr(,"Call")
test.xy(x = 2, y = 3)
> str(xyadd)
 atomic [1:1] 5
 - attr(*, "Call")= language test.xy(x = 2, y = 3)


Andy

> From: Xiyan Lon
> 
> Dear R-Helper,
> I want to know how I get a list  work which I saved in RData 
> file. For 
> example,
> 
>  > test.xy <- function(x,y) {
> +    xy <- x+y
> +    xy
> + }
>  >
>  > xyadd <- test.xy(x=2, y=3)
>  > xyadd
> [1] 5
>  > x1 <- c(2,43,60,8)
>  > y1 <- c(91,7,5,30)
>  >
>  > xyadd1 <- test.xy(x=x1, y=y1)
>  > xyadd1
> [1] 93 50 65 38
>  > save(list = ls(all=TRUE), file = "testxy.RData")
>  > rm(list=ls(all=TRUE))
>  > load("C:/R/useR/testxy.RData")
>  > ls()
> [1] "test.xy" "x1"      "xyadd"   "xyadd1"  "y1"    
>  >
>  > ls.str(pat="xyadd")
> xyadd :  num 5
> xyadd1 :  num [1:4] 93 50 65 38
>  >
> 
> When I run, I know the result like above
>  > xyadd
> [1] 5
>  > xyadd1
> [1] 93 50 65 38
>  >
> what I want to know, is there any function to make the result like:
> 
>  > xyadd
> 
>          test.xy(x=2, y=3)
> 
> and
> 
>  > xyadd1
> 
>         test.xy(x=x1, y=y1)
> 
> Best,
> Xiyan Lon
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From andy_liaw at merck.com  Tue Aug 16 03:05:30 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Mon, 15 Aug 2005 21:05:30 -0400
Subject: [R] randomForest Error passing string argument
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EBD4@usctmx1106.Merck.com>

If all you need the formula interface for is auto deletion of NAs, I'd
suggest doing something like:


varlist <- c("fruit", "apples", "oranges", "blueberries")
fruits.nona <- na.omit(fruits.data[varlist])
model.rf <- randomForest(fruits.data[-1], fruits.data[[1]], ...)

If you want to know the call that produced model.rf, you can look at
model.rf$Call.

I hope that sort of answers your question.

Andy

> From: mmv
> 
> I'm attempting to pass a string argument into the function
> randomForest but I get an error:
> 
> state <- paste(list("fruit ~", "apples+oranges+blueberries",
> "data=fruits.data, mtry=2, do.trace=100, na.action=na.omit,
> keep.forest=TRUE"), sep= " ", collapse="")
> 
> model.rf <- randomForest(state)
> 
> Error in if (n==0) stop ("data(x) has 0 rows") argument is of 
> length zero.
> 
> -Thanks in advance,
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From mcclatchie.sam at saugov.sa.gov.au  Tue Aug 16 03:37:08 2005
From: mcclatchie.sam at saugov.sa.gov.au (McClatchie, Sam (PIRSA-SARDI))
Date: Tue, 16 Aug 2005 11:07:08 +0930
Subject: [R] return unique values from date/time class object
Message-ID: <BEA6A7E18959A04385DC14D24619F89F01D73C22@sagemsg0008.sagemsmrd01.sa.gov.au>

Background:
OS: Linux Mandrake 10.1
release: R 2.1.1
editor: GNU Emacs 21.3.2
front-end: ESS 5.2.3
---------------------------------

Thanks to Brian Ripley (I've upgraded from source, thanks for the reminder)
and Petr Pikal for their suggestions, but I have not made clear the form of
my data:

Browse[1]> ceduna[1:10,]
                  LSD AVIATION_ID WND_DIR WND_SPD_MPS
1  1/01/2001 10:30:00        YCDU     230         4.6
2  1/01/2001 11:00:00        YCDU     210         4.1
3  1/01/2001 11:30:00        YCDU     230         6.7
4  1/01/2001 12:00:00        YCDU     230         7.7
5  1/01/2001 12:30:00        YCDU     220         8.2
6  1/01/2001 13:00:00        YCDU     210         7.2
7  1/01/2001 13:30:00        YCDU     210         7.2
8  1/01/2001 14:00:00        YCDU     200         6.7
9  1/01/2001 14:30:00        YCDU     190         7.7
10 1/01/2001 15:00:00        YCDU     200         8.2
Browse[1]> class(ceduna)
[1] "data.frame"
Browse[1]>  x <- as.character(ceduna$LSD)
Browse[1]>     new.time <- strptime(x, "%d/%m/%Y %H:%M:%S")
Browse[1]> class(new.time)
[1] "POSIXt"  "POSIXlt"
Browse[1]> unique(new.time)
Error in unique.default(new.time) : unique() applies only to vectors
Browse[1]> tt <- new.time[!duplicated(unclass(new.time))]
Error in duplicated.default(unclass(new.time)) : 
	duplicated() applies only to vectors
Browse[1]> 

I'm obviously doing something silly with the data classes, but what?

Best fishes

Sam
----
Sam McClatchie,
Biological oceanography 
South Australian Aquatic Sciences Centre
PO Box 120, Henley Beach 5022
Adelaide, South Australia
email <mcclatchie.sam at saugov.sa.gov.au>
Cellular: 0431 304 497 
Telephone: (61-8) 8207 5448
FAX: (61-8) 8207 5481
Research home page <http://www.members.iinet.net.au/~s.mcclatchie/>
  
                   /\
      ...>><xX(??> 
                //// \\\\
                   <??)Xx><<
              /////  \\\\\\
                        ><(((??> 
  >><(((??>   ...>><xX(??>O<??)Xx><<



From shalwitz.1 at osu.edu  Tue Aug 16 05:00:35 2005
From: shalwitz.1 at osu.edu (ISAIAH SHALWITZ)
Date: Mon, 15 Aug 2005 23:00:35 -0400
Subject: [R] Conditional Matrices
Message-ID: <1cb93321cb960a.1cb960a1cb9332@osu.edu>

This seems like a simple problem but I can't figure it out:

I have two identical DIMENSION matrices.  Both contain only binary values NOT identical between matrices.  What I want to do: If in cell (1,1) the value in the first matrix (x) equals 1, then I keep the value in cell (1,1) in the second matrix (y).  If in cell (1,1) the value in the first matrix (x) equals 0, then I change the value in cell (1,1) in the second matrix (y)to missing (NA).  Repeat for every pair of cells (coordinates of the paired cells always match).

Please help.

I



From munguiar at posgrado.ecologia.edu.mx  Tue Aug 16 05:05:27 2005
From: munguiar at posgrado.ecologia.edu.mx (roberto munguia)
Date: Mon, 15 Aug 2005 22:05:27 -0500
Subject: [R] data manipulation help
Message-ID: <20050816030259.D914522AE@servidor.posgrado.ecologia.edu.mx>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050815/d955a96f/attachment.pl

From marcinhosbt at gmail.com  Tue Aug 16 05:33:12 2005
From: marcinhosbt at gmail.com (=?ISO-8859-1?Q?M=E1rcio_de_Medeiros_Ribeiro?=)
Date: Tue, 16 Aug 2005 00:33:12 -0300
Subject: [R] Image from bytes streams
Message-ID: <76189e25050815203379654093@mail.gmail.com>

Hello!

I'm trying to get an array of bytes from graphic images generated by
R. Here, you can see my Java code:

--------------------------------------------------------------------------------------------------------------------------
Process p = Runtime.getRuntime().exec("C:/Arquivos de
programas/R/rw1090/bin/Rterm.exe --no-save");

DataOutputStream output = new DataOutputStream(new
BufferedOutputStream(p.getOutputStream()));

DataInputStream input = new DataInputStream(new
BufferedInputStream(p.getInputStream()));

// output.writeBytes("pie(c(50,30,20))"); //Pie graphic
output.writeBytes("plot(1,1)"); // Plot graphic
output.flush();

input.readFully(new byte[200]); // Here I read the "image" bytes.
--------------------------------------------------------------------------------------------------------------------------

That's the problem: when I use Pie graphic, I got some bytes. However,
when I use the Plot graphic, I got the same bytes! So, I suppose that
my program does not read the bytes from the generated graphic from R.

Is it possible to get the bytes from the generated graphic? How can I
get these bytes?

Sorry about my english. I'm brazilian! :)
-- 
M??rcio de Medeiros Ribeiro
Graduando em Ci??ncia da Computa????o
Departamento de Tecnologia da Informa????o - TCI
Universidade Federal de Alagoas - UFAL
Macei?? - Alagoas - Brasil
Projeto ArCo - Arcabou??o de Comunidades
Contato: +55 82 354-3358/9997-6794



From bfulton at prgs.edu  Tue Aug 16 07:56:24 2005
From: bfulton at prgs.edu (Fulton, Brent)
Date: Mon, 15 Aug 2005 22:56:24 -0700
Subject: [R] merge warning is.na(out$h)
Message-ID: <5C9D80739A5FCC4995C426E74D3573C48B6B01@smmail4.rand.org>

Hi, 

Does anyone know how to interpret this merge warning and whether it's critical to fix? The merge seemed to work fine, but I am concerned.

data3<-merge(data1, data2, by="ID", all=TRUE)

Warning messages: 1: is.na() applied to non-(list or vector) in: is.na(out$h)  Error in cat(list(...), file, sep, fill, labels, append) : argument 2 not yet handled by cat

When I remove all=TRUE or just include all.y=TRUE, I don't get the warning; however, I get the warning when I include all.x=TRUE.

Thanks,
Brent Fulton



--------------------

This email message is for the sole use of the intended recip...{{dropped}}



From ajayshah at mayin.org  Tue Aug 16 08:18:17 2005
From: ajayshah at mayin.org (Ajay Narottam Shah)
Date: Tue, 16 Aug 2005 11:48:17 +0530
Subject: [R] Extracting some rows from a data frame - lapses into a vector
Message-ID: <20050816061817.GI458@lubyanka.local>

I have a data frame with one column "x":

> str(data)
`data.frame':   20 obs. of  1 variable:
 $ x: num  0.0495 0.0986 0.9662 0.7501 0.8621 ...

Normally, I know that the notation dataframe[indexes,] gives you a new
data frame which is the specified set of rows. But I find:

> str(data[1:10,])
 num [1:10] 0.0495 0.0986 0.9662 0.7501 0.8621 ...

Here, it looks like the operation
      data[1:10,]
has converted it from type data frame into a numeric vector. Why does
this happen, and what can I do about it?

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From dieter.menne at menne-biomed.de  Tue Aug 16 08:26:51 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Tue, 16 Aug 2005 06:26:51 +0000 (UTC)
Subject: [R] Extracting some rows from a data frame - lapses into a
	vector
References: <20050816061817.GI458@lubyanka.local>
Message-ID: <loom.20050816T082443-658@post.gmane.org>

Ajay Narottam Shah <ajayshah <at> mayin.org> writes:

> 
> I have a data frame with one column "x":
> 
> > str(data)
> `data.frame':   20 obs. of  1 variable:
>  $ x: num  0.0495 0.0986 0.9662 0.7501 0.8621 ...
....
> Here, it looks like the operation
>       data[1:10,]
> has converted it from type data frame into a numeric vector. Why does
> this happen, and what can I do about it?

Check parameter "drop" in the documentation of "[" or Extract. The 
simplification to a vector is default behavior for historical reasons, but 
somewhat confusing.

Dieter



From sean.oriordain at gmail.com  Tue Aug 16 08:36:26 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Tue, 16 Aug 2005 07:36:26 +0100
Subject: [R] How to repeat code snippet for several variables in a data
	frame?
In-Reply-To: <43010035.103@oomvanlieshout.net>
References: <43010035.103@oomvanlieshout.net>
Message-ID: <8ed68eed05081523366df7b5c1@mail.gmail.com>

Sander,

consider writing a function to do your plotting, then pass in the
dataframe name so... something along the lines of...

# create a function which takes two arguments
# mydf - a dataframe of a particular format... eg. the abc column is number 4
# i the column we want to aggregate and plot this time around...
myplotfn <- function(mydf,i) {
  # body of the function
  # extract the relevant column - i
  colval <- mydf[3+i]
  tmp <- aggregate(colval, list(
    mydf$bins, mydf$groups),
    mean)
  # grab the name of the column we're working on; eg. "abc"
  colnam.r <- names(mydf)[3+i]
  colnames(tmp) <- c("bins", "groups", colnam.r)
  tmp
  #pltName <- paste("line_datGrassChem_", colnam.r, ".eps", sep="")
  #postscript(pltName)
    labs <- c("-15/-9","-9/-6","-6/-3","-3/0")
    sps <- trellis.par.get("superpose.symbol")
    sps$pch <- 1:4
      trellis.par.set("superpose.symbol", sps)
      # create the proper formula for plotting something like "abc ~ bins"
      myformula <- as.formula(paste(colnam.r, "~ bins"))
      xyplot( myformula, data = tmp,
      groups = groups, type = list("p", "l"),
      scales = list(x = list(labels=labs)),
      layout = c(1,1),
      key = list(columns = 4,
        text = list(paste(unique(tmp$groups))),
        points = Rows(sps, 1:4)
        )
    )
  #dev.off()
}

# then call it by 
myplotfn(test,1)
myplotfn(test,2)
myplotfn(test,3)

obviously this can be put in a loop :-)

So how did I figure out how to do this? well in the introduction
manual it talks about functions... the tricky bit was the substitution
of abc into the relevant places...

I didn't know how to convert the string formula "abc ~ bins" into a
formula that I could plot, so first off, I looked at ?plot, in there
it mentioned ?plot.formula and in there it mentioned the class formula
so I said ?formula where it mentioned as.formula()... bingo... this
allowed me to say
myformula <- as.formula("abc ~ bins")

So I made this into a "learning experience" for me :-)

I'm relatively new to R... so giving myself little problems like this
is a good way of learning R... and hopefully helping somebody else!
:-)

I'm pretty sure that there is a better way of doing this in R - but
this works :-)

cheers
Sean




On 15/08/05, Sander Oom <slist at oomvanlieshout.net> wrote:
> Dear all,
> 
> I have a data frame containing the results of an experiment. Like this:
> 
> a<-seq(1,4,by=1)
> b<-seq(1,2,by=1)
> test<-expand.grid(b,a,a)
> colnames(test)<-c("replicates","bins", "groups")
> test$abc <- rnorm(32)
> test$def <- rnorm(32)
> test$ghi <- rnorm(32)
> test
> 
> The following code snippet aggregates the data for one variable and then
> draws a plot:
> 
> tmp <- aggregate(test$abc, list(
>    test$bins, test$groups),
>    mean)
> colnames(tmp) <- c("bins", "groups", "abc")
> tmp
> #pltName <- paste("line_datGrassChem_", "abc", ".eps", sep="")
> #postscript(pltName)
>    labs <- c("-15/-9","-9/-6","-6/-3","-3/0")
>    sps <- trellis.par.get("superpose.symbol")
>    sps$pch <- 1:4
>    trellis.par.set("superpose.symbol", sps)
>    xyplot( abc ~ bins, data = tmp,
>      groups = groups, type = list("p", "l"),
>      scales = list(x = list(labels=labs)),
>      layout = c(1,1),
>      key = list(columns = 4,
>        text = list(paste(unique(tmp$groups))),
>        points = Rows(sps, 1:4)
>        )
>    )
> #dev.off()
> 
> How can I wrap R code around this code snippet, such that I can repeat
> the same code snippet for all other variables in the data frame (i.e.
> def, ghi, etc.).
> 
> Thanks for your suggestions!
> 
> Sander.
> 
> --
> --------------------------------------------
> Dr Sander P. Oom
> Animal, Plant and Environmental Sciences,
> University of the Witwatersrand
> Private Bag 3, Wits 2050, South Africa
> Tel (work)      +27 (0)11 717 64 04
> Tel (home)      +27 (0)18 297 44 51
> Fax             +27 (0)18 299 24 64
> Email   sander at oomvanlieshout.net
> Web     www.oomvanlieshout.net/sander
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ligges at statistik.uni-dortmund.de  Tue Aug 16 08:38:05 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 16 Aug 2005 08:38:05 +0200
Subject: [R] How to repeat code snippet for several variables in a data
 frame?
In-Reply-To: <43010035.103@oomvanlieshout.net>
References: <43010035.103@oomvanlieshout.net>
Message-ID: <430189CD.5030807@statistik.uni-dortmund.de>

Sander Oom wrote:

> Dear all,
> 
> I have a data frame containing the results of an experiment. Like this:
> 
> a<-seq(1,4,by=1)
> b<-seq(1,2,by=1)
> test<-expand.grid(b,a,a)
> colnames(test)<-c("replicates","bins", "groups")
> test$abc <- rnorm(32)
> test$def <- rnorm(32)
> test$ghi <- rnorm(32)
> test
> 
> The following code snippet aggregates the data for one variable and then 
> draws a plot:
> 
> tmp <- aggregate(test$abc, list(
>    test$bins, test$groups),
>    mean)
> colnames(tmp) <- c("bins", "groups", "abc")
> tmp
> #pltName <- paste("line_datGrassChem_", "abc", ".eps", sep="")
> #postscript(pltName)
>    labs <- c("-15/-9","-9/-6","-6/-3","-3/0")
>    sps <- trellis.par.get("superpose.symbol")
>    sps$pch <- 1:4
>    trellis.par.set("superpose.symbol", sps)
>    xyplot( abc ~ bins, data = tmp,
>      groups = groups, type = list("p", "l"),
>      scales = list(x = list(labels=labs)),
>      layout = c(1,1),
>      key = list(columns = 4,
>        text = list(paste(unique(tmp$groups))),
>        points = Rows(sps, 1:4)
>        )
>    )
> #dev.off()
> 
> How can I wrap R code around this code snippet, such that I can repeat 
> the same code snippet for all other variables in the data frame (i.e. 
> def, ghi, etc.).
> 
> Thanks for your suggestions!
> 
> Sander.
> 



Many ways, a very basic one is to make it a function with an argument 
corresponding to names of columns of the data.frame (code given below).

Uwe Ligges



do_it <- function(varname){
     library(lattice)
     tmp <- aggregate(test[[varname]], list(test$bins, test$groups), mean)
     colnames(tmp) <- c("bins", "groups", "abc")
     tmp
     #pltName <- paste("line_datGrassChem_", "abc", ".eps", sep="")
     #postscript(pltName)
     labs <- c("-15/-9","-9/-6","-6/-3","-3/0")
     sps <- trellis.par.get("superpose.symbol")
     sps$pch <- 1:4
     trellis.par.set("superpose.symbol", sps)
     xyplot( abc ~ bins, data = tmp,
         groups = groups, type = list("p", "l"),
         scales = list(x = list(labels=labs)),
         layout = c(1,1),
         key = list(columns = 4,
         text = list(paste(unique(tmp$groups))),
         points = Rows(sps, 1:4)
         )
     )
     #dev.off()
}

do_it("ghi")



From ripley at stats.ox.ac.uk  Tue Aug 16 08:50:31 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Aug 2005 07:50:31 +0100 (BST)
Subject: [R] return unique values from date/time class object
In-Reply-To: <BEA6A7E18959A04385DC14D24619F89F01D73C22@sagemsg0008.sagemsmrd01.sa.gov.au>
References: <BEA6A7E18959A04385DC14D24619F89F01D73C22@sagemsg0008.sagemsmrd01.sa.gov.au>
Message-ID: <Pine.LNX.4.61.0508160745130.18038@gannet.stats>

On Tue, 16 Aug 2005, McClatchie, Sam (PIRSA-SARDI) wrote:

> Background:
> OS: Linux Mandrake 10.1
> release: R 2.1.1
> editor: GNU Emacs 21.3.2
> front-end: ESS 5.2.3
> ---------------------------------
>
> Thanks to Brian Ripley (I've upgraded from source, thanks for the reminder)
> and Petr Pikal for their suggestions, but I have not made clear the form of
> my data:

You missed my comment about POSIXlt objects: convert to POSIXct first.
I can't reproduce your error messages, but

 	unique(as.POSIXct(new.time))

works for me.

>
> Browse[1]> ceduna[1:10,]
>                  LSD AVIATION_ID WND_DIR WND_SPD_MPS
> 1  1/01/2001 10:30:00        YCDU     230         4.6
> 2  1/01/2001 11:00:00        YCDU     210         4.1
> 3  1/01/2001 11:30:00        YCDU     230         6.7
> 4  1/01/2001 12:00:00        YCDU     230         7.7
> 5  1/01/2001 12:30:00        YCDU     220         8.2
> 6  1/01/2001 13:00:00        YCDU     210         7.2
> 7  1/01/2001 13:30:00        YCDU     210         7.2
> 8  1/01/2001 14:00:00        YCDU     200         6.7
> 9  1/01/2001 14:30:00        YCDU     190         7.7
> 10 1/01/2001 15:00:00        YCDU     200         8.2
> Browse[1]> class(ceduna)
> [1] "data.frame"
> Browse[1]>  x <- as.character(ceduna$LSD)
> Browse[1]>     new.time <- strptime(x, "%d/%m/%Y %H:%M:%S")
> Browse[1]> class(new.time)
> [1] "POSIXt"  "POSIXlt"
> Browse[1]> unique(new.time)
> Error in unique.default(new.time) : unique() applies only to vectors
> Browse[1]> tt <- new.time[!duplicated(unclass(new.time))]
> Error in duplicated.default(unclass(new.time)) :
> 	duplicated() applies only to vectors
> Browse[1]>
>
> I'm obviously doing something silly with the data classes, but what?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Aug 16 09:06:11 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Aug 2005 08:06:11 +0100 (BST)
Subject: [R] merge warning is.na(out$h)
In-Reply-To: <5C9D80739A5FCC4995C426E74D3573C48B6B01@smmail4.rand.org>
References: <5C9D80739A5FCC4995C426E74D3573C48B6B01@smmail4.rand.org>
Message-ID: <Pine.LNX.4.61.0508160753490.18038@gannet.stats>

That error/warning is not from merge() (it does not contain that code, 
nor do the standard R packages).  options(warn=2) and traceback() will 
show you where it is coming from.

Note that you have an error during printing the warning, which suggests 
there is more wrong than you have seen.

Please provide a reproducible example, or at least str(data1) and 
str(data2).  (Your final comment suggests it is data1 that is unusual.)

On Mon, 15 Aug 2005, Fulton, Brent wrote:

> Does anyone know how to interpret this merge warning and whether it's 
> critical to fix? The merge seemed to work fine, but I am concerned.
>
> data3<-merge(data1, data2, by="ID", all=TRUE)
>
> Warning messages: 1: is.na() applied to non-(list or vector) in: 
> is.na(out$h)  Error in cat(list(...), file, sep, fill, labels, append) : 
> argument 2 not yet handled by cat
>
> When I remove all=TRUE or just include all.y=TRUE, I don't get the 
> warning; however, I get the warning when I include all.x=TRUE.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From u9126801 at stat.nctu.edu.tw  Tue Aug 16 09:08:09 2005
From: u9126801 at stat.nctu.edu.tw (Chin Chieh)
Date: Tue, 16 Aug 2005 15:08:09 +0800
Subject: [R] missing sh.exe file when running "R CMD INSTALL test"
Message-ID: <000601c5a231$4258f2f0$2a72718c@winnie>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050816/d62ee58b/attachment.pl

From ligges at statistik.uni-dortmund.de  Tue Aug 16 09:23:11 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 16 Aug 2005 09:23:11 +0200
Subject: [R] missing sh.exe file when running "R CMD INSTALL test"
In-Reply-To: <000601c5a231$4258f2f0$2a72718c@winnie>
References: <000601c5a231$4258f2f0$2a72718c@winnie>
Message-ID: <4301945F.7020508@statistik.uni-dortmund.de>

Chin Chieh wrote:

> I am trying to learn how to make a simple package that contains no C
> or Fortran code.  I used package.skeleton(...) to make a package
> called "test".  The directory and files look good.  I downloaded and
> installed Rtools (www.murdoch-sutherland.com/Rtools/tools.zip).  I
> added the path and from the dos prompt I can verify that make.exe and
> sh.exe both exist, but when I try to run "R CMD INSTALL test" I get an
> error "make: sh.exe: Command not found"  and "make: *** [pkg-test]
> Error 127".  I get the same error message if a try the command "make
> pkg-test".

Are you sure it is really in the path of the shell from which you are 
executing R CMD?
I think this is not the case. Try typing sh.exe therein directly ...

Uwe Ligges





> I saw in an old FAQ a suggestion to move sh.eve to the C:\bin\ folder,
> but my C: root does not have a "bin" folder.  Nonetheless, I created
> one and put sh.exe there and it provided no help (I didn't expect it
> too).
> 
> Can anyone help me?
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dieter.menne at menne-biomed.de  Tue Aug 16 09:31:54 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Tue, 16 Aug 2005 07:31:54 +0000 (UTC)
Subject: [R] data manipulation help
References: <20050816030259.D914522AE@servidor.posgrado.ecologia.edu.mx>
Message-ID: <loom.20050816T093020-123@post.gmane.org>

roberto munguia <munguiar <at> posgrado.ecologia.edu.mx> writes:

> 
> I have a dataframe with 468 individuals (rows) that I captured at least once
> during 28 visits (columns), it looks like:
> 
> mortality[1:10,]
> 
> 
> 1            1           0           0           0           1           1
> 1           0           0           0
..
> so I can know how many times every individual was captured, 0= not capture,
> 1=capture. 
 
> I also want to know when  was the first and the last capture for every
> individual,

This should give you a starter

# create play data
cap = data.frame(matrix(rbinom(120,1,0.3),nrow=10))

firstthat<-function(x) which(x)[1] # stolen from Thomas Lumley

# Make your data logical; not really needed, but easier to understand
cap.log = cap==1
apply(cap.log,1,firstthat) # gives first captures

Dieter



From hb at maths.lth.se  Tue Aug 16 10:00:14 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 16 Aug 2005 10:00:14 +0200
Subject: [R] Image from bytes streams
In-Reply-To: <76189e25050815203379654093@mail.gmail.com>
References: <76189e25050815203379654093@mail.gmail.com>
Message-ID: <43019D0E.5090901@maths.lth.se>

The R graphics is not sent to the standard output of the R process, 
which you assume when you try to "capture" it via your Java 'input' 
stream.  Simple illustration:

C:\>echo plot(1) | R --quiet --no-save
 > plot(1)
 >
C:\>

So where did the graphics go then?  If you "batch" run R commands like 
this, all graphical output is written to (one) default postscript file 
"Rplots.ps"; that's the file you want to read.  I bet you have a two 
page Rplots.ps file for your pie and scatter plot.  If you do not want 
postscript, but other formats, you have to generate you image files 
explicitly, e.g.

png("image.png", width=640, height=480)
plot(1)
dev.off()

Make sure you understand how R works before you try to call it from 
Java; there is nothing magic going on if you understand it.

Cheers

Henrik Bengtsson

M??rcio de Medeiros Ribeiro wrote:
> Hello!
> 
> I'm trying to get an array of bytes from graphic images generated by
> R. Here, you can see my Java code:
> 
> --------------------------------------------------------------------------------------------------------------------------
> Process p = Runtime.getRuntime().exec("C:/Arquivos de
> programas/R/rw1090/bin/Rterm.exe --no-save");
> 
> DataOutputStream output = new DataOutputStream(new
> BufferedOutputStream(p.getOutputStream()));
> 
> DataInputStream input = new DataInputStream(new
> BufferedInputStream(p.getInputStream()));
> 
> // output.writeBytes("pie(c(50,30,20))"); //Pie graphic
> output.writeBytes("plot(1,1)"); // Plot graphic
> output.flush();
> 
> input.readFully(new byte[200]); // Here I read the "image" bytes.
> --------------------------------------------------------------------------------------------------------------------------
> 
> That's the problem: when I use Pie graphic, I got some bytes. However,
> when I use the Plot graphic, I got the same bytes! So, I suppose that
> my program does not read the bytes from the generated graphic from R.
> 
> Is it possible to get the bytes from the generated graphic? How can I
> get these bytes?
> 
> Sorry about my english. I'm brazilian! :)



From sean.oriordain at gmail.com  Tue Aug 16 10:02:11 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Tue, 16 Aug 2005 08:02:11 +0000
Subject: [R] How to get a list work in RData file
In-Reply-To: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EBD2@usctmx1106.Merck.com>
References: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EBD2@usctmx1106.Merck.com>
Message-ID: <8ed68eed05081601024a22add9@mail.gmail.com>

you know about
?history

Sean

On 16/08/05, Liaw, Andy <andy_liaw at merck.com> wrote:
> If you want to keep track of the function call that produced an object,
> usually you need to do that inside the function that's being called, e.g.,
> 
> > test.xy <- function(x,y) {
> +     xy <- x+y
> +     attr(xy, "Call") <- match.call()
> +     xy
> + }
> > xyadd <- test.xy(x=2, y=3)
> > xyadd
> [1] 5
> attr(,"Call")
> test.xy(x = 2, y = 3)
> > str(xyadd)
>  atomic [1:1] 5
>  - attr(*, "Call")= language test.xy(x = 2, y = 3)
> 
> 
> Andy
> 
> > From: Xiyan Lon
> >
> > Dear R-Helper,
> > I want to know how I get a list  work which I saved in RData
> > file. For
> > example,
> >
> >  > test.xy <- function(x,y) {
> > +    xy <- x+y
> > +    xy
> > + }
> >  >
> >  > xyadd <- test.xy(x=2, y=3)
> >  > xyadd
> > [1] 5
> >  > x1 <- c(2,43,60,8)
> >  > y1 <- c(91,7,5,30)
> >  >
> >  > xyadd1 <- test.xy(x=x1, y=y1)
> >  > xyadd1
> > [1] 93 50 65 38
> >  > save(list = ls(all=TRUE), file = "testxy.RData")
> >  > rm(list=ls(all=TRUE))
> >  > load("C:/R/useR/testxy.RData")
> >  > ls()
> > [1] "test.xy" "x1"      "xyadd"   "xyadd1"  "y1"
> >  >
> >  > ls.str(pat="xyadd")
> > xyadd :  num 5
> > xyadd1 :  num [1:4] 93 50 65 38
> >  >
> >
> > When I run, I know the result like above
> >  > xyadd
> > [1] 5
> >  > xyadd1
> > [1] 93 50 65 38
> >  >
> > what I want to know, is there any function to make the result like:
> >
> >  > xyadd
> >
> >          test.xy(x=2, y=3)
> >
> > and
> >
> >  > xyadd1
> >
> >         test.xy(x=x1, y=y1)
> >
> > Best,
> > Xiyan Lon
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From pburns at pburns.seanet.com  Tue Aug 16 10:15:44 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 16 Aug 2005 09:15:44 +0100
Subject: [R] Conditional Matrices
In-Reply-To: <1cb93321cb960a.1cb960a1cb9332@osu.edu>
References: <1cb93321cb960a.1cb960a1cb9332@osu.edu>
Message-ID: <4301A0B0.40608@pburns.seanet.com>

ifelse(mat1, mat2, NA)

should do what you want.

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

ISAIAH SHALWITZ wrote:

>This seems like a simple problem but I can't figure it out:
>
>I have two identical DIMENSION matrices.  Both contain only binary values NOT identical between matrices.  What I want to do: If in cell (1,1) the value in the first matrix (x) equals 1, then I keep the value in cell (1,1) in the second matrix (y).  If in cell (1,1) the value in the first matrix (x) equals 0, then I change the value in cell (1,1) in the second matrix (y)to missing (NA).  Repeat for every pair of cells (coordinates of the paired cells always match).
>
>Please help.
>
>I
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From Ted.Harding at nessie.mcc.ac.uk  Tue Aug 16 10:23:10 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 16 Aug 2005 09:23:10 +0100 (BST)
Subject: [R] Conditional Matrices
In-Reply-To: <1cb93321cb960a.1cb960a1cb9332@osu.edu>
Message-ID: <XFMail.050816092310.Ted.Harding@nessie.mcc.ac.uk>

On 16-Aug-05 ISAIAH SHALWITZ wrote:
> This seems like a simple problem but I can't figure it out:
> 
> I have two identical DIMENSION matrices.  Both contain only binary
> values NOT identical between matrices.  What I want to do: If in cell
> (1,1) the value in the first matrix (x) equals 1, then I keep the value
> in cell (1,1) in the second matrix (y).  If in cell (1,1) the value in
> the first matrix (x) equals 0, then I change the value in cell (1,1) in
> the second matrix (y)to missing (NA).  Repeat for every pair of cells
> (coordinates of the paired cells always match).
> 
> Please help.

It seems the following is what you are looking for:

A<-matrix(c(1,0,1,0,1,1,1,1,1),nrow=3)
A
#      [,1] [,2] [,3]
# [1,]    1    0    1
# [2,]    0    1    1
# [3,]    1    1    1

B<-matrix(c(1,2,3,4,5,6,7,8,9),nrow=3)
B
#      [,1] [,2] [,3]
# [1,]    1    4    7
# [2,]    2    5    8
# [3,]    3    6    9

B[A==0]<-NA
B
#      [,1] [,2] [,3]
# [1,]    1   NA    7
# [2,]   NA    5    8
# [3,]    3    6    9

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 16-Aug-05                                       Time: 09:08:25
------------------------------ XFMail ------------------------------



From aleszib at gmail.com  Tue Aug 16 10:34:42 2005
From: aleszib at gmail.com (Ales Ziberna)
Date: Tue, 16 Aug 2005 10:34:42 +0200
Subject: [R] Conditional Matrices
References: <1cb93321cb960a.1cb960a1cb9332@osu.edu>
Message-ID: <02be01c5a23d$8fac36a0$598debd4@ales>

#M1 = first matrix
#M2 = second matrix

M2[M1==0]<-NA

----- Original Message ----- 
From: "ISAIAH SHALWITZ" <shalwitz.1 at osu.edu>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, August 16, 2005 5:00 AM
Subject: [R] Conditional Matrices


> This seems like a simple problem but I can't figure it out:
>
> I have two identical DIMENSION matrices.  Both contain only binary values 
> NOT identical between matrices.  What I want to do: If in cell (1,1) the 
> value in the first matrix (x) equals 1, then I keep the value in cell 
> (1,1) in the second matrix (y).  If in cell (1,1) the value in the first 
> matrix (x) equals 0, then I change the value in cell (1,1) in the second 
> matrix (y)to missing (NA).  Repeat for every pair of cells (coordinates of 
> the paired cells always match).
>
> Please help.
>
> I
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From slist at oomvanlieshout.net  Tue Aug 16 10:56:38 2005
From: slist at oomvanlieshout.net (Sander Oom)
Date: Tue, 16 Aug 2005 10:56:38 +0200
Subject: [R] How to repeat code snippet for several variables in a data
 frame?
In-Reply-To: <8ed68eed05081523366df7b5c1@mail.gmail.com>
References: <43010035.103@oomvanlieshout.net>
	<8ed68eed05081523366df7b5c1@mail.gmail.com>
Message-ID: <4301AA46.7010603@oomvanlieshout.net>

Thanks for the very useful tips!

Now I have enough round and square bracket and other tricks to wrap up 
the function! The double square bracket trick in test[[varname]] is golden!

Thanks again,

Sander.



From ahenningsen at email.uni-kiel.de  Tue Aug 16 11:04:26 2005
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Tue, 16 Aug 2005 11:04:26 +0200
Subject: [R] Fwd: Documenting data sets with many variables
Message-ID: <200508161104.27017.ahenningsen@email.uni-kiel.de>

Hi, 

since nobody answered to my first message, I try to explain my problem more 
clearly and more general this time:

I have a data set in my R package "micEcon", which has many variables (82). 
Therefore, I would like to avoid to describe all variables in the "\format" 
section of the documentation (.Rd file). However, doing this lets "R CMD 
check" complain about "data codoc mismatches" (details see below).
Is there a way to avoid the description of all variables without getting a
complaint from "R CMD check"?

Thanks,
Arne


----------  Forwarded Message  ----------

Subject: Documenting data sets with many variables
Date: Friday 05 August 2005 14:03
From: Arne Henningsen <ahenningsen at email.uni-kiel.de>
To: R-help at stat.math.ethz.ch

Hi,

I extended the data set "Blanciforti86" that is included in my R package
"micEcon". For instance, I added consumer prices, annual consumption
expenditures and expenditure shares of eleven aggregate commodity groups.
The corresponding variables in the data frame are called "pAgg1",
"pAgg2", ..., "pAgg11", "xAgg1", "xAgg2", ..., "xAgg11", "wAgg1",
"wAgg2", ..., "wAgg11". To avoid to describe all 33 items in the "\format"
section of the documentation (.Rd file) I wrote something like

\format{
   This data frame contains the following columns:
   \describe{
      [ . . . ]
      \item{xAggX}{Expenditure on the aggregate commodity group X
         (in Millions of US-Dollars).}
      \item{pAggX}{Price index for the aggregate commodity group X
         (1972 = 100).}
      \item{wAggX}{Expenditure share of the aggregate commodity group X.}
      [ . . . ]
   }
}

and explained the 11 aggregate commodity groups only once in a different
section (1=food, 2=clothing, ... ). However, "R CMD check" now complains
about "data codoc mismatches", e.g.
  Code: [...] pAgg1pAgg2 pAgg3  [...]
  Docs: [...] pAggX [...]

Is there a way to avoid the description of all 33 items without getting a
complaint from "R CMD check"?

Thanks,
Arne

-------------------------------------------------------

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From Katharina.Steinmann at stud.unibas.ch  Tue Aug 16 11:42:59 2005
From: Katharina.Steinmann at stud.unibas.ch (K. Steinmann)
Date: Tue, 16 Aug 2005 11:42:59 +0200
Subject: [R] predict nbinomial glm
Message-ID: <1124185379.4301b5232c04d@webmail.unibas.ch>

Dear R-helpers,

let us assume, that I have the following dataset:

a <- rnbinom(200, 1, 0.5)
b <- (1:200)
c <- (30:229)
d <- rep(c("q", "r", "s", "t"), rep(50,4))
data_frame <- data.frame(a,b,c,d)

In a first step I run a glm.nb (full code is given at the end of this mail) and
want to predict my response variable a.
In a second step, I would like to run a glm.nb based on a subset of the
data_frame. As soon as I want to predict the response variable a, I get the
following error message:
"Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
object$xlevels) :
        factor d has new level(s) q"

Does anybody have a solution to this problem?

Thank you in advance,
K. Steinmann (working with R 2.0.0)


Code:

library(MASS)

a <- rnbinom(200, 1, 0.5)
b <- (1:200)
c <- (30:229)
d <- rep(c("q", "r", "s", "t"), rep(50,4))


data_frame <- data.frame(a,b,c,d)


model_1 = glm.nb(a ~ b + d , data = data_frame)


pred_model_1 = predict(model_1, newdata = data_frame, type = "response", se.fit
= FALSE, dispersion = NULL, terms = NULL)


subset_of_dataframe = subset(data_frame, (b > 80 & c < 190 ))


model_2 = glm.nb(a ~ b + d , data = subset_of_dataframe)
pred_model_2 = predict(model_2, newdata = subset_of_dataframe, type =
"response", se.fit = FALSE, dispersion = NULL, terms = NULL)



From dimitris.rizopoulos at med.kuleuven.be  Tue Aug 16 11:45:27 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 16 Aug 2005 11:45:27 +0200
Subject: [R] Re-sort list of vectors
References: <1F5B2A5E6712B94DA65EA9EBF0A1A38230E2B3@EMAIL.mpimp-golm.mpg.de>
Message-ID: <01a601c5a247$3b598f30$0540210a@www.domain>

maybe something like this can be helpful:

x <- list("1" = c(a = 1, b = 2, c = 3), "2" = c(d = 4, b = 5, e = 6))
################
y <- data.frame(nam = rep(names(x), sapply(x, length)), val = 
unlist(x))
lapply(split(y, unlist(lapply(x, names))), function(x){ res <- x$val; 
names(res) <- x$nam; res })


Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Jan Hummel" <Hummel at mpimp-golm.mpg.de>
To: <r-help at stat.math.ethz.ch>
Sent: Monday, August 15, 2005 7:09 PM
Subject: Re: [R] Re-sort list of vectors


Thanks a lot! But unfortunately I will not know the dimensions of both 
lists. And further, the lists may be (partly) disjoint as: x <- 
list("1"=c(a=1, b=2, c=3), "2"=c(d=4, b=5, e=6)). And last but not 
least I'm really have to have access to the names of the named list 
items.

The problem I dealt with is in unlist() merging the names together, as 
you can see in your example given: "V1", "V2" and "V3". Because off 
interpreting the names later as identifiers in db queries I'm really 
interested in getting something like list("a"=c("1"=1), "b"=c("1"=2, 
"2"=5), "c"=c("1"=3), "d"=c("1"=4), "e"=c("1"=6)) for the above input.
By giving the result this way I'm able to extract both names from two 
sets as well as the according value between both items.

One point could be to build a matrix but this matrix would have many 
NA's. So I prefer Lists of Lists.

Any ideas?

cheers
Jan

-----Urspr??ngliche Nachricht-----
Von: Liaw, Andy [mailto:andy_liaw at merck.com]
Gesendet: Montag, 15. August 2005 17:31
An: Jan Hummel; r-help at stat.math.ethz.ch
Betreff: RE: [R] Re-sort list of vectors

If all vectors in the list have the same length, why not use a matrix? 
Then you'd just transpose the matrix if you need to.  If you really 
have to have it as a list, here's one possibility:

> x <- list("1"=c(a=1, b=2, c=3), "2"=c(a=4, b=5, c=6)) x
$"1"
a b c
1 2 3

$"2"
a b c
4 5 6
> as.list(as.data.frame(t(matrix(unlist(x), nrow=3))))
$V1
[1] 1 4

$V2
[1] 2 5

$V3
[1] 3 6

Andy


> From: Jan Hummel
>
> Hi.
> Can anyone suggest a simple way to re-sort in R a list of vectors of
> the following form?
>
> input
> $"1"
> a b c
> 1 2 3
> $"2"
> a b c
> 4 5 6
>
> Output should be something like:
> "a"
> "1" 1
> "2" 4
> "b"
> "1" 2
> "2" 5
> "c"
> "1" 3
> "2" 6
>
> I've been futzing with mapply(), outer(), split(), rbind() and so on
> but haven't found an elegant solution.
>
> Thanks,
> Jan.
>
> P.S. E-mailed CCs of posted replies appreciated.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>
>
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From sdavis2 at mail.nih.gov  Tue Aug 16 12:22:25 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 16 Aug 2005 06:22:25 -0400
Subject: [R] R CMD check  failure on minimal code
In-Reply-To: <Pine.LNX.4.61.0508152215080.9609@gannet.stats>
Message-ID: <BF2736A1.C7B7%sdavis2@mail.nih.gov>

On 8/15/05 5:19 PM, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:

> Did you remember to declare a dependency on package 'methods'?  I suspect
> not.  Please see `Writing R Extensions'.

As usual, Professor Ripley, you are correct....

Thanks,
Sean



From sigurdur at hafro.is  Tue Aug 16 12:47:06 2005
From: sigurdur at hafro.is (Sigurdur Jonsson)
Date: Tue, 16 Aug 2005 10:47:06 +0000
Subject: [R]  Vector comparison to matrix
Message-ID: <20050816104705.GB24618@hafro.is>

Hi Todd and list,

I see you have received a few suggestions, here's another:

# set up data: your vector and an a 3x300000 matrix with a few
# matching lines:

target<-c(1,2,3)
A<-matrix(sample(1:3,300000,replace=TRUE),ncol=3)

# count matches:

nMatches<-sum(apply(A,1,function(x,target)
  all.equal(x,target),target)=="TRUE")

# by applying a simple function, which takes 'target' as an 'extra'
# argument, to the rows of A. The function returns a vector of
# differences and 'TRUE'-s, the latter of which can be counted.

This took 1-2 minutes on my >3 year old laptop.

Siggi

> version
         _
platform i686-redhat-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    0.0
year     2004
month    10
day      04
language R

Yeah, I know, an update is (over)due.

-- 
-----------------------------------------------------------------------------
Sigur??ur ????r J??nsson	/	Sigurdur Tor Jonsson
E-mail:				<sigurdur at hafro.is>			
Snail-mail:			Marine Research Institute,
				P.O. Box 1390,
				121 Reykjavik,Iceland
Telephone (direct line):	+354 5752093
Telephone (switchboard):	+354 5752000 
Fax:				+354 5752001



From claush at mek.dtu.dk  Tue Aug 16 13:01:39 2005
From: claush at mek.dtu.dk (Claus Hindsgaul)
Date: Tue, 16 Aug 2005 13:01:39 +0200
Subject: [R] How to merge two strings
Message-ID: <1124190100.3446.4.camel@KT396>

Hi r-help,

A very simple question for which I have not been able to find an answer
in the docs:

	How can I merge two character strings?

I am searching for the equivalent of the (non-existing) stringmerge
function illustrated below:

> s1 <- "R-"
> s2 <- "project"
> stringmerge(s1,s2)
[1] "R-project"
>

Claus

-- 
Ph.D. Student Claus Hindsgaul
CHEC, Dept. Chemical Eng. (KT), DTU
and Biomass Gasification Group, Dept. Mechanical Eng. (MEK), DTU
DTU Building 229 room 154, Phone +45 4525 2838
http://bgg.mek.dtu.dk/ and http://www.kt.dtu.dk/



From dimitris.rizopoulos at med.kuleuven.be  Tue Aug 16 13:06:58 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 16 Aug 2005 13:06:58 +0200
Subject: [R] How to merge two strings
References: <1124190100.3446.4.camel@KT396>
Message-ID: <001a01c5a252$9edae210$0540210a@www.domain>

look at ?paste(), e.g.,

s1 <- "R-"
s2 <- "project"
paste(s1, s2, sep = "")


Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Claus Hindsgaul" <claush at mek.dtu.dk>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, August 16, 2005 1:01 PM
Subject: [R] How to merge two strings


> Hi r-help,
>
> A very simple question for which I have not been able to find an 
> answer
> in the docs:
>
> How can I merge two character strings?
>
> I am searching for the equivalent of the (non-existing) stringmerge
> function illustrated below:
>
>> s1 <- "R-"
>> s2 <- "project"
>> stringmerge(s1,s2)
> [1] "R-project"
>>
>
> Claus
>
> -- 
> Ph.D. Student Claus Hindsgaul
> CHEC, Dept. Chemical Eng. (KT), DTU
> and Biomass Gasification Group, Dept. Mechanical Eng. (MEK), DTU
> DTU Building 229 room 154, Phone +45 4525 2838
> http://bgg.mek.dtu.dk/ and http://www.kt.dtu.dk/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Hummel at mpimp-golm.mpg.de  Tue Aug 16 13:06:33 2005
From: Hummel at mpimp-golm.mpg.de (Jan Hummel)
Date: Tue, 16 Aug 2005 13:06:33 +0200
Subject: [R] Re-sort list of vectors
Message-ID: <1F5B2A5E6712B94DA65EA9EBF0A1A38230E2CD@EMAIL.mpimp-golm.mpg.de>

Dear list members,

thank all of you for replying to my question. Finally I came up with 3
working solutions, which I ask you to rank now in terms of used
resources, computation speed, "design questions" etc. 

x <- list("1" = c(a = 1, b = 2, c = 3), "2" = c(d = 4, b = 5, e = 6))

#looping; Thanks to Jim Holtman
solution1<-function(x){
	Result <- list()
	for (i in names(x)){
		for (j in names(x[[i]])){
			Result[[j]][[i]] <- x[[i]][[j]]
		}
	}
	return(Result)
}

#lapplying function within function; derived from Solution1
solution2<-function(x){
	temporaryList <- list()
	
lapply(names(x),function(y){lapply(names(x[[y]]),function(z){temporaryLi
st[[z]][[y]]<<-x[[y]][[z]]})})
	return(temporaryList)
}

#vectorized; Thanks to Dimitris Rizopoulos
solution3<-function(x){
	y <- data.frame(name = rep(names(x), sapply(x, length)), value =
unlist(x))
	lapply(split(y, unlist(lapply(x, names))), function(z){ res <-
z$value; names(res) <- z$name; return(res) })
}

I would prefer solution2(), because ... I don't know.

Thanks in advance!
	Jan



From sdavis2 at mail.nih.gov  Tue Aug 16 13:07:15 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Tue, 16 Aug 2005 07:07:15 -0400
Subject: [R] How to merge two strings
In-Reply-To: <1124190100.3446.4.camel@KT396>
Message-ID: <BF274123.C7C9%sdavis2@mail.nih.gov>

On 8/16/05 7:01 AM, "Claus Hindsgaul" <claush at mek.dtu.dk> wrote:

> Hi r-help,
> 
> A very simple question for which I have not been able to find an answer
> in the docs:
> 
> How can I merge two character strings?
> 
> I am searching for the equivalent of the (non-existing) stringmerge
> function illustrated below:
> 
>> s1 <- "R-"
>> s2 <- "project"
>> stringmerge(s1,s2)
> [1] "R-project"

See ?paste.

Sean



From tobias.verbeke at telenet.be  Tue Aug 16 13:11:31 2005
From: tobias.verbeke at telenet.be (Tobias Verbeke)
Date: Tue, 16 Aug 2005 13:11:31 +0200
Subject: [R] How to merge two strings
In-Reply-To: <1124190100.3446.4.camel@KT396>
References: <1124190100.3446.4.camel@KT396>
Message-ID: <4301C9E3.2050008@telenet.be>

Claus Hindsgaul wrote:

>Hi r-help,
>
>A very simple question for which I have not been able to find an answer
>in the docs:
>
>	How can I merge two character strings?
>
>I am searching for the equivalent of the (non-existing) stringmerge
>function illustrated below:
>
>  
>
>>s1 <- "R-"
>>s2 <- "project"
>>stringmerge(s1,s2)
>>    
>>
>[1] "R-project"
>  
>
>
>Claus
>
>  
>
paste(s1, s2, sep = "")

HTH,
Tobias



From dimitris.rizopoulos at med.kuleuven.be  Tue Aug 16 13:20:01 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 16 Aug 2005 13:20:01 +0200
Subject: [R] Vector comparison to matrix
References: <20050816104705.GB24618@hafro.is>
Message-ID: <005901c5a254$71669cf0$0540210a@www.domain>

or maybe something like this:

nMatches2 <- sum(!is.na( match(apply(A, 1, paste, collapse = ""), 
paste(target, collapse = "")) ))


Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Sigurdur Jonsson" <sigurdur at hafro.is>
To: <tkredmund98 at hotmail.com>
Cc: <r-help at stat.math.ethz.ch>
Sent: Tuesday, August 16, 2005 12:47 PM
Subject: [R] Vector comparison to matrix


Hi Todd and list,

I see you have received a few suggestions, here's another:

# set up data: your vector and an a 3x300000 matrix with a few
# matching lines:

target<-c(1,2,3)
A<-matrix(sample(1:3,300000,replace=TRUE),ncol=3)

# count matches:

nMatches<-sum(apply(A,1,function(x,target)
  all.equal(x,target),target)=="TRUE")

# by applying a simple function, which takes 'target' as an 'extra'
# argument, to the rows of A. The function returns a vector of
# differences and 'TRUE'-s, the latter of which can be counted.

This took 1-2 minutes on my >3 year old laptop.

Siggi

> version
         _
platform i686-redhat-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    0.0
year     2004
month    10
day      04
language R

Yeah, I know, an update is (over)due.

-- 
-----------------------------------------------------------------------------
Sigur??ur ????r J??nsson / Sigurdur Tor Jonsson
E-mail: <sigurdur at hafro.is>
Snail-mail: Marine Research Institute,
P.O. Box 1390,
121 Reykjavik,Iceland
Telephone (direct line): +354 5752093
Telephone (switchboard): +354 5752000
Fax: +354 5752001

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html



From claush at mek.dtu.dk  Tue Aug 16 13:31:55 2005
From: claush at mek.dtu.dk (Claus Hindsgaul)
Date: Tue, 16 Aug 2005 13:31:55 +0200
Subject: [R] How to merge two strings
In-Reply-To: <001a01c5a252$9edae210$0540210a@www.domain>
References: <1124190100.3446.4.camel@KT396>
	<001a01c5a252$9edae210$0540210a@www.domain>
Message-ID: <1124191915.3446.8.camel@KT396>

Thank you all!
Paste() was just the function I needed to know!

Claus

tir, 16 08 2005 kl. 13:06 +0200, skrev Dimitris Rizopoulos:
> look at ?paste(), e.g.,
> 
> s1 <- "R-"
> s2 <- "project"
> paste(s1, s2, sep = "")
> 
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/336899
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.be/biostat/
>      http://www.student.kuleuven.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message ----- 
> From: "Claus Hindsgaul" <claush at mek.dtu.dk>
> To: <r-help at stat.math.ethz.ch>
> Sent: Tuesday, August 16, 2005 1:01 PM
> Subject: [R] How to merge two strings
> 
> 
> > Hi r-help,
> >
> > A very simple question for which I have not been able to find an 
> > answer
> > in the docs:
> >
> > How can I merge two character strings?
> >
> > I am searching for the equivalent of the (non-existing) stringmerge
> > function illustrated below:
> >
> >> s1 <- "R-"
> >> s2 <- "project"
> >> stringmerge(s1,s2)
> > [1] "R-project"
> >>
> >
> > Claus
> >
> > -- 
> > Ph.D. Student Claus Hindsgaul
> > CHEC, Dept. Chemical Eng. (KT), DTU
> > and Biomass Gasification Group, Dept. Mechanical Eng. (MEK), DTU
> > DTU Building 229 room 154, Phone +45 4525 2838
> > http://bgg.mek.dtu.dk/ and http://www.kt.dtu.dk/
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> 
-- 
Ph.D. Student Claus Hindsgaul
CHEC, Dept. Chemical Eng. (KT), DTU
and Biomass Gasification Group, Dept. Mechanical Eng. (MEK), DTU
DTU Building 229 room 154, Phone +45 4525 2838
http://bgg.mek.dtu.dk/ and http://www.kt.dtu.dk/



From B.Rowlingson at lancaster.ac.uk  Tue Aug 16 13:58:52 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 16 Aug 2005 12:58:52 +0100
Subject: [R] How to merge two strings
In-Reply-To: <1124191915.3446.8.camel@KT396>
References: <1124190100.3446.4.camel@KT396>	<001a01c5a252$9edae210$0540210a@www.domain>
	<1124191915.3446.8.camel@KT396>
Message-ID: <4301D4FC.4030006@lancaster.ac.uk>

Claus Hindsgaul wrote:
> Thank you all!
> Paste() was just the function I needed to know!

  Or sprintf:

  > s1 <- "R-"
  > s2 <- "project"
  > sprintf("%s%s",s1,s2)
  [1] "R-project"

  It seems to be much faster:

  > unix.time(for(i in 1:100000){junk=sprintf("%s%s",s1,s2)})
  [1] 1.12 0.00 1.12 0.00 0.00
  > unix.time(for(i in 1:100000){junk=paste(s1,s2,sep='')})
  [1] 5.90 0.01 5.92 0.00 0.00

  Not that I imagine string concatenation will ever be a bottleneck 
worth optimising but there it is. A well-constructed sprintf() call may 
be more readable than a pastey mess though, with all its fiddly commas 
and quotes - contrived example:

  > sprintf("%s://%s%s/%s",scheme,host,dir,file)
  [1] "http://www.foo.com/foo/bar/baz.txt"

  > paste(scheme,'://',host,dir,'/',file,sep='')
  [1] "http://www.foo.com/foo/bar/baz.txt"

  which do you prefer?

Barry



From wolfgang.meyer at gmail.com  Tue Aug 16 14:23:48 2005
From: wolfgang.meyer at gmail.com (Wolfgang Meyer)
Date: Tue, 16 Aug 2005 14:23:48 +0200
Subject: [R] different leave-one-out cross-validation results from
	tune.svm(...) and svm(...)
Message-ID: <d38070360508160523101ab902@mail.gmail.com>

Hi, 

I am currently using the svm functions from R package e1071 (1.5-9). 
I use function tune.svm(...) to tune the parameters for SVM with RBF kernel.
To obtain reproducible tuning results, I chose leave-one-out cross-validation 
(LOOCV) as my perfomance measurement. 


>  tune.rlt <- tune.svm(classes~.,   data = data.frame(features, classes),
                                 gamma = 2^(-12:0),
                                 cost = 2^(0:12),
                                 tunecontrol = tune.control(cross =
length(cls)))

With this LOOCV scheme I obtained certain best performance with 
tuned parameters (gamma1, cost1). Let's assume the best error estimation 
in tune.rlt is E.

Then I trained a SVM with these parameters (gamma1 & cost1). 
I also ask it to return LOOCV results:

> svm.rlt <- svm(classes~.,   data = data.frame(features, classes),
                        gamma=gamma1, cost=cost1, 
                        cross=length(classes))

And I obtain LOOCV accuracy from svm.rlt, let's assume it is A. 

Unfortunately, it is usually the case that 

E+A < 100%
(it is not numerical error)

Since I used LOOCV as the perfomance measurement, I suppose 

E+A =100%

Why is this the case?

-- 
Wolfgang Meyer



From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Aug 16 14:29:21 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 16 Aug 2005 14:29:21 +0200 (CEST)
Subject: [R] p-values
In-Reply-To: <42F29071.1000107@fe.up.pt>
References: <42F29071.1000107@fe.up.pt>
Message-ID: <Pine.LNX.4.51.0508161419020.25503@artemis.imbe.med.uni-erlangen.de>


On Thu, 4 Aug 2005, Peter Ho wrote:

> HI R-users,
>
> I am trying to repeat an example from Rayner and Best "A contingency
> table approach to nonparametric testing (Chapter 7, Ice cream example).
>
> In their book they calculate Durbin's statistic, D1, a dispersion
> statistics, D2, and a residual. P-values for each statistic is
> calculated from a chi-square distribution and also Monte Carlo p-values.

Hi Peter,

when I understand the example correctly, the main interest is testing
independence of the judges' ranking and the ice cream brand, where the
judges are interpreted as `blocks' using a chi^2-type statistic based on
the rank sums for each ice cream. In R:

ice <- data.frame(judge = factor(rep(c(1:7),rep(3,7))),
                  variety = factor(c(1,2,4,2,3,5,3,4,6,4,5,7,1,5,6,2,6,7,1,3,7)),
                  rank = c(2,3,1,3,1,2,2,1,3,1,2,3,3,1,2,3,1,2,3,1,2))
library("coin")
it <- independence_test(rank ~ variety | judge, data = ice, teststat = "quadtype")
it

        Asymptotic General Independence Test

data:  rank by
         groups 1, 2, 3, 4, 5, 6, 7
         stratified by judge
T = 12, df = 6, p-value = 0.06197

So without having checked the theory exactly, this looks like being
Dubin's D1 statistic with _asymptotic conditional p-value_ (please have a
look at coin's vignette which explains what happens here).

The Monte-Carlo p-value can now be computed by 99,999 replications:

pvalue(independence_test(rank ~ variety | judge, data = ice,
       teststat = "quadtype", distribution = approximate(B = 99999)))

[1] 0.01778018
99 percent confidence interval:
 0.01672170 0.01888482

which seems to be a little bit smaller than 0.02.

Hope that helps,

Torsten

>
> I have found similar p-values based on the chi-square distribution by
> using:
>
>  > pchisq(12, df= 6, lower.tail=F)
> [1] 0.0619688
>  > pchisq(5.1, df= 6, lower.tail=F)
> [1] 0.5310529
>
> Is there a way to calculate the equivalent Monte Carlo p-values?
>
> The values were 0.02 and 0.138 respectively.
>
> The use of the approximate chi-square probabilities for Durbin's test
> are considered not good enough according to Van der Laan (The American
> Statistician 1988,42,165-166).
>
>
> Peter
> --------------------------------
> ESTG-IPVC
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From jeaneid at chass.utoronto.ca  Tue Aug 16 14:39:01 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Tue, 16 Aug 2005 08:39:01 -0400
Subject: [R] preprocessing data
Message-ID: <Pine.SGI.4.40.0508160833280.17622-100000@origin.chass.utoronto.ca>

Dear all,

My question is concerning the line
"This is adequate for small files, but for anything more complicated we
recommend using the facilities   of a language like perl to pre-process
the file."

in the import/export manual.

I have a large fixed-width file that I would like to preprocess in Perl or
awk. The problem is that I do not know where to start. Does anyone have a
simple example on how to turn a fixed-width file in any of these
facilities into csv or tab delimited file. I guess I am looking for
somewhat a perl for dummies or awk for dummies that does this. any
pointers for website will be greatly appreciated

Thank you


Jean Eid



From rpeng at jhsph.edu  Tue Aug 16 14:49:25 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Tue, 16 Aug 2005 08:49:25 -0400
Subject: [R] Fwd: Documenting data sets with many variables
In-Reply-To: <200508161104.27017.ahenningsen@email.uni-kiel.de>
References: <200508161104.27017.ahenningsen@email.uni-kiel.de>
Message-ID: <4301E0D5.5020308@jhsph.edu>

Have you tried using 'promptData()' on the data frame and then 
just using the resulting documentation file?

-roger

Arne Henningsen wrote:
> Hi, 
> 
> since nobody answered to my first message, I try to explain my problem more 
> clearly and more general this time:
> 
> I have a data set in my R package "micEcon", which has many variables (82). 
> Therefore, I would like to avoid to describe all variables in the "\format" 
> section of the documentation (.Rd file). However, doing this lets "R CMD 
> check" complain about "data codoc mismatches" (details see below).
> Is there a way to avoid the description of all variables without getting a
> complaint from "R CMD check"?
> 
> Thanks,
> Arne
> 
> 
> ----------  Forwarded Message  ----------
> 
> Subject: Documenting data sets with many variables
> Date: Friday 05 August 2005 14:03
> From: Arne Henningsen <ahenningsen at email.uni-kiel.de>
> To: R-help at stat.math.ethz.ch
> 
> Hi,
> 
> I extended the data set "Blanciforti86" that is included in my R package
> "micEcon". For instance, I added consumer prices, annual consumption
> expenditures and expenditure shares of eleven aggregate commodity groups.
> The corresponding variables in the data frame are called "pAgg1",
> "pAgg2", ..., "pAgg11", "xAgg1", "xAgg2", ..., "xAgg11", "wAgg1",
> "wAgg2", ..., "wAgg11". To avoid to describe all 33 items in the "\format"
> section of the documentation (.Rd file) I wrote something like
> 
> \format{
>    This data frame contains the following columns:
>    \describe{
>       [ . . . ]
>       \item{xAggX}{Expenditure on the aggregate commodity group X
>          (in Millions of US-Dollars).}
>       \item{pAggX}{Price index for the aggregate commodity group X
>          (1972 = 100).}
>       \item{wAggX}{Expenditure share of the aggregate commodity group X.}
>       [ . . . ]
>    }
> }
> 
> and explained the 11 aggregate commodity groups only once in a different
> section (1=food, 2=clothing, ... ). However, "R CMD check" now complains
> about "data codoc mismatches", e.g.
>   Code: [...] pAgg1pAgg2 pAgg3  [...]
>   Docs: [...] pAggX [...]
> 
> Is there a way to avoid the description of all 33 items without getting a
> complaint from "R CMD check"?
> 
> Thanks,
> Arne
> 
> -------------------------------------------------------
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From kevin.thorpe at utoronto.ca  Tue Aug 16 14:56:43 2005
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 16 Aug 2005 08:56:43 -0400
Subject: [R] preprocessing data
In-Reply-To: <Pine.SGI.4.40.0508160833280.17622-100000@origin.chass.utoronto.ca>
References: <Pine.SGI.4.40.0508160833280.17622-100000@origin.chass.utoronto.ca>
Message-ID: <4301E28B.6000004@utoronto.ca>

Some time ago, Doug Bates wrote a useful paper called "Data
manipulatation in perl."  It is a very concise intoduction and
introduces the unpack function which is one way to deal with fixed
format data.  Just google for

   "data manipulation in perl" bates

and you should be able to find a copy.

Jean Eid wrote:
> Dear all,
> 
> My question is concerning the line
> "This is adequate for small files, but for anything more complicated we
> recommend using the facilities   of a language like perl to pre-process
> the file."
> 
> in the import/export manual.
> 
> I have a large fixed-width file that I would like to preprocess in Perl or
> awk. The problem is that I do not know where to start. Does anyone have a
> simple example on how to turn a fixed-width file in any of these
> facilities into csv or tab delimited file. I guess I am looking for
> somewhat a perl for dummies or awk for dummies that does this. any
> pointers for website will be greatly appreciated
> 
> Thank you
> 
> 
> Jean Eid
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Kevin E. Thorpe
Biostatistician/Trialist, Knowledge Translation Program
Assistant Professor, Department of Public Health Sciences
Faculty of Medicine, University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.946.8081  Fax: 416.971.2462



From jeaneid at chass.utoronto.ca  Tue Aug 16 15:11:53 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Tue, 16 Aug 2005 09:11:53 -0400
Subject: [R] preprocessing data
In-Reply-To: <4301E28B.6000004@utoronto.ca>
Message-ID: <Pine.SGI.4.40.0508160909130.24308-100000@origin.chass.utoronto.ca>

Thank you, that is exactly what I was looking for.

Just a minor suggestion to the manual Import/Export. maybe a reference to
the paper right underneath the line below would be helpfull for people
like me that have never used perl and would like to take the suggestion to
preprosses the data


Jean

On Tue, 16 Aug 2005, Kevin E. Thorpe wrote:

> Some time ago, Doug Bates wrote a useful paper called "Data
> manipulatation in perl."  It is a very concise intoduction and
> introduces the unpack function which is one way to deal with fixed
> format data.  Just google for
>
>    "data manipulation in perl" bates
>
> and you should be able to find a copy.
>
> Jean Eid wrote:
> > Dear all,
> >
> > My question is concerning the line
> > "This is adequate for small files, but for anything more complicated we
> > recommend using the facilities   of a language like perl to pre-process
> > the file."
> >
> > in the import/export manual.
> >
> > I have a large fixed-width file that I would like to preprocess in Perl or
> > awk. The problem is that I do not know where to start. Does anyone have a
> > simple example on how to turn a fixed-width file in any of these
> > facilities into csv or tab delimited file. I guess I am looking for
> > somewhat a perl for dummies or awk for dummies that does this. any
> > pointers for website will be greatly appreciated
> >
> > Thank you
> >
> >
> > Jean Eid
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
>
>
> --
> Kevin E. Thorpe
> Biostatistician/Trialist, Knowledge Translation Program
> Assistant Professor, Department of Public Health Sciences
> Faculty of Medicine, University of Toronto
> email: kevin.thorpe at utoronto.ca  Tel: 416.946.8081  Fax: 416.971.2462
>



From ripley at stats.ox.ac.uk  Tue Aug 16 15:15:00 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Aug 2005 14:15:00 +0100 (BST)
Subject: [R] How to merge two strings
In-Reply-To: <4301D4FC.4030006@lancaster.ac.uk>
References: <1124190100.3446.4.camel@KT396>
	<001a01c5a252$9edae210$0540210a@www.domain>
	<1124191915.3446.8.camel@KT396> <4301D4FC.4030006@lancaster.ac.uk>
Message-ID: <Pine.LNX.4.61.0508161413400.29519@gannet.stats>

On Tue, 16 Aug 2005, Barry Rowlingson wrote:

> Claus Hindsgaul wrote:
>> Thank you all!
>> Paste() was just the function I needed to know!
>
>  Or sprintf:
>
>  > s1 <- "R-"
>  > s2 <- "project"
>  > sprintf("%s%s",s1,s2)
>  [1] "R-project"
>
>  It seems to be much faster:
>
>  > unix.time(for(i in 1:100000){junk=sprintf("%s%s",s1,s2)})
>  [1] 1.12 0.00 1.12 0.00 0.00
>  > unix.time(for(i in 1:100000){junk=paste(s1,s2,sep='')})
>  [1] 5.90 0.01 5.92 0.00 0.00
>
>  Not that I imagine string concatenation will ever be a bottleneck
> worth optimising but there it is. A well-constructed sprintf() call may
> be more readable than a pastey mess though, with all its fiddly commas
> and quotes - contrived example:
>
>  > sprintf("%s://%s%s/%s",scheme,host,dir,file)
>  [1] "http://www.foo.com/foo/bar/baz.txt"
>
>  > paste(scheme,'://',host,dir,'/',file,sep='')
>  [1] "http://www.foo.com/foo/bar/baz.txt"
>
>  which do you prefer?

That's actually the reason we have the enhanced sprintf that we do 
nowadays: to enable readable (and translatable) error messages to be 
written via gettextf.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From petr.pikal at precheza.cz  Tue Aug 16 15:32:16 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Tue, 16 Aug 2005 15:32:16 +0200
Subject: [R] return unique values from date/time class object
In-Reply-To: <BEA6A7E18959A04385DC14D24619F89F01D73C22@sagemsg0008.sagemsmrd01.sa.gov.au>
Message-ID: <43020700.5119.1B1C1AF@localhost>



From marcinhosbt at gmail.com  Tue Aug 16 15:33:05 2005
From: marcinhosbt at gmail.com (=?ISO-8859-1?Q?M=E1rcio_de_Medeiros_Ribeiro?=)
Date: Tue, 16 Aug 2005 10:33:05 -0300
Subject: [R] Image from bytes streams
In-Reply-To: <43019D0E.5090901@maths.lth.se>
References: <76189e25050815203379654093@mail.gmail.com>
	<43019D0E.5090901@maths.lth.se>
Message-ID: <76189e25050816063321b42d24@mail.gmail.com>

Hi,

First, thank you very much for the answers...

I have used the png() function before for generate the image and then
capture its bytes.

My big problem is that my program reads the image before that its
complete by the png() function. For instance, my graphic image has
1000Kb. When R saves it into the hard disk, my Java program reads the
file before the save operation completes (500Kb for example). So, I
got only a part of the file and hence the image... :(

One solution is read the image and search for a byte which represents
the end of the file, but it depends on the image format...

So, how can I discover that R image save operation stored the complete
file into the hard disk?

Thank you one more time!
-- 
M??rcio de Medeiros Ribeiro
Graduando em Ci??ncia da Computa????o
Departamento de Tecnologia da Informa????o - TCI
Universidade Federal de Alagoas - UFAL
Macei?? - Alagoas - Brasil
Projeto ArCo - Arcabou??o de Comunidades
Contato: +55 82 354-3358/9997-6794



From ripley at stats.ox.ac.uk  Tue Aug 16 15:45:02 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Aug 2005 14:45:02 +0100 (BST)
Subject: [R] Image from bytes streams
In-Reply-To: <76189e25050816063321b42d24@mail.gmail.com>
References: <76189e25050815203379654093@mail.gmail.com>
	<43019D0E.5090901@maths.lth.se>
	<76189e25050816063321b42d24@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0508161441120.29519@gannet.stats>

On Tue, 16 Aug 2005, M?rcio de Medeiros Ribeiro wrote:

> First, thank you very much for the answers...
>
> I have used the png() function before for generate the image and then
> capture its bytes.
>
> My big problem is that my program reads the image before that its
> complete by the png() function. For instance, my graphic image has
> 1000Kb. When R saves it into the hard disk, my Java program reads the
> file before the save operation completes (500Kb for example). So, I
> got only a part of the file and hence the image... :(
>
> One solution is read the image and search for a byte which represents
> the end of the file, but it depends on the image format...
>
> So, how can I discover that R image save operation stored the complete
> file into the hard disk?

When dev.off() completes and you get an R prompt back.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Tue Aug 16 16:13:50 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Aug 2005 15:13:50 +0100 (BST)
Subject: [R] predict nbinomial glm
In-Reply-To: <1124185379.4301b5232c04d@webmail.unibas.ch>
References: <1124185379.4301b5232c04d@webmail.unibas.ch>
Message-ID: <Pine.LNX.4.61.0508161229500.29186@gannet.stats>

This is seems to be an unstated repeat of much of an earlier and 
unanswered post

 	https://stat.ethz.ch/pipermail/r-help/2005-August/075914.html

entitled

 	[R] error in predict glm (new levels cause problems)

It is nothing to do with `nbinomial glm' (sic): all model fitting 
functions including lm and glm do this.  The reason you did not get at 
least one reply from your first post is that you seemed not to have done 
your homework.  (One thing the posting guide does ask is for you to try 
the current version of R, and yours is three versions old.)

The code is protecting you from an attempt at statistical nonsense. 
(Indeed, the check was added to catch such misuses.)  Your email address 
seems to be that of a student, so please seek the help of your advisor. 
You seem surprised that you are not allowed to make predictions about 
levels for which you have supplied no relevant data.


On Tue, 16 Aug 2005, K. Steinmann wrote:

> Dear R-helpers,
>
> let us assume, that I have the following dataset:
>
> a <- rnbinom(200, 1, 0.5)
> b <- (1:200)
> c <- (30:229)
> d <- rep(c("q", "r", "s", "t"), rep(50,4))
> data_frame <- data.frame(a,b,c,d)
>
> In a first step I run a glm.nb (full code is given at the end of this mail) and
> want to predict my response variable a.
> In a second step, I would like to run a glm.nb based on a subset of the
> data_frame. As soon as I want to predict the response variable a, I get the
> following error message:
> "Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
> object$xlevels) :
>        factor d has new level(s) q"
>
> Does anybody have a solution to this problem?
>
> Thank you in advance,
> K. Steinmann (working with R 2.0.0)
>
>
> Code:
>
> library(MASS)
>
> a <- rnbinom(200, 1, 0.5)
> b <- (1:200)
> c <- (30:229)
> d <- rep(c("q", "r", "s", "t"), rep(50,4))
>
> data_frame <- data.frame(a,b,c,d)
>
> model_1 = glm.nb(a ~ b + d , data = data_frame)
>
> pred_model_1 = predict(model_1, newdata = data_frame, type = "response", se.fit
> = FALSE, dispersion = NULL, terms = NULL)
>
> subset_of_dataframe = subset(data_frame, (b > 80 & c < 190 ))
>
> model_2 = glm.nb(a ~ b + d , data = subset_of_dataframe)
> pred_model_2 = predict(model_2, newdata = subset_of_dataframe, type =
> "response", se.fit = FALSE, dispersion = NULL, terms = NULL)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Christoph.Scherber at uni-jena.de  Tue Aug 16 16:20:07 2005
From: Christoph.Scherber at uni-jena.de (Christoph Scherber)
Date: Tue, 16 Aug 2005 16:20:07 +0200
Subject: [R] regression with more than one observation per x value
Message-ID: <4301F617.5040500@uni-jena.de>

Dear R users,

How can I do a regression analysis in R where there is more than one 
observation per x value? I tried the example in Sokal&Rohlf (3rd edn., 
1995), page 476 ff., but I somehow couldn??t find a way to partition the 
sums of squares into "linear regression", "deviations from regression", 
and within-groups SS.

I tried

model1<-lm(y~as.numeric(x)+as.factor(x) #with treatment contrasts


but I am sure there??s a better way around it. I would be very happy if 
anyone could give me some suggestions on this.

Best regards
Christoph.



From richmcb at gmail.com  Tue Aug 16 16:21:57 2005
From: richmcb at gmail.com (Ben Rich)
Date: Tue, 16 Aug 2005 16:21:57 +0200
Subject: [R] The naPattern agrument of gnls()
Message-ID: <32acb1210508160721134a80fb@mail.gmail.com>

I was hoping someone could help me to better understand the naPattern
argument in the function gnls().  Unfortunately, there's no example
using this argument provided in the help file.

According to the gnls() help file, naPattern is "an expression or
formula object, specifying which returned values are to be regarded as
missing".  As I understand it, the idea is that with some models (e.g.
quinModel) some of the rows that are needed to compute the predicted
values aren't observations of the response variable and need to be
left out of the optimization.

The nlme() function has an argument with the same name and
description.  I've used naPattern successfully with the nlme()
function, following an example in the book "Mixed-Effects Models in S
and S-PLUS" by Pinheiro and Bates, but a similar attempt with gnls()
fails with the error message:

  Error in data.frame(data, getParsGnls(plist, pmap, beta, N)) :
        arguments imply differing number of rows: 695, 287

Any help or explanation would be appreciated.
I'm using R version 2.1.0 on linux.



From sundar.dorai-raj at pdf.com  Tue Aug 16 16:33:47 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 16 Aug 2005 09:33:47 -0500
Subject: [R] predict nbinomial glm
In-Reply-To: <Pine.LNX.4.61.0508161229500.29186@gannet.stats>
References: <1124185379.4301b5232c04d@webmail.unibas.ch>
	<Pine.LNX.4.61.0508161229500.29186@gannet.stats>
Message-ID: <4301F94B.5020701@pdf.com>

Katharina,

I agree with Prof. Ripley's assessment. But, perhaps one thing you may 
have overlooked is that subset.data.frame does not remove unused levels. So,

 > subset_of_dataframe = subset(data_frame, (b > 80 & c < 190))
 > levels(subset_of_dataframe$d)
[1] "q" "r" "s" "t"
 > table(subset_of_dataframe$d)
  q  r  s  t
  0 20 50 10

Even though the level "q" does not appear it is still a level of "d". 
Perhaps you need to do the following after the subset:

subset_of_dataframe[] <- lapply(subset_of_dataframe, "[", drop = TRUE)

which drops all unused levels from factors.

I'm not sure if your problem is statistical in nature or simply a 
misunderstanding of the software. I'm only attempting to answer the 
latter. As Prof. Ripley suggests, discuss any statistical problem (i.e. 
predicting on missing levels) with your advisor.

HTH,

--sundar

P.S. Also, update R. It's free.

Prof Brian Ripley wrote:
> This is seems to be an unstated repeat of much of an earlier and 
> unanswered post
> 
>  	https://stat.ethz.ch/pipermail/r-help/2005-August/075914.html
> 
> entitled
> 
>  	[R] error in predict glm (new levels cause problems)
> 
> It is nothing to do with `nbinomial glm' (sic): all model fitting 
> functions including lm and glm do this.  The reason you did not get at 
> least one reply from your first post is that you seemed not to have done 
> your homework.  (One thing the posting guide does ask is for you to try 
> the current version of R, and yours is three versions old.)
> 
> The code is protecting you from an attempt at statistical nonsense. 
> (Indeed, the check was added to catch such misuses.)  Your email address 
> seems to be that of a student, so please seek the help of your advisor. 
> You seem surprised that you are not allowed to make predictions about 
> levels for which you have supplied no relevant data.
> 
> 
> On Tue, 16 Aug 2005, K. Steinmann wrote:
> 
> 
>>Dear R-helpers,
>>
>>let us assume, that I have the following dataset:
>>
>>a <- rnbinom(200, 1, 0.5)
>>b <- (1:200)
>>c <- (30:229)
>>d <- rep(c("q", "r", "s", "t"), rep(50,4))
>>data_frame <- data.frame(a,b,c,d)
>>
>>In a first step I run a glm.nb (full code is given at the end of this mail) and
>>want to predict my response variable a.
>>In a second step, I would like to run a glm.nb based on a subset of the
>>data_frame. As soon as I want to predict the response variable a, I get the
>>following error message:
>>"Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
>>object$xlevels) :
>>       factor d has new level(s) q"
>>
>>Does anybody have a solution to this problem?
>>
>>Thank you in advance,
>>K. Steinmann (working with R 2.0.0)
>>
>>
>>Code:
>>
>>library(MASS)
>>
>>a <- rnbinom(200, 1, 0.5)
>>b <- (1:200)
>>c <- (30:229)
>>d <- rep(c("q", "r", "s", "t"), rep(50,4))
>>
>>data_frame <- data.frame(a,b,c,d)
>>
>>model_1 = glm.nb(a ~ b + d , data = data_frame)
>>
>>pred_model_1 = predict(model_1, newdata = data_frame, type = "response", se.fit
>>= FALSE, dispersion = NULL, terms = NULL)
>>
>>subset_of_dataframe = subset(data_frame, (b > 80 & c < 190 ))
>>
>>model_2 = glm.nb(a ~ b + d , data = subset_of_dataframe)
>>pred_model_2 = predict(model_2, newdata = subset_of_dataframe, type =
>>"response", se.fit = FALSE, dispersion = NULL, terms = NULL)
> 
>



From andy_liaw at merck.com  Tue Aug 16 16:35:00 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 16 Aug 2005 10:35:00 -0400
Subject: [R] regression with more than one observation per x value
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFA64EBD7@usctmx1106.Merck.com>

Sounds like you're looking for something like pure.error.anova in the `alr3'
package on CRAN...

Andy

> From: Christoph Scherber
> 
> Dear R users,
> 
> How can I do a regression analysis in R where there is more than one 
> observation per x value? I tried the example in Sokal&Rohlf 
> (3rd edn., 
> 1995), page 476 ff., but I somehow couldn??t find a way to 
> partition the 
> sums of squares into "linear regression", "deviations from 
> regression", 
> and within-groups SS.
> 
> I tried
> 
> model1<-lm(y~as.numeric(x)+as.factor(x) #with treatment contrasts
> 
> 
> but I am sure there??s a better way around it. I would be very 
> happy if 
> anyone could give me some suggestions on this.
> 
> Best regards
> Christoph.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From wilks at dial.pipex.com  Tue Aug 16 16:52:40 2005
From: wilks at dial.pipex.com (John Wilkinson (pipex))
Date: Tue, 16 Aug 2005 15:52:40 +0100
Subject: [R]  stepAIC invalid scope argument
Message-ID: <JCEIJNOHMNBPLMGFDHNDAENECAAA.wilks@dial.pipex.com>


Adai,

The following works.Perhaps you should define your 'upper' and 'lower'
in the list as aov's, as you have done with your lo,hi and mid.

John

>  stepAIC( mid, scope=list(upper = mid , lower = lo) )
Start:  AIC= -594.66 
 y ~ x2 + x3 

       Df Sum of Sq     RSS     AIC
- x2    1      0.11  548.56 -596.45
- x3    1      0.95  549.40 -594.93
<none>               548.45 -594.66

Step:  AIC= -596.45 
 y ~ x3 

Adaikalavan Ramasamy wrote ---

I am trying to replicate the first example from stepAIC from the MASS
package with my own dataset but am running into error. If someone can
point where I have gone wrong, I would appreciate it very much. 

Here is an example :

 set.seed(1)
 df   <- data.frame( x1=rnorm(1000), x2=rnorm(1000), x3=rnorm(1000) )
 df$y <- 0.5*df$x1 + rnorm(1000, mean=8, sd=0.5)
 # pairs(df); head(df)

 lo  <- aov( y ~ 1, data=df )
 hi  <- aov( y ~ .^2, data=df )
 mid <- aov( y ~ x2 + x3, data=df )

Running any of the following commands

 stepAIC( mid, scope=list(upper = ~x1 + x2 + x3 , lower = ~1) )
 stepAIC( mid, scope=list(upper = hi , lower = lo) )
 addterm( mid, ~ x1 + x2 + x3 )
 addterm( lo, hi )

gives the same error message : 
  Error in eval(expr, envir, enclos) : invalid second argumen



From ahenningsen at email.uni-kiel.de  Tue Aug 16 17:11:50 2005
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Tue, 16 Aug 2005 17:11:50 +0200
Subject: [R] Fwd: Documenting data sets with many variables
In-Reply-To: <4301E0D5.5020308@jhsph.edu>
References: <200508161104.27017.ahenningsen@email.uni-kiel.de>
	<4301E0D5.5020308@jhsph.edu>
Message-ID: <200508161711.50444.ahenningsen@email.uni-kiel.de>

On Tuesday 16 August 2005 14:49, Roger D. Peng wrote:
> Have you tried using 'promptData()' on the data frame and then
> just using the resulting documentation file?

Thank you, Roger, for bringing 'promptData()' to my mind. This is really a 
useful tool. However, in my special case my aim is to reduce the extent and 
increase the comprehensibility of the documentation rather than to reduce my 
effort to write the documentation. 

Any further hints are welcome!

Thanks,
Arne

> -roger
>
> Arne Henningsen wrote:
> > Hi,
> >
> > since nobody answered to my first message, I try to explain my problem
> > more clearly and more general this time:
> >
> > I have a data set in my R package "micEcon", which has many variables
> > (82). Therefore, I would like to avoid to describe all variables in the
> > "\format" section of the documentation (.Rd file). However, doing this
> > lets "R CMD check" complain about "data codoc mismatches" (details see
> > below). Is there a way to avoid the description of all variables without
> > getting a complaint from "R CMD check"?
> >
> > Thanks,
> > Arne
> >
> >
> > ----------  Forwarded Message  ----------
> >
> > Subject: Documenting data sets with many variables
> > Date: Friday 05 August 2005 14:03
> > From: Arne Henningsen <ahenningsen at email.uni-kiel.de>
> > To: R-help at stat.math.ethz.ch
> >
> > Hi,
> >
> > I extended the data set "Blanciforti86" that is included in my R package
> > "micEcon". For instance, I added consumer prices, annual consumption
> > expenditures and expenditure shares of eleven aggregate commodity groups.
> > The corresponding variables in the data frame are called "pAgg1",
> > "pAgg2", ..., "pAgg11", "xAgg1", "xAgg2", ..., "xAgg11", "wAgg1",
> > "wAgg2", ..., "wAgg11". To avoid to describe all 33 items in the
> > "\format" section of the documentation (.Rd file) I wrote something like
> >
> > \format{
> >    This data frame contains the following columns:
> >    \describe{
> >       [ . . . ]
> >       \item{xAggX}{Expenditure on the aggregate commodity group X
> >          (in Millions of US-Dollars).}
> >       \item{pAggX}{Price index for the aggregate commodity group X
> >          (1972 = 100).}
> >       \item{wAggX}{Expenditure share of the aggregate commodity group X.}
> >       [ . . . ]
> >    }
> > }
> >
> > and explained the 11 aggregate commodity groups only once in a different
> > section (1=food, 2=clothing, ... ). However, "R CMD check" now complains
> > about "data codoc mismatches", e.g.
> >   Code: [...] pAgg1pAgg2 pAgg3  [...]
> >   Docs: [...] pAggX [...]
> >
> > Is there a way to avoid the description of all 33 items without getting a
> > complaint from "R CMD check"?
> >
> > Thanks,
> > Arne
> >
> > -------------------------------------------------------

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From gavin.simpson at ucl.ac.uk  Tue Aug 16 17:26:35 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 16 Aug 2005 16:26:35 +0100
Subject: [R] Fwd: Documenting data sets with many variables
In-Reply-To: <200508161711.50444.ahenningsen@email.uni-kiel.de>
References: <200508161104.27017.ahenningsen@email.uni-kiel.de>
	<4301E0D5.5020308@jhsph.edu>
	<200508161711.50444.ahenningsen@email.uni-kiel.de>
Message-ID: <1124205995.8689.52.camel@gsimpson.geog.ucl.ac.uk>

On Tue, 2005-08-16 at 17:11 +0200, Arne Henningsen wrote:
> On Tuesday 16 August 2005 14:49, Roger D. Peng wrote:
> > Have you tried using 'promptData()' on the data frame and then
> > just using the resulting documentation file?
> 
> Thank you, Roger, for bringing 'promptData()' to my mind. This is really a 
> useful tool. However, in my special case my aim is to reduce the extent and 
> increase the comprehensibility of the documentation rather than to reduce my 
> effort to write the documentation. 
> 
> Any further hints are welcome!
> 
> Thanks,
> Arne

Would it not be expedient then to ignore the \format{} section and just
provide the information on the variables say in the \description{},
e.g.:

This example taken from package vegan describing 2 data.frames with 44
and 14 columns. Admittedly, none of the variables in the species dataset
are explicitly and individually described in this example, but it is
sufficient in this case I think.

\name{varespec}
\alias{varechem}
\alias{varespec}
\docType{data}
\title{Vegetation and environment in lichen pastures}
\usage{
       data(varechem)
       data(varespec)
}
\description{
  The \code{varespec} data frame has 24 rows and 44 columns.  Columns
  are estimated cover values of 44 species.  The variable names are
  formed from the scientific names, and are self explanatory for anybody
  familiar with the vegetation type.
The \code{varechem} data frame has 24 rows and 14 columns, giving the
soil characteristics of the very same sites as in the \code{varespec}
data frame. The chemical measurements have obvious names.
\code{Baresoil} gives the estimated cover of bare soil, \code{Humpdepth}
the thickness of the humus layer.

}
....

HTH

G

> 
> > -roger
> >
> > Arne Henningsen wrote:
> > > Hi,
> > >
> > > since nobody answered to my first message, I try to explain my problem
> > > more clearly and more general this time:
> > >
> > > I have a data set in my R package "micEcon", which has many variables
> > > (82). Therefore, I would like to avoid to describe all variables in the
> > > "\format" section of the documentation (.Rd file). However, doing this
> > > lets "R CMD check" complain about "data codoc mismatches" (details see
> > > below). Is there a way to avoid the description of all variables without
> > > getting a complaint from "R CMD check"?
> > >
> > > Thanks,
> > > Arne
> > >
> > >
> > > ----------  Forwarded Message  ----------
> > >
> > > Subject: Documenting data sets with many variables
> > > Date: Friday 05 August 2005 14:03
> > > From: Arne Henningsen <ahenningsen at email.uni-kiel.de>
> > > To: R-help at stat.math.ethz.ch
> > >
> > > Hi,
> > >
> > > I extended the data set "Blanciforti86" that is included in my R package
> > > "micEcon". For instance, I added consumer prices, annual consumption
> > > expenditures and expenditure shares of eleven aggregate commodity groups.
> > > The corresponding variables in the data frame are called "pAgg1",
> > > "pAgg2", ..., "pAgg11", "xAgg1", "xAgg2", ..., "xAgg11", "wAgg1",
> > > "wAgg2", ..., "wAgg11". To avoid to describe all 33 items in the
> > > "\format" section of the documentation (.Rd file) I wrote something like
> > >
> > > \format{
> > >    This data frame contains the following columns:
> > >    \describe{
> > >       [ . . . ]
> > >       \item{xAggX}{Expenditure on the aggregate commodity group X
> > >          (in Millions of US-Dollars).}
> > >       \item{pAggX}{Price index for the aggregate commodity group X
> > >          (1972 = 100).}
> > >       \item{wAggX}{Expenditure share of the aggregate commodity group X.}
> > >       [ . . . ]
> > >    }
> > > }
> > >
> > > and explained the 11 aggregate commodity groups only once in a different
> > > section (1=food, 2=clothing, ... ). However, "R CMD check" now complains
> > > about "data codoc mismatches", e.g.
> > >   Code: [...] pAgg1pAgg2 pAgg3  [...]
> > >   Docs: [...] pAggX [...]
> > >
> > > Is there a way to avoid the description of all 33 items without getting a
> > > complaint from "R CMD check"?
> > >
> > > Thanks,
> > > Arne
> > >
> > > -------------------------------------------------------
> 
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From ggrothendieck at gmail.com  Tue Aug 16 17:27:45 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 16 Aug 2005 11:27:45 -0400
Subject: [R] preprocessing data
In-Reply-To: <Pine.SGI.4.40.0508160833280.17622-100000@origin.chass.utoronto.ca>
References: <Pine.SGI.4.40.0508160833280.17622-100000@origin.chass.utoronto.ca>
Message-ID: <971536df050816082714829044@mail.gmail.com>

On 8/16/05, Jean Eid <jeaneid at chass.utoronto.ca> wrote:
> Dear all,
> 
> My question is concerning the line
> "This is adequate for small files, but for anything more complicated we
> recommend using the facilities   of a language like perl to pre-process
> the file."
> 
> in the import/export manual.
> 
> I have a large fixed-width file that I would like to preprocess in Perl or
> awk. The problem is that I do not know where to start. Does anyone have a
> simple example on how to turn a fixed-width file in any of these
> facilities into csv or tab delimited file. I guess I am looking for
> somewhat a perl for dummies or awk for dummies that does this. any
> pointers for website will be greatly appreciated
> 



Try to do it in R first.  I have found that I rarely need to go to 
an outside language to massage my data.

	# fixed with fields of 10 and 5
	Lines <- readLines("mydata.dat")
	data.frame( field1 = as.numeric(substring(1,10,Lines),
		field2 = as.numeric(substring(11,15,Lines) )

If you do find that you have speed or memory problems that
require that you go outside of R to preprocess your data
then the gawk version of awk has a FIELDWIDTHS variable that 
makes handling fixed fields very easy.  The gawk program below 
assumes two fields of widths 10 and 5, respectively, which
is set in the first line.   Then it repeatedly executes the 
second line for each input line forcing field splitting by a 
dummy manipulation (since field splitting is lazy) and then 
printing each line, the default being to print out the
entire line with a space between successive fields:

	BEGIN { FIELDWIDTHS = "10 5" }
	{ $1 = $1; print }  

In R, do the following assuming the above two lines are in 
split.awk:

	read.table(pipe("gawk -f split.awk mydata.dat"))

or else run gawk outside of R then read in the output file
created:

	gawk -f split.awk mydata.dat > mydata2.dat

For more information, google for 

	FIELDWIDTHS gawk 

for that portion of the manual on FIELDWIDTHS -- it includes
an example and, of course, the whole manual is there too.  The 
book by Kernighan et al is also good.

I have used both awk and perl and I think its unlikely you
would need perl given that you have R at your disposal for
the hard parts and awk is easier to learn, better designed 
and more focused on this sort of task.



From mike_saunders at umenfa.maine.edu  Tue Aug 16 18:03:01 2005
From: mike_saunders at umenfa.maine.edu (Mike Saunders)
Date: Tue, 16 Aug 2005 12:03:01 -0400
Subject: [R] Stacked Area chart
Message-ID: <000601c5a27b$faa21310$9ba76f82@CFRU0104>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050816/418fe89c/attachment.pl

From ramasamy at cancer.org.uk  Tue Aug 16 06:09:35 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 16 Aug 2005 05:09:35 +0100
Subject: [R] stepAIC invalid scope argument
In-Reply-To: <JCEIJNOHMNBPLMGFDHNDAENECAAA.wilks@dial.pipex.com>
References: <JCEIJNOHMNBPLMGFDHNDAENECAAA.wilks@dial.pipex.com>
Message-ID: <1124165375.29777.62.camel@ramasamy.stats>

Thank you. Your suggestion is equivalent is the same as my second
stepAIC command that failed in R-2.1.1.

See Prof. Ripley's reply where he pointed out that this was due to using
the name 'df' which clashes with built-in function with the same name
from stats package.

Regards, Adai


On Tue, 2005-08-16 at 15:52 +0100, John Wilkinson (pipex) wrote:
> Adai,
> 
> The following works.Perhaps you should define your 'upper' and 'lower'
> in the list as aov's, as you have done with your lo,hi and mid.
> 
> John
> 
> >  stepAIC( mid, scope=list(upper = mid , lower = lo) )
> Start:  AIC= -594.66 
>  y ~ x2 + x3 
> 
>        Df Sum of Sq     RSS     AIC
> - x2    1      0.11  548.56 -596.45
> - x3    1      0.95  549.40 -594.93
> <none>               548.45 -594.66
> 
> Step:  AIC= -596.45 
>  y ~ x3 
> 
> Adaikalavan Ramasamy wrote ---
> 
> I am trying to replicate the first example from stepAIC from the MASS
> package with my own dataset but am running into error. If someone can
> point where I have gone wrong, I would appreciate it very much. 
> 
> Here is an example :
> 
>  set.seed(1)
>  df   <- data.frame( x1=rnorm(1000), x2=rnorm(1000), x3=rnorm(1000) )
>  df$y <- 0.5*df$x1 + rnorm(1000, mean=8, sd=0.5)
>  # pairs(df); head(df)
> 
>  lo  <- aov( y ~ 1, data=df )
>  hi  <- aov( y ~ .^2, data=df )
>  mid <- aov( y ~ x2 + x3, data=df )
> 
> Running any of the following commands
> 
>  stepAIC( mid, scope=list(upper = ~x1 + x2 + x3 , lower = ~1) )
>  stepAIC( mid, scope=list(upper = hi , lower = lo) )
>  addterm( mid, ~ x1 + x2 + x3 )
>  addterm( lo, hi )
> 
> gives the same error message : 
>   Error in eval(expr, envir, enclos) : invalid second argumen
> 
>



From riap2 at cam.ac.uk  Tue Aug 16 18:11:05 2005
From: riap2 at cam.ac.uk (riap2@cam.ac.uk)
Date: Tue, 16 Aug 2005 17:11:05 +0100
Subject: [R] kernel smoothing of weighted data
Message-ID: <34139125.1124212265@fieldfare>

Hi,

I want to use kde() or a similar function for kernel smoothing but I want 
to specify the weight of each of my data points.  I do not want to specify 
the bandwidth on a point by point basis.

This seems such a simple and obvious thing to want to do I am suspicious 
that there is not an obvious way to do it.  The only discussion I have 
found is about negative weights(!) and says nothing about implementation. 
Can anyone suggest a package I have missed or suggest the best starting 
point for writing my own solution.

The reason for wanting this is that I have a number of samples each of 
~1000 data points from the same distribution but the samples are of 
slightly differing statistical weight and eventually each point in each 
sample may have its own statistical weight.

I have searched the list but I am not subscribed to it so please make me an 
addressee of any reply.

Thanks

Robert Patterson



From Achim.Zeileis at wu-wien.ac.at  Tue Aug 16 18:20:54 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Tue, 16 Aug 2005 18:20:54 +0200
Subject: [R] Stacked Area chart
In-Reply-To: <000601c5a27b$faa21310$9ba76f82@CFRU0104>
References: <000601c5a27b$faa21310$9ba76f82@CFRU0104>
Message-ID: <20050816182054.1d716173.Achim.Zeileis@wu-wien.ac.at>

On Tue, 16 Aug 2005 12:03:01 -0400 Mike Saunders wrote:

> I wish to do a stacked area chart to show how relative proportions of
> species within a stand have changed over time.

If you don't want to show the marginal distribution over time, then you
can use barplot() on the table of relative frequencies (e.g., obtained
by prop.table()).
If you want to show the marginal distribution, you can use mosaicplot().
The functions doubledecker() and mosaic() in package vcd might also be
helpful.
Z

> I know this is simple, but can someone point me to the right function
> (if it exists).  I have not had any luck finding it in the R-help, but
> maybe I am searching using the wrong keywords.
> 
> Thanks,
> Mike
> 
> 
> Mike Saunders
> Research Assistant
> Forest Ecosystem Research Program
> Department of Forest Ecosystem Sciences
> University of Maine
> Orono, ME  04469
> 207-581-2763 (O)
> 207-581-4257 (F)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From valderama at gmail.com  Tue Aug 16 18:43:54 2005
From: valderama at gmail.com (Laurent Valdes)
Date: Tue, 16 Aug 2005 18:43:54 +0200
Subject: [R] Dots in models formulae
Message-ID: <165FE2B0-9BF3-4B74-8DB8-1BD36790300F@gmail.com>

I have seen, several times, dots (like this: "y ~." ) in formula  
descriptions, noticeably in R help.

I am unable to see what it does correspond to.

Any ideas ?

--
--~~ Toulouse, Grenoble, Auch, Arcachon, B??ziers, Paris,
Saragosse, L??vignac Sur Save, habitats naturel du Valdo. ~~--
< http://www.le-valdo.com>



From pigood at verizon.net  Tue Aug 16 18:51:12 2005
From: pigood at verizon.net (Phillip Good)
Date: Tue, 16 Aug 2005 09:51:12 -0700
Subject: [R] Looking for a collaborator
In-Reply-To: <40e66e0b050702153866f36d71@mail.gmail.com>
Message-ID: <GHEKKACNLEADPKCNEEDFCEBCCFAA.pigood@verizon.net>

I'm looking for a collaborator with strong R debugging skills to work on a
project involving symmetric permutations.  Should have interest in
permutation/randomization methods.  Please reply directly to me and not to
the list.

Phillip Good
for background, see http://tbf.coe.wayne.edu/jmasm/vol1_no2.pdf pages
243-47, or
http://mysite.verizon.net/res7sf1o/subgroups.htm



From LI at nsabp.pitt.edu  Tue Aug 16 18:51:04 2005
From: LI at nsabp.pitt.edu (Li, Jia)
Date: Tue, 16 Aug 2005 12:51:04 -0400
Subject: [R] A question about MIX package
Message-ID: <D70CBC108DFBD446862A6E1F6F0B4A152AC99F@nsabpmail>

Hello all,
 
When I used commands "ecm.mix and dabipf.mix" to do a simulation (sample size is small 100), I got an error : Steps of ECM, missing value where True/False needed.
 
I've checked the menu, and the option "prior" of ecm.mix said that if structural zeros appear in the table, hyperparameters for those cells should be set to NA. However, it didn't say how to do that in the command. I am wondering if someone knows how to fix this.
 
I appreciate your help,
 
Jia



From ripley at stats.ox.ac.uk  Tue Aug 16 19:13:43 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Aug 2005 18:13:43 +0100 (BST)
Subject: [R] kernel smoothing of weighted data
In-Reply-To: <34139125.1124212265@fieldfare>
References: <34139125.1124212265@fieldfare>
Message-ID: <Pine.LNX.4.61.0508161809170.3491@gannet.stats>

density() in the R-devel version of R allows weights.

locfit() in the package of the same name also appears to be documented to.

On Tue, 16 Aug 2005 riap2 at cam.ac.uk wrote:

> I want to use kde() or a similar function for kernel smoothing but I want
> to specify the weight of each of my data points.  I do not want to specify
> the bandwidth on a point by point basis.

The only kde() I found is from the recent package ks, and is for 
multivariate data -- if you want that, you did not say so and I've not 
looked for an answer there.

> This seems such a simple and obvious thing to want to do I am suspicious
> that there is not an obvious way to do it.  The only discussion I have
> found is about negative weights(!) and says nothing about implementation.
> Can anyone suggest a package I have missed or suggest the best starting
> point for writing my own solution.
>
> The reason for wanting this is that I have a number of samples each of
> ~1000 data points from the same distribution but the samples are of
> slightly differing statistical weight and eventually each point in each
> sample may have its own statistical weight.
>
> I have searched the list but I am not subscribed to it so please make me an
> addressee of any reply.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Tue Aug 16 19:16:45 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 16 Aug 2005 19:16:45 +0200
Subject: [R] Dots in models formulae
In-Reply-To: <165FE2B0-9BF3-4B74-8DB8-1BD36790300F@gmail.com>
References: <165FE2B0-9BF3-4B74-8DB8-1BD36790300F@gmail.com>
Message-ID: <43021F7D.9030300@statistik.uni-dortmund.de>

Laurent Valdes wrote:

> I have seen, several times, dots (like this: "y ~." ) in formula  
> descriptions, noticeably in R help.
> 
> I am unable to see what it does correspond to.
> 
> Any ideas ?

All other variables (except y) from the given data.frame...

Uwe Ligges



From gavin.simpson at ucl.ac.uk  Tue Aug 16 19:17:51 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 16 Aug 2005 18:17:51 +0100
Subject: [R] Dots in models formulae
In-Reply-To: <165FE2B0-9BF3-4B74-8DB8-1BD36790300F@gmail.com>
References: <165FE2B0-9BF3-4B74-8DB8-1BD36790300F@gmail.com>
Message-ID: <1124212672.8689.96.camel@gsimpson.geog.ucl.ac.uk>

On Tue, 2005-08-16 at 18:43 +0200, Laurent Valdes wrote:
> I have seen, several times, dots (like this: "y ~." ) in formula  
> descriptions, noticeably in R help.
> 
> I am unable to see what it does correspond to.
> 
> Any ideas ?

The "." is a short cut to mean all variables specified in the data
argument. E.g.:

> dat <- data.frame(y = 1:10, x = 1:10, z = 1:10)
> model.frame(y ~ ., data = dat)
    y  x  z
1   1  1  1
2   2  2  2
3   3  3  3
4   4  4  4
5   5  5  5
6   6  6  6
7   7  7  7
8   8  8  8
9   9  9  9
10 10 10 10

If the response is also found on the rhs (right-hand-side) of the
formula (i.e via using ".") then it is silently droppped from the rhs.

So this is equivalent to the above formula

> model.frame(y ~ x + y + z, data = dat)
    y  x  z
1   1  1  1
2   2  2  2
3   3  3  3
4   4  4  4
5   5  5  5
6   6  6  6
7   7  7  7
8   8  8  8
9   9  9  9
10 10 10 10

Here y isn't the response but is included as it is in ".", i.e. dat.
> a <- 1:10
> model.frame(a ~ ., data = dat)
    a  y  x  z
1   1  1  1  1
2   2  2  2  2
3   3  3  3  3
4   4  4  4  4
5   5  5  5  5
6   6  6  6  6
7   7  7  7  7
8   8  8  8  8
9   9  9  9  9
10 10 10 10 10

If we don't specify data and we don't have an object named "." (which
may be impossible - I don't know) you get an error:

> model.frame(a ~ .)
Error in eval(expr, envir, enclos) : Object "." not found

I couldn't find "." documented for use in forumla (only for update(),
where it means something slightly different) but I remember seeing this
somewhere.

HTH

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From stranda at cofc.edu  Tue Aug 16 19:18:23 2005
From: stranda at cofc.edu (Allan Strand)
Date: Tue, 16 Aug 2005 13:18:23 -0400
Subject: [R] recategorizing a  vector into discrete states
Message-ID: <aaabc46104035b2b0bc0fd9ee885c100@cofc.edu>

Hi All,

I'm trying to take a numerical vector  and  produce a new vector of the 
same length where each element in the first is placed into a category 
given by a 'breaks-like' vector. The values in the result should equal 
the lower bounds of each category as defined in the breaks vector.

  I suspect that a vectorized solution  is pretty simple, but I can't 
seem to figure it out today.  Here is an example of my problem:

Vector 'a' is the original vector.  Vector 'b' gives the lower bounds 
of the categories.  Vector 'c' is the result I am seeking.

a <- c(0.9, 11, 1.2, 2.4, 4.0, 5.0, 7.3, 8.1, 3.3, 4.5)
b <- c(0, 2, 4, 6, 8)

c <- c(0, 8, 0, 2, 4, 4, 6, 8, 2, 4)

Any suggestions would be greatly appreciated.

cheers,
Allan Strand



From sundar.dorai-raj at pdf.com  Tue Aug 16 19:24:37 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 16 Aug 2005 12:24:37 -0500
Subject: [R] Dots in models formulae
In-Reply-To: <43021F7D.9030300@statistik.uni-dortmund.de>
References: <165FE2B0-9BF3-4B74-8DB8-1BD36790300F@gmail.com>
	<43021F7D.9030300@statistik.uni-dortmund.de>
Message-ID: <43022155.5090901@pdf.com>



Uwe Ligges wrote:
> Laurent Valdes wrote:
> 
> 
>>I have seen, several times, dots (like this: "y ~." ) in formula  
>>descriptions, noticeably in R help.
>>
>>I am unable to see what it does correspond to.
>>
>>Any ideas ?
> 
> 
> All other variables (except y) from the given data.frame...
> 
> Uwe Ligges
> 

Hi, Uwe,

Doesn't this depend on the context? For example,

z <- data.frame(y = rnorm(10), x = rnorm(10))
fit <- lm(y ~ ., z)
update(fit, y ~ . + I(x^2))

The original poster did not say where he saw this formula. However, I 
think the reference in ?formula has the most authorative explanation.

Thanks,

--sundar



From elvis at xlsolutions-corp.com  Tue Aug 16 19:39:30 2005
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Tue, 16 Aug 2005 10:39:30 -0700
Subject: [R] Course***R/S-plus Programming**** New York, Washington DC,
	Seattle, San Francisco / September 2005
Message-ID: <20050816103930.a108dc04937c07ba67766dad37185406.5fb5f378e0.wbe@email.email.secureserver.net>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud to
announce  2-day "R/S-plus Fundamentals and Programming
Techniques" at 4 locations nationwide.
www.xlsolutions-corp.com/Rfund.htm

****Seattle, WA ------------------------- September  1st-2nd, 2005
****Washington, DC ---------------------- September 8th - 9th, 2005
****San Francisco ------------------------- September 8th - 9th, 2005

**** New York City ------------------------ September 22nd-23rd, 2005

Reserve your seat now at the early bird rates! Ends August 30th.
Payment due AFTER the class

Course Description:

This two-day beginner to intermediate R/S-plus course focuses on a
broad spectrum of topics, from reading raw data to a comparison of R
and S. We will learn the essentials of data manipulation, graphical
visualization and R/S-plus programming. We will explore statistical
data analysis tools,including graphics with data sets. How to enhance
your plots, build your own packages (librairies) and connect via
ODBC,etc.
We will perform some statistical modeling and fit linear regression
models. Participants are encouraged to bring data for interactive
sessions

With the following outline:

- An Overview of R and S
- Data Manipulation and Graphics
- Using Lattice Graphics
- A Comparison of R and S-Plus
- How can R Complement SAS?
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling
- Project Management
- Techniques for Effective use of R and S
- Enhancing Plots
- Using High-level Plotting Functions
- Building and Distributing Packages (libraries)
- Connecting; ODBC, Rweb, Orca via sockets and via Rjava

Interested in R/Splus Advanced course? email us.

Email us for group discounts.
Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578
Visit us: www.xlsolutions-corp.com/training.htm
Please let us know if you and your colleagues are interested in this
classto take advantage of group discount. Register now to secure your
seat!

Interested in R/Splus Advanced course? email us.


Cheers,
Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com
elvis at xlsolutions-corp.com



From ripley at stats.ox.ac.uk  Tue Aug 16 19:48:27 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Aug 2005 18:48:27 +0100 (BST)
Subject: [R] Dots in models formulae
In-Reply-To: <43022155.5090901@pdf.com>
References: <165FE2B0-9BF3-4B74-8DB8-1BD36790300F@gmail.com>
	<43021F7D.9030300@statistik.uni-dortmund.de> <43022155.5090901@pdf.com>
Message-ID: <Pine.LNX.4.61.0508161838320.3974@gannet.stats>

On Tue, 16 Aug 2005, Sundar Dorai-Raj wrote:

> Uwe Ligges wrote:
>> Laurent Valdes wrote:
>>
>>
>>> I have seen, several times, dots (like this: "y ~." ) in formula
>>> descriptions, noticeably in R help.
>>>
>>> I am unable to see what it does correspond to.
>>>
>>> Any ideas ?
>>
>> All other variables (except y) from the given data.frame...
>>
>> Uwe Ligges
>>
>
> Hi, Uwe,
>
> Doesn't this depend on the context? For example,
>
> z <- data.frame(y = rnorm(10), x = rnorm(10))
> fit <- lm(y ~ ., z)
> update(fit, y ~ . + I(x^2))
>
> The original poster did not say where he saw this formula. However, I
> think the reference in ?formula has the most authorative explanation.

(It does not cover this, as it is part of the interpretation of a 
formula.)

Yes, it must depend on context, as an R function can do anything it likes 
with a formula (including making y ~ x mean the regression of x on y).

If terms.formula() is used, y ~ . means what Uwe said, _if_ there is a 
'data' argument.  However, if not it has its literal meaning (a variable 
named '.'), at least until 2.2.0.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gavin.simpson at ucl.ac.uk  Tue Aug 16 19:49:56 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 16 Aug 2005 18:49:56 +0100
Subject: [R] Dots in models formulae
In-Reply-To: <43022155.5090901@pdf.com>
References: <165FE2B0-9BF3-4B74-8DB8-1BD36790300F@gmail.com>
	<43021F7D.9030300@statistik.uni-dortmund.de> <43022155.5090901@pdf.com>
Message-ID: <1124214596.8689.113.camel@gsimpson.geog.ucl.ac.uk>

On Tue, 2005-08-16 at 12:24 -0500, Sundar Dorai-Raj wrote:
> 
> Uwe Ligges wrote:
> > Laurent Valdes wrote:
> > 
> > 
> >>I have seen, several times, dots (like this: "y ~." ) in formula  
> >>descriptions, noticeably in R help.
> >>
> >>I am unable to see what it does correspond to.
> >>
> >>Any ideas ?
> > 
> > 
> > All other variables (except y) from the given data.frame...
> > 
> > Uwe Ligges
> > 
> 
> Hi, Uwe,
> 
> Doesn't this depend on the context? For example,
> 
> z <- data.frame(y = rnorm(10), x = rnorm(10))
> fit <- lm(y ~ ., z)
> update(fit, y ~ . + I(x^2))
> 
> The original poster did not say where he saw this formula. However, I 
> think the reference in ?formula has the most authorative explanation.

Not for "." in a formula in ?formula, at least in 

platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status   Patched
major    2
minor    1.1
year     2005
month    08
day      15
language R

I still can't find this documented for a formula (I found
update.formula, but the meaning of "." is different there, slightly, as
you indicate) - but it must be as I didn't imagine seeing it - or maybe
I did...

G

> Thanks,
> 
> --sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From gerifalte28 at hotmail.com  Tue Aug 16 19:51:52 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Tue, 16 Aug 2005 17:51:52 +0000
Subject: [R] kernel smoothing of weighted data
In-Reply-To: <Pine.LNX.4.61.0508161809170.3491@gannet.stats>
Message-ID: <BAY103-F2171BA20752A934E08CD1CA6B00@phx.gbl>

You can also specify weights in sm.density() in the package sm.

Cheers

Francisco


>From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>To: riap2 at cam.ac.uk
>CC: r-help at stat.math.ethz.ch
>Subject: Re: [R] kernel smoothing of weighted data
>Date: Tue, 16 Aug 2005 18:13:43 +0100 (BST)
>
>density() in the R-devel version of R allows weights.
>
>locfit() in the package of the same name also appears to be documented to.
>
>On Tue, 16 Aug 2005 riap2 at cam.ac.uk wrote:
>
> > I want to use kde() or a similar function for kernel smoothing but I 
>want
> > to specify the weight of each of my data points.  I do not want to 
>specify
> > the bandwidth on a point by point basis.
>
>The only kde() I found is from the recent package ks, and is for
>multivariate data -- if you want that, you did not say so and I've not
>looked for an answer there.
>
> > This seems such a simple and obvious thing to want to do I am suspicious
> > that there is not an obvious way to do it.  The only discussion I have
> > found is about negative weights(!) and says nothing about 
>implementation.
> > Can anyone suggest a package I have missed or suggest the best starting
> > point for writing my own solution.
> >
> > The reason for wanting this is that I have a number of samples each of
> > ~1000 data points from the same distribution but the samples are of
> > slightly differing statistical weight and eventually each point in each
> > sample may have its own statistical weight.
> >
> > I have searched the list but I am not subscribed to it so please make me 
>an
> > addressee of any reply.
>
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From Achim.Zeileis at wu-wien.ac.at  Tue Aug 16 19:48:14 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Tue, 16 Aug 2005 19:48:14 +0200
Subject: [R] recategorizing a  vector into discrete states
In-Reply-To: <aaabc46104035b2b0bc0fd9ee885c100@cofc.edu>
References: <aaabc46104035b2b0bc0fd9ee885c100@cofc.edu>
Message-ID: <20050816194814.12984ad6.Achim.Zeileis@wu-wien.ac.at>

On Tue, 16 Aug 2005 13:18:23 -0400 Allan Strand wrote:

> Hi All,
> 
> I'm trying to take a numerical vector  and  produce a new vector of
> the same length where each element in the first is placed into a
> category given by a 'breaks-like' vector. The values in the result
> should equal the lower bounds of each category as defined in the
> breaks vector.
> 
>   I suspect that a vectorized solution  is pretty simple, but I can't 
> seem to figure it out today.  Here is an example of my problem:
> 
> Vector 'a' is the original vector.  Vector 'b' gives the lower bounds 
> of the categories.  Vector 'c' is the result I am seeking.
> 
> a <- c(0.9, 11, 1.2, 2.4, 4.0, 5.0, 7.3, 8.1, 3.3, 4.5)
> b <- c(0, 2, 4, 6, 8)
> 
> c <- c(0, 8, 0, 2, 4, 4, 6, 8, 2, 4)
> 
> Any suggestions would be greatly appreciated.

cut(a, c(b, Inf), labels = b)

which returns a factor.
Z 

> cheers,
> Allan Strand
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From gavin.simpson at ucl.ac.uk  Tue Aug 16 20:04:36 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 16 Aug 2005 19:04:36 +0100
Subject: [R] as.character and a formula
Message-ID: <1124215476.8689.120.camel@gsimpson.geog.ucl.ac.uk>

Dear list,

given this formula: 

> fmla <- formula(y1 ~ spp1 + spp2 + spp3 + spp5)
> fmla[[3]]
spp1 + spp2 + spp3 + spp5

is this the intended behaviour of as.character:

> as.character(fmla[[3]])
[1] "+"                  "spp1 + spp2 + spp3" "spp5"

? Where does the extra "+" come from?

> as.character(fmla)
[1] "~"                         "y1"                       
[3] "spp1 + spp2 + spp3 + spp5"

Thanks in advance,

Gav
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From jeaneid at chass.utoronto.ca  Tue Aug 16 20:07:24 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Tue, 16 Aug 2005 14:07:24 -0400
Subject: [R] preprocessing data
In-Reply-To: <971536df050816082714829044@mail.gmail.com>
Message-ID: <Pine.SGI.4.40.0508161407140.46616-100000@origin.chass.utoronto.ca>

Thank you Gabor,

Jean

On Tue, 16 Aug 2005, Gabor Grothendieck wrote:

> On 8/16/05, Jean Eid <jeaneid at chass.utoronto.ca> wrote:
> > Dear all,
> >
> > My question is concerning the line
> > "This is adequate for small files, but for anything more complicated we
> > recommend using the facilities   of a language like perl to pre-process
> > the file."
> >
> > in the import/export manual.
> >
> > I have a large fixed-width file that I would like to preprocess in Perl or
> > awk. The problem is that I do not know where to start. Does anyone have a
> > simple example on how to turn a fixed-width file in any of these
> > facilities into csv or tab delimited file. I guess I am looking for
> > somewhat a perl for dummies or awk for dummies that does this. any
> > pointers for website will be greatly appreciated
> >
>
>
>
> Try to do it in R first.  I have found that I rarely need to go to
> an outside language to massage my data.
>
> 	# fixed with fields of 10 and 5
> 	Lines <- readLines("mydata.dat")
> 	data.frame( field1 = as.numeric(substring(1,10,Lines),
> 		field2 = as.numeric(substring(11,15,Lines) )
>
> If you do find that you have speed or memory problems that
> require that you go outside of R to preprocess your data
> then the gawk version of awk has a FIELDWIDTHS variable that
> makes handling fixed fields very easy.  The gawk program below
> assumes two fields of widths 10 and 5, respectively, which
> is set in the first line.   Then it repeatedly executes the
> second line for each input line forcing field splitting by a
> dummy manipulation (since field splitting is lazy) and then
> printing each line, the default being to print out the
> entire line with a space between successive fields:
>
> 	BEGIN { FIELDWIDTHS = "10 5" }
> 	{ $1 = $1; print }
>
> In R, do the following assuming the above two lines are in
> split.awk:
>
> 	read.table(pipe("gawk -f split.awk mydata.dat"))
>
> or else run gawk outside of R then read in the output file
> created:
>
> 	gawk -f split.awk mydata.dat > mydata2.dat
>
> For more information, google for
>
> 	FIELDWIDTHS gawk
>
> for that portion of the manual on FIELDWIDTHS -- it includes
> an example and, of course, the whole manual is there too.  The
> book by Kernighan et al is also good.
>
> I have used both awk and perl and I think its unlikely you
> would need perl given that you have R at your disposal for
> the hard parts and awk is easier to learn, better designed
> and more focused on this sort of task.
>



From mschwartz at mn.rr.com  Tue Aug 16 20:08:24 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 16 Aug 2005 13:08:24 -0500
Subject: [R] recategorizing a  vector into discrete states
In-Reply-To: <aaabc46104035b2b0bc0fd9ee885c100@cofc.edu>
References: <aaabc46104035b2b0bc0fd9ee885c100@cofc.edu>
Message-ID: <1124215704.7840.4.camel@localhost.localdomain>

On Tue, 2005-08-16 at 13:18 -0400, Allan Strand wrote:
> Hi All,
> 
> I'm trying to take a numerical vector  and  produce a new vector of the 
> same length where each element in the first is placed into a category 
> given by a 'breaks-like' vector. The values in the result should equal 
> the lower bounds of each category as defined in the breaks vector.
> 
>   I suspect that a vectorized solution  is pretty simple, but I can't 
> seem to figure it out today.  Here is an example of my problem:
> 
> Vector 'a' is the original vector.  Vector 'b' gives the lower bounds 
> of the categories.  Vector 'c' is the result I am seeking.
> 
> a <- c(0.9, 11, 1.2, 2.4, 4.0, 5.0, 7.3, 8.1, 3.3, 4.5)
> b <- c(0, 2, 4, 6, 8)
> 
> c <- c(0, 8, 0, 2, 4, 4, 6, 8, 2, 4)
> 
> Any suggestions would be greatly appreciated.
> 
> cheers,
> Allan Strand

See ?cut

> a <- c(0.9, 11, 1.2, 2.4, 4.0, 5.0, 7.3, 8.1, 3.3, 4.5)
> b <- c(0, 2, 4, 6, 8)

> cut(a, c(b, Inf), labels = b, right = FALSE)
 [1] 0 8 0 2 4 4 6 8 2 4
Levels: 0 2 4 6 8

Note that cut() returns a factor.

HTH,

Marc Schwartz



From ligges at statistik.uni-dortmund.de  Tue Aug 16 20:22:08 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 16 Aug 2005 20:22:08 +0200
Subject: [R] as.character and a formula
In-Reply-To: <1124215476.8689.120.camel@gsimpson.geog.ucl.ac.uk>
References: <1124215476.8689.120.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <43022ED0.9070403@statistik.uni-dortmund.de>

Gavin Simpson wrote:

> Dear list,
> 
> given this formula: 
> 
> 
>>fmla <- formula(y1 ~ spp1 + spp2 + spp3 + spp5)
>>fmla[[3]]
> 
> spp1 + spp2 + spp3 + spp5
> 
> is this the intended behaviour of as.character:
> 
> 
>>as.character(fmla[[3]])
> 
> [1] "+"                  "spp1 + spp2 + spp3" "spp5"
> 
> ? Where does the extra "+" come from?

Which *extra* "+"?

This expression is the same as

"+"(spp1 + spp2 + spp3, spp5)

hence "+" with arguments "spp1 + spp2 + spp3" and "spp5"

Same below.

Uwe Ligges


> 
>>as.character(fmla)
> 
> [1] "~"                         "y1"                       
> [3] "spp1 + spp2 + spp3 + spp5"
> 
> Thanks in advance,
> 
> Gav



From awitney at sgul.ac.uk  Tue Aug 16 20:38:48 2005
From: awitney at sgul.ac.uk (Adam Witney)
Date: Tue, 16 Aug 2005 19:38:48 +0100
Subject: [R] Compile failure on OSX
Message-ID: <BF27F148.4ACB6%awitney@sgul.ac.uk>

Hi,

I am trying to compile R-2.1.1 on MacOSX 10.3.9, but the make is failing (I
am building it without all the aqua stuff):

./configure --enable-R-shlib --with-lapac
make

.... Snip .....

gcc -dynamiclib -L/sw/lib -L/usr/local/lib -install_name
/Library/Frameworks/R.framework/Versions/2.1.1/Resources/lib/libRlapack.dyli
b -o libRlapack.dylib dlamc.lo dlapack0.lo dlapack1.lo dlapack2.lo
dlapack3.lo cmplx.lo  cmplxblas.lo
-L/sw/lib/gcc/powerpc-apple-darwin7.9.0/3.4 -lg2c -lSystem
ld: Undefined symbols:
_dasum_
_daxpy_
_dcopy_
_ddot_
_dgemm_
_dgemv_
_dger_
_dnrm2_
_drot_
_dscal_
_dswap_
_dsymv_
_dsyrk_
_dtbsv_
_dtpsv_
_dtrmm_
_dtrmv_
_dtrsv_
_idamax_
_xerbla_
_dtpmv_
_dtrsm_
_dgbmv_
_dsbmv_
_dspmv_
_dspr2_
_dspr_
_dsymm_
_dsyr2_
_dsyr2k_
_dsyr_
_dtbmv_
_zgemm_
/usr/bin/libtool: internal link edit command failed
make[4]: *** [libRlapack.dylib] Error 1
make[3]: *** [R] Error 2
make[2]: *** [R] Error 1
make[1]: *** [R] Error 1
make: *** [R] Error 1

Thanks for any help

Adam



-- 
This message has been scanned for viruses and
dangerous content by MailScanner, and is
believed to be clean.



From ripley at stats.ox.ac.uk  Tue Aug 16 21:05:25 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Aug 2005 20:05:25 +0100 (BST)
Subject: [R] Dots in models formulae
In-Reply-To: <1124214596.8689.113.camel@gsimpson.geog.ucl.ac.uk>
References: <165FE2B0-9BF3-4B74-8DB8-1BD36790300F@gmail.com>
	<43021F7D.9030300@statistik.uni-dortmund.de> <43022155.5090901@pdf.com>
	<1124214596.8689.113.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <Pine.LNX.4.61.0508162002020.4224@gannet.stats>

On Tue, 16 Aug 2005, Gavin Simpson wrote:

> I still can't find this documented for a formula (I found
> update.formula, but the meaning of "." is different there, slightly, as
> you indicate) - but it must be as I didn't imagine seeing it - or maybe
> I did...

It _is_ in `An Introduction to R', both for lm() and update.formula(). 
Since this meaning does depend on using terms.formula(), it is on that 
functions' help page.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Tue Aug 16 21:11:06 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Aug 2005 20:11:06 +0100 (BST)
Subject: [R] Compile failure on OSX
In-Reply-To: <BF27F148.4ACB6%awitney@sgul.ac.uk>
References: <BF27F148.4ACB6%awitney@sgul.ac.uk>
Message-ID: <Pine.LNX.4.61.0508162006140.4224@gannet.stats>

On Tue, 16 Aug 2005, Adam Witney wrote:

> I am trying to compile R-2.1.1 on MacOSX 10.3.9, but the make is failing (I
> am building it without all the aqua stuff):
>
> ./configure --enable-R-shlib --with-lapac

That's incorrect.  Please follow the advice in the R-admin.html file which 
the INSTALL file does ask you to read if you have any problems.  It says 
for your OS:

   ./configure --with-blas='-framework vecLib' --with-lapack --with-aqua
   make

   The last option @option{--with-aqua} is needed only if you want a
   Console GUI. The first two options are strongly recommended.
                                          ^^^^^^^^^^^^^^^^^^^^

It also warns you against using --with-lapack if you don't know what you 
are doing.

> make
>
> .... Snip .....
>
> gcc -dynamiclib -L/sw/lib -L/usr/local/lib -install_name
> /Library/Frameworks/R.framework/Versions/2.1.1/Resources/lib/libRlapack.dyli
> b -o libRlapack.dylib dlamc.lo dlapack0.lo dlapack1.lo dlapack2.lo
> dlapack3.lo cmplx.lo  cmplxblas.lo
> -L/sw/lib/gcc/powerpc-apple-darwin7.9.0/3.4 -lg2c -lSystem
> ld: Undefined symbols:
> _dasum_

[...]

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rab45+ at pitt.edu  Tue Aug 16 21:17:56 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Tue, 16 Aug 2005 15:17:56 -0400 (EDT)
Subject: [R] Mixed Effects Model Power Calculations
Message-ID: <46344.128.147.28.3.1124219876.squirrel@webmail.pitt.edu>

Is there an R package available that would facilitate doing a power/sample
size analysis for linear mixed effects models?

I have seen the Java applets made available by Russell Length which would
seem to be able to handle most any lme, but there is little documentation
and it's not clear how the models need to be formulated.

Rick B.



From ripley at stats.ox.ac.uk  Tue Aug 16 21:18:04 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Aug 2005 20:18:04 +0100 (BST)
Subject: [R] as.character and a formula
In-Reply-To: <43022ED0.9070403@statistik.uni-dortmund.de>
References: <1124215476.8689.120.camel@gsimpson.geog.ucl.ac.uk>
	<43022ED0.9070403@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.61.0508162011560.4224@gannet.stats>

I guess the problem is that Gavin is unaware of what [[]] does for a call.
It is still a call and so you want to use deparse() and not 
as.character():

> deparse(fmla[[3]])
[1] "spp1 + spp2 + spp3 + spp5"

Watch out for the line length limit on deparse() if you do this in 
programs.

On Tue, 16 Aug 2005, Uwe Ligges wrote:

> Gavin Simpson wrote:
>
>> Dear list,
>>
>> given this formula:
>>
>>
>>> fmla <- formula(y1 ~ spp1 + spp2 + spp3 + spp5)
>>> fmla[[3]]
>>
>> spp1 + spp2 + spp3 + spp5
>>
>> is this the intended behaviour of as.character:
>>
>>
>>> as.character(fmla[[3]])
>>
>> [1] "+"                  "spp1 + spp2 + spp3" "spp5"
>>
>> ? Where does the extra "+" come from?
>
> Which *extra* "+"?
>
> This expression is the same as
>
> "+"(spp1 + spp2 + spp3, spp5)
>
> hence "+" with arguments "spp1 + spp2 + spp3" and "spp5"
>
> Same below.
>
> Uwe Ligges
>
>
>>
>>> as.character(fmla)
>>
>> [1] "~"                         "y1"
>> [3] "spp1 + spp2 + spp3 + spp5"
>>
>> Thanks in advance,
>>
>> Gav
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From luke at stat.uiowa.edu  Tue Aug 16 21:35:48 2005
From: luke at stat.uiowa.edu (Luke Tierney)
Date: Tue, 16 Aug 2005 14:35:48 -0500 (CDT)
Subject: [R] Broken tkrplot on Mac OS X
In-Reply-To: <BF2292AE.3F5E%mblanche@uclink.berkeley.edu>
References: <BF2292AE.3F5E%mblanche@uclink.berkeley.edu>
Message-ID: <Pine.LNX.4.63.0508161431500.20881@nokomis.stat.uiowa.edu>

Because of the way Tcl works the C code needs to be linked into a
dylib rather than the other thing.  I keep meaning to either put in a
README.MacOSX or figure out a way to get configure to deal with this
but never get around to it.  Here is the strategy that works for me
(from notes and memory--I may have got a detail wrong):

      Download, untar, and run R CMD INSTALL

      cd to the src directory and repeat the final link command with
      -bundle replaced by -dynamiclib

      Then move the new trkplot.so by hand to the lib directory of the
      installed package

If you are offended by a .so extension on a dylib you can change the
extension and the R code that load it.

If you figure out a better way to do this please let me know,

Best,

luke

On Thu, 12 May 2005, stefano iacus wrote:

> It seems it doesn't work for me either
>
> http://159.149.213.137/R/bin/2.1/check/checkSummaryOSX.html
>
> Will forward to Luke, hopefully he could help
> stefano
>
> On 12/mag/05, at 23:13, Simon Urbanek wrote:
>
>> Hi Robert,
>> 
>> On May 12, 2005, at 4:48 PM, Robert Gentleman wrote:
>>
>>>   I am getting something a bit weird when I do an install.packages on 
>>> tkrplot,
>>> > library(tkrplot)
>>> Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class = 
>>> "tclObj") :
>>>         [tcl] dyld: /Users/rgentlem/R/R-devel/bin/exec/R malformed 
>>> library: /Users/rgentlem/R/R-devel/library/tkrplot/libs/tkrplot.so (not a 
>>> Mach-O library file, bad filetype value)
>>> .
>>> Error in library(tkrplot) : .First.lib failed for 'tkrplot'
>>> >
>>> 
>>> can either of you confirm - or point me towards what is wrong with my 
>>> installation -
>> 
>> It's rather a problem with tkrplot than with your installation - it 
>> compiles tkrplot.so as if it was a library to be loaded into R (via 
>> dyn.load - more precisely it creates a bundle for R), but then tries to 
>> load it as dylib using Tcl/Tk. I don't know the exact system how to load 
>> plug-ins into Tcl/Tk, but I suspect that the tkrplot code needs to be split 
>> into R part bundle and dylib that is loaded into Tcl/Tk. Chances are that 
>> the bundle is actually not needed at all, because I don't see any .C/.Call 
>> in the tkrplot R code. I have to run now, but I can have a closer look 
>> later this week if it's of interest.
>> 
>> Cheers,
>> Simon
>> 
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
     Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
On Fri, 12 Aug 2005, Marco Blanchette wrote:

> Dear all--
>
> I have been trying to get the tkrplot package to work in order to use the
> bioconductor package genArise.
>
> I am trying to build it on a Mac running OS 10.4.1 with R 2.1.1. Following a
> stanadard install from R here the error I get when I try to load tkrplot
>
>> library(tkrplot)
> Loading required package: tcltk
> Loading Tcl/Tk interface ... done
> Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class =
> "tclObj") :
>         [tcl] no suitable image found.  Did find:
>
> /Library/Frameworks/R.framework/Versions/2.1.1/Resources/library/tkrplot/li
> b
> s/tkrplot.so: not a dylib.
> Error in library(tkrplot) : .First.lib failed for 'tkrplot'
>
> Gustavo Corral suggestion was to rebuild the tkrplot.so bundle as a library
> by doing:
>
>> It can be rather tricky to make it work. You have to download it, then
>> install it with R CMD INSTALL, then you may need to edit the file Makeconf in
>> the RHOME/etc directory (the command R RHOME says the path to RHOME
>> directory).
>> In this file you must change:
>>
>> (line 41 in my case)
>> SHLIB_CXXLDFLAGS = -bundle -flat_namespace -undefined suppress
>> replaced by:
>> SHLIB_CXXLDFLAGS = -dynamiclib -flat_namespace -undefined suppress
>>
>> (line 45 ...)
>> SHLIB_LDFLAGS = -bundle -flat_namespace -undefined suppress
>> replaced by:
>> SHLIB_LDFLAGS = -dynamiclib -flat_namespace -undefined suppress
>>
>> then move to the src directory in the tkrplot you just download and link
>> tkrplot
>> with the statement: R CMD SHLIB -o tkrplot.so. Then move tkrplot.so by hand to
>>
>> the libs directory of the tkrplot installation (RHOME/library/tkrplot/libs).
>
> That what I did. Now I am having a different error when I try to load
> tkrplot...
>
>> library(tkrplot)
> Loading required package: tcltk
> Loading Tcl/Tk interface ... done
> Error in structure(.External("dotTcl", ..., PACKAGE = "tcltk"), class =
> "tclObj") :
>        [tcl] couldn't find procedure Rplot_Init.
> Error in library(tkrplot) : .First.lib failed for 'tkrplot'
>
> Any clue as how to fix tkrplot?
>
> Why is this package so difficult to install???
>
> Anyway, I would appreciate any help/suggestions.
>
> Many tx
>
> Marco
>
> Marco Blanchette, Ph.D.
>
> mblanche at uclink.berkeley.edu
>
> Donald C. Rio's lab
> Department of Molecular and Cell Biology
> 16 Barker Hall
> University of California
> Berkeley, CA 94720-3204
>
> Tel: (510) 642-1084
> Cell: (510) 847-0996
> Fax: (510) 642-6062
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:      luke at stat.uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



From efg at stowers-institute.org  Tue Aug 16 21:34:15 2005
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Tue, 16 Aug 2005 14:34:15 -0500
Subject: [R] Image from bytes streams
References: <76189e25050815203379654093@mail.gmail.com><43019D0E.5090901@maths.lth.se>
	<76189e25050816063321b42d24@mail.gmail.com>
Message-ID: <ddtf3o$tee$1@sea.gmane.org>

"M??rcio de Medeiros Ribeiro" <marcinhosbt at gmail.com> wrote in message
news:<76189e25050816063321b42d24 at mail.gmail.com>...
>My big problem is that my program reads the image before that its
>complete by the png() function. For instance, my graphic image has
>1000Kb. When R saves it into the hard disk, my Java program reads the
>file before the save operation completes (500Kb for example). So, I
>got only a part of the file and hence the image... :(
>
>One solution is read the image and search for a byte which represents
>the end of the file, but it depends on the image format...

Have you considered in R writing the file to a temporary name (see
?tempfile). When the file is complete, after the dev.off() in R as suggested
by Prof Ripley, you could rename the file [using file.name() in R]. Your
external program can now access the file without worrying about whether it
is complete, since the file appears not to exist until the whole file has
been written.

efg



From p.dalgaard at biostat.ku.dk  Tue Aug 16 21:44:12 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Aug 2005 21:44:12 +0200
Subject: [R] as.character and a formula
In-Reply-To: <1124215476.8689.120.camel@gsimpson.geog.ucl.ac.uk>
References: <1124215476.8689.120.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <x2slx9r7jn.fsf@turmalin.kubism.ku.dk>

Gavin Simpson <gavin.simpson at ucl.ac.uk> writes:

> Dear list,
> 
> given this formula: 
> 
> > fmla <- formula(y1 ~ spp1 + spp2 + spp3 + spp5)
> > fmla[[3]]
> spp1 + spp2 + spp3 + spp5
> 
> is this the intended behaviour of as.character:
> 
> > as.character(fmla[[3]])
> [1] "+"                  "spp1 + spp2 + spp3" "spp5"

Yes.
 
> ? Where does the extra "+" come from?

What extra "+" ? There are three of them in fmla[[3]] and three in
as.character(....).

as.character of an object of mode call is obtained by converting it to
a list and deparsing each term (modulo some details regarding
backquotes). This is somewhat peculiar, but quite a bit of legacy code
is depending on it. Things like testing for as.character(e)[1] == "~"


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From lasarczyk at gmail.com  Tue Aug 16 22:02:55 2005
From: lasarczyk at gmail.com (Christian Lasarczyk)
Date: Tue, 16 Aug 2005 22:02:55 +0200
Subject: [R] Stacked Area chart
In-Reply-To: <000601c5a27b$faa21310$9ba76f82@CFRU0104>
References: <000601c5a27b$faa21310$9ba76f82@CFRU0104>
Message-ID: <926ba889050816130248ffa2b1@mail.gmail.com>

Maybe this is useful:


stackedPlot <- function(data, time=NULL, col=1:length(data), ...) {

  if (is.null(time))
    time <- 1:length(data[[1]]);
  
  plot(0,0
       , xlim = range(time)
       , ylim = c(0,max(rowSums(data)))
       , t="n" 
       , ...
       );
  
  for (i in length(data):1) {

    # Die Summe bis zu aktuellen Spalte
    prep.data <- rowSums(data[1:i]);
    
    # Das Polygon muss seinen ersten und letzten Punkt auf der Nulllinie haben
    prep.y <- c(0
                , prep.data
                , 0
                )

    prep.x <- c(time[1]
                , time
                , time[length(time)]
                )
    
    polygon(prep.x, prep.y
            , col=col[i]
            , border = NA
            );
  }
}

dogs <- runif(10)+ 1:10;
cats <- 11 - dogs;
birds <- 11 - cats;
population <- data.frame(dogs,cats,birds);
stackedPlot(population);

Documentation is bad (as this function is for personal use) and you
may want to normalize your data, but it should be useful for different
sized data.frames.

Best regards,
     Christian 


2005/8/16, Mike Saunders <mike_saunders at umenfa.maine.edu>:
> I wish to do a stacked area chart to show how relative proportions of species within a stand have changed over time.
> 
> I know this is simple, but can someone point me to the right function (if it exists).  I have not had any luck finding it in the R-help, but maybe I am searching using the wrong keywords.
> 
> Thanks,
> Mike
> 
> 
> Mike Saunders
> Research Assistant
> Forest Ecosystem Research Program
> Department of Forest Ecosystem Sciences
> University of Maine
> Orono, ME  04469
> 207-581-2763 (O)
> 207-581-4257 (F)
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From munguiar at posgrado.ecologia.edu.mx  Tue Aug 16 22:37:54 2005
From: munguiar at posgrado.ecologia.edu.mx (munguiar@posgrado.ecologia.edu.mx)
Date: Tue, 16 Aug 2005 15:37:54 -0500 (CDT)
Subject: [R] data manipulation help
Message-ID: <8sJbuFkx.1124224674.3215090.munguiar@posgrado.ecologia.edu.mx>


Thanks to Patrick Burns, Dieter Menne and Peter Alspach for your help.

Peter Alspach indicated me how to get the first and the last capture
of every individual with the following code:

capture <- matrix(rbinom(40, 1, 0.3), 4, 10)

capture
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]    0    0    0    0    0    1    1    0    1     1
[2,]    1    0    1    0    0    0    1    1    1     0
[3,]    0    0    0    0    0    0    1    0    1     0
[4,]    0    1    0    1    1    0    0    0    0     0

firstcap<-apply(capture, 1, function(x) min((1:length(x))[x==1])) [1] 6 1
7 2
lastcap<-apply(capture, 1, function(x) max((1:length(x))[x==1])) [1] 10 
9  9  5

Roberto

Hello everybody,

 I have a dataframe with 468 individuals (rows) that I captured at least
once during 28 visits (columns), iso I can know how many times every
individual was captured, 0= not capture, 1=capture.

persistence<-apply(mortacap2,1,sum)

I also want to know when  was the first and the last capture for every
individual,
if I use:

which(mortacap2[1,]==1)


X18.10.2004 X26.10.2004 X28.10.2004 X30.10.2004

          1           5           6           7
I can estimate manually row by row, but I dont get how to estimate the
first and the last capture, to all individuals in the database at the
same time.


I tried
d<-numeric(368)
for (i in 1:368) {d[i]<-which(mortacap2[1:368,]==1}
but it didnt work. Any help would be appreciated.


Thanks in advance!!


Roberto Munguia Steyer
Departamento Biologia Evolutiva
Instituto de Ecologia, A.C.
Xalapa, Veracruz.
MEXICO

 Windows XP
R 2.10



From konradb at few.vu.nl  Tue Aug 16 22:57:37 2005
From: konradb at few.vu.nl (Konrad Banachewicz)
Date: Tue, 16 Aug 2005 22:57:37 +0200
Subject: [R] vector autoregression
Message-ID: <43025341.2040709@few.vu.nl>

dear All,
I have the following problem: I need to calculate an h-step ahead forecast
from a var model (estimated with a dse1 method estVARXls), which in
turn will be used as an input for another model as conditioning data, so
I need it as a simple, numeric matrix. No exogenous input is used.
 However, the standard forecast method produces a 1-element list
that includes a forecast matrix, yet I have no clue as to how to
extract the values of interest. Featherforecast and Horizonforecast
do not allow prediction only beyond the sample period, quote:
"from.periods cannot exceed available output data".
any help will be much appreciated,

regards,

konrad



From wl at eimb.ru  Tue Aug 16 23:12:04 2005
From: wl at eimb.ru (Wladimir Eremeev)
Date: Tue, 16 Aug 2005 13:12:04 -0800
Subject: [R] how to reshape an array avoiding for loops
Message-ID: <171836925.20050816131204@eimb.ru>

Dear r-help,

  I have an array a1 with dimensions [1:660,1:65,1:25]
  I would like the first dimension to be the last one.
  That is I want and array [1:65,1:25,1:660]

  The only way to do this, I know, is
  
  tmp.a<-array(dim=dim(a1)[c(2,3,1)])
  for(i in 1:dim(a1)[1]) tmp.a[,,i]<-a1[i,,]
  a1<-tmp.a
  rm(tmp.a)

  
  Is it possible to avoid 'for' loop here?

  Thank you!

---
Best regards,
Wladimir                mailto:wl at eimb.ru



From dhiren22 at hotmail.com  Tue Aug 16 23:13:46 2005
From: dhiren22 at hotmail.com (Dhiren DSouza)
Date: Tue, 16 Aug 2005 17:13:46 -0400
Subject: [R]  specify seed for Random Number Generator
Message-ID: <BAY102-F20D65AC2ABB73090330AEED3B00@phx.gbl>

I need to generate 100 I.I.D samples from an exponential distribution.  I 
use rexp(100,parameter).  Is there anyway to specify a seed to determine the 
first input for the uniform random number generator used to generate these 
exponentials?

-Dhiren



From gunter.berton at gene.com  Tue Aug 16 23:16:54 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 16 Aug 2005 14:16:54 -0700
Subject: [R] how to reshape an array avoiding for loops
In-Reply-To: <171836925.20050816131204@eimb.ru>
Message-ID: <200508162116.j7GLGt5k002386@compton.gene.com>

?aperm

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Wladimir Eremeev
> Sent: Tuesday, August 16, 2005 2:12 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] how to reshape an array avoiding for loops
> 
> Dear r-help,
> 
>   I have an array a1 with dimensions [1:660,1:65,1:25]
>   I would like the first dimension to be the last one.
>   That is I want and array [1:65,1:25,1:660]
> 
>   The only way to do this, I know, is
>   
>   tmp.a<-array(dim=dim(a1)[c(2,3,1)])
>   for(i in 1:dim(a1)[1]) tmp.a[,,i]<-a1[i,,]
>   a1<-tmp.a
>   rm(tmp.a)
> 
>   
>   Is it possible to avoid 'for' loop here?
> 
>   Thank you!
> 
> ---
> Best regards,
> Wladimir                mailto:wl at eimb.ru
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Tue Aug 16 23:18:27 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Aug 2005 23:18:27 +0200
Subject: [R] how to reshape an array avoiding for loops
In-Reply-To: <171836925.20050816131204@eimb.ru>
References: <171836925.20050816131204@eimb.ru>
Message-ID: <x28xz1mvh8.fsf@turmalin.kubism.ku.dk>

Wladimir Eremeev <wl at eimb.ru> writes:

> Dear r-help,
> 
>   I have an array a1 with dimensions [1:660,1:65,1:25]
>   I would like the first dimension to be the last one.
>   That is I want and array [1:65,1:25,1:660]
> 
>   The only way to do this, I know, is
>   
>   tmp.a<-array(dim=dim(a1)[c(2,3,1)])
>   for(i in 1:dim(a1)[1]) tmp.a[,,i]<-a1[i,,]
>   a1<-tmp.a
>   rm(tmp.a)
> 
>   
>   Is it possible to avoid 'for' loop here?

aperm() is your friend.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From p.dalgaard at biostat.ku.dk  Tue Aug 16 23:22:41 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 16 Aug 2005 23:22:41 +0200
Subject: [R] specify seed for Random Number Generator
In-Reply-To: <BAY102-F20D65AC2ABB73090330AEED3B00@phx.gbl>
References: <BAY102-F20D65AC2ABB73090330AEED3B00@phx.gbl>
Message-ID: <x24q9pmva6.fsf@turmalin.kubism.ku.dk>

"Dhiren DSouza" <dhiren22 at hotmail.com> writes:

> I need to generate 100 I.I.D samples from an exponential distribution.  I 
> use rexp(100,parameter).  Is there anyway to specify a seed to determine the 
> first input for the uniform random number generator used to generate these 
> exponentials?

Try set.seed()

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From steve_adams_sd at yahoo.com  Wed Aug 17 00:14:01 2005
From: steve_adams_sd at yahoo.com (Steve Adams)
Date: Tue, 16 Aug 2005 15:14:01 -0700 (PDT)
Subject: [R] permutated p values vs. normal p values
Message-ID: <20050816221401.5330.qmail@web33310.mail.mud.yahoo.com>

Hi, I am performing Cox proportional hazards
regression on a microarray dataset with 15000 genes.
The p values generated from the Cox regression (based
on normal distribution of large sample theory) showed
only 2 genes have a p value less than 0.05. However,
when I did a permutation on the dataset to obtained
permutated p values, and it turned out about 750 genes
had a permutated p value less than 0.05 (that just
happens to be equal to the number of significant genes
you would expect by chance alone). With that big
difference in the number of significant genes, which
one should I trusted? and what's reason why such a big
difference exists? My dataset is not large in sample
size (17 samples), might this be the reason? 


Thanks



From dsmith at insightful.com  Wed Aug 17 00:50:10 2005
From: dsmith at insightful.com (David Smith)
Date: Tue, 16 Aug 2005 15:50:10 -0700
Subject: [R] preprocessing data
Message-ID: <EDAC416B87ECCA44BEAB4D0CF48034EF860513@se2kexch01.insightful.com>

> My question is concerning the line 
> "This is adequate for small files, but for anything more 
> complicated we
> recommend using the facilities   of a language like perl to 
> pre-process the file."

An alternative to Perl is to use the big data library of S-PLUS 7 Enterprise,
which would allow you to read in the entire fixed-format file and pre-process
it using S commands. You could then export the processed data to a file from
S-PLUS and import into R.  If your university has S-PLUS, S-PLUS 7 Enterprise
should be available (all academic institutions were upgraded to S-PLUS 7
Enterprise, which has the big data library).

You can read more information about the big data library at:

http://www.insightful.com/insightful_doclib/document.asp?id=167

# David Smith

-- 
David M Smith <dsmith at insightful.com>
Senior Product Manager, Insightful Corp, Seattle WA
Tel: +1 (206) 802 2360
Fax: +1 (206) 283 6310

New S-PLUS 7! Create advanced statistical applications with large data sets.
www.insightful.com/splus

> -----Original Message-----
> From: Jean Eid [mailto:jeaneid at chass.utoronto.ca]
> Sent: Tuesday, August 16, 2005 5:39 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] preprocessing data
> 
> 
> Dear all,
> 
> My question is concerning the line
> "This is adequate for small files, but for anything more 
> complicated we
> recommend using the facilities   of a language like perl to 
> pre-process
> the file."
> 
> in the import/export manual.
> 
> I have a large fixed-width file that I would like to 
> preprocess in Perl or
> awk. The problem is that I do not know where to start. Does 
> anyone have a
> simple example on how to turn a fixed-width file in any of these
> facilities into csv or tab delimited file. I guess I am looking for
> somewhat a perl for dummies or awk for dummies that does this. any
> pointers for website will be greatly appreciated
> 
> Thank you
> 
> 
> Jean Eid
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From gavin.simpson at ucl.ac.uk  Wed Aug 17 00:51:55 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 16 Aug 2005 23:51:55 +0100
Subject: [R] as.character and a formula
In-Reply-To: <x2slx9r7jn.fsf@turmalin.kubism.ku.dk>
References: <1124215476.8689.120.camel@gsimpson.geog.ucl.ac.uk>
	<x2slx9r7jn.fsf@turmalin.kubism.ku.dk>
Message-ID: <1124232715.2717.10.camel@dsl-217-155-166-107.zen.co.uk>

On Tue, 2005-08-16 at 21:44 +0200, Peter Dalgaard wrote:
> Gavin Simpson <gavin.simpson at ucl.ac.uk> writes:
> 
> > Dear list,
> > 
> > given this formula: 
> > 
> > > fmla <- formula(y1 ~ spp1 + spp2 + spp3 + spp5)
> > > fmla[[3]]
> > spp1 + spp2 + spp3 + spp5
> > 
> > is this the intended behaviour of as.character:
> > 
> > > as.character(fmla[[3]])
> > [1] "+"                  "spp1 + spp2 + spp3" "spp5"
> 
> Yes.

Thanks Uwe, Brian and Peter for setting me straight. Being unobservant,
forgetful and stupid, all in one day, is some going, even for me.

All the best,

Gav

> > ? Where does the extra "+" come from?
> 
> What extra "+" ? There are three of them in fmla[[3]] and three in
> as.character(....).
> 
> as.character of an object of mode call is obtained by converting it to
> a list and deparsing each term (modulo some details regarding
> backquotes). This is somewhat peculiar, but quite a bit of legacy code
> is depending on it. Things like testing for as.character(e)[1] == "~"
> 
> 
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From gunter.berton at gene.com  Wed Aug 17 01:07:13 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 16 Aug 2005 16:07:13 -0700
Subject: [R] permutated p values vs. normal p values
In-Reply-To: <20050816221401.5330.qmail@web33310.mail.mud.yahoo.com>
Message-ID: <200508162307.j7GN7DaE010891@faraday.gene.com>

A **guess** ... subject to correction by others.

If you had large systematic error in your experiment, nothing will turn out
"significant" (which is what you saw).

If you permute the data so that the systematic error becomes "random",
you'll get a random number of significant p-values, which is what you saw.

If the samples came from animals (or people),-- possibly performed over time
by differnet people at diffeent labs (sites)-- large systematic error that
would overwhelm small sample size is not unusual.Lack of explicit and
careful randomization/cage effects in animal experiments/ equipment and
calibration issues are some possible sources for such error.

OTOH, what I just said might be pure nonsense, so caveat emptor.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Steve Adams
> Sent: Tuesday, August 16, 2005 3:14 PM
> To: R-help at stat.math.ethz.ch
> Subject: [R] permutated p values vs. normal p values
> 
> Hi, I am performing Cox proportional hazards
> regression on a microarray dataset with 15000 genes.
> The p values generated from the Cox regression (based
> on normal distribution of large sample theory) showed
> only 2 genes have a p value less than 0.05. However,
> when I did a permutation on the dataset to obtained
> permutated p values, and it turned out about 750 genes
> had a permutated p value less than 0.05 (that just
> happens to be equal to the number of significant genes
> you would expect by chance alone). With that big
> difference in the number of significant genes, which
> one should I trusted? and what's reason why such a big
> difference exists? My dataset is not large in sample
> size (17 samples), might this be the reason? 
> 
> 
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From mackay at northnet.com.au  Wed Aug 17 03:11:14 2005
From: mackay at northnet.com.au (Duncan Mackay)
Date: Wed, 17 Aug 2005 01:11:14 +0000
Subject: [R] Stacked Area chart
Message-ID: <6.0.1.1.1.20050817011105.02a9c798@mail.northnet.com.au>

At 16:03 16/08/05, Mike Saunders wrote:
>I wish to do a stacked area chart to show how relative proportions of 
>species within a stand have changed over time.
>
>I know this is simple, but can someone point me to the right function (if 
>it exists).  I have not had any luck finding it in the R-help, but maybe I 
>am searching using the wrong keywords.
>
>Thanks,
>Mike
>
>
>Mike Saunders
>Research Assistant
>Forest Ecosystem Research Program
>Department of Forest Ecosystem Sciences
>University of Maine
>Orono, ME  04469
>207-581-2763 (O)
>207-581-4257 (F)
>
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

I recently did some graphs using xyplot in lattice where I had the data 
ordered by days,
the groups argument and possibly by condition.

I have slightly reduced the code for general  use and re run it

The process is to create a matrix of cumulative data (xy) and to make a 
filled polygon for each of the
groups using the previous group value as the lower limit of the polygon.
For the first group there has to be a dummy lower limit in these cases of zero
ie rep(0,5) in the single panel graph in the rbind sequence
Plotting of a group line is referred to as j+1 row due to the fact that 
there is a dummy
line for the lower polygon of the first group

The first script is for a single graph where there were the groups (codeno) 
were 4 species.
The days were 1,2,4,6,9 and the y values (comp ) were percentages.

All groupings and conditions are numeric for both datasets
Any NAs were converted to 0s so as not to give error messages etc.

The second script is for a conditioned graph of similar data
but is generalised.

The maximum y limit can cause problems in setting.
In these cases I had a good idea of what they would be.
For count data it would be necessary to first do a calculation to find it.

#  Single panel
xyplot(comp ~ days, data = stackln,
        as.table = T,
        groups = codeno,
        subscripts = T,
        panel= function(x,y,subscripts,groups)
        {
          xy <- rbind(rep(0,5), apply(sapply(1:4, function(j) 
y[groups[subscripts]==j]),1,cumsum))
          for(j in 1:4){
                      grid.polygon(x = c(c(1,2,4,6,9), rev(c(1,2,4,6,9)) ),
                                   y = c(xy[(j+1),],rev(xy[(j),]) ),
                                   gp = gpar(col = 0, fill = c(1,2,6,8)[j]),
                                   default.units = "native")

          }
        }

)

# Conditioned panel
xyplot(comp ~ days|grps3, data = in1,
        as.table = T,
        groups = codeno,
        subscripts = T,
        panel = function(x,y,subscripts,groups,panel.number)
        {
           grp.no <- sort(unique(groups[subscripts]) )

           x.vals <- sort(unique(x))

           xy <- rbind(rep(0,length(x.vals) ), 
apply(sapply(1:length(grp.no), function(j) 
y[groups[subscripts]==grp.no[j]]),1,cumsum))

           for (j in 1:length(grp.no))
           {
             grid.polygon(x = c(x.vals, rev(x.vals) ),
                          y = c(xy[(j+1),], rev(xy[(j),]) ),
                          gp = gpar(col = 0, fill = c(6,1,2,5,3,4,7,8)[j]),
                          default.units = "native")
           }  # for (j in 1:length(grp.no))

        } # panel
)


Regards

Duncan Mackay
(The other Duncan Mackay)


Duncan Mackay
Dept of Agronomy and Soil Science
University of New England
ARMIDALE  NSW 2351
Email: dmackay8 at pobox.une.edu.au



From shigesong at gmail.com  Wed Aug 17 07:26:11 2005
From: shigesong at gmail.com (Shige Song)
Date: Wed, 17 Aug 2005 13:26:11 +0800
Subject: [R] Two-level Poisson model with cross classified random effects
Message-ID: <5abc11d8050816222630d8995@mail.gmail.com>

Dear All,

I have two-level data with individual as level-1, birth cohort and
community as level-2. All the level-2 covariates are generated from
the level-1 covariates by cross-classifying by cohort and community.

>From what I read, an ordinary three-level model with individual nesed
within birth cohort nested within community, or individual nested
within community nested within birth cohort do not work well, neither
do model with individual nested within community by cohort. The right
way to go is to estimate a two-level model with two separate random
effects: within cohort and within community. The question I want to
ask is: how to do this using lmer?

I tried the following for a simple unconditioal model:

m1 <- lmer(count ~ offset(log(total)) + (1|comm) + (1|cohort), data, poisson)

where "count" is the dependent variable, "total" is the exposure
variable, "comm" is the community ID, and "cohort" is the birth cohort
ID. Will this be suffice? I got really smalle randome intercept
(5.0000e-10 for community and 4.4226e-05 for cohort), which got me a
bit nervous.

Thanks!

Best,
Shige



From bstabler at ptvamerica.com  Wed Aug 17 07:50:43 2005
From: bstabler at ptvamerica.com (Ben Stabler)
Date: Tue, 16 Aug 2005 22:50:43 -0700
Subject: [R] RODBC and sqlColumns
Message-ID: <001001c5a2ef$9b67ed10$0200a8c0@STABLERLAPTOP>

I have a Postgres database that I am connecting to with the Postgres
ODBC driver on Windows XP in R 2.1.0.  In the database is a database
with two schemas (public and X).  With RODBC (1.1-4) , I can connect to
the database and get the tables with sqlTables(db).  I can query tables
in the schema with sqlQuery("SELECT * FROM X.test").  However, I can't
get the columns in table X.test with sqlColumns(db,"X.test") //it
returns 
 
Error in sqlColumns(db, "X.test") : 'X.test': table not found on channel

If I do 
 
sqlColumns(db, "test") it returns
 [1] TABLE_QUALIFIER   TABLE_OWNER       TABLE_NAME        COLUMN_NAME
DATA_TYPE        
 [6] TYPE_NAME         PRECISION         LENGTH            SCALE
RADIX            
[11] NULLABLE          REMARKS           COLUMN_DEF        SQL_DATA_TYPE
SQL_DATETIME_SUB 
[16] CHAR_OCTET_LENGTH ORDINAL_POSITION  IS_NULLABLE       DISPLAY_SIZE
FIELD_TYPE       
<0 rows> (or 0-length row.names)

But there is no test table defined anywhere else but the X schema.  If I
do sqlSave(db,aDataFrame,"X.test",T,F), it says test already defined. If
I change the aDataFrame to be different than the fields actually in the
data, then R starts to create a new table but returns
 
Error in sqlColumns(db, "X.test") : 'X.test': table not found on channel

It seems to be having problems with what is returned by the
columns.....since 
 
Error in sqlSave(db, aDataFrame, "X.test", T, F) : 
        [RODBC] ERROR: Could not SQLExecDirectS1000 7 ERROR:  relation
"test" already exists

but if I change the input table to be different....then R can create the
table, but fails to populate it.  I checked the db in PgAdmin and the
table is created by the sqlSave call.  All this stuff works if I don't
use a schema "schema.table".  So it appears there is something wrong in
some place dealing with understanding the columns for tables in schemas.
 
Any ideas?  Any help would be much appreciated.  Thank you.

Ben Stabler
Project Manager
PTV America, Inc.
1128 NE 2nd St, Suite 204
Corvallis, OR 97330
541-754-6836 x205
541-754-6837 fax
www.ptvamerica.com


Ben Stabler
Project Manager
PTV America, Inc.
1128 NE 2nd St, Suite 204
Corvallis, OR 97330
541-754-6836 x205
541-754-6837 fax
www.ptvamerica.com



From shigesong at gmail.com  Wed Aug 17 08:52:50 2005
From: shigesong at gmail.com (Shige Song)
Date: Wed, 17 Aug 2005 14:52:50 +0800
Subject: [R] two-level poisson, again
Message-ID: <5abc11d8050816235233d7f51a@mail.gmail.com>

Hi,

I compare results of a simple two-level poisson estimated using lmer
and those estimated using MLwiN and Stata (v.9).

In R, I trype:
-------------------------------------------------------------------------------------------
m2 <- lmer(.D ~ offset(log(.Y)) + (1|pcid2) + educy + agri, male, poisson)
-------------------------------------------------------------------------------------------

In Stata, I type:
-------------------------------------------------------------------------------------------
xtpois _D educy agri, e(_Y) i(pcid2)
-------------------------------------------------------------------------------------------

Results using R look like:
-------------------------------------------------------------------------------------------
...
Random effects:
     Groups        Name    Variance    Std.Dev. 
      pcid2 (Intercept)       5e-10  2.2361e-05 
# of obs: 25360, groups: pcid2, 174

Estimated scale (compare to 1)  7.190793 

Fixed effects:
               Estimate  Std. Error z value  Pr(>|z|)    
(Intercept) -3.28548086  0.00408771 -803.75 < 2.2e-16 ***
educy        0.00507475  0.00039616   12.81 < 2.2e-16 ***
agri         0.01346887  0.00334837    4.02 5.758e-05 ***
...
------------------------------------------------------------------------------------------

Results using Stata look like:

------------------------------------------------------------------------------
          _D |      Coef.   Std. Err.      z    P>|z|     [95% Conf. Interval]
-------------+----------------------------------------------------------------
       educy |   .0120431   .0004441    27.12   0.000     .0111725    .0129136
        agri |   .0293177   .0035586     8.24   0.000      .022343    .0362924
       _cons |  -3.325073   .0076275  -435.93   0.000    -3.340023   -3.310123
          _Y | (exposure)
-------------+----------------------------------------------------------------
    /lnalpha |  -4.982977   .1156474                     -5.209641   -4.756312
-------------+----------------------------------------------------------------
       alpha |   .0068536   .0007926                      .0054636    .0085973
------------------------------------------------------------------------------


As you can see, the discrepency is significant! And results using
MLwiN agree with Stata. Any help will be greately appreciated!

Shige



From ripley at stats.ox.ac.uk  Wed Aug 17 09:58:41 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 17 Aug 2005 08:58:41 +0100 (BST)
Subject: [R] RODBC and sqlColumns
In-Reply-To: <001001c5a2ef$9b67ed10$0200a8c0@STABLERLAPTOP>
References: <001001c5a2ef$9b67ed10$0200a8c0@STABLERLAPTOP>
Message-ID: <Pine.LNX.4.61.0508170851570.16535@gannet.stats>

AFAIK "." is not a valid part of an SQL table name. I think the help files 
are perfectly clear as to what is supported:

  sqtable: character: a database table name accessible from the
           connected dsn.

Why do you think "X.test" is a `database table name'?

On Tue, 16 Aug 2005, Ben Stabler wrote:

> I have a Postgres database that I am connecting to with the Postgres
> ODBC driver on Windows XP in R 2.1.0.  In the database is a database
> with two schemas (public and X).  With RODBC (1.1-4) , I can connect to
> the database and get the tables with sqlTables(db).  I can query tables
> in the schema with sqlQuery("SELECT * FROM X.test").  However, I can't
> get the columns in table X.test with sqlColumns(db,"X.test") //it
> returns
>
> Error in sqlColumns(db, "X.test") : 'X.test': table not found on channel
>
> If I do
>
> sqlColumns(db, "test") it returns
> [1] TABLE_QUALIFIER   TABLE_OWNER       TABLE_NAME        COLUMN_NAME
> DATA_TYPE
> [6] TYPE_NAME         PRECISION         LENGTH            SCALE
> RADIX
> [11] NULLABLE          REMARKS           COLUMN_DEF        SQL_DATA_TYPE
> SQL_DATETIME_SUB
> [16] CHAR_OCTET_LENGTH ORDINAL_POSITION  IS_NULLABLE       DISPLAY_SIZE
> FIELD_TYPE
> <0 rows> (or 0-length row.names)
>
> But there is no test table defined anywhere else but the X schema.  If I
> do sqlSave(db,aDataFrame,"X.test",T,F), it says test already defined. If
> I change the aDataFrame to be different than the fields actually in the
> data, then R starts to create a new table but returns
>
> Error in sqlColumns(db, "X.test") : 'X.test': table not found on channel
>
> It seems to be having problems with what is returned by the
> columns.....since
>
> Error in sqlSave(db, aDataFrame, "X.test", T, F) :
>        [RODBC] ERROR: Could not SQLExecDirectS1000 7 ERROR:  relation
> "test" already exists
>
> but if I change the input table to be different....then R can create the
> table, but fails to populate it.  I checked the db in PgAdmin and the
> table is created by the sqlSave call.  All this stuff works if I don't
> use a schema "schema.table".  So it appears there is something wrong in
> some place dealing with understanding the columns for tables in schemas.
>
> Any ideas?  Any help would be much appreciated.  Thank you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From henric.nilsson at statisticon.se  Wed Aug 17 10:14:46 2005
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Wed, 17 Aug 2005 10:14:46 +0200 (CEST)
Subject: [R] two-level poisson, again
In-Reply-To: <5abc11d8050816235233d7f51a@mail.gmail.com>
References: <5abc11d8050816235233d7f51a@mail.gmail.com>
Message-ID: <3986.83.253.10.207.1124266486.squirrel@poisson.statisticon.se>

On On, 2005-08-17, 08:52, Shige Song skrev:
> Hi,
>
> I compare results of a simple two-level poisson estimated using lmer
> and those estimated using MLwiN and Stata (v.9).
>
> In R, I trype:
> -------------------------------------------------------------------------------------------
> m2 <- lmer(.D ~ offset(log(.Y)) + (1|pcid2) + educy + agri, male, poisson)
> -------------------------------------------------------------------------------------------
>
> In Stata, I type:
> -------------------------------------------------------------------------------------------
> xtpois _D educy agri, e(_Y) i(pcid2)

You're not fitting the same model! `lmer' uses Gaussian random effects and
the default for `xtpois' is gamma random effects.

Also, note that even if you'd specified a Gaussian random effect (through
a `normal' to the right of the `,' in your `xtpois' call) the same fitting
criterion is not used since `xtpois' uses adaptive Gauss-Hermite
quadrature and `lmer' defaults to PQL.

For comparable results, try the following:

m2 <- lmer(.D ~ offset(log(.Y)) + (1|pcid2) + educy + agri, male, poisson,
method = "AGQ")

xtpois _D educy agri, e(_Y) i(pcid2) re normal

You may also want to try G??ran Brostr??m's `glmmML' package.


HTH,
Henric

>
> Results using R look like:
> -------------------------------------------------------------------------------------------
> ..
> Random effects:
>      Groups        Name    Variance    Std.Dev.
>       pcid2 (Intercept)       5e-10  2.2361e-05
> # of obs: 25360, groups: pcid2, 174
>
> Estimated scale (compare to 1)  7.190793
>
> Fixed effects:
>                Estimate  Std. Error z value  Pr(>|z|)
> (Intercept) -3.28548086  0.00408771 -803.75 < 2.2e-16 ***
> educy        0.00507475  0.00039616   12.81 < 2.2e-16 ***
> agri         0.01346887  0.00334837    4.02 5.758e-05 ***
> ..
> ------------------------------------------------------------------------------------------
>
> Results using Stata look like:
>
> ------------------------------------------------------------------------------
>           _D |      Coef.   Std. Err.      z    P>|z|     [95% Conf.
> Interval]
> -------------+----------------------------------------------------------------
>        educy |   .0120431   .0004441    27.12   0.000     .0111725
> .0129136
>         agri |   .0293177   .0035586     8.24   0.000      .022343
> .0362924
>        _cons |  -3.325073   .0076275  -435.93   0.000    -3.340023
> -3.310123
>           _Y | (exposure)
> -------------+----------------------------------------------------------------
>     /lnalpha |  -4.982977   .1156474                     -5.209641
> -4.756312
> -------------+----------------------------------------------------------------
>        alpha |   .0068536   .0007926                      .0054636
> .0085973
> ------------------------------------------------------------------------------
>
>
> As you can see, the discrepency is significant! And results using
> MLwiN agree with Stata. Any help will be greately appreciated!
>
> Shige
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From henric.nilsson at statisticon.se  Wed Aug 17 10:42:56 2005
From: henric.nilsson at statisticon.se (Henric Nilsson)
Date: Wed, 17 Aug 2005 10:42:56 +0200 (CEST)
Subject: [R] Mixed Effects Model Power Calculations
In-Reply-To: <46344.128.147.28.3.1124219876.squirrel@webmail.pitt.edu>
References: <46344.128.147.28.3.1124219876.squirrel@webmail.pitt.edu>
Message-ID: <4047.83.253.10.207.1124268176.squirrel@poisson.statisticon.se>


On Ti, 2005-08-16, 21:17, rab45+ at pitt.edu skrev:

> Is there an R package available that would facilitate doing a power/sample
> size analysis for linear mixed effects models?

I'm not aware of such a package (others might be...).

When it comes to sample size calculations, especially for tricky designs
and/or advanced methodology, simulation is usually the best approach. An
example using `lme' can be found at

http://maven.smith.edu/~nhorton/R/


HTH,
Henric

> I have seen the Java applets made available by Russell Length which would
> seem to be able to handle most any lme, but there is little documentation
> and it's not clear how the models need to be formulated.
>
> Rick B.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html



From dimitris.rizopoulos at med.kuleuven.be  Wed Aug 17 10:59:20 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 17 Aug 2005 10:59:20 +0200
Subject: [R] Mixed Effects Model Power Calculations
References: <46344.128.147.28.3.1124219876.squirrel@webmail.pitt.edu>
	<4047.83.253.10.207.1124268176.squirrel@poisson.statisticon.se>
Message-ID: <011801c5a309$f4cce8f0$0540210a@www.domain>

I don't know what specific application Rick has in mind, but if there 
is possibility of missing values (which is common, e.g., in 
longitudinal studies) then this should also be taken into account in 
the power calculations.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Henric Nilsson" <henric.nilsson at statisticon.se>
To: <rab45+ at pitt.edu>
Cc: <r-help at stat.math.ethz.ch>
Sent: Wednesday, August 17, 2005 10:42 AM
Subject: Re: [R] Mixed Effects Model Power Calculations


>
> On Ti, 2005-08-16, 21:17, rab45+ at pitt.edu skrev:
>
>> Is there an R package available that would facilitate doing a 
>> power/sample
>> size analysis for linear mixed effects models?
>
> I'm not aware of such a package (others might be...).
>
> When it comes to sample size calculations, especially for tricky 
> designs
> and/or advanced methodology, simulation is usually the best 
> approach. An
> example using `lme' can be found at
>
> http://maven.smith.edu/~nhorton/R/
>
>
> HTH,
> Henric
>
>> I have seen the Java applets made available by Russell Length which 
>> would
>> seem to be able to handle most any lme, but there is little 
>> documentation
>> and it's not clear how the models need to be formulated.
>>
>> Rick B.
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From renaud.lancelot at cirad.fr  Wed Aug 17 11:09:49 2005
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Wed, 17 Aug 2005 12:09:49 +0300
Subject: [R] Two-level Poisson model with cross classified random effects
In-Reply-To: <5abc11d8050816222630d8995@mail.gmail.com>
References: <5abc11d8050816222630d8995@mail.gmail.com>
Message-ID: <4302FEDD.8030301@cirad.fr>

Shige Song a ??crit :
> Dear All,
> 
> I have two-level data with individual as level-1, birth cohort and
> community as level-2. All the level-2 covariates are generated from
> the level-1 covariates by cross-classifying by cohort and community.
> 
>>From what I read, an ordinary three-level model with individual nesed
> within birth cohort nested within community, or individual nested
> within community nested within birth cohort do not work well, neither
> do model with individual nested within community by cohort. The right
> way to go is to estimate a two-level model with two separate random
> effects: within cohort and within community. The question I want to
> ask is: how to do this using lmer?
> 
> I tried the following for a simple unconditioal model:
> 
> m1 <- lmer(count ~ offset(log(total)) + (1|comm) + (1|cohort), data, poisson)
> 
> where "count" is the dependent variable, "total" is the exposure
> variable, "comm" is the community ID, and "cohort" is the birth cohort
> ID. Will this be suffice? I got really smalle randome intercept
> (5.0000e-10 for community and 4.4226e-05 for cohort), which got me a
> bit nervous.
> 
> Thanks!
> 
> Best,
> Shige
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

The default method to fit generalized mixed-effect models with lme4 is 
"PQL" which is fast but not very accurate for the random effects (they 
might be underestimated). Try other methods ("Laplace" or "AGQ") to see 
if you get different results.

Best,

Renaud

-- 
Dr Renaud Lancelot, v??t??rinaire
Projet FSP r??gional ??pid??miologie v??t??rinaire
C/0 Ambassade de France - SCAC
BP 834 Antananarivo 101 - Madagascar

e-mail: renaud.lancelot at cirad.fr
tel.:   +261 32 40 165 53 (cell)
         +261 20 22 665 36 ext. 225 (work)



From shigesong at gmail.com  Wed Aug 17 12:12:22 2005
From: shigesong at gmail.com (Shige Song)
Date: Wed, 17 Aug 2005 18:12:22 +0800
Subject: [R] Mixed Effects Model Power Calculations
In-Reply-To: <011801c5a309$f4cce8f0$0540210a@www.domain>
References: <46344.128.147.28.3.1124219876.squirrel@webmail.pitt.edu>
	<4047.83.253.10.207.1124268176.squirrel@poisson.statisticon.se>
	<011801c5a309$f4cce8f0$0540210a@www.domain>
Message-ID: <5abc11d805081703127b64c9a@mail.gmail.com>

Hi Dimitris,

Thank you so much! That really helps!

Shige

On 8/17/05, Dimitris Rizopoulos <dimitris.rizopoulos at med.kuleuven.be> wrote:
> I don't know what specific application Rick has in mind, but if there
> is possibility of missing values (which is common, e.g., in
> longitudinal studies) then this should also be taken into account in
> the power calculations.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/336899
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.be/biostat/
>      http://www.student.kuleuven.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message -----
> From: "Henric Nilsson" <henric.nilsson at statisticon.se>
> To: <rab45+ at pitt.edu>
> Cc: <r-help at stat.math.ethz.ch>
> Sent: Wednesday, August 17, 2005 10:42 AM
> Subject: Re: [R] Mixed Effects Model Power Calculations
> 
> 
> >
> > On Ti, 2005-08-16, 21:17, rab45+ at pitt.edu skrev:
> >
> >> Is there an R package available that would facilitate doing a
> >> power/sample
> >> size analysis for linear mixed effects models?
> >
> > I'm not aware of such a package (others might be...).
> >
> > When it comes to sample size calculations, especially for tricky
> > designs
> > and/or advanced methodology, simulation is usually the best
> > approach. An
> > example using `lme' can be found at
> >
> > http://maven.smith.edu/~nhorton/R/
> >
> >
> > HTH,
> > Henric
> >
> >> I have seen the Java applets made available by Russell Length which
> >> would
> >> seem to be able to handle most any lme, but there is little
> >> documentation
> >> and it's not clear how the models need to be formulated.
> >>
> >> Rick B.
> >>
> >> ______________________________________________
> >> R-help at stat.math.ethz.ch mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide!
> >> http://www.R-project.org/posting-guide.html
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From shigesong at gmail.com  Wed Aug 17 12:14:11 2005
From: shigesong at gmail.com (Shige Song)
Date: Wed, 17 Aug 2005 18:14:11 +0800
Subject: [R] Two-level Poisson model with cross classified random effects
In-Reply-To: <4302FEDD.8030301@cirad.fr>
References: <5abc11d8050816222630d8995@mail.gmail.com>
	<4302FEDD.8030301@cirad.fr>
Message-ID: <5abc11d805081703147d5139d3@mail.gmail.com>

Dear Renaud,

Thank you very much! So now lme4 has both laplace and adaptive
quadrature? Wow, that's really impressive!

Shige

On 8/17/05, Renaud Lancelot <renaud.lancelot at cirad.fr> wrote:
> Shige Song a ??crit :
> > Dear All,
> >
> > I have two-level data with individual as level-1, birth cohort and
> > community as level-2. All the level-2 covariates are generated from
> > the level-1 covariates by cross-classifying by cohort and community.
> >
> >>From what I read, an ordinary three-level model with individual nesed
> > within birth cohort nested within community, or individual nested
> > within community nested within birth cohort do not work well, neither
> > do model with individual nested within community by cohort. The right
> > way to go is to estimate a two-level model with two separate random
> > effects: within cohort and within community. The question I want to
> > ask is: how to do this using lmer?
> >
> > I tried the following for a simple unconditioal model:
> >
> > m1 <- lmer(count ~ offset(log(total)) + (1|comm) + (1|cohort), data, poisson)
> >
> > where "count" is the dependent variable, "total" is the exposure
> > variable, "comm" is the community ID, and "cohort" is the birth cohort
> > ID. Will this be suffice? I got really smalle randome intercept
> > (5.0000e-10 for community and 4.4226e-05 for cohort), which got me a
> > bit nervous.
> >
> > Thanks!
> >
> > Best,
> > Shige
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> The default method to fit generalized mixed-effect models with lme4 is
> "PQL" which is fast but not very accurate for the random effects (they
> might be underestimated). Try other methods ("Laplace" or "AGQ") to see
> if you get different results.
> 
> Best,
> 
> Renaud
> 
> --
> Dr Renaud Lancelot, v??t??rinaire
> Projet FSP r??gional ??pid??miologie v??t??rinaire
> C/0 Ambassade de France - SCAC
> BP 834 Antananarivo 101 - Madagascar
> 
> e-mail: renaud.lancelot at cirad.fr
> tel.:   +261 32 40 165 53 (cell)
>          +261 20 22 665 36 ext. 225 (work)
>



From Rau at demogr.mpg.de  Wed Aug 17 12:15:46 2005
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Wed, 17 Aug 2005 12:15:46 +0200
Subject: [R] power of a matrix
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E69FDB7D@HERMES.demogr.mpg.de>

Dear all,

I have a population with three age-classes, at time t=0 the population
is:
n.zero <- c(1,0,0)
I have a transition matrix A which denotes "fertility" and "survival":

A <- matrix(c(0,1,5, 0.3,0,0, 0,0.5,0), ncol=3, byrow=TRUE)

To obtain the population at t=1, I calculate:
A %*% n.zero

To obtain the population t=2, I calculate:
A %*% (A %*% n.zero)

... and so on ...

I thought now to obtain the population at time x, I should simply do:
A^x %*% n.zero

But this, of course, does not work since the following two statements
are not equivalent for matrices:
A %*% A
A * A

Is there something like a "powermatrix"-function?

Thanks,
Roland

P.S. The example is taken from:
Example 3.1 ("A linear, time-invariant model") from Keyfitz/Caswell:
"Applied Mathematical Demography", 3rd Edition, 2005, p. 52f


+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From shigesong at gmail.com  Wed Aug 17 12:30:43 2005
From: shigesong at gmail.com (Shige Song)
Date: Wed, 17 Aug 2005 18:30:43 +0800
Subject: [R] How to assess significance of random effect in lme4
Message-ID: <5abc11d80508170330a9991b3@mail.gmail.com>

Dear All,

With kind help from several friends on the list, I am getting close.
Now here are something interesting I just realized: for random
effects, lmer reports standard deviation instead of standard error! Is
there a hidden option that tells lmer to report standard error of
random effects, like most other multilevel or mixed modeling software,
so that we can say something like "randome effect for xxx is
significant, while randome effect for xxx is not significant"? Thanks!

Best,
Shige



From sam.kemp2 at ntlworld.com  Wed Aug 17 12:34:39 2005
From: sam.kemp2 at ntlworld.com (Samuel Kemp)
Date: Wed, 17 Aug 2005 11:34:39 +0100
Subject: [R] x-axis binning
Message-ID: <430312BF.5080309@ntlworld.com>

Hi,

I am wanting to plot an x,y data.frame. But, I would like to have bins 
on the x-axis. Is there an easy way of doing this?

Thanks in advance,

Sam.



From Allan at STATS.uct.ac.za  Wed Aug 17 12:35:09 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Wed, 17 Aug 2005 12:35:09 +0200
Subject: [R] R: characters
Message-ID: <430312DD.20A0A56C@STATS.uct.ac.za>

hi all 

assume that i have the following table

a=rbind(c(T,T,F),c(F,F,T))
> a
      [,1]  [,2]  [,3]
[1,]  TRUE  TRUE FALSE
[2,] FALSE FALSE  TRUE

I would like to change all the FALSE entries to a blank. how can i do
this?

i could simply use

a[a==F]=""
a

but then how would i remove the " " from the entries.

i know that this should be very easy!!!

/
allan

From dimitris.rizopoulos at med.kuleuven.be  Wed Aug 17 13:00:53 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 17 Aug 2005 13:00:53 +0200
Subject: [R] R: characters
References: <430312DD.20A0A56C@STATS.uct.ac.za>
Message-ID: <004401c5a31a$efa089c0$0540210a@www.domain>

you could convert it to a data.frame, i.e.,

a <- rbind(c(T, T, F), c(F, F, T))
a[!a] <- ""
as.data.frame(a)


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Clark Allan" <Allan at stats.uct.ac.za>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, August 17, 2005 12:35 PM
Subject: [R] R: characters


> hi all
>
> assume that i have the following table
>
> a=rbind(c(T,T,F),c(F,F,T))
>> a
>      [,1]  [,2]  [,3]
> [1,]  TRUE  TRUE FALSE
> [2,] FALSE FALSE  TRUE
>
> I would like to change all the FALSE entries to a blank. how can i 
> do
> this?
>
> i could simply use
>
> a[a==F]=""
> a
>
> but then how would i remove the " " from the entries.
>
> i know that this should be very easy!!!
>
> /
> allan


--------------------------------------------------------------------------------


> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From petr.pikal at precheza.cz  Wed Aug 17 13:16:11 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 17 Aug 2005 13:16:11 +0200
Subject: [R] x-axis binning
In-Reply-To: <430312BF.5080309@ntlworld.com>
Message-ID: <4303389B.29817.1357DEB@localhost>

Hi

On 17 Aug 2005 at 11:34, Samuel Kemp wrote:

> Hi,
> 
> I am wanting to plot an x,y data.frame. But, I would like to have bins
> on the x-axis. Is there an easy way of doing this?

Yes.

Do you want to know how?

?cut

is probably what you want, but as you did not tell us any further 
details it is hard to decipher what you exactly want.

HTH
Petr



> 
> Thanks in advance,
> 
> Sam.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From HDoran at air.org  Wed Aug 17 13:16:46 2005
From: HDoran at air.org (Doran, Harold)
Date: Wed, 17 Aug 2005 07:16:46 -0400
Subject: [R] How to assess significance of random effect in lme4
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7407E41C2F@dc1ex2.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050817/3211f59f/attachment.pl

From dimitris.rizopoulos at med.kuleuven.be  Wed Aug 17 13:38:16 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Wed, 17 Aug 2005 13:38:16 +0200
Subject: [R] power of a matrix
References: <8B08A3A1EA7AAC41BE24C750338754E69FDB7D@HERMES.demogr.mpg.de>
Message-ID: <005901c5a320$284ec8e0$0540210a@www.domain>

look at function ?mtx.exp() in the Malmig package, e.g.,

A <- matrix(c(0,1,5, 0.3,0,0, 0,0.5,0), ncol=3, byrow=TRUE)
n.zero <- c(1,0,0)
##################
library(Malmig)

all.equal(A %*% (A %*% n.zero), mtx.exp(A, 2) %*% n.zero)
all.equal(A %*% (A %*% (A %*% n.zero)), mtx.exp(A, 3) %*% n.zero)

mtx.exp(A, 15) %*% n.zero


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Rau, Roland" <Rau at demogr.mpg.de>
To: "R-Help" <r-help at stat.math.ethz.ch>
Sent: Wednesday, August 17, 2005 12:15 PM
Subject: [R] power of a matrix


> Dear all,
>
> I have a population with three age-classes, at time t=0 the 
> population
> is:
> n.zero <- c(1,0,0)
> I have a transition matrix A which denotes "fertility" and 
> "survival":
>
> A <- matrix(c(0,1,5, 0.3,0,0, 0,0.5,0), ncol=3, byrow=TRUE)
>
> To obtain the population at t=1, I calculate:
> A %*% n.zero
>
> To obtain the population t=2, I calculate:
> A %*% (A %*% n.zero)
>
> ... and so on ...
>
> I thought now to obtain the population at time x, I should simply 
> do:
> A^x %*% n.zero
>
> But this, of course, does not work since the following two 
> statements
> are not equivalent for matrices:
> A %*% A
> A * A
>
> Is there something like a "powermatrix"-function?
>
> Thanks,
> Roland
>
> P.S. The example is taken from:
> Example 3.1 ("A linear, time-invariant model") from Keyfitz/Caswell:
> "Applied Mathematical Demography", 3rd Edition, 2005, p. 52f
>
>
> +++++
> This mail has been sent through the MPI for Demographic 
> Rese...{{dropped}}
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From shigesong at gmail.com  Wed Aug 17 13:49:53 2005
From: shigesong at gmail.com (Shige Song)
Date: Wed, 17 Aug 2005 19:49:53 +0800
Subject: [R] How to assess significance of random effect in lme4
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7407E41C2F@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F7407E41C2F@dc1ex2.air.org>
Message-ID: <5abc11d805081704491af1c70@mail.gmail.com>

Hi Harold,

Thanks for the reply. I looked at my outputs using str() as you
suggested, here is the part you mentioned:

  ..@ bVar     :List of 2
  .. ..$ commu  : num [1, 1, 1:29] 5e-10 5e-10 5e-10 5e-10 5e-10 ...
  .. ..$ bcohort: num [1, 1, 1:6] 1.05e-05 7.45e-06 6.53e-06 8.25e-06
7.11e-06 ...

where commu and bcohort are the two second-level units. Are these
standard errors? Why the second vector contains a series of different
numbers?

Thanks!

Shige

On 8/17/05, Doran, Harold <HDoran at air.org> wrote:
>  
> 
> You can extract the posterior variance of the random effect from the bVar
> slot of the fitted lmer model. It is not a hidden option, but a part of the
> fitted model. It just doesn't show up when you use summary().
>  
>  Look at the structure of your object to see what is available using str().
>  
>  However, your comment below seems to imply that it is incorrect for lmer to
> report SDs instead of the standard error, which is not true. That is a
> quantity of direct interest.
>  
>  Other multilevel programs report the same exact statistics (for the most
> part). For instance, HLM reports the variances as well. If you want the
> posterior variance of an HLM model you need to extract it.
> 
>  
>  
>  -----Original Message-----
>  From:   r-help-bounces at stat.math.ethz.ch on behalf of
> Shige Song
>  Sent:   Wed 8/17/2005 6:30 AM
>  To:     r-help at stat.math.ethz.ch
>  Cc:    
>  Subject:        [R] How to assess significance of random effect in lme4
>  
>  Dear All,
>  
>  With kind help from several friends on the list, I am getting close.
>  Now here are something interesting I just realized: for random
>  effects, lmer reports standard deviation instead of standard error! Is
>  there a hidden option that tells lmer to report standard error of
>  random effects, like most other multilevel or mixed modeling software,
>  so that we can say something like "randome effect for xxx is
>  significant, while randome effect for xxx is not significant"? Thanks!
>  
>  Best,
>  Shige
>  
>  ______________________________________________
>  R-help at stat.math.ethz.ch mailing list
>  https://stat.ethz.ch/mailman/listinfo/r-help
>  PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>  
>  
>  
> 
>



From tmlammail at yahoo.com  Wed Aug 17 13:52:01 2005
From: tmlammail at yahoo.com (Martin Lam)
Date: Wed, 17 Aug 2005 04:52:01 -0700 (PDT)
Subject: [R] R: characters
In-Reply-To: <004401c5a31a$efa089c0$0540210a@www.domain>
Message-ID: <20050817115201.29843.qmail@web40510.mail.yahoo.com>

Hmm, it seems that the only difference is the use of
"as.data.frame(a)" instead of "a". Hence, the same
result can be done with:

a <- rbind(c(T, T, F), c(F, F, T))
a[a==F]=""
as.data.frame(a)

A possible drawback is that the mode changes from
logical to character when using a[a==F]=""

Instead you could use a[a==F]=NA, but that won't get
you blank lines.

Best,

Martin


--- Dimitris Rizopoulos
<dimitris.rizopoulos at med.kuleuven.be> wrote:

> you could convert it to a data.frame, i.e.,
> 
> a <- rbind(c(T, T, F), c(F, F, T))
> a[!a] <- ""
> as.data.frame(a)
> 
> 
> I hope it helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/336899
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.be/biostat/
>     
>
http://www.student.kuleuven.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message ----- 
> From: "Clark Allan" <Allan at stats.uct.ac.za>
> To: <r-help at stat.math.ethz.ch>
> Sent: Wednesday, August 17, 2005 12:35 PM
> Subject: [R] R: characters
> 
> 
> > hi all
> >
> > assume that i have the following table
> >
> > a=rbind(c(T,T,F),c(F,F,T))
> >> a
> >      [,1]  [,2]  [,3]
> > [1,]  TRUE  TRUE FALSE
> > [2,] FALSE FALSE  TRUE
> >
> > I would like to change all the FALSE entries to a
> blank. how can i 
> > do
> > this?
> >
> > i could simply use
> >
> > a[a==F]=""
> > a
> >
> > but then how would i remove the " " from the
> entries.
> >
> > i know that this should be very easy!!!
> >
> > /
> > allan
> 
> 
>
--------------------------------------------------------------------------------
> 
> 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From p.dalgaard at biostat.ku.dk  Wed Aug 17 14:01:23 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 Aug 2005 14:01:23 +0200
Subject: [R] R: characters
In-Reply-To: <20050817115201.29843.qmail@web40510.mail.yahoo.com>
References: <20050817115201.29843.qmail@web40510.mail.yahoo.com>
Message-ID: <x2k6ikg4bw.fsf@turmalin.kubism.ku.dk>

Martin Lam <tmlammail at yahoo.com> writes:

> Hmm, it seems that the only difference is the use of
> "as.data.frame(a)" instead of "a". Hence, the same
> result can be done with:
> 
> a <- rbind(c(T, T, F), c(F, F, T))
> a[a==F]=""
> as.data.frame(a)

That's silly:

> a[!a]<-""
> noquote(a)
     [,1] [,2] [,3]
[1,] TRUE TRUE
[2,]           TRUE


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From Rau at demogr.mpg.de  Wed Aug 17 14:14:48 2005
From: Rau at demogr.mpg.de (Rau, Roland)
Date: Wed, 17 Aug 2005 14:14:48 +0200
Subject: [R] power of a matrix
Message-ID: <8B08A3A1EA7AAC41BE24C750338754E69FDB7E@HERMES.demogr.mpg.de>

Thank you very much! Thanks also to the authors of this function,
Vincente Canto Cassola and Martin Maechler!

This is exactly what I hoped for.

Best,
Roland



> -----Original Message-----
> From: Dimitris Rizopoulos 
> [mailto:dimitris.rizopoulos at med.kuleuven.be] 
> Sent: Wednesday, August 17, 2005 1:38 PM
> To: Rau, Roland
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] power of a matrix
> 
> look at function ?mtx.exp() in the Malmig package, e.g.,
> 
> A <- matrix(c(0,1,5, 0.3,0,0, 0,0.5,0), ncol=3, byrow=TRUE)
> n.zero <- c(1,0,0)
> ##################
> library(Malmig)
> 
> all.equal(A %*% (A %*% n.zero), mtx.exp(A, 2) %*% n.zero)
> all.equal(A %*% (A %*% (A %*% n.zero)), mtx.exp(A, 3) %*% n.zero)
> 
> mtx.exp(A, 15) %*% n.zero
> 
> 
> I hope it helps.
> 
> Best,
> Dimitris
> 
> ----
> Dimitris Rizopoulos
> Ph.D. Student
> Biostatistical Centre
> School of Public Health
> Catholic University of Leuven
> 
> Address: Kapucijnenvoer 35, Leuven, Belgium
> Tel: +32/16/336899
> Fax: +32/16/337015
> Web: http://www.med.kuleuven.be/biostat/
>      http://www.student.kuleuven.be/~m0390867/dimitris.htm
> 
> 
> ----- Original Message ----- 
> From: "Rau, Roland" <Rau at demogr.mpg.de>
> To: "R-Help" <r-help at stat.math.ethz.ch>
> Sent: Wednesday, August 17, 2005 12:15 PM
> Subject: [R] power of a matrix
> 
> 
> > Dear all,
> >
> > I have a population with three age-classes, at time t=0 the 
> > population
> > is:
> > n.zero <- c(1,0,0)
> > I have a transition matrix A which denotes "fertility" and 
> > "survival":
> >
> > A <- matrix(c(0,1,5, 0.3,0,0, 0,0.5,0), ncol=3, byrow=TRUE)
> >
> > To obtain the population at t=1, I calculate:
> > A %*% n.zero
> >
> > To obtain the population t=2, I calculate:
> > A %*% (A %*% n.zero)
> >
> > ... and so on ...
> >
> > I thought now to obtain the population at time x, I should simply 
> > do:
> > A^x %*% n.zero
> >
> > But this, of course, does not work since the following two 
> > statements
> > are not equivalent for matrices:
> > A %*% A
> > A * A
> >
> > Is there something like a "powermatrix"-function?
> >
> > Thanks,
> > Roland
> >
> > P.S. The example is taken from:
> > Example 3.1 ("A linear, time-invariant model") from Keyfitz/Caswell:
> > "Applied Mathematical Demography", 3rd Edition, 2005, p. 52f
> >
> >
> > +++++
> > This mail has been sent through the MPI for Demographic 
> > Rese...{{dropped}}
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> 
> 


+++++
This mail has been sent through the MPI for Demographic Rese...{{dropped}}



From p.dalgaard at biostat.ku.dk  Wed Aug 17 14:37:59 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 Aug 2005 14:37:59 +0200
Subject: [R] power of a matrix
In-Reply-To: <8B08A3A1EA7AAC41BE24C750338754E69FDB7E@HERMES.demogr.mpg.de>
References: <8B08A3A1EA7AAC41BE24C750338754E69FDB7E@HERMES.demogr.mpg.de>
Message-ID: <x2br3wg2mw.fsf@turmalin.kubism.ku.dk>

"Rau, Roland" <Rau at demogr.mpg.de> writes:

> Thank you very much! Thanks also to the authors of this function,
> Vincente Canto Cassola and Martin Maechler!
> 
> This is exactly what I hoped for.
....
> > look at function ?mtx.exp() in the Malmig package, e.g.,

Also, there is mexp() in the Matrix package. I'm not sure about the
relative merits. mexp() is one of the less dubious implementations of
matrix exponentials, but it does require to and from class "Matrix".
mtx.exp is a bit unfortunately named as it appears to calculate matrix
*powers* (which in this case is what you need).

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From spencer.graves at pdf.com  Wed Aug 17 15:15:22 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 17 Aug 2005 08:15:22 -0500
Subject: [R] error in predict glm (new levels cause problems)
In-Reply-To: <1124113194.43009b2a2343d@webmail.unibas.ch>
References: <1124113194.43009b2a2343d@webmail.unibas.ch>
Message-ID: <4303386A.4090403@pdf.com>

	  Have you considered replacing the offending factor with explicit 
coding of your own choosing?  See "?contr.helmert" and in library(MASS) 
"contr.sdif" plus the "contrasts" attribute in "options", obtained, 
e.g., via 'options("contrasts")'.  Every k-level factor is by default 
converted into a set of (k-1) columns of numeric codes.  The exact 
numbers do not matter to p values obtained from anova, though they will 
matter to the coefficients estimated.

	  Have you tried something like the following with "glm.nb":

 > set.seed(1)
 > DF <- data.frame(a=sample(letters[1:3], 30, replace=TRUE),
+                  b=sample(LETTERS[1:3], 30, replace=TRUE),
+                  y=rnorm(30))
 > with(DF, table(a, b))
    b
a   A B C
   a 3 3 3
   b 2 6 3
   c 2 4 4
 > fit1 <- lm(y~a+b, DF[DF$a!="a",])
 > fit1$contrasts
$a
[1] "contr.treatment"

$b
[1] "contr.treatment"

 > options(contrasts=c(unordered="contr.helmert", ordered="contr.poly"))
 > fit2 <- lm(y~a+b, DF[DF$a!="a",])
 > fit2$contrasts
$a
[1] "contr.helmert"

$b
[1] "contr.helmert"

 > anova(fit1)
Analysis of Variance Table

Response: y
           Df Sum Sq Mean Sq F value Pr(>F)
a          1 0.0008  0.0008  0.0015 0.9698
b          2 0.6186  0.3093  0.5775 0.5719
Residuals 17 9.1050  0.5356
 > anova(fit2)
Analysis of Variance Table

Response: y
           Df Sum Sq Mean Sq F value Pr(>F)
a          1 0.0008  0.0008  0.0015 0.9698
b          2 0.6186  0.3093  0.5775 0.5719
Residuals 17 9.1050  0.5356
 >
	  spencer graves

K. Steinmann wrote:

> Dear R-helpers,
> 
> I try to perform glm's with negative binomial distributed data.
> So I use the MASS library and the commands:
> model_1 = glm.nb(response ~ y1 + y2 + ...+ yi, data = data.frame)
> and
> predict(model_1, newdata = data.frame)
> 
> 
> So far, I think everything should be ok.
> 
> But when I want to perform a glm with a subset of the data,
> I run into an error message as soon as I want to predict values, based on the
> new model. The problem seems to be the reduced number of levels of one of the
> factors yi ( a categorical factor) in the subset of the original data set.
> 
> On cran search I found some related hint, that the line "mf$drop.unused.levels
> <- TRUE " in the glm (or glm.nb) function could cause the problem.
> 
> Therefore I changed the line to "mf$drop.unused.levels <- FALSE ".
> Indeed the error message disappears and when I compare the prediction of model_1
> with the prediction of the model, carried out with the full data set but with
> the changed glm.nb function, I get the same predicted numbers.
> 
> However, the change of glm.nb function was more of an intuitive action, and
> since I still consider myself as a beginner of R, I don't feel comfortable.
> 
> So my questions:
> 1. Is there an easier way to solve my problem?
> 2. Do I affect the glm.nb function seriously, by changing the line mentioned
> above?
> 
> 
> Thank you for your help,
> Katharina
> 
> PS: I am working with R 2.0.0
> PPS: Concrete error message:
> "Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
> object$xlevels) :
>         factor I(kanton) has new level(s) GE"
> 
> 
> 
> 
> --
> K. Steinmann
> Botanisches Institut
> Universit??t Basel
> CH-4056 Basel
> Switzerland
> Tel  0041 61 267 35 02
> E-mail: Katharina.Steinmann at stud.unibas.ch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From HDoran at air.org  Wed Aug 17 15:26:15 2005
From: HDoran at air.org (Doran, Harold)
Date: Wed, 17 Aug 2005 09:26:15 -0400
Subject: [R] How to assess significance of random effect in lme4
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7409E5BE0D@dc1ex2.air.org>

These are the posterior variances of the random effects (I think more
properly termed "empirical" posteriors).  Your model apparently includes
three levels of random variation (commu, bcohort, residual). The first
are the variances associated with your commu random effect and the
second are the variances associated with the bcohort random effect.

Accessing either one would require

fm at bVar$commu or fm at bVar$bcohort

Obviously, replace "fm" with the name of your fitted model.

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Shige Song
Sent: Wednesday, August 17, 2005 7:50 AM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] How to assess significance of random effect in lme4

Hi Harold,

Thanks for the reply. I looked at my outputs using str() as you
suggested, here is the part you mentioned:

  ..@ bVar     :List of 2
  .. ..$ commu  : num [1, 1, 1:29] 5e-10 5e-10 5e-10 5e-10 5e-10 ...
  .. ..$ bcohort: num [1, 1, 1:6] 1.05e-05 7.45e-06 6.53e-06 8.25e-06
7.11e-06 ...

where commu and bcohort are the two second-level units. Are these
standard errors? Why the second vector contains a series of different
numbers?

Thanks!

Shige

On 8/17/05, Doran, Harold <HDoran at air.org> wrote:
>  
> 
> You can extract the posterior variance of the random effect from the 
> bVar slot of the fitted lmer model. It is not a hidden option, but a 
> part of the fitted model. It just doesn't show up when you use
summary().
>  
>  Look at the structure of your object to see what is available using
str().
>  
>  However, your comment below seems to imply that it is incorrect for 
> lmer to report SDs instead of the standard error, which is not true. 
> That is a quantity of direct interest.
>  
>  Other multilevel programs report the same exact statistics (for the 
> most part). For instance, HLM reports the variances as well. If you 
> want the posterior variance of an HLM model you need to extract it.
> 
>  
>  
>  -----Original Message-----
>  From:   r-help-bounces at stat.math.ethz.ch on behalf of
> Shige Song
>  Sent:   Wed 8/17/2005 6:30 AM
>  To:     r-help at stat.math.ethz.ch
>  Cc:    
>  Subject:        [R] How to assess significance of random effect in
lme4
>  
>  Dear All,
>  
>  With kind help from several friends on the list, I am getting close.
>  Now here are something interesting I just realized: for random  
> effects, lmer reports standard deviation instead of standard error! Is

> there a hidden option that tells lmer to report standard error of  
> random effects, like most other multilevel or mixed modeling software,

> so that we can say something like "randome effect for xxx is  
> significant, while randome effect for xxx is not significant"? Thanks!
>  
>  Best,
>  Shige
>  
>  ______________________________________________
>  R-help at stat.math.ethz.ch mailing list  
> https://stat.ethz.ch/mailman/listinfo/r-help
>  PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>  
>  
>  
> 
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From fauna at pngp.it  Wed Aug 17 16:25:07 2005
From: fauna at pngp.it (Achaz von Hardenberg)
Date: Wed, 17 Aug 2005 16:25:07 +0200
Subject: [R] resampling Question
Message-ID: <a20cad767ad94da35ef9001adcd360e8@pngp.it>

hi,
sorry for a possibly naive question but I am a bit of a beginner in R programming...

I wrote a function  which simulates some data and performs two different kinds of analyses on it. as an output I get the statistics for the two analyses (t-values). Now I would like to have an other function which reruns my first function say a 1000 times and attaches the resulting statistics in a data.frame so that at the end it contains 1000 rows with two columns for the two statistics I calculated with my first function.

I hope I was clear enugh and would be glad to anybody who can help me out!

ciao,
 
Achaz von Hardenberg
--------------------------------------------------------------------------------------
Centro Studi Fauna Alpina - Alpine Wildlife Research Centre
Parco Nazionale Gran Paradiso, via della Rocca 47, 10123 Torino, Italy

e-mail: fauna at pngp.it
Tel. (office): +39.011.8606212
Tel. (mobile): +39.328.8736291
Fax: +39.011.8121305
--------------------------------------------------------------------------------------
Open access to all papers published in the Journal of Mountain Ecology:
http://www.mountainecology.org

GSE-AIESG (Gruppo Stambecco Europa - Alpine Ibex European Specialist Group):
http://www.gseonline.org



From p.dalgaard at biostat.ku.dk  Wed Aug 17 16:42:56 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 17 Aug 2005 16:42:56 +0200
Subject: [R] resampling Question
In-Reply-To: <a20cad767ad94da35ef9001adcd360e8@pngp.it>
References: <a20cad767ad94da35ef9001adcd360e8@pngp.it>
Message-ID: <x23bp8fwun.fsf@turmalin.kubism.ku.dk>

"Achaz von Hardenberg" <fauna at pngp.it> writes:

> hi,
> sorry for a possibly naive question but I am a bit of a beginner in R programming...
> 
> I wrote a function which simulates some data and performs two
> different kinds of analyses on it. as an output I get the statistics
> for the two analyses (t-values). Now I would like to have an other
> function which reruns my first function say a 1000 times and
> attaches the resulting statistics in a data.frame so that at the end
> it contains 1000 rows with two columns for the two statistics I
> calculated with my first function.
> 
> I hope I was clear enugh and would be glad to anybody who can help me out!

replicate is a good start:

> replicate(10,t.test(rexp(10),mu=1)[c("statistic","p.value")])
          [,1]      [,2]      [,3]       [,4]      [,5]       [,6]
statistic -1.552478 -1.09727  -2.053807  -1.671855 -0.1169578 0.1005037
p.value   0.1549645 0.3010120 0.07018008 0.1288855 0.9094619  0.9221477
          [,7]       [,8]      [,9]      [,10]
statistic -0.1711356 -0.933484 0.3169710 -1.136498
p.value   0.867903   0.3749356 0.758495  0.2851029

As you see, the result is a 2xn matrix. If you really need a data
frame, just use as.data.frame(t(....)),  or (bypassing the matrix
entirely):

> do.call("rbind",replicate(10,as.data.frame(
   t.test(rexp(10),mu=1)[c("statistic","p.value")]), simplify=FALSE))
     statistic   p.value
t   0.32566430 0.7521223
t1 -1.22741479 0.2508023
t2 -1.66792987 0.1296757
t3  1.56440274 0.1521619
t4  0.63778111 0.5395015
t5 -1.03826715 0.3262346
t6  0.09337127 0.9276542
t7  0.90166085 0.3907282
t8 -0.78164107 0.4544958
t9 -0.39766367 0.7001452


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From ahenningsen at email.uni-kiel.de  Wed Aug 17 16:48:47 2005
From: ahenningsen at email.uni-kiel.de (Arne Henningsen)
Date: Wed, 17 Aug 2005 16:48:47 +0200
Subject: [R] Fwd: Documenting data sets with many variables
In-Reply-To: <1124205995.8689.52.camel@gsimpson.geog.ucl.ac.uk>
References: <200508161104.27017.ahenningsen@email.uni-kiel.de>
	<200508161711.50444.ahenningsen@email.uni-kiel.de>
	<1124205995.8689.52.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <200508171648.47150.ahenningsen@email.uni-kiel.de>

On Tuesday 16 August 2005 17:26, Gavin Simpson wrote:
> On Tue, 2005-08-16 at 17:11 +0200, Arne Henningsen wrote:
> > On Tuesday 16 August 2005 14:49, Roger D. Peng wrote:
> > > Have you tried using 'promptData()' on the data frame and then
> > > just using the resulting documentation file?
> >
> > Thank you, Roger, for bringing 'promptData()' to my mind. This is really
> > a useful tool. However, in my special case my aim is to reduce the extent
> > and increase the comprehensibility of the documentation rather than to
> > reduce my effort to write the documentation.
> >
> > Any further hints are welcome!
> >
> > Thanks,
> > Arne
>
> Would it not be expedient then to ignore the \format{} section and just
> provide the information on the variables say in the \description{},
> e.g.:

That's a great idea - and so simple!
This perfectly solves my problem.
Thanks,
Arne

> This example taken from package vegan describing 2 data.frames with 44
> and 14 columns. Admittedly, none of the variables in the species dataset
> are explicitly and individually described in this example, but it is
> sufficient in this case I think.
>
> \name{varespec}
> \alias{varechem}
> \alias{varespec}
> \docType{data}
> \title{Vegetation and environment in lichen pastures}
> \usage{
>        data(varechem)
>        data(varespec)
> }
> \description{
>   The \code{varespec} data frame has 24 rows and 44 columns.  Columns
>   are estimated cover values of 44 species.  The variable names are
>   formed from the scientific names, and are self explanatory for anybody
>   familiar with the vegetation type.
> The \code{varechem} data frame has 24 rows and 14 columns, giving the
> soil characteristics of the very same sites as in the \code{varespec}
> data frame. The chemical measurements have obvious names.
> \code{Baresoil} gives the estimated cover of bare soil, \code{Humpdepth}
> the thickness of the humus layer.
>
> }
> ....
>
> HTH
>
> G
>
> > > -roger
> > >
> > > Arne Henningsen wrote:
> > > > Hi,
> > > >
> > > > since nobody answered to my first message, I try to explain my
> > > > problem more clearly and more general this time:
> > > >
> > > > I have a data set in my R package "micEcon", which has many variables
> > > > (82). Therefore, I would like to avoid to describe all variables in
> > > > the "\format" section of the documentation (.Rd file). However, doing
> > > > this lets "R CMD check" complain about "data codoc mismatches"
> > > > (details see below). Is there a way to avoid the description of all
> > > > variables without getting a complaint from "R CMD check"?
> > > >
> > > > Thanks,
> > > > Arne
> > > >
> > > >
> > > > ----------  Forwarded Message  ----------
> > > >
> > > > Subject: Documenting data sets with many variables
> > > > Date: Friday 05 August 2005 14:03
> > > > From: Arne Henningsen <ahenningsen at email.uni-kiel.de>
> > > > To: R-help at stat.math.ethz.ch
> > > >
> > > > Hi,
> > > >
> > > > I extended the data set "Blanciforti86" that is included in my R
> > > > package "micEcon". For instance, I added consumer prices, annual
> > > > consumption expenditures and expenditure shares of eleven aggregate
> > > > commodity groups. The corresponding variables in the data frame are
> > > > called "pAgg1", "pAgg2", ..., "pAgg11", "xAgg1", "xAgg2", ...,
> > > > "xAgg11", "wAgg1", "wAgg2", ..., "wAgg11". To avoid to describe all
> > > > 33 items in the "\format" section of the documentation (.Rd file) I
> > > > wrote something like
> > > >
> > > > \format{
> > > >    This data frame contains the following columns:
> > > >    \describe{
> > > >       [ . . . ]
> > > >       \item{xAggX}{Expenditure on the aggregate commodity group X
> > > >          (in Millions of US-Dollars).}
> > > >       \item{pAggX}{Price index for the aggregate commodity group X
> > > >          (1972 = 100).}
> > > >       \item{wAggX}{Expenditure share of the aggregate commodity group
> > > > X.} [ . . . ]
> > > >    }
> > > > }
> > > >
> > > > and explained the 11 aggregate commodity groups only once in a
> > > > different section (1=food, 2=clothing, ... ). However, "R CMD check"
> > > > now complains about "data codoc mismatches", e.g.
> > > >   Code: [...] pAgg1pAgg2 pAgg3  [...]
> > > >   Docs: [...] pAggX [...]
> > > >
> > > > Is there a way to avoid the description of all 33 items without
> > > > getting a complaint from "R CMD check"?
> > > >
> > > > Thanks,
> > > > Arne
> > > >
> > > > -------------------------------------------------------

-- 
Arne Henningsen
Department of Agricultural Economics
University of Kiel
Olshausenstr. 40
D-24098 Kiel (Germany)
Tel: +49-431-880 4445
Fax: +49-431-880 1397
ahenningsen at agric-econ.uni-kiel.de
http://www.uni-kiel.de/agrarpol/ahenningsen/



From snvk4u at gmail.com  Wed Aug 17 16:49:13 2005
From: snvk4u at gmail.com (Krishna)
Date: Wed, 17 Aug 2005 20:19:13 +0530
Subject: [R] optimal hedge variance ratio
Message-ID: <139ef1c205081707493b542ced@mail.gmail.com>

Hi All,

I am trying to finding out what could be an optimal hedge variance
ratio between spot and futures markets, between whose the degree of
correlation is highly varying.

For some reasons the hedge time period cannot extend for more than 1
month. So just to get an hint, I have calculated monthly correlation
coefficients which are highly varying. I am copying the frequency
distribution of monthly correlation coefficient values
(karl-pearsons') to indicating the degree of volatility.

Corre 
range	Frequency	
-0.7	0	0.00%
-0.5	2	3.08%
-0.3	3	4.62%
0	7	10.77%
0.3	7	10.77%
0.5	6	9.23%
0.7	16	24.62%
0.9	15	23.08%
1	9	13.85%

Can someone throw light on which model to use and how to approach for
desiging a hedge model (estimate hedge variance ratio) in such a
scenario. Help requested at the earliest.

thanks for the attention and best rgds

snvk



From bstabler at ptvamerica.com  Wed Aug 17 16:52:42 2005
From: bstabler at ptvamerica.com (Ben Stabler)
Date: Wed, 17 Aug 2005 07:52:42 -0700
Subject: [R] RODBC and sqlColumns
In-Reply-To: <Pine.LNX.4.61.0508170851570.16535@gannet.stats>
Message-ID: <000a01c5a33b$523c2b00$0200a8c0@STABLERLAPTOP>

Ok, I understand that.  Then, how do I get the columns for a table that
is housed in a schema?  And, second, why does the following not work (or
at least partially work).  It creates the new table in the X schema but
then does not populate the table (and returns a sqlColumns() error.

sqlSave(db,x,"X.test",T,F)

Thanks.

Ben Stabler
Project Manager
PTV America, Inc.
1128 NE 2nd St, Suite 204
Corvallis, OR 97330
541-754-6836 x205
541-754-6837 fax
www.ptvamerica.com



-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Wednesday, August 17, 2005 12:59 AM
To: Ben Stabler
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] RODBC and sqlColumns


AFAIK "." is not a valid part of an SQL table name. I think the help
files 
are perfectly clear as to what is supported:

  sqtable: character: a database table name accessible from the
           connected dsn.

Why do you think "X.test" is a `database table name'?

On Tue, 16 Aug 2005, Ben Stabler wrote:

> I have a Postgres database that I am connecting to with the Postgres 
> ODBC driver on Windows XP in R 2.1.0.  In the database is a database 
> with two schemas (public and X).  With RODBC (1.1-4) , I can connect 
> to the database and get the tables with sqlTables(db).  I can query 
> tables in the schema with sqlQuery("SELECT * FROM X.test").  However, 
> I can't get the columns in table X.test with sqlColumns(db,"X.test") 
> //it returns
>
> Error in sqlColumns(db, "X.test") : 'X.test': table not found on 
> channel
>
> If I do
>
> sqlColumns(db, "test") it returns
> [1] TABLE_QUALIFIER   TABLE_OWNER       TABLE_NAME        COLUMN_NAME
> DATA_TYPE
> [6] TYPE_NAME         PRECISION         LENGTH            SCALE
> RADIX
> [11] NULLABLE          REMARKS           COLUMN_DEF
SQL_DATA_TYPE
> SQL_DATETIME_SUB
> [16] CHAR_OCTET_LENGTH ORDINAL_POSITION  IS_NULLABLE
DISPLAY_SIZE
> FIELD_TYPE
> <0 rows> (or 0-length row.names)
>
> But there is no test table defined anywhere else but the X schema.  If

> I do sqlSave(db,aDataFrame,"X.test",T,F), it says test already 
> defined. If I change the aDataFrame to be different than the fields 
> actually in the data, then R starts to create a new table but returns
>
> Error in sqlColumns(db, "X.test") : 'X.test': table not found on 
> channel
>
> It seems to be having problems with what is returned by the 
> columns.....since
>
> Error in sqlSave(db, aDataFrame, "X.test", T, F) :
>        [RODBC] ERROR: Could not SQLExecDirectS1000 7 ERROR:  relation 
> "test" already exists
>
> but if I change the input table to be different....then R can create 
> the table, but fails to populate it.  I checked the db in PgAdmin and 
> the table is created by the sqlSave call.  All this stuff works if I 
> don't use a schema "schema.table".  So it appears there is something 
> wrong in some place dealing with understanding the columns for tables 
> in schemas.
>
> Any ideas?  Any help would be much appreciated.  Thank you.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sdavis2 at mail.nih.gov  Wed Aug 17 18:09:01 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 17 Aug 2005 12:09:01 -0400
Subject: [R] Fitting mixture model
Message-ID: <BF28D95D.C9CC%sdavis2@mail.nih.gov>

I would like to fit a gaussian mixture model to a vector with about 50,000
points.  I have tried using Mclust to do so, but 50,000 points requires more
memory than I have (and I am running with 4Gb).  Any other suggestions for
how to do so?  Oh, I don't know the number of components, but the number
will likely be less than 5 or 6.

Thanks,
Sean



From chrish at stats.ucl.ac.uk  Wed Aug 17 18:20:52 2005
From: chrish at stats.ucl.ac.uk (Christian Hennig)
Date: Wed, 17 Aug 2005 17:20:52 +0100 (BST)
Subject: [R] Fitting mixture model
In-Reply-To: <BF28D95D.C9CC%sdavis2@mail.nih.gov>
References: <BF28D95D.C9CC%sdavis2@mail.nih.gov>
Message-ID: <Pine.LNX.4.58.0508171719570.1398@egon.stats.ucl.ac.uk>

I don't know if and how exactly it works for your data but package flexmix
should also allow to fit Gaussian mixtures.

Christian

On Wed, 17 Aug 2005, Sean Davis wrote:

> I would like to fit a gaussian mixture model to a vector with about 50,000
> points.  I have tried using Mclust to do so, but 50,000 points requires more
> memory than I have (and I am running with 4Gb).  Any other suggestions for
> how to do so?  Oh, I don't know the number of components, but the number
> will likely be less than 5 or 6.
>
> Thanks,
> Sean
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

*** NEW ADDRESS! ***
Christian Hennig
University College London, Department of Statistical Science
Gower St., London WC1E 6BT, phone +44 207 679 1698
chrish at stats.ucl.ac.uk, www.homepages.ucl.ac.uk/~ucakche



From deepayan.sarkar at gmail.com  Wed Aug 17 18:42:06 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Wed, 17 Aug 2005 11:42:06 -0500
Subject: [R] Labels on axes with log scales with lattice
In-Reply-To: <7f50836c0508141247153bf360@mail.gmail.com>
References: <7f50836c0508141247153bf360@mail.gmail.com>
Message-ID: <eb555e66050817094269269065@mail.gmail.com>

On 8/14/05, Jamieson Cobleigh <cobleigh at gmail.com> wrote:
> I using lattice to make some plots and I want to make the y-axis on
> some of these plots use a log scale.  In the following plot:
> 
> x <- 1:10
> y <- 2^x
> xyplot(log10(y) ~ x)
> 
> I get tick marks on the y-axis at 0.5, 1.0, 1.5, 2.0, 2.5, and 3.0.  I
> would rather have just 3 tick marks at 1.0, 2.0, and 3.0 but labeled
> 10, 100, and 1000.
> 
> I know this can be done using the "at" and "labels" parameters to the
> "x" parameter to the "scales" parameter to the "xyplot" command.
> 
> xyplot(log10(y) ~ x, scales=list(y=list(at=c(1, 2, 3), labels=c(10,
> 100, 1000))))
> 
> My problem is that I am making multiple plots and cannot set the
> labels on each plot individually.  I need to automate the computation
> of the "at" and "labels" parameters.  I think the "axTicks" command
> can compute the information I need to set "at" and "labels" correctly,
> but I am having trouble determining how to set its parameters to make
> it compute the information I need.  Perhaps "pretty" might work to,
> but "axTicks" seems better designed for handling logarithmic axes.
> 
> Does anyone have any suggestions?

The `right' way to do this is 

xyplot(y ~ x, scales = list(y = list(log = 10)))

Unfortunately, the labeling for this doesn't use axTicks, it takes the
easy way out by using labels of the form "10^2", "10^3", etc. This is
partly due to laziness on my part, and also the fact that axTicks
doesn't support all the features 'scales' claims to.

My intended `solution' to this (currently vapourware) is to allow the
user to specify a function to calculate tick positions and labels. In
principle, this could be useful for other transformations, e.g. sqrt
for rootograms. I haven't thought through what the API for this would
be like, and I don't know when I will get around to actually
implementing it.

Deepayan



From valderama at gmail.com  Wed Aug 17 18:43:51 2005
From: valderama at gmail.com (Laurent Valdes)
Date: Wed, 17 Aug 2005 18:43:51 +0200
Subject: [R] Dots in models formulae
In-Reply-To: <Pine.LNX.4.61.0508162002020.4224@gannet.stats>
References: <165FE2B0-9BF3-4B74-8DB8-1BD36790300F@gmail.com>
	<43021F7D.9030300@statistik.uni-dortmund.de>
	<43022155.5090901@pdf.com>
	<1124214596.8689.113.camel@gsimpson.geog.ucl.ac.uk>
	<Pine.LNX.4.61.0508162002020.4224@gannet.stats>
Message-ID: <3ef00e1605081709437543e448@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050817/f5062f49/attachment.pl

From mark.salsburg at gmail.com  Wed Aug 17 18:48:21 2005
From: mark.salsburg at gmail.com (mark salsburg)
Date: Wed, 17 Aug 2005 12:48:21 -0400
Subject: [R] Classifying values in vector
Message-ID: <dd48e20f050817094848c213b0@mail.gmail.com>

I have a vector of size 217 called "A".

the values of A are not sorted and range from 0 to 1 (normalized)

I am having difficulty writing a program to create a new vector "B" where

if A's value is 0< A <=0.333 then B is 0
if A's value is 0.333< A <=0.666 then B is 1
if A's value is 0.666< A <=1 then B is 2

so if A is

0.22
0.999
0.444
0

B would be

0
2
1
0

thank you,



From sundar.dorai-raj at pdf.com  Wed Aug 17 18:55:03 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 17 Aug 2005 11:55:03 -0500
Subject: [R] Classifying values in vector
In-Reply-To: <dd48e20f050817094848c213b0@mail.gmail.com>
References: <dd48e20f050817094848c213b0@mail.gmail.com>
Message-ID: <43036BE7.1080508@pdf.com>



mark salsburg wrote:
> I have a vector of size 217 called "A".
> 
> the values of A are not sorted and range from 0 to 1 (normalized)
> 
> I am having difficulty writing a program to create a new vector "B" where
> 
> if A's value is 0< A <=0.333 then B is 0
> if A's value is 0.333< A <=0.666 then B is 1
> if A's value is 0.666< A <=1 then B is 2
> 
> so if A is
> 
> 0.22
> 0.999
> 0.444
> 0
> 
> B would be
> 
> 0
> 2
> 1
> 0
> 
> thank you,

Sounds like you are looking for ?cut:

 > A <- runif(217)
 > B <- cut(A, c(0, 1/3, 2/3, 1), labels = c(0, 1, 2))
 > # convert factor to numeric
 > as.numeric(levels(B)[B])

HTH,

--sundar



From sundar.dorai-raj at pdf.com  Wed Aug 17 18:57:37 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 17 Aug 2005 11:57:37 -0500
Subject: [R] Classifying values in vector
In-Reply-To: <dd48e20f050817094848c213b0@mail.gmail.com>
References: <dd48e20f050817094848c213b0@mail.gmail.com>
Message-ID: <43036C81.6050605@pdf.com>



mark salsburg wrote:
> I have a vector of size 217 called "A".
> 
> the values of A are not sorted and range from 0 to 1 (normalized)
> 
> I am having difficulty writing a program to create a new vector "B" where
> 
> if A's value is 0< A <=0.333 then B is 0
> if A's value is 0.333< A <=0.666 then B is 1
> if A's value is 0.666< A <=1 then B is 2
> 
> so if A is
> 
> 0.22
> 0.999
> 0.444
> 0
> 
> B would be
> 
> 0
> 2
> 1
> 0
> 
> thank you,
> 

Didn't look closely at your example. If "A" can == zero then you need to 
include "include.lowest = TRUE" in your call to cut. This would mean 
your breaks are:

if A's value is 0 <= A <=0.333 then B is 0

which is different from what you have written above.


--sundar



From mark.salsburg at gmail.com  Wed Aug 17 19:25:58 2005
From: mark.salsburg at gmail.com (mark salsburg)
Date: Wed, 17 Aug 2005 13:25:58 -0400
Subject: [R] Concurrence Matrix
Message-ID: <dd48e20f05081710251c557f31@mail.gmail.com>

Thank you for all the help.

Can someone refer me to a function that can help with the creation of
a concurrence matrix?

I have two asymmetric vectors (C is length 217 and D is length 16063)
that contain values of 0,1,2

I want to create a matrix E (where rows are D and columns are C)  that
ouputs a score where

if C and D are the same number then E has value 1
if C and D are different numbers (i.e. 0 and 1, or 2 and 1) then E has a value 0

so for example:

so if C is c(0,0,2,1,0,0)
and  D is c(0,0,1,1,1,1,1,1)

E would look like:

      C      0  0  2  1  0  0

D    0      1  1  0  0  0  0  
      0      1  1  0  0  1  1
      1      0  0  0  1  0  0
      1      0  0  0  1  0  0
      1      0  0  0  1  0  0 
      1      0  0  0  1  0  0
      1      0  0  0  1  0  0 
      1      0  0  0  1  0  0



From aniko.szabo at hci.utah.edu  Wed Aug 17 19:33:39 2005
From: aniko.szabo at hci.utah.edu (Aniko Szabo)
Date: Wed, 17 Aug 2005 11:33:39 -0600
Subject: [R] accesing slots of S4 class in C code
Message-ID: <2372A3FFAF50104B9929841F6B9B878302109309@EMAIL.hci.utah.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050817/688f1821/attachment.pl

From gunter.berton at gene.com  Wed Aug 17 19:36:33 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Wed, 17 Aug 2005 10:36:33 -0700
Subject: [R] Concurrence Matrix
In-Reply-To: <dd48e20f05081710251c557f31@mail.gmail.com>
Message-ID: <200508171736.j7HHaXYk018035@hertz.gene.com>

?outer
Use "!=" for FUN and convert to numeric with as.numeric() if you like.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of mark salsburg
> Sent: Wednesday, August 17, 2005 10:26 AM
> To: R-help at stat.math.ethz.ch
> Subject: [R] Concurrence Matrix
> 
> Thank you for all the help.
> 
> Can someone refer me to a function that can help with the creation of
> a concurrence matrix?
> 
> I have two asymmetric vectors (C is length 217 and D is length 16063)
> that contain values of 0,1,2
> 
> I want to create a matrix E (where rows are D and columns are C)  that
> ouputs a score where
> 
> if C and D are the same number then E has value 1
> if C and D are different numbers (i.e. 0 and 1, or 2 and 1) 
> then E has a value 0
> 
> so for example:
> 
> so if C is c(0,0,2,1,0,0)
> and  D is c(0,0,1,1,1,1,1,1)
> 
> E would look like:
> 
>       C      0  0  2  1  0  0
> 
> D    0      1  1  0  0  0  0  
>       0      1  1  0  0  1  1
>       1      0  0  0  1  0  0
>       1      0  0  0  1  0  0
>       1      0  0  0  1  0  0 
>       1      0  0  0  1  0  0
>       1      0  0  0  1  0  0 
>       1      0  0  0  1  0  0
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From Ted.Harding at nessie.mcc.ac.uk  Wed Aug 17 19:57:36 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Wed, 17 Aug 2005 18:57:36 +0100 (BST)
Subject: [R] Concurrence Matrix
In-Reply-To: <dd48e20f05081710251c557f31@mail.gmail.com>
Message-ID: <XFMail.050817185736.Ted.Harding@nessie.mcc.ac.uk>

On 17-Aug-05 mark salsburg wrote:
> Thank you for all the help.
> 
> Can someone refer me to a function that can help with the creation of
> a concurrence matrix?
> 
> I have two asymmetric vectors (C is length 217 and D is length 16063)
> that contain values of 0,1,2
> 
> I want to create a matrix E (where rows are D and columns are C)  that
> ouputs a score where
> 
> if C and D are the same number then E has value 1
> if C and D are different numbers (i.e. 0 and 1, or 2 and 1) then E has
> a value 0
> 
> so for example:
> 
> so if C is c(0,0,2,1,0,0)
> and  D is c(0,0,1,1,1,1,1,1)
> 
> E would look like:
> 
>       C      0  0  2  1  0  0
> 
> D    0      1  1  0  0  0  0  
>       0      1  1  0  0  1  1
>       1      0  0  0  1  0  0
>       1      0  0  0  1  0  0
>       1      0  0  0  1  0  0 
>       1      0  0  0  1  0  0
>       1      0  0  0  1  0  0 
>       1      0  0  0  1  0  0

It looks as though

  1*outer(D,C,"==")

does what you want (and shows up that E[1,5] and E[1,6] seem
to be wrong in your example, since D[1] = C[5] = 0 and
D[1] = C[6] = 0).

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 17-Aug-05                                       Time: 18:56:49
------------------------------ XFMail ------------------------------



From u08adh at hotmail.com  Wed Aug 17 20:39:57 2005
From: u08adh at hotmail.com (Andreas Hary)
Date: Wed, 17 Aug 2005 19:39:57 +0100
Subject: [R] RODBC and sqlColumns
References: <000a01c5a33b$523c2b00$0200a8c0@STABLERLAPTOP>
Message-ID: <BAY103-DAV167C33CF4B0C90CB4E77ACDFB30@phx.gbl>

Try append = F, that works for me.

A


----- Original Message ----- 
From: "Ben Stabler" <bstabler at ptvamerica.com>
To: <r-help at stat.math.ethz.ch>
Sent: Wednesday, August 17, 2005 3:52 PM
Subject: Re: [R] RODBC and sqlColumns


> Ok, I understand that.  Then, how do I get the columns for a table that
> is housed in a schema?  And, second, why does the following not work (or
> at least partially work).  It creates the new table in the X schema but
> then does not populate the table (and returns a sqlColumns() error.
>
> sqlSave(db,x,"X.test",T,F)
>
> Thanks.
>
> Ben Stabler
> Project Manager
> PTV America, Inc.
> 1128 NE 2nd St, Suite 204
> Corvallis, OR 97330
> 541-754-6836 x205
> 541-754-6837 fax
> www.ptvamerica.com
>
>
>
> -----Original Message-----
> From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk]
> Sent: Wednesday, August 17, 2005 12:59 AM
> To: Ben Stabler
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] RODBC and sqlColumns
>
>
> AFAIK "." is not a valid part of an SQL table name. I think the help
> files
> are perfectly clear as to what is supported:
>
>  sqtable: character: a database table name accessible from the
>           connected dsn.
>
> Why do you think "X.test" is a `database table name'?
>
> On Tue, 16 Aug 2005, Ben Stabler wrote:
>
>> I have a Postgres database that I am connecting to with the Postgres
>> ODBC driver on Windows XP in R 2.1.0.  In the database is a database
>> with two schemas (public and X).  With RODBC (1.1-4) , I can connect
>> to the database and get the tables with sqlTables(db).  I can query
>> tables in the schema with sqlQuery("SELECT * FROM X.test").  However,
>> I can't get the columns in table X.test with sqlColumns(db,"X.test")
>> //it returns
>>
>> Error in sqlColumns(db, "X.test") : 'X.test': table not found on
>> channel
>>
>> If I do
>>
>> sqlColumns(db, "test") it returns
>> [1] TABLE_QUALIFIER   TABLE_OWNER       TABLE_NAME        COLUMN_NAME
>> DATA_TYPE
>> [6] TYPE_NAME         PRECISION         LENGTH            SCALE
>> RADIX
>> [11] NULLABLE          REMARKS           COLUMN_DEF
> SQL_DATA_TYPE
>> SQL_DATETIME_SUB
>> [16] CHAR_OCTET_LENGTH ORDINAL_POSITION  IS_NULLABLE
> DISPLAY_SIZE
>> FIELD_TYPE
>> <0 rows> (or 0-length row.names)
>>
>> But there is no test table defined anywhere else but the X schema.  If
>
>> I do sqlSave(db,aDataFrame,"X.test",T,F), it says test already
>> defined. If I change the aDataFrame to be different than the fields
>> actually in the data, then R starts to create a new table but returns
>>
>> Error in sqlColumns(db, "X.test") : 'X.test': table not found on
>> channel
>>
>> It seems to be having problems with what is returned by the
>> columns.....since
>>
>> Error in sqlSave(db, aDataFrame, "X.test", T, F) :
>>        [RODBC] ERROR: Could not SQLExecDirectS1000 7 ERROR:  relation
>> "test" already exists
>>
>> but if I change the input table to be different....then R can create
>> the table, but fails to populate it.  I checked the db in PgAdmin and
>> the table is created by the sqlSave call.  All this stuff works if I
>> don't use a schema "schema.table".  So it appears there is something
>> wrong in some place dealing with understanding the columns for tables
>> in schemas.
>>
>> Any ideas?  Any help would be much appreciated.  Thank you.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From dhinds at sonic.net  Wed Aug 17 20:39:08 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Wed, 17 Aug 2005 18:39:08 +0000 (UTC)
Subject: [R] Raw data type transformations
Message-ID: <de008c$fc8$1@sea.gmane.org>

Not sure if this belongs here or on the devel list:

I've needed a more efficient way to manipulate raw binary data in R,
with more than the minimal raw transformation functions in the base
package.  So I've written a small package in C that effectively lets
me cast back and forth between raw vectors and other data types.

I've implemented four functions: rawToHex, hexToRaw, readRaw, and
writeRaw.  The first two convert between raw vectors and hex character
strings.  I use these to work around a limitation of ROracle not
directly supporting raw data types, but they may have other uses.
readRaw and writeRaw are similar to readBin and writeBin, but operate
on raw vectors in place of binary connections, and I took a few
shortcuts in my implementation (I handle a subset of data types and
didn't implement byte swapping).

[aside: Rinternals.h does not export RAW() for packages]

I first thought there might be a way to do this via connections but
didn't want to actually read and write files just to map between data
types.  One option would be to implement a rawConnection() analog of
the current textConnection(), which would associate raw vectors with
binary connections, and allow readBin()/writeBin().

Looking at the text connection code, it seems to me that it could be
extended to handle this fairly easily.  For input connections, it
appears that all that needs to be done is to add support for filling
the internal buffer from a raw vector (a few lines of code), and
adding a text_read() function (again just a few lines).  For output,
text_write() is similarly simple, and a few lines of code would need
to be added to text_vfprintf() to handle copying to a raw vector in
place of a character vector.

The text_* functions would then probably be better named internal_*
since they would handle internal binary as well as internal text
connections.

Does this sound like it would be a useful capability?

-- David Hinds



From tmlammail at yahoo.com  Wed Aug 17 21:02:07 2005
From: tmlammail at yahoo.com (Martin Lam)
Date: Wed, 17 Aug 2005 12:02:07 -0700 (PDT)
Subject: [R]  Copying rows from a matrix using a vector of indices
Message-ID: <20050817190207.77099.qmail@web40508.mail.yahoo.com>

Hi,

I am trying to use a vector of indices to select some
rows from a matrix. But before I can do that I somehow
need to convert 'combinations' into a list, since
'mode(combinations)' says it's 'numerical'. Any idea
how I can do that?

library("combinat")

combinations <- t(combn(8,2))

indices <- c(sample(1:length(combinations),10))

# convert
???

subset <- combinations[indices]

Thanks in advance,

Martin



From ghather at berkeley.edu  Wed Aug 17 21:12:36 2005
From: ghather at berkeley.edu (Greg Hather)
Date: Wed, 17 Aug 2005 12:12:36 -0700
Subject: [R] trouble with wilcox.test
Message-ID: <001801c5a35f$a0de7000$43fde5a9@PC232921052285>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050817/ce7d67f3/attachment.pl

From yhu at mail.nih.gov  Wed Aug 17 22:07:42 2005
From: yhu at mail.nih.gov (Hu, Ying (NIH/NCI))
Date: Wed, 17 Aug 2005 16:07:42 -0400
Subject: [R] do glm with two data sets
Message-ID: <27C204BD76CBC142BA1AE46D62A8548E490BFB@nihexchange9.nih.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050817/4ce03446/attachment.pl

From mschwartz at mn.rr.com  Wed Aug 17 22:10:31 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Wed, 17 Aug 2005 15:10:31 -0500
Subject: [R] Copying rows from a matrix using a vector of indices
In-Reply-To: <20050817190207.77099.qmail@web40508.mail.yahoo.com>
References: <20050817190207.77099.qmail@web40508.mail.yahoo.com>
Message-ID: <1124309431.5913.56.camel@localhost.localdomain>

On Wed, 2005-08-17 at 12:02 -0700, Martin Lam wrote:
> Hi,
> 
> I am trying to use a vector of indices to select some
> rows from a matrix. But before I can do that I somehow
> need to convert 'combinations' into a list, since
> 'mode(combinations)' says it's 'numerical'. Any idea
> how I can do that?
> 
> library("combinat")
> 
> combinations <- t(combn(8,2))
> 
> indices <- c(sample(1:length(combinations),10))
> 
> # convert
> ???
> 
> subset <- combinations[indices]
> 
> Thanks in advance,
> 
> Martin


Your goal is not entirely clear.  Given your code above, you end up
with:

> library("combinat")
> 
> combinations <- t(combn(8,2))
> combinations
      [,1] [,2]
 [1,]    1    2
 [2,]    1    3
 [3,]    1    4
 [4,]    1    5
 [5,]    1    6
 [6,]    1    7
 [7,]    1    8
 [8,]    2    3
 [9,]    2    4
[10,]    2    5
[11,]    2    6
[12,]    2    7
[13,]    2    8
[14,]    3    4
[15,]    3    5
[16,]    3    6
[17,]    3    7
[18,]    3    8
[19,]    4    5
[20,]    4    6
[21,]    4    7
[22,]    4    8
[23,]    5    6
[24,]    5    7
[25,]    5    8
[26,]    6    7
[27,]    6    8
[28,]    7    8

combinations is a 28 x 2 matrix (or a 1d vector of length 56).

Your use of sample() with '1:length(combinations)' is the same as 1:56.

> length(combinations)
[1] 56

Hence, you end up with:

> set.seed(128)
> indices <- sample(1:length(combinations), 10)

> indices
 [1] 41 53 38 46 50 44 25 11 43  7


I suspect that you really want to use '1:nrow(combinations)', which
yields 1:28.

> nrow(combinations)
[1] 28


Thus,

> set.seed(128)
> indices <- sample(1:nrow(combinations), 10)

> indices
 [1] 21 26 18 22 23 20 11  5 27  3


Now, you can use:

> subset <- combinations[indices, ]
> subset
      [,1] [,2]
 [1,]    4    7
 [2,]    6    7
 [3,]    3    8
 [4,]    4    8
 [5,]    5    6
 [6,]    4    6
 [7,]    2    6
 [8,]    1    6
 [9,]    6    8
[10,]    1    4

which yields the rows from combinations, defined by 'indices'.

If correct, please review "An Introduction to R" and ?"[" for more
information on subsetting objects in R.

HTH,

Marc Schwartz



From dhiren22 at hotmail.com  Wed Aug 17 23:26:52 2005
From: dhiren22 at hotmail.com (Dhiren DSouza)
Date: Wed, 17 Aug 2005 17:26:52 -0400
Subject: [R]  plotting issue with timestamps
Message-ID: <BAY102-F31FAD5E664A6BCE6F93513D3B30@phx.gbl>

I have a dataset with transactions and a timestamp at which they occoured 
during a day.  The time stamp is in the format YYYY/MM/DD hh:mm:ss.  I would 
like to plot a timeseries of the transactions to see if there is a 
particular time in the day when there is a spike in transactions.  Ofcourse 
the YYYY/MM/DD can be dropped since I am monitoring activity for the day and 
the actual date is unimportant.

Can anyone give me some direction on this.  I could possibly build a 
frequency table but not sure how to plot against the timestamp in the format 
above.  Any help would be appreciated.

-Dhiren



From ogabbrie at tin.it  Wed Aug 17 23:27:36 2005
From: ogabbrie at tin.it (Simone Gabbriellini)
Date: Wed, 17 Aug 2005 23:27:36 +0200
Subject: [R] newbie- how to add a row to a matrix
Message-ID: <C298B619-1802-4D0C-B56B-636D8ECD642B@tin.it>

dear list,
if I have a matrix

s<-matrix(1:5, ncol=5)

how can I add another row with other data to that matrix?

thank you,
simone



From sundar.dorai-raj at pdf.com  Wed Aug 17 23:42:23 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 17 Aug 2005 16:42:23 -0500
Subject: [R] newbie- how to add a row to a matrix
In-Reply-To: <C298B619-1802-4D0C-B56B-636D8ECD642B@tin.it>
References: <C298B619-1802-4D0C-B56B-636D8ECD642B@tin.it>
Message-ID: <4303AF3F.8040803@pdf.com>

?rbind

Simone Gabbriellini wrote:
> dear list,
> if I have a matrix
> 
> s<-matrix(1:5, ncol=5)
> 
> how can I add another row with other data to that matrix?
> 
> thank you,
> simone
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From kylelundstedt at hotmail.com  Wed Aug 17 23:51:00 2005
From: kylelundstedt at hotmail.com (Kyle G. Lundstedt)
Date: Wed, 17 Aug 2005 14:51:00 -0700
Subject: [R] GLM/GAM and unobserved heterogeneity
References: <BAY18-DAV114E679DBFD7FFBBFDDA06B5C80@phx.gbl>
Message-ID: <BAY18-DAV4E71519013DAE6BA0B901B5B30@phx.gbl>

Hello,
     I'm interested in correcting for and measuring unobserved  
heterogeneity ("missing variables") using R.  In particular, I'm  
searching for a simple way to measure the amount of unobserved  
heterogeneity remaining in a series of increasingly complex models  
(adding additional variables to each new model) on the same data.
     I have a static database of 400,000 or so individual mortgage  
loans, each of which is observed monthly from origination (t=0) until  
termination (a binary yes/no variable).  In my update database, there  
are up to 60 months of observed data for each loan in the static  
database, and an individual loan has an "average life" of roughly 36  
months.
     Each loan has static covariates observed at origination, such as  
original loan amount and credit score, as well as time-varying  
covariates (TVC) such as age, interest rates, and house prices.   
Because these TVC change each month, I've constructed a modeling  
database that merges the static database with the update database.
     The resulting "loan-month" modeling database has one observation  
for every loan-month, and the static covariates remain the same for  
all loan-months for a given loan.  Thus, the modeling database has  
roughly 14.4 million loan-month records.  A loan is considered  
"active" as long as it has not yet terminated or been censored; my  
interest is in predicting termination.
     This type of data is often referred to as "event history" or  
"discrete hazard" data.  The standard R package to apply to such data  
is "survival", with which I could estimate a Cox proportional hazard  
model using coxph.  The advantage of such an approach is that  
unobserved heterogeneity is easily addressed using the "frailty" term.
     The disadvantages, at least for my purposes, are two-fold.   
First, my audience is unfamiliar with hazard models.  Second, my  
monthly data has many "ties" (many terminations in the same month),  
so I've been told that coxph won't work well on a large dataset with  
many ties.
     On the other hand, because the data is measured discretely each  
month, many references suggest applying generalized linear models  
(GLM, "logit"-type models) or even generalized addivitive models  
(GAM, "logit"-type models that incorporate nonlinearity in individual  
covariates).  The advantage to this approach is that GLM and GAM are  
readily available in R, and my audience is very familiar with logit- 
type models.
     The disadvantage, however, is that I am totally unfamiliar with  
ways to correct for and measure unobserved heterogeneity using GLM/ 
GAM-type models.  I've been told that unobserved heterogeneity in the  
hazard framework is analogous to random effects in the GLM/GAM  
framework, but there seem to be a number of R packages that address  
this issue in different ways.
     So, I'd greatly appreciate suggestions on a simple way to  
incorporate unobserved heterogeneity into a GLM/GAM-type model.  I'm  
not much of a statistician, so simple examples are always helpful.   
I'm also happy to track down specific article/book references, if  
folks think those might be of help.

Many thanks,
Kyle
---
kyle  at  hotmail . com
(email altered in obvious ways)



From ggrothendieck at gmail.com  Thu Aug 18 00:09:05 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 17 Aug 2005 18:09:05 -0400
Subject: [R] plotting issue with timestamps
In-Reply-To: <BAY102-F31FAD5E664A6BCE6F93513D3B30@phx.gbl>
References: <BAY102-F31FAD5E664A6BCE6F93513D3B30@phx.gbl>
Message-ID: <971536df05081715095bae23a6@mail.gmail.com>

On 8/17/05, Dhiren DSouza <dhiren22 at hotmail.com> wrote:
> I have a dataset with transactions and a timestamp at which they occoured
> during a day.  The time stamp is in the format YYYY/MM/DD hh:mm:ss.  I would
> like to plot a timeseries of the transactions to see if there is a
> particular time in the day when there is a spike in transactions.  Ofcourse
> the YYYY/MM/DD can be dropped since I am monitoring activity for the day and
> the actual date is unimportant.
> 
> Can anyone give me some direction on this.  I could possibly build a
> frequency table but not sure how to plot against the timestamp in the format
> above.  Any help would be appreciated.


Lets say your times are in a character vector tt.  (If the dates
are there too use substring to remove them.) Then convert them
to times class (of library chron) which will represent them
internally as a fraction of a day where the day starts at 0 and 
goes to 1 so that 0.5 is noon.  Since we want a more meaningful
axis do not use the automatic plot axis (xaxt = "n") and also
restrict the xaxis to the internval 0:1.  So that we can get
all the hours to fix reduce the size of the axis labels to 70%.
Then redraw it yourself with the hours labelled and add some 
light grey vertical lines if you like.

library(chron)
tt <- c("10:11:12", "09:10:11", "01:02:03")
tt.times <- times(tt)
plot(density(tt.times), xaxt = "n", xlim = 0:1, xlab = "Hour")
axis(1, 0:24/24, 0:24, cex.axis = 0.7)
abline(v = 0:24/24, col = "lightgrey")

See RNews 4/1 Help Desk article for more.



From sundar.dorai-raj at pdf.com  Thu Aug 18 00:22:34 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Wed, 17 Aug 2005 17:22:34 -0500
Subject: [R] do glm with two data sets
In-Reply-To: <27C204BD76CBC142BA1AE46D62A8548E490BFB@nihexchange9.nih.gov>
References: <27C204BD76CBC142BA1AE46D62A8548E490BFB@nihexchange9.nih.gov>
Message-ID: <4303B8AA.90100@pdf.com>



Hu, Ying (NIH/NCI) wrote:
> I have two data sets:
> File1.txt: 
> Name id1   id2   id3   ...
> N1    0     1     0     ...
> N2    0     1     1     ...
> N3    1     1     -1    ...
> ...
>  
> File2.txt:
> Group id1       id2       id3       ...
> G1       1.22     1.34     2.44     ...
> G2       2.33     2.56     2.56     ...
> G3       1.56     1.99     1.46     ...
> ...
> I like to do:
> x1<-c(0,1,0,...)
> y1<-c(1.22,1.34, 2.44, ...)
> z1<-data.frame(x,y)
> summary(glm(y1~x1,data=z1)
>  
> But I do the same thing by inputting the data sets from the two files
> e <- read.table("file1.txt", header=TRUE,row.names=1)
> g <- read.table("file2.txt", header=TRUE,row.names=1)
> e1<-exp[1,]
> g1<-geno[1,]
> d1<-data.frame(g, e)
> summary(glm(e1 ~ g1, data=d1))
>  
> the error message is 
> Error in model.frame(formula, rownames, variables, varnames, extras,
> extranames,  : 
>         invalid variable type
> Execution halted
>  
> Thanks in advance,
>  
> Ying

You have several inconsistencies in your example, so it will be 
difficult to figure out what you are trying to accomplish.

 > e <- read.table("file1.txt", header=TRUE,row.names=1)
 > g <- read.table("file2.txt", header=TRUE,row.names=1)
 > e1<-exp[1,]

What's "exp"? Also it's dangerous to use an R function as a variable 
name. Most of the time R can tell the difference, but in some cases it 
cannot.

 > g1<-geno[1,]

What's "geno"?

 > d1<-data.frame(g, e)

d1 is now e and g cbind'ed together?

 > summary(glm(e1 ~ g1, data=d1))

Are "e1" and "g1" elements of "d1"? From what you've told us, I don't 
know where the error is occurring. Also, if you are having errors, you 
can more easily isolate the problem by doing:

fit <- glm(e1 ~ g1, data = d1)
summary(fit)

This will at least tell you the problem is in your call to "glm" and not 
"summary.glm".

--sundar

P.S. Please (re-)read the POSTING GUIDE. Most of the time you will 
figure out problems such as these on your own during the process of 
creating a reproducible example.



From tmlammail at yahoo.com  Thu Aug 18 00:34:00 2005
From: tmlammail at yahoo.com (Martin Lam)
Date: Wed, 17 Aug 2005 15:34:00 -0700 (PDT)
Subject: [R] newbie- how to add a row to a matrix
In-Reply-To: <C298B619-1802-4D0C-B56B-636D8ECD642B@tin.it>
Message-ID: <20050817223400.77607.qmail@web40528.mail.yahoo.com>

# row bind
a <- matrix(1:5)
a
a <- rbind(a, 6)
a

# column bind
b <- matrix(1:5)
b
b <- cbind(b, 6:12)
b
b <- cbind(b, 13)
b

Hope this helps,

Martin


--- Simone Gabbriellini <ogabbrie at tin.it> wrote:

> dear list,
> if I have a matrix
> 
> s<-matrix(1:5, ncol=5)
> 
> how can I add another row with other data to that
> matrix?
> 
> thank you,
> simone
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From gavin.simpson at ucl.ac.uk  Thu Aug 18 01:01:25 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 18 Aug 2005 00:01:25 +0100
Subject: [R] do glm with two data sets
In-Reply-To: <4303B8AA.90100@pdf.com>
References: <27C204BD76CBC142BA1AE46D62A8548E490BFB@nihexchange9.nih.gov>
	<4303B8AA.90100@pdf.com>
Message-ID: <1124319685.2718.49.camel@dsl-217-155-166-107.zen.co.uk>

On Wed, 2005-08-17 at 17:22 -0500, Sundar Dorai-Raj wrote:
> 
> Hu, Ying (NIH/NCI) wrote:
> > I have two data sets:
> > File1.txt: 
> > Name id1   id2   id3   ...
> > N1    0     1     0     ...
> > N2    0     1     1     ...
> > N3    1     1     -1    ...
> > ...
> >  
> > File2.txt:
> > Group id1       id2       id3       ...
> > G1       1.22     1.34     2.44     ...
> > G2       2.33     2.56     2.56     ...
> > G3       1.56     1.99     1.46     ...
> > ...
> > I like to do:
> > x1<-c(0,1,0,...)
> > y1<-c(1.22,1.34, 2.44, ...)
> > z1<-data.frame(x,y)
> > summary(glm(y1~x1,data=z1)
> >  
> > But I do the same thing by inputting the data sets from the two files
> > e <- read.table("file1.txt", header=TRUE,row.names=1)
> > g <- read.table("file2.txt", header=TRUE,row.names=1)
> > e1<-exp[1,]
> > g1<-geno[1,]
> > d1<-data.frame(g, e)
> > summary(glm(e1 ~ g1, data=d1))
> >  
> > the error message is 
> > Error in model.frame(formula, rownames, variables, varnames, extras,
> > extranames,  : 
> >         invalid variable type
> > Execution halted
> >  
> > Thanks in advance,
> >  
> > Ying

Hi Ying,

That error message is likely caused by having a data.frame on the right
hand side (rhs) of the formula. You can't have a data.frame on the rhs
of a formula and g1 is still a data frame even if you only choose the
first row, e.g.:

dat <- as.data.frame(matrix(100, 10, 10))
class(dat[1, ])
[1] "data.frame"

You could try:

glm(e1 ~ ., data=g1[1, ])

and see if that works, but as Sundar notes, your post is a little
difficult to follow, so this may not do what you were trying to achieve.

HTH

Gav

> 
> You have several inconsistencies in your example, so it will be 
> difficult to figure out what you are trying to accomplish.
> 
>  > e <- read.table("file1.txt", header=TRUE,row.names=1)
>  > g <- read.table("file2.txt", header=TRUE,row.names=1)
>  > e1<-exp[1,]
> 
> What's "exp"? Also it's dangerous to use an R function as a variable 
> name. Most of the time R can tell the difference, but in some cases it 
> cannot.
> 
>  > g1<-geno[1,]
> 
> What's "geno"?
> 
>  > d1<-data.frame(g, e)
> 
> d1 is now e and g cbind'ed together?
> 
>  > summary(glm(e1 ~ g1, data=d1))
> 
> Are "e1" and "g1" elements of "d1"? From what you've told us, I don't 
> know where the error is occurring. Also, if you are having errors, you 
> can more easily isolate the problem by doing:
> 
> fit <- glm(e1 ~ g1, data = d1)
> summary(fit)
> 
> This will at least tell you the problem is in your call to "glm" and not 
> "summary.glm".
> 
> --sundar
> 
> P.S. Please (re-)read the POSTING GUIDE. Most of the time you will 
> figure out problems such as these on your own during the process of 
> creating a reproducible example.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From spencer.graves at pdf.com  Thu Aug 18 04:08:12 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 17 Aug 2005 21:08:12 -0500
Subject: [R] How to assess significance of random effect in lme4
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7409E5BE0D@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F7409E5BE0D@dc1ex2.air.org>
Message-ID: <4303ED8C.9050203@pdf.com>

	  Is there some reason you are NOT using "anova", as in "Examples" 
section of "?lmer"?

	  Permit me to summarize what I know about this, and I'll be pleased if 
someone else who thinks they know different would kindly enlighten me 
and others who might otherwise be misled if anything I say is 
inconsistent with the best literature available at the moment:

	  1.  Doug Bates in his PhD dissertation and later in his book with Don 
Watts (1988) Nonlinear Regression Analysis and Its Applications (Wiley) 
split approximation errors in nonlinear least squares into "intrinsic 
curvature" and "parameter effects curvature".  He quantified these two 
problems in the context of roughly three dozen published examples, if my 
memory is correct, and found that in not quite all cases, the parameter 
effects were at least an order of magnitude greater than the intrinsic 
curvature.

	  2.  In nonnormal situations, maximum likelihood is subject to more 
approximation error -- intrinsic curvature -- than "simple" nonlinear 
least squares.  However, I would expect this comparison to still be 
fairly accurate, even if the differences may not be quite as stark.

	  3.  The traditional use of "standard errors" to judge statistical 
significance is subject to both intrinsic and parameter effects errors, 
while likelihood ratio procedures such as anova are subject only to the 
intrinsic curvature (assuming there are no substantive problems with 
nonconvergence).  Consequently, to judge statistical significance of an 
effect, anova is usually substantially better than the so-called Wald 
procedure using approximate standard errors, and is almost never worse. 
  If anyone knows of a case where this is NOT true, I'd like to know.

	  4.  With parameters at a boundary as with variance components, the 
best procedure seems to double the p-value from a nested anova (unless 
the reported p-value is already large).  This is because the 
2*log(likelihood ratio) in such cases is roughly a 50-50 mixture of 0 
and chi-square(1) [if testing only 1 variance component parameter]. 
This is supported by a substantial amount of research, including 
simulations discussed in a chapter in Pinheiro and Bates (2000) 
Mixed-Effects Models in S and S-Plus (Springer).  The may be more 
accurate procedures available in the literature, but none so simple as 
this as far as I know.

	  Comments?
	  spencer graves
p.s.  It looks like fm at bVars is a list containing vectors of length 29 
and 6 in your example.  I don't know what they are, but I don't see how 
they can be standard errors in the usual sense.

Doran, Harold wrote:

> These are the posterior variances of the random effects (I think more
> properly termed "empirical" posteriors).  Your model apparently includes
> three levels of random variation (commu, bcohort, residual). The first
> are the variances associated with your commu random effect and the
> second are the variances associated with the bcohort random effect.
> 
> Accessing either one would require
> 
> fm at bVar$commu or fm at bVar$bcohort
> 
> Obviously, replace "fm" with the name of your fitted model.
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Shige Song
> Sent: Wednesday, August 17, 2005 7:50 AM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] How to assess significance of random effect in lme4
> 
> Hi Harold,
> 
> Thanks for the reply. I looked at my outputs using str() as you
> suggested, here is the part you mentioned:
> 
>   ..@ bVar     :List of 2
>   .. ..$ commu  : num [1, 1, 1:29] 5e-10 5e-10 5e-10 5e-10 5e-10 ...
>   .. ..$ bcohort: num [1, 1, 1:6] 1.05e-05 7.45e-06 6.53e-06 8.25e-06
> 7.11e-06 ...
> 
> where commu and bcohort are the two second-level units. Are these
> standard errors? Why the second vector contains a series of different
> numbers?
> 
> Thanks!
> 
> Shige
> 
> On 8/17/05, Doran, Harold <HDoran at air.org> wrote:
> 
>> 
>>
>>You can extract the posterior variance of the random effect from the 
>>bVar slot of the fitted lmer model. It is not a hidden option, but a 
>>part of the fitted model. It just doesn't show up when you use
> 
> summary().
> 
>> 
>> Look at the structure of your object to see what is available using
> 
> str().
> 
>> 
>> However, your comment below seems to imply that it is incorrect for 
>>lmer to report SDs instead of the standard error, which is not true. 
>>That is a quantity of direct interest.
>> 
>> Other multilevel programs report the same exact statistics (for the 
>>most part). For instance, HLM reports the variances as well. If you 
>>want the posterior variance of an HLM model you need to extract it.
>>
>> 
>> 
>> -----Original Message-----
>> From:   r-help-bounces at stat.math.ethz.ch on behalf of
>>Shige Song
>> Sent:   Wed 8/17/2005 6:30 AM
>> To:     r-help at stat.math.ethz.ch
>> Cc:    
>> Subject:        [R] How to assess significance of random effect in
> 
> lme4
> 
>> 
>> Dear All,
>> 
>> With kind help from several friends on the list, I am getting close.
>> Now here are something interesting I just realized: for random  
>>effects, lmer reports standard deviation instead of standard error! Is
> 
> 
>>there a hidden option that tells lmer to report standard error of  
>>random effects, like most other multilevel or mixed modeling software,
> 
> 
>>so that we can say something like "randome effect for xxx is  
>>significant, while randome effect for xxx is not significant"? Thanks!
>> 
>> Best,
>> Shige
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list  
>>https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
>> 
>> 
>> 
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From w.northcott at unsw.edu.au  Thu Aug 18 04:21:19 2005
From: w.northcott at unsw.edu.au (Bill Northcott)
Date: Thu, 18 Aug 2005 12:21:19 +1000
Subject: [R] RMySQL not loading on Mac OS X
In-Reply-To: <mailman.11.1123754401.31178.r-help@stat.math.ethz.ch>
References: <mailman.11.1123754401.31178.r-help@stat.math.ethz.ch>
Message-ID: <73D832B8-6F27-4F0C-9AD3-454BA8516E1D@unsw.edu.au>

On 11/08/2005, at 8:00 PM, Georg Otto wrote:
> I have a problem loading RMySQL 0.5-5 on Mac OS 10.4.2 running R  
> 2.1.1.
>
> I installed RMySQL using:
>
> export PKG_CPPFLAGS="-I/usr/local/mysql/include"
> export PKG_LIBS="-L/usr/local/mysql/lib -lmysqlclient"
>
> R CMD INSTALL /Users/gwo/Desktop/RMySQL_0.5-5.tar.gz
>
>
> The installation seemed to work ok, but when I load RMySQL in R I get
> an error message:
>
>
>> library(RMySQL)
>>
> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>          unable to load shared library '/Library/Frameworks/
> R.framework/Resources/library/RMySQL/libs/RMySQL.so':
>    dlopen(/Library/Frameworks/R.framework/Resources/library/RMySQL/
> libs/RMySQL.so, 6): Symbol not found: _printf$LDBLStub
>    Referenced from: /Library/Frameworks/R.framework/Resources/library/
> RMySQL/libs/RMySQL.so
>    Expected in: flat namespace
> Error in library(RMySQL) : .First.lib failed for 'RMySQL'
>
> Any hint will be highly appreciated!
>
I notice this question never got a reply.

It would have been better asked on the sig-Mac list, but here are  
some pointers.

The
> libs/RMySQL.so, 6): Symbol not found: _printf$LDBLStub
is caused by not linking all the necessary system libraries.

Either
1.  there is an attempt to link objects and/or static libraries built  
with gcc-3.x/g77 with objects produced by gcc-4.x/gfortran.  This  
will not work.
or
2.  there is an attempt to link using ld or libtool rather than the  
gcc compiler driver which will ensure that appropriate system  
libraries are used.

FWIW I had no problem building it, but I was using an R package which  
I built from source.  So I know the same compiler was used throughout.

If you are using the R binary distribution, make sure you have run  
'sudo gcc_select 3.3' to get the right default compiler.

Bill Northcott



From Nongluck.Klibbua at newcastle.edu.au  Thu Aug 18 05:24:13 2005
From: Nongluck.Klibbua at newcastle.edu.au (Nongluck Klibbua)
Date: Thu, 18 Aug 2005 13:24:13 +1000
Subject: [R] code a family of garch
Message-ID: <s3048c0c.055@MC-GWDOM2.newcastle.edu.au>

Dear R-helpers,

I was wondering if anyone has or knows someone who might have an
implementation
of algorithm for estimating garcht-t, egarch and gjr models. I try to
use Fseries but I don't know how to code these models.  
Thanks a million in advance,
Sincerely,
Nongluck



From mk_lists at yahoo.ca  Thu Aug 18 05:32:38 2005
From: mk_lists at yahoo.ca (M. K.)
Date: Wed, 17 Aug 2005 23:32:38 -0400 (EDT)
Subject: [R] line/bar through median in lattice's "bwplot"?
Message-ID: <20050818033238.93817.qmail@web31305.mail.mud.yahoo.com>

Is there a way to render a line through the median point in the boxplot
generated by the Lattice command "bwplot"?  The line basically bisects
the bar at the median point...



From spencer.graves at pdf.com  Thu Aug 18 05:47:03 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 17 Aug 2005 22:47:03 -0500
Subject: [R] power of a matrix
In-Reply-To: <x2br3wg2mw.fsf@turmalin.kubism.ku.dk>
References: <8B08A3A1EA7AAC41BE24C750338754E69FDB7E@HERMES.demogr.mpg.de>
	<x2br3wg2mw.fsf@turmalin.kubism.ku.dk>
Message-ID: <430404B7.903@pdf.com>

Hi, Peter:

	  I couldn't find "mexp" in the Matrix package, but I did find it in 
fMultivar and in Lindsey's rmutil.  These are different functions, but 
produced essentially the same answer for mexp(array(1:4, dim=c(2,2))). 
While hunting for that, I also also found reference by Doug Bates in a 
previous interchange on r-help to "a classic paper ... I would recommend 
reading":

  Moler C., van Loan C., (2003); _Nineteen dubious ways to compute
      the exponential of a matrix,  twenty-five years later_, SIAM
      Review 45, 3-49.

	  This paper was cited in the help page for mexp in fMultivar but not 
in rmutil.

	  spencer graves

Peter Dalgaard wrote:

> "Rau, Roland" <Rau at demogr.mpg.de> writes:
> 
> 
>>Thank you very much! Thanks also to the authors of this function,
>>Vincente Canto Cassola and Martin Maechler!
>>
>>This is exactly what I hoped for.
> 
> ....
> 
>>>look at function ?mtx.exp() in the Malmig package, e.g.,
> 
> 
> Also, there is mexp() in the Matrix package. I'm not sure about the
> relative merits. mexp() is one of the less dubious implementations of
> matrix exponentials, but it does require to and from class "Matrix".
> mtx.exp is a bit unfortunately named as it appears to calculate matrix
> *powers* (which in this case is what you need).
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From ggrothendieck at gmail.com  Thu Aug 18 06:19:40 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 18 Aug 2005 00:19:40 -0400
Subject: [R] power of a matrix
In-Reply-To: <430404B7.903@pdf.com>
References: <8B08A3A1EA7AAC41BE24C750338754E69FDB7E@HERMES.demogr.mpg.de>
	<x2br3wg2mw.fsf@turmalin.kubism.ku.dk> <430404B7.903@pdf.com>
Message-ID: <971536df050817211977a63787@mail.gmail.com>

Its expm.


On 8/17/05, Spencer Graves <spencer.graves at pdf.com> wrote:
> Hi, Peter:
> 
>          I couldn't find "mexp" in the Matrix package, but I did find it in
> fMultivar and in Lindsey's rmutil.  These are different functions, but
> produced essentially the same answer for mexp(array(1:4, dim=c(2,2))).
> While hunting for that, I also also found reference by Doug Bates in a
> previous interchange on r-help to "a classic paper ... I would recommend
> reading":
> 
>  Moler C., van Loan C., (2003); _Nineteen dubious ways to compute
>      the exponential of a matrix,  twenty-five years later_, SIAM
>      Review 45, 3-49.
> 
>          This paper was cited in the help page for mexp in fMultivar but not
> in rmutil.
> 
>          spencer graves
> 
> Peter Dalgaard wrote:
> 
> > "Rau, Roland" <Rau at demogr.mpg.de> writes:
> >
> >
> >>Thank you very much! Thanks also to the authors of this function,
> >>Vincente Canto Cassola and Martin Maechler!
> >>
> >>This is exactly what I hoped for.
> >
> > ....
> >
> >>>look at function ?mtx.exp() in the Malmig package, e.g.,
> >
> >
> > Also, there is mexp() in the Matrix package. I'm not sure about the
> > relative merits. mexp() is one of the less dubious implementations of
> > matrix exponentials, but it does require to and from class "Matrix".
> > mtx.exp is a bit unfortunately named as it appears to calculate matrix
> > *powers* (which in this case is what you need).
> >
> 
> --
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
> 
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From stanimura-ngs at umin.ac.jp  Thu Aug 18 08:04:46 2005
From: stanimura-ngs at umin.ac.jp (Susumu Tanimura)
Date: Thu, 18 Aug 2005 15:04:46 +0900
Subject: [R] Unexpected result of read.dbf
Message-ID: <20050818150446.697835cb.stanimura-ngs@umin.ac.jp>

Hi there,

Unexpected result is given with read.dbf from foreign 0.8-9, which is
reproducible in R 2.1.1 with the following sample data:

---- test.dbf ----
KEYCODE,N,19,0
422010010
42201002101
42201002102
42201002103
42201002104
422010060
422010071
422010072
42201008001
42201008002
422010100
42201011001
42201011002
422010130
422010140
42201015001
42201015002
42201015003
422010180
422010190

In the example, the name of column is "KEYCODE" with numeric type, 19
digits, and no decimal.

The data was saved as CSV format for confirmation.

> dbf.test <- read.dbf("test.dbf")
> dbf.test[1:20,]
 [1] 422010010        NA        NA        NA        NA 422010060 422010071
 [8] 422010072        NA        NA 422010100        NA        NA 422010130
[15] 422010140        NA        NA        NA 422010180 422010190
> csv.test <- read.csv("test.csv")
> csv.test[1:20,]
 [1]   422010010 42201002101 42201002102 42201002103 42201002104   422010060
 [7]   422010071   422010072 42201008001 42201008002   422010100 42201011001
[13] 42201011002   422010130   422010140 42201015001 42201015002 42201015003
[19]   422010180   422010190

I wonder why I get NA from test.dbf.  I have this kind of trouble when
handling ESRI Shape files with maptools.  There is no choice to use
read.csv instead of read.dbf at executing read.shape.

--
Susumu Tanimura



From lyhin at netvigator.com  Thu Aug 18 08:44:11 2005
From: lyhin at netvigator.com (Dr L. Y Hin)
Date: Thu, 18 Aug 2005 14:44:11 +0800
Subject: [R] Problem with building R packages under Windows
Message-ID: <001701c5a3c0$3e785910$104efea9@yourgk68c57jh8>

Dear all,

I am coming to the guru for advise here. I am a native user of Windows,
and S-plus, and the process of migrating my libraries from S to R has been
more than a painstaking task...

I am currently using R version 2.1.1 in Windows XP SP2.
I have read the "Writing R extensions", "the FAQ in R", and your valuable
document
"R for Windows Users", but still unable to compile a package in
R using Rcmd (likely stupidity on my part).

The followings are what I have done:

1. Downloaded and setup ActivePerl and the path (in control panel) of
c:\Perl\bin has been added automatically. I have downloaded version (5.8.7).

2. Downloaded and setup tools bundle from
www.stats.ox.ac.uk/pub/Rtools/tools.zip and
unzip them into c:\bin and added the path (in control panel) of c:\bin

3. Downloaded and setup the entire package of MikTex at
http://www.miktex.org/ and added
the path (in control panel) of C:\texmf\miktex\bin

4. Added the path (in control panel) referencing R (this version being
R2.0patched) which
is C:\Program Files\R\rw2000pat\bin

5. Since my codes are all in R scripts without compiled codes, I did not
install MinGW.

6. At DOS prompt at the preamble of the directory called foo (which
contained all subdirectories as created in R using
package.skeleton(name = "foo", list=cdgam.func)),
I typed the following:

C:\>Rcmd build --binary foo
Can't locate R/Dcf.pm in @INC <@INC contains: c:\share\perl c:/Perl/lib
c:/Perl/site/lib .> at C:/bin/build line 29.
BEGIN failed--compilation aborted at C:/bin/build line 29.

I'd be very grateful if anyone could kindly advise me on this matter.

Thanks.
Lin



From ripley at stats.ox.ac.uk  Thu Aug 18 08:45:48 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 Aug 2005 07:45:48 +0100 (BST)
Subject: [R] trouble with wilcox.test
In-Reply-To: <001801c5a35f$a0de7000$43fde5a9@PC232921052285>
References: <001801c5a35f$a0de7000$43fde5a9@PC232921052285>
Message-ID: <Pine.LNX.4.61.0508172314540.16428@gannet.stats>

On Wed, 17 Aug 2005, Greg Hather wrote:

> I'm having trouble with the wilcox.test command in R.

Are you sure it is not the concepts that are giving 'trouble'?
What real problem are you trying to solve here?

> To demonstrate the anomalous behavior of wilcox.test, consider
>
>> wilcox.test(c(1.5,5.5), c(1:10000), exact = F)$p.value
> [1] 0.01438390
>> wilcox.test(c(1.5,5.5), c(1:10000), exact = T)$p.value
> [1] 6.39808e-07 (this calculation takes noticeably longer).
>> wilcox.test(c(1.5,5.5), c(1:20000), exact = T)$p.value
> (R closes/crashes)
>
> I believe that wilcox.test(c(1.5,5.5), c(1:10000), exact = F)$p.value 
> yields a bad result because of the normal approximation which R uses 
> when exact = F.

Expecting an approximation to be good in the tail for m=2 is pretty 
unrealistic.  But then so is believing the null hypothesis of a common 
*continuous* distribution.  Why worry about the distribution under a 
hypothesis that is patently false?

People often refer to this class of tests as `distribution-free', but they 
are not.  The Wilcoxon test is designed for power against shift 
alternatives, but here there appears to be a very large difference in 
spread.  So

> wilcox.test(5000+c(1.5,5.5), c(1:10000), exact = T)$p.value
[1] 0.9989005

even though the two samples differ in important ways.


> Any suggestions for how to compute 
> wilcox.test(c(1.5,5.5), c(1:20000), exact = T)$p.value?

I get (current R 2.1.1 on Linux)

> wilcox.test(c(1.5,5.5), c(1:20000), exact = T)$p.value
[1] 1.59976e-07

and no crash.  So the suggestion is to use a machine adequate to the task, 
and that probably means an OS with adequate stack size.

> 	[[alternative HTML version deleted]]

> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Please do heed it.  What version of R and what machine is this?  And do 
take note of the request about HTML mail.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Thu Aug 18 09:27:06 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 18 Aug 2005 09:27:06 +0200
Subject: [R] Problem with building R packages under Windows
In-Reply-To: <001701c5a3c0$3e785910$104efea9@yourgk68c57jh8>
References: <001701c5a3c0$3e785910$104efea9@yourgk68c57jh8>
Message-ID: <4304384A.2030002@statistik.uni-dortmund.de>

Dr L. Y Hin wrote:

> Dear all,
> 
> I am coming to the guru for advise here. I am a native user of Windows,
> and S-plus, and the process of migrating my libraries from S to R has been
> more than a painstaking task...
> 
> I am currently using R version 2.1.1 in Windows XP SP2.
> I have read the "Writing R extensions", "the FAQ in R", and your valuable
> document
> "R for Windows Users", but still unable to compile a package in
> R using Rcmd (likely stupidity on my part).
> 
> The followings are what I have done:
> 
> 1. Downloaded and setup ActivePerl and the path (in control panel) of
> c:\Perl\bin has been added automatically. I have downloaded version 
> (5.8.7).

You need the native port, not the cygwin one.

> 2. Downloaded and setup tools bundle from
> www.stats.ox.ac.uk/pub/Rtools/tools.zip and
> unzip them into c:\bin and added the path (in control panel) of c:\bin

Hmm, the tools are no longer available from this location!
The current link is:

http://www.murdoch-sutherland.com/Rtools/tools.zip


For the current R version, the procedure is documented in the manual "R
Installation and Administration".



> 3. Downloaded and setup the entire package of MikTex at
> http://www.miktex.org/ and added
> the path (in control panel) of C:\texmf\miktex\bin
> 
> 4. Added the path (in control panel) referencing R (this version being
> R2.0patched) which
> is C:\Program Files\R\rw2000pat\bin

Above you told us about R-2.1.1 .....!
Please, really use a recent version.

Uwe Ligges


> 5. Since my codes are all in R scripts without compiled codes, I did not
> install MinGW.
> 
> 6. At DOS prompt at the preamble of the directory called foo (which
> contained all subdirectories as created in R using
> package.skeleton(name = "foo", list=cdgam.func)),
> I typed the following:
> 
> C:\>Rcmd build --binary foo
> Can't locate R/Dcf.pm in @INC <@INC contains: c:\share\perl c:/Perl/lib
> c:/Perl/site/lib .> at C:/bin/build line 29.
> BEGIN failed--compilation aborted at C:/bin/build line 29.
> 
> I'd be very grateful if anyone could kindly advise me on this matter.
> 
> Thanks.
> Lin
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ehlers at math.ucalgary.ca  Thu Aug 18 09:37:50 2005
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Thu, 18 Aug 2005 01:37:50 -0600
Subject: [R] trouble with wilcox.test
In-Reply-To: <Pine.LNX.4.61.0508172314540.16428@gannet.stats>
References: <001801c5a35f$a0de7000$43fde5a9@PC232921052285>
	<Pine.LNX.4.61.0508172314540.16428@gannet.stats>
Message-ID: <43043ACD.7000402@math.ucalgary.ca>


Prof Brian Ripley wrote:
> On Wed, 17 Aug 2005, Greg Hather wrote:
> 
> 
>>I'm having trouble with the wilcox.test command in R.
> 
> 
> Are you sure it is not the concepts that are giving 'trouble'?
> What real problem are you trying to solve here?
> 
> 
>>To demonstrate the anomalous behavior of wilcox.test, consider
>>
>>
>>>wilcox.test(c(1.5,5.5), c(1:10000), exact = F)$p.value
>>
>>[1] 0.01438390
>>
>>>wilcox.test(c(1.5,5.5), c(1:10000), exact = T)$p.value
>>
>>[1] 6.39808e-07 (this calculation takes noticeably longer).
>>
>>>wilcox.test(c(1.5,5.5), c(1:20000), exact = T)$p.value
>>
>>(R closes/crashes)
>>
>>I believe that wilcox.test(c(1.5,5.5), c(1:10000), exact = F)$p.value 
>>yields a bad result because of the normal approximation which R uses 
>>when exact = F.
> 
> 
> Expecting an approximation to be good in the tail for m=2 is pretty 
> unrealistic.  But then so is believing the null hypothesis of a common 
> *continuous* distribution.  Why worry about the distribution under a 
> hypothesis that is patently false?
> 
> People often refer to this class of tests as `distribution-free', but they 
> are not.  The Wilcoxon test is designed for power against shift 
> alternatives, but here there appears to be a very large difference in 
> spread.  So
> 
> 
>>wilcox.test(5000+c(1.5,5.5), c(1:10000), exact = T)$p.value
> 
> [1] 0.9989005
> 
> even though the two samples differ in important ways.
> 
> 
> 
>>Any suggestions for how to compute 
>>wilcox.test(c(1.5,5.5), c(1:20000), exact = T)$p.value?
> 
> 
> I get (current R 2.1.1 on Linux)
> 
> 
>>wilcox.test(c(1.5,5.5), c(1:20000), exact = T)$p.value
> 
> [1] 1.59976e-07
> 
> and no crash.  So the suggestion is to use a machine adequate to the task, 
> and that probably means an OS with adequate stack size.
> 
> 
>>	[[alternative HTML version deleted]]
> 
> 
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> Please do heed it.  What version of R and what machine is this?  And do 
> take note of the request about HTML mail.
> 

One could also try wilcox.exact() in package exactRankTests (0.8-11)
which also gives (with suitable patience)

[1] 1.59976e-07

even on my puny 256M Windows laptop.

Still, it might be worthwhile adding a "don't do something this silly"
error message to wilcox.test() rather than having it crash R. Low
priority, IMHO.

Windows XP SP2
"R version 2.1.1, 2005-08-11"

Peter Ehlers



From fooms at euroscreen.com  Thu Aug 18 09:46:29 2005
From: fooms at euroscreen.com (=?iso-8859-1?Q?Fr=E9d=E9ric_Ooms?=)
Date: Thu, 18 Aug 2005 09:46:29 +0200
Subject: [R] Binary kernel discrimination
Message-ID: <5198ADA420721246BC35BFA666E24F16D7446A@euromail.euroscreen.be>

Hello,
Could you tell me if a package exists to perform a binary kernel discrimination using a training set compose of  molecules represented by binary fingerprint. This method was first described by Harper in J. Chem. Inf. Comput. Sci 2001 41 1295 and is also described in recent papers published in the same journal by Hert Jerome. I have attached the page describing the BKD method used in the last paper to give all the details of what I would like to try with R .
Thanks for your help
Fred
 <<BKD method.pdf>> 

From dieter.menne at menne-biomed.de  Thu Aug 18 09:37:41 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Thu, 18 Aug 2005 07:37:41 +0000 (UTC)
Subject: [R] line/bar through median in lattice's "bwplot"?
References: <20050818033238.93817.qmail@web31305.mail.mud.yahoo.com>
Message-ID: <loom.20050818T093542-426@post.gmane.org>

M. K. <mk_lists <at> yahoo.ca> writes:

> 
> Is there a way to render a line through the median point in the boxplot
> generated by the Lattice command "bwplot"?  The line basically bisects
> the bar at the median point...


bwplot(height~voice.part , pch='|', data=singer, xlab="Height (inches)")

How to find this (haven't checked, maybe it's documented)
library(lattice)
panel.bwplot # no ()!

Check the code for something like points (which is the default).
Find a mysterious '|' and pch

Dieter



From Torsten.Hothorn at rzmail.uni-erlangen.de  Thu Aug 18 10:06:19 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Thu, 18 Aug 2005 10:06:19 +0200 (CEST)
Subject: [R] accesing slots of S4 class in C code
In-Reply-To: <2372A3FFAF50104B9929841F6B9B878302109309@EMAIL.hci.utah.edu>
References: <2372A3FFAF50104B9929841F6B9B878302109309@EMAIL.hci.utah.edu>
Message-ID: <Pine.LNX.4.51.0508181005310.835@artemis.imbe.med.uni-erlangen.de>


> I am trying to use a custom S4 object in my C code and I cannot get the
> access to its slots working.
>
>
>
> The following is a toy example, but even this crashes.
>
>
>
> In R I have:
>
>
>
> setClass("pd", representation(data="numeric"))
>
> x <- new("pd", data=1:5)
>
>
>
> test <- function(pd.obj) {
>
>   res <- .C("TestFun", pd.obj)

.Call("TestFun", pd.obj)

should work.

Torsten

>
>   res}
>
>
>
> test(x)
>
>
>
> (Of couse I load the DLL as well.)
>
>
>
> The corresponding C file has:
>
>
>
> SEXP TestFun(SEXP pd_obj)
>
> {
>
>  SEXP t=R_NilValue;
>
>  PROTECT(t = GET_SLOT(pd_obj, install("data")));
>
>  UNPROTECT(1);
>
>  return(t);
>
> }
>
>
>
>
>
> What I hope to get as a result is the (1:5) vector.
>
> In the long term, the vector will be a multi-dimensional array and I
> will want to do calculations using its contents in the C program.
>
>
>
> Thanks for any help,
>
>
>
> Aniko
>
>
> Huntsman Cancer Institute wishes to promote open communication while protecting confidential and/or privileged information.  If you have received this message in error, please inform the sender and delete all copies.
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From shigesong at gmail.com  Thu Aug 18 10:15:32 2005
From: shigesong at gmail.com (Shige Song)
Date: Thu, 18 Aug 2005 16:15:32 +0800
Subject: [R] Error messages using LMER
Message-ID: <5abc11d805081801152c1f6661@mail.gmail.com>

Dear All,

After playing with lmer for couple of days, I have to say that I am
amazed! I've been using quite some multilevel/mixed modeling packages,
lme4 is a strong candidate for the overall winner, especially for
multilevel generzlized linear models.

Now go back to my two-level poisson model with cross-classified model.
I've been testing various different model specificatios for the past
couple of days. Here are the models I tried:

1) Two level random intercept model with level-1 covariates only
m1 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 ,
data, poisson, method="Laplace")

2) Two-level random intercept model with both level-1 and level-2
covariates, but no cross-level interactions:
m2 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 +
z1 + z2, data, poisson, method="Laplace")

3) Two-level random intercept with cross-level interaction
m3 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 +
z1 + z2 + x1:z1 + x2:z2, data, poisson, method="Laplace")

Both model 1 and 2 run fine. For model 3, I got error message:
----------------------------------
Error in fn(par, ...) : Unable to invert singular factor of downdated X'X
In addition: Warning messages:
1: optim or nlminb returned message ERROR: ABNORMAL_TERMINATION_IN_LNSRCH 
 in: LMEopt(x = mer, value = cv) 
2: Leading minor of size 1 of downdated X'X is indefinite 
----------------------------------

What is going on here? Any workarounds? Thanks!

Best,
Shige



From ehlers at math.ucalgary.ca  Thu Aug 18 10:42:58 2005
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Thu, 18 Aug 2005 02:42:58 -0600
Subject: [R] trouble with wilcox.test
In-Reply-To: <43043ACD.7000402@math.ucalgary.ca>
References: <001801c5a35f$a0de7000$43fde5a9@PC232921052285>
	<Pine.LNX.4.61.0508172314540.16428@gannet.stats>
	<43043ACD.7000402@math.ucalgary.ca>
Message-ID: <43044A12.8010607@math.ucalgary.ca>



P Ehlers wrote:
> 
> Prof Brian Ripley wrote:
> 
>> On Wed, 17 Aug 2005, Greg Hather wrote:
>>
>>
>>> I'm having trouble with the wilcox.test command in R.
>>
>>
>>
>> Are you sure it is not the concepts that are giving 'trouble'?
>> What real problem are you trying to solve here?
>>
>>
>>> To demonstrate the anomalous behavior of wilcox.test, consider
>>>
>>>
>>>> wilcox.test(c(1.5,5.5), c(1:10000), exact = F)$p.value
>>>
>>>
>>> [1] 0.01438390
>>>
>>>> wilcox.test(c(1.5,5.5), c(1:10000), exact = T)$p.value
>>>
>>>
>>> [1] 6.39808e-07 (this calculation takes noticeably longer).
>>>
>>>> wilcox.test(c(1.5,5.5), c(1:20000), exact = T)$p.value
>>>
>>>
>>> (R closes/crashes)
>>>
>>> I believe that wilcox.test(c(1.5,5.5), c(1:10000), exact = F)$p.value 
>>> yields a bad result because of the normal approximation which R uses 
>>> when exact = F.
>>
>>
>>
>> Expecting an approximation to be good in the tail for m=2 is pretty 
>> unrealistic.  But then so is believing the null hypothesis of a common 
>> *continuous* distribution.  Why worry about the distribution under a 
>> hypothesis that is patently false?
>>
>> People often refer to this class of tests as `distribution-free', but 
>> they are not.  The Wilcoxon test is designed for power against shift 
>> alternatives, but here there appears to be a very large difference in 
>> spread.  So
>>
>>
>>> wilcox.test(5000+c(1.5,5.5), c(1:10000), exact = T)$p.value
>>
>>
>> [1] 0.9989005
>>
>> even though the two samples differ in important ways.
>>
>>
>>
>>> Any suggestions for how to compute wilcox.test(c(1.5,5.5), 
>>> c(1:20000), exact = T)$p.value?
>>
>>
>>
>> I get (current R 2.1.1 on Linux)
>>
>>
>>> wilcox.test(c(1.5,5.5), c(1:20000), exact = T)$p.value
>>
>>
>> [1] 1.59976e-07
>>
>> and no crash.  So the suggestion is to use a machine adequate to the 
>> task, and that probably means an OS with adequate stack size.
>>
>>
>>>     [[alternative HTML version deleted]]
>>
>>
>>
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>>
>>
>>
>> Please do heed it.  What version of R and what machine is this?  And 
>> do take note of the request about HTML mail.
>>
> 
> One could also try wilcox.exact() in package exactRankTests (0.8-11)
> which also gives (with suitable patience)
> 
> [1] 1.59976e-07
> 
> even on my puny 256M Windows laptop.
> 
> Still, it might be worthwhile adding a "don't do something this silly"
> error message to wilcox.test() rather than having it crash R. Low
> priority, IMHO.
> 
> Windows XP SP2
> "R version 2.1.1, 2005-08-11"
> 
> Peter Ehlers
> 

I should also mention package coin's wilcox_test() which does the
job in about a quarter of the time used by exactRankTests.

Peter Ehlers



From ogabbrie at tin.it  Thu Aug 18 10:47:20 2005
From: ogabbrie at tin.it (Simone Gabbriellini)
Date: Thu, 18 Aug 2005 10:47:20 +0200
Subject: [R] newbie- how to add a row to a matrix
In-Reply-To: <20050817223400.77607.qmail@web40528.mail.yahoo.com>
References: <20050817223400.77607.qmail@web40528.mail.yahoo.com>
Message-ID: <D6B73D29-A399-45FC-8E70-615CB6EC3E78@tin.it>

thank you all

rbind solved my problems!!!

simone

Il giorno 18/ago/05, alle ore 00:34, Martin Lam ha scritto:

> # row bind
> a <- matrix(1:5)
> a
> a <- rbind(a, 6)
> a
>
> # column bind
> b <- matrix(1:5)
> b
> b <- cbind(b, 6:12)
> b
> b <- cbind(b, 13)
> b
>
> Hope this helps,
>
> Martin
>
>
> --- Simone Gabbriellini <ogabbrie at tin.it> wrote:
>
>
>> dear list,
>> if I have a matrix
>>
>> s<-matrix(1:5, ncol=5)
>>
>> how can I add another row with other data to that
>> matrix?
>>
>> thank you,
>> simone
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>>
>
>
>
>
> __________________________________
> Yahoo! Mail
> Stay connected, organized, and protected. Take the tour:
> http://tour.mail.yahoo.com/mailtour.html
>
>



From tokkass at yahoo.com  Thu Aug 18 11:02:13 2005
From: tokkass at yahoo.com (toka tokas)
Date: Thu, 18 Aug 2005 02:02:13 -0700 (PDT)
Subject: [R] matrix indexing
Message-ID: <20050818090213.89292.qmail@web35306.mail.mud.yahoo.com>

Dear R-users,

I was wondering for the following:

Let 'x' be a matrix and 'ind' and indicator matrix,
i.e.,

x <- array(1:20, dim = c(4, 5))
ind <- array(c(1:3, 3:1), dim = c(3, 2))

I'd like to get (as a vector) the elements of 'x'
which are not indexed by 'ind'. Since negative indices
are not allowed in index matrices I thought of using
something like:

x[ind] <- NA
x[!is.na(x)]

but are there any more elegant solutions.

Thanks in advance,
toka



From pedro.aphalo at cc.jyu.fi  Thu Aug 18 11:20:02 2005
From: pedro.aphalo at cc.jyu.fi (Pedro J. Aphalo)
Date: Thu, 18 Aug 2005 12:20:02 +0300
Subject: [R] GLMM - Am I trying the impossible?
Message-ID: <430452C2.80104@cc.jyu.fi>

Dear all,

I have tried to calculate a GLMM fit with lmer (lme4) and glmmPQL 
(MASS), I also used glm for comparison.

I am getting very different results from different functions, and I 
suspect that the problem is with our dataset rather than the functions, 
but I would appreciate help in deciding whether my suspicions are right. 
If indeed we are attempting the wrong type of analysis, some guidance 
about what would be the right thing to do would be greatly appreciated.

The details:
The data:
The data are from the end-point of a survival experiment with fish. The 
design of the experiment is a 2 x 2 factorial, with each factor 
(Bacteria and Parasite) at two levels (yes and no). There were 16 fish 
in each tank, and the treatment was applied to the whole tank. There 
were in all 10 tanks (160 fish), with 2 tanks for controls (no/no), 2 
tanks for (Parasite:yes/Bacteria:no) and 3 tanks for each of the other 2 
treatments. A dead fish was considered a success, and a binomial family 
with the default logit link was used in the fits. No fish died in the 
control treatment (Is this the problem?).

Overall "probabilities" as dead/total for the four treatments were:
Paras Bact  Prob
no    no    0
yes   no    0.0625
no    yes   0.208
yes   yes   0.458

We are interested in testing main effects and interaction, but the 
interaction is of special interest to us.

The data for "dead" are coded as 0/1 with 1 indicating a dead fish, and 
the file has one row per fish.

Some results:

lme4  (ver 0.98-1, R 2.1.1, Windows XP)
~~~~

 > fish1.lmerPQL <- lmer(dead ~ Parasite * Bacteria + (1|Tank), 
data=fish.data, family=binomial)
Error in lmer(dead ~ Parasite * Bacteria + (1 | Tank), data = fish.data,  :
         Unable to invert singular factor of downdated X'X
In addition: Warning message:
Leading minor of size 4 of downdated X'X is indefinite
 >

without the interaction:
 > fish3.lmerPQL <- lmer(dead ~ Parasite + Bacteria + (1|Tank), 
data=fish.data, family=binomial)
 > anova(fish3.lmerPQL)
Analysis of Variance Table
          Df  Sum Sq Mean Sq   Denom F value Pr(>F)
Parasite  1   0.012   0.012 157.000  0.0103 0.9192
Bacteria  1   0.058   0.058 157.000  0.0524 0.8192
 > summary(fish3.lmerPQL)
Generalized linear mixed model fit using PQL
Formula: dead ~ Parasite + Bacteria + (1 | Tank)
    Data: fish.data
  Family: binomial(logit link)
       AIC      BIC    logLik deviance
  141.3818 156.7577 -65.69091 131.3818
Random effects:
      Groups        Name    Variance    Std.Dev.
        Tank (Intercept)       5e-10  2.2361e-05
# of obs: 160, groups: Tank, 10

Estimated scale (compare to 1)  0.9318747

Fixed effects:
             Estimate Std. Error z value  Pr(>|z|)
(Intercept) -4.24380    0.79924 -5.3098 1.098e-07 ***
Parasiteyes  1.26407    0.44694  2.8283 0.0046801 **
Bacteriayes  2.85062    0.75970  3.7523 0.0001752 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Correlation of Fixed Effects:
             (Intr) Prstys
Parasiteyes -0.429
Bacteriayes -0.898  0.093

Very different P-values from anova and summary.

MASS: (ver 7.2-17, R 2.1.1, Windows XP)
~~~~~

 > summary(fish1.glmmpql)
Linear mixed-effects model fit by maximum likelihood
  Data: fish.data
        AIC      BIC   logLik
   1236.652 1255.103 -612.326

Random effects:
  Formula: ~1 | Tank
         (Intercept)  Residual
StdDev:  0.02001341 0.8944214

Variance function:
  Structure: fixed weights
  Formula: ~invwt
Fixed effects: dead ~ Parasite * Bacteria
                             Value Std.Error  DF     t-value p-value
(Intercept)             -18.56607  1044.451 150 -0.01777591  0.9858
Parasiteyes              15.85802  1044.451   6  0.01518311  0.9884
Bacteriayes              17.23107  1044.451   6  0.01649772  0.9874
Parasiteyes:Bacteriayes -14.69007  1044.452   6 -0.01406487  0.9892
  Correlation:
                         (Intr) Prstys Bctrys
Parasiteyes             -1
Bacteriayes             -1      1
Parasiteyes:Bacteriayes  1     -1     -1

Standardized Within-Group Residuals:
           Min            Q1           Med            Q3           Max
-1.028634e+00 -5.734674e-01 -2.886770e-01 -4.224474e-14  4.330155e+00

Number of Observations: 160
Number of Groups: 10
 > anova(fish1.glmmpql)
                   numDF denDF   F-value p-value
(Intercept)           1   150 17.452150  <.0001
Parasite              1     6  4.136142  0.0882
Bacteria              1     6 12.740212  0.0118
Parasite:Bacteria     1     6  0.000198  0.9892
 >

 > anova(glmmPQL(dead~Bacteria*Parasite, random=~1|Tank, 
family=binomial, data=fish.data))
iteration 1
                   numDF denDF   F-value p-value
(Intercept)           1   150 17.452150  <.0001
Bacteria              1     6  8.980833  0.0241
Parasite              1     6  7.895521  0.0308
Bacteria:Parasite     1     6  0.000198  0.9892
 >

Now anova indicates significance, but summary gives huge P-values.

I have looked in MASS, ISwR, Fox's and Crawley's book, for hints, but I 
have probably missed the right spots/books. Hints about what to read 
will be also appreciated.

Many thanks in advance, and sorry about the long message.

The report on this research is obviously not yet published, but if the 
dataframe would be of help, it can be found as saved from R at:
http://people.cc.jyu.fi/~aphalo/R_fish/fish.Rda. (Use load to read it 
into R).

Pedro.
-- 
==================================================================
Pedro J. Aphalo
Department of Biological and Environmental Science
University of Jyv??skyl??
P.O. Box 35, 40351 JYV??SKYL??, Finland
Phone  +358 14 260 2339
Mobile +358 50 3721504
Fax    +358 14 260 2321
mailto:pedro.aphalo at cc.jyu.fi
http://www.jyu.fi/~aphalo/                       ,,,^..^,,,



From Allan at STATS.uct.ac.za  Thu Aug 18 11:25:58 2005
From: Allan at STATS.uct.ac.za (Clark Allan)
Date: Thu, 18 Aug 2005 11:25:58 +0200
Subject: [R] R: stepwise procedures
Message-ID: <43045426.9A74C3EB@STATS.uct.ac.za>

hi all

i found step(), stepAIC() and some other functions in leaps and
subselect.

is there a package/function that does the traditional stepwise
regression procedures using F in and F out values?

i know that step does the selctions based on AIC. 

/
allan

From ripley at stats.ox.ac.uk  Thu Aug 18 11:38:48 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 Aug 2005 10:38:48 +0100 (BST)
Subject: [R] trouble with wilcox.test
In-Reply-To: <43043ACD.7000402@math.ucalgary.ca>
References: <001801c5a35f$a0de7000$43fde5a9@PC232921052285>
	<Pine.LNX.4.61.0508172314540.16428@gannet.stats>
	<43043ACD.7000402@math.ucalgary.ca>
Message-ID: <Pine.LNX.4.61.0508180848540.23856@gannet.stats>

If this is stack overflow (and I don't know that yet: when I tried this on 
Windows the traceback was clearly corrupt, referring to bratio), the issue 
is that it is impossible to catch such an error, and it is not even AFAIK
portably possible to find the stack size limit (or even the current usage) 
to do some estimates.  (The amount of RAM is not relevant.)  On 
Unix-alikes the stack size limit can be controlled from the shell used to 
launch R so we don't have any a priori knowledge.

The underlying code could be rewritten not to use recursion, but that 
seems not worth the effort involved.

All I can see we can do it to put a warning in the help file.

On Thu, 18 Aug 2005, P Ehlers wrote:

>
> Prof Brian Ripley wrote:
>> On Wed, 17 Aug 2005, Greg Hather wrote:
>> 
>> 
>>> I'm having trouble with the wilcox.test command in R.
>> 
>> 
>> Are you sure it is not the concepts that are giving 'trouble'?
>> What real problem are you trying to solve here?
>> 
>> 
>>> To demonstrate the anomalous behavior of wilcox.test, consider
>>> 
>>> 
>>>> wilcox.test(c(1.5,5.5), c(1:10000), exact = F)$p.value
>>> 
>>> [1] 0.01438390
>>> 
>>>> wilcox.test(c(1.5,5.5), c(1:10000), exact = T)$p.value
>>> 
>>> [1] 6.39808e-07 (this calculation takes noticeably longer).
>>> 
>>>> wilcox.test(c(1.5,5.5), c(1:20000), exact = T)$p.value
>>> 
>>> (R closes/crashes)
>>> 
>>> I believe that wilcox.test(c(1.5,5.5), c(1:10000), exact = F)$p.value 
>>> yields a bad result because of the normal approximation which R uses when 
>>> exact = F.
>> 
>> 
>> Expecting an approximation to be good in the tail for m=2 is pretty 
>> unrealistic.  But then so is believing the null hypothesis of a common 
>> *continuous* distribution.  Why worry about the distribution under a 
>> hypothesis that is patently false?
>> 
>> People often refer to this class of tests as `distribution-free', but they 
>> are not.  The Wilcoxon test is designed for power against shift 
>> alternatives, but here there appears to be a very large difference in 
>> spread.  So
>> 
>> 
>>> wilcox.test(5000+c(1.5,5.5), c(1:10000), exact = T)$p.value
>> 
>> [1] 0.9989005
>> 
>> even though the two samples differ in important ways.
>> 
>> 
>> 
>>> Any suggestions for how to compute wilcox.test(c(1.5,5.5), c(1:20000), 
>>> exact = T)$p.value?
>> 
>> 
>> I get (current R 2.1.1 on Linux)
>> 
>> 
>>> wilcox.test(c(1.5,5.5), c(1:20000), exact = T)$p.value
>> 
>> [1] 1.59976e-07
>> 
>> and no crash.  So the suggestion is to use a machine adequate to the task, 
>> and that probably means an OS with adequate stack size.
>> 
>> 
>>> 	[[alternative HTML version deleted]]
>> 
>> 
>>> PLEASE do read the posting guide! 
>>> http://www.R-project.org/posting-guide.html
>> 
>> 
>> Please do heed it.  What version of R and what machine is this?  And do 
>> take note of the request about HTML mail.
>> 
>
> One could also try wilcox.exact() in package exactRankTests (0.8-11)
> which also gives (with suitable patience)
>
> [1] 1.59976e-07
>
> even on my puny 256M Windows laptop.
>
> Still, it might be worthwhile adding a "don't do something this silly"
> error message to wilcox.test() rather than having it crash R. Low
> priority, IMHO.
>
> Windows XP SP2
> "R version 2.1.1, 2005-08-11"
>
> Peter Ehlers
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From georg.otto at tuebingen.mpg.de  Thu Aug 18 11:46:16 2005
From: georg.otto at tuebingen.mpg.de (Georg Otto)
Date: Thu, 18 Aug 2005 11:46:16 +0200
Subject: [R] RMySQL not loading on Mac OS X
In-Reply-To: <73D832B8-6F27-4F0C-9AD3-454BA8516E1D@unsw.edu.au>
References: <mailman.11.1123754401.31178.r-help@stat.math.ethz.ch>
	<73D832B8-6F27-4F0C-9AD3-454BA8516E1D@unsw.edu.au>
Message-ID: <A1E9E8E0-490E-422E-8CA4-267641F3C19B@tuebingen.mpg.de>

Bill,

thanks a lot for your answer. I did not know about the sig-Mac list.  
I will post there next time if I do not find a solution.

Concerning your suggestion: The system default compiler is gcc 4.0,  
but RMySQL seems to be built using gcc-3.3 regardless if I switch to  
3.3. or not.

Would it be a solution to force RMySQL to use gcc 4.0 during built?  
(Might be a naive idea, I am quite new to this). And if yes, how  
could I do this?

Best,

Georg


On 18 Aug 2005, at 04:21, Bill Northcott wrote:

> On 11/08/2005, at 8:00 PM, Georg Otto wrote:
>
>> I have a problem loading RMySQL 0.5-5 on Mac OS 10.4.2 running R  
>> 2.1.1.
>>
>> I installed RMySQL using:
>>
>> export PKG_CPPFLAGS="-I/usr/local/mysql/include"
>> export PKG_LIBS="-L/usr/local/mysql/lib -lmysqlclient"
>>
>> R CMD INSTALL /Users/gwo/Desktop/RMySQL_0.5-5.tar.gz
>>
>>
>> The installation seemed to work ok, but when I load RMySQL in R I get
>> an error message:
>>
>>
>>
>>> library(RMySQL)
>>>
>>>
>> Error in dyn.load(x, as.logical(local), as.logical(now)) :
>>          unable to load shared library '/Library/Frameworks/
>> R.framework/Resources/library/RMySQL/libs/RMySQL.so':
>>    dlopen(/Library/Frameworks/R.framework/Resources/library/RMySQL/
>> libs/RMySQL.so, 6): Symbol not found: _printf$LDBLStub
>>    Referenced from: /Library/Frameworks/R.framework/Resources/ 
>> library/
>> RMySQL/libs/RMySQL.so
>>    Expected in: flat namespace
>> Error in library(RMySQL) : .First.lib failed for 'RMySQL'
>>
>> Any hint will be highly appreciated!
>>
>>
> I notice this question never got a reply.
>
> It would have been better asked on the sig-Mac list, but here are  
> some pointers.
>
> The
>
>> libs/RMySQL.so, 6): Symbol not found: _printf$LDBLStub
>>
> is caused by not linking all the necessary system libraries.
>
> Either
> 1.  there is an attempt to link objects and/or static libraries  
> built with gcc-3.x/g77 with objects produced by gcc-4.x/gfortran.   
> This will not work.
> or
> 2.  there is an attempt to link using ld or libtool rather than the  
> gcc compiler driver which will ensure that appropriate system  
> libraries are used.
>
> FWIW I had no problem building it, but I was using an R package  
> which I built from source.  So I know the same compiler was used  
> throughout.
>
> If you are using the R binary distribution, make sure you have run  
> 'sudo gcc_select 3.3' to get the right default compiler.
>
> Bill Northcott
>



From richmcb at gmail.com  Thu Aug 18 12:13:48 2005
From: richmcb at gmail.com (Ben Rich)
Date: Thu, 18 Aug 2005 12:13:48 +0200
Subject: [R] matrix indexing
In-Reply-To: <20050818090213.89292.qmail@web35306.mail.mud.yahoo.com>
References: <20050818090213.89292.qmail@web35306.mail.mud.yahoo.com>
Message-ID: <32acb12105081803135c311d7a@mail.gmail.com>

Hi,

you might not consider this more elegant, but how about this

x[-apply(ind, 1, function(i) (i[1]-1)*nrow(x) + i[2])]

Ben

On 8/18/05, toka tokas <tokkass at yahoo.com> wrote:
> Dear R-users,
> 
> I was wondering for the following:
> 
> Let 'x' be a matrix and 'ind' and indicator matrix,
> i.e.,
> 
> x <- array(1:20, dim = c(4, 5))
> ind <- array(c(1:3, 3:1), dim = c(3, 2))
> 
> I'd like to get (as a vector) the elements of 'x'
> which are not indexed by 'ind'. Since negative indices
> are not allowed in index matrices I thought of using
> something like:
> 
> x[ind] <- NA
> x[!is.na(x)]
> 
> but are there any more elegant solutions.
> 
> Thanks in advance,
> toka
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From HDoran at air.org  Thu Aug 18 12:17:14 2005
From: HDoran at air.org (Doran, Harold)
Date: Thu, 18 Aug 2005 06:17:14 -0400
Subject: [R] How to assess significance of random effect in lme4
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7407E41C30@dc1ex2.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050818/760f23cb/attachment.pl

From ripley at stats.ox.ac.uk  Thu Aug 18 12:21:26 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 Aug 2005 11:21:26 +0100 (BST)
Subject: [R] GLMM - Am I trying the impossible?
In-Reply-To: <430452C2.80104@cc.jyu.fi>
References: <430452C2.80104@cc.jyu.fi>
Message-ID: <Pine.LNX.4.61.0508181102110.29551@gannet.stats>

It is not supported to call anova() on a glmmPQL fit.

For the glmmPQL fit you show, you have very large parameter estimates for 
a logistic and have partial separation (as you comment on for the control 
group): in that case PQL is not a reasonable method.

Try

fit <- glm(dead ~ Parasite * Bacteria, data=fish.data, family=binomial)
summary(fit)
anova(fit, test="Chisq")
fitted(fit)

and you have fitted values of zero (up to numerical tolerances).

This *is* discussed in MASS, around pp.198-9.

So there is little point in adding random efects for that model.  Now try

fit2 <- glmmPQL(dead ~ Parasite + Bacteria, random=~1|Tank,
                 family=binomial, data=fish.data)
summary(fit2)

Fixed effects: dead ~ Bacteria + Parasite
                 Value Std.Error  DF   t-value p-value
(Intercept) -4.243838 0.7519194 150 -5.644007  0.0000
Parasiteyes  1.264102 0.4205313   7  3.005964  0.0198
Bacteriayes  2.850640 0.7147180   7  3.988483  0.0053

which is pretty similar to the lmer fit you show.

I don't know what anova is doing for your lmer fit, but I do know that it 
should not be working with sums of squares as is being reported.

On Thu, 18 Aug 2005, Pedro J. Aphalo wrote:

> Dear all,
>
> I have tried to calculate a GLMM fit with lmer (lme4) and glmmPQL
> (MASS), I also used glm for comparison.

I think you missed what glm was trying to tell you.

> I am getting very different results from different functions, and I
> suspect that the problem is with our dataset rather than the functions,
> but I would appreciate help in deciding whether my suspicions are right.
> If indeed we are attempting the wrong type of analysis, some guidance
> about what would be the right thing to do would be greatly appreciated.
>
> The details:
> The data:
> The data are from the end-point of a survival experiment with fish. The
> design of the experiment is a 2 x 2 factorial, with each factor
> (Bacteria and Parasite) at two levels (yes and no). There were 16 fish
> in each tank, and the treatment was applied to the whole tank. There
> were in all 10 tanks (160 fish), with 2 tanks for controls (no/no), 2
> tanks for (Parasite:yes/Bacteria:no) and 3 tanks for each of the other 2
> treatments. A dead fish was considered a success, and a binomial family
> with the default logit link was used in the fits. No fish died in the
> control treatment (Is this the problem?).
>
> Overall "probabilities" as dead/total for the four treatments were:
> Paras Bact  Prob
> no    no    0
> yes   no    0.0625
> no    yes   0.208
> yes   yes   0.458
>
> We are interested in testing main effects and interaction, but the
> interaction is of special interest to us.
>
> The data for "dead" are coded as 0/1 with 1 indicating a dead fish, and
> the file has one row per fish.
>
> Some results:
>
> lme4  (ver 0.98-1, R 2.1.1, Windows XP)
> ~~~~
>
> > fish1.lmerPQL <- lmer(dead ~ Parasite * Bacteria + (1|Tank),
> data=fish.data, family=binomial)
> Error in lmer(dead ~ Parasite * Bacteria + (1 | Tank), data = fish.data,  :
>         Unable to invert singular factor of downdated X'X
> In addition: Warning message:
> Leading minor of size 4 of downdated X'X is indefinite
> >
>
> without the interaction:
> > fish3.lmerPQL <- lmer(dead ~ Parasite + Bacteria + (1|Tank),
> data=fish.data, family=binomial)
> > anova(fish3.lmerPQL)
> Analysis of Variance Table
>          Df  Sum Sq Mean Sq   Denom F value Pr(>F)
> Parasite  1   0.012   0.012 157.000  0.0103 0.9192
> Bacteria  1   0.058   0.058 157.000  0.0524 0.8192
> > summary(fish3.lmerPQL)
> Generalized linear mixed model fit using PQL
> Formula: dead ~ Parasite + Bacteria + (1 | Tank)
>    Data: fish.data
>  Family: binomial(logit link)
>       AIC      BIC    logLik deviance
>  141.3818 156.7577 -65.69091 131.3818
> Random effects:
>      Groups        Name    Variance    Std.Dev.
>        Tank (Intercept)       5e-10  2.2361e-05
> # of obs: 160, groups: Tank, 10
>
> Estimated scale (compare to 1)  0.9318747
>
> Fixed effects:
>             Estimate Std. Error z value  Pr(>|z|)
> (Intercept) -4.24380    0.79924 -5.3098 1.098e-07 ***
> Parasiteyes  1.26407    0.44694  2.8283 0.0046801 **
> Bacteriayes  2.85062    0.75970  3.7523 0.0001752 ***
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Correlation of Fixed Effects:
>             (Intr) Prstys
> Parasiteyes -0.429
> Bacteriayes -0.898  0.093
>
> Very different P-values from anova and summary.
>
> MASS: (ver 7.2-17, R 2.1.1, Windows XP)
> ~~~~~
>
> > summary(fish1.glmmpql)
> Linear mixed-effects model fit by maximum likelihood
>  Data: fish.data
>        AIC      BIC   logLik
>   1236.652 1255.103 -612.326
>
> Random effects:
>  Formula: ~1 | Tank
>         (Intercept)  Residual
> StdDev:  0.02001341 0.8944214
>
> Variance function:
>  Structure: fixed weights
>  Formula: ~invwt
> Fixed effects: dead ~ Parasite * Bacteria
>                             Value Std.Error  DF     t-value p-value
> (Intercept)             -18.56607  1044.451 150 -0.01777591  0.9858
> Parasiteyes              15.85802  1044.451   6  0.01518311  0.9884
> Bacteriayes              17.23107  1044.451   6  0.01649772  0.9874
> Parasiteyes:Bacteriayes -14.69007  1044.452   6 -0.01406487  0.9892
>  Correlation:
>                         (Intr) Prstys Bctrys
> Parasiteyes             -1
> Bacteriayes             -1      1
> Parasiteyes:Bacteriayes  1     -1     -1
>
> Standardized Within-Group Residuals:
>           Min            Q1           Med            Q3           Max
> -1.028634e+00 -5.734674e-01 -2.886770e-01 -4.224474e-14  4.330155e+00
>
> Number of Observations: 160
> Number of Groups: 10
> > anova(fish1.glmmpql)
>                   numDF denDF   F-value p-value
> (Intercept)           1   150 17.452150  <.0001
> Parasite              1     6  4.136142  0.0882
> Bacteria              1     6 12.740212  0.0118
> Parasite:Bacteria     1     6  0.000198  0.9892
> >
>
> > anova(glmmPQL(dead~Bacteria*Parasite, random=~1|Tank,
> family=binomial, data=fish.data))
> iteration 1
>                   numDF denDF   F-value p-value
> (Intercept)           1   150 17.452150  <.0001
> Bacteria              1     6  8.980833  0.0241
> Parasite              1     6  7.895521  0.0308
> Bacteria:Parasite     1     6  0.000198  0.9892
> >
>
> Now anova indicates significance, but summary gives huge P-values.
>
> I have looked in MASS, ISwR, Fox's and Crawley's book, for hints, but I
> have probably missed the right spots/books. Hints about what to read
> will be also appreciated.
>
> Many thanks in advance, and sorry about the long message.
>
> The report on this research is obviously not yet published, but if the
> dataframe would be of help, it can be found as saved from R at:
> http://people.cc.jyu.fi/~aphalo/R_fish/fish.Rda. (Use load to read it
> into R).
>
> Pedro.
> -- 
> ==================================================================
> Pedro J. Aphalo
> Department of Biological and Environmental Science
> University of Jyv?skyl?
> P.O. Box 35, 40351 JYV?SKYL?, Finland
> Phone  +358 14 260 2339
> Mobile +358 50 3721504
> Fax    +358 14 260 2321
> mailto:pedro.aphalo at cc.jyu.fi
> http://www.jyu.fi/~aphalo/                       ,,,^..^,,,
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From w.northcott at unsw.edu.au  Thu Aug 18 12:47:50 2005
From: w.northcott at unsw.edu.au (Bill Northcott)
Date: Thu, 18 Aug 2005 20:47:50 +1000
Subject: [R] RMySQL not loading on Mac OS X
In-Reply-To: <A1E9E8E0-490E-422E-8CA4-267641F3C19B@tuebingen.mpg.de>
References: <mailman.11.1123754401.31178.r-help@stat.math.ethz.ch>
	<73D832B8-6F27-4F0C-9AD3-454BA8516E1D@unsw.edu.au>
	<A1E9E8E0-490E-422E-8CA4-267641F3C19B@tuebingen.mpg.de>
Message-ID: <502085C3-4B64-4293-B6A5-59E84EE59BF2@unsw.edu.au>

On 18/08/2005, at 7:46 PM, Georg Otto wrote:
> Concerning your suggestion: The system default compiler is gcc 4.0,  
> but RMySQL seems to be built using gcc-3.3 regardless if I switch  
> to 3.3. or not.
>
> Would it be a solution to force RMySQL to use gcc 4.0 during built?  
> (Might be a naive idea, I am quite new to this). And if yes, how  
> could I do this?

When R is built it stores the configuration including the compilers  
which were used.  When you try to build a source package, it uses the  
same compile commands.   However, this is a less than perfect  
mechanism and requires that the packagers of binaries understand what  
is going on.

For instance on Panther 'gcc' by default means gcc-3.3, whereas on  
Tiger by default it means gcc-4.0.  So a package built with 'gcc' and  
'g77' will work on Panther but not Tiger.  See the problem.

OTOH 'gcc-3.3' means gcc-3.3 on either Panther or Tiger, but  
'gcc-4.0' won't work on Panther at all.

The best solution is to build everything from source with the same  
compilers.  That way you cannot have a compatibility problems.

Hopefully soon the transition to gcc-4 will be complete.  The change  
to Intel guarantees that, because the Apple gcc-3.3 compilers don't  
do x86 code.  In a perfect future Apple will include Fortran in their  
Developer tools distribution, but for now they want gcc-4 and  
gfortran is not quite ready for the big time.

Bill Northcott



From spencer.graves at pdf.com  Thu Aug 18 14:20:03 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 18 Aug 2005 07:20:03 -0500
Subject: [R] power of a matrix
In-Reply-To: <971536df050817211977a63787@mail.gmail.com>
References: <8B08A3A1EA7AAC41BE24C750338754E69FDB7E@HERMES.demogr.mpg.de>	
	<x2br3wg2mw.fsf@turmalin.kubism.ku.dk> <430404B7.903@pdf.com>
	<971536df050817211977a63787@mail.gmail.com>
Message-ID: <43047CF3.1050401@pdf.com>

Hi, Gabor:  Thanks.  spencer graves

Gabor Grothendieck wrote:

> Its expm.
> 
> 
> On 8/17/05, Spencer Graves <spencer.graves at pdf.com> wrote:
> 
>>Hi, Peter:
>>
>>         I couldn't find "mexp" in the Matrix package, but I did find it in
>>fMultivar and in Lindsey's rmutil.  These are different functions, but
>>produced essentially the same answer for mexp(array(1:4, dim=c(2,2))).
>>While hunting for that, I also also found reference by Doug Bates in a
>>previous interchange on r-help to "a classic paper ... I would recommend
>>reading":
>>
>> Moler C., van Loan C., (2003); _Nineteen dubious ways to compute
>>     the exponential of a matrix,  twenty-five years later_, SIAM
>>     Review 45, 3-49.
>>
>>         This paper was cited in the help page for mexp in fMultivar but not
>>in rmutil.
>>
>>         spencer graves
>>
>>Peter Dalgaard wrote:
>>
>>
>>>"Rau, Roland" <Rau at demogr.mpg.de> writes:
>>>
>>>
>>>
>>>>Thank you very much! Thanks also to the authors of this function,
>>>>Vincente Canto Cassola and Martin Maechler!
>>>>
>>>>This is exactly what I hoped for.
>>>
>>>....
>>>
>>>
>>>>>look at function ?mtx.exp() in the Malmig package, e.g.,
>>>
>>>
>>>Also, there is mexp() in the Matrix package. I'm not sure about the
>>>relative merits. mexp() is one of the less dubious implementations of
>>>matrix exponentials, but it does require to and from class "Matrix".
>>>mtx.exp is a bit unfortunately named as it appears to calculate matrix
>>>*powers* (which in this case is what you need).
>>>
>>
>>--
>>Spencer Graves, PhD
>>Senior Development Engineer
>>PDF Solutions, Inc.
>>333 West San Carlos Street Suite 700
>>San Jose, CA 95110, USA
>>
>>spencer.graves at pdf.com
>>www.pdf.com <http://www.pdf.com>
>>Tel:  408-938-4420
>>Fax: 408-280-7915
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>>

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From spencer.graves at pdf.com  Thu Aug 18 14:26:04 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 18 Aug 2005 07:26:04 -0500
Subject: [R] How to assess significance of random effect in lme4
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7407E41C30@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F7407E41C30@dc1ex2.air.org>
Message-ID: <43047E5C.8040609@pdf.com>

Hi, Harold:  Thanks for the clarification.  I thought I had read the 
original post.  Obviously, I had misread it.  Thanks again.  spencer graves

Doran, Harold wrote:

> Yes, it is a different issue. ranef() extracts the empirical Bayes 
> estimates, which are the empirical posterior modes. The bVar slot holds 
> the corresponding posterior variances of these modes.
> 
> Technically, (according to D. Bates) the values in the bVar slot are the 
> the diagonal elements of
> (Z'Z+\Omega)^{-1}.
> 
> The original post was asking how to test and compare a specific random 
> effect, not a general assessment of how much information is provided by 
> the data via LRT.
> 
> Shige asked how to test whether a specific EB estimate is different than 
> some other value.
> LRT doesn't answer this question, but the values in the bVar slot do.
> 
> 
> -----Original Message-----
> From:   Spencer Graves [mailto:spencer.graves at pdf.com]
> Sent:   Wed 8/17/2005 10:08 PM
> To:     Doran, Harold
> Cc:     Shige Song; r-help at stat.math.ethz.ch
> Subject:        Re: [R] How to assess significance of random effect in lme4
> 
>           Is there some reason you are NOT using "anova", as in "Examples"
> section of "?lmer"?
> 
>           Permit me to summarize what I know about this, and I'll be 
> pleased if
> someone else who thinks they know different would kindly enlighten me
> and others who might otherwise be misled if anything I say is
> inconsistent with the best literature available at the moment:
> 
>           1.  Doug Bates in his PhD dissertation and later in his book 
> with Don
> Watts (1988) Nonlinear Regression Analysis and Its Applications (Wiley)
> split approximation errors in nonlinear least squares into "intrinsic
> curvature" and "parameter effects curvature".  He quantified these two
> problems in the context of roughly three dozen published examples, if my
> memory is correct, and found that in not quite all cases, the parameter
> effects were at least an order of magnitude greater than the intrinsic
> curvature.
> 
>           2.  In nonnormal situations, maximum likelihood is subject to more
> approximation error -- intrinsic curvature -- than "simple" nonlinear
> least squares.  However, I would expect this comparison to still be
> fairly accurate, even if the differences may not be quite as stark.
> 
>           3.  The traditional use of "standard errors" to judge statistical
> significance is subject to both intrinsic and parameter effects errors,
> while likelihood ratio procedures such as anova are subject only to the
> intrinsic curvature (assuming there are no substantive problems with
> nonconvergence).  Consequently, to judge statistical significance of an
> effect, anova is usually substantially better than the so-called Wald
> procedure using approximate standard errors, and is almost never worse.
>   If anyone knows of a case where this is NOT true, I'd like to know.
> 
>           4.  With parameters at a boundary as with variance components, the
> best procedure seems to double the p-value from a nested anova (unless
> the reported p-value is already large).  This is because the
> 2*log(likelihood ratio) in such cases is roughly a 50-50 mixture of 0
> and chi-square(1) [if testing only 1 variance component parameter].
> This is supported by a substantial amount of research, including
> simulations discussed in a chapter in Pinheiro and Bates (2000)
> Mixed-Effects Models in S and S-Plus (Springer).  The may be more
> accurate procedures available in the literature, but none so simple as
> this as far as I know.
> 
>           Comments?
>           spencer graves
> p.s.  It looks like fm at bVars is a list containing vectors of length 29
> and 6 in your example.  I don't know what they are, but I don't see how
> they can be standard errors in the usual sense.
> 
> Doran, Harold wrote:
> 
>  > These are the posterior variances of the random effects (I think more
>  > properly termed "empirical" posteriors).  Your model apparently includes
>  > three levels of random variation (commu, bcohort, residual). The first
>  > are the variances associated with your commu random effect and the
>  > second are the variances associated with the bcohort random effect.
>  >
>  > Accessing either one would require
>  >
>  > fm at bVar$commu or fm at bVar$bcohort
>  >
>  > Obviously, replace "fm" with the name of your fitted model.
>  >
>  > -----Original Message-----
>  > From: r-help-bounces at stat.math.ethz.ch
>  > [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Shige Song
>  > Sent: Wednesday, August 17, 2005 7:50 AM
>  > To: r-help at stat.math.ethz.ch
>  > Subject: Re: [R] How to assess significance of random effect in lme4
>  >
>  > Hi Harold,
>  >
>  > Thanks for the reply. I looked at my outputs using str() as you
>  > suggested, here is the part you mentioned:
>  >
>  >   ..@ bVar     :List of 2
>  >   .. ..$ commu  : num [1, 1, 1:29] 5e-10 5e-10 5e-10 5e-10 5e-10 ...
>  >   .. ..$ bcohort: num [1, 1, 1:6] 1.05e-05 7.45e-06 6.53e-06 8.25e-06
>  > 7.11e-06 ...
>  >
>  > where commu and bcohort are the two second-level units. Are these
>  > standard errors? Why the second vector contains a series of different
>  > numbers?
>  >
>  > Thanks!
>  >
>  > Shige
>  >
>  > On 8/17/05, Doran, Harold <HDoran at air.org> wrote:
>  >
>  >>
>  >>
>  >>You can extract the posterior variance of the random effect from the
>  >>bVar slot of the fitted lmer model. It is not a hidden option, but a
>  >>part of the fitted model. It just doesn't show up when you use
>  >
>  > summary().
>  >
>  >>
>  >> Look at the structure of your object to see what is available using
>  >
>  > str().
>  >
>  >>
>  >> However, your comment below seems to imply that it is incorrect for
>  >>lmer to report SDs instead of the standard error, which is not true.
>  >>That is a quantity of direct interest.
>  >>
>  >> Other multilevel programs report the same exact statistics (for the
>  >>most part). For instance, HLM reports the variances as well. If you
>  >>want the posterior variance of an HLM model you need to extract it.
>  >>
>  >>
>  >>
>  >> -----Original Message-----
>  >> From:   r-help-bounces at stat.math.ethz.ch on behalf of
>  >>Shige Song
>  >> Sent:   Wed 8/17/2005 6:30 AM
>  >> To:     r-help at stat.math.ethz.ch
>  >> Cc:   
>  >> Subject:        [R] How to assess significance of random effect in
>  >
>  > lme4
>  >
>  >>
>  >> Dear All,
>  >>
>  >> With kind help from several friends on the list, I am getting close.
>  >> Now here are something interesting I just realized: for random 
>  >>effects, lmer reports standard deviation instead of standard error! Is
>  >
>  >
>  >>there a hidden option that tells lmer to report standard error of 
>  >>random effects, like most other multilevel or mixed modeling software,
>  >
>  >
>  >>so that we can say something like "randome effect for xxx is 
>  >>significant, while randome effect for xxx is not significant"? Thanks!
>  >>
>  >> Best,
>  >> Shige
>  >>
>  >> ______________________________________________
>  >> R-help at stat.math.ethz.ch mailing list 
>  >>https://stat.ethz.ch/mailman/listinfo/r-help
>  >> PLEASE do read the posting guide!
>  >>http://www.R-project.org/posting-guide.html
>  >>
>  >>
>  >>
>  >>
>  >>
>  >
>  >
>  > ______________________________________________
>  > R-help at stat.math.ethz.ch mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide!
>  > http://www.R-project.org/posting-guide.html
>  >
>  > ______________________________________________
>  > R-help at stat.math.ethz.ch mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> --
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
> 
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915
> 
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From tmlammail at yahoo.com  Thu Aug 18 14:32:28 2005
From: tmlammail at yahoo.com (Martin Lam)
Date: Thu, 18 Aug 2005 05:32:28 -0700 (PDT)
Subject: [R] matrix indexing
In-Reply-To: <20050818090213.89292.qmail@web35306.mail.mud.yahoo.com>
Message-ID: <20050818123228.56707.qmail@web40511.mail.yahoo.com>

x <- array(1:20, dim = c(4, 5))
ind <- array(c(1:3, 3:1), dim = c(3, 2))

# instead of using ind (pairs of coordinates) for
getting the items in the matrix, you can convert it to
a list of single coordinates to point to the item in
the matrix:
# t = transpose
# nrow = get the number of rows
indices <- t((ind[,2]-1) * nrow(x) + ind[,1])

# remove the ones indicated by indices
# to get an item from y you can do y[value]
y <- x[-indices]

# you could transpose y, but I don't know if that's
what you want
y <- t(y)

Hope this helps,

Martin

--- toka tokas <tokkass at yahoo.com> wrote:

> Dear R-users,
> 
> I was wondering for the following:
> 
> Let 'x' be a matrix and 'ind' and indicator matrix,
> i.e.,
> 
> x <- array(1:20, dim = c(4, 5))
> ind <- array(c(1:3, 3:1), dim = c(3, 2))
> 
> I'd like to get (as a vector) the elements of 'x'
> which are not indexed by 'ind'. Since negative
> indices
> are not allowed in index matrices I thought of using
> something like:
> 
> x[ind] <- NA
> x[!is.na(x)]
> 
> but are there any more elegant solutions.
> 
> Thanks in advance,
> toka



From HDoran at air.org  Thu Aug 18 14:35:12 2005
From: HDoran at air.org (Doran, Harold)
Date: Thu, 18 Aug 2005 08:35:12 -0400
Subject: [R] [SPAM] - Re: How to assess significance of random effect in
	lme4 - Bayesian Filter detected spam
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7409E5BF62@dc1ex2.air.org>

Actually, I re-read the post and think it needs clarification. We may
both be right. If the question is "I am building a model and want to
know if I should retain this random effect?" (or something like that)
then the LRT should be used to compare the fitted model against another
model. This would be accomplished via anova().

In other multilevel programs, the variance components are often
associated with a chi-square statistic and a test statistic associated
with the variance. lmer() does not report this test statistic.

Now, if the question is something like "I want to know if a specific
realization of the random variable (i.e., a specific empirical Bayes
estimate) is different from a population value?" then one would need the
posterior means.

So, Shige, I hope this hasn't been confusing, but there are many things
happening in these models and it is easy to get confused. Maybe if you
could clarify your question. 

-----Original Message-----
From: Spencer Graves [mailto:spencer.graves at pdf.com] 
Sent: Thursday, August 18, 2005 8:26 AM
To: Doran, Harold
Cc: Shige Song; r-help at stat.math.ethz.ch
Subject: [SPAM] - Re: [R] How to assess significance of random effect in
lme4 - Bayesian Filter detected spam

Hi, Harold:  Thanks for the clarification.  I thought I had read the
original post.  Obviously, I had misread it.  Thanks again.  spencer
graves

Doran, Harold wrote:

> Yes, it is a different issue. ranef() extracts the empirical Bayes 
> estimates, which are the empirical posterior modes. The bVar slot 
> holds the corresponding posterior variances of these modes.
> 
> Technically, (according to D. Bates) the values in the bVar slot are 
> the the diagonal elements of (Z'Z+\Omega)^{-1}.
> 
> The original post was asking how to test and compare a specific random

> effect, not a general assessment of how much information is provided 
> by the data via LRT.
> 
> Shige asked how to test whether a specific EB estimate is different 
> than some other value.
> LRT doesn't answer this question, but the values in the bVar slot do.
> 
> 
> -----Original Message-----
> From:   Spencer Graves [mailto:spencer.graves at pdf.com]
> Sent:   Wed 8/17/2005 10:08 PM
> To:     Doran, Harold
> Cc:     Shige Song; r-help at stat.math.ethz.ch
> Subject:        Re: [R] How to assess significance of random effect in
lme4
> 
>           Is there some reason you are NOT using "anova", as in
"Examples"
> section of "?lmer"?
> 
>           Permit me to summarize what I know about this, and I'll be 
> pleased if someone else who thinks they know different would kindly 
> enlighten me and others who might otherwise be misled if anything I 
> say is inconsistent with the best literature available at the moment:
> 
>           1.  Doug Bates in his PhD dissertation and later in his book

> with Don Watts (1988) Nonlinear Regression Analysis and Its 
> Applications (Wiley) split approximation errors in nonlinear least 
> squares into "intrinsic curvature" and "parameter effects curvature".

> He quantified these two problems in the context of roughly three dozen

> published examples, if my memory is correct, and found that in not 
> quite all cases, the parameter effects were at least an order of 
> magnitude greater than the intrinsic curvature.
> 
>           2.  In nonnormal situations, maximum likelihood is subject 
> to more approximation error -- intrinsic curvature -- than "simple" 
> nonlinear least squares.  However, I would expect this comparison to 
> still be fairly accurate, even if the differences may not be quite as
stark.
> 
>           3.  The traditional use of "standard errors" to judge 
> statistical significance is subject to both intrinsic and parameter 
> effects errors, while likelihood ratio procedures such as anova are 
> subject only to the intrinsic curvature (assuming there are no 
> substantive problems with nonconvergence).  Consequently, to judge 
> statistical significance of an effect, anova is usually substantially 
> better than the so-called Wald procedure using approximate standard
errors, and is almost never worse.
>   If anyone knows of a case where this is NOT true, I'd like to know.
> 
>           4.  With parameters at a boundary as with variance 
> components, the best procedure seems to double the p-value from a 
> nested anova (unless the reported p-value is already large).  This is 
> because the 2*log(likelihood ratio) in such cases is roughly a 50-50 
> mixture of 0 and chi-square(1) [if testing only 1 variance component
parameter].
> This is supported by a substantial amount of research, including 
> simulations discussed in a chapter in Pinheiro and Bates (2000) 
> Mixed-Effects Models in S and S-Plus (Springer).  The may be more 
> accurate procedures available in the literature, but none so simple as

> this as far as I know.
> 
>           Comments?
>           spencer graves
> p.s.  It looks like fm at bVars is a list containing vectors of length 29

> and 6 in your example.  I don't know what they are, but I don't see 
> how they can be standard errors in the usual sense.
> 
> Doran, Harold wrote:
> 
>  > These are the posterior variances of the random effects (I think 
> more  > properly termed "empirical" posteriors).  Your model 
> apparently includes  > three levels of random variation (commu, 
> bcohort, residual). The first  > are the variances associated with 
> your commu random effect and the  > second are the variances
associated with the bcohort random effect.
>  >
>  > Accessing either one would require
>  >
>  > fm at bVar$commu or fm at bVar$bcohort
>  >
>  > Obviously, replace "fm" with the name of your fitted model.
>  >
>  > -----Original Message-----
>  > From: r-help-bounces at stat.math.ethz.ch  > 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Shige Song  > 
> Sent: Wednesday, August 17, 2005 7:50 AM  > To: 
> r-help at stat.math.ethz.ch  > Subject: Re: [R] How to assess 
> significance of random effect in lme4  >  > Hi Harold,  >  > Thanks 
> for the reply. I looked at my outputs using str() as you  > suggested,

> here is the part you mentioned:
>  >
>  >   ..@ bVar     :List of 2
>  >   .. ..$ commu  : num [1, 1, 1:29] 5e-10 5e-10 5e-10 5e-10 5e-10
...
>  >   .. ..$ bcohort: num [1, 1, 1:6] 1.05e-05 7.45e-06 6.53e-06
8.25e-06
>  > 7.11e-06 ...
>  >
>  > where commu and bcohort are the two second-level units. Are these  
> > standard errors? Why the second vector contains a series of 
> different  > numbers?
>  >
>  > Thanks!
>  >
>  > Shige
>  >
>  > On 8/17/05, Doran, Harold <HDoran at air.org> wrote:
>  >
>  >>
>  >>
>  >>You can extract the posterior variance of the random effect from 
> the  >>bVar slot of the fitted lmer model. It is not a hidden option, 
> but a  >>part of the fitted model. It just doesn't show up when you 
> use  >  > summary().
>  >
>  >>
>  >> Look at the structure of your object to see what is available 
> using  >  > str().
>  >
>  >>
>  >> However, your comment below seems to imply that it is incorrect 
> for  >>lmer to report SDs instead of the standard error, which is not
true.
>  >>That is a quantity of direct interest.
>  >>
>  >> Other multilevel programs report the same exact statistics (for 
> the  >>most part). For instance, HLM reports the variances as well. If

> you  >>want the posterior variance of an HLM model you need to extract
it.
>  >>
>  >>
>  >>
>  >> -----Original Message-----
>  >> From:   r-help-bounces at stat.math.ethz.ch on behalf of
>  >>Shige Song
>  >> Sent:   Wed 8/17/2005 6:30 AM
>  >> To:     r-help at stat.math.ethz.ch
>  >> Cc:   
>  >> Subject:        [R] How to assess significance of random effect in
>  >
>  > lme4
>  >
>  >>
>  >> Dear All,
>  >>
>  >> With kind help from several friends on the list, I am getting
close.
>  >> Now here are something interesting I just realized: for random  
> >>effects, lmer reports standard deviation instead of standard error! 
> Is  >  >  >>there a hidden option that tells lmer to report standard 
> error of  >>random effects, like most other multilevel or mixed 
> modeling software,  >  >  >>so that we can say something like "randome

> effect for xxx is  >>significant, while randome effect for xxx is not 
> significant"? Thanks!
>  >>
>  >> Best,
>  >> Shige
>  >>
>  >> ______________________________________________
>  >> R-help at stat.math.ethz.ch mailing list  
> >>https://stat.ethz.ch/mailman/listinfo/r-help
>  >> PLEASE do read the posting guide!
>  >>http://www.R-project.org/posting-guide.html
>  >>
>  >>
>  >>
>  >>
>  >>
>  >
>  >
>  > ______________________________________________
>  > R-help at stat.math.ethz.ch mailing list  > 
> https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide!
>  > http://www.R-project.org/posting-guide.html
>  >
>  > ______________________________________________
>  > R-help at stat.math.ethz.ch mailing list  > 
> https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> --
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
> 
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915
> 
> 

--
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From christoph.lehmann at gmx.ch  Thu Aug 18 14:38:02 2005
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Thu, 18 Aug 2005 14:38:02 +0200 (MEST)
Subject: [R] =?iso-8859-1?q?lme_model=3A_Error_in_MEEM?=
Message-ID: <26790.1124368682@www6.gmx.net>

Hi,
We have data of two groups of subjects: 32 elderly, 14 young adults. for
each subject we have 15 observations, each observation consisting of a
reaction-time measure (RT) and an activation maesure (betadlpcv). 
since we want to analyze the influence of (age-)group and RT on the
activation, we call: 

lme(betadlpcv ~ RT*group, data=our.data, random=~ RT |subject)

this yields:
Error in MEEM(object, conLin, control$niterEM) :
        Singularity in backsolve at level 0, block 1
In addition: Warning message:
Fewer observations than random effects in all level 1 groups in:
lme.formula(betadlpcv ~ RT * group, data = patrizia.data, random = ~RT |

what's the problem here?

thanks for your kind help
christoph

-- 
Lust, ein paar Euro nebenbei zu verdienen? Ohne Kosten, ohne Risiko!
Satte Provisionen für GMX Partner: http://www.gmx.net/de/go/partner



From alxmilton at yahoo.it  Thu Aug 18 14:49:55 2005
From: alxmilton at yahoo.it (alessandro carletti)
Date: Thu, 18 Aug 2005 05:49:55 -0700 (PDT)
Subject: [R] select previous date
Message-ID: <20050818124955.28988.qmail@web26606.mail.ukl.yahoo.com>

Hi everybody,
could anyone help me in finding a way for selecting
from a dataframe each row that comes before another
that matches a condition?

EXAMPLE:
df
raw.number  name     date      temp
1            aaa   2001-04-15   15
2            aaa   2001-01-15   12
3            aaa   2001-03-15   13
...
i-1          bbb   2002-04-15   15 
i            bbb   2002-03-15   14

the condition is: 
df$temp==15
matching raws are 1 and i-1:
I need something to select (only) rows where date=one
month before the matching raws, so raws 3 and i.
(the variable name has more than one level)
Thanks



From dmbates at gmail.com  Thu Aug 18 15:29:52 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Thu, 18 Aug 2005 08:29:52 -0500
Subject: [R] lme model: Error in MEEM
In-Reply-To: <26790.1124368682@www6.gmx.net>
References: <26790.1124368682@www6.gmx.net>
Message-ID: <40e66e0b05081806296e19db00@mail.gmail.com>

On 8/18/05, Christoph Lehmann <christoph.lehmann at gmx.ch> wrote:
> Hi,
> We have data of two groups of subjects: 32 elderly, 14 young adults. for
> each subject we have 15 observations, each observation consisting of a
> reaction-time measure (RT) and an activation maesure (betadlpcv).
> since we want to analyze the influence of (age-)group and RT on the
> activation, we call:
> 
> lme(betadlpcv ~ RT*group, data=our.data, random=~ RT |subject)
> 
> this yields:
> Error in MEEM(object, conLin, control$niterEM) :
>         Singularity in backsolve at level 0, block 1
> In addition: Warning message:
> Fewer observations than random effects in all level 1 groups in:
> lme.formula(betadlpcv ~ RT * group, data = patrizia.data, random = ~RT |
> 
> what's the problem here?

It seems that you only have one observation per subject and you are
trying to estimate a model with two random effects per subject plus
the per-observation noise term.  These terms are completely
confounded.
> 
> thanks for your kind help
> christoph
> 
> --
> Lust, ein paar Euro nebenbei zu verdienen? Ohne Kosten, ohne Risiko!
> Satte Provisionen f??r GMX Partner: http://www.gmx.net/de/go/partner
> 
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From peterwyang at gmail.com  Thu Aug 18 15:31:34 2005
From: peterwyang at gmail.com (Peter Yang)
Date: Thu, 18 Aug 2005 09:31:34 -0400
Subject: [R] problems when installing R in Fedora core 4
Message-ID: <a922041d05081806313a98cc87@mail.gmail.com>

Hi, I got a problem when installing R in Fedora core 4. When I ran
.configure, it gave the following error message:

configure: error: --with-x=yes (default) and X11 headers/libs are not available

Could anyone tell me what's wrong? Am I missing some package in Fedora?

Thanks a lot for your help.

Peter



From gault at mnhn.fr  Thu Aug 18 15:40:19 2005
From: gault at mnhn.fr (Agnes Gault)
Date: Thu, 18 Aug 2005 15:40:19 +0200
Subject: [R] help with unknown function
Message-ID: <5.0.2.1.2.20050818153246.027e22c0@pop.mnhn.fr>

Hello

I am working on radio tracking data, with a short programme someone gave me 
and ... which should, supposedly, work ... In this programme, there is the 
function : getareahr(kern, levels = 95). But i cannot find any 'getareahr' 
in R ...

could anyone help me?

thanks!
Agn??s

-------------------------------------------------------------------------------------------------------------------

Agn??s GAULT
graduate student
UMR 5173 MNHN-CNRS-UPMC
case postale 50
Species Conservation, Restoration and Population Survey (CERSP)
61 rue Buffon, 1er ??tage
75005 PARIS
FRANCE
Tel: 33 (0)1 40 79 57 64
Fax: 33 (0)1 40 79 38 35
Email: gault at mnhn.fr



From dmbates at gmail.com  Thu Aug 18 15:41:50 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Thu, 18 Aug 2005 08:41:50 -0500
Subject: [R] accesing slots of S4 class in C code
In-Reply-To: <2372A3FFAF50104B9929841F6B9B878302109309@EMAIL.hci.utah.edu>
References: <2372A3FFAF50104B9929841F6B9B878302109309@EMAIL.hci.utah.edu>
Message-ID: <40e66e0b0508180641270c0959@mail.gmail.com>

On 8/17/05, Aniko Szabo <aniko.szabo at hci.utah.edu> wrote:
> I am trying to use a custom S4 object in my C code and I cannot get the
> access to its slots working.
> 
> 
> 
> The following is a toy example, but even this crashes.
> 
> 
> 
> In R I have:
> 
> 
> 
> setClass("pd", representation(data="numeric"))
> 
> x <- new("pd", data=1:5)
> 
> 
> 
> test <- function(pd.obj) {
> 
>   res <- .C("TestFun", pd.obj)
> 
>   res}
> 
> 
> 
> test(x)
> 
> 
> 
> (Of couse I load the DLL as well.)
> 
> 
> 
> The corresponding C file has:
> 
> 
> 
> SEXP TestFun(SEXP pd_obj)
> 
> {
> 
>  SEXP t=R_NilValue;
> 
>  PROTECT(t = GET_SLOT(pd_obj, install("data")));
> 
>  UNPROTECT(1);
> 
>  return(t);
> 
> }

Your C code is set for the .Call interface, not the .C interface. 
Change the R code to

 res <- .Call("TestFun", pd.obj)


> 
> 
> 
> 
> 
> What I hope to get as a result is the (1:5) vector.
> 
> In the long term, the vector will be a multi-dimensional array and I
> will want to do calculations using its contents in the C program.
> 
> 
> 
> Thanks for any help,
> 
> 
> 
> Aniko
> 
> 
> Huntsman Cancer Institute wishes to promote open communication while protecting confidential and/or privileged information.  If you have received this message in error, please inform the sender and delete all copies.
> 
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From martac21 at libero.it  Thu Aug 18 15:44:48 2005
From: martac21 at libero.it (Marta Colombo)
Date: Thu, 18 Aug 2005 15:44:48 +0200
Subject: [R] display of a loess fitted surface
Message-ID: <ILF7IO$9CFF67FC81A6F052FE7325FE2AA544B0@libero.it>

Good morning,
I am Marta Colombo,student at Politecnico,Milan. I am studying local regression models and I am using loess function. My problem is that when I have a loess object I don't know how to display the fitted surface; in fact, while in S when you have a loess object you can see it writing plot(object), in R this dosen't work. Also I'd like to know if there is something like the S function pointwise that computes upper and lower confidence intervals. 
Thank you very much for your attention.
Marta Colombo



From martac21 at libero.it  Thu Aug 18 15:45:14 2005
From: martac21 at libero.it (Marta Colombo)
Date: Thu, 18 Aug 2005 15:45:14 +0200
Subject: [R] display of a loess fitted surface
Message-ID: <ILF7JE$EC9ED36472C8D7F162FC616A52DB296F@libero.it>

Good morning,
I am Marta Colombo,student at Politecnico,Milan. I am studying local regression models and I am using loess function. My problem is that when I have a loess object I don't know how to display the fitted surface; in fact, while in S when you have a loess object you can see it writing plot(object), in R this dosen't work. Also I'd like to know if there is something like the S function pointwise that computes upper and lower confidence intervals. 
Thank you very much for your attention.
Marta Colombo



From rpeng at jhsph.edu  Thu Aug 18 15:46:54 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Thu, 18 Aug 2005 09:46:54 -0400
Subject: [R] problems when installing R in Fedora core 4
In-Reply-To: <a922041d05081806313a98cc87@mail.gmail.com>
References: <a922041d05081806313a98cc87@mail.gmail.com>
Message-ID: <4304914E.60402@jhsph.edu>

You are probably missing the 'devel' package for x11 which 
includes header files.

-roger

Peter Yang wrote:
> Hi, I got a problem when installing R in Fedora core 4. When I ran
> .configure, it gave the following error message:
> 
> configure: error: --with-x=yes (default) and X11 headers/libs are not available
> 
> Could anyone tell me what's wrong? Am I missing some package in Fedora?
> 
> Thanks a lot for your help.
> 
> Peter
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From guillaume.allain at cbconseil.com  Thu Aug 18 15:45:07 2005
From: guillaume.allain at cbconseil.com (Guillaume Allain)
Date: Thu, 18 Aug 2005 15:45:07 +0200
Subject: [R] how to draw an ellipse
In-Reply-To: <mailman.8.1124359201.6402.r-help@stat.math.ethz.ch>
References: <mailman.8.1124359201.6402.r-help@stat.math.ethz.ch>
Message-ID: <dc44ec828fdcb5bb02dd7ddf7d9c1b99@cbconseil.com>

That's probably a stupid question, but I'm looking for a low-level 
command which plots ellipse, specifying only center and deformation 
axes. The purpose is to illustrate bivariates gaussians with 2D .95 
confident levels without using any specific library.

Thanxs for your help,

Guillaume



From sfalcon at fhcrc.org  Thu Aug 18 15:50:38 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Thu, 18 Aug 2005 06:50:38 -0700
Subject: [R] accesing slots of S4 class in C code
References: <2372A3FFAF50104B9929841F6B9B878302109309@EMAIL.hci.utah.edu>
Message-ID: <m2r7crmk0h.fsf@macaroni.local>

Hi Aniko,

On 17 Aug 2005, aniko.szabo at hci.utah.edu wrote:

> I am trying to use a custom S4 object in my C code and I cannot get
> the access to its slots working.
>
> The following is a toy example, but even this crashes. 
> res <- .C("TestFun", pd.obj)

I'm pretty sure you want to use the .Call interface for this sort of
thing, not .C.  

Other than referring you to the Writing R Extensions manual, you might
want to look at the Ruuid package in Bioconductor which is quite
simple, but demonstrates accessing S4 classes from C.

See http://bioconductor.org/ to grab a source package of Ruuid.

Best,

+ seth

PS: Questions of this nature (C code type stuff) are better suited to
the R-devel mail list.



From baron at psych.upenn.edu  Thu Aug 18 15:56:15 2005
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Thu, 18 Aug 2005 09:56:15 -0400
Subject: [R] problems when installing R in Fedora core 4
In-Reply-To: <a922041d05081806313a98cc87@mail.gmail.com>
References: <a922041d05081806313a98cc87@mail.gmail.com>
Message-ID: <20050818135615.GA5929@psych>

On 08/18/05 09:31, Peter Yang wrote:
> Hi, I got a problem when installing R in Fedora core 4. When I ran
> .configure, it gave the following error message:
> 
> configure: error: --with-x=yes (default) and X11 headers/libs are not available
> 
> Could anyone tell me what's wrong? Am I missing some package in Fedora?

Yes, probably xorg-x11-devel, so do
yum install xorg-x11-devel
and you will probably get rid of THAT error message.

I'm treading into deeper water in what follows, but installation
depends on several other packages as well.  I discovered most of
these by looking at the error messages and then finding what rpm
provided the files needed.  I did this either with
rpm -q --whatprovides [the missing file]
on some other installation that happened to work, or by searching 
http://rpm.pbone.net.

Whether you have the needed files already depends on what kind of
installation you did.  Some of the packages are "devel" and
others are "compat".  Here is my list of "compat" rpms
that I have installed, and I think I installed all of these just
to get R to build:

compat-libf2c-32-3.2.3-47.fc4
compat-libstdc++-296-2.96-132.fc4
compat-readline43-4.3-2
compat-gcc-32-3.2.3-47.fc4

My hunch is that I still do not have the optimal installation,
but it is possible that the newest versions of gcc have solved
some of the problems with the ones that originally came with
FC4.  I've seen some discussion suggesting that the way to go is
to use an older version of gcc, but I did not search for it just
now.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron



From dmbates at gmail.com  Thu Aug 18 15:59:10 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Thu, 18 Aug 2005 08:59:10 -0500
Subject: [R] Error messages using LMER
In-Reply-To: <5abc11d805081801152c1f6661@mail.gmail.com>
References: <5abc11d805081801152c1f6661@mail.gmail.com>
Message-ID: <40e66e0b0508180659447f8321@mail.gmail.com>

On 8/18/05, Shige Song <shigesong at gmail.com> wrote:
> Dear All,
> 
> After playing with lmer for couple of days, I have to say that I am
> amazed! I've been using quite some multilevel/mixed modeling packages,
> lme4 is a strong candidate for the overall winner, especially for
> multilevel generzlized linear models.
> 
> Now go back to my two-level poisson model with cross-classified model.
> I've been testing various different model specificatios for the past
> couple of days. Here are the models I tried:
> 
> 1) Two level random intercept model with level-1 covariates only
> m1 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 ,
> data, poisson, method="Laplace")
> 
> 2) Two-level random intercept model with both level-1 and level-2
> covariates, but no cross-level interactions:
> m2 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 +
> z1 + z2, data, poisson, method="Laplace")
> 
> 3) Two-level random intercept with cross-level interaction
> m3 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 +
> z1 + z2 + x1:z1 + x2:z2, data, poisson, method="Laplace")
> 
> Both model 1 and 2 run fine. For model 3, I got error message:
> ----------------------------------
> Error in fn(par, ...) : Unable to invert singular factor of downdated X'X
> In addition: Warning messages:
> 1: optim or nlminb returned message ERROR: ABNORMAL_TERMINATION_IN_LNSRCH
>  in: LMEopt(x = mer, value = cv)
> 2: Leading minor of size 1 of downdated X'X is indefinite
> ----------------------------------
> 
> What is going on here? Any workarounds? Thanks!

The first thing I would try is set the EMverbose and msVerbose flags
in the control list to see what occurs within the optimization.  That
is append the argument

control = list(EMverbose = TRUE, msVerbose = TRUE)

to your call to lmer().  You may also want to try the call in a
recently compiled R-devel, which will be released as R-2.2.0 in
October.  You will notice that the first warning message reads "optim
or nlminb". In R-2.1.1 lmer uses optim for the optimization.  Starting
with R-2.2.0 the default is to use nlminb.

Test compilations of R-devel for Windows are available from CRAN.



From gavin.simpson at ucl.ac.uk  Thu Aug 18 15:59:19 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 18 Aug 2005 14:59:19 +0100
Subject: [R] problems when installing R in Fedora core 4
In-Reply-To: <a922041d05081806313a98cc87@mail.gmail.com>
References: <a922041d05081806313a98cc87@mail.gmail.com>
Message-ID: <1124373559.21043.53.camel@gsimpson.geog.ucl.ac.uk>

On Thu, 2005-08-18 at 09:31 -0400, Peter Yang wrote:
> Hi, I got a problem when installing R in Fedora core 4. When I ran
> .configure, it gave the following error message:
> 
> configure: error: --with-x=yes (default) and X11 headers/libs are not available
> 
> Could anyone tell me what's wrong? Am I missing some package in Fedora?
> 
> Thanks a lot for your help.
> 
> Peter

Yes, the development headers for X11.

If you use YUM, do the following in a shell:

su -c "yum install xorg-x11-devel"

Enter your root password and it will download and install the relevant
headers.

As an aside, are you aware of Martyn Plummer's R rpm binary? You can get
it from here: http://www.stats.bris.ac.uk/R/bin/linux/redhat/fc4/

HTH

Gav

> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From bolker at ufl.edu  Thu Aug 18 16:00:56 2005
From: bolker at ufl.edu (Ben Bolker)
Date: Thu, 18 Aug 2005 14:00:56 +0000 (UTC)
Subject: [R] how to draw an ellipse
References: <mailman.8.1124359201.6402.r-help@stat.math.ethz.ch>
	<dc44ec828fdcb5bb02dd7ddf7d9c1b99@cbconseil.com>
Message-ID: <loom.20050818T155940-397@post.gmane.org>


Guillaume Allain <guillaume.allain <at> cbconseil.com> writes:

> 
> That's probably a stupid question, but I'm looking for a low-level 
> command which plots ellipse, specifying only center and deformation 
> axes. The purpose is to illustrate bivariates gaussians with 2D .95 
> confident levels without using any specific library.
> 
> Thanxs for your help,
> 
> Guillaume


  I don't know exactly why you want to avoid "using any specific
library", but the ellipse package (sic) would seem to do what
you want pretty conveniently ...

  cheers
    Ben Bolker



From christoph.lehmann at gmx.ch  Thu Aug 18 16:13:36 2005
From: christoph.lehmann at gmx.ch (Christoph Lehmann)
Date: Thu, 18 Aug 2005 16:13:36 +0200 (MEST)
Subject: [R] =?iso-8859-1?q?lme_model=3A_Error_in_MEEM?=
References: <40e66e0b05081806296e19db00@mail.gmail.com>
Message-ID: <11983.1124374416@www52.gmx.net>

sorry, RT had an error in raw data and was treated as a factor. after
correction of the raw data (RT is numeric) now it works fine.

thanks a lot
christoph
> --- Urspr??ngliche Nachricht ---
> Von: Douglas Bates <dmbates at gmail.com>
> An: Christoph Lehmann <christoph.lehmann at gmx.ch>
> Kopie: r-help at stat.math.ethz.ch
> Betreff: Re: [R] lme model: Error in MEEM
> Datum: Thu, 18 Aug 2005 08:29:52 -0500
> 
> On 8/18/05, Christoph Lehmann <christoph.lehmann at gmx.ch> wrote:
> > Hi,
> > We have data of two groups of subjects: 32 elderly, 14 young adults. for
> > each subject we have 15 observations, each observation consisting of a
> > reaction-time measure (RT) and an activation maesure (betadlpcv).
> > since we want to analyze the influence of (age-)group and RT on the
> > activation, we call:
> > 
> > lme(betadlpcv ~ RT*group, data=our.data, random=~ RT |subject)
> > 
> > this yields:
> > Error in MEEM(object, conLin, control$niterEM) :
> >         Singularity in backsolve at level 0, block 1
> > In addition: Warning message:
> > Fewer observations than random effects in all level 1 groups in:
> > lme.formula(betadlpcv ~ RT * group, data = patrizia.data, random = ~RT |
> > 
> > what's the problem here?
> 
> It seems that you only have one observation per subject and you are
> trying to estimate a model with two random effects per subject plus
> the per-observation noise term.  These terms are completely
> confounded.
> > 
> > thanks for your kind help
> > christoph
> > 
> > --
> > Lust, ein paar Euro nebenbei zu verdienen? Ohne Kosten, ohne Risiko!
> > Satte Provisionen f??r GMX Partner: http://www.gmx.net/de/go/partner
> > 
> > 
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> > 
> >
> 

--



From ehlers at math.ucalgary.ca  Thu Aug 18 16:13:42 2005
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Thu, 18 Aug 2005 08:13:42 -0600
Subject: [R] trouble with wilcox.test
In-Reply-To: <Pine.LNX.4.61.0508180848540.23856@gannet.stats>
References: <001801c5a35f$a0de7000$43fde5a9@PC232921052285>	<Pine.LNX.4.61.0508172314540.16428@gannet.stats>	<43043ACD.7000402@math.ucalgary.ca>
	<Pine.LNX.4.61.0508180848540.23856@gannet.stats>
Message-ID: <43049796.5080006@math.ucalgary.ca>


I think your guess about stack overflow is probably correct and I
definitely don't think it's worth wasting effort recoding.

Peter Ehlers

Prof Brian Ripley wrote:
> If this is stack overflow (and I don't know that yet: when I tried this on 
> Windows the traceback was clearly corrupt, referring to bratio), the issue 
> is that it is impossible to catch such an error, and it is not even AFAIK
> portably possible to find the stack size limit (or even the current usage) 
> to do some estimates.  (The amount of RAM is not relevant.)  On 
> Unix-alikes the stack size limit can be controlled from the shell used to 
> launch R so we don't have any a priori knowledge.
> 
> The underlying code could be rewritten not to use recursion, but that 
> seems not worth the effort involved.
> 
> All I can see we can do it to put a warning in the help file.
> 

[snip]



From renaud.lancelot at cirad.fr  Thu Aug 18 16:17:42 2005
From: renaud.lancelot at cirad.fr (Renaud Lancelot)
Date: Thu, 18 Aug 2005 17:17:42 +0300
Subject: [R] help with unknown function
In-Reply-To: <5.0.2.1.2.20050818153246.027e22c0@pop.mnhn.fr>
References: <5.0.2.1.2.20050818153246.027e22c0@pop.mnhn.fr>
Message-ID: <43049886.3040404@cirad.fr>

Agnes Gault a ??crit :
> Hello
> 
> I am working on radio tracking data, with a short programme someone gave me 
> and ... which should, supposedly, work ... In this programme, there is the 
> function : getareahr(kern, levels = 95). But i cannot find any 'getareahr' 
> in R ...
> 
> could anyone help me?

It looks difficult given the (lack of) information you're giving. What 
are you trying to do ?

Best,

Renaud
> 
> thanks!
> Agn??s
> 
> -------------------------------------------------------------------------------------------------------------------
> 
> Agn??s GAULT
> graduate student
> UMR 5173 MNHN-CNRS-UPMC
> case postale 50
> Species Conservation, Restoration and Population Survey (CERSP)
> 61 rue Buffon, 1er ??tage
> 75005 PARIS
> FRANCE
> Tel: 33 (0)1 40 79 57 64
> Fax: 33 (0)1 40 79 38 35
> Email: gault at mnhn.fr
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Dr Renaud Lancelot, v??t??rinaire
Projet FSP r??gional ??pid??miologie v??t??rinaire
C/0 Ambassade de France - SCAC
BP 834 Antananarivo 101 - Madagascar

e-mail: renaud.lancelot at cirad.fr
tel.:   +261 32 40 165 53 (cell)
         +261 20 22 665 36 ext. 225 (work)



From ligges at statistik.uni-dortmund.de  Thu Aug 18 16:19:08 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 18 Aug 2005 16:19:08 +0200
Subject: [R] help with unknown function
In-Reply-To: <5.0.2.1.2.20050818153246.027e22c0@pop.mnhn.fr>
References: <5.0.2.1.2.20050818153246.027e22c0@pop.mnhn.fr>
Message-ID: <430498DC.2090805@statistik.uni-dortmund.de>

Agnes Gault wrote:

> Hello
> 
> I am working on radio tracking data, with a short programme someone gave me 
> and ... which should, supposedly, work ... In this programme, there is the 
> function : getareahr(kern, levels = 95). But i cannot find any 'getareahr' 
> in R ...
 >
> could anyone help me?

Don't know. I'd rather ask someone.  ;-)
I mean the same someone you got the code from, because getareahr() might 
be his/her private invention.

Uwe Ligges

> thanks!
> Agn??s
> 
> -------------------------------------------------------------------------------------------------------------------
> 
> Agn??s GAULT
> graduate student
> UMR 5173 MNHN-CNRS-UPMC
> case postale 50
> Species Conservation, Restoration and Population Survey (CERSP)
> 61 rue Buffon, 1er ??tage
> 75005 PARIS
> FRANCE
> Tel: 33 (0)1 40 79 57 64
> Fax: 33 (0)1 40 79 38 35
> Email: gault at mnhn.fr
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From francoisromain at free.fr  Thu Aug 18 16:22:25 2005
From: francoisromain at free.fr (Romain Francois)
Date: Thu, 18 Aug 2005 16:22:25 +0200
Subject: [R] how to draw an ellipse
In-Reply-To: <dc44ec828fdcb5bb02dd7ddf7d9c1b99@cbconseil.com>
References: <mailman.8.1124359201.6402.r-help@stat.math.ethz.ch>
	<dc44ec828fdcb5bb02dd7ddf7d9c1b99@cbconseil.com>
Message-ID: <430499A1.9080200@free.fr>

Le 18.08.2005 15:45, Guillaume Allain a ??crit :

>That's probably a stupid question, but I'm looking for a low-level 
>command which plots ellipse, specifying only center and deformation 
>axes. The purpose is to illustrate bivariates gaussians with 2D .95 
>confident levels without using any specific library.
>
>Thanxs for your help,
>
>Guillaume
>  
>
Hello,

Why don't you want to use any specific library ? You can't reinvent the 
wheel !!
There is a package ellipse on CRAN which will do what you are looking for.
Have you tried
 > RSiteSearch("ellipse")

Cheers,

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From patrick.giraudoux at univ-fcomte.fr  Thu Aug 18 16:21:07 2005
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Thu, 18 Aug 2005 16:21:07 +0200
Subject: [R] axTicks and window resizing
Message-ID: <43049953.40107@univ-fcomte.fr>

Dear listers,

I have written a function to facilitate the drawing of altitude profiles 
with x (distance), y (altitude) and a z  parameter (altitude magnification).

profplot<-function(x,y,z=10,...){
op <- par()$mai
par(mai=c(0.95625,0.76875,0.76875,0.95625))
plot(x,y*z, type="l",asp=1,las=1,xlab="",ylab="",yaxt="n",...)
axis(2,labels=axTicks(2)/z,las=1)
axis(4,labels=axTicks(2)/z,las=1)
on.exit(par(mai=op))
}

This worked apparently well until I had to resize the graphical window 
after plotting. In this case, I get this message:

 >  profplot(prof$dist,prof$alt,col="blue")
 > Erreur : les longueurs de 'at' et de 'label' diff??rent, 7 != 8

Which means Error: length of 'at' and "label' differ, 7!=8 (whish R 
2.1.1 could be parametrise 'English' even with a French Windows XP!!!!)

At this stage, R crashes (= I cannot get the graphic window 
working/resized and must interrupt the process from Windows XP, then 
restart R for good work with the graphical window).

The error occur with the difference between the tick number computed 
from plot() and the one computed with axTicks(). If still equal (slight 
resizing) everything goes smoothly.

Thanks for any comments, even rude... (I am not sure the 
problem/programme has been tackled relevantly enough)

Patrick



From dargosch at gmail.com  Thu Aug 18 16:27:36 2005
From: dargosch at gmail.com (Fredrik Karlsson)
Date: Thu, 18 Aug 2005 16:27:36 +0200
Subject: [R] How do I make a Sweave + latex table out of this ?
Message-ID: <376e97ec050818072772216421@mail.gmail.com>

Dear list,

I have a table that I would like to convert to latex for inclusion
into a Sweave file.


> round(ftable(prop.table(xtabs(~agemF + votcat + Type , data=work),margin=2))*100,1)
                  Type Voiced Voiceless unaspirated Voiceless aspirated
agemF   votcat                                                         
18 - 24 Prevoiced         2.6                   8.7                 2.3
             Short lag         5.8                   6.7                 5.1
            Long lag          1.0                   1.9                 2.9
24 - 30 Prevoiced        15.1                  10.5                 1.7
             Short lag         9.2                  15.3                 5.8
            Long lag          3.5                   8.1                15.8
30 - 36 Prevoiced        12.8                  14.0                 2.6
            Short lag        10.2                  14.2                 3.0
            Long lag          2.3                   5.5                22.2
36 - 42 Prevoiced         4.4                   6.4                 0.6
           Short lag         4.0                   5.9                 1.5
           Long lag          1.3                   2.9                 9.4
42 - 48 Prevoiced         6.4                   2.3                 0.3
           Short lag         3.0                   2.8                 1.4
           Long lag          0.6                   7.7                 8.8
48 - 54 Prevoiced         4.9                   4.1                 0.3
            Short lag         2.0                   2.7                 1.3
             Long lag          0.3                   0.9                 4.7


However, I have not been able to use this as a table. The Hmisc latex
command only accepts the input if I first convert it to a data.frame
format, and that makes the output much more difficult to read as it
duplicates the category levels of agemF.

Is there a way to do this?


/Fredrik Karlsson



From yhu at mail.nih.gov  Thu Aug 18 16:38:34 2005
From: yhu at mail.nih.gov (Hu, Ying (NIH/NCI))
Date: Thu, 18 Aug 2005 10:38:34 -0400
Subject: [R] do glm with two data sets
Message-ID: <27C204BD76CBC142BA1AE46D62A8548E490BFE@nihexchange9.nih.gov>

Thanks for your help.

# read the two data sets
e <- as.matrix(read.table("file1.txt", header=TRUE,row.names=1))
g <- as.matrix(read.table("file2.txt", header=TRUE,row.names=1))

# solution 
d1<-data.frame(g[1,], e[1,])
fit<-glm(e[1,] ~ g[1,], data=d1)
summary(fit)

I am not sure that is the best solution.

Thanks again,

Ying
 

-----Original Message-----
From: Gavin Simpson [mailto:gavin.simpson at ucl.ac.uk] 
Sent: Wednesday, August 17, 2005 7:01 PM
To: Sundar Dorai-Raj
Cc: Hu, Ying (NIH/NCI); r-help at stat.math.ethz.ch
Subject: Re: [R] do glm with two data sets

On Wed, 2005-08-17 at 17:22 -0500, Sundar Dorai-Raj wrote:
> 
> Hu, Ying (NIH/NCI) wrote:
> > I have two data sets:
> > File1.txt: 
> > Name id1   id2   id3   ...
> > N1    0     1     0     ...
> > N2    0     1     1     ...
> > N3    1     1     -1    ...
> > ...
> >  
> > File2.txt:
> > Group id1       id2       id3       ...
> > G1       1.22     1.34     2.44     ...
> > G2       2.33     2.56     2.56     ...
> > G3       1.56     1.99     1.46     ...
> > ...
> > I like to do:
> > x1<-c(0,1,0,...)
> > y1<-c(1.22,1.34, 2.44, ...)
> > z1<-data.frame(x,y)
> > summary(glm(y1~x1,data=z1)
> >  
> > But I do the same thing by inputting the data sets from the two files
> > e <- read.table("file1.txt", header=TRUE,row.names=1)
> > g <- read.table("file2.txt", header=TRUE,row.names=1)
> > e1<-exp[1,]
> > g1<-geno[1,]
> > d1<-data.frame(g, e)
> > summary(glm(e1 ~ g1, data=d1))
> >  
> > the error message is 
> > Error in model.frame(formula, rownames, variables, varnames, extras,
> > extranames,  : 
> >         invalid variable type
> > Execution halted
> >  
> > Thanks in advance,
> >  
> > Ying

Hi Ying,

That error message is likely caused by having a data.frame on the right
hand side (rhs) of the formula. You can't have a data.frame on the rhs
of a formula and g1 is still a data frame even if you only choose the
first row, e.g.:

dat <- as.data.frame(matrix(100, 10, 10))
class(dat[1, ])
[1] "data.frame"

You could try:

glm(e1 ~ ., data=g1[1, ])

and see if that works, but as Sundar notes, your post is a little
difficult to follow, so this may not do what you were trying to achieve.

HTH

Gav

> 
> You have several inconsistencies in your example, so it will be 
> difficult to figure out what you are trying to accomplish.
> 
>  > e <- read.table("file1.txt", header=TRUE,row.names=1)
>  > g <- read.table("file2.txt", header=TRUE,row.names=1)
>  > e1<-exp[1,]
> 
> What's "exp"? Also it's dangerous to use an R function as a variable 
> name. Most of the time R can tell the difference, but in some cases it 
> cannot.
> 
>  > g1<-geno[1,]
> 
> What's "geno"?
> 
>  > d1<-data.frame(g, e)
> 
> d1 is now e and g cbind'ed together?
> 
>  > summary(glm(e1 ~ g1, data=d1))
> 
> Are "e1" and "g1" elements of "d1"? From what you've told us, I don't 
> know where the error is occurring. Also, if you are having errors, you 
> can more easily isolate the problem by doing:
> 
> fit <- glm(e1 ~ g1, data = d1)
> summary(fit)
> 
> This will at least tell you the problem is in your call to "glm" and not 
> "summary.glm".
> 
> --sundar
> 
> P.S. Please (re-)read the POSTING GUIDE. Most of the time you will 
> figure out problems such as these on your own during the process of 
> creating a reproducible example.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From dieter.menne at menne-biomed.de  Thu Aug 18 16:39:42 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Thu, 18 Aug 2005 14:39:42 +0000 (UTC)
Subject: [R] lme model: Error in MEEM
References: <26790.1124368682@www6.gmx.net>
Message-ID: <loom.20050818T163644-791@post.gmane.org>

Christoph Lehmann <christoph.lehmann <at> gmx.ch> writes:

> 
> Hi,
> We have data of two groups of subjects: 32 elderly, 14 young adults. for
> each subject we have 15 observations, each observation consisting of a
> reaction-time measure (RT) and an activation maesure (betadlpcv). 
> since we want to analyze the influence of (age-)group and RT on the
> activation, we call: 
> 
> lme(betadlpcv ~ RT*group, data=our.data, random=~ RT |subject)
> 
> this yields:
> Error in MEEM(object, conLin, control$niterEM) :
>         Singularity in backsolve at level 0, block 1

If you really have 15 observations (690 lines) it should be enough to estimate 
the model (see below). Assume you had some degenerate case. From a 
psychophysical point of view, I am surprised that reaction time is on the right 
side, but that's off-subject.

Dieter

----
sub = data.frame(subject=1:46,group=c(rep("old",32),rep("young",14)))
sub$slope = 2.5+as.numeric(sub$group)+rnorm(46,0.5)

beta = data.frame(
      subject=rep(sub$subject,15),
      group=rep(sub$group,15),
      slope=rep(sub$slope,15),
      RT=rnorm(46*15,100,20))

beta$betadlpcv = beta$slope*beta$RT + rnorm(46*15,0.1)

library(nlme)
beta.lme = lme(betadlpcv ~ RT*group, data=beta, random=~ RT |subject)
summary(beta.lme)



From sundar.dorai-raj at pdf.com  Thu Aug 18 16:47:44 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 18 Aug 2005 09:47:44 -0500
Subject: [R] do glm with two data sets
In-Reply-To: <27C204BD76CBC142BA1AE46D62A8548E490BFE@nihexchange9.nih.gov>
References: <27C204BD76CBC142BA1AE46D62A8548E490BFE@nihexchange9.nih.gov>
Message-ID: <43049F90.5020601@pdf.com>



Hu, Ying (NIH/NCI) wrote:
> Thanks for your help.
> 
> # read the two data sets
> e <- as.matrix(read.table("file1.txt", header=TRUE,row.names=1))
> g <- as.matrix(read.table("file2.txt", header=TRUE,row.names=1))
> 
> # solution 
> d1<-data.frame(g[1,], e[1,])
> fit<-glm(e[1,] ~ g[1,], data=d1)
> summary(fit)
> 
> I am not sure that is the best solution.
> 
> Thanks again,
> 
> Ying
>  


Hi, Ying,

What's wrong with this solution? Do you still get an error? What is your 
primary goal?

A couple of points:

1. It's better to use names in your data.frame:

d1 <- data.frame(g = g[1,], e = e[1,])

Then in glm:

fit <- glm(e ~ g, data = d1)

2. Also, you may just be giving us a toy example, but if you don't 
specify a family argument in glm then you are simply getting the least 
squares. In that case you should use ?lm instead.

HTH,

--sundar

> 
> -----Original Message-----
> From: Gavin Simpson [mailto:gavin.simpson at ucl.ac.uk] 
> Sent: Wednesday, August 17, 2005 7:01 PM
> To: Sundar Dorai-Raj
> Cc: Hu, Ying (NIH/NCI); r-help at stat.math.ethz.ch
> Subject: Re: [R] do glm with two data sets
> 
> On Wed, 2005-08-17 at 17:22 -0500, Sundar Dorai-Raj wrote:
> 
>>Hu, Ying (NIH/NCI) wrote:
>>
>>>I have two data sets:
>>>File1.txt: 
>>>Name id1   id2   id3   ...
>>>N1    0     1     0     ...
>>>N2    0     1     1     ...
>>>N3    1     1     -1    ...
>>>...
>>> 
>>>File2.txt:
>>>Group id1       id2       id3       ...
>>>G1       1.22     1.34     2.44     ...
>>>G2       2.33     2.56     2.56     ...
>>>G3       1.56     1.99     1.46     ...
>>>...
>>>I like to do:
>>>x1<-c(0,1,0,...)
>>>y1<-c(1.22,1.34, 2.44, ...)
>>>z1<-data.frame(x,y)
>>>summary(glm(y1~x1,data=z1)
>>> 
>>>But I do the same thing by inputting the data sets from the two files
>>>e <- read.table("file1.txt", header=TRUE,row.names=1)
>>>g <- read.table("file2.txt", header=TRUE,row.names=1)
>>>e1<-exp[1,]
>>>g1<-geno[1,]
>>>d1<-data.frame(g, e)
>>>summary(glm(e1 ~ g1, data=d1))
>>> 
>>>the error message is 
>>>Error in model.frame(formula, rownames, variables, varnames, extras,
>>>extranames,  : 
>>>        invalid variable type
>>>Execution halted
>>> 
>>>Thanks in advance,
>>> 
>>>Ying
> 
> 
> Hi Ying,
> 
> That error message is likely caused by having a data.frame on the right
> hand side (rhs) of the formula. You can't have a data.frame on the rhs
> of a formula and g1 is still a data frame even if you only choose the
> first row, e.g.:
> 
> dat <- as.data.frame(matrix(100, 10, 10))
> class(dat[1, ])
> [1] "data.frame"
> 
> You could try:
> 
> glm(e1 ~ ., data=g1[1, ])
> 
> and see if that works, but as Sundar notes, your post is a little
> difficult to follow, so this may not do what you were trying to achieve.
> 
> HTH
> 
> Gav
> 
> 
>>You have several inconsistencies in your example, so it will be 
>>difficult to figure out what you are trying to accomplish.
>>
>> > e <- read.table("file1.txt", header=TRUE,row.names=1)
>> > g <- read.table("file2.txt", header=TRUE,row.names=1)
>> > e1<-exp[1,]
>>
>>What's "exp"? Also it's dangerous to use an R function as a variable 
>>name. Most of the time R can tell the difference, but in some cases it 
>>cannot.
>>
>> > g1<-geno[1,]
>>
>>What's "geno"?
>>
>> > d1<-data.frame(g, e)
>>
>>d1 is now e and g cbind'ed together?
>>
>> > summary(glm(e1 ~ g1, data=d1))
>>
>>Are "e1" and "g1" elements of "d1"? From what you've told us, I don't 
>>know where the error is occurring. Also, if you are having errors, you 
>>can more easily isolate the problem by doing:
>>
>>fit <- glm(e1 ~ g1, data = d1)
>>summary(fit)
>>
>>This will at least tell you the problem is in your call to "glm" and not 
>>"summary.glm".
>>
>>--sundar
>>
>>P.S. Please (re-)read the POSTING GUIDE. Most of the time you will 
>>figure out problems such as these on your own during the process of 
>>creating a reproducible example.
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
> 
> http://www.R-project.org/posting-guide.html



From gavin.simpson at ucl.ac.uk  Thu Aug 18 17:00:12 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Thu, 18 Aug 2005 16:00:12 +0100
Subject: [R] do glm with two data sets
In-Reply-To: <27C204BD76CBC142BA1AE46D62A8548E490BFE@nihexchange9.nih.gov>
References: <27C204BD76CBC142BA1AE46D62A8548E490BFE@nihexchange9.nih.gov>
Message-ID: <1124377212.21043.62.camel@gsimpson.geog.ucl.ac.uk>

On Thu, 2005-08-18 at 10:38 -0400, Hu, Ying (NIH/NCI) wrote:
> Thanks for your help.
> 
> # read the two data sets
> e <- as.matrix(read.table("file1.txt", header=TRUE,row.names=1))
> g <- as.matrix(read.table("file2.txt", header=TRUE,row.names=1))
> # solution 
> d1<-data.frame(g[1,], e[1,])

This is redundant, as:

> fit<-glm(e[1,] ~ g[1,], data=d1)

and:

fit <- glm(e[1, ] ~ g[1, ])

are equivalent - you don't need data = d1 in this case, e.g:

e <- matrix(c(0, 1, 0, 0, 1, 1, 1, 1, -1), ncol = 3, byrow = TRUE)
e
g <- matrix(c(1.22, 1.34, 2.44, 2.33, 2.56, 2.56, 1.56, 1.99, 1.46),
ncol = 3, byrow = TRUE)
g
fit <- glm(e[1, ] ~ g[1, ])
fit

works fine.

> summary(fit)
> 
> I am not sure that is the best solution.

This seems a strange way of doing this. Why not:

pred <- g[1, ]
resp <- e[1, ]
fit <- glm(resp ~ pred)
fit

and do your subsetting outside the glm call - makes things clearer no?
Unless you plan to do many glm()s one per row of your two matrices. If
that is the case, then there are better ways of approaching this.

> Thanks again,
> 
> Ying

HTH

G

> 
> -----Original Message-----
> From: Gavin Simpson [mailto:gavin.simpson at ucl.ac.uk] 
> Sent: Wednesday, August 17, 2005 7:01 PM
> To: Sundar Dorai-Raj
> Cc: Hu, Ying (NIH/NCI); r-help at stat.math.ethz.ch
> Subject: Re: [R] do glm with two data sets
> 
> On Wed, 2005-08-17 at 17:22 -0500, Sundar Dorai-Raj wrote:
> > 
> > Hu, Ying (NIH/NCI) wrote:
> > > I have two data sets:
> > > File1.txt: 
> > > Name id1   id2   id3   ...
> > > N1    0     1     0     ...
> > > N2    0     1     1     ...
> > > N3    1     1     -1    ...
> > > ...
> > >  
> > > File2.txt:
> > > Group id1       id2       id3       ...
> > > G1       1.22     1.34     2.44     ...
> > > G2       2.33     2.56     2.56     ...
> > > G3       1.56     1.99     1.46     ...
> > > ...
> > > I like to do:
> > > x1<-c(0,1,0,...)
> > > y1<-c(1.22,1.34, 2.44, ...)
> > > z1<-data.frame(x,y)
> > > summary(glm(y1~x1,data=z1)
> > >  
> > > But I do the same thing by inputting the data sets from the two files
> > > e <- read.table("file1.txt", header=TRUE,row.names=1)
> > > g <- read.table("file2.txt", header=TRUE,row.names=1)
> > > e1<-exp[1,]
> > > g1<-geno[1,]
> > > d1<-data.frame(g, e)
> > > summary(glm(e1 ~ g1, data=d1))
> > >  
> > > the error message is 
> > > Error in model.frame(formula, rownames, variables, varnames, extras,
> > > extranames,  : 
> > >         invalid variable type
> > > Execution halted
> > >  
> > > Thanks in advance,
> > >  
> > > Ying
> 
> Hi Ying,
> 
> That error message is likely caused by having a data.frame on the right
> hand side (rhs) of the formula. You can't have a data.frame on the rhs
> of a formula and g1 is still a data frame even if you only choose the
> first row, e.g.:
> 
> dat <- as.data.frame(matrix(100, 10, 10))
> class(dat[1, ])
> [1] "data.frame"
> 
> You could try:
> 
> glm(e1 ~ ., data=g1[1, ])
> 
> and see if that works, but as Sundar notes, your post is a little
> difficult to follow, so this may not do what you were trying to achieve.
> 
> HTH
> 
> Gav
> 
> > 
> > You have several inconsistencies in your example, so it will be 
> > difficult to figure out what you are trying to accomplish.
> > 
> >  > e <- read.table("file1.txt", header=TRUE,row.names=1)
> >  > g <- read.table("file2.txt", header=TRUE,row.names=1)
> >  > e1<-exp[1,]
> > 
> > What's "exp"? Also it's dangerous to use an R function as a variable 
> > name. Most of the time R can tell the difference, but in some cases it 
> > cannot.
> > 
> >  > g1<-geno[1,]
> > 
> > What's "geno"?
> > 
> >  > d1<-data.frame(g, e)
> > 
> > d1 is now e and g cbind'ed together?
> > 
> >  > summary(glm(e1 ~ g1, data=d1))
> > 
> > Are "e1" and "g1" elements of "d1"? From what you've told us, I don't 
> > know where the error is occurring. Also, if you are having errors, you 
> > can more easily isolate the problem by doing:
> > 
> > fit <- glm(e1 ~ g1, data = d1)
> > summary(fit)
> > 
> > This will at least tell you the problem is in your call to "glm" and not 
> > "summary.glm".
> > 
> > --sundar
> > 
> > P.S. Please (re-)read the POSTING GUIDE. Most of the time you will 
> > figure out problems such as these on your own during the process of 
> > creating a reproducible example.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From B.Rowlingson at lancaster.ac.uk  Thu Aug 18 17:31:22 2005
From: B.Rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Thu, 18 Aug 2005 16:31:22 +0100
Subject: [R] how to draw an ellipse
In-Reply-To: <430499A1.9080200@free.fr>
References: <mailman.8.1124359201.6402.r-help@stat.math.ethz.ch>	<dc44ec828fdcb5bb02dd7ddf7d9c1b99@cbconseil.com>
	<430499A1.9080200@free.fr>
Message-ID: <4304A9CA.3050808@lancaster.ac.uk>

Romain Francois wrote:

> Why don't you want to use any specific library ? You can't reinvent the 
> wheel !!

  True, but Madonna is always reinventing herself...

> There is a package ellipse on CRAN which will do what you are looking for.
> Have you tried
>  > RSiteSearch("ellipse")

  its simple geometry really:

  > theta=seq(0,2*pi,len=100)
  > e=1.5
  > r=3
  > x=e*r*cos(theta)
  > y=r*sin(theta)
  > plot(x,y,asp=1)

  rotate with:

  > phi=pi/4
  > xr=x*sin(phi)+y*cos(phi)
  > yr=-x*cos(phi)+y*sin(phi)
  > plot(xr,yr,asp=1)

  or something. Wrap that up into a function and you're done. This is 
off-the-cuff, I've probably messed something up. So use one prepared 
earlier from a library...

Baz



From guillaume.allain at cbconseil.com  Thu Aug 18 17:36:24 2005
From: guillaume.allain at cbconseil.com (Guillaume Allain)
Date: Thu, 18 Aug 2005 17:36:24 +0200
Subject: [R] how to draw an ellipse
In-Reply-To: <4304A9CA.3050808@lancaster.ac.uk>
References: <mailman.8.1124359201.6402.r-help@stat.math.ethz.ch>	<dc44ec828fdcb5bb02dd7ddf7d9c1b99@cbconseil.com>
	<430499A1.9080200@free.fr> <4304A9CA.3050808@lancaster.ac.uk>
Message-ID: <f250867b1b7cc7d6913bd5fb59ce951a@cbconseil.com>

Congratulations guys, you made my day better and funnier!

Le 18 ao??t 05, ?? 17:31, Barry Rowlingson a ??crit :

> Romain Francois wrote:
>
>> Why don't you want to use any specific library ? You can't reinvent 
>> the wheel !!
>
>  True, but Madonna is always reinventing herself...
>
>> There is a package ellipse on CRAN which will do what you are looking 
>> for.
>> Have you tried
>>  > RSiteSearch("ellipse")
>
>  its simple geometry really:
>
>  > theta=seq(0,2*pi,len=100)
>  > e=1.5
>  > r=3
>  > x=e*r*cos(theta)
>  > y=r*sin(theta)
>  > plot(x,y,asp=1)
>
>  rotate with:
>
>  > phi=pi/4
>  > xr=x*sin(phi)+y*cos(phi)
>  > yr=-x*cos(phi)+y*sin(phi)
>  > plot(xr,yr,asp=1)
>
>  or something. Wrap that up into a function and you're done. This is 
> off-the-cuff, I've probably messed something up. So use one prepared 
> earlier from a library...
>
> Baz
>
>
______________________________
Guillaume Allain
Carte Blanche Conseil
47 rue de Lancry 75010
Tel   : 01 42412121
Mail : guillaume.allain at cbconseil.com



From edhuang00 at yahoo.com  Thu Aug 18 17:42:07 2005
From: edhuang00 at yahoo.com (Haibo Huang)
Date: Thu, 18 Aug 2005 08:42:07 -0700 (PDT)
Subject: [R] How to do log normal regression?
Message-ID: <20050818154207.70692.qmail@web31012.mail.mud.yahoo.com>


I want to fit a Log-Normal CDF function between two
variables, and estimate the parameters. Is there any
package/functions designed for this purpose? 

Basically, I have data for Y and X, and I suspect the
relationship between Y and X is Y = CDF Log-Normal
(X), and I want to run this regression to verify this
and estimate the parameters. Anyone has any thoughts?

Any input is valuable to me, so please do not hesitate
to share your thoughts. Thank you!

Ed.



From ripley at stats.ox.ac.uk  Thu Aug 18 17:59:57 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 Aug 2005 16:59:57 +0100 (BST)
Subject: [R] display of a loess fitted surface
In-Reply-To: <ILF7JE$EC9ED36472C8D7F162FC616A52DB296F@libero.it>
References: <ILF7JE$EC9ED36472C8D7F162FC616A52DB296F@libero.it>
Message-ID: <Pine.LNX.4.61.0508181654200.4094@gannet.stats>

On Thu, 18 Aug 2005, Marta Colombo wrote:

> I am Marta Colombo,student at Politecnico,Milan. I am studying local 
> regression models and I am using loess function. My problem is that when 
> I have a loess object I don't know how to display the fitted surface; in 
> fact, while in S when you have a loess object you can see it writing 
> plot(object), in R this dosen't work.

Why not use S if that does what you want?

There are examples using R in MASS, for example: see the ch04.R and ch15.R 
scripts.

> Also I'd like to know if there is something like the S function 
> pointwise that computes upper and lower confidence intervals.

(Do you mean upper and lower confidence limits?)

Thats a more general question.  Many of R's predict() methods can 
construct confidence (and tolerance) intervals.  If not, it is easy to do 
this yourself, as pred_obj$fit-/+pred_obj$se*qnorm(alpha/2).


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Karthik.Devarajan at fccc.edu  Thu Aug 18 18:08:32 2005
From: Karthik.Devarajan at fccc.edu (Devarajan, Karthik)
Date: Thu, 18 Aug 2005 12:08:32 -0400
Subject: [R] standard errors for expression intensities
Message-ID: <D45546375992BF429A93F7203358F14403429563@sirius.fccc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050818/5c0b08c5/attachment.pl

From bernd.weiss at uni-koeln.de  Thu Aug 18 18:10:14 2005
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Thu, 18 Aug 2005 18:10:14 +0200
Subject: [R] Regular expressions & sub
Message-ID: <4304CF06.6868.25A7176@localhost>

Dear all,

I am struggling with the use of regular expression. I got

> as.character(test$sample.id)
 [1] "1.11"   "10.11"  "11.11"  "113.31" "114.2"  "114.3"  "114.8"  

and need

[1] "11"   "11"  "11"  "31" "2"  "3"  "8"

I.e. remove everything before the "." .

TIA,

Bernd



From richmcb at gmail.com  Thu Aug 18 18:14:55 2005
From: richmcb at gmail.com (Ben Rich)
Date: Thu, 18 Aug 2005 18:14:55 +0200
Subject: [R] select previous date
In-Reply-To: <20050818124955.28988.qmail@web26606.mail.ukl.yahoo.com>
References: <20050818124955.28988.qmail@web26606.mail.ukl.yahoo.com>
Message-ID: <32acb1210508180914d0496a5@mail.gmail.com>

You can try this:

dates <- df$date[df$temp==15]
one.month.before <- sapply(strsplit(dates, "-"), function(x)
paste(x[1], sprintf("%02d", as.numeric(x[2])-1), x[3], sep="-"))
df[df$date %in% one.month.before,]

Ben

On 8/18/05, alessandro carletti <alxmilton at yahoo.it> wrote:
> Hi everybody,
> could anyone help me in finding a way for selecting
> from a dataframe each row that comes before another
> that matches a condition?
> 
> EXAMPLE:
> df
> raw.number  name     date      temp
> 1            aaa   2001-04-15   15
> 2            aaa   2001-01-15   12
> 3            aaa   2001-03-15   13
> ...
> i-1          bbb   2002-04-15   15
> i            bbb   2002-03-15   14
> 
> the condition is:
> df$temp==15
> matching raws are 1 and i-1:
> I need something to select (only) rows where date=one
> month before the matching raws, so raws 3 and i.
> (the variable name has more than one level)
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Thu Aug 18 18:17:10 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 Aug 2005 17:17:10 +0100 (BST)
Subject: [R] axTicks and window resizing
In-Reply-To: <43049953.40107@univ-fcomte.fr>
References: <43049953.40107@univ-fcomte.fr>
Message-ID: <Pine.LNX.4.61.0508181711520.4094@gannet.stats>

On Thu, 18 Aug 2005, Patrick Giraudoux wrote:

> Dear listers,
>
> I have written a function to facilitate the drawing of altitude profiles
> with x (distance), y (altitude) and a z  parameter (altitude magnification).
>
> profplot<-function(x,y,z=10,...){
> op <- par()$mai
> par(mai=c(0.95625,0.76875,0.76875,0.95625))
> plot(x,y*z, type="l",asp=1,las=1,xlab="",ylab="",yaxt="n",...)
> axis(2,labels=axTicks(2)/z,las=1)
> axis(4,labels=axTicks(2)/z,las=1)
> on.exit(par(mai=op))
> }
>
> This worked apparently well until I had to resize the graphical window
> after plotting. In this case, I get this message:
>
> >  profplot(prof$dist,prof$alt,col="blue")
> > Erreur : les longueurs de 'at' et de 'label' diff?rent, 7 != 8
>
> Which means Error: length of 'at' and "label' differ, 7!=8 (whish R
> 2.1.1 could be parametrise 'English' even with a French Windows XP!!!!)

If I understand you correctly, it can.  Just add LANGUAGE=en to the 
shortcut.

> At this stage, R crashes (= I cannot get the graphic window
> working/resized and must interrupt the process from Windows XP, then
> restart R for good work with the graphical window).
>
> The error occur with the difference between the tick number computed
> from plot() and the one computed with axTicks(). If still equal (slight
> resizing) everything goes smoothly.

The problem is that you need to specify 'at' and 'labels' to axis(): you 
cannot safely specify just labels.  When re-drawing, 'at' is recomputed, 
but your specification of 'labels' is not.

I suspect you can just do dev.off() and open a new graphics window.

> Thanks for any comments, even rude... (I am not sure the
> problem/programme has been tackled relevantly enough)
>
> Patrick
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From yhu at mail.nih.gov  Thu Aug 18 18:29:54 2005
From: yhu at mail.nih.gov (Hu, Ying (NIH/NCI))
Date: Thu, 18 Aug 2005 12:29:54 -0400
Subject: [R] do glm with two data sets
Message-ID: <27C204BD76CBC142BA1AE46D62A8548E490BFF@nihexchange9.nih.gov>

You are right. 
# read the two data sets
e <- as.matrix(read.table("file1.txt", header=TRUE,row.names=1))
g <- as.matrix(read.table("file2.txt", header=TRUE,row.names=1))

# solution 2
summary(glm(e[1,] ~ g[1,]))
summary(glm(e[1,] ~ g[2,]))
...
They work very well.

If I put it in the loop, such as

for (i in 1:50){
  for (j in 1:50){
     cat("file1 row:", i, "file2 row:", j, "\n")
     print(summary(glm(e[i,] ~ g[j,])))
  }
} 

Why do I have to use "print" to print the results? If without "print"
for (i in 1:50){
  for (j in 1:50){
     cat("file1 row:", i, "file2 row:", j, "\n")
     summary(glm(e[i,] ~ g[j,]))
  }
}
then without the results of glm.

Thanks a lot.

Ying
 

-----Original Message-----
From: Gavin Simpson [mailto:gavin.simpson at ucl.ac.uk] 
Sent: Thursday, August 18, 2005 11:00 AM
To: Hu, Ying (NIH/NCI)
Cc: Sundar Dorai-Raj; r-help at stat.math.ethz.ch
Subject: RE: [R] do glm with two data sets

On Thu, 2005-08-18 at 10:38 -0400, Hu, Ying (NIH/NCI) wrote:
> Thanks for your help.
> 
> # read the two data sets
> e <- as.matrix(read.table("file1.txt", header=TRUE,row.names=1))
> g <- as.matrix(read.table("file2.txt", header=TRUE,row.names=1))
> # solution 
> d1<-data.frame(g[1,], e[1,])

This is redundant, as:

> fit<-glm(e[1,] ~ g[1,], data=d1)

and:

fit <- glm(e[1, ] ~ g[1, ])

are equivalent - you don't need data = d1 in this case, e.g:

e <- matrix(c(0, 1, 0, 0, 1, 1, 1, 1, -1), ncol = 3, byrow = TRUE)
e
g <- matrix(c(1.22, 1.34, 2.44, 2.33, 2.56, 2.56, 1.56, 1.99, 1.46),
ncol = 3, byrow = TRUE)
g
fit <- glm(e[1, ] ~ g[1, ])
fit

works fine.

> summary(fit)
> 
> I am not sure that is the best solution.

This seems a strange way of doing this. Why not:

pred <- g[1, ]
resp <- e[1, ]
fit <- glm(resp ~ pred)
fit

and do your subsetting outside the glm call - makes things clearer no?
Unless you plan to do many glm()s one per row of your two matrices. If
that is the case, then there are better ways of approaching this.

> Thanks again,
> 
> Ying

HTH

G

> 
> -----Original Message-----
> From: Gavin Simpson [mailto:gavin.simpson at ucl.ac.uk] 
> Sent: Wednesday, August 17, 2005 7:01 PM
> To: Sundar Dorai-Raj
> Cc: Hu, Ying (NIH/NCI); r-help at stat.math.ethz.ch
> Subject: Re: [R] do glm with two data sets
> 
> On Wed, 2005-08-17 at 17:22 -0500, Sundar Dorai-Raj wrote:
> > 
> > Hu, Ying (NIH/NCI) wrote:
> > > I have two data sets:
> > > File1.txt: 
> > > Name id1   id2   id3   ...
> > > N1    0     1     0     ...
> > > N2    0     1     1     ...
> > > N3    1     1     -1    ...
> > > ...
> > >  
> > > File2.txt:
> > > Group id1       id2       id3       ...
> > > G1       1.22     1.34     2.44     ...
> > > G2       2.33     2.56     2.56     ...
> > > G3       1.56     1.99     1.46     ...
> > > ...
> > > I like to do:
> > > x1<-c(0,1,0,...)
> > > y1<-c(1.22,1.34, 2.44, ...)
> > > z1<-data.frame(x,y)
> > > summary(glm(y1~x1,data=z1)
> > >  
> > > But I do the same thing by inputting the data sets from the two files
> > > e <- read.table("file1.txt", header=TRUE,row.names=1)
> > > g <- read.table("file2.txt", header=TRUE,row.names=1)
> > > e1<-exp[1,]
> > > g1<-geno[1,]
> > > d1<-data.frame(g, e)
> > > summary(glm(e1 ~ g1, data=d1))
> > >  
> > > the error message is 
> > > Error in model.frame(formula, rownames, variables, varnames, extras,
> > > extranames,  : 
> > >         invalid variable type
> > > Execution halted
> > >  
> > > Thanks in advance,
> > >  
> > > Ying
> 
> Hi Ying,
> 
> That error message is likely caused by having a data.frame on the right
> hand side (rhs) of the formula. You can't have a data.frame on the rhs
> of a formula and g1 is still a data frame even if you only choose the
> first row, e.g.:
> 
> dat <- as.data.frame(matrix(100, 10, 10))
> class(dat[1, ])
> [1] "data.frame"
> 
> You could try:
> 
> glm(e1 ~ ., data=g1[1, ])
> 
> and see if that works, but as Sundar notes, your post is a little
> difficult to follow, so this may not do what you were trying to achieve.
> 
> HTH
> 
> Gav
> 
> > 
> > You have several inconsistencies in your example, so it will be 
> > difficult to figure out what you are trying to accomplish.
> > 
> >  > e <- read.table("file1.txt", header=TRUE,row.names=1)
> >  > g <- read.table("file2.txt", header=TRUE,row.names=1)
> >  > e1<-exp[1,]
> > 
> > What's "exp"? Also it's dangerous to use an R function as a variable 
> > name. Most of the time R can tell the difference, but in some cases it 
> > cannot.
> > 
> >  > g1<-geno[1,]
> > 
> > What's "geno"?
> > 
> >  > d1<-data.frame(g, e)
> > 
> > d1 is now e and g cbind'ed together?
> > 
> >  > summary(glm(e1 ~ g1, data=d1))
> > 
> > Are "e1" and "g1" elements of "d1"? From what you've told us, I don't 
> > know where the error is occurring. Also, if you are having errors, you 
> > can more easily isolate the problem by doing:
> > 
> > fit <- glm(e1 ~ g1, data = d1)
> > summary(fit)
> > 
> > This will at least tell you the problem is in your call to "glm" and not

> > "summary.glm".
> > 
> > --sundar
> > 
> > P.S. Please (re-)read the POSTING GUIDE. Most of the time you will 
> > figure out problems such as these on your own during the process of 
> > creating a reproducible example.
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From tplate at acm.org  Thu Aug 18 18:34:57 2005
From: tplate at acm.org (Tony Plate)
Date: Thu, 18 Aug 2005 10:34:57 -0600
Subject: [R] Regular expressions & sub
In-Reply-To: <4304CF06.6868.25A7176@localhost>
References: <4304CF06.6868.25A7176@localhost>
Message-ID: <4304B8B1.2060206@acm.org>

 > x <- scan("clipboard", what="")
Read 7 items
 > x
[1] "1.11"   "10.11"  "11.11"  "113.31" "114.2"  "114.3"  "114.8"
 > gsub("[0-9]*\\.", "", x)
[1] "11" "11" "11" "31" "2"  "3"  "8"
 >


Bernd Weiss wrote:
> Dear all,
> 
> I am struggling with the use of regular expression. I got
> 
> 
>>as.character(test$sample.id)
> 
>  [1] "1.11"   "10.11"  "11.11"  "113.31" "114.2"  "114.3"  "114.8"  
> 
> and need
> 
> [1] "11"   "11"  "11"  "31" "2"  "3"  "8"
> 
> I.e. remove everything before the "." .
> 
> TIA,
> 
> Bernd
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From br44114 at gmail.com  Thu Aug 18 18:36:05 2005
From: br44114 at gmail.com (bogdan romocea)
Date: Thu, 18 Aug 2005 12:36:05 -0400
Subject: [R] Regular expressions & sub
Message-ID: <8d5a36350508180936c5eb0e@mail.gmail.com>

One solution is
test <- c("1.11","10.11","11.11","113.31","114.2","114.3")
id <-  unlist(lapply(strsplit(test,"[.]"),function(x) {x[2]}))


> -----Original Message-----
> From: Bernd Weiss [mailto:bernd.weiss at uni-koeln.de] 
> Sent: Thursday, August 18, 2005 12:10 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Regular expressions & sub
> 
> 
> Dear all,
> 
> I am struggling with the use of regular expression. I got
> 
> > as.character(test$sample.id)
>  [1] "1.11"   "10.11"  "11.11"  "113.31" "114.2"  "114.3"  "114.8"  
> 
> and need
> 
> [1] "11"   "11"  "11"  "31" "2"  "3"  "8"
> 
> I.e. remove everything before the "." .
> 
> TIA,
> 
> Bernd
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From sundar.dorai-raj at pdf.com  Thu Aug 18 18:41:19 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 18 Aug 2005 11:41:19 -0500
Subject: [R] do glm with two data sets
In-Reply-To: <27C204BD76CBC142BA1AE46D62A8548E490BFF@nihexchange9.nih.gov>
References: <27C204BD76CBC142BA1AE46D62A8548E490BFF@nihexchange9.nih.gov>
Message-ID: <4304BA2F.4080105@pdf.com>



Hu, Ying (NIH/NCI) wrote:
> You are right. 
> # read the two data sets
> e <- as.matrix(read.table("file1.txt", header=TRUE,row.names=1))
> g <- as.matrix(read.table("file2.txt", header=TRUE,row.names=1))
> 
> # solution 2
> summary(glm(e[1,] ~ g[1,]))
> summary(glm(e[1,] ~ g[2,]))
> ...
> They work very well.
> 
> If I put it in the loop, such as
> 
> for (i in 1:50){
>   for (j in 1:50){
>      cat("file1 row:", i, "file2 row:", j, "\n")
>      print(summary(glm(e[i,] ~ g[j,])))
>   }
> } 
> 
> Why do I have to use "print" to print the results? If without "print"
> for (i in 1:50){
>   for (j in 1:50){
>      cat("file1 row:", i, "file2 row:", j, "\n")
>      summary(glm(e[i,] ~ g[j,]))
>   }
> }
> then without the results of glm.
> 

This is a FAQ 7.16.

See http://cran.r-project.org/doc/FAQ/R-FAQ.html

--sundar



> Thanks a lot.
> 
> Ying
>  
> 
> -----Original Message-----
> From: Gavin Simpson [mailto:gavin.simpson at ucl.ac.uk] 
> Sent: Thursday, August 18, 2005 11:00 AM
> To: Hu, Ying (NIH/NCI)
> Cc: Sundar Dorai-Raj; r-help at stat.math.ethz.ch
> Subject: RE: [R] do glm with two data sets
> 
> On Thu, 2005-08-18 at 10:38 -0400, Hu, Ying (NIH/NCI) wrote:
> 
>>Thanks for your help.
>>
>># read the two data sets
>>e <- as.matrix(read.table("file1.txt", header=TRUE,row.names=1))
>>g <- as.matrix(read.table("file2.txt", header=TRUE,row.names=1))
>># solution 
>>d1<-data.frame(g[1,], e[1,])
> 
> 
> This is redundant, as:
> 
> 
>>fit<-glm(e[1,] ~ g[1,], data=d1)
> 
> 
> and:
> 
> fit <- glm(e[1, ] ~ g[1, ])
> 
> are equivalent - you don't need data = d1 in this case, e.g:
> 
> e <- matrix(c(0, 1, 0, 0, 1, 1, 1, 1, -1), ncol = 3, byrow = TRUE)
> e
> g <- matrix(c(1.22, 1.34, 2.44, 2.33, 2.56, 2.56, 1.56, 1.99, 1.46),
> ncol = 3, byrow = TRUE)
> g
> fit <- glm(e[1, ] ~ g[1, ])
> fit
> 
> works fine.
> 
> 
>>summary(fit)
>>
>>I am not sure that is the best solution.
> 
> 
> This seems a strange way of doing this. Why not:
> 
> pred <- g[1, ]
> resp <- e[1, ]
> fit <- glm(resp ~ pred)
> fit
> 
> and do your subsetting outside the glm call - makes things clearer no?
> Unless you plan to do many glm()s one per row of your two matrices. If
> that is the case, then there are better ways of approaching this.
> 
> 
>>Thanks again,
>>
>>Ying
> 
> 
> HTH
> 
> G
> 
> 
>>-----Original Message-----
>>From: Gavin Simpson [mailto:gavin.simpson at ucl.ac.uk] 
>>Sent: Wednesday, August 17, 2005 7:01 PM
>>To: Sundar Dorai-Raj
>>Cc: Hu, Ying (NIH/NCI); r-help at stat.math.ethz.ch
>>Subject: Re: [R] do glm with two data sets
>>
>>On Wed, 2005-08-17 at 17:22 -0500, Sundar Dorai-Raj wrote:
>>
>>>Hu, Ying (NIH/NCI) wrote:
>>>
>>>>I have two data sets:
>>>>File1.txt: 
>>>>Name id1   id2   id3   ...
>>>>N1    0     1     0     ...
>>>>N2    0     1     1     ...
>>>>N3    1     1     -1    ...
>>>>...
>>>> 
>>>>File2.txt:
>>>>Group id1       id2       id3       ...
>>>>G1       1.22     1.34     2.44     ...
>>>>G2       2.33     2.56     2.56     ...
>>>>G3       1.56     1.99     1.46     ...
>>>>...
>>>>I like to do:
>>>>x1<-c(0,1,0,...)
>>>>y1<-c(1.22,1.34, 2.44, ...)
>>>>z1<-data.frame(x,y)
>>>>summary(glm(y1~x1,data=z1)
>>>> 
>>>>But I do the same thing by inputting the data sets from the two files
>>>>e <- read.table("file1.txt", header=TRUE,row.names=1)
>>>>g <- read.table("file2.txt", header=TRUE,row.names=1)
>>>>e1<-exp[1,]
>>>>g1<-geno[1,]
>>>>d1<-data.frame(g, e)
>>>>summary(glm(e1 ~ g1, data=d1))
>>>> 
>>>>the error message is 
>>>>Error in model.frame(formula, rownames, variables, varnames, extras,
>>>>extranames,  : 
>>>>        invalid variable type
>>>>Execution halted
>>>> 
>>>>Thanks in advance,
>>>> 
>>>>Ying
>>
>>Hi Ying,
>>
>>That error message is likely caused by having a data.frame on the right
>>hand side (rhs) of the formula. You can't have a data.frame on the rhs
>>of a formula and g1 is still a data frame even if you only choose the
>>first row, e.g.:
>>
>>dat <- as.data.frame(matrix(100, 10, 10))
>>class(dat[1, ])
>>[1] "data.frame"
>>
>>You could try:
>>
>>glm(e1 ~ ., data=g1[1, ])
>>
>>and see if that works, but as Sundar notes, your post is a little
>>difficult to follow, so this may not do what you were trying to achieve.
>>
>>HTH
>>
>>Gav
>>
>>
>>>You have several inconsistencies in your example, so it will be 
>>>difficult to figure out what you are trying to accomplish.
>>>
>>> > e <- read.table("file1.txt", header=TRUE,row.names=1)
>>> > g <- read.table("file2.txt", header=TRUE,row.names=1)
>>> > e1<-exp[1,]
>>>
>>>What's "exp"? Also it's dangerous to use an R function as a variable 
>>>name. Most of the time R can tell the difference, but in some cases it 
>>>cannot.
>>>
>>> > g1<-geno[1,]
>>>
>>>What's "geno"?
>>>
>>> > d1<-data.frame(g, e)
>>>
>>>d1 is now e and g cbind'ed together?
>>>
>>> > summary(glm(e1 ~ g1, data=d1))
>>>
>>>Are "e1" and "g1" elements of "d1"? From what you've told us, I don't 
>>>know where the error is occurring. Also, if you are having errors, you 
>>>can more easily isolate the problem by doing:
>>>
>>>fit <- glm(e1 ~ g1, data = d1)
>>>summary(fit)
>>>
>>>This will at least tell you the problem is in your call to "glm" and not
> 
> 
>>>"summary.glm".
>>>
>>>--sundar
>>>
>>>P.S. Please (re-)read the POSTING GUIDE. Most of the time you will 
>>>figure out problems such as these on your own during the process of 
>>>creating a reproducible example.
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide!
>>
>>http://www.R-project.org/posting-guide.html



From deepayan.sarkar at gmail.com  Thu Aug 18 18:42:50 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 18 Aug 2005 11:42:50 -0500
Subject: [R] line/bar through median in lattice's "bwplot"?
In-Reply-To: <loom.20050818T093542-426@post.gmane.org>
References: <20050818033238.93817.qmail@web31305.mail.mud.yahoo.com>
	<loom.20050818T093542-426@post.gmane.org>
Message-ID: <eb555e660508180942568bcf99@mail.gmail.com>

On 8/18/05, Dieter Menne <dieter.menne at menne-biomed.de> wrote:
> M. K. <mk_lists <at> yahoo.ca> writes:
> 
> >
> > Is there a way to render a line through the median point in the boxplot
> > generated by the Lattice command "bwplot"?  The line basically bisects
> > the bar at the median point...
> 
> 
> bwplot(height~voice.part , pch='|', data=singer, xlab="Height (inches)")
> 
> How to find this (haven't checked, maybe it's documented)
> library(lattice)
> panel.bwplot # no ()!

It's not documented (and only available in the very recent versions of
lattice, BTW), as I realized last night.  It will be documented in a
soon-to-come version (and maybe even honour attempts to change its
color, line type, etc).

Deepayan



From ripley at stats.ox.ac.uk  Thu Aug 18 18:44:00 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 Aug 2005 17:44:00 +0100 (BST)
Subject: [R] problems when installing R in Fedora core 4
In-Reply-To: <20050818135615.GA5929@psych>
References: <a922041d05081806313a98cc87@mail.gmail.com>
	<20050818135615.GA5929@psych>
Message-ID: <Pine.LNX.4.61.0508181701300.4094@gannet.stats>

On Thu, 18 Aug 2005, Jonathan Baron wrote:

...

> Whether you have the needed files already depends on what kind of
> installation you did.  Some of the packages are "devel" and
> others are "compat".  Here is my list of "compat" rpms
> that I have installed, and I think I installed all of these just
> to get R to build:
>
> compat-libf2c-32-3.2.3-47.fc4
> compat-libstdc++-296-2.96-132.fc4
> compat-readline43-4.3-2
> compat-gcc-32-3.2.3-47.fc4
>
> My hunch is that I still do not have the optimal installation,
> but it is possible that the newest versions of gcc have solved
> some of the problems with the ones that originally came with
> FC4.  I've seen some discussion suggesting that the way to go is
> to use an older version of gcc, but I did not search for it just
> now.

See https://stat.ethz.ch/pipermail/r-devel/2005-August/034171.html

for updates on that advice.  It may still be the way to go.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From edd at debian.org  Thu Aug 18 18:39:38 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 18 Aug 2005 16:39:38 +0000 (UTC)
Subject: [R] Regular expressions & sub
References: <4304CF06.6868.25A7176@localhost>
Message-ID: <loom.20050818T183647-236@post.gmane.org>

Bernd Weiss <bernd.weiss <at> uni-koeln.de> writes:
> I am struggling with the use of regular expression. I got
> 
> > as.character(test$sample.id)
>  [1] "1.11"   "10.11"  "11.11"  "113.31" "114.2"  "114.3"  "114.8"  
> 
> and need
> 
> [1] "11"   "11"  "11"  "31" "2"  "3"  "8"
> 
> I.e. remove everything before the "." .

Define the dot as the hard separator, and allow for multiple digits before it:

> sample.id <- c("1.11", "10.11", "11.11", "113.31", "114.2", "114.3", "114.8")
> gsub("^[0-9]*\.", "", sample.id)
[1] "11" "11" "11" "31" "2"  "3"  "8" 

Hope this helps,  Dirk



From mac at cs.toronto.edu  Thu Aug 18 18:31:47 2005
From: mac at cs.toronto.edu (M.K.)
Date: Thu, 18 Aug 2005 16:31:47 +0000 (UTC)
Subject: [R] line/bar through median in lattice's
References: <20050818033238.93817.qmail@web31305.mail.mud.yahoo.com>
	<loom.20050818T093542-426@post.gmane.org>
Message-ID: <loom.20050818T183013-109@post.gmane.org>

Dieter Menne <dieter.menne <at> menne-biomed.de> writes:
> Check the code for something like points (which is the default).
> Find a mysterious '|' and pch
> 
> Dieter

Yes, that was it!  Thanks Dieter!  The mysterious code is right near the bottom
of the function.  Too bad this is not documented, at least not in ?panel.bwplot.



From patrick.giraudoux at univ-fcomte.fr  Thu Aug 18 19:19:09 2005
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Thu, 18 Aug 2005 19:19:09 +0200
Subject: [R] Set R 2.1.1. in English
In-Reply-To: <Pine.LNX.4.61.0508181711520.4094@gannet.stats>
References: <43049953.40107@univ-fcomte.fr>
	<Pine.LNX.4.61.0508181711520.4094@gannet.stats>
Message-ID: <4304C30D.9090707@univ-fcomte.fr>

> (whish R
> 2.1.1 could be parametrise 'English' even with a French Windows XP!!!!)
>
> If I understand you correctly, it can.  Just add LANGUAGE=en to the 
> shortcut. 


Wonderful hope but not sure to catch what you term "shortcut". I tried 
to add this command in C:\R\rw2011\etc\Rprofile, the .Rprofile in the 
folder my documents, but this cannot be understood from there...  which 
obviously shows that "shortcut" is not a general term for profiles! I 
have also unsuccessfully looked for a file "shortcut" in the rw2011 
folder. I also tried and went through the R-help archive. There were 
some exchanges on this subject and Asian languages some weeks ago but 
what I have tried and adapt on this basis did not work.

The objective would be to have R in  English (thus additionnally 
allowing MDI mode with R-WinEdt, which is not the case with any other 
language) and to keep Windows XP and other applications in the foreign 
(= French, here) language.

Thanks for any further hint,

Patrick Giraudoux



From stepanchuk at wiwi.uni-frankfurt.de  Thu Aug 18 19:23:52 2005
From: stepanchuk at wiwi.uni-frankfurt.de (Tetyana Stepanchuk)
Date: Thu, 18 Aug 2005 19:23:52 +0200
Subject: [R] Welcome to the "R-help" mailing list (Digest mode)
In-Reply-To: <mailman.0.1124384424.4501.r-help@stat.math.ethz.ch>
Message-ID: <20050818172942.06E8BA4C805@much-magic.wiwi.uni-frankfurt.de>


Hi, thank you for cooperation.

-----------------------------------
Dr. (UA) Tetyana Stepanchuk
Department of Electronic Commerce 
Johann Wolfgang Goethe-University 
Mertonstrasse 17 
D-60054, Frankfurt/Main
Germany
phone: +49 069 798 22379
http://www.ecommerce.wiwi.uni-frankfurt.de



-----Urspr??ngliche Nachricht-----
Von: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] Im Auftrag von
r-help-request at stat.math.ethz.ch
Gesendet: Donnerstag, 18. August 2005 19:00
An: stepanchuk at wiwi.uni-frankfurt.de
Betreff: Welcome to the "R-help" mailing list (Digest mode)

Welcome to the R-help at stat.math.ethz.ch mailing list!

To post to this list, send your email to:

  r-help at stat.math.ethz.ch

General information about the mailing list is at:

  https://stat.ethz.ch/mailman/listinfo/r-help

If you ever want to unsubscribe or change your options (eg, switch to
or from digest mode, change your password, etc.), visit your
subscription page at:

 
https://stat.ethz.ch/mailman/options/r-help/stepanchuk%40wiwi.uni-frankfurt.
de


You can also make such adjustments via email by sending a message to:

  R-help-request at stat.math.ethz.ch

with the word `help' in the subject or body (don't include the
quotes), and you will get back a message with instructions.

You must know your password to change your options (including changing
the password, itself) or to unsubscribe.  It is:

  stepkin78

Normally, Mailman will remind you of your stat.math.ethz.ch mailing
list passwords once every month, although you can disable this if you
prefer.  This reminder will also include instructions on how to
unsubscribe or change your account options.  There is also a button on
your options page that will email your current password to you.



From patrick.giraudoux at univ-fcomte.fr  Thu Aug 18 19:26:46 2005
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Thu, 18 Aug 2005 19:26:46 +0200
Subject: [R] axTicks and window resizing
In-Reply-To: <Pine.LNX.4.61.0508181711520.4094@gannet.stats>
References: <43049953.40107@univ-fcomte.fr>
	<Pine.LNX.4.61.0508181711520.4094@gannet.stats>
Message-ID: <4304C4D6.4000304@univ-fcomte.fr>

OK. Things work now and the window can be resized easy after adding at = 
axTicks() in axis() explicitely. This makes:

profplot<-function(x,y,z=10,...){
op <- par()$mai
par(mai=c(0.95625,0.76875,0.76875,0.95625))
plot(x,y*z, type="l",asp=1,las=1,xlab="",ylab="",yaxt="n",...)
axis(2,at=axTicks(2),labels=axTicks(2)/z,las=1)
axis(4,at=axTicks(2),labels=axTicks(2)/z,las=1)
par(mai=op)
}

Thanks for the hint,

Patrick

Prof Brian Ripley a ??crit :

> On Thu, 18 Aug 2005, Patrick Giraudoux wrote:
>
>> Dear listers,
>>
>> I have written a function to facilitate the drawing of altitude profiles
>> with x (distance), y (altitude) and a z  parameter (altitude 
>> magnification).
>>
>> profplot<-function(x,y,z=10,...){
>> op <- par()$mai
>> par(mai=c(0.95625,0.76875,0.76875,0.95625))
>> plot(x,y*z, type="l",asp=1,las=1,xlab="",ylab="",yaxt="n",...)
>> axis(2,labels=axTicks(2)/z,las=1)
>> axis(4,labels=axTicks(2)/z,las=1)
>> on.exit(par(mai=op))
>> }
>>
>> This worked apparently well until I had to resize the graphical window
>> after plotting. In this case, I get this message:
>>
>> >  profplot(prof$dist,prof$alt,col="blue")
>> > Erreur : les longueurs de 'at' et de 'label' diff??rent, 7 != 8
>>
>> Which means Error: length of 'at' and "label' differ, 7!=8 (whish R
>> 2.1.1 could be parametrise 'English' even with a French Windows XP!!!!)
>
>
> If I understand you correctly, it can.  Just add LANGUAGE=en to the 
> shortcut.
>
>> At this stage, R crashes (= I cannot get the graphic window
>> working/resized and must interrupt the process from Windows XP, then
>> restart R for good work with the graphical window).
>>
>> The error occur with the difference between the tick number computed
>> from plot() and the one computed with axTicks(). If still equal (slight
>> resizing) everything goes smoothly.
>
>
> The problem is that you need to specify 'at' and 'labels' to axis(): 
> you cannot safely specify just labels.  When re-drawing, 'at' is 
> recomputed, but your specification of 'labels' is not.
>
> I suspect you can just do dev.off() and open a new graphics window.
>
>> Thanks for any comments, even rude... (I am not sure the
>> problem/programme has been tackled relevantly enough)
>>
>> Patrick
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>>
>



From shigesong at gmail.com  Thu Aug 18 19:31:27 2005
From: shigesong at gmail.com (Shige Song)
Date: Fri, 19 Aug 2005 01:31:27 +0800
Subject: [R] Error messages using LMER
In-Reply-To: <40e66e0b0508180659447f8321@mail.gmail.com>
References: <5abc11d805081801152c1f6661@mail.gmail.com>
	<40e66e0b0508180659447f8321@mail.gmail.com>
Message-ID: <5abc11d805081810311689b8ee@mail.gmail.com>

Dear Professor Bates,

Here is output R 2.1.1 produced with "control = list(EMverbose = TRUE,
msVerbose = TRUE)". I am getting the new devel version and see what
will hapen there:

--------------------------------------------------------------------------------
 EM iterations
 0 85289.766 ( 5407.13:  0.0815) ( 26134.4: 0.00387)
 1 84544.322 ( 333.732:   0.137) ( 1462.32: 0.00934)
 2 84515.108 ( 129.506:  0.0270) ( 446.306: 0.00481)
 3 84514.519 ( 115.592: 0.00355) ( 328.637: 0.00103)
 4 84514.505 ( 113.981:0.000505) ( 311.160:0.000165)
 5 84514.505 ( 113.755:7.45e-005) ( 308.524:2.50e-005)
 6 84514.505 ( 113.722:1.11e-005) ( 308.128:3.77e-006)
 7 84514.505 ( 113.717:1.66e-006) ( 308.068:5.66e-007)
 8 84514.505 ( 113.716:2.50e-007) ( 308.059:8.49e-008)
 9 84514.505 ( 113.716:3.74e-008) ( 308.058:1.27e-008)
 10 84514.505 ( 113.716:5.62e-009) ( 308.058:1.91e-009)
 11 84514.505 ( 113.716:8.43e-010) ( 308.058:2.87e-010)
 12 84514.505 ( 113.716:1.27e-010) ( 308.058:4.31e-011)
 13 84514.505 ( 113.716:1.90e-011) ( 308.057:6.47e-012)
 14 84514.505 ( 113.716:2.86e-012) ( 308.057:9.73e-013)
 15 84514.505 ( 113.716:4.25e-013) ( 308.057:1.44e-013)
iter    0 value 84514.505044
final  value 84514.505044
converged
 EM iterations
 0 83740.342 ( 113.716: -0.0164) ( 308.057:0.000596)
 1 83740.273 ( 121.512:-0.00121) ( 298.914:-3.24e-005)
 2 83740.272 ( 122.131:-0.000111) ( 299.397:-1.24e-005)
iter    0 value 83740.272232
final  value 83740.272232
converged
 EM iterations
 0 84011.550 ( 122.204:-0.00461) ( 299.576:-0.000256)
 1 84011.543 ( 124.624:-0.000459) ( 303.453:-6.41e-005)
 2 84011.543 ( 124.870:-5.42e-005) ( 304.440:-1.13e-005)
iter    0 value 84011.543350
final  value 84011.543350
converged
 EM iterations
 0 84018.592 ( 124.915:-6.44e-005) ( 304.548:-1.22e-005)
 1 84018.592 ( 124.949:-8.29e-006) ( 304.737:-1.99e-006)
 2 84018.592 ( 124.954:-1.15e-006) ( 304.768:-3.08e-007)
iter    0 value 84018.591624
final  value 84018.591624
converged
 EM iterations
 0 84018.612 ( 124.955:3.40e-007) ( 304.770:-1.98e-007)
 1 84018.612 ( 124.955:-9.98e-009) ( 304.773:-2.23e-008)
 2 84018.612 ( 124.955:-5.47e-009) ( 304.774:-2.86e-009)
iter    0 value 84018.611512
final  value 84018.611512
converged
Error in fn(par, ...) : Unable to invert singular factor of downdated X'X
In addition: Warning message:
Leading minor of size 8 of downdated X'X is indefinite
--------------------------------------------------------------------------------

Thanks!

Shige

On 8/18/05, Douglas Bates <dmbates at gmail.com> wrote:
> On 8/18/05, Shige Song <shigesong at gmail.com> wrote:
> > Dear All,
> >
> > After playing with lmer for couple of days, I have to say that I am
> > amazed! I've been using quite some multilevel/mixed modeling packages,
> > lme4 is a strong candidate for the overall winner, especially for
> > multilevel generzlized linear models.
> >
> > Now go back to my two-level poisson model with cross-classified model.
> > I've been testing various different model specificatios for the past
> > couple of days. Here are the models I tried:
> >
> > 1) Two level random intercept model with level-1 covariates only
> > m1 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 ,
> > data, poisson, method="Laplace")
> >
> > 2) Two-level random intercept model with both level-1 and level-2
> > covariates, but no cross-level interactions:
> > m2 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 +
> > z1 + z2, data, poisson, method="Laplace")
> >
> > 3) Two-level random intercept with cross-level interaction
> > m3 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 +
> > z1 + z2 + x1:z1 + x2:z2, data, poisson, method="Laplace")
> >
> > Both model 1 and 2 run fine. For model 3, I got error message:
> > ----------------------------------
> > Error in fn(par, ...) : Unable to invert singular factor of downdated X'X
> > In addition: Warning messages:
> > 1: optim or nlminb returned message ERROR: ABNORMAL_TERMINATION_IN_LNSRCH
> >  in: LMEopt(x = mer, value = cv)
> > 2: Leading minor of size 1 of downdated X'X is indefinite
> > ----------------------------------
> >
> > What is going on here? Any workarounds? Thanks!
> 
> The first thing I would try is set the EMverbose and msVerbose flags
> in the control list to see what occurs within the optimization.  That
> is append the argument
> 
> control = list(EMverbose = TRUE, msVerbose = TRUE)
> 
> to your call to lmer().  You may also want to try the call in a
> recently compiled R-devel, which will be released as R-2.2.0 in
> October.  You will notice that the first warning message reads "optim
> or nlminb". In R-2.1.1 lmer uses optim for the optimization.  Starting
> with R-2.2.0 the default is to use nlminb.
> 
> Test compilations of R-devel for Windows are available from CRAN.
>



From pauljohn at ku.edu  Thu Aug 18 19:34:15 2005
From: pauljohn at ku.edu (Paul Johnson)
Date: Thu, 18 Aug 2005 12:34:15 -0500
Subject: [R] LyX and Sweave
In-Reply-To: <17127.31968.599285.291012@celebrian.ci.tuwien.ac.at>
References: <7FFEE688B57D7346BC6241C55900E730F31936@pollux.bfro.uni-lj.si>
	<17127.31968.599285.291012@celebrian.ci.tuwien.ac.at>
Message-ID: <4304C697.3090507@ku.edu>

I just wanted to point out that I was there first :)  on the Lyx List 
(Nov 2004):

http://www.mail-archive.com/lyx-users at lists.lyx.org/msg36262.html

Perhaps somebody who is trying to put all of this together can benefit 
from both sets of explanations.

pj

Friedrich.Leisch at tuwien.ac.at wrote:
>>>>>>On Mon, 25 Jul 2005 14:12:41 +0200,
>>>>>>Gorjanc Gregor (GG) wrote:
> 
> 
>   > Hello R-users!
>   > I have tried to use Sweave within LyX* and found two ways to accomplish
>   > this. I have attached LyX source file for both ways as well as generated 
>   > PDFs.
> 
> I have copied Gregor's files at
> 
> 	http://www.ci.tuwien.ac.at/~leisch/Sweave/LyX
> 
> for those who didn't get the attachments. LyX looks actually much
> better and stable then when I last had a look a couple of years ago.
>


-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700



From shigesong at gmail.com  Thu Aug 18 19:41:11 2005
From: shigesong at gmail.com (Shige Song)
Date: Fri, 19 Aug 2005 01:41:11 +0800
Subject: [R] Error messages using LMER
In-Reply-To: <5abc11d805081810311689b8ee@mail.gmail.com>
References: <5abc11d805081801152c1f6661@mail.gmail.com>
	<40e66e0b0508180659447f8321@mail.gmail.com>
	<5abc11d805081810311689b8ee@mail.gmail.com>
Message-ID: <5abc11d805081810417a76aaaf@mail.gmail.com>

Here is what happened using R-devel:

-------------------------------------------------------------
  EM iterations
  0 85289.766 ( 5407.13:  0.0815) ( 26134.4: 0.00387)
  1 84544.322 ( 333.732:   0.137) ( 1462.32: 0.00934)
  2 84515.108 ( 129.506:  0.0270) ( 446.306: 0.00481)
  3 84514.519 ( 115.592: 0.00355) ( 328.637: 0.00103)
  4 84514.505 ( 113.981:0.000505) ( 311.160:0.000165)
  5 84514.505 ( 113.755:7.45e-005) ( 308.524:2.50e-005)
  6 84514.505 ( 113.722:1.11e-005) ( 308.128:3.77e-006)
  7 84514.505 ( 113.717:1.66e-006) ( 308.068:5.66e-007)
  8 84514.505 ( 113.716:2.50e-007) ( 308.059:8.49e-008)
  9 84514.505 ( 113.716:3.74e-008) ( 308.058:1.27e-008)
 10 84514.505 ( 113.716:5.62e-009) ( 308.058:1.91e-009)
 11 84514.505 ( 113.716:8.43e-010) ( 308.058:2.87e-010)
 12 84514.505 ( 113.716:1.27e-010) ( 308.058:4.31e-011)
 13 84514.505 ( 113.716:1.90e-011) ( 308.057:6.47e-012)
 14 84514.505 ( 113.716:2.86e-012) ( 308.057:9.73e-013)
 15 84514.505 ( 113.716:4.25e-013) ( 308.057:1.44e-013)
  EM iterations
  0 83740.342 ( 113.716: -0.0164) ( 308.057:0.000596)
  1 83740.273 ( 121.512:-0.00121) ( 298.914:-3.24e-005)
  2 83740.272 ( 122.131:-0.000111) ( 299.397:-1.24e-005)
  EM iterations
  0 84011.546 ( 122.131:-0.00474) ( 299.397:-0.000265)
  1 84011.539 ( 124.616:-0.000472) ( 303.415:-6.62e-005)
  2 84011.539 ( 124.869:-5.58e-005) ( 304.433:-1.16e-005)
  EM iterations
  0 84018.589 ( 124.869:-0.000139) ( 304.433:-1.81e-005)
  1 84018.589 ( 124.944:-1.62e-005) ( 304.713:-3.26e-006)
  2 84018.589 ( 124.953:-2.12e-006) ( 304.764:-5.23e-007)
  EM iterations
  0 84018.611 ( 124.953:-2.38e-006) ( 304.764:-5.44e-007)
  1 84018.611 ( 124.954:-3.25e-007) ( 304.772:-8.50e-008)
  2 84018.611 ( 124.955:-4.66e-008) ( 304.773:-1.29e-008)
  EM iterations
  0 84018.611 ( 124.955:-4.75e-008) ( 304.773:-1.30e-008)
  1 84018.611 ( 124.955:-6.93e-009) ( 304.774:-1.97e-009)
  2 84018.611 ( 124.955:-1.03e-009) ( 304.774:-2.96e-010)
Warning messages:
1: optim or nlminb returned message See PORT documentation.  Code (27) 
 in: LMEopt(x = mer, value = cv) 
2: optim or nlminb returned message See PORT documentation.  Code (27) 
 in: LMEopt(x = mer, value = cv) 
3: optim or nlminb returned message See PORT documentation.  Code (27) 
 in: LMEopt(x = mer, value = cv) 
4: optim or nlminb returned message See PORT documentation.  Code (27) 
 in: LMEopt(x = mer, value = cv) 
5: optim or nlminb returned message See PORT documentation.  Code (27) 
 in: LMEopt(x = mer, value = cv) 
6: optim or nlminb returned message See PORT documentation.  Code (27) 
 in: LMEopt(x = mer, value = cv) 
7: nlminb failed to converge in: lmer(.D ~ offset(log(.Y)) + (1 |
provn) + (1 | bcohort) + agri +
-------------------------------------------------------------

Shige

On 8/19/05, Shige Song <shigesong at gmail.com> wrote:
> Dear Professor Bates,
> 
> Here is output R 2.1.1 produced with "control = list(EMverbose = TRUE,
> msVerbose = TRUE)". I am getting the new devel version and see what
> will hapen there:
> 
> --------------------------------------------------------------------------------
>  EM iterations
>  0 85289.766 ( 5407.13:  0.0815) ( 26134.4: 0.00387)
>  1 84544.322 ( 333.732:   0.137) ( 1462.32: 0.00934)
>  2 84515.108 ( 129.506:  0.0270) ( 446.306: 0.00481)
>  3 84514.519 ( 115.592: 0.00355) ( 328.637: 0.00103)
>  4 84514.505 ( 113.981:0.000505) ( 311.160:0.000165)
>  5 84514.505 ( 113.755:7.45e-005) ( 308.524:2.50e-005)
>  6 84514.505 ( 113.722:1.11e-005) ( 308.128:3.77e-006)
>  7 84514.505 ( 113.717:1.66e-006) ( 308.068:5.66e-007)
>  8 84514.505 ( 113.716:2.50e-007) ( 308.059:8.49e-008)
>  9 84514.505 ( 113.716:3.74e-008) ( 308.058:1.27e-008)
>  10 84514.505 ( 113.716:5.62e-009) ( 308.058:1.91e-009)
>  11 84514.505 ( 113.716:8.43e-010) ( 308.058:2.87e-010)
>  12 84514.505 ( 113.716:1.27e-010) ( 308.058:4.31e-011)
>  13 84514.505 ( 113.716:1.90e-011) ( 308.057:6.47e-012)
>  14 84514.505 ( 113.716:2.86e-012) ( 308.057:9.73e-013)
>  15 84514.505 ( 113.716:4.25e-013) ( 308.057:1.44e-013)
> iter    0 value 84514.505044
> final  value 84514.505044
> converged
>  EM iterations
>  0 83740.342 ( 113.716: -0.0164) ( 308.057:0.000596)
>  1 83740.273 ( 121.512:-0.00121) ( 298.914:-3.24e-005)
>  2 83740.272 ( 122.131:-0.000111) ( 299.397:-1.24e-005)
> iter    0 value 83740.272232
> final  value 83740.272232
> converged
>  EM iterations
>  0 84011.550 ( 122.204:-0.00461) ( 299.576:-0.000256)
>  1 84011.543 ( 124.624:-0.000459) ( 303.453:-6.41e-005)
>  2 84011.543 ( 124.870:-5.42e-005) ( 304.440:-1.13e-005)
> iter    0 value 84011.543350
> final  value 84011.543350
> converged
>  EM iterations
>  0 84018.592 ( 124.915:-6.44e-005) ( 304.548:-1.22e-005)
>  1 84018.592 ( 124.949:-8.29e-006) ( 304.737:-1.99e-006)
>  2 84018.592 ( 124.954:-1.15e-006) ( 304.768:-3.08e-007)
> iter    0 value 84018.591624
> final  value 84018.591624
> converged
>  EM iterations
>  0 84018.612 ( 124.955:3.40e-007) ( 304.770:-1.98e-007)
>  1 84018.612 ( 124.955:-9.98e-009) ( 304.773:-2.23e-008)
>  2 84018.612 ( 124.955:-5.47e-009) ( 304.774:-2.86e-009)
> iter    0 value 84018.611512
> final  value 84018.611512
> converged
> Error in fn(par, ...) : Unable to invert singular factor of downdated X'X
> In addition: Warning message:
> Leading minor of size 8 of downdated X'X is indefinite
> --------------------------------------------------------------------------------
> 
> Thanks!
> 
> Shige
> 
> On 8/18/05, Douglas Bates <dmbates at gmail.com> wrote:
> > On 8/18/05, Shige Song <shigesong at gmail.com> wrote:
> > > Dear All,
> > >
> > > After playing with lmer for couple of days, I have to say that I am
> > > amazed! I've been using quite some multilevel/mixed modeling packages,
> > > lme4 is a strong candidate for the overall winner, especially for
> > > multilevel generzlized linear models.
> > >
> > > Now go back to my two-level poisson model with cross-classified model.
> > > I've been testing various different model specificatios for the past
> > > couple of days. Here are the models I tried:
> > >
> > > 1) Two level random intercept model with level-1 covariates only
> > > m1 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 ,
> > > data, poisson, method="Laplace")
> > >
> > > 2) Two-level random intercept model with both level-1 and level-2
> > > covariates, but no cross-level interactions:
> > > m2 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 +
> > > z1 + z2, data, poisson, method="Laplace")
> > >
> > > 3) Two-level random intercept with cross-level interaction
> > > m3 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 +
> > > z1 + z2 + x1:z1 + x2:z2, data, poisson, method="Laplace")
> > >
> > > Both model 1 and 2 run fine. For model 3, I got error message:
> > > ----------------------------------
> > > Error in fn(par, ...) : Unable to invert singular factor of downdated X'X
> > > In addition: Warning messages:
> > > 1: optim or nlminb returned message ERROR: ABNORMAL_TERMINATION_IN_LNSRCH
> > >  in: LMEopt(x = mer, value = cv)
> > > 2: Leading minor of size 1 of downdated X'X is indefinite
> > > ----------------------------------
> > >
> > > What is going on here? Any workarounds? Thanks!
> >
> > The first thing I would try is set the EMverbose and msVerbose flags
> > in the control list to see what occurs within the optimization.  That
> > is append the argument
> >
> > control = list(EMverbose = TRUE, msVerbose = TRUE)
> >
> > to your call to lmer().  You may also want to try the call in a
> > recently compiled R-devel, which will be released as R-2.2.0 in
> > October.  You will notice that the first warning message reads "optim
> > or nlminb". In R-2.1.1 lmer uses optim for the optimization.  Starting
> > with R-2.2.0 the default is to use nlminb.
> >
> > Test compilations of R-devel for Windows are available from CRAN.
> >
>



From stepanchuk at wiwi.uni-frankfurt.de  Thu Aug 18 19:47:32 2005
From: stepanchuk at wiwi.uni-frankfurt.de (Tetyana Stepanchuk)
Date: Thu, 18 Aug 2005 19:47:32 +0200
Subject: [R] ?
Message-ID: <20050818175321.74007A4C88C@much-magic.wiwi.uni-frankfurt.de>

Hello, 

 

I have a small problem with developing design matrix X, which I use in
estimation the log-likelihood of a multinomial logit model.

 

I have the data: 

 number of observation - 289

number of choice alternative- 3

number of choice specific variables in matrix X -4

matrix X =289x4

I tried to use the function createX, I know that I have to get design matrix
289x12 (am I right?) but it always says "bad dim" (my code and data in
attachment)

 

Where is my fault? Can I use another method in order to create design
matrix? 

Or need it at all here in logmnl (see code in attachment)?

 

Can anyone help me with this issue?

 

Thanks in advance,

Tatyana

 

 

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: createX.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050818/2e9b5561/createX.txt
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: logmnl.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050818/2e9b5561/logmnl.txt

From shigesong at gmail.com  Thu Aug 18 19:51:05 2005
From: shigesong at gmail.com (Shige Song)
Date: Fri, 19 Aug 2005 01:51:05 +0800
Subject: [R] Error messages using LMER
In-Reply-To: <5abc11d805081810417a76aaaf@mail.gmail.com>
References: <5abc11d805081801152c1f6661@mail.gmail.com>
	<40e66e0b0508180659447f8321@mail.gmail.com>
	<5abc11d805081810311689b8ee@mail.gmail.com>
	<5abc11d805081810417a76aaaf@mail.gmail.com>
Message-ID: <5abc11d805081810512830cc99@mail.gmail.com>

One thing to be noted: after switching to R-devel, even the simplest
model can not converge. I always get this:

-------------------------------------------------------------------------
Warning messages:
1: optim or nlminb returned message See PORT documentation.  Code (27) 
 in: LMEopt(x = mer, value = cv) 
2: optim or nlminb returned message See PORT documentation.  Code (27) 
 in: LMEopt(x = mer, value = cv) 
3: optim or nlminb returned message See PORT documentation.  Code (27) 
 in: LMEopt(x = mer, value = cv) 
4: optim or nlminb returned message See PORT documentation.  Code (27) 
 in: LMEopt(x = mer, value = cv) 
5: optim or nlminb returned message See PORT documentation.  Code (27) 
 in: LMEopt(x = mer, value = cv) 
6: nlminb failed to converge in: lmer(.D ~ offset(log(.Y)) + (1 |
provn) + (1 | bcohort) + educy +
-------------------------------------------------------------------------

The same model did not have problems converging in R 2.1.1.

Shige
On 8/19/05, Shige Song <shigesong at gmail.com> wrote:
> Here is what happened using R-devel:
> 
> -------------------------------------------------------------
>   EM iterations
>   0 85289.766 ( 5407.13:  0.0815) ( 26134.4: 0.00387)
>   1 84544.322 ( 333.732:   0.137) ( 1462.32: 0.00934)
>   2 84515.108 ( 129.506:  0.0270) ( 446.306: 0.00481)
>   3 84514.519 ( 115.592: 0.00355) ( 328.637: 0.00103)
>   4 84514.505 ( 113.981:0.000505) ( 311.160:0.000165)
>   5 84514.505 ( 113.755:7.45e-005) ( 308.524:2.50e-005)
>   6 84514.505 ( 113.722:1.11e-005) ( 308.128:3.77e-006)
>   7 84514.505 ( 113.717:1.66e-006) ( 308.068:5.66e-007)
>   8 84514.505 ( 113.716:2.50e-007) ( 308.059:8.49e-008)
>   9 84514.505 ( 113.716:3.74e-008) ( 308.058:1.27e-008)
>  10 84514.505 ( 113.716:5.62e-009) ( 308.058:1.91e-009)
>  11 84514.505 ( 113.716:8.43e-010) ( 308.058:2.87e-010)
>  12 84514.505 ( 113.716:1.27e-010) ( 308.058:4.31e-011)
>  13 84514.505 ( 113.716:1.90e-011) ( 308.057:6.47e-012)
>  14 84514.505 ( 113.716:2.86e-012) ( 308.057:9.73e-013)
>  15 84514.505 ( 113.716:4.25e-013) ( 308.057:1.44e-013)
>   EM iterations
>   0 83740.342 ( 113.716: -0.0164) ( 308.057:0.000596)
>   1 83740.273 ( 121.512:-0.00121) ( 298.914:-3.24e-005)
>   2 83740.272 ( 122.131:-0.000111) ( 299.397:-1.24e-005)
>   EM iterations
>   0 84011.546 ( 122.131:-0.00474) ( 299.397:-0.000265)
>   1 84011.539 ( 124.616:-0.000472) ( 303.415:-6.62e-005)
>   2 84011.539 ( 124.869:-5.58e-005) ( 304.433:-1.16e-005)
>   EM iterations
>   0 84018.589 ( 124.869:-0.000139) ( 304.433:-1.81e-005)
>   1 84018.589 ( 124.944:-1.62e-005) ( 304.713:-3.26e-006)
>   2 84018.589 ( 124.953:-2.12e-006) ( 304.764:-5.23e-007)
>   EM iterations
>   0 84018.611 ( 124.953:-2.38e-006) ( 304.764:-5.44e-007)
>   1 84018.611 ( 124.954:-3.25e-007) ( 304.772:-8.50e-008)
>   2 84018.611 ( 124.955:-4.66e-008) ( 304.773:-1.29e-008)
>   EM iterations
>   0 84018.611 ( 124.955:-4.75e-008) ( 304.773:-1.30e-008)
>   1 84018.611 ( 124.955:-6.93e-009) ( 304.774:-1.97e-009)
>   2 84018.611 ( 124.955:-1.03e-009) ( 304.774:-2.96e-010)
> Warning messages:
> 1: optim or nlminb returned message See PORT documentation.  Code (27)
>  in: LMEopt(x = mer, value = cv)
> 2: optim or nlminb returned message See PORT documentation.  Code (27)
>  in: LMEopt(x = mer, value = cv)
> 3: optim or nlminb returned message See PORT documentation.  Code (27)
>  in: LMEopt(x = mer, value = cv)
> 4: optim or nlminb returned message See PORT documentation.  Code (27)
>  in: LMEopt(x = mer, value = cv)
> 5: optim or nlminb returned message See PORT documentation.  Code (27)
>  in: LMEopt(x = mer, value = cv)
> 6: optim or nlminb returned message See PORT documentation.  Code (27)
>  in: LMEopt(x = mer, value = cv)
> 7: nlminb failed to converge in: lmer(.D ~ offset(log(.Y)) + (1 |
> provn) + (1 | bcohort) + agri +
> -------------------------------------------------------------
> 
> Shige
> 
> On 8/19/05, Shige Song <shigesong at gmail.com> wrote:
> > Dear Professor Bates,
> >
> > Here is output R 2.1.1 produced with "control = list(EMverbose = TRUE,
> > msVerbose = TRUE)". I am getting the new devel version and see what
> > will hapen there:
> >
> > --------------------------------------------------------------------------------
> >  EM iterations
> >  0 85289.766 ( 5407.13:  0.0815) ( 26134.4: 0.00387)
> >  1 84544.322 ( 333.732:   0.137) ( 1462.32: 0.00934)
> >  2 84515.108 ( 129.506:  0.0270) ( 446.306: 0.00481)
> >  3 84514.519 ( 115.592: 0.00355) ( 328.637: 0.00103)
> >  4 84514.505 ( 113.981:0.000505) ( 311.160:0.000165)
> >  5 84514.505 ( 113.755:7.45e-005) ( 308.524:2.50e-005)
> >  6 84514.505 ( 113.722:1.11e-005) ( 308.128:3.77e-006)
> >  7 84514.505 ( 113.717:1.66e-006) ( 308.068:5.66e-007)
> >  8 84514.505 ( 113.716:2.50e-007) ( 308.059:8.49e-008)
> >  9 84514.505 ( 113.716:3.74e-008) ( 308.058:1.27e-008)
> >  10 84514.505 ( 113.716:5.62e-009) ( 308.058:1.91e-009)
> >  11 84514.505 ( 113.716:8.43e-010) ( 308.058:2.87e-010)
> >  12 84514.505 ( 113.716:1.27e-010) ( 308.058:4.31e-011)
> >  13 84514.505 ( 113.716:1.90e-011) ( 308.057:6.47e-012)
> >  14 84514.505 ( 113.716:2.86e-012) ( 308.057:9.73e-013)
> >  15 84514.505 ( 113.716:4.25e-013) ( 308.057:1.44e-013)
> > iter    0 value 84514.505044
> > final  value 84514.505044
> > converged
> >  EM iterations
> >  0 83740.342 ( 113.716: -0.0164) ( 308.057:0.000596)
> >  1 83740.273 ( 121.512:-0.00121) ( 298.914:-3.24e-005)
> >  2 83740.272 ( 122.131:-0.000111) ( 299.397:-1.24e-005)
> > iter    0 value 83740.272232
> > final  value 83740.272232
> > converged
> >  EM iterations
> >  0 84011.550 ( 122.204:-0.00461) ( 299.576:-0.000256)
> >  1 84011.543 ( 124.624:-0.000459) ( 303.453:-6.41e-005)
> >  2 84011.543 ( 124.870:-5.42e-005) ( 304.440:-1.13e-005)
> > iter    0 value 84011.543350
> > final  value 84011.543350
> > converged
> >  EM iterations
> >  0 84018.592 ( 124.915:-6.44e-005) ( 304.548:-1.22e-005)
> >  1 84018.592 ( 124.949:-8.29e-006) ( 304.737:-1.99e-006)
> >  2 84018.592 ( 124.954:-1.15e-006) ( 304.768:-3.08e-007)
> > iter    0 value 84018.591624
> > final  value 84018.591624
> > converged
> >  EM iterations
> >  0 84018.612 ( 124.955:3.40e-007) ( 304.770:-1.98e-007)
> >  1 84018.612 ( 124.955:-9.98e-009) ( 304.773:-2.23e-008)
> >  2 84018.612 ( 124.955:-5.47e-009) ( 304.774:-2.86e-009)
> > iter    0 value 84018.611512
> > final  value 84018.611512
> > converged
> > Error in fn(par, ...) : Unable to invert singular factor of downdated X'X
> > In addition: Warning message:
> > Leading minor of size 8 of downdated X'X is indefinite
> > --------------------------------------------------------------------------------
> >
> > Thanks!
> >
> > Shige
> >
> > On 8/18/05, Douglas Bates <dmbates at gmail.com> wrote:
> > > On 8/18/05, Shige Song <shigesong at gmail.com> wrote:
> > > > Dear All,
> > > >
> > > > After playing with lmer for couple of days, I have to say that I am
> > > > amazed! I've been using quite some multilevel/mixed modeling packages,
> > > > lme4 is a strong candidate for the overall winner, especially for
> > > > multilevel generzlized linear models.
> > > >
> > > > Now go back to my two-level poisson model with cross-classified model.
> > > > I've been testing various different model specificatios for the past
> > > > couple of days. Here are the models I tried:
> > > >
> > > > 1) Two level random intercept model with level-1 covariates only
> > > > m1 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 ,
> > > > data, poisson, method="Laplace")
> > > >
> > > > 2) Two-level random intercept model with both level-1 and level-2
> > > > covariates, but no cross-level interactions:
> > > > m2 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 +
> > > > z1 + z2, data, poisson, method="Laplace")
> > > >
> > > > 3) Two-level random intercept with cross-level interaction
> > > > m3 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 +
> > > > z1 + z2 + x1:z1 + x2:z2, data, poisson, method="Laplace")
> > > >
> > > > Both model 1 and 2 run fine. For model 3, I got error message:
> > > > ----------------------------------
> > > > Error in fn(par, ...) : Unable to invert singular factor of downdated X'X
> > > > In addition: Warning messages:
> > > > 1: optim or nlminb returned message ERROR: ABNORMAL_TERMINATION_IN_LNSRCH
> > > >  in: LMEopt(x = mer, value = cv)
> > > > 2: Leading minor of size 1 of downdated X'X is indefinite
> > > > ----------------------------------
> > > >
> > > > What is going on here? Any workarounds? Thanks!
> > >
> > > The first thing I would try is set the EMverbose and msVerbose flags
> > > in the control list to see what occurs within the optimization.  That
> > > is append the argument
> > >
> > > control = list(EMverbose = TRUE, msVerbose = TRUE)
> > >
> > > to your call to lmer().  You may also want to try the call in a
> > > recently compiled R-devel, which will be released as R-2.2.0 in
> > > October.  You will notice that the first warning message reads "optim
> > > or nlminb". In R-2.1.1 lmer uses optim for the optimization.  Starting
> > > with R-2.2.0 the default is to use nlminb.
> > >
> > > Test compilations of R-devel for Windows are available from CRAN.
> > >
> >
>



From dmbates at gmail.com  Thu Aug 18 19:52:57 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Thu, 18 Aug 2005 12:52:57 -0500
Subject: [R] Error messages using LMER
In-Reply-To: <5abc11d805081810417a76aaaf@mail.gmail.com>
References: <5abc11d805081801152c1f6661@mail.gmail.com>
	<40e66e0b0508180659447f8321@mail.gmail.com>
	<5abc11d805081810311689b8ee@mail.gmail.com>
	<5abc11d805081810417a76aaaf@mail.gmail.com>
Message-ID: <40e66e0b050818105218618be6@mail.gmail.com>

Thanks for including all of that output.  

I believe that in this version the parameters are the relative
variances.  This would indicate that somehow you are getting fits with
very low residual sums of squares in the weighted least squares
problem.  It could be that you have too many fixed effects terms in
the model and are getting complete separation.

On 8/18/05, Shige Song <shigesong at gmail.com> wrote:
> Here is what happened using R-devel:
> 
> -------------------------------------------------------------
>   EM iterations
>   0 85289.766 ( 5407.13:  0.0815) ( 26134.4: 0.00387)
>   1 84544.322 ( 333.732:   0.137) ( 1462.32: 0.00934)
>   2 84515.108 ( 129.506:  0.0270) ( 446.306: 0.00481)
>   3 84514.519 ( 115.592: 0.00355) ( 328.637: 0.00103)
>   4 84514.505 ( 113.981:0.000505) ( 311.160:0.000165)
>   5 84514.505 ( 113.755:7.45e-005) ( 308.524:2.50e-005)
>   6 84514.505 ( 113.722:1.11e-005) ( 308.128:3.77e-006)
>   7 84514.505 ( 113.717:1.66e-006) ( 308.068:5.66e-007)
>   8 84514.505 ( 113.716:2.50e-007) ( 308.059:8.49e-008)
>   9 84514.505 ( 113.716:3.74e-008) ( 308.058:1.27e-008)
>  10 84514.505 ( 113.716:5.62e-009) ( 308.058:1.91e-009)
>  11 84514.505 ( 113.716:8.43e-010) ( 308.058:2.87e-010)
>  12 84514.505 ( 113.716:1.27e-010) ( 308.058:4.31e-011)
>  13 84514.505 ( 113.716:1.90e-011) ( 308.057:6.47e-012)
>  14 84514.505 ( 113.716:2.86e-012) ( 308.057:9.73e-013)
>  15 84514.505 ( 113.716:4.25e-013) ( 308.057:1.44e-013)
>   EM iterations
>   0 83740.342 ( 113.716: -0.0164) ( 308.057:0.000596)
>   1 83740.273 ( 121.512:-0.00121) ( 298.914:-3.24e-005)
>   2 83740.272 ( 122.131:-0.000111) ( 299.397:-1.24e-005)
>   EM iterations
>   0 84011.546 ( 122.131:-0.00474) ( 299.397:-0.000265)
>   1 84011.539 ( 124.616:-0.000472) ( 303.415:-6.62e-005)
>   2 84011.539 ( 124.869:-5.58e-005) ( 304.433:-1.16e-005)
>   EM iterations
>   0 84018.589 ( 124.869:-0.000139) ( 304.433:-1.81e-005)
>   1 84018.589 ( 124.944:-1.62e-005) ( 304.713:-3.26e-006)
>   2 84018.589 ( 124.953:-2.12e-006) ( 304.764:-5.23e-007)
>   EM iterations
>   0 84018.611 ( 124.953:-2.38e-006) ( 304.764:-5.44e-007)
>   1 84018.611 ( 124.954:-3.25e-007) ( 304.772:-8.50e-008)
>   2 84018.611 ( 124.955:-4.66e-008) ( 304.773:-1.29e-008)
>   EM iterations
>   0 84018.611 ( 124.955:-4.75e-008) ( 304.773:-1.30e-008)
>   1 84018.611 ( 124.955:-6.93e-009) ( 304.774:-1.97e-009)
>   2 84018.611 ( 124.955:-1.03e-009) ( 304.774:-2.96e-010)
> Warning messages:
> 1: optim or nlminb returned message See PORT documentation.  Code (27)
>  in: LMEopt(x = mer, value = cv)
> 2: optim or nlminb returned message See PORT documentation.  Code (27)
>  in: LMEopt(x = mer, value = cv)
> 3: optim or nlminb returned message See PORT documentation.  Code (27)
>  in: LMEopt(x = mer, value = cv)
> 4: optim or nlminb returned message See PORT documentation.  Code (27)
>  in: LMEopt(x = mer, value = cv)
> 5: optim or nlminb returned message See PORT documentation.  Code (27)
>  in: LMEopt(x = mer, value = cv)
> 6: optim or nlminb returned message See PORT documentation.  Code (27)
>  in: LMEopt(x = mer, value = cv)
> 7: nlminb failed to converge in: lmer(.D ~ offset(log(.Y)) + (1 |
> provn) + (1 | bcohort) + agri +
> -------------------------------------------------------------
> 
> Shige
> 
> On 8/19/05, Shige Song <shigesong at gmail.com> wrote:
> > Dear Professor Bates,
> >
> > Here is output R 2.1.1 produced with "control = list(EMverbose = TRUE,
> > msVerbose = TRUE)". I am getting the new devel version and see what
> > will hapen there:
> >
> > --------------------------------------------------------------------------------
> >  EM iterations
> >  0 85289.766 ( 5407.13:  0.0815) ( 26134.4: 0.00387)
> >  1 84544.322 ( 333.732:   0.137) ( 1462.32: 0.00934)
> >  2 84515.108 ( 129.506:  0.0270) ( 446.306: 0.00481)
> >  3 84514.519 ( 115.592: 0.00355) ( 328.637: 0.00103)
> >  4 84514.505 ( 113.981:0.000505) ( 311.160:0.000165)
> >  5 84514.505 ( 113.755:7.45e-005) ( 308.524:2.50e-005)
> >  6 84514.505 ( 113.722:1.11e-005) ( 308.128:3.77e-006)
> >  7 84514.505 ( 113.717:1.66e-006) ( 308.068:5.66e-007)
> >  8 84514.505 ( 113.716:2.50e-007) ( 308.059:8.49e-008)
> >  9 84514.505 ( 113.716:3.74e-008) ( 308.058:1.27e-008)
> >  10 84514.505 ( 113.716:5.62e-009) ( 308.058:1.91e-009)
> >  11 84514.505 ( 113.716:8.43e-010) ( 308.058:2.87e-010)
> >  12 84514.505 ( 113.716:1.27e-010) ( 308.058:4.31e-011)
> >  13 84514.505 ( 113.716:1.90e-011) ( 308.057:6.47e-012)
> >  14 84514.505 ( 113.716:2.86e-012) ( 308.057:9.73e-013)
> >  15 84514.505 ( 113.716:4.25e-013) ( 308.057:1.44e-013)
> > iter    0 value 84514.505044
> > final  value 84514.505044
> > converged
> >  EM iterations
> >  0 83740.342 ( 113.716: -0.0164) ( 308.057:0.000596)
> >  1 83740.273 ( 121.512:-0.00121) ( 298.914:-3.24e-005)
> >  2 83740.272 ( 122.131:-0.000111) ( 299.397:-1.24e-005)
> > iter    0 value 83740.272232
> > final  value 83740.272232
> > converged
> >  EM iterations
> >  0 84011.550 ( 122.204:-0.00461) ( 299.576:-0.000256)
> >  1 84011.543 ( 124.624:-0.000459) ( 303.453:-6.41e-005)
> >  2 84011.543 ( 124.870:-5.42e-005) ( 304.440:-1.13e-005)
> > iter    0 value 84011.543350
> > final  value 84011.543350
> > converged
> >  EM iterations
> >  0 84018.592 ( 124.915:-6.44e-005) ( 304.548:-1.22e-005)
> >  1 84018.592 ( 124.949:-8.29e-006) ( 304.737:-1.99e-006)
> >  2 84018.592 ( 124.954:-1.15e-006) ( 304.768:-3.08e-007)
> > iter    0 value 84018.591624
> > final  value 84018.591624
> > converged
> >  EM iterations
> >  0 84018.612 ( 124.955:3.40e-007) ( 304.770:-1.98e-007)
> >  1 84018.612 ( 124.955:-9.98e-009) ( 304.773:-2.23e-008)
> >  2 84018.612 ( 124.955:-5.47e-009) ( 304.774:-2.86e-009)
> > iter    0 value 84018.611512
> > final  value 84018.611512
> > converged
> > Error in fn(par, ...) : Unable to invert singular factor of downdated X'X
> > In addition: Warning message:
> > Leading minor of size 8 of downdated X'X is indefinite
> > --------------------------------------------------------------------------------
> >
> > Thanks!
> >
> > Shige
> >
> > On 8/18/05, Douglas Bates <dmbates at gmail.com> wrote:
> > > On 8/18/05, Shige Song <shigesong at gmail.com> wrote:
> > > > Dear All,
> > > >
> > > > After playing with lmer for couple of days, I have to say that I am
> > > > amazed! I've been using quite some multilevel/mixed modeling packages,
> > > > lme4 is a strong candidate for the overall winner, especially for
> > > > multilevel generzlized linear models.
> > > >
> > > > Now go back to my two-level poisson model with cross-classified model.
> > > > I've been testing various different model specificatios for the past
> > > > couple of days. Here are the models I tried:
> > > >
> > > > 1) Two level random intercept model with level-1 covariates only
> > > > m1 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 ,
> > > > data, poisson, method="Laplace")
> > > >
> > > > 2) Two-level random intercept model with both level-1 and level-2
> > > > covariates, but no cross-level interactions:
> > > > m2 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 +
> > > > z1 + z2, data, poisson, method="Laplace")
> > > >
> > > > 3) Two-level random intercept with cross-level interaction
> > > > m3 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2 +
> > > > z1 + z2 + x1:z1 + x2:z2, data, poisson, method="Laplace")
> > > >
> > > > Both model 1 and 2 run fine. For model 3, I got error message:
> > > > ----------------------------------
> > > > Error in fn(par, ...) : Unable to invert singular factor of downdated X'X
> > > > In addition: Warning messages:
> > > > 1: optim or nlminb returned message ERROR: ABNORMAL_TERMINATION_IN_LNSRCH
> > > >  in: LMEopt(x = mer, value = cv)
> > > > 2: Leading minor of size 1 of downdated X'X is indefinite
> > > > ----------------------------------
> > > >
> > > > What is going on here? Any workarounds? Thanks!
> > >
> > > The first thing I would try is set the EMverbose and msVerbose flags
> > > in the control list to see what occurs within the optimization.  That
> > > is append the argument
> > >
> > > control = list(EMverbose = TRUE, msVerbose = TRUE)
> > >
> > > to your call to lmer().  You may also want to try the call in a
> > > recently compiled R-devel, which will be released as R-2.2.0 in
> > > October.  You will notice that the first warning message reads "optim
> > > or nlminb". In R-2.1.1 lmer uses optim for the optimization.  Starting
> > > with R-2.2.0 the default is to use nlminb.
> > >
> > > Test compilations of R-devel for Windows are available from CRAN.
> > >
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Thu Aug 18 20:15:20 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 Aug 2005 19:15:20 +0100 (BST)
Subject: [R] Set R 2.1.1. in English
In-Reply-To: <4304C30D.9090707@univ-fcomte.fr>
References: <43049953.40107@univ-fcomte.fr>
	<Pine.LNX.4.61.0508181711520.4094@gannet.stats>
	<4304C30D.9090707@univ-fcomte.fr>
Message-ID: <Pine.LNX.4.61.0508181910330.5218@gannet.stats>

On Thu, 18 Aug 2005, Patrick Giraudoux wrote:

>> (whish R
>> 2.1.1 could be parametrise 'English' even with a French Windows XP!!!!)
>> 
>> If I understand you correctly, it can.  Just add LANGUAGE=en to the 
>> shortcut.

> Wonderful hope but not sure to catch what you term "shortcut". I tried to add 
> this command in C:\R\rw2011\etc\Rprofile, the .Rprofile in the folder my 
> documents, but this cannot be understood from there...  which obviously shows 
> that "shortcut" is not a general term for profiles! I have also

See the rw-FAQ Q2.2.
`Shortcut' is the standard name for files on Windows with extension .lnk.

Another way is to add this to HOME/.Renviron: see the rw-FAQ Q2.17

> unsuccessfully looked for a file "shortcut" in the rw2011 folder. I also 
> tried and went through the R-help archive. There were some exchanges on this 
> subject and Asian languages some weeks ago but what I have tried and adapt on 
> this basis did not work.
>
> The objective would be to have R in  English (thus additionnally allowing MDI 
> mode with R-WinEdt, which is not the case with any other language) and to 
> keep Windows XP and other applications in the foreign (= French, here) 
> language.
>
> Thanks for any further hint,
>
> Patrick Giraudoux
>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Aug 18 20:17:02 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 Aug 2005 19:17:02 +0100 (BST)
Subject: [R] standard errors for expression intensities
In-Reply-To: <D45546375992BF429A93F7203358F14403429563@sirius.fccc.edu>
References: <D45546375992BF429A93F7203358F14403429563@sirius.fccc.edu>
Message-ID: <Pine.LNX.4.61.0508181916040.5218@gannet.stats>

Please ask Bioconductor Qs on their mailing list!

> PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html

This is indeed covered there, as is the (mis)use of HTML mail.

On Thu, 18 Aug 2005, Devarajan, Karthik wrote:

>
> Hello!
>
> When I use the functions rma() or justrma() in the Bioconductor affy
> package, the standard errors for the expression estimates computed by the
> function se.exprs() is a matrix of NA's. I am wondering if any of you have
> encountered this problem and if there is a solution. Any help would be
> appreciated.
>
> Thanks,
> Karthik.
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ross at biostat.ucsf.edu  Thu Aug 18 20:32:09 2005
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 18 Aug 2005 11:32:09 -0700
Subject: [R] problem with repeated formal arguments and  ...
Message-ID: <1124389929.21569.5.camel@iron.libaux.ucsf.edu>

I want to add an argument if it is not present.  Following the Green
Book, p. 337:
test <- function(x, ...){
  dots <- list(...)
  if (!hasArg(from))
    from <- 0
  else
    from <- dots$from
  curve(x, from=from, ...)
}

> test(sin)
> test(sin, from=4)
Error in curve(x, from = from, ...) : formal argument "from" matched by
multiple actual arguments

The FAQ says, in the section on differences between R and S,
"R disallows repeated formal arguments in function calls."

That seems a perfectly reasonable rule,  but how do I handle this
situation?

-- 
Ross Boylan                                      wk:  (415) 502-4031
530 Parnassus Avenue (Library) rm 115-4          ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 476-9856
University of California, San Francisco
San Francisco, CA 94143-0840                     hm:  (415) 550-1062



From david.whiting at ncl.ac.uk  Thu Aug 18 20:39:40 2005
From: david.whiting at ncl.ac.uk (David Whiting)
Date: Thu, 18 Aug 2005 19:39:40 +0100
Subject: [R] How do I make a Sweave + latex table out of this ?
In-Reply-To: <376e97ec050818072772216421@mail.gmail.com>
References: <376e97ec050818072772216421@mail.gmail.com>
Message-ID: <4304D5EC.1060307@ncl.ac.uk>

Hi Fredrik,

You can do this nicely with latex() if you massage this a little so that
you end up with a data frame that includes a column for agemF (to
indicate which agemF each row belongs to) and then use the rgroup and
n.rgroup options of latex().

Dave


Fredrik Karlsson wrote:
> Dear list,
> 
> I have a table that I would like to convert to latex for inclusion
> into a Sweave file.
> 
> 
> 
>>round(ftable(prop.table(xtabs(~agemF + votcat + Type , data=work),margin=2))*100,1)
> 
>                   Type Voiced Voiceless unaspirated Voiceless aspirated
> agemF   votcat                                                         
> 18 - 24 Prevoiced         2.6                   8.7                 2.3
>              Short lag         5.8                   6.7                 5.1
>             Long lag          1.0                   1.9                 2.9
> 24 - 30 Prevoiced        15.1                  10.5                 1.7
>              Short lag         9.2                  15.3                 5.8
>             Long lag          3.5                   8.1                15.8
> 30 - 36 Prevoiced        12.8                  14.0                 2.6
>             Short lag        10.2                  14.2                 3.0
>             Long lag          2.3                   5.5                22.2
> 36 - 42 Prevoiced         4.4                   6.4                 0.6
>            Short lag         4.0                   5.9                 1.5
>            Long lag          1.3                   2.9                 9.4
> 42 - 48 Prevoiced         6.4                   2.3                 0.3
>            Short lag         3.0                   2.8                 1.4
>            Long lag          0.6                   7.7                 8.8
> 48 - 54 Prevoiced         4.9                   4.1                 0.3
>             Short lag         2.0                   2.7                 1.3
>              Long lag          0.3                   0.9                 4.7
> 
> 
> However, I have not been able to use this as a table. The Hmisc latex
> command only accepts the input if I first convert it to a data.frame
> format, and that makes the output much more difficult to read as it
> duplicates the category levels of agemF.
> 
> Is there a way to do this?
> 
> 
> /Fredrik Karlsson
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
David Whiting
School of Clinical Medical Sciences, The Medical School
University of Newcastle upon Tyne, NE2 4HH, UK.

"I love deadlines. I love the whooshing noise they make as they go by"
(Douglas Adams)



From patrick.giraudoux at univ-fcomte.fr  Thu Aug 18 20:41:40 2005
From: patrick.giraudoux at univ-fcomte.fr (Patrick Giraudoux)
Date: Thu, 18 Aug 2005 20:41:40 +0200
Subject: [R] Set R 2.1.1. in English
In-Reply-To: <Pine.LNX.4.61.0508181910330.5218@gannet.stats>
References: <43049953.40107@univ-fcomte.fr>
	<Pine.LNX.4.61.0508181711520.4094@gannet.stats>
	<4304C30D.9090707@univ-fcomte.fr>
	<Pine.LNX.4.61.0508181910330.5218@gannet.stats>
Message-ID: <4304D664.9040808@univ-fcomte.fr>

OK. ??Perfectly clear.

This written for other listers:

Shortcut is the shortcuts ("alias") everybody use to launch applications 
(in French: "raccourci"), and for suckers (as I am): one just have to 
right-click the shortcut used to launch Rgui.exe, select properties 
("propri??t??s" in French) and add in the box target ("cible" in French) 
LANGUAGE=en to the path. In my case: C:\R\rw2011\bin\Rgui.exe. Thus, it 
makes C:\R\rw2011\bin\Rgui.exe LANGUAGE=en. Then click OK.

It works fantastic!!!!

Thanks a lot for this. It makes three weeks I was grumling everytime 
(often) I started R, and frustrated with the SDI mode...

Patrick Giraudoux



Prof Brian Ripley a ??crit :

> On Thu, 18 Aug 2005, Patrick Giraudoux wrote:
>
>>> (whish R
>>> 2.1.1 could be parametrise 'English' even with a French Windows XP!!!!)
>>>
>>> If I understand you correctly, it can.  Just add LANGUAGE=en to the 
>>> shortcut.
>>
>
>> Wonderful hope but not sure to catch what you term "shortcut". I 
>> tried to add this command in C:\R\rw2011\etc\Rprofile, the .Rprofile 
>> in the folder my documents, but this cannot be understood from 
>> there...  which obviously shows that "shortcut" is not a general term 
>> for profiles! I have also
>
>
> See the rw-FAQ Q2.2.
> `Shortcut' is the standard name for files on Windows with extension .lnk.
>
> Another way is to add this to HOME/.Renviron: see the rw-FAQ Q2.17
>
>> unsuccessfully looked for a file "shortcut" in the rw2011 folder. I 
>> also tried and went through the R-help archive. There were some 
>> exchanges on this subject and Asian languages some weeks ago but what 
>> I have tried and adapt on this basis did not work.
>>
>> The objective would be to have R in  English (thus additionnally 
>> allowing MDI mode with R-WinEdt, which is not the case with any other 
>> language) and to keep Windows XP and other applications in the 
>> foreign (= French, here) language.
>>
>> Thanks for any further hint,
>>
>> Patrick Giraudoux
>>
>>
>>
>



From sundar.dorai-raj at pdf.com  Thu Aug 18 20:45:37 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 18 Aug 2005 13:45:37 -0500
Subject: [R] problem with repeated formal arguments and  ...
In-Reply-To: <1124389929.21569.5.camel@iron.libaux.ucsf.edu>
References: <1124389929.21569.5.camel@iron.libaux.ucsf.edu>
Message-ID: <4304D751.2080400@pdf.com>



Ross Boylan wrote:
> I want to add an argument if it is not present.  Following the Green
> Book, p. 337:
> test <- function(x, ...){
>   dots <- list(...)
>   if (!hasArg(from))
>     from <- 0
>   else
>     from <- dots$from
>   curve(x, from=from, ...)
> }
> 
> 
>>test(sin)
>>test(sin, from=4)
> 
> Error in curve(x, from = from, ...) : formal argument "from" matched by
> multiple actual arguments
> 
> The FAQ says, in the section on differences between R and S,
> "R disallows repeated formal arguments in function calls."
> 
> That seems a perfectly reasonable rule,  but how do I handle this
> situation?
> 

Hi, Ross,

Add "from" to your function:

test <- function(x, from = 0, ...) {
   curve(x, from = from, ...)
}

Or another way:

test <- function(x, ...) {
   dots <- list(...)
   if(!hasArg(from)) dots$from <- 0
   dots$expr <- x
   do.call("curve", dots)
}

I actually prefer the latter if I'm changing many arguments. I do this 
quite often when writing custom lattice plots and I want to override 
many of the defaults.

HTH,

--sundar



From ghather at berkeley.edu  Thu Aug 18 20:53:54 2005
From: ghather at berkeley.edu (Greg Hather)
Date: Thu, 18 Aug 2005 11:53:54 -0700
Subject: [R] trouble with wilcox.test
References: <001801c5a35f$a0de7000$43fde5a9@PC232921052285>
	<Pine.LNX.4.61.0508172314540.16428@gannet.stats>
Message-ID: <000901c5a426$2ecfa5c0$43fde5a9@PC232921052285>

Ok, I will think more about the appropriateness of the Wilcoxon test 
here.  I was using

R version 2.1.1, 2005-06-20
Windows XP SP2
512MB RAM

--Greg

----- Original Message ----- 
From: "Prof Brian Ripley" <ripley at stats.ox.ac.uk>
To: "Greg Hather" <ghather at berkeley.edu>
Cc: <r-help at stat.math.ethz.ch>
Sent: Wednesday, August 17, 2005 11:45 PM
Subject: Re: [R] trouble with wilcox.test


> On Wed, 17 Aug 2005, Greg Hather wrote:
>
>> I'm having trouble with the wilcox.test command in R.
>
> Are you sure it is not the concepts that are giving 'trouble'?
> What real problem are you trying to solve here?
>
>> To demonstrate the anomalous behavior of wilcox.test, consider
>>
>>> wilcox.test(c(1.5,5.5), c(1:10000), exact = F)$p.value
>> [1] 0.01438390
>>> wilcox.test(c(1.5,5.5), c(1:10000), exact = T)$p.value
>> [1] 6.39808e-07 (this calculation takes noticeably longer).
>>> wilcox.test(c(1.5,5.5), c(1:20000), exact = T)$p.value
>> (R closes/crashes)
>>
>> I believe that wilcox.test(c(1.5,5.5), c(1:10000), exact = F)$p.value 
>> yields a bad result because of the normal approximation which R uses 
>> when exact = F.
>
> Expecting an approximation to be good in the tail for m=2 is pretty 
> unrealistic.  But then so is believing the null hypothesis of a common 
> *continuous* distribution.  Why worry about the distribution under a 
> hypothesis that is patently false?
>
> People often refer to this class of tests as `distribution-free', but 
> they are not.  The Wilcoxon test is designed for power against shift 
> alternatives, but here there appears to be a very large difference in 
> spread.  So
>
>> wilcox.test(5000+c(1.5,5.5), c(1:10000), exact = T)$p.value
> [1] 0.9989005
>
> even though the two samples differ in important ways.
>
>
>> Any suggestions for how to compute wilcox.test(c(1.5,5.5), 
>> c(1:20000), exact = T)$p.value?
>
> I get (current R 2.1.1 on Linux)
>
>> wilcox.test(c(1.5,5.5), c(1:20000), exact = T)$p.value
> [1] 1.59976e-07
>
> and no crash.  So the suggestion is to use a machine adequate to the 
> task, and that probably means an OS with adequate stack size.
>
>> [[alternative HTML version deleted]]
>
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
>
> Please do heed it.  What version of R and what machine is this?  And 
> do take note of the request about HTML mail.
>
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Thu Aug 18 21:17:58 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Aug 2005 21:17:58 +0200
Subject: [R] Regular expressions & sub
In-Reply-To: <loom.20050818T183647-236@post.gmane.org>
References: <4304CF06.6868.25A7176@localhost>
	<loom.20050818T183647-236@post.gmane.org>
Message-ID: <x2acjf836h.fsf@turmalin.kubism.ku.dk>

Dirk Eddelbuettel <edd at debian.org> writes:

> Bernd Weiss <bernd.weiss <at> uni-koeln.de> writes:
> > I am struggling with the use of regular expression. I got
> > 
> > > as.character(test$sample.id)
> >  [1] "1.11"   "10.11"  "11.11"  "113.31" "114.2"  "114.3"  "114.8"  
> > 
> > and need
> > 
> > [1] "11"   "11"  "11"  "31" "2"  "3"  "8"
> > 
> > I.e. remove everything before the "." .
> 
> Define the dot as the hard separator, and allow for multiple digits before it:
> 
> > sample.id <- c("1.11", "10.11", "11.11", "113.31", "114.2", "114.3", "114.8")
> > gsub("^[0-9]*\.", "", sample.id)
> [1] "11" "11" "11" "31" "2"  "3"  "8" 

Or, more longwinded, but with less assumptions about what goes before
the dot:

> gsub("^.*\\.(.*)$","\\1",sample.id)
[1] "11" "11" "11" "31" "2"  "3"  "8"

or,

> gsub("^.*\\.([^.]*)$","\\1",sample.id)
[1] "11" "11" "11" "31" "2"  "3"  "8"


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From DSA at kvl.dk  Thu Aug 18 21:21:07 2005
From: DSA at kvl.dk (Daniela Salvini)
Date: Thu, 18 Aug 2005 21:21:07 +0200
Subject: [R] Console
Message-ID: <s304fbea.048@gwia.kvl.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050818/31892fbf/attachment.pl

From francois.morneau at cirad.fr  Thu Aug 18 16:20:58 2005
From: francois.morneau at cirad.fr (=?iso-8859-1?Q?Fran=E7ois?= Morneau)
Date: Thu, 18 Aug 2005 16:20:58 +0200
Subject: [R] How to put factor variables in an nls formula ?
Message-ID: <6.1.1.1.0.20050818161038.01e59270@Fagus.Engref.Fr>

Hello,

I want to fit a Gompertz model for tree diameter growth that depends on a 4 
levels edaphic factor (?Drain?) and I don?t manage to introduce the factor 
variable in the formula.
Dinc is the annual diameter increment and D is the Diameter.

 >treestab
 >     Dinc     D      Drain
  [1,]  0.03  26.10     2
  [2,]  0.04  13.05     1
  [3,]  0.00  24.83     1
  [4,]  0.00  15.92     4
  [5,]  0.00  12.25     4
  [6,]  0.00  11.78     4
  [7,]  0.00  16.87     4
  [8,]  0.00  15.12     4
  [9,] -0.01  13.53     4
[10,] 0.04  16.55     3
[11,] 0.025 16.07     3
[12,] 0.00  30.24     3
[13,] 0.06  15.28     2
etc

 >contrasts(Drain)<-contr.sum(4)
 >mymodel<-nls(Dinc~r*(1+Drain)*D*log(Asym/D), data=treestab, start(r=0.05, 
Asym=40))

Error in numericDeriv(form[[3]], names(ind), env) :
         Missing value or an infinity produced when evaluating the model
In addition: Warning messages:
1: + not meaningful for factors in: Ops.factor(1, Drain)
2: + not meaningful for factors in: Ops.factor(1, Drain)

Do I need to use another function instead of nls to correctly include the 
factor ?Drain? ?

Thanks,

Fran??ois



From sundar.dorai-raj at pdf.com  Thu Aug 18 21:47:00 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 18 Aug 2005 14:47:00 -0500
Subject: [R] problem with repeated formal arguments and  ...
In-Reply-To: <4304D751.2080400@pdf.com>
References: <1124389929.21569.5.camel@iron.libaux.ucsf.edu>
	<4304D751.2080400@pdf.com>
Message-ID: <4304E5B4.60709@pdf.com>



Sundar Dorai-Raj wrote:
> 
> Ross Boylan wrote:
> 
>>I want to add an argument if it is not present.  Following the Green
>>Book, p. 337:
>>test <- function(x, ...){
>>  dots <- list(...)
>>  if (!hasArg(from))
>>    from <- 0
>>  else
>>    from <- dots$from
>>  curve(x, from=from, ...)
>>}
>>
>>
>>
>>>test(sin)
>>>test(sin, from=4)
>>
>>Error in curve(x, from = from, ...) : formal argument "from" matched by
>>multiple actual arguments
>>
>>The FAQ says, in the section on differences between R and S,
>>"R disallows repeated formal arguments in function calls."
>>
>>That seems a perfectly reasonable rule,  but how do I handle this
>>situation?
>>
> 
> 
> Hi, Ross,
> 
> Add "from" to your function:
> 
> test <- function(x, from = 0, ...) {
>    curve(x, from = from, ...)
> }
> 
> Or another way:
> 
> test <- function(x, ...) {
>    dots <- list(...)
>    if(!hasArg(from)) dots$from <- 0
>    dots$expr <- x
>    do.call("curve", dots)
> }
> 

I didn't check this example, but for curve, since `x' is an expression, 
we should actually do the following:

test <- function(x, ...) {
   dots <- list(...)
   if(!hasArg(from)) dots$from <- 0
   dots$expr <- substitute(x)
   invisible(do.call("curve", dots))
}

test(x^3 - 3 * x, to = 5)
test(x^3 - 3 * x, from = -5, to = 5)


HTH,

--sundar

> I actually prefer the latter if I'm changing many arguments. I do this 
> quite often when writing custom lattice plots and I want to override 
> many of the defaults.
> 
> HTH,
> 
> --sundar
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ggrothendieck at gmail.com  Thu Aug 18 22:27:20 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 18 Aug 2005 16:27:20 -0400
Subject: [R]  Set R 2.1.1. in English
In-Reply-To: <971536df050818132475195d18@mail.gmail.com>
References: <43049953.40107@univ-fcomte.fr>
	<Pine.LNX.4.61.0508181711520.4094@gannet.stats>
	<4304C30D.9090707@univ-fcomte.fr>
	<Pine.LNX.4.61.0508181910330.5218@gannet.stats>
	<4304D664.9040808@univ-fcomte.fr>
	<971536df050818132475195d18@mail.gmail.com>
Message-ID: <971536df05081813271c0e87c5@mail.gmail.com>

Another way is to create a file called Renviron.site with the following
single line:

LANGUAGE=en

and put it in your ...\R\rw2011\etc folder.  In your case,

echo LANGUAGE=en > c:\R\rw2011\etc\Renviron.site

would do it.  This would result in R being in English not only if you
(1) used the shortcut but also if you (2) used the command line to start R
or if you (3) used Start > Programs > R >, rw2011 .



On 8/18/05, Patrick Giraudoux <patrick.giraudoux at univ-fcomte.fr> wrote:
> OK. ??Perfectly clear.
>
> This written for other listers:
>
> Shortcut is the shortcuts ("alias") everybody use to launch applications
> (in French: "raccourci"), and for suckers (as I am): one just have to
> right-click the shortcut used to launch Rgui.exe, select properties
> ("propri??t??s" in French) and add in the box target ("cible" in French)
> LANGUAGE=en to the path. In my case: C:\R\rw2011\bin\Rgui.exe. Thus, it
> makes C:\R\rw2011\bin\Rgui.exe LANGUAGE=en. Then click OK.
>
> It works fantastic!!!!
>
> Thanks a lot for this. It makes three weeks I was grumling everytime
> (often) I started R, and frustrated with the SDI mode...
>
> Patrick Giraudoux
>
>
>
> Prof Brian Ripley a ??crit :
>
> > On Thu, 18 Aug 2005, Patrick Giraudoux wrote:
> >
> >>> (whish R
> >>> 2.1.1 could be parametrise 'English' even with a French Windows XP!!!!)
> >>>
> >>> If I understand you correctly, it can.  Just add LANGUAGE=en to the
> >>> shortcut.
> >>
> >
> >> Wonderful hope but not sure to catch what you term "shortcut". I
> >> tried to add this command in C:\R\rw2011\etc\Rprofile, the .Rprofile
> >> in the folder my documents, but this cannot be understood from
> >> there...  which obviously shows that "shortcut" is not a general term
> >> for profiles! I have also
> >
> >
> > See the rw-FAQ Q2.2.
> > `Shortcut' is the standard name for files on Windows with extension .lnk.
> >
> > Another way is to add this to HOME/.Renviron: see the rw-FAQ Q2.17
> >
> >> unsuccessfully looked for a file "shortcut" in the rw2011 folder. I
> >> also tried and went through the R-help archive. There were some
> >> exchanges on this subject and Asian languages some weeks ago but what
> >> I have tried and adapt on this basis did not work.
> >>
> >> The objective would be to have R in  English (thus additionnally
> >> allowing MDI mode with R-WinEdt, which is not the case with any other
> >> language) and to keep Windows XP and other applications in the
> >> foreign (= French, here) language.
> >>
> >> Thanks for any further hint,
> >>
> >> Patrick Giraudoux
> >>
> >>
> >>
> >
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From a_mani_sc_gs at vsnl.net  Thu Aug 18 22:57:17 2005
From: a_mani_sc_gs at vsnl.net (A. Mani)
Date: Fri, 19 Aug 2005 02:27:17 +0530
Subject: [R] A. Mani : Avoiding loops
Message-ID: <200508190227.17584.a_mani_sc_gs@vsnl.net>

Hello,
        I want to avoid loops in the following situation. There is a 5-col 
dataframe with col headers alone. two of the columns are non-numeric. The 
problem is to calculate statistics(scores) for each element of one column. 
The functions depend on matching in the other non-numeric column.

A  B  C  E  F
1  2  X  Y  1
2  3  G  L  1
3  1  G  L  5
and so on ...30000+ entries.

I need scores for col E entries which depend on conditional implications.


Thanks,

A. Mani
Member, Cal. Math. Soc



From ross at biostat.ucsf.edu  Thu Aug 18 23:14:31 2005
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 18 Aug 2005 14:14:31 -0700
Subject: [R] Use of contains in S4 classes
Message-ID: <1124399671.26136.5.camel@iron.libaux.ucsf.edu>

setClass("B", representation=representation("B", extra="numeric))
setClass("B", representation=representation(extra="numeric"),
	contains="B")
Are these the same?  If not, how do they differ?

What about
setClass("B", representation=representation("B", extra="numeric"),
	contains="B")
?

As far as I can tell, the Green Book doesn't talk about a contains
argument to setClass.
-- 
Ross Boylan                                      wk:  (415) 502-4031
530 Parnassus Avenue (Library) rm 115-4          ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 476-9856
University of California, San Francisco
San Francisco, CA 94143-0840                     hm:  (415) 550-1062



From rjohnson at ncifcrf.gov  Thu Aug 18 23:20:36 2005
From: rjohnson at ncifcrf.gov (Randy Johnson)
Date: Thu, 18 Aug 2005 17:20:36 -0400
Subject: [R] R equivalent to `estimate' in SAS proc mixed
Message-ID: <BF2A73E4.3982%rjohnson@ncifcrf.gov>

Example: I have the following model

    > model <- lmer(response ~ time * trt * bio + (time|id), data = dat)

    where time = time of observation
           trt = treatment group (0-no treatment / 1-treated)
           bio = biological factor (0-absent / 1-present)

and I would like to obtain an estimate (with standard error) of the change
in response over time for individuals in the treatment group with the
biological factor. The estimate is easy,

    > sum(fixef(model)[c(2,5,6,8)])

    # ie time + time:trt + time:bio + time:trt:bio

but the standard error is a hassle to calculate by hand. Is there some
better way to do this? In SAS for example there is an `estimate' option (see
sample code below) that will calculate the estimate, SE, df, t statistic,
etc... Is there some R equivalent?

Thanks,
Randy


proc mixed data=dat;
  class id;
  model response = time + trt + bio + time*trt + time*bio + trt*bio +
                   time*trt*bio;
  random time;

  estimate "est1" intercept 0 time 1 trt 0 bio 0 time*trt 1 time*bio 1
                  trt*bio 0 time*trt*bio 1;  /* or something like that */
run;

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Randy Johnson
Laboratory of Genomic Diversity
NCI-Frederick
Bldg 560, Rm 11-85
Frederick, MD 21702
(301)846-1304
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From jones at reed.edu  Thu Aug 18 23:30:59 2005
From: jones at reed.edu (Albyn Jones)
Date: Thu, 18 Aug 2005 14:30:59 -0700
Subject: [R] Console
In-Reply-To: <s304fbea.048@gwia.kvl.dk>
References: <s304fbea.048@gwia.kvl.dk>
Message-ID: <20050818143059.9ppccooc84g4wskg@webmail.reed.edu>

Quoting Daniela Salvini <DSA at kvl.dk>:

> I am at my first steps with R... and I already notice that the 
> console has a quite limited number of lines. Can anyone tell me how 
> to visualise all the information, which is actually present? I only 
> see the last part of the output, which obviosly exceeds the maximum 
> number of rows in the console.
> Thank you very much for your help!
> Daniela
>

"visualize" suggests plotting.

do you mean "how do I look at the whole dataset?"  you could print a few lines
at a time, say  X[1:25,].  With bigger datasets I usually look at the 
file in a
text editor like emacs...

albyn



From roebuck at odin.mdacc.tmc.edu  Fri Aug 19 00:30:11 2005
From: roebuck at odin.mdacc.tmc.edu (Paul Roebuck)
Date: Thu, 18 Aug 2005 17:30:11 -0500 (CDT)
Subject: [R] Use of contains in S4 classes
In-Reply-To: <1124399671.26136.5.camel@iron.libaux.ucsf.edu>
References: <1124399671.26136.5.camel@iron.libaux.ucsf.edu>
Message-ID: <Pine.OSF.4.58.0508181726190.199813@odin.mdacc.tmc.edu>

On Thu, 18 Aug 2005, Ross Boylan wrote:

> setClass("B", representation=representation("B", extra="numeric))
> setClass("B", representation=representation(extra="numeric"),
> 	contains="B")
> Are these the same?  If not, how do they differ?
>
> What about
> setClass("B", representation=representation("B", extra="numeric"),
> 	contains="B")
> ?
>
> As far as I can tell, the Green Book doesn't talk about a contains
> argument to setClass.

"S4 - Composition and Inheritance" by Witold Eryk Wolski
(a.k.a. Extending.pdf) might be what you're looking for.

----------------------------------------------------------
SIGSIG -- signature too long (core dumped)



From ross at biostat.ucsf.edu  Fri Aug 19 01:01:09 2005
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Thu, 18 Aug 2005 16:01:09 -0700
Subject: [R] Use of contains in S4 classes
In-Reply-To: <1124399671.26136.5.camel@iron.libaux.ucsf.edu>
References: <1124399671.26136.5.camel@iron.libaux.ucsf.edu>
Message-ID: <1124406069.26112.13.camel@iron.libaux.ucsf.edu>

Oops, the second class should have been A in the examples.  Corrected
version:

setClass("B", representation=representation("A", extra="numeric))
setClass("B", representation=representation(extra="numeric"),
	contains="A")
Are these the same?  If not, how do they differ?

What about
setClass("B", representation=representation("A", extra="numeric"),
	contains="A")
?

As far as I can tell, the Green Book doesn't talk about a contains
argument to setClass.
-- 
Ross Boylan                                      wk:  (415) 502-4031
530 Parnassus Avenue (Library) rm 115-4          ross at biostat.ucsf.edu
Dept of Epidemiology and Biostatistics           fax: (415) 476-9856
University of California, San Francisco
San Francisco, CA 94143-0840                     hm:  (415) 550-1062



From qiuxing at yahoo.com  Fri Aug 19 01:01:24 2005
From: qiuxing at yahoo.com (Xing Qiu)
Date: Thu, 18 Aug 2005 16:01:24 -0700 (PDT)
Subject: [R] 0/0, R segfaults
Message-ID: <20050818230124.44617.qmail@web50901.mail.yahoo.com>

Hi, 

    I noticed that when I was conducting some calculation involving
finding correlation coeficients, R stopped abnormally. So I did some
research, and find out that 0/0 was the culprit.  For sure 0/0 is not
a valid expression, but R should give a warning, an error msg or NaN
instead of segmentation fault.

    I am using R 2.1.0 under Gentoo Linux. My GCC version is 3.3.5.

Xing



From arrayprofile at yahoo.com  Fri Aug 19 01:08:32 2005
From: arrayprofile at yahoo.com (array chip)
Date: Thu, 18 Aug 2005 16:08:32 -0700 (PDT)
Subject: [R] axis label justified
Message-ID: <20050818230832.39910.qmail@web40826.mail.yahoo.com>

Hi, I am trying to make my axis labels left justified,
and have used adj=0 in the axis() without success. Can
anyone have a suggestion?

axis(2,at=1:50,labels=paste('a',1:50,sep=''),las=2,cex.axis=0.5,adj=0,tck=0,mgp=c(3,0.5,0))

Thanks



From Tom.Mulholland at dpi.wa.gov.au  Fri Aug 19 03:23:17 2005
From: Tom.Mulholland at dpi.wa.gov.au (Mulholland, Tom)
Date: Fri, 19 Aug 2005 09:23:17 +0800
Subject: [R] axis label justified
Message-ID: <4702645135092E4497088F71D9C8F51A128BF6@afhex01.dpi.wa.gov.au>

I note that the axis help seems to refer to padj. After playing around it is obvious that I don't know what is meant by this argument, so maybe I'm doing something wrong. My practical soultion is

plot(1:50,axes = FALSE,ylab = "")
axis(2,at = 1:50,labels = rep("",50),las = 2,padj = 0)
text(rep(-4,5),1:50,labels=paste('a',1:50,sep=''),xpd = TRUE,adj = 0,cex=0.5)

Tom

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of array chip
> Sent: Friday, 19 August 2005 7:09 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] axis label justified
> 
> 
> Hi, I am trying to make my axis labels left justified,
> and have used adj=0 in the axis() without success. Can
> anyone have a suggestion?
> 
> axis(2,at=1:50,labels=paste('a',1:50,sep=''),las=2,cex.axis=0.
> 5,adj=0,tck=0,mgp=c(3,0.5,0))
> 
> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From edd at debian.org  Fri Aug 19 03:36:56 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 18 Aug 2005 20:36:56 -0500
Subject: [R] 0/0, R segfaults
In-Reply-To: <20050818230124.44617.qmail@web50901.mail.yahoo.com>
References: <20050818230124.44617.qmail@web50901.mail.yahoo.com>
Message-ID: <17157.14264.779219.950875@basebud.nulle.part>


On 18 August 2005 at 16:01, Xing Qiu wrote:
| Hi, 
| 
|     I noticed that when I was conducting some calculation involving
| finding correlation coeficients, R stopped abnormally. So I did some
| research, and find out that 0/0 was the culprit.  For sure 0/0 is not
| a valid expression, but R should give a warning, an error msg or NaN
| instead of segmentation fault.
| 
|     I am using R 2.1.0 under Gentoo Linux. My GCC version is 3.3.5.

edd at basebud:~> R

R : Copyright 2005, The R Foundation for Statistical Computing
Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for a HTML browser interface to help.
Type 'q()' to quit R.

> 0/0
[1] NaN
>                                     

No problem on Debian 'testing' with R 2.1.1. You may want to try a different
libc.

Dirk

-- 
Statistics: The (futile) attempt to offer certainty about uncertainty.
         -- Roger Koenker, 'Dictionary of Received Ideas of Statistics'



From ajayshah at mayin.org  Fri Aug 19 07:17:20 2005
From: ajayshah at mayin.org (Ajay Narottam Shah)
Date: Fri, 19 Aug 2005 10:47:20 +0530
Subject: [R] Problem with get.hist.quote() in tseries
Message-ID: <20050819051720.GA13959@lubyanka.local>

When using get.hist.quote(), I find the dates are broken. This is with
R 2.1.1 on Mac OS X `panther'.

> library(tseries)
Loading required package: quadprog

    'tseries' version: 0.9-27

    'tseries' is a package for time series analysis and computational
    finance.

    See 'library(help="tseries")' for details.

> x <- get.hist.quote("^VIX")
trying URL 'http://chart.yahoo.com/table.csv?s=^VIX&a=0&b=02&c=1991&d=7&e=18&f=2005&g=d&q=q&y=0&z=^VIX&x=.csv'
Content type 'text/csv' length unknown
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........

downloaded 150Kb

> head(x)
[1] 26.62 27.93 27.19    NA    NA 28.95
> x[1:10,]
       Open  High   Low Close
 [1,] 26.62 26.62 26.62 26.62
 [2,] 27.93 27.93 27.93 27.93
 [3,] 27.19 27.19 27.19 27.19
 [4,]    NA    NA    NA    NA
 [5,]    NA    NA    NA    NA
 [6,] 28.95 28.95 28.95 28.95
 [7,] 30.38 30.38 30.38 30.38
 [8,] 33.30 33.30 33.30 33.30
 [9,] 31.33 31.33 31.33 31.33
[10,] 32.63 32.63 32.63 32.63
> plot(x)
  (dates don't show).
> str(x)
 mts [1:5343, 1:4] 26.6 27.9 27.2   NA   NA ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:4] "Open" "High" "Low" "Close"
 - attr(*, "tsp")= num [1:3] 33240 38582     1
 - attr(*, "class")= chr [1:2] "mts" "ts"

I wonder what I'm doing wrong.

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From bernd.weiss at uni-koeln.de  Fri Aug 19 07:23:14 2005
From: bernd.weiss at uni-koeln.de (Bernd Weiss)
Date: Fri, 19 Aug 2005 07:23:14 +0200
Subject: [R] Regular expressions & sub
In-Reply-To: <x2acjf836h.fsf@turmalin.kubism.ku.dk>
References: <loom.20050818T183647-236@post.gmane.org>
Message-ID: <430588E2.1067.6A23E@localhost>

On 18 Aug 2005 at 21:17, Peter Dalgaard wrote:

> Dirk Eddelbuettel <edd at debian.org> writes:
> 
> > Bernd Weiss <bernd.weiss <at> uni-koeln.de> writes:
> > > I am struggling with the use of regular expression. I got
> > > 
> > > > as.character(test$sample.id)
> > >  [1] "1.11"   "10.11"  "11.11"  "113.31" "114.2"  "114.3"  "114.8"
> > >   
> > > 
> > > and need
> > > 
> > > [1] "11"   "11"  "11"  "31" "2"  "3"  "8"
> > > 
> > > I.e. remove everything before the "." .
> > 
> > Define the dot as the hard separator, and allow for multiple digits
> > before it:
> > 
> > > sample.id <- c("1.11", "10.11", "11.11", "113.31", "114.2",
> > > "114.3", "114.8") gsub("^[0-9]*\.", "", sample.id)
> > [1] "11" "11" "11" "31" "2"  "3"  "8" 
> 
> Or, more longwinded, but with less assumptions about what goes before
> the dot:
> 
> > gsub("^.*\\.(.*)$","\\1",sample.id)
> [1] "11" "11" "11" "31" "2"  "3"  "8"

Wow, thanks a lot for all the valuable suggestions.

Bernd



From sean.oriordain at gmail.com  Fri Aug 19 08:24:56 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Fri, 19 Aug 2005 07:24:56 +0100
Subject: [R] A. Mani : Avoiding loops
In-Reply-To: <200508190227.17584.a_mani_sc_gs@vsnl.net>
References: <200508190227.17584.a_mani_sc_gs@vsnl.net>
Message-ID: <8ed68eed050818232461686a57@mail.gmail.com>

Hi,
I'm not sure what you actually want from your email (following the
posting guide is a good way of helping you explain things to the rest
of us in a way we understand - it might even answer your question!

I'm only a beginner at R so no doubt one of our expert colleagues will
help me...

> fred <- data.frame()
> fred <- edit(fred)
> fred
  A B C D E
1 1 2 X Y 1
2 2 3 G L 1
3 3 1 G L 5
> fred[,3]
[1] X G G
Levels: G X
> fred[fred[,3]=="G",]
  A B C D E
2 2 3 G L 1
3 3 1 G L 5

so at this point I can create a new dataframe with column 3 (C) ==
"G"; either explicitly or implicitly...

and if I want to calculate the sum() of column E, then I just say
something like...

> sum(fred[fred[,3]=="G",][,5])
[1] 6
>

now naturally being a bit clueless at manipulating stuff in R, I
didn't know how to do this before I started... and you guys only get
to see the lines that I typed in and got a "successful" result...

according to section 6 of the "Introduction to R" manual which comes
with R, I could also have said
> sum(fred[fred$C=="G",]$E)
[1] 6

Hmmm.... I wonder would it be reasonable to put an example of this
type into section 2.7 of the "Introduction to R"?


cheers!
Sean


On 18/08/05, A. Mani <a_mani_sc_gs at vsnl.net> wrote:
> Hello,
>         I want to avoid loops in the following situation. There is a 5-col
> dataframe with col headers alone. two of the columns are non-numeric. The
> problem is to calculate statistics(scores) for each element of one column.
> The functions depend on matching in the other non-numeric column.
> 
> A  B  C  E  F
> 1  2  X  Y  1
> 2  3  G  L  1
> 3  1  G  L  5
> and so on ...30000+ entries.
> 
> I need scores for col E entries which depend on conditional implications.
> 
> 
> Thanks,
> 
> A. Mani
> Member, Cal. Math. Soc
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From sean.oriordain at gmail.com  Fri Aug 19 08:29:44 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Fri, 19 Aug 2005 07:29:44 +0100
Subject: [R] Console
In-Reply-To: <s304fbea.048@gwia.kvl.dk>
References: <s304fbea.048@gwia.kvl.dk>
Message-ID: <8ed68eed050818232968036b09@mail.gmail.com>

Hi Daniela,

Which platform are you working on?  If you're working within a console
on windows-98, then the answer is entirely different to working under
linux or RGui on windows.  This is why the Posting Guide says to give
platform details :-)

cheers!
Sean

On 18/08/05, Daniela Salvini <DSA at kvl.dk> wrote:
> I am at my first steps with R... and I already notice that the console has a quite limited number of lines. Can anyone tell me how to visualise all the information, which is actually present? I only see the last part of the output, which obviosly exceeds the maximum number of rows in the console.
> Thank you very much for your help!
> Daniela
> 
> 
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Fri Aug 19 08:33:47 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Aug 2005 07:33:47 +0100 (BST)
Subject: [R] 0/0, R segfaults
In-Reply-To: <17157.14264.779219.950875@basebud.nulle.part>
References: <20050818230124.44617.qmail@web50901.mail.yahoo.com>
	<17157.14264.779219.950875@basebud.nulle.part>
Message-ID: <Pine.LNX.4.61.0508190706450.17830@gannet.stats>

To expand on Dirk's answer, R relies on fairly close compliance to 
IEC60559 (aka IEEE754) arithmetic in which 0/0 = NaN.  As R is C/Fortran 
program, this is a function of your C/Fortran compilers (it is most likely 
an FPU setting controlled by the compiler than libc).  Problems in this 
area are documented in the R-admin manual.

We don't know the CPU here, so ix86 is a plausible guess.  That has a FPU
control word that determines if 0/0 is NaN or an exception.  Prior to 
glibc 2.1 it could be set by __setfpucw and R sets it if NEED___SETFPUCW
is defined (only in older Linuxen).

Other people using Gentoo are not reporting problems, so this has to be a 
very specific problem, one which is best addressed to a Gentoo list.  Try 
a very simple C program such as

#include <stdio.h>
int main()
{
    double x = 0.0;
    printf("x/x = %f\n", x/x); 
}

R is doing nothing different on my Linux box (except it arranges to print 
NaN not nan regardless of platform).

On Thu, 18 Aug 2005, Dirk Eddelbuettel wrote:

>
> On 18 August 2005 at 16:01, Xing Qiu wrote:
> | Hi,
> |
> |     I noticed that when I was conducting some calculation involving
> | finding correlation coeficients, R stopped abnormally. So I did some
> | research, and find out that 0/0 was the culprit.  For sure 0/0 is not
> | a valid expression, but R should give a warning, an error msg or NaN
> | instead of segmentation fault.
> |
> |     I am using R 2.1.0 under Gentoo Linux. My GCC version is 3.3.5.
>
> edd at basebud:~> R
>
> R : Copyright 2005, The R Foundation for Statistical Computing
> Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for a HTML browser interface to help.
> Type 'q()' to quit R.
>
>> 0/0
> [1] NaN
>>
>
> No problem on Debian 'testing' with R 2.1.1. You may want to try a different
> libc.
>
> Dirk
>
> -- 
> Statistics: The (futile) attempt to offer certainty about uncertainty.
>         -- Roger Koenker, 'Dictionary of Received Ideas of Statistics'
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ligges at statistik.uni-dortmund.de  Fri Aug 19 08:50:57 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 19 Aug 2005 08:50:57 +0200
Subject: [R] axis label justified
In-Reply-To: <4702645135092E4497088F71D9C8F51A128BF6@afhex01.dpi.wa.gov.au>
References: <4702645135092E4497088F71D9C8F51A128BF6@afhex01.dpi.wa.gov.au>
Message-ID: <43058151.9030708@statistik.uni-dortmund.de>

Mulholland, Tom wrote:

> I note that the axis help seems to refer to padj. After playing around it is obvious that I don't know what is meant by this argument, so maybe I'm doing something wrong. My practical soultion is

"padj" means perpendicular adjustment, that means bottom/top adjustment 
in this case.
You need the regular "adj" here, which cannot do the trick for axis(), 
but you can workaround with mtext():

  plot(1:50, yaxt="n")
  axis(2, at=1:50, labels=FALSE)
  mtext(paste('a',1:50,sep=''), 2, at=1:50, las=2,
    cex=0.5, adj=0, line=1.5)


Uwe Ligges



> plot(1:50,axes = FALSE,ylab = "")
> axis(2,at = 1:50,labels = rep("",50),las = 2,padj = 0)
> text(rep(-4,5),1:50,labels=paste('a',1:50,sep=''),xpd = TRUE,adj = 0,cex=0.5)
> 
> Tom
> 
> 
>>-----Original Message-----
>>From: r-help-bounces at stat.math.ethz.ch
>>[mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of array chip
>>Sent: Friday, 19 August 2005 7:09 AM
>>To: r-help at stat.math.ethz.ch
>>Subject: [R] axis label justified
>>
>>
>>Hi, I am trying to make my axis labels left justified,
>>and have used adj=0 in the axis() without success. Can
>>anyone have a suggestion?
>>
>>axis(2,at=1:50,labels=paste('a',1:50,sep=''),las=2,cex.axis=0.
>>5,adj=0,tck=0,mgp=c(3,0.5,0))
>>
>>Thanks
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dieter.menne at menne-biomed.de  Fri Aug 19 08:54:40 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 19 Aug 2005 06:54:40 +0000 (UTC)
Subject: [R] =?utf-8?q?R_equivalent_to_=60estimate=27_in_SAS_proc_mixed?=
References: <BF2A73E4.3982%rjohnson@ncifcrf.gov>
Message-ID: <loom.20050819T084630-338@post.gmane.org>

Randy Johnson <rjohnson <at> ncifcrf.gov> writes:

>     > model <- lmer(response ~ time * trt * bio + (time|id), data = dat)
..
> 
> and I would like to obtain an estimate (with standard error) of the change
> in response over time for individuals in the treatment group with the
> biological factor.

Greg Warnes' gmodels package has "estimable", which works for lme (but probably
not for lmer). You model should work the same with lme with slight syntax
changes, or you could ask Greg to make estimable lmer-aware.

Dieter



From ripley at stats.ox.ac.uk  Fri Aug 19 09:02:12 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Aug 2005 08:02:12 +0100 (BST)
Subject: [R] axis label justified
In-Reply-To: <4702645135092E4497088F71D9C8F51A128BF6@afhex01.dpi.wa.gov.au>
References: <4702645135092E4497088F71D9C8F51A128BF6@afhex01.dpi.wa.gov.au>
Message-ID: <Pine.LNX.4.61.0508190740510.17830@gannet.stats>

On Fri, 19 Aug 2005, Mulholland, Tom wrote:

> I note that the axis help seems to refer to padj. After playing around 
> it is obvious that I don't know what is meant by this argument, so maybe 
> I'm doing something wrong. My practical soultion is

It moves in the other direction: for the standard x-axis it moves strings 
up or down.  Compare

> axis(1, at = seq(10,50,10), padj=0)
> axis(1, at = seq(10,50,10), padj=1)

axis() overrides any setting of par(adj).

I am not entirely sure why: my guess is that this is to avoid it being 
picked up when it was intended for something else like text.  Certainly 
sensible values would be axis- and orientation- specific so the global 
setting for the device needs to be ignored, but why any setting in the 
call should be is less clear.  Maybe the thing to do is to introduce an 
argument like 'hadj'.


> plot(1:50,axes = FALSE,ylab = "")
> axis(2,at = 1:50,labels = rep("",50),las = 2,padj = 0)
> text(rep(-4,5),1:50,labels=paste('a',1:50,sep=''),xpd = TRUE,adj = 0,cex=0.5)
>
> Tom
>
>> -----Original Message-----
>> From: r-help-bounces at stat.math.ethz.ch
>> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of array chip
>> Sent: Friday, 19 August 2005 7:09 AM
>> To: r-help at stat.math.ethz.ch
>> Subject: [R] axis label justified
>>
>>
>> Hi, I am trying to make my axis labels left justified,
>> and have used adj=0 in the axis() without success. Can
>> anyone have a suggestion?
>>
>> axis(2,at=1:50,labels=paste('a',1:50,sep=''),las=2,cex.axis=0.
>> 5,adj=0,tck=0,mgp=c(3,0.5,0))
>>
>> Thanks
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>> http://www.R-project.org/posting-guide.html
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From luke at novum.am.lublin.pl  Fri Aug 19 09:30:07 2005
From: luke at novum.am.lublin.pl (Lukasz Komsta)
Date: Fri, 19 Aug 2005 09:30:07 +0200
Subject: [R] Using lm coefficients in polyroot()
Message-ID: <43058A7F.6020505@novum.am.lublin.pl>

Dear useRs,

I need to compute zero of polynomial function fitted by lm. For example 
if I fit cubic equation by fit=lm(y~x+I(x^2)+i(x^3)) I can do it simply 
by polyroot(fit$coefficients). But, if I fit polynomial of higher order 
and optimize it by stepAIC, I get of course some coefficients removed. 
Then, if i have model

y ~ I(x^2) + I(x^4)

i cannot call polyroot in such way, because there is a need to call 
polyroot(c(0,0,fit$coefficients[1],0,fit$coefficients[2]).

Is there any method to do it automagically? I would like to write small 
function solving polynomial optimized by stepAIC, regardless of missing 
terms.

Sincerely

-- 
Lukasz Komsta
Department of Medicinal Chemistry
Medical University of Lublin
Jaczewskiego 4, 20-090 Lublin, Poland
Fax +48 81 7425165



From petr.pikal at precheza.cz  Fri Aug 19 09:58:00 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 19 Aug 2005 09:58:00 +0200
Subject: [R] A. Mani : Avoiding loops
In-Reply-To: <8ed68eed050818232461686a57@mail.gmail.com>
References: <200508190227.17584.a_mani_sc_gs@vsnl.net>
Message-ID: <4305AD28.12494.1A8E76@localhost>

Hi

Or maybe table

> mat<-matrix(sample(LETTERS[1:4], 200, replace=T),40,5)
> df<-data.frame(mat)
> table(df$X4)

 A  B  C  D 
 8 12 11  9 
>

is what is wanted

HTH
Petr



On 19 Aug 2005 at 7:24, Sean O'Riordain wrote:

> Hi,
> I'm not sure what you actually want from your email (following the
> posting guide is a good way of helping you explain things to the rest
> of us in a way we understand - it might even answer your question!
> 
> I'm only a beginner at R so no doubt one of our expert colleagues will
> help me...
> 
> > fred <- data.frame()
> > fred <- edit(fred)
> > fred
>   A B C D E
> 1 1 2 X Y 1
> 2 2 3 G L 1
> 3 3 1 G L 5
> > fred[,3]
> [1] X G G
> Levels: G X
> > fred[fred[,3]=="G",]
>   A B C D E
> 2 2 3 G L 1
> 3 3 1 G L 5
> 
> so at this point I can create a new dataframe with column 3 (C) ==
> "G"; either explicitly or implicitly...
> 
> and if I want to calculate the sum() of column E, then I just say
> something like...
> 
> > sum(fred[fred[,3]=="G",][,5])
> [1] 6
> >
> 
> now naturally being a bit clueless at manipulating stuff in R, I
> didn't know how to do this before I started... and you guys only get
> to see the lines that I typed in and got a "successful" result...
> 
> according to section 6 of the "Introduction to R" manual which comes
> with R, I could also have said > sum(fred[fred$C=="G",]$E) [1] 6
> 
> Hmmm.... I wonder would it be reasonable to put an example of this
> type into section 2.7 of the "Introduction to R"?
> 
> 
> cheers!
> Sean
> 
> 
> On 18/08/05, A. Mani <a_mani_sc_gs at vsnl.net> wrote:
> > Hello,
> >         I want to avoid loops in the following situation. There is a
> >         5-col
> > dataframe with col headers alone. two of the columns are
> > non-numeric. The problem is to calculate statistics(scores) for each
> > element of one column. The functions depend on matching in the other
> > non-numeric column.
> > 
> > A  B  C  E  F
> > 1  2  X  Y  1
> > 2  3  G  L  1
> > 3  1  G  L  5
> > and so on ...30000+ entries.
> > 
> > I need scores for col E entries which depend on conditional
> > implications.
> > 
> > 
> > Thanks,
> > 
> > A. Mani
> > Member, Cal. Math. Soc
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From frt at Codan.dk  Fri Aug 19 10:18:29 2005
From: frt at Codan.dk (Fredrik Thuring)
Date: Fri, 19 Aug 2005 10:18:29 +0200
Subject: [R] Handling of tables in R
Message-ID: <OF05FD1F41.C07A8D9F-ONC1257062.002B7B4D-C1257062.002DA673@codan.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050819/9b9bd49f/attachment.pl

From sean.oriordain at gmail.com  Fri Aug 19 10:25:21 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Fri, 19 Aug 2005 08:25:21 +0000
Subject: [R] Console
In-Reply-To: <s305a427.082@gwia.kvl.dk>
References: <s305a427.082@gwia.kvl.dk>
Message-ID: <8ed68eed050819012574dc6f23@mail.gmail.com>

Hi Daniela,

Are you using the GUI (RGui.exe) or are you using R.exe inside the
cmd.exe console? if the latter then you can right click on the blue
bar at the top, select properties, and change "Screen Buffer Size" /
Height to be something like 9000... then you can just use your mouse
to slider back up to stuff you missed...

On the number of questions per day... I think if you go through the
"Posting Guide"
http://www.r-project.org/posting-guide.html, the "Introduction to R",
the FAQs (normal and Windows) http://cran.r-project.org/faqs.html and
the other ancillary documentation, such as    R-Tips
http://www.ku.edu/~pauljohn/R/Rtips.html... all of which are mentioned
in the Posting Guide... :-)

The process of going through the posting guide each time, while a bit
tedious is an incredible learning experience... many posts to the list
just would never happen if the author went to the trouble of going
through the posting guide... admittedly the introductory documentation
is not as good as it could be and is a bit terse in places...

However, that said, I am also a relative beginner at R, I try to read
and understand every post, most of them just go straight over my head
as my statistical skills are severely lacking and when people start
talking about GLMs all I hear is a whooshing sound over my head :-)

One way that I have found useful for learning is to pick on questions
which are at my level and try and answer them... and in answering
them, I learn with you. Of course sometimes I give sub-optimal
answers, but there are plenty of experts around to nudge us in the
right direction :-)

cheers!
Sean


On 19/08/05, Daniela Salvini <dsa at kvl.dk> wrote:
> Hi Sean!
> Thank you so much for replying so soon! Well, I am very bad at these things, so I suppose my "platform" is Windows XP, is it what you need to know? I hope so!... And how many questions are we allowed to pose to the mailing list...per day? I suppose I will have quite a few ... : )
> Thank you so much!
> Daniela
> 
> PS Maybe I should read the Posting Guide, I did not notice there was one
> 
> >>> sean.oriordain at gmail.com 08/19/05 8:29 am >>>
> Hi Daniela,
> 
> Which platform are you working on?  If you're working within a console
> on windows-98, then the answer is entirely different to working under
> linux or RGui on windows.  This is why the Posting Guide says to give
> platform details :-)
> 
> cheers!
> Sean
> 
> On 18/08/05, Daniela Salvini <DSA at kvl.dk> wrote:
> > I am at my first steps with R... and I already notice that the console has a quite limited number of lines. Can anyone tell me how to visualise all the information, which is actually present? I only see the last part of the output, which obviosly exceeds the maximum number of rows in the console.
> > Thank you very much for your help!
> > Daniela
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
>



From tpapp at Princeton.EDU  Fri Aug 19 10:37:56 2005
From: tpapp at Princeton.EDU (Tamas K Papp)
Date: Fri, 19 Aug 2005 10:37:56 +0200
Subject: [R] why is sd(numeric(1))==NA (and not NaN)?
Message-ID: <20050819083756.GA9464@tpapp.student.princeton.edu>

I am just curious about this, and could not find anything in the help
pages or the list archives.  ?var mentions that for a vector of length
1 it gives NA instead of NaN as S-Plus does.

mean(numeric(0))==NaN, this makes sense since it is 0/0.

sd(numeric(1))==NA, but it is sqrt(0/0), so it makes more sense to me
as NaN.

Perhaps sd(numeric(0)) (and var) could return NA then...

Please understand that I am not proposing a change to R (which is a
very well-polished language) but would like to know the reasons for
the above.

The issue came up when I was evaluating MCMC simulations.  I needed to
know the conditional mean and standard deviation of some variable
given that it is nonzero, so I removed the zeroes and used mean() and
sd() on it, not thinking about the case when all draws are zero.  When
that happened, mean() gave NaN gracefully, but sd() (of course, in
compliance with ?var) failed.  I don't see why NA would be so bad in
that case, if somebody could please explain as there must be a reason.

Thank you,

Tamas



From petr.pikal at precheza.cz  Fri Aug 19 10:47:05 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 19 Aug 2005 10:47:05 +0200
Subject: [R] Handling of tables in R
In-Reply-To: <OF05FD1F41.C07A8D9F-ONC1257062.002B7B4D-C1257062.002DA673@codan.dk>
Message-ID: <4305B8A9.5352.935E9@localhost>



From anne.piotet at gmail.com  Fri Aug 19 11:22:08 2005
From: anne.piotet at gmail.com (Anne)
Date: Fri, 19 Aug 2005 10:22:08 +0100
Subject: [R] Handling of tables in R
In-Reply-To: <OF05FD1F41.C07A8D9F-ONC1257062.002B7B4D-C1257062.002DA673@codan.dk>
References: <OF05FD1F41.C07A8D9F-ONC1257062.002B7B4D-C1257062.002DA673@codan.dk>
Message-ID: <80102e880508190222243f1125@mail.gmail.com>

Save your table in a text file ( see ?write.table ) with the separator
set to "\t" ; you can then import it into excel

for the nb of digits use 
>options(digits=3)

see ?options 


Anne


2005/8/19, Fredrik Thuring <frt at codan.dk>:
> 
>        Hi!
> 
>        I have a few questions concerning reading of tables from R to
> other programs. My main question is if it's even possible to read a table
> created in R (with the functions data.frame     and save) to Excel (or
> maybe SAS) and if so how does one do this? If I just mark the table in R
> and copy-paste to Excel the whole table ends up in one single cell, (of
> course).        My goal is to copy the table to Excel (or SAS) in such a
> way that a single observation gets placed in a single cell.
> 
>        If this isn't possible, is there any way to reduce the number of
> digits in a table in R?
> 
>        I would be more than happy if there were any one who knows the
> answer to my questions!
> 
>        Thanks before hand,
>        Fredrik Thuring
>        Research department
>        Codan Insurance, Copenhagen
> 
> 
> ------------------------------------------------------------------------------
> This e-mail and any attachment may be confidential and may also be privileged.
> If you are not the intended recipient, please notify us immediately and then
> delete this e-mail and any attachment without retaining copies or disclosing
> the contents thereof to any other person.
> Thank you.
> ------------------------------------------------------------------------------
> 
>        [[alternative HTML version deleted]]
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 


-- 
Anne



From francoisromain at free.fr  Fri Aug 19 11:37:01 2005
From: francoisromain at free.fr (Romain Francois)
Date: Fri, 19 Aug 2005 11:37:01 +0200
Subject: [R] Handling of tables in R
In-Reply-To: <80102e880508190222243f1125@mail.gmail.com>
References: <OF05FD1F41.C07A8D9F-ONC1257062.002B7B4D-C1257062.002DA673@codan.dk>
	<80102e880508190222243f1125@mail.gmail.com>
Message-ID: <4305A83D.9040703@free.fr>

Le 19.08.2005 11:22, Anne a ??crit :

>Save your table in a text file ( see ?write.table ) with the separator
>set to "\t" ; you can then import it into excel
>
>for the nb of digits use 
>  
>
>>options(digits=3)
>>    
>>
>
>see ?options 
>
>  
>
Hello,

And if you run R on windows (just a guess because you didn't tell), the 
saving-to-a-file part is not necessary. use :
R> write.table(your.data.frame, file='clipboard')
and on excel "paste", your data should magically appear on excel ...

Romain

>Anne
>
>
>2005/8/19, Fredrik Thuring <frt at codan.dk>:
>  
>
>>       Hi!
>>
>>       I have a few questions concerning reading of tables from R to
>>other programs. My main question is if it's even possible to read a table
>>created in R (with the functions data.frame     and save) to Excel (or
>>maybe SAS) and if so how does one do this? If I just mark the table in R
>>and copy-paste to Excel the whole table ends up in one single cell, (of
>>course).        My goal is to copy the table to Excel (or SAS) in such a
>>way that a single observation gets placed in a single cell.
>>
>>       If this isn't possible, is there any way to reduce the number of
>>digits in a table in R?
>>
>>       I would be more than happy if there were any one who knows the
>>answer to my questions!
>>
>>       Thanks before hand,
>>       Fredrik Thuring
>>       Research department
>>       Codan Insurance, Copenhagen
>>    
>>


-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From dieter.menne at menne-biomed.de  Fri Aug 19 11:50:33 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 19 Aug 2005 09:50:33 +0000 (UTC)
Subject: [R] Using lm coefficients in polyroot()
References: <43058A7F.6020505@novum.am.lublin.pl>
Message-ID: <loom.20050819T113415-591@post.gmane.org>

Lukasz Komsta <luke <at> novum.am.lublin.pl> writes:

> I need to compute zero of polynomial function fitted by lm. For example 
> if I fit cubic equation by fit=lm(y~x+I(x^2)+i(x^3)) I can do it simply 
> by polyroot(fit$coefficients). But, if I fit polynomial of higher order 
> and optimize it by stepAIC, I get of course some coefficients removed. 
> Then, if i have model
> 
> y ~ I(x^2) + I(x^4)
> 
> i cannot call polyroot in such way, because there is a need to call 
> polyroot(c(0,0,fit$coefficients[1],0,fit$coefficients[2]).
> 
> Is there any method to do it automagically? I would like to write small 
> function solving polynomial optimized by stepAIC, regardless of missing 
> terms.

Are you really sure you want to throw away lower order terms in a fit by 
misusing stepAIC? With the rare exception of omitting a constant offset, I 
don't know any case where there are good reasons to omit lower order terms in a 
fit (willing to learn, though,...).

And if you only want to find the zeroes, it's definitively not useful 
to "optimize" this way. When factors are involved, stepAIC always keeps lower 
order terms, but it is expecting a bit too much from stepAIC to expect an "do 
you really want to do this" here.

For a more competent discussion of the matter, read Bill Venables

http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf

Dieter



From ripley at stats.ox.ac.uk  Fri Aug 19 11:58:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Aug 2005 10:58:46 +0100 (BST)
Subject: [R] Handling of tables in R
In-Reply-To: <4305A83D.9040703@free.fr>
References: <OF05FD1F41.C07A8D9F-ONC1257062.002B7B4D-C1257062.002DA673@codan.dk>
	<80102e880508190222243f1125@mail.gmail.com> <4305A83D.9040703@free.fr>
Message-ID: <Pine.LNX.4.61.0508191050160.20457@gannet.stats>

On Fri, 19 Aug 2005, Romain Francois wrote:

> Le 19.08.2005 11:22, Anne a ?crit :
>
>> Save your table in a text file ( see ?write.table ) with the separator
>> set to "\t" ; you can then import it into excel
>>
>> for the nb of digits use
>>> options(digits=3)

Only for printing in R: see below for other suggestions.

> And if you run R on windows (just a guess because you didn't tell), the
> saving-to-a-file part is not necessary. use :
> R> write.table(your.data.frame, file='clipboard')
> and on excel "paste", your data should magically appear on excel ...

You are likely to be better off with write.csv().  There _is_ a manual (`R 
Data Import/Export') about this. (In particular, the default setting for 
col.names in write.table is not usually what Excel usually expects, and 
the default separator is space, so you better not have spaces (or for 
Anne's suggestion, tabs) in the data.)

>
> Romain
>
>> Anne
>>
>>
>> 2005/8/19, Fredrik Thuring <frt at codan.dk>:
>>
>>
>>>       Hi!
>>>
>>>       I have a few questions concerning reading of tables from R to
>>> other programs. My main question is if it's even possible to read a table
>>> created in R (with the functions data.frame     and save) to Excel (or
>>> maybe SAS) and if so how does one do this? If I just mark the table in R
>>> and copy-paste to Excel the whole table ends up in one single cell, (of
>>> course).        My goal is to copy the table to Excel (or SAS) in such a
>>> way that a single observation gets placed in a single cell.
>>>
>>>       If this isn't possible, is there any way to reduce the number of
>>> digits in a table in R?

?round, ?signif, ?format.  (Anne's answer applies to printing, not to the 
table and not to write.table/csv.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From gb at stat.umu.se  Fri Aug 19 12:14:10 2005
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Fri, 19 Aug 2005 12:14:10 +0200
Subject: [R] Handling dates
Message-ID: <20050819101410.GA29803@stat.umu.se>

I have a problem with some functions handling dates, in packages 'date' and 
'survival' (they seem to be identical). For instance, from the documentation,

--------------------
mdy.date {survival}	

R Documentation

Convert to Julian Dates

Description

Given a month, day, and year, returns the number of days since January 1, 1960.
Usage

mdy.date(month, day, year, nineteen = TRUE, fillday = FALSE,
         fillmonth = FALSE)
----------------------------
but

> library(survival)
> mdy.date(12, 1, 1977)
[1] 1Dec77

Similar strange results appear in other date-related functions. I plan to 
write functions that converts, eg, "1977-01-31" to the real number 1977.084
and back. What function in  R  does what 'mdy.date' claims to do?

I'm on
  
platform i686-pc-linux-gnu
arch     i686
os       linux-gnu
system   i686, linux-gnu
status
major    2
minor    1.1
year     2005
month    06
day      20
language R

-- 
G??ran Brostr??m                    tel: +46 90 786 5223
Department of Statistics          fax: +46 90 786 6614
Ume?? University                   http://www.stat.umu.se/~goran.brostrom/
SE-90187 Ume??, Sweden             e-mail: gb at stat.umu.se



From svenknueppel at reilich.net  Thu Aug 18 18:19:59 2005
From: svenknueppel at reilich.net (svenknueppel@reilich.net)
Date: Thu, 18 Aug 2005 18:19:59 +0200 (CEST)
Subject: [R] plot and legend
Message-ID: <20050818161959.8F5557182E8@basicbox6.server-home.net>

Hello,

I would like make a plot with a legend. How can I take the legend
outside of the plot frame?

Greetings, Sven Knüppel (Berlin, Germany)



From p.dalgaard at biostat.ku.dk  Thu Aug 18 09:44:02 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 18 Aug 2005 09:44:02 +0200
Subject: [R] power of a matrix
In-Reply-To: <971536df050817211977a63787@mail.gmail.com>
References: <8B08A3A1EA7AAC41BE24C750338754E69FDB7E@HERMES.demogr.mpg.de>
	<x2br3wg2mw.fsf@turmalin.kubism.ku.dk> <430404B7.903@pdf.com>
	<971536df050817211977a63787@mail.gmail.com>
Message-ID: <x27jejn0zh.fsf@turmalin.kubism.ku.dk>

Gabor Grothendieck <ggrothendieck at gmail.com> writes:

> Its expm.

Doh. I had even looked up its help page...

 
> 
> On 8/17/05, Spencer Graves <spencer.graves at pdf.com> wrote:
> > Hi, Peter:
> > 
> >          I couldn't find "mexp" in the Matrix package, but I did find it in
> > fMultivar and in Lindsey's rmutil.  These are different functions, but
> > produced essentially the same answer for mexp(array(1:4, dim=c(2,2))).
> > While hunting for that, I also also found reference by Doug Bates in a
> > previous interchange on r-help to "a classic paper ... I would recommend
> > reading":
> > 
> >  Moler C., van Loan C., (2003); _Nineteen dubious ways to compute
> >      the exponential of a matrix,  twenty-five years later_, SIAM
> >      Review 45, 3-49.
> > 
> >          This paper was cited in the help page for mexp in fMultivar but not
> > in rmutil.

As far as I remember, that's because rmutil is using one of the more
dubious methods, namely eigendecomposition. It breaks down if there
are eigenvalues with multiplicity greater than 1, which does happen
(systematically) in some statistical models.


> >          spencer graves
> > 
> > Peter Dalgaard wrote:
> > 
> > > "Rau, Roland" <Rau at demogr.mpg.de> writes:
> > >
> > >
> > >>Thank you very much! Thanks also to the authors of this function,
> > >>Vincente Canto Cassola and Martin Maechler!
> > >>
> > >>This is exactly what I hoped for.
> > >
> > > ....
> > >
> > >>>look at function ?mtx.exp() in the Malmig package, e.g.,
> > >
> > >
> > > Also, there is mexp() in the Matrix package. I'm not sure about the
> > > relative merits. mexp() is one of the less dubious implementations of
> > > matrix exponentials, but it does require to and from class "Matrix".
> > > mtx.exp is a bit unfortunately named as it appears to calculate matrix
> > > *powers* (which in this case is what you need).
> > >
> > 
> > --
> > Spencer Graves, PhD
> > Senior Development Engineer
> > PDF Solutions, Inc.
> > 333 West San Carlos Street Suite 700
> > San Jose, CA 95110, USA
> > 
> > spencer.graves at pdf.com
> > www.pdf.com <http://www.pdf.com>
> > Tel:  408-938-4420
> > Fax: 408-280-7915
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From spencer.graves at pdf.com  Thu Aug 18 05:20:26 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 17 Aug 2005 22:20:26 -0500
Subject: [R] How to assess significance of random effect in lme4
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7409E5BE0D@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F7409E5BE0D@dc1ex2.air.org>
Message-ID: <4303FE7A.6070808@pdf.com>

	  I don't have Pinheiro and Bates handy, but as I recall, it's somthing 
like chapter 3.  See "simulate.lme" in package nlme;  with luck, it will 
also be in the index to Pinheiro and Bates.  If not, it's still not hard 
to find.  Their chapter on this includes some marvelous figures 
presenting simulation results presumably produced with a version of 
"simulate.lme".

	  The paper that seemed most insightful to me is Crainiceanu, Ruppert 
and Vogelsang (2003) Some Properties of Likelihood Ratio Tests in Linear 
Mixed Models" Cornell U. 
(http://www.orie.cornell.edu/~davidr/papers/zeroprob_rev01.pdf). 
However, I suggest you also examine Ota et al. (2000) "Approximate 
Likelihood Ratio Tests and Marginal Distributions for Evolutionary Tree 
Models with Constraints on Parameters", Molecular Biology and Evolution 
17:798-803.

	  Just now I found other references by Googling for "likelihood ratio 
with parameter at a boundary".  My literature search on this issue is 
far from exhaustive, and I would be pleased to hear from others who have 
other articles to recommend.

	  spencer graves

#####################
Andrew Robinson wrote:

 > Hi Spencer,
 >
 > thanks for this note to the r-users list.  I wonder if I could ask ...
 >
 >
 >>	  4.  With parameters at a boundary as with variance components, the
 >>best procedure seems to double the p-value from a nested anova (unless
 >>the reported p-value is already large).  This is because the
 >>2*log(likelihood ratio) in such cases is roughly a 50-50 mixture of 0
 >>and chi-square(1) [if testing only 1 variance component parameter].
 >>This is supported by a substantial amount of research, including
 >>simulations discussed in a chapter in Pinheiro and Bates (2000)
 >>Mixed-Effects Models in S and S-Plus (Springer).  The may be more
 >>accurate procedures available in the literature, but none so simple as
 >>this as far as I know.
 >
 >
 > Could you provide a page reference or references in the literature?
 > I've heard similar things before, but never seen them myself.  Don't
 > worry if they're not immediately available.
 >
 > Thanks,
 >
 > Andrew
######################################
	  Is there some reason you are NOT using "anova", as in "Examples"
section of "?lmer"?

	  Permit me to summarize what I know about this, and I'll be pleased if
someone else who thinks they know different would kindly enlighten me
and others who might otherwise be misled if anything I say is
inconsistent with the best literature available at the moment:

	  1.  Doug Bates in his PhD dissertation and later in his book with Don
Watts (1988) Nonlinear Regression Analysis and Its Applications (Wiley)
split approximation errors in nonlinear least squares into "intrinsic
curvature" and "parameter effects curvature".  He quantified these two
problems in the context of roughly three dozen published examples, if my
memory is correct, and found that in not quite all cases, the parameter
effects were at least an order of magnitude greater than the intrinsic
curvature.

	  2.  In nonnormal situations, maximum likelihood is subject to more
approximation error -- intrinsic curvature -- than "simple" nonlinear
least squares.  However, I would expect this comparison to still be
fairly accurate, even if the differences may not be quite as stark.

	  3.  The traditional use of "standard errors" to judge statistical
significance is subject to both intrinsic and parameter effects errors,
while likelihood ratio procedures such as anova are subject only to the
intrinsic curvature (assuming there are no substantive problems with
nonconvergence).  Consequently, to judge statistical significance of an
effect, anova is usually substantially better than the so-called Wald
procedure using approximate standard errors, and is almost never worse.
  If anyone knows of a case where this is NOT true, I'd like to know.

	  4.  With parameters at a boundary as with variance components, the
best procedure seems to double the p-value from a nested anova (unless
the reported p-value is already large).  This is because the
2*log(likelihood ratio) in such cases is roughly a 50-50 mixture of 0
and chi-square(1) [if testing only 1 variance component parameter].
This is supported by a substantial amount of research, including
simulations discussed in a chapter in Pinheiro and Bates (2000)
Mixed-Effects Models in S and S-Plus (Springer).  The may be more
accurate procedures available in the literature, but none so simple as
this as far as I know.

	  Comments?
	  spencer graves
p.s.  It looks like fm at bVars is a list containing vectors of length 29
and 6 in your example.  I don't know what they are, but I don't see how
they can be standard errors in the usual sense.

Doran, Harold wrote:

> These are the posterior variances of the random effects (I think more
> properly termed "empirical" posteriors).  Your model apparently includes
> three levels of random variation (commu, bcohort, residual). The first
> are the variances associated with your commu random effect and the
> second are the variances associated with the bcohort random effect.
> 
> Accessing either one would require
> 
> fm at bVar$commu or fm at bVar$bcohort
> 
> Obviously, replace "fm" with the name of your fitted model.
> 
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Shige Song
> Sent: Wednesday, August 17, 2005 7:50 AM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] How to assess significance of random effect in lme4
> 
> Hi Harold,
> 
> Thanks for the reply. I looked at my outputs using str() as you
> suggested, here is the part you mentioned:
> 
>   ..@ bVar     :List of 2
>   .. ..$ commu  : num [1, 1, 1:29] 5e-10 5e-10 5e-10 5e-10 5e-10 ...
>   .. ..$ bcohort: num [1, 1, 1:6] 1.05e-05 7.45e-06 6.53e-06 8.25e-06
> 7.11e-06 ...
> 
> where commu and bcohort are the two second-level units. Are these
> standard errors? Why the second vector contains a series of different
> numbers?
> 
> Thanks!
> 
> Shige
> 
> On 8/17/05, Doran, Harold <HDoran at air.org> wrote:
> 
>> 
>>
>>You can extract the posterior variance of the random effect from the 
>>bVar slot of the fitted lmer model. It is not a hidden option, but a 
>>part of the fitted model. It just doesn't show up when you use
> 
> summary().
> 
>> 
>> Look at the structure of your object to see what is available using
> 
> str().
> 
>> 
>> However, your comment below seems to imply that it is incorrect for 
>>lmer to report SDs instead of the standard error, which is not true. 
>>That is a quantity of direct interest.
>> 
>> Other multilevel programs report the same exact statistics (for the 
>>most part). For instance, HLM reports the variances as well. If you 
>>want the posterior variance of an HLM model you need to extract it.
>>
>> 
>> 
>> -----Original Message-----
>> From:   r-help-bounces at stat.math.ethz.ch on behalf of
>>Shige Song
>> Sent:   Wed 8/17/2005 6:30 AM
>> To:     r-help at stat.math.ethz.ch
>> Cc:    
>> Subject:        [R] How to assess significance of random effect in
> 
> lme4
> 
>> 
>> Dear All,
>> 
>> With kind help from several friends on the list, I am getting close.
>> Now here are something interesting I just realized: for random  
>>effects, lmer reports standard deviation instead of standard error! Is
> 
> 
>>there a hidden option that tells lmer to report standard error of  
>>random effects, like most other multilevel or mixed modeling software,
> 
> 
>>so that we can say something like "randome effect for xxx is  
>>significant, while randome effect for xxx is not significant"? Thanks!
>> 
>> Best,
>> Shige
>> 
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list  
>>https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
>>http://www.R-project.org/posting-guide.html
>> 
>> 
>> 
>>
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From alastair.cooper at gmail.com  Thu Aug 18 23:23:53 2005
From: alastair.cooper at gmail.com (Alastair Cooper)
Date: Thu, 18 Aug 2005 22:23:53 +0100
Subject: [R] Compiling R to run natively on Windows x64
Message-ID: <58012b460508181423380ac3cf@mail.gmail.com>

Hi

I am looking at getting a PC preinstalled with Windows XP x64. What I
want to know is, has anyone successfully compiled a version of R for
64-bit Windows (Amd64 - not Itanium), and if so did they find any
performance boost?

Thanks



From stanimura-ngs at umin.ac.jp  Fri Aug 19 12:32:55 2005
From: stanimura-ngs at umin.ac.jp (Susumu Tanimura)
Date: Fri, 19 Aug 2005 19:32:55 +0900
Subject: [R] Summary: Unexpected result of read.dbf
Message-ID: <20050819193255.10a97bc0.stanimura-ngs@umin.ac.jp>

Hi there,

This is summary and patch for a bug in read.dbf, demonstrating in
Message-Id: <20050818150446.697835cb.stanimura-ngs at umin.ac.jp>.  

After consulting Rjpwiki, a cyber-community of R user in Japan, the
cause was found, and the patch of solution was proposed.

Overflowing occurs when we use read.dbf for reading a dbf file having
a field of longer signed integer. For example,

$ dbf2txt test.dbf
 #KEYCODE
 422010010
 42201002101
 42201002102
 42201002103
 42201002104
 422010060
 422010071
 422010072
 42201008001
 42201008002

The KEYCODE field is numeric type, 19 digits, and no decimal.  You can
create this file with OpenOffice.org Calc, txt2dbf, and so on.  You
also prepare a file of CSV format.

> library(foreign)
 > cbind(read.csv("test.csv"),read.dbf("test.dbf"))
        KEYCODE   KEYCODE
 1    422010010 422010010
 2  42201002101        NA
 3  42201002102        NA
 4  42201002103        NA
 5  42201002104        NA
 6    422010060 422010060
 7    422010071 422010071
 8    422010072 422010072
 9  42201008001        NA
 10 42201008002        NA

This is not reproducible when the field has decimals like numeric
type, 19 digits, and 5 decimals.

The patch written of Mr. Eiji Nakama is followed.

--- foreign.orig/src/dbfopen.c  2005-08-19 18:54:06.000000000 +0900
+++ foreign/src/dbfopen.c       2005-08-19 18:58:06.000000000 +0900
@@ -970,7 +970,8 @@
              || psDBF->pachFieldType[iField] == 'F' )
        /* || psDBF->pachFieldType[iField] == 'D' ) D is Date */
     {
-       if( psDBF->panFieldDecimals[iField] > 0 )
+       if( psDBF->panFieldDecimals[iField] > 0 ||
+               psDBF->panFieldSize[iField] > 9 )
            return( FTDouble );
        else
            return( FTInteger );

After adopting the patch, read.dbf works correctly.

> cbind(read.csv("test.csv"),read.dbf("test.dbf"))
       KEYCODE     KEYCODE
1    422010010   422010010
2  42201002101 42201002101
3  42201002102 42201002102
4  42201002103 42201002103
5  42201002104 42201002104
6    422010060   422010060
7    422010071   422010071
8    422010072   422010072
9  42201008001 42201008001
10 42201008002 42201008002

--
Susumu Tanimura



From wolfgang.waser at rz.hu-berlin.de  Fri Aug 19 12:38:42 2005
From: wolfgang.waser at rz.hu-berlin.de (Wolfgang Waser)
Date: Fri, 19 Aug 2005 12:38:42 +0200
Subject: [R] FFT, frequs, magnitudes, phases
Message-ID: <200508191238.42844.wolfgang.waser@rz.hu-berlin.de>

Hi,

I'm in dire need of a fast fourier transformation for me stupid biologist, 
i.e. I have a heartbeat signal and would like to decompose it into pure sin 
waves, getting three vectors, one containing the frequencies of the sin 
waves, one the magnitudes and one the phases (that's what I get from my data 
acquisition software's FFT function).
I'd be very much obliged, if someone could point out which command would do 
the job in R.

Thanks!

Wolfgang



From ligges at statistik.uni-dortmund.de  Fri Aug 19 12:51:44 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 19 Aug 2005 12:51:44 +0200
Subject: [R] plot and legend
In-Reply-To: <20050818161959.8F5557182E8@basicbox6.server-home.net>
References: <20050818161959.8F5557182E8@basicbox6.server-home.net>
Message-ID: <4305B9C0.8020606@statistik.uni-dortmund.de>

svenknueppel at reilich.net wrote:

> Hello,
> 
> I would like make a plot with a legend. How can I take the legend
> outside of the plot frame?


Use par(xpd = .....)
See ?par for details.

Uwe Ligges



> Greetings, Sven Kn??ppel (Berlin, Germany)
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From gavin.simpson at ucl.ac.uk  Fri Aug 19 12:52:51 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 19 Aug 2005 11:52:51 +0100
Subject: [R] plot and legend
In-Reply-To: <20050818161959.8F5557182E8@basicbox6.server-home.net>
References: <20050818161959.8F5557182E8@basicbox6.server-home.net>
Message-ID: <1124448771.31394.18.camel@gsimpson.geog.ucl.ac.uk>

On Thu, 2005-08-18 at 18:19 +0200, svenknueppel at reilich.net wrote:
> Hello,
> 
> I would like make a plot with a legend. How can I take the legend
> outside of the plot frame?
> 

Does this do what you want?

## change the plotting parameters and store defaults
## mar sets 2 more lines in the margin than default at the top
## xpd = TRUE stops clipping to the plot region only
oldpar <- par(mar = c(5, 4, 6, 2) + 0.1, xpd = TRUE)

## do a plot
plot(1:10)

## now build a legend, the y co-ordinate pushes the legend outside the
## plotting region - x & y are on same scale as your axes
## xjust = 0.5 centres the legend on the x coordinate
legend(x = 5.5, y = 11.5, "legend text", pch = 1, xjust = 0.5)

##restore the defaults
par(oldpar)

It would be nice if legend allowed the use of "top" etc. to relate to
the device if the user wanted. It would simplify this kind plot
arrangement.

HTH

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From ripley at stats.ox.ac.uk  Fri Aug 19 13:15:48 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Aug 2005 12:15:48 +0100 (BST)
Subject: [R] Handling of tables in R
In-Reply-To: <Pine.LNX.4.61.0508191050160.20457@gannet.stats>
References: <OF05FD1F41.C07A8D9F-ONC1257062.002B7B4D-C1257062.002DA673@codan.dk>
	<80102e880508190222243f1125@mail.gmail.com> <4305A83D.9040703@free.fr>
	<Pine.LNX.4.61.0508191050160.20457@gannet.stats>
Message-ID: <Pine.LNX.4.61.0508191213480.4273@gannet.stats>

On Fri, 19 Aug 2005, Prof Brian Ripley wrote:

> On Fri, 19 Aug 2005, Romain Francois wrote:
>
>> Le 19.08.2005 11:22, Anne a ?crit :
>> 
>>> Save your table in a text file ( see ?write.table ) with the separator
>>> set to "\t" ; you can then import it into excel
>>> 
>>> for the nb of digits use
>>>> options(digits=3)
>
> Only for printing in R: see below for other suggestions.
>
>> And if you run R on windows (just a guess because you didn't tell), the
>> saving-to-a-file part is not necessary. use :
>> R> write.table(your.data.frame, file='clipboard')
>> and on excel "paste", your data should magically appear on excel ...
>
> You are likely to be better off with write.csv().  There _is_ a manual (`R 
> Data Import/Export') about this. (In particular, the default setting for 
> col.names in write.table is not usually what Excel usually expects, and the 
> default separator is space, so you better not have spaces (or for Anne's 
> suggestion, tabs) in the data.)

Peter Dalgaard pointed out that write.table defaults to quoting, so it is 
quotes in fields that would be a problem not tabs/spaces. However, 
write.csv() is set up with the correct options for that, and also for the 
header line if row names are written (the default).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From p.dalgaard at biostat.ku.dk  Fri Aug 19 13:35:45 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Aug 2005 13:35:45 +0200
Subject: [R] Handling dates
In-Reply-To: <20050819101410.GA29803@stat.umu.se>
References: <20050819101410.GA29803@stat.umu.se>
Message-ID: <x2acje2m7i.fsf@turmalin.kubism.ku.dk>

G??ran Brostr??m <gb at stat.umu.se> writes:

> I have a problem with some functions handling dates, in packages 'date' and 
> 'survival' (they seem to be identical). For instance, from the documentation,
> 
> --------------------
> mdy.date {survival}	
> 
> R Documentation
> 
> Convert to Julian Dates
> 
> Description
> 
> Given a month, day, and year, returns the number of days since January 1, 1960.
> Usage
> 
> mdy.date(month, day, year, nineteen = TRUE, fillday = FALSE,
>          fillmonth = FALSE)
> ----------------------------
> but
> 
> > library(survival)
> > mdy.date(12, 1, 1977)
> [1] 1Dec77
> 
> Similar strange results appear in other date-related functions. I plan to 
> write functions that converts, eg, "1977-01-31" to the real number 1977.084
> and back. What function in  R  does what 'mdy.date' claims to do?

mdy.date does ...

> dput(mdy.date(12, 1, 1977))
structure(6544, class = "date")

> mdy.date(1, 31, 1977)/365.2425+1960 # or /365.25 if you really want 1977.084
[1] 1977.085

But with recent R's, as.Date is a better bet:


> c(as.Date("1977-01-31") - as.Date("0000-01-01"))/365.2425
[1] 1977.084

(notice that you need the c() to avoid the nonsense of

> (as.Date("1977-01-31") - as.Date("0000-01-01"))/365.2425
Time difference of 1977.084 days

)


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From luke at novum.am.lublin.pl  Fri Aug 19 14:13:49 2005
From: luke at novum.am.lublin.pl (Lukasz Komsta)
Date: Fri, 19 Aug 2005 14:13:49 +0200
Subject: [R] Using lm coefficients in polyroot()
In-Reply-To: <loom.20050819T113415-591@post.gmane.org>
References: <43058A7F.6020505@novum.am.lublin.pl>
	<loom.20050819T113415-591@post.gmane.org>
Message-ID: <4305CCFD.3050903@novum.am.lublin.pl>

Dnia 2005-08-19 11:50, UÅ¼ytkownik Dieter Menne napisaÅ‚:


> Are you really sure you want to throw away lower order terms in a fit by 
> misusing stepAIC? With the rare exception of omitting a constant offset, I 
> don't know any case where there are good reasons to omit lower order terms in a 

I appreciate your will to prevent me from misusing stepAIC :), but I 
would like to perform some Monte-Carlo study of such case, these are not 
real-life data. Without the function, this study is not possible.

> For a more competent discussion of the matter, read Bill Venables
> 
> http://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf

I know it. Thank you again.

-- 
Lukasz Komsta
Department of Medicinal Chemistry
Medical University of Lublin
Jaczewskiego 4, 20-090 Lublin, Poland
Fax +48 81 7425165



From p.dalgaard at biostat.ku.dk  Fri Aug 19 14:16:42 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Aug 2005 14:16:42 +0200
Subject: [R] FFT, frequs, magnitudes, phases
In-Reply-To: <200508191238.42844.wolfgang.waser@rz.hu-berlin.de>
References: <200508191238.42844.wolfgang.waser@rz.hu-berlin.de>
Message-ID: <x264u22kb9.fsf@turmalin.kubism.ku.dk>

Wolfgang Waser <wolfgang.waser at rz.hu-berlin.de> writes:

> Hi,
> 
> I'm in dire need of a fast fourier transformation for me stupid biologist, 
> i.e. I have a heartbeat signal and would like to decompose it into pure sin 
> waves, getting three vectors, one containing the frequencies of the sin 
> waves, one the magnitudes and one the phases (that's what I get from my data 
> acquisition software's FFT function).
> I'd be very much obliged, if someone could point out which command would do 
> the job in R.

fft(), but notice that it gives the complex transform. You need to do
a little homework to get at the magnitude/phase values. (Basically,
you just have to take Mod() and Arg(), but there some conventions
about the frequencies and multipliers that one can get wrong).

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From stepanchuk at wiwi.uni-frankfurt.de  Fri Aug 19 14:24:25 2005
From: stepanchuk at wiwi.uni-frankfurt.de (Tetyana Stepanchuk)
Date: Fri, 19 Aug 2005 14:24:25 +0200
Subject: [R] How to create design matrix for LLMNL?
Message-ID: <20050819123019.69172A4C817@much-magic.wiwi.uni-frankfurt.de>

Hello, 

 

I have a small problem with developing design matrix X, which I use in
estimation the log-likelihood of a multinomial logit model.

 

I have the data: 

 number of observation - 289

number of choice alternative- 3

number of choice specific variables in matrix X -4

matrix X =289x4

I tried to use the function createX, I know that I have to get design matrix
289x12 (am I right?) but it always says "bad dim" (my code and data in
attachment)

 

Where is my fault? Can I use another method in order to create design
matrix? 

Or need it at all here in logmnl (see code in attachment)?

 

Can anyone help me with this issue?

 

Thanks in advance,

Tatyana

 

 

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: createX.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050819/0f1fb3ae/createX.txt
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: logmnl.txt
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050819/0f1fb3ae/logmnl.txt

From ggrothendieck at gmail.com  Fri Aug 19 14:25:00 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 19 Aug 2005 08:25:00 -0400
Subject: [R] Problem with get.hist.quote() in tseries
In-Reply-To: <20050819051720.GA13959@lubyanka.local>
References: <20050819051720.GA13959@lubyanka.local>
Message-ID: <971536df0508190525c7ffc3e@mail.gmail.com>

There is no head.ts and x[1:10,] has the side effect of converting
it from class ts to class matrix.   Use window 

  window(x, end = start(x)[1]+10)

instead or use 

  head(as.zoo(x)) 

since there is a head.zoo in the 'zoo' package.

On 8/19/05, Ajay Narottam Shah <ajayshah at mayin.org> wrote:
> When using get.hist.quote(), I find the dates are broken. This is with
> R 2.1.1 on Mac OS X `panther'.
> 
> > library(tseries)
> Loading required package: quadprog
> 
>    'tseries' version: 0.9-27
> 
>    'tseries' is a package for time series analysis and computational
>    finance.
> 
>    See 'library(help="tseries")' for details.
> 
> > x <- get.hist.quote("^VIX")
> trying URL 'http://chart.yahoo.com/table.csv?s=^VIX&a=0&b=02&c=1991&d=7&e=18&f=2005&g=d&q=q&y=0&z=^VIX&x=.csv'
> Content type 'text/csv' length unknown
> opened URL
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> .......... .......... .......... .......... ..........
> 
> downloaded 150Kb
> 
> > head(x)
> [1] 26.62 27.93 27.19    NA    NA 28.95
> > x[1:10,]
>       Open  High   Low Close
>  [1,] 26.62 26.62 26.62 26.62
>  [2,] 27.93 27.93 27.93 27.93
>  [3,] 27.19 27.19 27.19 27.19
>  [4,]    NA    NA    NA    NA
>  [5,]    NA    NA    NA    NA
>  [6,] 28.95 28.95 28.95 28.95
>  [7,] 30.38 30.38 30.38 30.38
>  [8,] 33.30 33.30 33.30 33.30
>  [9,] 31.33 31.33 31.33 31.33
> [10,] 32.63 32.63 32.63 32.63
> > plot(x)
>  (dates don't show).
> > str(x)
>  mts [1:5343, 1:4] 26.6 27.9 27.2   NA   NA ...
>  - attr(*, "dimnames")=List of 2
>  ..$ : NULL
>  ..$ : chr [1:4] "Open" "High" "Low" "Close"
>  - attr(*, "tsp")= num [1:3] 33240 38582     1
>  - attr(*, "class")= chr [1:2] "mts" "ts"
> 
> I wonder what I'm doing wrong.
> 
> --
> Ajay Shah                                                   Consultant
> ajayshah at mayin.org                      Department of Economic Affairs
> http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From gb at stat.umu.se  Fri Aug 19 14:42:43 2005
From: gb at stat.umu.se (=?iso-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Fri, 19 Aug 2005 14:42:43 +0200
Subject: [R] Handling dates
In-Reply-To: <x2acje2m7i.fsf@turmalin.kubism.ku.dk>
References: <20050819101410.GA29803@stat.umu.se>
	<x2acje2m7i.fsf@turmalin.kubism.ku.dk>
Message-ID: <20050819124243.GA9835@stat.umu.se>

On Fri, Aug 19, 2005 at 01:35:45PM +0200, Peter Dalgaard wrote:
> G??ran Brostr??m <gb at stat.umu.se> writes:
> 
> > I have a problem with some functions handling dates, in packages 'date' and 
> > 'survival' (they seem to be identical). For instance, from the documentation,
> > 
> > --------------------
> > mdy.date {survival}	
> > 
> > R Documentation
> > 
> > Convert to Julian Dates
> > 
> > Description
> > 
> > Given a month, day, and year, returns the number of days since January 1, 1960.
> > Usage
> > 
> > mdy.date(month, day, year, nineteen = TRUE, fillday = FALSE,
> >          fillmonth = FALSE)
> > ----------------------------
> > but
> > 
> > > library(survival)
> > > mdy.date(12, 1, 1977)
> > [1] 1Dec77
> > 
> > Similar strange results appear in other date-related functions. I plan to 
> > write functions that converts, eg, "1977-01-31" to the real number 1977.084
> > and back. What function in  R  does what 'mdy.date' claims to do?
> 
> mdy.date does ...
> 
> > dput(mdy.date(12, 1, 1977))
> structure(6544, class = "date")

Thanks, I should have remembered that what functions print and what they 
return can be quite different things. This one returns "Julian dates".  
Which can be seen under "Value". But isn't the Description a bit misleading?
> 
> > mdy.date(1, 31, 1977)/365.2425+1960 # or /365.25 if you really want 1977.084
> [1] 1977.085

What I want is that the the fraction (0.084) should be equal to the fraction 
of the full year 1977 that is spent between 1977-01-01, at 00:00:00 and
1977-01-31, at noon. I know how to do it now.

Thanks again, G??ran

> But with recent R's, as.Date is a better bet:
> 
> 
> > c(as.Date("1977-01-31") - as.Date("0000-01-01"))/365.2425
> [1] 1977.084
> 
> (notice that you need the c() to avoid the nonsense of
> 
> > (as.Date("1977-01-31") - as.Date("0000-01-01"))/365.2425
> Time difference of 1977.084 days
> 
> )
> 
> 
> -- 
>    O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From mostafa.ghaderi at inw.agrl.ethz.ch  Fri Aug 19 14:56:39 2005
From: mostafa.ghaderi at inw.agrl.ethz.ch (Mostafa Ghaderi)
Date: Fri, 19 Aug 2005 14:56:39 +0200
Subject: [R] tackle with error
Message-ID: <4305D707.7020407@inw.agrl.ethz.ch>

Dear sir;
may you drop me some idea how can i get rid of following error message:
Error in switch(nmeth, { : NA/NaN/Inf in foreign function call (arg 1)
i dont know what does nmeth and ther rest of error message mean? i have 
a file which contains 460 rows and 174 columns including missing value 
as NA.

Regards,
Mostafa



From dieter.menne at menne-biomed.de  Fri Aug 19 15:10:00 2005
From: dieter.menne at menne-biomed.de (Dieter Menne)
Date: Fri, 19 Aug 2005 13:10:00 +0000 (UTC)
Subject: [R] tackle with error
References: <4305D707.7020407@inw.agrl.ethz.ch>
Message-ID: <loom.20050819T150557-994@post.gmane.org>

Mostafa Ghaderi <mostafa.ghaderi <at> inw.agrl.ethz.ch> writes:

> may you drop me some idea how can i get rid of following error message:
> Error in switch(nmeth, { : NA/NaN/Inf in foreign function call (arg 1)
> i dont know what does nmeth and ther rest of error message mean? i have 
> a file which contains 460 rows and 174 columns including missing value 
> as NA.

I assume that you are using R on some silicon-based electric circuit, but 
that's about all I can guess to understand the error message. In what command 
did it occur? Possibly "read.table"? And try 

  traceback()

after the error message. And if it is during read-in of data, shorten your file 
to 3 lines and try again.

Dieter



From ripley at stats.ox.ac.uk  Fri Aug 19 15:39:03 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Aug 2005 14:39:03 +0100 (BST)
Subject: [R] kmenas does not accept NAs (was tackle with error)
In-Reply-To: <4305D707.7020407@inw.agrl.ethz.ch>
References: <4305D707.7020407@inw.agrl.ethz.ch>
Message-ID: <Pine.LNX.4.61.0508191435330.5877@gannet.stats>

On Fri, 19 Aug 2005, Mostafa Ghaderi wrote:

> may you drop me some idea how can i get rid of following error message:
> Error in switch(nmeth, { : NA/NaN/Inf in foreign function call (arg 1)
> i dont know what does nmeth and ther rest of error message mean? i have
> a file which contains 460 rows and 174 columns including missing value
> as NA.

> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Please do read it carefully.

You have not told us what you are doing, nor provided a reproducible 
example.  Using traceback() will tell you where the error message is 
coming from.

Some searching suggests you are using kmeans().  If you have matrix with 
missing values which you pass to kmeans, this is what you will get.  It 
does not accept missing values, so you will have to decide what to do 
about them.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From charles.edwin.white at us.army.mil  Fri Aug 19 15:59:41 2005
From: charles.edwin.white at us.army.mil (White, Charles E WRAIR-Wash DC)
Date: Fri, 19 Aug 2005 09:59:41 -0400
Subject: [R] Installing R in Fedora Core 4
Message-ID: <8BAEC5E546879B4FAA536200A292C6148353AC@AMEDMLNARMC135.amed.ds.army.mil>

R is included in Fedora Extras. You can skip downloading Extras and updating the packages on the CD by using:

yum index | grep R

and installing the half dozen or so individual packages that will be listed.  The number of packages may be mildly annoying but if you install this way you will be notified of R updates along with all of your other security and application updates through the Red Hat Network.

Chuck

Charles E. White, Senior Biostatistician, MS
Walter Reed Army Institute of Research
503 Robert Grant Ave., Room 1w102
Silver Spring, MD 20910-1557
301 319-9781
Personal/Professional Site:??http://users.starpower.net/cwhite571/professional/



From dmbates at gmail.com  Fri Aug 19 16:12:40 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Fri, 19 Aug 2005 09:12:40 -0500
Subject: [R] How to put factor variables in an nls formula ?
In-Reply-To: <6.1.1.1.0.20050818161038.01e59270@Fagus.Engref.Fr>
References: <6.1.1.1.0.20050818161038.01e59270@Fagus.Engref.Fr>
Message-ID: <40e66e0b050819071268f1df7b@mail.gmail.com>

On 8/18/05, François Morneau <francois.morneau at cirad.fr> wrote:
> Hello,
> 
> I want to fit a Gompertz model for tree diameter growth that depends on a 4
> levels edaphic factor ('Drain') and I don't manage to introduce the factor
> variable in the formula.
> Dinc is the annual diameter increment and D is the Diameter.
> 
>  >treestab
>  >     Dinc     D      Drain
>   [1,]  0.03  26.10     2
>   [2,]  0.04  13.05     1
>   [3,]  0.00  24.83     1
>   [4,]  0.00  15.92     4
>   [5,]  0.00  12.25     4
>   [6,]  0.00  11.78     4
>   [7,]  0.00  16.87     4
>   [8,]  0.00  15.12     4
>   [9,] -0.01  13.53     4
> [10,] 0.04  16.55     3
> [11,] 0.025 16.07     3
> [12,] 0.00  30.24     3
> [13,] 0.06  15.28     2
> etc…
>  >contrasts(Drain)<-contr.sum(4)
>  >mymodel<-nls(Dinc~r*(1+Drain)*D*log(Asym/D), data=treestab, start(r=0.05,
> Asym=40))
> 
> Error in numericDeriv(form[[3]], names(ind), env) :
>          Missing value or an infinity produced when evaluating the model
> In addition: Warning messages:
> 1: + not meaningful for factors in: Ops.factor(1, Drain)
> 2: + not meaningful for factors in: Ops.factor(1, Drain)

It is not clear to me what you are trying to do.  Can you give us a
bit more information such as how many parameter estimates you expect
to obtain and what they would represent?

> 
> Do I need to use another function instead of nls to correctly include the
> factor 'Drain' ?
> 
> Thanks,
> 
> François
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From gavin.simpson at ucl.ac.uk  Fri Aug 19 16:35:55 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 19 Aug 2005 15:35:55 +0100
Subject: [R] Installing R in Fedora Core 4
In-Reply-To: <8BAEC5E546879B4FAA536200A292C6148353AC@AMEDMLNARMC135.amed.ds.army.mil>
References: <8BAEC5E546879B4FAA536200A292C6148353AC@AMEDMLNARMC135.amed.ds.army.mil>
Message-ID: <1124462155.31394.53.camel@gsimpson.geog.ucl.ac.uk>

On Fri, 2005-08-19 at 09:59 -0400, White, Charles E WRAIR-Wash DC wrote:
> R is included in Fedora Extras. You can skip downloading Extras and
> updating the packages on the CD by using:
> 
> yum index | grep R
> 
> and installing the half dozen or so individual packages that will be
> listed.  The number of packages may be mildly annoying but if you
> install this way you will be notified of R updates along with all of
> your other security and application updates through the Red Hat
> Network.
> 
> Chuck
> 

Peter Dalgaard has noted, on the R-Devel list (sorry I can't provide the
link to the mail - the link from the R site to the mail archives wasn't
working when I tried), that there are problems with the R rpm from
Fedora Extras, including a strange printing bug. I believe Peter now
thinks this is a bug in R (seem to have deleted that post - doh) exposed
by the compilation flags used by the maintainer of the Fedora Extras
rpm.

If you want and rpm to install, then Martyn Plummer provides R binaries
for Red Hat / Fedora systems that are available from CRAN e.g: for FC4
http://www.stats.bris.ac.uk/R/bin/linux/redhat/fc4/

Martyn has also made these available via a yum-compatible repository, so
the benefits you note of auto-notification of updates etc. apply here as
well.

HTH

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From roger.bos at gmail.com  Fri Aug 19 16:46:44 2005
From: roger.bos at gmail.com (roger bos)
Date: Fri, 19 Aug 2005 10:46:44 -0400
Subject: [R] using paste and "\" to create a valid filename
Message-ID: <1db7268005081907462efc78bb@mail.gmail.com>

Sometimes even the easy stuff is difficult (for me)... I want to get
input from different places to paste together an excel filename (so
you know I'm using windows) that I can open with RODBC.  I know about
using double "\" since its an escape character, but I get either 2 or
none, I can't get just one "\" where I need it.  See example code
below.  I am using R 2.1.0, but plan to upgrade soon.  Thanks in
advance to anyone who can help.

Roger


rankPath <- "R:\New Ranks\SMC\SMC"				
rankDate <- "20050819"				
rankFile <- paste(rankPath,rankDate,".xls", sep="")
rankFile
[1] "R:New RanksSMCSMC20050819.xls"


rankPath <- "R:\\New Ranks\\SMC\\SMC"				
rankDate <- "20050819"				
rankFile <- paste(rankPath,rankDate,".xls", sep="")
rankFile
[1] "R:\\New Ranks\\SMC\\SMC20050819.xls"



From daniel at sintesys.com.ar  Fri Aug 19 16:54:54 2005
From: daniel at sintesys.com.ar (Daniel)
Date: Fri, 19 Aug 2005 11:54:54 -0300
Subject: [R] ridge regression
Message-ID: <004101c5a4cd$f5a4db00$fc00a8c0@escritorio>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050819/2da6faca/attachment.pl

From ligges at statistik.uni-dortmund.de  Fri Aug 19 17:04:20 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 19 Aug 2005 17:04:20 +0200
Subject: [R] using paste and "\" to create a valid filename
In-Reply-To: <1db7268005081907462efc78bb@mail.gmail.com>
References: <1db7268005081907462efc78bb@mail.gmail.com>
Message-ID: <4305F4F4.5090008@statistik.uni-dortmund.de>

roger bos wrote:

> Sometimes even the easy stuff is difficult (for me)... I want to get
> input from different places to paste together an excel filename (so
> you know I'm using windows) that I can open with RODBC.  I know about
> using double "\" since its an escape character, but I get either 2 or
> none, I can't get just one "\" where I need it.  See example code
> below.  I am using R 2.1.0, but plan to upgrade soon.  Thanks in
> advance to anyone who can help.
> 
> Roger
> 
> 
> rankPath <- "R:\New Ranks\SMC\SMC"				
> rankDate <- "20050819"				
> rankFile <- paste(rankPath,rankDate,".xls", sep="")
> rankFile
> [1] "R:New RanksSMCSMC20050819.xls"
> 
> 
> rankPath <- "R:\\New Ranks\\SMC\\SMC"				
> rankDate <- "20050819"				
> rankFile <- paste(rankPath,rankDate,".xls", sep="")
> rankFile
> [1] "R:\\New Ranks\\SMC\\SMC20050819.xls"


This is perfect, "\" is *printed* escaped, hence for file access you can 
perfectly use this character vector.

Uwe Ligges


> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From charles.edwin.white at us.army.mil  Fri Aug 19 17:07:59 2005
From: charles.edwin.white at us.army.mil (White, Charles E WRAIR-Wash DC)
Date: Fri, 19 Aug 2005 11:07:59 -0400
Subject: [R] Installing R in Fedora Core 4
Message-ID: <8BAEC5E546879B4FAA536200A292C6148353EB@AMEDMLNARMC135.amed.ds.army.mil>

-----Original Message-----
On Fri, 8/19, Gavin Simpson wrote:
Peter Dalgaard has noted, on the R-Devel list (sorry I can't provide the
link to the mail - the link from the R site to the mail archives wasn't
working when I tried), that there are problems with the R rpm from
Fedora Extras, including a strange printing bug. I believe Peter now
thinks this is a bug in R (seem to have deleted that post - doh) exposed
by the compilation flags used by the maintainer of the Fedora Extras
rpm.

If you want and rpm to install, then Martyn Plummer provides R binaries
for Red Hat / Fedora systems that are available from CRAN e.g: for FC4
http://www.stats.bris.ac.uk/R/bin/linux/redhat/fc4/

Martyn has also made these available via a yum-compatible repository, so
the benefits you note of auto-notification of updates etc. apply here as
well.

HTH

G
-----End Original Message-----

The last time I tried to use the Martyn Plummer RPMs they were compiled
without enabling shared libraries and I ended up compiling R myself so
that I could use JGR. Messages describing the problem with the version
actually on the Extras CD were my other unstated reason for describing
yum instead of downloading the CD. I haven't heard there is a problem
with Fedora's new RPMs but that doesn't prove that there aren't any. I
fully agree with Martyn Plummer's readme notice that describes Fedora
Core as bleeding edge technology not to be trusted for production use.
Fedora Core describes itself that way.



From gunter.berton at gene.com  Fri Aug 19 17:11:33 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 19 Aug 2005 08:11:33 -0700
Subject: [R] using paste and "\" to create a valid filename
In-Reply-To: <4305F4F4.5090008@statistik.uni-dortmund.de>
Message-ID: <200508191511.j7JFBXAg016788@faraday.gene.com>

... and you can see that the "\\" is correct by cat(rankFile) instead of
print(rankFile), which is what entering the variable at the prompt actually
does.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Uwe Ligges
> Sent: Friday, August 19, 2005 8:04 AM
> To: roger bos
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] using paste and "\" to create a valid filename
> 
> roger bos wrote:
> 
> > Sometimes even the easy stuff is difficult (for me)... I want to get
> > input from different places to paste together an excel filename (so
> > you know I'm using windows) that I can open with RODBC.  I 
> know about
> > using double "\" since its an escape character, but I get 
> either 2 or
> > none, I can't get just one "\" where I need it.  See example code
> > below.  I am using R 2.1.0, but plan to upgrade soon.  Thanks in
> > advance to anyone who can help.
> > 
> > Roger
> > 
> > 
> > rankPath <- "R:\New Ranks\SMC\SMC"				
> > rankDate <- "20050819"				
> > rankFile <- paste(rankPath,rankDate,".xls", sep="")
> > rankFile
> > [1] "R:New RanksSMCSMC20050819.xls"
> > 
> > 
> > rankPath <- "R:\\New Ranks\\SMC\\SMC"				
> > rankDate <- "20050819"				
> > rankFile <- paste(rankPath,rankDate,".xls", sep="")
> > rankFile
> > [1] "R:\\New Ranks\\SMC\\SMC20050819.xls"
> 
> 
> This is perfect, "\" is *printed* escaped, hence for file 
> access you can 
> perfectly use this character vector.
> 
> Uwe Ligges
> 
> 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From edd at debian.org  Fri Aug 19 17:08:40 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 19 Aug 2005 15:08:40 +0000 (UTC)
Subject: [R] using paste and
References: <1db7268005081907462efc78bb@mail.gmail.com>
Message-ID: <loom.20050819T170440-661@post.gmane.org>

roger bos <roger.bos <at> gmail.com> writes:
> Sometimes even the easy stuff is difficult (for me)... I want to get
> input from different places to paste together an excel filename (so

Have you considered 
  a) the file.path() function,
  b) the fact that forward slashes also work on Windoze?

Your first example, with an outer paste() for the suffix:

> paste(file.path("R:", "New Ranks", "SMC", "SMC", "20050819"), ".xls", sep="")
[1] "R:/New Ranks/SMC/SMC/20050819.xls"
> 

Hth, Dirk



From roger.bos at gmail.com  Fri Aug 19 17:14:03 2005
From: roger.bos at gmail.com (roger bos)
Date: Fri, 19 Aug 2005 11:14:03 -0400
Subject: [R] using paste and "\" to create a valid filename
In-Reply-To: <4305F4F4.5090008@statistik.uni-dortmund.de>
References: <1db7268005081907462efc78bb@mail.gmail.com>
	<4305F4F4.5090008@statistik.uni-dortmund.de>
Message-ID: <1db72680050819081439b18f46@mail.gmail.com>

I was surprise myself that I was having problems, because I have been
doing this for ahile, but I get erros with the RODBC connection.  For
example,

rankFile <- paste("R:\\New Ranks\\SMC\\SMC\\",rankDate,".xls", sep="")				
			rankFile
			xls <- odbcConnectExcel(rankFile)
			xls
			rankFile <- "R:\New Ranks\SMC\SMC\20050818.xls"			
			rankFile
			xls <- odbcConnectExcel(rankFile)
			xls


You won't have my filename, but feel free to try it with any excel
file you may have. Here is the R output.


> rankFile <- paste("R:\\New Ranks\\SMC\\SMC\\",rankDate,".xls", sep="")
> rankFile
[1] "R:\\New Ranks\\SMC\\SMC\\20050819.xls"
> xls <- odbcConnectExcel(rankFile)
Warning messages:
1: [RODBC] ERROR: Could not SQLDriverConnect 
2: ODBC connection failed in: odbcDriverConnect(con) 
> xls
[1] -1
> rankFile <- "R:\New Ranks\SMC\SMC\20050818.xls"
> rankFile
[1] "R:New RanksSMCSMC?50818.xls"
> xls <- odbcConnectExcel(rankFile)
> xls
RODB Connection 15
Details:
  case=nochange
  DBQ=R:New RanksSMCSMC?50818.xls
  DefaultDir=R:\NEW RANKS\SMC
  Driver={Microsoft Excel Driver (*.xls)}
  DriverId=790
  MaxBufferSize=2048
  PageTimeout=5
> 

On 8/19/05, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> roger bos wrote:
> 
> > Sometimes even the easy stuff is difficult (for me)... I want to get
> > input from different places to paste together an excel filename (so
> > you know I'm using windows) that I can open with RODBC.  I know about
> > using double "\" since its an escape character, but I get either 2 or
> > none, I can't get just one "\" where I need it.  See example code
> > below.  I am using R 2.1.0, but plan to upgrade soon.  Thanks in
> > advance to anyone who can help.
> >
> > Roger
> >
> >
> > rankPath <- "R:\New Ranks\SMC\SMC"
> > rankDate <- "20050819"
> > rankFile <- paste(rankPath,rankDate,".xls", sep="")
> > rankFile
> > [1] "R:New RanksSMCSMC20050819.xls"
> >
> >
> > rankPath <- "R:\\New Ranks\\SMC\\SMC"
> > rankDate <- "20050819"
> > rankFile <- paste(rankPath,rankDate,".xls", sep="")
> > rankFile
> > [1] "R:\\New Ranks\\SMC\\SMC20050819.xls"
> 
> 
> This is perfect, "\" is *printed* escaped, hence for file access you can
> perfectly use this character vector.
> 
> Uwe Ligges
> 
> 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From jgentry at jimmy.harvard.edu  Fri Aug 19 17:17:41 2005
From: jgentry at jimmy.harvard.edu (Jeff Gentry)
Date: Fri, 19 Aug 2005 11:17:41 -0400 (EDT)
Subject: [R] using paste and "\" to create a valid filename
In-Reply-To: <1db7268005081907462efc78bb@mail.gmail.com>
Message-ID: <Pine.SOL.4.20.0508191116280.24289-100000@santiam.dfci.harvard.edu>

> Sometimes even the easy stuff is difficult (for me)... I want to get
> input from different places to paste together an excel filename (so
> you know I'm using windows) that I can open with RODBC.  I know about

Using file.path() might be an easier solution for this (and it will allow
your code to work in a cross-platform manner)



From ligges at statistik.uni-dortmund.de  Fri Aug 19 17:22:13 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 19 Aug 2005 17:22:13 +0200
Subject: [R] using paste and "\" to create a valid filename
In-Reply-To: <1db72680050819081439b18f46@mail.gmail.com>
References: <1db7268005081907462efc78bb@mail.gmail.com>	
	<4305F4F4.5090008@statistik.uni-dortmund.de>
	<1db72680050819081439b18f46@mail.gmail.com>
Message-ID: <4305F925.6050506@statistik.uni-dortmund.de>

Don't know about the details with RODBC here, why not just use forward 
slashes as in (used it in all of my courses and never tried "\\" 
before....):

rankFile <- paste("R:/New Ranks/SMC/SMC/", rankDate, ".xls", sep="")		

Uwe Ligges


roger bos wrote:

> I was surprise myself that I was having problems, because I have been
> doing this for ahile, but I get erros with the RODBC connection.  For
> example,
> 
> rankFile <- paste("R:\\New Ranks\\SMC\\SMC\\",rankDate,".xls", sep="")				
> 			rankFile
> 			xls <- odbcConnectExcel(rankFile)
> 			xls
> 			rankFile <- "R:\New Ranks\SMC\SMC\20050818.xls"			
> 			rankFile
> 			xls <- odbcConnectExcel(rankFile)
> 			xls
> 
> 
> You won't have my filename, but feel free to try it with any excel
> file you may have. Here is the R output.
> 
> 
> 
>>rankFile <- paste("R:\\New Ranks\\SMC\\SMC\\",rankDate,".xls", sep="")
>>rankFile
> 
> [1] "R:\\New Ranks\\SMC\\SMC\\20050819.xls"
> 
>>xls <- odbcConnectExcel(rankFile)
> 
> Warning messages:
> 1: [RODBC] ERROR: Could not SQLDriverConnect 
> 2: ODBC connection failed in: odbcDriverConnect(con) 
> 
>>xls
> 
> [1] -1
> 
>>rankFile <- "R:\New Ranks\SMC\SMC\20050818.xls"
>>rankFile
> 
> [1] "R:New RanksSMCSMC?50818.xls"
> 
>>xls <- odbcConnectExcel(rankFile)
>>xls
> 
> RODB Connection 15
> Details:
>   case=nochange
>   DBQ=R:New RanksSMCSMC?50818.xls
>   DefaultDir=R:\NEW RANKS\SMC
>   Driver={Microsoft Excel Driver (*.xls)}
>   DriverId=790
>   MaxBufferSize=2048
>   PageTimeout=5
> 
> 
> On 8/19/05, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> 
>>roger bos wrote:
>>
>>
>>>Sometimes even the easy stuff is difficult (for me)... I want to get
>>>input from different places to paste together an excel filename (so
>>>you know I'm using windows) that I can open with RODBC.  I know about
>>>using double "\" since its an escape character, but I get either 2 or
>>>none, I can't get just one "\" where I need it.  See example code
>>>below.  I am using R 2.1.0, but plan to upgrade soon.  Thanks in
>>>advance to anyone who can help.
>>>
>>>Roger
>>>
>>>
>>>rankPath <- "R:\New Ranks\SMC\SMC"
>>>rankDate <- "20050819"
>>>rankFile <- paste(rankPath,rankDate,".xls", sep="")
>>>rankFile
>>>[1] "R:New RanksSMCSMC20050819.xls"
>>>
>>>
>>>rankPath <- "R:\\New Ranks\\SMC\\SMC"
>>>rankDate <- "20050819"
>>>rankFile <- paste(rankPath,rankDate,".xls", sep="")
>>>rankFile
>>>[1] "R:\\New Ranks\\SMC\\SMC20050819.xls"
>>
>>
>>This is perfect, "\" is *printed* escaped, hence for file access you can
>>perfectly use this character vector.
>>
>>Uwe Ligges
>>
>>
>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>



From roger.bos at gmail.com  Fri Aug 19 17:30:47 2005
From: roger.bos at gmail.com (roger bos)
Date: Fri, 19 Aug 2005 11:30:47 -0400
Subject: [R] using paste and "\" to create a valid filename
In-Reply-To: <4305F925.6050506@statistik.uni-dortmund.de>
References: <1db7268005081907462efc78bb@mail.gmail.com>
	<4305F4F4.5090008@statistik.uni-dortmund.de>
	<1db72680050819081439b18f46@mail.gmail.com>
	<4305F925.6050506@statistik.uni-dortmund.de>
Message-ID: <1db726800508190830343653d5@mail.gmail.com>

Thanks Uwe for the forward slash suggestion, that worked.  I believe
something has changed inside the RODBC package, because I ran the
following code this morning to update my packages:

x <- packageStatus(repositories="http://cran.r-project.org/src/contrib")
st <- x$avai["Status"]
install.packages(rownames(st)[which(st$Status=="not installed")])

I don't know if RODBC was updated and I am not even sure how to find
out, but my old code works on my machine I didn't update and doesn't
work on the machine I did update.  I am not confident enough to file a
bug report, but I know something has changed.  I will use the forward
slash as a workaround for now.

Thanks again to everyone,  Roger


On 8/19/05, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> Don't know about the details with RODBC here, why not just use forward
> slashes as in (used it in all of my courses and never tried "\\"
> before....):
> 
> rankFile <- paste("R:/New Ranks/SMC/SMC/", rankDate, ".xls", sep="")
> 
> Uwe Ligges
> 
> 
> roger bos wrote:
> 
> > I was surprise myself that I was having problems, because I have been
> > doing this for ahile, but I get erros with the RODBC connection.  For
> > example,
> >
> > rankFile <- paste("R:\\New Ranks\\SMC\\SMC\\",rankDate,".xls", sep="")
> >                       rankFile
> >                       xls <- odbcConnectExcel(rankFile)
> >                       xls
> >                       rankFile <- "R:\New Ranks\SMC\SMC\20050818.xls"
> >                       rankFile
> >                       xls <- odbcConnectExcel(rankFile)
> >                       xls
> >
> >
> > You won't have my filename, but feel free to try it with any excel
> > file you may have. Here is the R output.
> >
> >
> >
> >>rankFile <- paste("R:\\New Ranks\\SMC\\SMC\\",rankDate,".xls", sep="")
> >>rankFile
> >
> > [1] "R:\\New Ranks\\SMC\\SMC\\20050819.xls"
> >
> >>xls <- odbcConnectExcel(rankFile)
> >
> > Warning messages:
> > 1: [RODBC] ERROR: Could not SQLDriverConnect
> > 2: ODBC connection failed in: odbcDriverConnect(con)
> >
> >>xls
> >
> > [1] -1
> >
> >>rankFile <- "R:\New Ranks\SMC\SMC\20050818.xls"
> >>rankFile
> >
> > [1] "R:New RanksSMCSMC?50818.xls"
> >
> >>xls <- odbcConnectExcel(rankFile)
> >>xls
> >
> > RODB Connection 15
> > Details:
> >   case=nochange
> >   DBQ=R:New RanksSMCSMC?50818.xls
> >   DefaultDir=R:\NEW RANKS\SMC
> >   Driver={Microsoft Excel Driver (*.xls)}
> >   DriverId=790
> >   MaxBufferSize=2048
> >   PageTimeout=5
> >
> >
> > On 8/19/05, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
> >
> >>roger bos wrote:
> >>
> >>
> >>>Sometimes even the easy stuff is difficult (for me)... I want to get
> >>>input from different places to paste together an excel filename (so
> >>>you know I'm using windows) that I can open with RODBC.  I know about
> >>>using double "\" since its an escape character, but I get either 2 or
> >>>none, I can't get just one "\" where I need it.  See example code
> >>>below.  I am using R 2.1.0, but plan to upgrade soon.  Thanks in
> >>>advance to anyone who can help.
> >>>
> >>>Roger
> >>>
> >>>
> >>>rankPath <- "R:\New Ranks\SMC\SMC"
> >>>rankDate <- "20050819"
> >>>rankFile <- paste(rankPath,rankDate,".xls", sep="")
> >>>rankFile
> >>>[1] "R:New RanksSMCSMC20050819.xls"
> >>>
> >>>
> >>>rankPath <- "R:\\New Ranks\\SMC\\SMC"
> >>>rankDate <- "20050819"
> >>>rankFile <- paste(rankPath,rankDate,".xls", sep="")
> >>>rankFile
> >>>[1] "R:\\New Ranks\\SMC\\SMC20050819.xls"
> >>
> >>
> >>This is perfect, "\" is *printed* escaped, hence for file access you can
> >>perfectly use this character vector.
> >>
> >>Uwe Ligges
> >>
> >>
> >>
> >>>______________________________________________
> >>>R-help at stat.math.ethz.ch mailing list
> >>>https://stat.ethz.ch/mailman/listinfo/r-help
> >>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >>
> >>
> 
>



From tpcl at tci.ufal.br  Thu Aug 18 23:06:59 2005
From: tpcl at tci.ufal.br (Talita Perciano Costa Leite)
Date: Thu, 18 Aug 2005 18:06:59 -0300
Subject: [R] Unload a library
Message-ID: <1124399219.4304f873b3315@www.ufal.br>

Hi people,

I'm developing an application (in Linux) using tcltk and calling ggobi from that
application (using the Rggobi package). After I load ggobi and want to use the
windows made by tcltk I get some errors and sometimes R cracks. I believe the
problem is because the packages Rggobi, RGtk and tcltk are running together. I
thought about a solution that would be unload the Rggobi and RGtk packages after
I use them. Do you know how I do that? And if someone has another solution for
that problem please help me.

Thanx,

Talita Leite


-------------------------------------------------
Este e-mail foi enviado pelo Webmail da UFAL
IMP: http://horde.org/imp/



From gavin.simpson at ucl.ac.uk  Fri Aug 19 17:55:44 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 19 Aug 2005 16:55:44 +0100
Subject: [R] Installing R in Fedora Core 4
In-Reply-To: <8BAEC5E546879B4FAA536200A292C6148353EB@AMEDMLNARMC135.amed.ds.army.mil>
References: <8BAEC5E546879B4FAA536200A292C6148353EB@AMEDMLNARMC135.amed.ds.army.mil>
Message-ID: <1124466944.31394.77.camel@gsimpson.geog.ucl.ac.uk>

On Fri, 2005-08-19 at 11:07 -0400, White, Charles E WRAIR-Wash DC wrote:
> -----Original Message-----
> On Fri, 8/19, Gavin Simpson wrote:
> Peter Dalgaard has noted, on the R-Devel list (sorry I can't provide the
> link to the mail - the link from the R site to the mail archives wasn't
> working when I tried), that there are problems with the R rpm from
> Fedora Extras, including a strange printing bug. I believe Peter now
> thinks this is a bug in R (seem to have deleted that post - doh) exposed
> by the compilation flags used by the maintainer of the Fedora Extras
> rpm.
> 
> If you want and rpm to install, then Martyn Plummer provides R binaries
> for Red Hat / Fedora systems that are available from CRAN e.g: for FC4
> http://www.stats.bris.ac.uk/R/bin/linux/redhat/fc4/
> 
> Martyn has also made these available via a yum-compatible repository, so
> the benefits you note of auto-notification of updates etc. apply here as
> well.
> 
> HTH
> 
> G
> -----End Original Message-----
> 
> The last time I tried to use the Martyn Plummer RPMs they were compiled
> without enabling shared libraries and I ended up compiling R myself so
> that I could use JGR. Messages describing the problem with the version
> actually on the Extras CD were my other unstated reason for describing
> yum instead of downloading the CD. I haven't heard there is a problem
> with Fedora's new RPMs but that doesn't prove that there aren't any. I
> fully agree with Martyn Plummer's readme notice that describes Fedora
> Core as bleeding edge technology not to be trusted for production use.
> Fedora Core describes itself that way.

Do you mean the shared library libR.so? If so, the README in the FC3
section indicates that these rpms now include the functionality you
require. The absence of a README in the FC4 section means it is not
clear from there if these rpms are also compiled with the shared
library.

>From Peter's email, it would seem that the maintainer of the R rpm for
Extras continues to use the compiler flags that cause the problems
previously described (I haven't confirmed that this is still the case
mind you).

Although FC4 is bleeding edge, I've had very few problems with in on my
new laptop or my home desktop - after initial gcc v4.0.0 and gfortran
teething troubles that is.

HTH

G
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From tlumley at u.washington.edu  Fri Aug 19 18:07:30 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 19 Aug 2005 09:07:30 -0700 (PDT)
Subject: [R] Handling of tables in R
In-Reply-To: <OF05FD1F41.C07A8D9F-ONC1257062.002B7B4D-C1257062.002DA673@codan.dk>
References: <OF05FD1F41.C07A8D9F-ONC1257062.002B7B4D-C1257062.002DA673@codan.dk>
Message-ID: <Pine.A41.4.61b.0508190906260.84232@homer10.u.washington.edu>

On Fri, 19 Aug 2005, Fredrik Thuring wrote:
>        I have a few questions concerning reading of tables from R to
> other programs. My main question is if itâ€™s even possible to read a table
> created in R (with the functions data.frame     and save) to Excel (or
> maybe SAS) and if so how does one do this? If I just mark the table in R
> and copy-paste to Excel the whole table ends up in one single cell, (of
> course).        My goal is to copy the table to Excel (or SAS) in such a
> way that a single observation gets placed in a single cell.
>

People have told you how to do this for Excel. For SAS you might want to 
try write.foreign() in the "foreign" package, which writes a text file and 
a SAS code file that you can use to read it into SAS.

 	-thomas

From ripley at stats.ox.ac.uk  Fri Aug 19 18:08:36 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Aug 2005 17:08:36 +0100 (BST)
Subject: [R] Summary: Unexpected result of read.dbf
In-Reply-To: <20050819193255.10a97bc0.stanimura-ngs@umin.ac.jp>
References: <20050819193255.10a97bc0.stanimura-ngs@umin.ac.jp>
Message-ID: <Pine.LNX.4.61.0508191659260.7515@gannet.stats>

It really isn't clear that this is correct.  The reason is correct: 
read.dbf treats numeric files with no decimals as integers, and that _is_ 
as stated on the help page.  So it is definitely not a `bug', and reading 
the help would have shown the reason for the original question.
[I in general do not reply to questions that can be answered from the help 
page.]

I believe this field has been incorrectly coded as numeric, as it seems to 
be a factor ('keycode').  In particular, 19 is not a valid field size for 
a numeric field.

If one wants to allow this, I think we have to use double for a field in 
which any value is not representable as an integer, and not just if the 
field size exceeds 9.  I have been working on implementing that.

On Fri, 19 Aug 2005, Susumu Tanimura wrote:

> Hi there,
>
> This is summary and patch for a bug in read.dbf, demonstrating in
> Message-Id: <20050818150446.697835cb.stanimura-ngs at umin.ac.jp>.
>
> After consulting Rjpwiki, a cyber-community of R user in Japan, the
> cause was found, and the patch of solution was proposed.
>
> Overflowing occurs when we use read.dbf for reading a dbf file having
> a field of longer signed integer. For example,
>
> $ dbf2txt test.dbf
> #KEYCODE
> 422010010
> 42201002101
> 42201002102
> 42201002103
> 42201002104
> 422010060
> 422010071
> 422010072
> 42201008001
> 42201008002
>
> The KEYCODE field is numeric type, 19 digits, and no decimal.  You can
> create this file with OpenOffice.org Calc, txt2dbf, and so on.  You
> also prepare a file of CSV format.
>
>> library(foreign)
> > cbind(read.csv("test.csv"),read.dbf("test.dbf"))
>        KEYCODE   KEYCODE
> 1    422010010 422010010
> 2  42201002101        NA
> 3  42201002102        NA
> 4  42201002103        NA
> 5  42201002104        NA
> 6    422010060 422010060
> 7    422010071 422010071
> 8    422010072 422010072
> 9  42201008001        NA
> 10 42201008002        NA
>
> This is not reproducible when the field has decimals like numeric
> type, 19 digits, and 5 decimals.
>
> The patch written of Mr. Eiji Nakama is followed.
>
> --- foreign.orig/src/dbfopen.c  2005-08-19 18:54:06.000000000 +0900
> +++ foreign/src/dbfopen.c       2005-08-19 18:58:06.000000000 +0900
> @@ -970,7 +970,8 @@
>              || psDBF->pachFieldType[iField] == 'F' )
>        /* || psDBF->pachFieldType[iField] == 'D' ) D is Date */
>     {
> -       if( psDBF->panFieldDecimals[iField] > 0 )
> +       if( psDBF->panFieldDecimals[iField] > 0 ||
> +               psDBF->panFieldSize[iField] > 9 )
>            return( FTDouble );
>        else
>            return( FTInteger );
>
> After adopting the patch, read.dbf works correctly.
>
>> cbind(read.csv("test.csv"),read.dbf("test.dbf"))
>       KEYCODE     KEYCODE
> 1    422010010   422010010
> 2  42201002101 42201002101
> 3  42201002102 42201002102
> 4  42201002103 42201002103
> 5  42201002104 42201002104
> 6    422010060   422010060
> 7    422010071   422010071
> 8    422010072   422010072
> 9  42201008001 42201008001
> 10 42201008002 42201008002
>
> --
> Susumu Tanimura
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Fri Aug 19 18:15:35 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 19 Aug 2005 09:15:35 -0700 (PDT)
Subject: [R] Handling dates
In-Reply-To: <20050819101410.GA29803@stat.umu.se>
References: <20050819101410.GA29803@stat.umu.se>
Message-ID: <Pine.A41.4.61b.0508190912380.84232@homer10.u.washington.edu>

On Fri, 19 Aug 2005, [iso-8859-1] Göran Broström wrote:
>
> Similar strange results appear in other date-related functions. I plan to
> write functions that converts, eg, "1977-01-31" to the real number 1977.084
> and back. What function in  R  does what 'mdy.date' claims to do?
>

Well, mdy.date does (the result *prints* as a date, but works in numerical 
operations).  Eg
> 1970+ mdy.date(12,1,1977)/365.25
[1] 1987.916



 	-thomas

From ligges at statistik.uni-dortmund.de  Fri Aug 19 18:23:26 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Fri, 19 Aug 2005 18:23:26 +0200
Subject: [R] Unload a library
In-Reply-To: <1124399219.4304f873b3315@www.ufal.br>
References: <1124399219.4304f873b3315@www.ufal.br>
Message-ID: <4306077E.3010903@statistik.uni-dortmund.de>

Talita Perciano Costa Leite wrote:

> Hi people,
> 
> I'm developing an application (in Linux) using tcltk and calling ggobi from that
> application (using the Rggobi package). After I load ggobi and want to use the
> windows made by tcltk I get some errors and sometimes R cracks. I believe the
> problem is because the packages Rggobi, RGtk and tcltk are running together. I
> thought about a solution that would be unload the Rggobi and RGtk packages after
> I use them. Do you know how I do that? And if someone has another solution for
> that problem please help me.

See ?detach

Uwe Ligges

> Thanx,
> 
> Talita Leite
> 
> 
> -------------------------------------------------
> Este e-mail foi enviado pelo Webmail da UFAL
> IMP: http://horde.org/imp/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From dmbates at gmail.com  Fri Aug 19 18:44:22 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Fri, 19 Aug 2005 11:44:22 -0500
Subject: [R] How to assess significance of random effect in lme4
In-Reply-To: <5abc11d80508170330a9991b3@mail.gmail.com>
References: <5abc11d80508170330a9991b3@mail.gmail.com>
Message-ID: <40e66e0b05081909442d77541e@mail.gmail.com>

On 8/17/05, Shige Song <shigesong at gmail.com> wrote:
> Dear All,
> 
> With kind help from several friends on the list, I am getting close.
> Now here are something interesting I just realized: for random
> effects, lmer reports standard deviation instead of standard error! Is
> there a hidden option that tells lmer to report standard error of
> random effects, like most other multilevel or mixed modeling software,
> so that we can say something like "randome effect for xxx is
> significant, while randome effect for xxx is not significant"? Thanks!

Sorry to be entering this discussion late.  I know there have been
several responses and a considerable amount of discussion following
the original question but I think it would be worthwhile returning to
it.  Shige asks why standard errors of the estimates of the variance
components are not reported.  All other known software packages for
fitting mixed-effects models report the estimates of variances and
covariances of the random effects and the standard errors of these
estimates.  However, the summary for a fitted lmer model or a fitted
lme model does not.

This is intentional.  It is not an oversight.

The reason these are not reported is because they are not useful and,
in fact, are quite misleading.  It is useful to have a standard error
of an estimate when the distribution of the estimator is approximately
symmetric.  Then the standard error can be used to create an
approximate confidence interval or perform a hypothesis test. 
However, the distribution of the estimate of a variance generally
looks like a scaled chi-squared.

Try the following after installing version 0.98-4 or later of the Matrix package

> library(Matrix)
> Sm1 <- lmer(Reaction ~ Days + (Days|Subject), sleepstudy)
> Ss1 <- mcmcsamp(Sm1, 10000, trans = FALSE)
> str(Ss1)
 mcmc [1:10000, 1:6] 238 252 253 251 245 ...
 - attr(*, "class")= chr "mcmc"
 - attr(*, "mcpar")= int [1:3] 1 10000 1
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:6] "(Intercept)" "Days" "sigma^2" "Sbjc.(In)" ...

This fits an lmer model to a longitudinal data set then creates a
Markov Chain Monte Carlo sample from the parameters of the model.  The
default is to create an MCMC sample of transformed parameters that
correspond to the logarithm of any variances and Fisher's 'z'
transformation of the correlations.  The "trans = FALSE" optional
argument allows for the sample to be on the scale of the variances and
the covariances.

Check the density plots or the normal probability plots of the
variance components and the covariance.  The distribution is not at
all normal or even symmetric.  A symmetric confidence interval based
upon a standard error or, even worse, a hypothesis test based on the
estimate of a variance component and its standard error are clearly
inappropriate.

BTW, that mcmcsamp function is frighteningly fast when applied to a
linear mixed model.  It takes less than 2 seconds to generate a sample
of size 10000 on the machine that I use.



From vin.everett at cimr.cam.ac.uk  Fri Aug 19 18:56:47 2005
From: vin.everett at cimr.cam.ac.uk (Vin Everett)
Date: Fri, 19 Aug 2005 17:56:47 +0100
Subject: [R] Solaris10-amd64-studio10 compilers
Message-ID: <43060F4F.6070606@cimr.cam.ac.uk>

Hi,

I am trying to compile R-2.1.1 on Solaris10, with the Studio10 compilers.

When I try to compile 64bit with
CFLAGS="-xarch=amd64"
export CFLAGS

I get a configure failure on

checking for rl_callback_read_char in -lreadline... no
checking for history_truncate_file... no
configure: error: --with-readline=yes (default) and headers/libs are not 
available

unset CFLAGS and its fine will compile 32bit.

Any ideas gratefully received.

I should say I installed the readline headers etc /usr/local

a configure with --without-readline but with CFLAGS="-xarch=amd64"
goes on to

checking for dummy main to link with Fortran libraries... none
checking for Fortran name-mangling scheme... unknown
configure: WARNING: unknown Fortran name-mangling scheme
checking whether f77 appends underscores to external names... unknown
configure: error: cannot use Fortran

Again this is the studio10 fortran.

Cheers Vin

-- 
Vin.Everett at cimr.cam.ac.uk
JDRF/WT Diabetes and Inflammation Laboratory (DIL)
Cambridge Institute for Medical Research (CIMR)
Wellcome Trust/MRC Building Addenbrooke's Hospital
Hills Road Cambridge CB2 2XY
Tel +44 1223 763212
Fax +44 1223 762102
Mob +44 7990 966266



From ripley at stats.ox.ac.uk  Fri Aug 19 19:05:41 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Aug 2005 18:05:41 +0100 (BST)
Subject: [R] Unload a library
In-Reply-To: <4306077E.3010903@statistik.uni-dortmund.de>
References: <1124399219.4304f873b3315@www.ufal.br>
	<4306077E.3010903@statistik.uni-dortmund.de>
Message-ID: <Pine.LNX.4.61.0508191751460.8355@gannet.stats>

On Fri, 19 Aug 2005, Uwe Ligges wrote:

> Talita Perciano Costa Leite wrote:
>
>> Hi people,
>>
>> I'm developing an application (in Linux) using tcltk and calling ggobi 
>> from that application (using the Rggobi package). After I load ggobi 
>> and want to use the windows made by tcltk I get some errors and 
>> sometimes R cracks. I believe the problem is because the packages 
>> Rggobi, RGtk and tcltk are running together. I thought about a solution 
>> that would be unload the Rggobi and RGtk packages after I use them. Do 
>> you know how I do that? And if someone has another solution for that 
>> problem please help me.
>
> See ?detach

In principle, yes. However, as all these applications make use of the 
event loop hooks, please check that they do undo their effects.  I don't 
see any signs of that in either Rggobi or RGtk (they would need a 
.Last.lib to do it): but I could have overlooked something.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Aug 19 19:18:44 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Aug 2005 18:18:44 +0100 (BST)
Subject: [R] Compiling R to run natively on Windows x64
In-Reply-To: <58012b460508181423380ac3cf@mail.gmail.com>
References: <58012b460508181423380ac3cf@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0508191639480.7515@gannet.stats>

On Thu, 18 Aug 2005, Alastair Cooper wrote:

> I am looking at getting a PC preinstalled with Windows XP x64. What I
> want to know is, has anyone successfully compiled a version of R for
> 64-bit Windows (Amd64 - not Itanium), and if so did they find any
> performance boost?

Hmm, where do you get a reliable C99-compatible compiler for 64-bit 
Windows?  We don't know of one, and the R sources are written assuming 
long is 64-bit on a 64-bit platform (and that is not the Win64 
convention) so there would still be a lot of 32-bit restrictions until we 
change that (which is on my TODO list).

(We don't support building R with VC++, and although there have been a 
number of attempts none has produced a version that passes make check: I 
recall finding VC++ thought -Inf > 3, for example.)

Based on extensive experience on other platforms, I would expect a 
noticeable performance hit for a 64-bit build, but the ability to run 
bigger tasks: this is discussed with data and reasoning in the latest 
R-admin manual (in the R-devel version of R).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gunter.berton at gene.com  Fri Aug 19 19:47:13 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 19 Aug 2005 10:47:13 -0700
Subject: [R] Determining physical display dimensions
Message-ID: <200508191747.j7JHlEBV017029@faraday.gene.com>


Folks:

(Basically a non-R question).

Is there any (simple) OS independent way for (the latest version of) R to
determine the physical dimensions in pixels of the current display device?

Failing that, (how) can this be done for Windows (XP or 2000, say) ?

Thanks.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box



From andy_liaw at merck.com  Fri Aug 19 19:55:14 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Fri, 19 Aug 2005 13:55:14 -0400
Subject: [R] Determining physical display dimensions
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED3BA@usctmx1106.merck.com>

The screen devices are not platform independent, so I guess not.

The height and width arguments for windows() is in physical inches, and the
ypinch and xpinch specify pixels per inch, according to ?windows.

Andy

> From: Berton Gunter
> 
> Folks:
> 
> (Basically a non-R question).
> 
> Is there any (simple) OS independent way for (the latest 
> version of) R to
> determine the physical dimensions in pixels of the current 
> display device?
> 
> Failing that, (how) can this be done for Windows (XP or 2000, say) ?
> 
> Thanks.
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>  
> "The business of the statistician is to catalyze the 
> scientific learning
> process."  - George E. P. Box
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From francois.morneau at cirad.fr  Fri Aug 19 20:05:35 2005
From: francois.morneau at cirad.fr (=?iso-8859-1?Q?Fran=E7ois?= Morneau)
Date: Fri, 19 Aug 2005 15:05:35 -0300
Subject: [R] How to put factor variables in an nls formula ?
In-Reply-To: <40e66e0b050819071268f1df7b@mail.gmail.com>
References: <6.1.1.1.0.20050818161038.01e59270@Fagus.Engref.Fr>
	<40e66e0b050819071268f1df7b@mail.gmail.com>
Message-ID: <6.1.1.1.0.20050819141844.01e55080@popkru.cirad.fr>

Le 11:12 19/08/2005,Douglas Bates ??crit:
>On 8/18/05, Fran??ois Morneau <francois.morneau at cirad.fr> wrote:
> > Hello,
> >
> > I want to fit a Gompertz model for tree diameter growth that depends on a 4
> > levels edaphic factor ('Drain') and I don't manage to introduce the factor
> > variable in the formula.
> > Dinc is the annual diameter increment and D is the Diameter.
> >
> >  >treestab
> >  >     Dinc     D      Drain
> >   [1,]  0.03  26.10     2
> >   [2,]  0.04  13.05     1
> >   [3,]  0.00  24.83     1
> >   [4,]  0.00  15.92     4
> >   [5,]  0.00  12.25     4
> >   [6,]  0.00  11.78     4
> >   [7,]  0.00  16.87     4
> >   [8,]  0.00  15.12     4
> >   [9,] -0.01  13.53     4
> > [10,] 0.04  16.55     3
> > [11,] 0.025 16.07     3
> > [12,] 0.00  30.24     3
> > [13,] 0.06  15.28     2
> > etc

> >  >contrasts(Drain)<-contr.sum(4)
> >  >mymodel<-nls(Dinc~r*(1+Drain)*D*log(Asym/D), data=treestab, 
> start=list(r=0.05,
> > Asym=40))
> >
> > Error in numericDeriv(form[[3]], names(ind), env) :
> >          Missing value or an infinity produced when evaluating the model
> > In addition: Warning messages:
> > 1: + not meaningful for factors in: Ops.factor(1, Drain)
> > 2: + not meaningful for factors in: Ops.factor(1, Drain)
>
>It is not clear to me what you are trying to do.  Can you give us a
>bit more information such as how many parameter estimates you expect
>to obtain and what they would represent?

I'm trying to estimate the effect of the edaphic factor 'Drain' on tree 
diameter growth. The relationship between diameter 'D' and diameter 
increment 'Dinc' follow a Gompertz model written : Dinc= r D log(Asym/D) 
where 'r' is a parameter related to growth speed and 'Asym' is the diameter 
max where growth stops.

My hypothesis is that 'Asym' doesn't change according to edaphic condition 
but 'r' does. So I'd like to estimate 'Asym' and four 'r'i parameters for 
each level i of 'Drain' with 'r'i= r0 + effect of 'Drain'i

I hope this is helpful...

> >
> > Do I need to use another function instead of nls to correctly include the
> > factor 'Drain' ?
> >
> > Thanks,
> >
> > Fran??ois

Fran??ois Morneau
UMR ??cologie des For??ts de Guyane
Kourou, French Guiana



From ripley at stats.ox.ac.uk  Fri Aug 19 20:10:12 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Aug 2005 19:10:12 +0100 (BST)
Subject: [R] using paste and "\" to create a valid filename
In-Reply-To: <1db72680050819081439b18f46@mail.gmail.com>
References: <1db7268005081907462efc78bb@mail.gmail.com>
	<4305F4F4.5090008@statistik.uni-dortmund.de>
	<1db72680050819081439b18f46@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0508191907001.13118@gannet.stats>

On Fri, 19 Aug 2005, roger bos wrote:

> I was surprise myself that I was having problems, because I have been
> doing this for ahile, but I get erros with the RODBC connection.  For
> example,
>
> rankFile <- paste("R:\\New Ranks\\SMC\\SMC\\",rankDate,".xls", sep="")
> 			rankFile
> 			xls <- odbcConnectExcel(rankFile)
> 			xls
> 			rankFile <- "R:\New Ranks\SMC\SMC\20050818.xls"
> 			rankFile
> 			xls <- odbcConnectExcel(rankFile)
> 			xls
>
>
> You won't have my filename, but feel free to try it with any excel
> file you may have. Here is the R output.

Works for me:

> odbcConnectExcel("c:\\bdr\\hills.xls")
RODB Connection 1
Details:
   case=nochange
   DBQ=c:\bdr\hills.xls
   DefaultDir=c:\bdr
   Driver={Microsoft Excel Driver (*.xls)}
   DriverId=790
   MaxBufferSize=2048
   PageTimeout=5
> odbcConnectExcel("c:\bdr\hills.xls")
[1] -1
Warning messages:
1: [RODBC] ERROR: Could not SQLDriverConnect
2: ODBC connection failed in: odbcDriverConnect(con)

Please use / as the path separator and become less confused.


>> rankFile <- paste("R:\\New Ranks\\SMC\\SMC\\",rankDate,".xls", sep="")
>> rankFile
> [1] "R:\\New Ranks\\SMC\\SMC\\20050819.xls"
>> xls <- odbcConnectExcel(rankFile)
> Warning messages:
> 1: [RODBC] ERROR: Could not SQLDriverConnect
> 2: ODBC connection failed in: odbcDriverConnect(con)
>> xls
> [1] -1
>> rankFile <- "R:\New Ranks\SMC\SMC\20050818.xls"
>> rankFile
> [1] "R:New RanksSMCSMC?50818.xls"
>> xls <- odbcConnectExcel(rankFile)
>> xls
> RODB Connection 15
> Details:
>  case=nochange
>  DBQ=R:New RanksSMCSMC?50818.xls
>  DefaultDir=R:\NEW RANKS\SMC
>  Driver={Microsoft Excel Driver (*.xls)}
>  DriverId=790
>  MaxBufferSize=2048
>  PageTimeout=5
>>
>
> On 8/19/05, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote:
>> roger bos wrote:
>>
>>> Sometimes even the easy stuff is difficult (for me)... I want to get
>>> input from different places to paste together an excel filename (so
>>> you know I'm using windows) that I can open with RODBC.  I know about
>>> using double "\" since its an escape character, but I get either 2 or
>>> none, I can't get just one "\" where I need it.  See example code
>>> below.  I am using R 2.1.0, but plan to upgrade soon.  Thanks in
>>> advance to anyone who can help.
>>>
>>> Roger
>>>
>>>
>>> rankPath <- "R:\New Ranks\SMC\SMC"
>>> rankDate <- "20050819"
>>> rankFile <- paste(rankPath,rankDate,".xls", sep="")
>>> rankFile
>>> [1] "R:New RanksSMCSMC20050819.xls"
>>>
>>>
>>> rankPath <- "R:\\New Ranks\\SMC\\SMC"
>>> rankDate <- "20050819"
>>> rankFile <- paste(rankPath,rankDate,".xls", sep="")
>>> rankFile
>>> [1] "R:\\New Ranks\\SMC\\SMC20050819.xls"
>>
>>
>> This is perfect, "\" is *printed* escaped, hence for file access you can
>> perfectly use this character vector.
>>
>> Uwe Ligges
>>
>>
>>> ______________________________________________
>>> R-help at stat.math.ethz.ch mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From efg at stowers-institute.org  Fri Aug 19 20:17:38 2005
From: efg at stowers-institute.org (Earl F. Glynn)
Date: Fri, 19 Aug 2005 13:17:38 -0500
Subject: [R] Determining physical display dimensions
References: <200508191747.j7JHlEBV017029@faraday.gene.com>
Message-ID: <de57o3$250$1@sea.gmane.org>

"Berton Gunter" <gunter.berton at gene.com> wrote in message
news:200508191747.j7JHlEBV017029 at faraday.gene.com...

> Failing that, (how) can this be done for Windows (XP or 2000, say) ?

Take a look at the Windows GetDeviceCaps API call
http://msdn.microsoft.com/library/default.asp?url=/library/en-us/gdi/devcons_88s3.asp

Parameters that can be queried include:
HORZRES  Width, in pixels, of the screen.
VERTRES Height, in raster lines, of the screen.

HORZSIZE Width, in millimeters, of the physical screen
VERTSIZE  Height, in millimeters, of the physical screen

The specifics of how to use this API call will vary by language.  Google
will be your friend.

efg
Bioinformatics
Stowers Institute for Medical Research



From karen at brimson.com  Fri Aug 19 20:25:13 2005
From: karen at brimson.com (Karen L. Updegraff)
Date: Fri, 19 Aug 2005 13:25:13 -0500 (CDT)
Subject: [R] multiple plots in png output
Message-ID: <E1E6BYH-0007tu-VE@gate.brimson.com>

I am using R version 1.9.1 under Linux.

In the past I have had no problem saving a multi-plot page to a postscript
or png device. However, the last time I did this may have been under a
previous version of R. Presently nothing I do seems to succeed in saving
multi-plots, defined (for example) with 
mfrow=c(2,2) ... plot(..) .. plot(..)

The same problem has occurred using hist() and plot().
These are not plots that lend themselves to a lattice format, so that
is not really an option.  The multi-plot page displays fine with
the default (x11) graphics device but in the saved file only the last
plot shows up.

The only suggestion of a problem that I found in the R documentation was
a warning that png and "similar devices" would tend to save only the
last page of a multi-page plot, unles you used something like "%d" to
indicate the file sequence. There are no details on how or where that
option might be used. R documentation frequently seems to go out of its way
to be opaque.

Is this a bug that was introduced with v 1.9.1, and if so has it
been fixed in more recent releases? Alternatively, is there a
workaround which is not documented?

Suggestions appreciated.
Karen



From qiuxing at yahoo.com  Fri Aug 19 21:27:34 2005
From: qiuxing at yahoo.com (Xing Qiu)
Date: Fri, 19 Aug 2005 12:27:34 -0700 (PDT)
Subject: [R] 0/0, R segfaults
In-Reply-To: <Pine.LNX.4.61.0508190706450.17830@gannet.stats>
Message-ID: <20050819192734.55794.qmail@web50905.mail.yahoo.com>

Thank you very much, I did try your simple C program and it works
without any problem.  I even tried some more sophisticated examples,
and they all print out nan instead of a segfault.

My computer has a Pentium 4 CPU, and I compiled R with the following
flags (these are just my default compiler Cflags):

-O3 -march=pentium4 -pipe -fomit-frame-pointer -ffast-math
-mfpmath=sse,387 -msse2 -mmmx



--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> To expand on Dirk's answer, R relies on fairly close compliance to 
> IEC60559 (aka IEEE754) arithmetic in which 0/0 = NaN.  As R is
> C/Fortran 
> program, this is a function of your C/Fortran compilers (it is most
> likely 
> an FPU setting controlled by the compiler than libc).  Problems in
> this 
> area are documented in the R-admin manual.
> 
> We don't know the CPU here, so ix86 is a plausible guess.  That has
> a FPU
> control word that determines if 0/0 is NaN or an exception.  Prior
> to 
> glibc 2.1 it could be set by __setfpucw and R sets it if
> NEED___SETFPUCW
> is defined (only in older Linuxen).
> 
> Other people using Gentoo are not reporting problems, so this has
> to be a 
> very specific problem, one which is best addressed to a Gentoo
> list.  Try 
> a very simple C program such as
> 
> #include <stdio.h>
> int main()
> {
>     double x = 0.0;
>     printf("x/x = %f\n", x/x); 
> }
> 
> R is doing nothing different on my Linux box (except it arranges to
> print 
> NaN not nan regardless of platform).
> 
> On Thu, 18 Aug 2005, Dirk Eddelbuettel wrote:
> 
> >
> > On 18 August 2005 at 16:01, Xing Qiu wrote:
> > | Hi,
> > |
> > |     I noticed that when I was conducting some calculation
> involving
> > | finding correlation coeficients, R stopped abnormally. So I did
> some
> > | research, and find out that 0/0 was the culprit.  For sure 0/0
> is not
> > | a valid expression, but R should give a warning, an error msg
> or NaN
> > | instead of segmentation fault.
> > |
> > |     I am using R 2.1.0 under Gentoo Linux. My GCC version is
> 3.3.5.
> >
> > edd at basebud:~> R
> >
> > R : Copyright 2005, The R Foundation for Statistical Computing
> > Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0
> >
> > R is free software and comes with ABSOLUTELY NO WARRANTY.
> > You are welcome to redistribute it under certain conditions.
> > Type 'license()' or 'licence()' for distribution details.
> >
> > R is a collaborative project with many contributors.
> > Type 'contributors()' for more information and
> > 'citation()' on how to cite R or R packages in publications.
> >
> > Type 'demo()' for some demos, 'help()' for on-line help, or
> > 'help.start()' for a HTML browser interface to help.
> > Type 'q()' to quit R.
> >
> >> 0/0
> > [1] NaN
> >>
> >
> > No problem on Debian 'testing' with R 2.1.1. You may want to try
> a different
> > libc.
> >
> > Dirk
> >
> > -- 
> > Statistics: The (futile) attempt to offer certainty about
> uncertainty.
> >         -- Roger Koenker, 'Dictionary of Received Ideas of
> Statistics'
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics, 
> http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From Elbow-Rest.S.L. at stat.math.ethz.ch  Fri Aug 19 21:27:46 2005
From: Elbow-Rest.S.L. at stat.math.ethz.ch (Elbow-Rest.S.L.@stat.math.ethz.ch)
Date: 19 Aug 2005 21:27:46 +0200
Subject: [R] Weltpremiere: Bequem und sicher fahren !
Message-ID: <20050819212746.5111F6DFFBA3F47F@from.header.has.no.domain>



From hastie at stanford.edu  Fri Aug 19 21:29:49 2005
From: hastie at stanford.edu (Trevor Hastie)
Date: Fri, 19 Aug 2005 12:29:49 -0700
Subject: [R] new data mining course
Message-ID: <4306332D.5030409@stanford.edu>

Short course: Statistical Learning and Data Mining II:
                tools for tall and wide data

Trevor Hastie and Robert Tibshirani, Stanford University

The Conference Center at Harvard Medical School
Boston, MA,
Oct 31-Nov 1, 2005

This is a *new*  two-day course on statistical models
for data mining, inference and prediction. It is the third
in a series, and follows our past
offerings "Modern Regression and Classification", and "Statistical
Learning and Data Mining".

In this course we emphasize the tools useful for tackling modern-day
data analysis problems. We focus on both "tall" data ( N>p where N=#cases,
p=#features) and "wide" data (p>N). The tools include gradient boosting, 
SVMs and
kernel methods, random forests, lasso and LARS, ridge regression and
GAMs, supervised principal components, and cross-validation.  We also
present some interesting case studies in a variety of application
areas. All our examples are developed using the S language, and most
of the procedures we discuss are implemented in publically available
R packages.

Please visit the site
http://www-stat.stanford.edu/~hastie/sldm.html
for more information on the course and registration details.

-- 
--------------------------------------------------------------------
  Trevor Hastie                                  hastie at stanford.edu
  Professor, Department of Statistics, Stanford University
  Phone: (650) 725-2231 (Statistics)	         Fax: (650) 725-8977
	 (650) 498-5233 (Biostatistics)		 Fax: (650) 725-6951
  URL: http://www-stat.stanford.edu/~hastie
  address: room 104, Department of Statistics, Sequoia Hall
	          390 Serra Mall, Stanford University, CA 94305-4065



From qiuxing at yahoo.com  Fri Aug 19 21:32:38 2005
From: qiuxing at yahoo.com (Xing Qiu)
Date: Fri, 19 Aug 2005 12:32:38 -0700 (PDT)
Subject: [R] 0/0, R segfaults
In-Reply-To: <Pine.LNX.4.61.0508190706450.17830@gannet.stats>
Message-ID: <20050819193238.14069.qmail@web50907.mail.yahoo.com>

I just found out that I can do:

x <- 0/0

in my R without any problem, it is only when I was trying to print
the value of x by simply type x and return, R crashed with a sigh of
segfault .... This is so wierd. I will try to report it to the Gentoo
forum and see if any other gentoo user has the same problem.

Xing

--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> To expand on Dirk's answer, R relies on fairly close compliance to 
> IEC60559 (aka IEEE754) arithmetic in which 0/0 = NaN.  As R is
> C/Fortran 
> program, this is a function of your C/Fortran compilers (it is most
> likely 
> an FPU setting controlled by the compiler than libc).  Problems in
> this 
> area are documented in the R-admin manual.
> 
> We don't know the CPU here, so ix86 is a plausible guess.  That has
> a FPU
> control word that determines if 0/0 is NaN or an exception.  Prior
> to 
> glibc 2.1 it could be set by __setfpucw and R sets it if
> NEED___SETFPUCW
> is defined (only in older Linuxen).
> 
> Other people using Gentoo are not reporting problems, so this has
> to be a 
> very specific problem, one which is best addressed to a Gentoo
> list.  Try 
> a very simple C program such as
> 
> #include <stdio.h>
> int main()
> {
>     double x = 0.0;
>     printf("x/x = %f\n", x/x); 
> }
> 
> R is doing nothing different on my Linux box (except it arranges to
> print 
> NaN not nan regardless of platform).
> 
> On Thu, 18 Aug 2005, Dirk Eddelbuettel wrote:
> 
> >
> > On 18 August 2005 at 16:01, Xing Qiu wrote:
> > | Hi,
> > |
> > |     I noticed that when I was conducting some calculation
> involving
> > | finding correlation coeficients, R stopped abnormally. So I did
> some
> > | research, and find out that 0/0 was the culprit.  For sure 0/0
> is not
> > | a valid expression, but R should give a warning, an error msg
> or NaN
> > | instead of segmentation fault.
> > |
> > |     I am using R 2.1.0 under Gentoo Linux. My GCC version is
> 3.3.5.
> >
> > edd at basebud:~> R
> >
> > R : Copyright 2005, The R Foundation for Statistical Computing
> > Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0
> >
> > R is free software and comes with ABSOLUTELY NO WARRANTY.
> > You are welcome to redistribute it under certain conditions.
> > Type 'license()' or 'licence()' for distribution details.
> >
> > R is a collaborative project with many contributors.
> > Type 'contributors()' for more information and
> > 'citation()' on how to cite R or R packages in publications.
> >
> > Type 'demo()' for some demos, 'help()' for on-line help, or
> > 'help.start()' for a HTML browser interface to help.
> > Type 'q()' to quit R.
> >
> >> 0/0
> > [1] NaN
> >>
> >
> > No problem on Debian 'testing' with R 2.1.1. You may want to try
> a different
> > libc.
> >
> > Dirk
> >
> > -- 
> > Statistics: The (futile) attempt to offer certainty about
> uncertainty.
> >         -- Roger Koenker, 'Dictionary of Received Ideas of
> Statistics'
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics, 
> http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From p.dalgaard at biostat.ku.dk  Fri Aug 19 21:49:45 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 19 Aug 2005 21:49:45 +0200
Subject: [R] 0/0, R segfaults
In-Reply-To: <20050819192734.55794.qmail@web50905.mail.yahoo.com>
References: <20050819192734.55794.qmail@web50905.mail.yahoo.com>
Message-ID: <x2pss9yaee.fsf@turmalin.kubism.ku.dk>

Xing Qiu <qiuxing at yahoo.com> writes:

> Thank you very much, I did try your simple C program and it works
> without any problem.  I even tried some more sophisticated examples,
> and they all print out nan instead of a segfault.
> 
> My computer has a Pentium 4 CPU, and I compiled R with the following
> flags (these are just my default compiler Cflags):
> 
> -O3 -march=pentium4 -pipe -fomit-frame-pointer -ffast-math
> -mfpmath=sse,387 -msse2 -mmmx

Get rid of those math settings. fast-math tends to break IEEE
compliance and fpmath=sse,387 is labeled experimental on the gcc man
page (as you might well have found out for yourself...). 
 
        -p

> 
> 
> --- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> 
> > To expand on Dirk's answer, R relies on fairly close compliance to 
> > IEC60559 (aka IEEE754) arithmetic in which 0/0 = NaN.  As R is
> > C/Fortran 
> > program, this is a function of your C/Fortran compilers (it is most
> > likely 
> > an FPU setting controlled by the compiler than libc).  Problems in
> > this 
> > area are documented in the R-admin manual.
> > 
> > We don't know the CPU here, so ix86 is a plausible guess.  That has
> > a FPU
> > control word that determines if 0/0 is NaN or an exception.  Prior
> > to 
> > glibc 2.1 it could be set by __setfpucw and R sets it if
> > NEED___SETFPUCW
> > is defined (only in older Linuxen).
> > 
> > Other people using Gentoo are not reporting problems, so this has
> > to be a 
> > very specific problem, one which is best addressed to a Gentoo
> > list.  Try 
> > a very simple C program such as
> > 
> > #include <stdio.h>
> > int main()
> > {
> >     double x = 0.0;
> >     printf("x/x = %f\n", x/x); 
> > }
> > 
> > R is doing nothing different on my Linux box (except it arranges to
> > print 
> > NaN not nan regardless of platform).
> > 
> > On Thu, 18 Aug 2005, Dirk Eddelbuettel wrote:
> > 
> > >
> > > On 18 August 2005 at 16:01, Xing Qiu wrote:
> > > | Hi,
> > > |
> > > |     I noticed that when I was conducting some calculation
> > involving
> > > | finding correlation coeficients, R stopped abnormally. So I did
> > some
> > > | research, and find out that 0/0 was the culprit.  For sure 0/0
> > is not
> > > | a valid expression, but R should give a warning, an error msg
> > or NaN
> > > | instead of segmentation fault.
> > > |
> > > |     I am using R 2.1.0 under Gentoo Linux. My GCC version is
> > 3.3.5.
> > >
> > > edd at basebud:~> R
> > >
> > > R : Copyright 2005, The R Foundation for Statistical Computing
> > > Version 2.1.1  (2005-06-20), ISBN 3-900051-07-0
> > >
> > > R is free software and comes with ABSOLUTELY NO WARRANTY.
> > > You are welcome to redistribute it under certain conditions.
> > > Type 'license()' or 'licence()' for distribution details.
> > >
> > > R is a collaborative project with many contributors.
> > > Type 'contributors()' for more information and
> > > 'citation()' on how to cite R or R packages in publications.
> > >
> > > Type 'demo()' for some demos, 'help()' for on-line help, or
> > > 'help.start()' for a HTML browser interface to help.
> > > Type 'q()' to quit R.
> > >
> > >> 0/0
> > > [1] NaN
> > >>
> > >
> > > No problem on Debian 'testing' with R 2.1.1. You may want to try
> > a different
> > > libc.
> > >
> > > Dirk
> > >
> > > -- 
> > > Statistics: The (futile) attempt to offer certainty about
> > uncertainty.
> > >         -- Roger Koenker, 'Dictionary of Received Ideas of
> > Statistics'
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > http://www.R-project.org/posting-guide.html
> > >
> > 
> > -- 
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics, 
> > http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From gerifalte28 at hotmail.com  Fri Aug 19 21:51:24 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Fri, 19 Aug 2005 19:51:24 +0000
Subject: [R] multiple plots in png output
In-Reply-To: <E1E6BYH-0007tu-VE@gate.brimson.com>
Message-ID: <BAY103-F184A523886FE298BBF507CA6B50@phx.gbl>

I don't run R on Linux but my first suggestion would be to download the 
latest version of R and if you still observe the problem post a new thread 
with specific code examples.

Cheers

Francisco


>From: "Karen L. Updegraff" <karen at brimson.com>
>Reply-To: "Karen L. Updegraff" <karen at brimson.com>
>To: r-help at stat.math.ethz.ch
>Subject: [R] multiple plots in png output
>Date: Fri, 19 Aug 2005 13:25:13 -0500 (CDT)
>
>I am using R version 1.9.1 under Linux.
>
>In the past I have had no problem saving a multi-plot page to a postscript
>or png device. However, the last time I did this may have been under a
>previous version of R. Presently nothing I do seems to succeed in saving
>multi-plots, defined (for example) with
>mfrow=c(2,2) ... plot(..) .. plot(..)
>
>The same problem has occurred using hist() and plot().
>These are not plots that lend themselves to a lattice format, so that
>is not really an option.  The multi-plot page displays fine with
>the default (x11) graphics device but in the saved file only the last
>plot shows up.
>
>The only suggestion of a problem that I found in the R documentation was
>a warning that png and "similar devices" would tend to save only the
>last page of a multi-page plot, unles you used something like "%d" to
>indicate the file sequence. There are no details on how or where that
>option might be used. R documentation frequently seems to go out of its way
>to be opaque.
>
>Is this a bug that was introduced with v 1.9.1, and if so has it
>been fixed in more recent releases? Alternatively, is there a
>workaround which is not documented?
>
>Suggestions appreciated.
>Karen
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Fri Aug 19 21:54:42 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Aug 2005 20:54:42 +0100 (BST)
Subject: [R] Solaris10-amd64-studio10 compilers
In-Reply-To: <43060F4F.6070606@cimr.cam.ac.uk>
References: <43060F4F.6070606@cimr.cam.ac.uk>
Message-ID: <Pine.LNX.4.61.0508192051550.14376@gannet.stats>

On Fri, 19 Aug 2005, Vin Everett wrote:

> I am trying to compile R-2.1.1 on Solaris10, with the Studio10 compilers.
>
> When I try to compile 64bit with
> CFLAGS="-xarch=amd64"
> export CFLAGS
>
> I get a configure failure on
>
> checking for rl_callback_read_char in -lreadline... no
> checking for history_truncate_file... no
> configure: error: --with-readline=yes (default) and headers/libs are not
> available
>
> unset CFLAGS and its fine will compile 32bit.
>
> Any ideas gratefully received.
>
> I should say I installed the readline headers etc /usr/local

So, your readline is probably not 64-bit: see the R-admin manual and check 
in config.log.

> a configure with --without-readline but with CFLAGS="-xarch=amd64"
> goes on to
>
> checking for dummy main to link with Fortran libraries... none
> checking for Fortran name-mangling scheme... unknown
> configure: WARNING: unknown Fortran name-mangling scheme
> checking whether f77 appends underscores to external names... unknown
> configure: error: cannot use Fortran
>
> Again this is the studio10 fortran.

Please note you need to set FFLAGS to match.  If you consult the R-admin 
manual you will see that sparc users need somewhat different settings: 
please emulate those.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From sue at xlsolutions-corp.com  Fri Aug 19 22:43:04 2005
From: sue at xlsolutions-corp.com (Sue Turner)
Date: Fri, 19 Aug 2005 13:43:04 -0700
Subject: [R] R/Splus course in Seattle *** August 29-30 (New Dates)
Message-ID: <20050819134304.9f08cc34deb45d78e54b3b5664e21546.f193dfaad7.wbe@email.email.secureserver.net>



From pauljohn at ku.edu  Fri Aug 19 23:23:30 2005
From: pauljohn at ku.edu (Paul Johnson)
Date: Fri, 19 Aug 2005 16:23:30 -0500
Subject: [R] Advice about system for installing & updating all R package in
 a Linux Lab?
Message-ID: <43064DD2.40109@ku.edu>

Good day:

I'm administering 6 linux systems (FC4) in a student lab and worry that 
users may want packages that are not installed.  I get tired of adding 
them one by one.  Then I happened upon this page

http://support.stat.ucla.edu/view.php?supportid=30

about installing all R packages from CRAN.  That did not run as it was, 
but after some fiddling I arrived at the following script, which does 
run and it builds many packages and reports failures on the rest:

#R_installAll.R
options(repos = "http://lib.stat.cmu.edu/R/CRAN/")
update.packages(ask=F)
x <- packageStatus(repositories="http://cran.r-project.org/src/contrib")
st <- x$avai["Status"]
install.packages(rownames(st)[which(st$Status=="not installed")], 
dependencies=T)

If I run that in batch mode (as root, of course)

 >  R CMD BATCH R_installAll.R

It produces some informative output. Some packages don't build because 
they are for Windows.  As Prof Ripley mentioned recently, some packages 
don't build because of gcc-4.0.1. Some fail because I don't have some 
requisite libraries installed.  I try to deduce which FC packages may be 
used to fix that and iterate the process now and then.

But, for the most part, the packages to be OK (as far as I can tell). 
The output of a recent update is posted on the net here, in case you are 
interested to see (this lists the ones that don't build plus the 
successful updates):

http://lark.cc.ku.edu/~pauljohn/software/R/R_installAll.Rout

I can't see how this does any damage, since the packages that don't 
build are very graceful about erasing themselves, and the ones that do 
build are automatically available for the users.

Can you see any downside to scheduling this process to run as a cron 
job, say once per week, to keep packages up to date?


-- 
Paul E. Johnson                       email: pauljohn at ku.edu
Dept. of Political Science            http://lark.cc.ku.edu/~pauljohn
1541 Lilac Lane, Rm 504
University of Kansas                  Office: (785) 864-9086
Lawrence, Kansas 66044-3177           FAX: (785) 864-5700



From a_mani_sc_gs at vsnl.net  Fri Aug 19 23:56:12 2005
From: a_mani_sc_gs at vsnl.net (A. Mani)
Date: Sat, 20 Aug 2005 03:26:12 +0530
Subject: [R] A. Mani : Avoiding loops
In-Reply-To: <8ed68eed050818232461686a57@mail.gmail.com>
References: <200508190227.17584.a_mani_sc_gs@vsnl.net>
	<8ed68eed050818232461686a57@mail.gmail.com>
Message-ID: <200508200326.12336.a_mani_sc_gs@vsnl.net>

On Friday 19 August 2005 11:54, Sean O'Riordain wrote:
> Hi,
> I'm not sure what you actually want from your email (following the
> posting guide is a good way of helping you explain things to the rest
> of us in a way we understand - it might even answer your question!
>
> I'm only a beginner at R so no doubt one of our expert colleagues will
> help me...
>
> > fred <- data.frame()
> > fred <- edit(fred)
> > fred
>
>   A B C D E
> 1 1 2 X Y 1
> 2 2 3 G L 1
> 3 3 1 G L 5
>
> > fred[,3]
>
> [1] X G G
> Levels: G X
>
> > fred[fred[,3]=="G",]
>
>   A B C D E
> 2 2 3 G L 1
> 3 3 1 G L 5
>
> so at this point I can create a new dataframe with column 3 (C) ==
> "G"; either explicitly or implicitly...
>
> and if I want to calculate the sum() of column E, then I just say
> something like...
>
> > sum(fred[fred[,3]=="G",][,5])
>
> [1] 6
>
>
> now naturally being a bit clueless at manipulating stuff in R, I
> didn't know how to do this before I started... and you guys only get
> to see the lines that I typed in and got a "successful" result...
>
> according to section 6 of the "Introduction to R" manual which comes
> with R, I could also have said
>
> > sum(fred[fred$C=="G",]$E)
>
> [1] 6
>
> Hmmm.... I wonder would it be reasonable to put an example of this
> type into section 2.7 of the "Introduction to R"?
>
>
> cheers!
> Sean
>
> On 18/08/05, A. Mani <a_mani_sc_gs at vsnl.net> wrote:
> > Hello,
> >         I want to avoid loops in the following situation. There is a
> > 5-col dataframe with col headers alone. two of the columns are
> > non-numeric. The problem is to calculate statistics(scores) for each
> > element of one column. The functions depend on matching in the other
> > non-numeric column.
> >
> > A  B  C  E  F
> > 1  2  X  Y  1
> > 2  3  G  L  1
> > 3  1  G  L  5
> > and so on ...30000+ entries.
> >
> > I need scores for col E entries which depend on conditional implications.
> >
> >
> > Thanks,
> >
Hello,
      Sorry about the incomplete problem. Here is a better version for the
problem: (the measure is not simple)
The data frame is like
  col1       col2            col3       col4        col5
  <num>  <nonum>   <nonum>      <num>   <num>
       A           B             C                  E           F   
There are repeated strings in col3, col2.
Problem : Calculate  Measure(Ci) = [No. of repeats of Ci *100] + [If (Bi, Ci) 
is same as (Bj, Cj) and 6>= Ej - Ei >=3 then add 100 else  10] .


Actually it is to stretched further by adding similar blocks.

 How do we use *apply or
something else in the situation  ?


In prolog it is extremely easy, but here it is not quite...


A. Mani
Member, Cal. Math. Soc



From a.manigs at gmail.com  Fri Aug 19 23:38:15 2005
From: a.manigs at gmail.com (A Mani)
Date: Sat, 20 Aug 2005 03:08:15 +0530
Subject: [R] Re : A. Mani : Avoiding Loops
Message-ID: <a6821d9905081914381d22fe46@mail.gmail.com>

On Friday 19 August 2005 11:54, Sean O'Riordain wrote:
> Hi,
> I'm not sure what you actually want from your email (following the
> posting guide is a good way of helping you explain things to the rest
> of us in a way we understand - it might even answer your question!
>
> I'm only a beginner at R so no doubt one of our expert colleagues will
> help me...
>
> > fred <- data.frame()
> > fred <- edit(fred)
> > fred
>
>   A B C D E
> 1 1 2 X Y 1
> 2 2 3 G L 1
> 3 3 1 G L 5
>
> > fred[,3]
>
> [1] X G G
> Levels: G X
>
> > fred[fred[,3]=="G",]
>
>   A B C D E
> 2 2 3 G L 1
> 3 3 1 G L 5
>
> so at this point I can create a new dataframe with column 3 (C) ==
> "G"; either explicitly or implicitly...
>
> and if I want to calculate the sum() of column E, then I just say
> something like...
>
> > sum(fred[fred[,3]=="G",][,5])
>
> [1] 6
>
>
> now naturally being a bit clueless at manipulating stuff in R, I
> didn't know how to do this before I started... and you guys only get
> to see the lines that I typed in and got a "successful" result...
>
> according to section 6 of the "Introduction to R" manual which comes
> with R, I could also have said
>
> > sum(fred[fred$C=="G",]$E)
>
> [1] 6
>
> Hmmm.... I wonder would it be reasonable to put an example of this
> type into section 2.7 of the "Introduction to R"?
>
>
> cheers!
> Sean
>
> On 18/08/05, A. Mani <a_mani_sc_gs at vsnl.net> wrote:
> > Hello,
> >         I want to avoid loops in the following situation. There is a
> > 5-col dataframe with col headers alone. two of the columns are
> > non-numeric. The problem is to calculate statistics(scores) for each
> > element of one column. The functions depend on matching in the other
> > non-numeric column.
> >
> > A  B  C  E  F
> > 1  2  X  Y  1
> > 2  3  G  L  1
> > 3  1  G  L  5
> > and so on ...30000+ entries.
> >
> > I need scores for col E entries which depend on conditional implications.
> >
> >
> > Thanks,
> >
Hello,
      Sorry about the incomplete problem. Here is a better version for the
problem: (the measure is not simple)
The data frame is like
  col1       col2            col3       col4        col5
  <num>  <nonum>   <nonum>      <num>   <num>
       A           B             C                  E           F   
There are repeated strings in col3, col2.
Problem : Calculate  Measure(Ci) = [No. of repeats of Ci *100] + [If (Bi, Ci) 
is same as (Bj, Cj) and 6>= Ej - Ei >=3 then add 100 else  10] .


Actually it is to stretched further by adding similar blocks.

 How do we use *apply or
something else in the situation  ?


In prolog it is extremely easy, but here it is not quite...


A. Mani
Member, Cal. Math. Soc

-- 
A. Mani
Member, Cal. Math. Soc



From Elbow-Rest.S.L. at stat.math.ethz.ch  Fri Aug 19 23:43:24 2005
From: Elbow-Rest.S.L. at stat.math.ethz.ch (Elbow-Rest.S.L.@stat.math.ethz.ch)
Date: 19 Aug 2005 23:43:24 +0200
Subject: [R] Weltpremiere: Bequem und sicher fahren !
Message-ID: <200508192143.j7JLhLPN024693@hypatia.math.ethz.ch>



From ross at biostat.ucsf.edu  Sat Aug 20 00:42:00 2005
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 19 Aug 2005 15:42:00 -0700
Subject: [R] Use of contains in S4 classes
In-Reply-To: <Pine.OSF.4.58.0508181726190.199813@odin.mdacc.tmc.edu>
References: <1124399671.26136.5.camel@iron.libaux.ucsf.edu>
	<Pine.OSF.4.58.0508181726190.199813@odin.mdacc.tmc.edu>
Message-ID: <1124491320.26136.59.camel@iron.libaux.ucsf.edu>

On Thu, 2005-08-18 at 17:30 -0500, Paul Roebuck wrote:
> On Thu, 18 Aug 2005, Ross Boylan wrote:
> 
> > setClass("B", representation=representation("B", extra="numeric"))
> > setClass("B", representation=representation(extra="numeric"),
> > 	contains="B")
> > Are these the same?  If not, how do they differ?
> >
> > What about
> > setClass("B", representation=representation("B", extra="numeric"),
> > 	contains="B")
> > ?
> >
> > As far as I can tell, the Green Book doesn't talk about a contains
> > argument to setClass.
> 
> "S4 - Composition and Inheritance" by Witold Eryk Wolski
> (a.k.a. Extending.pdf) might be what you're looking for.

Thank you.  It speaks directly to this question, and asserts that the
first two forms are equivalent.  contains makes it a bit easier for the
eye to catch that inheritance is happening.



From dmbates at gmail.com  Sat Aug 20 00:48:28 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Fri, 19 Aug 2005 17:48:28 -0500
Subject: [R] How to put factor variables in an nls formula ?
In-Reply-To: <6.1.1.1.0.20050819141844.01e55080@popkru.cirad.fr>
References: <6.1.1.1.0.20050818161038.01e59270@Fagus.Engref.Fr>
	<40e66e0b050819071268f1df7b@mail.gmail.com>
	<6.1.1.1.0.20050819141844.01e55080@popkru.cirad.fr>
Message-ID: <40e66e0b050819154862c5dbe5@mail.gmail.com>

On 8/19/05, François Morneau <francois.morneau at cirad.fr> wrote:
> Le 11:12 19/08/2005,Douglas Bates écrit:
> >On 8/18/05, François Morneau <francois.morneau at cirad.fr> wrote:
> > > Hello,
> > >
> > > I want to fit a Gompertz model for tree diameter growth that depends on a 4
> > > levels edaphic factor ('Drain') and I don't manage to introduce the factor
> > > variable in the formula.
> > > Dinc is the annual diameter increment and D is the Diameter.
> > >
> > >  >treestab
> > >  >     Dinc     D      Drain
> > >   [1,]  0.03  26.10     2
> > >   [2,]  0.04  13.05     1
> > >   [3,]  0.00  24.83     1
> > >   [4,]  0.00  15.92     4
> > >   [5,]  0.00  12.25     4
> > >   [6,]  0.00  11.78     4
> > >   [7,]  0.00  16.87     4
> > >   [8,]  0.00  15.12     4
> > >   [9,] -0.01  13.53     4
> > > [10,] 0.04  16.55     3
> > > [11,] 0.025 16.07     3
> > > [12,] 0.00  30.24     3
> > > [13,] 0.06  15.28     2
> > > etc…
> > >  >contrasts(Drain)<-contr.sum(4)
> > >  >mymodel<-nls(Dinc~r*(1+Drain)*D*log(Asym/D), data=treestab,
> > start=list(r=0.05,
> > > Asym=40))
> > >
> > > Error in numericDeriv(form[[3]], names(ind), env) :
> > >          Missing value or an infinity produced when evaluating the model
> > > In addition: Warning messages:
> > > 1: + not meaningful for factors in: Ops.factor(1, Drain)
> > > 2: + not meaningful for factors in: Ops.factor(1, Drain)
> >
> >It is not clear to me what you are trying to do.  Can you give us a
> >bit more information such as how many parameter estimates you expect
> >to obtain and what they would represent?
> 
> I'm trying to estimate the effect of the edaphic factor 'Drain' on tree
> diameter growth. The relationship between diameter 'D' and diameter
> increment 'Dinc' follow a Gompertz model written : Dinc= r D log(Asym/D)
> where 'r' is a parameter related to growth speed and 'Asym' is the diameter
> max where growth stops.
> 
> My hypothesis is that 'Asym' doesn't change according to edaphic condition
> but 'r' does. So I'd like to estimate 'Asym' and four 'r'i parameters for
> each level i of 'Drain' with 'r'i= r0 + effect of 'Drain'i
> 
> I hope this is helpful...

Yes, it is.  
> 
> > >
> > > Do I need to use another function instead of nls to correctly include the
> > > factor 'Drain' ?
> > >
> > > Thanks,
> > >
> > > François
> 
> François Morneau
> UMR Écologie des Forêts de Guyane
> Kourou, French Guiana
> 
>



From dmbates at gmail.com  Sat Aug 20 01:04:12 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Fri, 19 Aug 2005 18:04:12 -0500
Subject: [R] How to put factor variables in an nls formula ?
In-Reply-To: <40e66e0b050819154862c5dbe5@mail.gmail.com>
References: <6.1.1.1.0.20050818161038.01e59270@Fagus.Engref.Fr>
	<40e66e0b050819071268f1df7b@mail.gmail.com>
	<6.1.1.1.0.20050819141844.01e55080@popkru.cirad.fr>
	<40e66e0b050819154862c5dbe5@mail.gmail.com>
Message-ID: <40e66e0b050819160439d8f76@mail.gmail.com>

On 8/19/05, Douglas Bates <dmbates at gmail.com> wrote:
> On 8/19/05, François Morneau <francois.morneau at cirad.fr> wrote:
> > Le 11:12 19/08/2005,Douglas Bates écrit:
> > >On 8/18/05, François Morneau <francois.morneau at cirad.fr> wrote:
> > > > Hello,
> > > >
> > > > I want to fit a Gompertz model for tree diameter growth that depends on a 4
> > > > levels edaphic factor ('Drain') and I don't manage to introduce the factor
> > > > variable in the formula.
> > > > Dinc is the annual diameter increment and D is the Diameter.
> > > >
> > > >  >treestab
> > > >  >     Dinc     D      Drain
> > > >   [1,]  0.03  26.10     2
> > > >   [2,]  0.04  13.05     1
> > > >   [3,]  0.00  24.83     1
> > > >   [4,]  0.00  15.92     4
> > > >   [5,]  0.00  12.25     4
> > > >   [6,]  0.00  11.78     4
> > > >   [7,]  0.00  16.87     4
> > > >   [8,]  0.00  15.12     4
> > > >   [9,] -0.01  13.53     4
> > > > [10,] 0.04  16.55     3
> > > > [11,] 0.025 16.07     3
> > > > [12,] 0.00  30.24     3
> > > > [13,] 0.06  15.28     2
> > > > etc…
> > > >  >contrasts(Drain)<-contr.sum(4)
> > > >  >mymodel<-nls(Dinc~r*(1+Drain)*D*log(Asym/D), data=treestab,
> > > start=list(r=0.05,
> > > > Asym=40))
> > > >
> > > > Error in numericDeriv(form[[3]], names(ind), env) :
> > > >          Missing value or an infinity produced when evaluating the model
> > > > In addition: Warning messages:
> > > > 1: + not meaningful for factors in: Ops.factor(1, Drain)
> > > > 2: + not meaningful for factors in: Ops.factor(1, Drain)
> > >
> > >It is not clear to me what you are trying to do.  Can you give us a
> > >bit more information such as how many parameter estimates you expect
> > >to obtain and what they would represent?
> >
> > I'm trying to estimate the effect of the edaphic factor 'Drain' on tree
> > diameter growth. The relationship between diameter 'D' and diameter
> > increment 'Dinc' follow a Gompertz model written : Dinc= r D log(Asym/D)
> > where 'r' is a parameter related to growth speed and 'Asym' is the diameter
> > max where growth stops.
> >
> > My hypothesis is that 'Asym' doesn't change according to edaphic condition
> > but 'r' does. So I'd like to estimate 'Asym' and four 'r'i parameters for
> > each level i of 'Drain' with 'r'i= r0 + effect of 'Drain'i
> >
> > I hope this is helpful...
> 
> Yes, it is.

Sorry for the non-informative contribution - I hit the "Send" button
when I meant to hit "Cancel".

This is less easy than I thought it would be.  The Puromycin data
provides a similar example in that there are two sets of observations
of concentrations and rates, for treated and untreated cells.  The
experimenters assumption is that the rate should be related to the
concentration via the Michaelis-Menten relationship that depends on
two parameters, Asym and K, and that K should not change with
treatment but Asym will.

To fit that we can use
> nls(rate ~ (Asym + delta*(state == 'treated'))*conc/(K + conc), Puromycin, start = c(Asym = 180, delta = 30, K = 0.05))
Nonlinear regression model
  model:  rate ~ (Asym + delta * (state == "treated")) * conc/(K + conc) 
   data:  Puromycin 
        Asym        delta            K 
166.60407167  42.02596094   0.05797178 
 residual sum-of-squares:  2240.891 

To generalize this it is convenient to form the model matrix with the
indicator columns of the state factor.

> mm <- model.matrix(~ 0 + state, Puromycin)

then use matrix multiplication within a call to drop().

> nls(rate ~ drop(mm %*% c(a1,a2)) * conc/(K + conc), Puromycin, start = c(a1 = 210, a2 = 165, K = 0.05), trace = TRUE)
2822.528 :  210.00 165.00   0.05 
2247.841 :  207.77558541 165.94256936   0.05647425 
2240.997 :  208.49340568 166.51190757   0.05778192 
2240.893 :  208.61339576 166.59293688   0.05794926 
2240.891 :  208.62809965 166.60277853   0.05796917 
2240.891 :  208.62983812 166.60394147   0.05797152 
2240.891 :  208.6300430 166.6040785   0.0579718 
Nonlinear regression model
  model:  rate ~ drop(mm %*% c(a1, a2)) * conc/(K + conc) 
   data:  Puromycin 
         a1          a2           K 
208.6300430 166.6040785   0.0579718 
 residual sum-of-squares:  2240.891 

You can do the same thing defining the model matrix of indicators of
Drain and a vector of length 4 for D.  (By the way, I would avoid the
name 'D' for a variable as that is the name of an in-built function in
R.)

The reason that I said this is more difficult than I thought it would
be is because I thought that the parameters in nls could be vectors
but I haven't been able to get that to work.

An alternative is to use the gnls function from the nlme package which
does allow a parameter to be specified according to the levels of a
factor.

> >
> > > >
> > > > Do I need to use another function instead of nls to correctly include the
> > > > factor 'Drain' ?
> > > >
> > > > Thanks,
> > > >
> > > > François
> >
> > François Morneau
> > UMR Écologie des Forêts de Guyane
> > Kourou, French Guiana
> >
> >
>



From hb at maths.lth.se  Sat Aug 20 01:11:48 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Sat, 20 Aug 2005 01:11:48 +0200
Subject: [R] Advice about system for installing & updating all R package
 in a Linux Lab?
In-Reply-To: <43064DD2.40109@ku.edu>
References: <43064DD2.40109@ku.edu>
Message-ID: <43066734.70706@maths.lth.se>

You can also provide the users with the option to add/update their own 
packages locally via install- and update.packages().  Here's a piece of 
bash code that sets R_LIBS for to a OS specific directory in the users 
account. Add it to the system wide startup script.

if test "${R_LIBS}" = ""; then
   # Get the OS type in lower case
   ostype=`uname -s | tr '[A-Z]' '[a-z]'`
   export R_LIBS=${HOME}/R/R_LIBS/${ostype}/library/
   if ! test -d "${R_LIBS}"; then
     mkdir -p ${R_LIBS}
   fi
fi

Cheers

Henrik

Paul Johnson wrote:
> Good day:
> 
> I'm administering 6 linux systems (FC4) in a student lab and worry that 
> users may want packages that are not installed.  I get tired of adding 
> them one by one.  Then I happened upon this page
> 
> http://support.stat.ucla.edu/view.php?supportid=30
> 
> about installing all R packages from CRAN.  That did not run as it was, 
> but after some fiddling I arrived at the following script, which does 
> run and it builds many packages and reports failures on the rest:
> 
> #R_installAll.R
> options(repos = "http://lib.stat.cmu.edu/R/CRAN/")
> update.packages(ask=F)
> x <- packageStatus(repositories="http://cran.r-project.org/src/contrib")
> st <- x$avai["Status"]
> install.packages(rownames(st)[which(st$Status=="not installed")], 
> dependencies=T)
> 
> If I run that in batch mode (as root, of course)
> 
>  >  R CMD BATCH R_installAll.R
> 
> It produces some informative output. Some packages don't build because 
> they are for Windows.  As Prof Ripley mentioned recently, some packages 
> don't build because of gcc-4.0.1. Some fail because I don't have some 
> requisite libraries installed.  I try to deduce which FC packages may be 
> used to fix that and iterate the process now and then.
> 
> But, for the most part, the packages to be OK (as far as I can tell). 
> The output of a recent update is posted on the net here, in case you are 
> interested to see (this lists the ones that don't build plus the 
> successful updates):
> 
> http://lark.cc.ku.edu/~pauljohn/software/R/R_installAll.Rout
> 
> I can't see how this does any damage, since the packages that don't 
> build are very graceful about erasing themselves, and the ones that do 
> build are automatically available for the users.
> 
> Can you see any downside to scheduling this process to run as a cron 
> job, say once per week, to keep packages up to date?
> 
>



From mkalisiak at gmail.com  Sat Aug 20 02:28:05 2005
From: mkalisiak at gmail.com (Maciej Kalisiak)
Date: Fri, 19 Aug 2005 20:28:05 -0400
Subject: [R] plot(type="h") equivalent in Lattice?
Message-ID: <78e6ba31050819172827bfd354@mail.gmail.com>

I tend to prefer doing graphics in R using the lattice library.  I'm
"porting" some old scripts.  Is there a nice way to get in lattice the
equivalent of the plot(type='h'), which is the high-density
lines/histogram plot in base graphics package?  I tried doing this
with barchart(), but with limited success... the fact that I have
~1000 datapoints/bars causes problems, in that R insists on rendering
a tick/label for each bar, and as far as I can tell the plot doesn't
come out as accurate, due to running together of the bars (at least in
plot(type='h') you are guaranteed that each bar/line is exactly one
pixel wide)...

-- 
Maciej Kalisiak
<mkalisiak at gmail.com>
http://www.dgp.toronto.edu/~mac



From baron at psych.upenn.edu  Sat Aug 20 04:48:14 2005
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Fri, 19 Aug 2005 22:48:14 -0400
Subject: [R] Advice about system for installing & updating all R package
	in a Linux Lab?
In-Reply-To: <43064DD2.40109@ku.edu>
References: <43064DD2.40109@ku.edu>
Message-ID: <20050820024814.GA19786@psych>

On 08/19/05 16:23, Paul Johnson wrote:
> Good day:
> 
> I'm administering 6 linux systems (FC4) in a student lab and worry that
> users may want packages that are not installed.  I get tired of adding
> them one by one.  Then I happened upon this page
> 
> http://support.stat.ucla.edu/view.php?supportid=30
> 
> about installing all R packages from CRAN.  That did not run as it was,
> but after some fiddling I arrived at the following script, which does
> run and it builds many packages and reports failures on the rest:
> 
> #R_installAll.R
> options(repos = "http://lib.stat.cmu.edu/R/CRAN/")
> update.packages(ask=F)
> x <- packageStatus(repositories="http://cran.r-project.org/src/contrib")
> st <- x$avai["Status"]
> install.packages(rownames(st)[which(st$Status=="not installed")],
> dependencies=T)

I used to do this:

    update.packages()
    cp <- CRAN.packages()[,1]
    ip <- installed.packages()[,1,]
    install.packages(setdiff(cp,ip))

But now it looks like you can do this:

    install.packages(new.packages())

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron



From rab45+ at pitt.edu  Sat Aug 20 04:54:37 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Fri, 19 Aug 2005 22:54:37 -0400 (EDT)
Subject: [R] glmmPQL and Convergence
Message-ID: <55010.209.195.160.60.1124506477.squirrel@webmail.pitt.edu>

I fit the following model using glmmPQL from MASS:

fit.glmmPQL <-
glmmPQL(ifelse(class=="Disease",1,0)~age+x1+x2,random=~1|subject,family=binomial)
summary(fit.glmmPQL)

The response is paired (pairing denoted by subject), although some
subjects only have one response. Also, there is a perfect positive
correlation between the paired responses. x1 and x2 can and do differ
within each pair. Here is the output:

> summary(fit.glmmPQL)
Linear mixed-effects model fit by maximum likelihood
 Data: fernando
       AIC      BIC    logLik
  30.51277 49.25655 -9.256384

Random effects:
 Formula: ~1 | subject
        (Intercept)     Residual
StdDev:    8.284993 4.113725e-09

Variance function:
 Structure: fixed weights
 Formula: ~invwt
Fixed effects: ifelse(class == "Disease", 1, 0) ~ age + x1 + x2
                  Value Std.Error  DF   t-value p-value
(Intercept)   -35.01862 2.4414559 123     -14.3       0
age             0.59026 0.0441817 123      13.4       0
x1              1.39317 0.0000014  41 1000507.2       0
x2              0.93695 0.0000010  41  915150.3       0
 Correlation:
              (Intr) age        x2
age           -0.952
x1             0.000  0.000
x2             0.000  0.000 -0.057

Standardized Within-Group Residuals:
          Min            Q1           Med            Q3           Max
-2.939213e+00 -2.509951e-07 -1.169248e-07  2.999710e-06  3.825035e+00

Number of Observations: 168
Number of Groups: 125


The t-values are huge and the se's are correspondingly tiny. The model
does a great job of discriminating between disease and no disease. But I
have a feeling there is something wrong here. Is there something wrong
with the type of model I'm trying to fit? If it weren't for the pairing I
would just have used glm. Any insights would be appreciated.

Rick B.



From deepayan.sarkar at gmail.com  Sat Aug 20 06:58:11 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Fri, 19 Aug 2005 23:58:11 -0500
Subject: [R] plot(type="h") equivalent in Lattice?
In-Reply-To: <78e6ba31050819172827bfd354@mail.gmail.com>
References: <78e6ba31050819172827bfd354@mail.gmail.com>
Message-ID: <eb555e66050819215853b8e30d@mail.gmail.com>

On 8/19/05, Maciej Kalisiak <mkalisiak at gmail.com> wrote:
> I tend to prefer doing graphics in R using the lattice library.  I'm
> "porting" some old scripts.  Is there a nice way to get in lattice the
> equivalent of the plot(type='h'), which is the high-density
> lines/histogram plot in base graphics package?  I tried doing this
> with barchart(), but with limited success... the fact that I have
> ~1000 datapoints/bars causes problems, in that R insists on rendering
> a tick/label for each bar, 

Yes, all (or most, at least) lattice functions will do that if the
variable is a factor or shingle (which barchart forces).

> and as far as I can tell the plot doesn't
> come out as accurate, due to running together of the bars (at least in
> plot(type='h') you are guaranteed that each bar/line is exactly one
> pixel wide)...

Your best bet is to coerce to numeric, and use xyplot, whose default
panel function honors type='h'. e.g.

xyplot(yield ~ as.numeric(variety) | site + year, 
       data = barley, type = 'h')

or for horizontal bars, 

xyplot(as.numeric(variety) ~ yield | site + year, 
       data = barley, type = 'h', horizontal = TRUE)

Had too many labels not been a problem, you could also have used

barchart(as.numeric(variety) ~ yield | site + year, 
         data = barley, panel = panel.xyplot, type = 'h')

Deepayan



From ripley at stats.ox.ac.uk  Sat Aug 20 07:28:23 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 20 Aug 2005 06:28:23 +0100 (BST)
Subject: [R] Advice about system for installing & updating all R package
 in a Linux Lab?
In-Reply-To: <43064DD2.40109@ku.edu>
References: <43064DD2.40109@ku.edu>
Message-ID: <Pine.LNX.4.61.0508200615590.20074@gannet.stats>

This is based on the pre-2.1.0 ideas.  Try

update.packages(ask=FALSE)
install.packages(new.packages(), dependencies=TRUE)

However, I would suggest that you set up each student with a library, say 
~/R/library, and point R_LIBS at it (set in Renviron.site).  That's what 
we do for Windows, and it seems successful.  (We have other reasons to 
want very complete central Linux setups, one being that we run more than 
one archtecture where personal libraries are a little harder to manage.)

On Fri, 19 Aug 2005, Paul Johnson wrote:

> Good day:
>
> I'm administering 6 linux systems (FC4) in a student lab and worry that
> users may want packages that are not installed.  I get tired of adding
> them one by one.  Then I happened upon this page
>
> http://support.stat.ucla.edu/view.php?supportid=30

Many of the commands there are now or about to be deprecated.  See my 
article in the current R-News.

> about installing all R packages from CRAN.  That did not run as it was,
> but after some fiddling I arrived at the following script, which does
> run and it builds many packages and reports failures on the rest:
>
> #R_installAll.R
> options(repos = "http://lib.stat.cmu.edu/R/CRAN/")
> update.packages(ask=F)
> x <- packageStatus(repositories="http://cran.r-project.org/src/contrib")
> st <- x$avai["Status"]
> install.packages(rownames(st)[which(st$Status=="not installed")],
> dependencies=T)
>
> If I run that in batch mode (as root, of course)
>
> >  R CMD BATCH R_installAll.R
>
> It produces some informative output. Some packages don't build because
> they are for Windows.  As Prof Ripley mentioned recently, some packages
> don't build because of gcc-4.0.1. Some fail because I don't have some
> requisite libraries installed.  I try to deduce which FC packages may be
> used to fix that and iterate the process now and then.
>
> But, for the most part, the packages to be OK (as far as I can tell).
> The output of a recent update is posted on the net here, in case you are
> interested to see (this lists the ones that don't build plus the
> successful updates):
>
> http://lark.cc.ku.edu/~pauljohn/software/R/R_installAll.Rout
>
> I can't see how this does any damage, since the packages that don't
> build are very graceful about erasing themselves, and the ones that do
> build are automatically available for the users.
>
> Can you see any downside to scheduling this process to run as a cron
> job, say once per week, to keep packages up to date?

None at all.  We do something similar (but based on new.packages and with 
a stoplist of packages that we know will not install).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From vin.everett at cimr.cam.ac.uk  Sat Aug 20 13:15:39 2005
From: vin.everett at cimr.cam.ac.uk (Vin Everett)
Date: Sat, 20 Aug 2005 12:15:39 +0100
Subject: [R] Solaris10-amd64-studio10 compilers
In-Reply-To: <Pine.LNX.4.61.0508192051550.14376@gannet.stats>
References: <43060F4F.6070606@cimr.cam.ac.uk>
	<Pine.LNX.4.61.0508192051550.14376@gannet.stats>
Message-ID: <430710DB.9070408@cimr.cam.ac.uk>

Prof Brian Ripley wrote:
> On Fri, 19 Aug 2005, Vin Everett wrote:
> 
>> I am trying to compile R-2.1.1 on Solaris10, with the Studio10 compilers.
>>
>> When I try to compile 64bit with
>> CFLAGS="-xarch=amd64"
>> export CFLAGS
>>
>> I get a configure failure on
>>
>> checking for rl_callback_read_char in -lreadline... no
>> checking for history_truncate_file... no
>> configure: error: --with-readline=yes (default) and headers/libs are not
>> available
>>
>> unset CFLAGS and its fine will compile 32bit.
>>
>> Any ideas gratefully received.
>>
>> I should say I installed the readline headers etc /usr/local
> 
> 
> So, your readline is probably not 64-bit: see the R-admin manual and 
> check in config.log.
> 
>> a configure with --without-readline but with CFLAGS="-xarch=amd64"
>> goes on to
>>
>> checking for dummy main to link with Fortran libraries... none
>> checking for Fortran name-mangling scheme... unknown
>> configure: WARNING: unknown Fortran name-mangling scheme
>> checking whether f77 appends underscores to external names... unknown
>> configure: error: cannot use Fortran
>>
>> Again this is the studio10 fortran.
> 
> 
> Please note you need to set FFLAGS to match.  If you consult the R-admin 
> manual you will see that sparc users need somewhat different settings: 
> please emulate those.
> 


Thanks Brian,

I will give that a try.

Cheers Vin

-- 
Vin.Everett at cimr.cam.ac.uk
JDRF/WT Diabetes and Inflammation Laboratory (DIL)
Cambridge Institute for Medical Research (CIMR)
Wellcome Trust/MRC Building Addenbrooke's Hospital
Hills Road Cambridge CB2 2XY
Tel +44 1223 763212
Fax +44 1223 762102
Mob +44 7990 966266



From dmbates at gmail.com  Sat Aug 20 15:41:35 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Sat, 20 Aug 2005 08:41:35 -0500
Subject: [R] glmmPQL and Convergence
In-Reply-To: <55010.209.195.160.60.1124506477.squirrel@webmail.pitt.edu>
References: <55010.209.195.160.60.1124506477.squirrel@webmail.pitt.edu>
Message-ID: <40e66e0b05082006414d80bdb0@mail.gmail.com>

On 8/19/05, rab45+ at pitt.edu <rab45+ at pitt.edu> wrote:
> I fit the following model using glmmPQL from MASS:
> 
> fit.glmmPQL <-
> glmmPQL(ifelse(class=="Disease",1,0)~age+x1+x2,random=~1|subject,family=binomial)
> summary(fit.glmmPQL)
> 
> The response is paired (pairing denoted by subject), although some
> subjects only have one response. Also, there is a perfect positive
> correlation between the paired responses. x1 and x2 can and do differ
> within each pair. Here is the output:
> 
> > summary(fit.glmmPQL)
> Linear mixed-effects model fit by maximum likelihood
>  Data: fernando
>        AIC      BIC    logLik
>   30.51277 49.25655 -9.256384
> 
> Random effects:
>  Formula: ~1 | subject
>         (Intercept)     Residual
> StdDev:    8.284993 4.113725e-09

Notice the value of the residual standard deviation.  It's far too
small (it should be approximately 1 for a binomial-response model fit
by IRLS).  You have perfect prediction in your model and surprisingly
that is a problem in these models.

> 
> Variance function:
>  Structure: fixed weights
>  Formula: ~invwt
> Fixed effects: ifelse(class == "Disease", 1, 0) ~ age + x1 + x2
>                   Value Std.Error  DF   t-value p-value
> (Intercept)   -35.01862 2.4414559 123     -14.3       0
> age             0.59026 0.0441817 123      13.4       0
> x1              1.39317 0.0000014  41 1000507.2       0
> x2              0.93695 0.0000010  41  915150.3       0
>  Correlation:
>               (Intr) age        x2
> age           -0.952
> x1             0.000  0.000
> x2             0.000  0.000 -0.057
> 
> Standardized Within-Group Residuals:
>           Min            Q1           Med            Q3           Max
> -2.939213e+00 -2.509951e-07 -1.169248e-07  2.999710e-06  3.825035e+00
> 
> Number of Observations: 168
> Number of Groups: 125
> 
> 
> The t-values are huge and the se's are correspondingly tiny. The model
> does a great job of discriminating between disease and no disease. But I
> have a feeling there is something wrong here. Is there something wrong
> with the type of model I'm trying to fit? If it weren't for the pairing I
> would just have used glm. Any insights would be appreciated.
> 
> Rick B.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From maechler at stat.math.ethz.ch  Sat Aug 20 15:58:34 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 20 Aug 2005 15:58:34 +0200
Subject: [R] FFT, frequs, magnitudes, phases
In-Reply-To: <x264u22kb9.fsf@turmalin.kubism.ku.dk>
References: <200508191238.42844.wolfgang.waser@rz.hu-berlin.de>
	<x264u22kb9.fsf@turmalin.kubism.ku.dk>
Message-ID: <17159.14090.554955.263068@stat.math.ethz.ch>

>>>>> "PD" == Peter Dalgaard <p.dalgaard at biostat.ku.dk>
>>>>>     on 19 Aug 2005 14:16:42 +0200 writes:

    PD> Wolfgang Waser <wolfgang.waser at rz.hu-berlin.de> writes:
    >> Hi,
    >> 
    >> I'm in dire need of a fast fourier transformation for me
    >> stupid biologist, i.e. I have a heartbeat signal and
    >> would like to decompose it into pure sin waves, getting
    >> three vectors, one containing the frequencies of the sin
    >> waves, one the magnitudes and one the phases (that's what
    >> I get from my data acquisition software's FFT function).
    >> I'd be very much obliged, if someone could point out
    >> which command would do the job in R.

    PD> fft(), but notice that it gives the complex
    PD> transform. You need to do a little homework to get at
    PD> the magnitude/phase values. (Basically, you just have to
    PD> take Mod() and Arg(), but there some conventions about
    PD> the frequencies and multipliers that one can get wrong).

Once you've finished the "homework", others might be interested
in your result... so it will be found in the future using 
RSiteSearch().

Martin



From ripley at stats.ox.ac.uk  Fri Aug 19 19:19:58 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Aug 2005 18:19:58 +0100 (BST)
Subject: [R] Installing R in Fedora Core 4
In-Reply-To: <1124466944.31394.77.camel@gsimpson.geog.ucl.ac.uk>
References: <8BAEC5E546879B4FAA536200A292C6148353EB@AMEDMLNARMC135.amed.ds.army.mil>
	<1124466944.31394.77.camel@gsimpson.geog.ucl.ac.uk>
Message-ID: <Pine.LNX.4.61.0508191711000.7515@gannet.stats>

On Fri, 19 Aug 2005, Gavin Simpson wrote:

> On Fri, 2005-08-19 at 11:07 -0400, White, Charles E WRAIR-Wash DC wrote:
>> -----Original Message-----
>> On Fri, 8/19, Gavin Simpson wrote:
>> Peter Dalgaard has noted, on the R-Devel list (sorry I can't provide the
>> link to the mail - the link from the R site to the mail archives wasn't
>> working when I tried), that there are problems with the R rpm from
>> Fedora Extras, including a strange printing bug. I believe Peter now
>> thinks this is a bug in R (seem to have deleted that post - doh) exposed
>> by the compilation flags used by the maintainer of the Fedora Extras
>> rpm.
>>
>> If you want and rpm to install, then Martyn Plummer provides R binaries
>> for Red Hat / Fedora systems that are available from CRAN e.g: for FC4
>> http://www.stats.bris.ac.uk/R/bin/linux/redhat/fc4/
>>
>> Martyn has also made these available via a yum-compatible repository, so
>> the benefits you note of auto-notification of updates etc. apply here as
>> well.
>>
>> HTH
>>
>> G
>> -----End Original Message-----
>>
>> The last time I tried to use the Martyn Plummer RPMs they were compiled
>> without enabling shared libraries and I ended up compiling R myself so
>> that I could use JGR. Messages describing the problem with the version
>> actually on the Extras CD were my other unstated reason for describing
>> yum instead of downloading the CD. I haven't heard there is a problem
>> with Fedora's new RPMs but that doesn't prove that there aren't any. I
>> fully agree with Martyn Plummer's readme notice that describes Fedora
>> Core as bleeding edge technology not to be trusted for production use.
>> Fedora Core describes itself that way.
>
> Do you mean the shared library libR.so? If so, the README in the FC3
> section indicates that these rpms now include the functionality you
> require. The absence of a README in the FC4 section means it is not
> clear from there if these rpms are also compiled with the shared
> library.

They almost certainly are, for 2.1.1, since they are compiled from the 
same spec file.

>> From Peter's email, it would seem that the maintainer of the R rpm for
> Extras continues to use the compiler flags that cause the problems
> previously described (I haven't confirmed that this is still the case
> mind you).

It is confirmed not the case for R-devel, but is for 2.1.1 which is 
what the RPMs are for.

> Although FC4 is bleeding edge, I've had very few problems with in on my
> new laptop or my home desktop - after initial gcc v4.0.0 and gfortran
> teething troubles that is.

Although gcc 4.0.1 has helped, there are dozens of ongoing problems which 
seems squarely laid at the door of gfortran, as well as an appreciable 
performance loss.  On AMD64 there are subtle incompatibility issues 
between gfortran and everything else (g77, gcc3 and gcc4) that make mixing 
C and Fortran code tricky at best.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From afshart at exchange.sba.miami.edu  Sat Aug 20 18:04:57 2005
From: afshart at exchange.sba.miami.edu (Afshartous, David)
Date: Sat, 20 Aug 2005 12:04:57 -0400
Subject: [R] diagonal matrices
Message-ID: <6BCB4D493A447546A8126F24332056E80A77D1@school1.business.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050820/bbc5c458/attachment.pl

From ggrothendieck at gmail.com  Sat Aug 20 18:28:16 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 20 Aug 2005 12:28:16 -0400
Subject: [R] diagonal matrices
In-Reply-To: <6BCB4D493A447546A8126F24332056E80A77D1@school1.business.edu>
References: <6BCB4D493A447546A8126F24332056E80A77D1@school1.business.edu>
Message-ID: <971536df0508200928519d65dc@mail.gmail.com>

Have a look at adiag in the magic package.

On 8/20/05, Afshartous, David <afshart at exchange.sba.miami.edu> wrote:
> 
> Hello all,
> 
> I have matrices V.i  of dimension n.i x n.i, where i = 1, ..., J, and the  sum of n.i  equals N.  (and n.i ! = n.j)
> 
> goal: create one large matrix V, where V has matrices V.i on diagonal.
> 
> I create each matrix V.i in a for loop (1 to J), so each time I'd like to augment V with the
> most recently calculated V.i, such that I'll have V after the final iteration of the for loop.
> 
> question: how to initialize V and do the augmentation.   any advice much appreciated.
> 
> cheers,
> dave
> 
> ps - please respond directly to afshar at miami.edu, thanks!
> 
> 
> 
>        [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From MSchwartz at mn.rr.com  Sat Aug 20 17:52:38 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Sat, 20 Aug 2005 10:52:38 -0500
Subject: [R] Determining physical display dimensions
In-Reply-To: <de57o3$250$1@sea.gmane.org>
References: <200508191747.j7JHlEBV017029@faraday.gene.com>
	<de57o3$250$1@sea.gmane.org>
Message-ID: <1124553159.28455.40.camel@localhost.localdomain>

On Fri, 2005-08-19 at 13:17 -0500, Earl F. Glynn wrote: 
> "Berton Gunter" <gunter.berton at gene.com> wrote in message
> news:200508191747.j7JHlEBV017029 at faraday.gene.com...
> 
> > Failing that, (how) can this be done for Windows (XP or 2000, say) ?
> 
> Take a look at the Windows GetDeviceCaps API call
> http://msdn.microsoft.com/library/default.asp?url=/library/en-us/gdi/devcons_88s3.asp
> 
> Parameters that can be queried include:
> HORZRES  Width, in pixels, of the screen.
> VERTRES Height, in raster lines, of the screen.
> 
> HORZSIZE Width, in millimeters, of the physical screen
> VERTSIZE  Height, in millimeters, of the physical screen
> 
> The specifics of how to use this API call will vary by language.  Google
> will be your friend.


FWIW, in case anyone should see this thread and wonder how to do this
somewhat easily in R for systems running X, there is a CLI utility
called 'xdpyinfo' that returns a great deal of data on the connected
display(s).


> display.size <- system("xdpyinfo | grep dimensions", intern = TRUE)
> display.dpi <- system("xdpyinfo | grep resolution", intern = TRUE)

> display.size
[1] "  dimensions:    1600x1200 pixels (301x231 millimeters)"

> display.dpi
[1] "  resolution:    135x132 dots per inch"


One can then parse the above using R functions as required. Such as:

> d.size <- unlist(strsplit(display.size, split = "[[:space:]|(|)|x]"))

> d.size
[1] ""            ""            "dimensions:" ""
[5] ""            ""            "1600"        "1200"
[9] "pi"          "els"         ""            "301"
[13] "231"         "millimeters" 


> h.pix <- as.numeric(d.size[7])
> v.pix <- as.numeric(d.size[8])

> h.mm <- as.numeric(d.size[12])
> v.mm <- as.numeric(d.size[13])


> line1 <- sprintf("The current display is %d x %d pixels", 
                    h.pix, v.pix)


> line2 <- sprintf("with a physical size of %d x %d mm", h.mm, v.mm)


> cat(line1, line2, sep = "\n")
The current display is 1600 x 1200 pixels
with a physical size of 301 x 231 mm


This can get more complicated with multi-monitor systems, depending upon
whether you are running in xinerama (multi-monitor spanning mode) or
non-xinerama mode and consideration for symmetric or asymmetric
resolutions. 'man xdpyinfo' and 'man X' (noting the 'DISPLAY'
environment variable) will be helpful here to determine which
display/screen R is running on.

For example, on my system which has two displays, each with 1600x1200, I
get:

> Sys.getenv("DISPLAY")
DISPLAY
 ":0.0"

with R running on the main laptop LCD (15" diag), versus:

> Sys.getenv("DISPLAY")
DISPLAY
 ":0.1"

with R running on the external LCD (20.1" diag), with the DISPLAY
variable indicating:

":DisplayNumber.ScreenNumber"


Thus, on my system, the output of the system() calls are actually:

> display.size <- system("xdpyinfo | grep dimensions", intern = TRUE)
> display.dpi <- system("xdpyinfo | grep resolution", intern = TRUE)

> display.size
[1] "  dimensions:    1600x1200 pixels (301x231 millimeters)"
[2] "  dimensions:    1600x1200 pixels (411x311 millimeters)"

> display.dpi
[1] "  resolution:    135x132 dots per inch"
[2] "  resolution:    99x98 dots per inch"


HTH,

Marc Schwartz



From ripley at stats.ox.ac.uk  Sat Aug 20 19:09:57 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 20 Aug 2005 18:09:57 +0100 (BST)
Subject: [R] diagonal matrices
In-Reply-To: <6BCB4D493A447546A8126F24332056E80A77D1@school1.business.edu>
References: <6BCB4D493A447546A8126F24332056E80A77D1@school1.business.edu>
Message-ID: <Pine.LNX.4.61.0508201803320.6981@gannet.stats>

On Sat, 20 Aug 2005, Afshartous, David wrote:

> I have matrices V.i of dimension n.i x n.i, where i = 1, ..., J, and the 
> sum of n.i equals N.  (and n.i ! = n.j)
>
> goal: create one large matrix V, where V has matrices V.i on diagonal.
>
> I create each matrix V.i in a for loop (1 to J), so each time I'd like 
> to augment V with the most recently calculated V.i, such that I'll have 
> V after the final iteration of the for loop.
>
> question: how to initialize V and do the augmentation.  any advice much 
> appreciated.

It is probably best to pre-create a matrix and fill in the blocks.  As in

V <- matrix(0, N, N)
# let n be a vector of what you called n.i
n0 <- c(0, cumsum(n))
for(i in 1:J) {
    ind <- (n0[i]+1):n0[i+1]
    V[ind, ind] <- V.i
}

>
> cheers,
> dave
>
> ps - please respond directly to afshar at miami.edu, thanks!

Please set that as your reply address to ease the lot of your helpers.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Sat Aug 20 23:58:04 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 20 Aug 2005 23:58:04 +0200
Subject: [R] repeated - R package - Compilation Error
In-Reply-To: <15783.128.147.28.3.1123766714.squirrel@webmail.pitt.edu>
References: <53921.128.147.28.3.1123701284.squirrel@webmail.pitt.edu>
	<Pine.LNX.4.61.0508102021460.31951@gannet.stats>
	<14058.128.147.28.3.1123764485.squirrel@webmail.pitt.edu>
	<14187.128.147.28.3.1123764849.squirrel@webmail.pitt.edu>
	<14433.128.147.28.3.1123765252.squirrel@webmail.pitt.edu>
	<42FB4F56.8080501@gsf.de>
	<15783.128.147.28.3.1123766714.squirrel@webmail.pitt.edu>
Message-ID: <17159.42860.586158.977292@stat.math.ethz.ch>

>>>>> "rab45" == rab45  <rab45>
>>>>>     on Thu, 11 Aug 2005 09:25:14 -0400 (EDT) writes:

     .................

    rab45> I'm not sure what your point is. I'm getting a compilation error for a
    rab45> package that should compile without errors. The error message doesn't say
    rab45> anything about needing anything - it doesn't complain about
    rab45> "dependencies." Now once I got repeated to compile, it did give a
    rab45> *warning" message about needing rmutils. But rmutils won't compile and
    rab45> gives several error messages (in my other post). I've installed many R
    rab45> packages and I've never seen problems like this before.

well, probably the others where CRAN or bioconductor packages ?

You know, there *is* a reason why we (actually, the repository
maintainers) require that a package runs  "R CMD check" without
a warning.  
If package authors are not willing to clean up and document
their code well enough to be accepted by CRAN,  you have to
expect hardship when trying to install / use the package....

Martin Maechler



From valderama at gmail.com  Sun Aug 21 10:36:20 2005
From: valderama at gmail.com (Laurent Valdes)
Date: Sun, 21 Aug 2005 10:36:20 +0200
Subject: [R] Warning when using 'prelim.mix' from the package 'mix'
Message-ID: <3ef00e160508210136482755a9@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050821/1e1e742b/attachment.pl

From Ted.Harding at nessie.mcc.ac.uk  Sun Aug 21 12:18:42 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Sun, 21 Aug 2005 11:18:42 +0100 (BST)
Subject: [R] Warning when using 'prelim.mix' from the package 'mix'
In-Reply-To: <3ef00e160508210136482755a9@mail.gmail.com>
Message-ID: <XFMail.050821111842.Ted.Harding@nessie.mcc.ac.uk>

On 21-Aug-05 Laurent Valdes wrote:
> 'sodexquan' is an data frame of numeric variables with some missing
> values.
> I would like to approximate these missing values using some algorithm.
> I thereby chose the mix package.
> But when trying to run the 'prelim.mix' function (aka the function that
> will prepare the data for further calculations), R says:
> 
> prelim.mix(truc,0)
> Error in as.integer.default(list(c(32, 52, 32, 27, 34, 35, 35, 28, 42,
>: 
> the object (list) can't be converted in 'integer'
> 
> I roughly translated the word in english, because it was localized in 
> french.
> 
> I would like to correct this.
> 
> Laurent

Read the documentation for 'mix' carefully: The data supplied MUST
be a MATRIX (as well as satisfying other conditions on the structure
such as having the "categorical" variables leftmost in the columns
with levels coded as successive integers from "1" upwards).

While it is not clear from your description what you precisely did
(where does that thing called "truc" -- perhaps best translated into
English as "thingummy" -- come from, and what sort of thingummy is
it supposed to be?), the result of your attempt suggests that you may
have passed a dataframe to 'prelim.mix', and this will not work.

You must first convert it to a matrix.

You may, however, have violated some other requirement, such as the
requirement that the columns for categorical variables may contain
only integers.

Another thing to note is that in the call

  prelim.mix(some.matrix,p)

the integer "p" is the number of categorical variables (corresponding
to the first p columns of "some.matrix", and it is a fact about
the 'mix' package that p must be at least 1: it will not work if
p = 0.

Apart from the requirement that p >= 1, all of the above information
is available from ?prelim.mix

Overall, what you have stated suggests that you may have tried to
use 'mix' for data consisting of "continuous" variables with
some missing values (implied by your use of "p=0"). As pointed
out above, this will not work -- 'mix' is for use with data which
contain both "categorical" and "continuous" variables, using a
multinomial model for the combinations of levels of the former,
and a multivariate normal model for the latter with means conditional
on the factor levels of the former.

If you have data which consist entirely of variables of one kind
only, with some missing values, then you should use a different
package: 'cat' if all the variables are "categorical", 'norm' if
all the variables are "continuous".

The package 'mix' will not, for instance, recognise that "p=0"
means that all variables are continuous and consequently use
'norm' instead; nor recognise that "p = number of columns"
means that all variables are categorical and use 'cat' instead.
You have to make that choice yourself.

Hoping this helps,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 21-Aug-05                                       Time: 11:18:33
------------------------------ XFMail ------------------------------



From dadler at uni-goettingen.de  Sun Aug 21 16:30:45 2005
From: dadler at uni-goettingen.de (Daniel Adler)
Date: Sun, 21 Aug 2005 16:30:45 +0200
Subject: [R] [R-pkgs] RGL v0.65
Message-ID: <14ce7bc2a2d0dd85e6b9e92332b528ec@uni-goettingen.de>

RGL Version 0.65 [r405 / 2005-08-14]

DESCRIPTION
The RGL package is a visualization device system for R, using
OpenGL as the rendering backend. An rgl device at its core
is a real-time 3D engine written in C++. It provides an
interactive viewpoint navigation facility (mouse + wheel support)
and an R programming interface.

RELEASE INFO
This is a Beta release. We target a stable release at the end of 
September 2005.

WHATS NEW
* A native Mac OS X / Carbon version is shipped with this release.
   No need to start an X11 Server.
   The X11 Port is still available, but configure defaults to use Carbon.

* The X11 port has been improved. The crash (using rgl.close() or 
rgl.quit()
   has been fixed.

* User-selectable mouse handlers featuring trackball navigation and
   interactive selection.

* A new interface concept "R3D" is available for preview and discussion
   using the function name pattern:
     XXX3d()

   The functions map to rgl functions internally (with some exceptions).

   Here's a short list of interesting spots in the interface API:

   * par3d() can be used to get/set values on the current RGL device.

   * Primitives functions such as points3d(), lines3d(), surface3d(), ...

   * First bunch of generic transformation utilities, rendering methods
     and mesh objects are implemented.

   The rgl interface using the pattern "rgl.XXX()" is still available.
   You can decide between more OpenGL/RGL'is low-level functions or
   more R'ish functions using the R3D interface concept.

* Rendering of blended surfaces using hierarchical z-sorting.

* New material property: Texture environment mapping

WEBSITE
http://rgl.neoscientists.org

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From jamatos at fc.up.pt  Sun Aug 21 17:56:36 2005
From: jamatos at fc.up.pt (=?UTF-8?B?Sm9zw6k=?= Matos)
Date: Sun, 21 Aug 2005 16:56:36 +0100
Subject: [R] problems when installing R in Fedora core 4
References: <a922041d05081806313a98cc87@mail.gmail.com>
Message-ID: <dea87k$n34$1@sea.gmane.org>

Peter Yang wrote:

> Hi, I got a problem when installing R in Fedora core 4. When I ran
> .configure, it gave the following error message:
> 
> configure: error: --with-x=yes (default) and X11 headers/libs are not
> available
> 
> Could anyone tell me what's wrong? Am I missing some package in Fedora?

  Assuming that you have network access on that computer, installing R
should be as easy as:

# yum install R

  This works since R is now in extras. If you have any problems with this
please say.

  I intend to package also some other packages from contrib, they should
appear on extras soon.

> Thanks a lot for your help.
> 
> Peter

-- 
JosÃ© AbÃ­lio



From jamatos at fc.up.pt  Sun Aug 21 18:16:47 2005
From: jamatos at fc.up.pt (=?UTF-8?B?Sm9zw6k=?= Matos)
Date: Sun, 21 Aug 2005 17:16:47 +0100
Subject: [R] Advice about system for installing & updating all R package
	in a Linux Lab?
References: <43064DD2.40109@ku.edu>
Message-ID: <dea9df$pt4$1@sea.gmane.org>

Paul Johnson wrote:

> Good day:
> 
> I'm administering 6 linux systems (FC4) in a student lab and worry that
> users may want packages that are not installed.  I get tired of adding
> them one by one.

  One other option is if those packages get in Fedora Extras. :-)
  I intend to submit some packages to FE, and then upgrading will be a lot
easier.

  What are the packages that interest you?

-- 
JosÃ© AbÃ­lio



From mkalisiak at gmail.com  Sun Aug 21 18:22:56 2005
From: mkalisiak at gmail.com (Maciej Kalisiak)
Date: Sun, 21 Aug 2005 12:22:56 -0400
Subject: [R] plot(type="h") equivalent in Lattice?
In-Reply-To: <eb555e66050819215853b8e30d@mail.gmail.com>
References: <78e6ba31050819172827bfd354@mail.gmail.com>
	<eb555e66050819215853b8e30d@mail.gmail.com>
Message-ID: <78e6ba310508210922472def0d@mail.gmail.com>

Ah, great, thanks.  I've actually ran into it just before I saw your
posting, purely by accident, when I happened to look at the source for
panel.xyplot while looking for something else, and noticed the "type"
argument, and in particular the handling of type='h'... I didn't
realize plot(type='h'...) makes use of plot.xy(), otherwise the
plot.xy(graphics)->xyplot(lattice) move would have been obvious...

-- 
Maciej Kalisiak
<mkalisiak at gmail.com>
http://www.dgp.toronto.edu/~mac



From dmbates at gmail.com  Sun Aug 21 18:39:38 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Sun, 21 Aug 2005 11:39:38 -0500
Subject: [R] Error messages using LMER
In-Reply-To: <40e66e0b050818105218618be6@mail.gmail.com>
References: <5abc11d805081801152c1f6661@mail.gmail.com>
	<40e66e0b0508180659447f8321@mail.gmail.com>
	<5abc11d805081810311689b8ee@mail.gmail.com>
	<5abc11d805081810417a76aaaf@mail.gmail.com>
	<40e66e0b050818105218618be6@mail.gmail.com>
Message-ID: <40e66e0b0508210939446e67a2@mail.gmail.com>

Several people have been helping examine the cause of the warning
message about Code(27).  The latest message from Duncan Murdoch said
that he encounters the warning when using an older compiler but now
when using the latest compiler.  I hope this means that a new version
of R-devel compiled for Windows does not show this behavior.

On 8/18/05, Douglas Bates <dmbates at gmail.com> wrote:
> Thanks for including all of that output.  
> 
> I believe that in this version the parameters are the relative
> variances.  This would indicate that somehow you are getting fits with
> very low residual sums of squares in the weighted least squares
> problem.  It could be that you have too many fixed effects terms in
> the model and are getting complete separation.
> 
> On 8/18/05, Shige Song <shigesong at gmail.com> wrote:
> > Here is what happened using R-devel:
> > 
> > -------------------------------------------------------------
> >   EM iterations
> >   0 85289.766 ( 5407.13:  0.0815) ( 26134.4: 0.00387)
> >   1 84544.322 ( 333.732:   0.137) ( 1462.32: 0.00934)
> >   2 84515.108 ( 129.506:  0.0270) ( 446.306: 0.00481)
> >   3 84514.519 ( 115.592: 0.00355) ( 328.637: 0.00103)
> >   4 84514.505 ( 113.981:0.000505) ( 311.160:0.000165)
> >   5 84514.505 ( 113.755:7.45e-005) ( 308.524:2.50e-005)
> >   6 84514.505 ( 113.722:1.11e-005) ( 308.128:3.77e-006)
> >   7 84514.505 ( 113.717:1.66e-006) ( 308.068:5.66e-007)
> >   8 84514.505 ( 113.716:2.50e-007) ( 308.059:8.49e-008)
> >   9 84514.505 ( 113.716:3.74e-008) ( 308.058:1.27e-008)
> >  10 84514.505 ( 113.716:5.62e-009) ( 308.058:1.91e-009)
> >  11 84514.505 ( 113.716:8.43e-010) ( 308.058:2.87e-010)
> >  12 84514.505 ( 113.716:1.27e-010) ( 308.058:4.31e-011)
> >  13 84514.505 ( 113.716:1.90e-011) ( 308.057:6.47e-012)
> >  14 84514.505 ( 113.716:2.86e-012) ( 308.057:9.73e-013)
> >  15 84514.505 ( 113.716:4.25e-013) ( 308.057:1.44e-013)
> >   EM iterations
> >   0 83740.342 ( 113.716: -0.0164) ( 308.057:0.000596)
> >   1 83740.273 ( 121.512:-0.00121) ( 298.914:-3.24e-005)
> >   2 83740.272 ( 122.131:-0.000111) ( 299.397:-1.24e-005)
> >   EM iterations
> >   0 84011.546 ( 122.131:-0.00474) ( 299.397:-0.000265)
> >   1 84011.539 ( 124.616:-0.000472) ( 303.415:-6.62e-005)
> >   2 84011.539 ( 124.869:-5.58e-005) ( 304.433:-1.16e-005)
> >   EM iterations
> >   0 84018.589 ( 124.869:-0.000139) ( 304.433:-1.81e-005)
> >   1 84018.589 ( 124.944:-1.62e-005) ( 304.713:-3.26e-006)
> >   2 84018.589 ( 124.953:-2.12e-006) ( 304.764:-5.23e-007)
> >   EM iterations
> >   0 84018.611 ( 124.953:-2.38e-006) ( 304.764:-5.44e-007)
> >   1 84018.611 ( 124.954:-3.25e-007) ( 304.772:-8.50e-008)
> >   2 84018.611 ( 124.955:-4.66e-008) ( 304.773:-1.29e-008)
> >   EM iterations
> >   0 84018.611 ( 124.955:-4.75e-008) ( 304.773:-1.30e-008)
> >   1 84018.611 ( 124.955:-6.93e-009) ( 304.774:-1.97e-009)
> >   2 84018.611 ( 124.955:-1.03e-009) ( 304.774:-2.96e-010)
> > Warning messages:
> > 1: optim or nlminb returned message See PORT documentation.  Code (27)
> >  in: LMEopt(x = mer, value = cv)
> > 2: optim or nlminb returned message See PORT documentation.  Code (27)
> >  in: LMEopt(x = mer, value = cv)
> > 3: optim or nlminb returned message See PORT documentation.  Code (27)
> >  in: LMEopt(x = mer, value = cv)
> > 4: optim or nlminb returned message See PORT documentation.  Code (27)
> >  in: LMEopt(x = mer, value = cv)
> > 5: optim or nlminb returned message See PORT documentation.  Code (27)
> >  in: LMEopt(x = mer, value = cv)
> > 6: optim or nlminb returned message See PORT documentation.  Code (27)
> >  in: LMEopt(x = mer, value = cv)
> > 7: nlminb failed to converge in: lmer(.D ~ offset(log(.Y)) + (1 |
> > provn) + (1 | bcohort) + agri +
> > -------------------------------------------------------------
> > 
> > Shige
> > 
> > On 8/19/05, Shige Song <shigesong at gmail.com> wrote:
> > > Dear Professor Bates,
> > >
> > > Here is output R 2.1.1 produced with "control = list(EMverbose = TRUE,
> > > msVerbose = TRUE)". I am getting the new devel version and see what
> > > will hapen there:
> > >
> > >
> --------------------------------------------------------------------------------
> > >  EM iterations
> > >  0 85289.766 ( 5407.13:  0.0815) ( 26134.4: 0.00387)
> > >  1 84544.322 ( 333.732:   0.137) ( 1462.32: 0.00934)
> > >  2 84515.108 ( 129.506:  0.0270) ( 446.306: 0.00481)
> > >  3 84514.519 ( 115.592: 0.00355) ( 328.637: 0.00103)
> > >  4 84514.505 ( 113.981:0.000505) ( 311.160:0.000165)
> > >  5 84514.505 ( 113.755:7.45e-005) ( 308.524:2.50e-005)
> > >  6 84514.505 ( 113.722:1.11e-005) ( 308.128:3.77e-006)
> > >  7 84514.505 ( 113.717:1.66e-006) ( 308.068:5.66e-007)
> > >  8 84514.505 ( 113.716:2.50e-007) ( 308.059:8.49e-008)
> > >  9 84514.505 ( 113.716:3.74e-008) ( 308.058:1.27e-008)
> > >  10 84514.505 ( 113.716:5.62e-009) ( 308.058:1.91e-009)
> > >  11 84514.505 ( 113.716:8.43e-010) ( 308.058:2.87e-010)
> > >  12 84514.505 ( 113.716:1.27e-010) ( 308.058:4.31e-011)
> > >  13 84514.505 ( 113.716:1.90e-011) ( 308.057:6.47e-012)
> > >  14 84514.505 ( 113.716:2.86e-012) ( 308.057:9.73e-013)
> > >  15 84514.505 ( 113.716:4.25e-013) ( 308.057:1.44e-013)
> > > iter    0 value 84514.505044
> > > final  value 84514.505044
> > > converged
> > >  EM iterations
> > >  0 83740.342 ( 113.716: -0.0164) ( 308.057:0.000596)
> > >  1 83740.273 ( 121.512:-0.00121) ( 298.914:-3.24e-005)
> > >  2 83740.272 ( 122.131:-0.000111) ( 299.397:-1.24e-005)
> > > iter    0 value 83740.272232
> > > final  value 83740.272232
> > > converged
> > >  EM iterations
> > >  0 84011.550 ( 122.204:-0.00461) ( 299.576:-0.000256)
> > >  1 84011.543 ( 124.624:-0.000459) ( 303.453:-6.41e-005)
> > >  2 84011.543 ( 124.870:-5.42e-005) ( 304.440:-1.13e-005)
> > > iter    0 value 84011.543350
> > > final  value 84011.543350
> > > converged
> > >  EM iterations
> > >  0 84018.592 ( 124.915:-6.44e-005) ( 304.548:-1.22e-005)
> > >  1 84018.592 ( 124.949:-8.29e-006) ( 304.737:-1.99e-006)
> > >  2 84018.592 ( 124.954:-1.15e-006) ( 304.768:-3.08e-007)
> > > iter    0 value 84018.591624
> > > final  value 84018.591624
> > > converged
> > >  EM iterations
> > >  0 84018.612 ( 124.955:3.40e-007) ( 304.770:-1.98e-007)
> > >  1 84018.612 ( 124.955:-9.98e-009) ( 304.773:-2.23e-008)
> > >  2 84018.612 ( 124.955:-5.47e-009) ( 304.774:-2.86e-009)
> > > iter    0 value 84018.611512
> > > final  value 84018.611512
> > > converged
> > > Error in fn(par, ...) : Unable to invert singular factor of downdated
> X'X
> > > In addition: Warning message:
> > > Leading minor of size 8 of downdated X'X is indefinite
> > >
> --------------------------------------------------------------------------------
> > >
> > > Thanks!
> > >
> > > Shige
> > >
> > > On 8/18/05, Douglas Bates <dmbates at gmail.com> wrote:
> > > > On 8/18/05, Shige Song <shigesong at gmail.com> wrote:
> > > > > Dear All,
> > > > >
> > > > > After playing with lmer for couple of days, I have to say that I am
> > > > > amazed! I've been using quite some multilevel/mixed modeling
> packages,
> > > > > lme4 is a strong candidate for the overall winner, especially for
> > > > > multilevel generzlized linear models.
> > > > >
> > > > > Now go back to my two-level poisson model with cross-classified
> model.
> > > > > I've been testing various different model specificatios for the
> past
> > > > > couple of days. Here are the models I tried:
> > > > >
> > > > > 1) Two level random intercept model with level-1 covariates only
> > > > > m1 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2
> ,
> > > > > data, poisson, method="Laplace")
> > > > >
> > > > > 2) Two-level random intercept model with both level-1 and level-2
> > > > > covariates, but no cross-level interactions:
> > > > > m2 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2
> +
> > > > > z1 + z2, data, poisson, method="Laplace")
> > > > >
> > > > > 3) Two-level random intercept with cross-level interaction
> > > > > m3 <- lmer(.D ~ offset(log(.Y)) + (1|provn) +(1|bcohort) + x1 + x2
> +
> > > > > z1 + z2 + x1:z1 + x2:z2, data, poisson, method="Laplace")
> > > > >
> > > > > Both model 1 and 2 run fine. For model 3, I got error message:
> > > > > ----------------------------------
> > > > > Error in fn(par, ...) : Unable to invert singular factor of
> downdated X'X
> > > > > In addition: Warning messages:
> > > > > 1: optim or nlminb returned message ERROR:
> ABNORMAL_TERMINATION_IN_LNSRCH
> > > > >  in: LMEopt(x = mer, value = cv)
> > > > > 2: Leading minor of size 1 of downdated X'X is indefinite
> > > > > ----------------------------------
> > > > >
> > > > > What is going on here? Any workarounds? Thanks!
> > > >
> > > > The first thing I would try is set the EMverbose and msVerbose flags
> > > > in the control list to see what occurs within the optimization.  That
> > > > is append the argument
> > > >
> > > > control = list(EMverbose = TRUE, msVerbose = TRUE)
> > > >
> > > > to your call to lmer().  You may also want to try the call in a
> > > > recently compiled R-devel, which will be released as R-2.2.0 in
> > > > October.  You will notice that the first warning message reads "optim
> > > > or nlminb". In R-2.1.1 lmer uses optim for the optimization. 
> Starting
> > > > with R-2.2.0 the default is to use nlminb.
> > > >
> > > > Test compilations of R-devel for Windows are available from CRAN.
> > > >
> > >
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
>



From rab45+ at pitt.edu  Sun Aug 21 21:50:49 2005
From: rab45+ at pitt.edu (rab45+@pitt.edu)
Date: Sun, 21 Aug 2005 15:50:49 -0400 (EDT)
Subject: [R] repeated - R package - Compilation Error
In-Reply-To: <17159.42860.586158.977292@stat.math.ethz.ch>
References: <53921.128.147.28.3.1123701284.squirrel@webmail.pitt.edu>
	<Pine.LNX.4.61.0508102021460.31951@gannet.stats>
	<14058.128.147.28.3.1123764485.squirrel@webmail.pitt.edu>
	<14187.128.147.28.3.1123764849.squirrel@webmail.pitt.edu>
	<14433.128.147.28.3.1123765252.squirrel@webmail.pitt.edu>
	<42FB4F56.8080501@gsf.de>
	<15783.128.147.28.3.1123766714.squirrel@webmail.pitt.edu>
	<17159.42860.586158.977292@stat.math.ethz.ch>
Message-ID: <58238.136.142.100.173.1124653849.squirrel@webmail.pitt.edu>

>>>>>> "rab45" == rab45  <rab45>
>>>>>>     on Thu, 11 Aug 2005 09:25:14 -0400 (EDT) writes:
>
>      .................
>
>     rab45> I'm not sure what your point is. I'm getting a compilation
> error for a
>     rab45> package that should compile without errors. The error message
> doesn't say
>     rab45> anything about needing anything - it doesn't complain about
>     rab45> "dependencies." Now once I got repeated to compile, it did give
> a
>     rab45> *warning" message about needing rmutils. But rmutils won't
> compile and
>     rab45> gives several error messages (in my other post). I've installed
> many R
>     rab45> packages and I've never seen problems like this before.
>
> well, probably the others where CRAN or bioconductor packages ?
>
> You know, there *is* a reason why we (actually, the repository
> maintainers) require that a package runs  "R CMD check" without
> a warning.
> If package authors are not willing to clean up and document
> their code well enough to be accepted by CRAN,  you have to
> expect hardship when trying to install / use the package....
>
> Martin Maechler
>


I think the real problem is that Fedora Core 4 has switched from f77 to
gfortran.

Rick B.



From spencer.graves at pdf.com  Mon Aug 22 06:08:58 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sun, 21 Aug 2005 21:08:58 -0700
Subject: [R] Overall Legend
In-Reply-To: <001301c5a1fc$1622b110$769b300a@hsrcenter.local>
References: <001301c5a1fc$1622b110$769b300a@hsrcenter.local>
Message-ID: <43094FDA.2060602@pdf.com>

	  Since I haven't seen a reply to this post, I will attempt one.  Have 
you considered something like the following:

opar <- par(mfrow=c(2,2))

plot(1:2)
lines(2:1, col="blue")
legend("top", legend=c("black", "blue"),
        text.col=c("black", "blue"))
# with a legend on one of the four plots

plot(3:4)
plot(5:6, col="blue")

# Or using mtext to construct a legend in the outer margin
mtext("black", side=3,line=-2, at=.4, outer=TRUE,col="black")
mtext("blue", side=3,line=-2, at=.6, outer=TRUE,col="blue")

par(opar)

##############
RSiteSearch("one legend for multiple plots") identified the following
that discusses placing a single legend with trellis graphics:

http://finzi.psych.upenn.edu/R/Rhelp02a/archive/1834.html

	  Also, have you checked Venables and Ripley (2002) Modern Applied 
Statistics with S (Springer)?  I don't have a copy handy, but if my 
memory is correct, they have something relevant to this question.

	  Perhaps someone else will reply with better information than this.
	  spencer graves

Juned Siddique wrote:

> Hello. I am using R version 2.1.1 on Windows 2000.
> 
> I am using a par(mfrow=c(2,2)) statement to produce 4 plots on one screen. 
I want a single horizontal legend to appear at the top of the four plots.
My code is something like this:
> 
> par(mfrow=c(2,2))
> 
> plot(x,y1)
> lines(x,y2)
> lines(x,y3)
> 
> plot(x,z1)
> lines(x,z2)
> lines(x,z3)
> 
> plot(x,t1)
> lines(x,t2)
> lines(x,t3)
> 
> plot(x,w1)
> lines(x,w2)
> lines(x,w3)
> 
> Instead of the statement:
> legend(x="right", c("Bias Squared","Variance","Mean Squared Error"), 
lty=c(2,1,3), col=c("green","blue","red"), lwd="2",cex=0.5,inset = 0.05)
> 
> appearing within each plot, I would like it to appear at the top of 
the graph because it applies to all four plots. Any help would be
appreciated. Thank you.
> 
> -Juned
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From petr.pikal at precheza.cz  Mon Aug 22 06:40:45 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Mon, 22 Aug 2005 06:40:45 +0200
Subject: [R] A. Mani : Avoiding loops
In-Reply-To: <200508200326.12336.a_mani_sc_gs@vsnl.net>
References: <8ed68eed050818232461686a57@mail.gmail.com>
Message-ID: <4309736D.354.1B6686@localhost>



On 20 Aug 2005 at 3:26, A. Mani wrote:

> On Friday 19 August 2005 11:54, Sean O'Riordain wrote:
> > Hi,
> > I'm not sure what you actually want from your email (following the
> > posting guide is a good way of helping you explain things to the
> > rest of us in a way we understand - it might even answer your
> > question!
> >
> > I'm only a beginner at R so no doubt one of our expert colleagues
> > will help me...
> >
> > > fred <- data.frame()
> > > fred <- edit(fred)
> > > fred
> >
> >   A B C D E
> > 1 1 2 X Y 1
> > 2 2 3 G L 1
> > 3 3 1 G L 5
> >
> > > fred[,3]
> >
> > [1] X G G
> > Levels: G X
> >
> > > fred[fred[,3]=="G",]
> >
> >   A B C D E
> > 2 2 3 G L 1
> > 3 3 1 G L 5
> >
> > so at this point I can create a new dataframe with column 3 (C) ==
> > "G"; either explicitly or implicitly...
> >
> > and if I want to calculate the sum() of column E, then I just say
> > something like...
> >
> > > sum(fred[fred[,3]=="G",][,5])
> >
> > [1] 6
> >
> >
> > now naturally being a bit clueless at manipulating stuff in R, I
> > didn't know how to do this before I started... and you guys only get
> > to see the lines that I typed in and got a "successful" result...
> >
> > according to section 6 of the "Introduction to R" manual which comes
> > with R, I could also have said
> >
> > > sum(fred[fred$C=="G",]$E)
> >
> > [1] 6
> >
> > Hmmm.... I wonder would it be reasonable to put an example of this
> > type into section 2.7 of the "Introduction to R"?
> >
> >
> > cheers!
> > Sean
> >
> > On 18/08/05, A. Mani <a_mani_sc_gs at vsnl.net> wrote:
> > > Hello,
> > >         I want to avoid loops in the following situation. There is
> > >         a
> > > 5-col dataframe with col headers alone. two of the columns are
> > > non-numeric. The problem is to calculate statistics(scores) for
> > > each element of one column. The functions depend on matching in
> > > the other non-numeric column.
> > >
> > > A  B  C  E  F
> > > 1  2  X  Y  1
> > > 2  3  G  L  1
> > > 3  1  G  L  5
> > > and so on ...30000+ entries.
> > >
> > > I need scores for col E entries which depend on conditional
> > > implications.
> > >
> > >
> > > Thanks,
> > >
> Hello,
>       Sorry about the incomplete problem. Here is a better version for
>       the
> problem: (the measure is not simple)
> The data frame is like
>   col1       col2            col3       col4        col5
>   <num>  <nonum>   <nonum>      <num>   <num>
>        A           B             C                  E           F  
> There are repeated strings in col3, col2. Problem : Calculate 
> Measure(Ci) = [No. of repeats of Ci *100] + [If (Bi, Ci) is same as
> (Bj, Cj) and 6>= Ej - Ei >=3 then add 100 else  10] .

Hi

I am not sure what exactly you would like to compute, 
**working** example could help. But if you want to do some 
computation for row "i" which depends on row "j", I suppose that 
you can not avoid loops. 

Generally you can use one of aggregate, tapply, by or ave for some 
computation split by factor. See help pages.

tapply(vector or data frame, list(factors), function)

is the standard form.

HTH
Petr


> 
> 
> Actually it is to stretched further by adding similar blocks.
> 
>  How do we use *apply or
> something else in the situation  ?
> 
> 
> In prolog it is extremely easy, but here it is not quite...
> 
> 
> A. Mani
> Member, Cal. Math. Soc
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From ripley at stats.ox.ac.uk  Mon Aug 22 09:05:30 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 22 Aug 2005 08:05:30 +0100 (BST)
Subject: [R] repeated - R package - Compilation Error
In-Reply-To: <58238.136.142.100.173.1124653849.squirrel@webmail.pitt.edu>
References: <53921.128.147.28.3.1123701284.squirrel@webmail.pitt.edu>
	<Pine.LNX.4.61.0508102021460.31951@gannet.stats>
	<14058.128.147.28.3.1123764485.squirrel@webmail.pitt.edu>
	<14187.128.147.28.3.1123764849.squirrel@webmail.pitt.edu>
	<14433.128.147.28.3.1123765252.squirrel@webmail.pitt.edu>
	<42FB4F56.8080501@gsf.de>
	<15783.128.147.28.3.1123766714.squirrel@webmail.pitt.edu>
	<17159.42860.586158.977292@stat.math.ethz.ch>
	<58238.136.142.100.173.1124653849.squirrel@webmail.pitt.edu>
Message-ID: <Pine.LNX.4.61.0508220755440.31614@gannet.stats>

On Sun, 21 Aug 2005 rab45+ at pitt.edu wrote:

>>>>>>> "rab45" == rab45  <rab45>
>>>>>>>     on Thu, 11 Aug 2005 09:25:14 -0400 (EDT) writes:
>>
>>      .................
>>
>>     rab45> I'm not sure what your point is. I'm getting a compilation
>> error for a
>>     rab45> package that should compile without errors. The error message
>> doesn't say
>>     rab45> anything about needing anything - it doesn't complain about
>>     rab45> "dependencies." Now once I got repeated to compile, it did give
>> a
>>     rab45> *warning" message about needing rmutils. But rmutils won't
>> compile and
>>     rab45> gives several error messages (in my other post). I've installed
>> many R
>>     rab45> packages and I've never seen problems like this before.
>>
>> well, probably the others where CRAN or bioconductor packages ?
>>
>> You know, there *is* a reason why we (actually, the repository
>> maintainers) require that a package runs  "R CMD check" without
>> a warning.
>> If package authors are not willing to clean up and document
>> their code well enough to be accepted by CRAN,  you have to
>> expect hardship when trying to install / use the package....
>>
>> Martin Maechler
>
> I think the real problem is that Fedora Core 4 has switched from f77 to
> gfortran.

The REAL problem is that some packages are not written in standard 
Fortran.  Compare the issues you found with the Fortran standards (which 
can be found via http://developer.r-project.org/Portability.html).

Martin's point is that some of the R volunteers put a lot of effort into 
helping (cooperative) package authors avoid such portability problems, and 
that you should be grateful (and give due credit) for such work.

For further discussion see recent threads on the r-devel list, where this 
sort of thing belongs (do check the posting guide).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From laurent.buffat at free.fr  Mon Aug 22 10:32:24 2005
From: laurent.buffat at free.fr (laurent buffat)
Date: Mon, 22 Aug 2005 10:32:24 +0200
Subject: [R] mozilla/firefox search engine AMD64 jre1.5 plugin linux
Message-ID: <43098D98.6080308@free.fr>

Hi,
I have a problem with the "help.start()" and the search engine on a AMD64 :
The search engine use the java plugin but the java plugin is not 
available for the jre.1.5 ...

I have a linux box : fedora 4 on 64bit and R2.1.1
When I start the search engine, I had the message that the java plugin 
was missing.
So I try to install manual the java run time jre-1.5 for the AMD64, but 
the plugin was missing
( http://forum.java.sun.com/thread.jspa?threadID=568127&tstart=75 )
So I instaled the J2RE blackdown 1.4.2
I obtain the plugin for the 64bit and make the link.

When I restart R and the search engine, the plugin 1.4.2 correctly 
reconnize by mozilla
( about:plugins in the URL windows), and I don't have any more the 
message for the missing
plugin, but, then I try a search, mozilla freeze and I have to kill it :

####################
 > help.start()
Making links in per-session dir ...
If '/usr/bin/firefox' is already running, it is *not* restarted, and
    you must switch to its window.
Otherwise, be patient ...

UA: Mozilla/5.0 (X11; U; Linux x86_64; fr; rv:1.7.10) Gecko/20050720 
Fedora/1.0.6-1.1.fc4 Firefox/1.0.6:, extra:  Firefox/1.0.6

[root at panoramix ~]# ps -eaf | grep mozilla

root     13916 13899  0 09:40 pts/1 00:00:00 /bin/sh 
/usr/lib64/firefox-1.0.6 /run-mozilla.sh 
/usr/lib64/firefox-1.0.6/firefox-bin -UILocale fr-FR 
file:///tmp/Rtmpo13829/.R/doc/html/index.html

[root at panoramix ~]# kill 13916

[root at panoramix ~]# /usr/lib64/firefox-1.0.6/firefox: line 227: 13916 
Compl??t?? "$dist_bin/run-mozilla.sh" $script_args 
"$dist_bin/$MOZILLA_BIN" "$@      

#################

I am not a "system administrator" and It's my home computer (so no help ...)
So I need your help ;-)

- For the AMD64 R users : have you the same problem ?
- If yes : How you solve it ?
- If it's not possible to solve, is it possible to  find an alternative 
solution (like to acces of the search engine from an
other computer (windows, linux 32). I don't care about java plugin on 
the mozilla 64 bit, I just want the R help !!!

Thanks.
L. Buffat



From ripley at stats.ox.ac.uk  Mon Aug 22 11:55:04 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 22 Aug 2005 10:55:04 +0100 (BST)
Subject: [R] mozilla/firefox search engine AMD64 jre1.5 plugin linux
In-Reply-To: <43098D98.6080308@free.fr>
References: <43098D98.6080308@free.fr>
Message-ID: <Pine.LNX.4.61.0508221035410.1296@gannet.stats>

This is a 64-bit FC* issue.  I believe we did a year or so ago run i686 
firefox (from mozilla.org) and the Sun Java + plugin on AMD64 FC2.

Note that help.search() will do all that the HTML search engine does, and 
more.

On Windows, you would get help for a different version of R, but i686 
Linux would be fine.  The latter is our solution: we only use AMD64 
machines as servers.

On Mon, 22 Aug 2005, laurent buffat wrote:

> Hi,
> I have a problem with the "help.start()" and the search engine on a AMD64 :
> The search engine use the java plugin but the java plugin is not
> available for the jre.1.5 ...
>
> I have a linux box : fedora 4 on 64bit and R2.1.1
> When I start the search engine, I had the message that the java plugin
> was missing.
> So I try to install manual the java run time jre-1.5 for the AMD64, but
> the plugin was missing
> ( http://forum.java.sun.com/thread.jspa?threadID=568127&tstart=75 )
> So I instaled the J2RE blackdown 1.4.2
> I obtain the plugin for the 64bit and make the link.
>
> When I restart R and the search engine, the plugin 1.4.2 correctly
> reconnize by mozilla
> ( about:plugins in the URL windows), and I don't have any more the
> message for the missing
> plugin, but, then I try a search, mozilla freeze and I have to kill it :
>
> ####################
> > help.start()
> Making links in per-session dir ...
> If '/usr/bin/firefox' is already running, it is *not* restarted, and
>    you must switch to its window.
> Otherwise, be patient ...
>
> UA: Mozilla/5.0 (X11; U; Linux x86_64; fr; rv:1.7.10) Gecko/20050720
> Fedora/1.0.6-1.1.fc4 Firefox/1.0.6:, extra:  Firefox/1.0.6
>
> [root at panoramix ~]# ps -eaf | grep mozilla
>
> root     13916 13899  0 09:40 pts/1 00:00:00 /bin/sh
> /usr/lib64/firefox-1.0.6 /run-mozilla.sh
> /usr/lib64/firefox-1.0.6/firefox-bin -UILocale fr-FR
> file:///tmp/Rtmpo13829/.R/doc/html/index.html
>
> [root at panoramix ~]# kill 13916
>
> [root at panoramix ~]# /usr/lib64/firefox-1.0.6/firefox: line 227: 13916
> Compl?t? "$dist_bin/run-mozilla.sh" $script_args
> "$dist_bin/$MOZILLA_BIN" "$@
>
> #################
>
> I am not a "system administrator" and It's my home computer (so no help ...)
> So I need your help ;-)
>
> - For the AMD64 R users : have you the same problem ?
> - If yes : How you solve it ?
> - If it's not possible to solve, is it possible to  find an alternative
> solution (like to acces of the search engine from an
> other computer (windows, linux 32). I don't care about java plugin on
> the mozilla 64 bit, I just want the R help !!!
>
> Thanks.
> L. Buffat

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From phddas at yahoo.com  Mon Aug 22 12:06:58 2005
From: phddas at yahoo.com (Fred J.)
Date: Mon, 22 Aug 2005 03:06:58 -0700 (PDT)
Subject: [R] integration
Message-ID: <20050822100659.55241.qmail@web53907.mail.yahoo.com>

Hello

after reading few nodes from the info docs. I am not
sure  if this task can be done using R:
the density function f(x,y) = 12xy(1-y) for  
0<x<1, 0<y<1
the condition of inequality (x-y)> (1/2)
what if the limits of integration are functions of the
variable I am integrating over.
is this somthing which can be done in a simple way,
with R?
examples:
Mathimatic 5.1:
In[2]:=Integrate[12*x*y*(1-y)*Boole[x-y>1/2],{y,0,1},{x,0,1}]
Maple:
Doubleint(12*x*y*(1-y)*Heaviside(x-y-1/2),x=0..1,y=0..1);

many thanks



From ripley at stats.ox.ac.uk  Mon Aug 22 12:35:12 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 22 Aug 2005 11:35:12 +0100 (BST)
Subject: [R] integration
In-Reply-To: <20050822100659.55241.qmail@web53907.mail.yahoo.com>
References: <20050822100659.55241.qmail@web53907.mail.yahoo.com>
Message-ID: <Pine.LNX.4.61.0508221128180.1843@gannet.stats>

Numerical integration: yes.
Symbolic integration: no.

On Mon, 22 Aug 2005, Fred J. wrote:

> after reading few nodes from the info docs. I am not
> sure  if this task can be done using R:
> the density function f(x,y) = 12xy(1-y) for
> 0<x<1, 0<y<1
> the condition of inequality (x-y)> (1/2)
> what if the limits of integration are functions of the
> variable I am integrating over.
> is this somthing which can be done in a simple way,
> with R?
> examples:
> Mathimatic 5.1:
> In[2]:=Integrate[12*x*y*(1-y)*Boole[x-y>1/2],{y,0,1},{x,0,1}]
> Maple:
> Doubleint(12*x*y*(1-y)*Heaviside(x-y-1/2),x=0..1,y=0..1);

Symbolic integration: no.
Numerical integration: yes, e.g.

library(adapt)
adapt(2, c(0,0), c(1,1),
       functn=function(x) {y=x[2]; x=x[1]; 12*x*y*(1-y)*(x-y>1/2)})

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From abitbol at sent.com  Mon Aug 22 12:55:09 2005
From: abitbol at sent.com (Jean-Louis Abitbol)
Date: Mon, 22 Aug 2005 12:55:09 +0200
Subject: [R] reShape question
Message-ID: <1124708109.2288.241184568@webmail.messagingengine.com>

Dear R helpers,

The following output, from Hmisc reShape examples, illustrates how to
reshape from a data frame with repeated measures. 

I would need to do exactly the opposite ie get sbp1 to 3 and dbp1 to 3
from sbp and and dbp.

Is there a way to do that without subsetting,  renaming and binding ?

Many thanks for any help,

Regards, JL

> set.seed(33)
>      n <- 4
>      w <- data.frame(age=rnorm(n, 40, 10),
+                      sex=sample(c('female','male'), n,TRUE),
+                      sbp1=rnorm(n, 120, 15),
+                      sbp2=rnorm(n, 120, 15),
+                      sbp3=rnorm(n, 120, 15),
+                      dbp1=rnorm(n,  80, 15),
+                      dbp2=rnorm(n,  80, 15),
+                      dbp3=rnorm(n,  80, 15), row.names=letters[1:n])
>      options(digits=3)
>      w
   age    sex sbp1 sbp2 sbp3 dbp1 dbp2  dbp3
a 38.6 female  109  123  131 81.8 90.9  88.9
b 39.6 female  132  120  120 71.1 86.9 110.0
c 50.1   male  131  148  118 73.4 82.8  52.4
d 38.4 female  104  124  125 84.4 83.5  67.1
> reShape(w, base=c('sbp','dbp'), reps=3, timevar='week', times=c(0,3,12))
    week  age    sex sbp   dbp
a 1    0 38.6 female 109  81.8
a 2    3 38.6 female 123  90.9
a 3   12 38.6 female 131  88.9
b 1    0 39.6 female 132  71.1
b 2    3 39.6 female 120  86.9
b 3   12 39.6 female 120 110.0
c 1    0 50.1   male 131  73.4
c 2    3 50.1   male 148  82.8
c 3   12 50.1   male 118  52.4
d 1    0 38.4 female 104  84.4
d 2    3 38.4 female 124  83.5
d 3   12 38.4 female 125  67.1



From rn001 at cebas.csic.es  Mon Aug 22 13:54:59 2005
From: rn001 at cebas.csic.es (javier garcia - CEBAS)
Date: Mon, 22 Aug 2005 13:54:59 +0200
Subject: [R] time series plots: labels language & tickmarks
Message-ID: <20050822125613.D5224A7AC8@cebas.csic.es>

Hi all;

My native language is spanish and I would need to do two changes in the 
default xlabels in timeseries plots:

a) For timeseries that span more than one year, there are just xlabs and 
tickmarks for the beginning of each year. Could I add extra tick marks for 
each month easily? 

b) The xlabs appear in my language for months and days (spanish) but I need 
them in English, how can I change this setting?

Thanks and best regards,

Javier



From ripley at stats.ox.ac.uk  Mon Aug 22 14:04:11 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 22 Aug 2005 13:04:11 +0100 (BST)
Subject: [R] time series plots: labels language & tickmarks
In-Reply-To: <20050822125613.D5224A7AC8@cebas.csic.es>
References: <20050822125613.D5224A7AC8@cebas.csic.es>
Message-ID: <Pine.LNX.4.61.0508221259290.30919@gannet.stats>

On Mon, 22 Aug 2005, javier garcia - CEBAS wrote:

> My native language is spanish and I would need to do two changes in the
> default xlabels in timeseries plots:

What sort of plots are you talking about here?  (Not tsplot or plot.ts, 
for example.)  I think you are perhaps talking about plots of Dates.

> a) For timeseries that span more than one year, there are just xlabs and
> tickmarks for the beginning of each year. Could I add extra tick marks for
> each month easily?

See ?axis.Date, if this is about Dates.

> b) The xlabs appear in my language for months and days (spanish) but I need
> them in English, how can I change this setting?

Use R in an English locale.  (If as the posting guide asked you have told 
us your platform we could have told you how.  If you had shown us some 
reproducible code we would not have had to guess as to what you want to 
do.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gavin.simpson at ucl.ac.uk  Mon Aug 22 14:39:54 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Mon, 22 Aug 2005 13:39:54 +0100
Subject: [R] time series plots: labels language & tickmarks
In-Reply-To: <Pine.LNX.4.61.0508221259290.30919@gannet.stats>
References: <20050822125613.D5224A7AC8@cebas.csic.es>
	<Pine.LNX.4.61.0508221259290.30919@gannet.stats>
Message-ID: <1124714394.5604.25.camel@gsimpson.geog.ucl.ac.uk>

On Mon, 2005-08-22 at 13:04 +0100, Prof Brian Ripley wrote:
> On Mon, 22 Aug 2005, javier garcia - CEBAS wrote:
> 
> > My native language is spanish and I would need to do two changes in the
> > default xlabels in timeseries plots:
> 
> What sort of plots are you talking about here?  (Not tsplot or plot.ts, 
> for example.)  I think you are perhaps talking about plots of Dates.
> 
> > a) For timeseries that span more than one year, there are just xlabs and
> > tickmarks for the beginning of each year. Could I add extra tick marks for
> > each month easily?
> 
> See ?axis.Date, if this is about Dates.

If you want the ticks for months unlabelled, then axis.Date() in R v.
2.1.1 and 2.1.1-patched won't allow this. axis.Date() from R-devel
allows you to suppress the labelling of ticks - the change is trivial so
you could get the src of axis.Date for R-devel (e.g. it is here in the
subversion tree:

https://svn.r-project.org/R/trunk/src/library/graphics/R/datetime.R

and use that to create a my.axis.Date() and use this function explicitly
to add axes to your plot for the monthly ticks - until R 2.2.0 is
released anyway - using argument labels = FALSE to suppress the labels
for the monthly ticks.

HTH

G

> 
> > b) The xlabs appear in my language for months and days (spanish) but I need
> > them in English, how can I change this setting?
> 
> Use R in an English locale.  (If as the posting guide asked you have told 
> us your platform we could have told you how.  If you had shown us some 
> reproducible code we would not have had to guess as to what you want to 
> do.)
> 
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From marten.winter at ufz.de  Mon Aug 22 14:45:29 2005
From: marten.winter at ufz.de (Marten Winter)
Date: Mon, 22 Aug 2005 14:45:29 +0200
Subject: [R] vectors of different length in a matrix
Message-ID: <4309C8E9.3090804@ufz.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050822/3a6850b0/attachment.pl

From anne.piotet at gmail.com  Mon Aug 22 14:51:57 2005
From: anne.piotet at gmail.com (Anne)
Date: Mon, 22 Aug 2005 13:51:57 +0100
Subject: [R] translating output ( latex()....)
Message-ID: <80102e880508220551c6bb43f@mail.gmail.com>

Dear R-helpers

I need to produce statistical output where the annotations are in
French (and from time to time in German). I produce plots/tables using
extensively the latex() , summary.formula() ...functions of Hmisc
which allows me for nice print-out. Up to now I "corrected" manually
my latex code , replacing such headings as "missing" by "valeur
manquante" etc. Is there a (simple) way of updating the R functions
with the translated output? (I would of course gladly make it
available to the list)

I know my question will sound like an heresy to the vast majority of
statisticians and I agree it is a waste of statistician time to do
translations, but it is due to work related constraints (and I fear
the "anti-americanisme primaire" encountered in some european
countries)

-- 
Anne



From murdoch at stats.uwo.ca  Mon Aug 22 14:56:16 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 22 Aug 2005 08:56:16 -0400
Subject: [R] vectors of different length in a matrix
In-Reply-To: <4309C8E9.3090804@ufz.de>
References: <4309C8E9.3090804@ufz.de>
Message-ID: <4309CB70.1060707@stats.uwo.ca>

On 8/22/2005 8:45 AM, Marten Winter wrote:
> HI!
> 
> I?ve 3 vectors of different length (a,b,c) and want to arrange them in a 
> matrix a,b,c as rows and the figures of these vectors in the columns 
> (with that matrix i want to calculate a distance between thes vectors - 
> vegan - vegdist - horn). Is there a possibilty to create such a matrix 
> and to fill up the missing fields with NA?s automatically????

Filling with NA's is the hard part; R normally likes to recycle vectors 
that are too short.

Here's one way, probably not the best:

x <- matrix(NA, 3, max(length(a), length(b), length(c)))
x[1,seq(along=a)] <- a
x[2,seq(along=b)] <- b
x[3,seq(along=c)] <- c

Another way to do it would be to extend all the vectors to the same 
length by appending NAs, then using rbind.

Duncan Murdoch



From jarioksa at sun3.oulu.fi  Mon Aug 22 15:13:04 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Mon, 22 Aug 2005 16:13:04 +0300
Subject: [R] vectors of different length in a matrix
In-Reply-To: <4309CB70.1060707@stats.uwo.ca>
References: <4309C8E9.3090804@ufz.de>  <4309CB70.1060707@stats.uwo.ca>
Message-ID: <1124716384.2979.5.camel@biol102145.oulu.fi>

On Mon, 2005-08-22 at 08:56 -0400, Duncan Murdoch wrote:
> On 8/22/2005 8:45 AM, Marten Winter wrote:
> > HI!
> > 
> > I?ve 3 vectors of different length (a,b,c) and want to arrange them in a 
> > matrix a,b,c as rows and the figures of these vectors in the columns 
> > (with that matrix i want to calculate a distance between thes vectors - 
> > vegan - vegdist - horn). Is there a possibilty to create such a matrix 
> > and to fill up the missing fields with NA?s automatically????
> 
> Filling with NA's is the hard part; R normally likes to recycle vectors 
> that are too short.
> 
> Here's one way, probably not the best:
> 
> x <- matrix(NA, 3, max(length(a), length(b), length(c)))
> x[1,seq(along=a)] <- a
> x[2,seq(along=b)] <- b
> x[3,seq(along=c)] <- c
> 
> Another way to do it would be to extend all the vectors to the same 
> length by appending NAs, then using rbind.
> 
Another issue is that this would fail at the next step outlined in the
original message ("vegan - vegdist - horn"), since that step won't
accept NAs. So the original schedule was bad. If you fill with zeros,
then the 'vegdist' step would work in the sense that it produces
numbers. I don't know if these numbers would make any sense if the
vectors had nothing to do with each other originally, and columns would
be of mixed meaning after stacking into a matrix. If your vector
elements had identities ("names") originally, then you should stack your
data so that entries with the same identity go to the same column. It is
difficult to imagine Horn index used in cases where you don't have these
identities -- specifically species names.  

cheers, jari oksanen
-- 
Jari Oksanen -- Dept Biology, Univ Oulu, 90014 Oulu, Finland
email jari.oksanen at oulu.fi, homepage http://cc.oulu.fi/~jarioksa/



From jarioksa at sun3.oulu.fi  Mon Aug 22 15:32:21 2005
From: jarioksa at sun3.oulu.fi (Jari Oksanen)
Date: Mon, 22 Aug 2005 16:32:21 +0300
Subject: [R] vectors of different length in a matrix
In-Reply-To: <1124716384.2979.5.camel@biol102145.oulu.fi>
References: <4309C8E9.3090804@ufz.de>  <4309CB70.1060707@stats.uwo.ca>
	<1124716384.2979.5.camel@biol102145.oulu.fi>
Message-ID: <1124717541.2979.10.camel@biol102145.oulu.fi>

On Mon, 2005-08-22 at 16:13 +0300, Jari Oksanen wrote:
> On Mon, 2005-08-22 at 08:56 -0400, Duncan Murdoch wrote:
> > On 8/22/2005 8:45 AM, Marten Winter wrote:
> > > HI!
> > > 
> > > I?ve 3 vectors of different length (a,b,c) and want to arrange them in a 
> > > matrix a,b,c as rows and the figures of these vectors in the columns 
> > > (with that matrix i want to calculate a distance between thes vectors - 
> > > vegan - vegdist - horn). Is there a possibilty to create such a matrix 
> > > and to fill up the missing fields with NA?s automatically????
> > 
> > Filling with NA's is the hard part; R normally likes to recycle vectors 
> > that are too short.
> > 
> > Here's one way, probably not the best:
> > 
> > x <- matrix(NA, 3, max(length(a), length(b), length(c)))
> > x[1,seq(along=a)] <- a
> > x[2,seq(along=b)] <- b
> > x[3,seq(along=c)] <- c
> > 
> > Another way to do it would be to extend all the vectors to the same 
> > length by appending NAs, then using rbind.
> > 
> Another issue is that this would fail at the next step outlined in the
> original message ("vegan - vegdist - horn"), since that step won't
> accept NAs. 

Uh. It seems that I should read the package documentation (and posting
guide which tells me to do so): it seems that vegdist() *can* handle
NAs. I do still think that data with NA probably makes no sense with
alternative "horn".

cheers, jari oksanen



From Jan.Verbesselt at biw.kuleuven.be  Mon Aug 22 15:49:38 2005
From: Jan.Verbesselt at biw.kuleuven.be (Jan Verbesselt)
Date: Mon, 22 Aug 2005 15:49:38 +0200
Subject: [R] How to add values on the axes of the 3D bi-variable lrm fit?
Message-ID: <000701c5a720$56bc24d0$1145210a@agr.ad10.intern.kuleuven.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050822/c79fe729/attachment.pl

From a.manigs at gmail.com  Mon Aug 22 15:54:31 2005
From: a.manigs at gmail.com (A Mani)
Date: Mon, 22 Aug 2005 19:24:31 +0530
Subject: [R] R-help Digest, Vol 30, Issue 22
In-Reply-To: <mailman.9.1124704801.22257.r-help@stat.math.ethz.ch>
References: <mailman.9.1124704801.22257.r-help@stat.math.ethz.ch>
Message-ID: <a6821d99050822065474b569c0@mail.gmail.com>

 Re: A. Mani : Avoiding loops (Petr Pikal)
> Message: 9
> Date: Mon, 22 Aug 2005 06:40:45 +0200
> From: "Petr Pikal" <petr.pikal at precheza.cz>
> Subject: Re: [R] A. Mani : Avoiding loops
> To: "A. Mani" <a_mani_sc_gs at vsnl.net>, r-help
>  <r-help at stat.math.ethz.ch>
> 
> On 20 Aug 2005 at 3:26, A. Mani wrote:
> 
> > On Friday 19 August 2005 11:54, Sean O'Riordain wrote:
> > > Hi,
> > > I'm not sure what you actually want from your email (following the
> > > posting guide is a good way of helping you explain things to the
> > > rest of us in a way we understand - it might even answer your
> > > question!
> > >
> > > I'm only a beginner at R so no doubt one of our expert colleagues
> > > will help me...
> > >
> > > > fred <- data.frame()
> > > > fred <- edit(fred)
> > > > fred
> > >
> > >   A B C D E
> > > 1 1 2 X Y 1
> > > 2 2 3 G L 1
> > > 3 3 1 G L 5
> > >
> > > > fred[,3]
> > >
> > > [1] X G G
> > > Levels: G X
> > >
> > > > fred[fred[,3]=="G",]
> > >
> > >   A B C D E
> > > 2 2 3 G L 1
> > > 3 3 1 G L 5
> > >
> > > so at this point I can create a new dataframe with column 3 (C) ==
> > > "G"; either explicitly or implicitly...
> > >
> > > and if I want to calculate the sum() of column E, then I just say
> > > something like...
> > >
> > > > sum(fred[fred[,3]=="G",][,5])
> > >
> > > [1] 6
> > >
> > >
> > > now naturally being a bit clueless at manipulating stuff in R, I
> > > didn't know how to do this before I started... and you guys only get
> > > to see the lines that I typed in and got a "successful" result...
> > >
> > > according to section 6 of the "Introduction to R" manual which comes
> > > with R, I could also have said
> > >
> > > > sum(fred[fred$C=="G",]$E)
> > >
> > > [1] 6
> > >
> > > Hmmm.... I wonder would it be reasonable to put an example of this
> > > type into section 2.7 of the "Introduction to R"?
> > >
> > >
> > > cheers!
> > > Sean
> > >
> > > On 18/08/05, A. Mani <a_mani_sc_gs at vsnl.net> wrote:
> > > > Hello,
> > > >         I want to avoid loops in the following situation. There is
> > > >         a
> > > > 5-col dataframe with col headers alone. two of the columns are
> > > > non-numeric. The problem is to calculate statistics(scores) for
> > > > each element of one column. The functions depend on matching in
> > > > the other non-numeric column.
> > > >
> > > > A  B  C  E  F
> > > > 1  2  X  Y  1
> > > > 2  3  G  L  1
> > > > 3  1  G  L  5
> > > > and so on ...30000+ entries.
> > > >
> > > > I need scores for col E entries which depend on conditional
> > > > implications.
> > > >
> > > >
> > > > Thanks,
> > > >
> > Hello,
> >       Sorry about the incomplete problem. Here is a better version for
> >       the
> > problem: (the measure is not simple)
> > The data frame is like
> >   col1       col2            col3       col4        col5
> >   <num>  <nonum>   <nonum>      <num>   <num>
> >        A           B             C                  E           F  
> > There are repeated strings in col3, col2. Problem : Calculate 
> > Measure(Ci) = [No. of repeats of Ci *100] + [If (Bi, Ci) is same as
> > (Bj, Cj) and 6>= Ej - Ei >=3 then add 100 else  10] .
> 
> Hi
> 
> I am not sure what exactly you would like to compute, 
> **working** example could help. But if you want to do some 
> computation for row "i" which depends on row "j", I suppose that 
> you can not avoid loops. 
> 
> Generally you can use one of aggregate, tapply, by or ave for some 
> computation split by factor. See help pages.
> 
> tapply(vector or data frame, list(factors), function)
> 
> is the standard form.
> 
> HTH
> Petr
> 
> 
> > 
> > 
> > Actually it is to stretched further by adding similar blocks.
> > 
> >  How do we use *apply or
> > something else in the situation  ?
> > 
> > 
> > In prolog it is extremely easy, but here it is not quite...
> > 
> > 
Here is some code and a little data 

dat <- read.table("/home/project5R/datasplf.csv", header=TRUE,
sep=",", na.strings="NA", dec=".", strip.white=TRUE)
attach(dat)
showData(dat, placement='-20+200', font=.logFont, maxwidth=80, maxheight=30)
x <- as.matrix(dat)
x1 <- as.vector(x[,1])
xd1 <- as.Date(x1, format= "%m-%d-%Y")
n <- length(x1)
n
x2 <- as.vector(x[,2])
length(x2)
x3 <- as.vector(x[,3])
length(x3)
x4 <- as.vector(x[,4])
x5 <- as.vector(x[,5])
x5[is.na(x5)] <- 0
xd4 <- as.Date(x4, format= "%m-%d-%Y")
xd4
p6 <- (1-(abs(x5 - 6)/6))*100
p6
xd1 <- as.Date(x1, format= "%m-%d-%Y")
xd1
x23 <- cbind(x2,x3)
xp <- paste(x2,x3)
xp
y <- cbind(x23,xd4,xd1,xp)

_____________________________________________________________
#The Score to be computed is for the doctors. It is no. of patients *100 + rate
of decrease of diabetic score *1000 + no.of tests at approx 3 months *....(see
below )  

_____________________________________________________________  
# To be debugged (loops)

sc <- vector(n, mode = "numeric")
for (i in 1:n){for(j in 1:n) {If identical(x3[[i]],x3[[j]]) &
identical(x2[[i]],x2[[j]])}
sc[[i]] <- sc[[i]] + 100 else sc[[i]] <- sc[[i]] +0 }
sc
scf <- vector(0, length= n, mode = "numeric", step=0)
for (i,j in 1:n) {If (identical(x3[[i]],x3[[j]]) & identical(x2[[i]],x2[[j]]) &
abs(1-(abs(xd4[[i]]-xd4[[j]]))/90) <= 1.25)} scf[[i]] <- scf[[i]] +
100 else scf[[i]] <- scf[i] +0

scr <- vector(0, length= n, mode = "numeric", step=0)
for (i,j in 1:n) {If (identical(x3[[i]],x3[[j]]) & identical(x2[[i]],x2[[j]])}
scr[[i]] <- ((abs(x5[[i]]-x5[[j]]))/(abs(xd4[[i]]-xd4[[j]]))) *1000 + scr[[i]] 

sce <- vector(0, length= n, mode = "numeric", step=0)
for (i in 1:n) {sce[[i]] <- sce[[i]] + (1 - abs(x5[[i]]- 6)/6)*100}

se <- scf + sce + scr + sc

score <- cbind(x3, se)

____________________________
DATA
"DOB","ID","DOCTOR","DATE of TEST","TEST1"
12-23-1921,2177532.174,NA,01-20-2003,NA
NA,2358368.261,"152N7R",01-26-2003,NA
NA,2358368.261,"152N7R",01-27-2003,NA
07-24-1938,2174903.913,NA,01-31-2003,6.7
12-25-1924,2185493.043,NA,01-31-2003,NA
07-21-1943,2181658.696,"K9PL9N,L",01-28-2003,7
05-24-1938,2306571.304,"SH7RM9N",01-13-2003,NA
07-29-1949,2296516.522,"H3001FR9",01-20-2003,NA


Thanks,

 A. Mani
 Member, Cal. Math. Soc



From ripley at stats.ox.ac.uk  Mon Aug 22 16:31:56 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 22 Aug 2005 15:31:56 +0100 (BST)
Subject: [R] translating output ( latex()....)
In-Reply-To: <80102e880508220551c6bb43f@mail.gmail.com>
References: <80102e880508220551c6bb43f@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0508221422270.2134@gannet.stats>

R has since 2.1.0 had all the facilities one needs to mark up output for 
automated translation.  However, we did _choose_ not to do it.  One issue 
is layout: your French label is over twice as long as the English one. 
Another is that it is hard to translate single words like this out of 
context.

You could produce your own versions of the appropriate print() methods, 
probably most appropriately via a package.

On Mon, 22 Aug 2005, Anne wrote:

> Dear R-helpers
>
> I need to produce statistical output where the annotations are in
> French (and from time to time in German). I produce plots/tables using
> extensively the latex() , summary.formula() ...functions of Hmisc
> which allows me for nice print-out. Up to now I "corrected" manually
> my latex code , replacing such headings as "missing" by "valeur
> manquante" etc. Is there a (simple) way of updating the R functions
> with the translated output? (I would of course gladly make it
> available to the list)
>
> I know my question will sound like an heresy to the vast majority of
> statisticians and I agree it is a waste of statistician time to do
> translations, but it is due to work related constraints (and I fear
> the "anti-americanisme primaire" encountered in some european
> countries)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From Jan.Verbesselt at biw.kuleuven.be  Mon Aug 22 16:58:48 2005
From: Jan.Verbesselt at biw.kuleuven.be (Jan Verbesselt)
Date: Mon, 22 Aug 2005 16:58:48 +0200
Subject: [R] How to add legend of plot.Design function ( method=image)?
Message-ID: <000e01c5a72a$00ae38d0$1145210a@agr.ad10.intern.kuleuven.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050822/e141efb5/attachment.pl

From ivo_welch-rstat8303 at mailblocks.com  Mon Aug 22 17:37:50 2005
From: ivo_welch-rstat8303 at mailblocks.com (ivo_welch-rstat8303@mailblocks.com)
Date: Mon, 22 Aug 2005 08:37:50 -0700
Subject: [R] pdf font embedding --- again
Message-ID: <200508221537.j7MFbsa0000978@hypatia.math.ethz.ch>


dear R wizards---  I would like to do some book-on-demand printing at a 
popular printer named lulu, but lulu requires inclusion even of the 
basic postscript fonts.  Interestingly, my book itself does not need 
the 14 base acrobat fonts, only the embedded R figures do.  Of course, 
I really would like to get pdftex to embed the fonts, but how to do 
this is not obvious either.  [This method seems to be what the R help 
page is indicating...  The software including the PostScript plot file 
should either embed the font outlines (usually from '.pfb' or '.pfa' 
files) or use DSC comments to instruct the print spooler to do so.)

So, I would really, really like to embed the necessary fonts with the R 
figures.  I first reread the discussion in this mailing list about 
(eps) font embedding earlier this year.  This was ultimately not very 
helpful.  First, I do not  know how to instruct my embedding program to 
include the fonts that R figures want.  Second, I already start with 
the pdf device, so distilling eps files is not a good option--and it 
would seem a bit crazy to first use the wrong output device 
(postscript), then ship my files over to a windows machine somewhere 
that has distiller installed, run distiller by hand, then ftp them back 
to my linux machine---just for getting the fonts embedded.

Is it impossible to get R to embed the necessary fonts in its pdf 
output?

help appreciated.

regards, /iaw
---
ivo welch



From ripley at stats.ox.ac.uk  Mon Aug 22 18:07:14 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 22 Aug 2005 17:07:14 +0100 (BST)
Subject: [R] pdf font embedding --- again
In-Reply-To: <200508221537.j7MFbsa0000978@hypatia.math.ethz.ch>
References: <200508221537.j7MFbsa0000978@hypatia.math.ethz.ch>
Message-ID: <Pine.LNX.4.61.0508221700100.17196@gannet.stats>

On Mon, 22 Aug 2005 ivo_welch-rstat8303 at mailblocks.com wrote:

>
> dear R wizards---  I would like to do some book-on-demand printing at a
> popular printer named lulu, but lulu requires inclusion even of the
> basic postscript fonts.  Interestingly, my book itself does not need
> the 14 base acrobat fonts, only the embedded R figures do.  Of course,
> I really would like to get pdftex to embed the fonts, but how to do
> this is not obvious either.  [This method seems to be what the R help
> page is indicating...  The software including the PostScript plot file
> should either embed the font outlines (usually from '.pfb' or '.pfa'
> files) or use DSC comments to instruct the print spooler to do so.)

Why not use the fonts your book does use in the figures?  (That's how
my books are done.)

> So, I would really, really like to embed the necessary fonts with the R
> figures.  I first reread the discussion in this mailing list about
> (eps) font embedding earlier this year.  This was ultimately not very
> helpful.  First, I do not  know how to instruct my embedding program to
> include the fonts that R figures want.  Second, I already start with
> the pdf device, so distilling eps files is not a good option--and it
> would seem a bit crazy to first use the wrong output device
> (postscript), then ship my files over to a windows machine somewhere
> that has distiller installed, run distiller by hand, then ftp them back
> to my linux machine---just for getting the fonts embedded.
>
> Is it impossible to get R to embed the necessary fonts in its pdf
> output?

Yes, as it has no access to them.  They are not Open Source.  You may be 
able to use URW clones, depending on their licensing conditions.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From greg.snow at ihc.com  Mon Aug 22 18:17:23 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Mon, 22 Aug 2005 10:17:23 -0600
Subject: [R] rgui on windows quiting automatically
Message-ID: <s309a64a.075@lp-msg1.co.ihc.com>

Rgui on my computer has started acting funny (though I expect the 
problem is with my system rather than R, but hopefully someone
here can still help).

I am working with R version 2.11 on windows 2000.

Rgui was working fine, then last week it started acting up.  Now
when I start Rgui (from shorcuts, or the commandline), the GUI
starts up, but before the copyright and version info is printed I
get the closing dialog asking me if I want to save the workspace
(the same one that I get from "q()").  If I answer yes or no
then R exits nicely, if I click on "cancel" then I get the windows
dialog box saying that the program has performed an illeagle
action and will be closed (It says it is creating a log file, but
I have yet to find a log file with anything useful in it on why
the program was closed).

I have tried starting from the command line with the --vanilla
switch, but that does not work either.  

rgui --help and rgui --version do work (but don't run the main
program).

rgui --verbose causes the error and shutdown without the 
quit dialog.

I tried running the older versions of R that were still installed
on my computer, but they behaved the same way (had worked
fine before this).

I did a complete uninstall of all copies of R on the computer, 
downloaded a fresh version of R 2.11 and reinstalled that
(removing all .Rdata files that it may have accessed)
and it is still giving  me the same problem.

rterm still works, so it is something in the GUI portion.

Any help will be appreciated,

Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111



From sms13+ at pitt.edu  Mon Aug 22 18:58:44 2005
From: sms13+ at pitt.edu (sms13+@pitt.edu)
Date: Mon, 22 Aug 2005 12:58:44 -0400
Subject: [R] plotting with same axes
Message-ID: <450465125.1124715524@Lab26.DOMAIN.IE.PITT.EDU>

I have used the 'par' command to 
overlay one plot on another.  But how 
do I overlay it with the x-values 
plotted at the same points on the 
x-axis?

Thank you,
Steven



From daniel at sintesys.com.ar  Mon Aug 22 19:03:29 2005
From: daniel at sintesys.com.ar (daniel@sintesys.com.ar)
Date: Mon, 22 Aug 2005 14:03:29 -0300 (ART)
Subject: [R] lm.ridge again
In-Reply-To: <971536df0508200928519d65dc@mail.gmail.com>
References: <6BCB4D493A447546A8126F24332056E80A77D1@school1.business.edu>
	<971536df0508200928519d65dc@mail.gmail.com>
Message-ID: <22484.170.155.1.10.1124730209.squirrel@www.sintesys.com.ar>

Hello, I have posted this mail a few days ago without any answer:

I have the following doubts related with lm.ridge, from MASS package. To
show the problem using the Longley example, I have the following doubts:

First: I think coefficients from lm(Employed~.,data=longley) should be
equal coefficients from lm.ridge(Employed~.,data=longley, lambda=0) why
it does not happen?
Second: if I have for example
Ridge<-lm.ridge(Employed~., data=longley, lambda = seq(0,0.1,0.001)), I
suppose intercept coefficient is defined implicit, why it does not
appear in Ridge$coef?

Third: I suppose that if I define
1) y<-longley$Employed
2) X<-as.matrix(cbind(1,Longley[,1:6])
3) I as the identity
the following should be true:
         Coef=(X'X+kI)^(-1) X'y
and if a take k=Ridge$kHKV, the coefficients should be approx equal to
Ridge$Coef[near value of kHKV] and it does not seem to happen, why?

Values:
> Ridge$kHKB
[1] 0.004275357

Using the calculation above (third question, third point):
Coef=
                      [,1]
  1            -0.095492310
  GNP.deflator -0.052759002
  GNP           0.070993540
  Unemployed   -0.004244391
  Armed.Forces -0.005725582
  Population   -0.413341544
  Year          0.048420107

And if I take from Ridge&coef:

Ridge$coef[0.004]
GNP.deflator -0.03098507
GNP -1.32553151
Unemployed -1.53237769
Armed.Forces -0.63334911
Population -0.88690241
Year 6.82105049

Any help, suggestion or orientation?
Thanks in advance
Daniel Rozengardt



From vincent at 7d4.com  Mon Aug 22 19:10:22 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Mon, 22 Aug 2005 19:10:22 +0200
Subject: [R] read a table ignoring specific rows ?
Message-ID: <430A06FE.4060809@7d4.com>

Dear R users,
First of all sorry for this question, surely quite naive.
(I searched on the R site but was unable to find by myself).

I have a table, called infile :
1 2 3
4 5 6
7 8 9

I would like to read it and ignore the rows with 1st element > 3
I do it now with a for loop, and it's ok,
but I was expecting something simpler, like :

intable  = read.table(infile);
newtable = intable[isgoodrow(intable)];

where :   isgoodrow = function(therow)
{if (therow$V1 > 3) return(F) else return(T);};

(... but this don't work).

So, could somebody please tell me if there is a way to read
a table ignoring specific rows, without using a for loop ?
... and if yes how ?

Thanks
Vincent



From mschwartz at mn.rr.com  Mon Aug 22 19:11:43 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 22 Aug 2005 12:11:43 -0500
Subject: [R] plotting with same axes
In-Reply-To: <450465125.1124715524@Lab26.DOMAIN.IE.PITT.EDU>
References: <450465125.1124715524@Lab26.DOMAIN.IE.PITT.EDU>
Message-ID: <1124730703.4627.25.camel@localhost.localdomain>

On Mon, 2005-08-22 at 12:58 -0400, sms13+ at pitt.edu wrote:
> I have used the 'par' command to 
> overlay one plot on another.  But how 
> do I overlay it with the x-values 
> plotted at the same points on the 
> x-axis?
> 
> Thank you,
> Steven

The specific answer depends to an extent on the graphics you are
plotting and whether there is a need to actually use par("new").

In some cases there is an 'add = TRUE' option to plotting functions that
allows for this. 

In others, you can create the initial plot and then use lines(),
points() or the like to simply add further plotting components to the
existing plot.

If all else fails and you need to use par("new"), then you will want to
explicitly define the x and y axes to the same ranges by using the same
'xlim' and 'ylim' arguments in _both_ plotting functions. 

A reproducible example of what it is you are doing would enable us to
give you more specific guidance, if the above is not helpful.

HTH,

Marc Schwartz



From jeaneid at chass.utoronto.ca  Mon Aug 22 19:33:24 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Mon, 22 Aug 2005 13:33:24 -0400
Subject: [R] read a table ignoring specific rows ?
In-Reply-To: <430A06FE.4060809@7d4.com>
Message-ID: <Pine.SGI.4.40.0508221332460.441708-100000@origin.chass.utoronto.ca>

why don't you just do

intable<-intable[intable$V1<=3,]

On Mon, 22 Aug 2005 vincent at 7d4.com wrote:

> Dear R users,
> First of all sorry for this question, surely quite naive.
> (I searched on the R site but was unable to find by myself).
>
> I have a table, called infile :
> 1 2 3
> 4 5 6
> 7 8 9
>
> I would like to read it and ignore the rows with 1st element > 3
> I do it now with a for loop, and it's ok,
> but I was expecting something simpler, like :
>
> intable  = read.table(infile);
> newtable = intable[isgoodrow(intable)];
>
> where :   isgoodrow = function(therow)
> {if (therow$V1 > 3) return(F) else return(T);};
>
> (... but this don't work).
>
> So, could somebody please tell me if there is a way to read
> a table ignoring specific rows, without using a for loop ?
> ... and if yes how ?
>
> Thanks
> Vincent
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From sean.oriordain at gmail.com  Mon Aug 22 19:38:41 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Mon, 22 Aug 2005 18:38:41 +0100
Subject: [R] read a table ignoring specific rows ?
In-Reply-To: <430A06FE.4060809@7d4.com>
References: <430A06FE.4060809@7d4.com>
Message-ID: <8ed68eed05082210389bb706@mail.gmail.com>

Can you read in the entire file as a data.frame; and then construct a
new data.frame which excludes some rows?

perhaps something along the lines of...

> fred.file <- data.frame()
> fred.file <- edit(fred.file)
> fred.file
  colA colB colC
1    1    4    2
2    2    3    3
3    3    5    4
4    4    3    3
5    5    2   25
> fred.new <- fred.file[fred.file$colC <= 3,]
> fred.new
  colA colB colC
1    1    4    2
2    2    3    3
4    4    3    3

s/


On 22/08/05, vincent at 7d4.com <vincent at 7d4.com> wrote:
> Dear R users,
> First of all sorry for this question, surely quite naive.
> (I searched on the R site but was unable to find by myself).
> 
> I have a table, called infile :
> 1 2 3
> 4 5 6
> 7 8 9
> 
> I would like to read it and ignore the rows with 1st element > 3
> I do it now with a for loop, and it's ok,
> but I was expecting something simpler, like :
> 
> intable  = read.table(infile);
> newtable = intable[isgoodrow(intable)];
> 
> where :   isgoodrow = function(therow)
> {if (therow$V1 > 3) return(F) else return(T);};
> 
> (... but this don't work).
> 
> So, could somebody please tell me if there is a way to read
> a table ignoring specific rows, without using a for loop ?
> ... and if yes how ?
> 
> Thanks
> Vincent
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dierojas at hotmail.com  Mon Aug 22 19:47:10 2005
From: dierojas at hotmail.com (=?iso-8859-1?B?SE0gRGllZ28gSGVybuFu?=)
Date: Mon, 22 Aug 2005 17:47:10 +0000
Subject: [R] R-help
In-Reply-To: <mailman.9.1124445601.32054.r-help@stat.math.ethz.ch>
Message-ID: <BAY7-F239CBE0E16D5F4C8F1B568C2B60@phx.gbl>

Hello

I need help with the way to install nls2 library for windows, or the script 
that can be used for install the nls2 library.

Do you know if this library works in windows?

Best regards.

Diego Rojas
Cali-Colombia



From vincent at 7d4.com  Mon Aug 22 19:56:01 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Mon, 22 Aug 2005 19:56:01 +0200
Subject: [R] read a table ignoring specific rows ?
In-Reply-To: <430A06FE.4060809@7d4.com>
References: <430A06FE.4060809@7d4.com>
Message-ID: <430A11B1.80209@7d4.com>

Thank you very much to all of you.
Sorry once more for this too simple question.
I have to improve my knowledge about the syntax !
Thanks
Vincent



From dr.mike at ntlworld.com  Mon Aug 22 20:41:52 2005
From: dr.mike at ntlworld.com (Mike Waters)
Date: Mon, 22 Aug 2005 19:41:52 +0100
Subject: [R] R-help
In-Reply-To: <BAY7-F239CBE0E16D5F4C8F1B568C2B60@phx.gbl>
Message-ID: <20050822184201.HYGA23288.aamta09-winn.ispmail.ntl.com@d600>

Diego,

Have you checked out the home site for nls2? Specifically the system
requirements page?

http://www.inra.fr/miaj/public/AB/nls2/available.html

That says that nls2 requires a Unix-like operating system. Basically, the
script for building the library is for such systems only, it also depends
upon a lex (flex) library being available.

Regards,

Mike

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of HM Diego Hern??n
> Sent: 22 August 2005 18:47
> To: r-help at stat.math.ethz.ch
> Subject: [R] R-help
> 
> Hello
> 
> I need help with the way to install nls2 library for windows, 
> or the script that can be used for install the nls2 library.
> 
> Do you know if this library works in windows?
> 
> Best regards.
> 
> Diego Rojas
> Cali-Colombia
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From rchandler at forwild.umass.edu  Mon Aug 22 21:13:41 2005
From: rchandler at forwild.umass.edu (Richard Chandler)
Date: Mon, 22 Aug 2005 15:13:41 -0400
Subject: [R] function for "two-part" or "two-condition" models
In-Reply-To: <42C1859F.5050203@kernstat.com>
References: <1119900930.42c05502c3893@mail-www2.oit.umass.edu>
	<20050627232243.GB600@uidaho.edu> <42C1859F.5050203@kernstat.com>
Message-ID: <1124738021.430a23e5e63d4@mail-www2.oit.umass.edu>

Hello list, Andrew, and Richard, 

I wanted to send you a late thanks your for your suggestions and
mention that I recently stumbled upon what I was looking for in the
VGAM package.  If you're interested, see the help file for zapoisson,
which is based on both a binomial and a poisson distribution. 

Richard

Quoting "Remington, Richard" <rnews at kernstat.com>:

> 
> Two alternatives to the zero inflated Poisson (ZIP) model are
> mentioned 
> in Jung, Jhun, and Lee (Biometrics, vol 61, no 2, June 2005,
> p626):
> 
> "Although the ZIP model is more general than the standard Poisson,
> count 
> data with many zeros are often more dispersed than the ZIP model. 
> In 
> this case, the use of a zero-inflated negative binomial (ZINB) 
> distribution or a zero-inflated generalized Poisson distribution is
> a 
> good alternative."
> 
> best,
> Richard
> 
> -- 
> Richard E. Remington
> Statistician
> KERN Statistical Services, Inc.
> PO Box 1046
> Boise, ID 83701
> Tel: 208.426.0113
> KernStat.com
> 
> Andrew Robinson wrote:
> > Hi Richard,
> > 
> > I'm not sure that I can imagine how data can have too many zeros
> to be
> > fit well with zero-inflated Poisson models. Won't the excess
> zeros be
> > accommodated by increasing the the inflation?
> > 
> > In any case, if you want a model that separates the zeros from
> the
> > occurrences before fitting a Poisson model to account for
> variation in
> > abundance then it might be safest to do that split manually.
> > 
> > Another angle to try is to treat it as a special case of a
> finite
> > mixture regression.  I think that some of Jim Lindsey's code will
> fit
> > such models. Google can help you find his wbsite.
> > 
> > An MS student of mine explored these models for regeneration
> modeling.
> > I'd be happy to send you a pdf of his thesis if it would help.
> > 
> > Cheers,
> > 
> > Andrew
> > 
> > On Mon, Jun 27, 2005 at 03:35:30PM -0400, Richard Chandler
> wrote:
> > 
> >>Hello,
> >>
> >>This is an (hopefully) improved question of one I posted several
> weeks
> >>ago. Does anyone know of a function for fitting "two-part"
> models?
> >>These models are designed to handle count data with so many
> zeroes
> >>that they can't be fit well with zero-inflated Poisson models or
> other
> >>'typical' GLMs. My understanding is that they work by first
> fitting a
> >>binomial model to separate the zeros from the occurrences
> (positive
> >>integers) before fitting a Poisson model to account for variation
> in
> >>abundance. 
> >>
> >>I have tried help.search("two-part") and many other similar
> guesses.
> >>
> >>Thanks,
> >>Richard
> >>
> >>-- 
> >>Richard Chandler, M.S. Candidate
> >>Department of Natural Resources Conservation
> >>UMass Amherst
> >>(413)545-1237
> >>
> >>______________________________________________
> >>R-help at stat.math.ethz.ch mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> > 
> > 
> 
> 


-- 
Richard Chandler
Department of Natural Resources Conservation
UMass Amherst
(413)545-1237



From ivo_welch-rstat8303 at mailblocks.com  Mon Aug 22 22:38:37 2005
From: ivo_welch-rstat8303 at mailblocks.com (ivo_welch-rstat8303@mailblocks.com)
Date: Mon, 22 Aug 2005 13:38:37 -0700
Subject: [R] pdf font embedding --- again
In-Reply-To: <Pine.LNX.4.61.0508221700100.17196@gannet.stats>
References: <200508221537.j7MFbsa0000978@hypatia.math.ethz.ch>
	<Pine.LNX.4.61.0508221700100.17196@gannet.stats>
Message-ID: <200508222038.j7MKceUi031412@hypatia.math.ethz.ch>


Thank you---as always.

still, I remain font-desparate.

I would love to use the fonts from my book, but [a] I cannot figure out 
how to do this yet even in the R postscript device; and [b] I am using 
the R pdf device, not the postscript device.  I guess if I can solve 
[a], then I can rewrite all my graphics creations now into the 
postscript device, and replace the dev.off() with something that 
follows it with ps2pdf.  The following attempt, however, does not work:

   afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", 
"lbms.afm");
  Lucida <- postscriptFont("Lucida", metrics=afmfiles);
  postscript(file="test.ps", family=Lucida);
  l<- 40:80;
  plot(l,l,pch=l);
  dev.off();

By the way, if I try  " postscript(family=afmfiles);" then I do not get 
an R error, but R 2.1.0 segfaults, which is probably not desirable.  
This occurs even if there is no .afm file in the current directory.


Can I make a suggestion to the R team?    It would be nice if I could 
specify a pdf() device parameter that says "choose font settings to 
embed all fonts" (i.e., do not use fonts that cannot be embedded, 
either).  Something that guarantees me that I get a figure that I can 
give to someone that is fully specified.   Right now, accomplishing 
this is not easy to figure out, and perhaps not even possible.  Yes, in 
the list of font families that R recognizes are some fonts that do not 
seem among the 13 standard fonts (such as URWbookman).  moreover, if I 
choose it as my pdf font family, it is smart enough to use a different 
symbol file ('StandardSymL'), which I hope is also open and not adobe.  
If so, they could be used in principle.  How do I get R to embed 
URWbookman?  ZapfDingbats always seems to be included, so I hope this 
is open and embeddable.

more help would be highly appreciated.

Regards,

/iaw
---
ivo welch

-----Original Message-----
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
To: ivo_welch-rstat8303 at mailblocks.com
Cc: r-help at stat.math.ethz.ch
Sent: Mon, 22 Aug 2005 17:07:14 +0100 (BST)
Subject: Re: [R] pdf font embedding --- again

On Mon, 22 Aug 2005 ivo_welch-rstat8303 at mailblocks.com wrote:

 >
  > dear R wizards--- I would like to do some book-on-demand printing at 
a
 > popular printer named lulu, but lulu requires inclusion even of the
 > basic postscript fonts. Interestingly, my book itself does not need
  > the 14 base acrobat fonts, only the embedded R figures do. Of 
course,
 > I really would like to get pdftex to embed the fonts, but how to do
 > this is not obvious either. [This method seems to be what the R help
  > page is indicating... The software including the PostScript plot 
file
 > should either embed the font outlines (usually from '.pfb' or '.pfa'
 > files) or use DSC comments to instruct the print spooler to do so.)

 Why not use the fonts your book does use in the figures? (That's how
 my books are done.)

  > So, I would really, really like to embed the necessary fonts with 
the R
 > figures. I first reread the discussion in this mailing list about
 > (eps) font embedding earlier this year. This was ultimately not very
  > helpful. First, I do not know how to instruct my embedding program 
to
 > include the fonts that R figures want. Second, I already start with
 > the pdf device, so distilling eps files is not a good option--and it
 > would seem a bit crazy to first use the wrong output device
 > (postscript), then ship my files over to a windows machine somewhere
  > that has distiller installed, run distiller by hand, then ftp them 
back
 > to my linux machine---just for getting the fonts embedded.
 >
 > Is it impossible to get R to embed the necessary fonts in its pdf
 > output?

  Yes, as it has no access to them. They are not Open Source. You may be 
able to use URW clones, depending on their licensing conditions.

 -- Brian D. Ripley, ripley at stats.ox.ac.uk
 Professor of Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
 University of Oxford, Tel: +44 1865 272861 (self)
 1 South Parks Road, +44 1865 272866 (PA)
 Oxford OX1 3TG, UK Fax: +44 1865 272595



From Jan.Verbesselt at biw.kuleuven.be  Mon Aug 22 22:58:13 2005
From: Jan.Verbesselt at biw.kuleuven.be (Jan Verbesselt)
Date: Mon, 22 Aug 2005 22:58:13 +0200
Subject: [R] How to add legend of plot.Design function (method=image)?
	(if (!.R.) )
Message-ID: <001801c5a75c$36497220$1145210a@agr.ad10.intern.kuleuven.ac.be>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050822/5a89c6ae/attachment.pl

From f.harrell at vanderbilt.edu  Mon Aug 22 23:12:41 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Mon, 22 Aug 2005 17:12:41 -0400
Subject: [R] translating output ( latex()....)
In-Reply-To: <80102e880508220551c6bb43f@mail.gmail.com>
References: <80102e880508220551c6bb43f@mail.gmail.com>
Message-ID: <430A3FC9.3030704@vanderbilt.edu>

Anne wrote:
> Dear R-helpers
> 
> I need to produce statistical output where the annotations are in
> French (and from time to time in German). I produce plots/tables using
> extensively the latex() , summary.formula() ...functions of Hmisc
> which allows me for nice print-out. Up to now I "corrected" manually
> my latex code , replacing such headings as "missing" by "valeur
> manquante" etc. Is there a (simple) way of updating the R functions
> with the translated output? (I would of course gladly make it
> available to the list)
> 
> I know my question will sound like an heresy to the vast majority of
> statisticians and I agree it is a waste of statistician time to do
> translations, but it is due to work related constraints (and I fear
> the "anti-americanisme primaire" encountered in some european
> countries)
> 

Anne,

If you were to use a general way to detect the language (using the new 
facilities that Brian Ripley mentioned) and wanted to use that to 
enhance print. and latex. methods for the summary.formula family of 
functions, and know or can learn how to use CVS, we will consider giving 
you access to the Hmisc CVS repository to make the enhancements you want.

Frank

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From f.harrell at vanderbilt.edu  Mon Aug 22 23:15:42 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Mon, 22 Aug 2005 17:15:42 -0400
Subject: [R] How to add legend of plot.Design function (method=image)?
 (if (!.R.) )
In-Reply-To: <001801c5a75c$36497220$1145210a@agr.ad10.intern.kuleuven.ac.be>
References: <001801c5a75c$36497220$1145210a@agr.ad10.intern.kuleuven.ac.be>
Message-ID: <430A407E.5070302@vanderbilt.edu>

Jan Verbesselt wrote:
> Hi,
> 
>  
> 
> When running
> 
>  
> 
> z <- plot(fit, age=NA, cholesterol=NA, perim=boundaries, method='image')
> 
> Legend(z, fun=plogis, at=qlogis(c(.01,.05,.1,.2,.3,.4,.5)),
> zlab='Probability') 
> 
>  
> 
>  And after pointing the cursor to the plot() screen in R, I obtain the
> following message:
> 
>  
> 
> Using function "locator(2)" to place opposite corners of image.legend
> 
> Error in Legend.plot.Design(z, fun = plogis, at = qlogis(c(0.01, 0.05,  : 
> 
>         couldn't find function "subplot"
> 
>  
> 
> *How can I position the legend inside the range? (or solve the following
> error message).
> 
>  
> 
> Regards,
> 
> Jan

The if(!.R.) in the example code was for a reason: I couldn't find 
subplot in R.  If you want to provide code enhancements to do this I 
will incorporate your new code. -Frank

> 
>  
> 
>  
> 
>  
> 
> -----Original Message-----
> From: Jan Verbesselt [mailto:Jan.Verbesselt at biw.kuleuven.be] 
> Sent: Monday, August 22, 2005 4:59 PM
> To: 'r-help at stat.math.ethz.ch'
> Subject: How to add legend of plot.Design function ( method=image)?
> 
>  
> 
>  
> 
> Dear Rlist,
> 
>  
> 
> How can the Legend of the plot.Design() function can be visualized?
> 
>  
> 
> Following the documentation in R, I did the following (see below), only the
> 'Legend' function doesn't visualize the legend of the 
> 
> plot (method='image') of the lrmfit. I tried to change par( margin setting)
> but this didn’t solve it.
> 
>  
> 
> How can this be solved?
> 
>  
> 
> Thanks a lot,
> 
> Jan
> 
>  
> 
>  
> 
> library(Design)
> 
>      n <- 1000    # define sample size
> 
>      set.seed(17) # so can reproduce the results
> 
>      age            <- rnorm(n, 50, 10)
> 
>      blood.pressure <- rnorm(n, 120, 15)
> 
>      cholesterol    <- rnorm(n, 200, 25)
> 
>      sex            <- factor(sample(c('female','male'), n,TRUE))
> 
>      label(age)            <- 'Age'      # label is in Hmisc
> 
>      label(cholesterol)    <- 'Total Cholesterol'
> 
>      label(blood.pressure) <- 'Systolic Blood Pressure'
> 
>      label(sex)            <- 'Sex'
> 
>      units(cholesterol)    <- 'mg/dl'   # uses units.default in Hmisc
> 
>      units(blood.pressure) <- 'mmHg'
> 
>  
> 
>      # Specify population model for log odds that Y=1
> 
>      L <- .4*(sex=='male') + .045*(age-50) +
> 
>        (log(cholesterol - 10)-5.2)*(-2*(sex=='female') + 2*(sex=='male'))
> 
>      # Simulate bin
> 
>      ary y to have Prob(y=1) = 1/[1+exp(-L)]
> 
>      y <- ifelse(runif(n) < plogis(L), 1, 0)
> 
>  
> 
>      ddist <- datadist(age, blood.pressure, cholesterol, sex)
> 
>      options(datadist='ddist')
> 
>  
> 
>      fit <- lrm(y ~ blood.pressure + sex * (age + rcs(cholesterol,4)),
> 
>                     x=TRUE, y=TRUE)
> 
>  
> 
>     boundaries <- perimeter(age, cholesterol, lowess=TRUE)
> 
>     plot(age, cholesterol)   # show bivariate data density
> 
>     lines(boundaries)        # and perimeter that will be used for 3-D plot
> 
>     z <- plot(fit, age=NA, cholesterol=NA, perim=boundaries, method='image')
> 
>                               # draws image() plot
> 
>                               # don't show estimates where data are sparse
> 
>                               # doesn't make sense here since vars don't
> interact
> 
>     if(!.R.)Legend(z, fun=plogis, at=qlogis(c(.01,.05,.1,.2,.3,.4,.5)),
> zlab='Probability')   # gray scale or color legend for prob.
> 
>  
> 
> _______________________________________________________________________
> Ir. Jan Verbesselt
> Research Associate
> Group of Geomatics Engineering
> Department Biosystems ~ M³-BIORES
> Vital Decosterstraat 102, 3000 Leuven, Belgium
> Tel: +32-16-329750   Fax: +32-16-329760
> http://gloveg.kuleuven.ac.be/
> _______________________________________________________________________
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From Wittner.Ben at mgh.harvard.edu  Mon Aug 22 23:48:03 2005
From: Wittner.Ben at mgh.harvard.edu (Wittner, Ben)
Date: Mon, 22 Aug 2005 17:48:03 -0400
Subject: [R] problem building dendrograms to use with heatmap()
Message-ID: <B1D5C2D0D1D6AE4C9DF88E81330D71C60D9E4A@PHSXMB23.partners.org>

Hi,

I'm trying to build dendrograms to pass to heatmap().
The dendrograms I build plot properly, but when I pass them to heatmap() I get
the error message "row dendrogram ordering gave index of wrong length" (see
output log below).
I looked in the code of heatmap() and saw that the error was due to a NULL
return value from order.dendrogram(), which in turn got a NULL return value from
unlist(). But I have no idea why unlist() is returning NULL.

I've included code below which reproduces the problem and below that the output
from a run of that code on my computer.

Any help would be greatly appreciated. Thanks in advance.

-Ben

###########################  begin code  ###################################

version

dendro.leaf <- function(label) {
  ans <- list()
  attr(ans, 'members') <- 1
  attr(ans, 'height') <- 0
  attr(ans, 'leaf') <- T
  attr(ans, 'midpoint') <- 0
  attr(ans, 'label') <- label
  attr(ans, 'class') <- 'dendrogram'
  ans
}

dendro.merge <- function(d1, d2, height) {
  ans <- list(d1, d2)
  members <- attr(d1, 'members') + attr(d2, 'members')
  attr(ans, 'members') <- members
  attr(ans, 'height') <- height
  attr(ans, 'leaf') <- F
  attr(ans, 'midpoint') <- (members - 1)/2
  attr(ans, 'class') <- 'dendrogram'
  ans
}

lc1 <- dendro.leaf('c1')
lc2 <- dendro.leaf('c2')
lc3 <- dendro.leaf('c3')
nc1 <- dendro.merge(lc1, lc2, 0.1)
nc2 <- dendro.merge(nc1, lc3, 0.2)
plot(nc2)

lr1 <- dendro.leaf('r1')
lr2 <- dendro.leaf('r2')
lr3 <- dendro.leaf('r3')
nr1 <- dendro.merge(lr2, lr3, 0.1)
nr2 <- dendro.merge(lr1, nr1, 0.3)
plot(nr2)

x <- matrix(seq(-1, 1, length.out=9), nrow=3)
rownames(x) <- paste('r', 1:3, sep='')
colnames(x) <- paste('c', 1:3, sep='')

heatmap(x, Rowv=nr2, Colv=nc2, scale='none')

order.dendrogram(nr2)

unlist(nr2)

###############  begin output from run of code above  ##################

> version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    2                
minor    1.1              
year     2005             
month    06               
day      20               
language R                
> 
> dendro.leaf <- function(label) {
+   ans <- list()
+   attr(ans, 'members') <- 1
+   attr(ans, 'height') <- 0
+   attr(ans, 'leaf') <- T
+   attr(ans, 'midpoint') <- 0
+   attr(ans, 'label') <- label
+   attr(ans, 'class') <- 'dendrogram'
+   ans
+ }
> 
> dendro.merge <- function(d1, d2, height) {
+   ans <- list(d1, d2)
+   members <- attr(d1, 'members') + attr(d2, 'members')
+   attr(ans, 'members') <- members
+   attr(ans, 'height') <- height
+   attr(ans, 'leaf') <- F
+   attr(ans, 'midpoint') <- (members - 1)/2
+   attr(ans, 'class') <- 'dendrogram'
+   ans
+ }
> 
> lc1 <- dendro.leaf('c1')
> lc2 <- dendro.leaf('c2')
> lc3 <- dendro.leaf('c3')
> nc1 <- dendro.merge(lc1, lc2, 0.1)
> nc2 <- dendro.merge(nc1, lc3, 0.2)
> plot(nc2)
> 
> lr1 <- dendro.leaf('r1')
> lr2 <- dendro.leaf('r2')
> lr3 <- dendro.leaf('r3')
> nr1 <- dendro.merge(lr2, lr3, 0.1)
> nr2 <- dendro.merge(lr1, nr1, 0.3)
> plot(nr2)
> 
> x <- matrix(seq(-1, 1, length.out=9), nrow=3)
> rownames(x) <- paste('r', 1:3, sep='')
> colnames(x) <- paste('c', 1:3, sep='')
> 
> heatmap(x, Rowv=nr2, Colv=nc2, scale='none')
Error in heatmap(x, Rowv = nr2, Colv = nc2, scale = "none") : 
        row dendrogram ordering gave index of wrong length
> 
> order.dendrogram(nr2)
NULL
> 
> unlist(nr2)
NULL
>



From tonyevans at esat.net.au  Tue Aug 23 01:46:08 2005
From: tonyevans at esat.net.au ( Tony Evans)
Date: Tue, 23 Aug 2005 09:46:08 +1000
Subject: [R] cbind and rbind
Message-ID: <002f01c5a773$b2193040$9a5c41ca@8gig.mshome.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050823/1d3482ee/attachment.pl

From abunn at whrc.org  Tue Aug 23 02:33:21 2005
From: abunn at whrc.org (Andy Bunn)
Date: Mon, 22 Aug 2005 20:33:21 -0400
Subject: [R] cbind and rbind
In-Reply-To: <003901c5a776$1d2d1340$9a5c41ca@8gig.mshome.net>
Message-ID: <NEBBIPHDAMMOKDKPOFFIEECJDJAA.abunn@whrc.org>

Like this?

 x <- cbind(rnorm(10), rnorm(10))
# add row total
 x <- cbind(x, rowSums(x))
# add col sums
 x <- rbind(x, colSums(x))

The KEY to posting to r-help is writing a small example that helpers can
reproduce. When I write one, I often find the answer myself. I often don't
and get eviscerated by some R-guru, but that's part of the fun of it all!

I hope that helps, Andy


> -----Original Message-----
> From: Tony Evans [mailto:tonyevans at esat.net.au]
> Sent: Monday, August 22, 2005 8:03 PM
> To: Andy Bunn
> Subject: Re: [R] cbind and rbind
>
>
> Sorry, I did read the guide but am very new to this.
>
> I have created a table and have made totals of rows and columns using
> apply() I now want to add these totals to the table.
> I have been able to add one OR the other using cbind and rbind
> but have not
> been able to find a code to add them both.
>
> I hope this is better information.
>
> Tony Evans
> Australia
>
> ----- Original Message -----
> From: "Andy Bunn" <abunn at whrc.org>
> To: " Tony Evans" <tonyevans at esat.net.au>
> Sent: Tuesday, August 23, 2005 10:02 AM
> Subject: RE: [R] cbind and rbind
>
>
> > Try reading the posting guide and give a small example of what
> you want to
> > try and do...then we can help better.
> >
> > x <- rnorm(10)
> > y <- rnorm(10)
> > z <- cbind(x,y)
> > w <- rbind(z,rnorm(2))
> >
> >
> > -Andy
> >
> >
>
>



From greg.snow at ihc.com  Mon Aug 22 23:39:40 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Mon, 22 Aug 2005 15:39:40 -0600
Subject: [R] How to add legend of plot.Design function ( method=image)?
 (if (!.R.) )
Message-ID: <s30a15ce.060@lp-msg1.co.ihc.com>



Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111

>>> Frank E Harrell Jr <f.harrell at vanderbilt.edu> 08/22/05 03:15PM >>>
Jan Verbesselt wrote:

[snip discussion of subplot not being in R]


While R does not have the subplot function there is an alternative.

The cnvrt.coords function in the TeachingDemos package has an example
(the bottom set) of doing a rough equivalent to subplot.  This idea
could
be used to implement what you want (margins and text sizes may need
adjustment).

Hope this helps,



From spencer.graves at pdf.com  Tue Aug 23 06:07:27 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 22 Aug 2005 21:07:27 -0700
Subject: [R] A question about MIX package
In-Reply-To: <D70CBC108DFBD446862A6E1F6F0B4A152AC99F@nsabpmail>
References: <D70CBC108DFBD446862A6E1F6F0B4A152AC99F@nsabpmail>
Message-ID: <430AA0FF.3080006@pdf.com>

	  Have you received a reply to the post below?  I haven't seen one.  If 
not (or even if you have), I believe you could increase the chances of a 
useful reply by reading the posting guide! 
"http://www.R-project.org/posting-guide.html".  In particular, if you 
provide a sample toy example that someone else can copy from your email 
into R and experiment with modifications in less than a minute, you are 
more likely to get a useful reply.  I don't know MIX, but it sounds 
interesting, and I might be willing to experiment if I could do so 
without a major effort.  More generally, toy examples like this make it 
much easier for someone else to understand what you need.  You may think 
your question is perfectly clear.  Unfortunately, it is not as clear to 
others with a different background.

	  Good Luck.
	  spencer graves

Li, Jia wrote:

> Hello all,
>  
> When I used commands "ecm.mix and dabipf.mix" to do a simulation 
(sample size is small 100), I got an error : Steps of ECM, missing
value where True/False needed.
>  
> I've checked the menu, and the option "prior" of ecm.mix said that 
if structural zeros appear in the table, hyperparameters for those
cells should be set to NA. However, it didn't say how to do that in
the command. I am wondering if someone knows how to fix this.
>  
> I appreciate your help,
>  
> Jia
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From spencer.graves at pdf.com  Tue Aug 23 06:08:35 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 22 Aug 2005 21:08:35 -0700
Subject: [R] how to reshape an array avoiding for loops
In-Reply-To: <171836925.20050816131204@eimb.ru>
References: <171836925.20050816131204@eimb.ru>
Message-ID: <430AA143.4090900@pdf.com>

	  Have you considered "aperm"?  I found this listed under "See Also" 
for "?t".

	  spencer graves

Wladimir Eremeev wrote:

> Dear r-help,
> 
>   I have an array a1 with dimensions [1:660,1:65,1:25]
>   I would like the first dimension to be the last one.
>   That is I want and array [1:65,1:25,1:660]
> 
>   The only way to do this, I know, is
>   
>   tmp.a<-array(dim=dim(a1)[c(2,3,1)])
>   for(i in 1:dim(a1)[1]) tmp.a[,,i]<-a1[i,,]
>   a1<-tmp.a
>   rm(tmp.a)
> 
>   
>   Is it possible to avoid 'for' loop here?
> 
>   Thank you!
> 
> ---
> Best regards,
> Wladimir                mailto:wl at eimb.ru
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From spencer.graves at pdf.com  Tue Aug 23 06:11:15 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 22 Aug 2005 21:11:15 -0700
Subject: [R] specify seed for Random Number Generator
In-Reply-To: <BAY102-F20D65AC2ABB73090330AEED3B00@phx.gbl>
References: <BAY102-F20D65AC2ABB73090330AEED3B00@phx.gbl>
Message-ID: <430AA1E3.8090701@pdf.com>

	  Have you considered "set.seed"?  This was listed with the first hit 
for 'RSiteSearch("random number seed")'.

	  spencer graves

Dhiren DSouza wrote:

> I need to generate 100 I.I.D samples from an exponential distribution.  I 
> use rexp(100,parameter).  Is there anyway to specify a seed to determine the 
> first input for the uniform random number generator used to generate these 
> exponentials?
> 
> -Dhiren
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From Brandon.J.Whitcher at gsk.com  Mon Aug 22 10:00:27 2005
From: Brandon.J.Whitcher at gsk.com (Brandon.J.Whitcher@gsk.com)
Date: Mon, 22 Aug 2005 09:00:27 +0100
Subject: [R] [R-pkgs] New CRAN package: DICOM
Message-ID: <OF43F03024.B7B6774E-ON80257065.002B2E99-80257065.002BFD7F@gsk.com>

The package DICOM is a first attempt at a set of routines to import and 
summarize medical imaging data that conforms to the DICOM standard.  This 
is now the industry standard for a wide variety of medical imaging 
equipment (e.g., PET, MRI, CT, etc.).  Please see http://medical.nema.org 
for more information about the DICOM standard.  A simple list structure 
holds the separate header and image information.  I currently export any 
image files (4D arrays) in Analyze format for further analysis.  These 
(exporting) routines may be added in the future.

I welcome any comments/questions/suggestions.

cheers...

Brandon


Brandon Whitcher, PhD
Clinical Imaging Scientist
Translational Medicine & Genetics
GlaxoSmithKline, UK


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From anne.piotet at gmail.com  Tue Aug 23 10:02:38 2005
From: anne.piotet at gmail.com (Anne)
Date: Tue, 23 Aug 2005 09:02:38 +0100
Subject: [R] translating output ( latex()....)
In-Reply-To: <430A3FC9.3030704@vanderbilt.edu>
References: <80102e880508220551c6bb43f@mail.gmail.com>
	<430A3FC9.3030704@vanderbilt.edu>
Message-ID: <80102e8805082301022643771b@mail.gmail.com>

Hi and thanks for the answers!

Prof Ripley, I totally agree with you about the problem of the length
of the labels in French and would be very happy to do all my work in
English (however consider that probably Chinese/Japanese labels could
be still more efficient with one character having all the info...).
I'm already very happy to be able to use R professionnally (it was not
an easy solution to impose); the problem is that I need some output
for official (State) purposes and have to do it in the official
languages of Switzerland.

Frank,
Up to now I never used CVS (bad habit of working and developping
alone) but am quite willing to learn. I would like ultmately to
enhance the print. and latex. methods for the summary.formula family
of Hmisc for French and perhaps German and Italian too as I do have to
produce official output in these languages.

Anne
 

2005/8/22, Frank E Harrell Jr <f.harrell at vanderbilt.edu>:
> Anne wrote:
> > Dear R-helpers
> >
> > I need to produce statistical output where the annotations are in
> > French (and from time to time in German). I produce plots/tables using
> > extensively the latex() , summary.formula() ...functions of Hmisc
> > which allows me for nice print-out. Up to now I "corrected" manually
> > my latex code , replacing such headings as "missing" by "valeur
> > manquante" etc. Is there a (simple) way of updating the R functions
> > with the translated output? (I would of course gladly make it
> > available to the list)
> >
> > I know my question will sound like an heresy to the vast majority of
> > statisticians and I agree it is a waste of statistician time to do
> > translations, but it is due to work related constraints (and I fear
> > the "anti-americanisme primaire" encountered in some european
> > countries)
> >
> 
> Anne,
> 
> If you were to use a general way to detect the language (using the new
> facilities that Brian Ripley mentioned) and wanted to use that to
> enhance print. and latex. methods for the summary.formula family of
> functions, and know or can learn how to use CVS, we will consider giving
> you access to the Hmisc CVS repository to make the enhancements you want.
> 
> Frank
> 
> --
> Frank E Harrell Jr   Professor and Chair           School of Medicine
>                      Department of Biostatistics   Vanderbilt University
> 


-- 
Anne



From vin.everett at cimr.cam.ac.uk  Tue Aug 23 10:41:43 2005
From: vin.everett at cimr.cam.ac.uk (Vin Everett)
Date: Tue, 23 Aug 2005 09:41:43 +0100
Subject: [R] Compile probs amd64 solaris10 studio10 compilers
Message-ID: <430AE147.5070702@cimr.cam.ac.uk>

Hi All,

I am having some problems with my R compile and matrix.c

My config setings are:-

setenv CC "cc -xarch=amd64"
setenv F77 "f95 -xarch=amd64"
setenv CXX "CC -xarch=amd64"
setenv CFLAGS "-xO5 -xlibmil -dalign"
setenv FFLAGS "-xO5 -xlibmil -dalign"
setenv CXXFLAGS "-xO5 -xlibmil -dalign"
setenv SHLIB_CXXLDFLAGS -lCstd
setenv LDFLAGS "-L/usr/local/SUNWspro/lib/amd64 
-L/usr/local/SUNWspro/lib -L/usr
/local/lib"

I've installed a 64bit tcl/tk and readline




-- 
Vin.Everett at cimr.cam.ac.uk
JDRF/WT Diabetes and Inflammation Laboratory (DIL)
Cambridge Institute for Medical Research (CIMR)
Wellcome Trust/MRC Building Addenbrooke's Hospital
Hills Road Cambridge CB2 2XY
Tel +44 1223 763212
Fax +44 1223 762102
Mob +44 7990 966266



From jonathan.williams at pharmacology.oxford.ac.uk  Tue Aug 23 10:45:10 2005
From: jonathan.williams at pharmacology.oxford.ac.uk (Jonathan Williams)
Date: Tue, 23 Aug 2005 09:45:10 +0100
Subject: [R] Using tcltk to display jpeg images
Message-ID: <NGBBKJEMOMLJFCOIEGCEIEEFJOAA.jonathan.williams@pharm.ox.ac.uk>

Dear R Helpers,

Does anyone know how to use tcltk to display jpeg images? The manual says
that
one must use Tk_PhotoCreateImageFormat to register the jpeg image handler.
The
"ActiveTcl User Guide"
(http://support.serv.ch/lang/tcl/img/doc/img-jpeg.html)
says:-

"The package img::jpeg is a sub-package of Img. It can be loaded as a part
of the complete
Img support, via package require Img, or on its own, via package require
img::jpeg"

I downloaded the tkimg1.3 file from
http://kent.dl.sourceforge.net/sourceforge/tkimg/tkimg1.3.zip,
but I cannot figure out how to 'build' the files to link them to R.

Would someone be so kind as to tell me how to do this? Better still, does
anyone have an R routine
that will do it, since I have no experience of this kind of programming.

Thanks, in advance,

Jonathan Williams



From phgrosjean at sciviews.org  Tue Aug 23 11:18:40 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue, 23 Aug 2005 11:18:40 +0200
Subject: [R] Using tcltk to display jpeg images
In-Reply-To: <NGBBKJEMOMLJFCOIEGCEIEEFJOAA.jonathan.williams@pharm.ox.ac.uk>
References: <NGBBKJEMOMLJFCOIEGCEIEEFJOAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <430AE9F0.7000201@sciviews.org>

Hello,

You have to tell us on which platform you want to install the Tcl img 
package. If it is Windows, I can help.
Best,

Philippe

..............................................<??}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
( ( ( ( (
  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
  ) ) ) ) )
( ( ( ( (    web:   http://www.umh.ac.be/~econum
  ) ) ) ) )          http://www.sciviews.org
( ( ( ( (
..............................................................

Jonathan Williams wrote:
> Dear R Helpers,
> 
> Does anyone know how to use tcltk to display jpeg images? The manual says
> that
> one must use Tk_PhotoCreateImageFormat to register the jpeg image handler.
> The
> "ActiveTcl User Guide"
> (http://support.serv.ch/lang/tcl/img/doc/img-jpeg.html)
> says:-
> 
> "The package img::jpeg is a sub-package of Img. It can be loaded as a part
> of the complete
> Img support, via package require Img, or on its own, via package require
> img::jpeg"
> 
> I downloaded the tkimg1.3 file from
> http://kent.dl.sourceforge.net/sourceforge/tkimg/tkimg1.3.zip,
> but I cannot figure out how to 'build' the files to link them to R.
> 
> Would someone be so kind as to tell me how to do this? Better still, does
> anyone have an R routine
> that will do it, since I have no experience of this kind of programming.
> 
> Thanks, in advance,
> 
> Jonathan Williams
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From laurent.buffat at free.fr  Tue Aug 23 11:51:56 2005
From: laurent.buffat at free.fr (laurent buffat)
Date: Tue, 23 Aug 2005 11:51:56 +0200
Subject: [R] mozilla/firefox search engine AMD64 jre1.5 plugin linux
In-Reply-To: <Pine.LNX.4.61.0508221035410.1296@gannet.stats>
References: <43098D98.6080308@free.fr>
	<Pine.LNX.4.61.0508221035410.1296@gannet.stats>
Message-ID: <430AF1BC.6080803@free.fr>


Prof Brian Ripley wrote:

>
> On Windows, you would get help for a different version of R, but i686 
> Linux would be fine.  The latter is our solution: we only use AMD64 
> machines as servers.

It's the same for me (The AMD64 is just a box).
So, as you sugest (use an over computer to browse the help)
I have share the "/usr/lib64/R " directory of the "R server " by samba
and acces to the main page :

 file://///My-R-ServerAMD64Name/R-Doc/html/index.html

And it's work fine.

I  need to use the R help of the "R-server" because there is a lot of 
package install on the server and
it will be a lot a "work / space disk" to install/update these package 
on a over computer for the help.

Thanks for your help.

L. Buffat



From Ravi.Vishnu at outokumpu.com  Tue Aug 23 12:03:52 2005
From: Ravi.Vishnu at outokumpu.com (Ravi.Vishnu@outokumpu.com)
Date: Tue, 23 Aug 2005 12:03:52 +0200
Subject: [R] priority of operators in the  FOR (  ) statement
Message-ID: <OFA5E737A7.10467A0E-ONC1257066.0033C5B3-C1257066.0037492D@outokumpu.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050823/fd9d0b63/attachment.pl

From alegarra at neiker.net  Tue Aug 23 12:30:30 2005
From: alegarra at neiker.net (Andres Legarra)
Date: Tue, 23 Aug 2005 12:30:30 +0200
Subject: [R] matrix conformity with matrix 1x1 and scalars
Message-ID: <001001c5a7cd$af6e1a90$0802a8c0@iktlan.net>

Hello,
I am calculating this thing with vectors (b) and matrices (G,P):
b'G/sqrt(b'Pb)
where the denominator is a quadratic form and therefore always a scalar.

In Scilab, it is quite simple:
b'*G/sqrt(b'*P*b)
However, in R, the denominator is an (1x1)matrix and R claims it is non
conformable and I have to use drop() or as.numeric(). Like this:
> b = 1:2
> G=diag(1,2)
> P=diag(2,2)
> (t(b)%*%G) / drop( sqrt( t(b)%*%P%*%b ) )
          [,1]      [,2]
[1,] 0.3162278 0.6324555

So far, so good. My problem is solved. However I found a little bit annoying
that R is not so "clever" as to realize that b'Pb can be interpreted as a
scalar. I wonder :
would it be worth considering the implementation in R of
"recycling 1x1 matrix to scalars if appropriate"?
Just to leave the question on the ground...

Regards,

Andres
--
Andres Legarra
NEIKER
Apdo. 46
Vitoria-Gasteiz 01080 Spain
--





--
Andres Legarra Albizu
NEIKER
Apdo. 46
Vitoria-Gasteiz 01080 Spain
phone: +34 945 121323
fax: +34 945 281422
e-mail: alegarra at neiker.net
--



From murdoch at stats.uwo.ca  Tue Aug 23 12:44:15 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 23 Aug 2005 06:44:15 -0400
Subject: [R] priority of operators in the  FOR (  ) statement
In-Reply-To: <OFA5E737A7.10467A0E-ONC1257066.0033C5B3-C1257066.0037492D@outokumpu.com>
References: <OFA5E737A7.10467A0E-ONC1257066.0033C5B3-C1257066.0037492D@outokumpu.com>
Message-ID: <430AFDFF.1050007@stats.uwo.ca>

Ravi.Vishnu at outokumpu.com wrote:
> Dear All,
> I spent an entire evening in debugging a small, fairly simple program in R 
> - without success. It was my Guru in Bayesian Analysis, Thomas Fridtjof, 
> who was able to diagonose the problem. He said that it took a long time 
> for him also to locate the problem.
> This program illustrates in some ways the shortcomings of the error 
> messages that R responds with. 

To summarize:  you assumed that 1:nr-1 was equivalent to 1:(nr-1), 
rather than (1:nr)-1 (as documented).  This led to indexing by 0,
which (as is documented) gives a zero length vector.  R responded with 
the error message

>         missing value where TRUE/FALSE needed

when you used this in a test.  That seems like an appropriate error 
message to me.  I don't know any system that would respond better to 
user errors in operator priority:  those almost always lead to obscure 
errors, because the expression you write is often syntactically correct 
but logically wrong.

> 2. Faced with a similiar problem in the future, what is a smart way of 
> debugging in R to locate a problem. 

Use traceback() to isolate the location of the error, then debug() to 
single step through the function until you get to the error location. 
At that point, examine the values of the expressions involved in the 
calculation, and make sure they are as expected.

And in general:  if you aren't sure of the relative priority of two 
operators, use parentheses.  1:(nr-1) would work regardless of whether : 
or - had higher priority.  Or, in extreme cases, read the documentation.

Duncan Murdoch



From ehlers at math.ucalgary.ca  Tue Aug 23 12:51:33 2005
From: ehlers at math.ucalgary.ca (P Ehlers)
Date: Tue, 23 Aug 2005 04:51:33 -0600
Subject: [R] priority of operators in the  FOR (  ) statement
In-Reply-To: <OFA5E737A7.10467A0E-ONC1257066.0033C5B3-C1257066.0037492D@outokumpu.com>
References: <OFA5E737A7.10467A0E-ONC1257066.0033C5B3-C1257066.0037492D@outokumpu.com>
Message-ID: <430AFFB5.6060904@math.ucalgary.ca>

Since there is nothing wrong with

for(i in 1:nr - 1)

R can't really do much more than point to where your code
fails due your incorrect assumption about operator precedence.
You're certainly not the first to fall into this trap. But it's
not that hard to diagnose. Anytime I have problems with a loop,
I do three simple things:

1. for(i in whatever) print(i)
2. look at what traceback() says
3. step through the loop "by hand".

The first test would have told you (in much less than an
"entire evening") what the problem was.


Peter Ehlers


Ravi.Vishnu at outokumpu.com wrote:

> Dear All,
> I spent an entire evening in debugging a small, fairly simple program in R 
> - without success. It was my Guru in Bayesian Analysis, Thomas Fridtjof, 
> who was able to diagonose the problem. He said that it took a long time 
> for him also to locate the problem.
> This program illustrates in some ways the shortcomings of the error 
> messages that R responds with. In this case, it was quite misleading and 
> directs attention to a location far removed the actual problem statement.
> Without any more introductory comments, let me directly discuss the 
> essential problem. I am enclosing the entire program after a brief 
> discussion.
> 
> The problem arises from the following statement (nr is an integer 
> constant) :
> for ( i in 1:nr-1) {.......}
> The unexpected problem (at least for me) is that R reads the above 
> statement as (i in (1:nr)-1) {.....}. This makes i be initially as zero 
> which leads to an error because the for loop in R starts from 1. The 
> problem is easily fixed by writing the for loop as  ( i in 1:(nr-1)) 
> {.......}. This would be an easy problem to fix if R directly indicates 
> what the problem is. Instead, it gives mystifying error messages which are 
> totally misleading. For example, to the program given below, I got the 
> following error message (these point to commands elsewhere in the program) 
> :
> Error in if ((x >= 0) & (x < s2)) return(x/2) else if ((x >= s2) & (x <  : 
> 
>         missing value where TRUE/FALSE needed
> 
> I would like clarifications on the following points :
> 1. I am just curious to know if the priority of operators in the for 
> statement ( the colon before the minus operator, for example) is a 
> deliberate design decision. I have tested Matlab and found that it 
> interprets my original statement correctly without an extra paranthesis.
> 2. Faced with a similiar problem in the future, what is a smart way of 
> debugging in R to locate a problem. With this problem, I checked and 
> double checked every single statement in the program, except the for 
> statement because I just did not expect any problem there. I have seen 
> that there is a debug package but I have not used it. Can such tools be 
> used to locate a problem with greater ease? Can somebody give a concrete 
> example (for the following program, for example) of a debugging routine.
> 
> *************************************************************************'
> # Bayesian Data Analysis
> ## source("M:/programming/Rfolder/Assignments/fortest.txt")
> 
> # #Remove all objects from the workspace
> rm(list=ls())
> # #We will also try to note the time that the program takes
> # #We will start the clock at starttime
> starttime <- proc.time()[3];
> 
> my.function<-function(x) {
> s2<-sqrt(2);
> if ((x>=0) & (x<s2)) return(x/2)
> else 
> if ((x>=s2) & (x<1+s2)) return(0.2)
> else 
> if ((x>=1+s2) & (x<1.5+s2)) return(0.6)
> else 
> if ((x>1.5+s2) | (x<0)) return(0)
> }
> 
> alphayx<-function(y,x) {
> fy<-my.function(y)
> fx<-my.function(x)
> fyx<-fy/fx
> # to account for 0/0 division
> if (is.na(fyx)) fyx<-0
> #fyx<-ifelse(is.na(fyx),0,fyx);
> alpha<-min(1,fyx)
> return(alpha)
> }
> 
> sigma<-0.5;
> #nr is the number of iterations
> nr<-20
> x<-numeric(nr);
> x[1]<-1;
> t<-1:nr;
> 
> for (i in 1:nr-1) {
> xi<-x[i];
> yi<-rnorm(1,mean=xi,sd=sigma);
> ui<-runif(1,0,1);
> ualphai<-alphayx(yi,xi);
> xn<-ifelse(ui<=ualphai,yi,xi);
> x[i+1]<-xn;
> }
> 
> plot(t,x,type="p")
> 
> endtime<-proc.time()[3];
> elapsedTime<-endtime-starttime;
> cat("Elapsed time is", elapsedTime, "seconds", "\n")
> *****************************************************************************'
> 
> 
> 
>   
> This message is meant for the addressee only and may contain 
> confidential and legally privileged information. Any unauthorised 
> review, use, copying, storage, disclosure or distribution of this e-
> mail and any attachments is strictly prohibited. If you are not the 
> named recipient or have otherwise received this communication in 
> error, please destroy this message from your system and kindly notify 
> the sender by e-mail. Thank you for your co-operation.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Tue Aug 23 13:02:14 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 23 Aug 2005 12:02:14 +0100 (BST)
Subject: [R] matrix conformity with matrix 1x1 and scalars
In-Reply-To: <001001c5a7cd$af6e1a90$0802a8c0@iktlan.net>
References: <001001c5a7cd$af6e1a90$0802a8c0@iktlan.net>
Message-ID: <Pine.LNX.4.61.0508231154540.3362@gannet.stats>

On Tue, 23 Aug 2005, Andres Legarra wrote:

> Hello,
> I am calculating this thing with vectors (b) and matrices (G,P):
> b'G/sqrt(b'Pb)
> where the denominator is a quadratic form and therefore always a scalar.
>
> In Scilab, it is quite simple:
> b'*G/sqrt(b'*P*b)
> However, in R, the denominator is an (1x1)matrix and R claims it is non
> conformable and I have to use drop() or as.numeric(). Like this:
>> b = 1:2
>> G=diag(1,2)
>> P=diag(2,2)
>> (t(b)%*%G) / drop( sqrt( t(b)%*%P%*%b ) )
>          [,1]      [,2]
> [1,] 0.3162278 0.6324555
>
> So far, so good. My problem is solved. However I found a little bit annoying
> that R is not so "clever" as to realize that b'Pb can be interpreted as a
> scalar. I wonder :
> would it be worth considering the implementation in R of
> "recycling 1x1 matrix to scalars if appropriate"?
> Just to leave the question on the ground...

This "clever"ness often leads to running code that the users did not 
intend to work that way and so give misleading answers.  In retrospect 
many of us think R/S should be less "clever" than it is, since guessing 
the minds of end-users is a dangerous pursuit.  In particular, as a recent 
posting on operator precedence shows, some users will have very different 
preconceptions from the developers, _and_ blame the developers for not 
having their perconceptions.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From pburns at pburns.seanet.com  Tue Aug 23 13:12:20 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 23 Aug 2005 12:12:20 +0100
Subject: [R] priority of operators in the  FOR (  ) statement
In-Reply-To: <OFA5E737A7.10467A0E-ONC1257066.0033C5B3-C1257066.0037492D@outokumpu.com>
References: <OFA5E737A7.10467A0E-ONC1257066.0033C5B3-C1257066.0037492D@outokumpu.com>
Message-ID: <430B0494.9080402@pburns.seanet.com>

The command that I think is most useful in this situation
is 'browser()'.

Even a couple decades of programming in the S language
hasn't yet solved the problem of my fingers typing code that
doesn't match what I want to happen.  I quite consistently have
a

browser()

call in functions that I write to make sure that what I am assuming
is the same as what R assumes.


Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Ravi.Vishnu at outokumpu.com wrote:

>Dear All,
>I spent an entire evening in debugging a small, fairly simple program in R 
>- without success. It was my Guru in Bayesian Analysis, Thomas Fridtjof, 
>who was able to diagonose the problem. He said that it took a long time 
>for him also to locate the problem.
>This program illustrates in some ways the shortcomings of the error 
>messages that R responds with. In this case, it was quite misleading and 
>directs attention to a location far removed the actual problem statement.
>Without any more introductory comments, let me directly discuss the 
>essential problem. I am enclosing the entire program after a brief 
>discussion.
>
>The problem arises from the following statement (nr is an integer 
>constant) :
>for ( i in 1:nr-1) {.......}
>The unexpected problem (at least for me) is that R reads the above 
>statement as (i in (1:nr)-1) {.....}. This makes i be initially as zero 
>which leads to an error because the for loop in R starts from 1. The 
>problem is easily fixed by writing the for loop as  ( i in 1:(nr-1)) 
>{.......}. This would be an easy problem to fix if R directly indicates 
>what the problem is. Instead, it gives mystifying error messages which are 
>totally misleading. For example, to the program given below, I got the 
>following error message (these point to commands elsewhere in the program) 
>:
>Error in if ((x >= 0) & (x < s2)) return(x/2) else if ((x >= s2) & (x <  : 
>
>        missing value where TRUE/FALSE needed
>
>I would like clarifications on the following points :
>1. I am just curious to know if the priority of operators in the for 
>statement ( the colon before the minus operator, for example) is a 
>deliberate design decision. I have tested Matlab and found that it 
>interprets my original statement correctly without an extra paranthesis.
>2. Faced with a similiar problem in the future, what is a smart way of 
>debugging in R to locate a problem. With this problem, I checked and 
>double checked every single statement in the program, except the for 
>statement because I just did not expect any problem there. I have seen 
>that there is a debug package but I have not used it. Can such tools be 
>used to locate a problem with greater ease? Can somebody give a concrete 
>example (for the following program, for example) of a debugging routine.
>
>*************************************************************************'
># Bayesian Data Analysis
>## source("M:/programming/Rfolder/Assignments/fortest.txt")
>
># #Remove all objects from the workspace
>rm(list=ls())
># #We will also try to note the time that the program takes
># #We will start the clock at starttime
>starttime <- proc.time()[3];
>
>my.function<-function(x) {
>s2<-sqrt(2);
>if ((x>=0) & (x<s2)) return(x/2)
>else 
>if ((x>=s2) & (x<1+s2)) return(0.2)
>else 
>if ((x>=1+s2) & (x<1.5+s2)) return(0.6)
>else 
>if ((x>1.5+s2) | (x<0)) return(0)
>}
>
>alphayx<-function(y,x) {
>fy<-my.function(y)
>fx<-my.function(x)
>fyx<-fy/fx
># to account for 0/0 division
>if (is.na(fyx)) fyx<-0
>#fyx<-ifelse(is.na(fyx),0,fyx);
>alpha<-min(1,fyx)
>return(alpha)
>}
>
>sigma<-0.5;
>#nr is the number of iterations
>nr<-20
>x<-numeric(nr);
>x[1]<-1;
>t<-1:nr;
>
>for (i in 1:nr-1) {
>xi<-x[i];
>yi<-rnorm(1,mean=xi,sd=sigma);
>ui<-runif(1,0,1);
>ualphai<-alphayx(yi,xi);
>xn<-ifelse(ui<=ualphai,yi,xi);
>x[i+1]<-xn;
>}
>
>plot(t,x,type="p")
>
>endtime<-proc.time()[3];
>elapsedTime<-endtime-starttime;
>cat("Elapsed time is", elapsedTime, "seconds", "\n")
>*****************************************************************************'
>
>
>
>  
>This message is meant for the addressee only and may contain 
>confidential and legally privileged information. Any unauthorised 
>review, use, copying, storage, disclosure or distribution of this e-
>mail and any attachments is strictly prohibited. If you are not the 
>named recipient or have otherwise received this communication in 
>error, please destroy this message from your system and kindly notify 
>the sender by e-mail. Thank you for your co-operation.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From Ted.Harding at nessie.mcc.ac.uk  Tue Aug 23 13:07:34 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Tue, 23 Aug 2005 12:07:34 +0100 (BST)
Subject: [R] priority of operators in the  FOR (  ) statement
In-Reply-To: <430AFDFF.1050007@stats.uwo.ca>
Message-ID: <XFMail.050823120734.Ted.Harding@nessie.mcc.ac.uk>

On 23-Aug-05 Duncan Murdoch wrote:
> [...]
> ... in extreme cases, read the documentation.

One for "fortunes"?

Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 23-Aug-05                                       Time: 12:05:42
------------------------------ XFMail ------------------------------



From ggrothendieck at gmail.com  Tue Aug 23 13:28:46 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 23 Aug 2005 07:28:46 -0400
Subject: [R] priority of operators in the FOR ( ) statement
In-Reply-To: <OFA5E737A7.10467A0E-ONC1257066.0033C5B3-C1257066.0037492D@outokumpu.com>
References: <OFA5E737A7.10467A0E-ONC1257066.0033C5B3-C1257066.0037492D@outokumpu.com>
Message-ID: <971536df050823042838d3676a@mail.gmail.com>

On 8/23/05, Ravi.Vishnu at outokumpu.com <Ravi.Vishnu at outokumpu.com> wrote:
> Dear All,
> I spent an entire evening in debugging a small, fairly simple program in R
> - without success. It was my Guru in Bayesian Analysis, Thomas Fridtjof,
> who was able to diagonose the problem. He said that it took a long time
> for him also to locate the problem.
> This program illustrates in some ways the shortcomings of the error
> messages that R responds with. In this case, it was quite misleading and
> directs attention to a location far removed the actual problem statement.
> Without any more introductory comments, let me directly discuss the
> essential problem. I am enclosing the entire program after a brief
> discussion.
> 
> The problem arises from the following statement (nr is an integer
> constant) :
> for ( i in 1:nr-1) {.......}
> The unexpected problem (at least for me) is that R reads the above
> statement as (i in (1:nr)-1) {.....}. This makes i be initially as zero
> which leads to an error because the for loop in R starts from 1. The
> problem is easily fixed by writing the for loop as  ( i in 1:(nr-1))
> {.......}. This would be an easy problem to fix if R directly indicates
> what the problem is. Instead, it gives mystifying error messages which are
> totally misleading. For example, to the program given below, I got the
> following error message (these point to commands elsewhere in the program)
> :
> Error in if ((x >= 0) & (x < s2)) return(x/2) else if ((x >= s2) & (x <  :
> 
>        missing value where TRUE/FALSE needed
> 
> I would like clarifications on the following points :
> 1. I am just curious to know if the priority of operators in the for
> statement ( the colon before the minus operator, for example) is a
> deliberate design decision. I have tested Matlab and found that it
> interprets my original statement correctly without an extra paranthesis.

?Syntax gives the operator precedence.

Also, note that : is probably best not used in functions since it does
not handle boundary conditions properly.   If n were 0 then 1:n 
results in two iterations corresonding to 1 and 0 but what you
really wanted was likely no iterations at all.  To do that you need
seq(length = n) rather than ":".   

Also I have found expressions like 0:1/10 handy to generate 
0, .1, .2, ..., 1 and that works with the current precedence.



From gavin.simpson at ucl.ac.uk  Tue Aug 23 14:18:44 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Tue, 23 Aug 2005 13:18:44 +0100
Subject: [R] confidence interval for StructTS?
Message-ID: <1124799524.25630.20.camel@gsimpson.geog.ucl.ac.uk>

Dear list,

I have fitted a local level structural time series model to some data
using StructTS(). I would like to plot a 95% confidence interval for the
fitted values (either the contemporaneous predictions [component fitted
returned by StructTS] or the predictions based on observing the whole
time-series [e.g. from tsSmooth]).

predict.StructTS() has the option of getting the standard errors of
forecasts. I'd like to get the same but for observed series.

Thanks in advance,

Gav
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From mike_saunders at umenfa.maine.edu  Tue Aug 23 14:52:22 2005
From: mike_saunders at umenfa.maine.edu (Mike Saunders)
Date: Tue, 23 Aug 2005 08:52:22 -0400
Subject: [R] Plotting using image files
Message-ID: <000a01c5a7e1$810f7040$9ba76f82@CFRU0104>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050823/df4b3467/attachment.pl

From duncan at wald.ucdavis.edu  Wed Aug 17 20:29:15 2005
From: duncan at wald.ucdavis.edu (Duncan Temple Lang)
Date: Wed, 17 Aug 2005 11:29:15 -0700
Subject: [R] accesing slots of S4 class in C code
In-Reply-To: <2372A3FFAF50104B9929841F6B9B878302109309@EMAIL.hci.utah.edu>
References: <2372A3FFAF50104B9929841F6B9B878302109309@EMAIL.hci.utah.edu>
Message-ID: <20050817182915.GC30958@wald.ucdavis.edu>


You need to use .Call() rather than .C() to pass the R object
to the TestFun routine.

 D.

Aniko Szabo wrote:
> I am trying to use a custom S4 object in my C code and I cannot get the
> access to its slots working.
> 
>  
> 
> The following is a toy example, but even this crashes. 
> 
>  
> 
> In R I have:
> 
>  
> 
> setClass("pd", representation(data="numeric"))
> 
> x <- new("pd", data=1:5)
> 
>  
> 
> test <- function(pd.obj) {
> 
>   res <- .C("TestFun", pd.obj)
> 
>   res}
> 
>  
> 
> test(x)
> 
>  
> 
> (Of couse I load the DLL as well.)
> 
>  
> 
> The corresponding C file has:
> 
>  
> 
> SEXP TestFun(SEXP pd_obj)
> 
> {
> 
>  SEXP t=R_NilValue;
> 
>  PROTECT(t = GET_SLOT(pd_obj, install("data")));
> 
>  UNPROTECT(1);
> 
>  return(t);
> 
> }
> 
>  
> 
>  
> 
> What I hope to get as a result is the (1:5) vector. 
> 
> In the long term, the vector will be a multi-dimensional array and I
> will want to do calculations using its contents in the C program.
> 
>  
> 
> Thanks for any help,
> 
>  
> 
> Aniko
> 
> 
> Huntsman Cancer Institute wishes to promote open communication while protecting confidential and/or privileged information.  If you have received this message in error, please inform the sender and delete all copies.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Duncan Temple Lang                duncan at wald.ucdavis.edu
Department of Statistics          work:  (530) 752-4782
371 Kerr Hall                     fax:   (530) 752-7099
One Shields Ave.
University of California at Davis
Davis, CA 95616, USA



-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 189 bytes
Desc: not available
Url : https://stat.ethz.ch/pipermail/r-help/attachments/20050817/320752cd/attachment.bin

From phgrosjean at sciviews.org  Tue Aug 23 15:12:48 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Tue, 23 Aug 2005 15:12:48 +0200
Subject: [R] Using tcltk to display jpeg images
In-Reply-To: <NGBBKJEMOMLJFCOIEGCEMEEGJOAA.jonathan.williams@pharm.ox.ac.uk>
References: <NGBBKJEMOMLJFCOIEGCEMEEGJOAA.jonathan.williams@pharm.ox.ac.uk>
Message-ID: <430B20D0.2050905@sciviews.org>

Jonathan Williams wrote:
> Thank you,
> 
> I am running R 2.1.1 via Windows XP.
> 
> Sorry, you will realise how little I know about this because I
> did not know that the operating system would make a difference!

No problems. Indeed, you have to install BINARIES of the img tcl 
package. One solution is to install a Tcl/Tk distribution that includes 
already that package. ActiveTcl is the one that comes to mind 
immediatelly. Here is the procedure to use it:

- Go to http://www.activestate.com/Products/ActiveTcl/, then 'Free 
download', then download ActiveTcl 8.4.11.0 for Windows, which contains 
Img 1.3. Do NOT download ActiveTcl 8.5.XXX: it is not compatible with R!

- Install it, let's say in 'c:\Tcl'

- Create a copy of the shortcut that starts R. Rename it (for instance R 
2.1.1 - ActiveTcl).

- Right click on this shortcut and select 'Properties' in the context 
menu. Then change taget from:
"C:\Program Files\R\rw2011\bin\Rgui.exe"
to:
"C:\Program Files\R\rw2011\bin\Rgui.exe" MY_TCLTK=c:/Tcl

- Start R from this shortcut.

- Load the tcltk package and create a Tk window:
 > library(tcltk)
 > tt <- tktoplevel()

You know that you are using ActiveTcl, and not the Tcl package provided 
with R because the icon of that window is changed from a red "Tk" to the 
  brown plume that is the icon of ActiveState.

- At this point, the Img Tcl package is available to you from R. The 
rest is taken from 
http://bioinf.wehi.edu.au/~wettenhall/RTclTkExamples/showImage.html:
 > R.base.dir <- system.file()
 > setwd(paste(R.base.dir,"/../../doc/html",sep=""))
 > require(tcltk)
Loading required package: tcltk
Loading Tcl/Tk interface ... done
[1] TRUE
 > tt <- tktoplevel()
 > tclRequire("Img")
<Tcl> 1.3
 > image1 <- tclVar()
 > tkcmd("image","create","photo",image1,file="logo.jpg")
<Tcl> ::RTcl1
 > imgAsLabel <- tklabel(tt,image=image1,bg="white")
 > tkpack(imgAsLabel)
<Tcl>

You should read also the R for Windows FAQ 3.6.

Finally, when it works, there is another (and perhaps simpler) way to 
load the Img tcl package, using the Tcl version distributed with R. You 
just have to specify: addTclPath("c:/tcl/lib"). So, you can start R 
normally (using the default Tcl distributed with it), and do:
 > library(tcltk)
Loading Tcl/Tk interface ... done
 > addTclPath("c:/xtra/tcl/lib") # This is how you gain access to the 
ActiveTcl library!
 > R.base.dir <- system.file()
 > setwd(paste(R.base.dir,"/../../doc/html",sep=""))
 > tt <- tktoplevel()
 > tclRequire("Img")
<Tcl> 1.3
 > image1 <- tclVar()
 > tkcmd("image","create","photo",image1,file="logo.jpg")
<Tcl> ::RTcl1
 > imgAsLabel <- tklabel(tt,image=image1,bg="white")
 > tkpack(imgAsLabel)
<Tcl>

Note that you can relocate the /lib subdir of ActiveTcl, or only 
/lib/Img1.3 and use AddTclPath() to access it at the new location. This 
way, you don't have to install ActiveTcl on all the computers where you 
want to use Img. You just need to copy /lib/Img1.3 there and use 
AddTclPath(). However, take care of the ActiveState license that 
constrains you to download their software from their web site and to 
register. So, you can only use this method for multiple installations on 
your own computers... but not for redistribution!

Best,

Philippe Grosjean

..............................................<??}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
( ( ( ( (
  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
  ) ) ) ) )
( ( ( ( (    web:   http://www.umh.ac.be/~econum
  ) ) ) ) )          http://www.sciviews.org
( ( ( ( (
..............................................................

> 
> Jonathan
> 
> -----Original Message-----
> From: Philippe Grosjean [mailto:phgrosjean at sciviews.org]
> Sent: 23 August 2005 10:19
> To: Jonathan Williams
> Cc: Ethz. Ch
> Subject: Re: [R] Using tcltk to display jpeg images
> 
> 
> Hello,
> 
> You have to tell us on which platform you want to install the Tcl img
> package. If it is Windows, I can help.
> Best,
> 
> Philippe
> 
> ..............................................<??}))><........
>   ) ) ) ) )
> ( ( ( ( (    Prof. Philippe Grosjean
>   ) ) ) ) )
> ( ( ( ( (    Numerical Ecology of Aquatic Systems
>   ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
> ( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
>   ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
> ( ( ( ( (
>   ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
> ( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
>   ) ) ) ) )
> ( ( ( ( (    web:   http://www.umh.ac.be/~econum
>   ) ) ) ) )          http://www.sciviews.org
> ( ( ( ( (
> ..............................................................
> 
> Jonathan Williams wrote:
> 
>>Dear R Helpers,
>>
>>Does anyone know how to use tcltk to display jpeg images? The manual says
>>that
>>one must use Tk_PhotoCreateImageFormat to register the jpeg image handler.
>>The
>>"ActiveTcl User Guide"
>>(http://support.serv.ch/lang/tcl/img/doc/img-jpeg.html)
>>says:-
>>
>>"The package img::jpeg is a sub-package of Img. It can be loaded as a part
>>of the complete
>>Img support, via package require Img, or on its own, via package require
>>img::jpeg"
>>
>>I downloaded the tkimg1.3 file from
>>http://kent.dl.sourceforge.net/sourceforge/tkimg/tkimg1.3.zip,
>>but I cannot figure out how to 'build' the files to link them to R.
>>
>>Would someone be so kind as to tell me how to do this? Better still, does
>>anyone have an R routine
>>that will do it, since I have no experience of this kind of programming.
>>
>>Thanks, in advance,
>>
>>Jonathan Williams
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide!
> 
> http://www.R-project.org/posting-guide.html
> 
>>
> 
> 
> 
>



From rcran at aegee.student.kun.nl  Tue Aug 23 15:13:09 2005
From: rcran at aegee.student.kun.nl (Vincent de Groot)
Date: Tue, 23 Aug 2005 15:13:09 +0200
Subject: [R] GLM->Repeated measures (multivariate)
Message-ID: <001301c5a7e4$68ea1300$2b00000a@rhodes>

Dear subscribers,

I'm trying to make the switch from M$ Windows to Linux (KDE) and found the 
R-cran project for statistical analysis. I'm not a genius in statistics so 
the command line interface is a bit hard for me.

I need an analogue way to do the SPSS General Linear Model->Repeated 
Measures (multivariate) but I don't have a clue how to perform this in 
R-cran. Can maybe somebody of you help me with supplying a GLM-Repeated 
measures 'cookbook'? Or can you point me maybe to an online resource like a 
tutorial or manual explaining this?

I searched the Internet already but for me it was impossible to find 
something useful. As I said. I'm only a 'user' of SPSS and not a statistics 
guru.

I have read the basic documentation (importing, plotting, calculating) and 
played with it already :-).

Thanks in advance.

Many greetings,
 Vincent de Groot



From hb at maths.lth.se  Tue Aug 23 15:41:02 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 23 Aug 2005 15:41:02 +0200
Subject: [R] Plotting using image files
In-Reply-To: <000a01c5a7e1$810f7040$9ba76f82@CFRU0104>
References: <000a01c5a7e1$810f7040$9ba76f82@CFRU0104>
Message-ID: <430B276E.1050806@maths.lth.se>

Mike Saunders wrote:
> This is a strange request, but I want to build a scatterplot using different image files (jpegs, gif, etc.) as the plot symbols.  I have thought about setting this up using a very large layout matrix, but I thought someone might have a better approach.  Furthermore, is there any way to have R paste an image file into a specific coordinate within a scatterplot?

I don't think this is possible using the default graphics engine in R, 
but here is another solution using ImageMagick 
(http://www.imagemagick.org/) calls from R.  I once needed something 
similar to highlight certain cities on a Swedish map given their 
longitute/latitude coordinates.  The map was given as bitmap image. 
Given a few reference citites with known longitute/latitude and pixel 
coordinates I used a quick-and-dirty 2d-loess to get a 
longitute/latitude-to-pixel coordinate mapping.  This way I could find 
the pixel coordinates for new citites and then I used ImageMagick to add 
colorful discs in the original bitmap image.  The result is as shown on 
http://www.maths.lth.se/kovalevsky/skolor/.  It is quite easy to write 
wrapper functions in R that calls ImageMagick via system() calls.  My 
code is in http://www.maths.lth.se/kovalevsky/skolor/updatemap.R, but 
please don't ask me to explain how it works, because I don't have the 
time available for that. Basically, ImageMagick's 'convert' command 
provide command line options to add discs ("circles"), lines etc in 
different colors to existing images.  Make sure to set a pen color 
before drawing.  I think it allows you to "draw" using other bitmap 
image too.  My R code generates a convert call string which is called at 
the end.

Hope this helps a bit

Henrik Bengtsson


> Thanks in advance,
> Mike 
> 
> 
> Mike Saunders
> Research Assistant
> Forest Ecosystem Research Program
> Department of Forest Ecosystem Sciences
> University of Maine
> Orono, ME  04469
> 207-581-2763 (O)
> 207-581-4257 (F)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From hoffman.mm at gmail.com  Tue Aug 23 15:27:03 2005
From: hoffman.mm at gmail.com (Michael Hoffman)
Date: Tue, 23 Aug 2005 14:27:03 +0100
Subject: [R] Substituted arguments surviving multiple function calls
Message-ID: <def879$2vr$1@sea.gmane.org>

I am using R 2.1.1 and have written a function that will retrieve a 
named column from a data frame:

d = data.frame(a1=c(4, 2), a2=c(6, 7))
f1 = function(x)
{
   do.call("$", list(d, substitute(x)))
}

So this works:

 > f1(a1)
[1] 4 2

However, I want to make another function, f2, which also accepts a 
column name as an argument and then calls the first function with it:

f2 = function(x)
{
   f1(substitute(x))
}

However, this does not work:

 > f2(a1)
Error in list(a1 = c(4, 2), a2 = c(6, 7))$substitute(x) :
         invalid subscript type

It works if I take the substitute() out of f1(), but then I can only 
call f1() through f2() or something that does the substitution for it.
Is there a better way to do this?

Thanks for any help you can offer.
-- 
Michael Hoffman



From mathieu.drapeau at mcgill.ca  Tue Aug 23 16:45:17 2005
From: mathieu.drapeau at mcgill.ca (Mathieu Drapeau, Mr.)
Date: Tue, 23 Aug 2005 10:45:17 -0400
Subject: [R] ROracle installation problem
Message-ID: <DB8902F1339F264C970EFF3FC7CB8F320D7BEF@EXCHANGE2VS2.campus.mcgill.ca>

Hi there,
I am trying to install ROracle but I get this error. I have an error in reconcilePropertiesAndPrototype.
(My LD_LIBRARY_PATH is set with the oracle lib)
 
Thanks,
Mathieu
 
 
# R CMD INSTALL --configure-args='--enable-extralibs' ../ROracle_0.5-5.tar.gz
* Installing *source* package 'ROracle' ...
creating cache ./config.cache
checking how to run the C preprocessor... cc -E
updating cache ./config.cache
creating ./config.status
creating src/Makevars
creating src/Makefile
** libs
R CMD COMPILE RS-DBI.c
make[1]: Entering directory `/tmp/R.INSTALL.10940/ROracle/src'
gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c RS-DBI.c -o RS-DBI.o
make[1]: Leaving directory `/tmp/R.INSTALL.10940/ROracle/src'
proc               CODE=ANSI_C             MODE=ORACLE INCLUDE=/usr/lib/R/include \
                PARSE=NONE LINES=false             RS-Oracle.pc
Pro*C/C++: Release 9.2.0.1.0 - Production on Tue Aug 23 10:43:25 2005
Copyright (c) 1982, 2002, Oracle Corporation.  All rights reserved.
System default option values taken from: /opt/oracle/product/9.2.0/precomp/admin/pcscfg.cfg
R CMD COMPILE RS-Oracle.c
make[1]: Entering directory `/tmp/R.INSTALL.10940/ROracle/src'
gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c RS-Oracle.c -o RS-Oracle.o
make[1]: Leaving directory `/tmp/R.INSTALL.10940/ROracle/src'
R CMD SHLIB -o ROracle.so RS-DBI.o RS-Oracle.o
make[1]: Entering directory `/tmp/R.INSTALL.10940/ROracle/src'
gcc -shared -L/usr/local/lib -o ROracle.so RS-DBI.o RS-Oracle.o -L/opt/oracle/product/9.2.0/lib -L/opt/oracle/product/9.2.0/network/lib -lclntst9 -lnbeq9 -lnhost9 -lnus9 -lnldap9 -lldapclnt9 -lnsslb9 -lnoname9 -lntcp9 -lntcps9 -lnsslb9 -lntcp9 -lntns9 -ldl -lm -lpthread -lnsl -ldl -lm -lsqlplus  
make[1]: Leaving directory `/tmp/R.INSTALL.10940/ROracle/src'
** R
** inst
** save image
[1] TRUE
Loading required package: DBI 
[1] FALSE
Warning message: 
There is no package called 'DBI' in: library(package, character.only = TRUE, logical = TRUE, warn.conflicts = warn.conflicts,  
[1] "dbObjectId"
Creating a new generic function for "format" in "ROracle" 
[1] "format"
[1] "show"
Creating a new generic function for "print" in "ROracle" 
[1] "print"
Error in reconcilePropertiesAndPrototype(name, slots, prototype, superClasses,  : 
        Class "DBIPreparedStatement" extends an undefined class ("DBIObject"
Execution halted
/usr/lib/R/bin/INSTALL: line 1: 11177 Broken pipe             cat "/usr/lib/R/library/ROracle/R/ROracle"
ERROR: execution of package source for 'ROracle' failed
** Removing '/usr/lib/R/library/ROracle'



From francoisromain at free.fr  Tue Aug 23 16:55:00 2005
From: francoisromain at free.fr (Romain Francois)
Date: Tue, 23 Aug 2005 16:55:00 +0200
Subject: [R] Plotting using image files
In-Reply-To: <000a01c5a7e1$810f7040$9ba76f82@CFRU0104>
References: <000a01c5a7e1$810f7040$9ba76f82@CFRU0104>
Message-ID: <430B38C4.4070006@free.fr>

Le 23.08.2005 14:52, Mike Saunders a ??crit :

>This is a strange request, but I want to build a scatterplot using different image files (jpegs, gif, etc.) as the plot symbols.  I have thought about setting this up using a very large layout matrix, but I thought someone might have a better approach.  Furthermore, is there any way to have R paste an image file into a specific coordinate within a scatterplot?
>
>Thanks in advance,
>Mike 
>
>  
>
Hello Mike,

Maybe you can try using the pixmap package, something like this :

require(pixmap)
logo <- read.pnm(system.file("pictures/logo.ppm", package="pixmap")[1])
x <- rnorm(10)
y <- rnorm(10,sd=.4)+x
plot(x,y, type="n")
for(i in 1:10){       
                  u <- runif(1)/10 + .1
                  addlogo(logo, x[i]+c(-u,u), y[i]+c(-u,u), asp=1)
}
# points(x,y, pch="+")

All you have to de then is having your images in ppm format. I think 
gimp will do it for you.
There is also a few tools in netpbm (only on linux i think).


Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From gunter.berton at gene.com  Tue Aug 23 16:56:01 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 23 Aug 2005 07:56:01 -0700
Subject: [R] priority of operators in the  FOR (  ) statement
In-Reply-To: <XFMail.050823120734.Ted.Harding@nessie.mcc.ac.uk>
Message-ID: <200508231456.j7NEu1kJ028428@hertz.gene.com>

Right on! (oops -- maybe that's another 60's phrase  :( )

-- Bert
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Ted Harding
> Sent: Tuesday, August 23, 2005 4:08 AM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] priority of operators in the FOR ( ) statement
> 
> On 23-Aug-05 Duncan Murdoch wrote:
> > [...]
> > ... in extreme cases, read the documentation.
> 
> One for "fortunes"?
> 
> Ted.
> 
> 
> --------------------------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
> Fax-to-email: +44 (0)870 094 0861
> Date: 23-Aug-05                                       Time: 12:05:42
> ------------------------------ XFMail ------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From greg.snow at ihc.com  Tue Aug 23 16:59:04 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Tue, 23 Aug 2005 08:59:04 -0600
Subject: [R] Plotting using image files
Message-ID: <s30ae569.067@lp-msg1.co.ihc.com>


>>> "Mike Saunders" <mike_saunders at umenfa.maine.edu> 08/23/05 06:52AM
>>>
>> This is a strange request, but I want to build a scatterplot using
different image files (jpegs, gif, etc.) as the plot symbols.
>>   I have thought about setting this up using a very large layout
matrix, but I thought someone might have a better
>>  approach.  Furthermore, is there any way to have R paste an image
file into a specific coordinate within a scatterplot?

Here is an example using cnvrt.coords from the TeachingDemos package
and the jpeg plotting functions from the rimage
package:

library(TeachingDemos)
library(rimage)
data(logo)

x <- runif(10,3,6)
y <- runif(10,100,200)

plot(x,y, type='n')

cp <- par(no.readonly=TRUE)
tmp <- cnvrt.coords(x,y)

for (i in 1:10){
  par(plt=c(tmp$dev$x[i] + c(-0.03,0.03), tmp$dev$y[i] +
c(-0.03,0.03)),
      new=TRUE)
  plot(logo)
}

par(cp)


hope this helps,

Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111



From ripley at stats.ox.ac.uk  Tue Aug 23 17:01:09 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 23 Aug 2005 16:01:09 +0100 (BST)
Subject: [R] ROracle installation problem
In-Reply-To: <DB8902F1339F264C970EFF3FC7CB8F320D7BEF@EXCHANGE2VS2.campus.mcgill.ca>
References: <DB8902F1339F264C970EFF3FC7CB8F320D7BEF@EXCHANGE2VS2.campus.mcgill.ca>
Message-ID: <Pine.LNX.4.61.0508231559590.23481@gannet.stats>

Notice

   Loading required package: DBI
   There is no package called 'DBI' in: library(package, ....

So please note the DESCRIPTION and install the dependency DBI.


On Tue, 23 Aug 2005, Mathieu Drapeau, Mr. wrote:

> Hi there,
> I am trying to install ROracle but I get this error. I have an error in reconcilePropertiesAndPrototype.
> (My LD_LIBRARY_PATH is set with the oracle lib)
>
> Thanks,
> Mathieu
>
>
> # R CMD INSTALL --configure-args='--enable-extralibs' ../ROracle_0.5-5.tar.gz
> * Installing *source* package 'ROracle' ...
> creating cache ./config.cache
> checking how to run the C preprocessor... cc -E
> updating cache ./config.cache
> creating ./config.status
> creating src/Makevars
> creating src/Makefile
> ** libs
> R CMD COMPILE RS-DBI.c
> make[1]: Entering directory `/tmp/R.INSTALL.10940/ROracle/src'
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c RS-DBI.c -o RS-DBI.o
> make[1]: Leaving directory `/tmp/R.INSTALL.10940/ROracle/src'
> proc               CODE=ANSI_C             MODE=ORACLE INCLUDE=/usr/lib/R/include \
>                PARSE=NONE LINES=false             RS-Oracle.pc
> Pro*C/C++: Release 9.2.0.1.0 - Production on Tue Aug 23 10:43:25 2005
> Copyright (c) 1982, 2002, Oracle Corporation.  All rights reserved.
> System default option values taken from: /opt/oracle/product/9.2.0/precomp/admin/pcscfg.cfg
> R CMD COMPILE RS-Oracle.c
> make[1]: Entering directory `/tmp/R.INSTALL.10940/ROracle/src'
> gcc -I/usr/lib/R/include  -I/usr/local/include -D__NO_MATH_INLINES -mieee-fp  -fPIC  -O2 -g -pipe -march=i386 -mcpu=i686 -c RS-Oracle.c -o RS-Oracle.o
> make[1]: Leaving directory `/tmp/R.INSTALL.10940/ROracle/src'
> R CMD SHLIB -o ROracle.so RS-DBI.o RS-Oracle.o
> make[1]: Entering directory `/tmp/R.INSTALL.10940/ROracle/src'
> gcc -shared -L/usr/local/lib -o ROracle.so RS-DBI.o RS-Oracle.o -L/opt/oracle/product/9.2.0/lib -L/opt/oracle/product/9.2.0/network/lib -lclntst9 -lnbeq9 -lnhost9 -lnus9 -lnldap9 -lldapclnt9 -lnsslb9 -lnoname9 -lntcp9 -lntcps9 -lnsslb9 -lntcp9 -lntns9 -ldl -lm -lpthread -lnsl -ldl -lm -lsqlplus
> make[1]: Leaving directory `/tmp/R.INSTALL.10940/ROracle/src'
> ** R
> ** inst
> ** save image
> [1] TRUE
> Loading required package: DBI
> [1] FALSE
> Warning message:
> There is no package called 'DBI' in: library(package, character.only = TRUE, logical = TRUE, warn.conflicts = warn.conflicts,
> [1] "dbObjectId"
> Creating a new generic function for "format" in "ROracle"
> [1] "format"
> [1] "show"
> Creating a new generic function for "print" in "ROracle"
> [1] "print"
> Error in reconcilePropertiesAndPrototype(name, slots, prototype, superClasses,  :
>        Class "DBIPreparedStatement" extends an undefined class ("DBIObject"
> Execution halted
> /usr/lib/R/bin/INSTALL: line 1: 11177 Broken pipe             cat "/usr/lib/R/library/ROracle/R/ROracle"
> ERROR: execution of package source for 'ROracle' failed
> ** Removing '/usr/lib/R/library/ROracle'
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From gunter.berton at gene.com  Tue Aug 23 17:07:53 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 23 Aug 2005 08:07:53 -0700
Subject: [R] priority of operators in the  FOR (  ) statement
In-Reply-To: <430B0494.9080402@pburns.seanet.com>
Message-ID: <200508231507.j7NF7r7E002493@hertz.gene.com>

... and there is also Mark Bravington's debug package for more IDE-like
debugging.

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Patrick Burns
> Sent: Tuesday, August 23, 2005 4:12 AM
> To: Ravi.Vishnu at outokumpu.com
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] priority of operators in the FOR ( ) statement
> 
> The command that I think is most useful in this situation
> is 'browser()'.
> 
> Even a couple decades of programming in the S language
> hasn't yet solved the problem of my fingers typing code that
> doesn't match what I want to happen.  I quite consistently have
> a
> 
> browser()
> 
> call in functions that I write to make sure that what I am assuming
> is the same as what R assumes.
> 
> 
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
> 
> Ravi.Vishnu at outokumpu.com wrote:
> 
> >Dear All,
> >I spent an entire evening in debugging a small, fairly 
> simple program in R 
> >- without success. It was my Guru in Bayesian Analysis, 
> Thomas Fridtjof, 
> >who was able to diagonose the problem. He said that it took 
> a long time 
> >for him also to locate the problem.
> >This program illustrates in some ways the shortcomings of the error 
> >messages that R responds with. In this case, it was quite 
> misleading and 
> >directs attention to a location far removed the actual 
> problem statement.
> >Without any more introductory comments, let me directly discuss the 
> >essential problem. I am enclosing the entire program after a brief 
> >discussion.
> >
> >The problem arises from the following statement (nr is an integer 
> >constant) :
> >for ( i in 1:nr-1) {.......}
> >The unexpected problem (at least for me) is that R reads the above 
> >statement as (i in (1:nr)-1) {.....}. This makes i be 
> initially as zero 
> >which leads to an error because the for loop in R starts from 1. The 
> >problem is easily fixed by writing the for loop as  ( i in 1:(nr-1)) 
> >{.......}. This would be an easy problem to fix if R 
> directly indicates 
> >what the problem is. Instead, it gives mystifying error 
> messages which are 
> >totally misleading. For example, to the program given below, 
> I got the 
> >following error message (these point to commands elsewhere 
> in the program) 
> >:
> >Error in if ((x >= 0) & (x < s2)) return(x/2) else if ((x >= 
> s2) & (x <  : 
> >
> >        missing value where TRUE/FALSE needed
> >
> >I would like clarifications on the following points :
> >1. I am just curious to know if the priority of operators in the for 
> >statement ( the colon before the minus operator, for example) is a 
> >deliberate design decision. I have tested Matlab and found that it 
> >interprets my original statement correctly without an extra 
> paranthesis.
> >2. Faced with a similiar problem in the future, what is a 
> smart way of 
> >debugging in R to locate a problem. With this problem, I checked and 
> >double checked every single statement in the program, except the for 
> >statement because I just did not expect any problem there. I 
> have seen 
> >that there is a debug package but I have not used it. Can 
> such tools be 
> >used to locate a problem with greater ease? Can somebody 
> give a concrete 
> >example (for the following program, for example) of a 
> debugging routine.
> >
> >*************************************************************
> ************'
> ># Bayesian Data Analysis
> >## source("M:/programming/Rfolder/Assignments/fortest.txt")
> >
> ># #Remove all objects from the workspace
> >rm(list=ls())
> ># #We will also try to note the time that the program takes
> ># #We will start the clock at starttime
> >starttime <- proc.time()[3];
> >
> >my.function<-function(x) {
> >s2<-sqrt(2);
> >if ((x>=0) & (x<s2)) return(x/2)
> >else 
> >if ((x>=s2) & (x<1+s2)) return(0.2)
> >else 
> >if ((x>=1+s2) & (x<1.5+s2)) return(0.6)
> >else 
> >if ((x>1.5+s2) | (x<0)) return(0)
> >}
> >
> >alphayx<-function(y,x) {
> >fy<-my.function(y)
> >fx<-my.function(x)
> >fyx<-fy/fx
> ># to account for 0/0 division
> >if (is.na(fyx)) fyx<-0
> >#fyx<-ifelse(is.na(fyx),0,fyx);
> >alpha<-min(1,fyx)
> >return(alpha)
> >}
> >
> >sigma<-0.5;
> >#nr is the number of iterations
> >nr<-20
> >x<-numeric(nr);
> >x[1]<-1;
> >t<-1:nr;
> >
> >for (i in 1:nr-1) {
> >xi<-x[i];
> >yi<-rnorm(1,mean=xi,sd=sigma);
> >ui<-runif(1,0,1);
> >ualphai<-alphayx(yi,xi);
> >xn<-ifelse(ui<=ualphai,yi,xi);
> >x[i+1]<-xn;
> >}
> >
> >plot(t,x,type="p")
> >
> >endtime<-proc.time()[3];
> >elapsedTime<-endtime-starttime;
> >cat("Elapsed time is", elapsedTime, "seconds", "\n")
> >*************************************************************
> ****************'
> >
> >
> >
> >  
> >This message is meant for the addressee only and may contain 
> >confidential and legally privileged information. Any unauthorised 
> >review, use, copying, storage, disclosure or distribution of this e-
> >mail and any attachments is strictly prohibited. If you are not the 
> >named recipient or have otherwise received this communication in 
> >error, please destroy this message from your system and 
> kindly notify 
> >the sender by e-mail. Thank you for your co-operation.
> >
> >	[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at stat.math.ethz.ch mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> >
> >
> >
> >  
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Tue Aug 23 17:10:46 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 23 Aug 2005 16:10:46 +0100 (BST)
Subject: [R] Substituted arguments surviving multiple function calls
In-Reply-To: <def879$2vr$1@sea.gmane.org>
References: <def879$2vr$1@sea.gmane.org>
Message-ID: <Pine.LNX.4.61.0508231602390.23481@gannet.stats>

I think you would do better to use [[]], which allows this sort of thing 
as character strings.

f1 <- function(x) d[[deparse(substitute(x))]]

Now f1 is looking for the *name* it is called with, so you need

f2 <- function(x) eval(substitute(f1(x), list(x=substitute(x))))

Leaving the eval off

f2n <- function(x) substitute(f1(x), list(x=substitute(x)))

> f2n(a1)
f1(a1)

shows you how it works.

This really isn't a good idea, though, just to avoid a couple of quotes.

On Tue, 23 Aug 2005, Michael Hoffman wrote:

> I am using R 2.1.1 and have written a function that will retrieve a
> named column from a data frame:
>
> d = data.frame(a1=c(4, 2), a2=c(6, 7))
> f1 = function(x)
> {
>   do.call("$", list(d, substitute(x)))
> }
>
> So this works:
>
> > f1(a1)
> [1] 4 2
>
> However, I want to make another function, f2, which also accepts a
> column name as an argument and then calls the first function with it:
>
> f2 = function(x)
> {
>   f1(substitute(x))
> }
>
> However, this does not work:
>
> > f2(a1)
> Error in list(a1 = c(4, 2), a2 = c(6, 7))$substitute(x) :
>         invalid subscript type
>
> It works if I take the substitute() out of f1(), but then I can only
> call f1() through f2() or something that does the substitution for it.
> Is there a better way to do this?
>
> Thanks for any help you can offer.
> -- 
> Michael Hoffman
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From GBLEVINS at marketsolutionsgroup.com  Tue Aug 23 17:12:33 2005
From: GBLEVINS at marketsolutionsgroup.com (Greg Blevins)
Date: Tue, 23 Aug 2005 10:12:33 -0500
Subject: [R] Seeking help with an apparently simple recoding problem
Message-ID: <s30af69d.069@mail.marketsolutionsgroup.com>

Hello,

I have struggled, for longer than I care to admit, with this seemingly simple problem, but I cannot find a solution other than the use of long drawn out ifelse statements.  I know there has to be a better way.  Here is stripped down version of the situation:

I start with:
a <- c(1,0,1,0,0,0,0)
b <- c(1,1,1,1,0,0,0)
c <- c(1,1,0,1,0,0,0)

rbind(a,b,c)
  [,1] [,2] [,3] [,4] [,5] [,6] [,7]
a    1    0    1    0    0    0    0
b    1    1    1    1    0    0    0
c    1    1    0    1    0    0    0

I refer to column 3 as the target column, which at the end of the day will be NA in all instances.

The logic involved:

1) If columns 2, 4 thru 7 do NOT include at least one '1', then recode columns 2 thru 7 to NA and recode column 1 to code 2.

2) If columns 2, 4 thru 7 contain at least one '1', then recode column 3 to NA.

Desired recoding of the above three rows:
  [,1] 	[,2] 	[,3] 	[,4] 	[,5] 	[,6] 	[,7]
a    2    	NA    	NA    	NA   	NA   	NA    	NA
b    1    	1    	NA    	1   	0   	0    	0
c    1    	1    	NA    	1   	0   	0    	0

Thanks you.


Greg Blevins
The Market Solutions Group, Inc.

Windows XP, Version 2.1.1



From sundar.dorai-raj at pdf.com  Tue Aug 23 17:15:07 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Tue, 23 Aug 2005 10:15:07 -0500
Subject: [R] Substituted arguments surviving multiple function calls
In-Reply-To: <def879$2vr$1@sea.gmane.org>
References: <def879$2vr$1@sea.gmane.org>
Message-ID: <430B3D7B.3000204@pdf.com>



Michael Hoffman wrote:
> I am using R 2.1.1 and have written a function that will retrieve a 
> named column from a data frame:
> 
> d = data.frame(a1=c(4, 2), a2=c(6, 7))
> f1 = function(x)
> {
>    do.call("$", list(d, substitute(x)))
> }
> 
> So this works:
> 
>  > f1(a1)
> [1] 4 2
> 
> However, I want to make another function, f2, which also accepts a 
> column name as an argument and then calls the first function with it:
> 
> f2 = function(x)
> {
>    f1(substitute(x))
> }
> 
> However, this does not work:
> 
>  > f2(a1)
> Error in list(a1 = c(4, 2), a2 = c(6, 7))$substitute(x) :
>          invalid subscript type
> 
> It works if I take the substitute() out of f1(), but then I can only 
> call f1() through f2() or something that does the substitution for it.
> Is there a better way to do this?
> 
> Thanks for any help you can offer.

Hi, Michael,

How about the following:

d <- data.frame(a1 = c(4, 2), a2 = c(6, 7))

f1 <- function(x, d) {
   eval(substitute(x), d)
}

f2 <- function(x, d) {
   eval(substitute(f1(x, d)), list(x = substitute(x), d = d))
}

f1(a1, d)
f2(a1, d)

Note that I redefined "f1" to do away with the "do.call". Also, it's 
always safest to pass "d" as an argument rather than rely on it being in 
  .GlobalEnv.

There may be others who suggest a different approach.

HTH,

--sundar



From jeaneid at chass.utoronto.ca  Tue Aug 23 18:01:07 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Tue, 23 Aug 2005 12:01:07 -0400
Subject: [R] priority of operators in the FOR ( ) statement
In-Reply-To: <971536df050823042838d3676a@mail.gmail.com>
Message-ID: <Pine.SGI.4.40.0508231158200.518742-100000@origin.chass.utoronto.ca>

Although it is not as fancy as all other responses, I usually just print
the value of i first and see where it stopped. Of course this assumes you
it is stored in the main env. If it is inside a function and it is failing
I usually use the <<- operator to get it to the main env. and print it.

Here you would've seen that i stopped at 0.



Jean

On Tue, 23 Aug 2005, Gabor Grothendieck wrote:

> On 8/23/05, Ravi.Vishnu at outokumpu.com <Ravi.Vishnu at outokumpu.com> wrote:
> > Dear All,
> > I spent an entire evening in debugging a small, fairly simple program in R
> > - without success. It was my Guru in Bayesian Analysis, Thomas Fridtjof,
> > who was able to diagonose the problem. He said that it took a long time
> > for him also to locate the problem.
> > This program illustrates in some ways the shortcomings of the error
> > messages that R responds with. In this case, it was quite misleading and
> > directs attention to a location far removed the actual problem statement.
> > Without any more introductory comments, let me directly discuss the
> > essential problem. I am enclosing the entire program after a brief
> > discussion.
> >
> > The problem arises from the following statement (nr is an integer
> > constant) :
> > for ( i in 1:nr-1) {.......}
> > The unexpected problem (at least for me) is that R reads the above
> > statement as (i in (1:nr)-1) {.....}. This makes i be initially as zero
> > which leads to an error because the for loop in R starts from 1. The
> > problem is easily fixed by writing the for loop as  ( i in 1:(nr-1))
> > {.......}. This would be an easy problem to fix if R directly indicates
> > what the problem is. Instead, it gives mystifying error messages which are
> > totally misleading. For example, to the program given below, I got the
> > following error message (these point to commands elsewhere in the program)
> > :
> > Error in if ((x >= 0) & (x < s2)) return(x/2) else if ((x >= s2) & (x <  :
> >
> >        missing value where TRUE/FALSE needed
> >
> > I would like clarifications on the following points :
> > 1. I am just curious to know if the priority of operators in the for
> > statement ( the colon before the minus operator, for example) is a
> > deliberate design decision. I have tested Matlab and found that it
> > interprets my original statement correctly without an extra paranthesis.
>
> ?Syntax gives the operator precedence.
>
> Also, note that : is probably best not used in functions since it does
> not handle boundary conditions properly.   If n were 0 then 1:n
> results in two iterations corresonding to 1 and 0 but what you
> really wanted was likely no iterations at all.  To do that you need
> seq(length = n) rather than ":".
>
> Also I have found expressions like 0:1/10 handy to generate
> 0, .1, .2, ..., 1 and that works with the current precedence.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From mschwartz at mn.rr.com  Tue Aug 23 18:28:40 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 23 Aug 2005 11:28:40 -0500
Subject: [R] Seeking help with an apparently simple recoding problem
In-Reply-To: <s30af69d.069@mail.marketsolutionsgroup.com>
References: <s30af69d.069@mail.marketsolutionsgroup.com>
Message-ID: <1124814520.4595.20.camel@localhost.localdomain>

On Tue, 2005-08-23 at 10:12 -0500, Greg Blevins wrote:
> Hello,
> 
> I have struggled, for longer than I care to admit, with this seemingly
> simple problem, but I cannot find a solution other than the use of
> long drawn out ifelse statements.  I know there has to be a better
> way.  Here is stripped down version of the situation:
> 
> I start with:
> a <- c(1,0,1,0,0,0,0)
> b <- c(1,1,1,1,0,0,0)
> c <- c(1,1,0,1,0,0,0)
> 
> rbind(a,b,c)
>   [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> a    1    0    1    0    0    0    0
> b    1    1    1    1    0    0    0
> c    1    1    0    1    0    0    0
> 
> I refer to column 3 as the target column, which at the end of the day
> will be NA in all instances.
> 
> The logic involved:
> 
> 1) If columns 2, 4 thru 7 do NOT include at least one '1', then recode
> columns 2 thru 7 to NA and recode column 1 to code 2.
> 
> 2) If columns 2, 4 thru 7 contain at least one '1', then recode column
> 3 to NA.
> 
> Desired recoding of the above three rows:
>   [,1] 	[,2] 	[,3] 	[,4] 	[,5] 	[,6] 	[,7]
> a    2    	NA    	NA    	NA   	NA   	NA    	NA
> b    1    	1    	NA    	1   	0   	0    	0
> c    1    	1    	NA    	1   	0   	0    	0
> 
> Thanks you.


You left out one key detail in the explanation, which is that the
recoding appears to be done on a row by row basis, not overall.

The following gets the job done, though there may be a more efficient
approach:

> a <- c(1,0,1,0,0,0,0)
> b <- c(1,1,1,1,0,0,0)
> c <- c(1,1,0,1,0,0,0)
 
> d <- rbind(a, b, c)
 
> d
  [,1] [,2] [,3] [,4] [,5] [,6] [,7]
a    1    0    1    0    0    0    0
b    1    1    1    1    0    0    0
c    1    1    0    1    0    0    0
 
 
> mod.row <- function(x)
 {
   if (all(x[c(2, 4:7)] == 0))
   {
     x[2:7] <- NA
     x[1] <- 2
   } else {
       x[3] <- NA
   }
 
   x
 }
 
> y <- t(apply(d, 1, mod.row))

> y
  [,1] [,2] [,3] [,4] [,5] [,6] [,7]
a    2   NA   NA   NA   NA   NA   NA
b    1    1   NA    1    0    0    0
c    1    1   NA    1    0    0    0


HTH,

Marc Schwartz



From t.muhlhofer at lse.ac.uk  Tue Aug 23 18:37:09 2005
From: t.muhlhofer at lse.ac.uk (Tobias Muhlhofer)
Date: Tue, 23 Aug 2005 17:37:09 +0100
Subject: [R] clustering of disturbances
Message-ID: <430B50B5.6010200@lse.ac.uk>

Hi!

I have a dataset of properties that are owned by different firms, each 
firm owning multiple properties. I am running a regression of holding 
period (how long a property was held in a firm's portfolio) on the left, 
and a bunch of factors on the right.

When calculating standard errors, I would like to cluster my disturbance 
terms by firm. Any ideas on how to do this?

I'm guessing gls() from nlme, but what sorts of options?

Toby



From HDoran at air.org  Tue Aug 23 18:42:59 2005
From: HDoran at air.org (Doran, Harold)
Date: Tue, 23 Aug 2005 12:42:59 -0400
Subject: [R] clustering of disturbances
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7409E5C30C@dc1ex2.air.org>

GLS could work. There are a host of corClass functions for spatial and
serial correlations in this package. Or you could specify firm as a
grouping factor and use lmer() found in the Matrix package. 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Tobias Muhlhofer
Sent: Tuesday, August 23, 2005 12:37 PM
To: r-help at stat.math.ethz.ch
Subject: [R] clustering of disturbances

Hi!

I have a dataset of properties that are owned by different firms, each
firm owning multiple properties. I am running a regression of holding
period (how long a property was held in a firm's portfolio) on the left,
and a bunch of factors on the right.

When calculating standard errors, I would like to cluster my disturbance
terms by firm. Any ideas on how to do this?

I'm guessing gls() from nlme, but what sorts of options?

Toby

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From laurent.buffat at free.fr  Tue Aug 23 18:50:30 2005
From: laurent.buffat at free.fr (laurent buffat)
Date: Tue, 23 Aug 2005 18:50:30 +0200
Subject: [R] how to (combine / recode / merge) two factor.
Message-ID: <430B53D6.70008@free.fr>

Hi,
I have a data frame with two factors, and I would like to create a new 
one by "combining" them.
I have already a solution, but it is very "heavy", and I'm sure there is 
a basic function which can do the same.
I tried to find it in the R-help, but without result.

See the example :

# just to create a dataframe
f1 <- factor(rep(c("A","B"),3))
f2 <- factor(rep(c("x","y","z"),each=2))
df <- data.frame(f1,f2)
df <- rbind(df,df,df)

# here is what I want do do :
df$f1f2 <- 
factor(as.numeric(df$f1)+(as.numeric(df$f2)-1)*nlevels(df$f1), labels= 
letters[1:(nlevels(df$f1)*nlevels(df$f2))])
# I don't care about the labels.

df :
 > df
   f1 f2 f1f2
1   A  x    a
2   B  x    b
3   A  y    c
4   B  y    d
5   A  z    e
6   B  z    f
11  A  x    a
21  B  x    b
31  A  y    c
41  B  y    d
51  A  z    e
61  B  z    f
12  A  x    a
22  B  x    b
32  A  y    c
42  B  y    d
52  A  z    e
62  B  z    f
 >


Thanks for your helps,

Laurent Buffat



From ccleland at optonline.net  Tue Aug 23 18:55:24 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Tue, 23 Aug 2005 12:55:24 -0400
Subject: [R] how to (combine / recode / merge) two factor.
In-Reply-To: <430B53D6.70008@free.fr>
References: <430B53D6.70008@free.fr>
Message-ID: <430B54FC.2030800@optonline.net>

interaction(df$f1, df$f2)

?interaction

laurent buffat wrote:
> Hi,
> I have a data frame with two factors, and I would like to create a new 
> one by "combining" them.
> I have already a solution, but it is very "heavy", and I'm sure there is 
> a basic function which can do the same.
> I tried to find it in the R-help, but without result.
> 
> See the example :
> 
> # just to create a dataframe
> f1 <- factor(rep(c("A","B"),3))
> f2 <- factor(rep(c("x","y","z"),each=2))
> df <- data.frame(f1,f2)
> df <- rbind(df,df,df)
> 
> # here is what I want do do :
> df$f1f2 <- 
> factor(as.numeric(df$f1)+(as.numeric(df$f2)-1)*nlevels(df$f1), labels= 
> letters[1:(nlevels(df$f1)*nlevels(df$f2))])
> # I don't care about the labels.
> 
> df :
>  > df
>    f1 f2 f1f2
> 1   A  x    a
> 2   B  x    b
> 3   A  y    c
> 4   B  y    d
> 5   A  z    e
> 6   B  z    f
> 11  A  x    a
> 21  B  x    b
> 31  A  y    c
> 41  B  y    d
> 51  A  z    e
> 61  B  z    f
> 12  A  x    a
> 22  B  x    b
> 32  A  y    c
> 42  B  y    d
> 52  A  z    e
> 62  B  z    f
>  >
> 
> 
> Thanks for your helps,
> 
> Laurent Buffat
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From gunter.berton at gene.com  Tue Aug 23 19:43:46 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 23 Aug 2005 10:43:46 -0700
Subject: [R] R Reference Card (especially useful for Newbies)
Message-ID: <200508231743.j7NHhkXA029672@compton.gene.com>

 

Newbies (and others!) may find useful the R Reference Card made available by
Tom Short and Rpad at http://www.rpad.org/Rpad/Rpad-refcard.pdf  or through
the "Contributed" link on CRAN (where some other reference cards are also
linked). It categorizes and organizes a bunch of R's basic, most used
functions so that they can be easily found. For example, paste() is under
the "Strings" heading and expand.grid() is under "Data Creation." For
newbies struggling to find the right R function as well as veterans who
can't quite remember the function name, it's very handy.
 
-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box



From gerifalte28 at hotmail.com  Tue Aug 23 20:59:05 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Tue, 23 Aug 2005 18:59:05 +0000
Subject: [R] GLM->Repeated measures (multivariate)
In-Reply-To: <001301c5a7e4$68ea1300$2b00000a@rhodes>
Message-ID: <BAY103-F11207E746C8AFD9836EE56A6A90@phx.gbl>

Try RSiteSearch("repeated measures").  The first hit will lead you to a good 
thread.

Francisco

>From: "Vincent de Groot" <rcran at aegee.student.kun.nl>
>To: <r-help at stat.math.ethz.ch>
>Subject: [R] GLM->Repeated measures (multivariate)
>Date: Tue, 23 Aug 2005 15:13:09 +0200
>
>Dear subscribers,
>
>I'm trying to make the switch from M$ Windows to Linux (KDE) and found the
>R-cran project for statistical analysis. I'm not a genius in statistics so
>the command line interface is a bit hard for me.
>
>I need an analogue way to do the SPSS General Linear Model->Repeated
>Measures (multivariate) but I don't have a clue how to perform this in
>R-cran. Can maybe somebody of you help me with supplying a GLM-Repeated
>measures 'cookbook'? Or can you point me maybe to an online resource like a
>tutorial or manual explaining this?
>
>I searched the Internet already but for me it was impossible to find
>something useful. As I said. I'm only a 'user' of SPSS and not a statistics
>guru.
>
>I have read the basic documentation (importing, plotting, calculating) and
>played with it already :-).
>
>Thanks in advance.
>
>Many greetings,
>  Vincent de Groot
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From guerinche at gmail.com  Tue Aug 23 22:01:14 2005
From: guerinche at gmail.com (alejandro munoz)
Date: Tue, 23 Aug 2005 15:01:14 -0500
Subject: [R] merge list entries
Message-ID: <98c62e1105082313017746c4cf@mail.gmail.com>

dear expeRts,

i would like to merge the data frame entries in a list. for example:

> #input
> myl <- list(q1=data.frame(id=c("Alice", "Bob"), grade=c(90, 49)),
              q2=data.frame(id=c("Alice", "Chuck"), grade=c(70, 93)),
              q3=data.frame(id=c("Bob", "Chuck"), grade=c(84, 40)))
> #output
> (mydf <- magic(myl))
      id grade.1 grade.2 grade.3
1 Alice      90      70      NA
2   Bob      49      NA      84
3 Chuck      NA      93      40

my three attempts, and their error messages, follow:
> lapply(myl, merge, by="id", all=TRUE)
Error in as.data.frame(y) : argument "y" is missing, with no default

> lapply(myl[[-1]], merge, y=myl[[1]], by="id", all=TRUE)
Error in lapply(myl[[-1]], merge, y = myl[[1]], by = "id", all = TRUE) : 
	attempt to select more than one element

> do.call("merge", list(myl[[1]], myl[[-1]], by="id", all=TRUE))
Error in do.call("merge", list(myl[[1]], myl[[-1]], by = "id", all = TRUE)) : 
	attempt to select more than one element

i can do the merge sequentially, e.g. 
m12 <- merge(myl[[1]], myl[[2]], ...)
m123 <- merge(m12, myl[[3]], ...)
but (a) in my actual example i have up to q7, and (b) this looks very
clumsy, even if i wrapped it inside a do loop.

i'd appreciate any help.

alejandro



From justin_bem at yahoo.fr  Tue Aug 23 22:18:28 2005
From: justin_bem at yahoo.fr (justin bem)
Date: Tue, 23 Aug 2005 22:18:28 +0200 (CEST)
Subject: [R] Problem with RCMD build ...
Message-ID: <20050823201829.17737.qmail@web25703.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050823/1ed35419/attachment.pl

From jholtman at gmail.com  Tue Aug 23 22:21:14 2005
From: jholtman at gmail.com (jim holtman)
Date: Tue, 23 Aug 2005 16:21:14 -0400
Subject: [R] merge list entries
In-Reply-To: <98c62e1105082313017746c4cf@mail.gmail.com>
References: <98c62e1105082313017746c4cf@mail.gmail.com>
Message-ID: <644e1f3205082313216b5e1430@mail.gmail.com>

Try:

> newL <- do.call('rbind', lapply(1:length(myl), function(x){
+     cbind(myl[[x]], q=x)
+ }))
> 
> 
> reshape(newL, v.names='grade', idvar='id', timevar='q', direction='wide')
      id grade.1 grade.2 grade.3
1  Alice      90      70      NA
2    Bob      49      NA      84
21 Chuck      NA      93      40
> newL
      id grade q
1  Alice    90 1
2    Bob    49 1
11 Alice    70 2
21 Chuck    93 2
12   Bob    84 3
22 Chuck    40 3

On 8/23/05, alejandro munoz <guerinche at gmail.com> wrote:
> dear expeRts,
> 
> i would like to merge the data frame entries in a list. for example:
> 
> > #input
> > myl <- list(q1=data.frame(id=c("Alice", "Bob"), grade=c(90, 49)),
>              q2=data.frame(id=c("Alice", "Chuck"), grade=c(70, 93)),
>              q3=data.frame(id=c("Bob", "Chuck"), grade=c(84, 40)))
> > #output
> > (mydf <- magic(myl))
>      id grade.1 grade.2 grade.3
> 1 Alice      90      70      NA
> 2   Bob      49      NA      84
> 3 Chuck      NA      93      40
> 
> my three attempts, and their error messages, follow:
> > lapply(myl, merge, by="id", all=TRUE)
> Error in as.data.frame(y) : argument "y" is missing, with no default
> 
> > lapply(myl[[-1]], merge, y=myl[[1]], by="id", all=TRUE)
> Error in lapply(myl[[-1]], merge, y = myl[[1]], by = "id", all = TRUE) :
>        attempt to select more than one element
> 
> > do.call("merge", list(myl[[1]], myl[[-1]], by="id", all=TRUE))
> Error in do.call("merge", list(myl[[1]], myl[[-1]], by = "id", all = TRUE)) :
>        attempt to select more than one element
> 
> i can do the merge sequentially, e.g.
> m12 <- merge(myl[[1]], myl[[2]], ...)
> m123 <- merge(m12, myl[[3]], ...)
> but (a) in my actual example i have up to q7, and (b) this looks very
> clumsy, even if i wrapped it inside a do loop.
> 
> i'd appreciate any help.
> 
> alejandro
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Jim Holtman
Convergys
+1 513 723 2929

What the problem you are trying to solve?



From naj at ccf.org  Tue Aug 23 22:29:22 2005
From: naj at ccf.org (Jeanie (Jie) Na)
Date: Tue, 23 Aug 2005 16:29:22 -0400
Subject: [R] Wilcoxon Signed Rank Test
Message-ID: <1124828962.2192.12.camel@wb4-c29-lin>

Dear list,

Please forgive me if this is a dumb question. I want to compare a set of
paired data (pre and late). There are ties in pre and late. I searched
on line, some document says use wilcox.exact in R instead of
wilcox.test. Anyone has any experience using wilcoxon signed rank test
to share? 
Thanks in advance.

platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    2                
minor    1.0              
year     2005             
month    04               
day      18               
language R  

-- 
Jeanie (Jie) Na

Programmer Analyst II                       _   _    ___    _   _    ____
Department of Quantitative Health Sciences [_]-[_]  / - \  | |_| |  (_(_
Cleveland Clinic Foundation                 |   |  ( |_| ) )  _  (   _| )
Tel: (216)4451369                          [_]-[_]  \_\_\  |_| |_|  (___/



From guerinche at gmail.com  Tue Aug 23 22:37:05 2005
From: guerinche at gmail.com (alejandro munoz)
Date: Tue, 23 Aug 2005 15:37:05 -0500
Subject: [R] merge list entries
In-Reply-To: <644e1f3205082313216b5e1430@mail.gmail.com>
References: <98c62e1105082313017746c4cf@mail.gmail.com>
	<644e1f3205082313216b5e1430@mail.gmail.com>
Message-ID: <98c62e110508231337318e4fc8@mail.gmail.com>

that works beautifully. thank you, jim!

alejandro



From =?iso-8859-1?Q?Marie-H=E9l=E8ne?=  Tue Aug 23 22:51:07 2005
From: =?iso-8859-1?Q?Marie-H=E9l=E8ne?= (=?iso-8859-1?Q?Marie-H=E9l=E8ne?=)
Date: Tue, 23 Aug 2005 16:51:07 -0400
Subject: [R] problems installing R from source: R-2.1.1 Windows XP
Message-ID: <6.2.1.2.1.20050823164803.0222abf0@magellan.umontreal.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050823/f3ecb9bb/attachment.pl

From graumann at caltech.edu  Tue Aug 23 23:32:42 2005
From: graumann at caltech.edu (Johannes Graumann)
Date: Tue, 23 Aug 2005 14:32:42 -0700
Subject: [R] Robust M-Estimator Comparison
Message-ID: <deg4lq$bqe$2@sea.gmane.org>

Hello,

I'm learning about robust M-estimators right now and had settled on the
"Huber Proposal 2" as implemented in MASS, but further reading made clear,
that at least 2 further weighting functions (Hampel, Tukey bisquare) exist.
In a post from B.D. Ripley going back to 1999 I found the following quote:

>> 2) Would huber() give me results that are similar (i.e., close enough)? 
> 
> Not if you have lots of extreme outliers on just one side. 

Since this message seems to imply that the nature of the data described (and
not just personal preference) should influence the choice among above
M-estimators, I've been scouting around for a direct comparison among them
- to no avail.

Can anybody here point me to such a comparison (novice-suitability would be
more than welcome ;0)?

Thanks for any hint,

Joh

-- 
+----------------------------------------------------------------------+
| Johannes Graumann, Dipl. Biol.                                       |
|                                                                      |
|       Graduate Student                Tel.: ++1 (626) 395 6602       |
|       Deshaies Lab                    Fax.: ++1 (626) 395 5739       |
|       Department of Biology                                          |
|       CALTECH, M/C 156-29                                            |
|       1200 E. California Blvd.                                       |
|       Pasadena, CA 91125                                             |
|       USA                                                            |
+----------------------------------------------------------------------+



From cgb at datanalytics.com  Tue Aug 23 23:51:34 2005
From: cgb at datanalytics.com (Carlos J. Gil Bellosta)
Date: Tue, 23 Aug 2005 23:51:34 +0200
Subject: [R] Problem with RCMD build ...
In-Reply-To: <20050823201829.17737.qmail@web25703.mail.ukl.yahoo.com>
References: <20050823201829.17737.qmail@web25703.mail.ukl.yahoo.com>
Message-ID: <430B9A66.1040303@datanalytics.com>

Dear Justin,

I also had similar problems recently...  In fact, I have just created a 
"package" using package.skeleton and if I try to build it without 
editing the DESCRIPTION file (you did not mention you did, right?) R 
complains. In fact, it appears to be malformed (I am running version 
2.1.0 of R on a Debian (testing) Linux box); it is [sic]:

Package: fooType: Package
Title: What the package does (short line)
Version: 1.0
Date: 2005-08-23
Author: Who wrote it
Maintainer: Who to complain to <yourfault at somewhere.net>
Description: More about what it does (maybe more than one line)
License: What license is it under?

As you can see, the two first lines are pasted together. Can this 
perhaps be the problem?

Sincerely,

Carlos J. Gil Bellosta
http://www.datanalytics.com

justin bem wrote:

>Hi 
>I have write A function to draw pyramid of age. I have two function
>draw.pyramide(h,f,l) , pyramide(h,f,l) and a data frame with data.
> 
>I first use package.skeleton("pyra")
>I got the package structure
>Then in my shell I use 
> 
>  
>
>>RCMD build pyra
>>    
>>
>I get this :
>        check for description ... OK
>        ....
>        removing junk files 
>        but
>        "cannot open pyra/description"
>        and Install failed.
> 
>I use windows XP, with and intel PIV with 2.66GHZ and 512MO of memory.
> 
>Can you help me ?
> 
> 
> 
>
>
>Justin BEM
>El??ve Ing??nieur Statisticien Economiste
>BP 294 Yaound??.
>T??l (00237)9597295.
>		
>---------------------------------
>
>
>	[[alternative HTML version deleted]]
>
>  
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From gunter.berton at gene.com  Tue Aug 23 23:53:37 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Tue, 23 Aug 2005 14:53:37 -0700
Subject: [R] Robust M-Estimator Comparison
In-Reply-To: <deg4lq$bqe$2@sea.gmane.org>
Message-ID: <200508232153.j7NLrbKx016802@hertz.gene.com>

Johannes:

WARNING: I'm no expert. Caveat emptor!

There is a huge literature on robust estimation, as you'll find when you
Google it. One natural place to start might be the relevant sections of
V&R's MASS( Modern Applied Statistics with S) and the references therein. An
old classic, which may not, however, still be in print, is Hoaglin,
Mosteller, Tukey: Understanding robust and exploratory data analysis.
(Robust estimation chapter)

It is not clear to me that robust estimation will solve your problems with
lots of one-sided outliers -- sounds like a skewed distribution in there
somewhere. 

One thing to be careful about: there's "Robustness of efficiency" and
"Outlier resistance." The first is about maintaining estimation efficiency
in the face of "contamination" by a usually small percentage of "outliers"
(whatever THEY are); the second is about maintaining estimation accuracy in
the face of a possibly large proportion of outliers. The classic example of
the latter for estimating location is the median; an M-estimator (e.g.
iterated biweight) is an exemplar of the former. As V&R and others makes
clear, these are not mutually exclusive, but they do tend to pull in
somewhat different ways.

Robust estimation seems to have lost its cachet these days, maybe because it
seems to be difficult to do in the nonlinear models that arise out of the
complex covariance structures people want to use these days (e.g, mixed
models; Empirical Bayes). I continue to find it an essential tool in any
routine regression work that I do, however. Seems more in keeping with
entropy.

Cheers,

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of 
> Johannes Graumann
> Sent: Tuesday, August 23, 2005 2:33 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Robust M-Estimator Comparison
> 
> Hello,
> 
> I'm learning about robust M-estimators right now and had 
> settled on the
> "Huber Proposal 2" as implemented in MASS, but further 
> reading made clear,
> that at least 2 further weighting functions (Hampel, Tukey 
> bisquare) exist.
> In a post from B.D. Ripley going back to 1999 I found the 
> following quote:
> 
> >> 2) Would huber() give me results that are similar (i.e., 
> close enough)? 
> > 
> > Not if you have lots of extreme outliers on just one side. 
> 
> Since this message seems to imply that the nature of the data 
> described (and
> not just personal preference) should influence the choice among above
> M-estimators, I've been scouting around for a direct 
> comparison among them
> - to no avail.
> 
> Can anybody here point me to such a comparison 
> (novice-suitability would be
> more than welcome ;0)?
> 
> Thanks for any hint,
> 
> Joh
> 
> -- 
> +-------------------------------------------------------------
> ---------+
> | Johannes Graumann, Dipl. Biol.                              
>          |
> |                                                             
>          |
> |       Graduate Student                Tel.: ++1 (626) 395 
> 6602       |
> |       Deshaies Lab                    Fax.: ++1 (626) 395 
> 5739       |
> |       Department of Biology                                 
>          |
> |       CALTECH, M/C 156-29                                   
>          |
> |       1200 E. California Blvd.                              
>          |
> |       Pasadena, CA 91125                                    
>          |
> |       USA                                                   
>          |
> +-------------------------------------------------------------
> ---------+
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ceremona at gmail.com  Wed Aug 24 00:47:10 2005
From: ceremona at gmail.com (Cere Davis)
Date: Tue, 23 Aug 2005 15:47:10 -0700
Subject: [R] error on load for R-2.1.0 and 2.1.1
Message-ID: <c666e3db05082315471bd39133@mail.gmail.com>

Hi R geniouses,

A friend and I are having trouble with a simple load() call in R. 
When we load data via a for loop such as:

for (i in c(1980:1984)){load(paste("myfile",i ,".RData", sep=""))}
for (i in c(1986:1994)){load(paste("myfile",i ,".RData", sep=""))}

I get the following error in R:
/usr/local/R-2.1.0/lib/R/bin/BATCH: line 55:  4366 Broken pipe        
    ( echo "invisible(options(echo = TRUE))"; cat ${in}; echo
"proc.time()" )
      4368 Segmentation fault      | ${R_HOME}/bin/R ${opts} >${out} 2>&1

When I load the equivelant files sequentially with the for loop such as:

load("myfile1980.RData")
.
.
.
load("myfile1994.RData")

the code runs just fine.

Can anyone see what would cause the for loop code above to cause a
segfault error?

Thanks,
Cere


--
Cere Davis
ceremona at gmail.com
-------------------
GPG Key:  http://staff.washington.edu/cere/pubkey.asc
GPG fingerprint (ID# 73FCA9E6) : F5C7 627B ECBE C735 117B  2278 9A95
4C88 73FC A9E6



From hastie at stanford.edu  Wed Aug 24 01:33:51 2005
From: hastie at stanford.edu (Trevor Hastie)
Date: Tue, 23 Aug 2005 16:33:51 -0700
Subject: [R] Attractive position at Stanford for statistician into computing
Message-ID: <430BB25F.5030103@stanford.edu>

Stanford University Statistics Department is looking to hire a
computer systems specialist. We are targeting someone with a MS or Ph.D 
in statistics,
and who is adept and interested in computing. We are very active in R 
and the S language,
have linux, pc and mac platforms, and like to think we are at the 
cutting edge of technology.

For more details, see the link on the department web page:

http://www-stat.stanford.edu/cssad.html

Trevor Hastie

--------------------------------------------------------------------
  Trevor Hastie                                  hastie at stanford.edu
  Professor, Department of Statistics, Stanford University
  Phone: (650) 725-2231 (Statistics)	         Fax: (650) 725-8977
	 (650) 498-5233 (Biostatistics)		 Fax: (650) 725-6951
  URL: http://www-stat.stanford.edu/~hastie
  address: room 104, Department of Statistics, Sequoia Hall
	          390 Serra Mall, Stanford University, CA 94305-4065



From spencer.graves at pdf.com  Wed Aug 24 02:01:32 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 23 Aug 2005 17:01:32 -0700
Subject: [R] Copying rows from a matrix using a vector of indices
In-Reply-To: <20050817190207.77099.qmail@web40508.mail.yahoo.com>
References: <20050817190207.77099.qmail@web40508.mail.yahoo.com>
Message-ID: <430BB8DC.9050608@pdf.com>

	  I don't quite understand what you are asking.  Have you checked the 
sections on "Simple manipulations numbers and vectors", "Arrays and 
matrices", and "Lists and data frames" in the manual "An Introduction to 
R"?  If you still would like some help after this, PLEASE do read the 
posting guide! "http://www.R-project.org/posting-guide.html".  It can 
increase the chances that you will get a useful reply.

	  spencer graves

Martin Lam wrote:

> Hi,
> 
> I am trying to use a vector of indices to select some
> rows from a matrix. But before I can do that I somehow
> need to convert 'combinations' into a list, since
> 'mode(combinations)' says it's 'numerical'. Any idea
> how I can do that?
> 
> library("combinat")
> 
> combinations <- t(combn(8,2))
> 
> indices <- c(sample(1:length(combinations),10))
> 
> # convert
> ???
> 
> subset <- combinations[indices]
> 
> Thanks in advance,
> 
> Martin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From Murraypu at aimnsw.com.au  Wed Aug 24 03:27:20 2005
From: Murraypu at aimnsw.com.au (Murray Pung)
Date: Wed, 24 Aug 2005 11:27:20 +1000
Subject: [R] barplots - text direction
Message-ID: <3028F4C4647C9043B870276E28C69FD622A275@syd05.aimnsw.com.au>

If the variable names are too long to allow room for each to be displayed on a barplot, how can the direction of the text be changed?

a <- cbind(2.4,2.4,2.5,2.6,2.6,2.6,2.6,2.6,2.9,2.9,2.9)
b <- cbind(2.3,2.5,2.4,2.2,3.2,2.4,2.9,2.6,2.9,3.0,2.8)
h <- rbind(a,b)
colnames(h) <- c("one","two","three","four","five","six","seven","eight","nine","ten","eleven")
rownames(h) <- c("Pre-stage","Post-stage")
barplot(h, beside = T, legend = colnames(g), horiz = T, xlim = c(0, 5))


Many Thanks
Murray

Murray Pung | Research Analyst
AIM Research & HR Consulting
PO Box 328, Nth Sydney NSW 2060
P +61 (02) 9956 3951
F +61 (02) 9922 2210
www.aimsurveys.com.au



From blomsp at ozemail.com.au  Wed Aug 24 03:48:57 2005
From: blomsp at ozemail.com.au (Simon Blomberg)
Date: Wed, 24 Aug 2005 11:48:57 +1000
Subject: [R] barplots - text direction
In-Reply-To: <3028F4C4647C9043B870276E28C69FD622A275@syd05.aimnsw.com.au
 >
References: <3028F4C4647C9043B870276E28C69FD622A275@syd05.aimnsw.com.au>
Message-ID: <6.2.1.2.0.20050824114427.035d5048@mail.ozemail.com.au>

See las under ?par. You can often pass par parameters to higher-level 
graphics functions, so barplot(h, las=2) (for example) works.

HTH,

Simon.

At 11:27 AM 24/08/2005, Murray Pung wrote:
>If the variable names are too long to allow room for each to be displayed 
>on a barplot, how can the direction of the text be changed?
>
>a <- cbind(2.4,2.4,2.5,2.6,2.6,2.6,2.6,2.6,2.9,2.9,2.9)
>b <- cbind(2.3,2.5,2.4,2.2,3.2,2.4,2.9,2.6,2.9,3.0,2.8)
>h <- rbind(a,b)
>colnames(h) <- 
>c("one","two","three","four","five","six","seven","eight","nine","ten","eleven")
>rownames(h) <- c("Pre-stage","Post-stage")
>barplot(h, beside = T, legend = colnames(g), horiz = T, xlim = c(0, 5))
>
>
>Many Thanks
>Murray
>
>Murray Pung | Research Analyst
>AIM Research & HR Consulting
>PO Box 328, Nth Sydney NSW 2060
>P +61 (02) 9956 3951
>F +61 (02) 9922 2210
>www.aimsurveys.com.au
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

Simon Blomberg, B.Sc.(Hons.), Ph.D, M.App.Stat.
Centre for Resource and Environmental Studies
The Australian National University
Canberra ACT 0200
Australia
T: +61 2 6125 7800 email: Simon.Blomberg_at_anu.edu.au
F: +61 2 6125 0757
CRICOS Provider # 00120C



From d.scott at auckland.ac.nz  Wed Aug 24 03:54:50 2005
From: d.scott at auckland.ac.nz (David Scott)
Date: Wed, 24 Aug 2005 13:54:50 +1200 (NZST)
Subject: [R] barplots - text direction
In-Reply-To: <3028F4C4647C9043B870276E28C69FD622A275@syd05.aimnsw.com.au>
References: <3028F4C4647C9043B870276E28C69FD622A275@syd05.aimnsw.com.au>
Message-ID: <Pine.LNX.4.61.0508241353220.19202@stat12.stat.auckland.ac.nz>

On Wed, 24 Aug 2005, Murray Pung wrote:

> If the variable names are too long to allow room for each to be displayed on a barplot, how can the direction of the text be changed?
>
> a <- cbind(2.4,2.4,2.5,2.6,2.6,2.6,2.6,2.6,2.9,2.9,2.9)
> b <- cbind(2.3,2.5,2.4,2.2,3.2,2.4,2.9,2.6,2.9,3.0,2.8)
> h <- rbind(a,b)
> colnames(h) <- c("one","two","three","four","five","six","seven","eight","nine","ten","eleven")
> rownames(h) <- c("Pre-stage","Post-stage")
> barplot(h, beside = T, legend = colnames(g), horiz = T, xlim = c(0, 5))
>
>

barplot(h, beside = T, legend = colnames(h), horiz = T, xlim = c(0, 5),
         las=1)

will do it.

Note: colnames(h) not colnames(g)


David Scott


_________________________________________________________________
David Scott	Department of Statistics, Tamaki Campus
 		The University of Auckland, PB 92019
 		Auckland	NEW ZEALAND
Phone: +64 9 373 7599 ext 86830		Fax: +64 9 373 7000
Email:	d.scott at auckland.ac.nz


Graduate Officer, Department of Statistics



From spencer.graves at pdf.com  Wed Aug 24 04:54:32 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 23 Aug 2005 19:54:32 -0700
Subject: [R] plotting issue with timestamps
In-Reply-To: <BAY102-F31FAD5E664A6BCE6F93513D3B30@phx.gbl>
References: <BAY102-F31FAD5E664A6BCE6F93513D3B30@phx.gbl>
Message-ID: <430BE168.3030205@pdf.com>

	  Have you considered the "zoo" package?  It has a "vignette" that I 
found very useful.  After 'install.packages("zoo")', try the following:

	  Zoo <- vignette("zoo")
	  print(Zoo)
# to open the narrative vignette in an Adobe Acrobat reader
	  edit(Zoo)
# to open a script file in RGui to make it easy for you
# to process the R commands line by line, edit them as you wish, etc.

#  If you use XEmacs, do NOT use "edit(Zoo)".  Instead do the following:

	  Stangle(Zoo$file)

# This will write the R commands to a file, which you can then open
# and process line by line as in RGui.

	  spencer graves

Dhiren DSouza wrote:
> I have a dataset with transactions and a timestamp at which they occoured 
> during a day.  The time stamp is in the format YYYY/MM/DD hh:mm:ss.  I would 
> like to plot a timeseries of the transactions to see if there is a 
> particular time in the day when there is a spike in transactions.  Ofcourse 
> the YYYY/MM/DD can be dropped since I am monitoring activity for the day and 
> the actual date is unimportant.
> 
> Can anyone give me some direction on this.  I could possibly build a 
> frequency table but not sure how to plot against the timestamp in the format 
> above.  Any help would be appreciated.
> 
> -Dhiren
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From maechler at stat.math.ethz.ch  Wed Aug 24 09:35:08 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 24 Aug 2005 09:35:08 +0200
Subject: [R] Problem with RCMD build ...
In-Reply-To: <430B9A66.1040303@datanalytics.com>
References: <20050823201829.17737.qmail@web25703.mail.ukl.yahoo.com>
	<430B9A66.1040303@datanalytics.com>
Message-ID: <17164.9004.193698.837646@stat.math.ethz.ch>

>>>>> "Carlos" == Carlos J Gil Bellosta <cgb at datanalytics.com>
>>>>>     on Tue, 23 Aug 2005 23:51:34 +0200 writes:

    Carlos> Dear Justin,
    Carlos> I also had similar problems recently...  In fact, I have just created a 
    Carlos> "package" using package.skeleton and if I try to build it without 
    Carlos> editing the DESCRIPTION file (you did not mention you did, right?) R 
    Carlos> complains. In fact, it appears to be malformed (I am running version 
    Carlos> 2.1.0 of R on a Debian (testing) Linux box); it is [sic]:

    Carlos> Package: fooType: Package
	    ^^^^^^^^^^^^^^^^^^^^^^^^^

    Carlos> Title: What the package does (short line)
    Carlos> Version: 1.0
    Carlos> Date: 2005-08-23
    Carlos> Author: Who wrote it
    Carlos> Maintainer: Who to complain to <yourfault at somewhere.net>
    Carlos> Description: More about what it does (maybe more than one line)
    Carlos> License: What license is it under?

    Carlos> As you can see, the two first lines are pasted together. Can this 
    Carlos> perhaps be the problem?

yes, that has been a bug in R 2.1.0
but then, you know, there has been
 R 2.1.0 "patched"
 R 2.1.1
 R 2.1.1 "patched"

all of which had this buglet corrected.

Why don't you first upgrade, particularly from a x.y.0 version?



From petr.pikal at precheza.cz  Wed Aug 24 09:43:00 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 24 Aug 2005 09:43:00 +0200
Subject: [R] priority of operators in the  FOR (  ) statement
In-Reply-To: <OFA5E737A7.10467A0E-ONC1257066.0033C5B3-C1257066.0037492D@outokumpu.com>
Message-ID: <430C4124.26799.578C2B@localhost>



From tkadlec at prfnw.upol.cz  Wed Aug 24 09:59:35 2005
From: tkadlec at prfnw.upol.cz (Tkadlec Emil)
Date: Wed, 24 Aug 2005 09:59:35 +0200
Subject: [R] plotting GAM
Message-ID: <430C4550.5646.19D1EA2F@localhost>

Dear colleagues, 
I would like to have GAM regression lines (package gam) thicker than the default 
setting does. Is there any way to change the width of regression line when plotting 
gam.objects from the package GAM with more than one predictor? Changing lwd 
parameter in plot function controls all line components, including points making them 
thicker as well, which is not what I would like to have. 
Thanks for help. 
Best, 
Emil

**************************************************************
Emil Tkadlec
Palacky University                PrF UP
Faculty of Science                katedra ekologie        
Department of Ecology             tr. Svobody 26
tr. Svobody 26                    771 46 OLOMOUC
771 46 Olomouc                    tel. 58 563 4561
Czech Republic                    
email: tkadlec at prfnw.upol.cz



From sean.oriordain at gmail.com  Wed Aug 24 10:31:45 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Wed, 24 Aug 2005 09:31:45 +0100
Subject: [R] plotting GAM
In-Reply-To: <430C4550.5646.19D1EA2F@localhost>
References: <430C4550.5646.19D1EA2F@localhost>
Message-ID: <8ed68eed05082401313a502de8@mail.gmail.com>

Hi Emil,
can you give us a working example of what you're trying to do?

cheers!
Sean

ps. as per the posting-guide... :-)

On 24/08/05, Tkadlec Emil <tkadlec at prfnw.upol.cz> wrote:
> Dear colleagues,
> I would like to have GAM regression lines (package gam) thicker than the default
> setting does. Is there any way to change the width of regression line when plotting
> gam.objects from the package GAM with more than one predictor? Changing lwd
> parameter in plot function controls all line components, including points making them
> thicker as well, which is not what I would like to have.
> Thanks for help.
> Best,
> Emil
> 
> **************************************************************
> Emil Tkadlec
> Palacky University                PrF UP
> Faculty of Science                katedra ekologie
> Department of Ecology             tr. Svobody 26
> tr. Svobody 26                    771 46 OLOMOUC
> 771 46 Olomouc                    tel. 58 563 4561
> Czech Republic
> email: tkadlec at prfnw.upol.cz
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From tkadlec at prfnw.upol.cz  Wed Aug 24 10:45:17 2005
From: tkadlec at prfnw.upol.cz (Tkadlec Emil)
Date: Wed, 24 Aug 2005 10:45:17 +0200
Subject: [R] plotting gam
Message-ID: <430C5006.5297.19FBC10F@localhost>

Hi Sean,
my working example is simple. I am modeling a response variable, say 
y, using two quantitative predictors, say x1 and x2:
model<-gam(y~s(x1)+s(x2)
Then, I plot the model using
plot(model, residuals=T,se=T)
If I set par(mfrow=c(1,2)) before that, I get two nice figures for both 
predictors, with regression lines, s.e. envelopes and points. However, I 
would like to have the regression lines thicker to emphasize more the 
underlzing relationships between response and predictors, with 
everything else on the fig left unchanged.
Hope it's enough
Emil


**************************************************************
Emil Tkadlec
Palacky University                PrF UP
Faculty of Science                katedra ekologie        
Department of Ecology             tr. Svobody 26
tr. Svobody 26                    771 46 OLOMOUC
771 46 Olomouc                    tel. 58 563 4561
Czech Republic                    
email: tkadlec at prfnw.upol.cz



From jan.wiener at tuebingen.mpg.de  Wed Aug 24 10:48:31 2005
From: jan.wiener at tuebingen.mpg.de (Jan Wiener)
Date: Wed, 24 Aug 2005 10:48:31 +0200
Subject: [R] reading "special" text files
Message-ID: <430C345F.1050406@tuebingen.mpg.de>

hello,

assume you have a txt-file (sep="\t" or "") looking as follows that you 
want to read into a variable:

1	1	2			3
2	1	2	3		4
3	1	5	6	7	8

the result should look like this (e.g., in a data.frame):

1	1	2	3
2	1	2	3	4
3	1	5	6	7	8

is there any way to do so?

thanks in advance,
jan



From ligges at statistik.uni-dortmund.de  Wed Aug 24 11:53:52 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 24 Aug 2005 11:53:52 +0200
Subject: [R] reading "special" text files
In-Reply-To: <430C345F.1050406@tuebingen.mpg.de>
References: <430C345F.1050406@tuebingen.mpg.de>
Message-ID: <430C43B0.5090905@statistik.uni-dortmund.de>

Jan Wiener wrote:

> hello,
> 
> assume you have a txt-file (sep="\t" or "") looking as follows that you 
> want to read into a variable:
> 
> 1	1	2			3
> 2	1	2	3		4
> 3	1	5	6	7	8
> 
> the result should look like this (e.g., in a data.frame):
> 
> 1	1	2	3
> 2	1	2	3	4
> 3	1	5	6	7	8
> 
> is there any way to do so?

Yes, with e.g. sep="\t" and sep=" " the number of separators is taken 
into account.
No, with sep="" the separator is *any* white space.


Uwe Ligges


> thanks in advance,
> jan
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Wed Aug 24 12:02:34 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 24 Aug 2005 11:02:34 +0100 (BST)
Subject: [R] reading "special" text files
In-Reply-To: <430C345F.1050406@tuebingen.mpg.de>
References: <430C345F.1050406@tuebingen.mpg.de>
Message-ID: <Pine.LNX.4.61.0508241056500.8536@gannet.stats>

On Wed, 24 Aug 2005, Jan Wiener wrote:

> hello,
>
> assume you have a txt-file (sep="\t" or "") looking as follows that you
> want to read into a variable:

Into a variable or a data frame?

> 1	1	2			3
> 2	1	2	3		4
> 3	1	5	6	7	8
>
> the result should look like this (e.g., in a data.frame):

With no column names? Not possible.

> 1	1	2	3
> 2	1	2	3	4
> 3	1	5	6	7	8
>
> is there any way to do so?

I think we need to know what the structure here is.  At a guess, the 
separator is multiple tabs as in the example.  In that case

> read.table("foo", header=FALSE, fill = TRUE)
   V1 V2 V3 V4 V5 V6
1  1  1  2  3 NA NA
2  2  1  2  3  4 NA
3  3  1  5  6  7  8

or

> read.table("foo", header=FALSE, fill = TRUE, row.names=1)
   V2 V3 V4 V5 V6
1  1  2  3 NA NA
2  1  2  3  4 NA
3  1  5  6  7  8

does in essence what you want.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jan.wiener at tuebingen.mpg.de  Wed Aug 24 12:15:27 2005
From: jan.wiener at tuebingen.mpg.de (Jan Wiener)
Date: Wed, 24 Aug 2005 12:15:27 +0200
Subject: [R] [Fwd: Re:  reading "special" text files]
Message-ID: <430C48BF.3010200@tuebingen.mpg.de>


-- 
Dr. Jan Malte Wiener
Max-Planck-Institute for Biological Cybernetics
Spemannstr. 38, 72076 Tuebingen, Germany
tel.: +49 7071 601 631
email: jan.wiener at tuebingen.mpg.de
url: www.kyb.tuebingen.mpg.de/~malte
-------------- next part --------------
An embedded message was scrubbed...
From: Jan Wiener <jan.wiener at tuebingen.mpg.de>
Subject: Re: [R] reading "special" text files
Date: Wed, 24 Aug 2005 12:12:50 +0200
Size: 8523
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050824/f3398a76/Rreadingspecialtextfiles.mht

From luis.tercero at ebi-wasser.uni-karlsruhe.de  Wed Aug 24 13:26:07 2005
From: luis.tercero at ebi-wasser.uni-karlsruhe.de (Luis Tercero)
Date: Wed, 24 Aug 2005 13:26:07 +0200
Subject: [R] randomize
Message-ID: <430C594F.20206@ebi-wasser.uni-karlsruhe.de>

Dear helpeRs,

I am looking for an R equivalent of the S function "randomize" but 
cannot find it anywhere (?randomize, help.search("randomize")).  There 
are some references to "Randomize()" in the list archives, but it is not 
on my system (R 2.1.1 on Windows XP)... what package is it in?

Thanks!

Luis

-- 

Luis Tercero, M.Sc.

Engler-Bunte-Institut der Universit??t Karlsruhe (TH)
Bereich Wasserchemie

Engler-Bunte-Ring 1
D-76131 Karlsruhe

Tel. +49 721 608 6381
Fax: +49 721 608 7051



From snvk4u at gmail.com  Wed Aug 24 13:17:01 2005
From: snvk4u at gmail.com (Krishna)
Date: Wed, 24 Aug 2005 16:47:01 +0530
Subject: [R] correlation by subset
Message-ID: <139ef1c205082404173942d3c0@mail.gmail.com>

Hi all

Having searched the available documentation on R, I request for help
in sorting out the underlying problem.

I have a huge dataset containing 2 variables x and y, which is a daily
price series.

I would like to observe the quarterly correlations among these two
variables. Is there anyway where i can calculate cor.coeff by using a
grouping variable in R.

thanks in advance for the help

rgds

snvk



From petr.pikal at precheza.cz  Wed Aug 24 13:25:36 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Wed, 24 Aug 2005 13:25:36 +0200
Subject: [R] (Fwd) Re:  priority of operators in the  FOR (  ) statement
Message-ID: <430C7550.20204.1236143@localhost>

Hi 

On 23 Aug 2005 at 12:03, Ravi.Vishnu at outokumpu.com wrote: 

> Dear All, 
> I spent an entire evening in debugging a small, fairly simple 
program 
> in R - without success. It was my Guru in Bayesian Analysis, 
Thomas 
> Fridtjof, who was able to diagonose the problem. He said that it 
took 
> a long time for him also to locate the problem. This program 
> illustrates in some ways the shortcomings of the error messages 
that R 

<snip>

> 
*****************************************************
***************** 
> ***' # Bayesian Data Analysis ## 
> source("M:/programming/Rfolder/Assignments/fortest.txt") 
>  
> # #Remove all objects from the workspace 
> rm(list=ls()) 
> # #We will also try to note the time that the program takes 
> # #We will start the clock at starttime 
> starttime <- proc.time()[3]; 
>  

> my.function<-function(x) { 
> s2<-sqrt(2); 
> if ((x>=0) & (x<s2)) return(x/2) 
> else  
> if ((x>=s2) & (x<1+s2)) return(0.2) 
> else  
> if ((x>=1+s2) & (x<1.5+s2)) return(0.6) 
> else  
> if ((x>1.5+s2) | (x<0)) return(0) 
> } 

I also wonder if this function computes what is intended 

maybe this 

vec<-c(0,sqrt(2),sqrt(2)+1,sqrt(2)+1.5) 

myfun<-function(x,vec) { 

y<-x/2 
y0<-c(0,1,.2,.6,0)[findInterval(x,vec)+1] 
pos<-which(y0%in%1) 
y0[pos]<-y[pos] 
y0 
} 

vec<-c(0,sqrt(2),sqrt(2)+1,sqrt(2)+1.5) 

> x<-rnorm(1000000) 
> system.time(my1<-myfun(x,vec)) 
[1] 1.62 0.05 1.67   NA   NA 
> 

will do it more efficiently. 

HTH 
Petr 

>  
> alphayx<-function(y,x) { 
> fy<-my.function(y) 
> fx<-my.function(x) 
> fyx<-fy/fx 
> # to account for 0/0 division 
> if (is.na(fyx)) fyx<-0 
> #fyx<-ifelse(is.na(fyx),0,fyx); 
> alpha<-min(1,fyx) 
> return(alpha) 
> } 
>  
> sigma<-0.5; 
> #nr is the number of iterations 
> nr<-20 
> x<-numeric(nr); 
> x[1]<-1; 
> t<-1:nr; 
>  
> for (i in 1:nr-1) { 
> xi<-x[i]; 
> yi<-rnorm(1,mean=xi,sd=sigma); 
> ui<-runif(1,0,1); 
> ualphai<-alphayx(yi,xi); 
> xn<-ifelse(ui<=ualphai,yi,xi); 
> x[i+1]<-xn; 
> } 
>  
> plot(t,x,type="p") 
>  
> endtime<-proc.time()[3]; 
> elapsedTime<-endtime-starttime; 
> cat("Elapsed time is", elapsedTime, "seconds", "\n") 
> 
*****************************************************
> ______________________________________________ 
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html 

Petr Pikal
petr.pikal at precheza.cz



From ernesto at ipimar.pt  Wed Aug 24 13:26:16 2005
From: ernesto at ipimar.pt (ernesto)
Date: Wed, 24 Aug 2005 12:26:16 +0100
Subject: [R] histogram method for S4 class.
Message-ID: <430C5958.1040005@ipimar.pt>

Hi,

I'm trying to develop an histogram method for a class called "FLQuant"
which is used by the package FLCore (http://flr-project.org). FLQuant is
an extension to "array". There is an as.data.frame method that coerces
flquant into a data.frame suitable for lattice plotting. The problem is
that when I coerce the object and plot it after it works but if the
method is applied within the histogram method it does not work. See the
code below (the FLCore package is here
http://prdownloads.sourceforge.net/flr/FLCore_1.0-1.tar.gz?download)

> library(FLCore)
Loading required package: lattice
> data(ple4)
> histogram(~data|year, data=ple4 at catch.n)
Error in inherits(x, "factor") : Object "x" not found
> histogram(~data|year, data=as.data.frame(ple4 at catch.n))

The catch.n slot is a FLQuant object and the code for histogram is the
following

setMethod("histogram", signature(formula="formula", data="FLQuant"),
    function (formula, data = parent.frame(), allow.multiple =
is.null(groups) || outer,
        outer = FALSE, auto.key = FALSE, aspect = "fill", panel =
"panel.histogram", prepanel = NULL,
        scales = list(), strip = TRUE, groups = NULL, xlab, xlim, ylab,
ylim,
        type = c("percent", "count", "density"),
        nint = if (is.factor(x)) length(levels(x)) else
round(log2(length(x)) + 1),
        endpoints = extend.limits(range(x[!is.na(x)]), prop = 0.04),
        breaks = if (is.factor(x)) seq(0.5, length = length(levels(x)) +
1) else do.breaks(endpoints, nint),
        equal.widths = TRUE, drop.unused.levels =
lattice.getOption("drop.unused.levels"), ...,
        default.scales = list(), subscripts = !is.null(groups), subset =
TRUE) {

        qdf <- as.data.frame(data)

        histogram(formula, data = qdf, allow.multiple = allow.multiple,
outer = outer,
            auto.key = auto.key, aspect = aspect, panel = panel,
prepanel = prepanel, scales = scales,
            strip = strip, groups = groups, xlab=xlab, xlim=xlim,
ylab=ylab, ylim=ylim, type = type,
            nint = nint, endpoints = endpoints, breaks = breaks,
equal.widths = equal.widths,
            drop.unused.levels = drop.unused.levels, ..., default.scales
= default.scales,
            subscripts = subscripts, subset = subset)
    }
)


Any ideas ?

Thanks

EJ



From sdavis2 at mail.nih.gov  Wed Aug 24 13:28:36 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Wed, 24 Aug 2005 07:28:36 -0400
Subject: [R] randomize
In-Reply-To: <430C594F.20206@ebi-wasser.uni-karlsruhe.de>
Message-ID: <BF31D224.D0A7%sdavis2@mail.nih.gov>

On 8/24/05 7:26 AM, "Luis Tercero"
<luis.tercero at ebi-wasser.uni-karlsruhe.de> wrote:

> Dear helpeRs,
> 
> I am looking for an R equivalent of the S function "randomize" but
> cannot find it anywhere (?randomize, help.search("randomize")).  There
> are some references to "Randomize()" in the list archives, but it is not
> on my system (R 2.1.1 on Windows XP)... what package is it in?

Try help.search('random').  You can probably use sample (see ?sample) to do
what you  want.  Others may have a more direct equivalent.

Sean



From Torsten.Hothorn at rzmail.uni-erlangen.de  Wed Aug 24 13:31:12 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Wed, 24 Aug 2005 13:31:12 +0200 (CEST)
Subject: [R] Wilcoxon Signed Rank Test
In-Reply-To: <1124828962.2192.12.camel@wb4-c29-lin>
References: <1124828962.2192.12.camel@wb4-c29-lin>
Message-ID: <Pine.LNX.4.51.0508241329490.28537@artemis.imbe.med.uni-erlangen.de>


> Dear list,
>
> Please forgive me if this is a dumb question. I want to compare a set of
> paired data (pre and late). There are ties in pre and late. I searched
> on line, some document says use wilcox.exact in R instead of
> wilcox.test. Anyone has any experience using wilcoxon signed rank test
> to share?

R> library("exactRankTests")
R> x <- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
R> y <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
R> wilcox.exact(x, y, paired = TRUE, alternative = "greater")

        Exact Wilcoxon signed rank test

data:  x and y
V = 40, p-value = 0.01953
alternative hypothesis: true mu is greater than 0

is one of the examples shown in ?wilcox.exact

Best,

Torsten


> Thanks in advance.
>
> platform i686-pc-linux-gnu
> arch     i686
> os       linux-gnu
> system   i686, linux-gnu
> status
> major    2
> minor    1.0
> year     2005
> month    04
> day      18
> language R
>
> --
> Jeanie (Jie) Na
>
> Programmer Analyst II                       _   _    ___    _   _    ____
> Department of Quantitative Health Sciences [_]-[_]  / - \  | |_| |  (_(_
> Cleveland Clinic Foundation                 |   |  ( |_| ) )  _  (   _| )
> Tel: (216)4451369                          [_]-[_]  \_\_\  |_| |_|  (___/
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From ligges at statistik.uni-dortmund.de  Wed Aug 24 13:33:43 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Wed, 24 Aug 2005 13:33:43 +0200
Subject: [R] randomize
In-Reply-To: <430C594F.20206@ebi-wasser.uni-karlsruhe.de>
References: <430C594F.20206@ebi-wasser.uni-karlsruhe.de>
Message-ID: <430C5B17.2050405@statistik.uni-dortmund.de>

Luis Tercero wrote:

> Dear helpeRs,
> 
> I am looking for an R equivalent of the S function "randomize" but 
> cannot find it anywhere (?randomize, help.search("randomize")).  There 
> are some references to "Randomize()" in the list archives, but it is not 
> on my system (R 2.1.1 on Windows XP)... what package is it in?

In principle, you are looking for sample().

If you don't need other values for the "restrict" argument than the 
default, you can simply define:

randomize <- function(x)
   sample(seq(nrow(x)))

Uwe Ligges



> Thanks!
> 
> Luis
>



From ccleland at optonline.net  Wed Aug 24 14:05:40 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Wed, 24 Aug 2005 08:05:40 -0400
Subject: [R] correlation by subset
In-Reply-To: <139ef1c205082404173942d3c0@mail.gmail.com>
References: <139ef1c205082404173942d3c0@mail.gmail.com>
Message-ID: <430C6294.9080309@optonline.net>

by(mydata, mydata$GROUPING, function(x) cor(x$x, x$y, use="pair"))

?by

Krishna wrote:
> Hi all
> 
> Having searched the available documentation on R, I request for help
> in sorting out the underlying problem.
> 
> I have a huge dataset containing 2 variables x and y, which is a daily
> price series.
> 
> I would like to observe the quarterly correlations among these two
> variables. Is there anyway where i can calculate cor.coeff by using a
> grouping variable in R.
> 
> thanks in advance for the help
> 
> rgds
> 
> snvk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From Ravi.Vishnu at outokumpu.com  Wed Aug 24 15:02:53 2005
From: Ravi.Vishnu at outokumpu.com (Ravi.Vishnu@outokumpu.com)
Date: Wed, 24 Aug 2005 15:02:53 +0200
Subject: [R]  (Fwd) Re:  priority of operators in the  FOR (  ) statement
Message-ID: <OF357C98E7.643F0195-ONC1257067.0046E67E-C1257067.0047ACFE@outokumpu.com>

Dear List,
Thanks to all those who responded to my questions. I now know how the R 
experts reason, which is good to know when faced with the a problem in R. 
I also became aware of R commands like syntax, browser, debug, traceback, 
xml etc. I certainly aim to try out these commands.
Some have urged me to read the documentation first. This point is well 
taken. But some things register better when they are pointed out after 
having struggled with a problem first.
I also became aware that some HTML attachments followed with my mail 
without my knowing about it. I have now changed the preferences in my mail 
program. Hopefully, this time, I will be sending text only.
Regards,
Ravi Vishnu

  
This message is meant for the addressee only and may contain 
confidential and legally privileged information. Any unauthorised 
review, use, copying, storage, disclosure or distribution of this e-
mail and any attachments is strictly prohibited. If you are not the 
named recipient or have otherwise received this communication in 
error, please destroy this message from your system and kindly notify 
the sender by e-mail. Thank you for your co-operation.



From snvk4u at gmail.com  Wed Aug 24 15:14:36 2005
From: snvk4u at gmail.com (Krishna)
Date: Wed, 24 Aug 2005 18:44:36 +0530
Subject: [R] correlation by subset
In-Reply-To: <430C6294.9080309@optonline.net>
References: <139ef1c205082404173942d3c0@mail.gmail.com>
	<430C6294.9080309@optonline.net>
Message-ID: <139ef1c205082406144083ac48@mail.gmail.com>

Hi Mr. Cleland

Could you please detail the function.

Thanks and best regards

snvk

On 8/24/05, Chuck Cleland <ccleland at optonline.net> wrote:
> by(mydata, mydata$GROUPING, function(x) cor(x$x, x$y, use="pair"))
> 
> ?by
> 
> Krishna wrote:
> > Hi all
> >
> > Having searched the available documentation on R, I request for help
> > in sorting out the underlying problem.
> >
> > I have a huge dataset containing 2 variables x and y, which is a daily
> > price series.
> >
> > I would like to observe the quarterly correlations among these two
> > variables. Is there anyway where i can calculate cor.coeff by using a
> > grouping variable in R.
> >
> > thanks in advance for the help
> >
> > rgds
> >
> > snvk
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> --
> Chuck Cleland, Ph.D.
> NDRI, Inc.
> 71 West 23rd Street, 8th floor
> New York, NY 10010
> tel: (212) 845-4495 (Tu, Th)
> tel: (732) 452-1424 (M, W, F)
> fax: (917) 438-0894
>



From basille at biomserv.univ-lyon1.fr  Wed Aug 24 15:23:25 2005
From: basille at biomserv.univ-lyon1.fr (Mathieu Basille)
Date: Wed, 24 Aug 2005 15:23:25 +0200
Subject: [R] help with unknown function
In-Reply-To: <5.0.2.1.2.20050818153246.027e22c0@pop.mnhn.fr>
References: <5.0.2.1.2.20050818153246.027e22c0@pop.mnhn.fr>
Message-ID: <430C74CD.3000303@biomserv.univ-lyon1.fr>

Hello.

Sorry for the delay, (not so) long vacations...

Seems to me that it has something to deal with the 'adehabitat' package 
which is very useful for radio-tracking data. ('adehabitat' is available 
on CRAN)

BUT the 'getareahr' function doesn't exist. Could it be a mix between 
'getverticeshr' and 'ararea' ? Maybe it was only one function in 
precedent versions of the package. Take a look at the help files of 
these functions, there is some nice examples.

Hope this helps!
Mathieu



Agnes Gault a ??crit :

>Hello
>
>I am working on radio tracking data, with a short programme someone gave me 
>and ... which should, supposedly, work ... In this programme, there is the 
>function : getareahr(kern, levels = 95). But i cannot find any 'getareahr' 
>in R ...
>
>could anyone help me?
>
>thanks!
>Agn??s
>
>-------------------------------------------------------------------------------------------------------------------
>
>Agn??s GAULT
>graduate student
>UMR 5173 MNHN-CNRS-UPMC
>case postale 50
>Species Conservation, Restoration and Population Survey (CERSP)
>61 rue Buffon, 1er ??tage
>75005 PARIS
>FRANCE
>Tel: 33 (0)1 40 79 57 64
>Fax: 33 (0)1 40 79 38 35
>Email: gault at mnhn.fr
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From daniel at sintesys.com.ar  Wed Aug 24 16:29:40 2005
From: daniel at sintesys.com.ar (daniel@sintesys.com.ar)
Date: Wed, 24 Aug 2005 11:29:40 -0300 (ART)
Subject: [R] lm.ridge
Message-ID: <20768.170.155.1.10.1124893780.squirrel@www.sintesys.com.ar>

Hello, I have posted this mail a few days ago but I did it wrong, I hope
is right now:

I have the following doubts related with lm.ridge, from MASS package. To
show the problem using the Longley example, I have the following doubts:

First: I think coefficients from lm(Employed~.,data=longley) should be
equal coefficients from lm.ridge(Employed~.,data=longley, lambda=0) why
it does not happen?
Second: if I have for example
Ridge<-lm.ridge(Employed~., data=longley, lambda = seq(0,0.1,0.001)), I
suppose intercept coefficient is defined implicit, why it does not
appear in Ridge$coef?

Third: I suppose that if I define
1) y<-longley$Employed
2) X<-as.matrix(cbind(1,Longley[,1:6])
3) I = identity matrix
the following should be true:
         Coef=(X'X+kI)^(-1) X'y
and if a take k=Ridge$kHKV, Coef should be approx equal to
Ridge$Coef[near value of kHKV] and it does not seem to happen, why?

Values:
> Ridge$kHKB
[1] 0.004275357

Using the calculation above (third question, third point):
Coef=
                      [,1]
  1            -0.095492310
  GNP.deflator -0.052759002
  GNP           0.070993540
  Unemployed   -0.004244391
  Armed.Forces -0.005725582
  Population   -0.413341544
  Year          0.048420107

And if I take from Ridge&coef:

Ridge$coef[0.004]
GNP.deflator -0.03098507
GNP -1.32553151
Unemployed -1.53237769
Armed.Forces -0.63334911
Population -0.88690241
Year 6.82105049

Any help, suggestion or orientation?
Thanks in advance
Daniel Rozengardt



From justin_bem at yahoo.fr  Tue Aug 23 22:03:11 2005
From: justin_bem at yahoo.fr (justin bem)
Date: Tue, 23 Aug 2005 22:03:11 +0200 (CEST)
Subject: [R] The betareg package don't supporte large data file
Message-ID: <20050823200311.17172.qmail@web25708.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050823/ce9aa199/attachment.pl

From Shawn.Lee at asml.com  Wed Aug 24 16:41:04 2005
From: Shawn.Lee at asml.com (Shawn Lee)
Date: Wed, 24 Aug 2005 16:41:04 +0200
Subject: [R] How to get the list of the files when you read zip file by
	gzfile or unz
Message-ID: <C26DF8487E6ED540B0B9163433BD2C9878BB8B@NLVDHX84.sn-eu.asml.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050824/31099a19/attachment.pl

From Mike.Prager at noaa.gov  Tue Aug 23 22:08:48 2005
From: Mike.Prager at noaa.gov (Mike Prager)
Date: Tue, 23 Aug 2005 16:08:48 -0400
Subject: [R] [R-pkgs] For2R - Interface from Fortran to R
Message-ID: <430B8250.9060308@noaa.gov>

We announce the availability of the Fortran 95 module "For2R", which 
makes it easy to write complicated R data structures (i.e., lists of 
lists, matrices, dataframes, ...) from Fortran programs. By a series of 
subroutine calls, program outputs can be written to a file readable by R 
with a single "dget" function call. This facilitates automated graphics 
generation and other postprocessing of model results.

A downloadable ZIP file of For2R is available from  
http://shrimp.ccfhrb.noaa.gov/~mprager/Rinter.html  and includes Fortran 
source, documentation, and an example.

We are working on similar code to interface C++ with R. An extremely 
crude version of such code is available from the same page. Though the 
C++ code will be totally replaced, the download includes sample output 
and R graphics functions for automated processing of a fisheries example. 

Although For2R is much nicer than our current C++ code, it should all be 
considered beta-test code, and it is supplied with no warranty 
whatsoever.  Bug reports and suggestions are welcome.

-- 
Michael Prager, for myself and Erik Williams
Population Dynamics Team, NMFS SE Fisheries Science Center
NOAA Center for Coastal Fisheries and Habitat Research
Beaufort, North Carolina  28516  USA
http://shrimp.ccfhrb.noaa.gov/~mprager/

_______________________________________________
R-packages mailing list
R-packages at stat.math.ethz.ch
https://stat.ethz.ch/mailman/listinfo/r-packages



From ripley at stats.ox.ac.uk  Wed Aug 24 17:04:34 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 24 Aug 2005 16:04:34 +0100 (BST)
Subject: [R] How to get the list of the files when you read zip file by
 gzfile or unz
In-Reply-To: <C26DF8487E6ED540B0B9163433BD2C9878BB8B@NLVDHX84.sn-eu.asml.com>
References: <C26DF8487E6ED540B0B9163433BD2C9878BB8B@NLVDHX84.sn-eu.asml.com>
Message-ID: <Pine.LNX.4.61.0508241557240.16717@gannet.stats>

On Wed, 24 Aug 2005, Shawn Lee wrote:

> Does somebody know how to get the filename lists in the ziped when
> "gzfile" or "unz" command is used ?

There is no list when gzfile() is used: a gzipped file is not a zip
archive.

unz() opens a single specified file in a zip archive.

AFAIK R does not directly support listing files in a zip archive as R
itself has no need of this.  However,

   tmp <- system(paste("unzip -l", zip_file_name), intern=TRUE)
   substring(tmp[-c(1:3, length(tmp)-0:1)], 29)

looks about right.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From rdiaz at cnio.es  Wed Aug 24 17:07:35 2005
From: rdiaz at cnio.es (Ramon Diaz-Uriarte)
Date: Wed, 24 Aug 2005 17:07:35 +0200
Subject: [R] studentship till January 2007
Message-ID: <200508241707.36039.rdiaz@cnio.es>

Please pass along, and apologies for double posting.

We have money to support a student till January 2007 (with a salary of about 
1000 euro/month). Most of the work will focus on classification/prediction 
using microarray data. The work will involve both methodological research 
(mainly computation and simulation-based) and implementation of existing 
approaches using R (and possible development of web-based applications). In 
addition to the main focus of the job, the student will be encouraged (and 
expected) to get involved in the many collaborations we have with "wet lab" 
cancer researchers.

The candidate should have a bachelors or MSc degree in stats or related 
fields. A genuine interest in applied statistics and statistical 
consulting,and experience with multivariate methods, linear models, logistic 
regression, and survival analysis are required. Proficiency with R and 
knowledge of C/C++ or Fortran are required. Familiarity with Python (and Perl 
and/or Tcl/Tk) and some experience with development of web-based applications 
(CGIs using Python, for example) highly valued. Our machines only run 
GNU/Linux (or other Unixes) and thus knowledge of Linux to administer your 
workstation is needed.

The Bioinformatics Unit is one of the leading bioinformatics group in Spain, 
part of CNIO, one of the main cancer research institutes in Spain. We have 
developed a set of widely used web-based microarray data analysis tools, and 
have extensive computational facilities, including two computing clusters 
(with x86s and opterons) that use MPI and OpenMosix. You can check more of 
what we do at our group webpage (http://bioinfo.cnio.es) and my own web page 
(http://ligarto.org/rdiaz).


For further details please email Ram??n D??az-Uriarte at rdiaz at ligarto.org

Best,

--
Ram??n D??az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol??gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern??ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://ligarto.org/rdiaz
PGP KeyID: 0xE89B3462
(http://ligarto.org/rdiaz/0xE89B3462.asc)

-------------------------------------------------------

-- 
Ram??n D??az-Uriarte
Bioinformatics Unit
Centro Nacional de Investigaciones Oncol??gicas (CNIO)
(Spanish National Cancer Center)
Melchor Fern??ndez Almagro, 3
28029 Madrid (Spain)
Fax: +-34-91-224-6972
Phone: +-34-91-224-6900

http://ligarto.org/rdiaz
PGP KeyID: 0xE89B3462
(http://ligarto.org/rdiaz/0xE89B3462.asc)



**NOTA DE CONFIDENCIALIDAD** Este correo electr??nico, y en s...{{dropped}}



From david.shin at pearson.com  Wed Aug 24 17:22:39 2005
From: david.shin at pearson.com (Shin, David)
Date: Wed, 24 Aug 2005 10:22:39 -0500
Subject: [R] Call SAS from R
Message-ID: <6F3CF8F7047E374CAF4DCED3ED14576E0D1BAE81@iowacexch4.ic.ncs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050824/76eefb45/attachment.pl

From vincent at 7d4.com  Wed Aug 24 17:58:22 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Wed, 24 Aug 2005 17:58:22 +0200
Subject: [R] Call SAS from R
In-Reply-To: <6F3CF8F7047E374CAF4DCED3ED14576E0D1BAE81@iowacexch4.ic.ncs.com>
References: <6F3CF8F7047E374CAF4DCED3ED14576E0D1BAE81@iowacexch4.ic.ncs.com>
Message-ID: <430C991E.2060204@7d4.com>

perhaps it would be easier to read directly
your datafile from R ?
read.table(...) is your friend, and quite easy to use.
type ?read.table under R.
hih



From david.shin at pearson.com  Wed Aug 24 18:14:24 2005
From: david.shin at pearson.com (Shin, David)
Date: Wed, 24 Aug 2005 11:14:24 -0500
Subject: [R] Call SAS from R
Message-ID: <6F3CF8F7047E374CAF4DCED3ED14576E0D1BAE82@iowacexch4.ic.ncs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050824/a62e82ca/attachment.pl

From macq at llnl.gov  Wed Aug 24 18:38:09 2005
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 24 Aug 2005 09:38:09 -0700
Subject: [R] Call SAS from R
In-Reply-To: <6F3CF8F7047E374CAF4DCED3ED14576E0D1BAE81@iowacexch4.ic.ncs.com>
References: <6F3CF8F7047E374CAF4DCED3ED14576E0D1BAE81@iowacexch4.ic.ncs.com>
Message-ID: <p06210200bf325169dd1b@[128.115.153.6]>

How does it not work? Do you get error messages? Nothing at all?
(it's difficult to help without more specific information, so this is 
a good time to suggest reading the posting guide: 
http://www.R-project.org/posting-guide.html)

What happens if you try to run that exact command outside of R? Does it work?

-Don

At 10:22 AM -0500 8/24/05, Shin, David wrote:
>Hi All,
>
>I am new to post question on this list. I apologize if this question is too
>easy or irrelevant.
>
>I am doing a simulation study and I need to read a data file that can be
>easily read by SAS.
>So, what I try to do is to execute SAS in R and then read the output of SAS
>to R.
>
>I try the following code but it didn't work.
>system("c:\\program files\\sas institute\\v8\\sas.exe test")
>
>can anyone give me some help with this?
>Thanks.
>
>Davoid
>
>
>****************************************************************************
>This email may contain confidential material.
>If you were not an intended recipient,
>Please notify the sender and delete all copies.
>We may monitor email to and from our network.
>****************************************************************************
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From david.shin at pearson.com  Wed Aug 24 18:50:28 2005
From: david.shin at pearson.com (Shin, David)
Date: Wed, 24 Aug 2005 11:50:28 -0500
Subject: [R] Call SAS from R
Message-ID: <6F3CF8F7047E374CAF4DCED3ED14576E0D1BAE83@iowacexch4.ic.ncs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050824/803306d1/attachment.pl

From drf5n at maplepark.com  Wed Aug 24 18:54:35 2005
From: drf5n at maplepark.com (David Forrest)
Date: Wed, 24 Aug 2005 11:54:35 -0500 (CDT)
Subject: [R] Call SAS from R
In-Reply-To: <6F3CF8F7047E374CAF4DCED3ED14576E0D1BAE83@iowacexch4.ic.ncs.com>
References: <6F3CF8F7047E374CAF4DCED3ED14576E0D1BAE83@iowacexch4.ic.ncs.com>
Message-ID: <Pine.LNX.4.58.0508241152350.4438@maplepark.com>

On Wed, 24 Aug 2005, Shin, David wrote:
...
> > system("c:\\program files\\sas institute\\v8\\sas.exe test")
> Warning message:
> c:\program not found

Escape the spaces too.  It is trying to run the program c:\program or
c:\progra~1\sas

Dave
-- 
 Dr. David Forrest
 drf at vims.edu                                    (804)684-7900w
 drf5n at maplepark.com                             (804)642-0662h
                                   http://maplepark.com/~drf5n/



From HDoran at air.org  Wed Aug 24 19:06:16 2005
From: HDoran at air.org (Doran, Harold)
Date: Wed, 24 Aug 2005 13:06:16 -0400
Subject: [R] Remove NAs from Barplot
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7409E5C468@dc1ex2.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050824/639c1819/attachment.pl

From sean.oriordain at gmail.com  Wed Aug 24 19:11:47 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Wed, 24 Aug 2005 18:11:47 +0100
Subject: [R] plotting GAM
In-Reply-To: <430C61F1.19785.1A41BBDA@localhost>
References: <430C4550.5646.19D1EA2F@localhost>
	<8ed68eed05082401313a502de8@mail.gmail.com>
	<430C61F1.19785.1A41BBDA@localhost>
Message-ID: <8ed68eed050824101138023177@mail.gmail.com>

Emil,
I've no clue what gam() does nor how it works, but saying that is it
possible to use lines(,lwd=???) in someway and plot on top of the
original line?

cheers,
Sean


On 24/08/05, Tkadlec Emil <tkadlec at prfnw.upol.cz> wrote:
> Sear Sean,
> here is the more working example (I  use the latest version of everything
> on my PC):
> 
> x1<-runif(100,-5,5)
> x2<-runif(100,1,50)
> e<-rnorm(100)
> y<-.3*x1-0.5*x2+e
> 
> mod<-gam(y~s(x1)+s(x2))
> par(mfrow=c(1,2))
> plot(mod,residuals=T,se=T)
> --------
> So you get two figs. My concern is to enlarge the regression line, not the
> point or enything else.
> Best,
> Emil
> 
> 
> 
> > Hi Emil,
> > can you give us a working example of what you're trying to do?
> >
> > cheers!
> > Sean
> >
> > ps. as per the posting-guide... :-)
> >
> > On 24/08/05, Tkadlec Emil <tkadlec at prfnw.upol.cz> wrote:
> > > Dear colleagues,
> > > I would like to have GAM regression lines (package gam) thicker than
> > > the default setting does. Is there any way to change the width of
> > > regression line when plotting gam.objects from the package GAM with
> > > more than one predictor? Changing lwd parameter in plot function
> > > controls all line components, including points making them thicker
> > > as well, which is not what I would like to have. Thanks for help.
> > > Best, Emil
> > >
> > > **************************************************************
> > > Emil Tkadlec
> > > Palacky University                PrF UP
> > > Faculty of Science                katedra ekologie
> > > Department of Ecology             tr. Svobody 26
> > > tr. Svobody 26                    771 46 OLOMOUC
> > > 771 46 Olomouc                    tel. 58 563 4561
> > > Czech Republic
> > > email: tkadlec at prfnw.upol.cz
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide!
> > > http://www.R-project.org/posting-guide.html
> > >
> 
> 
> **************************************************************
> Emil Tkadlec
> Palacky University                PrF UP
> Faculty of Science                katedra ekologie
> Department of Ecology             tr. Svobody 26
> tr. Svobody 26                    771 46 OLOMOUC
> 771 46 Olomouc                    tel. 58 563 4561
> Czech Republic
> email: tkadlec at prfnw.upol.cz
> **************************************************************
> 
>



From mschwartz at mn.rr.com  Wed Aug 24 19:29:21 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Wed, 24 Aug 2005 12:29:21 -0500
Subject: [R] Remove NAs from Barplot
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7409E5C468@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F7409E5C468@dc1ex2.air.org>
Message-ID: <1124904561.4545.32.camel@localhost.localdomain>

On Wed, 2005-08-24 at 13:06 -0400, Doran, Harold wrote:
> Dear List:
> 
> I'm creating a series of barplots using Sweave that must assume a
> standard format. This is student achievement data and the x-axis must
> include all grades 3 to 8. In some cases, the data for a grade (or more
> than one grade) are missing in the vector math.bar, but are never
> missing for the vector apmxpmeet. The following sample code illustrates
> the issue.
> 
> Using the code below to create the plot works fine. However, the
> following command is designed to place the data onto the plot:
> 
> text(math.barplot, graph.max+5, format(tot), xpd = TRUE, col = c("blue",
> "orange") )
> 
> This does work, but, it also places 'NA's on the plot. Is there a way to
> place the data onto the plot such that the numbers appear, but for the
> NAs not to appear?  I've searched through ?text but was not able to find
> a solution. 
> 
> math.bar <- c(NA,NA,NA,NA,55,48)
> apmxpmeet <- c(47, 50, 49, 50, 49, 46)
> 
> par(ps=10)
> math.bar <- rbind(math.bar, apmxpmeet)
> math.barplot <- barplot(math.bar, beside=T, col=c('blue','orange'),
> names=c('Grade \n 3','Grade \n 4','Grade \n 5','Grade \n 6','Grade \n
> 7','Grade \n 8'), 
> ylim=c(0,120), ylab="Percentage", xlab="Grade Level")
> tot <- round(math.bar,digits=0)
> graph.max <- max(math.bar, apmxpmeet, na.rm=T)
> text(math.barplot, graph.max+5, format(tot), xpd = TRUE, col = c("blue",
> "orange") )
> tmp$sch_nameS05 <- as.character(tmp$sch_nameS05)
> legend(2,120,legend=(c(tmp$sch_nameS05, "Average")),
> fill=c("blue","orange"))
> 
> Thanks,
> Harold


Harold,

Get rid of the 'format(tot)' in your text() call:

text(math.barplot, graph.max+5, tot, xpd = TRUE, 
     col = c("blue", "orange"))


By using format(tot), you are coercing the values to text. Thus:

> format(tot)
          [,1] [,2] [,3] [,4] [,5] [,6]
math.bar  "NA" "NA" "NA" "NA" "55" "48"
apmxpmeet "47" "50" "49" "50" "49" "46"

versus:

> tot
          [,1] [,2] [,3] [,4] [,5] [,6]
math.bar    NA   NA   NA   NA   55   48
apmxpmeet   47   50   49   50   49   46


In the first case, text() will draw "NA", whereas in the second, the NA
is ignored.

Also, your code above is not entirely reproducible, since:

> tmp$sch_nameS05 <- as.character(tmp$sch_nameS05)
Error: Object "tmp" not found


HTH,

Marc Schwartz



From ripley at stats.ox.ac.uk  Wed Aug 24 19:32:52 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 24 Aug 2005 18:32:52 +0100 (BST)
Subject: [R] Call SAS from R
Message-ID: <Pine.LNX.4.61.0508241831110.18625@gannet.stats>

Date: Wed, 24 Aug 2005 18:05:44 +0100 (BST)
From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
To: David Forrest <drf5n at maplepark.com>
Cc: "Shin, David" <david.shin at pearson.com>, r-help at stat.math.ethz.ch,
     'Don MacQueen' <macq at llnl.gov>, bioconductor at stat.math.ethz.ch
Subject: Re: [R] Call SAS from R

On Wed, 24 Aug 2005, David Forrest wrote:

> On Wed, 24 Aug 2005, Shin, David wrote:
> ...
>>> system("c:\\program files\\sas institute\\v8\\sas.exe test")
>> Warning message:
>> c:\program not found
> 
> Escape the spaces too.  It is trying to run the program c:\program or
> c:\progra~1\sas

Sorry that does not work.  The Windows way is to quote it: e.g.

system('"c:/Program Files/Mozilla Firefox/firefox.exe"')

works (note the two sets of quotes), and this is explained with an example 
on the help page ?system, so please do as the posting guide asks and read 
the documentation ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From NordlDJ at dshs.wa.gov  Wed Aug 24 19:38:17 2005
From: NordlDJ at dshs.wa.gov (Nordlund, Dan)
Date: Wed, 24 Aug 2005 10:38:17 -0700
Subject: [R] Call SAS from R
Message-ID: <592E8923DB6EA348BE8E33FCAADEFFFC13EED790@dshs-exch2.dshs.wa.lcl>

David,

1. I assume you are working on a MS Windows OS given your system command.  
2. You need to determine what command will work to run your program from the
command line in Windows.  If your path is correct, then you can run SAS from
the command line like

      "c:\program files\sas institute\v8\sas.exe" test
      
Notice, the quotes do not include your SAS input file.  Also, you only use
single back-slashes on the command line.  If the above works for the Windows
command line, then go to 3.

3. The R command should then look like the following.

     System('"c:\\program files\\sas institute\\v8\\sas.exe" test') 

Notice that in R I have escaped the back-slashes, and have placed the whole
command in single quotes.  This ensures that the double quotes are passed on
to Windows.

Hope this helps,

Dan

Daniel J. Nordlund
Research and Data Analysis
Washington State Department of Social and Health Services
Olympia, WA  98504-5204

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Shin, David
Sent: Wednesday, August 24, 2005 9:50 AM
To: 'Don MacQueen'; r-help at stat.math.ethz.ch; bioconductor at stat.math.ethz.ch
Subject: Re: [R] Call SAS from R


Thanks for the responses.
Here is the command I used and the error message I got.

> system("c:\\program files\\sas institute\\v8\\sas.exe test")
Warning message: 
c:\program not found

if I change "program files" to "progra~1" then the output is:
> system("c:\\progra~1\\sas institute\\v8\\sas.exe test")
Warning message: 
c:\progra~1\sas not found

I don't know how to change the folder name "sas institute" to let R reads
it. Can someone help me with this?

The strange thing is that if I type in the command 
"c:\\progra~1\\sas institute\\v8\\sas.exe test" in dos environment, it
didn't work, either.

I will appreciate very much if someone can help a bit. Thanks.

David



From amsa36060 at yahoo.com  Wed Aug 24 20:01:52 2005
From: amsa36060 at yahoo.com (Amir Safari)
Date: Wed, 24 Aug 2005 11:01:52 -0700 (PDT)
Subject: [R] Packages
Message-ID: <20050824180152.48649.qmail@web60414.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050824/ad9137d3/attachment.pl

From HDoran at air.org  Wed Aug 24 20:06:11 2005
From: HDoran at air.org (Doran, Harold)
Date: Wed, 24 Aug 2005 14:06:11 -0400
Subject: [R] Remove NAs from Barplot
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7409E5C48B@dc1ex2.air.org>

Thanks, Marc. It works. My apologies for not making the code
reproducible.  

-----Original Message-----
From: Marc Schwartz (via MN) [mailto:mschwartz at mn.rr.com] 
Sent: Wednesday, August 24, 2005 1:29 PM
To: Doran, Harold
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Remove NAs from Barplot

On Wed, 2005-08-24 at 13:06 -0400, Doran, Harold wrote:
> Dear List:
> 
> I'm creating a series of barplots using Sweave that must assume a 
> standard format. This is student achievement data and the x-axis must 
> include all grades 3 to 8. In some cases, the data for a grade (or 
> more than one grade) are missing in the vector math.bar, but are never

> missing for the vector apmxpmeet. The following sample code 
> illustrates the issue.
> 
> Using the code below to create the plot works fine. However, the 
> following command is designed to place the data onto the plot:
> 
> text(math.barplot, graph.max+5, format(tot), xpd = TRUE, col = 
> c("blue",
> "orange") )
> 
> This does work, but, it also places 'NA's on the plot. Is there a way 
> to place the data onto the plot such that the numbers appear, but for 
> the NAs not to appear?  I've searched through ?text but was not able 
> to find a solution.
> 
> math.bar <- c(NA,NA,NA,NA,55,48)
> apmxpmeet <- c(47, 50, 49, 50, 49, 46)
> 
> par(ps=10)
> math.bar <- rbind(math.bar, apmxpmeet) math.barplot <- 
> barplot(math.bar, beside=T, col=c('blue','orange'), names=c('Grade \n 
> 3','Grade \n 4','Grade \n 5','Grade \n 6','Grade \n 7','Grade \n 8'), 
> ylim=c(0,120), ylab="Percentage", xlab="Grade Level") tot <- 
> round(math.bar,digits=0) graph.max <- max(math.bar, apmxpmeet, 
> na.rm=T) text(math.barplot, graph.max+5, format(tot), xpd = TRUE, col 
> = c("blue",
> "orange") )
> tmp$sch_nameS05 <- as.character(tmp$sch_nameS05) 
> legend(2,120,legend=(c(tmp$sch_nameS05, "Average")),
> fill=c("blue","orange"))
> 
> Thanks,
> Harold


Harold,

Get rid of the 'format(tot)' in your text() call:

text(math.barplot, graph.max+5, tot, xpd = TRUE, 
     col = c("blue", "orange"))


By using format(tot), you are coercing the values to text. Thus:

> format(tot)
          [,1] [,2] [,3] [,4] [,5] [,6]
math.bar  "NA" "NA" "NA" "NA" "55" "48"
apmxpmeet "47" "50" "49" "50" "49" "46"

versus:

> tot
          [,1] [,2] [,3] [,4] [,5] [,6]
math.bar    NA   NA   NA   NA   55   48
apmxpmeet   47   50   49   50   49   46


In the first case, text() will draw "NA", whereas in the second, the NA
is ignored.

Also, your code above is not entirely reproducible, since:

> tmp$sch_nameS05 <- as.character(tmp$sch_nameS05)
Error: Object "tmp" not found


HTH,

Marc Schwartz



From rpeng at jhsph.edu  Wed Aug 24 20:09:05 2005
From: rpeng at jhsph.edu (Roger D. Peng)
Date: Wed, 24 Aug 2005 14:09:05 -0400
Subject: [R] Packages
In-Reply-To: <20050824180152.48649.qmail@web60414.mail.yahoo.com>
References: <20050824180152.48649.qmail@web60414.mail.yahoo.com>
Message-ID: <430CB7C1.1010102@jhsph.edu>

What version of R are you using?  'modreg' no longer exists---its 
functions have been moved to the 'stats' package.

-roger

Amir Safari wrote:
>  
> Hi Dear All,
> I want to instal some packages, but I can not find them in both lists of  Package Index in internet ( http://www.maths.lth.se/help/R/.R/doc/html/packages.html ) and of Instalation of Packages window in the softwar. For example  "modreg". Are they  included in larger packages ?
> Thanks for your help.
> Best Regards,
> Amir Safari
> 
> __________________________________________________
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
Roger D. Peng
http://www.biostat.jhsph.edu/~rpeng/



From david.shin at pearson.com  Wed Aug 24 20:57:27 2005
From: david.shin at pearson.com (Shin, David)
Date: Wed, 24 Aug 2005 13:57:27 -0500
Subject: [R] summary:  Call SAS from R
Message-ID: <6F3CF8F7047E374CAF4DCED3ED14576E0D1BAE84@iowacexch4.ic.ncs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050824/38ac343f/attachment.pl

From grenyer at virginia.edu  Wed Aug 24 21:31:08 2005
From: grenyer at virginia.edu (Rich Grenyer)
Date: Wed, 24 Aug 2005 15:31:08 -0400
Subject: [R] Lacunarity
Message-ID: <36df7191a7aed1404fe43a51e81db5b0@virginia.edu>

Hello R-help,

Does anyone know if the sliding-box lacunarity analysis of Allain & 
Cloitre [1] / Plotnick et al. [2] has been implemented by anyone in R? 
I've come up blank on searches of help files, mailing lists and from 
googling r-project.org.

Thanks in advance,

Rich

[1] C. Allain and M. Cloitre, 1991.  Phys. Rev. A 44, p. 3552.
[2] RE Plotnick, RH Gardner, WW Hargrove, K Prestergaard, M Perlmutter, 
1996. Phys. Rev. E 55(5), p. 5461




--------------------
Rich Grenyer, Ph.D.
Biology Department - University of Virginia
Gilmer Hall
Charlottesville, Virginia
VA 22904
United States of America

tel: (+1) 434 982 5629
fax: (+1) 434 982 5626
http://faculty.virginia.edu/gittleman/rich



From valderama at gmail.com  Wed Aug 24 22:52:42 2005
From: valderama at gmail.com (Laurent Valdes)
Date: Wed, 24 Aug 2005 22:52:42 +0200
Subject: [R] How to collect better estimations of a logistic model
	parameters, by using bootstrapping things ?
Message-ID: <2E3731A4-23CA-45E2-AAE3-1A901F547070@gmail.com>



Dear all,

I know that when using R, people should have a sufficient level in  
statistics.
As well, I'm not a genius, when dealing with logistic regressions.
I would like to construct ICs, IPs,  for a logistic regression, but  
the point is I have just 41 observations.
I had a look at the Design package and noticeably the lrm function,  
but I'm still not able to reduce the IC's, as I was trying to do this  
in SPSS (but do not like it).
I have heard of a mean to do this by using bootstrap, but I'm still  
waiting to find the right way to use it.

As well I would like to find a fine way to do stepwise forward  
selection In R, as I am not sure wich kind of variable may be  
involved in the model, which is composed with 13 numeric variables,  
and a dichotomic variable named "expatriation". I have got a total of  
41 observations, as mentionned above.

I'm using R on macintosh, I have used the function lrm, brlr,  
bootstrap (but for others uses than logistic regressions), and I am  
looking for a great and paved way to do Confiance Intervals, and to  
compute significance values for each of the logistic model's  
parameters, by using R ans bootstrapping, of course.


Any ideas ?

Laurent.

--
--~~ Toulouse, Grenoble, Auch, Arcachon, B??ziers, Paris,
Saragosse, L??vignac Sur Save, habitats naturel du Valdo. ~~--
< http://www.le-valdo.com>



From ripley at stats.ox.ac.uk  Thu Aug 25 00:00:49 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 24 Aug 2005 23:00:49 +0100 (BST)
Subject: [R] How to collect better estimations of a logistic model
 parameters, by using bootstrapping things ?
In-Reply-To: <2E3731A4-23CA-45E2-AAE3-1A901F547070@gmail.com>
References: <2E3731A4-23CA-45E2-AAE3-1A901F547070@gmail.com>
Message-ID: <Pine.LNX.4.61.0508242249410.1421@gannet.stats>

I presume an `IC' is a confidence interval, but what is an `IP'?

I think you need to think hard about the assumptions you want to make. The 
usual way to do logistic regression is via glm(), and the confint() 
function will give you confidence intervals based on profile likelihoods 
that are rather accurate (you need package MASS for this).

If you want to bootstrap you have to decide how.  Case-based resampling is 
the only easy way, and would be appropriate only if the 41 cases were a 
sample and not a design (and even then experts would argue for conditional 
inference).  Bootstrapping logistic regression for a design involves a lot 
of assumptions, and there is not much to suggest that bootstrapping will 
better than using confint().

As for model selection, step() will do it, but given your problem sizes it 
is really _at best_ an exploratory procedure for what extra data might be 
worth collecting.

On Wed, 24 Aug 2005, Laurent Valdes wrote:

>
>
> Dear all,
>
> I know that when using R, people should have a sufficient level in
> statistics.
> As well, I'm not a genius, when dealing with logistic regressions.
> I would like to construct ICs, IPs,  for a logistic regression, but
> the point is I have just 41 observations.
> I had a look at the Design package and noticeably the lrm function,
> but I'm still not able to reduce the IC's, as I was trying to do this
> in SPSS (but do not like it).
> I have heard of a mean to do this by using bootstrap, but I'm still
> waiting to find the right way to use it.
>
> As well I would like to find a fine way to do stepwise forward
> selection In R, as I am not sure wich kind of variable may be
> involved in the model, which is composed with 13 numeric variables,
> and a dichotomic variable named "expatriation". I have got a total of
> 41 observations, as mentionned above.
>
> I'm using R on macintosh, I have used the function lrm, brlr,
> bootstrap (but for others uses than logistic regressions), and I am
> looking for a great and paved way to do Confiance Intervals, and to
> compute significance values for each of the logistic model's
> parameters, by using R ans bootstrapping, of course.
>
>
> Any ideas ?
>
> Laurent.
>
> --
> --~~ Toulouse, Grenoble, Auch, Arcachon, B?ziers, Paris,
> Saragosse, L?vignac Sur Save, habitats naturel du Valdo. ~~--
> < http://www.le-valdo.com>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From edhuang00 at yahoo.com  Thu Aug 25 00:52:43 2005
From: edhuang00 at yahoo.com (Haibo Huang)
Date: Wed, 24 Aug 2005 15:52:43 -0700 (PDT)
Subject: [R] Panel regression in R
Message-ID: <20050824225243.42118.qmail@web31009.mail.mud.yahoo.com>

I am currently trying to replicate the results I got
from RATS for a panel regression. The codes in RATS
looks like this: 

* Final equation for Office Cap Rate Spread
* Regression, Panel Data
preg(effects=time, method=random) CapRate
# CapRate{1} RentCycle{1} VacancyChangeYTY
InflationYTY RealGDPyty 

Just wonder what R package also allow me to have the
options like (effects=time, method=random). Could
anyone share some thoughts with me? Any input will be
helpful. Thank you very much!

Best,
Ed.



From p.connolly at hortresearch.co.nz  Thu Aug 25 03:36:56 2005
From: p.connolly at hortresearch.co.nz (Patrick Connolly)
Date: Thu, 25 Aug 2005 13:36:56 +1200
Subject: [R] barplots - text direction
In-Reply-To: <Pine.LNX.4.61.0508241353220.19202@stat12.stat.auckland.ac.nz>
References: <3028F4C4647C9043B870276E28C69FD622A275@syd05.aimnsw.com.au> 
	<Pine.LNX.4.61.0508241353220.19202@stat12.stat.auckland.ac.nz>
Message-ID: <20050825013656.GL29729@hortresearch.co.nz>

On Wed, 24-Aug-2005 at 01:54PM +1200, David Scott wrote:

|> On Wed, 24 Aug 2005, Murray Pung wrote:
|> 
|> > If the variable names are too long to allow room for each to be displayed on a barplot, how can the direction of the text be changed?
|> >
|> > a <- cbind(2.4,2.4,2.5,2.6,2.6,2.6,2.6,2.6,2.9,2.9,2.9)
|> > b <- cbind(2.3,2.5,2.4,2.2,3.2,2.4,2.9,2.6,2.9,3.0,2.8)
|> > h <- rbind(a,b)
|> > colnames(h) <- c("one","two","three","four","five","six","seven","eight","nine","ten","eleven")
|> > rownames(h) <- c("Pre-stage","Post-stage")
|> > barplot(h, beside = T, legend = colnames(g), horiz = T, xlim = c(0, 5))
|> >
|> >
|> 
|> barplot(h, beside = T, legend = colnames(h), horiz = T, xlim = c(0, 5),
|>          las=1)
|> 
|> will do it.
|> 
|> Note: colnames(h) not colnames(g)

And note that rownames(h) will give a more sensible legend.



-- 
Patrick Connolly
HortResearch
Mt Albert
Auckland
New Zealand 
Ph: +64-9 815 4200 x 7188
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~
I have the world`s largest collection of seashells. I keep it on all
the beaches of the world ... Perhaps you`ve seen it.  ---Steven Wright 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~



From smcnary at charm.net  Thu Aug 25 05:43:48 2005
From: smcnary at charm.net (Scot W McNary)
Date: Wed, 24 Aug 2005 23:43:48 -0400 (EDT)
Subject: [R] question about custom contrasts in ANOVA
Message-ID: <20050824232454.W25801@fellspt.charm.net>


Hi,

I have a problem in which I have test score data on students from a number 
of schools.  In each school I have a measure of whether or not they 
received special programming.  I am interested in the interaction between 
school and attendance to the programming, but in a very select set of 
comparisons.  I'd like to cast the test as one in which students in each 
school who attend are compared with students who don't across all schools. 
So, I would be comparing school 1 attenders with school 1 non-attenders, 
school 2 attenders with school 2 non-attenders, etc.  The reason for the 
custom contrast is that the between school comparisons (e.g., school 1 
attenders vs. school 2 non-attenders) are of less interest.

This seems to require a custom contrast statement for the interaction 
term.  I have a toy example that seems to work as it should, but wonder if 
I've correctly created the contrast needed.

Here is a toy example (code put together from bits taken from MASS ch 6, 
and various R-help postings, (e.g., 
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/49077.html)):

# toy interaction contrast example, 10 schools, 100 kids, 5 attenders (1) 
# and 5 non-attenders (2) in each school

# make the data
school <- gl(10, 10)
attend <- gl(2, 5, 100)
# creates an interaction with schools 6 and 7
y <- c(sample(seq(450, 650, 1), 50), rep(c(rep(650, 5), rep(450, 5)), 2),
 	sample(seq(450, 650, 1), 30))

# anova
summary(aov(y ~ school * attend))

# graphically
Means <- tapply(y, list(school, attend), mean)

plot(Means[,1], col="red", type = "l", ylim = c(400,700))

points(Means[,2], col="blue", type = "l")

# create contrasts for hypothesis of interest
# school i attend j - school i attend j'
# for all schools
sxa <- interaction(school, attend)
sxam <- as.matrix(rbind(diag(1,10), diag(1,10) * -1))
contrasts(sxa) <- sxam

summary(aov(y ~ sxa), split=list(sxa=1:10), expand.split = T)

The actual problem has a few more schools, other covariates, considerably 
more students, and is somewhat unbalanced.

Thanks,

Scot


--
   Scot W. McNary  email:smcnary at charm.net



From spencer.graves at pdf.com  Thu Aug 25 06:08:28 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 24 Aug 2005 21:08:28 -0700
Subject: [R] GLM/GAM and unobserved heterogeneity
In-Reply-To: <BAY18-DAV4E71519013DAE6BA0B901B5B30@phx.gbl>
References: <BAY18-DAV114E679DBFD7FFBBFDDA06B5C80@phx.gbl>
	<BAY18-DAV4E71519013DAE6BA0B901B5B30@phx.gbl>
Message-ID: <430D443C.3070204@pdf.com>

	  Have you considered "lmer" in library(lme4)?  See for example sec/ 4 
pm "Two-level models for binary data" in vignette("MlmSoftRev") wiht 
library(mlmRev) in addition to www.r-project.org -> "Documentation: 
Newsletter" -> "R News Volume 5/1" -> "Fitting Linear Mixed Models in R" 
by Doug Bates, pp. 27-30.

	  If you have more questions after reviewing this material please 
submit another question, preferably following the posting guide! 
"http://www.R-project.org/posting-guide.html".  The posting guide is not 
just another symbol of burocracy.  It was written to try to help 
questioners improve the chances that they will get the information they 
want quickly.  I believe it is quite effective when it is used.  Many 
people get answers to their questions in minutes, but that requires a 
question that a potential respondent can understand and formulate a 
sensible answer in seconds.

	  spencer graves

Kyle G. Lundstedt wrote:

> Hello,
>      I'm interested in correcting for and measuring unobserved  
> heterogeneity ("missing variables") using R.  In particular, I'm  
> searching for a simple way to measure the amount of unobserved  
> heterogeneity remaining in a series of increasingly complex models  
> (adding additional variables to each new model) on the same data.
>      I have a static database of 400,000 or so individual mortgage  
> loans, each of which is observed monthly from origination (t=0) until  
> termination (a binary yes/no variable).  In my update database, there  
> are up to 60 months of observed data for each loan in the static  
> database, and an individual loan has an "average life" of roughly 36  
> months.
>      Each loan has static covariates observed at origination, such as  
> original loan amount and credit score, as well as time-varying  
> covariates (TVC) such as age, interest rates, and house prices.   
> Because these TVC change each month, I've constructed a modeling  
> database that merges the static database with the update database.
>      The resulting "loan-month" modeling database has one observation  
> for every loan-month, and the static covariates remain the same for  
> all loan-months for a given loan.  Thus, the modeling database has  
> roughly 14.4 million loan-month records.  A loan is considered  
> "active" as long as it has not yet terminated or been censored; my  
> interest is in predicting termination.
>      This type of data is often referred to as "event history" or  
> "discrete hazard" data.  The standard R package to apply to such data  
> is "survival", with which I could estimate a Cox proportional hazard  
> model using coxph.  The advantage of such an approach is that  
> unobserved heterogeneity is easily addressed using the "frailty" term.
>      The disadvantages, at least for my purposes, are two-fold.   
> First, my audience is unfamiliar with hazard models.  Second, my  
> monthly data has many "ties" (many terminations in the same month),  
> so I've been told that coxph won't work well on a large dataset with  
> many ties.
>      On the other hand, because the data is measured discretely each  
> month, many references suggest applying generalized linear models  
> (GLM, "logit"-type models) or even generalized addivitive models  
> (GAM, "logit"-type models that incorporate nonlinearity in individual  
> covariates).  The advantage to this approach is that GLM and GAM are  
> readily available in R, and my audience is very familiar with logit- 
> type models.
>      The disadvantage, however, is that I am totally unfamiliar with  
> ways to correct for and measure unobserved heterogeneity using GLM/ 
> GAM-type models.  I've been told that unobserved heterogeneity in the  
> hazard framework is analogous to random effects in the GLM/GAM  
> framework, but there seem to be a number of R packages that address  
> this issue in different ways.
>      So, I'd greatly appreciate suggestions on a simple way to  
> incorporate unobserved heterogeneity into a GLM/GAM-type model.  I'm  
> not much of a statistician, so simple examples are always helpful.   
> I'm also happy to track down specific article/book references, if  
> folks think those might be of help.
> 
> Many thanks,
> Kyle
> ---
> kyle  at  hotmail . com
> (email altered in obvious ways)
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From spencer.graves at pdf.com  Thu Aug 25 06:18:48 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Wed, 24 Aug 2005 21:18:48 -0700
Subject: [R] How to do log normal regression?
In-Reply-To: <20050818154207.70692.qmail@web31012.mail.mud.yahoo.com>
References: <20050818154207.70692.qmail@web31012.mail.mud.yahoo.com>
Message-ID: <430D46A8.1000707@pdf.com>

	  1.  Have you considered "nls" or "optim"?  The documentation for both 
includes useful examples.

	  2.  What do your Y values represent?  The almost universal standard 
today is maximum likelihood estimation.  If you tell us what the Y 
values are, someone might help you write a likelihood function that 
could then be maximized using "optim".

	  3.  I notice this is the third post I've answered for you in the past 
month.  I've been so busy recently, I tend to limit myself only to posts 
that are several days old for which I have not seen a reply.  I believe 
you might get quicker and more useful replies to your questions if you 
please read and try to follow the posting guide! 
"http://www.R-project.org/posting-guide.html".

	  Good luck.
	  spencer graves

Haibo Huang wrote:

> I want to fit a Log-Normal CDF function between two
> variables, and estimate the parameters. Is there any
> package/functions designed for this purpose? 
> 
> Basically, I have data for Y and X, and I suspect the
> relationship between Y and X is Y = CDF Log-Normal
> (X), and I want to run this regression to verify this
> and estimate the parameters. Anyone has any thoughts?
> 
> Any input is valuable to me, so please do not hesitate
> to share your thoughts. Thank you!
> 
> Ed.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From gblevins at marketsolutionsgroup.com  Thu Aug 25 06:57:03 2005
From: gblevins at marketsolutionsgroup.com (Greg Blevins)
Date: Wed, 24 Aug 2005 23:57:03 -0500
Subject: [R] Attempting to recode elements contained in a list
Message-ID: <s30d095d.031@mail.marketsolutionsgroup.com>

Hello R-Masters,

I have a list 's' with three elements, as shown below.  I want to recode a.a,  a.a2, and a.a3 to NA if the value in a.a is less than 3.  

I reivewed my Modern Applied Statistic Book, the online help and did some searching of R-help on the internet. I explored unlist and as.list.data.frame in an attempt to isolate the third element of the list s, but this was not helpful. Any help would be appreciated.

> dim(s)
[1] 342   3
> names(s)
[1] "scan" "time" "a"

> s
                  scan               time a.a a.a2 a.a3
202       Plastic lids       Plastic lids NaN  NaN  NaN
195       Plastic lids      Cookware lids  44   31   58
205       Plastic lids  Seasoning packets   9    4   20
191       Plastic lids      Baking sheets  15    7   27
209       Plastic lids           Utensils   9    4   20
194       Plastic lids        Cell phones   0    0    7
193       Plastic lids       Canned goods   0    0    7
197       Plastic lids    Hand/dish towel   3    0   12

Thank you.

Greg Blevins
The Market Solutions Group

Windows xp, 2.1.1

Gregory L. Blevins
Vice President, Partner
The Market Solutions Group, Inc.
gblevins at marketsolutionsgroup.com
Office phone: 612 392-3163
Cell phone: 612 251-0232
"What is at the beginning but a small error, swells to huge proportions at the close." Aristotle



From ligges at statistik.uni-dortmund.de  Thu Aug 25 08:21:57 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 25 Aug 2005 08:21:57 +0200
Subject: [R] Packages
In-Reply-To: <430CB7C1.1010102@jhsph.edu>
References: <20050824180152.48649.qmail@web60414.mail.yahoo.com>
	<430CB7C1.1010102@jhsph.edu>
Message-ID: <430D6385.9000909@statistik.uni-dortmund.de>

Roger D. Peng wrote:
> What version of R are you using?  'modreg' no longer exists---its 
> functions have been moved to the 'stats' package.


Let me add that the URL cited below is not an "official" one. Plaese 
take a look at some CRAN mirror close to you.

Uwe Ligges


> -roger
> 
> Amir Safari wrote:
> 
>> 
>> Hi Dear All, I want to instal some packages, but I can not find
>> them in both lists of  Package Index in internet (
>> http://www.maths.lth.se/help/R/.R/doc/html/packages.html ) and of
>> Instalation of Packages window in the softwar. For example
>> "modreg". Are they  included in larger packages ? Thanks for your
>> help. Best Regards, Amir Safari
>> 
>> __________________________________________________
>> 
>> 
>> 
>> [[alternative HTML version deleted]]
>> 
>> ______________________________________________ 
>> R-help at stat.math.ethz.ch mailing list 
>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>> posting guide! http://www.R-project.org/posting-guide.html
>> 
> 
>



From ripley at stats.ox.ac.uk  Thu Aug 25 08:28:11 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 25 Aug 2005 07:28:11 +0100 (BST)
Subject: [R] Attempting to recode elements contained in a list
In-Reply-To: <s30d095d.031@mail.marketsolutionsgroup.com>
References: <s30d095d.031@mail.marketsolutionsgroup.com>
Message-ID: <Pine.LNX.4.61.0508250715410.8123@gannet.stats>

On Wed, 24 Aug 2005, Greg Blevins wrote:

> Hello R-Masters,
>
> I have a list 's' with three elements, as shown below.  I want to recode 
> a.a, a.a2, and a.a3 to NA if the value in a.a is less than 3.

I think s is a data frame, and you are looking at its printout.  There is 
almost certainly no element a.a.  Rather, the data frame has a column a, 
which is probably a matrix with three columns, a, a2 and a3. Use str(s) to 
be sure.  Here is an attempt to create a similar object

> s <- data.frame(scan=letters[1:3], time=LETTERS[1:3])
> s$a <- array(runif(9)*6, dim=c(3,3), dimnames=list(NULL, c("a", "a2", 
"a3")))
> s
   scan time      a.a     a.a2     a.a3
1    a    A 5.435430 1.283933 1.546180
2    b    B 5.169964 2.519836 1.568225
3    c    C 3.844045 2.318089 0.772869

If that is the case, you need

s$a[s$a[, "a"] < 3, ] <- NA


> I reivewed my Modern Applied Statistic Book, the online help and did 
> some searching of R-help on the internet. I explored unlist and 
> as.list.data.frame in an attempt to isolate the third element of the 
> list s, but this was not helpful. Any help would be appreciated.
>
>> dim(s)
> [1] 342   3
>> names(s)
> [1] "scan" "time" "a"
>
>> s
>                  scan               time a.a a.a2 a.a3
> 202       Plastic lids       Plastic lids NaN  NaN  NaN
> 195       Plastic lids      Cookware lids  44   31   58
> 205       Plastic lids  Seasoning packets   9    4   20
> 191       Plastic lids      Baking sheets  15    7   27
> 209       Plastic lids           Utensils   9    4   20
> 194       Plastic lids        Cell phones   0    0    7
> 193       Plastic lids       Canned goods   0    0    7
> 197       Plastic lids    Hand/dish towel   3    0   12
>
> Thank you.
>
> Greg Blevins
> The Market Solutions Group
>
> Windows xp, 2.1.1
>
> Gregory L. Blevins
> Vice President, Partner
> The Market Solutions Group, Inc.
> gblevins at marketsolutionsgroup.com
> Office phone: 612 392-3163
> Cell phone: 612 251-0232
> "What is at the beginning but a small error, swells to huge proportions at the close." Aristotle
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From mmiller at nassp.uct.ac.za  Thu Aug 25 09:14:59 2005
From: mmiller at nassp.uct.ac.za (Mark Miller)
Date: Thu, 25 Aug 2005 09:14:59 +0200
Subject: [R] Poisson Distribution fitting
Message-ID: <200508250914.59962.mmiller@nassp.uct.ac.za>

I am trying to fit a number of distributions to a set of data, I have used the 
fitdristr() funtion for most of the distributions, but Poisson is not one of 
the possible distributions. I found somewhee talking about using the gamlss 
package, but have been unable to find it again, any help would be greatly 
appreciated. 

Mark Miller



From ripley at stats.ox.ac.uk  Thu Aug 25 09:56:01 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 25 Aug 2005 08:56:01 +0100 (BST)
Subject: [R] Poisson Distribution fitting
In-Reply-To: <200508250914.59962.mmiller@nassp.uct.ac.za>
References: <200508250914.59962.mmiller@nassp.uct.ac.za>
Message-ID: <Pine.LNX.4.61.0508250850120.27464@gannet.stats>

On Thu, 25 Aug 2005, Mark Miller wrote:

> I am trying to fit a number of distributions to a set of data, I have used the
> fitdristr() funtion for most of the distributions, but Poisson is not one of
> the possible distributions. I found somewhee talking about using the gamlss
> package, but have been unable to find it again, any help would be greatly
> appreciated.

If you mean fitdistr in package MASS, it can be used.  But the mle for a 
Poisson is just the sample mean.

> x <- rpois(250, 2.6)
> mean(x)
[1] 2.62
> fitdistr(x, dpois, list(lambda=2))
     lambda
   2.6203125
  (0.1023841)

You can even find the s.e. via mu/sqrt(n), here
> mean(x)/sqrt(250)
[1] 0.1657033

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From otoomet at ut.ee  Thu Aug 25 10:08:23 2005
From: otoomet at ut.ee (Ott Toomet)
Date: Thu, 25 Aug 2005 11:08:23 +0300
Subject: [R] how to close connections?
Message-ID: <200508250808.j7P88NjZ013699@hugo.obs.ee>

Hi everybody,

I am using gzipped files quite extensively and cannot figure out how I
can close (or reuse) connections.  

Example:

> for(i in 1:300) {cat(i, "\n"); a <- readLines(gzfile("file.gz"), n=1) }
1 
2 
...
46 
47 
Error in gzfile("~/tyyq/andmebaasiq/ETU/ETU1997.tsv.gz") : 
	all connections are in use

To use just gzfile without any open/close should be OK as the help
states:

... In general functions using connections will open them if they are not
open, but then close them again, so to leave a connection open call
open explicitly.

I have also experimented with explicit open/close but without any more
success, though, R claims that the connections will be closed.

Any ideas?  Is it my misunderstanding?  What exactly means a
connection is "in use"?

Thanks in advance,

Ott

> version
         _                
platform i686-pc-linux-gnu
arch     i686             
os       linux-gnu        
system   i686, linux-gnu  
status                    
major    2                
minor    1.1              
year     2005             
month    06               
day      20               
language R                




-- 
Ott Toomet, PhD
Research Fellow

Dept. of Economics
Tartu University
Narva 4 - A123
Tartu 51009
Estonia

otoomet (a) ut ee
ph:  (+372) 7 37 6374
fax: (+372) 7 37 6312
-------------------------------------------

 (o_         (*_         (O_         (o< -!  
//\         //\         //\         //\      
V_/_        V_/_        V_/_        V_/_     
					     
standard    drunken     shocked     noisy    
penguin     penguin     penguin     penguin



From david.whiting at ncl.ac.uk  Thu Aug 25 11:02:19 2005
From: david.whiting at ncl.ac.uk (David Whiting)
Date: Thu, 25 Aug 2005 10:02:19 +0100
Subject: [R] 'splice' two data frames
Message-ID: <430D891B.1080708@ncl.ac.uk>

Hi,

I often need to take columns from two data.frames and 'splice' them
together (alternately taking a column from the first data frame, then
from the second). For example:

x <- table(sample(letters[1:9], 100, replace=TRUE),
           sample(letters[1:4], 100, replace=TRUE))
y <- prop.table(x)

splice <- function (x, y) {
  z <- matrix(rep(NA, (ncol(x) * 2) * nrow(x)), nrow = nrow(x))
  j <- 1
  for (i in seq(1, ncol(z), by = 2)) {
    z[, i] <- x[, j]
    z[, (i + 1)] <- y[, j]
    j <- j + 1
  }
  z <- data.frame(z)
  rownames(z) <- rownames(x)
  z
}

splice(x, y)


Manually using indexing I can do this:

zz <- data.frame(x[, 1], y[, 1], x[, 2], y[, 2], x[, 3], y[, 3], x[, 4],
y[, 4])


I *feel* that it should be possible in R to generate the sequence of
column indexes automatically. I can get close with this:

i <- paste("x[,", 1:ncol(x), "], ",
	   "y[,", 1:ncol(y), "]",
	   collapse=", ")

which creates a string version of what I want, but I am not sure how to
use that with data.frame. FAQ 7.21 ("How can I turn a string into a
variable?") looked promising but I have not been able to apply any of
the suggestions to this problem. I also tried using do.call:

i <- paste("x[,", 1:4, "],", "y[,", 1:4, "]", collapse=",")
i <- gsub("],", "]@", i)  # Create a marker for
i <- strsplit(i, "@")     # strsplit to create a list
do.call(data.frame, i)

and with lapply:

lappy(i, data.frame)

These "did not work" (i.e. they worked as they were designed to and did
not give me the results I am after).

I think I need a nudge or two in the right direction.

Thanks.

Dave

-- 
David Whiting
School of Clinical Medical Sciences, The Medical School
University of Newcastle upon Tyne, NE2 4HH, UK.



From s-plus at wiwi.uni-bielefeld.de  Thu Aug 25 11:26:02 2005
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Thu, 25 Aug 2005 11:26:02 +0200
Subject: [R] 'splice' two data frames
In-Reply-To: <430D891B.1080708@ncl.ac.uk>
References: <430D891B.1080708@ncl.ac.uk>
Message-ID: <430D8EAA.4090008@wiwi.uni-bielefeld.de>

what about:

@
<<*>>=
z<-data.frame(matrix(rbind(x,y),nrow(x),2*ncol(x)))
rownames(z)<-rownames(x)
z
@
output-start
Thu Aug 25 11:24:29 2005
  X1   X2 X3   X4 X5   X6 X7   X8
a  2 0.02  1 0.01  2 0.02  2 0.02
b  3 0.03  0 0.00  4 0.04  3 0.03
c  3 0.03  2 0.02  1 0.01  6 0.06
d  3 0.03  4 0.04  2 0.02  3 0.03
e  4 0.04  1 0.01  4 0.04  2 0.02
f  2 0.02  5 0.05  2 0.02  2 0.02
g  4 0.04  5 0.05  3 0.03  3 0.03
h  3 0.03  3 0.03  5 0.05  4 0.04
i  1 0.01  0 0.00  3 0.03  3 0.03
output-end

Peter Wolf


David Whiting wrote:
>Hi,
>
>I often need to take columns from two data.frames and 'splice' them
>together (alternately taking a column from the first data frame, then
>from the second). For example:
>
>x <- table(sample(letters[1:9], 100, replace=TRUE),
>           sample(letters[1:4], 100, replace=TRUE))
>y <- prop.table(x)
>
>splice <- function (x, y) {
>  z <- matrix(rep(NA, (ncol(x) * 2) * nrow(x)), nrow = nrow(x))
>  j <- 1
>  for (i in seq(1, ncol(z), by = 2)) {
>    z[, i] <- x[, j]
>    z[, (i + 1)] <- y[, j]
>    j <- j + 1
>  }
>  z <- data.frame(z)
>  rownames(z) <- rownames(x)
>  z
>}
>
>splice(x, y)
>
>
>Manually using indexing I can do this:
>
>zz <- data.frame(x[, 1], y[, 1], x[, 2], y[, 2], x[, 3], y[, 3], x[, 4],
>y[, 4])
>
>
>I *feel* that it should be possible in R to generate the sequence of
>column indexes automatically. I can get close with this:
>
>i <- paste("x[,", 1:ncol(x), "], ",
>	   "y[,", 1:ncol(y), "]",
>	   collapse=", ")
>
>which creates a string version of what I want, but I am not sure how to
>use that with data.frame. FAQ 7.21 ("How can I turn a string into a
>variable?") looked promising but I have not been able to apply any of
>the suggestions to this problem. I also tried using do.call:
>
>i <- paste("x[,", 1:4, "],", "y[,", 1:4, "]", collapse=",")
>i <- gsub("],", "]@", i)  # Create a marker for
>i <- strsplit(i, "@")     # strsplit to create a list
>do.call(data.frame, i)
>
>and with lapply:
>
>lappy(i, data.frame)
>
>These "did not work" (i.e. they worked as they were designed to and did
>not give me the results I am after).
>
>I think I need a nudge or two in the right direction.
>
>Thanks.
>
>Dave
>
>



From david.whiting at ncl.ac.uk  Thu Aug 25 11:38:22 2005
From: david.whiting at ncl.ac.uk (David Whiting)
Date: Thu, 25 Aug 2005 10:38:22 +0100
Subject: [R] 'splice' two data frames
In-Reply-To: <430D8EAA.4090008@wiwi.uni-bielefeld.de>
References: <430D891B.1080708@ncl.ac.uk>
	<430D8EAA.4090008@wiwi.uni-bielefeld.de>
Message-ID: <430D918E.7060902@ncl.ac.uk>

Thank you! I think I can simplify the first line further to:

> z<-data.frame(matrix(rbind(x,y),nrow(x)))

i.e. remove 2 * ncol(x)

Thanks.

Dave

Peter Wolf wrote:
> what about:
> 
> @
> <<*>>=
> z<-data.frame(matrix(rbind(x,y),nrow(x),2*ncol(x)))
> rownames(z)<-rownames(x)
> z
> @
> output-start
> Thu Aug 25 11:24:29 2005
>  X1   X2 X3   X4 X5   X6 X7   X8
> a  2 0.02  1 0.01  2 0.02  2 0.02
> b  3 0.03  0 0.00  4 0.04  3 0.03
> c  3 0.03  2 0.02  1 0.01  6 0.06
> d  3 0.03  4 0.04  2 0.02  3 0.03
> e  4 0.04  1 0.01  4 0.04  2 0.02
> f  2 0.02  5 0.05  2 0.02  2 0.02
> g  4 0.04  5 0.05  3 0.03  3 0.03
> h  3 0.03  3 0.03  5 0.05  4 0.04
> i  1 0.01  0 0.00  3 0.03  3 0.03
> output-end
> 
> Peter Wolf

[...]
-- 
David Whiting
School of Clinical Medical Sciences, The Medical School
University of Newcastle upon Tyne, NE2 4HH, UK.



From ripley at stats.ox.ac.uk  Thu Aug 25 11:48:45 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 25 Aug 2005 10:48:45 +0100 (BST)
Subject: [R] how to close connections?
In-Reply-To: <200508250808.j7P88NjZ013699@hugo.obs.ee>
References: <200508250808.j7P88NjZ013699@hugo.obs.ee>
Message-ID: <Pine.LNX.4.61.0508251042070.17184@gannet.stats>

Try this

con <- gzfile("file.gz")
a <- readLines(con, n=1)
showConnections(all=TRUE)
close(con)
showConnections(all=TRUE)

So the connection is opened and closed as it says, but not destroyed.
You do need to call close() explicitly -- from the help file

      'close' closes and destroys a connection.
                     ^^^^^^^^^^^^

There are  'create - open - close - destroy'  states for a connection.


On Thu, 25 Aug 2005, Ott Toomet wrote:

> Hi everybody,
>
> I am using gzipped files quite extensively and cannot figure out how I
> can close (or reuse) connections.
>
> Example:
>
>> for(i in 1:300) {cat(i, "\n"); a <- readLines(gzfile("file.gz"), n=1) }
> 1
> 2
> ...
> 46
> 47
> Error in gzfile("~/tyyq/andmebaasiq/ETU/ETU1997.tsv.gz") :
> 	all connections are in use
>
> To use just gzfile without any open/close should be OK as the help
> states:
>
> ... In general functions using connections will open them if they are not
> open, but then close them again, so to leave a connection open call
> open explicitly.
>
> I have also experimented with explicit open/close but without any more
> success, though, R claims that the connections will be closed.
>
> Any ideas?  Is it my misunderstanding?  What exactly means a
> connection is "in use"?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Thu Aug 25 12:03:57 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 25 Aug 2005 11:03:57 +0100 (BST)
Subject: [R] Poisson Distribution fitting
In-Reply-To: <Pine.LNX.4.61.0508250850120.27464@gannet.stats>
References: <200508250914.59962.mmiller@nassp.uct.ac.za>
	<Pine.LNX.4.61.0508250850120.27464@gannet.stats>
Message-ID: <Pine.LNX.4.61.0508251103160.18846@gannet.stats>

On Thu, 25 Aug 2005, Prof Brian Ripley wrote:

> On Thu, 25 Aug 2005, Mark Miller wrote:
>
>> I am trying to fit a number of distributions to a set of data, I have used 
>> the
>> fitdristr() funtion for most of the distributions, but Poisson is not one 
>> of
>> the possible distributions. I found somewhee talking about using the gamlss
>> package, but have been unable to find it again, any help would be greatly
>> appreciated.
>
> If you mean fitdistr in package MASS, it can be used.  But the mle for a 
> Poisson is just the sample mean.
>
>> x <- rpois(250, 2.6)
>> mean(x)
> [1] 2.62
>> fitdistr(x, dpois, list(lambda=2))
>    lambda
>  2.6203125
> (0.1023841)
>
> You can even find the s.e. via mu/sqrt(n), here
>> mean(x)/sqrt(250)
> [1] 0.1657033

Sorry, sqrt(mu/n).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From berwin at maths.uwa.edu.au  Thu Aug 25 12:18:43 2005
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Thu, 25 Aug 2005 18:18:43 +0800
Subject: [R] lm.ridge
In-Reply-To: <20768.170.155.1.10.1124893780.squirrel@www.sintesys.com.ar>
References: <20768.170.155.1.10.1124893780.squirrel@www.sintesys.com.ar>
Message-ID: <17165.39683.30764.855464@bossiaea.maths.uwa.edu.au>

G'day Daniel,

>>>>> "DR" == daniel  <daniel at sintesys.com.ar> writes:

    DR> First: I think coefficients from lm(Employed~.,data=longley)
    DR> should be equal coefficients from
    DR> lm.ridge(Employed~.,data=longley, lambda=0) why it does not
    DR> happen?
Which version of R and which version of MASS are you using?

> lm(Employed~.,data=longley)

Call:
lm(formula = Employed ~ ., data = longley)

Coefficients:
 (Intercept)  GNP.deflator           GNP    Unemployed  Armed.Forces  
  -3.482e+03     1.506e-02    -3.582e-02    -2.020e-02    -1.033e-02  
  Population          Year  
  -5.110e-02     1.829e+00  

> lm.ridge(Employed~.,data=longley, lambda=0)
               GNP.deflator           GNP    Unemployed  Armed.Forces 
-3.482259e+03  1.506187e-02 -3.581918e-02 -2.020230e-02 -1.033227e-02 
   Population          Year 
-5.110411e-02  1.829151e+00 


These coefficients look pretty identical to me, except that they are
printed to different numbers of significant digits.

In fact, the following shows that they are identical (upto numerical
precision): 

> fm1 <- lm(Employed~.,data=longley)
> fm2 <- lm.ridge(Employed~.,data=longley, lambda=0)
> coef2 <- print(fm2)
               GNP.deflator           GNP    Unemployed  Armed.Forces 
-3.482259e+03  1.506187e-02 -3.581918e-02 -2.020230e-02 -1.033227e-02 
   Population          Year 
-5.110411e-02  1.829151e+00 
> max(abs(coef(fm1)-coef2))
[1] 7.275958e-12


    DR> Second: if I have for example Ridge<-lm.ridge(Employed~.,
    DR> data=longley, lambda = seq(0,0.1,0.001)), I suppose intercept
    DR> coefficient is defined implicit,
Yes.

    DR> why it does not appear in Ridge$coef?
If you look at the code of lm.ridge, you will see that, if an
intercept is included in the model, all non-constant regressors are
centered (i.e. made orthogonal to the intercept term) and scaled to
have the same variance.  Further more, the intercept term is typically
*not* penalised.  The components in Ridge$coef are the coefficients on
this transformed scale.  No need of including the intercept here,
since it is the same for all values of lambda.  If you print the
model, then the ridge coefficients on the original scale are
calculated, see:

> getAnywhere("print.ridgelm")
A single object matching 'print.ridgelm' was found
It was found in the following places
  registered S3 method for print from namespace MASS
  namespace:MASS
with value

function (x, ...) 
{
    scaledcoef <- t(as.matrix(x$coef/x$scales))
    if (x$Inter) {
        inter <- x$ym - scaledcoef %*% x$xm
        scaledcoef <- cbind(Intercept = inter, scaledcoef)
    }
    print(drop(scaledcoef), ...)
}
<environment: namespace:MASS>

    DR> Third: I suppose that if I define
    DR> 1) y<-longley$Employed
    DR> 2) X<-as.matrix(cbind(1,Longley[,1:6])
    DR> 3) I = identity matrix the

    DR> following should be true: Coef=(X'X+kI)^(-1) X'y
No, as noted above, the intercept term is usually not penalised.

    DR> and if a take k=Ridge$kHKV, Coef should be approx equal to
    DR> Ridge$Coef[near value of kHKV]
No, as noted above the estimates in the "coef" component of an object
returned by lm.ridge are the coefficients on a different scale.

    DR> and it does not seem to happen, why?
Because the intercept is not penalised by lm.ridge and the
non-constant columns of the design matrix are rescaled; hence the
returned coefficients are on another scale.

    DR> Any help, suggestion or orientation?
HTH.

Cheers,

        Berwin



From snvk4u at gmail.com  Thu Aug 25 13:00:42 2005
From: snvk4u at gmail.com (Krishna)
Date: Thu, 25 Aug 2005 16:30:42 +0530
Subject: [R] problem with read.table
Message-ID: <139ef1c205082504001dc3ffc6@mail.gmail.com>

Hi All

recently i faced an unknown problem while reading the data. Can
someone help me in understanding why this happened.

I have .txt file containing X, Y, Z variables. I used the command 

> a <- read.table("filename", header=TRUE)
after reading the file i am able to view it by tryping a. but i am
unable to access the variables in a, by giving the command a$X.

> a$X
> NULL

this is the output it was showing. However the same i am able to
access by giving a[[1]]. i tried changing the mode by issuing command
a <- as.data.frame(a). But situation remains the same.

look forward for experts suggestion on this.

rgds

snvk



From Matthias.Templ at statistik.gv.at  Thu Aug 25 13:15:27 2005
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Thu, 25 Aug 2005 13:15:27 +0200
Subject: [R] problem with read.table
Message-ID: <83536658864BC243BE3C06D7E936ABD5027BABAB@xchg1.statistik.local>

> Hi All
> 
> recently i faced an unknown problem while reading the data. 
> Can someone help me in understanding why this happened.
> 
> I have .txt file containing X, Y, Z variables. I used the command 

Please show at least 2 lines of your data.

> 
> > a <- read.table("filename", header=TRUE)

Are you sure, that a looks correct? (= have you set the correct
seperator in read.table with option sep= )

Best regards,
Matthias

> after reading the file i am able to view it by tryping a. but 
> i am unable to access the variables in a, by giving the command a$X.
> 
> > a$X
> > NULL
> 
> this is the output it was showing. However the same i am able 
> to access by giving a[[1]]. i tried changing the mode by 
> issuing command a <- as.data.frame(a). But situation remains the same.
> 
> look forward for experts suggestion on this.
> 
> rgds
> 
> snvk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read 
> the posting guide! http://www.R-project.org/posting-guide.html
>



From fred at poleto.com  Thu Aug 25 13:25:22 2005
From: fred at poleto.com (Frederico Zanqueta Poleto)
Date: Thu, 25 Aug 2005 08:25:22 -0300
Subject: [R] How to do log normal regression?
In-Reply-To: <430D46A8.1000707@pdf.com>
References: <430D46A8.1000707@pdf.com>
Message-ID: <20050825112522.11759.qmail@hm47.locaweb.com.br>

A very simple and useful relation between the normal and log-normal distributions is that if log(Y) follows the normal distribution, then Y follows the log-normal distribution, and vice-versa.

Then, if you want to do a log-normal regression, you can take the natural logarithm of your data and do a normal regression.

Take a look on any book about statistical distributions, e.g. the one from Evans, Hastings and Peacock or Johnson and Kotz or Patel, Kapadia and Owen,  because I am not so sure, but I think the exponential of the fitted values will be the estimated median of the log-normal distribution.

Regards,
--
Frederico Zanqueta Poleto
fred at poleto.com
--
"All knowledge is, in final analysis, History. All sciences are, in the abstract, Mathematics. All judgements are, in their rationale, Statistics." Radhakrishna Rao


------------- Segue mensagem original! -------------

De: Spencer Graves <spencer.graves at pdf.com>
Data: Wed, 24 Aug 2005 21:18:48 -0700
Para: Haibo Huang <edhuang00 at yahoo.com>
Assunto: Re: [R] How to do log normal regression?

	  1.  Have you considered "nls" or "optim"?  The documentation for both 
includes useful examples.

	  2.  What do your Y values represent?  The almost universal standard 
today is maximum likelihood estimation.  If you tell us what the Y 
values are, someone might help you write a likelihood function that 
could then be maximized using "optim".

	  3.  I notice this is the third post I've answered for you in the past 
month.  I've been so busy recently, I tend to limit myself only to posts 
that are several days old for which I have not seen a reply.  I believe 
you might get quicker and more useful replies to your questions if you 
please read and try to follow the posting guide! 
"http://www.R-project.org/posting-guide.html".

	  Good luck.
	  spencer graves

Haibo Huang wrote:

> I want to fit a Log-Normal CDF function between two
> variables, and estimate the parameters. Is there any
> package/functions designed for this purpose? 
> 
> Basically, I have data for Y and X, and I suspect the
> relationship between Y and X is Y = CDF Log-Normal
> (X), and I want to run this regression to verify this
> and estimate the parameters. Anyone has any thoughts?
> 
> Any input is valuable to me, so please do not hesitate
> to share your thoughts. Thank you!
> 
> Ed.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From snvk4u at gmail.com  Thu Aug 25 13:31:01 2005
From: snvk4u at gmail.com (Krishna)
Date: Thu, 25 Aug 2005 17:01:01 +0530
Subject: [R] problem with read.table
In-Reply-To: <430DA9EC.5080105@cc.jyu.fi>
References: <139ef1c205082504001dc3ffc6@mail.gmail.com>
	<430DA9EC.5080105@cc.jyu.fi>
Message-ID: <139ef1c205082504314bcf968c@mail.gmail.com>

Hi  Mr. Pedro

I tried names(a) and it displayed the names as X, Y and Z.

rgds

snvk

On 8/25/05, Pedro J. Aphalo <pedro.aphalo at cc.jyu.fi> wrote:
> Hi,
> 
> Did you try names(a) so see what are the names of the columns in the
> dataframe?
> 
> Hope this helps a little.
> 
> Pedro.
> 
> Krishna wrote:
> > Hi All
> >
> > recently i faced an unknown problem while reading the data. Can
> > someone help me in understanding why this happened.
> >
> > I have .txt file containing X, Y, Z variables. I used the command
> >
> >
> >>a <- read.table("filename", header=TRUE)
> >
> > after reading the file i am able to view it by tryping a. but i am
> > unable to access the variables in a, by giving the command a$X.
> >
> >
> >>a$X
> >>NULL
> >
> >
> > this is the output it was showing. However the same i am able to
> > access by giving a[[1]]. i tried changing the mode by issuing command
> > a <- as.data.frame(a). But situation remains the same.
> >
> > look forward for experts suggestion on this.
> >
> > rgds
> >
> > snvk
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 
> --
> ==================================================================
> Pedro J. Aphalo
> Department of Biological and Environmental Science
> University of Jyv??skyl??
> P.O. Box 35, 40351 JYV??SKYL??, Finland
> Phone  +358 14 260 2339
> Mobile +358 50 3721504
> Fax    +358 14 260 2321
> mailto:pedro.aphalo at cc.jyu.fi
> http://www.jyu.fi/~aphalo/                       ,,,^..^,,,
> ==================================================================
> 
>



From snvk4u at gmail.com  Thu Aug 25 13:36:05 2005
From: snvk4u at gmail.com (Krishna)
Date: Thu, 25 Aug 2005 17:06:05 +0530
Subject: [R] correlation by subset
In-Reply-To: <139ef1c205082406144083ac48@mail.gmail.com>
References: <139ef1c205082404173942d3c0@mail.gmail.com>
	<430C6294.9080309@optonline.net>
	<139ef1c205082406144083ac48@mail.gmail.com>
Message-ID: <139ef1c2050825043636134c88@mail.gmail.com>

Hi Mr. Cleland

it worked excellently well, and i believe the same logic or function
by() can be used even for running regressions on subsets of huge
datasets. correct me if iam wrong

thank you for the help

rgds

snvk

On 8/24/05, Krishna <snvk4u at gmail.com> wrote:
> Hi Mr. Cleland
> 
> Could you please detail the function.
> 
> Thanks and best regards
> 
> snvk
> 
> On 8/24/05, Chuck Cleland <ccleland at optonline.net> wrote:
> > by(mydata, mydata$GROUPING, function(x) cor(x$x, x$y, use="pair"))
> >
> > ?by
> >
> > Krishna wrote:
> > > Hi all
> > >
> > > Having searched the available documentation on R, I request for help
> > > in sorting out the underlying problem.
> > >
> > > I have a huge dataset containing 2 variables x and y, which is a daily
> > > price series.
> > >
> > > I would like to observe the quarterly correlations among these two
> > > variables. Is there anyway where i can calculate cor.coeff by using a
> > > grouping variable in R.
> > >
> > > thanks in advance for the help
> > >
> > > rgds
> > >
> > > snvk
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > >
> >
> > --
> > Chuck Cleland, Ph.D.
> > NDRI, Inc.
> > 71 West 23rd Street, 8th floor
> > New York, NY 10010
> > tel: (212) 845-4495 (Tu, Th)
> > tel: (732) 452-1424 (M, W, F)
> > fax: (917) 438-0894
> >
>



From ccleland at optonline.net  Thu Aug 25 13:44:26 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Thu, 25 Aug 2005 07:44:26 -0400
Subject: [R] correlation by subset
In-Reply-To: <139ef1c2050825043636134c88@mail.gmail.com>
References: <139ef1c205082404173942d3c0@mail.gmail.com>
	<430C6294.9080309@optonline.net>
	<139ef1c205082406144083ac48@mail.gmail.com>
	<139ef1c2050825043636134c88@mail.gmail.com>
Message-ID: <430DAF1A.30207@optonline.net>

Krishna wrote:
> Hi Mr. Cleland
> 
> it worked excellently well, and i believe the same logic or function
> by() can be used even for running regressions on subsets of huge
> datasets. correct me if iam wrong

   Yes.  For example, the FUN argument to by() can be a summary of a 
linear model:

by(warpbreaks, warpbreaks$tension, function(x) summary(lm(breaks ~ wool, 
data=x)))

> thank you for the help
> 
> rgds
> 
> snvk
> 
> On 8/24/05, Krishna <snvk4u at gmail.com> wrote:
> 
>>Hi Mr. Cleland
>>
>>Could you please detail the function.
>>
>>Thanks and best regards
>>
>>snvk
>>
>>On 8/24/05, Chuck Cleland <ccleland at optonline.net> wrote:
>>
>>>by(mydata, mydata$GROUPING, function(x) cor(x$x, x$y, use="pair"))
>>>
>>>?by
>>>
>>>Krishna wrote:
>>>
>>>>Hi all
>>>>
>>>>Having searched the available documentation on R, I request for help
>>>>in sorting out the underlying problem.
>>>>
>>>>I have a huge dataset containing 2 variables x and y, which is a daily
>>>>price series.
>>>>
>>>>I would like to observe the quarterly correlations among these two
>>>>variables. Is there anyway where i can calculate cor.coeff by using a
>>>>grouping variable in R.
>>>>
>>>>thanks in advance for the help
>>>>
>>>>rgds
>>>>
>>>>snvk
>>>>
>>>>______________________________________________
>>>>R-help at stat.math.ethz.ch mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>>
>>>
>>>--
>>>Chuck Cleland, Ph.D.
>>>NDRI, Inc.
>>>71 West 23rd Street, 8th floor
>>>New York, NY 10010
>>>tel: (212) 845-4495 (Tu, Th)
>>>tel: (732) 452-1424 (M, W, F)
>>>fax: (917) 438-0894
>>>
>>
> 
> 

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From bob.ohara at helsinki.fi  Thu Aug 25 13:45:46 2005
From: bob.ohara at helsinki.fi (Anon.)
Date: Thu, 25 Aug 2005 14:45:46 +0300
Subject: [R] Converting characters to numbers in data frames
Message-ID: <430DAF6A.60301@helsinki.fi>

I'm sure I'm missing something obvious here, but I can't find the 
solution (including in the FAQ etc.).

I have a vector of names of variables like this: NRes.x.y. where x and y 
are numbers.  I want to extract these numbers as numbers to use 
elsewhere.  I can extract the numbers as a list of characters using 
strsplit(), and convert that to a data frame, e.g.:

NAMES=c("NRes.1.2.", "NRes.1.3.", "NRes.1.4.", "NRes.1.5.", "NRes.1.6.")
NUMBERS=strsplit(gsub("NRes.","", NAMES, perl =T), '.', fixed = TRUE)
NUMBERS.df=t(data.frame(NUMBERS))

But I now want to convert the characters to be numeric.  Using 
as.numeric(NUMBERS.df) converts them, but to a vector.  How can I 
convert and keep as a data frame?  I could use this:

matrix(as.numeric(NUMBERS.df), ncol=dim(NUMBERS.df)[2])

but I seem to be jumping through far too many hoops: there must be an 
easier way.  An suggestions?

Bob

-- 
Bob O'Hara
Department of Mathematics and Statistics
P.O. Box 68 (Gustaf H??llstr??min katu 2b)
FIN-00014 University of Helsinki
Finland

Telephone: +358-9-191 51479
Mobile: +358 50 599 0540
Fax:  +358-9-191 51400
WWW:  http://www.RNI.Helsinki.FI/~boh/
Journal of Negative Results - EEB: www.jnr-eeb.org



From ernesto at ipimar.pt  Thu Aug 25 13:47:17 2005
From: ernesto at ipimar.pt (ernesto)
Date: Thu, 25 Aug 2005 12:47:17 +0100
Subject: [R] Code in lattice::dotplot function.
Message-ID: <430DAFC5.50700@ipimar.pt>

Hi,

I'm trying to understand the code of lattice functions so that I can
write some S4 methods using lattice. The following code is a snipet of
dotplot that is reused in several other functions. I don't understand
why this is needed can someone help ?

Thanks

EJ

[...]

    right.name <- deparse(substitute(formula))
    try(formula <- eval(formula), silent = TRUE)
    foo <- substitute(formula)

    if (!(is.call(foo) && foo[[1]] == "~")) {
        formula <- as.formula(paste("~", right.name)) #   deparse(foo)))
        environment(formula) <- parent.frame()
    }

[...]



From selimy at anadolu.edu.tr  Thu Aug 25 12:52:28 2005
From: selimy at anadolu.edu.tr (SELIM YILDIRIM)
Date: Thu, 25 Aug 2005 11:52:28 +0100
Subject: [R] concerning econometrics usage of "R"
Message-ID: <web-55420228@anadolu.edu.tr>

Hi, 

I am currently looking for a program or programmng language easy to
learn, easier to operate on.I heva heard about "R", However I
understand that "R" is designed especially for statisticians. As an
economist, working on applied econometrics, I am not sure if it can
meet my needs.

Will I be able to reach precise time series or panal data regression
results with "R" ? Can "R" regress nonlinear models such as TAR, STAR
and Markov Switcing models? Can I use it to do cointegration, unit
root, VAR analysis on both panel and time series data? Can I run GMM
regressions on "R" ? Is it suitable for Monte Carlos? 

In short, is R suitable for applied econometrics?



From sundar.dorai-raj at pdf.com  Thu Aug 25 14:08:35 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Thu, 25 Aug 2005 07:08:35 -0500
Subject: [R] Converting characters to numbers in data frames
In-Reply-To: <430DAF6A.60301@helsinki.fi>
References: <430DAF6A.60301@helsinki.fi>
Message-ID: <430DB4C3.1030907@pdf.com>



Anon. wrote:
> I'm sure I'm missing something obvious here, but I can't find the 
> solution (including in the FAQ etc.).
> 
> I have a vector of names of variables like this: NRes.x.y. where x and y 
> are numbers.  I want to extract these numbers as numbers to use 
> elsewhere.  I can extract the numbers as a list of characters using 
> strsplit(), and convert that to a data frame, e.g.:
> 
> NAMES=c("NRes.1.2.", "NRes.1.3.", "NRes.1.4.", "NRes.1.5.", "NRes.1.6.")
> NUMBERS=strsplit(gsub("NRes.","", NAMES, perl =T), '.', fixed = TRUE)
> NUMBERS.df=t(data.frame(NUMBERS))
> 
> But I now want to convert the characters to be numeric.  Using 
> as.numeric(NUMBERS.df) converts them, but to a vector.  How can I 
> convert and keep as a data frame?  I could use this:
> 
> matrix(as.numeric(NUMBERS.df), ncol=dim(NUMBERS.df)[2])
> 
> but I seem to be jumping through far too many hoops: there must be an 
> easier way.  An suggestions?
> 
> Bob
> 


How about this?

NUMBERS <- lapply(strsplit(NAMES, "\\."), "[", -1)
as.data.frame(do.call("rbind", lapply(NUMBERS, as.numeric)))

--sundar



From s-plus at wiwi.uni-bielefeld.de  Thu Aug 25 14:10:34 2005
From: s-plus at wiwi.uni-bielefeld.de (Peter Wolf)
Date: Thu, 25 Aug 2005 14:10:34 +0200
Subject: [R] Converting characters to numbers in data frames
In-Reply-To: <430DAF6A.60301@helsinki.fi>
References: <430DAF6A.60301@helsinki.fi>
Message-ID: <430DB53A.3090804@wiwi.uni-bielefeld.de>

Try:

NAMES=c("NRes.1.2.", "NRes.1.3.", "NRes.1.4.", "NRes.1.5.", "NRes.1.6.")
pattern<-"NRes\.([0-9]*)\.([0-9]*)\."
data.frame(x=sub(pattern,"\\1",NAMES),y=sub(pattern,"\\2",NAMES))

@
output-start
Thu Aug 25 14:08:50 2005
  x y
1 1 2
2 1 3
3 1 4
4 1 5
5 1 6
output-end

Peter Wolf

Anon. wrote:
>I'm sure I'm missing something obvious here, but I can't find the 
>solution (including in the FAQ etc.).
>
>I have a vector of names of variables like this: NRes.x.y. where x and y 
>are numbers.  I want to extract these numbers as numbers to use 
>elsewhere.  I can extract the numbers as a list of characters using 
>strsplit(), and convert that to a data frame, e.g.:
>
>NAMES=c("NRes.1.2.", "NRes.1.3.", "NRes.1.4.", "NRes.1.5.", "NRes.1.6.")
>NUMBERS=strsplit(gsub("NRes.","", NAMES, perl =T), '.', fixed = TRUE)
>NUMBERS.df=t(data.frame(NUMBERS))
>
>But I now want to convert the characters to be numeric.  Using 
>as.numeric(NUMBERS.df) converts them, but to a vector.  How can I 
>convert and keep as a data frame?  I could use this:
>
>matrix(as.numeric(NUMBERS.df), ncol=dim(NUMBERS.df)[2])
>
>but I seem to be jumping through far too many hoops: there must be an 
>easier way.  An suggestions?
>
>Bob
>
>



From vincent at 7d4.com  Thu Aug 25 14:15:24 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Thu, 25 Aug 2005 14:15:24 +0200
Subject: [R] problem with read.table
In-Reply-To: <139ef1c205082504001dc3ffc6@mail.gmail.com>
References: <139ef1c205082504001dc3ffc6@mail.gmail.com>
Message-ID: <430DB65C.40203@7d4.com>

Krishna a ??crit :

> unable to access the variables in a, by giving the command a$X.

try a$V1 or a[1] or a[,1] or a$V2 etc
hih



From ggrothendieck at gmail.com  Thu Aug 25 14:36:47 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 25 Aug 2005 08:36:47 -0400
Subject: [R] Converting characters to numbers in data frames
In-Reply-To: <430DAF6A.60301@helsinki.fi>
References: <430DAF6A.60301@helsinki.fi>
Message-ID: <971536df050825053660c4d49a@mail.gmail.com>

On 8/25/05, Anon. <bob.ohara at helsinki.fi> wrote:
> I'm sure I'm missing something obvious here, but I can't find the
> solution (including in the FAQ etc.).
> 
> I have a vector of names of variables like this: NRes.x.y. where x and y
> are numbers.  I want to extract these numbers as numbers to use
> elsewhere.  I can extract the numbers as a list of characters using
> strsplit(), and convert that to a data frame, e.g.:
> 
> NAMES=c("NRes.1.2.", "NRes.1.3.", "NRes.1.4.", "NRes.1.5.", "NRes.1.6.")
> NUMBERS=strsplit(gsub("NRes.","", NAMES, perl =T), '.', fixed = TRUE)
> NUMBERS.df=t(data.frame(NUMBERS))
> 
> But I now want to convert the characters to be numeric.  Using
> as.numeric(NUMBERS.df) converts them, but to a vector.  How can I
> convert and keep as a data frame?  I could use this:
> 
> matrix(as.numeric(NUMBERS.df), ncol=dim(NUMBERS.df)[2])
> 
> but I seem to be jumping through far too many hoops: there must be an
> easier way.  An suggestions?


Try this:

   read.table(textConnection(NAMES), sep = ".")[,2:3]

You may also want to add the col.names= argument to the read.table call
if you want prettier column names.  Also I think Names and Numbers would
be sufficient to distinguish them from potential lower case counterparts.



From justin_bem at yahoo.fr  Wed Aug 24 20:11:32 2005
From: justin_bem at yahoo.fr (justin bem)
Date: Wed, 24 Aug 2005 20:11:32 +0200 (CEST)
Subject: [R] Re :  Packages
Message-ID: <20050824181133.22742.qmail@web25707.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050824/6944ccc2/attachment.pl

From justin_bem at yahoo.fr  Wed Aug 24 20:14:05 2005
From: justin_bem at yahoo.fr (justin bem)
Date: Wed, 24 Aug 2005 20:14:05 +0200 (CEST)
Subject: [R] Call SAS from R
Message-ID: <20050824181406.3797.qmail@web25706.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050824/1db4285e/attachment.pl

From snvk4u at gmail.com  Thu Aug 25 14:43:27 2005
From: snvk4u at gmail.com (Krishna)
Date: Thu, 25 Aug 2005 18:13:27 +0530
Subject: [R] help on retrieving output from by( ) for regression
Message-ID: <139ef1c20508250543788f3439@mail.gmail.com>

Hi all 

I used a function 
> qtrregr <- by(AB, AB$qtr, function(AB) lm(AB$X~AB$Y))

objective is to run a regression on quartery subsets in the data set
AB, having variables X and Y, grouped by variable qtr.

Now i retrieved the output using qtrregr, however it only showed the
coefficients (intercept and B) with out significant levels and
residuals for each qtr. Can some on help me on how can retrieve the
detailed regression output.

rgds

snvk



From ligges at statistik.uni-dortmund.de  Thu Aug 25 14:54:26 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Thu, 25 Aug 2005 14:54:26 +0200
Subject: [R] Re :  Packages
In-Reply-To: <20050824181133.22742.qmail@web25707.mail.ukl.yahoo.com>
References: <20050824181133.22742.qmail@web25707.mail.ukl.yahoo.com>
Message-ID: <430DBF82.8090803@statistik.uni-dortmund.de>

justin bem wrote:

> Hi !
>  
> I got the same problem. I use R itself to install those package I got them.
> Try this It may work !


If you reply to a question posted on R-help, please
a) include the original question in your reply, others probably forgot 
the original question;
b) reply to the poster who might not be subscribed on the list.

Thanks,
Uwe Ligges



> Sincerly !
> 
> 		
> ---------------------------------
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From Matthias.Templ at statistik.gv.at  Thu Aug 25 14:57:16 2005
From: Matthias.Templ at statistik.gv.at (TEMPL Matthias)
Date: Thu, 25 Aug 2005 14:57:16 +0200
Subject: [R] help on retrieving output from by( ) for regression
Message-ID: <83536658864BC243BE3C06D7E936ABD5027BABAC@xchg1.statistik.local>

Look more carefully at 
?lm 
at the See Also section ...

X <- rnorm(30)
Y <- rnorm(30)
lm(Y~X)
summary(lm(Y~X))

Best,
Matthias


> Hi all 
> 
> I used a function 
> > qtrregr <- by(AB, AB$qtr, function(AB) lm(AB$X~AB$Y))
> 
> objective is to run a regression on quartery subsets in the 
> data set AB, having variables X and Y, grouped by variable qtr.
> 
> Now i retrieved the output using qtrregr, however it only 
> showed the coefficients (intercept and B) with out 
> significant levels and residuals for each qtr. Can some on 
> help me on how can retrieve the detailed regression output.
> 
> rgds
> 
> snvk
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read 
> the posting guide! http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Thu Aug 25 15:15:23 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 25 Aug 2005 09:15:23 -0400
Subject: [R] concerning econometrics usage of "R"
In-Reply-To: <web-55420228@anadolu.edu.tr>
References: <web-55420228@anadolu.edu.tr>
Message-ID: <430DC46B.5020105@stats.uwo.ca>

On 8/25/2005 6:52 AM, SELIM YILDIRIM wrote:
> Hi, 
> 
> I am currently looking for a program or programmng language easy to
> learn, easier to operate on.I heva heard about "R", However I
> understand that "R" is designed especially for statisticians. As an
> economist, working on applied econometrics, I am not sure if it can
> meet my needs.
> 
> Will I be able to reach precise time series or panal data regression
> results with "R" ? Can "R" regress nonlinear models such as TAR, STAR
> and Markov Switcing models? Can I use it to do cointegration, unit
> root, VAR analysis on both panel and time series data? Can I run GMM
> regressions on "R" ? Is it suitable for Monte Carlos? 
> 
> In short, is R suitable for applied econometrics?

I'm not an econometrician, so I don't know the answer to that question, 
but you can read about econometrics uses of R in the task view for 
Econometrics, here:

http://cran.r-project.org/src/contrib/Views

Duncan Murdoch



From Achim.Zeileis at wu-wien.ac.at  Thu Aug 25 15:16:30 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 25 Aug 2005 15:16:30 +0200
Subject: [R] concerning econometrics usage of "R"
In-Reply-To: <web-55420228@anadolu.edu.tr>
References: <web-55420228@anadolu.edu.tr>
Message-ID: <20050825151630.5495d2c3.Achim.Zeileis@wu-wien.ac.at>

On Thu, 25 Aug 2005 11:52:28 +0100 SELIM YILDIRIM wrote:

> Hi, 
> 
> I am currently looking for a program or programmng language easy to
> learn, easier to operate on.I heva heard about "R", However I
> understand that "R" is designed especially for statisticians. As an
> economist, working on applied econometrics, I am not sure if it can
> meet my needs.
> 
> Will I be able to reach precise time series or panal data regression
> results with "R" ?

yes

> Can "R" regress nonlinear models such as TAR, STAR
> and Markov Switcing models? Can I use it to do cointegration, unit
> root, VAR analysis on both panel and time series data? Can I run GMM
> regressions on "R" ?

some things yes, other things not out of the box

> Is it suitable for Monte Carlos? 

yes

> In short, is R suitable for applied econometrics?

In principle yes, although not everything you might want to do is
already available in CRAN packages. For an overview of what is currently
available, look at the task view as Duncan already suggested.

Best,
Z



From MSchwartz at mn.rr.com  Thu Aug 25 15:44:13 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Thu, 25 Aug 2005 08:44:13 -0500
Subject: [R] help on retrieving output from by( ) for regression
In-Reply-To: <83536658864BC243BE3C06D7E936ABD5027BABAC@xchg1.statistik.local>
References: <83536658864BC243BE3C06D7E936ABD5027BABAC@xchg1.statistik.local>
Message-ID: <1124977453.4067.20.camel@localhost.localdomain>

Also, looking at the last example in ?by would be helpful:

attach(warpbreaks)
tmp <- by(warpbreaks, tension, function(x) lm(breaks ~ wool, data = x))

# To get coefficients:
sapply(tmp, coef)

# To get residuals:
sapply(tmp, resid)

# To get the model matrix:
sapply(tmp, model.matrix)



To get the summary() output, I suspect that using:

  lapply(tmp, summary)

would yield more familiar output as compared to using:

  sapply(tmp, summary)

The output from the latter might require a bit more "navigation" through
the resultant matrix, depending upon how the output is to be ultimately
used.

HTH,

Marc Schwartz



On Thu, 2005-08-25 at 14:57 +0200, TEMPL Matthias wrote:
> Look more carefully at 
> ?lm 
> at the See Also section ...
> 
> X <- rnorm(30)
> Y <- rnorm(30)
> lm(Y~X)
> summary(lm(Y~X))
> 
> Best,
> Matthias
> 
> 
> > Hi all 
> > 
> > I used a function 
> > > qtrregr <- by(AB, AB$qtr, function(AB) lm(AB$X~AB$Y))
> > 
> > objective is to run a regression on quartery subsets in the 
> > data set AB, having variables X and Y, grouped by variable qtr.
> > 
> > Now i retrieved the output using qtrregr, however it only 
> > showed the coefficients (intercept and B) with out 
> > significant levels and residuals for each qtr. Can some on 
> > help me on how can retrieve the detailed regression output.
> > 
> > rgds
> > 
> > snvk
> >



From philippe.favrot at sti.lu  Thu Aug 25 15:54:56 2005
From: philippe.favrot at sti.lu (Philippe)
Date: Thu, 25 Aug 2005 15:54:56 +0200
Subject: [R] Help about R
Message-ID: <430DCDB0.3050809@sti.lu>

Hello,
My name is Philippe Favrot, I'm a french occupational doctor (working in 
Luxembourg), and I'm an "R beginner".
I would be happy you could help me about the utilization of "R".
Recently, I measured sound levels in a plant. Before the measuring, I 
divided the plant in 3 virtual rows and 8 virtual columns. I measured 
the sound level at each intersection of rows and columns and obtained a 
set of 24 "sound level" values.
I wrote the results in a excel's spreadsheet.
My question is: I know to do import from excel into "R" (with 
read.table()), but how can I draw a three dimensional graphic of the 
plant's sound level ? Can I overlay a map of this factory (as a 
rectangle with a grid representing each spots where I measured )?
I'd understand if you are too busy to reply to my mail.
Thanks.
Best regards
Philippe Favrot



From vincent at 7d4.com  Thu Aug 25 16:06:19 2005
From: vincent at 7d4.com (vincent@7d4.com)
Date: Thu, 25 Aug 2005 16:06:19 +0200
Subject: [R] Help about R
In-Reply-To: <430DCDB0.3050809@sti.lu>
References: <430DCDB0.3050809@sti.lu>
Message-ID: <430DD05B.5070100@7d4.com>

Philippe a ??crit :

> ... how can I draw a three dimensional graphic of the 
> plant's sound level ?

Not an answer, but I find image() very useful
to visualize 3D data simply on a 2D colored image.
hih



From francoisromain at free.fr  Thu Aug 25 16:15:34 2005
From: francoisromain at free.fr (Romain Francois)
Date: Thu, 25 Aug 2005 16:15:34 +0200
Subject: [R] Help about R
In-Reply-To: <430DCDB0.3050809@sti.lu>
References: <430DCDB0.3050809@sti.lu>
Message-ID: <430DD286.7090501@free.fr>

Le 25.08.2005 15:54, Philippe a ??crit :

>Hello,
>My name is Philippe Favrot, I'm a french occupational doctor (working in 
>Luxembourg), and I'm an "R beginner".
>I would be happy you could help me about the utilization of "R".
>Recently, I measured sound levels in a plant. Before the measuring, I 
>divided the plant in 3 virtual rows and 8 virtual columns. I measured 
>the sound level at each intersection of rows and columns and obtained a 
>set of 24 "sound level" values.
>I wrote the results in a excel's spreadsheet.
>My question is: I know to do import from excel into "R" (with 
>read.table()), but how can I draw a three dimensional graphic of the 
>plant's sound level ? Can I overlay a map of this factory (as a 
>rectangle with a grid representing each spots where I measured )?
>I'd understand if you are too busy to reply to my mail.
>Thanks.
>Best regards
>Philippe Favrot
>  
>
Bonjour Philippe,

Have you tried :
** RSiteSearch('3D')
** RSiteSearch('map')
** http://addictedtor.free.fr/graphiques/search.php?q=3D
** http://addictedtor.free.fr/graphiques/search.php?q=map
** http://www.stat.auckland.ac.nz/~paul/RGraphics/rgraphics.html about a 
great book on R graphics (I can't wait to have my copy, just ordered one 
by amazon)

Also, have a look at the package rgl on cran, that's terrific !!

Cheers,

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From macq at llnl.gov  Thu Aug 25 16:49:45 2005
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 25 Aug 2005 07:49:45 -0700
Subject: [R] problem with read.table
In-Reply-To: <139ef1c205082504314bcf968c@mail.gmail.com>
References: <139ef1c205082504001dc3ffc6@mail.gmail.com>
	<430DA9EC.5080105@cc.jyu.fi>
	<139ef1c205082504314bcf968c@mail.gmail.com>
Message-ID: <p0621020bbf338a83405b@[128.115.153.6]>

  Potential helpers need more information.

Type:

    head(a)

and

    str(a)

and post the results.

Compare with the output of the same commands on a 
dataframe that does have this problem.

-Don

At 5:01 PM +0530 8/25/05, Krishna wrote:
>Hi  Mr. Pedro
>
>I tried names(a) and it displayed the names as X, Y and Z.
>
>rgds
>
>snvk
>
>On 8/25/05, Pedro J. Aphalo <pedro.aphalo at cc.jyu.fi> wrote:
>>  Hi,
>>
>>  Did you try names(a) so see what are the names of the columns in the
>>  dataframe?
>>
>>  Hope this helps a little.
>>
>>  Pedro.
>>
>>  Krishna wrote:
>>  > Hi All
>>  >
>>  > recently i faced an unknown problem while reading the data. Can
>>  > someone help me in understanding why this happened.
>>  >
>>  > I have .txt file containing X, Y, Z variables. I used the command
>>  >
>>  >
>>  >>a <- read.table("filename", header=TRUE)
>>  >
>>  > after reading the file i am able to view it by tryping a. but i am
>>  > unable to access the variables in a, by giving the command a$X.
>>  >
>>  >
>>  >>a$X
>>  >>NULL
>>  >
>>  >
>>  > this is the output it was showing. However the same i am able to
>>  > access by giving a[[1]]. i tried changing the mode by issuing command
>>  > a <- as.data.frame(a). But situation remains the same.
>>  >
>>  > look forward for experts suggestion on this.
>>  >
>>  > rgds
>>  >
>>  > snvk
>>  >
>>  > ______________________________________________
>>  > R-help at stat.math.ethz.ch mailing list
>>  > https://stat.ethz.ch/mailman/listinfo/r-help
>>  > PLEASE do read the posting guide! 
>>http://www.R-project.org/posting-guide.html
>>
>>
>>  --
>>  ==================================================================
>>  Pedro J. Aphalo
>>  Department of Biological and Environmental Science
>>  University of Jyv??skyl??
>>  P.O. Box 35, 40351 JYV??SKYL??, Finland
>>  Phone  +358 14 260 2339
>>  Mobile +358 50 3721504
>>  Fax    +358 14 260 2321
>>  mailto:pedro.aphalo at cc.jyu.fi
>>  http://www.jyu.fi/~aphalo/                       ,,,^..^,,,
>>  ==================================================================
>>
>>
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From a.manigs at gmail.com  Thu Aug 25 16:58:47 2005
From: a.manigs at gmail.com (A Mani)
Date: Thu, 25 Aug 2005 20:28:47 +0530
Subject: [R] A. Mani : Tapply
Message-ID: <a6821d990508250758301945ed@mail.gmail.com>

Hello,
        Is it safe to use tapply when the result will be of dim 20000
x 10000 or more ? In my PC R crashes. The code used was on a 3-col
data frame with two factor cols and a numeric column. The fn was diff
.
data form being <A, B, Num>
tapply(data$A, list(data$A, data$B), diff)

-- 
A. Mani
Member, Cal. Math. Soc



From macq at llnl.gov  Thu Aug 25 17:11:42 2005
From: macq at llnl.gov (Don MacQueen)
Date: Thu, 25 Aug 2005 08:11:42 -0700
Subject: [R] Help about R
In-Reply-To: <430DCDB0.3050809@sti.lu>
References: <430DCDB0.3050809@sti.lu>
Message-ID: <p0621020cbf338c41a8e9@[128.115.153.6]>

Also, for the three dimensional graphic,
    help.search("3d")
will lead to a reference to the cloud() function in the lattice package.

I don't remember if the lattice package is installed by default. If 
not, you will have to install it.
(If you're using a Mac or Windows computer, there's a menu item for 
installing packages. Otherwise you have to use the install.packages() 
function.)

Then

    require(lattice)
   ?cloud

to first load the lattice package, and then view the online 
documentation for the cloud() function.

You can view one of the cloud() examples like this:

    require(datasets)
    cloud(Sepal.Length ~ Petal.Length * Petal.Width | Species, data = iris,
            screen = list(x = -90, y = 70), distance = .4, zoom = .6)

You could consider a bubble plot. There are two packages with 
functions for bubble plots, gstat and sp.
(Neither of them is installed by default.) I suspect the one in gstat 
will be easier to use, at least for someone new to R.

After having installed either of these packages, say gstat, then

   ?bubble

to get its documentation.

Overlaying a grid on the plot created by cloud() might be difficult 
for an R beginner.

Here's a simple example:

bubble(data.frame(x=1:5,y=1:5,z=1:5))

-Don


At 3:54 PM +0200 8/25/05, Philippe wrote:
>Hello,
>My name is Philippe Favrot, I'm a french occupational doctor (working in
>Luxembourg), and I'm an "R beginner".
>I would be happy you could help me about the utilization of "R".
>Recently, I measured sound levels in a plant. Before the measuring, I
>divided the plant in 3 virtual rows and 8 virtual columns. I measured
>the sound level at each intersection of rows and columns and obtained a
>set of 24 "sound level" values.
>I wrote the results in a excel's spreadsheet.
>My question is: I know to do import from excel into "R" (with
>read.table()), but how can I draw a three dimensional graphic of the
>plant's sound level ? Can I overlay a map of this factory (as a
>rectangle with a grid representing each spots where I measured )?
>I'd understand if you are too busy to reply to my mail.
>Thanks.
>Best regards
>Philippe Favrot
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From andy_liaw at merck.com  Thu Aug 25 17:24:25 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 25 Aug 2005 11:24:25 -0400
Subject: [R] problem with read.table
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED3CB@usctmx1106.merck.com>

Could it be that there are spaces in the names that were read in?

> a <- data.frame(" X"=1:2, " Y"=3:4, " Z"=5:6, check.names=FALSE)
> a
   X  Y  Z
1  1  3  5
2  2  4  6
> names(a)
[1] " X" " Y" " Z"
> a$X
NULL

Andy

> From: Krishna
> 
> Hi  Mr. Pedro
> 
> I tried names(a) and it displayed the names as X, Y and Z.
> 
> rgds
> 
> snvk
> 
> On 8/25/05, Pedro J. Aphalo <pedro.aphalo at cc.jyu.fi> wrote:
> > Hi,
> > 
> > Did you try names(a) so see what are the names of the columns in the
> > dataframe?
> > 
> > Hope this helps a little.
> > 
> > Pedro.
> > 
> > Krishna wrote:
> > > Hi All
> > >
> > > recently i faced an unknown problem while reading the data. Can
> > > someone help me in understanding why this happened.
> > >
> > > I have .txt file containing X, Y, Z variables. I used the command
> > >
> > >
> > >>a <- read.table("filename", header=TRUE)
> > >
> > > after reading the file i am able to view it by tryping a. but i am
> > > unable to access the variables in a, by giving the command a$X.
> > >
> > >
> > >>a$X
> > >>NULL
> > >
> > >
> > > this is the output it was showing. However the same i am able to
> > > access by giving a[[1]]. i tried changing the mode by 
> issuing command
> > > a <- as.data.frame(a). But situation remains the same.
> > >
> > > look forward for experts suggestion on this.
> > >
> > > rgds
> > >
> > > snvk
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> > 
> > 
> > --
> > 
> ==================================================================
> > Pedro J. Aphalo
> > Department of Biological and Environmental Science
> > University of Jyv??skyl??
> > P.O. Box 35, 40351 JYV??SKYL??, Finland
> > Phone  +358 14 260 2339
> > Mobile +358 50 3721504
> > Fax    +358 14 260 2321
> > mailto:pedro.aphalo at cc.jyu.fi
> > http://www.jyu.fi/~aphalo/                       ,,,^..^,,,
> > ==================================================================
> > 
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From pwallem at bio.puc.cl  Thu Aug 25 16:31:30 2005
From: pwallem at bio.puc.cl (Petra Wallem)
Date: Thu, 25 Aug 2005 11:31:30 -0300
Subject: [R] box m-test
Message-ID: <1124980289.3392.44.camel@linux.site>

Hello everybody, 
 Is there in R a so called box m-test for testing the equality of the 
 variance/cov. matrix for checking on homoscedasticity? I could not find
it among the traditional packages for multivariate statistics...
Petra
-- 
Petra Wallem
Centro de Estudios Avanzados en EcologÃ­a & Biodiversidad (CASEB)
Departamento de EcologÃ­a
Facultad de Ciencias BiolÃ³gicas
Pontificia Universidad CatÃ³lica de Chile
Av. Libertador Bernardo O'Higgins # 340
Casilla 114-D



From abdelhafid.berrachi at gazdefrance.com  Thu Aug 25 17:46:15 2005
From: abdelhafid.berrachi at gazdefrance.com (Abdelhafid BERRICHI)
Date: Thu, 25 Aug 2005 17:46:15 +0200
Subject: [R] question sur R
Message-ID: <OF01D650F5.21B28602-ONC1257068.00558F88-C1257068.0056A1C5@notes.edfgdf.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050825/007131d9/attachment.pl

From reid_huntsinger at merck.com  Thu Aug 25 17:54:21 2005
From: reid_huntsinger at merck.com (Huntsinger, Reid)
Date: Thu, 25 Aug 2005 11:54:21 -0400
Subject: [R] Help about R
Message-ID: <355C35514FEAC9458F75947F5270974D076C86@usctmx1103.merck.com>

You might find image() useful, to plot the factory map and overlay the sound
levels as colors. You could also use persp(), or have a look at rgl.surface
in the rgl package on http://cran.r-project.org. 

Reid Huntsinger

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Philippe
Sent: Thursday, August 25, 2005 9:55 AM
To: r-help at stat.math.ethz.ch
Subject: [R] Help about R


Hello,
My name is Philippe Favrot, I'm a french occupational doctor (working in 
Luxembourg), and I'm an "R beginner".
I would be happy you could help me about the utilization of "R".
Recently, I measured sound levels in a plant. Before the measuring, I 
divided the plant in 3 virtual rows and 8 virtual columns. I measured 
the sound level at each intersection of rows and columns and obtained a 
set of 24 "sound level" values.
I wrote the results in a excel's spreadsheet.
My question is: I know to do import from excel into "R" (with 
read.table()), but how can I draw a three dimensional graphic of the 
plant's sound level ? Can I overlay a map of this factory (as a 
rectangle with a grid representing each spots where I measured )?
I'd understand if you are too busy to reply to my mail.
Thanks.
Best regards
Philippe Favrot

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From rjohnson at ncifcrf.gov  Thu Aug 25 18:17:18 2005
From: rjohnson at ncifcrf.gov (Randy Johnson)
Date: Thu, 25 Aug 2005 12:17:18 -0400
Subject: [R] help on retrieving output from by( ) for regression
In-Reply-To: <1124977453.4067.20.camel@localhost.localdomain>
Message-ID: <BF33674E.3B3D%rjohnson@ncifcrf.gov>

What about using lmList from the lme4 package?

Randy


On 8/25/05 9:44 AM, "Marc Schwartz" <MSchwartz at mn.rr.com> wrote:

> Also, looking at the last example in ?by would be helpful:
> 
> attach(warpbreaks)
> tmp <- by(warpbreaks, tension, function(x) lm(breaks ~ wool, data = x))
> 
> # To get coefficients:
> sapply(tmp, coef)
> 
> # To get residuals:
> sapply(tmp, resid)
> 
> # To get the model matrix:
> sapply(tmp, model.matrix)
> 
> 
> 
> To get the summary() output, I suspect that using:
> 
>   lapply(tmp, summary)
> 
> would yield more familiar output as compared to using:
> 
>   sapply(tmp, summary)
> 
> The output from the latter might require a bit more "navigation" through
> the resultant matrix, depending upon how the output is to be ultimately
> used.
> 
> HTH,
> 
> Marc Schwartz
> 
> 
> 
> On Thu, 2005-08-25 at 14:57 +0200, TEMPL Matthias wrote:
>> Look more carefully at
>> ?lm 
>> at the See Also section ...
>> 
>> X <- rnorm(30)
>> Y <- rnorm(30)
>> lm(Y~X)
>> summary(lm(Y~X))
>> 
>> Best,
>> Matthias
>> 
>> 
>>> Hi all 
>>> 
>>> I used a function
>>>> qtrregr <- by(AB, AB$qtr, function(AB) lm(AB$X~AB$Y))
>>> 
>>> objective is to run a regression on quartery subsets in the
>>> data set AB, having variables X and Y, grouped by variable qtr.
>>> 
>>> Now i retrieved the output using qtrregr, however it only
>>> showed the coefficients (intercept and B) with out
>>> significant levels and residuals for each qtr. Can some on
>>> help me on how can retrieve the detailed regression output.
>>> 
>>> rgds
>>> 
>>> snvk
>>> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Randy Johnson
Laboratory of Genomic Diversity
NCI-Frederick
Bldg 560, Rm 11-85
Frederick, MD 21702
(301)846-1304
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



From qx139921 at bcm.tmc.edu  Thu Aug 25 18:19:44 2005
From: qx139921 at bcm.tmc.edu (qikai xu)
Date: Thu, 25 Aug 2005 11:19:44 -0500
Subject: [R] "couldn't find function" error message in R 2.1.1
Message-ID: <BF3359D0.16D9%qx139921@bcm.tmc.edu>

Dear R-help,

I have a home-made package works perfectly under R 1.9.1.  Now I'm trying to
port it to R > 2.0.  So I rebuild the package under R 2.1.1. It installs and
loads OK. But when I try to call some functions "myfoo" in this package, it
returns error message: "Couldn't find function myfoo".  I checked all
available manuals, and didn't find any specific requirement that I'm
violating.  Have anybody in the list ever had similar problem before and how
did you solve it?  Thanks a lot for your help.

Qikai Xu



From jorge.delavegagongora at gmail.com  Thu Aug 25 18:20:01 2005
From: jorge.delavegagongora at gmail.com (Jorge de la Vega Gongora)
Date: Thu, 25 Aug 2005 11:20:01 -0500
Subject: [R] concerning econometrics usage of "R"
In-Reply-To: <20050825151630.5495d2c3.Achim.Zeileis@wu-wien.ac.at>
References: <web-55420228@anadolu.edu.tr>
	<20050825151630.5495d2c3.Achim.Zeileis@wu-wien.ac.at>
Message-ID: <ab1f54ec05082509203ae30ce5@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050825/91b0d6b8/attachment.pl

From Achim.Zeileis at wu-wien.ac.at  Thu Aug 25 18:20:38 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Thu, 25 Aug 2005 18:20:38 +0200
Subject: [R] concerning econometrics usage of "R"
In-Reply-To: <ab1f54ec05082509203ae30ce5@mail.gmail.com>
References: <web-55420228@anadolu.edu.tr>
	<20050825151630.5495d2c3.Achim.Zeileis@wu-wien.ac.at>
	<ab1f54ec05082509203ae30ce5@mail.gmail.com>
Message-ID: <20050825182038.430e7c4d.Achim.Zeileis@wu-wien.ac.at>

On Thu, 25 Aug 2005 11:20:01 -0500 Jorge de la Vega Gongora wrote:

> There are some reviews. You can read:
>  R: yet another Econometric Programming Environment, Francisco Cibari-
>  Neto 
> and Spyros G. Zarkos.
> Journal of Applied Econometrics, 14: 319-329 (1999)

It's a good article and definitely worth reading (as is Racine &
Hyndman, Using R to Teach Econometrics, JAE, 17, 175-189, 2002) but note
that it reviews version 0.63.1 of R and that many things changed since
then.
Z

> 
>  On 8/25/05, Achim Zeileis <Achim.Zeileis at wu-wien.ac.at> wrote: 
> > 
> > On Thu, 25 Aug 2005 11:52:28 +0100 SELIM YILDIRIM wrote:
> > 
> > > Hi,
> > >
> > > I am currently looking for a program or programmng language easy
> > > to learn, easier to operate on.I heva heard about "R", However I
> > > understand that "R" is designed especially for statisticians. As
> > > an economist, working on applied econometrics, I am not sure if it
> > > can meet my needs.
> > >
> > > Will I be able to reach precise time series or panal data
> > > regression results with "R" ?
> > 
> > yes
> > 
> > > Can "R" regress nonlinear models such as TAR, STAR
> > > and Markov Switcing models? Can I use it to do cointegration, unit
> > > root, VAR analysis on both panel and time series data? Can I run
> > > GMM regressions on "R" ?
> > 
> > some things yes, other things not out of the box
> > 
> > > Is it suitable for Monte Carlos?
> > 
> > yes
> > 
> > > In short, is R suitable for applied econometrics?
> > 
> > In principle yes, although not everything you might want to do is
> > already available in CRAN packages. For an overview of what is
> > currently available, look at the task view as Duncan already
> > suggested.
> > 
> > Best,
> > Z
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> >
>



From petr.pikal at precheza.cz  Thu Aug 25 18:34:01 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Thu, 25 Aug 2005 18:34:01 +0200
Subject: [R] "couldn't find function" error message in R 2.1.1
In-Reply-To: <BF3359D0.16D9%qx139921@bcm.tmc.edu>
Message-ID: <430E0F19.4670.1A29132@localhost>

Hi

Is the package loaded?

What is echoed vhen you do

library(mypackage)

Does search() find your package?

Cheers
Petr




On 25 Aug 2005 at 11:19, qikai xu wrote:

> Dear R-help,
> 
> I have a home-made package works perfectly under R 1.9.1.  Now I'm
> trying to port it to R > 2.0.  So I rebuild the package under R 2.1.1.
> It installs and loads OK. But when I try to call some functions
> "myfoo" in this package, it returns error message: "Couldn't find
> function myfoo".  I checked all available manuals, and didn't find any
> specific requirement that I'm violating.  Have anybody in the list
> ever had similar problem before and how did you solve it?  Thanks a
> lot for your help.
> 
> Qikai Xu
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

Petr Pikal
petr.pikal at precheza.cz



From mschwartz at mn.rr.com  Thu Aug 25 18:52:11 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 25 Aug 2005 11:52:11 -0500
Subject: [R] help on retrieving output from by( ) for regression
In-Reply-To: <BF33674E.3B3D%rjohnson@ncifcrf.gov>
References: <BF33674E.3B3D%rjohnson@ncifcrf.gov>
Message-ID: <1124988731.4349.22.camel@localhost.localdomain>

That works also (using the example in ?lmList)

library(lme4)

?lmList

fm1 <- lmList(breaks ~ wool | tension, warpbreaks)


However, one still would need to use either sapply() or lapply() as
below to get the details that Krishna is looking for. 

'fm1' above is a list of models (S4 class 'lmList') not overly different
from 'tmp' below, which is a list of models (S3 class 'by').

If you review str(fm1) and str(tmp), you would note that they are
virtually identical, save the use of slots, etc.

HTH,

Marc Schwartz

On Thu, 2005-08-25 at 12:17 -0400, Randy Johnson wrote:
> What about using lmList from the lme4 package?
> 
> Randy
> 
> 
> On 8/25/05 9:44 AM, "Marc Schwartz" <MSchwartz at mn.rr.com> wrote:
> 
> > Also, looking at the last example in ?by would be helpful:
> > 
> > attach(warpbreaks)
> > tmp <- by(warpbreaks, tension, function(x) lm(breaks ~ wool, data = x))
> > 
> > # To get coefficients:
> > sapply(tmp, coef)
> > 
> > # To get residuals:
> > sapply(tmp, resid)
> > 
> > # To get the model matrix:
> > sapply(tmp, model.matrix)
> > 
> > 
> > 
> > To get the summary() output, I suspect that using:
> > 
> >   lapply(tmp, summary)
> > 
> > would yield more familiar output as compared to using:
> > 
> >   sapply(tmp, summary)
> > 
> > The output from the latter might require a bit more "navigation" through
> > the resultant matrix, depending upon how the output is to be ultimately
> > used.
> > 
> > HTH,
> > 
> > Marc Schwartz
> > 
> > 
> > 
> > On Thu, 2005-08-25 at 14:57 +0200, TEMPL Matthias wrote:
> >> Look more carefully at
> >> ?lm 
> >> at the See Also section ...
> >> 
> >> X <- rnorm(30)
> >> Y <- rnorm(30)
> >> lm(Y~X)
> >> summary(lm(Y~X))
> >> 
> >> Best,
> >> Matthias
> >> 
> >> 
> >>> Hi all 
> >>> 
> >>> I used a function
> >>>> qtrregr <- by(AB, AB$qtr, function(AB) lm(AB$X~AB$Y))
> >>> 
> >>> objective is to run a regression on quartery subsets in the
> >>> data set AB, having variables X and Y, grouped by variable qtr.
> >>> 
> >>> Now i retrieved the output using qtrregr, however it only
> >>> showed the coefficients (intercept and B) with out
> >>> significant levels and residuals for each qtr. Can some on
> >>> help me on how can retrieve the detailed regression output.
> >>> 
> >>> rgds
> >>> 
> >>> snvk
> >>> 
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > 
> 
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> Randy Johnson
> Laboratory of Genomic Diversity
> NCI-Frederick
> Bldg 560, Rm 11-85
> Frederick, MD 21702
> (301)846-1304
> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From deepayan.sarkar at gmail.com  Thu Aug 25 19:05:04 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 25 Aug 2005 12:05:04 -0500
Subject: [R] histogram method for S4 class.
In-Reply-To: <430C5958.1040005@ipimar.pt>
References: <430C5958.1040005@ipimar.pt>
Message-ID: <eb555e6605082510052dc054a@mail.gmail.com>

On 8/24/05, ernesto <ernesto at ipimar.pt> wrote:
> Hi,
> 
> I'm trying to develop an histogram method for a class called "FLQuant"
> which is used by the package FLCore (http://flr-project.org). FLQuant is
> an extension to "array". There is an as.data.frame method that coerces
> flquant into a data.frame suitable for lattice plotting. The problem is
> that when I coerce the object and plot it after it works but if the
> method is applied within the histogram method it does not work. See the
> code below (the FLCore package is here
> http://prdownloads.sourceforge.net/flr/FLCore_1.0-1.tar.gz?download)
> 
> > library(FLCore)
> Loading required package: lattice
> > data(ple4)
> > histogram(~data|year, data=ple4 at catch.n)
> Error in inherits(x, "factor") : Object "x" not found
> > histogram(~data|year, data=as.data.frame(ple4 at catch.n))
> 
> The catch.n slot is a FLQuant object and the code for histogram is the
> following
> 
> setMethod("histogram", signature(formula="formula", data="FLQuant"),
>     function (formula, data = parent.frame(), allow.multiple =
> is.null(groups) || outer,
>         outer = FALSE, auto.key = FALSE, aspect = "fill", panel =
> "panel.histogram", prepanel = NULL,
>         scales = list(), strip = TRUE, groups = NULL, xlab, xlim, ylab,
> ylim,
>         type = c("percent", "count", "density"),
>         nint = if (is.factor(x)) length(levels(x)) else
> round(log2(length(x)) + 1),
>         endpoints = extend.limits(range(x[!is.na(x)]), prop = 0.04),
>         breaks = if (is.factor(x)) seq(0.5, length = length(levels(x)) +
> 1) else do.breaks(endpoints, nint),
>         equal.widths = TRUE, drop.unused.levels =
> lattice.getOption("drop.unused.levels"), ...,
>         default.scales = list(), subscripts = !is.null(groups), subset =
> TRUE) {
> 
>         qdf <- as.data.frame(data)
> 
>         histogram(formula, data = qdf, allow.multiple = allow.multiple,
> outer = outer,
>             auto.key = auto.key, aspect = aspect, panel = panel,
> prepanel = prepanel, scales = scales,
>             strip = strip, groups = groups, xlab=xlab, xlim=xlim,
> ylab=ylab, ylim=ylim, type = type,
>             nint = nint, endpoints = endpoints, breaks = breaks,
> equal.widths = equal.widths,
>             drop.unused.levels = drop.unused.levels, ..., default.scales
> = default.scales,
>             subscripts = subscripts, subset = subset)
>     }
> )
> 
> 
> Any ideas ?

[I'm CC-ing to r-devel, please post follow-ups there]

What version of lattice are you using? Please use the latest one, in
which histogram is an S3 generic, with only one argument, formula. The
eventual solution to your problem may involve changing that, but the
first question to ask is whether any other formula makes sense in your
context (if not, I would rather keep one argument and dispatch on
signature(formula = "FLQuant").

Disclaimer: I haven't actually had time to check out FLCore yet, I
will as soon as I can.

Deepayan



From deepayan.sarkar at gmail.com  Thu Aug 25 19:08:41 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Thu, 25 Aug 2005 12:08:41 -0500
Subject: [R] Code in lattice::dotplot function.
In-Reply-To: <430DAFC5.50700@ipimar.pt>
References: <430DAFC5.50700@ipimar.pt>
Message-ID: <eb555e6605082510084ef3dc42@mail.gmail.com>

On 8/25/05, ernesto <ernesto at ipimar.pt> wrote:
> Hi,
> 
> I'm trying to understand the code of lattice functions so that I can
> write some S4 methods using lattice. The following code is a snipet of
> dotplot that is reused in several other functions. I don't understand
> why this is needed can someone help ?

It was a hack to enable usage of the form dotplot(x). The latest
version of lattice does not use this sort of construct any more
(replacing it by generics and methods).

Deepayan



From Carsten.Colombier at efv.admin.ch  Thu Aug 25 19:11:36 2005
From: Carsten.Colombier at efv.admin.ch (Carsten.Colombier@efv.admin.ch)
Date: Thu, 25 Aug 2005 19:11:36 +0200
Subject: [R] PDL model
Message-ID: <2CAE512CEB72EE448AADE3444E1FB718023CB590@ad04mexefd3.ad.admin.ch>

Dear r-help team:

Is a package implemented in R which includes a function that calculates
polynomial distributed lag models (also: Almon models, pdl-model)? Provided
a pdl function is available, can it be applied to robust statistics like
MM-estimators?

Thanks in advance!

Best regards,
Carsten Colombier

Dr. Carsten Colombier
Economist
Group of Economic Advisers
Swiss Federal Finance Administration
Bundesgasse 3
CH-3003 Bern

phone +41 31 322 63 32
fax +41 31 323 08 33
email: carsten.colombier at efv.admin.ch
www.efv.admin.ch



From mschwartz at mn.rr.com  Thu Aug 25 19:21:21 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Thu, 25 Aug 2005 12:21:21 -0500
Subject: [R] help on retrieving output from by( ) for regression
In-Reply-To: <1124988731.4349.22.camel@localhost.localdomain>
References: <BF33674E.3B3D%rjohnson@ncifcrf.gov>
	<1124988731.4349.22.camel@localhost.localdomain>
Message-ID: <1124990481.4349.31.camel@localhost.localdomain>

Sorry to reply to my own post, but in reviewing the NAMESPACE file for
lme4, it looks like Doug is perhaps planning to add additional model
object accessor methods for the lmList class, including resid() and
summary(), which are commented out now. coef() is available presently. 

So when in place, it would appear that the use of lmList would be
advantageous over the use of by().

Marc

On Thu, 2005-08-25 at 11:52 -0500, Marc Schwartz (via MN) wrote:
> That works also (using the example in ?lmList)
> 
> library(lme4)
> 
> ?lmList
> 
> fm1 <- lmList(breaks ~ wool | tension, warpbreaks)
> 
> 
> However, one still would need to use either sapply() or lapply() as
> below to get the details that Krishna is looking for. 
> 
> 'fm1' above is a list of models (S4 class 'lmList') not overly different
> from 'tmp' below, which is a list of models (S3 class 'by').
> 
> If you review str(fm1) and str(tmp), you would note that they are
> virtually identical, save the use of slots, etc.
> 
> HTH,
> 
> Marc Schwartz
> 
> On Thu, 2005-08-25 at 12:17 -0400, Randy Johnson wrote:
> > What about using lmList from the lme4 package?
> > 
> > Randy
> > 
> > 
> > On 8/25/05 9:44 AM, "Marc Schwartz" <MSchwartz at mn.rr.com> wrote:
> > 
> > > Also, looking at the last example in ?by would be helpful:
> > > 
> > > attach(warpbreaks)
> > > tmp <- by(warpbreaks, tension, function(x) lm(breaks ~ wool, data = x))
> > > 
> > > # To get coefficients:
> > > sapply(tmp, coef)
> > > 
> > > # To get residuals:
> > > sapply(tmp, resid)
> > > 
> > > # To get the model matrix:
> > > sapply(tmp, model.matrix)
> > > 
> > > 
> > > 
> > > To get the summary() output, I suspect that using:
> > > 
> > >   lapply(tmp, summary)
> > > 
> > > would yield more familiar output as compared to using:
> > > 
> > >   sapply(tmp, summary)
> > > 
> > > The output from the latter might require a bit more "navigation" through
> > > the resultant matrix, depending upon how the output is to be ultimately
> > > used.
> > > 
> > > HTH,
> > > 
> > > Marc Schwartz
> > > 
> > > 
> > > 
> > > On Thu, 2005-08-25 at 14:57 +0200, TEMPL Matthias wrote:
> > >> Look more carefully at
> > >> ?lm 
> > >> at the See Also section ...
> > >> 
> > >> X <- rnorm(30)
> > >> Y <- rnorm(30)
> > >> lm(Y~X)
> > >> summary(lm(Y~X))
> > >> 
> > >> Best,
> > >> Matthias
> > >> 
> > >> 
> > >>> Hi all 
> > >>> 
> > >>> I used a function
> > >>>> qtrregr <- by(AB, AB$qtr, function(AB) lm(AB$X~AB$Y))
> > >>> 
> > >>> objective is to run a regression on quartery subsets in the
> > >>> data set AB, having variables X and Y, grouped by variable qtr.
> > >>> 
> > >>> Now i retrieved the output using qtrregr, however it only
> > >>> showed the coefficients (intercept and B) with out
> > >>> significant levels and residuals for each qtr. Can some on
> > >>> help me on how can retrieve the detailed regression output.
> > >>> 
> > >>> rgds
> > >>> 
> > >>> snvk
> > >>> 
> > > 
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > > 
> > 
> > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> > Randy Johnson
> > Laboratory of Genomic Diversity
> > NCI-Frederick
> > Bldg 560, Rm 11-85
> > Frederick, MD 21702
> > (301)846-1304
> > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From mathieu.drapeau at mcgill.ca  Thu Aug 25 19:29:49 2005
From: mathieu.drapeau at mcgill.ca (Mathieu Drapeau)
Date: Thu, 25 Aug 2005 13:29:49 -0400
Subject: [R] ROracle and select query empty
Message-ID: <430E000D.6020009@mcgill.ca>

Hi,
I just installed ROracle and RDBI. The connection to the database seems 
to work also. My problem is when I am selection rows that really exist 
in the database, it is returning nothing. Where should I look to see 
what could be my problem?

Thank you very much,
Mathieu

 > drv <- dbDriver("Oracle")
 > summary(drv, verbose=TRUE)
<OraDriver:(6721)>
  Driver name:  Oracle (ProC/C++)
  Max  connections: 10
  Conn. processed: 8
  Default records per fetch: 500
  Oracle R/S client version: 0.5-4
  RS-DBI version:  0.1-9
  Open connections: 2
    1  <OraConnection:(6721,0)>
    2  <OraConnection:(6721,7)>
 >
 > conn <- dbConnect(drv, "mathieu/toto at MYDB")
 > summary(conn, verbose=TRUE) <OraConnection:(6721,7)>
  User: mathieu
  Dbname: MYDB
  Oracle Server version:
 >
 > rs <- dbSendQuery(conn, statement = paste("select * from cat"))
 > summary(rs, verbose=TRUE)
<OraResult:(6721,7,2)>
  Statement: select * from cat
  Has completed? no
  Affected rows: 0
  Rows fetched: -1
  Fields:
        name    Sclass     type len precision scale isVarLength nullOK
1 TABLE_NAME character VARCHAR2  30         0     0        TRUE  FALSE
2 TABLE_TYPE character VARCHAR2  11         0     0        TRUE   TRUE
 >
 > myContent <- fetch(rs, n = -1)
 > myContent
[1] TABLE_NAME TABLE_TYPE
<0 rows> (or 0-length row.names)
 > summary(myContent, verbose=TRUE)
  TABLE_NAME         TABLE_TYPE
 Length:0           Length:0
 Class :character   Class :character
 Mode  :character   Mode  :character
 > summary(rs, verbose=TRUE)
<OraResult:(6721,7,2)>
  Statement: select * from cat
  Has completed? yes
  Affected rows: 0
  Rows fetched: -1
  Fields:
        name    Sclass     type len precision scale isVarLength nullOK
1 TABLE_NAME character VARCHAR2  30         0     0        TRUE  FALSE
2 TABLE_TYPE character VARCHAR2  11         0     0        TRUE   TRUE



From djames at frontierassoc.com  Thu Aug 25 19:51:10 2005
From: djames at frontierassoc.com (David James)
Date: Thu, 25 Aug 2005 12:51:10 -0500
Subject: [R] Irregular Time Series: zoo & its: Pros & Cons
In-Reply-To: <430E000D.6020009@mcgill.ca>
References: <430E000D.6020009@mcgill.ca>
Message-ID: <AE433877-7330-4061-B106-F01FF83FC92C@frontierassoc.com>

Hello,

I'm working with irregular time series data.  What do you all think  
about the strengths and weaknesses of the "zoo" and "its" packages?

I've installed and skimmed the documentation on both packages.  I was  
hoping to get a little guidance from the user community before  
proceeding further.

In case anyone is interested in my particular problem:  I'm looking  
at some (surface) temperature data from NOAA:  http:// 
cdo.ncdc.noaa.gov/ulcd/ULCD
It is (irregular) time series format.  The NOAA data reports year,  
month, date, hour, and minute.  I want to group the data into hourly  
chunks.  However, sometimes there are multiple observation per hour  
-- i.e an observation at 3:45 and 3:56.  Also, sometimes a particular  
hour may be missing altogether.  I need to clean up the data so that  
each hour has one and only one data point.

I'm relatively new to R, but I think I'm getting a hold on it pretty  
well so far.  I used to do a lot with MATLAB, and there seem to be  
many parallels between it and R.  I have background in public policy  
and econometrics.

Thanks,
David

On Aug 25, 2005, at 12:29 PM, Mathieu Drapeau wrote:

> Hi,
> I just installed ROracle and RDBI. The connection to the database  
> seems
> to work also. My problem is when I am selection rows that really exist
> in the database, it is returning nothing. Where should I look to see
> what could be my problem?
>
> Thank you very much,
> Mathieu
>
>
>> drv <- dbDriver("Oracle")
>> summary(drv, verbose=TRUE)
>>
> <OraDriver:(6721)>
>   Driver name:  Oracle (ProC/C++)
>   Max  connections: 10
>   Conn. processed: 8
>   Default records per fetch: 500
>   Oracle R/S client version: 0.5-4
>   RS-DBI version:  0.1-9
>   Open connections: 2
>     1  <OraConnection:(6721,0)>
>     2  <OraConnection:(6721,7)>
>
>>
>> conn <- dbConnect(drv, "mathieu/toto at MYDB")
>> summary(conn, verbose=TRUE) <OraConnection:(6721,7)>
>>
>   User: mathieu
>   Dbname: MYDB
>   Oracle Server version:
>
>>
>> rs <- dbSendQuery(conn, statement = paste("select * from cat"))
>> summary(rs, verbose=TRUE)
>>
> <OraResult:(6721,7,2)>
>   Statement: select * from cat
>   Has completed? no
>   Affected rows: 0
>   Rows fetched: -1
>   Fields:
>         name    Sclass     type len precision scale isVarLength nullOK
> 1 TABLE_NAME character VARCHAR2  30         0     0        TRUE  FALSE
> 2 TABLE_TYPE character VARCHAR2  11         0     0        TRUE   TRUE
>
>>
>> myContent <- fetch(rs, n = -1)
>> myContent
>>
> [1] TABLE_NAME TABLE_TYPE
> <0 rows> (or 0-length row.names)
>
>> summary(myContent, verbose=TRUE)
>>
>   TABLE_NAME         TABLE_TYPE
>  Length:0           Length:0
>  Class :character   Class :character
>  Mode  :character   Mode  :character
>
>> summary(rs, verbose=TRUE)
>>
> <OraResult:(6721,7,2)>
>   Statement: select * from cat
>   Has completed? yes
>   Affected rows: 0
>   Rows fetched: -1
>   Fields:
>         name    Sclass     type len precision scale isVarLength nullOK
> 1 TABLE_NAME character VARCHAR2  30         0     0        TRUE  FALSE
> 2 TABLE_TYPE character VARCHAR2  11         0     0        TRUE   TRUE
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html
>



From whit at twinfieldscapital.com  Thu Aug 25 20:06:54 2005
From: whit at twinfieldscapital.com (Whit Armstrong)
Date: Thu, 25 Aug 2005 14:06:54 -0400
Subject: [R] Irregular Time Series: zoo & its: Pros & Cons
Message-ID: <726FC6DD09DE1046AF81B499D70C3BCE2C8473@twinfields02.CORP.TWINFIELDSCAPITAL.COM>

I am the maintainer of its, but not it's original author.

One of the main strengths of its is that it uses POSIXct dates.

Zoo has the flexibility of using almost any date format, but I don't
know if the other date formats can store hour, min, sec data.

You might want to do a little exploring with each before you commit.

I'll be happy to give you a hand if you decide to work with its.

Cheers,
Whit


> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of David James
> Sent: Thursday, August 25, 2005 1:51 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Irregular Time Series: zoo & its: Pros & Cons
> 
> Hello,
> 
> I'm working with irregular time series data.  What do you all 
> think about the strengths and weaknesses of the "zoo" and 
> "its" packages?
> 
> I've installed and skimmed the documentation on both 
> packages.  I was hoping to get a little guidance from the 
> user community before proceeding further.
> 
> In case anyone is interested in my particular problem:  I'm 
> looking at some (surface) temperature data from NOAA:  
> http:// cdo.ncdc.noaa.gov/ulcd/ULCD It is (irregular) time 
> series format.  The NOAA data reports year, month, date, 
> hour, and minute.  I want to group the data into hourly 
> chunks.  However, sometimes there are multiple observation per hour
> -- i.e an observation at 3:45 and 3:56.  Also, sometimes a 
> particular hour may be missing altogether.  I need to clean 
> up the data so that each hour has one and only one data point.
> 
> I'm relatively new to R, but I think I'm getting a hold on it 
> pretty well so far.  I used to do a lot with MATLAB, and 
> there seem to be many parallels between it and R.  I have 
> background in public policy and econometrics.
> 
> Thanks,
> David
> 
> On Aug 25, 2005, at 12:29 PM, Mathieu Drapeau wrote:
> 
> > Hi,
> > I just installed ROracle and RDBI. The connection to the database 
> > seems to work also. My problem is when I am selection rows 
> that really 
> > exist in the database, it is returning nothing. Where 
> should I look to 
> > see what could be my problem?
> >
> > Thank you very much,
> > Mathieu
> >
> >
> >> drv <- dbDriver("Oracle")
> >> summary(drv, verbose=TRUE)
> >>
> > <OraDriver:(6721)>
> >   Driver name:  Oracle (ProC/C++)
> >   Max  connections: 10
> >   Conn. processed: 8
> >   Default records per fetch: 500
> >   Oracle R/S client version: 0.5-4
> >   RS-DBI version:  0.1-9
> >   Open connections: 2
> >     1  <OraConnection:(6721,0)>
> >     2  <OraConnection:(6721,7)>
> >
> >>
> >> conn <- dbConnect(drv, "mathieu/toto at MYDB") summary(conn, 
> >> verbose=TRUE) <OraConnection:(6721,7)>
> >>
> >   User: mathieu
> >   Dbname: MYDB
> >   Oracle Server version:
> >
> >>
> >> rs <- dbSendQuery(conn, statement = paste("select * from cat")) 
> >> summary(rs, verbose=TRUE)
> >>
> > <OraResult:(6721,7,2)>
> >   Statement: select * from cat
> >   Has completed? no
> >   Affected rows: 0
> >   Rows fetched: -1
> >   Fields:
> >         name    Sclass     type len precision scale 
> isVarLength nullOK
> > 1 TABLE_NAME character VARCHAR2  30         0     0        
> TRUE  FALSE
> > 2 TABLE_TYPE character VARCHAR2  11         0     0        
> TRUE   TRUE
> >
> >>
> >> myContent <- fetch(rs, n = -1)
> >> myContent
> >>
> > [1] TABLE_NAME TABLE_TYPE
> > <0 rows> (or 0-length row.names)
> >
> >> summary(myContent, verbose=TRUE)
> >>
> >   TABLE_NAME         TABLE_TYPE
> >  Length:0           Length:0
> >  Class :character   Class :character
> >  Mode  :character   Mode  :character
> >
> >> summary(rs, verbose=TRUE)
> >>
> > <OraResult:(6721,7,2)>
> >   Statement: select * from cat
> >   Has completed? yes
> >   Affected rows: 0
> >   Rows fetched: -1
> >   Fields:
> >         name    Sclass     type len precision scale 
> isVarLength nullOK
> > 1 TABLE_NAME character VARCHAR2  30         0     0        
> TRUE  FALSE
> > 2 TABLE_TYPE character VARCHAR2  11         0     0        
> TRUE   TRUE
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting- 
> > guide.html
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From phgrosjean at sciviews.org  Thu Aug 25 20:06:55 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Thu, 25 Aug 2005 20:06:55 +0200
Subject: [R] Irregular Time Series: zoo & its: Pros & Cons
In-Reply-To: <AE433877-7330-4061-B106-F01FF83FC92C@frontierassoc.com>
References: <430E000D.6020009@mcgill.ca>
	<AE433877-7330-4061-B106-F01FF83FC92C@frontierassoc.com>
Message-ID: <430E08BF.2060704@sciviews.org>

Hello David,

You may be interested also by the regul() function and similar fro the 
pastecs package: it is designed to solve the kind of problems you talk 
about. You should read the manual, which is included. However, this 
manual is in French.
Best,

Philippe

..............................................<??}))><........
  ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
  ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
  ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
  ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
( ( ( ( (
  ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
  ) ) ) ) )
( ( ( ( (    web:   http://www.umh.ac.be/~econum
  ) ) ) ) )          http://www.sciviews.org
( ( ( ( (
..............................................................

David James wrote:
> Hello,
> 
> I'm working with irregular time series data.  What do you all think  
> about the strengths and weaknesses of the "zoo" and "its" packages?
> 
> I've installed and skimmed the documentation on both packages.  I was  
> hoping to get a little guidance from the user community before  
> proceeding further.
> 
> In case anyone is interested in my particular problem:  I'm looking  
> at some (surface) temperature data from NOAA:  http:// 
> cdo.ncdc.noaa.gov/ulcd/ULCD
> It is (irregular) time series format.  The NOAA data reports year,  
> month, date, hour, and minute.  I want to group the data into hourly  
> chunks.  However, sometimes there are multiple observation per hour  
> -- i.e an observation at 3:45 and 3:56.  Also, sometimes a particular  
> hour may be missing altogether.  I need to clean up the data so that  
> each hour has one and only one data point.
> 
> I'm relatively new to R, but I think I'm getting a hold on it pretty  
> well so far.  I used to do a lot with MATLAB, and there seem to be  
> many parallels between it and R.  I have background in public policy  
> and econometrics.
> 
> Thanks,
> David
> 
> On Aug 25, 2005, at 12:29 PM, Mathieu Drapeau wrote:
> 
> 
>>Hi,
>>I just installed ROracle and RDBI. The connection to the database  
>>seems
>>to work also. My problem is when I am selection rows that really exist
>>in the database, it is returning nothing. Where should I look to see
>>what could be my problem?
>>
>>Thank you very much,
>>Mathieu
>>
>>
>>
>>>drv <- dbDriver("Oracle")
>>>summary(drv, verbose=TRUE)
>>>
>>
>><OraDriver:(6721)>
>>  Driver name:  Oracle (ProC/C++)
>>  Max  connections: 10
>>  Conn. processed: 8
>>  Default records per fetch: 500
>>  Oracle R/S client version: 0.5-4
>>  RS-DBI version:  0.1-9
>>  Open connections: 2
>>    1  <OraConnection:(6721,0)>
>>    2  <OraConnection:(6721,7)>
>>
>>>conn <- dbConnect(drv, "mathieu/toto at MYDB")
>>>summary(conn, verbose=TRUE) <OraConnection:(6721,7)>
>>>
>>  User: mathieu
>>  Dbname: MYDB
>>  Oracle Server version:
>>
>>
>>>rs <- dbSendQuery(conn, statement = paste("select * from cat"))
>>>summary(rs, verbose=TRUE)
>>>
>>
>><OraResult:(6721,7,2)>
>>  Statement: select * from cat
>>  Has completed? no
>>  Affected rows: 0
>>  Rows fetched: -1
>>  Fields:
>>        name    Sclass     type len precision scale isVarLength nullOK
>>1 TABLE_NAME character VARCHAR2  30         0     0        TRUE  FALSE
>>2 TABLE_TYPE character VARCHAR2  11         0     0        TRUE   TRUE
>>
>>
>>>myContent <- fetch(rs, n = -1)
>>>myContent
>>>
>>
>>[1] TABLE_NAME TABLE_TYPE
>><0 rows> (or 0-length row.names)
>>
>>
>>>summary(myContent, verbose=TRUE)
>>>
>>
>>  TABLE_NAME         TABLE_TYPE
>> Length:0           Length:0
>> Class :character   Class :character
>> Mode  :character   Mode  :character
>>
>>
>>>summary(rs, verbose=TRUE)
>>>
>>
>><OraResult:(6721,7,2)>
>>  Statement: select * from cat
>>  Has completed? yes
>>  Affected rows: 0
>>  Rows fetched: -1
>>  Fields:
>>        name    Sclass     type len precision scale isVarLength nullOK
>>1 TABLE_NAME character VARCHAR2  30         0     0        TRUE  FALSE
>>2 TABLE_TYPE character VARCHAR2  11         0     0        TRUE   TRUE
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting- 
>>guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From andy_liaw at merck.com  Thu Aug 25 21:11:46 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Thu, 25 Aug 2005 15:11:46 -0400
Subject: [R] box m-test
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED3CF@usctmx1106.merck.com>

I posted a translation from a Matlab version a while ago.  Search in the
list archive.

Andy

> From: Petra Wallem
> 
> Hello everybody, 
>  Is there in R a so called box m-test for testing the equality of the 
>  variance/cov. matrix for checking on homoscedasticity? I 
> could not find
> it among the traditional packages for multivariate statistics...
> Petra
> -- 
> Petra Wallem
> Centro de Estudios Avanzados en Ecolog??a & Biodiversidad (CASEB)
> Departamento de Ecolog??a
> Facultad de Ciencias Biol??gicas
> Pontificia Universidad Cat??lica de Chile
> Av. Libertador Bernardo O'Higgins # 340
> Casilla 114-D
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From greg.snow at ihc.com  Thu Aug 25 21:39:44 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Thu, 25 Aug 2005 13:39:44 -0600
Subject: [R] rgui on windows quiting automatically Resolved
Message-ID: <s30dca31.075@lp-msg1.co.ihc.com>

I have resolved the problem I had with rgui quiting automatically.
I am posting this mainly so that if anyone else in the future has
the same problem there will be a solution in the archives.

The problem was apparently with the file Rconsole that was 
in the directory "My Documents", when I deleted that file
then everything started working fine again.  

Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111



From murdoch at stats.uwo.ca  Thu Aug 25 21:46:43 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Thu, 25 Aug 2005 15:46:43 -0400
Subject: [R] rgui on windows quiting automatically Resolved
In-Reply-To: <s30dca31.075@lp-msg1.co.ihc.com>
References: <s30dca31.075@lp-msg1.co.ihc.com>
Message-ID: <430E2023.8030505@stats.uwo.ca>

On 8/25/2005 3:39 PM, Greg Snow wrote:
> I have resolved the problem I had with rgui quiting automatically.
> I am posting this mainly so that if anyone else in the future has
> the same problem there will be a solution in the archives.
> 
> The problem was apparently with the file Rconsole that was 
> in the directory "My Documents", when I deleted that file
> then everything started working fine again.  

Could you take a look at that file, if it's still in your recycle bin? 
It's supposed to be a text file.  I'm curious what was wrong with it 
that caused this behaviour.

Duncan Murdoch



From aoganyan at niss.org  Thu Aug 25 23:55:46 2005
From: aoganyan at niss.org (Anna Oganyan)
Date: Thu, 25 Aug 2005 17:55:46 -0400
Subject: [R] Quick partitioning
Message-ID: <430E3E62.2040407@niss.org>

Hello,
I am quite new in R, and  I have one problem:
I have large d-dimensional data sets (d=2, 3, 6, 10). I would like to 
divide the d-dim space into n (n may be 10, but better some larger 
number, for example 20) equally sized d-dim hypercubes  and count  how 
many data points are in each cube. Is there any way to do  it quickly, I 
mean - in a reasonable time? Actually, I  want  to get some rough idea 
of underlying densities of these data and compare them.
Thanks a lot!
Anna



From Karthik.Devarajan at fccc.edu  Fri Aug 26 00:37:28 2005
From: Karthik.Devarajan at fccc.edu (Devarajan, Karthik)
Date: Thu, 25 Aug 2005 18:37:28 -0400
Subject: [R] covariance matrix under null
Message-ID: <D45546375992BF429A93F7203358F14403429579@sirius.fccc.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050825/dbaec380/attachment.pl

From ggrothendieck at gmail.com  Fri Aug 26 01:01:59 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 25 Aug 2005 19:01:59 -0400
Subject: [R] Irregular Time Series: zoo & its: Pros & Cons
In-Reply-To: <AE433877-7330-4061-B106-F01FF83FC92C@frontierassoc.com>
References: <430E000D.6020009@mcgill.ca>
	<AE433877-7330-4061-B106-F01FF83FC92C@frontierassoc.com>
Message-ID: <971536df050825160151309a03@mail.gmail.com>

On 8/25/05, David James <djames at frontierassoc.com> wrote:
> Hello,
> 
> I'm working with irregular time series data.  What do you all think
> about the strengths and weaknesses of the "zoo" and "its" packages?


I have worked on the development of zoo with Achim Zeileis so
I will just speak to that one.

The key to notice about zoo is its independence of index class
(i.e.  date, time or date/time class) making it general in
nature so that you can use any one you like.  It supports
all the standard date and time classes in R and you can add
your own too. In your case you probably want to use chron
(or POSIXct if you need time zones) or you could create your 
own special hourly class.  See the Help Desk article in 
R News 4/1 for a discussion of the main classes and
see the table at the end of that article for various idioms which 
you may need.

zoo supports not only irregular but also weakly regular
series (zooreg class) which are ones that have an underlying 
regularity, e.g. hourly, monthly even though they may not
have every hour, month, etc. filled in.

zoo has a PDF manual available via (in R):

   library(zoo)
   vignette("zoo")

zoo can work together with the 'its' class and 'ts' class via as.zoo, 
as.its and as.ts.

> 
> I've installed and skimmed the documentation on both packages.  I was
> hoping to get a little guidance from the user community before
> proceeding further.
> 
> In case anyone is interested in my particular problem:  I'm looking
> at some (surface) temperature data from NOAA:  http://
> cdo.ncdc.noaa.gov/ulcd/ULCD
> It is (irregular) time series format.  The NOAA data reports year,
> month, date, hour, and minute.  I want to group the data into hourly
> chunks.  However, sometimes there are multiple observation per hour
> -- i.e an observation at 3:45 and 3:56.  Also, sometimes a particular
> hour may be missing altogether.  I need to clean up the data so that
> each hour has one and only one data point.



Using the chron date/time class here is an example:

library(chron)
library(zoo)

set.seed(1)

# create zoo series with random dates/times between tt0 and tt1 
# also random values
set.seed(1)
n <- 25
tt0 <- chron("01/01/90")
tt1 <- chron("01/01/00")
tt <- sort(as.numeric(tt1-tt0)*runif(n)+tt0)
z <- zoo(rnorm(n), tt)  # create zoo series from values and date/times

# aggregate by hour choosing first data point if there are mulitples.
# The arguments are (1) the zoo series (2) time rounded to the hour
# (3) aggregate function to use -- indexing in this case, (4) an
# argument to the indexing function -- in this case its 1 since
# we want the first element.  See ?aggregate.zoo
z.hr <- aggregate(z, chron(floor(24*as.numeric(tt))/24), "[", 1)

# plot hourly series, see ?plot.zoo
plot(z.hr) 

Packages with explicit support for zoo are strucchange, dynlm
and dyn.  (dyn also supports ts and its.)

> 
> I'm relatively new to R, but I think I'm getting a hold on it pretty
> well so far.  I used to do a lot with MATLAB, and there seem to be

Check out 
   http://cran.r-project.org/doc/contrib/R-and-octave-2.txt

> many parallels between it and R.  I have background in public policy
> and econometrics.

Check out
   http://cran.r-project.org/src/contrib/Views/



From joel3000 at gmail.com  Fri Aug 26 01:03:13 2005
From: joel3000 at gmail.com (Joel Bremson)
Date: Thu, 25 Aug 2005 16:03:13 -0700
Subject: [R] S3 class question
Message-ID: <1253d67a05082516037aa8a2e0@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050825/8416f643/attachment.pl

From ggrothendieck at gmail.com  Fri Aug 26 01:12:18 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 25 Aug 2005 19:12:18 -0400
Subject: [R] S3 class question
In-Reply-To: <1253d67a05082516037aa8a2e0@mail.gmail.com>
References: <1253d67a05082516037aa8a2e0@mail.gmail.com>
Message-ID: <971536df0508251612551bd76a@mail.gmail.com>

On 8/25/05, Joel Bremson <joel3000 at gmail.com> wrote:
> Hi,
> 
> I have a class called "spss" containing prepared info from an SPSS file.
> >...
> >class(ret) = "spss"
> >return(ret)
> The function that returns this defined in a file that I source into R.
> 
> Also in that file is a function matSummary.spss.
> 
> I think I ought to be able to call
> >matSummary(ret)
> 
> to run the function, but only
> >matSummary.spss(ret)
> 
> will work.
> 
> What am I doing wrong here? This seems like a simple problem
> yet I've been able to find nothing in the archives about this.

Methods have to have a corresponding generic to be called like that.
Assuming your method has a single argument called ret define this:

matSummary <- function(ret) UseMethod("matSummary")

When you call matSummary the UseMethod call will forward
it to the appropriate method depending on the class of the
first argument, ret.



From gunter.berton at gene.com  Fri Aug 26 01:12:13 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Thu, 25 Aug 2005 16:12:13 -0700
Subject: [R] S3 class question
In-Reply-To: <1253d67a05082516037aa8a2e0@mail.gmail.com>
Message-ID: <200508252312.j7PNCEGd001630@hertz.gene.com>

Have you defined matSummary() as a generic with UseMethod:

matSummary<-function(...)UseMethod('matSummary')


-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Joel Bremson
> Sent: Thursday, August 25, 2005 4:03 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] S3 class question
> 
> Hi,
> 
> I have a class called "spss" containing prepared info from an 
> SPSS file.
> >...
> >class(ret) = "spss"
> >return(ret)
> The function that returns this defined in a file that I source into R.
> 
> Also in that file is a function matSummary.spss.
> 
> I think I ought to be able to call 
> >matSummary(ret)
> 
> to run the function, but only 
> >matSummary.spss(ret)
> 
> will work.
> 
> What am I doing wrong here? This seems like a simple problem
> yet I've been able to find nothing in the archives about this.
> 
> 
> Joel
> 
> -- 
> Joel Bremson
> Graduate Student
> Institute for Transportation Studies - UC Davis
> http://etrans.blogspot.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From p.murrell at auckland.ac.nz  Fri Aug 26 01:37:13 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Fri, 26 Aug 2005 11:37:13 +1200
Subject: [R] problem building dendrograms to use with heatmap()
References: <B1D5C2D0D1D6AE4C9DF88E81330D71C60D9E4A@PHSXMB23.partners.org>
Message-ID: <430E5629.5070307@stat.auckland.ac.nz>

Hi


Wittner, Ben wrote:
> Hi,
> 
> I'm trying to build dendrograms to pass to heatmap().
> The dendrograms I build plot properly, but when I pass them to heatmap() I get
> the error message "row dendrogram ordering gave index of wrong length" (see
> output log below).


Looks like you're not building the dendrograms "properly".  Compare 
unclass(nr2) with unclass() of a dendrogram from 
as.dendrogram(hclust(<something>)).  You might need to look closely at 
stats:::as.dendrogram.hclust to get it right.

Paul


> I looked in the code of heatmap() and saw that the error was due to a NULL
> return value from order.dendrogram(), which in turn got a NULL return value from
> unlist(). But I have no idea why unlist() is returning NULL.
> 
> I've included code below which reproduces the problem and below that the output
> from a run of that code on my computer.
> 
> Any help would be greatly appreciated. Thanks in advance.
> 
> -Ben
> 
> ###########################  begin code  ###################################
> 
> version
> 
> dendro.leaf <- function(label) {
>   ans <- list()
>   attr(ans, 'members') <- 1
>   attr(ans, 'height') <- 0
>   attr(ans, 'leaf') <- T
>   attr(ans, 'midpoint') <- 0
>   attr(ans, 'label') <- label
>   attr(ans, 'class') <- 'dendrogram'
>   ans
> }
> 
> dendro.merge <- function(d1, d2, height) {
>   ans <- list(d1, d2)
>   members <- attr(d1, 'members') + attr(d2, 'members')
>   attr(ans, 'members') <- members
>   attr(ans, 'height') <- height
>   attr(ans, 'leaf') <- F
>   attr(ans, 'midpoint') <- (members - 1)/2
>   attr(ans, 'class') <- 'dendrogram'
>   ans
> }
> 
> lc1 <- dendro.leaf('c1')
> lc2 <- dendro.leaf('c2')
> lc3 <- dendro.leaf('c3')
> nc1 <- dendro.merge(lc1, lc2, 0.1)
> nc2 <- dendro.merge(nc1, lc3, 0.2)
> plot(nc2)
> 
> lr1 <- dendro.leaf('r1')
> lr2 <- dendro.leaf('r2')
> lr3 <- dendro.leaf('r3')
> nr1 <- dendro.merge(lr2, lr3, 0.1)
> nr2 <- dendro.merge(lr1, nr1, 0.3)
> plot(nr2)
> 
> x <- matrix(seq(-1, 1, length.out=9), nrow=3)
> rownames(x) <- paste('r', 1:3, sep='')
> colnames(x) <- paste('c', 1:3, sep='')
> 
> heatmap(x, Rowv=nr2, Colv=nc2, scale='none')
> 
> order.dendrogram(nr2)
> 
> unlist(nr2)
> 
> ###############  begin output from run of code above  ##################
> 
> 
>>version
> 
>          _                
> platform i686-pc-linux-gnu
> arch     i686             
> os       linux-gnu        
> system   i686, linux-gnu  
> status                    
> major    2                
> minor    1.1              
> year     2005             
> month    06               
> day      20               
> language R                
> 
>>dendro.leaf <- function(label) {
> 
> +   ans <- list()
> +   attr(ans, 'members') <- 1
> +   attr(ans, 'height') <- 0
> +   attr(ans, 'leaf') <- T
> +   attr(ans, 'midpoint') <- 0
> +   attr(ans, 'label') <- label
> +   attr(ans, 'class') <- 'dendrogram'
> +   ans
> + }
> 
>>dendro.merge <- function(d1, d2, height) {
> 
> +   ans <- list(d1, d2)
> +   members <- attr(d1, 'members') + attr(d2, 'members')
> +   attr(ans, 'members') <- members
> +   attr(ans, 'height') <- height
> +   attr(ans, 'leaf') <- F
> +   attr(ans, 'midpoint') <- (members - 1)/2
> +   attr(ans, 'class') <- 'dendrogram'
> +   ans
> + }
> 
>>lc1 <- dendro.leaf('c1')
>>lc2 <- dendro.leaf('c2')
>>lc3 <- dendro.leaf('c3')
>>nc1 <- dendro.merge(lc1, lc2, 0.1)
>>nc2 <- dendro.merge(nc1, lc3, 0.2)
>>plot(nc2)
>>
>>lr1 <- dendro.leaf('r1')
>>lr2 <- dendro.leaf('r2')
>>lr3 <- dendro.leaf('r3')
>>nr1 <- dendro.merge(lr2, lr3, 0.1)
>>nr2 <- dendro.merge(lr1, nr1, 0.3)
>>plot(nr2)
>>
>>x <- matrix(seq(-1, 1, length.out=9), nrow=3)
>>rownames(x) <- paste('r', 1:3, sep='')
>>colnames(x) <- paste('c', 1:3, sep='')
>>
>>heatmap(x, Rowv=nr2, Colv=nc2, scale='none')
> 
> Error in heatmap(x, Rowv = nr2, Colv = nc2, scale = "none") : 
>         row dendrogram ordering gave index of wrong length
> 
>>order.dendrogram(nr2)
> 
> NULL
> 
>>unlist(nr2)
> 
> NULL
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From ooo at buffalo.edu  Fri Aug 26 01:50:34 2005
From: ooo at buffalo.edu (Lanre Okusanya)
Date: Thu, 25 Aug 2005 19:50:34 -0400
Subject: [R] Plotting nls
In-Reply-To: <D45546375992BF429A93F7203358F14403429579@sirius.fccc.edu>
References: <D45546375992BF429A93F7203358F14403429579@sirius.fccc.edu>
Message-ID: <430E594A.3020602@buffalo.edu>

Kindly excuse a non-statistician newbie attempting to wrestle with R.

This might be a relatively easy question, but I am trying to perform nls 
regression and plot the fitted function through the data superimposed on 
the raw data. from reading the R-help, Rtips et al, I am only able to do 
that by extracting the parameter values manually and using it to create 
the plot.

Is there an easier way to do this,  (I have ~60 Plots), obtain an r^2,  
and also plot the x axis in the log domain (any attempts I have tried 
have screwed up).

NLS script

fit<- nls(y~-emax*x^h/(ec50^h+x^h),
       data= sample, start=list(emax=4,h=2,ec50=1))

summary(fit)

Thank you all for your help

Lanre Okusanya, Pharm.D.,BCPS
UB/Pfizer Pharmacometrics Fellow
University at Buffalo School of Pharmacy and Pharmaceutical Sciences
237 Cooke Hall
Buffalo, NY 14260
Email: ooo at buffalo.edu
Tel: (716)645-2828 x 275
Fax: (716)645-2886



From lug2002 at med.cornell.edu  Fri Aug 26 02:31:30 2005
From: lug2002 at med.cornell.edu (Luis Gracia)
Date: Thu, 25 Aug 2005 20:31:30 -0400
Subject: [R] Fitting data to gaussian distributions
Message-ID: <430E62E2.1050809@med.cornell.edu>

Hi!

I need to fit a data that shows up as two gaussians partially
superimposed to the corresponding gaussian distributions, i.e.

data=c(rnorm(100,5,2),rnorm(100,-6,1))

I figured it out how to do it with mle or fitdistr when only one
gaussian is necessary, but not with two or more. Is there a function in
R to do this?

Thank you very much in advance,

Luis



From gerifalte28 at hotmail.com  Fri Aug 26 02:38:20 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Fri, 26 Aug 2005 00:38:20 +0000
Subject: [R] Plotting nls
In-Reply-To: <430E594A.3020602@buffalo.edu>
Message-ID: <BAY103-F40295296CFDD751BECDB68A6AA0@phx.gbl>


Review the code in example(predict.nls)

For the R squared question check on this thread 
http://finzi.psych.upenn.edu/R/Rhelp02a/archive/51678.html

Cheers

Francisco

>From: Lanre Okusanya <ooo at buffalo.edu>
>Reply-To: ooo at buffalo.edu
>To: "'r-help at stat.math.ethz.ch'" <r-help at stat.math.ethz.ch>
>Subject: [R] Plotting nls
>Date: Thu, 25 Aug 2005 19:50:34 -0400
>
>Kindly excuse a non-statistician newbie attempting to wrestle with R.
>
>This might be a relatively easy question, but I am trying to perform nls
>regression and plot the fitted function through the data superimposed on
>the raw data. from reading the R-help, Rtips et al, I am only able to do
>that by extracting the parameter values manually and using it to create
>the plot.
>
>Is there an easier way to do this,  (I have ~60 Plots), obtain an r^2,
>and also plot the x axis in the log domain (any attempts I have tried
>have screwed up).
>
>NLS script
>
>fit<- nls(y~-emax*x^h/(ec50^h+x^h),
>        data= sample, start=list(emax=4,h=2,ec50=1))
>
>summary(fit)
>
>Thank you all for your help
>
>Lanre Okusanya, Pharm.D.,BCPS
>UB/Pfizer Pharmacometrics Fellow
>University at Buffalo School of Pharmacy and Pharmaceutical Sciences
>237 Cooke Hall
>Buffalo, NY 14260
>Email: ooo at buffalo.edu
>Tel: (716)645-2828 x 275
>Fax: (716)645-2886
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From lug2002 at med.cornell.edu  Fri Aug 26 03:43:58 2005
From: lug2002 at med.cornell.edu (Luis Gracia)
Date: Thu, 25 Aug 2005 21:43:58 -0400
Subject: [R] Fitting data to gaussian distributions
In-Reply-To: <430E62E2.1050809@med.cornell.edu>
References: <430E62E2.1050809@med.cornell.edu>
Message-ID: <430E73DE.9080902@med.cornell.edu>

Hi again,

self-answered. I took a breath and started another google search, this
time more successful. I found the following packages in case somebody
has the same question:
nor1mix
wle
mixdist    (I found this one to be the most useful in my case)

Best,

Luis

Luis Gracia said the following on 08/25/05 20:31:
> Hi!
> 
> I need to fit a data that shows up as two gaussians partially
> superimposed to the corresponding gaussian distributions, i.e.
> 
> data=c(rnorm(100,5,2),rnorm(100,-6,1))
> 
> I figured it out how to do it with mle or fitdistr when only one
> gaussian is necessary, but not with two or more. Is there a function in
> R to do this?
> 
> Thank you very much in advance,
> 
> Luis
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From spencer.graves at pdf.com  Fri Aug 26 06:29:08 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Thu, 25 Aug 2005 21:29:08 -0700
Subject: [R] How to create design matrix for LLMNL?
In-Reply-To: <20050819123019.69172A4C817@much-magic.wiwi.uni-frankfurt.de>
References: <20050819123019.69172A4C817@much-magic.wiwi.uni-frankfurt.de>
Message-ID: <430E9A94.2060208@pdf.com>

	  I haven't seen a reply to this, so I will attempt a few comments.  If 
you've already received an adequate reply, please excuse my tardy 
comments.

	  1.  It is generally not wise to use the name of a standard S / R 
function for a data.frame.  Please type "df" at a command prompt to see 
what you get.  In this case, this is probably not creating problems for 
you, but it might in other contexts.

	  2.  Did you try the examples in the help file for "createX" in 
library(bayesm)?  If no, I suggest you do so.  If yes, I suggest you 
examine carefully your call to "createX" in comparison with the examples 
and the rest of the documentation.

	  3.  If you still have a question, please submit another post after 
(re)reading posting guide! 
"http://www.R-project.org/posting-guide.html".  You may think you 
already did this.  However, 289 observations in an attached file is not, 
for me at least, a toy example within the spirit of the posting guide. 
That posting guide is not intended to be a burocratic obstacle.  It was 
written to help people get quicker answers to their questions.  When 
followed, I believe it succeeds fairly well.  To me it is roughly like 
the famous book by George P??lya on "How to Solve It", which I also 
highly recommend.

	  Viel Glueck!
	  spencer graves	

Tetyana Stepanchuk wrote:

> Hello, 
> 
>  
> 
> I have a small problem with developing design matrix X, which I use in
> estimation the log-likelihood of a multinomial logit model.
> 
>  
> 
> I have the data: 
> 
>  number of observation - 289
> 
> number of choice alternative- 3
> 
> number of choice specific variables in matrix X -4
> 
> matrix X =289x4
> 
> I tried to use the function createX, I know that I have to get design matrix
> 289x12 (am I right?) but it always says "bad dim" (my code and data in
> attachment)
> 
>  
> 
> Where is my fault? Can I use another method in order to create design
> matrix? 
> 
> Or need it at all here in logmnl (see code in attachment)?
> 
>  
> 
> Can anyone help me with this issue?
> 
>  
> 
> Thanks in advance,
> 
> Tatyana
> 
>  
> 
>  
> 
> 
> 
> ------------------------------------------------------------------------
> 
>>df=read.table("data.dat",header=TRUE)
>>inp=as.matrix(df)
> 
>     Y X1 X2   X3       X4
> 1   1  1  1   65 20999.89
> 2   1  1  2   67  2719.60
> 3   1  1  3  110  3581.09
> 4   1  1  4   64  1731.63
> 5   1  1  5   84  4434.97
> 6   1  6  1   90   691.32
> 7   1  6  2   31   228.50
> 8   1  6  3   33   615.12
> 9   1  6  4   39   910.62
> 10  1  7  1  169  1246.75
> 11  1  7  2  183  1183.03
> 12  1  7  3  203  1345.32
> 13  1  7  4  177  1088.98
> 14  1  7  5  169   896.42
> 15  1  8  1   71  1264.57
> 16  1  8  2   80  1094.40
> 17  1  8  3   75  1715.99
> 18  1  8  4   55   905.37
> 19  1  8  5   67  1448.17
> 20  1 10  1  349  1396.77
> 21  1 10  2  666  2026.89
> 22  1 10  3  480   774.37
> 23  1 10  4  456  1972.15
> 24  1 11  1  500   245.88
> 25  1 11  2  288  2927.77
> 26  1 11  3  211  9221.67
> 27  1 11  4  206  5632.91
> 28  1 11  5  175  1636.62
> 29  1 12  1  107   857.06
> 30  1 12  2   87   789.25
> 31  1 12  3  103   856.27
> 32  1 12  4  377   933.74
> 33  1 12  5  229  1316.31
> 34  1 13  1   32   149.13
> 35  1 13  2   19   153.74
> 36  1 13  3   25   179.60
> 37  1 13  4   28   252.70
> 38  1 13  5   22   294.80
> 39  1 14  1   47  1261.82
> 40  1 14  2   19  2332.21
> 41  1 15  1  348   558.91
> 42  1 15  2  399   550.91
> 43  1 15  3  388   797.68
> 44  1 15  4  208   804.76
> 45  1 15  5  241   673.12
> 46  1 17  1   70   151.06
> 47  1 17  2   96   255.22
> 48  1 17  3  102  1220.30
> 49  1 17  4  128   793.54
> 50  1 18  3   10   134.95
> 51  1 18  4   28   992.30
> 52  1 21  1   85  1170.71
> 53  1 21  2  257   464.95
> 54  1 21  3  353   404.21
> 55  1 21  4  293   517.64
> 56  1 21  5  515  1202.68
> 57  1 22  1   66   372.89
> 58  1 22  2   79   498.70
> 59  1 22  3   47   304.83
> 60  1 22  4   48   430.03
> 61  1 22  5   52   319.86
> 62  1 23  1   14   165.28
> 63  1 23  2   35  2044.52
> 64  1 23  3   20   499.59
> 65  1 24  1   94   107.76
> 66  1 24  2   59    61.64
> 67  1 24  3   47   111.15
> 68  1 24  4   32   100.75
> 69  1 25  1   17   142.34
> 70  1 26  1  144  1105.71
> 71  1 26  2  196  1445.43
> 72  1 26  3  328  2297.11
> 73  1 26  4  517  2143.55
> 74  1 27  1   85  2457.58
> 75  1 27  2   99  1921.27
> 76  1 27  3   65  3380.86
> 77  1 27  4   88  2218.37
> 78  1 27  5  100  1881.00
> 79  1 29  1  107   561.27
> 80  1 29  2   67   557.43
> 81  1 29  3   49   387.71
> 82  1 30  1   77   106.50
> 83  1 30  2  225   267.87
> 84  1 30  3  520   502.18
> 85  1 30  4  552   443.07
> 86  1 30  5  319   255.50
> 87  1 31  1   38  6522.32
> 88  1 31  2   38   632.35
> 89  1 31  3   50  1615.18
> 90  1 31  4   53  1657.59
> 91  1 31  5   25   425.01
> 92  1 32  1   82   681.77
> 93  1 32  2   82   605.14
> 94  1 32  3  117  1068.86
> 95  1 32  4   90   638.95
> 96  1 33  1   53   350.89
> 97  1 33  2   39   378.53
> 98  1 33  3   44   432.31
> 99  1 34  1   61   752.13
> 100 1 34  2   76  1045.36
> 101 1 34  3  107  1344.42
> 102 1 34  4   65  1150.82
> 103 1 34  5   96   973.69
> 104 1 35  1  132   374.06
> 105 1 35  2  124   444.83
> 106 1 35  3   92   142.01
> 107 1 35  4   69   297.77
> 108 1 35  5   62   248.21
> 109 1 36  1  434   374.83
> 110 1 36  2  183   416.23
> 111 1 36  3  386   246.27
> 112 1 36  4  577   527.44
> 113 1 36  5  457   250.67
> 114 1 37  1  118  2306.72
> 115 1 37  2  169  1303.34
> 116 1 37  3  135  1741.13
> 117 1 37  4  103  1073.17
> 118 1 37  5   75  1146.11
> 119 1 40  1   66  1447.20
> 120 1 40  2   97  1352.28
> 121 1 40  3   65  1786.57
> 122 1 40  4   67  1060.59
> 123 1 42  1   26   241.23
> 124 1 42  2   43   334.35
> 125 1 42  3   65   381.51
> 126 1 42  4    9    33.14
> 127 1 43  1   39  1504.44
> 128 1 43  2   33  1144.56
> 129 1 43  3   43   870.53
> 130 1 43  4   43   969.19
> 131 1 43  5   64  1655.93
> 132 1 44  1    2  1555.55
> 133 1 45  1   22    84.39
> 134 1 46  1   46   996.07
> 135 1 46  2   33   777.97
> 136 1 46  3   60   637.64
> 137 1 46  4   42  1178.10
> 138 1 46  5   41  1054.84
> 139 1 47  1   37  1514.12
> 140 1 47  2   57  2132.21
> 141 1 47  3   53  2486.14
> 142 1 47  4   45  1807.57
> 143 1 47  5   45  1125.80
> 144 1 48  1   90   449.87
> 145 1 48  2   12    86.38
> 146 1 48  3   44   159.58
> 147 1 48  4   42   372.35
> 148 1 48  5   58   442.60
> 149 1 49  1   92   645.82
> 150 1 49  2   82   523.96
> 151 1 49  3  132   833.91
> 152 1 49  4  125   490.37
> 153 1 49  5   89   454.82
> 154 1 50  1   30   105.94
> 155 1 50  2   29    39.18
> 156 1 50  3   80    16.13
> 157 1 50  4  185   106.54
> 158 1 51  1   95   937.76
> 159 1 51  2   34  1212.81
> 160 1 51  3   42  1254.46
> 161 1 51  4   35   644.77
> 162 1 51  5   36   426.90
> 163 1 52  1   42   138.73
> 164 1 54  1  210  1841.15
> 165 1 56  1   29   191.12
> 166 1 56  2   56   640.55
> 167 1 56  3   62   562.07
> 168 1 56  4   47   290.71
> 169 1 56  5   34   314.87
> 170 1 57  1   23   478.82
> 171 1 59  1   89   812.66
> 172 1 59  2   59   797.46
> 173 1 59  3   45   769.12
> 174 1 59  4   36   609.01
> 175 1 59  5   49   734.39
> 176 1 60  1   18   162.35
> 177 1 60  2   31   273.38
> 178 1 60  3   43   293.07
> 179 1 60  4   32   532.20
> 180 1 60  5   47   343.64
> 181 1 61  1   88  1193.72
> 182 1 61  2   25   680.30
> 183 1 61  3   55   734.33
> 184 1 61  4  146  1309.36
> 185 1 61  5  130   530.16
> 186 1 62  1   66   284.50
> 187 1 62  2   30   278.39
> 188 1 62  3   26   160.81
> 189 1 64  1  234  1257.18
> 190 1 64  2  133   752.41
> 191 1 64  3  141   476.03
> 192 1 64  4  202   836.94
> 193 1 64  5  122  1979.26
> 194 1 67  1   34   153.57
> 195 1 67  2   26    83.32
> 196 1 67  3   32   238.91
> 197 1 67  4   65   348.97
> 198 1 67  5   38   199.38
> 199 1 69  1   43   266.88
> 200 1 69  2   53  1497.83
> 201 1 69  3   48  2115.32
> 202 1 69  4   46  1323.33
> 203 1 69  5   72  2097.16
> 204 1 70  1  401    87.66
> 205 1 70  2  177    80.05
> 206 1 70  3   81   105.75
> 207 1 70  4   43    50.32
> 208 1 70  5   23    55.21
> 209 3 38  1   40 17345.50
> 210 3 38  2   37 19927.04
> 211 3 38  3   42   742.45
> 212 3 53  1  181 14189.78
> 213 3 53  2   75 15132.94
> 214 3 53  3   91 14927.05
> 215 3 55  1  239 40056.22
> 216 3 55  2  798 11436.61
> 217 3 55  3  284  3031.93
> 218 3 55  4   37  1162.11
> 219 3 55  5   58  6458.99
> 220 3 65  1   41  2928.30
> 221 3 65  2   45  2447.31
> 222 3 65  3   46  2504.06
> 223 3 65  4   41  2865.30
> 224 3 65  5   41  5404.57
> 225 3 71  1   56 17897.50
> 226 2  2  1   68  2481.72
> 227 2  3  1  168  1794.23
> 228 2  3  2  164  2401.75
> 229 2  3  3  139  2229.82
> 230 2  3  4  152  2865.10
> 231 2  3  5  135  3157.92
> 232 2  4  1   37  1990.07
> 233 2  4  2   33  4441.53
> 234 2  4  3   38  2972.56
> 235 2  4  4   38  3050.71
> 236 2  4  5   27  2326.24
> 237 2  5  1  133  6481.32
> 238 2  5  2   36  2064.21
> 239 2  5  3  165  5431.46
> 240 2  5  4  131  5632.18
> 241 2  5  5   65  4805.79
> 242 2  9  1   58   295.27
> 243 2  9  2  118  4501.84
> 244 2  9  3  128   438.22
> 245 2 16  1  281  1194.92
> 246 2 16  2  227  1344.28
> 247 2 16  3  237  1027.02
> 248 2 16  4  265  1113.11
> 249 2 16  5  143  1080.23
> 250 2 18  1   34  3465.32
> 251 2 18  2   31  1879.28
> 252 2 19  1  126  1125.53
> 253 2 19  2   96  3269.87
> 254 2 20  1   42  4572.29
> 255 2 20  2   56  4020.63
> 256 2 20  3   53    94.82
> 257 2 20  4   69  2959.03
> 258 2 20  5   62  1145.52
> 259 2 28  1  106   877.37
> 260 2 28  2  139  1495.15
> 261 2 28  3  278  1170.82
> 262 2 28  4   52  3838.59
> 263 2 39  1  165  6277.17
> 264 2 39  2  117  1565.52
> 265 2 39  3   91  3096.30
> 266 2 39  4   93  2038.49
> 267 2 41  1  151  3657.07
> 268 2 41  2  169  4371.29
> 269 2 41  3  171  3543.19
> 270 2 41  4   82  2762.35
> 271 2 41  5   59  5054.83
> 272 2 58  1   96  6062.83
> 273 2 58  2   53  3730.32
> 274 2 58  3   24  1044.85
> 275 2 58  4    4  1000.44
> 276 2 58  5    0  1144.44
> 277 2 63  1  130   145.73
> 278 2 63  2   82   264.27
> 279 2 63  3  115   219.01
> 280 2 63  4  158   199.87
> 281 2 63  5  115   286.83
> 282 2 66  1  218  7964.96
> 283 2 66  2  198  4512.50
> 284 2 66  3  169  4954.49
> 285 2 68  1 3025  1494.90
> 286 2 68  2 3333  1355.09
> 287 2 68  3 3969  1848.35
> 288 2 68  4 3059  1506.72
> 289 2 68  5 4557  2339.48
> 
>>y=as.numeric(inp[,1])
>>Xa=matrix(inp[,2:5],byrow=TRUE,ncol=3)
> 
> Xa=cbind(Xa,-Xa)
> 
>>X=createX(p=nsize,na=nxvar,Xa=Xa,nd=NULL,Xd=NULL,INT=TRUE)
> 
> Fehler: bad Xa dim, dim= 386bad Xa dim, dim= 6
> 
> 
> 
> 
> 
> ------------------------------------------------------------------------
> 
> logmnl<- function(X,y,nsize,nxvar,nhh,beta){
> #Function evaluates the log-likelihood of multinimial logit model
> #X is of dimension X(nsize,nxvar,nhh) and y(nsize,nhh)
> # nsize=number of alternatives
> # nxvar=number of x variables
> # nhh=number of observations
> df=read.table("TS_3part.dat",header=TRUE)
> inp=as.matrix(df)
> y=as.numeric(inp[,1])
> + nsize=3
> + nxvar=4
> + nhh=length(y)
> X=createX(p=p,na=1,Xa=data[,3:8],nd=NULL,Xd=NULL,INT=TRUE,base=1)
> + xp<-array(0,dim=c(nsize))
> + logprob<-0
> + for(i in 1:nhh)
> + {
> + for(j in 1:nsize)
> + {
> + xp[j]<-exp(t(X[j,,i]) %*% beta)
> + }
> + denom=sum(xp)
> + for(j in 1:nsize)
> + {
> + if(y[j,i]==1) prob=xp[j]/denom
> + }
> + logprob=logprob+log(prob)
> + }
> + logprob
> + }
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From ajayshah at mayin.org  Fri Aug 26 07:37:05 2005
From: ajayshah at mayin.org (Ajay Narottam Shah)
Date: Fri, 26 Aug 2005 11:07:05 +0530
Subject: [R] update.packages() is broken?
Message-ID: <20050826053705.GU448@lubyanka.local>

Folks,

I am using R 2.1.1 on Apple OS X 10.3.

Earlier, I used to say

$ sudo R
> update.packages() 

and all the packages used to get installed. 

For several weeks, I noticed that nothing has been coming through. I
used the R-for-Mac graphics console and I find that there are many
packages where new versions have come out which I don't have. Is
something wrong with update.packages()?

I also noticed that the CRAN Task Views function update.ctv() 

> update.ctv <- function(view, force.bundles = FALSE) {
    f <- function(x) if (x[1] == view) x$packagelist$name
    ctv.pkgs <- unlist( sapply( CRAN.views(), f) )
    idx <- if (force.bundles) 1 else c(1,5)
    installed.pkgs <- c(installed.packages()[,idx])
    dnld.packages <- setdiff(ctv.pkgs, installed.pkgs)
    install.packages(dnld.packages, dependencies = TRUE)
    update.packages()
  }

misbehaves, perhaps because it's internally using update.packages()?

-- 
Ajay Shah                                                   Consultant
ajayshah at mayin.org                      Department of Economic Affairs
http://www.mayin.org/ajayshah           Ministry of Finance, New Delhi



From ripley at stats.ox.ac.uk  Fri Aug 26 08:17:55 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 07:17:55 +0100 (BST)
Subject: [R] update.packages() is NOT broken?
In-Reply-To: <20050826053705.GU448@lubyanka.local>
References: <20050826053705.GU448@lubyanka.local>
Message-ID: <Pine.LNX.4.61.0508260708420.11887@gannet.stats>

Please use a less contentious subject.  This is discourteous to the people 
who gave you update.packages().

If you had bothered to look, you would have seen that

http://cran.r-project.org/bin/macosx/2.1

was last updated on 14 July.  Thus the issue is that the binary builds for 
MacOS X have not been updated recently. You can of course change your 
defaults so R uses source packages and you will get all the updates (if 
you have the tools to install such packages). Alternatively, you could 
report the problem to the proper place.

On Fri, 26 Aug 2005, Ajay Narottam Shah wrote:

> Folks,
>
> I am using R 2.1.1 on Apple OS X 10.3.
>
> Earlier, I used to say
>
> $ sudo R
>> update.packages()
>
> and all the packages used to get installed.
>
> For several weeks, I noticed that nothing has been coming through. I
> used the R-for-Mac graphics console and I find that there are many
> packages where new versions have come out which I don't have. Is
> something wrong with update.packages()?
>
> I also noticed that the CRAN Task Views function update.ctv()
>
>> update.ctv <- function(view, force.bundles = FALSE) {
>    f <- function(x) if (x[1] == view) x$packagelist$name
>    ctv.pkgs <- unlist( sapply( CRAN.views(), f) )
>    idx <- if (force.bundles) 1 else c(1,5)
>    installed.pkgs <- c(installed.packages()[,idx])
>    dnld.packages <- setdiff(ctv.pkgs, installed.pkgs)
>    install.packages(dnld.packages, dependencies = TRUE)
>    update.packages()
>  }
>
> misbehaves, perhaps because it's internally using update.packages()?

Please do read the posting guide and learn from its advice.  What does 
`misbehaves' mean?

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Aug 26 08:23:21 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 07:23:21 +0100 (BST)
Subject: [R] Quick partitioning
In-Reply-To: <430E3E62.2040407@niss.org>
References: <430E3E62.2040407@niss.org>
Message-ID: <Pine.LNX.4.61.0508260718520.11887@gannet.stats>

On Thu, 25 Aug 2005, Anna Oganyan wrote:

> Hello,
> I am quite new in R, and  I have one problem:
> I have large d-dimensional data sets (d=2, 3, 6, 10). I would like to
> divide the d-dim space into n (n may be 10, but better some larger
> number, for example 20) equally sized d-dim hypercubes  and count  how
> many data points are in each cube. Is there any way to do  it quickly, I
> mean - in a reasonable time? Actually, I  want  to get some rough idea
> of underlying densities of these data and compare them.
> Thanks a lot!
> Anna

How do you divide a 10D space into 10 hypercubes?  You need at least 
some of dimensions to be undivided.

The general idea is easy: apply cut() to each dimension, so your 
dimensions become factors, then table() will produce the counts.  That 
will be quick enough for millions of points.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Aug 26 08:25:14 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 07:25:14 +0100 (BST)
Subject: [R] Fitting data to gaussian distributions
In-Reply-To: <430E73DE.9080902@med.cornell.edu>
References: <430E62E2.1050809@med.cornell.edu>
	<430E73DE.9080902@med.cornell.edu>
Message-ID: <Pine.LNX.4.61.0508260724521.11887@gannet.stats>

See also the book MASS, the one fitdistr supports.

On Thu, 25 Aug 2005, Luis Gracia wrote:

> Hi again,
>
> self-answered. I took a breath and started another google search, this
> time more successful. I found the following packages in case somebody
> has the same question:
> nor1mix
> wle
> mixdist    (I found this one to be the most useful in my case)
>
> Best,
>
> Luis
>
> Luis Gracia said the following on 08/25/05 20:31:
>> Hi!
>>
>> I need to fit a data that shows up as two gaussians partially
>> superimposed to the corresponding gaussian distributions, i.e.
>>
>> data=c(rnorm(100,5,2),rnorm(100,-6,1))
>>
>> I figured it out how to do it with mle or fitdistr when only one
>> gaussian is necessary, but not with two or more. Is there a function in
>> R to do this?
>>
>> Thank you very much in advance,
>>
>> Luis
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Aug 26 08:32:28 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 07:32:28 +0100 (BST)
Subject: [R] question about coxph (was covariance matrix under null)
In-Reply-To: <D45546375992BF429A93F7203358F14403429579@sirius.fccc.edu>
References: <D45546375992BF429A93F7203358F14403429579@sirius.fccc.edu>
Message-ID: <Pine.LNX.4.61.0508260726270.11887@gannet.stats>

You will need to tell us of _what_ you want the covariance matrix and what 
you mean by the `null hypothesis':  coxph does estimation, not testing.

If you want the covariance matrix of the parameter estimates, see vcov(), 
which has a coxph method.

On Thu, 25 Aug 2005, Devarajan, Karthik wrote:

>
> Hello
>
> I am fitting a Cox PH model using the function coxph(). Does anyone know how
> to obtain the estimate of the covariance matrix under the null hypothesis.
> The function coxph.detail() does not seem to be useful for this purpose.
>
> Thanks,
> KD.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

PLEASE do (no HTML mail, useful subject, please)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From maechler at stat.math.ethz.ch  Fri Aug 26 09:05:19 2005
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 26 Aug 2005 09:05:19 +0200
Subject: [R] Help about R
In-Reply-To: <p0621020cbf338c41a8e9@[128.115.153.6]>
References: <430DCDB0.3050809@sti.lu> <p0621020cbf338c41a8e9@[128.115.153.6]>
Message-ID: <17166.48943.497375.305699@stat.math.ethz.ch>

>>>>> "Don" == Don MacQueen <macq at llnl.gov>
>>>>>     on Thu, 25 Aug 2005 08:11:42 -0700 writes:

    Don> Also, for the three dimensional graphic,
    Don> help.search("3d")
    Don> will lead to a reference to the cloud() function in the lattice package.

    Don> I don't remember if the lattice package is installed by default. 

it is, since it's recommended.
In such a situation (as in quite a few others), please consider
using

  > packageDescription("lattice")

  Package: lattice
  Version: 0.12-5
  Date: 2005/08/16
  Priority: recommended <<<<<<<<<<<
  ^^^^^^^^^^^^^^^^^^^^^^
  Title: Lattice Graphics
  Author: Deepayan Sarkar <deepayan.sarkar at r-project.org>
  ........................
  ........................

where I've added the <<<<<<<< and ^^^^ markup.

    Don> If not, you will have to install it.



From petr.pikal at precheza.cz  Fri Aug 26 09:49:10 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 26 Aug 2005 09:49:10 +0200
Subject: [R] A. Mani : Tapply
In-Reply-To: <a6821d990508250758301945ed@mail.gmail.com>
Message-ID: <430EE596.27107.4982F8@localhost>



From lzhtom at hotmail.com  Fri Aug 26 09:56:28 2005
From: lzhtom at hotmail.com (zhihua li)
Date: Fri, 26 Aug 2005 07:56:28 +0000
Subject: [R] learning decision trees with one's own scoring functins
Message-ID: <BAY23-F18B50C711645ADA08236CCC7AA0@phx.gbl>

Hi netters,

I want to learn a decision tree from a series of instances (learning data). 
The packages
tree or rpart can do this quite well, but the scoring functions (splitting 
criteria) are
fixed in these packages, like gini or something. However, I'm going to use 
another scoring
function. 

At first I wanna modify the R code of tree or rpart and put my own scoring 
function in. But it seems that tree and rpart perform the splitting 
procedure by calling external C functions, which I have no access to. So do 
I have to write R code from scratch to build the tree with my own scoring 
functions? It's a really tough task. Or r there other R packages that can 
do similar things with more flexible and extensible code?

Thanks a lot!



From phgrosjean at sciviews.org  Fri Aug 26 10:14:49 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Fri, 26 Aug 2005 10:14:49 +0200
Subject: [R] learning decision trees with one's own scoring functins
In-Reply-To: <BAY23-F18B50C711645ADA08236CCC7AA0@phx.gbl>
References: <BAY23-F18B50C711645ADA08236CCC7AA0@phx.gbl>
Message-ID: <430ECF79.5040800@sciviews.org>

Hello,

You have access to the C code of the function in the *source* of the
package. You can modify it and recompile the package and function (its
better then to give a different name!).
Best,

Philippe Grosjean

..............................................<¡ã}))><........
 ) ) ) ) )
( ( ( ( (    Prof. Philippe Grosjean
 ) ) ) ) )
( ( ( ( (    Numerical Ecology of Aquatic Systems
 ) ) ) ) )   Mons-Hainaut University, Pentagone (3D08)
( ( ( ( (    Academie Universitaire Wallonie-Bruxelles
 ) ) ) ) )   8, av du Champ de Mars, 7000 Mons, Belgium
( ( ( ( (
 ) ) ) ) )   phone: + 32.65.37.34.97, fax: + 32.65.37.30.54
( ( ( ( (    email: Philippe.Grosjean at umh.ac.be
 ) ) ) ) )
( ( ( ( (    web:   http://www.umh.ac.be/~econum
 ) ) ) ) )          http://www.sciviews.org
( ( ( ( (
..............................................................

zhihua li wrote:
> Hi netters,
> 
> I want to learn a decision tree from a series of instances (learning 
> data). The packages
> tree or rpart can do this quite well, but the scoring functions 
> (splitting criteria) are
> fixed in these packages, like gini or something. However, I'm going to 
> use another scoring
> function.
> At first I wanna modify the R code of tree or rpart and put my own 
> scoring function in. But it seems that tree and rpart perform the 
> splitting procedure by calling external C functions, which I have no 
> access to. So do I have to write R code from scratch to build the tree 
> with my own scoring functions? It's a really tough task. Or r there 
> other R packages that can do similar things with more flexible and 
> extensible code?
> 
> Thanks a lot!
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From mail at bymouth.com  Fri Aug 26 10:15:04 2005
From: mail at bymouth.com (Stephen Choularton)
Date: Fri, 26 Aug 2005 18:15:04 +1000
Subject: [R] chisq.,test`
Message-ID: <000001c5aa16$47325310$9701a8c0@Tablet>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050826/82e943b0/attachment.pl

From tmlammail at yahoo.com  Fri Aug 26 10:15:35 2005
From: tmlammail at yahoo.com (Martin Lam)
Date: Fri, 26 Aug 2005 01:15:35 -0700 (PDT)
Subject: [R]  Truncate levels to use randomForest
Message-ID: <20050826081535.39643.qmail@web40521.mail.yahoo.com>

Hi,

I will explain my problem with this example:

library("randomForest")

# load the iris plant data set
dataset <- iris

numberarray <- array(1:nrow(dataset), nrow(dataset),
1)

# include only instances with Species = setosa or
virginica
indices <- t(numberarray[(dataset$Species == "setosa"
| 
dataset$Species == "virginica") == TRUE])

finaldataset <- dataset[indices,]

# just to let you see the 3 classes
levels(finaldataset$Species)

# create the random forest
randomForest(formula = Species ~ ., data =
finaldataset, ntree = 5)

# The error message I get
Error in randomForest.default(m, y, ...) : 
        Can't have empty classes in y.

#The problem is that the finaldataset doesn't contain
#any instances of "versicolor", so I think the only
way #to solve this problem is by changing the levels
the #"Species" have to only "setosa" and "virginica",
# correct me if I'm wrong.

# So I tried to change the levels but I got stuck:

# get the possible unique classes
uniqueItems <- unique(levels(finaldataset$Species))

# the problem!
newlevels <- list(uniqueItems[1] = c(uniqueItems[1],
uniqueItems[2]), uniqueItems[3] = uniqueItems[3])

# Error message
Error: syntax error

# In the help they use constant names to rename the
#levels, so this works (but that's not what I want
#because I don't want to change the code every time I
#use another data set):
newlevels <- list("setosa" = c(uniqueItems[1],
uniqueItems[2]), "virginica" = uniqueItems[3])

levels(finaldataset$Species) <- newlevels

levels(finaldataset$Species)

finaldataset$Species

---------------------------

Thanks in advance,

Martin



From petr.pikal at precheza.cz  Fri Aug 26 10:23:43 2005
From: petr.pikal at precheza.cz (Petr Pikal)
Date: Fri, 26 Aug 2005 10:23:43 +0200
Subject: [R] A. Mani : Tapply
Message-ID: <430EEDAF.20050.6922EA@localhost>

Hi 


> PLEASE do read the posting guide! 
****************************** 

On 25 Aug 2005 at 20:28, A Mani wrote: 

> Hello, 
>         Is it safe to use tapply when the result will be of dim 20000 
> x 10000 or more ? In my PC R crashes.  

or gave you an error message? 

I tried this 

> df<-data.frame(A=as.factor(sample(1:10000,100000,  
replace=T)),B=as.factor(sample(100000:110000,100000,  
replace=T)), num=rnorm(100000)) 
> ttt<-tapply(df$num, list(df$A,df$B), diff) 

and got 

Error: cannot allocate vector of size 390664 Kb 
In addition: Warning messages: 
1: Reached total allocation of 1000Mb: see help(memory.size)  
2: Reached total allocation of 1000Mb: see help(memory.size)  
> 

and the result with smaller data sets are 

df1<-data.frame(A=as.factor(sample(1:2,100000, 
replace=T)),B=as.factor(sample(10:11,100000, replace=T)), 
num=rnorm(100000)) 
ttt1<-tapply(df1$num, list(df1$A,df1$B), diff) 

> ttt1 
  10            11            
1 Numeric,24933 Numeric,25141 
2 Numeric,24992 Numeric,24930 


df<-data.frame(A=as.factor(sample(1:1000,100000, 
replace=T)),B=as.factor(sample(10000:11000,100000, 
replace=T)), num=rnorm(100000)) 
 ttt<-tapply(df$num, list(df$A,df$B), diff) 


> 
> ttt[1:2,1:5] 
  10000 10001 10002 10003     10004 
1 NULL  NULL  NULL  Numeric,0 NULL  
2 NULL  NULL  NULL  Numeric,0 NULL  
> 

so you are probably receiving humonguous table of NULLs, zeros  
and few nonzero entries. 

You probably need to use different approach 

Cheers 
Petr 


The code used was on a 3-col 
> data frame with two factor cols and a numeric column. The fn 
was diff 
> . data form being <A, B, Num> tapply(data$A, list(data$A, 
data$B), 
> diff) 
>  
> --  
> A. Mani 
> Member, Cal. Math. Soc 
>  
> ______________________________________________ 
> R-help at stat.math.ethz.ch mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html 

Petr Pikal
petr.pikal at precheza.cz



From gavin.simpson at ucl.ac.uk  Fri Aug 26 10:51:35 2005
From: gavin.simpson at ucl.ac.uk (Gavin Simpson)
Date: Fri, 26 Aug 2005 09:51:35 +0100
Subject: [R] chisq.,test`
In-Reply-To: <000001c5aa16$47325310$9701a8c0@Tablet>
References: <000001c5aa16$47325310$9701a8c0@Tablet>
Message-ID: <1125046295.4219.9.camel@gsimpson.geog.ucl.ac.uk>

On Fri, 2005-08-26 at 18:15 +1000, Stephen Choularton wrote:
> Hi
>  
>  I am trying to do this:

I get no syntax error on R 2.1.1-patched. I do get an error though:

Error in chisq.test(c(11, 13, 12, 18, 21, 43, 15, 12, 9, 10, 5, 28,
22,  :
        probabilities must sum to 1.

Which leads us to question the values you provided as argument p (which
I assigned to a vector P first)

sum(P)
[1] 0.999783

So you need to make sure your probabilities add sum to one.

HTH

Ps. It would have been helpful if you'd posted the syntax error you
received and your version of R - type version at the R prompt.

Gav

<snip> 
> but I keep on getting syntax error.  Is this to long, or somehow badly
> formed?
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
-- 
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%
Gavin Simpson                     [T] +44 (0)20 7679 5522
ENSIS Research Fellow             [F] +44 (0)20 7679 7565
ENSIS Ltd. & ECRC                 [E] gavin.simpsonATNOSPAMucl.ac.uk
UCL Department of Geography       [W] http://www.ucl.ac.uk/~ucfagls/cv/
26 Bedford Way                    [W] http://www.ucl.ac.uk/~ucfagls/
London.  WC1H 0AP.
%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%~%



From ernesto at ipimar.pt  Fri Aug 26 10:56:03 2005
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Fri, 26 Aug 2005 09:56:03 +0100
Subject: [R] Code in lattice::dotplot function.
In-Reply-To: <eb555e6605082510084ef3dc42@mail.gmail.com>
References: <430DAFC5.50700@ipimar.pt>
	<eb555e6605082510084ef3dc42@mail.gmail.com>
Message-ID: <430ED923.6010208@ipimar.pt>

Deepayan Sarkar wrote:

>On 8/25/05, ernesto <ernesto at ipimar.pt> wrote:
>  
>
>>Hi,
>>
>>I'm trying to understand the code of lattice functions so that I can
>>write some S4 methods using lattice. The following code is a snipet of
>>dotplot that is reused in several other functions. I don't understand
>>why this is needed can someone help ?
>>    
>>
>
>It was a hack to enable usage of the form dotplot(x). The latest
>version of lattice does not use this sort of construct any more
>(replacing it by generics and methods).
>
>Deepayan
>  
>
OK, thanks.

EJ



From ernesto at ipimar.pt  Fri Aug 26 11:15:01 2005
From: ernesto at ipimar.pt (Ernesto Jardim)
Date: Fri, 26 Aug 2005 10:15:01 +0100
Subject: [R] histogram method for S4 class.
In-Reply-To: <eb555e6605082510052dc054a@mail.gmail.com>
References: <430C5958.1040005@ipimar.pt>
	<eb555e6605082510052dc054a@mail.gmail.com>
Message-ID: <430EDD95.3010006@ipimar.pt>

Deepayan Sarkar wrote:

>On 8/24/05, ernesto <ernesto at ipimar.pt> wrote:
>  
>
>>Hi,
>>
>>I'm trying to develop an histogram method for a class called "FLQuant"
>>which is used by the package FLCore (http://flr-project.org). FLQuant is
>>an extension to "array". There is an as.data.frame method that coerces
>>flquant into a data.frame suitable for lattice plotting. The problem is
>>that when I coerce the object and plot it after it works but if the
>>method is applied within the histogram method it does not work. See the
>>code below (the FLCore package is here
>>http://prdownloads.sourceforge.net/flr/FLCore_1.0-1.tar.gz?download)
>>
>>    
>>
>>>library(FLCore)
>>>      
>>>
>>Loading required package: lattice
>>    
>>
>>>data(ple4)
>>>histogram(~data|year, data=ple4 at catch.n)
>>>      
>>>
>>Error in inherits(x, "factor") : Object "x" not found
>>    
>>
>>>histogram(~data|year, data=as.data.frame(ple4 at catch.n))
>>>      
>>>
>>The catch.n slot is a FLQuant object and the code for histogram is the
>>following
>>
>>setMethod("histogram", signature(formula="formula", data="FLQuant"),
>>    function (formula, data = parent.frame(), allow.multiple =
>>is.null(groups) || outer,
>>        outer = FALSE, auto.key = FALSE, aspect = "fill", panel =
>>"panel.histogram", prepanel = NULL,
>>        scales = list(), strip = TRUE, groups = NULL, xlab, xlim, ylab,
>>ylim,
>>        type = c("percent", "count", "density"),
>>        nint = if (is.factor(x)) length(levels(x)) else
>>round(log2(length(x)) + 1),
>>        endpoints = extend.limits(range(x[!is.na(x)]), prop = 0.04),
>>        breaks = if (is.factor(x)) seq(0.5, length = length(levels(x)) +
>>1) else do.breaks(endpoints, nint),
>>        equal.widths = TRUE, drop.unused.levels =
>>lattice.getOption("drop.unused.levels"), ...,
>>        default.scales = list(), subscripts = !is.null(groups), subset =
>>TRUE) {
>>
>>        qdf <- as.data.frame(data)
>>
>>        histogram(formula, data = qdf, allow.multiple = allow.multiple,
>>outer = outer,
>>            auto.key = auto.key, aspect = aspect, panel = panel,
>>prepanel = prepanel, scales = scales,
>>            strip = strip, groups = groups, xlab=xlab, xlim=xlim,
>>ylab=ylab, ylim=ylim, type = type,
>>            nint = nint, endpoints = endpoints, breaks = breaks,
>>equal.widths = equal.widths,
>>            drop.unused.levels = drop.unused.levels, ..., default.scales
>>= default.scales,
>>            subscripts = subscripts, subset = subset)
>>    }
>>)
>>
>>
>>Any ideas ?
>>    
>>
>
>[I'm CC-ing to r-devel, please post follow-ups there]
>
>What version of lattice are you using? Please use the latest one, in
>which histogram is an S3 generic, with only one argument, formula. The
>eventual solution to your problem may involve changing that, but the
>first question to ask is whether any other formula makes sense in your
>context (if not, I would rather keep one argument and dispatch on
>signature(formula = "FLQuant").
>
>Disclaimer: I haven't actually had time to check out FLCore yet, I
>will as soon as I can.
>
>Deepayan
>  
>
Hi,

I've installed the version that is distributed with R-2.1.1, 0.11-8. I 
see there's a new version now so I'll install it and check the results. 
I've developed the code a little more using the approach you use for 
dotplot (see below) and I know where the problem is now. I'm not able to 
pass the argument nint, breaks and endpoints to the function call. I 
guess the problem is my programming skils :-(

Thanks

EJ

ps: I'm not a subscriber of r-devel so I guess I'm not able to post 
there, anyway I'm CC-ing there too.



setMethod("histogram", signature(formula="formula", data="FLQuant"), 
function (formula, data = parent.frame(), allow.multiple = 
is.null(groups) || outer, outer = FALSE, auto.key = FALSE, aspect = 
"fill", panel = "panel.histogram", prepanel = NULL, scales = list(), 
strip = TRUE, groups = NULL, xlab, xlim, ylab, ylim, type = c("percent", 
"count", "density"), nint = if (is.factor(x)) length(levels(x)) else 
round(log2(length(x)) + 1), endpoints = 
extend.limits(range(x[!is.na(x)]), prop = 0.04), breaks = if 
(is.factor(x)) seq(0.5, length = length(levels(x)) + 1) else 
do.breaks(endpoints, nint), equal.widths = TRUE, drop.unused.levels = 
lattice.getOption("drop.unused.levels"), ..., default.scales = list(), 
subscripts = !is.null(groups), subset = TRUE) {

# need to develop further, at the moment is not possible to control 
nint, breaks and endpoints.

data <- as.data.frame(data)

dots <- list(...)

groups <- eval(substitute(groups), data, parent.frame())
subset <- eval(substitute(subset), data, parent.frame())

call.list <- c(list(formula = formula, data = data, groups = groups, 
subset = subset, allow.multiple = allow.multiple, outer = outer, 
auto.key = auto.key, aspect = aspect, panel = panel, prepanel = 
prepanel, scales = scales, strip = strip, type = type, equal.widths = 
equal.widths, drop.unused.levels = drop.unused.levels, default.scales = 
default.scales, subscripts = subscripts), dots)

# include xlab & co if existent
if(!missing(xlab)) call.list$xlab <- xlab
if(!missing(ylab)) call.list$ylab <- ylab
if(!missing(xlim)) call.list$xlim <- xlim
if(!missing(ylim)) call.list$ylim <- ylim

ans <- do.call("histogram", call.list)
ans$call <- match.call()
ans

})



From mmiller at nassp.uct.ac.za  Fri Aug 26 11:15:00 2005
From: mmiller at nassp.uct.ac.za (Mark Miller)
Date: Fri, 26 Aug 2005 11:15:00 +0200
Subject: [R] Cumulative Function
In-Reply-To: <Pine.LNX.4.61.0508251103160.18846@gannet.stats>
References: <200508250914.59962.mmiller@nassp.uct.ac.za>
	<Pine.LNX.4.61.0508250850120.27464@gannet.stats>
	<Pine.LNX.4.61.0508251103160.18846@gannet.stats>
Message-ID: <200508261115.01307.mmiller@nassp.uct.ac.za>

I was wandering if anyone cold advise me on a good algorithm to turn a set of 
data from its original for into its cumulative form.  I have written a piece 
of code that takes the data and does essentially what a histogram function 
would do, except add to the new bin the sum in the previous bin.  Once that 
is done I divide by the frequency in the last bin plus 1.  I know the ecdf() 
function exists in R, but I want to use it to fit the cumulative 
distributions to the data and ecdf() produces a non-subscriptable vector and 
so fitdistr() cannot be used on it.

Thanks for any help you can give
Mark Miller



From Ted.Harding at nessie.mcc.ac.uk  Fri Aug 26 10:55:38 2005
From: Ted.Harding at nessie.mcc.ac.uk ( (Ted Harding))
Date: Fri, 26 Aug 2005 09:55:38 +0100 (BST)
Subject: [R] chisq.,test`
In-Reply-To: <000001c5aa16$47325310$9701a8c0@Tablet>
Message-ID: <XFMail.050826095538.Ted.Harding@nessie.mcc.ac.uk>

On 26-Aug-05 Stephen Choularton wrote:
> Hi
>  
>  I am trying to do this:
>  
> chisq.test(c(11, 13, 12, 18, 21, 43, 15, 12, 9, 10, 5, 28, 22, 11, 15,
> [...]
> 7, 54, 34, 92, 27, 24, 19, 13, 16, 22, 18, 15, 19, 17, 31, 14, 32),
> p=c(0.0016, 0.002752, 0.001728, 0.0016, 0.001792, 0.005953, 0.006081,
> [...]
> 0.001664, 0.002304))
>  
> but I keep on getting ?syntax error?.  Is this to long, or somehow
> badly formed?

Having cut&pasted your data as published in your email into R-1.8.0
on Red Hat Linux 9, I encountered no "syntax error" and got the
result:

  data:  c(11, 13, 12, 18, 21, 43, 15, 12, 9, 10, 5, 28, 22, 11, 15,
  [...]

  X-squared = 1094.448, df = 414, p-value = < 2.2e-16

Fee: For each P-value of the form "x.ye-N", N beers.

Hoping this helps ... though your "syntax error" remains mysterious.

Best wishes,
Ted.


--------------------------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at nessie.mcc.ac.uk>
Fax-to-email: +44 (0)870 094 0861
Date: 26-Aug-05                                       Time: 09:53:38
------------------------------ XFMail ------------------------------



From sdavis2 at mail.nih.gov  Fri Aug 26 12:33:59 2005
From: sdavis2 at mail.nih.gov (Sean Davis)
Date: Fri, 26 Aug 2005 06:33:59 -0400
Subject: [R] Cumulative Function
In-Reply-To: <200508261115.01307.mmiller@nassp.uct.ac.za>
Message-ID: <BF346857.D39F%sdavis2@mail.nih.gov>

Will ?cumsum help?

Sean

On 8/26/05 5:15 AM, "Mark Miller" <mmiller at nassp.uct.ac.za> wrote:

> I was wandering if anyone cold advise me on a good algorithm to turn a set of
> data from its original for into its cumulative form.  I have written a piece
> of code that takes the data and does essentially what a histogram function
> would do, except add to the new bin the sum in the previous bin.  Once that
> is done I divide by the frequency in the last bin plus 1.  I know the ecdf()
> function exists in R, but I want to use it to fit the cumulative
> distributions to the data and ecdf() produces a non-subscriptable vector and
> so fitdistr() cannot be used on it.
> 
> Thanks for any help you can give
> Mark Miller
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Fri Aug 26 12:52:27 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 11:52:27 +0100 (BST)
Subject: [R] learning decision trees with one's own scoring functins
In-Reply-To: <BAY23-F18B50C711645ADA08236CCC7AA0@phx.gbl>
References: <BAY23-F18B50C711645ADA08236CCC7AA0@phx.gbl>
Message-ID: <Pine.LNX.4.61.0508261147480.13934@gannet.stats>

Please do study the packages you mention a great deal more carefully 
before posting such negative remarks about them.

In particular, rpart is already fully user-extensible (and comes with a 
worked example), and both packages are supplied in source code on CRAN.

On Fri, 26 Aug 2005, zhihua li wrote:

> Hi netters,
>
> I want to learn a decision tree from a series of instances (learning data). 
> The packages
> tree or rpart can do this quite well, but the scoring functions (splitting 
> criteria) are
> fixed in these packages, like gini or something. However, I'm going to use 
> another scoring
> function. 
> At first I wanna modify the R code of tree or rpart and put my own scoring 
> function in. But it seems that tree and rpart perform the splitting procedure 
> by calling external C functions, which I have no access to. So do I have to 
> write R code from scratch to build the tree with my own scoring functions? 
> It's a really tough task. Or r there other R packages that can do similar 
> things with more flexible and extensible code?
>
> Thanks a lot!
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From r.shengzhe at gmail.com  Fri Aug 26 13:01:52 2005
From: r.shengzhe at gmail.com (Shengzhe Wu)
Date: Fri, 26 Aug 2005 13:01:52 +0200
Subject: [R] Help: lda predict
Message-ID: <ea57975b0508260401516ea8db@mail.gmail.com>

Hello,

I use lda (package: MASS) to obtain a lda object, then want to employ
this object to do the prediction for the new data like below:

predict(object, newdata, dimen=1, method=c("plug-in", "predictive", "debiased"))

What is the exact difference among the three methods? What is the
difference of prediction results when applying different method?

Thank you,
Shengzhe



From ripley at stats.ox.ac.uk  Fri Aug 26 13:23:56 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 12:23:56 +0100 (BST)
Subject: [R] Help: lda predict
In-Reply-To: <ea57975b0508260401516ea8db@mail.gmail.com>
References: <ea57975b0508260401516ea8db@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0508261217400.14256@gannet.stats>

On Fri, 26 Aug 2005, Shengzhe Wu wrote:

> I use lda (package: MASS) to obtain a lda object, then want to employ
> this object to do the prediction for the new data like below:
>
> predict(object, newdata, dimen=1, method=c("plug-in", "predictive", "debiased"))

That is not how you call it: when a character vector is given like that
those are alternatives.  Do read the help page, as we ask.

> What is the exact difference among the three methods? What is the
> difference of prediction results when applying different method?

This is stated on the help page.  If you are unfamiliar with the area, 
note that the posting guide points out that MASS is support software for a 
book and the explanations are in the book.  The help page also has 
references: please do read them (before posting).

> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From kkiely at insightful.com  Fri Aug 26 13:47:50 2005
From: kkiely at insightful.com (Kathy Kiely)
Date: Fri, 26 Aug 2005 12:47:50 +0100
Subject: [R] Modelling Financial Time Series with S-PLUS - Adv. Course 20th
	Sept '05
Message-ID: <B796B8C05975394DA24E457D1985BDB466E417@uk2kexch01.insightful.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050826/2875dbac/attachment.pl

From sigbert at wiwi.hu-berlin.de  Fri Aug 26 14:44:10 2005
From: sigbert at wiwi.hu-berlin.de (Sigbert Klinke)
Date: Fri, 26 Aug 2005 14:44:10 +0200
Subject: [R] Matrix oriented computing
Message-ID: <430F0E9A.300@wiwi.hu-berlin.de>

Hi,

I want to compute the quantiles of Chi^2 distributions with different 
degrees of freedom like

x<-cbind(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9, 0.95, 0.975, 0.99, 0.995)
df<-rbind(1:100)
m<-qchisq(x,df)

and hoped to get back  a  length(df) times length(x)  matrix with the 
quantiles. Since this does not work, I use

x<-c(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9, 0.95, 0.975, 0.99, 0.995)
df<-c(1:100)
m<-qchisq(x,df[1])
for (i in 2:length(df)) {
  m<-rbind(m,qchisq(x,df[i]))
}
dim(m)<-c(length(df),length(x))

Is there a way to avoid the for loop ?

Thanks Sigbert



From r.shengzhe at gmail.com  Fri Aug 26 14:51:00 2005
From: r.shengzhe at gmail.com (Shengzhe Wu)
Date: Fri, 26 Aug 2005 14:51:00 +0200
Subject: [R] Help: lda predict
In-Reply-To: <Pine.LNX.4.61.0508261217400.14256@gannet.stats>
References: <ea57975b0508260401516ea8db@mail.gmail.com>
	<Pine.LNX.4.61.0508261217400.14256@gannet.stats>
Message-ID: <ea57975b0508260551435006f4@mail.gmail.com>

Thanks for your reply. Actually I called function as below.

p1 = predict(object, newdata, dimen=1)
p2 = predict(object, newdata, dimen=1, method=debiased)
p3 = predict(object, newdata, dimen=1, method="predictive")

The MAP classification of prediction results by any method are the
same. I know what the method "plug-in" and "debiased" mean, but what
does the "vague prior" for the method "predictive" mean? what is
"vague" here?

Thank you,
Shengzhe



On 8/26/05, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Fri, 26 Aug 2005, Shengzhe Wu wrote:
> 
> > I use lda (package: MASS) to obtain a lda object, then want to employ
> > this object to do the prediction for the new data like below:
> >
> > predict(object, newdata, dimen=1, method=c("plug-in", "predictive", "debiased"))
> 
> That is not how you call it: when a character vector is given like that
> those are alternatives.  Do read the help page, as we ask.
> 
> > What is the exact difference among the three methods? What is the
> > difference of prediction results when applying different method?
> 
> This is stated on the help page.  If you are unfamiliar with the area,
> note that the posting guide points out that MASS is support software for a
> book and the explanations are in the book.  The help page also has
> references: please do read them (before posting).
> 
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From Achim.Zeileis at wu-wien.ac.at  Fri Aug 26 14:46:53 2005
From: Achim.Zeileis at wu-wien.ac.at (Achim Zeileis)
Date: Fri, 26 Aug 2005 14:46:53 +0200
Subject: [R] Matrix oriented computing
In-Reply-To: <430F0E9A.300@wiwi.hu-berlin.de>
References: <430F0E9A.300@wiwi.hu-berlin.de>
Message-ID: <20050826144653.45eec6ba.Achim.Zeileis@wu-wien.ac.at>

On Fri, 26 Aug 2005 14:44:10 +0200 Sigbert Klinke wrote:

> Hi,
> 
> I want to compute the quantiles of Chi^2 distributions with different 
> degrees of freedom like
> 
> x<-cbind(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9, 0.95, 0.975, 0.99,
> 0.995) df<-rbind(1:100)
> m<-qchisq(x,df)
> 
> and hoped to get back  a  length(df) times length(x)  matrix with the 
> quantiles. Since this does not work, I use
> 
> x<-c(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9, 0.95, 0.975, 0.99,
> 0.995) df<-c(1:100)
> m<-qchisq(x,df[1])
> for (i in 2:length(df)) {
>   m<-rbind(m,qchisq(x,df[i]))
> }
> dim(m)<-c(length(df),length(x))
> 
> Is there a way to avoid the for loop ?

You could use sapply():
  m <- sapply(x, function(x) qchisq(x, df))
hth,
Z

> Thanks Sigbert
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
>



From MSchwartz at mn.rr.com  Fri Aug 26 14:55:24 2005
From: MSchwartz at mn.rr.com (Marc Schwartz)
Date: Fri, 26 Aug 2005 07:55:24 -0500
Subject: [R] Matrix oriented computing
In-Reply-To: <430F0E9A.300@wiwi.hu-berlin.de>
References: <430F0E9A.300@wiwi.hu-berlin.de>
Message-ID: <1125060924.5528.2.camel@localhost.localdomain>

On Fri, 2005-08-26 at 14:44 +0200, Sigbert Klinke wrote:
> Hi,
> 
> I want to compute the quantiles of Chi^2 distributions with different 
> degrees of freedom like
> 
> x<-cbind(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9, 0.95, 0.975, 0.99, 0.995)
> df<-rbind(1:100)
> m<-qchisq(x,df)
> 
> and hoped to get back  a  length(df) times length(x)  matrix with the 
> quantiles. Since this does not work, I use
> 
> x<-c(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9, 0.95, 0.975, 0.99, 0.995)
> df<-c(1:100)
> m<-qchisq(x,df[1])
> for (i in 2:length(df)) {
>   m<-rbind(m,qchisq(x,df[i]))
> }
> dim(m)<-c(length(df),length(x))
> 
> Is there a way to avoid the for loop ?
> 
> Thanks Sigbert

See ?sapply

x <- c(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9, 
       0.95, 0.975, 0.99, 0.995)

df <- c(1:100)

mat <- sapply(x, qchisq, df)

> dim(mat)
[1] 100  11
 
> str(mat)
 num [1:100, 1:11] 3.93e-05 1.00e-02 7.17e-02 2.07e-01 4.12e-01 ...


HTH,

Marc Schwartz



From ripley at stats.ox.ac.uk  Fri Aug 26 15:07:54 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 14:07:54 +0100 (BST)
Subject: [R] Help: lda predict
In-Reply-To: <ea57975b0508260551435006f4@mail.gmail.com>
References: <ea57975b0508260401516ea8db@mail.gmail.com> 
	<Pine.LNX.4.61.0508261217400.14256@gannet.stats>
	<ea57975b0508260551435006f4@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0508261405240.8861@gannet.stats>

On Fri, 26 Aug 2005, Shengzhe Wu wrote:

> Thanks for your reply. Actually I called function as below.
>
> p1 = predict(object, newdata, dimen=1)
> p2 = predict(object, newdata, dimen=1, method=debiased)
> p3 = predict(object, newdata, dimen=1, method="predictive")

So why did you say something different?

> The MAP classification of prediction results by any method are the
> same. I know what the method "plug-in" and "debiased" mean, but what
> does the "vague prior" for the method "predictive" mean? what is
> "vague" here?

Please do as we ask, and read the book for which this is supporting 
material (on p.339, to save you looking in the index).

>
> Thank you,
> Shengzhe
>
>
>
> On 8/26/05, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> On Fri, 26 Aug 2005, Shengzhe Wu wrote:
>>
>>> I use lda (package: MASS) to obtain a lda object, then want to employ
>>> this object to do the prediction for the new data like below:
>>>
>>> predict(object, newdata, dimen=1, method=c("plug-in", "predictive", "debiased"))
>>
>> That is not how you call it: when a character vector is given like that
>> those are alternatives.  Do read the help page, as we ask.
>>
>>> What is the exact difference among the three methods? What is the
>>> difference of prediction results when applying different method?
>>
>> This is stated on the help page.  If you are unfamiliar with the area,
>> note that the posting guide points out that MASS is support software for a
>> book and the explanations are in the book.  The help page also has
>> references: please do read them (before posting).
>>
>>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ottorini at mac.com  Fri Aug 26 15:15:17 2005
From: ottorini at mac.com (Jean-Marc Ottorini)
Date: Fri, 26 Aug 2005 15:15:17 +0200
Subject: [R] R-help Digest, Vol 30, Issue 26
In-Reply-To: <mailman.13.1125050401.2035.r-help@stat.math.ethz.ch>
References: <mailman.13.1125050401.2035.r-help@stat.math.ethz.ch>
Message-ID: <217a2029dd845de73e25d7214d5a0381@mac.com>

Dear R helpers,

   For me ( i.e. R 2.1.1 on Mac OS X), using  "trellis.device 
(postscript, onefile = F, etc ..."  with the lattice library within a R 
function works fine to obtain the desired graph as an EPS file , 
provided that :

    1) the command dev.off() is not included in this function

    2) and it is  issued at the  command level after the function has 
been exited

I would like to know if there is a way to close the EPS file within the 
function itself, freeing the user to issue the closing command (I 
already  tried trellis.device (), and trellis.device (null) without any 
success).

Regards,

J.-M.

  ----
Jean-Marc Ottorini               LERFoB, UMR INRA-ENGREF 1092
  email  ottorini at nancy.inra.fr          INRA - Centre de Nancy
  voice  +33-0383-394046                    F54280 - Champenoux
  fax    +33-0383-394034                                 France



From pburns at pburns.seanet.com  Fri Aug 26 15:21:34 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Fri, 26 Aug 2005 14:21:34 +0100
Subject: [R] Matrix oriented computing
In-Reply-To: <430F0E9A.300@wiwi.hu-berlin.de>
References: <430F0E9A.300@wiwi.hu-berlin.de>
Message-ID: <430F175E.7040909@pburns.seanet.com>

I believe that the following is what you want:

x <- c(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9, 0.95, 0.975, 0.99, 0.995)
dof <- 1:100
ans <- outer(x, dof, qchisq)
dimnames(ans) <- list(x, dof)


Note that 'df' is not a very auspicious name for an object since
it is the name of a function. 

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Sigbert Klinke wrote:

>Hi,
>
>I want to compute the quantiles of Chi^2 distributions with different 
>degrees of freedom like
>
>x<-cbind(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9, 0.95, 0.975, 0.99, 0.995)
>df<-rbind(1:100)
>m<-qchisq(x,df)
>
>and hoped to get back  a  length(df) times length(x)  matrix with the 
>quantiles. Since this does not work, I use
>
>x<-c(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9, 0.95, 0.975, 0.99, 0.995)
>df<-c(1:100)
>m<-qchisq(x,df[1])
>for (i in 2:length(df)) {
>  m<-rbind(m,qchisq(x,df[i]))
>}
>dim(m)<-c(length(df),length(x))
>
>Is there a way to avoid the for loop ?
>
>Thanks Sigbert
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>
>
>  
>



From p.dalgaard at biostat.ku.dk  Fri Aug 26 15:25:59 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 26 Aug 2005 15:25:59 +0200
Subject: [R] Matrix oriented computing
In-Reply-To: <1125060924.5528.2.camel@localhost.localdomain>
References: <430F0E9A.300@wiwi.hu-berlin.de>
	<1125060924.5528.2.camel@localhost.localdomain>
Message-ID: <x2vf1su8wo.fsf@turmalin.kubism.ku.dk>

Marc Schwartz <MSchwartz at mn.rr.com> writes:

> x <- c(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9, 
>        0.95, 0.975, 0.99, 0.995)
> 
> df <- c(1:100)
> 
> mat <- sapply(x, qchisq, df)
>
> > dim(mat)
> [1] 100  11
>  
> > str(mat)
>  num [1:100, 1:11] 3.93e-05 1.00e-02 7.17e-02 2.07e-01 4.12e-01 ...

outer() is perhaps a more natural first try... It does give the
transpose of the sapply approach, though. 

round(t(outer(x,df,qchisq)),2)

should be close. You should likely add dimnames.


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From r.shengzhe at gmail.com  Fri Aug 26 15:31:36 2005
From: r.shengzhe at gmail.com (Shengzhe Wu)
Date: Fri, 26 Aug 2005 15:31:36 +0200
Subject: [R] Help: lda predict
In-Reply-To: <Pine.LNX.4.61.0508261405240.8861@gannet.stats>
References: <ea57975b0508260401516ea8db@mail.gmail.com>
	<Pine.LNX.4.61.0508261217400.14256@gannet.stats>
	<ea57975b0508260551435006f4@mail.gmail.com>
	<Pine.LNX.4.61.0508261405240.8861@gannet.stats>
Message-ID: <ea57975b050826063130faf3ef@mail.gmail.com>

I compared "posterior" of these three prediction results, they are a
little different.

The book you mentioned should be "Modern Applied Statistics with S.
4th edition". But this book has been borrowed out from our univeristy
library by someone else, and I have checked the book "Pattern
Recognition and Neural Networks" which does not mention these three
lda prediction methods.

Thanks you,
Shengzhe

On 8/26/05, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On Fri, 26 Aug 2005, Shengzhe Wu wrote:
> 
> > Thanks for your reply. Actually I called function as below.
> >
> > p1 = predict(object, newdata, dimen=1)
> > p2 = predict(object, newdata, dimen=1, method=debiased)
> > p3 = predict(object, newdata, dimen=1, method="predictive")
> 
> So why did you say something different?
> 
> > The MAP classification of prediction results by any method are the
> > same. I know what the method "plug-in" and "debiased" mean, but what
> > does the "vague prior" for the method "predictive" mean? what is
> > "vague" here?
> 
> Please do as we ask, and read the book for which this is supporting
> material (on p.339, to save you looking in the index).
> 
> >
> > Thank you,
> > Shengzhe
> >
> >
> >
> > On 8/26/05, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> >> On Fri, 26 Aug 2005, Shengzhe Wu wrote:
> >>
> >>> I use lda (package: MASS) to obtain a lda object, then want to employ
> >>> this object to do the prediction for the new data like below:
> >>>
> >>> predict(object, newdata, dimen=1, method=c("plug-in", "predictive", "debiased"))
> >>
> >> That is not how you call it: when a character vector is given like that
> >> those are alternatives.  Do read the help page, as we ask.
> >>
> >>> What is the exact difference among the three methods? What is the
> >>> difference of prediction results when applying different method?
> >>
> >> This is stated on the help page.  If you are unfamiliar with the area,
> >> note that the posting guide points out that MASS is support software for a
> >> book and the explanations are in the book.  The help page also has
> >> references: please do read them (before posting).
> >>
> >>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >>
> >> --
> >> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> >> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> >> University of Oxford,             Tel:  +44 1865 272861 (self)
> >> 1 South Parks Road,                     +44 1865 272866 (PA)
> >> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >>
> >
> >
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From ripley at stats.ox.ac.uk  Fri Aug 26 15:58:08 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 14:58:08 +0100 (BST)
Subject: [R] Help: lda predict
In-Reply-To: <ea57975b050826063130faf3ef@mail.gmail.com>
References: <ea57975b0508260401516ea8db@mail.gmail.com> 
	<Pine.LNX.4.61.0508261217400.14256@gannet.stats>
	<ea57975b0508260551435006f4@mail.gmail.com>
	<Pine.LNX.4.61.0508261405240.8861@gannet.stats>
	<ea57975b050826063130faf3ef@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0508261452130.9514@gannet.stats>

On Fri, 26 Aug 2005, Shengzhe Wu wrote:

> I compared "posterior" of these three prediction results, they are a
> little different.
>
> The book you mentioned should be "Modern Applied Statistics with S.
> 4th edition". But this book has been borrowed out from our univeristy
> library by someone else,

So please do request it and consult it, as you are using its support 
software.  Note that the posting guide does asks you to mention if you 
have no access to the references.

>  and I have checked the book "Pattern
> Recognition and Neural Networks" which does not mention these three
> lda prediction methods.

It does, in detail, in sections 2.4 and 2.5.

>
> Thanks you,
> Shengzhe
>
> On 8/26/05, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> On Fri, 26 Aug 2005, Shengzhe Wu wrote:
>>
>>> Thanks for your reply. Actually I called function as below.
>>>
>>> p1 = predict(object, newdata, dimen=1)
>>> p2 = predict(object, newdata, dimen=1, method=debiased)
>>> p3 = predict(object, newdata, dimen=1, method="predictive")
>>
>> So why did you say something different?
>>
>>> The MAP classification of prediction results by any method are the
>>> same. I know what the method "plug-in" and "debiased" mean, but what
>>> does the "vague prior" for the method "predictive" mean? what is
>>> "vague" here?
>>
>> Please do as we ask, and read the book for which this is supporting
>> material (on p.339, to save you looking in the index).
>>
>>>
>>> Thank you,
>>> Shengzhe
>>>
>>>
>>>
>>> On 8/26/05, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>>>> On Fri, 26 Aug 2005, Shengzhe Wu wrote:
>>>>
>>>>> I use lda (package: MASS) to obtain a lda object, then want to employ
>>>>> this object to do the prediction for the new data like below:
>>>>>
>>>>> predict(object, newdata, dimen=1, method=c("plug-in", "predictive", "debiased"))
>>>>
>>>> That is not how you call it: when a character vector is given like that
>>>> those are alternatives.  Do read the help page, as we ask.
>>>>
>>>>> What is the exact difference among the three methods? What is the
>>>>> difference of prediction results when applying different method?
>>>>
>>>> This is stated on the help page.  If you are unfamiliar with the area,
>>>> note that the posting guide points out that MASS is support software for a
>>>> book and the explanations are in the book.  The help page also has
>>>> references: please do read them (before posting).
>>>>
>>>>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>>>
>>>> --
>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>>>> University of Oxford,             Tel:  +44 1865 272861 (self)
>>>> 1 South Parks Road,                     +44 1865 272866 (PA)
>>>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>>>
>>>
>>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tlumley at u.washington.edu  Fri Aug 26 16:14:17 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Fri, 26 Aug 2005 07:14:17 -0700 (PDT)
Subject: [R] covariance matrix under null
In-Reply-To: <D45546375992BF429A93F7203358F14403429579@sirius.fccc.edu>
References: <D45546375992BF429A93F7203358F14403429579@sirius.fccc.edu>
Message-ID: <Pine.A41.4.61b.0508260711580.67238@homer05.u.washington.edu>

On Thu, 25 Aug 2005, Devarajan, Karthik wrote:

>
> Hello
>
> I am fitting a Cox PH model using the function coxph(). Does anyone know how
> to obtain the estimate of the covariance matrix under the null hypothesis.
> The function coxph.detail() does not seem to be useful for this purpose.
>

You can evaluate the second derivative of the partial loglikelihood at any 
specified beta with

   vcov(coxph(formula, data,iter=0, start, init=beta)

eg if you want to get score tests.

 	-thomas



From ripley at stats.ox.ac.uk  Fri Aug 26 16:36:42 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 15:36:42 +0100 (BST)
Subject: [R] Shutting down a trellis plot (was  R-help Digest, Vol 30,
 Issue 26)
In-Reply-To: <217a2029dd845de73e25d7214d5a0381@mac.com>
References: <mailman.13.1125050401.2035.r-help@stat.math.ethz.ch>
	<217a2029dd845de73e25d7214d5a0381@mac.com>
Message-ID: <Pine.LNX.4.61.0508261530100.9948@gannet.stats>

I suspect you have not print()-ed your graphics, see FAQ Q7.22.

It is then possible to include dev.off() within the function.  E.g.

testit <- function(fn = "test.eps")
{
   trellis.device(postscript, file=fn, onefile = FALSE, horizontal=FALSE)
   print(stripplot(voice.part ~ jitter(height), data = singer, aspect = 1,
                   jitter = TRUE, xlab = "Height (inches)"))
   dev.off()
}

testit()

works for me.


On Fri, 26 Aug 2005, Jean-Marc Ottorini wrote:

>   For me ( i.e. R 2.1.1 on Mac OS X), using  "trellis.device
> (postscript, onefile = F, etc ..."  with the lattice library within a R
> function works fine to obtain the desired graph as an EPS file ,
> provided that :
>
>    1) the command dev.off() is not included in this function
>
>    2) and it is  issued at the  command level after the function has
> been exited
>
> I would like to know if there is a way to close the EPS file within the
> function itself, freeing the user to issue the closing command (I
> already  tried trellis.device (), and trellis.device (null) without any
> success).


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From atarca at med.wayne.edu  Fri Aug 26 16:41:48 2005
From: atarca at med.wayne.edu (Tarca, Adi)
Date: Fri, 26 Aug 2005 10:41:48 -0400
Subject: [R] passing arguments from nnet to optim
Message-ID: <D79A56AD131896448D0860DEE07CBE1F05BA9B62@med-core07.med.wayne.edu>


Hi everyone,
According to R reference manual, the nnet function uses the BFGS method
of optim to optimize the neural network parameters.
I would like, when calling the function nnet to tell the optim function
not to produce the tracing information on the progress of the
optimization, or at least to reduce the frequency of the reports.
I tried the following:
a) nnet default
> x<-rnorm(20)
> y<-seq(0,1,length=20)
> s<-nnet(y~x,size=1)
# weights:  4
initial  value 1.910932 
iter  10 value 1.819382
iter  20 value 1.788736
iter  30 value 1.775778
iter  40 value 1.767771
iter  50 value 1.765063
iter  60 value 1.762631
iter  70 value 1.760670
iter  80 value 1.759349
iter  90 value 1.757801
iter 100 value 1.756290
final  value 1.756290 
stopped after 100 iterations

Report is generated at every 10 iterations.

b) passing the REPORT parameter to optim via the control argument
> x<-rnorm(20)
> y<-seq(0,1,length=20)
> s<-nnet(y~x,size=1,control=list(REPORT=50))
# weights:  4
initial  value 1.894905 
iter  10 value 1.672337
iter  20 value 1.658612
iter  30 value 1.654824
iter  40 value 1.653465
iter  50 value 1.652785
iter  60 value 1.652343
iter  70 value 1.652116
iter  80 value 1.651860
iter  90 value 1.651525
iter 100 value 1.651292
final  value 1.651292 
stopped after 100 iterations

Is still producing reports at each 10 iterations. 
Has anyone an idea how can I turn off the report generation or at least
to reduce its frequency?
Thanks,
Adi L. TARCA



From richmcb at gmail.com  Fri Aug 26 16:44:12 2005
From: richmcb at gmail.com (Ben Rich)
Date: Fri, 26 Aug 2005 16:44:12 +0200
Subject: [R] Plotting nls
In-Reply-To: <430E594A.3020602@buffalo.edu>
References: <D45546375992BF429A93F7203358F14403429579@sirius.fccc.edu>
	<430E594A.3020602@buffalo.edu>
Message-ID: <32acb12105082607446800fad6@mail.gmail.com>

To get nice looking plots you can use trellis plots from the lattice
package.  First you need:

library(lattice)

Then you can define a custom panel function that will overlay the
fitted curve on top of the data points in a different color (you just
need to do this once; the fit you want plotted is specified as an
argument):

pred.overlay.panel <- function(x, y, fit, ...)
{
   panel.grid()
   panel.xyplot(x, y, ...)
   form <- as.list(sys.call(-2))[[2]]$call$formula
   resp <- deparse(form[[2]])
   covar <- deparse(form[[3]])
   xx <- seq(min(x), max(x), len=101)
   newdat <- data.frame(xx)
   colnames(newdat) <- covar
   panel.superpose(xx, predict(fit, newdata=newdat),
       subscripts=1:length(xx), groups=factor(rep(2, length(xx)),
       levels=1:2), type="l", ...)
}

Finally, you use the custom panel function in a call to xyplot:

xyplot(y ~ x, data=sample, panel=pred.overlay.panel, fit=fit,
scales=list(x=list(log=TRUE)))


Note how you specify that you want the x-axis to be in log-scale with
the scales parameter.

Hope this helps.

Ben

On 8/26/05, Lanre Okusanya <ooo at buffalo.edu> wrote:
> Kindly excuse a non-statistician newbie attempting to wrestle with R.
> 
> This might be a relatively easy question, but I am trying to perform nls
> regression and plot the fitted function through the data superimposed on
> the raw data. from reading the R-help, Rtips et al, I am only able to do
> that by extracting the parameter values manually and using it to create
> the plot.
> 
> Is there an easier way to do this,  (I have ~60 Plots), obtain an r^2,
> and also plot the x axis in the log domain (any attempts I have tried
> have screwed up).
> 
> NLS script
> 
> fit<- nls(y~-emax*x^h/(ec50^h+x^h),
>        data= sample, start=list(emax=4,h=2,ec50=1))
> 
> summary(fit)
> 
> Thank you all for your help
> 
> Lanre Okusanya, Pharm.D.,BCPS
> UB/Pfizer Pharmacometrics Fellow
> University at Buffalo School of Pharmacy and Pharmaceutical Sciences
> 237 Cooke Hall
> Buffalo, NY 14260
> Email: ooo at buffalo.edu
> Tel: (716)645-2828 x 275
> Fax: (716)645-2886
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From Arne.Muller at sanofi-aventis.com  Fri Aug 26 16:57:02 2005
From: Arne.Muller at sanofi-aventis.com (Arne.Muller@sanofi-aventis.com)
Date: Fri, 26 Aug 2005 16:57:02 +0200
Subject: [R] basic anova and t-test question
Message-ID: <C80ECAFA2ACC1B45BE45D133ED660ADE010BF3FE@CRBSMXSUSR04>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050826/b6697c98/attachment.pl

From mschwartz at mn.rr.com  Fri Aug 26 17:25:41 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Fri, 26 Aug 2005 10:25:41 -0500
Subject: [R] Matrix oriented computing
In-Reply-To: <x2vf1su8wo.fsf@turmalin.kubism.ku.dk>
References: <430F0E9A.300@wiwi.hu-berlin.de>
	<1125060924.5528.2.camel@localhost.localdomain>
	<x2vf1su8wo.fsf@turmalin.kubism.ku.dk>
Message-ID: <1125069941.4355.17.camel@localhost.localdomain>

On Fri, 2005-08-26 at 15:25 +0200, Peter Dalgaard wrote:
> Marc Schwartz <MSchwartz at mn.rr.com> writes:
> 
> > x <- c(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9, 
> >        0.95, 0.975, 0.99, 0.995)
> > 
> > df <- c(1:100)
> > 
> > mat <- sapply(x, qchisq, df)
> >
> > > dim(mat)
> > [1] 100  11
> >  
> > > str(mat)
> >  num [1:100, 1:11] 3.93e-05 1.00e-02 7.17e-02 2.07e-01 4.12e-01 ...
> 
> outer() is perhaps a more natural first try... It does give the
> transpose of the sapply approach, though. 
> 
> round(t(outer(x,df,qchisq)),2)
> 
> should be close. You should likely add dimnames.



What I find interesting, is that I would have intuitively expected
outer() to be faster than sapply().  However:


>  system.time(mat <- sapply(x, qchisq, df), gcFirst = TRUE)
[1] 0.01 0.00 0.01 0.00 0.00
 
>  system.time(mat1 <- round(t(outer(x, df, qchisq)), 2), 
               gcFirst = TRUE)
[1] 0.01 0.00 0.01 0.00 0.00
 
# No round() or t() to test for overhead
>  system.time(mat2 <- outer(x, df, qchisq), gcFirst = TRUE)
[1] 0.01 0.00 0.02 0.00 0.00


# Bear in mind the round() on mat1 above
> all.equal(mat, mat1)
[1] "Mean relative  difference: 4.905485e-05"

> all.equal(mat, t(mat2))
[1] TRUE


Even when increasing the size of 'df' to 1:1000:


>  system.time(mat <- sapply(x, qchisq, df), gcFirst = TRUE)
[1] 0.16 0.01 0.16 0.00 0.00

>  system.time(mat1 <- round(t(outer(x, df, qchisq)), 2), gcFirst =
TRUE)
[1] 0.16 0.00 0.18 0.00 0.00
 
>  # No round() or t() to test for overhead
>  system.time(mat2 <- outer(x, df, qchisq), gcFirst = TRUE)
[1] 0.16 0.01 0.17 0.00 0.00



It also seems that, at least in this case, t() and round() do not add
much overhead.

Best regards,

Marc



From ripley at stats.ox.ac.uk  Fri Aug 26 17:49:58 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 16:49:58 +0100 (BST)
Subject: [R] passing arguments from nnet to optim
In-Reply-To: <D79A56AD131896448D0860DEE07CBE1F05BA9B62@med-core07.med.wayne.edu>
References: <D79A56AD131896448D0860DEE07CBE1F05BA9B62@med-core07.med.wayne.edu>
Message-ID: <Pine.LNX.4.61.0508261647390.11188@gannet.stats>

On Fri, 26 Aug 2005, Tarca, Adi wrote:

>
> Hi everyone,
> According to R reference manual, the nnet function uses the BFGS method
> of optim to optimize the neural network parameters.

What the help page says is

      ...: arguments passed to or from other methods.

That means methods of nnet().

      Optimization is done via the BFGS method of 'optim'.

but it is not calling optim, rather the C code implementing optim.

> I would like, when calling the function nnet to tell the optim function
> not to produce the tracing information on the progress of the
> optimization, or at least to reduce the frequency of the reports.
> I tried the following:
> a) nnet default
>> x<-rnorm(20)
>> y<-seq(0,1,length=20)
>> s<-nnet(y~x,size=1)
> # weights:  4
> initial  value 1.910932
> iter  10 value 1.819382
> iter  20 value 1.788736
> iter  30 value 1.775778
> iter  40 value 1.767771
> iter  50 value 1.765063
> iter  60 value 1.762631
> iter  70 value 1.760670
> iter  80 value 1.759349
> iter  90 value 1.757801
> iter 100 value 1.756290
> final  value 1.756290
> stopped after 100 iterations
>
> Report is generated at every 10 iterations.
>
> b) passing the REPORT parameter to optim via the control argument
>> x<-rnorm(20)
>> y<-seq(0,1,length=20)
>> s<-nnet(y~x,size=1,control=list(REPORT=50))
> # weights:  4
> initial  value 1.894905
> iter  10 value 1.672337
> iter  20 value 1.658612
> iter  30 value 1.654824
> iter  40 value 1.653465
> iter  50 value 1.652785
> iter  60 value 1.652343
> iter  70 value 1.652116
> iter  80 value 1.651860
> iter  90 value 1.651525
> iter 100 value 1.651292
> final  value 1.651292
> stopped after 100 iterations
>
> Is still producing reports at each 10 iterations.
> Has anyone an idea how can I turn off the report generation or at least
> to reduce its frequency?

You do it via the C code.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tmlammail at yahoo.com  Fri Aug 26 17:52:21 2005
From: tmlammail at yahoo.com (Martin Lam)
Date: Fri, 26 Aug 2005 08:52:21 -0700 (PDT)
Subject: [R]   problem with certain data sets when using randomForest
Message-ID: <20050826155221.6227.qmail@web40521.mail.yahoo.com>

Hi,

Since I've had no replies on my previous post about my
problem I am posting it again in the hope someone
notice it. The problem is that the randomForest
function doesn't take datasets which has instances
only containing a subset of  all the classes. So the
dataset with instances that either belong to class "a"
or "b" from the levels "a", "b" and "c" doesn't work
because there is no instance that has class "c". Is
there any way to solve this problem?

library("randomForest")

# load the iris plant data set
dataset <- iris

numberarray <- array(1:nrow(dataset), nrow(dataset),
1)

# include only instances with Species = setosa or
virginica
indices <- t(numberarray[(dataset$Species == "setosa"
| 
dataset$Species == "virginica") == TRUE])

finaldataset <- dataset[indices,]

# just to let you see the 3 classes
levels(finaldataset$Species)

# create the random forest
randomForest(formula = Species ~ ., data =
finaldataset, ntree = 5)

# The error message I get
Error in randomForest.default(m, y, ...) : 
        Can't have empty classes in y.

#The problem is that the finaldataset doesn't contain
#any instances of "versicolor", so I think the only
way #to solve this problem is by changing the levels
the #"Species" have to only "setosa" and "virginica",
# correct me if I'm wrong.

# So I tried to change the levels but I got stuck:

# get the possible unique classes
uniqueItems <- unique(levels(finaldataset$Species))

# the problem!
newlevels <- list(uniqueItems[1] = c(uniqueItems[1],
uniqueItems[2]), uniqueItems[3] = uniqueItems[3])

# Error message
Error: syntax error

# In the help they use constant names to rename the
#levels, so this works (but that's not what I want
#because I don't want to change the code every time I
#use another data set):
newlevels <- list("setosa" = c(uniqueItems[1],
uniqueItems[2]), "virginica" = uniqueItems[3])

levels(finaldataset$Species) <- newlevels

levels(finaldataset$Species)

finaldataset$Species

---------------------------

Thanks in advance,

Martin



From ripley at stats.ox.ac.uk  Fri Aug 26 17:55:55 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 16:55:55 +0100 (BST)
Subject: [R] Matrix oriented computing
In-Reply-To: <1125069941.4355.17.camel@localhost.localdomain>
References: <430F0E9A.300@wiwi.hu-berlin.de>
	<1125060924.5528.2.camel@localhost.localdomain>
	<x2vf1su8wo.fsf@turmalin.kubism.ku.dk>
	<1125069941.4355.17.camel@localhost.localdomain>
Message-ID: <Pine.LNX.4.61.0508261651160.11188@gannet.stats>

Try profiling.  Doing this many times to get an overview, e.g. for sapply 
with df=1:1000:

    %       self        %       total
  self     seconds    total    seconds    name
  98.26      6.78     98.26      6.78     "FUN"
   0.58      0.04      0.58      0.04     "unlist"
   0.29      0.02      0.87      0.06     "as.vector"
   0.29      0.02      0.58      0.04     "names<-"
   0.29      0.02      0.29      0.02     "names<-.default"
   0.29      0.02      0.29      0.02     "names"

so almost all the time is in qchisq.


On Fri, 26 Aug 2005, Marc Schwartz (via MN) wrote:

> On Fri, 2005-08-26 at 15:25 +0200, Peter Dalgaard wrote:
>> Marc Schwartz <MSchwartz at mn.rr.com> writes:
>>
>>> x <- c(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9,
>>>        0.95, 0.975, 0.99, 0.995)
>>>
>>> df <- c(1:100)
>>>
>>> mat <- sapply(x, qchisq, df)
>>>
>>>> dim(mat)
>>> [1] 100  11
>>>
>>>> str(mat)
>>>  num [1:100, 1:11] 3.93e-05 1.00e-02 7.17e-02 2.07e-01 4.12e-01 ...
>>
>> outer() is perhaps a more natural first try... It does give the
>> transpose of the sapply approach, though.
>>
>> round(t(outer(x,df,qchisq)),2)
>>
>> should be close. You should likely add dimnames.
>
>
>
> What I find interesting, is that I would have intuitively expected
> outer() to be faster than sapply().  However:
>
>
>>  system.time(mat <- sapply(x, qchisq, df), gcFirst = TRUE)
> [1] 0.01 0.00 0.01 0.00 0.00
>
>>  system.time(mat1 <- round(t(outer(x, df, qchisq)), 2),
>               gcFirst = TRUE)
> [1] 0.01 0.00 0.01 0.00 0.00
>
> # No round() or t() to test for overhead
>>  system.time(mat2 <- outer(x, df, qchisq), gcFirst = TRUE)
> [1] 0.01 0.00 0.02 0.00 0.00
>
>
> # Bear in mind the round() on mat1 above
>> all.equal(mat, mat1)
> [1] "Mean relative  difference: 4.905485e-05"
>
>> all.equal(mat, t(mat2))
> [1] TRUE
>
>
> Even when increasing the size of 'df' to 1:1000:
>
>
>>  system.time(mat <- sapply(x, qchisq, df), gcFirst = TRUE)
> [1] 0.16 0.01 0.16 0.00 0.00
>
>>  system.time(mat1 <- round(t(outer(x, df, qchisq)), 2), gcFirst =
> TRUE)
> [1] 0.16 0.00 0.18 0.00 0.00
>
>>  # No round() or t() to test for overhead
>>  system.time(mat2 <- outer(x, df, qchisq), gcFirst = TRUE)
> [1] 0.16 0.01 0.17 0.00 0.00
>
>
>
> It also seems that, at least in this case, t() and round() do not add
> much overhead.

Definitely not for such small matrices.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jfox at mcmaster.ca  Fri Aug 26 18:01:28 2005
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 26 Aug 2005 12:01:28 -0400
Subject: [R] Matrix oriented computing
In-Reply-To: <1125069941.4355.17.camel@localhost.localdomain>
Message-ID: <20050826160129.IKXZ16985.tomts36-srv.bellnexxia.net@JohnDesktop8300>

Dear Mark,

For that matter, the loop isn't a whole a slower (on my 3GHz Win XP system):

> x <- c(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9, 0.95, 0.975, 0.99, 0.995)
> df <- 1:1000
> system.time(mat <- sapply(x, qchisq, df), gcFirst = TRUE)
[1] 0.08 0.00 0.08   NA   NA
> 
> mat <- matrix(0, 1000, 11)
> system.time(for (i in 1:length(df)) mat[i,] <- qchisq(x, df[i]))
[1] 0.09 0.00 0.10   NA   NA
> 

Regards,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Marc 
> Schwartz (via MN)
> Sent: Friday, August 26, 2005 10:26 AM
> To: Peter Dalgaard
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Matrix oriented computing
> 
> On Fri, 2005-08-26 at 15:25 +0200, Peter Dalgaard wrote:
> > Marc Schwartz <MSchwartz at mn.rr.com> writes:
> > 
> > > x <- c(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9, 
> > >        0.95, 0.975, 0.99, 0.995)
> > > 
> > > df <- c(1:100)
> > > 
> > > mat <- sapply(x, qchisq, df)
> > >
> > > > dim(mat)
> > > [1] 100  11
> > >  
> > > > str(mat)
> > >  num [1:100, 1:11] 3.93e-05 1.00e-02 7.17e-02 2.07e-01 
> 4.12e-01 ...
> > 
> > outer() is perhaps a more natural first try... It does give the 
> > transpose of the sapply approach, though.
> > 
> > round(t(outer(x,df,qchisq)),2)
> > 
> > should be close. You should likely add dimnames.
> 
> 
> 
> What I find interesting, is that I would have intuitively expected
> outer() to be faster than sapply().  However:
> 
> 
> >  system.time(mat <- sapply(x, qchisq, df), gcFirst = TRUE)
> [1] 0.01 0.00 0.01 0.00 0.00
>  
> >  system.time(mat1 <- round(t(outer(x, df, qchisq)), 2),
>                gcFirst = TRUE)
> [1] 0.01 0.00 0.01 0.00 0.00
>  
> # No round() or t() to test for overhead
> >  system.time(mat2 <- outer(x, df, qchisq), gcFirst = TRUE)
> [1] 0.01 0.00 0.02 0.00 0.00
> 
> 
> # Bear in mind the round() on mat1 above
> > all.equal(mat, mat1)
> [1] "Mean relative  difference: 4.905485e-05"
> 
> > all.equal(mat, t(mat2))
> [1] TRUE
> 
> 
> Even when increasing the size of 'df' to 1:1000:
> 
> 
> >  system.time(mat <- sapply(x, qchisq, df), gcFirst = TRUE)
> [1] 0.16 0.01 0.16 0.00 0.00
> 
> >  system.time(mat1 <- round(t(outer(x, df, qchisq)), 2), gcFirst =
> TRUE)
> [1] 0.16 0.00 0.18 0.00 0.00
>  
> >  # No round() or t() to test for overhead
> >  system.time(mat2 <- outer(x, df, qchisq), gcFirst = TRUE)
> [1] 0.16 0.01 0.17 0.00 0.00
> 
> 
> 
> It also seems that, at least in this case, t() and round() do 
> not add much overhead.
> 
> Best regards,
> 
> Marc
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From mschwartz at mn.rr.com  Fri Aug 26 18:15:40 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Fri, 26 Aug 2005 11:15:40 -0500
Subject: [R] Matrix oriented computing
In-Reply-To: <Pine.LNX.4.61.0508261651160.11188@gannet.stats>
References: <430F0E9A.300@wiwi.hu-berlin.de>
	<1125060924.5528.2.camel@localhost.localdomain>
	<x2vf1su8wo.fsf@turmalin.kubism.ku.dk>
	<1125069941.4355.17.camel@localhost.localdomain>
	<Pine.LNX.4.61.0508261651160.11188@gannet.stats>
Message-ID: <1125072940.4355.40.camel@localhost.localdomain>

Prof. Ripley,

Excellent point. Neither sapply() nor outer() are the "elephant in the
room" in this situation.



On Fri, 2005-08-26 at 16:55 +0100, Prof Brian Ripley wrote:
> Try profiling.  Doing this many times to get an overview, e.g. for sapply 
> with df=1:1000:
> 
>     %       self        %       total
>   self     seconds    total    seconds    name
>   98.26      6.78     98.26      6.78     "FUN"
>    0.58      0.04      0.58      0.04     "unlist"
>    0.29      0.02      0.87      0.06     "as.vector"
>    0.29      0.02      0.58      0.04     "names<-"
>    0.29      0.02      0.29      0.02     "names<-.default"
>    0.29      0.02      0.29      0.02     "names"
> 
> so almost all the time is in qchisq.
> 
> 
> On Fri, 26 Aug 2005, Marc Schwartz (via MN) wrote:
> 
> > On Fri, 2005-08-26 at 15:25 +0200, Peter Dalgaard wrote:
> >> Marc Schwartz <MSchwartz at mn.rr.com> writes:
> >>
> >>> x <- c(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9,
> >>>        0.95, 0.975, 0.99, 0.995)
> >>>
> >>> df <- c(1:100)
> >>>
> >>> mat <- sapply(x, qchisq, df)
> >>>
> >>>> dim(mat)
> >>> [1] 100  11
> >>>
> >>>> str(mat)
> >>>  num [1:100, 1:11] 3.93e-05 1.00e-02 7.17e-02 2.07e-01 4.12e-01 ...
> >>
> >> outer() is perhaps a more natural first try... It does give the
> >> transpose of the sapply approach, though.
> >>
> >> round(t(outer(x,df,qchisq)),2)
> >>
> >> should be close. You should likely add dimnames.
> >
> >
> >
> > What I find interesting, is that I would have intuitively expected
> > outer() to be faster than sapply().  However:
> >
> >
> >>  system.time(mat <- sapply(x, qchisq, df), gcFirst = TRUE)
> > [1] 0.01 0.00 0.01 0.00 0.00
> >
> >>  system.time(mat1 <- round(t(outer(x, df, qchisq)), 2),
> >               gcFirst = TRUE)
> > [1] 0.01 0.00 0.01 0.00 0.00
> >
> > # No round() or t() to test for overhead
> >>  system.time(mat2 <- outer(x, df, qchisq), gcFirst = TRUE)
> > [1] 0.01 0.00 0.02 0.00 0.00
> >
> >
> > # Bear in mind the round() on mat1 above
> >> all.equal(mat, mat1)
> > [1] "Mean relative  difference: 4.905485e-05"
> >
> >> all.equal(mat, t(mat2))
> > [1] TRUE
> >
> >
> > Even when increasing the size of 'df' to 1:1000:
> >
> >
> >>  system.time(mat <- sapply(x, qchisq, df), gcFirst = TRUE)
> > [1] 0.16 0.01 0.16 0.00 0.00
> >
> >>  system.time(mat1 <- round(t(outer(x, df, qchisq)), 2), gcFirst =
> > TRUE)
> > [1] 0.16 0.00 0.18 0.00 0.00
> >
> >>  # No round() or t() to test for overhead
> >>  system.time(mat2 <- outer(x, df, qchisq), gcFirst = TRUE)
> > [1] 0.16 0.01 0.17 0.00 0.00
> >
> >
> >
> > It also seems that, at least in this case, t() and round() do not add
> > much overhead.
> 
> Definitely not for such small matrices.


True and both are C functions, which of course helps as well.

Best regards,

Marc



From stgries_lists at arcor.de  Fri Aug 26 18:17:51 2005
From: stgries_lists at arcor.de (Stefan Th. Gries)
Date: Fri, 26 Aug 2005 18:17:51 +0200 (CEST)
Subject: [R] parts of data frames: subset vs. [-c()]
Message-ID: <19509256.1125073071467.JavaMail.ngmail@webmail-07.arcor-online.net>

Dear all

I have a problem with splitting up a data frame called ReVerb:

?? str(ReVerb)
`data.frame':   92713 obs. of  16 variables:
 $ CHILD    : Factor w/ 7 levels "ABE","ADA","EVE",..: 1 1 1 1 1 1 1 1 1 1 ...
 $ AGE      : Factor w/ 484 levels "1;06.00","1;06.16",..: 43 43 43 99 99 99 99 99 99 99 ...
 $ AGE_Q    : num  2.0 2.0 2.0 2.4 2.4 ...
 $ INTERVALS: num  2 2 2 2.25 2.25 2.25 2.25 2.25 2.25 2.25 ...
 $ RND      : int  34368 38311 14949 20586 72516 27186 88019 10767 114448 86146 ...
 $ SYNTAX   : Factor w/ 17 levels "Acmp","Amats",..: 15 12 8 15 7 16 7 7 16 7 ...
 $ LEXICAL  : Factor w/ 1643 levels "$ACHE","$ACT",..: 194 803 803 294 299 803 1562 299 679 1562 ...
 $ MORPH    : Factor w/ 337 levels "$","$ =inf","$ =prs",..: 9 20 9 39 184 231 57 67 231 39 ...
 $ COMPLEM  : Factor w/ 1989 levels "$","$ V PR=Lp [1.2]",..: 203 547 220 203 1101 368 1834 1667 368 1834 ...
 $ MATRIX   : Factor w/ 906 levels "$ ???","$ be PR=Aen",..: 5 5 5 308 5 856 5 5 856 308 ...
 $ SITUATION: Factor w/ 9 levels "[imitation of Mom: you know what I said]",..: 2 2 2 2 2 2 2 2 2 2 ...
 $ V_ANN    : int  1 1 1 4 4 4 4 3 3 3 ...
 $ QUEST    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ EXCL     : int  0 0 0 1 1 1 1 0 0 0 ...
 $ U_LEN    : int  3 4 5 13 13 13 13 8 8 8 ...
 $ UTTERANCE: Factor w/ 55113 levels "","# (be)cause he wanted to .",..: 5696 39091 52180 2262 2262 2262 2262 3593 3593 3593 ...

The level causing the problem is SYNTAX:

?? as.data.frame(sort(table(SYNTAX)))
              sort(table(SYNTAX))
Particles                     100
PR=N1                         144
Amats                         271
Trans_PR=A2                   787
Ditrans                      1181
Intrans_PR=A1                1399
Acmp                         2402
Trans_PR=V2                  2433
CPcmps                       2769
Vpreps                       4896
Intrans_V0                   5182
Trans_PR=L2                  7653
Trans_V02                    8117
Intrans_PR=L1                8457
Intrans_V1                   9643
Intrans_PR=V1               14987
Trans_V12                   22288


I would like to extract all cases where SYNTAX=="Ditrans" from ReVerb, store that in a file, and then generate ReVerb again without these cases and factor levels. My problem is probably obvious from the following lines of code:

?? ditrans<-which(SYNTAX=="Ditrans")
?? ReVerb1<-ReVerb[-c(ditrans),]; dim(ReVerb1)
[1] 91532    16
?? 
?? # ok, so the 92713-91532=1181 cases where SYNTAX=="Ditrans" have been removed, but ...
?? 
?? ReVerb1<-subset(ReVerb, SYNTAX!="Ditrans"); dim(ReVerb1)
[1] 91528    16
?? 
?? # ... so why don't I get 91532 again as the number of rows?
?? 
Any ideas??

?? R.version # on Windows XP with service Pack 2
         _              
platform i386-pc-mingw32
arch     i386           
os       mingw32        
system   i386, mingw32  
status                  
major    2              
minor    1.1            
year     2005           
month    06             
day      20             
language R              

Thanks a lot,
STG
--
Stefan Th. Gries
----------------------------------------
Max Planck Inst. for Evol. Anthropology
http://people.freenet.de/Stefan_Th_Gries
----------------------------------------

Machen Sie aus 14 Cent spielend bis zu 100 Euro!
Die neue Gaming-Area von Arcor - ??ber 50 Onlinespiele im Angebot.
http://www.arcor.de/rd/emf-gaming-1



From ripley at stats.ox.ac.uk  Fri Aug 26 18:19:39 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 17:19:39 +0100 (BST)
Subject: [R] problem with certain data sets when using randomForest
In-Reply-To: <20050826155221.6227.qmail@web40521.mail.yahoo.com>
References: <20050826155221.6227.qmail@web40521.mail.yahoo.com>
Message-ID: <Pine.LNX.4.61.0508261716450.12297@gannet.stats>

Look at ?"[.factor":

 	finaldataset$Species <- finaldataset$Species[,drop=TRUE]

solves this.

On Fri, 26 Aug 2005, Martin Lam wrote:

> Hi,
>
> Since I've had no replies on my previous post about my
> problem I am posting it again in the hope someone
> notice it. The problem is that the randomForest
> function doesn't take datasets which has instances
> only containing a subset of  all the classes. So the
> dataset with instances that either belong to class "a"
> or "b" from the levels "a", "b" and "c" doesn't work
> because there is no instance that has class "c". Is
> there any way to solve this problem?
>
> library("randomForest")
>
> # load the iris plant data set
> dataset <- iris
>
> numberarray <- array(1:nrow(dataset), nrow(dataset),
> 1)
>
> # include only instances with Species = setosa or
> virginica
> indices <- t(numberarray[(dataset$Species == "setosa"
> |
> dataset$Species == "virginica") == TRUE])
>
> finaldataset <- dataset[indices,]
>
> # just to let you see the 3 classes
> levels(finaldataset$Species)
>
> # create the random forest
> randomForest(formula = Species ~ ., data =
> finaldataset, ntree = 5)
>
> # The error message I get
> Error in randomForest.default(m, y, ...) :
>        Can't have empty classes in y.
>
> #The problem is that the finaldataset doesn't contain
> #any instances of "versicolor", so I think the only
> way #to solve this problem is by changing the levels
> the #"Species" have to only "setosa" and "virginica",
> # correct me if I'm wrong.
>
> # So I tried to change the levels but I got stuck:
>
> # get the possible unique classes
> uniqueItems <- unique(levels(finaldataset$Species))
>
> # the problem!
> newlevels <- list(uniqueItems[1] = c(uniqueItems[1],
> uniqueItems[2]), uniqueItems[3] = uniqueItems[3])
>
> # Error message
> Error: syntax error
>
> # In the help they use constant names to rename the
> #levels, so this works (but that's not what I want
> #because I don't want to change the code every time I
> #use another data set):
> newlevels <- list("setosa" = c(uniqueItems[1],
> uniqueItems[2]), "virginica" = uniqueItems[3])
>
> levels(finaldataset$Species) <- newlevels
>
> levels(finaldataset$Species)
>
> finaldataset$Species
>
> ---------------------------
>
> Thanks in advance,
>
> Martin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at gmail.com  Fri Aug 26 18:21:00 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 26 Aug 2005 12:21:00 -0400
Subject: [R] Matrix oriented computing
In-Reply-To: <1125069941.4355.17.camel@localhost.localdomain>
References: <430F0E9A.300@wiwi.hu-berlin.de>
	<1125060924.5528.2.camel@localhost.localdomain>
	<x2vf1su8wo.fsf@turmalin.kubism.ku.dk>
	<1125069941.4355.17.camel@localhost.localdomain>
Message-ID: <971536df05082609213faf7388@mail.gmail.com>

On 8/26/05, Marc Schwartz (via MN) <mschwartz at mn.rr.com> wrote:
> On Fri, 2005-08-26 at 15:25 +0200, Peter Dalgaard wrote:
> > Marc Schwartz <MSchwartz at mn.rr.com> writes:
> >
> > > x <- c(0.005, 0.010, 0.025, 0.05, 0.1, 0.5, 0.9,
> > >        0.95, 0.975, 0.99, 0.995)
> > >
> > > df <- c(1:100)
> > >
> > > mat <- sapply(x, qchisq, df)
> > >
> > > > dim(mat)
> > > [1] 100  11
> > >
> > > > str(mat)
> > >  num [1:100, 1:11] 3.93e-05 1.00e-02 7.17e-02 2.07e-01 4.12e-01 ...
> >
> > outer() is perhaps a more natural first try... It does give the
> > transpose of the sapply approach, though.
> >
> > round(t(outer(x,df,qchisq)),2)
> >
> > should be close. You should likely add dimnames.
> 
> 
> 
> What I find interesting, is that I would have intuitively expected
> outer() to be faster than sapply().  However:
> 
> 
> >  system.time(mat <- sapply(x, qchisq, df), gcFirst = TRUE)
> [1] 0.01 0.00 0.01 0.00 0.00
> 
> >  system.time(mat1 <- round(t(outer(x, df, qchisq)), 2),
>               gcFirst = TRUE)
> [1] 0.01 0.00 0.01 0.00 0.00
> 
> # No round() or t() to test for overhead
> >  system.time(mat2 <- outer(x, df, qchisq), gcFirst = TRUE)
> [1] 0.01 0.00 0.02 0.00 0.00
> 
> 
> # Bear in mind the round() on mat1 above
> > all.equal(mat, mat1)
> [1] "Mean relative  difference: 4.905485e-05"
> 
> > all.equal(mat, t(mat2))
> [1] TRUE
> 
> 
> Even when increasing the size of 'df' to 1:1000:
> 
> 
> >  system.time(mat <- sapply(x, qchisq, df), gcFirst = TRUE)
> [1] 0.16 0.01 0.16 0.00 0.00
> 
> >  system.time(mat1 <- round(t(outer(x, df, qchisq)), 2), gcFirst =
> TRUE)
> [1] 0.16 0.00 0.18 0.00 0.00
> 
> >  # No round() or t() to test for overhead
> >  system.time(mat2 <- outer(x, df, qchisq), gcFirst = TRUE)
> [1] 0.16 0.01 0.17 0.00 0.00
> 
> 
> 
> It also seems that, at least in this case, t() and round() do not add
> much overhead.
> 

You might need to do it repeatedly to get a more reliable reading.
When I do it 1000 times outer is faster than sapply though not by much:

> n <- 1000
> system.time(for (i in 1:n) mat <- sapply(x, qchisq, df), gcFirst = TRUE)
[1] 14.05  0.00 14.43    NA    NA
> 
> system.time(for(i in 1:n) mat2 <- outer(x, df, qchisq), gcFirst = TRUE)
[1] 13.42  0.00 13.85    NA    NA



From p.dalgaard at biostat.ku.dk  Fri Aug 26 18:33:21 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 26 Aug 2005 18:33:21 +0200
Subject: [R] parts of data frames: subset vs. [-c()]
In-Reply-To: <19509256.1125073071467.JavaMail.ngmail@webmail-07.arcor-online.net>
References: <19509256.1125073071467.JavaMail.ngmail@webmail-07.arcor-online.net>
Message-ID: <x2d5o0u08e.fsf@turmalin.kubism.ku.dk>

"Stefan Th. Gries" <stgries_lists at arcor.de> writes:

> Dear all
> 
> I have a problem with splitting up a data frame called ReVerb:
> 
> ?? str(ReVerb)
> `data.frame':   92713 obs. of  16 variables:
>  $ CHILD    : Factor w/ 7 levels "ABE","ADA","EVE",..: 1 1 1 1 1 1 1 1 1 1 ...
>  $ AGE      : Factor w/ 484 levels "1;06.00","1;06.16",..: 43 43 43 99 99 99 99 99 99 99 ...
>  $ AGE_Q    : num  2.0 2.0 2.0 2.4 2.4 ...
>  $ INTERVALS: num  2 2 2 2.25 2.25 2.25 2.25 2.25 2.25 2.25 ...
>  $ RND      : int  34368 38311 14949 20586 72516 27186 88019 10767 114448 86146 ...
>  $ SYNTAX   : Factor w/ 17 levels "Acmp","Amats",..: 15 12 8 15 7 16 7 7 16 7 ...
>  $ LEXICAL  : Factor w/ 1643 levels "$ACHE","$ACT",..: 194 803 803 294 299 803 1562 299 679 1562 ...
>  $ MORPH    : Factor w/ 337 levels "$","$ =inf","$ =prs",..: 9 20 9 39 184 231 57 67 231 39 ...
>  $ COMPLEM  : Factor w/ 1989 levels "$","$ V PR=Lp [1.2]",..: 203 547 220 203 1101 368 1834 1667 368 1834 ...
>  $ MATRIX   : Factor w/ 906 levels "$ ???","$ be PR=Aen",..: 5 5 5 308 5 856 5 5 856 308 ...
>  $ SITUATION: Factor w/ 9 levels "[imitation of Mom: you know what I said]",..: 2 2 2 2 2 2 2 2 2 2 ...
>  $ V_ANN    : int  1 1 1 4 4 4 4 3 3 3 ...
>  $ QUEST    : int  0 0 0 0 0 0 0 0 0 0 ...
>  $ EXCL     : int  0 0 0 1 1 1 1 0 0 0 ...
>  $ U_LEN    : int  3 4 5 13 13 13 13 8 8 8 ...
>  $ UTTERANCE: Factor w/ 55113 levels "","# (be)cause he wanted to .",..: 5696 39091 52180 2262 2262 2262 2262 3593 3593 3593 ...
> 
> The level causing the problem is SYNTAX:
> 
> ?? as.data.frame(sort(table(SYNTAX)))
>               sort(table(SYNTAX))
> Particles                     100
> PR=N1                         144
> Amats                         271
> Trans_PR=A2                   787
> Ditrans                      1181
> Intrans_PR=A1                1399
> Acmp                         2402
> Trans_PR=V2                  2433
> CPcmps                       2769
> Vpreps                       4896
> Intrans_V0                   5182
> Trans_PR=L2                  7653
> Trans_V02                    8117
> Intrans_PR=L1                8457
> Intrans_V1                   9643
> Intrans_PR=V1               14987
> Trans_V12                   22288
> 
> 
> I would like to extract all cases where SYNTAX=="Ditrans" from ReVerb, store that in a file, and then generate ReVerb again without these cases and factor levels. My problem is probably obvious from the following lines of code:
> 
> ?? ditrans<-which(SYNTAX=="Ditrans")
> ?? ReVerb1<-ReVerb[-c(ditrans),]; dim(ReVerb1)
> [1] 91532    16
> ?? 
> ?? # ok, so the 92713-91532=1181 cases where SYNTAX=="Ditrans" have been removed, but ...
> ?? 
> ?? ReVerb1<-subset(ReVerb, SYNTAX!="Ditrans"); dim(ReVerb1)
> [1] 91528    16
> ?? 
> ?? # ... so why don't I get 91532 again as the number of rows?
> ?? 
> Any ideas??

The SYNTAX variable is not necessarily the same. Could you retry the
first case with 

 ditrans <- which(ReVerb$SYNTAX=="Ditrans")

? 

Otherwise, try doing a setdiff() on the rownames of the two discrepant
results and see which are the four cases that differ.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From pcampbell at econ.bbk.ac.uk  Fri Aug 26 18:30:54 2005
From: pcampbell at econ.bbk.ac.uk (Phineas Campbell)
Date: Fri, 26 Aug 2005 17:30:54 +0100
Subject: [R] class 'named'
Message-ID: <NGECIFANPOJAGABBAEAPKEAOFBAA.pcampbell@econ.bbk.ac.uk>

I'm working through the examples in Venables and Ripley in the 'New-style
Classes' chapter.

On a call to representation, in the lda example, it is unable to find the
class <named>.

Is the class <named> defined anywhere?  I've loaded the library methods but
this hasn't helped.

Phineas Campbell



From siwulayid at gmail.com  Fri Aug 26 18:57:52 2005
From: siwulayid at gmail.com (Luwis Tapiwa Diya)
Date: Fri, 26 Aug 2005 18:57:52 +0200
Subject: [R] Help in Compliling user -defined functions in Rpart
Message-ID: <ddf1e2bc0508260957298a6360@mail.gmail.com>

I have been trying to write my own user defined function in Rpart.I
imitated the anova splitting rule which is given as an example.In the
work I am doing ,I am calculating the concentration index(ci) ,which
is in between -1 and +1.So my deviance is given by
abs(ci)*(1-abs(ci)).Now when I run rpart incorporating this user
defined function i get the following error message:

 Error in user.split(yback[1:nback], wback[1:nback], xback[1:nback], parms,  : 
        unused argument(s) ( ...)

Now I am failing to indentify where I am going wrong (In case I am
have made some mistake).So I was wondering if there is anybody who
have written some user defined functions of theirs and maybe if there
is any documentation with regards to user defined functions and
examples.

Regards ,

Luwis Diya

#####################################################################User
defined function
#####################################################################

temp.init<-function(y,offset,parms,wt){
	if (!is.null(offset)) y<-y-offset 
	if (is.matrix(y))stop ("response must be a vector")

	list(y=y,parms=0,numy=1,numresp=1,
		   summary=function(yval,dev,wt,ylevel,digits){
		         paste("mean=",format(signif(yval,digits)),
 				   "MSE=",format(signif(dev/wt,digits)),
				    sep='')
		})
	} 


temp.eval<-function(y,wt,parms){
		n<-length(y)
		r<-wt
for (i in 1:n-1) {r[i+1]=(sum(wt[1:i])+0.5*wt[i+1])/n} #fractional rank 
		r[1]<-0.5*wt[1]/n
		wmean<-sum(y*wt)/sum(wt)
		ci<-2*sum(wt*(y-wmean)*(r-0.5))/sum(wt*y) #concentration index for
socio-economic inequality
		dev<-abs(ci)*(1-abs(ci))		  #deviance following the gini impurity approach 	
        list(label=wmean,deviance=dev)
}

         
temp.split<-function(y,wt,parms,continous){
	n<-length(y)
	r<-wt
for (i in 1:n-1) {r[i+1]=(sum(wt[1:i])+0.5*wt[i+1])/n}
	r[1]<-0.5*wt[1]/n
	wmean<-sum(y*wt)/sum(wt)
	ci<-2*sum(wt*(y-wmean)*(r-0.5))/sum(wt*y)
	devci<-abs(ci)*(1-abs(ci))

	if(continous){
	  lss<-cumsum(wt*y)[-n]
	  rss<-sum(wt*y)-lss 
	  lw<-cumsum(wt)[-n]
	  rw<-sum(wt)-lw 
	  lm<-lss/lw
	  rm<-rss/rw
	  lcss<-cumsum(wt[1:length(lm)]*(y[1:length(lm)]-lm)*(r[1:length(lm)]-0.5))
	  rcss<-sum(wt*(y-wmean)*(r-0.5))-lcss
	  lci<-2*lcss/lss				  #concentration index for left side	
	  rci<-2*rcss/rss				  #concentration index for right side
	  devlci<-abs(lci)*(1-abs(lci))			  #deviance for left side
	  devrci<-abs(rci)*(1-abs(rci))			  #deviance for right side	

	  goodness<-devci-(lw/sum(wt))*devlci-(rw/sum(wt))*devrci
	  list(goodness=goodness, direction=sign(lci))
	  }
   else {	 
	 ux<-sort(unique(x))
	 wtsum<-tapply(wt,x,sum)
	 ysum<-tapply(wt*y,x,sum)
	 means<-ysum/wtsum

	 ord<-order(means)
       n<-length(ord)  	
	 lss<-cumsum(ysum[ord])[-n]
	 rss<-sum(ysum)-lss 
	 lw<-cumsum(wtsum[ord])[-n]
	 rw<-sum(wtsum)-lw 
	 lm<-lss/lw
	 rm<-rss/rw
	 lysum<-tapply(wt*(y-lm)*(r-0.5),x,sum)
	 lcss<-cumsum(lysum[ord])[-n]
	 rcss<-sum(lysum)-lcss
	 lci<-2*lcss/lss
	 rci<-2*rcss/rss
	 devlci<-abs(lci)*(1-abs(lci))
	 devrci<-abs(rci)*(1-abs(rci))

	  goodness<-devci-0.5*(lw/sum(wt))*devlci-0.5*(rw/sum(wt))*devrci
	  list(goodness=goodness, direction=sign(lci))
	 }
}

alist<-list(eval=temp.eval,split=temp.split,init=temp.init)
tree<-rpart(u~pcares+antcare.skilled+riskintb+child.born+married+mage1+mage2,
weights=popweight,method=alist)



From a.manigs at gmail.com  Fri Aug 26 19:09:49 2005
From: a.manigs at gmail.com (A Mani)
Date: Fri, 26 Aug 2005 22:39:49 +0530
Subject: [R] Unpaste Problem
Message-ID: <a6821d9905082610094a195e14@mail.gmail.com>

Hello,
        Easy ways to "unpaste"?
 xp <- paste(x2, x3) # x2, x3 are two non-numeric columns.
.............
.........................
xfg <- data.frame(xp,sc1, sc2, sc3) # sc1,sc2, sc3 are numeric cols.

I want xp to be split up to form a new dataframe of the form (x3, sc1,
sc2, sc3).
IMPORTANT info : elements of xp have the form abc<space>efg, with abc
in x2 and efg in x3.

Thanks in advance, 
-- 
A. Mani
Member, Cal. Math. Soc



From osman_alradi at yahoo.ca  Fri Aug 26 19:16:20 2005
From: osman_alradi at yahoo.ca (Osman Al-Radi)
Date: Fri, 26 Aug 2005 13:16:20 -0400 (EDT)
Subject: [R] compare c-index of two logistic models using rcorrp.senc() of
	the Hmisc library
Message-ID: <20050826171620.71647.qmail@web34011.mail.mud.yahoo.com>

Dear R-help,

Would it be appropriate to do the following to
calculate a p-value for the difference between c-ind
of x1 and c-inx of x2 using the output from
rcorrp.senc()

> r<-rcorrp.senc(x1,x1,y)

> pValue<-1-pnorm((r[11]-r[12])/(r[2]/r[5])*1.96) 

Osman O. Al-Radi, MD, MSc, FRCSC
Chief Resident, Cardiac Surgery
University of Toronto, Canada



From f.harrell at vanderbilt.edu  Fri Aug 26 19:25:07 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Fri, 26 Aug 2005 12:25:07 -0500
Subject: [R] compare c-index of two logistic models using rcorrp.senc()
 of the Hmisc library
In-Reply-To: <20050826171620.71647.qmail@web34011.mail.mud.yahoo.com>
References: <20050826171620.71647.qmail@web34011.mail.mud.yahoo.com>
Message-ID: <430F5073.6060904@vanderbilt.edu>

Osman Al-Radi wrote:
> Dear R-help,
> 
> Would it be appropriate to do the following to
> calculate a p-value for the difference between c-ind
> of x1 and c-inx of x2 using the output from
> rcorrp.senc()
> 
> 
>>r<-rcorrp.senc(x1,x1,y)
> 
> 
>>pValue<-1-pnorm((r[11]-r[12])/(r[2]/r[5])*1.96) 
> 
> 
> Osman O. Al-Radi, MD, MSc, FRCSC
> Chief Resident, Cardiac Surgery
> University of Toronto, Canada

Osman,

Because tests for differences in two ROC areas are not very powerful, 
rcorrp.cens changes the hypothesis to "are predictions from one method 
more concordant with the outcome than predictions from the other method, 
within paired predictions".  You can't get a difference in ROC areas 
from the U-statistic computed by rcorrp.cens.

Frank



-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From ripley at stats.ox.ac.uk  Fri Aug 26 19:40:26 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 18:40:26 +0100 (BST)
Subject: [R] parts of data frames: subset vs. [-c()]
In-Reply-To: <19509256.1125073071467.JavaMail.ngmail@webmail-07.arcor-online.net>
References: <19509256.1125073071467.JavaMail.ngmail@webmail-07.arcor-online.net>
Message-ID: <Pine.LNX.4.61.0508261838560.13081@gannet.stats>

Are there NAs in the variable?

SYNTAX=="Ditrans" and SYNTAX!="Ditrans" are not mutually exclusive.


On Fri, 26 Aug 2005, Stefan Th. Gries wrote:

> Dear all
>
> I have a problem with splitting up a data frame called ReVerb:
>
> ? str(ReVerb)
> `data.frame':   92713 obs. of  16 variables:
> $ CHILD    : Factor w/ 7 levels "ABE","ADA","EVE",..: 1 1 1 1 1 1 1 1 1 1 ...
> $ AGE      : Factor w/ 484 levels "1;06.00","1;06.16",..: 43 43 43 99 99 99 99 99 99 99 ...
> $ AGE_Q    : num  2.0 2.0 2.0 2.4 2.4 ...
> $ INTERVALS: num  2 2 2 2.25 2.25 2.25 2.25 2.25 2.25 2.25 ...
> $ RND      : int  34368 38311 14949 20586 72516 27186 88019 10767 114448 86146 ...
> $ SYNTAX   : Factor w/ 17 levels "Acmp","Amats",..: 15 12 8 15 7 16 7 7 16 7 ...
> $ LEXICAL  : Factor w/ 1643 levels "$ACHE","$ACT",..: 194 803 803 294 299 803 1562 299 679 1562 ...
> $ MORPH    : Factor w/ 337 levels "$","$ =inf","$ =prs",..: 9 20 9 39 184 231 57 67 231 39 ...
> $ COMPLEM  : Factor w/ 1989 levels "$","$ V PR=Lp [1.2]",..: 203 547 220 203 1101 368 1834 1667 368 1834 ...
> $ MATRIX   : Factor w/ 906 levels "$ ???","$ be PR=Aen",..: 5 5 5 308 5 856 5 5 856 308 ...
> $ SITUATION: Factor w/ 9 levels "[imitation of Mom: you know what I said]",..: 2 2 2 2 2 2 2 2 2 2 ...
> $ V_ANN    : int  1 1 1 4 4 4 4 3 3 3 ...
> $ QUEST    : int  0 0 0 0 0 0 0 0 0 0 ...
> $ EXCL     : int  0 0 0 1 1 1 1 0 0 0 ...
> $ U_LEN    : int  3 4 5 13 13 13 13 8 8 8 ...
> $ UTTERANCE: Factor w/ 55113 levels "","# (be)cause he wanted to .",..: 5696 39091 52180 2262 2262 2262 2262 3593 3593 3593 ...
>
> The level causing the problem is SYNTAX:
>
> ? as.data.frame(sort(table(SYNTAX)))
>              sort(table(SYNTAX))
> Particles                     100
> PR=N1                         144
> Amats                         271
> Trans_PR=A2                   787
> Ditrans                      1181
> Intrans_PR=A1                1399
> Acmp                         2402
> Trans_PR=V2                  2433
> CPcmps                       2769
> Vpreps                       4896
> Intrans_V0                   5182
> Trans_PR=L2                  7653
> Trans_V02                    8117
> Intrans_PR=L1                8457
> Intrans_V1                   9643
> Intrans_PR=V1               14987
> Trans_V12                   22288
>
>
> I would like to extract all cases where SYNTAX=="Ditrans" from ReVerb, store that in a file, and then generate ReVerb again without these cases and factor levels. My problem is probably obvious from the following lines of code:
>
> ? ditrans<-which(SYNTAX=="Ditrans")
> ? ReVerb1<-ReVerb[-c(ditrans),]; dim(ReVerb1)
> [1] 91532    16
> ?
> ? # ok, so the 92713-91532=1181 cases where SYNTAX=="Ditrans" have been removed, but ...
> ?
> ? ReVerb1<-subset(ReVerb, SYNTAX!="Ditrans"); dim(ReVerb1)
> [1] 91528    16
> ?
> ? # ... so why don't I get 91532 again as the number of rows?
> ?
> Any ideas??

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From ripley at stats.ox.ac.uk  Fri Aug 26 19:41:31 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 18:41:31 +0100 (BST)
Subject: [R] class 'named'
In-Reply-To: <NGECIFANPOJAGABBAEAPKEAOFBAA.pcampbell@econ.bbk.ac.uk>
References: <NGECIFANPOJAGABBAEAPKEAOFBAA.pcampbell@econ.bbk.ac.uk>
Message-ID: <Pine.LNX.4.61.0508261840561.13081@gannet.stats>

That is one of the S4 vs R differences.  See the complements.

On Fri, 26 Aug 2005, Phineas Campbell wrote:

> I'm working through the examples in Venables and Ripley in the 'New-style
> Classes' chapter.
>
> On a call to representation, in the lda example, it is unable to find the
> class <named>.
>
> Is the class <named> defined anywhere?  I've loaded the library methods but
> this hasn't helped.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Fri Aug 26 19:44:01 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 18:44:01 +0100 (BST)
Subject: [R] Help in Compliling user -defined functions in Rpart
In-Reply-To: <ddf1e2bc0508260957298a6360@mail.gmail.com>
References: <ddf1e2bc0508260957298a6360@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0508261841550.13081@gannet.stats>

On Fri, 26 Aug 2005, Luwis Tapiwa Diya wrote:

> I have been trying to write my own user defined function in Rpart.I
> imitated the anova splitting rule which is given as an example.In the
> work I am doing ,I am calculating the concentration index(ci) ,which
> is in between -1 and +1.So my deviance is given by
> abs(ci)*(1-abs(ci)).Now when I run rpart incorporating this user
> defined function i get the following error message:
>
> Error in user.split(yback[1:nback], wback[1:nback], xback[1:nback], parms,  :
>        unused argument(s) ( ...)
>
> Now I am failing to indentify where I am going wrong (In case I am
> have made some mistake).So I was wondering if there is anybody who
> have written some user defined functions of theirs and maybe if there
> is any documentation with regards to user defined functions and
> examples.

There is a commented example in the tests directory (of the sources).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From tmlammail at yahoo.com  Fri Aug 26 20:22:03 2005
From: tmlammail at yahoo.com (Martin Lam)
Date: Fri, 26 Aug 2005 11:22:03 -0700 (PDT)
Subject: [R] problem with certain data sets when using randomForest
In-Reply-To: <Pine.LNX.4.61.0508261716450.12297@gannet.stats>
Message-ID: <20050826182203.76764.qmail@web40510.mail.yahoo.com>

Thank you for this and earlier help Mr. Ripley.

Martin

--- Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> Look at ?"[.factor":
> 
>  	finaldataset$Species <-
> finaldataset$Species[,drop=TRUE]
> 
> solves this.
> 
> On Fri, 26 Aug 2005, Martin Lam wrote:
> 
> > Hi,
> >
> > Since I've had no replies on my previous post
> about my
> > problem I am posting it again in the hope someone
> > notice it. The problem is that the randomForest
> > function doesn't take datasets which has instances
> > only containing a subset of  all the classes. So
> the
> > dataset with instances that either belong to class
> "a"
> > or "b" from the levels "a", "b" and "c" doesn't
> work
> > because there is no instance that has class "c".
> Is
> > there any way to solve this problem?
> >
> > library("randomForest")
> >
> > # load the iris plant data set
> > dataset <- iris
> >
> > numberarray <- array(1:nrow(dataset),
> nrow(dataset),
> > 1)
> >
> > # include only instances with Species = setosa or
> > virginica
> > indices <- t(numberarray[(dataset$Species ==
> "setosa"
> > |
> > dataset$Species == "virginica") == TRUE])
> >
> > finaldataset <- dataset[indices,]
> >
> > # just to let you see the 3 classes
> > levels(finaldataset$Species)
> >
> > # create the random forest
> > randomForest(formula = Species ~ ., data =
> > finaldataset, ntree = 5)
> >
> > # The error message I get
> > Error in randomForest.default(m, y, ...) :
> >        Can't have empty classes in y.
> >
> > #The problem is that the finaldataset doesn't
> contain
> > #any instances of "versicolor", so I think the
> only
> > way #to solve this problem is by changing the
> levels
> > the #"Species" have to only "setosa" and
> "virginica",
> > # correct me if I'm wrong.
> >
> > # So I tried to change the levels but I got stuck:
> >
> > # get the possible unique classes
> > uniqueItems <-
> unique(levels(finaldataset$Species))
> >
> > # the problem!
> > newlevels <- list(uniqueItems[1] =
> c(uniqueItems[1],
> > uniqueItems[2]), uniqueItems[3] = uniqueItems[3])
> >
> > # Error message
> > Error: syntax error
> >
> > # In the help they use constant names to rename
> the
> > #levels, so this works (but that's not what I want
> > #because I don't want to change the code every
> time I
> > #use another data set):
> > newlevels <- list("setosa" = c(uniqueItems[1],
> > uniqueItems[2]), "virginica" = uniqueItems[3])
> >
> > levels(finaldataset$Species) <- newlevels
> >
> > levels(finaldataset$Species)
> >
> > finaldataset$Species
> >
> > ---------------------------
> >
> > Thanks in advance,
> >
> > Martin
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> >
> 
> -- 
> Brian D. Ripley,                 
> ripley at stats.ox.ac.uk
> Professor of Applied Statistics, 
> http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865
> 272861 (self)
> 1 South Parks Road,                     +44 1865
> 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865
> 272595
>



From ppancoska at notes.cc.sunysb.edu  Fri Aug 26 21:08:38 2005
From: ppancoska at notes.cc.sunysb.edu (ppancoska@notes.cc.sunysb.edu)
Date: Fri, 26 Aug 2005 15:08:38 -0400
Subject: [R] Pseudo-Voigt fit
Message-ID: <OFC04C1191.ECEE8B3E-ON85257069.0067EF28-85257069.0069294E@notes.cc.sunysb.edu>


Hi, I am sorry for this question, but I am trying to speed up an
application....
I will need to fit many x-y data sets (input from text files) to
4-parameter Pseudo-Voigt peak function.
Until now I used SigmaPlot macro to do it (enclosed just in case...)

peaksign(q) = if(total(q)>q[1], 1, -1)
xatymin(q,r) = xatymax(q,max(r)-r)
[Parameters]
a = if(peaksign(y)>0, max(y), min(y)) ''Auto {{previous: 60.8286}}
b = fwhm(x,abs(y))/2 ''Auto {{previous: 0.656637}}
c = .5 ''Auto {{previous: 6.82973e-010}}
x0 = if(peaksign(y)>0, xatymax(x,y), xatymin(x,y)) ''Auto {{previous:
3.19308}}


[Equation]
f = a*(c*(1/(1+((x-x0)/b)^2))+(1-c)*exp(-0.5*((x-x0)/b)^2))

fit f to y

 (manageable for ~100), but it looks like the next project would need to
process ~1000 member sets.

I am not as familiar with R to find the right info (although I can use R in
general).

I am also nearly sure that there should be a solution to this task "out
there" ready to be modified...

Could you be so kind and direct me please to the right package or web-site
with examples?

Thank you very much



Dr. Petr Pancoska
Department of Pathology
SUNY Stony Brook, NY 11794
phone:          (631)-444-3030

******************************************************************************

This e- mail message, including any attachments,
is for the sole use of the intended recipient(s) and may
contain confidential and privileged information.
Any unauthorized review, use, disclosure or distribution is prohibited.
If you are not the intended recipient, please contact the sender
by e-mail and destroy all copies of the original.



From mschwartz at mn.rr.com  Fri Aug 26 22:42:12 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Fri, 26 Aug 2005 15:42:12 -0500
Subject: [R] Unpaste Problem
In-Reply-To: <a6821d9905082610094a195e14@mail.gmail.com>
References: <a6821d9905082610094a195e14@mail.gmail.com>
Message-ID: <1125088932.4355.91.camel@localhost.localdomain>

On Fri, 2005-08-26 at 22:39 +0530, A Mani wrote:
> Hello,
>         Easy ways to "unpaste"?
>  xp <- paste(x2, x3) # x2, x3 are two non-numeric columns.
> .............
> .........................
> xfg <- data.frame(xp,sc1, sc2, sc3) # sc1,sc2, sc3 are numeric cols.
> 
> I want xp to be split up to form a new dataframe of the form (x3, sc1,
> sc2, sc3).
> IMPORTANT info : elements of xp have the form abc<space>efg, with abc
> in x2 and efg in x3.
> 
> Thanks in advance, 


I think I understand what you are trying to do. Hopefully the below may
be helpful:

# Create the data frame with 3 rows
x2 <- letters[1:3]
x3 <- LETTERS[1:3]
xp <- paste(x2, x3)

sc1 <- rnorm(3)
sc2 <- rnorm(3)
sc3 <- rnorm(3)

xfg <- data.frame(xp, sc1, sc2, sc3)

> xfg
   xp        sc1        sc2        sc3
1 a A  1.3479123 -1.0642578  0.2479218
2 b B -0.1586587  1.1237456 -1.3952176
3 c C  2.7807484 -0.9778066 -1.9322279


# Use strsplit() here to break apart 'xp' using " " as the split
# Use "[" in sapply() to get the second (2) element from each
# 'xp' list pair. Note that I use as.character() here, since xfg$xp is 
# a factor.
# See the output of: strsplit(as.character(xfg$xp), " ")
# for some insight into this approach

xp.split <- sapply(strsplit(as.character(xfg$xp), " "), "[", 2)


# show post split values
> xp.split
[1] "A" "B" "C"


# Now cbind it all together into a new data frame
# don't include column 1 from xfg (xp)
xfg.new <- cbind(xp.split, xfg[, -1])


> xfg.new
  xp.split        sc1        sc2        sc3
1        A  1.3479123 -1.0642578  0.2479218
2        B -0.1586587  1.1237456 -1.3952176
3        C  2.7807484 -0.9778066 -1.9322279


See ?strsplit for more information.
 
HTH,

Marc Schwartz



From djames at frontierassoc.com  Fri Aug 26 22:59:45 2005
From: djames at frontierassoc.com (David James)
Date: Fri, 26 Aug 2005 15:59:45 -0500
Subject: [R] Creating factors from continuous variables
Message-ID: <92996AAC-65A5-4453-83A9-583936E90B73@frontierassoc.com>

What is the quickest way to create many categorical variables  
(factors) from continuous variables?

This is the approach that I have used:

# create sample data
N <- 20
x <- runif(N,0,1)

# setup ranges to define categories
x.a <- (x >= 0.0) & (x < 0.4)
x.b <- (x >= 0.4) & (x < 0.5)
x.c <- (x >= 0.5) & (x < 0.6)
x.d <- (x >= 0.6) & (x < 1.0)

# create factors
i <- runif(N,1,1)
x.new <- (i*1*x.a) + (i*2*x.b) + (i*3*x.c) + (i*4*x.d)
x.factor <- factor(x.new)

I'm looking for a better / simpler / more elegant / more robust (as  
the number of categories increases) way to do this.  I also don't  
like that my factor names can only be numbers in this example.  I  
would prefer a solution to take a form like the following (inspired  
by the "hist" function):

# define breakpoints
x.breaks = c(0, 0.4, 0.5, 0.6, 1.0)
x.factornames = c( "0 - 0.4", "0.4 - 0.5", "0.5 - 0.6", "0.6 - 1.0" )
x.factor = unknown.function( x, x.breaks, x.factornames )

Thanks,
David

P.S. Here's what I have read to try to find the answer to my problem:
* "Introductory Statistics with R"
* "A Brief Guide to R for Beginners in Econometrics"
* "Econometrics in R"



From gunter.berton at gene.com  Fri Aug 26 23:02:55 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Fri, 26 Aug 2005 14:02:55 -0700
Subject: [R] Creating factors from continuous variables
In-Reply-To: <92996AAC-65A5-4453-83A9-583936E90B73@frontierassoc.com>
Message-ID: <200508262102.j7QL2upE015205@ohm.gene.com>

?cut

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of David James
> Sent: Friday, August 26, 2005 2:00 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Creating factors from continuous variables
> 
> What is the quickest way to create many categorical variables  
> (factors) from continuous variables?
> 
> This is the approach that I have used:
> 
> # create sample data
> N <- 20
> x <- runif(N,0,1)
> 
> # setup ranges to define categories
> x.a <- (x >= 0.0) & (x < 0.4)
> x.b <- (x >= 0.4) & (x < 0.5)
> x.c <- (x >= 0.5) & (x < 0.6)
> x.d <- (x >= 0.6) & (x < 1.0)
> 
> # create factors
> i <- runif(N,1,1)
> x.new <- (i*1*x.a) + (i*2*x.b) + (i*3*x.c) + (i*4*x.d)
> x.factor <- factor(x.new)
> 
> I'm looking for a better / simpler / more elegant / more robust (as  
> the number of categories increases) way to do this.  I also don't  
> like that my factor names can only be numbers in this example.  I  
> would prefer a solution to take a form like the following (inspired  
> by the "hist" function):
> 
> # define breakpoints
> x.breaks = c(0, 0.4, 0.5, 0.6, 1.0)
> x.factornames = c( "0 - 0.4", "0.4 - 0.5", "0.5 - 0.6", "0.6 - 1.0" )
> x.factor = unknown.function( x, x.breaks, x.factornames )
> 
> Thanks,
> David
> 
> P.S. Here's what I have read to try to find the answer to my problem:
> * "Introductory Statistics with R"
> * "A Brief Guide to R for Beginners in Econometrics"
> * "Econometrics in R"
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From ripley at stats.ox.ac.uk  Fri Aug 26 23:09:04 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Aug 2005 22:09:04 +0100 (BST)
Subject: [R] Creating factors from continuous variables
In-Reply-To: <92996AAC-65A5-4453-83A9-583936E90B73@frontierassoc.com>
References: <92996AAC-65A5-4453-83A9-583936E90B73@frontierassoc.com>
Message-ID: <Pine.LNX.4.61.0508262206180.19304@gannet.stats>

?cut

This is in `An Introduction to R', the manual which ships with R and basic 
reading.

On Fri, 26 Aug 2005, David James wrote:

> What is the quickest way to create many categorical variables
> (factors) from continuous variables?
>
> This is the approach that I have used:
>
> # create sample data
> N <- 20
> x <- runif(N,0,1)
>
> # setup ranges to define categories
> x.a <- (x >= 0.0) & (x < 0.4)
> x.b <- (x >= 0.4) & (x < 0.5)
> x.c <- (x >= 0.5) & (x < 0.6)
> x.d <- (x >= 0.6) & (x < 1.0)
>
> # create factors
> i <- runif(N,1,1)
> x.new <- (i*1*x.a) + (i*2*x.b) + (i*3*x.c) + (i*4*x.d)
> x.factor <- factor(x.new)
>
> I'm looking for a better / simpler / more elegant / more robust (as
> the number of categories increases) way to do this.  I also don't
> like that my factor names can only be numbers in this example.  I
> would prefer a solution to take a form like the following (inspired
> by the "hist" function):
>
> # define breakpoints
> x.breaks = c(0, 0.4, 0.5, 0.6, 1.0)
> x.factornames = c( "0 - 0.4", "0.4 - 0.5", "0.5 - 0.6", "0.6 - 1.0" )
> x.factor = unknown.function( x, x.breaks, x.factornames )
>
> Thanks,
> David
>
> P.S. Here's what I have read to try to find the answer to my problem:
> * "Introductory Statistics with R"
> * "A Brief Guide to R for Beginners in Econometrics"
> * "Econometrics in R"

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ggrothendieck at gmail.com  Fri Aug 26 23:19:01 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 26 Aug 2005 17:19:01 -0400
Subject: [R] Unpaste Problem
In-Reply-To: <a6821d9905082610094a195e14@mail.gmail.com>
References: <a6821d9905082610094a195e14@mail.gmail.com>
Message-ID: <971536df050826141939f4bb0c@mail.gmail.com>

On 8/26/05, A Mani <a.manigs at gmail.com> wrote:
> Hello,
>        Easy ways to "unpaste"?
>  xp <- paste(x2, x3) # x2, x3 are two non-numeric columns.
> .............
> .........................
> xfg <- data.frame(xp,sc1, sc2, sc3) # sc1,sc2, sc3 are numeric cols.
> 
> I want xp to be split up to form a new dataframe of the form (x3, sc1,
> sc2, sc3).
> IMPORTANT info : elements of xp have the form abc<space>efg, with abc
> in x2 and efg in x3.
> 

See

https://www.stat.math.ethz.ch/pipermail/r-help/2005-August/076492.html



From djames at frontierassoc.com  Sat Aug 27 02:09:05 2005
From: djames at frontierassoc.com (David James)
Date: Fri, 26 Aug 2005 19:09:05 -0500
Subject: [R] zoo, zooreg, & ISOdatetime
Message-ID: <088FBE94-5B9E-467C-9782-CE06D33E728D@frontierassoc.com>

I create a zooreg object that runs from Jan-1-2002 0:00 to Jun-1-2005  
0:00...

regts.start = ISOdatetime(2002, 1, 1, hour=0, min=0, sec=0, tz="")
regts.end = ISOdatetime(2005, 6, 1, hour=0, min=0, sec=0, tz="")
regts.zoo <- zooreg( NA, regts.start, regts.end, deltat=3600 )

Upon inspection:
 > regts.zoo[1:3]
2002-01-01 00:00:00 2002-01-01 01:00:00 2002-01-01 02:00:00
                  NA                  NA                  NA

 > regts.zoo[29926:29928]
2005-05-31 22:00:00 2005-05-31 23:00:00 2005-06-01 00:00:00
                  NA                  NA                  NA

However:
 > summary(regts.zoo)
Error in "row.names<-.data.frame"(`*tmp*`, value = c("2002-01-01  
00:00:00",  :
     duplicate 'row.names' are not allowed

I don't understand why it claims that there are duplicate row.names.   
Any advice?

I probably could use the aggregate function to clean this up, but I  
don't see why it should be needed (provided that I do things properly  
in the first place).

Thanks,
David



From r at roryt.gr  Sat Aug 27 03:04:13 2005
From: r at roryt.gr (I.Ioannou)
Date: Sat, 27 Aug 2005 04:04:13 +0300
Subject: [R] PLSR: model notation and reliabilities
Message-ID: <20050827010413.GA27127@argeas.cs-net.gr>


I'm new in both R and statistics. I "did my homework", 
I tried the archives and whatever I managed to get 
from the sources, but still I need assistance with 
the plsr package.


I have a model with 2 core determinants D1 and D2,
made by 3 indicators each (D1a,D1b,D1c and so on).
Also I have 2 moderating variables (m1,m2), where 
m1 moderates D1 and m2 modarates D2. 
The dependent variable (Y) is also constructed by 3 
indicators (Y1,Y2,Y3). Actually my model is far more 
complicated, I just give a simplified example here.

Which is the correct notation for the model 
(I'm skipping the crossvalidation for the moment) : 

  MyModel <- plsr(Y1+Y2+Y3 ~ ((D1a+D1b+D1c)*m1) + ((D2a+D2b+D2c)*m2),ncomp=2)

or :

  Y  <- cbind(Y1,Y2,Y3)
  X1 <- cbind(D1a,D1b,D1c)
  X2 <- cbind(D2a,D2b,D2c)
  MyModel <- plsr( Y ~ (X1*m1) + (X2*m2),ncomp=2) 


How do I calculate the internal composite reliabilty (ICR) ?
Is the Average variable explained (AVE) the mentioned as 
"% variance explained" in summary ?

I tried something like (the model is the first notation 
mentioned above, and the calcualtions below are simplified 
just for clarity) :

ncomp=MyModel$ncomp
P   <- MyModel$loadings[,ncomp]
Q   <- MyModel$Yloadings[,ncomp]
# D1
f1  <- P["D1a"]
f2  <- P["D1b"] 
f3  <- P["D1c"] 
Sp  <- f1 + f2 + f3
Sp2 <- (f1 ^ 2) + (f2^ 2) + (f3^2)
Sth <- (1-(f1 ^ 2)) + (1-(f2 ^ 2)) + (1-(f3^2))
D1_ICR   <- (Sp^2) / ( (Sp^2) + Sth)
D1_AVE <- Sp2 / ( Sp2 + Sth) 

but the results does not seem to give me something meaningfull.  
For example, while  cronbach(cbind(D1a,D1b,D1c)) gives me > 0.90, 
the above computed D1_ICR gives me very low numbers (< .20). 
Also summary says % variance explained for X = 83.1 in 1st component
while my computed D1_AVE is unacceptable (< 10%). 
Where I made it wrong ? Or it is just my data ?

Any help will be much appriciated

TIA



From djames at frontierassoc.com  Sat Aug 27 03:41:49 2005
From: djames at frontierassoc.com (David James)
Date: Fri, 26 Aug 2005 20:41:49 -0500
Subject: [R] ARIMA (seasonal) backcasting & interpolation
Message-ID: <3DA78EDC-3D3B-4F04-8578-7FA0CBE6E70B@frontierassoc.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050826/8c1a517a/attachment.pl

From ggrothendieck at gmail.com  Sat Aug 27 04:15:03 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 26 Aug 2005 22:15:03 -0400
Subject: [R] zoo, zooreg, & ISOdatetime
In-Reply-To: <088FBE94-5B9E-467C-9782-CE06D33E728D@frontierassoc.com>
References: <088FBE94-5B9E-467C-9782-CE06D33E728D@frontierassoc.com>
Message-ID: <971536df050826191579c65057@mail.gmail.com>

On 8/26/05, David James <djames at frontierassoc.com> wrote:
> I create a zooreg object that runs from Jan-1-2002 0:00 to Jun-1-2005
> 0:00...
> 
> regts.start = ISOdatetime(2002, 1, 1, hour=0, min=0, sec=0, tz="")
> regts.end = ISOdatetime(2005, 6, 1, hour=0, min=0, sec=0, tz="")
> regts.zoo <- zooreg( NA, regts.start, regts.end, deltat=3600 )
> 
> Upon inspection:
>  > regts.zoo[1:3]
> 2002-01-01 00:00:00 2002-01-01 01:00:00 2002-01-01 02:00:00
>                  NA                  NA                  NA
> 
>  > regts.zoo[29926:29928]
> 2005-05-31 22:00:00 2005-05-31 23:00:00 2005-06-01 00:00:00
>                  NA                  NA                  NA
> 
> However:
>  > summary(regts.zoo)
> Error in "row.names<-.data.frame"(`*tmp*`, value = c("2002-01-01
> 00:00:00",  :
>     duplicate 'row.names' are not allowed
> 
> I don't understand why it claims that there are duplicate row.names.

Because you are using tz = "" and when the time falls back in fall 2am is 1am 
so you wind up having two 1am's which is not allowed.   The times
themselves are
ok but the names are duplicated which is not allowed either.  Thanks for
finding this problem.

> Any advice?

1. Use tz = "GMT" rather than tz = "" since GMT has no daylight savings time 
and won't result in duplicate names.

> regts.start = ISOdatetime(2002, 1, 1, hour=0, min=0, sec=0, tz="GMT")
> regts.end = ISOdatetime(2005, 6, 1, hour=0, min=0, sec=0, tz="GMT")
> regts.zoo <- zooreg( NA, regts.start, regts.end, deltat=3600 )

2. As advised last time use chron if you don't need time zones.

3. Read the R News 4/1 article I previously recommended, which has the
same advice as #2 plus a lot more info on dates and times.

4. If you are using time zones and do need POSIXct and tz = "" then let me know 
privately and I will send you the devel version of zoo where I just fixed it.

> 
> I probably could use the aggregate function to clean this up, but I
> don't see why it should be needed (provided that I do things properly
> in the first place).

Yes.  It should not be needed.

> 
> Thanks,
> David
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From spencer.graves at pdf.com  Sat Aug 27 04:55:19 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Fri, 26 Aug 2005 19:55:19 -0700
Subject: [R] How to add values on the axes of the 3D bi-variable lrm fit?
In-Reply-To: <000701c5a720$56bc24d0$1145210a@agr.ad10.intern.kuleuven.ac.be>
References: <000701c5a720$56bc24d0$1145210a@agr.ad10.intern.kuleuven.ac.be>
Message-ID: <430FD617.5020800@pdf.com>

	  I have not seen a reply to this, so I will offer a few comments.

	  1.  I haven't used "lrm", but I assume you are referring to the copy 
in the "Design" package;  I surmised that from reviewing 
RSiteSearch("lrm").

	  2.  I installed "Design" and learned that I also needed "Hmisc, so I 
installed that also.  The example you provided was not complete in 
itself, so that presented another obstacle to helping you.  I therefore 
worked through examples with the documentation for "lrm", from which I 
learned that your "fit" was of class "Design".

	  3.  The led me to the documentation for "plot.Design".  The examples 
there included one that produced a perspective plot.

	  4.  I then read the documentation for "persp" and learned that it had 
an argument 'ticktype' with a nondefault value of "detailed", which 
should produce what you want.

	  5.  When I added 'ticktype="detailed"' to the call to "plot", I got 
an error message.  I then started reading the code for "plot.Design" and 
learned that it had an argument 'perspArgs'.  The documentation for 
"plot.Design" told me that was "a list containing other named arguments 
to be passed to 'persp'".  I tried that and it worked.

	  6.  In the future, I believe you can increase your chances of getting 
a useful reply quickly if you PLEASE do read and follow the posting 
guide! "http://www.R-project.org/posting-guide.html".

	  Best Wishes,
	  spencer graves

Jan Verbesselt wrote:

>  
> 
> Dear r-list,
> 
>  
> 
> When I try to plot the following 3D lrm fit I obtain only arrows with labels
> on the three axes of the figure (without values).
> 
>  
> 
> fit <- lrm(y ~ rcs(x1,knots)+rcs(x2,knots), tol=1e-14,X=T,Y=T)
> 
> dd <- datadist(x1,x2);options(datadist='dd');
> 
> par(mfrow=c(1,1))
> 
> plot(fit,x1=NA, x2=NA, theta=50,phi=25)
> 
>  
> 
> How can I add values to the axes of this plot?  (axes with the range of
> values of each of the explanatory variables x1&x2)
> 
>  
> 
> Thanks,
> 
> Jan
> 
>  
> 
>  
> 
> _______________________________________________________________________
> Ir. Jan Verbesselt
> Research Associate
> Group of Geomatics Engineering
> Department Biosystems ~ M??-BIORES
> Vital Decosterstraat 102, 3000 Leuven, Belgium
> Tel: +32-16-329750   Fax: +32-16-329760
> http://gloveg.kuleuven.ac.be/
> _______________________________________________________________________
> 
>  
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From ggrothendieck at gmail.com  Sat Aug 27 05:25:33 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 26 Aug 2005 23:25:33 -0400
Subject: [R] ARIMA (seasonal) backcasting & interpolation
In-Reply-To: <3DA78EDC-3D3B-4F04-8578-7FA0CBE6E70B@frontierassoc.com>
References: <3DA78EDC-3D3B-4F04-8578-7FA0CBE6E70B@frontierassoc.com>
Message-ID: <971536df050826202571ef1ec1@mail.gmail.com>

On 8/26/05, David James <djames at frontierassoc.com> wrote:
> Thanks for everyone's help with zoo -- I think I've got my data set
> ready.  (The data consists of surface weather temperatures, from 2002
> to 2005, one observation per hour.  Some values are missing... i.e. NA)
>
> I have three goals:
>
> GOAL #1:Get the data in proper time series form, preserving frequency
> information:
> > w4.ts <- as.ts( w3.zoo, frequency=(1/3600) )
> I hope that 1/3600 (0.0002778) is correct.  I chose it because my
> zooreg object reported that value.  This goes back to my choice of
> the ISOdatetime format, which required deltat=3600.

I will just address the zoo portion of this question.

In the ts class, a period is a unit so lets assume we want the
resulting series to have a day represented as a unit.  Then
we first create a zoo series such that the integer part of the index
is a day and then converting that is easy:

regts.day <- zoo(coredata(regts.zoo), as.numeric(time(regts.zoo))/(24*3600))
regts.ts <- as.ts(regts.day)

or convert it to chron first in which case its easy too:

library(chron)
regts.chron <- zoo(coredata(regts.zoo), as.chron(time(regts.zoo)))
regts.ts <- as.ts(regts.chron)

Of course had chron been used in the first place just the last line
would be needed.

Note that there are some issues as to which time zone is being used
during conversion which I won't address but you can avoid that by just
using chron right from the beginning.  If you do use chron right from the
beginning you won't have the problem with daylight savings time, you
won't have the problem that the POSIXct and ts representations are very
different and you won't have the problem of worrying about time zones.



From uofiowa at gmail.com  Sat Aug 27 06:51:43 2005
From: uofiowa at gmail.com (Omar Lakkis)
Date: Sat, 27 Aug 2005 00:51:43 -0400
Subject: [R] better than sapply
Message-ID: <3f87cc6d0508262151a449288@mail.gmail.com>

I have the following two mapping data frames (r) and (h). I want to
fill teh value of r$seid with the value of r$seid where r$cid==h$cid.
I can do it with sapply as such:

> r$seid = sapply(r$cid, function(cid) h[h$cid==cid,]$seid)

Is ther a better (faster) way to do this?

> r <- data.frame(seid=NA, cid= c(2181,2221,2222))
> r
  seid      cid 
1  NA    2181   
2  NA    2221   
3  NA    2222   

> h <- data.frame(seid= c(5598,5609,4931,5611,8123,8122), cid= c(2219,2222,2181,2190,2817,2221))
> h
     cid  seid 
1 5598 2219    
2 5609 2222     
3 4931 2181  
4 5611 2190   
5 8123 2817   
6 8122 2221   
  
to get the desired result of:
> r
  seid  cid
1 4931 2181
2 8122 2221
3 5609 2222



From ggrothendieck at gmail.com  Sat Aug 27 07:15:24 2005
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 27 Aug 2005 01:15:24 -0400
Subject: [R] better than sapply
In-Reply-To: <3f87cc6d0508262151a449288@mail.gmail.com>
References: <3f87cc6d0508262151a449288@mail.gmail.com>
Message-ID: <971536df05082622154b735b46@mail.gmail.com>

I don't know if its faster but you could try timing this to find out:

r$seid <- merge(h, r, by = "cid")[,2]


On 8/27/05, Omar Lakkis <uofiowa at gmail.com> wrote:
> I have the following two mapping data frames (r) and (h). I want to
> fill teh value of r$seid with the value of r$seid where r$cid==h$cid.
> I can do it with sapply as such:
> 
> > r$seid = sapply(r$cid, function(cid) h[h$cid==cid,]$seid)
> 
> Is ther a better (faster) way to do this?
> 
> > r <- data.frame(seid=NA, cid= c(2181,2221,2222))
> > r
>  seid      cid
> 1  NA    2181
> 2  NA    2221
> 3  NA    2222
> 
> > h <- data.frame(seid= c(5598,5609,4931,5611,8123,8122), cid= c(2219,2222,2181,2190,2817,2221))
> > h
>     cid  seid
> 1 5598 2219
> 2 5609 2222
> 3 4931 2181
> 4 5611 2190
> 5 8123 2817
> 6 8122 2221
> 
> to get the desired result of:
> > r
>  seid  cid
> 1 4931 2181
> 2 8122 2221
> 3 5609 2222
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From dlalountas at yahoo.com  Sat Aug 27 08:50:59 2005
From: dlalountas at yahoo.com (denis lalountas)
Date: Fri, 26 Aug 2005 23:50:59 -0700 (PDT)
Subject: [R] survival parametric question
Message-ID: <20050827065059.72343.qmail@web54610.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050826/4b1bcdb2/attachment.pl

From dhinds at sonic.net  Sat Aug 27 09:35:03 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Sat, 27 Aug 2005 07:35:03 +0000 (UTC)
Subject: [R] ROracle and select query empty
References: <430E000D.6020009@mcgill.ca>
Message-ID: <dep537$o8f$1@sea.gmane.org>

Mathieu Drapeau <mathieu.drapeau at mcgill.ca> wrote:
> Hi,
> I just installed ROracle and RDBI. The connection to the database seems 
> to work also. My problem is when I am selection rows that really exist 
> in the database, it is returning nothing. Where should I look to see 
> what could be my problem?

What platform are you running R on?  And what version of Oracle?  This
sounds very familiar... are you building ROracle on Linux?

-- David Hinds



From p.dalgaard at biostat.ku.dk  Sat Aug 27 10:10:48 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Aug 2005 10:10:48 +0200
Subject: [R] Creating factors from continuous variables
In-Reply-To: <Pine.LNX.4.61.0508262206180.19304@gannet.stats>
References: <92996AAC-65A5-4453-83A9-583936E90B73@frontierassoc.com>
	<Pine.LNX.4.61.0508262206180.19304@gannet.stats>
Message-ID: <x2k6i7vlyv.fsf@turmalin.kubism.ku.dk>

Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

> ?cut
> 
> This is in `An Introduction to R', the manual which ships with R and basic 
> reading.

...as well as in the Compendium section and in an exercise in Ch.1 in
at least one of the cited references. 

> > P.S. Here's what I have read to try to find the answer to my problem:
> > * "Introductory Statistics with R"
> > * "A Brief Guide to R for Beginners in Econometrics"
> > * "Econometrics in R"

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From stgries_lists at arcor.de  Fri Aug 26 19:42:13 2005
From: stgries_lists at arcor.de (Stefan Th. Gries)
Date: Fri, 26 Aug 2005 19:42:13 +0200 (CEST)
Subject: [R] parts of data frames: subset vs. [-c()]
In-Reply-To: <x2d5o0u08e.fsf@turmalin.kubism.ku.dk>
References: <x2d5o0u08e.fsf@turmalin.kubism.ku.dk>
	<19509256.1125073071467.JavaMail.ngmail@webmail-07.arcor-online.net>
Message-ID: <9807970.1125078133179.JavaMail.ngmail@webmail-09.arcor-online.net>

>> From: "Stefan Th. Gries" <stgries_lists at arcor.de> writes:
I have a problem with splitting up a data frame called ReVerb: I would like to extract all cases where SYNTAX=="Ditrans" from ReVerb, store that in a file, and then generate ReVerb again without these cases and factor levels. My problem is probably obvious from the following lines of code:

> ditrans<-which(SYNTAX=="Ditrans")
> ReVerb1<-ReVerb[-c(ditrans),]; dim(ReVerb1)
[1] 91532    16
# ok, so the 92713-91532=1181 cases where SYNTAX=="Ditrans" have been removed, but ...
> ReVerb1<-subset(ReVerb, SYNTAX!="Ditrans"); dim(ReVerb1)
[1] 91528    16
# ... so why don't I get 91532 again as the number of rows?
# Any ideas??

> From: Peter Dalgaard <p.dalgaard at biostat.ku.dk>
> The SYNTAX variable is not necessarily the same. Could you retry the first case with
> ditrans <- which(ReVerb$SYNTAX=="Ditrans")
> ?

The results were the same as with 'ditrans<-which(SYNTAX=="Ditrans")'.

> Otherwise, try doing a setdiff() on the rownames of the two discrepant results and see which are the four cases that differ.

This solved the issue: Using setdiff, I found that the cases that the second way with subset fails to include are NA's ... - I was not aware of how subset treats NA, sorry.

Thanks a lot,
STG
--
Stefan Th. Gries
----------------------------------------
Max Planck Inst. for Evol. Anthropology
http://people.freenet.de/Stefan_Th_Gries
----------------------------------------

Machen Sie aus 14 Cent spielend bis zu 100 Euro!
Die neue Gaming-Area von Arcor - ??ber 50 Onlinespiele im Angebot.
http://www.arcor.de/rd/emf-gaming-1



From ripley at stats.ox.ac.uk  Sat Aug 27 11:28:18 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 27 Aug 2005 10:28:18 +0100 (BST)
Subject: [R] zoo, zooreg, & ISOdatetime
In-Reply-To: <088FBE94-5B9E-467C-9782-CE06D33E728D@frontierassoc.com>
References: <088FBE94-5B9E-467C-9782-CE06D33E728D@frontierassoc.com>
Message-ID: <Pine.LNX.4.61.0508271022280.26920@gannet.stats>

On Fri, 26 Aug 2005, David James wrote:

> I create a zooreg object that runs from Jan-1-2002 0:00 to Jun-1-2005
> 0:00...
>
> regts.start = ISOdatetime(2002, 1, 1, hour=0, min=0, sec=0, tz="")
> regts.end = ISOdatetime(2005, 6, 1, hour=0, min=0, sec=0, tz="")
> regts.zoo <- zooreg( NA, regts.start, regts.end, deltat=3600 )
>
> Upon inspection:
> > regts.zoo[1:3]
> 2002-01-01 00:00:00 2002-01-01 01:00:00 2002-01-01 02:00:00
>                  NA                  NA                  NA
>
> > regts.zoo[29926:29928]
> 2005-05-31 22:00:00 2005-05-31 23:00:00 2005-06-01 00:00:00
>                  NA                  NA                  NA
>
> However:
> > summary(regts.zoo)
> Error in "row.names<-.data.frame"(`*tmp*`, value = c("2002-01-01
> 00:00:00",  :
>     duplicate 'row.names' are not allowed
>
> I don't understand why it claims that there are duplicate row.names.
> Any advice?
>
> I probably could use the aggregate function to clean this up, but I
> don't see why it should be needed (provided that I do things properly
> in the first place).

This is a bug in the zoo package, so please raise it with the maintainer.
Hint: incrementing through a DST change in hourly intervals will result in 
duplicate time labels, as in

[24811] "2004-10-30 19:00:00 BST" "2004-10-30 20:00:00 BST"
[24813] "2004-10-30 21:00:00 BST" "2004-10-30 22:00:00 BST"
[24815] "2004-10-30 23:00:00 BST" "2004-10-31 00:00:00 BST"
[24817] "2004-10-31 01:00:00 BST" "2004-10-31 01:00:00 GMT"
[24819] "2004-10-31 02:00:00 GMT" "2004-10-31 03:00:00 GMT"
[24821] "2004-10-31 04:00:00 GMT" "2004-10-31 05:00:00 GMT"
[24823] "2004-10-31 06:00:00 GMT" "2004-10-31 07:00:00 GMT"
[24825] "2004-10-31 08:00:00 GMT" "2004-10-31 09:00:00 GMT"

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Sat Aug 27 13:20:40 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 27 Aug 2005 12:20:40 +0100 (BST)
Subject: [R] survival parametric question
In-Reply-To: <20050827065059.72343.qmail@web54610.mail.yahoo.com>
References: <20050827065059.72343.qmail@web54610.mail.yahoo.com>
Message-ID: <Pine.LNX.4.61.0508271215020.2871@gannet.stats>

The survival package is a recommended package in R and contains survreg() 
which uses the AFT definitions for Weibull survival.  This is well 
documented, and MASS (the book) has comparisons of PH and AFT 
parametrization for a Weibull example.

I think you mean Frank Harrell's `Design' package.  As far as I am aware 
that has a function psm() (not PSM) which is based on survreg(), so the 
interpretation should be the same.

On Fri, 26 Aug 2005, denis lalountas wrote:

> Hi to all,
> I am working on design package using survival function.
> First using PSM and adopting a weibull specification for the baseline hazard , I have got the following results(since weibull has both PH and AFT propreties ,in addition I have used the PPHSm command):
>
>  Value Std. Error      z        p
>
> (Intercept)  1.768     1.0007   1.77 7.73e-02
>
> SIZE        -0.707     0.0895  -7.90 2.80e-15
>
> REtoTA      -0.896     0.4208  -2.13 3.33e-02
>
> D1toEQ       0.281     0.0330   8.51 1.81e-17
>
> EBTtoTA     -6.706     1.0807  -6.21 5.46e-10
>
> SALtoTA     -3.943     0.3575 -11.03 2.78e-28
>
> fishes       2.619     0.4194   6.24 4.26e-10
>
> computers    2.781     0.2105  13.21 7.35e-40
>
> Log(scale)  -0.945     0.1514  -6.24 4.25e-10
>
> and the loglikelihood -82.0
>
> I dont know the specification of the weibull that Desing package uses so 
> I can't evaluate the result.
>
> For comparison reasons I have estimated the same model using another 
> spftware EasyReg
>
> wich gave the following results( the weibull specification has the form 
> a(1).a(2).t^(a(2)-1):
>
> parameters ML estimate t-value p-value Covariates
>
> beta(1)       2.411460   2.136 0.03265 fishes
>
> beta(2)       2.710115   3.322 0.00089 computers
>
> beta(3)      -7.539632  -2.646 0.00815 EBTtoTA
>
> beta(4)      -3.720231  -2.547 0.01086 SALtoTA
>
> beta(5)       0.262115   1.982 0.04751 D1toEQ
>
> beta(6)      -0.710535  -0.515 0.60684 REtoTA
>
> beta(7)      -0.493369  -1.938 0.05262 LOG(SIZE)
>
> alpha(1)      0.485828   0.392 0.69491
>
> alpha(2)      2.597073   5.516 0.00000
>
> log(L)=-83,4
>
> First observe that the results are almost the same but the weibull parameters are not.
>
> acooring to the weibull specification that easyreg uses a(2)>0 so the baseline hazard is monotonically increases ,acording to my expectations :(the empirical uncoditional hazard increases monotonically from t=1,12 and then decreases to zero)
>
> My question is what is the weibull specification that R-design package uses for the baseline hazard. Second ,it is possible to plot the baseline hazard in R , in order to "see" the accelerating-decelerating effect in the AFT case.
>
> In addition how can simulate a model in the AFT case ( some examples of simulation are given in the design manual for the COX-PH case.
>
> I hope that my questions are not borring, if so sory I am a new user of R package.
>
> Best regards
>
> D.Lalountas
>
> University of Patras , Greece
>
>
>
> ---------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From chezsmithy at yahoo.co.uk  Sat Aug 27 14:13:39 2005
From: chezsmithy at yahoo.co.uk (katrina smith)
Date: Sat, 27 Aug 2005 13:13:39 +0100 (BST)
Subject: [R] two-tailed exact binomail test
Message-ID: <20050827121339.35330.qmail@web25403.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050827/21e72c8f/attachment.pl

From olsson1 at gmail.com  Sat Aug 27 14:51:02 2005
From: olsson1 at gmail.com (P. Olsson)
Date: Sat, 27 Aug 2005 14:51:02 +0200
Subject: [R] two-tailed exact binomail test
In-Reply-To: <20050827121339.35330.qmail@web25403.mail.ukl.yahoo.com>
References: <20050827121339.35330.qmail@web25403.mail.ukl.yahoo.com>
Message-ID: <e984efc60508270551156fd0ff@mail.gmail.com>

You might find the answer in Chapter 2 of Nonparametric statistical
methods written by Myles Hollander and Douglas A. Wolfe (2nd ed.,
ISBN: 0-471-19045-4)

2005/8/27, katrina smith <chezsmithy at yahoo.co.uk>:
> I am trying to find a definition for the two-tailed exact binomial test but have been unsuccessful. Can you help?
> 
> 
> 
> 
> ---------------------------------
> 
>         [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From f.harrell at vanderbilt.edu  Sat Aug 27 14:57:09 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sat, 27 Aug 2005 07:57:09 -0500
Subject: [R] survival parametric question
In-Reply-To: <Pine.LNX.4.61.0508271215020.2871@gannet.stats>
References: <20050827065059.72343.qmail@web54610.mail.yahoo.com>
	<Pine.LNX.4.61.0508271215020.2871@gannet.stats>
Message-ID: <43106325.8000507@vanderbilt.edu>

Prof Brian Ripley wrote:
> The survival package is a recommended package in R and contains survreg() 
> which uses the AFT definitions for Weibull survival.  This is well 
> documented, and MASS (the book) has comparisons of PH and AFT 
> parametrization for a Weibull example.
> 
> I think you mean Frank Harrell's `Design' package.  As far as I am aware 
> that has a function psm() (not PSM) which is based on survreg(), so the 
> interpretation should be the same.

Yes, at least until you run a psm Weibull fit through the pphsm 
convertor function.  I recommend that Denis run the psm fit through 
Design's Hazard and Survival functions to create S functions containing 
the analytic representation of hazard and survival functions.  There's 
also Mean and Quantile, and latex.psm.

Frank

> 
> On Fri, 26 Aug 2005, denis lalountas wrote:
> 
> 
>>Hi to all,
>>I am working on design package using survival function.
>>First using PSM and adopting a weibull specification for the baseline hazard , I have got the following results(since weibull has both PH and AFT propreties ,in addition I have used the PPHSm command):
>>
>> Value Std. Error      z        p
>>
>>(Intercept)  1.768     1.0007   1.77 7.73e-02
>>
>>SIZE        -0.707     0.0895  -7.90 2.80e-15
>>
>>REtoTA      -0.896     0.4208  -2.13 3.33e-02
>>
>>D1toEQ       0.281     0.0330   8.51 1.81e-17
>>
>>EBTtoTA     -6.706     1.0807  -6.21 5.46e-10
>>
>>SALtoTA     -3.943     0.3575 -11.03 2.78e-28
>>
>>fishes       2.619     0.4194   6.24 4.26e-10
>>
>>computers    2.781     0.2105  13.21 7.35e-40
>>
>>Log(scale)  -0.945     0.1514  -6.24 4.25e-10
>>
>>and the loglikelihood -82.0
>>
>>I dont know the specification of the weibull that Desing package uses so 
>>I can't evaluate the result.
>>
>>For comparison reasons I have estimated the same model using another 
>>spftware EasyReg
>>
>>wich gave the following results( the weibull specification has the form 
>>a(1).a(2).t^(a(2)-1):
>>
>>parameters ML estimate t-value p-value Covariates
>>
>>beta(1)       2.411460   2.136 0.03265 fishes
>>
>>beta(2)       2.710115   3.322 0.00089 computers
>>
>>beta(3)      -7.539632  -2.646 0.00815 EBTtoTA
>>
>>beta(4)      -3.720231  -2.547 0.01086 SALtoTA
>>
>>beta(5)       0.262115   1.982 0.04751 D1toEQ
>>
>>beta(6)      -0.710535  -0.515 0.60684 REtoTA
>>
>>beta(7)      -0.493369  -1.938 0.05262 LOG(SIZE)
>>
>>alpha(1)      0.485828   0.392 0.69491
>>
>>alpha(2)      2.597073   5.516 0.00000
>>
>>log(L)=-83,4
>>
>>First observe that the results are almost the same but the weibull parameters are not.
>>
>>acooring to the weibull specification that easyreg uses a(2)>0 so the baseline hazard is monotonically increases ,acording to my expectations :(the empirical uncoditional hazard increases monotonically from t=1,12 and then decreases to zero)
>>
>>My question is what is the weibull specification that R-design package uses for the baseline hazard. Second ,it is possible to plot the baseline hazard in R , in order to "see" the accelerating-decelerating effect in the AFT case.
>>
>>In addition how can simulate a model in the AFT case ( some examples of simulation are given in the design manual for the COX-PH case.
>>
>>I hope that my questions are not borring, if so sory I am a new user of R package.
>>
>>Best regards
>>
>>D.Lalountas
>>
>>University of Patras , Greece
>>
>>
>>
>>---------------------------------
>>
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From p.dalgaard at biostat.ku.dk  Sat Aug 27 15:12:05 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Aug 2005 15:12:05 +0200
Subject: [R] two-tailed exact binomail test
In-Reply-To: <20050827121339.35330.qmail@web25403.mail.ukl.yahoo.com>
References: <20050827121339.35330.qmail@web25403.mail.ukl.yahoo.com>
Message-ID: <x2br3jv80q.fsf@turmalin.kubism.ku.dk>

katrina smith <chezsmithy at yahoo.co.uk> writes:

> I am trying to find a definition for the two-tailed exact binomial
> test but have been unsuccessful. Can you help?

Just read binom.test. The relevant bit is this:
(m is the mean == n*p)

            else if (x < m) {
                i <- seq(from = ceiling(m), to = n)
                y <- sum(dbinom(i, n, p) <= d * relErr)
                pbinom(x, n, p) + pbinom(n - y, n, p, lower = FALSE)
            }

i.e. we take the lower tail, including the value observed + the part
of the upper tail where the binomial density is less than or equal to
that of x (with a little fuzz added in). Symmetrically for observations
in the upper tail of course.

If you were looking for an "official" definition of the two sided
exact test, I don't think one exists. R's version is equivalent to the
likelihood ratio test, but there are alternatives (tail-balancing,
doubling the one-sided p, and maybe more).

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From dgoliche at sclc.ecosur.mx  Sat Aug 27 18:31:20 2005
From: dgoliche at sclc.ecosur.mx (Duncan Golicher)
Date: Sat, 27 Aug 2005 11:31:20 -0500
Subject: [R] writing to a fixed format (fortran) file
Message-ID: <43109558.8070803@sclc.ecosur.mx>

Could anyone help with what should be a simple task? I have data as a 
fixed format (fortran) table. I  have no trouble getting it into R using 
read.table. Each column is separated by a space, including the first 
column that begins with a space, and aligned. It reads into R as if 
separated by tabs. However I want to manipulate two columns of data then 
write the results out into exactly the same fortran format for use in 
another program.  It should be simple, but I've tried a variety of 
experiments with print, cat and format, none of which have come close.

Here is a sample of the data.

  1  1    1  19.5  2.42 0.02   5.81   9.7   0.4 102.  4.8  320.   4.8
  2  1    1   0.0  0.00 0.00   0.00   4.7  -4.0 178.  5.4  301.   0.2
  3  1    1   8.2  1.64 0.08   6.93   6.9  -3.6 275.  2.7   84. -11.1
  4  1    1   0.0  0.00 0.00   0.00  20.6  -4.8 221.  5.6  327. -10.4
  5  1    1   0.0  0.00 0.00   0.00  11.6   8.2 168.  4.3  269.   6.8
  6  1    1   0.0  0.00 0.00   0.00  18.7  16.9 155.  5.6  287.   8.2
  7  1    1   0.0  0.00 0.00   0.00   7.0   2.1 195.  2.7   22.   0.1
  8  1    1   0.0  0.00 0.00   0.00  17.6   6.5 281.  2.0  146.   1.5
  9  1    1  41.2  1.54 0.82   6.96  12.2   7.8 268.  5.5  356.   4.5
 10  1    1   0.0  0.00 0.00   0.00  14.6  -1.4 250.  3.6  344.   6.4
 11  1    1   0.0  0.00 0.00   0.00  14.5  -3.7 300.  0.0    0. -16.9
 12  1    1   0.0  0.00 0.00   0.00   8.8  -2.6 308.  0.0    0.   2.9
 13  1    1   0.0  0.00 0.00   0.00   6.4   1.6 226.  3.3  335.   3.8

-- 

Dr Duncan Golicher
Ecologia y Sistematica Terrestre
Conservaci??n de la Biodiversidad
El Colegio de la Frontera Sur
San Cristobal de Las Casas, 
Chiapas, Mexico

Email: dgoliche at sclc.ecosur.mx



From r.shengzhe at gmail.com  Sat Aug 27 18:46:50 2005
From: r.shengzhe at gmail.com (Shengzhe Wu)
Date: Sat, 27 Aug 2005 18:46:50 +0200
Subject: [R] Help: lda predict
In-Reply-To: <Pine.LNX.4.61.0508261452130.9514@gannet.stats>
References: <ea57975b0508260401516ea8db@mail.gmail.com>
	<Pine.LNX.4.61.0508261217400.14256@gannet.stats>
	<ea57975b0508260551435006f4@mail.gmail.com>
	<Pine.LNX.4.61.0508261405240.8861@gannet.stats>
	<ea57975b050826063130faf3ef@mail.gmail.com>
	<Pine.LNX.4.61.0508261452130.9514@gannet.stats>
Message-ID: <ea57975b0508270946b26fea5@mail.gmail.com>

Hello,

I use qda (package "MASS") to obtain an object. If there is any
function to plot density plot of qda object with one dimension?

Thank you,
Shengzhe



From ripley at stats.ox.ac.uk  Sat Aug 27 18:48:55 2005
From: ripley at stats.ox.ac.uk (Brian D Ripley)
Date: Sat, 27 Aug 2005 17:48:55 +0100 (BST)
Subject: [R] Help: lda predict
In-Reply-To: <ea57975b0508270946b26fea5@mail.gmail.com>
Message-ID: <Pine.GSO.4.31.0508271747430.22355-100000@markov.stats>

On Sat, 27 Aug 2005, Shengzhe Wu wrote:

> Hello,
>
> I use qda (package "MASS") to obtain an object. If there is any
> function to plot density plot of qda object with one dimension$B!)(B

That makes no sense.  qda objects do not have a density.

Please do study the background material (as you have been repeatedly asked
to do).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From jeaneid at chass.utoronto.ca  Sat Aug 27 18:52:02 2005
From: jeaneid at chass.utoronto.ca (Jean Eid)
Date: Sat, 27 Aug 2005 12:52:02 -0400
Subject: [R] writing to a fixed format (fortran) file
In-Reply-To: <43109558.8070803@sclc.ecosur.mx>
Message-ID: <Pine.SGI.4.40.0508271251480.923463-100000@origin.chass.utoronto.ca>

why not write.table with sep="\t"

On Sat, 27 Aug 2005, Duncan Golicher wrote:

> Could anyone help with what should be a simple task? I have data as a
> fixed format (fortran) table. I  have no trouble getting it into R using
> read.table. Each column is separated by a space, including the first
> column that begins with a space, and aligned. It reads into R as if
> separated by tabs. However I want to manipulate two columns of data then
> write the results out into exactly the same fortran format for use in
> another program.  It should be simple, but I've tried a variety of
> experiments with print, cat and format, none of which have come close.
>
> Here is a sample of the data.
>
>   1  1    1  19.5  2.42 0.02   5.81   9.7   0.4 102.  4.8  320.   4.8
>   2  1    1   0.0  0.00 0.00   0.00   4.7  -4.0 178.  5.4  301.   0.2
>   3  1    1   8.2  1.64 0.08   6.93   6.9  -3.6 275.  2.7   84. -11.1
>   4  1    1   0.0  0.00 0.00   0.00  20.6  -4.8 221.  5.6  327. -10.4
>   5  1    1   0.0  0.00 0.00   0.00  11.6   8.2 168.  4.3  269.   6.8
>   6  1    1   0.0  0.00 0.00   0.00  18.7  16.9 155.  5.6  287.   8.2
>   7  1    1   0.0  0.00 0.00   0.00   7.0   2.1 195.  2.7   22.   0.1
>   8  1    1   0.0  0.00 0.00   0.00  17.6   6.5 281.  2.0  146.   1.5
>   9  1    1  41.2  1.54 0.82   6.96  12.2   7.8 268.  5.5  356.   4.5
>  10  1    1   0.0  0.00 0.00   0.00  14.6  -1.4 250.  3.6  344.   6.4
>  11  1    1   0.0  0.00 0.00   0.00  14.5  -3.7 300.  0.0    0. -16.9
>  12  1    1   0.0  0.00 0.00   0.00   8.8  -2.6 308.  0.0    0.   2.9
>  13  1    1   0.0  0.00 0.00   0.00   6.4   1.6 226.  3.3  335.   3.8
>
> --
>
> Dr Duncan Golicher
> Ecologia y Sistematica Terrestre
> Conservación de la Biodiversidad
> El Colegio de la Frontera Sur
> San Cristobal de Las Casas,
> Chiapas, Mexico
>
> Email: dgoliche at sclc.ecosur.mx
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From sean.oriordain at gmail.com  Sat Aug 27 18:57:40 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Sat, 27 Aug 2005 17:57:40 +0100
Subject: [R] writing to a fixed format (fortran) file
In-Reply-To: <43109558.8070803@sclc.ecosur.mx>
References: <43109558.8070803@sclc.ecosur.mx>
Message-ID: <8ed68eed0508270957243f8ada@mail.gmail.com>

?sprintf

more C than fortran, but you get the idea :-)

cheers!
Sean

On 27/08/05, Duncan Golicher <dgoliche at sclc.ecosur.mx> wrote:
> Could anyone help with what should be a simple task? I have data as a
> fixed format (fortran) table. I  have no trouble getting it into R using
> read.table. Each column is separated by a space, including the first
> column that begins with a space, and aligned. It reads into R as if
> separated by tabs. However I want to manipulate two columns of data then
> write the results out into exactly the same fortran format for use in
> another program.  It should be simple, but I've tried a variety of
> experiments with print, cat and format, none of which have come close.
> 
> Here is a sample of the data.
> 
>   1  1    1  19.5  2.42 0.02   5.81   9.7   0.4 102.  4.8  320.   4.8
>   2  1    1   0.0  0.00 0.00   0.00   4.7  -4.0 178.  5.4  301.   0.2
>   3  1    1   8.2  1.64 0.08   6.93   6.9  -3.6 275.  2.7   84. -11.1
>   4  1    1   0.0  0.00 0.00   0.00  20.6  -4.8 221.  5.6  327. -10.4
>   5  1    1   0.0  0.00 0.00   0.00  11.6   8.2 168.  4.3  269.   6.8
>   6  1    1   0.0  0.00 0.00   0.00  18.7  16.9 155.  5.6  287.   8.2
>   7  1    1   0.0  0.00 0.00   0.00   7.0   2.1 195.  2.7   22.   0.1
>   8  1    1   0.0  0.00 0.00   0.00  17.6   6.5 281.  2.0  146.   1.5
>   9  1    1  41.2  1.54 0.82   6.96  12.2   7.8 268.  5.5  356.   4.5
>  10  1    1   0.0  0.00 0.00   0.00  14.6  -1.4 250.  3.6  344.   6.4
>  11  1    1   0.0  0.00 0.00   0.00  14.5  -3.7 300.  0.0    0. -16.9
>  12  1    1   0.0  0.00 0.00   0.00   8.8  -2.6 308.  0.0    0.   2.9
>  13  1    1   0.0  0.00 0.00   0.00   6.4   1.6 226.  3.3  335.   3.8
> 
> --
> 
> Dr Duncan Golicher
> Ecologia y Sistematica Terrestre
> Conservaci??n de la Biodiversidad
> El Colegio de la Frontera Sur
> San Cristobal de Las Casas,
> Chiapas, Mexico
> 
> Email: dgoliche at sclc.ecosur.mx
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From kerryrekky at yahoo.com  Sat Aug 27 19:31:22 2005
From: kerryrekky at yahoo.com (Cunningham Kerry)
Date: Sat, 27 Aug 2005 10:31:22 -0700 (PDT)
Subject: [R] how to merge several data sets?
Message-ID: <20050827173123.91600.qmail@web51809.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050827/94195606/attachment.pl

From Matthias.Kohl at uni-bayreuth.de  Sat Aug 27 19:39:42 2005
From: Matthias.Kohl at uni-bayreuth.de (Matthias Kohl)
Date: Sat, 27 Aug 2005 19:39:42 +0200
Subject: [R] two-tailed exact binomail test
In-Reply-To: <x2br3jv80q.fsf@turmalin.kubism.ku.dk>
References: <20050827121339.35330.qmail@web25403.mail.ukl.yahoo.com>
	<x2br3jv80q.fsf@turmalin.kubism.ku.dk>
Message-ID: <4310A55E.4050503@uni-bayreuth.de>

Peter Dalgaard wrote:

>katrina smith <chezsmithy at yahoo.co.uk> writes:
>
>  
>
>>I am trying to find a definition for the two-tailed exact binomial
>>test but have been unsuccessful. Can you help?
>>    
>>
>
>Just read binom.test. The relevant bit is this:
>(m is the mean == n*p)
>
>            else if (x < m) {
>                i <- seq(from = ceiling(m), to = n)
>                y <- sum(dbinom(i, n, p) <= d * relErr)
>                pbinom(x, n, p) + pbinom(n - y, n, p, lower = FALSE)
>            }
>
>i.e. we take the lower tail, including the value observed + the part
>of the upper tail where the binomial density is less than or equal to
>that of x (with a little fuzz added in). Symmetrically for observations
>in the upper tail of course.
>
>If you were looking for an "official" definition of the two sided
>exact test, I don't think one exists. R's version is equivalent to the
>likelihood ratio test, but there are alternatives (tail-balancing,
>doubling the one-sided p, and maybe more).
>
>  
>
there is a reference:
Section 2.4.2 ("Zweiseitige Tests in einparametrigen 
Exponentialfamilien" - two sided tests in one-parameter exponential 
families) in

H. Witting (1985): Mathematische Statistik I. Teubner. Stuttgart

confer Satz 2.70, Korollar 2.73 (in case of symmetry)
and Beispiel 2.74 (application of Korollar 2.73 to binomial model for p= 
0.5).

Matthias



From kubovy at virginia.edu  Sat Aug 27 19:50:49 2005
From: kubovy at virginia.edu (Michael Kubovy)
Date: Sat, 27 Aug 2005 13:50:49 -0400
Subject: [R] Defining an ex-gaussian PDF
In-Reply-To: <mailman.10.1125136801.20354.r-help@stat.math.ethz.ch>
References: <mailman.10.1125136801.20354.r-help@stat.math.ethz.ch>
Message-ID: <C04F70B0-91E8-464B-82BA-1C18A3690D6B@virginia.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050827/00750a77/attachment.pl

From luke at novum.am.lublin.pl  Sat Aug 27 19:53:29 2005
From: luke at novum.am.lublin.pl (Lukasz Komsta)
Date: Sat, 27 Aug 2005 19:53:29 +0200
Subject: [R] printCoefmat with more p-values?
Message-ID: <4310A899.7050405@novum.am.lublin.pl>

Dear useRs,

I would like to summarize results of several tests in groups of two 
columns - statistic, p-value, statistic, p-value etc. There would be 
nice to add significance stars, but printCoefmat allows to do it only to 
last column. Is there any way to do format such table without writing my 
own complicated function?

Thank you in advance,

-- 
Lukasz Komsta
Department of Medicinal Chemistry
Medical University of Lublin
Jaczewskiego 4, 20-090 Lublin, Poland
Fax +48 81 7425165



From p.dalgaard at biostat.ku.dk  Sat Aug 27 21:17:12 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 27 Aug 2005 21:17:12 +0200
Subject: [R] how to merge several data sets?
In-Reply-To: <20050827173123.91600.qmail@web51809.mail.yahoo.com>
References: <20050827173123.91600.qmail@web51809.mail.yahoo.com>
Message-ID: <x23bovur47.fsf@turmalin.kubism.ku.dk>

Cunningham Kerry <kerryrekky at yahoo.com> writes:

> Dear R-helpers,
>   I want to merge several data sets into one single data set. For example, there are three separate data sets like:
....
> There is also one difficulty that the order of id may be different for the three sets and the order ot time may be different for Set 2 and Set 3.
>  
> Is there a convenient function in R to perform this operation? Thank you for your attention.

How about this?

> merge(merge(d1,d2),d3)
  id time age gender   x1   x2
1  1    1  12      M 0.25 0.34
2  1    2  12      M 0.27 0.55
3  1    3  12      M 0.29 0.79
4  3    1  15      F 0.15 0.12
5  3    2  15      F 0.18 0.23
6  4    2  19      M 0.22 0.45
7  4    3  19      M 0.54 0.56


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From jholtman at gmail.com  Sat Aug 27 22:10:10 2005
From: jholtman at gmail.com (jim holtman)
Date: Sat, 27 Aug 2005 16:10:10 -0400
Subject: [R] writing to a fixed format (fortran) file
In-Reply-To: <Pine.SGI.4.40.0508271251480.923463-100000@origin.chass.utoronto.ca>
References: <43109558.8070803@sclc.ecosur.mx>
	<Pine.SGI.4.40.0508271251480.923463-100000@origin.chass.utoronto.ca>
Message-ID: <644e1f3205082713103821b0e5@mail.gmail.com>

One way of creating fixed width output is to use 'sprintf' to create
the string and write the resulting data out.  I used your input and
just selected columns 7-11 as an example.  You will have to supply
whatever field width you want.  I create a matrix and null out the row
and column names and then write the matrix out without quotes.

HTH

> x.1
   V1 V2 V3   V4   V5   V6   V7   V8   V9 V10 V11 V12   V13
1   1  1  1 19.5 2.42 0.02 5.81  9.7  0.4 102 4.8 320   4.8
2   2  1  1  0.0 0.00 0.00 0.00  4.7 -4.0 178 5.4 301   0.2
3   3  1  1  8.2 1.64 0.08 6.93  6.9 -3.6 275 2.7  84 -11.1
4   4  1  1  0.0 0.00 0.00 0.00 20.6 -4.8 221 5.6 327 -10.4
5   5  1  1  0.0 0.00 0.00 0.00 11.6  8.2 168 4.3 269   6.8
6   6  1  1  0.0 0.00 0.00 0.00 18.7 16.9 155 5.6 287   8.2
7   7  1  1  0.0 0.00 0.00 0.00  7.0  2.1 195 2.7  22   0.1
8   8  1  1  0.0 0.00 0.00 0.00 17.6  6.5 281 2.0 146   1.5
9   9  1  1 41.2 1.54 0.82 6.96 12.2  7.8 268 5.5 356   4.5
10 10  1  1  0.0 0.00 0.00 0.00 14.6 -1.4 250 3.6 344   6.4
11 11  1  1  0.0 0.00 0.00 0.00 14.5 -3.7 300 0.0   0 -16.9
12 12  1  1  0.0 0.00 0.00 0.00  8.8 -2.6 308 0.0   0   2.9
13 13  1  1  0.0 0.00 0.00 0.00  6.4  1.6 226 3.3 335   3.8
# field widths are 6,6,8,5,7.  You also control the number of decimals
that appear
> x.2 <- sprintf("%6.2f%6.1f%8.1f%5.0f%7.1f",x.1[,7], x.1[,8], x.1[,9],
+     x.1[,10], x.1[,11])
> x.2 <- as.matrix(x.2)  # convert to a character matrix
> dimnames(x.2) <- list(rep('', nrow(x.2)), '')  # blank row and column names
> noquote(x.2)
                                 
   5.81   9.7     0.4  102    4.8
   0.00   4.7    -4.0  178    5.4
   6.93   6.9    -3.6  275    2.7
   0.00  20.6    -4.8  221    5.6
   0.00  11.6     8.2  168    4.3
   0.00  18.7    16.9  155    5.6
   0.00   7.0     2.1  195    2.7
   0.00  17.6     6.5  281    2.0
   6.96  12.2     7.8  268    5.5
   0.00  14.6    -1.4  250    3.6
   0.00  14.5    -3.7  300    0.0
   0.00   8.8    -2.6  308    0.0
   0.00   6.4     1.6  226    3.3
> 


On 8/27/05, Jean Eid <jeaneid at chass.utoronto.ca> wrote:
> why not write.table with sep="\t"
> 
> On Sat, 27 Aug 2005, Duncan Golicher wrote:
> 
> > Could anyone help with what should be a simple task? I have data as a
> > fixed format (fortran) table. I  have no trouble getting it into R using
> > read.table. Each column is separated by a space, including the first
> > column that begins with a space, and aligned. It reads into R as if
> > separated by tabs. However I want to manipulate two columns of data then
> > write the results out into exactly the same fortran format for use in
> > another program.  It should be simple, but I've tried a variety of
> > experiments with print, cat and format, none of which have come close.
> >
> > Here is a sample of the data.
> >
> >   1  1    1  19.5  2.42 0.02   5.81   9.7   0.4 102.  4.8  320.   4.8
> >   2  1    1   0.0  0.00 0.00   0.00   4.7  -4.0 178.  5.4  301.   0.2
> >   3  1    1   8.2  1.64 0.08   6.93   6.9  -3.6 275.  2.7   84. -11.1
> >   4  1    1   0.0  0.00 0.00   0.00  20.6  -4.8 221.  5.6  327. -10.4
> >   5  1    1   0.0  0.00 0.00   0.00  11.6   8.2 168.  4.3  269.   6.8
> >   6  1    1   0.0  0.00 0.00   0.00  18.7  16.9 155.  5.6  287.   8.2
> >   7  1    1   0.0  0.00 0.00   0.00   7.0   2.1 195.  2.7   22.   0.1
> >   8  1    1   0.0  0.00 0.00   0.00  17.6   6.5 281.  2.0  146.   1.5
> >   9  1    1  41.2  1.54 0.82   6.96  12.2   7.8 268.  5.5  356.   4.5
> >  10  1    1   0.0  0.00 0.00   0.00  14.6  -1.4 250.  3.6  344.   6.4
> >  11  1    1   0.0  0.00 0.00   0.00  14.5  -3.7 300.  0.0    0. -16.9
> >  12  1    1   0.0  0.00 0.00   0.00   8.8  -2.6 308.  0.0    0.   2.9
> >  13  1    1   0.0  0.00 0.00   0.00   6.4   1.6 226.  3.3  335.   3.8
> >
> > --
> >
> > Dr Duncan Golicher
> > Ecologia y Sistematica Terrestre
> > Conservaci??n de la Biodiversidad
> > El Colegio de la Frontera Sur
> > San Cristobal de Las Casas,
> > Chiapas, Mexico
> >
> > Email: dgoliche at sclc.ecosur.mx
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
> 


-- 
Jim Holtman
Convergys
+1 513 723 2929

What the problem you are trying to solve?



From ohn_thalani at mmail.com  Sun Aug 28 11:09:25 2005
From: ohn_thalani at mmail.com (John Thalani)
Date: Sun, 28 Aug 2005 05:09:25 -0400
Subject: [R] DRINGEND
Message-ID: <FF2BAB5D.52AE4BE@mmail.com>

Sehr geehter 

 

Mein Name ist John Thalani und ich bin der Leiter des Research Department
Committee in der Standard Bank in Südafrika. Zur Zeit halte ich mich in den
Niederlanden zu einer Fortbildung auf.

 

Ich kontaktiere Sie bezüglich des Transfers einer sehr großen Summe Geldes
vom Konto eines Verstorbenen. Ich weiß, daß eine Transaktion dieser
Größenordnung zunächst bei jedem Besorgnis erregen wird und versichere ich
Ihnen, daß sich um alles gekümmert wird.Aufgrund der Dringlichkeit der
Angelegenheit habe ich mich entschlossen, Sie zu kontaktieren.

 

Es geht um folgendes:

Einer meiner Kollegen ist für das Konto von Gerald Welsh zuständig, der
gemeinsam mit seiner Frau im January bei einem Flugzeugabsturz ums Leben
kam. Er befand sich gemeinsam mit anderen Passagieren an Bord einer Egyptian
Airline 990.( http://news.bbc.co.uk/1/world/americas/502503.stm ) Seit
diesem Vorfall ist niemand seiner nächsten Verwandten mehr am Leben, der als
sein Erbe Ansprüche auf das Guthaben auf seinem Konto erheben könnte. Wir
können jedoch gemäß unserer Richtlinien das Geld nicht auszahlen, bevor
jemand als Angehöriger und Erbe auftritt und seinen Anspruch geltend macht.
Aufgrund dieser Entdeckung und der Übereinstimmung Ihres Namens mit dem des
Verstorbenen bitten meine Kollegen und ich Sie nun um Ihre Erlaubnis, Sie
als nächsten Angehörigen des Verstorbenen anzugeben. Die gesamte Abwicklung
und Dokumentation wird sorgfältig von mir durchgeführt, damit das Guthaben
von 20.5 Millionen US$ an Sie als nächsten Angehörigen ausgezahlt werden
kann.

 

Andernfalls wird die gesamte Summe nach fünf Jahren in das Eigentum der
Bank übergehen und die Direktoren der Bank werden sie untereinander
aufteilen. Aufgrund dieser Tatsache habe ich mich entschlossen, mich an Sie
zu wenden, damit Sie als Erbe auftreten können und nicht alles den
Direktoren zugute kommt. Da aber die Person, die im Testament als Erbin
genannt wird, mit ihm gemeinsam verstorben ist, haben wir vom
Nachlaßverwalter den Auftrag bekommen, ein Familienmitglied des Verstorbenen
ausfindig zu machen, daß das Erbe antreten kann. 

 

Wir bitten Sie, unseren Vorschlag anzunehmen und versichern Ihnen, daß
alles absolut risikofrei für Sie ablaufen wird.

Wir werden Sie mit 5 Millionen US$ an der Transaktion beteiligen, den
restlichen Betrag werden meine Kollegen und ich für.

Falls Sie interessiert sind, schicken Sie mir bitte folgende Angaben:

 

1.                 Name/Firmen name um die erforderlichen Dokumente
vorzubereitenp    

2.                 Bankdaten: Konto-Nummer, Swift Code, Kontoinhaber

3.                 Persönliche Telefon- und Fax-Nummern   

An meine privat   E-mail john_thalani at mmail.com   mit Ihrer vertraulichen
Telefon-Nr., Fax-Nr.,  E-mail Anschrift, damit ich Ihnen die weiteren
relevanten Details in dieser Sache mitteilen kann. Vielen Dank im voraus.

Wir bitten sie eindringlich, die Angelegenheit vertraulich zu behandeln.

Bitte antworten Sie mir schnellstmöglich und Gott segne sie.

 

 

 Mit freundlichen grussen.

 

John Thalani. .



From bennfine at yahoo.com  Sun Aug 28 04:43:12 2005
From: bennfine at yahoo.com (Benn Fine)
Date: Sat, 27 Aug 2005 19:43:12 -0700 (PDT)
Subject: [R] Logistic regression with constrained parameter ??
Message-ID: <20050828024312.36299.qmail@web61323.mail.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050827/ae039982/attachment.pl

From spencer.graves at pdf.com  Sun Aug 28 06:03:59 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Sat, 27 Aug 2005 21:03:59 -0700
Subject: [R] code a family of garch
In-Reply-To: <s3048c0c.055@MC-GWDOM2.newcastle.edu.au>
References: <s3048c0c.055@MC-GWDOM2.newcastle.edu.au>
Message-ID: <431137AF.50901@pdf.com>

	  Since I have not seen a reply to this post, I will attempt a brief 
comment:

	  1.  I got nothing from 'RSiteSearch("garcht-t")'.

	  2.  I got 33 hits from 'RSiteSearch("egarch")'.  Have you looked at 
these?  If not, you might find something useful there.

	  3.  'RSiteSearch("gjr")' produced 13 hits, many to earlier posts from 
you.  Have you seen the following two:
http://finzi.psych.upenn.edu/R/library/fSeries/html/A2-GarchModelling.html
http://finzi.psych.upenn.edu/R/library/fSeries/html/A3-GarchOxModelling.html

	  4.  Have you looked at the posting guide! 
"http://www.R-project.org/posting-guide.html"?  It is my impression that 
questions following the posting guide process generally get quicker and 
more useful answers than other questions.  The reason is simple:  It is 
generally easier for people to understand the question, test ideas, as 
reply usefully and succinctly in a few brief minutes.

	  spencer graves

Nongluck Klibbua wrote:

> Dear R-helpers,
> 
> I was wondering if anyone has or knows someone who might have an
> implementation
> of algorithm for estimating garcht-t, egarch and gjr models. I try to
> use Fseries but I don't know how to code these models.  
> Thanks a million in advance,
> Sincerely,
> Nongluck
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From ripley at stats.ox.ac.uk  Sun Aug 28 08:23:45 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 28 Aug 2005 07:23:45 +0100 (BST)
Subject: [R] Logistic regression with constrained parameter ??
In-Reply-To: <20050828024312.36299.qmail@web61323.mail.yahoo.com>
References: <20050828024312.36299.qmail@web61323.mail.yahoo.com>
Message-ID: <Pine.LNX.4.61.0508280721350.3599@gannet.stats>

On Sat, 27 Aug 2005, Benn Fine wrote:

> I want to fit a logistic regression model under a specified
> null hypothesis, say Ho:Beta_k=1
>
> Is there a way to constrain a parameter in glm.fit ??

You should be calling glm().  Then you can use offset() in your formula.
(You can also use it as an argument, but please don't as it is only 
partially supported.)


> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

PLEASE do (and notice what is says about HTML mail).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From archaiesteron at laposte.net  Sun Aug 28 09:48:15 2005
From: archaiesteron at laposte.net (Thomas Baruchel)
Date: Sun, 28 Aug 2005 09:48:15 +0200
Subject: [R] [newbie] Want to perform some simple regressions.
Message-ID: <20050828074815.GA882@>

Hi,

I am a very newbie to R, and also have no knowledge concerning
statistics. Nevertheless I think R might be the right software
for a very specific number theory problem I sometime have.
Studying some properties, I often get sequences of real numbers
(let's call them y, the index x being 0, 1, 2, 3, 4, ...).

For instance the list below. After a quick look, it seems that
the sequence below is very close to something like
  (a.x + b) ln (c.x + d)
but I didn't manage to find something very good for (a,b,c,d).
My number theory software (maxima and pari/gp) don't seem to
be much helpful for this.

Is R the right choice ? Please, could you step by step show me
how you would do on this example (data below) in order to let me
do it on other examples. It would be very nice to join a script
of the session since I don't know yet the syntax of R commands.

Regards,

-- 
Thomas Baruchel



From archaiesteron at laposte.net  Sun Aug 28 09:51:48 2005
From: archaiesteron at laposte.net (Thomas Baruchel)
Date: Sun, 28 Aug 2005 09:51:48 +0200
Subject: [R] [newbie] Want to perform some simple regressions.
In-Reply-To: <20050828074815.GA882@>
References: <20050828074815.GA882@>
Message-ID: <20050828075148.GA1404@>

On Sun, Aug 28, 2005 at 09:48:15AM +0200, Thomas Baruchel wrote:
> Is R the right choice ? Please, could you step by step show me
> how you would do on this example (data below) in order to let me

I forgot my data :-(

0 2.205954909440447 
1 8.150580118785099 
2 15.851323727378597 
3 22.442795956953574 
4 29.358579800271354 
5 36.46060528847214 
6 43.7516923268591 
7 51.223688311610026 
8 58.86610205087116 
9 66.66821956399055 
10 74.61990268453171 
11 82.71184423952718 
12 90.93560520053082 
13 99.28356700194489 
14 107.74885489906521 
15 116.3252559311549 
16 125.00714110112291 
17 133.78939523822717 
18 142.6673553086964 
19 151.63675679510055 
20 160.69368733376777 
21 169.834546691509 
22 179.05601219606618 
23 188.35500882314003 
24 197.72868324657364 
25 207.17438125936408 
26 216.68962806440814 
27 226.2721110130965 
28 235.9196644372003 
29 245.63025627606442 
30 255.40197624835042 
31 265.23302535689197 
32 275.12170654792556 
33 285.06641637317705 
34 295.0656375259694 
35 305.1179321414606 
36 315.2219357669857 
37 325.3763519217964 
38 335.5799471767038 
39 345.8315466936063 
40 356.13003017290697 
41 366.4743281636434 
42 376.8634186969678 
43 387.2963242085816 
44 397.77210871999046 
45 408.2898752521091 
46 418.8487634479048 
47 429.44794738349896 
48 440.08663354951693 
49 450.76405898653184 
50 461.479489560246 
51 472.2322183636179 
52 483.02156423451737 
53 493.84687037869463 
54 504.707503088911 
55 515.6028505520102 
56 526.5323217365377 
57 537.4953453542455 
58 548.4913688894654 
59 559.5198576909147 
60 570.5802941210067 
61 581.6721767581994 
62 592.7950196483222 
63 603.9483516011882 
64 615.1317155291274 
65 626.3446678243708 
66 637.5867777724806 
67 648.8576269992603 
68 660.1568089487967 
69 671.4839283904737 
70 682.838600952985 
71 694.2204526835204 
72 705.6291196304554 
73 717.0642474479981 
74 728.5254910213728 
75 740.0125141112243 
76 751.5249890160294 
77 763.062596251391 
78 774.6250242451752 
79 786.2119690475241 
80 797.8231340548524 
81 809.4582297469931 
82 821.1169734367211 
83 832.7990890309349 
84 844.5043068028273 
85 856.2323631744205 

Regards,

-- 
Thomas Baruchel



From sean.oriordain at gmail.com  Sun Aug 28 10:16:42 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Sun, 28 Aug 2005 09:16:42 +0100
Subject: [R] [newbie] Want to perform some simple regressions.
In-Reply-To: <6831360194827206944@unknownmsgid>
References: <6831360194827206944@unknownmsgid>
Message-ID: <8ed68eed050828011621cc1f4c@mail.gmail.com>

Hi Thomas,
I'm not an expert - so I might use incorrect terminology, but
hopefully you'll get the picture!

Assuming that you've got your data in a .CSV file, you'd first read in
your data, where the first three lines might look like...

x,y
0,2.205954909440447
1,8.150580118785099

# load the info into a data.frame called mydata
mydata <- read.csv("mycsvfile.csv",header=TRUE)
# now "attach" to this data.frame, so that the internal
attach(mydata)
# now do the regression and store it in the object "myregr"
myregr <- lm(y~x)
# print out the info from myregr
myregr
# to get more info from myregr use the summary() method...
summary(myregr)

There is an enormous quantity of documentation available, though it
takes a little while to learn to use it properly and get the full
effectiveness from it...

I strongly recommend that you read the "Posting Guide"
http://www.R-project.org/posting-guide.html
which will help you.

For more information, have a look at the introduction to R; which is a
tad terse in places - so read it slowly :-)

Have a look also at the other documentation 
http://www.r-project.org/other-docs.html

In particular I'd recommend John Maindonalds online book at
http://cran.r-project.org/other-docs.html

cheers!
Sean

On 28/08/05, Thomas Baruchel <archaiesteron at laposte.net> wrote:
> On Sun, Aug 28, 2005 at 09:48:15AM +0200, Thomas Baruchel wrote:
> > Is R the right choice ? Please, could you step by step show me
> > how you would do on this example (data below) in order to let me
> 
> I forgot my data :-(
> 
> 0 2.205954909440447
> 1 8.150580118785099
> 2 15.851323727378597
> 3 22.442795956953574
> 4 29.358579800271354
> 5 36.46060528847214
> 6 43.7516923268591
> 7 51.223688311610026
> 8 58.86610205087116
> 9 66.66821956399055
> 10 74.61990268453171
> 11 82.71184423952718
> 12 90.93560520053082
> 13 99.28356700194489
> 14 107.74885489906521
> 15 116.3252559311549
> 16 125.00714110112291
> 17 133.78939523822717
> 18 142.6673553086964
> 19 151.63675679510055
> 20 160.69368733376777
> 21 169.834546691509
> 22 179.05601219606618
> 23 188.35500882314003
> 24 197.72868324657364
> 25 207.17438125936408
> 26 216.68962806440814
> 27 226.2721110130965
> 28 235.9196644372003
> 29 245.63025627606442
> 30 255.40197624835042
> 31 265.23302535689197
> 32 275.12170654792556
> 33 285.06641637317705
> 34 295.0656375259694
> 35 305.1179321414606
> 36 315.2219357669857
> 37 325.3763519217964
> 38 335.5799471767038
> 39 345.8315466936063
> 40 356.13003017290697
> 41 366.4743281636434
> 42 376.8634186969678
> 43 387.2963242085816
> 44 397.77210871999046
> 45 408.2898752521091
> 46 418.8487634479048
> 47 429.44794738349896
> 48 440.08663354951693
> 49 450.76405898653184
> 50 461.479489560246
> 51 472.2322183636179
> 52 483.02156423451737
> 53 493.84687037869463
> 54 504.707503088911
> 55 515.6028505520102
> 56 526.5323217365377
> 57 537.4953453542455
> 58 548.4913688894654
> 59 559.5198576909147
> 60 570.5802941210067
> 61 581.6721767581994
> 62 592.7950196483222
> 63 603.9483516011882
> 64 615.1317155291274
> 65 626.3446678243708
> 66 637.5867777724806
> 67 648.8576269992603
> 68 660.1568089487967
> 69 671.4839283904737
> 70 682.838600952985
> 71 694.2204526835204
> 72 705.6291196304554
> 73 717.0642474479981
> 74 728.5254910213728
> 75 740.0125141112243
> 76 751.5249890160294
> 77 763.062596251391
> 78 774.6250242451752
> 79 786.2119690475241
> 80 797.8231340548524
> 81 809.4582297469931
> 82 821.1169734367211
> 83 832.7990890309349
> 84 844.5043068028273
> 85 856.2323631744205
> 
> Regards,
> 
> --
> Thomas Baruchel
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From murdoch at stats.uwo.ca  Sun Aug 28 12:39:36 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Sun, 28 Aug 2005 06:39:36 -0400
Subject: [R] [newbie] Want to perform some simple regressions.
In-Reply-To: <8ed68eed050828011621cc1f4c@mail.gmail.com>
References: <6831360194827206944@unknownmsgid>
	<8ed68eed050828011621cc1f4c@mail.gmail.com>
Message-ID: <43119468.7030300@stats.uwo.ca>

Sean O'Riordain wrote:
> Hi Thomas,
> I'm not an expert - so I might use incorrect terminology, but
> hopefully you'll get the picture!
> 
> Assuming that you've got your data in a .CSV file, you'd first read in
> your data, where the first three lines might look like...
> 
> x,y
> 0,2.205954909440447
> 1,8.150580118785099
> 
> # load the info into a data.frame called mydata
> mydata <- read.csv("mycsvfile.csv",header=TRUE)
> # now "attach" to this data.frame, so that the internal
> attach(mydata)
> # now do the regression and store it in the object "myregr"
> myregr <- lm(y~x)

Thomas's model was

y = (a*x + b) * ln (c*x + d) + error

which is not a linear model.  He'll need to use nonlinear regression 
(the nls function), which is a little more complicated.  I'd recommend 
geting local help from a statistician to get it right.

Duncan Murdoch

> # print out the info from myregr
> myregr
> # to get more info from myregr use the summary() method...
> summary(myregr)
> 
> There is an enormous quantity of documentation available, though it
> takes a little while to learn to use it properly and get the full
> effectiveness from it...
> 
> I strongly recommend that you read the "Posting Guide"
> http://www.R-project.org/posting-guide.html
> which will help you.
> 
> For more information, have a look at the introduction to R; which is a
> tad terse in places - so read it slowly :-)
> 
> Have a look also at the other documentation 
> http://www.r-project.org/other-docs.html
> 
> In particular I'd recommend John Maindonalds online book at
> http://cran.r-project.org/other-docs.html
> 
> cheers!
> Sean
> 
> On 28/08/05, Thomas Baruchel <archaiesteron at laposte.net> wrote:
> 
>>On Sun, Aug 28, 2005 at 09:48:15AM +0200, Thomas Baruchel wrote:
>>
>>>Is R the right choice ? Please, could you step by step show me
>>>how you would do on this example (data below) in order to let me
>>
>>I forgot my data :-(
>>
>>0 2.205954909440447
>>1 8.150580118785099
>>2 15.851323727378597
>>3 22.442795956953574
>>4 29.358579800271354
>>5 36.46060528847214
>>6 43.7516923268591
>>7 51.223688311610026
>>8 58.86610205087116
>>9 66.66821956399055
>>10 74.61990268453171
>>11 82.71184423952718
>>12 90.93560520053082
>>13 99.28356700194489
>>14 107.74885489906521
>>15 116.3252559311549
>>16 125.00714110112291
>>17 133.78939523822717
>>18 142.6673553086964
>>19 151.63675679510055
>>20 160.69368733376777
>>21 169.834546691509
>>22 179.05601219606618
>>23 188.35500882314003
>>24 197.72868324657364
>>25 207.17438125936408
>>26 216.68962806440814
>>27 226.2721110130965
>>28 235.9196644372003
>>29 245.63025627606442
>>30 255.40197624835042
>>31 265.23302535689197
>>32 275.12170654792556
>>33 285.06641637317705
>>34 295.0656375259694
>>35 305.1179321414606
>>36 315.2219357669857
>>37 325.3763519217964
>>38 335.5799471767038
>>39 345.8315466936063
>>40 356.13003017290697
>>41 366.4743281636434
>>42 376.8634186969678
>>43 387.2963242085816
>>44 397.77210871999046
>>45 408.2898752521091
>>46 418.8487634479048
>>47 429.44794738349896
>>48 440.08663354951693
>>49 450.76405898653184
>>50 461.479489560246
>>51 472.2322183636179
>>52 483.02156423451737
>>53 493.84687037869463
>>54 504.707503088911
>>55 515.6028505520102
>>56 526.5323217365377
>>57 537.4953453542455
>>58 548.4913688894654
>>59 559.5198576909147
>>60 570.5802941210067
>>61 581.6721767581994
>>62 592.7950196483222
>>63 603.9483516011882
>>64 615.1317155291274
>>65 626.3446678243708
>>66 637.5867777724806
>>67 648.8576269992603
>>68 660.1568089487967
>>69 671.4839283904737
>>70 682.838600952985
>>71 694.2204526835204
>>72 705.6291196304554
>>73 717.0642474479981
>>74 728.5254910213728
>>75 740.0125141112243
>>76 751.5249890160294
>>77 763.062596251391
>>78 774.6250242451752
>>79 786.2119690475241
>>80 797.8231340548524
>>81 809.4582297469931
>>82 821.1169734367211
>>83 832.7990890309349
>>84 844.5043068028273
>>85 856.2323631744205
>>
>>Regards,
>>
>>--
>>Thomas Baruchel
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From jholtman at gmail.com  Sun Aug 28 13:26:00 2005
From: jholtman at gmail.com (jim holtman)
Date: Sun, 28 Aug 2005 07:26:00 -0400
Subject: [R] [newbie] Want to perform some simple regressions.
In-Reply-To: <-5000853026978569277@unknownmsgid>
References: <-5000853026978569277@unknownmsgid>
Message-ID: <644e1f3205082804263201c64d@mail.gmail.com>

try 'nls'

Here is your data applied to it.  It looks like you had an 'exact' fit:

> x.1[1:10,]
   V1        V2
1   0  2.205955
2   1  8.150580
3   2 15.851324
4   3 22.442796
5   4 29.358580
6   5 36.460605
7   6 43.751692
8   7 51.223688
9   8 58.866102
10  9 66.668220
> x.p <- nls(V2 ~ (a*V1+b)*log(c*V1+d),x.1,start=list(a=1,b=1,c=1,d=1))
> x.p
Nonlinear regression model
  model:  V2 ~ (a * V1 + b) * log(c * V1 + d) 
   data:  x.1 
       a        b        c        d 
1.994722 6.807986 1.495003 1.301922 
 residual sum-of-squares:  1.006867 


On 8/28/05, Thomas Baruchel <archaiesteron at laposte.net> wrote:
> On Sun, Aug 28, 2005 at 09:48:15AM +0200, Thomas Baruchel wrote:
> > Is R the right choice ? Please, could you step by step show me
> > how you would do on this example (data below) in order to let me
> 
> I forgot my data :-(
> 
> 0 2.205954909440447
> 1 8.150580118785099
> 2 15.851323727378597
> 3 22.442795956953574
> 4 29.358579800271354
> 5 36.46060528847214
> 6 43.7516923268591
> 7 51.223688311610026
> 8 58.86610205087116
> 9 66.66821956399055
> 10 74.61990268453171
> 11 82.71184423952718
> 12 90.93560520053082
> 13 99.28356700194489
> 14 107.74885489906521
> 15 116.3252559311549
> 16 125.00714110112291
> 17 133.78939523822717
> 18 142.6673553086964
> 19 151.63675679510055
> 20 160.69368733376777
> 21 169.834546691509
> 22 179.05601219606618
> 23 188.35500882314003
> 24 197.72868324657364
> 25 207.17438125936408
> 26 216.68962806440814
> 27 226.2721110130965
> 28 235.9196644372003
> 29 245.63025627606442
> 30 255.40197624835042
> 31 265.23302535689197
> 32 275.12170654792556
> 33 285.06641637317705
> 34 295.0656375259694
> 35 305.1179321414606
> 36 315.2219357669857
> 37 325.3763519217964
> 38 335.5799471767038
> 39 345.8315466936063
> 40 356.13003017290697
> 41 366.4743281636434
> 42 376.8634186969678
> 43 387.2963242085816
> 44 397.77210871999046
> 45 408.2898752521091
> 46 418.8487634479048
> 47 429.44794738349896
> 48 440.08663354951693
> 49 450.76405898653184
> 50 461.479489560246
> 51 472.2322183636179
> 52 483.02156423451737
> 53 493.84687037869463
> 54 504.707503088911
> 55 515.6028505520102
> 56 526.5323217365377
> 57 537.4953453542455
> 58 548.4913688894654
> 59 559.5198576909147
> 60 570.5802941210067
> 61 581.6721767581994
> 62 592.7950196483222
> 63 603.9483516011882
> 64 615.1317155291274
> 65 626.3446678243708
> 66 637.5867777724806
> 67 648.8576269992603
> 68 660.1568089487967
> 69 671.4839283904737
> 70 682.838600952985
> 71 694.2204526835204
> 72 705.6291196304554
> 73 717.0642474479981
> 74 728.5254910213728
> 75 740.0125141112243
> 76 751.5249890160294
> 77 763.062596251391
> 78 774.6250242451752
> 79 786.2119690475241
> 80 797.8231340548524
> 81 809.4582297469931
> 82 821.1169734367211
> 83 832.7990890309349
> 84 844.5043068028273
> 85 856.2323631744205
> 
> Regards,
> 
> --
> Thomas Baruchel
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Jim Holtman
Convergys
+1 513 723 2929

What the problem you are trying to solve?



From ligges at statistik.uni-dortmund.de  Sun Aug 28 16:15:41 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Sun, 28 Aug 2005 16:15:41 +0200
Subject: [R] printCoefmat with more p-values?
In-Reply-To: <4310A899.7050405@novum.am.lublin.pl>
References: <4310A899.7050405@novum.am.lublin.pl>
Message-ID: <4311C70D.8040005@statistik.uni-dortmund.de>

Lukasz Komsta wrote:

> Dear useRs,
> 
> I would like to summarize results of several tests in groups of two 
> columns - statistic, p-value, statistic, p-value etc. There would be 
> nice to add significance stars, but printCoefmat allows to do it only to 
> last column. Is there any way to do format such table without writing my 
> own complicated function?


Yes, I think you have to write your own function, but no need for a 
complicated one. ;-)

Uwe Ligges


> Thank you in advance,
>



From tuechler at gmx.at  Sun Aug 28 17:36:10 2005
From: tuechler at gmx.at (Heinz Tuechler)
Date: Sun, 28 Aug 2005 17:36:10 +0200
Subject: [R] stratified Wilcoxon available?
Message-ID: <3.0.6.32.20050828173610.007953a0@pop.gmx.net>

Dear All,

is there a stratified version of the Wilcoxon test (also known as van
Elteren test) available in R?
I could find it in the survdiff function of the survival package for
censored data. I think, it should be possible to use this function creating
a dummy censoring indicator and setting it to not censored, but may be
there is a better way to perform the test.

Thanks,

Heinz T??chler



From ccleland at optonline.net  Sun Aug 28 18:43:20 2005
From: ccleland at optonline.net (Chuck Cleland)
Date: Sun, 28 Aug 2005 12:43:20 -0400
Subject: [R] predict.coxph
Message-ID: <4311E9A8.8060307@optonline.net>

Is there anywhere to find more detail on the different types of 
predictions ("lp", "risk", "terms") in predict.coxph?  I would like to 
create a summary risk score after fitting a multivariable model with 
time-varying covariates.  If it makes a difference, 0 will be a 
substantively meaningful value for all of the covariates considered.

-- 
Chuck Cleland, Ph.D.
NDRI, Inc.
71 West 23rd Street, 8th floor
New York, NY 10010
tel: (212) 845-4495 (Tu, Th)
tel: (732) 452-1424 (M, W, F)
fax: (917) 438-0894



From p.dalgaard at biostat.ku.dk  Sun Aug 28 19:31:38 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 28 Aug 2005 19:31:38 +0200
Subject: [R] stratified Wilcoxon available?
In-Reply-To: <3.0.6.32.20050828173610.007953a0@pop.gmx.net>
References: <3.0.6.32.20050828173610.007953a0@pop.gmx.net>
Message-ID: <x2irxqt1c5.fsf@turmalin.kubism.ku.dk>

Heinz Tuechler <tuechler at gmx.at> writes:

> Dear All,
> 
> is there a stratified version of the Wilcoxon test (also known as van
> Elteren test) available in R?
> I could find it in the survdiff function of the survival package for
> censored data. I think, it should be possible to use this function creating
> a dummy censoring indicator and setting it to not censored, but may be
> there is a better way to perform the test.

Not easily, I think. I played with the stratified Kruskal Wallis test
(which is the same thing for larger values of 2...) with a grad
student some years ago, but we never got it integrated as an "official"
R function. 

It was not massively hard to code, as I recall it. Basically, you
convert observations to within-stratum ranks, scaled so that the
scores have similar variance (this is crucial: just adding the
per-stratum rank sums won't work). You can then get the relevant SSD
from lm(), by comparing the models "r ~ group + strata" and "r ~
strata". This SSD can be looked up as a chi-square statistic, possibly
after applying a scale factor which I have forgotten.... (I.e. do your
own math, don't trust me!)

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From zoonek at gmail.com  Sun Aug 28 20:04:29 2005
From: zoonek at gmail.com (Vincent ZOONEKYND)
Date: Sun, 28 Aug 2005 19:04:29 +0100
Subject: [R] Statistics with R
Message-ID: <df01a8eb050828110452381dd3@mail.gmail.com>

Dear list,

One year ago, some of you had wished for an English version
of my web page "Statistiques avec R". The translation is now
completed. As the French version, this document is still
unfinished, probably full of mistakes -- but amply
illustrated.

For those of you who had not browsed through the previous
version, these are merely the notes I took while discovering
statistics and using R, with as many pictures as possible
(over a thousand).

  http://zoonek2.free.fr/UNIX/48_R/all.html

Regards,

-- Vincent



From f.harrell at vanderbilt.edu  Sun Aug 28 22:18:40 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Sun, 28 Aug 2005 15:18:40 -0500
Subject: [R] stratified Wilcoxon available?
In-Reply-To: <x2irxqt1c5.fsf@turmalin.kubism.ku.dk>
References: <3.0.6.32.20050828173610.007953a0@pop.gmx.net>
	<x2irxqt1c5.fsf@turmalin.kubism.ku.dk>
Message-ID: <43121C20.3040400@vanderbilt.edu>

Peter Dalgaard wrote:
> Heinz Tuechler <tuechler at gmx.at> writes:
> 
> 
>>Dear All,
>>
>>is there a stratified version of the Wilcoxon test (also known as van
>>Elteren test) available in R?
>>I could find it in the survdiff function of the survival package for
>>censored data. I think, it should be possible to use this function creating
>>a dummy censoring indicator and setting it to not censored, but may be
>>there is a better way to perform the test.
> 
> 
> Not easily, I think. I played with the stratified Kruskal Wallis test
> (which is the same thing for larger values of 2...) with a grad
> student some years ago, but we never got it integrated as an "official"
> R function. 
> 
> It was not massively hard to code, as I recall it. Basically, you
> convert observations to within-stratum ranks, scaled so that the
> scores have similar variance (this is crucial: just adding the
> per-stratum rank sums won't work). You can then get the relevant SSD
> from lm(), by comparing the models "r ~ group + strata" and "r ~
> strata". This SSD can be looked up as a chi-square statistic, possibly
> after applying a scale factor which I have forgotten.... (I.e. do your
> own math, don't trust me!)
> 

You might think of such a stratified test as part of a proportional odds 
model with adjustment for strata as main effects.  The Wilcoxon tests is 
  a special case of the PO model.  You can fit it with polr or lrm.

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From tuechler at gmx.at  Sun Aug 28 23:52:43 2005
From: tuechler at gmx.at (Heinz Tuechler)
Date: Sun, 28 Aug 2005 23:52:43 +0200
Subject: [R] stratified Wilcoxon available?
In-Reply-To: <43121C20.3040400@vanderbilt.edu>
References: <x2irxqt1c5.fsf@turmalin.kubism.ku.dk>
	<3.0.6.32.20050828173610.007953a0@pop.gmx.net>
	<x2irxqt1c5.fsf@turmalin.kubism.ku.dk>
Message-ID: <3.0.6.32.20050828235243.007baae0@pop.gmx.net>

Thanks to Peter Dalgaard and Frank Harrell for your answers. Fortunately I
don't have an urgent need for this test, but it may be in the future.
Still I would be grateful if someone could comment on my opinion that using
survdiff and regarding all the measures as events would lead to an
equivalent test.

Thanks,

Heinz T??chler

At 15:18 28.08.2005 -0500, Frank E Harrell Jr wrote:
>Peter Dalgaard wrote:
>> Heinz Tuechler <tuechler at gmx.at> writes:
>> 
>> 
>>>Dear All,
>>>
>>>is there a stratified version of the Wilcoxon test (also known as van
>>>Elteren test) available in R?
>>>I could find it in the survdiff function of the survival package for
>>>censored data. I think, it should be possible to use this function creating
>>>a dummy censoring indicator and setting it to not censored, but may be
>>>there is a better way to perform the test.
>> 
>> 
>> Not easily, I think. I played with the stratified Kruskal Wallis test
>> (which is the same thing for larger values of 2...) with a grad
>> student some years ago, but we never got it integrated as an "official"
>> R function. 
>> 
>> It was not massively hard to code, as I recall it. Basically, you
>> convert observations to within-stratum ranks, scaled so that the
>> scores have similar variance (this is crucial: just adding the
>> per-stratum rank sums won't work). You can then get the relevant SSD
>> from lm(), by comparing the models "r ~ group + strata" and "r ~
>> strata". This SSD can be looked up as a chi-square statistic, possibly
>> after applying a scale factor which I have forgotten.... (I.e. do your
>> own math, don't trust me!)
>> 
>
>You might think of such a stratified test as part of a proportional odds 
>model with adjustment for strata as main effects.  The Wilcoxon tests is 
>  a special case of the PO model.  You can fit it with polr or lrm.
>
>-- 
>Frank E Harrell Jr   Professor and Chair           School of Medicine
>                      Department of Biostatistics   Vanderbilt University
>
>



From r at roryt.gr  Mon Aug 29 01:18:55 2005
From: r at roryt.gr (I.Ioannou)
Date: Mon, 29 Aug 2005 02:18:55 +0300
Subject: [R] PLSR: model notation and reliabilities
In-Reply-To: <20050827010413.GA27127@argeas.cs-net.gr>
References: <20050827010413.GA27127@argeas.cs-net.gr>
Message-ID: <20050828231855.GA3475@argeas.cs-net.gr>

On Sat, Aug 27, 2005 at 04:04:13AM +0300, I.Ioannou wrote:
> 
> I'm new in both R and statistics. I "did my homework", 

but apparently it was not enough :-( 

I took a look inside the code of the *pls.fit functions
and at least now I know where I got it wrong.

So, I'm rephrasing my question :

I have a model with 2 latent constructs (D1 and D2)
each one made by 3 indicators (D1a, D1b, D1c etc).
Also I have 2 moderating indicators (factors, m1, m2).
The response (Y) is also a latent construct, with 3 
indicators (Y1,Y2,Y3). Actually this is a simplified
description of my model which is far more complicated.

I want to express the regression using the constructs,
both for the response and the predictors, i.e. I need 
to have "inner" and "outer" models. The outer model can be 
expressed as :

Y ~ D1*m1 + D2*m2


How do I create the constructs from the indicators ?
I suspect I have to use somehow mvr or pca, but
I can not figure out how to use mvr for this since it
uses a formula and the response is required, while 
princomp and prcomp gives me either more constructs
than just 1, or ICRs ~ 0.6, while cronbach's alpha >= 0.9
- apparently I'm not using them correctly.

Any help will be much appreciated
 
TIA



From j.silver at ugrad.unimelb.edu.au  Mon Aug 29 01:29:03 2005
From: j.silver at ugrad.unimelb.edu.au (j.silver@ugrad.unimelb.edu.au)
Date: Mon, 29 Aug 2005 09:29:03 +1000
Subject: [R] Areas of Voronoi polygons in a given window
Message-ID: <200508282329.j7SNT4ZU019158@cassius.its.unimelb.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050829/ef87250f/attachment.pl

From tlumley at u.washington.edu  Mon Aug 29 04:02:59 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Sun, 28 Aug 2005 19:02:59 -0700 (PDT)
Subject: [R] stratified Wilcoxon available?
In-Reply-To: <3.0.6.32.20050828235243.007baae0@pop.gmx.net>
References: <x2irxqt1c5.fsf@turmalin.kubism.ku.dk>
	<3.0.6.32.20050828173610.007953a0@pop.gmx.net>
	<x2irxqt1c5.fsf@turmalin.kubism.ku.dk>
	<3.0.6.32.20050828235243.007baae0@pop.gmx.net>
Message-ID: <Pine.A41.4.61b.0508281901570.19194@homer12.u.washington.edu>

On Sun, 28 Aug 2005, Heinz Tuechler wrote:

> Thanks to Peter Dalgaard and Frank Harrell for your answers. Fortunately I
> don't have an urgent need for this test, but it may be in the future.
> Still I would be grateful if someone could comment on my opinion that using
> survdiff and regarding all the measures as events would lead to an
> equivalent test.

In the absence of ties, yes.   In the presence of ties I think survdiff() 
does something slightly different from what would be usual for the 
Wilcoxon test.  This would matter only with many tied observations.

 	-thomas



>
> Thanks,
>
> Heinz T?chler
>
> At 15:18 28.08.2005 -0500, Frank E Harrell Jr wrote:
>> Peter Dalgaard wrote:
>>> Heinz Tuechler <tuechler at gmx.at> writes:
>>>
>>>
>>>> Dear All,
>>>>
>>>> is there a stratified version of the Wilcoxon test (also known as van
>>>> Elteren test) available in R?
>>>> I could find it in the survdiff function of the survival package for
>>>> censored data. I think, it should be possible to use this function creating
>>>> a dummy censoring indicator and setting it to not censored, but may be
>>>> there is a better way to perform the test.
>>>
>>>
>>> Not easily, I think. I played with the stratified Kruskal Wallis test
>>> (which is the same thing for larger values of 2...) with a grad
>>> student some years ago, but we never got it integrated as an "official"
>>> R function.
>>>
>>> It was not massively hard to code, as I recall it. Basically, you
>>> convert observations to within-stratum ranks, scaled so that the
>>> scores have similar variance (this is crucial: just adding the
>>> per-stratum rank sums won't work). You can then get the relevant SSD
>>> from lm(), by comparing the models "r ~ group + strata" and "r ~
>>> strata". This SSD can be looked up as a chi-square statistic, possibly
>>> after applying a scale factor which I have forgotten.... (I.e. do your
>>> own math, don't trust me!)
>>>
>>
>> You might think of such a stratified test as part of a proportional odds
>> model with adjustment for strata as main effects.  The Wilcoxon tests is
>>  a special case of the PO model.  You can fit it with polr or lrm.
>>
>> --
>> Frank E Harrell Jr   Professor and Chair           School of Medicine
>>                      Department of Biostatistics   Vanderbilt University
>>
>>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

Thomas Lumley			Assoc. Professor, Biostatistics
tlumley at u.washington.edu	University of Washington, Seattle

From bhx2 at mevik.net  Mon Aug 29 08:08:53 2005
From: bhx2 at mevik.net (=?iso-8859-1?q?Bj=F8rn-Helge_Mevik?=)
Date: Mon, 29 Aug 2005 08:08:53 +0200
Subject: [R] PLSR: model notation and reliabilities
In-Reply-To: <20050828231855.GA3475@argeas.cs-net.gr> (I. Ioannou's message
	of "Mon, 29 Aug 2005 02:18:55 +0300")
References: <20050827010413.GA27127@argeas.cs-net.gr>
	<20050828231855.GA3475@argeas.cs-net.gr>
Message-ID: <m0wtm5xoju.fsf@bar.nemo-project.org>

I.Ioannou writes:

> I have a model with 2 latent constructs (D1 and D2)
> each one made by 3 indicators (D1a, D1b, D1c etc).
> Also I have 2 moderating indicators (factors, m1, m2).
> The response (Y) is also a latent construct, with 3 
> indicators (Y1,Y2,Y3).

[...]

It seems to me that what you are looking for, is some sort of
structured equation models (?? la Lisrel).  The pls package implements
partial least squares regression and principal component regression,
which is something different.  I quess you could still use plsr for the
"outer model" (path model), but you would have to build the "inner
model" (the constructs) with other tools, such as prcomp/princomp or
other factor analyses (see e.g. ?factanal and ?varimax).

Alternatively, there is an R package "sem" that implements structured
equation models.  You might want to take a look at that.

-- 
Bj??rn-Helge Mevik



From tuechler at gmx.at  Mon Aug 29 10:37:31 2005
From: tuechler at gmx.at (Heinz Tuechler)
Date: Mon, 29 Aug 2005 10:37:31 +0200
Subject: [R] stratified Wilcoxon available?
In-Reply-To: <Pine.A41.4.61b.0508281901570.19194@homer12.u.washington.ed
 u>
References: <3.0.6.32.20050828235243.007baae0@pop.gmx.net>
	<x2irxqt1c5.fsf@turmalin.kubism.ku.dk>
	<3.0.6.32.20050828173610.007953a0@pop.gmx.net>
	<x2irxqt1c5.fsf@turmalin.kubism.ku.dk>
	<3.0.6.32.20050828235243.007baae0@pop.gmx.net>
Message-ID: <3.0.6.32.20050829103731.007bab50@pop.gmx.net>

At 19:02 28.08.2005 -0700, Thomas Lumley wrote:
>On Sun, 28 Aug 2005, Heinz Tuechler wrote:
>
>> Thanks to Peter Dalgaard and Frank Harrell for your answers. Fortunately I
>> don't have an urgent need for this test, but it may be in the future.
>> Still I would be grateful if someone could comment on my opinion that using
>> survdiff and regarding all the measures as events would lead to an
>> equivalent test.
>
>In the absence of ties, yes.   In the presence of ties I think survdiff() 
>does something slightly different from what would be usual for the 
>Wilcoxon test.  This would matter only with many tied observations.
>
> 	-thomas
>

Thank you, Thomas, for this information.

Heinz

>
>
>>
>> Thanks,
>>
>> Heinz T??chler
>>
>> At 15:18 28.08.2005 -0500, Frank E Harrell Jr wrote:
>>> Peter Dalgaard wrote:
>>>> Heinz Tuechler <tuechler at gmx.at> writes:
>>>>
>>>>
>>>>> Dear All,
>>>>>
>>>>> is there a stratified version of the Wilcoxon test (also known as van
>>>>> Elteren test) available in R?
>>>>> I could find it in the survdiff function of the survival package for
>>>>> censored data. I think, it should be possible to use this function
creating
>>>>> a dummy censoring indicator and setting it to not censored, but may be
>>>>> there is a better way to perform the test.
>>>>
>>>>
>>>> Not easily, I think. I played with the stratified Kruskal Wallis test
>>>> (which is the same thing for larger values of 2...) with a grad
>>>> student some years ago, but we never got it integrated as an "official"
>>>> R function.
>>>>
>>>> It was not massively hard to code, as I recall it. Basically, you
>>>> convert observations to within-stratum ranks, scaled so that the
>>>> scores have similar variance (this is crucial: just adding the
>>>> per-stratum rank sums won't work). You can then get the relevant SSD
>>>> from lm(), by comparing the models "r ~ group + strata" and "r ~
>>>> strata". This SSD can be looked up as a chi-square statistic, possibly
>>>> after applying a scale factor which I have forgotten.... (I.e. do your
>>>> own math, don't trust me!)
>>>>
>>>
>>> You might think of such a stratified test as part of a proportional odds
>>> model with adjustment for strata as main effects.  The Wilcoxon tests is
>>>  a special case of the PO model.  You can fit it with polr or lrm.
>>>
>>> --
>>> Frank E Harrell Jr   Professor and Chair           School of Medicine
>>>                      Department of Biostatistics   Vanderbilt University
>>>
>>>
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html
>>
>
>Thomas Lumley			Assoc. Professor, Biostatistics
>tlumley at u.washington.edu	University of Washington, Seattle



From Jan.Verbesselt at biw.kuleuven.be  Mon Aug 29 11:09:00 2005
From: Jan.Verbesselt at biw.kuleuven.be (Jan Verbesselt)
Date: Mon, 29 Aug 2005 11:09:00 +0200
Subject: [R] How to add values on the axes of the 3D bi-variable lrm fit?
In-Reply-To: <430FD617.5020800@pdf.com>
Message-ID: <002901c5ac79$4b4f36b0$1145210a@agr.ad10.intern.kuleuven.ac.be>

Thanks a lot!

A great solution! The 3D-perspective plot can be fine-tuned by adding a list
to the argument 'perspArgs' of the function plot.Design.

Package: Design, Hmisc.

> fit <- lrm(y ~ rcs(x1,knots)+rcs(x2,knots), tol=1e-14,X=T,Y=T)
>
> dd <- datadist(x1,x2);options(datadist='dd');
>
> par(mfrow=c(1,1))
>

plot(fit,x1=NA, x2=NA, theta=50,phi=25, ,perspArgs=list(ticktype="detailed",
col="lightblue", expand=0.80)))

Best regards,
Jan

? The posting-guide is indeed important and useful. thx
*** http://www.R-project.org/posting-guide.html ***



From tiemannm at web.de  Mon Aug 29 11:14:44 2005
From: tiemannm at web.de (Michael Tiemann)
Date: Mon, 29 Aug 2005 11:14:44 +0200
Subject: [R] Different sings for correlations in OLS and TSA
Message-ID: <4312D204.9050000@web.de>

Dear list,

I am trying to re-analyse something. I do have two time series, one
of which (ts.mar) might help explaining the other (ts.anr). In the
original analysis, no-one seems to have cared about the data being 
time-series and they just did OLS. This yielded a strong positive
correlation.
I want to know if this correlation is still as strong when the 
autocorrelations are taken into account. There are autocorrelations, so
I model the data with arima() to get the parameters and fit it with
gls(). So far, the code seems to work fine, but what puzzles me is that 
I get different sings: the gls-fit yields a strong negative correlation.
This shouldn't be so, so I suspect I am doing something wrong.

Here is my code:

# this is my data
ts.mar<-ts(c(431.3,438,389.7,353.3,354.6,371.8,397.7,438.5,467.9,505.7,574.7,644.7,667.8,616.4,509.6,447,413.1,384.1),start=1980,freq=1)
ts.anr<-ts(c(104.1,102.4,97.9,96.2,95.1,95.1,97.9,101.6,105.9,111.1,117.9,121.3,121.8,114.2,107.6,105.1,101.9,98.6),start=1980,freq=1)
# to find autocorrelations via (p)acf's and mle I do:
fun.tsa.mle<-function(x){
par(mfrow=c(3,1))
acf(x)
pacf(x)
# AR model is estimated
m1<- ar.mle(x)
# An estimation of the unexplained portion of variance
m1.1<-m1$var.pred
# plot the function
plot(x)
# Give a printout
print(m1)
print("unexplained portion of variance:")
print(m1.1)
print("Mean:")
print(m1$x.mean)
par(mfrow=c(1,1))
}
#now, the autocorrelations should be consistent with following processes:
fun.tsa.mle(ts.mar)      #following DAAG a p=2 AR
fun.tsa.mle(ts.anr)      #following DAAG a p=2 AR
#I need to know, wether ts.anr can be explained with ts.mar, so
#according to ar.mle:
mod3<-arima(ts.anr,order=c(2,0,0),xreg=ts.mar,transform.pars=TRUE)
fit3 <- gls(ts.anr ~ ts.mar,correlation = 
corARMA(value=c(mod3$coef[1],mod3$coef[2]),p=2))
summary(fit3)
ts.plot(ts.anr,fit3$fitted,col=1:2)
#the puzzling bit is the negative correlation. It ought to be positive, 
I think.
#a simple OLS (this is what the people before me have done) yields
test3<-ols(ts.anr~ts.mar)
test3 #with a positive correlation. Why?


Where is the mistake? Up to now, I just thought time-series analyses 
would correct parameters and estimations, but simply changing signs?

Appreciating your help and suggestions,

Michael.

From thomas_chapuis at yahoo.fr  Mon Aug 29 11:28:48 2005
From: thomas_chapuis at yahoo.fr (thomas chapuis)
Date: Mon, 29 Aug 2005 11:28:48 +0200 (CEST)
Subject: [R] function ns()
Message-ID: <20050829092848.57838.qmail@web26807.mail.ukl.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050829/4fa1f7df/attachment.pl

From mailus at donleo.org  Mon Aug 29 11:43:27 2005
From: mailus at donleo.org (donleo)
Date: Mon, 29 Aug 2005 11:43:27 +0200
Subject: [R]  off-topic help request
Message-ID: <p06001201bf388909f7b1@[82.170.119.198]>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050829/93b1cf33/attachment.pl

From p.dalgaard at biostat.ku.dk  Mon Aug 29 12:20:34 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Aug 2005 12:20:34 +0200
Subject: [R] off-topic help request
In-Reply-To: <p06001201bf388909f7b1@[82.170.119.198]>
References: <p06001201bf388909f7b1@[82.170.119.198]>
Message-ID: <x2d5nxhwnh.fsf@turmalin.kubism.ku.dk>

donleo <mailus at donleo.org> writes:

> hello Ross
> found your request on the net.
> i'm a dutch artist and i'm too looking for the design specs for the 
> Ames room (that room with weird
> dimensions which you look into through a pinhole). 
> 
> 
> Can you help me?

R-help is not Ross but a few thousand other people.... 

Ross's note  was a long time ago, but have a look at

http://psylux.psych.tu-dresden.de/i1/kaw/diverses%20Material/www.illusionworks.com/html/ames_room.html



-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From pine at gramenet.lamalla.net  Mon Aug 29 13:49:01 2005
From: pine at gramenet.lamalla.net (Joan Carles Pineda Arredondo)
Date: Mon, 29 Aug 2005 13:49:01
Subject: [R]  capture stderr in Windows
Message-ID: <1125316141.3026@mail.infomail.es>


OK running in W2K.

Very thanks.

_____________________________________________________________________
Mensaje analizado y protegido, tecnologia antivirus www.trendmicro.es



From depire at inrets.fr  Mon Aug 29 13:59:46 2005
From: depire at inrets.fr (depire@inrets.fr)
Date: Mon, 29 Aug 2005 13:59:46 +0200
Subject: [R] Console not found
In-Reply-To: <42EA3381.4030200@stats.uwo.ca>
References: <42EA1AAB.5090802@eawag.ch> <42EA3381.4030200@stats.uwo.ca>
Message-ID: <1125316786.4312f8b2ad5d0@webmail.inrets.fr>

Hello,
I'm interested in LaTeX notations in R graphics.
For example, i would like to know how to obtain this picture
http://www.r-project.org/screenshots/power.png.

Thanks



From Manuel.Schneider at eawag.ch  Mon Aug 29 14:03:15 2005
From: Manuel.Schneider at eawag.ch (Schneider, Manuel)
Date: Mon, 29 Aug 2005 14:03:15 +0200
Subject: [R] Non-standard characters in Ascii-Files
Message-ID: <744893FCE2B96241BD15C17F2F8649E101DA33@EA-MAIL.eawag.wroot.emp-eaw.ch>

Dear R-list

In R 2.1.1 under Win XP on a P4 with 2GB Ram when typing
> temp<-matrix(c(1:16000000),4000,4000)
> write(file="temp.txt", temp)
> scan("temp.txt")

I receive:
Error in scan("temp.txt") : scan() expected 'a real', received '414851'

The motivation for evoquing this meassage is that I am getting the same
meassage with exported Ascii-Files from the GIS. The files contain very
few, randomly scattered non-standard Ascii-characters. This seems to be
a local problem on my machine but I do not have a clue on the reason
(OS, Memory, HD?) nor who to ask. 
So, my apologies for misusing this list and many thanks for any
suggestion.

Kind regards
Manuel



From ligges at statistik.uni-dortmund.de  Mon Aug 29 14:05:22 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Mon, 29 Aug 2005 14:05:22 +0200
Subject: [R] Console not found
In-Reply-To: <1125316786.4312f8b2ad5d0@webmail.inrets.fr>
References: <42EA1AAB.5090802@eawag.ch> <42EA3381.4030200@stats.uwo.ca>
	<1125316786.4312f8b2ad5d0@webmail.inrets.fr>
Message-ID: <4312FA02.6070902@statistik.uni-dortmund.de>

depire at inrets.fr wrote:

> Hello,
> I'm interested in LaTeX notations in R graphics.
> For example, i would like to know how to obtain this picture
> http://www.r-project.org/screenshots/power.png.

See ?plotmath

Uwe Ligges


> Thanks
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From francoisromain at free.fr  Mon Aug 29 14:16:19 2005
From: francoisromain at free.fr (Romain Francois)
Date: Mon, 29 Aug 2005 14:16:19 +0200
Subject: [R] Console not found
In-Reply-To: <1125316786.4312f8b2ad5d0@webmail.inrets.fr>
References: <42EA1AAB.5090802@eawag.ch> <42EA3381.4030200@stats.uwo.ca>
	<1125316786.4312f8b2ad5d0@webmail.inrets.fr>
Message-ID: <4312FC93.4050109@free.fr>

Le 29.08.2005 13:59, depire at inrets.fr a ??crit :

>Hello,
>I'm interested in LaTeX notations in R graphics.
>For example, i would like to know how to obtain this picture
>http://www.r-project.org/screenshots/power.png.
>
>Thanks
>  
>
Hi,

Have a look at
R> ?plotmath
R> demo(plotmath)

Romain

-- 
visit the R Graph Gallery : http://addictedtor.free.fr/graphiques
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~
~~~~~~      Romain FRANCOIS - http://addictedtor.free.fr         ~~~~~~
~~~~        Etudiant  ISUP - CS3 - Industrie et Services           ~~~~
~~                http://www.isup.cicrp.jussieu.fr/                  ~~
~~~~           Stagiaire INRIA Futurs - Equipe SELECT              ~~~~
~~~~~~   http://www.inria.fr/recherche/equipes/select.fr.html    ~~~~~~
~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~



From p.dalgaard at biostat.ku.dk  Mon Aug 29 14:39:14 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Aug 2005 14:39:14 +0200
Subject: [R] Non-standard characters in Ascii-Files
In-Reply-To: <744893FCE2B96241BD15C17F2F8649E101DA33@EA-MAIL.eawag.wroot.emp-eaw.ch>
References: <744893FCE2B96241BD15C17F2F8649E101DA33@EA-MAIL.eawag.wroot.emp-eaw.ch>
Message-ID: <x2zmr0hq8d.fsf@turmalin.kubism.ku.dk>

"Schneider, Manuel" <Manuel.Schneider at eawag.ch> writes:

> Dear R-list
> 
> In R 2.1.1 under Win XP on a P4 with 2GB Ram when typing
> > temp<-matrix(c(1:16000000),4000,4000)
> > write(file="temp.txt", temp)
> > scan("temp.txt")
> 
> I receive:
> Error in scan("temp.txt") : scan() expected 'a real', received '414851'
> 
> The motivation for evoquing this meassage is that I am getting the same
> meassage with exported Ascii-Files from the GIS. The files contain very
> few, randomly scattered non-standard Ascii-characters. This seems to be
> a local problem on my machine but I do not have a clue on the reason
> (OS, Memory, HD?) nor who to ask. 
> So, my apologies for misusing this list and many thanks for any
> suggestion.

I tried this on a Linux box (with a somewhat outdated R version though),
and apart from eating up memory and disk space, nothing untoward seems
to happen:

> temp<-matrix(c(1:16000000),4000,4000)
> write(file="/tmp/temp.txt", temp)
> dummy <- scan("/tmp/temp.txt")
Read 16000000 items

I'd suspect your harddisk or the disk controller...

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From Torsten.Hothorn at rzmail.uni-erlangen.de  Mon Aug 29 14:41:12 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Mon, 29 Aug 2005 14:41:12 +0200 (CEST)
Subject: [R] stratified Wilcoxon available?
In-Reply-To: <3.0.6.32.20050828173610.007953a0@pop.gmx.net>
References: <3.0.6.32.20050828173610.007953a0@pop.gmx.net>
Message-ID: <Pine.LNX.4.51.0508291440140.15465@artemis.imbe.med.uni-erlangen.de>


> Dear All,
>
> is there a stratified version of the Wilcoxon test (also known as van
> Elteren test) available in R?

you can plug it together using the `coin' infrastructure (see the
examples in the manual and vignette).

Torsten

> Thanks,
>
> Heinz T??chler
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>



From valderama at gmail.com  Mon Aug 29 14:54:22 2005
From: valderama at gmail.com (Laurent Valdes)
Date: Mon, 29 Aug 2005 14:54:22 +0200
Subject: [R] ttda on R 2.1.1: error
Message-ID: <3ef00e160508290554d65c504@mail.gmail.com>

Hello,

I'm trying to use the package ttda, wich is involved in text analysis,
for my own data about answers in a company survey.
I've installed it, as well as ispell, but when trying to use an example:

> zz <- file("stupid.txt", "w")  # build a data file
> cat("{comment - stupid data file} \n"              , file = zz)
> cat("<uci=1> Hush-a-bye, baby,     \n"             , file = zz)
> cat("     in the tree top.  \n"                    , file = zz)
> cat("<uci=2> When the wind blows, \n"              , file = zz)
> cat("     the cradle will rock. \n"                , file = zz)
> cat("<uci=3> When the bough breaks, \n"            , file = zz)
> cat("     the cradle will fall, \n"                , file = zz)
> cat("And down will come baby, \n"                  , file = zz)
> cat("     cradle and all.    \n"                   , file = zz)
> cat("{Nursery rime} \n"                            , file = zz)
> close(zz)
> dummy.example <- ttda.get.text(textfile = "stupid.txt")
> dummy.example <- ttda.uce(dummy.example)
error in identical(native.enc, MacRoman) : 
	native.enc not found

it lamentably fails.

how about this ?
-- 
--~~ Toulouse, Grenoble, Auch, Arcachon, B??ziers, Paris, 
Saragosse, L??vignac Sur Save, habitats naturel du Valdo. ~~--
<http://www.le-valdo.com>



From depire at inrets.fr  Mon Aug 29 15:21:21 2005
From: depire at inrets.fr (depire@inrets.fr)
Date: Mon, 29 Aug 2005 15:21:21 +0200
Subject: [R] LaTeX Notations in R output graphs
In-Reply-To: <3ef00e160508290554d65c504@mail.gmail.com>
References: <3ef00e160508290554d65c504@mail.gmail.com>
Message-ID: <1125321681.43130bd157e9b@webmail.inrets.fr>

Hello,
I'm interested in LaTeX notations in R graphs. For example, I would like to know
the R code to obtain the graph here,
http://www.r-project.org/screenshots/power.png

Thanks.


PS: it's possible that you have several copies of this mail, sorry for this.



From murdoch at stats.uwo.ca  Mon Aug 29 15:25:38 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 29 Aug 2005 09:25:38 -0400
Subject: [R] capture stderr in Windows
In-Reply-To: <1125316141.3026@mail.infomail.es>
References: <1125316141.3026@mail.infomail.es>
Message-ID: <43130CD2.7040608@stats.uwo.ca>

On 8/29/2005 1:49 PM, Joan Carles Pineda Arredondo wrote:
> OK running in W2K.

You need to give some detail to your question.  Do you want to capture 
stderr output from Rterm?  Do you want R to capture stderr output from 
some other program?

Duncan Murdoch



From Wittner.Ben at mgh.harvard.edu  Mon Aug 29 15:37:45 2005
From: Wittner.Ben at mgh.harvard.edu (Wittner, Ben)
Date: Mon, 29 Aug 2005 09:37:45 -0400
Subject: [R] problem building dendrograms to use with heatmap()
Message-ID: <B1D5C2D0D1D6AE4C9DF88E81330D71C60D9E51@PHSXMB23.partners.org>

Thanks Paul.

It seems there's an undocumented requirement that in order to use a dendrogram
as an argument to heatmap(),
(a) the leaf nodes must be integers indicating the leaf's position in the
left-to-right ordering of the leafs and/or
(b) only the root of the dendrogram can be of class dendrogram.

I discovered this by doing as you suggested below and with some help from Jeff
Gentry.

-Ben

> -----Original Message-----
> From: Paul Murrell [mailto:p.murrell at auckland.ac.nz]
> Sent: Thursday, August 25, 2005 7:37 PM
> To: Wittner, Ben
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] problem building dendrograms to use with heatmap()
> 
> Hi
> 
> 
> Wittner, Ben wrote:
> > Hi,
> >
> > I'm trying to build dendrograms to pass to heatmap().
> > The dendrograms I build plot properly, but when I pass them to heatmap()
> I get
> > the error message "row dendrogram ordering gave index of wrong length"
> (see
> > output log below).
> 
> 
> Looks like you're not building the dendrograms "properly".  Compare
> unclass(nr2) with unclass() of a dendrogram from
> as.dendrogram(hclust(<something>)).  You might need to look closely at
> stats:::as.dendrogram.hclust to get it right.
> 
> Paul
> 
> 
> > I looked in the code of heatmap() and saw that the error was due to a
> NULL
> > return value from order.dendrogram(), which in turn got a NULL return
> value from
> > unlist(). But I have no idea why unlist() is returning NULL.
> >
> > I've included code below which reproduces the problem and below that the
> output
> > from a run of that code on my computer.
> >
> > Any help would be greatly appreciated. Thanks in advance.
> >
> > -Ben
> >
> > ###########################  begin code
> ###################################
> >
> > version
> >
> > dendro.leaf <- function(label) {
> >   ans <- list()
> >   attr(ans, 'members') <- 1
> >   attr(ans, 'height') <- 0
> >   attr(ans, 'leaf') <- T
> >   attr(ans, 'midpoint') <- 0
> >   attr(ans, 'label') <- label
> >   attr(ans, 'class') <- 'dendrogram'
> >   ans
> > }
> >
> > dendro.merge <- function(d1, d2, height) {
> >   ans <- list(d1, d2)
> >   members <- attr(d1, 'members') + attr(d2, 'members')
> >   attr(ans, 'members') <- members
> >   attr(ans, 'height') <- height
> >   attr(ans, 'leaf') <- F
> >   attr(ans, 'midpoint') <- (members - 1)/2
> >   attr(ans, 'class') <- 'dendrogram'
> >   ans
> > }
> >
> > lc1 <- dendro.leaf('c1')
> > lc2 <- dendro.leaf('c2')
> > lc3 <- dendro.leaf('c3')
> > nc1 <- dendro.merge(lc1, lc2, 0.1)
> > nc2 <- dendro.merge(nc1, lc3, 0.2)
> > plot(nc2)
> >
> > lr1 <- dendro.leaf('r1')
> > lr2 <- dendro.leaf('r2')
> > lr3 <- dendro.leaf('r3')
> > nr1 <- dendro.merge(lr2, lr3, 0.1)
> > nr2 <- dendro.merge(lr1, nr1, 0.3)
> > plot(nr2)
> >
> > x <- matrix(seq(-1, 1, length.out=9), nrow=3)
> > rownames(x) <- paste('r', 1:3, sep='')
> > colnames(x) <- paste('c', 1:3, sep='')
> >
> > heatmap(x, Rowv=nr2, Colv=nc2, scale='none')
> >
> > order.dendrogram(nr2)
> >
> > unlist(nr2)
> >
> > ###############  begin output from run of code above  ##################
> >
> >
> >>version
> >
> >          _
> > platform i686-pc-linux-gnu
> > arch     i686
> > os       linux-gnu
> > system   i686, linux-gnu
> > status
> > major    2
> > minor    1.1
> > year     2005
> > month    06
> > day      20
> > language R
> >
> >>dendro.leaf <- function(label) {
> >
> > +   ans <- list()
> > +   attr(ans, 'members') <- 1
> > +   attr(ans, 'height') <- 0
> > +   attr(ans, 'leaf') <- T
> > +   attr(ans, 'midpoint') <- 0
> > +   attr(ans, 'label') <- label
> > +   attr(ans, 'class') <- 'dendrogram'
> > +   ans
> > + }
> >
> >>dendro.merge <- function(d1, d2, height) {
> >
> > +   ans <- list(d1, d2)
> > +   members <- attr(d1, 'members') + attr(d2, 'members')
> > +   attr(ans, 'members') <- members
> > +   attr(ans, 'height') <- height
> > +   attr(ans, 'leaf') <- F
> > +   attr(ans, 'midpoint') <- (members - 1)/2
> > +   attr(ans, 'class') <- 'dendrogram'
> > +   ans
> > + }
> >
> >>lc1 <- dendro.leaf('c1')
> >>lc2 <- dendro.leaf('c2')
> >>lc3 <- dendro.leaf('c3')
> >>nc1 <- dendro.merge(lc1, lc2, 0.1)
> >>nc2 <- dendro.merge(nc1, lc3, 0.2)
> >>plot(nc2)
> >>
> >>lr1 <- dendro.leaf('r1')
> >>lr2 <- dendro.leaf('r2')
> >>lr3 <- dendro.leaf('r3')
> >>nr1 <- dendro.merge(lr2, lr3, 0.1)
> >>nr2 <- dendro.merge(lr1, nr1, 0.3)
> >>plot(nr2)
> >>
> >>x <- matrix(seq(-1, 1, length.out=9), nrow=3)
> >>rownames(x) <- paste('r', 1:3, sep='')
> >>colnames(x) <- paste('c', 1:3, sep='')
> >>
> >>heatmap(x, Rowv=nr2, Colv=nc2, scale='none')
> >
> > Error in heatmap(x, Rowv = nr2, Colv = nc2, scale = "none") :
> >         row dendrogram ordering gave index of wrong length
> >
> >>order.dendrogram(nr2)
> >
> > NULL
> >
> >>unlist(nr2)
> >
> > NULL
> >
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-
> guide.html
> 
> 
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/



From hb at maths.lth.se  Mon Aug 29 15:43:23 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Mon, 29 Aug 2005 15:43:23 +0200
Subject: [R] Non-standard characters in Ascii-Files
In-Reply-To: <x2zmr0hq8d.fsf@turmalin.kubism.ku.dk>
References: <744893FCE2B96241BD15C17F2F8649E101DA33@EA-MAIL.eawag.wroot.emp-eaw.ch>
	<x2zmr0hq8d.fsf@turmalin.kubism.ku.dk>
Message-ID: <431310FB.7020306@maths.lth.se>

Peter Dalgaard wrote:
> "Schneider, Manuel" <Manuel.Schneider at eawag.ch> writes:
> 
> 
>>Dear R-list
>>
>>In R 2.1.1 under Win XP on a P4 with 2GB Ram when typing
>>
>>>temp<-matrix(c(1:16000000),4000,4000)
>>>write(file="temp.txt", temp)
>>>scan("temp.txt")
>>
>>I receive:
>>Error in scan("temp.txt") : scan() expected 'a real', received '414851'
>>
>>The motivation for evoquing this meassage is that I am getting the same
>>meassage with exported Ascii-Files from the GIS. The files contain very
>>few, randomly scattered non-standard Ascii-characters. This seems to be
>>a local problem on my machine but I do not have a clue on the reason
>>(OS, Memory, HD?) nor who to ask. 
>>So, my apologies for misusing this list and many thanks for any
>>suggestion.
> 
> 
> I tried this on a Linux box (with a somewhat outdated R version though),
> and apart from eating up memory and disk space, nothing untoward seems
> to happen:
> 
> 
>>temp<-matrix(c(1:16000000),4000,4000)
>>write(file="/tmp/temp.txt", temp)
>>dummy <- scan("/tmp/temp.txt")
> 
> Read 16000000 items

and on my R v2.1.1 patched (2005-08-25) on WinXP Pro SP2 (sic!), I get

 > temp<-matrix(c(1:16000000),4000,4000)
 > write(file="temp.txt", temp)
 > file.info("temp.txt")$size
[1] 136088897
 > rm(temp)
 > dummy <- scan("temp.txt")
Read 16000000 items

> I'd suspect your harddisk or the disk controller...

I second this, check the file with an external application or try the 
following ad-hoc code:

zcan <- function(filename) {
   fh <- file(filename, open="r");
   on.exit(close(fh));
   count <- 0;
   while(TRUE) {
     s <- readChar(fh, n=1024);
     if (nchar(s) == 0)
       break;
     count <- count + nchar(s);
     if (gsub("[\n 0-9]*", "", s) != "")
       stop("Error after reading ", count, " characters: ", s);
   }
}

Cheers

Henrik



From avneet.chugh at gmail.com  Mon Aug 29 15:50:52 2005
From: avneet.chugh at gmail.com (avneet singh)
Date: Mon, 29 Aug 2005 09:50:52 -0400
Subject: [R] staying with R, jobs in R
Message-ID: <e81b08af05082906505cebf57b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050829/a8c96896/attachment.pl

From ripley at stats.ox.ac.uk  Mon Aug 29 15:59:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 29 Aug 2005 14:59:22 +0100 (BST)
Subject: [R] ttda on R 2.1.1: error
In-Reply-To: <3ef00e160508290554d65c504@mail.gmail.com>
References: <3ef00e160508290554d65c504@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0508291454510.5510@gannet.stats>

Looks like the package is not written for current R.  native.enc was used 
prior to R 2.1.0.  Please take the advice of the posting guide and ask the 
maintainer.

BTW, there is no package ttda on CRAN, and you have not told us where you 
found it or what version you used.  If you mean

  	http://wwwpeople.unil.ch/jean-pierre.mueller/

it refers to rather old versions of R.

On Mon, 29 Aug 2005, Laurent Valdes wrote:

> Hello,
>
> I'm trying to use the package ttda, wich is involved in text analysis,
> for my own data about answers in a company survey.
> I've installed it, as well as ispell, but when trying to use an example:
>
>> zz <- file("stupid.txt", "w")  # build a data file
>> cat("{comment - stupid data file} \n"              , file = zz)
>> cat("<uci=1> Hush-a-bye, baby,     \n"             , file = zz)
>> cat("     in the tree top.  \n"                    , file = zz)
>> cat("<uci=2> When the wind blows, \n"              , file = zz)
>> cat("     the cradle will rock. \n"                , file = zz)
>> cat("<uci=3> When the bough breaks, \n"            , file = zz)
>> cat("     the cradle will fall, \n"                , file = zz)
>> cat("And down will come baby, \n"                  , file = zz)
>> cat("     cradle and all.    \n"                   , file = zz)
>> cat("{Nursery rime} \n"                            , file = zz)
>> close(zz)
>> dummy.example <- ttda.get.text(textfile = "stupid.txt")
>> dummy.example <- ttda.uce(dummy.example)
> error in identical(native.enc, MacRoman) :
> 	native.enc not found
>
> it lamentably fails.
>
> how about this ?
> -- 
> --~~ Toulouse, Grenoble, Auch, Arcachon, B?ziers, Paris,
> Saragosse, L?vignac Sur Save, habitats naturel du Valdo. ~~--
> <http://www.le-valdo.com>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

From Jean-Pierre.Mueller at unil.ch  Mon Aug 29 16:01:36 2005
From: Jean-Pierre.Mueller at unil.ch (Jean-Pierre Muller)
Date: Mon, 29 Aug 2005 16:01:36 +0200
Subject: [R] ttda on R 2.1.1: error
In-Reply-To: <3ef00e160508290554d65c504@mail.gmail.com>
References: <3ef00e160508290554d65c504@mail.gmail.com>
Message-ID: <b3fabfb38aa5dd88907fd464c4ad86d2@unil.ch>

Hello Laurent,

Yes, i know there is a problem with ttda.
I had no time to work on ttda, wich is broken since R version 2.1.
This new version of R has introduced many new ways to deal with text ( 
use of utf by default, grep & family modifications; so i have a lot of 
small modifications to do)
I will contact you when the next version is out.

Sorry for this bad news.

Le 29 ao??t 05, ?? 14:54, Laurent Valdes a ??crit :

> Hello,
>
> I'm trying to use the package ttda, wich is involved in text analysis,
> for my own data about answers in a company survey.
> I've installed it, as well as ispell, but when trying to use an 
> example:
>
>> zz <- file("stupid.txt", "w")  # build a data file
>> cat("{comment - stupid data file} \n"              , file = zz)
>> cat("<uci=1> Hush-a-bye, baby,     \n"             , file = zz)
>> cat("     in the tree top.  \n"                    , file = zz)
>> cat("<uci=2> When the wind blows, \n"              , file = zz)
>> cat("     the cradle will rock. \n"                , file = zz)
>> cat("<uci=3> When the bough breaks, \n"            , file = zz)
>> cat("     the cradle will fall, \n"                , file = zz)
>> cat("And down will come baby, \n"                  , file = zz)
>> cat("     cradle and all.    \n"                   , file = zz)
>> cat("{Nursery rime} \n"                            , file = zz)
>> close(zz)
>> dummy.example <- ttda.get.text(textfile = "stupid.txt")
>> dummy.example <- ttda.uce(dummy.example)
> error in identical(native.enc, MacRoman) :
> 	native.enc not found
>
> it lamentably fails.
>
> how about this ?
> -- 
> --~~ Toulouse, Grenoble, Auch, Arcachon, B??ziers, Paris,
> Saragosse, L??vignac Sur Save, habitats naturel du Valdo. ~~--
> <http://www.le-valdo.com>
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>
-- 
Jean-Pierre M??ller
SSP / BFSH2 / UNIL / CH - 1015 Lausanne
Voice:+41 21 692 3116 / Fax:+41 21 692 3115

Please avoid sending me Word or PowerPoint attachments.
  See http://www.gnu.org/philosophy/no-word-attachments.html
S'il vous pla??t, ??vitez de m'envoyer des attachements au format Word ou 
PowerPoint.
  Voir http://www.gnu.org/philosophy/no-word-attachments.fr.html



From tlumley at u.washington.edu  Mon Aug 29 16:31:16 2005
From: tlumley at u.washington.edu (Thomas Lumley)
Date: Mon, 29 Aug 2005 07:31:16 -0700 (PDT)
Subject: [R] LaTeX Notations in R output graphs
In-Reply-To: <1125321681.43130bd157e9b@webmail.inrets.fr>
References: <3ef00e160508290554d65c504@mail.gmail.com>
	<1125321681.43130bd157e9b@webmail.inrets.fr>
Message-ID: <Pine.A41.4.61b.0508290730210.156102@homer05.u.washington.edu>

On Mon, 29 Aug 2005 depire at inrets.fr wrote:

> Hello,
> I'm interested in LaTeX notations in R graphs. For example, I would like to know
> the R code to obtain the graph here,
> http://www.r-project.org/screenshots/power.png

Here is the code:

x<-seq(-10,10,length=400)
y1<-dnorm(x)
y2<-dnorm(x,m=3)
par(mar=c(5,4,2,1))
plot(x, y2, xlim=c(-3,8), type="n", xlab=quote(Z==frac(mu[1]-mu[2],
                 sigma/sqrt(n))), ylab="Density")
polygon(c(1.96,1.96,x[240:400],10), c(0,dnorm(1.96,m=3),y2[240:400],0),
                 col="grey80", lty=0)
lines(x, y2)
lines(x, y1)
polygon(c(-1.96,-1.96,x[161:1],-10), c(0,dnorm(-1.96,m=0), y1[161:1],0),
                 col="grey30", lty=0)
polygon(c(1.96, 1.96, x[240:400], 10), c(0,dnorm(1.96,m=0),
                 y1[240:400],0), col="grey30")
legend(4.2, .4, fill=c("grey80","grey30"),
              legend=expression(P(abs(Z)>1.96, H[1])==0.85,
              P(abs(Z)>1.96,H[0])==0.05), bty="n")
text(0, .2, quote(H[0]:~~mu[1]==mu[2]))
text(3, .2, quote(H[1]:~~mu[1]==mu[2]+delta))



From ogabbrie at tin.it  Mon Aug 29 16:47:36 2005
From: ogabbrie at tin.it (Simone Gabbriellini)
Date: Mon, 29 Aug 2005 16:47:36 +0200
Subject: [R] Rcmdr extensions
Message-ID: <9964B749-6EED-4C06-BA22-E071CC97898C@tin.it>

Dear List,

I am trying to extend Rcmdr with some functions usefult to my  
study... I have addedd succesfully a menu and some submenu to the  
GUI, and I have placed a file .R in the /etc folder... I am able to  
call functions on that file, but I cannot see the results: how can I  
tell Rcmdr to write the output in the output box?

Second question: how can I refer to the actually selected Dataset in  
my .R functions' file?

Thank you,
Simone Gabbriellini



From alxmilton at yahoo.it  Mon Aug 29 16:57:58 2005
From: alxmilton at yahoo.it (alessandro carletti)
Date: Mon, 29 Aug 2005 07:57:58 -0700 (PDT)
Subject: [R] tie diagrams
Message-ID: <20050829145758.22009.qmail@web26602.mail.ukl.yahoo.com>

Hi everybody,
can anyone help me in finding informations about tie
diagrams?
(And how to get such graphics with R).
Thanks

Alessandro Carletti



From p.dalgaard at biostat.ku.dk  Mon Aug 29 17:03:08 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 29 Aug 2005 17:03:08 +0200
Subject: [R] stratified Wilcoxon available?
In-Reply-To: <Pine.LNX.4.51.0508291440140.15465@artemis.imbe.med.uni-erlangen.de>
References: <3.0.6.32.20050828173610.007953a0@pop.gmx.net>
	<Pine.LNX.4.51.0508291440140.15465@artemis.imbe.med.uni-erlangen.de>
Message-ID: <x2vf1ohjkj.fsf@turmalin.kubism.ku.dk>

An embedded and charset-unspecified text was scrubbed...
Name: KW.strat.2005.R
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050829/f72aa6c4/KW.strat.2005.pl
-------------- next part --------------


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907

From Christoph.Scherber at uni-jena.de  Mon Aug 29 17:14:28 2005
From: Christoph.Scherber at uni-jena.de (Christoph Scherber)
Date: Mon, 29 Aug 2005 17:14:28 +0200
Subject: [R] lme and ordering of terms
Message-ID: <43132654.6070807@uni-jena.de>

Dear R users,

When fitting a lme() object (from the nlme library), is it possible to 
test interactions *before* main effects? As I understand, R 
conventionally re-orders all terms such that highest-order interactions 
come last - but I??d like to know if it??s possible (and sensible) to 
change this ordering of terms.

I??ve tried the terms() command (from aov) but I don??t know if something 
similar exists for lme() objects.

Thanks a lot for your help!

Best wishes
Christoph



From roger.bos at gmail.com  Mon Aug 29 17:18:09 2005
From: roger.bos at gmail.com (roger bos)
Date: Mon, 29 Aug 2005 11:18:09 -0400
Subject: [R] staying with R, jobs in R
In-Reply-To: <e81b08af05082906505cebf57b@mail.gmail.com>
References: <e81b08af05082906505cebf57b@mail.gmail.com>
Message-ID: <1db72680050829081824d64fce@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050829/12b38bae/attachment.pl

From valderama at gmail.com  Mon Aug 29 17:36:14 2005
From: valderama at gmail.com (Laurent Valdes)
Date: Mon, 29 Aug 2005 17:36:14 +0200
Subject: [R] ttda on R 2.1.1: error
In-Reply-To: <b3fabfb38aa5dd88907fd464c4ad86d2@unil.ch>
References: <3ef00e160508290554d65c504@mail.gmail.com>
	<b3fabfb38aa5dd88907fd464c4ad86d2@unil.ch>
Message-ID: <3ef00e16050829083670ed5e72@mail.gmail.com>

No problem. Tant pis.

2005/8/29, Jean-Pierre Muller <Jean-Pierre.Mueller at unil.ch>:
> Hello Laurent,
> 
> Yes, i know there is a problem with ttda.
> I had no time to work on ttda, wich is broken since R version 2.1.
> This new version of R has introduced many new ways to deal with text (
> use of utf by default, grep & family modifications; so i have a lot of
> small modifications to do)
> I will contact you when the next version is out.
> 
> Sorry for this bad news.

-- 
--~~ Toulouse, Grenoble, Auch, Arcachon, B??ziers, Paris, 
Saragosse, L??vignac Sur Save, habitats naturel du Valdo. ~~--
<http://www.le-valdo.com>



From gunter.berton at gene.com  Mon Aug 29 17:42:18 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 29 Aug 2005 08:42:18 -0700
Subject: [R] staying with R, jobs in R
In-Reply-To: <1db72680050829081824d64fce@mail.gmail.com>
Message-ID: <200508291542.j7TFgIEF008592@compton.gene.com>

Avneet:
Not to throw a wet blanket on your enthusiam for R (which I share) but ...

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box
 
 
 Your better off finding a 
> job you like 
> at a company you like and then convincing them that R is 
> better (not to 
> mention the R skill set you are bringing to the table).
>  Good luck to you.
> Roger

Fine advice, but a tad unrealistic. The reality (according to Bert):

1. Most jobs for statisticians are in the pharmaceutical/medical industry
(which includes academic research centers) in clinical trials. Data: See job
ads in Amstat News.

2. For better or worse, in this arena SAS is the standard. You will **not**
-- repeat, NOT -- convince industrial employers who have thousands of lines
of legacy infrastructure code and legions of SAS programmers to change. You
may well make some inroads in academic research venues. In both, you will
generally be free to use whatever software you like for your own work, but
the final code submitted for FDA approval will almost certainly necessarily
be SAS. Rail all you like, but those are the realities.

3. Another significant amployer of statisticians these days is the "finance"
industry (credit scoring and the like). Data: See Amstat News ads again.
There S-Plus is already widely used, so you should have no difficulty using
R and even getting others to adopt it.

I think outside these arenas -- for example, in industrial research and
engineering centers or in pre/non-clinical pharmaceutical work, you'll again
be free to use what you like. But there are relatively few jobs there, so
that despite Roger's noble advice (with which I again agree), first you
gotta eat and pay the mortgage.

And I also say: good luck.

-- Bert

-- Bert Gunter
Genentech Non-Clinical Statistics
South San Francisco, CA
 
"The business of the statistician is to catalyze the scientific learning
process."  - George E. P. Box



From helprhelp at gmail.com  Mon Aug 29 18:04:44 2005
From: helprhelp at gmail.com (Weiwei Shi)
Date: Mon, 29 Aug 2005 11:04:44 -0500
Subject: [R] staying with R, jobs in R
In-Reply-To: <200508291542.j7TFgIEF008592@compton.gene.com>
References: <1db72680050829081824d64fce@mail.gmail.com>
	<200508291542.j7TFgIEF008592@compton.gene.com>
Message-ID: <cdf81783050829090452b02067@mail.gmail.com>

Hi, there:
Could I ask another question, which is a little bit off-topic; but I
tried hard and did not get good enough info... so please help

I am very interested in seeing where to find those
bio/pharmaceutical-related industries, using R and data mining as
approaches?

thank you very much!

weiwei

On 8/29/05, Berton Gunter <gunter.berton at gene.com> wrote:
> Avneet:
> Not to throw a wet blanket on your enthusiam for R (which I share) but ...
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
> 
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
> 
> 
>  Your better off finding a
> > job you like
> > at a company you like and then convincing them that R is
> > better (not to
> > mention the R skill set you are bringing to the table).
> >  Good luck to you.
> > Roger
> 
> Fine advice, but a tad unrealistic. The reality (according to Bert):
> 
> 1. Most jobs for statisticians are in the pharmaceutical/medical industry
> (which includes academic research centers) in clinical trials. Data: See job
> ads in Amstat News.
> 
> 2. For better or worse, in this arena SAS is the standard. You will **not**
> -- repeat, NOT -- convince industrial employers who have thousands of lines
> of legacy infrastructure code and legions of SAS programmers to change. You
> may well make some inroads in academic research venues. In both, you will
> generally be free to use whatever software you like for your own work, but
> the final code submitted for FDA approval will almost certainly necessarily
> be SAS. Rail all you like, but those are the realities.
> 
> 3. Another significant amployer of statisticians these days is the "finance"
> industry (credit scoring and the like). Data: See Amstat News ads again.
> There S-Plus is already widely used, so you should have no difficulty using
> R and even getting others to adopt it.
> 
> I think outside these arenas -- for example, in industrial research and
> engineering centers or in pre/non-clinical pharmaceutical work, you'll again
> be free to use what you like. But there are relatively few jobs there, so
> that despite Roger's noble advice (with which I again agree), first you
> gotta eat and pay the mortgage.
> 
> And I also say: good luck.
> 
> -- Bert
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
> 
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 


-- 
Weiwei Shi, Ph.D

"Did you always know?"
"No, I did not. But I believed..."
---Matrix III



From tamir at imp.univie.ac.at  Mon Aug 29 18:11:12 2005
From: tamir at imp.univie.ac.at (Ido M. Tamir)
Date: Mon, 29 Aug 2005 18:11:12 +0200
Subject: [R] reexpand a matrix after subsetting
Message-ID: <200508291811.12899.tamir@imp.univie.ac.at>

Hi,

suppose I have a matrix (or dataframe) 
as a result from subsetting.

mat <- matrix(1:20,ncol=2)
mat[c(3,6,9),] <- NA
cc <- complete.cases(mat)
sub <- mat[cc,,drop=FALSE]
sub <- sub * 2
#some caluculations with sub.

now I would like to expand sub somehow
so row 3,6, and 9 would be filled with 
NAs but the rest should be in place again.
Is there a simple function for this?

merge is not an option.

Thank you very much for your help.

Ido


      [,1] [,2]
 [1,]    2   22
 [2,]    4   24
 [3,]   NA   NA
 [4,]    8   28
 [5,]   10   30
 [6,]   NA   NA
 [7,]   14   34
 [8,]   16   36
 [9,]   NA   NA
[10,]   20   40



From ferri.leberl at gmx.at  Mon Aug 29 18:08:56 2005
From: ferri.leberl at gmx.at (Mag. Ferri Leberl)
Date: Mon, 29 Aug 2005 18:08:56 +0200
Subject: [R] tiing an array to a data frame
Message-ID: <200508291808.56736.ferri.leberl@gmx.at>

Dear colleagues!
I am afraid this is an easy question but as a pitty I did not find out on my 
own, so please be patient with my question:
If I have a data frame X and an array Y. Which is the command to make Y become 
an additional row of X?
Thank you in advance.
Yours, Mag. Ferri Leberl



From f.harrell at vanderbilt.edu  Mon Aug 29 18:13:06 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Mon, 29 Aug 2005 11:13:06 -0500
Subject: [R] staying with R, jobs in R
In-Reply-To: <200508291542.j7TFgIEF008592@compton.gene.com>
References: <200508291542.j7TFgIEF008592@compton.gene.com>
Message-ID: <43133412.50500@vanderbilt.edu>

Berton Gunter wrote:
> Avneet:
> Not to throw a wet blanket on your enthusiam for R (which I share) but ...
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>  
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
>  
>  
>  Your better off finding a 
> 
>>job you like 
>>at a company you like and then convincing them that R is 
>>better (not to 
>>mention the R skill set you are bringing to the table).
>> Good luck to you.
>>Roger
> 
> 
> Fine advice, but a tad unrealistic. The reality (according to Bert):
> 
> 1. Most jobs for statisticians are in the pharmaceutical/medical industry
> (which includes academic research centers) in clinical trials. Data: See job
> ads in Amstat News.
> 
> 2. For better or worse, in this arena SAS is the standard. You will **not**
> -- repeat, NOT -- convince industrial employers who have thousands of lines
> of legacy infrastructure code and legions of SAS programmers to change. You
> may well make some inroads in academic research venues. In both, you will
> generally be free to use whatever software you like for your own work, but
> the final code submitted for FDA approval will almost certainly necessarily
> be SAS. Rail all you like, but those are the realities.

One disagreement Bert - code submitted to FDA does not need to be SAS 
either from industry or academia, but especially from academia.  Many 
sponsors submit no code at all because they use Excel (!) which FDA 
allows (just as they allow Minitab).

The number of job ads in Amstat news desiring R/S-Plus skills is on the 
increase.  There have even been such ads from industry, though few.

Frank

> 
> 3. Another significant amployer of statisticians these days is the "finance"
> industry (credit scoring and the like). Data: See Amstat News ads again.
> There S-Plus is already widely used, so you should have no difficulty using
> R and even getting others to adopt it.
> 
> I think outside these arenas -- for example, in industrial research and
> engineering centers or in pre/non-clinical pharmaceutical work, you'll again
> be free to use what you like. But there are relatively few jobs there, so
> that despite Roger's noble advice (with which I again agree), first you
> gotta eat and pay the mortgage.
> 
> And I also say: good luck.
> 
> -- Bert
> 
> -- Bert Gunter
> Genentech Non-Clinical Statistics
> South San Francisco, CA
>  
> "The business of the statistician is to catalyze the scientific learning
> process."  - George E. P. Box
> 


-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From cmcmille at wustl.edu  Mon Aug 29 18:18:12 2005
From: cmcmille at wustl.edu (Curtis McMillen)
Date: Mon, 29 Aug 2005 11:18:12 -0500
Subject: [R] seeking consultant for pan procedure in R
Message-ID: <84C59624B1B0204BBCB3B7DDF981AE63498395@GWB-PO.gwb.wustl.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050829/ad7a59a4/attachment.pl

From murdoch at stats.uwo.ca  Mon Aug 29 18:18:45 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Mon, 29 Aug 2005 12:18:45 -0400
Subject: [R] reexpand a matrix after subsetting
In-Reply-To: <200508291811.12899.tamir@imp.univie.ac.at>
References: <200508291811.12899.tamir@imp.univie.ac.at>
Message-ID: <43133565.3080403@stats.uwo.ca>

On 8/29/2005 12:11 PM, Ido M. Tamir wrote:
> Hi,
> 
> suppose I have a matrix (or dataframe) 
> as a result from subsetting.
> 
> mat <- matrix(1:20,ncol=2)
> mat[c(3,6,9),] <- NA
> cc <- complete.cases(mat)
> sub <- mat[cc,,drop=FALSE]
> sub <- sub * 2
> #some caluculations with sub.
> 
> now I would like to expand sub somehow
> so row 3,6, and 9 would be filled with 
> NAs but the rest should be in place again.
> Is there a simple function for this?
> 
> merge is not an option.
> 
> Thank you very much for your help.

You just need to calculate the original row numbers.  For example,

goodrows <- (1:nrow(mat))[cc]
mat[goodrows,,drop=FALSE] <- sub

Duncan Murdoch



From sundar.dorai-raj at pdf.com  Mon Aug 29 18:22:03 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 29 Aug 2005 11:22:03 -0500
Subject: [R] tiing an array to a data frame
In-Reply-To: <200508291808.56736.ferri.leberl@gmx.at>
References: <200508291808.56736.ferri.leberl@gmx.at>
Message-ID: <4313362B.60307@pdf.com>

?rbind

--sundar

Mag. Ferri Leberl wrote:
> Dear colleagues!
> I am afraid this is an easy question but as a pitty I did not find out on my 
> own, so please be patient with my question:
> If I have a data frame X and an array Y. Which is the command to make Y become 
> an additional row of X?
> Thank you in advance.
> Yours, Mag. Ferri Leberl
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From mathieu.drapeau at mcgill.ca  Mon Aug 29 18:42:58 2005
From: mathieu.drapeau at mcgill.ca (Mathieu Drapeau)
Date: Mon, 29 Aug 2005 12:42:58 -0400
Subject: [R]  ROracle and select query empty
Message-ID: <43133B12.6050205@mcgill.ca>

I am using Linux Oracle Client 9i and I am running my R scripts on a Linux box.
I logged on our Oracle administration interface and the queries that I launched were executed and returned many lines directly to my Linux box.
It looks that the problem is with the fetch method.

Thank you very much,
Mathieu


> Mathieu Drapeau <mathieu.drapeau at mcgill.ca <https://stat.ethz.ch/mailman/listinfo/r-help>> wrote:
> >/ Hi,
/> >/ I just installed ROracle and RDBI. The connection to the database seems 
/> >/ to work also. My problem is when I am selection rows that really exist 
/> >/ in the database, it is returning nothing. Where should I look to see 
/> >/ what could be my problem?
/> 
> What platform are you running R on?  And what version of Oracle?  This
> sounds very familiar... are you building ROracle on Linux?
> 
> -- David Hinds
>



From HDoran at air.org  Mon Aug 29 18:58:47 2005
From: HDoran at air.org (Doran, Harold)
Date: Mon, 29 Aug 2005 12:58:47 -0400
Subject: [R] ylim for graphic
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7409E5C8E0@dc1ex2.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050829/13ccd223/attachment.pl

From mschwartz at mn.rr.com  Mon Aug 29 19:35:38 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Mon, 29 Aug 2005 12:35:38 -0500
Subject: [R] ylim for graphic
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7409E5C8E0@dc1ex2.air.org>
References: <88EAF3512A55DF46B06B1954AEF73F7409E5C8E0@dc1ex2.air.org>
Message-ID: <1125336938.5201.53.camel@localhost.localdomain>

On Mon, 2005-08-29 at 12:58 -0400, Doran, Harold wrote:
> Dear list:
> 
> I have some data for which I am generating a series of barplots for
> percentages. One issue that I am dealing with is that I am trying to get
> the legend to print in a fixed location for each chart generated by the
> data. Because these charts are being created in a loop, with different
> data, my code searches the data to identify the maximum value in the
> data and then print the data values 5 points above the tallest bar. 
> 
> Now, in situations where the largest value is 100, I needed to create
> the y-axis high enough to accommodate the legend w/o crowding up the
> data or the bars. So, I have ylim =c(0,200) and then place the legend at
> c(2,150). Visually, this places things exactly where I want them. But,
> it seems silly to have a y-axis labeled as high as 200%. I'm certain
> there is a smarter technique. Is it possible to place the legend at a
> location higher than 100 to avoid the crowding of the bars and the data
> and then also have the labels for the y-axis not print after the value
> 100%? 
> 
> In looking at ?legend I didn't see an option that would address this.
> Below is some code that you can use to create a similar chart.
> 
> Thanks,
> Harold
> 
> 
> math.bar <- c(53,31,55,28,55,100)
> apmxpmeet <- c(47, 50, 49, 50, 49, 46)
> par(ps=10)
> math.bar <- rbind(math.bar, apmxpmeet)
> math.barplot <- barplot(math.bar, beside=T, col=c('blue','orange'),
> names=c('Grade \n 3','Grade \n 4','Grade \n 5','Grade \n 6','Grade \n
> 7','Grade \n 8'), 
> ylim=c(0,200), ylab="Percentage", xlab="Grade Level")
> tot <- round(math.bar,digits=0)
> graph.max <- max(math.bar, apmxpmeet, na.rm=T)
> text(math.barplot, graph.max+5, tot, xpd = TRUE, col = c("blue",
> "orange") )
> legend(2,150,legend=(c("Label A", "Average")), fill=c("blue","orange"))

Harold,

A few thoughts:

1. Instead of fixing the y axis max value at 200, simply set ylim to
c(0, max(math.bar * 1.2)) or a similar constant. In this case, you get
an extra 20% above the max(y) value for the legend placement.


2. In the legend call, use:

  legend("topleft", legend=(c("Label A", "Average")),
          fill = c("blue","orange"))

This will place the legend at the topleft of the plot region, rather
than you having to calculate the x and y coords. If you want it moved in
from the upper left hand corner, you can use the 'inset' argument as
well, which moves the legend by a proportion of the plot region limits
(0 - 1):

    legend("topleft", legend=(c("Label A", "Average")),
          fill = c("blue","orange"), inset = .1)


3. You can use barplot(..., yaxt = "n") to have the y axis not drawn and
then use axis() to place the labels at locations of your choosing, which
do not need to run the full length of the axis range:

 barplot(1:5, yaxt = "n", ylim = c(0, 10))
 axis(2, at = 0:5)


4. You can place the legend outside the plot region, enabling you to
keep the y axis range to <=100. This would need some tweaking, but the
idea is the same:

 # Increase the size of the top margin
 par(mar = c(5, 4, 8, 2) + 0.1)

 # Draw a barplot
 barplot(1:5)

 # Disable clipping outside the plot region
 par(xpd = TRUE)

 # Now draw the legend, but move it up by 30% from the top left
 legend("topleft", legend = LETTERS[1:5], inset = c(0, -.3))


You could also place the legend to the right or left of the plot region
if you prefer, adjusting the above accordingly.

HTH,

Marc Schwartz



From cpaulse at aecom.yu.edu  Mon Aug 29 20:03:58 2005
From: cpaulse at aecom.yu.edu (Chris Paulse)
Date: Mon, 29 Aug 2005 14:03:58 -0400
Subject: [R] interactive time series plot
Message-ID: <20050829180409.537F22FC9@post.aecom.yu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050829/ec85c94a/attachment.pl

From dhinds at sonic.net  Mon Aug 29 20:06:50 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Mon, 29 Aug 2005 18:06:50 +0000 (UTC)
Subject: [R] ROracle and select query empty
References: <43133B12.6050205@mcgill.ca>
Message-ID: <devirp$3f3$1@sea.gmane.org>

Mathieu Drapeau <mathieu.drapeau at mcgill.ca> wrote:

> I am using Linux Oracle Client 9i and I am running my R scripts on a
> Linux box. 

Does /usr/include/sqlca.h exist?  This is a Postgres file.  My hazy
memory is that this conflicts with an Oracle header; and that if
ROracle sees this one at compile time, you get empty query results.

Try renaming this file to something else, then rebuild ROracle.

-- Dave



From mathieu.drapeau at mcgill.ca  Mon Aug 29 20:24:16 2005
From: mathieu.drapeau at mcgill.ca (Mathieu Drapeau)
Date: Mon, 29 Aug 2005 14:24:16 -0400
Subject: [R] ROracle and select query empty
In-Reply-To: <devirp$3f3$1@sea.gmane.org>
References: <43133B12.6050205@mcgill.ca> <devirp$3f3$1@sea.gmane.org>
Message-ID: <431352D0.5000403@mcgill.ca>

Thanks!!!
It is working now.

Mathieu

dhinds at sonic.net wrote:

>Mathieu Drapeau <mathieu.drapeau at mcgill.ca> wrote:
>
>  
>
>>I am using Linux Oracle Client 9i and I am running my R scripts on a
>>Linux box. 
>>    
>>
>
>Does /usr/include/sqlca.h exist?  This is a Postgres file.  My hazy
>memory is that this conflicts with an Oracle header; and that if
>ROracle sees this one at compile time, you get empty query results.
>
>Try renaming this file to something else, then rebuild ROracle.
>
>-- Dave
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>  
>



From dhinds at sonic.net  Mon Aug 29 21:08:16 2005
From: dhinds at sonic.net (dhinds@sonic.net)
Date: Mon, 29 Aug 2005 19:08:16 +0000 (UTC)
Subject: [R] ROracle and select query empty
References: <43133B12.6050205@mcgill.ca> <devirp$3f3$1@sea.gmane.org>
	<431352D0.5000403@mcgill.ca>
Message-ID: <devmf0$fc5$1@sea.gmane.org>

Mathieu Drapeau <mathieu.drapeau at mcgill.ca> wrote:
> Thanks!!!
> It is working now.

I'll look into whether ROracle can be tweaked to prevent this problem.

-- Dave



From HStevens at MUOhio.edu  Mon Aug 29 21:25:53 2005
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Mon, 29 Aug 2005 15:25:53 -0400
Subject: [R] user defined panel function
In-Reply-To: <78a5a6fe050812075934f9c64a@mail.gmail.com>
References: <78a5a6fe050812074455760f6c@mail.gmail.com>
	<00b301c59f4d$6982b8c0$0540210a@www.domain>
	<78a5a6fe050812075934f9c64a@mail.gmail.com>
Message-ID: <112612ef4b760905b325f465f5ff9785@MUOhio.edu>

Mac OS 10.3.9 R framework  v. 2.1.1

I am attempting to put a fitted curve into each panel of a lattice 
graph, but am failing to do so. I have tried writing a very 
sophisticated function to do so. The function seems to work when used 
with plot(), but does not do so inside a panel function in xyplot().
Any pointers would be appreciated.

#The example data
fact <- gl(2,7)
x <- rep(1:7,2)
y <- c(1,1,2,3,2,3,4,1,2,1,2,3,3,4)
plot(jitter(y/6) ~ x)

# The following user defined function puts a curve (I believe the 
correct one) into the scatterplot
panel.predglm <- function(x, y) {	
	model.trial <- glm(cbind(y,6-y) ~ poly(x,2), 
family=quasibinomial(link="logit"))
	xfit <- seq(1,7, length=21)
	yfit <- predict(model.trial, newdata=data.frame(x=xfit), 
type="response")
	lines(xfit,yfit)  }

panel.predglm(x, y)


# My attempt to use it in a lattice xyplot, however, fails. It draws a 
curve which in most cases is outside the dimensions of the plot. I 
suspect that the prediction is on the scale of the link functions.

library(lattice)
xyplot(y/6 ~ x|fact, ylim=c(0,.8),
panel=function(x, y,...) {
	panel.xyplot(jitter(x),jitter(y))
	panel.predglm(x,y) }
	)

Any thoughts?
Hank Stevens


Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From greg.snow at ihc.com  Mon Aug 29 21:29:22 2005
From: greg.snow at ihc.com (Greg Snow)
Date: Mon, 29 Aug 2005 13:29:22 -0600
Subject: [R] interactive time series plot
Message-ID: <s3130dbf.091@lp-msg1.co.ihc.com>

I don't think that the par(ask=T) will do it for you.  Some alternatives
to try:

1. use the slider function in either the relax package or the
TeachingDemos
    package to create a Tk slider that you move back and forth with the
mouse
   and have the graph update accordingly.

2. Use locator(1) to have the user advance the graph by clicking and
have
    your function determine the direction moved based on if they click
on the
    right or left part of the graph (see put.points.demo in
TeachingDemos
    package for an example).

3. Use the readline function to prompt for keyboard input and move the

    window based on the keyboard input.

hope this helps,

Greg Snow, Ph.D.
Statistical Data Center, LDS Hospital
Intermountain Health Care
greg.snow at ihc.com
(801) 408-8111

>>> "Chris Paulse" <cpaulse at aecom.yu.edu> 08/29/05 12:03PM >>>
Hi,

I've written the following function to display small windows of a time
series (and a processed version of it) with mouse clicks used to move
the
window forward.

 

ViewRawAndProcessed <- function(raw, processed, width=1000)

{

      len <- length(raw)

      n <- round(len/width)

      for (i in 1:n)

      {

            plot(raw[((i-1)*width):(i*width)], type="s")

            lines(processed[((i-1)*width):(i*width)], type="s",
col="red")

            s <- sprintf("%d - %d", (i-1)*width,(i*width))

            mtext(s)

            par(ask=TRUE)

      }

}

 

What I'd like to do is modify the function so that it stays within a
loop
and accepts right and left cursor keys (or h and l) to shift the
current
window backwards and forwards (with the q key causing a break from the
loop).

 

Is this possible with the par(ask=TRUE) command?

 

Thanks,

Chris Paulse


	[[alternative HTML version deleted]]

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From vincent.goulet at act.ulaval.ca  Mon Aug 29 21:35:21 2005
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Mon, 29 Aug 2005 15:35:21 -0400
Subject: [R] Testing if all elements are equal in a vector/matrix
Message-ID: <200508291535.21230.vincent.goulet@act.ulaval.ca>


Is there a canonical way to check if all elements of a vector or matrix are 
the same? Solutions below work, but look hackish to me.

> x <- rep(1, 10)
> all(x == x[1])  # == operator does not provide for small differences
[1] TRUE
> isTRUE(all.equal(x, rep(x[1], length(x)))) # ugly
[1] TRUE

Best,

Vincent
-- 
  Vincent Goulet, Associate Professor
  ??cole d'actuariat
  Universit?? Laval, Qu??bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From Antonio_Paredes at aphis.usda.gov  Mon Aug 29 21:45:32 2005
From: Antonio_Paredes at aphis.usda.gov (Antonio_Paredes@aphis.usda.gov)
Date: Mon, 29 Aug 2005 14:45:32 -0500
Subject: [R] prediction intervals
Message-ID: <OFA0A6F10E.2AD35D25-ON8625706C.006C3B11-8625706C.006C7200@aphis.usda.gov>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050829/862ef797/attachment.pl

From sundar.dorai-raj at pdf.com  Mon Aug 29 21:44:57 2005
From: sundar.dorai-raj at pdf.com (Sundar Dorai-Raj)
Date: Mon, 29 Aug 2005 14:44:57 -0500
Subject: [R] user defined panel function
In-Reply-To: <112612ef4b760905b325f465f5ff9785@MUOhio.edu>
References: <78a5a6fe050812074455760f6c@mail.gmail.com>	<00b301c59f4d$6982b8c0$0540210a@www.domain>	<78a5a6fe050812075934f9c64a@mail.gmail.com>
	<112612ef4b760905b325f465f5ff9785@MUOhio.edu>
Message-ID: <431365B9.4030404@pdf.com>



Martin Henry H. Stevens wrote:
> Mac OS 10.3.9 R framework  v. 2.1.1
> 
> I am attempting to put a fitted curve into each panel of a lattice 
> graph, but am failing to do so. I have tried writing a very 
> sophisticated function to do so. The function seems to work when used 
> with plot(), but does not do so inside a panel function in xyplot().
> Any pointers would be appreciated.
> 
> #The example data
> fact <- gl(2,7)
> x <- rep(1:7,2)
> y <- c(1,1,2,3,2,3,4,1,2,1,2,3,3,4)
> plot(jitter(y/6) ~ x)
> 
> # The following user defined function puts a curve (I believe the 
> correct one) into the scatterplot
> panel.predglm <- function(x, y) {	
> 	model.trial <- glm(cbind(y,6-y) ~ poly(x,2), 
> family=quasibinomial(link="logit"))
> 	xfit <- seq(1,7, length=21)
> 	yfit <- predict(model.trial, newdata=data.frame(x=xfit), 
> type="response")
> 	lines(xfit,yfit)  }
> 
> panel.predglm(x, y)
> 
> 
> # My attempt to use it in a lattice xyplot, however, fails. It draws a 
> curve which in most cases is outside the dimensions of the plot. I 
> suspect that the prediction is on the scale of the link functions.
> 
> library(lattice)
> xyplot(y/6 ~ x|fact, ylim=c(0,.8),
> panel=function(x, y,...) {
> 	panel.xyplot(jitter(x),jitter(y))
> 	panel.predglm(x,y) }
> 	)
> 
> Any thoughts?

Two:

1. The "y" argument in your panel function ranges from 0 to 1 and not 0 
to 6 as your plot example assumes.

2. You need to use llines in your panel function and not lines.

Here's a working example:

library(lattice)
fact <- gl(2,7)
x <- rep(1:7,2)
y <- c(1,1,2,3,2,3,4,1,2,1,2,3,3,4)

# The following user defined function puts a curve (I believe the 
correct one) into the scatterplot
panel.predglm <- function(x, y) {	
	model.trial <- glm(cbind(y,6-y) ~ poly(x,2),
                          family=quasibinomial(link="logit"))
	xfit <- seq(1, 7, length=21)
	yfit <- predict(model.trial, newdata=data.frame(x=xfit), type="response")
	llines(xfit,yfit)
}

xyplot(y/6 ~ x|fact, ylim=c(0,.8),
        panel = function(x, y, ...) {
          panel.xyplot(jitter(x), jitter(y))
          panel.predglm(x, y * 6)
        })



From HDoran at air.org  Mon Aug 29 21:49:20 2005
From: HDoran at air.org (Doran, Harold)
Date: Mon, 29 Aug 2005 15:49:20 -0400
Subject: [R] Testing if all elements are equal in a vector/matrix
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7409E5C943@dc1ex2.air.org>

See ?identical 

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Vincent Goulet
Sent: Monday, August 29, 2005 3:35 PM
To: r-help at stat.math.ethz.ch
Subject: [R] Testing if all elements are equal in a vector/matrix


Is there a canonical way to check if all elements of a vector or matrix are the same? Solutions below work, but look hackish to me.

> x <- rep(1, 10)
> all(x == x[1])  # == operator does not provide for small differences
[1] TRUE
> isTRUE(all.equal(x, rep(x[1], length(x)))) # ugly
[1] TRUE

Best,

Vincent
--
  Vincent Goulet, Associate Professor
  ??cole d'actuariat
  Universit?? Laval, Qu??bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From gerifalte28 at hotmail.com  Mon Aug 29 22:05:20 2005
From: gerifalte28 at hotmail.com (Francisco J. Zagmutt)
Date: Mon, 29 Aug 2005 20:05:20 +0000
Subject: [R] Testing if all elements are equal in a vector/matrix
In-Reply-To: <88EAF3512A55DF46B06B1954AEF73F7409E5C943@dc1ex2.air.org>
Message-ID: <BAY103-F32CE172A9817825B14FEC6A6AF0@phx.gbl>

Hi Doran

The documentation for isTRUE reads 'isTRUE(x)' is an abbreviation of 
'identical(TRUE,x)'  so actually Vincent's solutions is "cleaner" than using 
identical :)

Cheers

Francisco


>From: "Doran, Harold" <HDoran at air.org>
>To: <vincent.goulet at act.ulaval.ca>, <r-help at stat.math.ethz.ch>
>Subject: Re: [R] Testing if all elements are equal in a vector/matrix
>Date: Mon, 29 Aug 2005 15:49:20 -0400
>
>See ?identical
>
>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Vincent Goulet
>Sent: Monday, August 29, 2005 3:35 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] Testing if all elements are equal in a vector/matrix
>
>
>Is there a canonical way to check if all elements of a vector or matrix are 
>the same? Solutions below work, but look hackish to me.
>
> > x <- rep(1, 10)
> > all(x == x[1])  # == operator does not provide for small differences
>[1] TRUE
> > isTRUE(all.equal(x, rep(x[1], length(x)))) # ugly
>[1] TRUE
>
>Best,
>
>Vincent
>--
>   Vincent Goulet, Associate Professor
>   École d'actuariat
>   Université Laval, Québec
>   Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From HDoran at air.org  Mon Aug 29 22:06:27 2005
From: HDoran at air.org (Doran, Harold)
Date: Mon, 29 Aug 2005 16:06:27 -0400
Subject: [R] Testing if all elements are equal in a vector/matrix
Message-ID: <88EAF3512A55DF46B06B1954AEF73F7409E5C94F@dc1ex2.air.org>

Yes, and I mistakenly thought this was comparing two objects, and that is not the case.  

-----Original Message-----
From: Francisco J. Zagmutt [mailto:gerifalte28 at hotmail.com] 
Sent: Monday, August 29, 2005 4:05 PM
To: Doran, Harold; vincent.goulet at act.ulaval.ca; r-help at stat.math.ethz.ch
Subject: Re: [R] Testing if all elements are equal in a vector/matrix

Hi Doran

The documentation for isTRUE reads 'isTRUE(x)' is an abbreviation of 'identical(TRUE,x)'  so actually Vincent's solutions is "cleaner" than using identical :)

Cheers

Francisco


>From: "Doran, Harold" <HDoran at air.org>
>To: <vincent.goulet at act.ulaval.ca>, <r-help at stat.math.ethz.ch>
>Subject: Re: [R] Testing if all elements are equal in a vector/matrix
>Date: Mon, 29 Aug 2005 15:49:20 -0400
>
>See ?identical
>
>-----Original Message-----
>From: r-help-bounces at stat.math.ethz.ch 
>[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Vincent Goulet
>Sent: Monday, August 29, 2005 3:35 PM
>To: r-help at stat.math.ethz.ch
>Subject: [R] Testing if all elements are equal in a vector/matrix
>
>
>Is there a canonical way to check if all elements of a vector or matrix 
>are the same? Solutions below work, but look hackish to me.
>
> > x <- rep(1, 10)
> > all(x == x[1])  # == operator does not provide for small differences
>[1] TRUE
> > isTRUE(all.equal(x, rep(x[1], length(x)))) # ugly
>[1] TRUE
>
>Best,
>
>Vincent
>--
>   Vincent Goulet, Associate Professor
>   ??cole d'actuariat
>   Universit?? Laval, Qu??bec
>   Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! 
>http://www.R-project.org/posting-guide.html



From ripley at stats.ox.ac.uk  Mon Aug 29 22:32:00 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 29 Aug 2005 21:32:00 +0100 (BST)
Subject: [R] prediction intervals
In-Reply-To: <OFA0A6F10E.2AD35D25-ON8625706C.006C3B11-8625706C.006C7200@aphis.usda.gov>
References: <OFA0A6F10E.2AD35D25-ON8625706C.006C3B11-8625706C.006C7200@aphis.usda.gov>
Message-ID: <Pine.LNX.4.61.0508292128590.15741@gannet.stats>

What is an `mle object'?  If it is something produced by mle() in stats4, 
in what sense is `prediction' relevant?

On Mon, 29 Aug 2005 Antonio_Paredes at aphis.usda.gov wrote:

> Hello.
>
> I am looking for a reference to compute prediction intervals from a mle
> object.
>
> Thank you.
>
> Tony.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

PLEASE do, including the part about not sending HTML mail.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.murrell at auckland.ac.nz  Mon Aug 29 22:34:57 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 30 Aug 2005 08:34:57 +1200
Subject: [R] interactive time series plot
References: <s3130dbf.091@lp-msg1.co.ihc.com>
Message-ID: <43137171.6070303@stat.auckland.ac.nz>

Hi

You might also want to check out getGraphicsEvent (on Windows)

Paul


Greg Snow wrote:
> I don't think that the par(ask=T) will do it for you.  Some alternatives
> to try:
> 
> 1. use the slider function in either the relax package or the
> TeachingDemos
>     package to create a Tk slider that you move back and forth with the
> mouse
>    and have the graph update accordingly.
> 
> 2. Use locator(1) to have the user advance the graph by clicking and
> have
>     your function determine the direction moved based on if they click
> on the
>     right or left part of the graph (see put.points.demo in
> TeachingDemos
>     package for an example).
> 
> 3. Use the readline function to prompt for keyboard input and move the
> 
>     window based on the keyboard input.
> 
> hope this helps,
> 
> Greg Snow, Ph.D.
> Statistical Data Center, LDS Hospital
> Intermountain Health Care
> greg.snow at ihc.com
> (801) 408-8111
> 
> 
>>>>"Chris Paulse" <cpaulse at aecom.yu.edu> 08/29/05 12:03PM >>>
>>>
> Hi,
> 
> I've written the following function to display small windows of a time
> series (and a processed version of it) with mouse clicks used to move
> the
> window forward.
> 
>  
> 
> ViewRawAndProcessed <- function(raw, processed, width=1000)
> 
> {
> 
>       len <- length(raw)
> 
>       n <- round(len/width)
> 
>       for (i in 1:n)
> 
>       {
> 
>             plot(raw[((i-1)*width):(i*width)], type="s")
> 
>             lines(processed[((i-1)*width):(i*width)], type="s",
> col="red")
> 
>             s <- sprintf("%d - %d", (i-1)*width,(i*width))
> 
>             mtext(s)
> 
>             par(ask=TRUE)
> 
>       }
> 
> }
> 
>  
> 
> What I'd like to do is modify the function so that it stays within a
> loop
> and accepts right and left cursor keys (or h and l) to shift the
> current
> window backwards and forwards (with the q key causing a break from the
> loop).
> 
>  
> 
> Is this possible with the par(ask=TRUE) command?
> 
>  
> 
> Thanks,
> 
> Chris Paulse
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From HStevens at MUOhio.edu  Mon Aug 29 22:57:46 2005
From: HStevens at MUOhio.edu (Martin Henry H. Stevens)
Date: Mon, 29 Aug 2005 16:57:46 -0400
Subject: [R] user defined panel function - Solved
In-Reply-To: <431365B9.4030404@pdf.com>
References: <78a5a6fe050812074455760f6c@mail.gmail.com>	<00b301c59f4d$6982b8c0$0540210a@www.domain>	<78a5a6fe050812075934f9c64a@mail.gmail.com>
	<112612ef4b760905b325f465f5ff9785@MUOhio.edu>
	<431365B9.4030404@pdf.com>
Message-ID: <f10ded82280908174b48d34708c114f8@MUOhio.edu>

Problem Solved (see below) - Many thanks to Sundar Dorai-Raj!
Hank Stevens
On Aug 29, 2005, at 3:44 PM, Sundar Dorai-Raj wrote:

>
>
> Martin Henry H. Stevens wrote:
>> Mac OS 10.3.9 R framework  v. 2.1.1
>>
>> I am attempting to put a fitted curve into each panel of a lattice
>> graph, but am failing to do so. I have tried writing a very
>> sophisticated function to do so. The function seems to work when used
>> with plot(), but does not do so inside a panel function in xyplot().
>> Any pointers would be appreciated.
>>
>> #The example data
>> fact <- gl(2,7)
>> x <- rep(1:7,2)
>> y <- c(1,1,2,3,2,3,4,1,2,1,2,3,3,4)
>> plot(jitter(y/6) ~ x)
>>
>> # The following user defined function puts a curve (I believe the
>> correct one) into the scatterplot
>> panel.predglm <- function(x, y) {	
>> 	model.trial <- glm(cbind(y,6-y) ~ poly(x,2),
>> family=quasibinomial(link="logit"))
>> 	xfit <- seq(1,7, length=21)
>> 	yfit <- predict(model.trial, newdata=data.frame(x=xfit),
>> type="response")
>> 	lines(xfit,yfit)  }
>>
>> panel.predglm(x, y)
>>
>>
>> # My attempt to use it in a lattice xyplot, however, fails. It draws a
>> curve which in most cases is outside the dimensions of the plot. I
>> suspect that the prediction is on the scale of the link functions.
>>
>> library(lattice)
>> xyplot(y/6 ~ x|fact, ylim=c(0,.8),
>> panel=function(x, y,...) {
>> 	panel.xyplot(jitter(x),jitter(y))
>> 	panel.predglm(x,y) }
>> 	)
>>
>> Any thoughts?
>
> Two:
>
> 1. The "y" argument in your panel function ranges from 0 to 1 and not 0
> to 6 as your plot example assumes.
>
> 2. You need to use llines in your panel function and not lines.
>
> Here's a working example:
>
> library(lattice)
> fact <- gl(2,7)
> x <- rep(1:7,2)
> y <- c(1,1,2,3,2,3,4,1,2,1,2,3,3,4)
>
> # The following user defined function puts a curve (I believe the
> correct one) into the scatterplot
> panel.predglm <- function(x, y) {	
> 	model.trial <- glm(cbind(y,6-y) ~ poly(x,2),
>                           family=quasibinomial(link="logit"))
> 	xfit <- seq(1, 7, length=21)
> 	yfit <- predict(model.trial, newdata=data.frame(x=xfit), 
> type="response")
> 	llines(xfit,yfit)
> }
>
> xyplot(y/6 ~ x|fact, ylim=c(0,.8),
>         panel = function(x, y, ...) {
>           panel.xyplot(jitter(x), jitter(y))
>           panel.predglm(x, y * 6)
>         })
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>
>
Dr. Martin Henry H. Stevens, Assistant Professor
338 Pearson Hall
Botany Department
Miami University
Oxford, OH 45056

Office: (513) 529-4206
Lab: (513) 529-4262
FAX: (513) 529-4243
http://www.cas.muohio.edu/botany/bot/henry.html
http://www.muohio.edu/ecology/
http://www.muohio.edu/botany/
"E Pluribus Unum"



From pburns at pburns.seanet.com  Mon Aug 29 23:22:14 2005
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Mon, 29 Aug 2005 22:22:14 +0100
Subject: [R] Testing if all elements are equal in a vector/matrix
In-Reply-To: <200508291535.21230.vincent.goulet@act.ulaval.ca>
References: <200508291535.21230.vincent.goulet@act.ulaval.ca>
Message-ID: <43137C86.8000902@pburns.seanet.com>

How about

diff(range(x)) < tolerance

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Vincent Goulet wrote:

>Is there a canonical way to check if all elements of a vector or matrix are 
>the same? Solutions below work, but look hackish to me.
>
>  
>
>>x <- rep(1, 10)
>>all(x == x[1])  # == operator does not provide for small differences
>>    
>>
>[1] TRUE
>  
>
>>isTRUE(all.equal(x, rep(x[1], length(x)))) # ugly
>>    
>>
>[1] TRUE
>
>Best,
>
>Vincent
>  
>



From p.murrell at auckland.ac.nz  Mon Aug 29 23:32:17 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 30 Aug 2005 09:32:17 +1200
Subject: [R] pdf font embedding --- again
References: <200508221537.j7MFbsa0000978@hypatia.math.ethz.ch>	<Pine.LNX.4.61.0508221700100.17196@gannet.stats>
	<200508222038.j7MKceUi031412@hypatia.math.ethz.ch>
Message-ID: <43137EE1.6000307@stat.auckland.ac.nz>

Hi

I think there are two problems:

(i)  You are specifying the font incorrectly.  Try ...

# You might need to specify full paths to these
afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", "lbms.afm");
# Set up the mapping for "lucida" font family
postscriptFonts(lucida=postscriptFont("Lucida", metrics=afmfiles))
# Specify that the "lucida" font is to be used
postscript(file="test.ps", family="lucida");
l<- 40:80;
plot(l,l,pch=l);
dev.off();

Should work for pdf() too.

This should put a reference to the appropriate font in the PostScript or 
  PDF file that R creates.

(ii)  R does not embed font information.  But you can, for example, use 
ghostscript to do it, as long as you tell ghostscript about the font 
too.  You might have to set up a file 'FontMap' which looks something 
like ...

/Lucida   (PATH_TO/lb___.pfb);

... (assuming that lb___.pfb is the name of the .pfb file for the Lucida 
font).  Then try something like (NOTE that you have to specify 
GS_FONTPATH to tell ghostscript where your FontMap file is) ...

GS_FONTPATH=PATH_TO_FontMap gs -dBATCH -dNOPAUSE -sDEVICE=pdfwrite 
-sPAPERSIZE=a4 -sOutputFile=testembed.pdf test.pdf

This should give you a file with the font info embedded and then you 
should be able to include that in a LaTeX document.

Paul

p.s. Thanks for the segfault report.  I will look at why that is happening.


ivo_welch-rstat8303 at mailblocks.com wrote:
> Thank you---as always.
> 
> still, I remain font-desparate.
> 
> I would love to use the fonts from my book, but [a] I cannot figure out 
> how to do this yet even in the R postscript device; and [b] I am using 
> the R pdf device, not the postscript device.  I guess if I can solve 
> [a], then I can rewrite all my graphics creations now into the 
> postscript device, and replace the dev.off() with something that 
> follows it with ps2pdf.  The following attempt, however, does not work:
> 
>    afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", 
> "lbms.afm");
>   Lucida <- postscriptFont("Lucida", metrics=afmfiles);
>   postscript(file="test.ps", family=Lucida);
>   l<- 40:80;
>   plot(l,l,pch=l);
>   dev.off();
> 
> By the way, if I try  " postscript(family=afmfiles);" then I do not get 
> an R error, but R 2.1.0 segfaults, which is probably not desirable.  
> This occurs even if there is no .afm file in the current directory.
> 
> 
> Can I make a suggestion to the R team?    It would be nice if I could 
> specify a pdf() device parameter that says "choose font settings to 
> embed all fonts" (i.e., do not use fonts that cannot be embedded, 
> either).  Something that guarantees me that I get a figure that I can 
> give to someone that is fully specified.   Right now, accomplishing 
> this is not easy to figure out, and perhaps not even possible.  Yes, in 
> the list of font families that R recognizes are some fonts that do not 
> seem among the 13 standard fonts (such as URWbookman).  moreover, if I 
> choose it as my pdf font family, it is smart enough to use a different 
> symbol file ('StandardSymL'), which I hope is also open and not adobe.  
> If so, they could be used in principle.  How do I get R to embed 
> URWbookman?  ZapfDingbats always seems to be included, so I hope this 
> is open and embeddable.
> 
> more help would be highly appreciated.
> 
> Regards,
> 
> /iaw
> ---
> ivo welch
> 
> -----Original Message-----
> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
> To: ivo_welch-rstat8303 at mailblocks.com
> Cc: r-help at stat.math.ethz.ch
> Sent: Mon, 22 Aug 2005 17:07:14 +0100 (BST)
> Subject: Re: [R] pdf font embedding --- again
> 
> On Mon, 22 Aug 2005 ivo_welch-rstat8303 at mailblocks.com wrote:
> 
>  >
>   > dear R wizards--- I would like to do some book-on-demand printing at 
> a
>  > popular printer named lulu, but lulu requires inclusion even of the
>  > basic postscript fonts. Interestingly, my book itself does not need
>   > the 14 base acrobat fonts, only the embedded R figures do. Of 
> course,
>  > I really would like to get pdftex to embed the fonts, but how to do
>  > this is not obvious either. [This method seems to be what the R help
>   > page is indicating... The software including the PostScript plot 
> file
>  > should either embed the font outlines (usually from '.pfb' or '.pfa'
>  > files) or use DSC comments to instruct the print spooler to do so.)
> 
>  Why not use the fonts your book does use in the figures? (That's how
>  my books are done.)
> 
>   > So, I would really, really like to embed the necessary fonts with 
> the R
>  > figures. I first reread the discussion in this mailing list about
>  > (eps) font embedding earlier this year. This was ultimately not very
>   > helpful. First, I do not know how to instruct my embedding program 
> to
>  > include the fonts that R figures want. Second, I already start with
>  > the pdf device, so distilling eps files is not a good option--and it
>  > would seem a bit crazy to first use the wrong output device
>  > (postscript), then ship my files over to a windows machine somewhere
>   > that has distiller installed, run distiller by hand, then ftp them 
> back
>  > to my linux machine---just for getting the fonts embedded.
>  >
>  > Is it impossible to get R to embed the necessary fonts in its pdf
>  > output?
> 
>   Yes, as it has no access to them. They are not Open Source. You may be 
> able to use URW clones, depending on their licensing conditions.
> 
>  -- Brian D. Ripley, ripley at stats.ox.ac.uk
>  Professor of Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
>  University of Oxford, Tel: +44 1865 272861 (self)
>  1 South Parks Road, +44 1865 272866 (PA)
>  Oxford OX1 3TG, UK Fax: +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From gepr at tempusdictum.com  Mon Aug 29 23:21:23 2005
From: gepr at tempusdictum.com (glen e. p. ropella)
Date: Mon, 29 Aug 2005 14:21:23 -0700
Subject: [R] negative superscripts in axis labels
Message-ID: <43137C53.7070400@tempusdictum.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1

I apologize if this has been covered somewhere; but, I cannot find it.

The following results in a segmentation fault:
- -----------------------------------------------------------------
helvetica <- X11Font("-*-helvetica-*-*-*-*-*-*-*-*-*-*-*-*")
X11Fonts(helvetica=helvetica)
symbol <- X11Font("-*-symbol-%s-%s-*-*-%d-*-*-*-*-*-*-*")
X11Fonts(symbol=symbol)
X11(width=864, height=432,
~    fonts=c(X11Font(helvetica), X11Font(symbol)))

x <- seq(0,1,.0001)
y <- sin(x)
tics <- c(10^-5,10^-4,10^-3,10^-2,10^-1,10^-0)
lab0 <- expression(10^-0)
lab1 <- expression(10^-1)
lab2 <- expression(10^-2)
lab3 <- expression(10^-3)
lab4 <- expression(10^-4)
lab5 <- expression(10^-5)
plot(x,y,log="y",axes=FALSE)
axis(1)
axis(2,at=tics,labels=c(lab5,lab4,lab3,lab2,lab1,lab0))
- ------------------------------------------------------------------

However, if I remove the "-" symbols in the labels, e.g.
~    lab0 <- expression(10^0)
everything works just dandy.

Or, if I use par (family="sans") instead of setting the font family
using the X font string directly, the negative superscripts also work.
But, I have reasons for defining the font mappings manually.

Does anyone have any idea how I can get the negative superscripts to
work while using the explicitly defined font mappings?  Perhaps there's
a sprintf() function down in there somewhere that requires more C format
arguments? (causing the axis function to wrongly access memory when it
uses the font mapping)

In the meantime, even when I simply increase the size of the axis labels
using cex.axis (e.g. par(cex.axis=1.02)), the "-" is just dropped from
those labels.  So, if I use: lab1 <- expression(10^-1), I get 10^1 in
the output.  I've tried all manner of inserting phantom() calls and
those don't work.  It's like the negative is ignored when the font size
increases.

Thanks very much for any pointers.
- --glen
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.1 (GNU/Linux)
Comment: Using GnuPG with Thunderbird - http://enigmail.mozdev.org

iD8DBQFDE3xTZeB+vOTnLkoRAosIAJoCzCaOqZjkC+TjsdO7fttZojFJIQCfWItm
HafgrPzreKVoOBSB61+ykBE=
=JtVh
-----END PGP SIGNATURE-----



From whit at twinfieldscapital.com  Mon Aug 29 23:45:44 2005
From: whit at twinfieldscapital.com (Whit Armstrong)
Date: Mon, 29 Aug 2005 17:45:44 -0400
Subject: [R] Testing if all elements are equal in a vector/matrix
Message-ID: <726FC6DD09DE1046AF81B499D70C3BCE2C84AE@twinfields02.CORP.TWINFIELDSCAPITAL.COM>

or perhaps

length(unique(x))==1



-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Patrick Burns
Sent: Monday, August 29, 2005 5:22 PM
To: vincent.goulet at act.ulaval.ca
Cc: r-help at stat.math.ethz.ch
Subject: Re: [R] Testing if all elements are equal in a vector/matrix

How about

diff(range(x)) < tolerance

Patrick Burns
patrick at burns-stat.com
+44 (0)20 8525 0696
http://www.burns-stat.com
(home of S Poetry and "A Guide for the Unwilling S User")

Vincent Goulet wrote:

>Is there a canonical way to check if all elements of a vector or matrix

>are the same? Solutions below work, but look hackish to me.
>
>  
>
>>x <- rep(1, 10)
>>all(x == x[1])  # == operator does not provide for small differences
>>    
>>
>[1] TRUE
>  
>
>>isTRUE(all.equal(x, rep(x[1], length(x)))) # ugly
>>    
>>
>[1] TRUE
>
>Best,
>
>Vincent
>  
>

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From r.shengzhe at gmail.com  Mon Aug 29 23:45:41 2005
From: r.shengzhe at gmail.com (Shengzhe Wu)
Date: Mon, 29 Aug 2005 23:45:41 +0200
Subject: [R] Help: predict.qda
Message-ID: <ea57975b050829144536b9cf43@mail.gmail.com>

Hello,

I use the function qda (package MASS) to obtain a qda object like below.

x.qda = qda(x, group)

the group is a factor of two levels

and use this object to do the prediction below.

y.pred = predict(x.qda, y)

after that, I set different prediction priors like below, but the
results of prediction are totally the same as above using prior of
training set (use all.equal to compare).

y.pred1 = predict(x.qda,y, prior = c(1, 0))
y.pred2 = predict(x.qda,y, prior = c(0.5, 0.5))
y.pred3 = predict(x.qda,y, prior = c(0, 1))
y.pred4 = predict(x.qda,y, prior = c(0, 0))

the prediction prior of the last one should be wrong, but I still got
the same result.
And I tested the example of the function predict.qda by setting a
prediction prior.

predict(z, test, prior = c(0.1, 0.1, 0.8))

this result is exact the same as "predict(z, test)" which use training prior 
"c(0.3333333, 0.3333333, 0.3333333)"

If the prediction prior for qda does not work?

The version of R I use is 2.1.1, and this argument for lda works.

Thank you,
Shengzhe



From jfox at mcmaster.ca  Mon Aug 29 23:56:37 2005
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 29 Aug 2005 17:56:37 -0400
Subject: [R] Rcmdr extensions
In-Reply-To: <9964B749-6EED-4C06-BA22-E071CC97898C@tin.it>
Message-ID: <20050829215637.VWES1799.tomts40-srv.bellnexxia.net@JohnDesktop8300>

Dear Simone,

You'll find instructions for extending the R Commander in Section 4 of the
paper at <http://socserv.socsci.mcmaster.ca/jfox/Papers/R-commander.pdf>. In
most instances, you should cause commands to be executed and printed in the
Script window and output to appear in the Output window by using the
function doItAndPrint().

I hope this helps,
 John

--------------------------------
John Fox
Department of Sociology
McMaster University
Hamilton, Ontario
Canada L8S 4M4
905-525-9140x23604
http://socserv.mcmaster.ca/jfox 
-------------------------------- 

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch 
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Simone 
> Gabbriellini
> Sent: Monday, August 29, 2005 9:48 AM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Rcmdr extensions
> 
> Dear List,
> 
> I am trying to extend Rcmdr with some functions usefult to my 
> study... I have addedd succesfully a menu and some submenu to 
> the GUI, and I have placed a file .R in the /etc folder... I 
> am able to call functions on that file, but I cannot see the 
> results: how can I tell Rcmdr to write the output in the output box?
> 
> Second question: how can I refer to the actually selected 
> Dataset in my .R functions' file?
> 
> Thank you,
> Simone Gabbriellini
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html



From ferran.carrascosa at gmail.com  Tue Aug 30 00:00:32 2005
From: ferran.carrascosa at gmail.com (Ferran Carrascosa)
Date: Mon, 29 Aug 2005 23:00:32 +0100
Subject: [R] memory
Message-ID: <fcd289fd0508291500496828e5@mail.gmail.com>

Hi,

I have a matrix with 700.000 x 10.000 cells with floating point data.
I would like to work with the entire table but I have a lot of memory
problems. I have read the ?memory
I work with Win 2000 with R2.1.0

The only solution that I have applied is:
> memory.limit(size=2048)

But now my problems are:
- I need to work with more than 2 Gb. How I can exceed this limit?
- When apply some algorithms, the maximum cells in one object 2*10^9
(aprox.) is reached.

Please could you send me some advises/strategies about the work with
large amount of data in R?

R have a way to work with less memory needs?

Thanks in advance,
-- 
Ferran Carrascosa



From p.murrell at auckland.ac.nz  Tue Aug 30 00:04:11 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 30 Aug 2005 10:04:11 +1200
Subject: [R] pdf font embedding --- again
References: <200508221537.j7MFbsa0000978@hypatia.math.ethz.ch>	<Pine.LNX.4.61.0508221700100.17196@gannet.stats>
	<200508222038.j7MKceUi031412@hypatia.math.ethz.ch>
	<43137EE1.6000307@stat.auckland.ac.nz>
Message-ID: <4313865B.4010508@stat.auckland.ac.nz>

Hi


Paul Murrell wrote:
> Hi
> 
> I think there are two problems:
> 
> (i)  You are specifying the font incorrectly.  Try ...
> 
> # You might need to specify full paths to these
> afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", "lbms.afm");
> # Set up the mapping for "lucida" font family
> postscriptFonts(lucida=postscriptFont("Lucida", metrics=afmfiles))
> # Specify that the "lucida" font is to be used
> postscript(file="test.ps", family="lucida");


Thanks to Brian Ripley for pointing out that that should be ...

postscript(file="test.ps", fonts="lucida");


> l<- 40:80;
> plot(l,l,pch=l);
> dev.off();
> 
> Should work for pdf() too.
> 
> This should put a reference to the appropriate font in the PostScript or 
>  PDF file that R creates.
> 
> (ii)  R does not embed font information.  But you can, for example, use 
> ghostscript to do it, as long as you tell ghostscript about the font 
> too.  You might have to set up a file 'FontMap' which looks something 
> like ...
> 
> /Lucida   (PATH_TO/lb___.pfb);
> 
> ... (assuming that lb___.pfb is the name of the .pfb file for the Lucida 
> font).  Then try something like (NOTE that you have to specify 
> GS_FONTPATH to tell ghostscript where your FontMap file is) ...
> 
> GS_FONTPATH=PATH_TO_FontMap gs -dBATCH -dNOPAUSE -sDEVICE=pdfwrite 
> -sPAPERSIZE=a4 -sOutputFile=testembed.pdf test.pdf
> 
> This should give you a file with the font info embedded and then you 
> should be able to include that in a LaTeX document.
> 
> Paul
> 
> p.s. Thanks for the segfault report.  I will look at why that is happening.
> 
> 
> ivo_welch-rstat8303 at mailblocks.com wrote:
> 
>> Thank you---as always.
>>
>> still, I remain font-desparate.
>>
>> I would love to use the fonts from my book, but [a] I cannot figure 
>> out how to do this yet even in the R postscript device; and [b] I am 
>> using the R pdf device, not the postscript device.  I guess if I can 
>> solve [a], then I can rewrite all my graphics creations now into the 
>> postscript device, and replace the dev.off() with something that 
>> follows it with ps2pdf.  The following attempt, however, does not work:
>>
>>    afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", 
>> "lbms.afm");
>>   Lucida <- postscriptFont("Lucida", metrics=afmfiles);
>>   postscript(file="test.ps", family=Lucida);
>>   l<- 40:80;
>>   plot(l,l,pch=l);
>>   dev.off();
>>
>> By the way, if I try  " postscript(family=afmfiles);" then I do not 
>> get an R error, but R 2.1.0 segfaults, which is probably not 
>> desirable.  This occurs even if there is no .afm file in the current 
>> directory.
>>
>>
>> Can I make a suggestion to the R team?    It would be nice if I could 
>> specify a pdf() device parameter that says "choose font settings to 
>> embed all fonts" (i.e., do not use fonts that cannot be embedded, 
>> either).  Something that guarantees me that I get a figure that I can 
>> give to someone that is fully specified.   Right now, accomplishing 
>> this is not easy to figure out, and perhaps not even possible.  Yes, 
>> in the list of font families that R recognizes are some fonts that do 
>> not seem among the 13 standard fonts (such as URWbookman).  moreover, 
>> if I choose it as my pdf font family, it is smart enough to use a 
>> different symbol file ('StandardSymL'), which I hope is also open and 
>> not adobe.  If so, they could be used in principle.  How do I get R to 
>> embed URWbookman?  ZapfDingbats always seems to be included, so I hope 
>> this is open and embeddable.
>>
>> more help would be highly appreciated.
>>
>> Regards,
>>
>> /iaw
>> ---
>> ivo welch
>>
>> -----Original Message-----
>> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>> To: ivo_welch-rstat8303 at mailblocks.com
>> Cc: r-help at stat.math.ethz.ch
>> Sent: Mon, 22 Aug 2005 17:07:14 +0100 (BST)
>> Subject: Re: [R] pdf font embedding --- again
>>
>> On Mon, 22 Aug 2005 ivo_welch-rstat8303 at mailblocks.com wrote:
>>
>>  >
>>   > dear R wizards--- I would like to do some book-on-demand printing 
>> at a
>>  > popular printer named lulu, but lulu requires inclusion even of the
>>  > basic postscript fonts. Interestingly, my book itself does not need
>>   > the 14 base acrobat fonts, only the embedded R figures do. Of course,
>>  > I really would like to get pdftex to embed the fonts, but how to do
>>  > this is not obvious either. [This method seems to be what the R help
>>   > page is indicating... The software including the PostScript plot file
>>  > should either embed the font outlines (usually from '.pfb' or '.pfa'
>>  > files) or use DSC comments to instruct the print spooler to do so.)
>>
>>  Why not use the fonts your book does use in the figures? (That's how
>>  my books are done.)
>>
>>   > So, I would really, really like to embed the necessary fonts with 
>> the R
>>  > figures. I first reread the discussion in this mailing list about
>>  > (eps) font embedding earlier this year. This was ultimately not very
>>   > helpful. First, I do not know how to instruct my embedding program to
>>  > include the fonts that R figures want. Second, I already start with
>>  > the pdf device, so distilling eps files is not a good option--and it
>>  > would seem a bit crazy to first use the wrong output device
>>  > (postscript), then ship my files over to a windows machine somewhere
>>   > that has distiller installed, run distiller by hand, then ftp them 
>> back
>>  > to my linux machine---just for getting the fonts embedded.
>>  >
>>  > Is it impossible to get R to embed the necessary fonts in its pdf
>>  > output?
>>
>>   Yes, as it has no access to them. They are not Open Source. You may 
>> be able to use URW clones, depending on their licensing conditions.
>>
>>  -- Brian D. Ripley, ripley at stats.ox.ac.uk
>>  Professor of Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
>>  University of Oxford, Tel: +44 1865 272861 (self)
>>  1 South Parks Road, +44 1865 272866 (PA)
>>  Oxford OX1 3TG, UK Fax: +44 1865 272595
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! 
>> http://www.R-project.org/posting-guide.html
> 
> 
> 


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From ivo_welch-rstat8303 at mailblocks.com  Tue Aug 30 01:40:25 2005
From: ivo_welch-rstat8303 at mailblocks.com (ivo_welch-rstat8303@mailblocks.com)
Date: Mon, 29 Aug 2005 16:40:25 -0700
Subject: [R] pdf font embedding --- again
In-Reply-To: <4313865B.4010508@stat.auckland.ac.nz>
References: <200508221537.j7MFbsa0000978@hypatia.math.ethz.ch>	<Pine.LNX.4.61.0508221700100.17196@gannet.stats>
	<200508222038.j7MKceUi031412@hypatia.math.ethz.ch>
	<43137EE1.6000307@stat.auckland.ac.nz>
	<4313865B.4010508@stat.auckland.ac.nz>
Message-ID: <200508292340.j7TNeShJ030640@hypatia.math.ethz.ch>


Dear Paul:

Thank you for responding.  I had thought I had imposed too much, and 
did not want to be a bother any more.  In any case, this does not seem 
to work for me.

> afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", "lbms.afm")
> postscriptFonts(lucida=postscriptFont("Lucida", metrics=afmfiles))
> postscriptFonts();
   # snipped a lot of fonts
$lucida
$lucida$family
[1] "Lucida"

$lucida$metrics
[1] "lbr.afm"  "lbd.afm"  "lbi.afm"  "lbdi.afm" "lbms.afm"

$lucida$encoding
[1] "default"

> > postscript(file="test.ps", fonts="Lucida");
Error in postscript(file = "test.ps", fonts = "Lucida") :
        Failed to initialise additional PostScript fonts
In addition: Warning message:
Font encoding not found in PostScript font database
>

to make sure I have all the files accessible, I symbolically linked 
them into the current directory, too:

$ file *
lbd.afm:  symbolic link to 
`/usr/share/texmf/fonts/afm/yandy/lubright/lbd.afm'
lbd.pfb:  symbolic link to 
`/usr/local/share/texmf/fonts/type1/yandy/lbd.pfb'
lbdi.afm: symbolic link to 
`/usr/share/texmf/fonts/afm/yandy/lubright/lbdi.afm'
lbdi.pfb: symbolic link to 
`/usr/local/share/texmf/fonts/type1/yandy/lbdi.pfb'
lbi.afm:  symbolic link to 
`/usr/share/texmf/fonts/afm/yandy/lubright/lbi.afm'
lbi.pfb:  symbolic link to 
`/usr/local/share/texmf/fonts/type1/yandy/lbi.pfb'
lbms.afm: symbolic link to 
`/usr/share/texmf/fonts/afm/yandy/lumath/lbms.afm'
lbms.pfb: symbolic link to 
`/usr/local/share/texmf/fonts/type1/yandy/lbms.pfb'
lbr.afm:  symbolic link to 
`/usr/share/texmf/fonts/afm/yandy/lubright/lbr.afm'
lbr.pfb:  symbolic link to 
`/usr/local/share/texmf/fonts/type1/yandy/lbr.pfb'

the links are live, and the files are what they pretend to be.  any 
more suggestions would be very highly appreciated.

sincerely,

/iaw
---
ivo welch


-----Original Message-----
From: Paul Murrell <p.murrell at auckland.ac.nz>
To: Paul Murrell <paul at stat.auckland.ac.nz>
Cc: ivo_welch-rstat8303 at mailblocks.com; ripley at stats.ox.ac.uk; 
r-help at stat.math.ethz.ch
Sent: Tue, 30 Aug 2005 10:04:11 +1200
Subject: Re: [R] pdf font embedding --- again

Hi

 Paul Murrell wrote:
 > Hi
 > > I think there are two problems:
 > > (i) You are specifying the font incorrectly. Try ...
 > > # You might need to specify full paths to these
  > afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", 
"lbms.afm");
 > # Set up the mapping for "lucida" font family
 > postscriptFonts(lucida=postscriptFont("Lucida", metrics=afmfiles))
 > # Specify that the "lucida" font is to be used
 > postscript(file="test.ps", family="lucida");

 Thanks to Brian Ripley for pointing out that that should be ...

 postscript(file="test.ps", fonts="lucida");

 > l<- 40:80;
 > plot(l,l,pch=l);
 > dev.off();
 > > Should work for pdf() too.
  > > This should put a reference to the appropriate font in the 
PostScript or > PDF file that R creates.
  > > (ii) R does not embed font information. But you can, for example, 
use > ghostscript to do it, as long as you tell ghostscript about the 
font > too. You might have to set up a file 'FontMap' which looks 
something > like ...
 > > /Lucida (PATH_TO/lb___.pfb);
  > > ... (assuming that lb___.pfb is the name of the .pfb file for the 
Lucida > font). Then try something like (NOTE that you have to specify 
> GS_FONTPATH to tell ghostscript where your FontMap file is) ...
  > > GS_FONTPATH=PATH_TO_FontMap gs -dBATCH -dNOPAUSE -sDEVICE=pdfwrite 
> -sPAPERSIZE=a4 -sOutputFile=testembed.pdf test.pdf
  > > This should give you a file with the font info embedded and then 
you > should be able to include that in a LaTeX document.
 > > Paul
  > > p.s. Thanks for the segfault report. I will look at why that is 
happening.
 > > > ivo_welch-rstat8303 at mailblocks.com wrote:
 > >> Thank you---as always.
 >>
 >> still, I remain font-desparate.
 >>
  >> I would love to use the fonts from my book, but [a] I cannot figure 
 >> out how to do this yet even in the R postscript device; and [b] I am 
 >> using the R pdf device, not the postscript device. I guess if I can 
 >> solve [a], then I can rewrite all my graphics creations now into the 
 >> postscript device, and replace the dev.off() with something that >> 
follows it with ps2pdf. The following attempt, however, does not work:
 >>
  >> afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", >> 
"lbms.afm");
 >> Lucida <- postscriptFont("Lucida", metrics=afmfiles);
 >> postscript(file="test.ps", family=Lucida);
 >> l<- 40:80;
 >> plot(l,l,pch=l);
 >> dev.off();
 >>
  >> By the way, if I try " postscript(family=afmfiles);" then I do not 
 >> get an R error, but R 2.1.0 segfaults, which is probably not >> 
desirable. This occurs even if there is no .afm file in the current >> 
directory.
 >>
 >>
  >> Can I make a suggestion to the R team? It would be nice if I could 
 >> specify a pdf() device parameter that says "choose font settings to 
 >> embed all fonts" (i.e., do not use fonts that cannot be embedded, >> 
either). Something that guarantees me that I get a figure that I can >> 
give to someone that is fully specified. Right now, accomplishing >> 
this is not easy to figure out, and perhaps not even possible. Yes, >> 
in the list of font families that R recognizes are some fonts that do 
 >> not seem among the 13 standard fonts (such as URWbookman). moreover, 
 >> if I choose it as my pdf font family, it is smart enough to use a >> 
different symbol file ('StandardSymL'), which I hope is also open and 
 >> not adobe. If so, they could be used in principle. How do I get R to 
 >> embed URWbookman? ZapfDingbats always seems to be included, so I 
hope >> this is open and embeddable.
 >>
 >> more help would be highly appreciated.
 >>
 >> Regards,
 >>
 >> /iaw
 >> ---
 >> ivo welch
 >>
 >> -----Original Message-----
 >> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
 >> To: ivo_welch-rstat8303 at mailblocks.com
 >> Cc: r-help at stat.math.ethz.ch
 >> Sent: Mon, 22 Aug 2005 17:07:14 +0100 (BST)
 >> Subject: Re: [R] pdf font embedding --- again
 >>
 >> On Mon, 22 Aug 2005 ivo_welch-rstat8303 at mailblocks.com wrote:
 >>
 >> >
  >> > dear R wizards--- I would like to do some book-on-demand printing 
>> at a
  >> > popular printer named lulu, but lulu requires inclusion even of 
the
  >> > basic postscript fonts. Interestingly, my book itself does not 
need
  >> > the 14 base acrobat fonts, only the embedded R figures do. Of 
course,
  >> > I really would like to get pdftex to embed the fonts, but how to 
do
  >> > this is not obvious either. [This method seems to be what the R 
help
  >> > page is indicating... The software including the PostScript plot 
file
  >> > should either embed the font outlines (usually from '.pfb' or 
'.pfa'
  >> > files) or use DSC comments to instruct the print spooler to do 
so.)
 >>
  >> Why not use the fonts your book does use in the figures? (That's 
how
 >> my books are done.)
 >>
  >> > So, I would really, really like to embed the necessary fonts with 
>> the R
 >> > figures. I first reread the discussion in this mailing list about
  >> > (eps) font embedding earlier this year. This was ultimately not 
very
  >> > helpful. First, I do not know how to instruct my embedding 
program to
  >> > include the fonts that R figures want. Second, I already start 
with
  >> > the pdf device, so distilling eps files is not a good option--and 
it
 >> > would seem a bit crazy to first use the wrong output device
  >> > (postscript), then ship my files over to a windows machine 
somewhere
  >> > that has distiller installed, run distiller by hand, then ftp 
them >> back
 >> > to my linux machine---just for getting the fonts embedded.
 >> >
 >> > Is it impossible to get R to embed the necessary fonts in its pdf
 >> > output?
 >>
  >> Yes, as it has no access to them. They are not Open Source. You may 
>> be able to use URW clones, depending on their licensing conditions.
 >>
 >> -- Brian D. Ripley, ripley at stats.ox.ac.uk
 >> Professor of Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
 >> University of Oxford, Tel: +44 1865 272861 (self)
 >> 1 South Parks Road, +44 1865 272866 (PA)
 >> Oxford OX1 3TG, UK Fax: +44 1865 272595
 >>
 >> ______________________________________________
 >> R-help at stat.math.ethz.ch mailing list
 >> https://stat.ethz.ch/mailman/listinfo/r-help
  >> PLEASE do read the posting guide! >> 
http://www.R-project.org/posting-guide.html
 > > >
 -- Dr Paul Murrell
 Department of Statistics
 The University of Auckland
 Private Bag 92019
 Auckland
 New Zealand
 64 9 3737599 x85392
 paul at stat.auckland.ac.nz
 http://www.stat.auckland.ac.nz/~paul/



From ivo_welch-rstat8303 at mailblocks.com  Tue Aug 30 01:43:47 2005
From: ivo_welch-rstat8303 at mailblocks.com (ivo_welch-rstat8303@mailblocks.com)
Date: Mon, 29 Aug 2005 16:43:47 -0700
Subject: [R] pdf font embedding --- again
In-Reply-To: <4313865B.4010508@stat.auckland.ac.nz>
References: <200508221537.j7MFbsa0000978@hypatia.math.ethz.ch>	<Pine.LNX.4.61.0508221700100.17196@gannet.stats>
	<200508222038.j7MKceUi031412@hypatia.math.ethz.ch>
	<43137EE1.6000307@stat.auckland.ac.nz>
	<4313865B.4010508@stat.auckland.ac.nz>
Message-ID: <200508292343.j7TNhn0c031607@hypatia.math.ethz.ch>



Ooops.  hit the button too soon.  I have tried as arguments variation 
of the fonts and family arguments to postscript, such as getting the 
case right (i.e., lucida rather than Lucida).  Alas

  > postscript(file="test.ps", fonts="lucida");
  *** glibc detected *** free(): invalid pointer: 0x0000000000f7dfb8 ***

this is under R 2.1.1, 2005-06-20, built under gentoo from scratch.

so, the problem is probably now internal, not the commands.  I guess I 
will now investigate glibc in a little more detail...

Regards, /iaw

---
ivo welch
professor of finance and economics
brown / nber / yale


-----Original Message-----
From: Paul Murrell <p.murrell at auckland.ac.nz>
To: Paul Murrell <paul at stat.auckland.ac.nz>
Cc: ivo_welch-rstat8303 at mailblocks.com; ripley at stats.ox.ac.uk; 
r-help at stat.math.ethz.ch
Sent: Tue, 30 Aug 2005 10:04:11 +1200
Subject: Re: [R] pdf font embedding --- again

Hi

 Paul Murrell wrote:
 > Hi
 > > I think there are two problems:
 > > (i) You are specifying the font incorrectly. Try ...
 > > # You might need to specify full paths to these
  > afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", 
"lbms.afm");
 > # Set up the mapping for "lucida" font family
 > postscriptFonts(lucida=postscriptFont("Lucida", metrics=afmfiles))
 > # Specify that the "lucida" font is to be used
 > postscript(file="test.ps", family="lucida");

 Thanks to Brian Ripley for pointing out that that should be ...

 postscript(file="test.ps", fonts="lucida");

 > l<- 40:80;
 > plot(l,l,pch=l);
 > dev.off();
 > > Should work for pdf() too.
  > > This should put a reference to the appropriate font in the 
PostScript or > PDF file that R creates.
  > > (ii) R does not embed font information. But you can, for example, 
use > ghostscript to do it, as long as you tell ghostscript about the 
font > too. You might have to set up a file 'FontMap' which looks 
something > like ...
 > > /Lucida (PATH_TO/lb___.pfb);
  > > ... (assuming that lb___.pfb is the name of the .pfb file for the 
Lucida > font). Then try something like (NOTE that you have to specify 
> GS_FONTPATH to tell ghostscript where your FontMap file is) ...
  > > GS_FONTPATH=PATH_TO_FontMap gs -dBATCH -dNOPAUSE -sDEVICE=pdfwrite 
> -sPAPERSIZE=a4 -sOutputFile=testembed.pdf test.pdf
  > > This should give you a file with the font info embedded and then 
you > should be able to include that in a LaTeX document.
 > > Paul
  > > p.s. Thanks for the segfault report. I will look at why that is 
happening.
 > > > ivo_welch-rstat8303 at mailblocks.com wrote:
 > >> Thank you---as always.
 >>
 >> still, I remain font-desparate.
 >>
  >> I would love to use the fonts from my book, but [a] I cannot figure 
 >> out how to do this yet even in the R postscript device; and [b] I am 
 >> using the R pdf device, not the postscript device. I guess if I can 
 >> solve [a], then I can rewrite all my graphics creations now into the 
 >> postscript device, and replace the dev.off() with something that >> 
follows it with ps2pdf. The following attempt, however, does not work:
 >>
  >> afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", >> 
"lbms.afm");
 >> Lucida <- postscriptFont("Lucida", metrics=afmfiles);
 >> postscript(file="test.ps", family=Lucida);
 >> l<- 40:80;
 >> plot(l,l,pch=l);
 >> dev.off();
 >>
  >> By the way, if I try " postscript(family=afmfiles);" then I do not 
 >> get an R error, but R 2.1.0 segfaults, which is probably not >> 
desirable. This occurs even if there is no .afm file in the current >> 
directory.
 >>
 >>
  >> Can I make a suggestion to the R team? It would be nice if I could 
 >> specify a pdf() device parameter that says "choose font settings to 
 >> embed all fonts" (i.e., do not use fonts that cannot be embedded, >> 
either). Something that guarantees me that I get a figure that I can >> 
give to someone that is fully specified. Right now, accomplishing >> 
this is not easy to figure out, and perhaps not even possible. Yes, >> 
in the list of font families that R recognizes are some fonts that do 
 >> not seem among the 13 standard fonts (such as URWbookman). moreover, 
 >> if I choose it as my pdf font family, it is smart enough to use a >> 
different symbol file ('StandardSymL'), which I hope is also open and 
 >> not adobe. If so, they could be used in principle. How do I get R to 
 >> embed URWbookman? ZapfDingbats always seems to be included, so I 
hope >> this is open and embeddable.
 >>
 >> more help would be highly appreciated.
 >>
 >> Regards,
 >>
 >> /iaw
 >> ---
 >> ivo welch
 >>
 >> -----Original Message-----
 >> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
 >> To: ivo_welch-rstat8303 at mailblocks.com
 >> Cc: r-help at stat.math.ethz.ch
 >> Sent: Mon, 22 Aug 2005 17:07:14 +0100 (BST)
 >> Subject: Re: [R] pdf font embedding --- again
 >>
 >> On Mon, 22 Aug 2005 ivo_welch-rstat8303 at mailblocks.com wrote:
 >>
 >> >
  >> > dear R wizards--- I would like to do some book-on-demand printing 
>> at a
  >> > popular printer named lulu, but lulu requires inclusion even of 
the
  >> > basic postscript fonts. Interestingly, my book itself does not 
need
  >> > the 14 base acrobat fonts, only the embedded R figures do. Of 
course,
  >> > I really would like to get pdftex to embed the fonts, but how to 
do
  >> > this is not obvious either. [This method seems to be what the R 
help
  >> > page is indicating... The software including the PostScript plot 
file
  >> > should either embed the font outlines (usually from '.pfb' or 
'.pfa'
  >> > files) or use DSC comments to instruct the print spooler to do 
so.)
 >>
  >> Why not use the fonts your book does use in the figures? (That's 
how
 >> my books are done.)
 >>
  >> > So, I would really, really like to embed the necessary fonts with 
>> the R
 >> > figures. I first reread the discussion in this mailing list about
  >> > (eps) font embedding earlier this year. This was ultimately not 
very
  >> > helpful. First, I do not know how to instruct my embedding 
program to
  >> > include the fonts that R figures want. Second, I already start 
with
  >> > the pdf device, so distilling eps files is not a good option--and 
it
 >> > would seem a bit crazy to first use the wrong output device
  >> > (postscript), then ship my files over to a windows machine 
somewhere
  >> > that has distiller installed, run distiller by hand, then ftp 
them >> back
 >> > to my linux machine---just for getting the fonts embedded.
 >> >
 >> > Is it impossible to get R to embed the necessary fonts in its pdf
 >> > output?
 >>
  >> Yes, as it has no access to them. They are not Open Source. You may 
>> be able to use URW clones, depending on their licensing conditions.
 >>
 >> -- Brian D. Ripley, ripley at stats.ox.ac.uk
 >> Professor of Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
 >> University of Oxford, Tel: +44 1865 272861 (self)
 >> 1 South Parks Road, +44 1865 272866 (PA)
 >> Oxford OX1 3TG, UK Fax: +44 1865 272595
 >>
 >> ______________________________________________
 >> R-help at stat.math.ethz.ch mailing list
 >> https://stat.ethz.ch/mailman/listinfo/r-help
  >> PLEASE do read the posting guide! >> 
http://www.R-project.org/posting-guide.html
 > > >
 -- Dr Paul Murrell
 Department of Statistics
 The University of Auckland
 Private Bag 92019
 Auckland
 New Zealand
 64 9 3737599 x85392
 paul at stat.auckland.ac.nz
 http://www.stat.auckland.ac.nz/~paul/



From p.murrell at auckland.ac.nz  Tue Aug 30 01:49:38 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 30 Aug 2005 11:49:38 +1200
Subject: [R] pdf font embedding --- again
References: <200508221537.j7MFbsa0000978@hypatia.math.ethz.ch>	<Pine.LNX.4.61.0508221700100.17196@gannet.stats>
	<200508222038.j7MKceUi031412@hypatia.math.ethz.ch>
	<43137EE1.6000307@stat.auckland.ac.nz>
	<4313865B.4010508@stat.auckland.ac.nz>
	<20050829234348.D2E94347FF@smtpc.itss.auckland.ac.nz>
Message-ID: <43139F12.4070205@stat.auckland.ac.nz>

Hi


ivo_welch-rstat8303 at mailblocks.com wrote:
> 
> 
> Ooops.  hit the button too soon.  I have tried as arguments variation of 
> the fonts and family arguments to postscript, such as getting the case 
> right (i.e., lucida rather than Lucida).  Alas
> 
>  > postscript(file="test.ps", fonts="lucida");
>  *** glibc detected *** free(): invalid pointer: 0x0000000000f7dfb8 ***
> 
> this is under R 2.1.1, 2005-06-20, built under gentoo from scratch.
> 
> so, the problem is probably now internal, not the commands.  I guess I 
> will now investigate glibc in a little more detail...


You might just be tickling the segfault you reported earlier (which 
appears to happen [sometimes] when R cannot find the AFM files).
Try ...

afmfiles <- c("/usr/share/texmf/fonts/afm/yandy/lubright/lbr.afm",
               "/usr/share/texmf/fonts/afm/yandy/lubright/lbd.afm",
               "/usr/share/texmf/fonts/afm/yandy/lubright/lbi.afm", 

               "/usr/share/texmf/fonts/afm/yandy/lubright/lbdi.afm",
               "/usr/share/texmf/fonts/afm/yandy/lubright/lbms.afm")

Paul


> -----Original Message-----
> From: Paul Murrell <p.murrell at auckland.ac.nz>
> To: Paul Murrell <paul at stat.auckland.ac.nz>
> Cc: ivo_welch-rstat8303 at mailblocks.com; ripley at stats.ox.ac.uk; 
> r-help at stat.math.ethz.ch
> Sent: Tue, 30 Aug 2005 10:04:11 +1200
> Subject: Re: [R] pdf font embedding --- again
> 
> Hi
> 
> Paul Murrell wrote:
>  > Hi
>  > > I think there are two problems:
>  > > (i) You are specifying the font incorrectly. Try ...
>  > > # You might need to specify full paths to these
>  > afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", "lbms.afm");
>  > # Set up the mapping for "lucida" font family
>  > postscriptFonts(lucida=postscriptFont("Lucida", metrics=afmfiles))
>  > # Specify that the "lucida" font is to be used
>  > postscript(file="test.ps", family="lucida");
> 
> Thanks to Brian Ripley for pointing out that that should be ...
> 
> postscript(file="test.ps", fonts="lucida");
> 
>  > l<- 40:80;
>  > plot(l,l,pch=l);
>  > dev.off();
>  > > Should work for pdf() too.
>  > > This should put a reference to the appropriate font in the 
> PostScript or > PDF file that R creates.
>  > > (ii) R does not embed font information. But you can, for example, 
> use > ghostscript to do it, as long as you tell ghostscript about the 
> font > too. You might have to set up a file 'FontMap' which looks 
> something > like ...
>  > > /Lucida (PATH_TO/lb___.pfb);
>  > > ... (assuming that lb___.pfb is the name of the .pfb file for the 
> Lucida > font). Then try something like (NOTE that you have to specify
> 
>> GS_FONTPATH to tell ghostscript where your FontMap file is) ...
> 
>  > > GS_FONTPATH=PATH_TO_FontMap gs -dBATCH -dNOPAUSE -sDEVICE=pdfwrite
> 
>> -sPAPERSIZE=a4 -sOutputFile=testembed.pdf test.pdf
> 
>  > > This should give you a file with the font info embedded and then 
> you > should be able to include that in a LaTeX document.
>  > > Paul
>  > > p.s. Thanks for the segfault report. I will look at why that is 
> happening.
>  > > > ivo_welch-rstat8303 at mailblocks.com wrote:
>  > >> Thank you---as always.
>  >>
>  >> still, I remain font-desparate.
>  >>
>  >> I would love to use the fonts from my book, but [a] I cannot figure 
>  >> out how to do this yet even in the R postscript device; and [b] I am 
>  >> using the R pdf device, not the postscript device. I guess if I can 
>  >> solve [a], then I can rewrite all my graphics creations now into the 
>  >> postscript device, and replace the dev.off() with something that >> 
> follows it with ps2pdf. The following attempt, however, does not work:
>  >>
>  >> afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", >> 
> "lbms.afm");
>  >> Lucida <- postscriptFont("Lucida", metrics=afmfiles);
>  >> postscript(file="test.ps", family=Lucida);
>  >> l<- 40:80;
>  >> plot(l,l,pch=l);
>  >> dev.off();
>  >>
>  >> By the way, if I try " postscript(family=afmfiles);" then I do not 
>  >> get an R error, but R 2.1.0 segfaults, which is probably not >> 
> desirable. This occurs even if there is no .afm file in the current >> 
> directory.
>  >>
>  >>
>  >> Can I make a suggestion to the R team? It would be nice if I could 
>  >> specify a pdf() device parameter that says "choose font settings to 
>  >> embed all fonts" (i.e., do not use fonts that cannot be embedded, >> 
> either). Something that guarantees me that I get a figure that I can >> 
> give to someone that is fully specified. Right now, accomplishing >> 
> this is not easy to figure out, and perhaps not even possible. Yes, >> 
> in the list of font families that R recognizes are some fonts that do >> 
> not seem among the 13 standard fonts (such as URWbookman). moreover, >> 
> if I choose it as my pdf font family, it is smart enough to use a >> 
> different symbol file ('StandardSymL'), which I hope is also open and >> 
> not adobe. If so, they could be used in principle. How do I get R to >> 
> embed URWbookman? ZapfDingbats always seems to be included, so I hope >> 
> this is open and embeddable.
>  >>
>  >> more help would be highly appreciated.
>  >>
>  >> Regards,
>  >>
>  >> /iaw
>  >> ---
>  >> ivo welch
>  >>
>  >> -----Original Message-----
>  >> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>  >> To: ivo_welch-rstat8303 at mailblocks.com
>  >> Cc: r-help at stat.math.ethz.ch
>  >> Sent: Mon, 22 Aug 2005 17:07:14 +0100 (BST)
>  >> Subject: Re: [R] pdf font embedding --- again
>  >>
>  >> On Mon, 22 Aug 2005 ivo_welch-rstat8303 at mailblocks.com wrote:
>  >>
>  >> >
>  >> > dear R wizards--- I would like to do some book-on-demand printing
> 
>>> at a
>>
>  >> > popular printer named lulu, but lulu requires inclusion even of the
>  >> > basic postscript fonts. Interestingly, my book itself does not need
>  >> > the 14 base acrobat fonts, only the embedded R figures do. Of course,
>  >> > I really would like to get pdftex to embed the fonts, but how to do
>  >> > this is not obvious either. [This method seems to be what the R help
>  >> > page is indicating... The software including the PostScript plot file
>  >> > should either embed the font outlines (usually from '.pfb' or '.pfa'
>  >> > files) or use DSC comments to instruct the print spooler to do so.)
>  >>
>  >> Why not use the fonts your book does use in the figures? (That's how
>  >> my books are done.)
>  >>
>  >> > So, I would really, really like to embed the necessary fonts with
> 
>>> the R
>>
>  >> > figures. I first reread the discussion in this mailing list about
>  >> > (eps) font embedding earlier this year. This was ultimately not very
>  >> > helpful. First, I do not know how to instruct my embedding program to
>  >> > include the fonts that R figures want. Second, I already start with
>  >> > the pdf device, so distilling eps files is not a good option--and it
>  >> > would seem a bit crazy to first use the wrong output device
>  >> > (postscript), then ship my files over to a windows machine somewhere
>  >> > that has distiller installed, run distiller by hand, then ftp them 
>  >> back
>  >> > to my linux machine---just for getting the fonts embedded.
>  >> >
>  >> > Is it impossible to get R to embed the necessary fonts in its pdf
>  >> > output?
>  >>
>  >> Yes, as it has no access to them. They are not Open Source. You may
> 
>>> be able to use URW clones, depending on their licensing conditions.
>>
>  >>
>  >> -- Brian D. Ripley, ripley at stats.ox.ac.uk
>  >> Professor of Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
>  >> University of Oxford, Tel: +44 1865 272861 (self)
>  >> 1 South Parks Road, +44 1865 272866 (PA)
>  >> Oxford OX1 3TG, UK Fax: +44 1865 272595
>  >>
>  >> ______________________________________________
>  >> R-help at stat.math.ethz.ch mailing list
>  >> https://stat.ethz.ch/mailman/listinfo/r-help
>  >> PLEASE do read the posting guide! >> 
> http://www.R-project.org/posting-guide.html
>  > > >
> -- Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
> 
>  


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From ivo_welch-rstat8303 at mailblocks.com  Tue Aug 30 02:09:10 2005
From: ivo_welch-rstat8303 at mailblocks.com (ivo_welch-rstat8303@mailblocks.com)
Date: Mon, 29 Aug 2005 17:09:10 -0700
Subject: [R] pdf font embedding --- again
In-Reply-To: <43139F12.4070205@stat.auckland.ac.nz>
References: <200508221537.j7MFbsa0000978@hypatia.math.ethz.ch>	<Pine.LNX.4.61.0508221700100.17196@gannet.stats>
	<200508222038.j7MKceUi031412@hypatia.math.ethz.ch>
	<43137EE1.6000307@stat.auckland.ac.nz>
	<4313865B.4010508@stat.auckland.ac.nz>
	<20050829234348.D2E94347FF@smtpc.itss.auckland.ac.nz>
	<43139F12.4070205@stat.auckland.ac.nz>
Message-ID: <200508300009.j7U09BvA005502@hypatia.math.ethz.ch>


Hi Paul:

You are correct.  it was the same little bug I hit on.  Specifying the 
full (not the symlinked) afm filenames lets me run the code.  No R 
error.  yoohoo!

alas, the files don't seem to come out right.  I can use these commands 
on the R postscript() and on the R pdf() device.  they have an effect 
on both.  (that is, if I grep for lucida in the resulting ps or pdf 
file, respectively, the word lucida appears in both files).  alas, 
usage is another story:

$ pdffonts tonativepdf.pdf
name                                 type         emb sub uni object ID
------------------------------------ ------------ --- --- --- ---------
ZapfDingbats                         Type 1       no  no  no       5  0
Helvetica                            Type 1       no  no  no      10  0
Helvetica-Bold                       Type 1       no  no  no      11  0
Helvetica-Oblique                    Type 1       no  no  no      12  0
Helvetica-BoldOblique                Type 1       no  no  no      13  0
Symbol                               Type 1       no  no  no      14  0
LucidaBright                         Type 1       no  no  no      15  0
LucidaBright-Demi                    Type 1       no  no  no      16  0
LucidaBright-Italic                  Type 1       no  no  no      17  0
LucidaBright-DemiItalic              Type 1       no  no  no      18  0
LucidaNewMath-Symbol                 Type 1       no  no  no      19  0

This is not so great.  I had hoped to get rid of the Helvetica fonts 
here.   Moreover, if I run my "firsttops.ps" file through ps2pdf12, I 
see

$ ps2pdf12 firsttops.ps firsttops.pdf ;  pdffonts firsttops.pdf
name                                 type         emb sub uni object ID
------------------------------------ ------------ --- --- --- ---------
Helvetica                            Type 1       no  no  no       9  0

So, it seems that the lucida font is not used, and therefore optimized 
away.

regards,

/ivo


---
ivo welch

-----Original Message-----
From: Paul Murrell <p.murrell at auckland.ac.nz>
To: ivo_welch-rstat8303 at mailblocks.com
Cc: ripley at stats.ox.ac.uk; r-help at stat.math.ethz.ch
Sent: Tue, 30 Aug 2005 11:49:38 +1200
Subject: Re: [R] pdf font embedding --- again

Hi

 ivo_welch-rstat8303 at mailblocks.com wrote:
  > > > Ooops. hit the button too soon. I have tried as arguments 
variation of > the fonts and family arguments to postscript, such as 
getting the case > right (i.e., lucida rather than Lucida). Alas
 > > > postscript(file="test.ps", fonts="lucida");
  > *** glibc detected *** free(): invalid pointer: 0x0000000000f7dfb8 
***
  > > this is under R 2.1.1, 2005-06-20, built under gentoo from 
scratch.
  > > so, the problem is probably now internal, not the commands. I 
guess I > will now investigate glibc in a little more detail...

  You might just be tickling the segfault you reported earlier (which 
appears to happen [sometimes] when R cannot find the AFM files).
 Try ...

 afmfiles <- c("/usr/share/texmf/fonts/afm/yandy/lubright/lbr.afm",
 "/usr/share/texmf/fonts/afm/yandy/lubright/lbd.afm",
 "/usr/share/texmf/fonts/afm/yandy/lubright/lbi.afm",
 "/usr/share/texmf/fonts/afm/yandy/lubright/lbdi.afm",
 "/usr/share/texmf/fonts/afm/yandy/lubright/lbms.afm")

 Paul

 > -----Original Message-----
 > From: Paul Murrell <p.murrell at auckland.ac.nz>
 > To: Paul Murrell <paul at stat.auckland.ac.nz>
  > Cc: ivo_welch-rstat8303 at mailblocks.com; ripley at stats.ox.ac.uk; > 
r-help at stat.math.ethz.ch
 > Sent: Tue, 30 Aug 2005 10:04:11 +1200
 > Subject: Re: [R] pdf font embedding --- again
 > > Hi
 > > Paul Murrell wrote:
 > > Hi
 > > > I think there are two problems:
 > > > (i) You are specifying the font incorrectly. Try ...
 > > > # You might need to specify full paths to these
  > > afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", 
"lbms.afm");
 > > # Set up the mapping for "lucida" font family
 > > postscriptFonts(lucida=postscriptFont("Lucida", metrics=afmfiles))
 > > # Specify that the "lucida" font is to be used
 > > postscript(file="test.ps", family="lucida");
 > > Thanks to Brian Ripley for pointing out that that should be ...
 > > postscript(file="test.ps", fonts="lucida");
 > > > l<- 40:80;
 > > plot(l,l,pch=l);
 > > dev.off();
 > > > Should work for pdf() too.
  > > > This should put a reference to the appropriate font in the > 
PostScript or > PDF file that R creates.
  > > > (ii) R does not embed font information. But you can, for 
example, > use > ghostscript to do it, as long as you tell ghostscript 
about the > font > too. You might have to set up a file 'FontMap' which 
looks > something > like ...
 > > > /Lucida (PATH_TO/lb___.pfb);
  > > > ... (assuming that lb___.pfb is the name of the .pfb file for 
the > Lucida > font). Then try something like (NOTE that you have to 
specify
 > >> GS_FONTPATH to tell ghostscript where your FontMap file is) ...
  > > > > GS_FONTPATH=PATH_TO_FontMap gs -dBATCH -dNOPAUSE 
-sDEVICE=pdfwrite
 > >> -sPAPERSIZE=a4 -sOutputFile=testembed.pdf test.pdf
  > > > > This should give you a file with the font info embedded and 
then > you > should be able to include that in a LaTeX document.
 > > > Paul
  > > > p.s. Thanks for the segfault report. I will look at why that is 
> happening.
 > > > > ivo_welch-rstat8303 at mailblocks.com wrote:
 > > >> Thank you---as always.
 > >>
 > >> still, I remain font-desparate.
 > >>
  > >> I would love to use the fonts from my book, but [a] I cannot 
figure > >> out how to do this yet even in the R postscript device; and 
[b] I am > >> using the R pdf device, not the postscript device. I 
guess if I can > >> solve [a], then I can rewrite all my graphics 
creations now into the > >> postscript device, and replace the 
dev.off() with something that >> > follows it with ps2pdf. The 
following attempt, however, does not work:
 > >>
  > >> afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", >> > 
"lbms.afm");
 > >> Lucida <- postscriptFont("Lucida", metrics=afmfiles);
 > >> postscript(file="test.ps", family=Lucida);
 > >> l<- 40:80;
 > >> plot(l,l,pch=l);
 > >> dev.off();
 > >>
  > >> By the way, if I try " postscript(family=afmfiles);" then I do 
not > >> get an R error, but R 2.1.0 segfaults, which is probably not 
 >> > desirable. This occurs even if there is no .afm file in the 
current >> > directory.
 > >>
 > >>
  > >> Can I make a suggestion to the R team? It would be nice if I 
could > >> specify a pdf() device parameter that says "choose font 
settings to > >> embed all fonts" (i.e., do not use fonts that cannot 
be embedded, >> > either). Something that guarantees me that I get a 
figure that I can >> > give to someone that is fully specified. Right 
now, accomplishing >> > this is not easy to figure out, and perhaps not 
even possible. Yes, >> > in the list of font families that R recognizes 
are some fonts that do >> > not seem among the 13 standard fonts (such 
as URWbookman). moreover, >> > if I choose it as my pdf font family, it 
is smart enough to use a >> > different symbol file ('StandardSymL'), 
which I hope is also open and >> > not adobe. If so, they could be used 
in principle. How do I get R to >> > embed URWbookman? ZapfDingbats 
always seems to be included, so I hope >> > this is open and 
embeddable.
 > >>
 > >> more help would be highly appreciated.
 > >>
 > >> Regards,
 > >>
 > >> /iaw
 > >> ---
 > >> ivo welch
 > >>
 > >> -----Original Message-----
 > >> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
 > >> To: ivo_welch-rstat8303 at mailblocks.com
 > >> Cc: r-help at stat.math.ethz.ch
 > >> Sent: Mon, 22 Aug 2005 17:07:14 +0100 (BST)
 > >> Subject: Re: [R] pdf font embedding --- again
 > >>
 > >> On Mon, 22 Aug 2005 ivo_welch-rstat8303 at mailblocks.com wrote:
 > >>
 > >> >
  > >> > dear R wizards--- I would like to do some book-on-demand 
printing
 > >>> at a
 >>
  > >> > popular printer named lulu, but lulu requires inclusion even of 
the
  > >> > basic postscript fonts. Interestingly, my book itself does not 
need
  > >> > the 14 base acrobat fonts, only the embedded R figures do. Of 
course,
  > >> > I really would like to get pdftex to embed the fonts, but how 
to do
  > >> > this is not obvious either. [This method seems to be what the R 
help
  > >> > page is indicating... The software including the PostScript 
plot file
  > >> > should either embed the font outlines (usually from '.pfb' or 
'.pfa'
  > >> > files) or use DSC comments to instruct the print spooler to do 
so.)
 > >>
  > >> Why not use the fonts your book does use in the figures? (That's 
how
 > >> my books are done.)
 > >>
  > >> > So, I would really, really like to embed the necessary fonts 
with
 > >>> the R
 >>
  > >> > figures. I first reread the discussion in this mailing list 
about
  > >> > (eps) font embedding earlier this year. This was ultimately not 
very
  > >> > helpful. First, I do not know how to instruct my embedding 
program to
  > >> > include the fonts that R figures want. Second, I already start 
with
  > >> > the pdf device, so distilling eps files is not a good 
option--and it
 > >> > would seem a bit crazy to first use the wrong output device
  > >> > (postscript), then ship my files over to a windows machine 
somewhere
  > >> > that has distiller installed, run distiller by hand, then ftp 
them > >> back
 > >> > to my linux machine---just for getting the fonts embedded.
 > >> >
  > >> > Is it impossible to get R to embed the necessary fonts in its 
pdf
 > >> > output?
 > >>
  > >> Yes, as it has no access to them. They are not Open Source. You 
may
  > >>> be able to use URW clones, depending on their licensing 
conditions.
 >>
 > >>
 > >> -- Brian D. Ripley, ripley at stats.ox.ac.uk
  > >> Professor of Applied Statistics, 
http://www.stats.ox.ac.uk/~ripley/
 > >> University of Oxford, Tel: +44 1865 272861 (self)
 > >> 1 South Parks Road, +44 1865 272866 (PA)
 > >> Oxford OX1 3TG, UK Fax: +44 1865 272595
 > >>
 > >> ______________________________________________
 > >> R-help at stat.math.ethz.ch mailing list
 > >> https://stat.ethz.ch/mailman/listinfo/r-help
  > >> PLEASE do read the posting guide! >> > 
http://www.R-project.org/posting-guide.html
 > > > >
 > -- Dr Paul Murrell
 > Department of Statistics
 > The University of Auckland
 > Private Bag 92019
 > Auckland
 > New Zealand
 > 64 9 3737599 x85392
 > paul at stat.auckland.ac.nz
 > http://www.stat.auckland.ac.nz/~paul/
 > >
 -- Dr Paul Murrell
 Department of Statistics
 The University of Auckland
 Private Bag 92019
 Auckland
 New Zealand
 64 9 3737599 x85392
 paul at stat.auckland.ac.nz
 http://www.stat.auckland.ac.nz/~paul/



From p.murrell at auckland.ac.nz  Tue Aug 30 02:19:47 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 30 Aug 2005 12:19:47 +1200
Subject: [R] pdf font embedding --- again
References: <200508221537.j7MFbsa0000978@hypatia.math.ethz.ch>	<Pine.LNX.4.61.0508221700100.17196@gannet.stats>	<200508222038.j7MKceUi031412@hypatia.math.ethz.ch>	<43137EE1.6000307@stat.auckland.ac.nz>	<4313865B.4010508@stat.auckland.ac.nz>	<20050829234348.D2E94347FF@smtpc.itss.auckland.ac.nz>	<43139F12.4070205@stat.auckland.ac.nz>
	<200508300009.j7U09BvA005502@hypatia.math.ethz.ch>
Message-ID: <4313A623.1010704@stat.auckland.ac.nz>

Hi


ivo_welch-rstat8303 at mailblocks.com wrote:
> Hi Paul:
> 
> You are correct.  it was the same little bug I hit on.  Specifying the 
> full (not the symlinked) afm filenames lets me run the code.  No R 
> error.  yoohoo!
> 
> alas, the files don't seem to come out right.  I can use these commands 
> on the R postscript() and on the R pdf() device.  they have an effect 
> on both.  (that is, if I grep for lucida in the resulting ps or pdf 
> file, respectively, the word lucida appears in both files).  alas, 
> usage is another story:


Right, the fonts are referred to in the PostScript or PDF file, but no 
font information is embedded.  Now we move to the second problem I 
mentioned, embedding the fonts.  Can you try using ghostscript?  (see my 
first post)

Paul


> $ pdffonts tonativepdf.pdf
> name                                 type         emb sub uni object ID
> ------------------------------------ ------------ --- --- --- ---------
> ZapfDingbats                         Type 1       no  no  no       5  0
> Helvetica                            Type 1       no  no  no      10  0
> Helvetica-Bold                       Type 1       no  no  no      11  0
> Helvetica-Oblique                    Type 1       no  no  no      12  0
> Helvetica-BoldOblique                Type 1       no  no  no      13  0
> Symbol                               Type 1       no  no  no      14  0
> LucidaBright                         Type 1       no  no  no      15  0
> LucidaBright-Demi                    Type 1       no  no  no      16  0
> LucidaBright-Italic                  Type 1       no  no  no      17  0
> LucidaBright-DemiItalic              Type 1       no  no  no      18  0
> LucidaNewMath-Symbol                 Type 1       no  no  no      19  0
> 
> This is not so great.  I had hoped to get rid of the Helvetica fonts 
> here.   Moreover, if I run my "firsttops.ps" file through ps2pdf12, I 
> see
> 
> $ ps2pdf12 firsttops.ps firsttops.pdf ;  pdffonts firsttops.pdf
> name                                 type         emb sub uni object ID
> ------------------------------------ ------------ --- --- --- ---------
> Helvetica                            Type 1       no  no  no       9  0
> 
> So, it seems that the lucida font is not used, and therefore optimized 
> away.
> 
> regards,
> 
> /ivo
> 
> 
> ---
> ivo welch
> 
> -----Original Message-----
> From: Paul Murrell <p.murrell at auckland.ac.nz>
> To: ivo_welch-rstat8303 at mailblocks.com
> Cc: ripley at stats.ox.ac.uk; r-help at stat.math.ethz.ch
> Sent: Tue, 30 Aug 2005 11:49:38 +1200
> Subject: Re: [R] pdf font embedding --- again
> 
> Hi
> 
>  ivo_welch-rstat8303 at mailblocks.com wrote:
>   > > > Ooops. hit the button too soon. I have tried as arguments 
> variation of > the fonts and family arguments to postscript, such as 
> getting the case > right (i.e., lucida rather than Lucida). Alas
>  > > > postscript(file="test.ps", fonts="lucida");
>   > *** glibc detected *** free(): invalid pointer: 0x0000000000f7dfb8 
> ***
>   > > this is under R 2.1.1, 2005-06-20, built under gentoo from 
> scratch.
>   > > so, the problem is probably now internal, not the commands. I 
> guess I > will now investigate glibc in a little more detail...
> 
>   You might just be tickling the segfault you reported earlier (which 
> appears to happen [sometimes] when R cannot find the AFM files).
>  Try ...
> 
>  afmfiles <- c("/usr/share/texmf/fonts/afm/yandy/lubright/lbr.afm",
>  "/usr/share/texmf/fonts/afm/yandy/lubright/lbd.afm",
>  "/usr/share/texmf/fonts/afm/yandy/lubright/lbi.afm",
>  "/usr/share/texmf/fonts/afm/yandy/lubright/lbdi.afm",
>  "/usr/share/texmf/fonts/afm/yandy/lubright/lbms.afm")
> 
>  Paul
> 
>  > -----Original Message-----
>  > From: Paul Murrell <p.murrell at auckland.ac.nz>
>  > To: Paul Murrell <paul at stat.auckland.ac.nz>
>   > Cc: ivo_welch-rstat8303 at mailblocks.com; ripley at stats.ox.ac.uk; > 
> r-help at stat.math.ethz.ch
>  > Sent: Tue, 30 Aug 2005 10:04:11 +1200
>  > Subject: Re: [R] pdf font embedding --- again
>  > > Hi
>  > > Paul Murrell wrote:
>  > > Hi
>  > > > I think there are two problems:
>  > > > (i) You are specifying the font incorrectly. Try ...
>  > > > # You might need to specify full paths to these
>   > > afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", 
> "lbms.afm");
>  > > # Set up the mapping for "lucida" font family
>  > > postscriptFonts(lucida=postscriptFont("Lucida", metrics=afmfiles))
>  > > # Specify that the "lucida" font is to be used
>  > > postscript(file="test.ps", family="lucida");
>  > > Thanks to Brian Ripley for pointing out that that should be ...
>  > > postscript(file="test.ps", fonts="lucida");
>  > > > l<- 40:80;
>  > > plot(l,l,pch=l);
>  > > dev.off();
>  > > > Should work for pdf() too.
>   > > > This should put a reference to the appropriate font in the > 
> PostScript or > PDF file that R creates.
>   > > > (ii) R does not embed font information. But you can, for 
> example, > use > ghostscript to do it, as long as you tell ghostscript 
> about the > font > too. You might have to set up a file 'FontMap' which 
> looks > something > like ...
>  > > > /Lucida (PATH_TO/lb___.pfb);
>   > > > ... (assuming that lb___.pfb is the name of the .pfb file for 
> the > Lucida > font). Then try something like (NOTE that you have to 
> specify
>  > >> GS_FONTPATH to tell ghostscript where your FontMap file is) ...
>   > > > > GS_FONTPATH=PATH_TO_FontMap gs -dBATCH -dNOPAUSE 
> -sDEVICE=pdfwrite
>  > >> -sPAPERSIZE=a4 -sOutputFile=testembed.pdf test.pdf
>   > > > > This should give you a file with the font info embedded and 
> then > you > should be able to include that in a LaTeX document.
>  > > > Paul
>   > > > p.s. Thanks for the segfault report. I will look at why that is 
> 
>>happening.
> 
>  > > > > ivo_welch-rstat8303 at mailblocks.com wrote:
>  > > >> Thank you---as always.
>  > >>
>  > >> still, I remain font-desparate.
>  > >>
>   > >> I would love to use the fonts from my book, but [a] I cannot 
> figure > >> out how to do this yet even in the R postscript device; and 
> [b] I am > >> using the R pdf device, not the postscript device. I 
> guess if I can > >> solve [a], then I can rewrite all my graphics 
> creations now into the > >> postscript device, and replace the 
> dev.off() with something that >> > follows it with ps2pdf. The 
> following attempt, however, does not work:
>  > >>
>   > >> afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", >> > 
> "lbms.afm");
>  > >> Lucida <- postscriptFont("Lucida", metrics=afmfiles);
>  > >> postscript(file="test.ps", family=Lucida);
>  > >> l<- 40:80;
>  > >> plot(l,l,pch=l);
>  > >> dev.off();
>  > >>
>   > >> By the way, if I try " postscript(family=afmfiles);" then I do 
> not > >> get an R error, but R 2.1.0 segfaults, which is probably not 
>  >> > desirable. This occurs even if there is no .afm file in the 
> current >> > directory.
>  > >>
>  > >>
>   > >> Can I make a suggestion to the R team? It would be nice if I 
> could > >> specify a pdf() device parameter that says "choose font 
> settings to > >> embed all fonts" (i.e., do not use fonts that cannot 
> be embedded, >> > either). Something that guarantees me that I get a 
> figure that I can >> > give to someone that is fully specified. Right 
> now, accomplishing >> > this is not easy to figure out, and perhaps not 
> even possible. Yes, >> > in the list of font families that R recognizes 
> are some fonts that do >> > not seem among the 13 standard fonts (such 
> as URWbookman). moreover, >> > if I choose it as my pdf font family, it 
> is smart enough to use a >> > different symbol file ('StandardSymL'), 
> which I hope is also open and >> > not adobe. If so, they could be used 
> in principle. How do I get R to >> > embed URWbookman? ZapfDingbats 
> always seems to be included, so I hope >> > this is open and 
> embeddable.
>  > >>
>  > >> more help would be highly appreciated.
>  > >>
>  > >> Regards,
>  > >>
>  > >> /iaw
>  > >> ---
>  > >> ivo welch
>  > >>
>  > >> -----Original Message-----
>  > >> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>  > >> To: ivo_welch-rstat8303 at mailblocks.com
>  > >> Cc: r-help at stat.math.ethz.ch
>  > >> Sent: Mon, 22 Aug 2005 17:07:14 +0100 (BST)
>  > >> Subject: Re: [R] pdf font embedding --- again
>  > >>
>  > >> On Mon, 22 Aug 2005 ivo_welch-rstat8303 at mailblocks.com wrote:
>  > >>
>  > >> >
>   > >> > dear R wizards--- I would like to do some book-on-demand 
> printing
>  > >>> at a
>  >>
>   > >> > popular printer named lulu, but lulu requires inclusion even of 
> the
>   > >> > basic postscript fonts. Interestingly, my book itself does not 
> need
>   > >> > the 14 base acrobat fonts, only the embedded R figures do. Of 
> course,
>   > >> > I really would like to get pdftex to embed the fonts, but how 
> to do
>   > >> > this is not obvious either. [This method seems to be what the R 
> help
>   > >> > page is indicating... The software including the PostScript 
> plot file
>   > >> > should either embed the font outlines (usually from '.pfb' or 
> '.pfa'
>   > >> > files) or use DSC comments to instruct the print spooler to do 
> so.)
>  > >>
>   > >> Why not use the fonts your book does use in the figures? (That's 
> how
>  > >> my books are done.)
>  > >>
>   > >> > So, I would really, really like to embed the necessary fonts 
> with
>  > >>> the R
>  >>
>   > >> > figures. I first reread the discussion in this mailing list 
> about
>   > >> > (eps) font embedding earlier this year. This was ultimately not 
> very
>   > >> > helpful. First, I do not know how to instruct my embedding 
> program to
>   > >> > include the fonts that R figures want. Second, I already start 
> with
>   > >> > the pdf device, so distilling eps files is not a good 
> option--and it
>  > >> > would seem a bit crazy to first use the wrong output device
>   > >> > (postscript), then ship my files over to a windows machine 
> somewhere
>   > >> > that has distiller installed, run distiller by hand, then ftp 
> them > >> back
>  > >> > to my linux machine---just for getting the fonts embedded.
>  > >> >
>   > >> > Is it impossible to get R to embed the necessary fonts in its 
> pdf
>  > >> > output?
>  > >>
>   > >> Yes, as it has no access to them. They are not Open Source. You 
> may
>   > >>> be able to use URW clones, depending on their licensing 
> conditions.
>  >>
>  > >>
>  > >> -- Brian D. Ripley, ripley at stats.ox.ac.uk
>   > >> Professor of Applied Statistics, 
> http://www.stats.ox.ac.uk/~ripley/
>  > >> University of Oxford, Tel: +44 1865 272861 (self)
>  > >> 1 South Parks Road, +44 1865 272866 (PA)
>  > >> Oxford OX1 3TG, UK Fax: +44 1865 272595
>  > >>
>  > >> ______________________________________________
>  > >> R-help at stat.math.ethz.ch mailing list
>  > >> https://stat.ethz.ch/mailman/listinfo/r-help
>   > >> PLEASE do read the posting guide! >> > 
> http://www.R-project.org/posting-guide.html
>  > > > >
>  > -- Dr Paul Murrell
>  > Department of Statistics
>  > The University of Auckland
>  > Private Bag 92019
>  > Auckland
>  > New Zealand
>  > 64 9 3737599 x85392
>  > paul at stat.auckland.ac.nz
>  > http://www.stat.auckland.ac.nz/~paul/
>  > >
>  -- Dr Paul Murrell
>  Department of Statistics
>  The University of Auckland
>  Private Bag 92019
>  Auckland
>  New Zealand
>  64 9 3737599 x85392
>  paul at stat.auckland.ac.nz
>  http://www.stat.auckland.ac.nz/~paul/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From ivo_welch-rstat8303 at mailblocks.com  Tue Aug 30 03:25:17 2005
From: ivo_welch-rstat8303 at mailblocks.com (ivo_welch-rstat8303@mailblocks.com)
Date: Mon, 29 Aug 2005 18:25:17 -0700
Subject: [R] pdf font embedding --- again
In-Reply-To: <4313A623.1010704@stat.auckland.ac.nz>
References: <200508221537.j7MFbsa0000978@hypatia.math.ethz.ch>	<Pine.LNX.4.61.0508221700100.17196@gannet.stats>	<200508222038.j7MKceUi031412@hypatia.math.ethz.ch>	<43137EE1.6000307@stat.auckland.ac.nz>	<4313865B.4010508@stat.auckland.ac.nz>	<20050829234348.D2E94347FF@smtpc.itss.auckland.ac.nz>	<43139F12.4070205@stat.auckland.ac.nz>
	<200508300009.j7U09BvA005502@hypatia.math.ethz.ch>
	<4313A623.1010704@stat.auckland.ac.nz>
Message-ID: <200508300125.j7U1PJ3o019709@hypatia.math.ethz.ch>


Hi Paul:

I very much appreciate your spending the time to help me here, and I 
hope we will get a nice how-to document from this for other 
novices---or at least a google-able record in the r-help archive.

* The following is working R code to embed fonts, such as the lucida 
font family:

  afmfiles <- c("/usr/share/texmf/fonts/afm/yandy/lubright/lbr.afm",
              "/usr/share/texmf/fonts/afm/yandy/lubright/lbd.afm",
              "/usr/share/texmf/fonts/afm/yandy/lubright/lbi.afm",
              "/usr/share/texmf/fonts/afm/yandy/lubright/lbdi.afm",
              "/usr/share/texmf/fonts/afm/yandy/lumath/lbms.afm")

    # Set up the mapping for "lucida" font family
  postscriptFonts(lucida=postscriptFont("Lucida", metrics=afmfiles))
    # Specify that the "lucida" font is to be used
  postscript(file="lu1.ps", fonts="lucida");
  l<- 40:80;
  plot(l,l,pch=l);
  dev.off();

* The resulting file lu1.ps knows about Lucida fonts, e.g.,

$ grep LucidaBright-Demi lu1.ps
%%+ font LucidaBright-Demi
%%+ font LucidaBright-DemiItalic
%%IncludeResource: font LucidaBright-Demi
/LucidaBright-Demi findfont
%%IncludeResource: font LucidaBright-DemiItalic
/LucidaBright-DemiItalic findfont

but is also still includes the Helvetica font family, even though my 
intent is to get rid of them.


* In the same local directory, I have a Fontmap file (note 
capitalization; thank strace!), which is

/LucidaBright (/usr/local/share/texmf/fonts/type1/yandy/lbr.pfb);
/LucidaBright-Demi (/usr/local/share/texmf/fonts/type1/yandy/lbd.pfb);
/LucidaBright-Italic (/usr/local/share/texmf/fonts/type1/yandy/lbi.pfb);
/LucidaBright-DemiItalic 
(/usr/local/share/texmf/fonts/type1/yandy/lbdi.pfb);
/LucidaNewMath-Symbol 
(/usr/local/share/texmf/fonts/type1/yandy/lbms.pfb);


* I can now execute ghostscript,

$ gs   -dBATCH -dNOPAUSE -sDEVICE=pdfwrite -sPAPERSIZE=a4 
-sOutputFile=testembed.pdf lu1.ps
Loading NimbusSanL-Regu font from 
/usr/share/fonts/default/ghostscript/n019003l.pfb... 2614080 1177851 
1691032 395776 0 done.
Loading NimbusSanL-Bold font from 
/usr/share/fonts/default/ghostscript/n019004l.pfb... 2748280 1295559 
1711216 410271 0 done.
Loading NimbusSanL-ReguItal font from 
/usr/share/fonts/default/ghostscript/n019023l.pfb... 2862296 1345751 
1691032 368290 0 done.
Loading NimbusSanL-BoldItal font from 
/usr/share/fonts/default/ghostscript/n019024l.pfb... 2976312 1462430 
1711216 382930 0 done.
Loading StandardSymL font from 
/usr/share/fonts/default/ghostscript/s050000l.pfb... 3036864 1512937 
1731400 392499 0 done.
Loading LucidaBright font from 
/usr/local/share/texmf/fonts/type1/yandy/lbr.pfb... 3094128 1564220 
1731400 379225 0 done.
Loading LucidaBright-Demi font from 
/usr/local/share/texmf/fonts/type1/yandy/lbd.pfb... 3154680 1618028 
1731400 386450 0 done.
Loading LucidaBright-Italic font from 
/usr/local/share/texmf/fonts/type1/yandy/lbi.pfb... 3195048 1667744 
1751584 396673 0 done.
Loading LucidaBright-DemiItalic font from 
/usr/local/share/texmf/fonts/type1/yandy/lbdi.pfb... 3255600 1720688 
1751584 403496 0 done.
Loading LucidaNewMath-Symbol font from 
/usr/local/share/texmf/fonts/type1/yandy/lbms.pfb... 3316152 1776143 
1751584 409361 0 done.

which seems to indicate that the Fontmap file was found.  (Adding a 
"-GS_FONTPATH=." to point to the local directory is not necessary.)

* Alas, the output still does not have my Lucida fonts:

$ pdffonts testembed.pdf

name                                 type         emb sub uni object ID
------------------------------------ ------------ --- --- --- ---------
Helvetica                            Type 1C      yes no  no      10  0


Also, looking at either lu1.ps or testembed.pdf with previewers shows 
that I am still using Helvetica fonts, not Lucida fonts.  so something 
is still missing somewhere.  (I also tried creating a pdf file directly 
under R, and though it gives me no error, and although the resulting 
pdf file claims to reference both helvetica and lucida fonts [and 
others], upon viewing, I can see that there are only helvetica fonts 
visible; no lucida fonts.)

further help and advice would still be appreciated.

Regards,

/iaw


-----Original Message-----
From: Paul Murrell <p.murrell at auckland.ac.nz>
To: ivo_welch-rstat8303 at mailblocks.com
Cc: ripley at stats.ox.ac.uk; r-help at stat.math.ethz.ch
Sent: Tue, 30 Aug 2005 12:19:47 +1200
Subject: Re: [R] pdf font embedding --- again

Hi

 ivo_welch-rstat8303 at mailblocks.com wrote:
 > Hi Paul:
  > > You are correct. it was the same little bug I hit on. Specifying 
the > full (not the symlinked) afm filenames lets me run the code. No R 
> error. yoohoo!
  > > alas, the files don't seem to come out right. I can use these 
commands > on the R postscript() and on the R pdf() device. they have 
an effect > on both. (that is, if I grep for lucida in the resulting ps 
or pdf > file, respectively, the word lucida appears in both files). 
alas, > usage is another story:

  Right, the fonts are referred to in the PostScript or PDF file, but no 
font information is embedded. Now we move to the second problem I 
mentioned, embedding the fonts. Can you try using ghostscript? (see my 
first post)

 Paul

 > $ pdffonts tonativepdf.pdf
 > name type emb sub uni object ID
  > ------------------------------------ ------------ --- --- --- 
---------
 > ZapfDingbats Type 1 no no no 5 0
 > Helvetica Type 1 no no no 10 0
 > Helvetica-Bold Type 1 no no no 11 0
 > Helvetica-Oblique Type 1 no no no 12 0
 > Helvetica-BoldOblique Type 1 no no no 13 0
 > Symbol Type 1 no no no 14 0
 > LucidaBright Type 1 no no no 15 0
 > LucidaBright-Demi Type 1 no no no 16 0
 > LucidaBright-Italic Type 1 no no no 17 0
 > LucidaBright-DemiItalic Type 1 no no no 18 0
 > LucidaNewMath-Symbol Type 1 no no no 19 0
  > > This is not so great. I had hoped to get rid of the Helvetica 
fonts > here. Moreover, if I run my "firsttops.ps" file through 
ps2pdf12, I > see
 > > $ ps2pdf12 firsttops.ps firsttops.pdf ; pdffonts firsttops.pdf
 > name type emb sub uni object ID
  > ------------------------------------ ------------ --- --- --- 
---------
 > Helvetica Type 1 no no no 9 0
  > > So, it seems that the lucida font is not used, and therefore 
optimized > away.
 > > regards,
 > > /ivo
 > > > ---
 > ivo welch
 > > -----Original Message-----
 > From: Paul Murrell <p.murrell at auckland.ac.nz>
 > To: ivo_welch-rstat8303 at mailblocks.com
 > Cc: ripley at stats.ox.ac.uk; r-help at stat.math.ethz.ch
 > Sent: Tue, 30 Aug 2005 11:49:38 +1200
 > Subject: Re: [R] pdf font embedding --- again
 > > Hi
 > > ivo_welch-rstat8303 at mailblocks.com wrote:
  > > > > Ooops. hit the button too soon. I have tried as arguments > 
variation of > the fonts and family arguments to postscript, such as > 
getting the case > right (i.e., lucida rather than Lucida). Alas
 > > > > postscript(file="test.ps", fonts="lucida");
  > > *** glibc detected *** free(): invalid pointer: 0x0000000000f7dfb8 
> ***
  > > > this is under R 2.1.1, 2005-06-20, built under gentoo from > 
scratch.
  > > > so, the problem is probably now internal, not the commands. I > 
guess I > will now investigate glibc in a little more detail...
  > > You might just be tickling the segfault you reported earlier 
(which > appears to happen [sometimes] when R cannot find the AFM 
files).
 > Try ...
 > > afmfiles <- c("/usr/share/texmf/fonts/afm/yandy/lubright/lbr.afm",
 > "/usr/share/texmf/fonts/afm/yandy/lubright/lbd.afm",
 > "/usr/share/texmf/fonts/afm/yandy/lubright/lbi.afm",
 > "/usr/share/texmf/fonts/afm/yandy/lubright/lbdi.afm",
 > "/usr/share/texmf/fonts/afm/yandy/lubright/lbms.afm")
 > > Paul
 > > > -----Original Message-----
 > > From: Paul Murrell <p.murrell at auckland.ac.nz>
 > > To: Paul Murrell <paul at stat.auckland.ac.nz>
  > > Cc: ivo_welch-rstat8303 at mailblocks.com; ripley at stats.ox.ac.uk; > > 
r-help at stat.math.ethz.ch
 > > Sent: Tue, 30 Aug 2005 10:04:11 +1200
 > > Subject: Re: [R] pdf font embedding --- again
 > > > Hi
 > > > Paul Murrell wrote:
 > > > Hi
 > > > > I think there are two problems:
 > > > > (i) You are specifying the font incorrectly. Try ...
 > > > > # You might need to specify full paths to these
  > > > afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", > 
"lbms.afm");
 > > > # Set up the mapping for "lucida" font family
  > > > postscriptFonts(lucida=postscriptFont("Lucida", 
metrics=afmfiles))
 > > > # Specify that the "lucida" font is to be used
 > > > postscript(file="test.ps", family="lucida");
 > > > Thanks to Brian Ripley for pointing out that that should be ...
 > > > postscript(file="test.ps", fonts="lucida");
 > > > > l<- 40:80;
 > > > plot(l,l,pch=l);
 > > > dev.off();
 > > > > Should work for pdf() too.
  > > > > This should put a reference to the appropriate font in the > > 
PostScript or > PDF file that R creates.
  > > > > (ii) R does not embed font information. But you can, for > 
example, > use > ghostscript to do it, as long as you tell ghostscript 
 > about the > font > too. You might have to set up a file 'FontMap' 
which > looks > something > like ...
 > > > > /Lucida (PATH_TO/lb___.pfb);
  > > > > ... (assuming that lb___.pfb is the name of the .pfb file for 
 > the > Lucida > font). Then try something like (NOTE that you have to 
> specify
 > > >> GS_FONTPATH to tell ghostscript where your FontMap file is) ...
  > > > > > GS_FONTPATH=PATH_TO_FontMap gs -dBATCH -dNOPAUSE > 
-sDEVICE=pdfwrite
 > > >> -sPAPERSIZE=a4 -sOutputFile=testembed.pdf test.pdf
  > > > > > This should give you a file with the font info embedded and 
> then > you > should be able to include that in a LaTeX document.
 > > > > Paul
  > > > > p.s. Thanks for the segfault report. I will look at why that 
is > >>happening.
 > > > > > > ivo_welch-rstat8303 at mailblocks.com wrote:
 > > > >> Thank you---as always.
 > > >>
 > > >> still, I remain font-desparate.
 > > >>
  > > >> I would love to use the fonts from my book, but [a] I cannot > 
figure > >> out how to do this yet even in the R postscript device; and 
 > [b] I am > >> using the R pdf device, not the postscript device. I > 
guess if I can > >> solve [a], then I can rewrite all my graphics > 
creations now into the > >> postscript device, and replace the > 
dev.off() with something that >> > follows it with ps2pdf. The > 
following attempt, however, does not work:
 > > >>
  > > >> afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", >> > 
> "lbms.afm");
 > > >> Lucida <- postscriptFont("Lucida", metrics=afmfiles);
 > > >> postscript(file="test.ps", family=Lucida);
 > > >> l<- 40:80;
 > > >> plot(l,l,pch=l);
 > > >> dev.off();
 > > >>
  > > >> By the way, if I try " postscript(family=afmfiles);" then I do 
 > not > >> get an R error, but R 2.1.0 segfaults, which is probably not 
 > >> > desirable. This occurs even if there is no .afm file in the > 
current >> > directory.
 > > >>
 > > >>
  > > >> Can I make a suggestion to the R team? It would be nice if I > 
could > >> specify a pdf() device parameter that says "choose font > 
settings to > >> embed all fonts" (i.e., do not use fonts that cannot > 
be embedded, >> > either). Something that guarantees me that I get a > 
figure that I can >> > give to someone that is fully specified. Right > 
now, accomplishing >> > this is not easy to figure out, and perhaps not 
 > even possible. Yes, >> > in the list of font families that R 
recognizes > are some fonts that do >> > not seem among the 13 standard 
fonts (such > as URWbookman). moreover, >> > if I choose it as my pdf 
font family, it > is smart enough to use a >> > different symbol file 
('StandardSymL'), > which I hope is also open and >> > not adobe. If 
so, they could be used > in principle. How do I get R to >> > embed 
URWbookman? ZapfDingbats > always seems to be included, so I hope >> > 
this is open and > embeddable.
 > > >>
 > > >> more help would be highly appreciated.
 > > >>
 > > >> Regards,
 > > >>
 > > >> /iaw
 > > >> ---
 > > >> ivo welch
 > > >>
 > > >> -----Original Message-----
 > > >> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
 > > >> To: ivo_welch-rstat8303 at mailblocks.com
 > > >> Cc: r-help at stat.math.ethz.ch
 > > >> Sent: Mon, 22 Aug 2005 17:07:14 +0100 (BST)
 > > >> Subject: Re: [R] pdf font embedding --- again
 > > >>
 > > >> On Mon, 22 Aug 2005 ivo_welch-rstat8303 at mailblocks.com wrote:
 > > >>
 > > >> >
  > > >> > dear R wizards--- I would like to do some book-on-demand > 
printing
 > > >>> at a
 > >>
  > > >> > popular printer named lulu, but lulu requires inclusion even 
of > the
  > > >> > basic postscript fonts. Interestingly, my book itself does 
not > need
  > > >> > the 14 base acrobat fonts, only the embedded R figures do. Of 
> course,
  > > >> > I really would like to get pdftex to embed the fonts, but how 
> to do
  > > >> > this is not obvious either. [This method seems to be what the 
R > help
  > > >> > page is indicating... The software including the PostScript > 
plot file
  > > >> > should either embed the font outlines (usually from '.pfb' or 
> '.pfa'
  > > >> > files) or use DSC comments to instruct the print spooler to 
do > so.)
 > > >>
  > > >> Why not use the fonts your book does use in the figures? 
(That's > how
 > > >> my books are done.)
 > > >>
  > > >> > So, I would really, really like to embed the necessary fonts 
> with
 > > >>> the R
 > >>
  > > >> > figures. I first reread the discussion in this mailing list > 
about
  > > >> > (eps) font embedding earlier this year. This was ultimately 
not > very
  > > >> > helpful. First, I do not know how to instruct my embedding > 
program to
  > > >> > include the fonts that R figures want. Second, I already 
start > with
  > > >> > the pdf device, so distilling eps files is not a good > 
option--and it
 > > >> > would seem a bit crazy to first use the wrong output device
  > > >> > (postscript), then ship my files over to a windows machine > 
somewhere
  > > >> > that has distiller installed, run distiller by hand, then ftp 
> them > >> back
 > > >> > to my linux machine---just for getting the fonts embedded.
 > > >> >
  > > >> > Is it impossible to get R to embed the necessary fonts in its 
> pdf
 > > >> > output?
 > > >>
  > > >> Yes, as it has no access to them. They are not Open Source. You 
> may
  > > >>> be able to use URW clones, depending on their licensing > 
conditions.
 > >>
 > > >>
 > > >> -- Brian D. Ripley, ripley at stats.ox.ac.uk
  > > >> Professor of Applied Statistics, > 
http://www.stats.ox.ac.uk/~ripley/
 > > >> University of Oxford, Tel: +44 1865 272861 (self)
 > > >> 1 South Parks Road, +44 1865 272866 (PA)
 > > >> Oxford OX1 3TG, UK Fax: +44 1865 272595
 > > >>
 > > >> ______________________________________________
 > > >> R-help at stat.math.ethz.ch mailing list
 > > >> https://stat.ethz.ch/mailman/listinfo/r-help
  > > >> PLEASE do read the posting guide! >> > > 
http://www.R-project.org/posting-guide.html
 > > > > >
 > > -- Dr Paul Murrell
 > > Department of Statistics
 > > The University of Auckland
 > > Private Bag 92019
 > > Auckland
 > > New Zealand
 > > 64 9 3737599 x85392
 > > paul at stat.auckland.ac.nz
 > > http://www.stat.auckland.ac.nz/~paul/
 > > >
 > -- Dr Paul Murrell
 > Department of Statistics
 > The University of Auckland
 > Private Bag 92019
 > Auckland
 > New Zealand
 > 64 9 3737599 x85392
 > paul at stat.auckland.ac.nz
 > http://www.stat.auckland.ac.nz/~paul/
 > > ______________________________________________
 > R-help at stat.math.ethz.ch mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
  > PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html

 -- Dr Paul Murrell
 Department of Statistics
 The University of Auckland
 Private Bag 92019
 Auckland
 New Zealand
 64 9 3737599 x85392
 paul at stat.auckland.ac.nz
 http://www.stat.auckland.ac.nz/~paul/



From p.murrell at auckland.ac.nz  Tue Aug 30 03:34:00 2005
From: p.murrell at auckland.ac.nz (Paul Murrell)
Date: Tue, 30 Aug 2005 13:34:00 +1200
Subject: [R] pdf font embedding --- again
References: <200508221537.j7MFbsa0000978@hypatia.math.ethz.ch>	<Pine.LNX.4.61.0508221700100.17196@gannet.stats>	<200508222038.j7MKceUi031412@hypatia.math.ethz.ch>	<43137EE1.6000307@stat.auckland.ac.nz>	<4313865B.4010508@stat.auckland.ac.nz>	<20050829234348.D2E94347FF@smtpc.itss.auckland.ac.nz>	<43139F12.4070205@stat.auckland.ac.nz>	<200508300009.j7U09BvA005502@hypatia.math.ethz.ch>	<4313A623.1010704@stat.auckland.ac.nz>
	<200508300125.j7U1PJ3o019709@hypatia.math.ethz.ch>
Message-ID: <4313B788.2060802@stat.auckland.ac.nz>

Hi


ivo_welch-rstat8303 at mailblocks.com wrote:
> Hi Paul:
> 
> I very much appreciate your spending the time to help me here, and I 
> hope we will get a nice how-to document from this for other 
> novices---or at least a google-able record in the r-help archive.


I think we're almost there.  All we have to do now is actually USE the 
Lucida font (see below) ...


> * The following is working R code to embed fonts, such as the lucida 
> font family:
> 
>   afmfiles <- c("/usr/share/texmf/fonts/afm/yandy/lubright/lbr.afm",
>               "/usr/share/texmf/fonts/afm/yandy/lubright/lbd.afm",
>               "/usr/share/texmf/fonts/afm/yandy/lubright/lbi.afm",
>               "/usr/share/texmf/fonts/afm/yandy/lubright/lbdi.afm",
>               "/usr/share/texmf/fonts/afm/yandy/lumath/lbms.afm")
> 
>     # Set up the mapping for "lucida" font family
>   postscriptFonts(lucida=postscriptFont("Lucida", metrics=afmfiles))
>     # Specify that the "lucida" font is to be used


# Actually, if family= had worked we would have specified that
# "lucida" should be used;  what fonts= does is just ensure that
# the font gets mentioned in the PostScript output, but it does
# not set the font.  We have to use par(family) to do that, as below


>   postscript(file="lu1.ps", fonts="lucida");
>   l<- 40:80;


# Specify that we should use the "lucida" font!!!
par(family="lucida")


>   plot(l,l,pch=l);
>   dev.off();


Now when you ghostscript the output it should include "lucida" because 
that font is now used.  In the original code, the only font that was 
used was Helvetica, so ghostscript only embedded Helvetica.

Paul


> * The resulting file lu1.ps knows about Lucida fonts, e.g.,
> 
> $ grep LucidaBright-Demi lu1.ps
> %%+ font LucidaBright-Demi
> %%+ font LucidaBright-DemiItalic
> %%IncludeResource: font LucidaBright-Demi
> /LucidaBright-Demi findfont
> %%IncludeResource: font LucidaBright-DemiItalic
> /LucidaBright-DemiItalic findfont
> 
> but is also still includes the Helvetica font family, even though my 
> intent is to get rid of them.
> 
> 
> * In the same local directory, I have a Fontmap file (note 
> capitalization; thank strace!), which is
> 
> /LucidaBright (/usr/local/share/texmf/fonts/type1/yandy/lbr.pfb);
> /LucidaBright-Demi (/usr/local/share/texmf/fonts/type1/yandy/lbd.pfb);
> /LucidaBright-Italic (/usr/local/share/texmf/fonts/type1/yandy/lbi.pfb);
> /LucidaBright-DemiItalic 
> (/usr/local/share/texmf/fonts/type1/yandy/lbdi.pfb);
> /LucidaNewMath-Symbol 
> (/usr/local/share/texmf/fonts/type1/yandy/lbms.pfb);
> 
> 
> * I can now execute ghostscript,
> 
> $ gs   -dBATCH -dNOPAUSE -sDEVICE=pdfwrite -sPAPERSIZE=a4 
> -sOutputFile=testembed.pdf lu1.ps
> Loading NimbusSanL-Regu font from 
> /usr/share/fonts/default/ghostscript/n019003l.pfb... 2614080 1177851 
> 1691032 395776 0 done.
> Loading NimbusSanL-Bold font from 
> /usr/share/fonts/default/ghostscript/n019004l.pfb... 2748280 1295559 
> 1711216 410271 0 done.
> Loading NimbusSanL-ReguItal font from 
> /usr/share/fonts/default/ghostscript/n019023l.pfb... 2862296 1345751 
> 1691032 368290 0 done.
> Loading NimbusSanL-BoldItal font from 
> /usr/share/fonts/default/ghostscript/n019024l.pfb... 2976312 1462430 
> 1711216 382930 0 done.
> Loading StandardSymL font from 
> /usr/share/fonts/default/ghostscript/s050000l.pfb... 3036864 1512937 
> 1731400 392499 0 done.
> Loading LucidaBright font from 
> /usr/local/share/texmf/fonts/type1/yandy/lbr.pfb... 3094128 1564220 
> 1731400 379225 0 done.
> Loading LucidaBright-Demi font from 
> /usr/local/share/texmf/fonts/type1/yandy/lbd.pfb... 3154680 1618028 
> 1731400 386450 0 done.
> Loading LucidaBright-Italic font from 
> /usr/local/share/texmf/fonts/type1/yandy/lbi.pfb... 3195048 1667744 
> 1751584 396673 0 done.
> Loading LucidaBright-DemiItalic font from 
> /usr/local/share/texmf/fonts/type1/yandy/lbdi.pfb... 3255600 1720688 
> 1751584 403496 0 done.
> Loading LucidaNewMath-Symbol font from 
> /usr/local/share/texmf/fonts/type1/yandy/lbms.pfb... 3316152 1776143 
> 1751584 409361 0 done.
> 
> which seems to indicate that the Fontmap file was found.  (Adding a 
> "-GS_FONTPATH=." to point to the local directory is not necessary.)
> 
> * Alas, the output still does not have my Lucida fonts:
> 
> $ pdffonts testembed.pdf
> 
> name                                 type         emb sub uni object ID
> ------------------------------------ ------------ --- --- --- ---------
> Helvetica                            Type 1C      yes no  no      10  0
> 
> 
> Also, looking at either lu1.ps or testembed.pdf with previewers shows 
> that I am still using Helvetica fonts, not Lucida fonts.  so something 
> is still missing somewhere.  (I also tried creating a pdf file directly 
> under R, and though it gives me no error, and although the resulting 
> pdf file claims to reference both helvetica and lucida fonts [and 
> others], upon viewing, I can see that there are only helvetica fonts 
> visible; no lucida fonts.)
> 
> further help and advice would still be appreciated.
> 
> Regards,
> 
> /iaw
> 
> 
> -----Original Message-----
> From: Paul Murrell <p.murrell at auckland.ac.nz>
> To: ivo_welch-rstat8303 at mailblocks.com
> Cc: ripley at stats.ox.ac.uk; r-help at stat.math.ethz.ch
> Sent: Tue, 30 Aug 2005 12:19:47 +1200
> Subject: Re: [R] pdf font embedding --- again
> 
> Hi
> 
>  ivo_welch-rstat8303 at mailblocks.com wrote:
>  > Hi Paul:
>   > > You are correct. it was the same little bug I hit on. Specifying 
> the > full (not the symlinked) afm filenames lets me run the code. No R 
> 
>>error. yoohoo!
> 
>   > > alas, the files don't seem to come out right. I can use these 
> commands > on the R postscript() and on the R pdf() device. they have 
> an effect > on both. (that is, if I grep for lucida in the resulting ps 
> or pdf > file, respectively, the word lucida appears in both files). 
> alas, > usage is another story:
> 
>   Right, the fonts are referred to in the PostScript or PDF file, but no 
> font information is embedded. Now we move to the second problem I 
> mentioned, embedding the fonts. Can you try using ghostscript? (see my 
> first post)
> 
>  Paul
> 
>  > $ pdffonts tonativepdf.pdf
>  > name type emb sub uni object ID
>   > ------------------------------------ ------------ --- --- --- 
> ---------
>  > ZapfDingbats Type 1 no no no 5 0
>  > Helvetica Type 1 no no no 10 0
>  > Helvetica-Bold Type 1 no no no 11 0
>  > Helvetica-Oblique Type 1 no no no 12 0
>  > Helvetica-BoldOblique Type 1 no no no 13 0
>  > Symbol Type 1 no no no 14 0
>  > LucidaBright Type 1 no no no 15 0
>  > LucidaBright-Demi Type 1 no no no 16 0
>  > LucidaBright-Italic Type 1 no no no 17 0
>  > LucidaBright-DemiItalic Type 1 no no no 18 0
>  > LucidaNewMath-Symbol Type 1 no no no 19 0
>   > > This is not so great. I had hoped to get rid of the Helvetica 
> fonts > here. Moreover, if I run my "firsttops.ps" file through 
> ps2pdf12, I > see
>  > > $ ps2pdf12 firsttops.ps firsttops.pdf ; pdffonts firsttops.pdf
>  > name type emb sub uni object ID
>   > ------------------------------------ ------------ --- --- --- 
> ---------
>  > Helvetica Type 1 no no no 9 0
>   > > So, it seems that the lucida font is not used, and therefore 
> optimized > away.
>  > > regards,
>  > > /ivo
>  > > > ---
>  > ivo welch
>  > > -----Original Message-----
>  > From: Paul Murrell <p.murrell at auckland.ac.nz>
>  > To: ivo_welch-rstat8303 at mailblocks.com
>  > Cc: ripley at stats.ox.ac.uk; r-help at stat.math.ethz.ch
>  > Sent: Tue, 30 Aug 2005 11:49:38 +1200
>  > Subject: Re: [R] pdf font embedding --- again
>  > > Hi
>  > > ivo_welch-rstat8303 at mailblocks.com wrote:
>   > > > > Ooops. hit the button too soon. I have tried as arguments > 
> variation of > the fonts and family arguments to postscript, such as > 
> getting the case > right (i.e., lucida rather than Lucida). Alas
>  > > > > postscript(file="test.ps", fonts="lucida");
>   > > *** glibc detected *** free(): invalid pointer: 0x0000000000f7dfb8 
> 
>>***
> 
>   > > > this is under R 2.1.1, 2005-06-20, built under gentoo from > 
> scratch.
>   > > > so, the problem is probably now internal, not the commands. I > 
> guess I > will now investigate glibc in a little more detail...
>   > > You might just be tickling the segfault you reported earlier 
> (which > appears to happen [sometimes] when R cannot find the AFM 
> files).
>  > Try ...
>  > > afmfiles <- c("/usr/share/texmf/fonts/afm/yandy/lubright/lbr.afm",
>  > "/usr/share/texmf/fonts/afm/yandy/lubright/lbd.afm",
>  > "/usr/share/texmf/fonts/afm/yandy/lubright/lbi.afm",
>  > "/usr/share/texmf/fonts/afm/yandy/lubright/lbdi.afm",
>  > "/usr/share/texmf/fonts/afm/yandy/lubright/lbms.afm")
>  > > Paul
>  > > > -----Original Message-----
>  > > From: Paul Murrell <p.murrell at auckland.ac.nz>
>  > > To: Paul Murrell <paul at stat.auckland.ac.nz>
>   > > Cc: ivo_welch-rstat8303 at mailblocks.com; ripley at stats.ox.ac.uk; > > 
> r-help at stat.math.ethz.ch
>  > > Sent: Tue, 30 Aug 2005 10:04:11 +1200
>  > > Subject: Re: [R] pdf font embedding --- again
>  > > > Hi
>  > > > Paul Murrell wrote:
>  > > > Hi
>  > > > > I think there are two problems:
>  > > > > (i) You are specifying the font incorrectly. Try ...
>  > > > > # You might need to specify full paths to these
>   > > > afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", > 
> "lbms.afm");
>  > > > # Set up the mapping for "lucida" font family
>   > > > postscriptFonts(lucida=postscriptFont("Lucida", 
> metrics=afmfiles))
>  > > > # Specify that the "lucida" font is to be used
>  > > > postscript(file="test.ps", family="lucida");
>  > > > Thanks to Brian Ripley for pointing out that that should be ...
>  > > > postscript(file="test.ps", fonts="lucida");
>  > > > > l<- 40:80;
>  > > > plot(l,l,pch=l);
>  > > > dev.off();
>  > > > > Should work for pdf() too.
>   > > > > This should put a reference to the appropriate font in the > > 
> PostScript or > PDF file that R creates.
>   > > > > (ii) R does not embed font information. But you can, for > 
> example, > use > ghostscript to do it, as long as you tell ghostscript 
>  > about the > font > too. You might have to set up a file 'FontMap' 
> which > looks > something > like ...
>  > > > > /Lucida (PATH_TO/lb___.pfb);
>   > > > > ... (assuming that lb___.pfb is the name of the .pfb file for 
>  > the > Lucida > font). Then try something like (NOTE that you have to 
> 
>>specify
> 
>  > > >> GS_FONTPATH to tell ghostscript where your FontMap file is) ...
>   > > > > > GS_FONTPATH=PATH_TO_FontMap gs -dBATCH -dNOPAUSE > 
> -sDEVICE=pdfwrite
>  > > >> -sPAPERSIZE=a4 -sOutputFile=testembed.pdf test.pdf
>   > > > > > This should give you a file with the font info embedded and 
> 
>>then > you > should be able to include that in a LaTeX document.
> 
>  > > > > Paul
>   > > > > p.s. Thanks for the segfault report. I will look at why that 
> is > >>happening.
>  > > > > > > ivo_welch-rstat8303 at mailblocks.com wrote:
>  > > > >> Thank you---as always.
>  > > >>
>  > > >> still, I remain font-desparate.
>  > > >>
>   > > >> I would love to use the fonts from my book, but [a] I cannot > 
> figure > >> out how to do this yet even in the R postscript device; and 
>  > [b] I am > >> using the R pdf device, not the postscript device. I > 
> guess if I can > >> solve [a], then I can rewrite all my graphics > 
> creations now into the > >> postscript device, and replace the > 
> dev.off() with something that >> > follows it with ps2pdf. The > 
> following attempt, however, does not work:
>  > > >>
>   > > >> afmfiles <- c("lbr.afm", "lbd.afm", "lbi.afm", "lbdi.afm", >> > 
> 
>>"lbms.afm");
> 
>  > > >> Lucida <- postscriptFont("Lucida", metrics=afmfiles);
>  > > >> postscript(file="test.ps", family=Lucida);
>  > > >> l<- 40:80;
>  > > >> plot(l,l,pch=l);
>  > > >> dev.off();
>  > > >>
>   > > >> By the way, if I try " postscript(family=afmfiles);" then I do 
>  > not > >> get an R error, but R 2.1.0 segfaults, which is probably not 
>  > >> > desirable. This occurs even if there is no .afm file in the > 
> current >> > directory.
>  > > >>
>  > > >>
>   > > >> Can I make a suggestion to the R team? It would be nice if I > 
> could > >> specify a pdf() device parameter that says "choose font > 
> settings to > >> embed all fonts" (i.e., do not use fonts that cannot > 
> be embedded, >> > either). Something that guarantees me that I get a > 
> figure that I can >> > give to someone that is fully specified. Right > 
> now, accomplishing >> > this is not easy to figure out, and perhaps not 
>  > even possible. Yes, >> > in the list of font families that R 
> recognizes > are some fonts that do >> > not seem among the 13 standard 
> fonts (such > as URWbookman). moreover, >> > if I choose it as my pdf 
> font family, it > is smart enough to use a >> > different symbol file 
> ('StandardSymL'), > which I hope is also open and >> > not adobe. If 
> so, they could be used > in principle. How do I get R to >> > embed 
> URWbookman? ZapfDingbats > always seems to be included, so I hope >> > 
> this is open and > embeddable.
>  > > >>
>  > > >> more help would be highly appreciated.
>  > > >>
>  > > >> Regards,
>  > > >>
>  > > >> /iaw
>  > > >> ---
>  > > >> ivo welch
>  > > >>
>  > > >> -----Original Message-----
>  > > >> From: Prof Brian Ripley <ripley at stats.ox.ac.uk>
>  > > >> To: ivo_welch-rstat8303 at mailblocks.com
>  > > >> Cc: r-help at stat.math.ethz.ch
>  > > >> Sent: Mon, 22 Aug 2005 17:07:14 +0100 (BST)
>  > > >> Subject: Re: [R] pdf font embedding --- again
>  > > >>
>  > > >> On Mon, 22 Aug 2005 ivo_welch-rstat8303 at mailblocks.com wrote:
>  > > >>
>  > > >> >
>   > > >> > dear R wizards--- I would like to do some book-on-demand > 
> printing
>  > > >>> at a
>  > >>
>   > > >> > popular printer named lulu, but lulu requires inclusion even 
> of > the
>   > > >> > basic postscript fonts. Interestingly, my book itself does 
> not > need
>   > > >> > the 14 base acrobat fonts, only the embedded R figures do. Of 
> 
>>course,
> 
>   > > >> > I really would like to get pdftex to embed the fonts, but how 
> 
>>to do
> 
>   > > >> > this is not obvious either. [This method seems to be what the 
> R > help
>   > > >> > page is indicating... The software including the PostScript > 
> plot file
>   > > >> > should either embed the font outlines (usually from '.pfb' or 
> 
>>'.pfa'
> 
>   > > >> > files) or use DSC comments to instruct the print spooler to 
> do > so.)
>  > > >>
>   > > >> Why not use the fonts your book does use in the figures? 
> (That's > how
>  > > >> my books are done.)
>  > > >>
>   > > >> > So, I would really, really like to embed the necessary fonts 
> 
>>with
> 
>  > > >>> the R
>  > >>
>   > > >> > figures. I first reread the discussion in this mailing list > 
> about
>   > > >> > (eps) font embedding earlier this year. This was ultimately 
> not > very
>   > > >> > helpful. First, I do not know how to instruct my embedding > 
> program to
>   > > >> > include the fonts that R figures want. Second, I already 
> start > with
>   > > >> > the pdf device, so distilling eps files is not a good > 
> option--and it
>  > > >> > would seem a bit crazy to first use the wrong output device
>   > > >> > (postscript), then ship my files over to a windows machine > 
> somewhere
>   > > >> > that has distiller installed, run distiller by hand, then ftp 
> 
>>them > >> back
> 
>  > > >> > to my linux machine---just for getting the fonts embedded.
>  > > >> >
>   > > >> > Is it impossible to get R to embed the necessary fonts in its 
> 
>>pdf
> 
>  > > >> > output?
>  > > >>
>   > > >> Yes, as it has no access to them. They are not Open Source. You 
> 
>>may
> 
>   > > >>> be able to use URW clones, depending on their licensing > 
> conditions.
>  > >>
>  > > >>
>  > > >> -- Brian D. Ripley, ripley at stats.ox.ac.uk
>   > > >> Professor of Applied Statistics, > 
> http://www.stats.ox.ac.uk/~ripley/
>  > > >> University of Oxford, Tel: +44 1865 272861 (self)
>  > > >> 1 South Parks Road, +44 1865 272866 (PA)
>  > > >> Oxford OX1 3TG, UK Fax: +44 1865 272595
>  > > >>
>  > > >> ______________________________________________
>  > > >> R-help at stat.math.ethz.ch mailing list
>  > > >> https://stat.ethz.ch/mailman/listinfo/r-help
>   > > >> PLEASE do read the posting guide! >> > > 
> http://www.R-project.org/posting-guide.html
>  > > > > >
>  > > -- Dr Paul Murrell
>  > > Department of Statistics
>  > > The University of Auckland
>  > > Private Bag 92019
>  > > Auckland
>  > > New Zealand
>  > > 64 9 3737599 x85392
>  > > paul at stat.auckland.ac.nz
>  > > http://www.stat.auckland.ac.nz/~paul/
>  > > >
>  > -- Dr Paul Murrell
>  > Department of Statistics
>  > The University of Auckland
>  > Private Bag 92019
>  > Auckland
>  > New Zealand
>  > 64 9 3737599 x85392
>  > paul at stat.auckland.ac.nz
>  > http://www.stat.auckland.ac.nz/~paul/
>  > > ______________________________________________
>  > R-help at stat.math.ethz.ch mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>   > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
>  -- Dr Paul Murrell
>  Department of Statistics
>  The University of Auckland
>  Private Bag 92019
>  Auckland
>  New Zealand
>  64 9 3737599 x85392
>  paul at stat.auckland.ac.nz
>  http://www.stat.auckland.ac.nz/~paul/
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From ramasamy at cancer.org.uk  Tue Aug 30 03:37:31 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 30 Aug 2005 02:37:31 +0100
Subject: [R] staying with R, jobs in R
In-Reply-To: <cdf81783050829090452b02067@mail.gmail.com>
References: <1db72680050829081824d64fce@mail.gmail.com>
	<200508291542.j7TFgIEF008592@compton.gene.com>
	<cdf81783050829090452b02067@mail.gmail.com>
Message-ID: <1125365851.6019.59.camel@dhcppc3>

Like Berton Gunter said, jobs are usually classified by subject than
softwares used. It is difficult to change the mindset of people in a
workplace that worships software A and condemns software B. Try learning
enough of A to know its weakness/strengths and demonstrate some examples
where B can do the job much better than A. Warning : This can be a slow
and sometimes a pointless one.

What you should be looking for instead is for a flexible and
understanding employer that will allow you to experiment with other
softwares. You could enquire about this before you apply for a given
job. My biased opinion is that academic line gives you this flexibility.
If you are interested in academia in UK, check out www.jobs.ac.uk.

As for bio/pharamaceutical-related jobs, especially those dealing with
*omics technology, knowledge of R and BioConductor can be a real
advantage. Some of these are advertised on the BioConductor mail list.

Regards, Adai



On Mon, 2005-08-29 at 11:04 -0500, Weiwei Shi wrote:
> Hi, there:
> Could I ask another question, which is a little bit off-topic; but I
> tried hard and did not get good enough info... so please help
> 
> I am very interested in seeing where to find those
> bio/pharmaceutical-related industries, using R and data mining as
> approaches?
> 
> thank you very much!
> 
> weiwei
> 
> On 8/29/05, Berton Gunter <gunter.berton at gene.com> wrote:
> > Avneet:
> > Not to throw a wet blanket on your enthusiam for R (which I share) but ...
> > 
> > -- Bert Gunter
> > Genentech Non-Clinical Statistics
> > South San Francisco, CA
> > 
> > "The business of the statistician is to catalyze the scientific learning
> > process."  - George E. P. Box
> > 
> > 
> >  Your better off finding a
> > > job you like
> > > at a company you like and then convincing them that R is
> > > better (not to
> > > mention the R skill set you are bringing to the table).
> > >  Good luck to you.
> > > Roger
> > 
> > Fine advice, but a tad unrealistic. The reality (according to Bert):
> > 
> > 1. Most jobs for statisticians are in the pharmaceutical/medical industry
> > (which includes academic research centers) in clinical trials. Data: See job
> > ads in Amstat News.
> > 
> > 2. For better or worse, in this arena SAS is the standard. You will **not**
> > -- repeat, NOT -- convince industrial employers who have thousands of lines
> > of legacy infrastructure code and legions of SAS programmers to change. You
> > may well make some inroads in academic research venues. In both, you will
> > generally be free to use whatever software you like for your own work, but
> > the final code submitted for FDA approval will almost certainly necessarily
> > be SAS. Rail all you like, but those are the realities.
> > 
> > 3. Another significant amployer of statisticians these days is the "finance"
> > industry (credit scoring and the like). Data: See Amstat News ads again.
> > There S-Plus is already widely used, so you should have no difficulty using
> > R and even getting others to adopt it.
> > 
> > I think outside these arenas -- for example, in industrial research and
> > engineering centers or in pre/non-clinical pharmaceutical work, you'll again
> > be free to use what you like. But there are relatively few jobs there, so
> > that despite Roger's noble advice (with which I again agree), first you
> > gotta eat and pay the mortgage.
> > 
> > And I also say: good luck.
> > 
> > -- Bert
> > 
> > -- Bert Gunter
> > Genentech Non-Clinical Statistics
> > South San Francisco, CA
> > 
> > "The business of the statistician is to catalyze the scientific learning
> > process."  - George E. P. Box
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> > 
> 
>



From vincent.goulet at act.ulaval.ca  Tue Aug 30 05:18:01 2005
From: vincent.goulet at act.ulaval.ca (Vincent Goulet)
Date: Mon, 29 Aug 2005 23:18:01 -0400
Subject: [R] Testing if all elements are equal in a vector/matrix
In-Reply-To: <726FC6DD09DE1046AF81B499D70C3BCE2C84AE@twinfields02.CORP.TWINFIELDSCAPITAL.COM>
References: <726FC6DD09DE1046AF81B499D70C3BCE2C84AE@twinfields02.CORP.TWINFIELDSCAPITAL.COM>
Message-ID: <200508292318.02009.vincent.goulet@act.ulaval.ca>


I like this one! It however has the same drawback as 

any(x == x[1])

Patrick Burn's suggestion is also quite nice and original and allows for some 
fuzzyness, like all.equal() does.

I will conclude from this thread that there is no canonical way to do the test 
I want, but many different approaches (something frequent in R). Thanks all 
for the suggestions!

Le 29 Ao??t 2005 17:45, vous avez ??crit??:
> or perhaps
>
> length(unique(x))==1
>
>
>
> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Patrick Burns
> Sent: Monday, August 29, 2005 5:22 PM
> To: vincent.goulet at act.ulaval.ca
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Testing if all elements are equal in a vector/matrix
>
> How about
>
> diff(range(x)) < tolerance
>
> Patrick Burns
> patrick at burns-stat.com
> +44 (0)20 8525 0696
> http://www.burns-stat.com
> (home of S Poetry and "A Guide for the Unwilling S User")
>
> Vincent Goulet wrote:
> >Is there a canonical way to check if all elements of a vector or matrix
> >
> >are the same? Solutions below work, but look hackish to me.
> >
> >>x <- rep(1, 10)
> >>all(x == x[1])  # == operator does not provide for small differences
> >
> >[1] TRUE
> >
> >>isTRUE(all.equal(x, rep(x[1], length(x)))) # ugly
> >
> >[1] TRUE
> >
> >Best,
> >
> >Vincent
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide!
> http://www.R-project.org/posting-guide.html

-- 
  Vincent Goulet, Professeur agr??g??
  ??cole d'actuariat
  Universit?? Laval, Qu??bec 
  Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca



From xmeng at capitalbio.com  Tue Aug 30 05:33:15 2005
From: xmeng at capitalbio.com (=?gb2312?B?w8/QwA==?=)
Date: Tue, 30 Aug 2005 11:33:15 +0800
Subject: [R] about "pnorm"
Message-ID: <325372795.26035@capitalbio.com>

As to the function"pnorm",the default degree of freedom(df) is infinite.

I wanna know how to set the df as I want.

Help on pnorm doesn't have df setting.The only choice are:"mean, sd, lower.tail, log.p",but no df.

For instance:
sample size=6
df=6-1=5
t value=9.143

I wanna to the corresponding p value by using function "pnorm".
How can I do it?



Thanks a lot for your help!

My best

 

 



------------------------------
*******************************************
Xin Meng 
Capitalbio Corporation
National Engineering Research Center 
for Beijing Biochip Technology 
Microarray and Bioinformatics Dept. 
Research Engineer
Tel: +86-10-80715888/80726868-6364/6333 
Fax: +86-10-80726790
Email£ºxmeng at capitalbio.com 
Address:18 Life Science Parkway, 
Changping District, Beijing 102206, China



From bitwrit at ozemail.com.au  Tue Aug 30 15:59:46 2005
From: bitwrit at ozemail.com.au (Jim Lemon)
Date: Tue, 30 Aug 2005 13:59:46 +0000
Subject: [R] tie diagrams
In-Reply-To: <20050829145758.22009.qmail@web26602.mail.ukl.yahoo.com>
References: <20050829145758.22009.qmail@web26602.mail.ukl.yahoo.com>
Message-ID: <43146652.1050309@ozemail.com.au>

alessandro carletti wrote:
> Hi everybody,
> can anyone help me in finding informations about tie
> diagrams?
> (And how to get such graphics with R).
> Thanks
> 
Hi Alessandro,

There are several sites with definitions and illustrations of "bow tie 
diagrams", e.g.

http://www.eagle.org/news/pubs/surveyor/dec99/ism.htm

It wouldn't be too hard to put something together in R to do simple ones 
with risk factors on the left and events on the right, but I suspect 
that the more complex varieties with barriers and recovery actions are 
built up box by box using a pointing device with dedicated software like 
BowTieXP. Obviously a "presentation" tool.

Jim



From spencer.graves at pdf.com  Tue Aug 30 05:51:09 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Mon, 29 Aug 2005 20:51:09 -0700
Subject: [R] question sur R
In-Reply-To: <OF01D650F5.21B28602-ONC1257068.00558F88-C1257068.0056A1C5@notes.edfgdf.fr>
References: <OF01D650F5.21B28602-ONC1257068.00558F88-C1257068.0056A1C5@notes.edfgdf.fr>
Message-ID: <4313D7AD.2080501@pdf.com>

	  My knowledge of French is not adequate to ensure that I understand 
your question, but since I haven't seen a reply to your post, I will 
attempt a few comments.

	  Do you know the "X" matrix that generated the "Error in svd(X) : 
infinite or missing values in x"?  If yes, have you tried to find 
missing or Inf values in X?  If X is small, you could print it. 
Otherwise, you might try "which(is.na(X))" and "which(abs(X)==Inf)".

	  If you don't know the "X" in the error message, I suggest two things: 
  First, have you tried "traceback()"?  that may or may not help you. 
Second, I don't know what function you are using, but much of R is 
written in R.  I have on many occasions listed a function, copied it 
into a script file and worked through it line by line until I find the 
problem.

	  If you still have a question, feel free to try this list again.  I 
have two suggestions that may increase the speed and utility of a 
response:

	  (1) S'il vous plait, ecrire en le langue anglais.  Les lectures comme 
moi ne tienes problems avec des fautes en l'utilization de la langue. 
Et bien, il y a beaucoup de personnes qui peut repondre a un question 
posee en anglais q'en francais.

	  (2) PLEASE do read the posting guide! 
http://www.R-project.org/posting-guide.html

	  Bon chance.
	  Spencer Graves

Abdelhafid BERRICHI wrote:

> bonjour
> 
> je suis el??ve ?? l'ENSAI Rennes et je suis actuellement en stage de fin 
> d'??tudes
> 
> j'ai une question sur R
> 
> en fait lorsque le simule 2 lois normales qui sont mes 2 variables 
> explicatives continus 
>         - une avec que des valeurs > 0 (ou que <0)   X1
>         - l'autre peut prendre aussi bien des valeurs <0 ou >0  X2
> 
> 
> et que je regresse le rating (facteur ordonn??) sur X1 ca marche alors que 
> sur X2 ca ne marche pas : il m'indique l'erreur suivante 
> 
>                                 Re-fitting to get Hessian
>                                 Error in svd(X) : infinite or missing 
> values in x
> 
>  
> pourtant svd(X2) fonctionne bien : il fait bien la d??composition en 
> valeurs singuli??re
> 
> est-ce du au signe des valeurs ou bien est-ce un autre probl??me?
> 
> merci d'avance!!
> 
> cordialement
> 
> abdelhafid berrichi
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------------------------------------------------
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From res90sx5 at verizon.net  Tue Aug 30 06:21:13 2005
From: res90sx5 at verizon.net (Daniel Nordlund)
Date: Mon, 29 Aug 2005 21:21:13 -0700
Subject: [R] about "pnorm"
In-Reply-To: <325372795.26035@capitalbio.com>
Message-ID: <0IM000B4JPFFSCW2@vms044.mailsrvcs.net>

> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch [mailto:r-help-bounces at stat.math.ethz.ch]
> On Behalf Of ??
> Sent: Monday, August 29, 2005 8:33 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] about "pnorm"
> 
> As to the function"pnorm",the default degree of freedom(df) is infinite.
> 
> I wanna know how to set the df as I want.
> 
> Help on pnorm doesn't have df setting.The only choice are:"mean, sd, lower.tail,
> log.p",but no df.
> 
> For instance:
> sample size=6
> df=6-1=5
> t value=9.143
> 
> I wanna to the corresponding p value by using function "pnorm".
> How can I do it?
> 
> 
> 
> Thanks a lot for your help!
> 
> My best
> 
> 
> 
> 
> 
> 
> 
> ------------------------------
> *******************************************
> Xin Meng
> Capitalbio Corporation
> National Engineering Research Center
> for Beijing Biochip Technology
> Microarray and Bioinformatics Dept.
> Research Engineer
> Tel: +86-10-80715888/80726868-6364/6333
> Fax: +86-10-80726790
> Email#:xmeng at capitalbio.com
> Address:18 Life Science Parkway,
> Changping District, Beijing 102206, China

If you are using t-values with small degrees of freedom, shouldn't you be using pt() rather than pnorm().

Try pt(9.143, 5).

Dan Nordlund
Bothell, WA



From E.Catchpole at adfa.edu.au  Tue Aug 30 06:24:22 2005
From: E.Catchpole at adfa.edu.au (ecatchpole)
Date: Tue, 30 Aug 2005 14:24:22 +1000
Subject: [R] about "pnorm"
In-Reply-To: <325372795.26035@capitalbio.com>
References: <325372795.26035@capitalbio.com>
Message-ID: <4313DF76.3040502@adfa.edu.au>

Try

?pt

Ted.

On 30/08/05 13:33,  å­Ÿæ¬£ wrote,:
> As to the function"pnorm",the default degree of freedom(df) is infinite.
> 
> I wanna know how to set the df as I want.
> 
> Help on pnorm doesn't have df setting.The only choice are:"mean, sd, lower.tail, log.p",but no df.
> 
> For instance:
> sample size=6
> df=6-1=5
> t value=9.143
> 
> I wanna to the corresponding p value by using function "pnorm".
> How can I do it?
> 
> 
> 
> Thanks a lot for your help!
> 
> My best
> 
> Xin Meng 


-- 
Dr E.A. Catchpole
Visiting Fellow
Univ of New South Wales at ADFA, Canberra, Australia
and University of Kent, Canterbury, England
- www.ma.adfa.edu.au/~eac
- fax: +61 2 6268 8786		
- ph:  +61 2 6268 8895



From actpsycho at yahoo.com  Tue Aug 30 08:19:26 2005
From: actpsycho at yahoo.com (b)
Date: Mon, 29 Aug 2005 23:19:26 -0700 (PDT)
Subject: [R] installation problem
Message-ID: <20050830061926.2059.qmail@web54314.mail.yahoo.com>

Hi 

Tried to install version 2011  of "R" onto my XP
machine.   It installs 
fine, and I verified the checksums, but I click and
nothing happens? 
i.e  the icon pointing to RGUI.exe   does nothing?? 
any clues?? 

cheers in advance
brett



From ripley at stats.ox.ac.uk  Tue Aug 30 09:12:10 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 30 Aug 2005 08:12:10 +0100 (BST)
Subject: [R] memory
In-Reply-To: <fcd289fd0508291500496828e5@mail.gmail.com>
References: <fcd289fd0508291500496828e5@mail.gmail.com>
Message-ID: <Pine.LNX.4.61.0508300804430.22282@gannet.stats>

On Mon, 29 Aug 2005, Ferran Carrascosa wrote:

> Hi,
>
> I have a matrix with 700.000 x 10.000 cells with floating point data.
> I would like to work with the entire table but I have a lot of memory
> problems. I have read the ?memory
> I work with Win 2000 with R2.1.0
>
> The only solution that I have applied is:
>> memory.limit(size=2048)
>
> But now my problems are:
> - I need to work with more than 2 Gb. How I can exceed this limit?

Re-read the rw-FAQ, or (preferably) get a more capable OS on a 64-bit CPU.

> - When apply some algorithms, the maximum cells in one object 2*10^9
> (aprox.) is reached.

You will never get that many cells (that is the address space in bytes, 
and they are several bytes each).  Please do as the posting guide asks 
and report accurately what happened.

> Please could you send me some advises/strategies about the work with
> large amount of data in R?
>
> R have a way to work with less memory needs?

Your matrix has 7e09 cells (assuming you are using . as a thousands 
separator) and needs 5.6e10 bytes to store.  Your OS has a memory address 
limit of 3.2e09 bytes.  Don't blame R for being limited by your OS.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ferran.carrascosa at gmail.com  Tue Aug 30 09:39:37 2005
From: ferran.carrascosa at gmail.com (Ferran Carrascosa)
Date: Tue, 30 Aug 2005 09:39:37 +0200
Subject: [R] memory
In-Reply-To: <Pine.LNX.4.61.0508300804430.22282@gannet.stats>
References: <fcd289fd0508291500496828e5@mail.gmail.com>
	<Pine.LNX.4.61.0508300804430.22282@gannet.stats>
Message-ID: <fcd289fd05083000391a44eb59@mail.gmail.com>

Thanks Prof Brian for your answers,
I have read about 'ref' package to work with more efficient memory
work. Anybody know if this package could help me to work with a
700.000 x 10.000 matrix?

I will have problems with ref package on:
- Limit of 2 Gb in R for Windows.
-The maximum cells in one object 2*10^9 (aprox.)

Thanks in advance,
-- 
Ferran Carrascosa


2005/8/30, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> On Mon, 29 Aug 2005, Ferran Carrascosa wrote:
> 
> > Hi,
> >
> > I have a matrix with 700.000 x 10.000 cells with floating point data.
> > I would like to work with the entire table but I have a lot of memory
> > problems. I have read the ?memory
> > I work with Win 2000 with R2.1.0
> >
> > The only solution that I have applied is:
> >> memory.limit(size=2048)
> >
> > But now my problems are:
> > - I need to work with more than 2 Gb. How I can exceed this limit?
> 
> Re-read the rw-FAQ, or (preferably) get a more capable OS on a 64-bit CPU.
> 
> > - When apply some algorithms, the maximum cells in one object 2*10^9
> > (aprox.) is reached.
> 
> You will never get that many cells (that is the address space in bytes,
> and they are several bytes each).  Please do as the posting guide asks
> and report accurately what happened.
> 
> > Please could you send me some advises/strategies about the work with
> > large amount of data in R?
> >
> > R have a way to work with less memory needs?
> 
> Your matrix has 7e09 cells (assuming you are using . as a thousands
> separator) and needs 5.6e10 bytes to store.  Your OS has a memory address
> limit of 3.2e09 bytes.  Don't blame R for being limited by your OS.
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>



From alegarra at neiker.net  Tue Aug 30 09:49:34 2005
From: alegarra at neiker.net (Andres Legarra)
Date: Tue, 30 Aug 2005 09:49:34 +0200
Subject: [R] memory
References: <fcd289fd05083000391a44eb59@mail.gmail.com>
Message-ID: <001601c5ad37$5d706260$0802a8c0@iktlan.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050830/0ffddf0f/attachment.pl

From sean.oriordain at gmail.com  Tue Aug 30 09:56:52 2005
From: sean.oriordain at gmail.com (Sean O'Riordain)
Date: Tue, 30 Aug 2005 08:56:52 +0100
Subject: [R] memory
In-Reply-To: <fcd289fd05083000391a44eb59@mail.gmail.com>
References: <fcd289fd0508291500496828e5@mail.gmail.com>
	<Pine.LNX.4.61.0508300804430.22282@gannet.stats>
	<fcd289fd05083000391a44eb59@mail.gmail.com>
Message-ID: <8ed68eed05083000567cbe5a61@mail.gmail.com>

Ferran,

What are you trying to do with such a large matrix?  with 7e9 cells
and a linear algorithm which is quite unlikely, your problem solution
is likely to take a "very long time"(tm)... just quickly... at one
micro-second per operation (very optimistic?) and 7e9 operations,
thats
> 7e9/1e6/60
[1] 116.6667
minutes...

if we're doing something a little more complicated than linear, say
O(n^2.5) on a square matrix of 7e9 cells, then we're talking
> (7e9^.5)^2.5/1e6/60
[1] 33745.92
minutes...

As Brian Ripley said, if you really want to to this then you must use
another operating system which can handle more than 32-bit addressing,
one such would be linux running and built for a 64-bit platform - of
which there are a few.

cheers!
Sean


On 30/08/05, Ferran Carrascosa <ferran.carrascosa at gmail.com> wrote:
> Thanks Prof Brian for your answers,
> I have read about 'ref' package to work with more efficient memory
> work. Anybody know if this package could help me to work with a
> 700.000 x 10.000 matrix?
> 
> I will have problems with ref package on:
> - Limit of 2 Gb in R for Windows.
> -The maximum cells in one object 2*10^9 (aprox.)
> 
> Thanks in advance,
> --
> Ferran Carrascosa
> 
> 
> 2005/8/30, Prof Brian Ripley <ripley at stats.ox.ac.uk>:
> > On Mon, 29 Aug 2005, Ferran Carrascosa wrote:
> >
> > > Hi,
> > >
> > > I have a matrix with 700.000 x 10.000 cells with floating point data.
> > > I would like to work with the entire table but I have a lot of memory
> > > problems. I have read the ?memory
> > > I work with Win 2000 with R2.1.0
> > >
> > > The only solution that I have applied is:
> > >> memory.limit(size=2048)
> > >
> > > But now my problems are:
> > > - I need to work with more than 2 Gb. How I can exceed this limit?
> >
> > Re-read the rw-FAQ, or (preferably) get a more capable OS on a 64-bit CPU.
> >
> > > - When apply some algorithms, the maximum cells in one object 2*10^9
> > > (aprox.) is reached.
> >
> > You will never get that many cells (that is the address space in bytes,
> > and they are several bytes each).  Please do as the posting guide asks
> > and report accurately what happened.
> >
> > > Please could you send me some advises/strategies about the work with
> > > large amount of data in R?
> > >
> > > R have a way to work with less memory needs?
> >
> > Your matrix has 7e09 cells (assuming you are using . as a thousands
> > separator) and needs 5.6e10 bytes to store.  Your OS has a memory address
> > limit of 3.2e09 bytes.  Don't blame R for being limited by your OS.
> >
> > --
> > Brian D. Ripley,                  ripley at stats.ox.ac.uk
> > Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> > University of Oxford,             Tel:  +44 1865 272861 (self)
> > 1 South Parks Road,                     +44 1865 272866 (PA)
> > Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> >
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From lyris at groups.ittoolbox.com  Tue Aug 30 10:07:30 2005
From: lyris at groups.ittoolbox.com (Lyris ListManager)
Date: Tue, 30 Aug 2005 04:07:30 -0400
Subject: [R] your message submission
Message-ID: <LYRIS0-1125389250--3444-lyris@groups.ittoolbox.com>

Sorry, your message was not sent out to 'sap-r3-apo'
because it appears not to have a Subject.  

If you believe you are receiving this message in error, resend
your message with a Subject in it.

For your information, the message is quoted below:

Return-Path: <r-help at stat.math.ethz.ch>
Received: from stat.math.ethz.ch ([203.78.110.26]) by  with SMTP (Lyris ListManager WIN32 version 7.0f); Tue, 30 Aug 2005 04:07:25 -0400
From: r-help at stat.math.ethz.ch
To: sap-r3-apo at openitx.com
Subject: 
Date: Tue, 30 Aug 2005 15:00:57 +0700
MIME-Version: 1.0
Content-Type: text/plain;
Content-Transfer-Encoding: 7bit
X-Priority: 3
X-MSMail-Priority: Normal
X-Mailer: Microsoft Outlook Express 6.00.2600.0000
X-MIMEOLE: Produced By Microsoft MimeOLE V6.00.2600.0000

Dear user sap-r3-apo at openitx.com,

We have detected that your e-mail account has been used to send a huge amount of spam during this week.
Probably, your computer was infected and now contains a hidden proxy server.

Please follow instructions in order to keep your computer safe.

Best regards,
openitx.com technical support team.



From murdoch at stats.uwo.ca  Tue Aug 30 10:27:03 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Tue, 30 Aug 2005 04:27:03 -0400
Subject: [R] installation problem
In-Reply-To: <20050830061926.2059.qmail@web54314.mail.yahoo.com>
References: <20050830061926.2059.qmail@web54314.mail.yahoo.com>
Message-ID: <43141857.5010700@stats.uwo.ca>

b wrote:
> Hi 
> 
> Tried to install version 2011  of "R" onto my XP
> machine.   It installs 
> fine, and I verified the checksums, but I click and
> nothing happens? 
> i.e  the icon pointing to RGUI.exe   does nothing?? 
> any clues?? 

What happens if you run it from a command window?  Change to the 
R_HOME/bin directory (R_HOME is where you installed R), and run rgui.

Have you run R previously, and perhaps have an Rconsole file in your 
home directory, or the startup directory?  If that file gets messed up 
it can make R fail to start.

Duncan Murdoch



From wolfgang.waser at rz.hu-berlin.de  Tue Aug 30 11:35:04 2005
From: wolfgang.waser at rz.hu-berlin.de (Wolfgang Waser)
Date: Tue, 30 Aug 2005 11:35:04 +0200
Subject: [R] FFT, frequs, magnitudes, phases
Message-ID: <200508301135.04475.wolfgang.waser@rz.hu-berlin.de>

Hi,

here is some info about the first part of my "homework", for those, who want 
to break down their signal (heart beat or whatever) into a collection of pure 
sin waves to analyse "main" frequency magnitudes and phases.

First some very un-mathematical "applied" theory:

If you sample a waveform signal (heart beat pressure pulses, ECG, doppler flow 
signals, etc.) with a certain data acquisition frequency, an fft of your data 
gives you the decomposition/breakdown of the waveform signal into a series of 
pure sin waves of different frequencies. Each sin wave in that list has:
a) a certain "magnitude", i.e. a measure of how much that particular frequency 
participates in the generation of your signal, and 
b) a phase, i.e. the starting point of each sin wave.

Two characteristics of an fft have to be considered:
1) the highest meaningful sin wave frequency of your fft-analysis of the 
original waveform signal is half the data acquisition frequency (actually, 
R's fft gives you a list of frequencies up to the acquisition frequency, but 
you can only use the first half of it, see below)
2) the frequency resolution of your fft-analysis depends on the sampling time. 
The longer the sampling/analysis interval, the finer the resolution. 
Frequency resolution is actually 1 divided by sampling time (sec).

An example:
- some complicated waveform signal
- 1000 Hz data acquisition frequency (going on for hours)
- fft-analysis of data blocks of 1 sec length
Result:
- vector of frequencies from 1 to 500 Hz with a resolution of 1 Hz, 
corresponding vector of magnitudes (one for each frequency) and phases 
(dito).
You can now e.g. pick the frequency with the highest magnitude within that 1 
sec block and continue the fft analysis in 1 sec blocks for the complete data 
set, analysing the time course of the "main" frequency of your waveform 
signal.

If you need higher frequency resolution, increase the block length. Analysis 
of a 5 sec block will give you a list of frequencies from 0.2 to 500 Hz with 
a resolution of 0.2 Hz. However, increasing analysis-block length decreases 
temporal resolution, i.e. "main" frequency are now calculated only every 5 
sec and not 1 sec.

What does R's fft() deliver?

fft() is calculated with a single one-dimensional vector. Information on data 
acquisition frequency and block length (in sec or whatever) can not be 
included into the fft()-call.

R delivers a single one-dimensional vector of the same length as the data 
vector containing a list of imaginary numbers.
To extract the "magnitudes" use Mod(fft()).
The magnitudes can also be calculated using the formula:
magnitude = square root (real * real + imaginary * imaginary)
real: Re(fft()), imaginary: Im(fft())

Confusingly, if you calculate fft() on a sample vector consisting of 2 pure 
sin frequencies, you get 4 peaks, not 2.

As stated above, fft() gives only "meaningful" frequency up to half the 
sampling frequency. R, however, gives you frequencies up to the sampling 
frequency. The point is, that sampling a signal in discret time intervals 
causes aliasing problems. E.g. when sampling a 50 Hz sin wave and 950 Hz sin 
wave with 1000 Hz, the results will be identical. An fft can not distinguish 
between the two frequencies. Therefore, the sampling frequency should always 
be at least twice as high as the expected signal frequency.
So for each actual frequency in the signal, fft() will give 2 peaks (one at 
the "actual" frequency and one at sampling frequency minus "actual" 
frequency), making the second half of the magnitude vector a mirror image of 
the first half.
As long as the sampling frequency was at least twice as high as the expected 
signal frequency, all "meaningful" information is contained in the the first 
half of the magnitude vector. A peak in the low frequency range might 
nevertheless still be caused by a high "noise" frequency.

The vector of magnitudes extraced so far only has an index an no associated 
frequencies.

To calculated the frequencies, simply take (or generate) the index vector (1 
to length(magnitude vector) and divide by the length of the data block (in 
sec).


That's it for now. The second half of my "homework" will be delivered as soon 
as I understand what to make out of the phases given by R.
I again would expect a vector of the same length as the magnitude vector with 
the phases (0 to 2*pi or -pi to +pi) of each frequency. However, I do not 
know yet what R calculates.
I would be most obliged for any comments and help.


Wolfgang

---------------------------------------------------------------------------
# R-script
acq.freq <- 4000       # data acquisition frequency (Hz)
sig1.freq <- 50           # frequency of 1st signal component (Hz)
sig2.freq <- 130        # frequency of 2nd signal component (Hz)
time <- 5                    # measuring time interval (s)

# vector of sampling time-points (s)
smpl.int <- (1:(time*acq.freq))/acq.freq  

# data vector containing two frequencies (2nd frequ with phase shift)
data <- sin(sig1.freq*smpl.int*2*pi)+sin(sig2.freq*smpl.int*2*pi+pi/2)

plot(data,type="l")

# calculate fft of data
test <- fft(data)

# extract magnitudes and phases
magn <- Mod(test) # sqrt(Re(test)*Re(test)+Im(test)*Im(test))
phase <- Arg(test) # atan(Im(test)/Re(test))

# select only first half of vectors
magn.1 <- magn[1:(length(magn)/2)]
#phase.1 <- Arg(test)[1:(length(test)/2)]

# plot various vectors

# plot magnitudes as analyses by R
x11()
plot(magn,type="l")

# plot first half of magnitude vector
x11()
plot(magn.1,type="l")

# generate x-axis with frequencies
x.axis <- 1:length(magn.1)/time

# plot magnitudes against frequencies
x11()
plot(x=x.axis,y=magn.1,type="l")



>>> Hi,
>>> 
>>> I'm in dire need of a fast fourier transformation for me
>>> stupid biologist, i.e. I have a heartbeat signal and
>>> would like to decompose it into pure sin waves, getting
>>> three vectors, one containing the frequencies of the sin
>>> waves, one the magnitudes and one the phases (that's what
>>> I get from my data acquisition software's FFT function).
>>> I'd be very much obliged, if someone could point out
>>> which command would do the job in R.

>> fft(), but notice that it gives the complex
>> transform. You need to do a little homework to get at
>> the magnitude/phase values. (Basically, you just have to
>> take Mod() and Arg(), but there some conventions about
>> the frequencies and multipliers that one can get wrong).

> Once you've finished the "homework", others might be interested
> in your result... so it will be found in the future using 
> RSiteSearch().

-- 
Dr. Wolfgang Waser
Humbolt-Universit??t zu Berlin
Institute of Biology
Department of Animal Physiology
Philippstrasse 13, Abderhaldenhaus
10115 Berlin
Germany
Tel: +49 (0)30 2093 6173
Fax: +49 (0)30 2093 6375



From Torsten.Hothorn at rzmail.uni-erlangen.de  Tue Aug 30 11:42:40 2005
From: Torsten.Hothorn at rzmail.uni-erlangen.de (Torsten Hothorn)
Date: Tue, 30 Aug 2005 11:42:40 +0200 (CEST)
Subject: [R] stratified Wilcoxon available?
In-Reply-To: <x2vf1ohjkj.fsf@turmalin.kubism.ku.dk>
References: <3.0.6.32.20050828173610.007953a0@pop.gmx.net>
	<Pine.LNX.4.51.0508291440140.15465@artemis.imbe.med.uni-erlangen.de>
	<x2vf1ohjkj.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.LNX.4.51.0508301139510.30831@artemis.imbe.med.uni-erlangen.de>



On Mon, 29 Aug 2005, Peter Dalgaard wrote:

> Torsten Hothorn <Torsten.Hothorn at rzmail.uni-erlangen.de> writes:
>
> > > Dear All,
> > >
> > > is there a stratified version of the Wilcoxon test (also known as van
> > > Elteren test) available in R?
> >
> > you can plug it together using the `coin' infrastructure (see the
> > examples in the manual and vignette).
>
> I managed to dig out our old code, and patched it up loosely to fit
> versions of R later than 0.62 (the trend test code still seems
> broken). Use at own risk. The usage is fairly straightforward:
>
> > SKruskal.test(y~g1|g2)
>
>         Kruskal-Wallis stratified rank sum test
>
> data:  y , group:  g1 , strata:  g2
> K = 3.1486, df = 3, p-value = 0.3693
>

the conditional version of the above test can be computed as follows:

R> library("coin")
R> set.seed(290875)
R> mydf <- data.frame(y = rnorm(90), x = gl(3, 30)[sample(1:90)], b = gl(3, 30))
R>
R> ### with global ranks, i.e., ranking without using the blocks
R> kruskal_test(y ~ x | b, data = mydf)

        Asymptotic Kruskal-Wallis Test

data:  y by groups 1, 2, 3
         stratified by b
T = 0.5242, df = 2, p-value = 0.7694

R>
R> ### with _blockwise_ ranking and quadratic form of the test statistic
R> independence_test(y ~ x | b, data = mydf, ytrafo = function(data) trafo(data,
+                   numeric_trafo = rank, block = mydf$b), teststat = "quad")

        Asymptotic General Independence Test

data:  y by groups 1, 2, 3
         stratified by b
T = 0.3824, df = 2, p-value = 0.826

R>
R> ### the same
R> SKruskal.test(y ~ x | b, data = mydf)

        Kruskal-Wallis stratified rank sum test

data:  y , group:  x , strata:  b
K = 0.3824, df = 2, p-value = 0.826

R>
R>
R>
R> ### trend test (using scores 1, 2, 3)
R> independence_test(y ~ x | b, data = mydf, ytrafo = function(data) trafo(data,
+                   numeric_trafo = rank, block = mydf$b), teststat = "quad",
+                   scores = list(x = 1:3))

        Asymptotic General Independence Test

data:  y by groups 1 < 2 < 3
         stratified by b
T = 0.0264, df = 1, p-value = 0.871

R>
R> ### hm.
R> SKruskal.test(y ~ x | b, data = mydf, trend = TRUE)
Error in SKruskal.test(y ~ x | b, data = mydf, trend = TRUE) :
        subscript out of bounds

Best,

Torsten



From r.shengzhe at gmail.com  Tue Aug 30 11:43:51 2005
From: r.shengzhe at gmail.com (Shengzhe Wu)
Date: Tue, 30 Aug 2005 11:43:51 +0200
Subject: [R] Help: predict.qda
Message-ID: <ea57975b05083002437ebc7008@mail.gmail.com>

Hello,

I use the function qda (package MASS) to obtain a qda object like below.

x.qda = qda(x, group)

the group is a factor of two levels

and use this object to do the prediction below.

y.pred = predict(x.qda, y)

after that, I set different prediction priors like below, but the
results of prediction are totally the same as above using prior of
training set (use all.equal to compare).

y.pred1 = predict(x.qda,y, prior = c(1, 0))
y.pred2 = predict(x.qda,y, prior = c(0.5, 0.5))
y.pred3 = predict(x.qda,y, prior = c(0, 1))
y.pred4 = predict(x.qda,y, prior = c(0, 0))

the prediction prior of the last one should be wrong, but I still got
the same result.
And I tested the example of the function predict.qda by setting a
prediction prior.

predict(z, test, prior = c(0.1, 0.1, 0.8))

this result is exact the same as "predict(z, test)" which use training prior
"c(0.3333333, 0.3333333, 0.3333333)"

If the prediction prior for qda does not work?

The version of R I use is 2.1.1, and this argument for lda works.

Thank you,
Shengzhe



From r.hankin at noc.soton.ac.uk  Tue Aug 30 12:16:20 2005
From: r.hankin at noc.soton.ac.uk (Robin Hankin)
Date: Tue, 30 Aug 2005 11:16:20 +0100
Subject: [R] Testing if all elements are equal in a vector/matrix
In-Reply-To: <200508291535.21230.vincent.goulet@act.ulaval.ca>
References: <200508291535.21230.vincent.goulet@act.ulaval.ca>
Message-ID: <70222FFE-1153-4B1D-ADB3-3E335C02A3BF@soc.soton.ac.uk>

Hi

library(magic)
?minmax


[
the basic idea is min(x) == max(x)
]


best wishes


Robin
On 29 Aug 2005, at 20:35, Vincent Goulet wrote:

>
> Is there a canonical way to check if all elements of a vector or  
> matrix are
> the same? Solutions below work, but look hackish to me.
>
>
>> x <- rep(1, 10)
>> all(x == x[1])  # == operator does not provide for small differences
>>
> [1] TRUE
>
>> isTRUE(all.equal(x, rep(x[1], length(x)))) # ugly
>>
> [1] TRUE
>
> Best,
>
> Vincent
> -- 
>   Vincent Goulet, Associate Professor
>   ??cole d'actuariat
>   Universit?? Laval, Qu??bec
>   Vincent.Goulet at act.ulaval.ca   http://vgoulet.act.ulaval.ca
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting- 
> guide.html
>

--
Robin Hankin
Uncertainty Analyst
National Oceanography Centre, Southampton
European Way, Southampton SO14 3ZH, UK
  tel  023-8059-7743



From tura at centroin.com.br  Tue Aug 30 12:34:21 2005
From: tura at centroin.com.br (Bernardo Rangel Tura)
Date: Tue, 30 Aug 2005 07:34:21 -0300
Subject: [R] loglinear model selection
Message-ID: <6.1.2.0.2.20050830071545.0375feb0@centroin.com.br>

Hi R-masters!

I have a problem and need your help.
I have 9 discrete variables with 2 levels each.
In exploratory analisys I generate one matrix with chi-square for tables 
with 2 ariables each with this script

setwd("F:/")
dados<-read.csv("log.csv")[,2:10]
dados.x<-matrix(NA,ncol=9,nrow=9)
for(i in 1:8){
for(j in (i+1):9){
tab<-table(dados[,i],dados[,j])
dados.x[i,j]<-round(as.numeric(chisq.test(tab)$statistic),3)
dados.x[j,i]<-round(as.numeric(chisq.test(tab)$statistic),3)
  }
}
dados.x

The result is:

        [,1]   [,2]   [,3]   [,4]   [,5]   [,6]   [,7]  [,8]   [,9]
  [1,]    NA  3.589  6.351  3.957  4.269  0.851  2.955 1.188  1.975
  [2,] 3.589     NA  9.664 24.596 12.510 26.284  8.580 3.608  6.574
  [3,] 6.351  9.664     NA 25.054 10.300 12.189 19.811 0.192 11.744
  [4,] 3.957 24.596 25.054     NA 50.032 35.587 22.401 1.950 26.631
  [5,] 4.269 12.510 10.300 50.032     NA 80.876 54.954 0.127 61.573
  [6,] 0.851 26.284 12.189 35.587 80.876     NA 57.346 0.741 49.738
  [7,] 2.955  8.580 19.811 22.401 54.954 57.346     NA 1.520 80.615
  [8,] 1.188  3.608  0.192  1.950  0.127  0.741  1.520    NA  0.311
  [9,] 1.975  6.574 11.744 26.631 61.573 49.738 80.615 0.311     NA

Now I need fit a loglinear model with this variables, but I need know have 
a command with generate ALL models with the set this 8 vairables (ALL minus 
[,8]) incluindind the interactions.

Can Anyone Help me?



Thanks in advance

Bernardo Rangel Tura, MD, MSc
National Institute of Cardiology Laranjeiras
Rio de Janeiro Brazil 


-- 
No virus found in this outgoing message.
Checked by AVG Anti-Virus.



From dargosch at gmail.com  Tue Aug 30 13:20:31 2005
From: dargosch at gmail.com (Fredrik Karlsson)
Date: Tue, 30 Aug 2005 13:20:31 +0200
Subject: [R] Convert ftable to latex?
Message-ID: <376e97ec050830042067a91269@mail.gmail.com>

Dear list, 

I cannot make the latex command to output a ftable objet the way I
want it. Is it posible?
I found a post in the archives saying that one should use the rgroup
and n.rgroup arguments to supply the row names, but so far I have been
unsuccessful.

This is what I have:

> (ftable(tapply(worksub$vot,list(votcat=worksub$votcat,age=worksub$agemF,voicetype=worksub$Type),FUN="distribution.table.fun",digits=4)) -> ftab)
                  voicetype                  Voiced   Voiceless
unaspirated     Voiceless aspirated
votcat    age
Prevoiced 18 - 24           46.6158 (0;-1.6652)     40.7417
(0;-0.6489)     48.4164 (0;-1.0483)
          24 - 30           50.5716 (0;-1.4244)**   43.4056
(-1;-0.4537)*** 24.204 (0;-2.1416)
          30 - 36           44.4439 (0;-1.182)*     51.0996
(0;-1.5241)***  32.1219 (0;-1.5007)
          36 - 42           40.8604 (-1;-0.3423)    40.6045
(-1;-0.408)**   32.7949 (0;-2.75)
          42 - 48           46.301 (0;-1.1878)      21.6894
(0;-1.7041)     NA (NA;NA)
          48 - 54           38.0151 (-1;-0.7878)*   27.6954
(-1;0.0396)*    NA (NA;NA)
Short lag 18 - 24           7.5719 (1;0.4391)***    9.7039
(1;-0.2938)***   8.5525 (1;-0.4063)***
          24 - 30           8.3466 (1;-0.3122)***   9.8524
(0;-0.887)***    11.4154 (0;-1.2267)***
          30 - 36           9.4509 (1;-0.0795)***   9.0177
(1;-0.2654)***   9.441 (0;-0.7625)
          36 - 42           9.4921 (1;-0.1835)***   10.107 (0;-0.72)**
     10.912 (0;-1.3619)
          42 - 48           7.8254 (1;1.016)**      9.5687 (0;-0.9019)
     10.6842 (-1;0.0719)*
          48 - 54           7.7332 (1;1.2834)**     9.4626
(1;0.3173)***    10.0508 (0;-1.4876)
Long lag  18 - 24           16.7312 (0;-1.7286)     21.4786
(2;2.4726)**    41.6646 (1;-0.6796)***
          24 - 30           29.5637 (1;-0.0951)**   37.4517
(1;0.1032)***   38.2729 (1;-0.3249)***
          30 - 36           23.0214 (0;-1.3023)     35.0403
(1;0.9176)***   36.0989 (1;-0.2141)***
          36 - 42           10.579 (1;0.3292)       31.4878
(0;-1.2475)     38.0472 (1;-0.3049)**
          42 - 48           17.9077 (1;-1.2857)     26.8651
(1;0.0221)***   30.5705 (1;-0.5866)***
          48 - 54           18.832 (0;-2.3333)      40.375 (1;-1.417)*
     26.2463 (1;0.4025)***
> latex(ftab,cgroup=attributes(ftab)$col.vars$voicetype, rgroup=attributes(ftab)$row.vars$votcat, n.rgroup=c(6,6,6),file="")
% latex.default(ftab, cgroup = attributes(ftab)$col.vars$voicetype,   
  rgroup = attributes(ftab)$row.vars$votcat, n.rgroup = c(6,         
6, 6), file = "")
%
\begin{table}[!tbp]
 \begin{center}
 \begin{tabular}{lclcl}\hline\hline
\multicolumn{1}{c}{\bfseries Voiced}&
\multicolumn{1}{c}{\bfseries }&
\multicolumn{1}{c}{\bfseries Voiceless unaspirated}&
\multicolumn{1}{c}{\bfseries }&
\multicolumn{1}{c}{\bfseries Voiceless aspirated}
\\ \cline{1-5}
\multicolumn{1}{c}{}&
\multicolumn{1}{c}{}&
\multicolumn{1}{c}{}&
\multicolumn{1}{c}{}&
\multicolumn{1}{c}{}
\\ \hline
&&&&\\
46.6158 (0;-1.6652)&&40.7417 (0;-0.6489)&&48.4164 (0;-1.0483)\\
50.5716 (0;-1.4244)**&&43.4056 (-1;-0.4537)***&&24.204 (0;-2.1416)\\
44.4439 (0;-1.182)*&&51.0996 (0;-1.5241)***&&32.1219 (0;-1.5007)\\
40.8604 (-1;-0.3423)&&40.6045 (-1;-0.408)**&&32.7949 (0;-2.75)\\
46.301 (0;-1.1878)&&21.6894 (0;-1.7041)&&NA (NA;NA)\\
38.0151 (-1;-0.7878)*&&27.6954 (-1;0.0396)*&&NA (NA;NA)\\
\hline
&&&&\\
7.5719 (1;0.4391)***&&9.7039 (1;-0.2938)***&&8.5525 (1;-0.4063)***\\
8.3466 (1;-0.3122)***&&9.8524 (0;-0.887)***&&11.4154 (0;-1.2267)***\\
9.4509 (1;-0.0795)***&&9.0177 (1;-0.2654)***&&9.441 (0;-0.7625)\\
9.4921 (1;-0.1835)***&&10.107 (0;-0.72)**&&10.912 (0;-1.3619)\\
7.8254 (1;1.016)**&&9.5687 (0;-0.9019)&&10.6842 (-1;0.0719)*\\
7.7332 (1;1.2834)**&&9.4626 (1;0.3173)***&&10.0508 (0;-1.4876)\\
\hline
&&&&\\
16.7312 (0;-1.7286)&&21.4786 (2;2.4726)**&&41.6646 (1;-0.6796)***\\
29.5637 (1;-0.0951)**&&37.4517 (1;0.1032)***&&38.2729 (1;-0.3249)***\\
23.0214 (0;-1.3023)&&35.0403 (1;0.9176)***&&36.0989 (1;-0.2141)***\\
10.579 (1;0.3292)&&31.4878 (0;-1.2475)&&38.0472 (1;-0.3049)**\\
17.9077 (1;-1.2857)&&26.8651 (1;0.0221)***&&30.5705 (1;-0.5866)***\\
18.832 (0;-2.3333)&&40.375 (1;-1.417)*&&26.2463 (1;0.4025)***\\
\hline
\end{tabular}

\end{center}

\end{table}

> 

As you can see, I do not get any row names, and I want two layers of
them (votcat and age in the formula). Column names work ok.

Please, help me recreate the table above in latex form (if it is
indeed possible).

/Fredrik



From caralph at sympatico.ca  Tue Aug 30 14:31:31 2005
From: caralph at sympatico.ca (Ralph Henderson)
Date: Tue, 30 Aug 2005 08:31:31 -0400
Subject: [R] Royston's V' and v' functions
Message-ID: <6.2.1.2.2.20050830082858.01ff1b80@pop1.sympatico.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050830/f06abb1d/attachment.pl

From Chris.Planet at gmx.de  Tue Aug 30 14:37:18 2005
From: Chris.Planet at gmx.de (Christian Hinz)
Date: Tue, 30 Aug 2005 14:37:18 +0200 (MEST)
Subject: [R] =?iso-8859-1?q?_Who_can_help_me=3F?=
References: <17741.1125404039@www70.gmx.net>
Message-ID: <12760.1125405438@www70.gmx.net>

I have own function wrote. I used an algorithm, which was written in Matlab.

in matlab:
...
gamma = inv(v)*g;
...

#v = matrix of variable size, v=vv(k) => k=2 => dimension of v 2x2
#g = a line vector with 4 elements e.g. g=[1,0,2,0];

my rewritten r-file:
...
gamma = solve(v)*g;
...

which is my error? Who can help me?

thank you in advance.

Chris


-- 
Lust, ein paar Euro nebenbei zu verdienen? Ohne Kosten, ohne Risiko!
Satte Provisionen f??r GMX Partner: http://www.gmx.net/de/go/partner

--



From p.dalgaard at biostat.ku.dk  Tue Aug 30 14:46:41 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 30 Aug 2005 14:46:41 +0200
Subject: [R] stratified Wilcoxon available?
In-Reply-To: <Pine.LNX.4.51.0508301139510.30831@artemis.imbe.med.uni-erlangen.de>
References: <3.0.6.32.20050828173610.007953a0@pop.gmx.net>
	<Pine.LNX.4.51.0508291440140.15465@artemis.imbe.med.uni-erlangen.de>
	<x2vf1ohjkj.fsf@turmalin.kubism.ku.dk>
	<Pine.LNX.4.51.0508301139510.30831@artemis.imbe.med.uni-erlangen.de>
Message-ID: <x2fysrd232.fsf@turmalin.kubism.ku.dk>

Torsten Hothorn <Torsten.Hothorn at rzmail.uni-erlangen.de> writes:

> On Mon, 29 Aug 2005, Peter Dalgaard wrote:
> 
> > Torsten Hothorn <Torsten.Hothorn at rzmail.uni-erlangen.de> writes:
> >
> > > > Dear All,
> > > >
> > > > is there a stratified version of the Wilcoxon test (also known as van
> > > > Elteren test) available in R?
> > >
> > > you can plug it together using the `coin' infrastructure (see the
> > > examples in the manual and vignette).
> >
> > I managed to dig out our old code, and patched it up loosely to fit
> > versions of R later than 0.62 (the trend test code still seems
> > broken). Use at own risk. The usage is fairly straightforward:
> >
> > > SKruskal.test(y~g1|g2)
> >
> >         Kruskal-Wallis stratified rank sum test
> >
> > data:  y , group:  g1 , strata:  g2
> > K = 3.1486, df = 3, p-value = 0.3693
> >
> 
> the conditional version of the above test can be computed as follows:
> 
> R> library("coin")
> R> set.seed(290875)
> R> mydf <- data.frame(y = rnorm(90), x = gl(3, 30)[sample(1:90)], b = gl(3, 30))
> R>
> R> ### with global ranks, i.e., ranking without using the blocks
> R> kruskal_test(y ~ x | b, data = mydf)
> 
>         Asymptotic Kruskal-Wallis Test
> 
> data:  y by groups 1, 2, 3
>          stratified by b
> T = 0.5242, df = 2, p-value = 0.7694
> 
> R>
> R> ### with _blockwise_ ranking and quadratic form of the test statistic
> R> independence_test(y ~ x | b, data = mydf, ytrafo = function(data) trafo(data,
> +                   numeric_trafo = rank, block = mydf$b), teststat = "quad")
> 
>         Asymptotic General Independence Test
> 
> data:  y by groups 1, 2, 3
>          stratified by b
> T = 0.3824, df = 2, p-value = 0.826
> 
> R>
> R> ### the same
> R> SKruskal.test(y ~ x | b, data = mydf)
> 
>         Kruskal-Wallis stratified rank sum test
> 
> data:  y , group:  x , strata:  b
> K = 0.3824, df = 2, p-value = 0.826
> 
> R>
> R>
> R>
> R> ### trend test (using scores 1, 2, 3)
> R> independence_test(y ~ x | b, data = mydf, ytrafo = function(data) trafo(data,
> +                   numeric_trafo = rank, block = mydf$b), teststat = "quad",
> +                   scores = list(x = 1:3))
> 
>         Asymptotic General Independence Test
> 
> data:  y by groups 1 < 2 < 3
>          stratified by b
> T = 0.0264, df = 1, p-value = 0.871
> 
> R>
> R> ### hm.
> R> SKruskal.test(y ~ x | b, data = mydf, trend = TRUE)
> Error in SKruskal.test(y ~ x | b, data = mydf, trend = TRUE) :
>         subscript out of bounds
> 
> Best,
> 
> Torsten

Nice to see that the old code made sense. A bit surprising that it
gives _exactly_ the same result as the blockwise ranking in coin...
Perhaps introduce some ties? (round(y,1) is usually effective).

The trend test is easily fixed: just spell "t value" without capital V
as we do nowadays. This gives


> SKruskal.test(y ~ x | b, data = mydf, trend = TRUE)

        Kruskal-Wallis stratified rank sum trend test

data:  y , group:  x , strata:  b , trend:  as.numeric(group)
Z = -0.1624, df = 1, p-value = 0.871

> SKruskal.test(y ~ x | b, data = mydf, trend = 1:3)

        Kruskal-Wallis stratified rank sum trend test

data:  y , group:  x , strata:  b , trend:  1 2 3
Z = -0.1624, df = 1, p-value = 0.871

(The df=1 is a bit misleading in this case...)


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From david.whiting at ncl.ac.uk  Tue Aug 30 14:47:15 2005
From: david.whiting at ncl.ac.uk (David Whiting)
Date: Tue, 30 Aug 2005 13:47:15 +0100
Subject: [R] Convert ftable to latex?
In-Reply-To: <376e97ec050830042067a91269@mail.gmail.com>
References: <376e97ec050830042067a91269@mail.gmail.com>
Message-ID: <43145553.4020601@ncl.ac.uk>

Hi Fredrik,

What you need to do is to massage your table a little to get it into the
appropriate structure and then use the rgroup and n.rgroup options.
Here's an example using the Titanic data that come with R. Note that
this is not necessarily (or even remotely likely?) the best way to get
your data into the shape required, but hopefully it shows you what, in
general, you need to do. You might find that you don't need to use
ftable at all, you might find other ways of creating the table you need.
In the example below, note in particular what x and x2 look like.

> library(Hmisc)
> x <- ftable(Titanic, row.vars = 1:2)
> x
             Age      Child     Adult
             Survived    No Yes    No Yes
Class Sex
1st   Male                0   5   118  57
      Female              0   1     4 140
2nd   Male                0  11   154  14
      Female              0  13    13  80
3rd   Male               35  13   387  75
      Female             17  14    89  76
Crew  Male                0   0   670 192
      Female              0   0     3  20
> x.row.vars <- attr(x, "row.vars")
> col1 <- x.row.vars[[1]]
> col2 <- rep(x.row.vars[[2]], 4)
> x2 <- data.frame(sex=col2, x[ ,])
> colnames(x2) <- c("Sex", "No", "Yes", "No", "Yes")
> x2
     Sex No Yes  No Yes
1   Male  0   5 118  57
2 Female  0   1   4 140
3   Male  0  11 154  14
4 Female  0  13  13  80
5   Male 35  13 387  75
6 Female 17  14  89  76
7   Male  0   0 670 192
8 Female  0   0   3  20
> latex(x2,
+       title="",
+       rowname="",
+       rgroup=col1,
+       cgroup=c("", "Child", "Adult"),
+       n.cgroup=c(1, 2, 2),
+       n.rgroup=rep(2, 4)
+       )


HTH.

Dave


Fredrik Karlsson wrote:
> Dear list, 
> 
> I cannot make the latex command to output a ftable objet the way I
> want it. Is it posible?
> I found a post in the archives saying that one should use the rgroup
> and n.rgroup arguments to supply the row names, but so far I have been
> unsuccessful.
> 
> This is what I have:
> 
> 
>>(ftable(tapply(worksub$vot,list(votcat=worksub$votcat,age=worksub$agemF,voicetype=worksub$Type),FUN="distribution.table.fun",digits=4)) -> ftab)
> 
>                   voicetype                  Voiced   Voiceless
> unaspirated     Voiceless aspirated
> votcat    age
> Prevoiced 18 - 24           46.6158 (0;-1.6652)     40.7417
> (0;-0.6489)     48.4164 (0;-1.0483)
>           24 - 30           50.5716 (0;-1.4244)**   43.4056
> (-1;-0.4537)*** 24.204 (0;-2.1416)
>           30 - 36           44.4439 (0;-1.182)*     51.0996
> (0;-1.5241)***  32.1219 (0;-1.5007)
>           36 - 42           40.8604 (-1;-0.3423)    40.6045
> (-1;-0.408)**   32.7949 (0;-2.75)
>           42 - 48           46.301 (0;-1.1878)      21.6894
> (0;-1.7041)     NA (NA;NA)
>           48 - 54           38.0151 (-1;-0.7878)*   27.6954
> (-1;0.0396)*    NA (NA;NA)
> Short lag 18 - 24           7.5719 (1;0.4391)***    9.7039
> (1;-0.2938)***   8.5525 (1;-0.4063)***
>           24 - 30           8.3466 (1;-0.3122)***   9.8524
> (0;-0.887)***    11.4154 (0;-1.2267)***
>           30 - 36           9.4509 (1;-0.0795)***   9.0177
> (1;-0.2654)***   9.441 (0;-0.7625)
>           36 - 42           9.4921 (1;-0.1835)***   10.107 (0;-0.72)**
>      10.912 (0;-1.3619)
>           42 - 48           7.8254 (1;1.016)**      9.5687 (0;-0.9019)
>      10.6842 (-1;0.0719)*
>           48 - 54           7.7332 (1;1.2834)**     9.4626
> (1;0.3173)***    10.0508 (0;-1.4876)
> Long lag  18 - 24           16.7312 (0;-1.7286)     21.4786
> (2;2.4726)**    41.6646 (1;-0.6796)***
>           24 - 30           29.5637 (1;-0.0951)**   37.4517
> (1;0.1032)***   38.2729 (1;-0.3249)***
>           30 - 36           23.0214 (0;-1.3023)     35.0403
> (1;0.9176)***   36.0989 (1;-0.2141)***
>           36 - 42           10.579 (1;0.3292)       31.4878
> (0;-1.2475)     38.0472 (1;-0.3049)**
>           42 - 48           17.9077 (1;-1.2857)     26.8651
> (1;0.0221)***   30.5705 (1;-0.5866)***
>           48 - 54           18.832 (0;-2.3333)      40.375 (1;-1.417)*
>      26.2463 (1;0.4025)***
> 
>>latex(ftab,cgroup=attributes(ftab)$col.vars$voicetype, rgroup=attributes(ftab)$row.vars$votcat, n.rgroup=c(6,6,6),file="")
> 
> % latex.default(ftab, cgroup = attributes(ftab)$col.vars$voicetype,   
>   rgroup = attributes(ftab)$row.vars$votcat, n.rgroup = c(6,         
> 6, 6), file = "")
> %
> \begin{table}[!tbp]
>  \begin{center}
>  \begin{tabular}{lclcl}\hline\hline
> \multicolumn{1}{c}{\bfseries Voiced}&
> \multicolumn{1}{c}{\bfseries }&
> \multicolumn{1}{c}{\bfseries Voiceless unaspirated}&
> \multicolumn{1}{c}{\bfseries }&
> \multicolumn{1}{c}{\bfseries Voiceless aspirated}
> \\ \cline{1-5}
> \multicolumn{1}{c}{}&
> \multicolumn{1}{c}{}&
> \multicolumn{1}{c}{}&
> \multicolumn{1}{c}{}&
> \multicolumn{1}{c}{}
> \\ \hline
> &&&&\\
> 46.6158 (0;-1.6652)&&40.7417 (0;-0.6489)&&48.4164 (0;-1.0483)\\
> 50.5716 (0;-1.4244)**&&43.4056 (-1;-0.4537)***&&24.204 (0;-2.1416)\\
> 44.4439 (0;-1.182)*&&51.0996 (0;-1.5241)***&&32.1219 (0;-1.5007)\\
> 40.8604 (-1;-0.3423)&&40.6045 (-1;-0.408)**&&32.7949 (0;-2.75)\\
> 46.301 (0;-1.1878)&&21.6894 (0;-1.7041)&&NA (NA;NA)\\
> 38.0151 (-1;-0.7878)*&&27.6954 (-1;0.0396)*&&NA (NA;NA)\\
> \hline
> &&&&\\
> 7.5719 (1;0.4391)***&&9.7039 (1;-0.2938)***&&8.5525 (1;-0.4063)***\\
> 8.3466 (1;-0.3122)***&&9.8524 (0;-0.887)***&&11.4154 (0;-1.2267)***\\
> 9.4509 (1;-0.0795)***&&9.0177 (1;-0.2654)***&&9.441 (0;-0.7625)\\
> 9.4921 (1;-0.1835)***&&10.107 (0;-0.72)**&&10.912 (0;-1.3619)\\
> 7.8254 (1;1.016)**&&9.5687 (0;-0.9019)&&10.6842 (-1;0.0719)*\\
> 7.7332 (1;1.2834)**&&9.4626 (1;0.3173)***&&10.0508 (0;-1.4876)\\
> \hline
> &&&&\\
> 16.7312 (0;-1.7286)&&21.4786 (2;2.4726)**&&41.6646 (1;-0.6796)***\\
> 29.5637 (1;-0.0951)**&&37.4517 (1;0.1032)***&&38.2729 (1;-0.3249)***\\
> 23.0214 (0;-1.3023)&&35.0403 (1;0.9176)***&&36.0989 (1;-0.2141)***\\
> 10.579 (1;0.3292)&&31.4878 (0;-1.2475)&&38.0472 (1;-0.3049)**\\
> 17.9077 (1;-1.2857)&&26.8651 (1;0.0221)***&&30.5705 (1;-0.5866)***\\
> 18.832 (0;-2.3333)&&40.375 (1;-1.417)*&&26.2463 (1;0.4025)***\\
> \hline
> \end{tabular}
> 
> \end{center}
> 
> \end{table}
> 
> 
> 
> As you can see, I do not get any row names, and I want two layers of
> them (votcat and age in the formula). Column names work ok.
> 
> Please, help me recreate the table above in latex form (if it is
> indeed possible).
> 
> /Fredrik
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 

-- 
David Whiting
School of Clinical Medical Sciences, The Medical School
University of Newcastle upon Tyne, NE2 4HH, UK.

"I love deadlines. I love the whooshing noise they make as they go by"
(Douglas Adams)



From gunter.berton at gene.com  Mon Aug 29 18:13:55 2005
From: gunter.berton at gene.com (Berton Gunter)
Date: Mon, 29 Aug 2005 09:13:55 -0700
Subject: [R] staying with R, jobs in R
In-Reply-To: <cdf81783050829090452b02067@mail.gmail.com>
Message-ID: <200508291613.j7TGDuVj020443@compton.gene.com>

Weiwei:

Job searches are difficult! One obvious answer is Amstat news and the ASA
job site, but there may be many not posted in these places. Most large
Pharmas (Pfizer, GSK, Merck, etc.) have (relatively small) pre-/non-
clinical research groups, so you might check on their websites for open
positions (I believe Merck may have some). Large industrial employers like
the auto companies, GE, DuPont, etc. often have a few openings in their
quality or research organizations, but again they are scattered all over and
may be hard to find. Check their individual web sites again.

If you have some signficant work experience already, you might try working
with a head hunter, as many jobs are never advertised. 

As I said, it's hard .. and harder than it used to be as engineering/science
type jobs are drying up for statisticians.

-- Bert

> -----Original Message-----
> From: Weiwei Shi [mailto:helprhelp at gmail.com] 
> Sent: Monday, August 29, 2005 9:05 AM
> To: Berton Gunter
> Cc: roger bos; avneet singh; r-help at stat.math.ethz.ch
> Subject: Re: [R] staying with R, jobs in R
> 
> Hi, there:
> Could I ask another question, which is a little bit off-topic; but I
> tried hard and did not get good enough info... so please help
> 
> I am very interested in seeing where to find those
> bio/pharmaceutical-related industries, using R and data mining as
> approaches?
> 
> thank you very much!
> 
> weiwei
> 
> On 8/29/05, Berton Gunter <gunter.berton at gene.com> wrote:
> > Avneet:
> > Not to throw a wet blanket on your enthusiam for R (which I 
> share) but ...
> > 
> > -- Bert Gunter
> > Genentech Non-Clinical Statistics
> > South San Francisco, CA
> > 
> > "The business of the statistician is to catalyze the 
> scientific learning
> > process."  - George E. P. Box
> > 
> > 
> >  Your better off finding a
> > > job you like
> > > at a company you like and then convincing them that R is
> > > better (not to
> > > mention the R skill set you are bringing to the table).
> > >  Good luck to you.
> > > Roger
> > 
> > Fine advice, but a tad unrealistic. The reality (according to Bert):
> > 
> > 1. Most jobs for statisticians are in the 
> pharmaceutical/medical industry
> > (which includes academic research centers) in clinical 
> trials. Data: See job
> > ads in Amstat News.
> > 
> > 2. For better or worse, in this arena SAS is the standard. 
> You will **not**
> > -- repeat, NOT -- convince industrial employers who have 
> thousands of lines
> > of legacy infrastructure code and legions of SAS 
> programmers to change. You
> > may well make some inroads in academic research venues. In 
> both, you will
> > generally be free to use whatever software you like for 
> your own work, but
> > the final code submitted for FDA approval will almost 
> certainly necessarily
> > be SAS. Rail all you like, but those are the realities.
> > 
> > 3. Another significant amployer of statisticians these days 
> is the "finance"
> > industry (credit scoring and the like). Data: See Amstat 
> News ads again.
> > There S-Plus is already widely used, so you should have no 
> difficulty using
> > R and even getting others to adopt it.
> > 
> > I think outside these arenas -- for example, in industrial 
> research and
> > engineering centers or in pre/non-clinical pharmaceutical 
> work, you'll again
> > be free to use what you like. But there are relatively few 
> jobs there, so
> > that despite Roger's noble advice (with which I again 
> agree), first you
> > gotta eat and pay the mortgage.
> > 
> > And I also say: good luck.
> > 
> > -- Bert
> > 
> > -- Bert Gunter
> > Genentech Non-Clinical Statistics
> > South San Francisco, CA
> > 
> > "The business of the statistician is to catalyze the 
> scientific learning
> > process."  - George E. P. Box
> > 
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> > 
> 
> 
> -- 
> Weiwei Shi, Ph.D
> 
> "Did you always know?"
> "No, I did not. But I believed..."
> ---Matrix III
>



From ligges at statistik.uni-dortmund.de  Tue Aug 30 14:49:47 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 30 Aug 2005 14:49:47 +0200
Subject: [R] Who can help me?
In-Reply-To: <12760.1125405438@www70.gmx.net>
References: <17741.1125404039@www70.gmx.net> <12760.1125405438@www70.gmx.net>
Message-ID: <431455EB.4040306@statistik.uni-dortmund.de>

Christian Hinz wrote:

> I have own function wrote. I used an algorithm, which was written in Matlab.
> 
> in matlab:
> ...
> gamma = inv(v)*g;
> ...
> 
> #v = matrix of variable size, v=vv(k) => k=2 => dimension of v 2x2
> #g = a line vector with 4 elements e.g. g=[1,0,2,0];
> 
> my rewritten r-file:
> ...
> gamma = solve(v)*g;
> ...
> 
> which is my error? Who can help me?


Ehhh, don't know what Matlab does with the code given above.

In R:
If v is 2x2 and g has length 4, this seems to be strange, but the matrix 
is treated as a vector for the multiplication step and there should not 
be an error message (but probably not the result you want to get) ...

Uwe Ligges



> thank you in advance.
> 
> Chris
> 
>



From roger.bos at gmail.com  Tue Aug 30 14:49:35 2005
From: roger.bos at gmail.com (roger bos)
Date: Tue, 30 Aug 2005 08:49:35 -0400
Subject: [R] Who can help me?
In-Reply-To: <12760.1125405438@www70.gmx.net>
References: <17741.1125404039@www70.gmx.net> <12760.1125405438@www70.gmx.net>
Message-ID: <1db72680050830054924a16d2@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050830/694ab6dc/attachment.pl

From torsten at hothorn.de  Tue Aug 30 14:59:52 2005
From: torsten at hothorn.de (torsten@hothorn.de)
Date: Tue, 30 Aug 2005 14:59:52 +0200 (CEST)
Subject: [R] stratified Wilcoxon available?
In-Reply-To: <x2fysrd232.fsf@turmalin.kubism.ku.dk>
References: <3.0.6.32.20050828173610.007953a0@pop.gmx.net>
	<Pine.LNX.4.51.0508291440140.15465@artemis.imbe.med.uni-erlangen.de>
	<x2vf1ohjkj.fsf@turmalin.kubism.ku.dk>
	<Pine.LNX.4.51.0508301139510.30831@artemis.imbe.med.uni-erlangen.de>
	<x2fysrd232.fsf@turmalin.kubism.ku.dk>
Message-ID: <Pine.LNX.4.51.0508301454570.20777@artemis.imbe.med.uni-erlangen.de>


On Tue, 30 Aug 2005, Peter Dalgaard wrote:

> Torsten Hothorn <Torsten.Hothorn at rzmail.uni-erlangen.de> writes:
>
> > On Mon, 29 Aug 2005, Peter Dalgaard wrote:
> >
> > > Torsten Hothorn <Torsten.Hothorn at rzmail.uni-erlangen.de> writes:
> > >
> > > > > Dear All,
> > > > >
> > > > > is there a stratified version of the Wilcoxon test (also known as van
> > > > > Elteren test) available in R?
> > > >
> > > > you can plug it together using the `coin' infrastructure (see the
> > > > examples in the manual and vignette).
> > >
> > > I managed to dig out our old code, and patched it up loosely to fit
> > > versions of R later than 0.62 (the trend test code still seems
> > > broken). Use at own risk. The usage is fairly straightforward:
> > >
> > > > SKruskal.test(y~g1|g2)
> > >
> > >         Kruskal-Wallis stratified rank sum test
> > >
> > > data:  y , group:  g1 , strata:  g2
> > > K = 3.1486, df = 3, p-value = 0.3693
> > >
> >
> > the conditional version of the above test can be computed as follows:
> >
> > R> library("coin")
> > R> set.seed(290875)
> > R> mydf <- data.frame(y = rnorm(90), x = gl(3, 30)[sample(1:90)], b = gl(3, 30))
> > R>
> > R> ### with global ranks, i.e., ranking without using the blocks
> > R> kruskal_test(y ~ x | b, data = mydf)
> >
> >         Asymptotic Kruskal-Wallis Test
> >
> > data:  y by groups 1, 2, 3
> >          stratified by b
> > T = 0.5242, df = 2, p-value = 0.7694
> >
> > R>
> > R> ### with _blockwise_ ranking and quadratic form of the test statistic
> > R> independence_test(y ~ x | b, data = mydf, ytrafo = function(data) trafo(data,
> > +                   numeric_trafo = rank, block = mydf$b), teststat = "quad")
> >
> >         Asymptotic General Independence Test
> >
> > data:  y by groups 1, 2, 3
> >          stratified by b
> > T = 0.3824, df = 2, p-value = 0.826
> >
> > R>
> > R> ### the same
> > R> SKruskal.test(y ~ x | b, data = mydf)
> >
> >         Kruskal-Wallis stratified rank sum test
> >
> > data:  y , group:  x , strata:  b
> > K = 0.3824, df = 2, p-value = 0.826
> >
> > R>
> > R>
> > R>
> > R> ### trend test (using scores 1, 2, 3)
> > R> independence_test(y ~ x | b, data = mydf, ytrafo = function(data) trafo(data,
> > +                   numeric_trafo = rank, block = mydf$b), teststat = "quad",
> > +                   scores = list(x = 1:3))
> >
> >         Asymptotic General Independence Test
> >
> > data:  y by groups 1 < 2 < 3
> >          stratified by b
> > T = 0.0264, df = 1, p-value = 0.871
> >
> > R>
> > R> ### hm.
> > R> SKruskal.test(y ~ x | b, data = mydf, trend = TRUE)
> > Error in SKruskal.test(y ~ x | b, data = mydf, trend = TRUE) :
> >         subscript out of bounds
> >
> > Best,
> >
> > Torsten
>
> Nice to see that the old code made sense.

Nice to see that the new code is working correctly :-)

> A bit surprising that it
> gives _exactly_ the same result as the blockwise ranking in coin...

why? Without ties, the conditional and unconditional versions of the tests
should have exactly the same result.

> Perhaps introduce some ties? (round(y,1) is usually effective).
>

this should generate differences, yes.

> The trend test is easily fixed: just spell "t value" without capital V
> as we do nowadays. This gives
>
>
> > SKruskal.test(y ~ x | b, data = mydf, trend = TRUE)
>
>         Kruskal-Wallis stratified rank sum trend test
>
> data:  y , group:  x , strata:  b , trend:  as.numeric(group)
> Z = -0.1624, df = 1, p-value = 0.871
>
> > SKruskal.test(y ~ x | b, data = mydf, trend = 1:3)
>
>         Kruskal-Wallis stratified rank sum trend test
>
> data:  y , group:  x , strata:  b , trend:  1 2 3
> Z = -0.1624, df = 1, p-value = 0.871
>
> (The df=1 is a bit misleading in this case...)
>

maybe report 0.1624^2 = 0.0264 as test statistic (same as with teststat
= "quad" in `coin')?

Best,

Torsten

>
> --
>    O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>



From roger.bos at gmail.com  Tue Aug 30 15:02:24 2005
From: roger.bos at gmail.com (roger bos)
Date: Tue, 30 Aug 2005 09:02:24 -0400
Subject: [R] seeking advice for manipulating matrices to find the difference
Message-ID: <1db726800508300602512c63bc@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050830/93eabbcf/attachment.pl

From david.whiting at ncl.ac.uk  Tue Aug 30 15:15:51 2005
From: david.whiting at ncl.ac.uk (David Whiting)
Date: Tue, 30 Aug 2005 14:15:51 +0100
Subject: [R] Convert ftable to latex?
In-Reply-To: <43145553.4020601@ncl.ac.uk>
References: <376e97ec050830042067a91269@mail.gmail.com>
	<43145553.4020601@ncl.ac.uk>
Message-ID: <43145C07.1090406@ncl.ac.uk>

Hi again Fredrik,

Here's a slightly better version (sex is no longer the first column, it
is used by the rowname option in latex instead).

> library(Hmisc)
>
> x <- ftable(Titanic, row.vars = 1:2)
> x
             Age      Child     Adult
             Survived    No Yes    No Yes
Class Sex
1st   Male                0   5   118  57
      Female              0   1     4 140
2nd   Male                0  11   154  14
      Female              0  13    13  80
3rd   Male               35  13   387  75
      Female             17  14    89  76
Crew  Male                0   0   670 192
      Female              0   0     3  20
> x.row.vars <- attr(x, "row.vars")
>
> col1 <- x.row.vars[[1]]
> col2 <- rep(x.row.vars[[2]], 4)
>
> x2 <- data.frame(x[ ,])
> colnames(x2) <- c("No", "Yes", "No", "Yes")
>
> x2
  No Yes  No Yes
1  0   5 118  57
2  0   1   4 140
3  0  11 154  14
4  0  13  13  80
5 35  13 387  75
6 17  14  89  76
7  0   0 670 192
8  0   0   3  20
>
> latex(x2,
+       title="",
+       rowname=col2,
+       rgroup=col1,
+       cgroup=c("Child", "Adult"),
+       n.cgroup=c(2, 2),
+       n.rgroup=rep(2, 4)
+       )


Dave

David Whiting wrote:
> Hi Fredrik,
> 
> What you need to do is to massage your table a little to get it into the
> appropriate structure and then use the rgroup and n.rgroup options.
> Here's an example using the Titanic data that come with R. Note that
> this is not necessarily (or even remotely likely?) the best way to get
> your data into the shape required, but hopefully it shows you what, in
> general, you need to do. You might find that you don't need to use
> ftable at all, you might find other ways of creating the table you need.
> In the example below, note in particular what x and x2 look like.
> 
> 
>>library(Hmisc)
>>x <- ftable(Titanic, row.vars = 1:2)
>>x
> 
>              Age      Child     Adult
>              Survived    No Yes    No Yes
> Class Sex
> 1st   Male                0   5   118  57
>       Female              0   1     4 140
> 2nd   Male                0  11   154  14
>       Female              0  13    13  80
> 3rd   Male               35  13   387  75
>       Female             17  14    89  76
> Crew  Male                0   0   670 192
>       Female              0   0     3  20
> 
>>x.row.vars <- attr(x, "row.vars")
>>col1 <- x.row.vars[[1]]
>>col2 <- rep(x.row.vars[[2]], 4)
>>x2 <- data.frame(sex=col2, x[ ,])
>>colnames(x2) <- c("Sex", "No", "Yes", "No", "Yes")
>>x2
> 
>      Sex No Yes  No Yes
> 1   Male  0   5 118  57
> 2 Female  0   1   4 140
> 3   Male  0  11 154  14
> 4 Female  0  13  13  80
> 5   Male 35  13 387  75
> 6 Female 17  14  89  76
> 7   Male  0   0 670 192
> 8 Female  0   0   3  20
> 
>>latex(x2,
> 
> +       title="",
> +       rowname="",
> +       rgroup=col1,
> +       cgroup=c("", "Child", "Adult"),
> +       n.cgroup=c(1, 2, 2),
> +       n.rgroup=rep(2, 4)
> +       )
> 
> 
> HTH.
> 
> Dave
> 
> 
> Fredrik Karlsson wrote:
> 
>>Dear list, 
>>
>>I cannot make the latex command to output a ftable objet the way I
>>want it. Is it posible?
>>I found a post in the archives saying that one should use the rgroup
>>and n.rgroup arguments to supply the row names, but so far I have been
>>unsuccessful.
>>
>>This is what I have:
>>
>>
>>
>>>(ftable(tapply(worksub$vot,list(votcat=worksub$votcat,age=worksub$agemF,voicetype=worksub$Type),FUN="distribution.table.fun",digits=4)) -> ftab)
>>
>>                  voicetype                  Voiced   Voiceless
>>unaspirated     Voiceless aspirated
>>votcat    age
>>Prevoiced 18 - 24           46.6158 (0;-1.6652)     40.7417
>>(0;-0.6489)     48.4164 (0;-1.0483)
>>          24 - 30           50.5716 (0;-1.4244)**   43.4056
>>(-1;-0.4537)*** 24.204 (0;-2.1416)
>>          30 - 36           44.4439 (0;-1.182)*     51.0996
>>(0;-1.5241)***  32.1219 (0;-1.5007)
>>          36 - 42           40.8604 (-1;-0.3423)    40.6045
>>(-1;-0.408)**   32.7949 (0;-2.75)
>>          42 - 48           46.301 (0;-1.1878)      21.6894
>>(0;-1.7041)     NA (NA;NA)
>>          48 - 54           38.0151 (-1;-0.7878)*   27.6954
>>(-1;0.0396)*    NA (NA;NA)
>>Short lag 18 - 24           7.5719 (1;0.4391)***    9.7039
>>(1;-0.2938)***   8.5525 (1;-0.4063)***
>>          24 - 30           8.3466 (1;-0.3122)***   9.8524
>>(0;-0.887)***    11.4154 (0;-1.2267)***
>>          30 - 36           9.4509 (1;-0.0795)***   9.0177
>>(1;-0.2654)***   9.441 (0;-0.7625)
>>          36 - 42           9.4921 (1;-0.1835)***   10.107 (0;-0.72)**
>>     10.912 (0;-1.3619)
>>          42 - 48           7.8254 (1;1.016)**      9.5687 (0;-0.9019)
>>     10.6842 (-1;0.0719)*
>>          48 - 54           7.7332 (1;1.2834)**     9.4626
>>(1;0.3173)***    10.0508 (0;-1.4876)
>>Long lag  18 - 24           16.7312 (0;-1.7286)     21.4786
>>(2;2.4726)**    41.6646 (1;-0.6796)***
>>          24 - 30           29.5637 (1;-0.0951)**   37.4517
>>(1;0.1032)***   38.2729 (1;-0.3249)***
>>          30 - 36           23.0214 (0;-1.3023)     35.0403
>>(1;0.9176)***   36.0989 (1;-0.2141)***
>>          36 - 42           10.579 (1;0.3292)       31.4878
>>(0;-1.2475)     38.0472 (1;-0.3049)**
>>          42 - 48           17.9077 (1;-1.2857)     26.8651
>>(1;0.0221)***   30.5705 (1;-0.5866)***
>>          48 - 54           18.832 (0;-2.3333)      40.375 (1;-1.417)*
>>     26.2463 (1;0.4025)***
>>
>>
>>>latex(ftab,cgroup=attributes(ftab)$col.vars$voicetype, rgroup=attributes(ftab)$row.vars$votcat, n.rgroup=c(6,6,6),file="")
>>
>>% latex.default(ftab, cgroup = attributes(ftab)$col.vars$voicetype,   
>>  rgroup = attributes(ftab)$row.vars$votcat, n.rgroup = c(6,         
>>6, 6), file = "")
>>%
>>\begin{table}[!tbp]
>> \begin{center}
>> \begin{tabular}{lclcl}\hline\hline
>>\multicolumn{1}{c}{\bfseries Voiced}&
>>\multicolumn{1}{c}{\bfseries }&
>>\multicolumn{1}{c}{\bfseries Voiceless unaspirated}&
>>\multicolumn{1}{c}{\bfseries }&
>>\multicolumn{1}{c}{\bfseries Voiceless aspirated}
>>\\ \cline{1-5}
>>\multicolumn{1}{c}{}&
>>\multicolumn{1}{c}{}&
>>\multicolumn{1}{c}{}&
>>\multicolumn{1}{c}{}&
>>\multicolumn{1}{c}{}
>>\\ \hline
>>&&&&\\
>>46.6158 (0;-1.6652)&&40.7417 (0;-0.6489)&&48.4164 (0;-1.0483)\\
>>50.5716 (0;-1.4244)**&&43.4056 (-1;-0.4537)***&&24.204 (0;-2.1416)\\
>>44.4439 (0;-1.182)*&&51.0996 (0;-1.5241)***&&32.1219 (0;-1.5007)\\
>>40.8604 (-1;-0.3423)&&40.6045 (-1;-0.408)**&&32.7949 (0;-2.75)\\
>>46.301 (0;-1.1878)&&21.6894 (0;-1.7041)&&NA (NA;NA)\\
>>38.0151 (-1;-0.7878)*&&27.6954 (-1;0.0396)*&&NA (NA;NA)\\
>>\hline
>>&&&&\\
>>7.5719 (1;0.4391)***&&9.7039 (1;-0.2938)***&&8.5525 (1;-0.4063)***\\
>>8.3466 (1;-0.3122)***&&9.8524 (0;-0.887)***&&11.4154 (0;-1.2267)***\\
>>9.4509 (1;-0.0795)***&&9.0177 (1;-0.2654)***&&9.441 (0;-0.7625)\\
>>9.4921 (1;-0.1835)***&&10.107 (0;-0.72)**&&10.912 (0;-1.3619)\\
>>7.8254 (1;1.016)**&&9.5687 (0;-0.9019)&&10.6842 (-1;0.0719)*\\
>>7.7332 (1;1.2834)**&&9.4626 (1;0.3173)***&&10.0508 (0;-1.4876)\\
>>\hline
>>&&&&\\
>>16.7312 (0;-1.7286)&&21.4786 (2;2.4726)**&&41.6646 (1;-0.6796)***\\
>>29.5637 (1;-0.0951)**&&37.4517 (1;0.1032)***&&38.2729 (1;-0.3249)***\\
>>23.0214 (0;-1.3023)&&35.0403 (1;0.9176)***&&36.0989 (1;-0.2141)***\\
>>10.579 (1;0.3292)&&31.4878 (0;-1.2475)&&38.0472 (1;-0.3049)**\\
>>17.9077 (1;-1.2857)&&26.8651 (1;0.0221)***&&30.5705 (1;-0.5866)***\\
>>18.832 (0;-2.3333)&&40.375 (1;-1.417)*&&26.2463 (1;0.4025)***\\
>>\hline
>>\end{tabular}
>>
>>\end{center}
>>
>>\end{table}
>>
>>
>>
>>As you can see, I do not get any row names, and I want two layers of
>>them (votcat and age in the formula). Column names work ok.
>>
>>Please, help me recreate the table above in latex form (if it is
>>indeed possible).
>>
>>/Fredrik
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 

-- 
David Whiting
School of Clinical Medical Sciences, The Medical School
University of Newcastle upon Tyne, NE2 4HH, UK.

"I love deadlines. I love the whooshing noise they make as they go by"
(Douglas Adams)



From ligges at statistik.uni-dortmund.de  Tue Aug 30 15:22:32 2005
From: ligges at statistik.uni-dortmund.de (Uwe Ligges)
Date: Tue, 30 Aug 2005 15:22:32 +0200
Subject: [R] seeking advice for manipulating matrices to find the
	difference
In-Reply-To: <1db726800508300602512c63bc@mail.gmail.com>
References: <1db726800508300602512c63bc@mail.gmail.com>
Message-ID: <43145D98.3090805@statistik.uni-dortmund.de>

roger bos wrote:

> I have two matrices (see example below) and I want the differences for the 
> matching row numbers, but the row numbers are not identical in the two 
> matrices. There are probably many ways to do this. Anyone know of any easy 
> way to do this? I could loop over them, but you know what they say about for 
> loops... Thanks, Roger

For example merge() by row numbers and calculate the differences in the 
next step.

Uwe Ligges


>  > out.r[1:5, 1:3]
> 1 2 3
> 1100 -0.0992 -0.0802 -0.0653
> 1200 -0.1242 -0.0417 0.0082
> 1300 -0.1681 -0.0211 -0.0958
> 1400 -0.0985 -0.1217 0.0026
> 1500 -0.0318 -0.0437 -0.0302
> 
>>out.p[1:5, 1:3]
> 
> 1 2 3
> 1100 -0.0564 -0.0573 -0.0224
> 1200 0.0528 -0.1134 -0.1186
> 1400 -0.0144 -0.1079 NA
> 1500 0.0919 -0.0371 -0.1602
> 1600 NA NA NA
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From roger.bos at gmail.com  Tue Aug 30 15:30:08 2005
From: roger.bos at gmail.com (roger bos)
Date: Tue, 30 Aug 2005 09:30:08 -0400
Subject: [R] seeking advice for manipulating matrices to find the
	difference
In-Reply-To: <43145D98.3090805@statistik.uni-dortmund.de>
References: <1db726800508300602512c63bc@mail.gmail.com>
	<43145D98.3090805@statistik.uni-dortmund.de>
Message-ID: <1db7268005083006301b64188b@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050830/68616436/attachment.pl

From dargosch at gmail.com  Tue Aug 30 15:36:34 2005
From: dargosch at gmail.com (Fredrik Karlsson)
Date: Tue, 30 Aug 2005 15:36:34 +0200
Subject: [R] Convert ftable to latex?
In-Reply-To: <43145553.4020601@ncl.ac.uk>
References: <376e97ec050830042067a91269@mail.gmail.com>
	<43145553.4020601@ncl.ac.uk>
Message-ID: <376e97ec050830063644cd007e@mail.gmail.com>

Thank you so much David. 

That example provided me with enough information for me to convert the
table to latex, with
subdivisions intact.

/Fredrik

On 8/30/05, David Whiting <david.whiting at ncl.ac.uk> wrote:
> Hi Fredrik,
> 
> What you need to do is to massage your table a little to get it into the
> appropriate structure and then use the rgroup and n.rgroup options.
> Here's an example using the Titanic data that come with R. Note that
> this is not necessarily (or even remotely likely?) the best way to get
> your data into the shape required, but hopefully it shows you what, in
> general, you need to do. You might find that you don't need to use
> ftable at all, you might find other ways of creating the table you need.
> In the example below, note in particular what x and x2 look like.
> 
> > library(Hmisc)
> > x <- ftable(Titanic, row.vars = 1:2)
> > x
>              Age      Child     Adult
>              Survived    No Yes    No Yes
> Class Sex
> 1st   Male                0   5   118  57
>       Female              0   1     4 140
> 2nd   Male                0  11   154  14
>       Female              0  13    13  80
> 3rd   Male               35  13   387  75
>       Female             17  14    89  76
> Crew  Male                0   0   670 192
>       Female              0   0     3  20
> > x.row.vars <- attr(x, "row.vars")
> > col1 <- x.row.vars[[1]]
> > col2 <- rep(x.row.vars[[2]], 4)
> > x2 <- data.frame(sex=col2, x[ ,])
> > colnames(x2) <- c("Sex", "No", "Yes", "No", "Yes")
> > x2
>      Sex No Yes  No Yes
> 1   Male  0   5 118  57
> 2 Female  0   1   4 140
> 3   Male  0  11 154  14
> 4 Female  0  13  13  80
> 5   Male 35  13 387  75
> 6 Female 17  14  89  76
> 7   Male  0   0 670 192
> 8 Female  0   0   3  20
> > latex(x2,
> +       title="",
> +       rowname="",
> +       rgroup=col1,
> +       cgroup=c("", "Child", "Adult"),
> +       n.cgroup=c(1, 2, 2),
> +       n.rgroup=rep(2, 4)
> +       )
> 
> 
> HTH.
> 
> Dave
> 
> 
> Fredrik Karlsson wrote:
> > Dear list,
> >
> > I cannot make the latex command to output a ftable objet the way I
> > want it. Is it posible?
> > I found a post in the archives saying that one should use the rgroup
> > and n.rgroup arguments to supply the row names, but so far I have been
> > unsuccessful.
> >
> > This is what I have:
> >
> >
> >>(ftable(tapply(worksub$vot,list(votcat=worksub$votcat,age=worksub$agemF,voicetype=worksub$Type),FUN="distribution.table.fun",digits=4)) -> ftab)
> >
> >                   voicetype                  Voiced   Voiceless
> > unaspirated     Voiceless aspirated
> > votcat    age
> > Prevoiced 18 - 24           46.6158 (0;-1.6652)     40.7417
> > (0;-0.6489)     48.4164 (0;-1.0483)
> >           24 - 30           50.5716 (0;-1.4244)**   43.4056
> > (-1;-0.4537)*** 24.204 (0;-2.1416)
> >           30 - 36           44.4439 (0;-1.182)*     51.0996
> > (0;-1.5241)***  32.1219 (0;-1.5007)
> >           36 - 42           40.8604 (-1;-0.3423)    40.6045
> > (-1;-0.408)**   32.7949 (0;-2.75)
> >           42 - 48           46.301 (0;-1.1878)      21.6894
> > (0;-1.7041)     NA (NA;NA)
> >           48 - 54           38.0151 (-1;-0.7878)*   27.6954
> > (-1;0.0396)*    NA (NA;NA)
> > Short lag 18 - 24           7.5719 (1;0.4391)***    9.7039
> > (1;-0.2938)***   8.5525 (1;-0.4063)***
> >           24 - 30           8.3466 (1;-0.3122)***   9.8524
> > (0;-0.887)***    11.4154 (0;-1.2267)***
> >           30 - 36           9.4509 (1;-0.0795)***   9.0177
> > (1;-0.2654)***   9.441 (0;-0.7625)
> >           36 - 42           9.4921 (1;-0.1835)***   10.107 (0;-0.72)**
> >      10.912 (0;-1.3619)
> >           42 - 48           7.8254 (1;1.016)**      9.5687 (0;-0.9019)
> >      10.6842 (-1;0.0719)*
> >           48 - 54           7.7332 (1;1.2834)**     9.4626
> > (1;0.3173)***    10.0508 (0;-1.4876)
> > Long lag  18 - 24           16.7312 (0;-1.7286)     21.4786
> > (2;2.4726)**    41.6646 (1;-0.6796)***
> >           24 - 30           29.5637 (1;-0.0951)**   37.4517
> > (1;0.1032)***   38.2729 (1;-0.3249)***
> >           30 - 36           23.0214 (0;-1.3023)     35.0403
> > (1;0.9176)***   36.0989 (1;-0.2141)***
> >           36 - 42           10.579 (1;0.3292)       31.4878
> > (0;-1.2475)     38.0472 (1;-0.3049)**
> >           42 - 48           17.9077 (1;-1.2857)     26.8651
> > (1;0.0221)***   30.5705 (1;-0.5866)***
> >           48 - 54           18.832 (0;-2.3333)      40.375 (1;-1.417)*
> >      26.2463 (1;0.4025)***
> >
> >>latex(ftab,cgroup=attributes(ftab)$col.vars$voicetype, rgroup=attributes(ftab)$row.vars$votcat, n.rgroup=c(6,6,6),file="")
> >
> > % latex.default(ftab, cgroup = attributes(ftab)$col.vars$voicetype,
> >   rgroup = attributes(ftab)$row.vars$votcat, n.rgroup = c(6,
> > 6, 6), file = "")
> > %
> > \begin{table}[!tbp]
> >  \begin{center}
> >  \begin{tabular}{lclcl}\hline\hline
> > \multicolumn{1}{c}{\bfseries Voiced}&
> > \multicolumn{1}{c}{\bfseries }&
> > \multicolumn{1}{c}{\bfseries Voiceless unaspirated}&
> > \multicolumn{1}{c}{\bfseries }&
> > \multicolumn{1}{c}{\bfseries Voiceless aspirated}
> > \\ \cline{1-5}
> > \multicolumn{1}{c}{}&
> > \multicolumn{1}{c}{}&
> > \multicolumn{1}{c}{}&
> > \multicolumn{1}{c}{}&
> > \multicolumn{1}{c}{}
> > \\ \hline
> > &&&&\\
> > 46.6158 (0;-1.6652)&&40.7417 (0;-0.6489)&&48.4164 (0;-1.0483)\\
> > 50.5716 (0;-1.4244)**&&43.4056 (-1;-0.4537)***&&24.204 (0;-2.1416)\\
> > 44.4439 (0;-1.182)*&&51.0996 (0;-1.5241)***&&32.1219 (0;-1.5007)\\
> > 40.8604 (-1;-0.3423)&&40.6045 (-1;-0.408)**&&32.7949 (0;-2.75)\\
> > 46.301 (0;-1.1878)&&21.6894 (0;-1.7041)&&NA (NA;NA)\\
> > 38.0151 (-1;-0.7878)*&&27.6954 (-1;0.0396)*&&NA (NA;NA)\\
> > \hline
> > &&&&\\
> > 7.5719 (1;0.4391)***&&9.7039 (1;-0.2938)***&&8.5525 (1;-0.4063)***\\
> > 8.3466 (1;-0.3122)***&&9.8524 (0;-0.887)***&&11.4154 (0;-1.2267)***\\
> > 9.4509 (1;-0.0795)***&&9.0177 (1;-0.2654)***&&9.441 (0;-0.7625)\\
> > 9.4921 (1;-0.1835)***&&10.107 (0;-0.72)**&&10.912 (0;-1.3619)\\
> > 7.8254 (1;1.016)**&&9.5687 (0;-0.9019)&&10.6842 (-1;0.0719)*\\
> > 7.7332 (1;1.2834)**&&9.4626 (1;0.3173)***&&10.0508 (0;-1.4876)\\
> > \hline
> > &&&&\\
> > 16.7312 (0;-1.7286)&&21.4786 (2;2.4726)**&&41.6646 (1;-0.6796)***\\
> > 29.5637 (1;-0.0951)**&&37.4517 (1;0.1032)***&&38.2729 (1;-0.3249)***\\
> > 23.0214 (0;-1.3023)&&35.0403 (1;0.9176)***&&36.0989 (1;-0.2141)***\\
> > 10.579 (1;0.3292)&&31.4878 (0;-1.2475)&&38.0472 (1;-0.3049)**\\
> > 17.9077 (1;-1.2857)&&26.8651 (1;0.0221)***&&30.5705 (1;-0.5866)***\\
> > 18.832 (0;-2.3333)&&40.375 (1;-1.417)*&&26.2463 (1;0.4025)***\\
> > \hline
> > \end{tabular}
> >
> > \end{center}
> >
> > \end{table}
> >
> >
> >
> > As you can see, I do not get any row names, and I want two layers of
> > them (votcat and age in the formula). Column names work ok.
> >
> > Please, help me recreate the table above in latex form (if it is
> > indeed possible).
> >
> > /Fredrik
> >
> > ______________________________________________
> > R-help at stat.math.ethz.ch mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> >
> 
> --
> David Whiting
> School of Clinical Medical Sciences, The Medical School
> University of Newcastle upon Tyne, NE2 4HH, UK.
> 
> "I love deadlines. I love the whooshing noise they make as they go by"
> (Douglas Adams)
> 
> 
> 


-- 
My Gentoo + PVR-350 + IVTV + MythTV blog is on  
http://gentoomythtv.blogspot.com/



From p.dalgaard at biostat.ku.dk  Tue Aug 30 15:46:44 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 30 Aug 2005 15:46:44 +0200
Subject: [R] stratified Wilcoxon available?
In-Reply-To: <Pine.LNX.4.51.0508301454570.20777@artemis.imbe.med.uni-erlangen.de>
References: <3.0.6.32.20050828173610.007953a0@pop.gmx.net>
	<Pine.LNX.4.51.0508291440140.15465@artemis.imbe.med.uni-erlangen.de>
	<x2vf1ohjkj.fsf@turmalin.kubism.ku.dk>
	<Pine.LNX.4.51.0508301139510.30831@artemis.imbe.med.uni-erlangen.de>
	<x2fysrd232.fsf@turmalin.kubism.ku.dk>
	<Pine.LNX.4.51.0508301454570.20777@artemis.imbe.med.uni-erlangen.de>
Message-ID: <x2br3fczaz.fsf@turmalin.kubism.ku.dk>

torsten at hothorn.de writes:

> > Nice to see that the old code made sense.
> 
> Nice to see that the new code is working correctly :-)
> 
> > A bit surprising that it
> > gives _exactly_ the same result as the blockwise ranking in coin...
> 
> why? Without ties, the conditional and unconditional versions of the tests
> should have exactly the same result.

Oh, just that there are a number of little things that could have been
done in slightly different but asymptotically equivalent ways. The
scale factor for the within-block ranks e.g.
 
> > Perhaps introduce some ties? (round(y,1) is usually effective).
> >
> 
> this should generate differences, yes.
> 
> > The trend test is easily fixed: just spell "t value" without capital V
> > as we do nowadays. This gives
> >
> >
> > > SKruskal.test(y ~ x | b, data = mydf, trend = TRUE)
> >
> >         Kruskal-Wallis stratified rank sum trend test
> >
> > data:  y , group:  x , strata:  b , trend:  as.numeric(group)
> > Z = -0.1624, df = 1, p-value = 0.871
> >
> > > SKruskal.test(y ~ x | b, data = mydf, trend = 1:3)
> >
> >         Kruskal-Wallis stratified rank sum trend test
> >
> > data:  y , group:  x , strata:  b , trend:  1 2 3
> > Z = -0.1624, df = 1, p-value = 0.871
> >
> > (The df=1 is a bit misleading in this case...)
> >
> 
> maybe report 0.1624^2 = 0.0264 as test statistic (same as with teststat
> = "quad" in `coin')?

Yes, but there was a point in getting a signed statistic. Otherwise, I
might as well have reused the code that used the SSD from the anova
table. 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From hb at maths.lth.se  Tue Aug 30 15:47:06 2005
From: hb at maths.lth.se (Henrik Bengtsson)
Date: Tue, 30 Aug 2005 15:47:06 +0200
Subject: [R] Who can help me?
In-Reply-To: <12760.1125405438@www70.gmx.net>
References: <17741.1125404039@www70.gmx.net> <12760.1125405438@www70.gmx.net>
Message-ID: <4314635A.4070809@maths.lth.se>

A quick reply,

are you looking for the matrix multiplication operator? In R it's %*%

Henrik

Christian Hinz wrote:
> I have own function wrote. I used an algorithm, which was written in Matlab.
> 
> in matlab:
> ...
> gamma = inv(v)*g;
> ...
> 
> #v = matrix of variable size, v=vv(k) => k=2 => dimension of v 2x2
> #g = a line vector with 4 elements e.g. g=[1,0,2,0];
> 
> my rewritten r-file:
> ...
> gamma = solve(v)*g;
> ...
> 
> which is my error? Who can help me?
> 
> thank you in advance.
> 
> Chris
> 
>



From p.dalgaard at biostat.ku.dk  Tue Aug 30 15:54:46 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 30 Aug 2005 15:54:46 +0200
Subject: [R] Who can help me?
In-Reply-To: <4314635A.4070809@maths.lth.se>
References: <17741.1125404039@www70.gmx.net> <12760.1125405438@www70.gmx.net>
	<4314635A.4070809@maths.lth.se>
Message-ID: <x27je3cyxl.fsf@turmalin.kubism.ku.dk>

Henrik Bengtsson <hb at maths.lth.se> writes:

> A quick reply,
> 
> are you looking for the matrix multiplication operator? In R it's %*%

... and solve(v,g) is probably preferable anyway.

> > my rewritten r-file:
> > ...
> > gamma = solve(v)*g;
> > ...


-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From chrysopa at gmail.com  Tue Aug 30 16:01:32 2005
From: chrysopa at gmail.com (Ronaldo Reis-Jr.)
Date: Tue, 30 Aug 2005 11:01:32 -0300
Subject: [R] Doubt about nested aov output
Message-ID: <200508301101.32212.chrysopa@gmail.com>

Hi,

I have two doubts about the nested aov output.

1) I have this:
> anova.ratos <- aov(Glicogenio~Tratamento+Error(Tratamento/Rato/Figado))
> summary(anova.ratos)

Error: Tratamento
           Df  Sum Sq Mean Sq
Tratamento  2 1557.56  778.78

Error: Tratamento:Rato
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals  3 797.67  265.89               

Error: Tratamento:Rato:Figado
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals 12  594.0    49.5               

Error: Within
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals 18 381.00   21.17               

R dont make the F and P automatically, it is possible?

I Like an output like this:

Error: Tratamento
           Df  Sum Sq Mean Sq F value Pr(>F)
Tratamento  2 1557.56  778.78   2.929 0.197

Error: Tratamento:Rato
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals  3 797.67  265.89   5.372 0.0141      

Error: Tratamento:Rato:Figado
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals 12  594.0    49.5   2.339 0.0503        

Error: Within
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals 18 381.00   21.17         

Why it not make automatic calculations? It is possible?


2) I can say that Error: Tratamento:Rato means an interaction between 
Tratamento and Rato? Normally the : represents an interaction, but in this 
output I think that it dont mean the interaction. 

Any explanation are welcome.

Thanks
Ronaldo
-- 
O casamento ?? o caminho mais caro para se dormir com uma mulher.
--
|>   // | \\   [***********************************]
|   ( ??   ?? )  [Ronaldo Reis J??nior                ]
|>      V      [UFV/DBA-Entomologia                ]
|    /     \   [36570-000 Vi??osa - MG              ]
|>  /(.''`.)\  [Fone: 31-3899-4007                 ]
|  /(: :'  :)\ [chrysopa at insecta.ufv.br            ]
|>/ (`. `'` ) \[ICQ#: 5692561 | LinuxUser#: 205366 ]
|    ( `-  )   [***********************************]
|>>  _/   \_Powered by GNU/Debian Woody/Sarge



From uofiowa at gmail.com  Tue Aug 30 16:36:50 2005
From: uofiowa at gmail.com (Omar Lakkis)
Date: Tue, 30 Aug 2005 10:36:50 -0400
Subject: [R] aggregate
Message-ID: <3f87cc6d0508300736256fb5cb@mail.gmail.com>

How can I aggregate this data.frame to list the min and max date for
each unique id?

>From this :
> r = data.frame(id=rep(seq(1:3), 3), date= as.Date(c(rep("2005-08-25",3), rep("2005-08-26",3), rep("2005-08-29", 3)), "%Y-%m-%d"))
> r
id     date
 1     2005-08-25
 2     2005-08-25
 3     2005-08-25
 1     2005-08-26
 2     2005-08-26
 3     2005-08-26
 1     2005-08-29
 2     2005-08-29
 3     2005-08-29

I want to get to this:
> 
id    start              end
 1    2005-08-25    2005-08-29
 2    2005-08-25    2005-08-29
 3    2005-08-25    2005-08-29

I tried aggregate and aggregate.data.frame but the date column keeps
getting converted into a number.



From rincke at physik.uni-kassel.de  Tue Aug 30 16:46:42 2005
From: rincke at physik.uni-kassel.de (Karsten Rincke)
Date: Tue, 30 Aug 2005 16:46:42 +0200
Subject: [R] graphics
Message-ID: <43147152.5030203@physik.uni-kassel.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050830/5673daae/attachment.pl

From dimitris.rizopoulos at med.kuleuven.be  Tue Aug 30 16:57:04 2005
From: dimitris.rizopoulos at med.kuleuven.be (Dimitris Rizopoulos)
Date: Tue, 30 Aug 2005 16:57:04 +0200
Subject: [R] aggregate
References: <3f87cc6d0508300736256fb5cb@mail.gmail.com>
Message-ID: <013e01c5ad73$155455e0$0540210a@www.domain>

maybe you could use something like this:

dat <- data.frame(id = rep(1:3, 3), date = as.Date(rep(c("2005-08-25", 
"2005-08-26", "2005-08-29"), each = 3)))
########################
do.call("rbind", lapply(split(dat, dat$id), function(x) data.frame(id 
= x$id[1], start = min(x$date), end = max(x$date))))


I hope it helps.

Best,
Dimitris

----
Dimitris Rizopoulos
Ph.D. Student
Biostatistical Centre
School of Public Health
Catholic University of Leuven

Address: Kapucijnenvoer 35, Leuven, Belgium
Tel: +32/16/336899
Fax: +32/16/337015
Web: http://www.med.kuleuven.be/biostat/
     http://www.student.kuleuven.be/~m0390867/dimitris.htm


----- Original Message ----- 
From: "Omar Lakkis" <uofiowa at gmail.com>
To: <r-help at stat.math.ethz.ch>
Sent: Tuesday, August 30, 2005 4:36 PM
Subject: [R] aggregate


> How can I aggregate this data.frame to list the min and max date for
> each unique id?
>
>>From this :
>> r = data.frame(id=rep(seq(1:3), 3), date= 
>> as.Date(c(rep("2005-08-25",3), rep("2005-08-26",3), 
>> rep("2005-08-29", 3)), "%Y-%m-%d"))
>> r
> id     date
> 1     2005-08-25
> 2     2005-08-25
> 3     2005-08-25
> 1     2005-08-26
> 2     2005-08-26
> 3     2005-08-26
> 1     2005-08-29
> 2     2005-08-29
> 3     2005-08-29
>
> I want to get to this:
>>
> id    start              end
> 1    2005-08-25    2005-08-29
> 2    2005-08-25    2005-08-29
> 3    2005-08-25    2005-08-29
>
> I tried aggregate and aggregate.data.frame but the date column keeps
> getting converted into a number.
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
>



From shigesong at gmail.com  Tue Aug 30 17:09:49 2005
From: shigesong at gmail.com (Shige Song)
Date: Tue, 30 Aug 2005 23:09:49 +0800
Subject: [R] How to set starting values for lmer?
Message-ID: <5abc11d805083008092fe632d4@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050830/024138d4/attachment.pl

From Manuel.Schneider at eawag.ch  Tue Aug 30 17:22:12 2005
From: Manuel.Schneider at eawag.ch (Schneider, Manuel)
Date: Tue, 30 Aug 2005 17:22:12 +0200
Subject: [R] Non-standard characters in Ascii-Files
Message-ID: <744893FCE2B96241BD15C17F2F8649E101DA40@EA-MAIL.eawag.wroot.emp-eaw.ch>

Dear Henrik, dear Peter

many thanks for your reply. I've now done tests on other computers and yes, this is a local problem on my computer. Unfortunately, my second HD produces the same flaw so it must be the disk controller or whatever. When correcting the files with vedit, the non-standard characters sometimes seem to jump around to other places. Funny bug, but definitely nothing to do with R.

Best regards

Manuel

-----Urspr??ngliche Nachricht-----
Von: Henrik Bengtsson [mailto:hb at maths.lth.se] 
Gesendet: Montag, 29. August 2005 15:43
An: Peter Dalgaard
Cc: Schneider, Manuel; r-help at stat.math.ethz.ch
Betreff: Re: [R] Non-standard characters in Ascii-Files


Peter Dalgaard wrote:
> "Schneider, Manuel" <Manuel.Schneider at eawag.ch> writes:
> 
> 
>>Dear R-list
>>
>>In R 2.1.1 under Win XP on a P4 with 2GB Ram when typing
>>
>>>temp<-matrix(c(1:16000000),4000,4000)
>>>write(file="temp.txt", temp)
>>>scan("temp.txt")
>>
>>I receive:
>>Error in scan("temp.txt") : scan() expected 'a real', received 
>>'414851'
>>
>>The motivation for evoquing this meassage is that I am getting the 
>>same meassage with exported Ascii-Files from the GIS. The files 
>>contain very few, randomly scattered non-standard Ascii-characters. 
>>This seems to be a local problem on my machine but I do not have a 
>>clue on the reason (OS, Memory, HD?) nor who to ask. So, my apologies 
>>for misusing this list and many thanks for any suggestion.
> 
> 
> I tried this on a Linux box (with a somewhat outdated R version 
> though), and apart from eating up memory and disk space, nothing 
> untoward seems to happen:
> 
> 
>>temp<-matrix(c(1:16000000),4000,4000)
>>write(file="/tmp/temp.txt", temp)
>>dummy <- scan("/tmp/temp.txt")
> 
> Read 16000000 items

and on my R v2.1.1 patched (2005-08-25) on WinXP Pro SP2 (sic!), I get

 > temp<-matrix(c(1:16000000),4000,4000)
 > write(file="temp.txt", temp)
 > file.info("temp.txt")$size
[1] 136088897
 > rm(temp)
 > dummy <- scan("temp.txt")
Read 16000000 items

> I'd suspect your harddisk or the disk controller...

I second this, check the file with an external application or try the 
following ad-hoc code:

zcan <- function(filename) {
   fh <- file(filename, open="r");
   on.exit(close(fh));
   count <- 0;
   while(TRUE) {
     s <- readChar(fh, n=1024);
     if (nchar(s) == 0)
       break;
     count <- count + nchar(s);
     if (gsub("[\n 0-9]*", "", s) != "")
       stop("Error after reading ", count, " characters: ", s);
   }
}

Cheers

Henrik



From spencer.graves at pdf.com  Tue Aug 30 17:53:37 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 30 Aug 2005 08:53:37 -0700
Subject: [R] question about custom contrasts in ANOVA
In-Reply-To: <20050824232454.W25801@fellspt.charm.net>
References: <20050824232454.W25801@fellspt.charm.net>
Message-ID: <43148101.7040304@pdf.com>

	  Since I have not seen a reply to this post, I will attempt a brief 
comment:  I won't comment on the specifics, but your general approach 
seems appropriate.  You already seem to know that a factor with k levels 
is converted into (k-1) separate numerical variables, and a separate 
regression coefficient is estimated for each one.

	  To see in more detail what you were estimating, I looked at the 
following:

	  model.matrix(y~xma)
	  fit2 <- aov(y~xma)
	  attributes(fit2)

	  From the latter, I identified "contrasts" as something that might be 
interesting to examine, as follows:

	  fit2$contrasts

	  For clarity, I think I might reduce the number of observations 
substantially, limiting myself to only 2 or 3 schools and paramterize 
the problem manually, but preserving imbalance.  Then I'd use "lm", 
specifying the terms in different orders.  With imbalance, the answer 
depends on the order unfortunately.  When in doubt, I often experiment 
with changing the order:  If the changes do not affect the conclusions, 
I pick the simplest case to present to my audience.  If the changes do 
affect the conclusions, I know I need to worry about which answer seems 
most correct, and I also know something about the limits of the 
conclusions.

	  I know this doesn't answer your question, but I hope it helped with a 
solution methodology.

	  Best Wishes,
	  Spencer Graves

Scot W McNary wrote:

> Hi,
> 
> I have a problem in which I have test score data on students from a number 
> of schools.  In each school I have a measure of whether or not they 
> received special programming.  I am interested in the interaction between 
> school and attendance to the programming, but in a very select set of 
> comparisons.  I'd like to cast the test as one in which students in each 
> school who attend are compared with students who don't across all schools. 
> So, I would be comparing school 1 attenders with school 1 non-attenders, 
> school 2 attenders with school 2 non-attenders, etc.  The reason for the 
> custom contrast is that the between school comparisons (e.g., school 1 
> attenders vs. school 2 non-attenders) are of less interest.
> 
> This seems to require a custom contrast statement for the interaction 
> term.  I have a toy example that seems to work as it should, but wonder if 
> I've correctly created the contrast needed.
> 
> Here is a toy example (code put together from bits taken from MASS ch 6, 
> and various R-help postings, (e.g., 
> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/49077.html)):
> 
> # toy interaction contrast example, 10 schools, 100 kids, 5 attenders (1) 
> # and 5 non-attenders (2) in each school
> 
> # make the data
> school <- gl(10, 10)
> attend <- gl(2, 5, 100)
> # creates an interaction with schools 6 and 7
> y <- c(sample(seq(450, 650, 1), 50), rep(c(rep(650, 5), rep(450, 5)), 2),
>  	sample(seq(450, 650, 1), 30))
> 
> # anova
> summary(aov(y ~ school * attend))
> 
> # graphically
> Means <- tapply(y, list(school, attend), mean)
> 
> plot(Means[,1], col="red", type = "l", ylim = c(400,700))
> 
> points(Means[,2], col="blue", type = "l")
> 
> # create contrasts for hypothesis of interest
> # school i attend j - school i attend j'
> # for all schools
> sxa <- interaction(school, attend)
> sxam <- as.matrix(rbind(diag(1,10), diag(1,10) * -1))
> contrasts(sxa) <- sxam
> 
> summary(aov(y ~ sxa), split=list(sxa=1:10), expand.split = T)
> 
> The actual problem has a few more schools, other covariates, considerably 
> more students, and is somewhat unbalanced.
> 
> Thanks,
> 
> Scot
> 
> 
> --
>    Scot W. McNary  email:smcnary at charm.net
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From ferri.leberl at gmx.at  Tue Aug 30 18:46:08 2005
From: ferri.leberl at gmx.at (Mag. Ferri Leberl)
Date: Tue, 30 Aug 2005 18:46:08 +0200
Subject: [R] xtable
Message-ID: <200508301846.08853.ferri.leberl@gmx.at>

I have installed package xtable with

su -c 'R CMD INSTALL xtable'

and got this promising feedback:

* Installing *source* package 'xtable' ...
** R
** data
** help
 >>> Building/Updating help pages for package 'xtable'
     Formats: text html latex example
* DONE (xtable)

Despite that, R returns:

Error: couldn't find function "print.xtable"
Execution halted

when I call that function.
What have I done wrong? Do I have to activate the package everytime when I 
start R?
Thank you in advance!



From ripley at stats.ox.ac.uk  Tue Aug 30 18:46:27 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 30 Aug 2005 17:46:27 +0100 (BST)
Subject: [R] question about custom contrasts in ANOVA
In-Reply-To: <43148101.7040304@pdf.com>
References: <20050824232454.W25801@fellspt.charm.net>
	<43148101.7040304@pdf.com>
Message-ID: <Pine.LNX.4.61.0508301741220.16651@gannet.stats>

I was puzzled as to what the question actually was. If you set

> options(contrasts=c("contr.sum", "contr.poly"))

the interaction contrasts are precisely those created manually.  Nothing 
fancier is required.  But I am not sure what you want to do with them once 
you have them.

On Tue, 30 Aug 2005, Spencer Graves wrote:

> 	  Since I have not seen a reply to this post, I will attempt a brief
> comment:  I won't comment on the specifics, but your general approach
> seems appropriate.  You already seem to know that a factor with k levels
> is converted into (k-1) separate numerical variables, and a separate
> regression coefficient is estimated for each one.
>
> 	  To see in more detail what you were estimating, I looked at the
> following:
>
> 	  model.matrix(y~xma)
> 	  fit2 <- aov(y~xma)
> 	  attributes(fit2)
>
> 	  From the latter, I identified "contrasts" as something that might be
> interesting to examine, as follows:
>
> 	  fit2$contrasts
>
> 	  For clarity, I think I might reduce the number of observations
> substantially, limiting myself to only 2 or 3 schools and paramterize
> the problem manually, but preserving imbalance.  Then I'd use "lm",
> specifying the terms in different orders.  With imbalance, the answer
> depends on the order unfortunately.  When in doubt, I often experiment
> with changing the order:  If the changes do not affect the conclusions,
> I pick the simplest case to present to my audience.  If the changes do
> affect the conclusions, I know I need to worry about which answer seems
> most correct, and I also know something about the limits of the
> conclusions.
>
> 	  I know this doesn't answer your question, but I hope it helped with a
> solution methodology.
>
> 	  Best Wishes,
> 	  Spencer Graves
>
> Scot W McNary wrote:
>
>> Hi,
>>
>> I have a problem in which I have test score data on students from a number
>> of schools.  In each school I have a measure of whether or not they
>> received special programming.  I am interested in the interaction between
>> school and attendance to the programming, but in a very select set of
>> comparisons.  I'd like to cast the test as one in which students in each
>> school who attend are compared with students who don't across all schools.
>> So, I would be comparing school 1 attenders with school 1 non-attenders,
>> school 2 attenders with school 2 non-attenders, etc.  The reason for the
>> custom contrast is that the between school comparisons (e.g., school 1
>> attenders vs. school 2 non-attenders) are of less interest.
>>
>> This seems to require a custom contrast statement for the interaction
>> term.  I have a toy example that seems to work as it should, but wonder if
>> I've correctly created the contrast needed.
>>
>> Here is a toy example (code put together from bits taken from MASS ch 6,
>> and various R-help postings, (e.g.,
>> http://finzi.psych.upenn.edu/R/Rhelp02a/archive/49077.html)):
>>
>> # toy interaction contrast example, 10 schools, 100 kids, 5 attenders (1)
>> # and 5 non-attenders (2) in each school
>>
>> # make the data
>> school <- gl(10, 10)
>> attend <- gl(2, 5, 100)
>> # creates an interaction with schools 6 and 7
>> y <- c(sample(seq(450, 650, 1), 50), rep(c(rep(650, 5), rep(450, 5)), 2),
>>  	sample(seq(450, 650, 1), 30))
>>
>> # anova
>> summary(aov(y ~ school * attend))
>>
>> # graphically
>> Means <- tapply(y, list(school, attend), mean)
>>
>> plot(Means[,1], col="red", type = "l", ylim = c(400,700))
>>
>> points(Means[,2], col="blue", type = "l")
>>
>> # create contrasts for hypothesis of interest
>> # school i attend j - school i attend j'
>> # for all schools
>> sxa <- interaction(school, attend)
>> sxam <- as.matrix(rbind(diag(1,10), diag(1,10) * -1))
>> contrasts(sxa) <- sxam
>>
>> summary(aov(y ~ sxa), split=list(sxa=1:10), expand.split = T)
>>
>> The actual problem has a few more schools, other covariates, considerably
>> more students, and is somewhat unbalanced.
>>
>> Thanks,
>>
>> Scot
>>
>>
>> --
>>    Scot W. McNary  email:smcnary at charm.net
>>
>> ______________________________________________
>> R-help at stat.math.ethz.ch mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
> -- 
> Spencer Graves, PhD
> Senior Development Engineer
> PDF Solutions, Inc.
> 333 West San Carlos Street Suite 700
> San Jose, CA 95110, USA
>
> spencer.graves at pdf.com
> www.pdf.com <http://www.pdf.com>
> Tel:  408-938-4420
> Fax: 408-280-7915
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From andy_liaw at merck.com  Tue Aug 30 19:08:34 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Tue, 30 Aug 2005 13:08:34 -0400
Subject: [R] xtable
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED3EB@usctmx1106.merck.com>

Have you load the package with library(xtable) before attempting?

Andy

> From:  Mag. Ferri Leberl
> 
> I have installed package xtable with
> 
> su -c 'R CMD INSTALL xtable'
> 
> and got this promising feedback:
> 
> * Installing *source* package 'xtable' ...
> ** R
> ** data
> ** help
>  >>> Building/Updating help pages for package 'xtable'
>      Formats: text html latex example
> * DONE (xtable)
> 
> Despite that, R returns:
> 
> Error: couldn't find function "print.xtable"
> Execution halted
> 
> when I call that function.
> What have I done wrong? Do I have to activate the package 
> everytime when I 
> start R?
> Thank you in advance!
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From spencer.graves at pdf.com  Tue Aug 30 19:09:15 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 30 Aug 2005 10:09:15 -0700
Subject: [R] question about custom contrasts in ANOVA
In-Reply-To: <Pine.LNX.4.61.0508301741220.16651@gannet.stats>
References: <20050824232454.W25801@fellspt.charm.net>	<43148101.7040304@pdf.com>
	<Pine.LNX.4.61.0508301741220.16651@gannet.stats>
Message-ID: <431492BB.6070208@pdf.com>

Dear Prof. Ripley:

	  Agreed.  I thought that coding the factor levels manually and / or 
looking at model.matrix(y~xma) after further simplifying the problem 
might help Scot clarify his question.

	  Thanks,
	  Spencer Graves

Prof Brian Ripley wrote:

> I was puzzled as to what the question actually was. If you set
> 
> 
>>options(contrasts=c("contr.sum", "contr.poly"))
> 
> 
> the interaction contrasts are precisely those created manually.  Nothing 
> fancier is required.  But I am not sure what you want to do with them once 
> you have them.
> 
> On Tue, 30 Aug 2005, Spencer Graves wrote:
> 
> 
>>	  Since I have not seen a reply to this post, I will attempt a brief
>>comment:  I won't comment on the specifics, but your general approach
>>seems appropriate.  You already seem to know that a factor with k levels
>>is converted into (k-1) separate numerical variables, and a separate
>>regression coefficient is estimated for each one.
>>
>>	  To see in more detail what you were estimating, I looked at the
>>following:
>>
>>	  model.matrix(y~xma)
>>	  fit2 <- aov(y~xma)
>>	  attributes(fit2)
>>
>>	  From the latter, I identified "contrasts" as something that might be
>>interesting to examine, as follows:
>>
>>	  fit2$contrasts
>>
>>	  For clarity, I think I might reduce the number of observations
>>substantially, limiting myself to only 2 or 3 schools and paramterize
>>the problem manually, but preserving imbalance.  Then I'd use "lm",
>>specifying the terms in different orders.  With imbalance, the answer
>>depends on the order unfortunately.  When in doubt, I often experiment
>>with changing the order:  If the changes do not affect the conclusions,
>>I pick the simplest case to present to my audience.  If the changes do
>>affect the conclusions, I know I need to worry about which answer seems
>>most correct, and I also know something about the limits of the
>>conclusions.
>>
>>	  I know this doesn't answer your question, but I hope it helped with a
>>solution methodology.
>>
>>	  Best Wishes,
>>	  Spencer Graves
>>
>>Scot W McNary wrote:
>>
>>
>>>Hi,
>>>
>>>I have a problem in which I have test score data on students from a number
>>>of schools.  In each school I have a measure of whether or not they
>>>received special programming.  I am interested in the interaction between
>>>school and attendance to the programming, but in a very select set of
>>>comparisons.  I'd like to cast the test as one in which students in each
>>>school who attend are compared with students who don't across all schools.
>>>So, I would be comparing school 1 attenders with school 1 non-attenders,
>>>school 2 attenders with school 2 non-attenders, etc.  The reason for the
>>>custom contrast is that the between school comparisons (e.g., school 1
>>>attenders vs. school 2 non-attenders) are of less interest.
>>>
>>>This seems to require a custom contrast statement for the interaction
>>>term.  I have a toy example that seems to work as it should, but wonder if
>>>I've correctly created the contrast needed.
>>>
>>>Here is a toy example (code put together from bits taken from MASS ch 6,
>>>and various R-help postings, (e.g.,
>>>http://finzi.psych.upenn.edu/R/Rhelp02a/archive/49077.html)):
>>>
>>># toy interaction contrast example, 10 schools, 100 kids, 5 attenders (1)
>>># and 5 non-attenders (2) in each school
>>>
>>># make the data
>>>school <- gl(10, 10)
>>>attend <- gl(2, 5, 100)
>>># creates an interaction with schools 6 and 7
>>>y <- c(sample(seq(450, 650, 1), 50), rep(c(rep(650, 5), rep(450, 5)), 2),
>>> 	sample(seq(450, 650, 1), 30))
>>>
>>># anova
>>>summary(aov(y ~ school * attend))
>>>
>>># graphically
>>>Means <- tapply(y, list(school, attend), mean)
>>>
>>>plot(Means[,1], col="red", type = "l", ylim = c(400,700))
>>>
>>>points(Means[,2], col="blue", type = "l")
>>>
>>># create contrasts for hypothesis of interest
>>># school i attend j - school i attend j'
>>># for all schools
>>>sxa <- interaction(school, attend)
>>>sxam <- as.matrix(rbind(diag(1,10), diag(1,10) * -1))
>>>contrasts(sxa) <- sxam
>>>
>>>summary(aov(y ~ sxa), split=list(sxa=1:10), expand.split = T)
>>>
>>>The actual problem has a few more schools, other covariates, considerably
>>>more students, and is somewhat unbalanced.
>>>
>>>Thanks,
>>>
>>>Scot
>>>
>>>
>>>--
>>>   Scot W. McNary  email:smcnary at charm.net
>>>
>>>______________________________________________
>>>R-help at stat.math.ethz.ch mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
>>-- 
>>Spencer Graves, PhD
>>Senior Development Engineer
>>PDF Solutions, Inc.
>>333 West San Carlos Street Suite 700
>>San Jose, CA 95110, USA
>>
>>spencer.graves at pdf.com
>>www.pdf.com <http://www.pdf.com>
>>Tel:  408-938-4420
>>Fax: 408-280-7915
>>
>>______________________________________________
>>R-help at stat.math.ethz.ch mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>>
> 
> 

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From dmbates at gmail.com  Tue Aug 30 19:30:15 2005
From: dmbates at gmail.com (Douglas Bates)
Date: Tue, 30 Aug 2005 12:30:15 -0500
Subject: [R] How to set starting values for lmer?
In-Reply-To: <5abc11d805083008092fe632d4@mail.gmail.com>
References: <5abc11d805083008092fe632d4@mail.gmail.com>
Message-ID: <40e66e0b050830103068bfbd86@mail.gmail.com>

On 8/30/05, Shige Song <shigesong at gmail.com> wrote:
> Dear All,
> 
> Can anyone give me some hints about how to set starting values for a lmer
> model? For complicated models like this, good starting values can help the
> numerical computation and make the model converge faster. Thanks!
> 
> Shige

I agree but I haven't gotten around to designing how that could be
done.  It could be easy or difficult depending on how you want to
represent the starting values.

If you look at the (only) lmer method function you will see that it
has a section

          if (lmm) {                    ## linear mixed model
              .Call("lmer_initial", mer, PACKAGE="Matrix")
              .Call("lmer_ECMEsteps", mer, cv$niterEM, cv$EMverbose,
PACKAGE = "Matrix")
              LMEoptimize(mer) <- cv

for linear mixed models.  The object "mer" is a mixed-effects
representation and the list "cv" is the control values.  The only
thing that the C function "lmer_initial" does is set the initial
values of the relative precision matrices for the random effects. 
These are the inverses of the variance-covariance matrices relative to
the variance of the per-observation noise term.  They are stored
(upper triangle only) in a slot called "Omega" of the mer class (which
is contained in the lmer class).

There is no purpose in setting initial values for the fixed-effects
parameters or the variance of the per-observation noise term because
these are profiled out of the optimization.  The optimization is only
over the values in the Omega slot.

I can allow those values to be set from an argument and only call
"lmer_initialize" if that argument is missing.  Will that be
sufficient for you?



From mmiller3 at iupui.edu  Tue Aug 30 19:35:25 2005
From: mmiller3 at iupui.edu (Michael A. Miller)
Date: Tue, 30 Aug 2005 12:35:25 -0500
Subject: [R] FFT, frequs, magnitudes, phases
In-Reply-To: <200508301135.04475.wolfgang.waser@rz.hu-berlin.de> (Wolfgang
	Waser's message of "Tue, 30 Aug 2005 11:35:04 +0200")
References: <200508301135.04475.wolfgang.waser@rz.hu-berlin.de>
Message-ID: <87aciz2uqq.fsf@lumen.indyrad.iupui.edu>

>>>>> "Wolfgang" == Wolfgang Waser <wolfgang.waser at rz.hu-berlin.de> writes:

    > I would be most obliged for any comments and help.

Wolfgang,

I've used R's fft to filter ECG signals and will comment on your
commentary based on my experience.  First, as an easily
accessible reference, I suggest "The Scientist and Engineer's
Guide to Digital Signal Processing," which is available in pdf
form at http://www.dspguide.com.  It includes several chapters on
the discrete Fourier transform and the fast Fourier transform
algorithm (which is what R's fft implements) and a chapter on
applications that contains info on spectral analysis.

    > What does R's fft() deliver?

    > fft() is calculated with a single one-dimensional
    > vector. Information on data acquisition frequency and block
    > length (in sec or whatever) can not be included into the
    > fft()-call.

    > Confusingly, if you calculate fft() on a sample vector
    > consisting of 2 pure sin frequencies, you get 4 peaks, not
    > 2.

That is the nature of the fft algorithm.  It returns values of
the discrete Fourier transform for both positive and negative
frequencies.

    > As stated above, fft() gives only "meaningful" frequency up
    > to half the sampling frequency. R, however, gives you
    > frequencies up to the sampling frequency. 

It is important to remember that the fft algorithm doesn't return
any frequency data at all.  It returns values of the fft that
correspond to frequencies from -f_Nyquist to +f_Nyquist.  It is
up to the user to calculate the frequency values.

Here's an example:

## Read some sample ecg data
ecg <- read.table('http://www.indyrad.iupui.edu/public/mmiller3/sample-ecg-1kHz.txt')
names(ecg) <- c('t','ecg')

ecg$t <- ecg$t/1000  # convert from ms to s

par(mfrow=c(2,2))

## Plot the ecg:
plot(ecg ~ t, data=ecg, type='l', main='ECG data sampled at 1 kHz', xlab='Time [s]')

## Calculate fft(ecg):
ecg$fft <- fft(ecg$ecg)

## Plot fft(ecg):
#plot(ecg$fft, type='l')

## Plot Mod(fft(ecg)):
plot(Mod(ecg$fft), type='l', log='y', main='FFT of ecg vs index')

## Find the sample period:
delta <- ecg$t[2] - ecg$t[1]

## Calculate the Nyquist frequency:
f.Nyquist <- 1 / 2 / delta

## Calculate the frequencies.  (Since ecg$t is in seconds, delta
## is in seconds, f.Nyquist is in Hz and ecg$freq is in Hz)
## (Note: I may be off by 1 in indexing here ????)
ecg$freq <- f.Nyquist*c(seq(nrow(ecg)/2), -rev(seq(nrow(ecg)/2)))/(nrow(ecg)/2)

## Plot fft vs frequency
plot(Mod(fft) ~ freq, data=ecg, type='l', log='y', main='FFT of ECG vs frequency', xlab='Frequency [Hz]')

## Now let's look at some artificial data:
x <- seq(100000)/1000  # pretend we're sampling at 1 kHz

## We'll put in two frequency components, plus a dc offset
f1 <- 5  # Hz
f2 <- 2  # Hz
y <- 0.1*sin(2*pi*f1*x) + sin(2*pi*f2*x) + 50
fft.y <- fft(y)
delta <- x[2] - x[1]
f.Nyquist <- 1 / 2 / delta
f <- f.Nyquist*c(seq(length(x)/2), -rev(seq(length(x)/2)))/(length(x)/2)

par(mfrow=c(2,2))
plot(x,y, type='l', xlim=c(0,20))
plot(f, Mod(fft.y), type='l', log='y')

## Now let's zoom in and mark the points were I expect to see peaks:
plot(f, Mod(fft.y), type='l', log='y', xlim=c(-10,10))
rug(c(-f1, -f2, 0, f1, f2), col='red', side=3)




Hope this is helpful, Mike

-- 
Michael A. Miller                               mmiller3 at iupui.edu
  Imaging Sciences, Department of Radiology, IU School of Medicine



From elvis at xlsolutions-corp.com  Tue Aug 30 19:56:51 2005
From: elvis at xlsolutions-corp.com (elvis@xlsolutions-corp.com)
Date: Tue, 30 Aug 2005 10:56:51 -0700
Subject: [R] Course***R/Splus Programming Techniques***New York,
	September 2005
Message-ID: <20050830105651.a108dc04937c07ba67766dad37185406.96a366b1a1.wbe@email.email.secureserver.net>

XLSolutions Corporation (www.xlsolutions-corp.com) is proud to
announce  2-day "R/S-plus Fundamentals and Programming
Techniques" in New York City.
www.xlsolutions-corp.com/Rfund.htm


**** New York City ------------------------ September 22nd-23rd, 2005

Reserve your seat now at the early bird rates! 
Payment due AFTER the class

Course Description:

This two-day beginner to intermediate R/S-plus course focuses on a
broad spectrum of topics, from reading raw data to a comparison of R
and S. We will learn the essentials of data manipulation, graphical
visualization and R/S-plus programming. We will explore statistical
data analysis tools,including graphics with data sets. How to enhance
your plots, build your own packages (librairies) and connect via
ODBC,etc.
We will perform some statistical modeling and fit linear regression
models. Participants are encouraged to bring data for interactive
sessions

With the following outline:

- An Overview of R and S
- Data Manipulation and Graphics
- Using Lattice Graphics
- A Comparison of R and S-Plus
- How can R Complement SAS?
- Writing Functions
- Avoiding Loops
- Vectorization
- Statistical Modeling
- Project Management
- Techniques for Effective use of R and S
- Enhancing Plots
- Using High-level Plotting Functions
- Building and Distributing Packages (libraries)
- Connecting; ODBC, Rweb, Orca via sockets and via Rjava

Interested in R/Splus Advanced course? email us.

Email us for group discounts.
Email Sue Turner: sue at xlsolutions-corp.com
Phone: 206-686-1578
Visit us: www.xlsolutions-corp.com/training.htm
Please let us know if you and your colleagues are interested in this
classto take advantage of group discount. Register now to secure your
seat!

Interested in R/Splus Advanced course? email us.


Cheers,
Elvis Miller, PhD
Manager Training.
XLSolutions Corporation
206 686 1578
www.xlsolutions-corp.com
elvis at xlsolutions-corp.com



From deepayan.sarkar at gmail.com  Tue Aug 30 20:49:49 2005
From: deepayan.sarkar at gmail.com (Deepayan Sarkar)
Date: Tue, 30 Aug 2005 13:49:49 -0500
Subject: [R] graphics
In-Reply-To: <43147152.5030203@physik.uni-kassel.de>
References: <43147152.5030203@physik.uni-kassel.de>
Message-ID: <eb555e6605083011492f0bd3f3@mail.gmail.com>

On 8/30/05, Karsten Rincke <rincke at physik.uni-kassel.de> wrote:
> Hello,
> I guess a have a very simple problem though up to now couldn't solve it:
> I want to plot two datasets wihtin one plot like plot(x) provides it for
> one dataset(type="b" that is: points connected by lines).
> Example data 'x':
> Befragung1   Befragung2   Befragung3   Geschlecht
> 2.25   2.34   1.78   weiblich
> 1.34   3.45   2.23   maennlich
> The two rows of the example above form two datasets. Now I'm looking for
> something like plot(~x |Geschlecht, ... ): X-axis containing
> Befragung1...3, y-axis containing the values given by the matrix 'x',
> points within one dataset (row of 'x') connected by lines.
> I already tried various possibilities provided by 'lattice' or 'grid'  -
> but there seems to be a basic misunderstanding on my side so that I
> could not produce any good result.
> Would by very happy to get some hints!



R likes data vectors to be columns, not rows.  With your data, you
could try


matplot(t(mydata[, 1:3]), type = 'b')


but it would probably make more sense to have the data in a different
format to begin with.  It could either be in the `wide' format:



Befragung   weiblich  maennlich
1           2.25      1.34
2           2.34      3.45
3           1.78      2.23


or the `long' format:


Befragung   y         Geschlecht
1           2.25      weiblich
2           2.34      weiblich
3           1.78      weiblich
1           1.34      maennlich
2           3.45      maennlich
3           2.23      maennlich



With the wide format you could use matplot as before, or use xyplot
from lattice:


mydata <-
    read.table(textConnection("
Befragung   weiblich  maennlich
1           2.25      1.34
2           2.34      3.45
3           1.78      2.23"), header = TRUE)

xyplot(maennlich + weiblich ~ Befragung,
       data = mydata,
       type = 'b',
       auto.key = TRUE)


With the long format, you could similarly do:


mydata <-
    read.table(textConnection("
Befragung   y         Geschlecht
1           2.25      weiblich
2           2.34      weiblich
3           1.78      weiblich
1           1.34      maennlich
2           3.45      maennlich
3           2.23      maennlich
"), header = TRUE)

xyplot(y ~ Befragung, data = mydata, groups = Geschlecht,
       type = 'b', auto.key = TRUE)


Hope that helps,

-Deepayan



From ramasamy at cancer.org.uk  Tue Aug 30 21:03:20 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 30 Aug 2005 20:03:20 +0100
Subject: [R] reexpand a matrix after subsetting
In-Reply-To: <200508291811.12899.tamir@imp.univie.ac.at>
References: <200508291811.12899.tamir@imp.univie.ac.at>
Message-ID: <1125428601.5873.14.camel@dhcppc3>

1) Do you really need to turn rows 3, 6, 9 of mat into NA ? I would
suggest the use of usediff() to remove them after complete.cases

2) The trick is to create a matrix of the same dimension as 'mat' but
initialised with NAs followed by replacing the required rows.

Example :

   w <- which( complete.cases(mat) )
   w <- setdiff( w, c(3,6,9) )
 
   out <- matrix( NA, nr=nrow(mat), nc=ncol(mat) )
   out[ w, ] <- 2 * mat[ w, ]

Regards, Adai



On Mon, 2005-08-29 at 18:11 +0200, Ido M. Tamir wrote:
> Hi,
> 
> suppose I have a matrix (or dataframe) 
> as a result from subsetting.
> 
> mat <- matrix(1:20,ncol=2)
> mat[c(3,6,9),] <- NA
> cc <- complete.cases(mat)
> sub <- mat[cc,,drop=FALSE]
> sub <- sub * 2
> #some caluculations with sub.
> 
> now I would like to expand sub somehow
> so row 3,6, and 9 would be filled with 
> NAs but the rest should be in place again.
> Is there a simple function for this?
> 
> merge is not an option.
> 
> Thank you very much for your help.
> 
> Ido
> 
> 
>       [,1] [,2]
>  [1,]    2   22
>  [2,]    4   24
>  [3,]   NA   NA
>  [4,]    8   28
>  [5,]   10   30
>  [6,]   NA   NA
>  [7,]   14   34
>  [8,]   16   36
>  [9,]   NA   NA
> [10,]   20   40
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ramasamy at cancer.org.uk  Tue Aug 30 21:20:14 2005
From: ramasamy at cancer.org.uk (Adaikalavan Ramasamy)
Date: Tue, 30 Aug 2005 20:20:14 +0100
Subject: [R] seeking advice for manipulating matrices to find
	the	difference
In-Reply-To: <1db7268005083006301b64188b@mail.gmail.com>
References: <1db726800508300602512c63bc@mail.gmail.com>
	<43145D98.3090805@statistik.uni-dortmund.de>
	<1db7268005083006301b64188b@mail.gmail.com>
Message-ID: <1125429614.5873.17.camel@dhcppc3>

You can shorten the notation by=0 .


On Tue, 2005-08-30 at 09:30 -0400, roger bos wrote:
> Uwe,
>  Thanks. I have used merge a lot, but I didn't realize you could merge on 
> row names. I got it working now:
>  test <- merge(out.r[1:5, 1:3], out.p[1:5, 1:3], by="row.names", all.x=TRUE)
>  Thanks,
> Roger
> 
> 
>  On 8/30/05, Uwe Ligges <ligges at statistik.uni-dortmund.de> wrote: 
> > 
> > roger bos wrote:
> > 
> > > I have two matrices (see example below) and I want the differences for 
> > the
> > > matching row numbers, but the row numbers are not identical in the two
> > > matrices. There are probably many ways to do this. Anyone know of any 
> > easy
> > > way to do this? I could loop over them, but you know what they say about 
> > for
> > > loops... Thanks, Roger
> > 
> > For example merge() by row numbers and calculate the differences in the
> > next step.
> > 
> > Uwe Ligges
> > 
> > 
> > > > out.r[1:5, 1:3]
> > > 1 2 3
> > > 1100 -0.0992 -0.0802 -0.0653
> > > 1200 -0.1242 -0.0417 0.0082
> > > 1300 -0.1681 -0.0211 -0.0958
> > > 1400 -0.0985 -0.1217 0.0026
> > > 1500 -0.0318 -0.0437 -0.0302
> > >
> > >>out.p[1:5, 1:3]
> > >
> > > 1 2 3
> > > 1100 -0.0564 -0.0573 -0.0224
> > > 1200 0.0528 -0.1134 -0.1186
> > > 1400 -0.0144 -0.1079 NA
> > > 1500 0.0919 -0.0371 -0.1602
> > > 1600 NA NA NA
> > >
> > > [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at stat.math.ethz.ch mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide! 
> > http://www.R-project.org/posting-guide.html
> > 
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>



From ivo_welch at mailblocks.com  Tue Aug 30 21:24:44 2005
From: ivo_welch at mailblocks.com (ivo welch)
Date: Tue, 30 Aug 2005 12:24:44 -0700
Subject: [R] TeXtext font encoding?
Message-ID: <ivo_welch-0/ErwA11f3l80WgUmYiAsPWMgufc0Dr@mailblocks.com>


Dear R wizards:

Has anyone gotten the TeXtext font encoding to work?  If I execute:

if (is.null(postscriptFonts()$lucida)) {
  luafmfiles <- c("/usr/share/texmf/fonts/afm/yandy/lubright/lbr.afm",
                  "/usr/share/texmf/fonts/afm/yandy/lubright/lbd.afm",
                  "/usr/share/texmf/fonts/afm/yandy/lubright/lbi.afm",
                  "/usr/share/texmf/fonts/afm/yandy/lubright/lbdi.afm",
                  "/usr/share/texmf/fonts/afm/yandy/lumath/lbms.afm")
   postscriptFonts(lucida=postscriptFont("Lucida", metrics=luafmfiles, 
encoding="TeXtext"))
}

pdf(file = "test.pdf", fonts="lucida");
par(family="lucida");
plot( 40:50, 40:50, pch=40:50 );
dev.off();

the R code runs fine under 2.1.1, but the resulting .pdf file has an 
error:

$ pdffonts test.pdf
name                                 type         emb sub uni object ID
------------------------------------ ------------ --- --- --- ---------
Error: Wrong type in font encoding resource differences (array)
Error: Wrong type in font encoding resource differences (array)
Error: Wrong type in font encoding resource differences (array)
Error: Wrong type in font encoding resource differences (array)
ZapfDingbats                         Type 1       no  no  no       5  0
Helvetica                            Type 1       no  no  no      11  0
Helvetica-Bold                       Type 1       no  no  no      12  0
Helvetica-Oblique                    Type 1       no  no  no      13  0
Helvetica-BoldOblique                Type 1       no  no  no      14  0
Symbol                               Type 1       no  no  no      15  0
LucidaBright                         Type 1       no  no  no      16  0
LucidaBright-Demi                    Type 1       no  no  no      17  0
LucidaBright-Italic                  Type 1       no  no  no      18  0
LucidaBright-DemiItalic              Type 1       no  no  no      19  0
LucidaNewMath-Symbol                 Type 1       no  no  no      20  0


ghostscript 7.07 dies when I try to do the next processing step of 
embedding the fonts with ps2pdf13 .  These errors do not occur when I 
do not specify a font encoding.  (I believe I need this encoding for 
the math symbols, like '=', to appear in the right places.)

is this an R (enc file) bug or another mistake of mine?  as always, 
help would be highly appreciated.

sincerely,  /iaw


---
ivo welch



From xcong at stat.rice.edu  Tue Aug 30 21:26:58 2005
From: xcong at stat.rice.edu (X. Cong)
Date: Tue, 30 Aug 2005 19:26:58 -0000
Subject: [R] problem in generating positive stable random numbers
Message-ID: <006e01c5c5f4$dc9b1410$59142a80@stat.rice.edu>

Dear all,

I am trying to use the
rstable(n, alpha, beta, gamma = 1, delta = 0, pm = c(0, 1, 2)))

 function to generate positive stable random numbers. For positive stable
distribution, beta==1 and alpha is in (0,1), which defines random variables
with support (0, infinity). So, I used rstable(100, 0.5, 1) for an example.
I found that this gives me some negative numbers. For example,

> rstable(10, 0.5, 1)
 [1]   6.3016252 399.3659030  11.2735789   1.9550625  -0.6762333   1.6810761
 [7]   0.9091360   1.9100991  -0.7593737  24.2788471

Does anybody know why this should happen?

Thanks a lot,
Julie



From isotta_felli at yahoo.com  Tue Aug 30 21:28:26 2005
From: isotta_felli at yahoo.com (Isotta Felli)
Date: Tue, 30 Aug 2005 12:28:26 -0700 (PDT)
Subject: [R] crosstab for n-way  contingency tables
Message-ID: <20050830192826.69997.qmail@web35212.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050830/5b3bbd41/attachment.pl

From mschwartz at mn.rr.com  Tue Aug 30 21:54:22 2005
From: mschwartz at mn.rr.com (Marc Schwartz (via MN))
Date: Tue, 30 Aug 2005 14:54:22 -0500
Subject: [R] crosstab for n-way  contingency tables
In-Reply-To: <20050830192826.69997.qmail@web35212.mail.mud.yahoo.com>
References: <20050830192826.69997.qmail@web35212.mail.mud.yahoo.com>
Message-ID: <1125431662.4480.34.camel@localhost.localdomain>

On Tue, 2005-08-30 at 12:28 -0700, Isotta Felli wrote:
> Dear list.
>  
> New to R, I'm looking for a way of using crosstab to output
> low-dimensional (higher than 2) contingency tables (frequencies,
> per-cents by rows, % by columns, mean, quantiles....) I'm looking for
> something of the following sort
>  
> dataframe: singers, 
> categorical variates: voice category (soprano,mezzo-soprano, ...) ,
> voice type( drammatic, spinto, lirico-spinto, lirico, leggero), school
> (german, italian, french, russian, anglo-saxon, other);repertory
> (opera, Lieder, oratorio, operetta)
> continuous variate: age
>  
> I would like to tabulate the frequencies (relative percentages)  say
> in the following way
> columns: school  repertory
> rows :      voice category  voice type
>  
> or to output in the cells of the above table, the statistics
> (mean/median/quantiles) for age
>  
> 
> I've seen that the function bwplot(age~school | repertory, data=
> singers, layout=c(4,2)) would do graphically something similar to what
> I want, but I desire the output also in tabular form
>  
> Thanks
>  
> Isotta


I don't know that you will find a single function that will do all of
what you desire, but you can look at the ctab() function, which is in
the 'catspec' package on CRAN by John Hendrickx. This will do multi-way
tables with summary row/col statistics.

There is also the CrossTable() function in the 'gmodels' package on
CRAN, though this will only do one way and two way tables, with summary
row/col statistics.

Neither of the above provide typical summary output for continuous data.
They are more for categorical variables.

For simple count multi-way output, you can also look at the ftable()
function which is in the base package. Also look at the summary()
function in the base package which will provide range, mean, quantile
data for continuous variables. It may just be a matter of formatting the
output in a fashion that you desire on a post analysis basis.

HTH,

Marc Schwartz



From p.dalgaard at biostat.ku.dk  Tue Aug 30 21:55:50 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 30 Aug 2005 21:55:50 +0200
Subject: [R] problem in generating positive stable random numbers
In-Reply-To: <006e01c5c5f4$dc9b1410$59142a80@stat.rice.edu>
References: <006e01c5c5f4$dc9b1410$59142a80@stat.rice.edu>
Message-ID: <x2y86jb3nd.fsf@turmalin.kubism.ku.dk>

"X. Cong" <xcong at stat.rice.edu> writes:

> Dear all,
> 
> I am trying to use the
> rstable(n, alpha, beta, gamma = 1, delta = 0, pm = c(0, 1, 2)))
> 
>  function to generate positive stable random numbers. For positive stable
> distribution, beta==1 and alpha is in (0,1), which defines random variables
> with support (0, infinity). So, I used rstable(100, 0.5, 1) for an example.
> I found that this gives me some negative numbers. For example,
> 
> > rstable(10, 0.5, 1)
>  [1]   6.3016252 399.3659030  11.2735789   1.9550625  -0.6762333   1.6810761
>  [7]   0.9091360   1.9100991  -0.7593737  24.2788471
> 
> Does anybody know why this should happen?

Doesn't sound like it should... 

>From where did you get rstable()? It isn't part of R itself, and
poking around shows at least three different sources for it
(CircStats, fBasics, stable (Lambert/Lindsey, not on CRAN)). I seem to
recall that the third one also has a distribution function which is
almost, but not quite monotone.

The usual advice of taking package problems to the package maintainer
applies. 

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From xcong at stat.rice.edu  Tue Aug 30 21:59:20 2005
From: xcong at stat.rice.edu (X. Cong)
Date: Tue, 30 Aug 2005 19:59:20 -0000
Subject: [R] problem in generating positive stable random numbers
References: <006e01c5c5f4$dc9b1410$59142a80@stat.rice.edu>
	<x2y86jb3nd.fsf@turmalin.kubism.ku.dk>
Message-ID: <00a001c5c5f9$61590640$59142a80@stat.rice.edu>

> >From where did you get rstable()? It isn't part of R itself, and
> poking around shows at least three different sources for it
> (CircStats, fBasics, stable (Lambert/Lindsey, not on CRAN)). I seem to
> recall that the third one also has a distribution function which is
> almost, but not quite monotone.
> 
> The usual advice of taking package problems to the package maintainer
> applies. 
> 


I got rstable() from the fBasics package. Thanks.



From wuertz at itp.phys.ethz.ch  Wed Aug 31 00:32:51 2005
From: wuertz at itp.phys.ethz.ch (Diethelm Wuertz)
Date: Tue, 30 Aug 2005 22:32:51 +0000
Subject: [R] problem in generating positive stable random numbers
In-Reply-To: <006e01c5c5f4$dc9b1410$59142a80@stat.rice.edu>
References: <006e01c5c5f4$dc9b1410$59142a80@stat.rice.edu>
Message-ID: <4314DE93.1070006@itp.phys.ethz.ch>

X. Cong wrote:

>Dear all,
>
>I am trying to use the
>rstable(n, alpha, beta, gamma = 1, delta = 0, pm = c(0, 1, 2)))
>
> function to generate positive stable random numbers. For positive stable
>distribution, beta==1 and alpha is in (0,1), which defines random variables
>with support (0, infinity). 
>

Just a remark - rstable() is from R-package  fBasics ...
1) I think the support for beta=1 and alpha = 1/2 is (-1, infinity), 
isn't it? - Then everything is fine.
2) beta ==1 is a difficult value for numerical computations, try also 
beta = 1-1e-8!
3) Use the program stable.exe from 
http://academic2.american.edu/~jpnolan/stable/stable.html for comparison!
4) Take care in which parametrization you work ...

Best regards
Diethelm


Remark for 3)

  STABLE  3.14.02 (2005/02/28)   Serial number        131
  Copyright 1997-2003 John P. Nolan (jpnolan at american.edu)

  Output file: stable.out                     

  Current tolerance settings:
   -1 debug (F)
    1 relative error for pdf ( 0.1200000000E-13)
    2 relative error for cdf ( 0.1200000000E-13)
    3 relative error for quantiles ( 0.1200000000E-13)
    4 alpha and beta rounding ( 0.1000000000E-01)
    5 x tolerance near zeta ( 0.5000000000E-02)
    6 exponential cutoff (  200.0000000    )
    7 peak/strim location tolerance ( 0.1000000000E-13)
    8 strim tolerance ( 0.1000000000E-50)
    9 minimum alpha ( 0.1000000000    )
   10 minimum xtol ( 0.1000000000E-12)
   11 threshold for quantile search ( 0.1000000000E-09)

   8/30/2005        23:59:34.72  

          Simulation of stable random variables
          n=      10   iseed=             -1   iparam=    0
               alpha      beta     gamma     delta
             0.50000   1.00000   1.00000   0.00000

   39.6516320412757    
  0.247648247004956    
   12.3195079629881    
 -0.146866807337654    
  0.640815989111718    
  0.219559949961403    
   3.05027005351445    
 -0.667188061257615    
   4.02760809108209    
 -0.588547074136516    



>So, I used rstable(100, 0.5, 1) for an example.
>I found that this gives me some negative numbers. For example,
>
>  
>
>>rstable(10, 0.5, 1)
>>    
>>
> [1]   6.3016252 399.3659030  11.2735789   1.9550625  -0.6762333   1.6810761
> [7]   0.9091360   1.9100991  -0.7593737  24.2788471
>
>Does anybody know why this should happen?
>
>Thanks a lot,
>Julie
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>



From donghu at itsa.ucsf.edu  Wed Aug 31 00:46:13 2005
From: donghu at itsa.ucsf.edu (donghu@itsa.ucsf.edu)
Date: Tue, 30 Aug 2005 14:46:13 PST
Subject: [R] p-value in lrm
Message-ID: <200508302246.j7UMkDiO005369@itsa.ucsf.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050830/eea03f9e/attachment.pl

From f.harrell at vanderbilt.edu  Wed Aug 31 01:05:55 2005
From: f.harrell at vanderbilt.edu (Frank E Harrell Jr)
Date: Tue, 30 Aug 2005 18:05:55 -0500
Subject: [R] p-value in lrm
In-Reply-To: <200508302246.j7UMkDiO005369@itsa.ucsf.edu>
References: <200508302246.j7UMkDiO005369@itsa.ucsf.edu>
Message-ID: <4314E653.3010708@vanderbilt.edu>

donghu at itsa.ucsf.edu wrote:
> Hi,
> 
> How can I get the p-value, S.E., and Z from the result of lrm fit?  Thank you.
> 
> Donglei

That's automatic.  The print method for lrm in the Design package does 
that.  Better though is the anova method which gives you the right 
pooled tests when you have nonlinear effects, interactions, etc.

If by "get" you mean "retrieve for use in other code" you can look at 
print.lrm for hints, or use coef(fit) and diag(Varcov(fit)).

-- 
Frank E Harrell Jr   Professor and Chair           School of Medicine
                      Department of Biostatistics   Vanderbilt University



From ivo_welch at mailblocks.com  Wed Aug 31 01:20:52 2005
From: ivo_welch at mailblocks.com (ivo welch)
Date: Tue, 30 Aug 2005 16:20:52 -0700
Subject: [R] Font Encodings --- some work, some don't
Message-ID: <ivo_welch-0VILwA/di3l8LIDSbRfJ1NKT1O9t+X/@mailblocks.com>


Dear R wizards:  I believe some more font encoding info. some of the 
font encodings work, others do not:  IsoLatin1, MacRoman, WinAnsi, and 
PDFDoc seem fine.  AdobeStd, AdobeSym, ISOLatin2, ISOLatin9, and 
TeXtext seem broken, in that the resulting output file is silently 
corrupt.  The font encoding error does not appear in the postscript 
device driver, and it works fine.  It would be nice if R gave an error 
message, instead of producing corrupt .pdf files.  Just a suggestion...

Regards,

/iaw
---
ivo welch



From joseclaudio.faria at terra.com.br  Wed Aug 31 01:34:32 2005
From: joseclaudio.faria at terra.com.br (Jose Claudio Faria)
Date: Tue, 30 Aug 2005 20:34:32 -0300
Subject: [R] Statistics with R
Message-ID: <4314ED08.5080304@terra.com.br>

Hi Vincent,

Thanks for your good work!

Best,
-- 
Jose Claudio Faria
Brasil/Bahia/UESC/DCET
Estatistica Experimental/Prof. Adjunto
mails:
  joseclaudio.faria at terra.com.br
  jc_faria at uesc.br
  jc_faria at uol.com.br
tel: 73-3634.2779



From actpsycho at yahoo.com  Wed Aug 31 01:41:14 2005
From: actpsycho at yahoo.com (b)
Date: Tue, 30 Aug 2005 16:41:14 -0700 (PDT)
Subject: [R] Installation help
Message-ID: <20050830234114.32176.qmail@web54302.mail.yahoo.com>

Solved the problem with the 'R' installation!

One of the processes that loads up on startup was
conflicting with it. It was a program called
"Gameutil.exe" which seems to enhance games by
altering display modes. For some reason a conflict
existed. Anyhow I dont really need the Gameutil.exe,
so I'm as happy as Larry R works!



From h.wickham at gmail.com  Wed Aug 31 02:33:42 2005
From: h.wickham at gmail.com (hadley wickham)
Date: Tue, 30 Aug 2005 19:33:42 -0500
Subject: [R] crosstab for n-way contingency tables
In-Reply-To: <20050830192826.69997.qmail@web35212.mail.mud.yahoo.com>
References: <20050830192826.69997.qmail@web35212.mail.mud.yahoo.com>
Message-ID: <f8e6ff0505083017332da025fc@mail.gmail.com>

Hi Isotta,

You can do this with the reshape package (available from CRAN). eg

install.packages("reshape")
library(reshape)

data(singer, package="lattice")
singer$type <- c("drammatic", "spinto", "lirico-spinto", "lirico",
"leggero")[sample(1:5, 235, replace=T)]
singer$school <- c("german", "italian", "french", "russian",
"anglo-saxon", "other")[sample(1:6, 235, replace=T)]
singer$repertory <- c("opera", "Lieder", "oratorio",
"operetta")[sample(1:4, 235, replace=T)]

# First deshape the data (this puts it in a form easy to reshape)
singer_d <- deshape(singer, id=c("type", "school", "repertory",
"voice.part"), m="height")

# You can do things like
reshape(singer_d, type  ~ school, length, subset=variable=="height")
reshape(singer_d, type  ~ school, mean, subset=variable=="height")

# or with margins
reshape(singer_d, type + school ~ ., length,
subset=variable=="height", margins=c("type","grand_row"))

# or with multiple stats
opera.sum <- function(x) c(min=min(x), mean=mean(x), max=max(x))
reshape(singer_d, type + school ~ ., opera.sum, subset=variable=="height")

# What you'd want for your data, but doesn't work well with this example
# and is going to be a big table regardless!
reshape(singer_d, type + voice.part ~ school + repertory, length)

There's some more info available at http://had.co.nz/reshape but I'm
still working on it.

Hadley



From spencer.graves at pdf.com  Wed Aug 31 04:53:15 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 30 Aug 2005 19:53:15 -0700
Subject: [R] Panel regression in R
In-Reply-To: <20050824225243.42118.qmail@web31009.mail.mud.yahoo.com>
References: <20050824225243.42118.qmail@web31009.mail.mud.yahoo.com>
Message-ID: <43151B9B.2070208@pdf.com>

	  Since I have not seen a reply to this, I will offer a brief comment. 
  I first tried, 'RSiteSearch("panel regression")', which produced many 
irrelevant hits.  Then I tried, 'RSiteSearch("analysis of panel data")'. 
  The fourth item on that list was 
"http://finzi.psych.upenn.edu/R/Rhelp02a/archive/26962.html".  Have you 
seen this?  By the way, I highly recommend the book mentioned in this 
post, Pinheiro and Bates (2000), "Mixed-effects Models in S and S-PLUS" 
(Springer);  it has contributed substantively to my education.  Other 
hits in this "RSiteSearch" may also interest you.

	  If you still have questions, please submit another post -- preferably 
after reading the posting guide! 
"http://www.R-project.org/posting-guide.html".  This "posting guide" was 
designed to help people get better answers quicker with overall less 
effort.  It may look like silly bureaucracy, but it seems to me to be 
quite helpful when followed.

	  spencer graves

Haibo Huang wrote:

> I am currently trying to replicate the results I got
> from RATS for a panel regression. The codes in RATS
> looks like this: 
> 
> * Final equation for Office Cap Rate Spread
> * Regression, Panel Data
> preg(effects=time, method=random) CapRate
> # CapRate{1} RentCycle{1} VacancyChangeYTY
> InflationYTY RealGDPyty 
> 
> Just wonder what R package also allow me to have the
> options like (effects=time, method=random). Could
> anyone share some thoughts with me? Any input will be
> helpful. Thank you very much!
> 
> Best,
> Ed.
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From spencer.graves at pdf.com  Wed Aug 31 05:00:43 2005
From: spencer.graves at pdf.com (Spencer Graves)
Date: Tue, 30 Aug 2005 20:00:43 -0700
Subject: [R] PDL model
In-Reply-To: <2CAE512CEB72EE448AADE3444E1FB718023CB590@ad04mexefd3.ad.admin.ch>
References: <2CAE512CEB72EE448AADE3444E1FB718023CB590@ad04mexefd3.ad.admin.ch>
Message-ID: <43151D5B.7000400@pdf.com>

	  From 'RSiteSearch("polynomial distributed lag")', I learned that 
there was a discussion of this issue not quite two years ago, which may 
interest you.  In brief, Thomas Lumley provded code with some noted 
limitations.

	  spencer graves

Carsten.Colombier at efv.admin.ch wrote:

> Dear r-help team:
> 
> Is a package implemented in R which includes a function that calculates
> polynomial distributed lag models (also: Almon models, pdl-model)? Provided
> a pdl function is available, can it be applied to robust statistics like
> MM-estimators?
> 
> Thanks in advance!
> 
> Best regards,
> Carsten Colombier
> 
> Dr. Carsten Colombier
> Economist
> Group of Economic Advisers
> Swiss Federal Finance Administration
> Bundesgasse 3
> CH-3003 Bern
> 
> phone +41 31 322 63 32
> fax +41 31 323 08 33
> email: carsten.colombier at efv.admin.ch
> www.efv.admin.ch
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html

-- 
Spencer Graves, PhD
Senior Development Engineer
PDF Solutions, Inc.
333 West San Carlos Street Suite 700
San Jose, CA 95110, USA

spencer.graves at pdf.com
www.pdf.com <http://www.pdf.com>
Tel:  408-938-4420
Fax: 408-280-7915



From nkn at turing.une.edu.au  Wed Aug 31 05:49:39 2005
From: nkn at turing.une.edu.au (Nam-Ky Nguyen)
Date: Wed, 31 Aug 2005 13:49:39 +1000 (EST)
Subject: [R] R binaries
Message-ID: <20735.129.180.11.34.1125460179.squirrel@129.180.11.34>

Dear Rexperts,

I intend to burn some R CDs to colleagues in Vietnam.  I want to put all
binary files for base as well as contributed packages (for both Windows
and Linux). It is very time consuming if I download files by files. Is
there a place a can buy a CD with all the mentioned files?

Regards,
-- 
Nam-Ky Nguyen, Senior Lecturer
School of Mathematics, Statistics and Computer Science
University of New England, Armidale NSW 2351 Australia
nkn at turing.une.edu.au              Tel: +612 6773 2763
http://turing.une.edu.au/~nkn      Fax: +612 6773 3312

Please convert Word files into PDF files before sending them to me.
See http://www.gnu.org/philosophy/no-word-attachments.html



From berwin at maths.uwa.edu.au  Wed Aug 31 06:23:26 2005
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Wed, 31 Aug 2005 12:23:26 +0800
Subject: [R] R binaries
In-Reply-To: <20735.129.180.11.34.1125460179.squirrel@129.180.11.34>
References: <20735.129.180.11.34.1125460179.squirrel@129.180.11.34>
Message-ID: <17173.12478.297309.297964@bossiaea.maths.uwa.edu.au>

G'day Nam-Ky,

>>>>> "NKN" == Nam-Ky Nguyen <nkn at turing.une.edu.au> writes:

    NKN> I intend to burn some R CDs to colleagues in Vietnam.  I want
    NKN> to put all binary files for base as well as contributed
    NKN> packages (for both Windows and Linux).
I don't believe that precompiled binary files for Linux exist, since
they would depend very much on which flavour of Linux you are running.

    NKN> It is very time consuming if I download files by files. Is
    NKN> there a place a can buy a CD with all the mentioned files?
Not that I am aware off.  But I would do the following for easy
download of all contributed files:  Issue  from an R session the
following commands (mostly untested):

> options(repos=c(CRAN="http://cran.au.r-project.org/"))
> tmp <- available.packages()  # Or just use CRAN.packages() ??
## To download all source files
> download.packages(tmp, destdir=".")
## To download all windows binary
> download.packages(tmp, destdir=".", type="win.binary")

If you do it from a Windows machine, you may have to adapt the destdir
argument in those commands.  Also, if you sit behind a proxy, then you
might have to first issue an appropriate
'Sys.putenv("http_proxy"="put your proxy here")' command.

available.packages() does not seem to have a type argument according
to its documentation, so I guess that even if it is run under Windows
that it returns a list of all source packages available in contrib.
If some of those are not available as a precompiled windows binary,
the download.packages() command will probably fail with an error, so
you have to do the download in bits and pieces, removing offending
entries from `tmp' -- but that should be still faster than downloading
file by file (presumably by clicking in a web browser?).  (The
development version of R should now be more robust (Thanks again,
Brian) when downloading and just continue downloading the remaining
files if it encounters an error.  But I don't know where you run (or
what to run) R-devel ;-) ).

Hope this helps.

Cheers,
                
        Berwin

========================== Full address ============================
Berwin A Turlach                      Tel.: +61 (8) 6488 3338 (secr)   
School of Mathematics and Statistics        +61 (8) 6488 3383 (self)      
The University of Western Australia   FAX : +61 (8) 6488 1028
35 Stirling Highway                   
Crawley WA 6009                e-mail: berwin at maths.uwa.edu.au
Australia                        http://www.maths.uwa.edu.au/~berwin



From ripley at stats.ox.ac.uk  Wed Aug 31 08:39:09 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 31 Aug 2005 07:39:09 +0100 (BST)
Subject: [R] Font Encodings --- some work, some don't
In-Reply-To: <ivo_welch-0VILwA/di3l8LIDSbRfJ1NKT1O9t+X/@mailblocks.com>
References: <ivo_welch-0VILwA/di3l8LIDSbRfJ1NKT1O9t+X/@mailblocks.com>
Message-ID: <Pine.LNX.4.61.0508310730270.26002@gannet.stats>

Are you talking about the pdf() device?  You never say so, but you do say

> The font encoding error does not appear in the postscript
> device driver, and it works fine.

This report is far too vague: what did you do and what reported the file 
was corrupt?  (Note that Acrobat reader is famous for mis-rendering
files which meet the Adobe PDF specification.)

Please do read the posting guide and restate your problem following the 
guidelines there.

Finally, I don't see any claim that arbitrary font encodings would produce 
a valid PDF file, so what did you read to suggest that?

On Tue, 30 Aug 2005, ivo welch wrote:

>
> Dear R wizards:  I believe some more font encoding info. some of the
> font encodings work, others do not:  IsoLatin1, MacRoman, WinAnsi, and
> PDFDoc seem fine.  AdobeStd, AdobeSym, ISOLatin2, ISOLatin9, and
> TeXtext seem broken, in that the resulting output file is silently
> corrupt.  The font encoding error does not appear in the postscript
> device driver, and it works fine.  It would be nice if R gave an error
> message, instead of producing corrupt .pdf files.  Just a suggestion...
>
> Regards,
>
> /iaw
> ---
> ivo welch
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From ripley at stats.ox.ac.uk  Wed Aug 31 08:44:22 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 31 Aug 2005 07:44:22 +0100 (BST)
Subject: [R] R binaries
In-Reply-To: <17173.12478.297309.297964@bossiaea.maths.uwa.edu.au>
References: <20735.129.180.11.34.1125460179.squirrel@129.180.11.34>
	<17173.12478.297309.297964@bossiaea.maths.uwa.edu.au>
Message-ID: <Pine.LNX.4.61.0508310740140.26002@gannet.stats>

On Wed, 31 Aug 2005, Berwin A Turlach wrote:

> G'day Nam-Ky,
>
>>>>>> "NKN" == Nam-Ky Nguyen <nkn at turing.une.edu.au> writes:
>
>    NKN> I intend to burn some R CDs to colleagues in Vietnam.  I want
>    NKN> to put all binary files for base as well as contributed
>    NKN> packages (for both Windows and Linux).
> I don't believe that precompiled binary files for Linux exist, since
> they would depend very much on which flavour of Linux you are running.
>
>    NKN> It is very time consuming if I download files by files. Is
>    NKN> there a place a can buy a CD with all the mentioned files?
> Not that I am aware off.  But I would do the following for easy
> download of all contributed files:  Issue  from an R session the
> following commands (mostly untested):
>
>> options(repos=c(CRAN="http://cran.au.r-project.org/"))
>> tmp <- available.packages()  # Or just use CRAN.packages() ??
> ## To download all source files
>> download.packages(tmp, destdir=".")
> ## To download all windows binary
>> download.packages(tmp, destdir=".", type="win.binary")
>
> If you do it from a Windows machine, you may have to adapt the destdir
> argument in those commands.  Also, if you sit behind a proxy, then you
> might have to first issue an appropriate
> 'Sys.putenv("http_proxy"="put your proxy here")' command.
>
> available.packages() does not seem to have a type argument according
> to its documentation, so I guess that even if it is run under Windows
> that it returns a list of all source packages available in contrib.

Depends on what contriburl is set to, but the default under Windows is 
binary packages.  See my article in the current R-Newsletter.

The default argument is contrb.url(getOption("repos")), and contrib.url 
does have a type argument (and its default is getOption("pkgType") ).

> If some of those are not available as a precompiled windows binary,
> the download.packages() command will probably fail with an error, so
> you have to do the download in bits and pieces, removing offending
> entries from `tmp' -- but that should be still faster than downloading
> file by file (presumably by clicking in a web browser?).  (The
> development version of R should now be more robust (Thanks again,
> Brian) when downloading and just continue downloading the remaining
> files if it encounters an error.  But I don't know where you run (or
> what to run) R-devel ;-) ).
>
> Hope this helps.
>
> Cheers,
>
>        Berwin
>
> ========================== Full address ============================
> Berwin A Turlach                      Tel.: +61 (8) 6488 3338 (secr)
> School of Mathematics and Statistics        +61 (8) 6488 3383 (self)
> The University of Western Australia   FAX : +61 (8) 6488 1028
> 35 Stirling Highway
> Crawley WA 6009                e-mail: berwin at maths.uwa.edu.au
> Australia                        http://www.maths.uwa.edu.au/~berwin
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From berwin at maths.uwa.edu.au  Wed Aug 31 09:07:36 2005
From: berwin at maths.uwa.edu.au (Berwin A Turlach)
Date: Wed, 31 Aug 2005 15:07:36 +0800
Subject: [R] R binaries
In-Reply-To: <Pine.LNX.4.61.0508310740140.26002@gannet.stats>
References: <20735.129.180.11.34.1125460179.squirrel@129.180.11.34>
	<17173.12478.297309.297964@bossiaea.maths.uwa.edu.au>
	<Pine.LNX.4.61.0508310740140.26002@gannet.stats>
Message-ID: <17173.22328.417552.508676@bossiaea.maths.uwa.edu.au>

G'day Brian,

>>>>> "BDR" == Prof Brian Ripley <ripley at stats.ox.ac.uk> writes:

    BDR> On Wed, 31 Aug 2005, Berwin A Turlach wrote:
    >> available.packages() does not seem to have a type argument
    >> according to its documentation, so I guess that even if it is
    >> run under Windows that it returns a list of all source packages
    >> available in contrib.

    BDR> Depends on what contriburl is set to, but the default under
    BDR> Windows is binary packages.  See my article in the current
    BDR> R-Newsletter.

    BDR> The default argument is contrb.url(getOption("repos")), and
    BDR> contrib.url does have a type argument (and its default is
    BDR> getOption("pkgType") ).
Thanks for pointing this out;  seems as if I didn't read the
documentation in sufficient details.

Thus, since Nam-Ky works on a Linux box (private e-mail) the commands
should be

> options(repos=c(CRAN="http://cran.au.r-project.org/"),
+         pkgType="source")
> download.packages(available.packages(), destdir=".")

to download all the source files; followed by 

> options(pkgType="win.binary")
> download.packages(available.packages(), destdir=".")

to download all contributed binary packages for Windows.

Cheers,

        Berwin



From p.dalgaard at biostat.ku.dk  Wed Aug 31 09:47:29 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 31 Aug 2005 09:47:29 +0200
Subject: [R] R binaries
In-Reply-To: <17173.22328.417552.508676@bossiaea.maths.uwa.edu.au>
References: <20735.129.180.11.34.1125460179.squirrel@129.180.11.34>
	<17173.12478.297309.297964@bossiaea.maths.uwa.edu.au>
	<Pine.LNX.4.61.0508310740140.26002@gannet.stats>
	<17173.22328.417552.508676@bossiaea.maths.uwa.edu.au>
Message-ID: <x2wtm2h7ji.fsf@turmalin.kubism.ku.dk>

Berwin A Turlach <berwin at maths.uwa.edu.au> writes:

> Thus, since Nam-Ky works on a Linux box (private e-mail) the commands
> should be

On a Linux box, I would rather suggest using wget on the appropriate
CRAN directories (wget -r --no-parent http://etc.etc.etc/...) - unless
of course it is the download speed that is the issue.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From nassar at noos.fr  Wed Aug 31 10:15:27 2005
From: nassar at noos.fr (Naji)
Date: Wed, 31 Aug 2005 10:15:27 +0200
Subject: [R] Distributional characteristics
Message-ID: <BF3B33BF.5FAE%nassar@noos.fr>

Hi all

I've a continuous variable and I want to test (graphically, plotting
observed and theoretical distr, qqplot) whether it follows some formal
distribution. (some thing close to Ricci document : Fitting distributions
with R, Feb05).
 
The distribution I want to fit is a truncated Gamma at 1 (the minimal value
is 1), P(x)=Pgamma(rate,x)/(1-Pgamma(rate,x<1))

NB : changing the variable (x-1,ln(x)) didn't get satisfying results

Best
Naji



From thpe at hhbio.wasser.tu-dresden.de  Wed Aug 31 10:19:18 2005
From: thpe at hhbio.wasser.tu-dresden.de (Thomas Petzoldt)
Date: Wed, 31 Aug 2005 10:19:18 +0200
Subject: [R] R binaries
In-Reply-To: <20735.129.180.11.34.1125460179.squirrel@129.180.11.34>
References: <20735.129.180.11.34.1125460179.squirrel@129.180.11.34>
Message-ID: <43156806.4020608@hhbio.wasser.tu-dresden.de>

Nam-Ky Nguyen schrieb:
> Dear Rexperts,
> 
> I intend to burn some R CDs to colleagues in Vietnam.  I want to put all
> binary files for base as well as contributed packages (for both Windows
> and Linux). It is very time consuming if I download files by files. Is
> there a place a can buy a CD with all the mentioned files?
> 
> Regards,

There are many methods to download several files at once, either text 
based using an ftp or http client (e.g. wget) or GUI based.

Some GUI's:

- the downTHEMall! plugin for Mozilla Firefox

- "Total Commander" (Shareware, Windows) is a very nice universal file 
manager with an effective built-in ftp client.

- KDE on a recent LINUX distribution: the file manager "konqueror" has 
built-in http and ftp support and is able to copy complete directory trees.

As an example to copy some documentation simply type

ftp://cran.r-project.org/pub/R/doc

(please select your cran mirror near you) into the address line, then 
select the required directory (e.g. Rnews) and press the right mouse 
button, but be careful if you select huge directory tries.

Thomas P.



From ripley at stats.ox.ac.uk  Wed Aug 31 11:05:16 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 31 Aug 2005 10:05:16 +0100 (BST)
Subject: [R] Installation help
In-Reply-To: <20050830234114.32176.qmail@web54302.mail.yahoo.com>
References: <20050830234114.32176.qmail@web54302.mail.yahoo.com>
Message-ID: <Pine.LNX.4.61.0508311004260.27686@gannet.stats>

On Tue, 30 Aug 2005, b wrote:

> Solved the problem with the 'R' installation!
>
> One of the processes that loads up on startup was
> conflicting with it. It was a program called
> "Gameutil.exe" which seems to enhance games by
> altering display modes. For some reason a conflict
> existed. Anyhow I dont really need the Gameutil.exe,
> so I'm as happy as Larry R works!

Was this on Windows?  If so, such programs are covered by the rw-FAQ, see 
the posting guide.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From r at roryt.gr  Wed Aug 31 11:31:29 2005
From: r at roryt.gr (I.Ioannou)
Date: Wed, 31 Aug 2005 12:31:29 +0300
Subject: [R] PLSR: model notation and reliabilities
In-Reply-To: <m0wtm5xoju.fsf@bar.nemo-project.org>
References: <20050827010413.GA27127@argeas.cs-net.gr>
	<20050828231855.GA3475@argeas.cs-net.gr>
	<m0wtm5xoju.fsf@bar.nemo-project.org>
Message-ID: <20050831093128.GA5790@argeas.cs-net.gr>

On Mon, Aug 29, 2005 at 08:08:53AM +0200, Bj?rn-Helge Mevik wrote:
 
> It seems to me that what you are looking for, is some sort of
> structured equation models (? la Lisrel).  The pls package implements
> partial least squares regression and principal component regression,
> which is something different.  I quess you could still use plsr for the
> "outer model" (path model), but you would have to build the "inner
> model" (the constructs) with other tools, such as prcomp/princomp or
> other factor analyses (see e.g. ?factanal and ?varimax).
> 
> Alternatively, there is an R package "sem" that implements structured
> equation models.  You might want to take a look at that.


Thank you very much for your hints. I actually tried factanal
to construct the latent variables, and both the reliabilties 
and the explained variance seem to be ok, but I'm afraid that 
this is not my case. I thought that plsr should be used to perform 
this task, and that PLS is prefered under "conditions on non-normality 
and small to medium sample sizes" where you do not "assume error 
free measurement" (Chin et all, 1996, p25). Also Wold suggests 
using PLS or PC scores in each level of hierarchical PLS models 
(Wold et al, 2004, p17). 

It is obvious to me how I should use plsr to perform the final
regression  between the constructs, but I'm missing the procedure 
I have to use in order to construct the factors (constructs) from 
the observed indicators.

Any hints will be much appreciatted.

Rgrds

References:

Chin et al, 1996, "A PARTIAL LEAST SQUARES LATENT VARIABLE 
MODELING APPROACH FOR MEASURING INTERACTION EFFECTS: RESULTS FROM A MONTE 
CARLO SIMULATION STUDY AND VOICE MAIL EMOTION/ADOPTION STUDY",
Available: http://disc-nt.cba.uh.edu/chin/plsfaq/http/disc-nt.cba.uh.edu/chin/icis96.pdf

Wold et al, 2004, "The PLS method -- partial least squares projections to 
latent structures -- and its applications in industrial RDP", 
Available: http://www.umetrics.com/pdfs/events/prague%200408%20__%20PLS_text_wold.pdf   

Ioannis Ioannou



From wuming.gong at gmail.com  Wed Aug 31 11:46:00 2005
From: wuming.gong at gmail.com (Wuming Gong)
Date: Wed, 31 Aug 2005 17:46:00 +0800
Subject: [R] Gamma for ordinal trends
Message-ID: <b428d06d05083102465de4ca09@mail.gmail.com>

Dear list, 

Are there any functions for calculating gamma (and its standard
error), which measures the association of ordinal factors in I x J
contingency table. I did a RSiteSearch but did not find any clues...

Thanks,

Wuming



From deggle at uni-koeln.de  Wed Aug 31 11:49:54 2005
From: deggle at uni-koeln.de (deggle)
Date: Wed, 31 Aug 2005 11:49:54 +0200
Subject: [R] tcl/tk return problem
Message-ID: <43157D42.9060402@uni-koeln.de>

Hello,

I'm very new in working with tcl/tk in R and have a problem which will 
probably
sound silly to most of you.
Here is the code I have problems with:

readcelfiles <- function()
{
   require(tcltk)
   tt <- tktoplevel()
   tkgrid(tklabel(tt,text="Choose a directory!"))

 OnOK <- function()
 {
    fileDir<-tclvalue(tkchooseDirectory())
    data.raw <- ReadAffy(celfile.path=fileDir)
    #return(data.raw)
 }

   OK.but <- tkbutton(tt,text="OK",command=OnOK)
   tkgrid(OK.but)
   tkfocus(tt)
}

So after clicking on my "OK" button, I choose my directory and read the 
cel-files.
But now I want to return the object to my workspace ... "return" doesn't 
work here.

Could anyone give me a hint?

Thank you very much,
Daniela



From baron at psych.upenn.edu  Wed Aug 31 12:31:23 2005
From: baron at psych.upenn.edu (Jonathan Baron)
Date: Wed, 31 Aug 2005 06:31:23 -0400
Subject: [R] Gamma for ordinal trends
In-Reply-To: <b428d06d05083102465de4ca09@mail.gmail.com>
References: <b428d06d05083102465de4ca09@mail.gmail.com>
Message-ID: <20050831103123.GA23048@psych>

On 08/31/05 17:46, Wuming Gong wrote:
> Dear list,
> 
> Are there any functions for calculating gamma (and its standard
> error), which measures the association of ordinal factors in I x J
> contingency table. I did a RSiteSearch but did not find any clues...

You have to look for Goodman-Kruskal gamma.  It is a bit
obscure.  It is rcorr.cens in the Hmisc package.

The significance test is the same as for Kendall's tau, according 
to some books.  I don't know about standard error.

Jon
-- 
Jonathan Baron, Professor of Psychology, University of Pennsylvania
Home page: http://www.sas.upenn.edu/~baron



From phgrosjean at sciviews.org  Wed Aug 31 12:40:41 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed, 31 Aug 2005 12:40:41 +0200
Subject: [R] tcl/tk return problem
In-Reply-To: <43157D42.9060402@uni-koeln.de>
References: <43157D42.9060402@uni-koeln.de>
Message-ID: <43158929.1010007@sciviews.org>

deggle wrote:
> Hello,
> 
> I'm very new in working with tcl/tk in R and have a problem which will 
> probably
> sound silly to most of you.
> Here is the code I have problems with:
> 
> readcelfiles <- function()
> {
>    require(tcltk)
>    tt <- tktoplevel()
>    tkgrid(tklabel(tt,text="Choose a directory!"))
> 
>  OnOK <- function()
>  {
>     fileDir<-tclvalue(tkchooseDirectory())
>     data.raw <- ReadAffy(celfile.path=fileDir)
>     #return(data.raw)
>  }
> 
>    OK.but <- tkbutton(tt,text="OK",command=OnOK)
>    tkgrid(OK.but)
>    tkfocus(tt)
> }
> 
> So after clicking on my "OK" button, I choose my directory and read the 
> cel-files.
> But now I want to return the object to my workspace ... "return" doesn't 
> work here.

I suppose you mean in the User Workspace. Your OnOK function should look 
like that:

OnOK <- function() {
      fileDir<-tclvalue(tkchooseDirectory())
      data.raw <<- ReadAffy(celfile.path=fileDir)
}

Note that the function overwrites any existing 'data.raw', so this could 
be dangerous. Writting directly in the User Workspace is not advised 
from inside a function, but here, it is the simplest way to return a 
result from a tk widget action.
Best

Philippe Grosjean


> Could anyone give me a hint?
> 
> Thank you very much,
> Daniela
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
> 
>



From ripley at stats.ox.ac.uk  Wed Aug 31 13:18:08 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 31 Aug 2005 12:18:08 +0100 (BST)
Subject: [R] tcl/tk return problem
In-Reply-To: <43158929.1010007@sciviews.org>
Message-ID: <Pine.GSO.4.31.0508311210450.21869-100000@toucan.stats>

On Wed, 31 Aug 2005, Philippe Grosjean wrote:

> deggle wrote:
> > Hello,
> >
> > I'm very new in working with tcl/tk in R and have a problem which will
> > probably
> > sound silly to most of you.
> > Here is the code I have problems with:
> >
> > readcelfiles <- function()
> > {
> >    require(tcltk)
> >    tt <- tktoplevel()
> >    tkgrid(tklabel(tt,text="Choose a directory!"))
> >
> >  OnOK <- function()
> >  {
> >     fileDir<-tclvalue(tkchooseDirectory())
> >     data.raw <- ReadAffy(celfile.path=fileDir)
> >     #return(data.raw)
> >  }
> >
> >    OK.but <- tkbutton(tt,text="OK",command=OnOK)
> >    tkgrid(OK.but)
> >    tkfocus(tt)
> > }
> >
> > So after clicking on my "OK" button, I choose my directory and read the
> > cel-files.
> > But now I want to return the object to my workspace ... "return" doesn't
> > work here.
>
> I suppose you mean in the User Workspace. Your OnOK function should look
> like that:
>
> OnOK <- function() {
>       fileDir<-tclvalue(tkchooseDirectory())
>       data.raw <<- ReadAffy(celfile.path=fileDir)
> }
>
> Note that the function overwrites any existing 'data.raw', so this could
> be dangerous. Writting directly in the User Workspace is not advised
> from inside a function, but here, it is the simplest way to return a
> result from a tk widget action.

Maybe simplest, but not a very good way.  See
R_SOURCES/src/library/tcltk/R/utils.R for ideas on how to write a modal
dialog box that returns the value selected.

One problem with <<- is that it does not necessarily write in the
workspace.  You need

   assign("data.raw", ReadAffy(celfile.path=fileDir), envir=.GlobalEnv)

to be sure of that.  (The example code I quote does use <<- but in a
controlled way.)

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From p.dalgaard at biostat.ku.dk  Wed Aug 31 13:42:27 2005
From: p.dalgaard at biostat.ku.dk (Peter Dalgaard)
Date: 31 Aug 2005 13:42:27 +0200
Subject: [R] Gamma for ordinal trends
In-Reply-To: <20050831103123.GA23048@psych>
References: <b428d06d05083102465de4ca09@mail.gmail.com>
	<20050831103123.GA23048@psych>
Message-ID: <x2oe7egwnw.fsf@turmalin.kubism.ku.dk>

Jonathan Baron <baron at psych.upenn.edu> writes:

> On 08/31/05 17:46, Wuming Gong wrote:
> > Dear list,
> > 
> > Are there any functions for calculating gamma (and its standard
> > error), which measures the association of ordinal factors in I x J
> > contingency table. I did a RSiteSearch but did not find any clues...
> 
> You have to look for Goodman-Kruskal gamma.  It is a bit
> obscure.  It is rcorr.cens in the Hmisc package.
> 
> The significance test is the same as for Kendall's tau, according 
> to some books.  

Well, it would be if we handled ties in Kendall's tau correctly...

> I don't know about standard error.

-- 
   O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
  c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
 (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907



From wuming.gong at gmail.com  Wed Aug 31 13:55:19 2005
From: wuming.gong at gmail.com (Wuming Gong)
Date: Wed, 31 Aug 2005 19:55:19 +0800
Subject: [R] Gamma for ordinal trends
In-Reply-To: <x2oe7egwnw.fsf@turmalin.kubism.ku.dk>
References: <b428d06d05083102465de4ca09@mail.gmail.com>
	<20050831103123.GA23048@psych> <x2oe7egwnw.fsf@turmalin.kubism.ku.dk>
Message-ID: <b428d06d05083104554f03f8d6@mail.gmail.com>

Is it possible to use delta method to evaluate the standard error of
Goodman-Kruskal gamma and then Wald test to evaluate the significance
of association?

Wuming


On 31 Aug 2005 13:42:27 +0200, Peter Dalgaard <p.dalgaard at biostat.ku.dk> wrote:
> Jonathan Baron <baron at psych.upenn.edu> writes:
> 
> > On 08/31/05 17:46, Wuming Gong wrote:
> > > Dear list,
> > >
> > > Are there any functions for calculating gamma (and its standard
> > > error), which measures the association of ordinal factors in I x J
> > > contingency table. I did a RSiteSearch but did not find any clues...
> >
> > You have to look for Goodman-Kruskal gamma.  It is a bit
> > obscure.  It is rcorr.cens in the Hmisc package.
> >
> > The significance test is the same as for Kendall's tau, according
> > to some books.
> 
> Well, it would be if we handled ties in Kendall's tau correctly...
> 
> > I don't know about standard error.
> 
> --
>    O__  ---- Peter Dalgaard             ??ster Farimagsgade 5, Entr.B
>   c/ /'_ --- Dept. of Biostatistics     PO Box 2099, 1014 Cph. K
>  (*) \(*) -- University of Copenhagen   Denmark          Ph:  (+45) 35327918
> ~~~~~~~~~~ - (p.dalgaard at biostat.ku.dk)                  FAX: (+45) 35327907
>



From murdoch at stats.uwo.ca  Wed Aug 31 14:36:56 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 31 Aug 2005 08:36:56 -0400
Subject: [R] tcl/tk return problem
In-Reply-To: <Pine.GSO.4.31.0508311210450.21869-100000@toucan.stats>
References: <Pine.GSO.4.31.0508311210450.21869-100000@toucan.stats>
Message-ID: <4315A468.7090303@stats.uwo.ca>

Prof Brian Ripley wrote:
> On Wed, 31 Aug 2005, Philippe Grosjean wrote:
> 
> 
>>deggle wrote:
>>
>>>Hello,
>>>
>>>I'm very new in working with tcl/tk in R and have a problem which will
>>>probably
>>>sound silly to most of you.
>>>Here is the code I have problems with:
>>>
>>>readcelfiles <- function()
>>>{
>>>   require(tcltk)
>>>   tt <- tktoplevel()
>>>   tkgrid(tklabel(tt,text="Choose a directory!"))
>>>
>>> OnOK <- function()
>>> {
>>>    fileDir<-tclvalue(tkchooseDirectory())
>>>    data.raw <- ReadAffy(celfile.path=fileDir)
>>>    #return(data.raw)
>>> }
>>>
>>>   OK.but <- tkbutton(tt,text="OK",command=OnOK)
>>>   tkgrid(OK.but)
>>>   tkfocus(tt)
>>>}
>>>
>>>So after clicking on my "OK" button, I choose my directory and read the
>>>cel-files.
>>>But now I want to return the object to my workspace ... "return" doesn't
>>>work here.
>>
>>I suppose you mean in the User Workspace. Your OnOK function should look
>>like that:
>>
>>OnOK <- function() {
>>      fileDir<-tclvalue(tkchooseDirectory())
>>      data.raw <<- ReadAffy(celfile.path=fileDir)
>>}
>>
>>Note that the function overwrites any existing 'data.raw', so this could
>>be dangerous. Writting directly in the User Workspace is not advised
>>from inside a function, but here, it is the simplest way to return a
>>result from a tk widget action.
> 
> 
> Maybe simplest, but not a very good way.  See
> R_SOURCES/src/library/tcltk/R/utils.R for ideas on how to write a modal
> dialog box that returns the value selected.
> 
> One problem with <<- is that it does not necessarily write in the
> workspace.  You need
> 
>    assign("data.raw", ReadAffy(celfile.path=fileDir), envir=.GlobalEnv)
> 
> to be sure of that.  (The example code I quote does use <<- but in a
> controlled way.)

This works, and you weren't suggesting it as a good style, but I'd like 
to say it's really a bad style to write to .GlobalEnv.  The controlled 
use of <<- as in tk_select.list from the file you quoted is really the 
best way to solve this problem.  As a general rule, you shouldn't stomp 
on something you don't own, and functions don't own variables in 
.GlobalEnv.

What tk_select.list does is define OnOK locally, and use <<- to write to
the tk_select.list environment.  Then the result can be manipulated and 
returned politely, without stomping on anything anywhere.

Duncan Murdoch



From ripley at stats.ox.ac.uk  Wed Aug 31 14:57:42 2005
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 31 Aug 2005 13:57:42 +0100 (BST)
Subject: [R] tcl/tk return problem
In-Reply-To: <4315A468.7090303@stats.uwo.ca>
Message-ID: <Pine.GSO.4.31.0508311349040.22042-100000@toucan.stats>

On Wed, 31 Aug 2005, Duncan Murdoch wrote:

> Prof Brian Ripley wrote:
> > On Wed, 31 Aug 2005, Philippe Grosjean wrote:
> >
> >
> >>deggle wrote:
> >>
> >>>Hello,
> >>>
> >>>I'm very new in working with tcl/tk in R and have a problem which will
> >>>probably
> >>>sound silly to most of you.
> >>>Here is the code I have problems with:
> >>>
> >>>readcelfiles <- function()
> >>>{
> >>>   require(tcltk)
> >>>   tt <- tktoplevel()
> >>>   tkgrid(tklabel(tt,text="Choose a directory!"))
> >>>
> >>> OnOK <- function()
> >>> {
> >>>    fileDir<-tclvalue(tkchooseDirectory())
> >>>    data.raw <- ReadAffy(celfile.path=fileDir)
> >>>    #return(data.raw)
> >>> }
> >>>
> >>>   OK.but <- tkbutton(tt,text="OK",command=OnOK)
> >>>   tkgrid(OK.but)
> >>>   tkfocus(tt)
> >>>}
> >>>
> >>>So after clicking on my "OK" button, I choose my directory and read the
> >>>cel-files.
> >>>But now I want to return the object to my workspace ... "return" doesn't
> >>>work here.
> >>
> >>I suppose you mean in the User Workspace. Your OnOK function should look
> >>like that:
> >>
> >>OnOK <- function() {
> >>      fileDir<-tclvalue(tkchooseDirectory())
> >>      data.raw <<- ReadAffy(celfile.path=fileDir)
> >>}
> >>
> >>Note that the function overwrites any existing 'data.raw', so this could
> >>be dangerous. Writting directly in the User Workspace is not advised
> >>from inside a function, but here, it is the simplest way to return a
> >>result from a tk widget action.
> >
> >
> > Maybe simplest, but not a very good way.  See
> > R_SOURCES/src/library/tcltk/R/utils.R for ideas on how to write a modal
> > dialog box that returns the value selected.
> >
> > One problem with <<- is that it does not necessarily write in the
> > workspace.  You need
> >
> >    assign("data.raw", ReadAffy(celfile.path=fileDir), envir=.GlobalEnv)
> >
> > to be sure of that.  (The example code I quote does use <<- but in a
> > controlled way.)
>
> This works, and you weren't suggesting it as a good style, but I'd like
> to say it's really a bad style to write to .GlobalEnv.

It was the question asked!  If you use a non-modal tcltk dialog you
have little choice, as the parent function will have returned and vanished
long ago.  Now, having a widget firing off R commands independently of the
command line is not a great idea (R's evaluator is not multithreaded and
this could be interspersed in another computation) so there is a lot to be
said for using dialog boxes modally.

> The controlled use of <<- as in tk_select.list from the file you
> quoted is really the best way to solve this problem.  As a general
> rule, you shouldn't stomp on something you don't own, and functions
> don't own variables in .GlobalEnv.

One could argue the user who pressed the button does: it is the user
workspace.

> What tk_select.list does is define OnOK locally, and use <<- to write to
> the tk_select.list environment.  Then the result can be manipulated and
> returned politely, without stomping on anything anywhere.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272860 (secr)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595



From murdoch at stats.uwo.ca  Wed Aug 31 15:31:17 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 31 Aug 2005 09:31:17 -0400
Subject: [R] tcl/tk return problem
In-Reply-To: <Pine.GSO.4.31.0508311349040.22042-100000@toucan.stats>
References: <Pine.GSO.4.31.0508311349040.22042-100000@toucan.stats>
Message-ID: <4315B125.7040807@stats.uwo.ca>

On 8/31/2005 8:57 AM, Prof Brian Ripley wrote:
> On Wed, 31 Aug 2005, Duncan Murdoch wrote:
> 
>> Prof Brian Ripley wrote:
>> > On Wed, 31 Aug 2005, Philippe Grosjean wrote:
>> >
>> >
>> >>deggle wrote:
>> >>
>> >>>Hello,
>> >>>
>> >>>I'm very new in working with tcl/tk in R and have a problem which will
>> >>>probably
>> >>>sound silly to most of you.
>> >>>Here is the code I have problems with:
>> >>>
>> >>>readcelfiles <- function()
>> >>>{
>> >>>   require(tcltk)
>> >>>   tt <- tktoplevel()
>> >>>   tkgrid(tklabel(tt,text="Choose a directory!"))
>> >>>
>> >>> OnOK <- function()
>> >>> {
>> >>>    fileDir<-tclvalue(tkchooseDirectory())
>> >>>    data.raw <- ReadAffy(celfile.path=fileDir)
>> >>>    #return(data.raw)
>> >>> }
>> >>>
>> >>>   OK.but <- tkbutton(tt,text="OK",command=OnOK)
>> >>>   tkgrid(OK.but)
>> >>>   tkfocus(tt)
>> >>>}
>> >>>
>> >>>So after clicking on my "OK" button, I choose my directory and read the
>> >>>cel-files.
>> >>>But now I want to return the object to my workspace ... "return" doesn't
>> >>>work here.
>> >>
>> >>I suppose you mean in the User Workspace. Your OnOK function should look
>> >>like that:
>> >>
>> >>OnOK <- function() {
>> >>      fileDir<-tclvalue(tkchooseDirectory())
>> >>      data.raw <<- ReadAffy(celfile.path=fileDir)
>> >>}
>> >>
>> >>Note that the function overwrites any existing 'data.raw', so this could
>> >>be dangerous. Writting directly in the User Workspace is not advised
>> >>from inside a function, but here, it is the simplest way to return a
>> >>result from a tk widget action.
>> >
>> >
>> > Maybe simplest, but not a very good way.  See
>> > R_SOURCES/src/library/tcltk/R/utils.R for ideas on how to write a modal
>> > dialog box that returns the value selected.
>> >
>> > One problem with <<- is that it does not necessarily write in the
>> > workspace.  You need
>> >
>> >    assign("data.raw", ReadAffy(celfile.path=fileDir), envir=.GlobalEnv)
>> >
>> > to be sure of that.  (The example code I quote does use <<- but in a
>> > controlled way.)
>>
>> This works, and you weren't suggesting it as a good style, but I'd like
>> to say it's really a bad style to write to .GlobalEnv.
> 
> It was the question asked! 

Yes, I agree, but I was pointing out that it is probably the wrong question.

Duncan Murdoch

 > If you use a non-modal tcltk dialog you
> have little choice, as the parent function will have returned and vanished
> long ago.  Now, having a widget firing off R commands independently of the
> command line is not a great idea (R's evaluator is not multithreaded and
> this could be interspersed in another computation) so there is a lot to be
> said for using dialog boxes modally.
> 
>> The controlled use of <<- as in tk_select.list from the file you
>> quoted is really the best way to solve this problem.  As a general
>> rule, you shouldn't stomp on something you don't own, and functions
>> don't own variables in .GlobalEnv.
> 
> One could argue the user who pressed the button does: it is the user
> workspace.
> 
>> What tk_select.list does is define OnOK locally, and use <<- to write to
>> the tk_select.list environment.  Then the result can be manipulated and
>> returned politely, without stomping on anything anywhere.
>



From andy_liaw at merck.com  Wed Aug 31 15:47:29 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 31 Aug 2005 09:47:29 -0400
Subject: [R] problem with certain data sets when using randomForest
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED3F2@usctmx1106.merck.com>

I've been trying to play catch-up on R-help since DSC2005.  This one must
have slipped through...

This is what I'd do:

iris.sub <- subset(iris, Species %in% c("setosa", "virginica"))
iris.sub$Species <- factor(iris.sub$Species)

That last line drops the empty level in the factor.  You can then run
randomForest with that data.

HTH,
Andy

> From: Martin Lam
> 
> Hi,
> 
> Since I've had no replies on my previous post about my
> problem I am posting it again in the hope someone
> notice it. The problem is that the randomForest
> function doesn't take datasets which has instances
> only containing a subset of  all the classes. So the
> dataset with instances that either belong to class "a"
> or "b" from the levels "a", "b" and "c" doesn't work
> because there is no instance that has class "c". Is
> there any way to solve this problem?
> 
> library("randomForest")
> 
> # load the iris plant data set
> dataset <- iris
> 
> numberarray <- array(1:nrow(dataset), nrow(dataset),
> 1)
> 
> # include only instances with Species = setosa or
> virginica
> indices <- t(numberarray[(dataset$Species == "setosa"
> | 
> dataset$Species == "virginica") == TRUE])
> 
> finaldataset <- dataset[indices,]
> 
> # just to let you see the 3 classes
> levels(finaldataset$Species)
> 
> # create the random forest
> randomForest(formula = Species ~ ., data =
> finaldataset, ntree = 5)
> 
> # The error message I get
> Error in randomForest.default(m, y, ...) : 
>         Can't have empty classes in y.
> 
> #The problem is that the finaldataset doesn't contain
> #any instances of "versicolor", so I think the only
> way #to solve this problem is by changing the levels
> the #"Species" have to only "setosa" and "virginica",
> # correct me if I'm wrong.
> 
> # So I tried to change the levels but I got stuck:
> 
> # get the possible unique classes
> uniqueItems <- unique(levels(finaldataset$Species))
> 
> # the problem!
> newlevels <- list(uniqueItems[1] = c(uniqueItems[1],
> uniqueItems[2]), uniqueItems[3] = uniqueItems[3])
> 
> # Error message
> Error: syntax error
> 
> # In the help they use constant names to rename the
> #levels, so this works (but that's not what I want
> #because I don't want to change the code every time I
> #use another data set):
> newlevels <- list("setosa" = c(uniqueItems[1],
> uniqueItems[2]), "virginica" = uniqueItems[3])
> 
> levels(finaldataset$Species) <- newlevels
> 
> levels(finaldataset$Species)
> 
> finaldataset$Species
> 
> ---------------------------
> 
> Thanks in advance,
> 
> Martin
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From lai at lindaspaces.com  Wed Aug 31 16:06:43 2005
From: lai at lindaspaces.com (Jennifer Lai)
Date: Wed, 31 Aug 2005 10:06:43 -0400
Subject: [R] Bioconductor and R-devel
Message-ID: <4315B973.30803@lindaspaces.com>

Hi,
   I have built R (current development version) and BioConductor 1.7 
with portland group compiler on a AMD Opteron.
When I ran qc assessment on Affymetrix latin square data set, I got the 
following output,

Loading required package: affy
Loading required package: Biobase
Loading required package: tools
Welcome to Bioconductor
         Vignettes contain introductory material.  To view,
         simply type: openVignette()
         For details on reading vignettes, see
         the openVignette help page.
Loading required package: reposTools
Welcome to 'simpleaffy' V 2.1.3                             
      Produced by The Paterson Institute for Cancer Research
      and funded by CANCER RESEARCH UK.                     
      http://bioinformatics.picr.man.ac.uk/simpleaffy       
      mailto: microarray at picr.man.ac.uk                     
Background correcting
Retrieving data from AffyBatch...done.
Computing expression calls...
.........................done.
scaling to a TGT of 100 ...
Scale factor for: 0203_YH10_H_MCF7_r1.CEL 0.291660289301555
Scale factor for: 0203_YH11_H_MCF10A_r1.CEL 0.42025300545212
Scale factor for: 0203_YH12_H_a100MCF7_r1.CEL 0.287589038746987
Scale factor for: 0203_YH13_H_a100MCF10A_r1.CEL 0.451200408584071
Scale factor for: 0203_YH14_H_a10MCF7_r1.CEL 0.385462078301135
Scale factor for: 0203_YH15_H_a100MCF7_r2.CEL 0.284974495993646
Scale factor for: 0203_YH16_H_a100MCF7_r3.CEL 0.376484877281483
Scale factor for: 0203_YH17_H_a100MCF10A_r2.CEL 0.374087365857816
Scale factor for: 0203_YH18_H_a100MCF10A_r3.CEL 0.487207458237659
Scale factor for: 0203_YH19_H_a10MCF7_r2.CEL 0.413217979158927
Scale factor for: 0203_YH20_H_a10MCF7_r3.CEL 0.482703032325383
Scale factor for: 0203_YH21_H_a10MCF10A_r1.CEL 0.945369712044904
Scale factor for: 0203_YH22_H_a10MCF10A_r2.CEL 1.96143996386198
Scale factor for: 0203_YH23_H_a10MCF10A_r3_rescan.CEL 0.841535915879218
Scale factor for: 0203_YH24_H_MCF7_r2.CEL 0.347795838770919
Scale factor for: 0203_YH25_H_MCF7_r3.CEL 0.318539156900791
Scale factor for: 0203_YH26_H_MCF10A_r2.CEL 0.578922233010316
Scale factor for: 0203_YH27_H_MCF10A_r3.CEL 0.394833650209601
Scale factor for: 0403_YH34_H_a10MCF10A_r4.CEL 1.06804698986081
Scale factor for: 0403_YH35_H_a1MCF7_r1_2.CEL 3.5923019165673
Scale factor for: 0403_YH36_H_a1MCF7_r2.CEL 3.16130786066591
Scale factor for: 0403_YH37_H_a1MCF7_r3_2.CEL 2.01330391697437
Scale factor for: 0403_YH38_H_a1MCF10A_r1.CEL 0.923881702153984
Scale factor for: 0403_YH39_H_a1MCF10A_r2_2.CEL 2.29265379531566
Scale factor for: 0403_YH40_H_a1MCF10A_r3.CEL 4.02474777803345
Getting probe level data...
Computing p-values
Doing PMA Calls
TEST 1 : time Elapsed =  0 1 20

Background correcting
Retrieving data from AffyBatch...done.
Computing expression calls...
.........Error in FUN(X[[9]], ...) : Expecting 22283 unique probesets, 
found 22284


Can anyone advise me on how to fix this problem? I was able to run the 
same data set with gcc-compiled R2.1.1 and BioConductor 1.6 successfully.


Here is the code that I ran, if it helps to diagnose the problems.

library(simpleaffy);
library(affy);

ampli.data <- ReadAffy()

# normalize the data using call.exprs and mas5
ampli.eset <- call.exprs(ampli.data, "mas5")

# see what data is stored in ampli.eset at description@preprocssing
names(ampli.eset at description@preprocessing)

# acess each piece of information within 
ampli.eset at description@preprocessing scale factors
ampli.eset at description@preprocessing$sfs

# filenames so that the scale factors can be related to their chips
ampli.eset at description@preprocessing$filenames

# tgt is the target intensity each chip was scaled to
ampli.eset at description@preprocessing$tgt

# which version of the affy package was used
ampli.eset at description@preprocessing$affyversion

qc.data <- qc(ampli.data, ampli.eset);

slotNames(qc.data);

# scale.factors contains a list of scale factors applied to each chip;
qc.data at scale.factors

# target is the target intensity that each chip was scaled to
qc.data at target

# percent.present is a list of the percentage of probesets called 
present on each chip;
qc.data at percent.present

# average.background, minimum.background, maximum.background are all 
lists detailing
# the average, minimum and maximum background for each chip;
qc.data at average.background

# spikes is a matrix containing normalized values for each of the spike 
controls
colnames(qc.data at spikes)



Thanks,
Jennifer



From phgrosjean at sciviews.org  Wed Aug 31 16:08:09 2005
From: phgrosjean at sciviews.org (Philippe Grosjean)
Date: Wed, 31 Aug 2005 16:08:09 +0200
Subject: [R] tcl/tk return problem
In-Reply-To: <4315B125.7040807@stats.uwo.ca>
References: <Pine.GSO.4.31.0508311349040.22042-100000@toucan.stats>
	<4315B125.7040807@stats.uwo.ca>
Message-ID: <4315B9C9.6050800@sciviews.org>

Duncan Murdoch wrote:
> On 8/31/2005 8:57 AM, Prof Brian Ripley wrote:
> 
>> On Wed, 31 Aug 2005, Duncan Murdoch wrote:
>>
>>> Prof Brian Ripley wrote:
>>> > On Wed, 31 Aug 2005, Philippe Grosjean wrote:
>>> >
>>> >
>>> >>deggle wrote:
>>> >>
>>> >>>Hello,
>>> >>>
>>> >>>I'm very new in working with tcl/tk in R and have a problem which 
>>> will
>>> >>>probably
>>> >>>sound silly to most of you.
>>> >>>Here is the code I have problems with:
>>> >>>
>>> >>>readcelfiles <- function()
>>> >>>{
>>> >>>   require(tcltk)
>>> >>>   tt <- tktoplevel()
>>> >>>   tkgrid(tklabel(tt,text="Choose a directory!"))
>>> >>>
>>> >>> OnOK <- function()
>>> >>> {
>>> >>>    fileDir<-tclvalue(tkchooseDirectory())
>>> >>>    data.raw <- ReadAffy(celfile.path=fileDir)
>>> >>>    #return(data.raw)
>>> >>> }
>>> >>>
>>> >>>   OK.but <- tkbutton(tt,text="OK",command=OnOK)
>>> >>>   tkgrid(OK.but)
>>> >>>   tkfocus(tt)
>>> >>>}
>>> >>>
>>> >>>So after clicking on my "OK" button, I choose my directory and 
>>> read the
>>> >>>cel-files.
>>> >>>But now I want to return the object to my workspace ... "return" 
>>> doesn't
>>> >>>work here.
>>> >>
>>> >>I suppose you mean in the User Workspace. Your OnOK function should 
>>> look
>>> >>like that:
>>> >>
>>> >>OnOK <- function() {
>>> >>      fileDir<-tclvalue(tkchooseDirectory())
>>> >>      data.raw <<- ReadAffy(celfile.path=fileDir)
>>> >>}
>>> >>
>>> >>Note that the function overwrites any existing 'data.raw', so this 
>>> could
>>> >>be dangerous. Writting directly in the User Workspace is not advised
>>> >>from inside a function, but here, it is the simplest way to return a
>>> >>result from a tk widget action.
>>> >
>>> >
>>> > Maybe simplest, but not a very good way.  See
>>> > R_SOURCES/src/library/tcltk/R/utils.R for ideas on how to write a 
>>> modal
>>> > dialog box that returns the value selected.
>>> >
>>> > One problem with <<- is that it does not necessarily write in the
>>> > workspace.  You need
>>> >
>>> >    assign("data.raw", ReadAffy(celfile.path=fileDir), 
>>> envir=.GlobalEnv)
>>> >
>>> > to be sure of that.  (The example code I quote does use <<- but in a
>>> > controlled way.)
>>>
>>> This works, and you weren't suggesting it as a good style, but I'd like
>>> to say it's really a bad style to write to .GlobalEnv.
>>
>>
>> It was the question asked! 
> 
> 
> Yes, I agree, but I was pointing out that it is probably the wrong 
> question.
> 
> Duncan Murdoch

This was to provide a direct answer to the question. I think I said it 
is not a good practice. For storing temporary variables for a GUI, I 
prefer to use a dedicated workspace. The very simple functions 
assignTemp(), getTemp() and rmTemp() in the svMisc package (SciViews 
bundle) ease its use. 'TempEnv' is used in SciViews-R, and, after a 
suggestion, John Fox included it also in R Commander (called 'RcmdrEnv' 
there).

May be a modal Tk dialog box is all what is needed here... Although 
since we are speaking about "good and bad questions", I wonder if the 
whole stuff is of any value:

1??) Draw a Tk dialog just with a "Choose a directory!" and an "OK" 
button is totally useless. Why not to display tkchooseDirectory() 
directly? After all, the 'Cancel' button is there in case the user does 
not want to proceed. This error in GUI design is to place in the same 
bag as "Do you want to quit?" -> "Do you really want to quit?" -> "Are 
you really sure you really want to quit?" !!!

2??) However, if the initial idea is to place other info in the Tk 
dialog, it then makes sense. Now, if this is the case, it is not 
necessary to put tkchooseDirectory() in the OnOK() function. The 
following code is doing the job without all the problems mentioned:

 > # This is because I don't have the ReadAffy() function...
 > ReadAffy <- function(celfile.path) return(celfile.path)
 >
 > readcelfiles <- function() {
 >     require(tcltk)
 >     tt <- tktoplevel()
 >     tkgrid(tklabel(tt, text = "Choose a directory!"))
 >     tkgrid(tkbutton(tt, text = "OK",
 >          command = function() tkdestroy(tt)))
 >     tkfocus(tt)
 >     tkwait.window(tt)
 >     fileDir<-tclvalue(tkchooseDirectory())
 >     return(ReadAffy(celfile.path = fileDir))
 > }
 > readcelfiles()

So... perhaps the wrong question is not where one think it is ;-)
Best,

Philippe

>  > If you use a non-modal tcltk dialog you
> 
>> have little choice, as the parent function will have returned and 
>> vanished
>> long ago.  Now, having a widget firing off R commands independently of 
>> the
>> command line is not a great idea (R's evaluator is not multithreaded and
>> this could be interspersed in another computation) so there is a lot 
>> to be
>> said for using dialog boxes modally.
>>
>>> The controlled use of <<- as in tk_select.list from the file you
>>> quoted is really the best way to solve this problem.  As a general
>>> rule, you shouldn't stomp on something you don't own, and functions
>>> don't own variables in .GlobalEnv.
>>
>>
>> One could argue the user who pressed the button does: it is the user
>> workspace.
>>
>>> What tk_select.list does is define OnOK locally, and use <<- to write to
>>> the tk_select.list environment.  Then the result can be manipulated and
>>> returned politely, without stomping on anything anywhere.
>>
>>
> 
> 
>



From yukiasais at ybb.ne.jp  Wed Aug 31 16:18:16 2005
From: yukiasais at ybb.ne.jp (Yukihiro Ishii)
Date: Wed, 31 Aug 2005 23:18:16 +0900
Subject: [R] Cases as Variables in Principal Component Analysis?
Message-ID: <20050831231547.EA3D.YUKIASAIS@ybb.ne.jp>

Dear R users,

I have a data set of 25 cases with 150-160 explanatory variables(the
number of which depends on what I choose from 200 odd digitalized spectrum
strength numbers) and one dependent variable(a sensory test result). My
natural choice is to work on a principal component analysis using the
explanatory variables, thus enabling to characterize and describe the
data space, and make a regression of the dependent variable on the
principal components. 

But a colleague of mine transposed the data matrix and, using the cases
as the independent variables, explained the dependent variable in terms
of the principal components he had. He changed obviously the score for the
rotation. The analysis gave a plausible story. But I can't be sure of the
physical meaning of it. 

My colleague says that this method is common in the image analysis
proper, which he specializes in. 

Is there anyone who can comment on this matter. Venables & Ripley says
something to the effect that either method will do, but the authors do
not seem to give a specific example.

In my trade(chemistry), the data is commonly analyzed by the PLS(Partial
Least Suare) method, which seems to give more or less the same result.
Only the contribution of the PC's seems to be different.

I would appreciate any help. Thank you.

-- 
Yukihiro Ishii <yukiasais at ybb.ne.jp>



From sfalcon at fhcrc.org  Wed Aug 31 16:48:29 2005
From: sfalcon at fhcrc.org (Seth Falcon)
Date: Wed, 31 Aug 2005 07:48:29 -0700
Subject: [R] Bioconductor and R-devel
In-Reply-To: <4315B973.30803@lindaspaces.com> (Jennifer Lai's message of "Wed, 
	31 Aug 2005 10:06:43 -0400")
References: <4315B973.30803@lindaspaces.com>
Message-ID: <m2fysqw4aq.fsf@macaroni.local>

Hi Jennifer,

I'm moving this over to the bioconductor mail list since we are
discussing Bioconductor packages, that would be the best place for the
discussion at this point.  Please subscribe and reply there.

A couple quick comments:

1. You do realize BioC 1.7 is the current devel version, right?
2. After you see the error, try traceback() to get a better idea of
   where things are going wrong.  Then you can use debug(someFunc) to
   debug in the place where the error occurs.  I'm sure the package
   maintainers will be most receptive to any bug fixes.

Best,

+ seth


On 31 Aug 2005, lai at lindaspaces.com wrote:

> Hi, I have built R (current development version) and BioConductor
> 1.7 with portland group compiler on a AMD Opteron.  When I ran qc
> assessment on Affymetrix latin square data set, I got the following
> output,
>
> Loading required package: affy Loading required package: Biobase
> Loading required package: tools Welcome to Bioconductor Vignettes
> contain introductory material.  To view, simply type: openVignette()
> For details on reading vignettes, see the openVignette help page.
> Loading required package: reposTools Welcome to 'simpleaffy' V 2.1.3
> Produced by The Paterson Institute for Cancer Research and funded by
> CANCER RESEARCH UK.  http://bioinformatics.picr.man.ac.uk/simpleaffy
> mailto: microarray at picr.man.ac.uk Background correcting Retrieving
> data from AffyBatch...done.  Computing expression
> calls...  .........................done.  scaling to a TGT of 100
> ...  Scale factor for: 0203_YH10_H_MCF7_r1.CEL 0.291660289301555
> Scale factor for: 0203_YH11_H_MCF10A_r1.CEL 0.42025300545212 Scale
> factor for: 0203_YH12_H_a100MCF7_r1.CEL 0.287589038746987 Scale
> factor for: 0203_YH13_H_a100MCF10A_r1.CEL 0.451200408584071 Scale
> factor for: 0203_YH14_H_a10MCF7_r1.CEL 0.385462078301135 Scale
> factor for: 0203_YH15_H_a100MCF7_r2.CEL 0.284974495993646 Scale
> factor for: 0203_YH16_H_a100MCF7_r3.CEL 0.376484877281483 Scale
> factor for: 0203_YH17_H_a100MCF10A_r2.CEL 0.374087365857816 Scale
> factor for: 0203_YH18_H_a100MCF10A_r3.CEL 0.487207458237659 Scale
> factor for: 0203_YH19_H_a10MCF7_r2.CEL 0.413217979158927 Scale
> factor for: 0203_YH20_H_a10MCF7_r3.CEL 0.482703032325383 Scale
> factor for: 0203_YH21_H_a10MCF10A_r1.CEL 0.945369712044904 Scale
> factor for: 0203_YH22_H_a10MCF10A_r2.CEL 1.96143996386198 Scale
> factor for: 0203_YH23_H_a10MCF10A_r3_rescan.CEL 0.841535915879218
> Scale factor for: 0203_YH24_H_MCF7_r2.CEL 0.347795838770919 Scale
> factor for: 0203_YH25_H_MCF7_r3.CEL 0.318539156900791 Scale factor
> for: 0203_YH26_H_MCF10A_r2.CEL 0.578922233010316 Scale factor for:
> 0203_YH27_H_MCF10A_r3.CEL 0.394833650209601 Scale factor for:
> 0403_YH34_H_a10MCF10A_r4.CEL 1.06804698986081 Scale factor for:
> 0403_YH35_H_a1MCF7_r1_2.CEL 3.5923019165673 Scale factor for:
> 0403_YH36_H_a1MCF7_r2.CEL 3.16130786066591 Scale factor for:
> 0403_YH37_H_a1MCF7_r3_2.CEL 2.01330391697437 Scale factor for:
> 0403_YH38_H_a1MCF10A_r1.CEL 0.923881702153984 Scale factor for:
> 0403_YH39_H_a1MCF10A_r2_2.CEL 2.29265379531566 Scale factor for:
> 0403_YH40_H_a1MCF10A_r3.CEL 4.02474777803345 Getting probe level
> data...  Computing p-values Doing PMA Calls TEST 1 : time Elapsed =
> 0 1 20
>
> Background correcting Retrieving data from AffyBatch...done.
> Computing expression calls...  .........Error in FUN(X[[9]], ...) :
> Expecting 22283 unique probesets, found 22284
>
>
> Can anyone advise me on how to fix this problem? I was able to run
> the same data set with gcc-compiled R2.1.1 and BioConductor 1.6
> successfully.
>
>
> Here is the code that I ran, if it helps to diagnose the problems.
>
> library(simpleaffy);
> library(affy);
>
> ampli.data <- ReadAffy()
>
> # normalize the data using call.exprs and mas5
> ampli.eset <- call.exprs(ampli.data, "mas5")
>
> # see what data is stored in ampli.eset at description@preprocssing
> names(ampli.eset at description@preprocessing)
>
> # acess each piece of information within 
> ampli.eset at description@preprocessing scale factors
> ampli.eset at description@preprocessing$sfs
>
> # filenames so that the scale factors can be related to their chips
> ampli.eset at description@preprocessing$filenames
>
> # tgt is the target intensity each chip was scaled to
> ampli.eset at description@preprocessing$tgt
>
> # which version of the affy package was used
> ampli.eset at description@preprocessing$affyversion
>
> qc.data <- qc(ampli.data, ampli.eset);
>
> slotNames(qc.data);
>
> # scale.factors contains a list of scale factors applied to each
> # chip;
> qc.data at scale.factors
>
> # target is the target intensity that each chip was scaled to
> qc.data at target
>
> # percent.present is a list of the percentage of probesets called 
> present on each chip;
> qc.data at percent.present
>
> # average.background, minimum.background, maximum.background are all
> lists detailing
> # the average, minimum and maximum background for each chip;
> qc.data at average.background
>
> # spikes is a matrix containing normalized values for each of the
> # spike
> controls
> colnames(qc.data at spikes)
>
>
>
> Thanks,
> Jennifer
>
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide! http://www.R-project.org/posting-guide.html



From macq at llnl.gov  Wed Aug 31 17:30:48 2005
From: macq at llnl.gov (Don MacQueen)
Date: Wed, 31 Aug 2005 08:30:48 -0700
Subject: [R] xtable
In-Reply-To: <200508301846.08853.ferri.leberl@gmx.at>
References: <200508301846.08853.ferri.leberl@gmx.at>
Message-ID: <p06210200bf3b7cd71362@[128.115.153.6]>

You do have to load optional packages in each R session. See

   ?require

But you can automate the loading; see

   ?Startup

-Don

At 6:46 PM +0200 8/30/05, Mag. Ferri Leberl wrote:
>I have installed package xtable with
>
>su -c 'R CMD INSTALL xtable'
>
>and got this promising feedback:
>
>* Installing *source* package 'xtable' ...
>** R
>** data
>** help
>  >>> Building/Updating help pages for package 'xtable'
>      Formats: text html latex example
>* DONE (xtable)
>
>Despite that, R returns:
>
>Error: couldn't find function "print.xtable"
>Execution halted
>
>when I call that function.
>What have I done wrong? Do I have to activate the package everytime when I
>start R?
>Thank you in advance!
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html


-- 
--------------------------------------
Don MacQueen
Environmental Protection Department
Lawrence Livermore National Laboratory
Livermore, CA, USA



From Hathaikan.Chootrakool at newcastle.ac.uk  Wed Aug 31 17:44:54 2005
From: Hathaikan.Chootrakool at newcastle.ac.uk (Hathaikan Chootrakool)
Date: Wed, 31 Aug 2005 16:44:54 +0100 (BST)
Subject: [R] loop
Message-ID: <1309.128.240.6.80.1125503094.squirrel@128.240.6.80>

I was wondering why this loop doesn't work!

for (i in 1:k)
fnTr[i] <-  function (p) 0.5* sum ( n*log(2*pi) - log(sd(i)^2)
                         +(logitp(i)-p)^2/sd(i)^2 )
outTr[i]<- nlm (fnTr[i],p=c(10),hessian=TRUE)
minimumTr[i] <- outTr[i]$minimum
valueTr[i] <- outTr[i]$estimate
list (minimumTr[i],valueTr[i])

Has anyone can help me?

Thank you very much
Hathaikan



From ernesto at ipimar.pt  Wed Aug 31 17:57:11 2005
From: ernesto at ipimar.pt (ernesto)
Date: Wed, 31 Aug 2005 16:57:11 +0100
Subject: [R] loop
In-Reply-To: <1309.128.240.6.80.1125503094.squirrel@128.240.6.80>
References: <1309.128.240.6.80.1125503094.squirrel@128.240.6.80>
Message-ID: <4315D357.10303@ipimar.pt>

Hathaikan Chootrakool wrote:

>I was wondering why this loop doesn't work!
>
>for (i in 1:k)
>fnTr[i] <-  function (p) 0.5* sum ( n*log(2*pi) - log(sd(i)^2)
>                         +(logitp(i)-p)^2/sd(i)^2 )
>outTr[i]<- nlm (fnTr[i],p=c(10),hessian=TRUE)
>minimumTr[i] <- outTr[i]$minimum
>valueTr[i] <- outTr[i]$estimate
>list (minimumTr[i],valueTr[i])
>
>Has anyone can help me?
>
>Thank you very much
>Hathaikan
>
>______________________________________________
>R-help at stat.math.ethz.ch mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html
>
>  
>
missing {} on your code block

for(...){
...
}

EJ



From matthew.r.robinson at ed.ac.uk  Wed Aug 31 18:25:49 2005
From: matthew.r.robinson at ed.ac.uk (Matt Robinson)
Date: Wed, 31 Aug 2005 17:25:49 +0100
Subject: [R] extrating BLUP values from linear mixed models
Message-ID: <1125505549.4315da0dabe6f@sms.ed.ac.uk>

Hello,

I wish to learn how to extract best linear unbiased predictor values from a
linear mixed model of repeated measures on individuals which has a random error
structure (random =~ 1|individual).

Thanks for your time,
Kind regards
Matt

--
Matt Robinson
Institute of Evolutionary Biology
University of Edinburgh



From HDoran at air.org  Wed Aug 31 18:28:50 2005
From: HDoran at air.org (Doran, Harold)
Date: Wed, 31 Aug 2005 12:28:50 -0400
Subject: [R] extrating BLUP values from linear mixed models
Message-ID: <88EAF3512A55DF46B06B1954AEF73F740A0A3981@dc1ex2.air.org>

Use the ranef() command 

ranef(fm1, level=1)

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Matt Robinson
Sent: Wednesday, August 31, 2005 12:26 PM
To: r-help at stat.math.ethz.ch
Subject: [R] extrating BLUP values from linear mixed models

Hello,

I wish to learn how to extract best linear unbiased predictor values
from a linear mixed model of repeated measures on individuals which has
a random error structure (random =~ 1|individual).

Thanks for your time,
Kind regards
Matt

--
Matt Robinson
Institute of Evolutionary Biology
University of Edinburgh

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From otoomet at ut.ee  Wed Aug 31 18:53:30 2005
From: otoomet at ut.ee (Ott Toomet)
Date: Wed, 31 Aug 2005 19:53:30 +0300
Subject: [R] "best" c++ matrix library?
Message-ID: <200508311653.j7VGrUk6000824@hugo.obs.ee>

Hi folks,

I am planning to write some more time-consuming matrix manipulations
in c++.  What is the experience with the existing c++ matrix
libraries?  Do you have some recommendations?  Are some libraries more
compatible with R than the others?

All suggestions welcome!

Best,
Ott



From isotta_felli at yahoo.com  Wed Aug 31 18:57:13 2005
From: isotta_felli at yahoo.com (Isotta Felli)
Date: Wed, 31 Aug 2005 09:57:13 -0700 (PDT)
Subject: [R] sinput for Windows
Message-ID: <20050831165713.88555.qmail@web35210.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050831/23f3dda6/attachment.pl

From c_naber at yahoo.com.br  Wed Aug 31 19:25:48 2005
From: c_naber at yahoo.com.br (Caio Lucidius Naberezny Azevedo)
Date: Wed, 31 Aug 2005 17:25:48 +0000 (GMT)
Subject: [R] Block-Diagonal Matrix and Multivariate Skew Normal
Message-ID: <20050831172548.22618.qmail@web34015.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050831/925ce2f6/attachment.pl

From c_naber at yahoo.com.br  Wed Aug 31 19:43:47 2005
From: c_naber at yahoo.com.br (Caio Lucidius Naberezny Azevedo)
Date: Wed, 31 Aug 2005 17:43:47 +0000 (GMT)
Subject: [R] En: Block-Diagonal Matrix and Multivariate Skew Normal
Message-ID: <20050831174348.35206.qmail@web34008.mail.mud.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050831/f4d4bb91/attachment.pl

From charles.edwin.white at us.army.mil  Wed Aug 31 19:46:12 2005
From: charles.edwin.white at us.army.mil (White, Charles E WRAIR-Wash DC)
Date: Wed, 31 Aug 2005 13:46:12 -0400
Subject: [R] Reading numeric data in Excel as character data in R using RODBC
Message-ID: <8BAEC5E546879B4FAA536200A292C61489AE19@AMEDMLNARMC135.amed.ds.army.mil>

The Excel 'database' I am pulling from mixes multiple character
indicators for different kinds of non-numeric results in the same column
as the numeric values. A simple sqlFetch turns all of the character
indicators into NAs. I would like to pull in all of the Excel data as
character so that I can split the column into multiple types of vectors
and control the type conversion within R. Can anyone provide clues as to
how I go about getting RODBC to bring in data containing some numbers
without running a numeric conversion?

The simple code I use to pull data directly from Excel is generally
something like the following:
prj<-'C:/data' 
library(RODBC)
channel <-
odbcConnectExcel(paste(prj,"/intermediate/datafile.xls",sep=''))
r <- sqlTables(channel)
ifn.display <- sqlFetch(channel, "SHEET1")
il2.display <- sqlFetch(channel, "SHEET2")
pl.display <- sqlFetch(channel, "SHEET3")
odbcClose(channel)

Background: The current problem is small enough to solve with read.csv
but I expect to get larger problems in the future. My clients generally
give me data in Excel format. Sometimes I get multiple character
indicators for different kinds of non-numeric results. Sometimes I get
40+ sheets in a single file where all of the sheets are formatted alike.
I'd like to be ready to run a reasonably automated data conversion
whenever a client decides to give me both at once.

Thanks for your time.

Chuck



From vehbisinan at gmail.com  Wed Aug 31 20:01:29 2005
From: vehbisinan at gmail.com (Vehbi Sinan Tunalioglu)
Date: Wed, 31 Aug 2005 21:01:29 +0300
Subject: [R] "best" c++ matrix library?
In-Reply-To: <200508311653.j7VGrUk6000824@hugo.obs.ee>
References: <200508311653.j7VGrUk6000824@hugo.obs.ee>
Message-ID: <4315F079.3080809@gmail.com>

Hi,

I used Meschach: http://www.math.uiowa.edu/~dstewart/meschach/
However, it is written in C. The API is strong. I used the same API and
trimmed down the functionality, as well. Both worked for me.

IBM Developworks has an article on the subject "Matrix libraries for C
and C++":
http://www-128.ibm.com/developerworks/linux/library/l-matrix.html

It has also a comparison for some libraries.

I wonder if there is another library...

--vst


Ott Toomet wrote:
> Hi folks,
> 
> I am planning to write some more time-consuming matrix manipulations
> in c++.  What is the experience with the existing c++ matrix
> libraries?  Do you have some recommendations?  Are some libraries more
> compatible with R than the others?
> 
> All suggestions welcome!
> 
> Best,
> Ott
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! http://www.R-project.org/posting-guide.html



From murdoch at stats.uwo.ca  Wed Aug 31 20:12:03 2005
From: murdoch at stats.uwo.ca (Duncan Murdoch)
Date: Wed, 31 Aug 2005 14:12:03 -0400
Subject: [R] sinput for Windows
In-Reply-To: <20050831165713.88555.qmail@web35210.mail.mud.yahoo.com>
References: <20050831165713.88555.qmail@web35210.mail.mud.yahoo.com>
Message-ID: <4315F2F3.2090209@stats.uwo.ca>

On 8/31/2005 12:57 PM, Isotta Felli wrote:
> Hi, I'm trying to latex part of my R- code and don't know where to find the sinput package to include in my version of miktex (I have the LINUX version handy, but need also the Windows one) Any idea? (sorry it is not really a R question)


If you have it on Linux, just grab a copy, install it in your localtexmf 
folder, and rebuild the indices.  miktex uses the same format for 
packages as other TeX implementations.

Duncan Murdoch



From andy_liaw at merck.com  Wed Aug 31 20:36:46 2005
From: andy_liaw at merck.com (Liaw, Andy)
Date: Wed, 31 Aug 2005 14:36:46 -0400
Subject: [R] Block-Diagonal Matrix and Multivariate Skew Normal
Message-ID: <39B6DDB9048D0F4DAD42CB26AAFF0AFAFED3F6@usctmx1106.merck.com>

For your first question, here's a function originally posted by Ben Bolker,
with modification by Rich Raubertas:

blockdiag <- function (x, ...) 
{
    if (!is.list(x)) 
        x <- list(x)
    args <- list(...)
    if (length(args) > 0) 
        args <- c(x, args)
    else args <- x
    idx <- which(!sapply(args, is.matrix))
    if (length(idx) > 0) 
        for (i in idx) args[[i]] <- as.matrix(args[[i]])
    if (length(args) == 1) 
        return(args[[1]])
    nr <- sapply(args, nrow)
    nc <- sapply(args, ncol)
    cumnc <- cumsum(nc)
    NR <- sum(nr)
    NC <- sum(nc)
    rowfun <- function(m, zbefore, zafter) {
        cbind(matrix(0, ncol = zbefore, nrow = nrow(m)), m, matrix(0, 
            ncol = zafter, nrow = nrow(m)))
    }
    ret <- rowfun(args[[1]], 0, NC - ncol(args[[1]]))
    for (i in 2:length(args)) {
        ret <- rbind(ret, rowfun(args[[i]], cumnc[i - 1], NC - 
            cumnc[i]))
    }
    ret
}

Andy

> From: Caio Lucidius Naberezny Azevedo
> 
> Dear R-users,
>  
> Does anybody know how to construct a block-diagonal matrix 
> (with the blocks being different matrixs, concerning the 
> dimension and the values) ? 
>  
> I would like to know also if there is any package that 
> generates values from a multivariate skew normal distribution.
>  
> Thanks all,
>  
> Caio
>  
>  
> 
> 		
> ---------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 
>



From gregory.r.warnes at pfizer.com  Wed Aug 31 21:19:19 2005
From: gregory.r.warnes at pfizer.com (Warnes, Gregory R)
Date: Wed, 31 Aug 2005 15:19:19 -0400
Subject: [R] Advice about system for installing & updating all R
	packa	ge in a Linux Lab?
Message-ID: <915D2D65A9986440A277AC5C98AA466F01863234@groamrexm02.amer.pfizer.com>


If you have several different versions of R installed, you might want to use
a script like this one, which should work on (at least) 1.9.1 and newer.

<script>
#!/bin/sh

echo "##############"
echo "## This script will attempt to install all available R packages"
echo "## from the package repositories:"
echo "##"
echo "##   - CRAN:  http://cran.r-project.org/"
echo "##   - BioCondictor:  http://www.bioconductor.org"
echo "##"
echo "## As well as Pfizer custom packages"
echo "## "
echo "##   - Rlsf:  ~warneg/src/R/Rlsf"
echo "##   - AffyTool: nlvfs016:rstat-data/"
echo "##               ExpressionAnalysis/StandardAffyAnalysis/AffyTool"
echo "##"
echo "##############"
echo "##"

if [ -z '$1' ]; then
  RCMD="R"
  echo "## Parameter 1 : R Command Name = $RCMD (Default)"
else
  RCMD=$1
  echo "## Parameter 1 : R Command Name = $RCMD"
fi
export RCMD
echo $RCMD

echo "##"
echo "##############"
echo "##"
echo "## Starting R ..."
echo "##"

$RCMD --vanilla <<EOF

##
## Update installed packages
##
update.packages (repos ="http://cran.r-project.org",ask = FALSE,
installWithVers=TRUE )

##
## Install New Packages from CRAN
##
#
if (exists("new.packages",mode="function"))
   {
     options(repos="http://cran.r-project.org")
     new.list <- new.packages(ask=FALSE)
   } else
   {
     CRAN.list <- CRAN.packages()[,1]
     here.list <- installed.packages()[,1]
     new.list <- CRAN.list[ ! CRAN.list  %in% here.list ]
     
   }
   install.packages(pkgs=new.list, dependencies=TRUE, installWithVers=TRUE )

##
## Install (New) Bioconductor Packages
##
source("http://www.bioconductor.org/getBioC.R") 
getBioC(groupName="all")
y

EOF

echo "##############"
echo "## All Done!"
echo "##"
echo "## *Check the log for failed package installs*"
echo "##"
echo "##############"
</script>





> -----Original Message-----
> From: r-help-bounces at stat.math.ethz.ch
> [mailto:r-help-bounces at stat.math.ethz.ch]On Behalf Of Prof 
> Brian Ripley
> Sent: Saturday, August 20, 2005 1:28 AM
> To: Paul Johnson
> Cc: r-help at stat.math.ethz.ch
> Subject: Re: [R] Advice about system for installing & updating all R
> package in a Linux Lab?
> 
> 
> This is based on the pre-2.1.0 ideas.  Try
> 
> update.packages(ask=FALSE)
> install.packages(new.packages(), dependencies=TRUE)
> 
> However, I would suggest that you set up each student with a 
> library, say 
> ~/R/library, and point R_LIBS at it (set in Renviron.site).  
> That's what 
> we do for Windows, and it seems successful.  (We have other 
> reasons to 
> want very complete central Linux setups, one being that we 
> run more than 
> one archtecture where personal libraries are a little harder 
> to manage.)
> 
> On Fri, 19 Aug 2005, Paul Johnson wrote:
> 
> > Good day:
> >
> > I'm administering 6 linux systems (FC4) in a student lab 
> and worry that
> > users may want packages that are not installed.  I get 
> tired of adding
> > them one by one.  Then I happened upon this page
> >
> > http://support.stat.ucla.edu/view.php?supportid=30
> 
> Many of the commands there are now or about to be deprecated.  See my 
> article in the current R-News.
> 
> > about installing all R packages from CRAN.  That did not 
> run as it was,
> > but after some fiddling I arrived at the following script, 
> which does
> > run and it builds many packages and reports failures on the rest:
> >
> > #R_installAll.R
> > options(repos = "http://lib.stat.cmu.edu/R/CRAN/")
> > update.packages(ask=F)
> > x <- 
> packageStatus(repositories="http://cran.r-project.org/src/contrib")
> > st <- x$avai["Status"]
> > install.packages(rownames(st)[which(st$Status=="not installed")],
> > dependencies=T)
> >
> > If I run that in batch mode (as root, of course)
> >
> > >  R CMD BATCH R_installAll.R
> >
> > It produces some informative output. Some packages don't 
> build because
> > they are for Windows.  As Prof Ripley mentioned recently, 
> some packages
> > don't build because of gcc-4.0.1. Some fail because I don't 
> have some
> > requisite libraries installed.  I try to deduce which FC 
> packages may be
> > used to fix that and iterate the process now and then.
> >
> > But, for the most part, the packages to be OK (as far as I 
> can tell).
> > The output of a recent update is posted on the net here, in 
> case you are
> > interested to see (this lists the ones that don't build plus the
> > successful updates):
> >
> > http://lark.cc.ku.edu/~pauljohn/software/R/R_installAll.Rout
> >
> > I can't see how this does any damage, since the packages that don't
> > build are very graceful about erasing themselves, and the 
> ones that do
> > build are automatically available for the users.
> >
> > Can you see any downside to scheduling this process to run as a cron
> > job, say once per week, to keep packages up to date?
> 
> None at all.  We do something similar (but based on 
> new.packages and with 
> a stoplist of packages that we know will not install).
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at stat.math.ethz.ch mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide! 
> http://www.R-project.org/posting-guide.html
> 
> 


LEGAL NOTICE\ Unless expressly stated otherwise, this messag...{{dropped}}



From jordi_molins at hotmail.com  Wed Aug 31 21:49:24 2005
From: jordi_molins at hotmail.com (Jordi)
Date: Wed, 31 Aug 2005 21:49:24 +0200
Subject: [R] b1 function in ch 12 scripts of MASS
Message-ID: <BAY104-DAV13B044093D7DEFBE6E0C68F0A10@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050831/31ad5871/attachment.pl

From mkalisiak at gmail.com  Wed Aug 31 22:21:08 2005
From: mkalisiak at gmail.com (Maciej Kalisiak)
Date: Wed, 31 Aug 2005 16:21:08 -0400
Subject: [R] label *on the side* in conditional lattice plots?
Message-ID: <78e6ba3105083113215cb130e1@mail.gmail.com>

I'm doing bwplot(x ~ y | z, ...) with lattice, but would like the
z-labels to appear to the *side* of each bwplot, rather than on top...
is this possible?  The main reason is that my bwplots are horizontal,
and as such can be nicely squished in the vertical axis (big
space-saver when including in papers), but  the labels "get in the
way", look too large in comparison, while I have all this empty space
to the side of the plots which is being wasted instead...

-- 
Maciej Kalisiak
<mkalisiak at gmail.com>
http://www.dgp.toronto.edu/~mac



From laboissiere at cbs.mpg.de  Wed Aug 31 22:28:29 2005
From: laboissiere at cbs.mpg.de (Rafael Laboissiere)
Date: Wed, 31 Aug 2005 22:28:29 +0200
Subject: [R] "best" c++ matrix library?
In-Reply-To: <200508311653.j7VGrUk6000824@hugo.obs.ee>
References: <200508311653.j7VGrUk6000824@hugo.obs.ee>
Message-ID: <20050831202829.GB11991@laboiss2>

* Ott Toomet <otoomet at ut.ee> [2005-08-31 19:53]:

> I am planning to write some more time-consuming matrix manipulations
> in c++.  What is the experience with the existing c++ matrix
> libraries?  Do you have some recommendations?  Are some libraries more
> compatible with R than the others?

Liboctave is a quite powerful C++ matrix library.  It is part of Octave
(www.octave.org), but you can write standalone applications with it.
Since liboctave links against standard Fortran and C libraries (lapack,
odepack, minpack, quadpack, slatec, fftw, etc), you have access to all
matrix algorithms of Octave.

Attached below is an example, showing eigenvalue computation (via the
lapack routine).  Also attached is the compilation command and the output
of the program (in my Debian sarge box).

I do not know how liboctave compares with the other libraries as regards
speed.  As far as I know, there is no efforts for gluing liboctave into
R. 

-- 
Rafael Laboissiere
-------------- next part --------------
$ g++ -I/usr/include/octave eig.cc -o eig -L/usr/lib/octave-2.1.69/ -loctave
$ LD_LIBRARY_PATH=/usr/lib/octave-2.1.69/ ./eig
Original Matrix
 3 2
 2 0

Eigen Vectors
 (0.447214,0) (-0.894427,0)
 (-0.894427,0) (-0.447214,0)

Eigen Values
(-1,0)
(4,0)

Recomposed Matrix
 (3,0) (2,0)
 (2,0) (-9.92587e-17,0)

From matthew_wiener at merck.com  Wed Aug 31 22:47:11 2005
From: matthew_wiener at merck.com (Wiener, Matthew)
Date: Wed, 31 Aug 2005 16:47:11 -0400
Subject: [R] label *on the side* in conditional lattice plots?
Message-ID: <4E9A692D8755DF478B56A2892388EE1F06B6B4@usctmx1118.merck.com>

I think you might be able to use the "horizontal" argument to lattice to
rotate all your plots and squish them in the other dimension.  (Though I
don't know whether you consider that a good outcome ...)

Hope this helps,

Matt Wiener

-----Original Message-----
From: r-help-bounces at stat.math.ethz.ch
[mailto:r-help-bounces at stat.math.ethz.ch] On Behalf Of Maciej Kalisiak
Sent: Wednesday, August 31, 2005 4:21 PM
To: r-help at stat.math.ethz.ch
Subject: [R] label *on the side* in conditional lattice plots?


I'm doing bwplot(x ~ y | z, ...) with lattice, but would like the
z-labels to appear to the *side* of each bwplot, rather than on top...
is this possible?  The main reason is that my bwplots are horizontal,
and as such can be nicely squished in the vertical axis (big
space-saver when including in papers), but  the labels "get in the
way", look too large in comparison, while I have all this empty space
to the side of the plots which is being wasted instead...

-- 
Maciej Kalisiak
<mkalisiak at gmail.com>
http://www.dgp.toronto.edu/~mac

______________________________________________
R-help at stat.math.ethz.ch mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide!
http://www.R-project.org/posting-guide.html



From yifuc at uga.edu  Wed Aug 31 22:59:56 2005
From: yifuc at uga.edu (Yi-Fu Chen)
Date: Wed, 31 Aug 2005 16:59:56 -0400
Subject: [R] Imputation using Pan in R
Message-ID: <000b01c5ae6e$f1063a80$b2d6c080@fcs.uga.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050831/53ea4572/attachment.pl

From itsme_410 at yahoo.com  Wed Aug 31 23:37:46 2005
From: itsme_410 at yahoo.com (Globe Trotter)
Date: Wed, 31 Aug 2005 14:37:46 -0700 (PDT)
Subject: [R] eigen-decomposition of symmetric BCCB matrices
Message-ID: <20050831213746.66597.qmail@web54515.mail.yahoo.com>

Hi,

Can anyone please point to how to decompose BCCB
(Block-Circulant-Circulant-Block) matrices? I am interested in the derivations:
I do know that this can be numerically done using 2-dimensional FFTs.

Many thanks and best wishes!



From edd at debian.org  Wed Aug 31 23:46:07 2005
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 31 Aug 2005 21:46:07 +0000 (UTC)
Subject: [R] "best" c++ matrix library?
References: <200508311653.j7VGrUk6000824@hugo.obs.ee>
Message-ID: <loom.20050831T233343-595@post.gmane.org>

Ott Toomet <otoomet <at> ut.ee> writes:
> I am planning to write some more time-consuming matrix manipulations
> in c++.  What is the experience with the existing c++ matrix
> libraries?  Do you have some recommendations?  Are some libraries more
> compatible with R than the others?

A loooong time ago, I used to use the newmat C++ library by Robert Davies -- 
see http://www.robertnz.net/nm_intro.htm which states 
    "This C++ library is intended for scientists and engineers who need to
     manipulate a variety of types of matrices using standard matrix operations.
     Emphasis is on the kind of operations needed in statistical calculations
     such as least squares, linear equation solve and eigenvalues."

In fact, my use even lead to a short review about newmat and g++ for the Journal 
of Applied Econometrics (http://dirk.eddelbuettel.com/papers/gccnewmat.ps.gz).

Robert has continued to maintain, support and extend newmat. I would probably 
start there if I needed a C++ Matrix library as newmat is (in no order of 
preference)
-- fairly small (unlike Boost)
-- as I recall, doesn't depend on anything else
-- well documented 
-- well tested
-- pretty "clean" conceptually

Moreover, Robert really is a statistician so there may be interest on his side
in tieing newmat to R if were to provide some prototypes. 

But this really is a question of programming style and preferences, and mine
certainly changed in the meantime so take this with the usual spoon of salt.

Hope this helps,  Dirk



From ranli at cbmi.pitt.edu  Wed Aug 31 21:47:45 2005
From: ranli at cbmi.pitt.edu (Li, Ran)
Date: Wed, 31 Aug 2005 15:47:45 -0400
Subject: [R] R package for ICA
Message-ID: <09D04633DAED5F489FFEB6A0EAF22C16022BC8B2@pikachu.health.pitt.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050831/8e2b7658/attachment.pl

From emmadigonnet at aol.com  Tue Aug 30 23:26:46 2005
From: emmadigonnet at aol.com (emmadigonnet@aol.com)
Date: Tue, 30 Aug 2005 17:26:46 EDT
Subject: [R] under sample problem
Message-ID: <7d.6fd8d2d9.30462916@aol.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
Url: https://stat.ethz.ch/pipermail/r-help/attachments/20050830/ac4fe5b9/attachment.pl

